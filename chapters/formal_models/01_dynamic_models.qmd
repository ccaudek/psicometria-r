# Il modello di revisione degli obiettivi {#sec-dynamic-models-goal-updating}


## Introduzione {.unnumbered .unlisted}

::: {.lead}
Molti dei fenomeni studiati in psicologia non sono statici, ma si sviluppano e si trasformano nel tempo. L’apprendimento, l’adattamento agli errori, la regolazione degli obiettivi, l’emergere o la remissione di sintomi clinici sono tutti esempi di *processi dinamici*, in cui ciò che osserviamo in un dato momento è il risultato di una storia pregressa.
:::

Tuttavia, gli strumenti statistici più utilizzati in psicologia trascurano spesso questa dimensione temporale. Confrontiamo medie, calcoliamo correlazioni o eseguiamo regressioni, spesso trattando le osservazioni come indipendenti tra loro. Questo approccio è utile per molte domande, ma inadeguato quando l’obiettivo è *comprendere l’evoluzione* di un comportamento o di uno stato psicologico.

Se vogliamo capire *come* le persone modificano i propri obiettivi, cambiano strategia, o si adattano nel tempo a esperienze positive e negative, abbiamo bisogno di un approccio che tenga conto della sequenza degli eventi. Serve un modello in grado di descrivere *le regole del cambiamento*.


## Perché abbiamo bisogno di modelli dinamici?

Un *modello dinamico* è una rappresentazione matematica che esplicita il modo in cui un sistema evolve nel tempo. La caratteristica distintiva di questi modelli è la presenza di *dipendenze temporali*: almeno una delle variabili dipende da valori passati, non solo da ciò che accade nel presente.

Questo è ciò che li differenzia dai modelli statici, dove ogni osservazione è trattata come indipendente dalle precedenti. Nei modelli dinamici, invece, esiste una *memoria* del passato, che influenza l’andamento futuro del processo. Nei modelli statici, la variabilità del comportamento è trattata come rumore o differenza individuale. Nei modelli dinamici, questa variabilità diventa informativa: è l'espressione dell'adattamento del sistema alle condizioni del contesto o alla propria storia passata.

Una classe importante di variabili in questo contesto è costituita dalle *variabili di stato* (in inglese: *state variables* o *stock variables*), che rappresentano il livello accumulato di una certa quantità nel tempo: un obiettivo personale, un livello di motivazione, una credenza, o un sintomo. Queste variabili si aggiornano a ogni passo temporale secondo una *regola di cambiamento*, definita in termini matematici.


### Come si costruisce un modello dinamico?

Formulare un modello dinamico significa tradurre in termini espliciti una teoria del cambiamento. I passaggi fondamentali sono:

1. *Identificare le variabili rilevanti*: quali sono gli elementi del sistema che vogliamo modellare?
2. *Stabilire le regole di aggiornamento*: come cambia ciascuna variabile nel tempo, in risposta a feedback o input esterni?
3. *Formalizzare il modello in equazioni*: trasformare le regole in una struttura matematica coerente.
4. *Valutare la validità del modello*: confrontare le sue previsioni con i dati osservati, usando metodi statistici appropriati.

Questo approccio è particolarmente adatto alla psicologia, dove l'interesse non è solo se un comportamento cambia, ma *come* evolve nel tempo.


## Un esempio concreto: il modello di revisione degli obiettivi

Per chiarire meglio questo concetto, partiamo da un esempio concreto: la regolazione degli obiettivi in base al feedback. Immaginiamo un esperimento in cui i partecipanti devono svolgere un compito ripetitivo, come classificare coppie di immagini. Prima di ogni prova (*trial*), ciascuno fissa un obiettivo personale—ad esempio, migliorare la velocità o la precisione rispetto al tentativo precedente. Al termine del trial, riceve un feedback sulla propria performance e può così decidere se mantenere o modificare l’obiettivo per la prova successiva.  

Questo ciclo – *definizione dell’obiettivo, esecuzione, feedback, aggiustamento* – è dinamico e si ripete in modo iterativo. Un buon modello dinamico riesce a catturare con precisione tale meccanismo, permettendo ad esempio di stimare quanto rapidamente una persona rivede le proprie aspirazioni in risposta a successi o fallimenti.  

Nel resto del capitolo, mostreremo come formalizzare matematicamente questo processo e come stimarne i parametri con un approccio bayesiano, implementato in Stan.  


### Come formalizzare questo processo?

Una delle ipotesi più semplici, ma sorprendentemente potenti, è che le persone modifichino i propri obiettivi in funzione della discrepanza tra i risultati ottenuti (*performance*) e le aspettative (*goal*). Se la performance supera l'obiettivo, le aspettative tendono ad aumentare (ambizione crescente). Se la performance è inferiore, si tende a ridurre le aspettative (aggiustamento conservativo).

@knight2023tutorial hanno formalizzato questa intuizione nel seguente modello dinamico lineare

$$
G_t = G_{t-1} + \alpha \cdot (P_{t-1} - G_{t-1}) + \beta ,
$$ {#eq-knight2023}

dove:

* $G_t$ è il nuovo obiettivo fissato al trial $t$,
* $P_{t-1}$ è la performance osservata al trial precedente,
* $\alpha$ rappresenta la sensibilità alla discrepanza (quanto il goal viene aggiornato in risposta all’errore),
* $\beta$ rappresenta un bias sistematico. $\beta$ > 0: deriva ambiziosa (es. pressione sociale); $\beta$ < 0: deriva cautelativa (es. affaticamento).

Questo è un modello *sample-level* perché assume che tutti i partecipanti condividano gli stessi parametri $\alpha$ e $\beta$, stimati sull’intero campione.


### Illustrazione numerica del modello

Per comprendere meglio il comportamento del modello, esaminiamo due scenari con gli stessi parametri:

* $\alpha = 0.5$ (apprendimento moderato: 50% della discrepanza viene incorporata nel nuovo obiettivo);
* $\beta = 2$ (tendenza sistematica ad aumentare l'obiettivo di 2 punti a ogni trial).

**Scenario 1: Performance superiore all'obiettivo.**

* Obiettivo precedente: $G_{t-1} = 50$ punti.
* Performance effettiva: $P_{t-1} = 60$ punti.

Calcolo:

$$
G_t = 50 + 0.5 \cdot (60 - 50) + 2 = 50 + 5 + 2 = \mathbf{57}.
$$

**Interpretazione:**
Il partecipante ha superato l’obiettivo (+10 punti). Il nuovo obiettivo si adatta parzialmente alla discrepanza (+5 punti, per effetto di $\alpha$) e riceve un'ulteriore spinta verso l'alto (+2 punti, per effetto di $\beta$).

Risultato: un aggiustamento ambizioso (da 50 a 57), dove $\beta$ amplifica l'effetto del successo.

**Scenario 2: Performance inferiore all'obiettivo.**

* Obiettivo precedente: $G_{t-1} = 50$ punti.
* Performance effettiva: $P_{t-1} = 40$ punti.

Calcolo:

$$
G_t = 50 + 0.5 \cdot (40 - 50) + 2 = 50 - 5 + 2 = \mathbf{47}.
$$

**Interpretazione:**
Nonostante la performance deludente (-10 punti), l'obiettivo si riduce a causa dell'errore (-5 punti, effetto $\alpha$), ma la componente $\beta$ (+2 punti) attenua il calo, evitando un crollo motivazionale.

Questo modello può riflettere la resilienza (ovvero la tendenza a non penalizzare eccessivamente gli insuccessi) e/o la pressione esterna (per esempio, un esperimento che "spinge" a migliorare).

**Confronto con $\beta$ = 0: l'effetto della deriva sistematica.**

Se $\beta$ fosse uguale a 0, gli obiettivi si muoverebbero solo in risposta alla performance:

 | Scenario       | Con $\beta$=2 | Senza $\beta$ ($\beta$=0) | Differenza |
 |----------------|---------|--------------|------------|
 | **Successo**   | 57      | 55           | +2 ($\beta$)     |
 | **Fallimento** | 47      | 45           | +2 ($\beta$)     |  

**Key insights:**  

- $\alpha$ guida l'*adattamento reattivo* (risposta alla discrepanza);  
- $\beta$ introduce una *tendenza proattiva*:  
  - $\beta$ > 0: "ambizione crescente" anche dopo fallimenti;  
  - $\beta$ < 0: "cautela strutturale" (es. affaticamento).  

**Sintesi delle interazioni.**

- **Dominio di $\alpha$**: quanto rapidamente l'obiettivo "insegue" la performance;  
- **Dominio di $\beta$**: direzione generale (progressiva/regressiva) indipendente dal feedback;  
- **Modelli completi** richiedono entrambi i parametri per catturare sia le risposte locali ($\alpha$) sia le tendenze globali ($\beta$).  


### Perché questo modello è importante? 

Questo approccio rappresenta un ponte tra la psicologia e la modellizzazione matematica, trasformando i processi cognitivi complessi, come la regolazione degli obiettivi, in relazioni quantitative verificabili. La sua struttura dinamica offre vantaggi unici sia per la ricerca teorica che per le applicazioni pratiche, in quanto consente di tradurre le intuizioni psicologiche in parametri misurabili.

Dal punto di vista metodologico, il modello supera il limite delle descrizioni qualitative, consentendo di quantificare aspetti cruciali del comportamento umano. Il parametro $\alpha$ cattura la sensibilità individuale alle discrepanze tra le prestazioni attese e quelle reali, rivelando quanto rapidamente una persona riveda i propri obiettivi. Valori elevati di $\alpha$ indicano un adattamento rapido agli errori, mentre valori bassi suggeriscono una maggiore perseveranza. Il parametro $\beta$, invece, svela tendenze sistemiche indipendenti dalla performance, come una spinta costante all'ambizione ($\beta$ > 0) o una progressiva riduzione delle aspettative ($\beta$ < 0). Questa distinzione consente di formulare ipotesi precise sul ruolo relativo del feedback e dei fattori contestuali nella regolazione degli obiettivi.

Il valore predittivo del modello lo rende particolarmente utile in ambito applicativo. Una volta stimati i parametri per un individuo o un gruppo, è possibile prevedere come reagiranno a specifici schemi di feedback. In ambito educativo, ciò consente di progettare interventi che bilancino sostegno e sfida, ottimizzando la motivazione. In ambito clinico, il modello può identificare schemi disfunzionali, come un eccessivo abbassamento degli obiettivi dopo un insuccesso (basso valore di $\alpha$ e valore negativo di $\beta$), tipico di stati depressivi o ansiosi. Nelle organizzazioni, invece, il modello permette di adattare i sistemi di valutazione e incentivazione alle caratteristiche dei team.

La sua flessibilità lo rende anche una solida base per esplorare ulteriori complessità. I ricercatori possono estenderlo per studiare gli effetti non lineari, le differenze individuali o l'impatto delle variabili contestuali, mantenendo comunque una struttura interpretabile. Questa combinazione di rigore matematico e rilevanza psicologica lo rende uno strumento prezioso per avanzare la teoria e la pratica in vari campi, dalle neuroscienze cognitive alle scienze organizzative.

In sintesi, il modello non solo chiarisce i meccanismi cognitivi alla base della regolazione degli obiettivi, ma fornisce anche un linguaggio comune per studiarli, prevederli e influenzarli, offrendo un contributo fondamentale alla comprensione di questo processo cruciale del comportamento umano. Questa integrazione tra rigore metodologico e rilevanza applicativa segna un passo importante verso una psicologia maggiormente ancorata ai dati e interventi più aderenti alle caratteristiche individuali.


## Verso una modellizzazione più ricca: estensioni del modello base  

Il modello *sample-level* offre una rappresentazione iniziale del processo di aggiornamento degli obiettivi, ma presenta inevitabili semplificazioni. Nella realtà, infatti, le persone mostrano differenze sistematiche nel modo in cui regolano le proprie aspettative in risposta ai feedback. Per cogliere questa complessità, @knight2023tutorial propongono diverse estensioni che arricchiscono il framework base mantenendone l'intuizione teorica fondamentale.  

Una prima direzione di sviluppo è rappresentata dal *modello a livello individuale*, che stima parametri distinti ($\alpha_i$ e $\beta_i$) per ciascun partecipante. Questo approccio permette di mappare la variabilità interindividuale nella sensibilità al feedback ($\alpha$) e nelle tendenze sistemiche ($\beta$), offrendo una fotografia più dettagliata delle differenze psicologiche. Ad esempio, potrebbe rivelare come alcuni individui mostrino un aggiustamento rapido degli obiettivi (α elevato), mentre altri mantengano maggiore stabilità nonostante gli insuccessi (α basso).  

Un ulteriore raffinamento è offerto dai *modelli gerarchici* (multilevel), dove i parametri individuali sono concepiti come estratti da distribuzioni iperparametriche di gruppo. Questa architettura combina i vantaggi dell'analisi a livello individuale con la robustezza statistica derivante dalla condivisione d'informazione tra unità (shrinkage effect). Il risultato è una stima più equilibrata che evita estremi implausibili, particolarmente utile quando si lavora con campioni ridotti o dati rumorosi.  

Per indagare l'impatto di condizioni sperimentali, il modello può essere esteso nella versione *a gruppi noti*, dove $\alpha$ e $\beta$ vengono stimati separatamente per diverse condizioni (es. gruppi con incentivi diversi). Questa estensione permette di testare ipotesi precise sull'influenza di manipolazioni sperimentali nei processi di regolazione. Ancora più sofisticato è il *mixture model*, che identifica sottogruppi latenti con dinamiche distinte senza assumere a priori le categorie, rivelando ad esempio cluster naturali di "adattatori flessibili" versus "perseveranti".  

Sebbene queste estensioni non siano trattate in dettaglio nel presente capitolo, rappresentano la direzione più promettente per modellare la ricchezza del comportamento umano. Il modello base mantiene comunque il suo valore come fondamento concettuale e strumento didattico, mentre le versioni avanzate offrono strumenti sempre più precisi per catturare l'eterogeneità psicologica.  

Questa evoluzione riflette un progresso metodologico cruciale: dal focus sulla tendenza centrale si passa a una modellizzazione distribuzionale che valorizza la variabilità individuale, trasformando le differenze da "rumore" a informazione teorica rilevante. La struttura gerarchica in particolare incarna una visione più matura dei processi psicologici, dove le dinamiche individuali sono contestualizzate all'interno di tendenze di gruppo e influenze contestuali.  

Pur nella loro crescente complessità, queste estensioni preservano il cuore dinamico del modello originale - l'idea che gli obiettivi si evolvano attraverso un dialogo continuo tra aspirazioni, esperienze e tendenze personali. È proprio questa combinazione di flessibilità e coerenza teorica a rendere il framework particolarmente adatto a esplorare la complessità dei processi decisionali umani in contesti sia sperimentali che applicativi.


## Stima dei parametri con Stan

Passando dalla teoria alla pratica, affrontiamo ora il cuore operativo della modellizzazione: la stima dei parametri che quantificano il processo di aggiornamento degli obiettivi. Il modello dinamico precedentemente descritto trova la sua concretizzazione statistica attraverso tre parametri chiave:

* $\alpha$: rappresenta la sensibilità alla discrepanza tra performance e obiettivi,
* $\beta$: cattura le tendenze sistemiche nel cambiamento degli obiettivi,
* $\sigma$: misura la variabilità residua non spiegata dal modello.

Per farlo, traduciamo l’equazione teorica in un *modello statistico* e utilizziamo un approccio bayesiano per stimare la distribuzione a posteriori dei parametri.


### Dal modello teorico al modello statistico

Il modello dinamico di base esprime la regola di aggiornamento degli obiettivi attraverso l'equazione deterministica 

$$
G_t = G_{t-1} + \alpha (P_{t-1} - G_{t-1}) + \beta .
$$

Tuttavia, per trasformarla in un modello statistico adatto all'analisi empirica, dobbiamo considerare la componente stocastica del processo. Introduciamo quindi un termine di errore che catturi la variabilità naturale nel processo di fissazione degli obiettivi, l'effetto di fattori non modellati esplicitamente e eventuali errori di misurazione. La versione statistica del modello diventa:

$$
\text{Goal osservato} \sim \mathcal{N}(G_t, \sigma) .
$$ {#eq-knight-stat}

In altre parole, assumiamo che il goal osservato sia distribuito normalmente attorno al valore previsto, con una certa variabilità $\sigma$.


### Il vantaggio dell'approccio bayesiano per modelli dinamici

La natura ricorsiva del modello -- dove ogni stima dipende dal valore precedente -- rende complessa l'applicazione di metodi frequentisti tradizionali. L'inferenza bayesiana supera questo limite offrendo un framework naturale per gestire dipendenze temporali e incertezze parametriche.  

Stan emerge come strumento particolarmente adatto, implementando algoritmi MCMC avanzati che:  

1) gestiscono efficientemente le correlazioni tra parametri,  
2) propagano coerentemente l'incertezza attraverso le catene temporali,  
3) integrano conoscenze pregresse via distribuzioni a priori.  

A differenza di approcci classici, l'output non si limita a stime puntuali ma fornisce distribuzioni complete a posteriori, catturando tutte le relazioni probabilistiche tra parametri e stati latenti. Questo permette di:  

- quantificare l'incertezza in modo rigoroso,  
- stimare probabilità dirette per ipotesi teoriche,  
- sviluppare previsioni robuste che incorporano tutte le fonti di variabilità.  


### Esempio: implementazione del modello in Stan

Il codice Stan presentato nel capitolo segue esattamente la struttura logica del modello teorico:

* i dati in input sono il numero dei trial, i goal osservati e le performance;
* i parametri da stimare sono $\alpha$, $\beta$ e $\sigma$;
* la regola di aggiornamento è implementata in un ciclo `for`, trial per trial;
* la distribuzione normale collega il goal previsto a quello osservato;
* un blocco aggiuntivo (`generated quantities`) consente di generare dati simulati a partire dai parametri stimati.

L’obiettivo non è solo stimare parametri, ma verificare se il modello è capace di riprodurre i dati osservati.


### Il codice Stan

Di seguito, riportiamo il modello completo implementato in Stan. Analizzeremo poi ciascuna parte.

```stan
// MODELLO PER L'AGGIORNAMENTO DEGLI OBIETTIVI BASATO SULLA PERFORMANCE PRECEDENTE

// ---------------------------
// BLOCCO DEI DATI: COSA FORNIAMO AL MODELLO
// ---------------------------
data {
  int Ntotal;                      // Numero totale di osservazioni (es. 600 trial)
  real trial[Ntotal];              // Numero del trial (es. 1, 2, 3, ..., 600)
  real observed_goal[Ntotal];      // Obiettivo desiderato osservato in ciascun trial
  real performance[Ntotal];        // Prestazione osservata in ciascun trial
}

// ---------------------------
// PARAMETRI DEL MODELLO: COSA VOGLIAMO STIMARE
// ---------------------------
parameters {
  real alpha;                      // Quanto il partecipante adatta il proprio obiettivo (apprendimento)
  real beta;                       // Tendenza generale a incrementare l’obiettivo (motivazione costante)
  real<lower=0> sigma;             // Variazione casuale attorno al goal previsto (rumore)
}

// ---------------------------
// MODELLO: COME SI SPIEGANO I DATI
// ---------------------------
model {
  real predicted_goal;             // Variabile temporanea per salvare la previsione del goal

  // --- PRIORS: aspettative iniziali sui parametri ---
  alpha ~ normal(0, 1);            // Alpha: in media 0, con incertezza (deviazione standard = 1)
  beta ~ normal(0, 1);             // Beta: idem
  sigma ~ normal(0, 1);            // Sigma: deviazione standard del rumore (deve essere positiva)

  // --- CICLO PER OGNI TRIAL ---
  for (i in 1:Ntotal) {

    // Caso speciale: primo trial → nessuna previsione, usiamo direttamente il dato osservato
    if (trial[i] == 1) {
      predicted_goal = observed_goal[i];
    }

    // Tutti i trial successivi → aggiornamento del goal basato sulla performance precedente
    if (trial[i] > 1) {
      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;
      // ↑ Questa è la "regola di apprendimento":
      // - Se la performance precedente è migliore del goal → l’obiettivo aumenta
      // - Se la performance è peggiore → l’obiettivo diminuisce
      // - Quanto cambia? Dipende da alpha (quanto il partecipante si adatta)
      // - A ogni passo si aggiunge anche un piccolo incremento costante (beta)
    }

    // Likelihood: assumiamo che il goal osservato sia vicino al goal previsto, con un po’ di rumore
    observed_goal[i] ~ normal(predicted_goal, sigma);
  }
}

// ---------------------------
// BLOCCO PER GENERARE PREVISIONI (non necessario, ma utile per valutare il modello)
// ---------------------------
generated quantities {
  real predicted_goal;              // Valore previsto dal modello
  real sampled_goal[Ntotal];        // Goal "simulati", generati dal modello

  for (i in 1:Ntotal) {
    if (trial[i] == 1) {
      predicted_goal = observed_goal[i];
    }
    if (trial[i] > 1) {
      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;
    }

    // Simuliamo un nuovo goal come se fosse stato osservato, aggiungendo variabilità
    sampled_goal[i] = normal_rng(predicted_goal, sigma);
  }
}
```


### Il problema che vogliamo risolvere

Ora poniamoci il problema di capire la logica del modello. Immaginiamo un partecipante al nostro compito sperimentale: nel primo trial fissa un obiettivo di risposta più veloce, nel secondo modifica leggermente l’obiettivo dopo aver ricevuto un feedback negativo, e nel terzo lo regola nuovamente in seguito a un miglioramento della performance.
Ci chiediamo: esiste una regola sottostante a questi aggiustamenti? Il modello mira proprio a stimare questi meccanismi, traducendo il processo di aggiornamento degli obiettivi in un insieme di equazioni che possiamo confrontare con i dati osservati.


### La logica del modello: tre ingredienti fondamentali

Il nostro modello si basa su un'idea semplice: quando una persona decide il suo prossimo obiettivo, considera:

1. Alpha ($\alpha$): il tasso di apprendimento. "Quanto mi faccio influenzare dalla mia performance precedente?"

  - *$\alpha$ positivo e alto:* "se ho fatto meglio del previsto, alzo molto l'obiettivo";
  - *$\alpha$ positivo e basso:* "anche se ho fatto bene, non cambio molto l'obiettivo";
  - *$\alpha$ vicino a 0:* "ignoro completamente la performance passata".

2. Beta ($\beta$): la tendenza costante. "Indipendentemente da come è andata, tendo sempre ad alzare/abbassare l'obiettivo?"

  - *$\beta$ negativo:* pessimismo - "ogni volta punto un po' più in basso";
  - *$\beta$ positivo:* ottimismo cronico - "ogni volta punto un po' più in alto".
  - *$\beta$ vicino a zero:* nessuna tendenza sistematica.

3. Sigma ($\sigma$): il rumore.  "Quanto sono imprevedibile nelle mie decisioni?"

  - *$\sigma$ basso:* decisioni molto coerenti e prevedibili;
  - *$\sigma$ alto:* decisioni più casuali e difficili da prevedere.


### La formula 

Ad ogni trial (eccetto il primo), l'obiettivo viene aggiornato così:

```
Nuovo Obiettivo = Vecchio Obiettivo + 
                  alpha × (Performance Precedente - Vecchio Obiettivo) + 
                  beta + 
                  Un Po' di Casualità
```

Esempio pratico. Supponiamo che $\alpha$ valga 0.6 e che $\beta$ valga 2. Nel trial precedente, l'obiettivo era di 50 kg e la performance ottenuta era di 55 kg.

**Calcolo del nuovo obiettivo:**

```
Nuovo Obiettivo = 50 + 0.6 × (55 - 50) + 2
                = 50 + 0.6 × 5 + 2  
                = 50 + 3 + 2
                = 55 kg
```

La persona ha superato l'obiettivo di 5 kg, quindi lo aumenta del 60% di questa differenza (3 kg) più la sua tendenza ottimistica (+2 kg).


### La Struttura del Codice Stan: Quattro Blocchi Logici

#### Blocco 1: DATA - "Cosa Sappiamo"

```stan
data {
  int Ntotal;                    // Quanti trial abbiamo osservato?
  real trial[Ntotal];            // Quale numero di trial è ciascuna osservazione?
  real observed_goal[Ntotal];    // Quali obiettivi ha dichiarato?
  real performance[Ntotal];      // Quali performance ha ottenuto?
}
```

**In parole semplici**: "Ecco i dati che abbiamo raccolto dall'esperimento."

#### Blocco 2: PARAMETERS - "Cosa Vogliamo Scoprire"

```stan
parameters {
  real alpha;                    // Il tasso di apprendimento
  real beta;                     // La tendenza costante
  real<lower=0> sigma;           // Quanto rumore c'è nei dati
}
```

**In parole semplici**: "Questi sono i valori ignoti che vogliamo stimare dai dati."


#### Blocco 3: MODEL - "Come Funziona il Cervello"

Questo è il cuore del modello. Qui diciamo a Stan: "Ecco come pensiamo che funzioni il processo mentale."

##### Passo 1: Le Nostre Aspettative Iniziali (Prior).

```stan
alpha ~ normal(0, 1);
beta ~ normal(0, 1);  
sigma ~ normal(0, 1);
```

**Traduzione**: "Prima di vedere i dati, pensiamo che $\alpha$ e $\beta$ siano attorno allo zero, ma non ne siamo sicuri."

##### Passo 2: Il Processo Trial-per-Trial.

```stan
for (i in 1:Ntotal) {
    if (trial[i] == 1) {
        // Primo trial: non abbiamo performance precedenti
        predicted_goal = observed_goal[i];
    } else {
        // Trial successivi: applichiamo la formula
        predicted_goal += alpha * (performance[i-1] - predicted_goal) + beta;
    }
    
    // Confrontiamo la previsione con quello che abbiamo osservato
    observed_goal[i] ~ normal(predicted_goal, sigma);
}
```

**Spiegazione del ciclo FOR**:

Immaginate di avere 10 trial. Il ciclo dice: "Ora analizziamo il trial 1, poi il trial 2, poi il trial 3, e così via fino al trial 10".

Per ogni trial:

1. Se si tratta del primo trial: non possiamo fare previsioni (non abbiamo performance precedenti), quindi prendiamo l'obiettivo osservato così com'è.
2. Se si tratta di un trial successivo, applichiamo la nostra formula per prevedere quale dovrebbe essere l'obiettivo.
3. Confronto: vediamo quanto la nostra previsione si avvicina a quanto dichiarato dalla persona.


#### Blocco 4: GENERATED QUANTITIES - "Simuliamo Nuovi Dati"

```stan
generated quantities {
    // Qui generiamo dati "finti" usando i parametri che abbiamo stimato
    real sampled_goal[Ntotal];
    
    // Stesso processo del blocco MODEL, ma generiamo nuovi dati
    for (i in 1:Ntotal) {
        // ... stessa logica di sopra ...
        sampled_goal[i] = normal_rng(predicted_goal, sigma);
    }
}
```

**A cosa serve?**

1. Controllo di qualità: i dati simulati assomigliano a quelli reali? Se sì, il modello è credibile.
2. Previsioni future: come si comporterebbe una nuova persona con le stesse caratteristiche?


### Il Processo di Stima: Come Stan Trova i Parametri

Stan non trova un singolo valore per $\alpha$, $\beta$ e $\sigma$. Invece, trova una distribuzione di valori possibili per ciascun parametro.

Esempio di risultati.

```
alpha: media = 0.7, intervallo credibile = [0.5, 0.9]
beta: media = 1.2, intervallo credibile = [0.8, 1.6]  
siagma: media = 3.1, intervallo credibile = [2.7, 3.5]
```

*Interpretazione*:

- questa persona si adatta abbastanza bene alle performance passate ($\alpha$ = 0.7);
- ha una leggera tendenza ottimistica ($\beta$ = 1.2);
- le sue decisioni presentano una moderata variabilità  ($\sigma$ = 3.1).


### Vantaggi di questo approccio

1. Interpretabilità: ogni parametro ha un significato psicologico chiaro;
2. Flessibilità: il modello si adatta a diversi pattern di comportamento.
3. Incertezza quantificata: non diciamo "$\alpha$ = 0.7", ma "$\alpha$ è probabilmente tra 0.5 e 0.9".
4. Predizioni testabili: possiamo generare nuovi dati e verificare se sono simili a quelli reali.


## Riassunto finale

| **Elemento**           | **Significato**                                                                                                             |
| ---------------------- | --------------------------------------------------------------------------------------------------------------------------- |
| $\alpha$               | Sensibilità all’errore: quanto il partecipante modifica l’obiettivo in base alla discrepanza tra performance e aspettativa. |
| $\beta$                | Spinta costante al cambiamento: riflette una tendenza sistematica (es. ambizione crescente).                                |
| $\sigma$               | Rumore residuo: variabilità non spiegata dal modello.                                                                       |
| `sampled_goal`         | Goal simulati dal modello, usati per verificare la bontà delle previsioni.                                                  |
| `generated quantities` | Blocchi che permettono di generare dati sintetici secondo le regole del modello. 

In sintesi, questo modello ci permette di "aprire la scatola nera" del processo decisionale umano, trasformando osservazioni comportamentali in parametri psicologici interpretabili. È un esempio di come la modellazione statistica possa illuminare i meccanismi cognitivi sottostanti al comportamento umano.


### Risultati finali dell'analisi

Al termine della modellazione in Stan, otteniamo tre componenti fondamentali per l'interpretazione.

* Le distribuzioni posteriori dei parametri ($\alpha$, $\beta$ e $\sigma$) rappresentano l'insieme completo dei valori plausibili per ciascun parametro, ottenuti integrando le informazioni ricavate dai dati osservati con le nostre conoscenze a priori. Queste distribuzioni ci permettono di quantificare l'incertezza delle nostre stime.

* Gli indicatori di qualità della stima, come l'R-hat (che valuta la convergenza delle catene MCMC) e l'`n_eff` (che misura l'efficienza del campionamento), forniscono importanti metriche diagnostiche per valutare l'affidabilità dei risultati. Un `R-hat` vicino a 1 e un `n_eff` sufficientemente alto indicano stime robuste.

* Infine, tramite il blocco "generated quantities", otteniamo dati simulati che ci permettono di verificare la capacità predittiva del modello. Queste simulazioni, insieme ai valori di sampled_goal, sono fondamentali per verificare se il modello è in grado di riprodurre pattern simili a quelli osservati nei dati reali, fornendo una validazione aggiuntiva della sua adeguatezza.


### Interpretazione e utilità dei risultati  

Le distribuzioni a posteriori forniscono risposte concrete alle nostre domande di ricerca. Esaminando i valori stimati di $\alpha$ possiamo valutare quanto i partecipanti si adattino alle performance precedenti, mentre l'analisi di $\beta$ rivela eventuali tendenze sistematiche ad aumentare o diminuire l'ambizione. Il parametro $\sigma$, d'altra parte, ci informa sul grado di variabilità nel processo di aggiornamento degli obiettivi.  

Attraverso i dati simulati possiamo condurre posterior predictive checks, un potente strumento diagnostico che confronta i dati generati dal modello con quelli effettivamente osservati, permettendoci di valutare la bontà e la plausibilità del nostro modello.


### Limitazioni e sviluppi futuri  

L'attuale implementazione presenta alcune semplificazioni: assume che i parametri $\alpha$, $\beta$ e $\sigma$ rimangano costanti nel tempo, non tiene conto di possibili differenze individuali e adotta una struttura puramente lineare, che potrebbe risultare troppo rigida per catturare relazioni complesse.  

Per aumentare la flessibilità del modello, sarebbe possibile introdurre una struttura gerarchica che contempli parametri specifici per ciascun individuo, consentire una variazione temporale dei parametri o incorporare termini non lineari per descrivere in modo più accurato la relazione tra performance e definizione degli obiettivi.


## Riflessioni conclusive {.unnumbered .unlisted}

Questo esempio mostra come i concetti psicologici complessi, come la regolazione degli obiettivi, possano essere formalizzati tramite modelli dinamici che rappresentano l’evoluzione temporale dei processi cognitivi. L’approccio adottato integra tre elementi essenziali: la formalizzazione teorica tramite equazioni, l’implementazione computazionale in Stan e l’inferenza bayesiana per stimare e valutare il modello in relazione ai dati.

Rispetto ai modelli statici, questa prospettiva consente non solo di verificare se un comportamento cambia, ma anche come, quando e in risposta a quali condizioni. Pur nella sua semplicità, il modello presentato illustra il potenziale di una psicologia formale e meccanicistica orientata all'identificazione dei processi generativi sottostanti i dati osservati.

Come sottolineato da @knight2023tutorial, questo paradigma si articola in tre fasi cruciali. In primo luogo, la costruzione di un modello generativo che specifichi esplicitamente i meccanismi ipotizzati. In secondo luogo, le ipotesi vengono tradotte in codice eseguibile, solitamente utilizzando linguaggi formali come Stan. Terzo, la valutazione della bontà del modello non solo mediante indicatori statistici, ma anche attraverso un confronto sistematico tra i dati osservati e quelli simulati.

Anche un modello apparentemente semplice, come quello presentato in questo articolo, può rivelarsi utile se soddisfa tre requisiti fondamentali: (1) poggia su basi teoriche esplicite e plausibili, (2) genera previsioni empiricamente verificabili e (3) può essere esteso per indagare nuove questioni di ricerca.

Il modello *sample-level* rappresenta infatti un punto di partenza che può essere arricchito in diverse direzioni: introducendo parametri individuali per catturare le differenze tra i soggetti, incorporando strutture gerarchiche per conciliare i diversi livelli di analisi o implementando modelli a gruppi latenti per identificare pattern non immediatamente evidenti nei dati.

Dal punto di vista didattico, questo esempio mostra come le teorie psicologiche possano essere tradotte in equazioni formali che possono essere simulate, testate e validate empiricamente. Questo approccio trasforma le ipotesi teoriche in affermazioni quantitative verificabili, superando l'analisi delle sole associazioni per abbracciare l'analisi dei processi.

In definitiva, la costruzione di modelli dinamici rappresenta un passo avanti verso una psicologia più rigorosa, che mira a spiegare i fenomeni anziché limitarsi a descriverli, contribuendo così allo sviluppo cumulativo della disciplina. Questo approccio spinge i ricercatori a considerare i meccanismi e i processi sottostanti, gettando le basi per una scienza psicologica più matura e predittiva.


## Informazioni sull'ambiente di sviluppo {.unnumbered .unlisted}

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered .unlisted}

