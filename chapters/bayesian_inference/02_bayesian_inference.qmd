---
execute:
  freeze: auto
---

# Inferenza bayesiana {#sec-bayes-inference}


::: callout-important
## In questo capitolo approfondirai i seguenti concetti fondamentali:  

- distribuzione marginale;
- approccio analitico e numerico per determinare la distribuzione a posteriori;
- linguaggi di programmazione probabilistici;
- inferenza predittiva.
::: 

::: callout-tip
## Prerequisiti

- Leggere il capitolo *Bayes' Rule* del testo di @Johnson2022bayesrules.
- Leggere *Navigating the Bayes maze: The psychologist's guide to Bayesian statistics, a hands-on tutorial with R code* [@alter2025navigating].
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()
```
:::

## Introduzione

Questo capitolo approfondisce i concetti introdotti nel precedente, presentando l'aggiornamento bayesiano in modo formale e dettagliato.

## Il Paradigma dell'Inferenza Bayesiana

L'inferenza bayesiana si basa sull'idea che la probabilità misuri il grado di certezza soggettiva riguardo a un'ipotesi o alla plausibilità di un valore per un parametro sconosciuto. Il cuore di questo approccio è l'**aggiornamento continuo**: le credenze iniziali (**priori**) vengono riviste alla luce di nuove informazioni provenienti dai dati, producendo credenze aggiornate (**posteriori**).

Ad esempio, immaginiamo di lanciare una moneta 10 volte e osservare 8 testa ($y = 8$). Vogliamo stabilire se la moneta sia equilibrata ($p = 0.5$). Per rispondere a questa domanda, definiamo un **modello generativo dei dati**, utilizzando il modello binomiale caratterizzato da $p$, la probabilità di ottenere testa. Questo parametro è l'oggetto della nostra inferenza.

## Approccio Classico: Massima Verosimiglianza

Nel contesto classico, uno dei metodi più utilizzati è la **massima verosimiglianza**, che stima $p$ come il rapporto tra successi e tentativi: $\hat{p} = y/N = 0.8$. Sebbene semplice, questa stima puntuale non fornisce informazioni sull'incertezza di $p$ né sulla plausibilità di valori alternativi.

## Probabilità e Incertezza

Secondo l'approccio bayesiano, la probabilità rappresenta una misura soggettiva della credibilità di un evento, ipotesi o parametro, basata sull'evidenza disponibile e sulle conoscenze pregresse (Kruschke, 2015). Ad esempio, la probabilità che un nuovo trattamento sia efficace è intesa come il grado di fiducia che attribuiamo a questa ipotesi, considerando sia i dati sia le informazioni pregresse.

La conoscenza a priori su un evento, ipotesi o parametro è descritta da una **distribuzione a priori**, indicata come $p(\theta)$. Questa distribuzione riflette ciò che riteniamo plausibile prima di osservare i dati. Quando raccogliamo nuove informazioni, rivediamo le nostre credenze, ridistribuendo la credibilità su tutto il range di valori possibili del parametro. Questo processo di aggiornamento produce la **distribuzione a posteriori**, denotata come $p(\theta \mid \text{dati})$, che rappresenta la nostra credenza aggiornata (Gelman, Hill e Vehtari, 2020).

Un aspetto filosofico e matematico distintivo dell'approccio bayesiano è la concezione del parametro d'interesse come una variabile casuale che può assumere valori differenti, anziché come un valore fisso (come avviene nel paradigma frequentista). Questa prospettiva permette di trattare il parametro come una distribuzione, fornendo una rappresentazione più flessibile delle incertezze.

Ad esempio, se tracciassimo la distribuzione a posteriori, l'asse $x$ rappresenterebbe l'intero intervallo di valori possibili per il parametro, mentre l'asse $y$ indicherebbe la densità di probabilità associata a ciascun valore. Il valore "utilizzabile" più credibile è spesso quello che massimizza la distribuzione (moda), o la sua media o mediana.

## Approccio Bayesiano: Priori e Posteriori

Il **teorema di Bayes** formalizza il processo di aggiornamento delle credenze, combinando le informazioni iniziali con quelle fornite dai dati. L'equazione fondamentale è:

$$
p(\theta \mid \text{dati}) = \frac{p(\theta) \cdot p(\text{dati} \mid \theta)}{p(\text{dati})},
$$

dove:

- $p(\theta)$ è la distribuzione **a priori**, che rappresenta ciò che sappiamo del parametro prima di osservare i dati.
- $p(\text{dati} \mid \theta)$ è la **verosimiglianza**, che descrive la probabilità di osservare i dati dati i valori ipotizzati del parametro.
- $p(\text{dati})$ è la probabilità marginale dei dati.

La distribuzione **a posteriori** $p(\theta \mid \text{dati})$ riflette la combinazione delle credenze iniziali con le informazioni derivanti dai dati osservati.

**Esempio: Moneta con $y = 8$ e $N = 10$.** Supponiamo di adottare una distribuzione a priori uniforme su $[0, 1]$, che attribuisce la stessa plausibilità a tutti i valori di $p$. Osservando $y = 8$ testa su $N = 10$ lanci, la verosimiglianza $p(y \mid \theta)$ sarà determinata dal modello binomiale. Combinando prior e verosimiglianza attraverso il teorema di Bayes otteniamo:

$$
p(\theta \mid y) \propto p(y \mid \theta) p(\theta).
$$

La distribuzione a posteriori risultante ci consente di:
1. Calcolare stime plausibili di $p$, come la mediana o la moda.
2. Quantificare l'incertezza su $p$, ad esempio tramite varianza o intervalli di credibilità.

Questo processo fornisce un quadro completo che integra informazioni iniziali e nuove evidenze, superando i limiti delle stime puntuali della massima verosimiglianza.

## Un'introduzione ai Priori

### Priori Non Informativi 

Come suggerisce il nome, i **priori non informativi** (Flat Priors) sono generalmente privi di informazioni specifiche. Esistono diverse tipologie di distribuzioni a priori non informative, ma la loro distinzione dettagliata esula dallo scopo di questa trattazione. Sono spesso definiti **flat priors** perché la loro funzione di densità di probabilità appare come una linea orizzontale quando rappresentata graficamente. Questa distribuzione, classificata come uniforme, assegna la stessa probabilità a tutti i possibili valori del parametro, riflettendo così un'ignoranza totale riguardo al parametro (Fox, 2022).

In generale, l'uso di priori non informativi è sconsigliato, a meno che non si abbia effettivamente nessuna conoscenza preliminare o convinzione riguardo ai valori probabili del parametro (Johnson et al., 2022; McElreath, 2020). Infatti, in alcuni casi, l'uso di un prior non informativo porta a una distribuzione a posteriori identica alla funzione di verosimiglianza, con stime dei parametri indistinguibili da quelle ottenute con l'approccio frequentista della massima verosimiglianza. Di conseguenza, l'adozione di un'inferenza bayesiana in tali contesti potrebbe essere non giustificata, poiché il concetto di priors è centrale nella statistica bayesiana.

### Priori Debolmente Informativi 

Spesso non abbiamo una conoscenza precisa del parametro d'interesse, ma solo un'idea generale o vincoli noti (ad esempio, l'associazione positiva tra ore di studio e punteggio in un test di matematica). In tali situazioni, possiamo utilizzare **priori debolmente informativi** (anche detti vaguely informative o default priors). Questi prior incorporano informazioni generali o vincoli sul parametro senza influenzare in modo eccessivo i risultati della posteriori. 

I priori debolmente informativi (Default Priors) rappresentano un compromesso tra l'integrazione di conoscenze pregresse e l'evitare bias significativi, permettendo ai dati di "dominare" i risultati (Fox, 2022; Gelman, Hill e Vehtari, 2020). Sono particolarmente utili quando le informazioni preliminari sono limitate o quando si desidera ridurre al minimo l'impatto di credenze iniziali forti.

### Priori Informativi

Diversamente dai priori debolmente informativi o non informativi, i **priori informativi** trasmettono informazioni deliberate e specifiche sul parametro d'interesse. Questi priori si basano su conoscenze consolidate, risultati di studi precedenti o opinioni di esperti e hanno un'influenza maggiore sulla distribuzione a posteriori rispetto ai priori default o flat (Fox, 2022). 

I priori informativi sono particolarmente utili in presenza di campioni ridotti, poiché restringono lo spazio credibile del parametro e consentono intervalli di incertezza più stretti (Kruschke, 2015). Tuttavia, richiedono una definizione accurata, basata su evidenze solide.

## Costante di Normalizzazione e Priori Coniugati

Nell'equazione del teorema di Bayes:

$$
p(\theta \mid \text{dati}) \propto p(\theta) \cdot p(\text{dati} \mid \theta),
$$

la **costante di normalizzazione**, indicata come $p(\text{dati})$, rappresenta la probabilità incondizionata di osservare i dati. Questo termine, che assicura che le probabilità sommino a 1, è calcolato considerando tutte le possibili combinazioni di dati, indipendentemente dai valori del parametro o dall'ipotesi specifica. La normalizzazione rende le distribuzioni risultanti delle probabilità standardizzate e utilizzabili.

In alcuni casi, combinare un prior con la funzione di verosimiglianza produce una distribuzione a posteriori della stessa famiglia del prior. Ad esempio, se il prior è una distribuzione normale e la verosimiglianza è anch'essa normale, il risultato sarà una distribuzione a posteriori normale. In tali casi, il prior è detto **coniugato** rispetto alla funzione di verosimiglianza (Kruschke, 2015). 

L'uso di priori coniugati semplifica notevolmente i calcoli bayesiani (Fox, 2022), evitando di dover calcolare integrali complessi per la normalizzazione. Tuttavia, quando ciò non è possibile e non esistono soluzioni in forma chiusa, si può ricorrere a metodi approssimativi come il campionamento casuale simulato, noto come **Markov-Chain Monte Carlo (MCMC)**. Questo metodo permette di stimare la distribuzione a posteriori anche in situazioni con parametri multipli o integrali ad alta dimensionalità.

## Implementazione e Calcolo nell’Inferenza Bayesiana

Per calcolare la distribuzione a posteriori nell’inferenza bayesiana, si possono seguire due principali approcci: **analitico** e **numerico**. Entrambi presentano vantaggi e limitazioni, e la scelta dipende dalla complessità del modello e dalla natura dei dati.

### Approccio Analitico (o Coniugato)

L’approccio analitico si basa sulla relazione **coniugata** tra la distribuzione a priori e la funzione di verosimiglianza. In questi casi:

- **Calcolo diretto**: La distribuzione a posteriori può essere determinata esattamente tramite formule matematiche.
- **Efficienza computazionale**: Non richiede metodi iterativi complessi, risultando rapido e semplice.

**Esempio**: Una distribuzione a priori Beta combinata con una verosimiglianza binomiale produce una distribuzione a posteriori ancora Beta. Questo è ideale per modelli semplici come l’inferenza sulla probabilità di successo di una moneta.

**Limitazioni**:

- Applicabile solo a modelli semplici e specifici.
- Non adatto a modelli complessi o dati reali che richiedono maggiore flessibilità.

### Approccio Numerico

Quando il calcolo analitico non è possibile, si utilizzano metodi numerici per approssimare la distribuzione a posteriori. Questi metodi sono più versatili e gestiscono modelli complessi, anche se a un costo computazionale maggiore.

#### Metodi Basati su Catene di Markov Monte Carlo (MCMC)

Gli algoritmi MCMC approssimano la distribuzione a posteriori tramite il campionamento iterativo:

- **Metropolis-Hastings**: Adatto a distribuzioni generiche, richiede la definizione di una funzione proposta.
- **Gibbs Sampling**: Efficace quando le distribuzioni condizionali sono note, anche se la distribuzione congiunta è complicata.

MCMC rappresenta la distribuzione a posteriori come un insieme di campioni, consentendo di stimare forma, centro e variabilità della distribuzione stessa. Con abbastanza iterazioni, questa approssimazione diventa accurata.

**Pratiche comuni in MCMC**:

- **Warm-up (o burn-in)**: Una fase iniziale in cui i campioni sono scartati per consentire all’algoritmo di stabilizzarsi e raggiungere la distribuzione target.
- **Thinning**: Riduce l’autocorrelazione nei campioni selezionando solo uno ogni *n* (es. ogni 5° campione), migliorando l’efficienza e l’indipendenza dei campioni.

### Altri Metodi Numerici

- **Variational Bayes**: Approssima la distribuzione a posteriori risolvendo un problema di ottimizzazione, minimizzando la divergenza di Kullback-Leibler tra una distribuzione proposta $q(z)$ e la distribuzione reale $p(z \mid x)$. È veloce ma meno preciso rispetto a MCMC.
- **Approssimazione di Laplace**: Semplifica la distribuzione a posteriori approssimandola con una normale centrata sul valore MAP, utile ma meno accurata per distribuzioni non gaussiane.

**Vantaggi e Svantaggi degli Approcci Numerici**

- **Vantaggi**:
  - Applicabilità a modelli complessi.
  - Flessibilità nell’incorporare informazioni a priori dettagliate.

- **Svantaggi**:
  - Richiedono risorse computazionali elevate.
  - Necessitano di un tuning accurato degli algoritmi (es. scelte iniziali in MCMC).

### Linguaggi di Programmazione Probabilistica (PPL)

I linguaggi di programmazione probabilistica semplificano l’implementazione dei metodi numerici, automatizzando il processo di inferenza bayesiana. Permettono ai ricercatori di concentrarsi sulla modellizzazione, lasciando ai PPL la gestione dell’inferenza.

#### PPL più Diffusi

- **Stan**: Efficiente e flessibile, ampiamente utilizzato in ambiti accademici.
- **PyMC**: Un’opzione user-friendly per la comunità Python.
- **TensorFlow Probability**: Combina modellizzazione probabilistica e apprendimento automatico.

I PPL consentono di definire il modello probabilistico e delegare l’inferenza agli algoritmi numerici sottostanti (MCMC o inferenza variazionale). Questo rende l’inferenza bayesiana più accessibile e applicabile a una vasta gamma di problemi, inclusi quelli in psicologia.

### Notazione

Nella formulazione dei modelli bayesiani utilizziamo la seguente notazione:

- **$y$**: Dati osservati.
- **$\theta$**: Parametri sconosciuti.
- **$x$**: Quantità note (es. predittori).

Esempio di modello:

$$
\begin{aligned}
y & \sim \mathrm{normal}(\mu, \sigma), \\
\mu & \sim \mathrm{normal}(0, 10), \\
\sigma & \sim \mathrm{normal}^+(\sigma \mid 0, 1),
\end{aligned}
$$

dove il simbolo $\sim$ indica *"è distribuito come"*. La stessa espressione può essere scritta in termini di probabilità:

$$
\begin{aligned}
p(y \mid \mu, \sigma) & = \mathrm{normal}(y \mid \mu, \sigma), \\
p(\mu) & = \mathrm{normal}(\mu \mid 0, 10), \\
p(\sigma) & = \mathrm{normal}^+(\sigma \mid 0, 1).
\end{aligned}
$$

### Approfondimenti sull’MCMC

L’MCMC è un argomento vasto e complesso, con una ricca letteratura dedicata. La sua essenza consiste nel campionamento iterativo dalla distribuzione a posteriori per stimarne forma, centro e variabilità. 

Ogni campione rappresenta un possibile valore del parametro d’interesse, e i campioni successivi dipendono dai precedenti, come i collegamenti di una catena. La convergenza alla distribuzione a posteriori richiede molte iterazioni e più catene per verificare l’affidabilità dell’approssimazione. Nonostante la complessità, l’MCMC è uno strumento indispensabile per l’inferenza bayesiana moderna.

## Riflessioni Conclusive

Al cuore della ricerca scientifica c'è una domanda del tipo: "dimmi qualcosa sulla variabile $\theta$ dato che ho osservato i dati $D$ e ho una certa conoscenza del meccanismo sottostante che genera i dati". La regola di Bayes fornisce la seguente risposta:

$$
p(\theta \mid D) = \frac{p(D \mid\theta) p(\theta)}{p(D)} = \frac{p(D \mid \theta) p(\theta)}{\int_\theta p(D \mid\theta) p(\theta) d\theta}.
$$

Questa equazione mostra come, partendo da un modello generativo $p(D \mid\theta)$ dei dati osservati e abbinato a una credenza a priori $p(\theta)$ su quali valori della variabile $\theta$ siano plausibili, possiamo inferire la distribuzione a posteriori $p(\theta \mid D)$ della variabile alla luce dei dati osservati.

La stima MAP (Massimo A Posteriori), che corrisponde al valore di $\theta$ che massimizza la distribuzione a posteriori, rappresenta una stima puntuale del parametro:

$$
\theta^* = \arg \max_\theta p(\theta \mid D).
$$

Nel caso di un prior non informativo (piatto), la stima MAP coincide con la stima di massima verosimiglianza, ovvero il valore di $\theta$ che massimizza la probabilità che il modello generi i dati osservati.


## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

