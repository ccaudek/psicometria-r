# Outlier {#sec-eda-outlier}

::: callout-note
## In questo capitolo imparerai a

- comprendere il ruolo e gli effetti degli outlier;
- individuare outlier con metodi univariati e multivariati;
- utilizzare il pacchetto {performance} in R per rilevarli;
- documentare e rendere riproducibili le procedure;
- considerare alternative (es. winsorizzazione) e preregistrare le scelte.
:::

::: callout-tip
## Prerequisiti

- Leggere "Check your outliers! An introduction to identifying statistical outliers in R with easystats" [@theriault2024check].
:::

::: callout-important
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(performance, see, datawizard, MASS)
```
:::

## Introduzione

Quando analizziamo dati reali, ci imbattiamo spesso in osservazioni che sembrano molto diverse dalla maggior parte delle altre. Questi valori anomali, chiamati outlier, possono avere origini diverse. Ad esempio, potrebbero derivare da errori di misura o inserimento dati, oppure essere casi estremi ma comunque validi.

Identificare e trattare gli outlier in modo appropriato è importante per evitare che distorcano i risultati dell'analisi. Tuttavia, non esiste una definizione universale di outlier: dipende dal contesto e dall'obiettivo dell'analisi.

In questo capitolo, esploreremo diversi metodi per individuare gli outlier, concentrandoci su tecniche robuste che minimizzano l'influenza di questi valori anomali sulle statistiche descrittive [@simmons2011false].

## Come Identificare gli Outlier

### Un primo metodo: i boxplot
  
  Uno strumento semplice e intuitivo per individuare gli outlier è il *boxplot*. Il boxplot riassume la distribuzione di una variabile mostrando la mediana, il primo e il terzo quartile (Q1 e Q3) e due estremi, detti "whiskers". I punti al di fuori di questi whiskers sono considerati potenziali outlier.

Esempio in R:

```{r}
data <- data.frame(
  value = c(rnorm(100, mean = 10, sd = 2), 30)
  ) # Aggiungiamo un outlier

ggplot(data, aes(y = value)) +
  geom_boxplot() +
  coord_flip()
```

Se il boxplot mostra un punto isolato lontano dagli altri dati, potrebbe essere un outlier.

### Metodi basati sulla variabilità

#### Intervallo interquartile (IQR)

John Tukey ha introdotto una definizione operativa di outlier basata sull'*Interquartile Range* (IQR), ovvero la differenza tra il terzo e il primo quartile:

- I valori inferiori a $Q1 - 1.5 \times IQR$ o superiori a $Q3 + 1.5 \times IQR$ sono considerati outlier moderati.
- I valori oltre $Q1 - 3 \times IQR$ o $Q3 + 3 \times IQR$ sono definiti *far out* outliers.

Esempio in R:

```{r}
Q1 <- quantile(data$value, 0.25)
Q3 <- quantile(data$value, 0.75)
IQR_value <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value

outliers <- data$value[data$value < lower_bound | data$value > upper_bound]
outliers
```

Questo metodo è efficace per distribuzioni simmetriche, ma potrebbe non funzionare bene con dati asimmetrici.


#### Median Absolute Deviation (MAD)

Un metodo più robusto rispetto all'IQR è il *Median Absolute Deviation* (MAD), che utilizza la mediana anziché la media per stimare la dispersione:
  
```{r}
mad_value <- mad(data$value)
threshold <- 3 * mad_value # Soglia classica per gli outlier

outliers_mad <- data$value[abs(data$value - median(data$value)) > threshold]
outliers_mad
```

Il MAD è meno sensibile agli outlier rispetto alla deviazione standard ed è spesso preferito per dati con distribuzioni non normali.

## Outlier Multivariati

Quando si considerano più variabili contemporaneamente, un valore potrebbe non apparire anomalo su una singola variabile, ma esserlo nel contesto dell'intero dataset. Un metodo comune per individuare questi outlier è la *Distanza di Mahalanobis*, che tiene conto delle correlazioni tra variabili.

Per comprendere intuitivamente la distanza di Mahalanobis, immaginate di avere una nube di punti che rappresentano individui, ciascuno con i propri valori di altezza e peso. Il “centro” di questa nube è un punto ideale che rappresenta una sorta di media multivariata (tenendo conto sia dell’altezza sia del peso). La distanza di Mahalanobis misura quanto ogni singolo individuo si allontana da questo centro, considerando la variabilità congiunta delle variabili (ad esempio, la correlazione tra altezza e peso). Se un individuo presenta caratteristiche molto diverse rispetto alla maggioranza, la sua distanza di Mahalanobis sarà elevata, segnalando un potenziale outlier.

::: {#fig-maha-dist}
![](../../figures/outliers.png){width="70%"}

Soglie per la detezione degli outliers nel caso di una metrica unidimensionale (pannello di sinistra) e nel caso di una rappresentazione multivariata della varianza (pannello di destra) -- figura creata da Sergen Cansiz.
:::

Esempio in R:

```{r}
X <- as.matrix(mtcars[, c("mpg", "hp")])
center <- colMeans(X)
cov_matrix <- cov(X)
mahal_dist <- mahalanobis(X, center, cov_matrix)

threshold <- qchisq(0.975, df = ncol(X)) # Soglia al 97.5%
outliers_mahal <- X[mahal_dist > threshold, ]
outliers_mahal
```

Questo metodo è utile per dataset con più variabili correlate, come misure biometriche (altezza e peso).


Tuttavia, la versione classica di questa misura non è particolarmente robusta: la presenza stessa di outlier può distorcere il calcolo del “centro” e della variabilità complessiva, rendendo meno affidabile l’individuazione di altri valori anomali. Per questo motivo, si preferisce utilizzare una variante più resistente, la Minimum Covariance Determinant (MCD), che diminuisce l’influenza degli outlier stessi nel processo di identificazione.

All’interno del pacchetto {performance} in R, è possibile applicare questa variante robusta utilizzando la funzione `check_outliers()` con l’argomento `method = "mcd"`. In questo modo, è possibile individuare gli outlier multivariati in maniera più solida e coerente, anche quando si lavora con dati fortemente influenzati da valori estremi.

```{r}
d <- mtcars[, c("mpg", "hp")]
outliers <- performance::check_outliers(d, method = "mcd", verbose = FALSE)
outliers
```

Si possono poi visualizzare questi outlier:

```{r}
plot(outliers)
```

Sono disponibili anche altre varianti multivariate documentate nella help page della funzione.


## Cosa Fare con gli Outlier?

Una volta identificati gli outlier, dobbiamo decidere se rimuoverli, correggerli o mantenerli [@leys2019classify]. Alcuni approcci comuni includono:

1. **Verificare la fonte del dato**: un errore di inserimento può essere corretto.
2. **Rimuovere gli outlier estremi**: utile se il valore è chiaramente un errore di misura.
3. **Usare metodi robusti**: strumenti come la mediana o il MAD sono meno influenzati dagli outlier.
4. **Trasformare i dati**: applicare logaritmi o altre trasformazioni può ridurre l'impatto degli outlier.
5. **Winsorizzazione**: invece di rimuovere gli outlier, possiamo limitarli a un massimo accettabile.

Nel pacchetto easystats, la funzione `winsorize()` di *{datawizard}* semplifica il compito di Winsorizzazione:
  
```r
winsorized_data <- 
  winsorize(data$value, method = "zscore", robust = TRUE, threshold = 3)
```

## Importanza della Trasparenza

Qualunque decisione va documentata chiaramente: quanti outlier sono stati individuati, con quale metodo, a quale threshold, come sono stati gestiti, e preferibilmente con il codice R utilizzato. La preregistrazione e la condivisione dei dati e del codice (ad es. su OSF) sono pratiche consigliate per garantire riproducibilità e trasparenza.

## Riflessioni Conclusive

Abbiamo mostrato come identificare gli outlier in modo coerente e trasparente, allineandoci alle buone pratiche correnti. Tuttavia, la buona pratica non si limita alla scelta degli algoritmi: è fondamentale anche preregistrare le decisioni, essere coerenti, trasparenti e fornire giustificazioni. 

## Informazioni sull'Ambiente di Sviluppo {.unnumbered}

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

