# La predizione bayesiana {#sec-mcmc-prediction}

::: callout-important
## In questo capitolo imparerai a

- 
:::

::: callout-tip
## Prerequisiti

- 
:::

::: .callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(cmdstanr, posterior, bayestestR)
```
:::

## Introduzione 

In questo capitolo esamineremo in dettaglio le distribuzioni predittive a priori e a posteriori. La distribuzione predittiva a priori rappresenta le aspettative sui dati prima di qualsiasi osservazione reale, riflettendo le conoscenze preesistenti e le ipotesi sui parametri del modello. Essa fornisce un'indicazione delle caratteristiche che i dati potrebbero assumere in base al modello. Confrontare queste previsioni con i dati effettivamente osservati consente di valutare la validità delle ipotesi incorporate nel modello.

La distribuzione predittiva è spesso di maggiore interesse rispetto alla distribuzione a posteriori. Mentre la distribuzione a posteriori descrive l'incertezza sui parametri (ad esempio, la proporzione di palline rosse in un'urna), la distribuzione predittiva descrive l'incertezza sugli eventi futuri (ad esempio, il colore della pallina che verrà estratta in futuro). Questa differenza è cruciale, soprattutto quando si tratta di prevedere gli effetti di un intervento, come la somministrazione di un trattamento a un paziente.

La distribuzione predittiva a posteriori è inoltre fondamentale per valutare quanto le previsioni del modello siano coerenti con i dati osservati. Se le previsioni del modello risultano allineate con i dati raccolti, il modello può essere considerato accurato nel rappresentare il processo generativo sottostante. Questo confronto è essenziale per convalidare il modello e assicurarsi che le ipotesi riflettano adeguatamente la realtà osservata.

## La distribuzione predittiva a posteriori {#sec-posterior-predictive-distribution}

La [distribuzione predittiva a posteriori](https://mc-stan.org/docs/stan-users-guide/posterior-predictive-checks.html#prior-predictive-checks) offre una valutazione critica della coerenza tra i dati reali e quelli simulati dal modello [@gelman2013philosophy]. Confrontando direttamente i dati osservati con quelli generati dal modello, essa permette di identificare eventuali discrepanze che potrebbero segnalare problemi nella specificazione del modello. In pratica, la PPC (Posterior Predictive Check) funge da test diagnostico, consentendo di rilevare e correggere eventuali carenze nel modello, migliorandone così le capacità predittive.

Per comprendere meglio il concetto, consideriamo la distribuzione predittiva a posteriori in termini di un modello coniugato normale-normale. Supponiamo di voler predire la media di una distribuzione normale futura, basandoci sui dati osservati e sulle nostre conoscenze a priori. La PPD ci offre uno strumento per calcolare queste probabilità, combinando le informazioni provenienti dai dati osservati con quelle fornite dalla distribuzione a priori.

Ad esempio, immaginiamo di aver raccolto dati sulle altezze di 100 persone, ottenendo una media campionaria di 170 cm e una deviazione standard campionaria di 10 cm. Il nostro obiettivo è stimare la media delle altezze in un futuro campione di $n=100$ persone. La nostra conoscenza a priori sulla media delle altezze è rappresentata da una distribuzione normale con media 175 cm e deviazione standard di 5 cm. 

In termini di notazione, possiamo esprimere questa distribuzione come $P(\tilde{y} \mid \theta=\theta_1)$, dove $\tilde{y}$ rappresenta un nuovo dato che è diverso dai dati attuali $y$, e $\theta_1$ è la media a posteriori. Tuttavia, in statistica bayesiana, è fondamentale incorporare tutta l'incertezza nei risultati. Poiché $\theta_1$ è solo uno dei possibili valori per $\theta$, dovremmo includere ogni valore di $\theta$ per la nostra previsione. Per ottenere la migliore previsione, possiamo "mediare" le previsioni attraverso i diversi valori di $\theta$, ponderando ciascun valore secondo la sua probabilità a posteriori.

La distribuzione risultante è la distribuzione predittiva a posteriori, che in notazione matematica è data da:

$$ P(\tilde{y} \mid y) = \int_\theta p(\tilde{y} \mid \theta, y) p(\theta \mid y) d\theta. $$

In questo modo, la distribuzione predittiva a posteriori combina le informazioni dai dati osservati con la conoscenza a priori, fornendo una previsione che riflette l'incertezza associata a tutti i possibili valori dei parametri del modello.

## Distribuzione predittiva a posteriori nel modello normale-normale

Nel modello coniugato normale-normale, se i dati osservati $Y = \{y_1, y_2, ..., y_n\}$ sono modellati come provenienti da una distribuzione normale con media $\mu$ e varianza $\sigma^2$, e assumendo una distribuzione a priori normale per $\mu$, la distribuzione a posteriori di $\mu$ sarà anch'essa normale.

### Formule della distribuzione predittiva a posteriori

Dato che:

1. I dati osservati $y_i \sim \mathcal{N}(\mu, \sigma^2)$
2. La prior per $\mu$ è $\mu \sim \mathcal{N}(\mu_0, \tau_0^2)$

La distribuzione a posteriori per $\mu$ sarà:

$$
\mu \mid Y \sim \mathcal{N}(\mu_n, \tau_n^2)
$$

dove:

$$
\mu_n = \frac{\tau_0^2 \bar{y} + \sigma^2 \mu_0}{\tau_0^2 + \sigma^2}
$$

e

$$
\tau_n^2 = \frac{\tau_0^2 \sigma^2}{\tau_0^2 + \sigma^2}
$$

Qui, $\bar{y}$ è la media campionaria dei dati osservati.

::: {#exm-}

Consideriamo che:

- $\mu_0 = 175$ cm (media a priori)
- $\tau_0 = 5$ cm (deviazione standard a priori)
- $\bar{y} = 170$ cm (media campionaria)
- $\sigma = 10$ cm (deviazione standard campionaria)
- $n = 100$ (numero di osservazioni)

I parametri della distribuzione a posteriori sono:

$$
\mu_n = \frac{(5^2 \cdot 170) + (10^2 \cdot 175)}{5^2 + 10^2} = \frac{42500 + 175000}{25 + 100} = \frac{217500}{125} = 174 \quad \text{cm}
$$

$$
\tau_n^2 = \frac{5^2 \cdot 10^2}{5^2 + 10^2} = \frac{2500}{125} = 20 \quad \text{cm}^2 \Rightarrow \tau_n = \sqrt{20} \approx 4.47 \quad \text{cm}
$$

Pertanto, la distribuzione a posteriori per $\mu$ è:

$$
\mu \mid Y \sim \mathcal{N}(174, 4.47^2)
$$

Per la distribuzione predittiva a posteriori, dobbiamo considerare anche la varianza della distribuzione futura. Se stiamo predicendo per $n_{\text{fut}}=100$ nuove osservazioni, la varianza della media predittiva sarà:

$$
\sigma_{\text{pred}}^2 = \tau_n^2 + \frac{\sigma^2}{n_{\text{fut}}}
$$

$$
\sigma_{\text{pred}}^2 = 20 + \frac{10^2}{100} = 20 + 1 = 21 \quad \text{cm}^2 \Rightarrow \sigma_{\text{pred}} = \sqrt{21} \approx 4.58 \quad \text{cm}
$$

Quindi, la distribuzione predittiva a posteriori è:

$$
\tilde{Y} \sim \mathcal{N}(174, 4.58^2)
$$

## Implementazione con `cmdstanr`

Per illustrare come viene generata la distribuzione predittiva a posteriori nel contesto del modello normale-normale, possiamo utilizzare `cmdstanr` per eseguire l'analisi. Il codice seguente mostra come configurare il modello e generare previsioni.

```{r}
# Dati osservati
set.seed(123)  # Imposta il seed per la riproducibilità
y_observed <- rnorm(100, 170, 10)
mean_y <- mean(y_observed)
std_y <- sd(y_observed)

# Parametri a priori
mu_0 <- 175
tau_0 <- 5

# Parametri posteriori
tau_n_sq <- (tau_0^2 * std_y^2) / (tau_0^2 + std_y^2)
tau_n <- sqrt(tau_n_sq)
mu_n <- (tau_0^2 * mean_y + std_y^2 * mu_0) / (tau_0^2 + std_y^2)

# Parametri predittivi
n_fut <- 100
sigma_pred_sq <- tau_n_sq + (std_y^2 / n_fut)
sigma_pred <- sqrt(sigma_pred_sq)
mu_pred <- mu_n

# Simulazioni
y_pred_samples <- rnorm(1000, mu_pred, sigma_pred)

# Dati per ggplot
data <- data.frame(Heights = y_pred_samples)

# Grafico
p <- ggplot(data, aes(x = Heights)) +
  geom_histogram(
    aes(y = ..density..), 
    bins = 30, 
    fill = "gray", 
    colour = "gray", 
    alpha = 0.5
  ) +
  geom_density(colour = "black", size = 1.5) +
  geom_vline(
    xintercept = mu_pred, 
    colour = "gray", 
    linetype = "dashed", 
    size = 1
  ) +
  labs(title = "Posterior Predictive Distribution for Heights",
       x = "Heights (cm)",
       y = "Density") +
  theme(legend.position = "none")

# Visualizza il grafico
print(p)
```

Questo codice produce un grafico che illustra visivamente la distribuzione predittiva a posteriori per le altezze nel nostro campione di 100 nuove osservazioni, tenendo conto sia dei dati osservati che delle nostre aspettative iniziali.

In sintesi, la distribuzione predittiva a posteriori è stata generata nel modo seguente:

1. Campioniamo un valore $\mu$ dalla distribuzione a posteriori di $\mu$.
2. Campioniamo un valore $\sigma$ dalla distribuzione a posteriori di $\sigma$.
3. Utilizziamo questi valori per generare un campione dalla distribuzione normale con parametri $\mu$ e $\sigma$.
4. Ripetiamo questo processo molte volte.

La distribuzione dei valori ottenuti da questi campionamenti costituisce la distribuzione predittiva a posteriori.

## Metodo MCMC

Quando usiamo un PPL come Stan, la distribuzione predittiva viene stimata mediante il campionamento da una catena di Markov, che è particolarmente utile in scenari complessi dove l'analisi analitica potrebbe essere impraticabile. Attraverso i metodi MCMC, si stimano le potenziali osservazioni future $p(\tilde{y} \mid y)$, indicate come $p(y^{rep} \mid y)$, seguendo questi passaggi:

1. Si campiona $\theta_i \sim p(\theta \mid y)$: Viene selezionato casualmente un valore del parametro (o dei parametri) dalla distribuzione a posteriori.
2. Si campiona $y^{rep} \sim p(y^{rep} \mid \theta_i)$: Viene scelta casualmente un'osservazione dalla funzione di verosimiglianza, condizionata al valore del parametro (o dei parametri)ottenuto nel passo precedente.

Ripetendo questi due passaggi un numero sufficiente di volte, l'istogramma risultante approssimerà la distribuzione predittiva a posteriori. 

Esaminiamo ora come ottenere la distribuzione predittiva a posteriori con Stan per i dati dell'esempio precedente. Iniziamo creando le distribuzioni a posteriori di $\mu$ e $\sigma$.

Definiamo un dizionario che contiene i dati.

```{r}
stan_data_gauss = list(
  N = length(y_observed),
  y = y_observed,
  mu_prior = 180,
  sigma_prior = 20,
  sigma_prior_mean = 10,
  sigma_prior_sd = 3
)
```

```{r}
y_mean = mean(y_observed)
y_std = sd(y_observed)

y_mean
y_std
```

Compiliamo e stampiamo il modello Stan:

```{r}
# Path to the Stan file
stan_file <- here::here("stan", "gaussian_model.stan")

# Create a CmdStanModel object
mod <- cmdstan_model(stan_file)
```

```{r}
mod$print()
```

Eseguiamo il campionamento MCMC:

```{r}
#| message: false
#| warning: false
#| output: false
#| 
fit <- mod$sample(
  data = stan_data_gauss,
  seed = 123,
  chains = 4,
  parallel_chains = 4,
  iter_sampling = 2000, 
  iter_warmup = 2000,
  show_messages = FALSE
)
```

Un sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:

```{r}
fit$summary(c("mu", "sigma"))
```

Estraiamo i dati prodotti dal modello `y_rep` e i dati osservati `y`:

```{r}
# Extract posterior predictive samples for y_rep
y_rep <- fit$draws(variables = "y_rep", format = "draws_matrix")

# Extract observed data
y_obs <- stan_data_gauss$y
```

Convertiamo `y_rep` in una matrice per compatibilità con *{bayesplot}*.

```{r}
# Convert y_rep to a matrix
y_rep_matrix <- as.matrix(y_rep)
```

Generiamo il posterior predictive chech plot:

```{r}
# Posterior predictive check plot
set.seed(123)
selected_indices <- sample(nrow(y_rep_matrix), 50)
ppc_dens_overlay(y = y_obs, yrep = y_rep_matrix[selected_indices, ])
```

La distribuzione predittiva a posteriori è utilizzata per eseguire i *controlli predittivi a posteriori* (PPC), noti come *Posterior Predictive Checks*. I PPC consistono in un confronto grafico tra $p(y^{rep} \mid y)$, ossia la distribuzione delle osservazioni future previste, e i dati osservati $y$. Questo confronto visivo permette di valutare se il modello utilizzato è adeguato per descrivere le proprietà dei dati osservati.

Oltre al confronto grafico tra le distribuzioni $p(y)$ e $p(y^{rep})$, è possibile effettuare un confronto tra le distribuzioni di varie statistiche descrittive calcolate su diversi campioni $y^{rep}$ e le corrispondenti statistiche calcolate sui dati osservati. Tipicamente, vengono considerate statistiche descrittive come la media, la varianza, la deviazione standard, il minimo o il massimo, ma è possibile confrontare qualsiasi altra statistica rilevante.

I controlli predittivi a posteriori offrono un valido strumento per un'analisi critica delle prestazioni del modello e, se necessario, per apportare eventuali modifiche o considerare modelli alternativi più adatti ai dati in esame.

## Distribuzione Predittiva a Priori

La **verifica predittiva a priori** è un metodo fondamentale per esplorare le implicazioni dei tuoi prior. Genera dati simulati basandosi unicamente sui prior, ignorando completamente i dati osservati. Questo permette di rispondere a domande cruciali come:

- I dati generati dal prior riflettono scenari plausibili?
- Il prior è troppo restrittivo o troppo ampio rispetto ai dati attesi?

Questa verifica è particolarmente utile per identificare eventuali incongruenze o assunzioni non realistiche prima di raccogliere i dati osservati.

### Modello Beta-Binomiale

Iniziamo con il caso più semplice. Il modello beta-binomiale è un esempio classico per illustrare la verifica predittiva a priori. In questo modello:

- `theta` rappresenta la probabilità di successo.
- Il prior su `theta` è distribuito secondo una distribuzione Beta parametrizzata da `alpha_prior` e `beta_prior`.
- I dati (`y`) seguono una distribuzione Bernoulliana condizionata su `theta`.

Il modello Stan per l'inferenza sui dati osservati è il seguente:

```
data {
  int<lower=0> N;             // Numero di osservazioni
  array[N] int<lower=0, upper=1> y; // Dati osservati (successi)
  real<lower=0> alpha_prior;  // Parametro alpha del prior Beta
  real<lower=0> beta_prior;   // Parametro beta del prior Beta
}
parameters {
  real<lower=0, upper=1> theta; // Probabilità di successo
}
model {
  theta ~ beta(alpha_prior, beta_prior); // Prior su theta
  y ~ bernoulli(theta);                  // Likelihood
}
```

Per eseguire la simulazione dalla distribuzione predittiva a priori, rimuoviamo il blocco `model` e utilizziamo `generated quantities` per simulare:

- l'estrazione di un valore per `theta` dalla distribuzione Beta specificata dai parametri del prior;
- la generazione di successi simulati (`y_sim`) dalla distribuzione Bernoulliana condizionata su theta.

Compiliamo il modello:

```{r}
# Create a CmdStanModel object
mod_prior <- cmdstan_model(here::here("stan", "betabinomial_prior.stan"))
```

Esaminiamo il modello:

```{r}
mod_prior$print()
```

In questo script abbiamo

* *eliminato il blocco `model`:* Questo blocco serve per l'inferenza Bayesiana, ma non è necessario per generare dati a priori.
* *aggiunto il blocco `generated quantities`:* In questo blocco generiamo quantità di interesse, come i dati simulati `y_sim` e il valore di `theta` estratto dalla distribuzione a priori.
* *utilizzato la funzione `beta_rng`* per estrarre un valore per `theta` dalla distribuzione $\mathcal{Beta}$ definita dai parametri `alpha_prior` e `beta_prior`. Questo valore rappresenta una possibile realizzazione del parametro prima di osservare i dati.
* *utilizzato la funzione `binomial_rng`* per simulare `N` osservazioni dalla distribuzione binomiale. Il parametro di successo `theta` è fissato al valore estratto `theta_prior`.

In sostanza, questo codice ci permette di generare un dataset simulato che potrebbe essere osservato se il processo stocastico fosse governato unicamente dai parametri specificati nella distribuzione a priori. In questo modo, possiamo valutare le proprietà del modello e la sua capacità di generare dati simili a quelli reali, prima ancora di avere a disposizione i dati osservati.

La distribuzione a priori rappresenta la nostra conoscenza o credenza sul valore del parametro `theta` prima di osservare i dati. Scegliendo diversi valori per `alpha_prior` e `beta_prior`, possiamo specificare diverse distribuzioni a priori e quindi esplorare come queste influenzano i risultati della simulazione.

I dati richiesti dal modello vengono specificati nel modo seguente:

```{r}
# Dati osservati
N <- 100               # Numero di osservazioni

# Parametri del prior
alpha_prior <- 4
beta_prior <- 6

# Dati per Stan
stan_data_prior <- list(
  N = N, 
  alpha_prior = alpha_prior, 
  beta_prior = beta_prior
)
```

Eseguiamo il campionamento:

```{r}
# Simulazione del prior
fit_prior <- mod_prior$sample(
  data = stan_data_prior,
  chains = 4, 
  iter_sampling = 1000, 
  iter_warmup = 0,
  fixed_param = TRUE, 
  show_messages = FALSE
)
```

Si noti l'argomento `fixed_param = TRUE` in quanto nessun parametro viene aggiornato.

Estraiamo i campioni a posteriori e visualizziamo i risultati:

```{r}
# Estraiamo theta_prior e y_sim
theta_prior <- fit_prior$draws("theta_prior")
y_sim <- fit_prior$draws("y_sim")
```

Generiamo la distribuzione a priori di `theta`:

```{r}
# Distribuzione a priori di theta
hist(
  theta_prior, 
  main = "Distribuzione a priori di theta", 
  xlab = "theta", 
  freq = FALSE
)
```

Costruiamo la distribuzione predittiva a priori della proporzione di successi:

```{r}
# Distribuzione dei successi simulati
y_sim_mean <- rowMeans(y_sim)
hist(
  y_sim_mean, 
  breaks = 20, 
  main = "Distribuzione predittiva a priori", 
  xlab = "Proporzione di successi", 
  freq = FALSE
)
```

La distribuzione predittiva a priori mostra che i dati simulati riflettono il comportamento atteso dato il *prior*. Per il prior $\mathcal{Beta}(4, 6)$:

- La media attesa di `theta` è $\mathbb{E}[\theta] = \frac{\alpha}{\alpha + \beta} = 0.4$.
- La varianza attesa è $\text{Var}(\theta) = \frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}$.

Con 14 successi su 100 osservazioni reali, corrispondenti a una proporzione di 0.14, notiamo che:

- Il prior $\mathcal{Beta}(4, 6)$ è informativo, con un centro più alto rispetto ai dati osservati.
- Se vogliamo un prior meno concentrato (ad esempio $\mathcal{Beta}(2, 2)$), i dati avranno un peso maggiore.

In conclusione, 

- utilizzare un prior informativo è appropriato se abbiamo conoscenze precedenti robuste;
- se vogliamo un prior che lasci maggior spazio ai dati osservati, potremmo scegliere distribuzioni più ampie come $\mathcal{Beta}(2, 2)$.

La verifica predittiva a priori è uno strumento potente per convalidare queste scelte.

### Modello Gaussiano

Consideriamo un secondo esempio, facciamo riferimento al caso discusso in precedenza dove veniva considerato un campione di dati gaussiani e un modello gaussiano in cui le distribuzioni a priori per μ e σ erano gaussiane.

Compiliamo e stampiamo il modello Stan per generare la distribuzione predittiva a priori:

```{r}
mod_gauss_prior <- cmdstan_model(
  here::here("stan", "gaussian_model_prior.stan")
)
```

```{r}
mod_gauss_prior$print()
```

```{r}
stan_data_gauss <- list(
  N = 100,
  mu_prior = 180,
  sigma_prior = 20,
  sigma_prior_mean = 10,
  sigma_prior_sd = 3
)
```


Eseguiamo il campionamento MCMC:

```{r}
#| message: false
#| warning: false
#| output: false
#| 
fit_gauss_prior <- mod_gauss_prior$sample(
  data = stan_data_gauss,
  chains = 4, 
  iter_sampling = 1000, 
  iter_warmup = 0,
  fixed_param = TRUE, # Nessun parametro aggiornato
  show_messages = FALSE
)
```

Un sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:

```{r}
# Estrai i campioni per mu e sigma
draws <- fit_gauss_prior$draws(c("mu", "sigma"))
print(draws)
```

Estraiamo i campioni per mu e sigma:

```{r}
draws <- fit_gauss_prior$draws(c("mu", "sigma"))
```

Convertiamo i campioni in data frame:

```{r}
draws_df <- as_draws_df(draws)
```

Creaiamo un grafico della distribuzione a priori di mu:

```{r}
draws_df |> 
  ggplot(aes(x = mu)) +
    geom_density(fill = "gray", alpha = 0.5) +
    labs(title = "Distribuzione Predittiva a Priori di Mu",
         x = "Mu",
         y = "Densità")
```

Distribuzione a priori di sigma:

```{r}
draws_df |> 
  ggplot(aes(x = sigma)) +
    geom_density(fill = "lightgray", alpha = 0.5) +
    labs(title = "Distribuzione Predittiva a Priori di Sigma",
         x = "Sigma",
         y = "Densità")
```

Il grafico della distribuzione predittiva a priori ci mostra che i prior utilizzati nel codice Stan implicano una distribuzione della variabile di interesse `y` che è approssimativamente normale con media di 180 e deviazione standard di 22. Questo *prior predictive check* garantisce che le distribuzioni a priori dei parametri `mu` e `sigma` siano realistiche e adeguate per l'analisi dei dati considerati. Un discorso simile si può fare per sigma. Questo passaggio consente di identificare e correggere eventuali ipotesi errate prima di procedere con l'analisi dei dati osservati, migliorando così la validità dei risultati ottenuti.

## Riflessioni Conclusive

Le distribuzioni predittive a priori e a posteriori, pur essendo generate in modo simile, differiscono per la fonte di informazione utilizzata nella loro costruzione.

- **Distribuzione Predittiva a Priori**: Questa distribuzione rappresenta le nostre aspettative sui dati prima che qualsiasi osservazione effettiva sia disponibile. Per costruirla, prendiamo i valori dei parametri dalla distribuzione a priori e li utilizziamo nella funzione di verosimiglianza per generare dati simulati. La distribuzione risultante di questi dati generati è la distribuzione predittiva a priori, che riflette le nostre conoscenze e incertezze iniziali, prima di osservare i dati reali.

- **Distribuzione Predittiva a Posteriori**: Dopo aver osservato i dati, aggiorniamo le nostre credenze sui parametri utilizzando il teorema di Bayes, ottenendo così la distribuzione a posteriori dei parametri. La distribuzione predittiva a posteriori viene quindi generata prendendo valori dei parametri dalla distribuzione a posteriori, che ora incorpora l'informazione ottenuta dai dati osservati, e utilizzandoli nella funzione di verosimiglianza per generare nuovi dati simulati. Questa distribuzione riflette le nostre previsioni sui dati futuri o non osservati, dopo aver tenuto conto dei dati già raccolti.

La differenza principale tra queste due distribuzioni predittive risiede nella distribuzione dei parametri utilizzata: nella distribuzione predittiva a priori si utilizzano i parametri estratti dal prior, mentre nella distribuzione predittiva a posteriori si utilizzano i parametri estratti dal posterior. La distribuzione predittiva a posteriori è generalmente più informativa poiché integra i dati osservati, migliorando le previsioni future.

È cruciale per l'integrità del modello che la distribuzione predittiva a posteriori sia coerente con la distribuzione dei dati osservati. Per verificare questa coerenza, si utilizzano le verifiche predittive a posteriori, confrontando la distribuzione predittiva con i dati empirici tramite tecniche come le stime di densità kernel (KDE). Questo confronto permette di valutare quanto bene il modello riesca ad approssimare la struttura reale dei dati e la sua capacità di fornire previsioni affidabili.

Ad esempio, consideriamo un modello gaussiano con varianza $\sigma^2$ nota:

$$
\begin{aligned}
  y\sim \mathop{\mathrm{N}}(\theta,\sigma^2),
\end{aligned}
$$

dove $\sigma^2$ descrive l'incertezza aleatoria. Usando un prior uniforme, la distribuzione a posteriori per $\theta$ sarà:

$$
\begin{aligned}
  p(\theta|y) \sim \mathop{\mathrm{N}}(\theta|\bar{y},\sigma^2/n),
\end{aligned}
$$

dove $\sigma^2/n$ rappresenta l'incertezza epistemica legata a $\theta$. La distribuzione predittiva a posteriori per un nuovo valore $\tilde{y}$ sarà:

$$
\begin{aligned}
  p(\tilde{y}|y) \sim \mathop{\mathrm{N}}(\tilde{y}|\bar{y},\sigma^2+\sigma^2/n),
\end{aligned}
$$

In questo caso, l'incertezza totale è data dalla somma dell'incertezza epistemica ($\sigma^2/n$) e dell'incertezza aleatoria ($\sigma^2$).

## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

