# Stima bayesiana della grandezza dell’effetto {#sec-bayesian-effect-size}

::: callout-note
## In questo capitolo imparerai a

- calcolare la grandezza dell'effetto usando `brm()` del pacchetto **brms**.
:::

::: callout-tip
## Prerequisiti

- Consultare l'articolo "Bayesian estimation supersedes the t test" [@kruschke2013bayesian]. 
:::

::: callout-important
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(cmdstanr, posterior, brms, bayestestR, insight)
```
:::

## Introduzione

Nel capitolo precedente abbiamo affrontato il problema del confronto tra due gruppi, stimando la differenza tra i punteggi di QI nei figli di madri con o senza diploma. Abbiamo visto come il paradigma bayesiano consenta di formulare inferenze probabilistiche su tale differenza, restituendo una distribuzione a posteriori che riflette l’incertezza residua dopo aver osservato i dati.

In questo capitolo approfondiamo un aspetto cruciale dell’inferenza psicologica: la valutazione della **rilevanza pratica** di un effetto. Non ci interessa solo se la differenza esiste, ma se è sufficientemente ampia da essere considerata sostanziale nel contesto della ricerca. È qui che entra in gioco la nozione di **grandezza dell’effetto** (*effect size*), che fornisce un’unità comparabile per esprimere l’intensità di una relazione o la magnitudine di una differenza.

## Standardizzare la differenza: Cohen’s d

Nel confronto tra due gruppi, una misura diffusa della grandezza dell’effetto è **Cohen’s d**, che standardizza la differenza tra le medie rispetto alla variabilità osservata:

$$
d = \frac{\mu_1 - \mu_2}{\sigma},
$$

dove $\mu_1$ e $\mu_2$ sono le medie dei due gruppi e $\sigma$ è una stima comune della deviazione standard. In ambito bayesiano, possiamo calcolare questa quantità *per ciascun campione a posteriori*, ottenendo così *una distribuzione intera di valori plausibili per Cohen’s d*, non un valore unico.

## Calcolo di Cohen’s d con `brms`

Partiamo dal modello già stimato nel capitolo precedente:

```{r}
#| output: false
kidiq <- rio::import(here::here("data", "kidiq.dta"))

fit_1 <- brm(
  kid_score ~ mom_hs, 
  data = kidiq, 
  backend = "cmdstanr",
  silent = 0
)
```

Estraiamo i campioni a posteriori della differenza tra gruppi (`b_mom_hs`) e della deviazione standard residua:

```{r}
post <- as_draws_df(fit_1)
d_samples <- post$b_mom_hs / post$sigma
```

### Visualizzazione dell’incertezza

```{r}
mcmc_areas(as_draws_df(tibble(d = d_samples)), pars = "d", prob = 0.89) +
  labs(
    title = "Distribuzione a posteriori di Cohen's d",
    subtitle = "Quantifica la rilevanza standardizzata della differenza osservata"
  )
```

### Statistiche riassuntive

```{r}
bayestestR::describe_posterior(d_samples, ci = 0.89)
```

Otteniamo così non solo la stima puntuale dell’effetto, ma anche:

* l’ampiezza dell’intervallo di credibilità,
* la simmetria o asimmetria della distribuzione,
* la probabilità che l’effetto sia positivo, o superi soglie rilevanti.

## Interpretare la grandezza dell’effetto

Secondo convenzioni psicometriche, i valori di *d* si interpretano come segue:

| Valore di *d* | Descrizione qualitativa |
| ------------- | ----------------------- |
| ≈ 0.2         | Effetto piccolo         |
| ≈ 0.5         | Effetto medio           |
| ≥ 0.8         | Effetto grande          |

Tuttavia, l’approccio bayesiano consente di andare oltre queste soglie arbitrarie. Possiamo calcolare, ad esempio:

```{r}
mean(d_samples > 0.5)  # Probabilità che l'effetto sia almeno medio
mean(d_samples > 0.8)  # Probabilità che l'effetto sia grande
```

Queste quantità rispondono a domande come:

*Qual è la probabilità che la differenza osservata tra i gruppi sia sostanziale, non solo statisticamente distinguibile da zero?*

## Riflessioni conclusive

L’effetto di una variabile indipendente non va soltanto rilevato: va **quantificato**. Cohen’s d, in ambito bayesiano, diventa uno strumento potente perché viene trattato come **variabile aleatoria**. Invece di fornire un numero fisso, fornisce una gamma di valori plausibili, con le relative probabilità. Questo ci consente di:

* rappresentare l’incertezza sulla grandezza dell’effetto in modo diretto e continuo,
* formulare **ipotesi probabilistiche** (es. "c’è il 90% di probabilità che l’effetto sia almeno medio"),
* comunicare risultati con maggiore trasparenza, evitando interpretazioni binarie.

In un contesto come quello psicologico, dove la variabilità è la regola e non l’eccezione, parlare in termini di **distribuzioni** anziché di **soglie fisse** significa rispettare la complessità del fenomeno studiato. E soprattutto, significa ancorare l’inferenza non solo ai dati osservati, ma alla struttura dell’incertezza che li accompagna.

## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

