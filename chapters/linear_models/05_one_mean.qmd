# Inferenza bayesiana su una media {#sec-mcmc-one-mean}

::: callout-important
## In questo capitolo imparerai a

- fare inferenza sulla media di un campione;
- trovare le distribuzioni a posteriori usando `brms`;
- verificare il modello usando i pp-check plots.
:::

::: callout-tip
## Prerequisiti

- Leggere il capitolo *Geocentric models* di Statistical rethinking [@McElreath_rethinking].
:::

::: .callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(cmdstanr, posterior, bayestestR, brms, ggdist)
```
:::

## Introduzione

In questo capitolo ci occuperemo di un tema classico in statistica: come inferire la media di una popolazione a partire da un campione di dati quantitativi. Si tratta di una situazione che incontriamo spesso in psicologia, ad esempio quando vogliamo stimare l‚Äôaltezza media, il livello medio di ansia, o la soddisfazione media in un certo gruppo di persone. Tuttavia, anzich√© affrontare questo problema nel modo tradizionale, qui lo considereremo da una prospettiva pi√π ampia e moderna, che mette al centro due concetti fondamentali per la psicologia scientifica: **variabilit√†** e **incertezza**.

### La variabilit√† come punto di partenza

Ogni volta che raccogliamo dati psicologici, ci confrontiamo inevitabilmente con la variabilit√†. Alcune differenze sono **tra individui**:

üîÄ¬†**Variabilit√† inter-individuale**: ad esempio, quanto differiscono tra loro le altezze, i tempi di reazione o i livelli di benessere soggettivo?

Altre differenze sono **all‚Äôinterno dello stesso individuo**, anche se meno visibili in un singolo rilevamento:

üîÑ¬†**Variabilit√† intra-individuale**: quanto potrebbe variare la risposta della stessa persona se la misurassimo in momenti diversi della giornata, o in giorni diversi? Anche quando non la osserviamo direttamente, la variabilit√† intra-individuale √® sempre una componente latente del dato psicologico, e ci invita a riflettere sulle fonti di instabilit√† e fluttuazione nei comportamenti e negli stati mentali.

### L'incertezza come oggetto dell'inferenza

A partire da questa variabilit√†, vogliamo formulare inferenze sul valore medio di un certo parametro (come l‚Äôaltezza media in una popolazione). Ma ogni inferenza √® anche un atto di **stima incerta**: nessun campione ci d√† la verit√†, ma solo una gamma di possibilit√† pi√π o meno plausibili.

In questo capitolo affronteremo quindi il problema dell‚Äôinferenza sulla media da due prospettive complementari:

* **Approccio frequentista**: basato sull‚Äôidea di ripetizione del campionamento e sul calcolo di un intervallo di confidenza;
* **Approccio bayesiano**: che assume esplicitamente l‚Äôincertezza e la rappresenta attraverso una distribuzione di probabilit√† (la *distribuzione a posteriori*).

### Perch√© usare `brms`?

Invece di derivare la distribuzione a posteriori della media in modo analitico (come nei modelli con prior coniugati), useremo il pacchetto `brms`, che si basa su un potente algoritmo di campionamento chiamato **NUTS** (No-U-Turn Sampler). Questo ci permetter√† di stimare numericamente l‚Äôintera distribuzione a posteriori della media e della variabilit√†, anche in casi in cui il calcolo analitico sarebbe difficile o impossibile. In questo modo, potremo:

* quantificare l‚Äôincertezza su ci√≤ che ci interessa (ad esempio: qual √® l‚Äôaltezza media? con quanta certezza lo possiamo dire?);
* visualizzare in modo intuitivo l‚Äôeffetto dei dati e dei priori sulle nostre stime;
* avvicinarci a un modo di pensare statistico pi√π adatto alla complessit√† della psicologia, dove ogni dato √® il risultato di molte fonti di variabilit√†.


## Il modello Normale: un primo passo nella descrizione della variabilit√† üîÄ

Quando parliamo di altezza, ansia, tempo di reazione o qualsiasi altra variabile psicologica continua, un punto di partenza comune √® il modello Normale. Questo modello assume che le osservazioni siano distribuite attorno a un valore medio, con una certa dispersione. In termini formali, diciamo che ogni osservazione $y_n$ √® generata da una distribuzione Normale con media $\mu$ e deviazione standard $\sigma$:

$$
y_n \;\sim\; \mathcal N\bigl(\mu, \sigma\bigr).
$$

Nel linguaggio dell‚Äôinferenza, $\mu$ rappresenta il valore centrale che vogliamo stimare, mentre $\sigma$ quantifica la variabilit√† delle osservazioni rispetto a quel centro. Entrambi i parametri sono ignoti, e l‚Äôobiettivo dell‚Äôinferenza √® proprio descrivere l‚Äôincertezza che abbiamo su di essi.

Nel capitolo precedente abbiamo visto come calcolare la distribuzione a posteriori di questi parametri in modo analitico, quando si utilizzano prior coniugati. In questo capitolo, invece, riprendiamo lo stesso problema, ma adottiamo un approccio pi√π generale e flessibile: stimiamo il modello usando il pacchetto `brms`, che utilizza metodi MCMC per approssimare la distribuzione a posteriori, anche quando non esistono soluzioni chiuse.


## Un esempio concreto: la variabilit√† dell‚Äôaltezza nei !Kung San üîÄ

Per rendere pi√π concreto il problema, useremo un dataset storico: i dati raccolti da Nancy Howell tra la fine degli anni ‚Äô60 presso i !Kung San, una popolazione del deserto del Kalahari con uno stile di vita basato su caccia e raccolta.

I dati che utilizzeremo riportano le altezze di individui adulti (con et√† superiore ai 18 anni). Questo esempio √® tratto da @McElreath_rethinking, ed √® ideale per iniziare a riflettere sulla **variabilit√† inter-individuale**.

```{r}
df <- rio::import(here::here("data", "Howell_18.csv"))
df |> head()
```

Il campione √® composto da 352 osservazioni:

```{r}
length(df$height)
```

### Distribuzione osservata dell‚Äôaltezza

Una prima esplorazione visiva ci aiuta a capire la forma della distribuzione osservata. L‚Äôistogramma seguente mostra come si distribuiscono le altezze nel campione:

```{r}
ggplot(df, aes(x = height)) +
  geom_histogram(binwidth = 5, color = "black", fill = "lightblue") +
  labs(title = "Distribuzione dell'altezza (cm)", x = "Altezza", y = "Frequenza") +
  theme(plot.title = element_text(hjust = 0.5))
```

La forma appare compatibile con una distribuzione Normale. Ma quanto bene si adatta?

```{r}
df |>
  ggplot(aes(sample = height)) +
  stat_qq() +
  stat_qq_line(colour = "red") +
  labs(title = "Normal Q-Q plot", x = "Quantili teorici", y = "Valori osservati") +
  theme(plot.title = element_text(hjust = 0.5))
```

Il Q-Q plot mostra un leggero scostamento: la curva empirica √® un po‚Äô pi√π piatta rispetto alla linea teorica, segno che la variabilit√† osservata √® leggermente inferiore a quella attesa da una Normale standard (code meno pesanti). Tuttavia, la discrepanza √® modesta, e possiamo comunque usare il modello gaussiano come prima approssimazione della distribuzione dei dati.


## Specifica del modello: una distribuzione per descrivere l‚Äôincertezza üîÄ

Nel modello bayesiano, ipotizziamo che ogni osservazione $y_n$ sia indipendente e identicamente distribuita (iid):

$$
y_n \sim \mathcal N(\mu, \sigma),
$$

* $\mu$: la media vera (ignota) della popolazione.
* $\sigma$: la deviazione standard vera, che misura **quanta variabilit√† c‚Äô√® tra gli individui**.

> L'assunzione di indipendenza implica che conoscere l'errore commesso su un individuo non ci dice nulla sull'errore commesso su un altro.
> L'assunzione di identica distribuzione implica che tutti gli individui provengano dalla stessa popolazione.

Scrivere $y_n \sim \mathcal N(\mu, \sigma)$ √® quindi un modo compatto per dire che **ogni osservazione √® un'espressione della variabilit√† inter-individuale**, distribuita attorno a un valore centrale.


## Stime preliminari: una fotografia della variabilit√† üîç

Prima di definire i priori o stimare la distribuzione a posteriori, √® utile esplorare alcune statistiche descrittive:

```{r}
mean(df$height)   # media campionaria
sd(df$height)     # deviazione standard campionaria
```

Queste due quantit√† ci offrono una prima ‚Äúfotografia‚Äù della variabilit√† nel campione:

* La **media campionaria** √® una stima iniziale di $\mu$, che potr√† guidarci nella scelta di una prior realistica.
* La **deviazione standard campionaria** √® una misura iniziale di $\sigma$, e descrive quanto le osservazioni si discostano, in media, dalla media.

Anche se queste statistiche non riflettono ancora in modo completo l‚Äôincertezza che abbiamo, sono molto utili per:

1. **Guidare la scelta dei priors** in un‚Äôottica informata;
2. **Individuare possibili outlier o anomalie**, che potrebbero influenzare sia l‚Äôinferenza frequentista sia quella bayesiana.


## Il modello frequentista: stimare la media come punto fisso üîÄ

Nel contesto dell‚Äôinferenza classica, uno dei modi pi√π semplici per stimare la **media di una popolazione** consiste nell‚Äôadottare un modello lineare senza predittori: un modello che si limita a stimare un‚Äôunica quantit√†, chiamata **intercetta**. In pratica, questo corrisponde a stimare la **media campionaria** dei dati osservati.

In R, questo modello si specifica in modo molto compatto:

```r
height ~ 1
```

Il simbolo `1` indica che vogliamo stimare solo l‚Äôintercetta, senza nessuna variabile esplicativa. In termini pratici, l‚Äôintercetta rappresenta qui la **media dell‚Äôaltezza** nel campione.

### Specifica e stima del modello

Possiamo stimare il modello con la funzione `lm()`:

```{r}
fm1 <- lm(
  formula = height ~ 1, 
  data = df
)
```

Questo comando applica il metodo della **minima somma dei quadrati**, producendo una stima puntuale della media, assieme a una misura della sua variabilit√†.

### Interpretare i risultati

L‚Äôoutput del modello si ottiene con:

```{r}
summary(fm1)
```

Il riassunto mostra diverse informazioni, ma le pi√π rilevanti in questo contesto sono:

* **La stima dell‚Äôintercetta** $\hat{\alpha}$: coincide con la media campionaria delle altezze.
* **L‚Äôerrore standard**: misura la variabilit√† attesa della stima $\hat{\alpha}$ se ripetessimo il campionamento molte volte.
* **Il p-value**: quantifica la probabilit√† di osservare un valore della statistica test cos√¨ estremo (o pi√π) se la media vera fosse 0. In questo caso ha scarso interesse pratico, perch√© il valore di riferimento (0 cm) non √® plausibile.
* **Il R¬≤**: che in assenza di predittori non √® interpretabile in modo utile.

### Intervallo di confidenza al 95%: una misura indiretta dell‚Äôincertezza

Il modello frequentista non descrive la nostra incertezza come una distribuzione su $\mu$, ma fornisce invece un **intervallo di confidenza**, che ha un‚Äôinterpretazione indiretta: se ripetessimo l‚Äôesperimento un numero molto elevato di volte, in circa il 95% dei casi l‚Äôintervallo conterrebbe il vero valore della media.

Possiamo calcolarlo con:

```{r}
confint(fm1, level = 0.95)
```

Questo intervallo si basa sulla formula classica:

$$
\hat{\alpha} \pm t_{\text{df}} \cdot \text{SE}(\hat{\alpha})
$$

dove:

* $\hat{\alpha}$ √® la stima puntuale della media,
* $t_{\text{df}}$ √® il quantile della distribuzione t di Student (con $n - 1$ gradi di libert√†),
* $\text{SE}(\hat{\alpha})$ √® l‚Äôerrore standard della stima.

### Calcolo manuale (opzionale)

Se vogliamo calcolare l‚Äôintervallo ‚Äúa mano‚Äù, possiamo scrivere:

```{r}
coef(fm1) + c(-1, 1) * qt(0.975, df.residual(fm1)) * 0.413
```

* `coef(fm1)` restituisce la stima dell‚Äôintercetta,
* `qt(0.975, df.residual(fm1))` fornisce il valore critico t,
* `0.413` √® l‚Äôerrore standard (da sostituire con quello esatto, se disponibile).

### Riflessione: cos‚Äô√® l‚Äôincertezza, per davvero?

Nel modello frequentista, l‚Äôincertezza sulla media √® descritta in termini di **variabilit√† potenziale tra campioni**, non come incertezza su un valore specifico. Il parametro $\mu$ √® trattato come **fisso ma ignoto**, e tutta l‚Äôincertezza risiede nella stima che otteniamo da un singolo campione.

In questo senso, l‚Äôapproccio frequentista **non fornisce una distribuzione sul parametro**: non possiamo dire ‚Äúla probabilit√† che la media sia tra 153 e 155 cm √® del 95%‚Äù, ma solo che ‚Äúse ripetessimo l‚Äôesperimento molte volte, l‚Äôintervallo conterrebbe la media vera nel 95% dei casi‚Äù.

Nel prossimo paragrafo vedremo come un modello bayesiano offra un‚Äôalternativa: trattare $\mu$ come una **variabile aleatoria** su cui esprimere direttamente l‚Äôincertezza, permettendoci di formulare affermazioni probabilistiche esplicite sui valori possibili del parametro.


## Il modello Bayesiano: descrivere l‚Äôincertezza con distribuzioni üîÄ

Dopo aver stimato la media dell‚Äôaltezza con il modello frequentista, possiamo affrontare lo stesso problema con un approccio bayesiano, usando il pacchetto `brms`. Questo ci consente di rappresentare in modo pi√π diretto l‚Äôincertezza che abbiamo sui parametri del modello.

Nel framework bayesiano, tutti i parametri sono trattati come **variabili aleatorie**: invece di stimare un singolo valore per la media, stimiamo una **distribuzione a posteriori**, che riflette l‚Äôincertezza residua dopo aver osservato i dati.

### Priori debolmente informativi: quando ‚Äúnon sappiamo molto‚Äù üîç

Ogni modello bayesiano richiede la specifica di **distribuzioni a priori**. Tuttavia, quando non abbiamo conoscenze forti da inserire, possiamo affidarci ai **priori debolmente informativi**: distribuzioni ampie, generiche e poco vincolanti, che permettono ai dati di ‚Äúparlare da soli‚Äù.

Se non specifichiamo nulla, `brms` user√† questi prior di default. √à un buon punto di partenza, soprattutto per modelli semplici e dataset abbastanza ricchi.


### Specifica del modello in `brms`

Il codice √® simile a quello usato con `lm()`:

```{r}
#| message: false
#| warning: false
#| output: false
#| 
fm2 <- brm(
  formula = height ~ 1,       # stima solo l'intercetta (media dell‚Äôaltezza)
  family = gaussian(),        # assunzione di distribuzione normale
  data = df,                  # dataset
  chains = 4,                 # numero di catene MCMC
  iter = 2000,                # iterazioni per catena
  warmup = 1000,              # periodo di adattamento
  backend = "cmdstanr"        # motore di calcolo efficiente
)
```

Qui stiamo stimando due parametri:

* $\mu$ ‚Üí media dell‚Äôaltezza nella popolazione;
* $\sigma$ ‚Üí deviazione standard, che rappresenta **quanta variabilit√† inter-individuale** osserviamo.

In termini formali, il modello √® scritto come:

$$
y_i = \alpha + \varepsilon_i,\quad \varepsilon_i \sim \mathcal{N}(0, \sigma).
$$

### Interpretare l‚Äôoutput: incertezza esplicitata

Una volta che il modello √® stato stimato, possiamo esaminarne l‚Äôoutput:

```{r}
summary(fm2)
```

Nel risultato troveremo:

* **Media della distribuzione a posteriori** per $\alpha$, che √® la stima centrale di $\mu$;
* **Errore standard a posteriori**, cio√® quanto fluttua $\mu$ nei campioni simulati;
* **Intervallo di credibilit√†** al 95%: l‚Äôintervallo in cui cade il 95% della distribuzione a posteriori di $\mu$.

A differenza dell‚Äôintervallo di confidenza frequentista, qui possiamo davvero dire:

> C‚Äô√® il 95% di probabilit√† che la media dell‚Äôaltezza si trovi in questo intervallo, dati il modello e i dati osservati.


### Riportare i risultati: due linguaggi per lo stesso fenomeno

| Approccio    | Risultato                                                                                           |
| ------------ | --------------------------------------------------------------------------------------------------- |
| Frequentista | ‚ÄúLa media stimata √® 154.6, con un intervallo di confidenza al 95% tra 153.8 e 155.4.‚Äù               |
| Bayesiano    | ‚ÄúLa media stimata a posteriori √® 154.6, con un intervallo di credibilit√† al 95% tra 153.8 e 155.4.‚Äù |

Numericamente possono coincidere, ma la **logica inferenziale √® diversa**: nel caso bayesiano, l‚Äôintervallo descrive ci√≤ che crediamo plausibile; nel frequentista, ci√≤ che la procedura catturerebbe nella maggior parte dei campioni ripetuti.


### Esplorare i campioni a posteriori: guardare l‚Äôincertezza in faccia

Dopo aver stimato il modello, possiamo accedere direttamente ai campioni generati dall‚Äôalgoritmo NUTS:

```{r}
as_draws_df(fm2) %>% head(3)
```

Ogni riga della colonna `b_Intercept` rappresenta un valore plausibile per $\mu$, estratto dalla sua distribuzione a posteriori. Questi campioni sono il cuore dell‚Äôinferenza bayesiana: ci permettono di costruire grafici, intervalli e ragionamenti probabilistici.


### Calcoli riassuntivi sui campioni

Possiamo usare i campioni per calcolare:

```{r}
# Media a posteriori
mean(as_draws_df(fm2)$b_Intercept)

# Deviazione standard a posteriori
sd(as_draws_df(fm2)$b_Intercept)

# Intervallo di credibilit√† al 95%
quantile(as_draws_df(fm2)$b_Intercept, probs = c(0.025, 0.975))
```

> Questi valori sintetizzano l‚Äôincertezza associata alla nostra stima della media: non un singolo punto, ma una nuvola di possibilit√†, tutte compatibili con i dati osservati.


### Conclusioni intermedie üîÄ

Abbiamo visto come:

* L‚Äôapproccio frequentista fornisca una **stima puntuale** e un **intervallo ipotetico** di copertura.
* L‚Äôapproccio bayesiano fornisca una **distribuzione completa a posteriori**, da cui possiamo derivare medie, intervalli, probabilit√† e visualizzazioni.

Entrambi gli approcci descrivono la **variabilit√† tra individui**, ma il metodo bayesiano offre strumenti pi√π trasparenti per rappresentare l‚Äô**incertezza sui parametri**.

> Questo √® particolarmente utile in psicologia, dove campioni ridotti, contesti variabili e differenze individuali richiedono modelli che sappiano dire ‚Äúquanto (non) sappiamo‚Äù.

Nel prossimo paragrafo vedremo come possiamo **personalizzare i priori**, incorporando informazioni pregresse (da studi precedenti, teoria, esperienza clinica‚Ä¶), e come questo possa influenzare l‚Äôinferenza nei casi in cui i dati da soli non siano sufficientemente informativi.


## Uso dei Prior nel Modello Bayesiano: rendere esplicite le ipotesi sull‚Äôincertezza üîç

Finora abbiamo visto che √® possibile stimare un modello bayesiano anche senza specificare esplicitamente i prior: in tal caso, `brms` utilizza prior debolmente informativi, lasciando che siano i dati a guidare l‚Äôinferenza.

Ma il cuore dell‚Äôapproccio bayesiano sta proprio qui: nella possibilit√† di incorporare conoscenze precedenti, aspettative, risultati di studi precedenti ‚Äî insomma, di modellare in modo **esplicito e trasparente** l‚Äôincertezza che abbiamo prima di vedere i dati.

### Tre domande chiave prima di stimare

Prima di usare un modello bayesiano, √® utile porsi alcune domande fondamentali:

* Cosa sappiamo gi√† del fenomeno?
* Come possiamo esprimere questa conoscenza sotto forma di distribuzioni?
* Quanto vogliamo che questa conoscenza influenzi l‚Äôinferenza?

La risposta a queste domande guida la scelta dei prior. Nei passaggi che seguono, vedremo come un modello informato da prior realistici possa non solo migliorare la stima, ma anche **aumentare la coerenza tra teoria e dati**.

### Specificare i prior: un esempio concreto üîÄ

Riprendiamo il nostro esempio sull‚Äôaltezza nella popolazione dei !Kung San. Supponiamo di avere un‚Äôidea ragionevole su quanto potrebbe essere la media e la variabilit√† delle altezze.

Possiamo tradurre questa conoscenza nel linguaggio delle distribuzioni:

* Per $\mu$ (la media), ipotizziamo:
  $\mu \sim \mathcal{N}(181, 30)$ ‚Äî una media attesa intorno a 181 cm, con ampio margine di incertezza.

* Per $\sigma$ (la deviazione standard), ipotizziamo:
  $\sigma \sim \mathcal{N}^+(0, 20)$ ‚Äî una normale troncata a destra, che garantisce valori positivi.

Questi prior sono **informativi ma ampi**: riflettono aspettative plausibili, senza imporre vincoli troppo rigidi.

> ‚ÑπÔ∏è McElreath scherza dicendo di usare come prior la propria altezza. L‚Äôironia nasconde un principio importante: *ogni ipotesi √® valida, purch√© dichiarata*. Un buon modello bayesiano non finge oggettivit√†, ma esplicita l‚Äôincertezza iniziale.


### Forma del modello con prior espliciti

Il modello completo si scrive cos√¨:

$$
\begin{aligned}
Y_i &\sim \mathcal{N}(\mu, \sigma) \\\\
\mu &\sim \mathcal{N}(181,\ 30) \\\\
\sigma &\sim \mathcal{N}^+(0,\ 20)
\end{aligned}
$$

Qui, sia la media sia la variabilit√† della popolazione sono trattate come **quantit√† soggette a incertezza**. La stima diventa un aggiornamento: partiamo da un‚Äôopinione iniziale e la modifichiamo alla luce dei dati.


### Implementazione in `brms`

```{r}
#| message: false
#| warning: false
#| output: false
#| 
fm3 <- brm(
  formula = height ~ 1,
  data    = df,
  family  = gaussian(),
  prior   = c(
    prior(normal(181, 30), class = "Intercept"),
    prior(normal(0, 20), class = "sigma")
  ),
  chains  = 4, iter = 2000,
  seed    = 1234,
  backend = "cmdstanr"
)
```

### Analisi dell‚Äôoutput

Una volta stimato il modello, possiamo esaminarlo come sempre con:

```{r}
summary(fm3)
```

Se i dati sono informativi (come in questo caso), l‚Äôeffetto dei prior sar√† contenuto: la distribuzione a posteriori sar√† molto simile a quella ottenuta con prior deboli. Questo √® un comportamento desiderabile: il prior **non deve forzare i risultati**, ma integrarsi con essi.

### Scegliere il livello dell‚Äôintervallo di credibilit√†

Possiamo modificare la probabilit√† coperta dall‚Äôintervallo credibile, ad esempio scegliendo un **intervallo all‚Äô89%** anzich√© al 95%:

```{r}
summary(fm3, prob = 0.89)
```

Questa scelta √® proposta da McElreath come default per motivi pedagogici: evitare che l‚Äôintervallo venga interpretato come test di significativit√†.

> ‚ÄúWhy 89%? Because it‚Äôs prime.‚Äù ‚Äî √® un invito a **pensare criticamente** alle convenzioni statistiche, e a riflettere su cosa stiamo cercando davvero di comunicare quando riportiamo un intervallo.


### Cosa otteniamo con prior espliciti?

Usare prior informativi consente di:

- Incorporare conoscenze teoriche, esperienze passate, dati precedenti.
- Rendere il modello pi√π robusto quando i dati sono scarsi o rumorosi.
- Evitare stime irrealistiche in contesti con alta incertezza.
- Esplicitare le nostre ipotesi, invece di nasconderle dietro un‚Äôapparente neutralit√†.


### Conclusione

In un modello bayesiano, ogni assunzione √® chiara e trattabile. I risultati non sono semplici numeri, ma **distribuzioni di credibilit√†** che raccontano ci√≤ che √® plausibile, dato ci√≤ che sapevamo prima e ci√≤ che abbiamo osservato ora.

> Questo rende l‚Äôapproccio bayesiano particolarmente adatto alla psicologia: un campo dove l‚Äôincertezza √® la norma, la variabilit√† √® parte del fenomeno da spiegare, e la trasparenza delle assunzioni √® fondamentale.

Nel prossimo paragrafo, ci concentreremo su come visualizzare e valutare queste distribuzioni a posteriori, usando strumenti diagnostici e grafici che ci aiutano a comprendere ‚Äî e comunicare ‚Äî la variabilit√† residua stimata dal modello.


## Visualizzare l‚Äôincertezza con `bayesplot`

Il pacchetto **`bayesplot`** √® uno strumento prezioso per ogni analisi bayesiana: permette di esplorare visivamente la variabilit√† delle stime a posteriori, di diagnosticare l‚Äôefficienza del campionamento MCMC e di verificare se il modello riesce a riprodurre i dati osservati.

In un contesto psicologico, dove spesso i dati sono rumorosi e le inferenze complesse, poter visualizzare **dove e quanto il modello √® incerto** √® fondamentale.


### Traceplot: osservare le catene in azione

Il traceplot mostra l‚Äôevoluzione dei campioni per ogni parametro nel corso delle iterazioni MCMC. Serve a controllare:

* che le catene siano **stazionarie** (nessuna deriva sistematica),
* che si **mescolino bene** (assenza di autocorrelazione),
* che ci sia **convergenza** (tutte le catene esplorano la stessa distribuzione).

```{r}
mcmc_trace(fm3, pars = c("Intercept", "sigma"), facet_args = list(nrow = 2))
```

Un buon traceplot mostra bande dense, senza tendenze crescenti o oscillazioni lente: questo suggerisce che il campionamento stia catturando in modo affidabile la distribuzione a posteriori.


### Densit√† a posteriori: cosa crediamo dopo aver visto i dati

Per visualizzare la distribuzione di probabilit√† di un parametro stimato, possiamo usare:

```{r}
mcmc_areas(fm3, regex_pars = "b_Intercept", prob = 0.89)
```

Questa funzione evidenzia l‚Äô**intervallo credibile** in cui cade, ad esempio, l‚Äô89% della densit√† a posteriori per la media dell‚Äôaltezza.

> üîé A differenza dell‚Äôintervallo di confidenza, qui possiamo davvero dire che **c‚Äô√® l‚Äô89% di probabilit√† che la media vera sia compresa in quell‚Äôintervallo**.


### Distribuzione congiunta di due parametri: incrociare incertezze

Quando vogliamo esplorare la relazione tra due parametri (ad esempio, media e deviazione standard), possiamo usare:

```{r}
mcmc_scatter(fm3, pars = c("Intercept", "sigma"))
```

Questo tipo di visualizzazione √® utile per valutare **dipendenze tra parametri**: ad esempio, se i campioni sono inclinati lungo una diagonale, significa che c‚Äô√® correlazione a posteriori tra i due.


### Posterior Predictive Check: il modello spiega davvero i dati?

Una delle forze dell‚Äôapproccio bayesiano √® che i modelli sono **generativi**: possiamo simulare nuovi dati partendo dalle distribuzioni a posteriori e confrontarli con quelli osservati.

```{r}
pp_check(fm3)
```

La funzione `pp_check()` mostra:

* in nero: la distribuzione dei dati osservati,
* in colore: pi√π repliche simulate dal modello.

Se le simulazioni coprono bene i dati reali, il modello √® coerente con le osservazioni. Se invece ci sono **scostamenti sistematici**, questo pu√≤ indicare che:

* la distribuzione scelta non √® adatta,
* ci sono outlier non gestiti,
* mancano variabili esplicative nel modello.


## L‚Äôapproccio tradizionale: il test t di Student

Prima dell‚Äôadozione diffusa dei metodi bayesiani, l‚Äôinferenza sulla media veniva solitamente effettuata con il **test t**. Questo approccio assume che la variabilit√† osservata nel campione (stimata con la deviazione standard campionaria) sia sufficiente a rappresentare l‚Äôincertezza sul parametro d‚Äôinteresse.

Il calcolo si basa sulla statistica:

$$
T = \frac{\bar{X} - \mu_0}{s / \sqrt{n}}.
$$

Il test permette di costruire un intervallo di confidenza, ma non di fare affermazioni probabilistiche sui parametri. Il valore $\mu$ √® considerato fisso ma sconosciuto, e l‚Äôincertezza √® attribuita unicamente al **campionamento**.


## Confronto tra approcci: stesso dato, epistemologie diverse

| Elemento                       | Frequentista                         | Bayesiano                           |
| ------------------------------ | ------------------------------------ | ----------------------------------- |
| Concetto di parametro          | Fisso ma ignoto                      | Variabile aleatoria                 |
| Incertezza                     | Tra campioni                         | Nei parametri                       |
| Intervallo (95%)               | Procedura che copre nel 95% dei casi | Credibilit√† del 95% sul valore vero |
| Estensione a modelli complessi | Limitata                             | Flessibile                          |
| Trasparenza delle assunzioni   | Implicita                            | Esplicita                           |

## Riflessioni conclusive: dalla variabilit√† all‚Äôincertezza

In questo capitolo ci siamo concentrati su un caso semplice ma essenziale: la stima della media di una variabile quantitativa. Questo esempio ci ha permesso di mettere a confronto due approcci fondamentali all‚Äôinferenza statistica ‚Äî quello frequentista e quello bayesiano ‚Äî evidenziandone le differenze concettuali e pratiche.

Nell‚Äôapproccio frequentista, l‚Äôincertezza viene trattata come una propriet√† della procedura di stima: non sappiamo quale valore ha il parametro, ma possiamo costruire intervalli che, se ripetessimo l‚Äôesperimento molte volte, conterrebbero il valore vero in una certa proporzione dei casi. In questa visione, i parametri sono fissi e ignoti, e tutta l‚Äôincertezza risiede nei dati campionari.

L‚Äôapproccio bayesiano, al contrario, considera i parametri come quantit√† soggette a incertezza e quindi descrivibili mediante distribuzioni di probabilit√†. Dopo aver osservato i dati, otteniamo una distribuzione a posteriori per ogni parametro, che ci permette di esprimere in modo diretto e intuitivo quanto riteniamo plausibili diversi valori del parametro stesso. Possiamo cos√¨ calcolare non solo medie e deviazioni, ma anche la probabilit√† che un parametro superi una certa soglia, o che la differenza tra due condizioni sia positiva.

Un aspetto centrale emerso nel confronto √® l‚Äôimportanza dei prior: nella prospettiva bayesiana, l‚Äôinferenza non √® mai del tutto ‚Äúneutra‚Äù, ma dipende anche da ci√≤ che sappiamo ‚Äî o assumiamo ‚Äî prima di osservare i dati. Quando i dati sono informativi, i risultati bayesiani tendono a convergere con quelli frequentisti. Ma nei casi in cui i dati sono scarsi, rumorosi o ambigui, la scelta dei prior pu√≤ fare la differenza, offrendo un‚Äôancora razionale che aiuta a stabilizzare le stime e a evitare conclusioni arbitrarie.

Gli strumenti di visualizzazione offerti da `bayesplot`, in particolare i traceplot, le densit√† a posteriori e i posterior predictive check, ci aiutano a rendere tangibile questa incertezza, permettendo di controllare se le catene MCMC stanno funzionando correttamente, di esplorare le relazioni tra i parametri e di valutare la capacit√† del modello di generare dati simili a quelli osservati. In questo senso, il modello bayesiano non √® solo un dispositivo inferenziale, ma anche un‚Äôinterfaccia per riflettere sul legame tra teoria e osservazione.

Tutto ci√≤ assume un significato particolare in psicologia, dove la variabilit√† tra individui, contesti e momenti √® parte integrante del fenomeno da comprendere. Un approccio statistico che rappresenta esplicitamente l‚Äôincertezza, invece di nasconderla o ridurla a un test binario, si rivela quindi pi√π adatto a riflettere la complessit√† reale della disciplina.

Nel prossimi capitoli ci sposteremo dal caso di una sola media al confronto tra due gruppi. Vedremo come l‚Äôapproccio bayesiano ci permetta di formulare domande pi√π ricche e informative, come: ‚ÄúQual √® la probabilit√† che il gruppo A abbia una media maggiore del gruppo B?‚Äù ‚Äî domande che superano il tradizionale criterio del ‚Äúsignificativo o no‚Äù, aprendoci a una comprensione pi√π sfumata e utile delle differenze tra condizioni.


::: {.callout-important title="Problemi" collapse="true"}

**Obiettivo:** Utilizzare i dati dello studio di @tarrats2025efficacy per replicare i risultati riportati nella Figura 2 , applicando sia l‚Äôapproccio frequentista che il framework bayesiano. Calcolare inoltre la grandezza dell‚Äôeffetto nel contesto bayesiano (Cohen‚Äôs $d$) e generare un grafico che visualizzi la distribuzione a posteriori della grandezza dell‚Äôeffetto ottenuta. 

:::

::: {.callout-tip title="Soluzioni" collapse="true"}

```{r}
#| message: false
#| warning: false
#| output: false
#| 
library(tidyverse)
library(readxl)
library(brms)
library(posterior)
library(bayestestR)

df <- read_excel(
  here::here(
    "data",
    "Tarrats-Pons.xlsx"
  ),
  sheet = 3
)

df |>
  group_by(Sample) |>
  summarize(
    avg = mean(`CESS-D`),
    n = n()
  )

df_wide <- df %>%
  select(IdentificationNumber, Sample, CESS_D = `CESS-D`) %>%
  pivot_wider(
    names_from = Sample, # da POST/PRE
    values_from = CESS_D, # i valori da mettere nelle colonne
    names_prefix = "CESSD_" # opzionale, per nominare CESSD_POST, CESSD_PRE
  )

# Controlla il risultato
head(df_wide)

df_wide$diff <- df_wide$CESSD_PRE - df_wide$CESSD_POST

hist(df_wide$diff)

t.test(df_wide$diff)

# t-test sulle differenze
res <- t.test(df_wide$diff)

# Numero di soggetti
n <- length(df_wide$diff)

# Calcolo di Cohen's d
d_t <- as.numeric(res$statistic) / sqrt(n)

# Mostro risultato
d_t

fm1 <- brm(
  formula = diff ~ 1, # Modello con sola intercetta (mu)
  data = df_wide,
  family = gaussian(), # Distribuzione Normale
  prior = c(
    brms::prior(normal(0, 10), class = "Intercept"), # Prior su mu
    brms::prior(normal(0, 10), class = "sigma") # Prior su sigma
  ),
  chains = 4,
  iter = 2000,
  seed = 1234,
  backend = "cmdstanr"
)
summary(fm1)
pp_check(fm1)

fm2 <- brm(
  formula = diff ~ 1, # Modello con sola intercetta (mu)
  data = df_wide,
  family = student(), # Distribuzione Normale
  prior = c(
    brms::prior(normal(0, 10), class = "Intercept"), # Prior su mu
    brms::prior(normal(0, 10), class = "sigma") # Prior su sigma
  ),
  chains = 4,
  iter = 2000,
  seed = 1234,
  backend = "cmdstanr"
)
summary(fm2)
pp_check(fm2)

post_samples <- posterior::as_draws_df(fm1)
head(post_samples)

post_samples$effect_size <- post_samples$b_Intercept / post_samples$sigma

# Calcolo diretto delle statistiche dell'effect size
mean_effect_size <- mean(post_samples$effect_size)
sd_effect_size <- sd(post_samples$effect_size)
ci_effect_size <- quantile(post_samples$effect_size, probs = c(0.025, 0.975))

# Stampa dei risultati
cat("=== Statistiche dell'Effect Size Bayesiano ===\n")
cat("Effect size medio:", round(mean_effect_size, 2), "\n")
cat("SD dell'effect size:", round(sd_effect_size, 2), "\n")
cat(
  "Intervallo di credibilit√† al 95%:",
  round(ci_effect_size[1], 2),
  "-",
  round(ci_effect_size[2], 2),
  "\n\n"
)

# Interpretazione dell'effect size secondo le convenzioni di Cohen
if (abs(mean_effect_size) < 0.2) {
  interpretation <- "piccolo"
} else if (abs(mean_effect_size) < 0.5) {
  interpretation <- "medio-piccolo"
} else if (abs(mean_effect_size) < 0.8) {
  interpretation <- "medio"
} else {
  interpretation <- "grande"
}
cat("Interpretazione (Cohen):", interpretation, "\n")

# Calcola la probabilit√† che l'effect size sia maggiore di zero
prob_positive <- mean(post_samples$effect_size > 0)
cat(
  "Probabilit√† che l'effect size sia positivo:",
  round(prob_positive * 100, 2),
  "%\n"
)

# Se necessario, calcola probabilit√† per altre soglie
prob_medium <- mean(post_samples$effect_size > 0.5)
cat(
  "Probabilit√† che l'effect size sia > 0.5 (medio):",
  round(prob_medium * 100, 2),
  "%\n"
)
prob_large <- mean(post_samples$effect_size > 0.8)
cat(
  "Probabilit√† che l'effect size sia > 0.8 (grande):",
  round(prob_large * 100, 2),
  "%\n"
)

# Visualizzazione della distribuzione posteriore dell'effect size
# (Per eseguire questo blocco, devi avere ggplot2 installato e caricato)
# library(ggplot2)
ggplot(post_samples, aes(x = effect_size)) +
  geom_density(fill = "skyblue", alpha = 0.5) +
  geom_vline(
    xintercept = mean_effect_size,
    color = "red",
    linetype = "dashed"
  ) +
  geom_vline(
    xintercept = ci_effect_size[1],
    color = "darkblue",
    linetype = "dotted"
  ) +
  geom_vline(
    xintercept = ci_effect_size[2],
    color = "darkblue",
    linetype = "dotted"
  ) +
  labs(
    title = "Distribuzione posteriore dell'Effect Size",
    x = "Effect Size (Cohen's d)",
    y = "Densit√†"
  ) +
  theme_minimal()
```
:::

## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}
