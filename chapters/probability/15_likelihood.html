<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Corrado Caudek">
<title>42&nbsp; La verosimiglianza – Psicometria</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/bayesian_inference/introduction_bayes_inference.html" rel="next">
<link href="../../chapters/probability/14_gauss.html" rel="prev">
<link href="../../style/gauss.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-51e9ba6732aa6bc0134376f05742e55b.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-520e231445e9edbb3e5f59e93d436564.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-QT5S3P9D31"></script><script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-QT5S3P9D31', { 'anonymize_ip': true});
</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/probability/introduction_probability.html">Probabilità</a></li><li class="breadcrumb-item"><a href="../../chapters/probability/15_likelihood.html"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Psicometria</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/psicometria-r/" title="Eseguire il codice" class="quarto-navigation-tool px-1" aria-label="Eseguire il codice"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalità lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Informazioni Generali</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../prefazione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/key_notions/introduction_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Fondamenti</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/01_data_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">La crisi di replicazione e la riforma metodologica in psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/02_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Concetti chiave</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/03_design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Campionamento, metodologia sperimentale e studi osservazionali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/04_measurement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/05_cognitive_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Modelli cognitivi</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/R/introduction_r_lang.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">R</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/01_r_syntax.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Un approccio moderno all’analisi dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/02_utility_functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Utility functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/03_r_programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Programmazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/04_r_packages.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Pacchetti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/05_dplyr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Introduzione a <code>dplyr</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/06_quarto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Quarto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/07_environment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">L’ambiente di programmazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/08_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Utilizzo di strumenti AI</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/eda/introduction_eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EDA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/01_project_structure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Le fasi del progetto di analisi dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/02_data_cleaning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Flusso di lavoro per la pulizia dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/04_exploring_qualitative_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Esplorare i dati qualitativi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/05_exploring_numeric_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Esplorare i dati numerici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/06_data_visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Principi della visualizzazione dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/07_loc_scale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Indicatori di tendenza centrale e variabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/07a_introduction_normal_distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Introduzione alla distribuzione normale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/08_correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Relazioni tra variabili</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/09_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Causalità dai dati osservazionali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/10_estimand.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Estimandi teorici e estimandi empirici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/11_outlier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Outlier</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/probability/introduction_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probabilità</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/01_intro_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Interpretazione della probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/02_probability_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Modelli probabilistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/03_prob_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">La Probabilità come misura della certezza razionale: un’interpretazione Bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/04_sigma-algebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Dal Discreto al Continuo: la <span class="math inline">\(\sigma\)</span>-algebra</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/05_conditional_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Probabilità condizionata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/06_bayes_theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/07_random_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/08_prob_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Distribuzioni di massa e di densità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/09_expval_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Proprietà delle variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/10_sampling_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11a_joint_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11b_cov_cor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Covarianza e correlazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11c_joint_prob_cont.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Caso continuo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/12a_intro_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Introduzione alle distribuzioni di probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/12_discr_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/13_cont_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/14_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Assunzione di gaussianità e trasformazioni dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/15_likelihood.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Inferenza</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/introduction_bayes_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/01_uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Abbracciare l’incertezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/02_intro_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">La quantificazione dell’incertezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/03_statistical_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Modelli statistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/04_bayesian_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/05_subj_prop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Aggiornare le credenze su un parametro: dal prior alla posterior</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/07_conjugate_families_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/08_conjugate_families_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/09_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/10_balance_prior_post.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/11_gamma_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Modello coniugato Gamma-Poisson</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/12_gamma_exponential_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Modello gamma-esponenziale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/13_post_pred_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Distribuzione predittiva a posteriori</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">MCMC</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/introduction_mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/01_metropolis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">L’algoritmo di Metropolis-Hastings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/02_ppl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Linguaggi di programmazione probabilistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/07_bayesian_workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Flusso di lavoro bayesiano</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Regressione</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/introduction_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/01_reglin_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">La regressione lineare bivariata: un approccio frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/02_regr_toward_mean.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">La regressione verso la media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/03_reglin_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Modello bayesiano di regressione lineare bivariata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/04_synt_sugar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Zucchero sintattico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/05_one_mean.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Inferenza bayesiana su una media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/07_two_means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Confronto tra le medie di due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/07a_effect_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Stima bayesiana della grandezza dell’effetto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/08_sample_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Pianificazione della dimensione campionaria</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/09_anova_1via.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">ANOVA ad una via</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/10_anova_2vie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">ANOVA ad due vie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/11_one_proportion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">Inferenza sulle proporzioni</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/12_two_proportions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">Confronto tra due proporzioni indipendenti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/13_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">Modello di Poisson</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">Frequentismo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/introduction_frequentist_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/01_intro_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">Inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/01a_stime_parametri.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/02_conf_interv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Intervalli di fiducia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/03_sample_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">La grandezza del campione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/04_test_ipotesi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">Significatività statistica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/05_two_ind_samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">Test t di Student per campioni indipendenti</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Crisi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/introduction_replication_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/01_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">La crisi della replicazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/02_limits_stat_freq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/03_effect_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">La grandezza dell’effetto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/04_s_m_errors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">Errori di segno e errori di grandezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/05_p_values.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">La fragilità del <em>p</em>-valore</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/06_changes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">82</span>&nbsp; <span class="chapter-title">Riforma</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/07_piranha.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">83</span>&nbsp; <span class="chapter-title">Il Problema del priming: sfide e paradossi nella psicologia sociale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/08_degrees_of_freedom.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">84</span>&nbsp; <span class="chapter-title">I gradi di libertà del ricercatore</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/09_integrity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">85</span>&nbsp; <span class="chapter-title">Integrità della ricerca</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Epilogo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/epiloque/epiloque.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Considerazioni Conclusive</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false">
 <span class="menu-text">Appendici</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a01_shell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">La Shell</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a01a_files.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Cartelle e documenti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a02_math_symbols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a03_latex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Equazioni Matematiche in LaTeX</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a11_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Numeri e intervalli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a12_sum_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Sommatorie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a13_sets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Insiemi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a14_combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">H</span>&nbsp; <span class="chapter-title">Calcolo combinatorio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a15_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">I</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a47_first_order_markov.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">J</span>&nbsp; <span class="chapter-title">Catene di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a50_lin_fun.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">K</span>&nbsp; <span class="chapter-title">La funzione lineare</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a71_install_cmdstan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">L</span>&nbsp; <span class="chapter-title">Come installare CmdStan</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Indice</h2>
   
  <ul class="collapse">
<li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione"><span class="header-section-number">42.1</span> Introduzione</a></li>
  <li><a href="#modellazione-statistica-del-lancio-di-una-moneta" id="toc-modellazione-statistica-del-lancio-di-una-moneta" class="nav-link" data-scroll-target="#modellazione-statistica-del-lancio-di-una-moneta"><span class="header-section-number">42.2</span> Modellazione Statistica del Lancio di una Moneta</a></li>
  <li><a href="#verosimiglianza-binomiale" id="toc-verosimiglianza-binomiale" class="nav-link" data-scroll-target="#verosimiglianza-binomiale"><span class="header-section-number">42.3</span> Verosimiglianza binomiale</a></li>
  <li><a href="#la-stima-di-massima-verosimiglianza" id="toc-la-stima-di-massima-verosimiglianza" class="nav-link" data-scroll-target="#la-stima-di-massima-verosimiglianza"><span class="header-section-number">42.4</span> La Stima di Massima Verosimiglianza</a></li>
  <li><a href="#calcolare-la-mle-in-r" id="toc-calcolare-la-mle-in-r" class="nav-link" data-scroll-target="#calcolare-la-mle-in-r"><span class="header-section-number">42.5</span> Calcolare la MLE in R</a></li>
  <li><a href="#verosimiglianza-congiunta" id="toc-verosimiglianza-congiunta" class="nav-link" data-scroll-target="#verosimiglianza-congiunta"><span class="header-section-number">42.6</span> Verosimiglianza Congiunta</a></li>
  <li><a href="#la-verosimiglianza-marginale" id="toc-la-verosimiglianza-marginale" class="nav-link" data-scroll-target="#la-verosimiglianza-marginale"><span class="header-section-number">42.7</span> La Verosimiglianza Marginale</a></li>
  <li><a href="#verosimiglianza-gaussiana" id="toc-verosimiglianza-gaussiana" class="nav-link" data-scroll-target="#verosimiglianza-gaussiana"><span class="header-section-number">42.8</span> Verosimiglianza Gaussiana</a></li>
  <li><a href="#il-rapporto-di-verosimiglianze" id="toc-il-rapporto-di-verosimiglianze" class="nav-link" data-scroll-target="#il-rapporto-di-verosimiglianze"><span class="header-section-number">42.9</span> Il rapporto di verosimiglianze</a></li>
  <li><a href="#riflessioni-conclusive" id="toc-riflessioni-conclusive" class="nav-link" data-scroll-target="#riflessioni-conclusive"><span class="header-section-number">42.10</span> Riflessioni Conclusive</a></li>
  <li><a href="#esercizi" id="toc-esercizi" class="nav-link" data-scroll-target="#esercizi">Esercizi</a></li>
  <li><a href="#informazioni-sullambiente-di-sviluppo" id="toc-informazioni-sullambiente-di-sviluppo" class="nav-link" data-scroll-target="#informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
  <li><a href="#bibliografia" id="toc-bibliografia" class="nav-link" data-scroll-target="#bibliografia">Bibliografia</a></li>
  </ul><div class="toc-actions"><ul class="collapse"><li><a href="https://github.com/ccaudek/psicometria-r/blob/main/chapters/probability/15_likelihood.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/psicometria-r/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/probability/introduction_probability.html">Probabilità</a></li><li class="breadcrumb-item"><a href="../../chapters/probability/15_likelihood.html"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-prob-likelihood" class="quarto-section-identifier"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><div class="callout callout-style-simple callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
In questo capitolo, imparerai a:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>
<strong>Comprendere il concetto di verosimiglianza</strong>: Scoprirai il ruolo fondamentale che la verosimiglianza svolge nella stima dei parametri statistici.</li>
<li>
<strong>Generare grafici della funzione di verosimiglianza</strong>:
<ul>
<li>Implementare grafici per la funzione di verosimiglianza nel caso binomiale.</li>
</ul>
</li>
<li>
<strong>Interpretare i grafici della funzione di verosimiglianza</strong>: Sviluppare le competenze necessarie per analizzare e trarre conclusioni dai grafici generati.</li>
<li>
<strong>Capire il principio di stima di massima verosimiglianza (MLE)</strong>: Approfondiremo il metodo di stima di massima verosimiglianza.</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Prerequisiti
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Leggere il capitolo <em>Estimation</em> <span class="citation" data-cites="schervish2014probability">(<a href="#ref-schervish2014probability" role="doc-biblioref">Schervish &amp; DeGroot, 2014</a>)</span>.</li>
<li>Leggere il capitolo <em>Bayes’ rule</em> <span class="citation" data-cites="Johnson2022bayesrules">(<a href="#ref-Johnson2022bayesrules" role="doc-biblioref">Johnson et al., 2022</a>)</span>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Preparazione del Notebook
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org/reference/here.html">here</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"_common.R"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/source.html">source</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<section id="introduzione" class="level2" data-number="42.1"><h2 data-number="42.1" class="anchored" data-anchor-id="introduzione">
<span class="header-section-number">42.1</span> Introduzione</h2>
<p>I ricercatori impiegano una varietà di modelli matematici per descrivere e prevedere il comportamento dei dati osservati. Questi modelli si differenziano principalmente per la loro struttura funzionale, ossia per il modo in cui stabiliscono relazioni tra le variabili osservate e i parametri teorici. La selezione del modello ottimale avviene mediante un confronto sistematico tra le previsioni teoriche generate dai diversi modelli e i dati empirici. Il modello le cui previsioni mostrano il miglior accordo con le osservazioni sperimentali viene considerato la rappresentazione più adeguata del fenomeno in esame.</p>
<p>In questo processo di valutazione, la funzione di verosimiglianza svolge un ruolo fondamentale: per <em>ciascun</em> possibile valore dei parametri, essa quantifica la plausibilità dei dati osservati qualora questi fossero effettivamente generati dal modello in esame. In altri termini, la verosimiglianza costruisce una vera e propria mappa di plausibilità parametrica, consentendo di identificare le combinazioni di parametri che massimizzano la coerenza tra modello e realtà osservata.</p>
<section id="il-principio-della-verosimiglianza" class="level3" data-number="42.1.1"><h3 data-number="42.1.1" class="anchored" data-anchor-id="il-principio-della-verosimiglianza">
<span class="header-section-number">42.1.1</span> Il Principio della Verosimiglianza</h3>
<p>La <strong>verosimiglianza</strong> quantifica la plausibilità di ciascun valore parametrico <strong>condizionatamente</strong> ai dati osservati. In termini intuitivi, essa rappresenta una misura di <strong>coerenza</strong> tra i parametri del modello e l’evidenza empirica disponibile.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 42.1</strong></span> Sia <span class="math inline">\(Y\)</span> un vettore aleatorio la cui distribuzione è caratterizzata da una funzione di densità (per variabili continue) o di massa di probabilità (per variabili discrete), denotata da <span class="math inline">\(f(y \mid \theta),\)</span> dove <span class="math inline">\(\theta \in \Theta\)</span> è un vettore di parametri definito nello spazio parametrico <span class="math inline">\(\Theta\)</span>.</p>
<p>Dopo aver osservato una realizzazione concreta <span class="math inline">\(y\)</span> di <span class="math inline">\(Y\)</span>, la <strong>funzione di verosimiglianza</strong> è definita come:</p>
<p><span class="math display">\[
L(\theta; y) = f(y \mid \theta),
\]</span></p>
<p>dove:</p>
<ul>
<li>
<strong><span class="math inline">\(y\)</span> è fissato</strong> (corrisponde ai dati osservati),<br>
</li>
<li>
<strong><span class="math inline">\(\theta\)</span> è variabile</strong> (rappresenta l’oggetto di inferenza).</li>
</ul>
<p>Questa funzione assegna a ogni possibile configurazione parametrica un <strong>grado di supporto empirico</strong>, rivelando quali valori di <span class="math inline">\(\theta\)</span> siano più <strong>consoni</strong> con l’evidenza sperimentale.</p>
</div>
</section><section id="relazione-tra-verosimiglianza-e-funzione-di-probabilità" class="level3" data-number="42.1.2"><h3 data-number="42.1.2" class="anchored" data-anchor-id="relazione-tra-verosimiglianza-e-funzione-di-probabilità">
<span class="header-section-number">42.1.2</span> Relazione tra Verosimiglianza e Funzione di Probabilità</h3>
<p>Sebbene la funzione di probabilità (o densità) e la funzione di verosimiglianza condividano la <strong>stessa forma matematica</strong> – <span class="math inline">\(f(y \mid \theta)\)</span> – il loro <strong>significato concettuale</strong> differisce sostanzialmente in base al contesto inferenziale.</p>
<section id="due-prospettive-a-confronto" class="level4" data-number="42.1.2.1"><h4 data-number="42.1.2.1" class="anchored" data-anchor-id="due-prospettive-a-confronto">
<span class="header-section-number">42.1.2.1</span> Due prospettive a confronto</h4>
<ol type="1">
<li>
<strong>Funzione di probabilità (densità/massa)</strong>
<ul>
<li>
<strong>Parametri (<span class="math inline">\(\theta\)</span>) fissi</strong>: assumiamo che siano noti o ipotizzati.<br>
</li>
<li>
<strong>Dati (<span class="math inline">\(y\)</span>) aleatori</strong>: descrive la distribuzione dei possibili risultati.<br>
</li>
<li>
<strong>Interpretazione</strong>: <span class="math inline">\(f(y \mid \theta)\)</span> quantifica la <em>probabilità (o densità) di osservare <span class="math inline">\(y\)</span></em> sotto un modello con parametri <span class="math inline">\(\theta\)</span>.<br>
</li>
<li>
<strong>Domanda chiave</strong>:<br><em>“Se il modello fosse <span class="math inline">\(\theta\)</span>, quanto sarebbero probabili questi dati?”</em>
</li>
</ul>
</li>
<li>
<strong>Funzione di verosimiglianza</strong>
<ul>
<li>
<strong>Dati (<span class="math inline">\(y\)</span>) fissi</strong>: corrispondono alle osservazioni effettive.<br>
</li>
<li>
<strong>Parametri (<span class="math inline">\(\theta\)</span>) variabili</strong>: rappresentano l’incertezza da risolvere.<br>
</li>
<li>
<strong>Interpretazione</strong>: <span class="math inline">\(L(\theta; y) = f(y \mid \theta)\)</span> misura la <em>plausibilità relativa</em> di <span class="math inline">\(\theta\)</span> alla luce di <span class="math inline">\(y\)</span>.<br>
</li>
<li>
<strong>Domanda chiave</strong>:<br><em>“Alla luce di questi dati, quanto sono credibili i diversi <span class="math inline">\(\theta\)</span>?”</em>
</li>
</ul>
</li>
</ol></section><section id="implicazioni-per-linferenza-statistica" class="level4" data-number="42.1.2.2"><h4 data-number="42.1.2.2" class="anchored" data-anchor-id="implicazioni-per-linferenza-statistica">
<span class="header-section-number">42.1.2.2</span> Implicazioni per l’inferenza statistica</h4>
<ul>
<li><p><strong>Approccio frequentista</strong>:<br>
La verosimiglianza è uno strumento per <em>stimare</em> i parametri (es. stima di massima verosimiglianza), senza assegnare loro una distribuzione di probabilità.</p></li>
<li>
<p><strong>Approccio bayesiano</strong>:<br>
La verosimiglianza agisce come <em>ponte</em> tra dati e parametri, combinando l’informazione empirica con le credenze iniziali (<em>prior</em>) per derivare la distribuzione <em>a posteriori</em>:</p>
<p><span class="math display">\[
P(\theta \mid y) \propto L(\theta; y) \cdot P(\theta).
\]</span></p>
<p>In questa visione, i dati <em>aggiornano</em> la nostra conoscenza su <span class="math inline">\(\theta\)</span> attraverso la verosimiglianza.</p>
</li>
</ul></section><section id="sintesi-delle-differenze" class="level4" data-number="42.1.2.3"><h4 data-number="42.1.2.3" class="anchored" data-anchor-id="sintesi-delle-differenze">
<span class="header-section-number">42.1.2.3</span> Sintesi delle differenze</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 29%">
<col style="width: 36%">
<col style="width: 34%">
</colgroup>
<thead><tr class="header">
<th>Caratteristica</th>
<th>Funzione di probabilità</th>
<th>Funzione di verosimiglianza</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Variabile di interesse</strong></td>
<td>
<span class="math inline">\(y\)</span> (aleatoria)</td>
<td>
<span class="math inline">\(\theta\)</span> (incognita)</td>
</tr>
<tr class="even">
<td><strong>Ruolo epistemologico</strong></td>
<td>Genera dati ipotetici</td>
<td>Valuta parametri plausibili</td>
</tr>
<tr class="odd">
<td><strong>Contesto d’uso</strong></td>
<td>Modellistica predittiva</td>
<td>Inferenza parametrica</td>
</tr>
</tbody>
</table>
<p>Questa dualità riflette un principio fondamentale: <strong>la stessa formula matematica assume significati distinti a seconda che l’obiettivo sia la <em>descrizione</em> del processo generativo o l’<em>inferenza</em> sui suoi parametri</strong>. La verosimiglianza, in particolare, è il motore dell’apprendimento statistico, trasformando dati in conoscenza.</p>
</section></section><section id="la-log-verosimiglianza" class="level3" data-number="42.1.3"><h3 data-number="42.1.3" class="anchored" data-anchor-id="la-log-verosimiglianza">
<span class="header-section-number">42.1.3</span> La Log-Verosimiglianza</h3>
<p>In molti contesti statistici e computazionali, risulta conveniente lavorare con la <strong>log-verosimiglianza</strong>, definita come il logaritmo (naturale) della funzione di verosimiglianza:</p>
<p><span class="math display">\[
\ell(\theta; y) = \log L(\theta; y) = \log f(y \mid \theta).
\]</span></p>
<p>Questa trasformazione offre notevoli vantaggi sotto diversi aspetti:</p>
<section id="vantaggi-computazionali" class="level4" data-number="42.1.3.1"><h4 data-number="42.1.3.1" class="anchored" data-anchor-id="vantaggi-computazionali">
<span class="header-section-number">42.1.3.1</span> Vantaggi Computazionali</h4>
<ul>
<li><p><strong>Stabilità numerica</strong>:<br>
Il prodotto di probabilità molto piccole può portare a valori numericamente instabili (<em>underflow</em>). Il logaritmo converte questi prodotti in somme, più gestibili dal punto di vista computazionale.</p></li>
<li>
<p><strong>Efficienza nei modelli con dati indipendenti</strong>:<br>
Nel caso di osservazioni indipendenti e identicamente distribuite (i.i.d.), la log-verosimiglianza complessiva diventa la somma dei contributi individuali:</p>
<p><span class="math display">\[
\ell(\theta; y_1, \dots, y_n) = \sum_{i=1}^n \log f(y_i \mid \theta),
\]</span></p>
<p>semplificando notevolmente i calcoli.</p>
</li>
</ul></section><section id="vantaggi-analitici" class="level4" data-number="42.1.3.2"><h4 data-number="42.1.3.2" class="anchored" data-anchor-id="vantaggi-analitici">
<span class="header-section-number">42.1.3.2</span> Vantaggi Analitici</h4>
<ul>
<li><p><strong>Ottimizzazione più semplice</strong>:<br>
Le derivate della log-verosimiglianza presentano un’espressione matematica più semplice rispetto a quelle della verosimiglianza originale, grazie alle proprietà del logaritmo che trasformano prodotti in somme. Questa semplificazione è particolarmente vantaggiosa nei metodi di ottimizzazione numerica come la massimizzazione della verosimiglianza (MLE), dove la stima dei parametri avviene risolvendo il sistema di equazioni ottenuto uguagliando a zero il gradiente (derivate prime).</p></li>
<li><p><strong>Proprietà additive</strong>:<br>
La forma additiva della log-verosimiglianza è particolarmente utile nei modelli gerarchici o nei casi in cui i dati provengono da più fonti indipendenti.</p></li>
</ul></section><section id="equivalenza-con-la-massimizzazione-della-verosimiglianza" class="level4" data-number="42.1.3.3"><h4 data-number="42.1.3.3" class="anchored" data-anchor-id="equivalenza-con-la-massimizzazione-della-verosimiglianza">
<span class="header-section-number">42.1.3.3</span> Equivalenza con la Massimizzazione della Verosimiglianza</h4>
<p>Poiché il logaritmo è una funzione <strong>monotona crescente</strong>, massimizzare <span class="math inline">\(\ell(\theta; y)\)</span> equivale a massimizzare <span class="math inline">\(L(\theta; y)\)</span>. Pertanto, le stime di massima verosimiglianza (MLE) possono essere ottenute indifferentemente dall’una o dall’altra.</p>
<p>In sintesi, la log-verosimiglianza combina <strong>efficienza computazionale</strong> e <strong>semplicità analitica</strong>, rendendola uno strumento fondamentale per l’inferenza statistica e l’analisi dati moderna.</p>
</section></section></section><section id="modellazione-statistica-del-lancio-di-una-moneta" class="level2" data-number="42.2"><h2 data-number="42.2" class="anchored" data-anchor-id="modellazione-statistica-del-lancio-di-una-moneta">
<span class="header-section-number">42.2</span> Modellazione Statistica del Lancio di una Moneta</h2>
<p>Per illustrare concretamente il concetto di verosimiglianza, consideriamo il classico problema della stima della probabilità di ottenere “testa” in una moneta. Sia <span class="math inline">\(\theta\)</span> questa probabilità incognita.</p>
<section id="modello-probabilistico" class="level3" data-number="42.2.1"><h3 data-number="42.2.1" class="anchored" data-anchor-id="modello-probabilistico">
<span class="header-section-number">42.2.1</span> Modello Probabilistico</h3>
<p>Assumiamo:</p>
<ol type="1">
<li>
<strong>Indipendenza</strong>: ogni lancio è statisticamente indipendente</li>
<li>
<strong>Stazionarietà</strong>: la probabilità <span class="math inline">\(\theta\)</span> rimane costante per tutti i lanci</li>
</ol>
<p>Per una sequenza di n lanci con y teste, la probabilità congiunta è:</p>
<p><span class="math display">\[
P(\text{dati}|\theta) = \prod_{i=1}^n P(\text{esito}_i|\theta) = \theta^y(1-\theta)^{n-y}
\]</span></p>
</section><section id="verosimiglianza-e-sua-interpretazione" class="level3" data-number="42.2.2"><h3 data-number="42.2.2" class="anchored" data-anchor-id="verosimiglianza-e-sua-interpretazione">
<span class="header-section-number">42.2.2</span> Verosimiglianza e Sua Interpretazione</h3>
<p>La funzione di verosimiglianza:</p>
<p><span class="math display">\[
L(\theta|\text{dati}) \propto \theta^y(1-\theta)^{n-y}
\]</span></p>
<p>rappresenta la plausibilità relativa dei diversi valori di <span class="math inline">\(\theta\)</span> alla luce dei dati osservati. Notiamo che:</p>
<ol type="1">
<li>
<strong>Forma funzionale</strong>: corrisponde al nucleo della distribuzione binomiale</li>
<li>
<strong>Costante di proporzionalità</strong>: il coefficiente binomiale è omesso poiché non influenza la stima di massima verosimiglianza</li>
<li>
<strong>Interpretazione</strong>: valori di <span class="math inline">\(\theta\)</span> che massimizzano <span class="math inline">\(L(\theta \mid \text{dati})\)</span> sono quelli che meglio “spiegano” i dati osservati</li>
</ol></section><section id="esempio-1-due-lanci" class="level3" data-number="42.2.3"><h3 data-number="42.2.3" class="anchored" data-anchor-id="esempio-1-due-lanci">
<span class="header-section-number">42.2.3</span> Esempio 1: Due lanci</h3>
<p>Immaginiamo di lanciare una moneta <strong>due volte</strong> e di osservare una <strong>testa</strong> e una <strong>croce</strong>. Il nostro obiettivo è stimare <span class="math inline">\(p_H\)</span>, cioè la probabilità che la moneta cada su testa. Per iniziare, valutiamo <strong>quanto sono plausibili</strong> due diversi valori di <span class="math inline">\(p_H\)</span> alla luce dei dati osservati, calcolando la funzione di verosimiglianza.</p>
<ul>
<li>
<p>Se <span class="math inline">\(p_H = 0.5\)</span> (una moneta equa), allora:</p>
<p><span class="math display">\[
L(0.5) = 0.5^1 \cdot (1 - 0.5)^1 = 0.25 .
\]</span></p>
</li>
<li>
<p>Se <span class="math inline">\(p_H = 0.4\)</span>, allora:</p>
<p><span class="math display">\[
L(0.4) = 0.4^1 \cdot 0.6^1 = 0.24 .
\]</span></p>
</li>
</ul>
<p>In entrambi i casi, la <strong>funzione di verosimiglianza</strong> ci dice quanto sia plausibile quel valore di <span class="math inline">\(p_H\)</span>, dati i risultati che abbiamo osservato (una testa e una croce). Come possiamo notare, il valore <span class="math inline">\(p_H = 0.5\)</span> è <strong>più compatibile</strong> con i dati osservati rispetto a <span class="math inline">\(p_H = 0.4\)</span>.</p>
</section><section id="calcolo-della-verosimiglianza-su-una-griglia-di-valori" class="level3" data-number="42.2.4"><h3 data-number="42.2.4" class="anchored" data-anchor-id="calcolo-della-verosimiglianza-su-una-griglia-di-valori">
<span class="header-section-number">42.2.4</span> Calcolo della verosimiglianza su una griglia di valori</h3>
<p>Ora ripetiamo questo calcolo per <strong>molti valori diversi</strong> di <span class="math inline">\(p_H\)</span>, compresi tra 0 e 1. Questo ci permette di <strong>visualizzare la funzione di verosimiglianza</strong> e di vedere per quali valori di <span class="math inline">\(p_H\)</span> essa è più alta.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Parametri osservati</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">2</span>             <span class="co"># Numero totale di lanci</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">1</span>             <span class="co"># Numero di teste osservate</span></span>
<span></span>
<span><span class="co"># Griglia di valori per p_H da 0 a 1</span></span>
<span><span class="va">p_H</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calcolo della funzione di verosimiglianza</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="va">p_H</span><span class="op">^</span><span class="va">y</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">p_H</span><span class="op">)</span><span class="op">^</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="rappresentazione-grafica" class="level3" data-number="42.2.5"><h3 data-number="42.2.5" class="anchored" data-anchor-id="rappresentazione-grafica">
<span class="header-section-number">42.2.5</span> Rappresentazione grafica</h3>
<p>Il grafico seguente mostra la <strong>funzione di verosimiglianza</strong> per i 100 valori di <span class="math inline">\(p_H\)</span>. Ogni punto della curva indica <strong>quanto è compatibile</strong> quel valore di <span class="math inline">\(p_H\)</span> con i dati che abbiamo osservato.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">p_H</span>, <span class="va">likelihood</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">p_H</span>, y <span class="op">=</span> <span class="va">likelihood</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>color <span class="op">=</span> <span class="va">okabe_ito_palette</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Funzione di Verosimiglianza per 2 Lanci\n(1 Testa, 1 Croce)"</span>,</span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">p</span><span class="op">[</span><span class="va">H</span><span class="op">]</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Verosimiglianza"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="15_likelihood_files/figure-html/unnamed-chunk-3-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="15_likelihood_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></a></p>
</figure>
</div>
</div>
</div>
</section><section id="cosa-ci-dice-il-grafico" class="level3" data-number="42.2.6"><h3 data-number="42.2.6" class="anchored" data-anchor-id="cosa-ci-dice-il-grafico">
<span class="header-section-number">42.2.6</span> Cosa ci dice il grafico?</h3>
<ul>
<li>La funzione di verosimiglianza raggiunge il suo massimo per <strong><span class="math inline">\(p_H = 0.5\)</span></strong>, che corrisponde alla proporzione osservata (1 testa su 2 lanci).</li>
<li>Questo valore di <span class="math inline">\(p_H\)</span> è quindi il <strong>più plausibile</strong> secondo i dati: rappresenta la <strong>stima di massima verosimiglianza</strong>.</li>
<li>I valori estremi (vicini a 0 o a 1) hanno verosimiglianza molto bassa: <strong>non spiegano bene</strong> il fatto che abbiamo ottenuto <strong>una testa e una croce</strong>.</li>
</ul>
<p>Ecco una versione migliorata e più didattica del tuo <strong>Esempio 2: Tre lanci</strong>, pensata per studenti che stanno imparando il concetto di verosimiglianza passo dopo passo. Mantiene l’approccio del primo esempio e rafforza la continuità logica, l’intuizione e l’interpretazione dei risultati, con un linguaggio semplice ma preciso.</p>
</section><section id="esempio-2-tre-lanci" class="level3" data-number="42.2.7"><h3 data-number="42.2.7" class="anchored" data-anchor-id="esempio-2-tre-lanci">
<span class="header-section-number">42.2.7</span> Esempio 2: Tre lanci</h3>
<p>Proseguiamo con un secondo esperimento: lanciamo una moneta <strong>tre volte</strong>, e otteniamo <strong>una testa e due croci</strong>. Anche in questo caso, vogliamo stimare <span class="math inline">\(p_H\)</span>, la probabilità che la moneta cada su testa, e valutare <strong>quali valori di <span class="math inline">\(p_H\)</span> sono più compatibili</strong> con i dati osservati.</p>
<p>Iniziamo calcolando la <strong>verosimiglianza</strong> per due valori specifici:</p>
<ul>
<li><p>Se <span class="math inline">\(p_H = 0.5\)</span> (moneta equa): <span class="math display">\[
L(0.5) = 0.5^1 \cdot (1 - 0.5)^2 = 0.5 \cdot 0.25 = 0.125
\]</span></p></li>
<li><p>Se <span class="math inline">\(p_H = 0.4\)</span>: <span class="math display">\[
L(0.4) = 0.4^1 \cdot 0.6^2 = 0.4 \cdot 0.36 = 0.144
\]</span></p></li>
</ul>
<p>Come vediamo, in questo caso <strong><span class="math inline">\(p_H = 0.4\)</span> ha una verosimiglianza maggiore</strong> rispetto a <span class="math inline">\(p_H = 0.5\)</span>: questo suggerisce che il valore 0.4 spiega meglio i dati (1 testa su 3 lanci) rispetto alla moneta equa.</p>
</section><section id="calcolo-su-una-griglia-di-valori" class="level3" data-number="42.2.8"><h3 data-number="42.2.8" class="anchored" data-anchor-id="calcolo-su-una-griglia-di-valori">
<span class="header-section-number">42.2.8</span> Calcolo su una griglia di valori</h3>
<p>Calcoliamo ora la verosimiglianza per <strong>100 valori compresi tra 0 e 1</strong> per visualizzare la funzione su tutto l’intervallo di probabilità.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Parametri osservati</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">3</span>             <span class="co"># Numero totale di lanci</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">1</span>             <span class="co"># Numero di teste osservate</span></span>
<span></span>
<span><span class="co"># Sequenza di valori possibili per p_H</span></span>
<span><span class="va">p_H</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calcolo della funzione di verosimiglianza</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="va">p_H</span><span class="op">^</span><span class="va">y</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">p_H</span><span class="op">)</span><span class="op">^</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="rappresentazione-grafica-1" class="level3" data-number="42.2.9"><h3 data-number="42.2.9" class="anchored" data-anchor-id="rappresentazione-grafica-1">
<span class="header-section-number">42.2.9</span> Rappresentazione grafica</h3>
<p>Il grafico seguente mostra la <strong>funzione di verosimiglianza</strong>: ci dice quanto ogni valore di <span class="math inline">\(p_H\)</span> è compatibile con l’osservazione di <strong>1 testa e 2 croci</strong>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Mostra la curva della verosimiglianza</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">p_H</span>, <span class="va">likelihood</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">p_H</span>, y <span class="op">=</span> <span class="va">likelihood</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Funzione di Verosimiglianza per 3 Lanci\n(1 Testa, 2 Croci)"</span>,</span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">p</span><span class="op">[</span><span class="va">H</span><span class="op">]</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Verosimiglianza"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="15_likelihood_files/figure-html/unnamed-chunk-5-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="15_likelihood_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></a></p>
</figure>
</div>
</div>
</div>
</section><section id="cosa-osserviamo" class="level3" data-number="42.2.10"><h3 data-number="42.2.10" class="anchored" data-anchor-id="cosa-osserviamo">
<span class="header-section-number">42.2.10</span> Cosa osserviamo?</h3>
<ul>
<li>Il <strong>massimo</strong> della funzione di verosimiglianza <strong>non è più in <span class="math inline">\(p_H = 0.5\)</span></strong>, ma <strong>più vicino a 0.33</strong>, cioè alla proporzione osservata (1 testa su 3 lanci).</li>
<li>Questo riflette il fatto che il valore di <span class="math inline">\(p_H\)</span> che <strong>meglio spiega i dati</strong> è quello che riproduce la frequenza osservata.</li>
<li>La curva è <strong>più stretta</strong> rispetto al caso con 2 lanci: abbiamo più informazioni, quindi possiamo stimare <span class="math inline">\(p_H\)</span> con maggiore precisione.</li>
<li>Anche qui, i valori estremi di <span class="math inline">\(p_H\)</span> (vicino a 0 o 1) hanno verosimiglianze basse, perché <strong>non giustificano bene</strong> l’osservazione di <strong>una testa e due croci</strong>.</li>
</ul></section><section id="interpretazione-dei-risultati" class="level3" data-number="42.2.11"><h3 data-number="42.2.11" class="anchored" data-anchor-id="interpretazione-dei-risultati">
<span class="header-section-number">42.2.11</span> Interpretazione dei Risultati</h3>
<ul>
<li>La funzione di verosimiglianza <strong>raggiunge il massimo</strong> per valori di <span class="math inline">\(p_H\)</span> vicini alla <strong>proporzione di teste osservata</strong>.</li>
<li>Quando il numero di lanci <strong>aumenta</strong>, la curva diventa più “stretta”: i dati ci permettono di stimare <span class="math inline">\(p_H\)</span> in modo più preciso.</li>
<li>Valori estremi di <span class="math inline">\(p_H\)</span> (vicini a 0 o 1) hanno <strong>verosimiglianze basse</strong>: non spiegano bene i dati osservati.</li>
</ul>
<p><strong>In sintesi</strong>, abbiamo visto come costruire la funzione di verosimiglianza <strong>a partire dai dati osservati</strong>, senza usare direttamente la distribuzione binomiale completa.<br>
La tua sezione è già molto chiara, ma possiamo migliorarla ulteriormente per renderla ancora più <strong>didattica e accessibile a studenti principianti</strong>, mantenendo un linguaggio preciso e coerente con le sezioni precedenti.<br>
L’obiettivo è aiutare gli studenti a vedere <strong>come la distribuzione binomiale si collega alla verosimiglianza</strong> e alla stima del parametro.</p>
</section></section><section id="verosimiglianza-binomiale" class="level2" data-number="42.3"><h2 data-number="42.3" class="anchored" data-anchor-id="verosimiglianza-binomiale">
<span class="header-section-number">42.3</span> Verosimiglianza binomiale</h2>
<p>Torniamo al nostro esperimento con la moneta, ma questa volta lo rendiamo un po’ più realistico: lanciamo la moneta <strong><span class="math inline">\(n = 30\)</span> volte</strong> e otteniamo <strong><span class="math inline">\(y = 23\)</span> teste</strong>.</p>
<p>Per modellare il numero totale di teste osservate, utilizziamo la <strong>distribuzione binomiale</strong>, che ci dice qual è la probabilità di ottenere esattamente <span class="math inline">\(y\)</span> successi su <span class="math inline">\(n\)</span> prove, quando la probabilità di successo in ogni singolo lancio è <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[
P(Y = y \mid \theta) = \binom{n}{y} \theta^y (1 - \theta)^{n - y}.
\]</span></p>
<p>In questo contesto:</p>
<ul>
<li>
<span class="math inline">\(Y\)</span> è una <strong>variabile casuale</strong> che rappresenta il numero di teste ottenute,</li>
<li>
<span class="math inline">\(y = 23\)</span> è il <strong>valore osservato</strong>,</li>
<li>
<span class="math inline">\(\theta\)</span> (o <span class="math inline">\(p_H\)</span>) è la <strong>probabilità incognita</strong> di ottenere testa in un singolo lancio.</li>
</ul>
<section id="dalla-distribuzione-alla-verosimiglianza" class="level3" data-number="42.3.1"><h3 data-number="42.3.1" class="anchored" data-anchor-id="dalla-distribuzione-alla-verosimiglianza">
<span class="header-section-number">42.3.1</span> Dalla distribuzione alla verosimiglianza</h3>
<p>Una volta osservati i dati (<span class="math inline">\(y = 23\)</span>), possiamo considerarli <strong>fissati</strong> e analizzare <strong>quanto ciascun valore possibile del parametro <span class="math inline">\(\theta\)</span></strong> (la probabilità di ottenere testa) <strong>sia compatibile con questi dati</strong>. Per farlo, possiamo <strong>riutilizzare direttamente la formula della distribuzione binomiale</strong>, trattandola come <strong>funzione di <span class="math inline">\(\theta\)</span></strong> anziché come funzione di <span class="math inline">\(y\)</span>:</p>
<p><span class="math display">\[
L(\theta \mid y = 23) = \binom{30}{23} \theta^{23} (1 - \theta)^7.
\]</span></p>
<p>Questa è la <strong>funzione di verosimiglianza</strong>, che ci dice quanto ogni valore di <span class="math inline">\(\theta\)</span> sia plausibile alla luce dei dati osservati. A differenza degli esempi precedenti (in cui abbiamo ignorato le costanti moltiplicative), qui <strong>non abbiamo bisogno di semplificare</strong> la formula: la funzione <code><a href="https://rdrr.io/r/stats/Binomial.html">dbinom()</a></code> in R calcola <strong>automaticamente l’intera espressione</strong>, costante inclusa.</p>
</section><section id="visualizzazione-della-funzione-di-verosimiglianza" class="level3" data-number="42.3.2"><h3 data-number="42.3.2" class="anchored" data-anchor-id="visualizzazione-della-funzione-di-verosimiglianza">
<span class="header-section-number">42.3.2</span> Visualizzazione della funzione di verosimiglianza</h3>
<p>Il codice seguente costruisce il <strong>grafico della funzione di verosimiglianza</strong>, calcolando per ogni valore di <span class="math inline">\(\theta\)</span> la probabilità di osservare <strong>23 successi su 30 prove</strong>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Parametri osservati</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span>       <span class="co"># Numero totale di lanci</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">23</span>       <span class="co"># Numero di teste osservate</span></span>
<span></span>
<span><span class="co"># Griglia di valori possibili per p_H</span></span>
<span><span class="va">p_H</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calcolo della funzione di verosimiglianza (usando la binomiale completa)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">y</span>, size <span class="op">=</span> <span class="va">n</span>, prob <span class="op">=</span> <span class="va">p_H</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Creazione del data frame</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">p_H</span>, <span class="va">likelihood</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Grafico della funzione di verosimiglianza</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">p_H</span>, y <span class="op">=</span> <span class="va">likelihood</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>color <span class="op">=</span> <span class="va">okabe_ito_palette</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Funzione di Verosimiglianza per 30 Lanci di Moneta (23 Teste)"</span>,</span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">p</span><span class="op">[</span><span class="va">H</span><span class="op">]</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Verosimiglianza"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="15_likelihood_files/figure-html/unnamed-chunk-6-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="15_likelihood_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></a></p>
</figure>
</div>
</div>
</div>
</section><section id="interpretazione-del-risultato" class="level3" data-number="42.3.3"><h3 data-number="42.3.3" class="anchored" data-anchor-id="interpretazione-del-risultato">
<span class="header-section-number">42.3.3</span> Interpretazione del risultato</h3>
<p>Osservando il grafico, vediamo che:</p>
<ul>
<li>la funzione di verosimiglianza raggiunge il suo <strong>massimo</strong> in corrispondenza di <strong><span class="math inline">\(p_H \approx 0.77\)</span></strong>;</li>
<li>questo significa che il valore di <span class="math inline">\(\theta\)</span> (cioè <span class="math inline">\(p_H\)</span>) che rende <strong>più plausibile</strong> l’osservazione di 23 teste su 30 è circa <strong>0.77</strong>;</li>
<li>in altre parole, <strong>la stima di massima verosimiglianza (MLE)</strong> per la probabilità di ottenere testa è: <span class="math display">\[
\hat{p}_H = \frac{23}{30} \approx 0.767.
\]</span>
</li>
</ul>
<p>Questo risultato è del tutto intuitivo: <strong>la stima migliore</strong> è la <strong>proporzione osservata</strong> di teste.<br>
La verosimiglianza ci mostra <strong>quali altri valori di <span class="math inline">\(\theta\)</span> sono meno compatibili</strong> con i dati.</p>
<p><strong>In sintesi</strong>, abbiamo visto come utilizzare <strong>direttamente la distribuzione binomiale</strong> per costruire la funzione di verosimiglianza. Questa funzione è uno <strong>strumento fondamentale</strong> per confrontare diversi valori possibili del parametro <span class="math inline">\(\theta\)</span> (cioè la probabilità di successo) <strong>alla luce dei dati osservati</strong>.</p>
<p>Nel caso della moneta lanciata 30 volte con 23 teste, abbiamo trattato il numero di successi osservati (<span class="math inline">\(y = 23\)</span>) come un dato fisso, e abbiamo valutato per <strong>quali valori di <span class="math inline">\(\theta\)</span></strong> questa osservazione sarebbe più plausibile.</p>
<p>In R, per calcolare la funzione di verosimiglianza <strong>non serve riscrivere manualmente la formula della binomiale</strong>. Possiamo usare la funzione <code><a href="https://rdrr.io/r/stats/Binomial.html">dbinom()</a></code>, che calcola le probabilità (o masse) della <strong>distribuzione binomiale</strong> per un dato numero di successi <span class="math inline">\(y\)</span>, un numero totale di prove <span class="math inline">\(n\)</span>, e una certa probabilità di successo <span class="math inline">\(\theta\)</span>.</p>
<p>Ad esempio, nel codice:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">y</span>, size <span class="op">=</span> <span class="va">n</span>, prob <span class="op">=</span> <span class="va">p_H</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>
<code>y</code> è il numero di successi osservati (23),</li>
<li>
<code>n</code> è il numero totale di prove (30),</li>
<li>
<code>p_H</code> è un vettore di valori di <span class="math inline">\(\theta\)</span> tra 0 e 1.</li>
</ul>
<p>Il risultato <code>likelihood</code> è un vettore che contiene, per ciascun valore di <span class="math inline">\(\theta\)</span>, la <strong>verosimiglianza</strong> associata a quel valore: cioè, <strong>quanto quel valore di <span class="math inline">\(\theta\)</span> è compatibile con i dati</strong> che abbiamo osservato.</p>
<p>Riassumendo:</p>
<ul>
<li>
<code><a href="https://rdrr.io/r/stats/Binomial.html">dbinom()</a></code> fornisce la <strong>funzione di probabilità</strong> della binomiale,</li>
<li>fissando <span class="math inline">\(y\)</span> e variando <span class="math inline">\(\theta\)</span>, usiamo <code><a href="https://rdrr.io/r/stats/Binomial.html">dbinom()</a></code> per costruire la <strong>funzione di verosimiglianza</strong>,</li>
<li>possiamo poi <strong>tracciare un grafico</strong> di questa funzione per <strong>visualizzare quali valori di <span class="math inline">\(\theta\)</span> sono più plausibili</strong>.</li>
</ul>
<p>Questa strategia mostra come la verosimiglianza possa essere costruita <strong>direttamente a partire da una distribuzione conosciuta</strong> (in questo caso, la binomiale) e <strong>implementata facilmente in R</strong> con strumenti standard.</p>
</section></section><section id="la-stima-di-massima-verosimiglianza" class="level2" data-number="42.4"><h2 data-number="42.4" class="anchored" data-anchor-id="la-stima-di-massima-verosimiglianza">
<span class="header-section-number">42.4</span> La Stima di Massima Verosimiglianza</h2>
<p>Nel momento in cui osserviamo dei dati e vogliamo stimare un parametro incognito (ad esempio, la probabilità <span class="math inline">\(\theta\)</span> che una moneta dia “testa”), un metodo classico è la <strong>stima di massima verosimiglianza</strong> (<em>Maximum Likelihood Estimation</em>, o <strong>MLE</strong>).</p>
<p>Anche se nella prospettiva bayesiana ci interessa la <strong>distribuzione completa</strong> dei valori plausibili del parametro (e non un singolo valore stimato), è utile conoscere il concetto di <strong>MLE</strong>, che rappresenta il <strong>valore di <span class="math inline">\(\theta\)</span> che rende i dati osservati più compatibili</strong> con il modello. Più avanti vedremo come la MLE corrisponde, nel caso di una prior uniforme, al <strong>valore massimo della distribuzione a posteriori</strong>.</p>
<section id="lidea-di-fondo" class="level3" data-number="42.4.1"><h3 data-number="42.4.1" class="anchored" data-anchor-id="lidea-di-fondo">
<span class="header-section-number">42.4.1</span> L’idea di Fondo</h3>
<p>La logica è semplice. Una volta osservati i dati, ci chiediamo: <strong>quali valori del parametro sono più compatibili con ciò che abbiamo visto?</strong> Il valore che risulta più plausibile è la stima di massima verosimiglianza.</p>
<p>Immagina di “provare” tanti valori di <span class="math inline">\(\theta\)</span>, e per ciascuno chiederti: <em>“se fosse questo il vero valore di <span class="math inline">\(\theta\)</span>, quanto sarebbe plausibile osservare questi dati?”</em> Il valore che <strong>meglio spiega i dati</strong> è quello scelto come stima.</p>
</section><section id="un-esempio-concreto" class="level3" data-number="42.4.2"><h3 data-number="42.4.2" class="anchored" data-anchor-id="un-esempio-concreto">
<span class="header-section-number">42.4.2</span> Un Esempio Concreto</h3>
<p>Hai lanciato una moneta <strong>30 volte</strong> e hai osservato <strong>23 teste</strong>. La tua domanda è: <em>quanto è sbilanciata la moneta?</em></p>
<p>Utilizziamo la <strong>funzione di verosimiglianza</strong>, che ci dice <strong>quanto ogni valore possibile di <span class="math inline">\(\theta\)</span> è compatibile con i dati osservati</strong>. Più alta è la verosimiglianza, più plausibile è il valore di <span class="math inline">\(\theta\)</span>.</p>
</section><section id="una-metafora-visiva" class="level3" data-number="42.4.3"><h3 data-number="42.4.3" class="anchored" data-anchor-id="una-metafora-visiva">
<span class="header-section-number">42.4.3</span> Una metafora visiva</h3>
<p>Immagina di osservare una curva che rappresenta la <strong>verosimiglianza</strong> al variare del parametro <span class="math inline">\(\theta\)</span>.<br>
La curva si alza, raggiunge un punto massimo, e poi scende: proprio come una collina.</p>
<p>Quel punto più alto della curva rappresenta il valore di <span class="math inline">\(\theta\)</span> che è <strong>più compatibile con i dati osservati</strong>: è il valore per cui i dati risultano <strong>più verosimili</strong>, secondo il modello.</p>
<p>Quel valore è chiamato <strong>stima di massima verosimiglianza</strong> (<em>maximum likelihood estimate</em>): è il punto in cima alla collina della verosimiglianza.</p>
</section><section id="come-si-trova-il-massimo" class="level3" data-number="42.4.4"><h3 data-number="42.4.4" class="anchored" data-anchor-id="come-si-trova-il-massimo">
<span class="header-section-number">42.4.4</span> Come si Trova il Massimo?</h3>
<p>Dal punto di vista matematico, il massimo di una funzione si trova dove la sua <strong>pendenza</strong> (la derivata) è <strong>zero</strong>: cioè, dove smette di salire e inizia a scendere.</p>
<p>Per la verosimiglianza binomiale (trasformata in log-verosimiglianza), questo calcolo si può fare in modo esatto. Se hai osservato <span class="math inline">\(y\)</span> successi su <span class="math inline">\(n\)</span> prove, la log-verosimiglianza è:</p>
<p><span class="math display">\[
\ell(\theta) = y \log \theta + (n - y) \log(1 - \theta),
\]</span></p>
<p>e la derivata si annulla quando:</p>
<p><span class="math display">\[
\hat{\theta} = \frac{y}{n}.
\]</span></p>
<p>In altre parole, <strong>la MLE è semplicemente la proporzione osservata di successi</strong>.</p>
</section><section id="un-punto-importante-per-lapproccio-bayesiano" class="level3" data-number="42.4.5"><h3 data-number="42.4.5" class="anchored" data-anchor-id="un-punto-importante-per-lapproccio-bayesiano">
<span class="header-section-number">42.4.5</span> Un punto Importante per l’Approccio Bayesiano</h3>
<p>Nel contesto bayesiano, <strong>non ci limitiamo a cercare il valore più plausibile del parametro</strong>, ma costruiamo una distribuzione completa che rappresenta <strong>l’incertezza su <span class="math inline">\(\theta\)</span></strong>. Tuttavia, <strong>il punto in cui la distribuzione a posteriori raggiunge il suo massimo</strong> viene chiamato <strong>MAP (Maximum A Posteriori)</strong>, e se assumiamo una <strong>distribuzione a priori uniforme</strong>, <strong>MLE e MAP coincidono</strong>. Quindi, la MLE può essere vista come un <strong>caso speciale</strong> del ragionamento bayesiano, utile per introdurre il concetto di compatibilità tra parametri e dati.</p>
</section></section><section id="calcolare-la-mle-in-r" class="level2" data-number="42.5"><h2 data-number="42.5" class="anchored" data-anchor-id="calcolare-la-mle-in-r">
<span class="header-section-number">42.5</span> Calcolare la MLE in R</h2>
<section id="metodo-1-valutazione-su-griglia" class="level3" data-number="42.5.1"><h3 data-number="42.5.1" class="anchored" data-anchor-id="metodo-1-valutazione-su-griglia">
<span class="header-section-number">42.5.1</span> Metodo 1: Valutazione su Griglia</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Parametri</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">23</span></span>
<span><span class="va">theta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calcolo della verosimiglianza binomiale</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">y</span>, size <span class="op">=</span> <span class="va">n</span>, prob <span class="op">=</span> <span class="va">theta</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Trova il massimo</span></span>
<span><span class="va">max_index</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">likelihood</span><span class="op">)</span></span>
<span><span class="va">optimal_theta</span> <span class="op">&lt;-</span> <span class="va">theta</span><span class="op">[</span><span class="va">max_index</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Risultato</span></span>
<span><span class="va">optimal_theta</span></span>
<span><span class="co">#&gt; [1] 0.7667</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Spiegazione:</strong></p>
<ul>
<li>
<code><a href="https://rdrr.io/r/stats/Binomial.html">dbinom()</a></code> calcola la verosimiglianza per ogni valore di <span class="math inline">\(\theta\)</span>;</li>
<li>
<code><a href="https://rdrr.io/r/base/which.min.html">which.max()</a></code> individua il massimo;</li>
<li>
<code>theta[max_index]</code> restituisce la stima MLE.</li>
</ul></section><section id="metodo-2-ottimizzazione-numerica" class="level3" data-number="42.5.2"><h3 data-number="42.5.2" class="anchored" data-anchor-id="metodo-2-ottimizzazione-numerica">
<span class="header-section-number">42.5.2</span> Metodo 2: Ottimizzazione Numerica</h3>
<p>In alternativa, possiamo trovare la MLE <strong>senza usare griglie</strong>, con un approccio più efficiente.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Funzione log-verosimiglianza negativa</span></span>
<span><span class="va">neg_log_likelihood</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="op">-</span> <span class="op">(</span><span class="va">y</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">theta</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Ottimizzazione numerica</span></span>
<span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/optim.html">optim</a></span><span class="op">(</span></span>
<span>  par <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>  fn <span class="op">=</span> <span class="va">neg_log_likelihood</span>,</span>
<span>  method <span class="op">=</span> <span class="st">"Brent"</span>,</span>
<span>  lower <span class="op">=</span> <span class="fl">1e-6</span>,</span>
<span>  upper <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="fl">1e-6</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">optimal_theta_numerical</span> <span class="op">&lt;-</span> <span class="va">result</span><span class="op">$</span><span class="va">par</span></span>
<span><span class="va">optimal_theta_numerical</span></span>
<span><span class="co">#&gt; [1] 0.7667</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Nota:</strong> abbiamo calcolato la <strong>log-verosimiglianza negativa</strong>, perché <code><a href="https://rdrr.io/r/stats/optim.html">optim()</a></code> cerca <strong>minimi</strong> per default.</p>
</section><section id="confronto-tra-le-soluzioni" class="level3" data-number="42.5.3"><h3 data-number="42.5.3" class="anchored" data-anchor-id="confronto-tra-le-soluzioni">
<span class="header-section-number">42.5.3</span> Confronto tra le Soluzioni</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span></span>
<span>  <span class="st">"Griglia"</span> <span class="op">=</span> <span class="va">optimal_theta</span>, </span>
<span>  <span class="st">"Ottimizzazione"</span> <span class="op">=</span> <span class="va">optimal_theta_numerical</span>, </span>
<span>  <span class="st">"Analitica"</span> <span class="op">=</span> <span class="va">y</span> <span class="op">/</span> <span class="va">n</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt;        Griglia Ottimizzazione      Analitica </span></span>
<span><span class="co">#&gt;         0.7667         0.7667         0.7667</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Tutti i metodi restituiscono lo stesso risultato:<br><span class="math display">\[
\hat{\theta} = \frac{23}{30} \approx 0.767.
\]</span></p>
</section></section><section id="verosimiglianza-congiunta" class="level2" data-number="42.6"><h2 data-number="42.6" class="anchored" data-anchor-id="verosimiglianza-congiunta">
<span class="header-section-number">42.6</span> Verosimiglianza Congiunta</h2>
<p>Abbiamo visto che, nel caso di una sequenza di <span class="math inline">\(n\)</span> lanci di una moneta, la funzione di <strong>verosimiglianza</strong> si basa sulla distribuzione binomiale. In questo caso, trattiamo un esperimento Bernoulliano ripetuto <span class="math inline">\(n\)</span> volte, e la nostra osservazione è <strong>il numero totale di successi</strong> (teste). Il numero complessivo di successi segue una <strong>distribuzione binomiale</strong>, e la funzione di verosimiglianza assume la forma:</p>
<p><span class="math display">\[
\mathcal{L}(\theta) = P(Y = y \mid \theta) = \binom{n}{y} \theta^y (1 - \theta)^{n - y}.
\]</span></p>
<p>Qui la verosimiglianza è espressa direttamente in termini del numero totale di successi e insuccessi, senza dover scrivere il contributo di ogni singolo lancio.</p>
<p>Tuttavia, possiamo affrontare la questione da una prospettiva diversa: <strong>invece di considerare il numero totale di successi, possiamo pensare alla verosimiglianza come il prodotto delle probabilità di ogni singolo lancio</strong>. Questo ci porta a una generalizzazione importante: la <strong>verosimiglianza congiunta</strong> di più osservazioni indipendenti.</p>
<section id="dal-caso-binomiale-alla-verosimiglianza-congiunta" class="level3" data-number="42.6.1"><h3 data-number="42.6.1" class="anchored" data-anchor-id="dal-caso-binomiale-alla-verosimiglianza-congiunta">
<span class="header-section-number">42.6.1</span> Dal Caso Binomiale alla Verosimiglianza Congiunta</h3>
<p>Nel caso dei lanci della moneta, le singole osservazioni sono <strong>prove Bernoulliane indipendenti</strong>, ovvero ogni singolo lancio è un’osservazione indipendente che segue una distribuzione Bernoulli con parametro <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[
P(Y_i = 1 \mid \theta) = \theta, \quad P(Y_i = 0 \mid \theta) = 1 - \theta.
\]</span></p>
<p>Se trattiamo ogni prova individualmente, la funzione di verosimiglianza per una <strong>singola osservazione</strong> è:</p>
<p><span class="math display">\[
\mathcal{L}(\theta \mid y_i) = \theta^{y_i} (1 - \theta)^{1 - y_i}.
\]</span></p>
<p>Ora, per un campione di <span class="math inline">\(n\)</span> osservazioni indipendenti, la <strong>verosimiglianza congiunta</strong> è il prodotto delle verosimiglianze delle singole osservazioni:</p>
<p><span class="math display">\[
\mathcal{L}(\theta \mid y_1, y_2, \dots, y_n) = \prod_{i=1}^{n} \theta^{y_i} (1 - \theta)^{1 - y_i}.
\]</span></p>
<p>Riconosciamo che questa espressione è identica alla funzione di verosimiglianza della distribuzione binomiale, perché il numero totale di successi è:</p>
<p><span class="math display">\[
y = \sum_{i=1}^{n} y_i.
\]</span></p>
<p>Quindi, riscrivendo la verosimiglianza congiunta, otteniamo:</p>
<p><span class="math display">\[
\mathcal{L}(\theta) = \theta^{\sum y_i} (1 - \theta)^{n - \sum y_i} = \theta^y (1 - \theta)^{n - y}.
\]</span></p>
<p><strong>Questa è proprio la verosimiglianza della distribuzione binomiale!</strong> Questo mostra che il caso binomiale può essere visto come una forma compatta di verosimiglianza congiunta per prove Bernoulliane indipendenti.</p>
</section><section id="perché-è-importante-la-verosimiglianza-congiunta" class="level3" data-number="42.6.2"><h3 data-number="42.6.2" class="anchored" data-anchor-id="perché-è-importante-la-verosimiglianza-congiunta">
<span class="header-section-number">42.6.2</span> Perché è Importante la Verosimiglianza Congiunta?</h3>
<p>L’idea della <strong>verosimiglianza congiunta</strong> è fondamentale perché ci permette di estendere i concetti di verosimiglianza dal caso di una singola osservazione al caso di molte osservazioni indipendenti. Questo è utile in molti contesti statistici:</p>
<ol type="1">
<li>
<strong>stimare parametri</strong> basandosi su un intero campione invece che su una singola osservazione;</li>
<li>
<strong>definire modelli statistici più complessi</strong>, in cui le osservazioni sono indipendenti ma possono avere diverse distribuzioni.</li>
</ol>
<p>In sintesi, l’esempio binomiale mostra che la verosimiglianza congiunta di prove Bernoulliane indipendenti si riconduce alla verosimiglianza binomiale. Tuttavia, la vera potenza della verosimiglianza congiunta si manifesta in distribuzioni continue come la normale, dove la produttoria delle densità di probabilità per singole osservazioni è chiaramente distinta dalla funzione di verosimiglianza per il campione intero.</p>
<p>La chiave per comprendere il concetto è rendersi conto che <strong>la verosimiglianza di un’intera sequenza di prove indipendenti è il prodotto delle singole verosimiglianze</strong>.</p>
</section><section id="esempio-osservazioni-raggruppate" class="level3" data-number="42.6.3"><h3 data-number="42.6.3" class="anchored" data-anchor-id="esempio-osservazioni-raggruppate">
<span class="header-section-number">42.6.3</span> Esempio: Osservazioni Raggruppate</h3>
<p>Per illustrare il concetto di <strong>verosimiglianza congiunta</strong> nel caso della distribuzione binomiale, consideriamo quattro gruppi distinti di osservazioni binomiali indipendenti:</p>
<ul>
<li>
<strong>gruppo 1</strong>: 23 successi su 30 prove,</li>
<li>
<strong>gruppo 2</strong>: 20 successi su 28 prove,</li>
<li>
<strong>gruppo 3</strong>: 29 successi su 40 prove,</li>
<li>
<strong>gruppo 4</strong>: 29 successi su 36 prove.</li>
</ul>
<p>Poiché ogni gruppo segue una distribuzione binomiale indipendente con lo stesso parametro <span class="math inline">\(\theta\)</span>, la log-verosimiglianza congiunta si ottiene <strong>sommando</strong> le log-verosimiglianze di ciascun gruppo:</p>
<p><span class="math display">\[
\log \mathcal{L}(\theta) = \sum_{i=1}^{4} \left[ y_i \log(\theta) + (n_i - y_i) \log(1 - \theta) \right],
\]</span></p>
<p>dove:</p>
<ul>
<li>
<span class="math inline">\(n_i\)</span> è il numero totale di prove nel gruppo <span class="math inline">\(i\)</span>,</li>
<li>
<span class="math inline">\(y_i\)</span> è il numero di successi nel gruppo <span class="math inline">\(i\)</span>.</li>
</ul>
<p>Sostituendo i valori specifici:</p>
<p><span class="math display">\[
\begin{aligned}
\log \mathcal{L}(\theta) &amp;= [23\log(\theta) + (30-23)\log(1 - \theta)] \\
&amp;\quad + [20\log(\theta) + (28-20)\log(1 - \theta)] \\
&amp;\quad + [29\log(\theta) + (40-29)\log(1 - \theta)] \\
&amp;\quad + [29\log(\theta) + (36-29)\log(1 - \theta)].
\end{aligned}
\]</span></p>
<p>Questa formula ci permette di calcolare <strong>quanto è plausibile</strong> il valore del parametro <span class="math inline">\(\theta\)</span>, tenendo conto simultaneamente di tutte le osservazioni nei quattro gruppi.</p>
</section><section id="implementazione-in-r" class="level3" data-number="42.6.4"><h3 data-number="42.6.4" class="anchored" data-anchor-id="implementazione-in-r">
<span class="header-section-number">42.6.4</span> Implementazione in R</h3>
<p>Supponiamo di avere i dati di <strong>quattro gruppi indipendenti</strong>, e vogliamo trovare la stima del parametro <span class="math inline">\(\theta\)</span> che <strong>massimizza la log-verosimiglianza congiunta</strong>. Procederemo passo dopo passo.</p>
<p><strong>1. Definire una funzione per la log-verosimiglianza congiunta.</strong></p>
<p>Questa funzione riceve un valore di <span class="math inline">\(\theta\)</span> e una lista di gruppi. Ogni gruppo contiene il numero totale di prove e il numero di successi. La funzione calcola la somma delle log-verosimiglianze per ciascun gruppo.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Funzione che calcola la log-verosimiglianza congiunta</span></span>
<span><span class="va">log_verosimiglianza_congiunta</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span>, <span class="va">dati</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Limitiamo theta per evitare log(0)</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">theta</span> <span class="op">&lt;=</span> <span class="fl">0</span><span class="op">)</span> <span class="va">theta</span> <span class="op">&lt;-</span> <span class="fl">1e-10</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">theta</span> <span class="op">&gt;=</span> <span class="fl">1</span><span class="op">)</span> <span class="va">theta</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fl">1e-10</span></span>
<span></span>
<span>  <span class="co"># Inizializziamo il totale</span></span>
<span>  <span class="va">somma_loglik</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span></span>
<span>  <span class="co"># Per ogni gruppo, calcoliamo il contributo alla log-verosimiglianza</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">dati</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">gruppo</span> <span class="op">&lt;-</span> <span class="va">dati</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span>   <span class="co"># Estrae il gruppo i-esimo</span></span>
<span>    <span class="va">n</span> <span class="op">&lt;-</span> <span class="va">gruppo</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>        <span class="co"># Numero totale di prove</span></span>
<span>    <span class="va">y</span> <span class="op">&lt;-</span> <span class="va">gruppo</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>        <span class="co"># Numero di successi</span></span>
<span></span>
<span>    <span class="co"># Aggiunge il contributo del gruppo alla somma totale</span></span>
<span>    <span class="va">somma_loglik</span> <span class="op">&lt;-</span> <span class="va">somma_loglik</span> <span class="op">+</span> <span class="va">y</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">theta</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="co"># Restituiamo il valore negativo (perché optim() cerca minimi)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="op">-</span><span class="va">somma_loglik</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>2. Inserire i dati.</strong></p>
<p>Qui definiamo i dati per ciascun gruppo come coppie (numero di prove, numero di successi):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Dati osservati per ciascun gruppo</span></span>
<span><span class="va">dati_gruppi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">30</span>, <span class="fl">23</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">28</span>, <span class="fl">20</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">40</span>, <span class="fl">29</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">36</span>, <span class="fl">29</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>3. Trovare la stima di θ che massimizza la verosimiglianza.</strong></p>
<p>Usiamo <code><a href="https://rdrr.io/r/stats/optim.html">optim()</a></code> per trovare numericamente il valore di <span class="math inline">\(\theta\)</span> che minimizza il <strong>valore negativo della log-verosimiglianza</strong>, ovvero che <strong>massimizza la log-verosimiglianza</strong>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Ricerca del valore ottimale di theta</span></span>
<span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/optim.html">optim</a></span><span class="op">(</span></span>
<span>  par <span class="op">=</span> <span class="fl">0.5</span>,                            <span class="co"># Valore iniziale</span></span>
<span>  fn <span class="op">=</span> <span class="va">log_verosimiglianza_congiunta</span>,  <span class="co"># Funzione da minimizzare</span></span>
<span>  dati <span class="op">=</span> <span class="va">dati_gruppi</span>,                  <span class="co"># Passiamo i dati</span></span>
<span>  method <span class="op">=</span> <span class="st">"L-BFGS-B"</span>,                 <span class="co"># Metodo con vincoli</span></span>
<span>  lower <span class="op">=</span> <span class="fl">0</span>, upper <span class="op">=</span> <span class="fl">1</span>                 <span class="co"># Vincoli: theta tra 0 e 1</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Stima ottimale trovata</span></span>
<span><span class="va">result</span><span class="op">$</span><span class="va">par</span></span>
<span><span class="co">#&gt; [1] 0.7537</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>4. Visualizzare la log-verosimiglianza.</strong></p>
<p>Costruiamo ora un grafico che mostri <strong>come varia la log-verosimiglianza</strong> al variare di <span class="math inline">\(\theta\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Valori di theta da esplorare</span></span>
<span><span class="va">theta_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0.01</span>, <span class="fl">0.99</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Vettore per salvare i valori di log-verosimiglianza</span></span>
<span><span class="va">log_likelihood_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">theta_values</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calcoliamo il valore della funzione per ogni valore di theta</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">theta_values</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">t</span> <span class="op">&lt;-</span> <span class="va">theta_values</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="va">log_likelihood_values</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">log_verosimiglianza_congiunta</span><span class="op">(</span><span class="va">t</span>, <span class="va">dati_gruppi</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ora costruiamo il grafico:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">ggplot</span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>theta <span class="op">=</span> <span class="va">theta_values</span>, log_likelihood <span class="op">=</span> <span class="va">log_likelihood_values</span><span class="op">)</span>,</span>
<span>  <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span>, y <span class="op">=</span> <span class="va">log_likelihood</span><span class="op">)</span></span>
<span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"blue"</span>, linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Funzione di Log-Verosimiglianza Congiunta"</span>,</span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Log-verosimiglianza negativa"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="15_likelihood_files/figure-html/unnamed-chunk-14-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="15_likelihood_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></a></p>
</figure>
</div>
</div>
</div>
<p>Con questo esempio abbiamo visto che:</p>
<ul>
<li>la <strong>log-verosimiglianza congiunta</strong> si ottiene <strong>sommando</strong> le log-verosimiglianze dei singoli gruppi;</li>
<li>è possibile trovare la stima ottimale di <span class="math inline">\(\theta\)</span> <strong>numericamente</strong>, senza formule complicate;</li>
<li>il grafico della log-verosimiglianza ci aiuta a <strong>visualizzare il punto in cui il modello è più compatibile con i dati</strong>.</li>
</ul>
<p>Questo approccio — basato sull’uso della verosimiglianza e della sua somma tra gruppi indipendenti — sarà anche <strong>la base per il passaggio all’inferenza bayesiana</strong>, dove aggiungeremo <strong>una distribuzione a priori</strong> per ottenere una distribuzione a posteriori di <span class="math inline">\(\theta\)</span>.</p>
</section></section><section id="la-verosimiglianza-marginale" class="level2" data-number="42.7"><h2 data-number="42.7" class="anchored" data-anchor-id="la-verosimiglianza-marginale">
<span class="header-section-number">42.7</span> La Verosimiglianza Marginale</h2>
<p>La <strong>verosimiglianza marginale</strong> è un concetto fondamentale nell’inferenza bayesiana, utilizzato per valutare <strong>quanto un modello sia compatibile con i dati osservati</strong>, tenendo conto dell’incertezza sui parametri.</p>
<p>A differenza della verosimiglianza standard, che misura la plausibilità dei dati per un valore <strong>fisso</strong> del parametro, la <strong>verosimiglianza marginale</strong> considera <strong>tutti i possibili valori del parametro</strong>, pesandoli in base alla loro probabilità a priori. Questo approccio permette di integrare l’incertezza nella valutazione del modello.</p>
<section id="caso-con-parametri-discreti" class="level3" data-number="42.7.1"><h3 data-number="42.7.1" class="anchored" data-anchor-id="caso-con-parametri-discreti">
<span class="header-section-number">42.7.1</span> Caso con Parametri Discreti</h3>
<p>Per comprendere meglio il concetto, consideriamo un esperimento in cui eseguiamo <strong>10 tentativi</strong> e otteniamo <strong>7 successi</strong>. Supponiamo che la probabilità di successo <span class="math inline">\(\theta\)</span> possa assumere solo tre valori discreti:</p>
<p><span class="math display">\[
\theta \in \{0.1, 0.5, 0.9\}.
\]</span></p>
<p>Per calcolare la <strong>verosimiglianza marginale</strong>, dobbiamo:</p>
<ol type="1">
<li>
<p><strong>Assegnare una probabilità a priori</strong> a ciascun valore di <span class="math inline">\(\theta\)</span>, ad esempio:</p>
<ul>
<li>Distribuzione uniforme: <span class="math display">\[
p(\theta = 0.1) = p(\theta = 0.5) = p(\theta = 0.9) = \frac{1}{3}.
\]</span>
</li>
<li>Distribuzione non uniforme (ad esempio, dando più peso a <span class="math inline">\(\theta = 0.5\)</span>): <span class="math display">\[
p(\theta = 0.1) = \frac{1}{4}, \quad p(\theta = 0.5) = \frac{1}{2}, \quad p(\theta = 0.9) = \frac{1}{4}.
\]</span>
</li>
</ul>
</li>
<li>
<p><strong>Calcolare la probabilità di osservare 7 successi su 10 prove per ogni valore di <span class="math inline">\(\theta\)</span></strong>:</p>
<p><span class="math display">\[
p(k=7 \mid \theta) = \binom{10}{7} \theta^7 (1 - \theta)^3.
\]</span></p>
</li>
<li>
<p><strong>Moltiplicare ciascuna di queste probabilità per la corrispondente probabilità a priori e sommare i risultati</strong>:</p>
<p><span class="math display">\[
p(k=7 \mid n=10) = \sum_{i} p(k=7 \mid \theta_i) p(\theta_i).
\]</span></p>
</li>
</ol>
<p>Sostituendo i valori per la distribuzione uniforme:</p>
<p><span class="math display">\[
p(k=7 \mid n=10) = \binom{10}{7} 0.1^7 (0.9)^3 \cdot \frac{1}{3} +
\binom{10}{7} 0.5^7 (0.5)^3 \cdot \frac{1}{3} +
\binom{10}{7} 0.9^7 (0.1)^3 \cdot \frac{1}{3}.
\]</span></p>
<p>Questa somma rappresenta la <strong>verosimiglianza marginale</strong>, ossia la probabilità di ottenere 7 successi su 10, considerando tutte le possibili incertezze su <span class="math inline">\(\theta\)</span>.</p>
</section><section id="caso-con-parametri-continui" class="level3" data-number="42.7.2"><h3 data-number="42.7.2" class="anchored" data-anchor-id="caso-con-parametri-continui">
<span class="header-section-number">42.7.2</span> Caso con Parametri Continui</h3>
<p>Nella maggior parte delle situazioni, il parametro <span class="math inline">\(\theta\)</span> non assume solo pochi valori discreti, ma può variare <strong>continuamente</strong> in un intervallo (ad esempio, tra 0 e 1). In questo caso, invece di sommare, dobbiamo <strong>integrare</strong>:</p>
<p><span class="math display">\[
p(k=7 \mid n=10) = \int_{0}^{1} \binom{10}{7} \theta^7 (1 - \theta)^3 p(\theta) \, d\theta.
\]</span></p>
<p>Qui:</p>
<ul>
<li>
<span class="math inline">\(p(\theta)\)</span> è la <strong>distribuzione a priori</strong> di <span class="math inline">\(\theta\)</span>.</li>
<li>L’integrale rappresenta una media ponderata della probabilità di ottenere i dati, considerando tutti i valori di <span class="math inline">\(\theta\)</span>.</li>
</ul>
<p>Ad esempio, se <span class="math inline">\(\theta \sim \text{Beta}(2,2)\)</span>, la verosimiglianza marginale diventa:</p>
<p><span class="math display">\[
p(k=7 \mid n=10) = \int_{0}^{1} \binom{10}{7} \theta^7 (1 - \theta)^3 \frac{\theta (1-\theta)}{B(2,2)} \, d\theta.
\]</span></p>
<p>Questo tipo di calcolo viene spesso risolto numericamente.</p>
</section><section id="calcolo-numerico-della-verosimiglianza-marginale-in-r" class="level3" data-number="42.7.3"><h3 data-number="42.7.3" class="anchored" data-anchor-id="calcolo-numerico-della-verosimiglianza-marginale-in-r">
<span class="header-section-number">42.7.3</span> Calcolo Numerico della Verosimiglianza Marginale in R</h3>
<p>Se vogliamo calcolare la verosimiglianza marginale numericamente, possiamo usare l’integrazione numerica in R.</p>
<p><strong>Caso con Parametri Discreti.</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Definiamo i valori possibili di theta e le probabilità a priori</span></span>
<span><span class="va">theta_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">0.9</span><span class="op">)</span></span>
<span><span class="va">prior_probs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">3</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">3</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">3</span><span class="op">)</span>  <span class="co"># Distribuzione uniforme</span></span>
<span></span>
<span><span class="co"># Calcoliamo la verosimiglianza per ciascun valore di theta</span></span>
<span><span class="va">likelihoods</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">7</span>, size <span class="op">=</span> <span class="fl">10</span>, prob <span class="op">=</span> <span class="va">theta_vals</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calcoliamo la verosimiglianza marginale sommando i contributi ponderati</span></span>
<span><span class="va">marginal_likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">likelihoods</span> <span class="op">*</span> <span class="va">prior_probs</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">marginal_likelihood</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.0582</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Caso con Parametri Continui.</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Definiamo la funzione di verosimiglianza pesata dalla prior</span></span>
<span><span class="va">integrand</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">7</span>, size <span class="op">=</span> <span class="fl">10</span>, prob <span class="op">=</span> <span class="va">theta</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="va">theta</span>, shape1 <span class="op">=</span> <span class="fl">2</span>, shape2 <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Eseguiamo l'integrazione numerica</span></span>
<span><span class="va">marginal_likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span><span class="va">integrand</span>, lower <span class="op">=</span> <span class="fl">0</span>, upper <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">$</span><span class="va">value</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">marginal_likelihood</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.1119</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="interpretazione-della-verosimiglianza-marginale" class="level3" data-number="42.7.4"><h3 data-number="42.7.4" class="anchored" data-anchor-id="interpretazione-della-verosimiglianza-marginale">
<span class="header-section-number">42.7.4</span> Interpretazione della Verosimiglianza Marginale</h3>
<p>La <strong>verosimiglianza marginale</strong> rappresenta la probabilità complessiva dei dati, <strong>tenendo conto di tutte le possibili incertezze sul parametro <span class="math inline">\(\theta\)</span></strong>.</p>
<ul>
<li>Se la verosimiglianza marginale è <strong>alta</strong>, significa che il modello nel suo insieme è compatibile con i dati osservati.</li>
<li>Se la verosimiglianza marginale è <strong>bassa</strong>, significa che, indipendentemente dal valore di <span class="math inline">\(\theta\)</span>, il modello non spiega bene i dati.</li>
</ul>
<p>A differenza della verosimiglianza classica, che valuta quanto siano probabili i dati per un <strong>singolo valore</strong> di <span class="math inline">\(\theta\)</span>, la verosimiglianza marginale <strong>considera tutte le possibili ipotesi sul parametro</strong>.</p>
</section><section id="ruolo-nella-statistica-bayesiana" class="level3" data-number="42.7.5"><h3 data-number="42.7.5" class="anchored" data-anchor-id="ruolo-nella-statistica-bayesiana">
<span class="header-section-number">42.7.5</span> Ruolo nella Statistica Bayesiana</h3>
<p>La verosimiglianza marginale svolge un ruolo cruciale nell’inferenza bayesiana perché appare nella <strong>formula di Bayes</strong>:</p>
<p><span class="math display">\[
p(\theta \mid D) = \frac{p(D \mid \theta) p(\theta)}{p(D)},
\]</span></p>
<p>dove <span class="math inline">\(p(D)\)</span> è la <strong>verosimiglianza marginale</strong>. Questa quantità:</p>
<ol type="1">
<li><p><strong>serve da fattore di normalizzazione</strong> per la distribuzione a posteriori <span class="math inline">\(p(\theta \mid D)\)</span>;</p></li>
<li>
<p><strong>permette di confrontare modelli diversi</strong>, attraverso il <strong>fattore di Bayes</strong>:</p>
<p><span class="math display">\[
BF = \frac{p(D \mid M_1)}{p(D \mid M_2)},
\]</span></p>
<p>dove <span class="math inline">\(M_1\)</span> e <span class="math inline">\(M_2\)</span> sono due modelli diversi.</p>
</li>
</ol>
<p>In conclusione, la <strong>verosimiglianza marginale</strong> è un concetto chiave nell’inferenza bayesiana, che ci permette di valutare quanto un modello sia coerente con i dati, tenendo conto di tutte le possibili incertezze sui parametri:</p>
<ul>
<li>per parametri <strong>discreti</strong>, si calcola come una somma ponderata;</li>
<li>per parametri <strong>continui</strong>, si calcola con un <strong>integrale</strong>;</li>
<li>è essenziale per il calcolo della distribuzione <strong>a posteriori</strong> e per il <strong>confronto tra modelli</strong>.</li>
</ul></section></section><section id="verosimiglianza-gaussiana" class="level2" data-number="42.8"><h2 data-number="42.8" class="anchored" data-anchor-id="verosimiglianza-gaussiana">
<span class="header-section-number">42.8</span> Verosimiglianza Gaussiana</h2>
<p>La distribuzione gaussiana (o distribuzione normale) è una delle distribuzioni più utilizzate in statistica perché descrive molti fenomeni naturali e psicologici. In questo capitolo esploreremo come si calcola la verosimiglianza, ovvero la plausibilità dei parametri, nel caso della distribuzione normale.</p>
<section id="caso-di-una-singola-osservazione" class="level3" data-number="42.8.1"><h3 data-number="42.8.1" class="anchored" data-anchor-id="caso-di-una-singola-osservazione">
<span class="header-section-number">42.8.1</span> Caso di una Singola Osservazione</h3>
<p>Immaginiamo di misurare il Quoziente Intellettivo (QI) di una persona e ottenere un valore specifico, ad esempio 114. Assumiamo che il QI segua una distribuzione normale con media <span class="math inline">\(\mu\)</span> sconosciuta e deviazione standard <span class="math inline">\(\sigma\)</span> nota (ad esempio <span class="math inline">\(\sigma = 15\)</span>).</p>
<p>La <strong>funzione di densità di probabilità</strong> per una distribuzione normale è:</p>
<p><span class="math display">\[
f(y \mid \mu, \sigma) = \frac{1}{\sigma\sqrt{2\pi}} \exp\left(-\frac{(y-\mu)^2}{2\sigma^2}\right) ,
\]</span></p>
<p>dove:</p>
<ul>
<li>
<span class="math inline">\(y\)</span> è il valore osservato,</li>
<li>
<span class="math inline">\(\mu\)</span> è la media (il parametro che vogliamo stimare),</li>
<li>
<span class="math inline">\(\sigma\)</span> è la deviazione standard (conosciuta).</li>
</ul>
<p>La <strong>verosimiglianza</strong> misura quanto diversi valori di <span class="math inline">\(\mu\)</span> sono plausibili, dato il valore osservato (114).</p>
<p><strong>Esempio pratico in R:</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Dati iniziali</span></span>
<span><span class="va">y_obs</span> <span class="op">&lt;-</span> <span class="fl">114</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">15</span></span>
<span><span class="va">mu_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">70</span>, <span class="fl">160</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calcolo della verosimiglianza</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">y_obs</span>, mean <span class="op">=</span> <span class="va">mu_values</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Grafico della verosimiglianza</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>mu <span class="op">=</span> <span class="va">mu_values</span>, likelihood <span class="op">=</span> <span class="va">likelihood</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mu</span>, y <span class="op">=</span> <span class="va">likelihood</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>color <span class="op">=</span> <span class="va">okabe_ito_palette</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Verosimiglianza per un singolo valore di QI (114)"</span>,</span>
<span>    x <span class="op">=</span> <span class="st">"Media (μ)"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Verosimiglianza"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="15_likelihood_files/figure-html/unnamed-chunk-17-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="15_likelihood_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></a></p>
</figure>
</div>
</div>
</div>
<p><strong>Qual è il valore migliore per <span class="math inline">\(\mu\)</span>?</strong></p>
<p>Il valore migliore di <span class="math inline">\(\mu\)</span> sarà quello che rende massima la verosimiglianza. In questo semplice caso, è esattamente il valore osservato (114):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mu_ottimale</span> <span class="op">&lt;-</span> <span class="va">mu_values</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">likelihood</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Il valore ottimale di μ è:"</span>, <span class="va">mu_ottimale</span><span class="op">)</span></span>
<span><span class="co">#&gt; Il valore ottimale di μ è: 114</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="log-verosimiglianza" class="level3" data-number="42.8.2"><h3 data-number="42.8.2" class="anchored" data-anchor-id="log-verosimiglianza">
<span class="header-section-number">42.8.2</span> Log-Verosimiglianza</h3>
<p>Spesso, per semplicità di calcolo, si usa la <strong>log-verosimiglianza</strong>, che trasforma i prodotti in somme, rendendo i calcoli più semplici e stabili:</p>
<p><span class="math display">\[
\log L(\mu \mid y, \sigma) = -\frac{1}{2}\log(2\pi) - \log(\sigma) - \frac{(y-\mu)^2}{2\sigma^2}.
\]</span></p>
<p><strong>Calcolo pratico con R:</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Funzione di log-verosimiglianza negativa usando dnorm()</span></span>
<span><span class="va">negative_log_likelihood</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">mu</span>, <span class="va">y</span>, <span class="va">sigma</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Ritorniamo il valore negativo della log-verosimiglianza</span></span>
<span>  <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">y</span>, mean <span class="op">=</span> <span class="va">mu</span>, sd <span class="op">=</span> <span class="va">sigma</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/optim.html">optim</a></span><span class="op">(</span></span>
<span>  par <span class="op">=</span> <span class="fl">100</span>, <span class="co"># Valore iniziale</span></span>
<span>  fn <span class="op">=</span> <span class="va">negative_log_likelihood</span>,</span>
<span>  y <span class="op">=</span> <span class="va">y_obs</span>,</span>
<span>  sigma <span class="op">=</span> <span class="va">sigma</span>,</span>
<span>  method <span class="op">=</span> <span class="st">"L-BFGS-B"</span>,</span>
<span>  lower <span class="op">=</span> <span class="fl">70</span>,</span>
<span>  upper <span class="op">=</span> <span class="fl">160</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">mu_max_loglik</span> <span class="op">&lt;-</span> <span class="va">result</span><span class="op">$</span><span class="va">par</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Il valore ottimale di μ dalla log-verosimiglianza è:"</span>, <span class="va">mu_max_loglik</span><span class="op">)</span></span>
<span><span class="co">#&gt; Il valore ottimale di μ dalla log-verosimiglianza è: 114</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In questo caso, otteniamo nuovamente <span class="math inline">\(\mu = 114\)</span>.</p>
</section><section id="campione-di-osservazioni-indipendenti" class="level3" data-number="42.8.3"><h3 data-number="42.8.3" class="anchored" data-anchor-id="campione-di-osservazioni-indipendenti">
<span class="header-section-number">42.8.3</span> Campione di Osservazioni Indipendenti</h3>
<p>Supponiamo di aver raccolto i punteggi alla scala <strong>BDI-II</strong> per 30 persone. Ciascun punteggio è un’osservazione indipendente da una distribuzione normale con <strong>media incognita <span class="math inline">\(\mu\)</span></strong> e <strong>deviazione standard nota <span class="math inline">\(\sigma = 6.5\)</span></strong>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Dati osservati (punteggi BDI-II)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span></span>
<span>  <span class="fl">26</span>, <span class="fl">35</span>, <span class="fl">30</span>, <span class="fl">25</span>, <span class="fl">44</span>, <span class="fl">30</span>, <span class="fl">33</span>, <span class="fl">43</span>, <span class="fl">22</span>, <span class="fl">43</span>, <span class="fl">24</span>, <span class="fl">19</span>, <span class="fl">39</span>, <span class="fl">31</span>, <span class="fl">25</span>, </span>
<span>  <span class="fl">28</span>, <span class="fl">35</span>, <span class="fl">30</span>, <span class="fl">26</span>, <span class="fl">31</span>, <span class="fl">41</span>, <span class="fl">36</span>, <span class="fl">26</span>, <span class="fl">35</span>, <span class="fl">33</span>, <span class="fl">28</span>, <span class="fl">27</span>, <span class="fl">34</span>, <span class="fl">27</span>, <span class="fl">22</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">6.5</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="calcolo-della-log-verosimiglianza" class="level3" data-number="42.8.4"><h3 data-number="42.8.4" class="anchored" data-anchor-id="calcolo-della-log-verosimiglianza">
<span class="header-section-number">42.8.4</span> Calcolo della Log-Verosimiglianza</h3>
<p>Definiamo una funzione che calcola la <strong>log-verosimiglianza totale</strong>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">log_likelihood</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">mu</span>, <span class="va">y</span>, <span class="va">sigma</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">y</span>, mean <span class="op">=</span> <span class="va">mu</span>, sd <span class="op">=</span> <span class="va">sigma</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Esploriamo ora un intervallo di valori plausibili per <span class="math inline">\(\mu\)</span> e calcoliamo la log-verosimiglianza per ciascun valore:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Intervallo di valori possibili per μ</span></span>
<span><span class="va">mu_range</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">sigma</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">sigma</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Inizializza vettore dei risultati</span></span>
<span><span class="va">log_lik_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">mu_range</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Ciclo esplicito per chiarezza didattica</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_along</a></span><span class="op">(</span><span class="va">mu_range</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">mu_val</span> <span class="op">&lt;-</span> <span class="va">mu_range</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="va">log_lik_values</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">log_likelihood</span><span class="op">(</span><span class="va">mu_val</span>, <span class="va">y</span>, <span class="va">sigma</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="visualizzazione-della-log-verosimiglianza" class="level3" data-number="42.8.5"><h3 data-number="42.8.5" class="anchored" data-anchor-id="visualizzazione-della-log-verosimiglianza">
<span class="header-section-number">42.8.5</span> Visualizzazione della Log-Verosimiglianza</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">ggplot</span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>mu <span class="op">=</span> <span class="va">mu_range</span>, log_likelihood <span class="op">=</span> <span class="va">log_lik_values</span><span class="op">)</span>,</span>
<span>  <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mu</span>, y <span class="op">=</span> <span class="va">log_likelihood</span><span class="op">)</span></span>
<span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>color <span class="op">=</span> <span class="va">okabe_ito_palette</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Log-verosimiglianza per punteggi BDI-II"</span>,</span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Log-verosimiglianza"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="15_likelihood_files/figure-html/unnamed-chunk-23-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="15_likelihood_files/figure-html/unnamed-chunk-23-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></a></p>
</figure>
</div>
</div>
</div>
<p>La linea tratteggiata rossa indica la <strong>media campionaria</strong>, che — come ci aspettiamo — è anche il valore che <strong>massimizza la log-verosimiglianza</strong>.</p>
</section><section id="ottimizzazione-numerica" class="level3" data-number="42.8.6"><h3 data-number="42.8.6" class="anchored" data-anchor-id="ottimizzazione-numerica">
<span class="header-section-number">42.8.6</span> Ottimizzazione Numerica</h3>
<p>Se volessimo calcolare il valore ottimale di <span class="math inline">\(\mu\)</span> in modo automatico:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Funzione negativa da minimizzare</span></span>
<span><span class="va">negative_log_likelihood</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">mu</span>, <span class="va">y</span>, <span class="va">sigma</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">y</span>, mean <span class="op">=</span> <span class="va">mu</span>, sd <span class="op">=</span> <span class="va">sigma</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Ottimizzazione con limiti</span></span>
<span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/optim.html">optim</a></span><span class="op">(</span></span>
<span>  par <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>,                   <span class="co"># Valore iniziale</span></span>
<span>  fn <span class="op">=</span> <span class="va">negative_log_likelihood</span>,   <span class="co"># Funzione da minimizzare</span></span>
<span>  y <span class="op">=</span> <span class="va">y</span>,</span>
<span>  sigma <span class="op">=</span> <span class="va">sigma</span>,</span>
<span>  method <span class="op">=</span> <span class="st">"L-BFGS-B"</span>,</span>
<span>  lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">mu_range</span><span class="op">)</span>,</span>
<span>  upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">mu_range</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">mu_optimal</span> <span class="op">&lt;-</span> <span class="va">result</span><span class="op">$</span><span class="va">par</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Il valore ottimale di μ è:"</span>, <span class="va">mu_optimal</span><span class="op">)</span></span>
<span><span class="co">#&gt; Il valore ottimale di μ è: 30.93</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>Abbiamo utilizzato <code>dnorm(..., log = TRUE)</code> per calcolare in modo semplice e numericamente stabile la log-verosimiglianza.</li>
<li>Il valore di <span class="math inline">\(\mu\)</span> che <strong>massimizza la log-verosimiglianza</strong> corrisponde alla <strong>media campionaria</strong>.</li>
<li>Questo è un caso in cui <strong>la stima di massima verosimiglianza ha una forma chiusa</strong>, ma l’approccio numerico resta utile e generalizzabile.</li>
</ul></section></section><section id="il-rapporto-di-verosimiglianze" class="level2" data-number="42.9"><h2 data-number="42.9" class="anchored" data-anchor-id="il-rapporto-di-verosimiglianze">
<span class="header-section-number">42.9</span> Il rapporto di verosimiglianze</h2>
<p>Quando conduciamo un’analisi statistica, spesso ci troviamo di fronte alla necessità di <strong>confrontare due modelli</strong> che cercano di spiegare gli stessi dati. Immaginiamo, ad esempio, di voler capire qual è la <strong>media</strong> di una certa variabile (come il punteggio a un test, il tempo di reazione, ecc.). Potremmo avere <strong>due ipotesi</strong> alternative sull’effettivo valore della media:</p>
<ul>
<li>secondo un primo modello, la media è <span class="math inline">\(\mu_1\)</span> (ad esempio, l’ipotesi “nulla”, che rappresenta uno stato di riferimento o di assenza di effetto),</li>
<li>secondo un secondo modello, la media è <span class="math inline">\(\mu_2\)</span> (ad esempio, l’ipotesi “alternativa”, che rappresenta un cambiamento o un effetto).</li>
</ul>
<p>Per decidere <strong>quale modello è più compatibile con i dati osservati</strong>, possiamo usare la <strong>verosimiglianza</strong> (<em>likelihood</em>). La verosimiglianza misura <strong>quanto bene un certo valore del parametro spiega i dati osservati</strong>. Più la verosimiglianza è alta, più i dati sono “coerenti” con quel valore.</p>
<section id="il-confronto" class="level3" data-number="42.9.1"><h3 data-number="42.9.1" class="anchored" data-anchor-id="il-confronto">
<span class="header-section-number">42.9.1</span> Il confronto</h3>
<p>Per confrontare i due modelli, calcoliamo la verosimiglianza dei dati in ciascun caso, e ne facciamo il rapporto:</p>
<p><span id="eq-prob-lr-def"><span class="math display">\[
\lambda = \frac{L(\mu_2 \mid \text{dati})}{L(\mu_1 \mid \text{dati})}
\tag{42.1}\]</span></span></p>
<p>dove:</p>
<ul>
<li>
<span class="math inline">\(L(\mu_2 \mid \text{dati})\)</span> è la verosimiglianza del <strong>modello alternativo</strong> (cioè, quanto sono compatibili i dati con <span class="math inline">\(\mu_2\)</span>),</li>
<li>
<span class="math inline">\(L(\mu_1 \mid \text{dati})\)</span> è la verosimiglianza del <strong>modello nullo</strong> (cioè, quanto sono compatibili i dati con <span class="math inline">\(\mu_1\)</span>).</li>
</ul>
<p>Questa quantità si chiama <strong>rapporto di verosimiglianze</strong> (<em>likelihood ratio</em>, LR), e rappresenta uno strumento per quantificare quanto i dati favoriscono un modello rispetto all’altro.</p>
</section><section id="come-si-interpreta-lambda" class="level3" data-number="42.9.2"><h3 data-number="42.9.2" class="anchored" data-anchor-id="come-si-interpreta-lambda">
<span class="header-section-number">42.9.2</span> Come si interpreta <span class="math inline">\(\lambda\)</span>?</h3>
<ul>
<li>Se <span class="math inline">\(\lambda &gt; 1\)</span>, significa che i dati supportano <strong>più il modello alternativo</strong>: i dati sono più probabili sotto <span class="math inline">\(\mu_2\)</span> che sotto <span class="math inline">\(\mu_1\)</span>.</li>
<li>Se <span class="math inline">\(\lambda &lt; 1\)</span>, significa che i dati supportano <strong>più il modello nullo</strong>: i dati sono più probabili sotto <span class="math inline">\(\mu_1\)</span> che sotto <span class="math inline">\(\mu_2\)</span>.</li>
<li>Se <span class="math inline">\(\lambda \approx 1\)</span>, allora i dati non permettono di distinguere chiaramente tra i due modelli.</li>
</ul>
<p><em>Il rapporto di verosimiglianze ci dice quale modello rende i dati osservati più “plausibili”.</em></p>
</section><section id="un-esempio" class="level3" data-number="42.9.3"><h3 data-number="42.9.3" class="anchored" data-anchor-id="un-esempio">
<span class="header-section-number">42.9.3</span> Un Esempio</h3>
<p>Immagina di aver lanciato una moneta <strong>10 volte</strong> e di aver ottenuto <strong>7 teste</strong>. Ti chiedi ora quale tra questi due modelli spiega meglio i dati:</p>
<ul>
<li>
<strong>Modello 1 (nullo)</strong>: la moneta è equa, quindi la probabilità di testa è <span class="math inline">\(\mu_1 = 0.5\)</span>;</li>
<li>
<strong>Modello 2 (alternativo)</strong>: la moneta è truccata a favore delle teste, e la probabilità di testa è <span class="math inline">\(\mu_2 = 0.7\)</span>.</li>
</ul></section><section id="calcolo-delle-verosimiglianze" class="level3" data-number="42.9.4"><h3 data-number="42.9.4" class="anchored" data-anchor-id="calcolo-delle-verosimiglianze">
<span class="header-section-number">42.9.4</span> Calcolo delle verosimiglianze</h3>
<p>Useremo la <strong>distribuzione binomiale</strong>, che descrive il numero di successi (in questo caso, teste) in un numero fisso di prove (10 lanci), dato un certo valore di probabilità.</p>
<p>La verosimiglianza è semplicemente la <strong>probabilità di ottenere 7 teste su 10 lanci</strong>, sotto ciascun modello:</p>
<ul>
<li>
<p>sotto il <strong>modello nullo</strong> (<span class="math inline">\(\mu_1 = 0.5\)</span>):</p>
<p><span class="math display">\[
L(0.5 \mid \text{7 teste}) = \binom{10}{7} (0.5)^7 (1 - 0.5)^3 = 120 \cdot (0.5)^{10} \approx 0.117
\]</span></p>
</li>
<li>
<p>sotto il <strong>modello alternativo</strong> (<span class="math inline">\(\mu_2 = 0.7\)</span>):</p>
<p><span class="math display">\[
L(0.7 \mid \text{7 teste}) = \binom{10}{7} (0.7)^7 (0.3)^3 \approx 120 \cdot 0.0824 \cdot 0.027 = 0.267
\]</span></p>
</li>
</ul></section><section id="calcolo-del-rapporto-di-verosimiglianze" class="level3" data-number="42.9.5"><h3 data-number="42.9.5" class="anchored" data-anchor-id="calcolo-del-rapporto-di-verosimiglianze">
<span class="header-section-number">42.9.5</span> Calcolo del rapporto di verosimiglianze</h3>
<p>Ora possiamo calcolare il <strong>rapporto</strong>:</p>
<p><span class="math display">\[
\lambda = \frac{L(0.7 \mid \text{7 teste})}{L(0.5 \mid \text{7 teste})} \approx \frac{0.267}{0.117} \approx 2.28
\]</span></p>
<p>Questo significa che <strong>i dati sono circa 2.3 volte più compatibili con l’ipotesi che la moneta sia truccata</strong> (con <span class="math inline">\(\mu = 0.7\)</span>) rispetto a quella che sia equa (<span class="math inline">\(\mu = 0.5\)</span>).</p>
</section><section id="visualizzare-le-funzioni-di-verosimiglianza" class="level3" data-number="42.9.6"><h3 data-number="42.9.6" class="anchored" data-anchor-id="visualizzare-le-funzioni-di-verosimiglianza">
<span class="header-section-number">42.9.6</span> Visualizzare le funzioni di verosimiglianza</h3>
<p>Possiamo visualizzare graficamente come cambia la verosimiglianza al variare della probabilità di testa (<span class="math inline">\(\theta\)</span>), mantenendo fisso il numero di lanci e il numero di teste osservate.</p>
<section id="codice-r" class="level4" data-number="42.9.6.1"><h4 data-number="42.9.6.1" class="anchored" data-anchor-id="codice-r">
<span class="header-section-number">42.9.6.1</span> Codice R</h4>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Parametri osservati</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">10</span>        <span class="co"># numero totale di lanci</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fl">7</span>         <span class="co"># numero di teste osservate</span></span>
<span></span>
<span><span class="co"># Sequenza di probabilità (theta)</span></span>
<span><span class="va">theta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Verosimiglianza per ogni theta</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">x</span>, size <span class="op">=</span> <span class="va">n</span>, prob <span class="op">=</span> <span class="va">theta</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Crea dataframe per ggplot</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>theta <span class="op">=</span> <span class="va">theta</span>, likelihood <span class="op">=</span> <span class="va">likelihood</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Verosimiglianza nei due modelli</span></span>
<span><span class="va">L_0.5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">x</span>, size <span class="op">=</span> <span class="va">n</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">L_0.7</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">x</span>, size <span class="op">=</span> <span class="va">n</span>, prob <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span></span>
<span><span class="va">LR</span> <span class="op">&lt;-</span> <span class="va">L_0.7</span> <span class="op">/</span> <span class="va">L_0.5</span></span>
<span></span>
<span><span class="co"># Crea grafico</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">df</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span>, y <span class="op">=</span> <span class="va">likelihood</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>color <span class="op">=</span> <span class="va">okabe_ito_palette</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0.5</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0.7</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"darkgreen"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0.5</span>, y <span class="op">=</span> <span class="va">L_0.5</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span>, size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0.7</span>, y <span class="op">=</span> <span class="va">L_0.7</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"darkgreen"</span>, size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Funzione di verosimiglianza per 7 teste su 10 lanci"</span>,</span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Verosimiglianza"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span></span>
<span>    <span class="st">"text"</span>, x <span class="op">=</span> <span class="fl">0.5</span>, y <span class="op">=</span> <span class="va">L_0.5</span> <span class="op">+</span> <span class="fl">0.01</span>, </span>
<span>    label <span class="op">=</span> <span class="st">"mu == 0.5"</span>, </span>
<span>    parse <span class="op">=</span> <span class="cn">TRUE</span>, hjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.2</span>, color <span class="op">=</span> <span class="st">"red"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span></span>
<span>    <span class="st">"text"</span>, x <span class="op">=</span> <span class="fl">0.7</span>, y <span class="op">=</span> <span class="va">L_0.7</span> <span class="op">+</span> <span class="fl">0.01</span>, </span>
<span>    label <span class="op">=</span> <span class="st">"mu == 0.7"</span>, parse <span class="op">=</span> <span class="cn">TRUE</span>, hjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.2</span>, color <span class="op">=</span> <span class="st">"darkgreen"</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="15_likelihood_files/figure-html/unnamed-chunk-25-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="15_likelihood_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></a></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Stampa dei risultati numerici</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"L(mu = 0.5) ="</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">L_0.5</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; L(mu = 0.5) = 0.117</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"L(mu = 0.7) ="</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">L_0.7</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; L(mu = 0.7) = 0.267</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Likelihood Ratio ="</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">LR</span>, <span class="fl">2</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Likelihood Ratio = 2.28</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Il grafico mostra come cambia la verosimiglianza al variare di <span class="math inline">\(\theta\)</span>, e indica visivamente i valori assunti nei due modelli specifici. Si vede chiaramente che <span class="math inline">\(\theta = 0.7\)</span> è più compatibile con l’osservazione di 7 teste.</p>
<p><strong>In sintesi</strong>, il <strong>rapporto di verosimiglianze</strong> è uno strumento per confrontare due ipotesi. Non richiede che una delle due sia vera, ma solo di confrontare <strong>quanto bene ciascuna spiega i dati osservati</strong>. In questo esempio, i dati favoriscono l’ipotesi che la moneta sia truccata, ma non in modo schiacciante. Il valore di <span class="math inline">\(\lambda = 2.28\)</span> indica un’evidenza moderata a favore del modello alternativo.</p>
</section></section><section id="rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike" class="level3" data-number="42.9.7"><h3 data-number="42.9.7" class="anchored" data-anchor-id="rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike">
<span class="header-section-number">42.9.7</span> Rapporti di Verosimiglianza Aggiustati e Criterio di Akaike</h3>
<p>Spesso il rapporto di verosimiglianza “grezzo” (<span class="math inline">\(\lambda\)</span>) deve essere aggiustato per tenere conto della differenza nel numero di parametri tra i modelli confrontati. Infatti, quando confrontiamo due modelli, quello con più parametri tende quasi sempre a descrivere meglio i dati osservati, ma ciò può essere dovuto semplicemente alla sua maggiore complessità. Questo fenomeno è noto come <strong>sovradattamento (overfitting)</strong>.</p>
<p>Per correggere questa tendenza, si usa un <strong>rapporto di verosimiglianza aggiustato</strong> (Adjusted Likelihood Ratio, indicato con <span class="math inline">\(\lambda_{\text{adj}}\)</span>. Questo tipo di aggiustamento penalizza i modelli più complessi, rendendo il confronto tra modelli più equo e affidabile.</p>
</section><section id="relazione-con-il-criterio-di-akaike-aic" class="level3" data-number="42.9.8"><h3 data-number="42.9.8" class="anchored" data-anchor-id="relazione-con-il-criterio-di-akaike-aic">
<span class="header-section-number">42.9.8</span> Relazione con il Criterio di Akaike (AIC)</h3>
<p>Una modalità comune per effettuare questa correzione è tramite il <strong>Criterio di Akaike (AIC)</strong>. L’AIC è definito come:</p>
<p><span id="eq-aic-def"><span class="math display">\[
\text{AIC} = 2k - 2\log(\lambda),
\tag{42.2}\]</span></span></p>
<p>in cui:</p>
<ul>
<li>
<span class="math inline">\(k\)</span> è il numero dei parametri del modello.</li>
<li>
<span class="math inline">\(\lambda\)</span> è il rapporto di verosimiglianza grezzo.</li>
</ul>
<p>Da questa equazione possiamo ricavare una formula per calcolare il rapporto di verosimiglianza aggiustato utilizzando l’AIC:</p>
<p><span class="math display">\[
\lambda_{\text{adj}} = \lambda \times e^{(k_1 - k_2)},
\]</span></p>
<p>dove:</p>
<ul>
<li>
<span class="math inline">\(k_1\)</span> è il numero di parametri del modello più semplice,</li>
<li>
<span class="math inline">\(k_2\)</span> è il numero di parametri del modello più complesso,</li>
<li>
<span class="math inline">\(e^{(k_1 - k_2)}\)</span> è il fattore correttivo che penalizza il modello più complesso.</li>
</ul>
<p>In breve, più parametri ha un modello, maggiore sarà la penalizzazione applicata.</p>
</section><section id="rapporto-tra-likelihood-ratio-e-aic" class="level3" data-number="42.9.9"><h3 data-number="42.9.9" class="anchored" data-anchor-id="rapporto-tra-likelihood-ratio-e-aic">
<span class="header-section-number">42.9.9</span> Rapporto tra Likelihood Ratio e AIC</h3>
<p>Il rapporto di verosimiglianza aggiustato tramite l’AIC consente di confrontare in modo equo modelli con un numero differente di parametri. Senza questa correzione, rischieremmo di scegliere sempre modelli più complessi, indipendentemente dalla loro reale capacità esplicativa, con il rischio di sovrastimare la qualità della loro spiegazione.</p>
<p>Utilizzare il rapporto di verosimiglianza aggiustato, quindi, permette di scegliere il modello migliore considerando sia la capacità di adattarsi ai dati, sia la semplicità del modello stesso.</p>
</section><section id="illustrazione" class="level3" data-number="42.9.10"><h3 data-number="42.9.10" class="anchored" data-anchor-id="illustrazione">
<span class="header-section-number">42.9.10</span> Illustrazione</h3>
<p>Immaginiamo un semplice esperimento psicologico sulla <strong>memoria visiva</strong>. Vogliamo capire se <strong>mostrare immagini emotivamente intense</strong> aiuta le persone a ricordare meglio, rispetto a immagini <strong>neutre</strong>.</p>
<p>Abbiamo due gruppi di partecipanti:</p>
<ul>
<li>il <strong>gruppo neutro</strong> vede 30 immagini neutre e ne ricorda correttamente <strong>14</strong>;</li>
<li>il <strong>gruppo emozionale</strong> vede 30 immagini emotivamente intense e ne ricorda <strong>22</strong>.</li>
</ul></section><section id="obiettivo" class="level3" data-number="42.9.11"><h3 data-number="42.9.11" class="anchored" data-anchor-id="obiettivo">
<span class="header-section-number">42.9.11</span> Obiettivo</h3>
<p>Vogliamo confrontare due modelli alternativi:</p>
<ul>
<li>
<strong>modello nullo (H₀)</strong>: la probabilità di ricordare un’immagine è <strong>uguale</strong> nei due gruppi;</li>
<li>
<strong>modello alternativo (H₁)</strong>: la probabilità di ricordare <strong>è diversa</strong> nei due gruppi.</li>
</ul></section><section id="dati-osservati" class="level3" data-number="42.9.12"><h3 data-number="42.9.12" class="anchored" data-anchor-id="dati-osservati">
<span class="header-section-number">42.9.12</span> Dati osservati</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">successi_neutro</span> <span class="op">&lt;-</span> <span class="fl">14</span></span>
<span><span class="va">successi_emozione</span> <span class="op">&lt;-</span> <span class="fl">22</span></span>
<span><span class="va">prove</span> <span class="op">&lt;-</span> <span class="fl">30</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="calcolo-della-verosimiglianza" class="level3" data-number="42.9.13"><h3 data-number="42.9.13" class="anchored" data-anchor-id="calcolo-della-verosimiglianza">
<span class="header-section-number">42.9.13</span> 1. Calcolo della Verosimiglianza</h3>
<p><strong>Ipotesi nulla: probabilità comune.</strong></p>
<p>Se la probabilità è la stessa in entrambi i gruppi, possiamo stimarla combinando i successi totali:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p_null</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">successi_neutro</span> <span class="op">+</span> <span class="va">successi_emozione</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fl">2</span> <span class="op">*</span> <span class="va">prove</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Log-verosimiglianza sotto H₀.</strong></p>
<p>Sotto l’ipotesi nulla, i dati di entrambi i gruppi devono essere spiegati da <strong>una sola probabilità</strong>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ll_null</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">successi_neutro</span>, <span class="va">prove</span>, <span class="va">p_null</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span> </span>
<span>           <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">successi_emozione</span>, <span class="va">prove</span>, <span class="va">p_null</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Ipotesi alternativa: probabilità diversa per ogni gruppo.</strong></p>
<p>Stimiamo separatamente la probabilità di ricordare in ciascun gruppo:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p_neutro</span> <span class="op">&lt;-</span> <span class="va">successi_neutro</span> <span class="op">/</span> <span class="va">prove</span></span>
<span><span class="va">p_emozione</span> <span class="op">&lt;-</span> <span class="va">successi_emozione</span> <span class="op">/</span> <span class="va">prove</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Log-verosimiglianza sotto H₁.</strong></p>
<p>Ogni gruppo ha la propria verosimiglianza:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ll_alt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">successi_neutro</span>, <span class="va">prove</span>, <span class="va">p_neutro</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span> </span>
<span>          <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">successi_emozione</span>, <span class="va">prove</span>, <span class="va">p_emozione</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="confronto-tra-modelli" class="level3" data-number="42.9.14"><h3 data-number="42.9.14" class="anchored" data-anchor-id="confronto-tra-modelli">
<span class="header-section-number">42.9.14</span> 2. Confronto tra Modelli</h3>
<p><strong>Rapporto di verosimiglianza (non penalizzato).</strong></p>
<p>Calcoliamo il <strong>rapporto tra le due verosimiglianze</strong>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">ll_alt</span> <span class="op">-</span> <span class="va">ll_null</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Questo ci dice <strong>quanto meglio il modello alternativo spiega i dati rispetto al modello nullo</strong>.</p>
</section><section id="penalizzazione-per-la-complessità" class="level3" data-number="42.9.15"><h3 data-number="42.9.15" class="anchored" data-anchor-id="penalizzazione-per-la-complessità">
<span class="header-section-number">42.9.15</span> 3. Penalizzazione per la Complessità</h3>
<p>I modelli più complessi tendono a spiegare meglio i dati, ma rischiano di <strong>adattarsi troppo</strong>. Per questo, usiamo un criterio che penalizza la complessità: l’<strong>AIC</strong> (Akaike Information Criterion).</p>
<p>Numero di parametri:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">k_null</span> <span class="op">&lt;-</span> <span class="fl">1</span>  <span class="co"># un'unica probabilità per entrambi i gruppi</span></span>
<span><span class="va">k_alt</span> <span class="op">&lt;-</span> <span class="fl">2</span>   <span class="co"># probabilità distinte per ciascun gruppo</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calcolo dell’AIC per ciascun modello:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">AIC_null</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">k_null</span> <span class="op">-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">ll_null</span></span>
<span><span class="va">AIC_alt</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">k_alt</span> <span class="op">-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">ll_alt</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Rapporto di verosimiglianza aggiustato.</strong></p>
<p>Usiamo l’AIC per calcolare una versione <strong>penalizzata</strong> del rapporto di verosimiglianze:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lr_adj</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">(</span><span class="va">AIC_null</span> <span class="op">-</span> <span class="va">AIC_alt</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Risultati:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Rapporto di verosimiglianza grezzo:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">lr</span>, <span class="fl">2</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Rapporto di verosimiglianza grezzo: 9.54</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Rapporto di verosimiglianza aggiustato (λ_adj):"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">lr_adj</span>, <span class="fl">2</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Rapporto di verosimiglianza aggiustato (λ_adj): 3.51</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Interpretazione:</strong></p>
<ul>
<li>se <strong>λ_adj &gt; 1</strong>, i dati sono più compatibili con il <strong>modello alternativo</strong> (due probabilità distinte);</li>
<li>se <strong>λ_adj ≈ 1</strong>, non c’è abbastanza evidenza per preferire un modello all’altro.</li>
</ul></section><section id="test-del-rapporto-di-verosimiglianza" class="level3" data-number="42.9.16"><h3 data-number="42.9.16" class="anchored" data-anchor-id="test-del-rapporto-di-verosimiglianza">
<span class="header-section-number">42.9.16</span> 4. Test del Rapporto di Verosimiglianza</h3>
<p>Possiamo testare formalmente <strong>se la differenza tra i modelli è rilevante</strong> o potrebbe essere dovuta al caso.</p>
<p>La statistica test è:</p>
<p><span class="math display">\[
-2 \cdot (\log L_{H_0} - \log L_{H_1})
\]</span></p>
<p>Questa statistica segue (approssimativamente) una <strong>distribuzione chi-quadrato</strong> con un numero di gradi di libertà pari alla <strong>differenza nel numero di parametri</strong> tra i modelli:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">LR_test</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">2</span> <span class="op">*</span> <span class="op">(</span><span class="va">ll_null</span> <span class="op">-</span> <span class="va">ll_alt</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="va">k_alt</span> <span class="op">-</span> <span class="va">k_null</span></span>
<span><span class="va">p_value</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq</a></span><span class="op">(</span><span class="va">LR_test</span>, <span class="va">df</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Statistica test (-2 log LR):"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">LR_test</span>, <span class="fl">2</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Statistica test (-2 log LR): 4.51</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Gradi di libertà:"</span>, <span class="va">df</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Gradi di libertà: 1</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Valore p del test:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">p_value</span>, <span class="fl">4</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Valore p del test: 0.0337</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>In sintesi</strong>,</p>
<ul>
<li>se <strong>p &lt; 0.05</strong>, possiamo concludere che il <strong>modello alternativo è da preferire</strong>: i dati sono difficilmente compatibili con l’ipotesi di probabilità uguali nei due gruppi;</li>
<li>se <strong>p &gt; 0.05</strong>, non abbiamo evidenza sufficiente per preferire il modello alternativo.</li>
</ul>
<p>Nel nostro esempio:</p>
<ul>
<li>la statistica test è ≈ 4.48;</li>
<li>il <strong>valore-p</strong> è ≈ 0.0337.</li>
</ul>
<p>👉 Poiché il valore-p è inferiore a 0.05, possiamo concludere che <strong>il gruppo emozionale ha una probabilità di ricordare credibilmente diversa da quella del gruppo neutro</strong>.</p>
</section></section><section id="riflessioni-conclusive" class="level2" data-number="42.10"><h2 data-number="42.10" class="anchored" data-anchor-id="riflessioni-conclusive">
<span class="header-section-number">42.10</span> Riflessioni Conclusive</h2>
<p>La funzione di verosimiglianza costituisce il fulcro dell’inferenza statistica, permettendo di quantificare la plausibilità dei parametri di un modello alla luce dei dati osservati. La sua costruzione poggia su tre elementi fondamentali: la scelta del modello generatore dei dati, lo spazio dei parametri e le evidenze empiriche.</p>
<p>Nel caso di modelli binomiali e gaussiani, la verosimiglianza assume forme analiticamente maneggevoli, facilitando sia la stima puntuale che la valutazione di ipotesi. In particolare:<br>
- <strong>Per la distribuzione normale</strong>, la stima di massima verosimiglianza di () coincide con la media campionaria, mentre la sua rappresentazione grafica offre una chiara indicazione della precisione della stima.<br>
- <strong>L’uso della log-verosimiglianza</strong> non solo semplifica i calcoli, ma migliora anche la stabilità numerica, specialmente in contesti con campioni di grandi dimensioni.<br>
- <strong>Il rapporto di verosimiglianza</strong> emerge come strumento versatile, capace di coniugare bontà di adattamento e parsimonia, come dimostrato da criteri quali l’AIC.</p>
<p>Questi strumenti non sono meri artifici tecnici, ma rappresentano un linguaggio comune per confrontare modelli e interpretare risultati in modo rigoroso. La loro corretta applicazione richiede tuttavia una comprensione approfondita delle assunzioni sottostanti, affinché le conclusioni tratte riflettano fedelmente la realtà dei dati.</p>
<p>In definitiva, la verosimiglianza – nelle sue diverse forme – rimane una guida indispensabile per navigare il complesso rapporto tra teoria e osservazione, offrendo un equilibrio tra flessibilità metodologica e robustezza inferenziale.</p>
</section><section id="esercizi" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="esercizi">Esercizi</h2>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="Problemi">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Problemi
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Spiega ciascuno dei concetti seguenti con una frase:</p>
<ul>
<li>probabilità.</li>
<li>funzione di massa di probabilità.</li>
<li>funzione di densità di probabilità.</li>
<li>distribuzione di probabilità.</li>
<li>distribuzione di probabilità discreta.</li>
<li>distribuzione di probabilità continua.</li>
<li>funzione di distribuzione cumulativa (cdf).</li>
<li>verosimiglianza</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="Problemi">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Problemi
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Supponi di aver misurato il livello di ansia (ad esempio usando una scala standardizzata) in un campione di 15 persone con i seguenti punteggi:</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ansia</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">23</span>, <span class="fl">27</span>, <span class="fl">30</span>, <span class="fl">29</span>, <span class="fl">25</span>, <span class="fl">28</span>, <span class="fl">26</span>, <span class="fl">24</span>, <span class="fl">31</span>, <span class="fl">29</span>, <span class="fl">27</span>, <span class="fl">26</span>, <span class="fl">28</span>, <span class="fl">30</span>, <span class="fl">25</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Assumendo che la deviazione standard sia nota e pari a 3.5, svolgi le seguenti attività in R:</p>
<ol type="1">
<li>Calcola la funzione di verosimiglianza gaussiana per diversi valori di <span class="math inline">\(\mu\)</span> nell’intervallo da 20 a 35.</li>
<li>Trova numericamente il valore di <span class="math inline">\(\mu\)</span> che rende massima la verosimiglianza (stima di massima verosimiglianza, MLE).</li>
<li>Disegna un grafico della funzione di verosimiglianza per visualizzare il risultato.</li>
</ol>
</div>
</div>
</div>
</section><section id="informazioni-sullambiente-di-sviluppo" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html">sessionInfo</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; R version 4.5.0 (2025-04-11)</span></span>
<span><span class="co">#&gt; Platform: aarch64-apple-darwin20</span></span>
<span><span class="co">#&gt; Running under: macOS Sequoia 15.5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Matrix products: default</span></span>
<span><span class="co">#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib </span></span>
<span><span class="co">#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; locale:</span></span>
<span><span class="co">#&gt; [1] C/UTF-8/C/C/C/C</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; time zone: Europe/Rome</span></span>
<span><span class="co">#&gt; tzcode source: internal</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attached base packages:</span></span>
<span><span class="co">#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; other attached packages:</span></span>
<span><span class="co">#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      </span></span>
<span><span class="co">#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     </span></span>
<span><span class="co">#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 </span></span>
<span><span class="co">#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     </span></span>
<span><span class="co">#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   </span></span>
<span><span class="co">#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; loaded via a namespace (and not attached):</span></span>
<span><span class="co">#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    </span></span>
<span><span class="co">#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    </span></span>
<span><span class="co">#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  </span></span>
<span><span class="co">#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   </span></span>
<span><span class="co">#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         </span></span>
<span><span class="co">#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       </span></span>
<span><span class="co">#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      </span></span>
<span><span class="co">#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   </span></span>
<span><span class="co">#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     </span></span>
<span><span class="co">#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         </span></span>
<span><span class="co">#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      </span></span>
<span><span class="co">#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    </span></span>
<span><span class="co">#&gt; [37] rmarkdown_2.29     compiler_4.5.0</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="bibliografia" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="bibliografia">Bibliografia</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-Johnson2022bayesrules" class="csl-entry" role="listitem">
Johnson, A. A., Ott, M., &amp; Dogucu, M. (2022). <em><span>Bayes Rules! An Introduction to Bayesian Modeling with R</span></em>. CRC Press.
</div>
<div id="ref-schervish2014probability" class="csl-entry" role="listitem">
Schervish, M. J., &amp; DeGroot, M. H. (2014). <em>Probability and statistics</em> (Vol. 563). Pearson Education London, UK:
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiato!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiato!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/psicometria-r\/intro\.html");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../chapters/probability/14_gauss.html" class="pagination-link" aria-label="Assunzione di gaussianità e trasformazioni dei dati">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Assunzione di gaussianità e trasformazioni dei dati</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/bayesian_inference/introduction_bayes_inference.html" class="pagination-link" aria-label="Introduzione">
        <span class="nav-page-text">Introduzione</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p><strong>Psicometria</strong> è una risorsa didattica creata per il corso di Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ccaudek/psicometria-r/blob/main/chapters/probability/15_likelihood.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/psicometria-r/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Realizzato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer><script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>


</body></html>