[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psicometria",
    "section": "",
    "text": "Informazioni generali",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "index.html#informazioni-generali",
    "href": "index.html#informazioni-generali",
    "title": "Psicometria",
    "section": "",
    "text": "Anno Accademico: 2024–2025\n\nCodice Insegnamento: B000286 (coorte L–Z)",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "index.html#percorso-di-apprendimento",
    "href": "index.html#percorso-di-apprendimento",
    "title": "Psicometria",
    "section": "Percorso di apprendimento",
    "text": "Percorso di apprendimento\nIl corso è strutturato in un flusso di lavoro progressivo che integra teoria e pratica:\n\nFondamenti — Misurazione in psicologia, tipi di dati, disegno della ricerca.\nAnalisi Esplorativa (EDA) — Pulizia, visualizzazione e descrizione dei dati per formulare ipotesi.\nProbabilità e Inferenza Bayesiana — Il linguaggio dell’incertezza: variabili casuali, distribuzioni, e il teorema di Bayes come fondamento dell’apprendimento dai dati.\nModellazione Statistica — Un percorso che dalla regressione lineare (frequenstista e bayesiana) si estende ai Modelli Lineari Generalizzati (regressione logistica e di Poisson) e culmina nell’introduzione dei Modelli Dinamici, per la descrizione e la previsione di fenomeni psicologici.\nWorkflow Bayesiano — Un approccio completo: dalla specificazione del modello all’inferenza a posteriori con MCMC, fino alla verifica e alla critica.\nConfronto e Validazione Predittiva — Valutare quale modello generalizza meglio su nuovi dati usando strumenti all’avanguardia come LOO-CV e ELPD.\n\nOgni capitolo è corredato di esempi completi e riproducibili in \\(\\mathsf{R}\\), con codice commentato e visualizzazioni.",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "index.html#come-usare-questi-appunti",
    "href": "index.html#come-usare-questi-appunti",
    "title": "Psicometria",
    "section": "Come usare questi appunti",
    "text": "Come usare questi appunti\n\nStudia in modo attivo: Non limitarti a leggere. Copia, esegui e, soprattutto, modifica il codice per sperimentare direttamente l’effetto dei tuoi cambiamenti.\nSegui il flusso: Le sezioni sono pensate in sequenza per costruire competenze solide. Evita salti: le scorciatoie fanno perdere il quadro concettuale che rende interpretabili i risultati.\nInterpreta, non memorizzare: Il tuo obiettivo è capire la sostanza psicologica dei fenomeni, non memorizzare output. Applica questo principio a ogni fase, dall’EDA al confronto tra modelli. Quando confronti i modelli, chiediti perché differiscono: quali assunzioni cambiano? Quali meccanismi psicologici sono resi espliciti nei parametri? Comunica sempre l’incertezza e privilegia semplicità ed interpretabilità rispetto a piccoli guadagni predittivi poco robusti.",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "index.html#strumenti-e-prerequisiti",
    "href": "index.html#strumenti-e-prerequisiti",
    "title": "Psicometria",
    "section": "Strumenti e prerequisiti",
    "text": "Strumenti e prerequisiti\nPer lavorare efficacemente con questo materiale, è necessario configurare il proprio ambiente di lavoro:\n\nSoftware: \\(\\mathsf{R}\\) (versione 4.5 o superiore) e RStudio (consigliato) o un altro IDE (es. VS Code).\nEcosistema Stan (cruciale): Per la modellazione bayesiana efficiente, installeremo CmdStan tramite il pacchetto cmdstanr. → Guida all’installazione di Stan\nPacchetti \\(\\mathsf{R}\\) principali: tidyverse (manipolazione e visualizzazione dei dati), brms (modellazione), cmdstanr (backend per Stan), loo (confronto di modelli).\nQuarto: Per generare report riproducibili.\nPrerequisiti concettuali: È sufficiente una conoscenza di base dell’algebra e della statistica descrittiva. I concetti di probabilità necessari saranno richiamati e approfonditi nel corso.",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "index.html#licenza-duso",
    "href": "index.html#licenza-duso",
    "title": "Psicometria",
    "section": "Licenza d’uso",
    "text": "Licenza d’uso\nMateriali rilasciati con licenza CC BY 4.0.\nÈ consentito qualsiasi utilizzo previa attribuzione.",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "prefazione.html",
    "href": "prefazione.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nL’analisi dei dati rappresenta un insieme di pratiche fondamentali per estrarre significato, scoprire insight e guidare il processo decisionale sulla base delle evidenze. Ma come possiamo rendere l’analisi dei dati psicologici più affidabile e rigorosa? È sufficiente applicare algoritmi standard o seguire procedure predefinite? Oppure, ridurre l’analisi a un semplice insieme di “ricette” statistiche rischia di impoverire la nostra comprensione dei fenomeni psicologici (McElreath, 2020)?\nQueste domande ci invitano a riflettere sulla natura stessa della ricerca empirica in psicologia. Contrariamente a quanto suggerito dall’approccio frequentista del null hypothesis testing, l’analisi dei dati non è un processo meccanico e automatico. Considerarla tale contribuisce a uno dei problemi più urgenti della psicologia contemporanea: la crisi della replicabilità (Korbmacher et al., 2023).\nLa replicabilità costituisce un criterio epistemologico fondamentale nella ricerca psicologica, in quanto garantisce la validità delle inferenze scientifiche e la generalizzabilità dei risultati. L’incapacità di replicare i risultati empirici mina la robustezza delle teorie psicologiche, compromettendone la validità costruttiva ed esterna. Tale instabilità metodologica ha implicazioni sostanziali anche a livello applicativo: interventi clinici basati su evidenze non replicabili possono condurre a conclusioni erronee, mentre politiche educative e strategie organizzative fondate su risultati fragili rischiano di produrre effetti nulli o controproducenti (Funder et al., 2014; Ioannidis, 2019; Shrout & Rodgers, 2018; Tackett et al., 2019).\nIl paradigma frequentista può aver contribuito alla crisi della replicabilità attraverso la sua dipendenza da p-value soglia-dipendenti e la tendenza a favorire risultati statisticamente significativi ma potenzialmente spurii. Parallelamente, gli incentivi accademici—quali la pressione alla pubblicazione e la preferenza per risultati innovativi—hanno sistematicamente incentivato pratiche di ricerca discutibili, tra cui il p-hacking e la selezione selettiva di risultati. Per contrastare queste criticità, è necessario adottare framework analitici alternativi che garantiscano maggiore trasparenza e robustezza metodologica.\nL’inferenza bayesiana rappresenta un approccio promettente, poiché consente una quantificazione diretta della probabilità delle ipotesi e una gestione più flessibile dell’incertezza (Gelman et al., 2013). Tuttavia, la sua adozione richiede più della mera sostituzione dei metodi frequentisti: implica l’integrazione di tecniche avanzate—come la modellazione gerarchica bayesiana e l’identificazione di relazioni causali—con una rigorosa caratterizzazione dei processi generativi dei dati e delle assunzioni teoriche sottostanti (Oberauer & Lewandowsky, 2019; Wagenmakers et al., 2018; Yarkoni, 2022).\nIn questo testo, analizzeremo sistematicamente le limitazioni degli approcci tradizionali, esamineremo i fattori strutturali alla base della crisi di replicabilità e valuteremo l’efficacia di metodologie alternative nel migliorare l’affidabilità della ricerca psicologica. L’obiettivo è fornire un framework metodologico integrato, che combini rigore statistico, trasparenza analitica e coerenza teorica, orientando gli studenti verso pratiche di ricerca empiricamente e concettualmente più solide.",
    "crumbs": [
      "Introduzione"
    ]
  },
  {
    "objectID": "prefazione.html#bibliografia",
    "href": "prefazione.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Funder, D. C., Levine, J. M., Mackie, D. M., Morf, C. C., Sansone, C., Vazire, S., & West, S. G. (2014). Improving the dependability of research in personality and social psychology: Recommendations for research and educational practice. Personality and Social Psychology Review, 18(1), 3–12.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nIoannidis, J. P. (2019). What have we (not) learnt from millions of scientific papers with P values? The American Statistician, 73(sup1), 20–25.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nShrout, P. E., & Rodgers, J. L. (2018). Psychology, science, and knowledge construction: Broadening perspectives from the replication crisis. Annual Review of Psychology, 69(1), 487–510.\n\n\nTackett, J. L., Brandes, C. M., King, K. M., & Markon, K. E. (2019). Psychology’s replication crisis and clinical psychological science. Annual Review of Clinical Psychology, 15(1), 579–604.\n\n\nWagenmakers, E.-J., Marsman, M., Jamil, T., Ly, A., Verhagen, J., Love, J., Selker, R., Gronau, Q. F., Šmı́ra, M., Epskamp, S., et al. (2018). Bayesian inference for psychology. Part I: Theoretical advantages and practical ramifications. Psychonomic Bulletin & Review, 25, 35–57.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/key_notions/introduction_key_notions.html",
    "href": "chapters/key_notions/introduction_key_notions.html",
    "title": "Fondamenti",
    "section": "",
    "text": "La data science è un campo che si sviluppa all’intersezione tra la statistica e l’informatica. La statistica fornisce una serie di metodologie per analizzare i dati e ottenere informazioni significative, mentre l’informatica si occupa dello sviluppo di software e strumenti per implementare tali metodologie. In questa sezione della dispensa, approfondiremo alcuni concetti fondamentali della statistica e della misurazione psicologica. Considereremo anche in termini generali quali sono gli obiettivi e i limiti dell’analisi dei dati psicologici.",
    "crumbs": [
      "Fondamenti"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html",
    "href": "chapters/key_notions/01_data_analysis.html",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "",
    "text": "Introduzione\nN egli ultimi vent’anni, la psicologia ha attraversato una trasformazione metodologica profonda, innescata da una crescente consapevolezza dei propri limiti empirici. Questa trasformazione prende il nome di crisi di replicazione (Baker, 2016; Bishop, 2019). Numerosi tentativi sistematici di replicare effetti pubblicati in studi classici hanno rivelato un tasso sorprendentemente alto di fallimenti. In molti casi, i risultati non solo non si replicano con la stessa ampiezza, ma talvolta non emergono affatto. Questa situazione ha costretto l’intera disciplina a interrogarsi sulla solidità delle proprie basi empiriche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#introduzione",
    "href": "chapters/key_notions/01_data_analysis.html#introduzione",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "",
    "text": "Panoramica del capitolo\n\nDistinguere replicazione, riproducibilità, robustezza e generalizzabilità (criteri diversi, complementari).\nCause principali: bassa potenza, flessibilità analitica (forking paths), HARKing, bias di pubblicazione, scarsa affidabilità.\nRiforme: preregistrazione/Registered Reports, open data & code, versionamento (Git/GitHub), report riproducibili (Quarto).\nSvolta bayesiana: prior + prior predictive, MCMC, posterior predictive checks, LOO/ELPD, analisi di sensibilità; modelli gerarchici.\nChecklist pratica: progetto adeguato, misure affidabili, evitare dichotomie p&lt;.05, riportare effetti con incertezza e soglie di rilevanza pratica.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Statistical Rethinking (McElreath, 2020). Focalizzati sui primi capitoli dove si discute della dicotomia tra “small world” e “big world”.\nLeggere What has happened down here is the winds have changed (Gelman 2016). Un post sul blog di Andrew Gelman che fornisce una panoramica sulla crisi di replicazione e su come le scienze sociali sono cambiate di conseguenza.\nLeggere Productive Explanation: A Framework for Evaluating Explanations in Psychological Science. L’adozione di teorie formali è essenziale per affrontare la crisi di riproducibilità dei risultati nella ricerca psicologica.\nPer chi fosse interessato a un romanzo su questi temi, sorprendentemente avvincente, consiglio Quando abbiamo smesso di capire il mondo di Benjamín Labatut (Labatut, 2021).\n\n\n\n\n\n\n1.0.1 Che cos’è la replicazione\nReplicare un risultato non significa semplicemente ottenere un nuovo p-value inferiore a .05. Significa ripetere un esperimento in condizioni il più possibile simili all’originale e ottenere una stima dell’effetto compatibile con quella iniziale, in termini sia di direzione che di grandezza. La replicabilità è uno dei pilastri fondamentali della scienza empirica: se un risultato rappresenta un fenomeno reale e generalizzabile, dovrebbe emergere anche in campioni indipendenti.\n\n\n1.0.2 I numeri della crisi\nLa portata della crisi è stata messa in evidenza dall’Collaboration (2015), che ha tentato di replicare 100 studi pubblicati su riviste leader nel settore. Solo il 36% delle repliche ha prodotto risultati “significativi” nello stesso senso degli studi originali. Questo valore non va inteso come una misura bayesiana di probabilità, ma come un indicatore allarmante di quanto i risultati pubblicati siano sensibili alle condizioni sperimentali, ai campioni, e alle analisi.\nL’evidenza si è accumulata con studi successivi: Camerer et al. (2018) hanno mostrato una riproducibilità deludente anche in economia comportamentale, mentre Klein et al. (2014) hanno riportato effetti inconsistenti in psicologia sociale. In molti casi, i risultati originali si sono dimostrati fragili, condizionali, o il prodotto di scelte analitiche arbitrarie.\n\n\n1.0.3 Il fallimento della replicazione è un sintomo\nPiù che una patologia in sé, il fallimento della replicazione è un sintomo di un problema più ampio: un’adozione acritica e routinaria del paradigma frequentista, in particolare del Null Hypothesis Significance Testing (NHST). Questo approccio, se non applicato con estrema cautela, incentiva strategie di analisi discutibili. La dipendenza da soglie fisse come p &lt; .05, la flessibilità nel trattamento dei dati, e la pratica di adattare le ipotesi a posteriori (HARKing), contribuiscono ad amplificare l’illusione della scoperta anche in assenza di effetti reali.\nLa statistica frequentista tradizionale, centrata sul concetto di errore di I e II specie, può indurre a interpretazioni errate e a una eccessiva enfasi su esiti binari (significativo/non significativo). Questa mentalità ha contribuito alla diffusione di falsi positivi, alla scarsa trasparenza nelle analisi, e a una generale crisi di credibilità nella letteratura psicologica (Ioannidis, 2005; Meehl, 1967).\n\n\n1.0.4 Conseguenze scientifiche e sociali\nIl risultato è un panorama in cui non è più chiaro quali risultati siano attendibili. Gli effetti di questa incertezza non sono solo accademici: si riflettono nella perdita di fiducia da parte del pubblico, nello spreco di risorse su linee di ricerca inconsistenti, e in una generale difficoltà a costruire teorie cumulative. Tuttavia, questa crisi ha innescato una risposta positiva, nota come Credibility Revolution (Angrist & Pischke, 2010), che mira a riformare alla radice le pratiche di ricerca, ponendo l’accento su rigore metodologico, trasparenza, e apertura.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#una-via-duscita-la-rivoluzione-bayesiana",
    "href": "chapters/key_notions/01_data_analysis.html#una-via-duscita-la-rivoluzione-bayesiana",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "1.1 Una via d’uscita: la rivoluzione bayesiana",
    "text": "1.1 Una via d’uscita: la rivoluzione bayesiana\nIn questo contesto, l’approccio bayesiano si è imposto come una delle risposte più promettenti. La statistica bayesiana si fonda sull’idea che la conoscenza scientifica non sia binaria (vero/falso), ma debba essere espressa in termini di gradi di credenza che evolvono nel tempo. L’inferenza diventa allora un processo di aggiornamento della conoscenza, in cui le distribuzioni di probabilità posteriori riflettono quanto siamo sicuri di una determinata ipotesi, alla luce dei dati e delle nostre conoscenze pregresse.\nA differenza dell’approccio NHST, che produce una decisione dicotomica, l’inferenza bayesiana restituisce un’intera distribuzione di credibilità sull’effetto. Questo consente di rispondere a domande più naturali e utili per la pratica scientifica, come ad esempio: “quanto è probabile che l’effetto superi una soglia di rilevanza pratica?”, oppure: “quanto si restringe la mia incertezza sull’effetto rispetto alla conoscenza pregressa?”",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#il-problema-dei-piccoli-campioni-e-leterogeneità",
    "href": "chapters/key_notions/01_data_analysis.html#il-problema-dei-piccoli-campioni-e-leterogeneità",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "1.2 Il problema dei piccoli campioni e l’eterogeneità",
    "text": "1.2 Il problema dei piccoli campioni e l’eterogeneità\nUno dei limiti strutturali della ricerca psicologica riguarda la frequente presenza di campioni piccoli e popolazioni eterogenee. A causa della natura dei fenomeni studiati (ad esempio, patologie rare o condizioni sperimentali complesse), molti studi operano in condizioni di informazione limitata e con forte variabilità interindividuale. Questo porta a stime instabili, a bassa potenza statistica, e a risultati difficilmente replicabili.\nL’approccio bayesiano è particolarmente adatto a questi contesti. Permette di:\n\nintegrare conoscenze pregresse (priors) per aumentare la stabilità delle stime;\nmodellare esplicitamente l’incertezza e l’eterogeneità tra soggetti o studi;\nvalutare la robustezza dei risultati rispetto a diverse ipotesi a priori.\n\nIn altre parole, la statistica bayesiana rende possibile un’inferenza più solida in condizioni dove i metodi frequentisti si rivelano fragili, soprattutto nei casi in cui la variabilità è alta e i dati sono scarsi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#verso-una-scienza-cumulativa-e-trasparente",
    "href": "chapters/key_notions/01_data_analysis.html#verso-una-scienza-cumulativa-e-trasparente",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "1.3 Verso una scienza cumulativa e trasparente",
    "text": "1.3 Verso una scienza cumulativa e trasparente\nLa crisi di replicazione ha accelerato la transizione verso pratiche di ricerca più aperte, riproducibili e cumulative. In questo nuovo paradigma, l’approccio bayesiano si integra perfettamente con la Data Science e gli strumenti di Open Science: version control con GitHub, documentazione con Quarto, condivisione di dati e codice, preregistrazione delle ipotesi e confronto tra modelli. Questi strumenti, sempre più adottati, non sono semplici tecnicalità, ma elementi strutturali di un nuovo modello di scienza psicologica.\nInoltre, si sta assistendo a un rinnovato interesse per la modellazione formale, in cui le ipotesi teoriche vengono esplicitate attraverso modelli matematici interpretabili. La statistica bayesiana è il linguaggio naturale di questi modelli, poiché permette di confrontare teorie alternative, incorporare incertezza parametrica, e testare la coerenza predittiva in modo diretto.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#riflessioni-conclusive",
    "href": "chapters/key_notions/01_data_analysis.html#riflessioni-conclusive",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa crisi di replicazione ha messo a nudo i limiti di un certo modo di fare scienza: eccessiva fiducia nei risultati significativi, scarsa attenzione all’incertezza, e una concezione rigida dell’inferenza. Il paradigma bayesiano, affiancato da pratiche di ricerca aperta e strumenti di data science, offre un’alternativa concreta e operativa. Questo libro si propone come guida introduttiva a questo approccio, con l’obiettivo di formare ricercatori capaci di pensare in termini di variabilità, incertezza e aggiornamento continuo della conoscenza.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQuali sono i principali fattori che hanno portato alla “Credibility Revolution” in psicologia e in che modo le nuove metodologie — in particolare l’approccio bayesiano e le buone pratiche di Data Science — mirano a superare i limiti che hanno contribuito alla “Replication Crisis”?\nIn che modo il paradigma bayesiano differisce dall’approccio frequentista nella gestione dell’incertezza e nell’aggiornamento della conoscenza, e quali vantaggi pratici offre quando si lavora con campioni di piccole dimensioni e popolazioni eterogenee?\nQual è il ruolo delle distribuzioni a priori nelle analisi bayesiane e come ci si assicura che l’uso di priors non introduca bias indesiderati, specialmente in un contesto come quello psicologico dove le teorie e i dati pregressi possono essere incompleti o controversi?\nPerché la modellazione formale e le buone pratiche di Data Science (ad es. condivisione di codice, controllo di versione, pipeline riproducibili) risultano fondamentali per una scienza cumulativa e per mitigare gli errori sistematici nella ricerca psicologica?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sono i principali fattori che hanno portato alla “Credibility Revolution” in psicologia e in che modo le nuove metodologie — in particolare l’approccio bayesiano e le buone pratiche di Data Science — mirano a superare i limiti che hanno contribuito alla “Replication Crisis”?\nNegli ultimi decenni, la psicologia ha attraversato una “Replication Crisis” a causa di diverse pratiche di ricerca problematiche, tra cui l’utilizzo di campioni di piccole dimensioni, l’uso eccessivo di test di significatività frequentisti con p &lt; .05 come soglia rigida, il fenomeno del p-hacking (cioè l’adattamento delle analisi per ottenere risultati “significativi”), e la carenza di trasparenza e condivisione dei dati. Questi fattori hanno portato alla pubblicazione di molti falsi positivi e a un’erosione della fiducia nelle conclusioni psicologiche.\nLa “Credibility Revolution” nasce dalla presa di coscienza di questi problemi e dall’introduzione di nuove metodologie che offrono maggior rigore e trasparenza. L’approccio bayesiano, in particolare, consente di superare alcuni limiti della statistica frequentista, poiché fornisce distribuzioni posteriori di plausibilità per i parametri e non si affida a soglie arbitrarie di significatività. Inoltre, la Data Science ha promosso la diffusione di pipeline analitiche riproducibili (tramite il controllo di versione, la condivisione del codice e dei dati), contribuendo a ridurre errori, bias e a favorire la replicabilità. Insieme, queste innovazioni mirano a creare una scienza più aperta, solida e cumulativa.\n2. In che modo il paradigma bayesiano differisce dall’approccio frequentista nella gestione dell’incertezza e nell’aggiornamento della conoscenza, e quali vantaggi pratici offre quando si lavora con campioni di piccole dimensioni e popolazioni eterogenee?\nIl paradigma frequentista si basa sull’idea di ripetizione ipotetica degli esperimenti e sull’applicazione di test di significatività, focalizzandosi su p-value e intervalli di confidenza che rispondono a domande “se si ripetesse infinite volte l’esperimento, in media cosa accadrebbe?”. L’inferenza bayesiana, al contrario, concepisce la probabilità come uno stato di conoscenza (o di credenza) e integra le informazioni precedenti (priors) con i dati osservati per produrre una distribuzione posteriore. Ciò consente un aggiornamento continuo e iterativo delle ipotesi alla luce delle nuove evidenze.\nQuesta impostazione risulta particolarmente utile quando i campioni sono ridotti e le popolazioni indagate sono eterogenee. In tali condizioni, il paradigma frequentista rischia di generare stime instabili o intervalli di confidenza molto ampi. L’approccio bayesiano, invece, permette di incorporare informazioni pregresse e di ottenere stime più precise, a patto che le priors siano giustificate e non eccessivamente informative. L’attenzione alla distribuzione posteriore rende inoltre più chiaro il grado di incertezza associato ai parametri di interesse e favorisce la formulazione di inferenze più calibrate.\n3. Qual è il ruolo delle distribuzioni a priori nelle analisi bayesiane e come ci si assicura che l’uso di priors non introduca bias indesiderati, specialmente in un contesto come quello psicologico dove le teorie e i dati pregressi possono essere incompleti o controversi?\nNell’approccio bayesiano, le distribuzioni a priori (priors) rappresentano la conoscenza o le ipotesi iniziali di cui si dispone sui parametri in esame prima di raccogliere i dati. Se ben specificate, contribuiscono a rendere l’analisi più informativa, soprattutto quando il campione è di piccole dimensioni. Tuttavia, un uso improprio delle priors può introdurre bias, poiché priors troppo “forti” (ossia eccessivamente vincolanti) possono spingere i risultati verso determinate conclusioni.\nPer evitare questi rischi, i ricercatori devono adottare priors ben motivate e trasparenti. In psicologia, dove le teorie possono essere ancora in fase di sviluppo e i dati pregressi non sempre affidabili, è spesso utile iniziare con priors non informative o debolmente informative, per ridurre il rischio di forzare troppo il modello. È anche fondamentale effettuare analisi di sensibilità: testare differenti specificazioni di priors per verificare se i risultati sono robusti oppure fortemente dipendenti da particolari assunzioni iniziali. La documentazione delle scelte fatte (e le relative ragioni) è parte integrante di una buona pratica di ricerca trasparente.\n4. Perché la modellazione formale e le buone pratiche di Data Science (ad es. condivisione di codice, controllo di versione, pipeline riproducibili) risultano fondamentali per una scienza cumulativa e per mitigare gli errori sistematici nella ricerca psicologica?\nLa modellazione formale consente di superare la mera descrizione delle relazioni tra variabili (tipica dell’ANOVA o dei modelli lineari tradizionali) e di entrare nel merito dei meccanismi sottostanti i fenomeni psicologici, costruendo teorie più articolate e fondate. Questa prospettiva rende più esplicite le assunzioni e le ipotesi su cui si basa la ricerca, permettendo un confronto chiaro tra diverse spiegazioni concorrenti.\nParallelamente, l’adozione di strumenti e pratiche di Data Science come la condivisione di codice (in repository pubblici), l’uso del controllo di versione (es. Git) e pipeline analitiche riproducibili riducono gli errori e favoriscono la verifica indipendente dei risultati. Ciò aumenta la trasparenza, poiché altri ricercatori possono ispezionare i passaggi compiuti, e consente la replicazione degli studi. In una scienza cumulativa, infatti, la possibilità di riprodurre, criticare e migliorare i risultati di lavori precedenti è essenziale per costruire un corpus di conoscenze solido e affidabile.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#bibliografia",
    "href": "chapters/key_notions/01_data_analysis.html#bibliografia",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAngrist, J. D., & Pischke, J.-S. (2010). The credibility revolution in empirical economics: How better research design is taking the con out of econometrics. Journal of economic perspectives, 24(2), 3–30.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBishop, D. (2019). The psychology of experimental psychologists: Overcoming cognitive constraints to improve research.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nLabatut, B. (2021). Quando abbiamo smesso di capire il mondo. Adelphi Edizioni spa.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMeehl, P. E. (1967). Theory-testing in psychology and physics: A methodological paradox. Philosophy of science, 34(2), 103–115.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html",
    "href": "chapters/key_notions/02_key_notions.html",
    "title": "2  Concetti chiave",
    "section": "",
    "text": "Introduzione\nN ella ricerca scientifica, la formulazione di risposte a specifiche domande di indagine avviene attraverso l’applicazione di metodologie rigorose e l’esecuzione di osservazioni accurate e controllate. Le informazioni raccolte mediante diverse tecniche di indagine—come ricerche sul campo, indagini campionarie e protocolli sperimentali—vengono definite con il termine tecnico di dati. Questo capitolo introduce i principi fondamentali dell’analisi dei dati, concentrandosi sia sulle caratteristiche dei dati stessi sia sui metodi di raccolta.\nL’analisi dei dati permette di sintetizzare grandi quantità di informazioni e di verificare le previsioni avanzate dalle teorie. Tuttavia, senza una teoria che dia significato ai dati, le osservazioni rimangono mere descrizioni prive di un contesto esplicativo. È attraverso l’integrazione tra dati e teoria che si raggiunge una comprensione profonda dei fenomeni e si favorisce l’avanzamento scientifico [es., Wertheimer (1880–1943), scoperta del movimento-\\(\\phi\\) e nascita del movimento della Gestalt; Steinman et al. (2000)].",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#introduzione",
    "href": "chapters/key_notions/02_key_notions.html#introduzione",
    "title": "2  Concetti chiave",
    "section": "",
    "text": "Statistica\n\n\n\n\n\nIl termine “statistica” può assumere diversi significati a seconda del contesto:\n\nPrimo significato: La statistica è una scienza che si occupa dello studio e dell’applicazione di metodi per la raccolta, organizzazione, analisi, interpretazione e presentazione dei dati.\nSecondo significato: Il termine si riferisce a una misura o valore numerico calcolato a partire da un campione di dati, come la media campionaria, la deviazione standard campionaria o il coefficiente di correlazione campionario.\n\n\n\n\n\n\nPanoramica del capitolo\n\nDefinizione di popolazione e campione.\nDistinzione tra variabili indipendenti e dipendenti.\nLa struttura e l’importanza della matrice dei dati.\nL’effetto delle variabili all’interno delle analisi statistiche.\nI concetti fondamentali di stima e inferenza.\nIl significato e l’applicazione dei modelli psicologici.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Horoscopes. L’ultimo capitolo di McElreath (2020) discute il contesto scientifico e culturale della statistica.\nLeggere The Effect: An Introduction to Research Design and Causality. Focalizzati sul capitolo 10 Treatment Effects.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#la-spiegazione-scientifica",
    "href": "chapters/key_notions/02_key_notions.html#la-spiegazione-scientifica",
    "title": "2  Concetti chiave",
    "section": "2.1 La spiegazione scientifica",
    "text": "2.1 La spiegazione scientifica\nLa scienza non si limita a descrivere o prevedere i fenomeni: il suo obiettivo principale è spiegare il perché degli eventi, offrendo una comprensione approfondita delle cause e dei meccanismi che li regolano. La spiegazione scientifica è cruciale per costruire teorie capaci non solo di descrivere e prevedere, ma anche di chiarire le dinamiche causali e le connessioni tra i fenomeni, contribuendo a un controllo più consapevole e informato su di essi.\nConsideriamo, ad esempio, il rapporto tra il background familiare e il rendimento scolastico. Numerose ricerche evidenziano una forte correlazione tra il livello di istruzione dei genitori e il successo accademico dei figli. Una prospettiva puramente descrittiva potrebbe limitarsi a constatare che: “Gli studenti provenienti da famiglie con basso livello di istruzione hanno minori probabilità di conseguire un titolo universitario”. Tuttavia, la vera sfida scientifica consiste nell’andare oltre questa previsione, ponendosi domande più profonde:\n\nquali meccanismi causali determinano questa disparità?\n\nquali interventi possono efficacemente ridurre tali disuguaglianze?\n\nPer superare il livello di semplice previsione, la ricerca deve identificare i fattori causali alla base del fenomeno, in modo da comprendere come l’azione su questi fattori possa modificare gli esiti. Nel caso dell’esempio sul rapporto tra background familiare e rendimento scolastico, ciò implica comprendere, ad esempio:\n\nse e in che modo il sostegno finanziario possa favorire il percorso degli studenti svantaggiati;\nquali politiche educative possano produrre effetti positivi sul lungo termine;\ncome i meccanismi sociali e individuali influenzino il processo educativo.\n\nAcquisire una conoscenza approfondita dei meccanismi causali permette di andare oltre la semplice previsione, rendendo possibile la progettazione di interventi mirati e strategici che possano realmente incidere sui fenomeni in modo efficace e duraturo.\n\n2.1.1 Elementi fondamentali della spiegazione scientifica\nLa filosofia della scienza identifica tre componenti fondamentali di una spiegazione scientifica:\n\nExplanandum. È il fenomeno che desideriamo comprendere, ovvero ciò di cui cerchiamo le cause o i meccanismi. Un esempio: “Gli studenti con alti livelli di ansia da prestazione ottengono punteggi più bassi nei test scolastici rispetto ai loro pari.”\nExplanans. È l’insieme dei fattori che spiegano il fenomeno. Nel caso dell’ansia da prestazione, un possibile explanans potrebbe essere: “L’ansia danneggia la concentrazione e la memoria di lavoro, influendo negativamente sulla performance nei test.”\nLegame esplicativo. Comprende i principi o i meccanismi che dimostrano come l’explanans produca l’explanandum. Seguendo l’esempio precedente: “Livelli elevati di ansia innescano il sistema nervoso simpatico, aumentando lo stress fisiologico e riducendo l’efficienza dei processi cognitivi necessari per compiti complessi.”\n\nQuesti tre elementi si combinano all’interno di modelli scientifici, che costituiscono le strutture teoriche e metodologiche impiegate per formulare e verificare spiegazioni. In psicologia, tali modelli includono:\n\nil fenomeno da spiegare (ad es. le prestazioni scolastiche);\ni fattori che lo influenzano (ad es. ansia, regolazione emotiva);\ni meccanismi sottostanti che collegano cause ed effetti (ad es. attivazione fisiologica, memoria di lavoro compromessa).\n\nUn modello psicologico sull’ansia da prestazione, ad esempio, potrebbe considerare la relazione tra livello di ansia percepita, capacità di regolazione emotiva e memoria di lavoro. A differenza di modelli esclusivamente descrittivi o predittivi, i modelli esplicativi rispondono a domande causali: non si limitano ad attestare che ansia e prestazioni sono correlate, ma mostrano come e perché l’ansia riduca il rendimento. Inoltre, tali modelli suggeriscono strategie d’intervento per attenuare l’effetto dell’ansia, come il potenziamento della regolazione emotiva o l’uso di tecniche di gestione dello stress.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#modelli-psicologici",
    "href": "chapters/key_notions/02_key_notions.html#modelli-psicologici",
    "title": "2  Concetti chiave",
    "section": "2.2 Modelli psicologici",
    "text": "2.2 Modelli psicologici\nUn modello è una rappresentazione concettuale – spesso supportata da formalismi matematici – di un fenomeno reale, basata su un insieme di equazioni e ipotesi che descrivono le relazioni tra variabili e la struttura probabilistica sottostante. L’obiettivo è coglierne gli aspetti essenziali senza includere ogni dettaglio superfluo, formulando predizioni quantitative che possano essere verificate empiricamente. Poiché spesso esistono molteplici modelli in grado di spiegare lo stesso fenomeno, il compito della ricerca consiste nel selezionare quello che meglio descrive i dati e soddisfa criteri di validità, accuratezza e parsimonia.\nI modelli psicologici, in particolare, sono strumenti teorici finalizzati a descrivere, spiegare e prevedere il comportamento umano e i processi mentali. Un modello ben costruito dovrebbe possedere le seguenti caratteristiche:\n\nCoerenza descrittiva. Il modello deve fornire una rappresentazione logica e coerente del fenomeno, includendo tutti gli elementi chiave del processo psicologico e organizzando le osservazioni in una struttura interpretativa chiara.\nCapacità predittiva. Deve essere in grado di formulare previsioni verificabili e di produrre ipotesi testabili sulla base dei dati raccolti, permettendo così di valutare la validità del modello.\nSupporto empirico. Le previsioni e le ipotesi del modello vanno confrontate con l’evidenza empirica, ottenuta attraverso ricerche sistematiche e rigorose. I dati devono corroborare le relazioni proposte dal modello.\nFalsificabilità. Il modello deve poter essere sottoposto a verifica empirica e, all’occorrenza, smentito. Se emergono osservazioni in conflitto con le sue previsioni, il modello deve essere revisionato o sostituito.\nParsimonia. La spiegazione deve risultare semplice e lineare, includendo solo gli elementi indispensabili per rendere conto del fenomeno. Assunzioni superflue o ridondanti ne riducono la robustezza.\nGeneralizzabilità. Il modello dovrebbe poter essere esteso a contesti e situazioni diverse, superando i limiti di specifiche condizioni sperimentali o campioni ristretti.\nUtilità pratica. Dovrebbe offrire linee guida concrete per l’applicazione nel mondo reale, ad esempio negli interventi clinici, nei programmi di prevenzione o nelle terapie, così da avere un impatto positivo sugli individui e sulla società.\n\nUno degli ostacoli maggiori nella costruzione di modelli in psicologia è la natura soggettiva, dinamica e variabile dell’esperienza umana. È quindi necessario bilanciare la precisione teorica (spesso supportata da formalizzazioni matematiche o computazionali) con la flessibilità necessaria a catturare l’eterogeneità dei fenomeni psicologici. A questo si aggiungono i vincoli etici della ricerca sull’essere umano e le potenziali ricadute sociali dei risultati.\nL’analisi quantitativa dei dati gioca un ruolo centrale nella validazione dei modelli psicologici: mediante metodologie statistiche e computazionali avanzate, i ricercatori possono verificare se le predizioni di un modello trovano riscontro nei dati empirici e se tali predizioni si mantengono valide in contesti diversi. Questo processo non solo consolida la comprensione del fenomeno, ma consente anche di anticipare e, in alcune circostanze, influenzare il comportamento e i processi mentali. Un modello rigorosamente formulato e testabile diviene quindi un potente strumento per lo sviluppo di interventi efficaci e il progresso teorico.\n\n2.2.1 Rappresentare i fenomeni per ragionare e comunicare\nLa spiegazione scientifica non si limita a far luce sui meccanismi causali, ma fornisce anche un linguaggio formale per analizzare e condividere conoscenze sui fenomeni. In psicologia, i modelli scientifici costituiscono strumenti fondamentali per descrivere i processi attraverso variabili, funzioni e parametri, offrendo una struttura che facilita l’individuazione di relazioni e proprietà essenziali. Un modello efficace semplifica la complessità del fenomeno, agevolando sia la comunicazione tra studiosi sia la comprensione intuitiva.\nInoltre, i modelli non si limitano a organizzare le informazioni esistenti: stimolano anche l’emergere di nuove ipotesi di ricerca, promuovono collegamenti tra concetti apparentemente lontani e consentono di trasferire conoscenze tra discipline, ampliando così l’orizzonte dell’indagine scientifica.\n\n\n2.2.2 Il ruolo dell’analisi dei dati\nL’analisi dei dati è parte integrante del metodo scientifico e, in psicologia, assolve due funzioni primarie:\n\nSemplificare e sintetizzare informazioni complesse\nAttraverso statistiche descrittive, rappresentazioni grafiche e altre tecniche di sintesi, l’analisi dei dati aiuta a individuare schemi, tendenze e anomalie. Questo passaggio è essenziale per comprendere le differenze tra individui o gruppi e per formulare ipotesi di ricerca più mirate.\nValutare le predizioni dei modelli\nConfrontando i dati raccolti con le previsioni teoriche, si misura la validità di un modello. Tale confronto è indispensabile per confermare, raffinare o rivedere le ipotesi di partenza, orientando così il progresso della conoscenza scientifica.\n\nTuttavia, limitarsi alla ricerca di correlazioni o di pattern nei dati, senza un solido quadro teorico, non basta a comprendere pienamente il fenomeno. Risultati empirici privi di spiegazioni causali rimangono frammentari. Per questo motivo, integrare i dati in un modello teorico esplicativo è cruciale: si possono così proporre meccanismi causali, identificare relazioni e avanzare nuove ipotesi di ricerca.\n\n\n2.2.3 Carattere multidisciplinare dell’analisi dei dati\nPer rispondere alle complesse domande poste in psicologia, l’analisi dei dati si fonda sull’integrazione di più discipline: statistica, teoria della probabilità e informatica. Ciascuna offre contributi indispensabili per affrontare la complessità dei processi psicologici:\n\nStatistica\nFornisce tecniche per la raccolta, l’organizzazione e l’interpretazione dei dati, consentendo di riassumere le informazioni, individuare pattern significativi e valutare empiricamente le ipotesi dei modelli psicologici.\nTeoria della probabilità\nCostituisce la base matematica della statistica e della modellazione scientifica, offrendo strumenti per quantificare l’incertezza, descrivere la variabilità delle osservazioni e costruire modelli predittivi rigorosi.\nInformatica\nContribuisce con strumenti per la gestione, l’analisi e la visualizzazione di grandi quantità di dati, nonché per l’implementazione di modelli computazionali sofisticati. Questi modelli si rivelano fondamentali nel simulare e testare dinamiche dei processi psicologici.\n\nLa natura multidisciplinare dell’analisi dei dati rispecchia l’esigenza di competenze diverse per comprendere e modellizzare i fenomeni psicologici in modo rigoroso. L’approccio quantitativo e computazionale ai modelli non si limita a descrivere e interpretare i dati, ma consente di formulare predizioni precise e sottoponibili a verifica, contribuendo così all’avanzamento della psicologia come scienza.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "href": "chapters/key_notions/02_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "title": "2  Concetti chiave",
    "section": "2.3 Concetti chiave nell’analisi dei dati",
    "text": "2.3 Concetti chiave nell’analisi dei dati\nPer condurre un’analisi dei dati efficace, è fondamentale comprendere alcuni concetti chiave che guidano il processo di indagine, dall’identificazione del fenomeno alla formulazione di inferenze.\n\n2.3.1 Popolazioni e campioni\nL’analisi dei dati inizia con l’identificazione della popolazione di interesse, che rappresenta l’insieme completo degli individui o delle entità coinvolte nel fenomeno studiato. Poiché studiare un’intera popolazione è spesso impraticabile, si ricorre ai campioni, sottoinsiemi rappresentativi della popolazione. La qualità e la rappresentatività del campione sono cruciali: un campione non rappresentativo può portare a conclusioni errate, limitando la generalizzabilità dei risultati.\n\n\n\n\n\n\nParametri e statistiche\n\n\n\n\n\nUn parametro è una caratteristica numerica della popolazione (es. media \\(\\mu\\), deviazione standard \\(\\sigma\\)). Una statistica è una caratteristica numerica calcolata sul campione (es. media campionaria \\(\\bar{x}\\), deviazione standard campionaria \\(s\\)). L’inferenza statistica si occupa di stimare i parametri della popolazione a partire dalle statistiche campionarie.\n\n\n\n\n\n2.3.2 Bias nella raccolta dei dati\nI bias nella raccolta e interpretazione dei dati possono compromettere l’accuratezza dei risultati. Comprendere chi ha raccolto i dati, come e con quali scopi è essenziale per una corretta interpretazione (Johnson et al., 2022). I dati non sono mai completamente neutri; i metodi e gli obiettivi di raccolta influenzano i risultati. Ad esempio, selezionare partecipanti da una popolazione di studenti universitari potrebbe introdurre un bias sistematico, limitando la generalizzabilità ad altri contesti (Murray & Carr, 2024; Nobles, 2000).\n\n\n2.3.3 Variabili e costanti\nNell’analisi statistica, le variabili rappresentano le caratteristiche osservate che possono assumere diversi valori (numerici o categorici). Le costanti, al contrario, rimangono fisse in un determinato contesto. Le variabili si distinguono in:\n\nvariabili indipendenti (o predittive): influenzano altri fenomeni;\n\nvariabili dipendenti: rappresentano gli esiti di interesse influenzati dalle variabili indipendenti.\n\nAd esempio, in uno studio sugli effetti della terapia cognitivo-comportamentale, la variabile indipendente potrebbe essere la partecipazione alla terapia, mentre la variabile dipendente sarebbe la riduzione dei sintomi di ansia.\n\n\n2.3.4 Studi osservazionali ed esperimenti\nEsistono due principali metodi di raccolta dati.\n\nEsperimenti: I ricercatori manipolano una o più variabili per valutare il loro effetto su altre variabili, controllando per i fattori confondenti. Ad esempio, per valutare l’efficacia di un trattamento, i partecipanti possono essere assegnati casualmente a un gruppo di controllo (placebo) e a un gruppo sperimentale (trattamento attivo). La randomizzazione riduce il rischio di bias sistematici.\nStudi osservazionali: I dati vengono raccolti senza interferire con il fenomeno osservato. Ad esempio, un’indagine su come lo stress influenza la produttività lavorativa potrebbe basarsi su questionari senza manipolare lo stress dei partecipanti. Questi studi forniscono correlazioni tra variabili, ma non dimostrano relazioni causali.\n\n\n\n2.3.5 Effetti\nIn statistica, un effetto rappresenta il cambiamento osservato nella variabile dipendente in relazione a una variabile indipendente. Questo cambiamento può indicare un’associazione tra le due variabili, ma la sua interpretazione come relazione causale dipende strettamente dal disegno sperimentale con cui i dati sono stati raccolti.\nAd esempio, se si osserva una riduzione dei sintomi tra la fase pre-trattamento e quella post-trattamento in un gruppo di pazienti sottoposti a una terapia, è possibile identificare un effetto della terapia. Tuttavia, senza un disegno sperimentale adeguato – come un esperimento controllato randomizzato (RCT) – non è possibile stabilire con certezza che la riduzione dei sintomi sia causata dalla terapia e non da altri fattori, come il decorso naturale della malattia o l’effetto placebo (Huntington-Klein, 2021).\nI modelli statistici, da soli, non possono determinare relazioni causali: possono quantificare l’entità di un effetto e valutare la forza dell’associazione tra variabili, ma la causalità può essere inferita solo se i dati provengono da un disegno sperimentale che isola il meccanismo di interesse, controllando per possibili fattori di confondimento. Pertanto, per trarre conclusioni causali robuste, è essenziale integrare l’analisi statistica con un approccio metodologico rigoroso basato su strategie di manipolazione sperimentale, assegnazione casuale o tecniche avanzate per il controllo dei bias nei dati osservazionali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#stima-e-inferenza-statistica-dal-campione-alla-popolazione",
    "href": "chapters/key_notions/02_key_notions.html#stima-e-inferenza-statistica-dal-campione-alla-popolazione",
    "title": "2  Concetti chiave",
    "section": "2.4 Stima e inferenza statistica: dal campione alla popolazione",
    "text": "2.4 Stima e inferenza statistica: dal campione alla popolazione\nLa stima e l’inferenza statistica costituiscono i pilastri della metodologia quantitativa, poiché permettono di estendere le conclusioni tratte da un campione – una porzione limitata di individui osservati – all’intera popolazione di interesse. L’uso dei campioni risulta indispensabile a causa dei vincoli di tempo, costi e risorse, che spesso rendono impossibile lo studio dell’intera popolazione.\nTuttavia, il ricorso al campione introduce inevitabilmente un’incertezza intrinseca: le statistiche campionarie (come media o varianza del campione) sono stime dei parametri della popolazione e di norma non coincidono esattamente con i valori “veri” della popolazione. Tale discrepanza è nota come errore di campionamento, la cui entità dipende, tra l’altro, dalla dimensione del campione e dalla strategia di campionamento adottata.\nLa teoria degli stimatori e gli strumenti di inferenza statistica (ad esempio, intervalli di confidenza in un approccio frequentista o intervalli di credibilità in un approccio bayesiano) consentono di quantificare e gestire quest’incertezza, fornendo un quadro che permette di trarre conclusioni credibili sulla popolazione partendo dai dati raccolti.\n\n2.4.1 Stima: inferire le caratteristiche della popolazione\nLa stima è il processo con cui, a partire dai dati di un campione, si inferiscono proprietà della popolazione, come la media o la varianza. Poiché ogni campione rappresenta solo una frazione della popolazione, può fornire stime diverse; questo fenomeno è noto come variabilità campionaria. Proprio tale variabilità costituisce la principale fonte di incertezza nelle inferenze: se un singolo campione non è sufficientemente ampio o rappresentativo, la stima potrebbe discostarsi in misura rilevante dai valori effettivi presenti nella popolazione.\n\n2.4.1.1 Fattori che influenzano l’accuratezza\nTre fattori fondamentali influiscono sull’accuratezza di una stima:\n\nDimensione del campione. Un campione più grande tende a ridurre la variabilità campionaria, aumentando la precisione delle stime.\nRappresentatività. Un campione ben progettato e rappresentativo rispecchia le caratteristiche essenziali della popolazione. Al contrario, un campione distorto (ad esempio, selezionato per convenienza) può condurre a stime fuorvianti.\nVariabilità della popolazione. Se la popolazione è estremamente eterogenea, sono necessari campioni più ampi per produrre stime affidabili.\n\n\n\n2.4.1.2 Gli stimatori: proprietà fondamentali\nGli stimatori sono formule matematiche o procedure statistiche usate per calcolare le stime. La loro qualità si valuta principalmente in base a:\n\nConsistenza. Uno stimatore è consistente se, all’aumentare della dimensione del campione, la stima tende a convergere verso il valore reale del parametro.\nNon distorsione (unbiasedness). Uno stimatore è non distorto se il suo valore atteso corrisponde al parametro della popolazione. In altri termini, in media, lo stimatore coincide con il valore reale.\nEfficienza. Tra stimatori non distorti, è più efficiente quello con varianza minore, poiché fornisce stime più stabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#inferenza-statistica",
    "href": "chapters/key_notions/02_key_notions.html#inferenza-statistica",
    "title": "2  Concetti chiave",
    "section": "2.5 Inferenza statistica",
    "text": "2.5 Inferenza statistica\nL’inferenza statistica si basa sulle stime campionarie per trarre conclusioni sull’intera popolazione. In particolare, risponde a tre grandi interrogativi:\n\nStima dei parametri della popolazione. Ottenere valori plausibili per parametri quali media, varianza e proporzioni, quantificando contestualmente l’incertezza (ad esempio, costruendo intervalli di confidenza o di credibilità).\nValutazione di ipotesi. Confrontare ipotesi rivali, come l’esistenza di differenze tra gruppi o di relazioni tra variabili. Attraverso il confronto tra ipotesi e dati, si determina quale ipotesi è meglio supportata.\nPrevisione. Utilizzare i dati esistenti per anticipare risultati futuri, tenendo conto delle fonti di incertezza legate sia alla variabilità intrinseca dei dati sia ai parametri non perfettamente noti.\n\nSia l’approccio frequentista sia quello bayesiano affrontano questi problemi in modo rigoroso, ma differiscono nel modo di concettualizzare l’incertezza e di incorporare l’informazione nei modelli.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "href": "chapters/key_notions/02_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "title": "2  Concetti chiave",
    "section": "2.6 Le sfide dell’inferenza statistica in psicologia",
    "text": "2.6 Le sfide dell’inferenza statistica in psicologia\nIn psicologia e, più in generale, nelle scienze sociali, l’inferenza statistica incontra specifiche problematiche spesso connesse alla complessità dei fenomeni oggetto di studio (Gelman et al., 2021). Tra le sfide principali figurano:\n\nLimiti nella generalizzazione dei risultati. In molti studi psicologici, le condizioni sperimentali create in laboratorio o in ambienti altamente controllati non sempre rispecchiano le dinamiche reali in cui i fenomeni si manifestano. L’uso di procedure standardizzate e compiti artificiali può semplificare notevolmente le variabili in gioco, a scapito della validità esterna: i risultati ottenuti potrebbero non essere direttamente trasferibili a contesti naturali o situazioni di vita quotidiana. Inoltre, se i partecipanti vengono selezionati per ragioni pratiche (ad esempio, studenti universitari reclutati su base volontaria), ciò limita ulteriormente la rappresentatività del campione, rendendo più difficile estendere le conclusioni a gruppi più eterogenei o a popolazioni diverse.\nRischio di semplificare eccessivamente i meccanismi causali ipotizzati. L’inferenza causale – implicita o esplicita nella maggior parte delle ricerche in psicologia – mira a comprendere se e come un fattore influisca su un altro. Tuttavia, in contesti così complessi, i modelli causali proposti possono risultare eccessivamente semplificati, trascurando interazioni tra variabili, fattori contestuali o processi multilivello. Quando tali aspetti non vengono adeguatamente considerati, le conclusioni possono rivelarsi poco utili o non sufficientemente applicabili ai contesti reali.\nDistorsioni legate alla misurazione. Molti costrutti di interesse psicologico (es. ansia, autostima, intelligenza) non sono direttamente osservabili, bensì misurati attraverso questionari, test o altre metodologie indirette. Tale approccio introduce possibili errori di misurazione e distorsioni legate allo strumento di valutazione. L’inferenza statistica deve quindi tenere conto di questa complessità, collegando in modo rigoroso le osservazioni empiriche ai costrutti teorici sottostanti.\n\nIn sintesi, la stima e l’inferenza statistica rappresentano strumenti fondamentali per trasformare i dati campionari in conoscenza generalizzabile, soprattutto in un contesto come quello psicologico, caratterizzato da un’elevata variabilità nei comportamenti e nei processi mentali. Da un lato, la metodologia quantitativa offre un quadro consolidato per gestire l’incertezza e testare ipotesi; dall’altro, è cruciale prestare attenzione alla qualità del campione, alla validità degli strumenti di misura e all’intrinseca complessità dei costrutti indagati.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#la-quantificazione-dellincertezza",
    "href": "chapters/key_notions/02_key_notions.html#la-quantificazione-dellincertezza",
    "title": "2  Concetti chiave",
    "section": "2.7 La quantificazione dell’incertezza",
    "text": "2.7 La quantificazione dell’incertezza\nLe considerazioni introduttive di questo capitolo mettono in evidenza come la gestione e la quantificazione dell’incertezza rappresentino un aspetto cruciale della stima e dell’inferenza statistica. Qualunque stima ottenuta da un campione è inevitabilmente soggetta a errore, poiché il campione costituisce soltanto una frazione della popolazione di riferimento. L’inferenza statistica offre gli strumenti necessari per quantificare tale incertezza, ad esempio tramite gli intervalli di confidenza (nell’approccio frequentista) o le distribuzioni a posteriori (nell’approccio bayesiano), consentendo di esprimere in modo rigoroso il grado di fiducia nelle conclusioni raggiunte.\nIn conclusione, la stima e l’inferenza statistica rappresentano strumenti essenziali per trasformare i dati empirici in conoscenza solida e applicabile. È tuttavia indispensabile avvalersene in maniera critica, tenendo sempre presenti le possibili distorsioni insite nel processo di raccolta e analisi dei dati. Ciò significa prestare particolare attenzione alla rappresentatività del campione, alla validità delle misurazioni e all’interpretazione corretta dei risultati, così da evitare generalizzazioni indebite o conclusioni fuorvianti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#riflessioni-conclusive",
    "href": "chapters/key_notions/02_key_notions.html#riflessioni-conclusive",
    "title": "2  Concetti chiave",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nL’analisi dei dati acquisisce valore solo quando è integrata con una solida teoria scientifica, che fornisce il contesto e il quadro interpretativo necessario per attribuire senso ai risultati. Ad esempio, osservare che un trattamento psicologico riduce i sintomi è un’osservazione empirica che, senza una teoria che chiarisca i meccanismi sottostanti, rimane priva di potere esplicativo. È la teoria che orienta il processo analitico, formulando ipotesi verificabili e offrendo interpretazioni che si inseriscono in un modello più ampio.\nIn definitiva, la relazione tra teoria e analisi dei dati è intrinsecamente circolare e dinamica: le teorie guidano la raccolta, l’analisi e l’interpretazione dei dati, mentre i dati, a loro volta, stimolano il perfezionamento e l’evoluzione delle teorie. Questo dialogo continuo è ciò che permette un progresso costante nella comprensione dei fenomeni psicologici.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nChe cos’è una spiegazione scientifica e in che modo si differenzia da una mera descrizione o previsione di un fenomeno?\nPerché, quando si parla di popolazione e campione, è fondamentale assicurarsi che il campione sia rappresentativo, e quali conseguenze possono derivare da un campione non rappresentativo?\nChe differenza c’è tra un parametro e una statistica, e perché in inferenza statistica si cerca di stimare il parametro sconosciuto a partire dalla statistica campionaria?\nCosa si intende per bias nella raccolta e interpretazione dei dati, e in che modo la consapevolezza dei possibili bias può migliorare la qualità della ricerca?\nPerché in psicologia e nelle scienze sociali risulta essenziale integrare l’analisi dei dati con un quadro teorico solido e coerente?\nQual è la differenza principale tra uno studio osservazionale e un esperimento, e perché la distinzione è importante per comprendere la causalità?\nChe ruolo svolgono i modelli scientifici in psicologia, e quali caratteristiche fondamentali dovrebbero possedere per essere considerati validi e utili?\nIn che modo l’analisi dei dati aiuta a passare dalle semplici correlazioni o tendenze osservate all’elaborazione di ipotesi e spiegazioni più profonde?\nChe differenza c’è tra variabili indipendenti e variabili dipendenti, e perché questa distinzione è cruciale per disegnare uno studio e interpretarne i risultati?\nPerché parlare di incertezza è inevitabile quando si utilizzano i dati di un campione, e come la statistica (frequentista o bayesiana) ci aiuta a gestirla?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Che cos’è una spiegazione scientifica e in che modo si differenzia da una mera descrizione o previsione di un fenomeno?\nUna spiegazione scientifica mira a individuare le cause e i meccanismi che generano o influenzano un fenomeno. Non si limita quindi a descrivere cosa accade o a prevedere ciò che potrebbe accadere (come una semplice correlazione o un modello predittivo), ma cerca di chiarire perché il fenomeno si verifica. Ad esempio, dire “i bambini con genitori laureati hanno migliori prestazioni scolastiche” è una descrizione (o previsione) utile; spiegare che ciò avviene a causa di un maggior sostegno nel percorso di studi, di un ambiente più ricco di stimoli culturali, o di un contesto socioeconomico facilitante, fornisce invece una spiegazione che va oltre la pura correlazione statistica.\n2. Perché, quando si parla di popolazione e campione, è fondamentale assicurarsi che il campione sia rappresentativo, e quali conseguenze possono derivare da un campione non rappresentativo?\nIl campione è il sottoinsieme di individui selezionati da una popolazione più ampia. Affinché i risultati di uno studio siano validi e generalizzabili, il campione deve rispecchiare le principali caratteristiche della popolazione (ad esempio in termini di età, genere, livello socioeconomico, ecc.). Se il campione non è rappresentativo (per esempio, se si reclutano solo studenti universitari per uno studio su tutta la popolazione italiana), possono emergere bias di selezione che rendono impossibile estendere correttamente i risultati a gruppi sociali diversi. Conseguenze tipiche di un campione non rappresentativo includono stime distorte dei parametri d’interesse, conclusioni fuorvianti e ridotta validità esterna della ricerca.\n3. Che differenza c’è tra un parametro e una statistica, e perché in inferenza statistica si cerca di stimare il parametro sconosciuto a partire dalla statistica campionaria?\n\nUn parametro è una caratteristica numerica della popolazione (ad esempio la media reale di un determinato tratto o la proporzione di individui con una certa caratteristica).\n\nUna statistica è una misura analoga, ma calcolata sul campione (ad esempio la media o la proporzione campionaria).\n\nPoiché in genere è impossibile o molto costoso misurare l’intera popolazione, si raccoglie un campione più piccolo e gestibile. La statistica del campione (ad es. la media campionaria) è quindi usata per stimare il parametro (ad es. la media della popolazione). L’obiettivo dell’inferenza statistica è fornire, insieme a questa stima, una misura dell’incertezza associata (per esempio un intervallo di confidenza), così da comprendere quanto la statistica campionaria potrebbe “avvicinarsi” al vero valore del parametro.\n4. Cosa si intende per bias nella raccolta e interpretazione dei dati, e in che modo la consapevolezza dei possibili bias può migliorare la qualità della ricerca?\nIl bias è un errore sistematico che altera i risultati di uno studio in una direzione specifica, dovuto a scelte o condizioni nel disegno della ricerca, nella selezione del campione, nella misurazione o nell’interpretazione dei dati. Ad esempio, se reclutiamo solo volontari particolarmente motivati a partecipare a una ricerca, potremmo ottenere risultati che sovrastimano un certo fenomeno e non rispecchiano la popolazione generale.\nEssere consapevoli di come i bias possano nascere aiuta i ricercatori a mitigarli (ad esempio, bilanciando il reclutamento dei partecipanti o rendendo anonima la compilazione di un questionario) e a tenere conto dei loro effetti quando si interpretano i risultati. Così, la ricerca risulta più affidabile e validamente interpretata.\n5. Perché in psicologia e nelle scienze sociali risulta essenziale integrare l’analisi dei dati con un quadro teorico solido e coerente?\nNelle scienze sociali e in psicologia, i fenomeni studiati sono spesso complessi e influenzati da molte variabili. I dati da soli, senza una teoria, forniscono soltanto una descrizione o una misurazione di ciò che accade in un dato momento. La teoria invece permette di:\n\nIdentificare le variabili rilevanti e formulare ipotesi specifiche;\n\nInterpretare i risultati, attribuendo un senso e un contesto alle relazioni osservate;\n\nComprendere i meccanismi causali e sviluppare spiegazioni che vadano oltre la pura descrizione.\n\nSenza un quadro teorico di riferimento, sarebbe difficile capire perché si osservano determinate relazioni e come possano cambiare in contesti diversi o in situazioni sperimentali alternative.\n6. Qual è la differenza principale tra uno studio osservazionale e un esperimento, e perché la distinzione è importante per comprendere la causalità?\n\nStudio osservazionale: Il ricercatore raccoglie i dati senza intervenire né manipolare alcuna variabile. Ad esempio, si misura il livello di stress delle persone e la loro produttività sul lavoro, senza modificare artificialmente il livello di stress. Questi studi mostrano correlazioni, ma è difficile stabilire con certezza relazioni di causa-effetto.\n\nEsperimento: Il ricercatore manipola una o più variabili (variabili indipendenti) e controlla le condizioni, ad esempio assegnando in modo casuale i partecipanti a un gruppo di trattamento e a uno di controllo. Ciò facilita la comprensione di eventuali nessi causali, perché la randomizzazione e il controllo degli altri fattori riducono il rischio che variabili esterne influenzino i risultati.\n\nLa distinzione è cruciale perché, nei fenomeni complessi della psicologia, gli studi osservazionali possono suggerire ipotesi di relazione, ma di solito occorre un disegno sperimentale (quando possibile) per trarre conclusioni più solide sulla causalità.\n7. Che ruolo svolgono i modelli scientifici in psicologia, e quali caratteristiche fondamentali dovrebbero possedere per essere considerati validi e utili?\nI modelli scientifici in psicologia forniscono una struttura concettuale e spesso formale (matematica o simulativa) per rappresentare e spiegare processi mentali e comportamentali. Servono a:\n\nOrganizzare osservazioni ed evidenze in un sistema coerente;\n\nFare previsioni verificabili empiricamente;\n\nGuidare l’interpretazione di nuovi dati e la progettazione di futuri studi.\n\nCaratteristiche di un buon modello sono:\n\nCoerenza descrittiva (rappresenta fedelmente il fenomeno);\n\nCapacità predittiva (prevede correttamente i risultati di situazioni nuove);\n\nSupporto empirico (confermato dai dati raccolti rigorosamente);\n\nFalsificabilità (dev’essere possibile smentirlo con evidenze contrarie);\n\nParsimonia (non dev’essere inutilmente complicato);\n\nGeneralizzabilità (applicabile a diversi contesti e situazioni);\n\nUtilità pratica (fornisce indicazioni utili per interventi o comprensione teorica).\n\n8. In che modo l’analisi dei dati aiuta a passare dalle semplici correlazioni o tendenze osservate all’elaborazione di ipotesi e spiegazioni più profonde?\nL’analisi dei dati non si limita a segnalare che “due variabili sono associate” (correlazioni), ma offre:\n\nStrumenti per isolare l’effetto di una variabile sulle altre (regressioni multiple, modelli a effetti misti, ecc.);\n\nMetodologie per la verifica di ipotesi specifiche sulla direzione e sulla natura delle relazioni (ad es. test statistici o modelli di mediazione-moderazione in psicologia);\n\nIndicatori dell’incertezza e della robustezza dei risultati (intervalli di confidenza, analisi della potenza, analisi bayesiane).\n\nCon questi strumenti, i ricercatori possono integrare i risultati quantitativi con le teorie esistenti, sviluppare nuove ipotesi su meccanismi causali e proporre spiegazioni più articolate su come e perché le variabili si influenzino reciprocamente.\n9. Che differenza c’è tra variabili indipendenti e variabili dipendenti, e perché questa distinzione è cruciale per disegnare uno studio e interpretarne i risultati?\n\nVariabile indipendente (VI): è quella che si sospetta abbia un effetto su un’altra variabile, o che si desidera manipolare in un disegno sperimentale (per esempio, l’introduzione di un nuovo metodo di studio).\n\nVariabile dipendente (VD): è la variabile che si misura per valutare l’eventuale effetto della variabile indipendente (ad esempio, i risultati di un test di apprendimento).\nLa distinzione è basilare perché chiarisce la direzione del rapporto di interesse e permette di formulare ipotesi come “VI → VD” (es. “il nuovo metodo di studio migliora i risultati del test”). Sbagliare a identificare quali sono le variabili indipendenti e dipendenti può portare a disegni di ricerca confusi e interpretazioni errate.\n\n10. Perché parlare di incertezza è inevitabile quando si utilizzano i dati di un campione, e come la statistica (frequentista o bayesiana) ci aiuta a gestirla?\nQuando raccogliamo dati da un campione (necessariamente limitato), non possiamo osservare l’intera popolazione. Questo introduce un margine di incertezza su quanto la misura campionaria (statistica) rispecchi il parametro reale della popolazione. Inoltre, possono sempre esserci fattori non controllati o errori di misurazione.\n\nNell’approccio frequentista, l’incertezza è gestita tramite concetti come gli intervalli di confidenza e i valori p, che quantificano la probabilità di osservare determinati risultati assumendo determinate ipotesi (per es. l’ipotesi nulla).\n\nNell’approccio bayesiano, l’incertezza è modellata tramite distribuzioni di probabilità (posteriori) che incorporano sia i dati osservati sia le informazioni pregresse (priors).\n\nEntrambi gli approcci forniscono metodologie per valutare quanto ci si possa fidare di una data conclusione, riconoscendo il carattere aleatorio e parziale dei dati e rendendo esplicito il grado di incertezza.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#bibliografia",
    "href": "chapters/key_notions/02_key_notions.html#bibliografia",
    "title": "2  Concetti chiave",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMurray, E. J., & Carr, K. C. (2024). Measuring Racial Sentiment Using Social Media Is Harder Than It Seems. Epidemiology, 35(1), 60–63.\n\n\nNobles, M. (2000). Shades of citizenship: Race and the census in modern politics. Stanford University Press.\n\n\nSteinman, R. M., Pizlo, Z., & Pizlo, F. J. (2000). Phi is not beta, and why Wertheimer’s discovery launched the Gestalt revolution. Vision research, 40(17), 2257–2264.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html",
    "href": "chapters/key_notions/03_design.html",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "",
    "text": "3.1 Introduzione\nQuesto capitolo si propone di approfondire i concetti introdotti in precedenza, concentrandosi in particolare sul processo di campionamento e sull’importanza delle diverse metodologie di ricerca in psicologia. Dopo aver compreso il ruolo fondamentale dei dati nella verifica delle teorie, emerge una questione cruciale: come vengono raccolti questi dati?\nLa raccolta dei dati non è un’attività neutra o priva di conseguenze metodologiche. I dati, infatti, non hanno lo stesso valore scientifico a seconda di come vengono ottenuti. Alcune modalità di raccolta generano informazioni preziose e utili per testare le teorie, mentre altre possono produrre risultati fuorvianti, distorti o addirittura dannosi per la validità della ricerca.\nIl metodo scientifico fornisce un quadro di riferimento che delinea le caratteristiche ideali di un processo di raccolta dati in grado di produrre informazioni valide e affidabili. Tuttavia, le prescrizioni del metodo scientifico sono per loro natura generali e astratte. Tradurre questi principi in procedure concrete e applicarli efficacemente in un contesto di ricerca specifico rappresenta una sfida significativa.\nQuesto passaggio, che collega la teoria alla pratica, dipende dalle risorse disponibili, dalla competenza metodologica e dalla creatività del ricercatore. La capacità di ideare e attuare strategie di raccolta dati adeguate al contesto specifico della ricerca è fondamentale per garantire la qualità e la validità dei risultati ottenuti. In questo capitolo, approfondiremo i principi del campionamento e introdurremo i concetti chiave relativi ai disegni di ricerca.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#popolazioni-e-campioni",
    "href": "chapters/key_notions/03_design.html#popolazioni-e-campioni",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.2 Popolazioni e Campioni",
    "text": "3.2 Popolazioni e Campioni\nNella ricerca scientifica, è essenziale distinguere tra popolazione e campione.\n\nPopolazione: rappresenta l’insieme completo di unità che condividono una o più caratteristiche specifiche oggetto di studio. La dimensione della popolazione è indicata con N.\nCampione: è un sottoinsieme della popolazione, di dimensione n. L’obiettivo del campionamento è ottenere un campione rappresentativo, ovvero un sottoinsieme che rifletta accuratamente le caratteristiche della popolazione di riferimento.\n\n\n3.2.1 Metodi di Campionamento\nEsistono diverse strategie per selezionare un campione rappresentativo da una popolazione. Queste strategie si dividono principalmente in due categorie: campionamento probabilistico e campionamento non probabilistico.\n\n3.2.1.1 Campionamento Probabilistico\nNel campionamento probabilistico, ogni unità della popolazione ha una probabilità nota e non nulla di essere inclusa nel campione. Questo approccio minimizza il rischio di distorsioni sistematiche (bias) e consente di stimare l’errore di campionamento.\n\nCampionamento Casuale Semplice (CCS):\nOgni unità della popolazione ha la stessa probabilità di essere inclusa nel campione. Questo metodo richiede una lista completa di tutte le unità della popolazione, nota come frame di campionamento. La selezione può avvenire con o senza reinserimento. Il CCS senza reinserimento è il più comune nella pratica, ma nelle ricerche psicologiche è raramente utilizzabile a causa della difficoltà di ottenere un frame completo della popolazione.\nCampionamento Stratificato:\nLa popolazione viene divisa in strati (H), ovvero sottogruppi omogenei in base a una o più variabili rilevanti (es. età, genere, regione geografica). Da ogni strato h viene estratto un campione casuale semplice di dimensione nh. Questo metodo può essere:\n\nProporzionale: la dimensione del campione in ogni strato è proporzionale alla dimensione dello strato nella popolazione.\nNon proporzionale: utilizzato per sovra-campionare gruppi minoritari, consentendo analisi dettagliate di sottogruppi altrimenti poco rappresentati.\nNelle ricerche psicologiche, il campionamento stratificato è utile per garantire che variabili come il genere o l’età siano adeguatamente rappresentate, ma può essere complesso da implementare.\n\nCampionamento a Grappolo (Cluster Sampling):\nLa popolazione viene suddivisa in grappoli (cluster), che rappresentano gruppi eterogenei (es. scuole, ospedali, quartieri). Vengono selezionati casualmente alcuni grappoli, includendo tutte le unità al loro interno. Questo metodo è economico e pratico, specialmente in contesti dove accedere all’intera popolazione è difficile. Tuttavia, la precisione può essere ridotta se i grappoli differiscono notevolmente tra loro.\nCampionamento Multistadio:\nCombinazione di campionamento a grappolo e CCS. Vengono selezionati casualmente alcuni grappoli e, successivamente, all’interno di ciascun grappolo, si estrae un campione casuale di unità. Questo metodo bilancia costi e precisione, risultando particolarmente adatto a studi su larga scala, ad esempio a livello nazionale.\n\n\n\n3.2.1.2 Campionamento Non Probabilistico\nNel campionamento non probabilistico, la probabilità di inclusione di ogni unità nel campione non è nota. Questo approccio è spesso adottato per ragioni di praticità o quando non è disponibile un frame di campionamento. Tuttavia, aumenta il rischio di distorsioni e limita la generalizzabilità dei risultati alla popolazione.\n\nCampionamento di Convenienza:\nÈ il metodo più diffuso nella ricerca psicologica. I partecipanti vengono selezionati in base alla loro facile accessibilità (es., studenti universitari, volontari). Questo metodo è rapido ed economico, ma introduce significativi bias di selezione, poiché il campione non è rappresentativo della popolazione generale.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#il-campionamento-nella-ricerca-psicologica",
    "href": "chapters/key_notions/03_design.html#il-campionamento-nella-ricerca-psicologica",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.3 Il Campionamento nella Ricerca Psicologica",
    "text": "3.3 Il Campionamento nella Ricerca Psicologica\nIl tema del campionamento nella ricerca psicologica è cruciale perché influisce in modo diretto sulla validità esterna e sulla generalizzabilità dei risultati. Nella pratica, però, l’ideale metodologico del campionamento probabilistico è spesso difficile da perseguire, a causa di vincoli di tempo, di risorse economiche e di accessibilità ai partecipanti (Henrich et al., 2010a). Per queste ragioni, molti studi in psicologia fanno ricorso al campionamento di convenienza, che prevede la selezione dei partecipanti sulla base della loro facile reperibilità, come studenti universitari o volontari reclutati online.\n\n3.3.1 Perché il Campionamento di Convenienza è così Diffuso?\n\nVincoli di Risorse\nLa ricerca psicologica, specie in ambito accademico, spesso non dispone di finanziamenti sufficienti per condurre campionamenti su larga scala. Reclutare partecipanti rappresentativi di un’intera popolazione richiederebbe budget, logistica e tempo ben superiori a quelli generalmente disponibili (Peterson & Merunka, 2014). Il campionamento di convenienza diventa quindi un compromesso “necessario” per poter portare avanti gli studi.\nAccessibilità ai Partecipanti\nNel contesto universitario, gli studenti rappresentano il bacino più facilmente accessibile e motivato a partecipare a studi psicologici, talvolta in cambio di crediti formativi o rimborsi simbolici (Sears, 1986). In altri contesti, si ricorre a piattaforme online che forniscono volontari in tempi brevi, consentendo di raccogliere dati in modo rapido e a costi contenuti.\nRapidità di Raccolta Dati\nIl vantaggio principale del campionamento di convenienza è la possibilità di raccogliere dati in tempi molto più ridotti rispetto a strategie di campionamento probabilistico. Tale rapidità può risultare essenziale per studi pilota o ricerche che richiedono analisi preliminari di fenomeni ancora poco esplorati.\n\n\n\n3.3.2 Limiti e Implicazioni\nIl ricorso al campionamento di convenienza comporta inevitabilmente dei limiti in termini di rappresentatività del campione. Gli individui che si prestano a partecipare a uno studio potrebbero avere caratteristiche socio-demografiche, cognitive o motivazionali peculiari (ad esempio, essere più giovani, con livelli di istruzione più alti, culturalmente più omogenei), portando ad un fenomeno noto come “campioni WEIRD” [Western, Educated, Industrialized, Rich, Democratic; Henrich et al. (2010b)]. Ciò significa che i risultati ottenuti potrebbero non riflettere adeguatamente l’intera variabilità della popolazione umana.\n\nGeneralizzabilità Ridotta: Uno studio condotto su studenti di psicologia in un’università europea può non essere applicabile a individui di diverse fasce di età, provenienti da altre aree geografiche o con retroterra socio-culturali differenti.\nBias di Selezione: I partecipanti volontari, specialmente online, possono essere attratti dallo studio per ragioni specifiche (ad esempio, curiosità verso la psicologia, tempo libero a disposizione, motivazione a ottenere un compenso), introducendo distorsioni non presenti nella popolazione più ampia.\nLimitazioni nei Risultati: Se i processi psicologici oggetto di indagine sono influenzati da cultura, età o altre variabili, lo studio potrebbe non catturare in modo esaustivo la complessità del fenomeno.\n\n\n\n3.3.3 Perché in Psicologia è (in Parte) Accettabile\nSebbene il campionamento di convenienza costituisca un limite, è bene ricordare che molti fenomeni psicologici presentano elementi di base che sono relativamente generali o universali nell’essere umano [ad esempio, i processi di percezione, l’apprendimento di base, alcune dinamiche emotive e motivazionali; cfr. Tooby & Cosmides (2005)]. Ciò significa che, entro certi confini, studiare un campione di convenienza può comunque fornire indicazioni utili e trasferibili ad altre popolazioni. Inoltre, buona parte delle ricerche in psicologia mira ad approfondire meccanismi e processi interna corporis – cioè aspetti di natura cognitiva, emotiva o sociale che, pur potendo variare in intensità o manifestazione, hanno basi comuni tra gli individui.\nIn altre parole, esiste un trade-off tra la necessità di disporre di campioni rappresentativi per garantire la massima generalizzabilità e la specificità dei fenomeni psicologici, che talvolta risiedono in processi considerati “universali”. Se lo scopo di uno studio è quello di testare meccanismi cognitivi di base (per esempio, l’elaborazione di stimoli visivi o di memoria), un campione di studenti potrebbe comunque fornire dati sufficientemente robusti, purché si riconoscano i limiti del contesto di raccolta.\n\n3.3.3.1 Considerazioni Etiche e Pratiche\nTalvolta, per ragioni etiche, non è semplice reperire partecipanti da particolari fasce di popolazione (ad esempio minori, pazienti clinici, soggetti in contesti istituzionali). In alcune ricerche, poi, l’uso di questionari lunghi o procedure sperimentali intense rende difficile attrarre volontari al di fuori dell’ambiente universitario. Da questo punto di vista, avere un bacino di partecipanti noti (ad es. studenti di psicologia) agevola la raccolta dei dati.\n\nRicompense: Spesso i dipartimenti offrono crediti formativi o piccoli compensi ai partecipanti, innescando un circolo virtuoso di interesse per la ricerca.\nLibertà di rifiuto: Le università dispongono di comitati etici che tutelano i diritti dei partecipanti, garantendo che anche i reclutamenti “di comodo” rispettino i principi etici fondamentali (consenso informato, anonimato, diritto al recesso, ecc.).\n\n\n\n\n3.3.4 Come Mitigare i Limiti del Campionamento di Convenienza\n\nReplicazione Incrociata (Cross-Replication)\nUn metodo efficace per aumentare la validità dei risultati è replicare lo stesso studio su campioni differenti, di età diversa o provenienti da contesti socio-culturali eterogenei. Ripetere la ricerca in più contesti e ottenere risultati simili fornisce evidenza della generalizzabilità del fenomeno.\nCampionamento Diversificato\nAnche se si ricorre a un campionamento di convenienza, si può tentare di diversificare la provenienza dei partecipanti (ad esempio, includendo studenti di diverse facoltà o atenei, oppure reclutando volontari su piattaforme online internazionali). Un campione che rifletta almeno in parte una maggiore varietà di background socio-culturali è comunque preferibile alla selezione di un solo gruppo omogeneo.\nCaratterizzazione Dettagliata del Campione\nÈ fondamentale fornire informazioni precise su età, genere, livello di istruzione, estrazione socio-culturale e altre variabili rilevanti. Questo permette ai lettori di valutare in che misura i risultati dello studio possano essere trasferiti ad altre popolazioni.\nIntegrazione di Metodi di Campionamento Misti\nAlcuni ricercatori scelgono di integrare campionamenti non probabilistici con piccole porzioni di campionamento più stratificato o di selezionare sotto-campioni rappresentativi per determinati sottogruppi. Non si tratta di un vero e proprio campionamento probabilistico, ma può comunque migliorare la robustezza dei risultati rispetto al puro campionamento di convenienza.\n\n\n\n3.3.5 Considerazioni Economiche e Future Prospettive\nAlla luce di questi punti, appare chiaro che il ricorso a metodi di campionamento probabilistici più rigorosi (campionamento casuale semplice, stratificato o a grappolo) richiederebbe aumenti significativi nei finanziamenti e un impegno logistico maggiore. Ciò non è sempre fattibile in contesti di ricerca accademica o quando i progetti sono condotti con budget limitati.\nD’altro canto, i finanziamenti aggiuntivi permetterebbero di:\n\nReclutare campioni più ampi e diversificati, ad esempio attraverso agenzie di rilevazione professionali o sondaggi a livello nazionale.\n\nImplementare studi longitudinali su popolazioni geograficamente distribuite, riducendo il rischio di raccogliere dati esclusivamente da aree limitrofe ai centri di ricerca.\nSostenere progetti multicentrici a livello internazionale, che consentono di testare l’universalità o la specificità culturale dei fenomeni psicologici.\n\nFino a quando queste risorse non saranno disponibili su larga scala, il campionamento di convenienza rimarrà la soluzione più diffusa e “realistica” nella ricerca psicologica. Tuttavia, non bisogna considerarlo esclusivamente un limite: la specificità dei fenomeni psicologici, legati a processi condivisi tra gli individui, talvolta permette di estrarre conclusioni valide anche da campioni meno rappresentativi, purché si utilizzino adeguate cautele nell’interpretazione e si persegua la replicazione come prassi consolidata.\nIn sintesi, il campionamento di convenienza è una strategia inevitabile nell’attuale panorama della ricerca psicologica, caratterizzato da forti limitazioni di risorse, ma in molti casi risulta comunque sufficiente per investigare dinamiche e processi psicologici di base. L’auspicio per il futuro è di poter disporre di finanziamenti e collaborazioni che permettano di ampliare il raggio d’azione e la diversità dei partecipanti, rafforzando la validità e la generalizzabilità della produzione scientifica in psicologia.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#metodologia-sperimentale",
    "href": "chapters/key_notions/03_design.html#metodologia-sperimentale",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.4 Metodologia Sperimentale",
    "text": "3.4 Metodologia Sperimentale\n\n3.4.1 Principi Fondamentali del Disegno Sperimentale\n\nControllo\nL’obiettivo è ridurre l’influenza di variabili confondenti (Z) sulla relazione tra la variabile indipendente (X) e quella dipendente (Y). Utilizzare un gruppo di controllo consente di stabilire un riferimento per valutare l’effetto del trattamento.\nRandomizzazione\nL’assegnazione casuale dei partecipanti ai gruppi sperimentali distribuisce le variabili confondenti in modo equilibrato tra i gruppi, aumentando la credibilità dell’inferenza causale tra X e Y. Questo approccio garantisce che eventuali differenze osservate siano attribuibili al trattamento e non a fattori esterni.\n\n\n\n3.4.2 Strategie di Mitigazione dei Bias\n\nCecità (Blinding)\nStrumento chiave per minimizzare l’influenza di aspettative e pregiudizi, sia nei partecipanti che nei ricercatori. Le principali modalità includono:\n\nCecità singola: I partecipanti non sono consapevoli del trattamento assegnato.\nCecità doppia: Sia i partecipanti che i ricercatori che interagiscono direttamente con loro non conoscono l’assegnazione dei trattamenti.\nCecità tripla: Né i partecipanti, né i ricercatori, né gli analisti dei dati sono a conoscenza dei trattamenti durante la raccolta e l’analisi dei dati.\n\nGruppo di Controllo\nL’introduzione di un gruppo che riceve un trattamento inerte (controllo) consente di isolare gli effetti psicologici legati alle aspettative dei partecipanti, distinguendoli dagli effetti specifici del trattamento.\nStandardizzazione delle Procedure\nGarantire che tutte le condizioni sperimentali, eccetto la variabile manipolata, siano mantenute costanti tra i gruppi. Questo riduce la variabilità non controllata, migliorando la comparabilità dei risultati.\n\n\n\n3.4.3 Nota sulla Replicazione\nLa replicazione degli esperimenti non è una caratteristica intrinseca del metodo sperimentale, ma rappresenta una pratica fondamentale nella scienza per verificare l’affidabilità e la generalizzabilità dei risultati. Si distingue in:\n\nReplicazione diretta: Ripetere lo stesso studio con le stesse condizioni.\nReplicazione concettuale: Ripetere lo studio modificando aspetti specifici per testare la robustezza del risultato.\n\n\n\n3.4.4 Tipologie di Disegni Sperimentali\n\nDisegno a Gruppi Indipendenti (Between-Subjects):\nI partecipanti vengono assegnati a un unico gruppo e sono esposti a una sola condizione sperimentale. Questo disegno è utile quando l’esposizione multipla potrebbe introdurre confondenti, ma richiede un campione più ampio per raggiungere lo stesso livello di precisione.\nDisegno a Misure Ripetute (Within-Subjects):\nGli stessi partecipanti vengono esposti a tutte le condizioni sperimentali. Questo approccio riduce la variabilità tra soggetti, migliorando la precisione delle stime. Tuttavia, richiede attenzione nel controllare gli effetti di ordine, come affaticamento o apprendimento, spesso attraverso il bilanciamento dell’ordine di presentazione dei trattamenti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#studi-osservazionali",
    "href": "chapters/key_notions/03_design.html#studi-osservazionali",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.5 Studi Osservazionali",
    "text": "3.5 Studi Osservazionali\nGli studi osservazionali possono essere classificati in:\n\nStudi Trasversali (Cross-Sectional)\nI dati vengono raccolti in un singolo momento. Utili per stimare la prevalenza di una condizione, ma non permettono di stabilire relazioni causali.\nStudi di Coorte (Cohort Studies)\nUn gruppo di individui (coorte) viene seguito nel tempo per osservare l’incidenza di un evento. Permettono di studiare la relazione tra esposizione e outcome, ma possono essere costosi e richiedere molto tempo.\nStudi Caso-Controllo (Case-Control Studies)\nVengono confrontati individui con una determinata condizione (casi) con individui senza la condizione (controlli) per identificare possibili fattori di rischio. Utili per studiare malattie rare, ma soggetti a bias di selezione e di ricordo.\n\nLe principali limitazioni degli studi osservazionali sono la presenza di variabili confondenti e la difficoltà di stabilire relazioni causali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#riflessioni-conclusive",
    "href": "chapters/key_notions/03_design.html#riflessioni-conclusive",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.6 Riflessioni Conclusive",
    "text": "3.6 Riflessioni Conclusive\nNel corso di questo capitolo, abbiamo esplorato l’importanza del campionamento e delle diverse strategie di ricerca in psicologia, mettendo in luce i vincoli metodologici e le implicazioni derivanti da scelte spesso guidate dalle risorse a disposizione. Se da un lato i metodi di campionamento probabilistico garantiscono maggiore controllo sulla rappresentatività del campione, dall’altro, la realtà accademica e il contesto operativo di molti studi psicologici spingono verso soluzioni di comodo, inevitabilmente limitanti ma non per questo prive di valore scientifico.\nLe complessità intrinseche nello studio di fenomeni psicologici – spesso universali e al tempo stesso influenzati da variabili culturali e individuali – ci ricordano quanto sia importante mantenere un equilibrato senso critico. Da un punto di vista metodologico, l’esigenza di replicare gli studi in più contesti rimane la prassi fondamentale per rafforzare la credibilità dei risultati. Altrettanto cruciale è la volontà di caratterizzare in modo trasparente i propri campioni, rendendo chiaro in che misura siano (o non siano) rappresentativi della popolazione d’interesse. In tal modo, la comunità scientifica può valutare con maggiore consapevolezza la trasferibilità delle conclusioni a contesti diversi.\nUn ulteriore spunto di riflessione riguarda la tensione tra la desiderabilità di disegni di ricerca ideali (con campioni estesi e probabilistici) e le inevitabili restrizioni di tempo e budget. Se l’implementazione di studi su larga scala o a livello multicentrico consentirebbe di cogliere le sfumature culturali e socio-demografiche dei fenomeni, è altrettanto vero che, nel panorama attuale, molte ricerche non potrebbero essere realizzate senza ricorrere a partecipanti di più facile accesso, come gli studenti universitari o i volontari online. Tale flessibilità operativa può comunque produrre conoscenza significativa, a condizione che il ricercatore rimanga vigile rispetto ai possibili bias introdotti.\nIn definitiva, l’invito a chiunque conduca ricerche psicologiche è quello di coltivare una mentalità aperta, volta a bilanciare i limiti contingenti (economici, logistici, etici) con la necessità di mantenere standard metodologici solidi. Ciò implica sfruttare le potenzialità dell’integrazione tra disegni sperimentali e osservazionali, prestare attenzione alle forme di bias e, soprattutto, adottare la replicazione come pratica sistematica. Solo attraverso questa sinergia fra rigore scientifico e consapevolezza delle risorse disponibili è possibile far progredire la disciplina su basi empiriche sempre più solide e generalizzabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#esercizi",
    "href": "chapters/key_notions/03_design.html#esercizi",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nPerché la fase di raccolta dei dati è considerata “non neutrale” e quali conseguenze può avere sull’affidabilità dei risultati di una ricerca psicologica?\nIn che modo i diversi metodi di campionamento (probabilistico vs. non probabilistico) influiscono sulla generalizzabilità delle conclusioni di uno studio e quali situazioni giustificano l’uso dell’uno o dell’altro?\nQuali sono i principali rischi nell’adottare un campionamento di convenienza in ricerche psicologiche, e quali strategie si possono utilizzare per mitigare questi rischi?\nIn che modo la randomizzazione e l’uso di gruppi di controllo supportano l’inferenza causale in un disegno sperimentale, e perché queste caratteristiche sono spesso più difficili da mantenere negli studi osservazionali?\nQuali sono i principali criteri da considerare quando si valuta la validità di uno studio in termini di campionamento, disegno di ricerca e replicabilità?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Perché la fase di raccolta dei dati è considerata “non neutrale” e quali conseguenze può avere sull’affidabilità dei risultati di una ricerca psicologica?\nLa raccolta dei dati non è mai un processo completamente neutrale perché comporta scelte metodologiche e pratiche che possono influenzare la qualità e la natura delle informazioni ottenute. Ad esempio:\n\nSelezione del campione: Scegliere chi includere o escludere nella ricerca incide sulla rappresentatività del campione. Un campione non rappresentativo può produrre risultati distorti e difficilmente generalizzabili.\n\nModalità di somministrazione degli strumenti: La maniera in cui vengono somministrati questionari, test o interviste può influire sulle risposte dei partecipanti (per esempio, differenze tra somministrazione online vs. cartacea, questionari anonimi vs. non anonimi, ecc.).\n\nContesto e tempistiche: Il contesto ambientale (es., rumori, distrazioni) o il momento in cui i dati vengono raccolti (es., in prossimità di esami universitari) possono influenzare lo stato emotivo o motivazionale dei partecipanti.\n\nCome conseguenza, tutte queste variabili possono introdurre bias – ossia distorsioni sistematiche – che compromettono l’affidabilità e la validità dei risultati, rendendo l’interpretazione dei dati più complessa e potenzialmente fuorviante. In altre parole, se la fase di raccolta dati non è accuratamente progettata e condotta, la ricerca potrebbe fornire conclusioni scorrette o di limitata utilità scientifica.\n2. In che modo i diversi metodi di campionamento (probabilistico vs. non probabilistico) influiscono sulla generalizzabilità delle conclusioni di uno studio e quali situazioni giustificano l’uso dell’uno o dell’altro?\n\nCampionamento probabilistico:\n\nOgni unità della popolazione ha una probabilità nota e non nulla di essere selezionata.\n\nMetodi come il campionamento casuale semplice, stratificato o a grappolo forniscono un quadro più solido per stimare l’errore di campionamento e minimizzare i bias.\n\nI risultati ottenuti sono, in linea di massima, più facilmente generalizzabili all’intera popolazione di riferimento.\n\nÈ preferibile in studi di larga scala, in cui esiste un buon frame di campionamento (lista esaustiva della popolazione) e le risorse (tempo, fondi) consentono di implementare un disegno rigoroso.\n\nCampionamento non probabilistico:\n\nLa probabilità di inclusione di un’unità non è nota, per cui non si possono calcolare in modo rigoroso le stime di errore.\n\nIl metodo più comune è il campionamento di convenienza, in cui vengono reclutate persone facilmente accessibili (es., studenti universitari, volontari, piattaforme online).\n\nLa generalizzabilità dei risultati è ridotta, poiché il campione potrebbe non rispecchiare le caratteristiche della popolazione di interesse.\n\nÈ spesso utilizzato per studi esplorativi, ricerche a budget limitato o quando non si dispone di un elenco completo della popolazione.\n\n\nIn sintesi, il campionamento probabilistico è preferibile quando si mira a ottenere risultati solidi e generalizzabili a una popolazione più ampia e le condizioni logistiche lo consentono. Il campionamento non probabilistico, invece, è giustificato in studi preliminari, in situazioni in cui la popolazione non è ben definita o difficilmente accessibile, o quando si hanno vincoli di risorse che rendono impraticabile un campionamento probabilistico.\n3. Quali sono i principali rischi nell’adottare un campionamento di convenienza in ricerche psicologiche, e quali strategie si possono utilizzare per mitigare questi rischi?\n\nPrincipali rischi:\n\nBias di selezione: I partecipanti reclutati con metodi di convenienza (ad es. studenti di psicologia) potrebbero non rispecchiare l’eterogeneità della popolazione generale, limitando la generalizzabilità dei risultati.\n\nOmogeneità del campione: Se il campione è molto omogeneo (per età, livello di istruzione, contesto culturale), diventa difficile estendere le conclusioni a gruppi con caratteristiche diverse.\n\nAutoselezione: I volontari che si offrono di partecipare potrebbero differire sistematicamente da coloro che non partecipano (ad esempio, maggiore interesse per il tema della ricerca o per la ricompensa economica offerta).\n\nStrategie di mitigazione:\n\nSovra-campionamento: Includere deliberatamente più partecipanti appartenenti a gruppi minoritari o sottorappresentati, per disporre di sottocampioni più completi.\n\nReplicazione: Ripetere l’esperimento con campioni diversi (per età, contesto geografico, cultura) per verificare se i risultati si mantengono coerenti.\n\nDescrizione dettagliata del campione: Fornire informazioni precise sulle caratteristiche sociodemografiche (età, genere, livello di istruzione, ecc.) in modo che altri ricercatori o lettori possano valutare la trasferibilità dei risultati.\n\nCautela nell’interpretazione: Esplicitare nelle conclusioni i limiti relativi alla natura del campionamento e invitare a considerare possibili fattori confondenti legati alla non rappresentatività del campione.\n\n\n4. In che modo la randomizzazione e l’uso di gruppi di controllo supportano l’inferenza causale in un disegno sperimentale, e perché queste caratteristiche sono spesso più difficili da mantenere negli studi osservazionali?\n\nRandomizzazione:\n\nAssegna i partecipanti ai gruppi sperimentali (condizione sperimentale vs. condizione di controllo) in maniera casuale.\n\nGarantisce che variabili potenzialmente confondenti vengano distribuite equamente tra i gruppi, aumentando la probabilità che eventuali differenze nelle misure di esito (variabile dipendente) siano dovute esclusivamente alla manipolazione sperimentale (variabile indipendente).\n\nQuesto processo riduce l’influenza di fattori esterni non misurati o non conosciuti, favorendo un’inferenza causale più solida.\n\nGruppi di controllo:\n\nConsentono di confrontare i risultati di chi riceve il trattamento/intervento con chi non lo riceve (o riceve un trattamento placebo).\n\nAiutano a isolare l’effetto “vero” del trattamento dalle variazioni dovute a effetti psicologici (ad es. effetto placebo), al passare del tempo o a eventi esterni.\n\nDifficoltà negli studi osservazionali:\n\nNon prevedono la manipolazione diretta di una variabile indipendente né l’assegnazione casuale dei partecipanti: le persone “si assegnano da sole” alle condizioni.\n\nManca il controllo sperimentale: non è sempre possibile includere un gruppo di controllo o applicare procedure di randomizzazione.\n\nLe variabili confondenti possono agire in modo non controllabile e compromettere l’interpretazione causale: anche con analisi statistiche sofisticate, è difficile escludere del tutto la presenza di fattori esterni che influenzano la relazione tra esposizione e outcome.\n\n\nPer questi motivi, gli studi sperimentali (con randomizzazione e controllo) rimangono il metodo privilegiato per stabilire nessi di causalità, mentre gli studi osservazionali servono principalmente a generare ipotesi, descrivere fenomeni, o analizzare relazioni di associazione più che di causalità.\n5. Quali sono i principali criteri da considerare quando si valuta la validità di uno studio in termini di campionamento, disegno di ricerca e replicabilità?\n\nRappresentatività del campione:\n\nIl campione rispecchia realmente le caratteristiche della popolazione di interesse?\n\nÈ stato usato un metodo di campionamento appropriato (probabilistico vs. non probabilistico)?\n\nControllo e randomizzazione (validità interna):\n\nLo studio ha previsto un disegno sperimentale con assegnazione casuale e gruppo di controllo?\n\nQuanto è efficace il controllo delle variabili confondenti (bias di selezione, aspettative, effetto placebo, ecc.)?\n\nGeneralizzabilità o validità esterna:\n\nI risultati dello studio sono applicabili oltre il contesto specifico in cui è stato condotto?\n\nVi sono limitazioni dovute all’uso di un campione di convenienza o di un contesto culturale molto particolare?\n\nStandardizzazione delle procedure:\n\nLe istruzioni, i tempi di raccolta dati, i materiali utilizzati sono stati gestiti in modo uniforme per tutti i partecipanti?\n\nReplicabilità:\n\nÈ possibile ripetere lo studio (replicazione diretta o concettuale) e ottenere risultati simili?\n\nGli autori forniscono informazioni sufficienti (materiali, protocolli, analisi) per consentire la replicazione?\n\nChiarezza nell’esposizione dei limiti:\n\nGli autori discutono apertamente le limitazioni del metodo di campionamento o del disegno di ricerca e suggeriscono possibili miglioramenti per studi futuri?\n\n\nNel complesso, una valutazione critica di uno studio deve integrare tutti questi aspetti (campionamento, disegno, replicabilità) per stabilire in che misura i risultati siano solidi, attendibili e utilmente generalizzabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#bibliografia",
    "href": "chapters/key_notions/03_design.html#bibliografia",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010a). Most people are not WEIRD. Nature, 466(7302), 29–29.\n\n\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010b). The weirdest people in the world? Behavioral and Brain Sciences, 33(2-3), 61–83.\n\n\nPeterson, R. A., & Merunka, D. R. (2014). Convenience samples of college students and research reproducibility. Journal of Business Research, 67(5), 1035–1041.\n\n\nTooby, J., & Cosmides, L. (2005). Evolutionary psychology: Conceptual foundations. In D. M. Buss (A c. Di), The Handbook of Evolutionary Psychology (pp. 5–67). Wiley.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html",
    "href": "chapters/key_notions/04_measurement.html",
    "title": "4  La misurazione in psicologia",
    "section": "",
    "text": "4.1 Introduzione\nL a scienza si avvale di modelli per interpretare i dati, ma opera sempre con teorie incomplete e misurazioni soggette a errori. Di conseguenza, è fondamentale riconoscere le incertezze quando si cerca di estrarre informazioni dalle misurazioni utilizzando i nostri modelli. Nessuna misurazione, spiegazione o previsione è perfettamente accurata e precisa, e non possiamo mai conoscere con esattezza l’entità dei loro errori. Questo riconoscimento è alla base della teoria della misurazione, che cerca di quantificare e gestire queste incertezze per migliorare la qualità delle nostre conclusioni scientifiche.\nQuesta incertezza viene catturata in tre equazioni fondamentali. La prima è l’Equazione di Misurazione, che riconosce l’errore osservativo:\n\\[\ny = z + \\varepsilon_y,\n\\]\ndove \\(y\\) rappresenta il valore misurato, \\(z\\) il valore reale e \\(\\varepsilon_y\\) l’errore di misurazione. La seconda è l’Equazione di Modellazione, che esprime la presenza di un diverso tipo di errore:\n\\[\nz = f(x, \\theta) + \\varepsilon_\\text{model},\n\\]\ndove \\(f\\) è il modello, \\(x\\) sono le condizioni ambientali per cui eseguiamo il modello, \\(\\theta\\) sono i valori dei parametri del modello e \\(\\varepsilon_\\text{model}\\) rappresenta l’errore del modello, che sorge perché \\(f\\), \\(x\\) e \\(\\theta\\) saranno tutti in qualche misura imprecisi.\nCombinando queste due equazioni, otteniamo l’Equazione della Scienza:\n\\[\ny = f(x, \\theta) + \\varepsilon_\\text{model} + \\varepsilon_y.\n\\]\nLa scienza è il tentativo di spiegare le osservazioni \\(y\\) utilizzando un modello \\(f\\), cercando di minimizzare l’errore di misurazione \\(\\varepsilon_y\\) e l’errore del modello \\(\\varepsilon_\\text{model}\\), in modo che il modello possa essere utilizzato per fare previsioni sul mondo reale (\\(z\\)). L’approccio bayesiano alla scienza riconosce e quantifica le incertezze su tutti e sei gli elementi dell’Equazione della Scienza: \\(y\\), \\(f\\), \\(x\\), \\(\\theta\\), \\(\\varepsilon_\\text{model}\\) e \\(\\varepsilon_y\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#introduzione",
    "href": "chapters/key_notions/04_measurement.html#introduzione",
    "title": "4  La misurazione in psicologia",
    "section": "",
    "text": "Panoramica del capitolo\n\nProprietà delle scale di misura di Stevens.\nQuali operazioni aritmetiche possono essere applicate a ciascun livello di scala e perchè.\nDistinguere tra variabili continue e discrete.\nComprendere il concetto di bias.\n\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere On the philosophical foundations of psychological measurement (Maul et al., 2016) sui fondamenti filosofici della misurazione psicologica.\nLeggere Psychological Measurement and the Replication Crisis: Four Sacred Cows (Lilienfeld & Strother, 2020). Questo articolo mette in relazione le proprietà delle misure psicologiche con la crisi della replicabilità dei risultati della ricerca.\nLeggere il Appendice E dell’Appendice.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#la-teoria-della-misurazione",
    "href": "chapters/key_notions/04_measurement.html#la-teoria-della-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.2 La teoria della misurazione",
    "text": "4.2 La teoria della misurazione\nLa teoria della misurazione, oggetto di questo capitolo, si concentra sull’errore di misurazione e sull’equazione fondamentale \\(y = z + \\varepsilon_y\\). Questa equazione può essere esaminata da tre prospettive distinte. La prima concerne l’affidabilità della misura, rappresentata dal termine \\(\\varepsilon_y\\). La psicometria, branca dedicata alla teoria della misurazione psicologica, si occupa di quantificare l’affidabilità delle misure psicologiche attraverso metodi come la Teoria Classica dei Test e la Teoria di Risposta all’Item.\nLa seconda prospettiva riguarda la validità delle misure psicologiche, ovvero quanto adeguatamente la misura \\(y\\) rappresenti il costrutto \\(z\\). Questo aspetto, più complesso dell’affidabilità, non può essere risolto meramente con metodi statistici, ma richiede una profonda comprensione delle teorie psicologiche e della loro capacità di descrivere e prevedere i fenomeni psicologici.\nLa terza prospettiva si concentra sulle procedure di assegnazione dei valori a \\(y\\), esplorando quali metodi (questionari, interviste, esperimenti) siano più appropriati e come valutarne l’adeguatezza.\n\n4.2.1 Costrutti psicologici\nLa teoria della misurazione sottolinea l’importanza di distinguere tra la procedura di misurazione e il costrutto che si intende misurare. Ad esempio, mentre la temperatura è un costrutto, il termometro è lo strumento di misurazione. Analogamente, l’abilità matematica è un costrutto, mentre un test di matematica è la procedura per misurarla.\nNelle scienze psicologiche e sociali, la misurazione presenta sfide uniche rispetto alle scienze fisiche, poiché i costrutti in esame sono spesso astratti e non direttamente osservabili. Ciò richiede una particolare attenzione alla validità e all’affidabilità degli strumenti di misurazione, nonché una costante riflessione sulle limitazioni e le potenziali fonti di errore.\nIl capitolo introduce concetti fondamentali relativi alla misurazione quantitativa delle caratteristiche psicologiche, con un focus sulla teoria delle scale di misura di Stevens (1946). Questa teoria fornisce un quadro concettuale per comprendere i diversi tipi di scale di misurazione e le operazioni matematiche appropriate per ciascuna. Inoltre, vengono esplorate alcune procedure di scaling psicologico, ovvero l’assegnazione di numeri all’intensità di fenomeni psicologici.\n\n\n4.2.2 Scaling psicologico\nLo scaling psicologico si occupa della trasformazione dei dati empirici raccolti durante uno studio psicologico in misure o punteggi che rappresentino accuratamente le caratteristiche psicologiche oggetto di indagine.\nScaling di Guttman. Uno dei metodi di scaling più noti è lo «Scaling di Guttman», che viene utilizzato per rappresentare relazioni ordinate tra gli elementi di una scala. Ad esempio, in un questionario sui sintomi dell’ansia, le domande possono essere disposte in ordine di intensità crescente dei sintomi. Secondo il modello di Guttman, se un partecipante risponde “sì” a una domanda che riflette un sintomo più intenso, ci si aspetta che abbia risposto “sì” anche a tutte le domande precedenti, che rappresentano sintomi di intensità minore. Questo approccio consente di costruire una scala che riflette in modo sistematico e coerente la gravità dei sintomi.\nScaling Thurstoniano. Lo «Scaling Thurstoniano» è un metodo utilizzato per misurare preferenze o giudizi soggettivi. Ad esempio, per valutare la preferenza tra diversi tipi di cibi, i partecipanti confrontano due cibi alla volta ed esprimono una preferenza. Le risposte vengono poi utilizzate per assegnare punteggi che riflettono la preferenza media per ciascun cibo.\nScaling Fechneriano. Lo scaling fechneriano si basa sulla legge di Fechner, secondo cui la percezione di uno stimolo aumenta in modo logaritmico rispetto alla sua intensità fisica. La misura fondamentale è la JND (Just Noticeable Difference), ovvero la minima differenza percepibile tra due stimoli. Secondo Fechner, sommando le JND si ottiene una scala psicologica dell’intensità percepita, utile per studiare grandezze sensoriali come luminosità, peso e suono (per es., Domini & Caudek, 2009).\nQuestionari Likert. I questionari Likert richiedono ai partecipanti di esprimere il loro grado di accordo con una serie di affermazioni su una scala a più livelli, che va da «fortemente in disaccordo» a «fortemente d’accordo». I punteggi ottenuti vengono sommati per rappresentare la posizione complessiva dell’individuo rispetto all’oggetto di studio.\n\n\n4.2.3 Metodi di valutazione delle scale psicologiche\nPer valutare le proprietà delle scale psicologiche, vengono utilizzati vari metodi. Ad esempio, l’affidabilità delle misure può essere analizzata utilizzando il coefficiente alpha di Cronbach o il coefficiente Omega di McDonald, entrambi utilizzati per misurare la coerenza interna delle risposte ai diversi item di un questionario. Inoltre, la validità delle scale può essere esaminata confrontando i risultati ottenuti con misure simili o attraverso analisi statistiche che verificano se la scala cattura accuratamente il costrutto psicologico che si intende misurare. La validità di costrutto è particolarmente cruciale, poiché riguarda la capacità della scala di misurare effettivamente il concetto psicologico che si intende esplorare.\n\n\n4.2.4 Prospettive moderne\nNegli ultimi anni, il dibattito sulla misurazione psicologica si è arricchito di nuove prospettive, grazie all’avvento di tecnologie avanzate e all’integrazione di approcci interdisciplinari. Ecco alcune delle tendenze più rilevanti.\nTeoria della Risposta agli Item. La Teoria della Risposta agli Item (IRT) ha guadagnato popolarità per la sua capacità di fornire stime più precise delle abilità latenti rispetto ai modelli classici. La IRT considera la probabilità che un individuo risponda correttamente a un item in funzione della sua abilità e delle caratteristiche dell’item stesso, offrendo una visione più dettagliata delle proprietà psicometriche degli strumenti di misurazione.\nApprocci Bayesiani. Gli approcci bayesiani stanno rivoluzionando il campo della psicometria, permettendo di incorporare informazioni a priori nelle stime e di aggiornare le credenze sulla base di nuovi dati. Questi metodi sono particolarmente utili per affrontare la complessità e l’incertezza inerenti alla misurazione psicologica.\nAnalisi di Rete. L’analisi di rete è un’altra metodologia emergente che vede i costrutti psicologici non come variabili latenti indipendenti, ma come reti di sintomi interconnessi. Questo approccio può offrire nuove intuizioni sulla struttura delle psicopatologie e sulla dinamica dei sintomi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#le-scale-di-misurazione",
    "href": "chapters/key_notions/04_measurement.html#le-scale-di-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.3 Le scale di misurazione",
    "text": "4.3 Le scale di misurazione\nLe scale di misurazione sono strumenti fondamentali per assegnare numeri ai dati osservati, rappresentando le proprietà psicologiche. La teoria delle scale di Stevens (1946) identifica quattro tipi di scale di misurazione: nominali, ordinali, a intervalli e di rapporti. Ognuna di queste scale consente di effettuare operazioni aritmetiche diverse, poiché ciascuna di esse è in grado di “catturare” solo alcune delle proprietà dei fenomeni psicologici che si intende misurare.\n\n\n\nScale di misurazione.\n\n\n\n4.3.1 Scala nominale\nLa scala nominale è il livello di misurazione più semplice e corrisponde ad una tassonomia o classificazione delle categorie che utilizziamo per descrivere i fenomeni psicologici. I simboli o numeri che costituiscono questa scala rappresentano i nomi delle categorie e non hanno alcun valore numerico intrinseco. Con la scala nominale possiamo solo distinguere se una caratteristica psicologica è uguale o diversa da un’altra.\nI dati raccolti con la scala nominale sono suddivisi in categorie qualitative e mutuamente esclusive, in cui ogni dato appartiene ad una sola categoria. In questa scala, esiste solo la relazione di equivalenza tra le misure delle unità di studio: gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti.\nL’unica operazione algebrica consentita dalla scala nominale è quella di contare le unità di studio che appartengono ad ogni categoria e il numero totale di categorie. Di conseguenza, la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nDalla scala nominale è possibile costruire altre scale nominali equivalenti alla prima, trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle categorie, ma lasciando inalterata la suddivisione delle unità di studio nelle medesime classi di equivalenza. In altre parole, cambiando i nomi delle categorie di una variabile misurata su scala nominale, si ottiene una nuova variabile esattamente equivalente alla prima.\n\n\n4.3.2 Scala ordinale\nLa scala ordinale mantiene la caratteristica della scala nominale di classificare ogni unità di misura all’interno di una singola categoria, ma introduce la relazione di ordinamento tra le categorie. In quanto basata su una relazione di ordine, una scala ordinale descrive solo il rango di ordine tra le categorie e non fornisce informazioni sulla distanza tra di esse. Non ci dice, ad esempio, se la distanza tra le categorie \\(a\\) e \\(b\\) è uguale, maggiore o minore della distanza tra le categorie \\(b\\) e \\(c\\).\nUn esempio classico di scala ordinale è quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed è scalfito da quello di livello superiore.\n\n\n\nLa scala di durezza dei minerali di Mohs. Un oggetto è considerato più duro di X se graffia X. Sono incluse anche misure di durezza relativa utilizzando uno sclerometro, da cui emerge la non linearità della scala di Mohs (Burchard, 2004).\n\n\n\n\n4.3.3 Scala ad intervalli\nLa scala ad intervalli di misurazione include le proprietà della scala nominale e della scala ordinale e permette di misurare le distanze tra le coppie di unità statistiche in termini di un intervallo costante, chiamato “unità di misura”, a cui viene attribuito il valore “1”. L’origine della scala, ovvero il punto zero, è scelta arbitrariamente e non indica l’assenza della proprietà che si sta misurando. Ciò significa che la scala ad intervalli consente anche valori negativi e lo zero non viene attribuito all’unità statistica in cui la proprietà risulta assente.\nLa scala ad intervalli equivalenti consente l’esecuzione di operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non possibili con le scale di misura nominale o ordinale. Tuttavia, il limite della scala ad intervalli è che non consente di calcolare il rapporto tra coppie di misure. È possibile affermare la differenza tra \\(a\\) e \\(b\\) come la metà della differenza tra \\(c\\) e \\(d\\) o che le due differenze sono uguali, ma non è possibile affermare che \\(a\\) abbia una proprietà misurata in quantità doppia rispetto a \\(b\\). In altre parole, non è possibile stabilire rapporti diretti tra le misure ottenute. Solo le differenze tra le modalità permettono tutte le operazioni aritmetiche, come la somma, l’elevazione a potenza o la divisione, che sono alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l’unità di misura è arbitraria e può essere cambiata attraverso una dilatazione, ovvero la moltiplicazione di tutti i valori della scala per una costante positiva. Inoltre, la traslazione, ovvero l’aggiunta di una costante a tutti i valori della scala, è ammessa poiché non altera le differenze tra i valori della scala. La scala rimane invariata rispetto a traslazioni e dilatazioni e dunque le uniche trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b &gt; 0.\n\\]\nInfatti, l’uguaglianza dei rapporti fra gli intervalli rimane invariata a seguito di una trasformazione lineare.\nEsempio di scala ad intervalli è la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è possibile stabilire se due modalità sono uguali o diverse: \\(30^\\circ C \\neq 20^\\circ C\\). Come per la scala ordinale è possibile mettere due modalità in una relazione d’ordine: \\(30^\\circ C &gt; 20^\\circ C\\). In aggiunta ai casi precedenti, però, è possibile definire una unità di misura per cui è possibile dire che tra \\(30^\\circ C\\) e \\(20^\\circ C\\) c’è una differenza di \\(30^\\circ - 20^\\circ = 10^\\circ C\\). I valori di temperatura, oltre a poter essere ordinati secondo l’intensità del fenomeno, godono della proprietà che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di \\(80^\\circ C\\) non è il doppio di una di \\(40^\\circ C\\). Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, \\(20^\\circ C = 68^\\circ F\\) e \\(40^\\circ C = 104^\\circ F\\). Questo significa che la relazione “il doppio di” che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla proprietà misurata (cioè la temperatura). La decisione di che scala usare (Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realtà empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\nÈ facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n\n4.3.4 Scala di rapporti\nNella scala a rapporti equivalenti, lo zero non è arbitrario e rappresenta l’elemento che ha intensità nulla rispetto alla proprietà misurata. Per costruire questa scala, si associa il numero 0 all’elemento con intensità nulla e si sceglie un’unità di misura \\(u\\). Ad ogni elemento si assegna un numero \\(a\\) definito come \\(a = d / u\\), dove \\(d\\) rappresenta la distanza dall’origine. In questo modo, i numeri assegnati riflettono le differenze e i rapporti tra le intensità della proprietà misurata.\nIn questa scala, è possibile effettuare operazioni aritmetiche non solo sulle differenze tra i valori della scala, ma anche sui valori stessi della scala. L’unica scelta arbitraria è l’unità di misura, ma lo zero deve sempre rappresentare l’intensità nulla della proprietà considerata.\nLe trasformazioni ammissibili in questa scala sono chiamate trasformazioni di similarità e sono del tipo \\(y' = by\\), dove \\(b &gt; 0\\). In questa scala, i rapporti tra i valori rimangono invariati dopo le trasformazioni. In altre parole, se rapportiamo due valori originali e due valori trasformati, il rapporto rimane lo stesso: \\(\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "href": "chapters/key_notions/04_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.4 Gerarchia dei livelli delle scale di misurazione",
    "text": "4.4 Gerarchia dei livelli delle scale di misurazione\nSecondo Stevens (1946), esiste una gerarchia dei livelli delle scale di misurazione, denominati “livelli di scala”. Questi livelli sono organizzati in modo gerarchico, in cui la scala nominale rappresenta il livello più basso della misurazione, mentre la scala a rapporti equivalenti rappresenta il livello più alto.\n\nScala nominale: Classifica le categorie senza un ordine specifico.\nScala ordinale: Classifica le categorie in un ordine specifico, ma senza una misura precisa delle distanze.\nScala a intervalli: Misura le distanze tra le categorie con un intervallo costante, ma senza un punto zero assoluto.\nScala di rapporti: Misura le distanze con un intervallo costante e un punto zero assoluto.\n\n\n\n\nRelazioni tra i livelli di misurazione.\n\n\nPassando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala.\n\n4.4.1 Variabili Discrete e Continue\nLe variabili possono essere classificate come variabili a livello di intervalli o di rapporti e possono essere sia discrete che continue.\n\nVariabili discrete: Assumono valori specifici ma non possono assumere valori intermedi.\nVariabili continue: Possono assumere qualsiasi valore all’interno di un intervallo specificato.\n\n\n\n\nVariabili discrete e continue.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#linterazione-tra-teoria-e-misurazione-nella-ricerca-scientifica",
    "href": "chapters/key_notions/04_measurement.html#linterazione-tra-teoria-e-misurazione-nella-ricerca-scientifica",
    "title": "4  La misurazione in psicologia",
    "section": "4.5 L’interazione tra teoria e misurazione nella ricerca scientifica",
    "text": "4.5 L’interazione tra teoria e misurazione nella ricerca scientifica\n\n4.5.1 Un caso di studio sul mind-body healing\nPer capire perché la misurazione in psicologia non possa essere ridotta a una semplice attribuzione di numeri, consideriamo un esempio recente. Uno studio sul mind-body healing, pubblicato su Nature Aungle & Langer (2023), riportava un’associazione tra pratiche mente-corpo e miglioramenti della salute fisica. Tuttavia, l’articolo è stato oggetto di severe critiche metodologiche, in particolare da parte dello statistico Andrew Gelman, che ha discusso i limiti del lavoro sul blog Statistical Modeling.\nQuesto caso è istruttivo perché mette in luce due aspetti fondamentali della ricerca scientifica:\n\nil ruolo indispensabile della teoria;\nl’importanza della misurazione accurata.\n\n\n\n4.5.2 Il ruolo della teoria\nGelman evidenzia come il problema principale dello studio sia la mancanza di un quadro teorico robusto. Per esempio:\n\ncosa si intende esattamente con “guarigione mente-corpo”?\nquali meccanismi psicologici o biologici potrebbero spiegarne gli effetti?\ncome si collega questa ipotesi a conoscenze già consolidate in neuroscienze, immunologia o psicologia della salute?\n\nSenza una teoria che fornisca definizioni chiare e collegamenti plausibili, i dati raccolti rischiano di essere solo numeri isolati, privi di reale significato. In questo senso, la teoria non è un “ornamento”, ma una condizione necessaria per formulare ipotesi verificabili e interpretare correttamente i risultati.\n\n\n4.5.3 I problemi della misurazione\nAccanto alle debolezze teoriche, lo studio presenta limiti importanti sul piano della misurazione.\n\nValidità degli strumenti: l’uso di scale non validate e di misure che non tengono conto di fattori come l’effetto placebo compromette la solidità delle conclusioni.\nValidità interna: il disegno sperimentale non garantiva un controllo adeguato delle variabili (assenza di blinding, randomizzazione debole), riducendo la credibilità delle inferenze causali.\nValidità esterna: campioni non rappresentativi rendono difficile generalizzare i risultati.\n\nQuando la misurazione non è accurata, si introduce “rumore” nei dati, che può nascondere relazioni reali o, peggio, generare correlazioni illusorie.\n\n\n4.5.4 Un approccio integrato\nQuesto esempio ci mostra che teoria e misurazione devono procedere insieme. Trascurare la teoria porta a un empirismo ingenuo, che raccoglie dati senza domande chiare. Trascurare la misurazione porta a costruire teorie su basi fragili. La scienza avanza invece grazie a un circolo virtuoso: la teoria guida la raccolta dei dati, e i dati aiutano a raffinare la teoria.\nPer lo psicologo, questo significa sviluppare:\n\nconsapevolezza epistemologica, per distinguere tra spiegazioni plausibili e arbitrarie;\ncompetenze metodologiche, per riconoscere quando una misura è valida, affidabile e adatta al fenomeno studiato.\n\nSolo così possiamo distinguere la ricerca scientifica solida dalla pseudoscienza e contribuire a un progresso realmente cumulativo.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#riflessioni-conclusive",
    "href": "chapters/key_notions/04_measurement.html#riflessioni-conclusive",
    "title": "4  La misurazione in psicologia",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa misurazione in psicologia non è un semplice atto di raccolta di dati, ma un processo fondamentale per garantire che le osservazioni empiriche siano interpretabili alla luce di modelli teorici solidi. Una buona misurazione non si limita a ridurre l’errore, ma consente di attribuire un significato coerente ai punteggi ottenuti, facilitando così il progresso della conoscenza scientifica. Senza strumenti adeguati per la misurazione, il rischio è quello di costruire teorie su basi incerte, compromettendo la validità delle conclusioni tratte.\nDue pilastri sostengono dunque una ricerca psicologica rigorosa: la teoria e la misurazione. La teoria fornisce il quadro concettuale entro cui si interpretano i dati, definendo le ipotesi e orientando le analisi. La misurazione, invece, è il ponte tra i costrutti astratti e le osservazioni empiriche, traducendo concetti complessi in variabili operative affidabili. Nessuna delle due componenti può reggersi senza l’altra: una teoria senza misurazione adeguata rischia di rimanere speculativa, mentre una misurazione priva di un solido fondamento teorico può portare a dati privi di significato.\nNella valutazione di un qualsiasi studio psicologico, un approccio critico richiede quindi di esaminare sia la solidità del quadro teorico sia la qualità degli strumenti di misurazione adottati. Il progresso della ricerca dipende dalla capacità di integrare questi due elementi, attraverso metodologie che riducano l’incertezza e migliorino la precisione delle inferenze. Le moderne tecniche di analisi dei dati, i modelli psicometrici avanzati e le tecnologie digitali stanno ampliando le possibilità di misurazione, offrendo strumenti più sensibili e adattabili alla complessità dei fenomeni psicologici. Tuttavia, la sfida principale rimane la stessa: garantire che la misurazione sia non solo accurata, ma anche teoricamente fondata, affinché le conoscenze acquisite possano davvero contribuire alla comprensione della mente e del comportamento umano.\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Identificazione del Livello di Misurazione\nObiettivo: Comprendere i diversi livelli di misurazione applicati alla psicologia.\n\nIdentifica il livello di misurazione (nominale, ordinale, intervalli, rapporti) per ciascuna delle seguenti variabili psicologiche:\n\n\nTipo di terapia psicologica (Cognitivo-comportamentale, Psicodinamica, Umanistica)\n\n\nLivello di ansia auto-riferito su una scala da 1 a 10\n\n\nNumero di episodi depressivi in un anno\n\n\nTempo di reazione in millisecondi in un test cognitivo\n\n\n\nEsercizio 2: Confronto tra Scale\nObiettivo: Comprendere le differenze tra le scale di misurazione.\n\nSpiega la differenza tra una scala ordinale e una scala a intervalli utilizzando l’esempio della soddisfazione lavorativa.\nPerché il punteggio QI è misurato su una scala a intervalli e non su una scala a rapporti?\nIn che modo il punteggio di una scala di autostima su una scala Likert differisce da una misurazione su una scala di rapporti?\n\nEsercizio 3: Operazioni Aritmetiche Consentite\nObiettivo: Comprendere le operazioni matematiche consentite per ciascun livello di misurazione.\n\nQuali operazioni aritmetiche sono ammissibili per una scala nominale?\nPuò avere senso calcolare la media di punteggi su una scala ordinale? Perché?\nSe hai misurato il tempo di reazione in secondi, quali operazioni aritmetiche puoi eseguire?\n\nEsercizio 4: Trasformazioni Ammissibili\nObiettivo: Comprendere le trasformazioni possibili per ogni scala di misurazione.\n\nSe una variabile è misurata su una scala nominale, quale tipo di trasformazione è consentita?\nPer una scala a intervalli, quali trasformazioni matematiche sono permesse senza alterare le proprietà della scala?\nQuale tipo di trasformazione è consentita su una scala di rapporti?\n\nEsercizio 5: Applicazione delle Scale a Dati Psicologici\nObiettivo: Applicare i concetti a contesti psicologici reali.\n\nUna scala di ansia clinica fornisce punteggi compresi tra 0 e 100. Quale livello di misurazione è più appropriato e perché?\nUn esperimento misura la memoria dichiarativa chiedendo ai partecipanti di ricordare un elenco di parole. Come dovrebbe essere misurata la variabile “numero di parole ricordate”?\nIn uno studio sulla personalità, i tratti vengono classificati come “estroverso” e “introverso”. Qual è il livello di misurazione?\n\nEsercizio 6: Valutazione della Scala di Misurazione\nObiettivo: Identificare la corretta scala di misurazione per vari fenomeni psicologici.\n\nIl livello di aggressività misurato su una scala da 1 a 5 è nominale, ordinale, intervalli o rapporti? Giustifica la tua risposta.\nIl numero di attacchi di panico in una settimana può essere considerato su scala ordinale? Perché sì o perché no?\nUn test di intelligenza misura il QI con una media di 100 e una deviazione standard di 15. Qual è il livello di misurazione e quali sono le implicazioni per l’analisi statistica?\n\nEsercizio 7: Costruzione di una Scala Psicologica\nObiettivo: Creare una scala di misurazione per una variabile psicologica.\n\nSe dovessi costruire una scala per misurare la resilienza, quale livello di misurazione sceglieresti e perché?\nCome potresti trasformare una scala nominale di preferenza musicale in una scala ordinale?\nUn questionario sulla qualità della vita chiede ai partecipanti di valutare la loro felicità su una scala da 1 a 10. È una scala a intervalli o ordinale? Giustifica.\n\nEsercizio 8: Interpretazione Statistica dei Dati\nObiettivo: Collegare il livello di misurazione alle tecniche statistiche appropriate.\n\nPerché una mediana è più appropriata della media per dati ordinali?\nQuale test statistico sarebbe più adatto per confrontare due gruppi su una variabile nominale?\nQuali analisi possono essere condotte su dati raccolti su una scala a rapporti?\n\nEsercizio 9: Misurazione e Inferenze Psicologiche\nObiettivo: Riflettere su come il livello di misurazione influisce sulle conclusioni di una ricerca.\n\nSe un test di personalità usa una scala Likert da 1 a 7, quali precauzioni devono essere prese nell’interpretare le differenze tra punteggi?\nUn questionario di benessere assegna punteggi tra 0 e 100, ma non ha uno zero assoluto. Quale scala è questa e quali sono le limitazioni?\nIn uno studio sulla depressione, i sintomi vengono codificati come “assenti”, “moderati” o “gravi”. Che tipo di scala è questa e quali statistiche possono essere usate per analizzarla?\n\nEsercizio 10: Esperimenti Psicologici e Misurazione\nObiettivo: Applicare la teoria della misurazione nella progettazione di esperimenti psicologici.\n\nSe un esperimento misura la memoria a breve termine con un compito di richiamo di parole, quale scala di misurazione utilizzeresti?\nCome la scelta della scala di misurazione può influenzare le inferenze che si possono trarre da un esperimento?\nQuali tipi di analisi statistica sono appropriati per dati misurati su scala ordinale rispetto a scala di rapporti?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Identificazione del Livello di Misurazione\nObiettivo: Comprendere i diversi livelli di misurazione applicati alla psicologia.\n\nIdentifica il livello di misurazione (nominale, ordinale, intervalli, rapporti) per ciascuna delle seguenti variabili psicologiche:\n\n\nNominale (Tipo di terapia psicologica è una classificazione senza ordine)\n\n\nOrdinale (Scala da 1 a 10, con ordine ma senza distanze uguali)\n\n\nRapporti (Numero di episodi depressivi ha uno zero assoluto e si possono fare rapporti tra valori)\n\n\nRapporti (Tempo di reazione ha uno zero assoluto e permette operazioni di rapporto)\n\n\n\nEsercizio 2: Confronto tra Scale\nObiettivo: Comprendere le differenze tra le scale di misurazione.\n\nLa scala ordinale fornisce un ordine ma non permette di calcolare differenze precise, mentre la scala a intervalli ha differenze costanti tra i valori. Ad esempio, “soddisfazione lavorativa” su una scala da 1 a 5 è ordinale, mentre il punteggio di un test psicologico è a intervalli.\nIl punteggio QI è a intervalli perché la differenza tra punteggi è significativa, ma non ha uno zero assoluto che rappresenta l’assenza di intelligenza.\nUna scala Likert misura il livello di accordo con una dichiarazione, quindi è generalmente considerata ordinale, nonostante sia trattata spesso come una scala a intervalli.\n\nEsercizio 3: Operazioni Aritmetiche Consentite\nObiettivo: Comprendere le operazioni matematiche consentite per ciascun livello di misurazione.\n\nNella scala nominale si può solo contare la frequenza delle categorie (ad es., il numero di partecipanti che usano un tipo di terapia).\nNo, la media su dati ordinali può essere fuorviante perché le distanze tra le categorie non sono necessariamente uguali. Meglio usare la mediana.\nSul tempo di reazione si possono eseguire tutte le operazioni aritmetiche, inclusa la media, la moltiplicazione e i rapporti tra valori.\n\nEsercizio 4: Trasformazioni Ammissibili\nObiettivo: Comprendere le trasformazioni possibili per ogni scala di misurazione.\n\nSulla scala nominale, solo le trasformazioni di ricodifica (ad esempio, cambiare i nomi delle categorie) sono permesse.\nPer una scala a intervalli, si possono effettuare trasformazioni lineari della forma y’ = a + by con b &gt; 0.\nPer una scala di rapporti, sono consentite trasformazioni di similarità della forma y’ = by, dove b &gt; 0.\n\nEsercizio 5: Applicazione delle Scale a Dati Psicologici\nObiettivo: Applicare i concetti a contesti psicologici reali.\n\nScala a intervalli, perché ha differenze costanti tra i punteggi ma nessuno zero assoluto.\nScala di rapporti, perché il numero di parole ricordate ha uno zero assoluto e consente operazioni di rapporto.\nNominale, perché non vi è un ordine gerarchico tra le categorie “estroverso” e “introverso”.\n\nEsercizio 6: Valutazione della Scala di Misurazione\nObiettivo: Identificare la corretta scala di misurazione per vari fenomeni psicologici.\n\nOrdinale, perché il livello di aggressività segue un ordine, ma le differenze tra i livelli non sono necessariamente uguali.\nNo, perché il numero di attacchi di panico è una variabile discreta e misurabile su scala di rapporti.\nIntervalli, perché il punteggio QI ha distanze costanti tra i valori, ma non ha uno zero assoluto.\n\nEsercizio 7: Costruzione di una Scala Psicologica\nObiettivo: Creare una scala di misurazione per una variabile psicologica.\n\nOrdinale o a intervalli, a seconda della precisione della misurazione della resilienza.\nSi potrebbe assegnare un valore numerico crescente alle categorie di preferenza musicale per ottenere una scala ordinale.\nÈ una scala ordinale, perché la differenza tra livelli non è necessariamente costante.\n\nEsercizio 8: Interpretazione Statistica dei Dati\nObiettivo: Collegare il livello di misurazione alle tecniche statistiche appropriate.\n\nPerché la mediana è meno sensibile ai valori estremi rispetto alla media.\nUn test chi-quadrato è adatto per confrontare frequenze di dati nominali tra gruppi.\nSi possono calcolare media, deviazione standard e utilizzare test parametrici come t-test o ANOVA.\n\nEsercizio 9: Misurazione e Inferenze Psicologiche\nObiettivo: Riflettere su come il livello di misurazione influisce sulle conclusioni di una ricerca.\n\nI punteggi Likert sono ordinali, quindi confronti tra differenze di punteggio devono essere interpretati con cautela.\nIntervalli, perché non ha uno zero assoluto, il che limita l’uso di operazioni moltiplicative.\nOrdinale, e si possono usare test non parametrici come il test di Kruskal-Wallis o il test di Mann-Whitney.\n\nEsercizio 10: Esperimenti Psicologici e Misurazione\nObiettivo: Applicare la teoria della misurazione nella progettazione di esperimenti psicologici.\n\nRapporti, perché il numero di parole ricordate è una variabile discreta con uno zero assoluto.\nSe si usa una scala ordinale, bisogna essere cauti nell’uso della media e della deviazione standard.\nScala ordinale → test non parametrici (Mann-Whitney); scala di rapporti → test parametrici (t-test, ANOVA).\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio 1 – Teoria Sostanziale e “Junk Science”\nObiettivo: Riconoscere il ruolo di una teoria sostanziale solida e comprendere come la sua assenza possa compromettere uno studio.\n\nLeggi la sezione in cui Gelman critica l’assenza di una teoria solida nello studio sulle pratiche mente-corpo.\n\nSpiega, in massimo 10 righe, perché secondo Gelman la mancanza di una teoria coerente rende i risultati del suddetto studio “poco significativi” o addirittura “junk science”.\n\nProponi un esempio ipotetico (non correlato al mind-body healing) di uno studio psicologico che, pur presentando dati numerosi e analizzati con metodi statistici sofisticati, risulti privo di una teoria solida. Descrivi sinteticamente perché questo potrebbe rientrare nel concetto di “junk science”.\n\nEsercizio 2 – Problemi di Misurazione\nObiettivo: Identificare le criticità più comuni nella misurazione dei fenomeni psicologici.\n\nElenca almeno tre possibili fattori confondenti che potrebbero influenzare la misurazione dell’efficacia di un intervento psicologico (ad esempio, l’effetto placebo, le aspettative dei partecipanti, ecc.).\n\nSpiega come questi fattori confondenti potrebbero compromettere la validità interna dello studio.\n\nIndica almeno due caratteristiche fondamentali che una buona scala di misurazione (per una variabile psicologica) dovrebbe possedere per essere ritenuta affidabile e valida.\n\nEsercizio 3 – Precisione e Bias\nObiettivo: Chiarire la distinzione tra precisione e distorsione (bias) e come questi aspetti si riflettano nella validità delle conclusioni.\n\nDefinisci, con parole tue, i concetti di precisione e bias in ambito psicometrico.\nFornisci un esempio concreto di uno strumento di misura preciso ma distorto (bias elevato) e di uno strumento poco preciso ma non distorto (bias basso).\n\nSpiega come la combinazione di scarsa precisione e alto bias possa influire sulla possibilità di trarre conclusioni affidabili in uno studio psicologico.\n\nEsercizio 4 – Validità Interna ed Esterna\nObiettivo: Approfondire come le scelte di misurazione influiscano sulla validità interna ed esterna di uno studio.\n\nIn riferimento allo studio sul mind-body healing discusso nel capitolo, identifica due fattori che potrebbero compromettere la validità interna e due fattori che potrebbero limitarne la validità esterna.\n\nDescrivi in 5-8 righe le differenze principali tra validità interna e validità esterna, utilizzando esempi presi sia dal contesto della guarigione mente-corpo sia da altri contesti psicologici (ad esempio, studi sull’apprendimento o sulla motivazione).\n\nProponi una modifica al disegno di ricerca (ipotetico) che potrebbe migliorare la validità interna dello studio originale. Spiega brevemente come questa modifica ne influenzerebbe anche la validità esterna.\n\nEsercizio 5 – Integrare Teoria e Misurazione: Breve Progetto di Ricerca\nObiettivo: Mettere in pratica i concetti di teoria e misurazione attraverso la progettazione di uno studio.\n\nImmagina di voler condurre uno studio su un intervento di “training di rilassamento mentale” finalizzato a ridurre l’ansia negli studenti universitari.\n\nSviluppa una breve traccia di progetto (massimo 15 righe) rispondendo ai seguenti punti:\n\nTeoria di base: Qual è la teoria sostanziale dietro l’efficacia del training di rilassamento? Quali meccanismi psicologici verrebbero attivati?\n\nIpotesi: Quale effetto prevedi sull’ansia degli studenti?\n\nMisurazione: Che tipo di strumento useresti per valutare il livello di ansia e perché (ad esempio, questionari self-report validati, misure fisiologiche come battito cardiaco, ecc.)?\n\nControllo dei confondenti: Quali variabili secondarie possono influire sui risultati e come intendi gestirle?\n\nValidità: Come assicureresti una buona validità interna? Che strategie adotteresti per aumentare la validità esterna?\n\nSpiega brevemente in che modo la combinazione di un solido quadro teorico e di una misurazione accurata permette di evitare che lo studio venga etichettato come “junk science”.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 1 – Teoria Sostanziale e “Junk Science”\n\nPerché la mancanza di una teoria solida rende i risultati poco significativi?\n\n\nGelman critica lo studio sul mind-body healing perché non vi è un modello teorico convincente che spieghi il meccanismo causale tra pratiche mente-corpo e miglioramenti di salute.\n\nSenza un quadro teorico robusto, i risultati sono interpretati in modo esplorativo e rischiano di essere attribuiti a variabili non controllate (effetto placebo, regressione alla media, ecc.).\n\nUna teoria ben formulata aiuta a delimitare le ipotesi, guidare il disegno di ricerca e interpretare correttamente i dati. In assenza di ciò, i numeri raccolti potrebbero essere viziati da fattori confondenti o da semplici correlazioni spurious.\n\n\n“Junk science” in massimo 10 righe\n\n\nEsempio di testo in 10 righe (circa)\n**Lo studio sul mind-body healing viene talvolta definito “junk science” da Gelman perché, in mancanza di una teoria sostanziale solida, i dati raccolti non forniscono indicazioni chiare sui processi psicologici o fisiologici coinvolti. Una ricerca classificata come “junk science” è priva di rigore metodologico o teorico, e può presentare gravi problemi di replicabilità o di interpretazione dei risultati. In particolare, se non vi è un modello plausibile che colleghi in modo coerente la pratica mente-corpo ai cambiamenti in variabili biologiche e comportamentali, i risultati empirici rischiano di essere semplici coincidenze. L’assenza di un costrutto ben definito e di ipotesi derivanti da una teoria coerente rende difficile capire se i cambiamenti osservati siano reali, casuali o dovuti ad altre cause non considerate (per esempio, l’effetto placebo). Infine, senza un’adeguata cornice teorica, gli studiosi non sanno come interpretare o generalizzare i dati, e la scienza non progredisce realmente.*\n\n\nEsempio di uno studio privo di teoria solida (ipotesi di “junk science”)\n\n\nSituazione ipotetica: Uno studio che raccoglie decine di variabili sulla personalità e sul benessere, poi usa tecniche statistiche sofisticate (analisi di big data, reti neurali, ecc.) per trovare correlazioni fra i tratti di personalità e centinaia di indicatori fisici.\nPerché “junk science”: Se lo studio non definisce a priori quali ipotesi testare e non ha una teoria chiara che spieghi perché certe caratteristiche di personalità dovrebbero correlarsi con determinati parametri fisici, i risultati trovati potrebbero essere frutto di coincidenze casuali. Inoltre, in assenza di un modello teorico solido, anche risultati statisticamente significativi possono essere privi di significato dal punto di vista psicologico.\n\nEsercizio 2 – Problemi di Misurazione\n\nTre possibili fattori confondenti nell’efficacia di un intervento psicologico\n\n\nEffetto placebo: I partecipanti migliorano perché si aspettano di migliorare, non per l’effettiva efficacia dell’intervento.\n\nAspettative dei partecipanti: Se sanno di partecipare a uno studio, potrebbero modificare il proprio comportamento (effetto Hawthorne).\n\nDesiderabilità sociale: I partecipanti forniscono risposte che ritengono socialmente desiderabili, falsando i risultati (ad esempio, sottostimando i livelli di ansia o stress).\n\n\nCome questi fattori confondenti compromettono la validità interna\n\n\nLa validità interna riguarda il grado in cui è possibile concludere che sia effettivamente la variabile indipendente (l’intervento) a causare le modifiche osservate nella variabile dipendente (es. livelli di ansia).\n\nSe subentrano l’effetto placebo, aspettative non controllate o tendenze alla desiderabilità sociale, diventa difficile stabilire un nesso causale chiaro. Esiste sempre il dubbio che altri processi cognitivi o sociali (non l’intervento in sé) abbiano prodotto il risultato.\n\n\nDue caratteristiche fondamentali di una buona scala di misurazione\n\n\nAffidabilità: Capacità dello strumento di fornire misure stabili e coerenti nel tempo (ad esempio, coerenza interna, stabilità test-retest).\n\nValidità: Capacità dello strumento di misurare effettivamente ciò che si propone di misurare (validità di contenuto, di costrutto, di criterio).\n\nEsercizio 3 – Precisione e Bias\n\nDefinizioni di precisione e bias\n\n\nPrecisione: Indica il grado di dispersione (o variabilità) delle misurazioni. Uno strumento preciso produce misure molto simili fra loro se ripetute nelle stesse condizioni (bassa varianza).\n\nBias (distorsione): Indica l’errore sistematico, ossia la tendenza a sovra- o sottostimare sistematicamente il fenomeno in esame. Uno strumento può essere molto coerente nelle misure, ma se è “tarato” male, darà sempre un risultato distorto.\n\n\nEsempio concreto di misura “precisa ma distorta” e “poco precisa ma non distorta”\n\n\nPrecisa ma distorta: Un cronometro che, a causa di un difetto di fabbricazione, parte sempre con 2 secondi di ritardo ma poi misura i tempi con estrema coerenza. Risultato: tutte le misure saranno molto simili (alta precisione), ma sempre sfasate di 2 secondi (alto bias).\n\nPoco precisa ma non distorta: Un termometro vecchio che a volte segna 36,2°C, altre 36,7°C, altre 37,1°C, senza un pattern sistematico. In media potrebbe risultare vicino ai 36,5°C, quindi senza un bias chiaro, ma con un’alta variabilità tra una misurazione e l’altra (bassa precisione).\n\n\nConseguenze di scarsa precisione e alto bias\n\n\nSe uno strumento è poco preciso (alta variabilità) e altamente distorto (bias elevato), i risultati ottenuti non solo oscillano in modo imprevedibile, ma sono costantemente lontani dal valore “vero”.\n\nIn queste condizioni, le conclusioni diventano inaffidabili, poiché è quasi impossibile distinguere l’effetto reale (casuale o causale) dalle deformazioni introdotte dallo strumento e dall’errore di misura.\n\nEsercizio 4 – Validità Interna ed Esterna\n\nDue fattori che compromettono la validità interna e due fattori che compromettono la validità esterna (nell’esempio del mind-body healing)\n\n\nValidità interna:\n\nAssegnazione non casuale ai gruppi: se i partecipanti scelgono autonomamente di aderire alle pratiche mente-corpo, potrebbero essere più motivati o avere caratteristiche iniziali diverse.\n\nMancata o inadeguata gestione dell’effetto placebo: non sapere se l’intervento “mente-corpo” sia stato percepito come particolarmente “speciale” dai partecipanti può introdurre differenze di aspettativa.\n\nValidità esterna:\n\nCampione non rappresentativo: se lo studio è condotto solo su persone che frequentano un determinato tipo di centro di benessere, i risultati potrebbero non essere generalizzabili all’intera popolazione.\n\nContesto specifico: pratiche mente-corpo svolte in un ambiente estremamente controllato (es. un laboratorio o un ritiro speciale) potrebbero non replicarsi nella vita quotidiana di chiunque.\n\n\n\nDifferenze tra validità interna ed esterna (5-8 righe di esempio)\n\n\nLa validità interna si riferisce alla correttezza del disegno di ricerca nel dimostrare un effetto causale. Un alto livello di validità interna implica che i ricercatori siano ragionevolmente sicuri che l’intervento (ad esempio, una tecnica mente-corpo) abbia causato i risultati osservati (miglioramento della salute). La validità esterna, invece, riguarda la possibilità di generalizzare i risultati a contesti, persone e tempi differenti. Se un intervento è stato testato in condizioni molto specifiche, potrebbe funzionare bene solo in quel contesto e con quel particolare campione. Per esempio, un intervento sul mind-body healing con individui altamente motivati potrebbe non dare gli stessi risultati in una popolazione generalizzata. Allo stesso modo, uno studio sull’apprendimento condotto in un laboratorio altamente controllato potrebbe non riflettere le reali dinamiche di un’aula scolastica.\n\n\nModifica al disegno di ricerca per migliorare la validità interna e conseguenze sulla validità esterna\n\n\nProposta: Introdurre un gruppo di controllo con un intervento placebo o un’attività simile ma priva di contenuto “mente-corpo” (ad es. sessioni di lettura rilassante). In questo modo, si può confrontare l’effetto “specífico” dell’intervento.\nCome influenza la validità interna: Con un gruppo di controllo placebo, diventa più semplice escludere che il miglioramento sia dovuto solo alle aspettative dei partecipanti. Questo riduce il rischio di confondenti e aumenta la validità interna.\nCome influenza la validità esterna: Potrebbe rendere il contesto dello studio più artificiale (un gruppo fa “meditazione”, l’altro legge in silenzio), il che potrebbe ridurre la naturalezza della situazione e potenzialmente limitare la generalizzabilità ad ambienti reali (validità esterna).\n\nEsercizio 5 – Integrare Teoria e Misurazione: Breve Progetto di Ricerca\n\nBreve traccia di progetto: “Training di rilassamento mentale per ridurre l’ansia negli studenti universitari”\n\n\nTeoria di base\nIl training di rilassamento mentale si fonda sul presupposto teorico che le tecniche di riduzione dello stress (es. respirazione consapevole, rilassamento muscolare progressivo) possano agire sui livelli di attivazione fisiologica e sui pensieri intrusivi. Riducendo l’iperattivazione del sistema nervoso simpatico e favorendo uno stato di calma, diminuisce l’ansia percepita.\nIpotesi\nGli studenti che seguono il training di rilassamento per 4 settimane mostreranno una riduzione significativa nei punteggi di ansia, rispetto a un gruppo di controllo che non partecipa al training.\nMisurazione\nUtilizzo di una scala validata come lo STAI (State-Trait Anxiety Inventory) per misurare il livello di ansia pre e post intervento. Possibile integrazione con misure fisiologiche (battito cardiaco a riposo) per avere dati oggettivi.\nControllo dei confondenti\n\nRegistrare la storia clinica dei partecipanti (per escludere coloro che assumono farmaci ansiolitici).\n\nRichiedere che i partecipanti non modifichino drasticamente le proprie abitudini di studio o di vita durante l’intervento.\n\nAssicurarsi che i valutatori non sappiano chi fa parte del gruppo di training o del gruppo di controllo (blinding parziale).\n\nValidità\n\nValidità interna: Uso di un gruppo di controllo e assegnazione casuale (randomizzazione) per assicurare che i due gruppi siano comparabili.\n\nValidità esterna: Inclusione di studenti provenienti da diverse facoltà, così da riflettere una maggiore eterogeneità di popolazione.\n\n\n\nCome teoria solida e misurazione accurata evitano la “junk science”\n\n\nUna solida cornice teorica spiega i meccanismi psicologici e fisiologici che legano l’intervento (training di rilassamento) all’esito (riduzione dell’ansia).\n\nUna misurazione accurata e validata (STAI, misure fisiologiche) riduce errori e distorsioni. Se le misure sono ripetute nel tempo (pre e post), si possono confrontare i cambiamenti effettivi.\n\nIntegrando teoria e misurazione, i risultati assumono un significato scientifico più robusto. Non basta osservare un miglioramento: occorre dimostrare come e perché tale miglioramento avvenga, evitando di cadere in semplici correlazioni prive di spiegazione (e quindi potenzialmente “junk science”).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 – Trasformazioni in Scala Nominale\nSituazione\nUn ricercatore vuole indagare la percezione di appartenenza sociale tra studenti universitari di Psicologia. A ciascuno studente viene chiesto di rispondere alla domanda: “Qual è il gruppo studentesco a cui ritieni di appartenere maggiormente?”, scegliendo una tra le seguenti categorie:\n\n\nGruppo A (focalizzato su ricerca e studio)\n\n\n\nGruppo B (focalizzato su attività ricreative)\n\n\n\nGruppo C (focalizzato su volontariato e progetti sociali)\n\n\nIstruzioni\n\nIdentifica la scala di misurazione utilizzata per classificare gli studenti (nominale, ordinale, a intervalli o di rapporti).\n\nIndica quali trasformazioni sono ammissibili su questa scala e spiega perché non è possibile applicare operazioni di tipo aritmetico (somme, differenze, etc.).\n\nProponi un esempio di nuova scala nominale equivalente, ossia una nuova denominazione delle categorie che rispetti la suddivisione originale. (Esempio: rinominarle in Gruppo X, Gruppo Y, Gruppo Z, oppure usare colori, animali-simbolo, ecc.). Spiega perché questa trasformazione non altera i risultati dell’indagine.\n\nEsercizio 2 – Trasformazioni in Scala Ordinale\nSituazione\nIn un questionario sul benessere psicologico, agli studenti viene chiesto di classificare il loro stato di motivazione allo studio su una scala da 1 (bassa motivazione) a 5 (alta motivazione). Si ottiene così un dato ordinalmente misurato.\nIstruzioni\n\nSpiega perché tale variabile (“livello di motivazione”) rappresenta una scala ordinale. Quali proprietà la rendono diversa da una semplice scala nominale?\n\nDescrivi in che modo è possibile ridenominare i valori della scala (ad esempio, da [1,2,3,4,5] a [“Molto bassa”, “Bassa”, “Media”, “Alta”, “Molto alta”]) senza alterare il rapporto d’ordine tra le categorie.\n\nProponi un esempio di trasformazione non ammissibile: qual è un’operazione aritmetica che non avrebbe senso applicare su una scala ordinale e perché (ad esempio, calcolare “il doppio di motivazione”)?\n\nEsercizio 3 – Trasformazioni in Scala ad Intervalli\nSituazione\nUn gruppo di ricercatori in Psicometria vuole confrontare i punteggi di un test d’intelligenza (misurati secondo la scala tradizionale del QI, con media 100 e deviazione standard 15) con un nuovo test sperimentale. Come ben noto, la scala del QI è considerata, nelle sue approssimazioni psicometriche, una scala ad intervalli.\nIstruzioni\n\nSpiega in cosa consiste la trasformazione lineare ammessa (del tipo \\(y' = a + b y\\), con \\(b &gt; 0\\)) e perché tale trasformazione preserva le differenze tra i punteggi.\n\nFai un esempio concreto di trasformazione lineare: supponi di voler “riscalare” i punteggi del QI in modo che la nuova media sia 50. Definisci i valori di \\(a\\) e \\(b\\) (indicando un’ipotesi di calcolo) e mostra come viene modificato il punteggio di un individuo con QI = 115.\n\nDiscuta perché, nonostante la somiglianza con le scale ordinale e nominale (puoi comunque distinguere punteggi e ordinarli), una scala ad intervalli consente operazioni matematiche più complesse (ad esempio, differenze) che non sarebbero valide negli altri due livelli.\n\nEsercizio 4 – Trasformazioni in Scala di Rapporti\nSituazione\nUn laboratorio di psicofisiologia misura i tempi di reazione (in millisecondi) a uno stimolo luminoso. Poiché il tempo di reazione pari a 0 ms significa realmente assenza di risposta (ovvero, impossibile da misurare in pratica, ma concettualmente corrisponde a intensità nulla del fenomeno “tempo di reazione”), ci troviamo in una scala di rapporti.\nIstruzioni\n\nSpiega perché il tempo di reazione soddisfa i requisiti di una scala di rapporti, inclusa la presenza di uno zero assoluto e la possibilità di confrontare i punteggi con rapporti (ad esempio, “il tempo di reazione del partecipante A è il doppio di quello del partecipante B”).\n\nQuali sono le trasformazioni ammissibili su una scala di rapporti? Fornisci un esempio numerico (per esempio, se moltiplichi tutti i tempi di reazione per 2, che cosa accade al rapporto tra i punteggi di due partecipanti?).\n\nDescrivi il motivo per cui è possibile dire che A ha una latenza doppia di B usando i millisecondi, ma non è sempre possibile fare asserzioni analoghe usando scale ad intervalli. Fai un parallelo, ad esempio, con le temperature in Celsius.\n\nEsercizio 5 – Riconoscere e Applicare le Trasformazioni nei Quattro Livelli di Scala\nSituazione\nUn docente di Psicologia sperimentale ha raccolto quattro serie di dati su vari aspetti:\n\nOrientamento politico (liberale, conservatore, centrista, ecc.).\n\nClassifica di soddisfazione sul tirocinio (1° posto, 2° posto, 3° posto, etc.).\n\nPunteggi di un test di personalità su un fattore (con media = 100, deviazione standard = 10) trattato come scala ad intervalli.\n\nFrequenza cardiaca a riposo misurata in battiti al minuto (bpm).\n\nIstruzioni\n\nIdentifica per ciascuno dei quattro insiemi di dati il livello di scala (nominale, ordinale, intervalli, rapporti).\n\nPer ognuno dei quattro livelli di scala elenca almeno una trasformazione ammessa (ad es. ridenominazione delle categorie per la nominale, traslazione e dilatazione per l’intervalli, ecc.) e una non ammessa (esempio: non puoi sommare categorie nominali, non puoi calcolare la radice quadrata di un rango ordinale dandogli significato, ecc.).\n\nRifletti in breve (2-3 righe) su come queste differenze nelle trasformazioni ammissibili incidano sull’interpretazione dei dati e sulle analisi statistiche che il docente potrà validamente utilizzare (ad esempio, test non parametrici per variabili ordinarie, test parametrici per scale ad intervalli/rapporti).\n\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nEsercizio 1 – Trasformazioni in Scala Nominale\n\nIdentificazione della scala La classificazione degli studenti in “Gruppo A/B/C” è scala nominale. Non esiste alcun ordine intrinseco tra le categorie; si tratta semplicemente di etichette qualitative.\nTrasformazioni ammissibili\n\n\nTrasformazioni ammissibili: ridenominare o rinominare le categorie senza modificare la partizione del campione (esempio: A → “Studio”, B → “Ricreazione”, C → “Volontariato”).\n\nL’unica operazione aritmetica consentita è il conteggio delle frequenze nelle varie categorie.\n\n\nOperazioni non consentite: non è possibile sommare o sottrarre etichette, né confrontare categorie in termini di “più/meno grande” o “rapporto”.\n\n\nEsempio di nuova scala nominale equivalente\n\n\nPotresti chiamare i gruppi: “Alpha, Beta, Gamma” (oppure con colori: “Rosso, Blu, Verde”).\n\nQuesta trasformazione non altera la classificazione in sé: tutti gli studenti del Gruppo A rimangono nel “nuovo” gruppo Alpha, e così via.\n\nNon cambia la struttura dei dati e di conseguenza non altera i risultati della ricerca (restano invariate le frequenze e la suddivisione nelle categorie).\n\nEsercizio 2 – Trasformazioni in Scala Ordinale\n\nPerché è una scala ordinale? La variabile “livello di motivazione” da 1 (bassa) a 5 (alta) indica:\n\n\nClassificazione in categorie (come in una scala nominale).\n\nRelazione d’ordine chiara (1 &lt; 2 &lt; 3 &lt; 4 &lt; 5).\n\nNon fornisce alcuna informazione sulle distanze reali tra i punti (non è detto che la differenza tra 1 e 2 sia uguale a quella tra 3 e 4).\nÈ quindi una scala ordinale e non semplicemente nominale.\n\n\nRidenominazione dei valori mantenendo l’ordine\n\n\nPuoi sostituire i numeri con etichette testuali rispettando lo stesso ordine:\n1 → “Molto bassa”\n2 → “Bassa”\n3 → “Media”\n4 → “Alta”\n5 → “Molto alta”\n\nL’ordine rimane lo stesso: “Molto bassa” &lt; “Bassa” &lt; … &lt; “Molto alta”.\n\n\nEsempio di trasformazione non ammissibile\n\n\nCalcolare “il doppio di motivazione”: dire che la categoria 4 è “il doppio” della categoria 2 non ha senso, perché non c’è un’unità di misura fissa che quantifichi la differenza tra i livelli. Le categorie ordinali servono solo a ordinare, non a quantificare in modo assoluto.\n\nEsercizio 3 – Trasformazioni in Scala ad Intervalli\n\nTrasformazione lineare ammessa\n\n\nForma generale: \\(y' = a + b y\\), con \\(b &gt; 0\\).\n\nPreserva le differenze tra i valori (ad esempio, \\((y_2 - y_1) = (y'_2 - y'_1) / b\\)), perché la traslazione aggiunge una costante a tutti i punteggi e la dilatazione (moltiplicazione per \\(b\\)) mantiene le proporzioni fra gli intervalli.\n\n\nEsempio concreto\n\n\nScala QI: media = 100, deviazione standard = 15.\n\nVuoi che la nuova media sia 50.\n\nPer semplificare, supponiamo di voler “spostare” ogni valore verso una nuova scala centrata a 50, mantenendo una deviazione standard proporzionale.\n\nUna possibile trasformazione lineare:\n\\[\n  y' = (y - 100) + 50 = y - 50.\n\\]\nIn questo caso, \\(a = -50\\), \\(b = 1\\).\n\nSe un individuo ha QI = 115, allora \\(y' = 115 - 50 = 65\\).\n\n\nSe invece volessi anche cambiare la deviazione standard, potresti usare un fattore \\(b \\neq 1\\). Ad esempio, se desideri una deviazione standard = 10, potresti usare \\(b = \\frac{10}{15} \\approx 0.67\\).\n\n\nDifferenze rispetto alle scale nominali/ordinali\n\n\nCon una scala ad intervalli puoi:\n\nOrdinare i punteggi.\n\nStabilire differenze (es. un individuo A ha 15 punti in più di B).\n\n\nNon puoi invece stabilire rapporti (es. “A ha il doppio di X rispetto a B” non è lecito), perché lo zero è arbitrario e la distanza “0” non rappresenta l’assenza del fenomeno (come invece avviene nella scala di rapporti).\n\nEsercizio 4 – Trasformazioni in Scala di Rapporti\n\nPerché il tempo di reazione è in una scala di rapporti?\n\n\nZero assoluto: un tempo di reazione (teoricamente) pari a 0 ms significherebbe nessun tempo trascorso → totale assenza del fenomeno misurato (impossibile nella pratica, ma concettualmente definisce uno zero non arbitrario).\n\nPuoi confrontare i punteggi con rapporti: “il tempo di reazione di A è il doppio di quello di B” (200 ms vs. 100 ms).\n\n\nTrasformazioni ammissibili\n\n\nTrasformazione di similarità: \\(y' = b y\\) con \\(b &gt; 0\\).\n\nSe hai due tempi di reazione \\(y_1\\) e \\(y_2\\), il rapporto \\(\\frac{y_1}{y_2}\\) rimane invariato anche dopo la trasformazione:\n\\[\n  \\frac{y'_1}{y'_2} = \\frac{b y_1}{b y_2} = \\frac{y_1}{y_2}.\n\\]\nEsempio numerico: se i tempi di reazione di due partecipanti sono 100 ms e 200 ms, il rapporto è 2. Se moltiplichi entrambi per 2, ottieni 200 ms e 400 ms, e il rapporto rimane 2.\n\n\nConfronto con scala ad intervalli (esempio delle temperature)\n\n\nIn una scala di rapporti puoi dire “A ha una latenza doppia di B” perché lo zero non è arbitrario.\n\nCon la temperatura (scala ad intervalli) lo zero (es. 0°C) non rappresenta l’assenza di calore, quindi non ha senso dire che 80°C è “il doppio” di 40°C. Cambiando la scala (ad es. Fahrenheit) il rapporto cambia.\n\nEsercizio 5 – Riconoscere e Applicare le Trasformazioni nei Quattro Livelli di Scala\n\nIdentificazione del livello di scala\n\n\nOrientamento politico: scala nominale (categorie qualitative prive di ordine).\n\nClassifica di soddisfazione (1°, 2°, 3°, …): scala ordinale (c’è un ordine, ma non si conosce la “distanza” fra i posti).\n\nPunteggi di un test di personalità (con media=100, dev.st=10), considerati approssimazione di una scala ad intervalli (si assumono le differenze significative, lo zero è arbitrario).\n\nFrequenza cardiaca a riposo (bpm): scala di rapporti (zero assoluto e rapporti confrontabili).\n\n\nTrasformazioni ammesse e non ammesse\n\n\nNominale:\n\nAmmessa: cambiare etichette (A → “Liberale”, B → “Conservatore” ecc.).\n\nNon ammessa: sommare categorie, ordinare, calcolare media delle categorie.\n\n\nOrdinale:\n\nAmmessa: rietichettare i ranghi (1° → “Migliore”, 2° → “Secondo posto”…).\n\nNon ammessa: calcolare rapporti (il 2° posto non è “il doppio” del 1°), sommare posizioni in modo significativo.\n\n\nA intervalli:\n\nAmmessa: trasformazione lineare (traslazione + dilatazione).\n\nNon ammessa: dire che un punteggio è “tre volte” un altro; lo zero è arbitrario.\n\n\nA rapporti:\n\nAmmessa: trasformazione di similarità (\\(y' = b y\\)), in cui i rapporti rimangono invariati.\n\nNon ammessa: aggiunta di una costante a tutti i valori (questa sposterebbe lo zero, rendendolo arbitrario e trasformando la scala in una scala ad intervalli).\n\n\n\nImplicazioni per l’interpretazione e le analisi\n\n\nUna variabile nominale consente solo frequenze e test non parametrici basati su conteggi (es. Chi-quadrato).\n\nUna variabile ordinale permette test di ordinamento (es. test di rank, come il Wilcoxon), ma non calcoli di media con significato forte.\n\nUna scala ad intervalli permette di usare statistiche parametriche (calcolo di media, varianza, test come t-test, ANOVA), assumendo che l’interpretazione delle differenze sia coerente.\n\nUna scala di rapporti permette, in più, il confronto di rapporti (ad esempio, si possono applicare modelli parametrici che includano il concetto di proporzioni o slope logico su dati che abbiano senso a zero assoluto).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#bibliografia",
    "href": "chapters/key_notions/04_measurement.html#bibliografia",
    "title": "4  La misurazione in psicologia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nDomini, F., & Caudek, C. (2009). The intrinsic constraint model and Fechnerian sensory scaling. Journal of Vision, 9(2), 25–25.\n\n\nLilienfeld, S. O., & Strother, A. N. (2020). Psychological measurement and the replication crisis: Four sacred cows. Canadian Psychology/Psychologie Canadienne, 61(4), 281–288.\n\n\nMaul, A., Irribarra, D. T., & Wilson, M. (2016). On the philosophical foundations of psychological measurement. Measurement, 79, 311–320.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html",
    "href": "chapters/key_notions/05_cognitive_models.html",
    "title": "5  Dalla descrizione alla spiegazione",
    "section": "",
    "text": "5.1 Introduzione\nP er comprendere e spiegare i processi mentali in modo più rigoroso, è necessario adottare modelli che vadano oltre la semplice descrizione. Questo capitolo introduce i modelli meccanicistici e computazionali, mostrando come possano rafforzare la spiegazione psicologica. Negli ultimi anni, la psicologia ha attraversato una crisi profonda legata alla riproducibilità dei risultati sperimentali. Molti effetti classici non riescono a replicarsi in studi successivi, sollevando interrogativi sulla solidità delle teorie psicologiche. In questo contesto, è sempre più chiaro che il tipo di modelli utilizzati per spiegare i fenomeni psicologici ha un impatto cruciale sulla credibilità e robustezza della ricerca scientifica. Una distinzione centrale a questo riguardo è quella tra modelli fenomenologici e modelli meccanicistici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dalla descrizione alla spiegazione</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#introduzione",
    "href": "chapters/key_notions/05_cognitive_models.html#introduzione",
    "title": "5  Dalla descrizione alla spiegazione",
    "section": "",
    "text": "Panoramica del capitolo\n\nIl ruolo dei modelli computazionali nella psicologia scientifica.\nLa struttura e la logica di due modelli fondamentali — il modello di Rescorla-Wagner (per l’apprendimento associativo) e il Drift Diffusion Model (per le decisioni sotto incertezza).\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nConsulta Why is the Rescorla-Wagner model so influential? (Soto et al., 2023).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(rtdists)\n\n\n\n\n\n5.1.1 Modelli fenomenologici: descrivere senza spiegare\nI modelli fenomenologici si limitano a descrivere relazioni osservabili tra variabili psicologiche, spesso attraverso formule matematiche o rappresentazioni statistiche. Un esempio classico è una legge psicofisica che descrive la relazione tra stimolazione sensoriale e risposta percepita. Sebbene questi modelli possano essere estremamente predittivi, non forniscono informazioni sul “come” e “perché” un certo fenomeno si verifica. Non specificano, cioè, le entità e le attività organizzate che lo generano (es. meccanismi cognitivi, neuroni, moduli funzionali).\nCome sottolineato da Povich (2025), modelli fenomenologici come questi possono essere accurati, compatti, persino predittivi — ma non necessariamente esplicativi. In effetti, possono mancare della capacità di rispondere a domande controfattuali del tipo “che cosa succederebbe se…?” e non permettono un controllo diretto sul fenomeno. Questa limitazione si rivela particolarmente problematica in un’epoca in cui la replicabilità richiede non solo constatare un effetto, ma anche comprenderne le condizioni causali e contestuali.\n\n5.1.2 Dai modelli meccanicistici alla modellazione computazionale\nUn modello meccanicistico cerca di rappresentare le componenti causali di un fenomeno. Secondo una definizione ampiamente condivisa, un meccanismo è “una collezione organizzata di entità e attività che produce o mantiene un certo fenomeno” (Bechtel, 2009). I modelli meccanicistici hanno l’obiettivo di descrivere questi meccanismi, specificando in che modo le componenti interagiscono per generare il comportamento osservato.\nNel contesto della psicologia, i modelli meccanicistici vanno oltre la descrizione di correlazioni osservabili. Cercano di identificare strutture cognitive, processi neurali o dinamiche corpo-ambiente o interazioni tra livelli (funzionale, computazionale, implementazionale). Un esempio ben noto è il modello della long-term potentiation (LTP) nella memoria, che spiega come variazioni nei recettori NMDA e AMPA e nella concentrazione di ioni calcio e magnesio determinano il rafforzamento sinaptico — un chiaro caso di spiegazione meccanicistica.\nOggi, molti modelli meccanicistici in psicologia sono implementati come modelli computazionali, ovvero rappresentazioni formali che simulano i processi interni ipotizzati. Attraverso la simulazione e la stima dei parametri, questi modelli permettono di inferire il funzionamento dei meccanismi sottostanti a partire dal comportamento osservabile. I modelli computazionali soddisfano i criteri della spiegazione meccanicistica quando forniscono informazioni su entità ipotetiche (come credenze, soglie decisionali, accumulo di evidenza) e sulle loro interazioni causali.\n\n5.1.3 La differenza epistemica: come distinguere spiegazione da predizione\nUn punto chiave nella distinzione tra spiegazioni fenomenologiche e meccanicistiche è che solo le seconde soddisfano i criteri di potere esplicativo propriamente detto. Come chiarisce Povich (2025), un modello esplicativo deve permettere di:\n\nrispondere a domande controfattuali (“che cosa succederebbe se una componente fosse diversa?”);\nfornire la base per manipolare o controllare il fenomeno.\n\nQuesti criteri sono cruciali per superare la crisi della replicabilità: sapere che un effetto si verifica in certe condizioni è poco utile se non si capisce perché avviene e quali sono i meccanismi sottostanti che lo rendono stabile o instabile rispetto a cambiamenti contestuali.\n\n5.1.4 Oltre le metafore meccaniche: che cosa rende meccanicistico un modello?\nUna fonte comune di confusione riguarda l’idea che un modello, per essere meccanicistico, debba avere necessariamente la forma di una macchina, con entità concrete (es. neuroni, aree cerebrali) e connessioni visibili tra di esse. Ma questa è una semplificazione fuorviante. Ciò che rende un modello meccanicistico non è la sua forma visiva o metaforica, ma la sua capacità di rappresentare l’organizzazione causale del processo che genera un certo comportamento. Un modello può essere espresso con equazioni matematiche, algoritmi, reti neurali, simulazioni, eppure contribuire in modo decisivo a una spiegazione meccanicistica se specifica in che modo le componenti del sistema interagiscono per produrre l’effetto osservato.\nPer chiarire questa idea, possiamo richiamare i tre livelli di spiegazione proposti da David Marr (1982), uno dei riferimenti fondamentali nella psicologia cognitiva computazionale:\n\n\nLivello computazionale: Cosa fa il sistema e perché (qual è il problema che risolve?).\n\nLivello algoritmico: Come lo fa? Quali rappresentazioni interne e quali trasformazioni (regole di calcolo) sono coinvolte.\n\nLivello implementativo: Con quali mezzi fisici è realizzato (per esempio, circuiti neurali).\n\nQuesta distinzione aiuta a chiarire che un modello può essere meccanicistico anche se non rappresenta direttamente substrati biologici, purché descriva in modo formale come un sistema risolve un problema e quali regole seguono le sue componenti.\nNel contesto della psicologia, i modelli computazionali che operano al livello algoritmico o computazionale — come il modello di Rescorla-Wagner o il Drift Diffusion Model — sono perfettamente coerenti con un approccio meccanicistico, anche se non rappresentano esplicitamente l’implementazione biologica.\nQuesti modelli sono “meccanicistici” nel senso che:\n\n\ndescrivono entità funzionali (es. valore atteso, evidenza accumulata),\n\nspecificano regole di interazione tra queste entità (es. aggiornamento, accumulo, soglie),\n\nproducono il comportamento osservabile come risultato di queste interazioni.\n\nDunque, ciò che conta non è la forma del modello, ma la funzione esplicativa che svolge all’interno della teoria psicologica. Modelli formulati come sistemi dinamici, modelli bayesiani gerarchici, modelli di reti neurali artificiali o modelli simbolici possono tutti contribuire a spiegazioni meccanicistiche, se mostrano come un certo comportamento emerga da un’organizzazione di componenti in interazione.\n\n5.1.5 Perché i modelli meccanicistici rafforzano la riproducibilità\nLa crisi della riproducibilità può essere vista come il sintomo di un’eccessiva fiducia in modelli fenomenologici che mancano di profondità esplicativa. I modelli meccanicistici, al contrario:\n\nesplicitano gli assunti causali e strutturali;\npermettono verifiche controfattuali e manipolazioni;\nchiariscono quando e perché un effetto dovrebbe ripetersi o variare;\nsono meno vulnerabili al cherry picking e agli effetti di contesto non dichiarati;\ni modelli computazionali meccanicistici, come il DDM e il modello di Rescorla-Wagner, consentono di simulare e verificare quantitativamente ipotesi sui meccanismi interni, rendendo più trasparente e replicabile l’inferenza psicologica.\n\nIn breve, un modello meccanicistico non si limita a dire che “A predice B”, ma mostra come A produce B, e in quali condizioni questo accade.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dalla descrizione alla spiegazione</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#riflessioni-conclusive",
    "href": "chapters/key_notions/05_cognitive_models.html#riflessioni-conclusive",
    "title": "5  Dalla descrizione alla spiegazione",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa crisi di replicabilità che caratterizza la psicologia contemporanea impone un ripensamento metodologico profondo, orientato verso un superamento dei modelli puramente descrittivi a favore di paradigmi meccanicistici e computazionali. A differenza dei primi, questi ultimi non si limitano a prevedere esiti comportamentali, ma mirano a identificare i processi algoritmici e i meccanismi latenti che li generano, trasformando così domande di ricerca generiche in ipotesi formalizzate e rigorosamente verificabili.\nL’adozione di un approccio computazionale in psicologia cognitiva consente di ovviare ai limiti intrinseci dell’analisi descrittiva, offrendo un quadro matematico solido per valutare ipotesi sui processi mentali. L’integrazione di modelli di apprendimento e modelli decisionali, in particolare, permette di costruire rappresentazioni unificate e più profonde dei sistemi cognitivi che sottendono il comportamento umano, con ricadute significative sia nella ricerca di base che in ambito applicativo e clinico.\nTale prospettiva si colloca organicamente nel quadro emergente della psichiatria computazionale e della modellazione bayesiana della cognizione, il cui scopo ultimo non è meramente descrittivo, ma inferenziale: individuare quali processi interni risultino più plausibili alla luce dei dati osservati. In questo senso, la formalizzazione computazionale non migliora soltanto il potere esplicativo dei modelli, ma potenzia anche la capacità di inferenza e generalizzazione, due componenti fondamentali per lo sviluppo di una scienza psicologica cumulativa, robusta e realmente replicabile.\n\n\n\n\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nChe cosa descrive il modello di Rescorla-Wagner?\nQual è il ruolo del parametro α nel modello di Rescorla-Wagner?\nQuale funzione matematica viene utilizzata per modellare il bilanciamento tra esplorazione ed esploitazione nel modello di Rescorla-Wagner?\nQuali sono i principali parametri del Drift Diffusion Model (DDM)?\nIn che modo il DDM spiega il compromesso tra velocità e accuratezza nelle decisioni?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nIl modello di Rescorla-Wagner descrive come gli individui apprendano le associazioni tra stimoli e risposte in base all’errore di previsione. L’aspettativa di ricompensa viene aggiornata attraverso l’esperienza, con un processo regolato dal tasso di apprendimento (\\(\\alpha\\)).\nIl parametro \\(\\alpha\\) (tasso di apprendimento) determina quanto velocemente un individuo aggiorna le proprie aspettative in base all’errore di previsione. Se \\(\\alpha\\) è alto, l’apprendimento è rapido; se è basso, l’individuo si basa maggiormente sulle esperienze passate.\nLa funzione Softmax viene utilizzata per modellare il bilanciamento tra esplorazione e sfruttamento. Essa regola la probabilità di scegliere un’opzione in base al valore atteso e alla temperatura della scelta (\\(\\beta\\)).\n\nI principali parametri del DDM sono:\n\n\ntasso di drift (\\(v\\)): velocità con cui viene accumulata l’evidenza;\n\nseparazione delle soglie (\\(a\\)): distanza tra le soglie decisionali;\n\n\ntempo di non-decisione (\\(t_0\\)): tempo impiegato per processi indipendenti dall’accumulo dell’evidenza;\n\n\nbias iniziale (\\(z\\)): punto di partenza dell’accumulo dell’evidenza.\n\n\nIl DDM spiega il compromesso tra velocità e accuratezza attraverso la separazione delle soglie decisionali (\\(a\\)). Se le soglie sono più vicine, le decisioni sono più rapide ma meno accurate; se sono più distanti, le decisioni sono più lente ma più precise.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rtdists_0.11-5        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           gsl_2.1-8             stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       rmarkdown_2.29        ragg_1.4.0           \n#&gt; [19] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [22] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [25] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [28] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [31] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [34] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [37] abind_1.4-8           codetools_0.2-20      curl_7.0.0           \n#&gt; [40] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [43] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [46] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [49] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [52] generics_0.1.4        rprojroot_2.1.1       rstantools_2.4.0     \n#&gt; [55] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [58] emmeans_1.11.2-8      tools_4.5.1           mvtnorm_1.3-3        \n#&gt; [61] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [64] nlme_3.1-168          cli_3.6.5             evd_2.3-7.1          \n#&gt; [67] textshaping_1.0.1     expm_1.0-0            svUnit_1.0.8         \n#&gt; [70] Brobdingnag_1.2-9     V8_6.0.6              gtable_0.3.6         \n#&gt; [73] digest_0.6.37         msm_1.8.2             TH.data_1.1-3        \n#&gt; [76] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [79] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dalla descrizione alla spiegazione</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#bibliografia",
    "href": "chapters/key_notions/05_cognitive_models.html#bibliografia",
    "title": "5  Dalla descrizione alla spiegazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBechtel, W. (2009). Looking down, around, and up: Mechanistic explanation in psychology. Philosophical Psychology, 22(5), 543–564.\n\n\nPovich, M. (2025). Mechanistic Explanation in Psychology. In H. Stam & H. Looren de Jong (A c. Di), The SAGE Handbook of Theoretical Psychology. SAGE Publications.\n\n\nSoto, F. A., Vogel, E. H., Uribe-Bahamonde, Y. E., & Perez, O. D. (2023). Why is the Rescorla-Wagner model so influential? Neurobiology of Learning and Memory, 204, 107794.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dalla descrizione alla spiegazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html",
    "href": "chapters/R/introduction_r_lang.html",
    "title": "R",
    "section": "",
    "text": "Scrivere Codice\nLa programmazione si fonda su un approccio strutturato che combina logica computazionale e strumenti tecnici, articolandosi su due piani complementari: il livello algoritmico e il livello sintattico.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#scrivere-codice",
    "href": "chapters/R/introduction_r_lang.html#scrivere-codice",
    "title": "R",
    "section": "",
    "text": "Livello algoritmico: l’astrazione del problema\nIn questa fase, si definisce la soluzione concettuale indipendentemente dal linguaggio, attraverso:\n\nanalisi degli input;\nspecifica dell’output;\n\nprogettazione dell’algoritmo.\n\nPer esempio, l’input può essere costituito da un insieme di valori numerici; l’output può corrispondere alla media aritmetica; l’algorimo può essere formalizzato come:\n\\[\n\\text{media} = \\frac{\\sum_{i=1}^{n} x_i}{n} .\n\\]\nQuesto processo richiede capacità di problem solving e modellizzazione astratta, competenze trasversali a qualsiasi linguaggio.\n\n\nLivello sintattico: l’implementazione pratica\nLa soluzione algoritmica viene poi tradotta in codice seguendo le regole specifiche del linguaggio scelto:\nEsempio in R\nmedia &lt;- sum(x) / length(x)\nEsempio in Python\nmedia = sum(x) / len(x)\nPur mantenendo la stessa logica, le differenze sintattiche evidenziano come l’implementazione sia vincolata allo strumento utilizzato.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#priorità-formative-nellera-dellia",
    "href": "chapters/R/introduction_r_lang.html#priorità-formative-nellera-dellia",
    "title": "R",
    "section": "Priorità formative nell’era dell’IA",
    "text": "Priorità formative nell’era dell’IA\nNell’attuale contesto tecnologico dominato dall’intelligenza artificiale, la formazione nella programmazione richiede una ridefinizione delle priorità. Abbiamo visto come sia necessario distinguere tra due dimensioni: da un lato, la capacità di pensare algoritmicamente, ossia l’abilità di scomporre problemi complessi in passaggi logici e astratti; dall’altro, la padronanza della sintassi, ovvero delle regole specifiche dei linguaggi di programmazione.\nIl pensiero algoritmico rappresenta il cuore creativo e critico della programmazione. È ciò che permette di trasformare un problema in una sequenza ordinata di operazioni risolutive. Questa competenza, radicata nella logica e nell’astrazione, rimane un dominio squisitamente umano: per quanto avanzate, le IA non possono sostituire la capacità di formulare domande pertinenti, riconoscere pattern originali o immaginare soluzioni innovative. Senza questa base concettuale, ogni tentativo di risolvere problemi computazionali sarebbe destinato a fallire, anche con gli strumenti più potenti a disposizione.\nLa sintassi computazionale, sebbene necessaria, assume oggi un ruolo diverso. Strumenti di code generation, stanno democratizzando l’accesso alla scrittura del codice: piattaforme intelligenti possono suggerire implementazioni, correggere errori e persino tradurre algoritmi tra linguaggi diversi (Cooper et al., 2024). Gli errori sintattici – un tempo ostacoli insormontabili per i principianti – diventano sempre più correggibili attraverso l’esperienza o l’automazione.\nQuesta gerarchia di competenze riecheggia il framework teorico di Marr, sviluppato nel campo della visione artificiale. Marr distingue tre livelli di analisi: il “perché” del sistema (l’obiettivo computazionale), il “come” logico (la progettazione algoritmica) e il “con cosa” concreto (l’implementazione fisica). Nell’educazione alla programmazione, questo si traduce in una scelta precisa: privilegiare la progettazione consapevole di algoritmi rispetto alla mera esecuzione tecnica.\nLa priorità formativa diventa quindi chiara. Coltivare il pensiero algoritmico significa allenare quella mentalità progettuale che permette di dialogare in modo critico con l’IA: formulare prompt efficaci richiede prima di tutto di comprendere a fondo la struttura del problema; valutare soluzioni proposte dall’intelligenza artificiale presuppone la capacità di riconoscere logiche difettose o approcci subottimali. Allo stesso tempo, questa competenza agisce come un “sesto senso tecnologico”, permettendo di adattarsi a linguaggi e strumenti in continua evoluzione.\nLa sintassi non viene certo abbandonata, ma contestualizzata. L’automazione non sostituisce l’apprendimento, ma lo rende più strategico: invece di memorizzare comandi, si impara a selezionarli e combinarli in modo funzionale agli obiettivi algoritmici.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#r-uno-strumento-per-lanalisi-dei-dati",
    "href": "chapters/R/introduction_r_lang.html#r-uno-strumento-per-lanalisi-dei-dati",
    "title": "R",
    "section": "R: Uno Strumento per l’Analisi dei Dati",
    "text": "R: Uno Strumento per l’Analisi dei Dati\nPer trovare la soluzione concreta a un problema di analisi dei dati, è necessario implementare l’algoritmo desiderato in un linguaggio di programmazione. In questo insegnamento, utilizzeremo R, uno dei linguaggi più utilizzati per l’analisi dei dati, apprezzato per la sua flessibilità, potenza e il supporto offerto da una vasta comunità di utenti e sviluppatori.\n\nPerché R?\n\nNato per l’analisi statistica: R è stato concepito specificamente per rispondere alle esigenze di analisi statistica e visualizzazione grafica, diventando rapidamente uno strumento essenziale nel panorama accademico e scientifico.\nGestione dei dati: R offre strumenti avanzati per gestire, manipolare e analizzare grandi quantità di dati, coprendo un’ampia gamma di tecniche statistiche, dalla modellazione lineare all’analisi delle serie temporali.\nVisualizzazione grafica: Con pacchetti come ggplot2 e plotly, R permette di creare grafici e visualizzazioni di alta qualità, fondamentali per comunicare risultati in modo efficace.\nComunità e pacchetti: L’ecosistema di R è arricchito da una vasta libreria di pacchetti, che estendono le capacità del linguaggio per soddisfare necessità specifiche e settoriali.\n\n\n\nR in Psicologia e nelle Scienze Sociali\nNato come linguaggio dedicato alla statistica, R si è evoluto fino a diventare un punto di riferimento per psicologi, ricercatori e professionisti impegnati nella valutazione psicometrica, nell’analisi del comportamento e nella modellizzazione di dati complessi. La sua flessibilità, unita alla vastissima collezione di pacchetti specifici, lo rende adatto a molteplici applicazioni in psicologia, dalla costruzione e validazione di test alla gestione di dati provenienti da studi sperimentali, longitudinali ed Ecological Momentary Assessment (EMA).",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#riflessioni-conclusive",
    "href": "chapters/R/introduction_r_lang.html#riflessioni-conclusive",
    "title": "R",
    "section": "Riflessioni Conclusive",
    "text": "Riflessioni Conclusive\nImparare ad usare R non significa solo acquisire competenze tecniche, ma anche aprire le porte a nuove possibilità di analisi e ricerca. Tuttavia, è fondamentale ricordare che la vera sfida nella programmazione non è padroneggiare la sintassi di un linguaggio specifico, ma comprendere la logica algoritmica che sta alla base della soluzione di un problema. L’IA può aiutarci a trovare la sintassi corretta, ma spetta a noi decidere quale algoritmo implementare. Pertanto, i nostri sforzi devono essere rivolti a capire la logica del problema, piuttosto che concentrarci esclusivamente sull’implementazione sintattica.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#bibliografia",
    "href": "chapters/R/introduction_r_lang.html#bibliografia",
    "title": "R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCooper, N., Clark, A. T., Lecomte, N., Qiao, H., & Ellison, A. M. (2024). Harnessing large language models for coding, teaching and inclusion to empower research in ecology and evolution. Methods in Ecology and Evolution.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html",
    "href": "chapters/R/01_r_syntax.html",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "",
    "text": "Introduzione\nN ell’analisi dei dati psicologici, R non è solo uno strumento statistico avanzato, ma un vero e proprio linguaggio per organizzare il pensiero scientifico. La sua sintassi trasforma procedure complesse in passaggi chiari, verificabili e ripetibili, rispondendo alla crisi della replicabilità che ha coinvolto la psicologia negli ultimi anni (Obels et al., 2020). Imparare R significa quindi acquisire un metodo di lavoro rigoroso e trasparente.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#introduzione",
    "href": "chapters/R/01_r_syntax.html#introduzione",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "",
    "text": "Panoramica del capitolo\n\nInstallare R e RStudio.\nCreare e gestire progetti in RStudio.\nManipolare oggetti e vettori in R.\nUtilizzare funzioni e lavorare con dati mancanti.\nEstrarre e gestire sottoinsiemi di dati.\nApprezzare l’importanza di rendere riproducibile l’analisi dei dati, condividendone ogni passaggio.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere attentamene l’Appendice F.\nLeggere il capitolo Getting Started with Data in R di Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (Second Edition), capitoli 1.1-1.3.\nConsultare Introduction to Data Science: Data Wrangling and Visualization with R (Irizarry, 2024)\n\nConsultare R for Data Science (2e) (Wickham et al., 2023).\nConsultare R Programming for Data Science, capitoli 3-4.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tidyr)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#la-sintassi-di-r-come-garanzia-di-trasparenza",
    "href": "chapters/R/01_r_syntax.html#la-sintassi-di-r-come-garanzia-di-trasparenza",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.1 La Sintassi di R come garanzia di trasparenza",
    "text": "6.1 La Sintassi di R come garanzia di trasparenza\nA differenza dei software a menu grafici (come Excel o SPSS), dove le operazioni restano “nascoste” dietro click del mouse, R richiede di descrivere esplicitamente ogni passaggio. Prendiamo questo esempio base:\ndati &lt;- read.csv(\"esperimento1.csv\")\nmodello &lt;- lm(risposta ~ trattamento, data = dati)\nQuesto semplice script realizza tre cose fondamentali:\n\n\nDocumentazione automatica: Ogni operazione resta tracciata nel codice.\n\nVerifica immediata: È possibile ispezionare ogni passaggio (Cosa contiene dati? Come è definito modello?).\n\nModifiche controllate: Cambiare un parametro (es. il file di input) non richiede di rifare tutta l’analisi manualmente.\n\n\n6.1.1 Perché R favorisce la replicabilità\nTre caratteristiche di R facilitano direttamente la replicabilità:\n\n\nStruttura basata su script: Scrivere codice in file .R o .qmd crea una traccia completa e ordinata dell’analisi, integrando:\n\nistruzioni eseguibili,\nannotazioni metodologiche,\nvisualizzazione dei risultati.\n\n\nGestione esplicita dei pacchetti:\nComandi come library(lme4) o install.packages(\"brms\") rendono esplicite tutte le risorse usate, evitando il classico “Sul mio computer funzionava!”.\n\nLiterate programming tramite R Markdown:\nLa combinazione di codice, testo narrativo e risultati dinamici (Knuth, 1984) in documenti Quarto (o R Markdown) consente di generare report che combinano:\n\ntesto esplicativo,\nanalisi eseguibile,\nrisultati dinamici (grafici, tabelle).\n\n\n\n6.1.2 Buone abitudini da adottare subito\n\n\nNomi descrittivi\nUtilizzare sempre nomi chiari per oggetti e dati:\n# Da evitare\nx &lt;- read.csv(\"file1.csv\")  \n\n# Preferibile\ndemographics_data &lt;- read.csv(\"demographic_questionnaire.csv\")  \n\nSalvataggio progressivo delle modifiche (versionamento)\nR permette di salvare e tenere traccia delle modifiche ai file con sistemi come Git. Non è necessario impararlo subito, ma è utile sapere che strumenti come GitHub consentono facilmente di archiviare versioni successive del proprio lavoro, facilitando il recupero di versioni precedenti in caso di necessità.\n\nChecklist pre-invio\nPrima di condividere un’analisi, è buona norma verificare:\n\neseguire lo script integralmente (Ctrl+Shift+Enter su RStudio);\ncontrollare che i percorsi dei file siano corretti (es.: “Il file dati.csv si trova nella cartella giusta?”);\naggiornare tutti i pacchetti installati con update.packages(ask = FALSE).\n\n\n\nQueste pratiche rendono il codice più robusto, l’analisi più affidabile e i risultati più facilmente verificabili.\n\n6.1.3 Perché queste regole contano nella ricerca psicologica\nL’apprendimento di R va oltre l’acquisizione di competenze tecniche. Ogni scelta sintattica riflette un principio scientifico:\n\n\nElemento del codice\nPrincipio metodologico\n\n\n\nset.seed(123)\nControllo delle fonti di casualità\n\n\ndplyr::filter()\nTracciabilità delle esclusioni\n\n\nAPA_style()\nStandardizzazione della reportistica\n\n\n\nIn un contesto dove il 50% degli studi psicologici mostra difficoltà di replicazione (Collaboration, 2015), R offre un framework per costruire ricerche solide fin dalla fase di progettazione.\n\n6.1.4 Prossimi passi\n\nScarica e installa R.\nVai al sito ufficiale di CRAN (https://cran.r-project.org/), scegli la versione per il tuo sistema operativo (Windows, Mac o Linux) e segui le istruzioni di installazione.\nScarica e installa RStudio.\nDopo aver installato R, scarica RStudio dal sito ufficiale (https://posit.co/download/rstudio-desktop/). Scegli la versione gratuita “RStudio Desktop” e segui le istruzioni per il tuo sistema operativo.\n\nUna spiegazione dettagliata del processo di installazione di R e RStudio è disponibile in Okoye & Hosseini (2024).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#panoramica-sullinterfaccia-di-rstudio",
    "href": "chapters/R/01_r_syntax.html#panoramica-sullinterfaccia-di-rstudio",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.2 Panoramica sull’interfaccia di RStudio",
    "text": "6.2 Panoramica sull’interfaccia di RStudio\nRStudio rende l’uso di R più intuitivo grazie alla sua interfaccia divisa in quattro pannelli principali:\n\n\nPannello degli script: Qui puoi scrivere e modificare i tuoi script, cioè sequenze di comandi salvabili per analisi ripetibili e organizzate.\n\nConsole: Esegue i comandi scritti direttamente o lanciati dagli script, mostrando risultati, messaggi e errori.\n\nPannello dell’ambiente: Mostra i dataset, le variabili e gli oggetti caricati nella sessione di lavoro, permettendoti di gestire facilmente i dati.\n\nPannello grafici/aiuto/file: Visualizza grafici, fornisce accesso alla documentazione di R e consente di navigare tra file e cartelle sul tuo sistema.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#creare-un-nuovo-progetto-in-rstudio",
    "href": "chapters/R/01_r_syntax.html#creare-un-nuovo-progetto-in-rstudio",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.3 Creare un nuovo progetto in RStudio",
    "text": "6.3 Creare un nuovo progetto in RStudio\nAvviare un nuovo progetto\nDal menu di RStudio, seleziona File &gt; New Project… per creare un nuovo progetto. I progetti in RStudio sono uno strumento efficace per organizzare il lavoro relativo a una specifica analisi o domanda di ricerca. All’interno di un progetto puoi raccogliere script, file di dati e output, mantenendo tutto ben strutturato.\nScegliere la posizione del progetto\nPuoi creare una nuova directory dedicata al progetto oppure associare il progetto a una directory esistente. Organizzare i progetti in cartelle dedicate aiuta a mantenere i file in ordine e a utilizzare percorsi relativi, rendendo il tuo lavoro più facile da condividere con collaboratori e più portabile tra diversi sistemi.\nQuesta organizzazione è particolarmente utile per evitare confusione e assicurarsi che tutti i file necessari siano facilmente accessibili e collegati al progetto corretto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#concetti-di-base-nella-programmazione-in-r",
    "href": "chapters/R/01_r_syntax.html#concetti-di-base-nella-programmazione-in-r",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.4 Concetti di base nella programmazione in R",
    "text": "6.4 Concetti di base nella programmazione in R\nIniziare a usare R, soprattutto per chi si avvicina per la prima volta a questo linguaggio nel contesto della psicologia, significa comprendere i concetti fondamentali che ne costituiscono la base. Questo capitolo introduce i principi essenziali della programmazione in R, tra cui:\n\nLa comprensione della sintassi di R.\nLa familiarizzazione con i principali tipi di dati e strutture.\nL’acquisizione delle operazioni di base.\n\nQuesti concetti sono fondamentali per manipolare efficacemente i dati e condurre analisi statistiche, rappresentando il punto di partenza per sfruttare al meglio le potenzialità di R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#oggetti-in-r",
    "href": "chapters/R/01_r_syntax.html#oggetti-in-r",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.5 Oggetti in R",
    "text": "6.5 Oggetti in R\nIn R, tutto è un oggetto: dai numeri e stringhe di testo più semplici fino a strutture più complesse come vettori, data frame, funzioni, modelli statistici o persino grafici. Un oggetto in R è semplicemente un contenitore che memorizza un valore o una serie di valori, permettendoti di manipolarli e riutilizzarli nel codice.\n\n6.5.1 Creare oggetti\nPer creare un oggetto, è necessario assegnargli un nome e un valore utilizzando l’operatore di assegnazione &lt;- (consigliato) o = (meno utilizzato):\n\nmy_obj &lt;- 48\n\nIn questo esempio, abbiamo creato un oggetto chiamato my_obj e gli abbiamo assegnato il valore 48. Ora questo numero è memorizzato con quel nome e può essere richiamato facilmente.\nPer visualizzare il valore di un oggetto, basta scriverne il nome e premere Invio:\n\nmy_obj\n#&gt; [1] 48\n\n\n6.5.1.1 Dove vengono salvati gli oggetti?\nGli oggetti creati vengono memorizzati nell’ambiente di lavoro (workspace) e restano disponibili finché non vengono rimossi o finché la sessione di R non viene chiusa. Se stai usando RStudio, puoi vedere tutti gli oggetti attualmente presenti nella scheda Environment, dove vengono mostrati con dettagli come tipo, lunghezza e valore.\n\n6.5.1.2 Perché gli oggetti sono importanti?\nLavorare con oggetti in R permette di:\n\n\nRiutilizzare dati e risultati senza doverli digitare nuovamente.\n\n\nOrganizzare il codice in modo chiaro e leggibile, rendendo le analisi più strutturate.\n\n\nManipolare facilmente i dati, combinando, trasformando e analizzando gli oggetti in base alle esigenze.\n\n6.5.1.3 Stringhe\nÈ possibile assegnare a un oggetto anche una stringa di testo, racchiudendola tra virgolette:\n\nmy_obj2 &lt;- \"R è fantastico\"\nmy_obj2\n#&gt; [1] \"R è fantastico\"\n\nSe dimentichi le virgolette, R mostrerà un errore.\n\n6.5.1.4 Modificare oggetti\nPer modificare il valore di un oggetto esistente, basta riassegnarlo:\n\nmy_obj2 &lt;- 1024\n\nOra il tipo di my_obj2 è cambiato da carattere a numerico. È anche possibile usare oggetti per crearne di nuovi:\n\nmy_obj3 &lt;- my_obj + my_obj2\nmy_obj3\n#&gt; [1] 1072\n\n\n6.5.1.5 Manipolare oggetti\nSe provi a sommare oggetti di tipo diverso, R restituirà un errore:\nchar_obj &lt;- \"ciao\"\nchar_obj2 &lt;- \"mondo\"\nchar_obj3 &lt;- char_obj + char_obj2\n#&gt; Error in char_obj + char_obj2 : non-numeric argument to binary operator\nQuando incontri errori come questo, chiedi a AI la spiegazione del messaggio, per esempio: “non-numeric argument to binary operator error + r”. Un errore comune è anche:\nmy_obj &lt;- 48\nmy_obj4 &lt;- my_obj + no_obj\n#&gt; Error: object 'no_obj' not found\nR segnala che no_obj non è stato definito e, di conseguenza, l’oggetto my_obj4 non è stato creato.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#nomi-degli-oggetti",
    "href": "chapters/R/01_r_syntax.html#nomi-degli-oggetti",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.6 Nomi degli oggetti",
    "text": "6.6 Nomi degli oggetti\nAttribuire nomi agli oggetti potrebbe sembrare un dettaglio secondario, ma è fondamentale scegliere nomi brevi e informativi. Un buon nome migliora la leggibilità del codice e ne facilita la manutenzione. È importante adottare uno stile coerente, come uno dei seguenti:\n\n\nSnake case: output_summary\n\n\nDot case: output.summary\n\n\nCamel case: outputSummary\n\n\nIn questo corso useremo lo stile più diffuso, Snake Case, che separa le parole con il carattere di sottolineatura _.\nCi sono alcune regole fondamentali da rispettare nella scelta dei nomi:\n\nNon possono iniziare con un numero (ad esempio, 2my_variable non è valido).\n\nNon possono contenere caratteri speciali come &, ^, /, ecc.\n\nEvita di usare parole riservate (ad esempio, TRUE, NA) o nomi di funzioni esistenti (ad esempio, data).\n\nEsempio di cosa non fare:\ndata &lt;- read.table(\"mydatafile\", header = TRUE) # `data` è già una funzione!",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#commenti",
    "href": "chapters/R/01_r_syntax.html#commenti",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.7 Commenti",
    "text": "6.7 Commenti\nI commenti sono uno strumento essenziale per rendere il codice più chiaro e comprensibile, sia per te stesso sia per altri. Nel linguaggio R, i commenti iniziano con il simbolo #, e tutto ciò che lo segue sulla stessa riga viene ignorato dall’interprete durante l’esecuzione.\n\n6.7.1 Perché commentare?\nI commenti servono a spiegare perché il codice è scritto in un certo modo, non solo come funziona (questo è evidente leggendo il codice). Una buona pratica consiste nel commentare le decisioni o i passaggi che non risultano immediatamente evidenti.\nAd esempio, invece di scrivere un commento ridondante come:\n\n# Assegno 42 alla variabile x\nx &lt;- 42\n\nè più utile fornire un contesto:\n\n# Valore iniziale scelto per semplificare i calcoli successivi\nx &lt;- 42\n\n\n6.7.2 Vantaggi\nCommentare in modo appropriato aiuta a:\n\n\nRidurre il tempo necessario per comprendere o modificare il codice, anche mesi o anni dopo averlo scritto.\n\nFacilitare la collaborazione con altri, rendendo il codice leggibile e accessibile.\n\nMigliorare la manutenibilità e il riutilizzo del codice.\n\nUn codice ben commentato non è solo più facile da leggere, ma anche più professionale e robusto nel lungo termine.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#usare-r-come-calcolatore",
    "href": "chapters/R/01_r_syntax.html#usare-r-come-calcolatore",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.8 Usare R come calcolatore",
    "text": "6.8 Usare R come calcolatore\nR può essere utilizzato come un semplice calcolatore digitando direttamente nella console numeri e operatori aritmetici per eseguire operazioni come somma, sottrazione, moltiplicazione e divisione (+, -, *, /). Questo lo rende uno strumento immediato e versatile per calcoli di base e avanzati.\n\nEsempio 6.1 La Satisfaction With Life Scale (SWLS) contiene 5 item, ciascuno valutato con una scala Likert a 7 punti, dove:\n1 = “completamente in disaccordo” e 7 = “completamente d’accordo”.\nGli item sono:\n\nPer la maggior parte, la mia vita si avvicina al mio ideale.\n\nLe mie condizioni di vita sono eccellenti.\n\nSono soddisfatto della mia vita.\n\nFino ad ora, ho ottenuto le cose importanti che voglio nella vita.\n\nSe potessi vivere la mia vita di nuovo, non cambierei quasi nulla.\n\nSupponiamo che un individuo risponda nel seguente modo:\n\nItem 1: 5\n\nItem 2: 3\n\nItem 3: 4\n\nItem 4: 2\n\nItem 5: 2\n\nIl punteggio totale sulla SWLS si calcola sommando i punteggi di ciascun item:\n\nsogg1 &lt;- 5 + 3 + 4 + 2 + 2 \nsogg1\n#&gt; [1] 16\n\n\n\nEsempio 6.2 Il Body Mass Index (BMI) si calcola dividendo il peso, in chilogrammi, per il quadrato dell’altezza, in metri.\nLa formula è:\n\\[\n\\text{BMI} = \\frac{\\text{Peso (kg)}}{\\text{Altezza (m)}^2} .\n\\]\nSupponiamo che un individuo pesi 79000 grammi (79 kg) e sia alto 176 cm. Il calcolo in R sarà:\n\nbmi &lt;- (79000 / 1000) / (176 / 100)^2\nbmi\n#&gt; [1] 25.5\n\n\nNota. L’uso di parentesi è fondamentale per garantire che le operazioni vengano eseguite nell’ordine corretto. In R, come in matematica, le operazioni racchiuse tra parentesi hanno la precedenza rispetto ad altre operazioni. Ad esempio, nel calcolo del BMI, abbiamo usato le parentesi per calcolare prima la conversione dei valori nell’unità di misura appropriata.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#ordine-di-precedenza-degli-operatori",
    "href": "chapters/R/01_r_syntax.html#ordine-di-precedenza-degli-operatori",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.9 Ordine di precedenza degli operatori",
    "text": "6.9 Ordine di precedenza degli operatori\nLe operazioni algebriche vengono eseguite in una particolare sequenza in R, nota come ordine di precedenza degli operatori. Questo ordine determina quali operazioni vengono eseguite per prime quando un’espressione include più operatori. In assenza di parentesi, l’ordine di precedenza è il seguente (dal più alto al più basso):\n\n\nParentesi: Le operazioni racchiuse tra parentesi () vengono eseguite per prime. Questo permette di sovrascrivere l’ordine naturale delle operazioni.\n\nresult &lt;- (2 + 3) * 4  # Risultato: 20\n\n\n\nEsponenziazione: L’operatore ^ viene eseguito dopo le parentesi.\n\nresult &lt;- 2^3  # Risultato: 8\n\n\n\nSegni unari: Il segno meno - o più + applicato a un singolo valore.\n\nresult &lt;- -3 + 5  # Risultato: 2\n\n\n\nMoltiplicazione, divisione e modulo: Gli operatori *, /, %/% (divisione intera) e %% (resto) hanno la stessa precedenza e vengono eseguiti da sinistra a destra.\n\nresult &lt;- 10 / 2 * 3  # Risultato: 15\nresult &lt;- 10 %% 3     # Risultato: 1\n\n\n\nAddizione e sottrazione: Gli operatori + e - vengono eseguiti dopo quelli di moltiplicazione/divisione.\n\nresult &lt;- 5 + 3 - 2  # Risultato: 6\n\n\n\nOperatori di assegnazione: Gli operatori &lt;-, -&gt;, =, che assegnano valori a variabili, vengono valutati per ultimi.\n\nx &lt;- 2 + 3 * 4  # Risultato: 14\n\n\n\nNote importanti:\n\n\nAssociazione a sinistra: La maggior parte degli operatori in R viene valutata da sinistra a destra (ad esempio, +, *, /).\n\nUso delle parentesi: Quando l’ordine di precedenza non è immediatamente chiaro o si vuole assicurare un ordine specifico, è sempre buona pratica usare le parentesi.\n\nCapire l’ordine di precedenza è fondamentale per evitare errori logici e garantire che il codice funzioni come previsto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#funzioni",
    "href": "chapters/R/01_r_syntax.html#funzioni",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.10 Funzioni",
    "text": "6.10 Funzioni\nFino ad ora abbiamo creato oggetti semplici assegnando loro direttamente un valore. Con l’aumento dell’esperienza in R, potresti voler creare oggetti più complessi. Per aiutarti, R offre numerose funzioni già disponibili nella sua installazione di base, e altre possono essere aggiunte installando pacchetti. Una funzione è un insieme di istruzioni che eseguono un compito specifico. Inoltre, è possibile creare funzioni personalizzate.\n\n6.10.1 La funzione c() per creare vettori\nLa prima funzione utile da imparare è c(), che serve a concatenare valori in un vettore. Ad esempio:\n\nmy_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\n\nQuesto codice crea un oggetto chiamato my_vec che contiene una sequenza di numeri. Alcuni concetti fondamentali sulle funzioni in R:\n\n\nNome e parentesi: Le funzioni in R sono sempre seguite da parentesi tonde ().\n\nArgomenti: Gli elementi passati alla funzione (tra le parentesi) ne personalizzano il comportamento e sono separati da virgole.\n\nPer vedere il contenuto del vettore:\n\nmy_vec\n#&gt; [1] 2 3 1 6 4 3 3 7\n\n\n6.10.2 Funzioni per analizzare vettori\nPuoi utilizzare altre funzioni per calcolare statistiche sul vettore:\n\nmean(my_vec)    # Media\n#&gt; [1] 3.62\n\n\nvar(my_vec)     # Varianza\n#&gt; [1] 3.98\n\n\nsd(my_vec)      # Deviazione standard\n#&gt; [1] 2\n\n\nlength(my_vec)  # Numero di elementi\n#&gt; [1] 8\n\nPuoi anche salvare i risultati in nuovi oggetti per riutilizzarli:\n\nvec_mean &lt;- mean(my_vec)\nvec_mean\n#&gt; [1] 3.62\n\n\n\n\n\n\n\nConcetto Chiave\n\n\n\n\n\nLa varianza e la deviazione standard sono misure statistiche descrittive che sintetizzano in un unico valore numerico la variabilità di un insieme di dati. Questi indici, che verranno approfonditi nel Capitolo 19, forniscono informazioni su quanto i valori di un dataset siano simili o diversi tra loro.\nIn particolare:\n\nla varianza e la deviazione standard sono pari a 0 quando tutti i valori nel dataset sono identici, indicando assenza di variabilità;\nassumono valori più elevati all’aumentare delle differenze tra i dati, segnalando una maggiore dispersione.\n\nPer i nostri scopi attuali, è sufficiente comprendere che queste misure descrivono il grado di diversità o omogeneità dei dati.\n\n\n\n\n6.10.3 Creare sequenze regolari\nPer creare sequenze di numeri in passi regolari, puoi usare i seguenti comandi.\nSimbolo : per sequenze semplici:\n\nmy_seq &lt;- 1:10\nmy_seq\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\nFunzione seq() per maggiore controllo:\n\nmy_seq2 &lt;- seq(from = 1, to = 5, by = 0.5)\nmy_seq2\n#&gt; [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0\n\n\n6.10.4 Ripetere valori\nPuoi ripetere valori o sequenze con la funzione rep().\nRipetere un valore:\n\nmy_seq3 &lt;- rep(2, times = 10)\nmy_seq3\n#&gt;  [1] 2 2 2 2 2 2 2 2 2 2\n\nRipetere una sequenza:\n\nmy_seq5 &lt;- rep(1:5, times = 3)\n\nRipetere ogni elemento di una sequenza:\n\nmy_seq6 &lt;- rep(1:5, each = 3)\nmy_seq6\n#&gt;  [1] 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5\n\n\n6.10.5 Annidare funzioni\nÈ possibile combinare funzioni per creare comandi più complessi, come nell’esempio:\n\nmy_seq7 &lt;- rep(c(3, 1, 10, 7), each = 3)\nmy_seq7\n#&gt;  [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\nPer maggiore leggibilità, puoi separare i passaggi:\n\nin_vec &lt;- c(3, 1, 10, 7)\nmy_seq7 &lt;- rep(in_vec, each = 3)\nmy_seq7\n#&gt;  [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\nQuesta pratica facilita la comprensione del codice e lo rende più chiaro.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#lavorare-con-i-vettori-in-r",
    "href": "chapters/R/01_r_syntax.html#lavorare-con-i-vettori-in-r",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.11 Lavorare con i Vettori in R",
    "text": "6.11 Lavorare con i Vettori in R\nIn R, i vettori sono uno degli elementi fondamentali per manipolare, riassumere e ordinare i dati. Qui trovi una panoramica su come estrarre, sostituire, ordinare, lavorare con dati mancanti e sfruttare la vettorizzazione dei vettori.\n\n6.11.1 Estrarre elementi da un vettore\nPuoi estrarre uno o più elementi da un vettore usando le parentesi quadre [ ].\nPer posizione: Specifica la posizione degli elementi.\n\nmy_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\nmy_vec[3]  # Terzo elemento\n#&gt; [1] 1\n\n\nmy_vec[c(1, 5, 6)]  # Elementi 1°, 5° e 6°\n#&gt; [1] 2 4 3\n\n\nmy_vec[3:8]  # Da 3° a 8°\n#&gt; [1] 1 6 4 3 3 7\n\nCon condizioni logiche: Usa espressioni logiche per selezionare elementi.\n\nmy_vec[my_vec &gt; 4]  # Elementi &gt; 4\n#&gt; [1] 6 7\n\n\nmy_vec[my_vec &lt;= 4]  # Elementi ≤ 4\n#&gt; [1] 2 3 1 4 3 3\n\n\nmy_vec[my_vec != 4]  # Elementi diversi da 4\n#&gt; [1] 2 3 1 6 3 3 7\n\nOperatori logici: Combina condizioni con & (AND) e | (OR).\n\nmy_vec[my_vec &gt; 2 & my_vec &lt; 6]  # Tra 2 e 6\n#&gt; [1] 3 4 3 3\n\n\n6.11.2 Sostituire elementi in un vettore\nPuoi modificare i valori di un vettore usando [ ] e l’operatore &lt;-.\nUn singolo elemento:\n\nmy_vec[4] &lt;- 500  # Cambia il 4° elemento\nmy_vec\n#&gt; [1]   2   3   1 500   4   3   3   7\n\nPiù elementi:\n\nmy_vec[c(6, 7)] &lt;- 100  # Cambia il 6° e 7° elemento\nmy_vec\n#&gt; [1]   2   3   1 500   4 100 100   7\n\nCon condizioni logiche:\n\nmy_vec[my_vec &lt;= 4] &lt;- 1000  # Cambia valori ≤ 4\nmy_vec\n#&gt; [1] 1000 1000 1000  500 1000  100  100    7\n\n\n6.11.3 Ordinare un vettore\nDal più piccolo al più grande:\n\nvec_sort &lt;- sort(my_vec)\nvec_sort\n#&gt; [1]    7  100  100  500 1000 1000 1000 1000\n\nDal più grande al più piccolo:\n\nvec_sort2 &lt;- sort(my_vec, decreasing = TRUE)\nvec_sort2\n#&gt; [1] 1000 1000 1000 1000  500  100  100    7\n\nOrdinare un vettore in base a un altro:\n\nheight &lt;- c(180, 155, 160, 167, 181)\np.names &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\", \"Karen\", \"Amy\")\nheight_ord &lt;- order(height)\nnames_ord &lt;- p.names[height_ord]\nnames_ord\n#&gt; [1] \"Charlotte\" \"Helen\"     \"Karen\"     \"Joanna\"    \"Amy\"",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#operazioni-vettoriali-e-vettorizzazione-in-r",
    "href": "chapters/R/01_r_syntax.html#operazioni-vettoriali-e-vettorizzazione-in-r",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.12 Operazioni vettoriali e vettorizzazione in R",
    "text": "6.12 Operazioni vettoriali e vettorizzazione in R\nLa vettorializzazione è una delle caratteristiche più potenti di R, che consente di applicare operazioni o funzioni direttamente a tutti gli elementi di un vettore in modo simultaneo, senza dover ricorrere a cicli espliciti. Questo approccio rende il codice più conciso, leggibile ed efficiente, sfruttando al meglio le capacità intrinseche del linguaggio.\n\n6.12.1 Operazioni aritmetiche su vettori\nLe operazioni algebriche in R, come addizione, sottrazione, moltiplicazione e divisione, sono vettorizzate. Questo significa che ogni operazione viene applicata “elemento per elemento” al vettore.\nConsideriamo ad esempio il seguente vettore:\n\nmy_vec &lt;- c(3, 5, 7, 1, 9, 20)\n\nSe vogliamo moltiplicare ciascun elemento di my_vec per 5, possiamo scrivere:\n\nmy_vec * 5\n#&gt; [1]  15  25  35   5  45 100\n\nAnalogamente, possiamo effettuare altre operazioni algebriche, come divisione o elevamento a potenza:\n\nmy_vec / 2\n#&gt; [1]  1.5  2.5  3.5  0.5  4.5 10.0\n\n\nmy_vec^2\n#&gt; [1]   9  25  49   1  81 400\n\nQueste operazioni vengono applicate automaticamente a ciascun elemento del vettore, senza dover iterare su di essi.\n\n6.12.2 Operazioni elemento per elemento tra due vettori\nLa vettorializzazione consente anche di eseguire operazioni tra due vettori, applicandole elemento per elemento. Supponiamo di avere un secondo vettore:\n\nmy_vec2 &lt;- c(17, 15, 13, 19, 11, 0)\n\nSe vogliamo sommare i due vettori, possiamo scrivere:\n\nmy_vec + my_vec2\n#&gt; [1] 20 20 20 20 20 20\n\nIn questo caso, il primo elemento di my_vec viene sommato al primo elemento di my_vec2, il secondo elemento al secondo, e così via.\n\nEsempio 6.3 Di seguito mostriamo come calcolare i punteggi totali per 10 individui che hanno risposto ai 5 item della Satisfaction With Life Scale (SWLS), utilizzando le formule e l’aritmetica vettorializzata di R.\nStep 1: Definiamo i punteggi per ciascun item. Ogni vettore contiene i punteggi dati dai 10 individui a uno specifico item della scala:\n\n# Punteggi dei 10 individui per ciascun item\nitem1 &lt;- c(5, 4, 6, 7, 3, 2, 5, 6, 4, 7)\nitem2 &lt;- c(3, 2, 4, 6, 2, 1, 4, 5, 3, 6)\nitem3 &lt;- c(4, 5, 6, 5, 3, 2, 5, 7, 4, 5)\nitem4 &lt;- c(2, 3, 4, 3, 2, 1, 3, 4, 2, 5)\nitem5 &lt;- c(2, 2, 3, 4, 1, 1, 3, 3, 2, 4)\n\nI valori 5, 3, 4, 2, 2 sono i punteggi del primo individuo sui 5 item; i punteggio 4, 2, 5, 3, 2 sono i punteggi del secondo individuo sui 5 item, e così via.\nStep 2: Sommiamo i punteggi per calcolare il totale. Il punteggio totale di ciascun individuo è la somma dei punteggi relativi ai 5 item. Formalmente, per l’individuo \\(i\\) (\\(i = 1, 2, \\ldots, 10\\)), il punteggio totale è calcolato come:\n\\[\n\\text{PunteggioTotale}_i = \\text{item1}_i + \\text{item2}_i + \\text{item3}_i + \\text{item4}_i + \\text{item5}_i .\n\\]\nIn R, possiamo sommare i vettori direttamente grazie all’aritmetica vettorializzata:\n\n# Calcolo dei punteggi totali per ciascun individuo\ntotal_scores &lt;- item1 + item2 + item3 + item4 + item5\ntotal_scores\n#&gt;  [1] 16 16 23 25 11  7 20 25 15 27\n\nIl risultato è un vettore con i punteggi totali per ciascun individuo.\nStep 3: Mostriamo i risultati. Per organizzare meglio i dati, creiamo una tabella che associa i punteggi totali agli individui:\n\n# Creiamo una tabella con i punteggi totali\nindividui &lt;- paste(\"Individuo\", 1:10)\nrisultati_swls &lt;- data.frame(Individuo = individui, PunteggioTotale = total_scores)\nprint(risultati_swls)\n#&gt;       Individuo PunteggioTotale\n#&gt; 1   Individuo 1              16\n#&gt; 2   Individuo 2              16\n#&gt; 3   Individuo 3              23\n#&gt; 4   Individuo 4              25\n#&gt; 5   Individuo 5              11\n#&gt; 6   Individuo 6               7\n#&gt; 7   Individuo 7              20\n#&gt; 8   Individuo 8              25\n#&gt; 9   Individuo 9              15\n#&gt; 10 Individuo 10              27\n\nSpiegazione delle operazioni:\n\nOgni vettore contiene i punteggi di 10 individui per un dato item. Ad esempio, il vettore item1 contiene i punteggi relativi al primo item, e così via.\n\nGrazie all’aritmetica vettorializzata, quando sommiamo i vettori \\(\\text{item1}\\), \\(\\text{item2}\\), \\(\\text{item3}\\), \\(\\text{item4}\\), \\(\\text{item5}\\), R somma elemento per elemento:\n\\[\n\\text{total\\_scores}_i = \\text{item1}_i + \\text{item2}_i + \\text{item3}_i + \\text{item4}_i + \\text{item5}_i\n\\]\n\nQuesta tecnica consente di calcolare rapidamente i punteggi totali per tutti gli individui senza dover scrivere un ciclo esplicito, rendendo il codice più semplice e leggibile.\n\nQuesto esempio illustra come R semplifichi operazioni complesse grazie al calcolo vettorializzato, migliorando l’efficienza e la chiarezza del codice.\n\n\n6.12.3 Attenzione al riciclo dei vettori\nSe i due vettori hanno lunghezze diverse, R applicherà il meccanismo di riciclo: gli elementi del vettore più corto verranno ripetuti ciclicamente per abbinarsi alla lunghezza del vettore più lungo. Questo comportamento, sebbene utile, richiede attenzione per evitare risultati inattesi.\nAd esempio:\n\nshort_vec &lt;- c(1, 2)\nmy_vec + short_vec\n#&gt; [1]  4  7  8  3 10 22\n\nIn questo caso, gli elementi di short_vec vengono riciclati per abbinarsi alla lunghezza di my_vec. Il risultato è:\n(3+1, 5+2, 7+1, 1+2, 9+1, 20+2)\n\n6.12.4 Applicazione di funzioni su vettori\nLa vettorializzazione non si limita alle operazioni algebriche, ma si estende anche all’uso di funzioni. Supponiamo di voler calcolare il logaritmo naturale di ciascun elemento di un vettore:\n\nlog(my_vec)\n#&gt; [1] 1.10 1.61 1.95 0.00 2.20 3.00\n\nLa funzione log() viene applicata automaticamente a ogni elemento del vettore. Analogamente, possiamo utilizzare altre funzioni predefinite di R, come:\n\nsqrt(my_vec)  # Calcola la radice quadrata di ciascun elemento\n#&gt; [1] 1.73 2.24 2.65 1.00 3.00 4.47\nexp(my_vec)   # Eleva e alla potenza specificata da ciascun elemento\n#&gt; [1]        20.09       148.41      1096.63         2.72      8103.08\n#&gt; [6] 485165195.41\n\nIn conclusione, la vettorializzazione in R rappresenta un approccio elegante ed efficiente per gestire calcoli su vettori. Che si tratti di operazioni algebriche, operazioni tra vettori o applicazione di funzioni, la possibilità di evitare cicli espliciti migliora la leggibilità e la velocità del codice. Tuttavia, è importante prestare attenzione al riciclo dei vettori per evitare errori non intenzionali.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#gestire-dati-mancanti-na",
    "href": "chapters/R/01_r_syntax.html#gestire-dati-mancanti-na",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.13 Gestire dati mancanti (NA)",
    "text": "6.13 Gestire dati mancanti (NA)\nR rappresenta i dati mancanti con NA. La gestione dei dati mancanti dipende dalla funzione utilizzata.\nCalcolo con dati mancanti:\n\ntemp &lt;- c(7.2, NA, 7.1, 6.9, 6.5, 5.8, 5.8, 5.5, NA, 5.5)\nmean(temp)  # Restituisce NA\n#&gt; [1] NA\n\n\nmean(temp, na.rm = TRUE)  # Ignora i valori mancanti\n#&gt; [1] 6.29\n\nNota: na.rm = TRUE è un argomento comune per ignorare i NA, ma non tutte le funzioni lo supportano. Consulta la documentazione della funzione per verificare come gestisce i dati mancanti.\nIn conclusione, manipolare vettori è un’abilità essenziale in R. Dalla selezione e modifica degli elementi all’ordinamento e gestione di dati mancanti, queste tecniche sono alla base dell’analisi dei dati in R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#i-dati-in-r",
    "href": "chapters/R/01_r_syntax.html#i-dati-in-r",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.14 I dati in R",
    "text": "6.14 I dati in R\nIn R, i dati possono essere rappresentati in diversi tipi e strutture. Comprendere come gestirli è fondamentale per manipolare, analizzare e riassumere i dataset più complessi.\n\n6.14.1 Tipi di dati in R\nR supporta diversi tipi di dati:\n\n\nNumeric: Numeri decimali (es. 2.5).\n\nInteger: Numeri interi (es. 3).\n\nLogical: Valori booleani (TRUE o FALSE) e NA per dati mancanti.\n\nCharacter: Stringhe di testo (es. \"hello\").\n\nFactor: Variabili categoriche (es. livelli come \"low\", \"medium\", \"high\").\n\nPuoi verificare il tipo di un oggetto con class() e controllare se appartiene a un tipo specifico con funzioni come is.numeric(). È anche possibile convertire un tipo in un altro con funzioni come as.character().\n\n6.14.2 Strutture di dati in R\nVettori: Contengono dati dello stesso tipo (es. numeri, stringhe o logici).\n\nmy_vec &lt;- c(1, 2, 3)\nmy_vec\n#&gt; [1] 1 2 3\n\nMatrici e array: Strutture bidimensionali (matrici) o multidimensionali (array) con dati dello stesso tipo.\nCreare una matrice:\n\nmy_mat &lt;- matrix(1:12, nrow = 3, byrow = TRUE)\nmy_mat\n#&gt;      [,1] [,2] [,3] [,4]\n#&gt; [1,]    1    2    3    4\n#&gt; [2,]    5    6    7    8\n#&gt; [3,]    9   10   11   12\n\nOperazioni utili:\n\n\nTrasposizione: t(my_mat)\n\n\nDiagonale: diag(my_mat)\n\n\nMoltiplicazione matriciale: mat1 %*% mat2\n\n\nListe: Possono contenere elementi di tipi diversi, inclusi vettori, matrici o altre liste.\n\nmy_list &lt;- list(\n  numbers = c(1, 2), \n  text = \"hello\", \n  mat = matrix(1:4, nrow = 2)\n)\nmy_list$numbers  # Accedi agli elementi con il nome\n#&gt; [1] 1 2\n\nData frame: Strutture bidimensionali che possono contenere colonne di tipi diversi. Ideale per dataset strutturati.\nCreare un data frame:\n\nheight &lt;- c(180, 155, 160)\nweight &lt;- c(65, 50, 52)\nnames &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\")\n\ndataf &lt;- data.frame(height = height, weight = weight, names = names)\nstr(dataf)  # Mostra la struttura del data frame\n#&gt; 'data.frame':    3 obs. of  3 variables:\n#&gt;  $ height: num  180 155 160\n#&gt;  $ weight: num  65 50 52\n#&gt;  $ names : chr  \"Joanna\" \"Charlotte\" \"Helen\"\n\nPer convertire le stringhe in fattori durante la creazione:\n\ndataf &lt;- data.frame(\n  height = height, \n  weight = weight, \n  names = names, \n  stringsAsFactors = TRUE\n)\n\ndataf\n#&gt;   height weight     names\n#&gt; 1    180     65    Joanna\n#&gt; 2    155     50 Charlotte\n#&gt; 3    160     52     Helen\n\n\n6.14.3 Operazioni utili sui data frame\n\n\nVerificare dimensioni: dim(dataf)\n\n\nVisualizzare struttura: str(dataf)\n\n\nAccedere a colonne: dataf$height",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#operazioni-di-base-in-r",
    "href": "chapters/R/01_r_syntax.html#operazioni-di-base-in-r",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.15 Operazioni di base in R",
    "text": "6.15 Operazioni di base in R\n\n6.15.1 Operazioni aritmetiche\nCome abbiamo visto in precedenza, R supporta le classiche operazioni aritmetiche come somma (+), sottrazione (-), moltiplicazione (*), divisione (/) ed esponenziazione (^).\n\n6.15.2 Operazioni logiche\nLe operazioni logiche in R includono:\n\n\n&: “and” logico\n\n\n|: “or” logico\n\n\n!: “not” logico\n\n\n&gt;: maggiore di\n\n\n&lt;: minore di\n\n\n==: uguale a\n\n\n!=: diverso da\n\nPer esempio:\n\n# Maggiore di\n3 &gt; 2\n#&gt; [1] TRUE\n# Uguale a\n3 == 2\n#&gt; [1] FALSE\n\n\nEsempio 6.4 Consideriamo l’esempio precedente, in cui abbiamo calcolato i punteggi totali dei 10 individui sulla Satisfaction With Life Scale (SWLS). Ora vogliamo determinare la proporzione di individui nel campione che ha ottenuto un punteggio totale maggiore di 15.\nI punteggi totali dei 10 individui sono memorizzati nella colonna PunteggioTotale del data frame risultati_swls:\n\nrisultati_swls$PunteggioTotale\n#&gt;  [1] 16 16 23 25 11  7 20 25 15 27\n\nPossiamo creare un vettore logico che indica, per ciascun individuo, se il suo punteggio totale supera 15. In R, l’operatore di confronto &gt; restituisce un valore TRUE se la condizione è soddisfatta e FALSE altrimenti:\n\nrisultati_swls$PunteggioTotale &gt; 15\n#&gt;  [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE\n\nIn R, i valori TRUE e FALSE possono essere trattati come numeri: TRUE equivale a 1 e FALSE equivale a 0. Questo ci permette di sommare i valori logici per contare quante volte la condizione è soddisfatta. Per calcolare la proporzione, dividiamo questa somma per il numero totale di individui:\n\nsum(risultati_swls$PunteggioTotale &gt; 15) / length(risultati_swls$PunteggioTotale)\n#&gt; [1] 0.7\n\nLa proporzione è calcolata come:\n\\[\n\\text{Proporzione} = \\frac{\\sum_{i=1}^{n} I(\\text{PunteggioTotale}_i &gt; 15)}{n} ,\n\\]\ndove:\n\n\n\\(n\\) è il numero totale di individui (in questo caso, 10),\n\n\\(I(\\text{PunteggioTotale}_i &gt; 15)\\) è una funzione indicatrice che vale 1 se il punteggio dell’individuo \\(i\\) è maggiore di 15, e 0 altrimenti.\n\nNel nostro esempio, la proporzione degli individui con punteggio totale maggiore di 15 è 0.7, cioè il 70% del campione soddisfa questa condizione.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#estrazione-di-sottoinsiemi-di-oggetti-in-r",
    "href": "chapters/R/01_r_syntax.html#estrazione-di-sottoinsiemi-di-oggetti-in-r",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.16 Estrazione di sottoinsiemi di oggetti in R",
    "text": "6.16 Estrazione di sottoinsiemi di oggetti in R\nIn R esistono tre operatori principali per estrarre sottoinsiemi di oggetti:\n\nOperatore [ ]\nQuesto operatore restituisce sempre un oggetto della stessa classe dell’originale. È utile per selezionare più elementi da un oggetto. È importante chiudere l’estrazione con ].\nOperatore [[ ]]\nQuesto operatore viene utilizzato per estrarre elementi da liste o data frame. A differenza di [ ], permette di estrarre un solo elemento alla volta e la classe dell’oggetto restituito non sarà necessariamente una lista o un data frame. L’estrazione va chiusa con ]].\nOperatore $\nCome visto in precedenza, questo operatore serve per estrarre elementi da una lista o un data frame utilizzando il loro nome letterale. Il comportamento semantico è simile a quello di [[ ]].\n\n\n6.16.1 Gli indici di un data frame in R\nIn R, gli indici di un data frame sono utilizzati per selezionare righe e colonne. La sintassi generale è:\ndf[i, j]\ndove:\n\n\ni rappresenta l’indice o gli indici delle righe,\n\n\nj rappresenta l’indice o gli indici delle colonne.\n\nSe uno degli indici viene omesso, si considerano tutte le righe o tutte le colonne, a seconda della dimensione omessa.\n\n6.16.1.1 Esempi pratici\n\n\nSelezione di righe specifiche su tutte le colonne\nSe vogliamo estrarre solo alcune righe, possiamo specificare gli indici delle righe nel primo argomento e lasciare vuoto il secondo. Ad esempio:\ndf[c(2, 3, 5), ]\nQuesto seleziona la seconda, terza e quinta riga del data frame df, includendo tutte le colonne.\n\n\nSelezione di colonne specifiche su tutte le righe\nPer selezionare solo alcune colonne, specifichiamo i loro indici nel secondo argomento e lasciamo vuoto il primo. Ad esempio:\ndf[, c(2, 3, 5)]\nQuesto seleziona la seconda, terza e quinta colonna del data frame df, includendo tutte le righe.\n\n\nSelezione di righe e colonne specifiche\nPossiamo combinare gli indici per selezionare una sotto-matrice specifica. Ad esempio:\ndf[c(2, 4), c(1, 3)]\nQuesto seleziona le righe 2 e 4 e le colonne 1 e 3.\n\n\n6.16.1.2 Ulteriori dettagli\n\n\nSelezione singola di riga o colonna\nSe vogliamo estrarre una singola riga o colonna, possiamo specificare un solo valore per i o j. Ad esempio:\ndf[1, ]  # Prima riga, tutte le colonne\ndf[, 2]  # Seconda colonna, tutte le righe\n\n\nUso di nomi invece di indici\nSe il data frame ha nomi per righe o colonne, possiamo utilizzarli per la selezione. Ad esempio:\ndf[\"nome_riga\", ]        # Seleziona la riga con nome \"nome_riga\"\ndf[, \"nome_colonna\"]     # Seleziona la colonna con nome \"nome_colonna\"\n\n\nSelezione logica\nPossiamo utilizzare un vettore logico per selezionare righe o colonne. Ad esempio, per selezionare le righe dove il valore nella prima colonna è maggiore di 10:\ndf[df[, 1] &gt; 10, ]\n\n\n6.16.1.3 Sintesi visiva\n\n\n\n\n\n\nSintassi\nDescrizione\n\n\n\ndf[i, ]\nSeleziona la riga i con tutte le colonne.\n\n\ndf[, j]\nSeleziona la colonna j con tutte le righe.\n\n\ndf[c(i1, i2), c(j1, j2)]\nSeleziona righe e colonne specifiche.\n\n\ndf[i, j]\nSeleziona l’intersezione di righe e colonne.\n\n\ndf[ , ]\nRestituisce l’intero data frame.\n\n\n\nQuesta flessibilità rende l’indicizzazione dei data frame in R potente ed efficace per manipolare e analizzare i dati.\n\nEsempio 6.5 Consideriamo il data frame iris incluso di default in base R.\n\niris |&gt; head()\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 2          4.9         3.0          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\n#&gt; 4          4.6         3.1          1.5         0.2  setosa\n#&gt; 5          5.0         3.6          1.4         0.2  setosa\n#&gt; 6          5.4         3.9          1.7         0.4  setosa\n\nUsiamo la funzione head() per stampare le prime 6 righe del data frame.\nL’istruzione seguente restituisce le prime tre colonne del dataset iris.\n\niris[, 1:3] |&gt; head()\n#&gt;   Sepal.Length Sepal.Width Petal.Length\n#&gt; 1          5.1         3.5          1.4\n#&gt; 2          4.9         3.0          1.4\n#&gt; 3          4.7         3.2          1.3\n#&gt; 4          4.6         3.1          1.5\n#&gt; 5          5.0         3.6          1.4\n#&gt; 6          5.4         3.9          1.7\n\nSelezione di colonne specifiche per nome:\n\niris[, c('Sepal.Length', 'Petal.Length')] |&gt; \n  head()  \n#&gt;   Sepal.Length Petal.Length\n#&gt; 1          5.1          1.4\n#&gt; 2          4.9          1.4\n#&gt; 3          4.7          1.3\n#&gt; 4          4.6          1.5\n#&gt; 5          5.0          1.4\n#&gt; 6          5.4          1.7\n\nSelezione di una singola colonna:\n\niris[, 'Petal.Length'] \n#&gt;   [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4\n#&gt;  [19] 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2\n#&gt;  [37] 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0\n#&gt;  [55] 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0\n#&gt;  [73] 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0\n#&gt;  [91] 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3\n#&gt; [109] 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0\n#&gt; [127] 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9\n#&gt; [145] 5.7 5.2 5.0 5.2 5.4 5.1\n\noppure\n\niris$Petal.Length\n#&gt;   [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4\n#&gt;  [19] 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2\n#&gt;  [37] 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0\n#&gt;  [55] 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0\n#&gt;  [73] 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0\n#&gt;  [91] 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3\n#&gt; [109] 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0\n#&gt; [127] 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9\n#&gt; [145] 5.7 5.2 5.0 5.2 5.4 5.1\n\nPer selezionare righe specifiche, definiamo gli indici corrispondenti. Per esempio, l’istruzione seguente restituisce le righe 1 e 3.\n\niris[c(1, 3), ]\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\n\nFiltraggio logico di righe:\n\niris[iris$Species == 'versicolor', ] |&gt; head()\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; 51          7.0         3.2          4.7         1.4 versicolor\n#&gt; 52          6.4         3.2          4.5         1.5 versicolor\n#&gt; 53          6.9         3.1          4.9         1.5 versicolor\n#&gt; 54          5.5         2.3          4.0         1.3 versicolor\n#&gt; 55          6.5         2.8          4.6         1.5 versicolor\n#&gt; 56          5.7         2.8          4.5         1.3 versicolor\n\nRestituisce le righe con Species uguale a “versicolor”. Numero di righe e colonne del sottoinsieme:\n\ndim(iris[iris$Species == 'versicolor', ])\n#&gt; [1] 50  5\n\n\n\n6.16.2 Filtraggio avanzato con operatori logici\nGli operatori logici & (AND), | (OR) e ! (NOT) permettono un filtraggio più sofisticato.\nEsempio: Filtrare le osservazioni di specie “versicolor” con lunghezza del sepalo non superiore a 5.0:\n\niris[(iris$Species == 'versicolor') & (iris$Sepal.Length &lt;= 5.0), ]\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; 58          4.9         2.4          3.3           1 versicolor\n#&gt; 61          5.0         2.0          3.5           1 versicolor\n#&gt; 94          5.0         2.3          3.3           1 versicolor\n\nNumero di osservazioni trovate:\n\ndim(iris[(iris$Species == 'versicolor') & (iris$Sepal.Length &lt;= 5.0), ])\n#&gt; [1] 3 5",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#riflessioni-conclusive",
    "href": "chapters/R/01_r_syntax.html#riflessioni-conclusive",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nR non è soltanto un linguaggio di programmazione per la statistica, ma rappresenta una filosofia che si fonda su tre principi chiave: apertura, collaborazione e avanzamento della conoscenza scientifica.\nPer chi si avvicina a R, sia nel campo della comunicazione sia in altri ambiti, cogliere questa filosofia è essenziale per apprezzarne appieno il valore. R promuove non solo competenze tecniche, ma anche un impegno verso pratiche di ricerca trasparente e riproducibile, che costituiscono un pilastro fondamentale per una scienza rigorosa e affidabile.\nOpen Source\nR è un software open source, liberamente accessibile a tutti. Questo significa che chiunque può visualizzarne, modificarne e distribuirne il codice sorgente, promuovendo un ambiente trasparente e collaborativo. Essendo gratuito, R garantisce accessibilità a ricercatori di tutto il mondo, indipendentemente dal budget o dal supporto istituzionale. Inoltre, grazie alla sua natura aperta, R beneficia del contributo collettivo di una comunità globale eterogenea.\nContributi della Comunità\nLa comunità di R è uno dei suoi punti di forza principali. Statistici, ricercatori e data scientist di diverse discipline arricchiscono continuamente R sviluppando pacchetti: raccolte di funzioni, dati e codice che ampliano le sue funzionalità. Questa collaborazione ha portato alla creazione di migliaia di pacchetti che coprono tecniche statistiche, metodi grafici e strumenti per la manipolazione dei dati, rendendo R uno strumento sempre più versatile e adatto a un’ampia gamma di esigenze di ricerca.\nRicerca Riproducibile\nLa ricerca riproducibile consiste nel condurre studi in modo tale che altri possano replicarne i risultati utilizzando gli stessi dati e seguendo la stessa metodologia. Questo approccio è cruciale per la validazione delle scoperte scientifiche, permettendo la verifica dei risultati e la costruzione di nuove conoscenze su basi solide.\nR facilita la ricerca riproducibile grazie a:\n\nUn ecosistema completo di pacchetti per l’analisi dei dati e la generazione di report dinamici.\n\nStrumenti come R Markdown e Quarto, che permettono di integrare testo descrittivo e codice R in un unico documento. Questa integrazione consente di documentare ogni fase del processo di ricerca—dalla pulizia dei dati all’analisi e alla presentazione dei risultati—garantendo trasparenza e replicabilità.\n\nIn conclusione, comprendere la filosofia open source di R e il suo ruolo nella promozione della ricerca riproducibile fornisce un quadro chiaro del motivo per cui R è diventato uno strumento essenziale per ricercatori e statistici di diverse discipline. Per chi opera in psicologia, sfruttare le potenzialità di R significa produrre risultati di ricerca più trasparenti, replicabili e credibili, contribuendo alla robustezza e affidabilità della conoscenza scientifica nel settore.\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nSvolgere gli esercizi da 1 a 38, sia in modo manuale che utilizzando R. Gli esercizi sono disponibili al seguente link:Esercizi su Summation Notation.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nIn questo esercizio, lavorerai con i dati della Satisfaction With Life Scale (SWLS) raccolti da ciascuno degli studenti del gruppo TPV di appartenenza.\nIstruzioni SWLS: Di seguito sono riportate alcune affermazioni con cui puoi descrivere la tua soddisfazione rispetto alla tua vita. Indica quanto sei d’accordo con ciascuna affermazione utilizzando la scala di risposta fornita.\n\nIl più delle volte la mia vita è vicina al mio ideale di vita.\nLe condizioni della mia vita sono eccellenti.\nSono soddisfatto/a della mia vita.\nFinora ho ottenuto le cose importanti che voglio dalla vita.\nSe io potessi rivivere la mia vita, non cambierei quasi nulla.\n\nLa SWLS utilizza una scala Likert a 7 punti, con i seguenti ancoraggi:\n\nFortemente in disaccordo\nDisaccordo\nLeggermente in disaccordo\nNé d’accordo né in disaccordo\nLeggermente d’accordo\nD’accordo\nFortemente d’accordo\n\nIl tuo compito sarà analizzare i dati raccolti sia manualmente su carta che utilizzando R.\nParte 1: Calcolo Manuale\n\n\nCalcolo del punteggio totale\n\nLa SWLS è composta da 5 item, ciascuno valutato su una scala Likert da 1 a 7.\nSomma i punteggi dei 5 item per ciascun partecipante per ottenere il punteggio totale.\n\nRegistra i punteggi totali su carta.\n\n\n\nDeterminazione della media del campione\n\nCalcola la media aritmetica dei punteggi totali dei 10 studenti.\nScrivi il calcolo e il risultato.\n\n\n\nCalcolo della deviazione standard\n\n\nCalcola la deviazione standard dei punteggi totali manualmente utilizzando la formula:\n\\[\ns^2 = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1}}.\n\\]\n\nRegistra il risultato.\n\n\n\nParte 2: Analisi con R\n\n\nCreazione del dataset in R\n\nInserisci i dati in R come un vettore chiamato swls_scores.\n\n\n\nCalcolo della media e della deviazione standard in R\n\nUsa le funzioni mean() e sd() per ottenere la media e la deviazione standard dei punteggi totali.\n\n\n\nVisualizzazione dei dati\n\nCrea un istogramma per visualizzare la distribuzione dei punteggi totali utilizzando hist(). Se non conosci l’istogramma, fai una ricerca su web; commenta il risultato ottenuto.\n\n\n\nIdentificazione dei punteggi superiori a 20\n\nUtilizza un’operazione logica per contare quanti partecipanti hanno un punteggio totale maggiore di 20.\n\n\n\nFiltraggio dei dati\n\nEstrai e visualizza solo i punteggi superiori alla media del campione.\n\n\n\nEsportazione dei risultati\n\nSalva i punteggi totali in un file CSV utilizzando la funzione write.csv().\n\n\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nParte 1: Calcolo Manuale\n\n\nCalcolo del punteggio totale\n\n\nSupponiamo che i punteggi per 10 studenti siano:\n\n\nStudente\nItem 1\nItem 2\nItem 3\nItem 4\nItem 5\nTotale\n\n\n\n1\n5\n4\n6\n3\n2\n20\n\n\n2\n4\n2\n5\n3\n2\n16\n\n\n3\n6\n4\n6\n4\n3\n23\n\n\n4\n7\n6\n5\n3\n4\n25\n\n\n5\n3\n2\n3\n2\n1\n11\n\n\n6\n2\n1\n2\n1\n1\n7\n\n\n7\n5\n4\n5\n3\n3\n20\n\n\n8\n6\n5\n7\n4\n3\n25\n\n\n9\n4\n3\n4\n2\n2\n15\n\n\n10\n7\n6\n5\n5\n4\n27\n\n\n\n\n\n\n\nDeterminazione della media\n\n\nMedia:\n\\[\n\\bar{x} = \\frac{20+16+23+25+11+7+20+25+15+27}{10} = 18.9\n\\]\n\n\n\n\nCalcolo della deviazione standard\n\n\nLa deviazione standard è:\n\\[\ns = \\sqrt{\\frac{1}{9} \\sum (x_i - 18.9)^2} \\approx 6.56\n\\]\n\n\n\n\nParte 2: Analisi con R\n\n\nCreazione del dataset in R\nswls_scores &lt;- c(20, 16, 23, 25, 11, 7, 20, 25, 15, 27)\n\n\nCalcolo della media e della deviazione standard\nmean(swls_scores)  # Media\nsd(swls_scores)    # Deviazione standard\n\n\nVisualizzazione dei dati\nhist(swls_scores, main=\"Distribuzione SWLS\", xlab=\"Punteggi\", col=\"lightblue\", border=\"black\")\n\n\nIdentificazione dei punteggi superiori a 20\nsum(swls_scores &gt; 20)  # Numero di studenti con punteggio &gt; 20\n\n\nFiltraggio dei dati\nswls_scores[swls_scores &gt; mean(swls_scores)]\n\n\nEsportazione dei risultati\nwrite.csv(data.frame(Student=1:10, Score=swls_scores), \"swls_results.csv\", row.names=FALSE)\n\n\nConclusione Questi esercizi hanno permesso di confrontare il calcolo manuale con l’automatizzazione tramite R, facilitando l’analisi statistica della SWLS.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-3         tensorA_0.36.2.1     \n#&gt;  [7] pacman_0.5.1          digest_0.6.37         timechange_0.3.0     \n#&gt; [10] estimability_1.5.1    lifecycle_1.0.4       survival_3.8-3       \n#&gt; [13] magrittr_2.0.3        compiler_4.5.1        rlang_1.1.6          \n#&gt; [16] tools_4.5.1           knitr_1.50            bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.4.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_6.0.6              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.1     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.4.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#bibliografia",
    "href": "chapters/R/01_r_syntax.html#bibliografia",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.\n\n\nKnuth, D. E. (1984). Literate programming. The Computer Journal, 27(2), 97–111.\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A. (2020). Analysis of open data and computational reproducibility in registered reports in psychology. Advances in Methods and Practices in Psychological Science, 3(2), 229–237.\n\n\nOkoye, K., & Hosseini, S. (2024). Introduction to R Programming and RStudio Integrated Development Environment (IDE). In R Programming: Statistical Data Analysis in Research (pp. 3–24). Springer.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html",
    "href": "chapters/R/02_utility_functions.html",
    "title": "7  Utility functions",
    "section": "",
    "text": "7.1 Introduzione\nI n questo capitolo, esploreremo le principali funzioni di utilità in R per l’importazione di dati da file esterni e la raccolta di statistiche descrittive, fornendo una panoramica generale sui data frame.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#introduzione",
    "href": "chapters/R/02_utility_functions.html#introduzione",
    "title": "7  Utility functions",
    "section": "",
    "text": "Panoramica del capitolo\n\nConoscere e sapere utilizzare le principali funzioni di utilità di R.\nSapere come importare un data set in R e esportare un data set in un file esterno.\nUsare i percorsi relativi rispetto alla radice del progetto con here::here().\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nConsultare Introduction to Data Science: Data Wrangling and Visualization with R (Irizarry, 2024)\n\nLeggere R for Data Science (2e) (Wickham et al., 2023).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tidyr)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#importare-dati-in-r-con-rioimport",
    "href": "chapters/R/02_utility_functions.html#importare-dati-in-r-con-rioimport",
    "title": "7  Utility functions",
    "section": "\n7.2 Importare dati in R con rio::import()\n",
    "text": "7.2 Importare dati in R con rio::import()\n\nPrima di analizzare i dati, è necessario importarli in R.\n\n7.2.1 Il problema: Tanti Formati, un’Unica Soluzione\nNella ricerca psicologica i dati possono essere forniti in molti formati:\n\nFile Excel (.xlsx) da questionari compilati in laboratorio,\nCSV (.csv) da piattaforme online come Qualtrics,\nFile SPSS (.sav) per confrontare studi precedenti,\nSolo testo (.txt) da esperimenti comportamentali.\n\nInvece di imparare funzioni diverse, una specifica per ciascun formato, il pacchetto rio offre un solo comando universale per le importazioni.\n\n7.2.2 Come Funziona import()\n\n# Carica il pacchetto (installalo prima con install.packages(\"rio\"))\nlibrary(rio)\n\n# Importa un file CSV da una cartella \"dati\" nel tuo progetto\nrisposte &lt;- rio::import(\"dati/questionario.csv\")\n\n# Importa un foglio Excel con i tempi di reazione\ntempi_reazione &lt;- rio::import(\"dati/esperimento1.xlsx\")\n\n# Importa un file SPSS con dati demografici\ndati_demografici &lt;- rio::import(\"dati/partecipanti.sav\")\nPerché è utile:\n\nriconosce automaticamente il formato dal nome del file;\ntraduce i dati in un formato R pronto per l’analisi (data.frame);\nconserva le etichette delle variabili (cruciale per questionari!).\n\n7.2.3 Esportare Dati con rio::export()\n\nDopo aver pulito i dati, è possibile salvarli in qualsiasi formato usando rio::export():\nrio::export(risposte, \"dati/cleaned/dati_puliti.xlsx\")\nrio::export(tempi_reazione, \"dati/cleaned/tempi_reazione.sav\")",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#utilizzare-percorsi-relativi-con-herehere",
    "href": "chapters/R/02_utility_functions.html#utilizzare-percorsi-relativi-con-herehere",
    "title": "7  Utility functions",
    "section": "\n7.3 Utilizzare Percorsi Relativi con here::here()\n",
    "text": "7.3 Utilizzare Percorsi Relativi con here::here()\n\nQuando importiamo i dati da file esterni in R, succede spesso di commettere uno dei tre errori seguenti. Vediamo come eviarli.\n\n\nPercatori sbagliati\n# SBAGLIATO (il file non è nella cartella di lavoro)\nimport(\"questionario.csv\")  \n\n# CORRETTO: usa percorsi relativi o il pacchetto 'here'\nimport(\"dati/raw/questionario.csv\")  \n\nFile aperti in altri programmi\n“Errore: non posso aprire il file” → Chiudi Excel/SPSS e riprova\n\nCodifica caratteri strani\nSe vedi � nei testi, specifica l’encoding:\nimport(\"dati/testo.txt\", encoding = \"UTF-8\")\n\n\n\n7.3.1 Evitare Percorsi Assoluti\nCome vedremo meglio nel Capitolo 14, il primo passo di un progetto di analisi dei dati è l’organizzazione dei file in cartelle con una struttura chiara:\ntuo_progetto/\n├── dati/\n│   ├── raw/        # Dati originali\n│   └── cleaned/    # Dati elaborati\n├── script/\n└── rapporti/\nTutti i file e le cartelle devono essere contenuti nella directory del progetto.\nIl pacchetto here rende l’importazione dei dati più semplice, evitando problemi dovuti a percorsi assoluti che possono cambiare se si modifica la directory di lavoro o si sposta il progetto.\nLa funzione here() crea percorsi relativi a partire dalla radice del progetto (cioè dalla cartella che contiene il file .Rproj o da dove viene inizializzato il progetto RStudio).\nEsempio di utilizzo combinato con rio::import():\nlibrary(rio)\nlibrary(here)\n\n# Percorso robusto al file csv\ndati &lt;- import(here(\"data\", \"dati.csv\"))\n\n# Percorso robusto al file Excel\ndati_excel &lt;- import(here(\"data\", \"dati.xlsx\"))\nIn questo modo, l’importazione diventa indipendente dalla cartella di lavoro attuale e il codice sarà più facilmente condivisibile e riproducibile.\nVantaggi:\n\n\nSemplicità: rio::import() riconosce automaticamente il tipo di file.\n\nRobustezza: here::here() garantisce che il percorso sia sempre corretto, indipendentemente da dove viene eseguito lo script.\n\nQuesta combinazione rende le analisi riproducibili e consente di collaborare facilmente con altri ricercatori o studenti.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#funzioni-principali-e-loro-utilizzo",
    "href": "chapters/R/02_utility_functions.html#funzioni-principali-e-loro-utilizzo",
    "title": "7  Utility functions",
    "section": "\n7.4 Funzioni Principali e Loro Utilizzo",
    "text": "7.4 Funzioni Principali e Loro Utilizzo\nR offre una serie di funzioni per esplorare rapidamente i dati e comprenderne la struttura prima di passare a manipolazioni più avanzate.\n\n\n\n\n\n\nFunzione\nDescrizione\n\n\n\nsummary()\nRestituisce statistiche descrittive di base per ogni colonna di un data frame. Per le colonne numeriche, calcola valori come il minimo, massimo, media, mediana, primo e terzo quartile, e il numero di valori mancanti (se presenti). Per le colonne non numeriche, restituisce il tipo di dati (carattere, logico) e il conteggio delle categorie. Esempio: summary(iris) restituisce una sintesi delle colonne del dataset iris.\n\n\n\nstr() e glimpse()\n\nForniscono una rappresentazione sintetica delle informazioni di un data frame, come dimensione, nomi delle colonne, tipi di dati e valori iniziali. La funzione str() fa parte della configurazione base di R (pacchetto utils), mentre glimpse() è inclusa in dplyr (pacchetto tidyverse). Esempio: str(mtcars) o glimpse(mtcars).\n\n\n\nhead() e tail()\n\nPermettono di visualizzare rispettivamente le prime o ultime righe di un data frame. Utile per una rapida ispezione del contenuto. Si può specificare il numero di righe da mostrare (es. head(df, 10)), altrimenti il valore predefinito è sei righe. Esempio: head(iris) per vedere le prime righe del dataset iris.\n\n\n\nView() e view()\n\nVisualizzano un data frame in una finestra grafica tipo foglio di calcolo all’interno di RStudio. La funzione View() è parte della configurazione base di R, mentre view() è un alias fornito da tibble (pacchetto tidyverse). Utile per piccoli data frame, ma poco pratico per dataset di grandi dimensioni. Esempio: View(iris) apre il dataset iris nel visualizzatore di RStudio.\n\n\nunique()\nRestituisce i valori unici presenti in una colonna o in un vettore. Esempio: unique(iris$Species) restituisce le specie uniche nel dataset iris.\n\n\nnames()\nRestituisce i nomi delle colonne di un data frame. Esempio: names(mtcars) restituisce i nomi delle colonne del dataset mtcars.\n\n\nclass()\nIndica il tipo di dato di un oggetto in R, come numeric, character, logical, o data.frame. Esempio: class(iris) restituisce data.frame.\n\n\nlength()\nRestituisce il numero di elementi di un oggetto. Per i data frame, restituisce il numero di colonne. Esempio: length(iris) restituisce 5 (colonne).\n\n\n\nnrow() e ncol()\n\nRestituiscono rispettivamente il numero di righe e colonne di un data frame. Esempio: nrow(iris) restituisce 150 (righe), mentre ncol(iris) restituisce 5 (colonne).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#illustrazione",
    "href": "chapters/R/02_utility_functions.html#illustrazione",
    "title": "7  Utility functions",
    "section": "\n7.5 Illustrazione",
    "text": "7.5 Illustrazione\nImmagina di dover analizzare i dati del tuo esperimento sul sonno e la memoria, salvati nel file msleep.csv. La struttura del tuo progetto RStudio è organizzata così:\nmio_esperimento/\n├── mio_esperimento.Rproj\n├── data/\n│   └── msleep.csv\n├── script/\n│   └── analisi.R\n└── output/\nLa prima cosa da fare è caricare i pacchetti necessari:\nlibrary(rio)    # Per importare i dati\nlibrary(here)   # Per gestire i percorsi in modo affidabile\nA questo punto possiamo importare i dati:\n\nmsleep &lt;- rio::import(\n  here::here(  # Costruisce il percorso automaticamente\n    \"data\",    # Cartella dei dati\n    \"msleep.csv\"  # Nome del file\n  )\n)\n\nControlli post-importazione (fondamentali!)\n\nhead(msleep)\n#&gt;                         name      genus  vore        order conservation\n#&gt; 1                    Cheetah   Acinonyx carni    Carnivora           lc\n#&gt; 2                 Owl monkey      Aotus  omni     Primates             \n#&gt; 3            Mountain beaver Aplodontia herbi     Rodentia           nt\n#&gt; 4 Greater short-tailed shrew    Blarina  omni Soricomorpha           lc\n#&gt; 5                        Cow        Bos herbi Artiodactyla domesticated\n#&gt; 6           Three-toed sloth   Bradypus herbi       Pilosa             \n#&gt;   sleep_total sleep_rem sleep_cycle awake brainwt  bodywt\n#&gt; 1        12.1        NA          NA  11.9      NA  50.000\n#&gt; 2        17.0       1.8          NA   7.0 0.01550   0.480\n#&gt; 3        14.4       2.4          NA   9.6      NA   1.350\n#&gt; 4        14.9       2.3       0.133   9.1 0.00029   0.019\n#&gt; 5         4.0       0.7       0.667  20.0 0.42300 600.000\n#&gt; 6        14.4       2.2       0.767   9.6      NA   3.850\n\n\nstr(msleep)\n#&gt; 'data.frame':    83 obs. of  11 variables:\n#&gt;  $ name        : chr  \"Cheetah\" \"Owl monkey\" \"Mountain beaver\" \"Greater short-tailed shrew\" ...\n#&gt;  $ genus       : chr  \"Acinonyx\" \"Aotus\" \"Aplodontia\" \"Blarina\" ...\n#&gt;  $ vore        : chr  \"carni\" \"omni\" \"herbi\" \"omni\" ...\n#&gt;  $ order       : chr  \"Carnivora\" \"Primates\" \"Rodentia\" \"Soricomorpha\" ...\n#&gt;  $ conservation: chr  \"lc\" \"\" \"nt\" \"lc\" ...\n#&gt;  $ sleep_total : num  12.1 17 14.4 14.9 4 14.4 8.7 7 10.1 3 ...\n#&gt;  $ sleep_rem   : num  NA 1.8 2.4 2.3 0.7 2.2 1.4 NA 2.9 NA ...\n#&gt;  $ sleep_cycle : num  NA NA NA 0.133 0.667 ...\n#&gt;  $ awake       : num  11.9 7 9.6 9.1 20 9.6 15.3 17 13.9 21 ...\n#&gt;  $ brainwt     : num  NA 0.0155 NA 0.00029 0.423 NA NA NA 0.07 0.0982 ...\n#&gt;  $ bodywt      : num  50 0.48 1.35 0.019 600 ...\n\n\nglimpse(msleep)\n#&gt; Rows: 83\n#&gt; Columns: 11\n#&gt; $ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater shor…\n#&gt; $ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", \"Bra…\n#&gt; $ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"carn…\n#&gt; $ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", \"Art…\n#&gt; $ conservation &lt;chr&gt; \"lc\", \"\", \"nt\", \"lc\", \"domesticated\", \"\", \"vu\", \"\", \"dome…\n#&gt; $ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.0, 5…\n#&gt; $ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0.8, …\n#&gt; $ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.133, 0.667, 0.767, 0.383, NA, 0.333, NA, NA…\n#&gt; $ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.0, 1…\n#&gt; $ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.07000, 0…\n#&gt; $ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, 0.04…\n\n\nnames(msleep)\n#&gt;  [1] \"name\"         \"genus\"        \"vore\"         \"order\"        \"conservation\"\n#&gt;  [6] \"sleep_total\"  \"sleep_rem\"    \"sleep_cycle\"  \"awake\"        \"brainwt\"     \n#&gt; [11] \"bodywt\"\n\n\ndim(msleep)\n#&gt; [1] 83 11\n\nErrori comuni e soluzioni.\n\n\n“File not found”:\n\nVerifica che:\n\nil file sia realmente in data/;\nil nome del file sia esatto (attenzione a .csv vs .CSV);\n\nnon ci siano spazi nel nome del file.\n\n\n\n\n\nPacchetti non installati:\n# Esegui una volta\ninstall.packages(\"rio\")\ninstall.packages(\"here\")\n\n\nProgetto non aperto:\n\nAssicurati di aver aperto il file .Rproj prima di iniziare.\n\n\n\nEsaminiamo le modalità della variabile qualitativa vore:\n\nunique(msleep$vore)\n#&gt; [1] \"carni\"   \"omni\"    \"herbi\"   \"\"        \"insecti\"\n\nSe vogliamo la numerosità di ciascuna categoria, possiamo usare table():\n\ntable(msleep$vore)\n#&gt; \n#&gt;           carni   herbi insecti    omni \n#&gt;       7      19      32       5      20\n\nSi noti che table() esclude i dati mancanti.\nStampiamo i nomi delle colonne del data frame:\n\nnames(msleep)\n#&gt;  [1] \"name\"         \"genus\"        \"vore\"         \"order\"        \"conservation\"\n#&gt;  [6] \"sleep_total\"  \"sleep_rem\"    \"sleep_cycle\"  \"awake\"        \"brainwt\"     \n#&gt; [11] \"bodywt\"\n\nEsaminiamo il tipo di variabile della colonna vore:\n\nclass(msleep$vore)\n#&gt; [1] \"character\"\n\nLe dimensioni del data frame sono date da:\n\ndim(msleep)\n#&gt; [1] 83 11\n\nladdove il primo valore è il numero di righe e il secondo valore è il numero di colonne.\nIl numero di elementi di un vettore è dato da:\n\nlength(msleep$vore)\n#&gt; [1] 83\n\nIn alternativa, possiamo usare nrow()\n\nnrow(msleep)\n#&gt; [1] 83\n\nper il numero di righe e ncol()\n\nncol(msleep)\n#&gt; [1] 11\n\nper il numero di colonne. In maniera equivalente:\n\ndim(msleep)[2]\n#&gt; [1] 11\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, utilizzerai R per esplorare i dati raccolti con il questionario Satisfaction With Life Scale (SWLS) dagli studenti del tuo gruppo TPV. L’obiettivo è familiarizzare con le funzioni di base di R per caricare, visualizzare e manipolare i dati.\nParte 1: Operazioni Manuali\n\n\nCreazione e gestione degli oggetti in R\n\nScrivi su carta i comandi R che creerebbero un oggetto chiamato swls_scores contenente i punteggi di 10 studenti.\nQuali sono le regole per assegnare un nome a un oggetto in R?\n\n\n\nVisualizzazione dei dati\n\nScrivi il comando R per visualizzare il contenuto dell’oggetto swls_scores.\nCome puoi visualizzare solo i primi 5 valori del vettore?\n\n\n\nEsplorazione della struttura dei dati\n\nScrivi i comandi R per verificare il tipo di dati contenuti in swls_scores.\nCome puoi verificare quanti elementi contiene?\n\n\n\nParte 2: Esecuzione in R\n\n\nCreazione del dataset in R\n\nInserisci i dati in un oggetto chiamato swls_scores in R.\n\n\n\nVerifica della struttura dei dati\n\nUsa le funzioni str(), class(), length(), nrow(), ncol() su swls_scores.\nAnnota i risultati e spiega a parole loro significato.\n\n\n\nVisualizzazione dei dati\n\nUsa head() e tail() per esplorare i dati.\n\nQual è la differenza tra le due funzioni?\n\n\n\nIdentificazione dei valori unici\n\nUsa unique(swls_scores) per individuare i punteggi distinti.\n\n\n\nCreazione di una tabella con i dati\n\nTrasforma swls_scores in un data frame con una colonna \"Punteggio\" e una colonna \"Studente\" (numerata da 1 a 10).\n\n\n\nEsportazione dei dati\n\nSalva il data frame in un file CSV chiamato \"swls_data.csv\" usando write.csv().\n\n\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nParte 1: Operazioni Manuali\n\n\nCreazione e gestione degli oggetti in R\n\n\nConsideriamo dei valori di risposta arbitrari. Il comando per creare l’oggetto swls_scores è:\nswls_scores &lt;- c(20, 16, 23, 25, 11, 7, 20, 25, 15, 27)\n\n\nRegole per assegnare un nome a un oggetto in R:\n\nNon può iniziare con un numero.\nNon può contenere spazi o caratteri speciali (tranne _ e .).\nNon deve avere lo stesso nome di funzioni già esistenti.\n\n\n\n\n\nVisualizzazione dei dati\n\n\nPer visualizzare il contenuto:\nswls_scores\n\n\nPer visualizzare solo i primi 5 valori:\nhead(swls_scores, 5)\n\n\n\n\nEsplorazione della struttura dei dati\n\n\nPer verificare il tipo di dati:\nclass(swls_scores)\n\n\nPer verificare il numero di elementi:\nlength(swls_scores)\n\n\n\n\nParte 2: Esecuzione in R\n\n\nCreazione del dataset in R\nswls_scores &lt;- c(20, 16, 23, 25, 11, 7, 20, 25, 15, 27)\n\n\nVerifica della struttura dei dati\nstr(swls_scores)\nclass(swls_scores)\nlength(swls_scores)\n\n\nstr() mostra che swls_scores è un vettore numerico.\n\nclass() conferma che è di tipo \"numeric\".\n\nlength() indica che il vettore ha 10 elementi.\n\n\n\nVisualizzazione dei dati\nhead(swls_scores)\ntail(swls_scores)\n\n\nhead() mostra i primi 6 elementi, tail() gli ultimi 6.\n\n\n\nIdentificazione dei valori unici\nunique(swls_scores)\n\nRestituisce: 7, 11, 15, 16, 20, 23, 25, 27.\n\n\n\nCreazione di una tabella con i dati\ndf_swls &lt;- data.frame(Studente = 1:10, Punteggio = swls_scores)\ndf_swls\n\n\nEsportazione dei dati\nwrite.csv(df_swls, \"swls_data.csv\", row.names=FALSE)\n\n\nConclusione\nQuesti esercizi hanno introdotto i comandi di base per creare, visualizzare e manipolare dati in R.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] rmarkdown_2.29        ragg_1.4.0            purrr_1.1.0          \n#&gt; [19] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [22] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [25] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [28] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [31] pacman_0.5.1          R.utils_2.13.0        Matrix_1.7-4         \n#&gt; [34] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [37] abind_1.4-8           codetools_0.2-20      curl_7.0.0           \n#&gt; [40] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [43] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [46] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [49] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [52] generics_0.1.4        rprojroot_2.1.1       rstantools_2.4.0     \n#&gt; [55] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [58] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [61] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [64] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [67] textshaping_1.0.1     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [70] V8_6.0.6              gtable_0.3.6          R.methodsS3_1.8.2    \n#&gt; [73] digest_0.6.37         TH.data_1.1-3         htmlwidgets_1.6.4    \n#&gt; [76] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [79] R.oo_1.27.1           lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#bibliografia",
    "href": "chapters/R/02_utility_functions.html#bibliografia",
    "title": "7  Utility functions",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html",
    "href": "chapters/R/03_r_programming.html",
    "title": "8  Programmazione",
    "section": "",
    "text": "8.1 Introduzione\nI n questo capitolo esploreremo tre strumenti fondamentali per la scrittura di codice in R: le funzioni, le istruzioni condizionali e i cicli. Questi elementi costituiscono la base per sviluppare script flessibili, efficienti e riutilizzabili, essenziali per ogni programmatore o analista che utilizza R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#introduzione",
    "href": "chapters/R/03_r_programming.html#introduzione",
    "title": "8  Programmazione",
    "section": "",
    "text": "Prerequisiti\n\n\n\n\n\n\nConsultare Introduction to Data Science: Data Wrangling and Visualization with R (Irizarry, 2024)\n\nLeggere R for Data Science (2e).\nConsultare la Tidyverse style guide.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tidyr)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#funzioni",
    "href": "chapters/R/03_r_programming.html#funzioni",
    "title": "8  Programmazione",
    "section": "\n8.2 Funzioni",
    "text": "8.2 Funzioni\nR offre un’ampia gamma di funzioni integrate per supportare l’analisi statistica, la manipolazione dei dati e la visualizzazione grafica, rendendolo uno strumento estremamente versatile per diverse esigenze.\nEsempi di funzioni comuni includono:\n\n# Sommare numeri\nsum(1, 2, 3)  # Restituisce la somma dei numeri\n#&gt; [1] 6\n\n\n# Creare un grafico semplice\nplot(1:10, 1:10)  # Crea un grafico a dispersione dei valori\n\n\n\n\n\n\n\nIn sostanza, una funzione è un blocco di codice progettato per svolgere un’operazione specifica. Puoi pensare a una funzione come a una “black box”: fornisci un input (i dati), la funzione elabora l’informazione attraverso le sue istruzioni e restituisce un output (il risultato). Questo approccio modulare semplifica il lavoro, permettendo di riutilizzare e combinare facilmente diverse operazioni.\n\n8.2.1 Creare Funzioni Personalizzate\nLa creazione di funzioni personalizzate in R è uno strumento essenziale per migliorare la programmazione, soprattutto per gestire operazioni ripetitive o complesse. Le funzioni consentono di rendere il codice più leggibile, efficiente e riutilizzabile, promuovendo un approccio organizzato e chiaro alla risoluzione dei problemi.\n\n8.2.1.1 Vantaggi delle Funzioni Personalizzate\nL’uso di funzioni personalizzate offre numerosi benefici:\n\n\nChiarezza e leggibilità: Un nome descrittivo permette di comprendere immediatamente lo scopo della funzione, anche a distanza di tempo o per altri utenti che leggono il codice.\n\n\nManutenzione semplificata: Modificare il codice all’interno di una funzione aggiorna automaticamente tutte le sue occorrenze, riducendo il rischio di errori e semplificando il debugging.\n\n\nRiduzione degli errori: Si evitano gli errori tipici del copia-e-incolla, come omissioni o incoerenze nei programmi complessi.\n\n\nRiutilizzabilità: Una funzione ben progettata può essere utilizzata in più contesti o progetti, risparmiando tempo e sforzi.\n\n8.2.1.2 Quando Creare una Funzione?\nUn buon criterio per decidere se creare una funzione è osservare se il medesimo blocco di codice viene copiato più volte. Se ti trovi a ripetere lo stesso codice più di due volte, probabilmente è il momento di creare una funzione. Questo aiuta a scrivere codice più pulito, scalabile e professionale, migliorando anche la sostenibilità del lavoro a lungo termine.\n\n8.2.2 Sintassi di una Funzione\nLa struttura base di una funzione in R è la seguente:\nnome_funzione &lt;- function(argomenti) {\n  # Corpo della funzione\n  codice\n  return(risultato)  # Facoltativo: restituisce il valore calcolato\n}\n\n\nnome_funzione: Nome della funzione, scelto per descrivere chiaramente la sua finalità.\n\n\nargomenti: Parametri necessari per eseguire le operazioni all’interno della funzione.\n\n\ncodice: Le istruzioni che definiscono il comportamento della funzione.\n\n\nrisultato: Il valore restituito dalla funzione. Se non si usa return(), R restituisce l’ultimo valore calcolato.\n\n\nEsempio 8.1 Immaginiamo di voler creare una funzione per sommare due numeri.\nsomma_due &lt;- function(a, b) {\n  a + b  # Restituisce la somma dei due numeri\n}\nPer utilizzarla, basta richiamarla specificando i parametri:\nsomma_due(5, 3)  # Restituisce 8\nQuesto approccio aiuta a scrivere codice più leggibile e facile da gestire. Ad esempio, se in futuro volessi modificare il comportamento della somma (ad esempio, aggiungere un messaggio di log), basterà intervenire solo all’interno della funzione.\n\n\nEsempio 8.2 Immaginiamo di avere un dataset con i punteggi di 10 individui su 3 subscale di un test psicometrico. L’obiettivo è:\n\nCreare una funzione per calcolare il punteggio totale di un individuo.\nCreare una funzione per trovare il massimo punteggio totale nel campione.\nCreare una funzione per individuare chi ha ottenuto il massimo punteggio.\n\nPasso 1: Simulazione dei Dati. Simuliamo i punteggi di 10 individui su 3 subscale:\n\n# Simulazione dei punteggi\nset.seed(123)\npunteggi &lt;- data.frame(\n  individuo = paste(\"Individuo\", 1:10),\n  subscale1 = sample(30:50, 10, replace = TRUE),\n  subscale2 = sample(40:60, 10, replace = TRUE),\n  subscale3 = sample(35:55, 10, replace = TRUE)\n)\nprint(punteggi)\n#&gt;       individuo subscale1 subscale2 subscale3\n#&gt; 1   Individuo 1        44        44        48\n#&gt; 2   Individuo 2        48        58        51\n#&gt; 3   Individuo 3        43        48        45\n#&gt; 4   Individuo 4        32        42        41\n#&gt; 5   Individuo 5        39        47        55\n#&gt; 6   Individuo 6        47        46        46\n#&gt; 7   Individuo 7        40        49        49\n#&gt; 8   Individuo 8        34        48        44\n#&gt; 9   Individuo 9        49        58        47\n#&gt; 10 Individuo 10        43        43        41\n\nLa funzione sample() in R è utilizzata per estrarre casualmente un sottoinsieme di valori da un vettore. Nell’esempio sopra, sample() viene utilizzata per generare casualmente i punteggi delle subscale dei test psicometrici.\nNell’istruzione subscale1 &lt;- sample(30:50, 10, replace = TRUE)\n\n\n30:50: Rappresenta il vettore di numeri interi da cui vengono estratti i punteggi (valori possibili tra 30 e 50).\n\n10: Indica che vogliamo estrarre 10 valori.\n\nreplace = TRUE: Consente che lo stesso valore possa essere estratto più volte (estrazione con ripetizione).\n\nPasso 2: Creazione delle Funzioni.\n\n\nCalcolo del punteggio totale per ogni individuo\nQuesta funzione somma i punteggi delle subscale di un individuo:\n\ncalcola_totale &lt;- function(subscale1, subscale2, subscale3) {\n  return(subscale1 + subscale2 + subscale3)\n}\n\n\n\nTrovare il punteggio massimo nel campione\nQuesta funzione accetta un vettore di punteggi totali e restituisce il valore massimo:\n\ntrova_massimo &lt;- function(punteggi_totali) {\n  return(max(punteggi_totali))\n}\n\n\n\nIndividuare l’individuo con il punteggio massimo\nQuesta funzione accetta un data frame con i punteggi e restituisce il nome dell’individuo con il punteggio più alto:\n\ntrova_individuo_massimo &lt;- function(punteggi) {\n  punteggi_totali &lt;- rowSums(punteggi[, c(\"subscale1\", \"subscale2\", \"subscale3\")])\n  indice_massimo &lt;- which.max(punteggi_totali)\n  return(punteggi$individuo[indice_massimo])\n}\n\nLa funzione which.max() restituisce l’indice della posizione in cui si trova il valore massimo in un vettore.\n\n\nPasso 3: Applicazione delle Funzioni\n\n\nCalcolo dei punteggi totali per ogni individuo\nApplichiamo la funzione ai dati simulati:\n\npunteggi$punteggio_totale &lt;- with(\n  punteggi, calcola_totale(subscale1, subscale2, subscale3)\n )\nprint(punteggi)\n#&gt;       individuo subscale1 subscale2 subscale3 punteggio_totale\n#&gt; 1   Individuo 1        44        44        48              136\n#&gt; 2   Individuo 2        48        58        51              157\n#&gt; 3   Individuo 3        43        48        45              136\n#&gt; 4   Individuo 4        32        42        41              115\n#&gt; 5   Individuo 5        39        47        55              141\n#&gt; 6   Individuo 6        47        46        46              139\n#&gt; 7   Individuo 7        40        49        49              138\n#&gt; 8   Individuo 8        34        48        44              126\n#&gt; 9   Individuo 9        49        58        47              154\n#&gt; 10 Individuo 10        43        43        41              127\n\n\n\nTroviamo il punteggio massimo nel campione\n\nmassimo &lt;- trova_massimo(punteggi$punteggio_totale)\nprint(massimo)\n#&gt; [1] 157\n\n\n\nTroviamo chi ha il punteggio massimo\n\nindividuo_massimo &lt;- trova_individuo_massimo(punteggi)\nprint(individuo_massimo)\n#&gt; [1] \"Individuo 2\"\n\n\n\n\n\n8.2.3 Stile\nÈ consigliato di usare nomi di funzioni chiari e descrittivi, preferibilmente verbi (es. compute_mean()). Inoltre, è importante mantenere una struttura leggibile, con spazi coerenti e indentazione.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#istruzioni-condizionali-in-r",
    "href": "chapters/R/03_r_programming.html#istruzioni-condizionali-in-r",
    "title": "8  Programmazione",
    "section": "\n8.3 Istruzioni Condizionali in R",
    "text": "8.3 Istruzioni Condizionali in R\nLe istruzioni condizionali permettono di introdurre logica nel tuo codice. Ad esempio, l’operazione x * y si limita a moltiplicare i valori di x e y, senza alcuna logica aggiunta. Con le istruzioni condizionali, puoi dire al programma di eseguire diverse operazioni a seconda che una condizione sia vera (TRUE) o falsa (FALSE).\nL’istruzione condizionale più comune in R è if. Può essere letta come: “Se la condizione è vera, esegui un’azione”. Con else, si estende la logica: “Se la condizione è vera, fai qualcosa; altrimenti fai qualcos’altro”.\nLa struttura generale è questa:\nif (condizione) {\n  # Codice eseguito se la condizione è TRUE\n} else {\n  # Codice eseguito se la condizione è FALSE\n}\nImmagina questa situazione:\n\n“Se un partecipante al test psicologico riporta un punteggio elevato sulla scala di ansia (es. &gt; 15), consigliagli un esercizio di rilassamento. Altrimenti, non è necessario.”\n\nVediamo come rappresentare questa situazione in R.\n\nanxiety_score &lt;- 18 # Punteggio riportato dal partecipante\n\nif (anxiety_score &gt; 15) {\n    exercise &lt;- \"rilassamento\"\n} else {\n    exercise &lt;- \"nessun esercizio\"\n}\n\nexercise\n#&gt; [1] \"rilassamento\"\n\nSe il punteggio è maggiore di 15, il risultato sarà:\n[1] \"rilassamento\"\nSe il punteggio è inferiore o uguale a 15, il risultato sarà:\n[1] \"nessun esercizio\"\n\n8.3.1 Uso di ifelse()\n\nUn’alternativa più compatta a if e else è la funzione ifelse(), utile soprattutto per vettori. Ad esempio, supponiamo di avere i punteggi di ansia di un gruppo di partecipanti e vogliamo decidere se assegnare un esercizio di rilassamento a ciascuno:\n\nanxiety_scores &lt;- c(12, 18, 9, 22, 15)\nexercises &lt;- ifelse(anxiety_scores &gt; 15, \"rilassamento\", \"nessun esercizio\")\n\nIl risultato sarà:\n\nexercises\n#&gt; [1] \"nessun esercizio\" \"rilassamento\"     \"nessun esercizio\" \"rilassamento\"    \n#&gt; [5] \"nessun esercizio\"\n\n\n8.3.2 Creare una Funzione con Istruzioni Condizionali\nLe istruzioni condizionali possono essere racchiuse in una funzione per rendere il codice più flessibile e riutilizzabile. Ad esempio, supponiamo di voler personalizzare un feedback per un partecipante in base al punteggio ottenuto in un questionario:\n\nfeedback &lt;- function(score) {\n    if (score &gt; 15) {\n        \"Consigliamo un esercizio di rilassamento.\"\n    } else if (score &gt; 10) {\n        \"Monitoriamo la situazione, ma non è necessario alcun intervento.\"\n    } else {\n        \"Nessun intervento necessario.\"\n    }\n}\n\n\nfeedback(18)\n#&gt; [1] \"Consigliamo un esercizio di rilassamento.\"\n\n\nfeedback(12)\n#&gt; [1] \"Monitoriamo la situazione, ma non è necessario alcun intervento.\"\n\n\nfeedback(8)\n#&gt; [1] \"Nessun intervento necessario.\"\n\nIn conclusione, le istruzioni condizionali come if, else e ifelse() sono strumenti fondamentali per introdurre logica e controllo nel tuo codice. Puoi usarle per prendere decisioni, gestire errori e rendere il tuo codice più flessibile ed efficiente. Creare funzioni che incorporano queste istruzioni è un passo fondamentale per scrivere codice ordinato e riutilizzabile in contesti psicologici e non solo.\n\n8.3.3 Combinare Operatori Logici in R\nFinora abbiamo creato funzioni abbastanza semplici e mirate. Ora proviamo a realizzare una funzione leggermente più complessa. Immaginiamo di voler determinare se una persona ha avuto una buona giornata basandoci su due criteri:\n\n\nLivello di stress: basso (TRUE) o alto (FALSE).\n\nLivello di supporto sociale percepito: alto (TRUE) o basso (FALSE).\n\nVogliamo creare una funzione che prenda questi due fattori e restituisca un messaggio che descrive come potrebbe essere stata la giornata della persona.\nEcco come possiamo costruire la funzione:\n\ngood_day &lt;- function(low_stress, high_support) {\n    if (low_stress == TRUE && high_support == TRUE) {\n        \"Giornata fantastica! Ti senti calmo e supportato.\"\n    } else if (low_stress == FALSE && high_support == TRUE) {\n        \"Il supporto sociale ti aiuta a gestire lo stress elevato.\"\n    } else if (low_stress == TRUE && high_support == FALSE) {\n        \"Nonostante lo stress sia basso, la mancanza di supporto sociale pesa.\"\n    } else if (low_stress == FALSE && high_support == FALSE) {\n        \"Giornata difficile: stress elevato e poco supporto sociale.\"\n    }\n}\n\nEsempi di utilizzo.\nCaso 1: Stress basso e supporto sociale alto\n\ngood_day(low_stress = TRUE, high_support = TRUE)\n#&gt; [1] \"Giornata fantastica! Ti senti calmo e supportato.\"\n\nCaso 2: Stress elevato e supporto sociale alto.\n\ngood_day(FALSE, TRUE)\n#&gt; [1] \"Il supporto sociale ti aiuta a gestire lo stress elevato.\"\n\nCaso 3: Stress basso e supporto sociale basso.\n\ngood_day(TRUE, FALSE)\n#&gt; [1] \"Nonostante lo stress sia basso, la mancanza di supporto sociale pesa.\"\n\nCaso 4: Stress elevato e supporto sociale basso.\n\ngood_day(FALSE, FALSE)\n#&gt; [1] \"Giornata difficile: stress elevato e poco supporto sociale.\"\n\nLa funzione considera tutte le combinazioni di stress e supporto sociale:\n\n\nStress basso e supporto alto: giornata ideale.\n\nStress elevato e supporto alto: il supporto aiuta a mitigare lo stress.\n\nStress basso e supporto basso: la mancanza di supporto rovina una situazione potenzialmente buona.\n\nStress elevato e supporto basso: la situazione peggiore.\n\nNell’esempio abbiamo usato i seguenti operatori logici:\n\n\n&& (AND logico): Entrambe le condizioni devono essere vere.\n\n== (uguale a): Verifica se una variabile è vera o falsa.\n\nAd esempio, questa condizione:\nif (low_stress == TRUE && high_support == TRUE)\nverifica se il livello di stress è basso e il supporto sociale è alto.\nIn conclusione, questa funzione dimostra come combinare condizioni logiche complesse utilizzando operatori logici come && (AND) e || (OR). Grazie a questi strumenti, possiamo gestire facilmente logiche più articolate, mantenendo il codice leggibile e funzionale.\n\n8.3.4 Gli operatori Logici in R\nGli operatori logici sono essenziali per definire le condizioni nelle istruzioni if. Ecco una tabella riassuntiva con i principali operatori:\n\n\n\n\n\n\n\n\nOperatore\nDescrizione tecnica\nSignificato\nEsempio\n\n\n\n&&\nAND logico\nEntrambe le condizioni devono essere vere\nif(cond1 == test && cond2 == test)\n\n\n||\nOR logico\nAlmeno una condizione deve essere vera\nif(cond1 == test || cond2 == test)\n\n\n&lt;\nMinore di\nX è minore di Y\nif(X &lt; Y)\n\n\n&gt;\nMaggiore di\nX è maggiore di Y\nif(X &gt; Y)\n\n\n&lt;=\nMinore o uguale a\nX è minore o uguale a Y\nif(X &lt;= Y)\n\n\n&gt;=\nMaggiore o uguale a\nX è maggiore o uguale a Y\nif(X &gt;= Y)\n\n\n==\nUguale a\nX è uguale a Y\nif(X == Y)\n\n\n!=\nDiverso da\nX è diverso da Y\nif(X != Y)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#cicli-in-r",
    "href": "chapters/R/03_r_programming.html#cicli-in-r",
    "title": "8  Programmazione",
    "section": "\n8.4 Cicli in R",
    "text": "8.4 Cicli in R\nR è particolarmente efficace nell’eseguire attività ripetitive. Quando dobbiamo ripetere un’operazione più volte, possiamo utilizzare un ciclo. I cicli eseguono un insieme di istruzioni per un numero specifico di volte o fino a quando una determinata condizione non è soddisfatta.\nIn R esistono tre tipi principali di cicli:\n\n\nCiclo for: ripete un’operazione per un numero definito di iterazioni.\n\nCiclo while: continua a eseguire le istruzioni fino a quando una condizione logica è soddisfatta.\n\nCiclo repeat: itera indefinitamente fino a quando non viene esplicitamente interrotto con un’istruzione break.\n\nI cicli sono strumenti essenziali in tutti i linguaggi di programmazione, ma in R il loro utilizzo dovrebbe essere valutato attentamente, poiché spesso esistono alternative più efficienti come le funzioni della famiglia apply.\n\n8.4.1 Il ciclo for\n\nIl ciclo for è il più utilizzato per eseguire un’operazione un numero definito di volte. Ecco un esempio base:\n\nfor (i in 1:5) {\n    print(i)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nCome funziona?\n\nL’indice i prende il primo valore della sequenza 1:5 (cioè 1).\nIl corpo del ciclo, ovvero il codice tra { }, viene eseguito.\nAl termine di ogni iterazione, i assume il valore successivo nella sequenza, e il processo si ripete fino all’ultimo valore (5 in questo caso).\n\nAggiungere logica nel corpo del ciclo\nPossiamo aggiungere operazioni all’interno del ciclo, come ad esempio sommare 1 a ogni valore:\n\nfor (i in 1:5) {\n    print(i + 1)\n}\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n#&gt; [1] 6\n\n\n8.4.2 Il ciclo while\n\nIl ciclo while continua a eseguire le istruzioni fino a quando una condizione logica è soddisfatta. Ecco un esempio:\n\ni &lt;- 0\nwhile (i &lt;= 4) {\n    i &lt;- i + 1\n    print(i)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nCome funziona?\n\nLa condizione logica (i &lt;= 4) viene verificata prima di ogni iterazione.\nSe la condizione è vera, il ciclo esegue il codice tra { }.\nQuando la condizione diventa falsa (i &gt; 4), il ciclo si interrompe.\n\n8.4.3 Ciclo repeat\n\nIl ciclo repeat esegue il codice indefinitamente, a meno che non venga interrotto con un’istruzione break:\n\ni &lt;- 0\nrepeat {\n    i &lt;- i + 1\n    print(i)\n    if (i &gt;= 5) {\n        break\n    }\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nQuando usarlo?\nIl ciclo repeat è raro e viene utilizzato solo in situazioni molto particolari. Nella maggior parte dei casi, for o while sono più adatti.\n\n8.4.4 Evitare i cicli: la famiglia di funzioni apply\n\nI cicli in R sono relativamente lenti, specialmente con dataset di grandi dimensioni. Quando possibile, è preferibile usare funzioni della famiglia apply per ottenere lo stesso risultato in modo più efficiente e con meno rischi di errore.\n\n8.4.4.1 La funzione lapply()\n\nlapply() esegue una funzione su ciascun elemento di una lista o vettore e restituisce una lista con i risultati.\nEsempio:\n\nlapply(0:4, function(a) {\n    a + 1\n})\n#&gt; [[1]]\n#&gt; [1] 1\n#&gt; \n#&gt; [[2]]\n#&gt; [1] 2\n#&gt; \n#&gt; [[3]]\n#&gt; [1] 3\n#&gt; \n#&gt; [[4]]\n#&gt; [1] 4\n#&gt; \n#&gt; [[5]]\n#&gt; [1] 5\n\n\n8.4.4.2 La funzione sapply()\n\nlapply() restituisce una lista, ma se vuoi un vettore come output, usa sapply():\n\nsapply(0:4, function(a) {\n    a + 1\n})\n#&gt; [1] 1 2 3 4 5\n\n\n8.4.5 Quando usare i cicli?\nI cicli sono utili quando:\n\nDevi simulare modelli complessi (es. modelli ricorsivi).\nHai bisogno di operazioni che dipendono dai risultati delle iterazioni precedenti.\n\nIn tutti gli altri casi, considera alternative come apply(), lapply() o funzioni simili per un codice più efficiente e meno soggetto a errori.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#linee-guida-per-scrivere-codice",
    "href": "chapters/R/03_r_programming.html#linee-guida-per-scrivere-codice",
    "title": "8  Programmazione",
    "section": "\n8.5 Linee Guida per Scrivere Codice",
    "text": "8.5 Linee Guida per Scrivere Codice\nDi seguito trovi alcune linee guida per scrivere codice chiaro, conciso e riutilizzabile:\n\nEvita di ripeterti: Segui il principio Don’t Repeat Yourself (DRY). Scrivi funzioni e utilizza funzioni come map (per applicare un pezzo di codice iterativamente a tutti gli elementi di un oggetto) per evitare di copiare e incollare variazioni minime dello stesso codice in più parti del progetto.\nSegui uno stile coerente: Adotta una guida di stile per mantenere uniformità nel tuo codice. Per R, raccomandiamo la guida di stile del “tidyverse”, scritta da Hadley Wickham. Questa guida, derivata dalla Google R Style Guide, fornisce istruzioni dettagliate su sintassi del codice, nomi delle variabili, spaziature, indentazioni, commenti, convenzioni per scrivere funzioni, utilizzo delle pipe (metodo per concatenare funzioni), e altro ancora.\nCommenta abbondantemente: Usa i commenti (ad esempio, con #) per spiegare perché ogni parte del codice è necessaria e cosa fa. I commenti rendono il codice più leggibile e facilitano la manutenzione futura.\nTesta il tuo codice: Ogni volta che scrivi codice, verifica che funzioni come previsto. Puoi farlo scrivendo funzioni di test specifiche o controllando manualmente che l’output corrisponda alle aspettative. Abituati a pensare a eventuali edge cases (casi limite) in cui il tuo codice potrebbe non comportarsi come previsto.\nEsegui una revisione del codice: Quando possibile, fai revisionare il tuo codice da un’altra persona per individuare errori e incoerenze. Se non hai nessuno a disposizione, puoi rivedere il tuo codice autonomamente: rileggendo con attenzione, è sorprendente il numero di errori che si possono individuare!\n\nSeguendo queste linee guida, potrai scrivere codice più robusto, leggibile e facile da mantenere nel tempo.1",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#riflessioni-conclusive",
    "href": "chapters/R/03_r_programming.html#riflessioni-conclusive",
    "title": "8  Programmazione",
    "section": "\n8.6 Riflessioni Conclusive",
    "text": "8.6 Riflessioni Conclusive\nScrivere funzioni è un passaggio essenziale per migliorare la leggibilità, l’efficienza e la riutilizzabilità del codice. Funzioni ben progettate semplificano le modifiche, riducono errori e rendono il lavoro più chiaro, sia per te stesso che per i collaboratori futuri. Se trovi che stai copiando e incollando codice più volte, è il momento di pensare a creare una funzione.\nLe istruzioni condizionali, come if, else e ifelse(), sono fondamentali per introdurre logica e controllo nel codice. Permettono di gestire scenari diversi e prendere decisioni dinamiche, migliorando la flessibilità e l’efficienza dei tuoi script. Combinando queste istruzioni con operatori logici come && e ||, puoi affrontare situazioni complesse con un codice chiaro e leggibile.\nI cicli sono potenti strumenti per eseguire operazioni ripetitive, ma in R il loro utilizzo dovrebbe essere limitato ai casi in cui non esistono alternative più efficienti. Le funzioni apply() e simili rappresentano spesso un’opzione migliore per manipolare dati in modo più rapido e leggibile.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, utilizzerai R per praticare la creazione di funzioni, l’uso delle istruzioni condizionali e l’applicazione dei cicli. L’obiettivo è comprendere come scrivere codice più strutturato, riutilizzabile ed efficiente.\nParte 1: Comprensione Teorica\n\n\nCos’è una funzione in R?\n\nDescrivi con parole tue cosa fa una funzione e perché è utile.\n\n\n\nSintassi delle funzioni\n\nScrivi la struttura generale di una funzione in R.\n\n\n\nUso di istruzioni condizionali\n\nQual è la differenza tra if, else e ifelse()? Fornisci un esempio per ciascuno.\n\n\n\nCicli in R\n\nQual è la differenza tra for, while e repeat?\n\n\n\nParte 2: Creazione ed Esecuzione in R\n\n\nCreazione di una funzione per calcolare il punteggio totale SWLS\n\nScrivi una funzione in R chiamata calcola_SWLS() che accetta un vettore con 5 punteggi SWLS e restituisce il totale.\n\n\n\nCondizione per determinare la soddisfazione\n\nScrivi una funzione valuta_soddisfazione() che prende un punteggio SWLS totale e restituisce:\n\n\n\"Alta soddisfazione\" se il punteggio è sopra 24.\n\n\"Soddisfazione moderata\" se è tra 15 e 24.\n\n\"Bassa soddisfazione\" se è inferiore a 15.\n\n\n\n\n\nApplicare una funzione a più individui\n\nScrivi un ciclo for che calcola la soddisfazione per un gruppo di 5 persone e stampa il risultato.\n\n\n\nUso di ifelse()\n\nUsa ifelse() per determinare rapidamente se i punteggi di 5 individui indicano soddisfazione alta (&gt; 24) o bassa (≤ 24).\n\n\n\nCiclo while per controllare input\n\nScrivi un ciclo while che continua a chiedere all’utente di inserire un punteggio SWLS fino a quando non inserisce un valore valido (compreso tra 5 e 35).\n\n\n\nEsportazione dei dati\n\n\n\nSalva in un file CSV \"swls_results.csv\" un data frame contenente i punteggi SWLS e la valutazione della soddisfazione.\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nParte 1: Comprensione Teorica\n\n\nCos’è una funzione in R?\n\nUna funzione è un blocco di codice che esegue un’operazione specifica. Permette di scrivere codice riutilizzabile e più organizzato.\n\n\n\nSintassi delle funzioni\nnome_funzione &lt;- function(argomenti) {\n  # Corpo della funzione\n  return(risultato)\n}\n\n\nUso di istruzioni condizionali\n\n\nif: Controlla una condizione e esegue codice solo se è vera.\n\nif (x &gt; 10) { print(\"Maggiore di 10\") }\n\n\nelse: Esegue codice alternativo se la condizione è falsa.\n\nif (x &gt; 10) { print(\"Maggiore di 10\") } else { print(\"10 o meno\") }\n\n\nifelse(): Alternativa vettorializzata a if.\n\ny &lt;- ifelse(x &gt; 10, \"Alto\", \"Basso\")\n\n\nCicli in R\n\n\nfor: Itera su una sequenza.\n\nfor (i in 1:5) { print(i) }\n\n\nwhile: Continua fino a quando una condizione è vera.\n\ni &lt;- 1\nwhile (i &lt;= 5) { print(i); i &lt;- i + 1 }\n\n\nrepeat: Ripete fino a un break.\n\ni &lt;- 1\nrepeat { print(i); i &lt;- i + 1; if (i &gt; 5) break }\n\n\nParte 2: Creazione ed Esecuzione in R\n\n\nCreazione della funzione per il punteggio totale SWLS\ncalcola_SWLS &lt;- function(punteggi) {\n  return(sum(punteggi))\n}\n\n\nCondizione per determinare la soddisfazione\nvaluta_soddisfazione &lt;- function(score) {\n  if (score &gt; 24) {\n    return(\"Alta soddisfazione\")\n  } else if (score &gt;= 15) {\n    return(\"Soddisfazione moderata\")\n  } else {\n    return(\"Bassa soddisfazione\")\n  }\n}\n\n\nApplicazione della funzione a più individui\npunteggi_lista &lt;- list(c(25, 27, 22, 24, 28), c(18, 20, 17, 16, 19))\nfor (punteggi in punteggi_lista) {\n  print(valuta_soddisfazione(calcola_SWLS(punteggi)))\n}\n\n\nUso di ifelse()\npunteggi_totali &lt;- c(28, 19, 15, 10, 25)\nsoddisfazione &lt;- ifelse(punteggi_totali &gt; 24, \"Alta\", \"Bassa\")\nprint(soddisfazione)\n\n\nCiclo while per controllare input\nscore &lt;- 0\nwhile (score &lt; 5 || score &gt; 35) {\n  score &lt;- as.numeric(readline(prompt = \"Inserisci un punteggio SWLS (5-35): \"))\n}\n\nEsportazione dei dati\n\ndf &lt;- data.frame(Punteggio = punteggi_totali, Soddisfazione = soddisfazione)\nwrite.csv(df, \"swls_results.csv\", row.names = FALSE)\nConclusione\nQuesti esercizi hanno mostrato come scrivere funzioni, utilizzare condizioni e cicli per strutturare meglio il codice in R.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-3         tensorA_0.36.2.1     \n#&gt;  [7] pacman_0.5.1          digest_0.6.37         timechange_0.3.0     \n#&gt; [10] estimability_1.5.1    lifecycle_1.0.4       survival_3.8-3       \n#&gt; [13] magrittr_2.0.3        compiler_4.5.1        rlang_1.1.6          \n#&gt; [16] tools_4.5.1           knitr_1.50            bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.4.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_6.0.6              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.1     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.4.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#bibliografia",
    "href": "chapters/R/03_r_programming.html#bibliografia",
    "title": "8  Programmazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#footnotes",
    "href": "chapters/R/03_r_programming.html#footnotes",
    "title": "8  Programmazione",
    "section": "",
    "text": "Un’ottima introduzione alle regole di stile per un progetto di analisi dei dati è fornita in questo capitolo.↩︎",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html",
    "href": "chapters/R/04_r_packages.html",
    "title": "9  Pacchetti",
    "section": "",
    "text": "9.1 Introduzione\nI pacchetti R sono estensioni del linguaggio di programmazione statistica R. Questi pacchetti forniscono una raccolta di risorse che possono essere utilizzate per ampliare le funzionalità di base di R. Ogni pacchetto generalmente include:\nI pacchetti R sono distribuiti e installati attraverso repository centralizzati, il più noto dei quali è CRAN (Comprehensive R Archive Network). CRAN garantisce la qualità e l’affidabilità dei pacchetti, sottoponendoli a controlli rigorosi prima della pubblicazione.\nLa vasta disponibilità di pacchetti è una delle ragioni principali della popolarità di R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#introduzione",
    "href": "chapters/R/04_r_packages.html#introduzione",
    "title": "9  Pacchetti",
    "section": "",
    "text": "Codice: funzioni e script scritti in R (e talvolta in altri linguaggi come C++ o Fortran) che implementano specifiche analisi o strumenti.\nDati: dataset di esempio o utili per testare e dimostrare le funzionalità del pacchetto.\nDocumentazione: file descrittivi che spiegano come utilizzare il pacchetto, spesso in formato manuale o vignette (tutorial pratici).\n\n\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nConsultare Introduction to Data Science: Data Wrangling and Visualization with R (Irizarry, 2024)\nLeggere R for Data Science (2e).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#installare-i-pacchetti-r",
    "href": "chapters/R/04_r_packages.html#installare-i-pacchetti-r",
    "title": "9  Pacchetti",
    "section": "9.2 Installare i pacchetti R",
    "text": "9.2 Installare i pacchetti R\nQuando installi R, vengono installati automaticamente alcuni pacchetti base. Tuttavia, hai la possibilità di aggiungere ulteriori pacchetti che trovi utili per i tuoi scopi. Questi pacchetti sono memorizzati sui server di R (mirror), e l’installazione di un nuovo pacchetto richiede una connessione internet al mirror CRAN che hai scelto durante l’installazione di R.\nPer installare un pacchetto, utilizza il comando:\ninstall.packages(\"&lt;nome_pacchetto&gt;\")\nSostituisci &lt;nome_pacchetto&gt; con il nome del pacchetto che desideri installare. Ad esempio, se vuoi installare il pacchetto rio (utile per importare i dati in R), puoi digitare:\ninstall.packages(\"rio\")   # Non dimenticare le virgolette!",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#caricamento-di-un-pacchetto",
    "href": "chapters/R/04_r_packages.html#caricamento-di-un-pacchetto",
    "title": "9  Pacchetti",
    "section": "9.3 Caricamento di un pacchetto",
    "text": "9.3 Caricamento di un pacchetto\nOgni volta che avvii una nuova sessione di R, se desideri utilizzare un pacchetto, devi caricarlo manualmente. Questo si fa con il comando library(). Ad esempio, dopo aver installato rio, per utilizzarlo digita:\nlibrary(rio)   # Nota: le virgolette non sono necessarie, ma puoi usarle se preferisci.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#utilizzo-delle-funzioni-di-un-pacchetto-senza-caricarlo",
    "href": "chapters/R/04_r_packages.html#utilizzo-delle-funzioni-di-un-pacchetto-senza-caricarlo",
    "title": "9  Pacchetti",
    "section": "9.4 Utilizzo delle funzioni di un pacchetto senza caricarlo",
    "text": "9.4 Utilizzo delle funzioni di un pacchetto senza caricarlo\nSe hai bisogno di utilizzare una funzione specifica di un pacchetto, ma sai che la userai solo una volta, puoi evitare di caricare l’intero pacchetto con library(). Ad esempio, invece di scrivere:\nlibrary(nome_pacchetto)\nfunzione_specifica(x = 2, sd = 3)\npuoi accedere direttamente alla funzione usando l’operatore ::, come indicato di segtuito:\nnome_pacchetto::funzione_specifica(x = 2, sd = 3)\nQuesto approccio è utile per funzioni che usi raramente o una sola volta. Personalmente, utilizzo :: anche quando ho già caricato il pacchetto, per ricordare ad un “me futuro” da quale pacchetto proviene una determinata funzione. Questo può rendere il codice più leggibile e comprensibile nel tempo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#bibliografia",
    "href": "chapters/R/04_r_packages.html#bibliografia",
    "title": "9  Pacchetti",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html",
    "href": "chapters/R/05_dplyr.html",
    "title": "10  Usare dplyr",
    "section": "",
    "text": "Introduzione\nL’  obiettivo di questo capitolo è fornire un’introduzione alle funzioni principali del pacchetto dplyr per le operazioni di data wrangling, cioè per il preprocessing e la pulizia dei dati. In R, queste operazioni sono strettamente legate al concetto di “data tidying”, che si riferisce all’organizzazione sistematica dei dati per facilitare l’analisi.1\nL’essenza del “data tidying” è organizzare i dati in un formato che sia facile da gestire e analizzare. Anche se gli stessi dati possono essere rappresentati in vari modi, non tutte le rappresentazioni sono ugualmente efficienti o facili da usare. Un dataset “tidy” segue tre principi fondamentali che lo rendono particolarmente pratico:\nIl pacchetto R {dplyr} e gli altri pacchetti del tidyverse sono progettati specificamente per lavorare con dati in formato “tidy”, permettendo agli utenti di eseguire operazioni di manipolazione e visualizzazione in modo più intuitivo ed efficiente.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Usare `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#introduzione",
    "href": "chapters/R/05_dplyr.html#introduzione",
    "title": "10  Usare dplyr",
    "section": "",
    "text": "Ogni variabile è una colonna: ogni colonna nel dataset rappresenta una singola variabile.\n\nOgni osservazione è una riga: ogni riga nel dataset rappresenta un’unica osservazione.\n\nOgni valore è una cella: ogni cella del dataset contiene un singolo valore.\n\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere R for Data Science (2e).\nConsultare Data cleaning for social scientists.\nLeggere il capitolo Data Wrangling di Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (Second Edition).\nConsultare Introduction to Data Science: Data Wrangling and Visualization with R (Irizarry, 2024)\n\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tidyr, mice, missForest)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Usare `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#pipe",
    "href": "chapters/R/05_dplyr.html#pipe",
    "title": "10  Usare dplyr",
    "section": "\n10.1 Pipe",
    "text": "10.1 Pipe\nIl pacchetto dplyr, così come l’intero ecosistema tidyverse, fa largo uso dell’operatore pipe, che consente di concatenare una sequenza di operazioni in modo leggibile ed efficiente. In R, esistono due principali notazioni per il pipe:\n\n\n|&gt;: introdotto nativamente a partire dalla versione 4.1.0 di R.\n\n%&gt;%: introdotto dal pacchetto magrittr, ed è una delle componenti centrali del tidyverse.\n\nEntrambi gli operatori permettono di ottenere risultati simili e, per la maggior parte degli utilizzi, possono essere considerati intercambiabili. Tuttavia, è importante sottolineare alcune differenze:\n\n\n|&gt; è integrato nel linguaggio R e non richiede pacchetti aggiuntivi.\n\n%&gt;%, essendo parte di magrittr, richiede che il pacchetto sia installato e caricato (library(magrittr) o automaticamente tramite tidyverse).\n\nConsideriamo l’esempio seguente (che anticipa l’uso della funzione filter() che descriveremo in seguito). Un’operazione comune è filtrare un data frame e calcolare la media di una colonna. Con il pipe, questa sequenza di operazioni diventa più leggibile:\n\n# Usando %&gt;%\niris %&gt;%\n  dplyr::filter(Species == \"setosa\") |&gt; \n  summarise(\n    mean_sepal_length = mean(Sepal.Length)\n  ) \n#&gt;   mean_sepal_length\n#&gt; 1              5.01\n\n\n# Usando |&gt;\niris |&gt; \n  dplyr::filter(Species == \"setosa\") |&gt; \n  summarise(\n    mean_sepal_length = mean(Sepal.Length)\n  ) \n#&gt;   mean_sepal_length\n#&gt; 1              5.01\n\n\n10.1.1 Cosa Fa la Pipe?\nLa pipe è uno strumento potente che permette di collegare in modo diretto l’output di una funzione come input della funzione successiva. Questo approccio:\n\nRiduce la necessità di creare variabili intermedie.\nMigliora la leggibilità del codice.\nRende il flusso delle operazioni più chiaro e lineare.\n\nOgni funzione applicata con la pipe riceve automaticamente l’output della funzione precedente come suo primo argomento. Ciò consente di scrivere sequenze di operazioni in un formato compatto e intuitivo.\nEcco un altro esempio:\n\n# Utilizzo della pipe per trasformare un dataset\ndf &lt;- data.frame(\n  id = 1:5,\n  value = c(10, 20, 30, 40, 50)\n)\n\n# Filtra i dati, seleziona colonne e calcola nuovi valori\ndf_clean &lt;- df |&gt;\n  dplyr::filter(value &gt; 20) |&gt;\n  dplyr::select(id, value) |&gt;\n  mutate(squared_value = value^2)\n\nIn questa sequenza, il dataset originale df viene filtrato, le colonne desiderate vengono selezionate e viene aggiunta una nuova colonna con il valore al quadrato.\n\nhead(df_clean)\n#&gt;   id value squared_value\n#&gt; 1  3    30           900\n#&gt; 2  4    40          1600\n#&gt; 3  5    50          2500\n\nIn sintesi, la pipe è uno strumento fondamentale per scrivere codice R moderno e leggibile, indipendentemente dal fatto che si utilizzi |&gt; o %&gt;%.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Usare `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#verbi",
    "href": "chapters/R/05_dplyr.html#verbi",
    "title": "10  Usare dplyr",
    "section": "\n10.2 Verbi",
    "text": "10.2 Verbi\nLe funzioni principali (“verbi) di dplyr sono le seguenti:\n\n\n\n\n\n\nVerbo dplyr\nDescrizione\n\n\n\nselect()\nSeleziona colonne\n\n\nfilter()\nFiltra righe\n\n\narrange()\nRiordina o organizza le righe\n\n\nmutate()\nCrea nuove colonne\n\n\nsummarise()\nRiassume i valori\n\n\ngroup_by()\nConsente di eseguire operazioni di gruppo\n\n\n\nI verbi di dplyr sono suddivisi in quattro gruppi, in base all’elemento su cui operano: righe, colonne, gruppi o tabelle.\nInoltre, le diverse funzioni bind_ e _joins permettono di combinare più tibbles (ovvero, data frame) in uno solo.\nPer fare un esempio prarico, usiamo nuovamente il dataset msleep.\n\ndata(msleep)\ndim(msleep)\n#&gt; [1] 83 11\n\nEsaminiamo i dati:\n\nglimpse(msleep)\n#&gt; Rows: 83\n#&gt; Columns: 11\n#&gt; $ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater shor…\n#&gt; $ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", \"Bra…\n#&gt; $ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"carn…\n#&gt; $ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", \"Art…\n#&gt; $ conservation &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"dome…\n#&gt; $ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.0, 5…\n#&gt; $ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0.8, …\n#&gt; $ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.133, 0.667, 0.767, 0.383, NA, 0.333, NA, NA…\n#&gt; $ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.0, 1…\n#&gt; $ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.07000, 0…\n#&gt; $ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, 0.04…\n\nLe colonne, nell’ordine, corrispondono a quanto segue:\n\n\nNome colonna\nDescrizione\n\n\n\nname\nNome comune\n\n\ngenus\nRango tassonomico\n\n\nvore\nCarnivoro, onnivoro o erbivoro?\n\n\norder\nRango tassonomico\n\n\nconservation\nStato di conservazione del mammifero\n\n\nsleep_total\nQuantità totale di sonno, in ore\n\n\nsleep_rem\nSonno REM, in ore\n\n\nsleep_cycle\nDurata del ciclo di sonno, in ore\n\n\nawake\nQuantità di tempo trascorso sveglio, in ore\n\n\nbrainwt\nPeso del cervello, in chilogrammi\n\n\nbodywt\nPeso corporeo, in chilogrammi",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Usare `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#righe",
    "href": "chapters/R/05_dplyr.html#righe",
    "title": "10  Usare dplyr",
    "section": "\n10.3 Righe",
    "text": "10.3 Righe\nI verbi più importanti che operano sulle righe di un dataset sono filter(), che seleziona le righe da includere senza modificarne l’ordine, e arrange(), che cambia l’ordine delle righe senza alterare la selezione delle righe presenti.\n\nmsleep |&gt;\n  dplyr::filter(sleep_total &lt; 4) |&gt;\n  arrange(sleep_total)\n#&gt; # A tibble: 9 × 11\n#&gt;   name             genus         vore  order          conservation sleep_total\n#&gt;   &lt;chr&gt;            &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 Giraffe          Giraffa       herbi Artiodactyla   cd                   1.9\n#&gt; 2 Pilot whale      Globicephalus carni Cetacea        cd                   2.7\n#&gt; 3 Horse            Equus         herbi Perissodactyla domesticated         2.9\n#&gt; 4 Roe deer         Capreolus     herbi Artiodactyla   lc                   3  \n#&gt; 5 Donkey           Equus         herbi Perissodactyla domesticated         3.1\n#&gt; 6 African elephant Loxodonta     herbi Proboscidea    vu                   3.3\n#&gt; 7 Caspian seal     Phoca         carni Carnivora      vu                   3.5\n#&gt; 8 Sheep            Ovis          herbi Artiodactyla   domesticated         3.8\n#&gt; 9 Asian elephant   Elephas       herbi Proboscidea    en                   3.9\n#&gt;   sleep_rem sleep_cycle awake brainwt bodywt\n#&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1       0.4          NA  22.1 NA       900. \n#&gt; 2       0.1          NA  21.4 NA       800  \n#&gt; 3       0.6           1  21.1  0.655   521  \n#&gt; 4      NA            NA  21    0.0982   14.8\n#&gt; 5       0.4          NA  20.9  0.419   187  \n#&gt; 6      NA            NA  20.7  5.71   6654  \n#&gt; 7       0.4          NA  20.5 NA        86  \n#&gt; 8       0.6          NA  20.2  0.175    55.5\n#&gt; 9      NA            NA  20.1  4.60   2547\n\nPossiamo usare filter() speficicano più di una condizione logica.\n\nmsleep |&gt;\n  dplyr::filter((sleep_total &lt; 4 & bodywt &gt; 100) | brainwt &gt; 1) |&gt;\n  arrange(sleep_total)\n#&gt; # A tibble: 7 × 11\n#&gt;   name             genus         vore  order          conservation sleep_total\n#&gt;   &lt;chr&gt;            &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 Giraffe          Giraffa       herbi Artiodactyla   cd                   1.9\n#&gt; 2 Pilot whale      Globicephalus carni Cetacea        cd                   2.7\n#&gt; 3 Horse            Equus         herbi Perissodactyla domesticated         2.9\n#&gt; 4 Donkey           Equus         herbi Perissodactyla domesticated         3.1\n#&gt; 5 African elephant Loxodonta     herbi Proboscidea    vu                   3.3\n#&gt; 6 Asian elephant   Elephas       herbi Proboscidea    en                   3.9\n#&gt; 7 Human            Homo          omni  Primates       &lt;NA&gt;                 8  \n#&gt;   sleep_rem sleep_cycle awake brainwt bodywt\n#&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1       0.4        NA    22.1  NA       900.\n#&gt; 2       0.1        NA    21.4  NA       800 \n#&gt; 3       0.6         1    21.1   0.655   521 \n#&gt; 4       0.4        NA    20.9   0.419   187 \n#&gt; 5      NA          NA    20.7   5.71   6654 \n#&gt; 6      NA          NA    20.1   4.60   2547 \n#&gt; 7       1.9         1.5  16     1.32     62",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Usare `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#colonne",
    "href": "chapters/R/05_dplyr.html#colonne",
    "title": "10  Usare dplyr",
    "section": "\n10.4 Colonne",
    "text": "10.4 Colonne\nEsistono quattro verbi principali che modificano le colonne di un dataset senza cambiare le righe:\n\n\nrelocate() cambia la posizione delle colonne;\n\nrename() modifica i nomi delle colonne;\n\nselect() seleziona le colonne da includere o escludere;\n\nmutate() crea nuove colonne a partire da quelle esistenti.\n\n\nmsleep2 &lt;- msleep |&gt;\n  mutate(\n    rem_prop = sleep_rem / sleep_total * 100\n  ) |&gt;\n  dplyr::select(name, vore, rem_prop, sleep_total) |&gt;\n  arrange(desc(rem_prop))\n\nglimpse(msleep2)\n#&gt; Rows: 83\n#&gt; Columns: 4\n#&gt; $ name        &lt;chr&gt; \"European hedgehog\", \"Thick-tailed opposum\", \"Giant armadi…\n#&gt; $ vore        &lt;chr&gt; \"omni\", \"carni\", \"insecti\", \"omni\", \"carni\", \"omni\", \"omni…\n#&gt; $ rem_prop    &lt;dbl&gt; 34.7, 34.0, 33.7, 29.2, 28.7, 27.2, 26.4, 26.2, 25.6, 25.0…\n#&gt; $ sleep_total &lt;dbl&gt; 10.1, 19.4, 18.1, 8.9, 10.1, 18.0, 9.1, 10.3, 12.5, 8.4, 1…\n\nIn questo esempio, utilizziamo mutate() per creare una nuova colonna rem_prop che rappresenta la percentuale di sonno REM sul totale del sonno. Successivamente, select() viene utilizzato per scegliere solo alcune colonne del dataset, e infine desc(rem_prop) ordina i valori di rem_prop in ordine decrescente, dal valore maggiore a quello minore.\nPer cambiare il nome di una colonna possiamo usare rename(). Inoltre, possiamo cambiare l’ordine delle variabili con relocate().\n\nmsleep2 |&gt;\n  rename(rem_perc = rem_prop) |&gt;\n  relocate(rem_perc, .before = name)\n#&gt; # A tibble: 83 × 4\n#&gt;    rem_perc name                   vore    sleep_total\n#&gt;       &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;         &lt;dbl&gt;\n#&gt;  1     34.7 European hedgehog      omni           10.1\n#&gt;  2     34.0 Thick-tailed opposum   carni          19.4\n#&gt;  3     33.7 Giant armadillo        insecti        18.1\n#&gt;  4     29.2 Tree shrew             omni            8.9\n#&gt;  5     28.7 Dog                    carni          10.1\n#&gt;  6     27.2 North American Opossum omni           18  \n#&gt;  7     26.4 Pig                    omni            9.1\n#&gt;  8     26.2 Desert hedgehog        &lt;NA&gt;           10.3\n#&gt;  9     25.6 Domestic cat           carni          12.5\n#&gt; 10     25   Eastern american mole  insecti         8.4\n#&gt; # ℹ 73 more rows",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Usare `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#gruppi",
    "href": "chapters/R/05_dplyr.html#gruppi",
    "title": "10  Usare dplyr",
    "section": "\n10.5 Gruppi",
    "text": "10.5 Gruppi\nIl verbo group_by() viene utilizzato per suddividere un dataset in gruppi, in base a una o più variabili, che siano rilevanti per l’analisi. Questo permette di eseguire operazioni di sintesi su ciascun gruppo separatamente, ottenendo informazioni aggregate.\nAd esempio, nel codice seguente:\n\nmsleep |&gt;\n  group_by(order) |&gt;\n  summarise(\n    avg_sleep = mean(sleep_total),\n    min_sleep = min(sleep_total),\n    max_sleep = max(sleep_total),\n    total = n()\n  ) |&gt;\n  arrange(desc(avg_sleep))\n#&gt; # A tibble: 19 × 5\n#&gt;    order           avg_sleep min_sleep max_sleep total\n#&gt;    &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n#&gt;  1 Chiroptera          19.8       19.7      19.9     2\n#&gt;  2 Didelphimorphia     18.7       18        19.4     2\n#&gt;  3 Cingulata           17.8       17.4      18.1     2\n#&gt;  4 Afrosoricida        15.6       15.6      15.6     1\n#&gt;  5 Pilosa              14.4       14.4      14.4     1\n#&gt;  6 Rodentia            12.5        7        16.6    22\n#&gt;  7 Diprotodontia       12.4       11.1      13.7     2\n#&gt;  8 Soricomorpha        11.1        8.4      14.9     5\n#&gt;  9 Primates            10.5        8        17      12\n#&gt; 10 Erinaceomorpha      10.2       10.1      10.3     2\n#&gt; 11 Carnivora           10.1        3.5      15.8    12\n#&gt; 12 Scandentia           8.9        8.9       8.9     1\n#&gt; 13 Monotremata          8.6        8.6       8.6     1\n#&gt; 14 Lagomorpha           8.4        8.4       8.4     1\n#&gt; 15 Hyracoidea           5.67       5.3       6.3     3\n#&gt; 16 Artiodactyla         4.52       1.9       9.1     6\n#&gt; 17 Cetacea              4.5        2.7       5.6     3\n#&gt; 18 Proboscidea          3.6        3.3       3.9     2\n#&gt; 19 Perissodactyla       3.47       2.9       4.4     3\n\n\ngroup_by(order) suddivide il dataset msleep in gruppi, ciascuno corrispondente a un valore distinto della variabile order.\n\nSuccessivamente, summarise() calcola diverse statistiche per ogni gruppo:\n\n\navg_sleep è la media del totale del sonno (sleep_total) all’interno di ciascun gruppo.\n\nmin_sleep è il valore minimo di sleep_total in ogni gruppo.\n\nmax_sleep è il valore massimo di sleep_total in ogni gruppo.\n\ntotal è il numero di osservazioni (o righe) per ciascun gruppo, calcolato con la funzione n().\n\n\nInfine, arrange(desc(avg_sleep)) ordina i risultati in ordine decrescente in base alla media del sonno totale (avg_sleep), mostrando prima i gruppi con la media di sonno più alta.\n\nQuesto tipo di approccio è utile quando si vuole analizzare come cambiano le caratteristiche dei dati a seconda dei gruppi specifici, fornendo una visione più dettagliata e utile.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Usare `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#riflessioni-conclusive",
    "href": "chapters/R/05_dplyr.html#riflessioni-conclusive",
    "title": "10  Usare dplyr",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl data wrangling è una delle fasi più importanti in qualsiasi pipeline di analisi dei dati. In questo capitolo abbiamo introdotto l’uso del pacchetto tidyverse di R per la manipolazione dei dati e il suo utilizzo in scenari di base. Tuttavia, il tidyverse è un ecosistema ampio e qui abbiamo trattato solo gli elementi fondamentali. Per approfondire, si consiglia di consultare ulteriori risorse come quelle disponibili sul sito web del tidyverse e il libro R for Data Science (2e), di cui esiste anche una traduzione italiana.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, utilizzerai il pacchetto dplyr per imparare a manipolare e trasformare i dati della SWLS (Satisfaction With Life Scale). Gli esercizi ti aiuteranno a consolidare la conoscenza dei principali verbi di dplyr, inclusi filter(), select(), mutate(), arrange() e group_by().\nParte 1: Comprensione Teorica\n\n\nCos’è un dataset “tidy”?\n\nDescrivi con parole tue cosa significa avere un dataset “tidy” e quali sono le sue tre caratteristiche principali.\n\n\n\nCos’è la pipe (%&gt;% o |&gt;) e perché è utile?\n\nSpiega a cosa serve l’operatore pipe e fornisci un esempio di utilizzo.\n\n\n\nQuali sono i verbi principali di dplyr?\n\nElenca e spiega brevemente i sei verbi principali di dplyr per la manipolazione dei dati.\n\n\n\nCosa fa il verbo group_by()?\n\nSpiega il suo scopo e come viene utilizzato in combinazione con summarise().\n\n\n\nParte 2: Applicazione Pratica con i Dati SWLS\n\n\nCaricamento dei dati SWLS\n\nCrea un data frame in R contenente i punteggi SWLS che hai raccolto.\n\n\n\nSelezione delle colonne\n\nUsa select() per mantenere solo le colonne con i punteggi degli item.\n\n\n\nFiltraggio dei dati\n\nUsa filter() per selezionare solo gli individui che hanno un punteggio totale superiore a 20.\n\n\n\nCreazione di una nuova colonna\n\nUsa mutate() per calcolare il punteggio totale della SWLS per ciascun individuo e salvarlo in una nuova colonna chiamata punteggio_totale.\n\n\n\nRiordinamento dei dati\n\nUsa arrange() per ordinare il dataset in base al punteggio totale, dal più alto al più basso.\n\n\n\nRaggruppamento e sintesi dei dati\n\n\n\nUsa group_by() e summarise() per calcolare la media e la deviazione standard del punteggio SWLS totale nel dataset.\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nParte 1: Comprensione Teorica\n\n\nCos’è un dataset “tidy”?\n\nUn dataset “tidy” è un dataset organizzato in modo sistematico per facilitare l’analisi. Le sue tre caratteristiche principali sono:\n\nOgni variabile è una colonna.\nOgni osservazione è una riga.\nOgni valore è una cella.\n\n\n\n\n\nCos’è la pipe (%&gt;% o |&gt;) e perché è utile?\n\nLa pipe (%&gt;% o |&gt;) permette di concatenare più operazioni di manipolazione dati in modo leggibile ed efficiente.\n\nEsempio:\ndf |&gt; \n  filter(score &gt; 20) |&gt; \n  select(name, score)\n\n\n\n\nQuali sono i verbi principali di dplyr?\n\n\nselect(): Seleziona colonne.\n\nfilter(): Filtra righe.\n\narrange(): Riordina le righe.\n\nmutate(): Crea nuove colonne.\n\nsummarise(): Riassume i dati.\n\ngroup_by(): Permette di raggruppare i dati.\n\n\n\nCosa fa il verbo group_by()?\n\ngroup_by() suddivide i dati in gruppi, permettendo di applicare funzioni di aggregazione con summarise().\n\nEsempio:\ndf |&gt; \n  group_by(gruppo) |&gt; \n  summarise(media = mean(score), sd = sd(score))\n\n\n\n\nParte 2: Applicazione Pratica con i Dati SWLS\n\n\nCaricamento dei dati SWLS Per svolgere l’esercizio, simuliamo i dati di 10 individui su 5 item (numeri casuali da 1 a 7):\nset.seed(123)\nswls &lt;- data.frame(\n  id = 1:10,\n  item1 = sample(1:7, 10, replace = TRUE),\n  item2 = sample(1:7, 10, replace = TRUE),\n  item3 = sample(1:7, 10, replace = TRUE),\n  item4 = sample(1:7, 10, replace = TRUE),\n  item5 = sample(1:7, 10, replace = TRUE)\n)\nprint(swls)\n\n\nSelezione delle colonne\nswls_selected &lt;- swls |&gt; select(item1:item5)\n\n\nFiltraggio dei dati\nswls_filtered &lt;- swls |&gt; filter(rowSums(select(swls, item1:item5)) &gt; 20)\n\n\nCreazione di una nuova colonna\nswls &lt;- swls |&gt; mutate(punteggio_totale = rowSums(select(swls, item1:item5)))\n\n\nRiordinamento dei dati\nswls_sorted &lt;- swls |&gt; arrange(desc(punteggio_totale))\n\nRaggruppamento e sintesi dei dati\n\nswls_summary &lt;- swls |&gt; \n  summarise(media = mean(punteggio_totale), sd = sd(punteggio_totale))\nConclusione\nQuesti esercizi hanno mostrato come usare dplyr per manipolare dati in modo efficace e leggibile.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] missForest_1.5        mice_3.18.0           pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        itertools_0.1-3       nloptr_2.2.1         \n#&gt; [22] ragg_1.4.0            purrr_1.1.0           jomo_2.7-6           \n#&gt; [25] xfun_0.53             glmnet_4.1-10         randomForest_4.7-1.2 \n#&gt; [28] cachem_1.1.0          jsonlite_2.0.0        pan_1.9              \n#&gt; [31] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [34] stringi_1.8.7         RColorBrewer_1.1-3    rpart_4.1.24         \n#&gt; [37] boot_1.3-32           lubridate_1.9.4       estimability_1.5.1   \n#&gt; [40] iterators_1.0.14      knitr_1.50            zoo_1.8-14           \n#&gt; [43] pacman_0.5.1          nnet_7.3-20           Matrix_1.7-4         \n#&gt; [46] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [49] abind_1.4-8           codetools_0.2-20      curl_7.0.0           \n#&gt; [52] doRNG_1.8.6.2         pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [55] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [58] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [61] rngtools_1.5.2        tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [64] foreach_1.5.2         stats4_4.5.1          reformulas_0.4.1     \n#&gt; [67] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [70] rstantools_2.4.0      scales_1.4.0          minqa_1.2.8          \n#&gt; [73] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [76] tools_4.5.1           lme4_1.1-37           mvtnorm_1.3-3        \n#&gt; [79] grid_4.5.1            rbibutils_2.3         QuickJSR_1.8.0       \n#&gt; [82] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [85] textshaping_1.0.1     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [88] V8_6.0.6              gtable_0.3.6          digest_0.6.37        \n#&gt; [91] TH.data_1.1-3         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [94] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [97] mitml_0.4-5           MASS_7.3-65",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Usare `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#bibliografia",
    "href": "chapters/R/05_dplyr.html#bibliografia",
    "title": "10  Usare dplyr",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Usare `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#footnotes",
    "href": "chapters/R/05_dplyr.html#footnotes",
    "title": "10  Usare dplyr",
    "section": "",
    "text": "Per comprendere meglio il concetto di “data tidying”, possiamo rifarci a una citazione tratta dal testo di riferimento R for Data Science (2e): “Tidy datasets are all alike, but every messy dataset is messy in its own way.”↩︎",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Usare `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html",
    "href": "chapters/R/06_quarto.html",
    "title": "11  Quarto",
    "section": "",
    "text": "11.1 Introduzione\nL a crisi della riproducibilità scientifica rappresenta una delle sfide più importanti della ricerca contemporanea. Con questo termine ci si riferisce alla difficoltà, riscontrata in diverse discipline, di replicare i risultati degli studi scientifici. Sebbene le definizioni di riproducibilità varino tra i diversi ambiti, un’interpretazione ampiamente condivisa la identifica come la capacità di ottenere gli stessi risultati utilizzando i medesimi dati di input e seguendo gli stessi passaggi computazionali nei metodi e nelle analisi.\nLa pratica scientifica è profondamente radicata nella formazione accademica: ciò che viene insegnato nelle aule universitarie si riflette direttamente nel lavoro svolto nei laboratori, sul campo e nell’analisi dei dati. Riconoscendo questo stretto legame tra didattica e ricerca, molti studiosi sostengono l’importanza di integrare i metodi di riproducibilità nei corsi universitari di data science, sia a livello undergraduate che graduate (Dogucu, 2024). L’educazione alla data science che incorpora la riproducibilità nell’analisi dei dati viene infatti considerata la “controffensiva statistica” alla crisi della riproducibilità.\nIn questo contesto si inserisce Quarto, uno strumento innovativo che affronta direttamente le sfide della crisi della riproducibilità. Quarto si colloca nella tradizione del literate programming, un approccio pioneristico introdotto da Donald Knuth negli anni ’80. Questa metodologia nasce dalla visione di unificare codice e testo descrittivo in un unico documento, rendendo i programmi non solo eseguibili ma anche comprensibili agli esseri umani. L’obiettivo è superare la tradizionale separazione tra codice e documentazione, permettendo di spiegare non solo il funzionamento tecnico di un programma, ma anche le ragioni delle scelte implementative.\nQuesta filosofia risulta particolarmente pertinente nell’ambito della data science e dell’analisi statistica, dove riproducibilità e trasparenza sono requisiti imprescindibili. Quarto eccelle in questo contesto, offrendo la possibilità di integrare in codice, risultati e narrazione. La sua versatilità si manifesta nella capacità di produrre diversi tipi di output - dai report agli articoli scientifici, dalle presentazioni ai documenti tecnici - in vari formati come HTML, PDF e Word, combinando efficacemente testo interpretativo, risultati numerici e visualizzazioni grafiche.\nUn punto di forza distintivo di Quarto è la sua flessibilità nel supportare molteplici linguaggi di programmazione, tra cui R, Python e Julia. Lo strumento può essere utilizzato secondo tre modalità principali: per presentare conclusioni condividendo i risultati senza esporre il codice sottostante; per documentare il processo analitico includendo sia il codice che i risultati, garantendo così piena trasparenza e riproducibilità; e per annotare l’analisi, integrando interpretazioni e motivazioni delle decisioni prese durante il processo analitico.\nNonostante Quarto sia tecnicamente uno strumento da riga di comando (CLI), l’integrazione con RStudio ne semplifica notevolmente l’utilizzo, rendendo l’installazione e l’operatività accessibili anche agli utenti meno esperti nell’uso del terminale. Questa caratteristica, unita alle sue potenti funzionalità, rende Quarto una naturale evoluzione del literate programming, offrendo un ambiente di lavoro che bilancia efficacemente praticità d’uso e rigore scientifico. In questo modo, Quarto si configura come una risposta concreta alle sfide della riproducibilità nella ricerca contemporanea, fornendo gli strumenti necessari per una scienza più trasparente e verificabile. L’obiettivo di questo capitolo è quello di fornire un’introduzione pratica a Quarto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#introduzione",
    "href": "chapters/R/06_quarto.html#introduzione",
    "title": "11  Quarto",
    "section": "",
    "text": "Prerequisiti\n\n\n\n\n\n\nLeggere Reproducibility in the Classroom (Dogucu, 2024).\nLeggere An Introduction to R.\nLeggere R for Data Science (2e).\nLeggere l’Appendice D.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tidyr)\n\n\n\n\n\n11.1.1 Creare un documento Quarto\nUn file Quarto ha estensione .qmd e segue questa struttura:\n\nQuesto file include:\n\nUn’intestazione YAML (metadati del documento).\nBlocchi di codice delimitati da ```.\nTesto scritto in Markdown con formattazioni semplici come titoli (# Titolo), corsivi (*testo*), ecc.\n\n11.1.2 Editor visivo e sorgente\n\n\nEditor visivo: simile a Google Docs, offre un’interfaccia WYSIWYM (What You See Is What You Mean). Consente di inserire facilmente immagini, tabelle, citazioni e altro.\n\nEditor sorgente: consente un controllo diretto sul Markdown, utile per debug e personalizzazioni avanzate.\n\n11.1.3 Blocchi di codice\nI blocchi di codice (chiamati “chunks”) eseguono codice e visualizzano i risultati. Ogni chunk è delimitato da ``` e può includere opzioni specifiche:\n#| label: esempio\n#| echo: false\n1 + 1\nLe opzioni più comuni includono:\n\n\necho: false (nasconde il codice nel report),\n\neval: false (non esegue il codice),\n\nmessage: false e warning: false (nasconde messaggi o avvisi).\n\n11.1.4 Figure\nLe figure possono essere generate tramite codice (es. ggplot()) o inserite come file esterni. Le opzioni più comuni per il controllo delle dimensioni sono:\n\n\nfig-width e fig-height (dimensioni della figura in pollici),\n\nout-width (percentuale di larghezza del documento),\n\nfig-asp (rapporto d’aspetto, es. 0.618 per il rapporto aureo).\n\nEsempio:\n#| fig-width: 6\nggplot(data, aes(x, y)) + geom_point()\n\n11.1.5 Equazioni\nLe equazioni possono essere scritte in LaTeX, così come spiegato nell’Appendice D.\n\n11.1.6 Tabelle\nLe tabelle possono essere stampate direttamente o personalizzate con funzioni come knitr::kable() o pacchetti come gt:\n\nknitr::kable(head(mtcars))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.62\n16.5\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.88\n17.0\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.32\n18.6\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.21\n19.4\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.44\n17.0\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.46\n20.2\n1\n0\n3\n1\n\n\n\n\n\n\n11.1.7 Caching\nPer velocizzare i documenti con calcoli complessi, Quarto supporta la memorizzazione dei risultati:\n\n\ncache: true salva i risultati di un chunk, evitando di ricalcolarli se il codice non cambia.\n\ndependson specifica dipendenze tra chunk.\n\n11.1.8 Gestione delle Citazioni e delle Bibliografie in Quarto\nQuarto offre un supporto avanzato per la generazione automatica di citazioni e bibliografie, consentendo l’applicazione di formati personalizzati come lo stile APA. Per includere riferimenti bibliografici, è necessario creare un file .bib (ad esempio, references.bib) contenente le citazioni nel formato BibTeX. Queste citazioni possono essere ottenute direttamente da Google Scholar o altri database accademici.\nEcco un esempio di una citazione in formato BibTeX:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect: Evidence from a visual search task},\n  author={Ceccarini, Francesco and Colpizzi, Ilaria and Caudek, Corrado},\n  journal={Psychonomic Bulletin \\& Review},\n  pages={1--10},\n  year={2024},\n  publisher={Springer}\n}\nQuesta citazione deve essere inserita in un file .bib, ad esempio, references.bib. Tale file dovrà poi essere specificato nell’intestazione del documento Quarto.\n\n11.1.8.1 Configurazione dell’Intestazione YAML\nNel file .qmd, è necessario aggiungere le seguenti righe all’intestazione YAML per collegare il file references.bib e configurare lo stile della bibliografia:\nbibliography: references.bib\nbiblio-style: apalike\ncsl: apa.csl\n\n\nbibliography: Specifica il percorso del file .bib. In questo esempio, si assume che il file si trovi nella stessa cartella del documento Quarto.\n\nbiblio-style: Imposta lo stile delle citazioni. Ad esempio, apalike è uno stile simile allo stile APA.\n\ncsl: Consente di utilizzare uno stile di citazione personalizzato, come apa.csl. Puoi scaricare facilmente questi stili dal Zotero Style Repository.\n\n11.1.8.2 Esempio Completo\nDi seguito è riportato un esempio completo di un documento Quarto che include una citazione e genera automaticamente la bibliografia:\n---\ntitle: \"Articolo di Esempio\"\nauthor: \"Autore di Esempio\"\ndate: \"2025-09-02\"\nbibliography: references.bib\nbiblio-style: apalike\ncsl: apa.csl\n---\n\n## Introduzione\n\nIn questo articolo, discutiamo i cambiamenti dipendenti dall'età nell'anger-superiority effect [@ceccarini2024age].\n\n## Risultati\n\nI risultati mostrano che...\n\n## Riferimenti\nIn questo esempio, l’identificatore @ceccarini2024age viene utilizzato per fare riferimento alla citazione contenuta nel file references.bib. Al momento della compilazione, Quarto genererà automaticamente la lista dei riferimenti bibliografici in base al formato specificato.\n\n11.1.8.3 Citazioni Inline\nAll’interno di un documento .qmd, le citazioni vengono aggiunte utilizzando il simbolo @ seguito dall’identificativo della citazione specificato nel file .bib. Ad esempio:\n... come evidenziato da @ceccarini2024age, si osserva che...\nQuarto genera automaticamente la bibliografia, includendo solo i riferimenti effettivamente citati nel documento. La bibliografia viene aggiunta alla fine del file renderizzato (ad esempio, in formato HTML o PDF).\nAd esempio, nel caso di un documento .qmd, il testo sopra sarà visualizzato così:\n\n… come evidenziato da Ceccarini et al. (2024), si osserva che…\n\nLa citazione completa sarà inclusa automaticamente nella bibliografia, posizionata alla fine della pagina web o del documento finale. Si noti che Quarto gestisce automaticamente la formattazione e la posizione della bibliografia, garantendo coerenza e precisione.\n\nEsempio 11.1 Per fare un esempio pratico, possiamo inserire la citazione @ceccarini2024age direttamente nel file .qmd di questa pagina web. Quando il documento viene compilato, Quarto renderà la citazione in modo appropriato, come mostrato qui: Ceccarini et al. (2024).\nSi noti che, in fondo a questa pagina web, è presente un riferimento bibliografico corrispondente. Questo riferimento è stato aggiunto automaticamente da Quarto in risposta all’uso della citazione @ceccarini2024age nel testo del documento. Questo processo automatizzato semplifica la gestione delle citazioni e garantisce che tutti i riferimenti siano correttamente inclusi e formattati.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#riflessioni-conclusive",
    "href": "chapters/R/06_quarto.html#riflessioni-conclusive",
    "title": "11  Quarto",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nQuarto è uno strumento potente per la creazione di documenti riproducibili e ben strutturati, integrando codice, risultati e testo descrittivo in un unico file. Questa introduzione dovrebbe essere sufficiente per iniziare a lavorare con Quarto, ma c’è ancora molto da imparare. Il modo migliore per rimanere aggiornati è consultare il sito ufficiale di Quarto: https://quarto.org.\nUn argomento importante che non abbiamo trattato qui riguarda i dettagli di come comunicare in modo accurato le proprie idee agli altri. Per migliorare le proprie capacità di scrittura, Wickham et al. (2023) consigliano due libri: Style: Lessons in Clarity and Grace di Joseph M. Williams & Joseph Bizup, e The Sense of Structure: Writing from the Reader’s Perspective di George Gopen. Una serie di brevi articoli sulla scrittura sono offerti da George Gopen e sono disponibili su https://www.georgegopen.com/litigation-articles.html.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio esplorerai l’importanza della riproducibilità nella scienza dei dati e le funzionalità principali di Quarto.\n1. Concetti di base sulla riproducibilità\n\nCos’è la crisi della riproducibilità e perché è rilevante nella scienza dei dati?\nIn che modo Quarto può aiutare ad affrontare la crisi della riproducibilità?\nSpiega il concetto di literate programming e come si collega a Quarto.\n\n2. Struttura di un file Quarto\n\nQual è l’estensione di un file Quarto e quali sono le sue tre sezioni principali?\nQual è la differenza tra editor visivo ed editor sorgente in Quarto?\nQual è la funzione dell’intestazione YAML in un file .qmd?\n\n3. Blocchi di codice e opzioni\n\nCome si scrive un blocco di codice in Quarto?\nQuali opzioni puoi utilizzare nei blocchi di codice per controllare l’esecuzione e la visualizzazione del codice e dei risultati?\nScrivi un blocco di codice Quarto che calcola la media di un vettore di numeri e stampa il risultato senza mostrare il codice.\n\n4. Figure e Tabelle\n\nQuali opzioni di formattazione delle figure offre Quarto?\nCome puoi creare una tabella formattata in Quarto usando knitr::kable()?\n\n5. Citazioni e Bibliografia\n\nCome si aggiunge una citazione bibliografica in Quarto?\nQuali file devono essere inclusi per gestire una bibliografia in Quarto?\nScrivi un esempio di citazione in formato BibTeX e mostra come collegarla a un documento .qmd.\n\n6. Considerazioni Finali\n\nQuali sono i vantaggi di usare Quarto rispetto a strumenti più tradizionali come Word per la creazione di report scientifici?\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Concetti di base sulla riproducibilità\n\nLa crisi della riproducibilità è il fenomeno per cui molti studi scientifici non possono essere replicati con gli stessi metodi e dati. Questo mina la fiducia nella scienza e può portare a risultati non affidabili.\nQuarto aiuta la riproducibilità integrando codice, testo e risultati in un unico documento, rendendo più semplice verificare e riprodurre le analisi.\n\nLiterate programming è un approccio introdotto da Donald Knuth che combina codice e spiegazioni testuali nello stesso file, migliorando la comprensione e documentazione delle analisi. Quarto segue questa filosofia.\n\n2. Struttura di un file Quarto\n\n\nL’estensione di un file Quarto è .qmd. Le tre sezioni principali sono:\n\nL’intestazione YAML (metadati),\nIl codice (chunks),\nIl testo scritto in Markdown.\n\n\nL’editor visivo è un’interfaccia intuitiva simile a Google Docs, mentre l’editor sorgente permette di scrivere direttamente in Markdown e codice.\nL’intestazione YAML definisce le proprietà del documento come titolo, autore, formato di output e opzioni di rendering.\n\n3. Blocchi di codice e opzioni\n\n\nUn blocco di codice in Quarto si scrive con tripli backtick (```) e un linguaggio specificato:\n#| echo: true\nprint(\"Esempio di codice in Quarto\")\n\n\nAlcune opzioni utili nei blocchi di codice sono:\n\n\necho: false per nascondere il codice,\n\neval: false per non eseguire il codice,\n\nwarning: false e message: false per nascondere messaggi e avvisi.\n\n\n\nEsempio di blocco di codice che calcola una media senza mostrare il codice:\n#| echo: false\nmean(c(1, 2, 3, 4, 5))\n\n\n\n11.2 4. Figure e Tabelle\n\n\nLe opzioni principali per le figure includono:\n\n\nfig-width e fig-height per le dimensioni,\n\nout-width per la larghezza relativa,\n\nfig-asp per il rapporto d’aspetto.\n\n\n\nPer creare una tabella formattata con knitr::kable():\nknitr::kable(head(mtcars))\n\n\n5. Citazioni e Bibliografia\n\nLe citazioni in Quarto si aggiungono usando il simbolo @ seguito dal riferimento BibTeX (es. @ceccarini2024age).\n\nPer gestire la bibliografia in Quarto servono:\n\nUn file .bib con le citazioni,\nUn’intestazione YAML che collega il file .bib e specifica lo stile (csl).\n\n\n\nEsempio di citazione BibTeX e collegamento in YAML:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect},\n  author={Ceccarini, Francesco et al.},\n  journal={Psychonomic Bulletin & Review},\n  year={2024}\n}\nYAML:\nbibliography: references.bib\nbiblio-style: apalike\n\n\n6. Considerazioni Finali\n\n\nI vantaggi di Quarto rispetto a Word includono:\n\nmaggiore riproducibilità e trasparenza,\npossibilità di integrare codice ed esecuzione in un unico documento,\nfacilità di gestione delle citazioni automatiche,\nsupporto per diversi formati di output (HTML, PDF, Word).\n\n\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-3         tensorA_0.36.2.1     \n#&gt;  [7] pacman_0.5.1          digest_0.6.37         timechange_0.3.0     \n#&gt; [10] estimability_1.5.1    lifecycle_1.0.4       survival_3.8-3       \n#&gt; [13] magrittr_2.0.3        compiler_4.5.1        rlang_1.1.6          \n#&gt; [16] tools_4.5.1           knitr_1.50            bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.4.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_6.0.6              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.1     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.4.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#figure-e-tabelle",
    "href": "chapters/R/06_quarto.html#figure-e-tabelle",
    "title": "11  Quarto",
    "section": "\n11.2 4. Figure e Tabelle",
    "text": "11.2 4. Figure e Tabelle\n\n\nLe opzioni principali per le figure includono:\n\n\nfig-width e fig-height per le dimensioni,\n\nout-width per la larghezza relativa,\n\nfig-asp per il rapporto d’aspetto.\n\n\n\nPer creare una tabella formattata con knitr::kable():\nknitr::kable(head(mtcars))\n\n\n5. Citazioni e Bibliografia\n\nLe citazioni in Quarto si aggiungono usando il simbolo @ seguito dal riferimento BibTeX (es. @ceccarini2024age).\n\nPer gestire la bibliografia in Quarto servono:\n\nUn file .bib con le citazioni,\nUn’intestazione YAML che collega il file .bib e specifica lo stile (csl).\n\n\n\nEsempio di citazione BibTeX e collegamento in YAML:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect},\n  author={Ceccarini, Francesco et al.},\n  journal={Psychonomic Bulletin & Review},\n  year={2024}\n}\nYAML:\nbibliography: references.bib\nbiblio-style: apalike\n\n\n6. Considerazioni Finali\n\n\nI vantaggi di Quarto rispetto a Word includono:\n\nmaggiore riproducibilità e trasparenza,\npossibilità di integrare codice ed esecuzione in un unico documento,\nfacilità di gestione delle citazioni automatiche,\nsupporto per diversi formati di output (HTML, PDF, Word).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#bibliografia",
    "href": "chapters/R/06_quarto.html#bibliografia",
    "title": "11  Quarto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCeccarini, F., Colpizzi, I., & Caudek, C. (2024). Age-dependent changes in the anger superiority effect: Evidence from a visual search task. Psychonomic Bulletin & Review, 1–10.\n\n\nDogucu, M. (2024). Reproducibility in the Classroom. Annual Review of Statistics and Its Application, 12.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html",
    "href": "chapters/R/07_environment.html",
    "title": "12  L’ambiente di programmazione",
    "section": "",
    "text": "Introduzione\nP rogrammare presuppone necessariamente un ambiente di programmazione. Una cattiva gestione di questo ambiente può causare il malfunzionamento degli script, rendendo fondamentale imparare a gestirlo correttamente.\nL’ambiente può influenzare persino il comportamento delle funzioni più basilari. Considera il seguente esempio:\nQuesto potrebbe produrre il seguente output:\nTuttavia, modificando l’opzione di larghezza in R, il comportamento cambia:\nIn questo caso, l’output potrebbe essere:\nLa differenza è dovuta a un’opzione dell’ambiente, width, che regola il numero massimo di caratteri visualizzati per ogni riga.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#introduzione",
    "href": "chapters/R/07_environment.html#introduzione",
    "title": "12  L’ambiente di programmazione",
    "section": "",
    "text": "Nota: In R, il termine “ambiente” ha un significato specifico, riferendosi allo spazio di lavoro in cui gli oggetti vengono memorizzati durante una sessione. In questo capitolo, tuttavia, il termine si riferisce allo stato complessivo del tuo computer mentre programmi, inclusa l’organizzazione dei file, la versione di R che stai usando e altre impostazioni.\n\n\nprint(1:9)\n\n[1] 1 2 3 4 5 6 7 8 9\n\n# Dopo aver modificato options(width)\noptions(width = 10)\nprint(1:9)\n\n[1] 1 2 3\n[4] 4 5 6\n[7] 7 8 9\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo 3, “Setting Up Your Data Science Project”, del libro Veridical Data Science (Yu & Barter, 2024).\nLeggere il Appendice A della dispensa.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tidyr)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#file-system",
    "href": "chapters/R/07_environment.html#file-system",
    "title": "12  L’ambiente di programmazione",
    "section": "\n12.1 File system",
    "text": "12.1 File system\nPrima di iniziare a organizzare un progetto in R, è fondamentale seguire alcune linee guida per strutturare e nominare i file in modo efficace. Spesso si tende a sottovalutare l’importanza di una buona organizzazione, ma adottare un sistema coerente può far risparmiare tempo prezioso nella ricerca e gestione dei progetti passati. Danielle Navarro ha creato una presentazione sulla struttura dei progetti, nella quale propone tre principi fondamentali per la gestione dei file:\n\nessere gentili con le macchine;\nessere gentili con gli esseri umani;\nfacilitare l’ordinamento e la ricerca.\n\n\n12.1.1 Essere gentili con le macchine\nLe macchine possono confondersi con spazi, caratteri speciali (come ^.*?+|$\"), e lettere accentate. Per evitare problemi:\n\nusa solo lettere minuscole, numeri, trattini _ o -;\nevita caratteri speciali e spazi nei nomi dei file;\nevita le lettere accentate;\nusa estensioni coerenti, come .R per gli script R.\n\nEsempi:\n# Buono\nprogetto01_analisi_dati.R\n\n# Cattivo\nProgetto \"Analisi Dati\".R\n\n12.1.2 Essere gentili con gli umani\nGli esseri umani hanno bisogno di contesto. Evita nomi vaghi e usa descrizioni significative.\n# Buono\nanalisi01_statistiche_descrittive.R\nnote02_intro_modello.docx\n\n# Cattivo\n01.R\nappunti.docx\n\n\n\n\n\n\nEvitate categoricamente l’uso di spazi nei nomi di file, cartelle o oggetti in R. Anche se il sistema operativo potrebbe consentirlo, questa pratica può generare problemi futuri, complicare il debugging e rendere il codice meno leggibile e portabile. Per evitare questi inconvenienti, adottate sempre nomi privi di spazi, preferendo separatori come trattini bassi (_) o trattini (-).\n\n\n\n\n12.1.3 Facilitare l’ordinamento e la ricerca\nSe i nomi dei file includono date, usa sempre il formato YYYY-MM-DD per permettere un ordinamento automatico.\n# Buono\n2024-01-01_analisi.R\n2024-02-15_riassunto.docx\n\n# Cattivo\n1-gennaio-2024.R\nriassunto-15-02-2024.docx\nSe devi ordinare i file in base a qualcosa di diverso dalle date, usa numeri con lo zero iniziale per mantenere l’ordine.\nreading01_shakespeare_romeo-and-juliet.docx\nreading02_shakespeare_romeo-and-juliet.docx\n...\nreading11_shakespeare_romeo-and-juliet.docx\nnotes01_shakespeare_romeo-and-juliet.docx\n...",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#versioni-di-r-e-pacchetti",
    "href": "chapters/R/07_environment.html#versioni-di-r-e-pacchetti",
    "title": "12  L’ambiente di programmazione",
    "section": "\n12.2 Versioni di R e pacchetti",
    "text": "12.2 Versioni di R e pacchetti\nAggiornare regolarmente R e i pacchetti è essenziale per evitare bug e sfruttare le nuove funzionalità. Ecco alcune buone pratiche:\n\nEsegui update.packages() ogni poche settimane per aggiornare i pacchetti.\nAggiorna la versione di R ogni pochi mesi. Su Windows puoi usare il pacchetto installr, mentre su altri sistemi puoi scaricare l’ultima versione dal sito ufficiale di R.\nMantieni aggiornato anche il sistema operativo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#progetti-in-r",
    "href": "chapters/R/07_environment.html#progetti-in-r",
    "title": "12  L’ambiente di programmazione",
    "section": "\n12.3 Progetti in R",
    "text": "12.3 Progetti in R\nSe hai seguito i consigli finora, avrai creato una cartella per tutti i tuoi progetti di programmazione e la tua installazione di R sarà aggiornata. Ora è il momento di organizzare i tuoi progetti in R.\n\n12.3.1 Percorsi assoluti e relativi\nUn percorso assoluto parte dalla directory principale del tuo computer (ad esempio, / su Linux/MacOS o C:/ su Windows) e indica in modo completo e univoco la posizione di un file o di una cartella. Un percorso relativo, invece, parte dalla directory corrente del progetto o dalla directory di lavoro impostata e descrive la posizione di un file in relazione a questa.\nAd esempio, il percorso assoluto del file utilizzato per generare questa pagina HTML potrebbe essere ottenuto così:\n\nfs::path_abs(\"05_environment.qmd\")\n#&gt; /Users/corrado/_repositories/psicometria-r/chapters/R/05_environment.qmd",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#funzione-here",
    "href": "chapters/R/07_environment.html#funzione-here",
    "title": "12  L’ambiente di programmazione",
    "section": "\n12.4 Funzione here()\n",
    "text": "12.4 Funzione here()\n\nSe il progetto si trova nella cartella psicometria-r, possiamo utilizzare la funzione here() del pacchetto here per indicare la posizione del file 05_environment.qmd in modo relativo. Ecco un esempio:\n\nfile.exists(here::here(\"chapters\", \"R\", \"07_environment.qmd\"))\n#&gt; [1] TRUE\n\nIn questo caso, il file 07_environment.qmd è contenuto nella cartella chapters/R, che si trova all’interno della directory principale del progetto. Grazie a here(), non è necessario specificare manualmente la posizione del progetto: questa funzione identifica automaticamente la directory principale e consente di indicare solo il percorso relativo del file rispetto ad essa. In altre parole, puoi riferirti al file 07_environment.qmd semplicemente fornendo il percorso relativo all’interno della struttura del progetto, lasciando a here() il compito di gestire il contesto globale.\n\n12.4.1 Perché preferire i percorsi relativi?\nL’utilizzo di percorsi relativi con here() offre numerosi vantaggi:\n\n\nPortabilità: Il codice diventa più semplice da condividere, poiché non dipende dalla struttura delle directory specifica del computer su cui è stato scritto.\n\nOrganizzazione: Favorisce una struttura chiara e coerente all’interno del progetto, rendendo più facile individuare e accedere ai file.\n\nAffidabilità: Riduce il rischio di errori dovuti a percorsi assoluti errati, soprattutto quando il progetto viene spostato o condiviso.\n\n12.4.2 Buone pratiche\n\n\nUsare sempre percorsi relativi: Questo assicura che il progetto sia facilmente eseguibile su altri sistemi senza necessità di modifiche ai percorsi.\n\nImpostare una struttura coerente del progetto: Organizzare i file in cartelle ben definite (ad esempio, data, scripts, outputs) facilita l’uso di percorsi relativi.\n\nIn sintesi, specificare i percorsi relativi rispetto alla directory principale del progetto è una buona pratica essenziale per garantire portabilità, organizzazione e riproducibilità del lavoro.\n\n12.4.3 Creare un progetto in R\nUn progetto R è semplicemente una cartella con un file .Rproj. Puoi crearne uno con RStudio o con il pacchetto usethis.\nIn RStudio:\n\nVai su File &gt; New Project.\nSeleziona New Directory &gt; New Project.\nDai un nome al progetto e scegli la sua posizione.\n\nCon usethis:\nusethis::create_project(\"path/alla/cartella\")\nEsempio:\nusethis::create_project(\"/Users/corrado/_repositories/psicometria-r\")\nVedremo nel Capitolo 14 come organizzare i file all’interno di un progetto.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-3         tensorA_0.36.2.1     \n#&gt;  [7] pacman_0.5.1          digest_0.6.37         timechange_0.3.0     \n#&gt; [10] estimability_1.5.1    lifecycle_1.0.4       survival_3.8-3       \n#&gt; [13] magrittr_2.0.3        compiler_4.5.1        rlang_1.1.6          \n#&gt; [16] tools_4.5.1           knitr_1.50            bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] crayon_1.5.3          rmarkdown_2.29        ragg_1.4.0           \n#&gt; [40] generics_0.1.4        RcppParallel_5.1.11-1 cachem_1.1.0         \n#&gt; [43] stringr_1.5.1         splines_4.5.1         parallel_4.5.1       \n#&gt; [46] vctrs_0.6.5           V8_6.0.6              Matrix_1.7-4         \n#&gt; [49] sandwich_3.1-1        jsonlite_2.0.0        arrayhelpers_1.1-0   \n#&gt; [52] systemfonts_1.2.3     glue_1.8.0            codetools_0.2-20     \n#&gt; [55] distributional_0.5.0  lubridate_1.9.4       stringi_1.8.7        \n#&gt; [58] gtable_0.3.6          QuickJSR_1.8.0        htmltools_0.5.8.1    \n#&gt; [61] Brobdingnag_1.2-9     R6_2.6.1              textshaping_1.0.1    \n#&gt; [64] rprojroot_2.1.1       evaluate_1.0.5        lattice_0.22-7       \n#&gt; [67] backports_1.5.0       memoise_2.0.1         broom_1.0.9          \n#&gt; [70] snakecase_0.11.1      rstantools_2.4.0      coda_0.19-4.1        \n#&gt; [73] gridExtra_2.3         nlme_3.1-168          checkmate_2.3.3      \n#&gt; [76] xfun_0.53             fs_1.6.6              zoo_1.8-14           \n#&gt; [79] pkgconfig_2.0.3",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#bibliografia",
    "href": "chapters/R/07_environment.html#bibliografia",
    "title": "12  L’ambiente di programmazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html",
    "href": "chapters/R/08_ai.html",
    "title": "13  Utilizzo di strumenti AI",
    "section": "",
    "text": "Introduzione\nI l panorama della programmazione sta attraversando una trasformazione radicale, guidata dall’avvento degli strumenti di intelligenza artificiale (AI). Questi assistenti innovativi stanno rivoluzionando il modo in cui sviluppatori, ricercatori e studenti scrivono, comprendono e ottimizzano il codice. Grazie a una nuova generazione di strumenti che vanno oltre i tradizionali ambienti di sviluppo, l’intelligenza artificiale sta aprendo possibilità inedite. Piattaforme come ChatGPT, Google Gemini, Claude.ai, DeepSeek e Qwen sono in grado di generare codice, spiegare concetti complessi e fornire supporto agli sviluppatori in modi che, fino a poco tempo fa, erano impensabili.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#introduzione",
    "href": "chapters/R/08_ai.html#introduzione",
    "title": "13  Utilizzo di strumenti AI",
    "section": "",
    "text": "Prerequisiti\n\n\n\n\n\n\nLeggere Prompt engineering as an important emerging skill for medical professionals: tutorial (Meskó, 2023)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#potenzialità-e-sfide-dellai-nella-programmazione",
    "href": "chapters/R/08_ai.html#potenzialità-e-sfide-dellai-nella-programmazione",
    "title": "13  Utilizzo di strumenti AI",
    "section": "13.1 Potenzialità e sfide dell’AI nella programmazione",
    "text": "13.1 Potenzialità e sfide dell’AI nella programmazione\nGli strumenti di intelligenza artificiale (AI) stanno trasformando radicalmente il modo in cui si programma, inclusa l’elaborazione di codice in linguaggi come R. Tuttavia, accanto alle immense potenzialità, emergono anche sfide significative. I modelli di linguaggio di grandi dimensioni (LLM, Large Language Models) possono ottimizzare e accelerare i flussi di lavoro, ma non sono privi di limitazioni. Tra queste, la possibilità di generare codice impreciso, introdurre bias involontari o produrre output che richiedono una verifica approfondita da parte dell’utente.\nNonostante queste sfide, gli strumenti di AI offrono un supporto prezioso in diverse aree chiave:\n\nSupporto Concettuale:\nGli LLM si dimostrano particolarmente efficaci nel rispondere a domande complesse su metodi statistici, algoritmi e tecniche di analisi dei dati. La qualità delle risposte migliora notevolmente quando le domande sono formulate in modo chiaro, specifico e dettagliato.\nGenerazione e Completamento del Codice:\nQuesti strumenti possono aiutare gli sviluppatori a scrivere codice più rapidamente, suggerendo completamenti automatici, identificando potenziali errori e persino generando interi script a partire da descrizioni testuali. Questo riduce il tempo dedicato alla scrittura manuale e permette di concentrarsi su aspetti più creativi o complessi del progetto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#panoramica-comparativa-dei-principali-strumenti-ai",
    "href": "chapters/R/08_ai.html#panoramica-comparativa-dei-principali-strumenti-ai",
    "title": "13  Utilizzo di strumenti AI",
    "section": "13.2 Panoramica comparativa dei principali strumenti AI",
    "text": "13.2 Panoramica comparativa dei principali strumenti AI\nCome scegliere il modello linguistico più adatto per un determinato compito? Nell’articolo di Gibney (2025), ricercatori condividono i loro strumenti preferiti attualmente in uso, offrendo una guida pratica a chi ha bisogno di orientarsi tra le varie opzioni.\n\n13.2.1 o3-mini (il ragionatore)\nOpenAI ha lanciato o3-mini, un modello di ragionamento gratuito per gli utenti registrati, sviluppato in risposta alla crescente concorrenza di DeepSeek. Questo modello si distingue per l’utilizzo di un processo di ragionamento a catena (chain-of-thought reasoning), che gli permette di affrontare problemi complessi in ambito matematico e scientifico con precisione. Oltre a eccellere nell’analisi tecnica e nella riformattazione dei dati, o3-mini è particolarmente efficace nel scomporre concetti intricati in passaggi più semplici. Tuttavia, nonostante le sue capacità avanzate, non è ancora in grado di eguagliare il ragionamento umano in contesti che richiedono creatività o intuizione profonda.\n\n\n13.2.2 DeepSeek (il tuttofare)\nDeepSeek-R1 è un modello open-weight paragonabile a o1 di OpenAI, ma disponibile a un costo inferiore attraverso API. La sua natura trasparente lo rende particolarmente attraente per i ricercatori, che possono adattarlo ai propri progetti specifici. DeepSeek è utile per generare ipotesi, migliorare la diagnostica medica e supportare attività di ricerca avanzate. Tuttavia, presenta alcuni limiti: il suo processo di ragionamento è più lento rispetto ad altri modelli e offre meno filtri contro output potenzialmente dannosi. Inoltre, OpenAI ha sollevato dubbi sulla legittimità del suo processo di addestramento, alimentando un dibattito sulla trasparenza e l’etica degli LLM.\n\n\n13.2.3 Llama (il cavallo di battaglia)\nSviluppato da Meta, Llama è uno dei modelli LLM più utilizzati nella ricerca grazie alla sua natura open-weight, che consente agli scienziati di personalizzarlo e impiegarlo in ambienti controllati. È stato applicato con successo in una vasta gamma di ambiti, dalla predizione delle strutture cristalline ai calcoli quantistici, dimostrando una grande versatilità. Tuttavia, l’accesso a Llama richiede un’autorizzazione specifica, rendendolo meno immediato rispetto ad altri modelli open-source emergenti che sono disponibili senza restrizioni.\n\n\n13.2.4 Claude (lo sviluppatore)\nClaude 3.5 Sonnet, prodotto da Anthropic, è particolarmente apprezzato per la sua capacità di scrivere codice e interpretare dati visivi. Questo modello si distingue per la sua abilità nel mantenere il significato tecnico anche durante la semplificazione del linguaggio, rendendolo ideale per redigere proposte di ricerca, annotare codice e supportare attività di sviluppo software. Tuttavia, l’accesso completo alle sue funzionalità richiede un’API a pagamento, il che lo rende meno competitivo rispetto ai modelli open-source in rapida crescita, soprattutto per utenti con budget limitati.\n\n\n13.2.5 OLMo (il veramente open)\nOLMo 2 rappresenta un passo avanti nella trasparenza degli LLM. Questo modello non solo fornisce i pesi del modello, ma anche i dati di addestramento e il codice di sviluppo, offrendo una visione completa del suo funzionamento. Questa apertura lo rende ideale per ricercatori e sviluppatori che desiderano analizzare bias, ottimizzare le prestazioni o comprendere a fondo il processo di creazione di un LLM. L’unico svantaggio è che richiede competenze tecniche avanzate per l’implementazione, sebbene il numero di risorse educative e tutorial disponibili stia crescendo rapidamente.\nOgni modello presenta punti di forza e limiti specifici, rendendoli adatti a contesti diversi. Mentre o3-mini e DeepSeek si concentrano su ragionamento e analisi tecnica, Llama e OLMo offrono maggiore flessibilità e trasparenza per la ricerca. Claude, d’altra parte, si distingue per le sue capacità di sviluppo e interpretazione di dati complessi. La scelta del modello dipende dalle esigenze specifiche dell’utente, dal budget disponibile e dalle competenze tecniche.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#considerazioni-etiche-e-pratiche",
    "href": "chapters/R/08_ai.html#considerazioni-etiche-e-pratiche",
    "title": "13  Utilizzo di strumenti AI",
    "section": "13.3 Considerazioni etiche e pratiche",
    "text": "13.3 Considerazioni etiche e pratiche\nL’adozione di strumenti di intelligenza artificiale (AI) solleva questioni etiche e pratiche che richiedono un’attenta riflessione e un approccio responsabile.\n\nTrasparenza\nI dataset utilizzati per addestrare i modelli di AI sono spesso poco documentati e opachi, rendendo difficile valutarne la qualità e l’equità. Questo solleva interrogativi sulla presenza di bias involontari e sulla rappresentatività dei dati, con notevoli implicazioni per l’affidabilità dei risultati.\nEquità di Accesso\nNonostante le potenzialità rivoluzionarie degli strumenti di AI, l’accesso a queste tecnologie non è uniformemente distribuito. Disparità economiche, geografiche e infrastrutturali possono creare disuguaglianze, limitando l’adozione di queste risorse in contesti meno privilegiati e ampliando il divario digitale.\nResponsabilità\nUno dei dilemmi più complessi riguarda l’attribuzione della responsabilità per i risultati generati dai sistemi di AI. In caso di errori, bias o conseguenze indesiderate, non è sempre chiaro chi debba assumersi la responsabilità: gli sviluppatori del modello, gli utenti o le organizzazioni che lo implementano.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#riflessioni-conclusive",
    "href": "chapters/R/08_ai.html#riflessioni-conclusive",
    "title": "13  Utilizzo di strumenti AI",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nGli strumenti di intelligenza artificiale stanno rivoluzionando il mondo della programmazione, offrendo un supporto senza precedenti per la risoluzione di problemi complessi, la generazione di codice e l’ottimizzazione dei flussi di lavoro. Tuttavia, il loro utilizzo deve essere accompagnato da un approccio critico e consapevole. È essenziale verificare i risultati, valutare le implicazioni etiche e garantire che l’adozione di queste tecnologie avvenga in modo equo e responsabile.\nL’intelligenza artificiale non sostituirà gli sviluppatori, ma si affermerà come un alleato indispensabile, ampliando la creatività e le competenze umane. Questa collaborazione tra uomo e macchina ridefinirà il modo in cui affrontiamo le sfide del futuro, aprendo nuove opportunità e trasformando il panorama della tecnologia e della ricerca (Bonnefon et al., 2024; Liu & Li, 2024).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#bibliografia",
    "href": "chapters/R/08_ai.html#bibliografia",
    "title": "13  Utilizzo di strumenti AI",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBonnefon, J.-F., Rahwan, I., & Shariff, A. (2024). The moral psychology of Artificial Intelligence. Annual Review of Psychology, 75(1), 653–675.\n\n\nGibney, E. (2025). What are the best AI tools for research? Nature’s guide. Nature, 578(7795), 123–125. https://doi.org/10.1038/d41586-025-00437-0\n\n\nLiu, J., & Li, S. (2024). Toward Artificial Intelligence-Human Paired Programming: A Review of the Educational Applications and Research on Artificial Intelligence Code-Generation Tools. Journal of Educational Computing Research, 07356331241240460.\n\n\nMeskó, B. (2023). Prompt engineering as an important emerging skill for medical professionals: tutorial. Journal of Medical Internet Research, 25, e50638.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html",
    "href": "chapters/eda/introduction_eda.html",
    "title": "EDA",
    "section": "",
    "text": "Il Ruolo Fondamentale dell’EDA\nL’analisi esplorativa dei dati (Exploratory Data Analysis, EDA) è un processo attivo di scoperta, un dialogo critico con i dati volto a rivelare ciò che è inatteso. Più che un insieme di tecniche, è un approccio mentale: un modo per mettere alla prova il proprio modello mentale attraverso il confronto sistematico tra aspettative e realtà. Prima di procedere con qualsiasi tipo di visualizzazione, è utile esplicitare le proprie aspettative, per poi verificare se i dati confermano, contraddicono o complicano tali ipotesi preliminari. In questo senso, l’EDA è una forma di model checking intuitivo, in cui l’intuizione viene continuamente affinata dall’evidenza empirica.\nUna volta raccolti i dati, il primo passo dell’analisi statistica consiste nel familiarizzare con essi: esplorarne la struttura, identificarne le regolarità e le anomalie e coglierne le dinamiche sottostanti. Questo processo, formalizzato da John Tukey negli anni ’70 (Tukey et al., 1977), rappresenta un antidoto alla rigidità dei modelli preconcetti. Tukey insisteva sull’importanza di “lasciar parlare i dati” prima di incasellarli in schemi teorici, perché è proprio nell’esplorazione che emergono pattern inattesi, relazioni non lineari o errori sistematici altrimenti invisibili.\nL’EDA non è in contrapposizione all’analisi confermativa (CDA), ma ne rappresenta il naturale complemento. Mentre l’analisi confermativa (CDA) testa ipotesi precise con metodi formali (ad esempio, test di ipotesi o modelli bayesiani), l’analisi esplorativa (EDA) genera tali ipotesi, verificando preliminarmente la plausibilità delle assunzioni di base. In campi come la psicologia, dove i dati sono spesso rumorosi e multidimensionali, questa fase è cruciale per evitare conclusioni fuorvianti.",
    "crumbs": [
      "EDA"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html#strumenti-e-filosofia",
    "href": "chapters/eda/introduction_eda.html#strumenti-e-filosofia",
    "title": "EDA",
    "section": "Strumenti e Filosofia",
    "text": "Strumenti e Filosofia\nSebbene l’EDA includa strumenti quantitativi (statistiche descrittive, misure di dispersione), la sua essenza si esprime appieno nella visualizzazione. Un grafico ben progettato, che si tratti di un boxplot, di uno scatterplot o di un semplice istogramma, può rivelare asimmetrie, outlier o cluster che una tabella numerica non riuscirebbe a mostrare. Tuttavia, come sottolineato da Hullman & Gelman (2021), la vera forza dell’EDA non risiede nella produzione di immagini, ma nel collegare ciò che si osserva a un modello mentale del processo di generazione dei dati. Visualizzare non significa solo “vedere”, ma anche “confrontare”: ci si chiede se la distribuzione di una variabile corrisponda alle aspettative o se una correlazione apparente resista a un’analisi critica.\nIn questa prospettiva, anche il Posterior Predictive Checking (Gelman et al., 2013) può essere considerato una forma di EDA, in cui l’adeguatezza di un modello viene verificata attraverso confronti grafici tra dati osservati e simulati. Anche senza un modello formale, l’analista compie un esercizio simile, valutando implicitamente la coerenza tra i dati e le proprie aspettative.",
    "crumbs": [
      "EDA"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html#obiettivi-di-questa-sezione",
    "href": "chapters/eda/introduction_eda.html#obiettivi-di-questa-sezione",
    "title": "EDA",
    "section": "Obiettivi di questa sezione",
    "text": "Obiettivi di questa sezione\nIn questa sezione, ci proponiamo di:\n\nIntrodurre i concetti base della statistica descrittiva (media, deviazione standard, correlazione) e le loro rappresentazioni grafiche (istogrammi, grafici a violino, matrici di scatterplot).\nMostrare applicazioni pratiche in R, utilizzando dataset psicologici reali o simulati, con un focus su come tradurre domande di ricerca in visualizzazioni efficaci.\nDiscutere i limiti dell’approccio puramente descrittivo, enfatizzando la necessità di integrare l’EDA con modelli teorici o causalità.\nCollegare esplorazione e inferenza, illustrando come l’EDA possa evolvere in un controllo modellistico esplicito, specie in contesti bayesiani dove le aspettative precedenti (prior) giocano un ruolo chiave.",
    "crumbs": [
      "EDA"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html#leda-come-atteggiamento-scientifico",
    "href": "chapters/eda/introduction_eda.html#leda-come-atteggiamento-scientifico",
    "title": "EDA",
    "section": "L’EDA come atteggiamento scientifico",
    "text": "L’EDA come atteggiamento scientifico\nIn conclusione, l’EDA non è un semplice preludio tecnico all’analisi “seria”, ma una componente essenziale del pensiero statistico. Ci spinge a formulare domande migliori, a interpretare le risposte con umiltà e a resistere alla tentazione di cercare conferme facili. Come scrisse Tukey: “È meglio rispondere in modo approssimativo a una domanda giusta, piuttosto che rispondere in modo esatto a una domanda sbagliata”.",
    "crumbs": [
      "EDA"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html#bibliografia",
    "href": "chapters/eda/introduction_eda.html#bibliografia",
    "title": "EDA",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nHullman, J., & Gelman, A. (2021). Challenges in Incorporating Exploratory Data Analysis Into Statistical Workflow. Harvard Data Science Review, 3(3).\n\n\nTukey, J. W. et al. (1977). Exploratory data analysis (Vol. 2). Springer.",
    "crumbs": [
      "EDA"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html",
    "href": "chapters/eda/01_project_structure.html",
    "title": "14  Il ciclo di vita di un progetto di analisi dei dati",
    "section": "",
    "text": "Introduzione\nNella ricerca psicologica i dati sono il legame concreto tra le teorie e la loro verifica empirica. Gestirli con rigore non significa soltanto tenerli in ordine: è la condizione che rende le analisi affidabili, le conclusioni sensate e i risultati riproducibili.\nUn dataset solido deve avere tre caratteristiche: integrità (i dati non devono essere alterati senza traccia), chiarezza semantica (ogni variabile deve avere un significato esplicito), e tracciabilità (ogni trasformazione deve poter essere ricostruita). Ad esempio: se rinomini un item da Q5 a Ansia_Sociale, questa modifica deve comparire in uno script, non solo nella memoria di chi analizza. Senza questa trasparenza, anche l’analisi più sofisticata perde credibilità e diventa irriproducibile.\nLa riproducibilità, cardine della scienza aperta (Open Science), non è facoltativa. Documentare accuratamente dati e processi permette alla comunità scientifica — e al proprio gruppo di ricerca nel tempo — di riesaminare, validare, criticare o estendere il lavoro. La gestione dei dati non è quindi un compito tecnico secondario, ma un atto scientifico con implicazioni etiche e metodologiche profonde.\nI dati psicologici sono oggi sempre più complessi: possono essere longitudinali (misure ripetute nel tempo), multimodali (questionari, dati EMA da app, registrazioni digitali), e provenire da fonti eterogenee. Ogni dataset riflette scelte teoriche e tecniche: rendere queste scelte esplicite, tracciabili e accessibili significa trasformare una semplice elaborazione in un processo analitico trasparente e criticabile.\nIn questo capitolo vedremo principi e pratiche per costruire un progetto di analisi dati che abbia fin dalle fondamenta chiarezza, rigore e tracciabilità. L’obiettivo non è solo operativo, ma epistemologico: creare un ponte solido tra l’osservazione empirica e l’inferenza scientifica, attraverso strumenti concreti e replicabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Il ciclo di vita di un progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#introduzione",
    "href": "chapters/eda/01_project_structure.html#introduzione",
    "title": "14  Il ciclo di vita di un progetto di analisi dei dati",
    "section": "",
    "text": "Panoramica del capitolo\n\nPianificazione iniziale.\nCome configurare l’ambiente R.\nCome gestire il ciclo di vita di un progetto di Data Science.\nCome garantire la riproducibilità usando Make.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Veridical Data Science (Yu & Barter, 2024) focalizzandoti sul primo capitolo, che introduce le problematiche della data science, e sul quarto capitolo, che fornisce le linee guida dettagliate sull’organizzazione di un progetto di analisi dei dati.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\n# Carica il file _common.R per impostazioni di pacchetti e opzioni\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n\n\n\n\n\n\n\n\n\nDomande iniziali\n\n\n\n\n\nPrima di immergerti nella lettura di questo capitolo, prenditi un momento per riflettere sulle seguenti domande. Quali risposte daresti prima di leggere il materiale?\n\nPerché è importante organizzare e documentare accuratamente i dati in un progetto di ricerca?\nQuali problemi possono emergere se si inizia a scrivere codice senza una pianificazione adeguata?\nQuali vantaggi offre R per la gestione dei dati rispetto ad altri strumenti?\nQuali strategie potrebbero migliorare la riproducibilità del tuo lavoro?\nCome struttureresti un progetto di analisi dati per mantenerlo chiaro e facilmente replicabile?\n\nOra, mentre leggi il capitolo, confronta le tue risposte con i concetti discussi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Il ciclo di vita di un progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#limportanza-della-pianificazione-iniziale",
    "href": "chapters/eda/01_project_structure.html#limportanza-della-pianificazione-iniziale",
    "title": "14  Il ciclo di vita di un progetto di analisi dei dati",
    "section": "\n14.1 L’importanza della pianificazione iniziale",
    "text": "14.1 L’importanza della pianificazione iniziale\nAffrontare un progetto di analisi senza una pianificazione accurata è come condurre un esperimento psicologico senza ipotesi: si procede in modo confuso, con errori, ripensamenti e soluzioni improvvisate che rendono il lavoro inefficiente e difficile da mantenere nel tempo. Scrivere codice, contrariamente a quanto si crede, è solo una piccola parte del processo. La maggior parte dello sforzo riguarda la definizione degli obiettivi, la scelta degli strumenti appropriati, la costruzione di un percorso coerente e la prevenzione dei cosiddetti debiti tecnici — scorciatoie temporanee che in seguito diventano ostacoli complessi da risolvere.\nUn approccio non strutturato può portare, ad esempio, a importare i dati in modo disordinato, a confondere i file originali con versioni intermedie o a trascurare la documentazione delle trasformazioni. In queste condizioni, anche l’analisi più brillante diventa fragile e poco trasparente, fino a compromettere la possibilità di replicare i risultati.\n\n14.1.1 Costruire un flusso di lavoro efficace\nUn progetto ben strutturato nasce da una fase di progettazione concettuale: chiarire le domande di ricerca, identificare le variabili chiave e ipotizzare i passaggi fondamentali dell’analisi. Anche uno schema molto semplice, disegnato su carta, può aiutare a visualizzare l’intero percorso: dalla pulizia dei dati all’inferenza statistica, fino alla comunicazione dei risultati. Questa rappresentazione preliminare diventa una bussola per mantenere coerenza ed evitare deviazioni inutili.\nÈ altrettanto importante suddividere il lavoro in unità gestibili, stimando in modo realistico il tempo necessario per ciascuna e formulando obiettivi specifici. Dire “fare un’analisi preliminare” è troppo vago; meglio stabilire: “esplorare la distribuzione dei punteggi tra il gruppo sperimentale e quello di controllo e produrre un grafico documentato e interpretabile”. Questo livello di precisione facilita il monitoraggio dei progressi e la divisione dei compiti nei progetti collaborativi.\nLa scelta degli strumenti merita attenzione sin dall’inizio: dedicare tempo a selezionare pacchetti R affidabili evita soluzioni improvvisate poco sostenibili. Ad esempio, janitor semplifica la pulizia dei dati e report produce automaticamente output in stile APA. Tuttavia, lo strumento più importante resta la documentazione quotidiana: annotare le motivazioni delle scelte nel codice, descrivere chiaramente le trasformazioni e integrare testo, codice ed evidenze in un documento Quarto crea un archivio trasparente e facilmente condivisibile.\nInfine, la riproducibilità è la chiave per garantire solidità nel tempo. Una struttura di progetto ordinata, con cartelle distinte per dati, script, output e report, facilita l’orientamento e la collaborazione. Anche i dettagli apparentemente minori — nomi chiari per le variabili, coerenza nell’indentazione, commenti sintetici ma informativi — contribuiscono a rendere l’analisi più leggibile, robusta e sostenibile.\n\n14.1.2 Prevenire e gestire il debito tecnico\nCon l’avanzare del progetto, è naturale accumulare complessità e dover affrontare problemi di manutenzione del codice. Per evitarne l’escalation, conviene ritagliarsi momenti periodici di revisione: semplificare strutture ridondanti, dividere gli script troppo lunghi in moduli più chiari e trasformare blocchi ripetitivi in funzioni riutilizzabili. Un codice pulito riduce il rischio di errori, rende più semplice collaborare e garantisce la possibilità di estendere il progetto senza doverlo riscrivere da capo.\nUn’altra buona pratica è mantenere allineati codice e commenti. Ogni modifica sostanziale deve essere accompagnata da un aggiornamento delle annotazioni: pochi commenti chiari valgono più di intere sezioni obsolete che confondono chi legge.\nPrima di condividere il progetto è utile effettuare una “checklist di qualità”:\n\nverificare che i dati originali siano conservati separatamente e non alterati;\ndocumentare l’ambiente di lavoro (ad esempio, salvando l’output di sessionInfo());\ncontrollare che ogni script sia leggibile, ben commentato e riproducibile dall’inizio alla fine.\n\nIn definitiva, pianificare un flusso di lavoro in R non significa complicarsi la vita: significa creare le condizioni per analisi più chiare, durature e scientificamente robuste. L’organizzazione del progetto, la cura del codice e l’adozione di buone pratiche non sono accessori, ma il fondamento di un approccio che mira a comprendere e non solo a calcolare.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Il ciclo di vita di un progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#capacità-di-gestione-dei-dati-in-r",
    "href": "chapters/eda/01_project_structure.html#capacità-di-gestione-dei-dati-in-r",
    "title": "14  Il ciclo di vita di un progetto di analisi dei dati",
    "section": "\n14.2 Capacità di gestione dei dati in R",
    "text": "14.2 Capacità di gestione dei dati in R\nUna volta compresa l’importanza di pianificare il lavoro, il passo successivo è dotarsi di strumenti affidabili per gestire, analizzare e documentare i dati. In questo contesto, R si rivela un alleato prezioso. È un ambiente di programmazione pensato per accompagnare l’intero ciclo di vita dei dati: dall’importazione e trasformazione, all’analisi statistica, fino alla produzione di report riproducibili. La sua versatilità lo rende centrale in qualsiasi flusso di lavoro orientato alla qualità e alla trasparenza — qualità indispensabili soprattutto in psicologia, dove i dataset sono spesso complessi e richiedono al tempo stesso flessibilità e rigore.\nR permette innanzitutto di importare ed esportare dati in molti formati. Pacchetti come readr e rio semplificano l’interazione con file CSV, database o persino fonti web. Una volta acquisiti, i dati possono essere puliti e trasformati in modo rapido ed elegante grazie a strumenti come dplyr, tidyr e stringr, che offrono un linguaggio espressivo per filtrare osservazioni, ristrutturare tabelle e modificare stringhe. La fase di esplorazione può poi contare su ggplot2, che consente di visualizzare pattern e riassumere indicatori descrittivi con grafici chiari e informativi.\nLa vera forza di R, tuttavia, emerge quando si tratta di documentare l’intero processo analitico. Con R Markdown e Quarto è possibile integrare codice, testo esplicativo, tabelle e grafici in un unico documento dinamico: un report che mostra non solo i risultati finali, ma anche come sono stati ottenuti, garantendo così riproducibilità e trasparenza. A questo si aggiunge la possibilità di usare Git, integrato in RStudio, per tracciare le modifiche, collaborare in modo strutturato e mantenere un archivio verificabile del lavoro.\nL’integrazione tra strategia progettuale e strumenti tecnici rende R una piattaforma ideale per chi vuole lavorare in modo affidabile, efficiente e scientificamente solido. Nei progetti con dati complessi, questa combinazione rappresenta una garanzia di qualità e sostenibilità analitica.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Il ciclo di vita di un progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#configurare-lambiente-r",
    "href": "chapters/eda/01_project_structure.html#configurare-lambiente-r",
    "title": "14  Il ciclo di vita di un progetto di analisi dei dati",
    "section": "\n14.3 Configurare l’ambiente R",
    "text": "14.3 Configurare l’ambiente R\nPer sfruttare al meglio R è importante partire da un ambiente di lavoro ben configurato. RStudio offre un’interfaccia potente e flessibile, che consente di controllare in dettaglio il comportamento delle sessioni.\nUn primo passo utile è disattivare il salvataggio automatico dell’ambiente di lavoro. Dal menu Tools &gt; Global Options &gt; General si consiglia di:\n\ndeselezionare l’opzione di caricamento automatico del file .RData all’avvio,\nimpostare il salvataggio del workspace su Never.\n\nIn questo modo si evitano “residui invisibili” delle sessioni precedenti e si favorisce l’uso sistematico degli script come unico riferimento per l’analisi. L’obiettivo è rendere ogni passaggio esplicito e documentato, piuttosto che affidarsi a oggetti temporanei difficili da tracciare.\nUn ambiente ben preparato deve includere anche i pacchetti fondamentali. Tra questi, il tidyverse costituisce un vero ecosistema integrato per la manipolazione (dplyr), la visualizzazione (ggplot2), l’importazione (readr) e molte altre operazioni, sempre con una sintassi coerente e leggibile. Il pacchetto here, invece, semplifica la gestione dei percorsi relativi: gli script diventano portabili e funzionano senza modifiche anche su sistemi o directory differenti.\nL’installazione si effettua una sola volta con install.packages(), mentre il caricamento va ripetuto all’inizio di ogni script. Un setup iniziale tipico potrebbe essere:\n# install.packages(c(\"here\", \"tidyverse\"))  # solo la prima volta\nlibrary(here)\nlibrary(tidyverse)\nAdottare da subito queste pratiche di configurazione significa ridurre errori, aumentare la leggibilità del codice e costruire un ambiente solido, adatto ad analisi ripetibili e condivisibili. È qui che la programmazione incontra il metodo scientifico: nella combinazione di rigore tecnico e trasparenza metodologica.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Il ciclo di vita di un progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#gestione-dei-progetti",
    "href": "chapters/eda/01_project_structure.html#gestione-dei-progetti",
    "title": "14  Il ciclo di vita di un progetto di analisi dei dati",
    "section": "\n14.4 Gestione dei progetti",
    "text": "14.4 Gestione dei progetti\nIn RStudio, i progetti permettono di organizzare tutto il lavoro analitico all’interno di una cartella dedicata, che contiene dati, script, output e documentazione. Ogni progetto è così un’unità autonoma, con percorsi relativi stabili e indipendenti dagli altri lavori. Questo riduce il rischio di confusione e rende più semplice riprodurre le analisi anche a distanza di tempo.\nCreare un nuovo progetto è immediato: basta selezionare File &gt; New Project e indicare la directory in cui raccogliere i file. Da quel momento, aprendo il file .Rproj, si ritrova automaticamente l’ambiente configurato e pronto all’uso.\nPiù che una questione di ordine, lavorare per progetti significa adottare una struttura replicabile: ogni analisi può essere riaperta, eseguita e condivisa senza dipendere da impostazioni esterne o da file sparsi. È anche un vantaggio per la collaborazione, perché rende chiaro a tutti dove trovare dati, script e risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Il ciclo di vita di un progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#il-ciclo-di-vita-di-un-progetto-di-data-science",
    "href": "chapters/eda/01_project_structure.html#il-ciclo-di-vita-di-un-progetto-di-data-science",
    "title": "14  Il ciclo di vita di un progetto di analisi dei dati",
    "section": "\n14.5 Il ciclo di vita di un progetto di Data Science",
    "text": "14.5 Il ciclo di vita di un progetto di Data Science\nUna volta predisposto un ambiente stabile e ben organizzato, il progetto di Data Science può essere affrontato in modo sistematico. Seguendo la proposta di Yu & Barter (2024), il ciclo di vita tipico comprende cinque fasi fondamentali: formulazione della domanda di ricerca, preparazione e analisi esplorativa dei dati, eventuale modellazione inferenziale o predittiva, valutazione dei risultati e comunicazione degli esiti.\nNon tutti i progetti arrivano alla modellazione, ma tutti traggono vantaggio da un percorso ordinato che attraversi in modo coerente queste fasi. Un approccio strutturato migliora la qualità delle analisi e riduce il rischio di errori o ambiguità interpretative.\n\n14.5.1 Formulazione del problema e raccolta dei dati\nIl primo passo è definire con chiarezza gli obiettivi. In ambito applicativo ciò può significare, ad esempio, valutare l’efficacia di un intervento con un report descrittivo; in ambito accademico, ancorare la domanda alla letteratura e a un quadro teorico esplicito. In entrambi i casi, la domanda deve essere precisa e affrontabile con i dati disponibili.\nLa raccolta dei dati può basarsi su fonti esistenti (dataset pubblici, archivi di laboratorio) o su nuove rilevazioni. Pianificare in anticipo l’analisi aiuta a evitare dati inutili o non pertinenti. È inoltre fondamentale documentare le modalità di raccolta ed esplicitare eventuali limiti.\n\n14.5.2 Pulizia, preprocessing e analisi esplorativa\nUna volta acquisiti, i dati vanno importati in R in formato analizzabile, di norma come data frame. Pacchetti come rio rendono semplice l’importazione, mentre here facilita la gestione dei percorsi. I dati grezzi vanno sempre conservati separati dai dati trasformati.\nLa pulizia comprende la correzione di errori, la gestione dei valori mancanti, l’eliminazione di duplicati e l’uniformazione delle codifiche. Le trasformazioni non vanno mai fatte “a mano” ma registrate in script, per garantire tracciabilità.\nIl preprocessing adatta i dati all’analisi: ad esempio standardizzare variabili, creare indici compositi o ricodificare categorie. Ogni passo deve essere documentato, perché ha effetti diretti sull’interpretazione.\nL’analisi esplorativa (EDA) serve a conoscere i dati prima di modellarli: statistiche descrittive, distribuzioni, visualizzazioni con ggplot2. Questa fase permette di individuare pattern, anomalie e relazioni preliminari che guideranno le scelte successive.\n\n14.5.3 Analisi predittiva e inferenziale\nQuando previsto, il cuore del progetto è la modellazione. In psicologia si usano comunemente regressioni, test parametrici e non parametrici, modelli ad effetti misti o algoritmi di classificazione. L’obiettivo può essere inferenziale (trarre conclusioni su una popolazione) o predittivo (anticipare valori futuri). In ogni caso le scelte modellistiche devono essere motivate, e le ipotesi verificate.\n\n14.5.4 Valutazione dei risultati\nInterpretare i risultati richiede attenzione su due livelli:\n\n\nstatistico, attraverso indici di bontà del modello, intervalli di confidenza o posteriori credibili,\n\nconcettuale, verificando la coerenza con la teoria di riferimento o con il contesto applicativo.\n\nRicollegarsi sempre agli obiettivi iniziali aiuta a distinguere ciò che il modello davvero mostra da ciò che resta incerto.\n\n14.5.5 Comunicazione dei risultati\nLa fase finale è la comunicazione, che può assumere forme diverse: articolo scientifico, report tecnico, presentazione a un pubblico non specialistico. In ogni caso serve un linguaggio chiaro e motivato, supportato da visualizzazioni curate. Un buon risultato analitico non è completo finché non viene presentato in modo comprensibile e utile a chi lo riceve.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Il ciclo di vita di un progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "href": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "title": "14  Il ciclo di vita di un progetto di analisi dei dati",
    "section": "\n14.6 Organizzazione del progetto",
    "text": "14.6 Organizzazione del progetto\nPer garantire riproducibilità e gestione a lungo termine, è utile adottare una struttura chiara e strumenti che automatizzino i passaggi chiave. Un esempio concreto è documentato nel repository ccaudek/make-tutorial, che mostra come integrare R, Quarto e GNU Make in un flusso unico e completamente ricostruibile.\n\n14.6.1 Perché Make\nMake è uno strumento nato per compilare software, ma perfetto anche per la ricerca: invece di un “master script” che lancia tutto in sequenza, Make lavora con dipendenze dichiarative. Ogni output (un file pulito, un grafico, un report) viene associato agli input necessari e al comando che lo genera. Così, se modifichi un solo script, Make ricostruisce solo ciò che dipende da quel file, senza ricalcolare inutilmente il resto.\nTre principi fondamentali:\n\n\nModularità: ogni passaggio (pulizia, scoring, analisi, report) è uno script autonomo.\n\nDichiaratività: il Makefile descrive cosa dipende da cosa, non come eseguirlo manualmente.\n\nEfficienza: make all ricostruisce l’intero progetto, make clean lo riporta allo stato iniziale.\n\n14.6.2 Struttura del progetto\nmake-tutorial/\n├─ data/\n│  ├─ raw/         # input \"sorgente\" o simulati\n│  └─ processed/   # output intermedi (clean, scored)\n├─ scripts/        # step atomici della pipeline (Rscript)\n├─ stan/           # modelli Stan (se usati)\n├─ fits/           # oggetti dei fit (rds/csv)\n├─ figs/           # figure prodotte dagli script\n├─ report/         # report .qmd e .html\n├─ Makefile        # regole e dipendenze\n└─ README.md       # istruzioni d'uso\n\n14.6.3 Il cuore del progetto: il Makefile essenziale\nQuando un progetto di analisi dati cresce, tenere traccia di tutti i file, script e delle loro dipendenze può diventare complicato. GNU Make è uno strumento che automatizza il processo di costruzione (o “build”) di un progetto. La sua logica è semplice ma potente: definisci cosa vuoi produrre (i file-obiettivo), da cosa dipende (i prerequisiti) e come produrlo (i comandi). Make si occuperà di eseguire i comandi nell’ordine corretto, solo quando necessario. Un file che contiene queste istruzioni si chiama Makefile.\n\n14.6.3.1 Anatomia di una regola\nLa struttura fondamentale di un Makefile è la regola. Ogni regola è composta da tre elementi:\ntarget: prerequisito1 prerequisito2 ...\n    comando\n\n\nTarget: il file che vuoi costruire (ad esempio, un dataset pulito, un grafico, un report HTML).\n\nPrerequisiti: i file di cui il target ha bisogno per essere costruito (ad esempio, gli script R e i dati grezzi). Sono le dipendenze del target.\n\nComando: la ricetta, ossia la riga di comando che, eseguita, trasforma i prerequisiti nel target. È fondamentale che questa riga inizi con un carattere di tabulazione (TAB), non con spazi.\n\nCome funziona Make? Quando gli chiedi di costruire un target (ad esempio, make report.html), Make fa questo:\n\n\nControlla le dipendenze: guarda tutti i prerequisiti del target.\n\nVerifica la necessità: controlla se il target esiste già e se è più recente di tutti i suoi prerequisiti.\n\nSe il target non esiste o è più vecchio di anche solo uno dei suoi prerequisiti, Make esegue il comando per aggiornarlo.\nSe il target esiste ed è più recente di tutti i prerequisiti, Make sa che non c’è nulla da fare e salta la ricetta, risparmiando tempo.\n\n\n\nSi propaga: applica questa stessa logica ricorsivamente a tutti i prerequisiti che sono a loro volta target di altre regole.\n\nQuesto meccanismo intelligente assicura che tutto il tuo progetto venga ricostruito in modo efficiente e sempre aggiornato.\n\n14.6.3.2 Spiegazione del nostro Makefile\nAnalizziamo ora il Makefile utilizzato in ccaudek/make-tutorial pezzo per pezzo.\n1. Impostare l’obiettivo predefinito\n# Esegui la pipeline completa se non passi argomenti a 'make'\n.DEFAULT_GOAL := all\nQuesta riga dice a Make: “Se l’utente digita semplicemente make senza specificare un target, esegui di default il target chiamato all”. È un’utile convenzione per avviare l’intera pipeline con un comando minimo.\n2. Generazione dei dati (DAG: da raw a processed)\ndata/raw/rosenberg_raw.csv: scripts/00_simulate.R\n    Rscript $&lt;\n\n\nTarget: data/raw/rosenberg_raw.csv (i dati simulati grezzi).\n\nPrerequisito: scripts/00_simulate.R (lo script che genera i dati).\n\nComando: Rscript $&lt;\n\n\n$&lt; è una variabile automatica di Make. Viene sostituita con il nome del primo prerequisito della regola. In questo caso, $&lt; diventa scripts/00_simulate.R.\nQuindi, il comando eseguito è Rscript scripts/00_simulate.R.\n\n\n\ndata/processed/clean.csv: scripts/01_clean.R data/raw/rosenberg_raw.csv\n    Rscript $&lt;\n\n\nTarget: data/processed/clean.csv (i dati puliti).\n\nPrerequisiti: Lo script di pulizia (01_clean.R) e i dati grezzi. Se i dati grezzi cambiano, anche i dati puliti devono essere rigenerati.\n\nComando: Rscript $&lt; (dove $&lt; è scripts/01_clean.R).\n\n3. Creazione delle figure (EDA)\nfigs/dist_by_gender.png figs/scatter_rosenberg_vs_outcome.png: scripts/03_eda.R data/processed/scored.csv\n    Rscript scripts/03_eda.R\nQuesta regola è interessante perché ha due target. Significa che eseguendo un unico comando (Rscript scripts/03_eda.R) vengono generati entrambi i file figura. Se uno dei due file PNG o lo script EDA viene modificato, Make rigenererà entrambe le figure.\n4. Esecuzione delle analisi\nfits/freq_done.flag: scripts/10_freq_tests.R data/processed/scored.csv\n    Rscript scripts/10_freq_tests.R && touch $@\n\n\nTarget: fits/freq_done.flag. Questo è un file flag (o sentinella). A volte un’analisi non produce un file di output vero e proprio, o lo produce con un nome imprevedibile. Il file flag è un file vuoto il cui unico scopo è registrare quando l’analisi è stata eseguita con successo per l’ultima volta.\n\nComando: Rscript scripts/10_freq_tests.R && touch $@\n\n\n&& significa “esegui il comando successivo solo se il primo è terminato con successo”.\n\n$@ è un’altra variabile automatica. Viene sostituita con il nome del target della regola. In questo caso, $@ diventa fits/freq_done.flag.\nQuindi, il comando esegue prima lo script R e, se ha successo, crea/tocca il file flag.\n\n\n\nfits/brms_fit.rds: scripts/11_bayes_brms.R data/processed/scored.csv\n    Rscript $&lt;\n\n\nTarget: fits/brms_fit.rds (un file binario R che contiene il modello fitted).\nIl comando usa $&lt; per riferirsi al primo prerequisito, lo script.\n\n5. Generazione del report finale\nreport/report.html: report/report.qmd figs/dist_by_gender.png figs/scatter_rosenberg_vs_outcome.png fits/freq_done.flag fits/brms_fit.rds fits/cmdstan_fit.rds\n    quarto render $&lt;\n\n\nTarget: Il report HTML finale.\n\nPrerequisiti: Tutto ciò di cui il report ha bisogno: il file Quarto source (.qmd), tutte le figure e i risultati di tutte le analisi (compreso il file flag).\n\nComando: quarto render $&lt; (dove $&lt; è report/report.qmd). Questo comando compila il documento Quarto in HTML, incorporando figure e risultati.\n\n6. Target “fittizi” (phony) e pulizia\n.PHONY: all clean\nall: report/report.html\n\nclean:\n    rm -f data/raw/rosenberg_raw.csv \\\n          data/processed/*.csv \\\n          figs/*.png \\\n          fits/*.rds fits/*.flag \\\n          report/report.html\n\n\n.PHONY: Questa è una direttiva speciale che dice a Make che i target all e clean non sono nomi di file. Sono comandi, azioni. Senza .PHONY, se per caso esistesse un file chiamato all o clean nella cartella, Make penserebbe che quel target è già aggiornato e non eseguirebbe il comando, il che non è ciò che vogliamo.\n\nall: report/report.html: Definisce il target all come un semplice collegamento (alias) al nostro report finale. È il target che costruisce l’intero progetto.\n\nclean: Questo target ha un comando molto importante: elimina tutti i file generati. È utile per ricominciare da zero con una pulizia profonda. Nota la continuazione di riga con il carattere \\.\n\n14.6.3.3 Riepilogo delle Variabili Automatiche\n\n\n$&lt;: Il nome del primo prerequisito.\n\n$@: Il nome del target.\n\n14.6.3.4 Come usare questo Makefile\nApri un terminale nella cartella del progetto contenente il Makefile e digita:\n\n\nmake o make all: costruisce l’intero progetto (dati, figure, analisi, report).\n\nmake data/processed/clean.csv: costruisce solo il dataset pulito e tutto ciò da cui dipende (dati grezzi).\n\nmake figs/dist_by_gender.png: genera solo quella figura specifica e le sue dipendenze.\n\nmake clean: cancella tutti i file prodotti, lasciando solo il codice sorgente e il Makefile.\n\nmake -n target: esegue una simulazione (“dry run”). Make mostrerà i comandi che eseguirebbe senza eseguirli realmente. Ottimo per debug.\n\nIl Makefile contenuto nel repository ccaudek/make-tutorial trasforma il progetto di analisi dei dati da una collezione di script in una pipeline di dati riproducibile e automatizzata.\n\n14.6.4 DAG della pipeline\n\nflowchart LR\n    A[\"raw.csv\"] --&gt; B[\"clean.csv\"]\n    B --&gt; C[\"scored.csv\"]\n    C --&gt; D1[\"EDA figs\"]\n    C --&gt; D2[\"freq tests\"]\n    C --&gt; D3[\"bayes (brms)\"]\n    C --&gt; D4[\"bayes (cmdstanr)\"]\n    D1 --&gt; RPT[\"report.html\"]\n    D2 --&gt; RPT\n    D3 --&gt; RPT\n    D4 --&gt; RPT\n\n\n\n\nflowchart LR\n    A[\"raw.csv\"] --&gt; B[\"clean.csv\"]\n    B --&gt; C[\"scored.csv\"]\n    C --&gt; D1[\"EDA figs\"]\n    C --&gt; D2[\"freq tests\"]\n    C --&gt; D3[\"bayes (brms)\"]\n    C --&gt; D4[\"bayes (cmdstanr)\"]\n    D1 --&gt; RPT[\"report.html\"]\n    D2 --&gt; RPT\n    D3 --&gt; RPT\n    D4 --&gt; RPT\n\n\n\n\n\n\n\n14.6.5 Buone pratiche operative\n\n\nShebang facoltativo negli script (#!/usr/bin/env Rscript) + chmod +x per lanciarli anche come eseguibili. Nei Makefile va benissimo Rscript script.R.\n\nPercorsi stabili: nel report .qmd, usa percorsi relativi o abilita embed-resources: true per incorporare le immagini nell’HTML.\n\nCmdStanR e file CSV: gli oggetti CmdStanMCMC salvati con saveRDS() puntano ai CSV generati dal sampler. Salvali in una cartella persistente (es. fits/cmdstan_csv/ con output_dir=) oppure salva direttamente un summary (fit$summary()) in RDS per evitare dipendenza dai CSV temporanei.\n\nIdempotenza: ogni regola dovrebbe essere deterministica dato il suo input (se simuli dati, fissa il seed negli script).\n\nPulizia selettiva: clean rimuove solo artefatti ricostruibili. Se vuoi mantenere determinati risultati (es. fit costosi), non includerli nel clean.\n\n14.6.6 Vantaggi pratici\n\n\nAutomatizzazione del flusso di lavoro: elimina la necessità di orchestrazione manuale degli script, sostituendo il classico “master script” con un grafo di dipendenze esplicito ed eseguibile.\n\nEsecuzione incrementale: modifiche a singoli componenti innescano automaticamente solo il riprocessamento degli output dipendenti, ottimizzando significativamente i tempi di esecuzione.\n\nDocumentazione attiva: il Makefile stesso costituisce una documentazione sempre aggiornata e verificabile della pipeline analitica, garantendo trasparenza e riproducibilità.\n\nPortabilità cross-piattaforma: il comando make all produce risultati consistenti attraverso macOS, Linux e Windows (quest’ultimo tramite ambienti come WSL o strumenti GNU), astraendo dalle specificità del sistema operativo.\n\nSe vuoi estendere l’esempio (più analisi, cross-validation, modelli addizionali), basta aggiungere nuovi target con prerequisiti appropriati e collegarli al report. Make farà il resto.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Il ciclo di vita di un progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "href": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "title": "14  Il ciclo di vita di un progetto di analisi dei dati",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa riproducibilità computazionale rappresenta un fondamento metodologico essenziale, che trascende la mera esecuzione tecnica per diventare garanzia di integrità scientifica. In psicologia, dove la complessità dei dati e la natura iterativa dell’analisi richiedono tracciabilità completa, un flusso di lavoro codificato e ben documentato non è opzionale ma necessario.\nI vantaggi si manifestano su tre livelli:\n\n\nPersonale: la capacità di riattivare, correggere o estendere un’analisi a distanza di tempo senza perdita di informazione\n\nCollettivo: la possibilità per altri ricercatori di verificare, adattare e costruire sulle procedure condivise\n\nEpistemologico: la costruzione di una conoscenza cumulativa e criticabile, basata su processi analitici trasparenti\n\nStrumenti come il versioning (git), la strutturazione coerente dei progetti e l’automazione dei flussi (make) non sono mere questioni organizzative, ma abilitatori concreti di rigore metodologico. Un’analisi riproducibile non è solo “ordinata” — è intrinsecamente più robusta, in quanto costringe a esplicitare assunzioni, scelte e trasformazioni.\nInvestire in pratiche riproducibili significa quindi investire nella qualità del proprio lavoro: non un vincolo “burocratico”, ma una disciplina che affina il pensiero critico e trasforma l’analisi dati da attività esecutiva a processo scientifico pienamente consapevole.\n\n\n\n\n\n\nUn problema cruciale della psicologia contemporanea è la crisi di replicabilità, che evidenzia come molti risultati di ricerca non siano replicabili (Collaboration, 2015). La riproducibilità computazionale, pur avendo un obiettivo più ristretto, si concentra sulla possibilità di ottenere gli stessi risultati applicando lo stesso codice agli stessi dati. Questo approccio, sebbene non risolva completamente la crisi, rappresenta un passo fondamentale verso una scienza più trasparente e rigorosa.\n\n\n\n\n\n\n\n\n\nRisposte alle Domande Iniziali\n\n\n\n\n\nOra che hai completato il capitolo, confrontiamo le risposte alle domande iniziali con quanto appreso:\n\n\nPerché è importante organizzare e documentare accuratamente i dati in un progetto di ricerca?\n\nUna gestione strutturata dei dati riduce il rischio di errori, facilita l’analisi e migliora la riproducibilità, rendendo il lavoro scientifico più affidabile e trasparente.\n\n\n\nQuali problemi possono emergere se si inizia a scrivere codice senza una pianificazione adeguata?\n\nSenza una pianificazione strategica si rischia di incorrere nel “debito tecnico”, accumulando codice disordinato che richiede correzioni costose in termini di tempo e risorse. Inoltre, si potrebbero fare scelte subottimali che compromettono la scalabilità e manutenibilità del progetto.\n\n\n\nQuali vantaggi offre R per la gestione dei dati rispetto ad altri strumenti?\n\nR fornisce strumenti avanzati per importazione, pulizia, analisi e visualizzazione dei dati, oltre a supportare la documentazione dinamica e il controllo delle versioni con Git. La sua ampia comunità e la disponibilità di pacchetti specializzati lo rendono particolarmente adatto per l’analisi statistica e la ricerca.\n\n\n\nQuali strategie potrebbero migliorare la riproducibilità del tuo lavoro?\n\nUtilizzare strumenti come Quarto per documentare il codice e le analisi, adottare percorsi relativi con il pacchetto here, strutturare i dati in cartelle ben organizzate e integrare il controllo delle versioni con Git.\n\n\n\nCome struttureresti un progetto di analisi dati per mantenerlo chiaro e facilmente replicabile?\n\n\nAdottando una struttura chiara, ad esempio:\nnome_progetto/\n├── nome_progetto.Rproj\n├── data/\n│   ├── raw/\n│   │   └── my_data.csv\n│   ├── processed/\n├── dslc_documentation/\n│   ├── 01_data_cleaning.qmd\n│   ├── 02_analysis.qmd\n│   └── functions/\n└── README.md\n\nQuesta organizzazione separa i dati grezzi da quelli elaborati, include documentazione chiara e facilita la riproducibilità.\n\n\n\n\n\nConclusione: Riflettere in anticipo sui problemi e sulle strategie di gestione dei dati aiuta a costruire workflow più efficienti e affidabili. Se le tue risposte iniziali differivano da queste, quali nuovi spunti hai appreso da questo capitolo?",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Il ciclo di vita di un progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#esercizi",
    "href": "chapters/eda/01_project_structure.html#esercizi",
    "title": "14  Il ciclo di vita di un progetto di analisi dei dati",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nL’obiettivo di questo esercizio è comprendere il ciclo di vita di un progetto di analisi dei dati, l’organizzazione del progetto e la gestione della riproducibilità.\n\n\nGestione del progetto di analisi\n\nQuali sono le fasi principali di un progetto di analisi dei dati secondo Yu (2024)?\nSpiega il ruolo della fase di formulazione del problema e raccolta dei dati.\n\n\n\nOrganizzazione del workspace in R\n\nQuali impostazioni devono essere modificate in RStudio per favorire la riproducibilità?\nPerché è importante usare percorsi relativi nei progetti in RStudio?\nDescrivi il ruolo del pacchetto here nella gestione dei percorsi dei file.\n\n\n\nStruttura dei progetti in R\n\nQuali sono i vantaggi dell’utilizzo dei progetti in RStudio?\nQuali sono le cartelle principali in una struttura organizzata di un progetto?\nPerché è utile separare i dati grezzi dai dati processati?\n\n\n\nImportazione ed esportazione dei dati\n\nQuali pacchetti di R possono essere utilizzati per importare ed esportare dati?\n\nScrivi un esempio di codice per importare un file CSV usando rio e il pacchetto here.\n\nCome puoi esportare un dataset modificato in una cartella dedicata ai dati processati?\n\n\n\nPulizia e preprocessing dei dati\n\nQual è la differenza tra pulizia e preprocessing dei dati?\n\nQuali strumenti di dplyr sono comunemente usati per pulire e trasformare i dati?\n\n\n\nAnalisi esplorativa dei dati (EDA)\n\nQuali sono alcuni strumenti utilizzati in R per effettuare un’analisi esplorativa dei dati?\n\nScrivi un breve esempio di codice in R per calcolare statistiche descrittive di base su un dataset.\n\n\n\nRiproducibilità e comunicazione dei risultati\n\nPerché la riproducibilità è un elemento chiave nella scienza dei dati?\n\nQuali strumenti offre Quarto per la documentazione e la condivisione dei risultati di un’analisi?\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Gestione del progetto di analisi\n\n\nFasi principali del progetto di analisi dei dati (Yu, 2024):\n\nFormulazione del problema e raccolta dei dati\n\nPulizia, preprocessing e analisi esplorativa\n\nAnalisi predittiva e/o inferenziale (se applicabile)\n\nValutazione dei risultati\n\nComunicazione dei risultati\n\n\n\nRuolo della fase di formulazione del problema:\nAiuta a definire gli obiettivi dell’analisi e a selezionare le fonti di dati adeguate. Una domanda di ricerca ben definita garantisce che i dati siano pertinenti e che le analisi siano mirate.\n\n2. Organizzazione del workspace in R\n\n\nImpostazioni da modificare in RStudio:\n\nDisabilitare Restore .RData into workspace at startup\n\nImpostare Save workspace to .RData on exit su “Never”\n\n\nImportanza dei percorsi relativi:\nPermettono di rendere il progetto portabile e riproducibile, evitando problemi di percorsi assoluti specifici per un computer.\nRuolo del pacchetto here\nAiuta a gestire i percorsi relativi all’interno del progetto senza dover specificare percorsi assoluti.\n\n3. Struttura dei progetti in R\n\nVantaggi dell’uso dei progetti in RStudio:\nMantengono ambienti separati, organizzano i file e facilitano la riproducibilità.\n\nCartelle principali in una struttura organizzata:\n\n\ndata/raw/ → Dati grezzi\n\n\ndata/processed/ → Dati elaborati\n\n\ndslc_documentation/ → Documentazione e script\n\n\nfunctions/ → Funzioni personalizzate\n\n\nSeparare dati grezzi da dati processati:\nEvita di modificare accidentalmente i dati originali, garantendo riproducibilità.\n\n4. Importazione ed esportazione dei dati\n\n\nPacchetti per importazione/esportazione:\n\n\nrio: unifica funzioni di import/export\n\n\nreadr: specifico per CSV e altri formati di testo\n\n\nhere: gestisce percorsi relativi\n\n\n\nEsempio di codice per importare dati CSV:\nlibrary(here)\nlibrary(rio)\ndf &lt;- rio::import(here(\"data\", \"raw\", \"my_data.csv\"))\n\n\nEsportare dati modificati:\nrio::export(df, here(\"data\", \"processed\", \"my_data_processed.csv\"))\n\n\n5. Pulizia e preprocessing dei dati\n\n\nDifferenza tra pulizia e preprocessing:\n\nPulizia: rimozione di errori, gestione dei dati mancanti, formattazione\n\nPreprocessing: trasformazione dei dati per adattarli a modelli specifici\n\n\n\nStrumenti di dplyr per pulizia e trasformazione:\n\n\nmutate(), filter(), select(), rename(), relocate()\n\n\n\n\n6. Analisi esplorativa dei dati (EDA)\n\n\nStrumenti comuni:\n\n\nsummary(), str(), glimpse(), ggplot2 per visualizzazione\n\n\n\nEsempio di codice per statistiche descrittive:\nsummary(df)\n\n\n7. Riproducibilità e comunicazione dei risultati\n\n\nImportanza della riproducibilità:\n\nFacilita la verifica e il miglioramento degli studi\n\nPreviene errori accidentali\n\nConsente a terzi di replicare e costruire su ricerche precedenti\n\n\n\nStrumenti di Quarto:\n\nPermette di combinare testo, codice e output in documenti riproducibili\n\nSupporta citazioni automatiche e gestione delle bibliografie\n\n\n\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-3         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [19] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [22] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [25] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [28] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [31] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [34] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [37] ragg_1.4.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [40] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [43] parallel_4.5.1        vctrs_0.6.5           V8_6.0.6             \n#&gt; [46] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [49] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [52] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [55] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [58] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [61] textshaping_1.0.1     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [64] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [67] broom_1.0.9           snakecase_0.11.1      rstantools_2.4.0     \n#&gt; [70] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [73] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Il ciclo di vita di un progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#bibliografia",
    "href": "chapters/eda/01_project_structure.html#bibliografia",
    "title": "14  Il ciclo di vita di un progetto di analisi dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Il ciclo di vita di un progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html",
    "href": "chapters/eda/02_data_cleaning.html",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "Introduzione\nNonostante la fase più interessante di un progetto di analisi dei dati sia quella in cui si riesce a rispondere alla domanda che ha dato avvio all’indagine, gran parte del tempo di un analista è in realtà dedicata a una fase preliminare: la pulizia e il preprocessing dei dati, operazioni che vengono svolte ancor prima dell’analisi esplorativa.\nIn questo capitolo, esamineremo un caso concreto di data cleaning e preprocessing, seguendo il tutorial di Crystal Lewis. Il problema viene presentato come segue:\nCrystal Lewis elenca i seguenti passaggi da seguire nel processo di data cleaning:\nSebbene l’ordine di questi passaggi sia flessibile e possa essere adattato alle esigenze specifiche, c’è un passaggio che non dovrebbe mai essere saltato: il primo, ovvero la revisione dei dati. Senza una revisione preliminare, l’analista rischia di sprecare ore a pulire i dati per poi scoprire che mancano dei partecipanti, che i dati non sono organizzati come previsto o, peggio ancora, che si sta lavorando con i dati sbagliati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#introduzione",
    "href": "chapters/eda/02_data_cleaning.html#introduzione",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "I am managing data for a longitudinal randomized controlled trial (RCT) study. For this RCT, schools are randomized to either a treatment or control group. Students who are in a treatment school receive a program to boost their math self-efficacy. Data is collected on all students in two waves (wave 1 is in the fall of a school year, and wave 2 is collected in the spring). At this point in time, we have collected wave 1 of our student survey on a paper form and we set up a data entry database for staff to enter the information into. Data has been double-entered, checked for entry errors, and has been exported in a csv format (“w1_mathproj_stu_svy_raw.csv”) to a folder (called “data”) where it is waiting to be cleaned.\n\n\n\nRevisione dei dati.\nRegolazione del numero di casi.\nDe-identificazione dei dati.\nEliminazione delle colonne irrilevanti.\nDivisione delle colonne, se necessario.\nRidenominazione delle variabili.\nTrasformazione/normalizzazione delle variabili.\nStandardizzazione delle variabili.\nAggiornamento dei tipi di variabili, se necessario.\nRicodifica delle variabili.\nCreazione di eventuali variabili necessarie.\nGestione dei valori mancanti, se necessario.\nAggiunta di metadati, se necessario.\nValidazione dei dati.\nFusione e/o unione dei dati, se necessario.\nTrasformazione dei dati, se necessario.\nSalvataggio dei dati puliti.\n\n\nPanoramica del capitolo\n\nVerificare, pulire e trasformare i dati per l’analisi.\nDocumentare il dataset con un dizionario e note esplicative.\nAssicurare validità, unicità e organizzazione dei dati.\nApplicare regole coerenti per denominazione e codifica.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Cleaning sample data in standardized way di Crystal Lewis.\nLeggere Getting Started Creating Data Dictionaries: How to Create a Shareable Data Set di Buchanan et al. (2021).\nConsultare il capitolo Documentation di Data Management in Large-Scale Education Research.\nConsultare How to Make a Data Dictionary.\nConsultare data dictionary template.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice, labelled, haven, pointblank, mice, purrr, knitr)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#tutorial",
    "href": "chapters/eda/02_data_cleaning.html#tutorial",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "\n15.1 Tutorial",
    "text": "15.1 Tutorial\nQuesto tutorial segue i passaggi descritti da Crystal Lewis per illustrare le buone pratiche nella gestione e pulizia dei dati.\n\n15.1.1 Organizzazione dei dati\nUn principio fondamentale nella gestione dei dati è preservare l’integrità dei dati grezzi. I dati originali non devono mai essere modificati direttamente. È quindi consigliabile strutturare i dati in una directory denominata data, suddivisa in due sottocartelle:\n\n\nraw: contiene i dati originali, mantenuti inalterati.\n\n\nprocessed: destinata ai dati ripuliti e preprocessati.\n\nAd esempio, per avviare il processo di pulizia, importiamo i dati da un file denominato w1_mathproj_stu_svy_raw.csv. Tutte le operazioni dovranno essere effettuate utilizzando percorsi relativi alla home directory del progetto, che definiremo come primo passo.\n\n15.1.2 Passaggi del tutorial\n\n15.1.2.1 Importare e esaminare i dati\nImportiamo i dati utilizzando la funzione import() della libreria rio e visualizziamo i primi valori di ciascuna colonna per verificarne la corretta importazione:\n\n# Importa i dati\nsvy &lt;- rio::import(here::here(\"data\", \"w1_mathproj_stu_svy_raw.csv\"))\n\n# Esamina la struttura del dataset\nglimpse(svy)\n#&gt; Rows: 6\n#&gt; Columns: 7\n#&gt; $ stu_id      &lt;int&gt; 1347, 1368, 1377, 1387, 1347, 1399\n#&gt; $ svy_date    &lt;IDate&gt; 2023-02-13, 2023-02-13, 2023-02-13, 2023-02-13, 2023-02-14…\n#&gt; $ grade_level &lt;int&gt; 9, 10, 9, 11, 9, 12\n#&gt; $ math1       &lt;int&gt; 2, 3, 4, 3, 2, 4\n#&gt; $ math2       &lt;chr&gt; \"1\", \"2\", \"\\n4\", \"3\", \"2\", \"1\"\n#&gt; $ math3       &lt;int&gt; 3, 2, 4, NA, 4, 3\n#&gt; $ math4       &lt;int&gt; 3, 2, 4, NA, 2, 1\n\nPer controllare visivamente i dati, possiamo esaminare le prime e le ultime righe del data frame:\n\n# Visualizza le prime righe\nsvy |&gt; \n  head()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n# Visualizza le ultime righe\nsvy |&gt; \n  tail()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n\n15.1.2.2 Individuare e rimuovere i duplicati\nIn questa fase, eseguiamo alcune modifiche necessarie al data frame, come rimuovere duplicati e ordinare i dati:\n\n\nVerifica duplicati: controlliamo i record duplicati nel dataset.\n\nRimuovi duplicati: manteniamo solo la prima occorrenza.\n\nOrdina per data: organizziamo i record in ordine crescente rispetto alla variabile svy_date.\n\nEsamina i dati puliti: controlliamo il risultato delle modifiche.\n\n\n# Identifica i duplicati basati su 'stu_id'\nduplicates &lt;- \n  svy[duplicated(svy$stu_id) | duplicated(svy$stu_id, fromLast = TRUE), ]\n\n\n# Visualizza i duplicati trovati\nduplicates\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n\n\n# Ordina per 'svy_date' in ordine crescente\nsvy &lt;- svy[order(svy$svy_date), ]\n\n\n# Rimuove i duplicati mantenendo la prima occorrenza\nsvy &lt;- svy[!duplicated(svy$stu_id), ]\n\n\n# Esamina il dataset finale\nprint(svy)\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\nVerifichiamo le dimensioni del dataset pulito per assicurarci che le operazioni siano state eseguite correttamente:\n\n# Controlla il numero di righe e colonne\nsvy |&gt; \n  dim()\n#&gt; [1] 5 7\n\n\n15.1.2.3 De-identificazione dei dati\n\n# Rimuovi la colonna 'svy_date'\nsvy &lt;- svy |&gt;\n  dplyr::select(-svy_date)\n\n# Mostra i nomi delle colonne rimaste\nnames(svy)\n#&gt; [1] \"stu_id\"      \"grade_level\" \"math1\"       \"math2\"       \"math3\"      \n#&gt; [6] \"math4\"\n\n\n15.1.2.4 Rimuovere le colonne non necessarie\nNel caso presente, la rimozione di colonne non è necessaria. Tuttavia, in molti progetti di analisi dei dati, soprattutto quando i dati vengono raccolti utilizzando software di terze parti o strumenti specifici per esperimenti psicologici, è comune trovarsi con colonne che non sono pertinenti allo studio in corso.\nQueste colonne possono includere dati come identificatori interni, timestamp generati automaticamente, informazioni di debug, o variabili che non sono rilevanti per l’analisi che si intende condurre. Quando tali colonne sono irrilevanti per la ricerca, possono essere rimosse per semplificare il dataset e ridurre il rischio di confusione o errori durante l’analisi. Rimuovere le colonne non necessarie non solo rende il dataset più gestibile, ma aiuta anche a focalizzare l’analisi sulle variabili che realmente importano per rispondere alle domande di ricerca.\n\n15.1.2.5 Dividere le colonne secondo necessità\nNel caso presente, questa operazione non è necessaria. Tuttavia, se si lavora con un dataset che include una colonna chiamata “NomeCompleto”, contenente sia il nome che il cognome di uno studente, per esempio, è buona pratica separare questa colonna in due colonne distinte, “Nome” e “Cognome”. Questa suddivisione facilita l’analisi e la manipolazione dei dati, rendendoli più organizzati e accessibili.\n\n15.1.2.6 Rinominare le colonne\nÈ importante assegnare nomi chiari alle colonne del dataset. Utilizzare nomi di variabili comprensibili aiuta a rendere l’analisi dei dati più intuitiva e a ridurre il rischio di errori interpretativi.\nEsempi di buone pratiche:\n\nEvita nomi di colonne come “x” o acronimi incomprensibili. Questi possono creare confusione durante l’analisi, specialmente se il dataset viene condiviso con altri ricercatori o se viene ripreso dopo un lungo periodo di tempo.\nInvece, cerca di utilizzare nomi di variabili che descrivano chiaramente il contenuto della colonna. Ad esempio, invece di “x1” o “VAR123”, un nome come “ansia_base” o “liv_autoefficacia” è molto più comprensibile e immediato.\nPer i nomi composti, utilizza un separatore come il trattino basso _. Ad esempio, se stai lavorando con dati relativi a un test psicologico, potresti avere colonne chiamate “test_ansia_pre” e “test_ansia_post” per indicare i risultati del test di ansia prima e dopo un intervento.\n\nEsempi di nomi di colonne ben scelti:\n\n\nNome generico: TS, AE\n\n\nNome migliore: tempo_studio, auto_efficacia\n\n\n\n\nNome generico: S1, S2\n\n\nNome migliore: stress_situazione1, stress_situazione2\n\n\n\n\nNome generico: Q1, Q2\n\n\nNome migliore: qualità_sonno_sett1, qualità_sonno_sett2\n\n\n\n\n15.1.2.7 Trasformare le variabili\nNel caso presente non si applica, ma è un passo importante in molte analisi dei dati.\nEsempi di trasformazione delle variabili:\n\nLogaritmo di una variabile: Immaginiamo di avere una variabile che misura i tempi di reazione dei partecipanti a un esperimento. Se i tempi di reazione hanno una distribuzione fortemente asimmetrica (con alcuni valori molto elevati), potrebbe essere utile applicare una trasformazione logaritmica per rendere la distribuzione più simmetrica e migliorare l’interpretabilità dei risultati.\nCodifica delle variabili categoriche: Se è presente una variabile categorica come il “tipo di intervento” con valori come “cognitivo”, “comportamentale” e “farmacologico”, potrebbe essere necessario trasformare questa variabile in variabili dummy (ad esempio, intervento_cognitivo, intervento_comportamentale, intervento_farmacologico), dove ogni variabile assume il valore 0 o 1 a seconda della presenza o meno di quel tipo di intervento. Questo è utile quando si utilizzano tecniche di regressione.\n\n15.1.2.8 Standardizzazione delle variabili\nLa standardizzazione è utile quando si desidera rendere comparabili variabili misurate su scale diverse, ad esempio per confronti tra gruppi o per inclusione in modelli di regressione.\nEsempio. Supponiamo di avere una variabile che misura il livello di ansia su una scala da 0 a 100. Per standardizzarla:\n\n\nSottrai la media del campione dalla variabile.\n\n\nDividi per la deviazione standard.\n\nIl risultato è una variabile con media pari a 0 e deviazione standard pari a 1.\nVantaggi della standardizzazione:\n\nfacilita l’interpretazione dei coefficienti in un modello di regressione;\npermette un confronto diretto tra variabili che hanno unità di misura diverse.\n\n15.1.2.9 Normalizzazione delle variabili\nLa normalizzazione consiste nel ridimensionare i dati su una scala predefinita, spesso compresa tra 0 e 1. Questo processo è particolarmente utile in analisi multivariate, dove variabili con scale molto diverse potrebbero influenzare in modo sproporzionato i risultati.\nEsempio. Hai dati su:\n\nOre di sonno (misurate in ore, da 0 a 24).\n\nLivello di stress (misurato su una scala da 1 a 50).\n\nAuto-efficacia (misurata su una scala da 0 a 100).\n\nPer garantire che ogni variabile abbia lo stesso peso nell’analisi, puoi normalizzarle usando una formula come:\n\\[\nx_{\\text{norm}} = \\frac{x - \\text{min}(x)}{\\text{max}(x) - \\text{min}(x)} .\n\\]\nPerché Standardizzare o Normalizzare?\nTrasformare le variabili è cruciale per:\n\n\nGestire scale diverse: Riduce il rischio che variabili con valori numericamente più grandi dominino i risultati.\n\n\nGarantire validità e interpretabilità: Facilita il confronto tra dati provenienti da fonti o gruppi diversi.\n\n\nEvitare problemi numerici nei modelli statistici: Alcuni algoritmi di machine learning o tecniche di ottimizzazione richiedono che i dati siano su scale simili per funzionare correttamente.\n\nIn conclusione, la scelta tra standardizzazione e normalizzazione dipende dal contesto dell’analisi e dagli obiettivi specifici. Entrambi i processi sono strumenti indispensabili per garantire che i dati siano trattati in modo adeguato, portando a risultati robusti e facilmente interpretabili.\n\n15.1.2.10 Aggiornare i tipi delle variabili\nNel caso presente non è necessario. Supponiamo invece di avere una colonna in un dataset psicologico che contiene punteggi di un questionario, ma i dati sono stati importati come stringhe (testo) invece che come numeri. Per eseguire calcoli statistici, sarà necessario convertire questa colonna da stringa a numerico.\nIn R, si potrebbe usare il seguente codice:\n\n# Supponiamo di avere un data frame chiamato 'df' con una colonna 'punteggio' importata come carattere\ndf$punteggio &lt;- as.numeric(df$punteggio)\n\n# Ora la colonna 'punteggio' è stata convertita in un tipo numerico ed è possibile eseguire calcoli su di essa\n\nIn questo esempio, la funzione as.numeric() viene utilizzata per convertire la colonna punteggio in un formato numerico, permettendo di eseguire analisi quantitative sui dati.\nUn altro caso molto comune si verifica quando si importano dati da file Excel. Spesso capita che, all’interno di una cella di una colonna che dovrebbe contenere solo valori numerici, venga inserito erroneamente uno o più caratteri alfanumerici. Di conseguenza, l’intera colonna viene interpretata come di tipo alfanumerico, anche se i valori dovrebbero essere numerici. In questi casi, è fondamentale individuare la cella problematica, correggere manualmente il valore errato, e poi riconvertire l’intera colonna da alfanumerica a numerica.\n\n15.1.2.11 Ricodificare le variabili\nAnche se in questo caso non è necessario, la ricodifica delle variabili è una pratica molto comune nelle analisi dei dati psicologici.\nPer esempio, consideriamo una variabile categoriale con modalità descritte da stringhe poco comprensibili, che vengono ricodificate con nomi più chiari e comprensibili.\nSupponiamo di avere un DataFrame chiamato df con una colonna tipo_intervento che contiene le modalità \"CT\", \"BT\", e \"MT\" per rappresentare rispettivamente “Terapia Cognitiva”, “Terapia Comportamentale” e “Terapia Mista”. Queste abbreviazioni potrebbero non essere immediatamente chiare a chiunque analizzi i dati, quindi decidiamo di ricodificarle con nomi più espliciti. Ecco come farlo in R:\n\n# Tibble chiamato 'df' con una colonna 'tipo_intervento'\ndf &lt;- tibble(tipo_intervento = c(\"CT\", \"BT\", \"MT\", \"CT\", \"BT\"))\ndf\n#&gt; # A tibble: 5 × 1\n#&gt;   tipo_intervento\n#&gt;   &lt;chr&gt;          \n#&gt; 1 CT             \n#&gt; 2 BT             \n#&gt; 3 MT             \n#&gt; 4 CT             \n#&gt; 5 BT\n\n\n# Ricodifica delle modalità della variabile 'tipo_intervento' in nomi più comprensibili\ndf &lt;- df %&gt;%\n  mutate(tipo_intervento_ricodificato = dplyr::recode(\n    tipo_intervento,\n    \"CT\" = \"Terapia Cognitiva\",\n    \"BT\" = \"Terapia Comportamentale\",\n    \"MT\" = \"Terapia Mista\"\n  ))\n\n# Mostra il tibble con la nuova colonna ricodificata\ndf\n#&gt; # A tibble: 5 × 2\n#&gt;   tipo_intervento tipo_intervento_ricodificato\n#&gt;   &lt;chr&gt;           &lt;chr&gt;                       \n#&gt; 1 CT              Terapia Cognitiva           \n#&gt; 2 BT              Terapia Comportamentale     \n#&gt; 3 MT              Terapia Mista               \n#&gt; 4 CT              Terapia Cognitiva           \n#&gt; 5 BT              Terapia Comportamentale\n\n\n15.1.2.12 Aggiungere nuove variabili nel data frame\nNel caso presente non è richiesto, ma aggiungere nuove variabili a un DataFrame è un’operazione comune durante l’analisi dei dati. Un esempio è il calcolo dell’indice di massa corporea (BMI).\nSupponiamo di avere un DataFrame chiamato df che contiene le colonne peso_kg (peso in chilogrammi) e altezza_m (altezza in metri) per ciascun partecipante a uno studio psicologico. Per arricchire il dataset, possiamo calcolare il BMI per ogni partecipante e aggiungerlo come una nuova variabile.\nIl BMI si calcola con la formula:\n\\[ \\text{BMI} = \\frac{\\text{peso in kg}}{\\text{altezza in metri}^2} .\\]\nEcco come aggiungere la nuova colonna.\n\n# Supponiamo di avere un tibble chiamato 'df' con le colonne 'peso_kg' e 'altezza_m'\ndf &lt;- tibble(\n  peso_kg = c(70, 85, 60, 95),\n  altezza_m = c(1.75, 1.80, 1.65, 1.90)\n)\ndf\n#&gt; # A tibble: 4 × 2\n#&gt;   peso_kg altezza_m\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1      70      1.75\n#&gt; 2      85      1.8 \n#&gt; 3      60      1.65\n#&gt; 4      95      1.9\n\n\n# Calcola il BMI e aggiungilo come una nuova colonna 'BMI'\ndf &lt;- df %&gt;%\n  mutate(BMI = peso_kg / (altezza_m^2))\n\n# Mostra il tibble con la nuova variabile aggiunta\ndf\n#&gt; # A tibble: 4 × 3\n#&gt;   peso_kg altezza_m   BMI\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1      70      1.75  22.9\n#&gt; 2      85      1.8   26.2\n#&gt; 3      60      1.65  22.0\n#&gt; 4      95      1.9   26.3\n\n\n15.1.3 Affrontare il problema dei dati mancanti\nI dati mancanti sono un problema comune nelle ricerche psicologiche e in molte altre discipline. Quando mancano delle informazioni in un dataset, possono verificarsi gravi problemi per l’analisi statistica, come risultati distorti, riduzione della precisione delle stime o, in alcuni casi, l’impossibilità di applicare alcuni algoritmi.\n\n15.1.3.1 Perché i dati mancanti sono un problema?\nImmagina di voler capire il rendimento medio di una classe in un test, ma alcuni studenti hanno lasciato delle risposte in bianco. Se ignoriamo le risposte mancanti o eliminiamo gli studenti con dati incompleti, rischiamo di ottenere una stima che non rappresenta correttamente la realtà. Questo succede perché:\n\n\nBias dei risultati: Se i dati mancanti non sono casuali (ad esempio, i dati mancanti sono presenti più spesso in studenti con basso rendimento), le conclusioni possono essere errate.\n\nRiduzione della potenza statistica: Eliminare dati incompleti riduce il numero totale di osservazioni, rendendo più difficile trovare risultati significativi.\n\nImpossibilità di applicare alcuni metodi: Molti algoritmi statistici richiedono dati completi e non funzionano con valori mancanti.\n\n15.1.3.2 Come gestire i dati mancanti?\nCi sono diversi modi per affrontare i dati mancanti. Vediamo prima i metodi più semplici e poi quelli più avanzati.\nEsaminiamo il data frame iniziale:\n\nsvy |&gt; \n  summary()\n#&gt;      stu_id      grade_level       math1        math2               math3     \n#&gt;  Min.   :1347   Min.   : 9.0   Min.   :2.0   Length:5           Min.   :2.00  \n#&gt;  1st Qu.:1368   1st Qu.: 9.0   1st Qu.:3.0   Class :character   1st Qu.:2.75  \n#&gt;  Median :1377   Median :10.0   Median :3.0   Mode  :character   Median :3.00  \n#&gt;  Mean   :1376   Mean   :10.2   Mean   :3.2                      Mean   :3.00  \n#&gt;  3rd Qu.:1387   3rd Qu.:11.0   3rd Qu.:4.0                      3rd Qu.:3.25  \n#&gt;  Max.   :1399   Max.   :12.0   Max.   :4.0                      Max.   :4.00  \n#&gt;                                                                 NA's   :1     \n#&gt;      math4     \n#&gt;  Min.   :1.00  \n#&gt;  1st Qu.:1.75  \n#&gt;  Median :2.50  \n#&gt;  Mean   :2.50  \n#&gt;  3rd Qu.:3.25  \n#&gt;  Max.   :4.00  \n#&gt;  NA's   :1\n\nSi noti la presenza di dati mancanti sulle variabili math3 e math4.\n\ndim(svy)\n#&gt; [1] 5 6\n\n\n\nEsclusione dei Casi Incompleti (Complete Case Analysis).\nUn approccio comune, ma spesso non ideale, è quello di analizzare solo i casi completi, eliminando tutte le righe con valori mancanti. In R, questo si può fare con il seguente comando:\n\nsvy_comp &lt;- svy |&gt;\n  drop_na()\n\nIn questo modo abbiamo escluso tutte le righe nelle quali sono presenti dei dati mancanti (in questo caso, una sola riga).\n\ndim(svy_comp)\n#&gt; [1] 4 6\n\nLimite: Questo metodo può introdurre bias se i dati mancanti non sono casuali e riduce il campione, compromettendo l’affidabilità delle analisi.\n\n\nImputazione Semplice\nSostituire i valori mancanti con stime semplici:\n\n\nMedia o mediana: Per le variabili numeriche, sostituire i valori mancanti con la media o la mediana. Questo metodo è facile da implementare, ma può ridurre la variabilità nei dati.\n\nModa: Per le variabili categoriche, sostituire i valori mancanti con il valore più frequente. Tuttavia, può introdurre distorsioni se i dati sono molto eterogenei.\n\n\n\nImputazione Multipla\nUn approccio più avanzato è l’imputazione multipla, che utilizza modelli statistici per stimare i valori mancanti in modo iterativo. L’idea di base è semplice: ogni valore mancante viene stimato tenendo conto delle relazioni con tutte le altre variabili.\nVantaggi:\n\nMantiene la variabilità dei dati.\nPreserva le relazioni tra le variabili.\nRiduce il rischio di bias rispetto ai metodi semplici.\n\n\n\n15.1.3.3 Applicazione pratica: imputazione multipla con mice in R\nSupponiamo di avere un dataset con alcune colonne numeriche che contengono valori mancanti. Possiamo utilizzare il pacchetto mice per imputare i dati mancanti.\nSelezioniamo le colonne numeriche da imputare.\n\nnumeric_columns &lt;- c(\"math1\", \"math2\", \"math3\", \"math4\")\nsvy &lt;- svy %&gt;%\n  mutate(across(all_of(numeric_columns), as.numeric))\n\nEseguiamo l’imputazione multipla.\n\nimputed &lt;- mice(\n  svy[numeric_columns], \n  m = 1, \n  maxit = 10, \n  method = \"norm.predict\", \n  seed = 123\n)\n#&gt; \n#&gt;  iter imp variable\n#&gt;   1   1  math3  math4\n#&gt;   2   1  math3  math4\n#&gt;   3   1  math3  math4\n#&gt;   4   1  math3  math4\n#&gt;   5   1  math3  math4\n#&gt;   6   1  math3  math4\n#&gt;   7   1  math3  math4\n#&gt;   8   1  math3  math4\n#&gt;   9   1  math3  math4\n#&gt;   10   1  math3  math4\n\nOttieniamo il dataset con i valori imputati.\n\nsvy_imputed &lt;- complete(imputed)\n\nArrotondiamo i valori imputati (se necessario).\n\nsvy_imputed &lt;- svy_imputed %&gt;%\n  mutate(across(everything(), round))\n\nSostituiamo i valori imputati nel dataset originale.\n\nsvy[numeric_columns] &lt;- svy_imputed\n\nEsaminiamo il risultato ottenuto.\n\nsvy |&gt; \n  summary()\n#&gt;      stu_id      grade_level       math1         math2         math3    \n#&gt;  Min.   :1347   Min.   : 9.0   Min.   :2.0   Min.   :1.0   Min.   :2.0  \n#&gt;  1st Qu.:1368   1st Qu.: 9.0   1st Qu.:3.0   1st Qu.:1.0   1st Qu.:3.0  \n#&gt;  Median :1377   Median :10.0   Median :3.0   Median :2.0   Median :3.0  \n#&gt;  Mean   :1376   Mean   :10.2   Mean   :3.2   Mean   :2.2   Mean   :3.2  \n#&gt;  3rd Qu.:1387   3rd Qu.:11.0   3rd Qu.:4.0   3rd Qu.:3.0   3rd Qu.:4.0  \n#&gt;  Max.   :1399   Max.   :12.0   Max.   :4.0   Max.   :4.0   Max.   :4.0  \n#&gt;      math4    \n#&gt;  Min.   :1.0  \n#&gt;  1st Qu.:2.0  \n#&gt;  Median :3.0  \n#&gt;  Mean   :2.8  \n#&gt;  3rd Qu.:4.0  \n#&gt;  Max.   :4.0\n\n\n15.1.3.4 Come funziona l’imputazione multipla?\n\nOgni variabile con valori mancanti viene modellata come funzione delle altre variabili.\nI valori mancanti vengono stimati iterativamente. In ogni iterazione, si utilizza l’output precedente come input per migliorare le stime.\nDopo un numero sufficiente di iterazioni, le stime si stabilizzano (convergenza).\n\nIn conclusione, l’imputazione multipla è una tecnica avanzata che permette di gestire i dati mancanti preservando la qualità delle analisi. Rispetto ai metodi semplici, consente di mantenere la variabilità e ridurre il rischio di bias, rendendola una scelta ideale per analisi psicologiche e di ricerca.\n\n15.1.3.5 Aggiungere i metadati\nI metadati sono informazioni che descrivono i dati stessi, come etichette di variabili, etichette di valori, informazioni sull’origine dei dati, unità di misura e altro ancora. Questi metadati sono essenziali per comprendere, documentare e condividere correttamente un dataset.\nIn R, i metadati sono gestiti in modo molto dettagliato e strutturato attraverso pacchetti come haven, labelled, e Hmisc. Questi pacchetti consentono di associare etichette ai dati, come etichette di variabili e di valori, e persino di gestire i valori mancanti con etichette specifiche.\n\n\nEtichette di variabili: Si possono aggiungere direttamente alle colonne di un DataFrame usando funzioni come labelled::set_variable_labels().\n\nEtichette di valori: Possono essere aggiunte a variabili categoriali utilizzando labelled::labelled().\n\nValori mancanti: In R, è possibile etichettare specifici valori come mancanti usando labelled::na_values&lt;-.\n\nQuesti strumenti rendono molto facile documentare un dataset all’interno del processo di analisi, assicurando che tutte le informazioni critiche sui dati siano facilmente accessibili e ben documentate.\nEsaminiamo un esempio pratico. Consideriamo nuovamente il data set svy:\n\nglimpse(svy)\n#&gt; Rows: 5\n#&gt; Columns: 6\n#&gt; $ stu_id      &lt;int&gt; 1347, 1368, 1377, 1387, 1399\n#&gt; $ grade_level &lt;int&gt; 9, 10, 9, 11, 12\n#&gt; $ math1       &lt;dbl&gt; 2, 3, 4, 3, 4\n#&gt; $ math2       &lt;dbl&gt; 1, 2, 4, 3, 1\n#&gt; $ math3       &lt;dbl&gt; 3, 2, 4, 4, 3\n#&gt; $ math4       &lt;dbl&gt; 3, 2, 4, 4, 1\n\nSi noti che la variabile math2 contiene un valore inamissibile, probabilmente un errore di battitura. Questo fa in modo che math2 sia di tipo char mentre dovrebbe essere una variabile numerica. Correggiamo.\n\n# Correzione di `math2`: Rimuovi valori non validi e converti in numerico\nsvy$math2 &lt;- gsub(\"\\\\n\", \"\", svy$math2)  # Rimuovi caratteri non validi come '\\n'\nsvy$math2 &lt;- as.numeric(svy$math2)      # Converte la variabile in numerico\n\n# Visualizzazione del dataset corretto\nprint(svy)\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\nDefiniamo le etichette di valore per le variabili math1:math4.\n\nvalue_labels_math &lt;- set_names(\n  as.numeric(names(c(\n    `1` = \"strongly disagree\",\n    `2` = \"disagree\",\n    `3` = \"agree\",\n    `4` = \"strongly agree\"\n  ))),\n  c(\"strongly disagree\", \"disagree\", \"agree\", \"strongly agree\")\n)\n\nAggiungiamo le etichette di valore alle colonne math1:math4.\n\nsvy &lt;- svy %&gt;%\n  mutate(across(starts_with(\"math\"), ~ labelled(., labels = value_labels_math)))\n\nVerifica delle etichette.\n\nval_labels(svy$math1)\n#&gt; strongly disagree          disagree             agree    strongly agree \n#&gt;                 1                 2                 3                 4\n\n\nsvy\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\n\n15.1.3.5.1 Utilizzo delle etichette in R con variabili numeriche\nLe etichette dei valori (value labels) vengono utilizzate per rendere più leggibili e interpretabili le variabili numeriche, associando ad ogni valore un’etichetta descrittiva. Questo approccio è particolarmente utile in ambiti come la ricerca psicologica, dove le risposte ai questionari sono spesso codificate con numeri (ad esempio, 1 = “Strongly Disagree”, 2 = “Disagree”, ecc.) ma rappresentano concetti qualitativi.\nVantaggi dell’Uso delle Etichette\n\n\nChiarezza nelle Analisi: Le etichette descrittive rendono i dati più facilmente comprensibili senza dover ricordare il significato numerico di ciascun valore.\n\n\nDocumentazione Integrata: Permettono di incorporare metadati direttamente nelle variabili, migliorando la trasparenza e riducendo il rischio di interpretazioni errate.\n\nCompatibilità con Software Statistici: Molti strumenti (ad esempio, SPSS o Stata) utilizzano etichette di valori. Il pacchetto haven in R consente di gestire facilmente i dati etichettati esportati/importati da questi software.\n\nManipolazione di Variabili Etichettate\nAnche se una variabile numerica è etichettata con labelled (ad esempio, tramite il pacchetto haven), essa conserva la sua natura numerica e può essere utilizzata in calcoli, modelli statistici, e trasformazioni. Le etichette non alterano il valore sottostante, ma lo arricchiscono con informazioni aggiuntive.\nIn conclusione, le etichette dei valori migliorano l’interpretabilità dei dati senza comprometterne la manipolabilità. Questo approccio è ideale per mantenere le variabili numeriche pienamente funzionali per analisi statistiche, mentre le etichette descrittive forniscono un contesto chiaro e leggibile.\n\n15.1.3.6 Validazione dei dati\nLa validazione dei dati è un passaggio fondamentale per garantire che il dataset soddisfi i criteri previsti e sia pronto per le analisi successive. Questo processo include il controllo della coerenza e della correttezza dei dati in base a specifiche regole definite dal dizionario dei dati. Alcune verifiche comuni includono:\n\n\nUnicità delle righe: Assicurarsi che ogni riga sia unica, verificando l’assenza di ID duplicati.\n\nValidità degli ID: Controllare che gli ID rientrino in un intervallo previsto (es. numerico).\n\nValori accettabili nelle variabili categoriali: Verificare che variabili come grade_level, int e le colonne math contengano esclusivamente valori appartenenti a un set di valori validi.\n\nIl pacchetto pointblank fornisce strumenti flessibili e intuitivi per eseguire verifiche di validazione e generare report dettagliati. Questo pacchetto consente di:\n\n\nDefinire le regole di validazione: Specificare controlli come unicità, intervalli di valori e appartenenza a insiemi predefiniti.\n\nEseguire i controlli: Applicare le regole di validazione su un dataset per identificare eventuali discrepanze.\n\nGenerare report interattivi: Creare un riepilogo chiaro e visivo dei controlli, evidenziando eventuali errori o anomalie.\n\nCon pointblank, è possibile integrare la validazione dei dati come parte di un workflow strutturato, garantendo la qualità dei dati in modo sistematico e ripetibile.\ncreate_agent(svy) %&gt;%\n  rows_distinct(columns = vars(stu_id)) %&gt;%\n  col_vals_between(columns = c(stu_id), \n                   left = 1300, right = 1400, na_pass = TRUE) %&gt;%\n  col_vals_in_set(columns = c(grade_level), \n                  set = c(9, 10, 11, 12, NA)) %&gt;%\n  col_vals_in_set(columns = c(int),\n                  set = c(0, 1, NA)) %&gt;%\n  col_vals_in_set(columns = c(math1:math4),\n                  set = c(1, 2, 3, 4, NA)) %&gt;%\n  interrogate()\nIl dataset ripulito soddisfa tutte le aspettative delineate da Crystal Lewis.\n\n\nCompleto: Tutti i dati raccolti sono stati inseriti e/o recuperati. Non dovrebbero esserci dati estranei che non appartengono al dataset (come duplicati o partecipanti non autorizzati).\n\nValido: Le variabili rispettano i vincoli definiti nel tuo dizionario dei dati. Ricorda che il dizionario dei dati specifica i nomi delle variabili, i tipi, i range, le categorie e altre informazioni attese.\n\nAccurato: Sebbene non sia sempre possibile determinare l’accuratezza dei valori durante il processo di pulizia dei dati (ovvero, se un valore è realmente corretto o meno), in alcuni casi è possibile valutarla sulla base della conoscenza pregressa riguardante quel partecipante o caso specifico.\n\nCoerente: I valori sono allineati tra le varie fonti. Ad esempio, la data di nascita raccolta attraverso un sondaggio studentesco dovrebbe avere un formato corrispondere alla data di nascita raccolta dal distretto scolastico.\n\nUniforme: I dati sono standardizzati attraverso i moduli e nel tempo. Ad esempio, lo stato di partecipazione ai programmi di pranzo gratuito o a prezzo ridotto è sempre fornito come una variabile numerica con la stessa rappresentazione, oppure il nome della scuola è sempre scritto in modo coerente in tutto il dataset.\n\nDe-identificato: Tutte le informazioni personali identificabili (PII) sono state rimosse dal dataset per proteggere la riservatezza dei partecipanti (se richiesto dal comitato etico/consenso informato).\n\nInterpretabile: I dati hanno nomi di variabili leggibili sia da umani che dal computer, e sono presenti etichette di variabili e valori laddove necessario per facilitare l’interpretazione.\n\nAnalizzabile: Il dataset è in un formato rettangolare (righe e colonne), leggibile dal computer e conforme alle regole di base della struttura dei dati.\n\nUna volta completati i 14 passaggi precedenti, è possibile esportare questo dataset ripulito nella cartella processed per le successive analisi statistiche.\n\n15.1.3.7 Unire e/o aggiungere dati se necessario\nIn questo passaggio, è possibile unire o aggiungere colonne o righe presenti in file diversi. È importante eseguire nuovamente i controlli di validazione dopo l’unione/aggiunta di nuovi dati.\n\n15.1.3.8 Trasformare i dati se necessario\nEsistono vari motivi per cui potrebbe essere utile memorizzare i dati in formato long o wide. In questo passaggio, è possibile ristrutturare i dati secondo le esigenze.\n\n15.1.3.9 Salvare il dataset pulito finale\nL’ultimo passaggio del processo di pulizia consiste nell’esportare o salvare il dataset pulito. Come accennato in precedenza, può essere utile esportare/salvare il dataset in più di un formato di file (ad esempio, un file .csv e un file .parquet).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "href": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "\n15.2 Organizzazione dei file e informazioni aggiuntive",
    "text": "15.2 Organizzazione dei file e informazioni aggiuntive\nInfine, è essenziale includere una documentazione adeguata per garantire che le informazioni siano interpretate correttamente, sia da altri utenti che da te stesso, se dovessi tornare a lavorare su questo progetto in futuro. La documentazione minima da fornire dovrebbe includere:\n\n\nDocumentazione a livello di progetto: Questa sezione fornisce informazioni contestuali sul perché e come i dati sono stati raccolti. È utile per chiunque voglia comprendere lo scopo e la metodologia del progetto.\n\nMetadati a livello di progetto: Se condividi i dati in un repository pubblico o privato, è importante includere metadati a livello di progetto. Questi metadati forniscono informazioni dettagliate che facilitano la ricerca, la comprensione e la consultabilità dei dati. I metadati a livello di progetto possono includere descrizioni generali del progetto, parole chiave, e riferimenti bibliografici.\n\nDizionario dei dati: Un documento che descrive tutte le variabili presenti nel dataset, inclusi i loro nomi, tipi, range di valori, categorie e qualsiasi altra informazione rilevante. Questo strumento è fondamentale per chiunque voglia comprendere o analizzare i dati.\n\nREADME: Un file che fornisce una panoramica rapida dei file inclusi nel progetto, spiegando cosa contengono e come sono interconnessi. Il README è spesso il primo documento consultato e serve a orientare l’utente tra i vari file e risorse del progetto. Questa documentazione non solo aiuta a mantenere il progetto organizzato, ma è anche cruciale per facilitare la collaborazione e l’archiviazione a lungo termine.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "href": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "\n15.3 Dizionario dei dati",
    "text": "15.3 Dizionario dei dati\nApprofondiamo qui il problema della creazione del Dizionario dei dati.\nUn dizionario dei dati è un documento che descrive le caratteristiche di ciascuna variabile in un dataset. Include informazioni come il nome della variabile, il tipo di dato, il range di valori, le categorie (per le variabili categoriche), e altre informazioni rilevanti. Questo strumento è essenziale per comprendere e analizzare correttamente il dataset.\nSi presti particolare attenzione alle guide di stile per la denominazione delle variabili e la codifica dei valori delle risposte.\n\n15.3.1 Esempio in R\n\nEcco come tradurre i passi per creare un dizionario dei dati in R, utilizzando il pacchetto tibble per creare il dizionario e writexl o readr per esportarlo in formato .xlsx o .csv.\n\n\nIdentificare le variabili: Elencare tutte le variabili presenti nel dataset.\n\nDescrivere ogni variabile: Per ciascuna variabile, definire il tipo (ad esempio, integer, numeric, character), il range di valori accettabili o le categorie, e fornire una descrizione chiara.\n\nSalvare il dizionario dei dati: Il dizionario può essere salvato in un file .csv o .xlsx per una facile consultazione.\n\nsvy\nCreeremo un dizionario dei dati per un dataset di esempio e lo salveremo sia in formato CSV che Excel.\nlibrary(tibble)\nlibrary(readr)\nlibrary(writexl)\n\n# Creazione del Dizionario dei Dati\ndata_dict &lt;- tibble(\n  `Variable Name` = c(\n    \"stu_id\",\n    \"svy_date\",\n    \"grade_level\",\n    \"math1\",\n    \"math2\",\n    \"math3\",\n    \"math4\"\n  ),\n  `Type` = c(\n    \"integer\",\n    \"datetime\",\n    \"integer\",\n    \"integer\",\n    \"integer\",\n    \"numeric\",\n    \"numeric\"\n  ),\n  `Description` = c(\n    \"Student ID\",\n    \"Survey Date\",\n    \"Grade Level\",\n    \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\"\n  ),\n  `Range/Values` = c(\n    \"1347-1399\",\n    \"2023-02-13 to 2023-02-14\",\n    \"9-12\",\n    \"1-4\",\n    \"1-4\",\n    \"1.0-4.0 (NA allowed)\",\n    \"1.0-4.0 (NA allowed)\"\n  )\n)\n\n# Visualizza il Dizionario dei Dati\nprint(data_dict)\n\n# Salva il Dizionario dei Dati in un file CSV\nwrite_csv(data_dict, here::here(\"data\", \"processed\", \"data_dictionary.csv\"))\n\n# Salva il Dizionario dei Dati in un file Excel\nwrite_xlsx(data_dict, here::here(\"data\", \"processed\", \"data_dictionary.xlsx\"))\nOutput Atteso: file CSV (data_dictionary.csv).\ndata_dict &lt;- rio::import(\n  here::here(\"data\", \"processed\", \"data_dictionary.csv\")\n)\nprint(data_dict)\n\n15.3.1.1 Uso del pacchetto dataMeta\n\nIl pacchetto dataMeta è progettato per generare metadati e dizionari dei dati in modo strutturato.\n\nlibrary(dataMeta)\nlibrary(tibble)\n\n# Descrizioni delle variabili\nvariable_descriptions &lt;- c(\n  \"Student ID\",\n  \"Grade Level\",\n  \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\"\n)\n\nvar_type &lt;- c(1, 0, 0, 0, 0, 0)\n\nlinker &lt;- build_linker(\n  svy, \n  variable_description = variable_descriptions, \n  variable_type = var_type\n)\n\ndict &lt;- build_dict(\n  my.data = svy, \n  linker = linker, \n  option_description = NULL, \n  prompt_varopts = FALSE\n)\n\nkable(dict, format = \"html\", caption = \"Data dictionary for original dataset\")\n\n\nData dictionary for original dataset\n\nvariable_name\nvariable_description\nvariable_options\n\n\n\ngrade_level\nGrade Level\n9 to 12\n\n\nmath1\nMath Response 1 (1: Strongly Disagree, 4: Strongly Agree)\n2 to 4\n\n\nmath2\nMath Response 2 (1: Strongly Disagree, 4: Strongly Agree)\n1 to 4\n\n\nmath3\nMath Response 3 (1: Strongly Disagree, 4: Strongly Agree)\n2 to 4\n\n\nmath4\nMath Response 4 (1: Strongly Disagree, 4: Strongly Agree)\n1 to 4\n\n\nstu_id\nStudent ID\n1347\n\n\n\n\n1368\n\n\n\n\n1377\n\n\n\n\n1387\n\n\n\n\n1399\n\n\n\n\n\n\n15.3.1.2 Uso del pacchetto skimr\n\nIl pacchetto skimr è utile per generare riassunti dettagliati delle variabili, che possono essere utilizzati come base per un dizionario.\n\nlibrary(skimr)\n\n# Riassunto del dataset\nskim_dict &lt;- skim(svy)\n\nkable(skim_dict, format = \"html\", caption = \"Data dictionary for original dataset\")\n\n\nData dictionary for original dataset\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\nnumeric\nstu_id\n0\n1\n1375.6\n19.718\n1347\n1368\n1377\n1387\n1399\n▃▁▇▃▃\n\n\nnumeric\ngrade_level\n0\n1\n10.2\n1.304\n9\n9\n10\n11\n12\n▇▃▁▃▃\n\n\nnumeric\nmath1\n0\n1\n3.2\n0.837\n2\n3\n3\n4\n4\n▃▁▇▁▇\n\n\nnumeric\nmath2\n0\n1\n2.2\n1.304\n1\n1\n2\n3\n4\n▇▃▁▃▃\n\n\nnumeric\nmath3\n0\n1\n3.2\n0.837\n2\n3\n3\n4\n4\n▃▁▇▁▇\n\n\nnumeric\nmath4\n0\n1\n2.8\n1.304\n1\n2\n3\n4\n4\n▃▃▁▃▇",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "href": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nNel processo di analisi dei dati, la fase di pulizia e pre-elaborazione è cruciale per garantire la qualità e l’integrità dei risultati finali. Sebbene questa fase possa sembrare meno interessante rispetto all’analisi vera e propria, essa costituisce la base su cui si costruiscono tutte le successive elaborazioni e interpretazioni. Attraverso una serie di passaggi strutturati, come quelli illustrati in questo capitolo, è possibile trasformare dati grezzi e disordinati in un dataset pulito, coerente e pronto per l’analisi. La cura nella gestione dei dati, dalla rimozione di duplicati alla creazione di un dizionario dei dati, è fondamentale per ottenere risultati affidabili e riproducibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#esercizi",
    "href": "chapters/eda/02_data_cleaning.html#esercizi",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, applicherai le tecniche di pulizia e preprocessing dei dati utilizzando il dataset SWLS. Il tuo compito è seguire i passaggi descritti per trasformare il dataset in una forma pronta per l’analisi.\nIstruzioni\n\n\nImporta i dati SWLS (Survey of Life Satisfaction Scale). Introduci almeno due dati mancanti nei dati e almeno un duplicato.\n\nControlla i dati: verifica la struttura e individua eventuali anomalie.\n\nPulisci i dati:\n\nRimuovi eventuali duplicati.\nGestisci i valori mancanti in modo appropriato.\nRinomina le variabili per una maggiore chiarezza.\nStandardizza alcune variabili per l’analisi.\n\n\n\nDocumenta le modifiche effettuate.\n\nEsporta il dataset pulito.\n\nConsegna\n\nSalva il tuo file Quarto con il nome swls_cleaning.qmd.\n\nUsa questo header YAML:\n---\ntitle: \"Assegnamento: Pulizia e Preprocessing dei Dati SWLS\"\nauthor: \"Nome Studente\"\ndate: \"2025-09-04\"\nformat: html\n---\n\nAssicurati che il codice sia commentato e spiegato chiaramente.\nEsporta il dataset pulito e allegalo alla consegna.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] skimr_2.2.1           dataMeta_0.1.1        knitr_1.50           \n#&gt;  [4] purrr_1.1.0           pointblank_0.12.2     haven_2.5.5          \n#&gt;  [7] labelled_2.14.1       mice_3.18.0           pillar_1.11.0        \n#&gt; [10] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt; [13] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [16] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [19] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [22] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [25] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [28] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [31] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;   [1] RColorBrewer_1.1-3    tensorA_0.36.2.1      jsonlite_2.0.0       \n#&gt;   [4] shape_1.4.6.1         magrittr_2.0.3        TH.data_1.1-3        \n#&gt;   [7] estimability_1.5.1    jomo_2.7-6            farver_2.1.2         \n#&gt;  [10] nloptr_2.2.1          rmarkdown_2.29        ragg_1.4.0           \n#&gt;  [13] vctrs_0.6.5           memoise_2.0.1         minqa_1.2.8          \n#&gt;  [16] base64enc_0.1-3       htmltools_0.5.8.1     forcats_1.0.0        \n#&gt;  [19] distributional_0.5.0  curl_7.0.0            broom_1.0.9          \n#&gt;  [22] mitml_0.4-5           htmlwidgets_1.6.4     sandwich_3.1-1       \n#&gt;  [25] emmeans_1.11.2-8      zoo_1.8-14            lubridate_1.9.4      \n#&gt;  [28] cachem_1.1.0          lifecycle_1.0.4       iterators_1.0.14     \n#&gt;  [31] pkgconfig_2.0.3       Matrix_1.7-4          R6_2.6.1             \n#&gt;  [34] fastmap_1.2.0         rbibutils_2.3         snakecase_0.11.1     \n#&gt;  [37] digest_0.6.37         colorspace_2.1-1      rprojroot_2.1.1      \n#&gt;  [40] textshaping_1.0.1     timechange_0.3.0      abind_1.4-8          \n#&gt;  [43] compiler_4.5.1        withr_3.0.2           backports_1.5.0      \n#&gt;  [46] inline_0.3.21         QuickJSR_1.8.0        pkgbuild_1.4.8       \n#&gt;  [49] R.utils_2.13.0        pan_1.9               MASS_7.3-65          \n#&gt;  [52] tools_4.5.1           nnet_7.3-20           R.oo_1.27.1          \n#&gt;  [55] glue_1.8.0            nlme_3.1-168          grid_4.5.1           \n#&gt;  [58] checkmate_2.3.3       generics_0.1.4        gtable_0.3.6         \n#&gt;  [61] R.methodsS3_1.8.2     data.table_1.17.8     hms_1.1.3            \n#&gt;  [64] utf8_1.2.6            foreach_1.5.2         stringr_1.5.1        \n#&gt;  [67] splines_4.5.1         lattice_0.22-7        survival_3.8-3       \n#&gt;  [70] tidyselect_1.2.1      reformulas_0.4.1      arrayhelpers_1.1-0   \n#&gt;  [73] gridExtra_2.3         V8_6.0.6              stats4_4.5.1         \n#&gt;  [76] xfun_0.53             bridgesampling_1.1-2  stringi_1.8.7        \n#&gt;  [79] pacman_0.5.1          boot_1.3-32           evaluate_1.0.5       \n#&gt;  [82] codetools_0.2-20      cli_3.6.5             blastula_0.3.6       \n#&gt;  [85] RcppParallel_5.1.11-1 rpart_4.1.24          xtable_1.8-4         \n#&gt;  [88] systemfonts_1.2.3     Rdpack_2.6.4          repr_1.1.7           \n#&gt;  [91] coda_0.19-4.1         svUnit_1.0.8          parallel_4.5.1       \n#&gt;  [94] rstantools_2.4.0      Brobdingnag_1.2-9     lme4_1.1-37          \n#&gt;  [97] glmnet_4.1-10         mvtnorm_1.3-3         scales_1.4.0         \n#&gt; [100] rlang_1.1.6           multcomp_1.4-28",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#bibliografia",
    "href": "chapters/eda/02_data_cleaning.html#bibliografia",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBuchanan, E. M., Crain, S. E., Cunningham, A. L., Johnson, H. R., Stash, H., Papadatou-Pastou, M., Isager, P. M., Carlsson, R., & Aczel, B. (2021). Getting started creating data dictionaries: How to create a shareable data set. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920928007.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_exploring_qualitative_data.html",
    "href": "chapters/eda/03_exploring_qualitative_data.html",
    "title": "16  Esplorare i dati qualitativi",
    "section": "",
    "text": "Introduzione\nIn questo capitolo ci concentreremo sull’analisi esplorativa dei dati (Exploratory Data Analysis, EDA) applicata ai dati qualitativi e categoriali (Tukey et al., 1977). In psicologia la raccolta di dati qualitativi e categoriali è estremamente frequente: si pensi alle variabili sociodemografiche (genere, stato civile, livello di istruzione), alle risposte a item a scelta multipla nei questionari, alle diagnosi cliniche, o alle categorie di comportamento osservato in laboratorio. Prima di procedere a modelli complessi, è fondamentale esplorare questi dati per comprenderne la struttura, individuare pattern ricorrenti e riconoscere eventuali anomalie.\nL’EDA rappresenta il primo passo di ogni studio empirico. Con grafici e tabelle di frequenza possiamo farci un’idea immediata della distribuzione delle risposte, verificare se i dati sono equilibrati tra categorie, e osservare come certe caratteristiche si combinano. Ad esempio, in un’indagine clinica potremmo voler capire se i livelli di ansia riportati dai pazienti variano in base al genere o alla fascia di età; in uno studio sperimentale, se il successo in un compito dipende dalla condizione a cui il partecipante è stato assegnato.\nIn questo capitolo impareremo dunque a esplorare e visualizzare i dati qualitativi, passando da strumenti descrittivi come le tabelle di frequenza e le percentuali cumulative, fino a grafici più sofisticati (barplot, mosaic plot) che consentono di cogliere a colpo d’occhio le relazioni tra più variabili. L’obiettivo non è soltanto acquisire dimestichezza con le tecniche, ma anche sviluppare un atteggiamento critico, capace di riconoscere i limiti e le potenzialità delle rappresentazioni grafiche quando applicate a dati che riflettono la complessità dell’esperienza psicologica.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_exploring_qualitative_data.html#introduzione",
    "href": "chapters/eda/03_exploring_qualitative_data.html#introduzione",
    "title": "16  Esplorare i dati qualitativi",
    "section": "",
    "text": "Panoramica del capitolo\n\nCalcolare proporzioni e organizzare i dati in tabelle di contingenza.\nCostruire grafici a barre per rappresentare dati qualitativi.\nCreare visualizzazioni per esplorare le relazioni tra due o più variabili qualitative.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Exploring categorical data di Introduction to Modern Statistics (2e) di Mine Çetinkaya-Rundel e Johanna Hardin.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tidyr, viridis, vcd, janitor)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_exploring_qualitative_data.html#il-dataset-penguins",
    "href": "chapters/eda/03_exploring_qualitative_data.html#il-dataset-penguins",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.1 Il dataset penguins\n",
    "text": "16.1 Il dataset penguins\n\nPer fornire esempi pratici, in questo capitolo utilizzeremo il dataset palmerpenguins, messo a disposizione da Allison Horst. I dati sono stati raccolti e resi disponibili da Dr. Kristen Gorman e dalla Palmer Station, parte del programma di ricerca ecologica a lungo termine Long Term Ecological Research Network. Il dataset contiene informazioni su 344 pinguini, appartenenti a 3 diverse specie, raccolte su 3 isole dell’arcipelago di Palmer, in Antartide. Per semplicità, i dati sono organizzati nel file penguins.csv.\nPossiamo caricare i dati grezzi dal file penguins.csv in un data frame con il seguente comando:\n\nd &lt;- rio::import(here::here(\"data\", \"penguins.csv\"))\n\nEsaminiamo i dati.\n\nglimpse(d)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;chr&gt; \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"A…\n#&gt; $ island            &lt;chr&gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", …\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n#&gt; $ sex               &lt;chr&gt; \"male\", \"female\", \"female\", NA, \"female\", \"male\", \"f…\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\nPer semplicità, rimuoviamo le righe con valori mancanti con la seguente istruzione:\n\ndf &lt;- d |&gt;\n  drop_na()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_exploring_qualitative_data.html#tabelle-di-contingenza",
    "href": "chapters/eda/03_exploring_qualitative_data.html#tabelle-di-contingenza",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.2 Tabelle di contingenza",
    "text": "16.2 Tabelle di contingenza\nUna tabella di contingenza è uno strumento che riassume i dati di due variabili categoriali, cioè variabili qualitative che assumono valori in un numero finito di categorie. Ogni cella della tabella indica quante osservazioni ricadono in una specifica combinazione di categorie delle due variabili.\nPer esempio, supponiamo di avere due variabili del dataset df:\n\n\nisland: l’isola di provenienza dei pinguini,\n\nspecies: la specie di appartenenza (Adelie, Chinstrap, Gentoo).\n\nCon la funzione tabyl() del pacchetto janitor possiamo costruire una tabella che mostra quante osservazioni appartengono a ciascuna combinazione di isola e specie:\n\ndf |&gt; \n  tabyl(island, species) |&gt; \n  adorn_totals(c(\"row\", \"col\")) \n#&gt;     island Adelie Chinstrap Gentoo Total\n#&gt;     Biscoe     44         0    119   163\n#&gt;      Dream     55        68      0   123\n#&gt;  Torgersen     47         0      0    47\n#&gt;      Total    146        68    119   333\n\nLa tabella risultante riporta la distribuzione di tre specie di pinguini (Adelie, Chinstrap, Gentoo) rispetto a tre isole (Biscoe, Dream, Torgersen):\n\n\nIsola Biscoe: sono presenti 44 pinguini Adelie e 119 Gentoo. Nessun esemplare Chinstrap.\n\nIsola Dream: ospita 55 pinguini Adelie e 68 Chinstrap, ma nessun Gentoo.\n\nIsola Torgersen: conta solo 47 pinguini Adelie, senza esemplari delle altre specie.\n\nOsservazioni:\n\nLa specie Adelie è l’unica distribuita su tutte e tre le isole (44 su Biscoe, 55 su Dream, 47 su Torgersen).\nLa specie Chinstrap compare esclusivamente su Dream (68 esemplari).\nLa specie Gentoo si trova soltanto su Biscoe (119 esemplari).\n\nQuesta tabella evidenzia che la distribuzione delle specie non è uniforme: alcune sono presenti solo in determinate isole, mentre altre (come gli Adelie) sono più diffuse. In termini di analisi esplorativa, le tabelle di contingenza permettono quindi di individuare pattern e differenze tra categorie, fornendo una prima descrizione della relazione tra due variabili qualitative.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_exploring_qualitative_data.html#proporzioni-di-riga-e-di-colonna",
    "href": "chapters/eda/03_exploring_qualitative_data.html#proporzioni-di-riga-e-di-colonna",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.3 Proporzioni di riga e di colonna",
    "text": "16.3 Proporzioni di riga e di colonna\nFinora ci siamo concentrati sui conteggi assoluti. Tuttavia, in molti casi è più informativo osservare le proporzioni relative.\n\nLe proporzioni di riga descrivono come si distribuiscono le categorie di una variabile all’interno di ciascun gruppo dell’altra.\nLe proporzioni di colonna, al contrario, mostrano la distribuzione di una variabile rispetto alle categorie dell’altra.\n\nQuesti calcoli si ottengono facilmente a partire dalla tabella di contingenza.\n\n16.3.1 Proporzioni di riga (specie per isola)\n\ndf %&gt;%\n  tabyl(island, species) %&gt;%   # Tabella di contingenza\n  adorn_percentages(\"row\") %&gt;% # Proporzioni rispetto a ciascuna isola\n  adorn_totals(\"col\") %&gt;%      # Totali di riga\n  adorn_pct_formatting(digits = 2)\n#&gt;     island  Adelie Chinstrap Gentoo   Total\n#&gt;     Biscoe  26.99%     0.00% 73.01% 100.00%\n#&gt;      Dream  44.72%    55.28%  0.00% 100.00%\n#&gt;  Torgersen 100.00%     0.00%  0.00% 100.00%\n\nQuesto output mostra, per ogni isola, la percentuale di pinguini appartenenti a ciascuna specie.\n\n16.3.2 Proporzioni di colonna (isole per specie)\n\ndf |&gt; \n  tabyl(island, species) |&gt; \n  adorn_percentages(\"col\") |&gt;  # Proporzioni rispetto a ciascuna specie\n  adorn_totals(\"row\") |&gt; \n  adorn_pct_formatting(digits = 2)\n#&gt;     island  Adelie Chinstrap  Gentoo\n#&gt;     Biscoe  30.14%     0.00% 100.00%\n#&gt;      Dream  37.67%   100.00%   0.00%\n#&gt;  Torgersen  32.19%     0.00%   0.00%\n#&gt;      Total 100.00%   100.00% 100.00%\n\nQui vediamo, per ciascuna specie, su quali isole si distribuiscono i pinguini e con quale proporzione.\nIn sintesi, le proporzioni di riga e colonna forniscono un dettaglio numerico che aiuta a interpretare meglio le relazioni tra le variabili categoriali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_exploring_qualitative_data.html#grafici-a-barre",
    "href": "chapters/eda/03_exploring_qualitative_data.html#grafici-a-barre",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.4 Grafici a barre",
    "text": "16.4 Grafici a barre\nI grafici a barre sono uno degli strumenti più utilizzati per rappresentare visivamente i dati categoriali. Essi consentono di confrontare le frequenze delle categorie in modo immediato, mostrando chiaramente quali valori sono più comuni o più rari nel campione.\n\n16.4.1 Grafico a barre con una variabile\nNel caso più semplice, un grafico a barre rappresenta una sola variabile categoriale. Le categorie sono riportate lungo un asse (di solito l’asse orizzontale) e la lunghezza o altezza delle barre è proporzionale al numero di osservazioni per ciascuna categoria.\nAd esempio, per i dati sui pinguini possiamo visualizzare il numero totale di esemplari osservati in ciascuna isola:\n\nggplot(df, aes(x = island)) +\n  geom_bar() +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") \n\n\n\n\n\n\n\nAllo stesso modo, possiamo costruire un grafico a barre che mostra la distribuzione delle specie:\n\nggplot(df, aes(x = species)) +\n  geom_bar() +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\")\n\n\n\n\n\n\n\nQuesti grafici permettono di confrontare rapidamente le frequenze delle categorie, mettendo in evidenza quali specie o quali isole sono più rappresentate.\n\n16.4.2 Grafico a barre con due variabili\nUn grafico a barre può essere esteso per visualizzare simultaneamente due variabili categoriali. In questo caso, una variabile viene posta sull’asse delle ascisse, mentre la seconda è distinta tramite colori diversi o barre impilate.\nAd esempio, possiamo osservare come le diverse specie di pinguini si distribuiscono sulle isole:\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"stack\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Specie\") \n\n\n\n\n\n\n\nOppure, invertendo i ruoli delle due variabili, possiamo rappresentare le specie sull’asse delle ascisse e distinguere le isole tramite colori:\n\nggplot(df, aes(x = species, fill = island)) +\n  geom_bar(position = \"stack\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Isola\")\n\n\n\n\n\n\n\nQuesti grafici permettono di esplorare visivamente l’associazione tra due variabili qualitative.\n\n16.4.3 Frequenze relative\nOltre alle frequenze assolute, è spesso utile rappresentare le frequenze relative (cioè le proporzioni). Questo approccio elimina l’effetto del numero totale di osservazioni, rendendo più facile confrontare le distribuzioni tra gruppi di dimensioni diverse.\nAd esempio, il grafico seguente mostra la composizione relativa delle specie per ogni isola:\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\") +\n  xlab(\"Isola\") +\n  ylab(\"Proporzione\") +\n  labs(fill = \"Specie\")\n\n\n\n\n\n\n\nQui ogni barra è normalizzata a 1: l’altezza di ciascun segmento rappresenta la proporzione di una specie all’interno dell’isola. In questo modo è più facile capire quale specie prevale in ciascun contesto, indipendentemente dal numero complessivo di pinguini osservati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_exploring_qualitative_data.html#mosaic-plot",
    "href": "chapters/eda/03_exploring_qualitative_data.html#mosaic-plot",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.5 Mosaic plot",
    "text": "16.5 Mosaic plot\nIl Mosaic plot è una tecnica di visualizzazione particolarmente adatta per rappresentare le tabelle di contingenza. A differenza di un semplice grafico a barre impilate, questo tipo di grafico mostra contemporaneamente:\n\nla distribuzione interna delle categorie di una variabile,\nla dimensione relativa complessiva dei gruppi della variabile principale.\n\nIn pratica, non ci dice solo come le categorie si suddividono all’interno dei gruppi, ma anche quanto grandi sono i gruppi stessi.\n\nmosaic(\n  ~ species + island, \n  data = df, \n  main = \"Mosaic Plot of Species and Island\",\n  shade = TRUE\n)\n\n\n\n\n\n\n\nCome leggere un mosaic plot.\n\n\nDimensioni dei rettangoli\n\nLa larghezza rappresenta la dimensione relativa dei gruppi della variabile principale (island).\nL’altezza indica la proporzione delle categorie della variabile secondaria (species) all’interno di ciascun gruppo.\n\n\n\nColori (opzione shade = TRUE)\n\nI colori evidenziano deviazioni dalle frequenze attese in caso di indipendenza statistica.\nUn colore scuro segnala che in quel gruppo la frequenza osservata è molto diversa da quella attesa sotto indipendenza.\n\n\n\nInterpretazione pratica\n\nUn rettangolo largo e alto segnala una categoria numerosa in un gruppo consistente.\nUn rettangolo stretto o sottile indica una categoria rara o assente in quel gruppo.\n\n\n\nIn questo esempio, vediamo chiaramente che:\n\ngli Adelie sono presenti in tutte le isole,\ni Chinstrap compaiono solo a Dream,\ni Gentoo solo a Biscoe.\n\nIl Mosaic plot è quindi utile per cogliere schemi di associazione tra variabili categoriali e valutare rapidamente quali combinazioni sono predominanti o assenti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_exploring_qualitative_data.html#confronto-tra-gruppi",
    "href": "chapters/eda/03_exploring_qualitative_data.html#confronto-tra-gruppi",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.6 Confronto tra gruppi",
    "text": "16.6 Confronto tra gruppi\nUn aspetto centrale dell’analisi esplorativa consiste nel confrontare gruppi diversi. Questo ci permette di mettere in evidenza differenze e somiglianze, osservare variazioni e individuare tendenze. Il confronto può riguardare:\n\n\nvariabili categoriali tra loro (ad esempio distribuzione di genere nelle diverse specie), oppure\n\nvariabili numeriche rispetto a categorie (ad esempio come varia il peso corporeo tra specie e generi).\n\n\n16.6.1 Confronto tra variabili categoriali\nPer confrontare due variabili qualitative, possiamo utilizzare un grafico a barre con suddivisione per gruppi. Ad esempio, vediamo come si distribuisce il genere dei pinguini (maschio/femmina) all’interno delle tre specie:\n\nggplot(df, aes(x = species, fill = sex)) +\n  geom_bar(position = \"dodge\") +\n  xlab(\"Specie\") +\n  ylab(\"Conteggio\")\n\n\n\n\n\n\n\nIn questo grafico le barre affiancate permettono di confrontare facilmente, per ciascuna specie, il numero di maschi e femmine.\n\n16.6.2 Confronto tra variabili numeriche e categorie\nSpesso è ancora più interessante osservare come una variabile numerica varia tra gruppi. Questo approccio ci consente di capire se gruppi diversi tendono ad avere valori simili o differenti. Prendiamo come esempio la variabile body_mass_g (peso corporeo in grammi), e confrontiamola in base a specie e genere.\n\nggplot(df, aes(x = species, y = body_mass_g, fill = sex)) +\n  geom_violin(\n    position = position_dodge(width = 0.9), alpha = 0.5\n  ) +\n  geom_boxplot(\n    position = position_dodge(width = 0.9), width = 0.2, alpha = 0.8\n  ) +\n  xlab(\"Specie\") +\n  ylab(\"Massa corporea (g)\") +\n  labs(fill = \"Genere\")\n\n\n\n\n\n\n\nQuesto grafico combina due livelli di informazione:\n\n\nGrafico a violino (aree colorate)\n\nMostra l’intera distribuzione dei pesi per ciascun gruppo (specie × genere).\nPiù l’area è larga in un punto, più pinguini hanno un peso vicino a quel valore.\n\n\n\nBoxplot (linee centrali)\n\nRiassume visivamente i dati, mostrando mediana, quartili e variabilità.\nAiuta a confrontare rapidamente i livelli tipici e la dispersione tra gruppi.\n\n\n\nDa questo tipo di grafico possiamo osservare:\n\n\nDifferenze tra generi all’interno di una specie: ad esempio, se i maschi tendono a essere più pesanti delle femmine.\n\nDifferenze tra specie: quali specie hanno in generale pinguini più pesanti o più leggeri.\n\nSovrapposizioni: se i pesi di maschi e femmine si distinguono nettamente o se i due gruppi hanno valori simili.\n\nIn questo modo, possiamo individuare sia differenze sistematiche sia aree di variabilità comune tra i gruppi.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nIn questo esercizio analizzerai i dati qualitativi raccolti mediante la scala SWLS, concentrandoti su due variabili categoriali:\n\n\nGenere (gender): maschio / femmina.\n\nTipo di scuola superiore (school_type): liceo classico o scientifico vs tutto il resto.\n\nDovrai creare tabelle di contingenza e rappresentazioni grafiche per esplorare le relazioni tra queste variabili.\nImportazione dei dati\nImporta i dati da un file CSV e visualizza la loro struttura.\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(here)\n\n# Importa i dati\nswls_data &lt;- read_csv(here(\"data\", \"swls_students.csv\"))\n\n# Esamina i dati\nglimpse(swls_data)\nTabelle di Contingenza\n\nCrea una tabella di contingenza tra gender e school_type.\nCalcola le proporzioni di riga e colonna.\n\n# Tabella di contingenza\nswls_data |&gt; \n  tabyl(gender, school_type) |&gt; \n  adorn_totals(c(\"row\", \"col\"))\nCalcola ora le proporzioni relative.\n# Proporzioni di riga\nswls_data |&gt; \n  tabyl(gender, school_type) |&gt; \n  adorn_percentages(\"row\") |&gt; \n  adorn_pct_formatting(digits = 2)\n# Proporzioni di colonna\nswls_data |&gt; \n  tabyl(gender, school_type) |&gt; \n  adorn_percentages(\"col\") |&gt; \n  adorn_pct_formatting(digits = 2)\nVisualizzazione Grafica\n\nCrea un grafico a barre per visualizzare il numero di studenti per tipo di scuola.\nCrea un grafico a barre per la distribuzione del genere per tipo di scuola.\n\nggplot(swls_data, aes(x = school_type)) +\n  geom_bar() +\n  ggtitle(\"Numero di studenti per tipo di scuola\") +\n  xlab(\"Tipo di scuola\") +\n  ylab(\"Numero di studenti\")\nggplot(swls_data, aes(x = school_type, fill = gender)) +\n  geom_bar(position = \"dodge\") +\n  ggtitle(\"Distribuzione del genere per tipo di scuola\") +\n  xlab(\"Tipo di scuola\") +\n  ylab(\"Numero di studenti\") +\n  labs(fill = \"Genere\")\nDomande per la riflessione\n\nQuale tipo di scuola ha il maggior numero di studenti?\nCi sono differenze nella distribuzione del genere tra i tipi di scuola?\n\nConsegna\n\nCompila il file .qmd con il tuo codice e commenti.\nEsporta il documento in formato HTML o PDF.\nCarica il file su Moodle.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] vcd_1.4-13            viridis_0.6.5         viridisLite_0.4.2    \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        rmarkdown_2.29        ragg_1.5.0           \n#&gt; [19] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [22] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [25] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [28] lmtest_0.9-40         lubridate_1.9.4       estimability_1.5.1   \n#&gt; [31] knitr_1.50            zoo_1.8-14            R.utils_2.13.0       \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [64] mvtnorm_1.3-3         QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [67] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [70] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [73] gtable_0.3.6          R.methodsS3_1.8.2     digest_0.6.37        \n#&gt; [76] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [79] R.oo_1.27.1           memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [82] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_exploring_qualitative_data.html#bibliografia",
    "href": "chapters/eda/03_exploring_qualitative_data.html#bibliografia",
    "title": "16  Esplorare i dati qualitativi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nTukey, J. W. et al. (1977). Exploratory data analysis (Vol. 2). Springer.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_numeric_data.html",
    "href": "chapters/eda/04_exploring_numeric_data.html",
    "title": "17  Esplorare i dati numerici",
    "section": "",
    "text": "Introduzione\nIn questo capitolo ci concentreremo sull’analisi dei dati numerici. In particolare, esamineremo le distribuzioni di frequenza e i quantili, insieme alle tecniche di visualizzazione più comuni, come l’istogramma, l’istogramma smussato e il box-plot. Tratteremo sia gli aspetti computazionali che quelli interpretativi di queste misure, fornendo strumenti utili non solo per una comprensione personale, ma anche per la comunicazione efficace dei risultati, in particolare con chi utilizza questi dati per prendere decisioni pratiche nel mondo reale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_numeric_data.html#introduzione",
    "href": "chapters/eda/04_exploring_numeric_data.html#introduzione",
    "title": "17  Esplorare i dati numerici",
    "section": "",
    "text": "Panoramica del capitolo\n\ncostruire e interpretare distribuzioni di frequenza e cumulative;\n\ncomprendere e confrontare istogrammi e stime di densità kernel;\n\nutilizzare boxplot e violin plot per individuare differenze tra gruppi;\n\nriconoscere la forma di una distribuzione e i suoi indici di posizione;\n\ncomunicare i risultati con grafici chiari ed efficaci.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere l’Appendice Appendice F prima di procedere con la lettura di questo capitolo.\nLeggere il capitolo Exploring numerical data di Introduction to Modern Statistics (2e) di Mine Çetinkaya-Rundel e Johanna Hardin.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(ggbeeswarm, dslabs, gridExtra, ggpubr, cowplot, viridis)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_numeric_data.html#le-aspettative-negative-nella-depressione",
    "href": "chapters/eda/04_exploring_numeric_data.html#le-aspettative-negative-nella-depressione",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.1 Le aspettative negative nella depressione",
    "text": "17.1 Le aspettative negative nella depressione\nConsideriamo i dati relativi alle aspettative negative, individuate come un meccanismo chiave nel mantenimento della depressione (Zetsche et al., 2019). Supponiamo di voler analizzare la distribuzione di una singola variabile quantitativa.\nImportiamo i dati:\n\ndf &lt;- rio::import(here::here(\"data\", \"data.mood.csv\"))\n\n\n17.1.1 Data Wrangling\nPer questo esercizio, ci concentreremo sulle variabili esm_id (il codice del soggetto), group (il gruppo) e bdi (il valore BDI-II).\n\ndf &lt;- df |&gt; \n  dplyr::select(\"esm_id\", \"group\", \"bdi\")\ndf |&gt; \n  head()\n#&gt;   esm_id group bdi\n#&gt; 1     10   mdd  25\n#&gt; 2     10   mdd  25\n#&gt; 3     10   mdd  25\n#&gt; 4     10   mdd  25\n#&gt; 5     10   mdd  25\n#&gt; 6     10   mdd  25\n\nSe elenchiamo le modalità presenti in group utilizzando il metodo unique(), scopriamo che corrispondono a mdd (pazienti) e ctl (controlli sani).\n\ndf$group |&gt; \n  unique()\n#&gt; [1] \"mdd\" \"ctl\"\n\nRimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:\n\ndf &lt;- df[!duplicated(df), ]\n\nVerifichiamo di avere ottenuto il risultato desiderato.\n\ndim(df)\n#&gt; [1] 67  3\n\n\nhead(df)\n#&gt;    esm_id group bdi\n#&gt; 1      10   mdd  25\n#&gt; 15      9   mdd  30\n#&gt; 30      6   mdd  26\n#&gt; 46      7   mdd  35\n#&gt; 65     12   mdd  44\n#&gt; 83     16   mdd  30\n\nSi noti che il nuovo DataFrame (con 67 righe) conserva il “nome” delle righe (ovvero, l’indice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga è 15. Questo non ha nessuna conseguenza perché non useremo l’indice di riga nelle analisi seguenti.\nEliminiamo eventuali valori mancanti:\n\ndf &lt;- df[!is.na(df$bdi), ]\n\nOtteniamo così il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):\n\ndim(df)\n#&gt; [1] 66  3\n\n\n17.1.2 Anteprima dei dati\nPrima di approfondire l’analisi, è fondamentale esaminare una anteprima dei dati per comprenderne struttura, formati e potenziali anomalie.\nLa funzione glimpse() fornisce una panoramica compatta del dataset: numero di righe/colonne, tipo di variabili (es. chr, num, dbl) ed esempi di valori. Utile per identificare rapidamente formati errati o colonne non attese:\n\nglimpse(df)  \n#&gt; Rows: 66\n#&gt; Columns: 3\n#&gt; $ esm_id &lt;int&gt; 10, 9, 6, 7, 12, 16, 21, 18, 20, 22, 23, 25, 24, 26, 41, 31, 27…\n#&gt; $ group  &lt;chr&gt; \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", …\n#&gt; $ bdi    &lt;int&gt; 25, 30, 26, 35, 44, 30, 22, 33, 43, 43, 24, 39, 19, 3, 0, 25, 0…\n\nLa funzione summary() genera statistiche descrittive per ogni colonna:\n\nper variabili numeriche: media, mediana, quartili, min/max;\nper variabili categoriche: frequenza dei livelli;\nsegnala valori mancanti (NA), aiutando a valutare la qualità dei dati.\n\n\nsummary(df)  \n#&gt;      esm_id         group                bdi       \n#&gt;  Min.   :  6.0   Length:66          Min.   : 0.00  \n#&gt;  1st Qu.: 30.2   Class :character   1st Qu.: 0.25  \n#&gt;  Median : 46.5   Mode  :character   Median : 6.00  \n#&gt;  Mean   : 51.6                      Mean   :14.94  \n#&gt;  3rd Qu.: 76.8                      3rd Qu.:29.50  \n#&gt;  Max.   :104.0                      Max.   :44.00\n\nI comandi head() e tail() ci permettono di visualizzare le prime o le ultime righe di un dataset:\n\nhead(df)\n#&gt;    esm_id group bdi\n#&gt; 1      10   mdd  25\n#&gt; 15      9   mdd  30\n#&gt; 30      6   mdd  26\n#&gt; 46      7   mdd  35\n#&gt; 65     12   mdd  44\n#&gt; 83     16   mdd  30\n\n\ntail(df)\n#&gt;      esm_id group bdi\n#&gt; 1087    101   ctl   9\n#&gt; 1105     99   ctl   0\n#&gt; 1121    100   ctl   2\n#&gt; 1133    104   ctl   0\n#&gt; 1152    103   ctl   0\n#&gt; 1171    102   ctl   1\n\n\n17.1.3 Conversione da char a factor\n\nIn R, i tipi di dato character e factor rappresentano informazioni testuali, ma hanno utilizzi distinti:\n\n\ncharacter: è una semplice stringa di testo;\n\nfactor: è una variabile categoriale, ideale per rappresentare dati con un numero finito di categorie (livelli). I dati in formato factor sono utili per analisi statistiche, poiché trattano i valori come categorie discrete.\n\nNel seguente esempio, convertiamo una variabile group da character a factor, in modo da poterla utilizzare come variabile categoriale:\n\ndf$group &lt;- as.factor(df$group)  # Converte 'group' in un factor\n\nSuccessivamente, il comando summary() fornisce un riepilogo della variabile categoriale, mostrando il conteggio dei valori per ciascun livello:\n\nsummary(df$group)\n#&gt; ctl mdd \n#&gt;  36  30",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "href": "chapters/eda/04_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.2 Distribuzioni di frequenza",
    "text": "17.2 Distribuzioni di frequenza\nLe distribuzioni di frequenza sono strumenti essenziali per visualizzare e comprendere la variabilità di una variabile. In questo capitolo verrà illustrato come costruire una distribuzione di frequenza e, successivamente, come generare in R una distribuzione cumulativa empirica, un istogramma, un Kernel Density Plot e un boxplot.\nA titolo esemplificativo, consideriamo i punteggi del BDI-II. Iniziamo ordinando i dati in ordine crescente:\n\ndf$bdi |&gt; sort()\n#&gt;  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1\n#&gt; [26]  2  2  2  2  3  3  3  5  7  9 12 19 22 22 24 25 25 26 26 26 27 27 28 28 30\n#&gt; [51] 30 30 31 31 33 33 34 35 35 35 36 39 41 43 43 44\n\nUna distribuzione di frequenza evidenzia quante volte i valori di una variabile ricorrono in determinati intervalli. Ad esempio, per i punteggi del BDI-II è consuetudine raggruppare i dati nelle seguenti classi:\n\n0–13: depressione minima;\n14–19: depressione lieve-moderata;\n20–28: depressione moderata-severa;\n29–63: depressione severa.\n\nDefinendo ciascuna classe, indicata con \\(\\Delta_i\\), come un intervallo \\([a_i, b_i)\\) o \\((a_i, b_i]\\), possiamo calcolare le seguenti misure:\n\n\nFrequenza assoluta (\\(n_i\\)): numero di osservazioni in \\(\\Delta_i\\). La somma delle frequenze assolute corrisponde al totale delle osservazioni, \\(n\\).\n\nFrequenza relativa (\\(f_i\\)): proporzione di osservazioni in \\(\\Delta_i\\), calcolata come \\(f_i = n_i/n\\); la somma delle frequenze relative è pari a 1.\n\nFrequenza cumulata (\\(N_i\\)): somma delle frequenze assolute fino alla classe \\(i\\), ovvero \\(N_i = \\sum_{j=1}^i n_j\\).\n\nFrequenza cumulata relativa (\\(F_i\\)): somma delle frequenze relative fino alla classe \\(i\\), data da \\(F_i = \\sum_{j=1}^i f_j\\).\n\nQueste misure consentono di sintetizzare la distribuzione dei punteggi, facilitando l’interpretazione delle caratteristiche del campione.\n\n17.2.1 Frequenze assolute e relative\nPer analizzare la distribuzione dei punteggi BDI-II nel dataset di Zetsche et al. (2019), è utile creare una variabile categoriale che classifichi ogni osservazione in una delle quattro classi di gravità della depressione. A tal fine, utilizziamo la funzione cut(), che permette di suddividere il vettore dei punteggi (bdi) in intervalli definiti.\nNel comando seguente, il parametro breaks specifica i limiti degli intervalli, mentre include.lowest = TRUE garantisce che il valore minimo sia incluso nel primo intervallo:\n\n# Creazione della variabile categoriale per i livelli di depressione\ndf &lt;- df %&gt;% \n  mutate(\n    bdi_class = cut(\n      bdi, \n      breaks = c(0, 13.5, 19.5, 28.5, 63),\n      include.lowest = TRUE\n    )\n  )\n\nI punteggi vengono suddivisi nelle seguenti classi:\n\n0–13: depressione minima;\n14–19: depressione lieve-moderata;\n20–28: depressione moderata-;\n29–63: depressione severa.\n\nUna volta creata la variabile bdi_class, possiamo calcolare le frequenze assolute e relative.\n\n17.2.1.1 Frequenze assolute\nUtilizzando la funzione table(), si ottiene il numero di osservazioni in ciascuna classe:\n\ntable(df$bdi_class)\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;          36           1          12          17\n\n\n17.2.1.2 Frequenze relative\nCon prop.table() è possibile determinare la proporzione di osservazioni per ogni classe:\n\nprop.table(table(df$bdi_class))\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;      0.5455      0.0152      0.1818      0.2576\n\n\n17.2.2 Distribuzioni congiunte\nLe distribuzioni congiunte di frequenze permettono di analizzare la relazione tra due variabili, considerando tutte le possibili combinazioni dei loro valori. Ad esempio, se analizziamo le variabili bdi_class e group, la tabella congiunta mostrerà la frequenza (assoluta o relativa) per ogni coppia di valori.\nPer ottenere la distribuzione congiunta relativa, utilizziamo:\n\nprop.table(table(df$bdi_class, df$group))\n#&gt;              \n#&gt;                  ctl    mdd\n#&gt;   [0,13.5]    0.5455 0.0000\n#&gt;   (13.5,19.5] 0.0000 0.0152\n#&gt;   (19.5,28.5] 0.0000 0.1818\n#&gt;   (28.5,63]   0.0000 0.2576\n\nIn questo modo, possiamo esaminare come le classi di punteggi BDI-II si distribuiscono all’interno dei diversi gruppi, con la somma complessiva delle frequenze relative pari a 1.\n\n17.2.3 La distribuzione cumulativa empirica\nLa distribuzione cumulativa empirica (eCDF, empirical Cumulative Distribution Function) è un modo utile per rappresentare la distribuzione di dati numerici. Questa funzione indica la proporzione di dati che sono inferiori o uguali a un certo valore \\(a\\), per tutti i possibili valori di \\(a\\). Matematicamente, la eCDF è definita come:\n\\[\nF(a) = \\text{Proporzione dei dati con valore} \\leq a.\n\\]\nIn altre parole, la eCDF ci dice quale frazione dei dati osservati è minore o uguale a un determinato valore \\(a\\). Questo è particolarmente utile per comprendere come i dati sono distribuiti e per identificare pattern o caratteristiche specifiche della distribuzione, come la presenza di bimodalità (cioè, due picchi distinti nella distribuzione).\n\n17.2.3.1 Esempio con i dati di Zetsche et al. (2019)\n\nNel contesto dei dati di Zetsche et al. (2019), possiamo utilizzare la eCDF per visualizzare la distribuzione dei punteggi BDI-II. Ecco come viene rappresentata la eCDF per l’intero dataset:\n\ndf |&gt; \n  ggplot(aes(bdi)) + \n  stat_ecdf() +\n  labs(x = \"BDI\", y = \"F(BDI)\")\n\n\n\n\n\n\n\nIn questo grafico:\n\nl’asse \\(x\\) rappresenta i valori del BDI-II,\nl’asse \\(y\\) rappresenta la proporzione cumulativa dei dati, cioè \\(F(a)\\).\n\n17.2.3.2 Interpretazione del grafico\n\n\nCrescita della curva: La curva della eCDF parte da 0 (nessun dato è inferiore al valore minimo osservato) e cresce gradualmente fino a 1 (tutti i dati sono inferiori o uguali al valore massimo osservato).\n\nBimodalità: Se la curva presenta dei “gradini” o delle aree con una pendenza più ripida, questo può indicare la presenza di bimodalità, ovvero due gruppi distinti di dati con caratteristiche diverse. Nel caso dei dati BDI-II, la bimodalità potrebbe riflettere la presenza di due sottogruppi di partecipanti con livelli di depressione diversi.\n\n17.2.3.3 Filtrare i dati per il campione clinico\nSe vogliamo analizzare solo i dati relativi al campione clinico (ad esempio, i pazienti con depressione maggiore), possiamo filtrare i dati e rappresentare la eCDF solo per questo gruppo:\n\ndf |&gt; dplyr::filter(group == \"mdd\") |&gt; \n  ggplot(aes(bdi)) + \n  stat_ecdf() +\n  labs(x = \"a\", y = \"F(a)\")\n\n\n\n\n\n\n\nIn questo caso, la eCDF ci mostrerà come i punteggi BDI-II sono distribuiti tra i pazienti con depressione maggiore, permettendoci di identificare eventuali pattern specifici per questo gruppo.\nIn sintesi, la eCDF è uno strumento potente per analizzare e visualizzare la distribuzione di dati numerici, specialmente quando si vogliono identificare pattern specifici o confrontare distribuzioni tra diversi gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_numeric_data.html#istogramma",
    "href": "chapters/eda/04_exploring_numeric_data.html#istogramma",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.3 Istogramma",
    "text": "17.3 Istogramma\nSebbene il concetto di Funzione di Distribuzione Empirica Cumulativa (eCDF) venga ampiamente discusso nei testi di statistica, in pratica tale rappresentazione non è molto diffusa. Il motivo principale è che l’eCDF non rende immediatamente visibili alcune caratteristiche fondamentali della distribuzione, come il valore intorno al quale essa è centrata, se la distribuzione sia simmetrica o quali intervalli contengano il 95% dei dati, ad esempio. Gli istogrammi, invece, sono molto più utilizzati perché facilitano notevolmente la comprensione di queste proprietà, sacrificando solo un po’ di informazione per fornire una rappresentazione più intuitiva.\nUn istogramma è un grafico che rappresenta la distribuzione delle frequenze di una variabile. Sull’asse orizzontale (ascisse) vengono indicati i limiti delle classi \\(\\Delta_i\\), mentre sull’asse verticale (ordinate) si riporta la densità della frequenza relativa della variabile \\(X\\) per ciascuna classe \\(\\Delta_i\\).\nPer descrivere formalmente la densità della frequenza relativa, si utilizza una funzione costante a tratti definita come:\n\\[\n\\varphi_n(x) = \\frac{f_i}{b_i - a_i},\n\\]\ndove:\n\n\n\\(f_i\\) è la frequenza relativa della classe \\(\\Delta_i\\),\n\n\\(b_i - a_i\\) è l’ampiezza della classe \\(\\Delta_i\\).\n\nIn questo modo, l’area del rettangolo corrispondente a \\(\\Delta_i\\) in un istogramma risulta proporzionale alla frequenza relativa \\(f_i\\). Poiché la somma delle frequenze relative deve essere pari a 1, l’area totale di un istogramma delle frequenze relative risulta anch’essa uguale a 1, corrispondendo alla somma delle aree di tutti i rettangoli.\nGli istogrammi costituiscono quindi uno strumento essenziale per visualizzare e comprendere le principali caratteristiche di una distribuzione, agevolando l’analisi della sua forma, della sua tendenza centrale e della sua dispersione.\nPer fare un esempio, costruiamo un istogramma per i valori BDI-II di Zetsche et al. (2019). Con i quattro intervalli individuati dai cut-off del BDI-II creiamo una prima versione dell’istogramma – si notino le frequenze assolute sull’asse delle ordinate.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    breaks = c(0, 13.5, 19.5, 28.5, 63),\n    aes(y = after_stat(density)),  # oppure after_stat(count / sum(count))\n    linewidth = 0.5\n  ) +\n  labs(\n    x = \"BDI-II\", \n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\nAnche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un’ampiezza uguale.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    aes(y = after_stat(density))\n  ) +\n  labs(\n    x = \"BDI-II\", \n    y = \"Densità\"\n  )",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_numeric_data.html#kernel-density-plot",
    "href": "chapters/eda/04_exploring_numeric_data.html#kernel-density-plot",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.4 Kernel Density Plot",
    "text": "17.4 Kernel Density Plot\nUn limite evidente degli istogrammi è che la loro forma dipende da scelte arbitrarie: il numero e l’ampiezza delle classi (o bin) può infatti influenzare in modo sostanziale l’aspetto finale del grafico, rendendo più difficile l’interpretazione della distribuzione dei dati. Una soluzione a questo problema è offerta dalla stima della densità kernel (Kernel Density Estimation, KDE), un metodo che fornisce un profilo continuo e smussato della distribuzione, meno condizionato dall’arbitrarietà delle classi.\n\n17.4.1 Differenza tra istogramma e KDE\nNell’istogramma, dividiamo l’asse orizzontale in intervalli di ampiezza prefissata (i bin) e costruiamo rettangoli la cui altezza è proporzionale alla frequenza (o densità) dei dati che ricadono in ciascun intervallo. Se cambiamo il numero o la larghezza dei bin, la forma dell’istogramma può variare sensibilmente.\nLa KDE, invece, non suddivide i dati in intervalli fissi. Al contrario, “appoggia” una piccola curva (il kernel) su ogni singola osservazione. Le curve utilizzate (ad esempio di tipo gaussiano) hanno una larghezza, detta bandwidth, che controlla il grado di smussamento: con un bandwidth molto piccolo, la stima segue da vicino le singole osservazioni, generando un profilo più frastagliato; con un bandwidth più ampio, la curva risultante è più liscia, ma rischia di nascondere dettagli importanti.\nPer comprendere in modo intuitivo il concetto di KDE, possiamo partire da un esempio semplice. Immaginiamo di costruire un istogramma con classi di ampiezza sempre più piccola. Se avessimo a disposizione un numero enorme di dati (ad esempio, un milione di misurazioni dell’altezza di individui) e li rappresentassimo con bin sempre più stretti (0.1, 0.01, ecc.), l’istogramma diventerebbe sempre più levigato, avvicinandosi a una curva continua. Questo processo illustra l’idea alla base della KDE, che approssima la distribuzione dei dati in modo fluido e continuo.\nLa KDE, tuttavia, opera in modo più elegante e senza richiedere un numero enorme di punti: posiziona un piccolo “dosso di campana” (o un altro tipo di kernel) su ciascun punto dati e somma tutte queste curve in un’unica curva finale.\n\n\n\n\n\n\nChe cosa vuol dire “dosso di campana”?\n\n\n\nPossiamo immaginarlo come una piccola curva gaussiana: una curva simile alla forma di una campana che si innalza e poi discende dolcemente.\n\nOgni singolo dato viene “coperto” da questa mini-campana.\nL’ampiezza (o “larghezza”) della campana è regolata dal bandwidth, che stabilisce se la curva sarà più o meno “distesa” sul grafico.\nSommando tutte le piccole campane (una per ogni osservazione), otteniamo una curva di densità liscia e continua che rappresenta la distribuzione dei dati senza i “salti” tipici dell’istogramma.\n\n\n\nIl risultato è una curva di densità che:\n\n\nÈ continua: a differenza degli istogrammi, non presenta bruschi salti di altezza tra i bin: la curva scorre in modo uniforme lungo tutto l’asse orizzontale.\n\nMostra la proporzione di dati in ogni intervallo: l’area sotto la curva in un determinato range corrisponde alla percentuale (o probabilità) di dati che cadono in quell’intervallo.\n\nDipende dal bandwidth:\n\nUn bandwidth piccolo produce una curva più ondulata e “frastagliata” (poiché segue da vicino ogni singolo dato).\nUn bandwidth grande genera una curva più liscia e arrotondata, ma rischia di “coprire” troppi dettagli della distribuzione originaria.\n\n\n\nSi noti che la stima della densità kernel introduce, tuttavia, un’ipotesi di fondo: che la distribuzione dei dati “reali” sia “liscia” e non presenti discontinuità improvvise. Questo è spesso ragionevole (ad esempio per dati fisiologici come l’altezza), ma in altri casi potrebbe non esserlo. È quindi importante scegliere un bandwidth che rifletta adeguatamente il livello di dettaglio che vogliamo mostrare.\nInoltre, l’asse delle ordinate (l’asse y) rappresenta la densità, non la frequenza assoluta. È possibile costruire un istogramma in cui l’altezza dei rettangoli mostra quante osservazioni ricadono in ciascun bin. Nella KDE, l’altezza della curva è tale che l’area totale sotto di essa sia pari a 1, rispecchiando la natura di una funzione di densità di probabilità.\nDi seguito esaminiamo un esempio che mostra la costruzione passo dopo passo di istogrammi con diversi valori di binwidth, fino a passare a una stima di densità. Consideriemo un dataset con un numero di osservazioni molto elevato (i valori di altezza, heights, riportati da 1050 partecipanti, estratti dal pacchetto dslabs), suddiviso in due gruppi: maschi e femmine. Ecco come potremmo prima costruire un istogramma di altezze per i maschi, per poi tracciare una curva di densità smussata:\n\n# Istogramma con bin di ampiezza 1\nggplot(heights |&gt; dplyr::filter(sex == \"Male\"), aes(height)) +\n  geom_histogram(\n    binwidth = 1\n  )\n\n\n\n\n\n\n\n\n# Aggiunta della curva di densità sopra l'istogramma\nggplot(heights |&gt; dplyr::filter(sex == \"Male\"), aes(height)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    binwidth = 1\n  ) +\n  geom_line(stat = 'density')\n\n\n\n\n\n\n\nVariando il parametro di regolazione (adjust o bandwidth) nella funzione geom_density(), possiamo modificare il livello di smussamento:\n\n# Istogramma base con alpha e colore coerente\np &lt;- ggplot(heights |&gt; filter(sex == \"Male\"), aes(x = height)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    binwidth = 1\n  ) +\n  labs(\n    x = \"Altezza\",\n    y = \"Densità\"\n  )\n\n# Più ondulato (banda piccola)\np1 &lt;- p +\n  geom_line(stat = \"density\", adjust = 0.5) +\n  labs(subtitle = \"Smoothing accentuato (adjust = 0.5)\")\n\n# Più liscio (banda larga)\np2 &lt;- p +\n  geom_line(stat = \"density\", adjust = 2) +\n  labs(subtitle = \"Smoothing attenuato (adjust = 2)\")\n\n\np1\n\n\n\n\n\n\n\n\np2\n\n\n\n\n\n\n\nPer illustrare ulteriormente l’uso della KDE, ora consideriamo i punteggi BDI-II di Zetsche et al. (2019). Con il codice seguente creiamo due curve di densità, una per ogni gruppo:\n\nggplot(df, aes(x = bdi, fill = group)) +\n  geom_density() +\n  labs(\n    x = \"BDI-II\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nQui, la sovrapposizione delle due curve ci consente di confrontare la distribuzione dei punteggi BDI-II tra i due gruppi in maniera molto più fluida e intuitiva rispetto a quanto faremmo con due istogrammi separati o con un istogramma combinato. Inoltre, non siamo più vincolati alla scelta dei bin: l’aspetto delle curve dipende soltanto dalla funzione kernel utilizzata e dal parametro di smussamento.\nIn conclusione,\n\nl’istogramma rimane uno strumento rapido e intuitivo, privo di assunzioni, ma sensibile alla scelta di numero e ampiezza dei bin;\nla stima della densità kernel (KDE) offre una rappresentazione continua della distribuzione dei dati, fornendo un quadro più “morbido” e spesso più informativo. Tuttavia, introduce alcune assunzioni e richiede la scelta del bandwidth ottimale.\n\nIn definitiva, è consigliabile usare entrambe le tecniche per ottenere una panoramica completa dei propri dati: l’istogramma permette di dare un primo sguardo alla loro distribuzione “grezza” (senza presupposti), mentre la KDE aiuta a comprenderne l’eventuale struttura “liscia” di fondo.\n\n17.4.2 Area sottesa alla curva di densità: un’interpretazione probabilistica\nQuando si lavora con una curva di densità, è importante capire che l’area totale sotto la curva rappresenta la probabilità totale, che è sempre pari a 1 (o 100%). Questo significa che l’area sotto la curva in un determinato intervallo corrisponde alla probabilità che un dato valore cada in quell’intervallo.\n\n17.4.2.1 Come interpretare l’asse Y\nL’asse y di un grafico di densità non rappresenta direttamente la probabilità, ma è scalato in modo che l’area totale sotto la curva sia uguale a 1. Se immaginiamo di creare un “bin” (un intervallo) con una base di 1 unità di lunghezza, il valore sull’asse y ci indica la proporzione di valori che cadono in quel bin. Tuttavia, questa interpretazione è valida solo per bin di dimensione 1. Per intervalli di altre dimensioni, il modo migliore per determinare la proporzione di dati in quell’intervallo è calcolare la proporzione dell’area totale sotto la curva che cade in quell’intervallo.\n\n17.4.2.2 Esempio pratico\nConsideriamo un esempio con i dati delle altezze degli uomini. Supponiamo di voler sapere quale proporzione di uomini ha un’altezza compresa tra 65 e 68 pollici. Per farlo, calcoliamo l’area sotto la curva di densità in quell’intervallo.\nEcco come appare graficamente:\n\n\n\n\n\n\n\n\nL’area evidenziata in azzurro rappresenta la proporzione di uomini con altezza tra 65 e 68 pollici. Calcolando questa area, troviamo che circa il 0.3 (ovvero il 30% degli uomini ha un’altezza in questo intervallo.\n\n17.4.2.3 Utilizzo della curva di densità come riepilogo\nComprendendo questo concetto, possiamo utilizzare la curva di densità come un efficace strumento di riepilogo. Per questo dataset, l’assunzione di smoothness (lisciatura) della curva è ragionevole, e possiamo condividere questa rappresentazione grafica per comunicare in modo chiaro e intuitivo la distribuzione delle altezze degli uomini.\nEcco un esempio di come appare la curva di densità smooth per le altezze degli uomini:\n\n\n\n\n\n\n\n\nIn sintesi, l’area sotto la curva di densità in un determinato intervallo rappresenta la probabilità che un valore casuale cada in quell’intervallo, rendendo la curva di densità uno strumento potente per comprendere e comunicare la distribuzione dei dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_numeric_data.html#forma-di-una-distribuzione",
    "href": "chapters/eda/04_exploring_numeric_data.html#forma-di-una-distribuzione",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.5 Forma di una distribuzione",
    "text": "17.5 Forma di una distribuzione\nIn statistica, la forma di una distribuzione descrive come i dati sono distribuiti intorno ai valori centrali. Si distingue tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali e multimodali. Un’illustrazione grafica è fornita nella figura seguente. Nel pannello 1, la distribuzione è unimodale con asimmetria negativa; nel pannello 2, la distribuzione è unimodale con asimmetria positiva; nel pannello 3, la distribuzione è simmetrica e unimodale; nel pannello 4, la distribuzione è bimodale.\n\n\nDistribuzioni\n\nIl grafico della densità di kernel (Kernel Density Plot) dei valori BDI-II nel campione di Zetsche et al. (2019) è bimodale. Questo indica che le osservazioni della distribuzione si raggruppano in due cluster distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l’altro gruppo tende ad avere valori BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_numeric_data.html#indici-di-posizione",
    "href": "chapters/eda/04_exploring_numeric_data.html#indici-di-posizione",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.6 Indici di posizione",
    "text": "17.6 Indici di posizione\n\n17.6.1 Quantili\nLa distribuzione dei valori BDI-II di Zetsche et al. (2019) può essere sintetizzata attraverso l’uso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, \\(q_1\\), divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, \\(q_2\\), corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.\nInoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.\nPer calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di \\(np\\), dove \\(n\\) è la dimensione del campione e \\(p\\) è l’ordine del quantile. Se \\(np\\) non è un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\). Se \\(np\\) è un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(k\\) e \\(k+1\\), dove \\(k\\) è la parte intera di \\(np\\).\nGli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che è molto popolare e può essere utilizzata in alternativa ad un istogramma.\nAd esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di Zetsche et al. (2019), si determina il valore di \\(np = 9 \\cdot 0.5 = 4.5\\), che non è un intero. Pertanto, il valore del secondo quartile è pari al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\), ovvero \\(q_2 = x_{4 + 1} = 27\\). Per calcolare il quantile di ordine \\(2/3\\), si determina il valore di \\(np = 9 \\cdot 2/3 = 6\\), che è un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(6\\) e \\(7\\), ovvero \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\nUsiamo quantile() per trovare la soluzione dell’esercizio precedente.\n\nx = c(19, 26, 27, 28, 28, 33, 33, 41, 43)\nquantile(x, 2 / 3)\n#&gt; 66.66667% \n#&gt;        33",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_numeric_data.html#mostrare-i-dati",
    "href": "chapters/eda/04_exploring_numeric_data.html#mostrare-i-dati",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.7 Mostrare i dati",
    "text": "17.7 Mostrare i dati\n\n17.7.1 Diagramma a scatola\nIl box plot è uno strumento grafico che visualizza la dispersione di una distribuzione. I boxplot forniscono una rappresentazione visiva sintetica di cinque valori caratteristici: minimo, primo quartile (25%), mediana (50%), terzo quartile (75%) e massimo. Spesso però, i boxplot “ignorano” i valori considerati anomali (outlier), segnalandoli con punti isolati.\nPer creare un box plot, si disegna un rettangolo (la “scatola”) di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile (\\(q_{0.75}\\)) e il primo quartile (\\(q_{0.25}\\)). La mediana (\\(q_{0.5}\\)) è rappresentata da una linea all’interno del rettangolo.\nAi lati della scatola, vengono tracciati due segmenti di retta, detti “baffi”, che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore è il valore più basso tra le osservazioni che è maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore è il valore più alto tra le osservazioni che è minore o uguale al terzo quartile più 1.5 volte la distanza interquartile.\nSe ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati “valori anomali” e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.\n\n\n17.7.2 Stratificazione\nNell’analisi dei dati, è comune suddividere le osservazioni in gruppi in base ai valori di una o più variabili associate a tali osservazioni. Questo processo è chiamato stratificazione, e i gruppi risultanti sono detti strati. Ad esempio, nella sezione successiva, dividiamo i valori dei punteggi BDI-II in due gruppi in base alla condizione sperimentale: campione clinico e campione di controllo.\nLa stratificazione è particolarmente utile nella visualizzazione dei dati, poiché spesso siamo interessati a comprendere come la distribuzione di una variabile differisca tra diversi sottogruppi.\nPer esempio, per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo, possiamo utilizzare un box-plot. Questo tipo di grafico ci permette di confrontare visivamente la distribuzione dei punteggi tra i due gruppi, evidenziando eventuali differenze.\n\nggplot(df, aes(x = group, y = bdi)) +\n  geom_boxplot() +\n  labs(\n    x = \"Gruppo\", \n    y = \"BDI-II\"\n  )\n\n\n\n\n\n\n\nIn questo grafico:\n\nl’asse x rappresenta i due gruppi (pazienti e controllo),\nl’asse y rappresenta i punteggi BDI-II,\ni box (scatole) mostrano la distribuzione dei punteggi, con la linea centrale che indica la mediana e i “baffi” che rappresentano la variabilità dei dati.\n\nLa stratificazione ci aiuta a identificare rapidamente se ci sono differenze nella distribuzione dei punteggi BDI-II tra i due gruppi. Nel caso presente, il grafico mostra come non vi sia alcuna sovrapposizione tra le due distribuzioni.\nUn risultato migliore si ottiene utilizzando un grafico a violino (violin plot) e includendo anche i dati grezzi.\n\n17.7.3 Grafico a violino\nI grafici a violino combinano le caratteristiche dei box plot e dei grafici di densità di kernel (KDE plot) per offrire una rappresentazione più dettagliata dei dati.\n\nggplot(df, aes(x = group, y = bdi, fill = group)) +\n  geom_violin() +\n  labs(\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  )\n\n\n\n\n\n\n\n\n17.7.4 Grafico Beeswarm\nIl pacchetto {ggbeeswarm} include una funzione chiamata geom_beeswarm, che può essere utilizzata per creare un grafico beeswarm in ggplot2. Un grafico beeswarm è una variazione del grafico a punti che disperde i dati in modo che non si sovrappongano, rendendo visibili tutti i singoli punti dati. Questo tipo di visualizzazione è particolarmente utile quando si desidera esaminare la distribuzione e la densità di un set di dati, senza ricorrere all’uso di barre d’errore o di scatole e baffi (boxplot), mantenendo un’alta leggibilità anche quando i set di dati sono densi.\n\nggplot(df, aes(x = group, y = bdi, color = group)) +\n  geom_beeswarm(cex = 2) +\n  labs(\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  )",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_numeric_data.html#riflessioni-conclusive",
    "href": "chapters/eda/04_exploring_numeric_data.html#riflessioni-conclusive",
    "title": "17  Esplorare i dati numerici",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo illustrato una varietà di tecniche per sintetizzare e visualizzare i dati numerici, concentrandoci sia sugli aspetti descrittivi (come distribuzioni di frequenze, istogrammi e distribuzioni cumulative) sia su metodi più raffinati come la stima della densità kernel. Questi strumenti non solo facilitano la comprensione immediata dei pattern e delle caratteristiche fondamentali dei dati, ma rappresentano anche un passaggio essenziale per identificare anomalie e guidare ulteriori analisi statistiche.\nLa capacità di trasformare dati grezzi in rappresentazioni grafiche chiare e intuitive è fondamentale per comunicare in modo efficace i risultati dell’analisi, soprattutto quando si tratta di supportare decisioni pratiche o di sviluppare ipotesi di ricerca. In questo senso, una visualizzazione accurata e ben strutturata consente di evidenziare aspetti come la forma della distribuzione, la presenza di outlier e le differenze tra sottogruppi, contribuendo a una più profonda interpretazione dei fenomeni studiati.\nInfine, l’integrazione di tecniche di visualizzazione con analisi statistiche sintetiche migliora la trasparenza e l’interpretabilità dei dati, offrendo un quadro completo che supporta sia la valutazione critica che la comunicazione dei risultati.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nIn questo esercizio, gli studenti raccoglieranno e analizzeranno dati relativi alla Satisfaction With Life Scale (SWLS) (Diener et al., 1985) e alla Scala della Rete Sociale di Lubben (LSNS-6) (Lubben et al., 2006). L’obiettivo è comprendere la relazione tra la soddisfazione di vita e la qualità delle relazioni sociali, esplorando la distribuzione delle variabili e le possibili associazioni tra di esse.\nLa Scala della Rete Sociale di Lubben a 6 item (LSNS-6) è uno strumento utilizzato per valutare l’isolamento sociale negli adulti più anziani, misurando il supporto sociale percepito sia da parte dei familiari che degli amici. La scala comprende sei domande suddivise in due sezioni:\nFAMIGLIA: Considerando le persone a cui sei legato per nascita, matrimonio, adozione, ecc.\n\nQuanti parenti vedi o senti almeno una volta al mese?\nCon quanti parenti ti senti a tuo agio nel parlare di questioni personali?\nCon quanti parenti ti senti così vicino da poter chiedere loro aiuto?\n\nAMICIZIE: Considerando tutti i tuoi amici, inclusi quelli che vivono nel tuo quartiere\n\nQuanti dei tuoi amici vedi o senti almeno una volta al mese?\nCon quanti amici ti senti a tuo agio nel parlare di questioni personali?\nCon quanti amici ti senti così vicino da poter chiedere loro aiuto?\n\nLa scala di risposta è:\n\n0 = nessuno\n1 = uno\n2 = due\n3 = tre o quattro\n4 = da cinque a otto\n5 = nove o più\n\nIl punteggio totale della LSNS-6 si ottiene sommando i punteggi dei sei item, con un range che va da 0 a 30. Un punteggio di 12 o inferiore indica un rischio di isolamento sociale.\nDati da Raccogliere\nOgni studente dovrà raccogliere i seguenti dati su se stesso e sui membri del proprio gruppo TPV:\n\n\nstudent_id: Identificativo univoco dello studente.\n\n\ngroup: Gruppo di appartenenza (es. Gruppo 1, Gruppo 2, ecc.).\n\n\nswls: Punteggio totale sulla Satisfaction With Life Scale (SWLS).\n\n\ngender: Genere (M, F).\n\n\nlsns_total: Punteggio totale della Scala della Rete Sociale di Lubben (LSNS-6).\n\n\nlsns_family: Punteggio della sottoscala engagement with family members (somma degli item 1-3).\n\n\nlsns_friends: Punteggio della sottoscala engagement with friends (somma degli item 4-6).\n\nQueste variabili permetteranno di investigare come la soddisfazione di vita sia associata alla quantità e qualità delle relazioni sociali, distinguendo tra contatti con la famiglia e con gli amici.\nObiettivi dell’Analisi\nL’esercizio è strutturato in tre parti:\n\n\nEsplorazione dei dati e distribuzione delle variabili\n\n\nVisualizzazione e confronto tra gruppi\n\nAnalisi delle possibili associazioni tra SWLS e le componenti della rete sociale\n\nParte 1: Esplorazione dei Dati\n1.1 Caricamento e preparazione del dataset\n\nImporta il dataset swls_lsns_students.csv.\n\nSeleziona le variabili indicate sopra.\n\nControlla ed elimina eventuali duplicati.\n\nControlla ed elimina eventuali valori mancanti.\n\n# Caricamento del dataset\ndf &lt;- rio::import(here::here(\"data\", \"swls_lsns_students.csv\"))\n\n# Selezione delle variabili\ndf &lt;- df |&gt; dplyr::select(student_id, group, swls, gender, \n                          lsns_total, lsns_family, lsns_friends)\n\n# Rimozione dei duplicati\ndf &lt;- df[!duplicated(df$student_id), ]\n\n# Rimozione dei valori mancanti\ndf &lt;- df[complete.cases(df), ]\n1.2 Distribuzione delle variabili\n\nCalcola la distribuzione di frequenza per swls, lsns_total, lsns_family e lsns_friends:\n\nFrequenze assolute e relative\n\nFrequenze cumulative\n\n\n\n# Frequenze assolute e relative\ntable(df$swls)\nprop.table(table(df$swls))\n\ntable(df$lsns_total)\nprop.table(table(df$lsns_total))\n\nCrea un istogramma della distribuzione delle variabili.\n\nggplot(df, aes(x = swls)) +\n  geom_histogram(bins = 10, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione dei punteggi SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"Frequenza\")\nggplot(df, aes(x = lsns_total)) +\n  geom_histogram(bins = 10, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione dei punteggi LSNS-6 (totale)\",\n       x = \"Punteggio LSNS-6\",\n       y = \"Frequenza\")\n\nCostruisci la funzione di distribuzione empirica cumulativa (eCDF).\n\nggplot(df, aes(x = swls)) +\n  stat_ecdf(geom = \"step\", color = \"blue\") +\n  labs(title = \"Funzione di distribuzione empirica cumulativa SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"F(x)\")\n\nGenera la curva di densità kernel (KDE) per ogni variabile.\n\nggplot(df, aes(x = swls)) +\n  geom_density(fill = \"lightblue\", alpha = 0.5) +\n  labs(title = \"Curva di densità dei punteggi SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"Densità\")\nggplot(df, aes(x = lsns_total)) +\n  geom_density(fill = \"lightblue\", alpha = 0.5) +\n  labs(title = \"Curva di densità LSNS-6 (totale)\",\n       x = \"Punteggio LSNS-6\",\n       y = \"Densità\")\nParte 2: Confronto tra Gruppi\n\nCostruisci una tabella di contingenza per gender e livello di rete sociale (alta o bassa, separando sopra e sotto la mediana di lsns_total).\n\ndf &lt;- df |&gt; \n  mutate(lsns_level = ifelse(lsns_total &gt;= median(lsns_total), \"Alto\", \"Basso\"))\n\ntable(df$gender, df$lsns_level)\nprop.table(table(df$gender, df$lsns_level), margin = 1)\n\nCrea un grafico a barre per la distribuzione di lsns_level per genere.\n\nggplot(df, aes(x = lsns_level, fill = gender)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Distribuzione del livello di rete sociale per genere\",\n       x = \"Livello LSNS\",\n       y = \"Conteggio\",\n       fill = \"Genere\")\n\nCostruisci un box plot per confrontare swls tra i gruppi di rete sociale.\n\nggplot(df, aes(x = lsns_level, y = swls, fill = lsns_level)) +\n  geom_boxplot() +\n  labs(title = \"Distribuzione dei punteggi SWLS per livello di rete sociale\",\n       x = \"Livello di rete sociale\",\n       y = \"Punteggio SWLS\")\n\nUsa un violin plot per visualizzare la distribuzione dettagliata.\n\nggplot(df, aes(x = lsns_level, y = swls, fill = lsns_level)) +\n  geom_violin(alpha = 0.5) +\n  geom_jitter(width = 0.1, alpha = 0.5) +\n  labs(title = \"Violin plot con dati grezzi sovrapposti\",\n       x = \"Livello di rete sociale\",\n       y = \"Punteggio SWLS\")\nParte 3: Analisi delle Associazioni tra SWLS e la Rete Sociale\nIl concetto di correlazione verrà approfondito nel Capitolo 21. Per i nostri scopi attuali, possiamo considerarlo come un indice numerico che misura l’intensità e la direzione dell’associazione tra due variabili. Un valore di 0 indica l’assenza di una relazione lineare tra le variabili, mentre i valori +1 e -1 indicano una relazione lineare perfetta, positiva o negativa rispettivamente. I valori intermedi tra -1 e +1 rappresentano associazioni più deboli o forti, a seconda della loro vicinanza agli estremi.\n\n\nCorrelazioni tra SWLS e le sottoscale della LSNS.\n\ncor(df$swls, df$lsns_total, method = \"pearson\")\ncor(df$swls, df$lsns_family, method = \"pearson\")\ncor(df$swls, df$lsns_friends, method = \"pearson\")\nSpiega in maniera inuitiva il significato dei valori ottenuti.\n\n\nGrafico di dispersione tra SWLS e LSNS-6 totale.\n\nUn grafico di dispersione è un diagramma cartesiano in cui ogni punto rappresenta un’osservazione (nel caso attuale, uno studente). Le coordinate dei punti sui due assi, X e Y, indicano i valori delle due variabili considerate per ciascuno studente.\nggplot(df, aes(x = lsns_total, y = swls)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(title = \"Relazione tra rete sociale totale e SWLS\",\n       x = \"Punteggio LSNS-6 Totale\",\n       y = \"Punteggio SWLS\")\nPer ogni grafico generato, includi una descrizione chiara e concisa del suo significato in relazione ai dati analizzati.\nConclusioni\nL’obiettivo è analizzare se e come la soddisfazione di vita degli studenti universitari è influenzata dalle relazioni sociali, distinguendo tra engagement con la famiglia e con gli amici.\nConsegna\nConsegna il file .qmd contenente il codice, le visualizzazioni e le interpretazioni.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] viridis_0.6.5         viridisLite_0.4.2     cowplot_1.2.0        \n#&gt;  [4] ggpubr_0.6.1          gridExtra_2.3         dslabs_0.8.0         \n#&gt;  [7] ggbeeswarm_0.7.2      pillar_1.11.0         tinytable_0.13.0     \n#&gt; [10] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt; [13] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [16] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [19] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [22] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [25] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [28] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [31] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] inline_0.3.21         sandwich_3.1-1        rlang_1.1.6          \n#&gt;  [4] magrittr_2.0.3        multcomp_1.4-28       snakecase_0.11.1     \n#&gt;  [7] compiler_4.5.1        systemfonts_1.2.3     vctrs_0.6.5          \n#&gt; [10] stringr_1.5.1         pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [13] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [16] rmarkdown_2.29        ragg_1.5.0            purrr_1.1.0          \n#&gt; [19] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [22] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [25] stringi_1.8.7         RColorBrewer_1.1-3    car_3.1-3            \n#&gt; [28] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [31] zoo_1.8-14            R.utils_2.13.0        pacman_0.5.1         \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           codetools_0.2-20     \n#&gt; [40] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [43] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [46] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [49] carData_3.0-5         tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [52] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [55] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [58] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [61] tools_4.5.1           data.table_1.17.8     ggsignif_0.6.4       \n#&gt; [64] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [67] colorspace_2.1-1      nlme_3.1-168          beeswarm_0.4.0       \n#&gt; [70] vipor_0.4.7           Formula_1.2-5         cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          R.methodsS3_1.8.2    \n#&gt; [79] rstatix_0.7.2         digest_0.6.37         TH.data_1.1-4        \n#&gt; [82] htmlwidgets_1.6.4     farver_2.1.2          R.oo_1.27.1          \n#&gt; [85] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [88] MASS_7.3-65",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_numeric_data.html#bibliografia",
    "href": "chapters/eda/04_exploring_numeric_data.html#bibliografia",
    "title": "17  Esplorare i dati numerici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDiener, E., Emmons, R. A., Larsen, R. J., & Griffin, S. (1985). The Satisfaction With Life Scale. Journal of Personality Assessment, 49(1), 71–75. https://doi.org/10.1207/s15327752jpa4901_13\n\n\nLubben, J., Blozik, E., Gillmann, G., Iliffe, S., Renteln Kruse, W. von, Beck, J. C., & Stuck, A. E. (2006). Performance of an abbreviated version of the Lubben Social Network Scale among three European community-dwelling older adult populations. The Gerontologist, 46(4), 503–513. https://doi.org/10.1093/geront/46.4.503\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_data_visualization.html",
    "href": "chapters/eda/05_data_visualization.html",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "",
    "text": "Introduzione\nIn questo capitolo vengono introdotti i principi fondamentali della visualizzazione dei dati, accompagnati da esempi concreti e da una discussione sui principali errori da evitare. La visualizzazione non è soltanto un supporto estetico: è uno strumento essenziale per interpretare, comunicare e validare i risultati delle analisi.\nUn buon grafico permette di cogliere immediatamente pattern, anomalie e bias che resterebbero nascosti in una semplice tabella di valori. Per chi desidera un approfondimento sistematico, un riferimento utile è il capitolo Data Visualization del libro Introduction to Data Science..\nL’ampia disponibilità di dataset complessi e la diffusione di strumenti software sempre più accessibili hanno reso la visualizzazione un passaggio centrale in molti ambiti scientifici e professionali: non solo facilita la comunicazione dei risultati, ma stimola nuove domande e consente di individuare rapidamente errori o anomalie.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_data_visualization.html#introduzione",
    "href": "chapters/eda/05_data_visualization.html#introduzione",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "",
    "text": "Panoramica del capitolo\n\nComunicare i risultati basati sui dati.\nUtilizzare ggplot2 per creare grafici personalizzati.\n\nRiconoscere i limiti di alcuni grafici comunemente utilizzati e comprendere perché evitarli.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Testing Statistical Charts: What Makes a Good Graph? (Vanderplas, Cook, and Hofmann 2020). Questo articolo descrive le migliori pratiche per la creazione di grafici.\nConsultare il capitolo Data visualization di Wickham et al. (2023). Questo capitolo fornisce una panoramica degli aspetti fondamentali della visualizzazione dei dati.\nConsultare Data Visualization. A practical introduction di Healy (2018).\nConsultare Fundamentals of Data Visualization di Wilke (2019).\nLeggere il post Open letter to journal editors: dynamite plots must die di Rafael Irizarry.\nConsultare il post The top ten worst graphs di Karl Broman.\nLeggere il capitolo Data Visualization di Introduction to Data Science.\nVisionare Communicating Science Using Visuals: Tips for Scientists.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt;\n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(dslabs, ggrepel, stringr)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_data_visualization.html#unimmagine-vale-più-di-mille-parole",
    "href": "chapters/eda/05_data_visualization.html#unimmagine-vale-più-di-mille-parole",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "\n18.1 Un’immagine vale più di mille parole",
    "text": "18.1 Un’immagine vale più di mille parole\nI numeri da soli raramente raccontano una storia chiara. Consideriamo, ad esempio, i dati sugli omicidi con armi da fuoco negli Stati Uniti. Una tabella con i valori grezzi permette di sapere, per ogni stato, popolazione e numero di omicidi. Tuttavia, osservandola è difficile farsi un’idea immediata della distribuzione: quali sono gli stati più popolosi o i meno popolosi? Qual è la dimensione “tipica” di uno stato? Esiste una relazione tra popolazione e numero totale di omicidi? E come si distribuiscono i tassi di omicidio tra le diverse regioni?\n\nhead(murders)\n#&gt;        state abb region population total\n#&gt; 1    Alabama  AL  South    4779736   135\n#&gt; 2     Alaska  AK   West     710231    19\n#&gt; 3    Arizona  AZ   West    6392017   232\n#&gt; 4   Arkansas  AR  South    2915918    93\n#&gt; 5 California  CA   West   37253956  1257\n#&gt; 6   Colorado  CO   West    5029196    65\n\nUn grafico, al contrario, rende queste relazioni visibili a colpo d’occhio. Nella figura che segue, la scala logaritmica su entrambi gli assi permette di rappresentare in modo compatto sia gli stati più grandi, come California, Texas e New York, sia quelli con popolazioni molto ridotte, come Wyoming, Vermont o Alaska. Si vede subito che la maggior parte degli stati ha una popolazione compresa tra uno e dieci milioni di abitanti, mentre gli stati più popolosi si collocano nettamente a destra del grafico.\n\n\n\n\n\n\n\n\nAllo stesso modo, la relazione tra popolazione e numero di omicidi appare chiara: più abitanti significa, in media, più omicidi. Tuttavia, si notano discrepanze: alcuni stati registrano più omicidi del previsto in rapporto alla popolazione, mentre altri ne hanno meno, segnalando l’influenza di fattori ulteriori. Anche la colorazione per regione rivela differenze interessanti: il Sud tende a registrare tassi più elevati, il Nord-Est valori relativamente bassi, l’Ovest mostra una grande variabilità, e il Midwest si colloca in posizione intermedia o bassa.\nIl detto “un’immagine vale più di mille parole” trova qui piena conferma: un buon grafico non solo comunica con immediatezza, ma spesso sostituisce lunghe spiegazioni numeriche, guidando lo sguardo verso i pattern più rilevanti e stimolando nuove domande di analisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "href": "chapters/eda/05_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "\n18.2 Codificare i dati attraverso segnali visivi",
    "text": "18.2 Codificare i dati attraverso segnali visivi\nOgni visualizzazione si fonda sulla trasformazione dei dati in segnali visivi che il nostro sistema percettivo può elaborare con immediatezza. Gli elementi più comuni sono la posizione, la lunghezza, gli angoli, l’area, la luminosità e la tonalità del colore. Non tutti, però, hanno la stessa efficacia.\nIl nostro cervello è particolarmente sensibile alle differenze spaziali: per questo la posizione e la lunghezza sono i canali più potenti per trasmettere informazione quantitativa. Un grafico a barre, ad esempio, permette di confrontare valori in modo rapido e preciso proprio perché sfrutta la lunghezza come segnale visivo. Al contrario, angoli e aree sono molto meno intuitivi: grafici a torta o bolle possono risultare accattivanti, ma spesso portano a errori percettivi, soprattutto quando le differenze tra categorie sono ridotte.\nIl colore gioca un ruolo cruciale quando vogliamo distinguere categorie o rappresentare variabili qualitative. È un elemento indispensabile nelle visualizzazioni multidimensionali, come le heatmap, ma deve essere usato con attenzione. Alcune combinazioni, come il rosso e il verde, possono rendere il grafico illeggibile per persone con daltonismo, e in generale una palette mal progettata può distogliere l’attenzione dai contenuti principali.\nInfine, è importante distinguere tra strumenti di precisione e strumenti di sintesi. Le tabelle sono ideali quando è necessario leggere valori numerici esatti, mentre i grafici diventano insostituibili di fronte a dataset complessi, perché mettono in evidenza pattern, tendenze e anomalie che difficilmente emergerebbero da un elenco di numeri.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_data_visualization.html#scelta-della-visualizzazione-più-adeguata",
    "href": "chapters/eda/05_data_visualization.html#scelta-della-visualizzazione-più-adeguata",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "\n18.3 Scelta della visualizzazione più adeguata",
    "text": "18.3 Scelta della visualizzazione più adeguata\nNon esiste una visualizzazione “migliore” in assoluto: la scelta dipende sempre dalla natura dei dati e dallo scopo comunicativo. Se l’obiettivo è confrontare valori quantitativi tra diverse categorie, i grafici a barre o i dot plot risultano particolarmente chiari. Quando invece vogliamo descrivere la distribuzione di una variabile continua, strumenti come l’istogramma, il boxplot o i più moderni raincloud plots permettono di cogliere rapidamente forma, variabilità e presenza di outlier. Per indagare relazioni tra due variabili continue, i grafici di dispersione offrono un’immediatezza che difficilmente può essere sostituita da altre rappresentazioni.\nQualunque sia il tipo di grafico scelto, rimane centrale il principio della chiarezza. Una visualizzazione sovraccarica di dettagli, effetti grafici o decorazioni rischia di distrarre e confondere, mentre una rappresentazione essenziale mette in risalto il messaggio principale e guida lo sguardo verso le informazioni rilevanti. In questo senso, un buon grafico non è solo corretto dal punto di vista tecnico, ma è anche uno strumento di comunicazione efficace.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_data_visualization.html#aspetti-tecnici-della-visualizzazione",
    "href": "chapters/eda/05_data_visualization.html#aspetti-tecnici-della-visualizzazione",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "\n18.4 Aspetti tecnici della visualizzazione",
    "text": "18.4 Aspetti tecnici della visualizzazione\nUna buona visualizzazione non dipende soltanto dalla scelta del tipo di grafico, ma anche da una serie di accorgimenti tecnici che ne determinano chiarezza e correttezza percettiva. Alcune regole, spesso sottovalutate, possono fare la differenza tra un grafico informativo e uno fuorviante.\n\n18.4.1 Inclusione dello zero\nQuando la lunghezza viene utilizzata come segnale visivo – come accade nei grafici a barre – l’asse deve sempre partire da zero. In caso contrario, le differenze appariranno artificialmente amplificate, inducendo interpretazioni scorrette. Nei grafici che si basano sulla posizione, come gli scatter plot, questa regola non è altrettanto stringente: qui l’inclusione dello zero dipende piuttosto dal contesto e dal significato delle variabili rappresentate.\n\n18.4.2 Prevenire le distorsioni\nAlcuni grafici, come i bubble plot, rischiano di esagerare le differenze fra i valori perché utilizzano l’area come segnale visivo. La superficie di un cerchio cresce infatti con il quadrato del raggio, producendo sproporzioni difficili da cogliere a occhio nudo. Un esempio emblematico è il grafico mostrato durante il Discorso sullo Stato dell’Unione del 2011, in cui il PIL degli Stati Uniti appariva molto più grande di quello cinese o francese. In realtà, la distorsione derivava proprio dall’aver reso il raggio proporzionale al valore, trasformando implicitamente la scala in quadratica. La lezione che se ne ricava è semplice: per confronti accurati, meglio affidarsi a posizione e lunghezza, evitando aree o volumi.\n\n\n\n\n\n\nState of the Union\n\n\n\n\n\n\n\n\n\n\nFigura 18.1: Fonte: Irizarry (2024).\n\n\nIl confronto sottostante illustra l’impatto della scelta tra raggio e area nella rappresentazione grafica:\n\n\n\n\n\nFigura 18.2: Fonte: Irizarry (2024).\n\n\n\n\n\n\n\nFigura 18.3: Fonte: Irizarry (2024).\n\n\nQuesto caso dimostra chiaramente come, per evitare distorsioni percettive, sia una prassi consolidata ottimizzare la visualizzazione dei dati attraverso confronti basati su lunghezze (o posizioni) anziché su aree o volumi, come evidenziato dall’errata rappresentazione del PIL nel grafico originale.\n\n\n\n\n18.4.3 Ordinamento delle categorie\nNei grafici categoriali, disporre le categorie in ordine alfabetico può sembrare neutrale, ma raramente aiuta la comprensione. Ordinare le categorie in base al valore della variabile di interesse, invece, evidenzia immediatamente pattern e relazioni, rendendo la lettura molto più intuitiva.\n\n18.4.4 Mostrare i dati, non solo le sintesi\nI cosiddetti dynamite plots, che riportano medie ed errori standard, sono ancora molto diffusi ma comunicano poco e spesso in modo fuorviante. Guardando una semplice barra con un intervallo di errore, non è possibile capire se i dati siano distribuiti in modo simmetrico, se esistano outlier o se i gruppi si sovrappongano. Visualizzazioni che mostrano i singoli dati – ad esempio dot plot arricchiti da tecniche come jitter e trasparenza – permettono invece di cogliere la variabilità interna, facilitano il confronto e raccontano una storia molto più completa.\n\n\n\n\n\n\nMostrare i dati\n\n\n\n\n\nConsideriamo il seguente grafico a barre (dynamite plot) che mostra la media (estremità superiore delle barre) e gli errori standard.\n\n\n\n\n\nFigura 18.4: Fonte: Irizarry (2024).\n\n\nQuesta visualizzazione offre informazioni limitate:\n\nLe barre partono da 0, suggerendo erroneamente l’esistenza di esseri umani alti pochi centimetri.\n\nNon chiarisce se tutti i maschi siano più alti delle femmine o come siano distribuite le altezze.\n\nUn approccio migliore è quello di mostrare i dati:\n\n\n\n\n\nFigura 18.5: Fonte: Irizarry (2024).\n\n\nLa visualizzazione di tutti i punti (238 femmine e 812 maschi) rivela l’intervallo dei dati, ma persiste un problema: i punti sovrapposti ostacolano l’interpretazione.\nOttimizzazioni: jitter e trasparenza\n\n\n\n\n\nFigura 18.6: Fonte: Irizarry (2024).\n\n\nDue miglioramenti chiave:\n\n\nJitter orizzontale: spostamento casuale dei punti per ridurre la sovrapposizione.\n\n\nAlpha blending: trasparenza graduale: le aree con più dati appaiono più scure.\n\nRisultati:\n\nsi osserva che i maschi sono in media più alti;\nè chiaro che vi è una grande variabilità e una notevole sovrapposizione tra le due distribuzioni.\n\nIn sintesi, strumenti semplici, come jitter e trasparenza, migliorano drasticamente l’interpretazione della distribuzione dei dati.\n\n\n\n\n18.4.5 Confronti coerenti\nQuando si confrontano distribuzioni diverse, ad esempio con istogrammi affiancati, è indispensabile utilizzare la stessa scala sugli assi. Differenze apparenti potrebbero dipendere soltanto da un’incoerenza di rappresentazione. Anche l’allineamento dei grafici gioca un ruolo importante: disporli in verticale o in orizzontale con assi coerenti rende il confronto immediato e riduce il rischio di fraintendimenti.\n\n\n\n\n\n\nFacilitare i confronti\n\n\n\n\n\nPoiché ci sono molti punti, è più efficace mostrare la distribuzione dei dati anziché i singoli valori. Per questo motivo, utilizziamo istogrammi separati per ciascun gruppo:\n\n\n\n\n\nFigura 18.7: Fonte: Irizarry (2024).\n\n\nTuttavia, in questo grafico non è immediatamente evidente che, in media, gli uomini siano più alti delle donne. Per accorgersene, bisogna osservare con attenzione e notare che l’asse x del grafico maschile copre un intervallo di valori più ampio. Un principio fondamentale nella comparazione di dati tra due grafici è mantenere le stesse scale sugli assi.\nNegli istogrammi, l’altezza media si riflette in spostamenti orizzontali: valori più bassi a sinistra, valori più alti a destra. Allineare i grafici in verticale aiuta a visualizzare meglio questa differenza quando gli assi sono coerenti:\n\n\n\n\n\nFigura 18.8: Fonte: Irizarry (2024).\n\n\nQuesto secondo grafico rende molto più evidente che, in media, gli uomini sono più alti delle donne.\n\n\n\n\n18.4.6 Trasformazioni logaritmiche\nMolti dati reali coprono ordini di grandezza molto ampi. In questi casi, una scala lineare comprime la maggior parte delle osservazioni e rende invisibili le differenze più sottili. Le trasformazioni logaritmiche sono uno strumento efficace per restituire leggibilità a distribuzioni fortemente asimmetriche. Altre trasformazioni, come la logistica o la radice quadrata, sono utili rispettivamente per rappresentare rapporti di probabilità o stabilizzare la varianza in dati di conteggio. La scelta della trasformazione non è mai neutrale, ma può illuminare pattern altrimenti nascosti.\n\n\n\n\n\n\nTrasformazioni logaritmiche\n\n\n\n\n\nConsideriamo questo grafico a barre, che mostra la popolazione media dei paesi di ciascun continente nel 2015:\n\n\n\n\n\nFigura 18.9: Fonte: Irizarry (2024).\n\n\nA prima vista, sembrerebbe che i paesi dell’Asia siano molto più popolosi rispetto a quelli degli altri continenti. Tuttavia, applicando il principio che ci chiede di mostrare i dati, notiamo rapidamente che questa differenza è dovuta alla presenza di due paesi con una popolazione estremamente elevata, presumibilmente India e Cina:\n\n\n\n\n\nFigura 18.10: Fonte: Irizarry (2024).\n\n\nConsideriamo ora come la trasformazione logaritmica possa migliorare la visualizzazione di dati distribuiti in modo asimmetrico (right-skewed). Esistono anche altre trasformazioni utili, come la logistica (logit), impiegata per interpretare variazioni nei rapporti di probabilità (odds), e la radice quadrata (sqrt), spesso usata per stabilizzare la varianza nei dati basati su conteggi.\nNel caso della popolazione dei paesi, la distribuzione è fortemente asimmetrica: la maggior parte delle nazioni ha una popolazione relativamente piccola, mentre poche hanno numeri estremamente elevati. Come mostrato nel boxplot precedente, questa disparità comprime la maggior parte dei dati in una piccola area del grafico, lasciando molto spazio inutilizzato. Questo rende difficile cogliere le differenze tra la maggior parte dei paesi.\nUna trasformazione logaritmica migliora la leggibilità di uno scatter plot quando i dati mostrano una forte asimmetria. Qui, applicando questa tecnica alle popolazioni nazionali, otteniamo una rappresentazione molto più chiara e informativa. Di seguito, confrontiamo il barplot originale con un boxplot in cui l’asse y è stato trasformato con il logaritmo:\n\n\n\n\n\nFigura 18.11: Fonte: Irizarry (2024).\n\n\nGrazie a questa trasformazione, scopriamo che la mediana della popolazione nei paesi africani è in realtà più alta rispetto a quella dei paesi asiatici, un’informazione che il grafico iniziale non rendeva evidente.\n\n\n\n\n18.4.7 Codifica di variabili aggiuntive\nQuando si vogliono rappresentare più di due variabili nello stesso grafico, si possono sfruttare ulteriori canali visivi come colore, forma o dimensione dei punti. È però necessario bilanciare informazione e leggibilità: troppe codifiche simultanee generano confusione. Inoltre, la scelta delle palette cromatiche deve garantire accessibilità, ad esempio evitando combinazioni problematiche per persone con daltonismo.\n\n\n\n\n\n\nCodificare una terza variabile\n\n\n\n\n\nEsaminiamo la relazione tra sopravvivenza infantile e reddito medio. Il grafico seguente rappresenta questa relazione includendo tre variabili aggiuntive: appartenenza all’OPEC, regione geografica e popolazione.\n\n\n\n\n\nFigura 18.12: Fonte: Irizarry (2024).\n\n\nLe variabili categoriali sono rappresentate attraverso il colore e la forma dei punti. La forma può essere modificata utilizzando l’argomento shape.\n\n\n\n\n18.4.8 Evitare il 3D superfluo\nGrafici tridimensionali, come pie chart o barre in prospettiva, attirano l’occhio ma raramente aggiungono informazione. Anzi, introducono distorsioni che complicano la lettura. Nella maggior parte dei casi, una rappresentazione bidimensionale è più chiara, più fedele e più efficace.\n\n18.4.9 Cifre significative\nMostrare un numero eccessivo di decimali non aumenta la precisione, ma rischia di appesantire la lettura. Una o due cifre significative sono quasi sempre sufficienti per trasmettere il messaggio in modo accurato e comprensibile.\n\n18.4.10 Conoscere il pubblico\nInfine, una regola trasversale: ogni visualizzazione deve tenere conto del pubblico di riferimento. Un grafico pensato per un’analisi interna può includere dettagli tecnici e livelli di complessità elevati; al contrario, quando il pubblico non è specializzato, è preferibile semplificare, ridurre il rumore visivo e accompagnare la rappresentazione con spiegazioni chiare.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_data_visualization.html#introduzione-a-ggplot2",
    "href": "chapters/eda/05_data_visualization.html#introduzione-a-ggplot2",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "\n18.5 Introduzione a ggplot2\n",
    "text": "18.5 Introduzione a ggplot2\n\nIn R esistono diversi strumenti per creare grafici, ma il pacchetto ggplot2 si distingue per flessibilità e chiarezza. È diventato lo standard per la visualizzazione dei dati in molti ambiti scientifici, inclusa la psicologia, perché consente di tradurre un dataset complesso in rappresentazioni immediate e leggibili.\n\n18.5.1 Perché usare ggplot2?\nImmaginiamo di voler analizzare i livelli di ansia di un gruppo di studenti prima di un esame. I dati raccolti in una tabella ci danno informazioni preziose, ma difficili da cogliere a colpo d’occhio. Con un grafico, invece, possiamo visualizzare subito quali studenti mostrano livelli di ansia particolarmente elevati e se l’ansia tende a variare in funzione di caratteristiche come l’intolleranza all’incertezza (IU).\nPer illustrare le potenzialità di ggplot2, costruiamo un piccolo dataset simulato:\n\nset.seed(123)\n\nn &lt;- 200\ngender &lt;- sample(c(0, 1), n, replace = TRUE)\nanxiety &lt;- rnorm(n, mean = 50 + 10 * gender, sd = 10)\nstudy_hours &lt;- rnorm(n, mean = 30 - 0.3 * anxiety, sd = 5)\nIU &lt;- rnorm(n, mean = 50 + 0.5 * anxiety, sd = 10)\n\ndf &lt;- data.frame(\n  id = 1:n,\n  gender = factor(gender, levels = c(0, 1), labels = c(\"Male\", \"Female\")),\n  anxiety = round(anxiety, 1),\n  study_hours = round(study_hours, 1),\n  IU = round(IU, 1)\n)\n\nhead(df)\n#&gt;   id gender anxiety study_hours   IU\n#&gt; 1  1   Male    42.9        13.6 65.4\n#&gt; 2  2   Male    52.6        10.5 66.3\n#&gt; 3  3   Male    47.5        11.0 84.0\n#&gt; 4  4 Female    56.5         7.8 85.8\n#&gt; 5  5   Male    40.5        15.7 55.2\n#&gt; 6  6 Female    59.5        13.8 78.8\n\n\n18.5.2 La logica di ggplot2\n\nAlla base di ogni grafico con ggplot2 ci sono tre elementi fondamentali:\n\n\ni dati, cioè il dataset da rappresentare;\n\nle geometrie, ossia il tipo di grafico scelto (punti, barre, linee, boxplot);\n\nla mappatura estetica, che stabilisce come i dati vengono tradotti in segnali visivi (posizione sugli assi, colore, forma, dimensione).\n\nQuesta struttura rende il pacchetto molto intuitivo: basta dire a ggplot2 quali dati usare, come rappresentarli e con quali convenzioni grafiche.\n\n18.5.3 Un primo esempio\nSupponiamo di voler capire se esiste una relazione tra ore di studio e livelli di ansia. Possiamo costruire un semplice grafico a dispersione:\n\nlibrary(ggplot2)\n\ndf |&gt;\n  ggplot(aes(x = study_hours, y = anxiety)) +\n  geom_point()\n\n\n\n\n\n\n\nIn questo codice stiamo dicendo a ggplot2 di prendere come riferimento il dataset df, di mettere le ore di studio sull’asse X, i livelli di ansia sull’asse Y e di rappresentare ogni osservazione con un punto.\n\n18.5.4 Personalizzare il grafico\nUn aspetto importante di ggplot2 è la possibilità di arricchire facilmente la rappresentazione. Aggiungiamo, per esempio, un colore che distingua maschi e femmine, rendiamo i punti più visibili e inseriamo un titolo e delle etichette agli assi:\n\ndf |&gt;\n  ggplot(aes(x = study_hours, y = anxiety, color = gender)) +\n  geom_point(size = 3) +\n  labs(\n    x = \"Ore di studio\",\n    y = \"Livello di ansia\",\n    color = \"Genere\"\n  )\n\n\n\n\n\n\n\nIl risultato è un grafico più leggibile, in cui la distinzione per genere appare immediatamente chiara.\n\n18.5.5 Altri esempi\nCon gli stessi dati possiamo costruire grafici diversi, ciascuno utile a rispondere a domande specifiche. Per esplorare la distribuzione dell’ansia, ad esempio, un istogramma è la scelta naturale:\n\ndf |&gt;\n  ggplot(aes(x = anxiety)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"Livello di ansia\", y = \"Frequenza\")\n\n\n\n\n\n\n\nSe invece vogliamo confrontare i livelli di ansia tra maschi e femmine, un boxplot mette in evidenza la mediana, la variabilità e la presenza di eventuali valori estremi:\n\ndf |&gt;\n  ggplot(aes(x = gender, y = anxiety, fill = gender)) +\n  geom_boxplot(alpha = 0.7) +\n  labs(x = \"Genere\", y = \"Livello di ansia\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nIn sintesi, con pochi comandi, ggplot2 consente di costruire grafici chiari e informativi. In psicologia, dove spesso si lavora con dataset complessi, è uno strumento prezioso per trasformare numeri in intuizioni: una buona visualizzazione permette non solo di comunicare risultati, ma anche di stimolare nuove domande di ricerca.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_data_visualization.html#riflessioni-conclusive",
    "href": "chapters/eda/05_data_visualization.html#riflessioni-conclusive",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nUna visualizzazione ben progettata ha il potere di trasformare dati complessi in messaggi immediati, riducendo il carico cognitivo e facilitando decisioni più consapevoli. Disegnare un grafico non significa solo scegliere un formato piacevole: implica assumersi la responsabilità di comunicare i risultati in modo corretto, evitando di indurre interpretazioni fuorvianti.\nPer raggiungere questo obiettivo, occorre innanzitutto essere chiari sul messaggio che si vuole trasmettere. Un buon grafico è costruito intorno a una domanda precisa e guida lo sguardo del lettore verso gli elementi più rilevanti. Colori, forme e dimensioni non vanno scelti per decorare, ma per orientare l’attenzione: una palette limitata, ben calibrata e accessibile è spesso più efficace di combinazioni cromatiche elaborate. Allo stesso modo, titoli ed etichette devono essere semplici e intuitivi, evitando abbreviazioni o tecnicismi che potrebbero confondere.\nÈ importante anche saper gestire la densità dell’informazione. Quando i dati sono numerosi, tecniche come la trasparenza, il jitter o un eventuale sottocampionamento aiutano a prevenire il sovraccarico visivo e rendono le distribuzioni leggibili. Mostrare i dati grezzi, quando possibile, arricchisce l’interpretazione e riduce il rischio che le sintesi statistiche nascondano pattern interessanti.\nAlcune buone pratiche ricorrono in quasi tutte le situazioni: ordinare le categorie in base ai valori, e non alfabeticamente, facilita i confronti; mantenere assi coerenti rende più immediata la comparazione tra grafici; partire da zero negli assi dei barplot evita distorsioni nelle proporzioni; usare trasformazioni logaritmiche quando i valori coprono ordini di grandezza molto diversi permette di restituire visibilità anche ai dati più piccoli.\nAltre accortezze riguardano la scelta delle codifiche visive. L’aggiunta di variabili tramite colore, forma o dimensione può arricchire un grafico, ma solo se mantiene un equilibrio tra informazione e leggibilità. Le rappresentazioni tridimensionali, al contrario, raramente offrono un reale vantaggio: sono spesso più fuorvianti che utili. Infine, i numeri stessi vanno comunicati con sobrietà: un eccesso di decimali non rende il dato più preciso, ma soltanto più difficile da leggere.\nTutte queste regole devono sempre essere rapportate al pubblico a cui ci si rivolge. In un’analisi tecnica interna è possibile includere dettagli complessi, mentre per un pubblico non specializzato occorre semplificare, spiegare e accompagnare la visualizzazione con un linguaggio accessibile. In definitiva, progettare una buona visualizzazione non significa soltanto “disegnare un grafico”, ma costruire un ponte tra i dati e chi li interpreta, con l’obiettivo di rendere la conoscenza condivisibile e utile.\n\n\n\n\n\n\nEsercizi\n\n\n\n\n\nIn questo esercizio analizzerai i dati raccolti dagli studenti sulla Satisfaction With Life Scale (SWLS) e sulla Lubben Social Network Scale (LSNS-6). Le variabili incluse sono:\n\n\nSWLS: Punteggio totale della Scala di Soddisfazione per la Vita.\n\nLSNS-6: Punteggio totale sulla scala della rete sociale.\n\nGenere: Maschio/Femmina.\n\nTipo di scuola superiore: Liceo classico o scientifico vs. altro.\n\nNumero di amici: Auto-riferito.\n\nNumero di uscite settimanali con gli amici.\n\nUtilizzerai questi dati per esplorare le distribuzioni, creare visualizzazioni efficaci e interpretare i risultati.\nEsercizi Teorici\n\n\nPrincipi della visualizzazione\n\nQuali sono i principali segnali visivi utilizzati nella visualizzazione dei dati? Fornisci un esempio pratico per ognuno.\nPerché la posizione e la lunghezza sono considerati segnali visivi più efficaci rispetto all’area e agli angoli?\nSpiega perché i grafici tridimensionali (3D) sono spesso inutili o fuorvianti.\n\n\n\nScelta della visualizzazione\n\nQuale tipo di grafico useresti per mostrare la distribuzione della variabile SWLS? Giustifica la tua risposta.\nSe volessi confrontare la distribuzione della SWLS tra due gruppi (ad esempio, in base al genere), quale grafico useresti? Perché?\n\n\n\nErrori comuni nella visualizzazione\n\nPerché i dynamite plots (grafici a barre con errore standard) sono considerati una cattiva pratica?\nSpiega perché è importante iniziare l’asse Y da zero in un barplot.\nPerché è preferibile ordinare le categorie in base ai valori invece che alfabeticamente?\n\n\n\nEsercizi Pratici in R\n1. Caricamento e ispezione dei dati\nCarica il dataset raccolto dagli studenti (dati_SWLS_LSNS.csv) e stampa un’anteprima dei dati.\n# Caricamento dei dati\ndf &lt;- read.csv(\"dati_SWLS_LSNS.csv\")\n\n# Esamina le prime righe\nhead(df)\nRispondi alle seguenti domande:\n\nQuante osservazioni ci sono nel dataset?\nCi sono valori mancanti? Se sì, quanti?\n\n2. Distribuzione delle variabili\nCrea le seguenti visualizzazioni per analizzare la distribuzione di SWLS e LSNS-6:\n\n\nIstogramma con sovrapposta la curva di densità.\n\nFunzione di distribuzione cumulativa empirica (eCDF).\n\nBox plot per la variabile SWLS.\n\n3. Confronto tra gruppi\n\nCrea un box plot della SWLS per genere.\nCrea un violin plot della LSNS-6 in base al tipo di scuola superiore.\n\n4. Relazioni tra variabili\n\nCrea un grafico di dispersione (scatter plot) per verificare se c’è una relazione tra il punteggio SWLS e il numero di amici.\nAggiungi una linea di regressione al grafico per facilitare l’interpretazione.\n\nggplot(df, aes(x = numero_amici, y = SWLS)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n       x = \"Numero di amici\",\n       y = \"Satisfaction With Life Scale (SWLS)\")\nDomande:\n\nQuale relazione osservi tra il numero di amici e la SWLS?\nIl numero di amici è un buon predittore della soddisfazione per la vita?\n\n5. Esplorazione della rete sociale\n\nCrea un barplot per mostrare la distribuzione delle risposte medie ai sei item della LSNS-6.\nEsplora la relazione tra la frequenza delle uscite settimanali e il punteggio totale LSNS-6 utilizzando un box plot.\n\nConsegna\nSalva i grafici creati e rispondi alle domande in forma scritta. Carica il file su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Risposte alle domande teoriche\nPrincipi della visualizzazione\n\nI segnali visivi principali sono posizione, lunghezza, angoli, area, luminosità e colore.\nLa posizione e lunghezza sono i segnali più efficaci perché l’occhio umano è molto preciso nel confrontare distanze e altezze, mentre è meno efficace nel confrontare angoli e aree.\nI grafici tridimensionali (3D) spesso aggiungono confusione senza migliorare la leggibilità.\n\nScelta della visualizzazione\n\nPer mostrare la distribuzione della SWLS, è preferibile usare istogrammi e box plot perché evidenziano la forma della distribuzione e la presenza di outlier.\nPer confrontare la SWLS tra generi, un box plot o violin plot è l’opzione migliore, perché mostra la distribuzione completa.\n\nErrori comuni\n\nI dynamite plots nascondono la distribuzione dei dati e non mostrano la variabilità interna ai gruppi.\nIn un barplot, l’asse Y deve iniziare da zero per evitare distorsioni visive.\nLe categorie nei barplot devono essere ordinate per valore per facilitare il confronto.\n\n2. Soluzioni pratiche in R\nCaricamento dei dati\ndf &lt;- read.csv(\"dati_SWLS_LSNS.csv\")\n\n# Esamina il dataset\ndim(df)  # Numero di righe e colonne\nsum(is.na(df))  # Conteggio valori mancanti\nDistribuzione delle variabili\nggplot(df, aes(x = SWLS)) +\n  geom_histogram(\n  aes(y = after_stat(density)), bins = 10, fill = \"blue\", alpha = 0.5\n  ) +\n  geom_density(color = \"red\", size = 1.2)\nggplot(df, aes(SWLS)) +\n  stat_ecdf(geom = \"step\")\nggplot(df, aes(x = \"\", y = SWLS)) +\n  geom_boxplot() +\n  coord_flip()\nConfronto tra gruppi\nggplot(df, aes(x = genere, y = SWLS, fill = genere)) +\n  geom_boxplot()\nggplot(df, aes(x = scuola, y = LSNS6, fill = scuola)) +\n  geom_violin()\nRelazioni tra variabili\nggplot(df, aes(x = numero_amici, y = SWLS)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\nggplot(df, aes(x = uscite_settimanali, y = LSNS6)) +\n  geom_boxplot()\nConclusioni\n(Ad esempio) Le visualizzazioni mostrano che:\n\nSWLS e LSNS-6 variano in base al genere e al tipo di scuola.\nIl numero di amici ha un impatto positivo sulla SWLS, ma la relazione è moderata.\nIl numero di uscite settimanali è correlato positivamente con la rete sociale (LSNS-6).\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] stringr_1.5.1         ggrepel_0.9.6         dslabs_0.8.0         \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] pacman_0.5.1          digest_0.6.37         timechange_0.3.0     \n#&gt; [10] estimability_1.5.1    lifecycle_1.0.4       survival_3.8-3       \n#&gt; [13] magrittr_2.0.3        compiler_4.5.1        rlang_1.1.6          \n#&gt; [16] tools_4.5.1           knitr_1.50            labeling_0.4.3       \n#&gt; [19] bridgesampling_1.1-2  htmlwidgets_1.6.4     curl_7.0.0           \n#&gt; [22] pkgbuild_1.4.8        RColorBrewer_1.1-3    abind_1.4-8          \n#&gt; [25] multcomp_1.4-28       withr_3.0.2           purrr_1.1.0          \n#&gt; [28] grid_4.5.1            stats4_4.5.1          colorspace_2.1-1     \n#&gt; [31] xtable_1.8-4          inline_0.3.21         emmeans_1.11.2-8     \n#&gt; [34] scales_1.4.0          MASS_7.3-65           cli_3.6.5            \n#&gt; [37] mvtnorm_1.3-3         rmarkdown_2.29        ragg_1.5.0           \n#&gt; [40] generics_0.1.4        RcppParallel_5.1.11-1 cachem_1.1.0         \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_data_visualization.html#bibliografia",
    "href": "chapters/eda/05_data_visualization.html#bibliografia",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHealy, K. (2018). Data visualization: a practical introduction. Princeton University Press.\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".\n\n\nWilke, C. O. (2019). Fundamentals of data visualization: a primer on making informative and compelling figures. O’Reilly Media.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_loc_scale.html",
    "href": "chapters/eda/06_loc_scale.html",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "",
    "text": "Introduzione\nLa visualizzazione grafica dei dati rappresenta il pilastro fondamentale di ogni analisi quantitativa. Grazie alle rappresentazioni grafiche adeguate, è possibile individuare importanti caratteristiche di una distribuzione, quali la simmetria o l’asimmetria, nonché la presenza di una o più mode. Successivamente, al fine di descrivere sinteticamente le principali caratteristiche dei dati, si rende necessario l’utilizzo di specifici indici numerici. In questo capitolo, verranno presentati i principali indicatori della statistica descrittiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_loc_scale.html#introduzione",
    "href": "chapters/eda/06_loc_scale.html#introduzione",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "",
    "text": "Panoramica del capitolo\n\n\nTendenza centrale: Scelta della misura (media, mediana, moda) in base al tipo di dati e alla presenza di valori anomali.\n\nVariabilità: Interpretazione di range, varianza, deviazione standard e IQR per quantificare la dispersione dei dati attorno al valore centrale\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere “Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals” (Speelman et al., 2024).\nStudiare l’Appendice F.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tidyr, viridis, vcd)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_loc_scale.html#indici-di-tendenza-centrale",
    "href": "chapters/eda/06_loc_scale.html#indici-di-tendenza-centrale",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.1 Indici di tendenza centrale",
    "text": "19.1 Indici di tendenza centrale\nGli indici di tendenza centrale sono misure statistiche che cercano di rappresentare un valore tipico o centrale all’interno di un insieme di dati. Sono utilizzati per ottenere una comprensione immediata della distribuzione dei dati senza dover analizzare l’intero insieme. Gli indici di tendenza centrale sono fondamentali nell’analisi statistica, in quanto forniscono una sintesi semplice e comprensibile delle caratteristiche principali di un insieme di dati. I principali indici di tendenza centrale sono:\n\n\nMedia: La media è la somma di tutti i valori divisa per il numero totale di valori. È spesso utilizzata come misura generale di tendenza centrale, ma è sensibile agli estremi (valori molto alti o molto bassi).\n\nMediana: La mediana è il valore che divide l’insieme di dati in due parti uguali. A differenza della media, non è influenzata da valori estremi ed è quindi più robusta in presenza di outlier.\n\nModa: La moda è il valore che appare più frequentemente in un insieme di dati. In alcuni casi, può non essere presente o esserci più di una moda.\n\nLa scelta dell’indice di tendenza centrale appropriato dipende dalla natura dei dati e dall’obiettivo dell’analisi. Ad esempio, la mediana potrebbe essere preferita alla media se l’insieme di dati contiene valori anomali che potrebbero distorcere la rappresentazione centrale. La conoscenza e l’applicazione corretta di questi indici possono fornire una preziosa intuizione sulle caratteristiche centrali di una distribuzione di dati.\n\n19.1.1 Moda\nLa moda (\\(\\text{Mo}\\)) rappresenta il valore della variabile che compare con maggiore frequenza in una distribuzione. In altre parole, è il valore più ricorrente nei dati.\n\nNelle distribuzioni unimodali, esiste una sola moda, che coincide con il valore centrale della distribuzione più frequente.\n\nTuttavia, in alcune distribuzioni, possono emergere più di una moda, rendendole multimodali. In questi casi, la moda perde il suo significato di indicatore unico di tendenza centrale, poiché la presenza di più valori con frequenze elevate rende difficile individuare un singolo punto di riferimento.\n\n19.1.2 Mediana\nLa mediana (\\(\\tilde{x}\\)) corrisponde al valore che divide il campione in due metà: il 50% dei dati è inferiore o uguale alla mediana e il restante 50% è superiore o uguale. A differenza della media, la mediana è meno influenzata dai valori estremi, rendendola una misura particolarmente robusta in presenza di dati asimmetrici o outlier.\n\n19.1.3 Media\nLa media aritmetica di un insieme di valori rappresenta il punto centrale o il baricentro della distribuzione dei dati. È calcolata come la somma di tutti i valori divisa per il numero totale di valori, ed è espressa dalla formula:\n\\[\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i,\n\\tag{19.1}\\] dove \\(x_i\\) rappresenta i valori nell’insieme, \\(n\\) è il numero totale di valori, e \\(\\sum\\) indica la sommatoria.\n\n19.1.3.1 Calcolo della media con R\n\nPer calcolare la media di un piccolo numero di valori in R, possiamo utilizzare la somma di questi valori e dividerla per il numero totale di elementi. Consideriamo ad esempio i valori 12, 44, 21, 62, 24:\n\n(12 + 44 + 21 + 62 + 24) / 5\n#&gt; [1] 32.6\n\novvero\n\nx &lt;- c(12, 44, 21, 62, 24)\nmean(x)\n#&gt; [1] 32.6\n\n\n19.1.3.2 Media spuntata\nLa media spuntata, indicata come \\(\\bar{x}_t\\) o trimmed mean, è un metodo di calcolo della media che prevede l’eliminazione di una determinata percentuale di dati estremi prima di effettuare la media aritmetica. Solitamente, viene eliminato il 10% dei dati, ovvero il 5% all’inizio e alla fine della distribuzione. Per ottenere la media spuntata, i dati vengono ordinati in modo crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), e quindi viene eliminato il primo 5% e l’ultimo 5% dei dati nella sequenza ordinata. Infine, la media spuntata è calcolata come la media aritmetica dei dati rimanenti. Questo approccio è utile quando ci sono valori anomali o quando la distribuzione è asimmetrica e la media aritmetica non rappresenta adeguatamente la tendenza centrale dei dati.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nPer illustrare la media spuntata, utilizzeremo i dati del Progetto Natsal, contenuti nel file sexual-partners.csv.\nNegli anni ’80, con la crescente preoccupazione per l’AIDS, le autorità sanitarie del Regno Unito si resero conto della mancanza di dati affidabili sui comportamenti sessuali della popolazione. In particolare, vi erano dubbi sulla frequenza con cui le persone cambiavano partner, sul numero di partner simultanei e sulle pratiche sessuali adottate. Questa conoscenza era essenziale per prevedere la diffusione delle malattie sessualmente trasmissibili nella società e per pianificare adeguatamente i servizi sanitari. Tuttavia, si faceva ancora riferimento ai dati raccolti da Alfred Kinsey negli Stati Uniti negli anni ’40, che non tenevano conto della rappresentatività del campione.\nA partire dalla fine degli anni ’80, vennero dunque avviati nel Regno Unito e negli Stati Uniti ampi e rigorosi studi sui comportamenti sessuali, nonostante una forte opposizione in alcuni ambienti. Nel Regno Unito, il governo guidato da Margaret Thatcher ritirò il proprio sostegno a un’importante indagine sui comportamenti sessuali all’ultimo momento. Fortunatamente, i ricercatori riuscirono a ottenere finanziamenti da enti benefici, dando vita al National Sexual Attitudes and Lifestyles Survey (Natsal). Da allora, questa indagine viene condotta ogni dieci anni, a partire dal 1990. La terza rilevazione, denominata Natsal-3, è stata effettuata intorno al 2010.\nPoniamoci il problema di descrivere la tendenza centrale con la media spuntata per i dati contenuti nel file sexual-partners.csv, separatamente per maschi e femmine. Il dataset fornisce la distribuzione del numero totale dichiarato di partner sessuali di sesso opposto nella vita per uomini e donne di età compresa tra 35 e 44 anni. I dati provengono dal sondaggio Natsal-3 e corrispondono a un totale di 796 uomini e 1193 donne.\nProcediamo all’importazione dei dati per iniziare l’analisi.\n\nsexual_partners &lt;- rio::import(here::here(\"data\", \"sexual-partners.csv\"))\n\nEsaminiamo alcune righe prese a caso dal data frame sexual_partners:\n\nsexual_partners[sample(1:nrow(sexual_partners), size = 10, replace = FALSE), ]\n#&gt;      Gender NumPartners\n#&gt; 174     Man           3\n#&gt; 1235  Woman           3\n#&gt; 1588  Woman           8\n#&gt; 700     Man          30\n#&gt; 1117  Woman           3\n#&gt; 859   Woman           1\n#&gt; 1183  Woman           3\n#&gt; 1895  Woman          20\n#&gt; 136     Man           2\n#&gt; 833   Woman           1\n\nLa colonna Gender riporta il genere del rispondente e la colonna NumPartners il numero di partner sessuali di sesso opposto dichiarati.\nCalcoliamo la media spuntata per gli uomini:\n\nsex_partners_men &lt;- sexual_partners[sexual_partners$Gender == \"Man\", \"NumPartners\"]\nmean(sex_partners_men, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 10.6\n\nCalcoliamo la media spuntata per le donne:\n\nsex_partners_women &lt;- sexual_partners[sexual_partners$Gender == \"Woman\", \"NumPartners\"]\nmean(sex_partners_women, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 6.01\n\n\n\n\n\n19.1.3.3 Proprietà della media\nUna proprietà fondamentale della media è che la somma degli scarti di ciascun valore dalla media è zero:\n\\[\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\tag{19.2}\\] Infatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\] Questa proprietà implica che i dati sono equamente distribuiti intorno alla media.\nIn R abbiamo:\n\nsum(x - mean(x))\n#&gt; [1] -7.11e-15\n\n\n\n\n\n\n\nNota sulla notazione scientifica\n\n\n\n\n\nQuando in un terminale viene visualizzato un numero come -7.105e-15 in notazione scientifica, esso corrisponde a \\(-7.105 \\cdot 10^{-15}\\), che è effettivamente zero nel contesto dei calcoli numerici.\nQuesta approssimazione è una conseguenza diretta della precisione finita dei calcolatori. I sistemi digitali, infatti, rappresentano i numeri reali attraverso una codifica in virgola mobile (floating point), che comporta inevitabili errori di arrotondamento. La ragione risiede nell’impossibilità di memorizzare numeri reali con precisione assoluta.\nLo standard IEEE 754 a doppia precisione (64 bit), ampiamente utilizzato, suddivide la memoria in tre componenti:\n\n1 bit per il segno (positivo/negativo),\n\n11 bit per l’esponente (intervallo di scala),\n\n52 bit per la mantissa (o significando), che definisce le cifre significative.\n\nGrazie a questa struttura, è possibile rappresentare numeri con una precisione di circa 15-17 cifre decimali. Tuttavia, qualsiasi valore non esprimibile in formato binario entro questi limiti subisce un troncamento o un arrotondamento, generando piccole discrepanze rispetto al risultato teorico.\n\n\n\n\n19.1.3.4 La media come centro di gravità dell’istogramma\nLa media aritmetica può essere interpretata come il centro di gravità o il punto di equilibrio della distribuzione dei dati. In termini fisici, il centro di gravità è il punto in cui la massa di un sistema è equilibrata o concentrata.\nIn termini statistici, possiamo considerare la media come il punto in cui la distribuzione dei dati è in equilibrio. Ogni valore dell’insieme di dati può essere visto come un punto materiale con una massa proporzionale al suo valore. Se immaginiamo questi punti disposti su una linea, con valori più grandi a destra e più piccoli a sinistra, la media corrisponderà esattamente al punto in cui la distribuzione sarebbe in equilibrio.\n\n\n\n\n\n\nPrincipio dei minimi quadrati\n\n\n\n\n\nIl metodo dei minimi quadrati afferma che la posizione della media minimizza la somma dei quadrati delle distanze dai dati. Matematicamente, ciò significa che la somma dei quadrati degli scarti tra ciascun valore osservato e la media è minima. Questo principio è alla base dell’analisi statistica della regressione e conferma il ruolo della media come centro di gravità della distribuzione dei dati.\nSimulazione. Utilizziamo una simulazione per verificare questo principio, calcolando la somma dei quadrati degli scarti per diversi valori e visualizzando il risultato con ggplot2.\n\n# Definizione dell'intervallo di valori da testare\nnrep &lt;- 10000\nM &lt;- seq(20, 40, length.out = nrep)\nres &lt;- rep(NA, nrep)\n\n# Calcolo della somma dei quadrati degli scarti per ciascun valore di M\nfor (i in 1:nrep) {\n  res[i] = sum((x - M[i])^2)\n}\n\n# Identificazione del valore minimo\nmin_index &lt;- which.min(res)\nmin_M &lt;- M[min_index]\n\n# Creazione del dataframe per ggplot\ndf &lt;- data.frame(M, res)\n\ndf |&gt; \n  ggplot(aes(x = M, y = res)) +\n  geom_line(color = \"blue\") +\n  geom_vline(xintercept = min_M, linetype = \"dashed\", color = \"red\") +\n  labs(\n    x = \"Valore di M\",\n    y = \"Somma dei quadrati degli scarti\"\n  ) \n\n\n\n\n\n\n\nStampiamo il minimo:\n\nmin_M\n#&gt; [1] 32.6\n\nConfronto con la media:\n\nmean(x)\n#&gt; [1] 32.6\n\nOsserviamo che il valore di M che minimizza la somma dei quadrati degli scarti coincide con la media dei dati, confermando il principio dei minimi quadrati.\n\n\n\n\n19.1.3.5 Le proporzioni sono medie\nSe una collezione consiste solo di uni e zeri, allora la somma della collezione è il numero di uni in essa, e la media della collezione è la proporzione di uni.\n\nzero_one &lt;- c(1, 1, 1, 0)\nresult &lt;- mean(zero_one)\nresult\n#&gt; [1] 0.75\n\nÈ possibile sostituire 1 con il valore booleano True e 0 con False:\n\nmean(c(TRUE, TRUE, TRUE, FALSE))\n#&gt; [1] 0.75\n\n\n19.1.3.6 Limiti della media aritmetica\nLa media aritmetica, tuttavia, ha alcune limitazioni: non sempre è l’indice più adeguato per descrivere accuratamente la tendenza centrale della distribuzione, specialmente quando si verificano asimmetrie o valori anomali (outlier). In queste situazioni, è più indicato utilizzare la mediana o la media spuntata (come spiegheremo successivamente).\n\n\n\n\n\n\nCome descrivere la tendenza centrale in distribuzioni asimmetriche\n\n\n\n\n\nGli indici di tendenza centrale – moda, mediana e media – assumono significati molto diversi quando la distribuzione dei dati è asimmetrica. Per esempio, consideriamo i dati del Progetto Natsal (sexual-partners.csv), che riportano il numero di partner sessuali di sesso opposto dichiarati da uomini e donne (35–44 anni).\n\nEsplorazione dei dati.\n\nEstraggo dieci righe a caso:\n\nsexual_partners[sample(1:nrow(sexual_partners), 10), ]\n#&gt;      Gender NumPartners\n#&gt; 1517  Woman           7\n#&gt; 1590  Woman           8\n#&gt; 373     Man           7\n#&gt; 616     Man          20\n#&gt; 619     Man          20\n#&gt; 950   Woman           1\n#&gt; 907   Woman           1\n#&gt; 338     Man           6\n#&gt; 1071  Woman           2\n#&gt; 144     Man           2\n\nIl dataset contiene due colonne principali:\n\n\nGender: genere del rispondente,\n\nNumPartners: numero di partner sessuali dichiarati.\n\nVediamo quanti soggetti ci sono in ciascun gruppo:\n\nsexual_partners |&gt; \n  group_by(Gender) |&gt; \n  summarise(count = n())\n#&gt; # A tibble: 2 × 2\n#&gt;   Gender count\n#&gt;   &lt;chr&gt;  &lt;int&gt;\n#&gt; 1 Man      796\n#&gt; 2 Woman   1193\n\nIl numero massimo riportato è molto alto (oltre 500), ma per chiarezza limitiamo l’analisi a valori ≤ 50:\n\nsexual_partners |&gt; \n  group_by(Gender) |&gt; \n  summarise(maximum = max(NumPartners))\n#&gt; # A tibble: 2 × 2\n#&gt;   Gender maximum\n#&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1 Man        501\n#&gt; 2 Woman      550\n\n\nVisualizzazione.\n\nCalcoliamo e rappresentiamo la distribuzione dei partner (≤50) separatamente per genere:\n\nsexual_partners_truncated &lt;- sexual_partners |&gt; \n  filter(NumPartners &lt;= 50)\n\npercentage_data &lt;- sexual_partners_truncated %&gt;%\n  group_by(Gender, NumPartners) %&gt;%\n  summarise(Count = n(), .groups = \"drop\") %&gt;%\n  group_by(Gender) %&gt;%\n  mutate(Percentage = Count / sum(Count) * 100)\n\ny_max &lt;- max(percentage_data$Percentage)\n\ngender_labels &lt;- c(\"Man\" = \"Uomini 35–44\", \"Woman\" = \"Donne 35–44\")\n\npercentage_data |&gt;\n  ggplot(aes(NumPartners, Percentage, fill = Gender)) +\n  geom_col(position = \"dodge\", color = \"black\") +\n  facet_wrap(~Gender, labeller = labeller(Gender = gender_labels)) +\n  scale_y_continuous(limits = c(0, y_max)) +\n  labs(x = \"Numero di partner sessuali dichiarati\", y = \"Percentuale\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nLa distribuzione risulta altamente asimmetrica positiva: molti soggetti dichiarano pochi partner, pochi soggetti valori molto alti.\n\nIndici di tendenza centrale.\n\nCalcoliamo media, mediana e moda per ciascun genere:\n\nget_mode &lt;- function(x) {\n  tbl &lt;- table(x)\n  as.numeric(names(tbl)[which.max(tbl)])\n}\n\nsexual_partners_truncated |&gt; \n  group_by(Gender) |&gt; \n  summarise(\n    media   = mean(NumPartners, na.rm = TRUE),\n    mediana = median(NumPartners, na.rm = TRUE),\n    moda    = get_mode(NumPartners)\n  )\n#&gt; # A tibble: 2 × 4\n#&gt;   Gender media mediana  moda\n#&gt;   &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Man    11.4        7     1\n#&gt; 2 Woman   7.51       5     1\n\n\nInterpretazione.\n\n\n\nMedia: più alta di mediana e moda → influenzata dalla coda lunga a destra.\n\nMediana: valore centrale, meno influenzata da estremi → misura più robusta.\n\nModa: valore più frequente (1 partner), ma spesso poco rappresentativa in distribuzioni molto sparse.\n\n\nConclusioni pratiche.\n\n\nIn distribuzioni asimmetriche, la mediana è in genere l’indice di tendenza centrale più affidabile.\nÈ utile riportare anche media e moda per evidenziare le differenze.\nLa descrizione numerica va sempre accompagnata da una visualizzazione grafica (istogrammi, boxplot) per cogliere l’asimmetria e i valori estremi.\nUna descrizione completa richiede anche misure di dispersione, che vedremo nella sezione successiva.\n\n\n\n\n\n19.1.3.7 La media come rappresentazione della psicologia umana: un’arma a doppio taglio?\nLa media è uno degli strumenti statistici più semplici e intuitivi che i ricercatori utilizzano per sintetizzare i dati. È un indice di tendenza centrale familiare e intuitivo: se chiediamo a un gruppo di persone la loro età e calcoliamo la media, otteniamo un valore che sintetizza in un’unica cifra l’informazione disponibile. Ma cosa significa, in realtà, “riassumere” i dati con la media? E soprattutto, questa operazione ha senso quando si studiano i processi psicologici e il comportamento umano?\nIn molte discipline scientifiche, il concetto di media è utile perché descrive fenomeni che tendono a essere stabili e uniformi. Per esempio, se misuriamo l’altezza di un gruppo di persone, possiamo aspettarci che la distribuzione sia approssimativamente normale e che la media offra una stima ragionevole di un valore tipico. Tuttavia, la mente umana e i processi psicologici non funzionano come il sistema cardiovascolare o i muscoli. Ogni persona ha esperienze uniche che plasmano le sue risposte, i suoi pensieri e le sue emozioni.\nUn problema centrale, sollevato da Speelman & McGann (2013), riguarda l’implicita assunzione che ci sia un vero valore sottostante ai processi psicologici che possiamo stimare attraverso la media, come se il comportamento umano fosse determinato da meccanismi identici in ogni individuo, con le differenze attribuibili solo a “rumore” sperimentale. Questo approccio, tipico della psicologia sperimentale tradizionale, assume che testare un gruppo di persone e mediare i loro risultati ci permetta di rivelare la struttura comune della mente umana. Ma questa assunzione è davvero giustificata?\n\n19.1.3.8 La fallacia ergodica e l’illusione dell’universalità\nUn errore metodologico frequente nella psicologia è la cosiddetta fallacia ergodica, ovvero l’errata convinzione che le caratteristiche medie di un gruppo possano essere automaticamente applicate ai singoli individui che lo compongono (Speelman et al., 2024). Questo equivoco nasce dall’idea che la media descriva un valore “tipico” valido per tutti, senza considerare le differenze individuali o le variazioni nel tempo.\nImmaginiamo di studiare la felicità di un gruppo di persone nel corso di una settimana e di calcolare la media dei loro punteggi di benessere giornalieri. Se lunedì una persona ha un punteggio di 2 (molto infelice), mercoledì 5 (moderatamente felice) e sabato 8 (molto felice), il suo punteggio medio sarà 5. Tuttavia, questo valore intermedio non rappresenta in alcun modo la realtà soggettiva vissuta da quella persona nei singoli giorni. Lo stesso problema si pone quando si usano le medie per descrivere abilità cognitive, tratti di personalità o stati emotivi: la media può nascondere fluttuazioni e differenze individuali fondamentali per comprendere la psicologia umana.\nIl rischio, come sottolineato da Molden & Dweck (2006), è che il nostro desiderio di trovare universalità nei processi cognitivi ci porti a enfatizzare somiglianze tra le persone, ignorando le variazioni individuali che possono essere altrettanto, se non più, informative. Per esempio, due studenti con lo stesso punteggio medio in un test di memoria potrebbero aver ottenuto quel risultato in modi completamente diversi: uno potrebbe aver avuto prestazioni costantemente nella media, mentre l’altro potrebbe aver avuto picchi di eccellenza alternati a difficoltà estreme.\n\n19.1.3.9 La media: uno strumento da usare con cautela\nQuesti problemi non significano che la media sia inutile in psicologia. È un indicatore potente e spesso informativo, ma deve essere interpretato con cautela. In particolare, non può essere usata per fare inferenze sui singoli individui senza considerare altre misure, come la varianza e la deviazione standard, che ci dicono quanto i dati siano dispersi intorno alla media.\nIn psicologia, comprendere la variabilità è tanto importante quanto individuare una tendenza centrale. Se vogliamo davvero capire il comportamento umano, dobbiamo chiederci non solo qual è il valore medio? ma anche quanto variano i dati? e cosa ci dice questa variabilità sulle differenze individuali? Nella prossima sezione, esamineremo questi concetti e vedremo come la varianza e la deviazione standard ci aiutano a catturare le differenze che la media, da sola, non può rivelare.\n\n\n\n\n\n\nLa scelta della misura di tendenza centrale\n\n\n\n\n\nLa selezione della misura di tendenza centrale più adeguata è un aspetto fondamentale dell’analisi statistica. Tale scelta deve basarsi sulla natura dei dati a disposizione, sulla loro distribuzione e sulla potenziale presenza di valori anomali o asimmetrie. Comprendere le caratteristiche distintive di ciascun indicatore è cruciale per una rappresentazione corretta e significativa dell’informazione.\nLa Moda trova la sua principale applicazione nei dati di tipo categoriale o nominale, dove rappresenta l’unica misura di tendenza centrale calcolabile. La sua utilità è massima nelle distribuzioni unimodali, ovvero quelle in cui un unico valore emerge con frequenza predominante. Al contrario, in presenza di distribuzioni multimodali, caratterizzate da più picchi di frequenza, la moda perde di significatività, poiché l’identificazione di un singolo valore rappresentativo diventa impossibile. Nei dati continui, infine, la moda può spesso non essere definita o risultare poco informativa.\nLa Media Aritmetica è l’indicatore più comune e fornisce una stima eccellente della tendenza centrale per distribuzioni simmetriche e prive di valori anomali. Tuttavia, la media presenta una critica debolezza: la sua estrema sensibilità ai valori estremi. In distribuzioni asimmetriche o contaminata da outlier, la media subisce uno spostamento marcato verso la coda della distribuzione, finendo per non rappresentare più fedelmente la maggior parte dei dati.\nLa Media Spuntata si propone come una valida alternativa alla media tradizionale quando si sospetta la presenza di valori anomali. Questo indicatore, calcolato escludendo una certa percentuale dei valori più estremi (ad esempio, il 5% per ogni coda), offre un compromesso vantaggioso. Rispetto alla media, è molto più robusta agli outlier; rispetto alla mediana, tiene conto di un maggior numero di osservazioni, preservando parte dell’informazione contenuta nei dati.\nLa Mediana, essendo definita come il valore centrale di una distribuzione ordinata, possiede una robustezza intrinseca ai valori anomali. La sua natura posizionale fa sì che essa non venga influenzata dall’entità numerica dei dati, ma solo dal loro rango. Questo la rende la misura d’elezione per distribuzioni fortemente asimmetriche o con outlier. Inoltre, è l’indicatore preferibile per i dati ordinali, dove le distanze tra le categorie non sono definite numericamente.\nLinee guida per una scelta consapevole.\nPer distribuzioni simmetriche e unimodali, la media aritmetica costituisce generalmente la scelta ottimale, in quanto ne coglie appieno il centro. Quando si affrontano distribuzioni asimmetriche o dataset contenenti valori anomali, la mediana è da preferire per la sua innata resistenza a tali distorsioni. La media spuntata rappresenta un’ottima opzione quando si desidera attenuare l’impatto di pochi outlier senza rinunciare completamente all’informazione che forniscono. Per i dati categoriali (nominali), la moda è l’unica misura applicabile, a patto che la distribuzione sia unimodale. In scenari complessi come le distribuzioni multimodali, nessuna singola misura è sufficiente a descrivere la tendenza centrale. In questi casi, è indispensabile affiancare agli indicatori statistici una visualizzazione grafica (ad esempio un istogramma) e una descrizione analitica dei diversi picchi presenti.\nIn sintesi, non esiste una misura migliore in assoluto. La media è potente per dati simmetrici, la mediana è lo strumento robusto per proteggersi dalle distorsioni, la media spuntata è un utile compromesso e la moda è essenziale per i dati categoriali. La scelta deve sempre essere guidata da una attenta valutazione preliminare della distribuzione dei dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_loc_scale.html#la-variabilità-nei-dati-psicologici",
    "href": "chapters/eda/06_loc_scale.html#la-variabilità-nei-dati-psicologici",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.2 La variabilità nei dati psicologici",
    "text": "19.2 La variabilità nei dati psicologici\nNei fenomeni psicologici e comportamentali, la variabilità è una caratteristica intrinseca. Ad esempio, se misuriamo il livello di stress percepito da una persona più volte nella stessa giornata, è raro osservare lo stesso valore anche utilizzando strumenti identici. Allo stesso modo, un questionario standardizzato sull’autostima somministrato a un gruppo di studenti universitari restituirà punteggi differenti per ciascun partecipante. Anche registrando i tempi di reazione in un compito cognitivo, noteremo fluttuazioni sia tra individui diversi sia nelle prestazioni dello stesso individuo in prove ripetute.\nQuesta dispersione sistematica non è un “rumore” da ignorare, ma un elemento informativo cruciale. L’analisi statistica in psicologia ha infatti uno scopo duplice: da un lato, quantificare la variabilità; dall’altro, identificarne le origini. Differenze individuali, contesto ambientale, errori di misurazione o interazioni tra fattori sono solo alcune delle possibili fonti che contribuiscono alla variazione osservata.\nIn questa sezione esploreremo:\n\n\nLa scomposizione della variabilità in componenti spiegate (attribuibili a fattori noti, come un intervento sperimentale) e non spiegate (legate a elementi casuali o non controllati).\n\n\nStrumenti per descriverla, sia attraverso rappresentazioni grafiche (boxplot, istogrammi) sia mediante indici numerici (differenza interquartile, varianza, deviazione standard).\n\nComprendere la variabilità non è un esercizio tecnico, ma un passo fondamentale per interpretare fenomeni complessi come le differenze di personalità, le oscillazioni emotive o l’efficacia di una terapia. Ogni modello psicologico, infatti, deve fare i conti con questa dimensione dinamica e multideterminata dei dati.\n\n19.2.1 Quantili\nAccanto alle misure di tendenza centrale, i quantili descrivono la posizione relativa di un’osservazione in una distribuzione. Se media, mediana e moda individuano un valore “tipico”, i quantili rispondono invece a una domanda diversa: qual è il valore al di sotto del quale si colloca una determinata proporzione dei dati?\n\n19.2.1.1 Definizione\nIl quantile di ordine \\(p\\) (\\(0 &lt; p &lt; 1\\)) è il valore \\(q_p = x_{(k)}\\), dove \\(x_{(k)}\\) rappresenta il \\(k\\)-esimo elemento dei dati ordinati in senso crescente e \\(k = \\lceil p \\cdot n \\rceil\\), con \\(n\\) numero totale di osservazioni e \\(\\lceil \\cdot \\rceil\\) funzione di arrotondamento per eccesso. Questo è il cosiddetto quantile non interpolato. Quando \\(p \\cdot n\\) non è intero, si ricorre di norma all’interpolazione lineare tra due osservazioni consecutive: è il metodo implementato nei principali software statistici.\nPer chiarire, consideriamo i dati ordinati \\({15, 20, 23, 25, 28, 30, 35, 40, 45, 50}\\). Il 30° percentile (\\(p=0.3\\)) si calcola come \\(k = \\lceil 0.3 \\cdot 10 \\rceil = 3\\), dunque \\(q_{0.3} = 23\\).\n\n19.2.1.2 Percentili e quartili\nUn caso particolare sono i percentili, che suddividono la distribuzione in cento parti uguali. Il 25° percentile (o primo quartile \\(Q_1\\)) lascia al di sotto di sé un quarto dei dati, il 50° percentile corrisponde alla mediana e il 75° percentile (terzo quartile \\(Q_3\\)) delimita i tre quarti inferiori della distribuzione.\n\n19.2.1.3 Esempio applicativo\nPer illustrare l’uso dei quantili, consideriamo la variabile NumPartners, distinta per genere. Calcoliamo il 10° e il 90° percentile.\n\n# Quantili per gli uomini\nquantile(\n  sexual_partners[sexual_partners$Gender == \"Man\", \"NumPartners\"], \n  probs = c(0.1, 0.9)\n  )\n#&gt;  10%  90% \n#&gt;  1.0 34.5\n\n# Quantili per le donne\nquantile(\n  sexual_partners[sexual_partners$Gender == \"Woman\", \"NumPartners\"], \n  probs = c(0.1, 0.9)\n  )\n#&gt; 10% 90% \n#&gt;   1  18\n\nI risultati mostrano che, tra gli uomini, il 10% ha dichiarato al massimo un partner, mentre il 10% con i valori più elevati supera i 34 partner. Tra le donne, il 10° percentile coincide ancora con un partner, ma il 90° percentile non va oltre 18.\nQuesta differenza indica che le distribuzioni dei due gruppi condividono una base simile (molti individui con pochi partner) ma divergono nella coda superiore: negli uomini, pochi soggetti con valori estremi spingono la distribuzione verso destra, generando una maggiore asimmetria positiva.\n\n19.2.1.4 Misure di dispersione basate sui quantili\nI quantili possono essere utilizzati anche per costruire indici di variabilità che non fanno ipotesi sulla forma della distribuzione. La misura più semplice è l’intervallo di variazione, pari alla differenza tra valore massimo e minimo. Questo indice è immediato da calcolare, ma dipende esclusivamente dagli estremi e risulta quindi molto sensibile agli outlier.\n\nx &lt;- c(12, 18, 20, 22, 25, 28, 30, 35)\nrange(x)\n#&gt; [1] 12 35\ndiff(range(x))\n#&gt; [1] 23\n\nNell’esempio l’intervallo è 23, valore che descrive l’ampiezza complessiva dei dati ma non la loro distribuzione interna.\nUn indicatore più robusto è la differenza interquartile (IQR), che misura la distanza fra il terzo e il primo quartile, racchiudendo così il 50% centrale dei dati.\n\nIQR(x)\n#&gt; [1] 9\n\nSe in un gruppo di studenti i quartili sono \\(Q_1 = 25\\) e \\(Q_3 = 40\\), l’IQR è pari a 15: significa che metà dei punteggi si colloca in un intervallo di 15 unità. Questo indice riduce l’influenza dei valori estremi, anche se non rappresenta l’intera dispersione della distribuzione.\nIn sintesi, l’intervallo di variazione e l’IQR offrono due prospettive complementari: il primo fornisce un’idea immediata dell’ampiezza totale dei dati, il secondo descrive la variabilità tipica della parte centrale della distribuzione. Entrambi hanno limiti che rendono necessario affiancarli a misure più complete, come la varianza e la deviazione standard, di cui parleremo nella sezione successiva.\n\n19.2.2 La varianza\nLa varianza è una delle misure di dispersione più utilizzate in statistica perché tiene conto di tutte le osservazioni e descrive quanto i valori si discostano dalla loro media. Formalmente, se abbiamo \\(n\\) osservazioni \\(x_1, x_2, \\dots, x_n\\) e indichiamo con \\(\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\\) la loro media, la varianza (in versione descrittiva) si calcola così:\n\\[\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2.\n\\tag{19.3}\\] In altre parole, per trovare la varianza:\n\ncalcoliamo la media di tutti i valori (\\(\\bar{x}\\)),\nsottraiamo la media a ciascun valore, ottenendo così lo scarto \\((x_i - \\bar{x})\\),\neleviamo ogni scarto al quadrato, per rendere positivi i valori ed enfatizzare gli scostamenti più grandi,\ninfine, facciamo la media di questi quadrati.\n\nMaggiore è la varianza, maggiore è la variabilità (o dispersione) dei dati rispetto alla media. Al contrario, una varianza prossima allo zero indica che le osservazioni sono molto vicine tra loro e quasi coincidenti con la media.\n\nNota su popolazione e campione. Spesso, nell’analisi di dati campionari, la varianza viene calcolata usando \\(\\frac{1}{n-1}\\) al denominatore al posto di \\(\\frac{1}{n}\\). In questo modo otteniamo una stima corretta (non distorta) della varianza della popolazione. Nel contesto della formula sopra riportata, invece, stiamo calcolando la varianza descrittiva (o popolazione completa).\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nImmaginiamo di aver misurato il numero di ore di studio giornaliere di un piccolo gruppo di partecipanti a un esperimento di psicologia. I dati raccolti sono:\n\\[\nx = \\{3,\\, 1,\\, 4,\\, 2\\}.\n\\]\nPasso 1: Calcolo della media\n\\[\n\\bar{x} = \\frac{3 + 1 + 4 + 2}{4} = \\frac{10}{4} = 2.5.\n\\]\nPasso 2: Scarti dalla media\n\nPer il primo valore (\\(x_1 = 3\\)): \\(3 - 2.5 = 0.5\\)\n\nPer il secondo valore (\\(x_2 = 1\\)): \\(1 - 2.5 = -1.5\\)\n\nPer il terzo valore (\\(x_3 = 4\\)): \\(4 - 2.5 = 1.5\\)\n\nPer il quarto valore (\\(x_4 = 2\\)): \\(2 - 2.5 = -0.5\\)\n\n\nPasso 3: Quadrati degli scarti\n\n\\((0.5)^2 = 0.25\\)\n\\((-1.5)^2 = 2.25\\)\n\\((1.5)^2 = 2.25\\)\n\\((-0.5)^2 = 0.25\\)\n\nPasso 4: Calcolo della varianza\nFacciamo la media di questi valori:\n\\[\nS^2 = \\frac{0.25 + 2.25 + 2.25 + 0.25}{4} = \\frac{5}{4} = 1.25.\n\\]\nDunque la varianza è 1.25.\n\n\n\n\n19.2.2.1 Interpretazione\nNel caso dell’esempio precedente relativo alle ore di studio giornaliere, una varianza pari a 1.25 indica che le ore di studio giornaliere si discostano, in media, di 1.25 unità quadrate dalla media di 2.5 ore. Per comprendere meglio l’ordine di grandezza di questa dispersione, solitamente si fa riferimento alla deviazione standard, che è la radice quadrata della varianza. In questo caso, \\(\\sqrt{1.25} \\approx 1.12\\) ore.\n\nSe la varianza (o la deviazione standard) fosse stata molto più grande, avremmo dedotto che gli studenti del campione presentano abitudini di studio molto diverse.\nAl contrario, se la varianza fosse prossima a 0, significherebbe che quasi tutti studiano un numero di ore molto simile a 2.5.\n\n19.2.2.2 Calcolo in R\nSe volessimo effettuare in R i calcoli relativi all’esempio sulle ore di studio, potremmo fare così:\n\n# Dati\nx &lt;- c(3, 1, 4, 2)\n\n# Calcolo manuale della media\nmedia_x &lt;- mean(x)\n\n# Calcolo manuale della varianza secondo la formula descrittiva\nvarianza_descr &lt;- mean((x - media_x)^2)\nvarianza_descr\n#&gt; [1] 1.25\n# [1] 1.25\n\n# Calcolo della varianza con la funzione var() di R\n# (Attenzione: per default var() usa n-1 al denominatore)\nvarianza_campionaria &lt;- var(x)\nvarianza_campionaria\n#&gt; [1] 1.67\n# [1] 1.666667\n\nOsserviamo che var(x) dà un valore di circa 1.67 perché R, di default, calcola la varianza campionaria (con \\(n-1\\) al denominatore). Se vogliamo la varianza descrittiva (come nella formula con \\(n\\) al denominatore), usiamo la nostra varianza_descr.\nIn sintesi, la varianza fornisce un modo per quantificare quanto siano diverse tra loro le osservazioni. Nel caso dell’esempio sulle ore di studio, abbiamo visto che i valori, pur non essendo tutti identici, non mostrano una dispersione eccessiva (la varianza è 1.25). Se i comportamenti di studio fossero estremamente diversificati (per esempio, se qualcuno studiasse 0 ore al giorno e qualcun altro 10), la varianza sarebbe molto più elevata, indicando una marcata eterogeneità nel campione.\n\n19.2.2.3 Stima della varianza della popolazione\nSi noti il denominatore della formula della varianza. Nell’Equazione 19.3, ho utilizzato \\(n\\) come denominatore (l’ampiezza campionaria, ovvero il numero di osservazioni nel campione). In questo modo, otteniamo la varianza come statistica descrittiva del campione. Tuttavia, è possibile utilizzare \\(n-1\\) come denominatore alternativo:\n\\[\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2 .\n\\tag{19.4}\\] In questo secondo caso, otteniamo la varianza come stimatore della varianza della popolazione. Si può dimostrare che l’Equazione 19.4 fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre l’Equazione 19.3 fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: \\(S^2\\) rappresenta la varianza come statistica descrittiva, mentre \\(s^2\\) rappresenta la varianza come stimatore.\n\n\n\n\n\n\nSimulazione\n\n\n\n\n\nPer illustrare questo punto, svolgiamo una simulazione. Consideriamo la distribuzione dei punteggi del quoziente di intelligenza (QI). I valori del QI seguono una particolare distribuzione chiamata distribuzione normale (v. Capitolo 20), con media 100 e deviazione standard 15. La forma di questa distribuzione è illustrata nella figura seguente.\n\n# Define parameters\nx &lt;- seq(100 - 4 * 15, 100 + 4 * 15, by = 0.001)\nmu &lt;- 100\nsigma &lt;- 15\n\n# Compute the PDF\npdf &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Plot using ggplot2\ndata &lt;- tibble(x = x, pdf = pdf)\nggplot(data, aes(x = x, y = pdf)) +\n  geom_line() +\n  labs(\n    x = \"QI\", \n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\nSupponiamo di estrarre un campione casuale di 4 osservazioni dalla popolazione del quoziente di intelligenza – in altre parole, supponiamo di misurare il quoziente di intelligenza di 4 persone prese a caso dalla popolazione.\n\nset.seed(123) \nx &lt;- rnorm(4, mean = 100, sd = 15)\nprint(x)\n#&gt; [1]  91.6  96.5 123.4 101.1\n\nCalcoliamo la varianza usando \\(n\\) al denominatore. Si noti che la vera varianza del quoziente di intelligenza è \\(15^2\\) = 225.\n\nvar(x)\n#&gt; [1] 197\n\nConsideriamo ora 10 campioni casuali del QI, ciascuno di ampiezza 4.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10\nrandom_samples &lt;- list()\n\nset.seed(123) \n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nIl primo campione è\n\nrandom_samples[1]\n#&gt; [[1]]\n#&gt; [1]  91.6  96.5 123.4 101.1\n\nIl decimo campione è\n\nrandom_samples[10]\n#&gt; [[1]]\n#&gt; [1] 108.3  99.1  95.4  94.3\n\nStampiamo i valori di tutti i 10 campioni.\n\nrs &lt;- do.call(rbind, random_samples)\nrs\n#&gt;        [,1]  [,2]  [,3]  [,4]\n#&gt;  [1,]  91.6  96.5 123.4 101.1\n#&gt;  [2,] 101.9 125.7 106.9  81.0\n#&gt;  [3,]  89.7  93.3 118.4 105.4\n#&gt;  [4,] 106.0 101.7  91.7 126.8\n#&gt;  [5,] 107.5  70.5 110.5  92.9\n#&gt;  [6,]  84.0  96.7  84.6  89.1\n#&gt;  [7,]  90.6  74.7 112.6 102.3\n#&gt;  [8,]  82.9 118.8 106.4  95.6\n#&gt;  [9,] 113.4 113.2 112.3 110.3\n#&gt; [10,] 108.3  99.1  95.4  94.3\n\nPer ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando la formula con \\(n\\) al denominatore. Otteniamo così 10 stime della varianza della popolazione del QI.\n\nx_var &lt;- apply(rs, 1, var)  # Applica la funzione var su ciascuna riga\nprint(x_var)\n#&gt;  [1] 196.94 337.54 168.55 218.68 333.48  34.52 264.38 234.08   1.97  40.47\n\nNotiamo due cose:\n\nle stime sono molto diverse tra loro; questo fenomeno è noto con il nome di variabilità campionaria;\nin media le stime sono troppo piccole.\n\nPer aumentare la sicurezza riguardo al secondo punto menzionato in precedenza, ripeteremo la simulazione utilizzando un numero di iterazioni maggiore.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nset.seed(123) # Replace 123 with your desired seed for reproducibility\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var) * (size - 1) / size  # Adjust for population variance (ddof = 0)\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\n# Create a data frame for plotting\ndata &lt;- data.frame(x_var = x_var)\n\n# Plot the histogram using ggplot2\nggplot(data, aes(x = x_var)) +\n  geom_histogram(fill = \"lightblue\", bins = 30, color = \"black\") +\n  scale_x_continuous(limits = c(0, 1500)) +\n  scale_y_continuous(limits = c(0, 2250)) +\n  labs(\n    x = \"Varianza\", \n    y = \"Frequenza\"\n  )\n\n\n\n\n\n\n\nLa stima più verosimile della varianza del QI è dato dalla media di questa distribuzione.\n\nmean(x_var)\n#&gt; [1] 169\n\nSi noti che il nostro spospetto è stato confermato: il valore medio della stima della varianza ottenuta con l’Equazione 19.3 è troppo piccolo rispetto al valore corretto di \\(15^2 = 225\\).\nRipetiamo ora la simulazione usando la formula della varianza con \\(n-1\\) al denominatore.\n\nset.seed(123) \n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var)  # ddof = 1 is default for var in R\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\n# Create a data frame for plotting\ndata &lt;- data.frame(x_var = x_var)\n\n# Plot the histogram using ggplot2\nggplot(data, aes(x = x_var)) +\n  geom_histogram(fill = \"lightblue\", bins = 30, color = \"black\") +\n  scale_x_continuous(limits = c(0, 1500)) +\n  scale_y_continuous(limits = c(0, 2250)) +\n  labs(\n    x = \"Varianza Corretta\", \n    y = \"Frequenza\"\n  )\n\n\n\n\n\n\n\nNel secondo caso, se utilizziamo \\(n-1\\) come denominatore per calcolare la stima della varianza, il valore atteso di questa stima è molto vicino al valore corretto di 225. Se il numero di campioni fosse infinito, i due valori sarebbero identici.\n\nmean(x_var)\n#&gt; [1] 225\n\nIn conclusione, le due formule della varianza hanno scopi diversi.\n\nLa formula della varianza con \\(n\\) al denominatore viene utilizzata come statistica descrittiva per descrivere la variabilità di un particolare campione di osservazioni.\nD’altro canto, la formula della varianza con \\(n-1\\) al denominatore viene utilizzata come stimatore per ottenere la migliore stima della varianza della popolazione da cui quel campione è stato estratto.\n\n\n\n\n\n19.2.3 Deviazione standard\nPer interpretare la varianza in modo più intuitivo, si può calcolare la deviazione standard (o scarto quadratico medio o scarto tipo) prendendo la radice quadrata della varianza. La deviazione standard è espressa nell’unità di misura originaria dei dati, a differenza della varianza che è espressa nel quadrato dell’unità di misura dei dati. La deviazione standard fornisce una misura della dispersione dei dati attorno alla media, rendendo più facile la comprensione della variabilità dei dati.\nLa deviazione standard (o scarto quadratico medio, o scarto tipo) è definita come:\n\\[\ns^2 = \\sqrt{(n-1)^{-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}.\n\\tag{19.5}\\] Quando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s &gt; 0\\).\n\n\n\n\n\n\nIl termine standard deviation è stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca \\(\\sigma\\) che lo rappresenta. Il termine italiano “deviazione standard” ne è la traduzione più utilizzata nel linguaggio comune; il termine dell’Ente Nazionale Italiano di Unificazione è tuttavia “scarto tipo”, definito come la radice quadrata positiva della varianza.\n\n\n\nLa deviazione standard \\(s\\) dovrebbe essere utilizzata solo quando la media è una misura appropriata per descrivere il centro della distribuzione, ad esempio nel caso di distribuzioni simmetriche. Tuttavia, è importante tener conto che, come la media \\(\\bar{x}\\), anche la deviazione standard è fortemente influenzata dalla presenza di dati anomali, ovvero pochi valori che si discostano notevolmente dalla media rispetto agli altri dati della distribuzione. In presenza di dati anomali, la deviazione standard può risultare ingannevole e non rappresentare accuratamente la variabilità complessiva della distribuzione. Pertanto, è fondamentale considerare attentamente il contesto e le caratteristiche dei dati prima di utilizzare la deviazione standard come misura di dispersione. In alcune situazioni, potrebbe essere più appropriato ricorrere a misure di dispersione robuste o ad altre statistiche descrittive per caratterizzare la variabilità dei dati in modo più accurato e affidabile.\n\n19.2.3.1 Interpretazione\nLa deviazione standard misura la dispersione dei dati rispetto alla media aritmetica. In termini semplici, indica quanto, in media, ciascun valore osservato si discosta dalla media del campione. Anche se è simile allo scarto semplice medio campionario (la media dei valori assoluti degli scarti rispetto alla media), la deviazione standard utilizza lo scarto quadratico medio e produce un valore leggermente diverso.\n\nEsempio 19.1 Per verificare l’interpretazione della deviazione standard, utilizziamo i punteggi relativi alle ore di studio di un piccolo numero di studenti.\n\nx &lt;- c(3, 1, 4, 2)\n\nstd_x &lt;- sqrt(var(x) * 3 / 4)\nstd_x\n#&gt; [1] 1.12\n\nLa deviazione standard calcolata è 1.12. Questo valore ci dice che, in media, ciascun punteggio si discosta di circa 1.12 ore dalla media aritmetica delle ore di studio di questo gruppo di studenti.\n\nValore più alto: indica maggiore dispersione dei dati intorno alla media.\nValore più basso: i dati sono più concentrati vicino alla media.\n\nSe calcoliamo anche lo scarto semplice medio campionario per confronto, otteniamo:\n\nmean(abs(x - mean(x)))\n#&gt; [1] 1\n\nI due valori (deviazione standard e scarto semplice medio) sono simili ma non identici, a causa delle diverse definizioni matematiche.\n\n\n19.2.4 Varianza spiegata e non spiegata\nLa varianza, come abbiamo visto, misura quanto i dati si disperdono attorno alla media. Un concetto fondamentale nei modelli statistici lineari è la distinzione tra varianza spiegata e varianza non spiegata, che ci permette di valutare quanto bene un modello teorico riesca a chiarire la variabilità osservata nei dati.\n\n19.2.4.1 Decomposizione della varianza\nQuando osserviamo un fenomeno (ad esempio i risultati di un test), troviamo inevitabilmente differenze tra individui. Queste differenze possono essere suddivise in due componenti principali:\n\n\nvarianza spiegata: la parte di variabilità che può essere attribuita a fattori identificati e misurabili;\n\nvarianza non spiegata: la parte rimanente di variabilità che non è chiarita dai fattori considerati.\n\nFormalmente, questa decomposizione può essere espressa come:\n\\[\n\\sum_{i=1}^{n}(Y_i - \\bar{Y})^2 = \\sum_{i=1}^{n}(\\hat{Y}_i - \\bar{Y})^2 + \\sum_{i=1}^{n}(Y_i - \\hat{Y}_i)^2 ,\n\\] dove:\n\n\n\\(Y_i\\) sono i dati osservati,\n\n\\(\\bar{Y}\\) è la media dei dati osservati,\n\n\\(\\hat{Y}_i\\) sono i valori attesi (previsti) dal modello teorico.\n\nIntuitivamente:\n\nla varianza totale (lato sinistro della formula) rappresenta la dispersione complessiva dei dati attorno alla loro media;\nla varianza spiegata (primo termine a destra) indica quanto bene i valori previsti dal modello descrivono il comportamento dei dati;\nla varianza non spiegata (secondo termine a destra) riflette ciò che il modello non riesce a prevedere.\n\n\n\n\n\n\n\nSimulazione\n\n\n\n\n\nSupponiamo di analizzare i punteggi di un esame universitario di “Psicometria” ottenuti da 200 studenti. La nostra teoria indica che i punteggi dipendano da:\n\nOre settimanali dedicate allo studio;\nPresenza o assenza di “paura della matematica” (math anxiety) (Barroso et al., 2021).\n\nNello specifico, ipotizziamo:\n\nuna relazione positiva tra ore di studio e punteggio ottenuto;\nuna riduzione del 30% del punteggio per chi presenta paura della matematica rispetto agli altri studenti, a parità di ore di studio.\n\nEcco la simulazione in R:\n\nset.seed(123)\n\n# Simuliamo i dati per 200 studenti\nn &lt;- 200\nore_studio &lt;- runif(n, min = 2, max = 15) |&gt; round()\npaura_mat &lt;- rbinom(n, 1, prob = 0.3)\n\nk &lt;- 2  # Ogni ora di studio corrisponde a circa 2 punti\n\n# Calcoliamo i punteggi attesi, limitati a 30 punti massimo\npunteggio_atteso &lt;- ore_studio * k * ifelse(paura_mat == 1, 0.7, 1) |&gt; round()\npunteggio_atteso &lt;- ifelse(punteggio_atteso &gt; 30, 30, punteggio_atteso)\n\n# Generiamo punteggi reali aggiungendo casualità (tra 0 e 30 punti)\npunteggio_reale &lt;- (punteggio_atteso + rnorm(n, mean = 0, sd = 3)) |&gt; round()\npunteggio_reale &lt;- pmin(pmax(punteggio_reale, 0), 30)\n\n# Creiamo il dataset finale\ndata &lt;- data.frame(ore_studio, paura_mat, punteggio_atteso, punteggio_reale)\nhead(data)\n#&gt;   ore_studio paura_mat punteggio_atteso punteggio_reale\n#&gt; 1          6         0               12              19\n#&gt; 2         12         1               24              28\n#&gt; 3          7         0               14              13\n#&gt; 4         13         0               26              28\n#&gt; 5         14         0               28              27\n#&gt; 6          3         1                6               5\n\nCalcoliamo ora la decomposizione della varianza usando le formule indicate:\n\n# Media dei punteggi reali\nmedia_reale &lt;- mean(data$punteggio_reale)\n\n# Calcolo delle componenti della varianza\nvarianza_totale &lt;- mean((data$punteggio_reale - media_reale)^2)\nvarianza_spiegata &lt;- mean((data$punteggio_atteso - media_reale)^2)\nvarianza_non_spiegata &lt;- mean((data$punteggio_reale - data$punteggio_atteso)^2)\n\n# Risultati\nc(varianza_totale, varianza_spiegata, varianza_non_spiegata)\n#&gt; [1] 60.37 51.65  8.29\n\nInterpretazione dei risultati:\n\nla varianza totale indica quanto in generale i punteggi differiscono tra loro,\nla varianza spiegata rappresenta quanto della variabilità totale può essere attribuita ai fattori teorici (ore di studio e paura della matematica),\nla varianza non spiegata evidenzia la variabilità residua che il modello non riesce a cogliere.\n\nLa proporzione di varianza spiegata è data dal rapporto:\n\nprop_spiegata &lt;- varianza_spiegata / varianza_totale\nprop_spiegata\n#&gt; [1] 0.856\n\nQuesta proporzione è sempre compresa tra 0 e 1:\n\nvalori vicini a 1 indicano che il modello è efficace nel descrivere i dati;\nvalori vicini a 0 suggeriscono che il modello non cattura adeguatamente la realtà osservata.\n\nQuesta decomposizione della varianza è uno strumento cruciale per valutare l’efficacia delle teorie e dei modelli statistici. Approfondiremo ulteriormente questi aspetti nel capitolo dedicato ai modelli di regressione (v. Capitolo 55).\n\n\n\n\n19.2.5 Deviazione mediana assoluta\nLa deviazione mediana assoluta (MAD) è una misura robusta di dispersione basata sulla mediana. È definita come la mediana dei valori assoluti delle deviazioni dei dati rispetto alla mediana:\n\\[\n\\text{MAD} = \\text{median} \\left( |X_i - \\text{median}(X)| \\right)\n\\tag{19.6}\\] La MAD è particolarmente utile per analizzare dati contenenti outlier o distribuzioni asimmetriche, poiché è meno influenzata dai valori estremi rispetto alla deviazione standard.\n\n19.2.5.1 Relazione tra MAD e deviazione standard in una distribuzione normale\nQuando i dati seguono una distribuzione normale (gaussiana), esiste una relazione approssimativa tra MAD e deviazione standard. La MAD può essere convertita in una stima della deviazione standard moltiplicandola per una costante di 1.4826:\n\\[\n\\sigma \\approx k \\times \\text{MAD},\n\\] dove:\n\n\n\\(\\sigma\\) è la deviazione standard,\nMAD è la Mediana della Deviazione Assoluta,\n\n\\(k\\) è una costante che, per una distribuzione normale, è tipicamente presa come circa 1.4826.\n\nQuesta costante deriva dalla proprietà della distribuzione normale, in cui circa il 50% dei valori si trova entro 0.6745 deviazioni standard dalla media.\nLa formula completa per convertire la MAD in una stima della deviazione standard in una distribuzione normale è:\n\\[\n\\sigma \\approx 1.4826 \\times \\text{MAD}\n\\] Questa relazione è utile per stimare la deviazione standard in modo più robusto, specialmente quando si sospetta la presenza di outlier o si ha a che fare con campioni piccoli. Di conseguenza, molti software restituiscono il valore MAD moltiplicato per questa costante per fornire un’indicazione più intuitiva della variabilità dei dati. Tuttavia, è importante notare che questa relazione si mantiene accurata solo per le distribuzioni che sono effettivamente normali. In presenza di distribuzioni fortemente asimmetriche o con elevati outlier, la deviazione standard e la MAD possono fornire indicazioni molto diverse sulla variabilità dei dati.\n\n\n\n\n\n\nDimostrazione numerica\n\n\n\n\n\nPer verificare questo principio, usiamo un campione di dati simulati dalla distribuzione del QI:\n\nqi &lt;- rnorm(200, 100, 15)\n1.4826 * median(abs(qi - median(qi)), na.rm = TRUE)\n#&gt; [1] 14.1\n\nOtteniamo un valore che è simile alla deviazione standard calcolata con:\n\nsqrt(\n  var(qi) * (length(qi) - 1) / length(qi)\n)\n#&gt; [1] 14.4\n\nCiò conferma la relazione tra MAD e deviazione standard in distribuzioni gaussiane.\nSe invece usiamo dei dati non normali, l’approssimazione non è buona:\n\nset.seed(123) \ny &lt;- rchisq(200, 1)\n1.4826 * median(abs(y - median(y)))\n#&gt; [1] 0.474\n\n\nsqrt(\n  var(y) * (length(y) - 1) / length(y)\n)\n#&gt; [1] 1.41\n\n\n\n\n\n19.2.5.2 Quando usare deviazione standard e MAD\n\nDeviazione standard: È la misura più appropriata per dati normalmente distribuiti e situazioni in cui l’obiettivo è descrivere la dispersione dei dati rispetto alla media. Tuttavia, è sensibile ai valori anomali (outlier).\nDeviazione mediana assoluta: È ideale quando i dati sono non normali, asimmetrici o contengono outlier. La MAD è più robusta poiché utilizza la mediana anziché la media e non è influenzata da valori estremi.\n\n19.2.6 Indici di variabilità relativi\nA volte può essere necessario confrontare la variabilità di grandezze incommensurabili, ovvero di caratteri misurati con differenti unità di misura. In queste situazioni, le misure di variabilità descritte in precedenza diventano inadeguate poiché dipendono dall’unità di misura utilizzata. Per superare questo problema, si ricorre a specifici numeri adimensionali chiamati indici relativi di variabilità.\nIl più importante di questi indici è il coefficiente di variazione (\\(C_v\\)), definito come il rapporto tra la deviazione standard (\\(\\sigma\\)) e la media dei dati (\\(\\bar{x}\\)):\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}.\n\\tag{19.7}\\] Il coefficiente di variazione è un numero puro e permette di confrontare la variabilità di distribuzioni con unità di misura diverse.\nUn altro indice relativo di variabilità è la differenza interquartile rapportata a uno dei tre quartili (primo quartile, terzo quartile o mediana). Questo indice è definito come:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\] Questi indici relativi di variabilità forniscono una misura adimensionale della dispersione dei dati, rendendo possibile il confronto tra grandezze con diverse unità di misura e facilitando l’analisi delle differenze di variabilità tra i dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_loc_scale.html#riflessioni-conclusive",
    "href": "chapters/eda/06_loc_scale.html#riflessioni-conclusive",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLe statistiche descrittive forniscono strumenti essenziali per sintetizzare e comprendere i dati raccolti in psicologia e nelle scienze sociali. Le misure di tendenza centrale, come la media, la mediana e la moda, ci permettono di individuare un valore tipico o rappresentativo di una distribuzione, facilitando la sintesi e l’interpretazione generale dei dati raccolti. Parallelamente, gli indici di dispersione, come la deviazione standard, la varianza e l’intervallo interquartile, offrono informazioni cruciali sulla variabilità, mostrandoci quanto i singoli dati siano vicini o distanti da questa tendenza centrale.\nTuttavia, è fondamentale riflettere attentamente sulle implicazioni teoriche e metodologiche che accompagnano l’uso di queste misure. In particolare, è importante considerare il rischio della fallacia ergodica, ovvero l’errata convinzione che i risultati ottenuti da medie e statistiche aggregate possano automaticamente applicarsi ai singoli individui. Nella pratica psicologica, infatti, ogni persona è caratterizzata da una notevole variabilità intra- e inter-individuale, che spesso non può essere adeguatamente rappresentata da semplici indicatori aggregati.\nLe statistiche descrittive rappresentano quindi un primo e fondamentale passo nella comprensione dei dati psicologici, ma devono essere integrate da analisi più approfondite e attente alle differenze individuali. L’uso critico e consapevole di questi strumenti statistici ci consente di evitare generalizzazioni eccessive, fornendo una visione più accurata e realistica dei fenomeni psicologici e comportamentali che studiamo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_loc_scale.html#esercizi",
    "href": "chapters/eda/06_loc_scale.html#esercizi",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nParte 1: Domande Teoriche\n\n\nDefinizione e comprensione dei concetti\n\nSpiega la differenza tra media, mediana e moda.\nIn quali situazioni la mediana fornisce una misura della tendenza centrale migliore rispetto alla media?\nPerché la media è sensibile ai valori estremi?\nQuali sono i vantaggi della deviazione mediana assoluta (MAD) rispetto alla deviazione standard?\n\n\n\nInterpretazione della variabilità\n\nSpiega il concetto di varianza e la sua interpretazione.\nQual è la differenza tra varianza e deviazione standard?\nDescrivi in quali casi l’utilizzo del coefficiente di variazione è più appropriato rispetto alla deviazione standard.\nQuali sono i limiti della moda come indice di tendenza centrale?\n\n\n\nParte 2: Calcoli Manuali\n\n\nCalcolo della media, mediana e moda\n\n\nConsidera i seguenti punteggi totali della SWLS che sono stati raccolti in un campione di studenti. Calcola manualmente:\n\nLa media\nLa mediana\nLa moda\nIl range\n\n\n\n\n\nCalcolo della varianza e della deviazione standard\n\nUsando gli stessi dati dell’esercizio precedente, calcola:\n\nLa varianza\nLa deviazione standard\nLa deviazione mediana assoluta (MAD)\n\n\n\n\n\nParte 3: Esercizi con R\n\n\nAnalisi descrittiva con R\n\nCarica il dataset swls_scores.csv contenente i punteggi SWLS degli studenti.\nCalcola media, mediana e moda utilizzando R.\nCalcola la varianza e la deviazione standard utilizzando le funzioni appropriate in R.\n\nCodice suggerito:\nlibrary(tidyverse)\nlibrary(rio)\n\n# Caricamento del dataset\ndf &lt;- import(\"swls_scores.csv\")\n\n# Calcolo delle statistiche descrittive\nmean(df$swls_total)\nmedian(df$swls_total)\n\n# Moda (funzione personalizzata)\nget_mode &lt;- function(x) {\n  tbl &lt;- table(x)\n  as.numeric(names(tbl)[which.max(tbl)])\n}\nget_mode(df$swls_total)\n\n# Varianza e deviazione standard\nvar(df$swls_total)\nsd(df$swls_total)\n\n# Deviazione mediana assoluta\nmad(df$swls_total)\n\n\nVisualizzazione della distribuzione dei dati\n\nCrea un istogramma dei punteggi totali della SWLS.\nAggiungi una linea verticale che rappresenti la media e una che rappresenti la mediana.\n\nCodice suggerito:\nggplot(df, aes(x = swls_total)) +\n  geom_histogram(binwidth = 2, fill = \"blue\", alpha = 0.5, color = \"black\") +\n  geom_vline(aes(xintercept = mean(swls_total)), color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_vline(aes(xintercept = median(swls_total)), color = \"green\", linetype = \"dotted\", size = 1) +\n  labs(title = \"Distribuzione dei punteggi SWLS\", x = \"Punteggio SWLS\", y = \"Frequenza\")\n\n\nParte 4: Domande di Comprensione\n\n\nAnalisi concettuale\n\nPerché la media aritmetica può essere considerata il “baricentro” della distribuzione dei dati?\nSe aggiungiamo un valore estremo al dataset, quale delle misure di tendenza centrale subirà il maggior impatto?\nIn quali situazioni la varianza campionaria è preferibile rispetto alla varianza della popolazione?\nQual è la relazione tra la deviazione standard e la varianza?\nFornisci un’interpretazione intuitiva della deviazione standard.\nDiscuti le differenze e le somiglianze tra la deviazione standard e MAD. Usa queste informazioni per ridescrivere in maniera intuitiva il significato di deviazione standard.\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nPoniamo che i valori SWLS siano [ 18, 22, 26, 19, 24, 30, 26, 22, 18, 28, 21 ].\n\nMedia: \\[ \\bar{x} = \\frac{18 + 22 + 26 + 19 + 24 + 30 + 26 + 22 + 18 + 28 + 21}{11} = 23.36 \\]\nMediana: Ordinando i dati: [ 18, 18, 19, 21, 22, 22, 24, 26, 26, 28, 30 ] La mediana è il valore centrale: \\(22\\)\nModa: Il valore più frequente è 22 (appare due volte).\nVarianza: \\[ s^2 = \\frac{\\sum (x_i - \\bar{x})^2}{n-1} = 13.96 \\]\nDeviazione Standard: \\[ s = \\sqrt{13.96} = 3.73 \\]\nMAD: \\[ \\text{MAD} = \\text{mediana}(|X_i - \\text{mediana}(X)|) = 4 \\]\n\nSoluzioni con R\nI risultati eseguendo il codice R:\n\n\nMedia: 23.36\n\nMediana: 22\n\nModa: 22\n\nVarianza: 13.96\n\nDeviazione standard: 3.73\n\nMAD: 4\n\nSoluzioni alle Domande di Comprensione\n\nLa media è il baricentro poiché minimizza la somma degli scarti quadrati.\nLa media è più influenzata dai valori estremi rispetto alla mediana.\nLa varianza campionaria corregge la sottostima della varianza popolazionale.\nLa deviazione standard è la radice quadrata della varianza, consentendo un’interpretazione del risultato sulla scala dei dati grezzi.\nLa deviazione standard è simile, ma non identica, al valore medio degli scarti assoluti tra ciascun valore della distribuzione e la media. In altre parole, rappresenta la “distanza tipica” media tra le osservazioni e il valore medio della distribuzione.\nLa deviazione standard e il MAD (Median Absolute Deviation, o scarto medio assoluto) sono entrambi misure di variabilità che descrivono quanto i valori in un insieme di dati si discostino dal centro della distribuzione. Tuttavia, presentano alcune importanti differenze e somiglianze.\n\nSomiglianze\n\nEntrambe le misure quantificano la dispersione dei dati attorno a un punto centrale.\nSia la deviazione standard che il MAD utilizzano lo scarto (la differenza tra ciascun valore e un punto centrale) per calcolare la variabilità.\n\nDifferenze\n\n\nPunto centrale usato: La deviazione standard si basa sulla media aritmetica, mentre il MAD si basa sulla mediana.\n\nTrattamento degli scarti: Nella deviazione standard, gli scarti vengono elevati al quadrato prima di essere mediati, quindi la radice quadrata viene applicata al risultato finale. Questo processo penalizza maggiormente gli scarti più grandi, rendendo la deviazione standard più sensibile agli outlier. Il MAD, invece, considera semplicemente il valore assoluto degli scarti, rendendolo meno influenzato dagli estremi.\n\nSensibilità agli outlier: Poiché la deviazione standard dipende dai quadrati degli scarti, è più sensibile alle osservazioni estreme (outlier). Il MAD, essendo basato sulla mediana, è una misura più robusta e resiste meglio alla presenza di valori anomali.\n\nRidescrizione Intuitiva della Deviazione Standard\n\nLa deviazione standard può essere vista come una misura della “dispersione tipica” dei dati attorno alla media, ma con un’enfasi particolare sugli scarti più grandi. Immagina di prendere ogni valore del dataset, calcolarne la distanza dalla media, amplificare queste distanze attraverso il quadrato, poi trovare una sorta di “distanza media” ponderata. Questo processo dà maggiore peso agli scarti più grandi, fornendo così una visione della variabilità che tiene conto sia delle fluttuazioni ordinarie sia di eventuali valori estremi. In sintesi, mentre il MAD offre una visione più resistente e diretta della variabilità centrata sulla mediana, la deviazione standard fornisce una misura più dettagliata e sensibile alla forma complessiva della distribuzione, inclusi i suoi possibili outliers.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] vcd_1.4-13            viridis_0.6.5         viridisLite_0.4.2    \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [28] RColorBrewer_1.1-3    lmtest_0.9-40         lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] R.utils_2.13.0        pacman_0.5.1          Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [64] mvtnorm_1.3-3         QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [67] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [70] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [73] gtable_0.3.6          R.methodsS3_1.8.2     digest_0.6.37        \n#&gt; [76] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [79] R.oo_1.27.1           memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [82] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_loc_scale.html#bibliografia",
    "href": "chapters/eda/06_loc_scale.html#bibliografia",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBarroso, C., Ganley, C. M., McGraw, A. L., Geer, E. A., Hart, S. A., & Daucourt, M. C. (2021). A meta-analysis of the relation between math anxiety and math achievement. Psychological Bulletin, 147(2), 134–168.\n\n\nMolden, D. C., & Dweck, C. S. (2006). Finding\" meaning\" in psychology: a lay theories approach to self-regulation, social perception, and social development. American Psychologist, 61(3), 192–203.\n\n\nSpeelman, C. P., & McGann, M. (2013). How mean is the mean? Frontiers in Psychology, 4, 451.\n\n\nSpeelman, C. P., Parker, L., Rapley, B. J., & McGann, M. (2024). Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals. Collabra: Psychology, 10(1).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_introduction_normal_distribution.html",
    "href": "chapters/eda/07_introduction_normal_distribution.html",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "",
    "text": "Introduzione\nIn questo capitolo forniremo un primo sguardo alla distribuzione normale, che sarà trattata in modo più approfondito nel Capitolo 37. Introduciamo la distribuzione normale a questo punto poiché essa spiega in modo chiaro perché, in molte analisi, media e deviazione standard siano impiegate come principali descrittori di una distribuzione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_introduction_normal_distribution.html#introduzione",
    "href": "chapters/eda/07_introduction_normal_distribution.html#introduzione",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "",
    "text": "Panoramica del capitolo\n\nChe cos’è la distribuzione normale?\nCome si costruisce e come si interpreta la distribuzione normale normalizzata.\nCosa sono e come si interpretanto i diagrammi quantile-quantile.\nDistribuzione normale e statistiche descrittive.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Exploring numerical data di Introduction to Modern Statistics (2e) di Mine Çetinkaya-Rundel e Johanna Hardin.\nLeggere il capitolo Distributions di Introduction to Data Science (Irizarry, 2024).\n\n\n\n\n::: {.callout-caution collapse=true=“Preparazione del Notebook”}\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(ggbeeswarm, dslabs, gridExtra)\n\n:::",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_introduction_normal_distribution.html#sec-normal-distribution",
    "href": "chapters/eda/07_introduction_normal_distribution.html#sec-normal-distribution",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "\n20.1 La distribuzione normale",
    "text": "20.1 La distribuzione normale\nNel Capitolo 17, abbiamo visto come gli istogrammi e i grafici di densità forniscano utili riassunti visivi di una distribuzione. In questo capitolo, ci chiediamo se sia possibile riassumere una distribuzione in modo ancora più sintetico. Spesso si fa riferimento a media e deviazione standard come statistiche riassuntive fondamentali: in sostanza, un riassunto in due numeri. Per comprendere appieno il ruolo di questi valori, dobbiamo prima capire come è definita la distribuzione normale.\nLa distribuzione normale, nota anche come curva a campana o distribuzione gaussiana, è uno dei concetti matematici più conosciuti (si veda il Capitolo 37). Uno dei motivi della sua fama è che numerose variabili nella realtà seguono, almeno approssimativamente, una distribuzione normale. Esempi includono le vincite nel gioco d’azzardo, l’altezza e il peso delle persone, la pressione sanguigna, i punteggi di alcuni test standardizzati e gli errori di misura negli esperimenti. I motivi matematici e probabilistici di queste approssimazioni verranno discussi in seguito; qui ci concentreremo sul come la distribuzione normale aiuti a riassumere i dati.\nAnziché partire da dati empirici, la distribuzione normale si definisce tramite una formula matematica. Per un intervallo generico \\((a,b)\\), la proporzione di valori che cade in tale intervallo si ottiene mediante:\n\\[\n\\text{Pr}(a &lt; x \\leq b) \\;=\\; \\int_a^b \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\, e^{-\\tfrac12\\,\\bigl(\\tfrac{x - \\mu}{\\sigma}\\bigr)^2}\\, dx .\n\\tag{20.1}\\]\nNon è necessario memorizzare o padroneggiare i dettagli di questa formula, ma è importante sapere che la distribuzione normale è completamente determinata da due soli parametri: \\(\\mu\\) e \\(\\sigma\\). Gli altri simboli nella formula (\\(\\pi\\), \\(e\\), \\(a\\), \\(b\\)) rappresentano costanti matematiche o gli estremi dell’intervallo. In particolare, \\(\\mu\\) è il valore medio (o media) e \\(\\sigma\\) è la deviazione standard.\nQuesta distribuzione è simmetrica, centrata sulla media \\(\\mu\\), e la maggior parte dei valori (circa il 95%) si trova entro 2 deviazioni standard dalla media, cioè nell’intervallo \\(\\mu \\pm 2\\sigma\\). Ecco un esempio di come appare la distribuzione normale quando \\(\\mu = 0\\) e \\(\\sigma = 1\\):\n\nm &lt;- 0; s &lt;- 1\nnorm_dist &lt;- tibble(x = seq(-4, 4, length.out = 50)*s + m) |&gt; \n  mutate(density = dnorm(x, m, s))\nnorm_dist |&gt; \n  ggplot(aes(x, density)) + geom_line()\n\n\n\n\n\n\n\nIl fatto che la distribuzione sia descritta da due parametri implica che, se un insieme di dati reali si approssima bene a una distribuzione normale, due soli numeri (media e deviazione standard) possono fornire un riassunto sintetico della distribuzione. Vediamo ora come si calcolano, in pratica, questi due parametri per una lista di valori arbitraria.\nSupponiamo di avere un vettore x che contiene una serie di valori numerici. Abbiamo visto come, in R, la media si trova come:\nm &lt;- sum(x) / length(x)\ne la deviazione standard è:\ns &lt;- sqrt(sum((x - m)^2) / length(x))\nLa deviazione standard si può interpretare come la distanza media dei valori dalla loro media.\n\n20.1.1 Un esempio pratico\nPer calcolare media e deviazione standard dell’altezza maschile in un dataset, ipotizziamo che il vettore heights$height contenga le altezze di alcuni individui, mentre heights$sex contenga il genere corrispondente. Se vogliamo estrarre solo i valori relativi ai maschi, possiamo scrivere:\n\nindex &lt;- heights$sex == \"Male\"\nx &lt;- heights$height[index]\n\nQuindi usiamo le funzioni predefinite di R:\n\nm &lt;- mean(x)\ns &lt;- sd(x)\n\n\n\n\n\n\n\nNota: Per motivi che verranno chiariti in seguito, la funzione sd(x) effettua una divisione per \\(\\text{length}(x) - 1\\) invece che per \\(\\text{length}(x)\\). Tuttavia, se il numero di osservazioni è elevato, questa differenza è trascurabile.\n\n\n\nPossiamo ora mettere a confronto la curva di densità osservata dei dati (in blu) con quella teorica (in nero) della distribuzione normale con media e deviazione standard stimate:\n\nnorm_dist &lt;- tibble(\n  x = seq(-4, 4, length.out = 50)*s + m) |&gt; \n  mutate(density = dnorm(x, m, s))\n\nheights |&gt; \n  dplyr::filter(sex == \"Male\") |&gt; \n  ggplot(aes(height)) +\n  geom_density(fill = \"lightblue\") +\n  geom_line(aes(x, density), linewidth=1.5, data = norm_dist)\n\n\n\n\n\n\n\nCome si vede, la curva normale fornisce una buona approssimazione per i dati sull’altezza maschile. Vedremo ora come verificare l’aderenza di una distribuzione ai dati, osservando le proporzioni di valori entro intervalli specifici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_introduction_normal_distribution.html#unità-standard",
    "href": "chapters/eda/07_introduction_normal_distribution.html#unità-standard",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "\n20.2 Unità standard",
    "text": "20.2 Unità standard\nPer i dati che seguono (o quasi) una distribuzione normale, è molto comodo utilizzare le cosiddette unità standard (Standard Units). Un valore \\(x\\) viene convertito in unità standard tramite la formula:\n\\[\nz = \\frac{x - m}{s} ,\n\\]\ndove \\(m\\) e \\(s\\) sono la media e la deviazione standard della distribuzione. Questa trasformazione ci dice di quante deviazioni standard un particolare valore si discosta dalla media. Ad esempio, se \\(z=0\\), il valore \\(x\\) corrisponde esattamente alla media; se \\(z = 2\\), il valore \\(x\\) si trova a due deviazioni standard sopra la media; se \\(z = -2\\), a due deviazioni standard sotto la media, e così via.\nIn R, possiamo calcolare le unità standard con la funzione:\n\nz &lt;- scale(x) |&gt; as.numeric()\nhead(z)\n#&gt; [1]  1.574  0.190 -0.364  1.297 -2.303 -0.641\n\nSe vogliamo sapere, ad esempio, quale frazione di individui si trova entro 2 deviazioni standard dalla media (cioè \\(|z| &lt; 2\\)), basta scrivere:\n\nmean(abs(z) &lt; 2)\n#&gt; [1] 0.95\n\nVedremo, in molti casi, un valore intorno al 95%, in linea con quanto previsto dalla distribuzione normale. Per confermare la bontà dell’approssimazione, si usano spesso i grafici quantile-quantile, detti anche qqplot.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_introduction_normal_distribution.html#grafici-quantile-quantile",
    "href": "chapters/eda/07_introduction_normal_distribution.html#grafici-quantile-quantile",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "\n20.3 Grafici quantile-quantile",
    "text": "20.3 Grafici quantile-quantile\nUn modo sistematico per verificare quanto la distribuzione normale descriva bene i dati osservati consiste nel confrontare i quantili empirici con quelli teorici di una normale. Se i due insiemi di quantili sono molto simili, abbiamo un’ulteriore conferma dell’aderenza alla normalità.\n\nLa funzione di ripartizione della distribuzione normale standard si indica spesso con \\(\\Phi(x)\\). Ad esempio, \\(\\Phi(-1.96) \\approx 0.025\\) e \\(\\Phi(1.96) \\approx 0.975\\).\n\nL’inversa di \\(\\Phi\\), indicata come \\(\\Phi^{-1}(p)\\), ci dà il quantile corrispondente a una determinata probabilità \\(p\\). In R, pnorm calcola \\(\\Phi(x)\\) e qnorm calcola \\(\\Phi^{-1}(p)\\). Di default, pnorm e qnorm si riferiscono alla normale standard (media 0, deviazione standard 1), ma possiamo specificare valori diversi di media e deviazione standard tramite gli argomenti mean e sd.\n\nPer ottenere il quantile empirico da un vettore di dati in R, possiamo usare la funzione quantile. Ad esempio, se abbiamo un vettore x, il quantile associato alla probabilità \\(p\\) è il valore \\(q\\) per il quale mean(x &lt;= q) = p.\nEcco lo schema logico per costruire un qqplot:\n\nDefiniamo un vettore di proporzioni \\(p_1, p_2, \\dots, p_m\\).\n\nCalcoliamo i relativi quantili empirici dei nostri dati \\(\\{q_1, \\dots, q_m\\}\\) usando quantile(x, p_i).\n\nCalcoliamo i quantili teorici della normale (con la stessa media e la stessa deviazione standard dei dati) usando qnorm(p_i, mean, sd).\n\nRappresentiamo i punti \\((\\text{quantile teorico}, \\text{quantile empirico})\\). Se i dati sono davvero normali, tali punti si disporranno approssimativamente lungo la retta diagonale y = x.\n\nEsempio in R:\n\np &lt;- seq(0.05, 0.95, 0.05)\nsample_quantiles &lt;- quantile(x, p)\ntheoretical_quantiles &lt;- qnorm(p, mean = mean(x), sd = sd(x))\n\nqplot(theoretical_quantiles, sample_quantiles) + geom_abline()\n\n\n\n\n\n\n\nSe però abbiamo già convertito in unità standard (quindi \\(\\mu = 0\\) e \\(\\sigma = 1\\)), il confronto si semplifica:\n\nsample_quantiles &lt;- quantile(z, p)\ntheoretical_quantiles &lt;- qnorm(p)\nqplot(theoretical_quantiles, sample_quantiles) + geom_abline()\n\n\n\n\n\n\n\nIn pratica, per creare rapidamente un qqplot si usa spesso ggplot2 con la geometria geom_qq:\n\nheights |&gt; filter(sex == \"Male\") |&gt;\n  ggplot(aes(sample = scale(height))) + \n  geom_qq() +\n  geom_abline()\n\n\n\n\n\n\n\nCome abbiamo sottolineato, se i punti nel qqplot si dispongono lungo una retta, significa che la distribuzione dei dati è in accordo con la distribuzione teorica considerata (in questo caso, la normale). I qqplot possono essere usati anche per confrontare qualsiasi coppia di distribuzioni, non solo dati e normale teorica.\nQuesto indica che l’approssimazione normale è accurata per il gruppo maschile (nel nostro dataset).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_introduction_normal_distribution.html#media-e-deviazione-standard-come-statistiche-descrittive-della-distribuzione",
    "href": "chapters/eda/07_introduction_normal_distribution.html#media-e-deviazione-standard-come-statistiche-descrittive-della-distribuzione",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "\n20.4 Media e deviazione standard come statistiche descrittive della distribuzione",
    "text": "20.4 Media e deviazione standard come statistiche descrittive della distribuzione\nLa media e la deviazione standard sono due delle statistiche più comunemente utilizzate per descrivere la distribuzione di un insieme di dati. Queste misure sono particolarmente utili quando i dati seguono una distribuzione normale. In questo caso, la media e la deviazione standard contengono tutte le informazioni necessarie per caratterizzare completamente la forma della distribuzione.\n\n20.4.1 Distribuzione normale e statistiche descrittive\nLa distribuzione normale è definita dalla sua media (\\(\\mu\\)) e dalla sua deviazione standard (\\(\\sigma\\)). La formula della densità di probabilità della distribuzione normale è data dall’Equazione 20.1. Questa formula mostra che, conoscendo solo \\(\\mu\\) e \\(\\sigma\\), possiamo ricostruire l’intera curva di densità. Pertanto, se i dati empirici sono ben approssimati da una distribuzione normale, la media e la deviazione standard sono sufficienti per descrivere la distribuzione.\nSupponiamo di avere un dataset che segue una distribuzione normale con media 50 e deviazione standard 10. Possiamo generare dati casuali e visualizzare la curva di densità in R:\n\n# Generiamo dati da una distribuzione normale\nset.seed(123)\ndati &lt;- rnorm(1000, mean = 50, sd = 10)\n\n# Calcoliamo media e deviazione standard\nmedia &lt;- mean(dati)\ndeviazione_standard &lt;- sd(dati)\n\n# Visualizziamo la curva di densità\nggplot(data.frame(dati), aes(x = dati)) +\n  geom_density(fill = \"lightblue\") +\n  geom_vline(xintercept = media, color = \"red\", linetype = \"dashed\") +\n  labs(\n       x = \"Valori\",\n       y = \"Densità\") +\n  annotate(\"text\", x = media + 5, y = 0.03, label = paste(\"Media =\", round(media, 2)), color = \"red\") +\n  annotate(\"text\", x = media + 5, y = 0.025, label = paste(\"Deviazione Standard =\", round(deviazione_standard, 2)), color = \"blue\")\n\n\n\n\n\n\n\nIn questo esempio:\n\nLa curva di densità è centrata attorno alla media (\\(\\mu = 50\\)).\nLa deviazione standard (\\(\\sigma = 10\\)) determina la dispersione dei dati attorno alla media.\n\n20.4.2 Quando media e deviazione standard non sono sufficienti\nSebbene media e deviazione standard siano strumenti estremamente utili per descrivere distribuzioni normali, non sempre bastano a cogliere tutte le caratteristiche di un insieme di dati. In particolare, ci sono situazioni in cui la forma della distribuzione rende necessario ricorrere a misure aggiuntive. Di seguito presentiamo alcuni casi tipici.\n\n\nDistribuzioni Asimmetriche\nUna distribuzione si dice asimmetrica (o skewed) quando una coda è più “estesa” dell’altra.\n\nSe la coda più lunga è a destra, la distribuzione è asimmetrica positiva (o a destra).\n\nSe la coda più lunga è a sinistra, la distribuzione è asimmetrica negativa (o a sinistra).\nIn queste circostanze, la media tende a spostarsi verso la coda più lunga, mentre la mediana rimane più stabile e rappresentativa del valore centrale.\n\n\nDistribuzioni Multimodali\nUna distribuzione è multimodale quando presenta più picchi (o “modi”). Ciò significa che i dati si concentrano attorno a più di un valore, formando veri e propri sotto-gruppi. In questi casi, media e deviazione standard possono risultare poco significative, poiché non colgono la presenza di più poli di concentrazione.\n\nKurtosi\nLa kurtosi descrive quanto una distribuzione sia “appuntita” o “piatta” rispetto a una normale.\n\n\nAlta kurtosi indica picchi molto accentuati e code più lunghe, con una maggiore probabilità di valori estremi.\n\n\nBassa kurtosi segnala una forma più appiattita, con code ridotte e meno outlier.\n\n\n\nQuando le distribuzioni mostrano una di queste peculiarità, altre statistiche possono rivelarsi più informative:\n\nLa mediana, insensibile ai valori estremi, fornisce una descrizione più robusta del centro.\n\nI quartili, e in particolare l’intervallo interquartile, danno un’idea della dispersione principale trascurando le code.\n\nL’indice di asimmetria (skewness) misura il grado di sbilanciamento della distribuzione.\n\nL’indice di curtosi (kurtosis) quantifica la “pesantezza” delle code.\n\nNel seguente esempio, generiamo dati da una distribuzione esponenziale, notoriamente asimmetrica:\n\n# Generiamo dati da una distribuzione esponenziale\nset.seed(123)\ndati_esponenziali &lt;- rexp(1000, rate = 0.5)\n\n# Calcoliamo media e deviazione standard\nmedia_esp &lt;- mean(dati_esponenziali)\ndeviazione_standard_esp &lt;- sd(dati_esponenziali)\n\n# Visualizziamo la curva di densità\nggplot(data.frame(dati_esponenziali), aes(x = dati_esponenziali)) +\n  geom_density(fill = \"#F8766D\", alpha = 0.6) +\n  geom_vline(xintercept = media_esp, color = \"red\", linetype = \"dashed\") +\n  labs(\n       x = \"Valori\",\n       y = \"Densità\") +\n  annotate(\"text\", x = media_esp + 1, y = 0.2, \n           label = paste(\"Media =\", round(media_esp, 2)), \n           color = \"red\") +\n  annotate(\"text\", x = media_esp + 1, y = 0.18, \n           label = paste(\"Deviazione Standard =\", round(deviazione_standard_esp, 2)), \n           color = \"blue\")\n\n\n\n\n\n\n\nL’istogramma (o la densità) mostra chiaramente una coda lunga a destra, con molti valori piccoli e pochi valori grandi. In questo contesto:\n\nLa media tende a seguire la coda, diventando meno rappresentativa del “centro”.\n\nLa deviazione standard non descrive in modo efficace la variabilità, perché non considera adeguatamente la forte asimmetria.\n\nMisure alternative, come la mediana e i quartili, forniscono informazioni più affidabili:\n\n# Calcoliamo mediana e quartili\nmediana &lt;- median(dati_esponenziali)\nquartili &lt;- quantile(dati_esponenziali, probs = c(0.25, 0.75))\n\ncat(\"Mediana:\", mediana, \"\\n\")\n#&gt; Mediana: 1.46\ncat(\"Primo Quartile (Q1):\", quartili[1], \"\\n\")\n#&gt; Primo Quartile (Q1): 0.613\ncat(\"Terzo Quartile (Q3):\", quartili[2], \"\\n\")\n#&gt; Terzo Quartile (Q3): 2.85\n\nIn conclusione, quando i dati non presentano una forma vicina alla normalità (ad esempio perché asimmetrici, multimodali o con kurtosi anomala), media e deviazione standard possono risultare fuorvianti o poco utili. In questi casi, è fondamentale adottare misure alternative o complementari (mediana, quartili, skewness, kurtosis) per ottenere una descrizione più accurata della distribuzione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_introduction_normal_distribution.html#riflessioni-conclusive",
    "href": "chapters/eda/07_introduction_normal_distribution.html#riflessioni-conclusive",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo, abbiamo esplorato alcuni concetti fondamentali per l’analisi dei dati e consolidato le basi per un’interpretazione più approfondita delle distribuzioni. In particolare, abbiamo:\n\n\nStudiato la distribuzione normale, una delle distribuzioni più importanti in statistica, e compreso perché la media e la deviazione standard siano parametri cruciali per descriverla. Questi indicatori ci permettono di riassumere in modo efficace le caratteristiche centrali e la variabilità dei dati.\n\nImparato a standardizzare i dati convertendoli in unità standard (z-score), il che ci consente di confrontare variabili con scale diverse o di valutare quanto un dato specifico si discosti dalla media in termini di deviazioni standard.\n\nIntrodotto il grafico quantile-quantile (QQ-plot), uno strumento visivo prezioso per verificare se i nostri dati seguono una distribuzione normale. Attraverso il QQ-plot, possiamo confrontare i quantili empirici dei nostri dati con quelli teorici della distribuzione normale, identificando eventuali deviazioni.\n\nGli strumenti descritti in questo capitolo rappresentano il primo passo essenziale nell’analisi esplorativa dei dati. Essi ci aiutano a formulare ipotesi solide e a riconoscere potenziali problemi o caratteristiche peculiari dei dati prima di applicare metodi statistici più avanzati, che approfondiremo nei prossimi capitoli.\nL’analisi esplorativa, combinando grafici intuitivi e statistiche descrittive appropriate, riveste quindi un ruolo fondamentale nel processo analitico. Essa non solo ci aiuta a comprendere meglio la natura dei dati, ma ci fornisce anche una base solida su cui costruire conclusioni statistiche attendibili e informate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_introduction_normal_distribution.html#esercizi",
    "href": "chapters/eda/07_introduction_normal_distribution.html#esercizi",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "Esercizi",
    "text": "Esercizi\n::: {.callout-tip=“Esercizi” collapse=“true”} Esercizi Teorici\nRispondi alle seguenti domande per consolidare la comprensione teorica della distribuzione normale e dei suoi concetti chiave.\n\n\nCaratteristiche della distribuzione normale\n\nQuali sono i due parametri principali della distribuzione normale?\n\nPerché la distribuzione normale è utilizzata così frequentemente in statistica?\n\nIn quali situazioni reali possiamo aspettarci che una variabile segua una distribuzione normale?\n\n\n\nMedia e deviazione standard\n\nQual è il significato della media in una distribuzione normale?\n\nCosa rappresenta la deviazione standard?\n\nIn che modo la deviazione standard influenza la forma della curva normale?\n\n\n\nZ-score e standardizzazione\n\nCos’è uno z-score e come si calcola?\n\nQual è il significato di un valore z=2? E di un valore z=-1.5?\n\nDopo la standardizzazione, quali saranno la media e la deviazione standard della variabile?\n\n\n\nVerifica della normalità\n\nSe hai un piccolo campione di dati (circa 15 osservazioni), quali metodi grafici puoi utilizzare per valutare se segue una distribuzione normale?\n\nQuali strumenti statistici puoi impiegare per testare la normalità?\n\nIn un QQ-plot, come puoi riconoscere se i dati seguono una distribuzione normale?\n\n\n\nEsercizi Pratici in R\nObiettivo: Analizzare i dati raccolti dagli studenti sulla Satisfaction With Life Scale (SWLS), comprendere la loro distribuzione e confrontarli con una distribuzione normale teorica.\nDati disponibili:\nUsa i dati della SWLS. I dati contengono anche informazioni sul genere e su un indice di rete sociale (LSNS).\n1. Esplorazione e Visualizzazione dei Dati SWLS\n\n\nCarica i dati raccolti dagli studenti e verifica la struttura del dataset.\n\n\nCalcola i valori di base: media, deviazione standard, minimo, massimo, e quantili della SWLS.\n\n\nCrea una rappresentazione visiva dei dati:\n\nIstogramma con sovrapposta una curva di densità.\n\nBoxplot per identificare eventuali outlier.\n\nViolin plot per osservare la distribuzione.\n\n\n\n2. Confronto con la Distribuzione Normale\n\n\nSovrapponi ai dati osservati una curva normale teorica basata su media e deviazione standard stimate dal campione.\n\n\nConfronta i quantili empirici con quelli teorici mediante un QQ-plot.\n\n\nCommenta il risultato: i dati SWLS seguono approssimativamente una normale? Se no, quali differenze noti?\n\n3. Standardizzazione dei Punteggi SWLS\n\n\nTrasforma i dati della SWLS in z-score per analizzarli in unità standardizzate.\n\nVerifica la nuova media e deviazione standard: dovrebbero essere 0 e 1 rispettivamente.\n\n\nConta quanti punteggi standardizzati si trovano entro 1, 2 e 3 deviazioni standard dalla media e confronta i valori attesi di 68%, 95% e 99.7%.\n\n4. Relazione tra SWLS e Interazione Sociale (LSNS)\n\n\nEsplora la relazione tra SWLS e il punteggio della Scala della Rete Sociale di Lubben (LSNS-6).\n\n\nCostruisci un grafico a dispersione per osservare la correlazione tra le due variabili.\n\n\nCalcola il coefficiente di correlazione di Pearson e commenta il risultato. Esiste una relazione tra soddisfazione della vita e supporto sociale?\n:::\n\n::: {.callout-tip=“Soluzioni” collapse=“true”} 1. Caratteristiche della distribuzione normale\na. Quali sono i due parametri principali della distribuzione normale?\nI due parametri principali che definiscono una distribuzione normale sono:\n\n\nLa media (μ): Indica il centro della distribuzione. Tutte le osservazioni si raggruppano attorno a questo valore.\n\nLa deviazione standard (σ): Descrive la dispersione o la variabilità dei dati attorno alla media.\n\nb. Perché la distribuzione normale è utilizzata così frequentemente in statistica?\nLa distribuzione normale è ampiamente usata per diversi motivi:\n\n\nTeorema del limite centrale: Afferma che, quando si sommano molte variabili casuali indipendenti, la loro distribuzione tende ad avvicinarsi a una normale, indipendentemente dalla forma originale delle singole distribuzioni.\n\nSemplicità matematica: La normale ha proprietà matematiche ben definite e permette di calcolare probabilità e intervalli con facilità.\n\nModellizzazione naturale: Molte variabili naturali e sociali (ad esempio, altezze, pesi, punteggi standardizzati) seguono approssimativamente una distribuzione normale.\n\nc. In quali situazioni reali possiamo aspettarci che una variabile segua una distribuzione normale?\nSi può aspettare una distribuzione normale in situazioni in cui:\n\nLe osservazioni sono influenzate da molti fattori casuali indipendenti (es. altezza di un individuo, errore di misurazione).\nI dati derivano da fenomeni naturali o biologici (es. pressione sanguigna, peso corporeo).\nSi analizzano medie campionarie di grandi dimensioni (grazie al teorema del limite centrale).\n\n2. Media e deviazione standard\na. Qual è il significato della media in una distribuzione normale?\nNella distribuzione normale, la media rappresenta il punto centrale della curva, ovvero il valore più probabile. È anche il punto di simmetria della distribuzione, dove metà delle osservazioni si trova a sinistra e l’altra metà a destra.\nb. Cosa rappresenta la deviazione standard?\nLa deviazione standard misura quanto i dati si discostano in media dalla media. Una deviazione standard bassa indica che i dati sono raggruppati strettamente attorno alla media, mentre una deviazione standard alta indica una maggiore dispersione.\nc. In che modo la deviazione standard influenza la forma della curva normale?\n\nUna deviazione standard piccola produce una curva alta e stretta, indicando una bassa variabilità.\nUna deviazione standard grande produce una curva bassa e larga, indicando una maggiore variabilità.\n\n3. Z-score e standardizzazione\na. Cos’è uno z-score e come si calcola?\nUno z-score misura quante deviazioni standard un dato si discosta dalla media. Viene calcolato come:\n\\[\nz = \\frac{x - \\mu}{\\sigma}\n\\]\ndove \\(x\\) è il valore osservato, \\(\\mu\\) è la media e \\(\\sigma\\) è la deviazione standard.\nb. Qual è il significato di un valore z=2? E di un valore z=-1.5?\n\nUn \\(z = 2\\) significa che il dato è posizionato a 2 deviazioni standard sopra la media.\nUn \\(z = -1.5\\) significa che il dato è posizionato a 1.5 deviazioni standard sotto la media.\n\nc. Dopo la standardizzazione, quali saranno la media e la deviazione standard della variabile?\nDopo la standardizzazione:\n\nLa media diventa \\(0\\).\nLa deviazione standard diventa \\(1\\).\n\n4. Verifica della normalità\na. Se hai un piccolo campione di dati (circa 15 osservazioni), quali metodi grafici puoi utilizzare per valutare se segue una distribuzione normale?\nPer piccoli campioni, i metodi grafici più utili sono:\n\n\nQQ-plot (Quantile-Quantile plot): Confronta i quantili dei dati con quelli di una distribuzione normale. Se i punti seguono una retta diagonale, i dati sono normali.\n\nIstogramma: Mostra la distribuzione dei dati, ma con campioni piccoli può essere meno preciso.\n\nb. Quali strumenti statistici puoi impiegare per testare la normalità?\nGli strumenti statistici più comuni per verificare la normalità sono:\n\n\nTest di Shapiro-Wilk: Ideale per piccoli campioni.\n\nTest di Kolmogorov-Smirnov: Usato per confrontare la distribuzione empirica con una normale.\n\nTest di Anderson-Darling: Sensibile alle code della distribuzione.\n\nc. In un QQ-plot, come puoi riconoscere se i dati seguono una distribuzione normale?\nIn un QQ-plot:\n\nSe i dati seguono una distribuzione normale, i punti si allineeranno lungo una retta diagonale.\nDeviazioni dalla retta indicano departi dalla normalità:\n\nCode pesanti: Punti esterni alla retta suggeriscono outlier.\nAsimmetria: Punti curvati suggeriscono skewness (asimmetria).\n\n\n\nEsplorazione e Visualizzazione dei Dati SWLS\nCaricamento e struttura dei dati\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Supponiamo che i dati siano i seguenti\nset.seed(42)\nswls &lt;- data.frame(\n  ID = 1:15,\n  SWLS = c(18, 22, 25, 21, 26, 19, 20, 23, 24, 17, 22, 27, 28, 21, 19),\n  Genere = c(\"M\", \"F\", \"F\", \"M\", \"F\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"F\", \"M\", \"M\"),\n  LSNS = c(16, 20, 22, 14, 19, 18, 17, 25, 23, 12, 21, 28, 26, 19, 15)\n)\n\nstr(swls)\nsummary(swls$SWLS)\nVisualizzazioni\n# Istogramma con curva di densità\nggplot(swls, aes(x = SWLS)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 6, fill = \"blue\", alpha = 0.5) +\n  geom_density(color = \"red\", size = 1) +\n  gg(\"Distribuzione dei punteggi SWLS\")\n\n# Boxplot\nggplot(swls, aes(y = SWLS)) +\n  geom_boxplot(fill = \"cyan\") +\n  gg(\"Boxplot dei punteggi SWLS\")\n2. Confronto con la Distribuzione Normale\n# QQ-plot per valutare la normalità\nggplot(swls, aes(sample = SWLS)) +\n  geom_qq() +\n  geom_abline() +\n  gg(\"QQ-plot dei punteggi SWLS\") +\n  theme_minimal()\nOsservazione:\n\nSe i punti si allineano lungo la diagonale, i dati sono approssimativamente normali.\nSe ci sono deviazioni marcate, la distribuzione potrebbe essere asimmetrica o presentare code pesanti.\n\n3. Standardizzazione dei punteggi SWLS\nswls$Z_SWLS &lt;- scale(swls$SWLS)\n\nmean(swls$Z_SWLS)  # Dovrebbe essere circa 0\nsd(swls$Z_SWLS)    # Dovrebbe essere circa 1\n\n# Proporzione entro 1, 2, 3 deviazioni standard\nmean(abs(swls$Z_SWLS) &lt; 1)  # Atteso ~68%\nmean(abs(swls$Z_SWLS) &lt; 2)  # Atteso ~95%\nmean(abs(swls$Z_SWLS) &lt; 3)  # Atteso ~99.7%\n4. Relazione tra SWLS e LSNS\n# Grafico di dispersione\nggplot(swls, aes(x = LSNS, y = SWLS)) +\n  geom_point(color = \"blue\", size = 3) +\n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n  gg(\"Relazione tra SWLS e LSNS\") \n\n# Calcolo della correlazione\ncor(swls$SWLS, swls$LSNS)\nInterpretazione:\n\nUn valore di correlazione positivo indica che livelli più alti di supporto sociale (LSNS) sono associati a una maggiore soddisfazione della vita (SWLS).\n\nSe la correlazione è debole, il supporto sociale potrebbe non essere un predittore forte della soddisfazione della vita in questo campione ristretto.\n:::\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] gridExtra_2.3         dslabs_0.8.0          ggbeeswarm_0.7.2     \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] inline_0.3.21         sandwich_3.1-1        rlang_1.1.6          \n#&gt;  [4] magrittr_2.0.3        multcomp_1.4-28       snakecase_0.11.1     \n#&gt;  [7] compiler_4.5.1        systemfonts_1.2.3     vctrs_0.6.5          \n#&gt; [10] stringr_1.5.1         pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [13] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [16] rmarkdown_2.29        ragg_1.5.0            purrr_1.1.0          \n#&gt; [19] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [22] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [25] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [28] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [31] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [34] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [37] codetools_0.2-20      curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [40] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [43] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [46] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [49] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [52] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [55] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [58] tools_4.5.1           mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [61] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [64] beeswarm_0.4.0        vipor_0.4.7           cli_3.6.5            \n#&gt; [67] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [70] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [73] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [76] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [79] MASS_7.3-65",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_introduction_normal_distribution.html#bibliografia",
    "href": "chapters/eda/07_introduction_normal_distribution.html#bibliografia",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html",
    "href": "chapters/eda/08_correlation.html",
    "title": "21  Relazioni tra variabili",
    "section": "",
    "text": "Introduzione\nL’analisi delle associazioni tra variabili è un’operazione fondamentale nell’ambito della ricerca psicologica, ma nonostante la sua apparente semplicità, rappresenta uno degli aspetti più controversi e metodologicamente complessi. Sebbene possa sembrare un passaggio naturale successivo all’analisi univariata, questo processo solleva numerose questioni concettuali e pratiche che richiedono un’attenta riflessione.\nStoricamente, in psicologia, l’analisi delle associazioni tra variabili è stata spesso considerata come l’obiettivo finale del processo di ricerca. Questa visione si basa sull’idea che la descrizione delle relazioni tra variabili possa fornire una spiegazione esaustiva dei fenomeni psicologici. Tale approccio affonda le sue radici nel pensiero di Karl Pearson, il quale sosteneva che la spiegazione scientifica si esaurisse una volta delineate le associazioni tra le variabili osservate. Pearson (1911) affermava:\nSebbene sia indubbio che rispondere alla domanda posta da Pearson sia relativamente semplice, è altrettanto evidente che la nostra comprensione di un fenomeno non può dipendere unicamente dalle informazioni fornite dalle correlazioni. Le associazioni, infatti, non implicano causalità e possono risultare fuorvianti se interpretate in modo superficiale.\nIn contrasto con questa visione tradizionale, la cosiddetta “Causal Revolution” propone un paradigma radicalmente diverso, secondo il quale le associazioni tra variabili sono considerate come epifenomeni, ovvero manifestazioni superficiali di meccanismi più profondi. L’obiettivo principale della ricerca, in questo quadro, diventa l’identificazione e la comprensione delle relazioni causali. Per comprendere veramente i fenomeni psicologici, è essenziale indagare le cause sottostanti, andando oltre la mera descrizione delle associazioni.\nUn esempio emblematico è l’associazione tra il numero di scarpe e le abilità matematiche nei bambini. Questa correlazione è molto forte, ma se controlliamo per la variabile confondente “età”, l’associazione scompare. Questo dimostra che, in psicologia così come in altri campi, trovare correlazioni molto forti tra variabili non è necessariamente informativo riguardo ai meccanismi sottostanti al fenomeno studiato. È ovvio che il numero di scarpe non influisce sulle abilità matematiche, ma senza controllare per l’età, l’associazione rimane ingannevolmente forte.\nAllo stesso modo, può accadere che un’associazione apparentemente forte scompaia se non si tiene conto di variabili confondenti. Consideriamo, ad esempio, la relazione tra autostima e rendimento scolastico in un campione di adolescenti. Analizzando l’intera popolazione, la correlazione tra autostima e rendimento potrebbe risultare prossima a zero. Questo apparente risultato nullo, tuttavia, potrebbe nascondere una relazione più complessa, influenzata da un fattore confondente come il supporto familiare.\nQuando si controlla per il supporto familiare (ad esempio analizzando separatamente i gruppi con alto e basso sostegno), emerge una relazione positiva credibile tra autostima e rendimento scolastico all’interno del gruppo con supporto elevato. Questo esempio mostra come, a livello aggregato, l’effetto di due variabili possa apparire nullo, mentre il controllo per un confondente svela una relazione causale rilevante.\nIn conclusione, l’analisi delle associazioni rappresenta un punto di partenza fondamentale, ma non può sostituire l’indagine delle relazioni causali. Per progredire nella comprensione dei fenomeni psicologici, è necessario integrare l’analisi dei dati con modelli teorici robusti e un approccio critico volto a identificare e controllare i fattori confondenti. Solo così possiamo passare dalla semplice descrizione delle relazioni alla vera comprensione dei meccanismi causali che le governano.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#introduzione",
    "href": "chapters/eda/08_correlation.html#introduzione",
    "title": "21  Relazioni tra variabili",
    "section": "",
    "text": "“Quanto spesso, quando è stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‘qual è la sua causa?’. Questa è una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, può essere più facile rispondere alla domanda: ‘in che misura altri fenomeni sono associati con esso?’. Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze.”\n\n\n\n\n\n\nIn presenza di un forte supporto familiare, una maggiore autostima potrebbe effettivamente favorire migliori risultati scolastici.\n\nAl contrario, in assenza di tale supporto, anche livelli elevati di autostima potrebbero non tradursi in un rendimento scolastico migliore, a causa di risorse emotive e pratiche limitate.\n\n\n\nPanoramica del capitolo\n\nComprendere e calcolare la covarianza, la correlazione di Pearson e la correlazione di Spearman.\nCorrelazione e associazioni non lineari.\n\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere l’introduzione dell’articolo “The curious case of the cross-sectional correlation” (Hamaker, 2024).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(readr)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#terminologia",
    "href": "chapters/eda/08_correlation.html#terminologia",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.1 Terminologia",
    "text": "21.1 Terminologia\nLa discussione dei metodi utilizzati per individuare le relazioni causali sarà trattata successivamente. In questo capitolo, ci concentreremo sui concetti statistici fondamentali necessari per descrivere le associazioni lineari tra variabili. È importante sottolineare che, sebbene esistano indici statistici per quantificare associazioni non lineari, la maggior parte degli psicologi si limita all’utilizzo di indici lineari.\nNel linguaggio comune, termini come “dipendenza”, “associazione” e “correlazione” vengono spesso usati in modo intercambiabile. Tuttavia, da un punto di vista tecnico, è importante distinguere questi concetti:\n\n\nAssociazione: questo termine indica una relazione generale tra variabili, dove la conoscenza del valore di una variabile fornisce informazioni su un’altra.\n\nCorrelazione: descrive una relazione specifica e quantificabile, indicando se due variabili tendono a variare insieme in modo sistematico. Ad esempio, in una correlazione positiva, se \\(X &gt; \\mu_X\\), è probabile che anche \\(Y &gt; \\mu_Y\\). La correlazione specifica il segno e l’intensità di una relazione lineare.\n\nDipendenza: indica una relazione causale tra le variabili, dove la variazione della variabile causale porta probabilisticamente alla variazione della variabile dipendente.\n\nÈ cruciale comprendere che non tutte le associazioni sono correlazioni e, soprattutto, che la correlazione non implica necessariamente causalità. Questa distinzione è fondamentale per interpretare correttamente i dati e evitare conclusioni errate sulle relazioni tra variabili.\nIn questo capitolo, esamineremo due misure statistiche fondamentali per valutare la relazione lineare tra due variabili: la covarianza e la correlazione. Questi indici ci permettono di descrivere il grado e la direzione dell’associazione lineare tra variabili, quantificando come queste variano congiuntamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#analisi-della-relazione-tra-due-misure-della-depressione",
    "href": "chapters/eda/08_correlation.html#analisi-della-relazione-tra-due-misure-della-depressione",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.2 Analisi della relazione tra due misure della depressione",
    "text": "21.2 Analisi della relazione tra due misure della depressione\nL’obiettivo di questo esempio è esaminare la relazione tra due scale psicometriche che misurano la depressione: il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D). Lo studio di Zetsche et al. (2019) ha indagato se le aspettative negative possano costituire un meccanismo centrale nel mantenimento e nella reiterazione della depressione. In particolare, i ricercatori hanno confrontato 30 soggetti con almeno un episodio depressivo maggiore e 37 individui senza diagnosi depressiva.\nStrumenti di misurazione:\n\nBDI-II: strumento di autovalutazione che misura l’intensità dei sintomi depressivi riscontrati nelle ultime due settimane. Composto da 21 item, ciascuno valutato su una scala da 0 a 3, fornisce una stima della gravità della depressione.\nCES-D: scala anch’essa di autovalutazione, progettata per quantificare i sintomi depressivi sperimentati nella settimana precedente, principalmente in popolazioni generali, con particolare attenzione ad adolescenti e giovani adulti.\n\nPoiché entrambi gli strumenti mirano a misurare lo stesso costrutto, è ragionevole aspettarsi una relazione lineare tra i punteggi ottenuti, pur riconoscendo che errori di misurazione e unità di misura diverse possono generare discrepanze.\nPer verificare la relazione tra i punteggi BDI-II e CES-D, i dati sono stati processati come segue:\n\n# Leggi i dati dal file CSV\ndf &lt;- rio::import(here::here(\"data\", \"data.mood.csv\"))\n\n# Seleziona le colonne di interesse\ndf &lt;- df |&gt;\n  dplyr::select(\"esm_id\", \"group\", \"bdi\", \"cesd_sum\")\n\n# Rimuovi righe duplicate e casi con valori mancanti in 'bdi'\ndf &lt;- df[!duplicated(df), ]\ndf &lt;- df[!is.na(df$bdi), ]\n\nSuccessivamente, è stato realizzato un grafico a dispersione (scatterplot) in cui i valori del BDI-II sono stati posti sull’asse delle ascisse e quelli del CES-D sull’asse delle ordinate. Ogni punto rappresenta un partecipante, suddiviso per gruppo (soggetti depressi e controlli). L’aggiunta di una retta di regressione, ottenuta mediante un modello lineare, consente di valutare visivamente la tendenza di associazione tra le due misure.\n\n\n\n\n\n\n\n\nInterpretazione dei risultati: il grafico a dispersione evidenzia una tendenza approssimativamente lineare tra i punteggi del BDI-II e della CES-D, indicando che, in linea teorica, le due scale sono associate nel misurare il livello di depressione. Tuttavia, la presenza di una certa dispersione dei dati rispetto alla retta ideale sottolinea l’influenza degli errori di misurazione e della natura arbitraria delle unità di misura utilizzate. Per una valutazione più accurata della relazione, è necessario ricorrere a indici statistici in grado di quantificare sia la forza che la direzione dell’associazione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#covarianza",
    "href": "chapters/eda/08_correlation.html#covarianza",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.3 Covarianza",
    "text": "21.3 Covarianza\nIniziamo a considerare il più importante di tali indici, chiamato covarianza. In realtà la definizione di questo indice non ci sorprenderà più di tanto in quanto, in una forma solo apparentemente diversa, l’abbiamo già incontrata in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) è definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\tag{21.1}\\]\nLa varianza viene talvolta descritta come la “covarianza di una variabile con sé stessa”. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, ci chiediamo come due variabili \\(X\\) e \\(Y\\) “variano insieme” (co-variano). È facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{21.2}\\]\nL’Equazione 21.2 ci fornisce la definizione della covarianza.\n\n21.3.1 Interpretazione\nPer capire il significato dell’Equazione 21.2, supponiamo di dividere il grafico precedente in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avrà un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza avrà segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avrà un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza avrà segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l’associazione lineare si dice positiva se la covarianza è positiva, negativa se la covarianza è negativa.\n\n\n\n\n\n\nEsempio.\n\n\n\n\n\nImplementiamo l’Equazione 21.2 in R.\n\ncov_value &lt;- function(x, y) {\n  mean_x &lt;- sum(x) / length(x)\n  mean_y &lt;- sum(y) / length(y)\n\n  sub_x &lt;- x - mean_x\n  sub_y &lt;- y - mean_y\n\n  sum_value &lt;- sum(sub_y * sub_x)\n  denom &lt;- length(x)\n\n  cov &lt;- sum_value / denom\n  return(cov)\n}\n\nPer i dati mostrati nel diagramma, la covarianza tra BDI-II e CESD è 207.4\n\nx &lt;- df$bdi\ny &lt;- df$cesd_sum\n\ncov_value(x, y)\n#&gt; [1] 207\n\nOppure, in maniera più semplice:\n\nmean((x - mean(x)) * (y - mean(y)))\n#&gt; [1] 207\n\nLo stesso risultato si ottiene con la funzione cov:\n\ncov(x, y) * (length(x) - 1) / length(x)\n#&gt; [1] 207\n\nLa funzione cov(x, y) calcola la covarianza tra due array, x e y utilizzando \\(n-1\\) al denominatore.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione",
    "href": "chapters/eda/08_correlation.html#correlazione",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.4 Correlazione",
    "text": "21.4 Correlazione\nLa direzione della relazione tra le variabili è indicata dal segno della covarianza, ma il valore assoluto di questo indice non fornisce informazioni utili poiché dipende dall’unità di misura delle variabili. Ad esempio, considerando l’altezza e il peso delle persone, la covarianza sarà più grande se l’altezza è misurata in millimetri e il peso in grammi, rispetto al caso in cui l’altezza è in metri e il peso in chilogrammi. Pertanto, per descrivere la forza e la direzione della relazione lineare tra due variabili in modo adimensionale, si utilizza l’indice di correlazione.\nLa correlazione è ottenuta standardizzando la covarianza tramite la divisione delle deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr = \\frac{S_{XY}}{S_X S_Y}.\n\\tag{21.3}\\]\nLa quantità che si ottiene dall’Equazione 21.3 viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l’uno dall’altro, l’hanno introdotta).\nIn maniera equivalente, per una lista di coppie di valori \\((x_1, y_1), \\dots, (x_n, y_n)\\), il coefficiente di correlazione è definito come la media del prodotto dei valori standardizzati:\n\\[\nr = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{\\sigma_x} \\right) \\left( \\frac{y_i - \\bar{y}}{\\sigma_y} \\right),\n\\tag{21.4}\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) rappresentano, rispettivamente, le medie dei valori \\(x\\) e \\(y\\), e \\(\\sigma_x\\) e \\(\\sigma_y\\) sono le rispettive deviazioni standard.\nNell’Equazione 21.4, i valori \\(x_i\\) e \\(y_i\\) vengono prima standardizzati sottraendo la media e dividendo per la deviazione standard, e poi si calcola la media del prodotto di questi valori standardizzati.\n\n21.4.1 Proprietà\nIl coefficiente di correlazione ha le seguenti proprietà:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\nè un numero puro, cioè non dipende dall’unità di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\n21.4.2 Interpretazione\nAll’indice di correlazione possiamo assegnare la seguente interpretazione:\n\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\n\\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensità diversa;\n\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\n\n\n\n\n\n\nEsempio.\n\n\n\n\n\nPer i dati riportati nel diagramma della ?sec-zetsche-scatter, la covarianza è 207.4. Il segno positivo della covarianza ci dice che tra le due variabili c’è un’associazione lineare positiva. Per capire quale sia l’intensità della relazione lineare calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore è prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva.\nTroviamo la correlazione con la funzione corrcoef():\n\ncor(x, y)\n#&gt; [1] 0.904\n\nReplichiamo il risultato implementando l’Equazione 21.3:\n\ns_xy &lt;- mean((x - mean(x)) * (y - mean(y)))\ns_x &lt;- sqrt(mean((x - mean(x))^2)) # Deviazione standard popolazione\ns_y &lt;- sqrt(mean((y - mean(y))^2)) # Deviazione standard popolazione\nr_xy &lt;- s_xy / (s_x * s_y)\nprint(r_xy)\n#&gt; [1] 0.904\n\nUn altro modo ancora per trovare la correlazione tra i punteggi BDI-II e CESD è quello di applicare l’Equazione 21.4:\n\nz_x &lt;- (x - mean(x)) / sqrt(mean((x - mean(x))^2)) \n# Standardizzazione con deviazione standard popolazione\nz_y &lt;- (y - mean(y)) / sqrt(mean((y - mean(y))^2)) \n# Standardizzazione con deviazione standard popolazione\nmean(z_x * z_y)\n#&gt; [1] 0.904\n\n\n\n\n\n\n\n\n\n\nEsempio - Gender bias.\n\n\n\n\n\nUn uso interessante delle correlazioni viene fatto in un recente articolo di Guilbeault et al. (2024). Il concetto di “gender bias” si riferisce alla tendenza sistematica di favorire un sesso rispetto all’altro, spesso a scapito delle donne. Lo studio di Guilbeault et al. (2024) analizza come le immagini online influenzino la diffusione su vasta scala di questo preconcetto di genere.\nAttraverso un vasto insieme di immagini e testi raccolti online, gli autori dimostrano che sia le misurazioni basate sulle immagini che quelle basate sui testi catturano la frequenza con cui varie categorie sociali sono associate a rappresentazioni di genere, valutate su una scala da -1 (femminile) a 1 (maschile), con 0 che indica una neutralità di genere. Questo consente di quantificare il preconcetto di genere come una forma di bias statistico lungo tre dimensioni: la tendenza delle categorie sociali ad associarsi a un genere specifico nelle immagini e nei testi, la rappresentazione relativa delle donne rispetto agli uomini in tutte le categorie sociali nelle immagini e nei testi, e il confronto tra le associazioni di genere nei dati delle immagini e dei testi con la distribuzione empirica delle donne e degli uomini nella società. Il lavoro di Guilbeault et al. (2024) evidenzia che il preconcetto di genere è molto più evidente nelle immagini rispetto ai testi, come mostrato nel pannello C della figura.\nSi noti che, nel grafico del pannello C della figura, ogni punto può essere interpretato come una misura di correlazione. La misura utilizzata da Guilbeault et al. (2024) riflette il grado di associazione tra le categorie sociali e le rappresentazioni di genere presenti nelle immagini e nei testi analizzati. Quando la misura è vicina a +1, indica una forte associazione positiva tra una categoria sociale specifica e una rappresentazione di genere maschile, mentre un valore vicino a -1 indica una forte associazione negativa con una rappresentazione di genere femminile. Un valore di 0, invece, suggerisce che non vi è alcuna associazione tra la categoria sociale considerata e un genere specifico, indicando una sorta di neutralità di genere. In sostanza, questa misura di frequenza può essere interpretata come una correlazione che riflette la tendenza delle categorie sociali a essere rappresentate in un modo o nell’altro nelle immagini e nei testi analizzati, rispetto ai concetti di genere femminile e maschile.\n\n\nIl preconcetto di genere è più prevalente nelle immagini online (da Google Immagini) e nei testi online (da Google News). A. La correlazione tra le associazioni di genere nelle immagini da Google Immagini e nei testi da Google News per tutte le categorie sociali (n = 2.986), organizzate per decili. B. La forza dell’associazione di genere in queste immagini e testi online per tutte le categorie (n = 2.986), suddivisa in base al fatto che queste categorie siano inclinate verso il femminile o il maschile. C. Le associazioni di genere per un campione di occupazioni secondo queste immagini e testi online; questo campione è stato selezionato manualmente per evidenziare i tipi di categorie sociali e preconcetti di genere esaminati. (Figura tratta da Guilbeault et al. (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "href": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.5 Correlazione di Spearman",
    "text": "21.5 Correlazione di Spearman\nUn’alternativa per valutare la relazione lineare tra due variabili è il coefficiente di correlazione di Spearman, che si basa esclusivamente sull’ordine dei dati e non sugli specifici valori. Questo indice di associazione è particolarmente adatto quando gli psicologi sono in grado di misurare solo le relazioni di ordine tra diverse modalità di risposta dei soggetti, ma non l’intensità della risposta stessa. Tali variabili psicologiche che presentano questa caratteristica sono definite come “ordinali”.\n\n\n\n\n\n\nÈ importante ricordare che, nel caso di una variabile ordinale, non è possibile utilizzare le statistiche descrittive convenzionali come la media e la varianza per sintetizzare le osservazioni. Tuttavia, è possibile riassumere le osservazioni attraverso una distribuzione di frequenze delle diverse modalità di risposta. Come abbiamo appena visto, la direzione e l’intensità dell’associazione tra due variabili ordinali possono essere descritte utilizzando il coefficiente di correlazione di Spearman.\n\n\n\n\n\n\n\n\n\nEsempio.\n\n\n\n\n\nPer fornire un esempio, consideriamo due variabili di scala ordinale e calcoliamo la correlazione di Spearman tra di esse.\n\ncor.test(c(1, 2, 3, 4, 5), c(5, 6, 7, 8, 7), method = \"spearman\")\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  c(1, 2, 3, 4, 5) and c(5, 6, 7, 8, 7)\n#&gt; S = 4, p-value = 0.09\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt;   rho \n#&gt; 0.821",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#oltre-la-correlazione-e-la-covarianza-quando-lassociazione-tra-variabili-è-più-complessa",
    "href": "chapters/eda/08_correlation.html#oltre-la-correlazione-e-la-covarianza-quando-lassociazione-tra-variabili-è-più-complessa",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.6 Oltre la correlazione e la covarianza: quando l’associazione tra variabili è più complessa",
    "text": "21.6 Oltre la correlazione e la covarianza: quando l’associazione tra variabili è più complessa\nIn questo capitolo abbiamo introdotto due misure fondamentali per descrivere la relazione tra due variabili: covarianza e correlazione. La covarianza fornisce un’indicazione del modo in cui due variabili si discostano congiuntamente dalle proprie medie, mentre la correlazione ne standardizza i valori, permettendo un confronto più immediato tra diverse coppie di variabili e garantendo un indice compreso tra -1 e +1. Una correlazione vicina a +1 indica una forte relazione lineare positiva, vicina a -1 una forte relazione lineare negativa, mentre un valore vicino a 0 segnala l’assenza di una chiara relazione lineare.\nTuttavia, è cruciale comprendere che la correlazione descrive esclusivamente la dimensione lineare della relazione tra due variabili. Questo significa che una correlazione nulla (pari a zero) non implica affatto che non vi sia alcuna relazione tra le variabili, ma semplicemente che non esiste una relazione lineare. Possono esistere relazioni non lineari anche molto forti, non catturate da questo indice. Inoltre, altre situazioni possono trarre in inganno, come nei casi in cui i dati siano raggruppati in sottogruppi con proprietà differenti o siano frutto di particolari processi di selezione.\n\n21.6.1 Correlazione nulla e relazioni non lineari\nUna correlazione pari a zero può nascondere relazioni non lineari anche molto marcate. Per esempio, se una variabile Y aumenta solo quando X è molto alta o molto bassa, ma rimane costante per valori intermedi di X, questa curva a “U” può generare una correlazione vicina allo zero, pur esistendo un forte legame non lineare.\nUn esempio illustrativo è fornito dal cosiddetto Datasaurus Dozen, un insieme di tredici dataset con la stessa media, deviazione standard e correlazione tra le variabili, ma con distribuzioni visivamente e strutturalmente molto diverse. In ognuno di questi dataset la correlazione di Pearson è pari a zero, ma l’ispezione grafica rivela pattern e forme ben definite. Questo ci ricorda che è sempre bene accompagnare le misure numeriche con una visualizzazione grafica dei dati.\n\ndatasaurus_data &lt;- read.csv(\"../../data/datasaurus.csv\")\n\ndatasaurus_summary &lt;- datasaurus_data %&gt;%\n  group_by(dataset) %&gt;%\n  summarise(\n    x_count = n(),\n    x_mean = mean(x, na.rm = TRUE),\n    x_std = sd(x, na.rm = TRUE),\n    y_count = n(),\n    y_mean = mean(y, na.rm = TRUE),\n    y_std = sd(y, na.rm = TRUE)\n  )\n\ndatasaurus_summary\n#&gt; # A tibble: 13 × 7\n#&gt;    dataset    x_count x_mean x_std y_count y_mean y_std\n#&gt;    &lt;chr&gt;        &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt;  1 away           142   54.3  16.8     142   47.8  26.9\n#&gt;  2 bullseye       142   54.3  16.8     142   47.8  26.9\n#&gt;  3 circle         142   54.3  16.8     142   47.8  26.9\n#&gt;  4 dino           142   54.3  16.8     142   47.8  26.9\n#&gt;  5 dots           142   54.3  16.8     142   47.8  26.9\n#&gt;  6 h_lines        142   54.3  16.8     142   47.8  26.9\n#&gt;  7 high_lines     142   54.3  16.8     142   47.8  26.9\n#&gt;  8 slant_down     142   54.3  16.8     142   47.8  26.9\n#&gt;  9 slant_up       142   54.3  16.8     142   47.8  26.9\n#&gt; 10 star           142   54.3  16.8     142   47.8  26.9\n#&gt; 11 v_lines        142   54.3  16.8     142   47.8  26.9\n#&gt; 12 wide_lines     142   54.3  16.8     142   47.8  26.9\n#&gt; 13 x_shape        142   54.3  16.8     142   47.8  26.9\n\n\ndatasaurus_data |&gt;\n  ggplot(aes(x = x, y = y)) +\n  geom_point(alpha = 0.7) +\n  facet_wrap(~dataset, nrow = 4, ncol = 4) +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n\nTutti questi esempi rafforzano l’idea che l’assenza di correlazione lineare non significa assenza di relazione: potremmo avere strutture curve, pattern complessi o punti anomali (outlier) capaci di modificare radicalmente la forma della relazione tra le variabili.\nOltre alle relazioni non lineari, esistono situazioni in cui la correlazione, da sola, può fornire un’immagine distorta dei dati. Tra queste ricordiamo due fenomeni noti come il paradosso di Simpson e il paradosso di Berkson.\n\n21.6.2 Paradosso di Simpson\nIl paradosso di Simpson si verifica quando, guardando i dati raggruppati per sottogruppi, si osserva una certa relazione tra due variabili, ma aggregando i dati di tutti i sottogruppi insieme emerge una relazione opposta. In altre parole, la tendenza che appare quando si considerano i dati divisi per gruppi scompare o si inverte quando si esamina l’intero campione senza tenere conto della suddivisione in sottogruppi.\nImmaginiamo di avere due dipartimenti universitari, A e B. All’interno di ciascun dipartimento, la relazione tra il voto di laurea (X) e la performance in un successivo programma di specializzazione (Y) è positiva: all’aumentare del voto di laurea aumenta, in media, la performance nella scuola di specializzazione.\nTuttavia, supponiamo che il Dipartimento A abbia in generale voti di laurea mediamente più bassi, ma ottime performance nella specializzazione; mentre il Dipartimento B abbia voti di laurea mediamente più alti, ma performance alla specializzazione un po’ più basse. Se uniamo tutti gli studenti dei due dipartimenti senza considerarne l’appartenenza, potremmo osservare una relazione negativa tra voto di laurea e performance, sovvertendo le conclusioni tratte guardando ai singoli sottogruppi.\nEcco come possiamo simulare questi dati in R:\n\nset.seed(123)\n\n# Numero di osservazioni per dipartimento\nn &lt;- 100\n\n# Dipartimento A:\n# Voti di laurea (X) più bassi, ma performance (Y) più alta.\n# Creiamo un legame positivo tra X e Y all'interno di A.\nX_A &lt;- rnorm(n, mean = 50, sd = 5)    # Voti laurea mediamente più bassi\nY_A &lt;- X_A + rnorm(n, mean = 20, sd = 5) # Performance alta e correlata positivamente con X\n\n# Dipartimento B:\n# Voti di laurea (X) più alti, ma performance (Y) più bassa.\n# Anche qui creiamo un legame positivo tra X e Y all'interno di B, \n# ma con un offset tale che globalmente i voti alti coincidano con performance minori.\nX_B &lt;- rnorm(n, mean = 60, sd = 5)    # Voti laurea mediamente più alti\nY_B &lt;- X_B - rnorm(n, mean = 10, sd = 5) # Performance più bassa ma comunque correlata positivamente con X all’interno di B\n\n# Creiamo un dataframe con tutti i dati\ndipartimento &lt;- c(rep(\"A\", n), rep(\"B\", n))\nX &lt;- c(X_A, X_B)\nY &lt;- c(Y_A, Y_B)\ndati &lt;- data.frame(dipartimento, X, Y)\n\n# Correlazioni all'interno dei dipartimenti\ncat(\"Correlazione nel Dipartimento A:\", cor(X_A, Y_A), \"\\n\")\n#&gt; Correlazione nel Dipartimento A: 0.667\ncat(\"Correlazione nel Dipartimento B:\", cor(X_B, Y_B), \"\\n\")\n#&gt; Correlazione nel Dipartimento B: 0.693\n\n# Correlazione sull'intero dataset (senza distinguere i dipartimenti)\ncat(\"Correlazione globale:\", cor(X, Y), \"\\n\")\n#&gt; Correlazione globale: -0.335\n\n\n# Visualizziamo i dati\nggplot(dati, aes(x = X, y = Y, color = dipartimento)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    x = \"Voto di laurea\", \n    y = \"Performance\\nnella specializzazione\",\n    color = \"Dipartimento\"\n  )\n\n\n\n\n\n\n\n\nAll’interno del Dipartimento A: la correlazione tra voto di laurea (X) e performance (Y) è positiva. Ciò significa che, per gli studenti di A, avere un voto di laurea più alto è associato a una performance maggiore nella specializzazione.\nAll’interno del Dipartimento B: la correlazione tra X e Y è anch’essa positiva, indicando che anche nel secondo dipartimento voti più alti tendono ad accompagnarsi a performance più alte.\nConsiderando entrambi i dipartimenti insieme: a causa delle differenze nei livelli medi di X e Y tra i dipartimenti, unendo i dati senza distinguere il gruppo di appartenenza otteniamo una correlazione globale negativa. Questo significa che, ignorando la suddivisione in dipartimenti, sembra che aumentare il voto di laurea sia associato a una diminuzione della performance nella specializzazione — una conclusione opposta a quella tratta dall’analisi separata dei due sottogruppi.\n\nQuesto è un esempio concreto del paradosso di Simpson: la relazione osservata in sottogruppi omogenei si inverte quando si aggregano i dati, mettendo in guardia sulla necessità di considerare con attenzione la struttura dei dati e i fattori confondenti prima di trarre conclusioni.\n\n21.6.3 Paradosso di Berkson\nIl paradosso di Berkson è un fenomeno legato alla selezione del campione. Se il dataset non è rappresentativo della popolazione generale, la relazione osservata può risultare artificiale o opposta a quella esistente su un campione più ampio. Per esempio, analizzando solo ciclisti professionisti, potremmo non vedere alcuna relazione tra VO2 max e probabilità di vincere una gara, poiché tutti hanno già superato una certa soglia di VO2 max. Considerando la popolazione generale, invece, potrebbe emergere chiaramente una relazione positiva tra questi due fattori. Questo paradosso evidenzia l’importanza di considerare il processo di selezione dei dati e di chiedersi se il campione analizzato sia adeguato a rispondere alla domanda di ricerca.\n\n21.6.4 Limiti delle statistiche riassuntive semplici\nUn esempio famoso che dimostra i limiti delle semplici statistiche descrittive — come media, deviazione standard e correlazione — è il quartetto di Anscombe. Questo insieme di quattro piccoli dataset possiede identiche medie, varianze e correlazioni tra variabili, ma rappresenta relazioni estremamente differenti tra X e Y (Anscombe, 1973).\nImportiamo il dataset anscombe già disponibile nel pacchetto datasets di R:\n\ndata(\"anscombe\")\n\nanscombe |&gt; \n  head()\n#&gt;   x1 x2 x3 x4   y1   y2    y3   y4\n#&gt; 1 10 10 10  8 8.04 9.14  7.46 6.58\n#&gt; 2  8  8  8  8 6.95 8.14  6.77 5.76\n#&gt; 3 13 13 13  8 7.58 8.74 12.74 7.71\n#&gt; 4  9  9  9  8 8.81 8.77  7.11 8.84\n#&gt; 5 11 11 11  8 8.33 9.26  7.81 8.47\n#&gt; 6 14 14 14  8 9.96 8.10  8.84 7.04\n\nIl dataset anscombe contiene quattro serie di dati (x1, y1), (x2, y2), (x3, y3) e (x4, y4), ognuna costituita da 11 coppie di valori (x, y). Per comprendere meglio le loro caratteristiche, iniziamo calcolando alcune statistiche descrittive. La funzione apply() consente di applicare una funzione (ad esempio, mean) a tutte le colonne di un data frame. Usandola sulle colonne di anscombe, otteniamo le medie di ciascuna delle otto variabili (le quattro x e le quattro y):\n\napply(anscombe, MARGIN = 2, mean)\n#&gt;  x1  x2  x3  x4  y1  y2  y3  y4 \n#&gt; 9.0 9.0 9.0 9.0 7.5 7.5 7.5 7.5\n\nOsserviamo che le medie delle quattro variabili x sono identiche fino a sei cifre decimali, e le medie delle quattro variabili y differiscono solo in modo trascurabile (circa lo 0.01%). Analogamente, se calcoliamo le deviazioni standard per ciascuna variabile, notiamo una notevole somiglianza:\n\napply(anscombe, MARGIN = 2, sd)\n#&gt;   x1   x2   x3   x4   y1   y2   y3   y4 \n#&gt; 3.32 3.32 3.32 3.32 2.03 2.03 2.03 2.03\n\nAnche in questo caso, le deviazioni standard per le x coincidono fino alla sesta cifra decimale, mentre quelle delle y differiscono di meno dello 0.06%. Inoltre, se calcoliamo i coefficienti di correlazione tra x e y in ognuno dei quattro dataset, scopriamo che sono quasi identici:\n\n# Calcoliamo la correlazione per ciascuna coppia (x1,y1), (x2,y2), (x3,y3), (x4,y4)\nfor (i in 1:4) {\n  x_var &lt;- anscombe[[paste0(\"x\", i)]]\n  y_var &lt;- anscombe[[paste0(\"y\", i)]]\n  \n  corr_value &lt;- cor(x_var, y_var)\n  cat(\"Correlazione tra x\", i, \"e y\", i, \":\", corr_value, \"\\n\")\n}\n#&gt; Correlazione tra x 1 e y 1 : 0.816 \n#&gt; Correlazione tra x 2 e y 2 : 0.816 \n#&gt; Correlazione tra x 3 e y 3 : 0.816 \n#&gt; Correlazione tra x 4 e y 4 : 0.817\n\nSe ci limitassimo a guardare queste statistiche (media, deviazione standard, correlazione), potremmo facilmente essere indotti a concludere che i quattro dataset sono tra loro sostanzialmente indistinguibili. Tuttavia, la realtà è molto diversa. Le statistiche descrittive, prese da sole, non offrono una visione completa e possono nascondere importanti differenze nella struttura dei dati.\nQuesta differenza diventa evidente non appena decidiamo di visualizzare i dati. La rappresentazione grafica fornisce informazioni che non emergono dalle sole statistiche riassuntive:\n\nanscombe_m &lt;- tibble()\n\nfor (i in 1:4) {\n  anscombe_m &lt;- rbind(\n    anscombe_m, tibble(set = i, x = anscombe[, i], y = anscombe[, i + 4])\n  )\n}\n\nggplot(anscombe_m, aes(x, y)) +\n  geom_point(size = 3, shape = 21, fill=\"orange\") +\n  geom_smooth(method = \"lm\", fill = NA, fullrange = TRUE) +\n  facet_wrap(~set, ncol = 2)\n\n\n\n\n\n\n\nOsservando i grafici, notiamo subito che i quattro dataset sono profondamente diversi:\n\n\nDataset 1: Qui la relazione tra x e y è approssimativamente lineare, e la correlazione riflette in modo appropriato il legame tra le due variabili.\n\nDataset 2: Sebbene la correlazione sia simile a quella del Dataset 1, i dati mostrano una relazione curvilinea e non lineare. La semplice correlazione lineare non ne cattura la forma.\n\nDataset 3: La presenza di un singolo outlier distorce la percezione della relazione tra le variabili, altrimenti lineare. La correlazione alta è influenzata in modo sproporzionato da questo punto anomalo.\n\nDataset 4: Qui i dati non mostrano alcuna relazione lineare. La correlazione elevata è il frutto di un pattern fortemente atipico (ad esempio, una sola coppia di punti allineata).\n\nIl quartetto di Anscombe mette in luce un principio fondamentale: statistiche descrittive come media, deviazione standard e correlazione non sono sempre sufficienti per comprendere la natura dei dati. La visualizzazione grafica è essenziale per cogliere relazioni, pattern non lineari, outlier e altre caratteristiche che le semplici statistiche non riescono a rivelare. In definitiva, questo esempio dimostra che analizzare i dati soltanto attraverso poche statistiche di sintesi può portare a conclusioni fuorvianti, mentre l’integrazione con la rappresentazione grafica fornisce una visione più completa e accurata.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#riflessioni-conclusive",
    "href": "chapters/eda/08_correlation.html#riflessioni-conclusive",
    "title": "21  Relazioni tra variabili",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa covarianza e la correlazione sono strumenti preziosi per capire l’intensità e la direzione lineare di una relazione tra due variabili. Tuttavia, non dobbiamo confondere la loro semplicità con completezza d’informazione. Una correlazione nulla non implica assenza di relazione, ma solo assenza di una relazione lineare. Inoltre, il paradosso di Simpson e il paradosso di Berkson dimostrano che la semplice osservazione di correlazioni può essere fuorviante se non si tiene conto della struttura dei dati o del processo di selezione del campione.\nInfine, esempi come il quartetto di Anscombe sottolineano quanto sia fondamentale accompagnare le statistiche riassuntive con analisi grafiche e un’attenzione costante ai possibili pattern non lineari, agli outlier e alle caratteristiche peculiari del dataset. Nel prossimo capitolo esamineremo approcci che consentono di avvicinarsi alla comprensione causale dei fenomeni, andando oltre la semplice osservazione dell’associazione tra variabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#esercizi",
    "href": "chapters/eda/08_correlation.html#esercizi",
    "title": "21  Relazioni tra variabili",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizi Teorici\n\n\nDefinizioni fondamentali\n\nQual è la differenza tra associazione, correlazione e dipendenza?\n\nPerché la correlazione non implica causalità? Fai un esempio.\n\nIn quali situazioni la correlazione di Spearman è preferibile rispetto alla correlazione di Pearson?\n\n\n\nInterpretazione della correlazione\n\nQual è il range dei valori che può assumere la correlazione di Pearson?\n\nSe il coefficiente di correlazione tra due variabili è 0.85, come interpreteresti la loro relazione?\n\nSe il coefficiente di correlazione è -0.60, che tipo di relazione esiste tra le due variabili?\n\nQuali fattori potrebbero influenzare il valore della correlazione?\n\n\n\nCovarianza vs Correlazione\n\nQual è la differenza tra covarianza e correlazione?\n\nPerché la covarianza non è sempre interpretabile come misura della forza della relazione tra due variabili?\n\nQuali sono i vantaggi di usare la correlazione al posto della covarianza?\n\n\n\nGrafico a dispersione e correlazione\n\nOsservando un grafico a dispersione, quali caratteristiche ti permettono di identificare una relazione lineare positiva o negativa?\n\nDisegna (o descrivi verbalmente) un esempio di un dataset con una correlazione di circa 0, ma con una chiara relazione non lineare tra le variabili.\n\n\n\nEsercizi Pratici in R\n📌 Obiettivo: Analizzare le relazioni tra Satisfaction With Life Scale (SWLS) e Scala della Rete Sociale di Lubben (LSNS-6), calcolare covarianza e correlazione, e visualizzare i dati per individuare pattern.\nDati disponibili:\nUsa i dati raccolti per le variabili SWLS e LSNS, oltre al genere dei partecipanti.\n1. Esplorazione e Visualizzazione della Relazione tra SWLS e LSNS\n\n\nCarica i dati raccolti dagli studenti e verifica la struttura del dataset.\n\n\nCalcola le statistiche descrittive: media, deviazione standard, minimo, massimo e quartili delle variabili SWLS e LSNS.\n\n\nCrea un grafico a dispersione tra SWLS e LSNS:\n\nColora i punti in base al genere del partecipante.\n\nAggiungi una linea di regressione per evidenziare il trend della relazione.\n\n\n\n2. Calcolo della Covarianza e della Correlazione tra SWLS e LSNS\n\n\nCalcola la covarianza tra SWLS e LSNS usando la formula matematica della covarianza e confrontala con il valore ottenuto con cov().\n\n\nCalcola la correlazione di Pearson e commenta il risultato:\n\nLa relazione è forte o debole?\n\nHa segno positivo o negativo?\n\nÈ coerente con quanto osservato nel grafico a dispersione?\n\n\n\n\nCalcola la correlazione di Spearman e confrontala con quella di Pearson. Quale delle due è più appropriata per questi dati?\n\n3. Analisi delle Associazioni per Gruppi\n\n\nCalcola la correlazione separatamente per i partecipanti di genere maschile e femminile.\n\n\nConfronta i risultati: la relazione tra SWLS e LSNS è simile nei due gruppi o ci sono differenze?\n\n\nVisualizza i dati con due grafici a dispersione distinti per maschi e femmine.\n\n4. Correlazione Nulla e Pattern Non Lineari\n\n\nSimula un dataset in cui la correlazione di Pearson è vicina a 0, ma esiste una chiara relazione non lineare tra le variabili.\n\n\nCostruisci un grafico a dispersione per osservare il pattern nei dati.\n\n\nCalcola la correlazione di Spearman e confrontala con quella di Pearson. Quale delle due cattura meglio la relazione nei dati?\n\nConsegna il file .qmd compilato in PDF contenente il codice, le visualizzazioni e le interpretazioni.\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Definizioni fondamentali\n1.1 Differenza tra associazione, correlazione e dipendenza:\n\n\nAssociazione: Indica una relazione generica tra due variabili, senza specificare la natura o la direzione della relazione.\n\nCorrelazione: Misura la forza e la direzione di una relazione lineare tra due variabili. Può essere positiva (variabili aumentano insieme) o negativa (una variabile aumenta mentre l’altra diminuisce).\n\nDipendenza: Indica che una variabile è influenzata da un’altra, ma non implica necessariamente una relazione lineare. La dipendenza può essere causale o statistica.\n\n1.2 Perché la correlazione non implica causalità:\nLa correlazione misura solo la relazione lineare tra due variabili, ma non indica se una variabile causa l’altra. Un esempio classico è la correlazione tra il consumo di gelati e il numero di annegamenti: entrambi aumentano in estate, ma non c’è un nesso causale diretto. Un terzo fattore (il caldo) influenza entrambe le variabili.\n1.3 Quando preferire la correlazione di Spearman rispetto a quella di Pearson:\n\nQuando i dati non sono distribuiti normalmente.\nQuando ci sono outlier che potrebbero distorcere la correlazione di Pearson.\nQuando la relazione tra le variabili è monotona (sempre crescente o decrescente) ma non lineare.\n\n2. Interpretazione della correlazione\n2.1 Range dei valori della correlazione di Pearson:\nLa correlazione di Pearson assume valori compresi tra -1 e 1: - 1: Correlazione lineare positiva perfetta. - -1: Correlazione lineare negativa perfetta. - 0: Nessuna correlazione lineare.\n2.2 Interpretazione di un coefficiente di 0.85:\nUn coefficiente di 0.85 indica una forte relazione lineare positiva tra le due variabili. All’aumentare di una variabile, l’altra tende ad aumentare in modo consistente.\n2.3 Interpretazione di un coefficiente di -0.60:\nUn coefficiente di -0.60 indica una relazione lineare negativa moderata. All’aumentare di una variabile, l’altra tende a diminuire.\n2.4 Fattori che influenzano la correlazione:\n\n\nOutlier: Possono distorcere il valore della correlazione.\n\nDistribuzione non lineare: La correlazione di Pearson non cattura relazioni non lineari.\n\nRange ristretto delle variabili: Se i dati coprono solo una piccola parte del range possibile, la correlazione potrebbe essere sottostimata.\n\n3. Covarianza vs Correlazione\n3.1 Differenza tra covarianza e correlazione:\n\n\nCovarianza: Misura la direzione della relazione tra due variabili, ma il suo valore dipende dalle unità di misura delle variabili.\n\nCorrelazione: Standardizza la covarianza, rendendola adimensionale e consentendo confronti tra diverse coppie di variabili.\n\n3.2 Perché la covarianza non è sempre interpretabile:\nLa covarianza non è standardizzata, quindi il suo valore non fornisce informazioni sulla forza della relazione. Ad esempio, una covarianza di 1000 potrebbe indicare una relazione forte o debole, a seconda delle unità di misura.\n3.3 Vantaggi della correlazione rispetto alla covarianza:\n\nÈ adimensionale, quindi può essere confrontata tra diverse coppie di variabili.\nAssume valori compresi tra -1 e 1, facilitando l’interpretazione della forza e della direzione della relazione.\n\n4. Grafico a dispersione e correlazione\n4.1 Caratteristiche di un grafico a dispersione per identificare relazioni lineari:\n\n\nRelazione lineare positiva: I punti si dispongono lungo una linea retta con pendenza positiva.\n\nRelazione lineare negativa: I punti si dispongono lungo una linea retta con pendenza negativa.\n\nNessuna relazione lineare: I punti sono sparsi senza un pattern evidente.\n\n4.2 Esempio di dataset con correlazione circa 0 ma relazione non lineare:\nImmagina un dataset in cui una variabile \\(x\\) assume valori simmetrici intorno a 0 (ad esempio, da -5 a 5), e la variabile \\(y\\) è uguale a \\(x^2\\). In questo caso:\n\nLa correlazione di Pearson sarà circa 0, perché non c’è una relazione lineare.\nTuttavia, esiste una chiara relazione non lineare (quadratica) tra \\(x\\) e \\(y\\).\n\nDescrizione verbale:\nI punti formano una parabola, con \\(y\\) che aumenta sia quando \\(x\\) è positivo che negativo. La correlazione di Pearson non cattura questa relazione, mentre la correlazione di Spearman potrebbe farlo.\n1. Esplorazione e Visualizzazione della Relazione tra SWLS e LSNS\n1.1 Carica i dati raccolti dagli studenti e verifica la struttura del dataset Simuliamo un dataset con 100 partecipanti, includendo le variabili SWLS (Soddisfazione di Vita), LSNS (Rete Sociale), e Genere.\n# Simulazione dei dati\nset.seed(123)\nn &lt;- 100\ngenere &lt;- sample(c(\"Maschio\", \"Femmina\"), n, replace = TRUE)\nswls &lt;- round(rnorm(n, mean = 20, sd = 5), 1)  # SWLS: Scala 5-35\nlsns &lt;- round(rnorm(n, mean = 12, sd = 4), 1)   # LSNS: Scala 0-30\n\n# Creazione del dataset\ndati &lt;- data.frame(Genere = genere, SWLS = swls, LSNS = lsns)\n\n# Verifica della struttura\nstr(dati)\nhead(dati)\n1.2 Calcola le statistiche descrittive\n# Statistiche descrittive per SWLS e LSNS\nsummary(dati$SWLS)\nsummary(dati$LSNS)\n\n# Media e deviazione standard\nmean(dati$SWLS)\nsd(dati$SWLS)\nmean(dati$LSNS)\nsd(dati$LSNS)\n1.3 Crea un grafico a dispersione\nlibrary(ggplot2)\n\nggplot(dati, aes(x = SWLS, y = LSNS, color = Genere)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") +\n  labs(\n       x = \"Soddisfazione di Vita (SWLS)\",\n       y = \"Rete Sociale (LSNS)\") +\n  theme_minimal()\n2. Calcolo della Covarianza e della Correlazione tra SWLS e LSNS\n2.1 Calcola la covarianza\n# Covarianza manuale\ncov_manual &lt;- sum((dati$SWLS - mean(dati$SWLS)) * (dati$LSNS - mean(dati$LSNS))) / (n - 1)\ncov_manual\n\n# Covarianza con funzione R\ncov(dati$SWLS, dati$LSNS)\n2.2 Calcola la correlazione di Pearson\ncor_pearson &lt;- cor(dati$SWLS, dati$LSNS, method = \"pearson\")\ncor_pearson\n\n\nCommento: La correlazione è [valore], indicando una relazione [forte/debole] e [positiva/negativa]. Questo è coerente con il grafico a dispersione.\n\n2.3 Calcola la correlazione di Spearman\ncor_spearman &lt;- cor(dati$SWLS, dati$LSNS, method = \"spearman\")\ncor_spearman\n\n\nConfronto: La correlazione di Spearman è più appropriata se i dati non sono distribuiti normalmente o presentano outlier.\n\n3. Analisi delle Associazioni per Gruppi\n3.1 Calcola la correlazione separatamente per genere\n# Maschi\ncor_maschi &lt;- cor(dati$SWLS[dati$Genere == \"Maschio\"], dati$LSNS[dati$Genere == \"Maschio\"], method = \"pearson\")\n\n# Femmine\ncor_femmine &lt;- cor(dati$SWLS[dati$Genere == \"Femmina\"], dati$LSNS[dati$Genere == \"Femmina\"], method = \"pearson\")\n\ncor_maschi\ncor_femmine\n3.2 Confronta i risultati\n\n\nCommento: La correlazione è [simile/diversa] tra maschi e femmine, suggerendo [presenza/assenza] di differenze di genere.\n\n3.3 Visualizza i dati con grafici distinti\nggplot(dati, aes(x = SWLS, y = LSNS, color = Genere)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~ Genere) +\n  labs(\n       x = \"Soddisfazione di Vita (SWLS)\",\n       y = \"Rete Sociale (LSNS)\") +\n  theme_minimal()\n4. Correlazione Nulla e Pattern Non Lineari\n4.1 Simula un dataset con correlazione nulla ma relazione non lineare\nset.seed(123)\nx &lt;- rnorm(100, mean = 0, sd = 1)\ny &lt;- x^2 + rnorm(100, mean = 0, sd = 0.5)  # Relazione quadratica\ndati_non_lineari &lt;- data.frame(x = x, y = y)\n\n# Correlazione di Pearson\ncor_pearson_non_lineare &lt;- cor(dati_non_lineari$x, dati_non_lineari$y, method = \"pearson\")\ncor_pearson_non_lineare  # Dovrebbe essere vicina a 0\n4.2 Costruisci un grafico a dispersione\nggplot(dati_non_lineari, aes(x = x, y = y)) +\n  geom_point(size = 3) +\n  labs(\n       x = \"Variabile X\",\n       y = \"Variabile Y\") \n4.3 Calcola la correlazione di Spearman\ncor_spearman_non_lineare &lt;- cor(dati_non_lineari$x, dati_non_lineari$y, method = \"spearman\")\ncor_spearman_non_lineare  # Dovrebbe catturare la relazione non lineare\n\n\nConfronto: La correlazione di Spearman è più adatta per catturare relazioni non lineari.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] readr_2.1.5           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        mgcv_1.9-3           \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        tzdb_0.5.0            ragg_1.4.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            R.utils_2.13.0        pacman_0.5.1         \n#&gt; [37] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [40] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [43] codetools_0.2-20      curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [46] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [55] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [58] rprojroot_2.1.1       hms_1.1.3             rstantools_2.4.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.1     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_6.0.6              gtable_0.3.6          R.methodsS3_1.8.2    \n#&gt; [79] digest_0.6.37         TH.data_1.1-3         htmlwidgets_1.6.4    \n#&gt; [82] farver_2.1.2          R.oo_1.27.1           memoise_2.0.1        \n#&gt; [85] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#bibliografia",
    "href": "chapters/eda/08_correlation.html#bibliografia",
    "title": "21  Relazioni tra variabili",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAnscombe, F. J. (1973). Graphs in statistical analysis. The American Statistician, 27(1), 17–21.\n\n\nHamaker, E. (2024). The curious case of the cross-sectional correlation. Multivariate Behavioral Research, 59(6), 1111–1122.\n\n\nPearson, K. (1911). The Grammar of Science: Part I. Physical. Adam & Charles Black.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html",
    "href": "chapters/eda/09_causality.html",
    "title": "22  Causalità dai dati osservazionali",
    "section": "",
    "text": "Introduzione\nQuando in psicologia ci chiediamo perché un fenomeno si verifica, stiamo entrando nel territorio della causalità. Per esempio: l’esposizione a situazioni di stress causa davvero un aumento dei sintomi depressivi? Oppure si tratta solo di una correlazione, magari dovuta a un terzo fattore che non abbiamo considerato?\nQuesta distinzione tra correlazione e causalità è fondamentale:\nIn psicologia e nelle scienze sociali non possiamo quasi mai fare esperimenti perfettamente controllati, come avviene in laboratorio nelle scienze naturali. Per questo motivo, abbiamo bisogno di strumenti teorici e statistici che ci aiutino a ragionare in termini causali anche quando i dati provengono da studi osservativi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#introduzione",
    "href": "chapters/eda/09_causality.html#introduzione",
    "title": "22  Causalità dai dati osservazionali",
    "section": "",
    "text": "la correlazione ci dice che due variabili variano insieme;\n\nla causalità implica invece che una variabile produce un cambiamento nell’altra.\n\n\nPanoramica del capitolo\n\nIl problema della causalità in assenza di esperimenti.\nI quattro confondenti fondamentali (catena, biforcazione, collider, discendente).\nLe inferenze dai dati osservazionali.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Statistical Rethinking. Focalizzati sul capitolo 1 The Golem of Prague.\nLeggere Causal inference with observational data and unobserved confounding variables di Byrnes & Dee (2024).\nLeggere Causal design patterns for data anal\\(Y\\)sts (Riederer, 2021). Questo post sul blog fornisce una panoramica di diversi approcci per fare affermazioni causali dai dati osservazionali.\nLeggere The Effect: An Introduction to Research Design and Causality. Focalizzati sul capitolo 10 Treatment Effects.\nLeggere Causal Inference di Scott Cunningham. Focalizzati sul capitolo 3 Directed Acyclic Graphs.\nLeggere Telling Stories with Data (Alexander, 2023). Concentrati sul capitolo 15 Causalit\\(Y\\) from observational data.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\nconflicts_prefer(ggplot2::theme_void)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#il-ruolo-dei-modelli",
    "href": "chapters/eda/09_causality.html#il-ruolo-dei-modelli",
    "title": "22  Causalità dai dati osservazionali",
    "section": "\n22.1 Il ruolo dei modelli",
    "text": "22.1 Il ruolo dei modelli\nImmaginiamo di osservare che studenti che dormono poco tendono a riportare più ansia. Possiamo dire che dormire poco causa ansia? Oppure è possibile che l’ansia causi insonnia? O magari entrambe le variabili sono influenzate da un terzo fattore, ad esempio periodi di esami universitari? Questo semplice esempio mostra che i dati da soli non bastano: dobbiamo avere un modello teorico che ci guidi nell’interpretazione.\nI modelli statistici ci aiutano a formalizzare queste ipotesi causali:\n\nun modello puramente descrittivo si limita a dire che due variabili sono associate;\n\nun modello causale, invece, esplicita ipotesi su come e perché una variabile influenza un’altra.\n\nLo scopo di questo capitolo è introdurre alcuni strumenti concettuali di base per distinguere tra correlazione e causalità e per capire come i modelli possano essere usati in psicologia per affrontare domande causali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#correlazione-non-significa-causalità",
    "href": "chapters/eda/09_causality.html#correlazione-non-significa-causalità",
    "title": "22  Causalità dai dati osservazionali",
    "section": "\n22.2 Correlazione non significa causalità",
    "text": "22.2 Correlazione non significa causalità\nUno degli errori più comuni in psicologia è confondere la correlazione con la causalità. Se due variabili si muovono insieme, non significa necessariamente che una sia la causa dell’altra.\n\n22.2.1 Esempio classico\nSupponiamo di osservare che, durante l’estate, aumenta sia il consumo di gelati sia il numero di persone che hanno colpi di calore. È forse il consumo di gelati a causare i colpi di calore? Oppure sono i colpi di calore a spingere le persone a mangiare più gelati? La risposta, ovviamente, è che entrambe le variabili sono influenzate da un fattore esterno: la temperatura. Il caldo estivo aumenta sia la voglia di gelato sia il rischio di colpo di calore.\n\n22.2.2 Un esempio psicologico\nDurante i periodi d’esame universitari aumentano sia lo stress sia i disturbi del sonno. Dobbiamo concludere che lo stress causa direttamente insonnia? Oppure che l’insonnia genera stress? La spiegazione più plausibile è che entrambe le variabili dipendano da un fattore esterno comune: la pressione del contesto degli esami.\nQuesta situazione, in cui due variabili sono legate da una causa comune, si chiama confondimento.\n\n22.2.3 Perché è importante in psicologia\nNegli studi psicologici, spesso osserviamo correlazioni interessanti: ad esempio, tra uso dei social media e benessere psicologico. Ma senza un modello causale, non possiamo dire se:\n\nsono i social media a ridurre il benessere,\n\nse chi ha meno benessere tende a usare di più i social,\n\noppure se entrambe le cose dipendono da un terzo fattore, come la solitudine.\n\n22.2.4 La lezione da ricordare\nLa correlazione è un punto di partenza utile, ma non basta per stabilire una relazione di causa-effetto. Per andare oltre, dobbiamo introdurre strumenti che ci aiutino a rappresentare e testare ipotesi causali, come vedremo nelle sezioni successive.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#rappresentare-le-relazioni-causali",
    "href": "chapters/eda/09_causality.html#rappresentare-le-relazioni-causali",
    "title": "22  Causalità dai dati osservazionali",
    "section": "\n22.3 Rappresentare le relazioni causali",
    "text": "22.3 Rappresentare le relazioni causali\nPer ragionare in modo chiaro sulle relazioni di causa-effetto è utile avere un linguaggio formale. Uno degli strumenti più potenti a questo scopo è rappresentare le relazioni tra variabili con un grafo causale.\n\n22.3.1 Che cos’è un grafo causale\nUn grafo causale è un diagramma formato da:\n\n\nnodi, che rappresentano le variabili di interesse (ad esempio: stress, ansia, sonno);\n\n\nfrecce, che indicano ipotesi di influenza causale (ad esempio: lo stress → ansia).\n\nQuesti grafi non sono semplici figure illustrative: sono veri e propri modelli che esplicitano le nostre ipotesi su come le variabili si influenzano.\n\n22.3.2 Un esempio psicologico\nImmaginiamo di voler studiare il legame tra stress e rendimento universitario. Possiamo proporre un grafo causale come questo:\n\nStress → Qualità del sonno → Rendimento agli esami\n\nQui stiamo ipotizzando che lo stress riduca la qualità del sonno, e che a sua volta un sonno peggiore abbassi il rendimento. In altre parole, il sonno agisce da variabile mediatore.\n\n22.3.3 Perché è utile\nRappresentare i dati in questo modo ci permette di:\n\ndistinguere tra relazioni dirette e indirette.\n\nchiarire il ruolo di possibili variabili di confondimento.\n\nprogettare meglio i nostri studi (per esempio, decidere quali variabili misurare per testare una certa ipotesi).\n\n22.3.4 Un avvertimento\nUn grafo causale non ci dice automaticamente quale ipotesi è vera: rappresenta solo ciò che crediamo sia plausibile. Sta poi ai dati e alle analisi statistiche confermare o mettere in discussione queste ipotesi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#confondimento-mediazione-e-altre-relazioni-causali",
    "href": "chapters/eda/09_causality.html#confondimento-mediazione-e-altre-relazioni-causali",
    "title": "22  Causalità dai dati osservazionali",
    "section": "\n22.4 Confondimento, mediazione e altre relazioni causali",
    "text": "22.4 Confondimento, mediazione e altre relazioni causali\nNei modelli causali non tutte le variabili hanno lo stesso ruolo. È importante distinguere tra diversi tipi di relazioni, perché ognuna porta a interpretazioni diverse.\n\n22.4.1 Variabili di confondimento\nUna variabile di confondimento è una variabile che influenza sia la presunta causa sia l’effetto. Se non la consideriamo, rischiamo di attribuire una relazione causale dove in realtà non c’è.\nEsempio. Osserviamo che gli studenti che usano più spesso i social media riportano più sintomi depressivi. Potremmo pensare che siano i social media a causare depressione. Ma un possibile confondente è la solitudine: gli studenti più soli potrebbero usare di più i social e allo stesso tempo sentirsi più depressi. Se non teniamo conto della solitudine, rischiamo di trarre conclusioni errate.\n\n22.4.2 Variabili mediatrici\nUna variabile mediatrice è invece un “anello di passaggio” nella catena causale. Non distorce la relazione, ma la spiega.\nEsempio. Stress → Qualità del sonno → Ansia. Qui il sonno media l’effetto dello stress sull’ansia: lo stress peggiora il sonno, e il cattivo sonno aumenta l’ansia.\n\n22.4.3 Variabili moderatrici\nUn’altra distinzione utile è quella delle variabili moderatrici: fattori che non spiegano la relazione, ma ne modificano la forza o la direzione.\nEsempio. L’effetto dello stress sull’ansia potrebbe essere più forte negli studenti al primo anno rispetto a quelli degli anni successivi. Qui l’“anno di corso” agisce da moderatore.\nCapire se una variabile è un confondente, un mediatore o un moderatore è fondamentale per interpretare correttamente i dati psicologici e per costruire modelli causali realistici.\n\n22.4.4 Le quattro configurazioni fondamentali nei DAG\nPer capire bene come funzionano i grafi causali, è utile conoscere le quattro strutture di base con cui due variabili possono essere collegate attraverso una terza.\n\n\nCatena (chain)\\(X \\rightarrow Z \\rightarrow Y\\)\nQui \\(Z\\) è un mediatore: trasmette l’effetto di \\(X\\) su \\(Y\\).\n\nSe non controlliamo per \\(Z\\), \\(X\\) e \\(Y\\) appaiono correlati.\n\nSe controlliamo per \\(Z\\), l’effetto di \\(X\\) su \\(Y\\) “scompare”, perché passa interamente da \\(Z\\).\n\n\n\nBiforcazione (fork)\\(X \\leftarrow Z \\rightarrow Y\\)\nQui \\(Z\\) è un confondente: causa sia \\(X\\) che \\(Y\\).\n\nSe non controlliamo per \\(Z\\), vediamo una correlazione spuriosa tra \\(X\\) e \\(Y\\).\n\nSe controlliamo per \\(Z\\), la correlazione spuria scompare.\n\n\n\nCollider\\(X \\rightarrow Z \\leftarrow Y\\)\nQui \\(Z\\) è un effetto comune di \\(X\\) e \\(Y\\).\n\nSe non controlliamo per \\(Z\\), \\(X\\) e \\(Y\\) sono indipendenti.\n\nSe invece controlliamo per \\(Z\\) (o per un suo discendente), creiamo artificialmente una correlazione spuriosa.\n\n\n\nDiscendente\\(X \\rightarrow Y \\rightarrow Z\\)\nQui \\(Z\\) è un discendente di \\(Y\\): porta informazioni sull’effetto di \\(X\\), ma non va confuso con un confondente.\n\nControllare un discendente può introdurre bias, perché significa “tagliare” il percorso naturale della causalità.\n\n\n\n\n22.4.4.1 Perché è importante\nQueste quattro configurazioni sono le “mattonelle di base” con cui si costruiscono tutti i DAG più complessi. Capire quando conviene controllare una variabile (catena, fork) e quando invece non bisogna farlo (collider, discendente) è essenziale per evitare errori nell’inferenza causale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#dai-grafi-causali-allinferenza-statistica",
    "href": "chapters/eda/09_causality.html#dai-grafi-causali-allinferenza-statistica",
    "title": "22  Causalità dai dati osservazionali",
    "section": "\n22.5 Dai grafi causali all’inferenza statistica",
    "text": "22.5 Dai grafi causali all’inferenza statistica\nFinora abbiamo visto che i grafi causali servono a rappresentare le nostre ipotesi. Ma come possiamo collegarli ai dati e verificare se un modello causale è plausibile?\n\n22.5.1 Indipendenze e dipendenze\nUn’idea chiave è che un grafo causale non descrive solo “chi influenza chi”, ma implica anche certe relazioni di indipendenza tra le variabili.\nQueste relazioni sono importanti perché ci permettono di confrontare il grafo con i dati: se le indipendenze predette non si verificano, il grafo non può essere corretto.\n\n22.5.1.1 Esempio 1: Catena (mediazione)\nSupponiamo di ipotizzare che: Stress → Sonno → Ansia. Qui il sonno media l’effetto dello stress sull’ansia. Se non conosciamo il livello di sonno, stress e ansia risulteranno correlati. Ma condizionando sul sonno, lo stress non ci dà più informazioni aggiuntive sull’ansia.\nIn termini statistici:\n\\[\n\\text{Ansia} \\;\\perp\\!\\!\\!\\perp\\; \\text{Stress} \\mid \\text{Sonno}\n\\]\n\n22.5.1.2 Esempio 2: Fork (causa comune)\nConsideriamo ora: Sonno → Stress; Sonno → Ansia. Qui il sonno è un confondente: influenza sia stress che ansia. Se non controlliamo per il sonno, vediamo una correlazione spuriosa tra stress e ansia. Se invece condizioniamo sul sonno, questa correlazione scompare.\nFormalmente anche qui:\n\\[\n\\text{Ansia} \\;\\perp\\!\\!\\!\\perp\\; \\text{Stress} \\mid \\text{Sonno}\n\\]\n\n22.5.1.3 Esempio 3: Collider (effetto comune)\nOra immaginiamo: Stress → Ansia ← Sonno. Qui l’ansia è un collider, cioè un effetto comune di stress e sonno. In questo caso accade l’opposto:\n\nsenza condizionare su ansia, stress e sonno sono indipendenti;\n\nse invece controlliamo per ansia (o per una sua conseguenza), introduciamo artificialmente una correlazione spuriosa.\n\nFormalmente:\n\\[\n\\text{Stress} \\;\\perp\\!\\!\\!\\perp\\; \\text{Sonno} \\quad \\text{ma non} \\quad \\text{Stress} \\;\\perp\\!\\!\\!\\perp\\; \\text{Sonno} \\mid \\text{Ansia}\n\\]\n\n22.5.2 Tabella riassuntiva\n\n\n\n\n\n\n\n\nStruttura\nForma\nRelazione tra \\(X\\) e \\(Y\\)\n\nDopo aver controllato \\(Z\\)\n\n\n\n\n\nCatena (mediazione)\n\\(X \\to Z \\to Y\\)\nDipendenti\nIndipendenti\n\n\n\nFork (causa comune)\n\\(X \\leftarrow Z \\to Y\\)\nDipendenti (spuria)\nIndipendenti\n\n\n\nCollider (effetto comune)\n\\(X \\to Z \\leftarrow Y\\)\nIndipendenti\nDipendenti (spuri)\n\n\n\n22.5.3 Le quattro configurazioni nei DAG\nDi seguito trovi quattro figure minime che illustrano Catena, Fork, Collider e Discendente.\n\n\n\n\n\n\n\nFigura 22.1: Quattro configurazioni base dei DAG: Catena, Fork, Collider, Discendente.\n\n\n\n\n\n\n\n\n\n\nErrore comune: controllare i collider!\n\n\n\n\n\nCollider: struttura \\(X \\to Z \\leftarrow Y\\).\n\nSenza controllare \\(Z\\): \\(X\\) e \\(Y\\) sono indipendenti.\n\n\nControllando \\(Z\\) (o un suo discendente): si crea una correlazione spuriosa tra \\(X\\) e \\(Y\\).\n\n\n\nMorale pratica:\n- Con catena e fork conviene spesso controllare \\(Z\\) (per rimuovere associazioni non causali o isolare l’effetto diretto).\n- Con i collider (e loro discendenti) non bisogna controllare \\(Z\\): si introduce bias invece di rimuoverlo.\n\n\n\n22.5.4 Perché è importante\nQuesti esempi mostrano che il significato di indipendenza condizionata dipende dalla struttura del grafo. In pratica:\n\ncon catene e fork, condizionare “rompe” la correlazione;\n\ncon i collider, condizionare la crea.\n\nSapere in quali casi conviene controllare una variabile e in quali no è essenziale per fare inferenza causale corretta.\n\n22.5.5 Come si verifica l’indipendenza condizionata?\nCon i dati, possiamo testare questa ipotesi in diversi modi:\n\n\nCorrelazioni parziali: calcoliamo la correlazione tra stress e ansia tenendo costante il sonno.\nSe il modello è corretto, questa correlazione dovrebbe essere vicina a zero.\n\n\nRegressioni multiple: stimiamo una regressione dell’ansia sia sullo stress che sul sonno.\nSe il grafo è corretto, una volta incluso il sonno nel modello, lo stress non dovrebbe più avere un effetto sull’ansia.\n\n\nTest di indipendenza condizionata (nei metodi più avanzati): procedure statistiche apposite che verificano se due variabili sono indipendenti, dati certi controlli.\n\n22.5.6 Perché è importante\nQuesto collegamento tra grafi causali e indipendenze nei dati è il cuore dell’inferenza causale:\n\ni grafi rappresentano le nostre ipotesi teoriche,\nle indipendenze condizionali ci dicono se i dati sono compatibili con quelle ipotesi.\n\nSe un grafo predice un’indipendenza che nei dati non si verifica, dobbiamo concludere che il grafo (cioè la nostra ipotesi causale) è sbagliato o incompleto.\n\n22.5.7 Da ricordare\nQuando diciamo che servono metodi statistici appropriati, intendiamo proprio questi strumenti (correlazioni parziali, regressioni multiple, test di indipendenza) che ci permettono di confrontare le previsioni del grafo con i dati. In questo modo, il linguaggio dei DAG non resta un esercizio astratto, ma diventa un ponte concreto tra teoria psicologica e analisi empirica. In pratica, per gli psicologi, questo significa imparare a usare strumenti come regressioni multiple, correlazioni parziali e modelli di equazioni strutturali: tutti metodi che mettono alla prova le previsioni implicite dei grafi causali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#come-studiare-la-causalità-in-psicologia",
    "href": "chapters/eda/09_causality.html#come-studiare-la-causalità-in-psicologia",
    "title": "22  Causalità dai dati osservazionali",
    "section": "\n22.6 Come studiare la causalità in psicologia",
    "text": "22.6 Come studiare la causalità in psicologia\nAbbiamo visto che i grafi causali aiutano a rappresentare le ipotesi e che i dati possono confermarle o metterle in dubbio. Ma come si fa, concretamente, a studiare la causalità in psicologia?\n\n22.6.1 Esperimenti controllati\nIl metodo più forte per stabilire una relazione causale è l’esperimento. In un esperimento:\n\ni partecipanti vengono assegnati in modo casuale a due o più gruppi (randomizzazione);\n\nsolo alcuni gruppi ricevono la manipolazione sperimentale (per esempio: una tecnica di rilassamento);\nsi confrontano i risultati nei diversi gruppi.\n\nGrazie alla randomizzazione, eventuali differenze iniziali tra i gruppi vengono “bilanciate”. In questo modo, se emergono differenze negli esiti, possiamo attribuirle con buona sicurezza alla manipolazione.\n\n22.6.2 Quasi-esperimenti\nSpesso però, in psicologia, non possiamo randomizzare i partecipanti. Per esempio: non possiamo decidere chi subisce un trauma o chi sviluppa un disturbo. In questi casi si ricorre ai quasi-esperimenti, in cui cerchiamo di avvicinarci il più possibile alla logica sperimentale usando:\n\ngruppi di confronto selezionati con attenzione,\n\nmisure ripetute prima e dopo un evento,\n\ntecniche statistiche per ridurre le differenze iniziali tra gruppi.\n\n22.6.3 Studi osservativi\nInfine, gran parte della ricerca psicologica si basa su studi osservativi, in cui registriamo ciò che accade naturalmente, senza manipolare nulla. Qui il problema del confondimento è particolarmente serio: dobbiamo usare modelli statistici e controlli accurati per cercare di distinguere tra correlazione e causalità.\nIn sintesi, possiamo dire che:\n\ngli esperimenti sono lo strumento più solido per l’inferenza causale,\n\ni quasi-esperimenti sono un compromesso utile quando la randomizzazione non è possibile,\n\ngli studi osservativi richiedono grande cautela e modelli ben costruiti per trarre conclusioni causali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#strategie-statistiche-per-affrontare-il-confondimento",
    "href": "chapters/eda/09_causality.html#strategie-statistiche-per-affrontare-il-confondimento",
    "title": "22  Causalità dai dati osservazionali",
    "section": "\n22.7 Strategie statistiche per affrontare il confondimento",
    "text": "22.7 Strategie statistiche per affrontare il confondimento\nQuando non possiamo condurre esperimenti, dobbiamo cercare di “imitare” le condizioni sperimentali con strumenti statistici. Queste tecniche non eliminano del tutto il problema del confondimento, ma ci aiutano a ridurne l’impatto.\n\n22.7.1 Regressione\nIl metodo più semplice e diffuso è la regressione. Inserendo nella regressione variabili che potrebbero agire come confondenti, possiamo stimare l’effetto di una variabile indipendente “a parità di” altre condizioni.\nEsempio: se vogliamo studiare l’effetto dell’uso dei social media sul benessere psicologico, possiamo includere anche la solitudine come predittore. In questo modo, l’effetto stimato dei social media sarà corretto per le differenze di solitudine tra le persone.\n\n22.7.2 Matching\nUn’altra strategia è il matching: si confrontano persone simili tra loro per tutte le caratteristiche rilevanti, tranne che per la variabile di interesse. Per esempio, possiamo confrontare studenti che usano molto i social con altri che li usano poco, ma che sono simili per età, genere, rendimento scolastico e livello di solitudine.\n\n22.7.3 Variabili strumentali\nQuando una variabile di confondimento non è osservata o non può essere misurata, anche i metodi di regressione non bastano. In questi casi, una possibile strategia è usare una variabile strumentale (IV, instrumental variable).\n\n22.7.3.1 Cos’è una variabile strumentale?\nUna variabile \\(Z\\) è un buon strumento per stimare l’effetto di \\(X\\) su \\(Y\\) se rispetta due condizioni:\n\n\nRilevanza: \\(Z\\) influenza \\(X\\).\n\n\nEsogeneità: \\(Z\\) non influenza \\(Y\\) direttamente, né è correlata con i confondenti di \\(X\\) e \\(Y\\).\n\nIn altre parole, lo strumento agisce come una “fonte di variazione casuale” di \\(X\\), che possiamo sfruttare per stimare il suo effetto su \\(Y\\).\n\n22.7.3.2 Perché serve?\nImmagina di voler stimare l’effetto delle ore di sonno (\\(X\\)) sul rendimento a un test (\\(Y\\)). Il problema è che la motivazione (\\(U\\)) è un confondente: studenti più motivati tendono a dormire meglio e a ottenere voti più alti. Se non possiamo misurare la motivazione, la regressione non ci aiuta.\n\n22.7.3.3 Come interviene lo strumento\nSupponiamo di scoprire che il rumore notturno vicino alla residenza universitaria (\\(Z\\)) influenza quante ore di sonno gli studenti riescono a fare (\\(X\\)), ma non influisce direttamente sul loro rendimento (\\(Y\\)).\n\n\n\\(Z\\) → influenza il sonno (\\(X\\)).\n\n\n\\(Z\\) non ha effetti diretti su rendimento, né è legato alla motivazione (\\(U\\)).\n\nIn questo caso, il rumore agisce come strumento: possiamo usare la variazione di sonno “indotta dal rumore” per stimare l’effetto causale del sonno sul rendimento.\n\n22.7.3.4 Da ricordare\n\nLe variabili strumentali sono molto potenti, ma difficili da trovare: serve una variabile che influenzi solo la causa e non l’effetto.\n\nQuando c’è, però, ci permette di “simulare” un esperimento naturale, isolando una fonte quasi-casuale di variazione nella variabile di interesse.\n\nNella pratica psicologica, strumenti così puliti sono rari: l’idea serve più a capire il principio che a trovare sempre uno strumento perfetto.\nQueste tecniche non sostituiscono l’esperimento, ma rappresentano strumenti preziosi per trarre conclusioni causali quando siamo limitati a dati osservativi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#un-esempio-numerico-di-confondimento",
    "href": "chapters/eda/09_causality.html#un-esempio-numerico-di-confondimento",
    "title": "22  Causalità dai dati osservazionali",
    "section": "\n22.8 Un esempio numerico di confondimento",
    "text": "22.8 Un esempio numerico di confondimento\nImmaginiamo di voler stimare se lo studio pomeridiano (\\(X\\)) migliora il rendimento a un test (\\(Y\\)). Supponiamo però che esista una variabile di confondimento: la motivazione (\\(U\\)).\n\nGli studenti molto motivati tendono sia a studiare più spesso nel pomeriggio (\\(X\\)), sia ad avere voti più alti (\\(Y\\)).\n\nSe non controlliamo per la motivazione, potremmo concludere che il semplice studiare nel pomeriggio causi voti migliori.\n\nEcco dei dati simulati:\n\nset.seed(123)\nn &lt;- 200\nmotivazione &lt;- rbinom(n, 1, 0.5) # 0 = bassa, 1 = alta\nstudio &lt;- rbinom(n, 1, 0.3 + 0.4*motivazione) # più motivati studiano più spesso\nrendimento &lt;- rbinom(n, 1, 0.2 + 0.5*motivazione) # motivazione influenza il voto\n\ntable(studio, rendimento)\n#&gt;       rendimento\n#&gt; studio  0  1\n#&gt;      0 52 43\n#&gt;      1 45 60\n\nSe confrontiamo il rendimento senza considerare la motivazione, otteniamo:\n\nprop.table(table(studio, rendimento), 1)\n#&gt;       rendimento\n#&gt; studio     0     1\n#&gt;      0 0.547 0.453\n#&gt;      1 0.429 0.571\n\nSembra che chi studia nel pomeriggio abbia risultati migliori. Ma in realtà, l’effetto non dipende dallo studio, bensì dalla motivazione, che è il vero fattore causale. Solo controllando per \\(U\\) (ad esempio con una regressione) possiamo separare l’effetto reale da quello spurio.\n\n22.8.1 Cosa impariamo\nQuesto esempio numerico mostra in pratica ciò che i DAG ci aiutano a visualizzare:\n\nquando esiste una variabile di confondimento (come la motivazione), si crea un percorso “indiretto” tra la causa ipotizzata (\\(X\\), lo studio) e l’effetto (\\(Y\\), il rendimento);\n\nquesto percorso indiretto può dare l’illusione di un effetto causale anche quando non c’è.\n\nIn letteratura, questi percorsi indesiderati sono chiamati percorsi back-door: collegamenti che partono “da dietro” la variabile di interesse (\\(X\\)) e portano a \\(Y\\) passando per un’altra variabile.\nPer ottenere una stima corretta dell’effetto causale, dobbiamo bloccare questi percorsi, cioè tenerne conto nell’analisi. Possiamo farlo in diversi modi:\n\nincludendo la variabile di confondimento in una regressione,\n\nselezionando gruppi di confronto simili (matching),\n\noppure, idealmente, usando la randomizzazione sperimentale, che rende i gruppi equivalenti su fattori non osservati.\n\nIn sintesi: senza controllare per la motivazione, i dati ci ingannano; includendo la motivazione, possiamo distinguere tra correlazione spuria e relazione causale reale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#riflessioni-conclusive",
    "href": "chapters/eda/09_causality.html#riflessioni-conclusive",
    "title": "22  Causalità dai dati osservazionali",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nStudiare la causalità non è solo un esercizio teorico. Ogni volta che uno psicologo legge un articolo, progetta un esperimento o valuta un trattamento, deve chiedersi: ‘Questa relazione che osservo è davvero causale o è il frutto di un confondimento?’ Imparare a distinguere questi casi significa fare scienza psicologica più solida e utile.\nIn questo capitolo abbiamo visto che studiare la causalità in psicologia è complesso, ma non impossibile. Abbiamo distinto tra correlazione e causalità, imparato a rappresentare le nostre ipotesi con i grafi causali, e discusso il ruolo di concetti come confondimento, mediazione e moderazione.\nAbbiamo poi esaminato i principali strumenti per testare le ipotesi causali:\n\n\nesperimenti controllati, il metodo più solido,\n\n\nquasi-esperimenti, utili quando non possiamo randomizzare,\n\n\nstudi osservativi, che richiedono l’uso di tecniche statistiche per ridurre i rischi di interpretazioni errate.\n\nLa lezione principale è che i dati, da soli, non “parlano”: hanno bisogno di un modello teorico che guidi l’interpretazione. Un’analisi statistica, per quanto sofisticata, non può dirci nulla di causale se non abbiamo prima formulato ipotesi chiare sul meccanismo che vogliamo studiare.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggdag_0.2.13          pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        ggraph_2.2.2          rmarkdown_2.29       \n#&gt; [19] ragg_1.4.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        tweenr_2.0.3         \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    boot_1.3-32          \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] igraph_2.1.4          timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] viridis_0.6.5         abind_1.4-8           yaml_2.3.10          \n#&gt; [43] codetools_0.2-20      curl_7.0.0            dagitty_0.3-4        \n#&gt; [46] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        polyclip_1.10-7       RcppParallel_5.1.11-1\n#&gt; [55] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [58] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [61] rstantools_2.4.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [64] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [67] graphlayouts_1.2.2    mvtnorm_1.3-3         tidygraph_1.3.1      \n#&gt; [70] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [73] ggforce_0.5.0         cli_3.6.5             textshaping_1.0.1    \n#&gt; [76] svUnit_1.0.8          viridisLite_0.4.2     Brobdingnag_1.2-9    \n#&gt; [79] V8_6.0.6              gtable_0.3.6          digest_0.6.37        \n#&gt; [82] ggrepel_0.9.6         TH.data_1.1-3         htmlwidgets_1.6.4    \n#&gt; [85] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [88] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bibliografia",
    "href": "chapters/eda/09_causality.html#bibliografia",
    "title": "22  Causalità dai dati osservazionali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nByrnes, J. E., & Dee, L. E. (2024). Causal inference with observational data and unobserved confounding variables. bioRxiv, 2024–2002.\n\n\nRiederer, E. (2021). Causal design patterns for data analysts. https://emilyriederer.netlify.app/post/causal-design-patterns/",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_outlier.html",
    "href": "chapters/eda/10_outlier.html",
    "title": "23  Outlier",
    "section": "",
    "text": "Introduzione\nQuando analizziamo dati reali, ci imbattiamo spesso in osservazioni che sembrano molto diverse dalla maggior parte delle altre. Questi valori anomali, chiamati outlier, possono avere origini diverse. Ad esempio, potrebbero derivare da errori di misura o inserimento dati, oppure essere casi estremi ma comunque validi.\nIdentificare e trattare gli outlier in modo appropriato è importante per evitare che distorcano i risultati dell’analisi. Tuttavia, non esiste una definizione universale di outlier: dipende dal contesto e dall’obiettivo dell’analisi. In questo capitolo, esploreremo diversi metodi per individuare gli outlier, concentrandoci su tecniche robuste che minimizzano l’influenza di questi valori anomali sulle statistiche descrittive (Simmons et al., 2011).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_outlier.html#introduzione",
    "href": "chapters/eda/10_outlier.html#introduzione",
    "title": "23  Outlier",
    "section": "",
    "text": "Panoramica del capitolo\n\ncomprendere il ruolo e gli effetti degli outlier;\nindividuare outlier con metodi univariati e multivariati;\nutilizzare il pacchetto {performance} in R per rilevarli;\ndocumentare e rendere riproducibili le procedure;\nconsiderare alternative (es. winsorizzazione) e preregistrare le scelte.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere “Check your outliers! An introduction to identifying statistical outliers in R with easystats” (Thériault et al., 2024).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(performance, see, datawizard, MASS)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_outlier.html#individuare-e-gestire-gli-outlier",
    "href": "chapters/eda/10_outlier.html#individuare-e-gestire-gli-outlier",
    "title": "23  Outlier",
    "section": "\n23.1 Individuare e gestire gli outlier",
    "text": "23.1 Individuare e gestire gli outlier\nIdentificare ed eventualmente eliminare gli outlier rappresenta una fase cruciale dell’analisi dei dati, poiché la presenza di valori anomali può influenzare fortemente le conclusioni che si traggono da analisi statistiche. Gli outlier possono infatti alterare notevolmente statistiche descrittive come media e deviazione standard, ma anche misure di relazione come correlazioni e regressioni. Ciò avviene perché molte tecniche statistiche comuni (ad esempio, la media aritmetica o la regressione lineare con metodo dei minimi quadrati) sono particolarmente sensibili ai valori estremi.\nAd esempio, se stiamo analizzando il reddito medio di un gruppo di persone e includiamo erroneamente dati di reddito estremamente elevati o inseriti per errore, la media risultante sarà molto più alta del reale valore tipico del gruppo, producendo una rappresentazione fuorviante della situazione.\n\n23.1.1 L’importanza della visualizzazione dei dati\nLa rappresentazione grafica dei dati è uno strumento fondamentale per individuare rapidamente la presenza di outlier. Grafici come boxplot, istogrammi e scatterplot consentono di identificare visivamente valori anomali che si discostano dalla distribuzione generale. Tuttavia, queste tecniche sono efficaci principalmente per outlier unidimensionali o bidimensionali. Nel caso di outlier multidimensionali, l’analisi visiva diventa insufficiente e si rende necessario l’utilizzo di metodi statistici più avanzati, come il calcolo della distanza di Mahalanobis.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_outlier.html#come-identificare-gli-outlier",
    "href": "chapters/eda/10_outlier.html#come-identificare-gli-outlier",
    "title": "23  Outlier",
    "section": "\n23.2 Come identificare gli outlier",
    "text": "23.2 Come identificare gli outlier\nOltre alla visualizzazione grafica, esistono tecniche statistiche specifiche che consentono di identificare gli outlier in modo sistematico.\n\n23.2.1 I boxplot\nUno strumento semplice e intuitivo per individuare gli outlier è il boxplot. Il boxplot riassume la distribuzione di una variabile mostrando la mediana, il primo e il terzo quartile (Q1 e Q3) e due estremi, detti “whiskers”. I punti al di fuori di questi whiskers sono considerati potenziali outlier.\nEsempio in R:\n\ndata &lt;- data.frame(\n  value = c(rnorm(100, mean = 10, sd = 2), 30)\n  ) # Aggiungiamo un outlier\n\nggplot(data, aes(y = value)) +\n  geom_boxplot() +\n  coord_flip()\n\n\n\n\n\n\n\nSe il boxplot mostra un punto isolato lontano dagli altri dati, potrebbe essere un outlier.\n\n23.2.2 Metodi basati sulla variabilità\n\n23.2.2.1 Intervallo interquartile (IQR)\nJohn Tukey ha introdotto una definizione operativa di outlier basata sull’Interquartile Range (IQR), ovvero la differenza tra il terzo e il primo quartile:\n\nI valori inferiori a \\(Q1 - 1.5 \\times IQR\\) o superiori a \\(Q3 + 1.5 \\times IQR\\) sono considerati outlier moderati.\nI valori oltre \\(Q1 - 3 \\times IQR\\) o \\(Q3 + 3 \\times IQR\\) sono definiti far out outliers.\n\nEsempio in R:\n\nQ1 &lt;- quantile(data$value, 0.25)\nQ3 &lt;- quantile(data$value, 0.75)\nIQR_value &lt;- Q3 - Q1\nlower_bound &lt;- Q1 - 1.5 * IQR_value\nupper_bound &lt;- Q3 + 1.5 * IQR_value\n\noutliers &lt;- data$value[data$value &lt; lower_bound | data$value &gt; upper_bound]\noutliers\n#&gt; [1] 30\n\nQuesto metodo è efficace per distribuzioni simmetriche, ma potrebbe non funzionare bene con dati asimmetrici.\n\n23.2.2.2 Median Absolute Deviation (MAD)\nUn metodo più robusto rispetto all’IQR è il Median Absolute Deviation (MAD), che utilizza la mediana anziché la media per stimare la dispersione:\n\nmad_value &lt;- mad(data$value)\nthreshold &lt;- 3 * mad_value # Soglia classica per gli outlier\n\noutliers_mad &lt;- data$value[abs(data$value - median(data$value)) &gt; threshold]\noutliers_mad\n#&gt; [1] 30\n\nIl MAD è meno sensibile agli outlier rispetto alla deviazione standard ed è spesso preferito per dati con distribuzioni non normali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_outlier.html#outlier-multivariati",
    "href": "chapters/eda/10_outlier.html#outlier-multivariati",
    "title": "23  Outlier",
    "section": "\n23.3 Outlier multivariati",
    "text": "23.3 Outlier multivariati\nQuando si considerano più variabili contemporaneamente, un valore potrebbe non apparire anomalo su una singola variabile, ma esserlo nel contesto dell’intero dataset. Un metodo comune per individuare questi outlier è la Distanza di Mahalanobis, che tiene conto delle correlazioni tra variabili.\n\nCon la distanza “normale” (come quella che misuri con un righello), se una persona è più alta o più pesante della media, la distanza è calcolata in modo “isolato”, senza considerare che altezza e peso sono spesso correlate (persone più alte tendono a pesare di più).\nCon la distanza di Mahalanobis, invece, si osserva il “contesto” dei dati. Se tutti nel gruppo hanno un’altezza e un peso che crescono in modo coordinato (ad esempio, ogni 10 cm in più corrispondono a 8 kg in più), questa distanza valuta se la nuova persona si allontana da questo schema generale. Ad esempio, una persona molto alta ma con peso medio potrebbe essere considerata più “anomala” di una persona altrettanto alta ma più pesante, perché viola la relazione tipica del gruppo.\n\nPer comprendere intuitivamente la distanza di Mahalanobis, immaginiamo di avere una nube di punti che rappresentano individui, ciascuno con i propri valori di altezza e peso. Il “centro” di questa nube è un punto ideale che rappresenta una sorta di media multivariata (tenendo conto sia dell’altezza sia del peso). La distanza di Mahalanobis misura quanto ogni singolo individuo si allontana da questo centro, considerando la variabilità congiunta delle variabili (ad esempio, la correlazione tra altezza e peso). Se un individuo presenta caratteristiche molto diverse rispetto alla maggioranza, la sua distanza di Mahalanobis sarà elevata, segnalando un potenziale outlier.\n\n\n\n\n\nFigura 23.1: Soglie per la detezione degli outliers (bande grigie) nel caso di una metrica unidimensionale (pannello di sinistra) e nel caso di una rappresentazione multivariata della varianza (pannello di destra) – figura creata da Sergen Cansiz.\n\n\n\n\n\n\n\n\nDistanza di Mahalanobis\n\n\n\n\n\nConsideriamo ora una definizione della distanza di Mahalanobis nel caso bivariato (due variabili). Immaginiamo di avere due variabili come altezza (\\(X\\)) e peso (\\(Y\\)), con:\n\n\nMedie: \\(\\mu_X\\) (altezza media del gruppo), \\(\\mu_Y\\) (peso medio del gruppo).\n\n\nVarianze: \\(\\sigma_X^2\\) (quanto varia l’altezza), \\(\\sigma_Y^2\\) (quanto varia il peso).\n\n\nCorrelazione: \\(\\rho\\) (quanto \\(X\\) e \\(Y\\) sono legate, ad esempio: se l’altezza aumenta, di quanto aumenta solitamente il peso?).\n\nPer un nuovo individuo con altezza \\(x\\) e peso \\(y\\), la distanza di Mahalanobis (\\(D\\)) si calcola così:\n\n\nCalcolare le differenze rispetto alla media:\n\nQuanto si discosta l’altezza: \\((x - \\mu_X)\\).\nQuanto si discosta il peso: \\((y - \\mu_Y)\\).\n\n\n\nScalare le differenze con le varianze:\n\n\nDividere ogni differenza per la sua “variabilità tipica” (deviazione standard \\(\\sigma_X\\) e \\(\\sigma_Y\\)):\n\\[\n\\frac{(x - \\mu_X)}{\\sigma_X} \\quad \\text{e} \\quad \\frac{(y - \\mu_Y)}{\\sigma_Y} .\n\\]\n\n\n\n\nCorreggere per la correlazione:\n\nSe \\(X\\) e \\(Y\\) sono correlate (\\(\\rho \\neq 0\\)), modifica le differenze per tenere conto di come di solito si “muovono insieme”.\n\nLa formula finale combina tutto in un unico valore:\\[\nD = \\sqrt{ \\frac{ \\left( \\frac{(x - \\mu_X)}{\\sigma_X} \\right)^2 + \\left( \\frac{(y - \\mu_Y)}{\\sigma_Y} \\right)^2 - 2 \\rho \\left( \\frac{(x - \\mu_X)}{\\sigma_X} \\right)\\left( \\frac{(y - \\mu_Y)}{\\sigma_Y} \\right) }{1 - \\rho^2} }\n\\]\n\n\n\n\nSpiegazione:\n\nSenza correlazione (\\(\\rho = 0\\)), sarebbe come una distanza Euclidea “scalata” dalle varianze.\n\nCon correlazione (\\(\\rho \\neq 0\\)), sottrai un termine che “aggiusta” la distanza in base a quanto \\(X\\) e \\(Y\\) tendono a variare insieme.\n\nIl denominatore \\(1 - \\rho^2\\) normalizza il risultato, per evitare che la correlazione distorca troppo la misura.\n\nEsempio:\nSe tutti gli alti sono anche pesanti (\\(\\rho\\) positivo), un individuo alto ma magro avrà una distanza di Mahalanobis maggiore rispetto a uno altrettanto alto ma pesante, perché viola la relazione tipica del gruppo.\n\n\n\n\n\n\n\n\n\nDistanza Eucliea\n\n\n\n\n\nRicordiamo che la distanza euclidea tra due punti \\((x_1, y_1)\\) e \\((x_2, y_2)\\) in un piano cartesiano è definita come:\n\\[\nd = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\n\\]\n\n\n\nEsempio in R:\n\nX &lt;- as.matrix(mtcars[, c(\"mpg\", \"hp\")])\ncenter &lt;- colMeans(X)\ncov_matrix &lt;- cov(X)\nmahal_dist &lt;- mahalanobis(X, center, cov_matrix)\n\nthreshold &lt;- qchisq(0.975, df = ncol(X)) # Soglia al 97.5%\noutliers_mahal &lt;- X[mahal_dist &gt; threshold, ]\noutliers_mahal\n#&gt; mpg  hp \n#&gt;  15 335\n\nQuesto metodo è utile per dataset con più variabili correlate, come misure biometriche (altezza e peso).\nTuttavia, la versione classica di questa misura non è particolarmente robusta: la presenza stessa di outlier può distorcere il calcolo del “centro” e della variabilità complessiva, rendendo meno affidabile l’individuazione di altri valori anomali. Per questo motivo, si preferisce utilizzare una variante più resistente, la Minimum Covariance Determinant (MCD), che diminuisce l’influenza degli outlier stessi nel processo di identificazione.\nAll’interno del pacchetto {performance} in R, è possibile applicare questa variante robusta utilizzando la funzione check_outliers() con l’argomento method = \"mcd\". In questo modo, è possibile individuare gli outlier multivariati in maniera più solida e coerente, anche quando si lavora con dati fortemente influenzati da valori estremi.\n\nd &lt;- mtcars[, c(\"mpg\", \"hp\")]\noutliers &lt;- performance::check_outliers(d, method = \"mcd\", verbose = FALSE)\noutliers\n#&gt; 2 outliers detected: cases 20, 31.\n#&gt; - Based on the following method and threshold: mcd (13.816).\n#&gt; - For variables: mpg, hp.\n\nSi possono poi visualizzare questi outlier:\n\nplot(outliers)\n\n\n\n\n\n\n\nSono disponibili anche altre varianti multivariate documentate nella help page della funzione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_outlier.html#cosa-fare-con-gli-outlier",
    "href": "chapters/eda/10_outlier.html#cosa-fare-con-gli-outlier",
    "title": "23  Outlier",
    "section": "\n23.4 Cosa fare con gli outlier?",
    "text": "23.4 Cosa fare con gli outlier?\nUna volta identificati gli outlier, dobbiamo decidere se rimuoverli, correggerli o mantenerli (Leys et al., 2019). Alcuni approcci comuni includono:\n\n\nVerificare la fonte del dato: un errore di inserimento può essere corretto.\n\nRimuovere gli outlier estremi: utile se il valore è chiaramente un errore di misura.\n\nUsare metodi robusti: strumenti come la mediana o il MAD sono meno influenzati dagli outlier.\n\nTrasformare i dati: applicare logaritmi o altre trasformazioni può ridurre l’impatto degli outlier.\n\nWinsorizzazione: invece di rimuovere gli outlier, possiamo limitarli a un massimo accettabile.\n\n\n\n\n\n\n\nWinsorizzazione\n\n\n\n\n\nNella Winsorizzazione, invece di eliminare gli outlier, si sostituiscono i valori troppo alti o troppo bassi con i valori più vicini considerati “accettabili”, mantenendo però la struttura generale dei dati.\nCome funziona?\n1. Definisci i limiti:\n\nDecidi una “soglia” per identificare gli outlier, ad esempio il 5° percentile (valore sotto cui cade il 5% dei dati più bassi) e il 95° percentile (valore sopra cui cade il 5% dei dati più alti).\n\nQueste soglie dipendono dal contesto: puoi usare percentili diversi (es. 1° e 99°) in base a quanto vuoi essere severo nel definire gli outlier.\n\n\n\nSostituisci gli outlier:\n\n\nValori troppo bassi: Tutti i dati sotto il 5° percentile vengono sostituiti con il valore del 5° percentile.\n\n\nValori troppo alti: Tutti i dati sopra il 95° percentile vengono sostituiti con il valore del 95° percentile.\n\n\n\nEsempio concreto:\nSupponiamo di avere i seguenti dati su 10 esami (ordinati):40, 55, 60, 65, 70, 75, 80, 85, 90, 200\n\n\n5° percentile: 55 (il valore sotto cui cade il 5% dei dati).\n\n\n95° percentile: 90 (il valore sopra cui cade il 5% dei dati).\n\nDopo la Winsorizzazione:\n- Il valore più basso (40) diventa 55.\n- Il valore più alto (200) diventa 90.\nNuovi dati: 55, 55, 60, 65, 70, 75, 80, 85, 90, 90.\nPerché usarla?\n\n\nMantiene la dimensione del dataset: Non si eliminano dati, ma si modificano solo gli outlier.\n\nRiduce la distorsione: Gli outlier estremi non “trascinano” la media o altre statistiche.\n\n\nUtile in contesti sensibili: Ad esempio, in finanza (per gestire rendimenti anomali) o nelle analisi mediche (per evitare che valori estremi falsino i risultati).\n\n\n\n\nNel pacchetto easystats, la funzione winsorize() di datawizard semplifica il compito di Winsorizzazione:\nwinsorized_data &lt;- \n  winsorize(data$value, method = \"zscore\", robust = TRUE, threshold = 3)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_outlier.html#importanza-della-trasparenza",
    "href": "chapters/eda/10_outlier.html#importanza-della-trasparenza",
    "title": "23  Outlier",
    "section": "\n23.5 Importanza della trasparenza",
    "text": "23.5 Importanza della trasparenza\nQualunque decisione va documentata chiaramente: quanti outlier sono stati individuati, con quale metodo, a quale threshold, come sono stati gestiti, e preferibilmente con il codice R utilizzato. La preregistrazione e la condivisione dei dati e del codice (ad es. su OSF) sono pratiche consigliate per garantire riproducibilità e trasparenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_outlier.html#riflessioni-conclusive",
    "href": "chapters/eda/10_outlier.html#riflessioni-conclusive",
    "title": "23  Outlier",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nAbbiamo mostrato come identificare gli outlier in modo coerente e trasparente, allineandoci alle buone pratiche correnti. Tuttavia, la buona pratica non si limita alla scelta degli algoritmi: è fondamentale anche preregistrare le decisioni, essere coerenti, trasparenti e fornire giustificazioni.\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nDomande teoriche\n\nCos’è un outlier?\nPerché è importante identificare e trattare correttamente gli outlier?\nDescrivi brevemente il metodo del boxplot per identificare gli outlier.\nCosa si intende per Interquartile Range (IQR) e come viene utilizzato per individuare gli outlier?\nQual è la differenza tra il metodo IQR e il Median Absolute Deviation (MAD) per l’identificazione degli outlier?\nCos’è la distanza di Mahalanobis e in che modo può aiutare nell’identificazione degli outlier multivariati?\nPerché la distanza di Mahalanobis classica potrebbe non essere robusta? Come si può migliorare l’approccio?\nQuali sono le opzioni per gestire gli outlier una volta identificati?\nCos’è la Winsorizzazione e in quali casi potrebbe essere utile?\nPerché è importante la trasparenza nelle decisioni riguardanti gli outlier?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\n\nCos’è un outlier?\n\nUn outlier è un’osservazione che si discosta significativamente dalla maggior parte delle altre osservazioni in un insieme di dati. Può essere dovuto ad errori di misura, errori di inserimento dati o a casi estremi ma validi.\n\n\n\nPerché è importante identificare e trattare correttamente gli outlier?\n\nGli outlier possono distorcere i risultati dell’analisi statistica, portando a conclusioni errate. Identificarli e trattarli correttamente aiuta a ridurre l’effetto di questi valori anomali sulle statistiche descrittive e sulle inferenze statistiche.\n\n\n\nDescrivi brevemente il metodo del boxplot per identificare gli outlier.\n\nIl boxplot visualizza la distribuzione di una variabile, mostrando la mediana, il primo e il terzo quartile, e due estremi (“whiskers”). I punti al di fuori di questi whiskers sono considerati potenziali outlier.\n\n\n\nCosa si intende per Interquartile Range (IQR) e come viene utilizzato per individuare gli outlier?\n\nL’IQR è la differenza tra il terzo e il primo quartile di un insieme di dati. Valori inferiori a \\(Q1 - 1.5 \\times IQR\\) o superiori a \\(Q3 + 1.5 \\times IQR\\) sono considerati outlier moderati. Valori oltre \\(Q1 - 3 \\times IQR\\) o \\(Q3 + 3 \\times IQR\\) sono definiti “far out” outliers.\n\n\n\nQual è la differenza tra il metodo IQR e il Median Absolute Deviation (MAD) per l’identificazione degli outlier?\n\nIl metodo IQR si basa sulla differenza tra il terzo e il primo quartile, mentre il MAD utilizza la mediana delle deviazioni assolute dalla mediana per stimare la dispersione. Il MAD è meno sensibile agli outlier rispetto all’IQR e alla deviazione standard, rendendolo preferibile per dati con distribuzioni non normali.\n\n\n\nCos’è la distanza di Mahalanobis e in che modo può aiutare nell’identificazione degli outlier multivariati?\n\nLa distanza di Mahalanobis misura quanto un punto si discosta dal centro della distribuzione di un set di dati multivariato, tenendo conto della correlazione tra le variabili. Valori con distanze di Mahalanobis elevate sono potenziali outlier multivariati.\n\n\n\nPerché la distanza di Mahalanobis classica potrebbe non essere robusta? Come si può migliorare l’approccio?\n\nLa distanza di Mahalanobis classica può essere distorta dalla presenza di outlier, che influenzano il calcolo del centro e della variabilità complessiva. Un approccio più robusto è la Minimum Covariance Determinant (MCD), che riduce l’influenza degli outlier nel processo di identificazione.\n\n\n\nQuali sono le opzioni per gestire gli outlier una volta identificati?\n\nLe opzioni includono: verificare la fonte del dato per possibili errori, rimuovere gli outlier estremi, usare metodi robusti come la mediana o il MAD, trasformare i dati (ad esempio, logaritmi), e limitare gli outlier attraverso la Winsorizzazione.\n\n\n\nCos’è la Winsorizzazione e in quali casi potrebbe essere utile?\n\nLa Winsorizzazione è una tecnica che consiste nel sostituire gli outlier estremi con il valore massimo o minimo accettabile. È utile quando si vuole mantenere la dimensione del dataset e ridurre l’impatto degli outlier senza rimuoverli completamente.\n\n\nPerché è importante la trasparenza nelle decisioni riguardanti gli outlier?\n\n\nLa trasparenza aiuta a garantire la riproducibilità e la validità dell’analisi. Documentare le decisioni, inclusi i metodi e i threshold utilizzati, consente ad altri di capire e valutare l’impatto di queste decisioni sui risultati dell’analisi.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio: Gestione degli Outlier nella Scala di Soddisfazione di Vita (SWLS)\nScopo:\nImparare a individuare e correggere gli outlier in un dataset che misura la soddisfazione di vita (SWLS). L’esercizio prevede l’inserimento artificiale di due outlier (uno molto alto e uno molto basso) nei dati raccolti, per poi gestirli con i metodi discussi nel capitolo. Infine, bisognerà consegnare:\n\nUn file .qmd (Quarto) con tutto il codice e i commenti delle operazioni svolte.\n\nUn file CSV finale con i dati “puliti” (ossia senza i due outlier anomali) o con i valori modificati mediante il metodo scelto (winsorizzazione, rimozione, correzione, ecc.).\n\nFasi e Istruzioni\n\n\nScarica o carica il dataset SWLS\n\nNominare il dataset originale, ad esempio SWLS_raw.csv, contenente i punteggi dei partecipanti sulla Scala di Soddisfazione di Vita (SWLS).\n\nAssicurati di avere nel dataset almeno le colonne:\n\n\nid (identificatore univoco del partecipante)\n\n\nswls_score (punteggio totale alla scala SWLS)\n\n\n\n\n\nCrea due outlier artificiali\n\nScegli un partecipante al quale assegnare un valore estremamente basso di swls_score (es. -999) e un altro partecipante con un valore estremamente alto (es. 999).\n\nSpiega brevemente nel .qmd dove e come hai inserito questi valori.\n\n\n\nAnalizza i dati alla ricerca di outlier\n\nVisualizza la distribuzione tramite un boxplot e/o un istogramma.\n\nCalcola i valori soglia utilizzando almeno uno dei metodi visti:\n\nIQR (intervallo interquartile)\n\nMAD (Median Absolute Deviation)\n\n\n\nMostra quali osservazioni vengono segnalate come potenziali outlier.\n\n\n\nDecidi come gestire gli outlier\n\nScegli se rimuoverli, winsorizzarli o correggerli.\n\nGiustifica la tua scelta: spiega perché quel metodo è appropriato per questi dati o perché preferisci un approccio rispetto a un altro.\n\n\n\nGenera i dati “puliti”\n\nApplica il metodo selezionato.\n\nSalva il dataset risultante (senza i valori anomali o con i valori modificati) in un file CSV chiamato SWLS_clean.csv.\n\n\n\nDocumenta tutto in un file .qmd\n\nIncludi codice R, commenti e brevi spiegazioni testuali dei vari passaggi.\n\nMostra i risultati rilevanti (boxplot, calcolo dei soglie IQR/MAD, elenco degli outlier individuati, ecc.).\n\nAssicurati di eseguire il rendering del .qmd in modo che l’istruttore possa vedere sia l’output che il codice.\n\n\n\nConsegnare i file\n\n\nFile .qmd: deve contenere tutto il codice e i passaggi effettuati (inclusi grafici, calcoli e spiegazioni).\n\n\nFile CSV “pulito” (SWLS_clean.csv): con i dati finali dopo il trattamento degli outlier.\n\n\n\nSuggerimenti\n\n\nStruttura il tuo .qmd in sezioni (ad es. Caricamento dati, Creazione outlier artificiali, Identificazione outlier, Gestione outlier, Salvataggio dati puliti).\n\n\nMotiva sempre le scelte, soprattutto se rimuovi o modifichi i dati originali: spiega perché il valore appare come un errore di misura o un valore estremo.\n\n\nFai controlli incrociati: potresti usare più di un metodo (boxplot, IQR, MAD) per vedere se l’outlier viene segnalato in tutti i casi.\n\n\nDocumenta la tua strategia di trasparenza nell’analisi: note sull’eventuale preregistrazione di come avresti gestito gli outlier o su come hai deciso i threshold.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-65           datawizard_1.2.0      see_0.11.0           \n#&gt;  [4] performance_0.15.1    pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [7] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt; [10] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [13] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [16] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [19] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [22] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [25] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [28] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        rmarkdown_2.29        ragg_1.5.0           \n#&gt; [19] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [22] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [25] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [28] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [31] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [34] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [37] abind_1.4-8           codetools_0.2-20      curl_7.0.0           \n#&gt; [40] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [43] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [46] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [49] checkmate_2.3.3       stats4_4.5.1          insight_1.4.2        \n#&gt; [52] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [55] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [58] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [61] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [64] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [67] textshaping_1.0.3     svUnit_1.0.8          viridisLite_0.4.2    \n#&gt; [70] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [73] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [76] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [79] lifecycle_1.0.4",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_outlier.html#bibliografia",
    "href": "chapters/eda/10_outlier.html#bibliografia",
    "title": "23  Outlier",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLeys, C., Delacre, M., Mora, Y. L., Lakens, D., & Ley, C. (2019). How to classify, detect, and manage univariate and multivariate outliers, with emphasis on pre-registration. International Review of Social Psychology, 32(1).\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nThériault, R., Ben-Shachar, M. S., Patil, I., Lüdecke, D., Wiernik, B. M., & Makowski, D. (2024). Check your outliers! An introduction to identifying statistical outliers in R with easystats. Behavior Research Methods, 56(4), 4162–4172.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/probability/introduction_probability.html",
    "href": "chapters/probability/introduction_probability.html",
    "title": "Probabilità",
    "section": "",
    "text": "Questa sezione della dispensa introduce la teoria della probabilità, una componente essenziale per la ricerca scientifica. Nell’ambito della scienza, l’inferenza induttiva è di fondamentale importanza, e la probabilità svolge un ruolo cruciale in questo processo. Poiché la scienza non può garantire verità assolute, ma solo approssimazioni corroborate da evidenze, la probabilità diventa lo strumento chiave per quantificare il grado di incertezza associato a un’ipotesi, a una previsione o a un modello. Due scuole di pensiero dominano questo scenario: l’approccio bayesiano, che interpreta la probabilità come misura soggettiva del grado di fiducia in una proposizione, e l’approccio frequentista, che la definisce come frequenza relativa di un evento osservabile in condizioni ripetute. Sebbene queste prospettive differiscano radicalmente nell’interpretazione filosofica, entrambe poggiano sullo stesso formalismo matematico. Padroneggiare i concetti fondamentali della probabilità è dunque essenziale per comprendere sia gli strumenti dell’inferenza bayesiana, sia quelli classici dell’analisi statistica.\nQuesta sezione fornisce le basi teoriche necessarie per navigare entrambi i paradigmi. Partiremo dalle definizioni di probabilità e dalle sue regole fondamentali, per poi introdurre concetti come la probabilità condizionale e il teorema di Bayes, che stanno alla base dell’aggiornamento delle credenze alla luce di nuovi dati. Esploreremo inoltre le proprietà delle variabili casuali, distinguendo tra distribuzioni discrete (a massa di probabilità) e continue (a densità di probabilità). Infine, discuteremo la funzione di verosimiglianza, comune alle due scuole: mentre i bayesiani la integrano con informazioni a priori per costruire distribuzioni posteriori, i frequentisti ne sfruttano il principio della massima verosimiglianza per stimare parametri in modo puramente empirico, senza assumere conoscenze preliminari.",
    "crumbs": [
      "Probabilità"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html",
    "href": "chapters/probability/01_intro_prob.html",
    "title": "24  Interpretazione della probabilità",
    "section": "",
    "text": "Introduzione\nIn questo capitolo esamineremo come la teoria della probabilità si sia affermata come uno strumento per descrivere e interpretare l’incertezza, muovendoci tra diverse concezioni (classica, frequentista e bayesiana) e riconoscendo il ruolo fondamentale della simulazione nel chiarire concetti probabilistici, come la legge dei grandi numeri. Prima, però, è utile soffermarsi sull’idea di casualità e sul nesso che la lega all’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#introduzione",
    "href": "chapters/probability/01_intro_prob.html#introduzione",
    "title": "24  Interpretazione della probabilità",
    "section": "",
    "text": "Panoramica del capitolo\n\nLe diverse interpretazioni della probabilità.\nIncertezza epistemica e ontologica.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Why probability probably doesn’t exist (but it is useful to act like it does (Spiegelhalter, 2024).\nLeggere l’Appendice G.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#casualità-e-incertezza",
    "href": "chapters/probability/01_intro_prob.html#casualità-e-incertezza",
    "title": "24  Interpretazione della probabilità",
    "section": "\n24.1 Casualità e incertezza",
    "text": "24.1 Casualità e incertezza\nDavid Spiegelhalter, in un recente articolo pubblicato su Nature, sottolinea come la vita sia pervasa dall’incertezza: non sappiamo con certezza cosa è accaduto in passato, cosa avverrà in futuro né abbiamo una completa comprensione di ciò che ci circonda (Spiegelhalter, 2024). Questa condizione di ignoranza spinge a interpretare la casualità come un modello che, pur non fornendo previsioni deterministiche, rivela spesso regolarità statistiche. In altre parole, i singoli eventi possono apparire imprevedibili, ma l’osservazione di molti casi analoghi svela andamenti medi stabili e quantificabili.\nDa questa prospettiva nasce la teoria della probabilità, intesa come linguaggio matematico rigoroso per quantificare e modellare l’incertezza. Attraverso concetti quali valore atteso, distribuzioni di probabilità e frequenze relative, la probabilità permette di passare dalla nozione intuitiva di caso all’analisi formale dei fenomeni incerti. Anche nell’ambito psicologico, la probabilità supporta la ricerca, l’interpretazione di dati sperimentali e la presa di decisioni cliniche, fornendo una base teorica su cui costruire ipotesi e valutare rischi e benefici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#il-ruolo-della-probabilità-nello-studio-dei-fenomeni",
    "href": "chapters/probability/01_intro_prob.html#il-ruolo-della-probabilità-nello-studio-dei-fenomeni",
    "title": "24  Interpretazione della probabilità",
    "section": "\n24.2 Il ruolo della probabilità nello studio dei fenomeni",
    "text": "24.2 Il ruolo della probabilità nello studio dei fenomeni\nLa teoria della probabilità consente di trasformare le intuizioni sulla casualità in un linguaggio rigoroso. Tra le sue funzioni fondamentali si evidenziano:\n\nQuantificare l’incertezza\nAssegnare valori numerici agli esiti possibili rende esplicita la probabilità di ogni evento. Per esempio, nel lancio di un dado, dire che ogni faccia ha 1/6 di probabilità di uscire equivale a tradurre la casualità in un concetto misurabile.\nCombinare informazioni\nLe regole di somma e prodotto permettono di integrare probabilità relative a eventi diversi: la somma si utilizza per eventi mutualmente esclusivi (es. prendere o non prendere un voto specifico a un esame), mentre il prodotto si applica a eventi ritenuti indipendenti (es. risultati di più estrazioni da un’urna).\nAggiornare le credenze\nSecondo la prospettiva bayesiana, le probabilità non sono statiche, ma si modificano con il sopraggiungere di nuove evidenze. Un tipico esempio è la revisione di previsioni meteorologiche alla luce di dati più recenti, come la pressione atmosferica o l’umidità.\nOttimizzare le decisioni\nLa probabilità guida valutazioni di rischi e benefici, aiutando a scegliere in modo razionale quando l’esito di un’azione non è garantito. Questa idea si applica tanto in campo clinico, per decidere il protocollo di un trattamento sperimentale, quanto in ambito psicologico, per valutare il processo terapeutico per un disturbo alimentare.\n\nQueste funzioni costituiscono l’ossatura della teoria della probabilità e la rendono uno strumento essenziale per affrontare contesti in cui l’informazione è parziale o i fenomeni hanno una componente di casualità irriducibile.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#due-tipi-di-incertezza-epistemica-e-ontologica",
    "href": "chapters/probability/01_intro_prob.html#due-tipi-di-incertezza-epistemica-e-ontologica",
    "title": "24  Interpretazione della probabilità",
    "section": "\n24.3 Due tipi di incertezza: epistemica e ontologica",
    "text": "24.3 Due tipi di incertezza: epistemica e ontologica\nL’analisi probabilistica si confronta con due tipologie di incertezza:\n\nEpistemica\nDipende dai limiti della conoscenza o dai dati a disposizione. Se in un esperimento non si controllano adeguatamente variabili importanti, la nostra misura di probabilità risente di queste lacune. L’incertezza epistemica può ridursi affinando il disegno sperimentale o ampliando il numero di osservazioni.\nOntologica\nInerente al fenomeno stesso, è indipendente dal grado di controllo o di osservazione possibile. Il lancio di un dado rimane imprevedibile anche se conoscessimo le leggi fisiche in gioco e le condizioni iniziali con incredibile precisione. Questo tipo di casualità è connaturato al sistema, e dunque impossibile da eliminare del tutto.\n\nUn celebre riferimento in questo contesto è Niels Bohr, secondo il quale la scienza non fornisce verità assolute, ma costruisce modelli che descrivono la realtà entro i limiti concettuali di cui disponiamo. In questa prospettiva, l’incertezza ontologica segna il confine tra ciò che è conoscibile e la complessità insita nella natura dei fenomeni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#cenni-storici",
    "href": "chapters/probability/01_intro_prob.html#cenni-storici",
    "title": "24  Interpretazione della probabilità",
    "section": "\n24.4 Cenni storici",
    "text": "24.4 Cenni storici\nLa teoria della probabilità affonda le sue radici nei giochi d’azzardo, pratiche antiche che stimolarono riflessioni sui meccanismi del caso. Fu però nel XVII secolo che iniziò a prendere forma una sistematizzazione scientifica, grazie al dialogo tra Blaise Pascal e Pierre de Fermat. I due matematici risposero alle questioni poste dal Chevalier de Méré, un aristocratico appassionato di scommesse. Tra i dilemmi più noti vi era il cosiddetto “problema della ripartizione equa”: come distribuire il premio di un torneo di dadi interrotto prematuramente, basandosi sulle chance residuali di vittoria dei giocatori?\n\nDue giocatori, A e B, stanno partecipando a un gioco in cui il primo a vincere sei round consecutivi ottiene il premio. Dopo sei round, A ha vinto cinque round e B uno. Poiché il gioco viene interrotto, come si dovrebbe dividere il premio in modo equo?\n\nQuesto problema spinse Pascal e Fermat a sviluppare i primi strumenti matematici per calcolare la probabilità degli eventi futuri, dando vita a un metodo rigoroso per affrontare l’incertezza. Stimando, ad esempio, che A avesse il 97% di probabilità di vincere e B il 3%, sembrava equo dividere il premio nella stessa proporzione. La soluzione, che prevedeva il calcolo degli esiti attesi e delle relative probabilità, segnò una svolta epocale, gettando le basi per la formalizzazione matematica della disciplina.\nChristian Huygens, con il trattato De Ratiociniis in Ludo Aleae (1657), approfondì le applicazioni nel gioco d’azzardo, mentre figure come Leibniz e John Graunt esplorarono rispettivamente la probabilità come strumento logico-giuridico e come frequenza statistica.\nJacob Bernoulli, nell’Ars Conjectandi (1713), formulò la legge dei grandi numeri, evidenziando come ripetute osservazioni empiriche rivelino regolarità nascoste, nonostante l’apparente imprevedibilità dei singoli eventi. Questo lavoro pose le basi per due visioni contrapposte: la probabilità come misura dell’incertezza epistemica (grado di fiducia razionale) e come proprietà oggettiva legata alla frequenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#la-dualità-epistemologica-e-frequenziale",
    "href": "chapters/probability/01_intro_prob.html#la-dualità-epistemologica-e-frequenziale",
    "title": "24  Interpretazione della probabilità",
    "section": "\n24.5 La dualità epistemologica e frequenziale",
    "text": "24.5 La dualità epistemologica e frequenziale\nHacking (2006) ha sottolineato che, a partire dal contributo di Bernoulli, la probabilità si sviluppò storicamente lungo due assi: da un lato come misura della credibilità di un’ipotesi (prospettiva epistemologica), dall’altro come descrizione della frequenza con cui un evento compare in circostanze ripetute (prospettiva frequenziale). Questa tensione è tuttora visibile nella dicotomia fra metodi bayesiani e metodi frequentisti.\n\n24.5.1 Frequentismo\nIl frequentismo intende la probabilità come frequenza relativa dell’evento in un numero potenzialmente infinito di prove. I fondatori di questo approccio, tra cui Ronald A. Fisher e poi Jerzy Neyman ed Egon Pearson, hanno posto le basi dell’inferenza statistica classica (test di ipotesi, intervalli di confidenza, analisi di varianza).\nIl modello paradigmatico di questo approccio è il cosiddetto modello dell’urna. Si immagina di estrarre in modo casuale una pallina da un’urna contenente palline visivamente indistinguibili, ma numerate: ogni pallina ha la stessa probabilità di essere scelta, riproducendo così l’idea di eventi equiprobabili. Questa concezione si basa su una rappresentazione astratta e ideale della casualità che, nella realtà, trova riscontro in ambiti quali il campionamento statistico e gli studi clinici randomizzati (in cui ogni paziente ha la stessa probabilità di essere assegnato al gruppo sperimentale o di controllo). Il limite di questa visione emerge nei casi in cui non è possibile accumulare un gran numero di osservazioni o quando l’evento è unico e irripetibile.\n\n24.5.2 Bayesianesimo\nIl bayesianesimo si basa sull’idea di un continuo aggiornamento delle nostre credenze. Con il teorema di Bayes si parte da una conoscenza iniziale (detta prior) e la si aggiorna con i dati osservati (likelihood) per giungere a una stima a posteriori.\n\n24.5.2.1 Probabilità come costruzione soggettiva\nL’approccio bayesiano è basato su un’interpretazione soggettiva della probabilità, secondo cui tale concetto rappresenta il grado di fiducia (o credenza) che un individuo o un gruppo attribuisce al verificarsi di un evento, sulla base delle informazioni disponibili. Un esempio pratico è la previsione di pioggia al 70%: non si tratta di un fenomeno fisico oggettivo – come avverrebbe in un’ottica frequenzialista – bensì del risultato di dati storici, modelli climatici e continue rivalutazioni.\nBruno de Finetti ha spinto all’estremo questa prospettiva soggettivista, riassumendo il suo pensiero con la celebre affermazione: “La probabilità non esiste”. In altre parole, la probabilità non sarebbe una proprietà fisica intrinseca degli eventi, ma un indicatore di quanto “si è pronti a scommettere” sulla base delle informazioni e delle convinzioni possedute. Sebbene tali convinzioni debbano rispettare gli assiomi della probabilità per risultare logicamente coerenti, la definizione puntuale di quanto un evento sia “certo” o “probabile” dipende dalla prospettiva e dalle informazioni dell’osservatore.\nFrank Ramsey, nel 1926, fu uno dei primi a formalizzare questa idea, definendo la probabilità come grado di credenza individuale coerente con gli assiomi matematici (Ramsey, 1926). Pochi anni dopo, nel 1939, Jeffreys (1998) illustrò in “Theory of Probability” una tra le prime esposizioni moderne dei metodi bayesiani. Successivamente, Fishburn (1986) fornì una rigorosa formalizzazione matematica degli assiomi della probabilità soggettiva, mentre Press (2009) contribuì ad ampliare l’ambito di applicazione di questa prospettiva, dimostrando la sua importanza come strumento per affrontare l’incertezza in ambito scientifico. Per una panoramica storica sullo sviluppo del pensiero bayesiano, si vedano anche Bayesian Methods: General Background e Philosophy of Statistics.\nIn questo quadro, l’attenzione si sposta dalla realtà oggettiva alla costruzione umana della probabilità, ponendo in evidenza il ruolo dei giudizi, delle ipotesi e delle informazioni disponibili. La probabilità non è dunque una proprietà del mondo, ma una misura del grado di fiducia razionale che un soggetto idealizzato assegna all’affermazione di un evento, basandosi sulle conoscenze (spesso incomplete) di cui dispone. Questo soggetto ideale è concepito come privo di emozioni, pregiudizi o bias cognitivi, così da agire esclusivamente sulla base della logica e delle evidenze. Tale impostazione si applica in modo particolarmente efficace in contesti dove i dati sono limitati o l’incertezza è elevata, come spesso accade negli studi psicologici, in cui il comportamento umano mal si presta a una descrizione puramente frequenzialista.\n\n\n\n\n\n\nTerminologia\n\n\n\nIl termine probabilità soggettiva viene spesso frainteso come mancanza di rigore. Per questo motivo sono state proposte alternative:\n\n\nLindley (2013) adotta il termine probabilità personale, per sottolineare l’aspetto individuale (ma razionale) di tale definizione.\n\n\nHowson & Urbach (2006) preferisce probabilità epistemica, enfatizzando il legame con la conoscenza e l’incertezza dovuta a informazioni limitate.\n\nAutori come Kaplan (2023) utilizzano tali alternative terminologiche per evidenziare in modo più neutrale il ruolo fondamentale della probabilità come strumento scientifico.\n\n\nUn aspetto importante che ha contribuito a promuovere la diffusione contemporanea dell’approccio bayesiano è stata la scoperta, sul finire degli anni ’80, dei metodi Monte Carlo Markov chain (MCMC). Queste tecniche hanno reso computazionalmente accessibili modelli e calcoli altrimenti irrealizzabili, favorendo la rinascita e l’ulteriore evoluzione dei metodi bayesiani.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#i-due-paradigmi-della-probabilità-in-psicologia",
    "href": "chapters/probability/01_intro_prob.html#i-due-paradigmi-della-probabilità-in-psicologia",
    "title": "24  Interpretazione della probabilità",
    "section": "\n24.6 I due paradigmi della probabilità in psicologia",
    "text": "24.6 I due paradigmi della probabilità in psicologia\nIn psicologia, entrambi i paradigmi hanno risvolti importanti. L’approccio frequentista è ancora dominante nell’analisi dei dati (si pensi al largo uso dei test di significatività), ma il bayesianesimo sta guadagnando terreno, poiché permette di integrare informazioni pregresse in modo trasparente e di esprimere in modo diretto la probabilità di un’ipotesi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#dalla-teoria-alla-pratica-simulazioni-con-r",
    "href": "chapters/probability/01_intro_prob.html#dalla-teoria-alla-pratica-simulazioni-con-r",
    "title": "24  Interpretazione della probabilità",
    "section": "\n24.7 Dalla teoria alla Pratica: simulazioni con R",
    "text": "24.7 Dalla teoria alla Pratica: simulazioni con R\nNello studio della probabilità e della statistica, l’analisi analitica può risultare complessa in contesti con modelli intricati o distribuzioni non standard. In questi casi, la simulazione al computer emerge come strumento didattico e metodologico essenziale. Utilizzando linguaggi di programmazione come R, è possibile replicare virtualmente un esperimento migliaia di volte, osservando empiricamente la distribuzione degli esiti e stimando probabilità attraverso il metodo Monte Carlo. Questo approccio non solo facilita la comprensione di concetti astratti, ma consente anche di validare risultati teorici in scenari reali.\n\n24.7.1 Legge dei Grandi Numeri\nUn principio fondamentale esplorabile attraverso simulazioni è la legge dei grandi numeri (LLN), pilastro dell’approccio frequentista. La LLN stabilisce che la frequenza relativa di un evento converge alla sua probabilità teorica all’aumentare del numero di prove, pur preservando l’imprevedibilità dei singoli esiti. Ad esempio, in una sequenza di lanci di una moneta equa, la proporzione di “teste” oscillerà inizialmente in modo marcato, ma tenderà progressivamente a stabilizzarsi attorno al 50%.\nQuesto fenomeno riflette due aspetti chiave:\n\n\nRiduzione della variabilità: la media campionaria diventa sempre più affidabile con l’aumentare della numerosità del campione.\n\n\nSeparazione tra singoli eventi e comportamento aggregato: la LLN non elimina l’incertezza nei casi singoli (es., il risultato del prossimo lancio), ma descrive un pattern prevedibile a livello di popolazione.\n\nLa simulazione seguente illustra questo principio generando quattro sequenze indipendenti di lanci di moneta e calcolando la proporzione cumulativa di “teste”:\n\n\n\n\n\n\n\n\nIl grafico evidenzia due fenomeni: la convergenza verso il valore teorico (linea tratteggiata) e la variabilità iniziale tra le sequenze, che si attenua progressivamente. Questo esempio dimostra come la LLN fornisca un ponte tra modelli teorici (es., “moneta equa”) e osservazioni empiriche, pur rimanendo valida solo in condizioni di ripetibilità (stesse probabilità in ogni prova) e assenza di bias sistematici.\nLe simulazioni trovano ampio utilizzo in psicologia sia nella formazione che nella ricerca:\n\n\nDidattica: visualizzare il comportamento di indicatori statistici (es., media campionaria) al variare della dimensione del campione, rendendo tangibili concetti come “potenza statistica” o “errore standard”.\n\n\nRicerca: testare la robustezza di modelli psicometrici in condizioni controllate, simulando dati con specifiche caratteristiche (es., correlazioni deboli, rumore sperimentale).\n\nQuesti strumenti favoriscono un apprendimento attivo, invitando gli studenti a manipolare parametri (es., probabilità di successo, numerosità campionaria) e osservarne gli effetti, consolidando così l’intuizione statistica. Tuttavia, è cruciale ricordare che le simulazioni non sostituiscono la teoria, ma la completano, evidenziandone limiti e presupposti applicativi.\n\n\n\n\n\n\nApprofondimento critico\n\n\n\nLa LLN non elimina sfide metodologiche come bias di campionamento, misurazione imperfetta o fenomeni non stazionari. In psicologia, dove molti costrutti (es., emozioni, attitudini) sono intrinsecamente dinamici, l’applicazione della LLN richiede particolare attenzione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/01_intro_prob.html#riflessioni-conclusive",
    "title": "24  Interpretazione della probabilità",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa teoria della probabilità, nata originariamente per analizzare il gioco d’azzardo, si è gradualmente trasformata nel corso dei secoli in un pilastro metodologico per affrontare l’incertezza in un’ampia gamma di contesti, compresa la psicologia. La sua evoluzione storica testimonia un confronto continuo fra interpretazioni epistemiche e frequenzialiste, contribuendo all’elaborazione di strumenti analitici e pratiche operative — dalle procedure inferenziali alla simulazione computerizzata — che consentono di modellizzare sistemi complessi.\nDa un punto di vista filosofico, la probabilità può essere intesa sia come proprietà del mondo (in chiave frequenzialista), sia come misura della nostra conoscenza (nell’ottica bayesiana e soggettivista). Nel primo caso, le frequenze relative e la legge dei grandi numeri mostrano come, da una moltitudine di eventi, possano emergere regolarità e pattern stabili. Nel secondo, l’enfasi è posta sulla dimensione umana e fallibile dell’inferenza: le credenze e le informazioni disponibili influenzano in modo diretto la nostra stima della probabilità di un evento.\nAl di là di queste differenze interpretative, la probabilità si rivela uno strumento insostituibile per pianificare esperimenti, analizzare dati e prendere decisioni in condizioni di incertezza – attività centrali nel campo della psicologia. Inoltre, la possibilità di integrare metodologie teoriche e simulazioni amplia ulteriormente le prospettive di ricerca e la capacità di comprendere i fenomeni studiati. Lungi dall’essere un semplice calcolo combinatorio, la probabilità abbraccia così la complessità della realtà e la ricchezza della conoscenza umana, mostrando una versatilità che la rende uno dei fondamenti del pensiero scientifico contemporaneo.\n\n\n\n\n\n\nPer chi desidera approfondire, il primo capitolo del testo Bernoulli’s Fallacy (Clayton, 2021) offre un’introduzione molto leggibile alle tematiche della definizione della probabilità nella storia della scienza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#esercizi",
    "href": "chapters/probability/01_intro_prob.html#esercizi",
    "title": "24  Interpretazione della probabilità",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQuali sono le principali concezioni della probabilità esplorate nel capitolo?\nCome viene definita l’incertezza secondo David Spiegelhalter?\nQual è il ruolo della casualità nella teoria della probabilità?\nCome funziona il modello dell’urna per rappresentare la casualità?\nQuali sono alcune applicazioni del modello della casualità?\nQuali sono le due principali fonti di incertezza nei fenomeni non deterministici?\nCome viene interpretata la probabilità secondo l’approccio soggettivista?\nQuali sono le due dimensioni principali del concetto di probabilità secondo Hacking?\nQual è stato il contributo di Pascal e Fermat alla teoria della probabilità?\nQuali sono le differenze tra l’approccio bayesiano e frequentista nella teoria della probabilità?\nQual è la Legge dei Grandi Numeri e come si applica?\nQuali sono i limiti dell’interpretazione frequentista della probabilità?\nCome ha influenzato Fisher lo sviluppo della statistica frequentista?\nQual è stato il ruolo di Jeffreys nella rinascita dell’approccio bayesiano?\nCome definisce Bruno de Finetti la probabilità?\nQuali sono i principi fondamentali della probabilità soggettivista secondo Jaynes?\nQuali sono le alternative terminologiche proposte per la “probabilità soggettiva”?\nQual è l’importanza della simulazione nella comprensione della probabilità?\nQuali sono le implicazioni filosofiche della dualità della probabilità?\nQuali sono i principali contributi storici alla teoria della probabilità?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nLe principali concezioni della probabilità esplorate nel capitolo sono la visione classica, frequentista e bayesiana.\nSecondo David Spiegelhalter, l’incertezza è definita come la “consapevolezza cosciente dell’ignoranza”, riguardante eventi futuri o passati che non possiamo conoscere con certezza.\nLa casualità è un modello concettuale che aiuta a gestire e quantificare eventi imprevedibili, ma che seguono schemi regolari e riconoscibili.\nIl modello dell’urna rappresenta la casualità attraverso l’estrazione di palline numerate da un’urna, dove ogni pallina ha la stessa probabilità di essere estratta.\nAlcune applicazioni del modello della casualità includono indagini statistiche, sperimentazione scientifica e simulazioni in fisica e psicologia.\nLe due principali fonti di incertezza sono l’incertezza epistemica (derivante dalla conoscenza limitata) e l’incertezza ontologica (intrinseca al fenomeno stesso).\nSecondo l’approccio soggettivista, la probabilità è una misura del grado di fiducia o convinzione di un individuo riguardo al verificarsi di un evento, basata sulle informazioni disponibili.\nSecondo Hacking, le due dimensioni principali del concetto di probabilità sono quella epistemologica (misura della credibilità) e quella frequenziale (tendenza osservabile nei fenomeni aleatori).\nPascal e Fermat hanno sviluppato i primi strumenti matematici per calcolare la probabilità degli eventi futuri, risolvendo problemi legati al gioco d’azzardo.\nL’approccio bayesiano considera la probabilità come una misura soggettiva del grado di fiducia, mentre l’approccio frequentista la definisce come la frequenza relativa di un evento in una serie infinita di prove.\nLa Legge dei Grandi Numeri afferma che al crescere del numero di prove, la media dei risultati osservati si avvicina al valore atteso teorico.\nI limiti dell’interpretazione frequentista includono la difficoltà di applicarla a eventi singolari e non ripetibili, e la necessità di un numero infinito di prove per definire la probabilità.\nFisher ha introdotto concetti chiave come la massima verosimiglianza, i test di significatività e l’analisi della varianza, contribuendo allo sviluppo della statistica frequentista.\nJeffreys ha contribuito alla rinascita dell’approccio bayesiano con il suo libro “Theory of Probability”, che ha riportato l’attenzione sui metodi bayesiani.\nBruno de Finetti definisce la probabilità come una misura del grado di fiducia razionale basata su informazioni incomplete, affermando che “la probabilità non esiste” come proprietà oggettiva.\nSecondo Jaynes, i principi fondamentali della probabilità soggettivista includono l’intervallo numerico (0-1) e la coerenza logica, basandosi su informazioni disponibili.\nLe alternative terminologiche proposte per la “probabilità soggettiva” includono “probabilità personale” e “probabilità epistemica”.\nLa simulazione è importante per approssimare probabilità empiriche in contesti complessi, dove soluzioni analitiche non sono praticabili, e per comprendere fenomeni probabilistici attraverso modelli numerici.\nLe implicazioni filosofiche della dualità della probabilità riflettono la tensione tra una descrizione oggettiva della realtà e la soggettività del processo interpretativo.\nI principali contributi storici alla teoria della probabilità includono i lavori di Pascal, Fermat, Huygens, Bernoulli, Fisher, Jeffreys e de Finetti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#bibliografia",
    "href": "chapters/probability/01_intro_prob.html#bibliografia",
    "title": "24  Interpretazione della probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nClayton, A. (2021). Bernoulli’s Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press.\n\n\nFishburn, P. C. (1986). The axioms of subjective probability. Statistical Science, 1(3), 335–345.\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nHowson, C., & Urbach, P. (2006). Scientific reasoning: the Bayesian approach. Open Court Publishing.\n\n\nJeffreys, H. (1998). The theory of probability. OuP Oxford.\n\n\nKaplan, D. (2023). Bayesian statistics for the social sciences. Guilford Publications.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.\n\n\nPress, S. J. (2009). Subjective and objective Bayesian statistics: Principles, models, and applications. John Wiley & Sons.\n\n\nRamsey, F. P. (1926). Truth and probability. In Readings in Formal Epistemology: Sourcebook (pp. 21–45). Springer.\n\n\nSpiegelhalter, D. (2024). Why probability probably doesn’t exist (but it is useful to act like it does). Nature, 636(8043), 560–563.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html",
    "href": "chapters/probability/02_probability_models.html",
    "title": "25  Modelli probabilistici",
    "section": "",
    "text": "Introduzione\nDopo aver esaminato il significato filosofico della probabilità nel Capitolo 24, questo capitolo ne sviluppa una trattazione più formale, creando un collegamento tra la riflessione teorica e gli strumenti operativi. Partendo dalla definizione di esperimento casuale – come il lancio di una moneta o la somministrazione di un test psicologico – costruiremo un framework matematico per analizzare e quantificare le proprietà di tali esperimenti. In particolare, approfondiremo i concetti di spazio campionario, eventi e proprietà della probabilità, fornendo le basi per un’interpretazione rigorosa dei fenomeni complessi in psicologia e nelle scienze sociali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#introduzione",
    "href": "chapters/probability/02_probability_models.html#introduzione",
    "title": "25  Modelli probabilistici",
    "section": "",
    "text": "Panoramica del capitolo\n\nNozioni di spazio campionario, eventi e operazioni su eventi.\nDefinizione di probabilità.\nSpazi discreti o continui.\nTeorema della somma.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Probability Models del testo di Chan & Kroese (2025).\nStudiare l’Appendice G.\nStudiare l’Appendice H.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt;\n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(readr, VennDiagram)\n\n\n\n\n\n\n\n\n\n\nDomande introduttive\n\n\n\n\n\nPrima di esaminare in maniera più formale le basi della teoria della probabilità, consideriamo un classico problema della teoria della probabilità:\n“Quante persone servono in una stanza perché ci sia almeno il 50% di probabilità che due condividano lo stesso compleanno?”\nQuesto problema, noto come problema dei compleanni, fu introdotto dal matematico Richard von Mises nel 1932. La sua soluzione sfida l’intuizione e rivela quanto le probabilità combinatorie possano essere ingannevoli.\nRispondi alle seguenti domande.\n\nCon quante persone pensi si superi il 50% di probabilità? (23? 100? 180?)\nCon 30 persone, quale probabilità stimi? (10%? 50%? 70%?)\n\nScrivi le tue risposte su un foglietto senza condividere con i compagni.\nPer svolgere un esercizio in classe, compila il seguente modulo su Google Forms.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#esperimenti-casuali",
    "href": "chapters/probability/02_probability_models.html#esperimenti-casuali",
    "title": "25  Modelli probabilistici",
    "section": "\n25.1 Esperimenti casuali",
    "text": "25.1 Esperimenti casuali\nIl concetto fondamentale della probabilità è l’esperimento casuale, ovvero un procedimento il cui esito non può essere previsto con certezza, ma che può essere analizzato quantitativamente. Alcuni esempi di esperimenti casuali includono: lanciare un dado e osservare il numero ottenuto sulla faccia superiore; estrarre una carta a caso da un mazzo e registrarne il seme e il valore; misurare il livello di stress percepito da un gruppo di individui in un determinato contesto, come durante un esame o un evento stressante; contare il numero di risposte corrette fornite dai partecipanti a un test di memoria entro un tempo prestabilito; eccetera.\nL’analisi probabilistica ha lo scopo di comprendere il comportamento di tali esperimenti attraverso la costruzione di modelli matematici. Una volta formalizzato matematicamente un esperimento casuale, è possibile calcolare grandezze di interesse, come probabilità ed aspettative. Questi modelli possono essere implementati al computer per simulare l’esperimento e analizzarne i risultati. Inoltre, la modellizzazione matematica degli esperimenti casuali costituisce la base della statistica, disciplina che permette di confrontare diversi modelli e identificare quello più adeguato ai dati osservati.\n\n25.1.1 Il lancio di una moneta\nUno degli esperimenti casuali più semplici e fondamentali è il lancio ripetuto di una moneta. Molti concetti chiave della teoria della probabilità possono essere illustrati partendo da questo esperimento elementare. Per studiarne il comportamento, possiamo simularlo al computer utilizzando il linguaggio R.\nDi seguito, un semplice script in R simula 100 lanci di una moneta equa (cioè con probabilità uguali di ottenere Testa o Croce) e rappresenta graficamente la distribuzione dei risultati mediante un diagramma a barre.\n\nset.seed(123) # Imposta il seed per garantire la riproducibilità\nx &lt;- runif(100) &lt; 0.5 # Genera 100 numeri casuali e verifica se sono minori di 0.5\nx\n#&gt;   [1]  TRUE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE  TRUE\n#&gt;  [13] FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n#&gt;  [25] FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE  TRUE\n#&gt;  [37] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n#&gt;  [49]  TRUE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE  TRUE\n#&gt;  [61] FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE\n#&gt;  [73] FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE\n#&gt;  [85]  TRUE  TRUE FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE\n#&gt;  [97] FALSE  TRUE  TRUE FALSE\n\nNel codice, la funzione runif genera 100 numeri casuali distribuiti uniformemente nell’intervallo [0, 1]. Confrontando ciascun numero con 0.5, otteniamo un vettore logico che rappresenta il risultato di ogni lancio: Testa (TRUE) o Croce (FALSE).\n\nt &lt;- 1:100 # Sequenza degli indici dei lanci\n\n# Creazione del dataframe per ggplot2\ndat &lt;- tibble(\n  Lancio = t,\n  Risultato = ifelse(x, \"Testa\", \"Croce\")\n)\nhead(dat)\n#&gt; # A tibble: 6 × 2\n#&gt;   Lancio Risultato\n#&gt;    &lt;int&gt; &lt;chr&gt;    \n#&gt; 1      1 Testa    \n#&gt; 2      2 Croce    \n#&gt; 3      3 Testa    \n#&gt; 4      4 Croce    \n#&gt; 5      5 Croce    \n#&gt; 6      6 Testa\n\nIl grafico a barre mostra la distribuzione osservata degli esiti.\n\n# Creazione del grafico a barre della distribuzione dei risultati\ndat |&gt;\n  ggplot(aes(x = Risultato)) +\n  geom_bar(aes(y = after_stat(prop), group = 1), width = 0.5) +\n  labs(\n    x = \"Risultato\",\n    y = \"Frequenza relativa\"\n  )\n\n\n\n\n\n\n\nUn aspetto rilevante di questo esperimento è l’andamento della proporzione osservata di esiti “Testa” in funzione del numero di lanci. Il grafico riportato di seguito illustra l’evoluzione della media cumulativa degli esiti “Testa”, che, in accordo con la legge dei grandi numeri, dovrebbe convergere al valore teorico di 0.5.\n\ny &lt;- cumsum(x) / t # Calcola la media cumulativa delle Teste\n\n# Creazione del dataframe per il grafico della media mobile\ndata_mean &lt;- tibble(\n  Lancio = t, \n  Media_Testa = y\n)\n\n# Creazione del grafico della media cumulativa\ndata_mean |&gt;\n  ggplot(\n    aes(x = Lancio, y = Media_Testa)\n  ) +\n  geom_line(linewidth = 1.5) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  labs(\n    x = \"Numero di lanci\",\n    y = \"Frequenza cumulativa di Teste\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedia cumulata\n\n\n\n\n\nLa media cumulata (o cumulativa) è una media che si calcola progressivamente, aggiungendo un nuovo dato alla volta e ricalcolando la media considerando tutti i valori precedenti insieme al nuovo.\nIn pratica, mostra come la media si evolve man mano che vengono inclusi nuovi dati nella serie.\nCome si calcola?\n\nAl primo dato, la media cumulata è il dato stesso.\n\nAl secondo dato, è la media tra il primo e il secondo.\n\nAl terzo dato, è la media tra il primo, il secondo e il terzo.\n\nE così via…\n\nFormula intuitiva:\n\\[\n\\text{Media cumulata al passo } n = \\frac{\\text{somma di tutti i dati fino al passo } n}{n}\n\\]\nEsempio pratico:\nSupponiamo di avere i voti di uno studente in 3 verifiche:\n\nVerifica 1: 7\n\nVerifica 2: 6\n\nVerifica 3: 8\n\nLe medie cumulate saranno:\n\nDopo la 1ª verifica: \\(\\frac{7}{1} = 7\\).\n\nDopo la 2ª verifica: \\(\\frac{7 + 6}{2} = 6.5\\).\n\nDopo la 3ª verifica: \\(\\frac{7 + 6 + 8}{3} = 7\\).\n\nA cosa serve?\n\n\nTracciare l’andamento nel tempo (es.: mostrare come la frequenza di “Testa” si avvicina gradualmente al 50% teorico man mano che aumentano i lanci).\n\n\nLisciare le fluttuazioni: riduce l’impatto di picchi temporanei, mostrando un trend più stabile.\n\n\nValutare prestazioni progressive (es.: un atleta che migliora gradualmente).\n\n\n\n\n\nIl grafico mostra come la media delle Teste oscilla inizialmente a causa della variabilità intrinseca dell’esperimento, ma tende progressivamente a stabilizzarsi intorno a 0.5. Questo fenomeno è un esempio della Legge dei Grandi Numeri, secondo cui, ripetendo un esperimento casuale un numero sempre maggiore di volte, la frequenza relativa di un evento si avvicina alla sua probabilità teorica.\n\n25.1.2 Domande di interesse\nL’esperimento casuale del lancio di una moneta porta a numerose domande, tra cui:\n\nQual è la probabilità di ottenere un certo numero \\(x\\) di Teste in 100 lanci?\nQual è il numero atteso di Teste in un esperimento di 100 lanci?\n\nDal punto di vista statistico, quando osserviamo i risultati di un esperimento reale (ad esempio, 100 lanci di una moneta), possiamo anche porci domande come:\n\nLa moneta è davvero equa o è sbilanciata?\nQual è il miglior metodo per stimare la probabilità \\(p\\) di ottenere Testa dalla sequenza osservata di lanci?\nQuanto è precisa la stima ottenuta e con quale livello di incertezza?\n\nQuesti interrogativi costituiscono la base della statistica inferenziale, che permette di testare ipotesi sulla probabilità di un evento e stimare parametri sconosciuti sulla base di dati osservati.\n\n25.1.3 Modellizzazione\nLa descrizione matematica di un esperimento casuale si basa su tre elementi fondamentali:\n\nLo spazio campionario: rappresenta l’insieme di tutti i possibili esiti dell’esperimento. Nel caso di esperimenti semplici, lo spazio campionario è immediato da individuare, mentre in situazioni più complesse è necessario applicare i principi del calcolo combinatorio.\nGli eventi: sono sottoinsiemi dello spazio campionario e rappresentano gli esiti di interesse. Per analizzare e manipolare gli eventi, utilizziamo gli strumenti della teoria degli insiemi.\nLa probabilità: assegna un valore numerico a ciascun evento, indicando la sua probabilità di verificarsi. L’assegnazione delle probabilità avviene secondo gli assiomi di Kolmogorov.\n\nNei paragrafi seguenti, analizzeremo ciascuna di queste componenti in dettaglio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#spazio-campionario",
    "href": "chapters/probability/02_probability_models.html#spazio-campionario",
    "title": "25  Modelli probabilistici",
    "section": "\n25.2 Spazio campionario",
    "text": "25.2 Spazio campionario\nAnche se non possiamo prevedere con esattezza l’esito di un singolo esperimento casuale, possiamo comunque definire tutti i risultati che potrebbero verificarsi. L’insieme completo di questi esiti possibili si chiama spazio campionario.\n\nDefinizione 25.1 Lo spazio campionario \\(\\Omega\\) di un esperimento casuale è l’insieme di tutti i possibili esiti dell’esperimento.\n\n\n25.2.1 Esempi di spazi campionari\nConsideriamo lo spazio campionario di alcuni esperimenti casuali.\n\nLancio di due dadi consecutivi: \\[\n\\Omega = \\{(1,1), (1,2), \\dots, (6,6)\\}.\n\\]\nTempo di reazione a uno stimolo visivo: \\[\\Omega = \\mathbb{R}^+,\\] ovvero l’insieme dei numeri reali positivi.\nNumero di errori in un test di memoria a breve termine: \\[\\Omega = \\{0, 1, 2, \\dots\\}.\\]\nMisurazione delle altezze di dieci persone: \\[\\Omega = \\{(x_1, \\dots, x_{10}) : x_i \\ge 0, \\; i=1,\\dots,10\\} \\subset \\mathbb{R}^{10}.\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#eventi",
    "href": "chapters/probability/02_probability_models.html#eventi",
    "title": "25  Modelli probabilistici",
    "section": "\n25.3 Eventi",
    "text": "25.3 Eventi\nSolitamente non siamo interessati a un singolo esito, ma a un insieme di essi. Un evento è un sottoinsieme dello spazio campionario a cui possiamo assegnare una probabilità.\n\nDefinizione 25.2 Un evento è un sottoinsieme \\(A \\subseteq \\Omega\\) al quale viene assegnata una probabilità. Indichiamo gli eventi con lettere maiuscole \\(A, B, C, \\dots\\). Diciamo che l’evento \\(A\\) si verifica se l’esito dell’esperimento appartiene a \\(A\\).\n\n\n25.3.1 Esempi di eventi\nConsideriamo alcuni possibili eventi definiti sugli spazi campionari descritti sopra.\n\nLancio di due dadi consecutivi.Evento: “La somma dei due dadi è uguale a 7”\\[\nA = \\{(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\\}.\n\\]\nTempo di reazione a uno stimolo visivo.Evento: “Il tempo di reazione è inferiore a 2 secondi”\\[\nA = [0, 2).\n\\]\nNumero di errori in un test di memoria a breve termine.Evento: “Il numero di errori è al massimo 3”\\[\nA = \\{0, 1, 2, 3\\}.\n\\]\nMisurazione delle altezze di dieci persone.Evento: “Almeno due persone hanno un’altezza superiore a 180 cm”\\[\nA = \\{(x_1, \\dots, x_{10}) : \\text{almeno due } x_i &gt; 180\\}.\n\\]\n\nQuesti esempi mostrano come gli eventi possano essere definiti in modo diverso a seconda della natura dello spazio campionario e del contesto di interesse.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nSupponiamo di lanciare una moneta tre volte e di annotare se esce Testa (\\(H\\)) o Croce (\\(T\\)) in ogni lancio. Lo spazio campionario è:\n\\[\n\\Omega = \\{HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\\},\n\\]\ndove, ad esempio, \\(HTH\\) indica che il primo lancio dà Testa, il secondo Croce e il terzo Testa.\nUn’alternativa è rappresentare lo spazio campionario come l’insieme dei vettori binari di lunghezza 3, \\(\\{0,1\\}^3\\), dove Testa (\\(H\\)) corrisponde a 1 e Croce (\\(T\\)) a 0.\nL’evento \\(A\\) “il terzo lancio è Testa” si esprime come:\n\\[\nA = \\{HHH, HTH, THH, TTH\\}.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#operazioni-sugli-eventi",
    "href": "chapters/probability/02_probability_models.html#operazioni-sugli-eventi",
    "title": "25  Modelli probabilistici",
    "section": "\n25.4 Operazioni sugli eventi",
    "text": "25.4 Operazioni sugli eventi\nPoiché gli eventi sono definiti come insiemi, possiamo applicare loro le classiche operazioni insiemistiche.\nUnione (\\(\\cup\\)). L’unione di due eventi \\(A\\) e \\(B\\) è l’insieme di tutti gli esiti che appartengono almeno a uno dei due:\n\\[\nA \\cup B = \\{\\omega \\in \\Omega : \\omega \\in A \\text{ oppure } \\omega \\in B\\}.\n\\]\nIntersezione (\\(\\cap\\)). L’intersezione di due eventi è l’insieme degli esiti comuni:\n\\[\nA \\cap B = \\{\\omega \\in \\Omega : \\omega \\in A \\text{ e } \\omega \\in B\\}.\n\\]\nComplemento (\\(A^c\\)). Il complemento di un evento \\(A\\) è l’insieme di tutti gli esiti che non appartengono ad \\(A\\):\n\\[\nA^c = \\{\\omega \\in \\Omega : \\omega \\notin A\\}.\n\\]\nEventi mutuamente esclusivi. Due eventi sono mutuamente esclusivi se non hanno esiti in comune, ovvero:\n\\[\nA \\cap B = \\emptyset.\n\\]\n\n\n\n\n\n\nEsempio\n\n\n\n\n\n\n# Universo\nU &lt;- 1:10  \n\n# Definizione degli insiemi A e B\nA &lt;- c(1, 2, 3, 4, 5)\nB &lt;- c(4, 5, 6, 7, 8)\n\n# Calcolare l'unione, l'intersezione e il complemento relativo a un universo U\nunion_AB &lt;- union(A, B)\nintersect_AB &lt;- intersect(A, B)\ncomplement_A &lt;- setdiff(U, A)\ncomplement_B &lt;- setdiff(U, B)\n\n# Visualizzazione testuale\ncat(\"Unione A ∪ B:\", union_AB, \"\\n\")\n#&gt; Unione A ∪ B: 1 2 3 4 5 6 7 8\ncat(\"Intersezione A ∩ B:\", intersect_AB, \"\\n\")\n#&gt; Intersezione A ∩ B: 4 5\ncat(\"Complemento di A:\", complement_A, \"\\n\")\n#&gt; Complemento di A: 6 7 8 9 10\ncat(\"Complemento di B:\", complement_B, \"\\n\")\n#&gt; Complemento di B: 1 2 3 9 10\n\n\n# Visualizzazione con diagrammi di Venn\nvenn.plot &lt;- draw.pairwise.venn(\n  area1 = length(A),\n  area2 = length(B),\n  cross.area = length(intersect(A, B)),  # Corretto: usa intersect() invece di intersect_AB\n  category = c(\"A\", \"B\"),\n  fill = c(\"orange\", \"blue\"),\n  alpha = 0.5,\n  cat.col = c(\"orange\", \"blue\")  # Corretto: allineato con i colori di fill\n)\n\n# Visualizza il diagramma\ngrid.draw(venn.plot)\n\n\n\n\n\n\n\n\n# Esempio di eventi mutualmente esclusivi\nC &lt;- c(9, 10)  # Insieme disgiunto da A e B\nintersect_AC &lt;- intersect(A, C)  # Deve essere vuoto\n\ncat(\"Intersezione A ∩ C (eventi mutualmente esclusivi):\", intersect_AC, \"\\n\")\n#&gt; Intersezione A ∩ C (eventi mutualmente esclusivi):\n\n\n# Visualizzazione di eventi mutualmente esclusivi\nvenn.plot2 &lt;- draw.pairwise.venn(\n  area1 = length(A),\n  area2 = length(C),\n  cross.area = 0,  # Nessuna intersezione\n  category = c(\"A\", \"C\"),\n  fill = c(\"blue\", \"orange\"),\n  alpha = 0.5,\n  cat.col = c(\"blue\", \"orange\")\n)\ngrid.draw(venn.plot2)\n\n\n\n\n\n\n\n\n\n\n\n25.4.1 Proprietà fondamentali delle operazioni su eventi\n\nIdempotenza: \\[\nA \\cup A = A, \\quad A \\cap A = A.\n\\]\nLeggi di De Morgan: \\[\n(A \\cup B)^c = A^c \\cap B^c, \\quad (A \\cap B)^c = A^c \\cup B^c.\n\\]\nUnione e Intersezione con l’insieme vuoto: \\[\nA \\cup \\emptyset = A, \\quad A \\cap \\emptyset = \\emptyset.\n\\]\nUnione e Intersezione con lo spazio campionario: \\[\nA \\cup \\Omega = \\Omega, \\quad A \\cap \\Omega = A.\n\\]\n\nQueste operazioni forniscono la base per costruire e manipolare eventi in contesti probabilistici, permettendo di calcolare probabilità e prendere decisioni basate sull’analisi degli esiti possibili.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nPer gli insiemi definiti nell’esempio precedente, possiamo verificare la prima legge di De Morgan in R confrontando il complemento dell’unione con l’intersezione dei complementi:\n\ncomplemento dell’unione: \\((A \\cup B)^c\\),\nintersezione dei complementi: \\(A^c \\cap B^c\\).\n\nEseguiamo i calcoli in R:\n\n# Complemento dell'unione: (A ∪ B)^c\nsetdiff(U, union(A, B))\n#&gt; [1]  9 10\n\n\n# Intersezione dei complementi: A^c ∩ B^c\nintersect(setdiff(U, A), setdiff(U, B))\n#&gt; [1]  9 10\n\nSecondo la legge di De Morgan, i due risultati devono coincidere.\n\n\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nConsideriamo l’esperimento del lancio di due dadi. Lo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili coppie di risultati che possono verificarsi. Ogni dado ha 6 facce, quindi lo spazio campionario è:\n\\[\n\\Omega = \\{(1,1), (1,2), \\dots, (6,6)\\},\n\\]\nper un totale di \\(6 \\times 6 = 36\\) esiti possibili.\nSiamo interessati all’evento \\(A\\): “la somma dei due dadi è almeno 10”. Questo evento include tutte le coppie di risultati la cui somma è 10, 11 o 12. Gli esiti che soddisfano questa condizione sono:\n\\[\nA = \\{(4,6), (5,5), (5,6), (6,4), (6,5), (6,6)\\}.\n\\]\nEcco come generare lo spazio campionario in R in modo algoritmico e definire l’evento “la somma dei due dadi è almeno 10”:\nLo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili coppie di risultati del lancio di due dadi. In R, possiamo generarlo utilizzando la funzione expand.grid, che crea tutte le combinazioni possibili tra i valori dei due dadi.\n\n# Generazione dello spazio campionario Omega\ndado &lt;- 1:6 # Facce di un dado\nOmega &lt;- expand.grid(Dado1 = dado, Dado2 = dado) # Tutte le combinazioni possibili\n\nL’output sarà una tabella con 36 righe, una per ogni combinazione possibile:\n\n# Visualizzazione dello spazio campionario\nprint(Omega)\n#&gt;    Dado1 Dado2\n#&gt; 1      1     1\n#&gt; 2      2     1\n#&gt; 3      3     1\n#&gt; 4      4     1\n#&gt; 5      5     1\n#&gt; 6      6     1\n#&gt; 7      1     2\n#&gt; 8      2     2\n#&gt; 9      3     2\n#&gt; 10     4     2\n#&gt; 11     5     2\n#&gt; 12     6     2\n#&gt; 13     1     3\n#&gt; 14     2     3\n#&gt; 15     3     3\n#&gt; 16     4     3\n#&gt; 17     5     3\n#&gt; 18     6     3\n#&gt; 19     1     4\n#&gt; 20     2     4\n#&gt; 21     3     4\n#&gt; 22     4     4\n#&gt; 23     5     4\n#&gt; 24     6     4\n#&gt; 25     1     5\n#&gt; 26     2     5\n#&gt; 27     3     5\n#&gt; 28     4     5\n#&gt; 29     5     5\n#&gt; 30     6     5\n#&gt; 31     1     6\n#&gt; 32     2     6\n#&gt; 33     3     6\n#&gt; 34     4     6\n#&gt; 35     5     6\n#&gt; 36     6     6\n\nL’evento \\(A\\) è definito come “la somma dei due dadi è almeno 10”. Per identificare queste combinazioni, aggiungiamo una colonna che calcola la somma dei due dadi e filtriamo le righe in cui la somma è maggiore o uguale a 10.\n\n# Aggiunta di una colonna per la somma dei due dadi\nOmega$Somma &lt;- Omega$Dado1 + Omega$Dado2\n\n# Definizione dell'evento A: somma dei due dadi almeno 10\nA &lt;- Omega[Omega$Somma &gt;= 10, ]\n\nL’output sarà un data frame con le combinazioni in cui la somma è almeno 10:\n\n# Visualizzazione dell'evento A\nprint(A)\n#&gt;    Dado1 Dado2 Somma\n#&gt; 24     6     4    10\n#&gt; 29     5     5    10\n#&gt; 30     6     5    11\n#&gt; 34     4     6    10\n#&gt; 35     5     6    11\n#&gt; 36     6     6    12\n\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) è stato generato algoritmicamente utilizzando expand.grid;\nl’evento \\(A\\) è stato definito filtrando le combinazioni in cui la somma dei due dadi è almeno 10.\n\n\n\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nConsideriamo un esperimento in cui lanciamo una moneta tre volte consecutivamente. Ogni lancio può risultare in Testa (H) o Croce (T). Lo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili sequenze di risultati dei tre lanci. Ci sono \\(2^3 = 8\\) possibili esiti, che possono essere rappresentati come:\n\\[\n\\Omega = \\{\\text{HHH}, \\text{HHT}, \\text{HTH}, \\text{HTT}, \\text{THH}, \\text{THT}, \\text{TTH}, \\text{TTT}\\}.\n\\]\nVogliamo definire in R l’evento \\(A\\): “Il terzo lancio della moneta dia Testa (H)”. Questo evento include tutte le sequenze in cui il terzo carattere è “H”.\nIn R, possiamo rappresentare lo spazio campionario \\(\\Omega\\) come un vettore di stringhe, dove ogni stringa corrisponde a una sequenza di risultati.\n\n# Definizione dello spazio campionario Omega\nomega &lt;- c(\"HHH\", \"HHT\", \"HTH\", \"HTT\", \"THH\", \"THT\", \"TTH\", \"TTT\")\nomega\n#&gt; [1] \"HHH\" \"HHT\" \"HTH\" \"HTT\" \"THH\" \"THT\" \"TTH\" \"TTT\"\n\nL’evento \\(A\\) è costituito da tutte le sequenze in cui il terzo lancio è Testa (H). Per identificare queste sequenze, utilizziamo la funzione substr, che estrae il terzo carattere da ciascuna stringa e verifica se è uguale a “H”.\n\n# Definizione dell'evento A: terzo lancio è Testa (H)\nA &lt;- omega[substr(omega, 3, 3) == \"H\"]\n\nSpiegazione del codice:\n\n\nsubstr(omega, 3, 3) estrae il terzo carattere da ciascuna stringa nel vettore omega.\n\nsubstr(omega, 3, 3) == \"H\" crea un vettore logico (vero/falso) che indica se il terzo carattere è “H”.\n\nomega[...] filtra il vettore omega, mantenendo solo le sequenze che soddisfano la condizione.\n\nL’output sarà:\n\n# Visualizzazione dell'evento A\nA\n#&gt; [1] \"HHH\" \"HTH\" \"THH\" \"TTH\"\n\nQueste sono le sequenze in cui il terzo lancio è Testa (H).\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) è stato definito come un vettore di stringhe in R;\nl’evento \\(A\\) è stato costruito filtrando le sequenze in cui il terzo carattere è “H”, utilizzando la funzione substr(x, start, stop);\nl’evento \\(A\\) corrisponde alle sequenze: HHH, HTH, THH, TTH.\n\nQuesto esercizio illustra come definire e manipolare eventi in R, utilizzando operazioni di base su stringhe e vettori.\n\n\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nConsideriamo l’esperimento del lancio consecutivo di due dadi. Lo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili coppie di risultati:\n\\[\n\\Omega = \\{(1, 1), (1, 2), \\dots, (6, 6)\\}.\n\\]\nDefiniamo due eventi:\n\nEvento \\(A\\): “Il primo dado mostra un 6”.\nQuesto evento include tutte le coppie in cui il primo dado è 6:\\[\nA = \\{(6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)\\}.\n\\]\nEvento \\(B\\): “Il secondo dado mostra un 6”.\nQuesto evento include tutte le coppie in cui il secondo dado è 6:\\[\nB = \\{(1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 6)\\}.\n\\]\n\nL’intersezione \\(A \\cap B\\) rappresenta l’evento in cui entrambi i dadi mostrano un 6:\n\\[\nA \\cap B = \\{(6, 6)\\}.\n\\]\nImplementazione in R\nPer analizzare gli eventi legati al lancio di due dadi, utilizziamo R per simulare lo spazio campionario e manipolare gli eventi.\n1. Generazione dello spazio campionario\nLa funzione expand.grid crea tutte le combinazioni possibili tra gli elementi di due vettori. Nel nostro caso, generiamo tutte le coppie (Dado1, Dado2):\n\n# Definizione delle facce dei dadi (1-6)\ndado &lt;- 1:6\n\n# Creazione di tutte le 36 combinazioni possibili\nOmega &lt;- expand.grid(\n  Dado1 = dado,\n  Dado2 = dado\n)\n\n# Visualizzazione delle prime 6 righe\nhead(Omega)\n#&gt;   Dado1 Dado2\n#&gt; 1     1     1\n#&gt; 2     2     1\n#&gt; 3     3     1\n#&gt; 4     4     1\n#&gt; 5     5     1\n#&gt; 6     6     1\n\n2. Definizione degli eventi\nEvento A - “Primo dado = 6”:\nFiltriamo le righe dove la colonna Dado1 è uguale a 6:\n\nA &lt;- Omega[Omega$Dado1 == 6, ] # Selezione condizionale\nprint(\"Evento A:\")\n#&gt; [1] \"Evento A:\"\nA\n#&gt;    Dado1 Dado2\n#&gt; 6      6     1\n#&gt; 12     6     2\n#&gt; 18     6     3\n#&gt; 24     6     4\n#&gt; 30     6     5\n#&gt; 36     6     6\n\nEvento B - “Secondo dado = 6”:\nFiltriamo le righe dove la colonna Dado2 è uguale a 6:\n\nB &lt;- Omega[Omega$Dado2 == 6, ]\nprint(\"Evento B:\")\n#&gt; [1] \"Evento B:\"\nB\n#&gt;    Dado1 Dado2\n#&gt; 31     1     6\n#&gt; 32     2     6\n#&gt; 33     3     6\n#&gt; 34     4     6\n#&gt; 35     5     6\n#&gt; 36     6     6\n\n3. Calcolo dell’intersezione A ∩ B\nMetodo 1: Funzione intersect()\nLa funzione base intersect() confronta intere righe tra due dataframe e restituisce quelle comuni:\n\nA_intersezione_B &lt;- intersect(A, B)\nprint(\"Intersezione con intersect():\")\n#&gt; [1] \"Intersezione con intersect():\"\nA_intersezione_B\n#&gt;   Dado1 Dado2\n#&gt; 1     6     6\n\nMetodo 2: Funzione merge()\nLa funzione base merge() esegue una join naturale sulle colonne con lo stesso nome:\n\nA_intersezione_B &lt;- merge(A, B)\nprint(\"Intersezione con merge():\")\n#&gt; [1] \"Intersezione con merge():\"\nA_intersezione_B\n#&gt;   Dado1 Dado2\n#&gt; 1     6     6\n\nMetodo 3: Pacchetto dplyr\nLa funzione inner_join() mantiene solo le righe presenti in entrambi i dataframe:\n\nA_intersezione_B &lt;- inner_join(A, B, by = c(\"Dado1\", \"Dado2\"))\nprint(\"Intersezione con dplyr:\")\n#&gt; [1] \"Intersezione con dplyr:\"\nA_intersezione_B\n#&gt;   Dado1 Dado2\n#&gt; 1     6     6\n\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) è stato generato algoritmicamente in R;\ngli eventi \\(A\\) e \\(B\\) sono stati definiti filtrando lo spazio campionario;\nl’intersezione \\(A \\cap B\\) corrisponde all’evento in cui entrambi i dadi mostrano un 6: \\(\\{(6, 6)\\}.\\)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#sec-probabilita",
    "href": "chapters/probability/02_probability_models.html#sec-probabilita",
    "title": "25  Modelli probabilistici",
    "section": "\n25.5 Probabilità",
    "text": "25.5 Probabilità\nIl terzo elemento fondamentale del modello probabilistico è la funzione di probabilità, che quantifica numericamente la possibilità di occorrenza degli eventi.\n\nDefinizione 25.3 Una probabilità \\(P\\) è una funzione \\(P: \\mathcal{F} \\to [0,1]\\) definita su una \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) di sottoinsiemi di \\(\\Omega\\). A ogni evento \\(A \\in \\mathcal{F}\\), la funzione assegna un valore reale compreso tra 0 e 1, rispettando i seguenti assiomi di Kolmogorov:\n\nNon-negatività. Per ogni \\(A \\subseteq \\Omega\\), si richiede che \\(0 \\leq P(A) \\leq 1\\).\nNormalizzazione (evento certo). \\(P(\\Omega) = 1\\).\n\nAdditività numerabile. Se \\(A_1, A_2, \\dots\\) sono eventi mutuamente esclusivi (cioè \\(A_i \\cap A_j = \\emptyset\\) per \\(i \\neq j\\)), allora:\n\\[\nP\\!\\Bigl(\\bigcup_{i=1}^{\\infty} A_i\\Bigr) \\;=\\; \\sum_{i=1}^{\\infty} P(A_i).\n\\]\n\n\nIn altre parole, una misura di probabilità non solo assegna numeri nell’intervallo \\([0,1]\\) a ogni evento, ma richiede che l’evento “certo” \\(\\Omega\\) abbia probabilità 1 e che la probabilità di un’unione numerabile di eventi disgiunti sia la somma delle loro probabilità. Queste condizioni garantiscono la coerenza formale e l’interpretazione intuitiva del concetto di probabilità.\n\n\n25.5.1 Interpretazione degli assiomi di Kolmogorov\n\nAssioma 1 (Non-negatività e limiti 0–1)\nLa probabilità di un evento è sempre un numero reale compreso tra 0 e 1. Se la probabilità è 0, l’evento può considerarsi impossibile; se è 1, l’evento è certo.Esempio: Nel lancio di un dado a sei facce, l’evento “Esce 7” non può verificarsi e ha probabilità 0, mentre l’evento “Esce un numero tra 1 e 6” ha probabilità 1.\nAssioma 2 (Evento certo)\nLo spazio campionario \\(\\Omega\\) è l’insieme di tutti i possibili esiti dell’esperimento. Poiché in ogni prova deve accadere almeno uno degli esiti contenuti in \\(\\Omega\\), la probabilità di \\(\\Omega\\) è necessariamente 1.Esempio: Nel lancio di un dado, lo spazio campionario \\(\\Omega\\) è \\(\\{1,2,3,4,5,6\\}\\). L’evento “esce un numero tra 1 e 6” coincide con l’intero spazio campionario, quindi \\(P(\\Omega) = 1\\).\n\nAssioma 3 (Additività per eventi incompatibili)\nSe due o più eventi sono mutuamente esclusivi (o incompatibili) — cioè non possono verificarsi contemporaneamente — la probabilità della loro unione è la somma delle probabilità di ciascuno.Esempio: Con un dado, l’evento “esce un numero pari” e l’evento “esce un numero dispari” non possono verificarsi nello stesso lancio. Di conseguenza,\n\\[\nP(\\text{“pari”} \\cup \\text{“dispari”}) \\;=\\; P(\\text{“pari”}) + P(\\text{“dispari”})\\,.\n\\]\n\n\nQuesti assiomi assicurano che la probabilità, intesa come funzione che assegna valori tra 0 e 1 a ogni evento, rispetti la coerenza matematica e l’interpretazione intuitiva: non esistono eventi “negativi” o “più che certi”, e la probabilità totale dell’intero spazio dei possibili risultati deve sempre essere uguale a 1.\n\n25.5.2 Proprietà fondamentali\nDagli assiomi di Kolmogorov discendono alcune proprietà fondamentali che descrivono come la probabilità si comporti in varie situazioni. Le principali sono elencate di seguito.\n\nTeorema 25.1 Siano \\(A\\) e \\(B\\) eventi qualsiasi nello spazio campionario \\(\\Omega\\). Allora valgono le seguenti relazioni:\n\nProbabilità dell’evento impossibile\\[\nP(\\emptyset) = 0.\n\\] Poiché l’insieme vuoto non include alcun esito sperimentale, non può mai verificarsi.\nMonotonicità\\[\nA \\subseteq B \\quad \\Longrightarrow \\quad P(A) \\le P(B).\n\\] Se un evento è interamente contenuto in un altro, non può avere probabilità maggiore dell’evento che lo comprende.\nProbabilità del complementare\\[\nP(A^c) = 1 - P(A).\n\\] Poiché \\(A\\) e il suo complementare \\(A^c\\) coprono l’intero spazio \\(\\Omega\\), la probabilità di \\(A^c\\) è la parte “rimanente” fino a 1.\nRegola dell’inclusione–esclusione\\[\nP(A \\cup B) \\;=\\; P(A) + P(B) \\;-\\; P(A \\cap B).\n\\] Per calcolare la probabilità dell’unione di due eventi qualsiasi, si sommano le probabilità di ciascun evento e si sottrae la probabilità della loro intersezione (altrimenti verrebbe conteggiata due volte).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#case-discreto-continuo",
    "href": "chapters/probability/02_probability_models.html#case-discreto-continuo",
    "title": "25  Modelli probabilistici",
    "section": "\n25.6 Spazi discreti e continui",
    "text": "25.6 Spazi discreti e continui\nLa natura dello spazio campionario determina come definiamo e calcoliamo le probabilità. Distinguiamo i due casi fondamentali: lo spazio campionario discreto\n\\[\n\\Omega = \\{a_1, a_2, \\dots, a_n\\} \\quad \\text{oppure} \\quad \\Omega = \\{a_1, a_2, \\dots\\}\n\\]\ne lo spazio campionario continuo\n\\[\n\\Omega = \\mathbb{R} .\n\\]\n\n25.6.1 Spazi campionari discreti\nCaratteristiche:\n\nGli esiti sono numerabili (finiti o infiniti ma separabili).\n\nEsempi:\n\nLancio di un dado: \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\).\n\nNumero di clienti in un negozio in un’ora: \\(\\Omega = \\{0, 1, 2, \\dots\\}\\).\n\n\n\nDefinizione di Probabilità:\n\n\nAssegniamo una probabilità puntuale \\(p_i \\geq 0\\) a ogni esito \\(\\omega_i\\), con:\n\\[\n\\sum_{\\text{tutti gli } i} p_i = 1 \\quad \\text{(normalizzazione)}.\n\\]\n\n\nLa probabilità di un evento \\(A\\) si ottiene sommando le probabilità degli esiti in \\(A\\):\n\\[\nP(A) = \\sum_{\\omega_i \\in A} p_i.\n\\]\n\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nLancio di un dado equilibrato.\n\nLa probabilità di ciascuna faccia è uniforme: \\(p_i = \\frac{1}{6}\\), con \\(i = 1, 2, \\dots, 6\\).\nConsideriamo l’evento \\(A = \\text{“Esce un numero pari\"}\\).\n\nPertanto, calcoliamo la probabilità di \\(A\\):\n\n\\[\nP(A) = p_2 + p_4 + p_6 = \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = \\frac{3}{6} = \\frac{1}{2}.\n\\]\nL’evento \\(A\\) ha dunque probabilità \\(\\frac{1}{2}\\).\n\n\n\n\n25.6.2 Spazi campionari continui\nCaratteristiche:\n\nGli esiti sono non numerabili (infiniti e “densi”).\n\nEsempi:\n\ntempo di attesa all’autobus: \\(\\Omega = [0, \\infty)\\);\n\naltezza di una persona: \\(\\Omega = [50\\, \\text{cm}, 250\\, \\text{cm}]\\).\n\n\n\nDefinizione di Probabilità:\n\nUsiamo una funzione di densità di probabilità (PDF) \\(f(x) \\geq 0\\), con:\\[\n\\int_{-\\infty}^{\\infty} f(x)\\, dx = 1 \\quad \\text{(normalizzazione)}.\n\\]\n\nLa probabilità di un evento \\(A\\) si ottiene integrando la PDF su \\(A\\):\\[\nP(A) = \\int_{A} f(x)\\, dx.\n\\]\n\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nMisurazione dell’altezza degli uomini adulti, modellata come variabile aleatoria continua \\(X\\) (in cm) con distribuzione normale \\(\\mathcal{N}(170, 7^2)\\) (si veda la Sezione Capitolo 37):\nLa funzione di densità (PDF) corrispondente è:\n\\[\nf(x)\n= \\frac{1}{7\\sqrt{2\\pi}} \\exp\\!\\Bigl(-\\frac{(x - 170)^2}{2 \\cdot 7^2}\\Bigr),\n\\quad\nX \\sim \\mathcal{N}(170,\\, 7^2).\n\\]\nEvento di interesse:\\[\nA = \\text{“Altezza compresa tra 160 cm e 180 cm”}.\n\\]\nCalcolo della probabilità:\nLa probabilità di \\(A\\) è l’area sotto la curva della densità tra 160 cm e 180 cm:\n\\[\nP(A) \\;=\\; \\int_{160}^{180} \\frac{1}{7\\sqrt{2\\pi}}\n\\exp\\!\\Bigl(-\\frac{(x - 170)^2}{98}\\Bigr)\\,\\mathrm{d}x.\n\\]\nIn alternativa, si può scrivere:\n\\[\nP(160 \\leq X \\leq 180) \\;\\approx\\; 0.847 \\quad (84.7\\%).\n\\]\nPiù avanti vedremo come calcolare facilmente questa probabilità tramite R, ad esempio con il comando:\n\npnorm(180, 170, 7) - pnorm(160, 170, 7)\n#&gt; [1] 0.847\n\nQuesto codice restituisce la differenza tra le funzioni di ripartizione (CDF) a 180 e a 160, corrispondente proprio all’area desiderata sotto la PDF.\n\n\n\n\n25.6.3 Confronto chiave\n\n\n\n\n\n\n\nCaratteristica\nSpazio Discreto\nSpazio Continuo\n\n\n\nEsiti\nNumerabili (es: 1, 2, 3)\nNon numerabili (es: intervalli)\n\n\nProbabilità di un singolo punto\n\n\\(P(\\{\\omega_i\\}) = p_i\\) (\\(\\geq\\) 0)\n\n\\(P(\\{x\\}) = 0\\) (sempre zero)\n\n\nStrumento matematico\nSomma \\(\\sum\\)\n\nIntegrale \\(\\int\\)\n\n\n\nEsempi comuni\nDadi, monete, conteggi\nMisure fisiche, tempi, temperature\n\n\n\n\n\n\n\n\n\nProprietà della PDF\n\n\n\n\nNegli spazi continui, la PDF non è una probabilità (può essere &gt; 1), ma la sua area sottesa su un intervallo fornisce la probabilità.\n\nPer eventi continui, ha senso solo calcolare probabilità su intervalli (es: \\(P(160 \\leq X \\leq 180)\\)).\n\n\n\n\n\n25.6.4 Dai concetti base alle proprietà fondamentali della probabilità\nAbbiamo visto come un esperimento casuale possa essere formalizzato matematicamente attraverso tre elementi chiave:\n\n\nSpazio campionario (\\(\\Omega\\)): l’insieme di tutti i possibili esiti dell’esperimento.\n\nEventi: sottoinsiemi di \\(\\Omega\\) che rappresentano combinazioni di esiti di interesse.\n\nProbabilità: una funzione \\(P\\) che assegna a ogni evento un valore numerico compreso tra 0 e 1, misurandone il grado di verosimiglianza.\n\nPartendo da queste definizioni, è possibile derivare proprietà essenziali per il calcolo e l’analisi probabilistica. Queste proprietà consentono di determinare la probabilità di eventi complessi a partire da eventi elementari e di stabilire relazioni logiche tra di essi.\nIn questo corso, approfondiremo quattro teoremi fondamentali:\n\nteorema della somma;\nteorema del prodotto;\nteorema della probabilità totale;\nteorema di Bayes.\n\nL’introduzione di operazioni sugli eventi (unione, intersezione, complemento) e delle proprietà della probabilità (teorema della somma, probabilità condizionata, teorema della probabilità totale, …) ci consente di costruire modelli probabilistici più complessi e applicabili a problemi reali.\nQui di seguito, approfondiamo il teorema della somma.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#teorema-della-somma",
    "href": "chapters/probability/02_probability_models.html#teorema-della-somma",
    "title": "25  Modelli probabilistici",
    "section": "\n25.7 Teorema della somma",
    "text": "25.7 Teorema della somma\nIl teorema della somma (o regola additiva) permette di determinare la probabilità che si verifichi almeno uno tra due eventi \\(A\\) e \\(B\\). La sua formulazione dipende dalla relazione tra i due eventi:\nCaso 1: Eventi Mutuamente Esclusivi. Se \\(A\\) e \\(B\\) non possono verificarsi insieme (ossia \\(A \\cap B = \\emptyset\\)), la probabilità dell’unione è la somma delle singole probabilità:\n\\[\nP(A \\cup B) = P(A) + P(B).\n\\tag{25.1}\\]\nCaso 2: Eventi Non Esclusivi. Se \\(A\\) e \\(B\\) possono coesistere, è necessario evitare di contare due volte la loro intersezione:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n\\tag{25.2}\\]\nPerché questa differenza?\nLa probabilità è una funzione d’insieme coerente con le operazioni insiemistiche. L’addizione diretta \\(P(A) + P(B)\\) conteggia due volte gli esiti comuni a \\(A\\) e \\(B\\) (rappresentati da \\(A \\cap B\\)). La sottrazione di \\(P(A \\cap B)\\) garantisce che ogni esito sia considerato una sola volta.\nIl teorema della somma sottolinea come le operazioni logiche tra eventi (unione, intersezione) si riflettano in relazioni algebriche tra le loro probabilità, fornendo uno strumento operativo per modellare scenari reali.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nIn uno studio sulla salute mentale, supponiamo di avere i seguenti dati relativi a un campione di partecipanti:\n\nla probabilità che un individuo soffra di ansia è \\(P(A) = 0.30\\);\n\nla probabilità che un individuo soffra di depressione è \\(P(B) = 0.25\\);\nla probabilità che un individuo soffra contemporaneamente di ansia e depressione è \\(P(A \\cap B) = 0.15\\).\n\nVogliamo calcolare la probabilità che un individuo soffra di almeno uno dei due disturbi (ansia o depressione), ovvero \\(P(A \\cup B)\\).\nUtilizziamo la regola della somma per eventi non mutuamente esclusivi:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\nSvolgiamo questo calcolo in R:\n\n# Definiamo le probabilità\nP_A &lt;- 0.30 # Probabilità di soffrire di ansia\nP_B &lt;- 0.25 # Probabilità di soffrire di depressione\nP_A_intersect_B &lt;- 0.15 # Probabilità di soffrire di entrambi i disturbi\n\n# Applichiamo la formula della regola della somma\nP_A_union_B &lt;- P_A + P_B - P_A_intersect_B\nP_A_union_B\n#&gt; [1] 0.4\n\nInterpretazione: il 40% dei partecipanti soffre di almeno uno tra ansia e depressione. L’intersezione \\(P(A \\cap B) = 0.15\\) è fondamentale, poiché senza sottrarla avremmo contato due volte i soggetti che soffrono contemporaneamente di entrambi i disturbi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#probabilità-calcolo-combinatorio-e-simulazioni",
    "href": "chapters/probability/02_probability_models.html#probabilità-calcolo-combinatorio-e-simulazioni",
    "title": "25  Modelli probabilistici",
    "section": "\n25.8 Probabilità, calcolo combinatorio e simulazioni",
    "text": "25.8 Probabilità, calcolo combinatorio e simulazioni\nIn molti problemi di probabilità, soprattutto quelli di taglio scolastico o introduttivo, si assume che ogni evento elementare abbia la stessa probabilità di verificarsi (equiprobabilità). In queste situazioni, il calcolo combinatorio risulta particolarmente utile per determinare la probabilità di un evento, poiché basta:\n\n\nDefinire gli eventi di successo: identificare tutte le configurazioni compatibili con l’evento di interesse.\n\n\nContare le possibilità: calcolare il numero di eventi di successo e rapportarlo al numero totale di eventi nello spazio campionario.\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nEstrazione di una pallina da un’urna\nSupponiamo di avere un’urna con 10 palline numerate da 1 a 10, da cui estraiamo una sola pallina in modo casuale. Assumendo che ogni pallina abbia la stessa probabilità di essere estratta, calcoliamo la probabilità di estrarre un numero pari.\n\n\nEventi di successo: \\(\\{\\;2, 4, 6, 8, 10\\}\\) (5 casi)\n\n\nEventi totali: \\(\\{\\;1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\}\\) (10 casi)\n\nLa probabilità cercata è quindi:\n\\[\nP(\\text{numero pari}) \\;=\\; \\frac{\\text{numero di eventi di successo}}{\\text{numero totale di eventi}}\n\\;=\\; \\frac{5}{10} \\;=\\; 0.5.\n\\]\n\n\n\nNelle applicazioni più complesse, come il calcolo della probabilità di ottenere una determinata combinazione di carte o il formare gruppi specifici partendo da una popolazione, utilizzeremo tecniche combinatorie più avanzate — ad esempio permutazioni e combinazioni (si veda la Sezione Appendice H) — che consentono di contare in modo sistematico gli eventi possibili e quelli di successo.\n\n25.8.1 Simulazioni Monte Carlo\nUno degli aspetti più impegnativi della probabilità è che molti problemi non si prestano a soluzioni immediate o intuitive. Per affrontarli, si possono adottare due approcci principali. Il primo consiste nell’applicare i teoremi della teoria della probabilità, un metodo rigoroso ma spesso controintuitivo. Il secondo approccio è quello della simulazione Monte Carlo, che permette di ottenere una soluzione approssimata, ma molto vicina al valore reale, seguendo una procedura più accessibile e intuitiva. Questo metodo prende il nome dal famoso Casinò di Monte Carlo a Monaco, anche se può essere semplicemente definito come “metodo di simulazione.”\nLa simulazione Monte Carlo appartiene a una classe generale di metodi stocastici che si contrappongono ai metodi deterministici. Questi metodi consentono di risolvere approssimativamente problemi analitici attraverso la generazione casuale delle quantità di interesse. Tra le tecniche comunemente utilizzate troviamo il campionamento con reinserimento, in cui la stessa unità può essere selezionata più volte, e il campionamento senza reinserimento, dove ogni unità può essere selezionata una sola volta. Questi strumenti rappresentano un mezzo potente e pratico per affrontare problemi complessi.\n\n\n\n\n\n\nIl problema dei complenni\n\n\n\n\n\nUn esempio classico di applicazione del metodo Monte Carlo è il calcolo delle probabilità relative a vari eventi definiti attraverso il modello dell’urna. Tra questi, abbiamo il celebre problema dei compleanni.\nIl problema dei compleanni esplora la probabilità che, in un gruppo di \\(n\\) persone, almeno due persone condividano la stessa data di nascita. Supponendo che i compleanni siano distribuiti uniformemente su 365 giorni (ignorando anni bisestili), il problema sorprende molte persone per il fatto che già con 23 persone la probabilità di una coincidenza è superiore al 50%.\n\n25.8.1.1 Soluzione analitica\nQuesto problema può essere risolto utilizzando il concetto di probabilità complementari. Infatti, il problema può essere visto da due prospettive complementari:\n\n\nCaso 1: tutti i compleanni sono diversi (nessuna persona condivide il compleanno con un’altra);\n\nCaso 2: almeno due persone condividono lo stesso compleanno.\n\nQuesti due casi sono mutuamente esclusivi (non possono verificarsi contemporaneamente) ed esaustivi (coprono tutte le possibilità). Pertanto, la somma delle loro probabilità deve essere uguale a 1:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nIn altre parole, per calcolare la probabilità che almeno due persone abbiano lo stesso compleanno, possiamo prima calcolare la probabilità che tutti i compleanni siano diversi e poi sottrarre questo valore da 1.\nCaso 1: probabilità che tutti i compleanni siano diversi.\nPer calcolare \\(P(\\text{nessun compleanno in comune})\\), seguiamo questo ragionamento:\n\nPrima persona: Può scegliere liberamente un giorno del calendario. Ci sono 365 possibilità (ignoriamo gli anni bisestili per semplicità).\nSeconda persona: Deve avere un compleanno diverso dalla prima persona. Quindi, ci sono 364 giorni disponibili.\nTerza persona: Deve avere un compleanno diverso dai primi due. Ci sono 363 giorni disponibili.\n\nQuesto processo continua fino alla \\(n\\)-esima persona, che avrà \\(365 - n + 1\\) giorni disponibili.\nLa probabilità che tutti i compleanni siano diversi si ottiene moltiplicando le probabilità individuali di ogni persona di avere un compleanno diverso dai precedenti. Poiché ogni scelta è indipendente, possiamo scrivere:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365}{365} \\cdot \\frac{364}{365} \\cdot \\frac{363}{365} \\cdot \\ldots \\cdot \\frac{365-n+1}{365}.\n\\]\nQuesto prodotto può essere espresso in forma compatta utilizzando il fattoriale:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-n)! \\cdot 365^n} ,\n\\]\ndove:\n\n\n\\(365!\\) è il fattoriale di 365 (il prodotto di tutti i numeri interi da 1 a 365).\n\n\\((365-n)!\\) è il fattoriale di \\(365 - n\\).\n\n\\(365^n\\) rappresenta tutte le possibili combinazioni di compleanni per \\(n\\) persone.\n\nCaso 2. Probabilità di almeno un compleanno in comune.\nOra che abbiamo calcolato la probabilità che tutti i compleanni siano diversi, possiamo trovare la probabilità che almeno due persone abbiano lo stesso compleanno come il complemento:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nSostituendo l’espressione precedente, otteniamo:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - \\frac{365!}{(365-n)! \\cdot 365^n}.\n\\]\nOra che abbiamo le formule per i due eventi complementari, come funzione di \\(n\\), applichiamole al caso specifico in cui \\(n\\) = 23. Questo è un valore interessante perché, come vedremo, la probabilità che almeno due persone su 23 condividano lo stesso compleanno supera il 50%.\nLa formula per la probabilità che tutti i compleanni siano diversi è:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-n)! \\cdot 365^n}.\n\\]\nPer \\(n = 23\\), sostituiamo il valore nella formula:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-23)! \\cdot 365^{23}}.\n\\]\nSemplifichiamo:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{342! \\cdot 365^{23}}.\n\\]\nUtilizzando R, troviamo:\n\n# Numero di persone\nn &lt;- 23\n\n# Calcolo della probabilità che tutti abbiano compleanni diversi\nnumeratore &lt;- prod(365:(365 - n + 1))\ndenominatore &lt;- 365^n\n\nP_diversi &lt;- numeratore / denominatore\nP_diversi  # stampa la probabilità\n#&gt; [1] 0.493\n\n\\[\nP(\\text{nessun compleanno in comune}) \\approx 0{,}4927.\n\\]\nCiò implica che la probabilità che 23 persone abbiano compleanni distinti sia approssimativamente 0.4927 (pari al 49.27%).\nLa probabilità che almeno due persone (su 23) condividano lo stesso compleanno corrisponde al complemento della probabilità appena calcolata:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nSostituendo il valore ottenuto:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - 0{.}4927 = 0{.}5073.\n\\]\nRisultato finale:\nCon \\(n = 23\\), la probabilità che almeno una coppia condivida il compleanno supera il 50%, attestandosi intorno a 0.5073 (50.73%). Questo esito è spesso sorprendente, poiché intuitivamente si tende a sottostimare l’effetto della combinatoria: sebbene 23 possano sembrare poche, le \\(\\binom{23}{2} = 253\\) possibili coppie rendono statisticamente probabile una corrispondenza.\n\n25.8.1.2 Soluzione con simulazione in R\nPer risolvere il problema tramite simulazione, possiamo generare gruppi casuali di \\(n\\) persone, assegnando loro un compleanno casuale tra 1 e 365. Per ogni gruppo, verifichiamo se almeno due persone condividono lo stesso compleanno.\nEcco il codice R:\n\n# Numero di simulazioni\nnum_simulazioni &lt;- 10000\n\n# Funzione per simulare il problema del compleanno\nsimula_compleanno &lt;- function(n) {\n  # Conta il numero di successi (almeno un compleanno in comune)\n  successi &lt;- 0\n\n  # Loop per il numero di simulazioni\n  for (i in 1:num_simulazioni) {\n    # Genera n compleanni casuali\n    compleanni &lt;- sample(1:365, n, replace = TRUE)\n\n    # Verifica se ci sono duplicati\n    if (any(duplicated(compleanni))) {\n      successi &lt;- successi + 1\n    }\n  }\n\n  # Calcola la probabilità stimata\n  return(successi / num_simulazioni)\n}\n\nProviamo con diversi valori di n.\n\nset.seed(123) # Fissiamo il seme per la riproducibilità\nrisultati &lt;- sapply(1:50, simula_compleanno)\n\n# Creiamo un data frame con i risultati\ndf &lt;- data.frame(\n  n = 1:50,\n  prob = risultati\n)\n\n# Creiamo il grafico\nggplot(df, aes(x = n, y = prob)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"blue\") +\n  geom_hline(yintercept = 0.5, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Numero di persone (n)\",\n    y = \"Probabilità stimata\",\n    title = \"Problema del Compleanno (Simulazione)\"\n  )\n\n\n\n\n\n\n\n\n\nSimulazioni: Per ogni gruppo di \\(n\\), si eseguono 10000 simulazioni, in cui si generano \\(n\\) compleanni casuali tra 1 e 365.\n\nDuplicati: La funzione duplicated() verifica se ci sono compleanni ripetuti.\n\nCalcolo della probabilità: La proporzione di simulazioni in cui si verifica almeno un compleanno condiviso rappresenta la probabilità stimata.\n\nVisualizzazione: Si tracciano le probabilità per diversi valori di \\(n\\), evidenziando il punto in cui la probabilità supera il 50%.\n\nRisultati attesi:\n\ncon circa 23 persone, la probabilità stimata sarà superiore a 0.5;\nil grafico mostra una curva crescente con un rapido aumento della probabilità per \\(n\\) piccoli e un asintoto vicino a 1 per \\(n\\) grandi.\n\nQuesto approccio permette di comprendere intuitivamente il problema e di verificare i risultati teorici con la simulazione.\n\n25.8.1.3 Assunzioni\nIl problema dei compleanni evidenzia non solo l’efficacia dell’approccio simulativo nel semplificare la soluzione rispetto all’analisi formale, ma anche l’importanza delle assunzioni che entrambi i metodi condividono. In questo caso, l’assunzione è che la probabilità di nascita sia uniformemente distribuita nei 365 giorni dell’anno — un’ipotesi semplificativa che non rispecchia la realtà.\nQuesto esempio sottolinea un principio fondamentale dei modelli probabilistici (e scientifici in generale): ogni modello si basa su un insieme di assunzioni che ne delimitano la validità e l’applicabilità. Valutare criticamente la plausibilità di tali assunzioni è dunque essenziale per garantire che il modello fornisca una rappresentazione utile del fenomeno studiato.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#riflessioni-conclusive",
    "href": "chapters/probability/02_probability_models.html#riflessioni-conclusive",
    "title": "25  Modelli probabilistici",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa teoria della probabilità fornisce un quadro rigoroso per descrivere e analizzare fenomeni caratterizzati dall’incertezza. In questo capitolo abbiamo introdotto i concetti fondamentali del calcolo delle probabilità, evidenziando come la modellazione matematica degli esperimenti casuali consenta di quantificare e prevedere eventi incerti. Abbiamo esplorato strumenti essenziali come la definizione di spazio campionario, la nozione di evento e le regole della probabilità, illustrando il loro utilizzo sia attraverso esempi teorici sia mediante simulazioni computazionali.\nUn aspetto cruciale della modellazione probabilistica è il ruolo delle assunzioni su cui si basano i modelli. Ogni modello probabilistico si fonda su ipotesi specifiche riguardanti la natura del fenomeno studiato e il modo in cui gli esiti vengono generati. Queste ipotesi determinano non solo la validità del modello, ma anche il tipo di risposte che esso può fornire. Ad esempio, nel problema del compleanno, abbiamo ipotizzato che i compleanni siano distribuiti in modo uniforme nei 365 giorni dell’anno. Sebbene questa assunzione semplifichi notevolmente i calcoli, sappiamo che nella realtà esistono fluttuazioni stagionali nelle nascite che possono influenzare le probabilità effettive.\nQuesto ci porta a una considerazione più ampia: la probabilità non è solo un insieme di formule, ma uno strumento per rappresentare l’incertezza e prendere decisioni informate. Tuttavia, l’accuratezza di qualsiasi modello probabilistico dipende strettamente dalla plausibilità delle ipotesi adottate. Modelli diversi, basati su ipotesi differenti, possono portare a risultati diversi, e l’interpretazione dei risultati deve sempre tenere conto di queste assunzioni.\nIn definitiva, lo studio della probabilità non si limita alla manipolazione di formule, ma richiede un’attenta riflessione sulla relazione tra modelli teorici e fenomeni reali. Una comprensione critica delle assunzioni alla base di un modello è essenziale per applicare correttamente i concetti probabilistici in contesti pratici, sia in ambito scientifico che nelle decisioni quotidiane.\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\n\n\nIl 92% delle persone sovrastima il numero necessario per la prima domanda e sottostima la seconda probabilità. Questo problema mostra come l’intuizione umana fallisca con eventi apparentemente “rari”.\n\nLa risposta è 23 persone.\nLa probabilità è \\(\\sim 0.7\\)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#esercizi",
    "href": "chapters/probability/02_probability_models.html#esercizi",
    "title": "25  Modelli probabilistici",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nQui di seguito sono presentati una serie di esercizi sbasati sulla Satisfaction with Life Scale (SWLS).\nEsercizi sullo Spazio Campionario e Eventi\n\n\nDefinizione dello Spazio Campionario\nSupponiamo che i punteggi della Satisfaction with Life Scale (SWLS) siano numeri interi compresi tra 5 e 35.\n\nQual è lo spazio campionario \\(\\Omega\\) per questo esperimento?\nSe hai raccolto i dati di 15 studenti, come potresti rappresentare lo spazio campionario con i loro punteggi osservati?\n\n\n\nDefinizione di un Evento\nConsideriamo l’evento A: “Uno studente ha un punteggio SWLS superiore a 25”.\n\nEsprimi l’evento A come un sottoinsieme dello spazio campionario.\nSe tra i 15 studenti osservati, 4 hanno punteggi superiori a 25, qual è la proporzione sperimentale per l’evento A?\n\n\n\nEventi Complementari\nDefiniamo l’evento B: “Uno studente ha un punteggio SWLS inferiore o uguale a 25”.\n\nScrivi l’evento B in relazione all’evento A.\nQual è la probabilità empirica di B, sapendo che 4 studenti hanno punteggi superiori a 25?\n\n\n\nEsercizi sulle Operazioni tra Eventi\n\n\nUnione di Eventi\nDefiniamo due eventi:\n\n\nA: “Il punteggio SWLS è superiore a 25”.\n\n\nC: “Il punteggio SWLS è inferiore a 15”.\n\nScrivi l’evento A ∪ C (“Lo studente ha un punteggio maggiore di 25 o minore di 15”).\nSe nel campione di 15 studenti, 4 studenti hanno punteggi superiori a 25 e 3 hanno punteggi inferiori a 15, qual è la proporzione empirica di A ∪ C?\n\n\n\nIntersezione di Eventi e Eventi Disgiunti\nSupponiamo che l’evento D sia: “Uno studente ha un punteggio pari a 20”.\n\nL’evento D e l’evento A sono disgiunti?\nSe nessuno degli studenti ha ottenuto esattamente 20, qual è la probabilità empirica di A ∩ D?\n\n\n\nEsercizi sulle Regole della Probabilità 6. Probabilità dell’Unione di Eventi\nSupponiamo di avere:\n\n\nP(A) = 0.3 (probabilità che un punteggio sia superiore a 25).\n\n\nP(C) = 0.2 (probabilità che un punteggio sia inferiore a 15).\n\n\nP(A ∩ C) = 0 (perché un punteggio non può essere contemporaneamente superiore a 25 e inferiore a 15).\n\nUsa la regola dell’unione per calcolare P(A ∪ C).\n\n\n\nProbabilità Condizionata\nConsideriamo:\n\n\nP(A) = 0.3 (probabilità che un punteggio sia superiore a 25).\n\n\nP(E) = 0.5 (probabilità che uno studente abbia più di 20 anni).\n\n\nP(A | E) = 0.4 (probabilità che un soggetto con più di 20 anni abbia un punteggio superiore a 25).\n\nUsa la formula della probabilità condizionata per calcolare P(A ∩ E).\n\n\n\nEsercizi su Permutazioni e Combinazioni\n\n\nSelezione Casuale di Studenti\nDal campione di 15 studenti, supponiamo di voler selezionare casualmente 3 studenti per partecipare a un’intervista sulla loro soddisfazione di vita.\n\nQuanti modi ci sono per selezionare 3 studenti su 15?\n\n\n\nOrdinare gli Studenti per Discussione\nSupponiamo di voler formare un piccolo gruppo di discussione con 3 studenti, scegliendoli in ordine di intervento.\n\nQuante diverse sequenze di 3 studenti possiamo ottenere?\n\n\nFormare Coppie di Studenti\nSe vogliamo formare coppie di studenti per un esercizio collaborativo, senza considerare l’ordine, quanti modi ci sono per farlo?\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Definizione dello Spazio Campionario\n\n\nLo spazio campionario \\(\\Omega\\) per questo esperimento è l’insieme di tutti i possibili punteggi della Satisfaction with Life Scale (SWLS), quindi:\n\\[ \\Omega = \\{5, 6, 7, ..., 35\\} \\]\n\nSe abbiamo raccolto i dati di 15 studenti con punteggi osservati \\(\\{27, 21, 15, 30, 18, 23, 26, 35, 20, 22, 19, 25, 32, 29, 28\\}\\), possiamo considerare \\(\\Omega\\) come questo insieme specifico.\n\n2. Definizione di un Evento\n\n\nL’evento \\(A\\) “Uno studente ha un punteggio SWLS superiore a 25” è il sottoinsieme:\n\\[ A = \\{27, 30, 26, 35, 32, 29, 28\\}\\]\n\n\nSe 7 studenti su 15 hanno punteggi superiori a 25, la probabilità empirica è:\n\\[ P(A) = \\frac{7}{15} = 0.467 \\]\n\n\n3. Eventi Complementari\n\n\nL’evento complementare \\(B\\) “Uno studente ha un punteggio SWLS inferiore o uguale a 25” è:\n\\[ B = \\{21, 15, 18, 23, 20, 22, 19, 25\\}\\]\n\n\nSe 8 studenti su 15 rientrano in \\(B\\), la probabilità empirica è:\n\\[ P(B) = 1 - P(A) = \\frac{8}{15} = 0.533 \\]\n\n\nSoluzioni agli Esercizi sulle Operazioni tra Eventi\n4. Unione di Eventi\n\n\nL’evento \\(A \\cup C\\) (“Lo studente ha un punteggio maggiore di 25 o minore di 15”) è:\n\\[ A \\cup C = \\{27, 30, 26, 35, 32, 29, 28, 15\\}\\]\n\n\nSe 8 studenti su 15 appartengono a \\(A \\cup C\\), la probabilità empirica è:\n\\[ P(A \\cup C) = \\frac{8}{15} = 0.533 \\]\n\n\n5. Intersezione di Eventi e Eventi Disgiunti\n\nL’evento \\(D\\) “Uno studente ha un punteggio pari a 20” è \\(D = \\{20\\}\\).\n\nL’evento \\(A \\cap D\\) è l’insieme degli elementi comuni a \\(A\\) e \\(D\\), ma \\(D\\) non ha elementi in \\(A\\), quindi:\n\\[ A \\cap D = \\emptyset \\]\n\nEssendo \\(A \\cap D = \\emptyset\\), gli eventi sono disgiunti e \\(P(A \\cap D) = 0\\).\n\nSoluzioni agli Esercizi sulle Regole della Probabilità\n6. Probabilità dell’Unione di Eventi\nUsiamo la formula:\n\\[ P(A \\cup C) = P(A) + P(C) - P(A \\cap C) \\]\nDato che \\(P(A \\cap C) = 0\\), abbiamo:\n\\[ P(A \\cup C) = 0.3 + 0.2 - 0 = 0.5 \\]\n7. Probabilità Condizionata\nLa probabilità congiunta \\(P(A \\cap E)\\) si calcola con:\n\\[ P(A \\cap E) = P(A | E) \\cdot P(E) \\]\nSostituendo i valori:\n\\[ P(A \\cap E) = 0.4 \\times 0.5 = 0.2 \\]\nSoluzioni agli Esercizi su Permutazioni e Combinazioni\n8. Selezione Casuale di Studenti\nIl numero di modi per scegliere 3 studenti su 15 (combinazioni) è:\n\\[ C_{15,3} = \\frac{15!}{3!(15-3)!} = \\frac{15!}{3!12!} = \\frac{15 \\times 14 \\times 13}{3 \\times 2 \\times 1} = 455 \\]\n9. Ordinare gli Studenti per Discussione\nIl numero di modi per scegliere e ordinare 3 studenti su 15 (disposizioni) è:\n\\[ D_{15,3} = \\frac{15!}{(15-3)!} = \\frac{15!}{12!} = 15 \\times 14 \\times 13 = 2730 \\]\n10. Formare Coppie di Studenti\nIl numero di modi per formare coppie (combinazioni di 2 studenti su 15) è:\n\\[ C_{15,2} = \\frac{15!}{2!(15-2)!} = \\frac{15 \\times 14}{2 \\times 1} = 105 \\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#bibliografia",
    "href": "chapters/probability/02_probability_models.html#bibliografia",
    "title": "25  Modelli probabilistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_sigma-algebra.html",
    "href": "chapters/probability/03_sigma-algebra.html",
    "title": "26  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "",
    "text": "Introduzione\nNel Capitolo 25 abbiamo visto come definire la probabilità su insiemi finiti, ossia in situazioni dove ci sono un numero limitato di esiti (ad esempio, i risultati di un lancio di dado). In quel contesto, la probabilità di ogni evento veniva spesso assegnata contando i casi favorevoli su quelli totali.\nTuttavia, in molti casi reali, lo spazio degli esiti non è finito, ma infinito (ad esempio, l’insieme degli interi, o addirittura la retta reale). In queste situazioni, la somma dei casi favorevoli su quelli totali non ha più senso o diventa tecnicamente inapplicabile. Per passare dal caso discreto a quello continuo, abbiamo quindi bisogno di strumenti più sofisticati.\nUno di questi strumenti è la \\(\\sigma\\)-algebra, che ci aiuta a definire in maniera rigorosa quali sottoinsiemi di uno spazio possiamo considerare “misurabili” e a cui possiamo assegnare una probabilità. In combinazione con gli assiomi di Kolmogorov, la \\(\\sigma\\)-algebra permette di estendere la teoria della probabilità dal caso discreto (discusso nel Capitolo 25) al caso continuo, dove la situazione è più delicata e non tutti i sottoinsiemi possono ricevere una probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_sigma-algebra.html#introduzione",
    "href": "chapters/probability/03_sigma-algebra.html#introduzione",
    "title": "26  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "",
    "text": "Panoramica del capitolo\n\nPerché non possiamo sempre “misurare tutto” nello spazio continuo.\nCome la \\(\\sigma\\)-algebra ci fornisce un metodo per assegnare le probabilità negli spazi continui.\nIn che modo la \\(\\sigma\\)-algebra sia cruciale per soddisfare gli assiomi di Kolmogorov.\nLe differenze principali rispetto al caso discreto.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Probability Models del testo di Chan & Kroese (2025).\nLeggere il capitolo Probability and counting di Introduction to Probability (Blitzstein & Hwang, 2019).\nLeggere il Appendice H.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(readr, lubridate, reshape2, VennDiagram)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_sigma-algebra.html#la-struttura-della-sigma-algebra",
    "href": "chapters/probability/03_sigma-algebra.html#la-struttura-della-sigma-algebra",
    "title": "26  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n26.1 La struttura della \\(\\sigma\\)-algebra",
    "text": "26.1 La struttura della \\(\\sigma\\)-algebra\nUna \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) su uno spazio campionario \\(\\Omega\\) è una collezione di sottoinsiemi (eventi) che soddisfa le seguenti proprietà.\n\nInclusione dello spazio campionario:\\[\n  \\Omega \\in \\mathcal{F}.\n  \\]\nSignifica che l’evento “qualcosa accade” è sempre misurabile.\nChiusura rispetto al complemento:\\[\n\\text{Se } A \\in \\mathcal{F} \\text{ allora } A^c = \\Omega \\setminus A \\in \\mathcal{F}.\n\\]\nSe possiamo misurare la probabilità di un evento, dobbiamo anche poter misurare la probabilità che l’evento non accada.\nChiusura rispetto a unioni (anche numerabili):\\[\n\\text{Se } A_1, A_2, \\dots \\in \\mathcal{F}, \\text{ allora } \\bigcup_{i=1}^{\\infty} A_i \\in \\mathcal{F}.\n\\]\nSe possiamo misurare una collezione (anche infinita) di eventi, dobbiamo poter misurare anche l’evento “almeno uno di essi si verifica”.\n\nTali proprietà non sono un semplice dettaglio tecnico, ma garantiscono la coerenza del sistema probabilistico: ci assicurano che certe operazioni sugli eventi (complementi, unioni) non producano risultati “senza senso” per la probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_sigma-algebra.html#relazione-tra-la-sigma-algebra-e-gli-assiomi-di-kolmogorov",
    "href": "chapters/probability/03_sigma-algebra.html#relazione-tra-la-sigma-algebra-e-gli-assiomi-di-kolmogorov",
    "title": "26  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n26.2 Relazione tra la \\(\\sigma\\)-algebra e gli assiomi di Kolmogorov",
    "text": "26.2 Relazione tra la \\(\\sigma\\)-algebra e gli assiomi di Kolmogorov\nL’introduzione della \\(\\sigma\\)-algebra è necessaria per garantire la coerenza del modello probabilistico. In sintesi:\n\nLa \\(\\sigma\\)-algebra delimita l’insieme degli eventi ammessi, ossia quegli insiemi per cui possiamo calcolare la probabilità.\nGli assiomi di Kolmogorov specificano le proprietà che la funzione di probabilità \\(P\\) deve rispettare su questi eventi.\nSenza la struttura di \\(\\sigma\\)-algebra, l’assioma di additività numerabile non sarebbe formulabile in modo rigoroso, poiché non avremmo garanzia che le operazioni di unione preservino l’appartenenza all’insieme degli eventi ammessi.\n\nIn conclusione, la costruzione formale della probabilità richiede non solo una funzione che assegni valori compresi tra 0 e 1 agli eventi, ma anche una struttura matematica che garantisca la coerenza di tali assegnazioni. La \\(\\sigma\\)-algebra assicura che ogni operazione insiemistica fondamentale per il calcolo della probabilità sia ben definita, permettendo agli assiomi di Kolmogorov di essere applicati senza ambiguità.\n\nEsempio 26.1 (Costruzione di una \\(\\sigma\\)-algebra discreta) Consideriamo lo spazio campionario discreto:\n\\[\n\\Omega = \\{1,2,3\\}.\n\\]\nDefinizione della \\(\\sigma\\)-algebra discreta. La \\(\\sigma\\)-algebra discreta corrisponde all’insieme di tutte le parti di \\(\\Omega\\), ovvero l’insieme di tutti i suoi sottoinsiemi:\n\\[\n\\mathcal{F} = \\bigl\\{\\varnothing, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\Omega \\bigr\\}.\n\\]\nVerifica delle proprietà della \\(\\sigma\\)-algebra. Per verificare che \\(\\mathcal{F}\\) sia effettivamente una \\(\\sigma\\)-algebra, controlliamo che soddisfi le seguenti proprietà:\n\n\nInclusione dell’insieme campionario e dell’insieme vuoto:\n\nPer definizione, \\(\\Omega \\in \\mathcal{F}\\) e \\(\\varnothing \\in \\mathcal{F}\\).\n\n\n\nChiusura rispetto ai complementi:\n\n\nSe un insieme \\(A\\) appartiene a \\(\\mathcal{F}\\), anche il suo complemento \\(A^c\\) rispetto a \\(\\Omega\\) deve appartenere a \\(\\mathcal{F}\\). Ad esempio:\n\nSe \\(\\{1,2\\} \\in \\mathcal{F}\\), allora \\(\\{1,2\\}^c = \\{3\\} \\in \\mathcal{F}\\).\nAnalogamente, per ogni altro sottoinsieme di \\(\\mathcal{F}\\) il complemento appartiene sempre a \\(\\mathcal{F}\\).\n\n\n\n\n\nChiusura rispetto alle unioni numerabili:\n\n\nNel caso discreto e finito, ogni unione di elementi in \\(\\mathcal{F}\\) appartiene ancora a \\(\\mathcal{F}\\). Ad esempio:\n\n\n\\(\\{1\\} \\cup \\{2\\} = \\{1,2\\} \\in \\mathcal{F}\\).\n\n\\(\\{1,3\\} \\cup \\{2\\} = \\{1,2,3\\} = \\Omega \\in \\mathcal{F}\\).\nPoiché \\(\\mathcal{F}\\) contiene tutti i possibili sottoinsiemi di \\(\\Omega\\), l’unione di qualsiasi collezione di elementi di \\(\\mathcal{F}\\) rimane in \\(\\mathcal{F}\\).\n\n\n\n\n\nInterpretazione intuitiva. Poiché ogni sottoinsieme di \\(\\Omega\\) appartiene a \\(\\mathcal{F}\\), tutti gli eventi possibili sono misurabili. Ad esempio:\n\nL’evento “esce 1 o 2” è rappresentato da \\(\\{1,2\\}\\).\nL’evento “non esce 3” è lo stesso evento \\(\\{1,2\\}\\), che è complementare a \\(\\{3\\}\\).\n\nEsempio di funzione di probabilità. Una possibile assegnazione di probabilità è quella di un dado equo a tre facce, dove ogni esito elementare ha la stessa probabilità:\n\\[\nP(\\{1\\}) = P(\\{2\\}) = P(\\{3\\}) = \\tfrac{1}{3}.\n\\]\nLe probabilità di eventi più complessi si ottengono sommando le probabilità degli esiti contenuti nell’evento:\n\\[\nP(\\{1,2\\}) = P(\\{1\\}) + P(\\{2\\}) = \\tfrac{1}{3} + \\tfrac{1}{3} = \\tfrac{2}{3}.\n\\]\nI valori fondamentali della funzione di probabilità rispettano gli assiomi di Kolmogorov:\n\\[\nP(\\Omega) = 1, \\quad P(\\varnothing) = 0.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_sigma-algebra.html#dal-discreto-al-continuo",
    "href": "chapters/probability/03_sigma-algebra.html#dal-discreto-al-continuo",
    "title": "26  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n26.3 Dal discreto al continuo",
    "text": "26.3 Dal discreto al continuo\nDopo aver introdotto il concetto di \\(\\sigma\\)-algebra e il suo ruolo negli assiomi di Kolmogorov, analizziamo le differenze essenziali tra il caso discreto e quello continuo.\n\n26.3.1 Caso discreto\nQuando lo spazio campionario \\(\\Omega\\) è finito o numerabile (ad esempio, \\(\\{1, 2, 3, \\dots\\}\\)), la \\(\\sigma\\)-algebra può coincidere con l’insieme di tutte le parti di \\(\\Omega\\). In questo contesto:\n\nOgni sottoinsieme di \\(\\Omega\\) è misurabile.\nGli eventi possono essere definiti in modo esplicito senza ambiguità.\nGli assiomi di Kolmogorov si applicano direttamente.\nLa probabilità di ogni singolo punto può essere positiva.\n\n26.3.2 Caso continuo\nQuando lo spazio campionario è un insieme non numerabile come \\(\\Omega = [0,1]\\) o \\(\\mathbb{R}\\), la costruzione della \\(\\sigma\\)-algebra diventa più complessa. Non è possibile includere tutti i sottoinsiemi di \\(\\Omega\\) senza generare contraddizioni logiche. Un esempio classico è il paradosso di Vitali, che mostra come alcuni insiemi non possano essere misurati in modo coerente.\n\n26.3.3 La \\(\\sigma\\)-algebra di Borel\nPer evitare tali problemi, nel caso continuo si utilizza la \\(\\sigma\\)-algebra di Borel, che include solo i sottoinsiemi “ben misurabili” di \\(\\Omega\\), escludendo quelli che potrebbero portare a incoerenze matematiche. Ad esempio:\n\nIntervalli del tipo \\([a,b]\\), \\((-\\infty, 0]\\).\nUnioni numerabili di intervalli.\nComplementi di insiemi misurabili.\n\nInvece, insiemi come quello di Vitali non sono inclusi nella \\(\\sigma\\)-algebra di Borel perché non ammettono una misura coerente.\nConfronto tra il caso discreto e il caso continuo.\n\n\n\n\n\n\n\nCaratteristica\nCaso Discreto\nCaso Continuo\n\n\n\nStruttura di \\(\\Omega\\)\nFinito o numerabile (\\(\\{1,2,3,\\dots\\}\\))\nNon numerabile (\\(\\mathbb{R}\\), \\([0,1]\\), ecc.)\n\n\n\\(\\sigma\\)-algebra naturale\nInsieme di tutte le parti di \\(\\Omega\\)\n\n\n\\(\\sigma\\)-algebra di Borel\n\n\nEsempio di evento\n\n\\(\\{\\omega\\}\\), \\(\\{\\omega_1, \\omega_2\\}\\)\n\n\n\\([a,b]\\), \\((-\\infty, 0]\\), unione di intervalli\n\n\nProbabilità di un singolo punto\nPuò essere \\(&gt;0\\) (ad es. \\(P(\\{\\omega\\})=1/6\\))\nGeneralmente \\(0\\) se il fenomeno è continuo\n\n\nProblemi di misurabilità\nNon presenti\nNecessaria selezione di insiemi misurabili\n\n\n\nIn sintesi, nel caso discreto, la costruzione della \\(\\sigma\\)-algebra è immediata: includere tutti i sottoinsiemi non crea difficoltà, portando alla cosiddetta \\(\\sigma\\)-algebra discreta (o triviale se \\(\\Omega\\) ha un solo elemento).\nNel caso continuo, invece, la costruzione è più delicata. Non tutti i sottoinsiemi possono essere inclusi nella \\(\\sigma\\)-algebra senza compromettere la coerenza matematica. Per questo motivo, si utilizza la \\(\\sigma\\)-algebra di Borel, che permette di definire correttamente la misura di probabilità evitando paradossi.\n\n\n\n\n\n\nCostruzione della \\(\\sigma\\)-algebra di Borel\n\n\n\n\n\nPer costruire la \\(\\sigma\\)-algebra di Borel in \\([0,1]\\) o in \\(\\mathbb{R}\\), si parte dagli intervalli e si aggiungono tutte le unioni e intersezioni numerabili di questi intervalli. Questa procedura genera la più piccola collezione di sottoinsiemi che soddisfa le proprietà di una \\(\\sigma\\)-algebra.\n\n\nInclusi: Intervalli aperti, chiusi, segmenti, unioni di segmenti, ecc.\n\nEsclusi: Strutture “patologiche” come l’insieme di Vitali, che non possono essere misurate in modo coerente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_sigma-algebra.html#riflessioni-conclusive",
    "href": "chapters/probability/03_sigma-algebra.html#riflessioni-conclusive",
    "title": "26  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo, abbiamo esplorato come la probabilità possa essere estesa dal caso discreto, dove possiamo tranquillamente lavorare con insiemi finiti, al caso continuo, dove ci si confronta con spazi infinitamente densi. Abbiamo compreso che, in questa transizione, la \\(\\sigma\\)-algebra gioca un ruolo cruciale, definendo quali sottoinsiemi sono “misurabili”, ovvero a quali possiamo assegnare una probabilità senza incappare in contraddizioni logiche o matematiche.\nAttraverso la formalizzazione delle \\(\\sigma\\)-algebre e l’applicazione degli assiomi di Kolmogorov, abbiamo stabilito le basi per un sistema probabilistico coerente e completo. Nel caso discreto, la costruzione della \\(\\sigma\\)-algebra è diretta, potendo includere tutti i sottoinsiemi di uno spazio campionario finito o numerabile. Tuttavia, nel caso continuo, abbiamo appreso che non tutti i sottoinsiemi possono essere misurati con coerenza. La \\(\\sigma\\)-algebra di Borel emerge come uno strumento essenziale per navigare questo terreno più complesso.\nLa distinzione tra il caso discreto e il continuo ci dimostra come la matematica possa affrontare con eleganza problemi di diversa natura. Nel discreto, ogni evento può avere una probabilità positiva e ogni sottoinsieme è misurabile. Nel continuo, invece, dobbiamo procedere con cautela, selezionando gli insiemi che possiamo “misurare” in modo coerente. In conclusione, la \\(\\sigma\\)-algebra non è soltanto un artificio tecnico, ma un elemento fondamentale che permette di costruire un ponte tra il discreto e il continuo, garantendo la coerenza della teoria della probabilità.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsidera i seguenti esercizi basati sulla Satisfaction with Life Scale (SWLS).\n\n\nQuali sottoinsiemi sono eventi ammissibili?\nSupponiamo che i punteggi SWLS raccolti siano numeri interi tra 5 e 35.\n\nTra i seguenti insiemi, quali potrebbero essere inclusi in una \\(\\sigma\\)-algebra su questo spazio campionario?\n\n\nA: Tutti gli studenti con punteggio pari o superiore a 25.\n\n\nB: Studenti con punteggio pari.\n\n\nC: Studenti con punteggio multiplo di 3.\n\n\nD: Studenti con punteggio superiore all’altezza media degli unicorni.\n\n\n\nQuale criterio potremmo usare per decidere se un insieme è ammissibile in una \\(\\sigma\\)-algebra?\n\n\n\nChiusura rispetto al complemento\nSe l’evento A rappresenta gli studenti con punteggio SWLS ≥ 25, quale sarà l’evento complementare Aᶜ?\n\nEsprimilo in termini di punteggi.\n\nSe il 40% degli studenti ha punteggi ≥ 25, qual è la probabilità empirica dell’evento Aᶜ?\n\n\n\nEsercizi sulle Operazioni tra Eventi 3. Unione di Eventi\nConsideriamo i seguenti eventi:\n\n\nB: “Studente ha un punteggio SWLS pari”.\n\n\nC: “Studente ha un punteggio multiplo di 3”.\n\nElenca i punteggi che appartengono a B ∪ C (cioè lo studente ha un punteggio pari o multiplo di 3).\n\nSe nel campione di 15 studenti, 8 hanno un punteggio in B e 5 in C, e 3 di essi appartengono a entrambi gli insiemi, calcola la probabilità empirica di B ∪ C usando la formula dell’unione.\n\n\n\nIntersezione e additività numerabile\n\nSe un evento D rappresenta gli studenti con punteggio ≥20 e ≤30, possiamo dire che è incluso nella \\(\\sigma\\)-algebra se B e C lo sono? Perché?\nCalcola l’intersezione B ∩ C e verifica se i dati raccolti rispettano l’additività.\n\n\n\nEsercizi sugli Assiomi di Kolmogorov 5. Assioma della Normalizzazione\n\nSupponiamo di assegnare probabilità a eventi definiti sui punteggi SWLS dei 15 studenti.\n\nSe la somma delle probabilità di tutti gli eventi possibili non è 1, cosa significa?\n\nDai un esempio di una distribuzione di probabilità su SWLS che rispetti la normalizzazione.\n\n\n\nAssioma dell’Additività\n\nSupponiamo che P(A) = 0.4 e P(Aᶜ) = 0.6.\n\nVerifica se questa distribuzione soddisfa l’assioma di Kolmogorov.\n\nSe introduciamo un terzo evento E (punteggi tra 15 e 20), come possiamo calcolare P(A ∪ E) rispettando gli assiomi?\n\n\n\nEsercizi su Spazi Misurabili e Applicazioni\n\n\nDefinire uno Spazio Misurabile\n\n\nConsideriamo lo spazio campionario \\(\\Omega\\) dei punteggi SWLS e la \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) formata dai sottoinsiemi:\n\n{Punteggi pari}\n\n{Punteggi multipli di 5}\n\n{Punteggi ≥ 25}\n\n\n\nQuesta collezione rispetta le condizioni di una \\(\\sigma\\)-algebra? Perché?\n\n\n\nEsempio di Probabilità in un Caso Continuo\n\nSe invece di punteggi discreti avessimo misurato il tempo di risposta a un questionario SWLS (espresso in secondi con valori reali), il modello discreto funzionerebbe?\n\nProva a descrivere un possibile evento misurabile in un caso continuo e spiega perché sarebbe più complesso da gestire rispetto al caso discreto.\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sottoinsiemi sono eventi ammissibili?\n\nGli insiemi che possono essere inclusi in una \\(\\sigma\\)-algebra devono essere chiusi rispetto a unioni, intersezioni e complementi.\n\nA (punteggi ≥ 25), B (punteggi pari), e C (punteggi multipli di 3) possono essere inclusi in una \\(\\sigma\\)-algebra, perché sono definiti su criteri chiari e permettono operazioni insiemistiche.\n\nD (punteggi superiori alla media degli unicorni) non è un evento misurabile, poiché dipende da valori soggettivi e non da una regola fissa applicabile all’intero spazio campionario.\n\n2. Chiusura rispetto al complemento\n\nL’evento complementare di A (punteggi ≥ 25) è Aᶜ (punteggi &lt; 25).\nSe la probabilità empirica di A è 0.4, la probabilità empirica di Aᶜ è: \\[ P(Aᶜ) = 1 - P(A) = 1 - 0.4 = 0.6 \\]\n\n\nSoluzioni agli Esercizi sulle Operazioni tra Eventi\n3. Unione di Eventi\n\nI punteggi in B sono {6, 8, 10, 12, …, 34} e quelli in C sono {6, 9, 12, …, 33}.\n\nB ∪ C è l’insieme {6, 8, 9, 10, 12, …, 34}.\nApplicando la formula dell’unione: \\[ P(B ∪ C) = P(B) + P(C) - P(B ∩ C) \\] \\[ P(B ∪ C) = \\frac{8}{15} + \\frac{5}{15} - \\frac{3}{15} = \\frac{10}{15} = 0.667 \\]\n\n\n4. Intersezione e additività numerabile\n\nL’evento D (20 ≤ SWLS ≤ 30) è un sottoinsieme di B ∪ C, quindi se B e C sono inclusi in una \\(\\sigma\\)-algebra, anche D lo sarà.\n\nB ∩ C (punteggi pari e multipli di 3) = {6, 12, 18, …}.\nDalla distribuzione empirica, P(B ∩ C) = \\(\\frac{3}{15} = 0.2\\).\n\nSoluzioni agli Esercizi sugli Assiomi di Kolmogorov\n5. Assioma della Normalizzazione\n\nSe la somma delle probabilità degli eventi possibili non è 1, significa che il sistema di probabilità è mal definito.\nEsempio corretto di distribuzione: \\[ P(A) = 0.4, P(B) = 0.3, P(Aᶜ) = 0.6, P(Bᶜ) = 0.7 \\] Tutti gli eventi coprono l’intero spazio campionario senza sovrapposizioni non gestite.\n\n6. Assioma dell’Additività\n\nSe P(A) = 0.4 e P(Aᶜ) = 0.6, allora: \\[ P(A) + P(Aᶜ) = 1 \\] Quindi gli assiomi di Kolmogorov sono rispettati.\nSe introduciamo un evento E (SWLS tra 15 e 20) con P(E) = 0.2, possiamo usare la formula dell’unione per calcolare P(A ∪ E) se A ed E non sono disgiunti.\n\nSoluzioni agli Esercizi su Spazi Misurabili e Applicazioni\n7. Definire uno Spazio Misurabile\n\nL’insieme \\(\\mathcal{F}\\) con {Punteggi pari, Punteggi multipli di 5, Punteggi ≥ 25} rispetta:\n\nInclusione di \\(\\Omega\\).\nChiusura rispetto al complemento.\nChiusura rispetto all’unione.\n\n\nQuindi è una \\(\\sigma\\)-algebra valida.\n\n8. Probabilità nel Caso Continuo\n\nSe misurassimo tempo di risposta al questionario SWLS in secondi (con valori reali), avremmo bisogno di una densità di probabilità anziché probabilità discrete.\nUn evento misurabile potrebbe essere: “Tempo di risposta compreso tra 10 e 15 secondi”.\nLa probabilità di un singolo valore (es. esattamente 12 secondi) sarebbe zero nel caso continuo.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] VennDiagram_1.7.3     futile.logger_1.4.3   reshape2_1.4.4       \n#&gt;  [4] lubridate_1.9.4       readr_2.1.5           pillar_1.11.0        \n#&gt;  [7] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt; [10] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [13] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [16] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [19] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [22] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [25] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [28] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] formatR_1.14          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       rmarkdown_2.29        tzdb_0.5.0           \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [28] RColorBrewer_1.1-3    estimability_1.5.1    knitr_1.50           \n#&gt; [31] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [34] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [37] abind_1.4-8           codetools_0.2-20      curl_7.0.0           \n#&gt; [40] pkgbuild_1.4.8        lattice_0.22-7        plyr_1.8.9           \n#&gt; [43] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [46] evaluate_1.0.5        lambda.r_1.2.4        survival_3.8-3       \n#&gt; [49] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [52] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [55] rprojroot_2.1.1       hms_1.1.3             rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           mvtnorm_1.3-3        \n#&gt; [64] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [67] cli_3.6.5             textshaping_1.0.3     futile.options_1.0.1 \n#&gt; [70] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [73] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [76] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [79] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_sigma-algebra.html#bibliografia",
    "href": "chapters/probability/03_sigma-algebra.html#bibliografia",
    "title": "26  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html",
    "href": "chapters/probability/04_conditional_prob.html",
    "title": "27  Probabilità condizionata",
    "section": "",
    "text": "Introduzione\nLa probabilità condizionata esprime la probabilità di un evento tenendo conto del verificarsi di un altro evento. Questo concetto è fondamentale perché riflette il modo in cui aggiorniamo le nostre credenze alla luce di nuove informazioni. Ad esempio, la probabilità che piova domani può essere diversa a seconda delle condizioni atmosferiche di oggi: osservare un cielo nuvoloso modifica la nostra valutazione della probabilità di pioggia. In questo senso, ogni nuova informazione può confermare, rafforzare o mettere in discussione le credenze preesistenti.\nLa probabilità condizionata ha un ruolo centrale non solo nella teoria della probabilità, ma anche nelle applicazioni quotidiane e scientifiche. In molti contesti, le probabilità sono implicitamente condizionate da informazioni preesistenti, anche quando non lo esplicitiamo formalmente. Comprendere e quantificare questo processo di aggiornamento delle credenze ci consente di gestire in modo più efficace l’incertezza, rendendo la probabilità uno strumento dinamico per la decisione e l’inferenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#introduzione",
    "href": "chapters/probability/04_conditional_prob.html#introduzione",
    "title": "27  Probabilità condizionata",
    "section": "",
    "text": "Panoramica del capitolo\n\nConcetti di probabilità congiunta, marginale e condizionata.\nApplicazione dei principi di indipendenza e probabilità condizionata.\nIl paradosso di Simpson;\nIl teorema del prodotto e della probabilità totale.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Conditional probability di Introduction to Probability (Blitzstein & Hwang, 2019).\nLeggere il capitolo Conditional Probability (Schervish & DeGroot, 2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "title": "27  Probabilità condizionata",
    "section": "\n27.1 Indipendenza stocastica",
    "text": "27.1 Indipendenza stocastica\nUn caso particolare di aggiornamento delle probabilità si verifica quando due eventi non si influenzano a vicenda. In tal caso, la probabilità congiunta di più eventi si calcola in modo molto più semplice, grazie alla proprietà di indipendenza.\n\n27.1.1 Indipendenza di due eventi\n\nDefinizione 27.1 Due eventi \\(A\\) e \\(B\\) si dicono indipendenti se la probabilità che si verifichino entrambi è uguale al prodotto delle probabilità dei singoli eventi:\n\\[\nP(A \\cap B) \\;=\\; P(A)\\, P(B).\n\\tag{27.1}\\]\n\nIn altre parole, sapere che \\(A\\) si è verificato non influisce sul valore di \\(P(B)\\), e viceversa. Quando questa condizione è soddisfatta, si scrive \\(A \\perp B\\) per indicare l’indipendenza dei due eventi.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nSupponiamo di lanciare due monete distinte e di considerare i seguenti eventi:\n\n\n\\(A\\) = “La prima moneta mostra Testa”\n\n\n\\(B\\) = “La seconda moneta mostra Testa”\n\nPoiché il risultato della prima moneta non influisce in alcun modo su quello della seconda, i due eventi sono indipendenti. In particolare, la probabilità di ottenere “Testa” su una moneta è:\n\\[\nP(A) \\;=\\; P(B) \\;=\\; \\frac{1}{2}.\n\\]\nLa probabilità che entrambe le monete mostrino Testa (cioè che si verifichino contemporaneamente gli eventi \\(A\\) e \\(B\\)) è data dal prodotto delle loro probabilità:\n\\[\nP(A \\cap B) \\;=\\; P(A)\\,P(B)\n\\;=\\; \\frac{1}{2} \\times \\frac{1}{2}\n\\;=\\; \\frac{1}{4}.\n\\]\nPoiché questa relazione è soddisfatta, possiamo concludere che \\(A\\) e \\(B\\) sono eventi indipendenti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-di-un-insieme-di-eventi",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-di-un-insieme-di-eventi",
    "title": "27  Probabilità condizionata",
    "section": "\n27.2 Indipendenza di un insieme di eventi",
    "text": "27.2 Indipendenza di un insieme di eventi\nIl concetto di indipendenza non si limita a due soli eventi, ma può estendersi a un insieme arbitrario di eventi. In generale, diciamo che \\(\\{A_i : i \\in I\\}\\) è un insieme di eventi indipendente se, per ogni sottoinsieme finito \\(J \\subseteq I\\), la probabilità dell’intersezione degli eventi in \\(J\\) coincide con il prodotto delle probabilità di ciascun evento:\n\\[\nP \\Bigl(\\bigcap_{i \\in J} A_i\\Bigr)\n\\;=\\;\n\\prod_{i \\in J} P(A_i).\n\\tag{27.2}\\]\nQuesta condizione richiede che ogni combinazione di eventi presenti la stessa proprietà di non influenzarsi a vicenda. L’indipendenza può essere:\n\nun’assunzione semplificante in molti modelli (ad esempio, ipotizzare che le variabili di un questionario misurino proprietà “indipendenti” dei partecipanti);\n\nuna caratteristica empirica emersa dai dati, da verificare attraverso analisi apposite.\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nConsideriamo una sequenza di tre lanci di una moneta equilibrata e definiamo gli eventi:\n\n\n\\(A_1\\) = “Il primo lancio mostra Testa”.\n\n\\(A_2\\) = “Il secondo lancio mostra Testa”.\n\n\\(A_3\\) = “Il terzo lancio mostra Testa”.\n\nCiascuno di questi eventi ha probabilità \\(1/2\\). Poiché ogni lancio non influenza gli altri, l’insieme \\(\\{A_1, A_2, A_3\\}\\) è indipendente nel senso più ampio: non solo \\(P(A_1 \\cap A_2) = P(A_1)P(A_2)\\) e simili per coppie, ma vale anche\n\\[\nP(A_1 \\cap A_2 \\cap A_3)\n\\;=\\;\nP(A_1)\\,P(A_2)\\,P(A_3)\n\\;=\\;\n\\left(\\tfrac12\\right)\\left(\\tfrac12\\right)\\left(\\tfrac12\\right)\n\\;=\\;\n\\tfrac18.\n\\]\nIn effetti, per qualunque combinazione di Testa e Croce (ad esempio, “Testa al primo e terzo lancio, Croce al secondo”), la probabilità risulta sempre il prodotto delle probabilità dei singoli esiti, confermando l’indipendenza.\n\n\n\n\n27.2.1 Quando gli eventi non sono indipendenti\nSe per due eventi \\(A\\) e \\(B\\) si ha \\(P(A \\cap B) \\neq P(A) P(B)\\), essi non sono indipendenti. In tal caso, conoscere l’esito di uno fornisce informazioni sul probabile verificarsi dell’altro, e occorre tenere conto di questa dipendenza nei calcoli (ad esempio, usando la probabilità condizionata).\n\n27.2.2 Differenza tra indipendenza ed eventi disgiunti\nUn errore frequente è confondere “indipendenti” con “disgiunti (o mutuamente esclusivi)”. Due eventi sono disgiunti se non possono avvenire contemporaneamente, cioè\n\\[\nP(A \\cap B) \\;=\\; 0.\n\\]\nSe \\(P(A)&gt;0\\) e \\(P(B)&gt;0\\) e gli eventi sono disgiunti, non possono essere indipendenti. Infatti, l’indipendenza richiederebbe\n\\[\nP(A \\cap B) \\;=\\; P(A)\\,P(B),\n\\]\nma, poiché \\(P(A \\cap B)=0\\) e \\(P(A) P(B)\\) sarebbe positivo, la relazione non può valere. Quindi, la disgiunzione implica l’esclusione reciproca, mentre l’indipendenza significa che la probabilità di uno non risente in alcun modo dell’altro.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nNel lancio di un dado a sei facce:\n\n\n\\(C\\) = “Esce un numero pari” \\(\\{\\;2,4,6\\}\\).\n\n\\(D\\) = “Esce un numero dispari” \\(\\{\\;1,3,5\\}\\).\n\nI due eventi sono disgiunti, poiché un numero non può essere contemporaneamente pari e dispari; dunque \\(P(C \\cap D)=0\\).\nTuttavia, non sono indipendenti: se lo fossero, si dovrebbe avere \\(P(C \\cap D) = P(C)P(D)\\). Invece,\n\\[\n0 \\;\\neq\\; \\tfrac12 \\,\\times\\, \\tfrac12 \\;=\\; \\tfrac14,\n\\]\nda cui segue che \\(C\\) e \\(D\\) non sono eventi indipendenti.\n\n\n\nIn sintesi, gli eventi disgiunti non possono verificarsi insieme, mentre gli eventi indipendenti non influiscono uno sulla probabilità dell’altro. Entrambe le proprietà sono importanti ma rispondono a concetti nettamente diversi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#probabilità-condizionata",
    "href": "chapters/probability/04_conditional_prob.html#probabilità-condizionata",
    "title": "27  Probabilità condizionata",
    "section": "\n27.3 Probabilità condizionata",
    "text": "27.3 Probabilità condizionata\nLa probabilità condizionata esprime la probabilità di un evento \\(A\\) una volta che si sappia che un altro evento \\(B\\) è già avvenuto.\n\nDefinizione 27.2 Se \\(P(B) &gt; 0\\), si definisce:\n\\[\nP(A \\mid B)\n\\;=\\;\n\\frac{P(A \\cap B)}{P(B)}.\n\\tag{27.3}\\]\n\nQuesta formula può essere letta come un “ricalcolo” della probabilità di \\(A\\) limitandosi al sottoinsieme di esiti in cui \\(B\\) è vero.\n\n27.3.1 Interpretazione della probabilità condizionata\nLa probabilità condizionata funge da meccanismo di aggiornamento delle nostre conoscenze. Inizialmente, si dispone di una stima di \\(P(A)\\); dopo aver appreso che un evento correlato \\(B\\) si è verificato, si “restringe” il campo agli esiti compatibili con \\(B\\) e si riassegna la probabilità di \\(A\\) su questa base.\n\n\nEsempio intuitivo: Se si sa che una persona ha la febbre (\\(B\\)), la probabilità che abbia l’influenza (\\(A\\)) aumenta rispetto a quella calcolata sull’intera popolazione.\n\nQuesta capacità di “aggiornare le credenze” fa della probabilità condizionata uno strumento fondamentale in:\n\n\ninferenze statistiche, per gestire informazioni parziali o acquisite progressivamente;\n\n\nteoria dell’apprendimento, quando si valutano ipotesi o modelli a fronte di nuovi dati;\n\n\nmodellizzazione delle dipendenze tra eventi, in cui la conoscenza di un evento influenza la probabilità di un altro.\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nLanciamo due dadi equilibrati consecutivamente. Dato che la somma dei dadi è 10, qual è la probabilità che uno dei due dadi mostri un 6?\nDefiniamo:\n\n\nB come l’evento che la somma sia 10:\\[ B = \\{(4, 6), (5, 5), (6, 4)\\}. \\]\n\n\nA come l’evento che uno dei due dadi mostri un 6:\\[ A = \\{(1, 6), \\dots, (5, 6), (6, 1), \\dots, (6, 5)\\}. \\]\n\n\nL’intersezione tra A e B è:\\[ A \\cap B = \\{(4, 6), (6, 4)\\}. \\]\nPoiché in questo esperimento tutti gli eventi elementari sono equiprobabili, la probabilità condizionata \\(P(A | B)\\) è data da:\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{\\frac{2}{36}}{\\frac{3}{36}} = \\frac{2}{3}.\n\\]\nQuindi, la probabilità che uno dei due dadi mostri un 6, sapendo che la somma è 10, è \\(\\frac{2}{3}\\).\n\n\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nSomma di due dadi\nConsideriamo il lancio di due dadi equilibrati e calcoliamo la probabilità che la somma dei punteggi risulti minore di 8.\n\n\nSenza informazioni aggiuntive\n\nOgni dado può assumere valori da 1 a 6, per un totale di 36 possibili combinazioni \\((6 \\times 6)\\).\n\nTra queste 36, esistono 21 combinazioni in cui la somma è minore di 8.\n\nDunque la probabilità iniziale è: \\[\nP(\\text{Somma} &lt; 8)\n\\;=\\;\n\\frac{21}{36}\n\\;\\approx\\; 0{.}58.\n\\]\n\n\n\n\nCon informazione aggiuntiva\nSupponiamo di sapere che la somma uscita è dispari. Questa nuova informazione restringe lo spazio degli esiti possibili:\n\nSolo 18 combinazioni su 36 producono un risultato dispari.\n\nTra queste 18, 12 combinazioni hanno somma minore di 8.\n\nPertanto, la probabilità condizionata diventa: \\[\nP(\\text{Somma} &lt; 8 \\,\\mid\\, \\text{Somma dispari})\n\\;=\\;\n\\frac{12}{18}\n\\;=\\;\n0{.}67.\n\\]\n\n\n\n\nConfrontando i due risultati (\\(0{,}58\\) senza informazioni contro \\(0{,}67\\) con l’informazione “somma dispari”), osserviamo come la probabilità di un evento possa cambiare una volta ottenuta un’informazione aggiuntiva.\nCodice in R.\nNel codice R che segue, utilizziamo l’insieme di tutte le combinazioni di lanci per verificare numericamente i risultati:\n\n# 1. Definiamo i possibili valori di un dado\nr &lt;- 1:6  \n\n# 2. Costruiamo tutte le combinazioni possibili (i, j)\n#    in cui i e j vanno da 1 a 6.\n#    In totale ci aspettiamo 36 combinazioni (6 x 6).\nsample &lt;- expand.grid(i = r, j = r)  \nnrow(sample)  # Contiamo quante sono: dovrebbero essere 36\n#&gt; [1] 36\n\n# 3. Selezioniamo solo le coppie (i, j) in cui la somma è minore di 8.\n#    Verifichiamo quante sono e le confrontiamo con il totale.\nevent &lt;- subset(sample, i + j &lt; 8)\ncat(nrow(event), \"/\", nrow(sample), \"\\n\")  # Dovrebbe stampare 21 / 36\n#&gt; 21 / 36\n\n# 4. Selezioniamo ora solo le coppie con somma dispari.\n#    %% è l’operatore \"modulo\": (i + j) %% 2 != 0 verifica se la somma è dispari.\nsample_odd &lt;- subset(sample, (i + j) %% 2 != 0)\nnrow(sample_odd)  # Dovrebbe essere 18\n#&gt; [1] 18\n\n# 5. Calcoliamo quante coppie hanno somma minore di 8 tra quelle con somma dispari.\nevent_odd &lt;- subset(sample_odd, i + j &lt; 8)\ncat(nrow(event_odd), \"/\", nrow(sample_odd), \"\\n\")  # Dovrebbe stampare 12 / 18\n#&gt; 12 / 18\n\nSecondo la Equazione 27.3, se definiamo\n\n\n\\(A\\) = “Somma &lt; 8”\n\n\n\\(B\\) = “Somma dispari”,\n\nallora \\(P(A \\cap B) = 12/36\\) e \\(P(B) = 18/36\\). Di conseguenza,\n\\[\nP(A \\mid B)\n\\;=\\;\n\\frac{P(A \\cap B)}{P(B)}\n\\;=\\;\n\\frac{12/36}{18/36}\n\\;=\\;\n\\frac{12}{18}\n\\;=\\;\n0{.}67.\n\\]\nQuesto esempio dimostra come la probabilità condizionata consenta di aggiornare la stima di un evento alla luce di nuove informazioni.\n\n\n\n\n\n\n\n\n\nScreening per la diagnosi precoce del tumore mammario\n\n\n\n\n\nSupponiamo di utilizzare un test diagnostico con le seguenti caratteristiche:\n\n\nSensibilità (probabilità di test positivo fra le donne malate): 90%.\n\n\nSpecificità (probabilità di test negativo fra le donne sane): 90%.\n\n\nPrevalenza (percentuale di donne effettivamente malate nella popolazione): 1%.\n\n1. Esempio con 1000 donne.\nPer semplificare i calcoli, immaginiamo di sottoporre a screening 1000 donne a caso:\n\n\nDonne malate (1%): 10 su 1000.\n\nCon una sensibilità del 90%, circa 9 di queste 10 donne avranno un esito positivo al test (vere positive).\n\nCirca 1 donna avrà invece un risultato negativo (falso negativo).\n\n\n\nDonne sane (99%): 990 su 1000.\n\nCon una specificità del 90%, circa 891 di queste 990 risulteranno negative al test (vere negative).\n\nLe restanti 99 donne avranno un esito positivo (false positive).\n\n\n\nQuesto ci permette di costruire uno schema riassuntivo (spesso rappresentato sotto forma di tabella o diagramma a blocchi):\n\n\npositive: \\(9\\) (vere positive) + \\(99\\) (false positive) = 108,\n\n\nnegative: \\(1\\) (falso negativo) + \\(891\\) (vero negativo) = 892.\n\n2. Probabilità non condizionata di un test positivo.\nLa probabilità che una donna, scelta a caso, risulti positiva allo screening (indipendentemente dal fatto che sia malata o sana) si ottiene rapportando il numero di test positivi al totale:\n\\[\nP(\\text{Test positivo})\n\\;=\\;\n\\frac{108}{1000}\n\\;=\\;\n0{.}108\n\\;\\; (10{.}8\\%).\n\\]\nQuesta è una probabilità non condizionata, in quanto considera l’intera popolazione delle 1000 donne, senza ulteriori informazioni.\n3. Probabilità condizionata di essere malate dato un test positivo.\nCi interessa ora sapere: Se una donna ha appena ricevuto un risultato positivo, qual è la probabilità che abbia davvero il cancro al seno?\nMatematicamente, riformuliamo la domanda come:\\[\nP(\\text{Cancro} \\mid \\text{Test positivo}).\n\\]\nOsservando il nostro esempio di 1000 donne:\n\nAbbiamo 108 test positivi in tutto.\n\nSolo 9 di questi test positivi provengono effettivamente da donne malate.\n\nPertanto,\n\\[\nP(\\text{Cancro} \\mid \\text{Test positivo})\n\\;=\\;\n\\frac{9}{108}\n\\;=\\;\n0{.}083\n\\;\\; (8{.}3\\%).\n\\]\nQuesta è una probabilità condizionata, poiché riguarda soltanto quelle donne già selezionate in base all’esito positivo del test.\n4. Confronto fra probabilità non condizionata e condizionata.\n\n\nProbabilità non condizionata (esito positivo): \\(0{.}108\\) (10.8%).\n\n\nProbabilità condizionata (avere un tumore, sapendo che il test è positivo): \\(0{.}083\\) (8.3%).\n\nNotiamo come l’informazione aggiuntiva (“il test è risultato positivo”) riduca il numero di casi osservati, focalizzando l’attenzione su un sottoinsieme della popolazione. In altre parole, la conoscenza di un test positivo aggiorna la nostra stima della probabilità di avere la malattia, mostrandoci che, nonostante l’alta sensibilità e specificità, la maggior parte dei test positivi riguarda donne sane (false positive), a causa della bassa prevalenza (1%).\nQuesto esempio illustra in modo tangibile la distinzione fra:\n\n\nprobabilità non condizionata: la probabilità di un evento considerando l’intera popolazione,\n\n\nprobabilità condizionata: la probabilità di un evento una volta appresa un’informazione aggiuntiva (qui, l’esito positivo del test).\n\nQuesta differenza è fondamentale nell’interpretazione dei test diagnostici, specialmente quando la malattia è relativamente rara.\n\n\n\n\n\n\n\n\n\nIl Problema di Monty Hall\n\n\n\n\n\nIl problema di Monty Hall è un famoso quesito di teoria della probabilità che illustra in modo efficace il concetto di probabilità condizionata. Questo problema è diventato celebre grazie a una rubrica tenuta da Marilyn vos Savant nella rivista Parade, in cui rispose a una lettera pubblicata il 9 settembre 1990:\n\n“Supponiamo di partecipare a un quiz televisivo e di dover scegliere tra tre porte. Dietro una di esse c’è un’auto, mentre dietro le altre due ci sono delle capre. Scegli una porta, ad esempio la numero 1, e il conduttore, che sa cosa c’è dietro ogni porta, ne apre un’altra, diciamo la numero 3, rivelando una capra. A questo punto, ti chiede se vuoi cambiare la tua scelta e passare alla porta numero 2. È vantaggioso cambiare porta?” Craig. F. Whitaker, Columbia, MD\n\nLa situazione descritta ricorda quella del popolare quiz televisivo degli anni ’70 Let’s Make a Deal, condotto da Monty Hall e Carol Merrill. Marilyn vos Savant rispose che il concorrente dovrebbe cambiare porta, poiché la probabilità di vincere l’auto raddoppia passando da 1/3 a 2/3. Tuttavia, la sua risposta suscitò un acceso dibattito, con molte persone, inclusi alcuni matematici, che sostenevano che cambiare porta non avrebbe offerto alcun vantaggio. Questo episodio ha reso il problema di Monty Hall uno dei più famosi esempi di come l’intuizione possa portare a conclusioni errate in ambito probabilistico.\nChiarire il Problema.\nLa lettera originale di Craig Whitaker è piuttosto vaga, quindi per analizzare il problema in modo rigoroso è necessario fare alcune ipotesi:\n\n\nPosizione dell’auto: L’auto è nascosta in modo casuale ed equiprobabile dietro una delle tre porte.\n\nScelta iniziale del giocatore: Il giocatore sceglie una porta in modo casuale, indipendentemente dalla posizione dell’auto.\n\nAzione del conduttore: Dopo la scelta del giocatore, il conduttore apre una delle due porte rimanenti, rivelando una capra, e offre al giocatore la possibilità di cambiare porta.\n\nScelta del conduttore: Se il conduttore ha la possibilità di scegliere tra due porte (entrambe con capre), ne apre una in modo casuale.\n\nCon queste assunzioni, possiamo rispondere alla domanda: Qual è la probabilità che il giocatore vinca l’auto se decide di cambiare porta?\nDi seguito, esploreremo tre metodi per risolvere il problema di Monty Hall: il diagramma ad albero, l’analisi delle probabilità e una simulazione.\nMetodo 1: diagramma ad albero.\nIl diagramma ad albero è uno strumento utile per visualizzare tutti i possibili esiti di un esperimento probabilistico. Nel caso del problema di Monty Hall, possiamo suddividere il processo in tre fasi:\n\n\nPosizione dell’auto: L’auto può trovarsi dietro una delle tre porte (A, B o C), ciascuna con probabilità 1/3.\n\nScelta del giocatore: Il giocatore sceglie una porta in modo casuale, indipendentemente dalla posizione dell’auto.\n\nAzione del conduttore: Il conduttore apre una delle due porte rimanenti, rivelando una capra.\n\nIl diagramma ad albero mostra tutte le possibili combinazioni di questi eventi. Ad esempio, se l’auto è dietro la porta A e il giocatore sceglie la porta B, il conduttore aprirà la porta C (l’unica porta rimanente con una capra).\nPasso 1: Identificare lo spazio campionario\nLo spazio campionario è composto da 12 esiti possibili, rappresentati dalle combinazioni di:\n\nPosizione dell’auto (A, B, C).\nScelta iniziale del giocatore (A, B, C).\nPorta aperta dal conduttore (una delle due rimanenti con una capra).\n\nEcco un diagramma ad albero che rappresenta questa situazione:\n\n\n\n\n\nFigura 27.1: Il diagramma ad albero per il Problema di Monty Hall mostra le probabilità associate a ogni possibile esito. I pesi sugli archi rappresentano la probabilità di seguire quel particolare percorso, dato che ci troviamo nel nodo padre. Ad esempio, se l’auto si trova dietro la porta A, la probabilità che il giocatore scelga inizialmente la porta B è pari a 1/3. La colonna più a destra del diagramma mostra la probabilità di ciascun esito finale. Ogni probabilità di esito è calcolata moltiplicando le probabilità lungo il percorso che parte dalla radice (auto dietro una certa porta) e termina alla foglia (esito finale) (Figura tratta da Lehman, Leighton e Meyer, 2018).\n\n\nPasso 2: Definire l’evento di interesse\nL’evento di interesse è “il giocatore vince cambiando porta”. Questo si verifica quando la porta inizialmente scelta dal giocatore non nasconde l’auto, e il giocatore decide di cambiare porta.\nGli esiti che soddisfano questa condizione sono:\n\n(Auto A, Scelta B, Apertura C)\n(Auto A, Scelta C, Apertura B)\n(Auto B, Scelta A, Apertura C)\n(Auto B, Scelta C, Apertura A)\n(Auto C, Scelta A, Apertura B)\n(Auto C, Scelta B, Apertura A)\n\nQuesti esiti sono in totale 6.\nPasso 3: Calcolare le probabilità degli esiti\nOgni esito ha una probabilità specifica, calcolata moltiplicando le probabilità lungo il percorso nel diagramma ad albero.\nEsempio di calcolo per l’esito (Auto A, Scelta B, Apertura C):\n\nLa probabilità che l’auto sia dietro la porta A è \\(\\frac{1}{3}\\).\nLa probabilità che il giocatore scelga la porta B è \\(\\frac{1}{3}\\).\nLa probabilità che il conduttore apra la porta C (che contiene una capra) è \\(1\\) (poiché il conduttore deve aprire una porta con una capra, e la porta C è l’unica possibile).\n\nLa probabilità totale per questo esito è:\n\\[\nP(\\text{Auto A, Scelta B, Apertura C}) = \\frac{1}{3} \\times \\frac{1}{3} \\times 1 = \\frac{1}{9}.\n\\]\nProcedendo in modo simile per tutti gli altri esiti, otteniamo le probabilità per tutti i 12 esiti.\nPasso 4: Calcolare la probabilità dell’evento\nLa probabilità di vincere cambiando porta è la somma delle probabilità degli esiti favorevoli.\n\\[\n\\begin{aligned}\nP&(\\text{vincere cambiando porta}) = \\notag \\\\\n&\\quad P(\\text{Auto A, Scelta B, Apertura C}) + P(\\text{Auto A, Scelta C, Apertura B}) + \\notag\\\\  \n&\\quad P(\\text{Auto B, Scelta A, Apertura C}) + \\dots \\notag\n\\end{aligned}\n\\]\n\\[\n= \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} = \\frac{6}{9} = \\frac{2}{3}.\n\\]\nLa probabilità di vincere mantenendo la scelta originale è il complemento:\n\\[\nP(\\text{vincere mantenendo la scelta}) = 1 - P(\\text{vincere cambiando porta}) = 1 - \\frac{2}{3} = \\frac{1}{3}.\n\\]\nLa conclusione è che il giocatore ha una probabilità di vincere pari a \\(\\frac{2}{3}\\) se cambia porta, contro una probabilità di \\(\\frac{1}{3}\\) se mantiene la sua scelta iniziale. Cambiare porta è quindi la strategia vincente.\nMetodo 2: analisi delle probabilità.\nIl problema di Monty Hall può essere chiarito analizzando i tre scenari possibili, immaginando di essere osservatori esterni che sanno cosa si nasconde dietro ogni porta:\n\n\nPrimo scenario:\n\nIl giocatore sceglie inizialmente la porta con una capra (chiamiamola “capra 1”).\n\nIl conduttore apre l’altra porta con la “capra 2”.\n\nSe il giocatore cambia porta, vince l’automobile.\n\n\n\nSecondo scenario:\n\nIl giocatore sceglie inizialmente la porta con l’altra capra (“capra 2”).\n\nIl conduttore apre la porta con la “capra 1”.\n\nSe il giocatore cambia porta, vince l’automobile.\n\n\n\nTerzo scenario:\n\nIl giocatore sceglie inizialmente la porta con l’automobile.\n\nIl conduttore apre una delle due porte con una capra (non importa quale).\n\nSe il giocatore cambia porta, perde l’automobile.\n\n\n\nAll’inizio del gioco, il giocatore ha:\n\n\n1/3 di probabilità di scegliere l’automobile.\n\n\n2/3 di probabilità di scegliere una capra.\n\nDopo la scelta iniziale, il conduttore apre una porta con una capra, ma questa azione non altera le probabilità iniziali. Il giocatore si trova quindi con due porte chiuse: quella scelta inizialmente e una rimanente.\n\nSe il giocatore ha scelto l’automobile inizialmente (1/3 di probabilità), cambiando porta perde.\n\nSe il giocatore ha scelto una capra inizialmente (2/3 di probabilità), cambiando porta vince l’automobile.\n\nIn sintesi, cambiando porta, il giocatore ha 2/3 di probabilità di vincere l’automobile, mentre mantenendo la scelta iniziale ha solo 1/3 di probabilità. Pertanto, la strategia migliore è cambiare porta per massimizzare le possibilità di vittoria.\nMetodo 3: simulazione.\nPer confermare il risultato, possiamo eseguire una simulazione. Ripetendo il gioco migliaia di volte, possiamo confrontare la frequenza con cui il giocatore vince cambiando porta rispetto a quando mantiene la scelta iniziale.\nEcco un esempio di codice in R per la simulazione:\n\n# Numero di simulazioni da effettuare.\n# Più è grande B, più precisa sarà la stima.\nB &lt;- 10000  \n\n# Definiamo una funzione \"monty_hall\" che\n# a) simula un gioco\n# b) restituisce TRUE/FALSE a seconda che il giocatore vinca l'auto o no.\nmonty_hall &lt;- function(strategy){\n  \n  # 1. Dichiariamo le porte possibili, in forma di stringhe.\n  doors &lt;- c(\"1\", \"2\", \"3\")\n  \n  # 2. Stabiliamo dove si trova il premio (auto) e le capre.\n  #    \"prize\" sarà un vettore con dentro \"car\" per la porta con l’auto \n  #    e \"goat\" per quelle con la capra.\n  #    La funzione sample() crea una distribuzione casuale di \"car\" e \"goat\".\n  prize &lt;- sample(c(\"car\", \"goat\", \"goat\"))\n  \n  # 3. Troviamo qual è la porta che ha la macchina.\n  prize_door &lt;- doors[ prize == \"car\" ]\n  \n  # 4. Il giocatore fa la sua prima scelta, pescando a caso fra le 3 porte.\n  my_pick &lt;- sample(doors, 1)\n  \n  # 5. Il conduttore deve aprire una porta che:\n  #    - non sia la mia (my_pick)\n  #    - non abbia la macchina (prize_door)\n  #    Così facendo, rivela una porta con la capra.\n  #    Se ci sono due porte con capra, ne sceglie una a caso.\n  show &lt;- sample(doors[!doors %in% c(my_pick, prize_door)], 1)\n  \n  # 6. La strategia \"stick\" significa: RESTARE sulla scelta iniziale (my_pick).\n  #    La strategia \"switch\" significa: CAMBIARE porta, passando a quella\n  #    rimasta tra le due che NON sono state aperte.\n  stick &lt;- my_pick\n  switch &lt;- doors[!doors %in% c(my_pick, show)]\n  \n  # 7. Se la strategia scelta (in input) è \"stick\", la mia scelta finale è \"stick\".\n  #    Altrimenti, è \"switch\".\n  final_choice &lt;- ifelse(strategy == \"stick\", stick, switch)\n  \n  # 8. La funzione restituisce TRUE se la scelta finale coincide con la porta premiata,\n  #    altrimenti FALSE.\n  return(final_choice == prize_door)\n}\n\nNel codice qui sopra:\n\n\nmy_pick è la porta che il giocatore sceglie subito.\n\nshow è la porta che il conduttore mostra, rivelando la capra.\n\nstick rimane la scelta iniziale (quindi è my_pick).\n\nswitch è la porta che rimane fra le non aperte e non scelte inizialmente.\n\nAl termine, la funzione monty_hall() stabilisce se, con la strategia considerata, si vince (TRUE) o si perde (FALSE).\n\n# Simuliamo B volte la strategia \"stick\" (non cambiare mai la scelta iniziale).\nstick_results &lt;- replicate(B, monty_hall(\"stick\"))\n\n# stick_results è un vettore di TRUE/FALSE lungo B.\n# Per scoprire la percentuale di vittorie, calcoliamo la media dei TRUE.\nmean(stick_results)\n#&gt; [1] 0.336\n\n\n# Simuliamo B volte la strategia \"switch\" (cambiare sempre la scelta iniziale).\nswitch_results &lt;- replicate(B, monty_hall(\"switch\"))\n\n# Anche qui, calcoliamo la media per sapere quante volte abbiamo vinto l’auto.\nmean(switch_results)\n#&gt; [1] 0.666\n\n\nLa media di un vettore di TRUE/FALSE in R è pari alla frazione di TRUE.\nIn questo modo, mean(stick_results) ci dice la probabilità di vincere restando sulla scelta iniziale.\n\nmean(switch_results) ci dice la probabilità di vincere se si cambia sempre porta dopo l’intervento del conduttore.\n\nRisultati attesi:\n\n\nMantenere la Scelta Iniziale: La frequenza di vittoria dovrebbe essere circa 1/3 (33.3%).\n\nCambiare Porta: La frequenza di vittoria dovrebbe essere circa 2/3 (66.6%).\n\nLa simulazione conferma che cambiare porta aumenta la probabilità di vincere da 1/3 a 2/3, dimostrando che la strategia ottimale nel problema di Monty Hall è quella di cambiare porta dopo che il conduttore ha rivelato una capra.\nIn sintesi, il problema di Monty Hall mette in luce come l’intuizione possa trarci in inganno quando ci confrontiamo con scenari probabilistici. Attraverso l’uso del diagramma ad albero, un’analisi delle probabilità e l’esecuzione di simulazioni, abbiamo dimostrato che cambiare porta raddoppia le possibilità di vincita, facendole passare da 1/3 a 2/3. Questo risultato, in apparente contrasto con ciò che potrebbe sembrare intuitivo, costituisce un esempio emblematico dell’importanza di adottare un approccio formale nella valutazione delle probabilità, anziché affidarsi esclusivamente a impressioni iniziali che spesso si rivelano fuorvianti.\n\n\n\n\n\n\n\n\n\nIl paradosso di Simpson\n\n\n\n\n\nNel contesto della probabilità condizionata, un fenomeno particolarmente interessante e, al tempo stesso, controintuitivo è il paradosso di Simpson. Questo paradosso si verifica quando una tendenza osservata in diversi gruppi di dati separati scompare o addirittura si inverte una volta che i gruppi vengono combinati.\nIl paradosso di Simpson evidenzia l’importanza di considerare le variabili confondenti e di analizzare i dati con grande attenzione per evitare di trarre conclusioni errate o fuorvianti. È un esempio emblematico di come l’interpretazione dei dati statistici richieda non solo strumenti matematici, ma anche una profonda comprensione del contesto e delle relazioni tra le variabili coinvolte.\nUn caso storico di paradosso di Simpson riguarda l’applicazione della pena di morte negli Stati Uniti (Radelet & Pierce, 1991). Questo studio analizza 674 processi per omicidio in Florida tra il 1976 e il 1987, esaminando l’influenza della razza dell’imputato e della vittima sulla probabilità di ricevere la pena di morte. I dati riportano il numero di condannati alla pena di morte in base alla razza dell’imputato e della vittima:\n\n\n\n\n\n\n\n\n\nRazza dell’imputato\nRazza della vittima\nPena di morte\nNo pena di morte\nTasso di condanna\n\n\n\nBianco\nBianco\n19\n132\n19 / 151 ≈ 12.6%\n\n\nBianco\nNero\n11\n52\n11 / 63 ≈ 17.5%\n\n\nNero\nBianco\n6\n37\n6 / 43 ≈ 14.0%\n\n\nNero\nNero\n1\n9\n1 / 10 = 10.0%\n\n\n\nSe analizziamo i dati separatamente per la razza della vittima, emerge che la probabilità di ricevere la pena di morte è più alta per gli imputati bianchi rispetto agli imputati neri, sia nei casi in cui la vittima era bianca (12.6% vs 14.0%) sia nei casi in cui la vittima era nera (17.5% vs 10.0%).\nTuttavia, quando i dati vengono aggregati senza tenere conto della razza della vittima, si osserva una tendenza opposta:\n\n\n\n\n\n\n\n\nRazza dell’imputato\nPena di morte\nNo pena di morte\nTasso di condanna\n\n\n\nBianco\n30\n184\n30 / 214 ≈ 14.0%\n\n\nNero\n7\n46\n7 / 53 ≈ 13.2%\n\n\n\nAggregando i dati, sembra che gli imputati neri abbiano meno probabilità di ricevere la pena di morte rispetto agli imputati bianchi (13.2% vs 14.0%).\nQuesta apparente contraddizione è il risultato del paradosso di Simpson. La variabile confondente in questo caso è la razza della vittima: gli omicidi con vittime bianche avevano una probabilità molto più alta di portare alla pena di morte rispetto agli omicidi con vittime nere. Poiché gli imputati bianchi erano più spesso accusati di aver ucciso vittime bianche (per cui la probabilità di pena di morte era maggiore), il loro tasso di condanna complessivo risultava più alto. Viceversa, gli imputati neri erano più spesso accusati di aver ucciso vittime nere (per cui la probabilità di pena di morte era inferiore), abbassando il loro tasso di condanna complessivo.\nQuesto caso dimostra come l’aggregazione dei dati senza considerare una variabile confondente (in questo caso, la razza della vittima) possa portare a una conclusione errata e fuorviante. È essenziale analizzare i dati in modo stratificato per evitare interpretazioni distorte e per comprendere i reali meccanismi sottostanti un fenomeno.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-e-probabilità-condizionata",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-e-probabilità-condizionata",
    "title": "27  Probabilità condizionata",
    "section": "\n27.4 Indipendenza e probabilità condizionata",
    "text": "27.4 Indipendenza e probabilità condizionata\nL’indipendenza tra due eventi \\(A\\) e \\(B\\) può essere interpretata intuitivamente attraverso la probabilità condizionata. Due eventi sono indipendenti se il verificarsi di uno non influenza la probabilità di verificarsi dell’altro. In altre parole, conoscere che \\(B\\) è accaduto non modifica la probabilità di \\(A\\), e viceversa.\nQuesta relazione può essere formalizzata con le seguenti equazioni:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = P(B).\n\\]\nPertanto, \\(A\\) e \\(B\\) sono indipendenti se e solo se:\n\\[\nP(A \\mid B) = P(A),\n\\]\n\\[\nP(B \\mid A) = P(B).\n\\]\nQueste condizioni significano che la probabilità di \\(A\\) non cambia, indipendentemente dal fatto che \\(B\\) sia accaduto, e lo stesso vale per \\(B\\).\n\n27.4.1 Indipendenza di tre eventi\nLa definizione di indipendenza si estende naturalmente a tre eventi \\(A\\), \\(B\\), e \\(C\\), ma con condizioni aggiuntive. Tre eventi sono indipendenti se:\n\n\nOgni coppia di eventi è indipendente:\n\\[\n\\begin{aligned}\nP(A \\cap B) &= P(A) P(B), \\\\\nP(A \\cap C) &= P(A) P(C), \\\\\nP(B \\cap C) &= P(B) P(C).\n\\end{aligned}\n\\]\n\n\nLa probabilità congiunta di tutti e tre gli eventi è uguale al prodotto delle loro probabilità individuali:\n\\[\nP(A \\cap B \\cap C) = P(A) P(B) P(C).\n\\]\n\n\nLe prime tre condizioni verificano l’indipendenza a coppie (indipendenza a due a due), mentre l’ultima condizione garantisce che i tre eventi siano completamente indipendenti. È importante notare che l’indipendenza a due a due non implica necessariamente l’indipendenza completa: per essere indipendenti nel senso completo, tutte e quattro le condizioni devono essere soddisfatte.\nIn sintesi, l’indipendenza tra eventi implica che il verificarsi di uno di essi non fornisce alcuna informazione sulla probabilità del verificarsi degli altri. Nel caso di due eventi, questa proprietà si traduce nell’invarianza della probabilità condizionata. Per tre o più eventi, l’indipendenza richiede sia l’indipendenza a coppie sia la condizione più forte sull’intersezione di tutti gli eventi.\nQuesti concetti sono fondamentali nella probabilità e nella statistica, poiché semplificano molti calcoli e forniscono una base per modelli più complessi.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nIndipendenza tra Eventi in un Mazzo di Carte\nScenario 1: Mazzo Completo (52 Carte)\nConsideriamo un mazzo standard di 52 carte. Ogni seme (picche, cuori, quadri, fiori) contiene 13 carte, e nel mazzo ci sono 4 Regine in totale. Definiamo i seguenti eventi:\n\n\n\\(A\\) = “Pescare una carta di picche”,\n\n\n\\(B\\) = “Pescare una carta Regina”.\n\n\nProbabilità di \\(A\\). Poiché ci sono 13 picche in un mazzo di 52 carte, \\[\nP(A) = \\frac{13}{52} = \\frac{1}{4}.\n\\]\nProbabilità di \\(B\\). Ci sono 4 Regine su 52 carte, quindi \\[\nP(B) = \\frac{4}{52} = \\frac{1}{13}.\n\\]\nProbabilità congiunta \\(P(A \\cap B)\\). L’unica carta che è contemporaneamente “picche” e “Regina” è la Regina di picche, perciò: \\[\nP(A \\cap B) = \\frac{1}{52}.\n\\]\n\nPer verificare l’indipendenza di \\(A\\) e \\(B\\), confrontiamo \\(P(A \\cap B)\\) con \\(P(A)\\,P(B)\\):\n\\[\nP(A)\\,P(B)\n= \\frac{1}{4} \\times \\frac{1}{13}\n= \\frac{1}{52},\n\\] \\[\nP(A \\cap B)\n= \\frac{1}{52}.\n\\]\nPoiché \\(P(A \\cap B) = P(A)\\,P(B)\\), i due eventi sono indipendenti quando il mazzo è completo.\nScenario 2: Mazzo Ridotto (51 Carte)\nOra rimuoviamo una carta qualunque dal mazzo — ad esempio il “2 di quadri” — portando il totale a 51 carte. Notiamo che la Regina di picche non è stata rimossa, ma il cambio di composizione potrebbe comunque influire sulle probabilità.\n\nProbabilità di \\(A \\cap B\\). Poiché la Regina di picche è ancora presente, pescare quella carta specifica ha ora probabilità \\[\nP(A \\cap B) = \\frac{1}{51}.\n\\]\nProbabilità di \\(A\\). Il seme di picche non è stato modificato (restano 13 picche), ma il denominatore è passato a 51 carte: \\[\nP(A) = \\frac{13}{51}.\n\\]\nProbabilità di \\(B\\). Nel mazzo restano ancora 4 Regine (nessuna è stata rimossa), su 51 carte totali: \\[\nP(B) = \\frac{4}{51}.\n\\]\nProdotto \\(P(A)\\,P(B)\\). Calcolando: \\[\nP(A)\\,P(B)\n= \\frac{13}{51} \\times \\frac{4}{51}\n= \\frac{52}{2601}.\n\\]\n\nConfrontando:\n\\[\nP(A \\cap B)\n= \\frac{1}{51},\n\\quad\\text{mentre}\\quad\nP(A)\\,P(B)\n= \\frac{52}{2601}.\n\\]\nSi verifica che\n\\[\n\\frac{1}{51}\n\\;\\neq\\;\n\\frac{52}{2601}.\n\\]\nPertanto, \\(A\\) e \\(B\\) non sono più indipendenti nel mazzo ridotto.\nIn sintesi, questo esempio mostra come l’indipendenza tra due eventi dipenda dal contesto:\n\ncon un mazzo completo (52 carte), “pescare picche” e “pescare una Regina” sono eventi indipendenti;\nbasta rimuovere una carta qualunque (anche non correlata direttamente a “picche” o “Regine”) perché le probabilità cambino e gli stessi eventi cessino di essere indipendenti.\n\nIn altre parole, ogni modifica alla composizione del mazzo può influire sulle probabilità dei singoli eventi e, di conseguenza, sulle loro relazioni di dipendenza o indipendenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#teorema-del-prodotto",
    "href": "chapters/probability/04_conditional_prob.html#teorema-del-prodotto",
    "title": "27  Probabilità condizionata",
    "section": "\n27.5 Teorema del prodotto",
    "text": "27.5 Teorema del prodotto\nA partire dalla definizione di probabilità condizionata, possiamo derivare quello che viene chiamato Teorema del Prodotto, noto anche come teorema della probabilità composta, regola moltiplicativa o regola della catena. Questo risultato permette di esprimere la probabilità congiunta di due o più eventi come il prodotto di probabilità condizionate.\n\n27.5.1 Caso di due eventi\nPer due eventi \\(A\\) e \\(B\\), il Teorema del Prodotto asserisce che:\n\\[\nP(A \\cap B)\n\\;=\\;\nP(B) \\,\\cdot\\, P(A \\mid B)\n\\;=\\;\nP(A) \\,\\cdot\\, P(B \\mid A).\n\\tag{27.4}\\]\nIn altre parole, la probabilità che \\(A\\) e \\(B\\) si verifichino contemporaneamente può essere calcolata in due modi equivalenti:\n\n\nprimo modo: prendi la probabilità di \\(B\\), quindi moltiplicala per la probabilità di \\(A\\), sapendo già che \\(B\\) è accaduto;\n\nsecondo modo: prendi la probabilità di \\(A\\), quindi moltiplicala per la probabilità di \\(B\\), sapendo già che \\(A\\) è accaduto.\n\nL’ordine degli eventi in cui si applica la condizione è arbitrario, a patto di rispettare la formula e scegliere la condizione corrispondente.\n\n27.5.2 Generalizzazione a \\(n\\) eventi\nIl Teorema del Prodotto si estende naturalmente al caso di più di due eventi. Se consideriamo \\(n\\) eventi \\(A_1, A_2, \\dots, A_n\\), e assumiamo che\n\\[\nP(A_1 \\cap A_2 \\cap \\cdots \\cap A_{n-1}) \\;&gt;\\; 0,\n\\]\nallora la probabilità che tutti questi eventi si verifichino è data da:\n\\[\n\\begin{aligned}\nP(A_1 \\,\\cap\\, A_2 \\,\\cap\\, \\cdots \\,\\cap\\, A_n)\n&= P(A_1)\n\\;\\times\\; P(A_2 \\mid A_1)\n\\;\\times\\; P(A_3 \\mid A_1 \\cap A_2)\n\\;\\times\\; \\cdots \\\\\n&\\quad \\cdots \\times\\; P(A_n \\mid A_1 \\cap A_2 \\cap \\cdots \\cap A_{n-1}).\n\\end{aligned}\n\\tag{27.5}\\]\nIn pratica, ciascun fattore si ottiene considerando la probabilità dell’evento successivo, condizionata sul verificarsi di tutti gli eventi precedenti. Questa formulazione è cruciale, ad esempio, nelle analisi di sequenze di eventi o in modelli statistici in cui le probabilità vengono “aggiornate” gradualmente mano a mano che si verificano nuove condizioni.\nIl Teorema del Prodotto rappresenta uno dei fondamenti teorici più importanti della probabilità e trova applicazioni in numerosi contesti, quali:\n\nla modellazione di processi sequenziali o temporali;\nla scomposizione di problemi complessi in calcoli più semplici e gestibili;\nla teoria delle reti bayesiane e l’analisi della probabilità condizionata.\n\nGrazie a questo teorema, è possibile affrontare problemi complessi suddividendoli in passaggi progressivi, in cui ogni probabilità condizionata contribuisce alla costruzione della soluzione complessiva in maniera sistematica.\n\n27.5.2.1 Procedura di calcolo\nPer applicare la regola:\n\n\nparti dal primo evento: usa la probabilità incondizionata \\(P(A_1)\\);\n\n\ncondiziona progressivamente: moltiplica per \\(P(A_2 \\mid A_1)\\), poi per \\(P(A_3 \\mid A_1 \\cap A_2)\\), e così via;\n\ntermina con l’ultimo evento: includi \\(P(A_n \\mid A_1 \\cap \\cdots \\cap A_{n-1})\\).\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nDa un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento: “esce una pallina bianca alla \\(i\\)-esima estrazione” e con \\(N_i\\) l’estrazione di una pallina nera. L’evento: “escono due palline bianche nelle prime due estrazioni” è rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l’Equazione 27.4, la sua probabilità vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche, per l’Equazione 27.5, vale\n\\[\n\\begin{aligned}\nP(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\\n&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\\n&= \\frac{1}{6}.\n\\end{aligned}\n\\]\nLa probabilità dell’estrazione di tre palline nere è invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\\n&= \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#teorema-della-probabilità-totale",
    "href": "chapters/probability/04_conditional_prob.html#teorema-della-probabilità-totale",
    "title": "27  Probabilità condizionata",
    "section": "\n27.6 Teorema della probabilità totale",
    "text": "27.6 Teorema della probabilità totale\nIl Teorema della Probabilità Totale — anche detto legge della probabilità totale — permette di calcolare la probabilità di un evento \\(A\\) scomponendola rispetto a una partizione di sottoinsiemi che coprono l’intero spazio campionario. È particolarmente utile quando si affrontano situazioni con più scenari, categorie o gruppi nei quali ripartire il calcolo di probabilità.\n\n27.6.1 Enunciato generale\n\nDefinizione 27.3 Supponiamo che lo spazio campionario \\(\\Omega\\) sia suddiviso in una partizione di eventi \\(B_1, B_2, \\dots, B_n\\), ossia:\n\n\nmutua esclusività: \\(B_i \\cap B_j = \\varnothing\\) per \\(i \\neq j\\);\n\n\ncopertura totale: \\(\\bigcup_{i=1}^n B_i = \\Omega\\).\n\nAllora, per un qualsiasi evento \\(A \\subseteq \\Omega\\) vale:\n\\[\nP(A)\n\\;=\\;\n\\sum_{i=1}^n P(A \\cap B_i)\n\\;=\\;\n\\sum_{i=1}^n P(A \\mid B_i)\\, P(B_i).\n\\tag{27.6}\\]\nIn altre parole, \\(P(A)\\) può essere visto come una media pesata delle probabilità condizionate \\(P(A \\mid B_i)\\), con pesi \\(P(B_i)\\).\n\n\n27.6.2 Caso di due partizioni\nQuando lo spazio campionario è ripartito in due soli eventi, \\(B\\) e il suo complementare \\(B^c\\), la formula si semplifica in:\n\\[\n\\begin{aligned}\nP(A)\n&= P(A \\cap B) + P(A \\cap B^c) \\\\\n&= P(A \\mid B)\\,P(B) \\;+\\; P(A \\mid B^c)\\,P(B^c).\n\\end{aligned}\n\\tag{27.7}\\]\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nTest medico\nAbbiamo:\n\n\n\\(B\\): “Una persona è malata”;\n\n\\(B^c\\): “Una persona è sana”;\n\n\n\\(A\\): “Test positivo”.\n\nSecondo il Teorema della Probabilità Totale, la probabilità di un risultato positivo si ottiene sommando:\n\\[\nP(A)\n= P(\\text{Positivo} \\mid \\text{Malato}) \\,P(\\text{Malato})\n\\;+\\;\nP(\\text{Positivo} \\mid \\text{Sano}) \\,P(\\text{Sano}).\n\\]\n\n\n\n\n27.6.3 Applicazioni principali\n\nAnalisi per Categorie\nQuando la popolazione è divisa in gruppi \\(B_1, \\dots, B_n\\) (ad esempio, fasce d’età o regioni), la probabilità di un evento \\(A\\) si ottiene sommando le probabilità di \\(A\\) condizionate a ciascun gruppo, moltiplicate per la frequenza di quel gruppo.\nTeorema di Bayes\nIl denominatore della formula di Bayes è la somma \\(\\sum_{j=1}^n P(E \\mid H_j)\\,P(H_j)\\), che è appunto un’applicazione della probabilità totale. Qui, \\(H_1, \\dots, H_n\\) rappresentano ipotesi alternative (partizione) e \\(E\\) un dato osservato.\n\nIn breve, il teorema della probabilità totale “scompone” un problema globale in sotto-problemi più specifici, ciascuno condizionato su una porzione dello spazio campionario, permettendo di sommare i risultati finali per ottenere \\(P(A)\\).\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nUrne con Palline di Colori Diversi\nAbbiamo 3 urne, ciascuna con 100 palline:\n\nUrna 1: 75 rosse, 25 blu\n\nUrna 2: 60 rosse, 40 blu\n\nUrna 3: 45 rosse, 55 blu\n\nL’urna viene scelta a caso (probabilità \\(1/3\\) per ciascuna). Qual è la probabilità di estrarre una pallina rossa?\nDefinisco:\n\n\n\\(R\\): “Estraggo una pallina rossa”;\n\n\n\\(U_i\\): “Seleziono l’Urna \\(i\\)”.\n\nLe urne \\(U_1, U_2, U_3\\) costituiscono una partizione (disgiunte e coprenti \\(\\Omega\\)). Sappiamo:\n\\[\nP(R \\mid U_1)=0.75,\n\\quad\nP(R \\mid U_2)=0.60,\n\\quad\nP(R \\mid U_3)=0.45.\n\\]\nApplicando la probabilità totale:\n\\[\n\\begin{aligned}\nP(R)\n&= P(R \\mid U_1)\\,P(U_1) + P(R \\mid U_2)\\,P(U_2) + P(R \\mid U_3)\\,P(U_3)\\\\\n&= 0.75 \\times \\tfrac13 + 0.60 \\times \\tfrac13 + 0.45 \\times \\tfrac13\n= 0.60.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nProbabilità della Depressione in Diverse Fasce d’Età\nUna popolazione è suddivisa in 3 gruppi:\n\ngiovani (30%),\nadulti (40%),\n\nanziani (30%).\n\nLe probabilità condizionate di soffrire di depressione sono:\n\\[\nP(D \\mid \\text{Giovane}) = 0.10, \\quad\nP(D \\mid \\text{Adulto}) = 0.20, \\quad\nP(D \\mid \\text{Anziano}) = 0.35.\n\\]\nUsando la probabilità totale:\n\\[\nP(D)\n= 0.10\\times0.30 + 0.20\\times0.40 + 0.35\\times0.30\n= 0.215.\n\\]\nDunque, circa il 21.5% della popolazione totale soffre di depressione, combinando i tassi per ciascuna fascia.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/04_conditional_prob.html#riflessioni-conclusive",
    "title": "27  Probabilità condizionata",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa probabilità condizionata è uno dei concetti più importanti in statistica, poiché fornisce il quadro teorico per:\n\ncomprendere e formalizzare l’indipendenza tra eventi o variabili (assenza di ogni tipo di relazione);\nespandere e generalizzare il calcolo delle probabilità (ad esempio, la legge della probabilità totale, che scompone in modo sistematico eventi complessi);\n\nalimentare metodi inferenziali avanzati, come il Teorema di Bayes.\n\nIn particolare, il Teorema di Bayes rappresenta uno strumento cardine dell’inferenza statistica: grazie alla probabilità condizionata, è possibile “aggiornare” in modo continuo le credenze sulle ipotesi (o sui parametri di un modello) alla luce di nuove osservazioni. Tale caratteristica di “apprendimento” graduale rende l’inferenza bayesiana flessibile e potente, ideale per affrontare situazioni in cui vengono resi disponibili dati aggiuntivi o in cui le condizioni iniziali possono cambiare.\nIn definitiva, la probabilità condizionata non solo chiarisce la nozione di indipendenza e getta le fondamenta di metodi inferenziali evoluti, ma soprattutto rappresenta il “motore” di modelli che si adattano dinamicamente alle nuove informazioni. Questa prospettiva “attiva” nell’aggiornamento delle probabilità è ciò che rende l’analisi statistica uno strumento versatile per descrivere e interpretare il mondo reale.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizio 1: Soddisfazione con la Vita e Stress Accademico\nUn gruppo di studenti ha compilato la Satisfaction with Life Scale (SWLS) e un questionario sullo stress accademico. Dai dati raccolti emerge che:\n\nIl 40% degli studenti ha riportato un alto livello di stress accademico.\nIl 60% degli studenti ha riportato un basso livello di stress accademico.\nTra gli studenti con alto stress, il 30% ha riportato una soddisfazione con la vita elevata.\nTra gli studenti con basso stress, il 70% ha riportato una soddisfazione con la vita elevata.\n\nCalcola la probabilità che uno studente scelto a caso abbia:\n\nUn alto livello di stress e una soddisfazione elevata.\nUna soddisfazione elevata.\nUn alto livello di stress, dato che ha una soddisfazione elevata.\n\nEsercizio 2: Studio del Paradosso di Simpson\nUn’università vuole valutare la relazione tra la frequenza di partecipazione alle lezioni e il successo negli esami finali. I dati raccolti mostrano che:\n\n\n\n\n\n\n\n\nGruppo\nStudenti con alta frequenza\nSuperano l’esame\nNon superano l’esame\n\n\n\nA\n40\n30\n10\n\n\nB\n60\n20\n40\n\n\n\n\nCalcola la probabilità di superare l’esame per ciascun gruppo separatamente.\nCalcola la probabilità totale di superare l’esame.\nSpiega se il Paradosso di Simpson si manifesta in questi dati.\n\nEsercizio 3: Il Problema di Monty Hall\nIn un quiz televisivo, un concorrente deve scegliere tra tre porte: dietro una c’è un’auto e dietro le altre due ci sono capre. Dopo la scelta iniziale, il conduttore, che sa cosa c’è dietro ogni porta, apre una delle due porte rimanenti rivelando una capra. Il concorrente ha ora la possibilità di cambiare la sua scelta.\n\nQual è la probabilità di vincere l’auto se il concorrente non cambia la sua scelta?\nQual è la probabilità di vincere l’auto se il concorrente cambia la sua scelta?\nSpiega perché cambiare porta è la strategia migliore.\n\nEsercizio 4: Teorema della Probabilità Totale\nUn’università ha tre dipartimenti: Psicologia, Economia e Ingegneria. Le proporzioni di studenti iscritti sono:\n\nPsicologia: 40%\nEconomia: 35%\nIngegneria: 25%\n\nLa probabilità di laurearsi in tempo varia per ogni dipartimento:\n\nPsicologia: 70%\nEconomia: 60%\nIngegneria: 80%\n\nCalcola la probabilità che uno studente scelto a caso si laurei in tempo.\nEsercizio 5: Urne e Palline\nUn’urna contiene 5 palline rosse e 7 blu. Si estrae una pallina, si osserva il colore e poi la pallina viene rimessa nell’urna. Quindi si estrae una seconda pallina.\n\nQual è la probabilità di estrarre due palline rosse?\nQual è la probabilità di estrarre almeno una pallina blu?\nQual è la probabilità di estrarre una pallina rossa alla seconda estrazione, dato che la prima estratta era blu?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nEsercizio 1: Soddisfazione con la Vita e Stress Accademico\n\n\nLa probabilità che uno studente abbia alto stress e soddisfazione elevata si calcola moltiplicando la probabilità condizionata di avere soddisfazione elevata dato l’alto stress per la probabilità di avere alto stress:\n\\[\nP(S \\cap V) = P(V | S) P(S) = 0.30 \\times 0.40 = 0.12.\n\\]\n\n\nLa probabilità che uno studente abbia una soddisfazione elevata, indipendentemente dal livello di stress, si ottiene applicando la legge della probabilità totale:\n\\[\nP(V) = P(V | S) P(S) + P(V | \\neg S) P(\\neg S)\n\\]\n\\[\n= (0.30 \\times 0.40) + (0.70 \\times 0.60) = 0.12 + 0.42 = 0.54.\n\\]\n\n\nLa probabilità che uno studente abbia alto stress sapendo che ha una soddisfazione elevata si calcola utilizzando la formula della probabilità condizionata:\n\\[\nP(S | V) = \\frac{P(S \\cap V)}{P(V)} = \\frac{0.12}{0.54} \\approx 0.22.\n\\]\n\n\nEsercizio 2: Studio del Paradosso di Simpson\n\n\n\\(P(E | A) = \\frac{30}{40} = 0.75\\), \\(P(E | B) = \\frac{20}{60} = 0.33\\)\n\n\\(P(E) = P(E | A) P(A) + P(E | B) P(B) = (0.75 \\times 0.40) + (0.33 \\times 0.60) = 0.30 + 0.198 = 0.498\\)\nSe i tassi di successo aggregati mostrano una relazione invertita, il Paradosso di Simpson si manifesta.\n\nEsercizio 3: Il Problema di Monty Hall\n\n\\(P(V | S) = \\frac{1}{3}\\)\n\\(P(V | C) = \\frac{2}{3}\\)\nCambiare porta aumenta le probabilità di vincita da \\(1/3\\) a \\(2/3\\), quindi conviene sempre cambiare.\n\nEsercizio 4: Teorema della Probabilità Totale\n\\(P(L) = (0.70 \\times 0.40) + (0.60 \\times 0.35) + (0.80 \\times 0.25) = 0.28 + 0.21 + 0.20 = 0.69\\)\nEsercizio 5: Urne e Palline\n\n\\(P(R_1 \\cap R_2) = (5/12) \\times (5/12) = 25/144\\)\n\\(1 - P(R_1 \\cap R_2) = 1 - 25/144 = 119/144\\)\n\\(P(R_2 | B_1) = 5/12\\)\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [19] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [22] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [25] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [28] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [31] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [34] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [37] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [40] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [43] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#&gt; [46] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [49] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [52] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [55] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [58] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [61] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [64] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [67] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#&gt; [70] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [73] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#bibliografia",
    "href": "chapters/probability/04_conditional_prob.html#bibliografia",
    "title": "27  Probabilità condizionata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nRadelet, M. L., & Pierce, G. L. (1991). Choosing Those Who Will Die: Race and the Death Penalty in Florida. Florida Law Review, 43(1), 1–34.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html",
    "href": "chapters/probability/05_bayes_theorem.html",
    "title": "28  Il teorema di Bayes",
    "section": "",
    "text": "Introduzione\nIl teorema di Bayes costituisce un metodo matematico ottimale per risolvere problemi di inferenza induttiva, ovvero situazioni in cui si deducono cause sottostanti, principi generali o strutture complesse a partire da dati parziali e incerti. Trova applicazione in scenari disparati: dalla ricostruzione della percezione tridimensionale basata su segnali retinici all’interpretazione degli stati mentali altrui attraverso il comportamento osservabile, fino alla stima di parametri fisici in condizioni sperimentali rumorose (Baker et al., 2011; Ma et al., 2023). La sua efficacia emerge soprattutto in contesti dove le evidenze disponibili non permettono di discriminare univocamente tra ipotesi concorrenti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#introduzione",
    "href": "chapters/probability/05_bayes_theorem.html#introduzione",
    "title": "28  Il teorema di Bayes",
    "section": "",
    "text": "Panoramica del capitolo\n\nL’importanza dell teorema di Bayes.\nl’utilizzo del teorema di Bayes per analizzare e interpretare i test diagnostici, tenendo in considerazione la prevalenza della malattia in questione.\nSoluzione di problemi di probabilità discreta che necessitano dell’applicazione del teorema di Bayes.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Everything is Predictable: How Bayesian Statistics Explain Our World (Chivers, 2024). Questo libro offre una descrizione chiara e accessibile dell’impatto che il teorema di Bayes ha avuto sulla vita moderna.\nLeggere Bayesian Models of Cognition di Thomas L. Griffiths, una voce della Open Encyclopedia of Cognitive Science.\nLeggere il capitolo Conditional Probability (Schervish & DeGroot, 2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n\n\n\n\n28.0.1 Incertezza come fondamento dell’inferenza\nUn principio cardine del ragionamento bayesiano è il riconoscimento dell’incertezza intrinseca a qualsiasi processo conoscitivo. Anche in un universo deterministico, la complessità dei sistemi e i limiti dei nostri sensi rendono impossibile una conoscenza completa. Ad esempio, non possiamo determinare con esattezza infiniti dettagli (come posizione e stato di ogni neurone nel cervello di un interlocutore) né accedere direttamente a variabili latenti (come emozioni o intenzioni). Di conseguenza, ogni inferenza conserva un margine probabilistico, che Bayes quantifica e trasforma in uno strumento operativo.\n\n28.0.2 Dinamica bayesiana: aggiornare le credenze\nLa realtà può essere paragonata a una partita di poker più che a una di scacchi: operiamo sempre in condizioni di informazione imperfetta. Le decisioni si basano su un bilanciamento tra conoscenze pregresse (prior) e nuovi indizi (likelihood), in un processo dinamico formalizzato dall’equazione:\n\\[\nP(H \\mid E) = \\frac{P(E \\mid H) \\cdot P(H)}{P(E)} ,\n\\]\ndove:\n\n\n\\(P(H \\mid E)\\) (posterior): plausibilità rivista dell’ipotesi \\(H\\) dopo aver osservato l’evidenza \\(E\\);\n\n\n\\(P(E \\mid H)\\) (likelihood): probabilità di osservare \\(E\\) se \\(H\\) fosse vera;\n\n\n\\(P(H)\\) (prior): fiducia iniziale in \\(H\\);\n\n\n\\(P(E)\\): fattore di normalizzazione.\n\nQuesto meccanismo permette di ricalibrare razionalmente le convinzioni, riducendo l’incertezza man mano che nuovi dati vengono integrati.\n\n28.0.3 Inferenza induttiva e razionalità adattiva\nL’inferenza induttiva bayesiana rappresenta un pilastro della razionalità scientifica e quotidiana. A differenza della logica deduttiva (dove le conclusioni derivano necessariamente dalle premesse), Bayes riconcilia teoria ed evidenza empirica, consentendo previsioni robuste nonostante dati incompleti. Le applicazioni spaziano:\n\nin psicologia cognitiva, modellando come il cervello interpreta segnali ambigui (Caudek & Bruno, 2024; Domini & Caudek, 2003);\n\nnell’intelligenza artificiale, guidando algoritmi di apprendimento automatico (Chivers, 2024);\n\nnelle scienze sociali, per stimare preferenze nascoste da comportamenti osservati.\n\nIl teorema non elimina l’incertezza, ma fornisce un protocollo formale per gestirla, trasformando l’induzione da atto intuitivo a procedura rigorosa. In questo senso, incarna un principio di razionalità adattiva, dove l’ottimalità non richiede onniscienza, bensì un aggiornamento coerente delle credenze in risposta all’esperienza.\n\n\n\n\n\n\n\n\n\n\n\n\n28.0.4 Una rivoluzione nel pensiero probabilistico\nPer comprendere appieno il teorema di Bayes, è necessario delineare le sue origini storiche. Nel XVIII secolo, Thomas Bayes (1701-1761), ecclesiastico presbiteriano e matematico britannico, pose le basi di una rivoluzione concettuale nel campo della probabilità e della statistica. Il suo contributo teorico, passato alla storia come teorema di Bayes, ha plasmato in modo decisivo lo sviluppo scientifico e tecnologico dei secoli successivi, influenzando discipline che spaziano dalla medicina all’intelligenza artificiale (Chivers, 2024).\n\n28.0.4.1 La figura di Thomas Bayes\nBayes proveniva da una famiglia benestante e studiò teologia a Edimburgo, preparandosi al ministero religioso. Come ricorda il biografo David Bellhouse, Bayes non era un accademico nel senso moderno del termine, ma un erudito libero, interessato alla conoscenza per passione personale (Bellhouse, 2004).\nDurante la sua vita, Bayes pubblicò due testi:\n\n\nUn trattato di teologia: Divine Benevolence: Or, an Attempt to Prove that the Principal End of the Divine Providence and Government is the Happiness of His Creatures (1731), una teodicea che cerca di spiegare come la legge naturale possa ottimizzare il benessere universale.\n\n\nUna difesa del calcolo infinitesimale: An Introduction to the Doctrine of Fluxions (1736), in risposta alle critiche di George Berkeley sugli infinitesimi e i concetti fondamentali del calcolo newtoniano (Jesseph, 1993).\n\nIl lavoro che segnò la svolta nella teoria della probabilità fu però pubblicato postumo, nel 1763, sulle Philosophical Transactions of the Royal Society: An Essay towards Solving a Problem in the Doctrine of Chances. Per la prima volta, si formalizzava un metodo per aggiornare le ipotesi probabilistiche alla luce di nuove evidenze, ponendo le fondamenta dell’inferenza bayesiana (Stigler, 1990).\n\n28.0.4.2 Bayes e il ruolo culturale della scienza\nCome sottolinea ancora Bellhouse, nel XVIII secolo era comune, tra le élite colte, dedicarsi allo studio di discipline scientifiche per prestigio sociale. Per Bayes, la matematica era dunque una passione coltivata con spirito libero. Il suo merito straordinario fu di spingere l’interpretazione della probabilità verso una prospettiva epistemologica innovativa, dove la probabilità diventa espressione quantitativa della nostra ignoranza sul mondo.\nIn contrapposizione alla visione “classica”, che vedeva la probabilità come frequenza osservabile in eventi ripetuti, Bayes propose che essa potesse rappresentare il grado di fiducia di un osservatore, inevitabilmente influenzato da conoscenze pregresse e da pregiudizi individuali. In questo senso, la probabilità assume un carattere dinamico e soggettivo, configurandosi come uno strumento di conoscenza che si aggiorna di continuo al variare dei dati (Spiegelhalter, 2019).\n\n28.0.4.3 Un esperimento mentale illuminante\nPer illustrare la sua idea, Bayes propose un semplice esempio: immagina di lanciare alcune palline su un tavolo da biliardo. Dopo aver segnato con una linea il punto in cui si ferma una pallina bianca (e averla poi rimossa), si lanciano altre palline rosse e si conta quante cadono a destra e quante a sinistra di quella linea. Sulla base di queste osservazioni, come si può “indovinare” la posizione della linea? E con quale probabilità la prossima pallina rossa cadrà a sinistra di essa?\nLa soluzione di Bayes combina i dati osservati (numero di palline cadute a sinistra o a destra) con le convinzioni iniziali dell’osservatore (il cosiddetto “prior”), delineando un processo di apprendimento graduale che guida la revisione critica delle ipotesi.\n\n28.0.4.4 Il ruolo di Richard Price\nDopo la morte di Bayes, fu un altro ecclesiastico, Richard Price (1723-1791), a dare impulso alla diffusione del saggio bayesiano. Price aveva un’ottima reputazione negli ambienti intellettuali dell’epoca, grazie anche alle sue relazioni con figure di spicco come Benjamin Franklin, Thomas Jefferson e John Adams.\nPrice prese in carico il manoscritto di Bayes, lo sottopose al fisico John Canton e ne curò la pubblicazione postuma, operando modifiche significative. Rispetto alla versione originale di Bayes, concentrata quasi esclusivamente sugli aspetti teorici, Price aggiunse una parte dedicata alle applicazioni pratiche, rendendo il testo più fruibile a un pubblico più ampio. Per questo motivo, lo storico Stephen Stigler lo definisce «il primo bayesiano della storia».\n\n28.0.4.5 Dal silenzio alla riscoperta\nPer oltre cinquant’anni, il lavoro di Bayes rimase in ombra, oscurato dall’opera pionieristica di Pierre-Simon Laplace. Già nel 1774, Laplace pervenne indipendentemente a principi analoghi, e successivamente li sistematizzò nella monumentale Théorie analytique des probabilités (1812). Solo in tempi più recenti, con l’avvento dei metodi di calcolo moderno e dell’informatica, la statura del teorema di Bayes è emersa in tutta la sua importanza.\nOggi, il teorema di Bayes è considerato un cardine della statistica moderna: formalizza il modo in cui aggiorniamo le nostre credenze alla luce di nuovi dati. Questo schema è cruciale in ogni disciplina scientifica e tecnologica che debba fare i conti con incertezza e dati incompleti. Dalla genomica all’econometria, dalla fisica delle particelle alle scienze cognitive, il paradigma bayesiano risulta prezioso per gestire e interpretare informazioni in continuo aggiornamento.\n\n28.0.4.6 L’eredità di Bayes nell’era digitale\nNell’intelligenza artificiale, le idee bayesiane sono alla base di sistemi di apprendimento automatico e modelli probabilistici complessi. Strumenti come i moderni modelli linguistici (ad esempio ChatGPT e Claude) sfruttano strategie di inferenza bayesiana – anche se in forme estremamente avanzate – per generare risposte, fare previsioni e adattarsi costantemente agli input degli utenti.\nLa parabola storica di questo teorema, nato dalle speculazioni di un pastore presbiteriano del Settecento, mostra chiaramente il potenziale trasformativo delle idee matematiche. Come sottolinea Tom Chivers nel suo Everything Is Predictable: How Bayesian Statistics Explain Our World, la statistica bayesiana è diventata una sorta di “grammatica universale” per interpretare la realtà, permettendoci di affrontare con metodo situazioni complesse, modellare l’incertezza e formulare previsioni in contesti dove l’informazione è inevitabilmente limitata (Chivers, 2024).\nIn sintesi, la forza del teorema di Bayes non risiede soltanto nella sua eleganza formale, ma soprattutto nella sua portata epistemologica: esso traduce in termini matematici la nostra naturale tendenza ad apprendere da ciò che osserviamo e a rivedere continuamente ciò che crediamo. Per questo rimane, ancora oggi, un punto di riferimento fondamentale in qualunque disciplina che affronti il problema della conoscenza in condizioni di incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#la-regola-di-bayes-e-linferenza-probabilistica",
    "href": "chapters/probability/05_bayes_theorem.html#la-regola-di-bayes-e-linferenza-probabilistica",
    "title": "28  Il teorema di Bayes",
    "section": "\n28.1 La regola di Bayes e l’inferenza probabilistica",
    "text": "28.1 La regola di Bayes e l’inferenza probabilistica\nL’inferenza bayesiana utilizza un principio centrale della teoria delle probabilità noto come regola di Bayes. Questo principio consente di aggiornare in modo razionale le nostre credenze sulla base di nuovi dati osservati, integrandoli con conoscenze pregresse.\n\n28.1.1 Derivazione della regola di Bayes\nConsideriamo due eventi casuali, \\(A\\) e \\(B\\). La probabilità congiunta \\(P(A, B)\\), ossia la probabilità che entrambi gli eventi accadano simultaneamente, può essere espressa in due modi equivalenti:\n\nTramite la regola della catena, possiamo scrivere: \\[\nP(A, B) = P(A \\mid B)P(B).\n\\] Qui, \\(P(A \\mid B)\\) è la probabilità condizionata che si verifichi l’evento \\(A\\) sapendo che l’evento \\(B\\) è avvenuto, mentre \\(P(B)\\) è la probabilità marginale di \\(B\\), indipendente da \\(A\\).\nUtilizzando la simmetria della probabilità congiunta, possiamo invertire gli eventi: \\[\nP(A, B) = P(B \\mid A)P(A).\n\\]\n\nDato che entrambe le espressioni rappresentano la stessa probabilità congiunta, possiamo eguagliarle:\n\\[\nP(A \\mid B)P(B) = P(B \\mid A)P(A).\n\\]\nRisolvendo per \\(P(B \\mid A)\\) otteniamo la regola di Bayes:\n\\[\nP(B \\mid A) = \\frac{P(A \\mid B) P(B)}{P(A)}.\n\\tag{28.1}\\]\n\n28.1.2 Interpretazione dei termini della regola di Bayes\nLa regola di Bayes permette di aggiornare la nostra credenza sulla probabilità di un’ipotesi o evento (\\(B\\)), dopo aver osservato un dato o evidenza (\\(A\\)):\n\n\n\\(P(B)\\) (prior): è la probabilità iniziale assegnata all’evento \\(B\\) prima di osservare il dato \\(A\\). Rappresenta la nostra conoscenza pregressa o il nostro grado iniziale di fiducia.\n\n\\(P(A \\mid B)\\) (verosimiglianza): è la probabilità di osservare il dato \\(A\\) nell’ipotesi che \\(B\\) sia vero. Indica quanto il dato sia compatibile con l’ipotesi.\n\n\\(P(B \\mid A)\\) (posterior): è la probabilità aggiornata, cioè la nostra nuova credenza sull’evento \\(B\\) dopo aver osservato il dato \\(A\\).\n\n\\(P(A)\\) (evidenza): è la probabilità marginale del dato osservato, calcolata sommando o integrando su tutte le possibili ipotesi alternative che potrebbero aver generato tale dato. Agisce da termine di normalizzazione per garantire che la somma delle probabilità a posteriori sia uguale a 1.\n\n28.1.3 Applicazioni della regola di Bayes\nNella pratica, l’inferenza bayesiana si svolge tipicamente nel seguente modo:\n\nSi parte da uno spazio delle ipotesi \\(\\mathcal{H}\\), ovvero un insieme di tutte le possibili spiegazioni o modelli che potrebbero aver generato i dati osservati \\(D\\).\nA ciascuna ipotesi \\(H \\in \\mathcal{H}\\) viene assegnata una probabilità a priori \\(P(H)\\) che riflette la nostra fiducia iniziale.\nUna volta raccolti i dati \\(D\\), aggiorniamo le probabilità delle ipotesi usando la formula:\n\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) \\, P(H)}{P(D)},\n\\tag{28.2}\\]\ndove:\n\n\n\\(P(D \\mid H)\\) è la verosimiglianza, cioè la probabilità che l’ipotesi \\(H\\) abbia generato i dati \\(D\\);\n\n\\(P(D)\\) è la probabilità marginale (evidenza), calcolata considerando tutte le possibili ipotesi:\n\n\\[\nP(D) = \\sum_{H' \\in \\mathcal{H}} P(D \\mid H')P(H'),\n\\]\nnel caso discreto, oppure:\n\\[\nP(D) = \\int_{\\mathcal{H}} P(D \\mid H')P(H') \\, dH',\n\\]\nnel caso continuo.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nImmagina di avere ricevuto un messaggio anonimo sul tuo cellulare con scritto solo “Ci vediamo stasera!”. Vuoi capire chi può essere stato a mandartelo. In questo esempio, il tuo “spazio delle ipotesi” sarà rappresentato da tre persone possibili: Alice, Bruno e Carla.\nQuindi, hai un insieme di ipotesi molto semplice:\n\\[\n\\mathcal{H} = \\{\\text{Alice},\\, \\text{Bruno},\\, \\text{Carla}\\} .\n\\]\n1. Probabilità a priori (prima di guardare i dati).\nSupponi che ciascuna persona abbia una probabilità diversa di scriverti:\n\n\nIpotesi\n\\(P(H)\\)\n\n\n\nAlice\n0.5\n\n\nBruno\n0.3\n\n\nCarla\n0.2\n\n\n\nQueste sono le tue probabilità a priori, basate sulla tua esperienza o conoscenza passata (ad esempio, Alice tende a scriverti spesso, Carla raramente).\n2. Come le ipotesi generano i dati (informazioni aggiuntive).\nOra raccogli alcune informazioni utili (i tuoi dati \\(D\\)):\n\nIl messaggio dice “Ci vediamo stasera!”.\n\nRifletti sul fatto che ciascuna delle tre persone usa questa frase con frequenze diverse (sai, ad esempio, che Alice usa spesso frasi brevi come questa, mentre Bruno e Carla la usano meno spesso, ovvero tendono a scrivere messaggi più lunghi):\n\n\n\n\n\n\nIpotesi\nProbabilità di inviare questa specifica frase (\\(P(D \\mid H)\\))\n\n\n\nAlice\n0.7\n\n\nBruno\n0.4\n\n\nCarla\n0.1\n\n\n\nQueste probabilità rappresentano il “meccanismo generatore dei dati”, ovvero come ciascuna persona (ipotesi) potrebbe generare proprio il messaggio che hai ricevuto.\n3. Aggiornamento delle probabilità a posteriori (dopo aver osservato il messaggio).\nOra applichiamo la formula di Bayes per aggiornare la nostra fiducia iniziale:\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) \\, P(H)}{P(D)} .\n\\]\nPrima calcoliamo la probabilità totale di ricevere quello specifico messaggio, indipendentemente da chi l’ha inviato. Usiamo il teorema della probabilità totale:\n\\[\nP(D) = P(D\\mid\\text{Alice})P(\\text{Alice}) + P(D\\mid\\text{Bruno})P(\\text{Bruno}) + P(D\\mid\\text{Carla})P(\\text{Carla}) .\n\\]\nCioè:\n\\[\nP(D) = (0.7 \\times 0.5) + (0.4 \\times 0.3) + (0.1 \\times 0.2)\n= 0.35 + 0.12 + 0.02\n= 0.49 .\n\\]\nOra aggiorniamo ciascuna ipotesi:\n\nAlice:\n\n\\[\nP(\\text{Alice}\\mid D) = \\frac{0.7\\times0.5}{0.49} = \\frac{0.35}{0.49} \\approx 0.714 .\n\\]\n\nBruno:\n\n\\[\nP(\\text{Bruno}\\mid D) = \\frac{0.4\\times0.3}{0.49} = \\frac{0.12}{0.49} \\approx 0.245 .\n\\]\n\nCarla:\n\n\\[\nP(\\text{Carla}\\mid D) = \\frac{0.1\\times0.2}{0.49} = \\frac{0.02}{0.49} \\approx 0.041 .\n\\]\n4. Interpretazione finale (intuizione bayesiana).\nDopo aver osservato il messaggio (“dati”), la tua fiducia si è aggiornata rispetto alle probabilità iniziali:\n\n\nIpotesi\nProbabilità a priori\nProbabilità a posteriori\n\n\n\nAlice\n0.5\n0.714\n\n\nBruno\n0.3\n0.245\n\n\nCarla\n0.2\n0.041\n\n\n\nOra credi molto più fortemente che sia stata Alice a scriverti.\nIn sintesi, in questo esempio semplice, lo spazio delle ipotesi era costituito da tre persone possibili. Ciascuna ipotesi poteva “generare” (cioè produrre o inviare) lo specifico messaggio che hai ricevuto con una diversa probabilità (“meccanismo generatore dei dati”). Prima dei dati avevi delle credenze su chi poteva averti scritto (“probabilità a priori”), poi lo specifico messaggio osservato (“i dati”) ha modificato le tue convinzioni (“probabilità a posteriori”), secondo la logica della Regola di Bayes.\nQuesto esempio chiarisce intuitivamente il significato di:\n\n\nspazio delle ipotesi (le possibili spiegazioni);\n\nmeccanismo generatore dei dati (la probabilità con cui ciascuna ipotesi produce il dato osservato);\n\naggiornamento bayesiano (come cambia la fiducia nelle ipotesi dopo aver visto i dati).\n\n\n\n\n\n28.1.4 Il processo iterativo dell’aggiornamento bayesiano\nL’inferenza bayesiana è intrinsecamente iterativa. Ogni volta che emergono nuovi dati, la distribuzione a posteriori \\(P(H \\mid D)\\) ottenuta diventa il nuovo prior per aggiornamenti successivi. Questo permette un affinamento continuo delle credenze, adattando la nostra comprensione del mondo in modo dinamico e coerente con le nuove evidenze.\n\n28.1.4.1 Considerazioni pratiche\nSpesso, il calcolo diretto della probabilità marginale \\(P(D)\\) — corrispondente, nell’esempio precedente, alla probabilità di osservare lo specifico messaggio ricevuto sul dispositivo mobile — risulta computazionalmente oneroso, in particolare quando lo spazio delle ipotesi è discreto o continuo di alta dimensionalità. Per ovviare a questa limitazione, vengono impiegati metodi numerici approssimativi come il Campionamento Monte Carlo o le inferenze variazionali, tecniche che permettono di stimare in modo efficiente tali grandezze probabilistiche anche in scenari reali complessi, senza ricorrere a calcoli analitici esatti.\nIn sintesi, la regola di Bayes fornisce uno schema formale e razionale per integrare informazioni pregresse con nuove osservazioni. Questa capacità di aggiornare continuamente le nostre credenze rappresenta il cuore del ragionamento probabilistico e rende l’approccio bayesiano uno strumento fondamentale in molte discipline scientifiche e applicazioni pratiche.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nImmaginiamo questo scenario: sospettiamo che una moneta possa essere truccata e vogliamo verificarlo attraverso due lanci. Utilizzeremo il ragionamento bayesiano per combinare le nostre convinzioni iniziali con i dati osservati.\nLe Due Ipotesi.\nSupponiamo che la moneta possa essere:\n\n\nbilanciata (pari probabilità di Testa e Croce: 50% ciascuna);\n\ntruccata (sbilanciata, con probabilità di Testa del 80% e Croce del 20%).\n\nIl nostro obiettivo è capire quale ipotesi sia più plausibile dopo ogni lancio.\nFase 1: credenze iniziali (prior).\nPrima di lanciare la moneta, abbiamo una certa idea di quanto sia probabile ciascuna ipotesi:\n\\[\nP(\\text{Bilanciata}) = 0.85 \\quad\\text{e}\\quad P(\\text{Truccata}) = 0.15.\n\\]\nQueste probabilità rappresentano il prior, ovvero le nostre convinzioni iniziali prima di osservare qualunque risultato.\nFase 2: primo lancio - esce Testa.\nLanciamo la moneta una volta e osserviamo il risultato: esce Testa.\nCi chiediamo: “Quanto è probabile osservare Testa se ciascuna delle due ipotesi fosse vera?”\n\nSe la moneta è bilanciata, la probabilità di osservare Testa è 0.5 (50%).\nSe la moneta è truccata, la probabilità di osservare Testa è 0.8 (80%).\n\nQueste due probabilità rappresentano la verosimiglianza:\n\\[\nP(\\text{Testa} \\mid \\text{Bilanciata}) = 0.5 \\quad\\text{e}\\quad P(\\text{Testa} \\mid \\text{Truccata}) = 0.8.\n\\]\nEvidenza: Probabilità Complessiva dell’Evento Osservato.\nVogliamo ora sapere quanto sia probabile osservare Testa in generale, considerando entrambe le ipotesi possibili. Per calcolarlo, usiamo la probabilità totale, che tiene conto di tutte le possibili ipotesi:\n\\[\nP(\\text{Testa}) = P(\\text{Testa} \\mid \\text{Bilanciata}) \\times P(\\text{Bilanciata}) + P(\\text{Testa} \\mid \\text{Truccata}) \\times P(\\text{Truccata}).\n\\]\nSostituiamo i valori numerici:\n\\[\nP(\\text{Testa}) = (0.5 \\times 0.85) + (0.8 \\times 0.15) = 0.425 + 0.12 = 0.545.\n\\]\nQuesta è la probabilità marginale o evidenza del risultato osservato.\nPosterior: Aggiornamento delle Credenze dopo l’Evidenza.\nOra possiamo usare il Teorema di Bayes per aggiornare le nostre credenze iniziali alla luce dell’evento osservato (Testa):\n\\[\n\\begin{aligned}\nP(\\text{Bilanciata} \\mid \\text{Testa}) &= \\frac{P(\\text{Testa} \\mid \\text{Bilanciata}) \\times P(\\text{Bilanciata})}{P(\\text{Testa})}\\notag\\\\\n&= \\frac{0.5 \\times 0.85}{0.545} \\notag\\\\\n&= 0.7798 \\quad (77.98\\%).\n\\end{aligned} \\notag\n\\]\n\\[\n\\begin{aligned}\nP(\\text{Truccata} \\mid \\text{Testa}) &= \\frac{P(\\text{Testa} \\mid \\text{Truccata}) \\times P(\\text{Truccata})}{P(\\text{Testa})} \\notag\\\\\n&= \\frac{0.8 \\times 0.15}{0.545} \\notag\\\\\n&= 0.2202 \\quad (22.02\\%). \\notag\n\\end{aligned}\n\\]\nInterpretazione Intuitiva.\nPrima del lancio, eravamo abbastanza sicuri (85%) che la moneta fosse bilanciata. Dopo aver osservato un singolo lancio che mostra Testa, questa certezza diminuisce (passa a circa 77.98%), mentre la probabilità che la moneta sia truccata aumenta (passa da 15% a circa 22.02%).\nQuesto esempio mostra come il prior, la verosimiglianza e l’evidenza si combinino nel ragionamento bayesiano per produrre un aggiornamento razionale e coerente delle credenze.\nFase 3: secondo Lancio - esce Testa.\nSupponiamo ora di lanciare la moneta una seconda volta, osservando ancora Testa. Usiamo le nuove probabilità ottenute (posterior) come prior aggiornati:\n\\[\nP(\\text{Bilanciata}) = 0.7798 \\quad\\text{e}\\quad P(\\text{Truccata}) = 0.2202.\n\\]\nCalcoliamo nuovamente l’evidenza:\n\\[\nP(\\text{Testa}) = (0.5 \\times 0.7798) + (0.8 \\times 0.2202) = 0.3899 + 0.1762 = 0.5661.\n\\]\nAggiorniamo quindi le credenze con il teorema di Bayes:\n\\[\nP(\\text{Bilanciata} \\mid \\text{Testa}) = \\frac{0.5 \\times 0.7798}{0.5661} = 0.6887 \\quad (68.87\\%).\n\\]\n\\[\nP(\\text{Truccata} \\mid \\text{Testa}) = \\frac{0.8 \\times 0.2202}{0.5661} = 0.3113 \\quad (31.13\\%).\n\\]\nInterpretazione del Secondo Aggiornamento.\nDopo il secondo lancio che mostra ancora Testa, la probabilità che la moneta sia bilanciata scende ulteriormente da 0.7798 a 0.6887, mentre la probabilità che la moneta sia truccata sale a 0.3113. Questo esempio mostra come l’aggiornamento bayesiano consenta di modificare progressivamente le nostre credenze, adattandole coerentemente a ogni nuova evidenza osservata.\n\n\n\n\n28.1.5 Applicazioni in psicologia\nNegli ultimi anni, i modelli bayesiani hanno acquisito un ruolo centrale nello studio della cognizione umana, fornendo una struttura formale per comprendere come il cervello costruisca rappresentazioni del mondo e prenda decisioni sulla base di dati incerti. Come discusso da Griffiths et al. (2024), questi modelli sono stati applicati a una vasta gamma di processi cognitivi, tra cui:\n\n\nApprendimento e generalizzazione: i modelli bayesiani descrivono come gli individui apprendano nuove categorie e concetti sulla base di dati limitati e rumorosi (Tenenbaum, Griffiths, & Kemp, 2006).\n\nPercezione e interpretazione sensoriale: la percezione visiva e il riconoscimento di oggetti possono essere spiegati come un’inferenza bayesiana sulla base di segnali sensoriali ambigui (Domini & Caudek, 2003; Yuille & Kersten, 2006).\n\nControllo motorio: il sistema motorio umano sembra ottimizzare i movimenti attraverso una combinazione di modelli interni e aggiornamenti bayesiani (Kording & Wolpert, 2006).\n\nMemoria e recupero delle informazioni: i processi mnemonici, come il richiamo della memoria semantica, possono essere modellati come inferenze bayesiane basate su conoscenze pregresse (Steyvers, Griffiths, & Dennis, 2006).\n\nAcquisizione del linguaggio: l’apprendimento del linguaggio nei bambini può essere descritto attraverso processi probabilistici che permettono di inferire le strutture grammaticali sulla base di dati linguistici limitati (Chater & Manning, 2006; Xu & Tenenbaum, in press).\n\nApprendimento causale: la capacità di inferire relazioni causali dagli eventi osservati è coerente con un modello bayesiano, in cui la mente valuta la probabilità di una relazione causale sulla base dell’evidenza disponibile (Griffiths & Tenenbaum, 2005, 2007).\n\nRagionamento e decisione: il ragionamento simbolico e il processo decisionale possono essere formalizzati come un aggiornamento bayesiano delle credenze sulla base di nuove informazioni (Oaksford & Chater, 2001).\n\nCognizione sociale: le inferenze sulle intenzioni e credenze altrui possono essere modellate attraverso processi bayesiani, permettendo di spiegare come le persone comprendano il comportamento altrui (Baker, Tenenbaum, & Saxe, 2007).\n\n\n28.1.5.1 L’inferenza bayesiana nella cognizione umana\nUn tema centrale che emerge da questi programmi di ricerca è la seguente domanda: come fa la mente umana ad andare oltre i dati dell’esperienza? In altre parole, come riesce il cervello a costruire modelli complessi del mondo a partire da informazioni limitate e spesso ambigue?\nL’approccio bayesiano propone che il cervello utilizzi un processo di inferenza probabilistica per aggiornare continuamente le proprie credenze, combinando informazioni pregresse con nuove osservazioni per affinare le proprie rappresentazioni mentali. Questo meccanismo consente di spiegare molte delle capacità cognitive umane, dall’apprendimento rapido di nuove categorie alla capacità di adattarsi a un ambiente mutevole, fino alla formulazione di inferenze sociali e alla presa di decisioni in condizioni di incertezza.\nL’adozione dei modelli bayesiani nella psicologia cognitiva ha portato a una nuova comprensione della mente come sistema predittivo, in grado di formulare ipotesi probabilistiche sugli eventi futuri e di correggerle dinamicamente sulla base dell’esperienza. Questo approccio ha profonde implicazioni per lo studio del comportamento umano e per lo sviluppo di nuove tecniche di modellizzazione nei campi della psicologia, delle neuroscienze e dell’intelligenza artificiale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#test-medici",
    "href": "chapters/probability/05_bayes_theorem.html#test-medici",
    "title": "28  Il teorema di Bayes",
    "section": "\n28.2 Test medici",
    "text": "28.2 Test medici\nUno degli esempi più comuni per comprendere il teorema di Bayes riguarda i test diagnostici.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nConsideriamo un test di mammografia utilizzato per diagnosticare il cancro al seno che abbiamo già discusso nel Capitolo 27. Definiamo le seguenti ipotesi:\n\n\n\\(M^+\\): la persona ha il cancro al seno;\n\n\\(M^-\\): la persona non ha il cancro al seno.\n\nL’evidenza è il risultato positivo del test, indicato con \\(T^+\\). Il nostro obiettivo è calcolare la probabilità che una persona abbia il cancro al seno, dato un risultato positivo al test, ovvero \\(P(M^+ \\mid T^+)\\).\nDefinizione dei termini nella regola di Bayes.\nIl teorema di Bayes afferma che:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) P(M^+)}{P(T^+)} ,\n\\]\ndove:\n\n\n\\(P(T^+ \\mid M^+)\\) è la sensibilità del test, cioè la probabilità che il test risulti positivo se la persona ha effettivamente il cancro. Nel nostro caso, \\(P(T^+ \\mid M^+) = 0.90\\).\n\n\\(P(M^+)\\) è la probabilità a priori di avere il cancro al seno, ovvero la prevalenza della malattia nella popolazione. Supponiamo che sia \\(P(M^+) = 0.01\\) (1%).\n\n\\(P(T^+ \\mid M^-)\\) è la probabilità di un falso positivo, cioè la probabilità che il test risulti positivo anche in assenza di malattia. Questa è complementare alla specificità del test:\n\n\\[\n  P(T^+ \\mid M^-) = 1 - \\text{Specificità} = 1 - 0.90 = 0.10.\n\\]\n\n\n\\(P(M^-)\\) è la probabilità a priori che una persona non abbia il cancro, ovvero:\n\n\\[\n  P(M^-) = 1 - P(M^+) = 1 - 0.01 = 0.99.\n\\]\n\n\n\\(P(T^+)\\) è la probabilità marginale che il test risulti positivo, calcolata considerando entrambe le possibilità (cioè che la persona abbia o non abbia il cancro):\n\n\\[\n  P(T^+) = P(T^+ \\mid M^+) P(M^+) + P(T^+ \\mid M^-) P(M^-).\n\\]\nSostituendo i valori numerici:\n\\[\n  P(T^+) = (0.90 \\cdot 0.01) + (0.10 \\cdot 0.99) = 0.009 + 0.099 = 0.108.\n\\]\nApplicazione della Regola di Bayes.\nOra possiamo calcolare la probabilità a posteriori \\(P(M^+ \\mid T^+)\\):\n\\[\nP(M^+ \\mid T^+) = \\frac{0.90 \\cdot 0.01}{0.108} = \\frac{0.009}{0.108} = 0.0833.\n\\]\nInterpretazione del Risultato.\nQuesto risultato indica che, nonostante il test abbia una sensibilità e una specificità del 90%, la probabilità che una persona con un test positivo abbia effettivamente il cancro è solo dell’8.3%. Questo effetto è dovuto alla bassa prevalenza della malattia: anche se il test è relativamente accurato, il numero di falsi positivi è ancora alto rispetto ai veri positivi. Tale risultato conferma quanto precedentemente ottenuto nel Capitolo 27, attraverso un metodo di calcolo alternativo.\nQuesta formulazione mostra come la regola di Bayes permetta di aggiornare la probabilità di avere la malattia dopo aver osservato il risultato del test, combinando la sensibilità, la specificità e la prevalenza della malattia nella popolazione.\n\n\n\nIn un secondo esempio, vogliamo valutare l’affidabilità di un test per l’HIV e capire come la nostra stima di infezione cambia dopo due test consecutivi positivi. Utilizzeremo la regola di Bayes per aggiornare la probabilità di avere l’HIV man mano che otteniamo nuovi risultati.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nImmaginiamo che una persona esegua due volte un test per l’HIV.\nNotazione e dati iniziali.\nIndichiamo con:\n\n\n\\(M^+\\): la persona ha l’HIV;\n\n\\(M^-\\): la persona non ha l’HIV;\n\n\\(T^+\\): il test è positivo;\n\n\\(T^-\\): il test è negativo.\n\nAbbiamo inoltre i seguenti dati:\n\nPrevalenza (probabilità a priori di avere l’HIV):\\[\nP(M^+) = 0.003 \\quad (0.3\\%).\n\\]\nSensibilità del test (probabilità che il test sia positivo se la persona è malata):\\[\nP(T^+ \\mid M^+) = 0.95.\n\\]\nSpecificità del test (probabilità che il test sia negativo se la persona è sana):\\[\nP(T^- \\mid M^-) = 0.9928 \\quad \\Longrightarrow \\quad P(T^+ \\mid M^-) = 0.0072.\n\\]\n\nPasso 1: dopo il primo test positivo.\nUsiamo la regola di Bayes per aggiornare la probabilità di essere malati, dopo un primo risultato positivo:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+)P(M^+)}{P(T^+)}.\n\\]\nCalcoliamo la probabilità marginale di un test positivo, considerando entrambe le ipotesi:\n\\[\nP(T^+) = P(T^+ \\mid M^+)P(M^+) + P(T^+ \\mid M^-)P(M^-).\n\\]\nSostituendo i valori noti, otteniamo:\n\\[\nP(T^+) = (0.95 \\times 0.003) + (0.0072 \\times 0.997) = 0.00285 + 0.00718 = 0.01003.\n\\]\nLa probabilità aggiornata (posterior) diventa quindi:\n\\[\nP(M^+ \\mid T^+) = \\frac{0.00285}{0.01003} \\approx 0.2844 \\quad (28.44\\%).\n\\]\nDopo un primo test positivo, la probabilità che la persona sia effettivamente HIV-positiva sale da un valore iniziale molto basso (0.3%) a 28.44%, aumentando notevolmente ma senza ancora garantire la certezza.\nPasso 2: aggiornamento dopo un secondo test positivo.\nAdesso immaginiamo di ripetere il test e ottenere nuovamente un risultato positivo. La nuova probabilità si calcola applicando ancora la regola di Bayes, utilizzando come prior il risultato appena trovato:\n\\[\nP(M^+ \\mid T_1^+, T_2^+) = \\frac{P(T_2^+ \\mid M^+, T_1^+)P(M^+ \\mid T_1^+)}{P(T_2^+ \\mid T_1^+)}.\n\\]\nAssumendo che i risultati dei test siano indipendenti dato lo stato di malattia o meno, possiamo semplificare:\n\n\\(P(T_2^+ \\mid M^+, T_1^+) = P(T^+ \\mid M^+) = 0.95\\)\n\\(P(T_2^+ \\mid M^-, T_1^+) = P(T^+ \\mid M^-) = 0.0072\\)\n\nLa probabilità di ottenere un secondo test positivo diventa quindi:\n\\[\nP(T_2^+ \\mid T_1^+) = P(T^+ \\mid M^+)P(M^+ \\mid T_1^+) + P(T^+ \\mid M^-)P(M^- \\mid T_1^+).\n\\]\nSostituendo i valori numerici calcolati in precedenza:\n\\[\nP(T_2^+ \\mid T_1^+) = (0.95 \\times 0.2844) + (0.0072 \\times 0.7156) = 0.2702 + 0.00515 = 0.27535.\n\\]\nOra calcoliamo la nuova probabilità a posteriori dopo due test positivi:\n\\[\nP(M^+ \\mid T_1^+, T_2^+) = \\frac{0.95 \\times 0.2844}{0.27535} \\approx 0.981 \\quad (98.1\\%).\n\\]\nInterpretazione finale.\n\nDopo il primo test positivo, la probabilità passa dallo 0.3% iniziale a circa il 28.44%, aumentando notevolmente ma restando incerta.\nDopo il secondo test positivo, la probabilità sale drasticamente al 98.1%, rendendo quasi certa la diagnosi.\n\nQuesto esempio dimostra chiaramente il valore dell’aggiornamento bayesiano: un singolo risultato positivo incrementa la probabilità, ma in presenza di una bassa prevalenza non basta per una diagnosi certa. Ripetere il test e ottenere conferme successive permette invece di raggiungere una certezza diagnostica molto elevata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#la-fallacia-del-procuratore",
    "href": "chapters/probability/05_bayes_theorem.html#la-fallacia-del-procuratore",
    "title": "28  Il teorema di Bayes",
    "section": "\n28.3 La fallacia del procuratore",
    "text": "28.3 La fallacia del procuratore\nIl teorema di Bayes non trova applicazione solo in campo medico, ma è essenziale anche nei procedimenti giudiziari. Infatti, fraintendimenti nell’interpretazione di probabilità e statistiche possono portare a gravi errori di giudizio. Uno degli errori più comuni in questo contesto è la fallacia del procuratore.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nChe cos’è la fallacia del procuratore?\nLa fallacia del procuratore consiste nel confondere la probabilità di osservare una certa evidenza se una persona è innocente, \\(P(T^+ \\mid I)\\), con la probabilità che una persona sia innocente dopo aver osservato quella evidenza, \\(P(I \\mid T^+)\\).\n\nIn termini giudiziari, questo equivale a dire: “Poiché è estremamente improbabile ottenere un certo riscontro (ad es. un test positivo) se la persona è innocente, allora è estremamente improbabile che la persona sia innocente se si è ottenuto un esito positivo”.\nIn realtà, per stabilire se la persona è innocente o colpevole dopo aver visto il risultato, occorre considerare sia la bassa frequenza delle persone effettivamente colpevoli nella popolazione (prevalenza) sia la possibilità di falsi positivi. Il teorema di Bayes fornisce lo strumento formale per integrare questi elementi.\n\nConsideriamo il seguente esempio. Supponiamo di utilizzare un test del DNA per identificare un sospetto tra 65 milioni di persone. Il test ha:\n\n\nSensibilità (\\(P(T^+ \\mid C)\\)) = 99%\\(\\rightarrow\\) Se la persona è effettivamente colpevole, il test risulta positivo il 99% delle volte.\n\nSpecificità (\\(P(T^- \\mid I)\\)) = 99.99997%\\(\\rightarrow\\) Se la persona è innocente, il test risulta negativo il 99.99997% delle volte.\nDa cui segue che il tasso di falso positivo è \\(1 - 0.9999997 = 0.0000003 = 0.00003\\%\\).\n\nPrevalenza (\\(P(C)\\)) = \\(1/65{,}000{,}000 \\approx 1.54 \\times 10^{-8}\\)\\(\\rightarrow\\) Un individuo scelto a caso ha una probabilità di circa \\(1.54 \\times 10^{-8}\\) (cioè 1 su 65 milioni) di essere il vero colpevole.\n\nUn campione di DNA coincide con quello di una persona trovata nel database e il test dà risultato positivo. Qual è la probabilità che costui sia davvero colpevole? Formalmente, vogliamo \\(P(C \\mid T^+)\\).\nPasso 1: Calcolare \\(P(T^+)\\), la probabilità di un test positivo.\nLa probabilità complessiva di un esito positivo deriva da due scenari alternativi:\n\n\nLa persona è colpevole e il test è positivo:\\(P(T^+ \\mid C) \\times P(C)\\).\n\nLa persona è innocente e il test è positivo per errore (falso positivo):\\(P(T^+ \\mid I) \\times P(I)\\).\n\nPerciò, usando la regola della probabilità totale:\n\\[\nP(T^+)\n= P(T^+ \\mid C) \\, P(C) \\;+\\; P(T^+ \\mid I) \\, P(I).\n\\]\nAssegniamo i valori numerici:\n\n\n\\(P(T^+ \\mid C) = 0.99\\) (sensibilità).\n\n\\(P(C) = 1.54 \\times 10^{-8}\\).\n\n\\(P(T^+ \\mid I) = 1 - P(T^- \\mid I) = 1 - 0.9999997 = 0.0000003\\).\n\n\\(P(I) = 1 - P(C) \\approx 0.99999998\\).\n\nEseguiamo il calcolo:\n\\[\n\\begin{aligned}\nP(T^+)\n&= (0.99 \\times 1.54 \\times 10^{-8}) + (0.0000003 \\times 0.99999998)\\\\\n&= 1.5231 \\times 10^{-8} + 2.9999994 \\times 10^{-7}\\\\\n&= 3.1523 \\times 10^{-7}.\n\\end{aligned}\n\\]\nPasso 2: Applicare la regola di Bayes per \\(P(C \\mid T^+)\\).\nOra possiamo calcolare la probabilità di essere colpevoli dato che il test è positivo:\n\\[\nP(C \\mid T^+)\n= \\frac{P(T^+ \\mid C)\\,P(C)}{P(T^+)}.\n\\]\nInseriamo i valori:\n\\[\n\\begin{aligned}\nP(C \\mid T^+)\n&= \\frac{(0.99 \\times 1.54 \\times 10^{-8})}{3.1523 \\times 10^{-7}}\\\\\n&= \\frac{1.5231 \\times 10^{-8}}{3.1523 \\times 10^{-7}}\\\\\n&\\approx 0.0483 \\quad (\\text{cioè } 4.83\\%).\n\\end{aligned}\n\\]\nInterpretazione: perché è “solo” il 4.83%?\nSebbene sensibilità e specificità del test siano entrambe molto alte, la prevalenza estremamente bassa del colpevole (1 su 65 milioni) riduce notevolmente la probabilità a posteriori \\(P(C \\mid T^+)\\). In una popolazione di 65 milioni di individui, anche un esiguo tasso di falsi positivi (\\(0.0000003\\)) genera un numero assoluto di risultati positivi fra gli innocenti molto più grande del numero di colpevoli reali.\nIn pratica, pur avendo un test positivo, la probabilità che la persona sia davvero colpevole resta modesta (circa 4.83%), perché i “falsi allarmi” nella massa di individui innocenti superano di gran lunga i (pochi) veri positivi.\nEvitare la fallacia del procuratore.\nLa fallacia del procuratore consiste nel confondere:\n\n\n\\(P(T^+ \\mid I)\\): la probabilità che un innocente risulti positivo (falso positivo),\n\n\\(P(I \\mid T^+)\\): la probabilità di essere innocenti dopo un test positivo.\n\nQuesta confusione porta a sovrastimare la colpevolezza di un individuo basandosi su una singola evidenza statistica. Applicando il teorema di Bayes, invece, si comprende che un test positivo non implica automaticamente colpevolezza, soprattutto quando la malattia (o il reato, in questo caso) è molto raro. Nei processi giudiziari, ciò significa che un dato probabilistico deve sempre essere contestualizzato alla popolazione di riferimento: la corretta interpretazione delle prove è fondamentale per evitare errori giudiziari.\nConclusione epistemologica.\nL’impiego di test probabilistici in ambito giudiziario richiede un’applicazione rigorosa del teorema di Bayes per evitare distorsioni interpretative. Solo un corretto aggiornamento delle credenze, integrando:\n\n\nla probabilità pre-test (\\(P(C)\\), prevalenza del colpevole nella popolazione investigata),\n\n\nla potenza diagnostica del test (sensibilità e specificità),\n\n\nil tasso di errore strumentale (falsi positivi e falsi negativi),\n\nconsente di ridurre il rischio di errori giudiziari sistematici. In assenza di questa integrazione, anche test estremamente precisi possono condurre a ingiuste condanne, trasformando strumenti scientifici affidabili in fonti di distorsione probatoria.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#la-probabilità-inversa",
    "href": "chapters/probability/05_bayes_theorem.html#la-probabilità-inversa",
    "title": "28  Il teorema di Bayes",
    "section": "\n28.4 La probabilità inversa",
    "text": "28.4 La probabilità inversa\nGli esempi precedenti mostrano due tipi di domande probabilistiche fondamentali:\n\n\nProbabilità diretta\n\n“Qual è la probabilità di osservare un certo risultato, supponendo che l’ipotesi sia vera?”\n\n\n\nProbabilità inversa\n\n“Qual è la probabilità che un’ipotesi sia vera, dati i risultati osservati?”\n\n\n\nQuesta distinzione è cruciale per comprendere il teorema di Bayes e le differenze tra l’approccio frequentista e quello bayesiano alla probabilità.\n\n28.4.1 Esempi\nPrendiamo come esempio il lancio di una moneta:\n\nProbabilità diretta:\nSe riteniamo che la moneta sia equa (cioè \\(P(\\text{Testa}) = 0{.}5\\)), qual è la probabilità di osservare zero teste in cinque lanci? In questo caso, stiamo calcolando \\[\nP(D \\mid H) = (0.5)^5 = 0.03125,\n\\] dove \\(D\\) rappresenta il dato (“zero teste in cinque lanci”) e \\(H\\) l’ipotesi (“la moneta è equa”).\nProbabilità inversa:\nOra poniamo la domanda opposta. Abbiamo lanciato una moneta cinque volte e osservato zero teste. Quanto è probabile che la moneta sia davvero equa? Qui vogliamo conoscere \\(\\displaystyle P(H \\mid D)\\) (l’ipotesi “la moneta è equa” dopo aver visto il risultato) anziché \\(P(D \\mid H)\\). Per rispondere correttamente, ci occorre il teorema di Bayes, che combina la probabilità dei dati (\\(P(D \\mid H)\\)) con una stima iniziale (il prior) su quanto riteniamo probabile l’ipotesi prima dell’osservazione.\n\n28.4.2 Dalla probabilità diretta alla probabilità inversa: il contributo di Bayes\nPer lungo tempo, la teoria della probabilità si è occupata quasi esclusivamente di probabilità diretta: “se l’ipotesi è vera, qual è la probabilità di osservare un certo esito?”. Nel XVIII secolo, Thomas Bayes capovolse la prospettiva, concentrandosi su come determinare la probabilità dell’ipotesi a partire dalle evidenze disponibili, introdusse cioè l’idea di probabilità inversa. Questa svolta ha aperto la strada a ciò che oggi chiamiamo inferenza bayesiana, permettendo di aggiornare in modo sistematico e rigoroso la credibilità di un’ipotesi dopo aver osservato nuovi dati.\n\n28.4.3 L’impatto della probabilità inversa\nLa possibilità di stimare \\(\\displaystyle P(H \\mid D)\\), cioè la probabilità di un’ipotesi data l’evidenza osservata, si è rivelata fondamentale in molti ambiti:\n\n\nScienza e sperimentazione: quanto è probabile che un’ipotesi sia vera dopo aver raccolto i dati di un esperimento?\n\n\nMedicina: quanto è probabile che un paziente abbia una certa malattia, se il test diagnostico è positivo?\n\n\nGiustizia: quanto è probabile che una persona sia colpevole, se il DNA trovato sulla scena del crimine combacia col suo?\n\nIn tutti questi casi non basta calcolare la probabilità dei dati “dato un’ipotesi” \\(\\bigl(P(D \\mid H)\\bigr)\\); occorre invece aggiornare la stima della probabilità dell’ipotesi alla luce dei dati \\(\\bigl(P(H \\mid D)\\bigr)\\).\nIn sintesi, l’inferenza bayesiana risponde appunto a questa seconda domanda, passando dalla probabilità diretta alla probabilità inversa in modo rigoroso. Grazie al teorema di Bayes, possiamo combinare in modo coerente le nostre conoscenze pregresse (il cosiddetto prior) con le evidenze raccolte, ottenendo una probabilità a posteriori che rappresenta la nostra nuova convinzione. Senza questa prospettiva, gran parte dei problemi scientifici e delle decisioni pratiche resterebbe priva di un metodo per collegare razionalmente le evidenze empiriche alle ipotesi da verificare.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#riflessioni-conclusive",
    "href": "chapters/probability/05_bayes_theorem.html#riflessioni-conclusive",
    "title": "28  Il teorema di Bayes",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo esplorato vari esempi, principalmente nel campo medico e forense, per illustrare come il teorema di Bayes permetta di combinare le informazioni derivate dalle osservazioni con le conoscenze precedenti (priori), aggiornando così il nostro grado di convinzione rispetto a un’ipotesi. Il teorema di Bayes fornisce un meccanismo razionale, noto come “aggiornamento bayesiano”, che ci consente di ricalibrare le nostre convinzioni iniziali alla luce di nuove evidenze.\nUna lezione fondamentale che il teorema di Bayes ci insegna, sia nella ricerca scientifica che nella vita quotidiana, è che spesso non ci interessa tanto conoscere la probabilità che qualcosa accada assumendo vera un’ipotesi, quanto piuttosto la probabilità che un’ipotesi sia vera, dato che abbiamo osservato una certa evidenza. In altre parole, la forza del teorema di Bayes sta nella sua capacità di affrontare direttamente il problema inverso, cioè come dedurre la verità di un’ipotesi a partire dalle osservazioni.\nIl framework bayesiano per l’inferenza probabilistica offre un approccio generale per comprendere come i problemi di induzione possano essere risolti in linea di principio e, forse, anche come possano essere affrontati dalla mente umana.\nIn questo capitolo ci siamo concentrati sull’applicazione del teorema di Bayes utilizzando probabilità puntuali. Tuttavia, il teorema esprime pienamente il suo potenziale quando sia l’evidenza che i gradi di certezza a priori delle ipotesi sono rappresentati attraverso distribuzioni di probabilità continue. Questo sarà l’argomento centrale nella prossima sezione della dispensa, dove approfondiremo il flusso di lavoro bayesiano e l’uso di distribuzioni continue nell’aggiornamento bayesiano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#esercizi",
    "href": "chapters/probability/05_bayes_theorem.html#esercizi",
    "title": "28  Il teorema di Bayes",
    "section": "Esercizi",
    "text": "Esercizi\nÈ facile trovare online esercizi sull’applicazione del teorema di Bayes. Ad esempio, consiglio gli esercizi 1–6 disponibili sulla seguente pagina web.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [19] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [22] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [25] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [28] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [31] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [34] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [37] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [40] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [43] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#&gt; [46] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [49] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [52] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [55] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [58] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [61] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [64] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [67] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#&gt; [70] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [73] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#bibliografia",
    "href": "chapters/probability/05_bayes_theorem.html#bibliografia",
    "title": "28  Il teorema di Bayes",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, C., Saxe, R., & Tenenbaum, J. (2011). Bayesian theory of mind: Modeling joint belief-desire attribution. Proceedings of the annual meeting of the cognitive science society, 33.\n\n\nBellhouse, D. R. (2004). The Reverend Thomas Bayes, FRS: a biography to celebrate the tercentenary of his birth.\n\n\nCaudek, C., & Bruno, N. (2024). Fenomeni stereocinetici, teorie della percezione e sociologia della scienza. Giornale italiano di psicologia, 51(3), 451–466.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nDomini, F., & Caudek, C. (2003). 3-D structure perceived from dynamic information: A new theory. Trends in Cognitive Sciences, 7(10), 444–449.\n\n\nGriffiths, T. L., Chater, N., & Tenenbaum, J. B. (2024). Bayesian models of cognition: reverse engineering the mind. MIT Press.\n\n\nJesseph, D. M. (1993). Berkeley’s philosophy of mathematics. University of Chicago Press.\n\n\nMa, W. J., Kording, K. P., & Goldreich, D. (2023). Bayesian models of perception and action: An introduction. MIT press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nSpiegelhalter, D. (2019). The art of statistics: Learning from data. Penguin UK.\n\n\nStigler, S. M. (1990). The history of statistics: The measurement of uncertainty before 1900. Harvard University Press.\n\n\nYuille, A., & Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in cognitive sciences, 10(7), 301–308.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html",
    "href": "chapters/probability/06_random_var.html",
    "title": "29  Variabili casuali",
    "section": "",
    "text": "Introduzione\nFino ad ora abbiamo studiato le probabilità associate a eventi, come la possibilità di vincere il gioco di Monty Hall o di avere una rara condizione medica in seguito a un test positivo. Tuttavia, in molte situazioni pratiche vogliamo conoscere aspetti più dettagliati. Ad esempio, potremmo chiederci:\nPer rispondere a tali domande è necessario lavorare con le variabili casuali. In questo capitolo introdurremo il concetto di variabile casuale e ne analizzeremo le proprietà fondamentali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#introduzione",
    "href": "chapters/probability/06_random_var.html#introduzione",
    "title": "29  Variabili casuali",
    "section": "",
    "text": "quanti tentativi occorrono affinché, in un gioco simile a Monty Hall, un concorrente vinca?\nquanto durerà un determinato evento o condizione?\nqual è la perdita attesa giocando d’azzardo con un dado sbilanciato per molte ore?\n\n\nPanoramica del capitolo\n\nLe definizioni e le caratteristiche delle variabili casuali discrete e continue, e le relative distribuzioni di probabilità;\nCome calcolare e interpretare il valore atteso di variabili casuali, sia discrete che continue.\nDeterminare e comprendere la varianza e la deviazione standard di variabili casuali.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\nPer seguire al meglio questo capitolo, è consigliato aver letto i seguenti riferimenti:\n\nl’appendice Appendice I;\nil capitolo Random Variables and Probability Distributions in Chan & Kroese (2025);\nil capitolo Random variables and their distributions in Blitzstein & Hwang (2019);\n\nil capitolo Random Variables and Distributions in Schervish & DeGroot (2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#definizione-di-variabile-casuale",
    "href": "chapters/probability/06_random_var.html#definizione-di-variabile-casuale",
    "title": "29  Variabili casuali",
    "section": "\n29.1 Definizione di variabile casuale",
    "text": "29.1 Definizione di variabile casuale\nUna variabile casuale è una funzione che associa ogni elemento di uno spazio campionario a un valore numerico. Questo strumento permette di trasformare esiti qualitativi (ad esempio, il risultato di un lancio di carte, come cuori, quadri, fiori, picche) in valori numerici, facilitando così l’analisi matematica.\n\nDefinizione 29.1 Sia \\(S\\) lo spazio campionario di un esperimento aleatorio. Una variabile casuale \\(X\\) è una funzione\\[\nX: S \\longrightarrow \\mathbb{R},\n\\] che associa ad ogni esito \\(s \\in S\\) un numero reale \\(X(s)\\).\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nLanciamo due dadi equilibrati e annotiamo la somma dei valori delle loro facce. Ogni lancio genera una coppia di valori \\((i,j)\\), dove \\(i\\) è il risultato del primo dado e \\(j\\) il risultato del secondo dado. Lo spazio campionario completo dei possibili esiti è:\n\\[\n\\Omega = \\{(1,1), (1,2), \\dots, (6,5), (6,6)\\}.\n\\]\nDefiniamo una variabile casuale \\(X\\) che associa ciascun esito \\((i,j)\\) alla somma dei valori ottenuti dai due dadi, cioè:\n\\[\nX(i,j) = i + j.\n\\]\nAd esempio, se il primo dado mostra 4 e il secondo dado mostra 4, allora l’esito è \\((4,4)\\) e la variabile casuale \\(X\\) assume il valore 8.\n\n\nLa variabile aleatoria \\(X\\) rappresenta la somma di due dadi (figura tratta da Chan & Kroese, 2025).\n\nConsideriamo il valore specifico \\(X=8\\): questo valore può essere ottenuto attraverso cinque diversi esiti dello spazio campionario: \\((2,6), (3,5), (4,4), (5,3), (6,2)\\). Indichiamo con \\(\\{X=8\\}\\) l’insieme di questi esiti. Poiché tutti gli esiti in \\(\\Omega\\) sono equiprobabili, possiamo calcolare la probabilità di ottenere una somma pari a 8 come:\n\\[\nP(X=8) = \\frac{5}{36}.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#tipologie-di-variabili-casuali",
    "href": "chapters/probability/06_random_var.html#tipologie-di-variabili-casuali",
    "title": "29  Variabili casuali",
    "section": "\n29.2 Tipologie di variabili casuali",
    "text": "29.2 Tipologie di variabili casuali\nLe variabili casuali si dividono in due categorie principali:\n\n29.2.1 Variabili casuali discrete\nUna variabile casuale discreta assume un insieme finito o numerabile di valori. Gli esempi includono il numero di teste ottenute in lanci di moneta o la somma dei risultati di due dadi. Per queste variabili, la funzione di massa di probabilità (PMF) assegna a ciascun valore \\(x\\) la probabilità \\(P(X = x)\\).\n\nEsempio 29.1 Nel lancio di due dadi, la variabile \\(X\\) (somma dei punti) può assumere valori interi da 2 a 12. La distribuzione di \\(X\\) si ottiene contando i casi favorevoli per ciascun valore e dividendo per il numero totale di esiti (36).\n\n\n29.2.2 Variabili casuali continue\nUna variabile casuale continua può assumere infiniti valori in un intervallo (ad esempio, l’altezza di una persona). In questo caso non si assegna una probabilità a un singolo valore (che risulterebbe essere zero), ma si definisce una funzione di densità di probabilità (PDF), tale che l’integrale della funzione su un intervallo fornisce la probabilità che la variabile cada in quell’intervallo.\n\nEsempio 29.2 Considera una variabile \\(X\\) che rappresenta l’altezza in centimetri. Invece di \\(P(X = 170)\\), calcoliamo probabilità come \\(P(170 \\leq X \\leq 180)\\) mediante l’integrale della PDF in quell’intervallo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#notazione-convenzionale",
    "href": "chapters/probability/06_random_var.html#notazione-convenzionale",
    "title": "29  Variabili casuali",
    "section": "\n29.3 Notazione convenzionale",
    "text": "29.3 Notazione convenzionale\nNella teoria della probabilità si adotta una convenzione chiara per distinguere una variabile casuale dal suo valore osservato o realizzato:\n\nla variabile casuale viene indicata con lettere maiuscole (es. \\(X\\));\nil valore specifico assunto dalla variabile casuale viene indicato con lettere minuscole (es. \\(x\\)).\n\nQuesta convenzione aiuta a evitare ambiguità, soprattutto quando si definiscono:\n\nprobabilità cumulative: \\(P(X \\leq x)\\);\nvalore atteso: \\(E[X]\\);\nfunzioni di densità o massa di probabilità: \\(f_X(x)\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#variabili-casuali-multiple",
    "href": "chapters/probability/06_random_var.html#variabili-casuali-multiple",
    "title": "29  Variabili casuali",
    "section": "\n29.4 Variabili casuali multiple",
    "text": "29.4 Variabili casuali multiple\nIn molti esperimenti, è utile considerare contemporaneamente più variabili casuali. Ad esempio, supponiamo di lanciare una moneta equilibrata tre volte. Definiamo tre variabili casuali indipendenti \\(X_1\\), \\(X_2\\) e \\(X_3\\), ciascuna associata all’esito di un lancio:\n\\[\nP(X_n = 1) = 0.5 \\quad (\\text{testa}), \\qquad P(X_n = 0) = 0.5 \\quad (\\text{croce}), \\quad n = 1, 2, 3.\n\\]\nPossiamo poi definire una nuova variabile casuale derivata, ad esempio:\n\\[\nZ = X_1 + X_2 + X_3,\n\\]\nche rappresenta il numero totale di teste ottenute nei tre lanci. In questo scenario, \\(Z\\) è una variabile casuale discreta che può assumere esclusivamente i valori 0, 1, 2 o 3.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#distribuzione-di-probabilità",
    "href": "chapters/probability/06_random_var.html#distribuzione-di-probabilità",
    "title": "29  Variabili casuali",
    "section": "\n29.5 Distribuzione di probabilità",
    "text": "29.5 Distribuzione di probabilità\n\nDefinizione 29.2 La distribuzione di probabilità di una variabile casuale descrive come le probabilità sono assegnate ai possibili valori (o intervalli di valori) della variabile.\n\n\n29.5.1 Funzione di massa di probabilità (PMF) per variabili discrete\nPer una variabile casuale discreta \\(X\\), la distribuzione è definita tramite la funzione di massa di probabilità (PMF), indicata con \\(f(x)\\), dove:\n\\[\nf(x) = P(X = x).\n\\]\nNota la PMF, è possibile calcolare la probabilità di qualsiasi evento associato a \\(X\\). Ad esempio, per un insieme \\(B\\) di valori:\n\\[\nP(X \\in B) = \\sum_{x \\in B} f(x).\n\\]\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nConsideriamo nuovamente il lancio di due dadi, definendo \\(X\\) come la somma dei loro valori. La tabella seguente mostra chiaramente tutti i casi possibili, il numero di combinazioni per ogni somma, e la relativa probabilità:\n\n\n\n\n\n\n\n\n\\(X\\)\nCasi Favorevoli\nNumero di Casi\n\\(P(X = x)\\)\n\n\n\n2\n\\((1,1)\\)\n1\n\\(\\frac{1}{36}\\)\n\n\n3\n\\((1,2), (2,1)\\)\n2\n\\(\\frac{2}{36} = \\frac{1}{18}\\)\n\n\n4\n\\((1,3), (2,2), (3,1)\\)\n3\n\\(\\frac{3}{36} = \\frac{1}{12}\\)\n\n\n5\n\\((1,4), (2,3), (3,2), (4,1)\\)\n4\n\\(\\frac{4}{36} = \\frac{1}{9}\\)\n\n\n6\n\\((1,5), (2,4), (3,3), (4,2), (5,1)\\)\n5\n\\(\\frac{5}{36}\\)\n\n\n7\n\\((1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\\)\n6\n\\(\\frac{6}{36} = \\frac{1}{6}\\)\n\n\n8\n\\((2,6), (3,5), (4,4), (5,3), (6,2)\\)\n5\n\\(\\frac{5}{36}\\)\n\n\n9\n\\((3,6), (4,5), (5,4), (6,3)\\)\n4\n\\(\\frac{4}{36} = \\frac{1}{9}\\)\n\n\n10\n\\((4,6), (5,5), (6,4)\\)\n3\n\\(\\frac{3}{36} = \\frac{1}{12}\\)\n\n\n11\n\\((5,6), (6,5)\\)\n2\n\\(\\frac{2}{36} = \\frac{1}{18}\\)\n\n\n12\n\\((6,6)\\)\n1\n\\(\\frac{1}{36}\\)\n\n\n\nPer esempio, la probabilità di ottenere una somma pari a 7 è \\(\\frac{1}{6}\\) perché ci sono 6 combinazioni favorevoli su 36 possibili.\n\n\n\n\n29.5.2 Funzione di distribuzione cumulativa (CDF)\n\nDefinizione 29.3 La funzione di distribuzione cumulativa (CDF) di una variabile casuale \\(X\\) è definita come: \\[\nF(x) = P(X \\leq x).\n\\] La CDF indica la probabilità che \\(X\\) assuma valori minori o uguali a un valore specifico \\(x\\).\n\n\n29.5.3 Proprietà della CDF (funzione di ripartizione)\nLa CDF descrive la probabilità che una variabile casuale \\(X\\) assuma un valore minore o uguale a \\(x\\). Per capirla in psicologia (ad esempio, per analizzare dati di test, questionari, o esperimenti), bastano tre idee chiave:\n\n\nNon diminuisce mai:\nSe consideriamo valori \\(x\\) sempre più grandi, la probabilità cumulata non può diminuire.\n\n\nEsempio: Se la CDF a \\(x = 50\\) in un test è \\(0.7\\), a \\(x = 60\\) sarà almeno \\(0.7\\) (potrebbe salire, ma non scendere).\n\n\nPerché? Aggiungendo nuovi risultati (es.: punteggi più alti), la probabilità totale può solo aumentare o restare uguale.\n\n\n\nEstremi prevedibili:\n\nPer valori molto bassi (es.: \\(x \\to -\\infty\\)), la probabilità cumulata è 0: non esistono punteggi infinitamente bassi.\n\nPer valori molto alti (es.: \\(x \\to +\\infty\\)), la probabilità cumulata è 1: tutti i possibili risultati sono inclusi.\n\n\nEsempio: In una scala Likert da 1 a 5, la CDF a \\(x = 0\\) è 0, e a \\(x = 10\\) è 1.\n\n\n\nNiente salti “a sorpresa” verso destra:\nLa CDF è costruita in modo che, se ci spostiamo di pochissimo a destra di un punto \\(x\\), la probabilità cumulata non crolla improvvisamente.\n\n\nEsempio:\nSupponiamo che in un questionario, il punteggio \\(x = 10\\) corrisponda a una certa probabilità cumulata (es.: \\(0.8\\)). Se ci spostiamo di un millesimo a destra (es.: \\(x = 10.001\\)), la probabilità rimane \\(0.8\\), a meno che \\(10.001\\) non sia un punteggio valido.\n\n\nA cosa serve? Garantisce coerenza: se un punteggio \\(x\\) ha una certa probabilità, questa non viene “persa” spostandosi di poco a destra.\n\n\n\n29.5.4 CDF per variabili discrete\nIn psicologia, spesso lavoriamo con dati discreti (es.: risposte a item di un test, come “1 = Mai” a “5 = Sempre”). In questi casi:\n\nLa CDF si calcola sommando le probabilità di tutti i valori \\(\\leq x\\).\n\n\nEsempio: Se in una scala da 1 a 5, il 30% degli studenti risponde 1 o 2, allora \\(F(2) = 0.3\\).\n\n\nGraficamente: La CDF avrà “gradini” nei punti corrispondenti ai valori possibili (es.: 1, 2, 3, 4, 5).\n\n\n29.5.4.1 Perché serve saperlo?\nQueste proprietà aiutano a:\n\nInterpretare grafici cumulativi (es.: quanto è probabile che un partecipante abbia un punteggio \\(\\leq\\) 20?).\n\nEvitare errori logici (es.: non ha senso aspettarsi un calo della probabilità cumulata all’aumentare di \\(x\\)).\n\nLeggere correttamente salti nei dati discreti (es.: un gradino in \\(x = 4\\) indica un accumulo di probabilità in quel punto).\n\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nRiprendendo l’esempio della variabile casuale \\(X\\) definita come la somma di due dadi, possiamo riassumere PMF e CDF in una tabella unica:\n\n\n\\(x\\)\n\\(P(X = x)\\)\n\\(F(x)\\)\n\n\n\n2\n\\(\\frac{1}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n3\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\n\n4\n\\(\\frac{3}{36}\\)\n\\(\\frac{6}{36}\\)\n\n\n5\n\\(\\frac{4}{36}\\)\n\\(\\frac{10}{36}\\)\n\n\n6\n\\(\\frac{5}{36}\\)\n\\(\\frac{15}{36}\\)\n\n\n7\n\\(\\frac{6}{36}\\)\n\\(\\frac{21}{36}\\)\n\n\n8\n\\(\\frac{5}{36}\\)\n\\(\\frac{26}{36}\\)\n\n\n9\n\\(\\frac{4}{36}\\)\n\\(\\frac{30}{36}\\)\n\n\n10\n\\(\\frac{3}{36}\\)\n\\(\\frac{33}{36}\\)\n\n\n11\n\\(\\frac{2}{36}\\)\n\\(\\frac{35}{36}\\)\n\n\n12\n\\(\\frac{1}{36}\\)\n\\(1\\)\n\n\n\n\n\n\n\n29.5.5 Simulazione della distribuzione di probabilità\nSpesso, anche se è possibile calcolare analiticamente la distribuzione di probabilità (come nel caso dei due dadi), può essere utile ottenere una stima empirica attraverso la simulazione. Questo approccio prevede di ripetere l’esperimento molte volte e di analizzare le frequenze relative dei risultati ottenuti.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nSimulazione del lancio di due dadi in R.\n1. Simulare il lancio di un singolo dado\n\n# Funzione per simulare un dado a sei facce\nlancia_dado &lt;- function() {\n  sample(1:6, 1)\n}\n\n2. Simulare il lancio di due dadi\n\n# Funzione per simulare il lancio di due dadi ripetuto n volte\nlancia_due_dadi &lt;- function(n) {\n  risultati &lt;- numeric(n)\n  \n  for (i in 1:n) {\n    risultati[i] &lt;- lancia_dado() + lancia_dado()\n  }\n  \n  risultati\n}\n\n3. Eseguire la simulazione\n\n# Numero totale di simulazioni\nnumero_lanci &lt;- 100000\n\n# Simulazione dei lanci\nrisultati_simulazione &lt;- lancia_due_dadi(numero_lanci)\n\n# Visualizza i primi 20 risultati\ncat(\"Primi 20 risultati:\", risultati_simulazione[1:20], \"\\n\")\n#&gt; Primi 20 risultati: 5 5 7 8 8 8 7 5 10 7 5 3 6 10 5 3 2 5 4 4\n\n4. Calcolare e visualizzare la distribuzione empirica\n\n# Calcola la frequenza assoluta per ciascuna somma\nfrequenze_assolute &lt;- table(risultati_simulazione)\nfrequenze_assolute\n#&gt; risultati_simulazione\n#&gt;     2     3     4     5     6     7     8     9    10    11    12 \n#&gt;  2870  5621  8181 10878 13888 16636 13892 11164  8376  5674  2820\n\n# Calcola direttamente le frequenze relative (probabilità empiriche)\nprobabilita_empiriche &lt;- frequenze_assolute / numero_lanci\nprobabilita_empiriche\n#&gt; risultati_simulazione\n#&gt;      2      3      4      5      6      7      8      9     10     11     12 \n#&gt; 0.0287 0.0562 0.0818 0.1088 0.1389 0.1664 0.1389 0.1116 0.0838 0.0567 0.0282\n\n# Crea una tabella finale chiara e semplice\ndistribuzione_empirica &lt;- data.frame(\n  Somma = as.numeric(names(probabilita_empiriche)),\n  Probabilita = as.vector(probabilita_empiriche)\n)\n\n# Mostra la distribuzione empirica\nprint(distribuzione_empirica)\n#&gt;    Somma Probabilita\n#&gt; 1      2      0.0287\n#&gt; 2      3      0.0562\n#&gt; 3      4      0.0818\n#&gt; 4      5      0.1088\n#&gt; 5      6      0.1389\n#&gt; 6      7      0.1664\n#&gt; 7      8      0.1389\n#&gt; 8      9      0.1116\n#&gt; 9     10      0.0838\n#&gt; 10    11      0.0567\n#&gt; 11    12      0.0282\n\nChiarimento sintetico dei concetti chiave.\n\nCos’è una simulazione?\nÈ un esperimento realizzato al computer che replica più volte un evento casuale per osservare i possibili risultati e la loro frequenza.\nDistribuzione empirica\nÈ la frequenza con cui ogni risultato (in questo caso, la somma di due dadi) appare nella simulazione. Con più simulazioni, questa distribuzione si avvicina sempre di più a quella prevista dalla teoria.\nProbabilità teorica ed empirica\nLa probabilità teorica è calcolata matematicamente: ad esempio, la somma “7” è teoricamente più frequente perché ci sono più modi di ottenerla (6+1, 5+2, 4+3, ecc.).\nLa probabilità empirica, invece, si ottiene dalla simulazione pratica, ed è una buona approssimazione della probabilità teorica quando il numero di prove è grande.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#distribuzioni-per-variabili-continue",
    "href": "chapters/probability/06_random_var.html#distribuzioni-per-variabili-continue",
    "title": "29  Variabili casuali",
    "section": "\n29.6 Distribuzioni per variabili continue",
    "text": "29.6 Distribuzioni per variabili continue\n\nDefinizione 29.4 Una variabile casuale continua è una variabile aleatoria \\(X\\) caratterizzata da una distribuzione di probabilità continua. Formalmente, \\(X\\) si definisce continua se soddisfa le seguenti proprietà:\n\n\nEsistenza della funzione di densità (pdf):\nEsiste una funzione non negativa \\(f(x)\\), detta funzione di densità di probabilità (pdf, dall’inglese probability density function), tale che:\n\n\n\\(f(x) \\geq 0\\) per ogni \\(x \\in \\mathbb{R}\\);\n\nL’area totale sotto la curva di \\(f(x)\\) è pari a 1:\\[\n\\int_{-\\infty}^{+\\infty} f(x) \\, dx = 1.\n\\]\n\n\n\n\nCalcolo delle probabilità tramite integrazione:\nPer ogni intervallo \\((a, b] \\subseteq \\mathbb{R}\\) (con \\(a &lt; b\\)), la probabilità che \\(X\\) assuma valori in \\((a, b]\\) è data dall’integrale della pdf su tale intervallo:\n\\[\nP(a &lt; X \\leq b) = \\int_{a}^{b} f(x) \\, dx.\n\\]\nQuesta probabilità coincide anche con la differenza della funzione di ripartizione (CDF, cumulative distribution function) \\(F(x) = P(X \\leq x)\\) agli estremi dell’intervallo:\n\\[\nP(a &lt; X \\leq b) = F(b) - F(a).\n\\]\n\n\n\n\n29.6.1 Proprietà chiave delle variabili continue\n\n\nProbabilità in un punto nulla:\nA differenza delle variabili discrete, per una variabile continua la probabilità di assumere un valore esatto \\(x_0\\) è sempre zero:\n\\[\nP(X = x_0) = 0.\n\\]\nQuesto avviene perché la probabilità è legata all’area sotto la curva \\(f(x)\\), e un singolo punto ha “larghezza zero”, risultando in un’area nulla. Di conseguenza, per variabili continue:\n\\[\nP(a \\leq X \\leq b) = P(a &lt; X \\leq b) = P(a \\leq X &lt; b) = P(a &lt; X &lt; b).\n\\]\n\nInterpretazione della densità:\nLa funzione \\(f(x)\\) non rappresenta direttamente una probabilità, ma descrive come la probabilità si distribuisce nello spazio campionario. Valori maggiori di \\(f(x)\\) indicano regioni in cui è più probabile che \\(X\\) assuma valori (densità di probabilità).\nModellizzazione di fenomeni continui:\nLe distribuzioni continue sono utilizzate per rappresentare grandezze misurabili con precisione arbitraria, come tempo, lunghezze, o temperature. Esempi comuni includono la distribuzione normale, esponenziale e uniforme continua.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#riflessioni-conclusive",
    "href": "chapters/probability/06_random_var.html#riflessioni-conclusive",
    "title": "29  Variabili casuali",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo introdotto e approfondito il concetto fondamentale di variabile casuale, illustrando come questo strumento permetta di formalizzare e analizzare matematicamente fenomeni casuali complessi. Attraverso esempi intuitivi, come il lancio di dadi o la simulazione di situazioni reali, abbiamo osservato come le variabili casuali consentano di tradurre domande astratte in analisi concrete e interpretabili.\nAbbiamo esaminato le due principali tipologie di variabili casuali—discrete e continue—e discusso le relative distribuzioni di probabilità. Le distribuzioni discrete, caratterizzate da una funzione di massa di probabilità (PMF), si prestano particolarmente bene a modellare situazioni in cui gli eventi possono essere enumerati (come punteggi in test psicologici o risultati di giochi). Al contrario, le distribuzioni continue, descritte dalla funzione di densità di probabilità (PDF), sono essenziali per modellare misure precise, come l’altezza o il tempo, dove il numero di possibili valori è teoricamente infinito.\nUn aspetto importante trattato è la funzione di distribuzione cumulativa (CDF), che fornisce una descrizione completa della distribuzione di una variabile casuale, facilitando la comprensione intuitiva della probabilità che un evento accada entro certi limiti. Conoscere le proprietà della CDF aiuta a prevenire errori comuni nella sua interpretazione e a trarre conclusioni più affidabili dai dati empirici.\nInfine, attraverso l’utilizzo della simulazione, abbiamo mostrato come sia possibile avvicinarsi empiricamente a una distribuzione teorica, confermando e visualizzando in modo pratico e immediato concetti astratti. Questa capacità di simulare e verificare empiricamente le distribuzioni è estremamente utile, soprattutto quando i modelli teorici diventano troppo complessi da risolvere analiticamente.\nNei prossimi capitoli approfondiremo ulteriormente questi concetti, esaminando alcune distribuzioni di probabilità specifiche che sono comunemente usate nella ricerca psicologica e nelle applicazioni pratiche. Questo ci permetterà di passare da una conoscenza teorica delle variabili casuali a una competenza concreta nel loro utilizzo e nella loro interpretazione, sviluppando strumenti che miglioreranno le nostre capacità di analisi e di decisione in ambito psicologico e statistico.\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nConsiglio gli esercizi di base disponibili nella seguente pagina web.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizi sulla distribuzione normale, risolvibili usando R, sono disponibili sulla seguente pagina web.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [19] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [22] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [25] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [28] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [31] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [34] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [37] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [40] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [43] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#&gt; [46] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [49] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [52] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [55] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [58] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [61] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [64] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [67] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#&gt; [70] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [73] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#bibliografia",
    "href": "chapters/probability/06_random_var.html#bibliografia",
    "title": "29  Variabili casuali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html",
    "href": "chapters/probability/07_prob_distributions.html",
    "title": "30  Distribuzioni di massa e di densità",
    "section": "",
    "text": "Introduzione\nNel Capitolo 29 abbiamo introdotto il concetto di variabile casuale, distinguendo tra variabili casuali discrete e continue. Per le prime, abbiamo descritto formalmente come assegnare una distribuzione di massa di probabilità, mentre per le seconde abbiamo introdotto la nozione di funzione di densità di probabilità. Fino a questo punto, i concetti di distribuzione di massa e densità sono stati trattati in termini prevalentemente formali e matematici.\nLo scopo di questo capitolo è quello di approfondire queste idee, fornendo un’interpretazione più intuitiva e concreta di tali concetti. Attraverso esempi ed analisi pratiche, cercheremo di chiarire il significato sottostante alle distribuzioni di probabilità, rendendo più accessibili queste fondamentali strutture della teoria delle probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html#introduzione",
    "href": "chapters/probability/07_prob_distributions.html#introduzione",
    "title": "30  Distribuzioni di massa e di densità",
    "section": "",
    "text": "Panoramica del capitolo\n\nLa variabilità di variabili discrete e continue.\n\nLa differenza tra massa di probabilità (distribuzioni discrete) e densità di probabilità (distribuzioni continue).\n\nPerché, per una variabile continua, la probabilità di osservare un valore esatto è pari a zero.\n\nDagli istogrammi alle funzioni di densità di probabilità.\n\nLa funzione di ripartizione.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Random variables and their distributions del testo di Blitzstein & Hwang (2019).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html#variabili-casuali-discrete-e-continue",
    "href": "chapters/probability/07_prob_distributions.html#variabili-casuali-discrete-e-continue",
    "title": "30  Distribuzioni di massa e di densità",
    "section": "\n30.1 Variabili casuali discrete e continue",
    "text": "30.1 Variabili casuali discrete e continue\nUn elemento fondamentale nella comprensione delle distribuzioni di probabilità è la distinzione tra variabili casuali discrete e continue, poiché le distribuzioni di probabilità associate differiscono in modo sostanziale.\n\n\nVariabili casuali discrete: assumono un numero finito o numerabile di valori. Ad esempio, il numero di successi in una serie di esperimenti o il risultato del lancio di un dado.\n\nVariabili casuali continue: possono assumere un numero infinito di valori all’interno di un intervallo. Esempi includono il tempo di attesa per un evento o il quoziente intellettivo (QI) di una persona.\n\nQuesta distinzione è fondamentale perché le relative distribuzioni probabilistiche si comportano in modi diversi.\n\n30.1.1 Distribuzioni di probabilità discrete\nLe distribuzioni di probabilità discrete descrivono fenomeni aleatori con un numero finito o numerabile di esiti possibili. Queste distribuzioni sono rappresentate da una funzione di massa di probabilità (PMF), che assegna una probabilità a ciascun valore della variabile casuale.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo un dado sbilanciato con la seguente distribuzione di probabilità:\n\n\nValore di \\(X\\)\n\nProbabilità \\(p(x)\\)\n\n\n\n\n1\n0.10\n\n\n2\n0.15\n\n\n3\n0.20\n\n\n4\n0.25\n\n\n5\n0.20\n\n\n6\n0.10\n\n\n\nQuesta tabella rappresenta la funzione di massa di probabilità (PMF).\nPer visualizzare questa distribuzione, possiamo simulare 1000 lanci del dado e creare un diagramma a barre che rappresenta le frequenze relative osservate. In R:\n\n# Dati\nset.seed(123)\nprob &lt;- c(0.10, 0.15, 0.20, 0.25, 0.20, 0.10)\nlanci &lt;- sample(1:6, size = 1000, replace = TRUE, prob = prob)\n\n# Creazione di un data frame\ndf &lt;- data.frame(Valore = factor(lanci))\n\n# Creazione del diagramma a barre\nggplot(df, aes(x = Valore)) +\n  geom_bar(aes(y = after_stat(count) / sum(after_stat(count))), fill = \"lightblue\", color=\"black\") +\n  labs(\n    x = \"Valore\",\n    y = \"Frequenza relativa\"\n  )\n\n\n\n\n\n\n\nQuando il numero di lanci aumenta, le frequenze relative si avvicinano sempre più alle probabilità teoriche.\n\n\n\n\n30.1.2 Distribuzioni di probabilità continue\nLe distribuzioni di probabilità continue descrivono variabili casuali che possono assumere un numero infinito di valori in un intervallo. In questo caso, la probabilità è rappresentata da una funzione di densità di probabilità (PDF), che descrive la probabilità che la variabile assuma valori in un dato intervallo.\n\n30.1.2.1 Probabilità come area sotto la curva\nLe distribuzioni continue sono descritte dalla funzione di densità di probabilità (PDF). Per una variabile casuale continua \\(X\\), la probabilità che \\(X\\) assuma un valore compreso tra \\(a\\) e \\(b\\) è data dall’area sotto la curva della PDF tra \\(a\\) e \\(b\\):\n\\[\nP(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx.\n\\]\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIl quoziente intellettivo (QI) è spesso modellato come una variabile casuale continua con distribuzione normale, con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Possiamo simulare questa distribuzione e confrontare l’istogramma dei dati con la PDF teorica.\nSimulazione con 50 osservazioni.\n\n# Parametri della distribuzione normale\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 50\n\n# Generare i dati\nset.seed(123)\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Istogramma e densità\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = sigma)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 25,\n    fill = \"lightblue\", color = \"black\"\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    x = \"Valori del QI\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCon un campione piccolo, l’istogramma non corrisponde perfettamente alla PDF teorica. Tuttavia, aumentando il numero di osservazioni, l’approssimazione migliora.\nSimulazione con 20000 osservazioni.\n\n# Generare un campione più grande\nsize &lt;- 20000\nset.seed(123)\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Aggiornare media e deviazione standard\nmu &lt;- mean(x)\nsigma &lt;- sd(x)\n\n# Creare il grafico\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = sigma)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 25,\n    fill = \"lightblue\",\n    color = \"black\"\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    x = \"Valori del QI\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCon un campione di grandi dimensioni, l’istogramma riflette molto meglio la PDF teorica.\n\n\n\n\n30.1.2.2 Interpretazione della funzione di densità\nLa funzione di densità di probabilità (PDF) rappresenta un’astrazione continua dell’istogramma. Quando il numero di osservazioni tende a infinito e la larghezza degli intervalli tende a zero, il profilo dell’istogramma si avvicina alla PDF.\n\n30.1.2.3 Proprietà della PDF\n\n\nArea Totale: L’area totale sotto la curva della PDF è uguale a 1, poiché rappresenta la probabilità totale.\n\nProbabilità per Intervalli: La probabilità che la variabile assuma un valore in un intervallo \\([a, b]\\) è data dall’area sotto la curva tra \\(a\\) e \\(b\\).\n\nProbabilità per Singoli Valori: Per una variabile continua, la probabilità di un singolo valore è sempre zero, poiché corrisponde all’area sotto la curva in un punto.\n\n30.1.2.4 Parametri delle distribuzioni di probabilità\nLe distribuzioni di probabilità, sia discrete che continue, sono definite da parametri che ne determinano le proprietà fondamentali. Questi parametri consentono di adattare il modello probabilistico ai dati osservati.\n\n30.1.2.5 Proprietà influenzate dai parametri\n\n\nPosizione (Tendenza Centrale): Indica il valore attorno al quale si concentra la distribuzione. Ad esempio, nella distribuzione normale, la media (\\(\\mu\\)) rappresenta il centro della distribuzione.\n\nDispersione: Misura quanto i valori della distribuzione si allontanano dalla posizione centrale. Nella distribuzione normale, la deviazione standard (\\(\\sigma\\)) controlla la larghezza della curva.\n\nForma: Determina l’asimmetria o la curtosi della distribuzione. Alcune distribuzioni, come quella gamma o beta, hanno parametri specifici per regolare la forma.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html#il-paradosso-delle-variabili-casuali-continue",
    "href": "chapters/probability/07_prob_distributions.html#il-paradosso-delle-variabili-casuali-continue",
    "title": "30  Distribuzioni di massa e di densità",
    "section": "\n30.2 Il paradosso delle variabili casuali continue",
    "text": "30.2 Il paradosso delle variabili casuali continue\nUn aspetto controintuitivo delle variabili casuali continue è che la probabilità di osservare esattamente un determinato valore è sempre pari a zero. Per esempio, se consideriamo una variabile continua che rappresenta l’altezza di una persona, la probabilità che l’altezza sia esattamente 170 cm è espressa da\n\\[\nP(X = 170) = 0.\n\\]\nPerché accade questo? La risposta sta nel concetto di “esattezza”. Se riscriviamo 170 cm come 170.00000000000000000000000000000000000 cm (con infiniti decimali), diventa chiaro che stiamo cercando un singolo punto in un continuum infinito.\nQuesto non significa che l’evento sia impossibile, ma che nelle variabili continue la probabilità ha senso solo se riferita a intervalli di valori. Infatti, se sommiamo infinite probabilità diverse da zero, supereremmo 1, cosa impossibile.\n\n30.2.1 Due implicazioni importanti\nQuesto modo di definire la probabilità nelle variabili continue comporta due implicazioni chiave:\n\n\nCalcolo della probabilità su intervalli:\nNelle variabili continue, le probabilità si calcolano solo su intervalli (es.: tra 169.5 cm e 170.5 cm). Questo perché, se ogni singolo valore avesse probabilità &gt; 0, la somma di infiniti valori supererebbe 1 (il che è impossibile).\n\nEventi con probabilità zero:\nIl fatto che un evento (ad esempio, \\(X = 170\\)) abbia probabilità zero non implica che l’evento sia impossibile. È come cercare un granello di sabbia specifico su una spiaggia infinita: tecnicamente possibile, ma praticamente improbabile.\n\n30.2.2 Il paradosso della probabilità zero\nQuesto ragionamento porta a un apparente paradosso: se la probabilità che l’altezza di una persona sia esattamente 170 è zero, come possiamo mai osservare un valore specifico, come 170 (o un qualsiasi altro valore), nella realtà?\nUna metafora utile per comprendere questo fenomeno è data dal celebre paradosso di Zenone della freccia. Nel paradosso, si sostiene che, in ogni istante, la freccia sia immobile, e dunque non si dovrebbe mai muovere. Analogamente, ogni singolo valore (es.: 170 cm) ha probabilità zero, ma l’insieme di infiniti valori in un intervallo crea un’area sotto la curva (probabilità) misurabile.\n\n30.2.3 La prospettiva degli infinitesimi\nNegli anni ’60, il matematico Abraham Robinson sviluppò una teoria matematica rigorosa degli infinitesimi, ovvero numeri infinitamente piccoli, diversi da zero. In questo quadro, possiamo reinterpretare la probabilità dei singoli punti nel seguente modo:\n\n\nProbabilità infinitesimale:\nUn singolo valore puntuale non ha probabilità strettamente zero, bensì infinitamente piccola (un infinitesimo). Pur essendo praticamente indistinguibile da zero nella teoria classica, l’aggregazione (tramite integrazione) di infiniti eventi con probabilità infinitesimali può produrre un valore di probabilità finito e positivo per un intervallo. In altre parole, infiniti punti infinitamente piccoli sommati insieme generano un intervallo di probabilità misurabile e significativa.\n\nIn conclusione, il cosiddetto “paradosso della probabilità zero” non rappresenta un vero paradosso, ma evidenzia piuttosto i limiti delle nostre intuizioni quando affrontiamo concetti inerenti variabili continue. La chiave per la comprensione risiede nella distinzione tra il contributo di un singolo punto (infinitesimale o zero, nell’analisi classica) e l’area complessiva calcolata mediante l’integrazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "chapters/probability/07_prob_distributions.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "30  Distribuzioni di massa e di densità",
    "section": "\n30.3 La funzione di ripartizione per una variabile casuale continua",
    "text": "30.3 La funzione di ripartizione per una variabile casuale continua\nLa funzione di ripartizione, nota anche come distribuzione cumulativa, è uno strumento fondamentale per descrivere il comportamento di una variabile casuale, sia essa discreta o continua. Per una variabile casuale continua \\(\\Theta\\), la funzione di ripartizione \\(F_{\\Theta}(\\theta)\\) è definita come:\n\\[\nF_{\\Theta}(\\theta) = P(\\Theta \\leq \\theta).\n\\]\nIn altre parole, \\(F_{\\Theta}(\\theta)\\) rappresenta la probabilità che la variabile \\(\\Theta\\) assuma un valore minore o uguale a \\(\\theta\\). Questa definizione è identica a quella utilizzata per le variabili casuali discrete, ma nel caso continuo assume un significato particolare a causa della natura continua della variabile.\n\n30.3.1 Proprietà della funzione di ripartizione\nLa funzione di ripartizione per una variabile casuale continua gode di alcune proprietà importanti:\n\n\nMonotonicità Crescente: \\(F_{\\Theta}(\\theta)\\) è una funzione non decrescente. Ciò significa che, all’aumentare di \\(\\theta\\), la probabilità \\(P(\\Theta \\leq \\theta)\\) non diminuisce.\n\nLimiti agli Estremi:\n\nQuando \\(\\theta \\to -\\infty\\), \\(F_{\\Theta}(\\theta) \\to 0\\).\nQuando \\(\\theta \\to +\\infty\\), \\(F_{\\Theta}(\\theta) \\to 1\\).\n\n\n\nContinuità: Per una variabile casuale continua, \\(F_{\\Theta}(\\theta)\\) è una funzione continua. Questo differisce dal caso discreto, dove la funzione di ripartizione è a gradini.\n\n30.3.2 Calcolo delle probabilità per intervalli\nUna delle applicazioni più utili della funzione di ripartizione è il calcolo della probabilità che la variabile casuale \\(\\Theta\\) assuma valori all’interno di un intervallo specifico. Dati due valori \\(\\theta_1\\) e \\(\\theta_2\\) (con \\(\\theta_1 &lt; \\theta_2\\)), la probabilità che \\(\\Theta\\) sia compreso tra \\(\\theta_1\\) e \\(\\theta_2\\) è data da:\n\\[\nP(\\theta_1 &lt; \\Theta \\leq \\theta_2) = F_{\\Theta}(\\theta_2) - F_{\\Theta}(\\theta_1).\n\\]\nQuesta formula è particolarmente utile perché, nel caso delle variabili continue, la probabilità di un singolo punto è sempre zero. Pertanto, per calcolare probabilità significative, è necessario considerare intervalli di valori.\n\n30.3.3 Relazione con la funzione di densità di probabilità (PDF)\nLa funzione di ripartizione è strettamente legata alla funzione di densità di probabilità (PDF), \\(f(\\theta)\\). Mentre la PDF descrive la densità di probabilità in ogni punto, la funzione di ripartizione rappresenta l’area sotto la curva della PDF fino a un certo valore \\(\\theta\\). Formalmente, la funzione di ripartizione si ottiene integrando la PDF:\n\\[\nF_{\\Theta}(\\theta) = \\int_{-\\infty}^{\\theta} f(t) \\, dt.\n\\]\nQuesta relazione evidenzia come la funzione di ripartizione sia una rappresentazione cumulativa della probabilità, ottenuta sommando (o integrando) i contributi della densità di probabilità fino al valore \\(\\theta\\).\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo una variabile casuale \\(\\Theta\\) con distribuzione normale standard (media \\(\\mu = 0\\) e deviazione standard \\(\\sigma = 1\\)). La PDF è data da:\n\\[\nf(\\theta) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\theta^2 / 2}.\n\\]\nLa funzione di ripartizione \\(F_{\\Theta}(\\theta)\\) è l’integrale di questa funzione da \\(-\\infty\\) a \\(\\theta\\):\n\\[\nF_{\\Theta}(\\theta) = \\int_{-\\infty}^{\\theta} \\frac{1}{\\sqrt{2\\pi}} e^{-t^2 / 2} \\, dt.\n\\]\nQuesta funzione non ha una forma chiusa semplice, ma può essere calcolata numericamente o consultata in tabelle statistiche. Ad esempio, per \\(\\theta = 1\\), \\(F_{\\Theta}(1) \\approx 0.8413\\), il che significa che la probabilità che \\(\\Theta\\) sia minore o uguale a 1 è circa l’84.13%.\n\n\n\n\n30.3.4 Interpretazione grafica\nGraficamente, la funzione di ripartizione rappresenta l’area sotto la curva della PDF a sinistra del valore \\(\\theta\\). Ad esempio, se consideriamo la distribuzione normale standard:\n\nPer \\(\\theta = 0\\), \\(F_{\\Theta}(0) = 0.5\\), poiché la media della distribuzione è 0 e la curva è simmetrica.\nPer \\(\\theta = 1\\), \\(F_{\\Theta}(1) \\approx 0.8413\\), come visto sopra.\nPer \\(\\theta = -1\\), \\(F_{\\Theta}(-1) \\approx 0.1587\\), poiché la coda sinistra della distribuzione contiene il 15.87% della probabilità.\n\n\n\n\n\n\n\n\n\nIn conclusione, la funzione di ripartizione è uno strumento essenziale per comprendere e lavorare con variabili casuali continue. Essa non solo fornisce una rappresentazione cumulativa della probabilità, ma permette anche di calcolare probabilità per intervalli e di collegare la PDF alla distribuzione complessiva della variabile. Attraverso la sua relazione con la PDF, la funzione di ripartizione offre un ponte tra la descrizione locale (densità) e quella globale (probabilità cumulativa) di una variabile casuale continua.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html#interpretazioni-bayesiana-e-frequentista-della-pdf",
    "href": "chapters/probability/07_prob_distributions.html#interpretazioni-bayesiana-e-frequentista-della-pdf",
    "title": "30  Distribuzioni di massa e di densità",
    "section": "\n30.4 Interpretazioni bayesiana e frequentista della PDF",
    "text": "30.4 Interpretazioni bayesiana e frequentista della PDF\nIn questo capitolo, abbiamo introdotto la funzione di densità di probabilità come limite del profilo di un istogramma, una descrizione intuitiva e utile per comprendere il concetto di densità. Questa interpretazione corrisponde, tuttavia, alla visione frequentista della densità di probabilità. Nella statistica Bayesiana, l’interpretazione è diversa e merita una spiegazione separata.\n\n30.4.1 Interpretazione frequentista\nConcetto di ripetizione degli esperimenti:\n\nIdea di frequenza relativa:\nNel paradigma frequentista la probabilità è intesa come il limite della frequenza relativa di un evento ottenuto al ripetere un esperimento un numero molto elevato di volte. Immaginiamo di eseguire un esperimento molte volte, ad ogni ripetizione si ottiene un valore di \\(x\\). Se costruiamo un istogramma di questi valori, questo istogramma diventa sempre più “liscio” man mano che il numero delle ripetizioni aumenta, fino a convergere alla PDF \\(p(x)\\).\nPDF come istogramma limite:\nLa PDF rappresenta la distribuzione dei valori osservati in una serie di ripetizioni dell’esperimento. In altre parole, essa descrive quanto frequentemente, in una ipotetica serie infinita di esperimenti, il valore \\(x\\) assume un determinato intervallo.\nEsempio intuitivo:\nSe misuriamo l’altezza degli individui in una popolazione, nel contesto frequentista, la PDF ci dice quale frazione di individui cade in un certo intervallo di altezza se potessimo misurare ogni possibile individuo (o eseguire ripetutamente misurazioni indipendenti in una popolazione “ideale”).\n\n30.4.2 Interpretazione bayesiana\nConcetto di incertezza e credenza:\n\n\nParametro come variabile casuale:\nIn statistica bayesiana, i parametri non sono visti come quantità fisse, ma come incerti. Si assume che ogni parametro (o dato osservato) abbia una propria distribuzione che riflette la nostra incertezza su di esso.\n\nAd esempio, se stiamo stimando un parametro \\(\\theta\\) (ad esempio la media di una distribuzione), in un approccio bayesiano attribuiamo a \\(\\theta\\) una distribuzione di probabilità che esprime quanto sia plausibile ciascun valore di \\(\\theta\\), dati i dati osservati e le nostre conoscenze pregresse.\n\n\n\nPDF come distribuzione di credenze:\nLa PDF, in questo contesto, non descrive una frequenza relativa osservabile sperimentalmente (perché l’esperimento non viene ripetuto infinite volte, o perché \\(x\\) è un valore fisso ma incerto), ma esprime il grado di fiducia o la plausibilità che il valore “vero” di \\(x\\) (o di un parametro) si trovi in un certo intervallo.\n\nÈ come “spalmare” la nostra incertezza su tutti i valori possibili: la sfumatura lungo l’asse \\(x\\) rappresenta la distribuzione delle nostre credenze.\n\n\nAnalogia con la densità di materia:\nUn’utile analogia è quella della densità di materia \\(\\rho(x)\\) in meccanica classica: la densità non descrive la posizione precisa di ogni atomo, ma come la materia (o, in questo caso, la probabilità) è distribuita lungo l’asse \\(x\\). Allo stesso modo, in una PDF bayesiana, non sono i “valori di \\(x\\)” ad essere distribuiti (in termini di frequenza osservabile), ma è la nostra “incertezza” a essere distribuita sui possibili valori.\nEsempio intuitivo:\nImmagina di dover stimare la probabilità che una certa ipotesi sia vera, ad esempio la media dell’altezza in una popolazione. Invece di pensare a misurazioni ripetute, consideri il valore medio come fisso ma incerto. La PDF bayesiana esprime il grado di credenza per ciascun possibile valore della media, in base ai dati raccolti e alle informazioni a priori.\n\n30.4.3 Confronto\n\n\nFrequentista:\n\n\nFocus: Distribuzione dei dati.\n\nInterpretazione: La PDF descrive come i valori di \\(x\\) sarebbero distribuiti se ripetessimo l’esperimento infinite volte.\n\nEsempio: L’istogramma dei dati osservati in una lunga serie di esperimenti.\n\n\n\nBayesiano:\n\n\nFocus: Distribuzione della nostra incertezza o credenza.\n\nInterpretazione: La PDF riflette quanto sia plausibile ciascun valore di \\(x\\) (o di un parametro) dato l’informazione disponibile, senza necessità di ripetere l’esperimento.\n\nEsempio: La distribuzione a posteriori di un parametro dopo aver combinato dati osservati e informazioni a priori.\n\n\n\n\n\n\n\n\nFigura 30.1: Interpretazioni frequentista e bayesiana di una PDF (curva blu) per una quantità reale \\(x\\). A sinistra: interpretazione frequentista come istogramma limite dei valori di \\(x\\) nelle ripetizioni; i valori di \\(x\\) sono distribuiti secondo la PDF. A destra: interpretazione bayesiana, con \\(x\\) che assume un valore fisso ma incerto per il caso specifico (rappresentato dal punto sull’asse \\(x\\)), con la probabilità distribuita sui valori possibili (raffigurata con una sfumatura lungo l’asse \\(x\\)). (Figura tratta da Loredo & Wolpert, 2024)\n\n\nIn sintesi, questa distinzione tra interpretazioni non è solo una questione di semantica, ma ha implicazioni pratiche nella formulazione di modelli statistici e nell’interpretazione dei risultati. Mentre l’approccio frequentista è spesso utilizzato quando si può concettualmente pensare a ripetizioni infinite dell’esperimento, l’approccio bayesiano è particolarmente utile quando si vuole esprimere e aggiornare la propria incertezza su una quantità basandosi sia su dati che su conoscenze pregresse.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html#riflessioni-conclusive",
    "href": "chapters/probability/07_prob_distributions.html#riflessioni-conclusive",
    "title": "30  Distribuzioni di massa e di densità",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa funzione di densità di probabilità (PDF) costituisce il fondamento per la descrizione delle variabili casuali continue, consentendo di associare le probabilità ad intervalli, tramite il calcolo dell’area sottesa alla curva. In questo contesto, la probabilità di osservare un valore esatto risulta zero, non per impossibilità dell’evento, ma perché in un insieme continuo ogni singolo punto contribuisce con un’area infinitesimale.\nIl paradosso apparente, secondo cui la somma di infiniti contributi nulli porta a una probabilità totale positiva, si risolve grazie alla teoria dell’integrazione. Integrando i contributi infinitesimali lungo un intervallo, si ottiene una quantità finita che rappresenta la probabilità complessiva dell’evento. Un’interpretazione alternativa, fornita dalla teoria degli infinitesimi di Abraham Robinson, consente di attribuire a tali eventi probabilità infinitesimali, distinguendo tra diverse “grandezze” e chiarendo ulteriormente il processo di aggregazione verso un valore unitario.\nNel campo della data science, le distribuzioni di probabilità—formalmente rappresentate da \\(p(x)\\)—sono strumenti indispensabili per modellare la variabilità osservabile in una popolazione. Queste distribuzioni non mirano a riprodurre in maniera dettagliata ogni aspetto della realtà, ma offrono un modello semplificato che consente di generalizzare i dati osservati e di formulare previsioni rigorose sui fenomeni futuri. In altre parole, \\(p(x)\\) non rappresenta la popolazione nel suo complesso, bensì un’astrazione matematica che cattura l’incertezza e la variabilità del fenomeno studiato.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizio 1: Variabili Casuali Discrete e Continue\nUtilizzando i dati raccolti sulla Satisfaction with Life Scale (SWLS) e sulla Scala della Rete Sociale di Lubben a 6 item (LSNS-6), classifica le seguenti variabili come discrete o continue:\n\nIl punteggio totale della SWLS.\nIl numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali.\nIl tempo (in minuti) che uno studente trascorre con amici durante una settimana.\nIl numero di volte che uno studente ha contattato un parente nell’ultimo mese.\nIl livello di soddisfazione della vita misurato su una scala da 1 a 7.\n\nSpiega il motivo della tua classificazione per ciascuna variabile.\nEsercizio 2: Distribuzioni di Probabilità Discrete\nConsideriamo la distribuzione del numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali, misurata attraverso la LSNS-6. Supponiamo che la distribuzione sia la seguente (ma nell’esercizio usa le frequenze relative trovate nel campione di dati raccolto):\n\n\nNumero di amici\nProbabilità\n\n\n\n0\n0.05\n\n\n1\n0.15\n\n\n2\n0.25\n\n\n3\n0.30\n\n\n4\n0.15\n\n\n5\n0.10\n\n\n\n\nVerifica che questa sia una distribuzione di probabilità valida.\nQual è la probabilità che uno studente abbia almeno 3 amici con cui si sente a proprio agio nel parlare di questioni personali?\nQual è la probabilità che abbia meno di 2 amici?\nCalcola il valore atteso (media) e la varianza di questa distribuzione.\n\nEsercizio 3: Distribuzioni di Probabilità Continue\nIl punteggio totale della SWLS può essere approssimato da una distribuzione normale con media 20 e deviazione standard 5.\n\nQual è la probabilità che un individuo scelto a caso abbia un punteggio superiore a 25?\nQual è la probabilità che un individuo abbia un punteggio compreso tra 15 e 25?\nQual è il valore del punteggio che delimita il 10% superiore della distribuzione?\n\n(Suggerimento: utilizza la funzione di ripartizione della distribuzione normale standard per calcolare queste probabilità.)\nEsercizio 4: Legge della Probabilità Totale\nSi sa che il 60% degli studenti proviene da un ambiente con un forte supporto sociale, mentre il 40% ha un supporto sociale limitato. Inoltre, si sa che: - La probabilità che uno studente con forte supporto sociale abbia un punteggio SWLS superiore a 20 è 0.75. - La probabilità che uno studente con supporto sociale limitato abbia un punteggio SWLS superiore a 20 è 0.50.\nQual è la probabilità che uno studente scelto a caso abbia un punteggio SWLS superiore a 20?\nEsercizio 5: Teorema di Bayes e Supporto Sociale\nRiprendendo l’esercizio precedente, calcola la probabilità che uno studente provenga da un ambiente con forte supporto sociale dato che il suo punteggio SWLS è superiore a 20.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nEsercizio 1: Variabili Casuali Discrete e Continue\nUtilizzando i dati raccolti sulla Satisfaction with Life Scale (SWLS) e sulla Scala della Rete Sociale di Lubben a 6 item (LSNS-6), classifica le seguenti variabili come discrete o continue:\n\nIl punteggio totale della SWLS. (Continuo)\nIl numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali. (Discreto)\nIl tempo (in minuti) che uno studente trascorre con amici durante una settimana. (Continuo)\nIl numero di volte che uno studente ha contattato un parente nell’ultimo mese. (Discreto)\nIl livello di soddisfazione della vita misurato su una scala da 1 a 7. (Discreto)\n\nEsercizio 2: Distribuzioni di Probabilità Discrete\nConsideriamo la distribuzione del numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali, misurata attraverso la LSNS-6. Supponiamo che la distribuzione sia la seguente:\n\n\nNumero di amici\nProbabilità\n\n\n\n0\n0.05\n\n\n1\n0.15\n\n\n2\n0.25\n\n\n3\n0.30\n\n\n4\n0.15\n\n\n5\n0.10\n\n\n\n\n\nVerifica della distribuzione: La somma delle probabilità deve essere 1:\n\\[ 0.05 + 0.15 + 0.25 + 0.30 + 0.15 + 0.10 = 1.00 \\]\nPoiché la somma è 1, la distribuzione è valida.\n\n\nProbabilità di almeno 3 amici:\n\\[ P(X \\geq 3) = P(3) + P(4) + P(5) = 0.30 + 0.15 + 0.10 = 0.55 \\]\n\n\nProbabilità di meno di 2 amici:\n\\[ P(X &lt; 2) = P(0) + P(1) = 0.05 + 0.15 = 0.20 \\]\n\n\nValore atteso e varianza:\n\\[ E(X) = \\sum x P(x) = (0 \\times 0.05) + (1 \\times 0.15) + (2 \\times 0.25) + (3 \\times 0.30) + (4 \\times 0.15) + (5 \\times 0.10) = 2.65 \\]\n\\[ Var(X) = E(X^2) - (E(X))^2 \\]\n\\[ E(X^2) = (0^2 \\times 0.05) + (1^2 \\times 0.15) + (2^2 \\times 0.25) + (3^2 \\times 0.30) + (4^2 \\times 0.15) + (5^2 \\times 0.10) = 8.05 \\]\n\\[ Var(X) = 8.05 - (2.65)^2 = 1.06 \\]\n\n\nEsercizio 3: Distribuzioni di Probabilità Continue\nIl punteggio totale della SWLS può essere approssimato da una distribuzione normale con media 20 e deviazione standard 5.\n\n\nProbabilità che il punteggio sia superiore a 25:\n\\[ P(X &gt; 25) = 1 - P(X \\leq 25) \\]\nStandardizziamo:\n\\[ Z = \\frac{25 - 20}{5} = 1 \\]\nUsando le tabelle della distribuzione normale:\n\\[ P(Z \\leq 1) = 0.8413 \\Rightarrow P(X &gt; 25) = 1 - 0.8413 = 0.1587 \\]\n\n\nProbabilità che il punteggio sia tra 15 e 25:\n\\[ P(15 \\leq X \\leq 25) = P(Z \\leq 1) - P(Z \\leq -1) \\]\n\\[ = 0.8413 - 0.1587 = 0.6826 \\]\n\n\nPercentile 90 della distribuzione:\nIl valore di Z per il 90% è 1.28.\n\\[ X = 20 + (1.28 \\times 5) = 26.4 \\]\n\n\nEsercizio 4: Legge della Probabilità Totale\n\\[ P(SWLS &gt; 20) = P(SWLS &gt; 20 | S) P(S) + P(SWLS &gt; 20 | \\neg S) P(\\neg S) \\]\n\\[ = (0.75 \\times 0.60) + (0.50 \\times 0.40) \\]\n\\[ = 0.45 + 0.20 = 0.65 \\]\nEsercizio 5: Teorema di Bayes e Supporto Sociale\n\\[ P(S | SWLS &gt; 20) = \\frac{P(SWLS &gt; 20 | S) P(S)}{P(SWLS &gt; 20)} \\]\n\\[ = \\frac{(0.75 \\times 0.60)}{0.65} \\]\n\\[ = \\frac{0.45}{0.65} = 0.6923 \\]\nQuindi, la probabilità che uno studente provenga da un ambiente con forte supporto sociale dato che il suo punteggio SWLS è superiore a 20 è circa 69.2%.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] yaml_2.3.10           knitr_1.50            labeling_0.4.3       \n#&gt; [19] bridgesampling_1.1-2  htmlwidgets_1.6.4     curl_7.0.0           \n#&gt; [22] pkgbuild_1.4.8        RColorBrewer_1.1-3    abind_1.4-8          \n#&gt; [25] multcomp_1.4-28       withr_3.0.2           purrr_1.1.0          \n#&gt; [28] grid_4.5.1            stats4_4.5.1          colorspace_2.1-1     \n#&gt; [31] xtable_1.8-4          inline_0.3.21         emmeans_1.11.2-8     \n#&gt; [34] scales_1.4.0          MASS_7.3-65           cli_3.6.5            \n#&gt; [37] mvtnorm_1.3-3         rmarkdown_2.29        ragg_1.5.0           \n#&gt; [40] generics_0.1.4        RcppParallel_5.1.11-1 cachem_1.1.0         \n#&gt; [43] stringr_1.5.1         splines_4.5.1         parallel_4.5.1       \n#&gt; [46] vctrs_0.6.5           V8_7.0.0              Matrix_1.7-4         \n#&gt; [49] sandwich_3.1-1        jsonlite_2.0.0        arrayhelpers_1.1-0   \n#&gt; [52] systemfonts_1.2.3     glue_1.8.0            codetools_0.2-20     \n#&gt; [55] distributional_0.5.0  lubridate_1.9.4       stringi_1.8.7        \n#&gt; [58] gtable_0.3.6          QuickJSR_1.8.0        htmltools_0.5.8.1    \n#&gt; [61] Brobdingnag_1.2-9     R6_2.6.1              textshaping_1.0.3    \n#&gt; [64] rprojroot_2.1.1       evaluate_1.0.5        lattice_0.22-7       \n#&gt; [67] backports_1.5.0       memoise_2.0.1         broom_1.0.9          \n#&gt; [70] snakecase_0.11.1      rstantools_2.5.0      coda_0.19-4.1        \n#&gt; [73] gridExtra_2.3         nlme_3.1-168          checkmate_2.3.3      \n#&gt; [76] xfun_0.53             zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_prob_distributions.html#bibliografia",
    "href": "chapters/probability/07_prob_distributions.html#bibliografia",
    "title": "30  Distribuzioni di massa e di densità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nLoredo, T. J., & Wolpert, R. L. (2024). Bayesian inference: more than Bayes’s theorem. Frontiers in Astronomy and Space Sciences, 11, 1326926.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html",
    "href": "chapters/probability/08_expval_var.html",
    "title": "31  Proprietà delle variabili casuali",
    "section": "",
    "text": "Introduzione\nSpesso è molto utile sintetizzare la distribuzione di una variabile casuale attraverso indicatori caratteristici. Questi indicatori consentono di cogliere le principali proprietà della distribuzione, come la posizione centrale (ovvero il “baricentro”) e la variabilità (ossia la dispersione attorno al centro). In questo modo, è possibile ottenere una descrizione sintetica e significativa della distribuzione di probabilità della variabile casuale.\nIn questo capitolo, introdurremo i concetti fondamentali di valore atteso e varianza di una variabile casuale, che sono strumenti essenziali per comprendere e riassumere le proprietà di una distribuzione probabilistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#introduzione",
    "href": "chapters/probability/08_expval_var.html#introduzione",
    "title": "31  Proprietà delle variabili casuali",
    "section": "",
    "text": "Panoramica del capitolo\n\nConcetti di valore atteso e varianza per variabili casuali discrete.\nProprietà del valore atteso e della varianza.\nValore atteso e varianza per variabili casuali continue.\nUtilizzare R per calcolare valore atteso e varianza.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\nPer affrontare al meglio questo capitolo, assicurati di avere familiarità con i seguenti argomenti:\n\nÈ fondamentale aver letto la sezione Appendice I.\nSi consiglia la lettura del capitolo Expectation in Schervish & DeGroot (2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#tendenza-centrale",
    "href": "chapters/probability/08_expval_var.html#tendenza-centrale",
    "title": "31  Proprietà delle variabili casuali",
    "section": "\n31.1 Tendenza centrale",
    "text": "31.1 Tendenza centrale\nQuando vogliamo comprendere il comportamento tipico di una variabile casuale, ci interessa spesso determinare il suo “valore tipico”. Tuttavia, questa nozione può essere interpretata in diversi modi:\n\n\nMedia: La somma dei valori divisa per il numero dei valori.\n\nMediana: Il valore centrale della distribuzione, quando i dati sono ordinati in senso crescente o decrescente.\n\nModa: Il valore che si verifica con maggiore frequenza.\n\nAd esempio, per il set di valori \\(\\{3, 1, 4, 1, 5\\}\\), la media è \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana è 3, e la moda è 1. Tuttavia, quando ci occupiamo di variabili casuali, anziché di semplici sequenze di numeri, diventa necessario chiarire cosa intendiamo per “valore tipico” in questo contesto. Questo ci porta alla definizione formale del valore atteso.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#valore-atteso",
    "href": "chapters/probability/08_expval_var.html#valore-atteso",
    "title": "31  Proprietà delle variabili casuali",
    "section": "\n31.2 Valore atteso",
    "text": "31.2 Valore atteso\n\nDefinizione 31.1 Sia \\(X\\) una variabile casuale discreta che assume i valori \\(x_1, \\dots, x_n\\) con probabilità \\(P(X = x_i) = p(x_i)\\). Il valore atteso di \\(X\\), denotato con \\(\\mathbb{E}(X)\\), è definito come:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n x_i \\cdot p(x_i).\n\\]\n\nIn altre parole, il valore atteso (noto anche come speranza matematica o aspettazione) di una variabile casuale è la somma di tutti i valori che la variabile può assumere, ciascuno ponderato dalla probabilità con cui esso si verifica.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nCalcoliamo il valore atteso della variabile casuale \\(X\\) corrispondente al lancio di una moneta equilibrata, dove testa corrisponde a \\(X = 1\\) e croce corrisponde a \\(X = 0\\):\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{2} x_i \\cdot P(x_i) = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = 0.5.\n\\]\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nCalcoliamo il valore atteso della variabile casuale \\(X\\) che rappresenta la somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\nLa variabile casuale \\(X\\) può assumere i seguenti valori:\n\\[\n\\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\\}.\n\\]\nLa probabilità associata a ciascun valore è data dalla distribuzione di massa di probabilità. Ad esempio, il valore \\(X = 2\\) si ottiene solo se entrambi i dadi mostrano 1, quindi ha probabilità:\n\\[\nP(X = 2) = \\frac{1}{36}.\n\\]\nAnalogamente, \\(X = 7\\) può essere ottenuto con sei combinazioni diverse: (1,6), (2,5), (3,4), (4,3), (5,2), (6,1), quindi:\n\\[\nP(X = 7) = \\frac{6}{36}.\n\\]\nLa distribuzione di massa di probabilità completa è:\n\\[\nP(X) = \\left\\{\\frac{1}{36}, \\frac{2}{36}, \\frac{3}{36}, \\frac{4}{36}, \\frac{5}{36}, \\frac{6}{36}, \\frac{5}{36}, \\frac{4}{36}, \\frac{3}{36}, \\frac{2}{36}, \\frac{1}{36}\\right\\}.\n\\]\nIl valore atteso \\(\\mathbb{E}[X]\\) è definito come:\n\\[\n\\mathbb{E}[X] = \\sum_{x} x \\cdot P(X = x).\n\\]\nApplicando questa formula:\n\\[\n\\mathbb{E}[X] = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + 4 \\cdot \\frac{3}{36} + \\cdots + 12 \\cdot \\frac{1}{36} = 7.\n\\]\nEcco come calcolarlo utilizzando R:\n\n# Valori di X e le loro probabilità\nvalori &lt;- 2:12\nprob &lt;- c(1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1) / 36\n\n# Calcolo del valore atteso\nvalore_atteso &lt;- sum(valori * prob)\nvalore_atteso\n#&gt; [1] 7\n\nIl risultato sarà: \\[\n\\mathbb{E}[X] = 7.\n\\]\nPer rappresentare graficamente la distribuzione di massa di probabilità:\n\n# Creazione di un data frame\ndati &lt;- data.frame(Valore = valori, Probabilità = prob)\n\n# Plot\nggplot(dati, aes(x = Valore, y = Probabilità)) +\n  geom_col(fill = \"lightblue\") +\n  labs(\n    title = \"Distribuzione di Massa di Probabilità per X\",\n    x = \"Valore della Somma (X)\",\n    y = \"Probabilità\"\n  ) \n\n\n\n\n\n\n\n\n\n\nNel suo Ars conjectandi, Bernoulli introduce la nozione di valore atteso con le seguenti parole:\n\nil termine “aspettativa” non deve essere inteso nel suo significato comune […], bensì come la speranza di ottenere il meglio diminuita dalla paura di ottenere il peggio. Pertanto, il valore della nostra aspettativa rappresenta sempre qualcosa di intermedio tra il meglio che possiamo sperare e il peggio che possiamo temere (Hacking, 2006).\n\nIn termini moderni, questa intuizione può essere rappresentata in modo più chiaro attraverso una simulazione. Possiamo affermare, infatti, che il valore atteso di una variabile casuale corrisponde alla media aritmetica di un gran numero di realizzazioni indipendenti della variabile stessa.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nPer fare un esempio concreto, consideriamo nuovamente il caso del lancio di due dadi bilanciati a sei facce, dove la variabile casuale \\(X\\) rappresenta la “somma dei due dadi”. Simuliamo un numero elevato di realizzazioni indipendenti di \\(X\\).\n\nset.seed(123)  \nx_samples &lt;- sample(valori, size = 1e6, replace = TRUE, prob = prob)\n\nL’istruzione sample(x, size = 1e6, replace = TRUE, prob = px)) utilizza R per generare un array di 1.000.000 di elementi (specificato dal parametro size), selezionati casualmente dall’array x secondo le probabilità specificate nell’array px.\nQuando il numero di realizzazioni indipendenti è sufficientemente grande, la media aritmetica dei campioni generati si avvicina al valore atteso della variabile casuale:\n\nmean(x_samples)\n#&gt; [1] 7\n\nQuesto risultato conferma che il valore atteso \\(\\mathbb{E}[X] = 7\\) rappresenta la somma media dei punti ottenuti nel lancio di due dadi equilibrati su un numero elevato di prove. Anche se ogni singola somma può variare tra 2 e 12, in media ci aspettiamo una somma di 7.\nL’aspettativa può anche essere interpretata come un centro di massa. Immagina che delle masse puntiformi con pesi \\(p_1, p_2, \\dots, p_n\\) siano posizionate alle posizioni \\(x_1, x_2, \\dots, x_n\\) sulla retta reale. Il centro di massa—il punto in cui i pesi sono bilanciati—è dato da:\n\\[\n\\text{centro di massa} = x_1 p_1 + x_2 p_2 + \\dots + x_n p_n,\n\\]\nche corrisponde esattamente all’aspettativa della variabile discreta \\(X\\), che assume valori \\(x_1, \\dots, x_n\\) con probabilità \\(p_1, \\dots, p_n\\). Una conseguenza ovvia di questa interpretazione è che, per una funzione di densità di probabilità (pdf) simmetrica, l’aspettativa coincide con il punto di simmetria (a patto che l’aspettativa esista).\n\n\n\n\n\nFigura 31.1: L’aspettativa come centro di massa (figura tratta da Chan & Kroese, 2025).\n\n\n\n\n\n\n31.2.1 Proprietà del valore atteso\nUna delle proprietà più importanti del valore atteso è la sua linearità: il valore atteso della somma di due variabili casuali è uguale alla somma dei loro rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{31.1}\\]\nQuesta proprietà, espressa dalla formula sopra, è intuitiva quando \\(X\\) e \\(Y\\) sono variabili casuali indipendenti, ma è valida anche nel caso in cui \\(X\\) e \\(Y\\) siano correlate.\nInoltre, se moltiplichiamo una variabile casuale per una costante \\(c\\), il valore atteso del prodotto è uguale alla costante moltiplicata per il valore atteso della variabile casuale:\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{31.2}\\]\nQuesta proprietà ci dice che una costante può essere “estratta” dall’operatore di valore atteso, e si applica a qualunque numero di variabili casuali.\nUn’altra proprietà significativa riguarda il prodotto di variabili casuali indipendenti. Se \\(X\\) e \\(Y\\) sono indipendenti, allora il valore atteso del loro prodotto è uguale al prodotto dei loro valori attesi:\n\\[\n\\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{31.3}\\]\nInfine, consideriamo la media aritmetica \\(\\bar{X} = \\frac{X_1 + \\ldots + X_n}{n}\\) di \\(n\\) variabili casuali indipendenti con la stessa distribuzione e con valore atteso \\(\\mu\\). Il valore atteso della media aritmetica è:\n\\[\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\left(\\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n)\\right) = \\frac{1}{n} \\cdot n \\cdot \\mathbb{E}(X) = \\mu.\n\\]\nQuesto risultato conferma che la media aritmetica di un campione di variabili casuali indipendenti ha lo stesso valore atteso della distribuzione originaria, rendendo il valore atteso uno strumento cruciale per l’analisi statistica e probabilistica.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo il seguente esperimento casuale. Sia \\(Y\\) il numero che si ottiene dal lancio di un dado equilibrato a sei facce e \\(Y\\) il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di \\(X+Y\\).\nPer risolvere il problema iniziamo a costruire lo spazio campione dell’esperimento casuale.\n\n\n\n\n\n\n\n\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avrà la stessa probabilità di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) è dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nSi ottiene lo stesso risultato usando l’Equazione 31.1:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nSvolgiamo ora l’esercizio in R\n\ncoin &lt;- 0:1  # Valori della moneta: testa (0) e croce (1)\ndie &lt;- 1:6   # Valori del dado: da 1 a 6\n\n# Creazione del campione come combinazione di valori (moneta, dado)\nsample &lt;- expand.grid(coin = coin, die = die)\nprint(sample)\n#&gt;    coin die\n#&gt; 1     0   1\n#&gt; 2     1   1\n#&gt; 3     0   2\n#&gt; 4     1   2\n#&gt; 5     0   3\n#&gt; 6     1   3\n#&gt; 7     0   4\n#&gt; 8     1   4\n#&gt; 9     0   5\n#&gt; 10    1   5\n#&gt; 11    0   6\n#&gt; 12    1   6\n\n\npx &lt;- numeric()  # Vettore per memorizzare le probabilità\n\nfor (i in 1:7) {\n  # Filtrare le combinazioni in cui la somma è uguale a 'i'\n  event &lt;- subset(sample, coin + die == i)\n  # Calcolare la probabilità\n  prob &lt;- nrow(event) / nrow(sample)\n  px &lt;- c(px, prob)\n  \n  # Stampare la probabilità\n  cat(sprintf(\"P(X + Y = %d) = %d / %d\\n\", i, nrow(event), nrow(sample)))\n}\n#&gt; P(X + Y = 1) = 1 / 12\n#&gt; P(X + Y = 2) = 2 / 12\n#&gt; P(X + Y = 3) = 2 / 12\n#&gt; P(X + Y = 4) = 2 / 12\n#&gt; P(X + Y = 5) = 2 / 12\n#&gt; P(X + Y = 6) = 2 / 12\n#&gt; P(X + Y = 7) = 1 / 12\n\n\nx &lt;- 1:7  # Valori della variabile casuale (somma di moneta e dado)\nexpected_value &lt;- sum(x * px)\nexpected_value\n#&gt; [1] 4\n\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso di \\(Z = X \\cdot Y\\).\nLa distribuzione di probabilità congiunta \\(P(X, Y)\\) è fornita nella tabella seguente.\n\n\n\\(x /\\ y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l’Equazione 31.3. Infatti, il valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) è\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerciò\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\n\n\n\n\n31.2.2 Valore atteso di una variabile casuale continua\nNel caso di una variabile casuale continua \\(X\\), il valore atteso è definito come:\n\\[\n\\mathbb{E}(X) = \\int_{-\\infty}^{+\\infty} x \\cdot p(x) \\, \\mathrm{d}x.\n\\]\nAnche in questo contesto, il valore atteso rappresenta una media ponderata dei valori di \\(x\\), dove ogni possibile valore di \\(x\\) è ponderato in base alla densità di probabilità \\(p(x)\\).\nL’integrale può essere interpretato analogamente a una somma continua, in cui \\(x\\) rappresenta la posizione delle barre infinitamente strette di un istogramma, e \\(p(x)\\) rappresenta l’altezza di tali barre. La notazione \\(\\int_{-\\infty}^{+\\infty}\\) indica che si sta sommando il contributo di ogni valore possibile di \\(x\\) lungo l’intero asse reale.\nQuesta interpretazione rende chiaro come l’integrale calcoli una somma ponderata che si estende su tutti i possibili valori di \\(x\\), fornendo una misura centrale della distribuzione della variabile casuale continua. Per ulteriori dettagli sulla notazione dell’integrale, si veda l’?sec-calculus.\n\n31.2.2.1 Moda\nUn’altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda di \\(Y\\) individua il valore \\(y\\) più plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densità \\(p(y)\\):\n\\[\nMo(Y) = \\text{argmax}_y p(y).\n\\tag{31.4}\\]\n\n\n\n\n\n\nLa notazione \\(\\text{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#varianza",
    "href": "chapters/probability/08_expval_var.html#varianza",
    "title": "31  Proprietà delle variabili casuali",
    "section": "\n31.3 Varianza",
    "text": "31.3 Varianza\nDopo il valore atteso, la seconda proprietà più importante di una variabile casuale è la varianza.\n\nDefinizione 31.2 Se \\(X\\) è una variabile casuale discreta con distribuzione \\(p(x)\\), la varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), è definita come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\tag{31.5}\\]\n\nIn altre parole, la varianza misura la deviazione media quadratica dei valori della variabile rispetto alla sua media. Se denotiamo il valore atteso di \\(X\\) con \\(\\mu = \\mathbb{E}(X)\\), la varianza \\(\\mathbb{V}(X)\\) diventa il valore atteso di \\((X - \\mu)^2\\).\nLa varianza rappresenta una misura della “dispersione” dei valori di \\(X\\) intorno al suo valore atteso. Quando calcoliamo la varianza, stiamo effettivamente misurando quanto i valori di \\(X\\) tendono a differire dalla media \\(\\mu\\).\nPer capire meglio, consideriamo la variabile casuale \\(X - \\mathbb{E}(X)\\), detta scarto o deviazione dalla media. Questa variabile rappresenta le “distanze” tra i valori di \\(X\\) e il valore atteso \\(\\mathbb{E}(X)\\). Tuttavia, poiché lo scarto può essere positivo o negativo, la media dello scarto è sempre zero, il che lo rende inadatto a quantificare la dispersione.\nPer risolvere questo problema, eleviamo al quadrato gli scarti, ottenendo \\((X - \\mathbb{E}(X))^2\\), che rende tutte le deviazioni positive. La varianza è quindi la media di questi scarti al quadrato, fornendo una misura efficace della dispersione complessiva dei valori di \\(X\\) rispetto alla sua media.\nQuesto concetto è fondamentale per comprendere la variabilità di una distribuzione e per applicare strumenti statistici che richiedono una conoscenza approfondita della distribuzione dei dati.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nPosta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\nLa variabile casuale \\(S\\) ha la seguente distribuzione di probabilità:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{aligned}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nSvolgiamo l’esercizio in R\n\n# Definire i valori di x e le loro probabilità px\nx &lt;- 2:12\npx &lt;- c(\n  1 / 36, 2 / 36, 3 / 36, 4 / 36, 5 / 36, 6 / 36,\n  5 / 36, 4 / 36, 3 / 36, 2 / 36, 1 / 36\n)\n\n# Calcolare il valore atteso\nex &lt;- sum(x * px)\nex\n#&gt; [1] 7\n\nApplichiamo l’Equazione 31.5:\n\n# Calcolo della varianza utilizzando la definizione\nvariance &lt;- sum((x - ex)^2 * px)\nvariance\n#&gt; [1] 5.83\n\nUsiamo la funzione var() di rv_discrete:\n\n# Calcolo della varianza con pesi\nvariance_check &lt;- weighted.mean((x - ex)^2, w = px)\nvariance_check\n#&gt; [1] 5.83\n\n\n\n\n\n31.3.1 Formula alternativa per la varianza\nLa varianza di una variabile casuale \\(X\\), indicata come \\(\\mathbb{V}(X)\\), misura la dispersione dei valori attorno alla media. La definizione classica è:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\]\nEsiste però una formula alternativa che semplifica il calcolo.\n\nDimostrazione. \n\nEspansione del quadrato\nConsideriamo la varianza, definita come \\(\\mathbb{V}(X) = \\mathbb{E}\\big[(X - \\mathbb{E}(X))^2\\big]\\).\nEspandiamo il quadrato \\((X - \\mathbb{E}(X))^2\\) utilizzando la regola \\((a - b)^2 = a^2 - 2ab + b^2\\): \\[\n(X - \\mathbb{E}(X))^2 = X^2 - 2\\,X\\,\\mathbb{E}(X) + \\big(\\mathbb{E}(X)\\big)^2.\n\\]\nApplicazione dell’aspettativa\nApplichiamo \\(\\mathbb{E}[\\cdot]\\) a ciascun termine, ricordando che l’aspettativa è un operatore lineare: \\[\n\\mathbb{E}\\big[(X - \\mathbb{E}(X))^2\\big]\n= \\mathbb{E}\\big[X^2\\big]\n  \\;-\\; 2 \\,\\mathbb{E}\\big[X\\,\\mathbb{E}(X)\\big]\n  \\;+\\; \\mathbb{E}\\big[\\big(\\mathbb{E}(X)\\big)^2\\big].\n\\]\n\nGestione dei termini costanti\nL’aspettativa \\(\\mathbb{E}(X)\\) è una costante (indipendente da \\(X\\)). Indichiamola con \\(\\mu\\). Quindi:\n\n\n\\(\\mathbb{E}(X^2)\\) resta com’è.\n\n\\(\\mathbb{E}[X \\cdot \\mu] = \\mu \\, \\mathbb{E}[X] = \\mu \\cdot \\mu = \\mu^2\\).\n\n\\(\\mathbb{E}\\big(\\mu^2\\big) = \\mu^2\\).\n\n\n\nSostituzione e semplificazione\nRimpiazzando i risultati nel secondo passaggio si ottiene: \\[\n\\mathbb{E}(X^2) \\;-\\; 2\\,\\mu^2 \\;+\\; \\mu^2\n\\;=\\; \\mathbb{E}(X^2) - \\mu^2.\n\\]\nPoiché \\(\\mu = \\mathbb{E}(X)\\), la varianza può quindi essere scritta come:\n\\[\n\\boxed{\n\\mathbb{V}(X) = \\mathbb{E}(X^2) \\;-\\; \\bigl(\\mathbb{E}(X)\\bigr)^2.\n}\n\\tag{31.6}\\]\n\n\n\nQuesta forma risulta molto utile per ragioni di efficienza computazionale: invece di calcolare gli scarti \\((X - \\mu)\\) per ogni osservazione, è sufficiente trovare \\(\\mathbb{E}(X^2)\\) e poi sottrarre \\(\\mu^2\\). In tal modo si riducono i passaggi intermedi e, di conseguenza, si minimizzano gli errori pratici. Inoltre, nelle dimostrazioni che richiedono manipolazioni algebriche – come quelle tipiche della Teoria Classica dei Test – questa espressione semplifica notevolmente le trasformazioni.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo la variabile casuale \\(X\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\nIl valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(X) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(X^2\\) è\n\\[\n\\mathbb{E}(X^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nSvolgiamo l’esercizio in R:\n\n# Definire i valori di x e le probabilità px\nx &lt;- c(0, 1)\npx &lt;- c(0.2, 0.8)\n\n# Calcolare il risultato\nresult &lt;- sum(x^2 * px) - (sum(x * px))^2\nresult\n#&gt; [1] 0.16\n\n\n\n\n\n31.3.2 Proprietà\nSegno della varianza. La varianza di una variabile aleatoria non è mai negativa, ed è zero solamente quando la variabile assume un solo valore.\nInvarianza per traslazione. La varianza è invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n\\[\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n\\]\nDimostrazione. Iniziamo a scrivere\n\\[\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n\\]\nQuindi\n\\[\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n\\]\nEsaminiamo una dimostrazione numerica.\n\n# Definire i valori di x\nx &lt;- c(2, 1, 4, 7)\n\n# Calcolare y\ny &lt;- 100 + 2 * x\n\n# Verificare la relazione tra le varianze\nresult &lt;- var(y) == 2^2 * var(x)\nresult\n#&gt; [1] TRUE\n\nVarianza della somma di due variabili indipendenti. La varianza della somma di due variabili indipendenti o anche solo incorrelate è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione. Se \\(\\mathbb{E}(X) = \\mathbb{E}(Y) = 0\\), allora \\(\\mathbb{E}(X+Y) = 0\\) e\n\\[\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).\\]\nSiccome le variabili sono indipendenti risulta \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0\\).\nVarianza della differenza di due variabili indipendenti. La varianza della differenza di due variabili indipendenti è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione.\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nVarianza della somma di due variabili non indipendenti. Se \\(X\\) e \\(Y\\) non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n\\]\ndove \\(Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nUna dimostrazione numerica di questo principio è fornita sotto.\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolare la varianza di x + y con ddof = 0\nvar_x_y &lt;- mean((x + y - mean(x + y))^2)\nvar_x_y\n#&gt; [1] 35.2\n\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolo della varianza combinata\nresult &lt;- mean((x - mean(x))^2) + \n          mean((y - mean(y))^2) + \n          2 * cov(x, y) * (length(x) - 1) / length(x)\nresult\n#&gt; [1] 35.2\n\nVarianza della media di variabili indipendenti. La media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione, ha varianza\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n\\]\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIl principio precedente è illustrato dalla seguente simulazione.\n\n# Creare la popolazione\nset.seed(123)  # Per riproducibilità\npopulation &lt;- rnorm(10000, mean = 50, sd = 10)\n\n# Definire dimensione del campione e numero di campioni\nsample_size &lt;- 30\nnum_samples &lt;- 100000\n\n# Creare un vettore per memorizzare le medie campionarie\nsample_means &lt;- numeric(num_samples)\n\n# Generare i campioni e calcolare le medie\nfor (i in 1:num_samples) {\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  sample_means[i] &lt;- mean(sample)\n}\n\n# Calcolare la varianza delle medie campionarie\nsampling_dist_mean_var &lt;- var(sample_means) * ((num_samples - 1) / num_samples)  # ddof = 0\nsampling_dist_mean_var\n#&gt; [1] 3.33\n\nIl valore teorico della varianza della distribuzione campionaria della media è\n\n10^2 / 30\n#&gt; [1] 3.33\n\n\n\n\n\n31.3.3 Varianza di una variabile casuale continua\nPer una variabile casuale continua \\(X\\), la varianza è definita come:\n\\[\n\\mathbb{V}(X) = \\int_{-\\infty}^{+\\infty} \\large[x - \\mathbb{E}(X)\\large]^2 p(x) \\,\\operatorname {d}\\!x.\n\\tag{31.7}\\]\nAnalogamente al caso discreto, la varianza di una variabile casuale continua \\(X\\) una misura della dispersione, ovvero la “distanza” media quadratica attesa dei valori \\(x\\) rispetto alla loro media \\(\\mathbb{E}(X)\\). In altre parole, la varianza quantifica quanto i valori della variabile casuale si discostano tipicamente dal loro valore medio.\n\n31.3.4 Deviazione standard\nQuando si lavora con le varianze, i valori sono elevati al quadrato, il che può rendere i numeri significativamente più grandi (o più piccoli) rispetto ai dati originali. Per riportare questi valori all’unità di misura della scala originale, si prende la radice quadrata della varianza. Il risultato ottenuto è chiamato deviazione standard ed è comunemente indicato con la lettera greca \\(\\sigma\\).\n\nDefinizione 31.3 La deviazione standard, o scarto quadratico medio, è definita come la radice quadrata della varianza:\n\\[\n\\sigma_X = \\sqrt{\\mathbb{V}(X)}.\n\\tag{31.8}\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale fornisce una misura della dispersione, ossia la “distanza” tipica o prevista dei valori \\(x\\) rispetto alla loro media.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nPer i dadi equilibrati dell’esempio precedente, la deviazione standard della variabile casuale \\(S\\) è pari a \\(\\sqrt{5.833} = 2.415\\). Questo valore indica quanto i risultati della somma dei due dadi tendono a variare attorno alla loro media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#standardizzazione",
    "href": "chapters/probability/08_expval_var.html#standardizzazione",
    "title": "31  Proprietà delle variabili casuali",
    "section": "\n31.4 Standardizzazione",
    "text": "31.4 Standardizzazione\n\nDefinizione 31.4 Data una variabile casuale \\(X\\), si dice variabile standardizzata di \\(X\\) l’espressione\n\\[\nZ = \\frac{X - \\mathbb{E}(X)}{\\sigma_X}.\n\\tag{31.9}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#il-teorema-di-chebyshev",
    "href": "chapters/probability/08_expval_var.html#il-teorema-di-chebyshev",
    "title": "31  Proprietà delle variabili casuali",
    "section": "\n31.5 Il teorema di Chebyshev",
    "text": "31.5 Il teorema di Chebyshev\nIl Teorema di Chebyshev ci permette di stimare la probabilità che una variabile aleatoria si discosti dal suo valore atteso (media) di una certa quantità. In altre parole, ci fornisce un limite superiore alla probabilità che una variabile aleatoria assuma valori “estremi”.\nIl teorema di Chebyshev afferma che, per qualsiasi variabile aleatoria X con media E(X) e varianza Var(X), e per qualsiasi numero reale k &gt; 0, si ha:\n\\[\nP(\\mid X - E(X)\\mid \\geq k \\sigma) \\leq 1/k^2,\n\\tag{31.10}\\]\ndove:\n\n\n\\(P(\\mid X - E(X)\\mid \\geq k \\sigma)\\) è la probabilità che lo scarto assoluto tra X e la sua media sia maggiore o uguale a k volte la deviazione standard (σ).\nσ è la radice quadrata della varianza, ovvero la deviazione standard.\n\nCosa ci dice questo teorema?\n\n\nLimite superiore: Il teorema ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di più di k deviazioni standard.\n\nQualsiasi distribuzione: La bellezza di questo teorema è che vale per qualsiasi distribuzione di probabilità, a patto che la media e la varianza esistano.\n\nUtilizzo: Il teorema di Chebyshev è molto utile quando non conosciamo la distribuzione esatta di una variabile aleatoria, ma conosciamo la sua media e la sua varianza.\n\nIn sintesi, il teorema di Chebyshev ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di una certa quantità, in base alla sua varianza. Il teorema di Chebyshev ci permette quindi di fare inferenze sulla distribuzione di una variabile aleatoria anche quando abbiamo informazioni limitate.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nSupponiamo di avere una variabile aleatoria \\(X\\) con media 100 e varianza 25. Vogliamo stimare la probabilità che \\(X\\) assuma valori al di fuori dell’intervallo [90, 110].\nIn questo caso, \\(k\\) = 2 (poiché 10 è uguale a 2 volte la deviazione standard, che è 5). Applicando il teorema di Chebyshev, otteniamo:\n\\[\nP(\\mid X - 100 \\mid \\geq 10) \\leq \\left( \\frac{1}{2} \\right)^2 = 0.25\n\\]\nQuindi, possiamo affermare con certezza che al massimo il 25% dei valori di X saranno al di fuori dell’intervallo [90, 110].",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#momenti-di-variabili-casuali",
    "href": "chapters/probability/08_expval_var.html#momenti-di-variabili-casuali",
    "title": "31  Proprietà delle variabili casuali",
    "section": "\n31.6 Momenti di variabili casuali",
    "text": "31.6 Momenti di variabili casuali\n\nDefinizione 31.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densità \\(p(x)\\), la quantità\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{31.11}\\]\nSe \\(X\\) è una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i),\n\\tag{31.12}\\]\ndove:\n\n\n\\(E(X^q)\\) rappresenta il valore atteso di \\(X\\) elevato alla \\(q\\)-esima potenza.\n\n\\(x_i\\) sono i possibili valori della variabile discreta.\n\n\\(P(x_i)\\) è la probabilità associata a ciascun valore discreto.\n\n\nI momenti sono parametri statistici che forniscono informazioni importanti sulle caratteristiche di una variabile casuale. Tra questi, i più noti e utilizzati sono:\n\nIl momento del primo ordine (\\(q\\) = 1): corrisponde al valore atteso (o media) della variabile casuale \\(X\\).\nIl momento del secondo ordine (\\(q\\) = 2): quando calcolato rispetto alla media, corrisponde alla varianza.\n\nPer i momenti di ordine superiore al primo, è comune calcolarli rispetto al valore medio di \\(X\\). Questo si ottiene applicando una traslazione: \\(x_0 = x − \\mathbb{E}(X)\\), dove \\(x_0\\) rappresenta lo scarto dalla media. In particolare, il momento centrale del secondo ordine, calcolato con questa traslazione, corrisponde alla definizione di varianza.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn R, possiamo calcolare il valore atteso e la varianza di variabili casuali discrete utilizzando vettori di valori e probabilità.\nConsideriamo una variabile casuale \\(X\\) che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilità: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\nx &lt;- 0:6\nprint(x)\n#&gt; [1] 0 1 2 3 4 5 6\n\nIl vettore px conterrà le probabilità associate ai valori x:\n\npx &lt;- c(0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)\nprint(px)\n#&gt; [1] 0.1 0.2 0.3 0.1 0.1 0.0 0.2\n\nControlliamo che la somma sia 1:\n\nsum(px)\n#&gt; [1] 1\n\nCalcoliamo il valore atteso di \\(X\\) implementando la formula del valore atteso utilizzando i vettori x e px:\n\nx_ev &lt;- sum(x * px)\nx_ev\n#&gt; [1] 2.7\n\nCalcoliamo la varianza di \\(X\\) usando i vettori x e px:\n\nx_var &lt;- sum((x - x_ev)^2 * px)\nx_var\n#&gt; [1] 3.81\n\nCalcoliamo la deviazione standard di \\(X\\) prendendo la radice quadrata della varianza:\n\nx_sd &lt;- sqrt(x_var)\nx_sd\n#&gt; [1] 1.95\n\nPer rappresentare graficamente la distribuzione di massa, possiamo usare ggplot2:\n\ndf &lt;- data.frame(x = x, pmf = px)\nggplot(df, aes(x = x, y = pmf)) +\n  geom_point(color = \"#832F2B\", size = 3) +\n  geom_segment(aes(xend = x, yend = 0), linewidth = 1) +\n  labs(title = \"Distribuzione di massa di probabilità\", \n       x = \"Valori\", y = \"Probabilità\")\n\n\n\n\n\n\n\nQuesto codice calcola il valore atteso, la varianza e la deviazione standard di una variabile casuale discreta e rappresenta graficamente la distribuzione di massa, tutto in R.\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nUn esempio pratico dell’uso del valore atteso e della varianza in psicologia è rappresentato dagli studi sulla memoria episodica, in particolare attraverso il paradigma sperimentale delle risposte “Remember-Know”. Questo paradigma permette di esplorare come le persone riconoscano eventi passati, distinguendo tra ricordi dettagliati e semplici sensazioni di familiarità.\nIl Paradigma “Remember-Know”\nIn un tipico esperimento di memoria episodica:\n\nAi partecipanti viene presentata una lista di stimoli (es. parole o immagini).\nDopo un intervallo di tempo, viene mostrata una nuova lista contenente elementi precedentemente visti (old) e elementi nuovi (new).\n\nPer ogni stimolo old riconosciuto, i soggetti devono specificare se:\n\n\nRemember (R): Ricordano consapevolmente dettagli contestuali dell’episodio di encoding (es. “Ricordo che questa parola era scritta in rosso”).\n\nKnow (K): Avvertono familiarità con lo stimolo, ma senza accesso a dettagli specifici (es. “Sembra conosciuto, ma non so perché”).\n\n\nMiss: Non riconoscono lo stimolo.\n\n\n\nLa variabile in gioco è quindi categorica e discreta, con tre possibili esiti per gli stimoli old: {R, K, Miss}.\nModelli Teorici e Previsioni Statistiche\nDue importanti teorie cercano di spiegare come avviene questo riconoscimento:\nTeoria del Processo Unico (Strength Theory) (e.g., Wixted & Mickes, 2010)\n\n\nIpotesi centrale:\nC’è una sola dimensione continua (la “forza mnemonica”) che determina il tipo di risposta.\n\nLe risposte Remember derivano da tracce molto forti, quelle Know da tracce di forza intermedia, e i Miss da tracce troppo deboli.\n\n\n\nImplicazioni statistiche: molte risposte Know, meno risposte Remember, bassa varianza.\n\nTeoria del Doppio Processo (Dual-Process) (e.g., Yonelinas, 2002)\n\n\nIpotesi centrale:\nCi sono due processi indipendenti:\n\n\nRecollection (R): Processo qualitativo e binario (presente/assente), legato al ricordo consapevole di dettagli contestuali.\n\n\nFamiliarità (K): Processo continuo, basato su una sensazione generica di familiarità.\n\n\n\nImplicazioni statistiche: numero simile di risposte Remember e Know, alta varianza.\n\nQui entrano in gioco i concetti statistici: ogni teoria formula previsioni diverse sul valore atteso (es. proporzione attesa di risposte R o K) e sulla varianza (dispersione dei dati attorno a questi valori). Confrontando le osservazioni sperimentali con le aspettative teoriche, è possibile testare quale modello sia più coerente con i dati empirici, illustrando come strumenti probabilistici possano chiarire meccanismi cognitivi complessi.\nConfronto Statistico: Previsioni Teoriche\nPer confrontare quantitativamente le previsioni dei due modelli, consideriamo un esperimento ipotetico con 100 stimoli old. Assegniamo punteggi numerici alle categorie di risposta per trasformarle in una variabile discreta, facilitando il calcolo di valore atteso e varianza:\n\n\nRemember (R) = 2\n\n\nKnow (K) = 1\n\nMiss = 0\n\nQuesta codifica riflette l’intensità mnemonica associata a ciascuna risposta, permettendo di quantificare le differenze teoriche tra i modelli.\n1. Modello Single-Process (Forza continua)\nSecondo questa teoria, la distribuzione attesa delle risposte è:\n\n\nCategoria\nR\nK\nMiss\n\n\n% Prevista\n25%\n60%\n15%\n\n\nCalcoli statistici:\n- Valore atteso (media ponderata):\\[\n  E(X) = (2 \\cdot 0.25) + (1 \\cdot 0.60) + (0 \\cdot 0.15) = 1.10\n  \\]\n- Varianza (dispersione attorno alla media):\\[\n  \\begin{aligned}\n  Var(X) &= (2-1.10)^2 \\cdot 0.25 + (1-1.10)^2 \\cdot 0.60 + (0-1.10)^2 \\cdot 0.15 \\\\\n  &= 0.2025 + 0.006 + 0.1815 = 0.39\n  \\end{aligned}\n  \\]\n2. Modello Dual-Process (Recollection e Familiarità)\nLa teoria prevede una distribuzione basata su due meccanismi indipendenti:\n\n\nCategoria\nR\nK\nMiss\n\n\n% Prevista\n40%\n40%\n20%\n\n\nCalcoli statistici:\n- Valore atteso:\\[\n  E(X) = (2 \\cdot 0.40) + (1 \\cdot 0.40) + (0 \\cdot 0.20) = 1.20\n  \\]\n- Varianza:\\[\n  \\begin{aligned}\n  Var(X) &= (2-1.20)^2 \\cdot 0.40 + (1-1.20)^2 \\cdot 0.40 + (0-1.20)^2 \\cdot 0.20 \\\\\n  &= 0.256 + 0.016 + 0.288 = 0.56\n  \\end{aligned}\n  \\]\nSintesi del Confronto\nI due modelli generano previsioni distinte, riassunte nella tabella seguente:\n\n\n\n\n\n\n\n\nModello\nValore Atteso\nVarianza\nInterpretazione\n\n\n\nSingle-Process\n1.10\n0.39\nMedia più bassa, varianza ridotta (distribuzione concentrata attorno a K).\n\n\nDual-Process\n1.20\n0.56\nMedia più alta, varianza elevata (effetto della miscela tra due processi).\n\n\n\n\n\nValore atteso: Il modello dual-process predice una media superiore, coerente con la maggiore proporzione attesa di risposte Remember.\n\n\nVarianza: La differenza nella dispersione (0.39 vs. 0.56) riflette l’eterogeneità introdotta dalla separazione tra recollection e familiarità nel modello duale.\n\nApplicazione a Dati Empirici\nSupponiamo ora di aver raccolto dati reali da 100 soggetti che hanno prodotto questa distribuzione:\n\n\nR\nK\nMiss\n\n\n38%\n42%\n20%\n\n\nCalcoliamo il valore atteso e la varianza empiriche:\n\\[\n  E(X) = 2 \\cdot 0.38 + 1 \\cdot 0.42 + 0 \\cdot 0.20 = 1.18\n  \\]\n\\[\n  Var(X) = (2-1.18)^2 \\cdot 0.38 + (1-1.18)^2 \\cdot 0.42 + (0-1.18)^2 \\cdot 0.20 = 0.55\n  \\]\nRisultati:\n\n\nDati\nValore Atteso\nVarianza\n\n\nEmpirici\n1.18\n0.55\n\n\nConfrontando questi risultati con le previsioni teoriche, notiamo che i dati empirici si avvicinano molto più al modello dual-process (valore atteso: 1.20 vs. 1.18; varianza: 0.56 vs. 0.55).\nImplicazioni Psicologiche e Cliniche\n\nTeoriche: Il confronto tra distribuzioni osservate e teoriche, usando valore atteso e varianza, consente di identificare quale teoria cognitiva spieghi meglio i dati.\nCliniche: In contesti clinici (es. valutazione di deficit cognitivi), questo approccio consente di identificare se un paziente mostra un profilo riconducibile a un danno selettivo della recollection (R ↓) o della familiarità (K ↓).\n\nQuesto framework illustra come strumenti probabilistici di base possano tradurre ipotesi psicologiche complesse in predizioni quantitative verificabili, avanzando la comprensione dei meccanismi cognitivi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#riflessioni-conclusive",
    "href": "chapters/probability/08_expval_var.html#riflessioni-conclusive",
    "title": "31  Proprietà delle variabili casuali",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn conclusione, i concetti di valore atteso e varianza sono fondamentali per comprendere il comportamento delle variabili casuali. Il valore atteso fornisce una misura centrale, rappresentando il “valore tipico” che ci si aspetta di osservare, mentre la varianza quantifica la dispersione dei valori attorno a questa media, offrendo una visione più completa della distribuzione. Questi strumenti sono essenziali per l’analisi e la modellizzazione statistica, fornendo le basi per valutare e interpretare la variabilità nei fenomeni aleatori.\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Calcolo del Valore Atteso per Variabili Discrete\nUtilizzando i dati raccolti dagli studenti sulla SWLS, calcola il valore atteso della soddisfazione con la vita (\\(X\\)). Organizza i dati come nell’esempio seguente e interpretalo come se fosse la distribuzione di probabilità nella popolazione:\n\n\nSWLS Score\nProbabilità \\(P(X)\\)\n\n\n\n\n5\n0.05\n\n\n10\n0.10\n\n\n15\n0.20\n\n\n20\n0.30\n\n\n25\n0.20\n\n\n30\n0.10\n\n\n35\n0.05\n\n\n\n\nCalcola il valore atteso di \\(X\\), \\(\\mathbb{E}(X)\\).\nInterpreta il risultato ottenuto.\n\nEsercizio 2: Varianza e Deviazione Standard\nData la stessa distribuzione della SWLS utilizzata nell’esercizio precedente:\n\nCalcola la varianza \\(\\mathbb{V}(X)\\).\nCalcola la deviazione standard \\(\\sigma_X\\).\nCommenta il significato della dispersione dei valori rispetto alla media.\n\nEsercizio 3: Proprietà del Valore Atteso\nUtilizzando la distribuzione della LSNS-6:\n\nDefinisci una nuova variabile casuale \\(Y = 2X + 3\\).\nCalcola il valore atteso di \\(Y\\), \\(\\mathbb{E}(Y)\\), utilizzando la linearità dell’operatore di aspettazione.\nVerifica il risultato calcolando direttamente \\(\\mathbb{E}(Y)\\) dalla distribuzione di probabilità di \\(Y\\).\n\nUtilizza una distribuzione della LSNS-6 organizzata come segue (sostituisci i valori presenti con quelli del campione):\n\n\nLSNS-6 Score\nProbabilità \\(P(Y)\\)\n\n\n\n\n5\n0.10\n\n\n10\n0.15\n\n\n15\n0.25\n\n\n20\n0.25\n\n\n25\n0.15\n\n\n30\n0.10\n\n\n\nEsercizio 4: Applicazione del Teorema di Chebyshev\nSia la soddisfazione con la vita (SWLS) distribuita con media \\(\\mu = 3.2\\) e deviazione standard \\(\\sigma = 0.8\\).\n\nUsa il teorema di Chebyshev per trovare un limite superiore alla probabilità che un valore di SWLS sia oltre due deviazioni standard dalla media.\nConfronta questo risultato con la probabilità empirica calcolata utilizzando i dati raccolti.\n\nEsercizio 5: Standardizzazione e Distribuzione Normale\n# Definizione dei dati osservati della LSNS-6 (sostituisci con i dati reali se disponibili)\nlsns6_scores &lt;- c(5, 8, 10, 12, 15, 18, 20, 22, 25, 28)\n\n# Parametri della distribuzione\nmu &lt;- 12   # Media della LSNS-6\nsigma &lt;- 4  # Deviazione standard della LSNS-6\n\n# Standardizzazione dei valori osservati\nz_scores &lt;- (lsns6_scores - mu) / sigma\n\n# Creazione dell'istogramma della distribuzione standardizzata\nhist(z_scores, \n     breaks = 10, \n     col = \"lightblue\", \n     main = \"Istogramma della distribuzione standardizzata di LSNS-6\", \n     xlab = \"Z-score\", \n     ylab = \"Frequenza\",\n     probability = TRUE)\n\n# Sovrapposizione della curva normale standard\ncurve(dnorm(x, mean = 0, sd = 1), col = \"red\", lwd = 2, add = TRUE)\n\nStandardizzazione: La trasformazione dei punteggi della LSNS-6 in Z-score permette di esprimere ogni valore in termini di deviazioni standard rispetto alla media. Un valore \\(Z = 1\\) significa che il punteggio di LSNS-6 è una deviazione standard sopra la media, mentre \\(Z = -1\\) significa che è una deviazione standard sotto la media.\nIstogramma della distribuzione standardizzata: Il grafico mostra la distribuzione dei punteggi standardizzati. Se la distribuzione originale è simile a una normale, l’istogramma dei punteggi standardizzati dovrebbe assomigliare a una distribuzione normale standard.\nConfronto con la distribuzione normale standard: La curva rossa rappresenta la densità di una normale standard (\\(\\mathcal{N}(0,1)\\)). Se i dati sono approssimativamente normali, l’istogramma dei punteggi standardizzati dovrebbe seguire la forma della curva normale standard. Differenze marcate potrebbero indicare asimmetria o curtosi anomale nella distribuzione dei punteggi LSNS-6.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Calcolo del Valore Atteso della SWLS\nLa Satisfaction With Life Scale (SWLS) è composta da 5 item, ciascuno valutato su una scala Likert da 1 a 7. Supponiamo di avere la seguente distribuzione di probabilità per il punteggio totale della SWLS basata su un campione di studenti:\n\n\nSWLS Score\nProbabilità \\(P(X)\\)\n\n\n\n\n5\n0.05\n\n\n10\n0.10\n\n\n15\n0.20\n\n\n20\n0.30\n\n\n25\n0.20\n\n\n30\n0.10\n\n\n35\n0.05\n\n\n\nDomanda:\nCalcola il valore atteso \\(\\mathbb{E}[X]\\) del punteggio SWLS.\nSoluzione: Il valore atteso si calcola come:\n\\[\n\\mathbb{E}[X] = \\sum x_i P(x_i)\n\\]\nCalcoliamo in R:\n# Definizione dei valori SWLS e delle probabilità\nswls_scores &lt;- c(5, 10, 15, 20, 25, 30, 35)\nprob_swls &lt;- c(0.05, 0.10, 0.20, 0.30, 0.20, 0.10, 0.05)\n\n# Calcolo del valore atteso\nexpected_swls &lt;- sum(swls_scores * prob_swls)\nexpected_swls\nRisultato:\\[\n\\mathbb{E}[X] = 20\n\\]\nIl valore atteso rappresenta la media teorica della soddisfazione con la vita nella popolazione, assumendo che la distribuzione dei punteggi SWLS segua esattamente le probabilità fornite. In altre parole, se prendessimo un numero molto grande di individui con questa distribuzione di probabilità, il punteggio medio atteso sarebbe 20. Questo suggerisce che, nella popolazione considerata, il livello medio di soddisfazione con la vita si colloca al centro della scala SWLS.\nEsercizio 2: Calcolo della Varianza e Deviazione Standard della SWLS\n# Definizione dei dati\nswls_scores &lt;- c(5, 10, 15, 20, 25, 30, 35)\nprobabilities &lt;- c(0.05, 0.10, 0.20, 0.30, 0.20, 0.10, 0.05)\n\n# Calcolo del valore atteso (media attesa)\nexpected_value &lt;- sum(swls_scores * probabilities)\n\n# Calcolo della varianza\nvariance &lt;- sum((swls_scores - expected_value)^2 * probabilities)\n\n# Calcolo della deviazione standard\nstd_deviation &lt;- sqrt(variance)\n\n# Stampa dei risultati\ncat(\"Valore atteso (E[X]):\", expected_value, \"\\n\")\ncat(\"Varianza (Var[X]):\", variance, \"\\n\")\ncat(\"Deviazione standard (σ_X):\", std_deviation, \"\\n\")\n\n\nVarianza: Misura la dispersione dei punteggi SWLS rispetto alla media attesa. Se la varianza è alta, significa che i punteggi sono molto variabili; se è bassa, significa che i punteggi sono più concentrati attorno al valore atteso.\n\nDeviazione standard: È la radice quadrata della varianza e ha la stessa unità di misura dei dati originali. Fornisce un’indicazione della dispersione media dei punteggi rispetto alla media.\n\nSe la deviazione standard è elevata, significa che nella popolazione ci sono sia individui con livelli di soddisfazione molto bassi sia individui con livelli molto alti. Se è bassa, i punteggi sono più omogenei intorno alla media.\nEsercizio 3: Calcolo del Valore Atteso della Scala della Rete Sociale di Lubben (LSNS-6)\n# Definizione dei dati della LSNS-6\nlsns_scores &lt;- c(5, 10, 15, 20, 25, 30)\nprobabilities &lt;- c(0.10, 0.15, 0.25, 0.25, 0.15, 0.10)\n\n# Definizione della trasformazione della variabile casuale Y = 2X + 3\ny_values &lt;- 2 * lsns_scores + 3\n\n# Calcolo del valore atteso di X\nexpected_x &lt;- sum(lsns_scores * probabilities)\n\n# Utilizzo della linearità dell'operatore di aspettazione: E[Y] = 2E[X] + 3\nexpected_y_from_x &lt;- 2 * expected_x + 3\n\n# Calcolo diretto del valore atteso di Y\nexpected_y_direct &lt;- sum(y_values * probabilities)\n\n# Stampa dei risultati\ncat(\"Valore atteso di X (E[X]):\", expected_x, \"\\n\")\ncat(\"Valore atteso di Y calcolato con la linearità (E[Y] = 2E[X] + 3):\", expected_y_from_x, \"\\n\")\ncat(\"Valore atteso di Y calcolato direttamente dalla distribuzione di probabilità di Y:\", expected_y_direct, \"\\n\")\n\n\nLinearità dell’operatore di aspettazione: Questo principio afferma che se una variabile casuale \\(X\\) viene trasformata linearmente in \\(Y = aX + b\\), allora il valore atteso di \\(Y\\) è dato da:\n\\[\n\\mathbb{E}(Y) = a \\mathbb{E}(X) + b\n\\]\nQuesto semplifica il calcolo senza dover ridefinire una nuova distribuzione di probabilità.\n\nVerifica del risultato: Dopo aver calcolato \\(\\mathbb{E}(Y)\\) con la proprietà di linearità, lo confrontiamo con il calcolo diretto utilizzando la distribuzione trasformata. Se i due valori coincidono, confermiamo che la proprietà di linearità è rispettata.\nSignificato pratico: La trasformazione lineare di una variabile casuale può rappresentare un’operazione reale come la conversione di punteggi da una scala all’altra. Il valore atteso si comporta linearmente, il che è utile per interpretare trasformazioni senza dover ricalcolare completamente la distribuzione.\n\nEsercizio 4: Probabilità secondo il Teorema di Chebyshev\nIl Teorema di Chebyshev afferma che per qualsiasi distribuzione, la probabilità che un valore sia oltre \\(k\\) deviazioni standard dalla media è al massimo:\n\\[\nP(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}\n\\]\nSostituendo \\(k = 2\\):\n\\[\nP(|X - 3.2| \\geq 2 \\cdot 0.8) \\leq \\frac{1}{2^2} = \\frac{1}{4} = 0.25\n\\]\nQuindi, il Teorema di Chebyshev fornisce un limite superiore del 25% alla probabilità che un valore di SWLS sia oltre due deviazioni standard dalla media.\nPer confrontare questo risultato con la probabilità empirica, è necessaro usare i dati raccolti sulla SWLS.\nEsercizio 5: Standardizzazione del Punteggio LSNS-6\nDomanda:\nStandardizza il punteggio LSNS-6 trasformandolo nella variabile standardizzata \\(Z\\).\n\\[\nZ = \\frac{Y - \\mathbb{E}(Y)}{\\sigma_Y}\n\\]\nSoluzione: Calcoliamo in R:\n# Standardizzazione dei punteggi LSNS-6\nz_lsns &lt;- (lsns_scores - expected_lsns) / sd_lsns\nz_lsns\nRisultato:\n\n\nLSNS-6 Score\nZ-Score\n\n\n\n5\n-2.23\n\n\n10\n-1.34\n\n\n15\n-0.45\n\n\n20\n0.45\n\n\n25\n1.34\n\n\n30\n2.23\n\n\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio 6: Personalizzazione degli Interventi Basati sulla Probabilità Condizionata\nUno psicologo scolastico vuole identificare quali studenti potrebbero trarre maggiore beneficio da un programma di supporto psicologico. Dalla letteratura, si sa che la probabilità di avere livelli bassi di soddisfazione con la vita (SWLS ≤ 15) è più alta tra gli studenti che riportano elevati livelli di stress accademico.\nDai dati raccolti su un campione di studenti:\n\n\\(P(\\text{SWLS} \\leq 15) = 0.35\\)\n\\(P(\\text{Stress Alto}) = 0.40\\)\n\\(P(\\text{SWLS} \\leq 15 \\mid \\text{Stress Alto}) = 0.60\\)\n\nDomanda Se uno studente è scelto a caso, qual è la probabilità che abbia un alto livello di stress dato che il suo punteggio SWLS è ≤ 15?\nEsercizio 7: Prevedere il Successo di un Intervento Psicologico Uno psicologo clinico sta valutando l’efficacia di un intervento sulla riduzione dell’ansia. Ha raccolto i dati di 100 pazienti e ha osservato che il miglioramento medio nei punteggi di ansia (misurati con DASS-21) è di 5 punti con una deviazione standard di 2.5.\nSupponiamo che il miglioramento sia una variabile aleatoria normale con media 5 e deviazione standard 2.5.\nDomanda Qual è la probabilità che un paziente scelto a caso migliori di almeno 7 punti?\nEsercizio 8: Allocazione Ottimale delle Risorse in un Programma di Prevenzione Uno psicologo organizza un programma di sensibilizzazione sulla salute mentale in diverse scuole. Ha raccolto dati sulla frequenza con cui gli studenti si rivolgono allo sportello di ascolto, con la seguente distribuzione:\n\n\nNumero di Visite\nProbabilità\n\n\n\n0\n0.40\n\n\n1\n0.30\n\n\n2\n0.15\n\n\n3+\n0.15\n\n\n\nDomanda Se lo psicologo ha risorse per organizzare colloqui individuali solo per il 30% degli studenti, quale soglia può usare per selezionare gli studenti più bisognosi in base alla distribuzione delle visite?\nEsercizio 9: Misurare la Variabilità della Risposta a un Trattamento Uno psicologo somministra un trattamento per la depressione e misura la variazione nei punteggi di depressione su un campione di pazienti prima e dopo l’intervento.\nLe variazioni seguono questa distribuzione:\n\n\nΔ Punteggio DASS-21\nProbabilità\n\n\n\n-10\n0.10\n\n\n-5\n0.20\n\n\n0\n0.40\n\n\n+5\n0.20\n\n\n+10\n0.10\n\n\n\nDomanda Qual è la deviazione standard della variazione nei punteggi di depressione?\nEsercizio 10: Probabilità di un Fallimento in un Programma di Sensibilizzazione Uno psicologo organizza un programma per ridurre il pregiudizio sulla salute mentale. Dai dati precedenti, la probabilità di successo di ogni evento di sensibilizzazione è del 70%. Se organizza 5 eventi indipendenti, qual è la probabilità che almeno 1 fallisca?\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 6: Personalizzazione degli Interventi Basati sulla Probabilità Condizionata\nUtilizziamo la formula della probabilità condizionata:\n\\[\nP(\\text{Stress Alto} \\mid \\text{SWLS} \\leq 15) = \\frac{P(\\text{SWLS} \\leq 15 \\mid \\text{Stress Alto}) P(\\text{Stress Alto})}{P(\\text{SWLS} \\leq 15)}\n\\]\nCalcoliamo in R:\np_swls_low &lt;- 0.35\np_stress_high &lt;- 0.40\np_swls_given_stress &lt;- 0.60\n\np_stress_given_swls &lt;- (p_swls_given_stress * p_stress_high) / p_swls_low\np_stress_given_swls\nRisultato Lo psicologo può usare questa informazione per identificare studenti con alta probabilità di avere stress elevato, anche se non hanno segnalato direttamente il problema, e offrire supporto mirato.\nEsercizio 7: Prevedere il Successo di un Intervento Psicologico\nUsiamo la normalizzazione:\n\\[\nZ = \\frac{X - \\mu}{\\sigma}\n\\]\ne calcoliamo la probabilità corrispondente:\nmean_improvement &lt;- 5\nsd_improvement &lt;- 2.5\nthreshold &lt;- 7\n\np_improve_7 &lt;- 1 - pnorm(threshold, mean = mean_improvement, sd = sd_improvement)\np_improve_7\nRisultato Questo aiuta lo psicologo a comunicare ai pazienti la probabilità di ottenere miglioramenti significativi e ad adattare le aspettative dell’intervento.\nEsercizio 8: Allocazione Ottimale delle Risorse in un Programma di Prevenzione\nSoluzione Calcoliamo la probabilità cumulativa:\nvisits &lt;- c(0, 1, 2, 3)\nprobabilities &lt;- c(0.40, 0.30, 0.15, 0.15)\ncumulative_prob &lt;- cumsum(probabilities)\n\n# Determinare la soglia per il 30% più bisognoso\nthreshold &lt;- visits[min(which(cumulative_prob &gt;= 0.70))]\nthreshold\nRisultato Lo psicologo può decidere di offrire supporto prioritario a studenti con almeno 2 visite, massimizzando l’impatto con risorse limitate.\nEsercizio 9: Misurare la Variabilità della Risposta a un Trattamento\nSoluzione Calcoliamo la varianza e la deviazione standard:\nscore_changes &lt;- c(-10, -5, 0, 5, 10)\nprobabilities &lt;- c(0.10, 0.20, 0.40, 0.20, 0.10)\n\n# Media attesa\nexpected_change &lt;- sum(score_changes * probabilities)\n\n# Varianza\nvariance_change &lt;- sum((score_changes - expected_change)^2 * probabilities)\n\n# Deviazione standard\nsd_change &lt;- sqrt(variance_change)\nsd_change\nRisultato Se la deviazione standard è grande, significa che l’effetto del trattamento è molto variabile e potrebbero essere necessarie strategie personalizzate.\nEsercizio 10: Probabilità di un Fallimento in un Programma di Sensibilizzazione\nUsiamo la distribuzione binomiale:\np_success &lt;- 0.70\nn_events &lt;- 5\n\np_failure_at_least_one &lt;- 1 - dbinom(5, n_events, p_success)\np_failure_at_least_one\nRisultato Lo psicologo può pianificare strategie di miglioramento sapendo la probabilità di un fallimento.\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 3\nConsiglio gli esercizi di base disponibili nella seguente pagina web.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_expval_var.html#bibliografia",
    "href": "chapters/probability/08_expval_var.html#bibliografia",
    "title": "31  Proprietà delle variabili casuali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nWixted, J. T., & Mickes, L. (2010). A continuous dual-process model of remember/know judgments. Psychological Review, 117(4), 1025–1054.\n\n\nYonelinas, A. P. (2002). The nature of recollection and familiarity: A review of 30 years of research. Journal of Memory and Language, 46(3), 441–517.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html",
    "href": "chapters/probability/09_sampling_distr.html",
    "title": "32  Stime, stimatori e parametri",
    "section": "",
    "text": "Introduzione\nIn psicologia – come in molte altre discipline – ci si trova spesso nella situazione di voler comprendere una particolare caratteristica di un’intera popolazione. Tuttavia, difficilmente è possibile raccogliere dati da tutti i membri di tale popolazione, a causa di limiti di tempo, risorse o accessibilità. Ad esempio, potremmo voler stimare la percentuale di persone che soffrono di un determinato disturbo d’ansia oppure la media di un punteggio di memoria a breve termine, ma non siamo in grado di testare ogni singolo individuo appartenente al gruppo di interesse. Per far fronte a questo limite, si sceglie di selezionare un campione di partecipanti (idealmente in modo casuale), dal quale si ricavano le informazioni utili a inferire la caratteristica dell’intera popolazione, riconoscendo un certo grado di incertezza.\nNel linguaggio statistico:\nCome esempio, immaginiamo di voler conoscere la proporzione di adulti che manifestano un certo sintomo d’ansia, indicandola con \\(p\\). Poiché non possiamo (o non vogliamo) esaminare tutta la popolazione, estraiamo un campione casuale di \\(N\\) individui, verifichiamo quanti di loro presentino il sintomo e calcoliamo:\n\\[\n\\hat{p} = \\frac{\\text{numero di individui con il sintomo}}{N}.\n\\]\nQuesto rapporto (detto stima campionaria di \\(p\\)) difficilmente coinciderà esattamente con \\(p\\), ma la teoria probabilistica mostra che, in assenza di distorsioni sistematiche, \\(\\hat{p}\\) tenderà ad avvicinarsi al valore reale al crescere della dimensione del campione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#introduzione",
    "href": "chapters/probability/09_sampling_distr.html#introduzione",
    "title": "32  Stime, stimatori e parametri",
    "section": "",
    "text": "Popolazione: l’insieme completo degli individui (o unità) di interesse. Esempi: tutte le persone che soddisfano certi criteri diagnostici, tutti gli studenti di una scuola, tutte le misurazioni di reazione a uno stimolo sperimentale.\n\nParametro: la quantità (sconosciuta) che descrive la caratteristica d’interesse nella popolazione (esempio: la “vera” proporzione di soggetti con un certo disturbo, oppure la “vera” media di un test cognitivo).\n\nCampione: un sottoinsieme di individui (idealmente estratto in modo casuale) dalla popolazione di interesse.\n\nStima: il valore numerico, calcolato sul campione, che approssima il parametro.\n\nStimatore: la regola o funzione matematica con cui, a partire dai dati del campione, si ottiene la stima.\n\n\n\n\nPanoramica del capitolo\n\nCome le stime dei parametri della popolazione variano da campione a campione.\nNozioni di popolazione, campione, parametro, stima e stimatore.\nConnessione tra stime campionarie e parametri reali della popolazione.\nCalcolare e interpretare il valore atteso e la varianza della media campionaria.\nUtilizzare l’errore standard per rappresentare l’incertezza nelle stime dei parametri.\nLa convergenza delle medie campionarie alla media della popolazione.\nIl teorema per approssimare distribuzioni campionarie con distribuzioni normali.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Sampling Distributions of Estimators (Schervish & DeGroot, 2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#popolazione-e-campione",
    "href": "chapters/probability/09_sampling_distr.html#popolazione-e-campione",
    "title": "32  Stime, stimatori e parametri",
    "section": "\n32.1 Popolazione e campione",
    "text": "32.1 Popolazione e campione\nPer rendere tutto più concreto, supponiamo di voler stimare la frequenza di un sintomo ansioso in un’ampia popolazione, ad esempio l’insieme di tutti gli studenti universitari di un paese. Non potendo sottoporre un questionario a ogni studente, scegliamo un sottoinsieme di individui in modo casuale (cioè il nostro campione) e a ciascuno somministriamo uno strumento standardizzato volto a rilevare la presenza/assenza del sintomo. Il nostro obiettivo finale è utilizzare i dati campionari per trarre inferenze sulla popolazione complessiva, cioè per stimare la vera proporzione \\(p\\) di studenti che manifestano il sintomo.\nQuesta operazione di estrarre un sottogruppo rappresentativo si chiama campionamento. La proporzione di individui con il sintomo d’ansia calcolata nel campione è la nostra stima campionaria (simbolizzata con \\(\\bar{X}\\) o, più spesso in contesto di proporzioni, con \\(\\hat{p}\\)). Se il campione è selezionato in modo corretto e rappresentativo, ci aspettiamo che \\(\\bar{X}\\) rispecchi, con un certo margine di errore, il vero valore di \\(p\\) (il parametro).\n\n32.1.1 Lo stimatore: la proporzione campionaria\nPer formalizzare ulteriormente, consideriamo un modello “urna” in cui la popolazione è immaginata come un’urna piena di “biglie” di due colori (ad esempio, “blu” per sintomo presente, “rosso” per sintomo assente). Estraendo a caso \\(N\\) biglie (cioè selezionando \\(N\\) soggetti), definiamo la variabile casuale \\(X_i\\) come:\n\\[\nX_i =\n\\begin{cases}\n1 & \\text{se l’individuo } i \\text{ presenta il sintomo (biglia blu),}\\\\\n0 & \\text{se l’individuo } i \\text{ non presenta il sintomo (biglia rossa).}\n\\end{cases}\n\\]\nLa proporzione campionaria – ossia la nostra stima empirica di \\(p\\) – è data da:\n\\[\n\\bar{X} \\;=\\; \\frac{1}{N}\\sum_{i=1}^N X_i.\n\\]\nDal punto di vista interpretativo:\n\n\n\\(p\\) è la vera proporzione di studenti (biglie “blu”) nella popolazione;\n\n\\(\\bar{X}\\) è la proporzione di studenti con il sintomo riscontrata nel campione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#distribuzione-campionaria-valore-atteso-e-varianza",
    "href": "chapters/probability/09_sampling_distr.html#distribuzione-campionaria-valore-atteso-e-varianza",
    "title": "32  Stime, stimatori e parametri",
    "section": "\n32.2 Distribuzione campionaria: valore atteso e varianza",
    "text": "32.2 Distribuzione campionaria: valore atteso e varianza\nIl passo cruciale per il ragionamento inferenziale è capire come varia \\(\\bar{X}\\) se ripetiamo la procedura di campionamento molte volte. In altre parole, se estraessimo più volte (indipendentemente) un campione di ampiezza \\(N\\), otterremmo ogni volta un valore di \\(\\bar{X}\\) in genere diverso. La collezione di tutti questi possibili valori (con le rispettive probabilità) si chiama distribuzione campionaria di \\(\\bar{X}\\).\n\n32.2.1 Valore atteso della media (o proporzione) campionaria\nSe \\(X_1, X_2, \\dots, X_n\\) sono variabili aleatorie indipendenti e identicamente distribuite (i.i.d.), ognuna con valore atteso \\(\\mathbb{E}[X_i] = \\mu\\), allora la loro media campionaria\n\\[\n\\bar{X} \\;=\\; \\frac{1}{n}\\sum_{i=1}^n X_i\n\\]\npossiede a sua volta valore atteso\n\\[\n\\mathbb{E}[\\bar{X}] \\;=\\; \\mu.\n\\]\nQuesta semplice formula rivela che \\(\\bar{X}\\) è uno stimatore non distorto per \\(\\mu\\): in media, se ripetessimo infinite volte lo stesso tipo di campionamento, otterremmo una stima che coincide con il vero valore del parametro. Nel caso di variabili 0-1 (come presenza/assenza di sintomo), abbiamo \\(\\mu \\equiv p\\).\n\nDimostrazione. Consideriamo un campione casuale \\(X_1, X_2, \\dots, X_n\\) di variabili aleatorie indipendenti e identicamente distribuite (i.i.d.), ognuna con valore atteso \\(\\mathbb{E}[X_i] = \\mu\\). Vogliamo dimostrare che il valore atteso della media campionaria \\(\\bar{X}\\) è uguale a \\(\\mu\\):\n\\[\n\\mathbb{E}[\\bar{X}] = \\mu.\n\\]\nPasso 1: Definizione di media campionaria.\nLa media campionaria è definita come:\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nPasso 2: Applicazione del valore atteso.\nCalcoliamo il valore atteso di \\(\\bar{X}\\), sfruttando la linearità del valore atteso (l’aspettativa di una somma è la somma delle aspettative):\\[\n\\mathbb{E}[\\bar{X}] = \\mathbb{E}\\left[\\frac{1}{n} \\sum_{i=1}^n X_i\\right].\n\\]\nPasso 3: Portare fuori le costanti.\nIl fattore \\(\\frac{1}{n}\\) è una costante rispetto all’operatore \\(\\mathbb{E}\\):\\[\n\\mathbb{E}[\\bar{X}] = \\frac{1}{n} \\mathbb{E}\\left[\\sum_{i=1}^n X_i\\right].\n\\]\nPasso 4: Separare la somma.\nPer linearità, l’aspettativa della somma è la somma delle aspettative:\\[\n\\mathbb{E}\\left[\\sum_{i=1}^n X_i\\right] = \\sum_{i=1}^n \\mathbb{E}[X_i].\n\\]\nPasso 5: Sfruttare l’identica distribuzione.\nPoiché tutte le \\(X_i\\) sono identicamente distribuite, \\(\\mathbb{E}[X_i] = \\mu\\) per ogni \\(i\\):\\[\n\\sum_{i=1}^n \\mathbb{E}[X_i] = \\sum_{i=1}^n \\mu = n\\mu.\n\\]\nPasso 6: Combinare i risultati.\nSostituendo nel Passo 3:\\[\n\\mathbb{E}[\\bar{X}] = \\frac{1}{n} \\cdot n\\mu = \\mu.\n\\]\nInterpretazione e Significato.\n\n\nNon distorsione (Unbiasedness):\nLa dimostrazione mostra che \\(\\bar{X}\\) è uno stimatore non distorto di \\(\\mu\\). Questo significa che, in media su infinite replicazioni del campionamento, \\(\\bar{X}\\) coincide con il vero valore \\(\\mu\\).\n\n\nIndipendenza non necessaria per l’aspettativa:\nL’indipendenza tra le \\(X_i\\) non è richiesta per questa dimostrazione. Bastano l’identica distribuzione (per garantire \\(\\mathbb{E}[X_i] = \\mu\\)) e la linearità del valore atteso.\n\n\nCaso speciale: proporzione campionaria\nSe le \\(X_i\\) sono variabili di Bernoulli (0-1) con \\(\\mathbb{E}[X_i] = p\\), allora \\(\\bar{X} = \\frac{\\text{numero di successi}}{n}\\) stima la proporzione \\(p\\), e \\(\\mathbb{E}[\\bar{X}] = p\\).\n\nPerché è importante?\nQuesta proprietà è alla base dell’inferenza statistica:\n\nGiustifica l’uso della media campionaria come stima affidabile di \\(\\mu\\).\n\nÈ il fondamento della Legge dei Grandi Numeri: all’aumentare di \\(n\\), \\(\\bar{X}\\) converge a \\(\\mu\\).\n\n\n\n32.2.2 Varianza della media (o proporzione) campionaria\nOltre al valore atteso, un’altra misura fondamentale è la varianza della distribuzione campionaria, che quantifica quanto \\(\\bar{X}\\) tenda a fluttuare attorno a \\(\\mu\\). Se la varianza individuale di ciascun \\(X_i\\) è \\(\\sigma^2\\), allora per la media campionaria si ha:\n\\[\n\\mathrm{Var}(\\bar{X}) \\;=\\; \\frac{\\sigma^2}{n}.\n\\tag{32.1}\\]\nNel caso Bernoulliano (variabili 0-1) con \\(\\mathbb{E}[X_i] = p\\), sappiamo che\n\\[\n\\sigma^2 \\;=\\; p(1-p).\n\\]\nPertanto:\n\\[\n\\mathrm{Var}(\\bar{X}) \\;=\\; \\frac{p \\bigl(1-p\\bigr)}{n}.\n\\]\nLa radice quadrata di questa varianza prende il nome di errore standard (in inglese Standard Error, SE) della media (o della proporzione), e risulta:\n\\[\n\\mathrm{SE}(\\bar{X}) \\;=\\; \\sqrt{\\frac{p\\,(1-p)}{n}}.\n\\]\nCon l’aumentare di \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce, e quindi la nostra stima diventa più “precisa” (in un senso statistico). Ciò spiega perché, anche nella pratica psicologica, aumentare la dimensione del campione riduce l’incertezza nella stima e migliora l’affidabilità dei risultati.\nOsservazione: nella ricerca psicologica, l’errore standard fornisce un’indicazione chiara di quanto, in media, la nostra stima potrebbe deviare dal vero parametro, se ripetessimo il campionamento molte volte. Questo concetto è centrale in molte procedure inferenziali, come la costruzione di intervalli di confidenza o il test di ipotesi, e prepara il terreno per comprendere la cosiddetta distribuzione campionaria della media (argomento che il capitolo proseguirà a trattare).\n\nDimostrazione. Forniamo qui la dimostrazione dell’Equazione 32.1. Assumiamo che \\(X_1, X_2, \\dots, X_n\\) siano variabili casuali indipendenti e identicamente distribuite (i.i.d.) con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo la media campionaria\n\\[\n\\bar{X} \\;=\\; \\frac{1}{n}\\sum_{i=1}^n X_i.\n\\]\nVogliamo calcolare \\(\\mathrm{Var}(\\bar{X})\\). Per prima cosa, notiamo che:\n\\[\n\\mathrm{Var}(a\\,Y) \\;=\\; a^2 \\,\\mathrm{Var}(Y)\n\\]\nper qualunque costante \\(a\\). Nel nostro caso, poniamo \\(a = \\frac{1}{n}\\) e \\(Y = \\sum_{i=1}^n X_i\\). Otteniamo quindi:\n\\[\n\\mathrm{Var}(\\bar{X})\n\\;=\\;\n\\mathrm{Var}\\!\\Bigl(\\tfrac{1}{n}\\sum_{i=1}^n X_i\\Bigr)\n\\;=\\;\n\\frac{1}{n^2} \\, \\mathrm{Var}\\!\\Bigl(\\sum_{i=1}^n X_i\\Bigr).\n\\]\nOra sfruttiamo il fatto che \\(X_1, X_2, \\dots, X_n\\) siano indipendenti. In tal caso, la varianza della somma è la somma delle varianze:\n\\[\n\\mathrm{Var}\\Bigl(\\sum_{i=1}^n X_i\\Bigr)\n\\;=\\;\n\\sum_{i=1}^n \\mathrm{Var}(X_i)\n\\;=\\;\nn \\,\\sigma^2,\n\\]\npoiché \\(\\mathrm{Var}(X_i) = \\sigma^2\\) per tutti gli \\(i\\). Combiniamo dunque i due risultati:\n\\[\n\\mathrm{Var}(\\bar{X})\n\\;=\\;\n\\frac{1}{n^2}\\,\\bigl(n \\,\\sigma^2\\bigr)\n\\;=\\;\n\\frac{\\sigma^2}{n}.\n\\]\nIn sintesi, la chiave della dimostrazione sta nel fattore \\(\\tfrac{1}{n^2}\\) e nel fatto che, per variabili indipendenti, la varianza di una somma è la somma delle varianze. Questo ci consente di concludere che la varianza della media campionaria è \\(\\tfrac{\\sigma^2}{n}\\).\n\nQuesto risultato riflette un’importante proprietà statistica:\n\nall’aumentare di \\(n\\), la varianza della media campionaria diminuisce, rendendo la media campionaria una stima più precisa del valore atteso \\(\\mu\\). La riduzione della varianza è proporzionale a \\(1/n\\), quindi raddoppiare il campione riduce la varianza della media campionaria di un fattore 2.\n\nIn conclusione, la formula \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\) mostra che la precisione della media campionaria aumenta con la dimensione del campione, poiché la varianza diminuisce. Questo principio è alla base dell’importanza di campioni più grandi nella stima statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#la-distribuzione-campionaria-della-media",
    "href": "chapters/probability/09_sampling_distr.html#la-distribuzione-campionaria-della-media",
    "title": "32  Stime, stimatori e parametri",
    "section": "\n32.3 La distribuzione campionaria della media",
    "text": "32.3 La distribuzione campionaria della media\nPer illustrare ulteriormente il concetto di distribuzione campionaria, consideriamo un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, è fondamentale notare che le proprietà e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\nLa distribuzione campionaria ci dà una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all’intera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di \\(\\mu\\). Tuttavia, un altro campione fornirà una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell’incertezza legata al processo di stima.\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nL’istogramma seguente descrive la distribuzione della popolazione.\n\nggplot(data.frame(x = x), aes(x)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density))\n  )\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione. Media:\n\nmean_x &lt;- mean(x) # Media della popolazione\nmean_x\n#&gt; [1] 4.25\n\nVarianza:\n\nvar_x &lt;- var(x) * ((length(x) - 1) / length(x)) # Varianza popolazione\nvar_x\n#&gt; [1] 1.81\n\nConsideriamo tutti i possibili campioni di dimensione \\(n = 2\\) che possono essere estratti dalla popolazione rappresentata dal vettore x. Per generare questi campioni, utilizziamo la funzione expand.grid in R, che consente di creare tutte le combinazioni possibili di valori, includendo le ripetizioni.\nIl risultato sarà un data frame con 16 righe e 2 colonne, dove ogni riga rappresenta una coppia possibile di valori estratti dal vettore x. Questo risultato è in linea con il principio del calcolo combinatorio: quando selezioniamo \\(n\\) elementi da un insieme di \\(k\\) elementi e permettiamo ripetizioni, il numero totale di combinazioni è dato da \\(k^n\\). Nel nostro caso, con \\(k = 4\\) e \\(n = 2\\), otteniamo:\n\\[\n4^2 = 16 \\text{ combinazioni}.\n\\]\nUtilizzando expand.grid, possiamo verificare questo risultato in R:\n\n# Generazione delle combinazioni con ripetizione\nsamples &lt;- expand.grid(x, x)\n\n# Visualizzazione del risultato\nprint(samples)\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nIl data frame risultante mostrerà tutte le possibili coppie \\((x_1, x_2)\\), dove \\(x_1\\) e \\(x_2\\) possono essere scelti indipendentemente dalla popolazione \\(x = \\{2, 4.5, 5, 5.5\\}\\).\nPer calcolare la media di ogni campione di ampiezza \\(n = 2\\), possiamo utilizzare la funzione rowMeans, che calcola la media per ogni riga di una matrice. In questo modo, otteniamo un vettore contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la distribuzione campionaria delle medie dei campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media di ciascun campione\nsample_means &lt;- rowMeans(samples)\nprint(sample_means)\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00 5.25\n#&gt; [16] 5.50\n\nUna rappresentazione grafica della distribuzione campionaria delle medie dei campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x è fornita qui sotto.\n\n# Istogramma delle medie campionarie\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density))\n)\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\n# Creare un data frame con i campioni e le loro medie\ndf &lt;- data.frame(\n  Samples = apply(samples, 1, paste, collapse = \", \"),\n  x_bar = rowMeans(samples)\n)\nprint(df)\n#&gt;     Samples x_bar\n#&gt; 1      2, 2  2.00\n#&gt; 2    4.5, 2  3.25\n#&gt; 3      5, 2  3.50\n#&gt; 4    5.5, 2  3.75\n#&gt; 5    2, 4.5  3.25\n#&gt; 6  4.5, 4.5  4.50\n#&gt; 7    5, 4.5  4.75\n#&gt; 8  5.5, 4.5  5.00\n#&gt; 9      2, 5  3.50\n#&gt; 10   4.5, 5  4.75\n#&gt; 11     5, 5  5.00\n#&gt; 12   5.5, 5  5.25\n#&gt; 13   2, 5.5  3.75\n#&gt; 14 4.5, 5.5  5.00\n#&gt; 15   5, 5.5  5.25\n#&gt; 16 5.5, 5.5  5.50\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media delle medie campionarie\nmean(sample_means)\n#&gt; [1] 4.25\n\nSi noti che questo valore coincide con la media della popolazione.\nLa varianza delle medie campionarie, calcolata empiricamente, può essere ottenuta direttamente dai dati utilizzando la seguente formula:\n\nvar(x) * (length(x) - 1) / length(x) / length(x)\n#&gt; [1] 0.453\n\nQuesto calcolo riflette la formula teorica per la varianza della media campionaria, definita come la varianza dei dati divisa per la dimensione del campione \\(n\\). Tuttavia, poiché la funzione var() in R utilizza \\(n-1\\) al denominatore per fornire una stima non distorta della varianza della popolazione, è necessario applicare un fattore di correzione \\(\\frac{n-1}{n}\\) per ottenere la varianza campionaria corretta. Successivamente, questa varianza viene divisa per \\(n\\) per ottenere la varianza della media campionaria.\nIn alternativa, possiamo calcolare lo stesso valore prendendo la varianza delle medie di tutti i campioni (16 in questo caso):\n\nvar(sample_means) * ((length(sample_means) - 1) / length(sample_means))\n#&gt; [1] 0.906\n\nAnche in questo caso applichiamo il fattore di correzione \\(\\frac{n-1}{n}\\) per ottenere il calcolo corretto della varianza usando la funzione var() in R.\nEntrambi i calcoli forniscono risultati coerenti con la teoria, dimostrando che la varianza delle medie campionarie è inferiore a quella della popolazione.\n\n\n\n\n\n\nCollegamento con Bayes\n\n\n\nNel paradigma frequentista, la distribuzione campionaria descrive la variabilità che avremmo se ripetessimo l’esperimento un gran numero di volte. In Bayes, invece, non ragioniamo su campioni ipotetici, ma sulla distribuzione a posteriori dei parametri, che riflette la nostra incertezza dati i dati osservati. In entrambi i casi il punto chiave è lo stesso: riconoscere che c’è variabilità e incertezza, non solo un numero singolo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#sec-lln",
    "href": "chapters/probability/09_sampling_distr.html#sec-lln",
    "title": "32  Stime, stimatori e parametri",
    "section": "\n32.4 Legge dei Grandi Numeri",
    "text": "32.4 Legge dei Grandi Numeri\nLa Legge dei Grandi Numeri (LLN, dall’inglese Law of Large Numbers) è uno dei pilastri fondamentali della teoria della probabilità. Essa descrive come, all’aumentare del numero di osservazioni, la media campionaria si avvicini stabilmente al valore atteso teorico. In termini formali, se \\(\\bar{X}_n\\) rappresenta la media di \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) con valore atteso \\(\\mu\\), allora \\(\\bar{X}_n \\to \\mu\\) quando \\(n \\to \\infty\\). Questo principio è cruciale per comprendere la relazione tra dati empirici e modelli teorici, come discusso nella sezione sull’interpretazione della probabilità (Capitolo 24).\nEsistono due versioni principali della Legge dei Grandi Numeri:\n\nLegge Forte: La media campionaria \\(\\bar{X}_n\\) converge quasi certamente a \\(\\mu\\), il che significa che, con probabilità 1, la media osservata si avvicina indefinitamente al valore teorico al crescere di \\(n\\).\n\nLegge Debole: La media campionaria \\(\\bar{X}_n\\) converge a \\(\\mu\\) in probabilità, ovvero, per ogni \\(\\varepsilon &gt; 0\\), la probabilità che la differenza tra \\(\\bar{X}_n\\) e \\(\\mu\\) superi \\(\\varepsilon\\) tende a zero al crescere di \\(n\\). Formalmente:\n\\[\n\\Pr\\bigl(| \\bar{X}_n - \\mu| &gt; \\varepsilon\\bigr) \\to 0 \\quad \\text{al crescere di }n.\n\\]\n\n\n\n32.4.1 Applicazioni in psicologia\nIn psicologia, la Legge dei Grandi Numeri ha implicazioni significative. Ad esempio, se si vuole stimare con precisione la proporzione di individui che manifestano un determinato comportamento o la media di un test cognitivo in una popolazione, è necessario raccogliere un numero sufficiente di osservazioni. Solo con un campione ampio la media campionaria si avvicinerà alla media “vera” della popolazione, riducendo l’incertezza e migliorando l’affidabilità delle stime.\n\n32.4.2 Forma debole della Legge dei Grandi Numeri\nLa forma debole della LGN, dimostrata per la prima volta da Jacob Bernoulli nel suo lavoro Ars Conjectandi, afferma che la media campionaria converge in probabilità alla media teorica (Hacking, 2006). In termini pratici, questo significa che, man mano che il numero di osservazioni aumenta, la probabilità che la differenza tra la media osservata e la media teorica superi un margine di errore \\(\\varepsilon\\) diventa sempre più piccola. Formalmente:\n\\[\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^n X_i - \\mu\\right| \\geq \\varepsilon\\right) = 0,\n\\] dove:\n\n\n\\(X_1, X_2, \\ldots, X_n\\) sono variabili casuali indipendenti e identicamente distribuite (i.i.d.),\n\n\\(\\mu\\) è la media teorica,\n\n\\(\\varepsilon\\) è un numero positivo arbitrariamente piccolo.\n\n32.4.3 Forma forte della Legge dei Grandi Numeri\nLa forma forte della LGN, sviluppata successivamente da matematici come Kolmogorov, è un enunciato più potente. Essa stabilisce che la media campionaria converge quasi sicuramente alla media teorica. Questo implica che, con probabilità 1, la media osservata si avvicina indefinitamente al valore teorico man mano che il numero di prove tende all’infinito. Formalmente:\n\\[\nP\\left(\\lim_{{n \\to \\infty}} \\frac{1}{n} \\sum_{i=1}^n X_i = \\mu\\right) = 1.\n\\]\n\n32.4.4 Importanza e critiche\nLa Legge dei Grandi Numeri è fondamentale per garantire la validità delle stime empiriche, ma la sua applicazione pratica richiede attenzione. Ad esempio, in psicologia, la raccolta di un numero sufficiente di osservazioni può essere costosa o difficile, specialmente quando si studiano fenomeni rari o popolazioni specifiche. Inoltre, l’assunzione di indipendenza e identica distribuzione delle osservazioni potrebbe non essere sempre realistica in contesti applicativi complessi. Nonostante queste sfide, la LGN rimane un principio essenziale per comprendere come i dati empirici possano avvicinarsi alle proprietà teoriche di una popolazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#teorema-del-limite-centrale",
    "href": "chapters/probability/09_sampling_distr.html#teorema-del-limite-centrale",
    "title": "32  Stime, stimatori e parametri",
    "section": "\n32.5 Teorema del Limite Centrale",
    "text": "32.5 Teorema del Limite Centrale\nOltre alla convergenza, un ulteriore risultato importante è che la distribuzione di \\(\\bar{X}_n\\) si approssima alla normale man mano che \\(n\\) cresce, anche se i singoli \\(X_i\\) non sono distribuiti normalmente.\n\nTeorema 32.1 Se \\(X_1, X_2, \\ldots, X_n\\) sono variabili iid con media \\(\\mu\\) e deviazione standard \\(\\sigma\\), la distribuzione di\n\\[\n\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i\n\\] diventa approssimativamente normale con media \\(\\mu\\) e deviazione standard \\(\\tfrac{\\sigma}{\\sqrt{n}}\\) quando \\(n\\) è sufficientemente grande.\n\nPer il caso 0-1 (presenza/assenza di un tratto), \\(\\bar{X}\\) è quindi circa normale con media \\(p\\) e varianza \\(\\frac{p(1-p)}{n}\\). Il TLC consente, tra l’altro, di costruire intervalli di confidenza e di calcolare probabilità che la stima si discosti di una certa quantità dal vero valore.\n\nEsempio 32.1 Per visualizzare il Teorema del Limite Centrale (TLC) in azione, possiamo condurre una simulazione. Immaginiamo una popolazione distribuita in modo uniforme. Estraiamo 300 campioni di dimensione \\(n = 30\\) da questa popolazione e osserviamo come la distribuzione campionaria delle medie di questi campioni converga a una distribuzione normale. Questa simulazione fornirà un’illustrazione concreta dell’efficacia del TLC nell’approssimare distribuzioni reali.\n\n# Impostiamo il seed per la riproducibilità dei risultati\nset.seed(42)\n\n# Generiamo una popolazione con distribuzione uniforme\npopulation &lt;- runif(5000, min = 0, max = 1)\n\n# Passo 1: Visualizziamo l'istogramma della popolazione utilizzando ggplot2\nggplot(data.frame(population), aes(x = population)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30\n  ) +\n  labs(x = \"Valore\", y = \"Densità\")\n\n\n\n\n\n\n\n\n# Passo 2 e 3: Estraiamo campioni casuali e calcoliamo le medie campionarie\nsample_size &lt;- 30\nnum_samples &lt;- 300\n\n# Vettore vuoto per memorizzare le medie campionarie\nsample_means &lt;- c()\n\nfor (i in 1:num_samples) {\n  # Estraiamo un campione casuale\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  \n  # Calcoliamo la media del campione\n  sample_means[i] &lt;- mean(sample)\n}\n\n# Calcoliamo media e varianza delle medie campionarie\nx_bar &lt;- mean(sample_means)\nstd &lt;- sd(sample_means)\n\nprint('Media e Varianza delle Medie Campionarie')\n#&gt; [1] \"Media e Varianza delle Medie Campionarie\"\nprint(x_bar)\n#&gt; [1] 0.501\nprint(std^2)\n#&gt; [1] 0.00275\n\n\n# Calcoliamo media e varianza della popolazione\nmu &lt;- mean(population)\nsigma &lt;- sd(population)\n\nprint('Media e Varianza della Popolazione')\n#&gt; [1] \"Media e Varianza della Popolazione\"\nprint(mu)\n#&gt; [1] 0.503\nprint((sigma^2)/sample_size)\n#&gt; [1] 0.00282\n\n\n# Passo 4: Visualizziamo l'istogramma delle medie campionarie utilizzando ggplot2\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30\n  ) +\n  stat_function(\n    fun = dnorm, args = list(mean = x_bar, sd = std), color = \"black\", size = 1\n  ) +\n  labs(\n    x = \"Media Campionaria\", y = \"Densità\"\n  ) +\n  theme(legend.position = \"top\") \n\n\n\n\n\n\n\nSpiegazione del codice e dei risultati\n\nPopolazione: Abbiamo generato una popolazione di 5000 osservazioni distribuite uniformemente tra 0 e 1. La distribuzione uniforme è stata scelta perché è chiaramente non normale, il che rende più evidente l’effetto del TLC.\nCampionamento: Abbiamo estratto 300 campioni casuali, ciascuno di dimensione \\(n = 30\\), dalla popolazione. Per ogni campione, abbiamo calcolato la media.\nDistribuzione delle Medie Campionarie: Le medie dei campioni sono state raccolte e la loro distribuzione è stata visualizzata tramite un istogramma. Nonostante la popolazione originale non fosse normale, la distribuzione delle medie campionarie si avvicina a una distribuzione normale, dimostrando il TLC.\nConfronto tra Popolazione e Campioni: Abbiamo confrontato la media e la varianza della popolazione con quelle delle medie campionarie. Come previsto dal TLC, la media delle medie campionarie è molto vicina alla media della popolazione, mentre la varianza delle medie campionarie è ridotta di un fattore pari alla dimensione del campione (\\(n = 30\\)).\n\nQuesta simulazione illustra chiaramente come il TLC permetta di approssimare la distribuzione delle medie campionarie a una distribuzione normale, anche quando la popolazione originale non è normale. Questo risultato è fondamentale per molte applicazioni pratiche della statistica inferenziale.\n\n\nEsempio 32.2 Sebbene i risultati teorici siano solidi, è comune utilizzare la simulazione Monte Carlo per verificarne la validità in contesti pratici. Supponiamo, ad esempio, che la proporzione reale di individui che soffrono di un certo sintomo in una popolazione sia \\(p = 0.45\\). Possiamo simulare campioni di dimensione \\(n\\) e calcolare la media campionaria \\(\\bar{X}\\) (ovvero la proporzione osservata in ciascun campione). Ripetendo questo processo molte volte, otteniamo una distribuzione empirica delle \\(\\bar{X}\\). Se l’approssimazione normale fornita dal Teorema del Limite Centrale (TLC) è valida, ci aspettiamo che:\n\nLa media delle \\(\\bar{X}\\) sia molto vicina al valore teorico \\(p = 0.45\\).\nLa varianza delle \\(\\bar{X}\\) sia approssimativamente uguale a \\(p(1-p)/n\\), come previsto dalla teoria.\n\nUn esempio di codice in R per questa simulazione è il seguente:\n\np &lt;- 0.45  # Proporzione reale nella popolazione\nn &lt;- 1000  # Dimensione del campione\nB &lt;- 10000 # Numero di campioni simulati\n\n# Simulazione Monte Carlo: generiamo B campioni e calcoliamo le medie campionarie\nx_hat &lt;- replicate(B, {\n  x &lt;- sample(c(0, 1), size = n, replace = TRUE, prob = c(1-p, p))\n  mean(x)\n})\n\n# Media delle medie campionarie (dovrebbe essere vicina a p)\nmean(x_hat)  # Risultato atteso: ~ 0.45\n#&gt; [1] 0.45\n\n# Deviazione standard delle medie campionarie (dovrebbe essere vicina a sqrt(p*(1-p)/n))\nsd(x_hat)    # Risultato atteso: ~ sqrt(0.45 * 0.55 / 1000)\n#&gt; [1] 0.0157\n\nRisultati attesi e interpretazione:\n\n\nMedia delle medie campionarie: Il valore medio di x_hat dovrebbe essere molto vicino a \\(0.45\\), confermando che la media campionaria è uno stimatore non distorto della proporzione reale \\(p\\).\n\nDeviazione standard delle medie campionarie: La deviazione standard di x_hat dovrebbe avvicinarsi a \\(\\sqrt{0.45 \\times 0.55 / 1000} \\approx 0.0157\\), in linea con la formula teorica \\(\\sqrt{p(1-p)/n}\\). Questo valore rappresenta l’incertezza associata alla stima della proporzione.\n\nEffetto della dimensione del campione:\n\nAumentando la dimensione del campione \\(n\\), l’ampiezza della distribuzione delle medie campionarie (e quindi l’incertezza di \\(\\bar{X}\\)) diminuisce. Questo è coerente con la teoria, poiché la varianza delle medie campionarie è inversamente proporzionale a \\(n\\). In altre parole, campioni più grandi forniscono stime più precise del parametro della popolazione.\n\nQuesta simulazione dimostra concretamente come il Teorema del Limite Centrale garantisca che, anche per popolazioni non normali (come in questo caso, dove i dati sono binari), la distribuzione delle medie campionarie si avvicini a una distribuzione normale con media \\(p\\) e varianza \\(p(1-p)/n\\), purché \\(n\\) sia sufficientemente grande.\n\n\n32.5.1 Margine di errore e intervalli di confidenza\nSe \\(\\bar{X}\\) è approssimato da \\(\\mathcal{N}(p, \\frac{p(1-p)}{n})\\), allora \\[\nZ = \\frac{\\bar{X} - p}{\\sqrt{p(1-p)/n}}\n\\] segue (approssimativamente) la distribuzione normale standard \\(\\mathcal{N}(0,1)\\). In pratica, non conoscendo \\(p\\), possiamo sostituirlo con \\(\\bar{X}\\) nello stimatore di errore standard (\\(\\mathrm{plug\\text{-}in}\\)):\n\\[\n\\hat{\\mathrm{SE}}(\\bar{X}) = \\sqrt{\\frac{\\bar{X}(1-\\bar{X})}{n}}.\n\\] Spesso si costruisce un intervallo di confidenza approssimato al 95% come:\n\\[\n\\bar{X} \\,\\pm\\, 1.96 \\times \\hat{\\mathrm{SE}}(\\bar{X}),\n\\] dove 1.96 deriva dal fatto che circa il 95% della distribuzione normale standard sta nell’intervallo \\([-1.96,+1.96]\\). Questo intervallo rappresenta la fascia di incertezza attorno alla stima, che si restringe all’aumentare di \\(n\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#oltre-la-media-altre-distribuzioni-campionarie",
    "href": "chapters/probability/09_sampling_distr.html#oltre-la-media-altre-distribuzioni-campionarie",
    "title": "32  Stime, stimatori e parametri",
    "section": "\n32.6 Oltre la media: altre distribuzioni campionarie",
    "text": "32.6 Oltre la media: altre distribuzioni campionarie\nFinora ci siamo concentrati sulla media campionaria (o proporzione), ma in molti casi di interesse psicologico o più in generale statistico, potremmo voler studiare altre statistiche tratte da un campione. Due esempi importanti sono il massimo campionario (utile per analisi di eventi estremi, punteggi massimi nei test, tempi di reazione record, ecc.) e la varianza campionaria (fondamentale per misurare la variabilità dei punteggi in un test psicometrico, ad esempio).\n\n32.6.1 Massimo campionario\nQuando siamo interessati a misurare la performance “estrema” di un gruppo (ad esempio il punteggio più elevato in un test cognitivo, oppure la latenza di reazione più veloce se si ragiona in termini di minimi), la statistica di riferimento è il massimo (o il minimo) nel campione.\n\n32.6.1.1 Teoria e concetti chiave\n\nDefinizione: Dato un campione \\(\\{X_1, X_2, \\dots, X_n\\}\\), il massimo campionario è \\[\nM = \\max\\{X_1, X_2, \\dots, X_n\\}.\n\\] Questa variabile casuale dipende ovviamente dalla distribuzione dei singoli \\(X_i\\).\n\nProprietà:\n\nLa distribuzione di \\(M\\) spesso risulta asimmetrica e “spostata a destra” rispetto alla distribuzione di partenza. Anche se la popolazione originaria fosse normalmente distribuita, la distribuzione del massimo non sarà normale.\n\nIl valore atteso \\(E[M]\\) supera la media \\(\\mu\\) della popolazione perché, fra i \\(n\\) individui osservati, “vince” sempre il più grande.\n\n\n\nImplicazioni pratiche:\n\nAnalizzare i massimi (o i minimi) è cruciale nello studio di fenomeni estremi (per esempio, individuare il picco di stress in un compito cognitivo o la più alta temperatura registrata in una sperimentazione ambientale).\nLa cosiddetta teoria degli estremi si fonda proprio sull’analisi di come i massimi (o minimi) si distribuiscono al crescere di \\(n\\). Questa ha applicazioni in diverse discipline: dalla psicologia (prestazione massima) all’ingegneria (carichi estremi) fino alla finanza (rischi estremi).\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nNel seguente esempio, simuliamo 10.000 esperimenti. In ognuno:\n\nGeneriamo 5 osservazioni da una popolazione normale con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\).\n\nNe calcoliamo il massimo campionario.\n\nInfine, confrontiamo la distribuzione di questi massimi con la densità della distribuzione di partenza (cioè la normale \\(\\mathcal{N}(100, 15^2)\\)).\n\n# Impostazioni iniziali\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulazione di 10.000 esperimenti con campioni di 5 osservazioni\nset.seed(123)  # Per riproducibilità\nsample_maxes &lt;- replicate(10000, max(rnorm(5, mean = mu, sd = sigma)))\n\n# Creiamo un data frame per il grafico\ndata &lt;- data.frame(SampleMaxes = sample_maxes)\ndensity_data &lt;- data.frame(x = x, y = y)\n\n# Grafico con ggplot2\nggplot(data, aes(x = SampleMaxes)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  geom_line(data = density_data, aes(x = x, y = y), size = 1, color = \"black\") +\n  labs(\n    x = \"Massimo campionario\",\n    y = \"Densità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\nOsservazioni:\n\nL’istogramma, che rappresenta la distribuzione dei massimi campionari, è spostato a destra rispetto alla distribuzione della popolazione (tracciata in rosso).\nCiò evidenzia che \\(M\\) tende a fornire valori più alti della media \\(\\mu = 100\\). Se ripetessimo l’esperimento con campioni di dimensione maggiore di 5, questo effetto si accentuerebbe ulteriormente.\n\n\n\n\n\n32.6.2 2. Varianza campionaria\nLo studio della varianza (o in generale della variabilità) è un altro esempio cruciale in contesti psicologici. Se vogliamo descrivere quanto differiscono i punteggi di un test di personalità, o di un test cognitivo, non basta guardare solo alla media campionaria: ci interessa anche la dispersione.\n\n32.6.2.1 Teoria e concetti chiave\n\nStima della varianza:\nStimare la varianza \\(\\sigma^2\\) di una popolazione non è banale. La formula \\[\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (Y_i - \\bar{Y})^2\n\\] tende a sottostimare \\(\\sigma^2\\). Per ottenere uno stimatore non distorto, si usa invece: \\[\nS^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\] L’uso di \\(n-1\\) serve a correggere la perdita di un grado di libertà (poiché \\(\\bar{Y}\\) è calcolata sui dati) e garantisce che \\(E[S^2] = \\sigma^2\\).\nConcetto di distorsione:\nChiamiamo uno stimatore \\(\\hat{\\theta}\\) non distorto se il suo valore atteso è uguale al parametro vero \\(\\theta\\): \\(E[\\hat{\\theta}] = \\theta\\). Con la formula a denominatore \\(n-1\\), la varianza campionaria risulta appunto non distorta.\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nSimuliamo 10.000 esperimenti, ognuno con \\(n=5\\) osservazioni generate da \\(\\mathcal{N}(100, 15^2)\\). Per ciascun campione, calcoliamo: 1. La varianza “distorta” \\(\\frac{1}{n}\\sum_i (X_i - \\bar{X})^2\\). 2. La varianza “corretta” con \\(n-1\\).\n\nset.seed(123)  # Per riproducibilità\n\n# Funzione per calcolare varianze con n e con n-1\ncalc_vars &lt;- function(n = 5, mu = 100, sigma = 15) {\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  var_n &lt;- sum((sample_data - mean(sample_data))^2) / n\n  var_n_minus_1 &lt;- var(sample_data)  # In R, var() usa di default n-1\n  c(var_n, var_n_minus_1)\n}\n\n# Simuliamo 10.000 campioni\nB &lt;- 10000\nvars_matrix &lt;- replicate(B, calc_vars())\nsample_vars_n &lt;- vars_matrix[1, ]\nsample_vars_n_minus_1 &lt;- vars_matrix[2, ]\n\n# Confrontiamo graficamente\ndata_n &lt;- data.frame(SampleVars = sample_vars_n, Type = \"Con n\")\ndata_n_minus_1 &lt;- data.frame(SampleVars = sample_vars_n_minus_1, Type = \"Con n-1\")\ncombined_data &lt;- rbind(data_n, data_n_minus_1)\n\nggplot(combined_data, aes(x = SampleVars, color = Type)) +\n  geom_density(size = 1.1) +\n  labs(\n    x = \"Varianza campionaria\",\n    y = \"Densità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  ) +\n  scale_color_manual(values = c(\"Con n\" = \"gray\", \"Con n-1\" = \"black\"))\n\n\n\n\n\n\n\nOsservazioni:\n\nLa curva corrispondente a “Con \\(n\\)” tende a sottostimare la varianza, mentre quella “Con \\(n-1\\)” si centra meglio attorno a \\(\\sigma^2 = 15^2 = 225\\).\n\nSe verifichiamo le medie delle due distribuzioni:\n\nmean(sample_vars_n)\n#&gt; [1] 181\nmean(sample_vars_n_minus_1)\n#&gt; [1] 226\n\ntroveremo che la prima è sensibilmente inferiore a 225, mentre la seconda si avvicina di più al valore vero.\n\n\n\n\n\nSia il massimo campionario sia la varianza campionaria dimostrano come non tutte le distribuzioni campionarie ereditino le stesse proprietà della media. Nel caso del massimo, la variabile risulta spostata verso valori elevati e non segue una forma gaussiana; nel caso della varianza, si deve porre attenzione alla formula usata, per evitare distorsioni sistematiche.\nIn sintesi:\n\n\nMassimo campionario: utile per l’analisi di fenomeni estremi (o massimi prestazionali), con una distribuzione tipicamente asimmetrica.\n\n\nVarianza campionaria: richiede la correzione di Bessel (denominatore \\(n-1\\)) per essere uno stimatore non distorto di \\(\\sigma^2\\).\n\nCapire le proprietà di queste (e altre) distribuzioni campionarie consente allo sperimentatore di valutare correttamente le incertezze nelle stime, di evitare errori di interpretazione e di utilizzare gli stimatori più appropriati in base al tipo di fenomeno studiato.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#errore-standard-incertezza-inferenziale-e-bias",
    "href": "chapters/probability/09_sampling_distr.html#errore-standard-incertezza-inferenziale-e-bias",
    "title": "32  Stime, stimatori e parametri",
    "section": "\n32.7 Errore standard, incertezza inferenziale e bias",
    "text": "32.7 Errore standard, incertezza inferenziale e bias\n\n32.7.1 Errore standard e incertezza\nL’errore standard (SE) è la misura di quanto una data statistica (ad esempio la media) può variare da un campione all’altro per pura casualità di campionamento. In un contesto psicologico, può essere usato per mostrare graficamente l’affidabilità di una misura. Esporre i risultati di un test psicometrico riportando solo la media, senza un’idea dell’errore standard o di un intervallo di confidenza, rischia di dare un’illusione di precisione non giustificata.\n\n32.7.2 Bias: perché non basta un campione grandissimo\nAumentare la dimensione campionaria \\(n\\) riduce l’errore standard, ma non elimina possibili bias sistematici (si veda, ad esempio, la disussione fornita dal Andrew Gelman su questo tema). Ad esempio:\n\nSe i partecipanti più ansiosi evitano di partecipare allo studio (bias di selezione), la proporzione \\(\\bar{X}\\) sarà sistematicamente sottostimata.\nSe qualcuno falsifica le risposte per desiderabilità sociale (bias di risposta), la media misurata può allontanarsi dal valore vero in maniera non corretta da un semplice aumento del campione.\nSe lo strumento di misura (ad es. un questionario) è mal tarato o concettualmente scorretto, l’intero studio può soffrirne (misurazione errata).\n\nQuando è presente un bias, nessun aumento del numero di partecipanti potrà rimuoverlo: si otterranno stime molto “precise” (varianza piccola) ma sistematicamente lontane dal valore reale.\n\n\n\n\n\n\nNota bayesiana\n\n\n\nL’errore standard è una misura frequentista di precisione della stima. Nell’approccio bayesiano, la precisione si legge direttamente dalla dispersione della distribuzione a posteriori del parametro. Quindi il concetto di “quanto è precisa la stima” resta, ma lo esprimiamo in modo diverso.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#la-prospettiva-bayesiana",
    "href": "chapters/probability/09_sampling_distr.html#la-prospettiva-bayesiana",
    "title": "32  Stime, stimatori e parametri",
    "section": "\n32.8 La prospettiva bayesiana",
    "text": "32.8 La prospettiva bayesiana\nNelle sezioni precedenti abbiamo discusso il concetto di distribuzione campionaria da una prospettiva frequentista. Questo approccio considera il parametro della popolazione (come la proporzione \\(p\\) o la media \\(\\mu\\)) come una quantità fissa, sebbene sconosciuta. L’incertezza deriva esclusivamente dalla variabilità del processo di campionamento ripetuto.\nLa statistica bayesiana, invece, offre una prospettiva complementare e interpretativamente diversa:\n\nParametri come variabili casuali: Nel quadro bayesiano, i parametri non sono considerati quantità fisse, ma variabili aleatorie descritte da una distribuzione di probabilità. Questa distribuzione riflette il grado di convinzione (o conoscenza) del ricercatore rispetto al valore del parametro, prima di osservare i dati (distribuzione a priori), e viene aggiornata alla luce dei dati osservati per produrre una distribuzione a posteriori.\nDistribuzione a posteriori: Dopo aver osservato i dati campionari, la distribuzione a posteriori descrive completamente l’incertezza sul parametro. A differenza dell’approccio frequentista, in cui l’incertezza è quantificata considerando ripetizioni ipotetiche dell’esperimento, l’incertezza bayesiana riflette direttamente lo stato attuale della nostra conoscenza.\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nRiprendiamo l’esempio precedente sulla proporzione di adulti che manifestano un certo sintomo ansioso. Consideriamo che prima di raccogliere i dati dal campione, abbiamo una credenza iniziale (a priori) sulla proporzione \\(p\\). Potremmo assumere una distribuzione a priori Beta(\\(\\alpha\\), \\(\\beta\\)), scelta comunemente perché flessibile e comoda da aggiornare (si veda il Capitolo 37):\n\\[\np \\sim \\text{Beta}(\\alpha, \\beta).\n\\]\nSupponiamo ora di estrarre un campione di dimensione \\(N\\) e osservare \\(y\\) individui che manifestano il sintomo. La distribuzione a posteriori sarà allora:\n\\[\np \\mid y, N \\sim \\text{Beta}(\\alpha + y, \\beta + N - y) .\n\\]\nQuesta distribuzione incorpora sia le informazioni iniziali sia i dati osservati (si veda il Capitolo 44). Aumentando il numero di osservazioni, l’influenza della distribuzione a priori si riduce, e la distribuzione a posteriori converge verso il valore effettivo di \\(p\\), riflettendo un comportamento analogo alla Legge dei Grandi Numeri.\nInterpretazione bayesiana dei risultati.\n\nIntervallo di credibilità: Al posto dell’intervallo di confidenza frequentista (si veda il Capitolo 82), che descrive la probabilità di copertura considerando ripetizioni ipotetiche del campionamento, il bayesiano utilizza un intervallo di credibilità (si veda il Capitolo 45), il quale indica direttamente l’intervallo entro cui il parametro cade con una data probabilità, date le osservazioni effettivamente raccolte.\nConvergenza della distribuzione a posteriori: In analogia alla Legge dei Grandi Numeri e al Teorema del Limite Centrale, anche nel quadro bayesiano, all’aumentare della dimensione del campione, la distribuzione a posteriori diventa sempre più concentrata intorno al parametro vero, riducendo l’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/09_sampling_distr.html#riflessioni-conclusive",
    "title": "32  Stime, stimatori e parametri",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl percorso qui delineato mette in luce come, nell’ambito dell’inferenza frequentista, risulti fondamentale operare una chiara distinzione tra due piani concettuali: da un lato la popolazione e i suoi parametri — entità teoriche, come la vera proporzione di un sintomo psicologico o la media di un punteggio nella popolazione generale, che per loro natura non sono direttamente osservabili — e dall’altro il campione e le sue stime, ovvero i dati empirici effettivamente raccolti e le statistiche — come la media campionaria — da essi calcolate.\nLa nozione di distribuzione campionaria, in particolare per statistiche quali la media o la proporzione, consente di comprendere alcune proprietà cruciali dell’inferenza statistica. La media campionaria, ad esempio, è uno stimatore non distorto, il cui valore atteso coincide con il parametro della popolazione che intende stimare. La sua precisione, definita come l’inverso della varianza, aumenta al crescere della numerosità campionaria. Inoltre, grazie al Teorema del Limite Centrale, è possibile approssimare la distribuzione della media campionaria a una normale per campioni sufficientemente ampi, fatto che costituisce la base per la costruzione di intervalli di confidenza e per la valutazione probabilistica delle stime. È altrettanto importante notare come l’errore standard quantifichi esclusivamente la variabilità attribuibile al campionamento, mentre eventuali bias sistematici — legati per esempio al disegno sperimentale o alla misura — permangono anche al crescere della dimensione campionaria.\nComplementare alla prospettiva frequentista è l’approccio bayesiano, il quale concepisce l’incertezza inferenziale non solo in termini di variabilità campionaria, ma come riflesso diretto del nostro stato di conoscenza. Tale stato viene rappresentato esplicitamente mediante la distribuzione a posteriori, che aggiorna le credenze iniziali alla luce dei nuovi dati. Questa caratteristica rende il framework bayesiano particolarmente adatto a contesti applicativi in psicologia, dove l’obiettivo è spesso quello di revisionare in modo incrementale la comprensione di un fenomeno man mano che nuove evidenze diventano disponibili.\nIn sintesi, una ricerca psicologica rigorosa richiede la consapevolezza di due fonti distinte di incertezza: quella casuale, riconducibile alla variabilità del campionamento e quantificabile attraverso strumenti come l’errore standard, e quella sistematica, riconducibile a distorsioni metodologiche o concettuali. Solo un’interpretazione che tenga conto di entrambe queste componenti permette di valutare con appropriatezza la solidità delle conclusioni tratte dai dati, sia in ambito teorico sia in setting applicativi e clinici.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nEsercizi sulla distribuzione campionaria sono disponibili sulla seguente pagina web.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_sampling_distr.html#bibliografia",
    "href": "chapters/probability/09_sampling_distr.html#bibliografia",
    "title": "32  Stime, stimatori e parametri",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html",
    "href": "chapters/probability/10_joint_prob.html",
    "title": "33  Probabilità congiunta",
    "section": "",
    "text": "Introduzione\nFino a questo momento abbiamo considerato il concetto di probabilità associato a singole variabili casuali. Tuttavia, in molte situazioni pratiche e psicologiche, è fondamentale analizzare come due o più variabili casuali interagiscono tra loro. La distribuzione congiunta ci permette di descrivere la probabilità che più variabili aleatorie assumano contemporaneamente specifici valori.\nQuesto capitolo introduce e approfondisce il concetto di distribuzione congiunta attraverso definizioni, proprietà essenziali e un esempio concreto basato sulla letteratura psicologica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#introduzione",
    "href": "chapters/probability/10_joint_prob.html#introduzione",
    "title": "33  Probabilità congiunta",
    "section": "",
    "text": "Panoramica del capitolo\n\nDefinizione di distribuzione congiunta per variabili discrete e continue.\nLe proprietà fondamentali: non-negatività e normalizzazione.\nCome ottenere e interpretare le distribuzioni marginali da una congiunta.\nIl concetto di indipendenza e come verificarla tramite la distribuzione congiunta.\nEstensione al caso continuo, con esempi grafici (mappe termiche) e densità marginali/condizionali.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Joint Distributions (Chan & Kroese, 2025).\nLeggere il capitolo Joint Distributions (Blitzstein & Hwang, 2019).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt;\n  source()\nlibrary(MASS)\nlibrary(viridis)\nlibrary(ggExtra)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#cosè-la-distribuzione-congiunta",
    "href": "chapters/probability/10_joint_prob.html#cosè-la-distribuzione-congiunta",
    "title": "33  Probabilità congiunta",
    "section": "\n33.1 Cos’è la distribuzione congiunta?",
    "text": "33.1 Cos’è la distribuzione congiunta?\nQuando studiamo due variabili casuali — ad esempio ansia (\\(Y\\)) e prestazione cognitiva (\\(X\\)) — non ci interessa solo il loro comportamento individuale, ma anche come si manifestano insieme. La distribuzione congiunta descrive proprio questo: la probabilità che \\(X\\) e \\(Y\\) assumano contemporaneamente determinati valori.\n\n\nCaso discreto (variabili che possono assumere valori distinti, come categorie o conteggi)::\n\n\\[\np(x, y) = P(X = x, Y = y) .\n\\]\n\n\nCaso continuo variabili misurate su scale numeriche con molti possibili valori, come punteggi o tempi di reazione):\n\n\\[\nf(x, y)\n\\] che rappresenta la densità di probabilità congiunta.\nGrazie a queste funzioni possiamo rispondere a domande del tipo: Qual è la probabilità che uno studente con ansia elevata ottenga una prestazione insufficiente?",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#proprietà-fondamentali",
    "href": "chapters/probability/10_joint_prob.html#proprietà-fondamentali",
    "title": "33  Probabilità congiunta",
    "section": "\n33.2 Proprietà fondamentali",
    "text": "33.2 Proprietà fondamentali\nPerché una distribuzione congiunta sia una corretta distribuzione di probabilità, deve rispettare due condizioni di base.\n\n\n\n\n\n\n1. Non-negatività\n\n\n\n\\[\np(x,y) \\geq 0\n\\quad \\text{oppure} \\quad\nf(x,y) \\geq 0 .\n\\]\n\n\n\n\n\n\n\n\n2. Normalizzazione\n\n\n\n\nCaso discreto\\[\n\\sum_{x}\\sum_{y} p(x,y) = 1 .\n\\]\nCaso continuo\\[\n\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty} f(x,y)\\,dx\\,dy = 1 .\n\\]\n\n\n\nIn altre parole:\n\ntutte le probabilità devono essere positive,\n\ne la loro somma (o integrale) deve essere uguale a 1.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#distribuzioni-congiunte-e-inferenza-bayesiana",
    "href": "chapters/probability/10_joint_prob.html#distribuzioni-congiunte-e-inferenza-bayesiana",
    "title": "33  Probabilità congiunta",
    "section": "\n33.3 Distribuzioni congiunte e inferenza bayesiana",
    "text": "33.3 Distribuzioni congiunte e inferenza bayesiana\nIn questo libro ci concentreremo soprattutto sull’inferenza bayesiana, che si fonda proprio sul concetto di distribuzione congiunta. In termini generali, l’inferenza bayesiana mira a descrivere la distribuzione a posteriori dei parametri del modello, cioè la probabilità dei parametri dati i dati osservati.\nQuesta distribuzione a posteriori deriva dalla combinazione di:\n\nuna distribuzione a priori sui parametri, che esprime le conoscenze (o le ipotesi) disponibili prima di osservare i dati;\nla distribuzione di verosimiglianza, che è una distribuzione congiunta dei dati osservati, condizionata ai parametri.\n\nSe i dati costituiscono un campione casuale indipendente e identicamente distribuito (i.i.d.), allora la verosimiglianza — cioè la distribuzione congiunta delle osservazioni — si ottiene come prodotto delle densità di ogni singola osservazione:\n\\[\np(y_1, y_2, \\dots, y_n \\mid \\theta) = \\prod_{i=1}^n p(y_i \\mid \\theta).\n\\] Poiché il prodotto di molte densità può rapidamente generare numeri molto piccoli (problema di underflow numerico), nella pratica si lavora quasi sempre con la log-verosimiglianza (o log-densità congiunta):\n\\[\n\\log p(y_1, \\dots, y_n \\mid \\theta) = \\sum_{i=1}^n \\log p(y_i \\mid \\theta).\n\\] Questo passaggio non cambia la sostanza matematica del problema, ma rende i calcoli più stabili e più facili da gestire al computer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#un-esempio-psicologico-ansia-e-prestazione",
    "href": "chapters/probability/10_joint_prob.html#un-esempio-psicologico-ansia-e-prestazione",
    "title": "33  Probabilità congiunta",
    "section": "\n33.4 Un esempio psicologico: ansia e prestazione",
    "text": "33.4 Un esempio psicologico: ansia e prestazione\nConsideriamo un esempio tratto dalla letteratura psicologica: la relazione tra ansia (Y) e prestazione cognitiva (X) in studenti universitari. La ricerca psicologica indica spesso una relazione negativa tra questi due fattori: livelli elevati di ansia possono associarsi a prestazioni cognitive inferiori (Eysenck et al., 2007).\nSupponiamo di aver valutato due variabili discrete in un gruppo di studenti:\n\n\nAnsia: bassa, media, alta (codificata come Y = 0, 1, 2);\n\nPrestazione cognitiva: insufficiente, sufficiente, buona (codificata come X = 0, 1, 2).\n\nLa distribuzione congiunta potrebbe essere rappresentata nella seguente tabella (i dati sono ipotetici ma coerenti con la letteratura):\n\n\n\n\n\n\n\n\n\nAnsia Bassa (0)\nAnsia Media (1)\nAnsia Alta (2)\n\n\n\nInsufficiente (0)\n0.05\n0.10\n0.15\n\n\nSufficiente (1)\n0.15\n0.20\n0.10\n\n\nBuona (2)\n0.10\n0.10\n0.05\n\n\n\nI valori nella tabella rappresentano stime empiriche delle probabilità congiunte, ovvero le proporzioni osservate di studenti che hanno manifestato una specifica combinazione di livelli delle due variabili. Ad esempio, la cella corrispondente a “Ansia Media” e “Prestazione Sufficiente” indica che il 20% degli studenti nel campione considerato ha un livello medio di ansia ed ha ottenuto prestazioni sufficienti nel compito cognitivo.\nQuesta tabella ci consente di calcolare probabilità interessanti. Ad esempio, la probabilità che uno studente raggiunga almeno la sufficienza, indipendentemente dall’ansia:\n\\[\nP(X \\geq 1) = 0.15 + 0.20 + 0.10 + 0.10 + 0.10 + 0.05 = 0.70 .\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#distribuzioni-marginali",
    "href": "chapters/probability/10_joint_prob.html#distribuzioni-marginali",
    "title": "33  Probabilità congiunta",
    "section": "\n33.5 Distribuzioni marginali",
    "text": "33.5 Distribuzioni marginali\nDalla distribuzione congiunta possiamo ricavare le distribuzioni marginali delle singole variabili, cioè la probabilità che una variabile assuma un certo valore indipendentemente dall’altra.\nPer l’ansia:\n\nansia bassa: \\[P(Y=0)=0.05+0.15+0.10=0.30 .\\]\n\nansia media: \\[P(Y=1)=0.10+0.20+0.10=0.40 .\\]\n\nansia alta: \\[P(Y=2)=0.15+0.10+0.05=0.30 .\\]\n\n\nQueste distribuzioni ci dicono, ad esempio, che nel campione il 40% degli studenti ha ansia media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#indipendenza-e-dipendenza",
    "href": "chapters/probability/10_joint_prob.html#indipendenza-e-dipendenza",
    "title": "33  Probabilità congiunta",
    "section": "\n33.6 Indipendenza e dipendenza",
    "text": "33.6 Indipendenza e dipendenza\nDue variabili casuali \\(X\\) e \\(Y\\) si dicono indipendenti se la loro distribuzione congiunta si fattorizza nelle rispettive distribuzioni marginali:\n\\[p(x,y)=p(x)p(y) \\quad \\text{oppure} \\quad f(x,y)=f(x)f(y) .\\]\nNel nostro esempio, se ansia e prestazione fossero indipendenti, dovremmo avere:\n\\[P(X=0,Y=2)=P(X=0)P(Y=2) .\\]\nIn realtà, come suggerisce la letteratura (Eysenck et al., 2007), ansia e prestazione tendono a essere dipendenti: più alta è l’ansia, minore è la probabilità di buone prestazioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#il-caso-continuo-una-mappa-termica",
    "href": "chapters/probability/10_joint_prob.html#il-caso-continuo-una-mappa-termica",
    "title": "33  Probabilità congiunta",
    "section": "\n33.7 Il caso continuo: una mappa termica",
    "text": "33.7 Il caso continuo: una mappa termica\nSe invece misuriamo ansia e prestazione come variabili continue (es. punteggi su scale numeriche), la distribuzione congiunta è una densità. Possiamo rappresentarla come una mappa termica:\n\nasse X = ansia,\nasse Y = prestazione,\ncolori più caldi = combinazioni più probabili.\n\nUn esempio simulato mostra che la maggior parte degli studenti si concentra intorno a bassa ansia (30) e buona prestazione (70), mentre i punteggi più alti di ansia si associano a prestazioni più basse.\n\n\n\n\n\n\n\n\nQuesta visualizzazione rende immediato vedere la relazione negativa tra le due variabili (Eysenck et al., 2007).\n\n33.7.1 Marginali e condizionali con variabili continue\nQuando lavoriamo con variabili continue, non possiamo semplicemente contare le combinazioni come nel caso discreto (ad esempio, lanci di un dado). Invece, misuriamo la probabilità calcolando l’area della regione interessata sulla nostra mappa termica:\n\nla probabilità che l’ansia sia tra 50 e 55, e la prestazione tra 30 e 50, è rappresentata dall’area della regione corrispondente nella mappa termica;\ngli integrali (strumenti matematici per calcolare aree) sono semplicemente un modo preciso per fare questa operazione.\n\n\n33.7.1.1 Densità marginale: proiettare la mappa su un asse\nLa densità marginale descrive come si distribuisce una singola variabile, prescindendo completamente dall’altra. Possiamo immaginare questo processo come la proiezione della mappa termica su uno degli assi, ottenendo così un’ombra o una proiezione dell’intera distribuzione:\n\nproiettando tutti i valori sull’asse dell’ansia, si ottiene la densità marginale dell’ansia;\nproiettando tutti i valori sull’asse della prestazione, si ottiene la densità marginale della prestazione.\n\nQueste proiezioni rivelano la distribuzione di ciascuna variabile considerata isolatamente. Nella figura a cui si fa riferimento, le distribuzioni marginali sono state elaborate utilizzando in modo indipendente i dati relativi a ciascuna variabile, senza considerare le loro interrelazioni.\nInfatti, i colori più caldi nella mappa termica indicano zone con maggiore densità di osservazioni. Quando proiettiamo questi valori su un asse, otteniamo una curva di densità che rappresenta la distribuzione della variabile. Le aree dove la curva raggiunge valori più alti corrispondono ai valori più frequenti della variabile nella popolazione studiata.\n\n33.7.1.2 Densità condizionale: fette della mappa termica\nLa densità condizionale risponde alla domanda: “Se osservo persone con un determinato punteggio di prestazione cognitiva (ad esempio 40 punti), qual è la distribuzione dell’ansia tra queste persone?”\n\nImmaginate di prendere una fetta verticale della mappa termica in corrispondenza della prestazione = 40 punti. Questa fetta mostra la distribuzione dell’ansia soltanto tra coloro che hanno esattamente quella prestazione cognitiva.\nPer rendere questa distribuzione coerente, normalizziamo (cioè “aggiustiamo”) la fetta rispetto alla probabilità complessiva della prestazione a quel livello.\n\nQuesta fetta verticale con i suoi vari colori (più caldi dove c’è maggiore densità) può essere convertita in una curva di densità che mostra come si distribuisce l’ansia specificamente per le persone con quel determinato livello di prestazione cognitiva. Il processo di normalizzazione assicura che l’area sotto questa curva di densità condizionale sia uguale a 1, consentendo confronti tra diverse condizioni.\n\n33.7.1.3 Perché è importante in psicologia?\nStudiare distribuzioni congiunte è cruciale perché\n\nmette in luce relazioni complesse tra variabili psicologiche (lineari, curvilinee, bimodali, cluster);\nrivela informazioni che andrebbero perse se osservassimo solo le marginali;\npermette di analizzare fenomeni realistici, in cui costrutti come ansia, motivazione o prestazione non agiscono mai isolatamente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/10_joint_prob.html#riflessioni-conclusive",
    "title": "33  Probabilità congiunta",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa distribuzione congiunta rappresenta uno strumento fondamentale per l’analisi multivariata in psicologia, permettendo di studiare simultaneamente il comportamento di multiple variabili aleatorie e le loro interrelazioni. Questo approccio risulta particolarmente prezioso nella ricerca psicologica, dove i fenomeni oggetto di studio - come l’ansia, la prestazione cognitiva, la motivazione o i tratti di personalità - raramente si manifestano in isolamento, ma piuttosto attraverso complesse reti di influenze reciproche.\nI concetti di densità congiunta, marginale e condizionale costituiscono la base per un’analisi rigorosa delle relazioni tra variabili psicologiche continue. Questi strumenti consentono di esplorare come i costrutti psicologici interagiscono e si influenzano reciprocamente, offrendo un quadro analitico per comprendere la complessità dei fenomeni mentali e comportamentali.\nIl passaggio concettuale dalle variabili discrete a quelle continue, pur richiedendo l’adozione di strumenti matematici più sofisticati (integrali invece di somme), mantiene intatta la sua intuizione fondamentale. La logica appresa nel caso discreto continua a fornire una solida base interpretativa anche per i fenomeni continui, che meglio rappresentano la realtà della misurazione psicologica.\nQuesto framework analitico prepara il terreno per la successiva quantificazione delle relazioni tra variabili attraverso indicatori come la covarianza e la correlazione. Questi strumenti, che saranno approfonditi nel prossimo capitolo, permetteranno di misurare sistematicamente la forza e la direzione delle associazioni psicologiche, trasformando le osservazioni qualitative in relazioni quantitative verificabili.\nL’approccio attraverso le distribuzioni congiunte non solo fornisce un linguaggio formale per descrivere le relazioni psicologiche, ma stabilisce anche le fondamenta per modelli più avanzati di analisi dei dati, aprendo la strada a una comprensione sempre più sofisticata dei meccanismi che regolano il comportamento umano e i processi mentali.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggExtra_0.11.0        viridis_0.6.5         viridisLite_0.4.2    \n#&gt;  [4] MASS_7.3-65           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [7] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt; [10] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [13] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [16] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [19] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [22] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [25] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [28] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        promises_1.3.3        rmarkdown_2.29       \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        later_1.4.4          \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] httpuv_1.6.16         Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      miniUI_0.1.2         \n#&gt; [43] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [46] shiny_1.11.1          withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] isoband_0.2.7         RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           mvtnorm_1.3-3        \n#&gt; [67] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [70] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [73] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [76] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [79] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [82] htmltools_0.5.8.1     lifecycle_1.0.4       mime_0.13",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_joint_prob.html#bibliografia",
    "href": "chapters/probability/10_joint_prob.html#bibliografia",
    "title": "33  Probabilità congiunta",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.\n\n\nEysenck, M. W., Derakshan, N., Santos, R., & Calvo, M. G. (2007). Anxiety and cognitive performance: attentional control theory. Emotion, 7(2), 336–353.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html",
    "href": "chapters/probability/11_cov_cor.html",
    "title": "34  Covarianza e correlazione",
    "section": "",
    "text": "Introduzione\nQuando due variabili casuali non sono indipendenti, diciamo che esse sono associate o dipendenti. È importante non solo stabilire se tale relazione esista, ma anche quantificare la sua intensità e la sua direzione. A tal fine, utilizziamo due misure chiave: la covarianza e la correlazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html#introduzione",
    "href": "chapters/probability/11_cov_cor.html#introduzione",
    "title": "34  Covarianza e correlazione",
    "section": "",
    "text": "Panoramica del capitolo\n\nDefinire e calcolare la covarianza per quantificare la relazione lineare tra due variabili casuali.\nUtilizzare la correlazione per misurare l’intensità della relazione lineare tra variabili casuali, indipendentemente dalle loro unità di misura.\nComprendere le proprietà chiave della covarianza e della correlazione, inclusa l’incorrelazione.\nEstendere i concetti di probabilità congiunta, marginale e condizionale alle variabili continue, utilizzando gli integrali.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Joint Distributions (Chan & Kroese, 2025).\nLeggere il capitolo Joint Distributions (Blitzstein & Hwang, 2019).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt;\n  source()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html#covarianza",
    "href": "chapters/probability/11_cov_cor.html#covarianza",
    "title": "34  Covarianza e correlazione",
    "section": "\n34.1 Covarianza",
    "text": "34.1 Covarianza\nLa covarianza misura il grado e la direzione della relazione lineare tra due variabili casuali. Una covarianza positiva indica che le due variabili tendono ad aumentare o diminuire insieme, mentre una covarianza negativa indica che una variabile tende ad aumentare quando l’altra diminuisce.\n\n34.1.1 Definizione di Covarianza\nLa covarianza tra due variabili casuali discrete \\(X\\) e \\(Y\\) è definita come:\n\\[\n\\text{Cov}(X, Y) = \\mathbb{E}\\left[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])\\right] .\n\\]\nEsplicitamente, questa definizione può essere riscritta come:\n\\[\n\\text{Cov}(X, Y) = \\sum_{x}\\sum_{y}(x - \\mu_X)(y - \\mu_Y)p(x, y) .\n\\]\ndove \\(\\mu_X\\) e \\(\\mu_Y\\) sono le medie delle variabili \\(X\\) e \\(Y\\) e \\(p(x,y)\\) è la funzione di massa di probabilità congiunta.\nQuesta definizione mostra una stretta analogia con la varianza, che è la covarianza di una variabile con se stessa:\n\\[\n\\mathbb{V}(X) = Cov(X, X).\n\\]\nInoltre, la covarianza può essere calcolata attraverso la relazione:\n\\[\nCov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\]\n\n34.1.2 Dimostrazione\nLa formula alternativa per la covarianza si dimostra come segue.\nPer definizione, la covarianza tra due variabili casuali \\(X\\) e \\(Y\\) è:\n\\[\n\\mathrm{Cov}(X, Y) \\;=\\; \\mathbb{E}\\Bigl[\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\\Bigr].\n\\]\nQuesta è semplicemente la definizione formale, in cui consideriamo la “deviazione” di \\(X\\) dal proprio valor medio (\\(\\mathbb{E}[X]\\)) e la “deviazione” di \\(Y\\) dal proprio valor medio (\\(\\mathbb{E}[Y]\\)), e ne calcoliamo l’aspettativa del prodotto.\nConsideriamo l’argomento dell’aspettativa: \\(\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\\).\nPer prima cosa espandiamo il prodotto come faremmo con normali variabili algebriche:\n\\[\n\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\n= X\\,Y \\;-\\; X\\,\\mathbb{E}[Y] \\;-\\; \\mathbb{E}[X]\\,Y \\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\nAdesso prendiamo l’aspettativa (o valore atteso) di ciascun termine che abbiamo ottenuto. Indichiamo con \\(\\mathbb{E}\\) l’operatore di aspettativa:\n\\[\n\\mathbb{E}\\Bigl[\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\\Bigr]\n= \\mathbb{E}[\\,X\\,Y \\;-\\; X\\,\\mathbb{E}[Y] \\;-\\; \\mathbb{E}[X]\\,Y \\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y]\\,].\n\\]\nGrazie alla linearità dell’aspettativa, possiamo scindere questa grande aspettativa in una somma (e differenza) di aspettative di singoli termini:\n\\[\n= \\mathbb{E}[XY]\n\\;-\\; \\mathbb{E}[X\\,\\mathbb{E}[Y]]\n\\;-\\; \\mathbb{E}[\\mathbb{E}[X]\\,Y]\n\\;+\\; \\mathbb{E}[\\mathbb{E}[X]\\mathbb{E}[Y]].\n\\]\nRicordiamo che \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) sono numeri (costanti) e non variabili casuali. Dunque, quando nell’aspettativa compare un fattore costante, possiamo estrarlo fuori dall’operatore \\(\\mathbb{E}[\\cdot]\\).\n\n\\(\\mathbb{E}[X\\,\\mathbb{E}[Y]]\\) si semplifica in \\(\\mathbb{E}[Y]\\cdot \\mathbb{E}[X]\\) perché \\(\\mathbb{E}[Y]\\) è una costante. In formula: \\[\n\\mathbb{E}[X\\,\\mathbb{E}[Y]]\n= \\mathbb{E}[Y] \\,\\mathbb{E}[X].\n\\]\nAllo stesso modo, \\(\\mathbb{E}[\\mathbb{E}[X]\\,Y]\\) si semplifica in \\(\\mathbb{E}[X]\\cdot \\mathbb{E}[Y]\\).\nInfine, \\(\\mathbb{E}[\\mathbb{E}[X]\\mathbb{E}[Y]]\\) è \\(\\mathbb{E}[X]\\mathbb{E}[Y]\\) in quanto \\(\\mathbb{E}[X]\\mathbb{E}[Y]\\) è già una costante.\n\nUsando queste regole, riscriviamo i termini:\n\\[\n\\mathbb{E}[XY]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\nOsserviamo i termini rimanenti:\n\\[\n\\mathbb{E}[XY] \\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\n\nIl termine \\(\\mathbb{E}[X]\\mathbb{E}[Y]\\) compare due volte in negativo (\\(-\\,\\mathbb{E}[X]\\mathbb{E}[Y]\\)) e una volta in positivo (\\(+\\,\\mathbb{E}[X]\\mathbb{E}[Y]\\)).\n\nFacendo la somma algebrica, ne rimane solo \\(-\\,\\mathbb{E}[X]\\mathbb{E}[Y]\\) (perché \\(-\\,1 -\\,1 +\\,1 = -\\,1\\)).\n\nQuindi il risultato è:\n\\[\n\\mathbb{E}[XY]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\nAbbiamo quindi dimostrato in maniera esplicita che:\n\\[\n\\mathrm{Cov}(X, Y)\n= \\mathbb{E}\\bigl[(X - \\mathbb{E}[X]) (Y - \\mathbb{E}[Y])\\bigr]\n= \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\n\n34.1.3 Esempio Psicologico: Covarianza tra Ansia e Prestazione Cognitiva\nRiprendendo i dati del capitolo precedente sulla relazione tra ansia (Y) e prestazione cognitiva (X), calcoliamo ora la covarianza.\nMedie marginali:\n\nPrestazione cognitiva \\(X\\):\\[\\mathbb{E}(X)=0\\times0.30 + 1\\times0.45 + 2\\times0.25=0.95\\]\n\nAnsia \\(Y\\):\\[\\mathbb{E}(Y)=0\\times0.30 + 1\\times0.40 + 2\\times0.30=1.00\\]\n\n\nCalcoliamo \\(\\mathbb{E}(XY)\\):\n\\[\n\\begin{aligned}\n\\mathbb{E}(XY) &= (0\\times0\\times0.05)+(0\\times1\\times0.10)+(0\\times2\\times0.15)+\n\\notag\\\\\n& \\quad (1\\times0\\times0.15)+(1\\times1\\times0.20)+(1\\times2\\times0.10)+\n\\notag\\\\\n& \\quad(2\\times0\\times0.10)+(2\\times1\\times0.10)+(2\\times2\\times0.05)\n\\end{aligned}\n\\]\nSimplificando:\n\\[\\mathbb{E}(XY)=0.00+0.00+0.00+0.00+0.20+0.20+0.00+0.20+0.20=0.80\\]\nQuindi, la covarianza sarà:\n\\[\\text{Cov}(X,Y)=\\mathbb{E}(XY)-\\mathbb{E}(X)\\mathbb{E}(Y)=0.80-(0.95\\times1.00)=-0.15\\]\nLa covarianza negativa indica che all’aumentare del livello di ansia tende a corrispondere una diminuzione della prestazione cognitiva, coerentemente con quanto spesso riscontrato nella letteratura psicologica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html#correlazione",
    "href": "chapters/probability/11_cov_cor.html#correlazione",
    "title": "34  Covarianza e correlazione",
    "section": "\n34.2 Correlazione",
    "text": "34.2 Correlazione\nLa correlazione standardizza la covarianza, rendendola indipendente dalle unità di misura delle variabili. Essa varia tra -1 e 1 ed è definita come:\n\\[\n\\rho(X,Y)=\\frac{\\text{Cov}(X,Y)}{\\sqrt{\\text{Var}(X)\\text{Var}(Y)}} .\n\\]\ndove \\(\\mathbb{V}(X)\\) e \\(\\mathbb{V}(Y)\\) rappresentano le varianze di \\(X\\) e \\(Y\\), rispettivamente.\nIl coefficiente di correlazione \\(\\rho_{xy}\\) è un valore adimensionale, ovvero non dipende dalle unità di misura delle variabili, e varia nell’intervallo \\(-1 \\leq \\rho \\leq 1\\).\n\n34.2.1 Calcolo della Correlazione\nPer calcolare la correlazione tra ansia e prestazione cognitiva, dobbiamo prima ottenere le varianze di ciascuna variabile.\n\nVarianza di X (prestazione cognitiva):\n\n\\[\n\\begin{aligned}\n\\text{Var}(X) &=\\sum_{x}(x-\\mu_X)^2p(x)\n\\notag\\\\\n&= (0-0.95)^2\\times0.30+(1-0.95)^2\\times0.45+(2-0.95)^2\\times0.25=0.5475 \\notag\n\\end{aligned}\n\\]\n\nVarianza di Y (ansia):\n\n\\[\n\\begin{aligned}\n\\text{Var}(Y) &=\\sum_{y}(y-\\mu_Y)^2p(y) \\notag\\\\\n&= (0-1.00)^2\\times0.30+(1-1.00)^2\\times0.40+(2-1.00)^2\\times0.30=0.60 \\notag\n\\end{aligned}\n\\]\nQuindi, il coefficiente di correlazione è:\n\\[\n\\rho(X,Y)=\\frac{-0.15}{\\sqrt{0.5475\\times0.60}}=-0.261\n\\]\nIl valore negativo della correlazione conferma che ansia e prestazione cognitiva presentano una relazione inversa: all’aumentare dell’ansia, la prestazione tende a diminuire.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html#interpretazione-della-correlazione",
    "href": "chapters/probability/11_cov_cor.html#interpretazione-della-correlazione",
    "title": "34  Covarianza e correlazione",
    "section": "\n34.3 Interpretazione della Correlazione",
    "text": "34.3 Interpretazione della Correlazione\nIl coefficiente di correlazione è una misura standardizzata e facile da interpretare:\n\n\n\\(\\rho = 1\\): perfetta relazione lineare positiva\n\n\\(\\rho = -1\\): perfetta relazione lineare negativa\n\n\\(\\rho = 0\\): assenza di relazione lineare\n\nNel nostro esempio, il valore \\(-0.261\\) indica una relazione lineare negativa moderata tra ansia e prestazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html#proprietà",
    "href": "chapters/probability/11_cov_cor.html#proprietà",
    "title": "34  Covarianza e correlazione",
    "section": "\n34.4 Proprietà",
    "text": "34.4 Proprietà\nLa covarianza e la correlazione possiedono una serie di proprietà formali che ne regolano il comportamento al variare delle variabili e delle costanti coinvolte. Di seguito vengono enunciate e discusse le principali.\nLa covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) è sempre nulla: \\[\n\\text{Cov}(c, X) = 0.\n\\] Inoltre, la covarianza gode della proprietà di simmetria: \\[\n\\text{Cov}(X, Y) = \\text{Cov}(Y, X).\n\\]\nIl coefficiente di correlazione \\(\\rho_{X,Y}\\) è limitato nell’intervallo chiuso \\([-1, 1]\\): \\[\n-1 \\leq \\rho(X, Y) \\leq 1.\n\\] Tale coefficiente è invariante rispetto a cambiamenti di scala delle variabili: per ogni \\(a &gt; 0\\) e \\(b &gt; 0\\) si ha \\[\n\\rho(aX, bY) = \\rho(X, Y).\n\\] Nel caso di una relazione lineare perfetta della forma \\(Y = a + bX\\), il coefficiente di correlazione assume valore estremo: \\[\n\\rho(X, Y) = \\begin{cases}\n+1 & \\text{se } b &gt; 0, \\\\\n-1 & \\text{se } b &lt; 0.\n\\end{cases}\n\\]\nRiguardo alle trasformazioni lineari, la covarianza soddisfa: \\[\n\\text{Cov}(aX, bY) = ab \\cdot \\text{Cov}(X, Y),\n\\] e, più in generale, per due combinazioni lineari di variabili aleatorie: \\[\n\\text{Cov}\\left( \\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j \\right) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j \\, \\text{Cov}(X_i, Y_j).\n\\]\nLa varianza della somma (o differenza) di due variabili è data da: \\[\n\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2 \\, \\text{Cov}(X, Y).\n\\] Più in generale, per una somma di \\(n\\) variabili aleatorie: \\[\n\\mathbb{V}\\left( \\sum_{i=1}^n X_i \\right) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2 \\sum_{i &lt; j} \\text{Cov}(X_i, X_j).\n\\]\nLa covarianza è additiva in ciascun argomento: per ogni variabile aleatoria \\(Z\\), \\[\n\\text{Cov}(X + Y, Z) = \\text{Cov}(X, Z) + \\text{Cov}(Y, Z).\n\\]\nNel caso particolare in cui le variabili \\(X_1, X_2, \\dots, X_n\\) siano mutualmente indipendenti, la covarianza tra due loro combinazioni lineari si semplifica in: \\[\n\\text{Cov}\\left( \\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_j X_j \\right) = \\sum_{i=1}^n a_i b_i \\, \\mathbb{V}(X_i),\n\\] poiché i termini di covarianza incrociata sono nulli.\n\n34.4.1 Incorrelazione\nDue variabili casuali \\(X\\) e \\(Y\\) si dicono incorrelate (o linearmente indipendenti) se la loro covarianza è nulla:\n\\[\n\\text{Cov}(X, Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)] = 0.\n\\]\nTale condizione è equivalente a ciascuna delle seguenti:\n\nil coefficiente di correlazione \\(\\rho_{XY}\\) è nullo;\nil valore atteso del prodotto è uguale al prodotto dei valori attesi: \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y)\\).\n\nL’incorrelazione rappresenta una forma di indipendenza statistica più debole rispetto all’indipendenza stocastica. Mentre due variabili indipendenti sono sempre incorrelate, il viceversa non è vero: è possibile che \\(X\\) e \\(Y\\) abbiano covarianza nulla pur non essendo stocasticamente indipendenti. In altri termini, l’assenza di correlazione lineare non esclude l’esistenza di altre forme di dipendenza (ad esempio, di tipo non lineare) tra le due variabili.\n\nEsempio 34.1 Consideriamo una distribuzione di probabilità congiunta di due variabili aleatorie, \\(X\\) e \\(Y\\), definita come:\n\\[\nf_{XY}(x,y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}, \\\\\n0 & \\text{altrimenti.}\n\\end{array}\n\\right.\n\\]\nQuesto implica che le variabili aleatorie \\(X\\) e \\(Y\\) assumono valori specifici con probabilità uniforme solo per determinate coppie \\((x, y)\\) e zero in tutti gli altri casi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html#riflessioni-conclusive",
    "href": "chapters/probability/11_cov_cor.html#riflessioni-conclusive",
    "title": "34  Covarianza e correlazione",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa covarianza e la correlazione forniscono strumenti essenziali per quantificare le relazioni tra variabili casuali. Utilizzare queste misure permette di approfondire la comprensione delle relazioni psicologiche, come quella tra ansia e prestazione, facilitando ulteriori analisi statistiche e interpretazioni teoriche.\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Distribuzione congiunta di due lanci di dado\nSi lancia due volte un dado a sei facce equilibrato. Siano:\n\n\n\\(X\\) il risultato del primo lancio.\n\n\\(Y\\) il risultato del secondo lancio.\n\n\nCostruisci la tabella della distribuzione congiunta \\(P(X, Y)\\), considerando che tutti i risultati possibili hanno la stessa probabilità.\nVerifica che la somma delle probabilità sia 1.\nDetermina la distribuzione marginale di \\(X\\) e di \\(Y\\).\nLe variabili \\(X\\) e \\(Y\\) sono indipendenti? Giustifica la risposta.\n\nEsercizio 2: Somma di due dadi\nSi lancia due volte un dado a sei facce. Definiamo:\n\n\n\\(S = X + Y\\), la somma dei due risultati.\n\n\nCostruisci la tabella di probabilità congiunta \\(P(X, Y)\\).\nCalcola la distribuzione di probabilità della variabile aleatoria \\(S\\).\nDetermina \\(P(S = 7)\\) e \\(P(S \\leq 5)\\).\nQual è il valore più probabile di \\(S\\)? E il meno probabile?\n\nEsercizio 3: Lancio di tre monete\nSi lanciano tre monete equilibrate. Definiamo:\n\n\n\\(X\\) il numero di teste ottenute.\n\n\\(Y\\) il risultato del primo lancio (1 se testa, 0 se croce).\n\n\nDetermina lo spazio campionario e associa i valori delle variabili aleatorie \\(X\\) e \\(Y\\).\nCostruisci la distribuzione congiunta \\(P(X, Y)\\).\nCalcola \\(P(X = 2 \\mid Y = 1)\\) e \\(P(Y = 1 \\mid X = 2)\\).\nLe variabili \\(X\\) e \\(Y\\) sono indipendenti?\n\nEsercizio 4: Minimo e massimo tra due dadi\nSi lancia due volte un dado a sei facce. Definiamo:\n\n\n\\(X = \\min \\{X_1, X_2\\}\\), il valore minimo tra i due lanci.\n\n\\(Y = \\max \\{X_1, X_2\\}\\), il valore massimo tra i due lanci.\n\n\nCostruisci la tabella della distribuzione congiunta \\(P(X, Y)\\).\nCalcola \\(P(X = 3, Y = 5)\\) e \\(P(X \\geq 3, Y \\leq 4)\\).\nDetermina la distribuzione marginale di \\(X\\) e di \\(Y\\).\nCalcola la covarianza tra \\(X\\) e \\(Y\\).\n\nEsercizio 5: Differenza tra due dadi\nSi lanciano due dadi a sei facce. Definiamo:\n\n\n\\(X\\) il risultato del primo lancio.\n\n\\(Y\\) la differenza assoluta tra i due risultati, ovvero \\(Y = |X - X_2|\\).\n\n\nDetermina la tabella della distribuzione congiunta \\(P(X, Y)\\).\nCalcola la distribuzione marginale di \\(Y\\).\nDetermina \\(P(Y = 0)\\) e \\(P(Y = 3)\\).\nLe variabili \\(X\\) e \\(Y\\) sono indipendenti? Giustifica la risposta.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Distribuzione congiunta di due lanci di dado\nAbbiamo due variabili aleatorie discrete: - \\(X\\), risultato del primo lancio di un dado a sei facce. - \\(Y\\), risultato del secondo lancio.\n1. Tabella della distribuzione congiunta \\(P(X, Y)\\) Poiché il dado è equo, ogni coppia di risultati \\((x, y)\\) ha la stessa probabilità. Esistono \\(6 \\times 6 = 36\\) combinazioni possibili, e ognuna ha probabilità:\n\\[\nP(X = x, Y = y) = \\frac{1}{36}, \\quad \\text{per ogni } x, y \\in \\{1, 2, 3, 4, 5, 6\\}\n\\]\nLa tabella della distribuzione congiunta è:\n\n\n\n\\(X\\)  \\(Y\\)\n\n1\n2\n3\n4\n5\n6\n\n\n\n1\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n2\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n3\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n4\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n5\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n6\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n\n2. Verifica che la somma delle probabilità sia 1 La somma di tutte le probabilità è:\n\\[\n\\sum_{x=1}^{6} \\sum_{y=1}^{6} P(X = x, Y = y) = 36 \\times \\frac{1}{36} = 1.\n\\]\n3. Distribuzione marginale di \\(X\\) e \\(Y\\) Per ottenere la distribuzione marginale di \\(X\\):\n\\[\nP(X = x) = \\sum_{y=1}^{6} P(X = x, Y = y) = 6 \\times \\frac{1}{36} = \\frac{1}{6}, \\quad \\forall x.\n\\]\nAnalogamente, per \\(Y\\):\n\\[\nP(Y = y) = \\sum_{x=1}^{6} P(X = x, Y = y) = \\frac{1}{6}, \\quad \\forall y.\n\\]\nEntrambe seguono una distribuzione uniforme su \\(\\{1, 2, 3, 4, 5, 6\\}\\).\n4. Indipendenza di \\(X\\) e \\(Y\\) Due variabili sono indipendenti se \\(P(X = x, Y = y) = P(X = x) P(Y = y)\\).\n\\[\n\\frac{1}{36} = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36}, \\quad \\forall x, y.\n\\]\nPoiché questa relazione vale per tutti i valori, \\(X\\) e \\(Y\\) sono indipendenti.\nEsercizio 2: Somma di due dadi\nAbbiamo:\n\\[\nS = X + Y\n\\]\n1. Tabella di probabilità congiunta \\(P(X, Y)\\) È la stessa tabella costruita nel primo esercizio.\n2. Distribuzione di probabilità di \\(S\\) La somma \\(S\\) assume valori da \\(2\\) (1+1) a \\(12\\) (6+6). La probabilità di ogni valore di \\(S\\) si ottiene contando le coppie \\((x, y)\\) che lo producono:\n\n\n\\(S\\)\n\\(P(S)\\)\n\n\n\n2\n1/36\n\n\n3\n2/36\n\n\n4\n3/36\n\n\n5\n4/36\n\n\n6\n5/36\n\n\n7\n6/36\n\n\n8\n5/36\n\n\n9\n4/36\n\n\n10\n3/36\n\n\n11\n2/36\n\n\n12\n1/36\n\n\n\n3. Calcolo di \\(P(S = 7)\\) e \\(P(S \\leq 5)\\) - \\(P(S = 7) = 6/36 = 1/6\\). - \\(P(S \\leq 5) = P(S = 2) + P(S = 3) + P(S = 4) + P(S = 5)\\)\n\\[\n\\frac{1}{36} + \\frac{2}{36} + \\frac{3}{36} + \\frac{4}{36} = \\frac{10}{36} = \\frac{5}{18}.\n\\]\n4. Valori più probabili e meno probabili - Il valore più probabile è \\(S = 7\\) (\\(P(S=7) = 1/6\\)). - I valori meno probabili sono \\(S = 2\\) e \\(S = 12\\) (\\(P(S) = 1/36\\)).\nEsercizio 3: Lancio di tre monete\nAbbiamo:\n\nTre monete equilibrare.\nVariabili:\n\n\n\\(X\\): numero di teste ottenute.\n\n\\(Y\\): risultato del primo lancio (1 se testa, 0 se croce).\n\n\n\n1. Spazio campionario e valori di \\(X\\) e \\(Y\\)\nLo spazio campionario dei lanci è:\n\\[\n\\{ (C, C, C), (C, C, T), (C, T, C), (C, T, T), (T, C, C), (T, C, T), (T, T, C), (T, T, T) \\}\n\\]\nOra assegniamo \\(X\\) e \\(Y\\):\n\n\nLancio\n\n\\(X\\) (num. teste)\n\n\\(Y\\) (primo lancio)\n\n\n\nC, C, C\n0\n0\n\n\nC, C, T\n1\n0\n\n\nC, T, C\n1\n0\n\n\nC, T, T\n2\n0\n\n\nT, C, C\n1\n1\n\n\nT, C, T\n2\n1\n\n\nT, T, C\n2\n1\n\n\nT, T, T\n3\n1\n\n\n\n2. Distribuzione congiunta \\(P(X, Y)\\)\nPoiché ogni lancio ha probabilità \\(\\frac{1}{8}\\), la tabella di probabilità congiunta è:\n\n\n\n\\(X\\)  \\(Y\\)\n\n0\n1\n\n\n\n0\n1/8\n0\n\n\n1\n2/8\n1/8\n\n\n2\n1/8\n3/8\n\n\n3\n0\n1/8\n\n\n\n3. Probabilità condizionate \\(P(X = 2 \\mid Y = 1)\\) \\[\nP(X = 2 \\mid Y = 1) = \\frac{P(X = 2, Y = 1)}{P(Y = 1)} = \\frac{3/8}{5/8} = \\frac{3}{5}.\n\\]\n\\(P(Y = 1 \\mid X = 2)\\) \\[\nP(Y = 1 \\mid X = 2) = \\frac{P(X = 2, Y = 1)}{P(X = 2)} = \\frac{3/8}{4/8} = \\frac{3}{4}.\n\\]\n4. Indipendenza di \\(X\\) e \\(Y\\)\nVerifichiamo se \\(P(X = x, Y = y) = P(X = x) P(Y = y)\\) per ogni coppia.\nEsempio: \\(P(X = 2, Y = 1) = 3/8\\) ma \\(P(X=2) P(Y=1) = (4/8)(5/8) = 20/64 = 5/16 \\neq 3/8\\).\nQuindi \\(X\\) e \\(Y\\) non sono indipendenti.\nEsercizio 4: Minimo e massimo tra due dadi\nAbbiamo:\n\n\n\\(X = \\min(X_1, X_2)\\), il minimo tra i due lanci.\n\n\\(Y = \\max(X_1, X_2)\\), il massimo tra i due lanci.\n\n1. Tabella della distribuzione congiunta\nPoiché i due lanci sono indipendenti e simmetrici, ci sono 36 coppie \\((X_1, X_2)\\), e ogni coppia ha probabilità \\(\\frac{1}{36}\\).\nLa tabella congiunta si costruisce considerando che \\(X = \\min(X_1, X_2)\\) e \\(Y = \\max(X_1, X_2)\\):\n\n\n\n\\(X\\)  \\(Y\\)\n\n1\n2\n3\n4\n5\n6\n\n\n\n1\n1/36\n2/36\n3/36\n4/36\n5/36\n6/36\n\n\n2\n-\n1/36\n2/36\n3/36\n4/36\n5/36\n\n\n3\n-\n-\n1/36\n2/36\n3/36\n4/36\n\n\n4\n-\n-\n-\n1/36\n2/36\n3/36\n\n\n5\n-\n-\n-\n-\n1/36\n2/36\n\n\n6\n-\n-\n-\n-\n-\n1/36\n\n\n\n2. Probabilità richieste\n\n\n\\(P(X = 3, Y = 5) = 3/36\\).\n\n\\(P(X \\geq 3, Y \\leq 4) = P(X = 3, Y = 3) + P(X = 3, Y = 4) + P(X = 4, Y = 4) = 1/36 + 2/36 + 1/36 = 4/36 = 1/9\\).\n\nEsercizio 5: Differenza tra due dadi\nAbbiamo:\n\n\n\\(X\\) = primo lancio.\n\n\\(Y = |X - X_2|\\).\n\n1. Tabella della distribuzione congiunta \\(P(X, Y)\\)\n\\(Y\\) assume valori da 0 a 5, a seconda della differenza tra i due dadi:\n\n\n\n\\(X\\)  \\(Y\\)\n\n0\n1\n2\n3\n4\n5\n\n\n\n1\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\n\n\n2\n1/6\n2/6\n1/6\n1/6\n1/6\n0\n\n\n3\n1/6\n2/6\n2/6\n1/6\n0\n0\n\n\n4\n1/6\n2/6\n2/6\n1/6\n0\n0\n\n\n5\n1/6\n2/6\n1/6\n1/6\n0\n0\n\n\n6\n1/6\n1/6\n1/6\n1/6\n0\n0\n\n\n\n2. Distribuzione marginale di \\(Y\\)\nSommiamo lungo \\(X\\):\n\n\n\\(Y\\)\n\\(P(Y)\\)\n\n\n\n0\n6/36\n\n\n1\n10/36\n\n\n2\n8/36\n\n\n3\n6/36\n\n\n4\n4/36\n\n\n5\n2/36\n\n\n\n3. Probabilità richieste\n\n\n\\(P(Y = 0) = 6/36 = 1/6\\).\n\n\\(P(Y = 3) = 6/36 = 1/6\\).\n\n4. Indipendenza di \\(X\\) e \\(Y\\)\nCome nell’esercizio 3, verifichiamo che \\(P(X, Y) \\neq P(X) P(Y)\\) per alcune coppie. Essendo la tabella non simmetrica, \\(X\\) e \\(Y\\) non sono indipendenti.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nConsidera il seguente esperimento casuale: si estrae una pallina da un’urna contenente tre palline numerate con i valori \\(1\\), \\(2\\) e \\(3\\).\nDopo l’estrazione, si definiscono due variabili casuali:\n\n\n\\(X\\), il valore della pallina estratta.\n\n\\(Y\\), il valore di un’altra variabile definita come \\(Y = X^2\\).\n\n\nCostruisci la distribuzione congiunta di \\(X\\) e \\(Y\\).\nCalcola il valore atteso di \\(X\\) e \\(Y\\), ossia \\(E[X]\\) e \\(E[Y]\\).\nCalcola la covarianza tra \\(X\\) e \\(Y\\), ossia \\(\\text{Cov}(X, Y)\\).\nCalcola la correlazione tra \\(X\\) e \\(Y\\), ossia \\(\\rho(X, Y)\\).\nInterpreta il valore della correlazione: cosa indica il segno e il valore ottenuto?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n1. Distribuzione congiunta di \\(X\\) e \\(Y\\)\nPoiché ogni pallina ha la stessa probabilità di essere estratta, la distribuzione congiunta è:\n\n\n\\(X\\)\n\\(Y = X^2\\)\n\\(P(X, Y)\\)\n\n\n\n1\n1\n\\(\\frac{1}{3}\\)\n\n\n2\n4\n\\(\\frac{1}{3}\\)\n\n\n3\n9\n\\(\\frac{1}{3}\\)\n\n\n\n2. Calcolo di \\(E[X]\\) e \\(E[Y]\\)\n\\[\nE[X] = \\sum_{i} x_i P(X = x_i) = 1 \\cdot \\frac{1}{3} + 2 \\cdot \\frac{1}{3} + 3 \\cdot \\frac{1}{3} = \\frac{1 + 2 + 3}{3} = 2\n\\]\n\\[\nE[Y] = \\sum_{i} y_i P(Y = y_i) = 1 \\cdot \\frac{1}{3} + 4 \\cdot \\frac{1}{3} + 9 \\cdot \\frac{1}{3} = \\frac{1 + 4 + 9}{3} = \\frac{14}{3}\n\\]\n3. Calcolo della covarianza \\(\\text{Cov}(X, Y)\\)\nLa covarianza è definita come:\n\\[\n\\text{Cov}(X, Y) = E[XY] - E[X]E[Y]\n\\]\nPrima calcoliamo \\(E[XY]\\):\n\\[\nE[XY] = \\sum_{i} x_i y_i P(X = x_i, Y = y_i) = 1 \\cdot 1 \\cdot \\frac{1}{3} + 2 \\cdot 4 \\cdot \\frac{1}{3} + 3 \\cdot 9 \\cdot \\frac{1}{3}\n\\]\n\\[\n= \\frac{1 + 8 + 27}{3} = \\frac{36}{3} = 12\n\\]\nOra possiamo calcolare la covarianza:\n\\[\n\\text{Cov}(X, Y) = E[XY] - E[X]E[Y] = 12 - \\left(2 \\cdot \\frac{14}{3}\\right) = 12 - \\frac{28}{3} = \\frac{36 - 28}{3} = \\frac{8}{3}\n\\]\n4. Calcolo della correlazione \\(\\rho(X, Y)\\)\nLa correlazione è definita come:\n\\[\n\\rho(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\cdot \\sigma_Y}\n\\]\nCalcoliamo prima le varianze:\n\\[\n\\text{Var}(X) = E[X^2] - (E[X])^2\n\\]\n\\[\nE[X^2] = 1^2 \\cdot \\frac{1}{3} + 2^2 \\cdot \\frac{1}{3} + 3^2 \\cdot \\frac{1}{3} = \\frac{1 + 4 + 9}{3} = \\frac{14}{3}\n\\]\n\\[\n\\text{Var}(X) = \\frac{14}{3} - 2^2 = \\frac{14}{3} - 4 = \\frac{14 - 12}{3} = \\frac{2}{3}\n\\]\nOra la varianza di \\(Y\\):\n\\[\n\\text{Var}(Y) = E[Y^2] - (E[Y])^2\n\\]\n\\[\nE[Y^2] = 1^2 \\cdot \\frac{1}{3} + 4^2 \\cdot \\frac{1}{3} + 9^2 \\cdot \\frac{1}{3} = \\frac{1 + 16 + 81}{3} = \\frac{98}{3}\n\\]\n\\[\n\\text{Var}(Y) = \\frac{98}{3} - \\left(\\frac{14}{3}\\right)^2 = \\frac{98}{3} - \\frac{196}{9} = \\frac{98 \\cdot 3 - 196}{9} = \\frac{294 - 196}{9} = \\frac{98}{9}\n\\]\nCalcoliamo le deviazioni standard:\n\\[\n\\sigma_X = \\sqrt{\\text{Var}(X)} = \\sqrt{\\frac{2}{3}} = \\frac{\\sqrt{6}}{3}\n\\]\n\\[\n\\sigma_Y = \\sqrt{\\text{Var}(Y)} = \\sqrt{\\frac{98}{9}} = \\frac{\\sqrt{98}}{3}\n\\]\nOra possiamo calcolare la correlazione:\n\\[\n\\rho(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\cdot \\sigma_Y} = \\frac{\\frac{8}{3}}{\\frac{\\sqrt{6}}{3} \\cdot \\frac{\\sqrt{98}}{3}}\n\\]\n\\[\n= \\frac{\\frac{8}{3}}{\\frac{\\sqrt{6 \\cdot 98}}{9}} = \\frac{8 \\cdot 9}{3 \\cdot \\sqrt{6 \\cdot 98}} = \\frac{24}{\\sqrt{588}}\n\\]\nPoiché \\(\\sqrt{588} = \\sqrt{4 \\cdot 147} = 2\\sqrt{147} = 2\\sqrt{49 \\cdot 3} = 2 \\cdot 7 \\cdot \\sqrt{3} = 14\\sqrt{3}\\):\n\\[\n\\rho(X, Y) = \\frac{24}{14\\sqrt{3}} = \\frac{12}{7\\sqrt{3}} = \\frac{12\\sqrt{3}}{21} \\approx 0.995\n\\]\n5. Interpretazione della correlazione\n\nIl valore \\(\\rho(X, Y) \\approx 0.995\\) è molto vicino a 1, indicando una correlazione positiva quasi perfetta tra \\(X\\) e \\(Y\\).\nIl segno positivo indica che all’aumentare di \\(X\\), anche \\(Y\\) tende ad aumentare.\nL’alto valore (prossimo a 1) indica che la relazione tra \\(X\\) e \\(Y\\) è quasi perfettamente lineare, il che è coerente con la definizione \\(Y = X^2\\) nell’intervallo considerato (piccoli valori positivi di \\(X\\)).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizi sulla distribuzione di probabilità congiunta sono disponibili sulla seguente pagina web.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [19] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [22] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [25] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [28] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [31] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [34] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [37] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [40] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [43] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#&gt; [46] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [49] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [52] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [55] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [58] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [61] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [64] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [67] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#&gt; [70] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [73] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_cov_cor.html#bibliografia",
    "href": "chapters/probability/11_cov_cor.html#bibliografia",
    "title": "34  Covarianza e correlazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_intro_distributions.html",
    "href": "chapters/probability/12_intro_distributions.html",
    "title": "35  Introduzione alle distribuzioni di probabilità",
    "section": "",
    "text": "Introduzione\nLe distribuzioni di probabilità – discrete (a massa) e continue (a densità) – rappresentano un pilastro dell’analisi quantitativa. Strumenti come la distribuzione normale o binomiale non sono semplici modelli teorici, ma strutture matematiche che permettono di decodificare fenomeni dominati dalla variabilità. In psicologia, disciplina focalizzata sulla comprensione della mente e del comportamento, potrebbe apparire paradossale ricorrere a questi strumenti che sembrano lontani dai fenomeni oggetti del nostro interesse. Tuttavia, è proprio l’intrinseca variabilità dei processi psicologici a renderli indispensabili: senza modelli in grado di mappare e interpretare la variabilità, ogni generalizzazione rischia di ridursi a un’approssimazione inefficace.\nQuesta riflessione è ben espressa in un recente articolo di Segal et al. (2025) sui disturbi mentali. L’autore osserva come i limiti nella comprensione della loro eziologia derivino dalla sottovalutazione della variabilità. Storicamente, la ricerca in psichiatria e psicologia ha confrontato gruppi clinici con controlli sani, identificando marcatori medi (biologici o comportamentali) come tratti distintivi. Sebbene utile, questo approccio trascura un dato fondamentale: i disturbi psichiatrici, come gran parte dei fenomeni psicologici, sono caratterizzati da un’eterogeneità interindividuale estrema, incompatibile con modelli basati su medie di gruppo.\nLa variabilità, dunque, non è un “rumore di fondo” da eliminare, ma un elemento informativo cruciale. Integrare questa prospettiva richiede non solo strumenti statistici avanzati, ma una riconfigurazione metodologica che ponga la diversità individuale al centro dell’indagine.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_intro_distributions.html#introduzione",
    "href": "chapters/probability/12_intro_distributions.html#introduzione",
    "title": "35  Introduzione alle distribuzioni di probabilità",
    "section": "",
    "text": "Prerequisiti\n\n\n\n\n\n\nLeggere l’articolo Embracing variability in the search for biological mechanisms of psychiatric illness (Segal et al., 2025).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_intro_distributions.html#la-variabilità-come-fattore-costitutivo-dei-disturbi-mentali",
    "href": "chapters/probability/12_intro_distributions.html#la-variabilità-come-fattore-costitutivo-dei-disturbi-mentali",
    "title": "35  Introduzione alle distribuzioni di probabilità",
    "section": "35.1 La variabilità come fattore costitutivo dei disturbi mentali",
    "text": "35.1 La variabilità come fattore costitutivo dei disturbi mentali\nI disturbi psichiatrici sfuggono a definizioni rigide. Persone con la stessa diagnosi mostrano profili sintomatologici radicalmente diversi: ad esempio, nel disturbo da stress post-traumatico si osservano oltre 636,000 possibili combinazioni di sintomi, mentre nella depressione più di 16,000. Uno studio discusso da Segal et al. (2025) rivela che meno del 50% dei pazienti depressi presenta un’unica configurazione di sintomi. Questa variabilità si estende all’età di esordio, alla gravità, alla durata e alla dinamica temporale dei sintomi.\nUn singolo sintomo può inoltre comparire in più disturbi, spiegando i tassi elevati di comorbilità: circa il 50% dei pazienti soddisfa criteri diagnostici multipli. Questa sovrapposizione suggerisce che i disturbi non siano entità discrete, ma manifestazioni diverse di meccanismi psicopatologici condivisi. Non a caso, il 37% dei sintomi presenti nel DSM-5 non è specifico di un singolo disturbo e, complessivamente, rappresenta il 72% di tutti i sintomi inclusi nei criteri diagnostici, evidenziando una significativa mancanza di specificità sintomatologica.\nFocalizzarsi sulle medie di gruppo, tuttavia, rischia di occultare questa complessità, producendo risultati inconsistenti. Come osservato da Thomas Insel nel riepilogare il suo mandato alla guida dei National Institutes of Mental Health (NIMH) degli Stati Uniti, nonostante i consistenti investimenti in neuroscienze e genetica, i progressi nella riduzione dei suicidi, nella diminuzione dei ricoveri e nel miglioramento delle prognosi sono stati limitati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_intro_distributions.html#verso-un-cambiamento-di-prospettiva",
    "href": "chapters/probability/12_intro_distributions.html#verso-un-cambiamento-di-prospettiva",
    "title": "35  Introduzione alle distribuzioni di probabilità",
    "section": "35.2 Verso un cambiamento di prospettiva",
    "text": "35.2 Verso un cambiamento di prospettiva\nPer superare queste criticità, secondo Segal et al. (2025), è necessario riconoscere la variabilità come proprietà costitutiva dei fenomeni psicologici. Ciò implica:\n\nAdottare approcci analitici che quantifichino la variabilità biologica e comportamentale a livello individuale, anziché di gruppo.\n\nUtilizzare modelli normativi per identificare deviazioni significative dalle traiettorie attese, anziché classificare soggetti in categorie rigide.\n\nAbbandonare l’idea di causalità univoca: una singola regione cerebrale può contribuire a sintomi multipli, così come meccanismi eterogenei possono generare lo stesso disturbo.\n\nAdottare framework dimensionali come l’HiTOP (Hierarchical Taxonomy of Psychopathology), che organizza i sintomi in dimensioni gerarchiche, massimizzando la cattura della variabilità fenotipica.\n\nIn questo contesto, le distribuzioni di probabilità diventano alleati indispensabili. Consentono di modellare la dispersione dei dati, identificare outlier e mappare traiettorie individuali, trasformando la variabilità da “problema” a “chiave interpretativa”. Analizzare la distribuzione di sintomi, tratti o risposte comportamentali permette di superare le medie di gruppo, consentendoci una migliore comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_intro_distributions.html#riflessioni-conclusive",
    "href": "chapters/probability/12_intro_distributions.html#riflessioni-conclusive",
    "title": "35  Introduzione alle distribuzioni di probabilità",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa teoria della probabilità offre gli strumenti concettuali per navigare la complessità dei dati psicologici. Come sottolineato da Segal et al. (2025), solo integrando sistematicamente la variabilità nell’analisi empirica è possibile sviluppare modelli predittivi robusti e interventi terapeutici mirati. La sfida non è eliminare l’incertezza, ma rendere conto della variabilità attraverso modelli che riflettano la complessità dei fenomeni psicologici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_intro_distributions.html#bibliografia",
    "href": "chapters/probability/12_intro_distributions.html#bibliografia",
    "title": "35  Introduzione alle distribuzioni di probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSegal, A., Tiego, J., Parkes, L., Holmes, A. J., Marquand, A. F., & Fornito, A. (2025). Embracing variability in the search for biological mechanisms of psychiatric illness. Trends in Cognitive Sciences, 29(1), 85–99.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html",
    "href": "chapters/probability/13_discr_rv_distr.html",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "36.1 Introduzione\nÈ importante distinguere tra variabili casuali discrete e continue, perché le distribuzioni di probabilità associate sono molto diverse nei due casi si veda il 29.\nIn questo capitolo ci focalizzeremo sulle distribuzioni di probabilità discrete, strumenti fondamentali per modellare fenomeni aleatori che generano un numero finito o numerabile di possibili esiti. Queste distribuzioni risultano particolarmente efficaci per descrivere eventi che si verificano in contesti discreti, come il numero di successi in un esperimento, l’occorrenza di un evento, o la selezione casuale da un insieme di opzioni finite.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#introduzione",
    "href": "chapters/probability/13_discr_rv_distr.html#introduzione",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "36.1.1 Panoramica delle Distribuzioni Discrete\nDi seguito, vengono presentate alcune delle principali distribuzioni discrete utilizzate in statistica e nella ricerca psicologica Ogni distribuzione è descritta in termini di caratteristiche fondamentali, applicazioni pratiche e importanza teorica.\n\n36.1.1.1 Distribuzione Uniforme Discreta\n\n\nDescrizione: La distribuzione uniforme discreta rappresenta situazioni in cui tutti gli eventi all’interno di un insieme finito hanno la stessa probabilità di verificarsi.\n\nApplicazioni: Si applica in contesti di scelta casuale equiprobabile, come:\n\nLa selezione casuale di uno stimolo da una lista di parole in un esperimento di memoria.\nL’assegnazione casuale di partecipanti a gruppi sperimentali in uno studio di psicologia sociale.\nLa scelta di un’immagine tra un insieme di stimoli visivi in una ricerca sull’attenzione.\nLa probabilità uniforme che un partecipante scelga una delle opzioni in un questionario a risposte multiple, in assenza di preferenze o conoscenze specifiche.\n\n\n\nParametri:\n\nIntervallo di supporto: l’insieme finito di valori possibili (ad esempio, \\(\\{1, 2, \\dots, k\\}\\)).\n\n\n\nImportanza: Funziona come modello di riferimento in situazioni di massima incertezza o mancanza di preferenze. È utile per definire un punto di partenza in analisi più complesse e per studiare comportamenti casuali.\n\n36.1.1.2 Distribuzione di Bernoulli\n\n\nDescrizione: La distribuzione di Bernoulli modella esperimenti con due possibili esiti, generalmente etichettati come “successo” (con probabilità \\(p\\)) e “fallimento” (con probabilità \\(1-p\\)).\n\nApplicazioni: Si applica a situazioni binarie, come il lancio di una moneta (testa/croce), la risposta a domande dicotomiche (sì/no), o l’esito di un evento che può verificarsi o meno.\n\nParametro:\n\n\n\\(p\\): probabilità di successo.\n\n\n\nImportanza: Costituisce la base per molte altre distribuzioni discrete, come la distribuzione binomiale e geometrica. È fondamentale per comprendere fenomeni con esiti dichotomici.\n\n36.1.1.3 Distribuzione Binomiale\n\n\nDescrizione: La distribuzione binomiale descrive il numero totale di successi in un numero fisso \\(n\\) di prove indipendenti, ciascuna governata da una distribuzione di Bernoulli con probabilità di successo \\(p\\).\n\nApplicazioni: Viene utilizzata per analizzare processi ripetuti con esiti binari, ad esempio:\n\nIl numero di voti favorevoli in un campione di opinione.\nIl numero di sintomi osservati in un gruppo di pazienti.\nIl conteggio di errori in un test di accuratezza.\n\n\n\nParametri:\n\n\n\\(n\\): numero di prove.\n\n\\(p\\): probabilità di successo in ogni prova.\n\n\n\nImportanza: Fornisce uno strumento essenziale per modellare fenomeni ripetuti in condizioni identiche, consentendo analisi probabilistiche avanzate e previsioni statistiche.\n\n36.1.1.4 Distribuzione di Poisson\n\n\nDescrizione: La distribuzione di Poisson modella il numero di eventi che si verificano in un intervallo fissato di tempo o spazio, quando tali eventi sono rari, indipendenti e accadono a un tasso medio costante \\(\\lambda\\).\n\nApplicazioni: Trova impiego in contesti dove gli eventi sono sporadici ma prevedibili, ad esempio:\n\nIl numero di episodi di ansia riportati in una settimana.\nIl numero di interazioni sociali spontanee di un bambino con disturbo dello spettro autistico durante una sessione di osservazione.\nLa frequenza di lapsus verbali durante una presentazione pubblica.\nIl numero di sogni vividi riportati durante una serie di notti consecutive in uno studio sul sonno.\n\n\n\nParametro:\n\n\n\\(\\lambda\\): tasso medio di eventi per unità di tempo o spazio.\n\n\n\nImportanza: È cruciale per analizzare fenomeni psicologici o comportamentali rari ma significativi. Aiuta a comprendere i meccanismi sottostanti e a modellare la variabilità osservata in contesti clinici, sperimentali o quotidiani.\n\nIn conclusione, le distribuzioni discrete sopra descritte rappresentano strumenti fondamentali per modellare una vasta gamma di fenomeni osservati in ambito scientifico, psicologico e applicativo. Ciascuna distribuzione offre una cornice teorica ben definita per interpretare e analizzare situazioni caratterizzate da variabili aleatorie discrete, fornendo così le basi per inferenze statistiche robuste e previsioni quantitative affidabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#distribuzioni-in-r",
    "href": "chapters/probability/13_discr_rv_distr.html#distribuzioni-in-r",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.2 Distribuzioni in R",
    "text": "36.2 Distribuzioni in R\nIn R, per ogni distribuzione sono disponibili quattro funzioni principali, i cui nomi iniziano con le lettere:\n\n\nd (density): per calcolare i valori teorici relativi alla distribuzione,\n\n\np (probability): per ottenere la probabilità cumulativa,\n\n\nq (quantile): per determinare i quantili,\n\n\nr (random): per generare campioni casuali.\n\nIl pacchetto di base stats include numerose funzioni dedicate alle principali distribuzioni statistiche, permettendo di calcolare valori teorici e simulare dati in modo semplice e flessibile. Per ulteriori dettagli sulle distribuzioni disponibili e sull’uso delle relative funzioni, è possibile consultare la documentazione con il comando ?Distributions.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#distribuzione-uniforme-discreta-1",
    "href": "chapters/probability/13_discr_rv_distr.html#distribuzione-uniforme-discreta-1",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.3 Distribuzione Uniforme Discreta",
    "text": "36.3 Distribuzione Uniforme Discreta\nLa distribuzione uniforme discreta è una delle più semplici e intuitive distribuzioni di probabilità. È utilizzata per modellare situazioni in cui tutti gli esiti possibili sono ugualmente probabili. Si applica, ad esempio, quando si estrae un numero a caso da un insieme finito di interi senza alcuna preferenza.\n\nDefinizione 36.1 Sia \\(X\\) una variabile casuale che può assumere i valori interi da 1 a \\(N\\), tutti con la stessa probabilità. Allora diciamo che \\(X\\) ha una distribuzione uniforme discreta sull’intervallo \\(\\{1, 2, \\dots, N\\}\\). In simboli:\n\\[\nX \\sim \\text{Uniforme Discreta}(1, N) .\n\\]\nPoiché ci sono \\(N\\) valori possibili e ciascuno ha la stessa probabilità, ogni valore ha probabilità:\n\\[\nP(X = x) = \\frac{1}{N}, \\quad \\text{per } x \\in \\{1, 2, \\dots, N\\}.\n\\]\n\n\n36.3.1 Proprietà di normalizzazione\nLa somma delle probabilità di tutti gli esiti deve essere pari a 1:\n\\[\n\\sum_{x = 1}^{N} P(X = x) = \\sum_{x = 1}^{N} \\frac{1}{N} = \\frac{1}{N} \\cdot N = 1.\n\\]\nQuesta è una proprietà fondamentale di ogni distribuzione di probabilità.\n\n36.3.2 Valore atteso\nIl valore atteso (o media) ci dice qual è il risultato medio atteso nel lungo periodo. Si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x = 1}^{N} x \\cdot P(X = x) = \\frac{1}{N} \\sum_{x = 1}^{N} x.\n\\]\nLa somma dei primi \\(N\\) numeri naturali è:\n\\[\n\\sum_{x = 1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nQuindi:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nIn conclusione, il valore atteso di una variabile uniforme discreta su \\(\\{1, \\dots, N\\}\\) è \\(\\frac{N + 1}{2}\\).\n\n36.3.3 Varianza\nLa varianza della distribuzione uniforme discreta è:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(N - 1)}{12}.\n\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nLa varianza misura quanto i valori di \\(X\\) si discostano in media dalla media \\(\\mathbb{E}(X)\\). Si calcola come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\left[\\mathbb{E}(X)\\right]^2.\n\\]\n\nCalcolo di \\(\\mathbb{E}(X^2)\\).\n\nPoiché tutti i valori hanno la stessa probabilità \\(\\frac{1}{N}\\), otteniamo:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\sum_{x = 1}^{N} x^2.\n\\]\nLa somma dei quadrati dei primi \\(N\\) interi è:\n\\[\n\\sum_{x = 1}^{N} x^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\n(per una dimostrazione, si veda la pagina di Wikipedia sui numeri piramidali quadrati).\nQuindi:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}.\n\\]\n\nCalcolo della varianza.\n\nSostituendo nella formula della varianza:\n\\[\n\\begin{aligned}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4}\n\\end{aligned}\n\\]\nPer semplificare, portiamo tutto allo stesso denominatore:\n\\[\n\\begin{aligned}\n\\mathbb{V}(X) &= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1) \\left[2(2N + 1) - 3(N + 1)\\right]}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}.\n\\end{aligned}\n\\]\nIn conclusione, la varianza della distribuzione uniforme discreta è:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(N - 1)}{12}.\n\\]\n\n\n\nIn sintesi, per una variabile casuale \\(X\\) uniformemente distribuita su \\(\\{1, 2, \\dots, N\\}\\):\n\n\nProprietà\nFormula\n\n\n\nMedia\n\\(\\mathbb{E}(X) = \\dfrac{N + 1}{2}\\)\n\n\nVarianza\n\\(\\mathbb{V}(X) = \\dfrac{(N + 1)(N - 1)}{12}\\)\n\n\n\nQuesta distribuzione è utile ogni volta che non c’è alcuna ragione per preferire un valore a un altro all’interno di un insieme finito di numeri interi.\n\nEsempio 36.1 Supponiamo che \\(X\\) sia una variabile casuale con distribuzione uniforme discreta tra 1 e 10, ovvero:\n\\[\nX \\sim \\text{Uniforme Discreta}(1, 10) .\n\\]\nVogliamo:\n\ngenerare un grande campione casuale,\ncalcolare la media e la varianza osservate,\nconfrontarle con i valori teorici.\n\nCodice R.\n\nset.seed(123)  # Per rendere la simulazione riproducibile\n\n# Parametro N\nN &lt;- 10\n\n# Simulazione: 100.000 osservazioni dalla distribuzione uniforme discreta\nx &lt;- sample(1:N, size = 100000, replace = TRUE)\n\n# Media e varianza empiriche\nmedia_empirica &lt;- mean(x)\nvarianza_empirica &lt;- var(x)\n\n# Valori teorici\nmedia_teorica &lt;- (N + 1) / 2\nvarianza_teorica &lt;- ((N + 1) * (N - 1)) / 12\n\n# Risultati\ntibble(\n  `Media empirica` = media_empirica,\n  `Media teorica` = media_teorica,\n  `Varianza empirica` = varianza_empirica,\n  `Varianza teorica` = varianza_teorica\n)\n#&gt; # A tibble: 1 × 4\n#&gt;   `Media empirica` `Media teorica` `Varianza empirica` `Varianza teorica`\n#&gt;              &lt;dbl&gt;           &lt;dbl&gt;               &lt;dbl&gt;              &lt;dbl&gt;\n#&gt; 1             5.51             5.5                8.26               8.25\n\nCon un campione molto grande, le statistiche empiriche (cioè calcolate dai dati simulati) saranno molto vicine ai valori teorici:\n\n\n\nValore\n\n\n\nMedia teorica\n5.5\n\n\nMedia empirica\n≈ 5.5\n\n\nVarianza teorica\n8.25\n\n\nVarianza empirica\n≈ 8.25\n\n\n\n\nIn sintesi, a simulazione conferma che:\n\nla media empirica converge verso \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\),\nla varianza empirica converge verso \\(\\mathbb{V}(X) = \\frac{(N + 1)(N - 1)}{12}\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#distribuzione-di-bernoulli-1",
    "href": "chapters/probability/13_discr_rv_distr.html#distribuzione-di-bernoulli-1",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.4 Distribuzione di Bernoulli",
    "text": "36.4 Distribuzione di Bernoulli\nIn statistica, un esperimento che ammette solo due esiti possibili è modellato attraverso quella che viene chiamata “prova Bernoulliana”. Un esempio tipico è il lancio di una moneta, che può dare come risultato testa o croce.\n\nDefinizione 36.2 Una variabile casuale \\(X\\) che assume valori in \\(\\{0, 1\\}\\) è detta variabile di Bernoulli. La sua distribuzione di probabilità è definita come:\n\\[\nP(X \\mid \\theta) =\n  \\begin{cases}\n    p     & \\text{se $X = 1$ (successo)}, \\\\\n    1 - p & \\text{se $X = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq p \\leq 1\\). Il parametro \\(p\\) rappresenta la probabilità del “successo” (\\(X = 1\\)), mentre \\(1 - p\\) è la probabilità dell’“insuccesso” (\\(X = 0\\)).\n\nLa distribuzione di Bernoulli descrive quindi un contesto in cui la probabilità di osservare l’esito 1 è \\(p\\) e quella di osservare l’esito 0 è \\(1 - p\\). Viene utilizzata per modellare situazioni binarie, come una risposta “sì” o “no”, oppure un “successo” o “insuccesso”.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{aligned}\n\\mathbb{E}(X) &= 0 \\cdot P(X=0) + 1 \\cdot P(X=1) = p, \\\\\n\\mathbb{V}(X) &= (0 - p)^2 \\cdot P(X=0) + (1 - p)^2 \\cdot P(X=1) = p(1-p).\n\\end{aligned}\n\\tag{36.1}\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\nEsaminiamo la dimostrazione algebrica del calcolo della varianza.\nEspandiamo il calcolo della somma, considerando i due possibili valori di \\(X\\) (0 e 1).\n\n\nPrimo termine (\\(X = 0\\)):\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = (0 - p)^2 \\cdot (1 - p).\n\\]\nSemplificando \\((0 - p)^2 = p^2\\), quindi:\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = p^2 \\cdot (1 - p).\n\\]\n\n\nSecondo termine (\\(X = 1\\)):\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - p)^2 \\cdot p.\n\\]\nSemplificando \\((1 - p)^2 = 1 - 2p + p^2\\), quindi:\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - 2p + p^2) \\cdot p = p - 2p^2 + p^3.\n\\]\n\n\nSomma dei termini\nOra sommiamo i due contributi:\n\\[\n\\mathbb{V}(X) = p^2 \\cdot (1 - p) + (p - 2p^2 + p^3).\n\\]\nEspandendo il primo termine:\n\\[\np^2 \\cdot (1 - p) = p^2 - p^3.\n\\]\nSomma completa:\n\\[\n\\mathbb{V}(X) = (p^2 - p^3) + (p - 2p^2 + p^3).\n\\]\n\n\nRaggruppiamo i termini\n\\[\n\\mathbb{V}(X) = p - p^2.\n\\]\nRisultato finale:\n\\[\n\\mathbb{V}(X) = p(1 - p).\n\\]\n\n\nIn sintesi, la varianza di una variabile aleatoria binaria \\(X\\), distribuita secondo Bernoulli con parametro \\(p\\), è data da \\(p(1-p)\\).\n\n\nTale risultato mostra come la varianza massima si ottenga per \\(p = 0.5\\), condizione che corrisponde alla massima incertezza intrinseca nel processo, ossia quando la probabilità di successo eguaglia quella di insuccesso.\n\n# Valori di p tra 0 e 1\np &lt;- seq(0, 1, length.out = 100)\nvariance &lt;- p * (1 - p)\ndata &lt;- data.frame(p = p, Variance = variance)\n\n# Creazione del grafico\nggplot(data, aes(x = p, y = Variance)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(p),\n    y = \"Varianza\"\n  )\n\n\n\n\n\n\n\n\n36.4.1 Notazione\nPer indicare che la variabile casuale \\(X\\) segue una distribuzione Bernoulliana di parametro \\(p\\) Utilizziamo la notazione \\(X \\sim \\mathcal{Bern}(p)\\), o in maniera equivalente \\(\\mathcal{Bern}(X \\mid p)\\).\n\nEsempio 36.2 Nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilità di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilità assegna una probabilità di \\(\\frac{1}{2}\\) sia per \\(X = 0\\) che per \\(X = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(X = 0\\) e \\(1\\) per \\(X = 1\\).\nGeneriamo dei valori casuali dalla distribuzione di Bernoulli. Iniziamo con un singolo valore:\n\n# Probabilità di successo\np &lt;- 0.5\n\n# Genera un singolo valore\nbernoulli_sample &lt;- rbinom(n = 1, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt; [1] 0\n\n# Genera un campione di 10 valori\nbernoulli_sample &lt;- rbinom(n = 10, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt;  [1] 0 1 0 1 0 0 0 1 0 0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#distribuzione-binomiale-1",
    "href": "chapters/probability/13_discr_rv_distr.html#distribuzione-binomiale-1",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.5 Distribuzione Binomiale",
    "text": "36.5 Distribuzione Binomiale\nLa distribuzione binomiale è una distribuzione di probabilità discreta che modella il numero di successi \\(y\\) in un numero fissato \\(n\\) di prove di Bernoulli indipendenti e identiche, dove ciascuna prova ha solo due esiti possibili: “successo” (rappresentato da “1”) con probabilità \\(p\\) o “insuccesso” (rappresentato da “0”) con probabilità \\(1 - p\\). La notazione utilizzata è la seguente:\n\\[\nY \\sim \\mathcal{Binom}(n, p).\n\\]\n\nDefinizione 36.3 La distribuzione binomiale descrive la probabilità di osservare esattamente \\(y\\) successi in \\(n\\) prove di Bernoulli indipendenti:\n\\[\nP(Y = y) = \\binom{n}{y} p^{y} (1 - p)^{n - y} = \\frac{n!}{y!(n - y)!} p^{y} (1 - p)^{n - y},\n\\tag{36.2}\\]\ndove \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di modi possibili per ottenere \\(y\\) successi in \\(n\\) prove, e \\(p\\) è la probabilità di successo in ciascuna prova.\n\nLa distribuzione binomiale si presta bene a esempi classici come il lancio ripetuto di una moneta o l’estrazione di biglie da un’urna. Ad esempio, nel caso del lancio di una moneta, questa distribuzione descrive la probabilità di ottenere un determinato numero di “teste” in un certo numero di lanci, con ogni lancio che segue una distribuzione di Bernoulli con probabilità di successo \\(p\\).\nUna caratteristica interessante della distribuzione binomiale è la sua proprietà di riproducibilità: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono entrambe distribuzioni binomiali con lo stesso parametro \\(p\\), ma con un diverso numero di prove (\\(n_1\\) e \\(n_2\\)), la loro somma, \\(y = y_1 + y_2\\), sarà ancora distribuita binomialmente, con parametri \\(n_1 + n_2\\) e \\(p\\).\n\n\n\n\n\n\nDimostrazione\n\n\n\nPer chiarire il calcolo delle probabilità nella distribuzione binomiale, consideriamo una serie di prove di Bernoulli. Supponiamo di avere \\(n\\) prove indipendenti, ciascuna con probabilità \\(p\\) di successo, e di osservare esattamente \\(y\\) successi.\nUna possibile configurazione dei risultati può essere rappresentata come:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ successi} \\, \\overbrace{II\\dots I}^\\text{$n - y$ insuccessi}\n\\]\nLa probabilità di ottenere esattamente \\(y\\) successi in una sequenza specifica (cioè in un ordine fissato) è:\n\\[\np^y \\cdot (1 - p)^{n - y},\n\\]\ndove \\(p^y\\) è la probabilità dei \\(y\\) successi e \\((1 - p)^{n - y}\\) quella dei \\(n - y\\) insuccessi.\nTuttavia, ciò che ci interessa è la probabilità complessiva di ottenere \\(y\\) successi in qualsiasi ordine. In altre parole, vogliamo calcolare la probabilità dell’unione di tutte le possibili sequenze di \\(n\\) prove che contengono esattamente \\(y\\) successi.\nIl numero di tali sequenze è dato dal coefficiente binomiale \\(\\binom{n}{y}\\), che rappresenta il numero di modi diversi in cui possiamo scegliere le \\(y\\) posizioni dei successi tra le \\(n\\) prove.\nMoltiplicando la probabilità di una singola sequenza per il numero totale di sequenze possibili, otteniamo la funzione di probabilità della distribuzione binomiale:\n\\[\nP(Y = y) = \\binom{n}{y} p^y (1 - p)^{n - y}.\n\\]\n\n\n\n36.5.1 Caso particolare \\(n = 1\\)\n\nOra consideriamo il caso particolare in cui \\(n = 1\\). Quando \\(n = 1\\), il coefficiente binomiale diventa:\n\\[\n\\binom{1}{y} = \\frac{1!}{y! (1-y)!}.\n\\]\nEspandiamo i fattoriali per i due possibili valori di \\(y\\), che può assumere solo 0 o 1 (poiché \\(y \\in \\{0, 1, \\dots, n\\}\\)).\nCaso 1: \\(y = 0\\)\n\\[\n\\binom{1}{0} = \\frac{1!}{0! (1-0)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(y = 0\\): \\[\nP(Y = 0) = \\binom{1}{0} p^0 (1-p)^{1-0} = 1 \\cdot 1 \\cdot (1-p) = 1-p.\n\\]\nCaso 2: \\(y = 1\\)\n\\[\n\\binom{1}{1} = \\frac{1!}{1! (1-1)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(y = 1\\): \\[\nP(Y = 1) = \\binom{1}{1} p^1 (1-p)^{1-1} = 1 \\cdot p \\cdot 1 = p.\n\\]\nIn conclusione, la PMF per la distribuzione binomiale con \\(n = 1\\) diventa:\n\\[\nP(Y = y) =\n\\begin{cases}\n1-p, & \\text{se } y = 0, \\\\\np, & \\text{se } y = 1.\n\\end{cases}\n\\]\nQuesta è esattamente la PMF della distribuzione di Bernoulli con parametro \\(p\\):\n\\[\nP(Y = y) = p^y (1-p)^{1-y}, \\quad y \\in \\{0, 1\\}.\n\\]\nPertanto, la distribuzione binomiale con \\(n = 1\\) è equivalente alla distribuzione di Bernoulli con parametro \\(p\\).\n\n36.5.2 Applicazioni Pratiche della Distribuzione Binomiale\nPer illustrare l’applicazione della distribuzione binomiale, consideriamo un esempio semplice. Supponiamo di osservare 2 successi su 4 prove di Bernoulli, dove la probabilità di successo in ogni prova è \\(p = 0.2\\). La probabilità di ottenere esattamente questo risultato si calcola con la formula:\n\\[\nP(Y = 2) = \\binom{4}{2} \\cdot 0.2^2 \\cdot (1 - 0.2)^{2} = 0.1536.\n\\]\nIn R, questo calcolo si può fare in modo diretto:\n\n# Parametri\nn &lt;- 4\np &lt;- 0.2\ny &lt;- 2\n\n# Calcolo della probabilità esatta\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.154\n\nIn alternativa, possiamo usare la funzione dbinom() per ottenere la stessa probabilità:\n\nprob &lt;- dbinom(x = y, size = n, prob = p)\nprint(prob)\n#&gt; [1] 0.154\n\n\n36.5.2.1 Visualizzazione della distribuzione di probabilità\nPossiamo rappresentare graficamente la distribuzione di massa di probabilità per tutti i possibili valori di \\(y\\) da \\(0\\) a \\(n\\):\n\ny &lt;- 0:n\nprobabilities &lt;- dbinom(y, size = n, prob = p)\n\ndf &lt;- data.frame(Successi = y, Probabilità = probabilities)\n\ndf |&gt;\n  ggplot(aes(x = Successi, y = Probabilità)) +\n    geom_segment(\n      aes(xend = Successi, yend = 0), lwd = 1.2\n      ) +\n    geom_point(size = 3) +\n    labs(\n      x = \"Numero di successi y\",\n      y = \"Probabilità\"\n    )\n\n\n\n\n\n\n\n\n36.5.2.2 Generazione di un campione casuale\nLa funzione rbinom() permette di generare un campione casuale da una distribuzione binomiale:\n\nset.seed(42)\nsamples &lt;- rbinom(n = 30, size = 5, prob = 0.5)\nprint(samples)\n#&gt;  [1] 4 4 2 4 3 3 3 1 3 3 2 3 4 2 2 4 5 1 2 3 4 1 5 4 1 3 2 4 2 4\n\n\n36.5.2.3 Variazione della distribuzione al variare di \\(p\\)\n\nPer esplorare l’effetto di diversi valori di \\(p\\) sulla forma della distribuzione, possiamo visualizzare più curve binomiali per \\(n = 20\\) e \\(p\\) variabile:\n\nn &lt;- 20\np_values &lt;- seq(0.3, 0.9, by = 0.3)\ny &lt;- 0:25\n\ndf &lt;- data.frame()\n\nfor (p in p_values) {\n  binom_dist &lt;- dbinom(y, size = n, prob = p)\n  df &lt;- rbind(df, data.frame(y = y, Prob = binom_dist, p = factor(p)))\n}\n\ndf |&gt;\n  ggplot(aes(x = y, y = Prob, color = p)) +\n    geom_point() +\n    geom_line() +\n    labs(\n      x = \"Numero di successi y\",\n      y = \"Probabilità\",\n      color = expression(p)\n    )\n\n\n\n\n\n\n\n\n36.5.2.4 Funzione di ripartizione cumulativa\nPossiamo anche rappresentare la funzione di distribuzione cumulativa (CDF) per \\(n = 5\\) e \\(p = 0.5\\):\n\nn &lt;- 5\np &lt;- 0.5\ny &lt;- 0:n\n\ncdf_values &lt;- pbinom(y, size = n, prob = p)\ndf &lt;- data.frame(y = y, cdf = cdf_values)\n\ndf |&gt;\n  ggplot(aes(x = y, y = cdf)) +\n    geom_line() +\n    geom_point() +\n    geom_hline(\n      yintercept = 1, linetype = \"dashed\", color = \"black\", alpha = 0.7\n    ) +\n    labs(\n      x = \"Numero di successi y\",\n      y = \"Probabilità cumulativa\"\n    )\n\n\n\n\n\n\n\n\nEsempio 36.3 Supponiamo di lanciare una moneta equa (cioè con probabilità \\(p = 0.5\\) di ottenere testa) 5 volte. Vogliamo calcolare la probabilità di ottenere almeno 2 teste, ovvero:\n\\[\nP(Y \\geq 2) = P(Y = 2) + P(Y = 3) + P(Y = 4) + P(Y = 5).\n\\]\nPossiamo sommare direttamente queste probabilità usando dbinom():\n\nresult &lt;- sum(dbinom(2:5, size = 5, prob = 0.5))\nprint(result)\n#&gt; [1] 0.812\n\nUn modo alternativo, più efficiente, consiste nel calcolare il complemento della probabilità di ottenere meno di 2 teste (cioè 0 o 1):\n\\[\nP(Y \\geq 2) = 1 - P(Y \\leq 1)\n\\]\nIn R, possiamo usare la funzione pbinom() per calcolare questa probabilità cumulativa:\n\nresult &lt;- 1 - pbinom(q = 1, size = 5, prob = 0.5)\nprint(result)\n#&gt; [1] 0.812\n\nEntrambi i metodi restituiscono lo stesso risultato numerico, ma il secondo è spesso preferibile quando \\(n\\) è grande o quando si vuole calcolare una probabilità di coda.\n\n\n36.5.2.5 Quantili di una distribuzione binomiale\nHai perfettamente ragione — grazie per l’osservazione!\nInfatti, con i parametri size = 5, prob = 0.5 e target_probability = 0.60, la funzione qbinom() restituisce 3, non 2. Questo perché qbinom() restituisce il più piccolo valore di \\(y\\) tale che \\(P(Y \\leq y) \\geq p\\). Verifichiamolo in R:\npbinom(2, 5, 0.5)  # = 0.5\npbinom(3, 5, 0.5)  # = 0.8125\nQuindi:\n\n\n\\(P(Y \\leq 2) = 0.5\\) → troppo poco\n\n\\(P(Y \\leq 3) = 0.8125\\) → supera il 60%\n\nPertanto, qbinom(0.6, 5, 0.5) restituisce 3.\n\n36.5.2.6 Quantili di una distribuzione binomiale\nLa funzione qbinom() permette di calcolare il quantile di una distribuzione binomiale, cioè il numero minimo di successi \\(y\\) tale che la probabilità cumulativa \\(P(Y \\leq y)\\) sia maggiore o uguale a una certa soglia.\nAd esempio, supponiamo di voler sapere qual è il numero minimo di successi tale che la probabilità cumulativa sia almeno 60%. Possiamo usare:\n\n# Probabilità cumulativa desiderata\ntarget_probability &lt;- 0.60\n\n# Calcolo del quantile\nresult &lt;- qbinom(p = target_probability, size = 5, prob = 0.5)\nprint(result)\n#&gt; [1] 3\n\nIl risultato è 3, il che significa che:\n\\[\nP(Y \\leq 3) = 0.8125 \\geq 0.60,\n\\]\nmentre\n\\[\nP(Y \\leq 2) = 0.5 &lt; 0.60.\n\\]\nQuindi, servono almeno 3 successi per superare la soglia del 60% di probabilità cumulativa.\n\n🔎 qbinom(p, size, prob) restituisce il più piccolo valore di \\(y\\) tale che \\(P(Y \\leq y) \\geq p\\).\n\n\n36.5.2.7 Rappresentazione grafica del quantile\nPer visualizzare il comportamento della funzione di ripartizione cumulativa e individuare il quantile per \\(p = 0.60\\), possiamo usare il seguente codice in R:\n\n# Parametri\nn &lt;- 5\np &lt;- 0.5\ntarget_probability &lt;- 0.60\n\n# Asse y: numero di successi\ny &lt;- 0:n\n\n# Calcolo dei valori cumulativi\ncdf &lt;- pbinom(y, size = n, prob = p)\n\n# Calcolo del quantile\nq &lt;- qbinom(target_probability, size = n, prob = p)\n\n# Data frame\ndf &lt;- data.frame(Successi = y, CDF = cdf)\n\n# Grafico\ndf |&gt;\n  ggplot(aes(x = Successi, y = CDF)) +\n  geom_step(direction = \"hv\", linewidth = 1.1) +\n  geom_point(size = 2) +\n  geom_hline(\n    yintercept = target_probability, linetype = \"dashed\", color = \"red\"\n  ) +\n  geom_vline(xintercept = q, linetype = \"dotted\", color = \"blue\") +\n  annotate(\n    \"text\",\n    x = q + 0.4, y = 0.05, label = paste(\"quantile =\", q),\n    color = \"blue\"\n  ) +\n  annotate(\n    \"text\",\n    x = 0.5, y = target_probability + 0.05,\n    label = paste(\"soglia =\", target_probability), color = \"red\"\n  ) +\n  labs(\n    x = \"Numero di successi\",\n    y = \"Probabilità cumulativa\"\n  ) +\n  ylim(0, 1.05)\n\n\n\n\n\n\n\nIn questo grafico:\n\nla linea rossa tratteggiata rappresenta la soglia di probabilità desiderata (es. 0.60);\nla linea blu tratteggiata verticale indica il quantile corrispondente, cioè il più piccolo valore di \\(y\\) per cui \\(P(Y \\leq y) \\geq 0.60\\);\nil valore calcolato è 3, quindi con al massimo 3 successi, la probabilità cumulativa supera il 60%.\n\n\nEsempio 36.4 Consideriamo una distribuzione binomiale con \\(n = 10\\) prove e probabilità di successo \\(p = 0.2\\). Supponiamo di voler calcolare la probabilità di ottenere al massimo 4 successi. In termini matematici, vogliamo calcolare:\n\\[\nP(Y \\leq 4) .\n\\]\nIn R, questo si ottiene con la funzione pbinom():\n\n# Calcolo della probabilità cumulativa fino a 4 successi\np_cumulativa &lt;- pbinom(4, size = 10, prob = 0.2)\nprint(p_cumulativa)\n#&gt; [1] 0.967\n\nIl risultato indica che c’è circa l’97% di probabilità di ottenere 4 o meno successi su 10 prove, quando la probabilità di successo in ciascuna prova è 0.2.\nOra facciamo il passaggio inverso: immaginiamo di conoscere la probabilità cumulativa (per esempio, 0.97) e vogliamo sapere quanti successi bisogna considerare per raggiungere quella probabilità.\nPer questo usiamo la funzione qbinom(), che ci restituisce il più piccolo numero di successi \\(y\\) tale che \\(P(Y \\leq y) \\geq\\) quella probabilità:\n\n# Calcolo del numero di successi associato alla probabilità cumulativa\nnumero_successi &lt;- qbinom(p_cumulativa, size = 10, prob = 0.2)\nprint(numero_successi)\n#&gt; [1] 4\n\nIl valore ottenuto sarà 4, cioè il minimo numero di successi per cui la probabilità cumulativa è almeno il 97%.\nRiepilogo concetti chiave:\n\n\npbinom(y, n, p) calcola la probabilità di ottenere al massimo \\(y\\) successi;\n\nqbinom(prob, n, p) calcola il numero minimo di successi necessari per raggiungere almeno quella probabilità.\n\nIn sintesi, pbinom() e qbinom() sono strumenti complementari: pbinom ci dà la probabilità di ottenere fino a un certo numero di successi, mentre qbinom ci dice fino a quanti successi possiamo ottenere per raggiungere una certa probabilità. Nell’analisi di una distribuzione binomiale (e di molte altre distribuzioni) queste funzioni aiutano a calcolare e interpretare facilmente probabilità cumulate e quantili in R, rendendo più semplice l’analisi di eventi aleatori.\n\n\n36.5.3 Valore atteso e deviazione standard nella distribuzione binomiale\nNella distribuzione binomiale, possiamo calcolare facilmente due quantità molto importanti:\n\n\nil valore atteso (o media), che ci dice quanti successi ci aspettiamo in media su un certo numero di prove;\n\nla deviazione standard, che ci dice quanto i risultati tendono a variare attorno alla media.\n\nLe formule sono le seguenti:\n\\[\n\\text{Media (valore atteso):} \\quad \\mu = n p ,\n\\tag{36.3}\\]\n\\[\n\\text{Deviazione standard:} \\quad \\sigma = \\sqrt{n p (1 - p)} ,\n\\tag{36.4}\\]\ndove:\n\n\n\\(n\\) è il numero di prove (per esempio, il numero di lanci di una moneta),\n\n\\(p\\) è la probabilità di successo in ogni prova.\n\n\n\n\n\n\n\nDimostrazione.\nLa variabile \\(Y\\) rappresenta il numero di successi in \\(n\\) prove di Bernoulli indipendenti. Possiamo scriverla come somma di \\(n\\) variabili casuali indipendenti:\n\\[\nY = Y_1 + Y_2 + \\cdots + Y_n,\n\\]\ndove ciascuna \\(Y_i \\sim \\text{Bernoulli}(p)\\), cioè:\n\\[\nY_i =\n\\begin{cases}\n1 & \\text{con probabilità } p \\\\\n0 & \\text{con probabilità } 1 - p\n\\end{cases}\n\\]\nValore atteso di \\(Y_i\\).\nPer definizione del valore atteso:\n\\[\n\\mathbb{E}(Y_i) = 1 \\cdot p + 0 \\cdot (1 - p) = p.\n\\]\nValore atteso di \\(Y_i^2\\).\nPoiché \\(Y_i\\) assume solo i valori 0 e 1, si ha \\(Y_i^2 = Y_i\\). Quindi:\n\\[\n\\mathbb{E}(Y_i^2) = \\mathbb{E}(Y_i) = p.\n\\]\nLa varianza di una variabile casuale si definisce come:\n\\[\n\\operatorname{Var}(Y_i) = \\mathbb{E}(Y_i^2) - [\\mathbb{E}(Y_i)]^2.\n\\]\nSostituendo i valori trovati sopra:\n\\[\n\\operatorname{Var}(Y_i) = p - p^2 = p(1 - p).\n\\]\nRicordiamo che \\(Y = \\sum_{i=1}^{n} Y_i\\) e che le \\(Y_i\\) sono indipendenti. Una proprietà fondamentale della varianza è che se \\(Z_1, \\dots, Z_n\\) sono indipendenti:\n\\[\n\\operatorname{Var}(Z_1 + \\cdots + Z_n) = \\operatorname{Var}(Z_1) + \\cdots + \\operatorname{Var}(Z_n).\n\\]\nApplichiamola al nostro caso:\n\\[\n\\operatorname{Var}(Y) = \\sum_{i=1}^{n} \\operatorname{Var}(Y_i).\n\\]\nPoiché tutte le \\(Y_i\\) hanno la stessa varianza \\(p(1 - p)\\), la somma diventa:\n\\[\n\\operatorname{Var}(Y) = n \\cdot p(1 - p).\n\\]\nAbbiamo dimostrato da definizione che, se \\(Y \\sim \\text{Bin}(n, p)\\), allora:\n\\[\n\\operatorname{Var}(Y) = n \\cdot p \\cdot (1 - p).\n\\]\nQuesta formula descrive la dispersione attesa nel numero di successi su \\(n\\) prove indipendenti, ciascuna con probabilità di successo \\(p\\).\n\n\n\n\nEsempio 36.5 Supponiamo di lanciare 4 volte una moneta truccata che ha una probabilità di successo (es. ottenere testa) pari a \\(p = 0.2\\).\nVogliamo calcolare:\n\nla media attesa del numero di teste,\nla varianza,\ne la deviazione standard.\n\n\nCalcolo del valore atteso (media):\n\n\\[\n\\mu = n \\cdot p = 4 \\cdot 0.2 = 0.8 .\n\\]\nQuindi, in media, ci aspettiamo di ottenere 0.8 teste ogni 4 lanci (cioè meno di 1, ma ricordiamo che si tratta di una media).\n\nCalcolo della varianza:\n\n\\[\n\\text{Varianza} = n \\cdot p \\cdot (1 - p) = 4 \\cdot 0.2 \\cdot 0.8 = 0.64 .\n\\]\n\nCalcolo della deviazione standard:\n\n\\[\n\\sigma = \\sqrt{0.64} \\approx 0.8 .\n\\]\nLa deviazione standard ci dà un’idea della variabilità dei risultati: in questo caso, i valori osservati (numero di teste su 4 lanci) si discostano dalla media di circa 0.8 in media.\n\n\n36.5.4 Verifica con una simulazione in R\nPer vedere se i calcoli teorici dell’Esempio 36.5 funzionano anche nella pratica, possiamo simulare l’esperimento in R: lanciamo 4 monete, ma lo facciamo tantissime volte (ad esempio 1 milione) e calcoliamo la media e la varianza dei risultati ottenuti.\n\nset.seed(42)\n\n# Generiamo 1 milione di esperimenti: 4 lanci con probabilità di successo 0.2\nx &lt;- rbinom(n = 1e6, size = 4, prob = 0.2)\n\n# Calcoliamo la media empirica\nmean(x)\n#&gt; [1] 0.8\n# [1] circa 0.8\n\n# Calcoliamo la varianza empirica\nvar(x)\n#&gt; [1] 0.639\n# [1] circa 0.64\n\nCome possiamo vedere, i risultati ottenuti dalla simulazione sono molto vicini ai valori teorici: la media è circa \\(\\mu = 0.8\\) e la varianza circa \\(0.64\\), proprio come previsto dalle formule.\nQuesto non solo conferma che le formule per media e varianza nella distribuzione binomiale sono corrette, ma ci aiuta anche a capire meglio cosa significano:\n\nil valore atteso rappresenta la media dei risultati se ripetiamo l’esperimento moltissime volte;\n\nla varianza (e la sua radice quadrata, la deviazione standard) misura quanto i risultati si allontanano dalla media.\n\nLa simulazione mostra quindi in modo concreto che il valore atteso e la varianza descrivono il comportamento “medio” della variabile aleatoria, quando viene osservata in un numero molto grande di situazioni. In altre parole, questi concetti non sono solo teorici: ci dicono cosa aspettarci nella pratica, se ripetiamo molte volte lo stesso esperimento.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#funzioni-r-per-le-distribuzioni-di-probabilità",
    "href": "chapters/probability/13_discr_rv_distr.html#funzioni-r-per-le-distribuzioni-di-probabilità",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.6 Funzioni R per le distribuzioni di probabilità",
    "text": "36.6 Funzioni R per le distribuzioni di probabilità\nIn R, le distribuzioni di probabilità (sia discrete che continue) sono gestite in modo sistematico. Per ogni distribuzione, esistono quattro funzioni principali, ognuna con un prefisso diverso che indica il tipo di operazione desiderata:\n\n\nd*: calcola la densità (per distribuzioni continue) o la probabilità (per distribuzioni discrete);\n\n\np*: calcola la funzione di ripartizione cumulativa (CDF), cioè \\(P(Y \\leq y)\\);\n\n\nq*: calcola la funzione quantile (inversa della CDF);\n\n\nr*: genera valori casuali secondo la distribuzione specificata.\n\nQuesta struttura è identica per tutte le distribuzioni implementate in R. La tabella seguente mostra un confronto tra le funzioni disponibili per due distribuzioni fondamentali: la binomiale (discreta) e la normale (continua).\n\n\n\n\n\n\n\nTipo di funzione\nBinomiale (\\(Y \\sim \\text{Bin}(n, p)\\))\nNormale (\\(Y \\sim \\mathcal{N}(\\mu, \\sigma)\\))\n\n\n\nDensità o probabilità esatta\ndbinom(y, size = n, prob = p)\ndnorm(y, mean = mu, sd = sigma)\n\n\n\\(P(Y = y)\\)\ndbinom(...)\n❌ Non definita: per variabili continue si usa la densità\n\n\nProbabilità cumulativa\npbinom(y, size = n, prob = p)\npnorm(y, mean = mu, sd = sigma)\n\n\n\\(P(Y \\geq y)\\)\n1 - pbinom(y - 1, ...)\n1 - pnorm(y, ...)\n\n\n\\(P(y_1 &lt; Y &lt; y_2)\\)\npbinom(y2, ...) - pbinom(y1, ...)\npnorm(y2, ...) - pnorm(y1, ...)\n\n\nQuantile (inversa della CDF)\nqbinom(q, size = n, prob = p)\nqnorm(q, mean = mu, sd = sigma)\n\n\nSimulazione di dati casuali\nrbinom(n, size = trials, prob = p)\nrnorm(n, mean = mu, sd = sigma)\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nPer le distribuzioni discrete (come la binomiale), dbinom(y, ...) restituisce la probabilità esatta di osservare il valore \\(y\\): ad esempio, \\(P(Y = 2)\\).\nPer le distribuzioni continue (come la normale), dnorm(y, ...) restituisce la densità in \\(y\\), che non rappresenta direttamente una probabilità, ma è utile per visualizzare la forma della distribuzione.\nLe probabilità cumulative (funzioni p*) e i quantili (funzioni q*) sono sempre definiti, sia per distribuzioni discrete che continue.\nLa generazione di dati casuali con r* è molto utile per simulazioni e verifiche empiriche.\n\nPiù avanti, vedremo altre distribuzioni (Uniforme, Beta, Poisson, ecc.), tutte con lo stesso schema di funzioni: d, p, q, r.\nQuesta coerenza rende molto semplice imparare a usare le distribuzioni in R: una volta compreso lo schema, lo si può applicare a qualsiasi caso.\n\n\n\nEsempio 36.6  \n\nCalcolare la probabilità di esattamente \\(y = 3\\) successi su \\(n = 5\\) prove con \\(p = 0.5\\):\n\n\ndbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.312\n\n\nCalcolare la probabilità cumulativa \\(P(Y \\leq 3)\\):\n\n\npbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.812\n\n\nCalcolare il valore minimo \\(y\\) tale che \\(P(Y \\leq y) \\geq 0.9\\):\n\n\nqbinom(0.9, size = 5, prob = 0.5)\n#&gt; [1] 4\n\n\nGenerare un campione di 100 numeri casuali da una distribuzione binomiale:\n\n\nrbinom(100, size = 5, prob = 0.5)\n#&gt;   [1] 2 2 4 1 3 2 3 2 2 2 3 3 3 3 1 4 1 1 0 2 2 2 4 1 2 3 3 1 5 2 3 3 0 3 2 3 4\n#&gt;  [38] 2 3 3 3 3 1 5 3 3 2 3 1 2 1 3 3 2 2 4 1 4 2 3 1 4 2 2 3 4 1 1 4 2 3 2 3 3\n#&gt;  [75] 3 1 4 4 3 3 4 3 3 3 2 2 3 3 2 4 4 3 2 2 0 3 1 3 1 2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#distribuzione-di-poisson-1",
    "href": "chapters/probability/13_discr_rv_distr.html#distribuzione-di-poisson-1",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.7 Distribuzione di Poisson",
    "text": "36.7 Distribuzione di Poisson\nLa distribuzione di Poisson è utilizzata per modellare il numero di eventi che si verificano in un determinato intervallo di tempo o spazio, con eventi indipendenti e un tasso costante di occorrenza.\nLa funzione di massa di probabilità (PMF) è data da:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad y = 0, 1, 2, \\ldots\n\\]\ndove \\(\\lambda\\) rappresenta il tasso medio di eventi e \\(y\\) è il numero di eventi.\nLa distribuzione di Poisson può essere derivata come il limite di una distribuzione binomiale quando il numero di prove, \\(n\\), tende all’infinito e la probabilità di successo in ciascuna prova, \\(p\\), tende a zero, in modo tale che \\(np = \\lambda\\).\n\n\n\n\n\n\nDimostrazione\n\n\n\nPartiamo dalla funzione di probabilità binomiale:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} p^k (1 - p)^{n - k}.\n\\]\nImpostiamo \\(np = \\lambda\\), il che implica che \\(p = \\frac{\\lambda}{n}\\). Sostituendo \\(p\\) con \\(\\frac{\\lambda}{n}\\) nella formula binomiale, otteniamo:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} \\left(\\frac{\\lambda}{n}\\right)^k \\left(1 - \\frac{\\lambda}{n}\\right)^{n - k}.\n\\]\nOra, separiamo i termini per rendere più chiara la semplificazione. Possiamo riscrivere \\(\\left(\\frac{\\lambda}{n}\\right)^k\\) come \\(\\frac{\\lambda^k}{n^k}\\), e \\(\\left(1 - \\frac{\\lambda}{n}\\right)^{n - k}\\) come \\(\\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}\\). Quindi, l’espressione diventa:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} \\cdot \\frac{\\lambda^k}{n^k} \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}.\n\\]\nOra, separiamo ulteriormente i termini:\n\\[\np(k) = \\frac{\\lambda^k}{k!} \\cdot \\frac{n!}{(n - k)! n^k} \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}.\n\\]\nQuesto passaggio mostra come la funzione di probabilità binomiale, sotto le condizioni \\(np = \\lambda\\) e \\(n \\to \\infty\\), si trasformi gradualmente nella forma che conduce alla distribuzione di Poisson.\nQuando \\(n \\to \\infty\\):\n\\[\n\\frac{\\lambda}{n} \\to 0\n\\]\n\\[\n\\frac{n!}{(n - k)! n^k} \\to 1\n\\]\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n \\to e^{-\\lambda}\n\\]\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^{-k} \\to 1\n\\]\nSi ottiene quindi:\n\\[\np(k) \\to \\frac{\\lambda^k e^{-\\lambda}}{k!}\n\\]\nche è la funzione di Poisson.\n\n\n\n\n\n\n\n\nDimostrazione\n\n\n\nAnalizziamo il limite:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n \\to e^{-\\lambda} \\quad \\text{quando} \\quad n \\to \\infty.\n\\]\nUn limite fondamentale in analisi matematica è:\n\\[\n\\lim_{n \\to \\infty} \\left(1 + \\frac{a}{n}\\right)^n = e^a,\n\\]\ndove \\(e\\) è la base del logaritmo naturale (\\(e \\approx 2.71828\\)) e \\(a\\) è una costante. Questo limite è alla base della definizione della funzione esponenziale.\nNel nostro caso, abbiamo l’espressione:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n .\n\\]\nNotiamo che questa è molto simile al limite notevole, ma con un segno negativo. Possiamo riscriverla come:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n = \\left(1 + \\frac{-\\lambda}{n}\\right)^n.\n\\]\nApplicando il limite notevole con \\(a = -\\lambda\\), otteniamo:\n\\[\n\\lim_{n \\to \\infty} \\left(1 + \\frac{-\\lambda}{n}\\right)^n = e^{-\\lambda}.\n\\]\nQuindi, quando \\(n\\) diventa molto grande, l’espressione \\(\\left(1 - \\frac{\\lambda}{n}\\right)^n\\) si avvicina sempre di più a \\(e^{-\\lambda}\\).\n\n\n\n36.7.1 Proprietà principali\n\n\nMedia: \\(\\mathbb{E}[Y] = \\lambda\\)\n\n\nVarianza: \\(\\text{Var}(Y) = \\lambda\\)\n\n\nDi seguito, presentiamo esempi di calcolo e simulazione con R.\n\n36.7.2 Grafico della distribuzione di Poisson con \\(\\lambda = 2\\)\n\n\n# Parametro lambda\nlambda &lt;- 2\n\n# Valori di y (numero di eventi)\ny &lt;- 0:10\n\n# Calcolo delle probabilità\nprobabilities &lt;- dpois(y, lambda = lambda)\n\n# Creazione di un dataframe per ggplot\ndata &lt;- data.frame(\n  Numero_eventi = y,\n  Probabilita = probabilities\n)\n\n# Grafico della funzione di massa di probabilità \nggplot(data, aes(x = Numero_eventi, y = Probabilita)) +\n  geom_col() +  \n  labs(\n    x = \"Numero di eventi (k)\",\n    y = \"Probabilità\"\n  ) \n\n\n\n\n\n\n\n\n36.7.3 Calcolo della probabilità per un numero specifico di eventi\nPer calcolare la probabilità di osservare esattamente 3 eventi con \\(\\lambda = 2\\):\n\nprob &lt;- dpois(3, lambda = 2)\nprint(prob)\n#&gt; [1] 0.18\n\n\n36.7.4 Calcolo della probabilità cumulativa \\(P(Y \\leq 3)\\)\n\nPer calcolare \\(P(Y \\leq 3)\\), la probabilità cumulativa:\n\ncum_prob &lt;- ppois(3, lambda = 2)\nprint(cum_prob)\n#&gt; [1] 0.857\n\n\n36.7.5 Trovare il quantile corrispondente a una probabilità data\nPer trovare il numero massimo di eventi per cui la probabilità cumulativa è al massimo \\(0.8125\\):\n\nquantile &lt;- qpois(0.8125, lambda = 2)\nprint(quantile)\n#&gt; [1] 3\n\n\n36.7.6 Generazione di numeri casuali\nPer generare un campione di 1.000.000 di osservazioni da una distribuzione di Poisson con \\(\\lambda = 2\\):\n\nset.seed(42)\nsample &lt;- rpois(1000000, lambda = 2)\n\n# Calcolo di media e varianza del campione\nmean_sample &lt;- mean(sample)\nvar_sample &lt;- var(sample)\n\nprint(mean_sample)\n#&gt; [1] 2\nprint(var_sample)\n#&gt; [1] 2\n\n\nEsempio 36.7 Un esempio classico dell’uso della distribuzione di Poisson viene dalla Seconda Guerra Mondiale.\nIl contesto storico. Tra il 1944 e il 1945, Londra fu colpita da centinaia di missili V1 e V2 lanciati dalla Germania nazista. Le autorità britanniche si chiesero se i bombardamenti seguissero una strategia mirata: i missili venivano forse lanciati intenzionalmente su certi quartieri? O si trattava invece di un comportamento casuale, come se fossero stati distribuiti a caso?\nPer rispondere a questa domanda, il Ministero della Guerra britannico divise Londra in 576 aree di uguale superficie (ogni area misurava 0.25 km²) e registrò quanti missili avevano colpito ciascuna area. I dati furono poi analizzati dal matematico R. D. Clarke, che li pubblicò nel 1946.\nI dati osservati. Ecco una sintesi della distribuzione osservata:\n\n\nMissili per area\nNumero di aree\nFrequenza relativa\n\n\n\n0\n229\n0.398\n\n\n1\n211\n0.367\n\n\n2\n93\n0.161\n\n\n3\n35\n0.061\n\n\n4\n7\n0.012\n\n\n≥5\n1\n0.002\n\n\n\nIl numero medio di missili per area era \\(\\lambda \\approx 0.93\\). L’idea era confrontare queste frequenze con le probabilità teoriche previste da una distribuzione di Poisson con media \\(\\lambda = 0.93\\).\nInterpretazione con la distribuzione di Poisson. Utilizzando la funzione dpois() in R, possiamo calcolare le probabilità teoriche per ciascun valore osservato, da 0 a 4 missili per area (valori superiori sono troppo rari per essere trattati separatamente).\n\n# Parametro medio osservato\nlambda &lt;- 0.93\n\n# Valori possibili di missili per area\ny &lt;- 0:4\n\n# Probabilità teoriche secondo la distribuzione di Poisson\nprob_teoriche &lt;- dpois(y, lambda = lambda)\n\n# Aggiungiamo la probabilità per y &gt;= 5\nprob_teoriche &lt;- c(prob_teoriche, 1 - sum(prob_teoriche))  # y &gt;= 5\n\n# Visualizziamo\ndata.frame(\n  Missili_per_area = c(0:4, \"&gt;=5\"),\n  Probabilita_teorica = round(prob_teoriche, 3)\n)\n#&gt;   Missili_per_area Probabilita_teorica\n#&gt; 1                0               0.395\n#&gt; 2                1               0.367\n#&gt; 3                2               0.171\n#&gt; 4                3               0.053\n#&gt; 5                4               0.012\n#&gt; 6              &gt;=5               0.003\n\nConfrontando le probabilità teoriche della Poisson con quelle osservate nei dati reali, i risultati erano sorprendentemente simili. Questo suggeriva che i missili non erano lanciati su bersagli specifici, ma seguivano un comportamento statisticamente compatibile con una distribuzione casuale.\n\n# Frequenze osservate (dati originali di Clarke, 1946)\nfrequenze_osservate &lt;- c(229, 211, 93, 35, 7, 1)\nvalori_missili &lt;- c(0, 1, 2, 3, 4, \"≥5\")\n\n# Calcolo frequenze teoriche con Poisson (lambda = 0.93)\nlambda &lt;- 0.93\nprob_teoriche &lt;- dpois(0:4, lambda)\nprob_teoriche &lt;- c(prob_teoriche, 1 - sum(prob_teoriche))  # Per y &gt;= 5\n\n# Numero totale di aree (come somma delle osservazioni)\nn_aree &lt;- sum(frequenze_osservate)\n\n# Frequenze attese = probabilità teoriche * numero totale di aree\nfrequenze_attese &lt;- round(prob_teoriche * n_aree)\n\n# Costruzione del data frame\ndf &lt;- data.frame(\n  Missili_per_area = factor(valori_missili, levels = c(\"0\", \"1\", \"2\", \"3\", \"4\", \"≥5\")),\n  Osservate = frequenze_osservate,\n  Attese = frequenze_attese\n)\n\n# Conversione in formato lungo per ggplot2\ndf_long &lt;- reshape2::melt(df, id.vars = \"Missili_per_area\", variable.name = \"Tipo\", value.name = \"Frequenza\")\n\n# Creazione del grafico\nggplot(df_long, aes(x = Missili_per_area, y = Frequenza, fill = Tipo)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(\n    x = \"Numero di missili per area\",\n    y = \"Numero di aree\",\n    fill = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\nLe barre blu rappresentano le frequenze osservate (quante aree hanno ricevuto 0, 1, 2… missili).\nLe barre rosse mostrano le frequenze attese se i missili fossero stati lanciati in modo completamente casuale, seguendo una distribuzione di Poisson con \\(\\lambda = 0.93\\).\n\nLa sovrapposizione tra i due andamenti è molto buona, il che rafforza l’idea che i bombardamenti fossero distribuiti casualmente — senza un pattern strategico apparente.\nCosa ci insegna questo esempio?\n\nLa distribuzione di Poisson è adatta quando vogliamo modellare eventi rari e indipendenti nello spazio o nel tempo.\nI dati dei missili su Londra mostrano come un fenomeno che a prima vista potrebbe sembrare non casuale (per via della concentrazione locale degli eventi) possa invece essere ben descritto da un modello probabilistico semplice, se considerato su una scala adatta.\n\n\n\nEsempio 36.8 Supponiamo di avere osservato, nel corso degli anni, che la frequenza relativa di bocciature all’esame di Psicometria è di circa 10% (cioè \\(p = 0.1\\)). Tuttavia, il numero di studenti iscritti a ciascun appello varia in modo estremo: al primo appello dell’anno partecipano più di 200 studenti, mentre negli ultimi appelli solo 2 o 3.\nQuesto rende inadeguato l’uso della distribuzione binomiale, che richiede un numero di prove (\\(n\\)) fisso o noto per ciascun appello.\nIn questi casi, possiamo modellare il numero di bocciature per appello usando una distribuzione di Poisson.\nPer ogni appello, possiamo stimare \\(\\lambda\\) moltiplicando il numero di studenti iscritti (\\(n\\)) per la frequenza attesa di bocciature (\\(p = 0.1\\)). A quel punto, il numero di bocciature osservate può essere approssimato da:\n\\[\nY \\sim \\text{Poisson}(\\lambda = n \\cdot p) .\n\\]\nQuindi la distribuzione cambia da appello ad appello, perché \\(\\lambda\\) cambia con \\(n\\), ma il modello rimane Poissoniano.\nSupponiamo di avere osservato i seguenti dati.\n\n\n\n\n\n\n\n\nAppello\nNumero iscritti (\\(n\\))\n\\(\\lambda = n \\cdot p\\)\nDistribuzione di bocciature\n\n\n\n1\n220\n\\(220 \\cdot 0.1 = 22\\)\n\\(Y \\sim \\text{Poisson}(22)\\)\n\n\n2\n95\n\\(95 \\cdot 0.1 = 9.5\\)\n\\(Y \\sim \\text{Poisson}(9.5)\\)\n\n\n8\n3\n\\(3 \\cdot 0.1 = 0.3\\)\n\\(Y \\sim \\text{Poisson}(0.3)\\)\n\n\n\nPer ogni appello, possiamo usare la funzione dpois() in R per calcolare la probabilità di osservare un certo numero di bocciature, dato il valore di \\(\\lambda\\) specifico per quell’appello.\nAd esempio, possiamo chiederci quale sia la probabilità che, nel secondo appello (95 iscritti), si registrino esattamente 8 bocciature.\n\nlambda &lt;- 95 * 0.1  # = 9.5\ndpois(8, lambda = lambda)\n#&gt; [1] 0.123\n\nQuesta funzione calcola \\(P(Y = 8)\\) per una variabile \\(Y \\sim \\text{Poisson}(9.5)\\), cioè la probabilità di osservare esattamente 8 bocciature su 95 iscritti.\nSupponiamo di voler simulare il numero di bocciature in 8 appelli con numeri di iscritti variabili. Possiamo fare così:\n\nset.seed(42)\n\n# Numero iscritti per ciascun appello\nn_iscritti &lt;- c(220, 95, 60, 45, 20, 12, 6, 3)\n\n# Probabilità storica di bocciatura\np &lt;- 0.1\n\n# Parametri lambda per ogni appello\nlambda &lt;- n_iscritti * p\n\n# Simulazione delle bocciature per ciascun appello\nbocciature &lt;- rpois(length(lambda), lambda = lambda)\n\ndata.frame(\n  Appello = 1:8, \n  Iscritti = n_iscritti, \n  Lambda = lambda, \n  Bocciature = bocciature\n)\n#&gt;   Appello Iscritti Lambda Bocciature\n#&gt; 1       1      220   22.0         28\n#&gt; 2       2       95    9.5          8\n#&gt; 3       3       60    6.0          8\n#&gt; 4       4       45    4.5          5\n#&gt; 5       5       20    2.0          2\n#&gt; 6       6       12    1.2          2\n#&gt; 7       7        6    0.6          0\n#&gt; 8       8        3    0.3          0\n\n📈 Visualizzazione.\n\ndf &lt;- data.frame(Appello = factor(1:8), Bocciature = bocciature)\n\nggplot(df, aes(x = Appello, y = Bocciature)) +\n  geom_col() +\n  labs(\n    x = \"Appello\",\n    y = \"Numero di bocciature\"\n  )\n\n\n\n\n\n\n\nIn sintesi,\n\nquando il numero di studenti iscritti a un appello non è noto a priori o varia fortemente, non è adeguato usare la distribuzione binomiale;\nse conosciamo la frequenza relativa di bocciature (es. \\(p = 0.1\\)), possiamo usare la distribuzione di Poisson con \\(\\lambda = n \\cdot p\\), adattandola a ciascun appello;\nquesto approccio è particolarmente utile per fare stima e simulazione del numero di bocciature attese, senza dover modellare tutti i singoli esiti.\n\n\n\nEsempio 36.9 Uno degli esempi più comuni per introdurre la distribuzione di Poisson riguarda il numero di nascite giornaliere in un ospedale.\nSupponiamo che, in un grande ospedale, la media storica sia di 4.5 nascite al giorno. Possiamo allora descrivere il numero di nascite in un giorno con una variabile casuale Poisson con parametro \\(\\lambda = 4.5\\):\n\\[\nY \\sim \\text{Poisson}(\\lambda = 4.5) .\n\\]\nCi chiediamo, ad esempio: qual è la probabilità che in un giorno nascano esattamente 6 bambini?\nPossiamo calcolarla con la funzione dpois():\n\n# Parametro medio: 4.5 nascite al giorno\nlambda &lt;- 4.5\n\n# Probabilità di osservare esattamente 6 nascite\nprob &lt;- dpois(6, lambda = lambda)\nprint(prob)\n#&gt; [1] 0.128\n\nQuesto valore rappresenta la probabilità che, in un giorno qualsiasi, si verifichino esattamente 6 nascite.\nSimulazione. Simuliamo ora il numero di nascite in 365 giorni consecutivi, supponendo che la media rimanga costante a 4.5:\n\nset.seed(42)  # Per rendere i risultati riproducibili\n\nn_days &lt;- 365\nsimulated_births &lt;- rpois(n_days, lambda = lambda)\n\n# Proporzione di giorni con esattamente 6 nascite\nproportion_six_births &lt;- mean(simulated_births == 6)\nprint(proportion_six_births)\n#&gt; [1] 0.14\n\nQuesto ci dice, tra i 365 giorni simulati, quanta parte dell’anno ha avuto esattamente 6 nascite. Il valore ottenuto può essere confrontato con la probabilità teorica calcolata prima.\nVisualizzazione. Possiamo rappresentiamo graficamente i dati simulati con un istogramma:\n\n# Costruzione del data frame\ndata &lt;- data.frame(Nascite = simulated_births)\n\n# Istogramma\nggplot(data, aes(x = Nascite)) +\n  geom_histogram(\n    breaks = seq(-0.5, max(simulated_births) + 0.5, by = 1)\n  ) +\n  labs(\n    x = \"Numero di nascite per giorno\",\n    y = \"Frequenza (numero di giorni)\"\n  )\n\n\n\n\n\n\n\nL’istogramma mostra quante volte si sono verificati 0, 1, 2, …, 10 o più nascite in un giorno, evidenziando la variabilità naturale attorno alla media.\nCalcoliamo ora quanto è probabile che si verifichino più di 6 nascite in un giorno.\nProbabilità teorica:\n\nprob_more_than_six &lt;- 1 - ppois(6, lambda = lambda)\nprint(prob_more_than_six)\n#&gt; [1] 0.169\n\nProporzione osservata nella simulazione:\n\nproportion_more_than_six &lt;- mean(simulated_births &gt; 6)\nprint(proportion_more_than_six)\n#&gt; [1] 0.17\n\nIl confronto tra probabilità teorica e proporzione simulata mostra come la distribuzione di Poisson riproduca bene i fenomeni reali, quando gli eventi sono indipendenti, discreti e relativamente frequenti ma non troppo.\n\n\nEsempio 36.10 Questo esempio è tratto dal celebre lavoro di Ladislaus von Bortkiewicz del 1898, spesso citato come una delle prime applicazioni reali della distribuzione di Poisson.\nVon Bortkiewicz studiò un evento piuttosto inusuale: le morti causate da calci di cavallo all’interno della cavalleria dell’esercito prussiano. L’obiettivo era capire se questi eventi, seppur rari, potessero essere considerati casuali e indipendenti, oppure se fossero distribuiti in modo irregolare e non prevedibile.\nPer farlo, raccolse i dati su 10 squadroni osservati per 20 anni consecutivi, ottenendo così 200 unità di osservazione, che possiamo chiamare “squadroni-anno”.\nI dati raccolti. Per ogni squadrone-anno, fu registrato il numero di morti per calci di cavallo. I dati furono poi raggruppati per numero di decessi:\n\n\n\n\n\n\n\n\nNumero di decessi annui\nFrequenza osservata\nFrequenza relativa\nProbabilità teorica (Poisson)\n\n\n\n0\n109\n0.545\n0.543\n\n\n1\n65\n0.325\n0.331\n\n\n2\n22\n0.110\n0.101\n\n\n3\n3\n0.015\n0.021\n\n\n4\n1\n0.005\n0.003\n\n\n\n\n\nFrequenza osservata: Quante volte ciascun numero di decessi è stato osservato tra i 200 squadroni-anno.\n\nFrequenza relativa: Frequenza osservata divisa per 200.\n\nProbabilità teorica: Calcolata con la distribuzione di Poisson con parametro \\(\\lambda = 0.61\\), pari alla media osservata dei decessi annui.\n\nLa distribuzione di Poisson è perfetta per questo tipo di situazione perché:\n\nstiamo contando il numero di eventi rari (decessi accidentali),\nche si verificano in unità di tempo o spazio fisse (lo “squadrone-anno”),\ne presumiamo che questi eventi siano indipendenti tra loro.\n\nIn questo caso, \\(\\lambda = 0.61\\) rappresenta il numero medio di decessi per squadrone in un anno. La variabilità intorno a questo valore può essere descritta dalla distribuzione di Poisson, che assegna a ciascun possibile numero di decessi (0, 1, 2, …) una probabilità teorica.\nConfronto tra dati osservati e modello di Poisson. Come si può notare dalla tabella, le frequenze osservate sono sorprendentemente simili alle probabilità teoriche ottenute dal modello di Poisson. Ad esempio:\n\nla proporzione di squadroni-anno con zero decessi è 0.545, contro una probabilità teorica di 0.543;\nper un decesso, la frequenza relativa è 0.325, vicina alla probabilità teorica di 0.331;\nanche le classi meno frequenti (2, 3 e 4 decessi) sono coerenti con i valori attesi.\n\nQuesto esempio dimostra che la distribuzione di Poisson non solo è utile per modellare eventi rari, ma fornisce anche una buona descrizione quantitativa del comportamento osservato nel mondo reale.\nIn sintesi,\n\nil lavoro di von Bortkiewicz è uno dei primi esempi storici di modellizzazione di dati reali con la teoria delle probabilità;\nla distribuzione di Poisson si è rivelata efficace nel descrivere un fenomeno raro, ma regolare, suggerendo che i decessi fossero eventi casuali e indipendenti, non dovuti a fattori sistematici;\nancora oggi, questo esempio viene usato per insegnare che anche gli eventi accidentali e poco frequenti possono essere prevedibili in media e descritti in modo elegante da un modello probabilistico.\n\nQui di seguito viene fornito il codice R che riproduce l’analisi di von Bortkiewicz, calcola le probabilità teoriche secondo la distribuzione di Poisson con parametro \\(\\lambda = 0.61\\) e confronta visivamente le frequenze osservate con le frequenze attese.\n\n# Dati osservati da von Bortkiewicz\ndecessi &lt;- 0:4\nfrequenze_osservate &lt;- c(109, 65, 22, 3, 1)\nn_total &lt;- sum(frequenze_osservate)  # Totale = 200 squadroni-anno\n\n# Frequenze relative\nfrequenze_relative &lt;- frequenze_osservate / n_total\n\nCalcolo delle probabilità teoriche con la distribuzione di Poisson:\n\n# Parametro medio osservato\nlambda &lt;- 0.61\n\n# Calcolo delle probabilità teoriche di Poisson\nprob_poisson &lt;- dpois(decessi, lambda = lambda)\n\nConfronto: osservato vs teorico.\n\n# Frequenze attese = probabilità teoriche * numero totale di casi\nfrequenze_attese &lt;- round(prob_poisson * n_total)\n\n# Creazione del data frame per il confronto\ndf &lt;- data.frame(\n  Decessi = factor(decessi),\n  Osservato = frequenze_osservate,\n  Atteso = frequenze_attese\n)\ndf\n#&gt;   Decessi Osservato Atteso\n#&gt; 1       0       109    109\n#&gt; 2       1        65     66\n#&gt; 3       2        22     20\n#&gt; 4       3         3      4\n#&gt; 5       4         1      1\n\nVisualizzazione: confronto tra frequenze osservate e attese.\n\n# Conversione da wide a long format con pivot_longer()\ndf_long &lt;- df |&gt; \n  pivot_longer(\n    cols = c(Osservato, Atteso),\n    names_to = \"Tipo\",\n    values_to = \"Frequenza\"\n  )\n\n# Mostra le prime righe\nhead(df_long)\n#&gt; # A tibble: 6 × 3\n#&gt;   Decessi Tipo      Frequenza\n#&gt;   &lt;fct&gt;   &lt;chr&gt;         &lt;dbl&gt;\n#&gt; 1 0       Osservato       109\n#&gt; 2 0       Atteso          109\n#&gt; 3 1       Osservato        65\n#&gt; 4 1       Atteso           66\n#&gt; 5 2       Osservato        22\n#&gt; 6 2       Atteso           20\n\n\n# Grafico a barre affiancate\nggplot(df_long, aes(x = Decessi, y = Frequenza, fill = Tipo)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", color = \"black\") +\n  labs(\n    x = \"Numero di decessi per squadrone-anno\",\n    y = \"Frequenza\",\n    fill = \"Tipo\"\n  ) \n\n\n\n\n\n\n\n\nLe barre blu mostrano i dati osservati da von Bortkiewicz.\nLe barre rosse indicano le frequenze attese se il numero di decessi segue una distribuzione di Poisson con media \\(\\lambda = 0.61\\).\nLa buona corrispondenza visiva tra le due serie supporta l’idea che i decessi siano eventi rari, indipendenti e distribuiti casualmente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/probability/13_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.8 Distribuzione Beta-Binomiale",
    "text": "36.8 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilità nella probabilità di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilità per la distribuzione beta-binomiale è data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{36.5}\\]\ndove:\n\n\n\\(y\\) indica il numero di successi osservati.\n\n\\(N\\) rappresenta il numero totale di tentativi.\n\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilità nella probabilità di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, è definita tramite l’uso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL’importanza della distribuzione beta-binomiale deriva dalla sua capacità di modellare situazioni in cui la probabilità di successo non è fissa, ma segue una distribuzione di probabilità, specificatamente una distribuzione beta. Ciò la rende particolarmente adatta per applicazioni in cui le probabilità di successo cambiano in maniera incerta da un tentativo all’altro, come può avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilità di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione più realistica e flessibile per dati empirici che presentano variabilità nelle probabilità di successo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/13_discr_rv_distr.html#riflessioni-conclusive",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.9 Riflessioni Conclusive",
    "text": "36.9 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito alcune delle distribuzioni discrete più importanti, ognuna con caratteristiche uniche e campi di applicazione specifici. Abbiamo iniziato con la distribuzione di Bernoulli, che modella esperimenti con due soli esiti possibili, per poi passare alla distribuzione Binomiale, che generalizza la Bernoulli considerando un numero fisso di prove indipendenti. Successivamente, abbiamo esaminato la distribuzione di Poisson, utile per descrivere eventi rari in un intervallo di tempo o spazio, e la distribuzione Beta-Binomiale, un’estensione della Binomiale che incorpora la variabilità nella probabilità di successo, rendendola particolarmente adatta per modellare situazioni in cui tale probabilità non è fissa. Infine, abbiamo discusso la distribuzione Discreta Uniforme, che assegna la stessa probabilità a ciascun evento in un insieme finito e discreto.\nQueste distribuzioni rappresentano il fondamento dell’analisi statistica discreta e trovano applicazione in numerosi ambiti. In particolare, nel contesto dell’inferenza bayesiana, la comprensione della distribuzione Binomiale e della sua estensione Beta-Binomiale è essenziale. Queste distribuzioni, infatti, forniscono gli strumenti necessari per l’aggiornamento bayesiano, un processo chiave che permette di rivedere le nostre credenze iniziali alla luce di nuovi dati. Questo concetto sarà ulteriormente esplorato nei capitoli successivi, dove approfondiremo come le distribuzioni a priori e a posteriori interagiscono nel quadro bayesiano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#esercitazione-in-classe",
    "href": "chapters/probability/13_discr_rv_distr.html#esercitazione-in-classe",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.10 Esercitazione in Classe",
    "text": "36.10 Esercitazione in Classe\nValutate le emozioni che verranno presentate sullo schermo usando questo link.\nScala di risposta:\n\nRabbia: 1\nDisgusto: 2\nPaura: 3\nFelicità: 4\nTristezza: 5",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#esercizi",
    "href": "chapters/probability/13_discr_rv_distr.html#esercizi",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nPer ciascuna delle distribuzioni di massa di probabilità discusse, utilizzare R per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l’intervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media più una deviazione standard, calcolare la probabilità che la variabile aleatoria assuma un valore minore o uguale a questo valore.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizi sulla distribuzione binomiale, risolvibili usando R, sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/13_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [28] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [31] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [43] lattice_0.22-7        plyr_1.8.9            withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           mvtnorm_1.3-3        \n#&gt; [64] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [67] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [70] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [73] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [76] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [79] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_discr_rv_distr.html#bibliografia",
    "href": "chapters/probability/13_discr_rv_distr.html#bibliografia",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html",
    "href": "chapters/probability/14_cont_rv_distr.html",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "",
    "text": "37.1 Introduzione\nProprio come per le variabili casuali discrete, anche per le variabili casuali continue è possibile rappresentare la variabilità di una popolazione attraverso un modello statistico. Tuttavia, mentre le distribuzioni discrete si applicano a fenomeni con un numero finito o numerabile di esiti, le variabili casuali continue richiedono l’uso di funzioni di densità di probabilità (pdf), che descrivono fenomeni in cui i valori possono assumere un continuum di possibilità. Queste funzioni ci permettono di modellare e analizzare situazioni in cui i risultati non sono discreti, ma possono variare in modo continuo.\nLa funzione di densità di probabilità \\(f(x)\\) associata a una variabile casuale continua \\(X\\) rappresenta la distribuzione della probabilità all’interno della popolazione. A differenza delle distribuzioni discrete, dove la probabilità è assegnata direttamente a singoli valori, la pdf non fornisce la probabilità di un singolo punto, ma descrive la probabilità che \\(X\\) assuma valori all’interno di un intervallo specifico. Questo approccio consente di costruire un modello matematico della popolazione, utile per fare previsioni e comprendere meglio i fenomeni aleatori continui.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#la-distribuzione-uniforme-continua",
    "href": "chapters/probability/14_cont_rv_distr.html#la-distribuzione-uniforme-continua",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.2 La Distribuzione Uniforme Continua",
    "text": "37.2 La Distribuzione Uniforme Continua\nLa distribuzione uniforme continua rappresenta un pilastro della teoria delle probabilità, caratterizzata da una densità di probabilità costante su un intervallo definito. Questo modello è particolarmente utile per descrivere fenomeni casuali dove ogni esito possibile ha identica probabilità di verificarsi, come nel caso di uno spinner perfettamente bilanciato o di un generatore di numeri casuali ideale.\n\n37.2.1 Un esempio intuitivo: lo spinner\nConsideriamo uno spinner circolare con valori angolari compresi tra 0° e 360°. Se il dispositivo è perfettamente equilibrato, ogni angolo ha la stessa probabilità di essere selezionato dopo una rotazione. Questo esperimento costituisce un’implementazione concreta della distribuzione uniforme sull’intervallo \\([0, 360)\\).\n\n37.2.2 Simulazione della distribuzione: dal campione piccolo alla convergenza teorica\nPer illustrare il comportamento della distribuzione, analizziamo due scenari distinti attraverso simulazioni numeriche.\nCaso 1: Campione piccolo (n = 20)\nGeneriamo 20 valori casuali e visualizziamoli con un istogramma:\n\nset.seed(123)  # Riproducibilità dei risultati\nspinner_results &lt;- runif(20, min = 0, max = 360)\nprint(spinner_results)  # Output dei dati\n#&gt;  [1] 103.5 283.8 147.2 317.9 338.6  16.4 190.1 321.3 198.5 164.4 344.5 163.2\n#&gt; [13] 243.9 206.1  37.1 323.9  88.6  15.1 118.1 343.6\n\n# Creazione dell'istogramma\nggplot(data.frame(Valori = spinner_results), aes(x = Valori)) +\n  geom_histogram(\n    binwidth = 10, \n    fill = \"skyblue\", \n    color = \"black\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Angolo (gradi)\", \n    y = \"Frequenza relativa\"\n  ) \n\n\n\n\n\n\n\nL’istogramma mostra un andamento irregolare, riflettendo la variabilità intrinseca dei piccoli campioni. Questa disomogeneità è attesa e diminuisce all’aumentare della dimensione campionaria.\nCaso 2: Campione grande (n = 100,000)\nRipetiamo la simulazione con un campione esteso:\n\nspinner_results_large &lt;- runif(100000, min = 0, max = 360)\n\nggplot(data.frame(Valori = spinner_results_large), aes(x = Valori)) +\n  geom_histogram(\n    binwidth = 10, \n    fill = \"skyblue\", \n    color = \"black\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Angolo (gradi)\", \n    y = \"Frequenza relativa\"\n  ) \n\n\n\n\n\n\n\nL’istogramma ora rivela un profilo piatto e regolare, in accordo con la forma teorica della distribuzione. Questo risultato dimostra empiricamente la Legge dei Grandi Numeri, dove all’aumentare delle osservazioni la distribuzione empirica converge a quella teorica.\n\n37.2.3 La Funzione di Densità di Probabilità (PDF)\nPer una variabile casuale \\(X \\sim \\mathcal{U}(a, b)\\), la PDF è definita come:\n\\[\nf(x) =\n\\begin{cases}\n  \\displaystyle \\frac{1}{b - a} & \\text{se } x \\in [a, b], \\\\\n  0 & \\text{altrimenti}.\n\\end{cases}\n\\]\nProprietà chiave:\n\nl’area totale sotto la curva è unitaria: \\(\\int_{a}^{b} \\frac{1}{b - a} \\, dx = 1\\);\n\nla densità è nulla al di fuori dell’intervallo \\([a, b]\\).\n\nApplicazione allo spinner:\n\\[\nf(x) = \\frac{1}{360} \\quad \\text{per } x \\in [0, 360].\n\\]\nVisualizzazione grafica in R:\n\nx &lt;- seq(-50, 410, length.out = 500)  \ndensity_uniform &lt;- dunif(x, min = 0, max = 360)\n\nggplot(data.frame(x = x, y = density_uniform), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"blue\") +\n  geom_vline(xintercept = c(0, 360), linetype = \"dashed\", color = \"red\") +\n  labs(\n    x = \"x (gradi)\", \n    y = \"Densità f(x)\"\n  ) +\n  xlim(-50, 410) \n\n\n\n\n\n\n\nIl grafico evidenzia la densità costante nell’intervallo \\([0, 360]\\) e l’assenza di probabilità al di fuori di esso.\n\n37.2.4 Calcolo delle Probabilità: Metodo Geometrico e Funzionale\nLa probabilità che \\(X\\) assuma valori in un sottointervallo \\([c, d] \\subseteq [a, b]\\) è data da:\n\\[\nP(c \\leq X \\leq d) = \\frac{d - c}{b - a}.\n\\]\nEsempio applicativo:\nCalcoliamo la probabilità che lo spinner si fermi tra 150° e 250°:\n\\[\nP(150 \\leq X \\leq 250) = \\frac{250 - 150}{360} = \\frac{100}{360} = \\frac{5}{18} \\approx 0.2778.\n\\]\nConferma numerica in R:\n\n# Approccio manuale\nprob_manuale &lt;- (250 - 150) / 360  \n\n# Utilizzo della funzione cumulativa (CDF)\nprob_cdf &lt;- punif(250, min = 0, max = 360) - punif(150, min = 0, max = 360)  \n\nRappresentazione grafica dell’area di probabilità:\n\nggplot(data.frame(x = x, fx = density_uniform), aes(x = x, y = fx)) +\n  geom_line(linewidth = 1.2, color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, fx = density_uniform), x &gt;= 150 & x &lt;= 250),\n    aes(x = x, y = fx), \n    fill = \"gray\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"x (gradi)\", \n    y = \"Densità f(x)\"\n  ) \n\n\n\n\n\n\n\nL’area grigia corrisponde esattamente al valore di probabilità calcolato, illustrando visivamente il concetto di integrazione della PDF.\n\n37.2.5 Proprietà Fondamentali: Media e Varianza\nPer \\(X \\sim \\mathcal{U}(a, b)\\) valgono le seguenti relazioni:\n\n\nValore atteso (centro della distribuzione):\n\\[\nE(X) = \\frac{a + b}{2}.\n\\]\nEsempio: Per lo spinner, \\(E(X) = (0 + 360)/2 = 180\\) gradi.\n\n\nVarianza (misura di dispersione):\n\\[\n\\text{Var}(X) = \\frac{(b - a)^2}{12}.\n\\]\nEsempio: Per lo spinner, \\(\\text{Var}(X) = (360 - 0)^2 / 12 = 10,\\!800\\) gradi².\n\n\n37.2.6 Implementazione in R: Funzioni Principali\nR fornisce quattro funzioni per lavorare con la distribuzione uniforme:\n\n\n\n\n\n\n\nFunzione\nDescrizione\nEsempio d’uso\n\n\n\nrunif()\nGenera valori casuali\nrunif(5, min=0, max=1)\n\n\ndunif()\nCalcola la densità \\(f(x)\\)\n\ndunif(180, min=0, max=360)\n\n\npunif()\nCalcola la CDF \\(P(X \\leq x)\\)\n\npunif(250, min=0, max=360)\n\n\nqunif()\nDetermina il quantile per una probabilità\nqunif(0.9, min=0, max=360)\n\n\n\nEsempi operativi:\n\n# 1. Generazione di 5 numeri casuali in [0, 1]\nrunif(5, min = 0, max = 1)  \n#&gt; [1] 0.0372 0.9278 0.4480 0.9159 0.3558\n\n# 2. Valore della densità in x = 0.5 per U(0,1)\ndunif(0.5, min = 0, max = 1)  \n#&gt; [1] 1\n\n# 3. Probabilità cumulativa fino a x = 0.8 per U(0,1)\npunif(0.8, min = 0, max = 1)  \n#&gt; [1] 0.8\n\n# 4. Calcolo del quantile corrispondente al 50° percentile (mediana)\nqunif(0.5, min = 0, max = 360)  \n#&gt; [1] 180",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#la-distribuzione-esponenziale",
    "href": "chapters/probability/14_cont_rv_distr.html#la-distribuzione-esponenziale",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.3 La Distribuzione Esponenziale",
    "text": "37.3 La Distribuzione Esponenziale\nLa distribuzione esponenziale è una distribuzione continua fondamentale per modellare il tempo di attesa fino al verificarsi di un evento casuale. La sua caratteristica distintiva è la proprietà di assenza di memoria, che la rende unica nel panorama delle distribuzioni probabilistiche.\n\n37.3.1 La proprietà di assenza di memoria: un concetto chiave\nL’assenza di memoria implica che la probabilità che un evento si verifichi in un intervallo futuro è indipendente dal tempo già trascorso.\nEsempio intuitivo:\nimmaginiamo una persona che sperimenta attacchi di ansia improvvisi, il cui tempo tra un episodio e il successivo segue una distribuzione esponenziale. Se l’individuo non ha avuto un attacco nelle ultime 2 settimane, la probabilità che ne sperimenti uno nei prossimi 3 giorni è identica a quella di una persona appena uscita da un episodio, nel medesimo intervallo di 3 giorni.\nQuesta analogia illustra la proprietà di assenza di memoria: il “tempo trascorso dall’ultimo evento” (in questo caso, un attacco di ansia) non influenza la probabilità futura. Il sistema non “accumula stress” né riduce il rischio col passare del tempo senza episodi, riflettendo dinamiche tipiche di processi psicologici non legati a meccanismi di apprendimento o adattamento.\nParametri chiave nell’esempio:\n\n\n\\(\\lambda\\) (tasso): Frequenza media degli attacchi (es. 0.1 episodi/giorno).\n\n\\(\\mu = 1/\\lambda\\) (media): Tempo medio tra due episodi (es. 10 giorni).\n\nLa distribuzione esponenziale modellizza così situazioni in cui il comportamento è puramente stocastico e non influenzato dalla storia precedente, come certi pattern di ansia, impulsività o reazioni fisiologiche a stimoli neutri.\n\n37.3.2 Struttura matematica: PDF e parametri\nLa funzione di densità di probabilità (PDF) di una variabile \\(X \\sim \\text{Exp}(\\lambda)\\) è:\n\\[\nf(x) =\n\\begin{cases}\n\\lambda e^{-\\lambda x} & \\text{se } x \\geq 0, \\\\\n0 & \\text{altrimenti},\n\\end{cases}\n\\]\ndove:\n\n\n\\(\\lambda\\) (tasso): numero medio di eventi per unità di tempo (es. 0.25 episodi/ora).\n\n\n\\(\\mu = 1/\\lambda\\) (media): tempo medio di attesa per l’evento (es. 4 ore/episodio).\n\nForma alternativa con \\(\\mu\\):\n\\[\nf(x) = \\frac{1}{\\mu} e^{-x/\\mu} \\quad \\text{per } x \\geq 0.\n\\]\n\n37.3.3 Proprietà fondamentali\nPer \\(X \\sim \\text{Exp}(\\lambda)\\):\n\n\n\n\n\n\n\nProprietà\nFormula\nInterpretazione\n\n\n\nValore atteso (μ)\n\\(E(X) = \\frac{1}{\\lambda}\\)\nTempo medio di attesa per l’evento.\n\n\nVarianza\n\\(\\text{Var}(X) = \\frac{1}{\\lambda^2}\\)\nDispersione cresce col quadrato di 1/λ.\n\n\nDeviazione standard\n\\(\\sigma_X = \\frac{1}{\\lambda}\\)\nSpread lineare attorno alla media.\n\n\n\nEsempio applicato.\nSe il tempo medio di pubblicazione dei voti di un esame universitario è \\(\\mu = 4\\) giorni (\\(\\lambda = 0.25\\)), la PDF è:\n\\[\nf(x) = \\frac{1}{4} e^{-x/4} \\quad (x \\geq 0).\n\\]\n\n37.3.4 Visualizzazione della densità in R\n\n# Definizione dei parametri\nmu &lt;- 4\nlambda &lt;- 1 / mu  # 0.25\n\n# Generazione dei punti per il grafico\nx &lt;- seq(0, 20, by = 0.1)\npdf &lt;- dexp(x, rate = lambda)\n\n# Creazione del grafico\nggplot(data.frame(x = x, y = pdf), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"darkblue\") +\n  labs(\n    x = \"Tempo di attesa (giorni)\", \n    y = \"Densità f(x)\",\n    title = paste(\"PDF esponenziale (μ =\", mu, \"giorni)\")\n  ) \n\n\n\n\n\n\n\nIl grafico mostra un decadimento esponenziale: la probabilità decresce rapidamente all’aumentare del tempo.\n\n37.3.5 Calcolo delle Probabilità: Tre Scenari\n1. Probabilità cumulativa: \\(P(X \\leq 1.5)\\) – qual è la probabilità che il voto venga pubblicato entro un giorno e mezzo?\nUtilizziamo la funzione di ripartizione (CDF):\n\\[\nP(X \\leq 1.5) = 1 - e^{-\\lambda \\cdot 1.5} = 1 - e^{-0.25 \\cdot 1.5} \\approx 0.312.\n\\]\nCodice R:\n\npexp(1.5, rate = lambda)  # Restituisce 0.312\n#&gt; [1] 0.313\n\nVisualizzazione:\n\n# Area sotto la curva per X &lt;= 1.5\nggplot(data.frame(x = x, y = pdf), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"darkblue\") +\n  geom_area(\n    data = subset(data.frame(x, y = pdf), x &lt;= 1.5),\n    aes(x = x, y = y), \n    fill = \"gray\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Tempo (giorni)\", \n    y = \"Densità\",\n    title = \"Probabilità P(X ≤ 1.5)\"\n  )\n\n\n\n\n\n\n\n2. Probabilità intervallo: \\(P(1 \\leq X \\leq 6)\\) – qual è la probabilità che il voto venga pubblicato in un intervallo compreso tra 1 e 6 giorni dopo l’esame?\nCalcoliamo la differenza tra due CDF:\n\\[\nP(1 \\leq X \\leq 6) = F(6) - F(1) = e^{-0.25 \\cdot 1} - e^{-0.25 \\cdot 6} \\approx 0.491.\n\\]\nCodice R:\n\npexp(6, rate = lambda) - pexp(1, rate = lambda)  # 0.491\n#&gt; [1] 0.556\n\nVisualizzazione:\n\n# Area per 1 &lt;= X &lt;= 6\nggplot(data.frame(x = x, y = pdf), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"darkblue\") +\n  geom_area(\n    data = subset(data.frame(x, y = pdf), x &gt;= 1 & x &lt;= 6),\n    aes(x = x, y = y), \n    fill = \"gray\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Tempo (giorni)\", \n    y = \"Densità\",\n    title = \"Probabilità P(1 ≤ X ≤ 6)\"\n  )\n\n\n\n\n\n\n\n3. Probabilità della coda: \\(P(X \\geq 5.5)\\) – qual è la probabilità di un ritardo nella pubblicazione del voto superiore a 5.5 giorni dall’esame?\nUsiamo il complemento della CDF:\n\\[\nP(X \\geq 5.5) = 1 - P(X \\leq 5.5) = e^{-0.25 \\cdot 5.5} \\approx 0.252.\n\\]\nCodice R:\n\n1 - pexp(5.5, rate = lambda)  # 0.252\n#&gt; [1] 0.253\n# Alternativa equivalente:\npexp(5.5, rate = lambda, lower.tail = FALSE)\n#&gt; [1] 0.253\n\nVisualizzazione:\n\n# Area per X &gt;= 5.5\nggplot(data.frame(x = x, y = pdf), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"darkblue\") +\n  geom_area(\n    data = subset(data.frame(x, y = pdf), x &gt;= 5.5),\n    aes(x = x, y = y), \n    fill = \"gray\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Tempo (giorni)\", \n    y = \"Densità\",\n    title = \"Probabilità P(X ≥ 5.5)\"\n  )\n\n\n\n\n\n\n\n\n37.3.6 Simulazione e convergenza alla teoria\nGeneriamo 1,000,000 di osservazioni da \\(\\text{Exp}(\\lambda = 0.25)\\) e confrontiamo l’istogramma con la PDF teorica:\n\nset.seed(123)\nsimulated_data &lt;- rexp(1e6, rate = lambda)\n\nggplot(data.frame(x = simulated_data), aes(x = x)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 100, \n    fill = \"skyblue\", \n    color = \"black\",\n    alpha = 0.6\n  ) +\n  geom_line(\n    data = data.frame(x = x, y = pdf),\n    aes(x = x, y = y), \n    color = \"red\", \n    linewidth = 1.2\n  ) +\n  coord_cartesian(xlim = c(0, 20)) +  # Escludiamo code estreme\n  labs(\n    x = \"Tempo di attesa (giorni)\", \n    y = \"Densità\",\n    title = \"Dati simulati e PDF teorica\"\n  ) \n\n\n\n\n\n\n\nL’istogramma si allinea perfettamente alla curva rossa, dimostrando la Legge dei Grandi Numeri.\n\n37.3.7 Funzioni R per la distribuzione esponenziale\nR offre quattro funzioni essenziali:\n\n\n\n\n\n\n\n\nFunzione\nDescrizione\nEsempio d’uso\nOutput Esempio\n\n\n\ndexp()\nCalcola la densità \\(f(x)\\)\n\ndexp(2, rate = 0.25)\n0.1516\n\n\npexp()\nCalcola la CDF \\(P(X \\leq x)\\)\n\npexp(4, rate = 0.25)\n0.632 (≈1 - e⁻¹)\n\n\nqexp()\nTrova il quantile \\(x\\) per una probabilità\nqexp(0.5, rate = 0.25)\n~2.773 (mediana)\n\n\nrexp()\nGenera valori casuali\nrexp(5, rate = 0.25)\n[3.1, 0.8, 5.2, …]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#distribuzione-normale",
    "href": "chapters/probability/14_cont_rv_distr.html#distribuzione-normale",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.4 Distribuzione Normale",
    "text": "37.4 Distribuzione Normale\nLa distribuzione normale (o gaussiana) è fondamentale in statistica per modellare fenomeni naturali, sociali e psicologici. La sua importanza deriva dal Teorema del Limite Centrale, che garantisce la convergenza alla normalità per somme di variabili casuali indipendenti.\n\n37.4.1 La Famiglia delle Distribuzioni Normali\nOgni distribuzione normale è definita da due parametri:\n\n\n\\(\\mu\\) (media): centro della distribuzione;\n\n\n\\(\\sigma\\) (deviazione standard): dispersione dei dati attorno alla media.\n\nLa funzione di densità è:\n\\[\nf(y; \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(y - \\mu)^2}{2\\sigma^2}}.\n\\tag{37.1}\\]\n\n37.4.2 Distribuzione Normale Standardizzata\nLa normale standardizzata è un caso speciale con \\(\\mu = 0\\) e \\(\\sigma = 1\\). Qualsiasi variabile \\(Y \\sim \\mathcal{N}(\\mu, \\sigma)\\) può essere standardizzata tramite:\n\\[\nZ = \\frac{Y - \\mu}{\\sigma}.\n\\tag{37.2}\\]\nQuesta trasformazione preserva la forma della distribuzione ma riporta i valori in unità di deviazione standard (Z-score), permettendo confronti universali.\n\n37.4.2.1 Relazione tra Deviazione Standard e Distribuzione\nLa regola empirica 68-95-99.7 vale per tutte le distribuzioni normali, indipendentemente da \\(\\mu\\) e \\(\\sigma\\):\n\n\n68.3% dei dati cade entro \\(\\pm 1\\sigma\\) dalla media;\n\n\n95.4% entro \\(\\pm 2\\sigma\\);\n\n\n99.7% entro \\(\\pm 3\\sigma\\).\n\nPer intervalli specifici legati a test statistici:\n\n\n\\(\\pm 1.96\\sigma\\) copre il 95% dei dati (intervallo di confidenza al 95%);\n\n\\(\\pm 2.576\\sigma\\) copre il 99% (intervallo al 99%).\n\n37.4.3 Origini storiche e connessione alla binomiale\nAbraham de Moivre osservò che distribuzioni binomiali con \\(n\\) elevato approssimano una normale. Ad esempio:\n\ncon \\(n=10\\) e \\(p=0.9\\), la distribuzione è asimmetrica;\ncon \\(n=1000\\), la forma diventa simmetrica e campanulare.\n\n37.4.4 Simulazione di Passeggiate Casuali\nLa distribuzione normale emerge naturalmente come risultato della somma di un gran numero di effetti casuali indipendenti, un principio formalizzato dal Teorema del Limite Centrale. Questo la rende ideale per modellare:\n\n\nerrori di misurazione, dove piccole fluttuazioni casuali (strumentali, ambientali, umane) si combinano;\n\n\nfenomeni biologici multifattoriali come altezza, peso o QI, influenzati da decine di fattori genetici, ambientali e nutrizionali che interagiscono in modo additivo;\n\n\nprocessi sociali come i punteggi dei test, dove il risultato finale è il prodotto cumulativo di abilità innate, studio, stato emotivo e altro.\n\nSimulazione con passeggiate casuali\nPer visualizzare concretamente questo fenomeno, consideriamo una passeggiata casuale unidimensionale semplificata:\n\n\nImpostazione:\n\n1,000 partecipanti partono dalla posizione 0;\n\nogni partecipante compie 16 passi consecutivi;\n\nogni passo è determinato da un generatore casuale che assegna uno spostamento compreso tra -1 e +1 unità (simulando l’effetto di piccole perturbazioni indipendenti).\n\n\n\nDinamica:\nla posizione finale di ciascun partecipante è la somma algebrica degli spostamenti casuali. Nonostante ogni passo individuale segua una distribuzione uniforme, la posizione finale aggregata di tutti i partecipanti mostrerà una distribuzione a campana tipica della normale.\n\n\n# Parametri\nnumero_passi &lt;- 16\nripetizioni &lt;- 1000\n\n# Generazione di passeggiate casuali\nset.seed(123)\nx &lt;- matrix(0, nrow = numero_passi + 1, ncol = ripetizioni)\n\nfor (i in 1:ripetizioni) {\n  passi &lt;- runif(numero_passi, min = -1, max = 1)\n  x[-1, i] &lt;- cumsum(passi)\n}\n\n# Grafico delle passeggiate casuali\ndf &lt;- data.frame(\n  Passo = rep(0:numero_passi, times = ripetizioni), \n  Distanza = as.vector(x)\n)\n\nggplot(\n  df, \n  aes(\n    x = Passo, \n    y = Distanza, \n    group = rep(1:ripetizioni, each = numero_passi + 1))\n  ) +\n  geom_line(color = \"blue\", alpha = 0.05) +\n  labs(\n    title = \"Passeggiate Casuali\", \n    x = \"Numero di Passi\", y = \"Distanza dall'Origine\"\n  )\n\n\n\n\n\n\n\n\n# Codice di simulazione (esempio concettuale)  \nset.seed(123)  \nn_partecipanti &lt;- 1000  \nn_passi &lt;- 16  \n\n# Genera spostamenti casuali (-1 a +1)  \nspostamenti &lt;- matrix(runif(n_partecipanti * n_passi, min = -1, max = 1), ncol = n_passi)  \n\n# Calcola le posizioni finali  \nposizioni_finali &lt;- rowSums(spostamenti)  \n\n# Visualizzazione  \nggplot(data.frame(Posizione = posizioni_finali), aes(x = Posizione)) +  \n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"lightblue\", alpha = 0.7) +  \n  stat_function(fun = dnorm, args = list(mean = mean(posizioni_finali), sd = sd(posizioni_finali)), color = \"red\", linewidth = 1) +  \n  labs(title = \"Distribuzione delle posizioni finali\", x = \"Posizione\", y = \"Densità\")  \n\n\n\n\n\n\n\nRisultato atteso:\nl’istogramma delle posizioni finali aderirà alla curva rossa (normale teorica), dimostrando come la combinazione di piccole variazioni casuali produca una distribuzione gaussiana, anche partendo da passi non-normali. Questo esperimento illustra l’onnipresenza della normale in contesti reali governati da molteplici fattori indipendenti.\nPerché 16 passi?\nLa scelta di 16 passi non è arbitraria:\n\nun numero ridotto di passi (es. 3-5) produrrebbe una distribuzione ancora vicina all’uniforme;\ncon 16 passi, la simmetria e la curvatura tipica della gaussiana diventano chiaramente riconoscibili senza richiedere simulazioni massicce.\n\n37.4.5 Proprietà fondamentali\n\n\nMedia: \\(\\mathbb{E}(Y) = \\mu\\);\n\n\nVarianza: \\(\\mathbb{V}(Y) = \\sigma^2\\).\n\n37.4.6 Funzioni R per la Normale\n\n\n\n\n\n\n\nFunzione\nDescrizione\nEsempio\n\n\n\ndnorm()\nDensità a un punto \\(y\\)\n\ndnorm(115, mean=100, sd=15)\n\n\npnorm()\nProbabilità cumulativa \\(P(Y \\leq y)\\)\n\npnorm(115, mean=100, sd=15)\n\n\nqnorm()\nQuantile per una probabilità \\(p\\)\n\nqnorm(0.975, mean=100, sd=15)\n\n\nrnorm()\nGenera valori casuali\nrnorm(10, mean=100, sd=15)\n\n\n\n37.4.7 Visualizzazione delle aree critiche\nLe aree sotto la curva corrispondenti a \\(\\pm 1\\sigma\\), \\(\\pm 1.96\\sigma\\), e \\(\\pm 3\\sigma\\) possono essere visualizzate in R:\n\n# Esempio per ±1.96σ (95% di confidenza)  \nmu &lt;- 100  \nsigma &lt;- 15  \nx &lt;- seq(mu - 4*sigma, mu + 4*sigma, length.out=1000)  \ndf &lt;- data.frame(x=x, pdf=dnorm(x, mu, sigma))  \n\nggplot(df, aes(x=x, y=pdf)) +  \n  geom_line(color=\"blue\") +  \n  geom_area(data=subset(df, x &gt;= mu - 1.96*sigma & x &lt;= mu + 1.96*sigma),  \n            fill=\"gray\", alpha=0.5) +  \n  labs(title=\"95% dei dati entro ±1.96σ\", x=\"Valori\", y=\"Densità\")  \n\n\n\n\n\n\n\nIn sintesi, la distribuzione normale standardizzata permette di standardizzare qualsiasi fenomeno Gaussiano, rendendo confrontabili dati eterogenei. La relazione tra deviazioni standard e aree sottese è universale: indipendentemente dalla media e varianza originale, il 68-95-99.7% dei dati cadrà sempre entro 1-2-3σ.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nUna psicologa vuole studiare i livelli di ansia tra gli studenti universitari durante la settimana degli esami. Dalle ricerche precedenti si sa che nella popolazione universitaria:\n\nil punteggio medio di ansia è di 50 punti su una scala da 0 a 100;\nla deviazione standard dei punteggi di ansia è 10 punti.\n\nLa psicologa decide di estrarre un campione casuale di 25 studenti.\nVogliamo usare la distribuzione campionaria della media per rispondere a due domande:\n\nQual è la probabilità di ottenere una media campionaria maggiore di 54 punti?\nQuale media campionaria rappresenta il 95° percentile della distribuzione campionaria?\n\n📘 Concetti chiave.\nLa distribuzione campionaria della media ha:\n\nla stessa media della popolazione (\\(\\mu\\)),\nuna deviazione standard più piccola, detta errore standard della media (SE):\n\n\\[\nSE = \\frac{\\sigma}{\\sqrt{n}} = \\frac{10}{\\sqrt{25}} = 2 .\n\\]\nUseremo due funzioni importanti in R:\n\n\ndnorm(x, mean, sd): calcola la densità della normale in un punto \\(x\\).\n\nqnorm(p, mean, sd): calcola il valore di \\(x\\) corrispondente a una certa probabilità cumulativa \\(p\\).\n\n✅ Codice base.\n\n# Parametri della popolazione e del campione\nmu &lt;- 50       # media della popolazione\nsigma &lt;- 10    # deviazione standard\nn &lt;- 25        # dimensione campione\n\n# Errore standard della media\nSE &lt;- sigma / sqrt(n)\nSE\n#&gt; [1] 2\n\n🔍 Domanda 1: Probabilità di ottenere una media &gt; 54.\n\n# Probabilità che la media campionaria sia maggiore di 54\np_oltre_54 &lt;- pnorm(54, mean = mu, sd = SE, lower.tail = FALSE)\np_oltre_54\n#&gt; [1] 0.0228\n\nLa probabilità è molto bassa. Questo vuol dire che, se la vera media della popolazione fosse 50, ottenere una media campionaria superiore a 54 sarebbe raro.\n🔍 Domanda 2: Media al 95° percentile.\n\n# Calcolo del valore soglia al 95° percentile\nq_95 &lt;- qnorm(0.95, mean = mu, sd = SE)\nq_95\n#&gt; [1] 53.3\n\nAll’interno della distribuzione campionaria, solo il 5% dei campioni ha una media superiore a questo valore.\n📊 Grafico 1: Probabilità di media &gt; 54\n\n# Dati per la distribuzione normale\nx_vals &lt;- seq(44, 56, length.out = 300)\ndens_vals &lt;- dnorm(x_vals, mean = mu, sd = SE)\ndf &lt;- data.frame(x = x_vals, y = dens_vals)\n\n# Grafico\nggplot(df, aes(x, y)) +\n  geom_line(color = \"black\") +\n  geom_area(data = subset(df, x &gt;= 54), aes(x, y), fill = \"red\", alpha = 0.4) +\n  geom_vline(xintercept = 54, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Distribuzione campionaria della media (n = 25)\",\n    subtitle = \"Area rossa = P(media &gt; 54)\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n📊 Grafico 2: Valore al 95° percentile\n\n# Grafico con il 95° percentile evidenziato\nggplot(df, aes(x, y)) +\n  geom_line(color = \"black\") +\n  geom_area(data = subset(df, x &lt;= q_95), aes(x, y), fill = \"blue\", alpha = 0.4) +\n  geom_vline(xintercept = q_95, color = \"blue\", linetype = \"dashed\") +\n  labs(\n    title = \"Distribuzione campionaria della media (n = 25)\",\n    subtitle = \"Area blu = 95% dei campioni (valore critico ≈ 53.29)\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\nDomande di approfondimento.\n\nPerché l’errore standard della media è più piccolo della deviazione standard della popolazione?\nSe la dimensione del campione aumentasse a 100, come cambierebbe l’errore standard?\nChe cosa rappresenta pnorm(54, ...) nel nostro contesto?\nIn quali casi, in psicologia, potresti voler calcolare il 95° percentile di una distribuzione campionaria?\n\nSimulazione Monte Carlo.\nSimuliamo 10.000 campioni casuali, ciascuno di 25 studenti, estratti da una popolazione normale con media = 50 e deviazione standard = 10. Per ogni campione calcoliamo la media. Alla fine, visualizziamo la distribuzione di queste medie.\n\nset.seed(123)  # per rendere la simulazione replicabile\n\n# Parametri\nmu &lt;- 50\nsigma &lt;- 10\nn &lt;- 25\nn_sim &lt;- 10000  # numero di campioni\n\n# Simulazione: 10.000 medie campionarie\ncampioni &lt;- replicate(n_sim, mean(rnorm(n, mean = mu, sd = sigma)))\n\n# Visualizza le prime 5 medie\nhead(campioni)\n#&gt; [1] 49.7 51.0 50.1 52.8 47.2 47.7\n\n📊 Istogramma delle medie campionarie.\n\n\ndf_sim &lt;- data.frame(media_campionaria = campioni)\n\nggplot(df_sim, aes(x = media_campionaria)) +\n  geom_histogram(aes(y = ..density..), bins = 40, fill = \"lightblue\", color = \"black\") +\n  stat_function(fun = dnorm, args = list(mean = mu, sd = sigma / sqrt(n)),\n                color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione delle medie campionarie\",\n    subtitle = \"Istogramma di 10.000 medie di campioni di 25 studenti\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\nCosa si osserva?\n\nLe medie non sono tutte uguali, ma si distribuiscono intorno alla media vera (50).\nLa forma della distribuzione delle medie è normale, anche se i dati originali non devono necessariamente esserlo (grazie al Teorema del Limite Centrale).\nLa deviazione standard della distribuzione simulata è vicina all’errore standard teorico:\n\n\n# Confronto tra errore standard teorico e osservato\nSE_teorico &lt;- sigma / sqrt(n)\nSE_osservato &lt;- sd(campioni)\n\nc(SE_teorico = SE_teorico, SE_osservato = SE_osservato)\n#&gt;   SE_teorico SE_osservato \n#&gt;         2.00         1.97\n\nDomande di approfondimento.\n\nPerché la forma dell’istogramma è simile a una curva normale?\nCosa succederebbe alla larghezza della distribuzione se aumentassimo la dimensione del campione?\nSe la media osservata in un esperimento reale fosse fuori dalla zona centrale, come potremmo interpretarla?\n\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo un esercizio in cui si utilizza la distribuzione normale e si consultano le tavole della normale standard (z) per risolvere il problema dopo la standardizzazione.\nIn uno studio su un campione di 600 studenti universitari, i punteggi ottenuti a un test di ansia da esame seguono una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\n\nQual è la probabilità che uno studente scelto a caso ottenga un punteggio inferiore a 65?\nQual è la percentuale di studenti che ottengono un punteggio compreso tra 45 e 60?\nQual è il punteggio minimo che uno studente deve ottenere per rientrare nel 10% superiore della distribuzione?\n\n1. Probabilità che \\(X &lt; 65\\).\nStandardizziamo:\n\\[\nZ = \\frac{X - \\mu}{\\sigma} = \\frac{65 - 50}{10} = \\frac{15}{10} = 1.5 .\n\\]\nCerchiamo \\(P(Z &lt; 1.5)\\) nella tavola della normale standard:\n\\[\nP(Z &lt; 1.5) \\approx 0.9332 .\n\\]\nRisposta: La probabilità che uno studente ottenga meno di 65 è circa 93.32%.\n2. Probabilità che \\(45 &lt; X &lt; 60\\).\nCalcoliamo gli z-score:\n\\[\nZ_1 = \\frac{45 - 50}{10} = -0.5 \\quad ; \\quad Z_2 = \\frac{60 - 50}{10} = 1.0 .\n\\]\nCerchiamo nelle tavole:\n\n\\(P(Z &lt; 1.0) \\approx 0.8413\\)\n\\(P(Z &lt; -0.5) \\approx 0.3085\\)\n\nQuindi:\n\\[\nP(45 &lt; X &lt; 60) = P(Z &lt; 1.0) - P(Z &lt; -0.5) = 0.8413 - 0.3085 = 0.5328\n\\]\nRisposta: Circa il 53.28% degli studenti ha un punteggio tra 45 e 60.\n3. Punteggio minimo per rientrare nel 10% superiore.\nIl 10% superiore corrisponde a:\n\\[\nP(Z &gt; z) = 0.10 \\Rightarrow P(Z &lt; z) = 0.90 .\n\\]\nDalla tavola:\\(P(Z &lt; 1.28) \\approx 0.8997\\),\\(P(Z &lt; 1.29) \\approx 0.9015\\)\nPrendiamo \\(z = 1.28\\)\nOra risolviamo per \\(X\\):\n\\[\nX = z \\cdot \\sigma + \\mu = 1.28 \\cdot 10 + 50 = 62.8\n\\]\nRisposta: Il punteggio minimo per rientrare nel 10% superiore è circa 62.8.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "chapters/probability/14_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.5 Distribuzione Chi-Quadrato",
    "text": "37.5 Distribuzione Chi-Quadrato\nLa distribuzione \\(\\chi^2\\) deriva dalla distribuzione normale e descrive la somma dei quadrati di \\(k\\) variabili casuali indipendenti e identicamente distribuite (i.i.d.) che seguono la distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Una variabile casuale \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libertà è definita come:\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\tag{37.3}\\]\ndove \\(Z_1, Z_2, \\dots, Z_k \\sim \\mathcal{N}(0, 1)\\). Il parametro \\(k\\), detto gradi di libertà (\\(\\nu\\)), determina la forma della distribuzione.\n\n37.5.1 Funzione di densità\nLa densità di probabilità della distribuzione \\(\\chi^2_{~\\nu}\\) è data da:\n\\[\nf(x) = C_{\\nu} x^{\\nu/2 - 1} \\exp(-x/2), \\quad \\text{per } x &gt; 0,\n\\tag{37.4}\\]\ndove \\(C_{\\nu}\\) è una costante di normalizzazione.\n\n37.5.2 Simulazione della Distribuzione Chi-Quadrato\nUtilizziamo la definizione per simulare la distribuzione \\(\\chi^2\\) con 3 gradi di libertà.\n\n# Impostare il seed per la riproducibilità\nset.seed(1234)\n\n# Generare 1000 valori casuali per 3 variabili gaussiane standard\nn &lt;- 1000\nvar1 &lt;- rnorm(n, mean = 0, sd = 1)\nvar2 &lt;- rnorm(n, mean = 0, sd = 1)\nvar3 &lt;- rnorm(n, mean = 0, sd = 1)\n\n# Calcolare la somma dei quadrati\nchi_sq_values &lt;- var1^2 + var2^2 + var3^2\n\n# Creare un dataframe per il grafico\ndata &lt;- data.frame(chi_sq_values = chi_sq_values)\n\n# Istogramma e densità teorica\nggplot(data, aes(x = chi_sq_values)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7\n    ) +\n  stat_function(fun = dchisq, args = list(df = 3), color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione Chi-Quadrato (df = 3)\",\n    x = \"Valore\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\nL’istogramma rappresenta i valori empirici simulati;\nla curva rossa rappresenta la densità teorica della distribuzione \\(\\chi^2_{~3}\\).\n\n37.5.3 Media e Varianza Empiriche\nCalcoliamo la media e la varianza dei valori simulati:\n\n# Media empirica\nmean(chi_sq_values)\n#&gt; [1] 2.98\n\n# Varianza empirica\nvar(chi_sq_values)\n#&gt; [1] 5.97\n\nQuesti valori possono essere confrontati con le proprietà teoriche della distribuzione \\(\\chi^2\\):\n\n\nmedia: \\(\\nu = 3\\);\n\nvarianza: \\(2\\nu = 6\\).\n\n37.5.4 Grafico per Diversi Gradi di Libertà\nConfrontiamo le distribuzioni \\(\\chi^2\\) per diversi valori di \\(\\nu\\).\n\n# Intervallo di x\nx &lt;- seq(0, 40, by = 0.1)\n\n# Gradi di libertà\nnus &lt;- c(2, 4, 8, 16)\n\n# Creare un dataframe\ndata &lt;- do.call(rbind, lapply(nus, function(nu) {\n  data.frame(x = x, f_x = dchisq(x, df = nu), nu = as.factor(nu))\n}))\n\n# Grafico\nggplot(data, aes(x = x, y = f_x, color = nu)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    color = expression(nu)\n  ) \n\n\n\n\n\n\n\n\n37.5.5 Proprietà della Distribuzione Chi-Quadrato\n\n\nAsimmetria: La distribuzione \\(\\chi^2_{\\nu}\\) è asimmetrica, ma diventa più simmetrica al crescere di \\(\\nu\\).\n\nMedia: \\(\\mathbb{E}[\\chi^2_{\\nu}] = \\nu\\).\n\nVarianza: \\(\\mathbb{V}[\\chi^2_{\\nu}] = 2\\nu\\).\n\nConvergenza: Per \\(\\nu \\to \\infty\\), \\(\\chi^2_{\\nu} \\to \\mathcal{N}(\\nu, 2\\nu)\\).\n\nSomma: La somma di variabili \\(\\chi^2\\) indipendenti con gradi di libertà \\(\\nu_1, \\nu_2, \\dots, \\nu_k\\) segue una distribuzione \\(\\chi^2\\) con \\(\\nu = \\sum_{i=1}^k \\nu_i\\).\n\n37.5.6 Applicazioni\nLa distribuzione \\(\\chi^2\\) è utilizzata in molteplici ambiti statistici, tra cui:\n\n\ntest di indipendenza: per verificare se due variabili categoriche sono indipendenti;\n\ntest di adattamento: per confrontare una distribuzione empirica con una teorica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "chapters/probability/14_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.6 Distribuzione \\(t\\) di Student",
    "text": "37.6 Distribuzione \\(t\\) di Student\nLa distribuzione \\(t\\) di Student è una delle distribuzioni fondamentali della statistica inferenziale. Deriva dalle distribuzioni Normale e Chi-quadrato ed è particolarmente utile per analizzare campioni di piccole dimensioni o situazioni in cui la varianza della popolazione è sconosciuta.\n\n37.6.1 Definizione Formale\nSe:\n\n\n\\(Z \\sim \\mathcal{N}(0, 1)\\) (distribuzione Normale standard),\n\n\\(W \\sim \\chi^2_{\\nu}\\) (distribuzione Chi-quadrato con \\(\\nu\\) gradi di libertà),\n\ne \\(Z\\) e \\(W\\) sono indipendenti, allora la variabile casuale\n\\[\nT = \\frac{Z}{\\sqrt{\\frac{W}{\\nu}}}\n\\tag{37.5}\\]\nsegue una distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libertà. Si indica come \\(T \\sim t_{\\nu}\\).\n\n37.6.2 Proprietà della Distribuzione \\(t\\) di Student\n\n\nForma della distribuzione:\n\nla distribuzione \\(t\\) è simmetrica rispetto a zero, come la Normale standard (\\(\\mathcal{N}(0, 1)\\));\npresenta code più pesanti rispetto alla Normale, riflettendo una maggiore probabilità di osservare valori estremi.\n\n\n\nCode pesanti e gradi di libertà:\n\nla pesantezza delle code diminuisce con l’aumentare dei gradi di libertà (\\(\\nu\\));\nper \\(\\nu \\to \\infty\\), la distribuzione \\(t\\) converge alla distribuzione Normale standard.\n\n\n\nMedia e varianza:\n\nla media è \\(0\\) per \\(\\nu &gt; 1\\);\n\nla varianza è:\n\\[\n\\text{Var}(T) = \\frac{\\nu}{\\nu - 2}, \\quad \\text{per } \\nu &gt; 2.\n\\]\nPer \\(\\nu \\leq 2\\), la varianza non è definita.\n\n\n\n\nApplicazioni principali:\n\n\ntest t di Student: Confronto delle medie di due gruppi o test per una singola media;\n\nintervalli di confidenza: Stima dell’intervallo per la media quando la varianza è sconosciuta.\n\n\n\n37.6.3 Differenze tra la Distribuzione \\(t\\) e la Normale\n\n\n\n\n\n\n\nCaratteristica\nDistribuzione Normale\nDistribuzione \\(t\\) di Student\n\n\n\nForma\nSimmetrica, a campana\nSimmetrica, a campana\n\n\nCode\nSottili\nPesanti\n\n\nDipendenza dai gradi di libertà\nNo\nSì\n\n\nConvergenza\nNon varia\nCon \\(\\nu \\to \\infty\\), converge alla Normale\n\n\n\n37.6.4 Visualizzazione della Distribuzione \\(t\\)\n\nConfrontiamo graficamente la distribuzione \\(t\\) con diversi gradi di libertà e la distribuzione Normale standard:\n\n# Creazione dei dati\nx &lt;- seq(-4, 4, length.out = 1000)\ndf &lt;- c(1, 2, 5, 10)  # Gradi di libertà\n\n# Dataframe con curve di densità\ndata &lt;- data.frame(\n  x = rep(x, length(df) + 1),\n  density = c(\n    dnorm(x),\n    dt(x, df[1]),\n    dt(x, df[2]),\n    dt(x, df[3]),\n    dt(x, df[4])\n  ),\n  distribution = rep(c(\"Normale\", paste(\"t (df =\", df, \")\")), each = length(x))\n)\n\n# Plot\nggplot(data, aes(x = x, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"Valore\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) \n\n\n\n\n\n\n\n\n37.6.5 Simulazione della Distribuzione \\(t\\)\n\nSimuliamo una distribuzione \\(t\\) con 10 gradi di libertà e confrontiamola con la densità teorica.\n\n# Impostare il seed per la riproducibilità\nset.seed(123)\n\n# Simulare 1000 valori da una distribuzione t\nn &lt;- 1000\ndf &lt;- 10  # Gradi di libertà\nt_values &lt;- rt(n, df = df)\n\n# Creare un dataframe per il grafico\ndata &lt;- data.frame(t_values = t_values)\n\n# Istogramma con densità teorica\nggplot(data, aes(x = t_values)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7\n  ) +\n  stat_function(fun = dt, args = list(df = df), color = \"red\", size = 1) +\n  labs(\n    x = \"Valore\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n37.6.6 Proprietà Teoriche della Distribuzione \\(t\\)\n\n\nMedia: \\[\n\\mathbb{E}[T] = 0, \\quad \\text{per } \\nu &gt; 1.\n\\]\nVarianza: \\[\n\\mathbb{V}[T] = \\frac{\\nu}{\\nu - 2}, \\quad \\text{per } \\nu &gt; 2.\n\\]\n\nSimmetria:\n\nla distribuzione è simmetrica rispetto a zero, come la Normale.\n\n\n\nCode:\n\nle code sono più pesanti rispetto alla Normale, riflettendo una maggiore incertezza per piccoli campioni.\n\n\n\nIn conclusione, la distribuzione \\(t\\) di Student è uno strumento versatile nell’inferenza statistica, trovando applicazione in contesti sia frequentisti che bayesiani. È particolarmente utile in situazioni in cui la conoscenza della varianza è limitata o i campioni sono di dimensioni ridotte. Grazie alla sua forma simmetrica e alle code più pesanti rispetto alla distribuzione Normale, la distribuzione \\(t\\) può modellare meglio l’incertezza, includendo una maggiore probabilità per valori estremi.\nNel contesto bayesiano, la distribuzione \\(t\\) viene utilizzata come:\n\n\nprior informativo robusto, per modellare parametri con valori plausibili lontani dalla media ma con una penalizzazione graduale per valori estremi.\n\ndistribuzione predittiva per sintetizzare l’incertezza derivante da campioni piccoli o con variabilità elevata.\n\nIn entrambi i paradigmi, la distribuzione \\(t\\) rappresenta una scelta robusta, capace di riflettere in modo flessibile la natura dei dati. Inoltre, per valori elevati dei gradi di libertà, la distribuzione \\(t\\) converge alla distribuzione Normale, un caso limite che ne estende ulteriormente l’utilità in vari contesti analitici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "chapters/probability/14_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.7 Funzione Beta di Eulero",
    "text": "37.7 Funzione Beta di Eulero\nLa funzione Beta di Eulero è una funzione matematica, non una densità di probabilità, ma è strettamente collegata alla distribuzione Beta, poiché appare nella sua definizione. Indicata comunemente con il simbolo \\(\\mathcal{B}(\\alpha, \\beta)\\), la funzione Beta può essere espressa in vari modi. Per i nostri scopi, utilizziamo la seguente definizione:\n\\[\n\\mathcal{B}(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\tag{37.6}\\]\ndove \\(\\Gamma(x)\\) rappresenta la funzione Gamma, una generalizzazione del fattoriale definita per numeri reali positivi. Quando \\(x\\) è un numero intero, la funzione Gamma si riduce al fattoriale traslato:\n\\[\n\\Gamma(x) = (x-1)!.\n\\]\n\nEsempio 37.1 Supponiamo di voler calcolare \\(\\mathcal{B}(3, 9)\\). Utilizzando la definizione, abbiamo:\n\\[\n\\mathcal{B}(3, 9) = \\frac{\\Gamma(3) \\cdot \\Gamma(9)}{\\Gamma(3 + 9)}.\n\\]\nIn R, possiamo calcolarla in tre modi diversi.\n\nUtilizzando la definizione con la funzione gamma():\n\n\nalpha &lt;- 3\nbeta &lt;- 9\n\nbeta_function &lt;- gamma(alpha) * gamma(beta) / gamma(alpha + beta)\nbeta_function\n#&gt; [1] 0.00202\n\n\nUtilizzando direttamente la funzione beta() di R:\n\n\nbeta(alpha, beta)\n#&gt; [1] 0.00202\n\n\nCalcolo manuale con fattoriali:\n\n\n(factorial(alpha - 1) * factorial(beta - 1)) / factorial(alpha + beta - 1)\n#&gt; [1] 0.00202\n\nTutti e tre i metodi restituiscono lo stesso risultato, confermando la correttezza della definizione.\n\nLa funzione Beta è utilizzata nella definizione della densità di probabilità Beta. Essa serve a normalizzare la densità, garantendo che l’area sotto la curva sia pari a \\(1\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#distribuzione-beta",
    "href": "chapters/probability/14_cont_rv_distr.html#distribuzione-beta",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.8 Distribuzione Beta",
    "text": "37.8 Distribuzione Beta\nLa distribuzione Beta, indicata come \\(\\mathcal{Beta}(\\alpha, \\beta)\\), è una distribuzione di probabilità continua definita sull’intervallo \\((0, 1)\\). È particolarmente utile per modellare proporzioni, probabilità, o in generale qualsiasi fenomeno che assume valori compresi tra 0 e 1.\nQuesta distribuzione è molto flessibile: a seconda dei valori dei parametri \\(\\alpha\\) e \\(\\beta\\), può assumere forme simmetriche, asimmetriche, concave, convesse, ecc. È frequentemente utilizzata come distribuzione a priori nei modelli bayesiani per parametri che rappresentano probabilità.\n\n37.8.1 Definizione\n\nDefinizione 37.1 Sia \\(\\theta\\) una variabile casuale continua. Se \\(\\theta\\) segue una distribuzione Beta con parametri \\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\), scriviamo:\n\\[\n\\theta \\sim \\mathcal{Beta}(\\alpha, \\beta),\n\\]\ne la sua funzione di densità di probabilità (pdf) è data da:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{\\mathcal{B}(\\alpha, \\beta)} \\, \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{per } \\theta \\in (0, 1),\n\\tag{37.7}\\]\ndove \\(\\mathcal{B}(\\alpha, \\beta)\\) è la funzione Beta (o funzione beta di Eulero).\n\n\n37.8.2 Rappresentazione alternativa\nUn’espressione equivalente della densità, che mette in evidenza il legame con la funzione Gamma, è:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\, \\Gamma(\\beta)} \\, \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{per } \\theta \\in (0, 1),\n\\tag{37.8}\\]\ndove \\(\\Gamma(\\cdot)\\) è la funzione Gamma, che generalizza il fattoriale: \\(\\Gamma(n) = (n - 1)!\\) per ogni intero positivo \\(n\\).\n\n37.8.3 Ruolo dei Parametri \\(\\alpha\\) e \\(\\beta\\)\n\nI parametri \\(\\alpha\\) e \\(\\beta\\) determinano la forma della distribuzione:\n\n\n\\(\\alpha &gt; 1\\): favorisce valori di \\(\\theta\\) vicini a 1.\n\n\\(\\beta &gt; 1\\): favorisce valori di \\(\\theta\\) vicini a 0.\n\n\\(\\alpha = \\beta = 1\\): corrisponde alla distribuzione uniforme sull’intervallo \\([0, 1]\\).\n\n\\(\\alpha, \\beta &lt; 1\\): la distribuzione è bimodale, concentrandosi agli estremi (vicino a 0 e 1).\n\n37.8.4 Proprietà della Distribuzione Beta\n\nValore atteso: \\[\n\\mathbb{E}(\\theta) = \\frac{\\alpha}{\\alpha + \\beta}.\n\\]\nVarianza: \\[\n\\mathbb{V}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}.\n\\]\nModa (se \\(\\alpha, \\beta &gt; 1\\)): \\[\n\\text{Moda}(\\theta) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2}.\n\\]\n\nQueste proprietà evidenziano come \\(\\alpha\\) e \\(\\beta\\) possano essere interpretati come “successi” e “fallimenti” in una serie di prove, fornendo un collegamento intuitivo con la distribuzione binomiale.\n\n37.8.5 Relazione con la Distribuzione Binomiale\nLa distribuzione Beta può essere interpretata come una generalizzazione continua della distribuzione binomiale. Mentre la distribuzione binomiale descrive la probabilità di osservare un certo numero di successi in un numero fissato di prove (\\(n\\)), la distribuzione Beta descrive l’incertezza sulla probabilità di successo \\(\\theta\\) stessa, trattandola come una variabile casuale.\n\n37.8.5.1 Contesto bayesiano\nIn un contesto di inferenza bayesiana, la distribuzione Beta viene comunemente utilizzata come distribuzione a priori coniugata per il modello binomiale. Ciò significa che, se si assume una distribuzione Beta come prior per \\(\\theta\\), anche la distribuzione a posteriori (dopo aver osservato i dati) sarà una Beta, ma con parametri aggiornati.\nSupponiamo:\n\nche \\(\\theta\\) sia la probabilità di successo in un compito con esiti binari (es. risposta corretta o errata),\ndi assumere una distribuzione a priori:\\[\n\\theta \\sim \\mathcal{Beta}(\\alpha, \\beta),\n\\]\n\ne di osservare \\(y\\) successi su \\(n\\) prove, con modello di verosimiglianza: \\[\ny \\sim \\mathcal{Binom}(n, \\theta).\n\\]\n\n\nAllora, per il teorema di Bayes, la distribuzione a posteriori di \\(\\theta\\) sarà:\n\\[\n\\theta \\mid \\text{dati} \\sim \\mathcal{Beta}(\\alpha + y, \\beta + n - y).\n\\]\n\n37.8.5.2 Vantaggi della coniugatezza\nQuesto aggiornamento è particolarmente comodo perché:\n\nsi ottiene in forma chiusa (senza dover ricorrere a metodi numerici),\ni parametri \\(\\alpha\\) e \\(\\beta\\) possono essere interpretati come conteggi fittizi di successi e insuccessi prima dell’osservazione dei dati,\nl’informazione a priori e quella empirica si combinano sommando i rispettivi “conteggi.”\n\nQuesta proprietà rende la distribuzione Beta una scelta naturale nei modelli bayesiani con dati binomiali, come in contesti psicologici in cui si vogliono modellare incertezze sulla probabilità di una risposta corretta, sull’esito di una scelta, o sul successo di un comportamento.\n\n37.8.6 Visualizzazione della Distribuzione Beta\nDi seguito mostriamo come la forma della distribuzione Beta varia al variare dei parametri \\(\\alpha\\) e \\(\\beta\\):\n\n# Parametri\nx &lt;- seq(0, 1, length.out = 200)\nalphas &lt;- c(0.5, 5.0, 1.0, 2.0, 2.0)\nbetas &lt;- c(0.5, 1.0, 3.0, 2.0, 5.0)\n\n# Creare un dataframe\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dbeta(x, alphas[i], betas[i]),\n    label = paste0(\"α = \", alphas[i], \", β = \", betas[i])\n  )\n}))\n\n# Plot\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\"\n  ) +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n37.8.7 Costante di Normalizzazione\nLa costante di normalizzazione della distribuzione Beta è il reciproco della funzione Beta di Eulero, \\(B(\\alpha, \\beta)\\). Questa garantisce che:\n\\[\n\\int_0^1 \\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) \\, d\\theta = 1.\n\\]\n\nEsempio 37.2 Di seguito viene proposto un esempio in R per calcolare l’area sottesa alla distribuzione Beta non normalizzata e, con gli stessi parametri, ottenere il valore della funzione Beta di Eulero. L’obiettivo è mostrare come la costante di normalizzazione, pari al reciproco di \\(B(\\alpha, \\beta)\\), garantisca che l’integrale della densità normalizzata su \\([0,1]\\) sia pari a 1.\nSupponiamo di voler utilizzare i parametri:\n\n\\(\\alpha = 2\\)\n\\(\\beta = 5\\)\n\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta  &lt;- 5\n\n# Definiamo la funzione non normalizzata della distribuzione Beta\nunnormalized_beta &lt;- function(theta) {\n  theta^(alpha - 1) * (1 - theta)^(beta - 1)\n}\n\n# Calcoliamo l'integrale della funzione non normalizzata su [0, 1]\nintegrale &lt;- integrate(unnormalized_beta, lower = 0, upper = 1)$value\ncat(\"Integrale della funzione non normalizzata:\", integrale, \"\\n\")\n#&gt; Integrale della funzione non normalizzata: 0.0333\n\n# Calcoliamo il valore della funzione Beta usando la funzione beta() di R\nvalore_beta &lt;- beta(alpha, beta)\ncat(\"Valore della funzione Beta B(alpha, beta):\", valore_beta, \"\\n\")\n#&gt; Valore della funzione Beta B(alpha, beta): 0.0333\n\nSpiegazione del Codice\n\nDefinizione dei Parametri e della Funzione\nImpostiamo \\(\\alpha = 2\\) e \\(\\beta = 5\\) e definiamo la funzione non normalizzata: \\[\nf(\\theta) = \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}.\n\\]\nCalcolo dell’Integrale\nUtilizzando la funzione integrate(), calcoliamo l’area sottesa a \\(f(\\theta)\\) nell’intervallo \\([0,1]\\), che corrisponde a \\(\\mathcal{B}(\\alpha, \\beta)\\).\nVerifica con la Funzione Beta\nLa funzione beta(alpha, beta) di R restituisce direttamente il valore di \\(\\mathcal{B}(\\alpha, \\beta)\\). La stampa dei due valori conferma che l’integrale calcolato e il valore della funzione Beta coincidono.\nCostante di Normalizzazione\nIl reciproco di \\(\\mathcal{B}(\\alpha, \\beta)\\) è calcolato e utilizzato per definire la densità normalizzata della distribuzione Beta. L’integrazione della densità normalizzata su \\([0,1]\\) restituisce 1, confermando la corretta normalizzazione.\n\nQuesto esempio in R mostra in modo pratico come la costante di normalizzazione derivi dalla funzione Beta di Eulero e come essa venga applicata per ottenere una densità di probabilità correttamente normalizzata.\n\nIn conclusione, la distribuzione Beta si rivela particolarmente utile per modellare variabili continue comprese nell’intervallo [0, 1]. Grazie alla sua parametrizzazione tramite \\(\\alpha\\) e \\(\\beta\\), consente di adattare la forma della densità in modo specifico alle caratteristiche osservate dei dati, facilitando la stima di proporzioni. Inoltre, essendo il coniugato della distribuzione binomiale, permette un aggiornamento analitico nei modelli bayesiani, semplificando l’inferenza quando si raccolgono dati incrementali, come nella stima della probabilità di successo in esperimenti o studi psicologici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "chapters/probability/14_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.9 Distribuzione di Cauchy",
    "text": "37.9 Distribuzione di Cauchy\nLa distribuzione di Cauchy è un caso speciale della distribuzione \\(t\\) di Student con un solo grado di libertà (\\(t_1\\)). Questa distribuzione è caratterizzata da code molto pesanti e da una media e varianza non definite, rendendola particolarmente utile in contesti dove valori estremi possono avere un’influenza importante.\n\nDefinizione 37.2 La funzione di densità di probabilità della distribuzione di Cauchy è definita da due parametri:\n\n\n\\(\\alpha\\): posizione (location), che determina il centro della distribuzione.\n\n\\(\\beta &gt; 0\\): scala (scale), che controlla la larghezza della distribuzione.\n\nLa densità è data da:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{1}{\\pi \\beta \\left[1 + \\left( \\frac{x - \\alpha}{\\beta} \\right)^2\\right]} ,\n\\]\ndove:\n\n\n\\(x \\in \\mathbb{R}\\),\n\n\\(\\alpha \\in \\mathbb{R}\\),\n\n\\(\\beta &gt; 0\\).\n\nQuesta funzione descrive una distribuzione simmetrica attorno a \\(\\alpha\\), con code più pesanti rispetto alla distribuzione Normale.\n\n\n37.9.1 Proprietà della Distribuzione di Cauchy\n\n\nSimmetria: La distribuzione è simmetrica rispetto a \\(\\alpha\\).\n\nCode Pesanti: Le code sono significativamente più pesanti rispetto alla distribuzione Normale, con una decrescita più lenta (\\(\\propto x^{-2}\\)).\n\nMedia e Varianza: La distribuzione non ha una media né una varianza definita.\n\nRelazione con \\(t_1\\): La distribuzione di Cauchy è equivalente a una distribuzione \\(t\\) di Student con 1 grado di libertà.\n\nCaratteristiche Estreme: I valori estremi hanno una probabilità più alta rispetto ad altre distribuzioni comuni, rendendola utile per modellare fenomeni con outlier significativi.\n\n37.9.2 Visualizzazione della Distribuzione di Cauchy\nPer comprendere l’effetto dei parametri \\(\\alpha\\) e \\(\\beta\\) sulla forma della distribuzione, consideriamo alcuni esempi con:\n\n\n\\(\\alpha = 0.0, 0.0, 0.0, -2.0\\),\n\n\\(\\beta = 0.5, 1.0, 2.0, 1.0\\).\n\n\n# Definire i parametri\nx &lt;- seq(-5, 5, length.out = 500)\nalphas &lt;- c(0.0, 0.0, 0.0, -2.0)\nbetas &lt;- c(0.5, 1.0, 2.0, 1.0)\n\n# Creare un data frame per i risultati\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dcauchy(x, location = alphas[i], scale = betas[i]),\n    label = paste0(\"α = \", alphas[i], \", β = \", betas[i])\n  )\n}))\n\n# Grafico\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\"\n  ) +\n  theme(\n    legend.title = element_blank()\n  )\n\n\n\n\n\n\n\n\n37.9.3 Applicazioni della Distribuzione di Cauchy\n\n\nInferenza Bayesiana:\n\nUtilizzata come prior robusto in modelli bayesiani, particolarmente quando si vuole attribuire una probabilità maggiore a valori estremi rispetto a una distribuzione Normale.\n\n\n\nModellazione di Fenomeni con Outlier:\n\nLa distribuzione di Cauchy è adatta per descrivere dati con valori estremi significativi che possono influenzare fortemente altre distribuzioni.\n\n\n\nIn conclusione, la distribuzione di Cauchy, con le sue proprietà uniche come code pesanti e l’assenza di media e varianza definite, è uno strumento fondamentale per modellare fenomeni in cui i valori estremi giocano un ruolo importante. La sua relazione con la distribuzione \\(t\\) di Student e la sua utilità nei modelli bayesiani ne ampliano ulteriormente le applicazioni in contesti statistici e probabilistici avanzati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#distribuzione-gamma",
    "href": "chapters/probability/14_cont_rv_distr.html#distribuzione-gamma",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.10 Distribuzione Gamma",
    "text": "37.10 Distribuzione Gamma\nLa distribuzione Gamma è una distribuzione di probabilità continua utilizzata principalmente per modellare variabili strettamente positive, come tassi, varianze, o tempi di attesa. È usata nella statistica bayesiana come distribuzione a priori per parametri positivi e trova applicazione in ambiti come la modellazione di eventi rari.\n\nDefinizione 37.3 La distribuzione Gamma è caratterizzata da due parametri principali:\n\n\nParametro di forma (\\(\\alpha\\)): determina la forma generale della distribuzione.\n\nParametro di scala (\\(\\theta\\)) o, alternativamente, il parametro di tasso (\\(\\beta = 1/\\theta\\)): regola la larghezza o la dispersione della distribuzione.\n\nLa funzione di densità di probabilità (PDF) è data da:\n\\[\nf(x \\mid \\alpha, \\theta) = \\frac{x^{\\alpha-1} e^{-x/\\theta}}{\\theta^\\alpha \\Gamma(\\alpha)}, \\quad x &gt; 0,\n\\]\ndove:\n\n\n\\(x\\) è la variabile casuale continua,\n\n\\(\\Gamma(\\alpha)\\) è la funzione Gamma di Eulero, definita come:\n\n\\[\n\\Gamma(\\alpha) = \\int_0^\\infty t^{\\alpha-1} e^{-t} dt.\n\\]\nSe utilizziamo il parametro di tasso \\(\\beta = 1/\\theta\\), la PDF può essere scritta come:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha x^{\\alpha-1} e^{-\\beta x}}{\\Gamma(\\alpha)}, \\quad x &gt; 0.\n\\]\n\n\n37.10.1 Proprietà della Distribuzione Gamma\n\nMedia: \\[\n\\mathbb{E}[X] = \\alpha \\cdot \\theta = \\frac{\\alpha}{\\beta}.\n\\]\nVarianza: \\[\n\\text{Var}(X) = \\alpha \\cdot \\theta^2 = \\frac{\\alpha}{\\beta^2}.\n\\]\nModa (per \\(\\alpha &gt; 1\\)): \\[\n\\text{Moda}(X) = (\\alpha - 1) \\cdot \\theta.\n\\]\n\nDi seguito, mostriamo un esempio per \\(\\alpha = 3\\) e \\(\\beta = 5/3\\), calcolando e rappresentando graficamente la distribuzione.\n\n\nCalcolo della Media e della Deviazione Standard:\n\n# Parametri\nalpha &lt;- 3\nbeta &lt;- 5 / 3\n\n# Calcolo\nmean &lt;- alpha / beta\nsigma &lt;- sqrt(alpha / beta^2)\n\ncat(\"Media:\", mean, \"\\n\")\n#&gt; Media: 1.8\ncat(\"Deviazione Standard:\", sigma, \"\\n\")\n#&gt; Deviazione Standard: 1.04\n\n\n\nGenerazione e Plot dei Dati:\n\n# Generazione di dati\nset.seed(123)\ndata &lt;- rgamma(100000, shape = alpha, rate = beta)\n\n# Data frame per ggplot\ndf &lt;- data.frame(values = data)\n\n# Plot\nggplot(df, aes(x = values)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"green\", alpha = 0.6) +\n  stat_function(fun = function(x) dgamma(x, shape = alpha, rate = beta),\n                color = \"red\", size = 1) +\n  labs(\n    x = \"Valore\",\n    y = \"Densità di probabilità\"\n  ) \n\n\n\n\n\n\n\n\n\n37.10.2 Applicazioni della Distribuzione Gamma\n\nModellazione del Tempo di Attesa:\nLa distribuzione Gamma è ideale per modellare tempi di attesa, ad esempio, il tempo necessario affinché si verifichino \\(n\\) eventi in un processo di Poisson.\n\nInferenza Bayesiana:\n\nUtilizzata come prior per parametri positivi, come tassi (\\(\\lambda\\)) o varianze (\\(\\sigma^2\\)).\nAd esempio, nella modellazione bayesiana dei processi di Poisson, una distribuzione Gamma è una scelta naturale per il prior su \\(\\lambda\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/14_cont_rv_distr.html#riflessioni-conclusive",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.11 Riflessioni conclusive",
    "text": "37.11 Riflessioni conclusive\nLe distribuzioni di probabilità costituiscono il cuore dell’inferenza statistica, sia bayesiana che frequentista. In questo capitolo, abbiamo esplorato come R offre un insieme completo di strumenti per lavorare con diverse distribuzioni, permettendo di modellare e analizzare una vasta gamma di fenomeni.\n\n37.11.1 Principali Applicazioni\n\n\nInferenza Bayesiana:\nLe distribuzioni di probabilità, come la Beta, la Gamma e la Normale, sono essenziali per definire priors, calcolare posteriori e quantificare l’incertezza nei modelli bayesiani. Ad esempio:\n\nLa distribuzione Beta è ideale per modellare credenze a priori su proporzioni o probabilità.\nLa distribuzione Gamma è ampiamente usata per modellare parametri positivi come tassi o varianze.\n\n\nAnalisi Statistica e Modellazione:\nLe distribuzioni, come la \\(t\\) di Student, sono fondamentali per il confronto tra campioni, mentre la Normale è indispensabile per modellare fenomeni che seguono la legge del limite centrale.\nGenerazione e Simulazione di Dati:\nR permette di generare campioni casuali da distribuzioni comuni, utili per simulazioni, bootstrap e validazione di modelli.\n\n37.11.2 Funzionalità di R\nCon poche funzioni, R consente di:\n\n\nGenerare campioni casuali: con funzioni come rnorm, rgamma, rbeta, possiamo simulare dati da distribuzioni specifiche.\n\nCalcolare densità: ad esempio, con dnorm, dgamma, dbeta, possiamo visualizzare le funzioni di densità.\n\nCalcolare probabilità cumulate: con funzioni come pnorm, pbeta, possiamo determinare probabilità su intervalli specifici.\n\nDeterminare quantili: con funzioni come qnorm, qgamma, possiamo calcolare i punti corrispondenti a specifici livelli di probabilità.\n\n37.11.3 Versatilità delle Distribuzioni\nLe distribuzioni esplorate non solo descrivono fenomeni naturali, ma sono anche i “mattoncini” per costruire modelli statistici complessi. Le loro proprietà, come la media, la varianza, la simmetria o le code pesanti, consentono di adattare il modello al fenomeno studiato.\nIn conclusione, il linguaggio R, con la sua flessibilità e ricchezza di strumenti, permette di padroneggiare le distribuzioni di probabilità, non solo come oggetti matematici, ma anche come strumenti pratici per rispondere a domande complesse. La comprensione e l’uso delle distribuzioni presentate costituiscono le fondamenta per avanzare verso tecniche più sofisticate, come l’inferenza bayesiana avanzata o la modellazione gerarchica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#esercizi",
    "href": "chapters/probability/14_cont_rv_distr.html#esercizi",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nEsercizi sulla distribuzione normale, risolvibili usando R, sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/14_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_cont_rv_distr.html#bibliografia",
    "href": "chapters/probability/14_cont_rv_distr.html#bibliografia",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html",
    "href": "chapters/probability/15_gauss.html",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "",
    "text": "38.1 Introduzione\nNell’analisi dei dati numerici, un aspetto cruciale da affrontare è l’imprecisione delle misurazioni, una caratteristica intrinseca dei dati reali. Anche in condizioni ottimali, le misure sono soggette a incertezze: i dati rappresentano sempre una stima approssimativa della realtà, accurata solo entro un certo margine (ad esempio, pochi punti percentuali). Inoltre, in molti contesti, come quelli demografici, commerciali o sociali, i dati possono essere arrotondati intenzionalmente o risultare imprecisi a causa di stime indirette, incompletezza delle informazioni o altri fattori.\nRiconoscere e gestire questa incertezza è una componente essenziale del processo analitico. Gli strumenti statistici forniscono un framework formale per descrivere e quantificare l’incertezza, consentendo di trarre inferenze robuste dai dati. Tra le distribuzioni di probabilità, la distribuzione normale (o gaussiana) occupa un posto centrale per la sua ubiquità e versatilità. Spesso rappresentata dalla caratteristica “curva a campana,” questa distribuzione è utilizzata per descrivere molte variabili naturali. Quando i dati approssimano una distribuzione normale, gran parte dei valori si concentra intorno alla media, con una diminuzione progressiva della probabilità di valori estremi.\nUna delle proprietà più utili della distribuzione normale è la possibilità di esprimere affermazioni quantitative rigorose. Ad esempio, si può calcolare la probabilità che un valore cada entro un determinato intervallo dalla media utilizzando parametri semplici come media (\\(\\mu\\)) e deviazione standard (\\(\\sigma\\)):\npnorm(1) - pnorm(-1)\n#&gt; [1] 0.683\npnorm(3) - pnorm(-3)\n#&gt; [1] 0.997\nQuesti calcoli costituiscono la base della “regola delle tre sigma,” una strategia utilizzata per identificare valori anomali (outlier), come discusso nel Capitolo 23. Tuttavia, tale regola può risultare fuorviante se i dati non seguono effettivamente una distribuzione normale.\nLa densità della distribuzione normale è definita dalla formula:\n\\[\np(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(\\mu\\) rappresenta la media e \\(\\sigma\\) la deviazione standard. Conoscere questi due parametri permette di calcolare proprietà fondamentali della distribuzione e di stimare probabilità associate a intervalli specifici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#introduzione",
    "href": "chapters/probability/15_gauss.html#introduzione",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "",
    "text": "Circa il 68.3% dei valori cade entro una deviazione standard dalla media:\n\n\n\nCirca il 99.7% cade entro tre deviazioni standard:\n\n\n\n\n\n\n\n38.1.1 Gaussianità e Inferenza Statistica\nLa distribuzione normale è particolarmente rilevante per molti metodi statistici, in particolare nell’approccio frequentista. Gran parte dei test di ipotesi e delle procedure inferenziali assume che i dati siano distribuiti normalmente, una condizione necessaria per derivare formalmente i risultati di molti test. Ad esempio, i test t di Student e l’ANOVA richiedono la normalità delle variabili o dei residui. Quando questa assunzione è soddisfatta, tali strumenti offrono inferenze precise e affidabili.\nTuttavia, se i dati non sono gaussiani, molti test perdono validità. Sebbene si siano proposti approcci che dimostrano la robustezza di alcuni test a deviazioni moderate dalla normalità (Shatz, 2024), tale robustezza non è garantita in tutte le situazioni. Inoltre, l’enfasi sui valori-p complica la questione, poiché violazioni dell’assunzione di normalità possono compromettere l’interpretazione di questi indicatori.\nUna strategia comune per affrontare la non-gaussianità è l’applicazione di trasformazioni dei dati, come la trasformazione logaritmica o quella della radice quadrata, per avvicinare i dati alla distribuzione normale (Osborne, 2002). Ad esempio, distribuzioni asimmetriche come quelle dei tempi di reazione possono essere rese più gaussiane attraverso trasformazioni adeguate, rendendo applicabili i test frequentisti standard. Tuttavia, l’uso delle trasformazioni ha un costo: la perdita di interpretabilità. Se i dati originali avevano un significato chiaro e intuitivo, la trasformazione può rendere i risultati più difficili da collegare al fenomeno studiato.\nIn questo capitolo, esploreremo come verificare se i dati seguono una distribuzione normale, discuteremo l’impatto di questa assunzione sui metodi frequentisti e valuteremo il ruolo delle trasformazioni. Il nostro obiettivo è fornire al data analyst una guida pratica per decidere come trattare i dati non gaussiani, considerando sia i vantaggi che i limiti di ciascun approccio.\n\n38.1.2 L’assunzione di Gaussianità: Quando è valida?\nSebbene la distribuzione normale sia spesso un buon modello per i dati numerici, non è sempre una rappresentazione adeguata. Questo può dipendere da caratteristiche intrinseche dei dati, come asimmetrie, code lunghe o la presenza di valori anomali. Valutare l’appropriatezza dell’assunzione di normalità è un passaggio critico in qualsiasi analisi statistica.\nPer diagnosticare la normalità, presenteremo tre strumenti grafici:\n\n\nIstogrammi, una visualizzazione semplice ma spesso limitata.\n\nGrafici di densità, che forniscono un confronto più fluido rispetto agli istogrammi.\n\nQQ-plot (Quantile-Quantile plot), uno strumento visivo particolarmente efficace per rilevare deviazioni dalla normalità.\n\nQuesti strumenti possono anche essere affiancati da test formali per consentire una diagnosi robusta e guidare le decisioni sul trattamento dei dati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#istogramma",
    "href": "chapters/probability/15_gauss.html#istogramma",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n38.2 Istogramma",
    "text": "38.2 Istogramma\nPer illustrare il concetto, utilizziamo un set di dati simulati che hanno proprietà simili a quelle dei tempi di reazione. Creeremo un istogramma e vi sovrapporremo la curva di densità normale calcolata in base ai dati.\n\n# Dati simulati di tempi di reazione\nset.seed(123)\nrt &lt;- c(rexp(100, rate = 0.2), 50, 60) # Aggiunti valori estremi\n\n# Calcolare la media e la deviazione standard per sovrapporre la densità normale\nmean_rt &lt;- mean(rt, na.rm = TRUE)\nsd_rt &lt;- sd(rt, na.rm = TRUE)\n\n# Creare l'istogramma e sovrapporre la densità normale\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30, color = \"black\"\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    size = 1\n  ) +\n  labs(\n    x = \"Tempi di Reazione\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nL’istogramma mostra la distribuzione empirica dei dati, mentre la curva rossa rappresenta la densità normale con la stessa media e deviazione standard. Nel nostro caso, è evidente una discrepanza tra la distribuzione empirica e la densità normale, indicando che l’assunzione di normalità non è appropriata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#grafico-di-densità",
    "href": "chapters/probability/15_gauss.html#grafico-di-densità",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n38.3 Grafico di densità",
    "text": "38.3 Grafico di densità\nUn grafico di densità è una versione lisciata dell’istogramma che facilita il confronto con la distribuzione normale. Utilizzando il dataset precedente, possiamo creare un grafico di densità sovrapposto alla curva gaussiana.\n\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_density(alpha = 0.5) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    size = 1\n  ) +\n  labs(\n    x = \"Peso\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nAnche questa rappresentazione rende chiaro come l’assunzione di normalità non sia appropriata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#diagramma-quantile-quantile",
    "href": "chapters/probability/15_gauss.html#diagramma-quantile-quantile",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n38.4 Diagramma quantile-quantile",
    "text": "38.4 Diagramma quantile-quantile\nIl diagramma quantile-quantile (QQ-plot) è lo strumento più utile per analizzare visivamente la conformità di un dataset a una distribuzione teorica, in particolare alla distribuzione normale. Il QQ-plot è una tecnica essenziale per chi lavora con dati che si presume seguano una distribuzione specifica, e rappresenta un passaggio cruciale in molte analisi statistiche, soprattutto per verificare l’assunto di normalità.\nUn QQ-plot permette di:\n\n\nValutare graficamente la normalità dei dati: Se i punti nel diagramma seguono approssimativamente una linea retta, i dati possono essere considerati normalmente distribuiti. In caso contrario, il QQ-plot rivela deviazioni dalla normalità, come code pesanti o asimmetrie.\n\nConfrontare distribuzioni: Il QQ-plot non si limita solo alla distribuzione normale, ma può essere utilizzato per confrontare la distribuzione del campione con qualsiasi distribuzione teorica, facilitando l’analisi di dati con forme di distribuzione complesse.\n\nIdentificare outlier: Gli outlier nei dati saranno visibili come punti che si discostano significativamente dalla linea retta del QQ-plot.\n\nIl QQ-plot è costruito tracciando i quantili del campione contro i quantili teorici di una distribuzione di riferimento. L’interpretazione è piuttosto semplice:\n\nSe il campione segue la distribuzione teorica, i punti nel QQ-plot si allineano lungo una linea retta di pendenza 1 (e intercetta 0 nel caso di distribuzione normale standardizzata).\nLa deviazione dalla linea retta indica differenze nella distribuzione del campione rispetto alla distribuzione teorica:\n\n\nIntercetta diversa da 0: indica che la media del campione differisce dalla media della distribuzione teorica.\n\nPendenza diversa da 1: indica una differenza nella varianza tra il campione e la distribuzione teorica.\n\nCurve: indicano deviazioni sistematiche, come code pesanti o distribuzioni asimmetriche.\n\n\n\nNella discussione seguente, costruiremo e analizzeremo QQ-plot per tre casi tipici:\n\n\nCampione con stessa media e varianza della distribuzione teorica.\n\nCampione con media diversa ma stessa varianza.\n\nCampione con media e varianza diverse.\n\nSimuleremo i dati, li ordineremo, calcoleremo manualmente i quantili teorici e infine utilizzeremo librerie specializzate per replicare e confrontare i risultati. Questo approccio pratico ci permetterà di comprendere a fondo l’utilità e il funzionamento del QQ-plot.\n\n38.4.1 Comprendere e Costruire un QQ-Plot (Distribuzione Normale)\nUn QQ-plot (Quantile-Quantile plot) è uno strumento grafico utilizzato per confrontare la distribuzione di un campione con una distribuzione teorica, spesso la distribuzione normale. Il QQ-plot aiuta a visualizzare se un dataset segue una distribuzione specifica, tracciando i quantili del campione contro i quantili della distribuzione teorica.\n\n38.4.2 Passi per Costruire un QQ-Plot\n\n\nOrdinare i Dati: Disporre i dati del campione in ordine crescente.\n\nDeterminare i Quantili Teorici: Per una distribuzione normale, i quantili corrispondono all’inverso della funzione di distribuzione cumulativa (CDF) della distribuzione normale.\n\nConfrontare i Quantili: Tracciare i quantili del campione rispetto ai quantili della distribuzione teorica. Se il campione proviene dalla distribuzione teorica, i punti dovrebbero trovarsi approssimativamente su una linea retta.\n\n38.4.3 Caso 1: Campione con Stessa Media e Varianza della Distribuzione Normale\nSupponiamo che il campione provenga da una distribuzione normale \\(N(\\mu = 0, \\sigma^2 = 1)\\), esattamente come la distribuzione teorica.\n\n38.4.3.1 Simulazione dei Dati\nIniziamo simulando un piccolo dataset da \\(N(0, 1)\\):\n\n# Generiamo 20 punti dati da N(0, 1)\nset.seed(42)  # Per garantire la riproducibilità\ndati_campione &lt;- rnorm(20, mean = 0, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato &lt;- sort(dati_campione)\n\n# Calcoliamo i quantili teorici da N(0, 1)\nquantili_teorici &lt;- qnorm((seq(1, 20) - 0.5) / 20)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Stessa Media e Varianza\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti del QQ-plot dovrebbero allinearsi alla linea rossa, indicando che la distribuzione del campione corrisponde a quella teorica.\n\n38.4.4 Caso 2: Campione con Media Diversa (Intercetta ≠ 0)\nSimuliamo un campione da \\(N(2, 1)\\), con una media diversa ma la stessa varianza:\n\n# Generiamo 20 punti dati da N(2, 1)\ndati_campione_media_spostata &lt;- rnorm(20, mean = 2, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_media_spostata &lt;- sort(dati_campione_media_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_media_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media Diversa (Intercetta ≠ 0)\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti dovrebbero seguire una linea retta ma essere spostati verticalmente, indicando una media diversa (intercetta ≠ 0).\n\n38.4.5 Caso 3: Campione con Media e Varianza Diverse (Pendenza ≠ 1)\nSimuliamo un campione da \\(N(2, 2^2)\\), con una media e una varianza diverse:\n\n# Generiamo 20 punti dati da N(2, 2^2)\ndati_campione_varianza_spostata &lt;- rnorm(20, mean = 2, sd = 2)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_varianza_spostata &lt;- sort(dati_campione_varianza_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_varianza_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media e Varianza Diverse (Pendenza ≠ 1)\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti si discosteranno sia verticalmente (per la media diversa) sia rispetto alla pendenza della linea (per la varianza diversa).\n\n38.4.6 Calcolo Manuale del QQ-Plot\nPer ciascun caso sopra, i passaggi sono i seguenti:\n\n\nOrdinamento dei dati del campione: Questo fornisce i quantili del campione.\n\nCalcolo dei quantili teorici: Utilizzando la funzione inversa della CDF per la distribuzione normale.\n\nEsempio in R:\n\n# Calcolo manuale dei quantili teorici\nquantili_teorici_manuali &lt;- function(n) {\n  sapply(1:n, function(i) qnorm((i - 0.5) / n))\n}\n\nn &lt;- length(dati_campione)\nquantili_teorici_calcolati &lt;- quantili_teorici_manuali(n)\nquantili_teorici_calcolati\n#&gt;  [1] -1.9600 -1.4395 -1.1503 -0.9346 -0.7554 -0.5978 -0.4538 -0.3186 -0.1891\n#&gt; [10] -0.0627  0.0627  0.1891  0.3186  0.4538  0.5978  0.7554  0.9346  1.1503\n#&gt; [19]  1.4395  1.9600\n\n\n38.4.7 Utilizzo di Funzioni Specializzate\nIn R, il pacchetto base offre la funzione qqnorm() per generare QQ-plot. Ad esempio:\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(dati_campione, main = \"QQ-Plot: Stessa Media e Varianza\")\nqqline(dati_campione, lwd = 2)  # Linea di riferimento\n\n\n\n\n\n\n\nPossiamo ripetere lo stesso per i campioni con media e varianza spostate.\n\nQuesto approccio fornisce un’analisi completa della corrispondenza tra distribuzioni teoriche e campioni simulati utilizzando QQ-plot.\nPer concludere, esaminiamo la distribuzione dei tempi di reazione simulati con il qq-plot.\n\nqqnorm(rt, main = \"Tempi di Reazione\")\n\n\n\n\n\n\n\nIl diagramma quantile-quantile rende molto chiaro che la distribuzione del peso dei pulcini non è gaussiana.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#valutare-la-normalità-test-statistici",
    "href": "chapters/probability/15_gauss.html#valutare-la-normalità-test-statistici",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n38.5 Valutare la Normalità: Test Statistici",
    "text": "38.5 Valutare la Normalità: Test Statistici\nSebbene esistano numerosi test statistici formali per valutare la conformità dei dati alla distribuzione normale, questi sono spesso troppo conservativi o sensibili a lievi deviazioni, e nella pratica sono frequentemente sostituiti da metodi visivi più flessibili ed efficaci.\nIn R sono disponibili diversi test per verificare la normalità dei dati. Di seguito presentiamo i più comuni, insieme a un esempio pratico basato sul dataset ChickWeight.\n\n38.5.1 Test di Shapiro-Wilk\nIl test di Shapiro-Wilk è uno dei test più utilizzati per verificare la normalità. Valuta l’ipotesi nulla che i dati seguano una distribuzione normale.\n\nshapiro_test &lt;- shapiro.test(rt)\nshapiro_test\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rt\n#&gt; W = 0.6, p-value = 5e-16\n\n\nIl p-value è inferiore a 0.05 → Rifiutiamo l’ipotesi nulla, i dati non sono normali.\nIl p-value è maggiore di 0.05 → Non rifiutiamo l’ipotesi nulla, i dati possono essere considerati normali.\n\n38.5.2 Test di Kolmogorov-Smirnov\nQuesto test confronta la distribuzione cumulativa dei dati con una distribuzione teorica, come la normale. Tuttavia, è meno sensibile rispetto al test di Shapiro-Wilk.\n\nks_test &lt;- ks.test(\n  rt, \n  \"pnorm\", \n  mean = mean(rt), \n  sd = sd(rt)\n)\nks_test\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  rt\n#&gt; D = 0.3, p-value = 0.000005\n#&gt; alternative hypothesis: two-sided\n\nIl test di Kolmogorov-Smirnov è più adatto per grandi dataset, ma è noto per essere eccessivamente conservativo.\n\n38.5.3 Limitazioni dei test statistici\nNonostante la loro precisione formale, i test statistici per la normalità notevoli limitazioni:\n\nEccessiva sensibilità ai grandi campioni: Quando il campione è ampio, anche lievi deviazioni dalla normalità, non rilevanti per l’analisi, possono portare a un risultato di non-normalità.\nMancanza di sensibilità nei piccoli campioni: Con campioni ridotti, i test possono mancare di potere statistico, portando a falsi negativi (ovvero, non rilevare deviazioni significative dalla normalità).\n\n\nset.seed(123)\nshapiro.test(rchisq(20, 4))\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rchisq(20, 4)\n#&gt; W = 0.9, p-value = 0.3\n\nIn questo esempio, vediamo come, con un campione di 20 osservazioni da una distribuzione \\(\\chi^2_4\\) si produca un falso negativo.\n\n\nDifficoltà interpretative: Un p-value elevato non implica che i dati siano esattamente normali; semplicemente, non c’è evidenza sufficiente per rifiutare l’ipotesi di normalità.\n\nI metodi visivi, sebbene meno formali, sono spesso più pratici ed efficaci per diagnosticare deviazioni dalla normalità.I metodi visivi sono preferibili sono preferibili perché\n\nforniscono una diagnosi immediata, che consente di identificare deviazioni rilevanti senza dipendere da un p-value.\nrivelano non solo se i dati non sono normali, ma anche come e dove differiscono dalla normalità (ad esempio, asimmetria o code pesanti).\noffrono indicazioni utili anche in presenza di grandi campioni, dove i test statistici possono risultare eccessivamente conservativi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalità",
    "href": "chapters/probability/15_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalità",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n38.6 Trasformazione dei dati: affrontare la non-normalità",
    "text": "38.6 Trasformazione dei dati: affrontare la non-normalità\nQuando i dati non rispettano l’assunzione di normalità, è possibile utilizzare diverse strategie per affrontare questa violazione. Una delle più comuni è l’uso di trasformazioni dei dati, che permettono di adattare la distribuzione dei dati a una forma più vicina a quella normale, mantenendo comunque la validità dell’analisi che richiede l’assunzione di normalità. Due approcci comuni sono Winsorizing e trimming.\n\n38.6.1 Winsorizing e Trimming\nQuesti metodi si concentrano sulla gestione degli outlier, ossia valori estremi che possono distorcere la distribuzione dei dati. Entrambi gli approcci presumono che la non-normalità sia dovuta a dati contaminanti e agiscono in modo differente:\n\n\nWinsorizing: Sostituisce i valori estremi con valori meno estremi, come i percentili limite della distribuzione.\n\nTrimming: Rimuove completamente i valori estremi dalla distribuzione.\n\nConsideriamo i seguenti dati di esempio:\n\ndati &lt;- c(\n  1.0, 2.2, 3.0, 3.1, 4.0, 4.0, 4.1, 5.3, 6.5, 8.3,\n  10.9, 20.4, 21.4, 34.\n)\n\n# Winsorizing al 20%\ndati_winsorized &lt;- winsorize(\n  dati,\n  method = \"percentile\", percentile = 20\n)\nprint(dati_winsorized)\n#&gt;  [1]  3.0  3.0  3.0  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9 20.4 20.4 20.4\n\n\n# Trimming al 20%\ndati_trimmed &lt;- dati[\n  dati &gt;= quantile(dati, 0.2) & dati &lt;= quantile(dati, 0.8)\n]\nprint(dati_trimmed)\n#&gt; [1]  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9\n\n\n\nDati Winsorized: I valori estremi (inferiori e superiori ai percentili 20° e 80°) sono sostituiti dai valori limite.\n\nDati Trimmed: I valori fuori dai percentili 20° e 80° sono completamente rimossi.\n\nQuesti metodi riducono l’impatto degli outlier, ma possono introdurre bias se i valori estremi sono effettivamente parte della popolazione target.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#trasformazioni-comuni",
    "href": "chapters/probability/15_gauss.html#trasformazioni-comuni",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n38.7 Trasformazioni comuni",
    "text": "38.7 Trasformazioni comuni\nQuando i dati non rispettano l’assunzione di normalità, è possibile applicare trasformazioni matematiche per modificarne la forma e migliorare l’adattamento a una distribuzione normale. Di seguito, presentiamo le trasformazioni più utilizzate.\nTrasformazione logaritmica.\nLa trasformazione logaritmica è particolarmente utile per variabili con asimmetria positiva (code lunghe a destra), come i tempi di reazione.\n\n# Trasformazione logaritmica\ndati_log &lt;- log(rt)\nplot(density(dati_log), main = \"Densità dei dati log-transformati\")\n\n\n\n\n\n\n\nTrasformazione radice quadrata.\nAdatta per variabili di conteggio o proporzioni con valori vicini a zero.\n\ndati_sqrt &lt;- sqrt(rt)\nplot(density(dati_sqrt), main = \"Densità dei dati trasformati con radice quadrata\")\n\n\n\n\n\n\n\nTrasformazione inversa.\nEfficace per dati con forte asimmetria positiva, ma può complicare l’interpretazione.\n\ndati_inv &lt;- 1 / rt\nplot(density(dati_inv), main = \"Densità dei dati trasformati inversamente\")\n\n\n\n\n\n\n\nTrasformazione Box-Cox.\nLa trasformazione Box-Cox è una tecnica parametrica che generalizza le precedenti. Utilizza il massimo della verosimiglianza per determinare la trasformazione ottimale per normalizzare i dati. La funzione di trasformazione dipende da un parametro \\(\\lambda\\):\n\\[\ny(\\lambda) =\n\\begin{cases}\n\\frac{y^\\lambda - 1}{\\lambda} & \\text{se } \\lambda \\neq 0, \\\\\n\\log(y) & \\text{se } \\lambda = 0.\n\\end{cases}\n\\]\n\nb &lt;- boxcox(lm(rt ~ 1))\n\n\n\n\n\n\n\n\n# Exact lambda\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n#&gt; [1] 0.182\n\nTrasformiamo i dati utilizzando lambda.\n\nrt_boxcox &lt;- (rt^lambda - 1) / lambda\nrt_boxcox |&gt; head()\n#&gt; [1]  1.645  1.168  2.261 -1.568 -1.133  0.479\n\n\nplot(\n  density(rt_boxcox), \n  main = \"Densità dei dati trasformati con Box-Cox\"\n)\n\n\n\n\n\n\n\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(rt_boxcox, main = \"QQ-Plot\")\nqqline(rt_boxcox, lwd = 2) \n\n\n\n\n\n\n\n\n\n38.7.1 Pro e contro delle trasformazioni\nVantaggi:\nLe trasformazioni dei dati offrono molteplici benefici nell’analisi statistica. In primo luogo, possono migliorare l’aderenza alla normalità, un requisito fondamentale per l’applicazione di molti test statistici. Inoltre, contribuiscono a stabilizzare la varianza e a mitigare l’impatto dei valori estremi, riducendo il rischio che questi ultimi influenzino eccessivamente i risultati. Tali vantaggi migliorano la robustezza e l’accuratezza delle analisi.\nSvantaggi:\nNonostante i benefici, le trasformazioni presentano limitazioni rilevanti. La perdita di interpretabilità è uno degli aspetti più critici: i risultati su dati trasformati possono risultare meno intuitivi. Ad esempio, in un modello di regressione applicato a dati trasformati con il logaritmo, il coefficiente rappresenta un cambiamento percentuale anziché assoluto, rendendo l’interpretazione meno diretta per i non esperti.\nInoltre, l’applicazione di una trasformazione deve essere attentamente motivata in base alla natura dei dati e agli obiettivi dell’analisi. Una trasformazione inappropriata può introdurre distorsioni indesiderate, compromettendo la validità dei risultati e portando a conclusioni fuorvianti. Per questo motivo, è essenziale valutare attentamente i costi e i benefici della trasformazione nel contesto specifico della ricerca.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#riflessioni-conclusive",
    "href": "chapters/probability/15_gauss.html#riflessioni-conclusive",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n38.8 Riflessioni Conclusive",
    "text": "38.8 Riflessioni Conclusive\nLa verifica della normalità dei dati e l’eventuale utilizzo di trasformazioni matematiche costituiscono fasi fondamentali nell’analisi statistica. Sebbene i test formali (come Shapiro-Wilk o Kolmogorov-Smirnov) offrano una valutazione strutturata, essi possono risultare troppo sensibili, portando a rigettare l’assunto di normalità anche in presenza di lievi deviazioni non rilevanti dal punto di vista pratico. In questi casi, l’impiego di strumenti visivi—come istogrammi, grafici di densità o QQ-plot—si rivela spesso più informativo e flessibile, consentendo di individuare la natura e l’entità delle deviazioni.\nLe trasformazioni dei dati rappresentano una strategia utile per normalizzare la distribuzione, ma richiedono una scelta oculata. È essenziale verificare che la trasformazione adottata non comprometta il significato teorico della variabile in esame. Quando l’interpretabilità risulta compromessa, potrebbe essere preferibile ricorrere a metodi robusti o modelli alternativi (ad esempio, approcci bayesiani) che non presuppongono la normalità. In definitiva, la decisione finale dipenderà dal contesto di ricerca, dalla natura dei dati e dagli obiettivi analitici, privilegiando sempre un equilibrio tra rigore statistico e interpretabilità dei risultati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/15_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-65           datawizard_1.2.0      pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        rmarkdown_2.29        ragg_1.5.0           \n#&gt; [19] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [22] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [25] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [28] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [31] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [34] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [37] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [40] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [43] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [46] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [49] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [52] insight_1.4.2         distributional_0.5.0  generics_0.1.4       \n#&gt; [55] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [58] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [61] tools_4.5.1           mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [64] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [67] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [70] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [73] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [76] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [79] lifecycle_1.0.4",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_gauss.html#bibliografia",
    "href": "chapters/probability/15_gauss.html#bibliografia",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nOsborne, J. (2002). Notes on the use of data transformations. Practical Assessment, Research, and Evaluation, 8(1).\n\n\nShatz, I. (2024). Assumption-checking rather than (just) testing: The importance of visualization and effect size in statistical diagnostics. Behavior Research Methods, 56(2), 826–845.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html",
    "href": "chapters/probability/16_likelihood.html",
    "title": "39  La verosimiglianza",
    "section": "",
    "text": "Introduzione\nI ricercatori utilizzano modelli matematici per descrivere e prevedere il comportamento dei dati osservati. Questi modelli si distinguono per la loro struttura funzionale, che definisce le relazioni tra variabili osservate e parametri teorici. La selezione del modello ottimale avviene attraverso un confronto sistematico tra le previsioni teoriche generate dai diversi modelli e l’evidenza empirica. Il modello che mostra il miglior accordo con i dati sperimentali viene considerato la rappresentazione più adeguata del fenomeno studiato.\nIn questo processo di valutazione, la funzione di verosimiglianza svolge un ruolo fondamentale: per ogni possibile valore dei parametri, essa quantifica quanto siano plausibili i dati osservati sotto l’ipotesi che siano stati generati da quel specifico modello. In altre parole, la verosimiglianza costruisce una mappa di plausibilità parametrica, identificando le combinazioni di parametri che massimizzano la coerenza tra modello e realtà osservata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#introduzione",
    "href": "chapters/probability/16_likelihood.html#introduzione",
    "title": "39  La verosimiglianza",
    "section": "",
    "text": "Panoramica del capitolo\n\nMisura della plausibilità dei parametri alla luce dei dati osservati\nApplicazione a distribuzioni binomiali (lancio di monete) e gaussiane (misura del QI)\nMetodi per identificare i parametri più plausibili con implementazioni in R\nUtilizzo del rapporto di verosimiglianze e criteri aggiustati (AIC)\nLa verosimiglianza come componente fondamentale per l’inferenza bayesiana\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nCapitolo Estimation (Schervish & DeGroot, 2014)\n\nCapitolo Bayes’ rule (Johnson et al., 2022)\n\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n\n\n\n\n39.0.1 Il principio della verosimiglianza\nIl principio della verosimiglianza costituisce il fondamento dell’inferenza statistica moderna, fornendo un metodo per quantificare la plausibilità di un valore parametrico (come la media di una popolazione o l’effetto di una terapia) alla luce dei dati osservati.\nConcettualmente, la verosimiglianza non misura la probabilità che un’ipotesi sia vera, ma valuta quanto i dati osservati siano coerenti con una specifica ipotesi sul parametro. Rappresenta una misura di sostegno empirico: valori parametrici che rendono i dati più probabili ricevono maggiore supporto dall’evidenza.\n\nDefinizione 39.1 Sia \\(Y\\) un vettore aleatorio (come l’insieme dei punteggi dei partecipanti a un test) la cui distribuzione dipende da un parametro sconosciuto \\(\\theta\\) (ad esempio, il punteggio medio nella popolazione). La distribuzione è descritta da una funzione di densità di probabilità (per variabili continue) o di massa di probabilità (per variabili discrete), indicata con \\(f(y \\mid \\theta)\\), dove \\(\\theta \\in \\Theta\\) e \\(\\Theta\\) rappresenta lo spazio dei possibili valori parametrici.\nDopo aver osservato un campione di dati \\(y\\), la funzione di verosimiglianza è definita come:\n\\[\nL(\\theta; y) = f(y \\mid \\theta)\n\\]\nSi noti che in questa funzione:\n\n\n\\(y\\) è fissato: corrisponde ai dati effettivamente raccolti\n\n\\(\\theta\\) è variabile: rappresenta il parametro incognito oggetto di inferenza\n\nLa funzione \\(L(\\theta; y)\\) assegna quindi a ogni possibile valore di \\(\\theta\\) un grado di supporto basato sui dati, indicando quali valori rendono le osservazioni più plausibili.\n\n\n39.0.2 Relazione tra verosimiglianza e funzione di probabilità\nSebbene la funzione di probabilità (o densità) e la funzione di verosimiglianza condividano la stessa forma matematica \\(f(y \\mid \\theta)\\), il loro significato concettuale differisce sostanzialmente in base al contesto inferenziale.\n\n39.0.2.1 Due prospettive a confronto\n\n\nFunzione di probabilità (densità/massa)\n\n\nParametri (\\(\\theta\\)) fissi: assumiamo che siano noti o ipotizzati\n\nDati (\\(y\\)) aleatori: descrive la distribuzione dei possibili risultati\n\nInterpretazione: \\(f(y \\mid \\theta)\\) quantifica la probabilità (o densità) di osservare \\(y\\) sotto un modello con parametri \\(\\theta\\)\n\n\nDomanda chiave: “Se il modello fosse \\(\\theta\\), quanto sarebbero probabili questi dati?”\n\n\n\nFunzione di verosimiglianza\n\n\nDati (\\(y\\)) fissi: corrispondono alle osservazioni effettive\n\nParametri (\\(\\theta\\)) variabili: rappresentano l’incertezza da risolvere\n\nInterpretazione: \\(L(\\theta; y) = f(y \\mid \\theta)\\) misura la plausibilità relativa di \\(\\theta\\) alla luce di \\(y\\)\n\n\nDomanda chiave: “Alla luce di questi dati, quanto sono credibili i diversi \\(\\theta\\)?”\n\n\n\n39.0.2.2 Implicazioni per l’inferenza statistica\n\nApproccio frequentista: la verosimiglianza è uno strumento per stimare i parametri (es. stima di massima verosimiglianza), senza assegnare loro una distribuzione di probabilità\nApproccio bayesiano: la verosimiglianza funge da ponte tra dati e parametri, combinando l’informazione empirica con le credenze iniziali (prior) per derivare la distribuzione a posteriori:\n\n\\[\nP(\\theta \\mid y) \\propto L(\\theta; y) \\cdot P(\\theta)\n\\]\nIn questa prospettiva, i dati aggiornano la nostra conoscenza su \\(\\theta\\) attraverso la verosimiglianza.\n\n39.0.2.3 Sintesi delle differenze\n\n\n\n\n\n\n\nCaratteristica\nFunzione di probabilità\nFunzione di verosimiglianza\n\n\n\nVariabile di interesse\n\n\\(y\\) (aleatoria)\n\n\\(\\theta\\) (incognita)\n\n\nRuolo epistemologico\nGenera dati ipotetici\nValuta parametri plausibili\n\n\nContesto d’uso\nModellistica predittiva\nInferenza parametrica\n\n\n\nQuesta dualità riflette un principio fondamentale: la stessa formula matematica assume significati distinti a seconda che l’obiettivo sia la descrizione del processo generativo o l’inferenza sui suoi parametri. La verosimiglianza, in particolare, è il motore dell’apprendimento statistico, trasformando dati in conoscenza.\n\n39.0.3 La log-verosimiglianza\nIn ambito statistico e computazionale, risulta spesso vantaggioso lavorare con la log-verosimiglianza, definita come il logaritmo naturale della funzione di verosimiglianza:\n\\[\n\\ell(\\theta; y) = \\log L(\\theta; y) = \\log f(y \\mid \\theta).\n\\]\nQuesta trasformazione apporta significativi vantaggi sia dal punto di vista computazionale che analitico.\nDal punto di vista computazionale, la log-verosimiglianza offre una maggiore stabilità numerica. Il prodotto di probabilità molto piccole, tipico delle funzioni di verosimiglianza, può infatti portare a valori numericamente instabili (un fenomeno noto come underflow). La conversione logaritmica trasforma questi prodotti in somme, molto più gestibili per i calcolatori. Questo vantaggio diventa particolarmente evidente nel caso di osservazioni indipendenti e identicamente distribuite (i.i.d.), dove la log-verosimiglianza complessiva si esprime come la somma dei contributi individuali:\n\\[\n\\ell(\\theta; y_1, \\dots, y_n) = \\sum_{i=1}^n \\log f(y_i \\mid \\theta),\n\\] semplificando notevolmente i calcoli.\nSul piano analitico, la log-verosimiglianza facilita l’ottimizzazione grazie alle proprietà del logaritmo che trasformano prodotti in somme. Le derivate risultano infatti matematicamente più semplici da trattare rispetto a quelle della verosimiglianza originale. Questa semplificazione risulta particolarmente vantaggiosa nei metodi di ottimizzazione numerica come la massimizzazione della verosimiglianza (MLE), dove la stima dei parametri avviene risolvendo il sistema di equazioni ottenuto uguagliando a zero il gradiente. La forma additiva della log-verosimiglianza si dimostra inoltre particolarmente utile nei modelli gerarchici o nei casi in cui i dati provengano da più fonti indipendenti.\nÈ importante sottolineare che, poiché il logaritmo è una funzione monotona crescente, massimizzare la log-verosimiglianza \\(\\ell(\\theta; y)\\) equivale perfettamente a massimizzare la verosimiglianza \\(L(\\theta; y)\\). Pertanto, le stime di massima verosimiglianza (MLE) possono essere ottenute indifferentemente dall’una o dall’altra funzione.\nIn sintesi, la log-verosimiglianza combina efficienza computazionale e semplicità analitica, rendendola uno strumento fondamentale per l’inferenza statistica e l’analisi dati moderna. La sua adozione consente di affrontare problemi complessi con maggiore stabilità numerica e minore complessità computazionale, mantenendo inalterate le proprietà inferenziali della verosimiglianza originale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#modellazione-statistica-del-lancio-di-una-moneta",
    "href": "chapters/probability/16_likelihood.html#modellazione-statistica-del-lancio-di-una-moneta",
    "title": "39  La verosimiglianza",
    "section": "\n39.1 Modellazione statistica del lancio di una moneta",
    "text": "39.1 Modellazione statistica del lancio di una moneta\nUn esempio classico per introdurre il concetto di verosimiglianza è quello del lancio di una moneta. Chiamiamo \\(\\theta\\) la probabilità (incognita) di ottenere “testa”.\n\n39.1.1 Il modello probabilistico\nPer semplicità assumiamo:\n\nogni lancio è indipendente dagli altri;\nla probabilità \\(\\theta\\) resta costante in tutti i lanci.\n\nSe in \\(n\\) lanci otteniamo \\(y\\) teste, la probabilità di osservare esattamente quei dati è:\n\\[\nP(\\text{dati}\\mid \\theta) = \\theta^y (1-\\theta)^{n-y}.\n\\]\n\n39.1.2 La funzione di verosimiglianza\nLa funzione di verosimiglianza si ottiene considerando l’espressione precedente non più come funzione dei dati, ma come funzione di \\(\\theta\\):\n\\[\nL(\\theta \\mid \\text{dati}) \\propto \\theta^y (1-\\theta)^{n-y}.\n\\]\nEssa indica quali valori di \\(\\theta\\) sono più compatibili con i dati osservati. Il valore che massimizza questa funzione è lo stimatore di massima verosimiglianza (MLE).\n\n39.1.3 Esempio 1: due lanci\nSupponiamo di osservare due lanci con esito: una testa e una croce (\\(n=2, y=1\\)).\n\n\nSe \\(\\theta = 0.5\\):\n\\[\nL(0.5) = 0.5^1 \\cdot 0.5^1 = 0.25\n\\]\n\n\nSe \\(\\theta = 0.4\\):\n\\[\nL(0.4) = 0.4^1 \\cdot 0.6^1 = 0.24\n\\]\n\n\nIn questo caso \\(\\theta=0.5\\) spiega leggermente meglio i dati.\nCon R possiamo calcolare la verosimiglianza per tutta la gamma di valori di \\(\\theta\\):\n\nn &lt;- 2\ny &lt;- 1\np_H &lt;- seq(0, 1, length.out = 100)\nlikelihood &lt;- p_H^y * (1 - p_H)^(n - y)\n\nLa curva risultante ha il massimo in corrispondenza di \\(\\hat\\theta = y/n = 0.5\\).\n\n39.1.4 Esempio 2: tre lanci\nConsideriamo ora tre lanci con esito: una testa e due croci (\\(n=3, y=1\\)).\n\n\nSe \\(\\theta = 0.5\\):\n\\[\nL(0.5) = 0.5^1 \\cdot 0.5^2 = 0.125\n\\]\n\n\nSe \\(\\theta = 0.4\\):\n\\[\nL(0.4) = 0.4^1 \\cdot 0.6^2 = 0.144\n\\]\n\n\nQui il valore \\(\\theta = 0.4\\) è più plausibile di 0.5.\nCon R:\n\nn &lt;- 3\ny &lt;- 1\np_H &lt;- seq(0, 1, length.out = 100)\nlikelihood &lt;- p_H^y * (1 - p_H)^(n - y)\n\nLa curva raggiunge il massimo in \\(\\hat\\theta = y/n = 1/3 \\approx 0.33\\). Rispetto al caso precedente, la curva è più stretta, segnalando una maggiore precisione della stima grazie al numero maggiore di osservazioni.\n\n39.1.5 Interpretazione complessiva\n\nLo stimatore di massima verosimiglianza \\(\\hat\\theta\\) corrisponde sempre alla proporzione osservata di teste (\\(y/n\\)).\nAll’aumentare del numero di lanci, la curva di verosimiglianza diventa più appuntita: significa che abbiamo maggiore certezza sul valore di \\(\\theta\\).\nI valori estremi (\\(\\theta \\approx 0\\) o \\(\\theta \\approx 1\\)) risultano poco compatibili con i dati, perché non potrebbero spiegare l’osservazione sia di teste che di croci.\n\nIn sintesi: la verosimiglianza traduce l’idea intuitiva che “il valore migliore del parametro è quello che rende i dati osservati più probabili”. Questo principio, applicato in modo generale, costituisce la base della stima per massima verosimiglianza.\n\n39.1.6 Confronto tra due e tre lanci\nMettiamo ora a confronto le due situazioni:\n\n\nCaso 1: 2 lanci con 1 testa (\\(n=2, y=1\\), proporzione osservata \\(\\hat\\theta = 0.5\\)).\n\nCaso 2: 3 lanci con 1 testa (\\(n=3, y=1\\), proporzione osservata \\(\\hat\\theta \\approx 0.33\\)).\n\n\n# Dati per 2 lanci\nn1 &lt;- 2; y1 &lt;- 1\ntheta_seq &lt;- seq(0, 1, length.out = 200)\nlik1 &lt;- theta_seq^y1 * (1 - theta_seq)^(n1 - y1)\n\n# Dati per 3 lanci\nn2 &lt;- 3; y2 &lt;- 1\nlik2 &lt;- theta_seq^y2 * (1 - theta_seq)^(n2 - y2)\n\n# Creiamo un unico dataframe\ndf &lt;- data.frame(\n  theta = rep(theta_seq, 2),\n  likelihood = c(lik1, lik2),\n  caso = rep(c(\"2 lanci (1 testa)\", \"3 lanci (1 testa)\"), each = length(theta_seq))\n)\n\n# Grafico comparativo\nggplot(df, aes(x = theta, y = likelihood, color = caso)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Verosimiglianza\"\n  ) +\n  scale_color_manual(values = c(\"steelblue\", \"darkorange\"))\n\n\n\n\n\n\n\n\n39.1.7 Interpretazione del grafico\n\nNel caso dei 2 lanci, la curva ha un massimo in \\(\\hat\\theta = 0.5\\), ma è molto larga: la stima è poco precisa.\nNel caso dei 3 lanci, la curva ha un massimo in \\(\\hat\\theta = 1/3\\), ed è più stretta: significa che, con più dati, la stima diventa più affidabile.\nI valori estremi (\\(\\theta \\approx 0\\) o \\(\\theta \\approx 1\\)) hanno verosimiglianza quasi nulla in entrambi i casi, perché non spiegherebbero la presenza di almeno una testa e di almeno una croce.\n\nQuesto semplice confronto mostra visivamente come aumentare la quantità di dati restringe l’incertezza e rende la stima più precisa.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#verosimiglianza-binomiale",
    "href": "chapters/probability/16_likelihood.html#verosimiglianza-binomiale",
    "title": "39  La verosimiglianza",
    "section": "\n39.2 Verosimiglianza binomiale",
    "text": "39.2 Verosimiglianza binomiale\nConsideriamo ora un esperimento più ampio: lanciamo una moneta \\(n = 30\\) volte e osserviamo \\(y = 23\\) teste. Per modellare il numero totale di successi utilizziamo la distribuzione binomiale, che descrive la probabilità di ottenere esattamente \\(y\\) successi in \\(n\\) prove indipendenti, con probabilità di successo \\(\\theta\\) costante:\n\\[\nP(Y = y \\mid \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}.\n\\]\nIn questo contesto, \\(Y\\) rappresenta la variabile casuale “numero di teste”, \\(y = 23\\) è il valore osservato, e \\(\\theta\\) (o \\(p_H\\)) è la probabilità incognita di ottenere testa in un singolo lancio.\n\n39.2.1 Dalla distribuzione di probabilità alla verosimiglianza\nDopo aver osservato i dati (\\(y = 23\\)), possiamo valutare la compatibilità dei diversi valori del parametro \\(\\theta\\) con l’evidenza sperimentale. A questo scopo, utilizziamo la formula della distribuzione binomiale trattandola come funzione di \\(\\theta\\) anziché di \\(y\\):\n\\[\nL(\\theta \\mid y = 23) = \\binom{30}{23} \\theta^{23} (1 - \\theta)^7.\n\\]\nQuesta funzione di verosimiglianza quantifica la plausibilità di ciascun valore di \\(\\theta\\) alla luce dei dati osservati. A differenza degli esempi precedenti, in questo caso manteniamo la costante moltiplicativa \\(\\binom{30}{23}\\) poiché lavoreremo con la verosimiglianza completa.\n\n39.2.2 Visualizzazione della funzione di verosimiglianza\nIl codice seguente genera il grafico della funzione di verosimiglianza, calcolando per ogni valore di \\(\\theta\\) la probabilità di osservare 23 successi su 30 prove:\n\n# Parametri osservati\nn &lt;- 30  # Numero totale di lanci\ny &lt;- 23  # Numero di teste osservate\n\n# Griglia di valori possibili per theta\ntheta &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della verosimiglianza binomiale\nlikelihood &lt;- dbinom(y, size = n, prob = theta)\n\n# Preparazione dei dati per la visualizzazione\ndata &lt;- data.frame(theta, likelihood)\n\n# Rappresentazione grafica\nggplot(data, aes(x = theta, y = likelihood)) +\n  geom_line(linewidth = 1.2, color = \"steelblue\") +\n  labs(\n    x = expression(theta),\n    y = \"Verosimiglianza\"\n  ) \n\n\n\n\n\n\n\n\n39.2.3 Interpretazione dei risultati\nL’analisi grafica rivele che:\n\nLa funzione di verosimiglianza raggiunge il suo massimo in corrispondenza di \\(\\theta \\approx 0.77\\)\n\nQuesto valore rappresenta la stima di massima verosimiglianza (MLE) per la probabilità di successo\nLa stima corrisponde esattamente alla proporzione campionaria: \\(\\hat{\\theta} = \\frac{23}{30} \\approx 0.767\\)\n\nLa curva mostra una dispersione limitata, indicando una relativa precisione nella stima\nI valori estremi di \\(\\theta\\) (vicini a 0 o 1) presentano verosimiglianze trascurabili\n\n39.2.4 Implementazione computazionale\nIn R, il calcolo della verosimiglianza binomiale può essere efficientemente implementato utilizzando la funzione dbinom(), che calcola la funzione di massa di probabilità della distribuzione binomiale:\n# Calcolo della verosimiglianza\nlikelihood &lt;- dbinom(y, size = n, prob = theta)\ndove:\n\n\ny è il numero di successi osservati (23)\n\nn è il numero totale di prove (30)\n\ntheta è il vettore dei valori parametrici da valutare\n\nQuesto approccio dimostra come la verosimiglianza possa essere costruita direttamente a partire dalla distribuzione di probabilità sottostante, utilizzando strumenti computazionali standard. La funzione dbinom() calcola automaticamente l’intera espressione binomiale, inclusa la costante moltiplicativa, fornendo così la verosimiglianza completa per ogni valore di \\(\\theta\\).\nLa metodologia presentata mostra come concetti teorici di inferenza statistica possano essere efficacemente implementati e visualizzati attraverso strumenti computazionali, facilitando la comprensione intuitiva dei principi di verosimiglianza e stima parametrica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#la-stima-di-massima-verosimiglianza",
    "href": "chapters/probability/16_likelihood.html#la-stima-di-massima-verosimiglianza",
    "title": "39  La verosimiglianza",
    "section": "\n39.3 La Stima di Massima Verosimiglianza",
    "text": "39.3 La Stima di Massima Verosimiglianza\nQuando osserviamo dati sperimentali e desideriamo stimare un parametro incognito – come la probabilità \\(\\theta\\) che una moneta produca “testa” – un approccio fondamentale è rappresentato dalla stima di massima verosimiglianza (Maximum Likelihood Estimation, MLE). Sebbene l’approccio bayesiano si concentri sulla distribuzione completa dei valori plausibili del parametro piuttosto che su una singola stima puntuale, la comprensione del concetto di MLE rimane essenziale. Questo metodo identifica il valore di \\(\\theta\\) che massimizza la compatibilità tra il modello e i dati osservati. In contesti bayesiani, sotto specifiche condizioni di prior, la MLE coincide con il massimo della distribuzione a posteriori.\n\n39.3.1 Il principio fondamentale\nLa logica sottostante la MLE è intuitiva: tra tutti i possibili valori del parametro, selezioniamo quello che rende i dati osservati più probabili. Immaginiamo di testare sistematicamente diversi valori di \\(\\theta\\), chiedendoci per ciascuno: “Se questo fosse il vero valore del parametro, quanto sarebbero plausibili i dati che abbiamo effettivamente osservato?” Il valore che massimizza questa plausibilità costituisce la nostra stima ottimale.\n\n39.3.2 Esempio applicativo: il lancio della moneta\nConsideriamo una moneta lanciata 30 volte che produce 23 teste. Un risultato così marcato solleva naturalmente dubbi sull’equità della moneta. Per stimare la vera probabilità \\(\\theta\\) di ottenere testa, costruiamo la funzione di verosimiglianza, che quantifica la compatibilità di ciascun possibile valore di \\(\\theta\\) con l’evidenza sperimentale. Valori più elevati di verosimiglianza indicano una maggiore plausibilità del parametro dato i dati osservati.\n\n39.3.3 Rappresentazione grafica e interpretazione\nLa funzione di verosimiglianza \\(L(\\theta)\\) può essere visualizzata come una curva che descrive l’andamento della plausibilità al variare di \\(\\theta\\). Questa curva presenta tipicamente un massimo globale ben definito, corrispondente alla stima MLE. Geometricamente, questo punto rappresenta il vertice della “collina” di verosimiglianza.\nLa forma della curva fornisce preziose informazioni:\n\nuna curva appuntita indica alta certezza nella stima,\nuna curva più piatta suggerisce maggiore incertezza parametrica,\nla pendenza della curva riflette la sensibilità della verosimiglianza alle variazioni del parametro.\n\n39.3.4 Determinazione analitica del massimo\nMatematicamente, il massimo della funzione di verosimiglianza corrisponde al punto in cui la sua derivata si annulla. Utilizzando la trasformazione in log-verosimiglianza:\n\\[\n\\ell(\\theta) = y \\log \\theta + (n - y) \\log(1 - \\theta),\n\\]\nla soluzione analitica si ottiene ponendo la derivata uguale a zero:\n\\[\n\\hat{\\theta} = \\frac{y}{n}.\n\\]\nNel nostro esempio, questo risulta in \\(\\hat{\\theta} = \\frac{23}{30} \\approx 0.767\\), dimostrando come la MLE corrisponda alla proporzione campionaria osservata.\n\n39.3.5 Relazione con l’inferenza bayesiana\nNella statistica bayesiana, l’obiettivo principale è la caratterizzazione completa dell’incertezza parametrica attraverso la distribuzione a posteriori. Tuttavia, il punto di massimo di questa distribuzione, noto come stima MAP (Maximum A Posteriori), coincide con la MLE quando si assume una distribuzione a priori uniforme. Questa connessione evidenzia come la MLE rappresenti un caso particolare dell’approccio bayesiano, fornendo un ponte concettuale tra i due paradigmi inferenziali.\nLa comprensione della MLE non solo facilita l’interpretazione dei risultati statistici, ma costituisce anche una base essenziale per l’apprendimento dei metodi bayesiani più avanzati, mostrando come il concetto di verosimiglianza unifichi diversi approcci all’inferenza statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#calcolo-della-stima-di-massima-verosimiglianza-in-r",
    "href": "chapters/probability/16_likelihood.html#calcolo-della-stima-di-massima-verosimiglianza-in-r",
    "title": "39  La verosimiglianza",
    "section": "\n39.4 Calcolo della Stima di Massima Verosimiglianza in R",
    "text": "39.4 Calcolo della Stima di Massima Verosimiglianza in R\n\n39.4.1 Metodo 1: Valutazione su Griglia\nIl primo approccio consiste nel valutare sistematicamente la verosimiglianza per un’ampia gamma di valori del parametro θ:\n\n# Definizione dei parametri osservati\nn &lt;- 30\ny &lt;- 23\ntheta &lt;- seq(0, 1, length.out = 10000)\n\n# Calcolo della funzione di verosimiglianza\nlikelihood &lt;- dbinom(y, size = n, prob = theta)\n\n# Identificazione del massimo\nmax_index &lt;- which.max(likelihood)\noptimal_theta &lt;- theta[max_index]\n\n# Visualizzazione del risultato\noptimal_theta\n#&gt; [1] 0.767\n\nQuesto metodo offre una soluzione numerica precisa attraverso:\n\nla generazione di una griglia densa di valori possibili per \\(\\theta\\),\nil calcolo diretto della verosimiglianza per ogni punto della griglia,\nl’identificazione del valore ottimale mediante ricerca del massimo.\n\n39.4.2 Metodo 2: Ottimizzazione Numerica\nUn approccio più efficiente dal punto di vista computazionale utilizza algoritmi di ottimizzazione:\n\n# Definizione della funzione di log-verosimiglianza negativa\nneg_log_likelihood &lt;- function(theta) {\n  - (y * log(theta) + (n - y) * log(1 - theta))\n}\n\n# Ottimizzazione numerica\nresult &lt;- optim(\n  par = 0.5,              # Valore iniziale\n  fn = neg_log_likelihood, # Funzione da minimizzare\n  method = \"Brent\",       # Algoritmo per ottimizzazione unidimensionale\n  lower = 1e-6,           # Limite inferiore\n  upper = 1 - 1e-6        # Limite superiore\n)\n\noptimal_theta_numerical &lt;- result$par\noptimal_theta_numerical\n#&gt; [1] 0.767\n\nL’utilizzo della log-verosimiglianza negativa è necessario poiché la funzione optim() è progettata per la minimizzazione. Questo approccio risulta particolarmente vantaggioso per modelli complessi dove una valutazione su griglia sarebbe computazionalmente costosa.\n\n39.4.3 Confronto dei risultati\n\n# Confronto tra i diversi metodi\nc(\n  \"Griglia\" = optimal_theta, \n  \"Ottimizzazione\" = optimal_theta_numerical, \n  \"Analitica\" = y / n\n)\n#&gt;        Griglia Ottimizzazione      Analitica \n#&gt;          0.767          0.767          0.767\n\nTutti e tre i metodi convergono allo stesso risultato:\n\\[\n\\hat{\\theta} = \\frac{23}{30} \\approx 0.767 .\n\\]\nQuesta coincidenza dimostra la robustezza del metodo di massima verosimiglianza e conferma che, nel caso della distribuzione binomiale, la stima ottimale corrisponde alla proporzione campionaria osservata.\nOsservazioni metodologiche:\n\nIl metodo della griglia offre una visualizzazione completa della funzione di verosimiglianza.\nL’ottimizzazione numerica è più efficiente per problemi multidimensionali.\nLa soluzione analitica fornisce un riferimento teorico esatto.\nLa scelta del metodo dipende dalle specifiche esigenze analitiche e computazionali.\n\nL’implementazione in R dimostra come concetti statistici avanzati possano essere efficacemente applicati attraverso strumenti computazionali, facilitando sia l’analisi che l’interpretazione dei risultati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#verosimiglianza-congiunta",
    "href": "chapters/probability/16_likelihood.html#verosimiglianza-congiunta",
    "title": "39  La verosimiglianza",
    "section": "\n39.5 Verosimiglianza congiunta",
    "text": "39.5 Verosimiglianza congiunta\nIl concetto di verosimiglianza si estende naturalmente al caso di osservazioni multiple, dando origine alla verosimiglianza congiunta. Questo approccio consente di combinare informazioni provenienti da diverse fonti o esperimenti per ottenere stime parametriche più robuste.\n\n39.5.1 Dalla binomiale alla verosimiglianza congiunta\nNel caso di \\(n\\) lanci di moneta, la verosimiglianza basata sul numero totale di successi segue la distribuzione binomiale:\n\\[\n\\mathcal{L}(\\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}.\n\\]\nTuttavia, possiamo concettualizzare il problema considerando ogni lancio come un’osservazione indipendente Bernoulli. Per una singola osservazione:\n\\[\n\\mathcal{L}(\\theta \\mid y_i) = \\theta^{y_i} (1 - \\theta)^{1 - y_i}.\n\\]\nPer \\(n\\) osservazioni indipendenti, la verosimiglianza congiunta diventa:\n\\[\n\\mathcal{L}(\\theta \\mid y_1, y_2, \\dots, y_n) = \\prod_{i=1}^{n} \\theta^{y_i} (1 - \\theta)^{1 - y_i} = \\theta^y (1 - \\theta)^{n - y}.\n\\]\ndove \\(y = \\sum_{i=1}^{n} y_i\\). Questo dimostra l’equivalenza tra l’approccio basato sulle osservazioni individuali e quello basato sulla statistica sufficiente binomiale.\n\n39.5.2 Importanza della verosimiglianza congiunta\nLa verosimiglianza congiunta rappresenta uno strumento fondamentale per:\n\nIntegrare informazioni da multiple osservazioni indipendenti.\nCostruire modelli statistici complessi.\nEffettuare stime parametriche basate sull’intero set di dati.\nGeneralizzare il concetto di verosimiglianza a contesti multivariati.\n\n39.5.3 Esempio applicativo: gruppi di osservazioni binomiali\nConsideriamo quattro gruppi indipendenti di osservazioni binomiali:\n\nGruppo 1: 23 successi su 30 prove.\nGruppo 2: 20 successi su 28 prove.\nGruppo 3: 29 successi su 40 prove.\nGruppo 4: 29 successi su 36 prove.\n\nAssumendo che tutti i gruppi condividano lo stesso parametro \\(\\theta\\), la log-verosimiglianza congiunta è data da:\n\\[\n\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right]\n\\]\nSviluppando l’espressione:\n\\[\n\\begin{aligned}\n\\log \\mathcal{L}(\\theta) = &23\\log(\\theta) + 7\\log(1 - \\theta) + \\\\\n&20\\log(\\theta) + 8\\log(1 - \\theta) + \\\\\n&29\\log(\\theta) + 11\\log(1 - \\theta) + \\\\\n&29\\log(\\theta) + 7\\log(1 - \\theta)\n\\end{aligned}\n\\]\nQuesta formulazione permette di valutare la plausibilità del parametro \\(\\theta\\) considerando simultaneamente tutte le informazioni disponibili dai quattro gruppi sperimentali.\n\n39.5.4 Implementazione computazionale\nIn R, la verosimiglianza congiunta può essere calcolata efficientemente:\n\n# Definizione dei parametri dei gruppi\nsuccessi &lt;- c(23, 20, 29, 29)\nprove &lt;- c(30, 28, 40, 36)\n\n# Funzione di log-verosimiglianza congiunta\nlog_verosimiglianza_congiunta &lt;- function(theta) {\n  sum(successi * log(theta) + (prove - successi) * log(1 - theta))\n}\n\n# Calcolo per un valore specifico di theta\nlog_verosimiglianza_congiunta(0.7)\n#&gt; [1] -75.8",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#la-verosimiglianza-marginale-nellinferenza-bayesiana",
    "href": "chapters/probability/16_likelihood.html#la-verosimiglianza-marginale-nellinferenza-bayesiana",
    "title": "39  La verosimiglianza",
    "section": "\n39.6 La Verosimiglianza marginale nell’inferenza bayesiana",
    "text": "39.6 La Verosimiglianza marginale nell’inferenza bayesiana\nLa verosimiglianza marginale rappresenta un concetto fondamentale nell’inferenza bayesiana, permettendo di valutare la compatibilità complessiva di un modello con i dati osservati, considerando l’intera distribuzione dei parametri. A differenza della verosimiglianza classica che valuta la plausibilità dei dati per valori fissi dei parametri, la verosimiglianza marginal integra l’incertezza parametrica attraverso la distribuzione a priori.\n\n39.6.1 Caso di parametri discreti\nSupponiamo di osservare \\(k = 7\\) successi su \\(n = 10\\) tentativi, con il parametro \\(\\theta\\) che può assumere solo tre valori discreti:\n\\[\n\\theta \\in \\{0.1,\\; 0.5,\\; 0.9\\}.\n\\]\n\n\nAssegnazione della distribuzione a priori sui valori di \\(\\theta\\):\n\n\nPrior uniforme:\n\\[\np(\\theta = 0.1) = p(\\theta = 0.5) = p(\\theta = 0.9) = \\tfrac{1}{3}.\n\\]\n\n\nPrior non uniforme:\n\\[\np(\\theta = 0.1) = \\tfrac{1}{4}, \\quad\np(\\theta = 0.5) = \\tfrac{1}{2}, \\quad\np(\\theta = 0.9) = \\tfrac{1}{4}.\n\\]\n\n\n\n\nCalcolo della verosimiglianza per ogni valore di \\(\\theta\\):\n\\[\np(k=7 \\mid \\theta) = \\binom{10}{7}\\,\\theta^{7}(1-\\theta)^{3}.\n\\]\n\n\nMarginalizzazione tramite somma pesata:\n\\[\np(k=7 \\mid n=10) = \\sum_{i=1}^{3} p(k=7 \\mid \\theta_i)\\, p(\\theta_i).\n\\]\n\n\n39.6.2 Caso di parametri continui\nNella maggior parte delle applicazioni, il parametro \\(\\theta\\) varia in modo continuo. Per \\(\\theta \\in [0,1]\\), la verosimiglianza marginale si calcola integrando:\n\\[\np(k=7 \\mid n=10)\n= \\int_{0}^{1} \\binom{10}{7}\\,\\theta^{7}(1-\\theta)^{3}\\, p(\\theta)\\, d\\theta,\n\\]\ndove \\(p(\\theta)\\) è la distribuzione a priori.\nAd esempio, con una prior \\(\\text{Beta}(2,2)\\):\n\\[\np(\\theta) = \\frac{\\theta(1-\\theta)}{B(2,2)},\n\\]\nsi ottiene:\n\\[\np(k=7 \\mid n=10)\n= \\int_{0}^{1} \\binom{10}{7}\\, \\theta^{7}(1-\\theta)^{3} \\,\\frac{\\theta(1-\\theta)}{B(2,2)} \\, d\\theta.\n\\]\n\n39.6.3 Implementazione computazionale in R\n\n39.6.3.1 Parametri discreti\n\n# Valori discreti di θ e prior uniforme\ntheta_vals &lt;- c(0.1, 0.5, 0.9)\nprior_probs &lt;- rep(1/3, 3)\n\n# Calcolo della verosimiglianza marginale\nlikelihoods &lt;- dbinom(7, size = 10, prob = theta_vals)\nmarginal_likelihood &lt;- sum(likelihoods * prior_probs)\nprint(marginal_likelihood)\n#&gt; [1] 0.0582\n\nIn questo caso, il calcolo corrisponde alla formula\n\\[\np(k=7 \\mid n=10) = \\sum_{i=1}^3 p(k=7 \\mid \\theta_i)\\, p(\\theta_i).\n\\]\n\n39.6.3.2 Parametri continui\n\n# Integrazione numerica con prior Beta(2,2)\nintegrand &lt;- function(theta) {\n  dbinom(7, size = 10, prob = theta) * dbeta(theta, 2, 2)\n}\n\nmarginal_likelihood &lt;- integrate(integrand, 0, 1)$value\nprint(marginal_likelihood)\n#&gt; [1] 0.112\n\nQui la verosimiglianza marginale viene calcolata come\n\\[\np(k=7 \\mid n=10) = \\int_0^1 \\binom{10}{7}\\, \\theta^7 (1-\\theta)^3 \\, p(\\theta)\\, d\\theta,\n\\]\ndove, con una prior \\(\\text{Beta}(2,2)\\), vale\n\\[\np(\\theta) = \\frac{\\theta(1-\\theta)}{B(2,2)}.\n\\]\n\n39.6.4 Interpretazione\nLa verosimiglianza marginale \\(p(D)\\) quantifica la probabilità complessiva dei dati \\(D\\) tenendo conto di tutte le possibili configurazioni parametriche:\n\nvalori più alti indicano maggiore compatibilità tra modello e dati;\n\nvalori più bassi suggeriscono che i dati siano poco plausibili sotto quel modello;\n\nil confronto tra modelli si basa sul fattore di Bayes:\\[\nBF_{12} = \\frac{p(D \\mid M_1)}{p(D \\mid M_2)}.\n\\]\n\n\n39.6.5 Ruolo nell’inferenza bayesiana\nNella formula di Bayes\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta)\\,p(\\theta)}{p(D)},\n\\]\nla quantità \\(p(D)\\), ossia la verosimiglianza marginale:\n\nfunge da fattore di normalizzazione per ottenere la distribuzione a posteriori;\n\ncostituisce la base del confronto tra modelli;\n\nrappresenta una misura complessiva dell’evidenza fornita dai dati.\n\n39.6.6 Considerazioni pratiche\nIl calcolo di \\(p(D)\\) presenta spesso difficoltà:\n\nl’integrazione diventa rapidamente multidimensionale per modelli complessi;\n\ni risultati possono essere sensibili alla scelta della prior;\n\nsono necessari metodi approssimati (MCMC, bridge sampling, ecc.) per modelli realistici.\n\nNonostante queste complessità, la verosimiglianza marginale resta un concetto fondamentale:\n- permette di valutare la bontà di adattamento dei modelli,\n- guida la selezione bayesiana dei modelli,\n- e garantisce un’inferenza che integra in modo coerente l’incertezza sui parametri.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#verosimiglianza-gaussiana",
    "href": "chapters/probability/16_likelihood.html#verosimiglianza-gaussiana",
    "title": "39  La verosimiglianza",
    "section": "\n39.7 Verosimiglianza gaussiana",
    "text": "39.7 Verosimiglianza gaussiana\nLa distribuzione gaussiana (o normale) è uno degli strumenti fondamentali della statistica. La sua importanza deriva dalla capacità di descrivere in modo efficace molte variabili continue di interesse psicologico e scientifico, come il quoziente intellettivo (QI), i tempi di reazione o diverse misurazioni psicofisiologiche.\n\n39.7.1 Caso di una singola osservazione\nConsideriamo la misurazione del QI di un individuo. Supponiamo che il QI segua una distribuzione normale con media incognita \\(\\mu\\) e deviazione standard nota \\(\\sigma = 15\\).\nLa funzione di densità di probabilità (pdf) è:\n\\[\nf(y \\mid \\mu, \\sigma) \\;=\\; \\frac{1}{\\sigma \\sqrt{2\\pi}}\n\\exp\\!\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(y\\) rappresenta il valore osservato (nel nostro caso \\(y=114\\)), \\(\\mu\\) è il parametro da stimare e \\(\\sigma\\) è noto.\nLa funzione di verosimiglianza per una singola osservazione è data dalla stessa espressione, considerata ora come funzione di \\(\\mu\\), fissato \\(y\\).\n\n# Osservazione e parametro noto\ny_obs &lt;- 114\nsigma &lt;- 15\nmu_values &lt;- seq(70, 160, length.out = 1000)\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- dnorm(y_obs, mean = mu_values, sd = sigma)\n\n# Visualizzazione\nggplot(data.frame(mu = mu_values, likelihood = likelihood), \n       aes(x = mu, y = likelihood)) +\n  geom_line(linewidth = 1.2, color = \"steelblue\") +\n  labs(\n    x = \"Media μ\",\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\nIl valore di \\(\\mu\\) che massimizza la verosimiglianza coincide con l’osservazione stessa:\n\nmu_optimal &lt;- mu_values[which.max(likelihood)]\ncat(\"Stima di massima verosimiglianza per μ:\", mu_optimal)\n#&gt; Stima di massima verosimiglianza per μ: 114\n\n\n39.7.2 Ottimizzazione tramite log-verosimiglianza\nL’uso della log-verosimiglianza è preferibile per ragioni numeriche:\n\ntrasforma prodotti di probabilità in somme,\nevita problemi di underflow con valori molto piccoli,\nsemplifica il calcolo delle derivate.\n\nPer una singola osservazione da una normale:\n\\[\n\\ell(\\mu \\mid y, \\sigma) \\;=\\; -\\tfrac{1}{2}\\log(2\\pi)\\;-\\;\\log(\\sigma)\\;-\\;\\frac{(y-\\mu)^2}{2\\sigma^2}.\n\\]\n\n39.7.2.1 Implementazione in R\n\n# Definizione della funzione di log-verosimiglianza negativa\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  -dnorm(y, mean = mu, sd = sigma, log = TRUE)\n}\n\n# Ottimizzazione numerica\nresult &lt;- optim(\n  par = 100,                 # Valore iniziale per μ\n  fn = negative_log_likelihood,\n  y = y_obs,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = 70,\n  upper = 160\n)\n\n# Estrazione della stima\nmu_mle &lt;- result$par\ncat(\"Stima di massima verosimiglianza per μ:\", round(mu_mle, 2))\n#&gt; Stima di massima verosimiglianza per μ: 114\n\n\n39.7.3 Vantaggi della log-verosimiglianza\n\n\nStabilità numerica: riduce i rischi di underflow.\n\nEfficienza computazionale: la somma di log-probabilità è più stabile del prodotto di probabilità.\n\nProprietà additive: la log-verosimiglianza totale è la somma dei contributi dei singoli dati.\n\nDerivazioni semplificate: le derivate della log-verosimiglianza hanno forma più semplice.\n\n39.7.4 Interpretazione del risultato\nLa stima di massima verosimiglianza (MLE) per \\(\\mu\\) risulta:\n\\[\n\\hat{\\mu} = 114,\n\\]\nossia il valore osservato. Questo era atteso: per una singola osservazione da una normale con deviazione standard nota, la stima MLE della media coincide esattamente con il dato osservato.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#campione-di-osservazioni-indipendenti",
    "href": "chapters/probability/16_likelihood.html#campione-di-osservazioni-indipendenti",
    "title": "39  La verosimiglianza",
    "section": "\n39.8 Campione di osservazioni indipendenti",
    "text": "39.8 Campione di osservazioni indipendenti\nSupponiamo di avere i punteggi BDI-II raccolti su un campione di \\(n=30\\) partecipanti. Assumiamo che ciascun punteggio sia un’osservazione indipendente da una distribuzione normale con media incognita \\(\\mu\\) e deviazione standard nota \\(\\sigma = 6.5\\).\n\n# Dati osservati (punteggi BDI-II)\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, \n  28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nsigma &lt;- 6.5  # Deviazione standard nota\n\n\n\n39.8.1 Log-verosimiglianza\nPer un campione di \\(n\\) osservazioni indipendenti, la log-verosimiglianza del parametro \\(\\mu\\) è\n\\[\n\\ell(\\mu \\mid y, \\sigma) \\;=\\; \\sum_{i=1}^n \\log f(y_i \\mid \\mu, \\sigma),\n\\]\ndove \\(f(y_i \\mid \\mu, \\sigma)\\) è la densità normale.\nIn R:\n\nlog_likelihood &lt;- function(mu, y, sigma) {\n  sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))\n}\n\nCalcoliamo \\(\\ell(\\mu)\\) per valori di \\(\\mu\\) attorno alla media campionaria:\n\nmu_range &lt;- seq(mean(y) - 2 * sigma, mean(y) + 2 * sigma, length.out = 1000)\nlog_lik_values &lt;- sapply(mu_range, function(mu_val) log_likelihood(mu_val, y, sigma))\n\n\n39.8.2 Visualizzazione\n\nlibrary(ggplot2)\n\nggplot(\n  data.frame(mu = mu_range, log_likelihood = log_lik_values),\n  aes(x = mu, y = log_likelihood)\n) +\n  geom_line(linewidth = 1.2, color = \"steelblue\") +\n  geom_vline(xintercept = mean(y), linetype = \"dashed\", color = \"red\", linewidth = 1) +\n  labs(\n    x = expression(mu),\n    y = \"Log-verosimiglianza\"\n  ) +\n  annotate(\"text\", x = mean(y) + 2, y = max(log_lik_values) - 5,\n           label = paste0(\"Media campionaria = \", round(mean(y), 2)),\n           color = \"red\", hjust = 0)\n\n\n\n\n\n\n\n\n39.8.3 Interpretazione\nLa curva mostra come varia la log-verosimiglianza al variare di \\(\\mu\\):\n\nil massimo si ottiene in corrispondenza della media campionaria, come previsto;\nla forma è concava e parabolica, tipica del modello normale;\nla larghezza della curva riflette l’incertezza della stima.\n\nIn altre parole, lo stimatore di massima verosimiglianza (MLE) di \\(\\mu\\) è la media campionaria:\n\\[\n\\hat{\\mu}_{\\text{MLE}} = \\bar{y}.\n\\]\n\n39.8.4 Ottimizzazione numerica\nPossiamo verificare la stima tramite algoritmi di ottimizzazione:\n\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  -sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))\n}\n\nresult &lt;- optim(\n  par = mean(y),\n  fn = negative_log_likelihood,\n  y = y,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = min(mu_range),\n  upper = max(mu_range)\n)\n\nmu_optimal &lt;- result$par\ncat(\"Stima numerica di massima verosimiglianza per μ:\", round(mu_optimal, 4))\n#&gt; Stima numerica di massima verosimiglianza per μ: 30.9\n\nConfronto con la media campionaria:\n\nsample_mean &lt;- mean(y)\n\ndata.frame(\n  Metodo = c(\"Ottimizzazione numerica\", \"Media campionaria\"),\n  Valore = c(mu_optimal, sample_mean),\n  Differenza = c(NA, abs(mu_optimal - sample_mean))\n)\n#&gt;                    Metodo Valore Differenza\n#&gt; 1 Ottimizzazione numerica   30.9         NA\n#&gt; 2       Media campionaria   30.9    1.1e-11\n\nIn conclusione, la stima ottenuta con l’ottimizzazione coincide perfettamente con la media campionaria. Questo conferma il risultato teorico: per un campione indipendente da una normale con varianza nota, lo stimatore MLE della media è la media campionaria.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#il-rapporto-di-verosimiglianze",
    "href": "chapters/probability/16_likelihood.html#il-rapporto-di-verosimiglianze",
    "title": "39  La verosimiglianza",
    "section": "\n39.9 Il rapporto di verosimiglianze",
    "text": "39.9 Il rapporto di verosimiglianze\nIn statistica capita spesso di dover confrontare modelli alternativi che cercano di spiegare gli stessi dati osservati. Ad esempio, nella stima della media di una variabile psicologica (punteggi ai test, tempi di reazione, ecc.), potremmo avere due ipotesi contrastanti:\n\n\nModello nullo (\\(H_0\\)): la media assume un valore fissato \\(\\mu_1\\) (tipicamente un valore di riferimento o assenza di effetto);\n\nModello alternativo (\\(H_1\\)): la media assume un valore diverso \\(\\mu_2\\) (indicativo di un effetto o cambiamento).\n\nIl rapporto di verosimiglianze (Likelihood Ratio, LR) fornisce una misura quantitativa dell’evidenza relativa a favore di un modello rispetto all’altro, basandosi direttamente sui dati.\n\n39.9.1 Definizione formale\nIl rapporto di verosimiglianze è definito come\n\\[\n\\lambda \\;=\\; \\frac{L(\\mu_2 \\mid \\text{dati})}{L(\\mu_1 \\mid \\text{dati})},\n\\]\ndove:\n\n\n\\(L(\\mu_2 \\mid \\text{dati})\\) è la verosimiglianza sotto l’ipotesi alternativa,\n\n\\(L(\\mu_1 \\mid \\text{dati})\\) è la verosimiglianza sotto l’ipotesi nulla.\n\n39.9.2 Interpretazione\n\n\n\\(\\lambda &gt; 1\\): i dati favoriscono il modello alternativo;\n\n\\(\\lambda &lt; 1\\): i dati favoriscono il modello nullo;\n\n\\(\\lambda \\approx 1\\): i dati non discriminano tra i modelli.\n\nLa distanza dall’unità indica quanto più probabili sono i dati sotto un modello rispetto all’altro.\n\n39.9.3 Esempio: lancio di una moneta\nSupponiamo di osservare \\(x = 7\\) successi su \\(n = 10\\) lanci. Confrontiamo due modelli:\n\n\n\\(H_0\\): moneta equa (\\(\\theta = 0.5\\))\n\n\\(H_1\\): moneta sbilanciata verso il successo (\\(\\theta = 0.7\\))\n\n\n39.9.3.1 Calcolo analitico\nLa verosimiglianza binomiale è:\n\\[\nL(\\theta \\mid x, n) \\;=\\; \\binom{n}{x}\\,\\theta^x(1-\\theta)^{n-x}.\n\\]\nSostituendo i valori:\n\n\\(L(0.5) = 120 \\cdot (0.5)^{10} \\approx 0.117\\)\n\\(L(0.7) = 120 \\cdot (0.7)^7 (0.3)^3 \\approx 0.267\\)\n\nQuindi:\n\\[\n\\lambda = \\frac{0.267}{0.117} \\;\\approx\\; 2.28.\n\\]\n\n39.9.3.2 Implementazione in R\n\n# Parametri osservati\nn &lt;- 10\nx &lt;- 7\n\n# Verosimiglianze\nL_null &lt;- dbinom(x, n, 0.5)\nL_alt  &lt;- dbinom(x, n, 0.7)\nlambda &lt;- L_alt / L_null\n\ncat(\"L(H0, θ=0.5):\", round(L_null, 3), \"\\n\")\n#&gt; L(H0, θ=0.5): 0.117\ncat(\"L(H1, θ=0.7):\", round(L_alt, 3), \"\\n\")\n#&gt; L(H1, θ=0.7): 0.267\ncat(\"Rapporto di verosimiglianze λ:\", round(lambda, 2), \"\\n\")\n#&gt; Rapporto di verosimiglianze λ: 2.28\n\n\n39.9.3.3 Visualizzazione grafica\n\ntheta_seq &lt;- seq(0, 1, length.out = 1000)\nlikelihood_vals &lt;- dbinom(x, n, theta_seq)\n\ndf &lt;- data.frame(theta = theta_seq, likelihood = likelihood_vals)\n\nggplot(df, aes(x = theta, y = likelihood)) +\n  geom_line(linewidth = 1.2, color = \"steelblue\") +\n  geom_vline(xintercept = c(0.5, 0.7), linetype = \"dashed\",\n             color = c(\"red\", \"darkgreen\"), linewidth = 1) +\n  geom_point(aes(x = 0.5, y = L_null), color = \"red\", size = 3) +\n  geom_point(aes(x = 0.7, y = L_alt), color = \"darkgreen\", size = 3) +\n  labs(\n    x = expression(theta),\n    y = \"Verosimiglianza\"\n  ) +\n  annotate(\"text\", x = 0.5, y = L_null + 0.01, label = \"H₀: θ = 0.5\",\n           color = \"red\", hjust = -0.1) +\n  annotate(\"text\", x = 0.7, y = L_alt + 0.01, label = \"H₁: θ = 0.7\",\n           color = \"darkgreen\", hjust = -0.1) \n\n\n\n\n\n\n\n\n39.9.4 Interpretazione dei risultati\nIl valore \\(\\lambda \\approx 2.28\\) indica che i dati sono circa 2.3 volte più probabili sotto l’ipotesi alternativa rispetto all’ipotesi nulla. Si tratta di un’evidenza moderata ma non decisiva a favore dell’ipotesi che la moneta sia predisposta verso il successo.\n\n39.9.5 Considerazioni metodologiche\n\n\nEvidenza relativa: il rapporto di verosimiglianze non misura la bontà assoluta del modello, ma solo la preferenza relativa.\n\nScala di interpretazione: valori tra 1 e 3 suggeriscono un’evidenza debole-moderata, mentre valori più grandi indicano supporto crescente.\n\nGeneralità: la logica del LR si applica a qualsiasi modello parametrico.\n\nConnessione bayesiana: con prior poco informative, \\(\\lambda\\) si avvicina al fattore di Bayes, strumento principe della selezione di modelli in ottica bayesiana.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike",
    "href": "chapters/probability/16_likelihood.html#rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike",
    "title": "39  La verosimiglianza",
    "section": "\n39.10 Rapporti di verosimiglianza aggiustati e criterio di Akaike",
    "text": "39.10 Rapporti di verosimiglianza aggiustati e criterio di Akaike\nQuando si confrontano modelli statistici, occorre tenere presente che i modelli più complessi, dotati di un numero maggiore di parametri, tendono naturalmente a produrre un miglior adattamento ai dati osservati. Questo vantaggio, tuttavia, può dipendere solo dalla maggiore flessibilità del modello, senza riflettere una reale capacità esplicativa. Il fenomeno, noto come sovradattamento (overfitting), richiede quindi criteri che penalizzino opportunamente la complessità.\n\n39.10.1 Il ruolo dell’AIC\nIl Criterio di Informazione di Akaike (AIC) rappresenta una soluzione semplice ed efficace. La sua formulazione è:\n\\[\n\\text{AIC} = 2k - 2 \\log(L),\n\\] dove:\n\n\n\\(k\\) è il numero di parametri del modello,\n\n\\(L\\) è la massima verosimiglianza del modello.\n\nIn questo modo l’AIC combina due aspetti:\n\nla bontà di adattamento, catturata da \\(-2 \\log(L)\\);\nla parsimonia, garantita dal termine di penalizzazione \\(2k\\).\n\n39.10.2 Esempio: memoria visiva ed emozione\nSupponiamo di voler valutare l’effetto del contenuto emotivo delle immagini sulla memoria visiva. In un esperimento, 30 partecipanti per condizione hanno ottenuto:\n\nsuccessi_neutro &lt;- 14\nsuccessi_emozione &lt;- 22\nprove &lt;- 30\n\n\n39.10.2.1 Modello nullo (\\(H_0\\)): probabilità comune\n\n# Probabilità congiunta stimata\np_null &lt;- (successi_neutro + successi_emozione) / (2 * prove)\n\n# Log-verosimiglianza\nll_null &lt;- dbinom(successi_neutro, prove, p_null, log = TRUE) +\n           dbinom(successi_emozione, prove, p_null, log = TRUE)\n\n\n39.10.2.2 Modello alternativo (\\(H_1\\)): probabilità distinte\n\n# Probabilità stimate separatamente\np_neutro &lt;- successi_neutro / prove\np_emozione &lt;- successi_emozione / prove\n\n# Log-verosimiglianza\nll_alt &lt;- dbinom(successi_neutro, prove, p_neutro, log = TRUE) +\n          dbinom(successi_emozione, prove, p_emozione, log = TRUE)\n\n\n39.10.2.3 Confronto tramite AIC\n\nAIC_null &lt;- 2 * 1 - 2 * ll_null  # Modello con 1 parametro\nAIC_alt  &lt;- 2 * 2 - 2 * ll_alt   # Modello con 2 parametri\n\ndelta_AIC &lt;- AIC_alt - AIC_null\n\n\nUn valore di AIC più basso indica il modello preferito.\nDifferenze \\(&gt; 2\\) suggeriscono evidenza sostanziale a favore del modello migliore.\nDifferenze \\(&gt; 10\\) forniscono evidenza decisiva.\n\n39.10.2.4 Test del rapporto di verosimiglianza\n\nLR_stat &lt;- -2 * (ll_null - ll_alt)\np_value &lt;- pchisq(LR_stat, df = 1, lower.tail = FALSE)\n\n\n39.10.3 Interpretazione\nIl confronto tra modelli fornisce due prospettive complementari:\n\n\nAIC: valuta la qualità relativa dei modelli, bilanciando adattamento e complessità.\n\nRapporto di verosimiglianza: consente un test formale della differenza tra modelli.\n\nNell’esempio, il test produce \\(p \\approx 0.034\\), mentre l’AIC mostra una chiara preferenza per il modello alternativo. Entrambi i criteri concordano: il modello che assegna probabilità distinte ai due gruppi descrive meglio i dati, suggerendo che il contenuto emotivo delle immagini facilita la memoria visiva.\nIn conclusione, l’uso integrato di AIC e rapporti di verosimiglianza permette di prendere decisioni modellistiche fondate, evitando il rischio di sovradattamento. In psicologia, dove i dati sono spesso rumorosi e complessi, questo approccio consente di mantenere un equilibrio cruciale tra capacità esplicativa e parsimonia.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#riflessioni-conclusive",
    "href": "chapters/probability/16_likelihood.html#riflessioni-conclusive",
    "title": "39  La verosimiglianza",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa funzione di verosimiglianza rappresenta il fondamento concettuale e operativo dell’inferenza statistica moderna, fornendo un ponte metodologico tra modelli teorici ed evidenza empirica. La sua efficacia deriva dalla capacità di quantificare sistematicamente la plausibilità dei parametri di un modello condizionatamente ai dati osservati, creando così un collegamento formale tra astrazione teorica e osservazione sperimentale.\nL’impianto teorico della verosimiglianza si basa su tre componenti essenziali: la specificazione del modello probabilistico generatore dei dati, la definizione dello spazio parametrico e l’incorporazione delle osservazioni empiriche. Questo framework si dimostra particolarmente efficace nei modelli binomiali e gaussiani, dove assume forme analiticamente trattabili che facilitano sia la stima puntuale che la verifica di ipotesi.\nNel contesto della distribuzione normale, la stima di massima verosimiglianza del parametro μ coincide elegantemente con la media campionaria, mentre la rappresentazione grafica della funzione di verosimiglianza offre una visualizzazione immediata della precisione della stima. L’adozione della log-verosimiglianza, oltre a semplificare i calcoli analitici, garantisce una maggiore stabilità numerica, particolarmente valuable in contesti con campioni di grandi dimensioni o modelli complessi.\nIl rapporto di verosimiglianza si configura come uno strumento particolarmente versatile, in grado di bilanciare sofisticatamente la bontà di adattamento con il principio di parsimonia modellistica. Questo bilanciamento trova la sua espressione formale in criteri di selezione modellistica come l’AIC, che penalizzano appropriatamente la complessità parametrica evitando il sovradattamento.\nLa verosimiglianza, nelle sue molteplici manifestazioni, non si limita a collegare modelli teorici e dati empirici, ma costituisce il motore propulsivo dell’inferenza bayesiana. Attraverso il teorema di Bayes, la verosimiglianza trasforma sistematicamente l’informazione a priori in distribuzioni posteriori, aggiornando razionalmente le nostre credenze alla luce dell’evidenza osservata. Questo duplice ruolo - sia nell’ambito frequentista che in quello bayesiano - testimonia la profondità e l’utilità di questo strumento statistico fondamentale.\nLa padronanza dei concetti di verosimiglianza e log-verosimiglianza rappresenta quindi una competenza essenziale per lo psicologo ricercatore, permettendo non solo l’analisi appropriata dei dati sperimentali, ma anche la comprensione critica dei modelli teorici che sottendono i processi psicologici investigati.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nSpiega ciascuno dei concetti seguenti con una frase:\n\nprobabilità.\nfunzione di massa di probabilità.\nfunzione di densità di probabilità.\ndistribuzione di probabilità.\ndistribuzione di probabilità discreta.\ndistribuzione di probabilità continua.\nfunzione di distribuzione cumulativa (cdf).\nverosimiglianza\n\n\n\n\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nSupponi di aver misurato il livello di ansia (ad esempio usando una scala standardizzata) in un campione di 15 persone con i seguenti punteggi:\nansia &lt;- c(23, 27, 30, 29, 25, 28, 26, 24, 31, 29, 27, 26, 28, 30, 25)\nAssumendo che la deviazione standard sia nota e pari a 3.5, svolgi le seguenti attività in R:\n\nCalcola la funzione di verosimiglianza gaussiana per diversi valori di \\(\\mu\\) nell’intervallo da 20 a 35.\nTrova numericamente il valore di \\(\\mu\\) che rende massima la verosimiglianza (stima di massima verosimiglianza, MLE).\nDisegna un grafico della funzione di verosimiglianza per visualizzare il risultato.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood.html#bibliografia",
    "href": "chapters/probability/16_likelihood.html#bibliografia",
    "title": "39  La verosimiglianza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "L’Inferenza Bayesiana nella Ricerca Psicologica: Un Approccio Integrato\nNel campo della psicologia, la valutazione dell’efficacia di un trattamento clinico rappresenta una sfida metodologica centrale. Immaginiamo, per esempio, di voler testare l’utilità di una nuova psicoterapia per la depressione. Come possiamo concludere, in modo credibile, che il trattamento funzioni? L’approccio tradizionale, di matrice frequentista, risponde a questa domanda confrontando le medie dei punteggi tra un gruppo sperimentale e un gruppo di controllo, producendo un p-value. Questo valore quantifica quanto sarebbe improbabile osservare una differenza così grande o più estrema se il trattamento non avesse alcun effetto. Tuttavia, tale procedura presenta limiti sostanziali, soprattutto quando applicata a fenomeni complessi e variabili come quelli psicologici.",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html#linferenza-bayesiana-nella-ricerca-psicologica-un-approccio-integrato",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html#linferenza-bayesiana-nella-ricerca-psicologica-un-approccio-integrato",
    "title": "Introduzione",
    "section": "",
    "text": "Limiti dell’approccio frequentista nella ricerca applicata\nL’inferenza frequentista, pur ampiamente diffusa, non fornisce risposte alla domanda che davvero interessa chi fa ricerca: qual è la probabilità che il trattamento sia efficace, dati i risultati osservati? Il p-value non esprime questa probabilità, ma si riferisce alla possibilità di osservare i dati ottenuti assumendo che l’effetto non esista, ovvero sotto l’ipotesi nulla. È una misura indiretta e controfattuale, che spesso viene fraintesa.\nUn secondo limite importante è l’incapacità dell’approccio frequentista di integrare conoscenze pregresse. Ogni studio viene trattato come un evento isolato, ignorando le evidenze precedenti e le ipotesi teoriche consolidate. Inoltre, il confronto tra medie non permette di modellare i meccanismi psicologici sottostanti, come i processi di mediazione o moderazione, che sono invece centrali per comprendere il funzionamento degli interventi.\nVa considerato anche che la significatività statistica dipende fortemente dalla dimensione campionaria: un effetto piccolo può risultare “statisticamente significativo” in un campione molto ampio, e viceversa. Infine, la logica binaria “significativo/non significativo” imposta una dicotomia artificiosa su fenomeni che sono, per loro natura, continui e incerti. In psicologia, dove le sfumature e le differenze individuali sono cruciali, questa rigidità metodologica si rivela particolarmente problematica.\nL’approccio bayesiano: un’alternativa coerente e flessibile\nL’inferenza bayesiana propone un modo differente di pensare l’analisi dei dati: più naturale, flessibile e informativo. Si basa sull’idea che possiamo iniziare con una convinzione preliminare — rappresentata da una distribuzione a priori — e aggiornarla alla luce delle nuove osservazioni — attraverso la verosimiglianza — per ottenere una distribuzione a posteriori. Questo procedimento riflette il modo in cui ragioniamo quotidianamente. Per esempio, se ci svegliamo e vediamo il cielo coperto, possiamo stimare intuitivamente che c’è una probabilità del 70% che piova: un’inferenza soggettiva basata su esperienze pregresse, che può essere aggiornata osservando altri segnali, come il meteo sul telefono.\nApplicando questo approccio alla ricerca psicologica, possiamo non solo rispondere alla domanda se un trattamento funziona, ma anche formulare stime probabilistiche dirette sull’efficacia, integrare conoscenze precedenti e modellare i processi psicologici sottostanti. In questo contesto, il modello bayesiano consente una lettura più profonda dei dati, sia teoricamente che praticamente.\nUn Esempio Concreto: Modellizzazione di un Effetto di Mediazione con un Approccio Bayesiano\nIn psicologia clinica, spesso si ipotizza che un intervento non agisca direttamente su un esito, ma attraverso un meccanismo intermedio. Questo è noto come effetto di mediazione.\nConsideriamo un’ipotesi di ricerca comune: una psicoterapia (variabile indipendente, \\(X\\)) non riduce i sintomi depressivi (variabile dipendente, \\(Y\\)) in modo diretto, ma agendo su una variabile mediatrice, come l’autoefficacia (mediatore, \\(M\\)).\nIl modello di mediazione può essere scomposto in tre percorsi:\n\n\nPercorso a: L’effetto del trattamento (\\(X\\)) sul mediatore (\\(M\\)). La psicoterapia aumenta l’autoefficacia?\n\nPercorso b: L’effetto del mediatore (\\(M\\)) sull’esito (\\(Y\\)), tenendo sotto controllo l’effetto del trattamento. Una maggiore autoefficacia riduce la depressione?\n\nPercorso c’ (c-primo): L’effetto diretto del trattamento (\\(X\\)) sull’esito (\\(Y\\)), al netto del mediatore.\n\nL’effetto indiretto (o mediato) è quantificato dal prodotto dei percorsi a e b (\\(a \\times b\\)). L’approccio bayesiano è particolarmente potente per stimare questo effetto, poiché ci permette di ottenere una distribuzione di probabilità completa per \\(a \\times b\\), invece di un singolo valore puntuale e un p-value.\nPer illustrare, simuliamo dei dati in R che rispecchino la nostra ipotesi.\n\nset.seed(42)\nn_per_group &lt;- 40\nn &lt;- n_per_group * 2\n\n# Gruppo 0: Controllo, Gruppo 1: Trattamento\ngroup &lt;- rep(c(0, 1), each = n_per_group)\n\n# Path 'a': Il trattamento aumenta l'autoefficacia di circa 8 punti.\n# Aggiungiamo un termine di errore con deviazione standard 5.\na_path &lt;- 8\nself_efficacy &lt;- rnorm(n, mean = 40 + a_path * group, sd = 5)\n\n# Path 'b': Ogni punto di autoefficacia riduce la depressione di 0.7 punti.\n# Path 'c'': Ipotizziamo un piccolo effetto diretto del trattamento (-1.5 punti).\n# Aggiungiamo un termine di errore con deviazione standard 4.\nb_path &lt;- -0.7\nc_prime_path &lt;- -1.5\ndepression &lt;- rnorm(n, mean = 30 + b_path * self_efficacy + c_prime_path * group, sd = 4)\n\n# Creazione del dataframe\ndati &lt;- tibble(\n  group = factor(group, labels = c(\"Controllo\", \"Psicoterapia\")),\n  self_efficacy,\n  depression\n)\n\nUn Primo Sguardo: Confronto tra le Medie\nUn’analisi preliminare può confrontare i livelli medi di depressione tra i due gruppi.\n\ndati %&gt;%\n  group_by(group) %&gt;%\n  summarise(\n    media_depressione = mean(depression),\n    sd_depressione = sd(depression)\n  )\n#&gt; # A tibble: 2 × 3\n#&gt;   group        media_depressione sd_depressione\n#&gt;   &lt;fct&gt;                    &lt;dbl&gt;          &lt;dbl&gt;\n#&gt; 1 Controllo                 2.33           5.31\n#&gt; 2 Psicoterapia             -6.41           4.49\n\nQuesto mostra un effetto complessivo (il gruppo “Psicoterapia” ha una media di depressione più bassa), ma non ci permette di capire come l’intervento funzioni, ovvero se l’effetto sia mediato dall’autoefficacia.\nCostruzione del Modello di Mediazione Bayesiano\nPer stimare l’effetto indiretto, definiamo un sistema di due equazioni di regressione che corrispondono ai percorsi del nostro modello:\n\n\nModello per il mediatore (\\(M\\)): \\(self\\_efficacy \\sim \\mathcal{N}(\\alpha_M + a \\cdot group, \\sigma_M)\\)\n\n\nModello per l’esito (\\(Y\\)): \\(depression \\sim \\mathcal{N}(\\alpha_Y + c' \\cdot group + b \\cdot self\\_efficacy, \\sigma_Y)\\)\n\n\nUsiamo il pacchetto brms per fittare questi due modelli.\n\n# Modello 1: Stima del percorso 'a' (group -&gt; self_efficacy)\nfit1 &lt;- brm(\n  bf(self_efficacy ~ group),\n  data = dati,\n  family = gaussian(),\n  seed = 42,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n\n# Modello 2: Stima dei percorsi 'b' (self_efficacy -&gt; depression) e 'c'' (group -&gt; depression)\nfit2 &lt;- brm(\n  bf(depression ~ self_efficacy + group),\n  data = dati,\n  family = gaussian(),\n  seed = 42,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n\nStima e Interpretazione dell’Effetto Indiretto\nOra combiniamo i risultati. Estraiamo i campioni dalla distribuzione a posteriori per il coefficiente del percorso a (b_groupPsicoterapia da fit1) e per il percorso b (b_self_efficacy da fit2). Il loro prodotto ci fornirà la distribuzione a posteriori dell’effetto indiretto (\\(a \\times b\\)).\n\n# Estrazione dei campioni dalle distribuzioni a posteriori\npost_fit1 &lt;- as_draws_df(fit1)\npost_fit2 &lt;- as_draws_df(fit2)\n\n# Calcolo della distribuzione a posteriori dell'effetto indiretto\nindirect_effect &lt;- post_fit1$b_groupPsicoterapia * post_fit2$b_self_efficacy\n\nAnalizziamo la distribuzione dell’effetto indiretto calcolandone la media e l’intervallo di credibilità al 95%.\n\n# Media a posteriori\nmean(indirect_effect)\n#&gt; [1] -5.3\n\n# Intervallo di Credibilità al 95%\nquantile(indirect_effect, probs = c(0.025, 0.975))\n#&gt;  2.5% 97.5% \n#&gt; -7.30 -3.46\n\nL’analisi bayesiana restituisce una stima media dell’effetto indiretto di circa -5.4 e un intervallo di credibilità al 95% che va da circa -7.7 a -3.4.\nInterpretazione Clinica\nPoiché l’intervallo di credibilità non contiene lo zero, abbiamo una forte evidenza a favore di un effetto di mediazione. Possiamo comunicare il risultato in modo intuitivo e probabilistico:\n\n“C’è una probabilità del 95% che la riduzione media dei sintomi depressivi, attribuibile all’aumento di autoefficacia indotto dalla psicoterapia, sia compresa tra 3.4 e 7.7 punti sulla scala della depressione.”\n\nQuesta formulazione è più informativa di un semplice p-value. Non solo ci dice che l’effetto è “statisticamente significativo”, ma ne quantifica la magnitudine e la nostra incertezza su di essa, fornendo uno strumento molto più ricco per la valutazione clinica e la presa di decisioni. Invece di un p-value, otteniamo un intervallo di credibilità, ad esempio: “Con probabilità del 95%, l’intervento riduce la depressione attraverso l’autoefficacia di almeno 3.4 punti.” Questa formulazione è più intuitiva e direttamente utile per decisioni cliniche.\nVantaggi principali dell’inferenza bayesiana\nL’approccio bayesiano presenta diversi vantaggi chiave: le assunzioni del modello sono esplicitate attraverso le distribuzioni a priori; la modellizzazione è flessibile e adattabile a processi psicologici complessi; le conclusioni si esprimono in termini probabilistici e non binari; l’approccio si adatta bene anche a campioni piccoli, grazie all’incorporazione di conoscenze pregresse.\nApplicazioni pratiche\nL’inferenza bayesiana non è una curiosità teorica: è ampiamente utilizzata in moltissimi contesti applicativi. Nei sistemi di raccomandazione (Netflix, Spotify), le preferenze degli utenti vengono aggiornate in tempo reale attraverso modelli bayesiani. Nei test A/B su larga scala (Google, Meta), il framework bayesiano consente di monitorare gli esperimenti in tempo reale, di interromperli precocemente se necessario, e di sfruttare esperienze passate per informare nuovi studi.\nIn medicina, l’approccio bayesiano è implicito nel modo in cui i medici interpretano i test diagnostici: combinano la prevalenza della malattia, la sensibilità e la specificità del test per stimare la probabilità che il paziente sia malato. Lo stesso accade nella finanza comportamentale, nella guida autonoma e nell’epidemiologia, come dimostrato durante la pandemia da COVID-19, dove i modelli bayesiani hanno permesso di stimare in tempo reale la diffusione del virus e l’efficacia delle misure di contenimento.\nAnche nella ricerca psicologica l’inferenza bayesiana offre strumenti preziosi: consente di aggregare evidenze da studi precedenti, modellare la variabilità individuale, personalizzare gli interventi in tempo reale e formulare inferenze utili per la pratica clinica. È uno strumento che rafforza il legame tra teoria, dati e decisione.\nPerché queste applicazioni funzionano?\nIl successo dei metodi bayesiani si fonda su tre caratteristiche fondamentali: la capacità di aggiornarsi continuamente con l’arrivo di nuovi dati, l’integrazione sistematica delle conoscenze pregresse, e una gestione sofisticata dell’incertezza, che non si riduce a un singolo valore ma si esprime come una distribuzione completa.",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html#oltre-la-differenza-tra-medie-inferenza-bayesiana-unidimensionale",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html#oltre-la-differenza-tra-medie-inferenza-bayesiana-unidimensionale",
    "title": "Introduzione",
    "section": "Oltre la differenza tra medie: inferenza bayesiana unidimensionale",
    "text": "Oltre la differenza tra medie: inferenza bayesiana unidimensionale\nIn questa sezione esploreremo i fondamenti dell’inferenza bayesiana applicata alla stima di un singolo parametro scalare, una situazione molto frequente nella ricerca psicologica e nelle scienze sociali. Esempi tipici includono la stima della proporzione di pazienti che rispondono a un trattamento, della media di un punteggio di ansia in una popolazione, della frequenza di un evento raro, o della durata media di un episodio clinico.\nAnalizzeremo quattro modelli statistici fondamentali:\n\nil modello binomiale per la stima di proporzioni;\nil modello normale per la stima di medie di variabili continue;\nil modello di Poisson per il conteggio di eventi;\nil modello esponenziale per l’analisi del tempo tra eventi.\n\nPer ciascuno di questi modelli, approfondiremo il processo di aggiornamento bayesiano: come la verosimiglianza interagisce con la distribuzione a priori per produrre la distribuzione a posteriori. Presenteremo due metodi principali per ottenere quest’ultima: l’approssimazione numerica tramite griglia, adatta per problemi didattici e semplici, e l’impiego delle distribuzioni coniugate, che permettono soluzioni analitiche eleganti ed efficienti.\nDedicheremo particolare attenzione all’influenza delle scelte a priori, alla sintesi della distribuzione a posteriori attraverso medie, intervalli di credibilità e rappresentazioni grafiche, e al significato delle inferenze bayesiane in un contesto psicologico.\nNel quadro della crisi di replicabilità che ha colpito la psicologia, l’inferenza bayesiana si distingue come una risposta metodologica matura. Essa evita le decisioni arbitrarie basate su soglie di significatività e promuove un’interpretazione più sfumata, trasparente e cumulativa dei risultati empirici, aprendo la strada a una scienza psicologica più affidabile e teoricamente informata (Gelman et al., 2013; McElreath, 2020).",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html#bibliografia",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html#bibliografia",
    "title": "Introduzione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html",
    "href": "chapters/bayesian_inference/01_uncertainty.html",
    "title": "40  Abbracciare l’incertezza",
    "section": "",
    "text": "Introduzione\nNella ricerca psicologica, così come in tutte le scienze empiriche, i dati che raccogliamo non sono mai privi di incertezza. Ogni misura, ogni stima e ogni conclusione che traiamo si accompagnano a un margine di dubbio. Comprendere e gestire questa incertezza non è un dettaglio tecnico, ma una parte essenziale del lavoro scientifico.\nQuando chiediamo a un campione di studenti universitari di valutare il proprio livello di ansia su una scala da 1 a 5, non otteniamo una misura perfetta e definitiva del “vero” livello di ansia. Otteniamo invece una stima influenzata da molte fonti di variabilità: la situazione contingente (per esempio, se quel giorno c’era un esame imminente), le caratteristiche individuali, e l’inevitabile errore di misura.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#introduzione",
    "href": "chapters/bayesian_inference/01_uncertainty.html#introduzione",
    "title": "40  Abbracciare l’incertezza",
    "section": "",
    "text": "40.0.1 Perché parlare di incertezza?\nIl concetto di incertezza ci obbliga a distinguere tra:\n\nciò che osserviamo direttamente (i dati raccolti);\nciò che vogliamo inferire (le proprietà psicologiche latenti, come ansia, autostima, motivazione).\n\nIn altre parole, l’incertezza è il ponte che collega i nostri dati grezzi alle conclusioni scientifiche. Ignorarla porta a una falsa sensazione di sicurezza; affrontarla in modo esplicito ci consente invece di fare affermazioni più oneste e più utili (Lindley, 2013).\n\n40.0.2 Dal dubbio al metodo\nParlare di incertezza non significa arrendersi al relativismo. Significa piuttosto riconoscere che ogni conclusione scientifica deve essere accompagnata da una valutazione della sua affidabilità. La psicologia, che si confronta con fenomeni complessi e variabili, ha un bisogno particolare di metodi che rendano questa valutazione trasparente e rigorosa.\nPanoramica del capitolo\n\nLa psicologia si confronta sempre con variabilità e incertezza nei dati.\nAbbiamo distinto tre forme di incertezza: aleatoria, epistemica, ontologica.\nL’approccio bayesiano offre un modo intuitivo per rappresentare e aggiornare le nostre convinzioni.\nLe credenze iniziali orientano la ricerca, i dati le modificano, le decisioni ne sono il risultato.\nLa crisi di replicazione mostra l’importanza di trattare l’incertezza in modo esplicito e trasparente.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il primo capitolo di Understanding Uncertainty di Lindley (Lindley, 2013).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(HDInterval)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#variabilità-e-incertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#variabilità-e-incertezza",
    "title": "40  Abbracciare l’incertezza",
    "section": "\n40.1 Variabilità e incertezza",
    "text": "40.1 Variabilità e incertezza\nQuando osserviamo un fenomeno psicologico, raramente troviamo valori identici tra i soggetti o persino nello stesso soggetto in momenti diversi. Questa variabilità è un fatto fondamentale della psicologia sperimentale: due studenti possono riportare livelli molto diversi di ansia prima di un esame, oppure lo stesso studente può mostrare oscillazioni da un giorno all’altro. La variabilità dei dati non è un ostacolo, ma un’informazione preziosa: ci dice che i processi psicologici non sono rigidi, bensì dinamici e influenzati da molteplici fattori.\nTuttavia, per passare dalla semplice descrizione (le misure raccolte) all’inferenza (conclusioni sui processi sottostanti) dobbiamo fare i conti con l’incertezza. L’incertezza non è altro che il riconoscimento formale del fatto che:\n\nnon possiamo mai conoscere con certezza assoluta i parametri psicologici reali (es. il “vero” livello di ansia di un individuo);\ni dati che raccogliamo sono solo una finestra parziale e rumorosa su questi parametri.\n\n\n\n\n\n\n\nEsempio\n\n\n\nImmaginiamo di stimare il punteggio medio di autostima in un campione di 50 studenti usando la Rosenberg Self-Esteem Scale. Il valore medio osservato (ad esempio, 28 punti) non è il “vero” livello medio della popolazione: è solo una stima, soggetta a oscillazioni dovute al caso. Se ripetessimo l’indagine con un altro campione di 50 studenti della stessa università, otterremmo quasi sicuramente un valore diverso (magari 27 o 29). Questa differenza riflette l’incertezza insita nel nostro processo di misurazione.\n\n\n\n40.1.1 Perché l’incertezza è cruciale in psicologia?\nIn discipline come la fisica, spesso si assume che i fenomeni abbiano leggi relativamente stabili. In psicologia, invece, i fenomeni sono complessi, soggetti a influenze contestuali, sociali e individuali. L’incertezza non è quindi un “rumore da eliminare”, ma un aspetto strutturale che dobbiamo modellare.\nNella ricerca psicologica, ignorare l’incertezza ha avuto conseguenze gravi: risultati poco replicabili, fiducia eccessiva nei valori “puntuali” delle stime, e difficoltà a distinguere effetti reali da fluttuazioni casuali. La crisi di replicazione in psicologia ci ricorda che non basta riportare un effetto medio; dobbiamo anche comunicare quanto siamo incerti su quell’effetto.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#fonti-di-incertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#fonti-di-incertezza",
    "title": "40  Abbracciare l’incertezza",
    "section": "\n40.2 Fonti di incertezza",
    "text": "40.2 Fonti di incertezza\nL’incertezza nei dati psicologici può avere origini diverse. È utile distinguere più tipi di incertezza. Questa classificazione non è un dettaglio teorico: ci aiuta a chiarire che cosa possiamo conoscere, che cosa rimane imprevedibile e quali sono i limiti dei nostri modelli. In particolare, distinguiamo tre categorie.\n\n40.2.1 1. Incertezza aleatoria\nÈ l’incertezza che deriva dall’imprevedibilità intrinseca dei fenomeni.\n\nAnche conoscendo tutti i fattori rilevanti, non potremmo determinare con certezza l’esito di un singolo evento.\nQuesta incertezza è quindi irriducibile: non possiamo eliminarla raccogliendo più dati.\n\nEsempio psicologico: in un compito di apprendimento associativo, lo stesso soggetto può occasionalmente dare la risposta “sbagliata” pur avendo appreso la regola, semplicemente perché i processi cognitivi e attentivi non sono perfettamente deterministici.\n\n40.2.2 2. Incertezza epistemica\nÈ l’incertezza che deriva dalla nostra conoscenza limitata.\n\nRiguarda il fatto che non osserviamo mai tutto: lavoriamo con dati parziali, campioni limitati e strumenti imperfetti.\nA differenza dell’incertezza aleatoria, questa può essere ridotta raccogliendo più dati o costruendo modelli migliori.\n\nEsempio psicologico: quando stimiamo il livello medio di ansia negli studenti prima di un esame, il campione che osserviamo ci fornisce solo una fotografia parziale. Con un campione più ampio o più rappresentativo, la nostra incertezza sulla media della popolazione si ridurrebbe.\n\n40.2.3 3. Incertezza ontologica (o “modellistica”)\nÈ l’incertezza che riguarda l’adeguatezza stessa del nostro modello.\n\nTutti i modelli sono semplificazioni: la vera complessità del comportamento umano non può mai essere catturata in modo completo.\nQuesta incertezza non è legata alla quantità di dati che raccogliamo, ma alla cornice teorica e metodologica che scegliamo per interpretarli.\n\nEsempio psicologico: se usiamo un modello di regressione lineare per descrivere la relazione tra stress e rendimento accademico, sappiamo che stiamo trascurando fattori come le dinamiche temporali, le interazioni sociali o l’influenza culturale.\n\n\n\n\n\n\nSintesi\n\n\n\n\n\nAleatoria → variabilità intrinseca del fenomeno (non eliminabile).\n\nEpistemica → limiti della nostra conoscenza (riducibile con più dati e strumenti migliori).\n\nOntologica → limiti dei nostri modelli (nessun modello è “vero”, solo più o meno utile).\n\nQuesta distinzione ci aiuta a non confondere diversi tipi di incertezza e a non attribuire agli strumenti statistici poteri che non hanno. Nel resto del capitolo vedremo come questi concetti possano essere resi più precisi e operativi.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#la-quantificazione-dellincertezza-nellapproccio-bayesiano",
    "href": "chapters/bayesian_inference/01_uncertainty.html#la-quantificazione-dellincertezza-nellapproccio-bayesiano",
    "title": "40  Abbracciare l’incertezza",
    "section": "\n40.3 La quantificazione dell’incertezza nell’approccio bayesiano",
    "text": "40.3 La quantificazione dell’incertezza nell’approccio bayesiano\nFinora abbiamo distinto diversi tipi di incertezza. Ma come possiamo rappresentarli in modo sistematico? L’approccio bayesiano fornisce una cornice molto potente, che useremo in tutto il libro.\nL’idea di base è semplice:\n\ninvece di parlare di una stima unica (per esempio, “il livello medio di ansia è 28”), parliamo di un insieme di valori possibili, ciascuno con un diverso grado di plausibilità.\nin questo modo, non diciamo soltanto quale valore ci sembra più probabile, ma anche quanto siamo incerti riguardo a questa conclusione.\n\n\n\n\n\n\n\nIntuizione\n\n\n\nPensiamo a un professore che, dopo il primo compito scritto, prova a immaginare come andrà l’esame finale di uno studente. Non può dare una previsione precisa: può solo dire che “probabilmente andrà così, ma potrebbe anche andare un po’ meglio o un po’ peggio”. Questa gamma di possibilità, con diverse gradazioni di plausibilità, è esattamente il modo in cui il pensiero bayesiano rappresenta l’incertezza.\n\n\n\n40.3.1 Dal punto di vista bayesiano\n\nPrima di raccogliere i dati, abbiamo sempre delle aspettative iniziali (ad esempio: “la media dell’ansia negli studenti è probabilmente intorno a un certo valore, ma potrebbe variare”).\nDopo aver raccolto i dati, aggiorniamo queste aspettative alla luce delle nuove osservazioni.\nIl risultato non è una singola risposta definitiva, ma una rappresentazione più informata della nostra incertezza.\n\nQuesto processo di aggiornamento delle credenze è il cuore del pensiero bayesiano: partiamo da ciò che già sappiamo o supponiamo, e lo correggiamo in base a ciò che osserviamo.\n\n40.3.2 Perché è utile in psicologia?\nIn psicologia ci confrontiamo continuamente con fenomeni complessi e variabili. L’approccio bayesiano ci permette di:\n\nesprimere in modo trasparente i nostri dubbi e le nostre ipotesi;\nintegrare informazioni provenienti da studi precedenti, teoria o esperienza clinica;\nrappresentare l’incertezza in modo chiaro, senza nasconderla dietro a valori unici e definitivi.\n\n40.3.3 Un esempio intuitivo: la moneta\nImmaginiamo di lanciare una moneta. Non sappiamo se sia perfettamente equilibrata, quindi non possiamo dire con certezza quale sarà il risultato del prossimo lancio. Quello che possiamo fare è descrivere le nostre credenze:\n\nse crediamo che la moneta sia equilibrata, attribuiremo circa la stessa probabilità a testa e croce;\nse dopo 10 lanci osserviamo 8 teste e 2 croci, saremo portati ad aggiornare questa convinzione, ritenendo più plausibile che la moneta “favorisca” la testa.\n\nQuello che cambia non è la moneta, ma la nostra conoscenza: l’approccio bayesiano formalizza proprio questo processo di aggiornamento.\n\n40.3.4 Un esempio psicologico parallelo\nSupponiamo di chiedere a 10 studenti di valutare il proprio livello di ansia prima di un esame, su una scala da 1 a 5.\n\nPrima di raccogliere i dati, potremmo pensare che “probabilmente” il punteggio medio sarà intorno a 3, ma non ne siamo sicuri.\nDopo aver raccolto le prime risposte, vediamo che 8 studenti riportano valori tra 4 e 5. Questo ci porta ad aggiornare la nostra convinzione: la media vera non è probabilmente 3, ma più alta.\n\nAncora una volta, non otteniamo una certezza assoluta, ma una nuova rappresentazione della nostra incertezza informata dai dati.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nL’approccio bayesiano non elimina l’incertezza: la rende esplicita e gestibile. Parla sempre in termini di plausibilità relativa: quanto un’ipotesi è più o meno credibile rispetto ad altre, alla luce dei dati.\n\n\n\n40.3.5 Il ruolo delle credenze e delle decisioni nella ricerca psicologica\nL’approccio bayesiano parte da un’osservazione semplice ma spesso trascurata: ogni ricerca comincia con delle credenze.\nQuando uno psicologo progetta uno studio, ha già delle aspettative:\n\ncrede che una nuova terapia possa ridurre i sintomi di depressione,\noppure che l’ansia aumenti in prossimità di un esame,\no ancora che i processi di apprendimento differiscano tra adolescenti e adulti.\n\nQueste credenze non sono “pregiudizi” da evitare, ma punti di partenza espliciti. Nel quadro bayesiano, le credenze iniziali vengono dichiarate apertamente e poi messe alla prova dei dati.\n\n40.3.5.1 Credenze che si aggiornano\nUn esempio: immaginiamo di ipotizzare che la pratica della mindfulness riduca i livelli di stress negli studenti universitari.\n\nPrima di raccogliere i dati, potremmo ritenere “piuttosto plausibile” un effetto positivo.\nDopo l’esperimento, se i dati mostrano una riduzione chiara, aggiorniamo la nostra convinzione rendendola più forte.\nSe invece i dati non confermano l’effetto, ridimensioniamo la nostra aspettativa.\n\nIl punto non è avere “ragione o torto”, ma imparare qualcosa di nuovo aggiornando in modo coerente le nostre credenze.\n\n40.3.5.2 Dalle credenze alle decisioni\nLe ricerche psicologiche non finiscono nei dati: portano sempre a delle decisioni pratiche:\n\nuno psicologo clinico deve decidere se raccomandare una terapia;\nun docente deve scegliere se modificare il proprio metodo di insegnamento;\nun ricercatore deve decidere se valga la pena replicare uno studio.\n\nL’approccio bayesiano fornisce un quadro chiaro per queste scelte: non dice “questo risultato è certo”, ma piuttosto “date le nostre conoscenze, alcune opzioni sono più plausibili e più prudenti di altre”.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\n\nLe credenze iniziali orientano la ricerca: non partiamo mai da zero.\nI dati ci permettono di aggiornarle in modo coerente.\nLe decisioni si basano non sulla certezza assoluta, ma sulla valutazione esplicita dell’incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#lincertezza-e-la-crisi-di-replicazione-in-psicologia",
    "href": "chapters/bayesian_inference/01_uncertainty.html#lincertezza-e-la-crisi-di-replicazione-in-psicologia",
    "title": "40  Abbracciare l’incertezza",
    "section": "\n40.4 L’incertezza e la crisi di replicazione in psicologia",
    "text": "40.4 L’incertezza e la crisi di replicazione in psicologia\nLa crisi di replicazione che ha attraversato la psicologia negli ultimi anni ha messo in luce un aspetto fondamentale: molti risultati della ricerca non erano così solidi come sembravano. Studi che riportavano effetti “statisticamente significativi” non sono stati replicati con la stessa forza o, in alcuni casi, non sono stati replicati affatto (Collaboration, 2015).\nUna delle cause principali è stata la sottovalutazione dell’incertezza:\n\nspesso i ricercatori comunicavano i risultati come se fossero certezze definitive, quando in realtà derivavano da campioni piccoli, da strumenti imperfetti e da modelli molto semplificati;\nL’incertezza era presente, ma non veniva rappresentata né discussa in modo trasparente.\n\n\n40.4.1 Un esempio concreto\nImmaginiamo uno studio che trova un aumento dell’autostima dopo un breve training motivazionale. Il risultato viene presentato come una scoperta solida. Ma se guardiamo meglio, scopriamo che:\n\nil campione era di appena 20 studenti,\nla variabilità delle risposte era alta,\nl’effetto osservato poteva essere in parte dovuto al caso.\n\nReplicando lo studio con un nuovo campione, l’effetto non si ripresenta: non perché fosse “falso” in senso assoluto, ma perché l’incertezza era stata trascurata nella prima analisi.\n\n40.4.2 Il ruolo dell’approccio bayesiano\nL’approccio bayesiano non elimina l’incertezza — e non pretende di farlo. Al contrario, la rende esplicita. Invece di dare un unico numero come se fosse definitivo, descrive un insieme di valori plausibili, con i loro gradi di credibilità.\nQuesta trasparenza è un antidoto alla crisi di replicazione:\n\npermette di comunicare meglio quanto un risultato sia fragile o robusto,\naiuta a distinguere tra effetti realmente consistenti e semplici fluttuazioni dovute al caso o a campioni ridotti,\nrende più facile confrontare e integrare i risultati di studi diversi.\n\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nLa crisi di replicazione ci ricorda che ignorare l’incertezza porta a conclusioni illusorie. Un approccio che riconosce e rappresenta l’incertezza — come quello bayesiano — non garantisce repliche perfette, ma favorisce una scienza più onesta, trasparente e cumulativa.\n\n\n\n\n\n\n\n\n\nFigura 40.1: Effetto della dimensione campionaria sull’incertezza della stima (media). A sinistra (n=20) la distribuzione delle stime della media è più larga: molte realizzazioni possibili. A destra (n=200) la distribuzione è più concentrata intorno al valore “vero” (linea tratteggiata). Questo illustra come l’incertezza sulla stima si riduca con campioni più grandi — un punto chiave per comprendere la replicabilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/01_uncertainty.html#riflessioni-conclusive",
    "title": "40  Abbracciare l’incertezza",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto che l’incertezza non è un difetto dei dati psicologici, ma una loro caratteristica fondamentale.\nAbbiamo distinto tre forme di incertezza:\n\n\naleatoria, legata all’imprevedibilità intrinseca dei fenomeni;\n\nepistemica, che riflette i limiti della nostra conoscenza e può ridursi con più dati o modelli migliori;\n\nontologica, che riguarda i limiti dei nostri modelli e ci ricorda che ogni descrizione è sempre una semplificazione.\n\nAbbiamo poi introdotto l’intuizione dell’approccio bayesiano: invece di cercare una certezza definitiva, rappresentiamo sempre una gamma di possibilità, con diversi gradi di plausibilità. In questo modo possiamo aggiornare le nostre convinzioni alla luce dei dati e prendere decisioni più consapevoli.\nInfine, abbiamo collegato questi concetti alla crisi di replicazione in psicologia, mostrando come la sottovalutazione dell’incertezza abbia portato a risultati fragili. Riconoscere e rappresentare l’incertezza non elimina il problema, ma favorisce una scienza più trasparente e cumulativa.\n\n\n\n\n\n\nSintesi finale\n\n\n\nL’incertezza non è un ostacolo da eliminare, ma il punto di partenza per una pratica scientifica più onesta. Il pensiero bayesiano ci offre un linguaggio e un metodo per affrontarla in modo esplicito, e nei prossimi capitoli vedremo come tradurre questa intuizione in strumenti concreti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#bibliografia",
    "href": "chapters/bayesian_inference/01_uncertainty.html#bibliografia",
    "title": "40  Abbracciare l’incertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html",
    "href": "chapters/bayesian_inference/02_intro_bayes.html",
    "title": "41  La quantificazione dell’incertezza",
    "section": "",
    "text": "Introduzione\nNel capitolo precedente abbiamo visto che l’incertezza è una componente inevitabile della ricerca psicologica. Abbiamo distinto diversi tipi di incertezza e abbiamo mostrato come l’approccio bayesiano offra un linguaggio per rappresentarla in modo esplicito.\nIn questo capitolo iniziamo a costruire gli strumenti tecnici di base del pensiero bayesiano. L’obiettivo non è ancora quello di entrare nei dettagli matematici, ma di sviluppare un’intuizione solida su alcuni concetti chiave:\nL’idea centrale è che il metodo bayesiano funziona come un processo di aggiornamento coerente delle credenze: partiamo da ciò che sappiamo, osserviamo i dati, e arriviamo a conclusioni più raffinate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#introduzione",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#introduzione",
    "title": "41  La quantificazione dell’incertezza",
    "section": "",
    "text": "Credenze iniziali (priori): come rappresentare ciò che sappiamo o supponiamo prima di raccogliere i dati.\n\nDati (likelihood): come descrivere formalmente l’informazione che proviene dall’osservazione empirica.\n\nCredenze aggiornate (posteriori): come combinare priori e dati per ottenere una descrizione più informata dell’incertezza.\n\n\n\n\n\n\n\n\nIntuizione\n\n\n\nIl pensiero bayesiano non elimina il dubbio, ma ci permette di trattarlo in modo sistematico: i dati non sostituiscono le nostre ipotesi, ma le trasformano.\n\n\nPanoramica del capitolo\n\nCome quantificare e rappresentare matematicamente l’incertezza attraverso le distribuzioni di densità.\nIl processo di integrazione delle nuove evidenze con le conoscenze preesistenti.\nCome i parametri sconosciuti determinano i dati osservati attraverso processi probabilistici.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Bayesian statistics for clinical research di Goligher et al. (2024).\nLeggere Dicing with the unknown di Tony O’Hagan, per una descrizione chiara della distinzione tra incertezza aleatoria e incertezza epistemica.\nLeggere il capitolo Estimation (Schervish & DeGroot, 2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#lincertezza-come-distribuzione-di-probabilità",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#lincertezza-come-distribuzione-di-probabilità",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.1 L’incertezza come distribuzione di probabilità",
    "text": "41.1 L’incertezza come distribuzione di probabilità\nFinora abbiamo parlato di incertezza in modo concettuale. Ora facciamo un passo in più: impariamo a rappresentarla formalmente.L’idea di base è che l’incertezza non si descrive con un singolo valore, ma con una gamma di valori possibili, a ciascuno dei quali attribuiamo un grado di plausibilità. Questo insieme di valori e plausibilità è ciò che chiamiamo distribuzione di probabilità.\n\n41.1.1 Un esempio intuitivo\nSupponiamo di stimare il livello medio di ansia negli studenti prima di un esame.\n\nNon sappiamo con certezza quale sia: potrebbe essere 2.8, oppure 3.1, o forse 3.5 su una scala da 1 a 5.\nAlcuni valori ci sembrano più plausibili di altri. Per esempio, 3.0 è più verosimile di 1.0 o di 5.0.\nPossiamo quindi rappresentare la nostra incertezza con una curva che assegna più “peso” ai valori plausibili e meno a quelli estremi.\n\n41.1.2 Perché usare distribuzioni?\nUsare distribuzioni di probabilità per rappresentare l’incertezza ha due vantaggi fondamentali:\n\n\nTrasparenza: invece di fingere di conoscere un valore preciso, dichiariamo chiaramente quanto siamo incerti.\n\nFlessibilità: possiamo aggiornare la distribuzione quando raccogliamo nuovi dati, vedendo come la nostra rappresentazione dell’incertezza cambia.\n\n41.1.3 Collegamento con la psicologia\nQuesta idea non vale solo per punteggi medi, ma per qualsiasi parametro di interesse psicologico:\n\nla forza di un effetto terapeutico,\nla relazione tra ansia e rendimento,\nla probabilità che un soggetto scelga una certa opzione in un compito cognitivo.\n\nIn tutti questi casi, non possiamo mai dire “il valore vero è X”: possiamo solo attribuire una distribuzione di probabilità ai possibili valori.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nRappresentare l’incertezza come una distribuzione di probabilità significa passare da una visione rigida (“il valore è uno solo”) a una visione più realistica e informativa (“alcuni valori sono più plausibili di altri”).\n\n\n\n\n\n\n\n\n\nFigura 41.1: Rappresentare l’incertezza sulla media dell’ansia come distribuzione di probabilità.\n\n\n\n\n\n41.1.4 La natura dinamica dell’incertezza bayesiana\nUn aspetto fondamentale dell’approccio bayesiano è che l’incertezza non è statica. Non rimaniamo bloccati nella distribuzione iniziale che assegniamo ai valori possibili: ogni volta che osserviamo nuovi dati, aggiorniamo la distribuzione.\nIn questo modo, la rappresentazione dell’incertezza è dinamica: evolve con l’accumularsi delle informazioni.\nEsempio psicologico:\n\nPrima di raccogliere i dati, possiamo pensare che la media dell’ansia degli studenti prima di un esame sia plausibilmente intorno a 3.\nDopo aver osservato le prime risposte, la distribuzione si sposta: se molti studenti riportano valori alti, la parte destra della curva diventa più plausibile.\nSe in seguito raccogliamo ancora più dati, la curva si restringe, riflettendo una maggiore precisione nelle nostre stime.\n\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nNel pensiero bayesiano, l’incertezza è viva: si muove, si aggiorna e si affina ogni volta che impariamo qualcosa di nuovo dai dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#le-fondamenta-concettuali-dellinferenza-bayesiana",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#le-fondamenta-concettuali-dellinferenza-bayesiana",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.2 Le fondamenta concettuali dell’inferenza bayesiana",
    "text": "41.2 Le fondamenta concettuali dell’inferenza bayesiana\nL’approccio bayesiano si fonda su un’idea semplice: ogni volta che raccogliamo dati, possiamo aggiornare in modo coerente le nostre credenze. Questa idea è riassunta in una formula molto celebre: il teorema di Bayes.\n\\[\nP(\\text{Ipotesi} \\mid \\text{Dati}) \\;=\\;\n\\frac{P(\\text{Dati} \\mid \\text{Ipotesi}) \\; \\times \\; P(\\text{Ipotesi})}{P(\\text{Dati})}\n\\]\n\n41.2.1 Intuizione della formula\n\n\n\\(P(\\text{Ipotesi})\\) → la nostra convinzione iniziale, detta prior (“quanto credevo plausibile questa ipotesi prima di raccogliere i dati”).\n\n\\(P(\\text{Dati} \\mid \\text{Ipotesi})\\) → la compatibilità tra l’ipotesi e ciò che osserviamo, detta verosimiglianza o likelihood.\n\n\\(P(\\text{Ipotesi} \\mid \\text{Dati})\\) → la convinzione aggiornata, detta posterior (“quanto credo plausibile questa ipotesi dopo aver visto i dati”).\n\n\\(P(\\text{Dati})\\) → un fattore di normalizzazione: garantisce che tutte le ipotesi considerate abbiano probabilità che sommano a 1.\n\nIn sintesi:\n\\[\n\\text{Posterior} \\;\\propto\\; \\text{Likelihood} \\times \\text{Prior}\n\\]\n\n41.2.2 Un esempio psicologico\nImmaginiamo di voler valutare se un nuovo training cognitivo riduce l’ansia negli studenti.\n\nPrima di raccogliere i dati, abbiamo una convinzione iniziale: pensiamo che l’effetto sia possibile, ma non ne siamo sicuri (prior).\nDopo aver somministrato il training a un piccolo gruppo, osserviamo una riduzione dell’ansia (dati). Questi dati sono più compatibili con l’ipotesi “il training funziona” che con “il training non funziona” (likelihood).\nCombinando le due cose otteniamo una nuova convinzione più informata (posterior): l’ipotesi che il training riduca l’ansia diventa più plausibile, ma con un margine di incertezza che continueremo a considerare.\n\n41.2.3 Perché è importante?\nl teorema di Bayes non è solo una formula: è un principio di ragionamento. Ci dice come passare in modo sistematico da ciò che sappiamo prima (priori) a ciò che sappiamo dopo aver osservato i dati (posteriori). Questa struttura ci permette di integrare teoria e dati in modo coerente, esplicitare le assunzioni iniziali e rappresentare sempre l’incertezza residua.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nIl teorema di Bayes è la regola che collega credenze iniziali, dati osservati e credenze aggiornate. Non elimina l’incertezza, ma ci mostra come aggiornarla in modo coerente.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#laggiornamento-bayesiano-in-azione-lesempio-del-globo-terrestre",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#laggiornamento-bayesiano-in-azione-lesempio-del-globo-terrestre",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.3 L’aggiornamento bayesiano in azione: l’esempio del globo terrestre",
    "text": "41.3 L’aggiornamento bayesiano in azione: l’esempio del globo terrestre\nPer capire come funziona concretamente il teorema di Bayes, immaginiamo un esperimento mentale proposto da McElreath nel suo testo Statistical Rethinking (McElreath, 2020). Abbiamo davanti a noi un globo terrestre (una sfera blu e marrone) e ci poniamo una domanda:\n\n“Quale proporzione della superficie terrestre è coperta da acqua?”\n\nSappiamo che gran parte del pianeta è mare, ma non conosciamo la percentuale precisa. Vogliamo stimarla con un piccolo “esperimento casuale”.\n\n41.3.1 Il setup sperimentale\nChiamiamo \\(p\\) la vera proporzione di superficie coperta d’acqua. Questo è il nostro parametro di interesse: il numero che vogliamo stimare.\nOgni volta che facciamo girare il globo e puntiamo il dito otteniamo un’osservazione:\n\n\nW se tocchiamo acqua,\n\nL se tocchiamo terra.\n\nIl nostro modello dei dati assume che ogni lancio sia indipendente e che la probabilità di osservare acqua sia proprio \\(p\\).\nAll’inizio non sappiamo nulla di preciso: potremmo allora assegnare a \\(p\\) una distribuzione a priori uniforme, cioè ritenere ogni valore compreso tra 0 e 1 ugualmente plausibile. Questo rappresenta uno stato di “ignoranza informativa”: nessuna preferenza iniziale per alcuni valori rispetto ad altri.\n\n41.3.2 La dinamica dell’apprendimento\n\nPrimo lancio → osserviamo “W” (acqua). Ora valori molto bassi di \\(p\\) diventano poco plausibili (se \\(p\\) fosse vicino a 0, sarebbe stato molto improbabile ottenere acqua al primo colpo). La distribuzione a posteriori si sposta, assegnando più probabilità a valori alti di \\(p\\).\nSecondo lancio → otteniamo “L” (terra). Questo dato porta nella direzione opposta: valori molto alti di \\(p\\) diventano meno plausibili. La distribuzione a posteriori si “riequilibra”, privilegiando valori intermedi.\n\nCon ogni nuova osservazione, il quadro cambia: nessun dato singolo è definitivo, ma ciascuno contribuisce a modificare il profilo della nostra incertezza.\n\n41.3.3 L’accumulo progressivo dell’evidenza\nImmaginiamo di osservare la sequenza: W, L, W, W, L, W, L, W, W.\n\nDopo ogni lancio, la distribuzione si aggiorna.\nOgni posterior diventa automaticamente il prior per il passo successivo.\nIn questo modo, l’apprendimento è cumulativo: non scartiamo mai le informazioni già raccolte, ma le integriamo con le nuove.\n\nQuesta è l’essenza dell’approccio bayesiano: una catena continua di aggiornamento delle credenze.\n\n41.3.4 L’evoluzione dell’incertezza\nUn punto cruciale è che non si aggiorna solo la stima più plausibile di \\(p\\), ma anche la larghezza della distribuzione:\n\ncon pochi dati, la distribuzione è ampia → riflette grande incertezza;\ncon più osservazioni, la distribuzione diventa più stretta → la nostra conoscenza si affina;\nla velocità e la forma del restringimento dipendono dai dati: sequenze molto coerenti riducono l’incertezza rapidamente, sequenze più variabili la riducono gradualmente.\n\n\n\n\n\n\n\n\n\n\n41.3.5 Come leggere il grafico\nIn ogni pannello, la linea grigia mostra il prior (prima dell’osservazione), e la linea blu il posterior (dopo l’osservazione). Si vede chiaramente come, passo dopo passo, la curva blu si restringa e si concentri intorno ai valori più compatibili con i dati. Ogni distribuzione aggiornata diventa la nuova base di partenza per il passo successivo.\nQuesto esempio mostra in modo concreto che l’inferenza bayesiana non cerca “una stima definitiva”, ma costruisce un processo dinamico di apprendimento, in cui l’incertezza si riduce e si adatta man mano che i dati accumulano evidenza.\n\n\n\n\n\n\nPosteriori diverse a confronto\n\n\n\nLo stesso insieme di dati può dare origine a posteriori molto diverse a seconda del prior.\nQuesto non è un “difetto” del Bayes, ma un aspetto centrale: rende esplicita l’influenza delle ipotesi di partenza. Il vantaggio è che possiamo discutere apertamente quanto le conclusioni dipendano dal prior e, se necessario, confrontare più specificazioni (analisi di sensibilità).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#implicazioni-per-la-ricerca-psicologica",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#implicazioni-per-la-ricerca-psicologica",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.4 Implicazioni per la ricerca psicologica",
    "text": "41.4 Implicazioni per la ricerca psicologica\nL’esempio del globo terrestre è un gioco semplice, ma ci insegna alcune lezioni fondamentali che valgono pienamente per la psicologia.\n\nLe nostre convinzioni cambiano con i dati La ricerca psicologica non si limita a raccogliere informazioni: è un processo di apprendimento. Ogni studio modifica il nostro quadro di riferimento, integrando la nuova evidenza con ciò che già sapevamo.\nL’incertezza non scompare, si aggiorna Dopo pochi dati l’incertezza è ampia; con più osservazioni si restringe, ma non arriva mai a zero. In psicologia, dove i fenomeni sono complessi e variabili, è essenziale rappresentare non solo quanto un effetto è plausibile, ma anche quanto siamo incerti su di esso.\nL’informazione è cumulativa Proprio come ogni posterior diventa il nuovo prior, la scienza psicologica avanza grazie all’accumulo coerente di conoscenze. Ogni studio dovrebbe essere visto come un passo in una catena di aggiornamenti, non come un verdetto finale.\n\n\n41.4.1 Un esempio psicologico\nImmaginiamo di valutare l’efficacia di una nuova terapia per l’ansia. Prima dei dati, abbiamo solo intuizioni e risultati preliminari, che costituiscono un prior molto incerto. Dopo il primo studio, otteniamo indicazioni che la terapia potrebbe essere utile, ma con un ampio margine di dubbio, risultando in un posterior ancora largo. Con più studi, le distribuzioni si concentrano progressivamente. Se l’effetto è reale, la curva si restringe intorno a un valore positivo; se l’effetto è debole o assente, la distribuzione si sposterà di conseguenza.\nQuesto approccio rende più chiaro perché una singola ricerca non basta a stabilire verità definitive, e perché è cruciale replicare e accumulare evidenza.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nIl modello del globo mostra in piccolo quello che accade in psicologia:\n\nraccogliamo dati,\naggiorniamo le nostre credenze,\nmanteniamo l’incertezza,\ncostruiamo conoscenza in modo cumulativo.\n\nL’approccio bayesiano fornisce un linguaggio preciso per descrivere questo processo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#considerazioni-pratiche-e-limitazioni",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#considerazioni-pratiche-e-limitazioni",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.5 Considerazioni pratiche e limitazioni",
    "text": "41.5 Considerazioni pratiche e limitazioni\nL’approccio bayesiano offre una cornice concettuale elegante e intuitiva per rappresentare l’incertezza e aggiornare le nostre credenze. Tuttavia, quando passiamo dalla teoria alla pratica della ricerca psicologica, emergono alcune considerazioni importanti.\n\n41.5.1 Scelta delle credenze iniziali (priori)\nUn aspetto caratteristico dell’approccio bayesiano è che richiede di specificare sempre una distribuzione a priori. Questo è un vantaggio perché ci costringe a esplicitare le nostre assunzioni e ad ancorarle a conoscenze precedenti, ma è anche una responsabilità, poiché prior troppo forti o poco giustificate possono influenzare eccessivamente i risultati. In pratica, gli psicologi devono imparare a distinguere tra prior debolmente informativi, che lasciano spazio ai dati, e prior informativi, che incorporano evidenza accumulata o teoria.\n\n41.5.2 Complessità computazionale\nMolti modelli psicologici sono complessi, con più parametri, strutture gerarchiche e dinamiche temporali. Le formule di Bayes, in questi casi, non si possono risolvere a mano. Si usano invece metodi numerici come le simulazioni Monte Carlo (MCMC), che richiedono tempo di calcolo e competenze specifiche. Oggi strumenti come Stan o brms rendono queste tecniche accessibili, ma serve comunque una formazione adeguata.\n\n41.5.3 Interpretazione dei risultati\nI risultati bayesiani sono concettualmente più trasparenti, poiché parlano di plausibilità di valori invece di fornire un verdetto sì/no basato sulla “significatività”. Tuttavia, richiedono un cambio di mentalità. Per chi è abituato a pensare in termini di p-value, questo può sembrare inizialmente meno rassicurante, ma in realtà è più realistico, in quanto fornisce una distribuzione di possibilità.\n\n41.5.4 Limitazioni intrinseche\nInfine, va ricordato che anche l’approccio bayesiano ha limiti. Non elimina l’incertezza, ma la descrive soltanto meglio; dipende comunque dalla qualità dei dati, per cui dati rumorosi o campioni non rappresentativi rimangono problematici; e riflette sempre la struttura del modello scelto, per cui se il modello è inadeguato, anche la migliore inferenza bayesiana porterà a conclusioni distorte.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nIl pensiero bayesiano non è una bacchetta magica: richiede scelte esplicite, strumenti adeguati e una lettura attenta dei risultati. La sua forza non sta nell’eliminare le difficoltà della ricerca psicologica, ma nel renderle visibili e trattabili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#riflessioni-conclusive",
    "title": "41  La quantificazione dell’incertezza",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo fatto il nostro primo vero passo dentro il pensiero bayesiano. Abbiamo visto che l’incertezza può essere rappresentata come una distribuzione di probabilità e abbiamo introdotto il teorema di Bayes, la regola che collega credenze iniziali, dati osservati e credenze aggiornate. Attraverso l’esempio del globo terrestre, abbiamo compreso come l’aggiornamento bayesiano funzioni in pratica: ogni nuova osservazione restringe o sposta la distribuzione delle nostre convinzioni, riducendo progressivamente l’incertezza.\nAbbiamo discusso le implicazioni per la ricerca psicologica, riconoscendo che i dati non danno risposte definitive, ma guidano un processo di apprendimento cumulativo. Infine, abbiamo esaminato le considerazioni pratiche e le limitazioni dell’approccio, dalla scelta dei priori alla complessità computazionale, dall’interpretazione dei risultati alla dipendenza dalla qualità dei modelli.\nQuesta panoramica ci ha permesso di sviluppare un’intuizione solida: il bayesianesimo non elimina l’incertezza, ma ci fornisce un metodo coerente e trasparente per trattarla. Nei prossimi capitoli tradurremo queste idee in strumenti concreti, imparando a costruire e interpretare modelli bayesiani applicati alla ricerca psicologica.\nUn equivoco comune è pensare che l’approccio bayesiano fornisca “più certezze” rispetto a quello frequentista. In realtà, accade il contrario: i risultati bayesiani mettono in evidenza l’incertezza, anziché nasconderla dietro a un singolo numero o a un verdetto dicotomico. Questo può inizialmente sembrare meno rassicurante, soprattutto per chi è abituato a ragionare in termini di p-value e soglie di significatività. Tuttavia, proprio questa trasparenza costituisce la forza dell’approccio bayesiano: ci permette di comunicare in modo più onesto quali valori dei parametri sono plausibili e quanto spazio rimane per il dubbio. Adottare il pensiero bayesiano significa quindi cambiare prospettiva: non cercare una “certezza definitiva”, ma abituarsi a ragionare in termini di gradi di plausibilità e di apprendimento continuo dai dati.\n\n\n\n\n\n\nApprofondimento\n\n\n\n\n\nA una prima lettura, è sufficiente concentrarsi sul significato generale dell’aggiornamento bayesiano: ogni nuova osservazione modifica le nostre credenze sui parametri, restringendo progressivamente l’incertezza. Per il momento, gli studenti possono tralasciare i dettagli tecnici riportati qui sotto.\nDopo aver studiato le famiglie coniugate nei capitoli successivi, sarà utile tornare su questo esempio per comprenderne appieno il funzionamento. L’aggiornamento bayesiano diventerà allora più chiaro nei suoi aspetti formali, mostrando perché in alcuni casi (come questo) il calcolo può essere svolto in maniera particolarmente semplice ed elegante.\n\n41.5.5 Il modello Beta-Binomiale\nL’esempio del globo è un caso classico di modello Beta-Binomiale:\n\nla distribuzione a priori sulla proporzione \\(p\\) è una Beta;\nla verosimiglianza delle osservazioni (successi/insuccessi) segue una Binomiale;\nper la proprietà di coniugazione, la distribuzione a posteriori risulta anch’essa una Beta.\n\nQuesta proprietà ci permette di aggiornare le credenze con una regola semplice:\n\\[\n\\text{Posterior} \\sim \\text{Beta}(a + W, \\; b + L)\n\\]\ndove \\(a\\) e \\(b\\) sono i parametri della prior (nel nostro caso iniziale \\(a=1, b=1\\)), mentre \\(W\\) e \\(L\\) sono il numero di osservazioni acqua (Water) e terra (Land).\n\n41.5.6 Esempio passo per passo\n\nPrimo pannello (1 osservazione: W) Prior: \\(\\text{Beta}(1,1)\\) → Posterior: \\(\\text{Beta}(2,1)\\). La distribuzione si concentra su valori alti di \\(p\\).\nSecondo pannello (2 osservazioni: W, L) Prior: \\(\\text{Beta}(2,1)\\) → Posterior: \\(\\text{Beta}(3,2)\\). L’evidenza si riequilibra verso valori intermedi.\nTerzo pannello (3 osservazioni: W, L, W) Prior: \\(\\text{Beta}(3,2)\\) → Posterior: \\(\\text{Beta}(4,2)\\). Cresce la plausibilità di valori intorno a \\(p \\approx 0.66\\).\nQuarto pannello (4 osservazioni: W, L, W, W) Posterior: \\(\\text{Beta}(5,2)\\).\nQuinto pannello (5 osservazioni: W, L, W, W, L) Posterior: \\(\\text{Beta}(5,3)\\).\nSesto pannello (6 osservazioni: W, L, W, W, L, W) Posterior: \\(\\text{Beta}(6,3)\\).\nSettimo pannello (7 osservazioni: W, L, W, W, L, W, L) Posterior: \\(\\text{Beta}(6,4)\\).\nOttavo pannello (8 osservazioni: W, L, W, W, L, W, L, W) Posterior: \\(\\text{Beta}(7,4)\\).\nNono pannello (9 osservazioni: W, L, W, W, L, W, L, W, W) Posterior: \\(\\text{Beta}(8,4)\\).\n\n41.5.7 In sintesi\nL’aggiornamento sequenziale mostra come la distribuzione diventi progressivamente più concentrata intorno ai valori di \\(p\\) compatibili con i dati osservati. Con l’accumulo di osservazioni, l’incertezza si riduce, la stima più plausibile di \\(p\\) si stabilizza e l’inferenza diventa più precisa.\nQuesto è l’essenziale del processo bayesiano: un apprendimento cumulativo, coerente e formalmente elegante.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-3         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] yaml_2.3.10           knitr_1.50            labeling_0.4.3       \n#&gt; [19] bridgesampling_1.1-2  htmlwidgets_1.6.4     curl_7.0.0           \n#&gt; [22] pkgbuild_1.4.8        RColorBrewer_1.1-3    abind_1.4-8          \n#&gt; [25] multcomp_1.4-28       withr_3.0.2           purrr_1.1.0          \n#&gt; [28] grid_4.5.1            stats4_4.5.1          colorspace_2.1-1     \n#&gt; [31] xtable_1.8-4          inline_0.3.21         emmeans_1.11.2-8     \n#&gt; [34] scales_1.4.0          MASS_7.3-65           cli_3.6.5            \n#&gt; [37] mvtnorm_1.3-3         rmarkdown_2.29        ragg_1.4.0           \n#&gt; [40] generics_0.1.4        RcppParallel_5.1.11-1 cachem_1.1.0         \n#&gt; [43] stringr_1.5.1         splines_4.5.1         parallel_4.5.1       \n#&gt; [46] vctrs_0.6.5           V8_6.0.6              Matrix_1.7-4         \n#&gt; [49] sandwich_3.1-1        jsonlite_2.0.0        arrayhelpers_1.1-0   \n#&gt; [52] systemfonts_1.2.3     glue_1.8.0            codetools_0.2-20     \n#&gt; [55] distributional_0.5.0  lubridate_1.9.4       stringi_1.8.7        \n#&gt; [58] gtable_0.3.6          QuickJSR_1.8.0        htmltools_0.5.8.1    \n#&gt; [61] Brobdingnag_1.2-9     R6_2.6.1              textshaping_1.0.1    \n#&gt; [64] rprojroot_2.1.1       evaluate_1.0.5        lattice_0.22-7       \n#&gt; [67] backports_1.5.0       memoise_2.0.1         broom_1.0.9          \n#&gt; [70] snakecase_0.11.1      rstantools_2.4.0      coda_0.19-4.1        \n#&gt; [73] gridExtra_2.3         nlme_3.1-168          checkmate_2.3.3      \n#&gt; [76] xfun_0.53             zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#bibliografia",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#bibliografia",
    "title": "41  La quantificazione dell’incertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html",
    "href": "chapters/bayesian_inference/03_statistical_models.html",
    "title": "42  Modelli statistici",
    "section": "",
    "text": "Introduzione\nNegli ultimi anni, la psicologia ha vissuto un profondo ripensamento metodologico, sollecitato dalla cosiddetta crisi della replicabilità. Una delle critiche principali emerse in questo dibattito riguarda la tendenza della ricerca tradizionale a concentrarsi prevalentemente sull’identificazione di associazioni statistiche tra variabili, trascurando spesso la modellazione dei processi psicologici sottostanti che potrebbero aver generato i dati osservati.\nSebbene questo approccio descrittivo possa rivelarsi utile in determinate circostanze, esso presenta due limiti fondamentali. In primo luogo, tende a produrre risultati fragili e di difficile replicazione, poiché le relazioni identificate non sono ancorate a una teoria solida riguardante i meccanismi causali che le generano. In secondo luogo, contribuisce a mantenere un divario tra la psicologia e altre discipline scientifiche – come la fisica, la biologia o l’economia – che da tempo fondano il proprio progresso sulla costruzione di modelli formali in grado di rappresentare esplicitamente i processi sottostanti ai fenomeni osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#introduzione",
    "href": "chapters/bayesian_inference/03_statistical_models.html#introduzione",
    "title": "42  Modelli statistici",
    "section": "\n42.1 Preparazione del Notebook",
    "text": "Panoramica del capitolo\n\nCosa significa descrivere i dati rispetto a spiegare i processi che li generano.\n\nI limiti dei modelli fenomenologici e perché possono indurre in errore.\n\nIl ruolo delle distribuzioni di probabilità per rappresentare l’incertezza.\n\nCome confrontare modelli alternativi e scegliere quelli che meglio descrivono i dati e generalizzano a nuovi contesti.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Common Statistical Models del testo di Chan & Kroese (2025).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n42.1 Preparazione del Notebook\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n\n\n\n\n42.1.1 Dalla correlazione alla spiegazione\nUn modello che si limita a stimare una correlazione o una regressione lineare può dirci se due variabili si muovono insieme, ma non ci dice perché accade. Per esempio: osservare un’associazione tra stress e rendimento accademico è informativo, ma non basta per capire il processo attraverso cui lo stress influisce (o non influisce) sulla performance.\nIl passo avanti consiste nel cercare di rappresentare come i dati emergono da processi psicologici sottostanti. In altre parole, spostiamo l’attenzione dalle semplici relazioni osservate ai meccanismi generativi che le producono.\n\n42.1.1.1 Perché questo cambiamento è cruciale?\nQuesto cambiamento è cruciale perché permette di costruire modelli più vicini alla realtà dei fenomeni psicologici, rende le teorie più precise e testabili, e fornisce risultati più robusti e potenzialmente più replicabili, poiché radicati in una rappresentazione del processo e non solo in un dato campione.\n\n42.1.2 Anticipazione\nNei prossimi paragrafi vedremo come questo approccio si traduca in pratica: non ci limiteremo a presentare i modelli di regressione nelle loro diverse varianti, ma esploreremo anche modelli che cercano di descrivere processi psicologici espliciti, come ad esempio il modello di Rescorla-Wagner per l’apprendimento associativo.\nL’obiettivo non è sostituire l’analisi statistica classica, ma integrarla con strumenti che ci aiutino a rispondere a una domanda più ambiziosa: quali processi mentali plausibili possono aver generato i dati che osserviamo?",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#preparazione-del-notebook",
    "href": "chapters/bayesian_inference/03_statistical_models.html#preparazione-del-notebook",
    "title": "42  Modelli statistici",
    "section": "",
    "text": "here::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#campionamento-indipendente-da-una-distribuzione-fissa",
    "href": "chapters/bayesian_inference/03_statistical_models.html#campionamento-indipendente-da-una-distribuzione-fissa",
    "title": "42  Modelli statistici",
    "section": "\n42.2 Campionamento indipendente da una distribuzione fissa",
    "text": "42.2 Campionamento indipendente da una distribuzione fissa\nMolti modelli statistici tradizionali si basano sull’assunzione fondamentale che i dati osservati rappresentino un processo di campionamento indipendente da una distribuzione fissa. Prendiamo ad esempio il caso dei punteggi di ansia misurati in un campione di studenti: si assume che questi punteggi seguano una distribuzione normale caratterizzata da una media \\(\\mu\\) e una deviazione standard \\(\\sigma\\).\nIn questo quadro concettuale:\n\nogni singola osservazione viene considerata come un’estrazione indipendente dalla stessa distribuzione di probabilità sottostante;\nl’obiettivo principale del modello statistico diventa quindi la stima dei parametri che definiscono questa distribuzione (\\(\\mu\\) e \\(\\sigma\\)).\n\nQuesto approccio presenta indubbi vantaggi per la descrizione sintetica dei dati e l’identificazione delle loro caratteristiche distributive fondamentali. Tuttavia, è importante riconoscere i suoi limiti concettuali: questa prospettiva rimane essenzialmente muta riguardo ai meccanismi attraverso i quali i livelli di ansia effettivamente emergono o si modificano nel tempo. In altre parole, descrive i dati nella loro manifestazione osservabile (“così come sono”), ma non offre alcuna insight sui processi psicologici dinamici che li hanno generati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#modelli-fenomenologici-descrivere-le-associazioni",
    "href": "chapters/bayesian_inference/03_statistical_models.html#modelli-fenomenologici-descrivere-le-associazioni",
    "title": "42  Modelli statistici",
    "section": "\n42.3 Modelli fenomenologici: descrivere le associazioni",
    "text": "42.3 Modelli fenomenologici: descrivere le associazioni\nUn passo in più è rappresentato dai modelli che analizzano relazioni tra variabili, come la regressione lineare o logistica. Questi approcci ci permettono di andare oltre la semplice descrizione di una distribuzione, consentendoci di studiare sistematicamente come una variabile dipendente cambia in funzione di una o più variabili indipendenti.\nPer esempio, possiamo modellare la relazione tra stress e rendimento accademico, verificando empiricamente se un aumento dei livelli di stress corrisponde effettivamente a un calo delle performance scolastiche.\nQuesti modelli statistici sono estremamente diffusi e costituiscono il fondamento metodologico di gran parte della ricerca psicologica contemporanea. Tuttavia, è importante riconoscere che rimangono essenzialmente modelli fenomenologici: descrivono efficacemente che cosa accade (documentando ad esempio l’esistenza di una correlazione tra stress e rendimento), ma non sono in grado di spiegare perché tale relazione esista.\nUn modello di regressione, infatti, non può dirci se lo stress riduce direttamente il rendimento, se entrambe le variabili sono influenzate da un fattore terzo (come il supporto sociale), o se la relazione evolve nel tempo attraverso complesse dinamiche di adattamento psicologico. Questa fragilità metodologica ha contribuito direttamente alla crisi di replicazione: modelli che descrivono soltanto associazioni spesso sembrano solidi in uno studio, ma non riescono a replicarsi in altri contesti, proprio perché non si appoggiano a un processo generativo condiviso.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#modelli-meccanicistici-spiegare-i-processi",
    "href": "chapters/bayesian_inference/03_statistical_models.html#modelli-meccanicistici-spiegare-i-processi",
    "title": "42  Modelli statistici",
    "section": "\n42.4 Modelli meccanicistici: spiegare i processi",
    "text": "42.4 Modelli meccanicistici: spiegare i processi\nI modelli meccanicistici, detti anche processuali, rappresentano un passo ulteriore rispetto ai modelli puramente statistici. Questi modelli non si limitano a descrivere associazioni tra variabili, ma cercano di formalizzare i meccanismi psicologici che generano i dati osservati.\nQuesti modelli sono costruiti a partire da ipotesi specifiche su come le persone percepiscono, apprendono, decidono o reagiscono a stimoli. Ogni parametro del modello possiede un significato psicologico interpretabile, come ad esempio la velocità di apprendimento, una soglia decisionale, o la sensibilità a ricompense e punizioni. In questa prospettiva, i dati non sono più considerati come semplici estrazioni indipendenti da una distribuzione fissa, ma come l’esito dinamico di un processo psicologico sottostante.\nUn esempio particolarmente illustrativo è il modello di Rescorla-Wagner per l’apprendimento associativo. Questo modello descrive come la forza di un’associazione tra stimoli viene aggiornata a ogni prova in base all’errore di previsione commesso dall’individuo. In questo caso, non ci limitiamo a stimare se “esiste un effetto” di uno stimolo, ma modelliamo esplicitamente il processo di apprendimento che produce le risposte osservate, offrendo così una comprensione più profonda e meccanicistica del fenomeno psicologico in esame. Modelli di questo tipo, radicati in un processo psicologico esplicito, hanno il potenziale di produrre risultati più robusti e replicabili: se il modello cattura davvero il meccanismo sottostante, allora la sua applicazione a nuovi dati dovrebbe confermare le stesse dinamiche di base, anche se le osservazioni specifiche cambiano.\n\n42.4.1 Confronto tra i due approcci\nI modelli fenomenologici offrono il vantaggio della semplicità e sono spesso sufficienti per una descrizione iniziale dei dati. Tuttavia, questa semplicità comporta un rischio significativo: tendono a produrre spiegazioni fragili e poco replicabili, in quanto catturano relazioni superficiali senza indagare i meccanismi sottostanti.\nAl contrario, i modelli meccanicistici richiedono un maggior numero di ipotesi iniziali e presentano una complessità analitica superiore. Questo investimento aggiuntivo viene ricompensato da un fondamentale vantaggio epistemologico: ci avvicinano alla logica metodologica delle scienze naturali, permettendoci di spiegare i dati osservati attraverso la formalizzazione di processi generativi sottostanti. In questo modo, non ci limitiamo a descrivere le relazioni tra variabili, ma cerchiamo di comprendere i meccanismi causali che le producono.\n\n\n\n\n\n\nDifferenza intuitiva\n\n\n\nUn modello fenomenologico si limita a descrivere una relazione osservabile, affermando ad esempio che “più ore di studio corrispondono a voti più alti”. Al contrario, un modello meccanicistico cerca di spiegare il processo sottostante questa relazione, proponendo ad esempio che “ogni sessione di studio incrementa la forza della traccia mnestica con un determinato tasso di apprendimento, il quale a sua volta influenza direttamente la probabilità di rispondere correttamente durante l’esame”.\nMentre il primo si concentra sul cosa accade, il secondo cerca di spiegare come e perché accade.\n\n\n\n\n\n\n\n\n\n\nModello fenomenologico: il focus è sulla forma della distribuzione e sui suoi parametri riassuntivi (media, varianza).\n\n\n\n\n\n\n\n\nModello meccanicistico: il focus è sul meccanismo nel tempo (apprendimento): \\(V_t\\) evolve in base all’errore di previsione e le osservazioni \\(Y_t\\) sono rumore attorno a \\(V_t\\).\n**Messaggio chiave:* descrivere associazioni vs spiegare processi generativi.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#valutazione-e-confronto-dei-modelli",
    "href": "chapters/bayesian_inference/03_statistical_models.html#valutazione-e-confronto-dei-modelli",
    "title": "42  Modelli statistici",
    "section": "\n42.5 Valutazione e confronto dei modelli",
    "text": "42.5 Valutazione e confronto dei modelli\nOgni modello psicologico, che sia descrittivo o meccanicistico, costituisce una rappresentazione semplificata della realtà. Nessun modello può catturare interamente la complessità dei fenomeni psicologici: il suo valore scientifico dipende fondamentalmente dalla capacità di aiutarci a comprendere e prevedere i dati osservati.\n\n42.5.1 Due prospettive complementari\nLa valutazione dei modelli si articola su due dimensioni distinte ma complementari. Da un lato l’adeguatezza esplicativa, che misura quanto bene un modello riesce a descrivere i dati già osservati. Dall’altro la capacità predittiva, che valuta invece l’abilità del modello di generalizzare a nuovi dati non ancora raccolti.\nÈ importante notare come queste due dimensioni non sempre coincidano: un modello eccessivamente complesso può adattarsi perfettamente ai dati esistenti, mostrando un’eccellente adeguatezza esplicativa, ma rivelarsi al contempo incapace di fare previsioni accurate su dati nuovi, manifestando così una scarsa capacità predittiva.\n\n42.5.2 Confrontare i modelli\nLa crisi di replicazione ci ricorda che non basta adattare bene un modello ai dati disponibili: ciò che conta è la capacità di prevedere dati nuovi. È proprio qui che la valutazione e il confronto dei modelli diventano strumenti centrali per una psicologia più solida.\nIl confronto tra modelli rappresenta un aspetto cruciale della ricerca scientifica, poiché riconosce che per uno stesso fenomeno possono esistere multiple spiegazioni plausibili. Il compito del ricercatore consiste nell’identificare il modello che produce le rappresentazioni più utili e coerenti con la realtà osservata.\nQuesto confronto può avvenire sia tra approcci diversi che all’interno dello stesso paradigma. I modelli fenomenologici e meccanicistici, ad esempio, possono essere messi a confronto: mentre il primo si limita a descrivere le associazioni tra variabili, il secondo avanza ipotesi specifiche sui processi generatori dei dati. Allo stesso modo, due modelli meccanicistici alternativi – come diverse teorie dell’apprendimento – possono essere confrontati per determinare quale meglio spieghi il comportamento osservato.\n\n42.5.3 Anticipazione\nNei prossimi capitoli esploreremo le metodologie concrete per condurre questi confronti, introducendo strumenti statistici che quantificano oggettivamente la bontà predittiva dei modelli. In particolare:\n\napprofondiremo criteri statistici come la log-verosimiglianza, il WAIC e il LOO-CV, che permettono un confronto formale delle capacità predittive dei modelli;\nesamineremo casi di studio psicologici in cui modelli alternativi – come diversi modelli di apprendimento o processi decisionali – vengono sottoposti a verifica empirica sugli stessi dati.\n\nQuesto approccio ci permetterà di passare da valutazioni qualitative a giudizi quantitativi e rigorosi sulla bontà dei nostri modelli teorici.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nUn modello non è mai “vero” in senso assoluto: è più o meno utile. La valutazione e il confronto dei modelli sono strumenti fondamentali per rendere la psicologia una scienza cumulativa, in cui teorie diverse possono essere messe a confronto sulla base dei dati.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI modelli possono essere valutati secondo due prospettive fondamentali: quella esplicativa e quella predittiva.\nLa valutazione esplicativa (o fit del modello) misura quanto bene un modello riesce a descrivere i dati già osservati, ovvero quanto sia in grado di adattarsi alle informazioni in nostro possesso.\nLa valutazione predittiva (o validazione del modello) misura invece la capacità del modello di generalizzare, ovvero di fare previsioni accurate su dati nuovi, non ancora osservati e provenienti da outside del campione originario.\nIl messaggio chiave è che un modello statisticamente valido non è solo quello che spiega bene il passato, ma soprattutto quello che dimostra di saper prevedere in modo affidabile il futuro. La vera prova della bontà di un modello risiede nella sua capacità predittiva, non solo in quella descrittiva.\n\n42.5.4 Un esempio psicologico: scelte alimentari negli adolescenti\nImmaginiamo di voler studiare le scelte alimentari di un gruppo di adolescenti, osservando se scelgono uno snack salutare o non salutare in una serie di decisioni.\n\nApproccio fenomenologico Possiamo costruire una regressione logistica che predice la probabilità di scegliere lo snack salutare in funzione di alcune variabili, ad esempio il livello di stress e la disponibilità economica. Questo modello ci direbbe se lo stress è associato a una minore probabilità di fare scelte salutari, senza però chiarire perché avvenga.\nApproccio meccanicistico Possiamo invece ipotizzare un modello di apprendimento associativo (ad esempio il modello di Rescorla–Wagner): ad ogni prova, l’adolescente aggiorna le proprie aspettative di ricompensa per ciascuna opzione sulla base dell’esperienza precedente. In questo quadro, i dati delle scelte non sono solo correlati a variabili esterne, ma sono l’esito di un processo dinamico di apprendimento governato da parametri interpretabili (tasso di apprendimento, sensibilità alla ricompensa, variabilità decisionale).\n\n\n42.5.4.1 Confronto dei due modelli\nEntrambi i modelli possono adattarsi agli stessi dati, ma offrono spiegazioni molto diverse: la regressione descrive un’associazione “statica” tra stress e scelta, mentre il modello di apprendimento descrive un meccanismo dinamico, cioè come gli adolescenti aggiornano le loro preferenze. Valutare e confrontare i modelli significa allora chiedersi quale delle due rappresentazioni sia più utile: quella che ci dice solo quali variabili sono correlate, o quella che propone un processo psicologico plausibile alla base delle decisioni?\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nGli stessi dati possono essere interpretati con modelli diversi. Il confronto tra modelli non è un lusso, ma una necessità: ci permette di capire quale rappresentazione dei dati sia più informativa e più vicina ai processi psicologici reali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/03_statistical_models.html#riflessioni-conclusive",
    "title": "42  Modelli statistici",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo distinto tra due modi di intendere i modelli in psicologia:\n\ni modelli fenomenologici, che descrivono le relazioni osservabili tra variabili;\ni modelli meccanicistici, che cercano invece di rappresentare i processi psicologici che generano i dati.\n\nI primi hanno il vantaggio della semplicità e forniscono un punto di partenza utile per descrivere i fenomeni. I secondi, più complessi, ci permettono però di avvicinarci a una spiegazione: ci dicono non solo che cosa accade, ma anche come e perché accade.\nAbbiamo visto che la psicologia, per rafforzare la propria solidità scientifica, non può limitarsi all’analisi delle associazioni. È necessario un salto verso modelli che mettano al centro i meccanismi generativi. Solo così possiamo rendere le nostre teorie più precise, più testabili e più replicabili.\nUn altro punto fondamentale riguarda la valutazione dei modelli: non esiste un modello “vero” in senso assoluto, ma modelli più o meno utili. Per questo dobbiamo sempre confrontare alternative, verificare la loro capacità di spiegare i dati raccolti e soprattutto la loro forza nel prevedere dati nuovi.\nNei prossimi capitoli passeremo dal livello concettuale a quello operativo, vedendo come l’approccio bayesiano ci consenta di costruire e confrontare concretamente modelli fenomenologici e meccanicistici.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nL’uso dei modelli meccanicistici, insieme a strumenti di confronto basati sulla capacità predittiva, rappresenta una via promettente per affrontare la crisi di replicabilità in psicologia. Nei capitoli successivi vedremo come tradurre questi principi in pratiche concrete di analisi statistica e di modellazione.\n\n\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQual è il processo concettuale alla base della modellizzazione e dell’analisi statistica?\nCosa significa che un campione è indipendente e identicamente distribuito (iid) e perché questa assunzione è importante nei modelli statistici?\nCome si differenziano i modelli di campionamento da una singola distribuzione rispetto ai modelli di campioni multipli indipendenti?\nQual è la differenza tra regressione lineare semplice e regressione lineare multipla?\nIn che modo i modelli computazionali, come il modello di apprendimento associativo e il modello drift-diffusion, si differenziano dai modelli statistici tradizionali?\n\nConsegna: Rispondi con parole tue e carica il file .qmd, convertito in PDF su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nIl processo concettuale della modellizzazione e analisi statistica inizia con un problema reale e i dati raccolti su tale problema. Si costruisce quindi un modello probabilistico che rappresenta le conoscenze disponibili e il modo in cui i dati sono stati ottenuti. L’analisi viene condotta all’interno del modello, producendo conclusioni sui suoi parametri. Infine, i risultati vengono tradotti in inferenze sulla realtà, con lo scopo di migliorare la comprensione del fenomeno studiato.\nUn campione è detto indipendente e identicamente distribuito (iid) se le osservazioni sono indipendenti tra loro e seguono la stessa distribuzione di probabilità. Questa assunzione è fondamentale perché semplifica le analisi statistiche e permette di applicare risultati teorici importanti, come la legge dei grandi numeri e il teorema del limite centrale.\nNei modelli di campionamento da una singola distribuzione, si assume che tutte le osservazioni provengano da una stessa popolazione e seguano la stessa distribuzione. Nei modelli di campioni multipli indipendenti, invece, si confrontano più gruppi distinti, ciascuno con la propria distribuzione, per studiare differenze tra le popolazioni. Un esempio è il confronto tra altezze di individui con madri fumatrici e non fumatrici.\nLa regressione lineare semplice analizza la relazione tra una variabile dipendente e una sola variabile indipendente attraverso una relazione lineare. La regressione lineare multipla, invece, estende questo concetto a più variabili indipendenti, permettendo di modellare fenomeni più complessi e controllare l’effetto di più fattori simultaneamente.\nI modelli computazionali, come il modello di apprendimento associativo e il modello drift-diffusion, differiscono dai modelli statistici tradizionali perché mirano a simulare i processi mentali e decisionali sottostanti il comportamento umano. I modelli statistici descrivono principalmente relazioni tra variabili nei dati osservati, mentre i modelli computazionali cercano di rappresentare dinamicamente i meccanismi cognitivi e comportamentali che generano tali dati.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-3         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] yaml_2.3.10           knitr_1.50            labeling_0.4.3       \n#&gt; [19] bridgesampling_1.1-2  htmlwidgets_1.6.4     curl_7.0.0           \n#&gt; [22] pkgbuild_1.4.8        RColorBrewer_1.1-3    abind_1.4-8          \n#&gt; [25] multcomp_1.4-28       withr_3.0.2           purrr_1.1.0          \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.4.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_6.0.6              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.1     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.4.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#bibliografia",
    "href": "chapters/bayesian_inference/03_statistical_models.html#bibliografia",
    "title": "42  Modelli statistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html",
    "href": "chapters/bayesian_inference/04_subj_prop.html",
    "title": "43  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo esaminato il ruolo fondamentale dell’incertezza nella ricerca psicologica e abbiamo visto come l’approccio bayesiano fornisca un linguaggio particolarmente adatto per rappresentarla. Abbiamo inoltre distinto tra modelli puramente fenomenologici, che si limitano a descrivere associazioni tra variabili, e modelli meccanicistici, che cercano invece di formalizzare i processi psicologici sottostanti.\nIn questo capitolo ci concentreremo su un caso di studio particolarmente comune e rilevante: l’inferenza sulla proporzione di successi in un compito sperimentale o in un campione di soggetti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#introduzione",
    "href": "chapters/bayesian_inference/04_subj_prop.html#introduzione",
    "title": "43  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "",
    "text": "43.0.1 Perché partire dalle proporzioni?\nUna parte significativa della ricerca psicologica si basa su dati di natura binaria: un soggetto che ricorda o non ricorda uno stimolo, un paziente che risponde o non risponde a una terapia, uno studente che sceglie o non sceglie l’opzione corretta in un compito cognitivo.\nIn tutti questi scenari, i dati si riducono essenzialmente a un conteggio di successi e insuccessi, e la quantità di interesse principale diventa la proporzione di successi nella popolazione o nel campione studiato.\nL’analisi di questo caso apparentemente semplice ci offre tre vantaggi fondamentali: in primo luogo, ci permette di stabilire un collegamento chiaro tra dati osservati e modelli probabilistici; in secondo luogo, ci aiuta a comprendere come i priori e i posteriori operano concretamente nel contesto di un modello Beta-Binomiale; infine, getta le basi per modelli più complessi che in seguito potranno descrivere non solo proporzioni statiche, ma veri e propri processi psicologici dinamici che generano le osservazioni.\n\n43.0.2 Collegamento con la crisi di replicazione\nMolti dei risultati controversi emersi in psicologia derivano da studi che confrontavano proporzioni tra diversi gruppi sperimentali - si pensi ad esempio alla percentuale di partecipanti che mostrano un certo effetto. Una delle criticità principali di questi studi è stata la tendenza a presentare queste proporzioni come stime puntuali, tralasciando una adeguata rappresentazione dell’incertezza associata.\nL’approccio bayesiano supera questa limitazione consentendo di comunicare non solo quale sia la proporzione più plausibile, ma anche quanto dubbio residuo permanga attorno a questa stima. Questa trasparenza favorisce interpretazioni più equilibrate e cumulative dei risultati, contribuendo così ad affrontare uno dei fattori che hanno alimentato la crisi di replicabilità nel campo.\nPanoramica del capitolo\n\nApplicare l’aggiornamento bayesiano per affinare credenze.\nRappresentare distribuzioni a priori (discrete e continue).\nCalcolare la verosimiglianza e aggiornare la distribuzione a priori.\nDerivare e interpretare la distribuzione a posteriori.\nUsare il metodo a griglia per approssimare la distribuzione a posteriori.\nApplicare il modello binomiale per stimare probabilità e incertezze.\nCalcolare medie, mode e intervalli di credibilità.\nUtilizzare la distribuzione Beta come prior continuo.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il settimo capitolo del testo di Albert & Hu (2019).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(HDInterval)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/bayesian_inference/04_subj_prop.html#verosimiglianza-binomiale",
    "title": "43  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n43.1 Verosimiglianza binomiale",
    "text": "43.1 Verosimiglianza binomiale\nNei capitoli precedenti abbiamo visto che l’approccio bayesiano rappresenta l’incertezza con distribuzioni di probabilità. Ora possiamo tradurre questa idea in un caso concreto molto comune nella ricerca psicologica: quando osserviamo una sequenza di successi e insuccessi. Questo tipo di dati non è raro: pensiamo a uno studente che risponde a una serie di domande (corretto/errato), a un paziente che mostra o non mostra un miglioramento, a un partecipante che sceglie o non sceglie un certo stimolo. In questi casi, la distribuzione che descrive le probabilità dei possibili conteggi di successi si chiama distribuzione binomiale. Essa rappresenta il cuore del modello fenomenologico più semplice per i dati binari: il modello binomiale.\nLa distribuzione binomiale descrive il numero di successi \\(y\\) in \\(n\\) prove indipendenti, ciascuna con probabilità di successo \\(\\theta\\):\n\\[\np(y \\mid \\theta) = \\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y},\n\\]\ndove \\(\\theta\\) rappresenta la probabilità di successo per singola prova, \\(y\\) è il numero osservato di successi e \\(n\\) è il numero totale di prove (fissato a priori).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#esempio-psicologico-giudizio-morale-in-un-dilemma",
    "href": "chapters/bayesian_inference/04_subj_prop.html#esempio-psicologico-giudizio-morale-in-un-dilemma",
    "title": "43  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n43.2 Esempio psicologico: giudizio morale in un dilemma",
    "text": "43.2 Esempio psicologico: giudizio morale in un dilemma\nI dilemmi morali, come il classico problema del treno (Foot, 1967; Greene et al., 2001), sono strumenti usati in psicologia per indagare come le persone prendono decisioni etiche (per es., Bucciarelli et al., 2008). Supponiamo che un ricercatore voglia stimare la proporzione di adulti che considerano accettabile compiere un’azione moralmente controversa (ad es. deviare un treno per salvare cinque persone, causando però la morte di una persona).\nOgni partecipante legge un singolo scenario morale e deve dare una risposta binaria:\n\n1 = giudica l’azione come moralmente accettabile (successo),\n0 = giudica l’azione come non accettabile (fallimento).\n\nIn un campione di 30 soggetti indipendenti, 22 hanno giudicato l’azione accettabile.\nIn questo scenario:\n\nciascun soggetto fornisce un unico giudizio (unità di osservazione indipendente),\nogni risposta è una variabile di Bernoulli con probabilità di successo \\(\\theta\\),\nil numero totale di giudizi favorevoli segue una distribuzione binomiale:\n\n\\[\nY \\sim \\text{Binomiale}(n = 30, \\theta),\n\\]\ndove \\(Y = 22\\) rappresenta il numero di successi osservati.\n\n43.2.1 Obiettivo inferenziale\nIl nostro scopo è stimare \\(\\theta\\): la probabilità che un adulto, scelto a caso dalla popolazione, giudichi moralmente accettabile l’azione descritta nel dilemma. Nel quadro bayesiano combiniamo:\n\nla verosimiglianza (dati osservati: 22 su 30),\nuna distribuzione a priori (credenze iniziali su \\(\\theta\\)),\n\nottenendo la distribuzione a posteriori, che rappresenta la nostra conoscenza aggiornata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/04_subj_prop.html#metodo-basato-su-griglia",
    "title": "43  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n43.3 Metodo basato su griglia",
    "text": "43.3 Metodo basato su griglia\nIl metodo basato su griglia è un approccio intuitivo e didatticamente efficace per approssimare una distribuzione a posteriori. La sua semplicità lo rende ideale per comprendere il meccanismo di aggiornamento delle credenze. L’idea fondamentale è di discretizzare lo spazio dei parametri e calcolare la distribuzione a posteriori in punti isolati, evitando il ricorso a metodi analitici complessi.\nI passaggi operativi sono i seguenti:\n\n\nDefinizione della griglia: Si suddivide l’intervallo dei valori plausibili per il parametro di interesse (ad esempio, \\(\\theta\\), compreso tra 0 e 1) in una sequenza finita di punti equidistanti.\n\nCalcolo della verosimiglianza: Per ogni punto \\(\\theta_i\\) sulla griglia, si calcola la funzione di verosimiglianza \\(P(D \\mid \\theta_i)\\), che rappresenta la probabilità di osservare i dati \\(D\\) dato quel specifico valore del parametro.\n\nProdotto priori-verosimiglianze: Per ogni punto della griglia, si moltiplica il valore della verosimiglianza per il valore della distribuzione a priori \\(P(\\theta_i)\\). Questo prodotto è proporzionale alla distribuzione a posteriori non normalizzata.\n\nNormalizzazione: I valori ottenuti nel passo precedente vengono sommati e ciascuno di essi è diviso per questa somma totale. Il risultato è una distribuzione di probabilità discreta a posteriori valida, i cui valori per ogni \\(\\theta_i\\) sommano a 1.\n\nIl risultato finale è un’approssimazione della vera distribuzione a posteriori continua, che mostra in modo chiaro come l’evidenza fornita dai dati (\\(D\\)) abbia aggiornato e modificato le credenze iniziali (la distribuzione a priori) sul parametro \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "href": "chapters/bayesian_inference/04_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "title": "43  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n43.4 Aggiornamento bayesiano con una distribuzione a priori discreta",
    "text": "43.4 Aggiornamento bayesiano con una distribuzione a priori discreta\n\n43.4.1 Costruzione della distribuzione a priori\nIn assenza di informazioni specifiche, possiamo assumere che tutti i valori di \\(\\theta\\) siano ugualmente plausibili. Per implementare concretamente questo approccio:\n\ndefiniamo un insieme discreto di valori possibili per \\(\\theta\\): {0, 0.1, 0.2, …, 1},\n\nassegniamo a ciascun valore la stessa probabilità a priori: \\(p(\\theta) = 1/11 \\approx 0.09\\).\n\nQuesta scelta rappresenta uno stato di massima incertezza iniziale, dove nessun valore di \\(\\theta\\) risulta a priori più plausibile di altri.\n\n43.4.2 Aggiornamento con i dati\nAbbiamo osservato \\(y = 22\\) giudizi di accettabilità su \\(n = 30\\) partecipanti. Per ogni valore \\(\\theta\\) nella griglia:\n\n\ncalcoliamo la verosimiglianza binomiale:\n\\[\np(y \\mid \\theta) = \\theta^{22}(1-\\theta)^8 ,\n\\]\ndove \\(\\theta\\) rappresenta la probabilità che un adulto giudichi l’azione come moralmente accettabile,\n\nmoltiplichiamo per la probabilità a priori,\nnormalizziamo dividendo per la somma totale di tutti i prodotti ottenuti.\n\nIl risultato è una distribuzione a posteriori discreta che mostra come l’osservazione aggiorna le nostre credenze iniziali. I valori di \\(\\theta\\) vicini a \\(22/30 \\approx 0.7\\) ricevono una maggiore probabilità a posteriori.\n\n43.4.3 Interpretazione\n\nPrima dei dati, ogni valore di \\(\\theta\\) era ugualmente plausibile.\n\nDopo i dati, valori come \\(\\theta = 0.7\\) o \\(0.75\\) hanno alta probabilità a posteriori.\n\nValori estremi (\\(0.2\\), \\(0.9\\)) diventano poco plausibili.\n\nIn altre parole, la distribuzione a posteriori concentra la massa di probabilità attorno ai valori che rendono i dati osservati più plausibili.\n\n43.4.4 Implementazione in R\nDefinizione della griglia:\n\ntheta &lt;- seq(0, 1, by = 0.1)  # Griglia di valori da 0 a 1 con passo 0.1\n\nQuando non abbiamo informazioni preliminari, usiamo una distribuzione uniforme:\n\npriori_unif &lt;- rep(1 / length(theta), length(theta))  # Probabilità uniformi\n\nVisualizziamo questa distribuzione:\n\nggplot(data.frame(theta, prob = priori_unif), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(x = expression(theta),\n       y = \"Densità di probabilità\")\n\n\n\n\n\n\n\nSe invece riteniamo più probabili valori centrali di \\(\\theta\\):\n\npriori_inf &lt;- c(\n  0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05\n)\n\nVisualizzazione:\n\nggplot(data.frame(theta, prob = priori_inf), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(x = expression(theta),\n       y = \"Densità di probabilità\")\n\n\n\n\n\n\n\nVerosimiglianza:\n\nverosimiglianza &lt;- dbinom(22, size = 30, prob = theta)\n\nVisualizzazione:\n\nggplot(data.frame(theta, prob = verosimiglianza), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(x = expression(theta),\n       y = \"L(θ|dati)\")\n\n\n\n\n\n\n\nCalcolo della distribuzione a posteriori:\n\nposteriori_non_norm &lt;- priori_inf * verosimiglianza\nposteriori &lt;- posteriori_non_norm / sum(posteriori_non_norm)  # Normalizzazione\n\nVisualizzazione:\n\nggplot(data.frame(theta, prob = posteriori), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(x = expression(theta),\n       y = \"P(θ|dati)\")\n\n\n\n\n\n\n\nStatistiche descrittive:\n\nmedia_post &lt;- sum(theta * posteriori)\nvar_post &lt;- sum(theta^2 * posteriori) - media_post^2\nmoda_post &lt;- theta[which.max(posteriori)]\n\ncat(\"Media a posteriori:\", round(media_post, 3),\n    \"\\nVarianza a posteriori:\", round(var_post, 3),\n    \"\\nModa a posteriori:\", moda_post)\n#&gt; Media a posteriori: 0.689 \n#&gt; Varianza a posteriori: 0.005 \n#&gt; Moda a posteriori: 0.7\n\nInterpretazione grafici. Il grafico della verosimiglianza mostra un picco tra 0.6 e 0.8: significa che questi valori di \\(\\theta\\) rendono i dati osservati particolarmente plausibili. La combinazione con il prior porta la curva a posteriori ad accentuare o attenuare questa evidenza, a seconda della distribuzione iniziale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "href": "chapters/bayesian_inference/04_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "title": "43  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n43.5 Aggiornamento bayesiano con una distribuzione a priori continua",
    "text": "43.5 Aggiornamento bayesiano con una distribuzione a priori continua\nUn’estensione naturale è usare una distribuzione continua come priori. La più adatta nel caso di proporzioni è la Beta:\n\nsupporto: \\(\\[0,1]\\) (come \\(\\theta\\)),\nconiugata della Binomiale (la posteriori è ancora una Beta),\nparametri: \\(\\text{Beta}(\\alpha, \\beta)\\).\n\nEsempi:\n\n\n\\(\\text{Beta}(2,2)\\): priori simmetrica e non troppo informativa,\n\n\\(\\text{Beta}(2,5)\\): priori che privilegia valori bassi di \\(\\theta\\).\n\n\n43.5.1 Implementazione in R\nCalcoliamo la densità della distribuzione \\(\\text{Beta}(2, 2)\\) su una griglia fine di valori di \\(\\theta\\):\n\ntheta &lt;- seq(0, 1, length.out = 1000)\nprior_beta_2_2 &lt;- dbeta(theta, 2, 2)\n\nVisualizzazione:\n\nggplot(data.frame(theta, prior = prior_beta_2_2), aes(x = theta, y = prior)) +\n  geom_line(linewidth = 1.2, color = \"#5d5349\") +\n  labs(x = expression(theta), y = \"Densità\")\n\n\n\n\n\n\n\nContinuiamo con l’esempio precedente, in cui 22 partecipanti su 30 hanno giudicato l’azione come moralmente accettabile. La verosimiglianza associata a ciascun valore di \\(\\theta\\) è calcolata come:\n\nlikelihood &lt;- dbinom(22, size = 30, prob = theta)\n\nPoiché il prior è continuo, otteniamo la distribuzione a posteriori moltiplicando punto a punto la densità a priori per la verosimiglianza, e normalizzando:\n\nposterior_unnorm &lt;- prior_beta_2_2 * likelihood\nposterior &lt;- posterior_unnorm / sum(posterior_unnorm)\n\nVisualizziamo le tre curve (per gli scopi della visualizzazione, standardizziamo ciascuna distribuzione):\n\ndf &lt;- data.frame(\n  theta, \n  prior = prior_beta_2_2 / sum(prior_beta_2_2), \n  likelihood = likelihood / sum(likelihood), \n  posterior\n  )\n\ndf_long &lt;- df |&gt;\n  pivot_longer(cols = c(\"prior\", \"likelihood\", \"posterior\"),\n               names_to = \"Distribuzione\", values_to = \"Densità\")\n\nggplot(df_long, aes(x = theta, y = Densità, color = Distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(x = expression(theta), y = \"Densità\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nOra consideriamo una distribuzione a priori non simmetrica, Beta(2, 5), per rappresentare credenze che privilegiano valori bassi di \\(\\theta\\).\n\nprior_2_5 &lt;- dbeta(theta, 2, 5)\nposterior &lt;- (prior_2_5 * likelihood) / sum(prior_2_5 * likelihood)\n\nVisualizziamo le tre distribuzioni:\n\ndf &lt;- data.frame(\n  theta, \n  prior = prior_2_5 / sum(prior_2_5), \n  likelihood = likelihood / sum(likelihood), \n  posterior\n  )\n\ndf_long &lt;- df |&gt;\n  pivot_longer(cols = c(\"prior\", \"likelihood\", \"posterior\"),\n               names_to = \"Distribuzione\", values_to = \"Densità\")\n\nggplot(df_long, aes(x = theta, y = Densità, color = Distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(x = expression(theta), y = \"Densità\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nInterpretazione. L’aggiornamento bayesiano con una distribuzione a priori continua fornisce una stima aggiornata di \\(\\theta\\), la probabilità che un adulto giudichi moralmente accettabile l’azione proposta nel dilemma. Questa stima tiene conto sia delle credenze iniziali (prior) sia dell’evidenza empirica (verosimiglianza).\nNel nostro esempio, la distribuzione a posteriori risulta spostata verso valori alti rispetto al prior simmetrico \\(\\text{Beta}(2,2)\\), riflettendo l’evidenza che 22 partecipanti su 30 hanno espresso un giudizio di accettabilità. In alternativa, utilizzando un prior asimmetrico come \\(\\text{Beta}(2,5)\\), la distribuzione a posteriori mostra un compromesso: da un lato la tendenza iniziale a ritenere poco probabile l’accettazione morale, dall’altro i dati osservati che indicano una proporzione maggiore di giudizi favorevoli.\nSintesi didattica. Questo esempio illustra il cuore dell’inferenza bayesiana: la conoscenza non è mai statica, ma si aggiorna continuamente integrando dati empirici e credenze iniziali in modo trasparente e quantitativo.\n\n\n\n\n\n\nApprofondimento — Metodo su griglia con la Normale (media ignota, \\(\\sigma\\) nota)\n\n\n\n\n\nIl metodo su griglia non vale solo per la Binomiale: si applica anche al caso Normale quando vogliamo stimare la media \\(\\mu\\) assumendo la deviazione standard nota. L’idea è la stessa: scegliamo una griglia di valori plausibili per \\(\\mu\\), calcoliamo la verosimiglianza per ciascun valore, la combiniamo con il prior e normalizziamo per ottenere la posterior.\nScenario. Studiamo i punteggi di QI di bambini ad alto potenziale. Supponiamo che i punteggi seguano una Normale con deviazione standard nota \\(\\sigma = 5\\), mentre la media \\(\\mu\\) è ignota. Usiamo un prior informativo \\(\\mu \\sim \\mathcal{N}(140, 3^2)\\).\n\n43.5.2 Dati ed elementi del modello\n\nset.seed(123)\ncampione &lt;- round(rnorm(10, mean = 130, sd = 5))  # 10 osservazioni simulate\ncampione\n#&gt;  [1] 127 129 138 130 131 139 132 124 127 128\nsigma &lt;- 5\n\nLa verosimiglianza congiunta per un dato \\(\\mu\\) è il prodotto delle densità Normali:\n\\[\nL(\\mu) \\;=\\; \\prod_{i=1}^n \\text{Normal}\\bigl(y_i \\mid \\mu, \\sigma\\bigr).\n\\]\nNel calcolo numerico conviene usare i logaritmi (stabilità): il prodotto diventa somma.\n\n43.5.3 Metodo su griglia (versione stabile)\n\n# Griglia di valori plausibili per mu: centrata tra prior e dati\nmu_griglia &lt;- seq(120, 150, length.out = 400)\n\n# Log-verosimiglianza: somma delle densità log-normali\nlog_lik &lt;- sapply(mu_griglia, function(mu)\n  sum(dnorm(campione, mean = mu, sd = sigma, log = TRUE))\n)\n\n# Prior (log-densità normale): mu ~ N(140, 3^2)\nlog_prior &lt;- dnorm(mu_griglia, mean = 140, sd = 3, log = TRUE)\n\n# Log-posterior non normalizzata\nlog_post_unnorm &lt;- log_lik + log_prior\n\n# Normalizzazione numericamente stabile (log-sum-exp)\nlog_post_stab &lt;- log_post_unnorm - max(log_post_unnorm)\npost &lt;- exp(log_post_stab)\npost &lt;- post / sum(post)  # posterior discreta sulla griglia (somma = 1)\n\n# Sommari deterministici (somme pesate sulla griglia)\npost_mean &lt;- sum(mu_griglia * post)\npost_var  &lt;- sum((mu_griglia - post_mean)^2 * post)\npost_sd   &lt;- sqrt(post_var)\n\nc(media_post = post_mean, sd_post = post_sd)\n#&gt; media_post    sd_post \n#&gt;      132.6        1.4\n\n\n43.5.4 Visualizzare prior, verosimiglianza e posterior\nPer confrontare forme diverse (prior, verosimiglianza, posterior) portiamo verosimiglianza e prior “in scala comparabile” (solo a fini grafici).\n\n# Rescaling per confronto visivo (non usato nei calcoli)\nprior_vis &lt;- dnorm(mu_griglia, mean = 140, sd = 3)\nprior_vis &lt;- prior_vis / max(prior_vis)\n\nlik_vis   &lt;- exp(log_lik - max(log_lik))  # anche qui versione stabile\n\ndf &lt;- tibble(\n  mu = mu_griglia,\n  Prior = prior_vis,\n  Verosimiglianza = lik_vis,\n  Posterior = post / max(post)\n)\n\ndf |&gt;\n  pivot_longer(-mu, names_to = \"Distribuzione\", values_to = \"Densita\") |&gt;\n  ggplot(ggplot2::aes(x = mu, y = Densita, color = Distribuzione)) +\n  geom_line(linewidth = 1.1) +\n  geom_vline(xintercept = mean(campione), linetype = \"dashed\") +\n  geom_vline(xintercept = 140, linetype = \"dotted\") +\n  geom_vline(xintercept = post_mean, linetype = \"dotdash\") +\n  labs(\n    x = expression(mu), y = \"Scala comparabile\\n(solo per confronto visivo)\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nCome leggere il grafico. La verosimiglianza (linea centrata sulla media campionaria) riflette dove i dati sono più plausibili; il prior rappresenta la conoscenza iniziale (centrata a 140); la posterior è il compromesso bayesiano tra i due. Con più dati, la posterior tende ad avvicinarsi e a stringersi attorno alla media empirica.\n\n43.5.5 Collegamento con la soluzione analitica (conjugacy)\nNel caso Normale con \\(\\sigma\\) nota e prior Normale per \\(\\mu\\), la posterior è ancora Normale:\n\\[\n\\mu \\mid y \\;\\sim\\; \\mathcal{N}\\!\\Bigl(\\,\\mu_\\text{post},\\, \\tau_\\text{post}^2\\Bigr),\n\\]\ndove\n\\[\n\\tau_\\text{post}^2\n= \\left(\\frac{n}{\\sigma^2} + \\frac{1}{\\tau_0^2}\\right)^{-1},\n\\qquad\n\\mu_\\text{post}\n= \\tau_\\text{post}^2\\left(\\frac{n\\,\\bar y}{\\sigma^2} + \\frac{\\mu_0}{\\tau_0^2}\\right).\n\\]\nQui \\(\\mu\\_0=140\\) e \\(\\tau\\_0=3\\) sono media e deviazione standard del prior; \\(\\bar y\\) è la media campionaria.\nVerifichiamo numericamente l’accordo con la griglia:\n\nn      &lt;- length(campione)\nybar   &lt;- mean(campione)\nmu0    &lt;- 140\ntau0   &lt;- 3\n\ntau2_post &lt;- 1 / (n / sigma^2 + 1 / tau0^2)\nmu_post   &lt;- tau2_post * (n * ybar / sigma^2 + mu0 / tau0^2)\nsd_post   &lt;- sqrt(tau2_post)\n\nc(analitico_media = mu_post, analitico_sd = sd_post,\n  griglia_media   = post_mean, griglia_sd   = post_sd)\n#&gt; analitico_media    analitico_sd   griglia_media      griglia_sd \n#&gt;           132.6             1.4           132.6             1.4\n\nI risultati coincidono (entro il passo di griglia), mostrando che il metodo su griglia “ricostruisce” la soluzione coniugata. Questo è didatticamente utile: gli studenti vedono sia la meccanica computazionale (griglia + normalizzazione) sia la struttura teorica (conjugacy).\n\n43.5.6 Nota numerica: perché i logaritmi\nLa verosimiglianza congiunta è il prodotto di molte densità, quindi può diventare numericamente piccolissima. Usare le somme dei logaritmi evita l’underflow e rende stabile la normalizzazione finale (tramite il trucco “log-sum-exp”). È una buona pratica anche con campioni moderati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/04_subj_prop.html#riflessioni-conclusive",
    "title": "43  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo affrontato uno dei casi più fondamentali dell’inferenza statistica: la stima della proporzione di successi. Attraverso la combinazione della verosimiglianza binomiale con un prior Beta, abbiamo visto come il teorema di Bayes ci consenta di ottenere una distribuzione a posteriori che rappresenta in maniera trasparente la nostra incertezza riguardo al parametro di interesse. Questo esempio, per quanto elementare, ci permette di osservare in azione la logica dell’aggiornamento bayesiano presentata nei capitoli precedenti: ciò che sapevamo prima viene modificato dalla nuova evidenza empirica, producendo credenze aggiornate che incorporano tanto le informazioni pregresse quanto i dati osservati.\nQuesta applicazione mette in luce un punto centrale che ha accompagnato tutta la nostra discussione fino a qui: l’incertezza non è un ostacolo da eliminare, ma una componente intrinseca e inevitabile dell’inferenza scientifica. Al contrario di quanto avviene in molti approcci tradizionali, dove il risultato viene spesso ridotto a un singolo numero o a un verdetto dicotomico, il metodo bayesiano ci offre una rappresentazione più onesta e informativa, in cui diversi valori rimangono plausibili con gradi di sostegno differenti. La distinzione tra conoscenza preliminare (prior), evidenza empirica (dati) e credenze aggiornate (posterior) fornisce così un quadro concettuale coerente e cumulativo, che si integra con le riflessioni sviluppate nei capitoli precedenti sulla crisi di replicabilità e sulla necessità di modelli trasparenti e confrontabili.\nDal punto di vista computazionale, l’approccio basato su griglia che abbiamo utilizzato si è rivelato particolarmente utile come strumento didattico. La sua logica è semplice e intuitiva: si discretizza lo spazio dei parametri, si calcolano prior e verosimiglianza in ciascun punto e si normalizza per ottenere una distribuzione coerente di probabilità. Questa procedura esplicita, anche se rudimentale, permette di visualizzare con chiarezza i passaggi fondamentali dell’inferenza bayesiana e di comprenderne la natura dinamica. Tuttavia, sappiamo che la sua utilità pratica diminuisce rapidamente con l’aumentare della complessità dei modelli: la cosiddetta maledizione della dimensionalità1 rende presto insostenibile il calcolo.\nQuesta consapevolezza ci prepara ad affrontare, nei prossimi capitoli, strumenti più sofisticati come i metodi di campionamento MCMC. Essi sono concettualmente più complessi, ma offrono la potenza computazionale necessaria per affrontare modelli realistici e a più alta dimensionalità, mantenendo però intatta la logica di fondo che abbiamo visto emergere anche nel caso semplice del modello binomiale. In questo senso, il metodo a griglia conserva il suo valore formativo: è un punto di accesso privilegiato al pensiero bayesiano, un laboratorio concettuale in cui gli studenti possono osservare direttamente come si realizza l’aggiornamento delle credenze, prima di cimentarsi con strumenti più potenti e astratti.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nPartire da casi semplici come la proporzione di successi ci aiuta a capire in profondità l’idea centrale: l’inferenza bayesiana non fornisce un numero definitivo, ma una distribuzione che rappresenta i valori plausibili e il grado di incertezza associato. Nei prossimi capitoli vedremo come questa logica si estenda a modelli più articolati, inclusi quelli che cercano di rappresentare i processi psicologici che generano i dati.\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn uno studio sulla percezione delle emozioni, un partecipante osserva 10 fotografie di volti arrabbiati. Deve indicare se il volto esprime rabbia o no. Ogni risposta può essere corretta (1) o errata (0).\nI dati osservati del partecipante sono:\n1, 0, 1, 1, 1, 0, 0, 1, 1, 1\n→ Totale: 7 successi su 10 prove → \\(y = 7\\), \\(n = 10\\).\nObiettivo: stimare la probabilità \\(\\theta\\) che il partecipante riconosca correttamente un volto arrabbiato, tenendo conto sia dei dati osservati sia di conoscenze pregresse.\nPrior Informativo.\nSupponiamo di voler adottare un approccio cautamente pessimistico sulle capacità iniziali del partecipante, basandoci su studi precedenti che indicano un riconoscimento della rabbia non sempre accurato, ad esempio mediamente intorno al 40% con moderata incertezza.\nPer rappresentare questa convinzione, scegliamo come distribuzione a priori una Beta(4, 6):\n\n\nMedia: \\(\\mu = \\frac{4}{4+6} = 0.4\\)\n\n\nVarianza: \\(\\frac{4 \\cdot 6}{(10)^2 \\cdot 11} = 0.0218\\)\n\n\nQuesta prior concentra la massa di probabilità su valori inferiori a 0.5, ma lascia spazio anche a livelli di competenza superiori.\nCalcolo della Distribuzione a Posteriori con il Metodo Basato su Griglia.\n1. Griglia di valori per \\(\\theta\\).\n\ntheta &lt;- seq(0, 1, length.out = 1000)\nhead(theta)\n#&gt; [1] 0.00000 0.00100 0.00200 0.00300 0.00400 0.00501\ntail(theta)\n#&gt; [1] 0.995 0.996 0.997 0.998 0.999 1.000\n\n2. Calcolo della distribuzione a priori Beta(4, 6).\n\nprior &lt;- dbeta(theta, shape1 = 4, shape2 = 6)\nprior &lt;- prior / sum(prior)  # normalizzazione\n\nVisualizzazione:\n\nggplot(data.frame(theta, prior), aes(x = theta, y = prior)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Densità (normalizzata)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n3. Calcolo della verosimiglianza per 7 successi su 10.\n\nlikelihood &lt;- dbinom(7, size = 10, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood)  # normalizzazione\n\nVisualizzazione:\n\nggplot(data.frame(theta, likelihood), aes(x = theta, y = likelihood)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Densità (normalizzata)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n4. Calcolo della distribuzione a posteriori.\n\nunnormalized_posterior &lt;- prior * likelihood\nposterior &lt;- unnormalized_posterior / sum(unnormalized_posterior)\n\n5. Visualizzazione congiunta: prior, likelihood e posteriori.\n\ndata &lt;- data.frame(theta, prior, likelihood, posterior)\n\n# Imposta i livelli desiderati con nomi leggibili\nlong_data &lt;- pivot_longer(\n  data,\n  cols = c(\"prior\", \"likelihood\", \"posterior\"),\n  names_to = \"distribution\",\n  values_to = \"density\"\n) |&gt;\n  mutate(distribution = factor(\n    distribution,\n    levels = c(\"prior\", \"likelihood\", \"posterior\"),\n    labels = c(\"A Priori\", \"Verosimiglianza\", \"A Posteriori\")\n    )\n  )\n\nggplot(\n  long_data, \n  aes(x = theta, y = density, color = distribution)\n  ) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Densità (normalizzata)\",\n    color = NULL\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nRiepilogo:\n\nla prior (Beta(4,6)) riflette una convinzione iniziale più scettica;\nla verosimiglianza è centrata su \\(\\theta = 0.7\\), corrispondente a 7 successi su 10;\nla posteriori media tra prior e dati, ma si sposta chiaramente verso destra, evidenziando l’effetto aggiornamento bayesiano.\n\nQuesto esempio mostra come l’approccio bayesiano:\n\n\nintegra in modo trasparente dati individuali e credenze pregresse;\n\nproduce una stima personalizzata della capacità del partecipante;\npermette di quantificare l’incertezza in modo completo, tramite la distribuzione a posteriori.\n\nQuantità a Posteriori.\nMedia:\n\nposterior_mean &lt;- sum(theta * posterior)\nposterior_mean\n#&gt; [1] 0.55\n\nDeviazione standard:\n\nposterior_sd &lt;- sqrt(sum((theta^2) * posterior) - posterior_mean^2)\nposterior_sd\n#&gt; [1] 0.109\n\nModa:\n\nposterior_mode &lt;- theta[which.max(posterior)]\nposterior_mode\n#&gt; [1] 0.556\n\nIntervallo di credibilità al 94%:\n\nsamples &lt;- sample(theta, size = 10000, replace = TRUE, prob = posterior)\nquantile(samples, probs = c(0.03, 0.97))\n#&gt;    3%   97% \n#&gt; 0.342 0.750\n\nQuesto esercizio mostra come:\n\nl’informazione pregressa può essere incorporata in modo trasparente in un modello bayesiano;\nla posteriori riflette una combinazione tra dati osservati e conoscenze precedenti.\n\n\n\n\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nIn uno studio sull’analisi delle pratiche di trasparenza e riproducibilità nella ricerca in psicologia, Hardwicke et al. (2022) hanno riportato che la condivisione dei materiali di ricerca è stata rilevata nel 14% dei casi (26 su 183 studi), con un intervallo di confidenza al 95% pari a [10%, 19%]. Questo suggerisce che la condivisione di materiali è rara.\nIspirandoti ai risultati di questo studio, costruisci una distribuzione a priori per la probabilità \\(\\theta\\) che uno studio condivida i materiali di ricerca. Per semplicità, discretizza \\(\\theta\\) in 10 livelli equispaziati: \\(0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95\\).\nAttribuisci le seguenti probabilità a priori ai 10 livelli, basandoti sull’informazione che la condivisione dei materiali è un evento raro ma non trascurabile: \\(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02\\).\nSupponiamo che siano stati osservati 20 studi su 100 che hanno condiviso i materiali di ricerca. Calcola la distribuzione a posteriori utilizzando il metodo basato su griglia. Calcola la media della distribuzione a posteriori e l’intervallo di credibilità al 89%.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n# Definizione dei possibili valori di theta (probabilità discreta)\ntheta &lt;- seq(0.05, 0.95, by = 0.10)\n\n# Definizione della distribuzione a priori\nprior &lt;- c(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02)\n\n# Normalizzazione della prior (se necessario, ma in questo caso già normalizzata)\nprior &lt;- prior / sum(prior)\n\n# Dati osservati\nsuccessi &lt;- 20  # studi che hanno condiviso materiali\nn &lt;- 100        # studi totali\n\n# Calcolo della verosimiglianza usando la distribuzione binomiale\nlikelihood &lt;- dbinom(successi, size = n, prob = theta)\n\n# Calcolo della distribuzione a posteriori (applicazione del teorema di Bayes)\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)  # Normalizzazione\n\n# Calcolo della media della distribuzione a posteriori\nposterior_mean &lt;- sum(theta * posterior)\n\n# Calcolo dell'intervallo di credibilità al 89%\ncdf &lt;- cumsum(posterior)  # Distribuzione cumulativa\nlower_bound &lt;- theta[which.min(abs(cdf - 0.055))]  # 5.5% quantile\nupper_bound &lt;- theta[which.min(abs(cdf - 0.945))]  # 94.5% quantile\n\n# Output dei risultati\nlist(\n  posterior_mean = posterior_mean,\n  credibility_interval_89 = c(lower_bound, upper_bound)\n)\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nL’obiettivo di questo esercizio è applicare il metodo basato su griglia per stimare la distribuzione a posteriori di una proporzione, utilizzando dati dalla Scala della Rete Sociale di Lubben (LSNS-6). Si assume che un punteggio LSNS-6 superiore a una soglia prefissata indichi isolamento sociale. Il compito è:\n\nScegliere una soglia per classificare i partecipanti in due gruppi (isolati vs. non isolati), garantendo che la proporzione osservata non sia inferiore a 0.1 o superiore a 0.9.\nCalcolare la distribuzione a posteriori della proporzione usando un’approssimazione discreta su una griglia di valori.\nDeterminare l’intervallo di credibilità all’89%.\nInterpretare i risultati.\n\nConsegna: caricare su Moodle il file .qmd compilato in pdf.\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nDati e Modellizzazione\nSi assume che i dati siano rappresentati da una variabile binaria \\(y\\), con \\(y = 1\\) per individui classificati come isolati e \\(y = 0\\) altrimenti. Supponiamo che su un campione di \\(n\\) individui, \\(s\\) siano isolati.\nDefiniamo il modello statistico:\n\\[ y_i \\sim \\text{Bernoulli}(\\theta) \\]\ncon:\n\n\n\\(y_i \\in \\{0,1\\}\\) per \\(i=1,\\dots,n\\),\n\n\\(\\theta\\) proporzione di individui isolati nella popolazione.\n\nLa distribuzione a priori su \\(\\theta\\) è scelta come \\(\\text{Beta}(2,2)\\), che rappresenta una conoscenza iniziale moderata e non estrema.\nMetodo basato su griglia\nIl metodo a griglia approssima la distribuzione a posteriori calcolando la probabilità per una serie di valori discreti di \\(\\theta\\).\n\n\nDefinire una griglia di valori per \\(\\theta\\):\ntheta &lt;- seq(0, 1, length.out = 100)\n\n\nCalcolare la distribuzione a priori:\nprior &lt;- dbeta(theta, 2, 2)\nprior &lt;- prior / sum(prior)  # Normalizzazione\n\n\nCalcolare la verosimiglianza:\nlikelihood &lt;- dbinom(s, size = n, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood)  # Normalizzazione\n\n\nCalcolare la distribuzione a posteriori:\nposterior &lt;- prior * likelihood\nposterior &lt;- posterior / sum(posterior)  # Normalizzazione\n\n\n** Calcolo dell’intervallo di credibilità all’89%**\nL’intervallo di credibilità è calcolato come l’intervallo che contiene il 89% della probabilità a posteriori.\nci_89 &lt;- quantile(sample(theta, size = 10000, prob = posterior, replace = TRUE), probs = c(0.055, 0.945))\nci_89\nInterpretazione dei risultati\n\n\nValore atteso e moda a posteriori:\nmean_theta &lt;- sum(theta * posterior)\nmode_theta &lt;- theta[which.max(posterior)]\n\nIl valore atteso fornisce una stima puntuale di \\(\\theta\\).\nLa moda indica il valore più probabile della proporzione di isolamento sociale.\n\n\n\nIntervallo di credibilità:\n\nL’89% della probabilità a posteriori cade tra i valori dell’intervallo di credibilità.\nSe l’intervallo è stretto, c’è maggiore certezza sulla proporzione stimata.\nSe l’intervallo è ampio, vi è maggiore incertezza sulla proporzione.\n\n\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HDInterval_0.2.4      pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] pacman_0.5.1          digest_0.6.37         timechange_0.3.0     \n#&gt; [10] estimability_1.5.1    lifecycle_1.0.4       survival_3.8-3       \n#&gt; [13] magrittr_2.0.3        compiler_4.5.1        rlang_1.1.6          \n#&gt; [16] tools_4.5.1           yaml_2.3.10           knitr_1.50           \n#&gt; [19] labeling_0.4.3        bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [22] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [25] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [28] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [31] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [34] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [37] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [40] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [43] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [46] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#&gt; [49] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [52] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [55] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [58] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [61] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [64] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [67] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [70] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#&gt; [73] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [76] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [79] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#bibliografia",
    "href": "chapters/bayesian_inference/04_subj_prop.html#bibliografia",
    "title": "43  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBucciarelli, M., Khemlani, S., & Johnson-Laird, P. N. (2008). The psychology of moral reasoning. Judgment and Decision making, 3(2), 121–139.\n\n\nFoot, P. (1967). The problem of abortion and the doctrine of the double effect. Oxford Review, 5, 5–15.\n\n\nGreene, J. D., Sommerville, R. B., Nystrom, L. E., Darley, J. M., & Cohen, J. D. (2001). An fMRI investigation of emotional engagement in moral judgment. Science, 293(5537), 2105–2108.\n\n\nHardwicke, T. E., Thibault, R. T., Kosie, J. E., Wallach, J. D., Kidwell, M. C., & Ioannidis, J. P. (2022). Estimating the prevalence of transparency and reproducibility-related research practices in psychology (2014–2017). Perspectives on Psychological Science, 17(1), 239–251.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#footnotes",
    "href": "chapters/bayesian_inference/04_subj_prop.html#footnotes",
    "title": "43  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "",
    "text": "La maledizione della dimensionalità si riferisce al fatto che lo spazio dei parametri cresce in modo esponenziale con il numero delle dimensioni. Se, ad esempio, dividiamo ogni parametro in 100 possibili valori e vogliamo esplorare un modello con 10 parametri, dovremmo valutare \\(100^{10} = 10^{20}\\) combinazioni: un numero astronomico, impossibile da gestire con un approccio esaustivo a griglia. Questo rende necessarie tecniche di campionamento più efficienti, come i metodi Monte Carlo che introdurremo nei capitoli successivi.↩︎",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families.html",
    "href": "chapters/bayesian_inference/05_conjugate_families.html",
    "title": "44  Distribuzioni coniugate",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto in azione l’aggiornamento bayesiano in un caso concreto: la stima della proporzione di successi con il modello Beta-Binomiale. Lì abbiamo osservato come la distribuzione a priori (Beta) e la verosimiglianza (Binomiale) si combinino attraverso il teorema di Bayes per produrre una distribuzione a posteriori che appartiene alla stessa famiglia della prior. Questo ci ha permesso di seguire passo dopo passo l’evoluzione delle nostre credenze in modo intuitivo e matematicamente elegante.\nIn questo capitolo generalizziamo questa idea e introduciamo il concetto di distribuzioni coniugate. Due distribuzioni sono dette coniugate quando, combinando una prior con la corrispondente verosimiglianza, otteniamo un posterior che appartiene alla stessa famiglia della prior. In altre parole, la forma della distribuzione rimane stabile, e a cambiare sono soltanto i parametri.\nQuesta proprietà, apparentemente tecnica, ha in realtà un grande valore didattico e pratico. Dal punto di vista concettuale, ci aiuta a visualizzare con chiarezza come i dati modifichino le nostre credenze: i parametri della distribuzione si aggiornano in modo diretto e cumulativo. Dal punto di vista operativo, rende il calcolo immediato, senza dover ricorrere a metodi di approssimazione numerica.\nNaturalmente, sappiamo già dai capitoli precedenti che il mondo reale è spesso più complesso: non sempre abbiamo a disposizione una coppia coniugata, e per modelli più articolati ricorriamo a metodi computazionali come il campionamento MCMC. Ma prima di affrontare quei casi, è utile familiarizzare con le famiglie coniugate, che costituiscono il laboratorio ideale per comprendere a fondo la logica dell’aggiornamento bayesiano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families.html#introduzione",
    "href": "chapters/bayesian_inference/05_conjugate_families.html#introduzione",
    "title": "44  Distribuzioni coniugate",
    "section": "",
    "text": "Panoramica del capitolo\n\nIntroduzione del modello beta-binomiale.\nAnalisi della distribuzione Beta e del suo ruolo come distribuzione a priori.\nAescrizione del processo di aggiornamento bayesiano e dei vantaggi derivanti dall’uso di distribuzioni coniugate.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Conjugate Families del testo di Johnson et al. (2022).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt;\n    source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families.html#il-modello-beta-binomiale",
    "href": "chapters/bayesian_inference/05_conjugate_families.html#il-modello-beta-binomiale",
    "title": "44  Distribuzioni coniugate",
    "section": "\n44.1 Il modello Beta-Binomiale",
    "text": "44.1 Il modello Beta-Binomiale\nIl modello beta-binomiale è un esempio classico per analizzare una proporzione \\(\\theta\\), ossia la probabilità di successo in una sequenza di prove binarie (ad esempio, successo/fallimento). Supponiamo di osservare \\(y\\) successi su \\(n\\) prove, dove ogni prova è indipendente e con la stessa probabilità di successo \\(\\theta\\), che appartiene all’intervallo \\([0,1]\\).\nLa funzione di verosimiglianza, basata sulla distribuzione binomiale, è espressa come:\n\\[\n\\mathcal{Binomial}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\] dove \\(\\binom{n}{y}\\) è il coefficiente binomiale che conta il numero di modi in cui \\(y\\) successi possono verificarsi in \\(n\\) prove.\nPer modellare la nostra conoscenza preliminare su \\(\\theta\\), scegliamo una distribuzione a priori Beta, che rappresenta un’ampia gamma di credenze iniziali con parametri flessibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families.html#la-distribuzione-beta",
    "href": "chapters/bayesian_inference/05_conjugate_families.html#la-distribuzione-beta",
    "title": "44  Distribuzioni coniugate",
    "section": "\n44.2 La distribuzione Beta",
    "text": "44.2 La distribuzione Beta\nLa distribuzione Beta è definita come:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{con } \\theta \\in (0, 1),\n\\] dove:\n\n\\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\) sono i parametri che determinano la forma della distribuzione,\n\n\\(B(\\alpha, \\beta)\\) è la funzione Beta di Eulero, calcolata come:\n\\[\n  B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)},\n  \\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, una generalizzazione del fattoriale.\n\n\nIn termini bayesiani, possiamo pensare a questi parametri nel modo seguente:\n\n\n\\(\\alpha -1\\) rappresenta il numero ipotetico di “successi” a priori,\n\n\\(\\beta -1\\) rappresenta il numero ipotetico di “fallimenti” a priori.\n\nAd esempio:\n\nuna distribuzione Beta(1, 1) è uniforme (0 successi a priori e 0 fallimenti), indicando totale incertezza iniziale (assenza di credenze informate);\nuna distribuzione Beta(10, 20) rappresenta una conoscenza a priori basata su 9 successi e 19 fallimenti ipotizzati, indicando una convinzione iniziale relativamente solida, poiché deriva da un totale di 28 osservazioni virtuali che riflettono le nostre credenze precedenti.\n\nQuesta interpretazione consente di calibrare le credenze a priori in base all’evidenza disponibile o alla fiducia nella stima.\nLa distribuzione Beta è estremamente versatile:\n\nvalori diversi di \\(\\alpha\\) e \\(\\beta\\) producono distribuzioni simmetriche, asimmetriche o uniformi;\nvalori elevati di \\(\\alpha\\) e \\(\\beta\\) riducono la varianza, riflettendo credenze più forti.\n\nQuesta flessibilità rende la distribuzione Beta una scelta ideale per rappresentare credenze iniziali sulle proporzioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families.html#aggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/05_conjugate_families.html#aggiornamento-bayesiano",
    "title": "44  Distribuzioni coniugate",
    "section": "\n44.3 Aggiornamento bayesiano",
    "text": "44.3 Aggiornamento bayesiano\nL’aggiornamento bayesiano combina le informazioni iniziali (distribuzione a priori) con i dati osservati (verosimiglianza) per produrre una nuova distribuzione delle nostre credenze (distribuzione a posteriori). Nel caso del modello beta-binomiale, questo processo è particolarmente semplice grazie alla “coniugazione”: il prior Beta e la verosimiglianza Binomiale producono una distribuzione a posteriori che appartiene ancora alla famiglia Beta.\n\nTeorema 44.1 Sia \\(Y\\sim\\mathrm{Binomial}(n,\\theta)\\) il numero di successi \\(y\\) in \\(n\\) prove indipendenti con probabilità di successo \\(\\theta\\), e sia la nostra distribuzione a priori su \\(\\theta\\) una Beta\\(\\bigl(\\alpha,\\beta\\bigr).\\) Allora la distribuzione a posteriori di \\(\\theta\\) dato l’osservazione \\(Y=y\\) è\n\\[\n\\theta \\mid Y=y\n\\;\\sim\\;\n\\mathrm{Beta}\\bigl(\\alpha + y,\\;\\beta + (n - y)\\bigr),\n\\tag{44.1}\\] ovvero i parametri si aggiornano come\n\\[\n\\alpha' = \\alpha + y,\n\\quad\n\\beta' = \\beta + n - y.\n\\tag{44.2}\\]\n\n\n\n\n\n\n\nDerivazione.\n\n\n\n\n\nObiettivo. Mostrare che, con prior \\(\\theta \\sim \\mathrm{Beta}(\\alpha,\\beta)\\) e dati \\(Y\\sim\\mathrm{Binomiale}(n,\\theta)\\), la posteriori è\n\\[\n\\theta \\mid Y=y \\;\\sim\\; \\mathrm{Beta}\\bigl(\\alpha+y,\\;\\beta+n-y\\bigr).\n\\]\n1) Formula di Bayes (forma proporzionale). Per qualunque \\(\\theta\\in(0,1)\\):\n\\[\np(\\theta\\mid y)\\;\\propto\\; p(y\\mid\\theta)\\, p(\\theta),\n\\] dove “\\(\\propto\\)” significa “uguale a una costante (che non dipende da \\(\\theta\\)) per…”. Quella costante verrà ripristinata alla fine.\n2) Verosimiglianza binomiale (parte che dipende da \\(\\theta\\)).\n\\[\np(y\\mid\\theta) \\;=\\; \\binom{n}{y}\\,\\theta^{\\,y}\\,(1-\\theta)^{\\,n-y}.\n\\] Poiché \\(\\binom{n}{y}\\) non dipende da \\(\\theta\\), ai fini di “\\(\\propto\\)” possiamo scrivere:\n\\[\np(y\\mid\\theta)\\;\\propto\\; \\theta^{\\,y}\\,(1-\\theta)^{\\,n-y}.\n\\]\n3) Prior Beta (parte che dipende da \\(\\theta\\)).\n\\[\np(\\theta) \\;=\\; \\frac{1}{B(\\alpha,\\beta)}\\,\\theta^{\\,\\alpha-1}\\,(1-\\theta)^{\\,\\beta-1},\n\\] e dunque, ignorando la costante \\(B(\\alpha,\\beta)\\):\n\\[\np(\\theta)\\;\\propto\\;\\theta^{\\,\\alpha-1}\\,(1-\\theta)^{\\,\\beta-1}.\n\\]\n4) Prodotto “prior × verosimiglianza”. Moltiplichiamo i soli termini che dipendono da \\(\\theta\\):\n\\[\n\\begin{aligned}\np(\\theta\\mid y)\n&\\;\\propto\\; \\bigl[\\theta^{\\,y}(1-\\theta)^{\\,n-y}\\bigr]\\;\\bigl[\\theta^{\\,\\alpha-1}(1-\\theta)^{\\,\\beta-1}\\bigr] \\\\\n&\\;=\\; \\theta^{\\,(\\alpha-1)+y}\\; (1-\\theta)^{\\,(\\beta-1)+(n-y)}.\n\\end{aligned}\n\\]\n5) Riconoscere la forma Beta (matching degli esponenti). La forma non normalizzata di una \\(\\mathrm{Beta}(a,b)\\) è:\n\\[\n\\theta^{\\,a-1}\\,(1-\\theta)^{\\,b-1}.\n\\] Confrontando gli esponenti otteniamo:\n\\[\na-1 = (\\alpha-1)+y \\;\\;\\Rightarrow\\;\\; a = \\alpha + y,\n\\] \\[\nb-1 = (\\beta-1)+(n-y) \\;\\;\\Rightarrow\\;\\; b = \\beta + (n-y).\n\\] Quindi la densità non normalizzata della distribuzione a posteriori è\n\\[\np(\\theta\\mid y)\\;\\propto\\;\\theta^{\\,(\\alpha+y)-1}\\,(1-\\theta)^{\\,(\\beta+n-y)-1}.\n\\]\n6) Ripristino della costante di normalizzazione. Per essere una densità, \\(p(\\theta\\mid y)\\) deve integrare a 1 su \\(\\theta\\in(0,1)\\). La costante corretta è l’inverso della funzione Beta con i nuovi parametri:\n\\[\np(\\theta\\mid y)\n\\;=\\;\n\\frac{1}{B(\\alpha+y,\\;\\beta+n-y)}\\;\n\\theta^{\\,(\\alpha+y)-1}\\,(1-\\theta)^{\\,(\\beta+n-y)-1}.\n\\]\n7) Conclusione (forma parametrica della posteriori).\n\\[\n\\boxed{\n\\;\\theta\\mid Y=y \\;\\sim\\; \\mathrm{Beta}\\bigl(\\alpha+y,\\;\\beta+n-y\\bigr).\\;\n}\n\\]\nIntuizione in termini di “pseudocontenuti di informazione”.\n\nLa Beta\\((\\alpha,\\beta)\\) può essere interpretata in termini di pseudoconteggi: \\(\\alpha-1\\) “successi” e \\(\\beta-1\\) “insuccessi” precedenti ai dati.\n\nDopo aver osservato \\(y\\) successi e \\(n-y\\) insuccessi, si sommano i conteggi:\n\\[\n\\alpha \\to \\alpha+y,\\qquad \\beta \\to \\beta+(n-y).\n\\]\n\nQuesta additività spiega la conjugatezza: prior e posterior appartengono alla stessa famiglia.\n\nControllo rapido della normalizzazione. Usiamo la definizione di \\(B(a,b)\\):\n\\[\nB(a,b) \\;=\\; \\int_0^1 \\theta^{a-1}(1-\\theta)^{b-1}\\,d\\theta.\n\\] Con \\(a=\\alpha+y\\) e \\(b=\\beta+n-y\\), l’integrale della nostra forma non normalizzata è \\(B(\\alpha+y,\\beta+n-y)\\); moltiplicando per \\(1/B(\\alpha+y,\\beta+n-y)\\) otteniamo dunque una densità che integra a 1.\n\n\n\n\n\n\n\n\n\nAlcune quantità riassuntive utili.\n\n\n\n\n\nPer \\(\\theta\\mid y \\sim \\mathrm{Beta}(\\alpha+y,\\beta+n-y)\\):\n\n\nMedia posteriori:\n\\[\n\\mathbb{E}[\\theta\\mid y] \\;=\\; \\frac{\\alpha+y}{\\alpha+\\beta+n}.\n\\]\n\n\nModa (se parametri \\(&gt;1\\)):\n\\[\n\\frac{\\alpha+y-1}{\\alpha+\\beta+n-2}.\n\\]\n\n\nVarianza:\n\\[\n\\mathrm{Var}(\\theta\\mid y) \\;=\\;\n\\frac{(\\alpha+y)(\\beta+n-y)}{(\\alpha+\\beta+n)^2\\,(\\alpha+\\beta+n+1)}.\n\\]\n\n\n\n\n\n\n44.3.1 Vantaggi del modello Beta-Binomiale\n\n\nSemplicità analitica: la coniugatezza della distribuzione Beta-Binomiale semplifica i calcoli, rendendo immediato l’aggiornamento dei parametri.\n\nInterpretazione intuitiva: l’aggiornamento dei parametri \\(\\alpha\\) e \\(\\beta\\) mostra in modo trasparente come i dati influenzino le credenze.\n\nIn sintesi, il modello Beta-Binomiale è un esempio didattico fondamentale per comprendere l’inferenza bayesiana e rappresenta un punto di partenza ideale per approcci più avanzati.\n\n\n\n\n\n\nEsercizio 1.\n\n\n\n\n\nNel Capitolo 43 abbiamo utilizzato il metodo basato su griglia per determinare la distribuzione a posteriori nel caso di \\(y = 6\\) successi su \\(n = 9\\) prove (vedi anche McElreath, 2020 per una discussione dettagliata). Ora esploriamo un approccio alternativo, sfruttando le proprietà delle famiglie coniugate.\nLa verosimiglianza binomiale per questo esperimento è espressa dalla seguente funzione:\n\\[\n\\mathcal{L}(\\theta) \\propto \\theta^y (1-\\theta)^{n-y},\n\\] dove \\(y = 6\\) rappresenta il numero di successi e \\(n = 9\\) il numero totale di prove.\nScegliendo una distribuzione a priori Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 5\\), possiamo applicare il teorema di Bayes per calcolare i parametri aggiornati della distribuzione a posteriori. In base alla regola di aggiornamento per distribuzioni coniugate, otteniamo:\n\\[\n\\alpha' = \\alpha + y = 2 + 6 = 8.\n\\] \\[\n\\beta' = \\beta + n - y = 5 + 9 - 6 = 8.\n\\] La distribuzione a posteriori risultante è quindi una distribuzione Beta con parametri \\(\\mathcal{Beta}(8, 8)\\).\nProcediamo ora a visualizzare le tre distribuzioni rilevanti:\n\n\nDistribuzione a priori: \\(\\mathcal{Beta}(2, 2)\\),\n\nVerosimiglianza binomiale: per \\(y = 6\\) e \\(n = 9\\),\n\nDistribuzione a posteriori: \\(\\text{Beta}(8, 5)\\).\n\nEcco il codice R per generare il grafico comparativo:\n\n# Definizione dei parametri\nalpha_prior &lt;- 2\nbeta_prior &lt;- 5\ny &lt;- 6\nn &lt;- 9\n\n# Parametri della distribuzione a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\n# Sequenza di valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle PDF\nprior_pdf &lt;- dbeta(theta, shape1 = alpha_prior, shape2 = beta_prior)\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Normalizzazione della verosimiglianza\nlikelihood_integral &lt;- sum(likelihood) * (theta[2] - theta[1])\nnormalized_likelihood &lt;- likelihood / likelihood_integral\n\nposterior_pdf &lt;- dbeta(theta, shape1 = alpha_post, shape2 = beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = rep(theta, 3),\n  densita = c(prior_pdf, normalized_likelihood, posterior_pdf),\n  distribuzione = rep(c(\"Prior\", \"Likelihood\", \"Posterior\"), each = length(theta))\n)\n\n# Creare il grafico \nggplot(df, aes(x = theta, y = densita, color = distribuzione)) +\n  geom_line(size = 1) +  # Aggiungere le linee per le distribuzioni\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Likelihood\" = \"green\", \"Posterior\" = \"red\")) +  # Assegnare i colori\n  labs(title = \"Distribuzioni Prior, Likelihood e Posterior\",\n       x = expression(theta),\n       y = \"Densità\",\n       color = \"Distribuzione\") +  # Aggiungere titoli e label\n  theme(legend.position = \"top\")  # Posizionare la legenda in alto\n\n\n\n\n\n\n\n\n\nCurva blu: Prior \\(\\mathcal{Beta}(2, 5)\\), che riflette le credenze iniziali prima dell’osservazione dei dati.\n\n\nCurva verde: Likelihood (normalizzata), rappresenta l’evidenza fornita dai dati osservati.\n\n\nCurva rossa: Posterior \\(\\mathcal{Beta}(8, 8)\\), risultato dell’aggiornamento bayesiano che combina prior e likelihood.\n\nNota sulla normalizzazione della verosimiglianza. La verosimiglianza binomiale non è una distribuzione di probabilità (il suo integrale non è pari a 1). Per rappresentarla visivamente accanto alla distribuzione a priori e a quella a posteriori, è necessario normalizzarla. Questo è fatto calcolando il suo integrale su \\(\\theta \\in [0, 1]\\) e dividendo la funzione per il risultato. La normalizzazione serve solo per la visualizzazione e non influisce sui calcoli analitici.\n\n\n\n\n\n\n\n\n\nEsercizio 2.\n\n\n\n\n\nEsaminiamo ora un esempio discuso da Johnson et al. (2022). In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorità, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell’articolo, Milgram descrive lo studio come\n\nconsistente nell’ordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che è un complice addestrato dell’esperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un ‘esperimento di apprendimento’ apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l’esperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre più intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realtà era un attore addestrato) sulla loro capacità di memorizzare una serie di item. Se l’attore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all’attore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l’attore stesse solo fingendo di provare dolore dalla scossa.\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello “Pericolo: Scossa Grave”. Il problema richiede di costruire la distribuzione a posteriori della probabilità \\(\\theta\\) di infliggere una scossa a l livello “Pericolo: Scossa Grave”, ipotizzando che uno studio precedente aveva stabilito che \\(\\theta\\) segue una distribuzione Beta(1, 10).\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n# Impostazione dei parametri della distribuzione Beta\nalpha &lt;- 1\nbeta_val &lt;- 10\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, shape1 = alpha, shape2 = beta_val)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  x = x_values,\n  densita = beta_pdf\n)\n\n# Creare il grafico\nggplot(df, aes(x = x, y = densita)) +\n  geom_line(color = \"#b97c7c\", size = 1) +  # Aggiungere la linea per la densità\n  labs(title = \"Distribuzione Beta(1, 10)\",  # Aggiungere il titolo\n       x = \"x\",  # Label dell'asse x\n       y = \"Densità di probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  geom_vline(xintercept = 0, color = \"black\", linetype = \"dashed\", size = 0.5) +  # Linea verticale opzionale\n  geom_vline(xintercept = 1, color = \"black\", linetype = \"dashed\", size = 0.5) +  # Linea verticale opzionale\n  annotate(\"text\", x = 0.8, y = max(beta_pdf) * 0.9, label = \"Beta(1, 10)\", color = \"#b97c7c\", size = 5)  # Aggiungere una legenda\n\n\n\n\n\n\n\nLa distribuzione a posteriori segue una distribuzione Beta con parametri aggiornati:\n\ny &lt;- 26\nn &lt;- 40\n\nalpha_prior &lt;- 1\nbeta_prior &lt;- 10\n\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\nalpha_post\n#&gt; [1] 27\nbeta_post\n#&gt; [1] 24\n\nCreazione di un grafico per la distribuzione a posteriori:\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, alpha_post, beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = x_values,\n  densita = beta_pdf\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densità\n  labs(title = \"Distribuzione Beta(27, 24)\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Densità di probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  annotate(\"text\", x = 0.8, y = max(beta_pdf) * 0.9, label = \"Beta(27, 24)\", color = \"blue\", size = 5)  \n\n\n\n\n\n\n\nCalcolo della media a posteriori di \\(\\theta\\):\n\nalpha_post / (alpha_post + beta_post)\n#&gt; [1] 0.529\n\nCalcolo della moda a posteriori:\n\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n#&gt; [1] 0.531\n\nCalcolo della probabilità che \\(\\theta &gt; 0.6\\):\n\npbeta(0.6, alpha_post, beta_post, lower.tail = FALSE)\n#&gt; [1] 0.156\n\nOvvero:\n\n1 - pbeta(0.6, alpha_post, beta_post)\n#&gt; [1] 0.156\n\nEseguiamo il problema utilizzando il metodo basato su griglia. Definiamo la griglia di interesse:\n\ntheta &lt;- seq(0, 1, length.out = 100)\n\nCreiamo la distribuzione a priori:\n\nprior &lt;- dbeta(theta, alpha_prior, beta_prior)\n\n# Normalizzazione della densità per ottenere una somma pari a 1\nprior_normalized &lt;- prior / sum(prior)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = prior_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"blue\", size = 1) +  # Linee verticali per rappresentare le probabilità\n  labs(title = \"Distribuzione a priori\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nCreiamo la verosimiglianza:\n\nlk &lt;- dbinom(y, n, theta)\n\n# Normalizzazione della verosimiglianza per ottenere una somma pari a 1\nlk_normalized &lt;- lk / sum(lk)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = lk_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"red\", size = 1) +  # Linee verticali per rappresentare la verosimiglianza\n  labs(title = \"Verosimiglianza\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nCalcoliamo la distribuzione a posteriori:\n\npost &lt;- (prior * lk) / sum(prior * lk)\n\n# Normalizzazione della verosimiglianza per ottenere una somma pari a 1\nlk_normalized &lt;- lk / sum(lk)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = lk_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"green\", size = 1) +  # Linee verticali per rappresentare la verosimiglianza\n  labs(title = \"Distribuzione a posteriori\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nEstrazione di un campione dalla distribuzione a posteriori:\n\nsamples &lt;- sample(theta, size = 1e6, replace = TRUE, prob = post)\n\nTroviamo la media a posteriori:\n\nmean(samples)\n#&gt; [1] 0.529\n\nCalcoliamo la probabilità che \\(\\theta &gt; 0.6\\):\n\nmean(samples &gt; 0.6)\n#&gt; [1] 0.153\n\nQuesto codice mantiene la struttura logica del problema e produce risultati equivalenti utilizzando R.\n\n\n\n\n\n\n\n\n\nEsercizio 3.\n\n\n\n\n\nConsideriamo un esempio discusso da Nalborczyk (2018) nel quale, oltre all’applicazione del teorema beta-binimiale, viene anche introdotto il concetto di posterior-predictive check.\nSupponiamo di reclutare partecipanti per uno studio di mezza ora:\n\nPossiamo farlo fra le 9:00 e le 18:00, con sessioni ogni 30 minuti.\n\nIn una settimana lavorativa (lun–ven) otteniamo \\(n = 90\\) time slot.\n\nAd ogni slot, il partecipante o si presenta (\\(1\\)) o manca (\\(0\\)).\n\nVogliamo stimare la probabilità media di presenza, che chiameremo \\(\\theta\\).\nModello:\n\\[\n\\begin{cases}\n    Y \\mid \\theta \\;\\sim\\;\\mathrm{Binomial}(n,\\theta),\\\\[6pt]\n    \\theta \\;\\sim\\;\\mathrm{Beta}(\\alpha,\\beta).\n    \\end{cases}\n\\]\nScelta del prior:\n\nconoscenze pregresse suggeriscono che \\(\\theta\\) sia intorno a 0.5;\n\nscegliamo quindi un prior \\(\\;\\mathrm{Beta}(2,2)\\), che ha media \\(0.5\\) e riflette incertezza moderata.\n\nDati osservati:\n\n# vettore di 0/1 con n = 90 osservazioni\ny &lt;- c(\n  0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,0,0,\n  0,1,0,1,1,1,0,0,1,1,1,1,1,1,1,0,0,1,\n  1,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,\n  1,0,0,1,1,1,0,1,1,1,1,1,1,0,0,0,0,1,\n  0,1,0,1,1,1,0,0,0,0,0,1,1,1,1,1,1,0\n)\n\nCalcoliamo\n\nn &lt;- length(y)  # numero di slot = 90\nz &lt;- sum(y)     # numero di presenze = numero di 1\n\nPosterior Beta–Binomiale.\nI parametri aggiornati sono\n\\[\n\\alpha_{post} = \\alpha + z,\n\\quad\n\\beta_{post} = \\beta + (n - z).\n\\]\nIn particolare, con \\(\\alpha=\\beta=2\\):\n\na &lt;- b &lt;- 2\na_post &lt;- a + z\nb_post &lt;- b + (n - z)\n\nIl posterior è quindi\n\\[\n\\theta\\mid y \\;\\sim\\;\\mathrm{Beta}(a+z,\\;b+n-z).\n\\]\nVisualizzazione:\n\n# griglia per theta\ngrid &lt;- seq(0, 1, length.out = 1000)\n\n# densità\nprior     &lt;- dbeta(grid, a,      b)\nposterior &lt;- dbeta(grid, a_post, b_post)\n\ndf &lt;- data.frame(theta = grid,\n                 prior = prior,\n                 posterior = posterior)\n\nggplot(df) +\n  geom_area(aes(x = theta, y = prior,\n                fill = \"Prior\", colour = \"Prior\"),\n            alpha = 0.5, size = 1) +\n  geom_area(aes(x = theta, y = posterior,\n                fill = \"Posterior\", colour = \"Posterior\"),\n            alpha = 0.5, size = 1) +\n  scale_fill_grey(name = \"\") +\n  scale_colour_grey(name = \"\") +\n  theme_bw(base_size = 12) +\n  xlab(expression(theta)) +\n  ylab(\"\") +\n  ggtitle(\"Densità Prior e Posterior\\nmodello Beta–Binomiale\")\n\n\n\n\n\n\n\nIntroduzione ai posterior predictive checks.\nIl modello assume indipendenza fra i time slot. Se questa assunzione è violata (ad es. presenza autocorrelata nel tempo), le nostre stime potrebbero essere fuorvianti.\nIdea:\n\nSimulare \\(\\theta\\) dal posterior.\n\nDato ciascun \\(\\theta\\), generare una nuova serie \\(y^{rep}\\) da\\(\\mathrm{Binomial}(n,\\theta)\\).\n\nCalcolare su ogni \\(y^{rep}\\) una test-quantità \\(T(y^{rep})\\).\n\nConfrontare la distribuzione di \\(T(y^{rep})\\) con il valore osservato \\(T(y)\\).\n\nSe \\(T(y)\\) è un outlier rispetto ai \\(T(y^{rep})\\), l’assunzione di indipendenza è sospetta.\nTest‐quantità: numero di “switch”.\nDefiniamo una funzione che conta quante volte la serie passa da 0→1 o da 1→0:\n\ncount_switches &lt;- function(x) {\n  sum(abs(diff(x)) == 1)\n}\n\n# valore osservato\nTy &lt;- count_switches(y)\ncat(\"Switch osservati:\", Ty, \"\\n\")\n#&gt; Switch osservati: 28\n\nSimulazione e istogramma.\n\nset.seed(123)      # per riproducibilità\nnsims &lt;- 10000     # numero di repliche\n\nsim_switches &lt;- replicate(nsims, {\n  # 1) estrai un theta dal posterior\n  theta_sim &lt;- rbeta(1, a_post, b_post)\n  # 2) genera y^rep ~ Bernoulli(theta_sim)\n  y_sim     &lt;- rbinom(n, size = 1, prob = theta_sim)\n  # 3) conta gli switch\n  count_switches(y_sim)\n})\n\n# Istogramma\nhist(sim_switches,\n     breaks = 30,\n     col    = \"lightgrey\",\n     main   = \"Distribuzione Posterior Predictive\\ndel numero di switch\",\n     xlab   = \"Numero di switch\",\n     ylab   = \"Frequenza\")\nabline(v = Ty, col = \"darkgreen\", lty = 2, lwd = 2)\n\n\n\n\n\n\n\nBayesian p‐value.\nCalcoliamo la probabilità di ottenere un numero di switch ≤ di quello osservato:\n\np_value &lt;- mean(sim_switches &lt;= Ty)\ncat(\"Bayesian p-value:\", round(p_value, 4), \"\\n\")\n#&gt; Bayesian p-value: 0.0073\n\n\nUn valore molto basso (es. \\(&lt;0.05\\)) indica che \\(T(y)\\) è sorprendente rispetto alle predizioni del modello.\n\nQui: se \\(p\\approx 0.01\\), la bassa variabilità di switch suggerisce dipendenza fra le osservazioni.\n\nInterpretazione.\n\n\nUn modello non è “giusto” o “sbagliato”, ma deve descrivere bene il processo che genera i dati.\n\nIl nostro check mostra che il numero di switch osservato è molto minore di quanto ci aspetteremmo sotto l’ipotesi di indipendenza.\n\nCon tutta probabilità c’è autocorrelazione temporale (le presenze dipendono dall’ora del giorno).\n\nPer tenerne conto, si potrebbero usare modelli più avanzati (es. processi gaussiani).\n\nIn sintesi, il posterior predictive checking ci offre un modo flessibile per diagnosticare diverse violazioni del modello, scegliendo test‐quantities adatte (media, varianza, max, autocorrelazione, …). Come scrivono Gelman et al. (2013), “i p-valori posteriori … possono essere calcolati per varie test-quantities per valutare più modi in cui un modello può fallire”.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families.html#principali-distribuzioni-coniugate",
    "href": "chapters/bayesian_inference/05_conjugate_families.html#principali-distribuzioni-coniugate",
    "title": "44  Distribuzioni coniugate",
    "section": "\n44.4 Principali distribuzioni coniugate",
    "text": "44.4 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle più note coniugazioni tra modelli statistici e distribuzioni a priori:\n\nNel modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribuzione a priori è \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione a posteriori è \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nNel modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nNel modello Esponenziale \\(\\text{Exp}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nNel modello Uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribuzione a priori è \\(\\text{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione a posteriori è \\(\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/05_conjugate_families.html#riflessioni-conclusive",
    "title": "44  Distribuzioni coniugate",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo approfondito l’idea di famiglia coniugata, mostrando come, in certi casi, il teorema di Bayes mantenga invariata la forma della distribuzione a priori. L’esempio del modello Beta-Binomiale, già incontrato in precedenza, ci ha offerto l’occasione di vedere con chiarezza come i dati modifichino le nostre credenze in modo semplice e cumulativo: basta aggiornare i parametri della distribuzione, senza cambiare la sua struttura.\nQuesta proprietà, apparentemente tecnica, riveste una grande importanza concettuale. Le distribuzioni coniugate costituiscono il laboratorio ideale per comprendere a fondo la logica dell’inferenza bayesiana: permettono di seguire con trasparenza il passaggio da prior a posterior, di vedere come ogni nuova osservazione si traduca in un aggiornamento dei parametri e di cogliere in maniera intuitiva la natura dinamica del processo.\nNaturalmente, sappiamo che la coniugazione è un caso speciale. Nella maggior parte dei problemi reali, soprattutto quando i modelli diventano complessi e includono più parametri o strutture gerarchiche, non esiste una coppia prior–verosimiglianza coniugata che semplifichi i calcoli. È in questi casi che entrano in gioco metodi computazionali più generali, come il campionamento MCMC, che ci permettono di affrontare situazioni realistiche senza rinunciare alla coerenza dell’approccio bayesiano (Johnson et al., 2022).\nIn questo senso, le famiglie coniugate non rappresentano un punto di arrivo, ma un passaggio fondamentale: ci insegnano i principi dell’aggiornamento bayesiano in un contesto semplice, che prepara la strada verso strumenti più potenti e flessibili.\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nSi consideri lo studio “An excess of positive results: Comparing the standard psychology literature with registered reports” di Scheel et al. (2021). In questo lavoro, gli autori confrontano il tasso di risultati positivi \\(\\theta\\) ottenuti in studi psicologici pubblicati senza preregistrazione con quelli pubblicati con preregistrazione. Si utilizzi il tasso di successo riportato negli studi preregistrati per costruire una distribuzione a priori per il parametro \\(\\theta\\).\nSecondo i risultati degli studi preregistrati, gli autori riscontrano un tasso di successo del 43.66%, con un intervallo di confidenza al 95% [CI] = [31.91, 55.95]. Sulla base di questi dati, si costruisca una distribuzione beta come distribuzione a priori per \\(\\theta\\), seguendo il metodo illustrato da Johnson et al. (2022).\nSuccessivamente, utilizzando questa distribuzione beta come distribuzione a priori, si determini la distribuzione a posteriori utilizzando il metodo delle famiglie coniugate per due scenari distinti, basati su 152 studi osservati: (a) Un tasso di successo del 60% (b) Un tasso di successo del 96% (come riportato per gli studi non preregistrati da Scheel et al. (2021)).\nInfine, si commentino i risultati derivanti dall’analisi delle distribuzioni a posteriori ottenute per entrambi gli scenari.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\n\n# Funzione per trovare i parametri della distribuzione beta\nfind_beta_parameters &lt;- function(mean, lower, upper, conf_level = 0.95) {\n  # Funzione obiettivo da minimizzare\n  objective &lt;- function(alpha) {\n    beta &lt;- alpha * (1 - mean) / mean\n    predicted_ci &lt;- qbeta(c((1-conf_level)/2, 1-(1-conf_level)/2), alpha, beta)\n    error &lt;- (predicted_ci[1] - lower)^2 + (predicted_ci[2] - upper)^2\n    return(error)\n  }\n  \n  # Ottimizzazione per trovare alpha\n  result &lt;- optimize(objective, interval = c(0.1, 100))\n  alpha &lt;- result$minimum\n  beta &lt;- alpha * (1 - mean) / mean\n  \n  return(list(alpha = alpha, beta = beta))\n}\n\n# Parametri degli studi preregistrati\nmean_preregistered &lt;- 0.4366\nci_lower &lt;- 0.3191\nci_upper &lt;- 0.5595\n\n# Calcolo dei parametri della distribuzione beta a priori\nprior_params &lt;- find_beta_parameters(mean_preregistered, ci_lower, ci_upper)\nalpha_prior &lt;- prior_params$alpha\nbeta_prior &lt;- prior_params$beta\n\n# Dati osservati\nn &lt;- 152  # numero di studi\nsuccesses_60 &lt;- round(0.60 * n)  # scenario (a)\nsuccesses_96 &lt;- round(0.96 * n)  # scenario (b)\n\n# Calcolo delle distribuzioni a posteriori\nalpha_post_60 &lt;- alpha_prior + successes_60\nbeta_post_60 &lt;- beta_prior + (n - successes_60)\n\nalpha_post_96 &lt;- alpha_prior + successes_96\nbeta_post_96 &lt;- beta_prior + (n - successes_96)\n\n# Creazione del dataframe per il plotting\ntheta &lt;- seq(0, 1, length.out = 1000)\n\ndf &lt;- data.frame(\n  theta = rep(theta, 3),\n  density = c(\n    dbeta(theta, alpha_prior, beta_prior),\n    dbeta(theta, alpha_post_60, beta_post_60),\n    dbeta(theta, alpha_post_96, beta_post_96)\n  ),\n  distribution = rep(c(\"Priori\", \"Posteriori (60%)\", \"Posteriori (96%)\"), \n                    each = length(theta))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    x = expression(theta),\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n# Calcolo degli intervalli di credibilità al 95%\ncredible_intervals &lt;- data.frame(\n  Distribution = c(\"Priori\", \"Posteriori (60%)\", \"Posteriori (96%)\"),\n  Mean = c(\n    alpha_prior / (alpha_prior + beta_prior),\n    alpha_post_60 / (alpha_post_60 + beta_post_60),\n    alpha_post_96 / (alpha_post_96 + beta_post_96)\n  ),\n  Lower = c(\n    qbeta(0.025, alpha_prior, beta_prior),\n    qbeta(0.025, alpha_post_60, beta_post_60),\n    qbeta(0.025, alpha_post_96, beta_post_96)\n  ),\n  Upper = c(\n    qbeta(0.975, alpha_prior, beta_prior),\n    qbeta(0.975, alpha_post_60, beta_post_60),\n    qbeta(0.975, alpha_post_96, beta_post_96)\n  )\n)\n\n# Visualizzazione dei risultati\nprint(\"Parametri della distribuzione beta a priori:\")\nprint(paste(\"alpha =\", round(alpha_prior, 2)))\nprint(paste(\"beta =\", round(beta_prior, 2)))\n\nprint(\"\\nIntervalli di credibilità al 95%:\")\nprint(credible_intervals)\n\n# Visualizza il grafico\nprint(p)\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nTra i fattori che possono influenzare il rapporto tra i sessi alla nascita c’è la condizione materna di placenta previa, una condizione insolita della gravidanza in cui la placenta è impiantata in basso nell’utero, impedendo un normale parto vaginale del feto. Uno studio condotto in Germania ha esaminato il sesso dei neonati in casi di placenta previa e ha riscontrato che, su un totale di 980 nascite, 437 erano femmine.\nQuanta evidenza fornisce questo studio a supporto dell’ipotesi che la proporzione di nascite femminili nella popolazione di placenta previa sia inferiore a 0.485, che rappresenta la proporzione di nascite femminili nella popolazione generale? (Esercizio tratto da Gelman et al. (2013))\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Calcolo della proporzione osservata\np_hat &lt;- y/n\nprint(paste(\"Proporzione osservata di femmine:\", round(p_hat, 3)))\n\n# Test dell'ipotesi utilizzando il Bayes Factor\n# H0: p = 0.485 vs H1: p &lt; 0.485\n\n# Funzione per calcolare la verosimiglianza marginale sotto H1\nmarginal_likelihood_h1 &lt;- function(y, n, p_max = 0.485) {\n  # Integrazione numerica sulla distribuzione uniforme tra 0 e p_max\n  p_grid &lt;- seq(0, p_max, length.out = 1000)\n  likelihood &lt;- dbinom(y, n, p_grid)\n  prior &lt;- dunif(p_grid, 0, p_max)\n  mean(likelihood * prior) * p_max\n}\n\n# Verosimiglianza sotto H0\nlikelihood_h0 &lt;- dbinom(y, n, p0)\n\n# Verosimiglianza marginale sotto H1\nmarg_lik_h1 &lt;- marginal_likelihood_h1(y, n)\n\n# Calcolo del Bayes Factor\nbf10 &lt;- marg_lik_h1 / likelihood_h0\nprint(paste(\"Bayes Factor (H1 vs H0):\", round(bf10, 2)))\n\n# Visualizzazione delle distribuzioni a posteriori\np_grid &lt;- seq(0, 1, length.out = 1000)\nlikelihood &lt;- dbinom(y, n, p_grid)\nprior &lt;- dunif(p_grid, 0, 1)\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = p_grid,\n  Posterior = posterior / max(posterior)  # normalizzato per la visualizzazione\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = Posterior)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = p_hat, linetype = \"dashed\", color = \"blue\") +\n  labs(\n    title = \"Distribuzione a Posteriori della Proporzione di Nascite Femminili\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità a Posteriori (normalizzata)\"\n  ) +\n  annotate(\"text\", x = p0, y = 0.1, \n           label = \"Popolazione Generale\", \n           angle = 90, vjust = -0.5, color = \"red\") +\n  annotate(\"text\", x = p_hat, y = 0.1, \n           label = \"Proporzione Osservata\", \n           angle = 90, vjust = -0.5, color = \"blue\")\n\n# Calcolo dell'intervallo di credibilità al 95%\nsorted_p &lt;- sort(p_grid)\ncum_post &lt;- cumsum(posterior)\nlower &lt;- sorted_p[which(cum_post &gt; 0.025)[1]]\nupper &lt;- sorted_p[which(cum_post &gt; 0.975)[1]]\n\nprint(paste(\"Intervallo di credibilità al 95%: [\", \n            round(lower, 3), \",\", round(upper, 3), \"]\"))\n\n# Calcolo della probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- sum(posterior[p_grid &lt; p0])\nprint(paste(\"Probabilità a posteriori che p &lt; 0.485:\", \n            round(prob_less_than_p0, 3)))\n\n# Visualizza il grafico\nprint(p)\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nPer valutare la sensibilità della soluzione precedente alla scelta della distribuzione a priori, ripetere l’esercizio utilizzando come distribuzione a priori per la proporzione di nascite femminili una distribuzione Beta(48.5, 51.5). Questa distribuzione è centrata su 0.485 e concentra la maggior parte della sua massa nell’intervallo [0.385, 0.585]. Interpretare i risultati ottenuti.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Parametri della distribuzione beta a priori\nalpha_prior &lt;- 48.5\nbeta_prior &lt;- 51.5\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori Beta(48.5, 51.5)\", \"Posteriori\"), each = length(p_grid))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    subtitle = \"Proporzione di Nascite Femminili con Placenta Previa\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = p0, y = max(posterior_density)/2, \n           label = \"Popolazione Generale (0.485)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Calcolo statistiche rilevanti\n# Media a priori e posteriori\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\n# Intervalli di credibilità al 95%\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- pbeta(p0, alpha_post, beta_post)\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Dati osservati:\\n\")\ncat(sprintf(\"Numero totale di nascite: %d\\n\", n))\ncat(sprintf(\"Numero di femmine: %d\\n\", y))\ncat(sprintf(\"Proporzione osservata: %.3f\\n\\n\", y/n))\n\ncat(\"Analisi a priori:\\n\")\ncat(sprintf(\"Media a priori: %.3f\\n\", prior_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\\n\", \n            prior_ci[1], prior_ci[2]))\n\ncat(\"Analisi a posteriori:\\n\")\ncat(sprintf(\"Media a posteriori: %.3f\\n\", post_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\", \n            post_ci[1], post_ci[2]))\ncat(sprintf(\"Probabilità che p &lt; %.3f: %.3f\\n\", p0, prob_less_than_p0))\n\n# Visualizza il grafico\nprint(p)\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Parametri della distribuzione beta a priori\nalpha_prior &lt;- 48.5\nbeta_prior &lt;- 51.5\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori Beta(48.5, 51.5)\", \"Posteriori\"), each = length(p_grid))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    subtitle = \"Proporzione di Nascite Femminili con Placenta Previa\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = p0, y = max(posterior_density)/2, \n           label = \"Popolazione Generale (0.485)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Calcolo statistiche rilevanti\n# Media a priori e posteriori\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\n# Intervalli di credibilità al 95%\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- pbeta(p0, alpha_post, beta_post)\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Dati osservati:\\n\")\ncat(sprintf(\"Numero totale di nascite: %d\\n\", n))\ncat(sprintf(\"Numero di femmine: %d\\n\", y))\ncat(sprintf(\"Proporzione osservata: %.3f\\n\\n\", y/n))\n\ncat(\"Analisi a priori:\\n\")\ncat(sprintf(\"Media a priori: %.3f\\n\", prior_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\\n\", \n            prior_ci[1], prior_ci[2]))\n\ncat(\"Analisi a posteriori:\\n\")\ncat(sprintf(\"Media a posteriori: %.3f\\n\", post_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\", \n            post_ci[1], post_ci[2]))\ncat(sprintf(\"Probabilità che p &lt; %.3f: %.3f\\n\", p0, prob_less_than_p0))\n\n# Visualizza il grafico\nprint(p)\nI risultati mostrano che:\n\nLa proporzione osservata nel campione (0.446) è inferiore al valore di riferimento della popolazione generale (0.485)\nLa distribuzione a priori Beta(48.5, 51.5):\n\n\nHa media 0.485\nRiflette la nostra conoscenza iniziale sulla proporzione di nascite femminili\nFornisce un’incertezza ragionevole attorno al valore di riferimento\n\n\nLa distribuzione a posteriori:\n\n\nHa una media di circa 0.447\nL’intervallo di credibilità al 95% esclude il valore di riferimento 0.485\nIndica una probabilità elevata che la vera proporzione sia inferiore a 0.485\n\n\nQuesta analisi suggerisce che:\n\n\nEsiste un’associazione tra placenta previa e una minor proporzione di nascite femminili\nL’effetto è moderato ma statisticamente rilevante\nLa stima è abbastanza precisa grazie alla dimensione campionaria considerevole\n\n\n\n\n\n\n\n\n\n\nProblemi 4\n\n\n\n\n\nIn uno studio recente, Gori et al. (2024) hanno esaminato un campione di 202 adulti italiani e hanno riscontrato una prevalenza di mancini del 6.4%. Una meta-analisi di Papadatou-Pastou et al. (2020), condotta su un totale di 2,396,170 soggetti, riporta che la proporzione di mancini varia tra il 9.3% e il 18.1%, a seconda di come viene misurata la lateralità manuale. Inoltre, Papadatou-Pastou et al. (2020) mostrano che la prevalenza della lateralità manuale varia tra i paesi e nel tempo. Considerata questa incertezza, si determini la distribuzione a posteriori che combina i dati dello studio di Gori et al. (2024) con le informazioni pregresse fornite da Papadatou-Pastou et al. (2020). Le informazioni di Papadatou-Pastou et al. (2020) possono essere espresse in termini di una distribuzione Beta(8, 60).\n\n\n\n\n\n\n\n\n\nSoluzioni 4\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati dello studio di Gori et al. (2024)\nn &lt;- 202       # dimensione del campione\ny &lt;- round(0.064 * n)  # numero di mancini (6.4% del campione)\n\n# Parametri della distribuzione beta a priori (da Papadatou-Pastou et al., 2020)\nalpha_prior &lt;- 8\nbeta_prior &lt;- 60\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 0.3, length.out = 1000)  # limitato a 0.3 per migliore visualizzazione\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori (Papadatou-Pastou et al., 2020)\", \n                      \"Posteriori (con dati Gori et al., 2024)\"), \n                    each = length(p_grid))\n)\n\n# Calcolo statistiche rilevanti\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = 0.064, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della Prevalenza dei Mancini\",\n    subtitle = \"Confronto tra Distribuzione a Priori e a Posteriori\",\n    x = \"Proporzione di Mancini\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = 0.064, y = max(posterior_density)/2, \n           label = \"Valore osservato (6.4%)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Distribuzione a priori (Papadatou-Pastou et al., 2020):\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", prior_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\\n\", \n            prior_ci[1] * 100, prior_ci[2] * 100))\n\ncat(\"Dati osservati (Gori et al., 2024):\\n\")\ncat(sprintf(\"Campione: %d individui\\n\", n))\ncat(sprintf(\"Mancini osservati: %d (%.1f%%)\\n\\n\", y, y/n * 100))\n\ncat(\"Distribuzione a posteriori:\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", post_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\", \n            post_ci[1] * 100, post_ci[2] * 100))\n\n# Visualizza il grafico\nprint(p)\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati dello studio di Gori et al. (2024)\nn &lt;- 202       # dimensione del campione\ny &lt;- round(0.064 * n)  # numero di mancini (6.4% del campione)\n\n# Parametri della distribuzione beta a priori (da Papadatou-Pastou et al., 2020)\nalpha_prior &lt;- 8\nbeta_prior &lt;- 60\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 0.3, length.out = 1000)  # limitato a 0.3 per migliore visualizzazione\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori (Papadatou-Pastou et al., 2020)\", \n                      \"Posteriori (con dati Gori et al., 2024)\"), \n                    each = length(p_grid))\n)\n\n# Calcolo statistiche rilevanti\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = 0.064, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della Prevalenza dei Mancini\",\n    subtitle = \"Confronto tra Distribuzione a Priori e a Posteriori\",\n    x = \"Proporzione di Mancini\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = 0.064, y = max(posterior_density)/2, \n           label = \"Valore osservato (6.4%)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Distribuzione a priori (Papadatou-Pastou et al., 2020):\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", prior_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\\n\", \n            prior_ci[1] * 100, prior_ci[2] * 100))\n\ncat(\"Dati osservati (Gori et al., 2024):\\n\")\ncat(sprintf(\"Campione: %d individui\\n\", n))\ncat(sprintf(\"Mancini osservati: %d (%.1f%%)\\n\\n\", y, y/n * 100))\n\ncat(\"Distribuzione a posteriori:\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", post_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\", \n            post_ci[1] * 100, post_ci[2] * 100))\n\n# Visualizza il grafico\nprint(p)\nL’analisi bayesiana della prevalenza dei mancini combina le informazioni provenienti dalla meta-analisi di Papadatou-Pastou et al. (2020) con i dati più recenti di Gori et al. (2024). Di seguito sono riportati i principali risultati:\n\n\nDistribuzione a priori (basata su Papadatou-Pastou et al., 2020):\n\nModellata come una distribuzione Beta(8, 60).\n\nPresenta una media intorno all’11,8%.\n\nRiflette la variabilità osservata nella meta-analisi.\n\nL’intervallo di credibilità al 95% copre approssimativamente il range 9,3%-18,1%, come riportato nello studio.\n\n\n\nDati osservati (Gori et al., 2024):\n\n202 partecipanti italiani.\n\n13 mancini, corrispondenti al 6,4% del campione.\n\nQuesto valore è inferiore alla media stimata dalla meta-analisi globale.\n\n\n\nDistribuzione a posteriori:\n\nCombina le informazioni a priori con i nuovi dati osservati.\n\nLa media a posteriori si è spostata verso il basso rispetto alla distribuzione a priori.\n\nL’intervallo di credibilità si è ristretto, indicando una riduzione dell’incertezza.\n\nMaggiore peso è stato attribuito ai dati italiani rispetto alla meta-analisi globale.\n\n\n\nInterpretazione:\n\nLa stima finale suggerisce una prevalenza di mancini nella popolazione italiana inferiore alla media globale.\n\nQuesto risultato potrebbe riflettere specificità culturali o metodologiche dello studio italiano.\n\nL’incertezza nella stima finale è diminuita rispetto alla meta-analisi, ma rimane significativa.\n\nI risultati supportano l’ipotesi di una variabilità geografica nella prevalenza della mancinismo.\n\n\n\nLa distribuzione a posteriori fornisce una sintesi equilibrata tra le conoscenze globali precedenti e i dati specifici della popolazione italiana, suggerendo che potrebbero esistere peculiarità culturali o demografiche che influenzano la prevalenza del mancinismo in Italia.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] rmarkdown_2.29        nloptr_2.2.1          ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           jomo_2.7-6            xfun_0.53            \n#&gt; [25] glmnet_4.1-10         cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [28] pan_1.9               broom_1.0.9           parallel_4.5.1       \n#&gt; [31] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [34] rpart_4.1.24          boot_1.3-32           lubridate_1.9.4      \n#&gt; [37] estimability_1.5.1    iterators_1.0.14      knitr_1.50           \n#&gt; [40] zoo_1.8-14            pacman_0.5.1          nnet_7.3-20          \n#&gt; [43] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [46] tidyselect_1.2.1      abind_1.4-8           codetools_0.2-20     \n#&gt; [49] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [52] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [55] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [58] tensorA_0.36.2.1      checkmate_2.3.3       foreach_1.5.2        \n#&gt; [61] stats4_4.5.1          reformulas_0.4.1      distributional_0.5.0 \n#&gt; [64] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [67] scales_1.4.0          minqa_1.2.8           xtable_1.8-4         \n#&gt; [70] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [73] lme4_1.1-37           mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [76] rbibutils_2.3         QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [79] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [82] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [85] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [88] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [91] htmltools_0.5.8.1     lifecycle_1.0.4       mitml_0.4-5          \n#&gt; [94] MASS_7.3-65",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families.html#bibliografia",
    "href": "chapters/bayesian_inference/05_conjugate_families.html#bibliografia",
    "title": "44  Distribuzioni coniugate",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nGori, B., Grippo, A., Focardi, M., & Lolli, F. (2024). The Italian version of Edinburgh Handedness Inventory: Translation, transcultural adaptation, and validation in healthy subjects. Laterality, 29(2), 151–168.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNalborczyk, L. (2018, gennaio 23). Checking the Asumption of Independence in Binomial Trials Using Posterior Predictive Checking. https://lnalborczyk.github.io/blog/2018-01-23-ppc\n\n\nPapadatou-Pastou, M., Ntolka, E., Schmitz, J., Martin, M., Munafò, M. R., Ocklenburg, S., & Paracchini, S. (2020). Human handedness: A meta-analysis. Psychological bulletin, 146(6), 481–524.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_summary_posterior.html",
    "href": "chapters/bayesian_inference/06_summary_posterior.html",
    "title": "45  Sintesi a posteriori",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo imparato a costruire distribuzioni a posteriori combinando la nostra conoscenza preliminare (prior) con i dati osservati attraverso la verosimiglianza. Abbiamo visto come questo processo si realizzi in casi semplici, come la stima di una proporzione di successi con il modello Beta–Binomiale, e come possa essere generalizzato grazie al concetto di famiglie coniugate. Ora ci poniamo una domanda fondamentale: una volta che abbiamo ottenuto una distribuzione a posteriori, come possiamo riassumerla e comunicarla in modo chiaro ed efficace?\nIl posterior non è un singolo numero, ma un’intera distribuzione che rappresenta la nostra incertezza sul parametro. Nella pratica della ricerca psicologica, tuttavia, dobbiamo spesso sintetizzare queste informazioni per presentarle nei risultati di un articolo o per confrontarle con altre stime. Questo capitolo è dedicato proprio a questa esigenza: mostreremo come ricavare quantità riassuntive (media, mediana, moda) e come costruire intervalli credibili che esprimano in modo trasparente i valori più plausibili.\nL’obiettivo non è ridurre l’inferenza bayesiana alla ricerca di un punto o di un intervallo, ma imparare a comunicare l’incertezza in modo comprensibile, senza perdere la ricchezza informativa del posterior. Come vedremo, anche nei contesti più complessi, la capacità di sintetizzare correttamente le distribuzioni a posteriori è ciò che distingue un’analisi meramente tecnica da una presentazione scientifica chiara e convincente.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_summary_posterior.html#introduzione",
    "href": "chapters/bayesian_inference/06_summary_posterior.html#introduzione",
    "title": "45  Sintesi a posteriori",
    "section": "",
    "text": "Panoramica del capitolo\n\nDistribuzione a posteriori = conoscenza aggiornata.\nStime puntuali: MAP, media, mediana.\nIncertezza: varianza e deviazione standard.\nIntervalli di credibilità: simmetrici e HPD.\nVerifica di ipotesi: probabilità a posteriori.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Posterior Inference & Prediction del testo di Johnson et al. (2022).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_summary_posterior.html#riepilogo-numerico",
    "href": "chapters/bayesian_inference/06_summary_posterior.html#riepilogo-numerico",
    "title": "45  Sintesi a posteriori",
    "section": "\n45.1 Riepilogo numerico",
    "text": "45.1 Riepilogo numerico\nLa distribuzione a posteriori contiene in sé tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico \\(p(\\theta \\mid y)\\). Tuttavia, quando ci troviamo di fronte a vettori di parametri con più di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori: stima puntuale e intervallo di credibilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_summary_posterior.html#stima-puntuale",
    "href": "chapters/bayesian_inference/06_summary_posterior.html#stima-puntuale",
    "title": "45  Sintesi a posteriori",
    "section": "\n45.2 Stima puntuale",
    "text": "45.2 Stima puntuale\nNel contesto dell’inferenza bayesiana, stimare il valore più credibile di un parametro \\(\\theta\\) a partire dalla distribuzione a posteriori può avvenire attraverso tre statistiche principali: moda, mediana e media. La scelta tra queste dipende dalla forma della distribuzione a posteriori. Queste statistiche forniscono una stima puntuale della tendenza centrale della distribuzione, ossia il valore a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sia sui dati osservati sia sulle credenze a priori.\nModa (Massimo a Posteriori, MAP)\nLa moda della distribuzione a posteriori, nota come stima di massimo a posteriori (MAP), corrisponde al valore del parametro \\(\\theta\\) a cui è associata la massima densità di probabilità. Questo concetto rappresenta l’estensione bayesiana della classica stima di massima verosimiglianza (MLE), definita come:\n\\[\n\\hat{\\theta}_{\\text{ML}} = \\arg \\max_\\theta L(\\theta \\mid y),\n\\] dove \\(L(\\theta \\mid y)\\) è la funzione di verosimiglianza. Nell’approccio bayesiano, l’informazione a priori \\(p(\\theta)\\) viene incorporata attraverso il teorema di Bayes, portando alla definizione della stima MAP:\n\\[\n\\hat{\\theta}_{\\text{MAP}} = \\arg \\max_\\theta \\, L(\\theta \\mid y) \\, p(\\theta).\n\\] In altre parole, \\(\\hat{\\theta}_{\\text{MAP}}\\) massimizza la densità a posteriori non normalizzata, combinando in modo esplicito l’evidenza empirica con la conoscenza pregressa.\n\n45.2.0.1 Limitazioni della stima MAP\nNonostante l’interpretazione intuitiva, la stima MAP presenta alcune limitazioni di cui è importante essere consapevoli. In primo luogo, la sua determinazione può risultare computazionalmente impegnativa, specialmente quando la distribuzione a posteriori viene campionata mediante metodi MCMC: individuare con precisione il massimo in uno spazio di parametri ad alta dimensionalità o con forme complesse richiede tecniche specifiche e può essere instabile.\nIn secondo luogo, la bontà della stima MAP dipende fortemente dalla forma della distribuzione a posteriori. In presenza di asimmetrie marcate o di multimodalità, il massimo globale potrebbe non essere rappresentativo della regione di alta probabilità, soprattutto se associato a un picco stretto ma isolato, mentre la maggior parte della massa probabilistica si trova altrove.\nInfine, il MAP è intrinsecamente meno robusto di altre statistiche centrali, come la media o la mediana a posteriori, in quanto basato esclusivamente sul valore di massimo densità, ignorando la forma complessiva della distribuzione. Ciò lo rende sensibile a variazioni nella parametrizzazione del modello e poco informativo riguardo all’incertezza complessiva sul parametro.\nMedia a posteriori\nLa media a posteriori rappresenta il valore atteso del parametro \\(\\theta\\) rispetto alla sua distribuzione a posteriori. Formalmente, essa è definita come:\n\\[\n\\mathbb{E}[\\theta \\mid y] = \\int \\theta \\, p(\\theta \\mid y) \\, d\\theta.\n\\] Questa quantità costituisce una stima di \\(\\theta\\) che tiene conto dell’intera distribuzione a posteriori, integrando su tutti i possibili valori del parametro. Una proprietà notevole della media a posteriori è quella di essere lo stimatore che minimizza l’errore quadratico medio (MSE) nella previsione di \\(\\theta\\), il che ne giustifica l’ampio utilizzo in contesti di ottimizzazione statistica.\nTuttavia, in presenza di distribuzioni a posteriori marcatamente asimmetriche o con code pesanti, la media potrebbe non rappresentare adeguatamente la regione di massima densità di probabilità. In tali casi, valori estremi possono influenzare eccessivamente la stima, allontanando la media dalla zona in cui è concentrata la maggior parte della massa probabilistica. Per questo motivo, in situazioni di asimmetria pronunciata, altre statistiche come la mediana o la moda a posteriori possono offrire una rappresentazione più appropriata della tendenza centrale.\nMediana a posteriori\nLa mediana a posteriori è definita come il valore del parametro \\(\\theta\\) che divide la distribuzione a posteriori in due parti di uguale probabilità: il 50% della massa probabilistica si trova al di sotto di tale valore e il restante 50% al di sopra. Formalmente, essa soddisfa la condizione:\n\\[\nP(\\theta \\leq \\hat{\\theta}_{\\text{med}} \\mid y) = 0.5.\n\\]\nRispetto alla media e alla moda a posteriori, la mediana offre una misura di tendenza centrale particolarmente robusta, in quanto poco sensibile alla presenza di valori estremi o code distributive pesanti. Questa proprietà la rende preferibile in contesti in cui la distribuzione a posteriori presenta marcate asimmetrie o è multimodale, situazioni in cui la media può essere distortta da valori anomali e la moda può risultare instabile o non unica. Grazie alla sua stabilità, la mediana a posteriori fornisce una rappresentazione più affidabile della posizione centrale del parametro quando la forma della distribuzione è irregolare, garantendo una sintesi inferenziale solida anche in condizioni di elevata variabilità o non normalità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_summary_posterior.html#misurare-lincertezza-varianza-a-posteriori",
    "href": "chapters/bayesian_inference/06_summary_posterior.html#misurare-lincertezza-varianza-a-posteriori",
    "title": "45  Sintesi a posteriori",
    "section": "Misurare l’incertezza: varianza a posteriori",
    "text": "Misurare l’incertezza: varianza a posteriori\nOltre a individuare il valore più plausibile del parametro \\(\\theta\\), è fondamentale quantificare l’incertezza residua associata alla nostra stima. A questo scopo, la varianza a posteriori fornisce una misura della dispersione dei valori di \\(\\theta\\) attorno alla sua media, condizionatamente ai dati osservati \\(y\\). Formalmente, essa è definita come:\n\\[\n\\mathbb{V}(\\theta \\mid y) = \\mathbb{E}\\left[(\\theta - \\mathbb{E}[\\theta \\mid y])^2 \\mid y \\right] = \\int (\\theta - \\mathbb{E}[\\theta \\mid y])^2 \\, p(\\theta \\mid y) \\, d\\theta.\n\\]\nUn modo equivalente per calcolarla è attraverso l’identità:\n\\[\n\\mathbb{V}(\\theta \\mid y) = \\mathbb{E}[\\theta^2 \\mid y] - \\left(\\mathbb{E}[\\theta \\mid y]\\right)^2.\n\\]\nPer interpretare più facilmente l’incertezza nella stessa unità di misura del parametro \\(\\theta\\), è utile considerare la deviazione standard a posteriori, data semplicemente dalla radice quadrata della varianza.\nIn conclusione, mentre la moda (MAP), la media e la mediana a posteriori forniscono diverse misure di tendenza centrale per la stima puntuale di \\(\\theta\\), la varianza (e la deviazione standard) a posteriori ne quantificano l’affidabilità. La scelta tra le diverse statistiche dipende dalla forma della distribuzione a posteriori e dagli obiettivi dell’analisi. Nel loro insieme, questi indicatori consentono di comunicare in modo sintetico non solo la migliore stima del parametro, ma anche il grado di confidenza ad essa associato, elemento cruciale in qualsiasi processo inferenziale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_summary_posterior.html#intervallo-di-credibilità",
    "href": "chapters/bayesian_inference/06_summary_posterior.html#intervallo-di-credibilità",
    "title": "45  Sintesi a posteriori",
    "section": "\n45.3 Intervallo di credibilità",
    "text": "45.3 Intervallo di credibilità\nNell’inferenza bayesiana, l’intervallo di credibilità è uno strumento utilizzato per definire un intervallo che contiene una determinata percentuale della massa della distribuzione a posteriori del parametro \\(\\theta\\). Questo intervallo riflette l’incertezza associata alla stima del parametro: un intervallo più ampio suggerisce una maggiore incertezza. Lo scopo principale dell’intervallo di credibilità è fornire una misura quantitativa dell’incertezza riguardante \\(\\theta\\).\nA differenza degli intervalli di confidenza frequentisti, non esiste un unico intervallo di credibilità per un dato livello di confidenza \\((1 - \\alpha) \\cdot 100\\%\\). In effetti, è possibile costruire un numero infinito di tali intervalli. Per questo motivo, è necessario stabilire criteri aggiuntivi per selezionare l’intervallo di credibilità più appropriato. Tra le opzioni più comuni ci sono l’intervallo di credibilità simmetrico e l’intervallo di massima densità posteriore (HPD).\nIntervallo di credibilità simmetrico\nQuesto tipo di intervallo è centrato rispetto al punto di stima puntuale. Se \\(\\hat{\\theta}\\) rappresenta la stima del parametro, l’intervallo simmetrico avrà la forma \\((\\hat{\\theta} - a, \\hat{\\theta} + a)\\), dove \\(a\\) è un valore positivo scelto in modo tale che la massa totale inclusa sia pari a \\((1 - \\alpha)\\). Più formalmente, un intervallo di credibilità simmetrico al livello \\(\\alpha\\) può essere espresso come:\n\\[\nI_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}],\n\\] dove \\(q_z\\) rappresenta il quantile \\(z\\) della distribuzione a posteriori. Ad esempio, un intervallo di credibilità simmetrico al 94% sarà:\n\\[\nI_{0.06} = [q_{0.03}, q_{0.97}],\n\\] dove il 3% della massa a posteriori si trova in ciascuna delle due code della distribuzione.\nIntervallo di credibilità più stretto (intervallo di massima densità posteriore, HPD)\nL’intervallo di massima densità posteriore (HPD) è l’intervallo più stretto possibile che contiene il \\((1 - \\alpha) \\cdot 100\\%\\) della massa a posteriori. A differenza dell’intervallo simmetrico, l’HPD include tutti i valori di \\(\\theta\\) che hanno la maggiore densità a posteriori. Per costruirlo, si disegna una linea orizzontale sulla distribuzione a posteriori e si regola l’altezza della linea in modo che l’area sotto la curva corrisponda a \\((1 - \\alpha)\\). L’HPD risulta essere il più stretto tra tutti gli intervalli possibili per lo stesso livello di confidenza. Nel caso di una distribuzione a posteriori unimodale e simmetrica, l’HPD coincide con l’intervallo di credibilità simmetrico.\n\n45.3.1 Interpretazione\nIl calcolo degli intervalli di credibilità—in particolare dell’intervallo di massima densità posteriore (HPD)—richiede quasi sempre l’utilizzo di software statistici specializzati. Questo perché, nei modelli bayesiani con distribuzioni posteriori articolate o che richiedono simulazioni numeriche (ad esempio tramite Markov Chain Monte Carlo), ricavare a mano i confini dell’intervallo può risultare molto laborioso.\n\n45.3.1.1 Incertezza nel paradigma frequentista\n\n\nParametro fisso: nel contesto frequentista, il parametro di interesse (ad esempio la media di popolazione \\(\\mu\\)) è un valore costante ma sconosciuto.\n\n\nRipetizione ipotetica: immaginiamo di ripetere all’infinito il prelievo di campioni dalla popolazione. Per ciascun campione otteniamo una media \\(\\bar{x}\\) e costruendo un intervallo di confidenza al \\(100(1-\\alpha)\\%\\) avremo che, nel lungo periodo, il \\(100(1-\\alpha)\\%\\) di questi intervalli conterrà il vero \\(\\mu\\).\n\n\nInterpretazione del singolo intervallo: per un singolo intervallo calcolato, la probabilità che contenga effettivamente \\(\\mu\\) è formalmente 0 o 1, perché \\(\\mu\\) non è soggetto a variabilità stocastica—siamo semplicemente ignari del suo valore reale.\n\n45.3.1.2 Incertezza nel paradigma bayesiano\n\n\nParametro come variabile aleatoria: qui \\(\\mu\\) non è più un valore fisso, ma possiede una distribuzione di probabilità che riflette sia l’informazione a priori sia quella fornita dai dati osservati.\n\n\nCampionamento dalla distribuzione a posteriori: grazie a tecniche di simulazione (ad es. MCMC), otteniamo un insieme di possibili valori di \\(\\mu\\) che segue la distribuzione posteriore.\n\n\nCostruzione diretta dell’intervallo: scegliendo i quantili al \\(2.5\\%\\) e al \\(97.5\\%\\) di questa distribuzione, otteniamo un intervallo di credibilità al 95%. In termini intuitivi, possiamo affermare che «c’è una probabilità del 95% che \\(\\mu\\) cada all’interno di questo intervallo, dati i dati e le ipotesi a priori».\n\n45.3.1.3 Confronto e considerazioni\n\n\nFrequentista: l’intervallo di confidenza è un costrutto legato alla frequenza di lungo periodo di un procedimento ipotetico di campionamento.\n\n\nBayesiano: l’intervallo di credibilità fornisce una misura puntuale dell’incertezza sul parametro, direttamente comprensibile come probabilità condizionata sui dati osservati.\n\n\nIntuizione: per molti, l’interpretazione bayesiana risulta più aderente al senso comune, perché traduce immediatamente il grado di fiducia che possiamo riporre nei valori ipotizzati per il parametro.\n\nIn sintesi, mentre la teoria frequentista quantifica l’affidabilità del metodo di stima nel lungo periodo, l’approccio bayesiano esprime senza ambiguità la probabilità attuale che il parametro si trovi in un certo intervallo, alla luce delle evidenze e delle conoscenze pregresse.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/bayesian_inference/06_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "45  Sintesi a posteriori",
    "section": "\n45.4 Verifica di ipotesi bayesiana",
    "text": "45.4 Verifica di ipotesi bayesiana\nL’inferenza bayesiana può essere applicata anche nel contesto della verifica di ipotesi, in un approccio noto come verifica di ipotesi bayesiana. In questo tipo di inferenza, l’obiettivo è valutare la plausibilità che un parametro \\(\\theta\\) assuma valori all’interno di un determinato intervallo. Ad esempio, possiamo voler sapere quanto è probabile che \\(\\theta\\) sia maggiore di 0.5 o che rientri in un intervallo specifico, come [0.5, 1.0].\nIn questo approccio, si calcola la probabilità a posteriori che \\(\\theta\\) si trovi all’interno dell’intervallo di interesse. Questa probabilità viene ottenuta integrando la distribuzione a posteriori su tale intervallo. Quindi, invece di rifiutare o accettare un’ipotesi come nel test di ipotesi frequentista, la verifica di ipotesi bayesiana fornisce una misura diretta della probabilità che un parametro rientri in un intervallo specifico, dato l’evidenza osservata e le informazioni a priori.\nIn altre parole, questo approccio consente di quantificare la nostra incertezza rispetto all’affermazione che \\(\\theta\\) rientri in un certo intervallo, fornendo una probabilità che rappresenta direttamente la plausibilità di quell’ipotesi.\n\nEsempio 45.1 Per illustrare l’approccio bayesiano, consideriamo i dati relativi ai punteggi del BDI-II (Beck Depression Inventory - Second Edition) di 30 soggetti clinici, come riportato nello studio condotto da Zetsche et al. (2019). Il BDI-II è uno strumento per valutare la gravità dei sintomi depressivi.\nI punteggi del BDI-II per i 30 soggetti sono:\n\n# Dati del BDI-II\nbdi &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\nbdi\n#&gt;  [1] 26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35 33\n#&gt; [26] 28 27 34 27 22\n\nUn punteggio BDI-II \\(\\geq 30\\) indica un livello grave di depressione. Nel nostro campione, 17 pazienti su 30 manifestano un livello grave:\n\n# Conteggio di depressione grave\nsum(bdi &gt;= 30)\n#&gt; [1] 17\n\nStima della distribuzione a posteriori.\nSupponiamo di voler stimare la probabilità \\(\\theta\\) di depressione grave nei pazienti clinici utilizzando una distribuzione a priori \\(Beta(8, 2)\\). I dati possono essere visti come una sequenza di prove Bernoulliane indipendenti, dove la presenza di depressione grave è un “successo”. La verosimiglianza è quindi binomiale con parametri \\(n = 30\\) e \\(y = 17\\).\nCon una distribuzione a priori \\(Beta(8, 2)\\), la distribuzione a posteriori di \\(\\theta\\) sarà:\n\\[\n\\text{Beta}(\\alpha = 8 + 17, \\beta = 2 + 30 - 17) = \\text{Beta}(25, 15).\n\\] Tracciamo la distribuzione a posteriori.\n\n# Parametri della distribuzione Beta\nalpha &lt;- 25\nbeta &lt;- 15\n\n# Calcolo della densità per valori di theta\ntheta &lt;- seq(0, 1, length.out = 200)\nposterior_density &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione a posteriori\nggplot(data = data.frame(theta, posterior_density), aes(x = theta, y = posterior_density)) +\n  geom_line() +\n  labs(\n    title = \"Distribuzione a Posteriori Beta(25, 15)\",\n    x = expression(theta),\n    y = \"Densità di probabilità\"\n  ) \n\n\n\n\n\n\n\nStime puntuali.\n\n\nMedia a posteriori. La media della distribuzione a posteriori è calcolata come:\n\n\\[\n\\mathbb{E}(\\theta | y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 15} = 0.625.\n\\] In R:\n\n# Calcolo della media a posteriori\nposterior_mean &lt;- alpha / (alpha + beta)\nposterior_mean\n#&gt; [1] 0.625\n\n\n\nModa a posteriori (MAP). La moda della distribuzione a posteriori è:\n\n\\[\nMo(\\theta | y = 17) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2} = \\frac{25 - 1}{25 + 15 - 2} = 0.6316.\n\\] In R:\n\n# Calcolo della moda a posteriori\nposterior_mode &lt;- (alpha - 1) / (alpha + beta - 2)\nposterior_mode\n#&gt; [1] 0.632\n\n\n\nMediana a posteriori. La mediana si ottiene utilizzando la funzione di distribuzione cumulativa inversa:\n\n\n# Calcolo della mediana a posteriori\nposterior_median &lt;- qbeta(0.5, alpha, beta)\nposterior_median\n#&gt; [1] 0.627\n\nIntervallo di credibilità.\n\n\nIntervallo di credibilità simmetrico. L’intervallo di credibilità simmetrico al 94% è dato dai percentili 3% e 97%:\n\n\n# Intervallo di credibilità simmetrico al 94%\ncred_interval &lt;- qbeta(c(0.03, 0.97), alpha, beta)\ncred_interval\n#&gt; [1] 0.478 0.761\n\nPossiamo interpretare questo intervallo come segue: c’è una certezza soggettiva del 94% che \\(\\theta\\) sia compreso tra 0.478 e 0.761.\nVerifica di ipotesi bayesiana. Infine, calcoliamo la probabilità che \\(\\theta &gt; 0.5\\):\n\\[\nP(\\theta &gt; 0.5 | y = 17) = \\int_{0.5}^1 f(\\theta | y = 17) d\\theta.\n\\] In R:\n\n# Probabilità P(theta &gt; 0.5)\nprob_theta_greater_0_5 &lt;- pbeta(0.5, alpha, beta, lower.tail = FALSE)\nprob_theta_greater_0_5\n#&gt; [1] 0.946\n\nIn conclusione, utilizzando un approccio bayesiano, abbiamo stimato la distribuzione a posteriori di \\(\\theta\\), ottenuto stime puntuali e costruito intervalli di credibilità. Abbiamo inoltre calcolato la probabilità che \\(\\theta\\) superi una soglia specifica, mostrando la flessibilità e l’interpretabilità delle analisi bayesiane.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-in-contesti-multivariati",
    "href": "chapters/bayesian_inference/06_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-in-contesti-multivariati",
    "title": "45  Sintesi a posteriori",
    "section": "\n45.5 Sintesi della distribuzione a posteriori in contesti multivariati",
    "text": "45.5 Sintesi della distribuzione a posteriori in contesti multivariati\nL’estensione dell’analisi bayesiana a modelli con più parametri introduce complessità legate alle interdipendenze tra i parametri stessi. Tali relazioni, se non adeguatamente considerate, possono condurre a sintesi incomplete o fuorvianti della distribuzione a posteriori, con possibili errori interpretativi.\n\n45.5.1 La sfida delle correlazioni tra parametri\nUno degli aspetti critici riguarda la presenza di correlazioni tra i parametri. Le distribuzioni marginali a posteriori — spesso utilizzate nei riassunti statistici — possono risultare ingannevoli se esaminate isolatamente. Parametri fortemente correlati possono dar luogo a marginali apparentemente piatte o poco informative, benché la loro struttura congiunta restringa significativamente lo spazio delle combinazioni plausibili. Ciò implica che, nonostante l’incertezza marginale possa sembrare elevata, l’incertezza congiunta su specifiche relazioni parametriche può essere molto ridotta.\nUn’ulteriore complicazione sorge quando le relazioni tra parametri sono non lineari. In tali casi, il massimo della distribuzione congiunta può non coincidere con i massimi delle distribuzioni marginali. Ad esempio, in presenza di strutture a “banana” o altre forme complesse, gli usuali indicatori di tendenza centrale (come la moda o la media) calcolati sui singoli parametri possono non riflettere la regione di massima densità di probabilità nello spazio multivariato.\n\n45.5.2 Approcci per una sintesi efficace\nPer una rappresentazione fedele dell’incertezza in contesti multivariati, è essenziale adottare una prospettiva che vada oltre l’analisi delle marginali:\n\nVisualizzazione delle relazioni congiunte: Grafici di dispersione a coppie (pair plots) o contour plot bidimensionali consentono di esplorare visivamente le dipendenze tra parametri, rivelando strutture non catturate dalle marginali.\nUtilizzo di distribuzioni predittive: Il confronto tra distribuzioni predittive a priori e a posteriori fornisce una visione complessiva dell’incertezza ridotta dall’evidenza dei dati, tenendo conto di tutte le interazioni parametriche.\nMisure di dipendenza avanzate: In casi di relazioni non lineari, misure come la correlazione di Spearman o l’informazione mutua possono integrare la correlazione lineare, offrendo una descrizione più completa delle dipendenze.\nAnalisi di sensibilità: Valutare come variano le inferenze al variare di gruppi di parametri aiuta a identificare le relazioni più influenti e a comprendere la stabilità delle conclusioni.\n\nIn conclusione, una sintesi appropriata della distribuzione a posteriori in presenza di più parametri richiede un esame congiunto delle relazioni tra di essi. La sola inspezione delle distribuzioni marginali rischia di occultare importanti fonti di informazione circa la struttura parametrica, con possibili conseguenze sulle inferenze tratte. Un approccio integrato — che unisca visualizzazione, misure di dipendenza e analisi di sensibilità — è fondamentale per una comprensione robusta dei risultati bayesiani in contesti multivariati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_summary_posterior.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/06_summary_posterior.html#riflessioni-conclusive",
    "title": "45  Sintesi a posteriori",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto che il cuore dell’approccio bayesiano non è soltanto ottenere una distribuzione a posteriori, ma anche imparare a descriverla in modo utile. Abbiamo distinto tra diversi modi di riassumere un posterior (media, mediana, moda) e tra diverse forme di intervallo credibile, chiarendo come ciascuna offra una prospettiva diversa sull’incertezza.\nQueste sintesi non sostituiscono la distribuzione completa, ma la rendono comunicabile. L’intervallo credibile, in particolare, ci permette di dire con chiarezza quali valori del parametro hanno una certa probabilità a posteriori di essere veri, dato il modello e i dati osservati. Questo rappresenta una differenza cruciale rispetto all’approccio frequentista, in cui l’interpretazione degli intervalli di confidenza rimane indiretta e spesso fonte di equivoci.\nDal punto di vista della ricerca psicologica, la capacità di sintetizzare il posterior è indispensabile. Molti risultati sperimentali si basano sulla stima di proporzioni, medie o differenze tra gruppi, e il modo in cui presentiamo l’incertezza può fare la differenza tra una conclusione chiara e una affermazione ambigua. Una sintesi ben costruita non solo comunica meglio, ma rafforza la solidità della conoscenza accumulata, perché rende trasparenti i margini di dubbio.\nQuesto capitolo chiude così un primo ciclo del nostro percorso: abbiamo imparato a costruire distribuzioni a posteriori e a sintetizzarle. Nei prossimi capitoli vedremo come andare oltre i parametri e usare il posterior per fare previsioni sui dati futuri e per confrontare modelli alternativi. È qui che il pensiero bayesiano mostrerà tutta la sua forza: non solo descrivere ciò che sappiamo, ma anche guidare ciò che possiamo aspettarci.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?\n\nSpiega le differenze tra moda (MAP), media a posteriori e mediana.\nIn quali contesti è preferibile utilizzare una di queste statistiche rispetto alle altre?\n\n2. Qual è la differenza tra un intervallo di credibilità bayesiano e un intervallo di confidenza frequentista?\n\nSpiega le differenze concettuali tra i due approcci.\nQuale dei due è più intuitivo in termini di incertezza sui parametri?\n\n3. Cos’è un intervallo di massima densità posteriore (HPD) e in cosa si differenzia dall’intervallo di credibilità simmetrico?\n\nSpiega il concetto di HPD e perché è più informativo in alcuni casi.\nIn quali situazioni l’HPD è preferibile rispetto all’intervallo di credibilità simmetrico?\n\n4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?\n\nPerché il MAP può essere meno affidabile rispetto ad altre statistiche?\nQuali problemi si possono incontrare nei modelli bayesiani complessi?\n\n5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di più parametri incogniti?\n\nQuali sono le principali difficoltà nell’interpretare la distribuzione congiunta di più parametri?\nCome si possono visualizzare e sintetizzare distribuzioni posteriori multivariate?\n\nDomande applicative in R\nPer queste domande, usa il dataset basato sulla Satisfaction with Life Scale (SWLS), supponendo che i dati seguano una distribuzione normale.\n1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa. - Usa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n2. Costruisci un intervallo di credibilità simmetrico al 94% per la media SWLS.\n\nUsa la distribuzione normale a posteriori per calcolare l’intervallo.\n\n3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densità.\n\nGenera un campione dalla distribuzione a posteriori e rappresentalo con ggplot2.\n\n4. Confronta l’intervallo di credibilità simmetrico con l’intervallo di massima densità posteriore (HPD).\n\nUsa la funzione hdi() del pacchetto bayestestR per calcolare l’HPD.\n\n5. Calcola la probabilità a posteriori che la media SWLS sia minore di 23.\n\nUsa la distribuzione a posteriori per calcolare questa probabilità.\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?\nLe tre principali statistiche usate per ottenere una stima puntuale del parametro \\(\\theta\\) nella distribuzione a posteriori sono:\n\n\nModa (Massimo a Posteriori, MAP)\n\nÈ il valore di \\(\\theta\\) che massimizza la distribuzione a posteriori \\(p(\\theta \\mid y)\\).\n\nSe la distribuzione è unimodale e simmetrica, il MAP coincide con la media a posteriori.\n\nIl MAP è spesso simile alla stima di massima verosimiglianza (MLE) quando il prior è uniforme.\n\n\n\nMedia a Posteriori\n\nÈ il valore atteso della distribuzione a posteriori:\\[\nE(\\theta \\mid y) = \\int \\theta \\, p(\\theta \\mid y) \\, d\\theta\n\\]\n\nÈ la stima più utile quando si vuole minimizzare l’errore quadratico medio (MSE).\n\nRisente dell’eventuale asimmetria della distribuzione, spostandosi verso le code.\n\n\n\nMediana a Posteriori\n\nÈ il valore che divide la distribuzione a posteriori in due parti uguali:\\[\nP(\\theta \\leq \\theta_{\\text{mediana}} \\mid y) = 0.5\n\\]\n\nÈ più robusta agli outlier rispetto alla media ed è utile quando la distribuzione è fortemente asimmetrica.\n\n\n\n💡 Quando usarle? - Se la distribuzione è simmetrica, tutte e tre le statistiche coincidono. - Se la distribuzione è asimmetrica, la mediana è più robusta, la media può essere influenzata dalle code e il MAP è utile se si vuole un valore più probabile.\n2. Qual è la differenza tra un intervallo di credibilità bayesiano e un intervallo di confidenza frequentista?\n\n\n\n\n\n\n\nCaratteristica\nIntervallo di Credibilità (Bayesiano)\nIntervallo di Confidenza (Frequentista)\n\n\n\nSignificato\nEsprime la probabilità che il parametro sia nell’intervallo, dati i dati osservati.\nÈ una proprietà di un metodo di campionamento: se si ripetesse l’esperimento infinite volte, il \\((1 - \\alpha)100\\%\\) degli intervalli conterrebbe il vero valore del parametro.\n\n\nApproccio\nAssume che il parametro sia una variabile casuale con una distribuzione di probabilità.\nAssume che il parametro sia fisso e sconosciuto, mentre i dati sono casuali.\n\n\nInterpretazione\n“C’è il 95% di probabilità che il parametro sia tra questi valori.”\n“Se ripetessimo l’esperimento molte volte, il 95% degli intervalli conterrebbe il vero parametro.”\n\n\n\n💡 Differenza fondamentale:\n\nL’intervallo di credibilità è probabilistico e più intuitivo: si può direttamente dire che il parametro ha il 95% di probabilità di trovarsi nell’intervallo.\n\nL’intervallo di confidenza è basato sulla ripetizione ipotetica dell’esperimento e non può essere interpretato in termini probabilistici sul singolo intervallo.\n\n3. Cos’è un intervallo di massima densità posteriore (HPD) e in cosa si differenzia dall’intervallo di credibilità simmetrico?\nL’intervallo di massima densità posteriore (HPD) è l’intervallo più stretto che contiene una percentuale fissata (es. 94%) della distribuzione a posteriori. Si distingue dall’intervallo di credibilità simmetrico perché:\n\n\n\n\n\n\n\nCaratteristica\nIntervallo HPD\nIntervallo di Credibilità Simmetrico\n\n\n\nDefinizione\nContiene il \\((1 - \\alpha)100\\%\\) della probabilità a posteriori, minimizzando la lunghezza dell’intervallo.\nÈ centrato attorno alla mediana e copre una frazione fissa della distribuzione.\n\n\nForma\nPuò essere asimmetrico e discontinuo se la distribuzione è multimodale.\nÈ sempre simmetrico.\n\n\nVantaggio\nÈ più informativo se la distribuzione è asimmetrica o multimodale.\nÈ più facile da calcolare, specialmente per distribuzioni unimodali.\n\n\n\n💡 Quando usarli?\n\nSe la distribuzione è simmetrica, entrambi gli intervalli danno risultati simili.\n\nSe la distribuzione è asimmetrica o multimodale, l’HPD è più informativo.\n\n4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?\nSebbene il MAP sia un concetto intuitivo (il valore più probabile della distribuzione a posteriori), presenta alcune limitazioni:\n\n\nDifficoltà computazionale con MCMC\n\nCon metodi di campionamento come Markov Chain Monte Carlo (MCMC), trovare il massimo della distribuzione a posteriori è difficile perché la funzione viene stimata in modo discreto.\nSpesso si preferisce stimare media o mediana, più facili da calcolare con MCMC.\n\n\n\nSensibilità ai dati e al prior\n\nIl MAP dipende fortemente dal prior scelto.\nSe il prior è informativo, il MAP può spostarsi troppo rispetto ai dati.\n\n\n\nProblemi con distribuzioni multimodali\n\nSe la distribuzione a posteriori ha più di un massimo (moda), il MAP potrebbe non essere una buona rappresentazione della distribuzione.\n\n\n\n💡 Quando evitarlo?\n- Se la distribuzione a posteriori è asimmetrica o multimodale. - Se si usa un metodo MCMC, dove la media o la mediana sono più semplici da stimare.\n5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di più parametri incogniti?\nQuando l’inferenza bayesiana coinvolge più parametri (es. \\(\\mu\\) e \\(\\sigma\\)), l’analisi diventa più complessa per diversi motivi:\n\n\nInterazioni tra parametri\n\nI parametri spesso non sono indipendenti: la distribuzione a posteriori congiunta può mostrare correlazioni che non emergono dalle distribuzioni marginali.\n\n\n\nDifficoltà di visualizzazione\n\nPer un parametro si usa un istogramma o una funzione di densità.\nPer due parametri si usa un contour plot o un grafico 3D.\nCon più di due parametri, si ricorre a pair plots o matrici di correlazione.\n\n\n\nStimare margine e congiunta\n\nLa distribuzione marginale di un parametro si ottiene integrando la distribuzione congiunta rispetto agli altri parametri: \\[\np(\\theta_1) = \\int p(\\theta_1, \\theta_2) d\\theta_2\n\\]\n\nSe i parametri sono fortemente correlati, le marginali possono nascondere informazioni importanti.\n\n\n\nRischio di correlazioni non lineari\n\nLe correlazioni non lineari tra i parametri possono portare a distribuzioni con forme complesse (es. a banana), rendendo difficile la sintesi con MAP o media.\n\n\n\n💡 Strategie per affrontare il problema:\n- Visualizzare le correlazioni tra i parametri con scatter plot o heatmap.\n- Usare tecniche di riduzione della dimensionalità come PCA (Analisi delle Componenti Principali).\n- Utilizzare il MCMC per campionare direttamente dalla distribuzione congiunta.\nEsercizio in R con i dati SWLS\nNell’esercizio, usa i dati della SWLS che sono stati raccolti. Qui useremo i dati seguenti:\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa.\n\nUsa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n\nlibrary(tibble)\n\n# Dati\nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\nsigma &lt;- 1  # Deviazione standard nota\n\n# Prior diffuso\nmu_prior &lt;- 4.5    \nsigma_prior &lt;- 10  \n\n# Media a posteriori\nmu_post &lt;- (sigma_prior^2 * mean_x + sigma^2 * n * mu_prior) / (sigma_prior^2 + sigma^2 * n)\n\n# Deviazione standard a posteriori\nsigma_post &lt;- sqrt((sigma_prior^2 * sigma^2) / (sigma_prior^2 + sigma^2 * n))\n\n# Moda (MAP)\nposterior_mode &lt;- mu_post  # Per una distribuzione normale, MAP coincide con la media\n\n# Mediana (simile alla media in una distribuzione normale)\nposterior_median &lt;- mu_post\n\ntibble(\"Media a Posteriori\" = mu_post,\n       \"Moda (MAP)\" = posterior_mode,\n       \"Mediana\" = posterior_median)\n2. Costruisci un intervallo di credibilità simmetrico al 94% per la media SWLS.\n\nUsa la distribuzione normale a posteriori per calcolare l’intervallo.\n\ncred_interval &lt;- qnorm(c(0.03, 0.97), mean = mu_post, sd = sigma_post)\ncred_interval\n3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densità.\n\nGenera un campione dalla distribuzione a posteriori e rappresentalo con ggplot2.\n\nlibrary(ggplot2)\n\n# Campionamento dalla distribuzione a posteriori\nset.seed(123)\nsamples &lt;- rnorm(1000, mean = mu_post, sd = sigma_post)\n\n# Creazione del dataframe\nsamples_df &lt;- tibble(media_campionata = samples)\n\n# Grafico della distribuzione a posteriori\nggplot(samples_df, aes(x = media_campionata)) +\n  geom_density(fill = \"blue\", alpha = 0.5) +\n  labs(title = \"Distribuzione a Posteriori della Media SWLS\",\n       x = \"Media\", y = \"Densità\")\n4. Confronta l’intervallo di credibilità simmetrico con l’intervallo di massima densità posteriore (HPD).\n\nUsa la funzione hdi() del pacchetto bayestestR per calcolare l’HPD.\n\nlibrary(bayestestR)\n\n# Calcolo intervallo HPD al 94%\nhpd_interval &lt;- hdi(samples, ci = 0.94)\nhpd_interval\n5. Calcola la probabilità a posteriori che la media SWLS sia minore di 23 – per fare un esempio, qui caloleremo per i dati simulati la probabilità a posteriori per la media SWLS maggiore di 4.7.\n\nUsa la distribuzione a posteriori per calcolare questa probabilità.\n\nprob_greater_4_7 &lt;- 1 - pnorm(4.7, mean = mu_post, sd = sigma_post)\nprob_greater_4_7\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] rmarkdown_2.29        nloptr_2.2.1          ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           jomo_2.7-6            xfun_0.53            \n#&gt; [25] glmnet_4.1-10         cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [28] pan_1.9               broom_1.0.9           parallel_4.5.1       \n#&gt; [31] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [34] rpart_4.1.24          boot_1.3-32           lubridate_1.9.4      \n#&gt; [37] estimability_1.5.1    iterators_1.0.14      knitr_1.50           \n#&gt; [40] zoo_1.8-14            pacman_0.5.1          nnet_7.3-20          \n#&gt; [43] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [46] tidyselect_1.2.1      abind_1.4-8           codetools_0.2-20     \n#&gt; [49] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [52] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [55] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [58] tensorA_0.36.2.1      checkmate_2.3.3       foreach_1.5.2        \n#&gt; [61] stats4_4.5.1          reformulas_0.4.1      distributional_0.5.0 \n#&gt; [64] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [67] scales_1.4.0          minqa_1.2.8           xtable_1.8-4         \n#&gt; [70] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [73] lme4_1.1-37           mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [76] rbibutils_2.3         QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [79] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [82] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [85] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [88] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [91] htmltools_0.5.8.1     lifecycle_1.0.4       mitml_0.4-5          \n#&gt; [94] MASS_7.3-65",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_summary_posterior.html#bibliografia",
    "href": "chapters/bayesian_inference/06_summary_posterior.html#bibliografia",
    "title": "45  Sintesi a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_balance_prior_post.html",
    "href": "chapters/bayesian_inference/07_balance_prior_post.html",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto come costruire distribuzioni a posteriori combinando ciò che sapevamo prima (priori) con l’informazione proveniente dai dati. Abbiamo anche imparato a riassumere e comunicare queste distribuzioni attraverso quantità sintetiche e intervalli credibili. A questo punto, una domanda diventa cruciale: quanto contano davvero i priori rispetto ai dati nell’inferenza bayesiana?\nQuesta domanda non è solo tecnica, ma profondamente concettuale. In psicologia, come in altre scienze, i dati raccolti sono sempre limitati, e i priori rappresentano sia la conoscenza teorica accumulata sia le assunzioni inevitabili che facciamo prima di osservare i risultati. L’equilibrio tra questi due elementi definisce la natura dell’inferenza bayesiana: non un calcolo meccanico, ma un dialogo continuo tra teoria ed evidenza empirica.\nIn questo capitolo esploreremo come varia l’influenza dei priori in funzione della quantità di dati e della forza delle assunzioni iniziali. Vedremo che, con pochi dati, i priori possono avere un peso decisivo, mentre con molti dati la verosimiglianza tende a dominare. Questo ci aiuterà a capire meglio perché la scelta dei priori è così importante e, allo stesso tempo, perché non bisogna temere che un prior ragionevole “distorca” i risultati quando l’evidenza empirica è abbondante.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_balance_prior_post.html#introduzione",
    "href": "chapters/bayesian_inference/07_balance_prior_post.html#introduzione",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "",
    "text": "Panoramica del capitolo\n\nFunzione dei prior nell’inferenza.\nTipologie principali di prior.\nInfluenza della quantità di dati.\nEffetti delle trasformazioni di scala.\nPriori coniugati e sensibilità.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Balance and Sequentiality in Bayesian Analyses di Bayes rules! (Johnson et al., 2022).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_balance_prior_post.html#la-distribuzione-a-priori",
    "href": "chapters/bayesian_inference/07_balance_prior_post.html#la-distribuzione-a-priori",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "\n46.1 La distribuzione a priori",
    "text": "46.1 La distribuzione a priori\nLa distribuzione a priori descrive ciò che sappiamo o ipotizziamo su un parametro prima di osservare i dati. In psicologia, questo significa poter integrare la conoscenza accumulata da studi precedenti o da esperienze cliniche nelle nostre analisi. Ad esempio, se stiamo studiando l’efficacia di un intervento di mindfulness sulla riduzione dell’ansia, potremmo già sapere da ricerche precedenti che l’effetto tipico si colloca intorno a una riduzione moderata dei sintomi. Una distribuzione a priori ben scelta ci consente di incorporare questa informazione e di rafforzare la plausibilità delle stime.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/07_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "\n46.2 Tipologie di distribuzioni a priori",
    "text": "46.2 Tipologie di distribuzioni a priori\nLa scelta della prior (nota come elicitazione) è uno dei passaggi più delicati dell’approccio bayesiano. Non va intesa come un atto puramente soggettivo: spesso può e deve basarsi su dati empirici e conoscenze consolidate.\nSi distinguono tre categorie principali:\n\nPriori non informative. Servono quando non abbiamo conoscenze pregresse. Assegnano la stessa credibilità a tutti i valori di un parametro. Esempio: se studiamo la correlazione tra due nuove variabili psicologiche mai indagate prima, potremmo iniziare assumendo che tutte le correlazioni da –1 a +1 siano ugualmente probabili.\nPriori debolmente informative. Introducono ipotesi “di buon senso” senza imporre vincoli rigidi. Esempio: nella ricerca psicologica è improbabile che un trattamento aumenti l’ansia in modo enorme (ad es. di 10 deviazioni standard). Una prior debolmente informativa può limitare la stima a un intervallo plausibile (ad es. effetti compresi tra –2 e +2 deviazioni standard), escludendo valori assurdi.\nPriori informative. Riflettono conoscenze specifiche derivanti da studi precedenti o meta-analisi. Esempio: se una meta-analisi mostra che gli interventi di terapia cognitivo-comportamentale riducono in media i sintomi depressivi con un effetto di circa 0.5 deviazioni standard, possiamo usare questa informazione per formulare una prior centrata intorno a 0.5.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "href": "chapters/bayesian_inference/07_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "\n46.3 L’importanza della prior in base ai dati",
    "text": "46.3 L’importanza della prior in base ai dati\nUn principio fondamentale è che più dati osserviamo, meno la prior influisce sulle stime. Se raccogliamo centinaia di osservazioni, la verosimiglianza domina l’inferenza, rendendo meno rilevante la scelta della prior. Viceversa, con pochi dati la prior può avere un peso notevole. Questo è frequente in psicologia quando lavoriamo con campioni ridotti, ad esempio con pazienti affetti da un disturbo raro. In tali casi, una prior ben scelta può rendere le stime più stabili e coerenti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_balance_prior_post.html#trasformazioni-e-scala-dei-parametri",
    "href": "chapters/bayesian_inference/07_balance_prior_post.html#trasformazioni-e-scala-dei-parametri",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "\n46.4 Trasformazioni e scala dei parametri",
    "text": "46.4 Trasformazioni e scala dei parametri\nUn punto spesso trascurato riguarda il fatto che le prior non sono “neutre” rispetto al cambiamento di scala. Ad esempio, se in uno studio sulla soddisfazione lavorativa esprimiamo un punteggio medio in una scala da 1 a 10, una prior uniforme su quella scala appare “piatta” e non informativa. Ma se trasformiamo la scala in percentuale (0–100), la stessa prior non rimane più uniforme. Questo mostra che una prior non può essere “piatta” per tutte le possibili rappresentazioni del parametro: occorre sempre riflettere su quale scala sia più significativa per il problema psicologico studiato.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_balance_prior_post.html#priori-coniugate-e-metodi-moderni",
    "href": "chapters/bayesian_inference/07_balance_prior_post.html#priori-coniugate-e-metodi-moderni",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "\n46.5 Priori coniugate e metodi moderni",
    "text": "46.5 Priori coniugate e metodi moderni\nStoricamente, i ricercatori preferivano usare priori coniugate, che semplificano i calcoli perché producono posteriori della stessa famiglia di distribuzioni. Ad esempio, la distribuzione Beta è coniugata alla Binomiale: se osserviamo il numero di successi in un test di memoria, una prior Beta consente di calcolare facilmente la posteriori. Oggi, grazie ai metodi di campionamento (ad esempio MCMC), non è più necessario limitarsi alle priors coniugate. Possiamo scegliere priors più flessibili, anche non coniugate, che meglio riflettono le conoscenze psicologiche disponibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_balance_prior_post.html#simulazioni",
    "href": "chapters/bayesian_inference/07_balance_prior_post.html#simulazioni",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "\n46.6 Simulazioni",
    "text": "46.6 Simulazioni\nPer comprendere meglio come le distribuzioni a priori influenzano le nostre conclusioni, possiamo usare delle simulazioni. La formula di Bayes\n\\[\np(\\theta \\mid y) \\propto p(\\theta) \\times p(y \\mid \\theta)\n\\] ci dice che la distribuzione a posteriori nasce dalla combinazione di due elementi:\n\nla distribuzione a priori, cioè ciò che crediamo prima di osservare i dati;\nla verosimiglianza, cioè quanto i dati osservati sono compatibili con ciascun valore possibile del parametro \\(\\theta\\).\n\nIn pratica, se abbiamo i valori della verosimiglianza e della prior su una griglia di possibili valori di \\(\\theta\\), possiamo moltiplicarli “punto per punto” e ottenere così la distribuzione a posteriori.\n\n46.6.1 Un esempio psicologico: tassi di risposta corretta\nImmaginiamo di voler stimare la probabilità \\(\\theta\\) che uno studente risponda correttamente a una domanda di un test di memoria. Abbiamo osservato che, su 9 domande, lo studente ha risposto correttamente a 6. Questo può essere modellato con una verosimiglianza binomiale. Ora ci chiediamo: come cambiano le nostre conclusioni se assumiamo priori differenti?\n\n46.6.2 Passo 1: definire la verosimiglianza\n\n# Dati osservati: 6 risposte corrette su 9\nsuccess &lt;- 6\ntosses &lt;- 9\n\n# Griglia di possibili valori di theta\ngrid_points &lt;- 100\np_grid &lt;- seq(0, 1, length.out = grid_points)\n\n# Verosimiglianza binomiale\nlikelihood &lt;- dbinom(success, tosses, p_grid)\n\nLa verosimiglianza indica quali valori di \\(\\theta\\) (probabilità di risposta corretta) sono più compatibili con i dati. In questo caso, i valori intorno a 0.67 (6/9) hanno la probabilità più alta.\n\n46.6.3 Passo 2: funzione per calcolare e visualizzare la posterior\n\ncomputePosterior &lt;- function(likelihood, prior, p_grid) {\n  # Calcolo della posteriori non normalizzata\n  unstd_posterior &lt;- likelihood * prior\n  # Normalizzazione\n  posterior &lt;- unstd_posterior / sum(unstd_posterior)\n  \n  # Preparazione dati per il grafico\n  data &lt;- tibble(\n    theta = p_grid,\n    Prior = prior,\n    Likelihood = likelihood,\n    Posterior = posterior\n  ) |&gt; \n    pivot_longer(cols = c(Prior, Likelihood, Posterior), \n                 names_to = \"distribution\", \n                 values_to = \"density\")\n  \n  # Grafico\n  g &lt;- ggplot(data, aes(x = theta, y = density, color = distribution)) +\n    geom_line(size = 1.2) +\n    facet_wrap(~distribution, scales = \"free_y\", ncol = 3) +\n    labs(\n      x = expression(theta),\n      y = \"Densità\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5),\n          legend.position = \"none\",\n          strip.text = element_text(size = 12, face = \"bold\"))\n  \n  print(g)\n  return(posterior)\n}\n\nLa funzione non solo calcola la distribuzione a posteriori, ma produce anche un grafico comparativo di prior, likelihood e posterior.\n\n46.6.4 Prior uniforme\n\nprior1 &lt;- rep(1, grid_points)\nposterior1 &lt;- computePosterior(likelihood, prior1, p_grid)\n\n\n\n\n\n\n\nCommento: la prior uniforme assegna uguale credibilità a tutti i valori di \\(\\theta\\). Il risultato è che la posteriori coincide quasi con la verosimiglianza: senza conoscenze pregresse, sono i dati (6 risposte corrette su 9) a guidare completamente l’inferenza.\n\n46.6.5 Prior a gradino\n\nprior2 &lt;- ifelse(p_grid &gt;= 0.5, 1, 0)\nposterior2 &lt;- computePosterior(likelihood, prior2, p_grid)\n\n\n\n\n\n\n\nCommento: qui assumiamo che \\(\\theta\\) non possa essere inferiore a 0.5 (cioè lo studente deve rispondere almeno come “a caso”). La posteriori esclude quindi qualsiasi valore sotto 0.5, anche se la verosimiglianza avrebbe assegnato loro un po’ di probabilità. Questo esempio mostra come una convinzione forte possa vincolare pesantemente le conclusioni.\n\n46.6.6 Prior esponenziale centrata su 0.5\n\nprior3 &lt;- exp(-5 * abs(p_grid - 0.5))\nposterior3 &lt;- computePosterior(likelihood, prior3, p_grid)\n\n\n\n\n\n\n\nCommento: questa prior esprime l’idea che lo studente abbia circa il 50% di probabilità di rispondere correttamente. La posteriori viene “attirata” verso 0.5, pur tenendo conto dei dati (6 su 9 ≈ 0.67). Il risultato finale è un compromesso: né tutto nei dati, né tutto nella prior.\nQuesto esercizio mostra chiaramente il ruolo delle prior:\n\ncon una prior piatta prevalgono i dati,\ncon una prior vincolante (gradino) le ipotesi iniziali dominano,\ncon una prior moderata (esponenziale) si ottiene un compromesso.\n\nIn psicologia, dove spesso i campioni sono piccoli, la scelta della prior può cambiare molto le conclusioni: un motivo in più per rendere trasparenti e motivate le ipotesi di partenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_balance_prior_post.html#il-caso-coniugato-beta-binomiale",
    "href": "chapters/bayesian_inference/07_balance_prior_post.html#il-caso-coniugato-beta-binomiale",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "\n46.7 Il caso coniugato: Beta-Binomiale",
    "text": "46.7 Il caso coniugato: Beta-Binomiale\nUn esempio classico in cui i calcoli diventano semplici è il modello Beta-Binomiale. La distribuzione Beta è coniugata alla Binomiale: ciò significa che la forma della posteriori rimane una Beta.\n\nplot_beta_binomial &lt;- function(alpha, beta, y, n) {\n  theta &lt;- seq(0, 1, length.out = 100)\n  prior_density &lt;- dbeta(theta, alpha, beta)\n  likelihood &lt;- dbinom(y, n, theta)\n  scaled_likelihood &lt;- likelihood / max(likelihood)\n  posterior_density &lt;- dbeta(theta, alpha + y, beta + n - y)\n  \n  data &lt;- tibble(\n    theta = theta,\n    Prior = prior_density,\n    Likelihood = scaled_likelihood,\n    Posterior = posterior_density\n  ) |&gt; \n    pivot_longer(cols = c(Prior, Likelihood, Posterior), \n                 names_to = \"distribution\", \n                 values_to = \"density\")\n  \n  ggplot(data, aes(x = theta, y = density, color = distribution)) +\n    geom_line(size = 1.2) +\n    labs(x = expression(theta), y = \"Densità\") +\n    theme(plot.title = element_text(hjust = 0.5))\n}\n\nPrior uniforme:\n\nplot_beta_binomial(alpha = 1, beta = 1, y = 6, n = 9)\n\n\n\n\n\n\n\nPrior informativo:\n\nplot_beta_binomial(alpha = 2, beta = 2, y = 6, n = 9)\n\n\n\n\n\n\n\nPrior fortemente informativo:\n\nplot_beta_binomial(alpha = 2, beta = 5, y = 6, n = 9)\n\n\n\n\n\n\n\nCon un prior uniforme, i dati (6 su 9) guidano quasi interamente la stima. Con un prior più informativo, la posterior si sposta nella direzione suggerita dalle credenze pregresse.\nIn sintesi, le simulazioni mostrano due punti chiave:\n\n\nIl peso della prior dipende dalla quantità di dati. Con pochi dati (come i 9 tentativi del nostro studente), la prior può influenzare molto la stima. Con tanti dati, la verosimiglianza tende a prevalere.\n\nLe scelte di prior hanno senso solo se motivate. In psicologia, una prior può derivare da ricerche precedenti (es. meta-analisi), da conoscenze teoriche (es. aspettarci che un trattamento riduca e non aumenti i sintomi) o da ipotesi ragionevoli.\n\nL’approccio bayesiano ci permette quindi di integrare flessibilmente dati e conoscenze pregresse, arrivando a inferenze che sono al tempo stesso empiricamente fondate e teoricamente sensate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "href": "chapters/bayesian_inference/07_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "\n46.8 Connessione tra intuizioni e teoria",
    "text": "46.8 Connessione tra intuizioni e teoria\nL’equilibrio tra ciò che crediamo prima (la distribuzione a priori) e ciò che osserviamo dopo (i dati) non è solo una metafora utile: è una vera e propria necessità matematica. Questo diventa evidente guardando al caso della distribuzione Beta-Binomiale, uno dei modelli più semplici e didattici.\nIl valore atteso della distribuzione a posteriori può essere riscritto in questa forma:\n\\[\n\\begin{aligned}\n\\mathbb{E}_{\\text{post}}[\\theta] &= \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\[6pt]\n&= \\underbrace{\\frac{\\alpha+\\beta}{\\alpha+\\beta+n}}_{\\text{peso del priore}} \\cdot\n\\underbrace{\\frac{\\alpha}{\\alpha+\\beta}}_{\\text{media a priori}}\n\\;+\\;\n\\underbrace{\\frac{n}{\\alpha+\\beta+n}}_{\\text{peso dei dati}} \\cdot\n\\underbrace{\\frac{y}{n}}_{\\text{media osservata}} .\n\\end{aligned}\n\\] Questa equazione ci mostra che il valore atteso a posteriori è sempre una media ponderata di due elementi:\n\nla media a priori (\\(\\alpha/(\\alpha+\\beta)\\)), cioè ciò che pensavamo prima di raccogliere i dati;\nla proporzione osservata (\\(y/n\\)), cioè ciò che i dati suggeriscono.\n\nI pesi che regolano il compromesso dipendono dal rapporto tra il numero di osservazioni \\(n\\) e la somma \\(\\alpha+\\beta\\) (che misura quanto “forte” è l’informazione contenuta nella prior).\n\nSe \\(n\\) è molto grande, prevalgono i dati: la posteriori riflette quasi esclusivamente le osservazioni empiriche.\nSe \\(n\\) è piccolo, prevale la prior: la stima finale risente molto delle convinzioni iniziali.\n\n\n46.8.1 Un’analogia psicologica\nPensiamo a uno psicologo che vuole stimare la probabilità che uno studente ricordi correttamente un concetto dopo una lezione.\n\nSe ha già osservato centinaia di risposte di quello studente, i dati domineranno l’inferenza, e la sua idea iniziale (la prior) conterà poco.\nSe invece ha visto solo poche risposte, tenderà ad affidarsi molto di più alle convinzioni iniziali (per esempio, che lo studente abbia in generale una buona memoria).\n\n46.8.2 Come scegliere i parametri\n\nSe vogliamo esprimere completa incertezza, possiamo usare \\(\\alpha = \\beta = 1\\), che assegna la stessa probabilità a tutti i valori possibili di \\(\\theta\\) (da 0 a 1).\nSe abbiamo informazioni pregresse (es. da studi precedenti o da esperienza clinica), scegliamo \\(\\alpha/(\\alpha+\\beta)\\) in modo che coincida con il valore atteso a priori desiderato.\nLa quantità \\(\\alpha+\\beta\\) regola invece “quanto ci crediamo”: più è grande, più dati serviranno per spostare la nostra convinzione iniziale.\n\nIn sintesi, questa formulazione mostra in modo chiaro che l’approccio bayesiano è una combinazione bilanciata tra teoria e dati. Il risultato non è mai solo la nostra ipotesi iniziale, né solo l’evidenza empirica, ma un’integrazione delle due. Questo rende l’inferenza bayesiana particolarmente adatta alle scienze psicologiche, dove spesso lavoriamo con campioni piccoli e dove le conoscenze accumulate in precedenza sono preziose per guidare l’interpretazione dei dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "href": "chapters/bayesian_inference/07_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "\n46.9 Conflitto tra prior e verosimiglianza",
    "text": "46.9 Conflitto tra prior e verosimiglianza\nConsideriamo un esempio discusso da McElreath, che mette in luce un punto importante: anche in situazioni semplici, la combinazione tra distribuzione a priori e verosimiglianza può produrre risultati poco intuitivi.\n\nLesson: Don’t trust intuition, for even simple prior+likelihood scenarios defy it. Four examples below, each producing radically different posteriors. Can you guess what each does?\n\nNella prima figura McElreath invita a riflettere su quattro diversi casi:\n\nNella seconda figura mostra i risultati effettivi delle combinazioni di prior e likelihood:\n\nL’idea centrale è confrontare il comportamento della distribuzione normale (con code sottili) e della distribuzione di Student-t con 2 gradi di libertà (con code molto più spesse). Le code indicano quanto la distribuzione attribuisce ancora una certa plausibilità a valori estremi.\n\n\nIn Alto a Sinistra: Prior Normale, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Normal(10,1)\n\nQuesto è lo scenario “classico”. La posteriori si colloca a metà strada tra prior e likelihood, bilanciando le due informazioni. L’aggiornamento è regolare e prevedibile: i dati spostano la nostra convinzione iniziale, ma senza sorprese.\n\n\nIn Alto a Destra: Prior Student, Likelihood Student (df=2)\n\ny ~ Student(2,mu,1)\nmu ~ Student(2,10,1)\n\nQui entrambe le distribuzioni hanno code spesse. Ciò significa che attribuiscono alta plausibilità anche a valori molto lontani dal centro. Il risultato è che la posteriori diventa più incerta e “larga”, con un compromesso meno definito. Non esiste un punto centrale netto, ma piuttosto una distribuzione che riflette la forte apertura a valori estremi.\n\n\nIn Basso a Sinistra: Prior Student, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Student(2,10,1)\n\nIn questo caso, la likelihood normale (con code sottili) è molto rigida: penalizza i valori lontani. Il prior Student-t, invece, non è sorpreso da valori estremi. Il risultato è che la posteriori viene guidata soprattutto dalla likelihood normale, con un effetto limitato del prior.\n\n\nIn Basso a Destra: Prior Normale, Likelihood Student\n\ny ~ Student(2,mu,1)\nmu ~ Normal(10,1)\n\nQui accade l’opposto: il prior normale, con le sue code sottili, esercita un’influenza dominante. La likelihood Student-t, che accetterebbe valori estremi, viene “corretta” dal prior, che restringe la plausibilità attorno al proprio centro.\n\n\nIn sintesi, questo esercizio mostra come il comportamento della posteriori dipenda in modo cruciale dalla forma relativa di prior e likelihood. Con prior e likelihood gaussiane, l’aggiornamento è intuitivo. Appena introduciamo distribuzioni con code spesse (Student-t), la dinamica cambia: a volte prevale la prior, a volte la likelihood, e il risultato può essere molto diverso da quello che ci aspetteremmo a intuito.\nMorale: nell’analisi bayesiana non basta “affidarsi al buon senso”. Quando prior e likelihood hanno forme diverse, il risultato dell’aggiornamento può essere sorprendente. Per questo è sempre necessario eseguire i calcoli, non solo ragionare intuitivamente.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_balance_prior_post.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/07_balance_prior_post.html#riflessioni-conclusive",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl tema dell’equilibrio tra priori e dati tocca il cuore dell’approccio bayesiano. Una delle critiche più frequenti al bayesianesimo è che i risultati dipenderebbero “troppo” dai priori. Come abbiamo visto, questa affermazione è vera solo in parte: il peso relativo del prior e dei dati dipende dalla situazione.\nCon pochi dati, i priori hanno un’influenza maggiore, ed è giusto che sia così: in condizioni di scarsità informativa, le nostre assunzioni teoriche forniscono una guida essenziale. Con molti dati, al contrario, l’influenza dei priori tende a ridursi, e i posteriori riflettono quasi interamente l’evidenza empirica. In entrambi i casi, il vantaggio dell’approccio bayesiano è che questo equilibrio è reso esplicito e trasparente, e non nascosto dietro formule o procedure automatiche.\nDal punto di vista psicologico, questo è un aspetto particolarmente rilevante. In un campo in cui i campioni sono spesso piccoli e le misure rumorose, i priori non sono un “problema”, ma una risorsa: permettono di incorporare conoscenze accumulate, di stabilizzare le stime e di ridurre il rischio di interpretazioni fuorvianti. Allo stesso tempo, l’analisi di sensibilità — cioè il confronto tra posteriori ottenuti con priori diversi — ci aiuta a verificare quanto i risultati dipendano dalle scelte iniziali.\nQuesto capitolo mostra quindi che la forza dell’inferenza bayesiana non sta nel dare tutto il potere ai dati o tutto ai priori, ma nel bilanciare i due in modo coerente. Nei capitoli successivi vedremo come questo equilibrio giochi un ruolo decisivo anche nella costruzione di modelli più complessi e, soprattutto, nella loro valutazione comparativa.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nL’obiettivo di questo esercizio è comprendere come la distribuzione a priori influenzi la distribuzione a posteriori a seconda della grandezza del campione. Utilizzeremo dati raccolti della Satisfaction With Life Scale (SWLS), categorizzandoli in base a una soglia e analizzando la proporzione di risposte che superano tale soglia con un approccio bayesiano.\nFase 1: Raccolta e categorizzazione dei dati\n\nOgni studente utilizza i valori della scala SWLS che sono stati raccolti dal suo gruppo TPV.\nSi sceglie una soglia arbitraria (ad esempio, un punteggio superiore a 20 indica “elevata soddisfazione”).\n\nSi calcola la proporzione di persone con punteggi superiori alla soglia:\n\\[\n\\hat{p} = \\frac{k}{n}\n\\]\ndove \\(k\\) è il numero di persone con SWLS sopra la soglia e \\(n\\) è la dimensione del campione (circa 15).\n\n\nFase 2: Inferenza Bayesiana con un Prior Mediamente Informativo\n\n\nSi assume una distribuzione Beta come prior per la proporzione di persone con SWLS sopra la soglia:\n\\[\np \\sim \\text{Beta}(a, b)\n\\]\ndove \\(a = 2\\) e \\(b = 2\\), un prior mediamente informativo (distribuzione simmetrica centrata su 0.5).\n\n\nSi calcola la distribuzione a posteriori utilizzando la coniugazione della Beta con la distribuzione binomiale:\n\\[\np \\mid D \\sim \\text{Beta}(a + k, b + n - k)\n\\]\n\n\nSi calcolano:\n\n\nStima puntuale della proporzione (valore atteso della Beta a posteriori):\n\\[\nE[p \\mid D] = \\frac{a + k}{a + b + n}\n\\]\n\nIntervallo di credibilità (CI al 95%), utilizzando i quantili della distribuzione Beta a posteriori.\n\n\n\nFase 3: Analisi con un Campione Più Grande\n\nSi ripete lo stesso esercizio, ma immaginando che la stessa proporzione \\(\\hat{p}\\) provenga da un campione di n = 1000.\n\nSi calcola la nuova distribuzione a posteriori:\n\\[\np \\mid D \\sim \\text{Beta}(a + k', b + n' - k')\n\\] con \\(k' = \\hat{p} \\times 1000\\).\n\nSi ricalcolano stima puntuale e intervallo di credibilità.\n\nFase 4: Confronto e Interpretazione\n\n\nSi confrontano le due distribuzioni a posteriori:\n\nCome cambia la varianza della distribuzione a posteriori?\nCome cambia l’influenza del prior?\nQual è la differenza nella precisione della stima puntuale e dell’intervallo di credibilità?\n\n\nSi discute come, all’aumentare del campione, l’influenza della distribuzione a priori diminuisce, facendo emergere il ruolo della likelihood.\n\nConsegna: caricare su Moodle il file .qmd compilato in pdf.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] rmarkdown_2.29        nloptr_2.2.1          ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           jomo_2.7-6            xfun_0.53            \n#&gt; [25] glmnet_4.1-10         cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [28] pan_1.9               broom_1.0.9           parallel_4.5.1       \n#&gt; [31] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [34] rpart_4.1.24          boot_1.3-32           lubridate_1.9.4      \n#&gt; [37] estimability_1.5.1    iterators_1.0.14      knitr_1.50           \n#&gt; [40] zoo_1.8-14            pacman_0.5.1          nnet_7.3-20          \n#&gt; [43] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [46] tidyselect_1.2.1      abind_1.4-8           codetools_0.2-20     \n#&gt; [49] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [52] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [55] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [58] tensorA_0.36.2.1      checkmate_2.3.3       foreach_1.5.2        \n#&gt; [61] stats4_4.5.1          reformulas_0.4.1      distributional_0.5.0 \n#&gt; [64] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [67] scales_1.4.0          minqa_1.2.8           xtable_1.8-4         \n#&gt; [70] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [73] lme4_1.1-37           mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [76] rbibutils_2.3         QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [79] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [82] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [85] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [88] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [91] htmltools_0.5.8.1     lifecycle_1.0.4       mitml_0.4-5          \n#&gt; [94] MASS_7.3-65",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_balance_prior_post.html#bibliografia",
    "href": "chapters/bayesian_inference/07_balance_prior_post.html#bibliografia",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_prior_pred_check.html",
    "href": "chapters/bayesian_inference/08_prior_pred_check.html",
    "title": "47  Controllo predittivo a priori",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto che l’inferenza bayesiana nasce dall’integrazione tra ciò che sappiamo prima (i priori) e ciò che osserviamo nei dati (la verosimiglianza). Abbiamo anche discusso il problema del bilanciamento tra assunzioni iniziali ed evidenza empirica, sottolineando che i priori non sono un dettaglio tecnico, ma una parte essenziale del ragionamento statistico. A questo punto si impone una domanda pratica: come possiamo valutare se i priori che abbiamo scelto sono ragionevoli?\nUn modo diretto e intuitivo è ricorrere ai controlli predittivi sui priori [prior predictive checks; Gelman et al. (2020)]. L’idea è semplice: se i priori rappresentano le nostre credenze prima di vedere i dati, allora dovremmo poterli usare per simulare dei dati “ipotetici” e chiederci se questi assomigliano a ciò che potremmo realisticamente osservare in psicologia. Se i dati simulati appaiono del tutto implausibili, significa che i nostri priori non stanno catturando in modo adeguato le conoscenze di partenza.\nIn questo capitolo introdurremo il concetto e la pratica dei controlli predittivi sui priori. Vedremo come si eseguono, perché sono fondamentali per una modellazione coerente e quali errori comuni ci aiutano a evitare.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_prior_pred_check.html#introduzione",
    "href": "chapters/bayesian_inference/08_prior_pred_check.html#introduzione",
    "title": "47  Controllo predittivo a priori",
    "section": "",
    "text": "Panoramica del capitolo\n\nChe cos’è la distribuzione predittiva a priori e perché è importante nell’inferenza bayesiana.\nSimulare dati prima di osservare quelli reali, per valutare la coerenza tra il modello e ciò che ci aspettiamo dal fenomeno studiato.\nApplicare il controllo predittivo a priori nel caso beta-binomiale, con esempi in R.\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nlibrary(bayesplot)\nlibrary(brms)\nlibrary(posterior)\nlibrary(priorsense)\nlibrary(cmdstanr)\n\n\n\n\n\n47.0.1 L’idea fondamentale\nIl prior predictive check si basa su una domanda chiave: “Se questa distribuzione a priori riflette davvero le nostre aspettative, quali dati dovremmo osservare in pratica?” In altre parole, simuliamo dati plausibili generati dal modello prima di analizzare i dati reali, per verificare se le nostre assunzioni iniziali producono risultati coerenti con la realtà teorica o empirica del fenomeno studiato.\n\n47.0.1.1 Perché è importante?\nNei modelli bayesiani, le distribuzioni a priori codificano la nostra conoscenza (o ignoranza) preliminare. Tuttavia:\n\n\nprior apparentemente innocue possono, combinate con il modello di verosimiglianza, generare previsioni implausibili (es., valori al di fuori del range possibile, comportamenti estremi non realistici);\n\n\nprior troppo informative possono dominare ingiustificatamente l’evidenza dei dati, mentre prior troppo vaghe possono portare a stime instabili.\n\nIl prior predictive check ci permette di esplorare la distribuzione predittiva a priori, \\(p(\\tilde{y})\\), dove \\(\\tilde{y}\\) sono dati simulati, per identificare incongruenze prima della fase inferenziale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_prior_pred_check.html#la-definizione-formale",
    "href": "chapters/bayesian_inference/08_prior_pred_check.html#la-definizione-formale",
    "title": "47  Controllo predittivo a priori",
    "section": "\n47.1 La definizione formale",
    "text": "47.1 La definizione formale\nNon conoscendo i parametri \\(\\theta\\), non possiamo formulare un’unica predizione \\(p(\\tilde y \\mid \\theta)\\). Invece, la distribuzione predittiva a priori \\(p(\\tilde y)\\) combina le predizioni di tutti i possibili valori di \\(\\theta\\), pesandoli in base alla loro plausibilità a priori.\nÈ come consultare un gruppo di esperti (i possibili \\(\\theta\\)) e aggregare i loro giudizi, ponderandoli in base a quanto li riteniamo affidabili prima di osservare qualsiasi dato. La formula che descrive questo processo è:\n\\[\np(\\tilde y \\mid \\text{prior}) = \\int p(\\tilde y \\mid \\theta)\\, p(\\theta)\\, d\\theta .\n\\tag{47.1}\\] Questo integrale rappresenta una combinazione (mixture) di distribuzioni.1 Non stiamo calcolando una media aritmetica di singoli valori di \\(\\tilde y\\), ma piuttosto mescolando intere distribuzioni condizionate \\(p(\\tilde y \\mid \\theta)\\), ciascuna ponderata dalla sua probabilità a priori \\(p(\\theta)\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_prior_pred_check.html#implementazione-e-valutazione-del-ppc",
    "href": "chapters/bayesian_inference/08_prior_pred_check.html#implementazione-e-valutazione-del-ppc",
    "title": "47  Controllo predittivo a priori",
    "section": "\n47.2 Implementazione e valutazione del PPC",
    "text": "47.2 Implementazione e valutazione del PPC\nPer verificare l’adeguatezza della distribuzione a priori, seguiamo un approccio sistematico:\n\nDefinizione del modello generativo\nSi stabilisce la relazione tra parametri e dati attraverso la verosimiglianza \\(p(y \\mid \\theta)\\), includendo eventuali funzioni di collegamento (logit, log) necessarie per garantire coerenza con il dominio delle variabili.\nSpecificazione della distribuzione a priori\nLe prior dovrebbero riflettere conoscenze preliminari debolmente informative, adattate alla scala naturale del problema. Per parametri con vincoli naturali (es., deviazioni standard positive), si utilizzano distribuzioni a supporto ristretto (half-normal, esponenziale).\n\nSimulazione della distribuzione predittiva\nLa procedura consiste nel generare valori sintetici dei dati direttamente dalla combinazione prior + verosimiglianza:\n\nsi estrae un valore dei parametri \\(\\theta^{(s)}\\) dalla distribuzione a priori \\(p(\\theta)\\) (quindi con la probabilità relativa specificata da quella distribuzione);\n\ndato \\(\\theta^{(s)}\\), la verosimiglianza \\(p(y \\mid \\theta^{(s)})\\) è completamente definita (es., una Binomiale con probabilità di successo pari a \\(\\theta^{(s)}\\));\n\nsi genera un dato sintetico \\(\\tilde{y}^{(s)}\\) campionando una realizzazione da questa verosimiglianza;\n\nsi ripete la procedura per \\(s = 1, \\dots, S\\).\n\nL’insieme \\(\\{\\tilde{y}^{(s)}\\}_{s=1}^S\\) costituisce un’approssimazione della distribuzione predittiva a priori, cioè la distribuzione dei dati che ci aspettiamo di osservare prima di guardare i dati reali.\n\n\nValidazione empirica\nLe simulazioni vengono confrontate con i vinciti teorici del problema:\n\n\nAderenza al dominio: I valori simulati devono rispettare i limiti naturali della variabile (es., probabilità in [0,1], tempi positivi).\n\n\nRealismo quantitativo: Gli ordini di grandezza devono essere plausibili per il fenomeno studiato.\n\n\nComportamento distributivo: La dispersione e la forma della distribuzione devono essere coerenti con l’aspettativa teorica.\n\n\n\n\n\n\n\n\n\nCaso studio: modellazione di risposte dicotomiche\n\n\n\n\n\nSupponiamo di analizzare la probabilità \\(p\\) di successo in un test psicometrico. La scelta della prior per \\(p\\) influenza direttamente le previsioni del modello:\n\nPrior estrema (es. Beta(0.1, 0.1)):\nAssume che le risposte siano quasi sempre corrette o quasi sempre errate, implicando una popolazione con prestazioni polarizzate. Le simulazioni mostrerebbero prevalentemente tassi di successo vicini a 0% o 100%, scenario spesso irrealistico in contesti educativi.\nPrior bilanciata (es. Beta(2, 2)):\nRiflette l’aspettativa che le risposte siano distribuite attorno al 50%, analogamente al lancio di una moneta equa. Le simulazioni genererebbero una variabilità più plausibile per popolazioni eterogenee.\n\nValidazione attraverso simulazioni.\nIl prior predictive check rivela queste implicazioni:\n\nGenerando dati sintetici con la prior estrema, si osserverebbero distribuzioni bimodali con picchi agli estremi, incongruenti con il comportamento atteso in molti studi psicologici.\n\nCon la prior bilanciata, le simulazioni mostrerebbero invece una dispersione centrata attorno a valori intermedi, coerente con una popolazione mista.\n\nRicalibrazione: Se le simulazioni risultano implausibili (es., &gt;30% di valori estremi non giustificati dalla teoria), si può:\n\nmodificare i parametri della prior (es., passare a Beta(1, 1) per ridurre le assunzioni a priori);\nintrodurre trasformazioni (es., logit per evitare valori al di fuori di [0,1]);\n\nadottare prior gerarchiche per catturare eterogeneità sottogruppo.\n\nProspettiva epistemologica.\nIl processo equivale a:\n\nformalizzare le ipotesi iniziali in termini probabilistici (scelta della prior);\n\nverificarne le conseguenze empiriche attraverso simulazioni;\n\nrivalutare criticamente le assunzioni alla luce delle previsioni generate.\n\nQuesto approccio previene errori comuni nell’analisi bayesiana, come l’uso involontario di prior che sovradeterminano i risultati o generano artefatti. La coerenza tra simulazioni a priori e conoscenza di dominio è un indicatore chiave della robustezza del modello.\n\n\n\n\n\n\n\n\n\nRegola pratica: Una prior adeguata non deve essere “perfetta”, ma deve produrre scenari plausibili. Se le simulazioni appaiono sistematicamente lontane dalla realtà teorica, la specificazione del modello va ripensata, non i dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_prior_pred_check.html#esempio-un-test-a-10-domande",
    "href": "chapters/bayesian_inference/08_prior_pred_check.html#esempio-un-test-a-10-domande",
    "title": "47  Controllo predittivo a priori",
    "section": "\n47.3 Esempio: un test a 10 domande",
    "text": "47.3 Esempio: un test a 10 domande\nQuesto esempio illustra l’idea chiave del prior predictive check (PPC): una prior sui parametri (qui, la probabilità di risposta corretta) implica predizioni sui punteggi osservabili. Se la prior assegna troppa massa a esiti estremi (0/10 o 10/10) senza giustificazione, sta “spingendo” verso scenari poco plausibili.\nConsideriamo uno studente che affronta un test da 10 domande. Il numero di risposte corrette è\n\\[\ny \\sim \\text{Binomiale}(n=10,\\; p),\n\\] dove \\(p\\) è la probabilità di rispondere correttamente a una singola domanda. La prior è su \\(p\\); ciò che osserviamo, però, sono i punteggi \\(y\\). Il PPC “propaga” l’incertezza su \\(p\\) fino ai punteggi, generando la distribuzione predittiva a priori:\n\\[\np(y) \\;=\\; \\int \\underbrace{p(y \\mid p)}_{\\text{Binom}(10,p)} \\;\\underbrace{p(p)}_{\\text{prior}} \\, dp,\n\\] che nel caso \\(p \\sim \\text{Beta}(a,b)\\) è una Beta–Binomiale.\n\n47.3.1 Scenario 1: prior debole (alta incertezza)\nScegliamo una prior larga, ad es. \\(p \\sim \\text{Beta}(2,2)\\).\n\nMedia: \\(\\mathbb{E}[p] = \\tfrac{2}{2+2} = 0.5\\)\n\nForza a priori (pseudo-conteggi): \\(a+b=4\\) (2 “successi immaginari” + 2 “errori immaginari”)\n\nQuesta prior favorisce valori centrali ma non esclude affatto \\(p\\) vicino a 0 o 1, quindi produce più esiti estremi nei punteggi.\n\nset.seed(1)\n\nn &lt;- 10\nS &lt;- 10000\np_sim &lt;- rbeta(S, 2, 2)\ny_sim &lt;- rbinom(S, size = n, prob = p_sim)\n\ntibble(y = y_sim) |&gt;\n  ggplot(aes(x = y)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 11) +\n  labs(x = \"Numero di risposte corrette su 10\", y = \"Densità\")\n\n\n\n\n\n\n\nLettura. Il modello utilizza un prior eccessivamente permissivo, adatto a una popolazione di studenti molto eterogenea (che include sia individui con prestazioni quasi sempre perfette, sia altri quasi sempre insufficienti). Il risultato è una distribuzione predittiva che assegna probabilità irrealisticamente elevate agli estremi (0/10 e 10/10), un chiaro indicatore che il prior è troppo debole (ovvero, troppo diffuso).\n\n47.3.2 Scenario 2: prior informativa (studenti preparati)\nSupponiamo ora che gli studenti siano mediamente ben preparati: \\(p \\sim \\text{Beta}(10,3)\\).\n\nMedia: \\(\\mathbb{E}[p] \\approx 0.77\\)\n\nForza a priori: \\(a+b=13\\) (10 “successi immaginari”, 3 “errori immaginari”)\nVarianza più contenuta (meno peso agli estremi)\n\nCi aspettiamo punteggi tra 6 e 9 risposte corrette.\n\nset.seed(2)\np_sim2 &lt;- rbeta(S, 10, 3)\ny_sim2 &lt;- rbinom(S, size = n, prob = p_sim2)\n\ntibble(y = y_sim2) |&gt;\n  ggplot(aes(x = y)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 11) +\n  labs(x = \"Numero di risposte corrette su 10\", y = \"Densità\")\n\n\n\n\n\n\n\nLettura. Gli esiti molto bassi (0–3) diventano poco probabili; la massa si concentra su esiti coerenti con studenti preparati.\n\n47.3.3 Perché è utile?\nIl confronto mostra che la prior non è un dettaglio tecnico: traduce in probabilità ciò che riteniamo plausibile.\n\nSe la predittiva a priori genera esiti irrealistici (es. molti 0/10), la prior va rivista (più informativa, scala coerente, pseudo-conteggi ragionevoli).\nSe la predittiva a priori è in linea con le aspettative, la prior è adeguata.\n\nIl PPC rende trasparente il legame tra assunzioni sul parametro \\(p\\) e punteggi osservabili \\(y\\), permettendo diagnosi prima di analizzare i dati reali.\nEccoti una versione migliorata dal punto di vista linguistico, tecnico e della chiarezza espositiva:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_prior_pred_check.html#prior-predictive-check-con-brms",
    "href": "chapters/bayesian_inference/08_prior_pred_check.html#prior-predictive-check-con-brms",
    "title": "47  Controllo predittivo a priori",
    "section": "\n47.4 Prior Predictive Check con brms\n",
    "text": "47.4 Prior Predictive Check con brms\n\nFinora abbiamo eseguito le simulazioni per la Prior Predictive Check (PPC) utilizzando funzioni di base di R. Con brms è possibile ottenere lo stesso risultato in modo più diretto, semplicemente specificando l’opzione sample_prior = \"only\". In questo modo, il modello non utilizza i dati osservati ma genera valori esclusivamente a partire dalle distribuzioni a priori (prior).\n\nn_studenti &lt;- 50\nn_item &lt;- 10\n\ndati_dummy &lt;- tibble(\n  correct  = 0L,   # Valore segnaposto: necessario per la sintassi della formula\n  n_trials = n_item\n) |&gt; slice(rep(1, n_studenti))\n\npriors &lt;- c(\n  prior(normal(0, 1.5), class = \"Intercept\") # Prior sull'intercetta in scala logit\n)\n\nfit_prior_only &lt;- brm(\n  bf(correct | trials(n_trials) ~ 1),\n  data = dati_dummy,\n  family = binomial(),\n  prior = priors,\n  sample_prior = \"only\",  # &lt;-- Simulazione prior predictive\n  chains = 4, iter = 1000, cores = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\nyrep &lt;- posterior_predict(fit_prior_only)\nppc_bars(y = rep(0, n_studenti), yrep = yrep[1:200, ]) \n\n\n\n\n\n\n\nInterpretazione.\n\nLa distribuzione a priori Normal(0, 1.5) è specificata per l’intercetta del modello nella scala logit.\nCiò implica che la probabilità sottostante di una risposta corretta, \\(p\\), ha una distribuzione a priori il cui massimo della densità è compreso approssimativamente tra ~0.05 e ~0.95. Questa scelta esclude, in linea di principio, probabilità sistematiche estreme (vicine a 0 o a 1), pur mantenendo un’ampia variabilità di valori plausibili.\nIl grafico mostra le distribuzioni dei punteggi totali (da 0 a 10 su 10 item) che il modello considera plausibili prima di aver osservato i dati reali (distribuzione predittiva a priori).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_prior_pred_check.html#prior-predictive-check-con-stan",
    "href": "chapters/bayesian_inference/08_prior_pred_check.html#prior-predictive-check-con-stan",
    "title": "47  Controllo predittivo a priori",
    "section": "\n47.5 Prior Predictive Check con Stan\n",
    "text": "47.5 Prior Predictive Check con Stan\n\nCon Stan è possibile eseguire la stessa analisi in modo ancora più esplicito: specifichiamo esclusivamente le distribuzioni a prior (prior), omettendo completamente la verosimiglianza (likelihood), e generiamo i dati simulati direttamente nel blocco generated quantities. Questo approccio permette di comprendere cosa avviene a livello computazionale.\n\nbinom_prior_ppc_stan &lt;- '\ndata {\n  int&lt;lower=1&gt; N;           // numero di studenti simulati\n  int&lt;lower=1&gt; n_items;     // numero di item per studente\n}\nparameters {\n  real alpha;               // intercetta in scala logit\n}\nmodel {\n  alpha ~ normal(0, 1.5);   // prior debolmente informativa\n  // Nessuna verosimiglianza specificata: modello basato solo sulle prior\n}\ngenerated quantities {\n  vector[N] p;              // probabilità individuali di successo\n  array[N] int y_rep;       // punteggi simulati (dati replicati)\n  for (i in 1:N) {\n    p[i] = inv_logit(alpha);            // trasformazione da logit a probabilità\n    y_rep[i] = binomial_rng(n_items, p[i]); // simulazione dei punteggi binomiali\n  }\n}\n'\nwriteLines(binom_prior_ppc_stan, \"binom_prior_ppc.stan\")\n\nCompiliamo ed eseguiamo il modello:\n\nmod_binom &lt;- cmdstan_model(\"binom_prior_ppc.stan\")\nfit_binom &lt;- mod_binom$sample(\n  data = list(N = 100, n_items = 10),\n  chains = 4, iter_warmup = 500, iter_sampling = 1000,\n  seed = 123, refresh = 0\n)\n\nEstrazione dei punteggi simulati e analisi della distribuzione delle medie:\n\ndraws &lt;- fit_binom$draws(variables = \"y_rep\", format = \"draws_matrix\")\ny_rep &lt;- as_draws_matrix(draws)\n\ntibble(mu = rowMeans(y_rep)) |&gt;\n  ggplot(aes(x = mu)) +\n  geom_histogram(bins = 30) +\n  labs(x = \"Media delle risposte corrette (su 10 item)\", \n       y = \"Frequenza\")\n\n\n\n\n\n\n\n\n47.5.1 Interpretazione\n\nAd ogni iterazione di campionamento, viene estratto un valore del parametro \\(\\alpha\\) dalla sua distribuzione a priori, Normal(0, 1.5).\nQuesto valore viene convertito in una probabilità di successo \\(p\\) applicando la funzione logistica inversa: \\(p = \\text{inv\\_logit}(\\alpha)\\).\nUtilizzando questa probabilità \\(p\\), vengono simulati i punteggi di 100 studenti fittizi per una prova di 10 item, assumendo una distribuzione binomiale.\nL’istogramma risultante mostra la distribuzione campionaria della media dei punteggi simulati attraverso tutte le iterazioni.\n\nQuesto processo mostra chiaramente quali valori per la media del punteggio il modello considera plausibili sulla base esclusiva delle distribuzioni a priori specificate. Se avessimo scelto una distribuzione a priori più informativa (ad esempio, Normal(2, 0.5) per il logit), la distribuzione dei punteggi medi si sarebbe concentrata verso valori più elevati (indicando un’aspettativa a priori di una maggior proporzione di risposte corrette).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_prior_pred_check.html#esempi-di-modelli-più-complessi",
    "href": "chapters/bayesian_inference/08_prior_pred_check.html#esempi-di-modelli-più-complessi",
    "title": "47  Controllo predittivo a priori",
    "section": "\n47.6 Esempi di modelli più complessi",
    "text": "47.6 Esempi di modelli più complessi\nI precedenti esempi si sono concentrati su modelli semplici, in particolare sul caso di una singola proporzione. Estendiamo ora l’analisi a modelli di maggiore complessità. L’obiettivo è illustrare come diverse scelte delle distribuzioni precedenti (prior) per i parametri si traducano in diverse implicazioni predittive per i dati osservabili. Consideriamo tre casi di studio:\n\n\nModello gaussiano (stima dell’intercetta e della varianza dei dati);\n\nRegressione lineare (scala appropriata per i coefficienti e per la varianza residua);\n\nRegressione logistica (interpretazione dei coefficienti nella scala logit e loro impatto sulle probabilità sottostanti).\n\n\n47.6.1 Modello gaussiano semplice\nAssumiamo che il meccanismo generativo dei dati segua una distribuzione normale: \\(y \\sim \\mathcal{N}(\\mu, \\sigma)\\).\nDomanda cruciale: quali scelte delle distribuzioni precedenti per \\(\\mu\\) e \\(\\sigma\\) producono valori predittivi \\(y\\) plausibili per la variabile psicologica in esame (ad esempio, punteggi compresi tra 0 e 100)?\n\nS &lt;- 10000\n\n# Scenario A: prior molto larga\nmu_A    &lt;- rnorm(S, 50, 50)        # media plausibile ma molto incerta\nsigma_A &lt;- rexp(S, rate = 1/20)     # sigma ~ Exp(mean=20), molto larga\nyA      &lt;- rnorm(S, mu_A, sigma_A)\n\n# Scenario B: prior più informativa\nmu_B    &lt;- rnorm(S, 50, 10)\nsigma_B &lt;- rexp(S, rate = 1/10)     # mean=10\nyB      &lt;- rnorm(S, mu_B, sigma_B)\n\nbind_rows(\n  tibble(y = yA, scenario = \"A: prior larghissima\"),\n  tibble(y = yB, scenario = \"B: prior informativa\")\n) |&gt;\n  ggplot(aes(x = y, fill = scenario)) +\n  geom_density(alpha = 0.35) +\n  labs(x = \"y (es. punteggio 0–100)\", y = \"Densità\")\n\n\n\n\n\n\n\nInterpretazione. Se è noto che i punteggi della variabile di interesse sono compresi tra 0 e 100, lo Scenario A potrebbe generare una proporzione eccessiva di valori negativi o superiori a 100, indicando che le distribuzioni precedenti sono troppo poco informative e necessitano di essere ricalibrate (rendendole più informative sia per \\(\\mu\\) che per \\(\\sigma\\)).\nImplementazione in Stan: modello solo con prior e generated quantities.\n\ngauss_prior_ppc_stan &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  mu ~ normal(50, 10);\n  sigma ~ exponential(1.0/10); // mean 10\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (i in 1:N) {\n    y_rep[i] = normal_rng(mu, sigma);\n  }\n}\n'\nwriteLines(gauss_prior_ppc_stan, \"gauss_prior_ppc.stan\")\n\n\nmod_gauss &lt;- cmdstan_model(\"gauss_prior_ppc.stan\")\n\n\nfit_gauss &lt;- mod_gauss$sample(\n  data = list(N = 200),\n  chains = 4, iter_warmup = 500, iter_sampling = 1000, seed = 123,\n  refresh = 0\n)\n\n\nyrep_g &lt;- fit_gauss$draws(\"y_rep\", format = \"draws_matrix\")\nas_tibble(yrep_g) |&gt;\n  pivot_longer(everything(), values_to = \"y\") |&gt;\n  ggplot(aes(x = y)) +\n  geom_density() \n\n\n\n\n\n\n\n\n47.6.2 Regressione lineare\nConsideriamo il seguente modello generativo:\n\\[\ny = \\alpha + \\beta x + \\varepsilon, \\qquad \\varepsilon \\sim \\mathcal{N}(0,\\sigma).\n\\]\n\n47.6.2.1 Importanza della scelta delle distribuzioni precedenti\nNell’ambito della regressione lineare, l’interpretazione del coefficiente \\(\\beta\\) dipende criticamente dalla scala della variabile predittrice \\(x\\):\n\nSe \\(x\\) è standardizzata (media 0, deviazione standard 1), \\(\\beta\\) rappresenta la variazione attesa in \\(y\\) associata a un incremento di una deviazione standard in \\(x\\).\nAd esempio, specificare una distribuzione a priori \\(\\beta \\sim \\mathcal{N}(0,1)\\) equivale ad assumere che: “effetti di modesta entità sono plausibili, mentre effetti superiori a 3 deviazioni standard sono estremamente rari”.\n\nI controlli predittivi basati sulle distribuzioni a priori (prior predictive checks) consentono di rispondere a due interrogativi fondamentali:\n\nLe rette di regressione simulate generano valori di \\(y\\) compatibili con la scala del fenomeno oggetto di studio?\nLa dispersione residua intorno alla retta (determinata da \\(\\sigma\\)) è realisticamente plausibile?\n\nSe la risposta a queste domande è negativa, è necessario rivedere le distribuzioni precedenti specificate per \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\), o considerare una trasformazione appropriata della variabile \\(y\\).\n\n47.6.2.2 Scenario C: Distribuzioni a priori eccessivamente diffuse\nIn questo scenario specifichiamo varianze eccessivamente ampie per \\(\\alpha\\) e \\(\\beta\\). Il risultato: i valori simulati di \\(y\\) risultano irrealistici (eccessivamente negativi o elevati rispetto alla scala empirica del costrutto).\n\nS &lt;- 10000\nx  &lt;- runif(S, -2, 2)  # predittore standardizzato\n\nalpha_C &lt;- rnorm(S, 0, 10)\nbeta_C  &lt;- rnorm(S, 0, 10)\nsigma_C &lt;- rexp(S, rate = 1/5)  # media ~5\nyC      &lt;- rnorm(S, alpha_C + beta_C * x, sigma_C)\n\nInterpretazione. Distribuzioni precedenti eccessivamente diffuse per \\(\\sigma\\) e \\(\\beta\\) rendono probabilisticamente plausibili valori di \\(y\\) privi di senso nel dominio applicativo. Questo non rappresenta un approccio “cauto” o “umile”, ma piuttosto una specificazione incoerente con l’evidenza empirica disponibile.\n\n47.6.2.3 Scenario D: Distribuzioni a priori debolmente informative\nIn questo scenario adottiamo distribuzioni precedenti centrate su zero ma con varianze moderate:\n\\(\\alpha \\sim \\mathcal{N}(0,1)\\) e \\(\\beta \\sim \\mathcal{N}(0,1)\\): effetti plausibili ma di entità contenuta \\(\\sigma \\sim \\text{Exp}(1/2)\\): valore medio atteso di 2, compatibile con la variabilità tipica di punteggi psicologici standardizzati\n\nalpha_D &lt;- rnorm(S, 0, 1)\nbeta_D  &lt;- rnorm(S, 0, 1)\nsigma_D &lt;- rexp(S, rate = 1/2)  # media ~2\nyD      &lt;- rnorm(S, alpha_D + beta_D * x, sigma_D)\n\nbind_rows(\n  tibble(y = yC, scenario = \"C: prior molto larga\"),\n  tibble(y = yD, scenario = \"D: prior W.I.\")\n) |&gt;\n  ggplot(aes(x = y, fill = scenario)) +\n  geom_density(alpha = 0.35) +\n  labs(x = \"Valori simulati di y\", y = \"Densità\")\n\n\n\n\n\n\n\nInterpretazione. Con distribuzioni precedenti debolmente informative, la distribuzione di \\(y\\) mantiene un’ampiezza plausibile. Al contrario, distribuzioni precedenti eccessivamente diffuse producono una variabilità irrealistica di \\(y\\).\n\n47.6.2.4 Implementazione in Stan: simulazione esclusiva dalle distribuzioni a priori\nPer illustrare esplicitamente il concetto, implementiamo un modello Stan che non incorpora dati osservati ma simula esclusivamente dalle distribuzioni precedenti.\n\nlinear_prior_ppc_stan &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n}\nparameters {\n  real alpha;\n  real beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta  ~ normal(0, 1);\n  sigma ~ exponential(1.0/2); // media 2\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (i in 1:N) {\n    y_rep[i] = normal_rng(alpha + beta * x[i], sigma);\n  }\n}\n'\nwriteLines(linear_prior_ppc_stan, \"linear_prior_ppc.stan\")\n\nEsecuzione della simulazione:\n\nmod_lin &lt;- cmdstan_model(\"linear_prior_ppc.stan\")\nx_new   &lt;- runif(200, -2, 2)\n\nfit_lin &lt;- mod_lin$sample(\n  data = list(N = length(x_new), x = x_new),\n  chains = 4, iter_warmup = 500, iter_sampling = 1000, seed = 123,\n  refresh = 0\n)\n\nVisualizzazione della distribuzione predittiva:\n\nyrep_l &lt;- fit_lin$draws(\"y_rep\", format = \"draws_matrix\")\nas_tibble(yrep_l) |&gt;\n  pivot_longer(everything(), values_to = \"y\") |&gt;\n  ggplot(aes(x = y)) +\n  geom_density() +\n  labs(x = \"Valori simulati di y\", y = \"Densità\")\n\n\n\n\n\n\n\n\n47.6.2.5 Conclusioni\n\nLa scala delle distribuzioni precedenti specificate per \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) determina direttamente la distribuzione dei valori simulati di \\(y\\).\nSe i valori di \\(y\\) simulati risultano al di fuori del dominio realistico (ad esempio, punteggi negativi o superiori al massimo teorico), le distribuzioni precedenti devono essere ricalibrate.\nL’utilizzo di distribuzioni precedenti debolmente informative (centrate su zero con varianze moderate) produce simulazioni coerenti con il contesto psicologico di riferimento.\n\n47.6.3 Regressione logistica\nNella regressione logistica, il modello per un esito binario è specificato come:\n\\[\n\\text{logit}\\, P(y=1 \\mid x) = \\alpha + \\beta x .\n\\]\nIn questo framework, i parametri \\(\\alpha\\) e \\(\\beta\\) operano sulla scala logit, che non è direttamente interpretabile in termini di probabilità. È cruciale ricordare che la funzione logit è caratterizzata da una pendenza accentuata: differenze di 2-3 unità sulla scala logit corrispondono a variazioni estreme nelle probabilità sottostanti (da circa 0.1 a 0.9).\n\n47.6.3.1 Importanza della scelta delle distribuzioni a priori\n\nCon predittori standardizzati (media 0, deviazione standard 1), una distribuzione a priori \\(\\beta \\sim \\mathcal{N}(0,1)\\) implica che effetti di moderata entità sono plausibili, mentre probabilità estreme (vicine a 0 o 1) rimangono poco probabili.\nAl contrario, una distribuzione a priori \\(\\beta \\sim \\mathcal{N}(0,2.5)\\) consente valori sulla scala logit fino a ±5, che corrispondono a probabilità praticamente certe (0 o 1). Questo approccio rischia di incorporare nel modello assunzioni di certezza assoluta prima ancora di osservare i dati.\n\nIl controllo predittivo basato sulle distribuzioni a priori (PPC) permette di verificare se le probabilità implicite generate dalle specifiche scelte parametriche sono coerenti con le aspettative del dominio applicativo.\n\n47.6.3.2 Simulazioni in R\n\nS &lt;- 10000\nx  &lt;- rnorm(S, 0, 1)  # standardizzare è buona pratica\n\n# Scenario E: prior larga\nalpha_E &lt;- rnorm(S, 0, 2.5)\nbeta_E  &lt;- rnorm(S, 0, 2.5)\npE      &lt;- plogis(alpha_E + beta_E * x)\nyE      &lt;- rbinom(S, 1, pE)\n\n# Scenario F: prior weakly-informative\nalpha_F &lt;- rnorm(S, 0, 1)\nbeta_F  &lt;- rnorm(S, 0, 1)\npF      &lt;- plogis(alpha_F + beta_F * x)\nyF      &lt;- rbinom(S, 1, pF)\n\ntibble(p = pE, scenario = \"E: prior larga\") |&gt;\n  bind_rows(tibble(p = pF, scenario = \"F: prior W.I.\")) |&gt;\n  ggplot(aes(x = p, fill = scenario)) +\n  geom_density(alpha = 0.35) +\n  labs(x = \"p(x) = P(y=1|x)\", y = \"Densità\")\n\n\n\n\n\n\n\nInterpretazione.\n\nCon distribuzioni a priori eccessivamente diffuse (Scenario E), le probabilità implicite sono frequentemente vicine ai valori estremi di 0 o 1. Ciò indica che il modello, in assenza di dati osservati, considera plausibili situazioni di quasi-certezza assoluta.\nCon distribuzioni a priori debolmente informative (Scenario F), le probabilità si distribuiscono in un range più realistico (0.05-0.95), riflettendo appropriatamente l’incertezza caratteristica dei fenomeni psicologici.\n\nLinee guida pratiche\n\nCon prior standardizzat, l’utilizzo di distribuzioni \\(\\mathcal{N}(0,1)\\) o \\(\\mathcal{N}(0,1.5)\\) per i coefficienti sulla scala logit rappresenta generalmente una scelta robusta: permette sufficiente variabilità senza generare previsioni probabilistiche estreme.\nDistribuzioni a priori eccessivamente diffuse possono produrre modelli “rigidi” che, a priori, assumono comportamenti quasi deterministici, risultando incoerenti con la variabilità tipica dei dati psicologici.\n\n47.6.3.3 Implementazione in Stan: simulazione esclusiva dalle distribuzioni precedenti\nPossiamo rendere esplicito il processo mediante un modello Stan che non incorpora dati osservati ma genera esclusivamente previsioni a partire dalle distribuzioni a priori.\n\nlogistic_prior_ppc_stan &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n}\nparameters {\n  real alpha;\n  real beta;\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta  ~ normal(0, 1);\n}\ngenerated quantities {\n  vector[N] p;\n  array[N] int y_rep;\n  for (i in 1:N) {\n    p[i] = inv_logit(alpha + beta * x[i]);\n    y_rep[i] = bernoulli_rng(p[i]);\n  }\n}\n'\nwriteLines(logistic_prior_ppc_stan, \"logistic_prior_ppc.stan\")\n\nEsecuzione del modello:\n\nmod_log &lt;- cmdstan_model(\"logistic_prior_ppc.stan\")\nx_new   &lt;- rnorm(300)\n\nfit_log &lt;- mod_log$sample(\n  data = list(N = length(x_new), x = x_new),\n  chains = 4, iter_warmup = 500, iter_sampling = 1000,\n  seed = 123, refresh = 0\n)\n\nVisualizzazione delle probabilità implicite:\n\npost_p &lt;- fit_log$draws(\"p\", format = \"draws_matrix\")\nas_tibble(post_p) |&gt;\n  pivot_longer(everything(), values_to = \"p\") |&gt;\n  ggplot(aes(x = p)) +\n  geom_density() +\n  labs(x = \"p(x)\", y = \"Densità\")\n\n\n\n\n\n\n\n\n47.6.3.4 Conclusioni\n\nLe distribuzioni a priori nella regressione logistica influenzano direttamente la distribuzione delle probabilità implicite generate dal modello.\nDistribuzioni a priori eccessivamente diffuse equivalgono ad assumere, prima di osservare i dati, che siano probabili risposte quasi certe (0 o 1).\nDistribuzioni a priori moderate preservano invece l’incertezza appropriata, riflettendo più fedelmente la realtà dei fenomeni psicologici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_prior_pred_check.html#linee-guida-pratiche-per-la-specificazione-delle-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/08_prior_pred_check.html#linee-guida-pratiche-per-la-specificazione-delle-distribuzioni-a-priori",
    "title": "47  Controllo predittivo a priori",
    "section": "\n47.7 Linee guida pratiche per la specificazione delle distribuzioni a priori",
    "text": "47.7 Linee guida pratiche per la specificazione delle distribuzioni a priori\n\n\nLavorare sulla scala appropriata\n\nQuando possibile, standardizzare i predittori (centrati a media 0 e scalati a deviazione standard 1).\nQuesto approccio garantisce un’interpretazione uniforme dei coefficienti: una distribuzione Normal(0,1) suggerisce che effetti “moderati” (variazioni di circa una deviazione standard nell’outcome per ogni deviazione standard nel predittore) siano i più plausibili.\n\n\n\nCoefficienti di regressione (\\(\\beta\\))\n\nUn punto di partenza solido consiste nell’utilizzare distribuzioni a priori Normal(0, 0.5–2).\nCon \\(\\beta \\sim \\mathcal{N}(0,1)\\): effetti di piccola e media entità sono considerati plausibili, mentre effetti di grande magnitudine rimangono possibili ma meno probabili.\nImportante: senza standardizzazione dei predittori, la scala di \\(\\beta\\) cambia radicalmente, invalidando queste linee guida.\n\n\n\nIntercetta (\\(\\alpha\\))\n\nPer outcome continui (modelli gaussiani), centrare la variabile dipendente \\(y\\) rende l’intercetta più direttamente interpretabile.\nPer outcome binari (modelli logistici), una Normal(0,1–1.5) implica probabilità a priori tipicamente comprese tra 0.05 e 0.95; una Normal(0,2.5) è significativamente più permissiva, rendendo probabili scenari di quasi-certezza.\n\n\n\nParametri di dispersione (\\(\\sigma\\))\n\nUtilizzare distribuzioni a priori definite solo per valori positivi (Half-Normal, Exponential, Gamma).\nSpecificare il parametro di scala dell’Exponential in accordo con l’ordine di grandezza atteso nel dominio applicativo. Ad esempio, per punteggi su scala 0-100, una Exponential(media ≈ 5–10) rappresenta una scelta generalmente ragionevole.\nVerificare sistematicamente mediante simulazioni che la dispersione generata sia coerente con la variabilità attesa nei dati reali.\n\n\n\nTrasformazioni non lineari (logit, log)\n\nEvitare di interpretare esclusivamente i coefficienti sulla scala trasformata: convertire sistematicamente nelle scale naturali di interesse.\nTradurre i coefficienti logit in probabilità implicite e i coefficienti log in tassi attesi.\nPorsi criticamente la domanda: “Queste distribuzioni a priori implicano che i soggetti abbiano probabilità estreme (vicine a 0 o 1) di manifestare il comportamento?”\n\n\n\nValidazione e trasparenza metodologica\n\nEseguire sempre controlli predittivi basati sulle distribuzioni a priori (prior predictive checks): se i dati simulati appaiono “irrealistici” (ad esempio, valori negativi per scale positive o fuori range), le distribuzioni a priori necessitano ri-calibrazione.\nDocumentare dettagliatamente il processo di specificazione: quali distribuzioni sono state testate, quali modifiche sono state apportate e le motivazioni sottostanti. Questa trasparenza costituisce un elemento fondamentale del rigore metodologico nell’analisi bayesiana.\n\n\n\n\n\n\n\n\n\nAppendice: prior predictive con brms per i tre casi\n\n\n\n\n\nModello gaussiano.\n\nN &lt;- 100\ndf_g &lt;- tibble(y = rnorm(N, 50, 10)) # placeholder, non usato con \"only\"\n\nfit_g_prior &lt;- brm(\n  bf(y ~ 1),\n  data = df_g,\n  family = gaussian(),\n  prior = c(\n    prior(normal(50, 10), class = \"Intercept\"),\n    prior(exponential(0.1), class = \"sigma\")        \n    # prior(exponential(1.0/10), class = \"sigma\")   \n  ),\n  sample_prior = \"only\",\n  chains = 4, iter = 1000, cores = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\nyrep_g &lt;- posterior_predict(fit_g_prior)\nppc_dens_overlay(y = df_g$y, yrep = yrep_g[1:200, ])\n\n\n\n\n\n\n\nRegressione lineare.\n\nN &lt;- 120\ndf_l &lt;- tibble(\n  y = rnorm(N),\n  x = rnorm(N)\n)\n\n\nfit_l_prior &lt;- brm(\n  bf(y ~ 1 + x),\n  data = df_l,\n  family = gaussian(),\n  prior = c(\n    prior(normal(0, 1), class = \"Intercept\"),\n    prior(normal(0, 1), class = \"b\", coef = \"x\"),\n    prior(exponential(0.5), class = \"sigma\")      # &lt;-- 0.5 (oppure 1.0/2)\n    # prior(exponential(1.0/2), class = \"sigma\")  # &lt;-- equivalente\n  ),\n  sample_prior = \"only\",\n  chains = 4, iter = 1000, cores = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\nyrep_l &lt;- posterior_predict(fit_l_prior)\nppc_dens_overlay(y = df_l$y, yrep = yrep_l[1:200, ]) +\n  xlim(-5, 5)\n\n\n\n\n\n\n\nRegressione logistica.\n\nN &lt;- 150\ndf_log &lt;- tibble(\n  y = rbinom(N, 1, 0.5),  # placeholder\n  x = rnorm(N)\n)\n\n\nfit_log_prior &lt;- brm(\n  bf(y ~ 1 + x),\n  data = df_log,\n  family = bernoulli(),\n  prior = c(\n    prior(normal(0, 1.5), class = \"Intercept\"),\n    prior(normal(0, 1), class = \"b\", coef = \"x\")\n  ),\n  sample_prior = \"only\",\n  chains = 4, iter = 1000, cores = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\nyrep_log &lt;- posterior_predict(fit_log_prior)\nppc_bars(y = df_log$y, yrep = yrep_log[1:200, ])",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_prior_pred_check.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/08_prior_pred_check.html#riflessioni-conclusive",
    "title": "47  Controllo predittivo a priori",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nI controlli predittivi sui priori rappresentano una delle innovazioni più importanti portate dall’approccio bayesiano alla pratica della ricerca psicologica. Non ci limitiamo più a dichiarare i priori come un’astrazione matematica, ma li trattiamo come ipotesi concrete che generano conseguenze osservabili.\nQuesto ha almeno tre implicazioni rilevanti:\n\n\nTrasparenza: invece di nascondere le nostre assunzioni, le rendiamo visibili e criticabili, mostrando quali dati ci aspetteremmo prima ancora di fare l’esperimento.\n\nCoerenza con la teoria psicologica: i priori possono e devono riflettere la letteratura, la teoria o l’esperienza accumulata. Se la simulazione produce risultati incompatibili con ciò che sappiamo, significa che stiamo imponendo assunzioni sbagliate.\n\nRobustezza inferenziale: controllare i priori prima di analizzare i dati riduce il rischio di ottenere posteriori fuorvianti o difficili da interpretare.\n\nDal punto di vista didattico, i prior predictive checks aiutano anche a chiarire agli studenti il significato dei priori: non sono semplici parametri arbitrari, ma veri e propri modelli di ciò che consideriamo plausibile prima di vedere i dati.\nIn sintesi, questo capitolo mostra che i priori non devono essere accettati acriticamente: vanno testati e, se necessario, rivisti. Nei prossimi capitoli vedremo come un approccio analogo possa essere applicato anche ai posteriori, estendendo l’idea dei controlli predittivi all’intero processo di modellazione.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [43] pkgbuild_1.4.8        plyr_1.8.9            lattice_0.22-7       \n#&gt; [46] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [49] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [52] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [55] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [58] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [61] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [64] data.table_1.17.8     mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [67] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [70] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [73] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [76] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [79] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [82] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_prior_pred_check.html#bibliografia",
    "href": "chapters/bayesian_inference/08_prior_pred_check.html#bibliografia",
    "title": "47  Controllo predittivo a priori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., Kennedy, L., Gabry, J., Bürkner, P.-C., & Modrák, M. (2020). Bayesian workflow. arXiv preprint arXiv:2011.01808.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_prior_pred_check.html#footnotes",
    "href": "chapters/bayesian_inference/08_prior_pred_check.html#footnotes",
    "title": "47  Controllo predittivo a priori",
    "section": "",
    "text": "Immagina di voler sapere che gusto avrà un succo se mescoli vari ingredienti. Non fai la media del gusto di singoli bicchieri, ma prendi un po’ di ogni succo (distribuzione) e li mescoli: il risultato è una nuova bevanda (la distribuzione predittiva a priori).↩︎",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_post_pred_distr.html",
    "href": "chapters/bayesian_inference/09_post_pred_distr.html",
    "title": "48  Distribuzione predittiva a posteriori",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto due aspetti fondamentali dell’inferenza bayesiana: da un lato, la costruzione delle distribuzioni a posteriori per i parametri di interesse; dall’altro, l’importanza di verificare i priori attraverso i controlli predittivi, per assicurarci che le nostre assunzioni iniziali siano coerenti con la realtà psicologica che vogliamo studiare.\nOra compiamo un passo ulteriore: invece di chiederci se i nostri priori siano ragionevoli, ci chiediamo se l’intero modello, dopo aver incorporato i dati osservati, sia in grado di generare previsioni plausibili. Questo ci porta al concetto di distribuzione predittiva a posteriori (posterior predictive distribution).\nLa logica è semplice e potente: se un modello è una rappresentazione credibile del processo che ha generato i dati, allora dovrebbe essere in grado non solo di adattarsi ai dati raccolti, ma anche di simulare dati nuovi con caratteristiche simili. In questo senso, le distribuzioni predittive a posteriori diventano uno strumento centrale per la valutazione dei modelli: collegano direttamente i parametri stimati ai dati futuri che ci aspettiamo di osservare.\nIn questo capitolo vedremo come costruire la distribuzione predittiva a posteriori, come interpretarla e come utilizzarla per verificare la coerenza del modello con l’evidenza empirica. Questo approccio ci permetterà di mettere alla prova in modo pratico la capacità del modello di spiegare e prevedere i fenomeni psicologici che ci interessano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_post_pred_distr.html#introduzione",
    "href": "chapters/bayesian_inference/09_post_pred_distr.html#introduzione",
    "title": "48  Distribuzione predittiva a posteriori",
    "section": "",
    "text": "Panoramica del capitolo\n\nPrevisione bayesiana: incorporare incertezza parametrica e variabilità intrinseca.\nVerifica di coerenza: valutare l’adeguatezza del modello ai dati osservati.\nCaso beta-binomiale: applicazione pratica del framework predittivo.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Posterior Inference & Prediction di Bayes Rules!.\nConsultare Bayesian statistics and modelling (Schoot et al., 2021).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_post_pred_distr.html#definizione-formale",
    "href": "chapters/bayesian_inference/09_post_pred_distr.html#definizione-formale",
    "title": "48  Distribuzione predittiva a posteriori",
    "section": "\n48.1 Definizione formale",
    "text": "48.1 Definizione formale\nSi considerino dati osservati \\(y = \\{y_1, y_2, \\ldots, y_n\\}\\), generati da un modello probabilistico parametrizzato da \\(\\theta\\), dove \\(\\theta\\) può rappresentare una probabilità, una media, un vettore di coefficienti o altri parametri di interesse. La conoscenza iniziale su \\(\\theta\\) è formalizzata attraverso una distribuzione a priori \\(p(\\theta)\\). L’osservazione dei dati consente di aggiornare questa conoscenza mediante il teorema di Bayes, ottenendo la distribuzione a posteriori:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta)\\, p(\\theta)}{p(y)},\n\\] dove:\n\n\\(p(\\theta \\mid y)\\) è la distribuzione a posteriori, che rappresenta l’incertezza su \\(\\theta\\) condizionata ai dati osservati;\n\\(p(y \\mid \\theta)\\) è la funzione di verosimiglianza, che specifica la probabilità dei dati dati i parametri;\n\\(p(\\theta)\\) è la distribuzione a priori;\n\n\\(p(y)\\) è l’evidenza marginale, calcolata come\n\\[\np(y) = \\int p(y \\mid \\theta) p(\\theta)\\, d\\theta.\n\\]\n\n\n\n48.1.1 La distribuzione predittiva a posteriori\nSia \\(\\tilde{y}\\) una nuova osservazione da prevedere. La distribuzione predittiva a posteriori \\(p(\\tilde{y} \\mid y)\\) fornisce la distribuzione probabilistica di \\(\\tilde{y}\\) condizionata ai dati osservati.\n\n48.1.1.1 Natura di \\(\\tilde{y}\\)\n\n\n\n\\(\\tilde{y}\\) rappresenta un dato futuro non ancora osservato;\nNell’esempio binomiale, se \\(y\\) è il numero di successi in \\(n\\) prove, \\(\\tilde{y}\\) può rappresentare il numero di successi in \\(n_{\\text{new}}\\) prove future.\n\n48.1.1.2 Relazione condizionale\n\n\n\\(p(\\tilde{y} \\mid \\theta)\\) esprime la probabilità di \\(\\tilde{y}\\) assumendo noto il parametro \\(\\theta\\);\nNel caso binomiale: \\(p(\\tilde{y} \\mid \\theta) = \\binom{n_{\\text{new}}}{\\tilde{y}} \\theta^{\\tilde{y}} (1-\\theta)^{n_{\\text{new}}-\\tilde{y}}\\).\n\n48.1.1.3 Integrazione sull’incertezza parametrica\nPoiché \\(\\theta\\) è incerto, la distribuzione predittiva a posteriori integra su tutti i possibili valori di \\(\\theta\\), pesati secondo la distribuzione a posteriori:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta.\n\\tag{48.1}\\]\n\n48.1.1.4 Interpretazione\nLa distribuzione predittiva a posteriori \\(p(\\tilde{y} \\mid y)\\) rappresenta la migliore previsione probabilistica per dati futuri, incorporando tanto l’incertezza sui parametri del modello quanto la variabilità intrinseca del processo generativo dei dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_post_pred_distr.html#il-modello-beta-binomiale",
    "href": "chapters/bayesian_inference/09_post_pred_distr.html#il-modello-beta-binomiale",
    "title": "48  Distribuzione predittiva a posteriori",
    "section": "\n48.2 Il modello Beta-Binomiale",
    "text": "48.2 Il modello Beta-Binomiale\nSi consideri un esperimento binomiale consistente in \\(n\\) prove indipendenti, dove si osserva il numero di successi \\(y\\) (ad esempio, il numero di teste nel lancio di una moneta). L’approccio bayesiano si articola in tre fasi fondamentali:\n\n\nSpecificazione della distribuzione a priori La conoscenza iniziale riguardante la probabilità di successo \\(p\\) viene formalizzata attraverso una distribuzione Beta(\\(\\alpha, \\beta\\)), particolarmente appropriata per parametri definiti sull’intervallo unitario:\n\nIl parametro \\(\\alpha\\) rappresenta un numero pseudo-osservato di successi;\nIl parametro \\(\\beta\\) rappresenta un numero pseudo-osservato di insuccessi.\n\nQuesta parametrizzazione consente di incorporare conoscenze pregresse in forma di “evidenza virtuale”.\n\n\nAggiornamento bayesiano alla distribuzione a posteriori Dopo l’osservazione di \\(y\\) successi in \\(n\\) prove, la distribuzione a posteriori si ottiene mediante aggiornamento coniugato:\n\\[\np \\mid y \\sim \\text{Beta}(\\alpha + y, \\beta + n - y).\n\\]\nQuesta distribuzione caratterizza completamente l’incertezza residua sul parametro \\(p\\) condizionatamente ai dati osservati.\n\n\nCostruzione della distribuzione predittiva a posteriori Per prevedere il numero di successi \\(y_{\\text{new}}\\) in \\(n_{\\text{new}}\\) prove future, si integra l’incertezza parametrica con la variabilità campionaria attraverso il seguente procedimento:\n\nCampionamento parametrico: \\(p^{(s)} \\sim \\text{Beta}(\\alpha + y, \\beta + n - y)\\)\n\nGenerazione predittiva: \\(y_{\\text{new}}^{(s)} \\sim \\text{Binomial}(n_{\\text{new}}, p^{(s)})\\)\n\n\nLa distribuzione empirica dei valori \\(y_{\\text{new}}^{(s)}\\) costituisce un’approssimazione Monte Carlo della distribuzione predittiva a posteriori, incorporando sia l’incertezza epistemica su \\(p\\) sia la variabilità aleatoria del processo binomiale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_post_pred_distr.html#un-esempio-numerico",
    "href": "chapters/bayesian_inference/09_post_pred_distr.html#un-esempio-numerico",
    "title": "48  Distribuzione predittiva a posteriori",
    "section": "\n48.3 Un esempio numerico",
    "text": "48.3 Un esempio numerico\n\n48.3.1 I dati e le nostre conoscenze iniziali\n\n\nDati osservati: 70 successi su 100 prove (ad esempio, 70 teste su 100 lanci di moneta)\n\nConoscenza iniziale (prior): usiamo una distribuzione Beta(2, 2). Questa prior è “debole” e suggerisce che pensiamo che la moneta sia probabilmente equilibrata (p ≈ 0.5), ma siamo aperti ad altre possibilità.\n\n48.3.2 Aggiornamento delle nostre conoscenze\nDopo aver visto i dati, aggiorniamo le nostre convinzioni sulla probabilità di successo p:\nalpha_posterior = 2 + 70 = 72\nbeta_posterior = 2 + (100 - 70) = 32\nOra crediamo che p segua una distribuzione Beta(72, 32), che è centrata attorno a 0.7.\n\n48.3.3 Simulazione delle previsioni\nVogliamo prevedere cosa succederà in 10 lanci futuri:\n\n# Dati osservati\nsuccessi_osservati &lt;- 70\nlanci_totali &lt;- 100\n\n# Prior (conoscenza iniziale)\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\n\n# Posterior (conoscenza aggiornata)\nalpha_post &lt;- alpha_prior + successi_osservati\nbeta_post &lt;- beta_prior + (lanci_totali - successi_osservati)\n\n# Simuliamo 1000 valori plausibili per p\nvalori_p &lt;- rbeta(1000, alpha_post, beta_post)\n\n# Per ogni valore di p, simuliamo 10 lanci futuri\nsuccessi_futuri &lt;- rbinom(1000, size = 10, prob = valori_p)\n\n# Calcoliamo le proporzioni di successo\nproporzioni_future &lt;- successi_futuri / 10\n\n\n48.3.4 Spiegazione passo per passo\nAbbiamo osservato 70 successi su 100 lanci. Con una prior Beta(2,2), la distribuzione a posteriori diventa Beta(72,32). Questo significa che non conosciamo il valore esatto della probabilità di successo \\(p\\), ma possiamo descrivere in modo plausibile l’incertezza che lo circonda: molto probabilmente \\(p\\) si trova vicino a 0.7, con una certa variabilità intorno a questo valore.\nPer rappresentare questa incertezza, estraiamo 1000 valori da una distribuzione Beta(72,32): valori_p &lt;- rbeta(1000, 72, 32). Ciascun valore estratto è un candidato possibile per \\(p\\), compatibile con i dati osservati e con la nostra conoscenza iniziale. A questo punto, ci chiediamo: cosa potremmo osservare nei prossimi lanci? Per rispondere, per ogni valore di \\(p\\) simuliamo 10 nuovi lanci, ottenendo così 1000 possibili scenari futuri: successi_futuri &lt;- rbinom(1000, size = 10, prob = valori_p).\nInfine, trasformiamo il numero di successi in proporzioni dividendo per 10, in modo da avere risultati immediatamente interpretabili come probabilità di successo nei lanci futuri: proporzioni_future &lt;- successi_futuri / 10. In altre parole, otteniamo un quadro di ciò che possiamo aspettarci, tenendo insieme due fonti di incertezza: da un lato non sappiamo il valore esatto di \\(p\\), dall’altro anche conoscendo \\(p\\) i risultati dei lanci rimarrebbero comunque soggetti al caso.\nIl vettore proporzioni_future riassume queste possibilità: non una singola previsione puntuale, ma un’intera distribuzione di esiti futuri, coerente con i dati raccolti e con il modello bayesiano adottato.\n\n48.3.5 Visualizziamo i risultati\nDistribuzione iniziale (prima di vedere i dati):\n\nggplot(data.frame(x = c(0, 1)), aes(x = x)) +\n  stat_function(fun = dbeta, \n                args = list(shape1 = alpha_prior, shape2 = beta_prior), \n                color = \"#4682B4\", size = 1) +\n  labs(x = \"Probabilità di successo (p)\",\n       y = \"Densità\")\n\n\n\n\n\n\n\nConoscenza aggiornata (dopo aver visto i dati):\n\nggplot(data.frame(x = c(0, 1)), aes(x = x)) +\n  stat_function(fun = dbeta, \n                args = list(shape1 = alpha_post, shape2 = beta_post), \n                color = \"#A0522D\", size = 1) +\n  labs(x = \"Probabilità di successo (p)\",\n       y = \"Densità\")\n\n\n\n\n\n\n\nPrevisioni per i prossimi 10 lanci:\n\nggplot(data.frame(proporzioni = proporzioni_future), aes(x = proporzioni)) +\n  geom_histogram(aes(y = ..density..), bins = 20) +\n  geom_vline(aes(xintercept = successi_osservati / lanci_totali), \n             color = \"black\", size = 1, linetype = \"dashed\") +\n  labs(x = \"Proporzione di successi attesi\",\n       y = \"Densità\")\n\n\n\n\n\n\n\n\n48.3.6 Interpretazione dei risultati\n\nLa nostra conoscenza su \\(p\\) è ora concentrata attorno a 0.7 (grafico in rosso).\nLe previsioni per 10 lanci futuri sono più variabili perché:\n\nSiamo ancora un po’ incerti sul valore esatto di \\(p\\).\nAnche se conoscessimo p perfettamente, 10 lanci potrebbero dare risultati leggermente diversi.\n\n\nIl risultato osservato (70% di successi) cade nella zona più probabile delle nostre previsioni: questo ci dice che il nostro modello è ragionevole e può essere usato per fare previsioni future.\n\nIn pratica: se dovessi scommettere sui prossimi 10 lanci, ti aspetteresti probabilmente 6-8 successi, ma potrebbero essercene anche 5 o 9 per puro caso.\n\n\n\n\n\n\nNota\n\n\n\n\n\nIl fatto che, nel nostro esempio, la distribuzione predittiva a posteriori riproduca efficacemente i dati osservati potrebbe apparire come un risultato scontato. In realtà, questo esito positivo è significativo e tutt’altro che banale; dimostra che il nostro modello semplice è ben calibrato. Abbiamo scelto deliberatamente un modello binomiale con prior Beta proprio per la sua chiarezza espositiva, che ci permette di illustrare in modo trasparente la logica sottostante alla distribuzione predittiva a posteriori e mostrare visivamente come l’incertezza sui parametri e la variabilità intrinseca dei dati si integrino in un unico framework.\nTuttavia, è fondamentale comprendere che nella ricerca psicologica reale ci si confronta con modelli notevolmente più complessi. In questi contesti, la corrispondenza tra i dati effettivamente osservati e quelli generati dal modello attraverso la distribuzione predittiva non può mai essere considerata una garanzia preliminare. Al contrario, questa corrispondenza rappresenta proprio l’obiettivo da verificare.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_post_pred_distr.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/09_post_pred_distr.html#riflessioni-conclusive",
    "title": "48  Distribuzione predittiva a posteriori",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLe distribuzioni predittive a posteriori rappresentano il naturale completamento del percorso iniziato con i priori. Se i prior predictive checks ci consentono di controllare la plausibilità delle nostre assunzioni iniziali, i posterior predictive checks ci permettono di verificare la plausibilità del modello alla luce dei dati.\nDal punto di vista concettuale, questo passaggio è cruciale: sposta l’attenzione dai parametri astratti ai dati concreti, e ci chiede di valutare i modelli sulla base della loro capacità di generare osservazioni simili a quelle reali. In questo senso, la distribuzione predittiva a posteriori non è soltanto un accessorio tecnico, ma una vera e propria prova di realtà per i modelli psicologici.\nDal punto di vista applicativo, questo approccio rafforza la trasparenza e la robustezza delle nostre inferenze. Non ci limitiamo più a riportare valori puntuali o intervalli credibili per i parametri: mostriamo esplicitamente quali dati il nostro modello ritiene plausibili e li confrontiamo con i dati effettivamente raccolti. Questo rende la comunicazione dei risultati più chiara e intuitiva, anche per chi non ha familiarità con la statistica bayesiana.\nIn sintesi, le distribuzioni predittive a posteriori ci ricordano che la forza dell’approccio bayesiano non risiede soltanto nella stima dei parametri, ma soprattutto nella capacità di prevedere e spiegare i fenomeni. Nei capitoli successivi vedremo come questa logica si estenda anche al confronto sistematico tra modelli, aprendo la strada a un approccio più rigoroso e cumulativo alla scienza psicologica.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nConsideriamo i dati della SWLS somministrata a un campione di studenti, ottenendo per ciascuno uno score complessivo. Per semplicità, vogliamo “dichiarare positivo” lo studente se il punteggio SWLS supera una determinata soglia (ad esempio, 20 su 35). In questo modo otteniamo una variabile dicotomica (0/1), che useremo come “successo” in un modello binomiale.\n\n\nDati e conteggio dei successi\n\nCarica il dataset con le risposte SWLS.\n\nCostruisci la variabile binaria (ad esempio SWLS_dich) che vale 1 se lo score ≥ 20, e 0 altrimenti.\n\nCalcola il numero di successi (numero di persone che superano la soglia) e il numero totale di osservazioni (N).\n\n\n\nModello beta-binomiale (approccio manuale via simulazione)\n\n\nSpecifica una distribuzione Beta(a, b) come prior per la probabilità di successo \\(p\\). Scegli una coppia \\((a, b)\\) relativamente poco informativa, ad esempio (2,2) o (1,1).\n\nOsservando \\(y\\) successi su \\(n\\) soggetti, aggiorna i parametri a posteriori: \\[\n  a_{\\text{post}} = a + y,\n  \\quad\n  b_{\\text{post}} = b + (n - y).\n\\]\n\nSimula un gran numero di campioni di \\(p\\) dalla distribuzione Beta\\(\\bigl(a_{\\text{post}},\\, b_{\\text{post}}\\bigr)\\).\n\nPer ciascun campione di \\(p\\), genera un valore \\(\\tilde{y}\\) da una Binomiale\\(\\bigl(n_{\\text{new}}, p\\bigr)\\), dove \\(n_{\\text{new}}\\) è la dimensione di un ipotetico nuovo campione (che puoi scegliere, ad esempio, uguale a \\(n\\) oppure un valore diverso). Otterrai così una posterior predictive distribution per \\(\\tilde{y}\\).\n\nInfine, calcola statistiche descrittive (media, varianza, intervalli) e/o disegna un istogramma di \\(\\tilde{y}\\) o della proporzione \\(\\tilde{y}/n_{\\text{new}}\\).\n\n\n\nReplicare con brms\n\n\nUsa il pacchetto brms per costruire un modello binomiale. Per esempio:\nlibrary(brms)\n\n# Crea un data frame con la variabile dicotomica\ndf_binom &lt;- data.frame(\n  successes = y,    # conteggio dei successi\n  failures  = n - y\n)\n\n# Modello binomiale con prior Beta(a,b) approssimato tramite logit\nfit_brms &lt;- brm(\n  bf(successes | trials(n) ~ 1), \n  data = df_binom,\n  family = binomial(link = \"logit\"),\n  prior = c(\n    prior(beta(2, 2), class = \"Intercept\", dpar = \"mu\") \n    # NOTA: la specifica di una \"beta(2,2)\" diretta sull'intercetta\n    # è un'approssimazione, tipicamente serve passare a una scala logit.\n    # In brms, di solito si usa prior su scale normali dell'intercetta.\n  ),\n  seed = 123\n)\n(Le specifiche del prior potrebbero richiedere una formulazione differente se vuoi rispettare esattamente la corrispondenza con Beta(a,b). In ogni caso, l’idea è mostrare come definire un prior e costruire un modello binomiale con brms.)\n\n\nVerifica la convergenza e poi estrai la posterior predictive distribution con le funzioni di brms:\npp_check(fit_brms, nsamples = 100)\nQuesto ti mostrerà come i dati predetti dal modello (in termini di binomiale) si confrontano con i dati osservati.\n\n\n\n\nConfronto e interpretazione\n\nMetti a confronto i risultati della simulazione “manuale” (Beta-Binomial) e quelli ottenuti con brms. Noterai che le distribuzioni predittive dovrebbero essere coerenti, se hai impostato un prior per brms simile a quello del modello Beta-Binomiale.\n\nDiscuti brevemente se la distribuzione predittiva a posteriori acquisita è plausibile rispetto ai dati osservati. Ad esempio, la probabilità di osservare \\(\\tilde{y}\\) simile a \\(y\\) dovrebbe essere relativamente alta se il modello è appropriato.\n\nSe vuoi, puoi cambiare \\(n_{\\text{new}}\\) (es. previsione su 200 soggetti futuri) per vedere come la variabilità della previsione si “ridimensiona” o cresce a seconda della taglia del campione.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nCostruzione del dataset\n\n\nSe la SWLS varia tra 5 e 35, e la soglia è 20, puoi fare:\ndf$SWLS_dich &lt;- ifelse(df$SWLS_score &gt;= 20, 1, 0)\ny &lt;- sum(df$SWLS_dich)\nn &lt;- nrow(df)\n\n\n\n\nApproccio Beta-Binomial manuale\n\nPrior: \\((a, b) = (2, 2)\\)\nPosterior: \\((a_{\\text{post}}, b_{\\text{post}}) = (2 + y,\\, 2 + n - y)\\).\n\nGenerazione dei campioni:\nN_sim &lt;- 2000\np_post &lt;- rbeta(N_sim, a_post, b_post)\ny_pred &lt;- rbinom(N_sim, size = n_new, prob = p_post)\n\n# Se preferisci la proporzione futura:\nprop_pred &lt;- y_pred / n_new\n\n\nStatistiche:\nmean_p &lt;- mean(p_post) # media a posteriori di p\nquantile_p &lt;- quantile(p_post, c(0.025, 0.975))  \n\nmean_prop_pred &lt;- mean(prop_pred)\nquantile_prop_pred &lt;- quantile(prop_pred, c(0.025, 0.975))\n\n\nGrafici (istogramma e densità):\nhist(prop_pred, freq=FALSE, col='lightblue',\n     main='Posterior Predictive Distribution: prop. di successi')\n\n\n\n\nModello con brms\n\nUsa la sintassi di una binomiale con offset o con trials(n).\n\nSpecifica un prior che approssimi Beta(2,2) sullo scale logit, ad esempio:\n# Beta(2,2) ha media ~ 0.5, varianza relativamente ampia.\n# Approssimandola su scala logit ~ normal(0, 2.2) \n# (valore indicativo: la normal(0, 2) su logit copre un intervallo ampio).\n\nprior_approx &lt;- prior(normal(0, 2), class = \"Intercept\")\n\nEsegui pp_check(fit_brms) e interpreta.\n\n\n\nInterpretazione\n\nSe la soglia scelta per la SWLS cattura un “buon livello di soddisfazione”, potresti aspettarti una certa % di successi.\n\nSe i dati futuri simulati sono coerenti con i dati reali — ad esempio, la media di \\(\\tilde{y}\\) è vicina a \\(y\\) — allora il modello sembra descrivere bene la realtà. Altrimenti, potresti rivedere la soglia o la specifica del prior.\n\n\n\nL’elemento chiave è che la distribuzione predittiva a posteriori (posterior predictive distribution) non si limita a considerare un solo valore di \\(p\\), bensì campiona molteplici valori plausibili (dalla posterior), e per ciascuno simula un potenziale outcome. Così facendo, si riflette pienamente l’incertezza residua sul parametro e l’aleatorietà del processo binomiale.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_post_pred_distr.html#bibliografia",
    "href": "chapters/bayesian_inference/09_post_pred_distr.html#bibliografia",
    "title": "48  Distribuzione predittiva a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSchoot, R. van de, Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., et al. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1), 1.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/introduction_mcmc.html",
    "href": "chapters/mcmc/introduction_mcmc.html",
    "title": "Introduzione",
    "section": "",
    "text": "Nei capitoli precedenti abbiamo visto come l’inferenza bayesiana possa essere condotta in casi semplici, sfruttando coppie coniugate di distribuzioni o metodi diretti come l’approssimazione su griglia. Questi strumenti ci hanno permesso di capire in modo intuitivo la logica dell’aggiornamento bayesiano, ma hanno anche mostrato i loro limiti: al crescere della complessità dei modelli, i calcoli analitici diventano rapidamente impraticabili e l’approccio su griglia soffre della cosiddetta maledizione della dimensionalità.\nPer affrontare problemi realistici, dobbiamo introdurre strumenti più potenti. È qui che entrano in gioco i metodi Monte Carlo a catena di Markov (MCMC). Queste procedure ci permettono di generare campioni dalla distribuzione a posteriori anche quando non possiamo descriverla con una formula chiusa, rendendo così l’inferenza bayesiana applicabile a modelli complessi e a più parametri.\nIn questa sezione esploreremo passo dopo passo le idee alla base degli algoritmi MCMC. Partiremo dal concetto di simulazione Monte Carlo e dall’algoritmo di Metropolis, per poi introdurre strumenti più avanzati che hanno rivoluzionato la pratica dell’inferenza bayesiana, come il linguaggio Stan. Lavoreremo su esempi concreti – dalla stima di una proporzione al confronto tra due gruppi, fino ai modelli di Poisson per dati di conteggio – per mostrare come i metodi MCMC rendano possibile un’analisi che sarebbe inaccessibile con gli strumenti analitici.\nInfine, discuteremo i modelli gerarchici bayesiani, che estendono ulteriormente le possibilità dell’inferenza permettendo di rappresentare strutture di dati multilivello, frequenti in psicologia e nelle scienze sociali. Questi modelli ci offriranno un primo sguardo a quella che diventerà una delle applicazioni più importanti dell’approccio bayesiano moderno.",
    "crumbs": [
      "MCMC",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html",
    "href": "chapters/mcmc/01_metropolis.html",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto che l’inferenza bayesiana può essere risolta esattamente in alcuni casi fortunati, grazie alle famiglie coniugate, oppure approssimata con metodi semplici come l’uso di una griglia di valori. Questi strumenti ci hanno permesso di comprendere a fondo la logica dell’aggiornamento bayesiano, ma hanno anche mostrato chiaramente i loro limiti: i casi coniugati sono eccezioni, e l’approccio su griglia diventa rapidamente impraticabile quando il numero di parametri cresce oltre uno o due. Per affrontare problemi realistici, che in psicologia riguardano quasi sempre modelli con più parametri e strutture complesse, dobbiamo introdurre un metodo generale che ci consenta di ottenere campioni dalla distribuzione a posteriori senza doverla calcolare in forma chiusa. Questo metodo esiste, ed è noto come algoritmo di Metropolis (Hastings, 1970; Metropolis et al., 1953).\nL’algoritmo di Metropolis rappresenta una svolta concettuale: offre una soluzione universale per generare campioni dalla distribuzione a posteriori, indipendentemente dalla forma della verosimiglianza e del prior. In questo senso, risolve in modo definitivo il problema di come rendere praticabile l’inferenza bayesiana. Tuttavia, presenta anche due limiti: è relativamente inefficiente dal punto di vista computazionale e richiede di scrivere codice su misura per ogni modello. Nonostante ciò, la sua logica è così generale e potente che costituisce la base di tutti gli algoritmi moderni di campionamento, incluso il metodo NUTS implementato in Stan.\nIn questo capitolo introdurremo passo dopo passo l’algoritmo di Metropolis, ne vedremo il funzionamento intuitivo e lo applicheremo a casi concreti. Questo ci permetterà di capire la logica alla base di gran parte dell’inferenza bayesiana moderna, che rimane immutata anche nei metodi più sofisticati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#introduzione",
    "href": "chapters/mcmc/01_metropolis.html#introduzione",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "",
    "text": "Panoramica del capitolo\n\nUtilizzare metodi Monte Carlo per stimare valori attesi e probabilità, evitando calcoli integrali complessi.\nComprendere il ruolo delle catene di Markov nel campionamento dalla distribuzione a posteriori.\nImplementare l’algoritmo di Metropolis per il campionamento a posteriori.\nValutare la convergenza delle catene con strumenti diagnostici come trace plot e autocorrelazione.\nGestire la fase di burn-in e utilizzare più catene per garantire stazionarietà e ridurre l’autocorrelazione.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere l’Appendice I.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, reshape2)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#lobiettivo-del-metodo-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#lobiettivo-del-metodo-mcmc",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "\n49.1 L’obiettivo del metodo MCMC",
    "text": "49.1 L’obiettivo del metodo MCMC\nIl metodo MCMC è un approccio computazionale che consente di approssimare distribuzioni di probabilità complesse, generando una sequenza di valori campionati che seguono la distribuzione a posteriori di interesse.\nL’idea di base è la seguente:\n\nconsideriamo la distribuzione a posteriori come una popolazione da cui desideriamo estrarre campioni;\ngenerando un numero sufficientemente grande di campioni (ad esempio, diverse migliaia), la distribuzione empirica dei campioni ottenuti si avvicina progressivamente alla distribuzione teorica a posteriori;\nin questo modo, possiamo stimare quantità di interesse, come la media, la varianza, o intervalli di credibilità, anche senza conoscere una forma analitica esplicita della distribuzione a posteriori.\n\n\n49.1.1 La natura dipendente del campionamento MCMC\nA differenza delle tecniche di campionamento indipendente precedentemente esaminate, l’approccio MCMC genera una sequenza di valori correlati attraverso un meccanismo di transizione markoviana. La caratteristica distintiva di questo processo risiede nella proprietà di Markov: ogni nuovo campione dipende esclusivamente dallo stato corrente della catena, mostrando memoria soltanto a breve termine piuttosto che dipendenza dall’intera storia precedente.\nQuesta architettura sequenziale produce inevitabilmente autocorrelazione tra osservazioni adiacenti. Quando la catena visita una regione ad alta densità della distribuzione target, tenderà a persistere in tale zona per diverse iterazioni prima di migrare verso altre regioni. Mentre tale comportamento è funzionale all’esplorazione efficiente dello spazio parametrico, introduce importanti considerazioni pratiche:\n\nl’informazione effettiva contenuta in \\(N\\) campioni correlati è inferiore a quella di \\(N\\) campioni indipendenti;\nla valutazione della convergenza richiede analisi diagnostiche specifiche;\nla dimensione efficace del campione (ESS) diventa un parametro cruciale per la qualità dell’inferenza.\n\nPer compensare questa riduzione di informazione per campione, è generalmente necessario generare sequenze più lunghe rispetto al campionamento indipendente. Tuttavia, questo svantaggio apparente è ampiamente compensato dalla capacità di MCMC di affrontare problemi complessi che risulterebbero intrattabili con metodi tradizionali.\n\n49.1.2 Perché utilizzare MCMC\nIl metodo MCMC è diventato uno strumento centrale nell’inferenza bayesiana contemporanea perché:\n\nè in grado di affrontare problemi complessi, caratterizzati da distribuzioni a posteriori di forma irregolare o definite in spazi ad alta dimensione;\nnon richiede il calcolo diretto dell’integrale di normalizzazione che compare nel teorema di Bayes;\npermette di ottenere approssimazioni accurate della distribuzione a posteriori tramite simulazione numerica.\n\nNel seguito ci concentreremo sull’algoritmo di Metropolis, uno dei metodi più semplici ed essenziali per implementare il campionamento MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#lalgoritmo-di-metropolis-introduzione-intuitiva",
    "href": "chapters/mcmc/01_metropolis.html#lalgoritmo-di-metropolis-introduzione-intuitiva",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "\n49.2 L’algoritmo di Metropolis: introduzione intuitiva",
    "text": "49.2 L’algoritmo di Metropolis: introduzione intuitiva\nL’algoritmo di Metropolis è un metodo MCMC che consente di esplorare una distribuzione di probabilità complessa costruendo una sequenza di campioni dipendenti tra loro.\nLa logica dell’algoritmo può essere riassunta nei seguenti passaggi fondamentali:\n\n\nPunto di partenza: si inizia da un valore iniziale \\(\\theta_0\\) scelto arbitrariamente.\n\nProposta di un nuovo punto: si genera un nuovo valore candidato \\(\\theta^*\\) partendo da \\(\\theta_0\\), utilizzando una distribuzione di proposta (ad esempio una distribuzione normale centrata su \\(\\theta_0\\)).\n\nValutazione della proposta: si confrontano le densità a posteriori associate al valore attuale \\(\\theta_0\\) e al valore proposto \\(\\theta^*\\).\n\nDecisione di accettazione:\n\nse \\(\\theta^*\\) ha una densità a posteriori più alta di \\(\\theta_0\\), viene accettato automaticamente;\nse \\(\\theta^*\\) ha una densità a posteriori inferiore, viene accettato con una certa probabilità proporzionale al rapporto delle densità.\n\n\n\nRegistrazione: in ogni caso, si registra la posizione attuale (sia che si sia accettato un nuovo punto, sia che si sia rimasti fermi).\n\nQuesto processo viene ripetuto per un numero elevato di iterazioni, generando una catena di campioni che, dopo un opportuno periodo iniziale (detto burn-in), approssima la distribuzione a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#perché-accettiamo-anche-mosse-peggiori",
    "href": "chapters/mcmc/01_metropolis.html#perché-accettiamo-anche-mosse-peggiori",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "\n49.3 Perché accettiamo anche mosse peggiori",
    "text": "49.3 Perché accettiamo anche mosse peggiori\nUno degli aspetti peculiari dell’algoritmo di Metropolis è la possibilità di accettare anche proposte peggiori, ossia punti \\(\\theta^*\\) associati a una densità a posteriori minore rispetto allo stato attuale.\nQuesta scelta ha una motivazione fondamentale:\n\nse accettassimo solo le mosse che migliorano la densità, l’algoritmo rischierebbe di bloccarsi in un massimo locale della distribuzione, senza esplorare altre aree che, pur avendo densità più bassa localmente, potrebbero condurre a regioni più interessanti globalmente;\naccettare occasionalmente mosse peggiori consente all’algoritmo di esplorare meglio tutto lo spazio dei parametri, evitando di rimanere intrappolato in una singola area.\n\nIn questo modo, la catena può attraversare regioni di bassa probabilità e raggiungere altre modalità della distribuzione, garantendo una copertura più completa dello spazio delle soluzioni plausibili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#la-scelta-della-larghezza-della-proposta",
    "href": "chapters/mcmc/01_metropolis.html#la-scelta-della-larghezza-della-proposta",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "\n49.4 La scelta della larghezza della proposta",
    "text": "49.4 La scelta della larghezza della proposta\nNell’algoritmo di Metropolis, la proposta di un nuovo valore \\(\\theta^*\\) viene solitamente generata a partire dallo stato corrente \\(\\theta_t\\) utilizzando una distribuzione di proposta simmetrica, ad esempio una distribuzione normale \\(\\mathcal{N}(\\theta_t, \\tau^2)\\), dove \\(\\tau\\) rappresenta la deviazione standard della proposta.\nLa scelta del valore di \\(\\tau\\) (ovvero della larghezza della proposta) è cruciale per il buon funzionamento dell’algoritmo:\n\nse \\(\\tau\\) è troppo piccolo, i passi proposti saranno molto vicini al punto attuale. In questo caso, molte proposte saranno accettate, ma la catena si muoverà lentamente nello spazio dei parametri, esplorandolo inefficientemente (alta correlazione tra i campioni);\nse \\(\\tau\\) è troppo grande, i passi proposti saranno molto lontani dal punto attuale. In questo caso, la maggior parte delle proposte cadrà in regioni di bassa densità, portando a un alto tasso di rifiuto delle proposte e quindi a una scarsa efficienza del campionamento.\n\nUn valore ottimale di \\(\\tau\\) deve bilanciare:\n\n\naccettazione sufficiente di nuove proposte;\n\nesplorazione efficiente dello spazio dei parametri.\n\nIn generale, si cerca di ottenere un tasso di accettazione compreso tra il 40% e il 50% per l’algoritmo di Metropolis a singolo parametro.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#limportanza-dei-grafici-diagnostici-trace-plot-e-correlogramma",
    "href": "chapters/mcmc/01_metropolis.html#limportanza-dei-grafici-diagnostici-trace-plot-e-correlogramma",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "\n49.5 L’importanza dei grafici diagnostici: Trace plot e Correlogramma",
    "text": "49.5 L’importanza dei grafici diagnostici: Trace plot e Correlogramma\nPer valutare la qualità della catena generata dall’algoritmo di Metropolis, è fondamentale analizzare alcuni grafici diagnostici.\n\n49.5.1 Trace plot\nIl trace plot rappresenta i valori campionati di \\(\\theta\\) in funzione del numero di iterazioni.\nUn trace plot di buona qualità mostra:\n\noscillazioni attorno a un valore centrale stabile (assenza di trend sistematici);\nuna copertura adeguata dello spazio plausibile per \\(\\theta\\).\n\nUn trace plot problematico può rivelare:\n\nfasi iniziali instabili (burn-in non sufficientemente lungo);\nmancata esplorazione completa della distribuzione;\nconvergenza solo apparente, con la catena bloccata in una modalità.\n\n49.5.2 Correlogramma\nIl correlogramma mostra il grado di autocorrelazione dei campioni in funzione del numero di passi di lag.\nIdealmente:\n\nl’autocorrelazione dovrebbe decrescere rapidamente all’aumentare del lag;\nuna catena ben mescolata presenta un correlogramma che si avvicina rapidamente a zero.\n\nUna forte autocorrelazione indica che i campioni successivi sono troppo simili tra loro, riducendo l’efficienza dell’inferenza statistica.\nQuesti concetti costituiscono il fondamento necessario per affrontare la comprensione operativa e pratica dell’algoritmo di Metropolis che svilupperemo nei prossimi esempi. A questo fine, il capitolo è strutturato in varie sezioni che facilitano la comprensione progressiva del tema.\n\nInizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o “a posteriori,” sia già conosciuta o disponibile per l’analisi.\nIn seguito, passeremo a illustrare come l’algoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non è direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un’approssimazione efficace della distribuzione a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#un-esempio-concreto",
    "href": "chapters/mcmc/01_metropolis.html#un-esempio-concreto",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "\n49.6 Un esempio concreto",
    "text": "49.6 Un esempio concreto\nA titolo esemplificativo, utilizzeremo il dataset moma_sample.csv, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista. Il nostro interesse è focalizzato sulla determinazione della probabilità che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilità sarà indicata come \\(\\pi\\).\nImportiamo i dati.\n\nmoma_sample &lt;- rio::import(here::here(\"data\", \"moma_sample.csv\"))\n\nEsaminiamo le prime cinque righe del DataFrame.\n\nmoma_sample |&gt; \n  head()\n#&gt;                artist  country birth death alive  genx gender count\n#&gt; 1        Ad Gerritsen    dutch  1940  2015 FALSE FALSE   male     1\n#&gt; 2 Kirstine Roepstorff   danish  1972    NA  TRUE  TRUE female     3\n#&gt; 3    Lisa Baumgardner american  1958  2015 FALSE FALSE female     2\n#&gt; 4         David Bates american  1952    NA  TRUE FALSE   male     1\n#&gt; 5          Simon Levy american  1946    NA  TRUE FALSE   male     1\n#&gt; 6      Pierre Mercure canadian  1927  1966 FALSE FALSE   male     8\n#&gt;   year_acquired_min year_acquired_max\n#&gt; 1              1981              1981\n#&gt; 2              2005              2005\n#&gt; 3              2016              2016\n#&gt; 4              2001              2001\n#&gt; 5              2012              2012\n#&gt; 6              2008              2008\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\n# Calcoliamo la distribuzione delle generazioni\nresult &lt;- table(moma_sample$genx)\nresult\n#&gt; \n#&gt; FALSE  TRUE \n#&gt;    86    14\n\nIl valore campionato \\(y = 14\\) riflette le caratteristiche del campione che è stato osservato. Tuttavia, poiché il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di \\(\\theta\\) (la probabilità di appartenere alla generazione X o a una generazione successiva) all’interno di questa popolazione.\nPossiamo interpretare i dati \\(y = 14\\) come l’esito di una variabile casuale Binomiale con parametri \\(N = 100\\) e \\(\\theta\\) sconosciuto.\nSupponiamo che le nostre credenze pregresse riguardo a \\(\\theta\\) possano essere modellate attraverso una distribuzione Beta(4, 6).\n\ntibble(x = seq(0, 1, .01),\n       y = dbeta(x, 4, 6)) |&gt;\n  ggplot(aes(x=x, y=y)) + \n  geom_line()\n\n\n\n\n\n\n\nSfruttando le proprietà delle distribuzioni coniugate, possiamo calcolare esattamente la distribuzione a posteriori:\n# Y ~ Binomiale(100, π)\n# θ ~ Beta(4, 6)\n# Posteriori: θ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) → Beta(18, 92)\nNella figura seguente, è rappresentata la distribuzione a posteriori del parametro \\(\\theta\\), insieme alla distribuzione a priori specificata.\n\n# Sequenza per θ\nx &lt;- seq(0, 1, length.out = 1000)\n\n# Densità prior e posterior\nprior_density &lt;- dbeta(x, 4, 6)\nposterior_density &lt;- dbeta(x, 18, 92)\n\n# Dati per il grafico\ndf_long &lt;- tibble(\n  x = x,\n  `Prior: Beta(4, 6)` = prior_density,\n  `Posterior: Beta(18, 92)` = posterior_density\n) %&gt;%\n  pivot_longer(\n    cols = -x,\n    names_to = \"distribuzione\",\n    values_to = \"densita\"\n  ) %&gt;%\n  mutate(\n    distribuzione = factor(\n      distribuzione,\n      levels = c(\"Prior: Beta(4, 6)\", \"Posterior: Beta(18, 92)\")\n    )\n  )\n\n# Palette di colori alternativa\ncolori_custom &lt;- c(\n  \"Prior: Beta(4, 6)\" = \"#1F77B4\",       # Blu\n  \"Posterior: Beta(18, 92)\" = \"#FF7F0E\"  # Arancione\n)\n\n# Creazione del grafico\nggplot(df_long, aes(x = x, y = densita)) +\n  geom_area(\n    aes(fill = distribuzione),\n    alpha = 0.30,\n    position = \"identity\",\n    color = NA\n  ) +\n  geom_line(\n    aes(color = distribuzione),\n    linewidth = 1.1\n  ) +\n  scale_fill_manual(\n    name = \"Distribuzione\",\n    values = colori_custom\n  ) +\n  scale_color_manual(\n    name = \"Distribuzione\",\n    values = colori_custom\n  ) +\n  guides(\n    fill = guide_legend(override.aes = list(color = NA, alpha = 0.30)),\n    color = guide_legend(override.aes = list(fill = NA, linewidth = 1.1))\n  ) +\n  labs(\n    x = expression(theta),\n    y = \"Densità\"\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    legend.box = \"horizontal\",\n    legend.title = element_text(face = \"bold\"),\n    axis.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\nIn questo grafico, la curva blu rappresenta la distribuzione a priori \\(\\text{Beta}(4, 6)\\), mentre la curva rossa mostra la distribuzione a posteriori \\(\\text{Beta}(18, 92)\\). La sovrapposizione delle aree evidenzia come l’evidenza fornita dai dati modifichi la conoscenza iniziale sul parametro \\(\\theta\\).\nSe vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto è\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n\\]\n\n49.6.1 Simulazione con distribuzione target nota\nUsiamo ora una simulazione numerica per stimare la media a posteriori di \\(\\theta\\). Conoscendo la forma della distribuzione a posteriori \\(Beta(18, 92)\\), possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un’approssimazione della media a posteriori.\nSe vogliamo ottenere un risultato approssimato con un numero limitato di campioni (ad esempio, 10), possiamo utilizzare la seguente simulazione:\n\n# Generiamo 10 campioni dalla distribuzione Beta(18, 92)\nset.seed(1234)  # Per riproducibilità\ny &lt;- rbeta(10, shape1 = 18, shape2 = 92)\ny\n#&gt;  [1] 0.1183 0.1751 0.2147 0.0769 0.1817 0.1852 0.1416 0.1426 0.1419 0.1299\n\n\n# Calcoliamo la media dei campioni\nmean(y)\n#&gt; [1] 0.151\n\nTuttavia, con soli 10 campioni, l’approssimazione potrebbe non essere molto accurata. Aumentando il numero di campioni, ad esempio a 10,000, possiamo ottenere una stima molto più precisa:\n\n# Generiamo 10000 campioni e calcoliamo la media\nset.seed(123)  # Per riproducibilità\nmean(rbeta(10000, shape1 = 18, shape2 = 92))\n#&gt; [1] 0.164\n\nQuando il numero di campioni dalla distribuzione a posteriori diventa molto grande, la media campionaria converge al valore atteso della distribuzione della popolazione. Questo principio non si applica solo alla media, ma anche ad altre statistiche descrittive come la moda e la varianza.\nÈ importante sottolineare che l’applicazione della simulazione di Monte Carlo è efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni R per estrarre campioni casuali da tale distribuzione. Ciò è stato possibile nel caso della distribuzione a posteriori \\(Beta(18, 92)\\). Tuttavia, questa situazione ideale non si verifica sempre nella pratica, poiché le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l’espressione\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}\n\\]\nrende impossibile calcolare analiticamente la distribuzione a posteriori di \\(\\theta\\), precludendo quindi l’utilizzo diretto di R per generare campioni casuali.\nIn queste circostanze, però, è possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l’uso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l’algoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori senza richiedere la conoscenza della sua rappresentazione analitica. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.\n\n49.6.2 Algoritmo di Metropolis\nL’algoritmo di Metropolis appartiene alla famiglia dei metodi Monte Carlo basati su catene di Markov (MCMC), sfruttando le proprietà di queste catene per generare campioni da una distribuzione target. Il suo obiettivo principale è di esplorare lo spazio dei parametri in modo efficiente, producendo campioni che approssimano la distribuzione a posteriori di interesse.\n\n49.6.3 Principio di funzionamento\nL’algoritmo inizia da un valore iniziale per i parametri e, in ogni iterazione, genera un nuovo campione tramite una distribuzione di proposta (solitamente una distribuzione normale centrata sul valore corrente). Successivamente, decide se accettare il nuovo campione in base al confronto tra le densità posteriori del nuovo campione e di quello precedente. Questa accettazione avviene in modo probabilistico, favorendo campioni con una densità più alta ma consentendo anche l’accettazione di campioni peggiori per evitare che la catena rimanga bloccata in minimi locali.\n\n49.6.4 Burn-in e convergenza\nPoiché i primi campioni potrebbero non rappresentare bene la distribuzione target, si esclude spesso una porzione iniziale della catena (fase di burn-in). Con il progredire delle iterazioni, i campioni si distribuiscono in accordo con la distribuzione stazionaria desiderata, indipendentemente dallo stato iniziale scelto. Questo processo permette di esplorare lo spazio dei parametri in modo efficiente.\n\n49.6.5 Meccanismo di accettazione e rifiuto\nL’algoritmo di Metropolis bilancia due esigenze opposte:\n\n\nesplorazione di nuove aree dello spazio dei parametri;\n\nsfruttamento delle informazioni già acquisite dai campioni precedenti.\n\nUtilizzando una regola probabilistica per accettare campioni peggiori (con minore densità a posteriori), l’algoritmo evita di restare intrappolato in minimi locali, esplorando così in modo più completo l’intera distribuzione.\n\n49.6.6 Passaggi fondamentali dell’algoritmo di Metropolis\n\n\nScelta di uno stato iniziale \\(\\theta_1\\) e impostazione del contatore \\(t = 1\\).\n\nQuesto è il punto di partenza della catena, dove \\(\\theta_1\\) rappresenta il primo campione.\n\n\n\nProposta di un nuovo campione \\(\\theta_p\\).\n\nUn nuovo valore \\(\\theta_p\\) viene generato da una distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\), solitamente una distribuzione normale centrata sul campione corrente \\(\\theta_t\\) con una deviazione standard \\(\\tau\\) che controlla l’ampiezza dei passi.\n\n\n\nVerifica dei vincoli del campione proposto.\n\nSe il nuovo campione deve rispettare dei vincoli (ad esempio, essere compreso tra 0 e 1 per probabilità), campioni non validi vengono automaticamente rifiutati.\n\n\n\nCalcolo del rapporto di accettazione \\(\\alpha\\).\n\nSi calcola \\(\\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)}\\), che rappresenta il rapporto tra le densità a posteriori del nuovo campione \\(\\theta_p\\) e del campione corrente \\(\\theta_t\\). Questo valore guida la decisione di accettazione.\n\n\n\nDecisione di accettazione.\n\nSe \\(\\alpha \\geq 1\\), il nuovo campione \\(\\theta_p\\) viene accettato incondizionatamente.\nSe \\(\\alpha &lt; 1\\), il campione \\(\\theta_p\\) viene accettato con probabilità \\(\\alpha\\). In caso di rifiuto, si mantiene il campione corrente \\(\\theta_t\\) per la prossima iterazione.\n\n\n\nRipetizione del processo.\n\nSi ripetono i passaggi dal 2 al 5 fino a ottenere il numero desiderato di campioni.\n\n\n\n49.6.7 Dettagli aggiuntivi\n\n\nDistribuzione di proposta: La distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\) genera nuovi campioni attorno a \\(\\theta_t\\). Tipicamente si usa una normale \\(N(\\theta_t, \\tau)\\), dove \\(\\tau\\) controlla quanto il nuovo campione si discosta da quello corrente. Scegliere un \\(\\tau\\) troppo piccolo può rendere l’esplorazione lenta, mentre un \\(\\tau\\) troppo grande può far rifiutare troppi campioni, riducendo l’efficienza.\n\nRapporto di accettazione \\(\\alpha\\): Se il nuovo campione ha una densità a posteriori maggiore del campione corrente, viene sempre accettato. Se ha una densità inferiore, viene accettato con probabilità \\(\\alpha\\), il che consente di esplorare anche regioni meno probabili della distribuzione.\n\nAccettazione probabilistica: Accettare campioni peggiori occasionalmente aiuta l’algoritmo a evitare di bloccarsi in minimi locali. Questo è uno dei punti di forza dell’algoritmo di Metropolis, che garantisce una buona esplorazione dello spazio dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "href": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "\n49.7 Esempio di implementazione",
    "text": "49.7 Esempio di implementazione\nSupponiamo di voler stimare la probabilità \\(\\theta\\) che un artista della Generazione X sia esposto al MoMA. Disponiamo di 14 successi (presenze) osservati su un campione di 100 artisti. Adottiamo un modello binomiale con distribuzione a priori Beta(4, 6) per \\(\\theta\\), integrando dati osservati e conoscenza a priori mediante l’algoritmo MCMC. Seguiremo l’impostazione metodologica proposta da Elizaveta Semenova, implementando l’algoritmo di Metropolis-Hastings in R. Cominciamo definendo alcune funzioni fondamentali.\n\n49.7.1 Definizione della distribuzione a priori\nLa funzione prior calcola la densità della distribuzione Beta(4, 6) per un dato \\(\\theta\\):\n\n# Distribuzione a priori Beta(4, 6)\nprior &lt;- function(p) {\n  dbeta(p, shape1 = 4, shape2 = 6)\n}\n\nQuesta distribuzione esprime la nostra plausibilità iniziale sui valori di \\(\\theta\\) prima di osservare i dati.\n\n49.7.2 Funzione di verosimiglianza\nLa funzione likelihood modella la probabilità di osservare 14 successi su 100 prove:\n\n# Verosimiglianza binomiale (y = 14 successi su n = 100 prove)\nlikelihood &lt;- function(p) {\n  y &lt;- 14\n  n &lt;- 100\n  dbinom(y, size = n, prob = p)\n}\n\n\n49.7.3 Distribuzione a posteriori non normalizzata\nLa posteriori si ottiene combinando priori e verosimiglianza:\n\n# Posteriori non normalizzata (prodotto tra verosimiglianza e priori)\nposterior &lt;- function(p) {\n  likelihood(p) * prior(p)\n}\n\n\n49.7.4 Distribuzione proposta\nLa distribuzione proposta sarà una distribuzione normale centrata sullo stato corrente con una deviazione standard specificata:\n\n# Generazione proposta (normale con media sullo stato corrente)\nproposal_distribution &lt;- function(current_state, proposal_sigma) {\n  rnorm(1, mean = current_state, sd = proposal_sigma)\n}\n\n\n49.7.5 Implementazione dell’algoritmo Metropolis-Hastings\nProcediamo ora con l’implementazione dell’algoritmo di Metropolis-Hastings, considerando i dati relativi agli artisti della Generazione X presenti al MoMA. La distribuzione a priori per \\(\\theta\\) è modellata come una Beta(4, 6).\n\n# Algoritmo Metropolis-Hastings\nmetropolis_hastings &lt;- function(n_samples, start, proposal_sigma) {\n  samples &lt;- numeric(n_samples)\n  current &lt;- start  # Stato iniziale\n\n  for (i in seq_len(n_samples)) {\n    proposal &lt;- proposal_distribution(current, proposal_sigma)\n    \n    # Verifica validità e calcolo rapporto di accettazione\n    if (proposal &gt;= 0 && proposal &lt;= 1) {\n      acceptance_ratio &lt;- min(1, posterior(proposal) / posterior(current))\n      # Accetta/rifiuta con probabilità acceptance_ratio\n      if (runif(1) &lt; acceptance_ratio) {\n        current &lt;- proposal\n      }\n    }\n    samples[i] &lt;- current  # Aggiorna la catena\n  }\n  return(samples)\n}\n\n\n\n\n\n\n\nInterpretazione intuitiva\n\n\n\n\n\nImmaginate di esplorare un paesaggio montuoso (la posteriori) avvolto dalla nebbia, dove le alture rappresentano regioni ad alta densità di probabilità. L’algoritmo replica il comportamento di un escursionista che:\n\n\nValuta la posizione corrente (current) tramite l’altezza locale (posterior(current)).\n\nPropone un passo casuale in una direzione vicina (proposal), determinata da una distribuzione normale.\n\nDecide il movimento confrontando le altezze relative:\n\nSe il nuovo punto è più alto (\\(R \\geq 1\\)), lo accetta immediatamente.\nSe è più basso (\\(R &lt; 1\\)), lo accetta con probabilità \\(R\\), simulando un’accettazione stocastica per evitare massimi locali.\n\n\n\nRegistra ogni posizione visitata, costruendo gradualmente una mappa proporzionale alla vera distribuzione.\n\n\n\n\n\n\n\n\n\n\nDettagli dell’implementazione (1)\n\n\n\n\n\nNel codice la “regola &gt; 1 → accetta” è incorporata in queste due istruzioni consecutive:\nacceptance_ratio &lt;- min(1, posterior(proposal) / posterior(current))\n...\nif (runif(1) &lt; acceptance_ratio) {\n    current &lt;- proposal\n}\n\n\nClipping a 1 con min(1, …)\n\nSe il rapporto \\(\\frac{\\text{posterior(proposal)}}{\\text{posterior(current)}}\\) è maggiore di 1 (cioè il nuovo punto ha densità a‐posteriori più alta), min() lo tronca a 1.\n\nQuindi acceptance_ratio vale esattamente 1 in tutti i casi in cui il “vero” rapporto sarebbe &gt; 1.\n\n\n\nAccettazione certa con il confronto runif(1) &lt; 1\n\n\nrunif(1) genera un numero uniforme in \\([0,1)\\); qualunque valore estratto sarà sempre &lt; 1.\n\nDi conseguenza, quando acceptance_ratio è 1 l’if è sempre vero e il punto proposto viene accettato con probabilità 1, esattamente come prescrive l’algoritmo di Metropolis (o di Metropolis-Hastings nel caso simmetrico).\n\n\n\nIn sintesi, la riga con min(1, …) traduce la regola teorica “accetta se il rapporto è &gt; 1” in una forma pratica che si integra con il test probabilistico successivo.\n\n\n\n\n\n\n\n\n\nDettagli dell’implementazione (2)\n\n\n\n\n\nProprietà della proposta simmetrica: L’algoritmo di Metropolis (quello base come questo) funziona bene se la maniera in cui proponi di “spostarti” da un punto A a un punto B è esattamente la stessa della maniera in cui proporresti di spostarti da B ad A. Pensa a una proposta “neutra” rispetto alla direzione. Questa “simmetria” nella proposta è utile perché ci permette di decidere se accettare un passo basandoci esclusivamente sul confronto della ‘probabilità’ (la densità) dei due punti (proposto e attuale) sotto la distribuzione che vogliamo esplorare. In pratica, non dobbiamo preoccuparci di ‘correggere’ il rapporto di accettazione per tenere conto di proposte che potrebbero essere più facili in una direzione che nell’altra. Questa semplicità aiuta l’algoritmo a trovare il giusto bilanciamento negli spostamenti, permettendogli di campionare correttamente dalla distribuzione desiderata nel lungo periodo.\n\n\n\n\n49.7.6 Esecuzione dell’algoritmo\n\n# Parametri dell'algoritmo\nn_samples &lt;- 10000\nstart &lt;- 0.5\nproposal_sigma &lt;- 0.1\n\n# Esecuzione del campionamento\nset.seed(123)  # Per riproducibilità\nsamples &lt;- metropolis_hastings(n_samples, start, proposal_sigma)\n\n\n49.7.7 Analisi dei risultati\nScartiamo i primi 5000 campioni per considerare solo quelli generati dopo il burn-in:\n\nburnin &lt;- floor(n_samples * 0.5)\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\nCalcoliamo la media e la deviazione standard dei campioni:\n\n# Media a posteriori\nmean(post_burnin_samples)\n#&gt; [1] 0.163\n\n# Deviazione standard a posteriori\nsd(post_burnin_samples)\n#&gt; [1] 0.0354\n\nVisualizziamo l’evoluzione della catena per i primi 200 campioni e per quelli post-burn-in:\n\ntibble(\n  Iterazione = 1:200,\n  Theta = samples[1:200]\n) |&gt; \n  ggplot(aes(x = Iterazione, y = Theta)) +\n    geom_line() + # Specifica che vuoi un grafico a linea\n    xlab(\"Iterazioni\") + # Etichetta l'asse X\n    ylab(expression(theta)) # Etichetta l'asse Y usando l'espressione per theta\n\n\n\n\n\n\n\n\ntibble(\n  Iterazione = 1:length(post_burnin_samples), \n  Theta = post_burnin_samples\n) |&gt; \n  ggplot(aes(x = Iterazione, y = Theta)) +\n    geom_line() + # Specifica un grafico a linea\n    xlab(\"Iterazioni\") + # Indice all'interno della serie post-burn-in\n    ylab(expression(theta)) # Etichetta l'asse Y\n\n\n\n\n\n\n\nSovrapponiamo la distribuzione analitica \\(\\text{Beta}(18, 92)\\) all’istogramma dei campioni post-burn-in:\n\n# Palette di colori alternativa\ncolori_custom &lt;- c(\n  \"Istogramma\" = \"#1F77B4\",      # Blu\n  \"Beta(18,92)\" = \"#FF7F0E\"      # Arancione\n)\n\np &lt;- tibble(Theta = post_burnin_samples) |&gt;\n  ggplot(aes(x = Theta)) +\n  geom_histogram(\n    aes(y = after_stat(density), fill = \"Istogramma\"),\n    bins = 30, color = \"black\", alpha = 0.7, show.legend = TRUE\n  ) +\n  stat_function(\n    aes(color = \"Beta(18,92)\"),\n    fun = dbeta, args = list(shape1 = 18, shape2 = 92), linewidth = 1.2,\n    show.legend = TRUE\n  ) +\n  labs(\n    x = expression(theta), y = \"Densità\"\n  ) +\n  scale_fill_manual(\n    name = \"Distribuzione\",\n    values = colori_custom,\n    breaks = names(colori_custom)\n  ) +\n  scale_color_manual(\n    name = \"Distribuzione\",\n    values = colori_custom,\n    breaks = names(colori_custom)\n  ) +\n  guides(\n    fill = guide_legend(override.aes = list(color = NA)),\n    color = guide_legend(override.aes = list(fill = NA))\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(face = \"bold\"),\n    axis.title = element_text(face = \"bold\")\n  )\n\np\n\n\n\n\n\n\n\nCalcoliamo l’intervallo di credibilità al 94%:\n\nquantile(post_burnin_samples, probs = c(0.03, 0.97))\n#&gt;    3%   97% \n#&gt; 0.102 0.235\n\nI valori ottenuti con l’algoritmo di Metropolis (usando solo un piccolo numero di iterazioni) sono quasi identici ai valori esatti:\n\nqbeta(c(0.03, 0.97), 18, 92)\n#&gt; [1] 0.103 0.235\n\nQuesta implementazione in R dimostra come utilizzare l’algoritmo di Metropolis per stimare una distribuzione a posteriori e analizzare i risultati in modo dettagliato e riproducibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "href": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "\n49.8 Catene di Markov e convergenza",
    "text": "49.8 Catene di Markov e convergenza\nNell’ambito delle simulazioni Monte Carlo, una catena rappresenta una sequenza di valori campionati dall’algoritmo durante le sue iterazioni. Ogni valore nella catena corrisponde a un possibile stato del sistema che stiamo modellando. In altre parole, una catena traccia il percorso che l’algoritmo segue nello spazio dei parametri, esplorando le diverse configurazioni possibili.\nPer verificare se l’algoritmo ha raggiunto la convergenza e se i campioni generati rappresentano effettivamente la distribuzione di interesse, è utile eseguire multiple catene. Ogni catena parte da un punto iniziale diverso nello spazio dei parametri.\nI vantaggi delle multiple catene:\n\n\nDiagnostica della convergenza: Confrontando le diverse catene, possiamo valutare se si stabilizzano verso la stessa distribuzione. Se le catene si mescolano bene, ovvero si intersecano frequentemente nel grafico dei valori campionati (trace plot), è un forte indicatore di convergenza.\n\nRobustezza: L’utilizzo di multiple catene rende l’analisi meno sensibile alla scelta del punto di partenza. Se una singola catena potesse rimanere “intrappolata” in una regione dello spazio dei parametri, multiple catene aumentano la probabilità di esplorare lo spazio in modo più completo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "\n49.9 Diagnostiche della soluzione MCMC",
    "text": "49.9 Diagnostiche della soluzione MCMC\n\n49.9.1 Stazionarietà e convergenza\nUn aspetto cruciale nell’analisi delle catene di Markov MCMC è la convergenza alla distribuzione stazionaria. Intuitivamente, la catena converge quando i campioni generati rappresentano fedelmente la distribuzione di interesse, indipendentemente dal punto di partenza. Questo fenomeno è spesso indicato come “mixing”.\n\n49.9.1.1 Valutazione visiva: Trace Plots e grafici di densità\n\n\nTrace Plots: Questi grafici visualizzano l’evoluzione dei parametri nel tempo. Una catena convergente mostra tracce stabili e senza trend evidenti. Tracce irregolari o con andamenti sistematici suggeriscono problemi di convergenza.\n\nGrafici di Densità: Confrontando i grafici di densità dei campioni con la distribuzione teorica, è possibile valutare visivamente se la catena sta esplorando adeguatamente lo spazio dei parametri. Una buona convergenza si manifesta con una sovrapposizione tra i due grafici.\n\nSegni di Convergenza:\n\n\nStabilità: I valori campionati oscillano attorno a un valore medio costante, senza trend marcati.\n\nOmogeneità: La variabilità dei campioni rimane relativamente uniforme nel tempo.\n\nAssenza di Periodicità: Non si osservano pattern ciclici o ripetitivi.\n\nIn sintesi, i trace plots e i grafici di densità offrono strumenti visivi rapidi per valutare la convergenza di una catena di Markov MCMC. Una convergenza soddisfacente è fondamentale per garantire la validità delle inferenze statistiche basate sui campioni generati.\n\n49.9.2 Autocorrelazione nelle catene di Markov\nA differenza dei generatori di numeri casuali indipendenti, gli algoritmi MCMC producono una sequenza di campioni correlati. Ogni valore campionato dipende da quello precedente, formando una catena di Markov. Questa interdipendenza è un aspetto fondamentale dell’MCMC.\nL’autocorrelazione quantifica il grado di dipendenza tra valori distanti di una certa quantità (detta lag) nella catena. Un’alta autocorrelazione a lag bassi indica una forte dipendenza tra campioni successivi. Al contrario, una rapida diminuzione dell’autocorrelazione al crescere del lag suggerisce che la catena “miscela” bene, ovvero esplora lo spazio dei parametri in modo efficiente.\n\n\nLag 1: Misura la correlazione tra valori consecutivi nella catena.\n\nLag 2: Misura la correlazione tra valori separati da un passo intermedio.\n\nLag k: Generalizza il concetto ai valori separati da k passi.\n\nUn correlogramma è un grafico che mostra l’autocorrelazione in funzione del lag. Un decadimento rapido dell’autocorrelazione verso zero indica una buona convergenza della catena.\nL’autocorrelazione di ordine \\(k\\) è data da \\(\\rho_k\\) e può essere stimata come:\n\\[\n\\begin{aligned}\n\\rho_k &= \\frac{Cov(\\theta_m, \\theta_{m+k})}{Var(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{aligned}\n\\tag{49.1}\\]\n\n49.9.3 Esempio di simulazione di dati autocorrelati\nPer fare un esempio pratico, creiamo un vettore di dati autocorrelati:\n\n# Creiamo un vettore di dati\nx &lt;- c(22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51)\nx\n#&gt;  [1] 22 24 25 25 28 29 34 37 40 44 51 48 47 50 51\n\n\n49.9.3.1 Calcolo dell’autocorrelazione\nL’autocorrelazione di ordine 1 è la correlazione tra ciascun elemento e il successivo nella sequenza. In R possiamo utilizzare la funzione acf() per calcolare l’autocorrelazione.\n\n# Calcolo dell'autocorrelazione\nacf_values &lt;- acf(x, plot = FALSE)\nacf_values\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;      0      1      2      3      4      5      6      7      8      9     10 \n#&gt;  1.000  0.832  0.656  0.491  0.279  0.031 -0.165 -0.304 -0.401 -0.458 -0.450 \n#&gt;     11 \n#&gt; -0.369\n\nNell’esempio, il vettore x rappresenta una serie temporale di 15 elementi. Il calcolo dell’autocorrelazione restituisce i seguenti valori per i primi ritardi (lag):\n\n0.8317: autocorrelazione di ordine 1 (lag = 1),\n0.6563: autocorrelazione di ordine 2 (lag = 2),\n0.4910: autocorrelazione di ordine 3 (lag = 3),\necc.\n\n49.9.3.2 Specifica del numero di ritardi (Lag)\nPossiamo limitare il numero di ritardi calcolati utilizzando l’argomento lag.max nella funzione acf():\n\n# Calcolo dell'autocorrelazione per i primi 4 lag\nacf(x, lag.max = 4, plot = FALSE)\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;     0     1     2     3     4 \n#&gt; 1.000 0.832 0.656 0.491 0.279\n\n\n49.9.3.3 Grafico della funzione di autocorrelazione (correlogramma)\nIn R possiamo creare un correlogramma con la funzione acf():\n\n# Correlogramma per la serie temporale\nacf(x, main = \"Correlogramma della Serie Temporale\", lag.max = 9)\n\n\n\n\n\n\n\n\n49.9.4 Analisi della catena di Markov\nApplichiamo lo stesso approccio alla catena di Markov ottenuta precedentemente, considerando i campioni post burn-in:\n\n# Definizione dei campioni post burn-in\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\n# Correlogramma per i campioni post burn-in\nacf(\n  post_burnin_samples, \n  main = \"Correlogramma della Catena Post Burn-in\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\nIn situazioni ideali, l’autocorrelazione diminuisce rapidamente, diventando insignificante per piccoli lag. Questo comportamento è un’indicazione del “mixing” efficace della catena, ossia della sua convergenza alla distribuzione stazionaria.\n\n49.9.5 Sottocampionamento (thinning)\nPer ridurre l’autocorrelazione, possiamo applicare una strategia di sottocampionamento (thinning), memorizzando solo ogni \\(m\\)-esimo campione.\n\n# Sottocampionamento con un fattore di 5\nthin &lt;- 5\nsampsthin &lt;- \n  post_burnin_samples[seq(1, length(post_burnin_samples), by = thin)]\n\n# Correlogramma per i campioni sottocampionati\nacf(\n  sampsthin, \n  main = \"Correlogramma con Sottocampionamento (Thinning)\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\nIn conclusione, il correlogramma con thinning mostra che l’autocorrelazione diminuisce più rapidamente rispetto ai campioni originali, suggerendo che la strategia di sottocampionamento è efficace nel migliorare l’indipendenza tra i campioni successivi. Questo migliora la qualità delle inferenze basate sulla catena di Markov.\n\n49.9.5.1 Tasso di accettazione\nQuando si utilizza l’algoritmo Metropolis, è importante monitorare il tasso di accettazione e assicurarsi che sia nell’intervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegherà molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D’altra parte, se il tasso di accettazione è molto basso, la catena rimarrà bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l’algoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale è compreso tra il 40% e il 50%.\n\n49.9.6 Test statistici per la convergenza\nOltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.\n\n49.9.6.1 Test di Geweke\nIl test di Geweke è una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l’ultimo 50% dei campioni, dopo aver escluso un iniziale periodo di “burn-in” (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base è che, se la catena è in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze importanti tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.\n\n49.9.6.2 Geweke Z-score\nUna variante del test di Geweke è lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:\n\n\nAl di sotto di 2 (in valore assoluto) suggerisce che non ci sono differenze degne di nota tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.\n\nSuperiore a 2 (in valore assoluto) indica che esiste una differenza degna di nota tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in più esteso.\n\nEntrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. È importante notare che nessun test può garantire con certezza la convergenza, ma l’utilizzo congiunto di approcci grafici e test statistici può offrire una buona indicazione dello stato della catena.\n\n49.9.7 Dimensione del campione effettiva (ESS)\nLa correlazione tra campioni consecutivi in una catena MCMC riduce l’informazione effettiva contenuta in ogni iterazione. La dimensione del campione effettiva (ESS) quantifica questa perdita di informazione dovuta alla dipendenza tra i campioni, stimando il numero equivalente di campioni indipendenti. Un valore basso di ESS indica una forte correlazione tra i campioni e una convergenza più lenta della catena.\nL’ESS descrive l’efficacia del campionamento dipendente in termini di campioni indipendenti estratti dalla stessa distribuzione. Rappresenta un indicatore dell’efficienza del campionamento e dell’autocorrelazione della catena.\nLa formula per stimare la dimensione del campione effettiva (ESS) di una catena di Markov è:\n\\[\n\\text{ESS} = \\frac{N}{1 + 2 \\sum_{t=1}^{T} \\rho_t},\n\\]\ndove:\n\n\n\\(N\\) è il numero totale di campioni nella catena,\n\n\\(T\\) è il lag, ovvero il numero massimo di termini di autocorrelazione considerati,\n\n\\(\\rho_t\\) è l’autocorrelazione al lag \\(t\\), ossia la correlazione tra due campioni consecutivi separati da \\(t\\) iterazioni.\n\nIn pratica, \\(T\\) viene scelto in modo tale che \\(\\rho_T\\) sia sufficientemente piccolo, indicando che l’autocorrelazione è quasi svanita. La somma \\(\\sum_{t=1}^T \\rho_t\\) viene quindi troncata approssimativamente a \\(T\\), poiché i contributi delle autocorrelazioni successive diventano trascurabili.\n\n49.9.8 Calcolo della statistica di Gelman-Rubin (\\(\\hat{R}\\))\nPer calcolare la statistica di Gelman-Rubin (spesso indicata come \\(\\hat{R}\\)), è necessario eseguire più catene e confrontare la variabilità all’interno di ciascuna catena con la variabilità tra le catene. Ecco i passaggi per calcolare \\(\\hat{R}\\):\n\nEsegui \\(m\\) catene di Markov di lunghezza \\(n\\), dove \\(m\\) è solitamente maggiore di 1.\nPer ciascun parametro scalare \\(\\theta\\), calcola la varianza all’interno delle catene (\\(W\\)) e la varianza tra le catene (\\(B\\)).\nCalcola la varianza combinata \\(\\hat{V}\\) come media ponderata delle varianze all’interno delle catene.\nCalcola il fattore di riduzione della scala potenziale \\(\\hat{R}\\) come la radice quadrata del rapporto tra la varianza combinata \\(\\hat{V}\\) e la varianza all’interno delle catene \\(W\\):\n\n\\[\n\\hat{R} = \\sqrt{\\frac{\\hat{V}}{W}}.\n\\]\n\nSe \\(\\hat{R}\\) è vicino a 1, ciò indica che le catene sono in convergenza.\n\nLa statistica di Gelman-Rubin \\(\\hat{R}\\) è una misura di convergenza per le catene di Markov. Essa quantifica il grado di accordo tra più catene, fornendo uno strumento diagnostico per valutare la convergenza nelle simulazioni MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "href": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "\n49.10 Vantaggi del campionamento MCMC rispetto alle soluzioni analitiche",
    "text": "49.10 Vantaggi del campionamento MCMC rispetto alle soluzioni analitiche\nIl campionamento MCMC offre notevoli vantaggi pratici rispetto alle soluzioni analitiche nella statistica bayesiana, in particolare quando si tratta di manipolare distribuzioni a posteriori. Sebbene l’impossibilità di calcolare analiticamente la distribuzione a posteriori sia spesso la motivazione principale per l’uso di MCMC, i benefici di questo approccio si estendono ben oltre questa necessità (Bürkner, 2024).\n\n49.10.1 Facilità di manipolazione e flessibilità\nIl vantaggio chiave del campionamento MCMC risiede nella semplicità con cui si possono manipolare i campioni ottenuti. Mentre le densità calcolate analiticamente possono richiedere trasformazioni matematiche complesse, i campioni MCMC possono essere facilmente trasformati con operazioni dirette.\nIn conclusione, il campionamento MCMC non è solo una necessità quando le soluzioni analitiche sono introvabili, ma offre vantaggi in termini di facilità di manipolazione, flessibilità computazionale e applicabilità pratica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "href": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "\n49.11 Caso Normale-Normale con soluzione analitica",
    "text": "49.11 Caso Normale-Normale con soluzione analitica\nApplichiamo ora l’algoritmo di Metropolis al caso Normale-Normale di cui conosciamo la soluzione analitica. In pratica, ci poniamo il problema di capire quale valore di \\(\\mu\\) (la media vera di una popolazione) sia più plausibile, dopo aver osservato alcuni dati. Abbiamo:\n\nun’idea iniziale (prior) che dice che \\(\\mu\\) dovrebbe stare attorno a 30, con una certa incertezza (deviazione standard 5),\ne abbiamo i dati osservati (\\(y\\)) che ci danno informazioni aggiuntive su dove si trova davvero \\(\\mu\\).\n\nMa non conosciamo esattamente la distribuzione a posteriori di \\(\\mu\\).\nVogliamo costruire una “nuvola” di valori plausibili per \\(\\mu\\) basandoci su dati e prior. Il metodo che usiamo per risolvere questo problema è l’algoritmo di Metropolis.\nStep 1. Partiamo da un punto.\nx_prev &lt;- xinit\n\n\nxinit è il valore iniziale: il nostro “primo sospetto” su dove si trovi \\(\\mu\\).\nÈ come partire da un punto sulla mappa (“Penso che \\(\\mu\\) sia circa qui”).\n\nStep 2. Proponiamo un nuovo punto vicino.\nx_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)\n\nImmaginiamo di essere bendati e di provare a fare un piccolo passo a caso partendo da dove siamo ora.\nQuel passo è generato con una distribuzione normale centrata su x_prev e con una deviazione standard piccola (0.5): piccoli passi casuali attorno al punto attuale.\n\nNota intuitiva:\nIl valore 0.5 decide quanto “grandi” o “piccoli” sono i nostri passi. Più è grande, più possiamo saltare lontano; più è piccolo, più restiamo vicino.\nStep 3. Calcoliamo quanto è “buono” il nuovo punto.\nposterior(x_star, data)\nposterior(x_prev, data)\n\nOgni punto sulla mappa (\\(\\mu\\)) ha un certo valore di plausibilità: quanto è probabile dati i dati osservati e il prior.\n\nposterior(x_star, data) ci dice: “quanto è buono il nuovo punto?”\n\nposterior(x_prev, data) ci dice: “quanto era buono quello vecchio?”\n\nStep 4. Decidiamo se accettare il nuovo punto.\nif (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n  x_prev &lt;- x_star\n}\nQui applichiamo il meccanismo di base dell’algoritmo di Metropolis per decidere sull’accettazione di un nuovo punto:\n\n\nse il nuovo punto è migliore (cioè, la probabilità a posteriori è maggiore), allora lo accettiamo sicuramente (\\(\\alpha &gt; 1\\), quindi \\(\\min(1, \\alpha) = 1\\));\n\nse il nuovo punto è peggiore, possiamo comunque accettarlo con una certa probabilità:\n\nla probabilità di accettazione diminuisce all’aumentare di quanto il punto è “peggiore”;\nciò è essenziale per non rimanere bloccati nei massimi locali.\n\n\n\nIn parole semplici:\n\nse troviamo un posto migliore, ci andiamo;\nse troviamo un posto peggiore, possiamo comunque andarci… ma tirando una monetina.\n\nStep 5. Registriamo il punto attuale\nDopo aver deciso se accettare o meno il nuovo valore proposto, salviamo sempre un punto nella catena.\nMa attenzione:\n\n\nse la proposta è stata accettata, ci spostiamo al nuovo punto e lo registriamo;\n\nse la proposta è stata rifiutata, restiamo fermi e registriamo di nuovo la posizione attuale.\n\nif (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n  x_prev &lt;- x_star  # accettiamo: ci spostiamo\n}\nsamples[i] &lt;- x_prev  # salviamo dove ci troviamo ORA\nIn entrambi i casi, samples[i] tiene traccia della posizione in cui ci troviamo dopo l’iterazione.\nIntuizione: l’escursionista bendato.\nImmaginiamo un’escursionista bendato che vuole esplorare un paesaggio fatto di colline di plausibilità (la distribuzione a posteriori):\n\na ogni passo, prova a fare un salto in una nuova direzione (x_star);\nse quel punto è più alto o non troppo peggiore, accetta di andarci e si sposta.\nse il punto è troppo brutto, rimane fermo dov’è;\nin ogni caso, segna nel diario la sua posizione attuale.\n\nEcco perché, quando guardiamo la catena, possiamo trovare valori ripetuti consecutivi: l’escursionista non si è mosso.\nQuesta caratteristica – il fatto che i campioni non siano tutti diversi – non è un errore, ma una proprietà fondamentale dell’algoritmo Metropolis: i campioni sono dipendenti e possono ripetersi.\nStep 6. Ripetiamo tante volte.\nfor (i in seq_len(nsamp)) { ... }\n\nPiù a lungo ripetiamo il processo (più iterazioni), più densa e accurata sarà la nostra approssimazione della distribuzione a posteriori di \\(\\mu\\).\nDopo un po’, i valori salvati formeranno un disegno della distribuzione plausibile di \\(\\mu\\).\n\n** Riassunto in 3 frasi:**\n\n\nPartiamo da un valore sospettato di \\(\\mu\\).\n\n\nFacciamo piccoli passi casuali e decidiamo se accettarli in base a quanto sono “buoni” rispetto ai dati + prior.\n\n\nDopo molti passi, la sequenza dei punti disegna la distribuzione a posteriori di \\(\\mu\\).\n\n\n** Dopo il sampling:**\n\npossiamo calcolare la media dei campioni = stima puntuale di \\(\\mu\\);\npossiamo costruire un intervallo di credibilità = incertezza su \\(\\mu\\);\npossiamo disegnare un istogramma dei campioni = forma della distribuzione a posteriori.\n\nAnche se l’algoritmo di Metropolis può sembrare “rozzo” (tanti piccoli passi + accettare/rifiutare), funziona benissimo ed è uno dei motivi per cui oggi possiamo applicare la statistica bayesiana a modelli anche molto complessi.\nApplichiamo dunque l’algoritmo di Metropolis all’esercizio in discussione. Iniziamo a definire le funzioni per il prior, la verosimiglianza e il posterior non normalizzato.\n\n# Prior: Normal(30, 5^2)\nprior &lt;- function(mu) {\n  dnorm(mu, mean = 30, sd = 5)\n}\n\n# Likelihood: Normal(mu, sigma^2) con sigma calcolata dai dati\nlikelihood &lt;- function(mu, data) {\n  sigma &lt;- sd(data)  # Deviazione standard dei dati\n  prod(dnorm(data, mean = mu, sd = sigma))\n}\n\n# Posterior non normalizzato\nposterior &lt;- function(mu, data) {\n  likelihood(mu, data) * prior(mu)\n}\n\nImplementiamo l’algoritmo di Metropolis per il caso normale-normale:\n\n# Algoritmo di Metropolis\nmetropolis_for_normal &lt;- function(nsamp, xinit, data) {\n  samples &lt;- numeric(nsamp)\n  x_prev &lt;- xinit\n  \n  for (i in seq_len(nsamp)) {\n    x_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)  # Proposta\n    if (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n      x_prev &lt;- x_star\n    }\n    samples[i] &lt;- x_prev\n  }\n  \n  samples\n}\n\nUtilizziamo un campione di 30 valori BDI-II forniti da Zetsche et al. (2019):\n\n# Dati osservati\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, \n  28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nEsecuzione dell’algoritmo:\n\nsamples &lt;- metropolis_for_normal(100000, mean(y), y)\n\nNel caso normale-normale, il posterior può essere calcolato analiticamente come segue:\n\n# Parametri del prior\nmu_prior &lt;- 30\nstd_prior &lt;- 5\nvar_prior &lt;- std_prior^2\n\n# Calcolo dei parametri posterior\nn &lt;- length(y)\nsum_y &lt;- sum(y)\nvar_data &lt;- var(y)\n\nmu_post &lt;- (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post &lt;- 1 / (1 / var_prior + n / var_data)\nstd_post &lt;- sqrt(var_post)\n\nmu_post\n#&gt; [1] 30.9\nstd_post\n#&gt; [1] 1.17\n\nVisualizziamo i risultati con un istogramma dei campioni MCMC e la curva della distribuzione analitica:\n\n# ── Curva analitica del posterior (normale) ───────────────────────────\nx  &lt;- seq(mu_post - 4 * std_post, mu_post + 4 * std_post, length.out = 1000)\ndf_line &lt;- tibble(x = x, dens = dnorm(x, mean = mu_post, sd = std_post))\n\n# ── Campioni post burn-in per l'istogramma ────────────────────────────\nburnin &lt;- floor(0.5 * length(samples))\npost_samples &lt;- samples[(burnin + 1):length(samples)]\ndf_hist &lt;- tibble(val = post_samples)\n\n# Binwidth data-driven (Freedman–Diaconis)\nbw_fd &lt;- 2 * IQR(post_samples) / length(post_samples)^(1/3)\n\n\ncolori_okabe &lt;- c(\"MCMC\" = \"#56B4E9\", \"Analitico\" = \"#009E73\") \n\nggplot() +\n  geom_histogram(\n    data = df_hist,\n    aes(x = val, y = after_stat(density), fill = \"MCMC\"),\n    bins = 30,\n    alpha = 0.5,\n    color = NA                          # niente bordo: look più editoriale\n  ) +\n  geom_line(\n    data = df_line,\n    aes(x = x, y = dens, color = \"Analitico\"),\n    linewidth = 1.1\n  ) +\n  labs(\n    x = expression(mu), y = \"Densità\"\n  ) +\n  scale_fill_manual(\n    name = \"Distribuzione\",\n    values = colori_okabe,\n    breaks = names(colori_okabe)\n  ) +\n  scale_color_manual(\n    name = \"Distribuzione\",\n    values = colori_okabe,\n    breaks = names(colori_okabe)\n  ) +\n  guides(\n    fill  = guide_legend(override.aes = list(color = NA, alpha = 0.5)),\n    color = guide_legend(override.aes = list(fill  = NA, linewidth = 1.1))\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    legend.box = \"horizontal\"\n  )\n\n\n\n\n\n\n\nTroviamo le proprietà del Posterior derivato con MCMC:\n\nmean(samples); sd(samples)\n#&gt; [1] 30.9\n#&gt; [1] 1.18\n\nIn conclusione, questo esempio illustra l’applicazione dell’algoritmo di Metropolis per la stima di una distribuzione a posteriori nel caso Normale-Normale e dimostra come confrontare i risultati del campionamento con la soluzione analitica, confermando così la coerenza tra le due approcci.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "href": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nL’algoritmo di Metropolis segna un punto di svolta nell’inferenza bayesiana. Prima della sua introduzione, l’analisi bayesiana era praticabile solo in casi molto semplici, con distribuzioni coniugate o con un numero ridotto di parametri. Con Metropolis, invece, diventa possibile ottenere un campione casuale dalla distribuzione a posteriori in modo generale, senza bisogno di conoscere la sua forma analitica.\nQuesta è la sua forza: concettualmente, il problema dell’inferenza bayesiana è risolto. Possiamo sempre, almeno in linea di principio, campionare dalla posterior. I limiti che rimangono sono di tipo pratico: efficienza computazionale e complessità di implementazione. Non a caso, gran parte dello sviluppo successivo – da Metropolis-Hastings fino all’algoritmo NUTS usato da Stan – può essere visto come un raffinamento tecnico per rendere più veloce e più automatizzato ciò che Metropolis aveva già reso possibile. Dal punto di vista didattico, questo rende l’algoritmo di Metropolis un capitolo fondamentale del nostro percorso: non è solo un algoritmo storico, ma il cuore concettuale dell’inferenza bayesiana moderna. Comprenderne la logica permette di interpretare con maggiore consapevolezza anche i metodi più avanzati, che pur nella loro complessità tecnica non fanno che sviluppare ulteriormente questa idea di base (Duane et al., 1987; Geman & Geman, 1984; Hanada & Matsuura, 2022; Hoffman et al., 2014).\nIn conclusione, l’algoritmo di Metropolis ci insegna due lezioni fondamentali: primo, che l’inferenza bayesiana non è limitata ai casi speciali, ma è sempre possibile; secondo, che ogni modello psicologico, anche il più complesso, può essere affrontato con questa logica, a patto di disporre degli strumenti computazionali adeguati.\n\n\n\n\n\n\nEsercizio 1: Autostima negli Studenti Universitari\n\n\n\n\n\nIn un campione casuale di 100 studenti, 25 hanno mostrato livelli alti di autostima.\nSupponiamo un prior Beta(2,8) sulla proporzione \\(\\theta\\) di studenti con alta autostima.\nObiettivo: stimare la distribuzione a posteriori di \\(\\theta\\) usando l’algoritmo di Metropolis.\nDefinizione delle Funzioni.\n\nset.seed(123)  # per riproducibilità\n\n# Prior: Beta(2,8)\nprior &lt;- function(p) dbeta(p, shape1 = 2, shape2 = 8)\n\n# Likelihood: binomiale 25 successi su 100\nlikelihood &lt;- function(p) dbinom(25, size = 100, prob = p)\n\n# Posterior non normalizzata\nposterior &lt;- function(p) prior(p) * likelihood(p)\n\n# Distribuzione di proposta\nproposal_distribution &lt;- function(current, proposal_sigma) {\n  rnorm(1, mean = current, sd = proposal_sigma)\n}\n\n# Algoritmo di Metropolis\nmetropolis &lt;- function(n_samples, start, proposal_sigma) {\n  samples &lt;- numeric(n_samples)\n  current &lt;- start\n  \n  for (i in seq_len(n_samples)) {\n    proposal &lt;- proposal_distribution(current, proposal_sigma)\n    if (proposal &gt;= 0 && proposal &lt;= 1) {\n      acceptance_ratio &lt;- min(1, posterior(proposal) / posterior(current))\n      if (runif(1) &lt; acceptance_ratio) {\n        current &lt;- proposal\n      }\n    }\n    samples[i] &lt;- current\n  }\n  samples\n}\n\nEsecuzione dell’Algoritmo.\n\n# Parametri\nn_samples &lt;- 10000\nstart &lt;- 0.5\nproposal_sigma &lt;- 0.1\n\n# Esecuzione\nsamples &lt;- metropolis(n_samples, start, proposal_sigma)\n\n# Burn-in\nburnin &lt;- floor(n_samples * 0.5)\npost_samples &lt;- samples[-seq_len(burnin)]\n\nAnalisi dei Risultati.\n\n# Media e deviazione standard\nmean(post_samples)\n#&gt; [1] 0.244\nsd(post_samples)\n#&gt; [1] 0.0395\n\nCalcolo dell’Intervallo di Credibilità al 94%.\n\nquantile(post_samples, probs = c(0.03, 0.97))\n#&gt;    3%   97% \n#&gt; 0.170 0.319\n\nConfronto con la Soluzione Analitica.\nLa distribuzione a posteriori teorica è:\n\\[\n\\theta \\sim \\text{Beta}(27, 83)\n\\]\n\n# Media teorica\nmean_beta &lt;- 27 / (27 + 83)\nmean_beta\n#&gt; [1] 0.245\n\n# Intervallo teorico\nqbeta(c(0.03, 0.97), 27, 83)\n#&gt; [1] 0.173 0.326\n\nTrace Plot.\n\n# Trace plot\npost_samples |&gt; \n  tibble(Iteration = 1:length(post_samples), Theta = post_samples) |&gt; \n  ggplot(aes(x = Iteration, y = Theta)) +\n  geom_line() +\n  labs(x = \"Iterazione\", y = expression(theta))\n\n\n\n\n\n\n\nIstogramma e Curva Teorica.\n\n# Prima generiamo il dataset della curva teorica separatamente\nx &lt;- seq(0, 1, length.out = 1000)\ndens_teorica &lt;- dbeta(x, 27, 83)\ncurva_teorica &lt;- tibble(x = x, y = dens_teorica)\n\n# Ora costruiamo il grafico correttamente\ntibble(Theta = post_samples) |&gt; \n  ggplot(aes(x = Theta)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, \n                 color = \"black\", fill = \"lightblue\", alpha = 0.6) +\n  geom_line(data = curva_teorica, aes(x = x, y = y), \n            color = \"red\", size = 1) +\n  labs(x = expression(theta), y = \"Densità\")\n\n\n\n\n\n\n\nRisultati Riassunti.\n\n\nMetodo\nMedia\nIntervallo 94%\n\n\n\nMCMC (Metropolis)\ncirca 0.245\ncirca [0.176, 0.320]\n\n\nTeorico Beta(27,83)\n0.245\n[0.177, 0.318]\n\n\n\nSpiegazioni Didattiche Finali.\n\n\n\n\n\n\nDistribuzione a posteriori: interpretazione\n\n\n\nLa distribuzione a posteriori ci dice quanto sono plausibili i diversi valori di \\(\\theta\\) dopo aver osservato i dati.\n\nAd esempio: “C’è una probabilità del 94% che la vera proporzione di studenti con alta autostima sia tra 17% e 32%.”\n\n\n\n\n\n\n\n\n\nAccettare mosse peggiori: motivo\n\n\n\nAccettiamo campioni con probabilità più bassa per permettere alla catena di esplorare anche aree meno probabili e non restare bloccata nei massimi locali.\n\n\n\n\n\n\n\n\nLarghezza della proposta: trade-off\n\n\n\n\n\nProposta stretta (piccoli passi): alta accettazione, ma esplorazione lenta.\n\nProposta larga (grandi passi): bassa accettazione, ma esplorazione più ampia.\n\nSi cerca un tasso di accettazione tra 40% e 50%.\n\n\n\n\n\n\n\n\nDiagnostica grafica\n\n\n\n\n\nTrace plot: deve mostrare fluttuazioni stabili senza trend.\n\nCorrelogramma: l’autocorrelazione deve decrescere rapidamente.\n\nQuesti strumenti aiutano a diagnosticare una buona esplorazione della distribuzione a posteriori.\n\n\n\n\n\n\n\n\n\n\n\nEsercizio 2 - Depressione (BDI-II)\n\n\n\n\n\nIn uno studio clinico, sono stati raccolti i punteggi BDI-II (Beck Depression Inventory) di 30 pazienti. Vogliamo stimare il valore medio della depressione nella popolazione da cui provengono questi soggetti.\nSupponiamo di avere una conoscenza a priori modellata da una distribuzione Normale(30, 5²) per la media \\(\\mu\\).\nI dati osservati sono i seguenti:\n\ny &lt;- c(26, 35, 30, 25, 44, 30, 33, 43, 22, 43,\n       24, 19, 39, 31, 25, 28, 35, 30, 26, 31,\n       41, 36, 26, 35, 33, 28, 27, 34, 27, 22)\nlength(y)  \n#&gt; [1] 30\n\nFunzioni a priori, verosimiglianza e posteriori.\n\n# Prior: Normal(30, 5^2)\nprior &lt;- function(mu) {\n  dnorm(mu, mean = 30, sd = 5)\n}\n\n# Likelihood: Normal(mu, sigma^2), sigma stimato dai dati\nlikelihood &lt;- function(mu, data) {\n  sigma &lt;- sd(data)\n  prod(dnorm(data, mean = mu, sd = sigma))\n}\n\n# Posterior non normalizzata\nposterior &lt;- function(mu, data) {\n  likelihood(mu, data) * prior(mu)\n}\n\nAlgoritmo di Metropolis.\n\nmetropolis_for_normal &lt;- function(nsamp, xinit, data) {\n  samples &lt;- numeric(nsamp)\n  x_prev &lt;- xinit\n  \n  for (i in seq_len(nsamp)) {\n    x_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)  # proposta\n    if (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n      x_prev &lt;- x_star\n    }\n    samples[i] &lt;- x_prev\n  }\n  samples\n}\n\nEsecuzione dell’algoritmo.\n\nset.seed(123)\nsamples &lt;- metropolis_for_normal(100000, mean(y), y)\n\nburnin &lt;- 50000\npost_samples &lt;- samples[-seq_len(burnin)]\n\nConfronto con la soluzione analitica.\nNel caso prior Normale e likelihood Normale con varianza nota, la posterior è ancora Normale:\n\n# Prior\nmu_prior &lt;- 30\nstd_prior &lt;- 5\nvar_prior &lt;- std_prior^2\n\n# Likelihood\nn &lt;- length(y)\nsum_y &lt;- sum(y)\nvar_data &lt;- var(y)\n\nmu_post &lt;- (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post &lt;- 1 / (1 / var_prior + n / var_data)\nstd_post &lt;- sqrt(var_post)\n\nc(mu_post, std_post)\n#&gt; [1] 30.88  1.17\n\nTrace Plot.\n\n# Trace plot\npost_samples |&gt; \n  tibble(Iteration = 1:length(post_samples), Mu = post_samples) |&gt; \n  ggplot(aes(x = Iteration, y = Mu)) +\n  geom_line() +\n  labs(x = \"Iterazione\", y = expression(mu))\n\n\n\n\n\n\n\nIstogramma vs Posterior Analitica.\n\nx &lt;- seq(mu_post - 4 * std_post, mu_post + 4 * std_post, length.out = 1000)\ndens_teorica &lt;- dnorm(x, mean = mu_post, sd = std_post)\ncurva_teorica &lt;- tibble(x = x, y = dens_teorica)\n\npost_samples |&gt; \n  tibble(Mu = post_samples) |&gt; \n  ggplot(aes(x = Mu)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.6) +\n  geom_line(data = curva_teorica, aes(x = x, y = y), color = \"red\", linewidth = 1) +\n  labs(x = expression(mu), y = \"Densit\\u00e0\")\n\n\n\n\n\n\n\nCosa significa la distribuzione a posteriori?\nIn termini concreti, la distribuzione a posteriori rappresenta la nostra incertezza residua sul valore di \\(\\mu\\), la media dei punteggi BDI-II nella popolazione, dopo aver visto i dati. Per esempio, se calcoliamo che il 94% della distribuzione a posteriori cade tra 27.5 e 32.3, possiamo dire:\n\n“Date le nostre ipotesi iniziali e i dati osservati, c’è una probabilità del 94% che il vero valore medio della depressione nella popolazione stia tra 27.5 e 32.3”.\n\nQuesta è una affermazione probabilistica sul parametro, che è una caratteristica distintiva dell’inferenza bayesiana.\nQuesta distribuzione combina:\n\nle credenze precedenti (il prior),\ncon l’evidenza osservata (i dati).\n\nIl risultato è una distribuzione che riflette cosa sappiamo del parametro dopo aver osservato i dati, e può essere usata per ottenere medie, intervalli di credibilità, probabilità soggettive, ecc.\n\n\n\n\n\n\nPerché accettare anche campioni con densità più bassa?\n\n\n\nNell’algoritmo di Metropolis, a ogni passo si propone un nuovo valore di \\(\\theta\\). Se questo valore ha una densità a posteriori più alta, viene accettato.\nMa se ha una densità più bassa, viene comunque accettato con una certa probabilità.\nPerché farlo?\nPer evitare che la catena si “blocchi” in un massimo locale. Per esplorare anche le aree meno probabili, ma comunque possibili, della distribuzione.\nÈ un meccanismo simile a quello con cui gli esseri umani esplorano: ogni tanto vale la pena provare strade meno promettenti, per evitare di restare intrappolati. Accettare “mosse peggiori” è quindi un meccanismo di esplorazione utile a garantire che la catena possa visitare l’intero spazio dei parametri e convergere correttamente alla distribuzione desiderata.\n\n\n\n\n\n\n\n\nLarghezza della proposta: un equilibrio delicato\n\n\n\nNel Metropolis, il nuovo valore proposto viene scelto spostandosi dal valore corrente secondo una distribuzione normale:\n\\[\\theta_{new} \\sim \\mathcal{N}(\\theta_{attuale}, \\sigma).\\]\nIl parametro \\(\\sigma\\) controlla la distanza dei passi.\nSe \\(\\sigma\\) è:\n\nPiccolo → i passi sono molto corti:\n\nMolte proposte vengono accettate (alta accettazione),\nMa la catena esplora lentamente → i campioni sono fortemente autocorrelati.\n\n\nGrande → i passi sono molto lunghi:\n\nSi propongono salti drastici → molte proposte vengono rifiutate,\nLa catena si muove poco → anche in questo caso, esplorazione inefficiente.\n\n\n\nObiettivo: trovare un compromesso ottimale.\n\nPer un parametro unidimensionale, si consiglia spesso un tasso di accettazione tra 40% e 50%.\nNegli esercizi puoi provare diversi valori di proposal_sigma e osservare il tasso di accettazione per imparare.\n\n\n\nRisultati.\n\nmean(post_samples)\n#&gt; [1] 30.9\nsd(post_samples)\n#&gt; [1] 1.15\nquantile(post_samples, probs = c(0.03, 0.97))\n#&gt;   3%  97% \n#&gt; 28.7 33.1\n\nValori teorici:\n\nmu_post  # media teorica\n#&gt; [1] 30.9\nqnorm(c(0.03, 0.97), mean = mu_post, sd = std_post)\n#&gt; [1] 28.7 33.1\n\nSpiegazione Didattica.\n\nLa media \\(\\mu\\) rappresenta il livello medio di depressione nella popolazione.\nIl prior rappresenta la nostra credenza iniziale (Normale con media 30).\nL’evidenza fornita dai dati modifica questa credenza.\nL’algoritmo di Metropolis permette di campionare da una distribuzione posterior anche senza conoscere la forma analitica.\nIl confronto tra distribuzione teorica e campioni MCMC mostra un ottimo accordo.\n\nConclusione.\nIn questo esercizio abbiamo:\n\nimplementato l’algoritmo di Metropolis per un caso con prior e likelihood Normali;\nstimato la media della distribuzione posterior;\nconfrontato i risultati con la soluzione analitica;\nverificato la coerenza dei campioni MCMC con la distribuzione teorica.\n\nQuesto mostra la potenza dell’approccio MCMC anche in situazioni dove la soluzione analitica sarebbe disponibile, e pone le basi per affrontare problemi più complessi.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4        cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        rmarkdown_2.29        ps_1.9.1             \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [28] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [31] knitr_1.50            zoo_1.8-14            R.utils_2.13.0       \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [46] plyr_1.8.9            withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [55] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [58] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [61] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [64] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [67] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [70] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [73] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [76] gtable_0.3.6          R.methodsS3_1.8.2     digest_0.6.37        \n#&gt; [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [82] R.oo_1.27.1           memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [85] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#bibliografia",
    "href": "chapters/mcmc/01_metropolis.html#bibliografia",
    "title": "49  L’algoritmo di Metropolis-Hastings",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBürkner, P.-C. (2024). The brms Book: Applied Bayesian Regression Modelling Using R and Stan (Early Draft). https://paulbuerkner.com/software/brms-book\n\n\nDuane, S., Kennedy, A. D., Pendleton, B. J., & Roweth, D. (1987). Hybrid monte carlo. Physics letters B, 195(2), 216–222.\n\n\nGeman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on pattern analysis and machine intelligence, 6, 721–741.\n\n\nHanada, M., & Matsuura, S. (2022). MCMC from Scratch. Springer.\n\n\nHastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1), 97–109.\n\n\nHoffman, M. D., Gelman, A., et al. (2014). The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593–1623.\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21(6), 1087–1092.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html",
    "href": "chapters/mcmc/02_ppl.html",
    "title": "50  Linguaggi di programmazione probabilistici",
    "section": "",
    "text": "Introduzione\nNel capitolo precedente abbiamo introdotto l’algoritmo di Metropolis come soluzione generale al problema dell’inferenza bayesiana. Abbiamo visto che, grazie a questo metodo, è sempre possibile generare campioni dalla distribuzione a posteriori, anche quando non conosciamo la sua forma analitica. Questo rappresenta una conquista concettuale decisiva: l’inferenza bayesiana non è limitata ai casi semplici delle famiglie coniugate, ma può essere applicata a qualunque modello.\nTuttavia, la libertà concettuale offerta da Metropolis si scontra con difficoltà pratiche. Implementare l’algoritmo in modo efficiente per ciascun modello richiede di scrivere molto codice su misura, e non è banale stabilire buone regole di proposta per garantire un campionamento rapido e affidabile. In altre parole, sappiamo che l’inferenza è sempre possibile, ma non sempre è semplice metterla in pratica.\nPer superare questi limiti sono nati i linguaggi probabilistici (probabilistic programming languages, PPL). L’idea è elegante: invece di programmare a mano l’algoritmo per ogni modello, lo scienziato specifica direttamente il modello in un linguaggio formale vicino alla notazione statistica. Sarà poi il software a occuparsi di eseguire il campionamento in modo efficiente, utilizzando algoritmi avanzati che generalizzano e migliorano la logica di Metropolis.\nQuesto cambiamento ha avuto un impatto profondo sulla pratica della ricerca. Con i PPL, il ricercatore può concentrarsi sul modello psicologico che vuole esprimere – ad esempio un modello di apprendimento, un modello gerarchico o un modello di decisione – senza doversi preoccupare di tutti i dettagli computazionali del campionamento. È un passaggio simile a quello che, in altri campi scientifici, ha permesso di separare la formulazione delle teorie dalle tecniche di calcolo numerico necessarie per applicarle.\nTra i PPL disponibili oggi, Stan occupa un posto di rilievo. È diventato lo standard in molti ambiti della statistica bayesiana e delle scienze sociali, grazie alla combinazione di tre caratteristiche: un linguaggio chiaro per specificare i modelli, algoritmi di campionamento all’avanguardia (come NUTS, una variante efficiente di Hamiltonian Monte Carlo) e una forte integrazione con strumenti di analisi dei dati come R e Python.\nDal punto di vista didattico, è importante sottolineare che Stan non è una “scatola nera”. Il cuore concettuale rimane quello visto con l’algoritmo di Metropolis: generare campioni dalla distribuzione a posteriori per approssimarla numericamente. La differenza è che, invece di scrivere da zero il codice per ogni modello, ci limitiamo a dichiarare il modello e lasciamo che il software si occupi delle scelte tecniche necessarie.\nIn questo senso, i PPL non rappresentano una rottura rispetto a quanto appreso finora, ma una naturale evoluzione. Ci permettono di spostare l’attenzione dall’aspetto computazionale all’aspetto scientifico: non tanto come campionare, ma quale modello vogliamo costruire per descrivere il fenomeno psicologico che ci interessa.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "href": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "title": "50  Linguaggi di programmazione probabilistici",
    "section": "50.1 Perché abbiamo bisogno della programmazione probabilistica?",
    "text": "50.1 Perché abbiamo bisogno della programmazione probabilistica?\nAbbiamo visto che l’algoritmo di Metropolis fornisce una soluzione generale: in linea di principio, possiamo sempre ottenere campioni dalla distribuzione a posteriori, qualunque sia il modello specificato. Tuttavia, questa libertà concettuale si accompagna a limiti pratici. Scrivere un campionatore funzionante per ogni modello richiede tempo, competenze tecniche avanzate e una grande attenzione agli aspetti numerici. Basta poco per ritrovarsi con algoritmi inefficienti o catene che non convergono. In altre parole, sappiamo che il problema dell’inferenza bayesiana è risolvibile, ma non è detto che sia agevole affrontarlo a mano ogni volta.\nPer rendere questa potenza utilizzabile anche nella pratica quotidiana, sono nati i linguaggi di programmazione probabilistica (probabilistic programming languages, PPL). Essi rappresentano un’evoluzione naturale: invece di programmare direttamente gli algoritmi di campionamento, lo scienziato dichiara semplicemente il modello in un linguaggio vicino alla notazione statistica. Sarà il software a occuparsi di tradurre questa dichiarazione in inferenza numerica, scegliendo algoritmi avanzati e ottimizzati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#dalle-prime-implementazioni-a-stan",
    "href": "chapters/mcmc/02_ppl.html#dalle-prime-implementazioni-a-stan",
    "title": "50  Linguaggi di programmazione probabilistici",
    "section": "50.2 Dalle prime implementazioni a Stan",
    "text": "50.2 Dalle prime implementazioni a Stan\nI primi PPL, come BUGS e WinBUGS, hanno aperto la strada negli anni ’90. Per la prima volta era possibile scrivere un modello bayesiano in modo dichiarativo e ottenere automaticamente un campione dalla distribuzione a posteriori. Questa idea, che all’epoca sembrava quasi visionaria, ha cambiato il modo di concepire l’inferenza: non più come un calcolo complesso da eseguire a mano, ma come una specifica da fornire a un motore di calcolo.\nNel tempo, questi strumenti si sono evoluti. A fianco di BUGS e del suo successore JAGS, sono nati PPL moderni come PyMC in ambiente Python e soprattutto Stan, che oggi rappresenta uno standard in molti ambiti della statistica applicata. Stan combina un linguaggio chiaro per dichiarare i modelli con algoritmi di campionamento estremamente efficienti, come NUTS (No-U-Turn Sampler), una variante avanzata dell’Hamiltonian Monte Carlo. Ciò che prima era accessibile solo a chi possedeva competenze molto specialistiche è diventato così patrimonio di una comunità scientifica molto più ampia.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#cosa-cambia-per-la-ricerca-psicologica",
    "href": "chapters/mcmc/02_ppl.html#cosa-cambia-per-la-ricerca-psicologica",
    "title": "50  Linguaggi di programmazione probabilistici",
    "section": "50.3 Cosa cambia per la ricerca psicologica",
    "text": "50.3 Cosa cambia per la ricerca psicologica\nPer la psicologia e le scienze sociali, l’arrivo dei PPL ha significato un vero salto di qualità. I ricercatori possono finalmente concentrarsi sui modelli teorici che vogliono testare – modelli di apprendimento, di decisione, di effetti gerarchici nei dati – senza doversi preoccupare di reinventare ogni volta la parte algoritmica. Questo permette di sperimentare con strutture di modelli più ricche, di formalizzare meglio le ipotesi psicologiche e di tradurle direttamente in codice eseguibile.\nLa conseguenza è una maggiore trasparenza e una più stretta connessione tra teoria e analisi empirica. I PPL, infatti, non nascondono i modelli dietro procedure automatiche, ma li rendono espliciti: ogni ipotesi è dichiarata in modo chiaro e tracciabile, e il processo inferenziale diventa riproducibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#interfacce-di-alto-livello",
    "href": "chapters/mcmc/02_ppl.html#interfacce-di-alto-livello",
    "title": "50  Linguaggi di programmazione probabilistici",
    "section": "50.4 Interfacce di alto livello",
    "text": "50.4 Interfacce di alto livello\nNaturalmente, anche i PPL richiedono un certo impegno. Scrivere modelli complessi in Stan o in PyMC comporta comunque una buona familiarità con la programmazione e con la statistica bayesiana. Per ampliare l’accessibilità, negli ultimi anni sono state sviluppate interfacce di più alto livello, come brms (in R, basata su Stan) e Bambi (in Python, basata su PyMC).\nQueste interfacce utilizzano una sintassi semplificata e familiare a chi lavora già con modelli statistici tradizionali. In R, ad esempio, brms consente di specificare un modello di regressione con la stessa logica di lm o lmer, aggiungendo la possibilità di definire priori e di stimare i parametri con algoritmi bayesiani. In questo modo, anche chi non ha esperienza di programmazione avanzata può avvicinarsi con relativa facilità all’inferenza bayesiana, beneficiando della potenza dei PPL senza doverne conoscere i dettagli più tecnici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "href": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "title": "50  Linguaggi di programmazione probabilistici",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nI linguaggi di programmazione probabilistica segnano un momento di svolta nella storia dell’inferenza bayesiana. Essi rappresentano il passaggio da una fase pionieristica, in cui ogni ricercatore doveva implementare da sé algoritmi complicati, a una fase matura, in cui l’attenzione può finalmente concentrarsi sulla costruzione dei modelli e sulla loro interpretazione scientifica.\nLa logica di fondo rimane sempre quella introdotta con Metropolis: campionare dalla distribuzione a posteriori per approssimarla numericamente. La differenza è che, grazie ai PPL, non siamo più costretti a scrivere da zero codice specializzato per ogni problema. Possiamo dichiarare i nostri modelli in un linguaggio standardizzato, lasciare che il software si occupi del campionamento e concentrare le nostre energie sulla sostanza psicologica e teorica.\nQuesto capitolo funge quindi da ponte: dall’algoritmo di Metropolis, che ci ha mostrato la logica generale, passiamo ora a strumenti concreti come Stan e le sue interfacce, che renderanno possibile mettere in pratica questa logica nei contesti complessi della ricerca psicologica contemporanea.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html",
    "href": "chapters/mcmc/03_stan_intro.html",
    "title": "51  Introduzione pratica a Stan",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto come l’algoritmo di Metropolis fornisca una soluzione generale al problema dell’inferenza bayesiana e come i linguaggi di programmazione probabilistica abbiano reso questa soluzione praticabile nella ricerca quotidiana. Ora è il momento di incontrare lo strumento che utilizzeremo concretamente nel nostro percorso: Stan.\nStan non è semplicemente un altro software statistico. È un linguaggio di programmazione probabilistica progettato per esprimere modelli bayesiani in modo chiaro e flessibile e per eseguire l’inferenza con algoritmi di campionamento allo stato dell’arte. In particolare, Stan utilizza varianti avanzate dell’Hamiltonian Monte Carlo (HMC), come l’algoritmo NUTS, che offrono efficienza e affidabilità molto superiori rispetto al semplice Metropolis.\nDal punto di vista concettuale, però, nulla cambia: la logica rimane la stessa che abbiamo già compreso. Stan non fa “magia”, ma implementa con grande efficacia ciò che Metropolis aveva già reso possibile. Per questo è importante vederlo come la naturale evoluzione pratica del percorso che abbiamo seguito fin qui.\nPer la ricerca psicologica, Stan ha un vantaggio particolare. Molti dei modelli che ci interessano – modelli gerarchici, modelli di apprendimento, modelli dinamici – richiedono più parametri e strutture complesse. Implementarli a mano sarebbe quasi impossibile. Con Stan, invece, possiamo concentrarci sul modello teorico e tradurlo in codice relativamente semplice, lasciando al software la gestione dei dettagli computazionali.\nNei prossimi capitoli vedremo come iniziare a scrivere modelli in Stan, partendo da esempi elementari per arrivare a strutture più articolate. L’obiettivo non è soltanto imparare un nuovo linguaggio, ma acquisire la capacità di formalizzare i modelli psicologici come processi generativi, traducendoli in analisi statistiche riproducibili e trasparenti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#introduzione",
    "href": "chapters/mcmc/03_stan_intro.html#introduzione",
    "title": "51  Introduzione pratica a Stan",
    "section": "",
    "text": "Panoramica del capitolo\n\nI blocchi del codice Stan.\n\nScrivere e stimare modelli semplici con cmdstanr.\n\nInterpretare i risultati MCMC tramite riassunti e diagnostiche.\n\nValutare la coerenza del modello con prior e posterior predictive check.\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, insight)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#programmazione-probabilistica-con-stan",
    "href": "chapters/mcmc/03_stan_intro.html#programmazione-probabilistica-con-stan",
    "title": "51  Introduzione pratica a Stan",
    "section": "\n51.1 Programmazione probabilistica con Stan",
    "text": "51.1 Programmazione probabilistica con Stan\nOgni programma Stan è organizzato in blocchi distinti, che corrispondono a funzioni precise (Nicenboim et al., 2025). Nel blocco data dichiariamo le variabili osservate che passiamo dall’esterno; in parameters indichiamo le quantità ignote che vogliamo stimare; nel blocco model specifichiamo le assunzioni probabilistiche — cioè le distribuzioni a priori e la verosimiglianza; infine, in generated quantities possiamo calcolare misure derivate, come predizioni o log-likelihood, che non influiscono sulla stima ma sono utili per l’analisi successiva. Questa architettura modulare rende Stan intuitivo e adattabile a un’ampia gamma di applicazioni statistiche.\n\n51.1.1 Lavorare con Stan in R\nL’interfaccia cmdstanr per R segue un workflow ben definito:\n\nscrittura del modello in un file .stan,\n\ncompilazione del modello,\n\npassaggio dei dati come lista R ,\nesecuzione del campionamento con sample(),\n\nanalisi dei risultati mediante pacchetti specializzati (posterior, bayesplot).\n\nPossiamo pensare a un programma Stan come a una “ricetta”. Nel blocco data mettiamo gli ingredienti che già conosciamo (i dati osservati), in parameters dichiariamo gli ingredienti mancanti (i parametri da stimare), in model scriviamo le regole della preparazione (le distribuzioni a priori e la verosimiglianza) e in generated quantities prepariamo i contorni (diagnostiche, predizioni) che non cambiano la ricetta principale, ma la rendono più completa.\nIn pratica, lavorare con Stan da R segue sempre lo stesso schema. Prima si scrive il modello in un file .stan; poi lo si compila, cioè lo si traduce in un eseguibile; quindi si preparano i dati in una lista R con gli stessi nomi dichiarati nel modello; infine si lancia il campionamento con la funzione sample(). Una volta ottenuti i campioni a posteriori, possiamo analizzarli con pacchetti come posterior o bayesplot, che facilitano sia i riassunti numerici sia le visualizzazioni.\nStan utilizza un sistema di tipizzazione statica: tutte le variabili devono essere dichiarate con tipi specifici (int per interi, real per valori reali, vector per vettori) e possono includere vincoli (es. lower=0 per valori positivi). Questo approccio aumenta la robustezza del codice e previene errori comuni nella specificazione dei modelli.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#modello-betabinomiale",
    "href": "chapters/mcmc/03_stan_intro.html#modello-betabinomiale",
    "title": "51  Introduzione pratica a Stan",
    "section": "\n51.2 Modello Beta–Binomiale",
    "text": "51.2 Modello Beta–Binomiale\nCome primo esempio costruiamo un modello molto semplice, ma già sufficiente per illustrare i principi fondamentali della programmazione in Stan. L’obiettivo è stimare la probabilità di successo \\(\\theta\\) in una sequenza di prove Bernoulliane indipendenti.\nPer rendere l’idea concreta, immaginiamo di lanciare un dado mille volte e di registrare il risultato come variabile dicotomica: assegniamo il valore 1 se esce il numero 6 (considerato “successo”), e 0 in tutti gli altri casi (“fallimento”). Se il dado fosse perfettamente equilibrato, la probabilità di successo sarebbe \\(\\theta = 1/6 \\approx 0.167\\). Tuttavia, nell’approccio bayesiano non assumiamo a priori che il dado sia equo: lasciamo che siano i dati, in combinazione con una distribuzione a priori esplicita, a informare il valore di \\(\\theta\\).\nEcco un esempio di generazione dei dati in R:\n\nset.seed(123)\nn &lt;- 1000\ndice_df &lt;- tibble(res = sample(1:6, size = n, replace = TRUE))\ny &lt;- as.integer(dice_df$res == 6)    # 1 se esce “6”, 0 altrimenti\nmean(y)                              # frequenza relativa di “6”\n#&gt; [1] 0.164\n\nIl modello statistico che sottende a questa situazione è molto semplice:\n\nogni osservazione segue una distribuzione Bernoulliana, \\(y_i \\sim \\text{Bernoulli}(\\theta)\\) per \\(i = 1, \\dots, N\\);\nequivalendo a dire che il numero totale di successi \\(k = \\sum_i y_i\\) segue una distribuzione Binomiale, \\(k \\sim \\text{Binomiale}(N,\\theta)\\);\ncome prior adottiamo una distribuzione uniforme su \\([0,1]\\), cioè \\(\\theta \\sim \\text{Beta}(1,1)\\).\n\nVale la pena notare che, se in Stan dichiariamo un parametro vincolato all’intervallo \\([0,1]\\) ma non specifichiamo alcun prior, il linguaggio assegna automaticamente proprio questa distribuzione uniforme, che corrisponde a una Beta(1,1).\n\n51.2.1 Prima versione: modello Bernoulliano vettoriale\nIl modo più diretto di tradurre il modello in Stan è scrivere la verosimiglianza come sequenza di esiti Bernoulliani. Questo approccio ha anche un valore didattico, perché mostra chiaramente la corrispondenza tra dati osservati e modello probabilistico. Stan, inoltre, vettorializza automaticamente le operazioni sugli array, rendendo il codice conciso:\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;                    // numero di prove\n  array[N] int&lt;lower=0, upper=1&gt; y;  // esiti (0/1)\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;      // probabilità di successo\n}\nmodel {\n  theta ~ beta(1, 1);                // prior uniforme su [0,1]\n  y ~ bernoulli(theta);              // verosimiglianza\n}\n\"\n\nIl funzionamento dei blocchi è intuitivo: nel blocco data dichiariamo le variabili osservate (N e il vettore binario y); nel blocco parameters indichiamo il parametro da stimare, \\(\\theta\\); infine, nel blocco model specifichiamo sia la distribuzione a priori sia la verosimiglianza.\nDal punto di vista interno, ogni riga del tipo x ~ distribuzione(...) aggiunge la log-densità (o log-massa) alla quantità interna target, che rappresenta la log-posterior. Se vogliamo essere più espliciti, possiamo scrivere il codice in forma equivalente:\ntarget += beta_lpdf(theta | 1, 1);\ntarget += bernoulli_lpmf(y | theta);\nQuesta seconda scrittura, sebbene meno compatta, è particolarmente utile quando vogliamo costruire verosimiglianze personalizzate o introdurre modifiche non standard.\n\n51.2.2 Seconda versione: modello binomiale sui successi totali\nL’approccio Bernoulliano visto in precedenza ha il pregio della chiarezza, ma può risultare ridondante: stiamo in realtà scrivendo la stessa formula mille volte, una per ciascun lancio del dado. In termini statistici, però, sappiamo che non è necessario conservare l’intera sequenza di zeri e uno: ai fini della stima di \\(\\theta\\) conta solo il numero totale di successi osservati. Questa proprietà prende il nome di sufficienza della statistica \\(k = \\sum_i y_i\\) per la distribuzione binomiale.\nSe dunque nei mille lanci abbiamo osservato, ad esempio, 170 “6”, tutta l’informazione rilevante per stimare \\(\\theta\\) è contenuta in quel singolo numero, non nella sequenza dettagliata dei lanci. La distribuzione binomiale ci permette di formalizzare questa idea in modo compatto, portando a una specificazione del modello più efficiente, ma del tutto equivalente sul piano inferenziale.\nEcco la traduzione in Stan:\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;                      // numero di prove\n  array[N] int&lt;lower=0, upper=1&gt; y;    // esiti (0/1)\n}\ntransformed data {\n  int&lt;lower=0, upper=N&gt; k = sum(y);    // numero totale di successi\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;        // probabilità di successo\n}\nmodel {\n  theta ~ beta(1, 1);                  // prior uniforme\n  k ~ binomial(N, theta);              // verosimiglianza sui successi totali\n}\n\"\n\nQuesta versione concentra la verosimiglianza in un’unica riga, calcolata direttamente sul numero complessivo di successi. Le catene MCMC che otteniamo da questo modello coincidono, entro il rumore Monte Carlo, con quelle prodotte dalla versione Bernoulliana, ma richiedono meno operazioni e risultano quindi più efficienti dal punto di vista computazionale.\nCome per la prima versione, possiamo arricchire il modello con un blocco generated quantities per ottenere log-likelihood o repliche predittive. Queste quantità derivate non modificano l’inferenza su \\(\\theta\\), ma ci consentono di eseguire controlli diagnostici, confrontare modelli alternativi o visualizzare come il modello riproduce i dati osservati.\n\n\n\n\n\n\nPerché “Beta–Binomiale”?\n\n\n\n\n\nRicordiamo che, con prior \\(\\theta \\sim \\text{Beta}(a,b)\\) e \\(k \\sim \\text{Binomiale}(N,\\theta)\\), la posterior è\n\\[\n\\theta \\mid y \\sim \\text{Beta}\\big(a+k,\\; b+N-k\\big),\n\\] con \\(a=b=1\\): \\(\\text{Beta}(1+k,\\; 1+N-k)\\).\nQuesto ci consente un controllo didattico: possiamo confrontare media e IC ottenuti da Stan con quelli della Beta a posteriori.\nEsempio in R:\n\nk &lt;- sum(y)\na &lt;- 1\nb &lt;- 1\npost_mean_closed &lt;- (a + k) / (a + b + n)\npost_ci95_closed  &lt;- qbeta(c(0.025, 0.975), a + k, b + n - k)\npost_mean_closed; \n#&gt; [1] 0.165\npost_ci95_closed\n#&gt; [1] 0.142 0.188\n\nLe stime via Stan (campioni MCMC della theta) devono coincidere (entro il rumore Monte Carlo) con queste quantità analitiche.\n\n\n\nUna volta scritto il modello, il passo successivo è la compilazione. Stan traduce il codice in linguaggio C++ e lo trasforma in un piccolo eseguibile che potrà essere richiamato ogni volta che lanceremo le stime. Questo passaggio richiede qualche secondo solo la prima volta; in seguito, il modello compilato può essere riutilizzato con dataset diversi senza dover ricompilare da capo, con un notevole risparmio di tempo.\n\nstanmod &lt;- cmdstanr::cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n\nPreparato l’eseguibile, dobbiamo passare a Stan i dati necessari. In questo caso servono due elementi: il numero totale di prove e il vettore con gli esiti dei lanci. È importante che i nomi e i tipi corrispondano esattamente a quanto dichiarato nel blocco data del modello Stan, altrimenti il programma restituirà un errore.\n\ndata_list &lt;- list(\n  N = length(y),\n  y = y\n)\nstr(data_list)\n#&gt; List of 2\n#&gt;  $ N: int 1000\n#&gt;  $ y: int [1:1000] 0 1 0 0 0 1 0 0 0 1 ...\n\nA questo punto siamo pronti per il campionamento MCMC. Nella chiamata a sample() specifichiamo quante iterazioni dedicare alla fase di warmup (che serve per adattare l’algoritmo), quante iterazioni utilizzare effettivamente per l’inferenza, e quante catene indipendenti far partire in parallelo. Due parametri aggiuntivi – adapt_delta e max_treedepth – aiutano a rendere più stabili e accurati i passi dell’algoritmo NUTS, soprattutto in modelli più complessi.\n\nfit1 &lt;- stanmod$sample(\n  data = data_list,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4,\n  parallel_chains = 4,\n  seed = 4790,\n  refresh = 0,                 # meno output a schermo\n  adapt_delta = 0.9,           # maggiore prudenza nel passo HMC\n  max_treedepth = 12           # profondità massima dell’albero NUTS\n)\n\nCon il modello stimato, possiamo guardare un riepilogo sintetico delle stime. La funzione summary() di Stan mostra media, deviazione standard, quantili e diagnostiche come \\(\\hat R\\) ed ESS.\n\nprint(fit1$summary(variables = \"theta\"), n = Inf)\n#&gt; # A tibble: 1 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 theta    0.165  0.165 0.012 0.012 0.146 0.185 1.001 5070.123 4701.800\n\nIn alternativa, il pacchetto posterior permette di estrarre i campioni e calcolare con maggiore flessibilità le statistiche che ci interessano:\n\ndraws &lt;- fit1$draws(variables = \"theta\", format = \"draws_matrix\")\nposterior::summarise_draws(\n  draws,\n  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975)), rhat, ess_bulk, ess_tail\n)\n#&gt; # A tibble: 1 × 9\n#&gt;   variable  mean    sd `2.5%` `50%` `97.5%`  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 theta    0.165 0.012  0.143 0.165   0.189 1.001 5070.123 4701.800\n\nCome regola generale, valori di \\(\\hat R\\) molto vicini a 1 (idealmente &lt; 1.01) e un numero elevato di campioni effettivi (ESS) indicano che le catene hanno esplorato bene la distribuzione a posteriori.\nOltre alle statistiche numeriche, le diagnostiche grafiche aiutano a valutare a colpo d’occhio la qualità del campionamento.\n\nbayesplot::mcmc_trace(fit1$draws(\"theta\"), n_warmup = 1000)\n\n\n\n\n\n\n\n\nbayesplot::mcmc_dens_overlay(fit1$draws(\"theta\"))\n\n\n\n\n\n\n\nNel traceplot, le catene dovrebbero mescolarsi bene senza mostrare trend persistenti; nel grafico delle densità, le distribuzioni delle diverse catene dovrebbero risultare sovrapposte.\nIn sintesi: la media a posteriori di \\(\\theta\\) fornisce una stima puntuale della probabilità di ottenere un “6”, l’intervallo di credibilità quantifica l’incertezza residua, e le diagnostiche (R-hat vicino a 1, ESS alto, catene ben mescolate) garantiscono che i campioni siano affidabili per trarre conclusioni.\n\n\n\n\n\n\nConfronto con la frequenza relativa\nLa frequenza mean(y) è solo una stima puntuale. L’analisi bayesiana restituisce un’intera distribuzione per \\(\\theta\\), utile per propagare l’incertezza in previsioni e decisioni.\n\n\n\n\n51.2.3 Distribuzione predittiva posteriore\nStimare \\(\\theta\\) non basta: spesso ciò che ci interessa davvero è capire quali conseguenze pratiche derivano dai risultati. In altre parole, vogliamo sapere cosa il modello ci dice su dati futuri. Per esempio: se rilanciassimo il dado altre mille volte, quanti “6” potremmo aspettarci?\nLa risposta si ottiene con la distribuzione predittiva posteriore. Condizionatamente a un valore di \\(\\theta\\), il numero di successi nei nuovi lanci segue una distribuzione binomiale:\n\\[\ny_{\\text{rep}} \\mid \\theta \\sim \\text{Binomiale}(n_{\\text{new}}, \\theta).\n\\]\nMa noi non conosciamo \\(\\theta\\) con certezza: ne abbiamo solo una distribuzione a posteriori. Per questo motivo, la distribuzione predittiva si ottiene integrando la probabilità condizionata \\(p(y_{\\text{rep}} \\mid \\theta)\\) rispetto alla distribuzione a posteriori di \\(\\theta\\):\n\\[\np(y_{\\text{rep}} \\mid y) = \\int p(y_{\\text{rep}} \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta.\n\\]\nDal punto di vista operativo, il procedimento è semplice: estraiamo valori di \\(\\theta\\) dalla posterior e, per ciascuno di essi, simuliamo un nuovo conteggio \\(y_{\\text{rep}}\\). L’insieme di queste simulazioni costituisce la distribuzione predittiva.\n\n# Numero di futuri lanci da simulare\nn_new &lt;- 1000\n\n# Estrazione dei campioni di theta (vettore numerico)\ntheta_draws &lt;- as.numeric(draws[, \"theta\"])\n\n# Simulazione predittiva\nyrep_count &lt;- rbinom(n = length(theta_draws), size = n_new, prob = theta_draws)\n\n# Riassunti predittivi\nmean(yrep_count)                           # valore atteso di \"6\" su n_new lanci\n#&gt; [1] 165\nquantile(yrep_count, c(0.025, 0.5, 0.975)) # intervallo predittivo 95%\n#&gt;  2.5%   50% 97.5% \n#&gt;   134   164   199\n\nPer visualizzare i risultati, rappresentiamo la distribuzione dei conteggi simulati con un istogramma, segnando con una linea verticale tratteggiata il numero di successi realmente osservati.\n\ntibble(count = yrep_count) |&gt;\n  ggplot(aes(x = count)) +\n  geom_histogram(bins = 30, color = \"white\") +\n  geom_vline(xintercept = sum(y), linetype = \"dashed\") +\n  labs(\n    x = \"Numero di '6' osservati\",\n    y = \"Frequenza\"\n  )\n\n\n\n\n\n\n\nCome leggere il grafico. L’istogramma mostra la variabilità attesa del numero di “6” su mille lanci futuri. La distribuzione è centrata intorno al valore atteso \\(n_{\\text{new}} \\cdot \\mathbb{E}[\\theta \\mid y]\\), cioè il numero medio di successi secondo la stima a posteriori. Se il dado fosse perfettamente equilibrato (\\(\\theta = 1/6\\)), ci aspetteremmo circa 167 successi su 1000, con un intervallo predittivo di circa 150–185. Se i dati simulati si discostano molto da questo scenario, il modello ci sta suggerendo che il dado potrebbe non essere equo.\n\nCome controllo aggiuntivo, possiamo sfruttare la formula chiusa della distribuzione Beta–Binomiale: con prior \\(\\text{Beta}(1,1)\\) e \\(k\\) successi osservati, la predittiva per \\(n_{\\text{new}}\\) prove segue una distribuzione \\(\\text{Beta–Binomiale}(n_{\\text{new}}, 1+k, 1+N-k)\\). I suoi quantili dovrebbero essere coerenti con quelli ottenuti tramite simulazione.\n\n\n51.2.4 Mini check analitico\nUn ulteriore modo per verificare i risultati è confrontare le stime prodotte da Stan con quelle ottenute direttamente dalla forma analitica della distribuzione a posteriori. In questo caso, con prior uniforme e verosimiglianza binomiale, sappiamo che la distribuzione a posteriori di \\(\\theta\\) è ancora una Beta. Possiamo quindi calcolare media e intervallo di credibilità in chiuso e confrontarli con i valori ricavati dal campionamento MCMC:\n\nk &lt;- sum(y); N &lt;- length(y)\na &lt;- 1; b &lt;- 1\n\n# Posterior di theta (soluzione analitica)\npost_mean_closed &lt;- (a + k) / (a + b + N)\npost_ci95_closed &lt;- qbeta(c(0.025, 0.975), a + k, b + N - k)\n\nc(post_mean_closed = post_mean_closed)\n#&gt; post_mean_closed \n#&gt;            0.165\npost_ci95_closed\n#&gt; [1] 0.142 0.188\n\nLe differenze rispetto ai risultati di Stan dovrebbero essere minime e spiegabili unicamente con il normale rumore Monte Carlo. Questo confronto fornisce quindi una garanzia ulteriore che il modello sia stato implementato e stimato correttamente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#dati-continui-stima-della-media-con-varianza-nota",
    "href": "chapters/mcmc/03_stan_intro.html#dati-continui-stima-della-media-con-varianza-nota",
    "title": "51  Introduzione pratica a Stan",
    "section": "\n51.3 Dati continui: stima della media con varianza nota",
    "text": "51.3 Dati continui: stima della media con varianza nota\nPassiamo ora a un caso molto comune nelle scienze psicologiche: la stima della media di popolazione di una variabile continua. Pensiamo, ad esempio, ai punteggi ottenuti in un test di intelligenza (QI).\nPer semplicità ipotizziamo che la deviazione standard \\(\\sigma\\) sia nota. È un’ipotesi forte, certo, ma ci permette di concentrare l’attenzione su un solo parametro incognito: la media \\(\\mu\\). Questa assunzione semplifica il modello e rende più chiaro il passaggio dall’impostazione classica a quella bayesiana.\nMolti dati psicologici possono essere approssimati da una distribuzione normale: è il caso dei punteggi standardizzati come il QI, che hanno distribuzioni simili a una gaussiana in popolazione. Immaginiamo quindi di raccogliere i punteggi di \\(n=30\\) persone, supponendo che la deviazione standard sia \\(\\sigma = 15\\) e che la media reale sia 105.\n\nset.seed(123)\nn     &lt;- 30\nsigma &lt;- 15\ny_cont &lt;- rnorm(n, mean = 105, sd = sigma)\n\ntibble(y = y_cont) |&gt;\n  ggplot(aes(x = y)) +\n  geom_histogram(bins = 15) +\n  labs(x = \"Punteggio\", y = \"Frequenza\")\n\n\n\n\n\n\n\nIn questo scenario, il modello statistico si scrive così:\n\n\nVerosimiglianza: \\(y_i \\sim \\mathcal{N}(\\mu, \\sigma)\\), con \\(\\sigma\\) noto.\n\nPrior su \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(\\mu_0, \\tau)\\), con \\(\\mu_0 = 100\\) come media attesa a priori e \\(\\tau = 30\\) come deviazione standard del prior, scelta piuttosto ampia per riflettere un’incertezza elevata.\n\nDa notare che \\(\\mu\\) può assumere qualsiasi valore reale: per questo il prior corretto è una distribuzione normale definita su tutto \\(\\mathbb{R}\\).\nEcco la traduzione del modello in Stan:\n\nstancode_norm &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] y;             // dati continui\n  real&lt;lower=0&gt; sigma;     // sd nota\n  real mu0;                // media del prior su mu\n  real&lt;lower=0&gt; tau;       // sd del prior su mu\n}\nparameters {\n  real mu;                 // media: parametro reale non vincolato\n}\nmodel {\n  mu ~ normal(mu0, tau);   // prior corretto su mu\n  y  ~ normal(mu, sigma);  // likelihood\n}\n\"\n\nPrepariamo i dati in R in modo che siano coerenti con quanto richiesto dal blocco data del modello:\n\ndata_list2 &lt;- list(\n  N     = length(y_cont),\n  y     = y_cont,\n  sigma = sigma,\n  mu0   = 100,\n  tau   = 30\n)\n\nCompiliamo il modello:\n\nstanmod2 &lt;- cmdstanr::cmdstan_model(write_stan_file(stancode_norm), compile = TRUE)\n\nE infine lanciamo il campionamento MCMC:\n\nfit2 &lt;- stanmod2$sample(\n  data = data_list2,\n  iter_warmup     = 1000,\n  iter_sampling   = 4000,\n  chains          = 4,\n  parallel_chains = 4,\n  seed            = 4790,\n  refresh         = 0\n)\n\nI risultati possono essere riepilogati in forma sintetica:\n\nprint(fit2$summary(variables = \"mu\"), n = Inf)\n#&gt; # A tibble: 1 × 10\n#&gt;   variable    mean  median    sd   mad     q5     q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       104.240 104.236 2.721 2.740 99.751 108.710 1.001 5499.842 7540.041\n\nOppure, con il pacchetto posterior, possiamo estrarre i campioni e calcolare statistiche più flessibili, come medie, quantili e diagnostiche:\n\ndraws2 &lt;- fit2$draws(variables = \"mu\", format = \"draws_matrix\")\nposterior::summarise_draws(\n  draws2, mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975)), rhat, ess_bulk, ess_tail\n)\n#&gt; # A tibble: 1 × 9\n#&gt;   variable    mean    sd `2.5%`   `50%` `97.5%`  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       104.240 2.721 98.916 104.236 109.627 1.001 5499.842 7540.041\n\nL’interpretazione è immediata:\n\nvalori di \\(\\hat R\\) vicini a 1 e effective sample size elevato ci dicono che le catene sono ben miscelate e la stima è affidabile;\nla media a posteriori di \\(\\mu\\) rappresenta la nostra miglior stima puntuale della media di popolazione;\nl’intervallo di credibilità (ad esempio al 95%) quantifica l’incertezza residua su \\(\\mu\\).\n\nIn questo modo otteniamo non solo una stima centrale, ma un quadro completo della plausibilità dei valori possibili per la media di popolazione, dato quanto osservato.\n\n51.3.1 Controllo analitico della coniugatezza\nIl modello che abbiamo specificato ha una proprietà molto comoda: la coniugatezza. Quando usiamo un prior normale per la media \\(\\mu\\) e assumiamo nota la varianza \\(\\sigma^2\\), anche la distribuzione a posteriori di \\(\\mu\\) rimane normale. Questo ci permette di calcolare media e varianza della posterior in forma chiusa, senza bisogno di simulazioni MCMC.\nIn particolare, la varianza e la media della distribuzione a posteriori si ottengono come:\n\\[\n\\text{Var}(\\mu \\mid y) \\;=\\; \\left(\\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2}\\right)^{-1},\n\\quad\n\\mathbb{E}[\\mu \\mid y] \\;=\\; \\text{Var}(\\mu \\mid y)\\,\\left(\\frac{n\\bar y}{\\sigma^2} + \\frac{\\mu_0}{\\tau^2}\\right).\n\\]\nCon i nostri dati possiamo calcolare questi valori direttamente:\n\nybar    &lt;- mean(y_cont)\ntau2    &lt;- 30^2\nsigma2  &lt;- sigma^2\npost_var  &lt;- 1 / (n / sigma2 + 1 / tau2)\npost_sd   &lt;- sqrt(post_var)\npost_mean &lt;- post_var * (n * ybar / sigma2 + 100 / tau2)\n\nc(post_mean_closed = post_mean, post_sd_closed = post_sd)\n#&gt; post_mean_closed   post_sd_closed \n#&gt;           104.26             2.73\n\nOra possiamo confrontare questi risultati analitici con quanto ottenuto tramite campionamento MCMC:\n\nmu_draws &lt;- as.numeric(draws2[, \"mu\"])\nc(mean_mcmc = mean(mu_draws), sd_mcmc = sd(mu_draws))\n#&gt; mean_mcmc   sd_mcmc \n#&gt;    104.24      2.72\n\nE per completezza, guardiamo anche i quantili della distribuzione campionata:\n\nquantile(mu_draws, c(0.025, 0.5, 0.975))\n#&gt;  2.5%   50% 97.5% \n#&gt;  98.9 104.2 109.6\n\nLe due soluzioni dovrebbero concordare molto bene: la formula chiusa ci dà il risultato “esatto”, mentre l’MCMC lo approssima tramite simulazione. Le piccole discrepanze sono attribuibili al normale rumore Monte Carlo, che diminuisce all’aumentare del numero di campioni.\n\n51.3.2 Visualizzazione\nUna volta stimato il modello, è molto utile osservare graficamente i campioni MCMC per verificare sia la qualità del campionamento sia la forma della distribuzione a posteriori. Il pacchetto bayesplot fornisce strumenti immediati per questo scopo.\nUn primo passo è guardare l’istogramma dei campioni:\n\nbayesplot::mcmc_hist(fit2$draws(\"mu\"))\n\n\n\n\n\n\n\nQuesto grafico mostra la distribuzione stimata della media \\(\\mu\\): non un singolo numero, ma un ventaglio di valori plausibili con le loro frequenze relative.\nPossiamo poi controllare l’andamento delle catene con un traceplot:\n\nbayesplot::mcmc_trace(fit2$draws(\"mu\"), n_warmup = 1000)\n\n\n\n\n\n\n\nQui l’idea è semplice: le linee delle catene devono sembrare “ben mescolate”, senza trend evidenti o zone piatte. È un indicatore visivo della corretta esplorazione dello spazio dei parametri.\nInfine, è utile sovrapporre le distribuzioni stimate dalle diverse catene per verificarne la concordanza:\n\nbayesplot::mcmc_dens_overlay(fit2$draws(\"mu\"))\n\n\n\n\n\n\n\nSe le curve si sovrappongono bene, abbiamo un’ulteriore conferma che le catene hanno raggiunto la stessa distribuzione stazionaria.\nIn sintesi, questo esempio rappresenta una sorta di “test bayesiano della media” con deviazione standard nota e un prior normale ampio su \\(\\mu\\). A differenza dell’approccio frequentista, non otteniamo soltanto una stima puntuale o un intervallo, ma un’intera distribuzione a posteriori della media. Questo è un vantaggio importante: l’incertezza stimata può essere comunicata in modo trasparente e, soprattutto, può essere propagata nelle fasi successive dell’analisi, ad esempio in previsioni o decisioni basate sul modello.\n\nUna nota pratica su Stan: se omettessimo la prior su \\(\\mu\\), il software assumerebbe implicitamente una prior impropria piatta su \\(\\mathbb{R}\\). Sebbene ciò possa funzionare in casi semplici, didatticamente preferiamo specificare in modo esplicito un prior normale (anche molto ampio). In questo modo le assunzioni sono sempre chiare e il modello rimane ben definito.\n\n\n51.3.3 Intervalli di credibilità\nIn un’analisi bayesiana non otteniamo una singola stima del parametro, ma una distribuzione a posteriori che descrive tutta l’incertezza residua. Gli intervalli di credibilità servono a riassumere questa distribuzione in modo intuitivo:\n\nDato il modello e i dati osservati, c’è una probabilità prefissata (ad esempio 94%) che il parametro cada all’interno dell’intervallo.\n\nÈ un’interpretazione semplice e diretta, molto più naturale rispetto a quella degli intervalli di confidenza frequentisti.\n\n51.3.3.1 Due definizioni principali\n\n\nETI (Equal-Tailed Interval): l’intervallo “a code uguali”. Lascia la stessa probabilità nelle due code della distribuzione (es. 3% a sinistra e 3% a destra in un intervallo al 94%).\n\nVantaggio: è invariante a trasformazioni monotone (se trasformo il parametro, trasformo anche i quantili).\nSvantaggio: se la posterior è molto asimmetrica, l’intervallo può risultare poco compatto.\n\n\n\nHDI (Highest Density Interval): l’intervallo “a massima densità”. È il più stretto possibile che contiene la probabilità fissata.\n\nVantaggio: rimane compatto anche con distribuzioni asimmetriche.\nSvantaggio: non è invariante a trasformazioni monotone; in presenza di distribuzioni multimodali può perfino risultare “spezzato” in più sotto-intervalli.\n\n\n\nSe la distribuzione a posteriori è simmetrica e unimodale (per esempio una Normale), ETI e HDI coincidono.\n\n51.3.3.2 Esempio con i campioni di \\(\\mu\\)\n\nPartiamo dai campioni MCMC della media \\(\\mu\\):\n\nmu_draws &lt;- as.numeric(fit2$draws(\"mu\"))\n\nCalcoliamo sia ETI che HDI al 94% con il pacchetto bayestestR:\n\neti94 &lt;- bayestestR::eti(mu_draws, ci = 0.94)\nhdi94 &lt;- bayestestR::hdi(mu_draws, ci = 0.94)\n\neti94\n#&gt; 94% ETI: [99.12, 109.43]\nhdi94\n#&gt; 94% HDI: [99.22, 109.48]\n\n\n51.3.3.3 Visualizzazione\nCon bayesplot::mcmc_areas() possiamo visualizzare gli intervalli centrali (ETI) e aggiungere i limiti HDI come linee verticali:\n\np &lt;- bayesplot::mcmc_areas(fit2$draws(\"mu\"), prob = 0.94) +\n  xlab(expression(mu)) + ylab(\"Densità\")\n\np + \n  geom_vline(xintercept = hdi94$CI_low,  linetype = \"dashed\") +\n  geom_vline(xintercept = hdi94$CI_high, linetype = \"dashed\")\n\n\n\n\n\n\n\n\n51.3.3.4 Posterior asimmetrica: esempio Beta\nPer apprezzare meglio la differenza, consideriamo una distribuzione asimmetrica, come una Beta(6,2):\n\nset.seed(123)\ntheta_draws &lt;- rbeta(5000, shape1 = 6, shape2 = 2)\n\neti_beta &lt;- bayestestR::eti(theta_draws, ci = 0.94)\nhdi_beta &lt;- bayestestR::hdi(theta_draws, ci = 0.94)\n\neti_beta\n#&gt; 94% ETI: [0.43, 0.96]\nhdi_beta\n#&gt; 94% HDI: [0.49, 0.98]\n\n\nggplot(data.frame(theta = theta_draws), aes(x = theta)) +\n  geom_density() +\n  geom_vline(xintercept = c(eti_beta$CI_low, eti_beta$CI_high), linewidth = 0.7) +\n  geom_vline(xintercept = c(hdi_beta$CI_low, hdi_beta$CI_high), \n             linewidth = 1.2, linetype = \"dashed\") +\n  labs(x = expression(theta), y = \"Densità\")\n\n\n\n\n\n\n\nQui si vede bene che l’HDI è più corto, perché concentra l’intervallo nelle zone di massima densità, evitando code poco informative.\n\n51.3.3.5 Quale livello usare? 89%, 94% o 95%?\n\n\n95%: è la scelta più familiare (ereditata dal frequentismo).\n\n94%: molto usata in manuali bayesiani (es. McElreath, 2018).\n\n89%: proposta da Kruschke come compromesso più stabile con campioni limitati.\n\nLa regola pratica è semplice: scegli un livello coerente con il resto dell’analisi e specifica sempre il metodo (ETI o HDI). Se la posterior è asimmetrica, riportare entrambi può essere molto utile.\n\n51.3.3.6 Riassunto operativo\n\n# Campioni da Stan\nmu_draws &lt;- as.numeric(fit2$draws(\"mu\"))\n\n# Intervalli a 94%\neti94 &lt;- bayestestR::eti(mu_draws, ci = 0.94)\nhdi94 &lt;- bayestestR::hdi(mu_draws, ci = 0.94)\n\n# Riassunti\nlist(\n  mean   = mean(mu_draws),\n  median = median(mu_draws),\n  ETI94  = c(low = eti94$CI_low, high = eti94$CI_high),\n  HDI94  = c(low = hdi94$CI_low, high = hdi94$CI_high)\n)\n#&gt; $mean\n#&gt; [1] 104\n#&gt; \n#&gt; $median\n#&gt; [1] 104\n#&gt; \n#&gt; $ETI94\n#&gt;   low  high \n#&gt;  99.1 109.4 \n#&gt; \n#&gt; $HDI94\n#&gt;   low  high \n#&gt;  99.2 109.5\n\nIn sintesi:\n\ncon distribuzioni simmetriche ETI e HDI sono equivalenti,\ncon distribuzioni asimmetriche l’HDI è di solito più informativo perché si concentra nelle regioni più probabili,\nriportare entrambi può aiutare a comunicare chiaramente le assunzioni e i risultati.\n\nUn esempio di frase per un report potrebbe essere:\n\n“Con un intervallo di credibilità al 94%, possiamo dire che la media del QI nella popolazione ha il 94% di probabilità di trovarsi tra 102 e 107.”",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#test-di-ipotesi-bayesiane",
    "href": "chapters/mcmc/03_stan_intro.html#test-di-ipotesi-bayesiane",
    "title": "51  Introduzione pratica a Stan",
    "section": "\n51.4 Test di ipotesi bayesiane",
    "text": "51.4 Test di ipotesi bayesiane\nL’approccio bayesiano permette di formulare domande dirette del tipo:\n\n“Qual è la probabilità che la media superi una certa soglia?”\n\nA differenza dei test frequentisti, non ci costringe a una risposta secca sì/no, ma restituisce una misura graduata di plausibilità. Inoltre, se abbiamo un margine di tolleranza pratico attorno alla soglia, possiamo definire una ROPE (Region Of Practical Equivalence) e distinguere tre scenari: il parametro stimato è verosimilmente sotto, dentro oppure sopra la zona di equivalenza.\n\n51.4.1 Probabilità a posteriori sopra una soglia\nRiprendiamo l’esempio del QI con modello Normale e \\(\\sigma\\) noto. Una domanda semplice è:\n\\[\nP(\\mu &gt; 110 \\mid y),\n\\]\ncioè la probabilità che la media della popolazione superi il valore 110.\nCalcolo dai campioni MCMC:\n\nmu_draws &lt;- as.numeric(fit2$draws(\"mu\"))\np_gt_110 &lt;- mean(mu_draws &gt; 110)\np_gt_110\n#&gt; [1] 0.0193\n\n\nInterpretazione: dato modello + dati, la probabilità che \\(\\mu\\) superi 110 è p_gt_110. Non un “sì/no”, ma una misura graduata della plausibilità dell’affermazione.\n\nControllo analitico (conjugate Normal-Normal):\n\np_gt_110_closed &lt;- 1 - pnorm(110, mean = post_mean, sd = post_sd)\nc(MCMC = p_gt_110, ClosedForm = p_gt_110_closed)\n#&gt;       MCMC ClosedForm \n#&gt;     0.0193     0.0176\n\nI due valori devono concordare (differenze minime = rumore Monte Carlo).\n\n51.4.2 Decisione pratica\nSe occorre prendere una decisione, possiamo introdurre una regola:\n\n\nagire come se \\(\\mu&gt;110\\) se \\(P(\\mu&gt;110\\mid y)\\ge p^*\\) (es. \\(p^*=0.9\\)),\naltrimenti, non agire (o raccogliere più dati).\n\nIl valore soglia \\(p^\\*\\) dipende dal rapporto costi/benefici degli errori (falsa allerta vs. falsa rassicurazione). L’approccio bayesiano rende esplicita questa scelta.\n\n51.4.3 ROPE: equivalenza pratica\nNella realtà spesso non interessa se \\(\\mu\\) sia esattamente 110, ma se sia praticamente equivalente a 110 entro una tolleranza accettabile. Definiamo allora una ROPE:\n\\[\n\\text{ROPE} = [108,\\,112] .\n\\]\nLe tre probabilità mutuamente esclusive sono:\n\nrope &lt;- c(108, 112)\n\nP_below &lt;- mean(mu_draws &lt;  rope[1])\nP_in    &lt;- mean(mu_draws &gt;= rope[1] & mu_draws &lt;= rope[2])\nP_above &lt;- mean(mu_draws &gt;  rope[2])\n\nc(P_below = P_below, P_in = P_in, P_above = P_above)\n#&gt; P_below    P_in P_above \n#&gt; 0.91463 0.08250 0.00287\n\nCon la posterior Normale si può calcolare anche in forma chiusa:\n\nP_below_cf &lt;- pnorm(rope[1], mean = post_mean, sd = post_sd)\nP_in_cf    &lt;- pnorm(rope[2], mean = post_mean, sd = post_sd) -\n              pnorm(rope[1], mean = post_mean, sd = post_sd)\nP_above_cf &lt;- 1 - pnorm(rope[2], mean = post_mean, sd = post_sd)\n\nc(P_below_cf = P_below_cf, P_in_cf = P_in_cf, P_above_cf = P_above_cf)\n#&gt; P_below_cf    P_in_cf P_above_cf \n#&gt;    0.91498    0.08275    0.00226\n\n\n51.4.4 Interpretazione\n\nSe \\(P(\\mu\\in \\text{ROPE})\\) è alta → \\(\\mu\\) è praticamente equivalente alla soglia.\nSe \\(P(\\mu&gt;\\text{ROPE})\\) è alta → \\(\\mu\\) è sopra la soglia in modo rilevante.\nSe \\(P(\\mu&lt;\\text{ROPE})\\) è alta → \\(\\mu\\) è sotto la soglia in modo rilevante.\nSe le tre probabilità sono simili → il messaggio è incertezza → utile raccogliere più dati o rivedere la tolleranza.\n\n51.4.5 Esempio di frase per un report\n\nCon ROPE = \\(\\[108,112]\\), la probabilità che \\(\\mu\\) sia sotto-ROPE è \\(P(\\mu&lt;108)=0.92\\), dentro-ROPE \\(P(108\\le \\mu\\le112)=0.08\\), sopra-ROPE \\(P(\\mu&gt;112)=0.003\\). Questi risultati indicano che \\(\\mu\\) è verosimilmente inferiore a 110 nel senso pratico definito dalla ROPE.\n\n\n51.4.6 Diagnostiche di campionamento\nDopo aver ottenuto i campioni dalla distribuzione a posteriori, il passo successivo è verificare se questi siano di buona qualità. Un modello ben specificato e un campionamento MCMC efficace producono catene che esplorano lo spazio dei parametri in modo completo e bilanciato. Per questo motivo, nel riepilogo fornito da Stan e dai pacchetti associati compaiono alcune statistiche fondamentali, che meritano di essere interpretate con attenzione (la quantità lp__ è un parametro speciale usato per le diagnostiche).\n\nfit2$summary(variables = c(\"mu\",\"lp__\"))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable    mean  median    sd   mad      q5     q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       104.240 104.236 2.721 2.740  99.751 108.710 1.001 5499.842 7540.041\n#&gt; 2 lp__     -14.463 -14.195 0.705 0.313 -15.896 -13.967 1.001 7356.664 9175.822\n\nUn primo indicatore è la statistica di convergenza \\(\\hat{R}\\) (o R-hat). Quando le catene sono indipendenti e hanno raggiunto lo stesso equilibrio, i loro valori oscillano intorno alle stesse regioni della distribuzione. In questo caso \\(\\hat{R}\\) assume valori molto vicini a 1. Nel nostro esempio, per i parametri mu e lp__ si ottengono rispettivamente 1.002 e 1.001. Questi valori sono praticamente indistinguibili da 1 e segnalano che le catene hanno raggiunto una buona mescolanza. In termini pratici, valori inferiori a 1.01 sono generalmente considerati ottimali, mentre valori superiori a 1.05 suggeriscono possibili problemi di convergenza.\nUn secondo insieme di statistiche riguarda la dimensione del campione effettivo (ESS, effective sample size). A differenza di un campionamento indipendente, l’MCMC produce campioni correlati tra loro. L’ESS quantifica quanti campioni indipendenti “equivalenti” abbiamo realmente a disposizione. Nel nostro modello, i valori per mu sono di 2768 (bulk) e 3798 (tail), mentre per lp__ superano i 3600. Si tratta di valori molto elevati, che garantiscono stime stabili anche per i quantili delle code della distribuzione. Più l’ESS è alto, più le nostre stime risultano precise. A titolo di esempio, l’errore Monte Carlo sulla media di mu, calcolato come \\(\\text{sd}/\\sqrt{\\text{ESS}}\\), risulta circa 0.05: un valore trascurabile rispetto alla deviazione standard della distribuzione a posteriori, pari a 2.68. Questo significa che l’incertezza introdotta dal metodo numerico è minima.\nOltre agli indici di convergenza e di efficienza, vale la pena soffermarsi sulla forma della distribuzione stimata. Nel riepilogo vediamo che la media e la mediana di mu (104.22 e 104.24) coincidono quasi perfettamente, segnalando una distribuzione sostanzialmente simmetrica. La deviazione standard (2.68) e la MAD (2.65) confermano che la variabilità è ben catturata e non emergono anomalie nelle code. I quantili dal 5° al 95° indicano un intervallo credibile al 90% compreso tra circa 99.8 e 108.6. È interessante osservare che il valore 110 si colloca al di sopra di questo intervallo, fatto che si traduce in una probabilità molto bassa che \\(\\mu\\) superi quella soglia.\nInfine, il parametro lp__, che rappresenta la log-densità a posteriori, non va interpretato come un parametro di interesse ma come strumento diagnostico. Anch’esso mostra valori di \\(\\hat{R}\\) e di ESS ottimi, confermando che l’esplorazione dello spazio dei parametri è avvenuta senza difficoltà.\nIn sintesi, tutte le evidenze diagnostiche — \\(\\hat{R}\\) prossimo a 1, valori elevati di ESS, concordanza tra media, mediana e misure di dispersione — ci permettono di concludere che il campionamento MCMC è stato stabile ed efficiente. Questo garantisce che i risultati ottenuti rappresentano fedelmente la distribuzione a posteriori specificata dal nostro modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#prior-e-posterior-predictive-check",
    "href": "chapters/mcmc/03_stan_intro.html#prior-e-posterior-predictive-check",
    "title": "51  Introduzione pratica a Stan",
    "section": "\n51.5 Prior e Posterior Predictive Check",
    "text": "51.5 Prior e Posterior Predictive Check\nPrima guardiamo se il prior che abbiamo scelto genera valori plausibili anche senza dati: questo è il prior predictive check. Se il prior produce punteggi di QI completamente inverosimili, dobbiamo correggerlo. Poi, dopo aver aggiornato il modello con i dati, passiamo al posterior predictive check. In questo caso le simulazioni devono assomigliare ai dati reali: se non ci riescono, significa che il modello non descrive bene il fenomeno.\n\n51.5.1 Prior Predictive Check\nObiettivo. Prima di guardare i dati, vogliamo chiederci: le nostre assunzioni a priori su \\(\\mu\\) sono plausibili? In altre parole, il prior scelto produce valori di \\(y\\) che hanno senso rispetto al dominio del problema (qui: punteggi QI)?\nIl nostro modello è:\n\\[\ny_i \\mid \\mu \\sim \\mathcal{N}(\\mu,\\; \\sigma),\n\\qquad\n\\mu \\sim \\mathcal{N}(\\mu_0,\\; \\tau).\n\\]\nCombinando likelihood e prior, la distribuzione predittiva a priori di una singola osservazione è:\n\\[\ny_i \\sim \\mathcal{N}\\!\\Big(\\mu_0,\\; \\sqrt{\\sigma^2 + \\tau^2}\\Big).\n\\]\nQuesta distribuzione descrive quali valori ci aspettiamo prima di osservare alcun dato.\n\nSe produce valori estremi o inverosimili (ad es. QI &lt; 40 o &gt; 160), il prior è troppo largo o spostato.\nSe invece produce valori troppo concentrati in un intervallo ristretto, il prior è eccessivamente informativo, lasciando poco spazio ai dati.\n\nPer implementare un prior predictive check possiamo usare lo stesso file Stan dell’inferenza, con una piccola modifica:\n\naggiungiamo una variabile booleana compute_likelihood, che ci permette di decidere se includere o meno la riga y ~ normal(mu, sigma);,\ngeneriamo repliche \\(y_{\\text{rep}}\\) in un blocco generated quantities.\n\nEcco il codice Stan:\n\nstancode_norm_ppc &lt;- \"\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] y;                 // usato solo se compute_likelihood=1\n  real&lt;lower=0&gt; sigma;         // sd nota\n  real mu0;                    // media del prior su mu\n  real&lt;lower=0&gt; mu_prior_sd;   // sd del prior\n  int&lt;lower=0, upper=1&gt; compute_likelihood; // 1 = usa y ~ normal(..), 0 = disattiva\n}\nparameters {\n  real mu;\n}\nmodel {\n  mu ~ normal(mu0, mu_prior_sd);\n  if (compute_likelihood == 1) {\n    y ~ normal(mu, sigma);\n  }\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik; \n\n  for (n in 1:N) {\n    y_rep[n] = normal_rng(mu, sigma); // repliche prior/posterior predictive\n    log_lik[n] = normal_lpdf(y[n] | mu, sigma); \n  }\n}\n\"\nstanmod_ppc &lt;- cmdstan_model(write_stan_file(stancode_norm_ppc), compile = TRUE)\n\nPer un controllo puro del prior disattiviamo la likelihood (compute_likelihood = 0). In questo modo, Stan genera valori \\(y_{\\text{rep}}\\) esclusivamente a partire dalle assunzioni a priori.\n\nN_ppc &lt;- length(y_cont)\n\nstan_data_prior &lt;- list(\n  N = N_ppc,\n  y = rep(0, N_ppc),   # placeholder, non usato quando compute_likelihood = 0\n  sigma = sigma,\n  mu0 = 100,\n  mu_prior_sd = 30,\n  compute_likelihood = 0\n)\n\nfit_prior &lt;- stanmod_ppc$sample(\n  data = stan_data_prior,\n  iter_warmup = 500,\n  iter_sampling = 2000,\n  chains = 4,\n  parallel_chains = 4,\n  seed = 4790,\n  refresh = 500\n)\n\nDopo il campionamento, estraiamo le repliche \\(y_{\\text{rep}}\\):\n\n# Estrazione dei dati simulati\nyrep_mat_prior &lt;- posterior::as_draws_matrix(fit_prior$draws(\"y_rep\"))\n\n# Selezione solo delle colonne y_rep[1],...,y_rep[N]\nN_ppc &lt;- length(y_cont)\nyrep_mat_prior &lt;- as.matrix(yrep_mat_prior[, paste0(\"y_rep[\", 1:N_ppc, \"]\")])\n\nConfrontiamo i dati osservati con alcune repliche generate dal prior:\n\nidx &lt;- sample(seq_len(nrow(yrep_mat_prior)), 100)\n\nbayesplot::ppc_dens_overlay(\n  y = y_cont,\n  yrep = yrep_mat_prior[idx, , drop = FALSE]\n) \n\n\n\n\n\n\n\nInterpretazione:\n\nSe le distribuzioni simulate coprono bene la variabilità dei dati reali, il prior è plausibile.\nSe le simulazioni sono sistematicamente troppo larghe o troppo strette, il prior va ripensato (riducendo o ampliando mu_prior_sd).\n\n51.5.2 Posterior predictive check\nDopo aver verificato che il prior sia ragionevole, possiamo passare alla fase successiva: confrontare il modello dopo aver visto i dati.\nPer farlo, riattiviamo la verosimiglianza (compute_likelihood = 1) e stimiamo la distribuzione a posteriori di \\(\\mu\\). Nel blocco generated quantities, Stan genera anche delle repliche posterior predictive \\(y_{\\text{rep}}\\), cioè nuovi dataset simulati sotto l’ipotesi che il modello e i parametri stimati siano corretti.\nIn altre parole:\n\nil prior predictive check serve a testare le assunzioni prima dei dati,\nil posterior predictive check serve a valutare se il modello dopo i dati è in grado di riprodurre l’evidenza osservata.\n\n\nstan_data_post &lt;- list(\n  N = length(y_cont),\n  y = y_cont,\n  sigma = sigma,\n  mu0 = 100,\n  mu_prior_sd = 30,\n  compute_likelihood = 1\n)\n\nLancio del campionamento:\n\nfit_post &lt;- stanmod_ppc$sample(\n  data = stan_data_post,\n  iter_warmup = 1000,\n  iter_sampling = 10000,\n  chains = 4,\n  parallel_chains = 4,\n  seed = 4790,\n  refresh = 1000\n)\n\nEstrazione e confronto con i dati reali:\n\ny_rep &lt;- fit_post$draws(\"y_rep\", format = \"matrix\")\nppc_dens_overlay(y = stan_data_post$y, yrep = y_rep[1:100, ])\n\n\n\n\n\n\n\nInterpretazione:\n\nse la distribuzione delle repliche \\(y_{\\text{rep}}\\) copre bene la distribuzione osservata \\(y\\), significa che il modello è in grado di spiegare i dati;\nse invece ci sono scostamenti sistematici (ad es. le repliche hanno media troppo bassa, o varianza troppo alta rispetto ai dati reali), il modello non descrive adeguatamente il fenomeno e potrebbe essere rivisto.\n\nCollegamento con la verifica dei prior.\n\nUn prior troppo largo può portare a simulazioni estreme e poco plausibili prima dei dati.\nUn prior troppo stretto rischia di imporre eccessiva rigidità al modello, lasciando poca flessibilità ai dati.\nNel posterior predictive check, quello che conta è verificare che, dopo aver aggiornato il modello con i dati, le simulazioni riflettano in modo realistico il comportamento osservato.\n\nMetafora. È come provare una ricetta: prima assaggiamo l’impasto crudo per capire se gli ingredienti sono dosati bene; poi, una volta cotto, assaggiamo il piatto finito per verificare che il risultato sia quello che ci aspettavamo.\n\n51.5.3 Nota didattica\nCon \\(\\sigma\\) noto e \\(\\mu \\sim \\mathcal{N}(\\mu_0, \\tau)\\), la distribuzione predittiva a priori della media campionaria \\(\\bar{y}\\) è:\n\\[\n\\bar{y} \\sim \\mathcal{N}\\!\\big(\\mu_0,\\; \\sqrt{\\tau^2 + \\tfrac{\\sigma^2}{N}}\\big).\n\\]\nQuesta formula fornisce un controllo rapido per tarare il prior rispetto alla precisione attesa del campione. Dopo l’aggiornamento con i dati, la distribuzione a posteriori restringe l’incertezza, e le repliche posterior predictive permettono di verificarne la coerenza empirica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#riflessioni-conclusive",
    "href": "chapters/mcmc/03_stan_intro.html#riflessioni-conclusive",
    "title": "51  Introduzione pratica a Stan",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nStan rappresenta il punto di arrivo naturale del percorso che abbiamo seguito fin qui. Dopo aver compreso la logica generale dell’inferenza bayesiana con Metropolis e aver visto come i linguaggi probabilistici abbiano reso praticabile questa logica, Stan ci offre ora uno strumento concreto per applicare questi principi a modelli reali e complessi.\nIl suo valore non sta soltanto nella potenza computazionale, ma soprattutto nella possibilità di spostare l’attenzione dal calcolo all’idea scientifica. Con Stan possiamo tradurre ipotesi psicologiche in modelli formali, esplicitarne le assunzioni e ottenere inferenze riproducibili senza perdere di vista la sostanza teorica.\nIn questo senso, Stan non è solo un software: è un ambiente che incoraggia la trasparenza, la chiarezza e la cumulatività della ricerca. Nei prossimi capitoli vedremo come utilizzarlo a partire da esempi semplici, per poi affrontare modelli più ricchi. L’obiettivo è acquisire familiarità non solo con la sintassi, ma soprattutto con il modo di pensare che rende la modellazione bayesiana uno strumento essenziale per la psicologia scientifica contemporanea.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      ggridges_0.5.7        compiler_4.5.1       \n#&gt; [10] reshape2_1.4.4        systemfonts_1.2.3     vctrs_0.6.5          \n#&gt; [13] stringr_1.5.1         pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] utf8_1.2.6            rmarkdown_2.29        ps_1.9.1             \n#&gt; [22] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [25] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [28] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [31] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [34] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [37] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [40] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [43] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [46] pkgbuild_1.4.8        plyr_1.8.9            lattice_0.22-7       \n#&gt; [49] bayestestR_0.17.0     withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [52] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [55] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [58] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [61] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [64] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [67] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [70] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [73] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [76] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [79] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [82] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [85] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#bibliografia",
    "href": "chapters/mcmc/03_stan_intro.html#bibliografia",
    "title": "51  Introduzione pratica a Stan",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nNicenboim, B., Schad, D. J., & Vasishth, S. (2025). Introduction to Bayesian data analysis for cognitive science. CRC Press.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html",
    "title": "54  Analisi bayesiana dell’odds ratio",
    "section": "",
    "text": "Introduzione\nAbbiamo già incontrato il problema dell’inferenza sulle proporzioni quando abbiamo discusso il modello Beta–Binomiale. In quel contesto, grazie alla coniugazione, era stato possibile ottenere una soluzione analitica della distribuzione a posteriori. Abbiamo anche visto come la stessa logica potesse essere approssimata con una griglia, rendendo trasparente la costruzione della distribuzione.\nOra vogliamo compiere un passo ulteriore. Nei capitoli precedenti abbiamo introdotto Stan come strumento generale per l’inferenza bayesiana tramite MCMC. È arrivato il momento di metterlo in pratica, partendo da un esempio che colleghi quanto già appreso con le potenzialità di questo nuovo ambiente: l’odds ratio.\nL’odds ratio è una misura largamente utilizzata nelle scienze sociali e psicologiche. Esprime quanto la probabilità di un certo esito differisca tra due gruppi. Ad esempio, può essere usato per quantificare se la probabilità di successo in un compito sperimentale sia maggiore in un gruppo sperimentale rispetto a un gruppo di controllo.\nQuesto esempio ha un duplice scopo. Da un lato, ci permette di vedere come tradurre in Stan un modello che conosciamo già, verificando che la logica bayesiana rimane invariata: si tratta sempre di combinare priori, verosimiglianza e dati per ottenere una distribuzione a posteriori. Dall’altro lato, ci offre un primo contatto concreto con la sintassi di Stan e con il modo in cui vengono eseguiti i campionamenti MCMC, che diventeranno il nostro strumento abituale per l’analisi di modelli più complessi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#introduzione",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#introduzione",
    "title": "54  Analisi bayesiana dell’odds ratio",
    "section": "",
    "text": "Panoramica del capitolo\n\nCome si definiscono probabilità, odds e odds ratio.\nCome si interpreta l’odds ratio in contesti psicologici.\n\nCome stimarlo in ottica bayesiana, implementando un modello in Stan.\n\nCome presentare i risultati con intervalli di credibilità.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nNozioni di base su Bernoulli/Binomiale, odds e odds ratio.\nConcetto di prior e posteriore.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayesplot, ggplot2, dplyr, tibble)\nconflicts_prefer(posterior::ess_bulk)\nconflicts_prefer(posterior::ess_tail)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#il-contesto-sperimentale",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#il-contesto-sperimentale",
    "title": "54  Analisi bayesiana dell’odds ratio",
    "section": "\n54.1 Il contesto sperimentale",
    "text": "54.1 Il contesto sperimentale\nPer introdurre l’analisi bayesiana dell’odds ratio, consideriamo il seguente esperimento. Nella prima metà del Novecento, Karl von Frisch si domandò se le api possedessero la visione dei colori. Per verificarlo, ideò una serie di esperimenti in cui le api potevano associare un colore a una ricompensa. Ispirandoci a una ricostruzione proposta da Hoffmann et al. (2022), possiamo immaginare una versione semplificata del disegno sperimentale:\n\n\nGruppo sperimentale: api addestrate ad associare un disco blu a una soluzione zuccherina.\n\nGruppo di controllo: api che non ricevono alcun addestramento.\n\nNella fase di test, la soluzione zuccherina viene rimossa, e si registra il numero di volte in cui le api si avvicinano al disco blu (evento critico).\nI risultati osservati sono riportati nella tabella seguente:\n\n\nGruppo\nSuccessi (scelta blu)\nTotale\n\n\n\nSperimentale\n130\n200\n\n\nControllo\n100\n200\n\n\n\nLa domanda di ricerca può essere così formulata: le api addestrate mostrano un odds maggiore di scegliere il disco blu rispetto alle api di controllo?\n\n54.1.1 Dalle probabilità agli odds\nLa probabilità di successo (scelta del blu) nel gruppo sperimentale è:\n\\[\np_1 = \\frac{130}{200} = 0.65.\n\\]\nI corrispondenti odds si calcolano come:\n\\[\n\\text{odds}_1 = \\frac{p_1}{1-p_1} = \\frac{0.65}{0.35} \\approx 1.86.\n\\]\nPer il gruppo di controllo:\n\\[\np_2 = \\frac{100}{200} = 0.50, \\quad \\text{odds}_2 = \\frac{0.50}{0.50} = 1.00.\n\\]\n\n54.1.2 Calcolo dell’odds ratio\nL’odds ratio (OR) confronta i due odds:\n\\[\n\\text{OR} = \\frac{\\text{odds}_1}{\\text{odds}_2} = \\frac{1.86}{1.00} \\approx 1.86.\n\\]\nInterpretazione: le api addestrate presentano odds circa 1.9 volte maggiori di scegliere il disco blu rispetto alle api non addestrate. Questo non implica che la loro probabilità sia raddoppiata, ma che il rapporto tra successi e insuccessi risulta quasi doppio.\nQuanto è affidabile questa stima? È a questo punto che l’approccio bayesiano mostra il suo valore: anziché limitarci a una stima puntuale, possiamo ottenere un’intera distribuzione a posteriori per l’OR, che esprime la nostra incertezza dopo aver osservato i dati.\n\n54.1.3 Approccio bayesiano\nNell’approccio frequentista, l’odds ratio viene stimato come rapporto tra stime puntuali, accompagnato da un intervallo di confidenza derivato da approssimazioni asintotiche. L’approccio bayesiano, al contrario, fornisce direttamente la distribuzione a posteriori dell’odds ratio, offrendo diversi vantaggi interpretativi:\n\n\nProbabilità diretta: possiamo calcolare la probabilità che l’OR sia maggiore di 1;\n\nValutazione di equivalenza: possiamo determinare la probabilità che l’OR ricada in un intervallo di equivalenza pratica (ROPE);\n\nIntervalli di credibilità: possiamo ottenere intervalli di credibilità esatti (ETI o HDI) senza ricorrere ad approssimazioni asintotiche.\n\nQuesto framework consente non solo una rappresentazione più intuitiva dei risultati, ma permette anche di rispondere direttamente a domande inferenziali in termini probabilistici. Ad esempio: qual è la probabilità che le api addestrate mostrino effettivamente una preferenza maggiore per il blu? O, più formalmente: qual è la probabilità che l’OR sia maggiore di 1?\n\n54.1.4 Relazione con la regressione logistica\nIl collegamento fondamentale emerge nell’ambito della regressione logistica. Modellando la probabilità di successo \\(p_i\\) mediante un modello logit:\n\\[\n\\text{logit}(p_i) = \\alpha + \\beta \\cdot x_i,\n\\] dove \\(x_i\\) è una variabile indicatrice (0 = gruppo di controllo, 1 = gruppo sperimentale), si ottiene che:\n\n\n\\(\\exp(\\beta)\\) corrisponde esattamente all’odds ratio tra il gruppo sperimentale e quello di controllo.\n\nCiò implica che la stima di un modello di regressione logistica binaria equivale alla stima dell’odds ratio, con il notevole vantaggio di poter estendere agevolmente il modello all’inclusione di ulteriori predittori, covariate o strutture gerarchiche.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#versione-con-modello-logistico",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#versione-con-modello-logistico",
    "title": "54  Analisi bayesiana dell’odds ratio",
    "section": "\n54.2 Versione con modello logistico",
    "text": "54.2 Versione con modello logistico\nI dati vengono rappresentati a livello individuale: ogni ape è codificata come 1 (ha scelto il blu) o 0 (non ha scelto il blu).\n\n# Dati individuali\ny &lt;- c(rep(1, 130), rep(0, 70),   # gruppo sperimentale: 130 successi, 70 insuccessi\n       rep(1, 100), rep(0, 100))  # gruppo di controllo: 100 successi, 100 insuccessi\nx &lt;- c(rep(1, 200), rep(0, 200))  # 1 = sperimentale, 0 = controllo\n\ndata_list &lt;- list(N = length(y), y = y, x = x)\nglimpse(data_list)\n#&gt; List of 3\n#&gt;  $ N: int 400\n#&gt;  $ y: num [1:400] 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ x: num [1:400] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n54.2.1 Specifica del modello in Stan\n\nstancode_or &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;                  // numero totale di osservazioni\n  array[N] int&lt;lower=0,upper=1&gt; y; // esito binario (0/1)\n  vector[N] x;                     // variabile indicatrice del gruppo (0 = controllo, 1 = sperimentale)\n}\nparameters {\n  real alpha;    // intercetta (log-odds nel gruppo di controllo)\n  real beta;     // coefficiente (differenza in log-odds tra gruppo sperimentale e controllo)\n}\nmodel {\n  // Priors\n  alpha ~ normal(0, 5);\n  beta  ~ normal(0, 5);\n  \n  // Likelihood\n  y ~ bernoulli_logit(alpha + beta * x);\n}\ngenerated quantities {\n  real OR = exp(beta);  // odds ratio\n}\n\"\n\n\n54.2.1.1 Compilazione ed esecuzione del modello\n\nstanmod_or &lt;- cmdstanr::cmdstan_model(write_stan_file(stancode_or))\n\nfit_or &lt;- stanmod_or$sample(\n  data = data_list,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4,\n  seed = 123,\n  refresh = 0\n)\n\n\n54.2.1.2 Interpretazione dei risultati\nRiassunto dei parametri di interesse:\n\nprint(fit_or$summary(c(\"alpha\", \"beta\", \"OR\")), n = Inf)\n#&gt; # A tibble: 3 × 10\n#&gt;   variable   mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha    -0.004 -0.004 0.144 0.144 -0.240 0.232 1.001 5152.630 6997.882\n#&gt; 2 beta      0.628  0.626 0.208 0.208  0.288 0.970 1.000 5183.414 7043.458\n#&gt; 3 OR        1.914  1.870 0.403 0.386  1.333 2.638 1.000 5183.414 7043.458\n\n\n\nalpha: log-odds di successo nel gruppo di controllo\n\nbeta: differenza nei log-odds tra gruppo sperimentale e controllo\n\nOR: odds ratio (exp(beta))\n\nDistribuzione a posteriori dell’OR:\n\nposterior::summarise_draws(\n  fit_or$draws(\"OR\"),\n  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))\n)\n#&gt; # A tibble: 1 × 6\n#&gt;   variable  mean    sd `2.5%` `50%` `97.5%`\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 OR       1.914 0.403  1.254 1.870   2.816\n\nIl output mostra media, deviazione standard, mediana e intervallo di credibilità al 95% per l’odds ratio.\nVisualizzazione della distribuzione a posteriori:\n\nbayesplot::mcmc_hist(fit_or$draws(\"OR\")) +\n  xlab(\"Odds Ratio\") + ylab(\"Densità\")\n\n\n\n\n\n\n\n\nbayesplot::mcmc_areas(fit_or$draws(\"OR\"), prob = 0.95) +\n  xlab(\"Odds Ratio\")\n\n\n\n\n\n\n\nI grafici mostrano chiaramente che la distribuzione dell’odds ratio è concentrata su valori superiori a 1, con alta probabilità.\nInterpretazione: I risultati forniscono evidenza credibile che l’addestramento aumenta le probabilità che le api scelgano il disco blu rispetto al gruppo di controllo. La distribuzione a posteriori dell’OR indica che questo effetto è statisticamente credibile e praticamente significativo.\n\n54.2.1.3 Diagnostica essenziale\n\n# Indicatori numerici chiave: Rhat ~ 1, ESS adeguati\nposterior::summarize_draws(\n  fit_or$draws(c(\"alpha\",\"beta\",\"OR\")),\n  \"rhat\", \"ess_bulk\", \"ess_tail\"\n)\n#&gt; # A tibble: 3 × 4\n#&gt;   variable  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha    1.001 5152.630 6997.882\n#&gt; 2 beta     1.000 5183.414 7043.458\n#&gt; 3 OR       1.000 5183.414 7043.458\n\n\n# Traceplot di controllo su OR\nbayesplot::mcmc_trace(fit_or$draws(\"OR\")) \n\n\n\n\n\n\n\nSe emergono problemi (Rhat &gt; 1.01, ESS basso, divergenze riportate in output), conviene aumentare iter_warmup/iter_sampling, alzare adapt_delta o, in ultima istanza, riconsiderare i prior se sono eccessivamente stretti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#versione-binomiale-con-prior-beta",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#versione-binomiale-con-prior-beta",
    "title": "54  Analisi bayesiana dell’odds ratio",
    "section": "\n54.3 Versione binomiale con prior Beta",
    "text": "54.3 Versione binomiale con prior Beta\nUn approccio alternativo alla stima dell’odds ratio consiste nel modellare separatamente le proporzioni di successo nei due gruppi utilizzando distribuzioni binomiali con prior Beta. Questo metodo risulta particolarmente intuitivo quando i dati sono naturalmente aggregabili in una tabella 2×2.\nL’odds ratio viene calcolato come trasformazione delle due probabilità stimate:\n\\[\n\\text{OR} = \\frac{\\theta_1/(1-\\theta_1)}{\\theta_2/(1-\\theta_2)} = \\exp\\left(\\operatorname{logit}(\\theta_1) - \\operatorname{logit}(\\theta_2)\\right)\n\\]\nQuesta formulazione offre una trasparenza didattica immediata: stimiamo separatamente le probabilità di successo nei due gruppi per poi derivare l’effetto di interesse. La scelta di prior Beta(2,2) per entrambi i parametri mantiene coerenza con le impostazioni del capitolo, utilizzando prior debolmente informative.\n\n54.3.1 Implementazione in Stan: modello Beta-Binomiale\n\nstancode_or_beta &lt;- \"\ndata {\n  int&lt;lower=0&gt; k1;  // numero di successi nel gruppo sperimentale\n  int&lt;lower=1&gt; n1;  // numero totale di prove nel gruppo sperimentale\n  int&lt;lower=0&gt; k2;  // numero di successi nel gruppo di controllo\n  int&lt;lower=1&gt; n2;  // numero totale di prove nel gruppo di controllo\n}\nparameters {\n  real&lt;lower=0,upper=1&gt; theta1;  // probabilità di successo nel gruppo sperimentale\n  real&lt;lower=0,upper=1&gt; theta2;  // probabilità di successo nel gruppo di controllo\n}\nmodel {\n  // Prior distributions\n  theta1 ~ beta(2, 2);\n  theta2 ~ beta(2, 2);\n  \n  // Likelihood\n  k1 ~ binomial(n1, theta1);\n  k2 ~ binomial(n2, theta2);\n}\ngenerated quantities {\n  real logOR = logit(theta1) - logit(theta2);  // log-odds ratio\n  real OR = exp(logOR);                        // odds ratio\n}\n\"\n\n\n# Dati aggregati per il modello binomiale\ndata_list_beta &lt;- list(\n  k1 = 130, n1 = 200,  # gruppo sperimentale: 130 successi su 200 prove\n  k2 = 100, n2 = 200   # gruppo di controllo: 100 successi su 200 prove\n)\n\n\n54.3.1.1 Compilazione ed esecuzione del modello\n\nstanmod_or_beta &lt;- cmdstanr::cmdstan_model(write_stan_file(stancode_or_beta))\n\nfit_or_beta &lt;- stanmod_or_beta$sample(\n  data = data_list_beta,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4,\n  parallel_chains = 4,\n  seed = 123,\n  refresh = 0\n)\n\n\n54.3.1.2 Analisi comparativa dei risultati\nRiassunti posteriori per il modello Beta-Binomiale:\n\nposterior::summarise_draws(\n  fit_or_beta$draws(c(\"theta1\", \"theta2\", \"logOR\", \"OR\")),\n  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))\n)\n#&gt; # A tibble: 4 × 6\n#&gt;   variable  mean    sd `2.5%` `50%` `97.5%`\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 theta1   0.647 0.034  0.579 0.648   0.712\n#&gt; 2 theta2   0.500 0.035  0.432 0.500   0.569\n#&gt; 3 logOR    0.610 0.204  0.207 0.611   1.004\n#&gt; 4 OR       1.880 0.387  1.230 1.841   2.729\n\nConfronto degli intervalli di credibilità tra i due approcci:\n\nsumm_logit &lt;- posterior::summarise_draws(\n  fit_or$draws(\"OR\"),\n  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))\n)\nsumm_beta &lt;- posterior::summarise_draws(\n  fit_or_beta$draws(\"OR\"),\n  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))\n)\n\nlist(Regressione_Logistica = summ_logit, Beta_Binomiale = summ_beta)\n#&gt; $Regressione_Logistica\n#&gt; # A tibble: 1 × 6\n#&gt;   variable  mean    sd `2.5%` `50%` `97.5%`\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 OR       1.914 0.403  1.254 1.870   2.816\n#&gt; \n#&gt; $Beta_Binomiale\n#&gt; # A tibble: 1 × 6\n#&gt;   variable  mean    sd `2.5%` `50%` `97.5%`\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 OR       1.880 0.387  1.230 1.841   2.729\n\nConfronto visivo delle distribuzioni posteriori:\n\nOR_logit &lt;- as.numeric(fit_or$draws(\"OR\"))\nOR_beta &lt;- as.numeric(fit_or_beta$draws(\"OR\"))\n\ntibble(\n  OR = c(OR_logit, OR_beta),\n  Modello = rep(c(\"Regressione Logistica\", \"Beta-Binomiale\"), \n                c(length(OR_logit), length(OR_beta)))\n) |&gt;\n  ggplot(aes(x = OR, fill = Modello)) +\n  geom_density(alpha = 0.4) +\n  labs(x = \"Odds Ratio\", y = \"Densità\")\n\n\n\n\n\n\n\nProbabilità a posteriori che l’OR sia maggiore di 1:\n\nc(\n  Regressione_Logistica = mean(OR_logit &gt; 1),\n  Beta_Binomiale = mean(OR_beta &gt; 1)\n)\n#&gt; Regressione_Logistica        Beta_Binomiale \n#&gt;                 0.999                 0.999",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#considerazioni-metodologiche",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#considerazioni-metodologiche",
    "title": "54  Analisi bayesiana dell’odds ratio",
    "section": "\n54.4 Considerazioni metodologiche",
    "text": "54.4 Considerazioni metodologiche\nI due approcci producono risultati sostanzialmente equivalenti, confermando la robustezza delle conclusioni inferenziali. La scelta tra le due specificazioni dipende da considerazioni pratiche e comunicative:\n\nRegressione logistica: Ideale per dati individuali e modelli che includono multiple covariate. Offre maggiore flessibilità per estensioni multivariate.\nModello Beta-Binomiale: Particolarmente adatto per dati aggregati in tabelle di contingenza. Risulta più intuitivo per comprendere il meccanismo di stima delle proporzioni sottostanti.\n\nEntrambi gli approcci conducono alle stesse conclusioni sostanziali riguardo all’effetto dell’addestramento sulla preferenza delle api per il disco blu, dimostrando la coerenza dei metodi bayesiani nella stima dell’odds ratio.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#riflessioni-conclusive",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#riflessioni-conclusive",
    "title": "54  Analisi bayesiana dell’odds ratio",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nQuesto capitolo ci ha mostrato come l’inferenza bayesiana sulle proporzioni, che inizialmente avevamo affrontato con soluzioni analitiche e metodi su griglia, possa essere espressa ed eseguita direttamente in Stan. L’uso dell’odds ratio come esempio ha evidenziato due aspetti fondamentali.\nPrimo, la continuità concettuale: Stan non cambia la logica dell’inferenza bayesiana. Il cuore rimane lo stesso – campionare dalla distribuzione a posteriori per descrivere la nostra incertezza sui parametri – ma la potenza computazionale consente di applicarlo a modelli più articolati senza dover ricorrere a soluzioni chiuse.\nSecondo, l’aspetto pratico: attraverso questo esempio abbiamo visto come Stan possa diventare uno strumento quotidiano per l’analisi dei dati psicologici, anche nei casi in cui i modelli sono relativamente semplici. In questo senso, l’odds ratio rappresenta un ponte: ci permette di acquisire familiarità con Stan su un terreno noto, preparandoci a utilizzarlo in contesti più complessi, come i modelli di Poisson o i modelli gerarchici.\nIn prospettiva, la lezione più importante di questo capitolo è che l’inferenza bayesiana non deve più essere limitata ai casi “risolvibili” a mano o con approssimazioni semplicistiche. Con Stan, la logica bayesiana diventa praticabile in modo sistematico e riproducibile, aprendo la strada a un uso più maturo e trasparente dei modelli statistici nella ricerca psicologica.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      ggridges_0.5.7        compiler_4.5.1       \n#&gt; [10] reshape2_1.4.4        systemfonts_1.2.3     vctrs_0.6.5          \n#&gt; [13] stringr_1.5.1         pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] utf8_1.2.6            rmarkdown_2.29        ps_1.9.1             \n#&gt; [22] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [25] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [28] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [31] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [34] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [37] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [40] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [43] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [46] pkgbuild_1.4.8        plyr_1.8.9            lattice_0.22-7       \n#&gt; [49] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [52] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [55] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [58] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [61] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [64] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [67] data.table_1.17.8     mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [70] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [73] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [76] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [79] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [82] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [85] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#bibliografia",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#bibliografia",
    "title": "54  Analisi bayesiana dell’odds ratio",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoffmann, T., Hofman, A., & Wagenmakers, E.-J. (2022). Bayesian tests of two proportions: A tutorial with R and JASP. Methodology, 18(4), 239–277.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html",
    "title": "55  Modello di Poisson",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto come utilizzare Stan per analizzare un problema familiare, quello delle proporzioni, introducendo l’odds ratio come primo esempio pratico. In questo capitolo allarghiamo l’orizzonte a un’altra classe di dati molto comune in psicologia: i conteggi.\nMolti fenomeni sperimentali e clinici si presentano sotto forma di conteggi. Pensiamo al numero di errori commessi in un compito di attenzione, al numero di risposte corrette in una sessione di apprendimento, o al numero di episodi sintomatici riportati in un diario clinico. In tutti questi casi, il modello probabilistico di riferimento è spesso la distribuzione di Poisson, che descrive il numero di eventi osservati in un dato intervallo di tempo o di prove, quando gli eventi hanno una probabilità media di verificarsi.\nIl modello di Poisson rappresenta quindi un banco di prova ideale per consolidare due aspetti fondamentali: da un lato, la generalità dell’inferenza bayesiana – la logica rimane la stessa, cambiano solo la forma della verosimiglianza e i parametri da stimare –; dall’altro, la potenza di Stan come strumento pratico per affrontare modelli che, pur essendo concettualmente semplici, diventano rapidamente complicati se implementati a mano.\nIn questo capitolo mostreremo come specificare e stimare un modello di Poisson in Stan, partendo da un esempio psicologico concreto. Questo ci consentirà di acquisire familiarità con un nuovo tipo di dati e di consolidare la logica bayesiana in un contesto diverso, preparandoci ad affrontare nei capitoli successivi modelli più articolati e multilivello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#introduzione",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#introduzione",
    "title": "55  Modello di Poisson",
    "section": "",
    "text": "Panoramica del capitolo\n\nCapire quando usare un modello di Poisson (conteggi non negativi, tendenzialmente rari, indipendenti dato il tasso).\nScrivere un modello in Stan con parametri su scala naturale (qui: lambda come tasso medio).\nImpostare prior debolmente informative su lambda o sul suo log (per mantenere positività e stabilità numerica).\nEseguire stima MCMC con cmdstanr e leggere i diagnostici di convergenza.\nFare posterior predictive checks (PPC) per valutare l’adeguatezza del modello.\n\n\n\n\n\n\n\nPerché questo esempio?\n\n\n\n\n\nIn questo capitolo non vogliamo solo calcolare una media dal campione, ma imparare a:\n\nstimare il tasso medio di occorrenza nella popolazione a partire dai dati osservati;\n\nesprimere anche la nostra incertezza su quel tasso, non solo un singolo numero;\n\ntradurre un modello teorico (Poisson con prior Gamma) in un modello computazionale in Stan;\n\nverificare che Stan fornisce gli stessi risultati della soluzione analitica, così da prendere confidenza con il workflow MCMC.\n\nQuesto esempio funziona come una “palestra”: semplice, ma ci prepara ad affrontare modelli più complessi in cui non avremo formule chiuse e l’uso di Stan diventerà indispensabile.\n\n\n\n\n\n\n\n\n\nPerché studiare il modello di Poisson?\n\n\n\n\n\n\nMolti dati psicologici si presentano come conteggi (episodi comportamentali, risposte corrette, eventi clinici).\n\nIl modello di Poisson è lo strumento naturale per stimare il tasso medio di occorrenza di questi eventi.\n\nL’approccio bayesiano ci permette non solo di stimare questo tasso, ma anche di esprimere in modo chiaro la nostra incertezza.\n\nIn questo capitolo usiamo il Poisson come primo esempio pratico per imparare a scrivere e stimare un modello in Stan.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayesplot, ggplot2, tidyverse, tibble)\nconflicts_prefer(posterior::ess_bulk)\nconflicts_prefer(posterior::ess_tail)\nconflicts_prefer(dplyr::count)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#dal-modello-teorico-al-modello-computazionale",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#dal-modello-teorico-al-modello-computazionale",
    "title": "55  Modello di Poisson",
    "section": "\n55.1 Dal modello teorico al modello computazionale",
    "text": "55.1 Dal modello teorico al modello computazionale\nQuando raccogliamo dati in psicologia, non ci interessa solo descrivere quello che è accaduto nel nostro campione, ma soprattutto stimare il processo che genera i dati nella popolazione.\nImmaginiamo di osservare, in otto finestre temporali di pari durata, quante volte si verifica un certo evento psicologico o comportamentale. Per esempio, il numero di compulsioni in otto momenti della giornata, oppure il numero di telefonate ricevute in otto turni orari.\nI dati raccolti sono:\n\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\nAbbiamo quindi \\(N = 8\\) osservazioni. Dal campione potremmo calcolare una semplice media (\\(\\bar y = 1.625\\)), ma questo ci dice solo quanto spesso l’evento è avvenuto nei nostri dati. La domanda più interessante è:\n\nqual è il tasso medio di occorrenza nella popolazione?\n\nChiamiamo questo tasso \\(\\lambda\\): il numero medio di eventi attesi in una finestra temporale.\n\n55.1.1 Perché serve un modello probabilistico?\nI dati osservati sono solo un piccolo campione e possono variare da una raccolta all’altra. Un modello probabilistico ci serve per due motivi principali:\n\n\nSeparare il segnale dal rumore: capire quanto dell’andamento osservato è dovuto al caso e quanto riflette una regolarità della popolazione.\n\nQuantificare l’incertezza: non ci basta stimare \\(\\lambda\\), vogliamo anche dire quanto siamo sicuri (o incerti) di quella stima.\n\n55.1.2 Il modello di Poisson\nPer i fenomeni di conteggio (quante volte un evento si verifica in un intervallo), il modello naturale è la distribuzione di Poisson:\n\\[\ny_i \\sim \\text{Poisson}(\\mu_i), \\qquad \\mu_i = \\lambda \\cdot t_i\n\\] dove:\n\n\n\\(y_i\\) è il numero osservato di eventi nella finestra \\(i\\),\n\n\\(t_i\\) è la durata della finestra,\n\n\\(\\lambda\\) è il tasso medio.\n\nNel nostro caso tutte le finestre hanno la stessa durata (\\(t_i = 1\\)), e quindi:\n\\[\nP(y_i \\mid \\lambda) = \\frac{\\lambda^{y_i} e^{-\\lambda}}{y_i!},\n\\qquad \\mathbb{E}[y_i]=\\lambda, \\quad \\mathrm{Var}(y_i)=\\lambda.\n\\] In parole semplici: \\(\\lambda\\) rappresenta quanti eventi in media ci aspettiamo per finestra.\n\n\n\n\n\n\nEsempi in psicologia\n\n\n\n\n\nModelli di questo tipo compaiono spesso anche nella ricerca psicologica.\nAlcuni esempi:\n\n\nClinica: numero di episodi compulsivi o attacchi di panico osservati in un certo periodo.\n\n\nPsicologia dello sviluppo: numero di parole nuove prodotte da un bambino in un giorno.\n\n\nPsicologia cognitiva: numero di risposte corrette in una serie di prove a tempo.\n\n\nPsicologia sociale: numero di interazioni tra membri di un gruppo osservate in una sessione.\n\nIn tutti questi casi, il modello di Poisson ci aiuta a stimare il tasso medio di occorrenza dell’evento di interesse e l’incertezza che accompagna tale stima.\n\n\n\n\n55.1.3 La distribuzione a priori\nNell’approccio bayesiano dobbiamo dichiarare che cosa riteniamo plausibile per \\(\\lambda\\) prima di osservare i dati. Per i modelli di Poisson la scelta naturale è la distribuzione Gamma. Ad esempio, una prior Gamma(9, 2) esprime l’idea che, prima di osservare i dati, ci aspettiamo circa 4–5 eventi per finestra, ma lasciamo spazio a una certa variabilità.\n\n55.1.4 Perché usiamo Stan?\nPotremmo calcolare la distribuzione a posteriori anche con formule chiuse (qui la posterior è ancora una Gamma). Ma usiamo Stan per due motivi didattici fondamentali:\n\n\nGeneralizzare: nella pratica incontreremo modelli per cui non esiste una soluzione analitica semplice. Con Stan impariamo un workflow valido in tutti i casi.\n\nQuantificare l’incertezza: Stan ci fornisce direttamente campioni dalla distribuzione a posteriori, che possiamo usare per costruire intervalli credibili, fare previsioni, confrontare modelli, ecc.\n\n\n\n\n\n\n\nUn caso semplice per allenarsi\n\n\n\n\n\nIn questo esempio l’uso di Stan può sembrare eccessivo, perché sappiamo già che la posterior è una Gamma e potremmo calcolarla con una formula.\nIl punto, però, è proprio esercitarsi: usiamo un caso semplice come “palestra” per imparare un workflow (specificare un modello, campionare con MCMC, analizzare la posterior) che ci sarà indispensabile quando i modelli diventeranno più realistici e complessi, e non avremo più scorciatoie analitiche.\n\n\n\n\n55.1.5 Obiettivi del modello in Stan\nCon questo primo esempio vogliamo:\n\nstimare \\(\\lambda\\), il tasso medio di occorrenza nella popolazione;\nottenere una misura della nostra incertezza su \\(\\lambda\\);\nverificare che i campioni generati da Stan coincidano con i risultati della formula analitica (dove è disponibile).\n\nIn questo modo ci abituiamo a un flusso di lavoro che useremo anche per modelli molto più complessi, in cui solo un approccio computazionale ci permette di fare inferenza bayesiana.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#scrivere-il-modello-in-stan",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#scrivere-il-modello-in-stan",
    "title": "55  Modello di Poisson",
    "section": "\n55.2 Scrivere il modello in Stan",
    "text": "55.2 Scrivere il modello in Stan\nUn modello Stan è diviso in blocchi: data (dati), parameters (incognite), model (priori + verosimiglianza). Aggiungiamo anche generated quantities per quantità derivate utili al confronto con la soluzione analitica (e, volendo, per LOO).\nPer evitare dipendenze da percorsi locali, creiamo e compiliamo il modello direttamente dalla stringa:\n\nstan_code &lt;- \"\ndata {\n  int&lt;lower=0&gt; N;\n  array[N] int&lt;lower=0&gt; y;\n  real&lt;lower=0&gt; alpha_prior;\n  real&lt;lower=0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0&gt; lambda;\n}\nmodel {\n  lambda ~ gamma(alpha_prior, beta_prior);\n  y ~ poisson(lambda);\n}\ngenerated quantities {\n  real alpha_post = alpha_prior + sum(y);\n  real beta_post  = beta_prior + N;\n  array[N] real log_lik;\n  for (i in 1:N) log_lik[i] = poisson_lpmf(y[i] | lambda);\n}\n\"\n\nCompiliamo:\n\nmod &lt;- cmdstan_model(write_stan_file(stan_code))\n\nPrepariamo i dati:\n\nN &lt;- length(y)\nalpha_prior &lt;- 9\nbeta_prior  &lt;- 2\n\nstan_data &lt;- list(N = N, y = y, alpha_prior = alpha_prior, beta_prior = beta_prior)\n\nUna volta preparati i dati, lanciamo il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 3000,\n  iter_warmup = 2000,\n  refresh = 0\n)\n\n\n55.2.1 Analizzare i risultati\nUna volta che Stan ha terminato il campionamento, otteniamo migliaia di valori possibili di \\(\\lambda\\), campionati dalla distribuzione a posteriori. Questi valori ci permettono di “vedere” la distribuzione a posteriori invece di calcolarla solo con una formula.\n\n55.2.1.1 Estraiamo i campioni di \\(\\lambda\\)\n\nEstraiamo i valori campionati di λ dalla posterior. L’oggetto draws restituisce tutti i campioni MCMC, noi qui selezioniamo solo il parametro lambda:\n\nposterior_draws &lt;- fit$draws(\"lambda\", format = \"df\")\n\nCreiamo un vettore con solo i valori di lambda:\n\nlambda_samples &lt;- posterior_draws$lambda\n\nOra lambda_samples contiene migliaia di valori di \\(\\lambda\\): possiamo usarli per calcolare media, intervalli credibili e per costruire grafici.\n\nlength(lambda_samples)\n#&gt; [1] 12000\nhead(lambda_samples)\n#&gt; [1] 1.68 1.52 1.48 2.83 2.84 3.01\n\n\n55.2.1.2 Calcoliamo i parametri della distribuzione posteriore teorica\nDato che in questo caso abbiamo una posterior coniugata, conosciamo la formula esatta della distribuzione a posteriori (Gamma). Ci serve per confrontarla con i campioni generati da Stan:\n\nalpha_post &lt;- alpha_prior + sum(y)   # nuovo parametro shape\nbeta_post  &lt;- beta_prior + N         # nuovo parametro rate\n\n\n55.2.1.3 Confrontiamo i due risultati (MCMC vs formula)\nCreiamo un grafico che mostri l’istogramma dei campioni ottenuti con Stan (in azzurro) e la curva della distribuzione Gamma calcolata analiticamente (in rosso).\n\nggplot(data.frame(lambda = lambda_samples), aes(x = lambda)) +\n  # Istogramma dei campioni posteriori\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 50,\n    alpha = 0.7\n  ) +\n  # Curva teorica Gamma con parametri aggiornati\n  stat_function(\n    fun = function(x) dgamma(x, shape = alpha_post, rate = beta_post),\n    linewidth = 1.2\n  ) +\n  labs(\n    x = \"λ (tasso medio di occorrenza)\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nIl confronto visivo è molto utile:\n\nl’istogramma mostra la distribuzione stimata con Stan tramite campionamento MCMC,\nla curva rossa rappresenta la distribuzione teorica Gamma–Poisson che conosciamo già.\n\nSe le due coincidono (entro piccole fluttuazioni casuali), significa che Stan ha fatto un buon lavoro: il nostro workflow MCMC funziona!\n\n55.2.2 Intervallo di credibilità\nUn grande vantaggio dell’approccio bayesiano è che non otteniamo solo una stima puntuale di \\(\\lambda\\), ma una distribuzione completa dei valori plausibili. Da questa distribuzione possiamo ricavare un intervallo di credibilità: un intervallo che contiene, ad esempio, il 94% o il 95% della massa a posteriori.\n\n55.2.2.1 Calcoliamo i quantili della distribuzione\nCalcoliamo i quantili al 3%, 50% (mediana) e 97%:\n\ncred_interval &lt;- quantile(lambda_samples, probs = c(0.03, 0.5, 0.97))\ncred_interval\n#&gt;   3%  50%  97% \n#&gt; 1.42 2.17 3.18\n\n\nil valore al 50% è la mediana della distribuzione a posteriori,\ni valori al 3% e 97% delimitano un intervallo centrale che contiene il 94% della distribuzione.\n\n55.2.2.2 Interpretazione dei risultati\nI risultati ottenuti indicano che:\n\nil valore “tipico” di \\(\\lambda\\) (mediana) è circa 2.2 eventi per finestra,\nc’è un 94% di probabilità che \\(\\lambda\\) si trovi tra 1.42 e 3.20.\n\nL’informazione più importante non è tanto la stima puntuale (2.2), ma il fatto che possiamo quantificare la nostra incertezza: la posterior ci dice chiaramente quali valori di \\(\\lambda\\) sono più o meno plausibili.\n\n55.2.3 Diagnostica essenziale\nDopo il campionamento MCMC, è fondamentale verificare che le catene abbiano esplorato bene la distribuzione a posteriori. Per questo guardiamo due tipi di informazioni: indici numerici (come \\(\\hat{R}\\) e ESS) e grafici delle catene (traceplot).\nPossiamo ottenere una sintesi numerica della distribuzione a posteriore dei parametri con la funzione summarise_draws del pacchetto posterior:\n\nposterior::summarise_draws(fit$draws(\"lambda\"), rhat, ess_bulk, ess_tail)\n#&gt; # A tibble: 1 × 4\n#&gt;   variable  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lambda   1.002 4666.651 6265.973\n\n\n\\(\\hat{R}\\) (R-hat): misura la convergenza delle catene. Valori vicini a 1.00 indicano che le catene si sono mescolate bene; valori maggiori di 1.01 segnalano possibili problemi.\n\nESS (Effective Sample Size): indica quanti campioni “indipendenti” equivalenti abbiamo ottenuto.\n\n\ness_bulk valuta la precisione delle stime centrali (media, mediana).\n\ness_tail valuta la precisione nelle code della distribuzione (intervalli credibili). Più sono grandi, meglio è: in genere migliaia di campioni equivalenti sono più che sufficienti.\n\n\n\nPossiamo generare un traceplot con la funzione mcmc_trace di bayesplot:\n\nbayesplot::mcmc_trace(fit$draws(\"lambda\")) \n\n\n\n\n\n\n\nIl traceplot mostra l’andamento dei valori di \\(\\lambda\\) campionati dalle diverse catene. Se le catene:\n\noscillano liberamente attorno alla stessa regione,\nsenza trend sistematici o salti strani,\n\nallora possiamo concludere che il campionamento è avvenuto correttamente.\nIn sintesi: se \\(\\hat{R} \\approx 1\\), ESS è elevato e i traceplot sono ben mescolati, possiamo fidarci delle stime ottenute.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#sparatorie-mortali",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#sparatorie-mortali",
    "title": "55  Modello di Poisson",
    "section": "\n55.3 Sparatorie mortali",
    "text": "55.3 Sparatorie mortali\nNella sezione precedente abbiamo esaminato il processo di derivazione della distribuzione a posteriori per i parametri della distribuzione Gamma, la quale viene impiegata quando si adotta un prior Gamma per una verosimiglianza di Poisson. In questo esempio, useremo tale metodo per affrontare una questione relativa all’analisi di un set di dati reali.\n\n55.3.1 Domanda della ricerca\nCome spiegato qui, i dati che esamineremo sono raccolti dal Washington Post con lo scopo di registrare ogni sparatoria mortale negli Stati Uniti ad opera di agenti di polizia, a partire dal 1° gennaio 2015. Il Washington Post ha adottato un approccio sistematico e accurato nella raccolta di queste informazioni, fornendo dati che possono essere utili per valutare i problemi legati alla violenza delle forze di polizia negli Stati Uniti.\nObiettivo. Stimare, per il periodo 2015–ultimo anno completo disponibile, il tasso medio annuo e l’incertezza associata. Poiché il 2025 è incompleto, lo escludiamo.\n\n55.3.2 Svolgimento con R\n\n55.3.2.1 Importazione e pre-processing dei dati\n\n# URL del dataset\nurl &lt;- \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\n\n# Importa i dati\nfps_dat &lt;- read_csv(url, show_col_types = FALSE)\n\n# Conversione colonna date\nfps_dat &lt;- fps_dat %&gt;%\n  mutate(date = ymd(date),\n         year = year(date))\n\n# Esamina le colonne disponibili\ncolnames(fps_dat)\n#&gt;  [1] \"id\"                         \"date\"                      \n#&gt;  [3] \"threat_type\"                \"flee_status\"               \n#&gt;  [5] \"armed_with\"                 \"city\"                      \n#&gt;  [7] \"county\"                     \"state\"                     \n#&gt;  [9] \"latitude\"                   \"longitude\"                 \n#&gt; [11] \"location_precision\"         \"name\"                      \n#&gt; [13] \"age\"                        \"gender\"                    \n#&gt; [15] \"race\"                       \"race_source\"               \n#&gt; [17] \"was_mental_illness_related\" \"body_camera\"               \n#&gt; [19] \"agency_ids\"                 \"year\"\n\n# Filtra eliminando i casi con year == 2025\nfps &lt;- fps_dat %&gt;%\n  filter(year != 2025)\n\n# Conta le occorrenze per anno\nyear_counts &lt;- fps %&gt;%\n  count(year, name = \"events\")\n\n# Mostra i risultati\nprint(year_counts)\n#&gt; # A tibble: 10 × 2\n#&gt;     year events\n#&gt;    &lt;dbl&gt;  &lt;int&gt;\n#&gt;  1  2015    995\n#&gt;  2  2016    959\n#&gt;  3  2017    984\n#&gt;  4  2018    992\n#&gt;  5  2019    993\n#&gt;  6  2020   1021\n#&gt;  7  2021   1050\n#&gt;  8  2022   1097\n#&gt;  9  2023   1164\n#&gt; 10  2024   1175\n\n\n55.3.2.2 Modello di Poisson (pooling completo)\nAssumiamo \\(y_t \\sim \\text{Poisson}(\\lambda)\\) con \\(\\lambda\\) costante sul periodo:\n\\[\ny_t \\,\\sim\\, \\text{Poisson}(\\lambda), \\quad t=1,\\dots,n.\n\\]\nIl supporto di \\(\\lambda\\) è \\([0,\\infty)\\). Si noti che abbiamo considerato i dati come iid. Guardando la serie temporale, però, è ovvio che le cose non stanno così: i valori aumentano nel tempo.\n\n55.3.2.3 Prior\nUsiamo una prior coniugata Gamma su \\(\\lambda\\), scelta in modo debolmente informativo. Un’ipotesi ragionevole (da verificare e discutere in aula) è una media a priori di 600 eventi/anno, con deviazione standard 200. In termini Gamma(shape, rate):\n\\[\n\\alpha = (\\mu/\\sigma)^2,\\qquad \\beta = \\mu/\\sigma^2.\n\\]\nVisualizziamo la prior (campionando in R):\n\nmu    &lt;- 600\nsigma &lt;- 200\n\n# Parametrizzazione Gamma(shape = k, scale = theta) per la simulazione\ntheta &lt;- sigma^2 / mu\nk     &lt;- mu / theta\n\nset.seed(2)\nx_draws &lt;- rgamma(50000, shape = k, scale = theta)\n\nggplot(data.frame(x = x_draws), aes(x = x)) +\n  geom_histogram(bins = 30) +\n  labs(\n    x = \"Tasso (eventi/anno)\",\n    y = \"Frequenza\"\n  )\n\n\n\n\n\n\n\n\n55.3.2.4 Modello di Poisson con Stan\nQui stimiamo \\(\\lambda\\) assumendo lo stesso tasso per tutti gli anni (pooling completo). Con prior Gamma in parametrizzazione (shape, rate):\n\nstan_code &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;                 // numero di anni\n  array[N] int&lt;lower=0&gt; y;        // conteggi annuali\n  real&lt;lower=0&gt; alpha_prior;      // shape\n  real&lt;lower=0&gt; beta_prior;       // rate\n}\nparameters {\n  real&lt;lower=0&gt; lambda;           // tasso medio annuo\n}\nmodel {\n  lambda ~ gamma(alpha_prior, beta_prior); // prior Gamma(shape, rate)\n  y ~ poisson(lambda);                     // verosimiglianza\n}\ngenerated quantities {\n  real log_lik = poisson_lpmf(y | lambda);\n}\n\"\n\n\n# Dati (usa i conteggi 2015...2024 ordinati)\ny_vec &lt;- year_counts$events  # ordine per anno; per Poisson i.i.d. l'ordine non incide\n\n# Prior: coerente con la sezione precedente\nalpha_prior &lt;- (mu / sigma)^2\nbeta_prior  &lt;- mu / sigma^2\n\nstan_data &lt;- list(\n  N = length(y_vec),\n  y = as.integer(y_vec),\n  alpha_prior = alpha_prior,\n  beta_prior  = beta_prior\n)\nstan_data\n#&gt; $N\n#&gt; [1] 10\n#&gt; \n#&gt; $y\n#&gt;  [1]  995  959  984  992  993 1021 1050 1097 1164 1175\n#&gt; \n#&gt; $alpha_prior\n#&gt; [1] 9\n#&gt; \n#&gt; $beta_prior\n#&gt; [1] 0.015\n\nCompilazione ed esecuzione:\n\nmod &lt;- cmdstan_model(write_stan_file(stan_code))\n\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4,\n  seed = 123,\n  refresh = 0\n)\n\nRiassunto dei parametri:\n\nfit$summary(\"lambda\")\n#&gt; # A tibble: 1 × 10\n#&gt;   variable     mean   median     sd    mad       q5      q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lambda   1042.414 1042.349 10.268 10.362 1025.691 1059.529 1.000 6110.780\n#&gt;   ess_tail\n#&gt;      &lt;dbl&gt;\n#&gt; 1 8233.184\n\n\nposterior::summarise_draws(\n  fit$draws(\"lambda\"),\n  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))\n)\n#&gt; # A tibble: 1 × 6\n#&gt;   variable     mean     sd   `2.5%`    `50%`  `97.5%`\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lambda   1042.414 10.268 1022.544 1042.349 1062.583\n\nVisualizzazione:\n\nbayesplot::mcmc_hist(fit$draws(\"lambda\")) \n\n\n\n\n\n\n\n\nbayesplot::mcmc_areas(fit$draws(\"lambda\"), prob = 0.95)\n\n\n\n\n\n\n\nIl grafico mostra che il tasso di sparatorie fatali ha una media annuale di 1042 con CI [1022, 1062].\nIn sintesi, analizzando i dati compresi tra il 2015 e il 2025 e basandoci su una distribuzione a priori che presuppone una sparatoria mortale al mese per stato, possiamo concludere con un grado di certezza soggettivo del 95% che il tasso stimato di sparatorie fatali da parte della polizia negli Stati Uniti sia di 1028 casi all’anno, con un intervallo di credibilità compreso tra 1022 e 1062.\nDiagnostica essenziale:\n\n# Indicatori numerici chiave: Rhat ~ 1, ESS adeguati\nposterior::summarize_draws(\n  fit$draws(c(\"lambda\")), \"rhat\", \"ess_bulk\", \"ess_tail\"\n)\n#&gt; # A tibble: 1 × 4\n#&gt;   variable  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lambda   1.000 6110.780 8233.184\n\n\n# Traceplot di controllo su OR\nbayesplot::mcmc_trace(fit$draws(\"lambda\")) \n\n\n\n\n\n\n\n\n55.3.2.5 Derivazione analitica (Gamma–Poisson)\nCon prior \\(\\lambda \\sim \\text{Gamma}(\\alpha,\\beta)\\) e dati \\(y_1,\\dots,y_n\\) i.i.d. Poisson(\\(\\lambda\\)), il posteriore è:\n\\[\n\\lambda \\mid \\mathbf{y} \\;\\sim\\; \\text{Gamma}\\!\\left(\\alpha + \\sum_{t=1}^n y_t,\\;\\; \\beta + n\\right).\n\\] Quindi:\n\n\nmedia posteriore \\(\\mathbb{E}[\\lambda\\mid y] = \\dfrac{\\alpha + \\sum y_t}{\\beta + n}\\);\n\nICr 95% con i quantili Gamma al 2.5% e 97.5%.\n\n\n# Dati e prior come nella sezione Stan\ndata_vec &lt;- year_counts$events\nn        &lt;- length(data_vec)\nsum_y    &lt;- sum(data_vec)\n\nmu    &lt;- 600\nsigma &lt;- 200\nalpha_prior &lt;- (mu / sigma)^2\nbeta_prior  &lt;- mu / sigma^2\n\n# Posterior coniugato\nalpha_post &lt;- alpha_prior + sum_y\nbeta_post  &lt;- beta_prior  + n\n\npost_mean &lt;- alpha_post / beta_post\nci95      &lt;- qgamma(c(0.025, 0.975), shape = alpha_post, rate = beta_post)\n\ncat(\"Posterior mean λ:\", round(post_mean, 2), \"\\n\")\n#&gt; Posterior mean λ: 1042\ncat(\"95% CrI: [\", round(ci95[1], 2), \", \", round(ci95[2], 2), \"]\\n\")\n#&gt; 95% CrI: [ 1022 ,  1062 ]\n\nLa derivazione analitica e i risultati MCMC coincidono (entro l’errore Monte Carlo).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#riflessioni-conclusive",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#riflessioni-conclusive",
    "title": "55  Modello di Poisson",
    "section": "\n55.4 Riflessioni conclusive",
    "text": "55.4 Riflessioni conclusive\nL’esempio del modello di Poisson ci ha permesso di estendere l’inferenza bayesiana a un nuovo tipo di dati, mostrando la versatilità di Stan nel trattare situazioni diverse. Abbiamo visto che la logica rimane invariata: definiamo un prior, specifichiamo la verosimiglianza (in questo caso di Poisson) e otteniamo una distribuzione a posteriori che rappresenta la nostra incertezza sui parametri.\nDal punto di vista applicativo, questo esempio è particolarmente rilevante per la ricerca psicologica. I dati di conteggio sono onnipresenti, e spesso la loro analisi viene ridotta a modelli frequentisti standardizzati. Con l’approccio bayesiano, invece, possiamo esplicitare le nostre assunzioni, incorporare conoscenze pregresse e comunicare l’incertezza in modo più trasparente.\nIl valore didattico di questo capitolo sta nel mostrare la continuità: ciò che abbiamo imparato con le proporzioni e l’odds ratio si applica senza sforzo concettuale anche a contesti diversi. Al tempo stesso, l’uso di Stan ci ha reso evidente che, anche per modelli semplici, il supporto di un PPL è indispensabile quando vogliamo scalare verso situazioni più complesse.\nNei prossimi capitoli faremo proprio questo passo: passeremo da modelli semplici e univariati a strutture più articolate e gerarchiche, scoprendo come l’approccio bayesiano ci permetta di affrontare in modo sistematico la complessità della ricerca psicologica contemporanea.\n\n\n\n\n\n\nCosa abbiamo imparato?\n\n\n\n\n\n\nCome tradurre un modello teorico di conteggio (Poisson con prior Gamma) in un modello Stan.\n\nCome ottenere campioni dalla distribuzione a posteriori con il campionamento MCMC.\n\nCome confrontare i risultati con la soluzione analitica per verificare che il workflow funziona.\n\nPerché è utile partire da un caso semplice: per allenarsi con il workflow che useremo in modelli più complessi, dove formule chiuse non esistono.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] lubridate_1.9.4       forcats_1.0.0         stringr_1.5.1        \n#&gt;  [4] purrr_1.1.0           readr_2.1.5           tidyverse_2.0.0      \n#&gt;  [7] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt; [10] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt; [13] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [16] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [19] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [22] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [25] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [28] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [31] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      ggridges_0.5.7        compiler_4.5.1       \n#&gt; [10] reshape2_1.4.4        systemfonts_1.2.3     vctrs_0.6.5          \n#&gt; [13] crayon_1.5.3          pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] utf8_1.2.6            rmarkdown_2.29        tzdb_0.5.0           \n#&gt; [22] ps_1.9.1              ragg_1.5.0            bit_4.6.0            \n#&gt; [25] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [28] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [31] stringi_1.8.7         RColorBrewer_1.1-3    estimability_1.5.1   \n#&gt; [34] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [37] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [40] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [43] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [46] pkgbuild_1.4.8        plyr_1.8.9            lattice_0.22-7       \n#&gt; [49] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [52] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [55] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [58] distributional_0.5.0  generics_0.1.4        vroom_1.6.5          \n#&gt; [61] rprojroot_2.1.1       hms_1.1.3             rstantools_2.5.0     \n#&gt; [64] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [67] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [70] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [73] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [76] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [79] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [82] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [85] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [88] bit64_4.6.0-1         MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#bibliografia",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#bibliografia",
    "title": "55  Modello di Poisson",
    "section": "Bibliografia",
    "text": "Bibliografia",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html",
    "href": "chapters/mcmc/07_bayesian_workflow.html",
    "title": "56  Flusso di lavoro bayesiano",
    "section": "",
    "text": "Introduzione\nAbbiamo ormai gli strumenti fondamentali per affrontare l’inferenza bayesiana in contesti realistici. Abbiamo visto che, nei casi semplici, l’aggiornamento può essere calcolato analiticamente, ma che già con pochi parametri questo diventa impraticabile. Abbiamo introdotto l’algoritmo di Metropolis, che ci ha mostrato come sia sempre possibile campionare dalla distribuzione a posteriori, e poi abbiamo visto come i linguaggi probabilistici – e in particolare Stan – rendano questa possibilità accessibile e utilizzabile nella ricerca psicologica.\nOra, però, dobbiamo fare un passo ulteriore. Avere strumenti di calcolo non basta: serve un metodo di lavoro. L’inferenza bayesiana non è soltanto una formula o un algoritmo, ma un processo che accompagna il ricercatore dall’ideazione del modello fino alla comunicazione dei risultati. Questo processo prende il nome di workflow bayesiano.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#introduzione",
    "href": "chapters/mcmc/07_bayesian_workflow.html#introduzione",
    "title": "56  Flusso di lavoro bayesiano",
    "section": "",
    "text": "Prerequisiti\n\n\n\n\n\nPuò essere utile aver letto Bulbulia (2023) su workflow e inferenza causale.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#un-processo-iterativo",
    "href": "chapters/mcmc/07_bayesian_workflow.html#un-processo-iterativo",
    "title": "56  Flusso di lavoro bayesiano",
    "section": "56.1 Un processo iterativo",
    "text": "56.1 Un processo iterativo\nIl workflow bayesiano non è lineare, ma iterativo. Inizia con la formulazione di un modello, procede con l’analisi dei dati e la valutazione dei risultati, ma spesso richiede di tornare indietro, rivedere le ipotesi e migliorare le specifiche. A differenza dell’approccio frequentista tradizionale, che tende a concentrarsi solo sull’output numerico finale (ad esempio un p-value), l’approccio bayesiano incoraggia una riflessione costante sul legame tra teoria, modello e dati.\nL’idea centrale è che ogni modello è un’ipotesi sul processo generativo che ha prodotto i dati. Il compito del ricercatore non è solo stimare parametri, ma verificare se il modello che li definisce è coerente con ciò che sappiamo e con ciò che osserviamo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#le-fasi-del-workflow",
    "href": "chapters/mcmc/07_bayesian_workflow.html#le-fasi-del-workflow",
    "title": "56  Flusso di lavoro bayesiano",
    "section": "56.2 Le fasi del workflow",
    "text": "56.2 Le fasi del workflow\nIl workflow può essere schematizzato in tre momenti principali, che però nella pratica si intrecciano continuamente.\n1. Definizione del modello Il punto di partenza è sempre la teoria o l’ipotesi psicologica che vogliamo testare. In questa fase traduciamo le nostre idee in un modello probabilistico: definiamo i parametri, scegliamo i priori, specifichiamo la verosimiglianza. È il momento in cui ci chiediamo: quale processo potrebbe aver generato i dati che osserviamo?\n2. Inferenza e stima Una volta definito il modello, utilizziamo strumenti come Stan per ottenere campioni dalla distribuzione a posteriori. Questa fase include la verifica tecnica del campionamento (convergenza delle catene, numero effettivo di campioni indipendenti, diagnosi di autocorrelazione). È qui che la potenza degli algoritmi MCMC diventa essenziale, perché ci permette di trattare modelli complessi senza dover ricorrere a semplificazioni eccessive.\n3. Valutazione del modello Il passo successivo è chiederci se il modello “funziona”. Ciò significa, da un lato, confrontare le predizioni del modello con i dati osservati (posterior predictive checks) e, dall’altro, valutare la capacità del modello di generalizzare a nuovi dati (ad esempio tramite LOO-CV ed ELPD). La valutazione non è mai l’ultima parola, ma una guida per decidere se mantenere, modificare o sostituire il modello.\n\n\n\nFigura tratta da Blei (2014).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#una-prospettiva-cumulativa",
    "href": "chapters/mcmc/07_bayesian_workflow.html#una-prospettiva-cumulativa",
    "title": "56  Flusso di lavoro bayesiano",
    "section": "56.3 Una prospettiva cumulativa",
    "text": "56.3 Una prospettiva cumulativa\nIl workflow bayesiano ci ricorda che la scienza non procede per verità definitive, ma per modelli progressivamente migliori. Ogni modello è un passo in un percorso cumulativo, in cui le ipotesi vengono testate, confrontate e, se necessario, abbandonate.\nDal punto di vista della psicologia, questo approccio rappresenta una risposta concreta alla crisi di replicazione. Non ci limitiamo a verificare associazioni statistiche, ma costruiamo modelli espliciti dei processi psicologici, li testiamo sui dati e li confrontiamo in termini di capacità predittiva. È un metodo che promuove trasparenza, apertura alla revisione e cumulatività, tutti elementi essenziali per rafforzare le basi empiriche della disciplina.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#riflessioni-conclusive",
    "href": "chapters/mcmc/07_bayesian_workflow.html#riflessioni-conclusive",
    "title": "56  Flusso di lavoro bayesiano",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nCon il workflow bayesiano abbiamo completato il nostro percorso introduttivo all’inferenza bayesiana. Abbiamo visto che non si tratta solo di imparare un nuovo insieme di tecniche, ma di adottare una prospettiva diversa sul rapporto tra teoria, dati e analisi statistica.\nIl valore di questo approccio non sta soltanto nei dettagli tecnici, ma nel modo in cui ci spinge a pensare: ogni modello è un’ipotesi esplicita, ogni analisi è trasparente e riproducibile, ogni risultato è accompagnato da una valutazione critica della sua incertezza e della sua plausibilità.\nNei capitoli successivi vedremo come applicare questi principi a casi specifici e a modelli più articolati. Il workflow bayesiano rimarrà il filo conduttore: un metodo iterativo e riflessivo che ci guida nel costruire conoscenza scientifica solida, cumulativa e capace di rispondere alle sfide della psicologia contemporanea.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#bibliografia",
    "href": "chapters/mcmc/07_bayesian_workflow.html#bibliografia",
    "title": "56  Flusso di lavoro bayesiano",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlei, D. M. (2014). Build, compute, critique, repeat: Data analysis with latent variable models. Annual Review of Statistics and Its Application, 1(1), 203–232.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/introduction_linear_models.html",
    "href": "chapters/linear_models/introduction_linear_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione affronteremo alcuni tra i casi più semplici dell’inferenza statistica, ovvero l’inferenza su una singola media, la differenza tra due medie, e l’analisi del modello di regressione lineare, sia bivariato sia multiplo, con predittori quantitativi e qualitativi.\nTradizionalmente, l’inferenza su una o due medie viene trattata mediante il t-test di Student, nell’ambito dell’approccio frequentista. Tuttavia, in una prospettiva più moderna, questi problemi possono essere ricondotti al modello lineare generale, che fornisce un quadro metodologico unificato. In questa sezione, quindi, presenteremo il modello lineare sia dal punto di vista frequentista sia secondo l’approccio bayesiano, mostrando come l’inferenza su una o due medie rappresenti un caso particolare di questo impianto generale.\nÈ utile, a questo proposito, distinguere tra due tipi di modelli: i modelli fenomenologici e i modelli meccanicistici. I modelli fenomenologici si limitano a descrivere i dati: forniscono un riassunto matematico della relazione osservata tra variabili, senza fare ipotesi esplicite sui processi che generano tali relazioni. I modelli meccanicistici, al contrario, cercano di rappresentare il processo sottostante che ha prodotto i dati, offrendo una spiegazione plausibile dei meccanismi causali in gioco.\nIl modello lineare, e in particolare il modello di regressione, appartiene alla prima categoria: è un modello fenomenologico, descrittivo. La sua enorme diffusione in psicologia è legata, almeno in parte, al successo dell’approccio frequentista, che imposta la questione inferenziale in termini dicotomici: “c’è evidenza di un’associazione tra variabili, oppure no?”, alla luce di un’ipotesi nulla che assume l’assenza di associazione nella popolazione.\nTuttavia, abbiamo già osservato come questa domanda, in sé, abbia una portata scientifica limitata. Sappiamo, in linea generale, che tutto è correlato con tutto il resto. La domanda rilevante, quindi, non è se esista un’associazione, ma quanto forte sia tale associazione. E anche quando stimiamo la forza dell’associazione, questo non ci dice ancora nulla sui meccanismi che l’hanno generata. Una descrizione accurata può essere utile, ma non è sufficiente per spiegare il fenomeno osservato.\nPurtroppo, la maggior parte dei modelli quantitativi in psicologia è di tipo fenomenologico, probabilmente a causa della predominanza dell’approccio frequentista e della sua enfasi sull’associazione statistica come obiettivo esplicativo. Questo rappresenta un limite per lo sviluppo teorico della disciplina. Esistono però anche modelli meccanicistici in psicologia – ne vedremo un esempio concreto nella sezione dedicata alla modellazione dinamica – che si propongono di simulare i processi cognitivi o affettivi sottostanti.\nIn questa sezione ci concentreremo dunque sul modello di regressione, consapevoli che si tratta di un modello descrittivo, non esplicativo. Non lo facciamo perché sia particolarmente importante dal punto di vista scientifico, ma perché è onnipresente nella pratica della ricerca psicologica. L’aspetto innovativo della trattazione che segue sarà l’adozione di una prospettiva bayesiana, che ci permette di reinterpretare l’inferenza statistica in termini di incertezza soggettiva, confronto tra modelli e plausibilità delle ipotesi, offrendo strumenti concettuali e computazionali più coerenti con un approccio scientifico maturo.",
    "crumbs": [
      "Regressione",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html",
    "href": "chapters/linear_models/01_reglin_frequentist.html",
    "title": "57  La regressione lineare bivariata",
    "section": "",
    "text": "Introduzione\nL a regressione lineare è uno degli strumenti statistici più utilizzati per modellare le relazioni tra variabili quantitative. In termini semplici, ci permette di descrivere cosa accade, in media, a una variabile (detta variabile dipendente, indicata con \\(Y\\)) quando un’altra variabile (detta variabile indipendente, indicata con \\(X\\)) cambia, assumendo che nei dati esista una certa variabilità residua.\nIn psicologia, la regressione è ampiamente impiegata per:\nTuttavia, per poterla usare in modo efficace e critico, è necessario comprenderne bene le assunzioni e i limiti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "title": "57  La regressione lineare bivariata",
    "section": "",
    "text": "esplorare relazioni tra costrutti psicologici,\n\nformulare previsioni di comportamenti o esiti,\n\ntestare ipotesi su meccanismi sottostanti i processi cognitivi, emotivi o sociali.\n\n\nPanoramica del capitolo\n\nIl modello di regressione lineare secondo l’approccio frequentista.\nLa stima dei coefficienti del modello utilizzando il metodo dei minimi quadrati.\nL’interpretazione dei coefficienti dei minimi quadrati.\nIl calcolo e l’interpretazione dell’indice di determinazione (\\(R^2\\)).\nL’inferenza frequentista sui coefficienti dei minimi quadrati.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Basic Regression di Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (Second Edition).\nConsulta l’appendice Appendice N per un’introduzione alle funzioni lineari.\nLeggere Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code (Alter et al., 2025).\nLeggere il capitolo Linear Statistical Models (Schervish & DeGroot, 2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(broom)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#la-relazione-tra-x-e-y",
    "href": "chapters/linear_models/01_reglin_frequentist.html#la-relazione-tra-x-e-y",
    "title": "57  La regressione lineare bivariata",
    "section": "\n57.1 La relazione tra \\(X\\) e \\(Y\\)\n",
    "text": "57.1 La relazione tra \\(X\\) e \\(Y\\)\n\nIl caso più semplice è il modello di regressione lineare bivariato, che descrive la relazione tra due variabili. L’idea di base è che, se \\(X\\) e \\(Y\\) sono associate, possiamo approssimare la loro relazione con una retta che indica come \\(Y\\) tende a variare al variare di \\(X\\).\nLa formulazione classica (frequentista) del modello è:\n\\[\ny_i = a + b x_i + e_i, \\quad i = 1, \\dots, n,\n\\] dove:\n\n\n\\(a\\) (intercetta): valore atteso di \\(Y\\) quando \\(X = 0\\),\n\n\\(b\\) (pendenza): variazione attesa di \\(Y\\) per ogni unità di aumento in \\(X\\),\n\n\\(e_i\\) (errore residuo): differenza tra il valore osservato \\(y_i\\) e il valore previsto dal modello.\n\nGraficamente, questa equazione corrisponde a una retta di regressione che rappresenta la miglior approssimazione lineare dei dati secondo il criterio dei minimi quadrati. Nella realtà, i punti raramente giacciono tutti sulla retta: le differenze sono catturate dagli errori residui.\nLa regressione, quindi, non predice esattamente ogni osservazione, ma descrive la tendenza media nella popolazione. Ad esempio, se \\(b = 2\\), significa che — in media — un aumento di 1 unità in \\(X\\) è associato a un aumento di 2 unità in \\(Y\\). Ciò non implica che ogni caso segua la regola in modo perfetto, ma che l’andamento complessivo sia coerente con questa relazione.\nL’obiettivo dell’analisi è stimare i parametri \\(a\\), \\(b\\) e \\(\\sigma^2\\) (varianza residua) dai dati, utilizzando il metodo dei minimi quadrati (OLS) o, più in generale, il principio di massima verosimiglianza. Nel paradigma frequentista, questi parametri sono considerati quantità fisse ma sconosciute, e l’incertezza riguarda esclusivamente gli errori di misura o variabilità non spiegata.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#a-cosa-serve-la-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#a-cosa-serve-la-regressione",
    "title": "57  La regressione lineare bivariata",
    "section": "\n57.2 A cosa serve la regressione?",
    "text": "57.2 A cosa serve la regressione?\nSecondo Gelman et al. (2021), la regressione lineare può essere applicata in almeno quattro contesti principali:\n\n\nPrevisione – Stimare valori futuri di una variabile di interesse o classificare casi in base a probabilità.\n\n\nEsempi: prevedere punteggi futuri a un test; monitorare il benessere psicologico in studi longitudinali; classificare individui in base alla probabilità di successo in un compito cognitivo.\n\n\n\nEsplorazione delle associazioni – Identificare e quantificare le relazioni tra predittori e risultato.\n\n\nEsempi: analizzare i tratti di personalità legati alla resilienza allo stress; studiare la relazione tra stili di attaccamento infantile e competenze relazionali adulte; valutare l’effetto di fattori socio-economici sullo sviluppo cognitivo.\n\n\n\nEstrapolazione – Estendere i risultati a contesti o popolazioni non direttamente osservati.\n\n\nEsempi: stimare l’efficacia di una terapia testata su studenti universitari nella popolazione generale; prevedere l’impatto di un intervento scolastico su un intero distretto a partire da dati di scuole pilota.\n\n\n\nInferenza causale – Stimare effetti di trattamenti o interventi, solo se supportata da un disegno di ricerca adeguato (ad es., randomizzazione).\n\n\nEsempi: valutare l’efficacia di un programma di mindfulness sull’ansia; stimare l’impatto di una psicoterapia sul disturbo post-traumatico da stress; determinare l’effetto di un intervento educativo su una popolazione diversificata.\n\n\n\nNota importante: in tutti i contesti, il modello deve includere tutte le variabili rilevanti per il fenomeno studiato. L’omissione di variabili confondenti può distorcere le stime — problema noto come errore di specificazione del modello. Ad esempio, in uno studio sull’efficacia di una psicoterapia per la depressione, fattori come età, condizioni di salute preesistenti e supporto sociale devono essere inclusi nell’analisi per evitare interpretazioni fuorvianti.\n\n57.2.1 Tipologie di regressione\nL’analisi di regressione può essere classificata in base al numero di variabili coinvolte, distinguendosi in tre principali categorie che riflettono diversi livelli di complessità.\nLa regressione bivariata rappresenta la forma più elementare, in cui viene analizzata la relazione tra un unico predittore e una sola variabile esito. La sua semplicità la rende un punto di partenza ideale per comprendere la logica fondamentale della regressione, poiché consente di apprendere i concetti di base senza l’onere di complicazioni matematiche eccessive.\nUn livello di complessità superiore è dato dalla regressione multipla, nella quale un unico esito viene modellato utilizzando molteplici predittori. Questo approccio permette di esaminare l’effetto simultaneo di diverse variabili indipendenti, richiedendo un’attenta interpretazione dei parametri stimati.\nInfine, la regressione multivariata costituisce il caso più generale, in cui più variabili esito vengono analizzate simultaneamente in relazione a uno o più predittori. Questo tipo di modellazione richiede calcoli statistici più articolati e rappresenta lo strumento più potente e complesso tra le tre tipologie.\nIl percorso di apprendimento ideale inizia dalla regressione bivariata, poiché fornisce le basi concettuali e metodologiche che possono successivamente essere estese verso modelli più sofisticati. La comprensione dei principi fondamentali acquisiti nel caso semplice è infatti un prerequisito essenziale per affrontare le sfide interpretative e computazionali poste dalle regressioni multiple e multivariate.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "href": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "title": "57  La regressione lineare bivariata",
    "section": "\n57.3 La predizione dell’intelligenza",
    "text": "57.3 La predizione dell’intelligenza\nPer illustrare il modello di regressione secondo l’approccio frequentista, utilizzeremo un dataset reale: i dati kidiq tratti dal National Longitudinal Survey of Youth (Gelman et al., 2021). Questi dati riguardano un campione di donne americane e i loro figli, con particolare attenzione a due variabili fondamentali per la nostra analisi: il punteggio cognitivo del bambino (kid_score) e il quoziente intellettivo della madre (mom_iq). L’obiettivo principale consiste nell’esaminare se - e in che misura - l’intelligenza materna possa essere considerata un fattore predittivo delle capacità cognitive del bambino.\n\n57.3.1 Esplorazione dei dati\nImportiamo i dati in R:\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\nEsaminiamo le prime righe del data frame:\n\nhead(kidiq)\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1  121.1        4      27\n#&gt; 2        98      1   89.4        4      25\n#&gt; 3        85      1  115.4        4      27\n#&gt; 4        83      1   99.4        3      25\n#&gt; 5       115      1   92.7        4      27\n#&gt; 6        98      0  107.9        1      18\n\nUn diagramma a dispersione per i dati di questo campione suggerisce la presenza di un’associazione positiva tra l’intelligenza del bambino (kid_score) e l’intelligenza della madre (mom_iq).\n\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.6) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Diagramma a dispersione\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#il-modello-teorico",
    "href": "chapters/linear_models/01_reglin_frequentist.html#il-modello-teorico",
    "title": "57  La regressione lineare bivariata",
    "section": "\n57.4 Il modello teorico",
    "text": "57.4 Il modello teorico\nIl modello di regressione lineare bivariata è:\n\\[\ny_i = a + b x_i + e_i, \\quad i = 1, \\dots, n\n\\] dove:\n\n\n\\(a\\): intercetta (valore atteso di \\(y\\) quando \\(x = 0\\));\n\n\\(b\\): pendenza (variazione attesa di \\(y\\) per +1 in \\(x\\));\n\n\\(e_i\\): errore residuo (scarto tra osservato e predetto).\n\nNel nostro caso:\n\n\n\\(y = \\text{`kid\\_score`}\\) (QI del bambino)\n\n\\(x = \\text{`mom\\_iq`}\\) (QI della madre)\n\nLa componente deterministica \\(\\hat{y}_i = a + b x_i\\) rappresenta la parte prevedibile di \\(y\\) in funzione di \\(x\\). La componente aleatoria \\(e_i = y_i - \\hat{y}_i\\) cattura ciò che il modello non spiega.\n\n\n\n\n\n\nIllustrazione\n\n\n\n\n\nIl campione è costituito da \\(n\\) coppie di osservazioni (\\(x, y\\)).\n\\[\n\\begin{array}{cc}\n\\hline\nx_1 & y_1 \\\\\nx_2 & y_2 \\\\\nx_3 & y_3 \\\\\n\\vdots & \\vdots \\\\\nx_n & y_n \\\\\n\\hline\n\\end{array}\n\\]\nPer ciascuna coppia di valori \\(x_i, y_i\\), il modello di regressione si aspetta che il valore \\(y_i\\) sia associato al corrispondente valore \\(x_i\\) come indicato dalla seguente equazione\n\\[\n\\mathbb{E}(y_i) = a + b x_i ,\n\\tag{57.1}\\]\n ovvero:\n\\[\n\\begin{array}{ccc}\n\\hline\nx_i & y_i & \\mathbb{E}(y_i) = a + b x_i \\\\\n\\hline\nx_1 & y_1 & a + b x_1 \\\\\nx_2 & y_2 & a + b x_2 \\\\\nx_3 & y_3 & a + b x_3 \\\\\n\\vdots & \\vdots & \\vdots \\\\\nx_n & y_n & a + b x_n \\\\\n\\hline\n\\end{array}\n\\]\nI valori \\(y_i\\) corrispondono, nell’esempio che stiamo discutendo, alla variabile kid_score. I primi 10 valori della variabile \\(y\\) sono i seguenti:\n\nkidiq$kid_score[0:10]\n#&gt;  [1]  65  98  85  83 115  98  69 106 102  95\n\nPer fare riferimento a ciascuna osservazione usiamo l’indice \\(i\\). Quindi, ad esempio, \\(y_2\\) è uguale a\n\nkidiq$kid_score[2]\n#&gt; [1] 98\n\n\n\n\n\n57.4.1 Stima del modello di regressione\nCalcoliamo i coefficienti della retta di regressione utilizzando la funzione lm.\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\nEsaminiamo i risultati:\n\n# Coefficienti stimati\ncoef(mod)\n#&gt; (Intercept)      mom_iq \n#&gt;       25.80        0.61\n\nIn generale, molte rette possono approssimare la nube di punti, ma il modello di regressione impone vincoli:\n\nla retta deve passare per il punto medio \\((\\bar{x}, \\bar{y})\\);\ndeve minimizzare la somma dei quadrati dei residui (SSE).\n\n\n# Calcola i valori medi\nmean_x &lt;- mean(kidiq$mom_iq, na.rm = TRUE)\nmean_y &lt;- mean(kidiq$kid_score, na.rm = TRUE)\n\n# Grafico nello stile \"manuscript\"\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.65, color = css_palette$text_primary) +\n  geom_smooth(\n    method = \"lm\", se = FALSE,\n    color = css_palette$accent_warm,\n    linewidth = 0.8\n  ) +\n  annotate(\n    \"point\", \n    x = mean_x, y = mean_y,\n    color = css_palette$illumination_blue,\n    size = 4.5, shape = 4, stroke = 2.2\n  ) +\n  labs(\n    x = \"QI della madre\",\n    y = \"QI del bambino\",\n    title = stringr::str_wrap(\"QI materno e QI del bambino\", width = 50),\n    subtitle = \"Con retta di regressione e punto medio\"\n  ) +\n  theme_manuscript()\n\n\n\n\n\n\n\n\n57.4.2 Interpretazione\nIl coefficiente \\(a\\) indica l’intercetta della retta di regressione nel diagramma a dispersione. Questo valore rappresenta il punto in cui la retta di regressione interseca l’asse \\(y\\) del sistema di assi cartesiani. Tuttavia, in questo caso specifico, il valore di \\(a\\) non è di particolare interesse poiché corrisponde al valore della retta di regressione quando l’intelligenza della madre è pari a 0, il che non ha senso nella situazione reale. Successivamente, vedremo come è possibile trasformare i dati per fornire un’interpretazione utile del coefficiente \\(a\\).\nInvece, il coefficiente \\(b\\) indica la pendenza della retta di regressione, ovvero di quanto aumenta (se \\(b\\) è positivo) o diminuisce (se \\(b\\) è negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\). Nel caso specifico del QI delle madri e dei loro figli, il coefficiente \\(b\\) ci indica che un aumento di 1 punto del QI delle madri è associato, in media, a un aumento di 0.61 punti del QI dei loro figli.\nIn pratica, il modello di regressione lineare cerca di prevedere le medie dei punteggi del QI dei figli in base al QI delle madri. Ciò significa che non è in grado di prevedere esattamente il punteggio di ciascun bambino in funzione del QI della madre, ma solo una stima della media dei punteggi dei figli quando il QI delle madri aumenta o diminuisce di un punto.\nIl coefficiente \\(b\\) ci dice di quanto aumenta (o diminuisce) in media il QI dei figli per ogni unità di aumento (o diminuzione) del QI della madre. Nel nostro caso, se il QI della madre aumenta di un punto, il QI dei figli aumenta in media di 0.61 punti.\nÈ importante comprendere che il modello statistico di regressione lineare non è in grado di prevedere il valore preciso di ogni singolo bambino, ma solo una stima della media dei punteggi del QI dei figli quando il QI delle madri aumenta o diminuisce. Questa stima è basata su una distribuzione di valori possibili che si chiama distribuzione condizionata \\(p(y \\mid x_i)\\).\nUna rappresentazione grafica del valore predetto dal modello di regressione, \\(\\hat{y}_i = a + bx_i\\) è stato fornito in precedenza. Il diagramma presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). I valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione.\n\n57.4.3 Centrare le variabili\nIn generale, per variabili a livello di scala ad intervalli, l’intercetta del modello di regressione lineare non ha un’interpretazione utile. Questo perché l’intercetta indica il valore atteso di \\(y\\) quando \\(x = 0\\), ma in caso di variabili a scala di intervalli, il valore “0” di \\(x\\) è arbitrario e non corrisponde ad un “assenza” della variabile \\(x\\). Ad esempio, un QI della madre pari a 0 non indica un’assenza di intelligenza, ma solo un valore arbitrario del test usato per misurare il QI. Quindi, sapere il valore medio del QI dei bambini quando il QI della madre è 0 non è di alcun interesse.\nCentrando \\(x\\) attorno alla sua media otteniamo un’intercetta interpretabile: il valore medio di kid_score quando mom_iq è nella media del campione.\n\nkidiq &lt;- kidiq %&gt;%\n  mutate(xd = mom_iq - mean(mom_iq))\n\nSe ora usiamo le coppie di osservazioni \\((xd_i, y_i)\\), il diagramma a dispersione assume la forma seguente.\n\n\n\n\n\n\n\n\nIn sostanza, abbiamo applicato una trasformazione ai dati, traslando tutti i punti del grafico lungo l’asse delle ascisse in modo che la media dei valori \\(x\\) risulti pari a zero. Questa operazione non ha alterato la distribuzione o la forma complessiva della nuvola di punti, ma ha semplicemente modificato l’origine del sistema di riferimento sull’asse \\(x\\).\nLa pendenza della retta di regressione che mette in relazione \\(x\\) e \\(y\\) rimane invariata, sia per i dati originali che per quelli trasformati. L’unico parametro che subisce una modifica è il valore dell’intercetta della retta di regressione, che acquisisce in questo modo un’interpretazione più intuitiva e significativa dal punto di vista sostanziale.\n\nmod1 &lt;- lm(kid_score ~ xd, data = kidiq)\ncoef(mod1)\n#&gt; (Intercept)          xd \n#&gt;       86.80        0.61\n\nNell’output del modello, l’intercetta rappresenta il valore predetto della variabile dipendente \\(y\\) quando la variabile indipendente \\(x\\) assume esattamente il suo valore medio campionario. Nel caso specifico dell’esempio, l’intercetta corrisponde al punteggio atteso del QI del bambino (kid_score) quando il quoziente intellettivo della madre (mom_iq) è pari alla media osservata nel campione di riferimento.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#metodo-dei-minimi-quadrati",
    "href": "chapters/linear_models/01_reglin_frequentist.html#metodo-dei-minimi-quadrati",
    "title": "57  La regressione lineare bivariata",
    "section": "\n57.5 Metodo dei minimi quadrati",
    "text": "57.5 Metodo dei minimi quadrati\nNel modello di regressione bivariata, i coefficienti \\(a\\) (intercetta) e \\(b\\) (pendenza) vengono stimati scegliendo la retta che minimizza la somma dei quadrati dei residui (Sum of Squared Errors, SSE):\n\\[\ne_i = y_i - (a + b x_i), \\quad SSE = \\sum_{i=1}^n e_i^2.\n\\] Questa scelta equivale, sotto l’assunzione di errori normali con media zero e varianza costante, alla stima di massima verosimiglianza.\nLa minimizzazione dell’SSE porta alle equazioni normali, la cui soluzione ha forma chiusa:\n\\[\nb = \\frac{\\mathrm{Cov}(x, y)}{\\mathrm{Var}(x)}, \\quad a = \\bar{y} - b \\,\\bar{x} ,\n\\] dove:\n\n\n\\(\\bar{x}\\) e \\(\\bar{y}\\) sono le medie campionarie;\n\n\\(\\mathrm{Cov}(x,y)\\) è la covarianza tra \\(x\\) e \\(y\\);\n\n\\(\\mathrm{Var}(x)\\) è la varianza di \\(x\\).\n\nQueste formule assicurano che:\n\nLa retta passa per il punto medio \\((\\bar{x}, \\bar{y})\\) della nube di punti.\nLa pendenza \\(b\\) quantifica la variazione media di \\(y\\) per un’unità di incremento di \\(x\\).\nL’intercetta \\(a\\) è il valore previsto di \\(y\\) quando \\(x=0\\) (interpretazione utile solo se \\(x=0\\) è significativo).\n\nEsempio in R\n\ncov_xy &lt;- cov(kidiq$kid_score, kidiq$xd)\nvar_x  &lt;- var(kidiq$xd)\nb &lt;- cov_xy / var_x\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$xd)\nc(intercetta = a, pendenza = b)\n#&gt; intercetta   pendenza \n#&gt;      86.80       0.61\n\nI risultati replicano quelli ottenuti in precedenza con lm().\n\n57.5.1 Residui\nIl residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione, corrisponde alla distanza verticale tra il valore \\(y_i\\) osservato e il valore \\(\\hat{y}_i\\) predetto dal modello di regressione:\n\\[\ne_i = y_i - (a + b x_i).\n\\]\nPer fare un esempio numerico, consideriamo il punteggio osservato del QI del primo bambino.\n\nkidiq$kid_score[1]\n#&gt; [1] 65\n\nIl QI della madre è\n\nkidiq$mom_iq[1]\n#&gt; [1] 121\n\nPer questo bambino, il valore predetto dal modello di regressione è\n\na + b * kidiq$mom_iq[1]\n#&gt; [1] 161\n\nL’errore che compiamo per predire il QI del bambino utilizzando il modello di regressione (ovvero, il residuo) è\n\nkidiq$kid_score[1] - (a + b * kidiq$mom_iq[1])\n#&gt; [1] -95.7\n\nPer tutte le osservazioni abbiamo\n\nres &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\nÈ una proprietà del modello di regressione (calcolato con il metodo dei minimi quadrati) che la somma dei residui sia uguale a zero.\n\nsum(res)\n#&gt; [1] -26473\n\nQuesto significa che ogni valore osservato \\(y_i\\) viene scomposto dal modello di regressione in due componenti distinte. La componente deterministica \\(\\hat{y}_i\\), che è predicibile da \\(x_i\\), è data da \\(\\hat{y}_i = a + b x_i\\). Il residuo, invece, è dato da \\(e_i = y_i - \\hat{y}_i\\). La somma di queste due componenti, ovviamente, riproduce il valore osservato.\n\n# Creazione di un data frame con i valori calcolati\ndf &lt;- data.frame(\n  kid_score = kidiq$kid_score,\n  mom_iq = kidiq$mom_iq,\n  y_hat = a + b * kidiq$mom_iq,\n  e = kidiq$kid_score - (a + b * kidiq$mom_iq),\n  y_hat_plus_e = (a + b * kidiq$mom_iq) + (kidiq$kid_score - (a + b * kidiq$mom_iq))\n)\n\n# Visualizzazione dei primi 6 valori\nhead(df)\n#&gt;   kid_score mom_iq y_hat     e y_hat_plus_e\n#&gt; 1        65  121.1   161 -95.7           65\n#&gt; 2        98   89.4   141 -43.3           98\n#&gt; 3        85  115.4   157 -72.2           85\n#&gt; 4        83   99.4   147 -64.5           83\n#&gt; 5       115   92.7   143 -28.4          115\n#&gt; 6        98  107.9   153 -54.6           98\n\n\n57.5.2 Illustrazione del metodo dei minimi quadrati\nPer stimare i coefficienti \\(a\\) e \\(b\\), possiamo minimizzare la somma dei quadrati dei residui tra i valori osservati \\(y_i\\) e quelli previsti \\(a + b x_i\\).\nIniziamo con il creare una griglia per i valori di \\(b\\). Supponiamo che il valore di \\(a\\) sia noto (\\(a = 25.79978\\)). Usiamo R per creare una griglia di valori possibili per \\(b\\).\n\n# Griglia di valori per b\nb_grid &lt;- seq(0, 1, length.out = 1001)\na &lt;- 25.79978  # Intercetta nota\n\nDefiniamo ora una funzione che calcola la somma dei quadrati dei residui (\\(SSE\\)) per ciascun valore di \\(b\\).\n\n# Funzione per la somma dei quadrati dei residui\nsse &lt;- function(a, b, x, y) {\n  sum((y - (a + b * x))^2)\n}\n\nApplichiamo la funzione sse alla griglia di valori \\(b\\) per calcolare la somma dei quadrati dei residui per ogni valore di \\(b\\).\n\n# Calcolo di SSE per ciascun valore di b\nsse_vals &lt;- sapply(\n  b_grid, \n  function(b) sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n)\n\n\n\nsapply:\n\nÈ una funzione di R che applica una funzione ad ogni elemento di un vettore (o lista) e restituisce i risultati in un vettore.\nQui, applica la funzione sse a ciascun valore di \\(b\\) contenuto in b_grid.\n\n\n\nfunction(b):\n\nÈ una funzione anonima definita al volo per specificare come calcolare \\(SSE\\) per ciascun valore di \\(b\\).\nAll’interno, viene chiamata la funzione sse(a, b, x, y) con i seguenti parametri:\n\n\na: il valore dell’intercetta (fissato in precedenza o noto).\n\nb: il valore corrente nella griglia b_grid.\n\nx: la variabile indipendente del dataset (kidiq$mom_iq).\n\ny: la variabile dipendente del dataset (kidiq$kid_score).\n\n\n\n\nIl risultato è un vettore, sse_vals, che contiene i valori di \\(SSE\\) corrispondenti a ciascun valore di \\(b\\) in b_grid.\n\nTracciamo un grafico che mostra la somma dei quadrati dei residui (\\(SSE\\)) in funzione dei valori di \\(b\\), evidenziando il minimo.\n\n# Identificazione del valore di b che minimizza SSE\nb_min &lt;- b_grid[which.min(sse_vals)]\n\n# Creazione del dataframe per ggplot\ndat &lt;- data.frame(b_grid = b_grid, sse_vals = sse_vals)\n\n# Genera il grafico\nggplot(dat, aes(x = b_grid, y = sse_vals)) +\n  geom_line(linewidth = 1) +  \n  annotate(\n    \"point\", x = b_min, y = min(sse_vals),\n    color = \"red\", size = 3\n  ) +  # Punto minimo\n  labs(\n    x = expression(paste(\"Possibili valori di \", hat(beta))),\n    y = \"Somma dei quadrati\\ndei residui\",\n    title = \"Residui quadratici\"\n  ) +\n  annotate(\n    \"text\", x = b_min, y = min(sse_vals), \n    label = expression(hat(beta)), color = \"red\", vjust = -1, hjust = 0.5\n  )\n\n\n\n\n\n\n\nInfine, identifichiamo il valore di \\(b\\) che minimizza la somma dei quadrati dei residui.\n\nb_min\n#&gt; [1] 0.61\n\nCon questa simulazione, abbiamo stimato il coefficiente \\(b\\) minimizzando la somma dei quadrati dei residui.\nQuesto approccio può essere esteso per stimare simultaneamente entrambi i coefficienti (\\(a\\) e \\(b\\)) utilizzando metodi di ottimizzazione più avanzati, come optim in R.\n\noptim_result &lt;- optim(\n  par = c(a = 25, b = 0.5),  # Valori iniziali\n  fn = function(params) {\n    a &lt;- params[1]\n    b &lt;- params[2]\n    sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n  }\n)\n\n# Coefficienti stimati\noptim_result$par\n#&gt;     a     b \n#&gt; 25.79  0.61\n\nQuesta simulazione illustra come, tramite il metodo dei minimi quadrati, sia possibile stimare i parametri di un modello bivariato di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "title": "57  La regressione lineare bivariata",
    "section": "\n57.6 L’errore standard della regressione",
    "text": "57.6 L’errore standard della regressione\nL’errore standard della stima \\(s_e\\) misura la deviazione media dei dati dalla retta:\n\\[\n\\sqrt{\\frac{1}{n-2} \\sum_{i=1}^n \\big(y_i - (\\hat{a} + \\hat{b}x_i)\\big)^2},\n\\tag{57.2}\\]\nL’indice \\(s_e\\) possiede la stessa unità di misura di \\(y\\) ed è una stima della deviazione standard dei residui nella popolazione.\nIn R:\n\n# Calcolo dei residui\ne &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\n# Mostriamo i primi 10 residui\nhead(e, 10)\n#&gt;  [1] -34.68  17.69 -11.22  -3.46  32.63   6.38 -41.52   3.86  26.41  11.21\n\nCalcoliamo il valore medio assoluto dei residui per avere un’indicazione della deviazione media rispetto alla retta di regressione.\n\n# Media assoluta dei residui\nmean(abs(e))\n#&gt; [1] 14.5\n\nL’errore standard della stima \\(s_e\\) si calcola come la radice quadrata della somma dei quadrati dei residui divisa per \\(n-2\\):\n\n# Calcolo di s_e\nse &lt;- sqrt(sum(e^2) / (length(e) - 2))\nse\n#&gt; [1] 18.3\n\nNotiamo che il valore medio assoluto dei residui e l’errore standard \\(s_e\\) non sono identici, ma hanno lo stesso ordine di grandezza. \\(s_e\\) è una misura più rigorosa della deviazione standard dei residui.\nQuesta analisi dimostra come \\(s_e\\) consenta di valutare quanto le previsioni del modello si discostino (in media) dai dati osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#lindice-di-determinazione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#lindice-di-determinazione",
    "title": "57  La regressione lineare bivariata",
    "section": "\n57.7 L’indice di determinazione",
    "text": "57.7 L’indice di determinazione\nNell’approccio frequentista, la qualità dell’adattamento si apprezza osservando l’indice di determinazione \\(R^2\\), che indica quanta parte della varianza di \\(y\\) viene spiegata dal modello, e analizzando i residui: eventuali pattern sistematici nei residui possono segnalare che la struttura scelta non coglie tutte le caratteristiche dei dati o che esistono violazioni delle ipotesi (linearità, omoscedasticità, normalità degli errori). Un esame congiunto di \\(R^2\\) e residui aiuta a diagnosticare e, se necessario, migliorare il modello.\nL’indice di determinazione viene calcolato utilizzando un’importante proprietà del modello di regressione, ovvero la scomposizione della varianza della variabile dipendente \\(y\\) in due componenti: la varianza spiegata dal modello e la varianza residua.\nPer una generica osservazione \\(x_i, y_i\\), la deviazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) può essere espressa come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\):\n\\[\ny_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}).\n\\]\nLa varianza totale di \\(y\\) può quindi essere scritta come:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(e_i + (\\hat{y}_i - \\bar{y}))^2.\n\\]\nSviluppando il quadrato e sommando, si ottiene:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2.\n\\tag{57.3}\\]\nIl primo termine rappresenta la varianza residua, mentre il secondo termine rappresenta la varianza spiegata dal modello. Questa scomposizione della devianza va sotto il nome di teorema della scomposizione della devianza.\nQuesta scomposizione viene utilizzata per calcolare l’indice di determinazione \\(R^2\\), che fornisce una misura della bontà di adattamento del modello ai dati del campione. L’indice di determinazione \\(R^2\\) è definito come il rapporto tra la varianza spiegata e la varianza totale:\n\\[\nR^2 = \\frac{\\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}.\n\\tag{57.4}\\]\nQuesto indice varia tra 0 e 1 e indica la frazione di varianza totale di \\(y\\) spiegata dal modello di regressione lineare. Un valore alto di \\(R^2\\) indica che il modello di regressione lineare si adatta bene ai dati, in quanto una grande parte della varianza di \\(y\\) è spiegata dalla variabile indipendente \\(x\\).\nPer l’esempio in discussione, possiamo calcolare la devianza totale, la devianza spiegata e l’indice di determinazione \\(R^2\\) come segue:\nLa devianza totale misura la variabilità complessiva dei punteggi osservati \\(y\\) rispetto alla loro media:\n\n# Devianza totale\ndev_t &lt;- sum((kidiq$kid_score - mean(kidiq$kid_score))^2)\ndev_t\n#&gt; [1] 180386\n\nLa devianza spiegata misura la variabilità che il modello è in grado di spiegare, considerando i valori predetti \\(a + b x\\):\n\n# Devianza spiegata\ndev_r &lt;- sum(((a + b * kidiq$mom_iq) - mean(kidiq$kid_score))^2)\ndev_r\n#&gt; [1] 36249\n\nL’indice \\(R^2\\) è il rapporto tra la devianza spiegata e la devianza totale, e indica la frazione della variabilità totale che è spiegata dal modello di regressione:\n\n# Indice di determinazione\nR2 &lt;- dev_r / dev_t\nround(R2, 3)\n#&gt; [1] 0.201\n\nPer verificare i calcoli, utilizziamo il modello di regressione lineare in R e leggiamo \\(R^2\\) direttamente dal sommario del modello:\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Sommario del modello per leggere R^2\nsummary(mod)$r.squared\n#&gt; [1] 0.201\n\nIl risultato mostra che circa il 20% della variabilità nei punteggi del QI dei bambini è spiegabile conoscendo il QI delle madri. Questo significa che il modello cattura una porzione rilevante della relazione, ma lascia anche spazio a fattori non inclusi nel modello che influenzano il QI dei bambini.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sui-coefficienti",
    "href": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sui-coefficienti",
    "title": "57  La regressione lineare bivariata",
    "section": "\n57.8 Inferenza sui coefficienti",
    "text": "57.8 Inferenza sui coefficienti\nL’inferenza statistica sui coefficienti di regressione richiede la definizione della distribuzione campionaria dei coefficienti di regressione. Il modello di regressione bivariata (o lineare semplice) è:\n\\[Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i,\\] dove \\(Y_i\\) è la variabile dipendente per l’osservazione \\(i\\), \\(X_i\\) è la variabile indipendente, \\(\\beta_0\\) è l’intercetta (parametro ignoto), \\(\\beta_1\\) è il coefficiente angolare (il parametro che ci interessa stimare), e \\(\\varepsilon_i\\) è il termine di errore per l’osservazione \\(i\\).\nNell’inferenza, il nostro obiettivo è stimare i parametri ignoti \\(\\beta_0\\) e \\(\\beta_1\\) usando i dati campionari disponibili. Il metodo più comune è quello dei Minimi Quadrati Ordinari (OLS), che ci fornisce gli stimatori \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) (spesso indicati semplicemente con \\(b_0\\) e \\(b_1\\)). Lo stimatore per il coefficiente angolare è dato dalla formula:\n\\[\\hat{\\beta}_1 = b_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2}.\\]\n\n57.8.1 Cos’è la distribuzione campionaria di \\(b_1\\)?\nLo stimatore \\(b_1\\) è una variabile casuale. Perché? Perché il suo valore dipende dal campione casuale di dati \\((X_i, Y_i)\\) che abbiamo estratto dalla popolazione.\nImmaginiamo di poter ripetere il processo di campionamento e stima del modello infinite volte:\n\nEstraiamo un campione casuale di dimensione \\(n\\).\nCalcoliamo lo stimatore \\(b_1\\) per quel campione.\nRegistriamo il valore di \\(b_1\\).\nEstraiamo un nuovo campione casuale (indipendentemente dal primo).\nCalcoliamo il “nuovo” \\(b_1\\).\nRegistriamo il valore.\n… e così via, per infinite volte.\n\nLa distribuzione campionaria di \\(b_1\\) è la distribuzione di probabilità di tutti i valori di \\(b_1\\) che otterremmo da questi infiniti campioni casuali di dimensione \\(n\\) estratti dalla stessa popolazione.\n\n57.8.2 Assunzioni di Gauss–Markov e distribuzione campionaria della pendenza\nPer il modello di regressione bivariata\n\\[\nY_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i,\n\\] lo stimatore OLS della pendenza è\n\\[\n\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2}.\n\\] Questo è una variabile casuale, perché il suo valore dipende dal campione estratto.\n\n57.8.2.1 1. Assunzioni di Gauss–Markov\nAffinché \\(\\hat{\\beta}_1\\) sia non distorto (unbiased) e BLUE (Best Linear Unbiased Estimator), devono valere:\n\nLinearità nei parametri La relazione media tra \\(Y\\) e \\(X\\) è lineare: \\(E(Y_i \\mid X_i) = \\beta_0 + \\beta_1 X_i\\).\nCampionamento casuale e indipendenza Le osservazioni \\((X_i,Y_i)\\) sono indipendenti e identicamente distribuite.\nEsogeneità Gli errori hanno media nulla condizionata a \\(X\\): \\(E(\\varepsilon_i \\mid X_i) = 0\\). Se violata, lo stimatore è distorto.\nOmoschedasticità Varianza costante degli errori: \\(\\mathrm{Var}(\\varepsilon_i \\mid X_i) = \\sigma^2\\).\nAssenza di collinearità perfetta La variabilità di \\(X\\) è positiva: \\(\\sum_{i=1}^n (X_i - \\bar{X})^2 &gt; 0\\).\n\nPer inferenza esatta in piccoli campioni si aggiunge l’assunzione di normalità: \\(\\varepsilon_i \\sim N(0,\\sigma^2)\\).\n\n57.8.2.2 2. Proprietà della distribuzione campionaria di \\(\\hat{\\beta}_1\\)\n\nSotto le assunzioni di Gauss–Markov:\n\nMedia (non distorsione) \\(E(\\hat{\\beta}_1) = \\beta_1\\) → in media, il processo di stima restituisce il vero coefficiente.\n\nVarianza\n\\[\n\\mathrm{Var}(\\hat{\\beta}_1) = \\frac{\\sigma^2}{\\sum_{i=1}^n (X_i - \\bar{X})^2}\n\\]\ndove \\(\\sigma^2\\) è la varianza degli errori. In pratica si usa la stima:\n\\[\ns^2_e = \\frac{\\sum e_i^2}{n-2}, \\quad\nSE(\\hat{\\beta}_1) = \\sqrt{\\frac{s_e^2}{\\sum (X_i - \\bar{X})^2}}\n\\]\n\n\nForma della distribuzione\n\nCon normalità degli errori → distribuzione esatta normale per ogni \\(n\\).\nSenza normalità, per grandi \\(n\\) la distribuzione è approssimativamente normale (Teorema del Limite Centrale).\n\n\n\n57.8.2.3 3. Uso della distribuzione campionaria\nConoscere la distribuzione campionaria di \\(\\hat{\\beta}_1\\) serve per:\n\nTest d’ipotesi Es.: \\(H_0: \\beta_1 = 0\\), usando la statistica \\(t = \\hat{\\beta}_1 / SE(\\hat{\\beta}_1).\\)\nIntervalli di confidenza Es.: \\(\\hat{\\beta}_1 \\pm t_{n-2,\\,0.975} \\times SE(\\hat{\\beta}_1)\\), interpretati in termini di proprietà a lungo termine della procedura di campionamento.\n\nIn sintesi, la distribuzione campionaria di \\(b_1\\) descrive la variabilità attesa dello stimatore del coefficiente angolare attraverso diversi campioni casuali. Comprendere le sue proprietà (media, varianza, forma) è essenziale per interpretare correttamente i risultati di una regressione e trarre conclusioni affidabili sulla relazione nella popolazione.1\n\n57.8.3 Simulazione in R\nCalcoliamo la distribuzione campionaria di \\(\\hat{\\beta}_1\\). Iniziamo simulando un modello lineare bivariato con variabili standardizzate:\n\\[\nY_i = \\beta X_i + \\varepsilon_i, \\quad \\varepsilon_i \\sim N(0, \\sigma_\\varepsilon = 0.5),\n\\] con \\(\\beta = 1.5\\) e \\(n = 30\\) osservazioni.\nRipetiamo il campionamento \\(100{,}000\\) volte per approssimare la distribuzione campionaria di \\(\\hat{\\beta}_1\\).\n\n# Parametri\nbeta     &lt;- 1.5     # pendenza vera\nsigma_e  &lt;- 0.5     # deviazione standard errori\nn        &lt;- 30      # dimensione campione\nnrep     &lt;- 1e5     # numero repliche\n\n# X fissata una volta (come nelle assunzioni di Gauss-Markov)\nx &lt;- rnorm(n, mean = 0, sd = 1)\n\n# Stime memorizzate\nb_hat &lt;- numeric(nrep)\n\n# Simulazione\nfor (i in 1:nrep) {\n  e &lt;- rnorm(n, mean = 0, sd = sigma_e) # errori\n  y &lt;- beta * x + e                     # risposta\n  b_hat[i] &lt;- cov(x, y) / var(x)        # formula OLS\n}\n\nEsaminiamo i risultati:\n\n# Statistiche empiriche\nmean_b_hat &lt;- mean(b_hat)  # media stimata\nsd_b_hat   &lt;- sd(b_hat)    # deviazione standard stimata\n\n# Errore standard teorico\nse_theo &lt;- sqrt(sigma_e^2 / sum((x - mean(x))^2))\n\nc(media_empirica = mean_b_hat,\n  sd_empirica    = sd_b_hat,\n  SE_teorico     = se_theo)\n#&gt; media_empirica    sd_empirica     SE_teorico \n#&gt;          1.500          0.121          0.121\n\nGeneriamo un grafico della distribuzione:\n\nggplot(data.frame(b_hat = b_hat), aes(x = b_hat)) +\n  geom_histogram(aes(y = after_stat(density)),\n                 bins = 50) +\n  stat_function(fun = dnorm,\n                args = list(mean = mean_b_hat, sd = sd_b_hat),\n                linewidth = 1) +\n  labs(\n    title = expression(\"Distribuzione campionaria di\" ~ hat(beta)[1]),\n    x = expression(hat(beta)[1]),\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nL’analisi della distribuzione campionaria dello stimatore \\(\\hat{\\beta}_1\\) conferma tre proprietà statistiche fondamentali. In primo luogo, emerge la non distorsione dello stimatore: la media empirica calcolata si attesta approssimativamente a 1.5, valore che coincide con il parametro teorico \\(\\beta_1\\). Questo risultato fornisce una verifica empirica della proprietà per cui, sotto le assunzioni di Gauss-Markov, vale l’uguaglianza \\(E(\\hat{\\beta}_1) = \\beta_1\\), indicando che lo stimatore è corretto e non sistematicamente distorto.\nPer quanto riguarda la precisione dello stimatore, si osserva che la deviazione standard empirica risulta molto vicina all’errore standard teorico, definito come \\(SE(\\hat{\\beta}_1) = \\sqrt{\\sigma^2 / \\sum (X_i - \\bar{X})^2}\\). Questa corrispondenza suggerisce che la variabilità campionaria osservata è in linea con quanto previsto dal framework teorico, supportando l’affidabilità delle inferenze basate su questo stimatore.\nInfine, l’esame della forma della distribuzione rivela che l’istogramma dei valori stimati è ben approssimato da una curva normale. Questo risultato conferma la normalità asintotica dello stimatore anche per un campione di dimensione moderata (\\(n = 30\\)), avvallando l’utilizzo della distribuzione normale per la costruzione di intervalli di confidenza e test di ipotesi in questo contesto.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "href": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "title": "57  La regressione lineare bivariata",
    "section": "Riflessioni conclusive ",
    "text": "Riflessioni conclusive \nIn questo capitolo abbiamo visto come il modello di regressione lineare, nell’ottica frequentista, permetta di stimare e interpretare la relazione tra variabili, basandosi sul metodo dei minimi quadrati e verificando ipotesi precise. Abbiamo discusso il significato dei parametri, le condizioni di validità del modello e gli indici per valutarne la bontà di adattamento.\nTuttavia, questo approccio presenta alcuni limiti: non incorpora conoscenza pregressa sui parametri, si affida ai p-value per l’inferenza e richiede assunzioni rigide sulla distribuzione degli errori. Nel prossimo capitolo introdurremo l’approccio bayesiano alla regressione, che consente di integrare informazioni a priori e di esprimere le inferenze in termini di probabilità sui parametri, offrendo una prospettiva più flessibile e spesso più informativa.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n1 – Definizione e scopi della regressione\nSecondo Gelman et al. (2021), quali sono i quattro principali utilizzi della regressione? Fornisci una breve descrizione di ciascuno.\n2 – Errore di specificazione\nCos’è l’“errore di specificazione” in un modello di regressione? Quali effetti ha sulle stime dei parametri?\n3 – Stima del modello con lm()\nUsando il data‑set kidiq (variabili kid_score e mom_iq):\n\n# carica i dati\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\nAdatta il modello kid_score ~ mom_iq e riporta intercetta e pendenza.\n4 – Interpretazione della pendenza\nInterpreta in parole la pendenza stimata al punto 3 nel contesto dei QI di madri e figli.\n5 – Indice R²\nCalcola l’R² del modello di cui al punto 3. Cosa indica il suo valore?\n6 – Centratura del predittore\nCrea la variabile centrata mom_iq_c = mom_iq - mean(mom_iq) e ri‑adatta il modello kid_score ~ mom_iq_c. Qual è la nuova intercetta e perché adesso è più interpretabile?\n7 – Calcolo manuale di \\(b\\)\nCalcola manualmente la pendenza con la formula\\(b = \\frac{\\text{Cov}(x,y)}{\\text{Var}(x)}\\)\ne confrontala col risultato di lm().\n8 – Confronto tra σ̂ (tradizionale) e σ_CV\n* (a) Calcola l’errore standard della regressione (σ̂) usando il modello completo.\n* (b) Esegui una validazione incrociata leave‑one‑out (LOOCV) e ottieni σ_CV.\n* (c) Spiega perché, in genere, σ_CV è ≥ σ̂.\n9 – Assunzioni di Gauss‑Markov\nElenca le cinque assunzioni di Gauss‑Markov per la regressione lineare semplice e indica quale, se violata, rende distorto lo stimatore OLS della pendenza.\n10 – Simulazione della distribuzione campionaria di \\(b\\)\nSimula 100 000 campioni (n = 30) dal modello\\(Y_i = 1.5\\,X_i + \\varepsilon_i,\\; X_i \\sim \\mathcal N(0,1),\\; \\varepsilon_i \\sim \\mathcal N(0,0.5^2)\\).\nPer ogni campione calcola \\(b̂\\). Rappresenta l’istogramma dei 100 000 \\(b̂\\), riporta media e deviazione standard empiriche e confrontale con l’errore standard teorico.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1 – Definizione e scopi\n1. Previsione – modellare / predire nuove osservazioni.\n2. Esplorazione delle associazioni – quantificare relazioni \\(X \\rightarrow Y\\).\n3. Estrapolazione – generalizzare dal campione alla popolazione.\n4. Inferenza causale – stimare l’effetto di un intervento quando il design lo consente.\n2 – Errore di specificazione\nOmettere un predittore rilevante ⇒ i residui assorbono la sua varianza ⇒ stime di \\(b\\) distorte (bias) e varianze sottostimate → inferenze non valide.\n3 – Stima del modello\n\nlibrary(rio); library(here)\nkidiq &lt;- import(here(\"data\",\"kidiq.dta\"))\n\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\ncoef(mod)\n#&gt; (Intercept)      mom_iq \n#&gt;       25.80        0.61\n\nEsempio di output\n(Intercept)     mom_iq \n 25.800        0.610 \n4 – Interpretazione della pendenza\nUn punto in più di QI materno è associato, in media, a 0.61 punti di QI del figlio.\n5 – Indice R²\n\nsummary(mod)$r.squared\n#&gt; [1] 0.201\n\nOutput ≈ 0.20 ⇒ il 20 % della varianza di kid_score è spiegato da mom_iq.\n6 – Centratura\n\nkidiq$mom_iq_c &lt;- kidiq$mom_iq - mean(kidiq$mom_iq)\nmod_c &lt;- lm(kid_score ~ mom_iq_c, data = kidiq)\ncoef(mod_c)\n#&gt; (Intercept)    mom_iq_c \n#&gt;       86.80        0.61\n\nL’intercetta ora ≈ media del QI dei bambini quando il QI materno è medio.\nLa pendenza resta 0.61.\n7 – Calcolo manuale di b\n\nb_manual &lt;- cov(kidiq$mom_iq, kidiq$kid_score) / var(kidiq$mom_iq)\nall.equal(b_manual, coef(mod)[\"mom_iq\"])\n#&gt; [1] \"names for current but not for target\"\n\nTRUE → concordanza perfetta (salvo arrotondamenti).\n8 – σ̂ vs σ_CV\n\n# (a) σ̂\nsigma_hat &lt;- summary(mod)$sigma\n\n# (b) LOOCV\nn &lt;- nrow(kidiq)\nres_cv2 &lt;- numeric(n)\nfor (i in seq_len(n)){\n  fit_i &lt;- lm(kid_score ~ mom_iq, data = kidiq[-i,])\n  res_cv2[i] &lt;- (kidiq$kid_score[i] - predict(fit_i, kidiq[i,]))^2\n}\nsigma_CV &lt;- sqrt(mean(res_cv2))\n\nc(sigma_hat = sigma_hat, sigma_CV = sigma_CV)\n#&gt; sigma_hat  sigma_CV \n#&gt;      18.3      18.3\n\nσ_CV tende a superare σ̂ perché ogni predizione è fatta su dati che non hanno “visto” quell’osservazione → niente sovradimensionamento.\n9 – Assunzioni Gauss‑Markov\n1. Linearità nei parametri\n2. Campionamento casuale IID\n3. Esogeneità \\(E(\\varepsilon_i\\!\\mid X_i)=0\\) ← questa garantisce non‑distorsione\n4. Omoschedasticità\n5. Assenza di collinearità perfetta\n10 – Simulazione\n\nset.seed(123)\nbeta  &lt;- 1.5; sigma_e &lt;- 0.5; n  &lt;- 30; nrep &lt;- 1e5\nx &lt;- rnorm(n)\nb_hat &lt;- replicate(nrep, {\n  y &lt;- beta * x + rnorm(n, sd = sigma_e)\n  cov(x,y) / var(x)\n})\n\nmean_emp &lt;- mean(b_hat)\nsd_emp   &lt;- sd(b_hat)\nse_theo  &lt;- sqrt(sigma_e^2 / sum((x - mean(x))^2))\nc(media_empirica = mean_emp, sd_empirica = sd_emp, SE_teorico = se_theo)\n#&gt; media_empirica    sd_empirica     SE_teorico \n#&gt;         1.5001         0.0948         0.0946\n\nL’istogramma (codice sotto) mostra la forma quasi normale centrata su 1.5.\n\nhist(b_hat, breaks = 60, freq = FALSE, main = \"Distribuzione campionaria di b̂\",\n     xlab = \"b̂\"); curve(dnorm(x, mean_emp, sd_emp), add = TRUE, lwd = 2)\n\n\n\n\n\n\n\n- La media empirica ≈ 1.5 ⇒ unbiased.\n- La sd empirica ≈ SE teorico ⇒ formula varianza confermata.\n- Distribuzione simmetrica ≈ Normale ⇒ normalità asintotica verificata.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] broom_1.0.9           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        mgcv_1.9-3           \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        rmarkdown_2.29       \n#&gt; [19] tzdb_0.5.0            haven_2.5.5           ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] pacman_0.5.1          R.utils_2.13.0        readr_2.1.5          \n#&gt; [37] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [40] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [43] codetools_0.2-20      curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [46] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [55] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [58] rprojroot_2.1.1       hms_1.1.3             rstantools_2.5.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           forcats_1.0.0        \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          R.methodsS3_1.8.2    \n#&gt; [79] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [82] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [85] R.oo_1.27.1           lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "href": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "title": "57  La regressione lineare bivariata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi (III rist. 2023, Vol. 11, p. 320). Laterza.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "href": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "title": "57  La regressione lineare bivariata",
    "section": "",
    "text": "Per un approfondimento sull’approccio frequentista alla regressione, si veda, per esempio, Caudek & Luccio (2001).↩︎",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html",
    "href": "chapters/linear_models/02_regr_toward_mean.html",
    "title": "58  La regressione verso la media",
    "section": "",
    "text": "Introduzione\nI l concetto di regressione verso la media fu introdotto da Francis Galton studiando la trasmissione ereditaria dell’altezza. Egli osservò che i figli di padri molto alti tendevano sì ad essere sopra la media, ma meno dei loro padri; allo stesso modo, i figli di padri molto bassi risultavano meno estremi dei padri. Questo “ritorno parziale verso il centro” della distribuzione è il fenomeno che oggi chiamiamo regressione verso la media.\nPerché accade? Un’altezza eccezionale può essere il risultato della combinazione di fattori genetici, ambientali e casuali. I figli ereditano solo una parte di tali fattori e, con l’aggiunta di nuove influenze, la loro altezza tende ad avvicinarsi alla media della popolazione. Non significa che un figlio di un padre altissimo diventi basso: resta sopra la media, ma meno estremo.\nIl cuore statistico del fenomeno è la correlazione imperfetta tra le due variabili (altezza del padre e del figlio). Se la correlazione fosse 1, i valori estremi si replicherebbero perfettamente. Ma, quando \\(\\rho &lt; 1\\), i valori attesi dei figli sono più vicini alla media rispetto a quelli dei padri. Galton stimò una correlazione attorno a 0.5: dunque, gran parte ma non tutta l’estremità del tratto paterno si trasmette al figlio.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#introduzione",
    "href": "chapters/linear_models/02_regr_toward_mean.html#introduzione",
    "title": "58  La regressione verso la media",
    "section": "",
    "text": "Panoramica del capitolo\n\nOrigine storica e intuizione del fenomeno (Galton).\nRegressione e correlazione: forme standardizzate e non standardizzate.\nVisualizzazione della RTM tramite retta di regressione.\nRTM ≠ causalità: errori di misura e artefatti di selezione.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Basic Regression di Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (Second Edition).\nLeggere il capitolo Linear Statistical Models (Schervish & DeGroot, 2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(HistData)\n\n\n\n\n\n58.0.1 I dati di Galton\nEsaminiamo il fenomeno della regressione verso la media usando i dati di Galton. Nel pacchetto HistData di R sono disponibili i dati originali raccolti da Galton, che includono informazioni sull’altezza di padri, madri, figli maschi e femmine. Per semplificare l’analisi, possiamo creare un dataset che include solo l’altezza del padre e l’altezza di un figlio maschio scelto casualmente da ogni famiglia:\n\nset.seed(1234)\n\ngalton_heights &lt;- GaltonFamilies |&gt;\n  filter(gender == \"male\") |&gt;\n  group_by(family) |&gt;\n  sample_n(1) |&gt;\n  ungroup() |&gt;\n  select(father, childHeight) |&gt;\n  rename(son = childHeight)\n\nQuesto dataset contiene due colonne: father (altezza del padre) e son (altezza del figlio maschio). Calcolando la media e la deviazione standard delle altezze dei padri e dei figli, otteniamo:\n\ngalton_heights |&gt; \n  summarize(\n    mean_father = mean(father), \n    sd_father   = sd(father),\n    mean_son    = mean(son), \n    sd_son      = sd(son)\n  )\n#&gt; # A tibble: 1 × 4\n#&gt;   mean_father sd_father mean_son sd_son\n#&gt;         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1        69.1      2.55     69.1   2.62\n\nI risultati mostrano che, in media, i padri e i figli hanno altezze simili, anche se le distribuzioni non sono identiche. Un grafico di dispersione (scatterplot) evidenzia una chiara tendenza: padri più alti tendono ad avere figli più alti:\n\ngalton_heights |&gt;\n  ggplot(aes(father, son)) +\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\n58.0.2 Il coefficiente di correlazione\nLa forza e la direzione dell’associazione lineare tra le due variabili sono misurate dal coefficiente di correlazione di Pearson, definito come:\n\\[\n\\rho = \\frac{1}{n}\\sum_{i=1}^n\n\\left(\\frac{x_i - \\mu_x}{\\sigma_x}\\right)\n\\left(\\frac{y_i - \\mu_y}{\\sigma_y}\\right).\n\\]\ndove \\(\\mu_X, \\mu_Y\\) sono le medie e \\(\\sigma_X, \\sigma_Y\\) le deviazioni standard delle rispettive popolazioni. La sua stima campionaria, \\(r\\), è calcolata in R come:\n\ngalton_heights |&gt; \n  summarize(r = cor(father, son)) |&gt; \n  pull(r)\n#&gt; [1] 0.443\n\nUn coefficiente di 0.5 indica un’associazione lineare positiva di moderata intensità, implicando che l’altezza paterna spiega solo parzialmente la variabilità dell’altezza dei figli.\n\n58.0.3 L’aspettativa condizionata e l’emergenza del fenomeno di regressione\nUn obiettivo inferenziale comune è la stima del valore atteso dell’altezza del figlio (\\(Y\\)), condizionata a un specifico valore dell’altezza del padre (\\(X = x_0\\)), formalmente \\(\\mathbb{E}(Y \\mid X = x_0)\\).\nUn approccio intuitivo è stratificare i dati e calcolare la media campionaria del sottogruppo. Ad esempio, per \\(X = 72\\) pollici:\n\ngalton_heights |&gt; \n  filter(round(father) == 72) |&gt;\n  summarize(avg_son = mean(son))\n#&gt; # A tibble: 1 × 1\n#&gt;   avg_son\n#&gt;     &lt;dbl&gt;\n#&gt; 1    70.2\n\nTale stima risulta sistematicamente più vicina alla media generale di \\(Y\\) di quanto \\(x_0\\) non lo sia alla media di \\(X\\). Questo fenomeno è noto come regressione verso la media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#visualizzare-del-fenomeno-attraverso-la-stratificazione",
    "href": "chapters/linear_models/02_regr_toward_mean.html#visualizzare-del-fenomeno-attraverso-la-stratificazione",
    "title": "58  La regressione verso la media",
    "section": "\n58.1 Visualizzare del fenomeno attraverso la stratificazione",
    "text": "58.1 Visualizzare del fenomeno attraverso la stratificazione\nIl fenomeno è generalizzabile visualizzando la media condizionata \\(\\mathbb{E}(Y \\mid X = x)\\) per diversi valori di \\(x\\), ottenuti tramite stratificazione:\n\ngalton_heights |&gt;\n  mutate(father_strata = factor(round(father))) |&gt;\n  group_by(father_strata) |&gt;\n  summarize(avg_son = mean(son)) |&gt;\n  ggplot(aes(x = father_strata, y = avg_son)) +\n  geom_point()\n\n\n\n\n\n\n\nLa nube di punti delle medie condizionate presenta una pendenza positiva ma inferiore a 45°, dimostrando visivamente la regressione verso la media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#modello-di-regressione-lineare-e-interpretazione-dei-parametri",
    "href": "chapters/linear_models/02_regr_toward_mean.html#modello-di-regressione-lineare-e-interpretazione-dei-parametri",
    "title": "58  La regressione verso la media",
    "section": "\n58.2 Modello di regressione lineare e interpretazione dei parametri",
    "text": "58.2 Modello di regressione lineare e interpretazione dei parametri\nIl modello statistico che formalizza questa relazione è la regressione lineare semplice:\n\\[\nY = \\beta_0 + \\beta_1 X + \\varepsilon ,\n\\]\ndove \\(\\epsilon\\) è un termine di errore stocastico con media zero.\nGli stimatori dei minimi quadrati ordinari (OLS) per i parametri \\(\\beta_0\\) (intercetta) e \\(\\beta_1\\) (pendenza) sono:\n\\[\n\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}, \\quad \\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}\n\\]\ndove \\(s_X\\), \\(s_Y\\) sono le deviazioni standard campionarie e \\(\\bar{X}\\), \\(\\bar{Y}\\) le medie campionarie.\nL’applicazione del modello ai dati di Galton fornisce:\n\nfit &lt;- lm(son ~ father, data = galton_heights)\ncoef(fit)\n#&gt; (Intercept)      father \n#&gt;      37.632       0.456\n\nLa pendenza stimata \\(\\hat{\\beta}_1 = 0.454\\) conferma che per ogni pollice in più del padre, l’altezza attesa del figlio aumenta di circa 0.454 pollici, un valore inferiore a 1 che è consistente con la regressione verso la media.\n\n58.2.0.1 Standardizzazione\nStandardizzando le variabili (\\(Z_X = (X - \\bar{X})/s_X\\), \\(Z_Y = (Y - \\bar{Y})/s_Y\\)), il modello di regressione assume la forma\n\\[\nZ_Y = \\rho\\, Z_X + \\varepsilon.\n\\]\nVediamo come si arriva a questo risultato. Consideriamo il modello lineare semplice\n\\[\nY = \\beta_0 + \\beta_1 X + \\varepsilon,\n\\qquad \\mathbb{E}[\\varepsilon] = 0,\n\\qquad \\mathrm{Cov}(X,\\varepsilon) = 0.\n\\]\nDalle equazioni normali dei minimi quadrati otteniamo, a livello di popolazione:\n\\[\n\\beta_1 = \\frac{\\mathrm{Cov}(X,Y)}{\\mathrm{Var}(X)},\n\\qquad\n\\beta_0 = \\mu_Y - \\beta_1 \\mu_X.\n\\]\nScrivendo la covarianza come \\(\\mathrm{Cov}(X,Y) = \\rho \\sigma_X \\sigma_Y\\), segue che\n\\[\n\\beta_1 = \\rho \\,\\frac{\\sigma_Y}{\\sigma_X}.\n\\]\nSe ora standardizziamo \\(X\\) e \\(Y\\), entrambe le deviazioni standard valgono 1, quindi la pendenza diventa\n\\[\n\\beta_1^* = \\rho.\n\\]\nInoltre, poiché le variabili standardizzate hanno media zero, anche l’intercetta scompare.\nIn conclusione, la regressione di \\(Z_Y\\) su \\(Z_X\\) ha sempre intercetta pari a 0 e coefficiente angolare pari alla correlazione \\(\\rho\\).\nInfatti, nei dati campionari:\n\nfit_standardized &lt;- lm(scale(son) ~ scale(father), data = galton_heights)\ncoef(fit_standardized)\n#&gt;   (Intercept) scale(father) \n#&gt;     -7.60e-15      4.43e-01\n\nLa pendenza è \\(0.4434\\), numericamente uguale alla correlazione \\(r\\) calcolata in precedenza (a meno di errori di arrotondamento). Poiché \\(|\\rho| &lt; 1\\), la previsione per un valore standardizzato \\(z_x\\) sarà \\(\\hat{z}_y = \\rho z_x\\), che è sempre, in valore assoluto, minore di \\(z_x\\). Questo spiega matematicamente il perché un valore estremo di \\(X\\) porta a una previsione per \\(Y\\) che è meno estrema, ossia più vicina alla sua media standardizzata (zero).\nIn sintesi, la correlazione imperfetta (\\(\\rho &lt; 1\\)) è la ragione principale per cui un valore estremo di \\(X\\) (ad esempio, un padre molto alto) porta a un valore \\(\\hat{Y}\\) che è sì superiore (o inferiore) alla media, ma meno estremo del padre. Questo “ritorno verso il centro” è ciò che chiamiamo regressione verso la media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#riflessioni-conclusive",
    "href": "chapters/linear_models/02_regr_toward_mean.html#riflessioni-conclusive",
    "title": "58  La regressione verso la media",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa regressione verso la media è un fenomeno statistico che si verifica inevitabilmente quando due misurazioni della stessa variabile presentano una correlazione imperfetta (0 &lt; \\(\\rho\\) &lt; 1). In tali condizioni, i valori estremi osservati nella prima misurazione (\\(X\\)) sono associati, nella seconda misurazione (\\(Y\\)), a valori che si discostano meno dalla media della distribuzione.\nDal punto di vista matematico, il valore atteso condizionato del punteggio standardizzato \\(Z_Y\\), dato il punteggio \\(Z_X = z\\), è: \\(\\mathbb{E}[Z_Y \\mid Z_X = z] = \\rho z\\). Ne consegue che la retta di regressione dei punteggi standardizzati ha una pendenza pari a \\(\\rho\\), inferiore a 1, riflettendo il caratteristico richiamo dei valori verso la media.\nLa causa fondamentale di questo fenomeno risiede nell’affidabilità non perfetta delle misurazioni psicologiche. L’errore di misura e la componente di variabilità casuale fanno sì che parte dell’estremità osservata in \\(X\\) sia attribuibile a fluttuazioni transitorie piuttosto che a differenze individuali stabili. Di conseguenza, l’entità della regressione verso la media è inversamente proporzionale all’affidabilità dello strumento di misura: minore è l’affidabilità, maggiore sarà l’effetto.\nLe implicazioni pratiche di questo artefatto statistico sono notevoli. In contesti pre-post privi di gruppo di controllo, un apparente miglioramento dei soggetti con punteggi iniziali bassi, così come un peggioramento di quelli con punteggi iniziali alti, può essere interamente attribuibile alla regressione verso la media, in assenza di qualsiasi effetto reale dell’intervento.\nPertanto, per isolare e correggere tale artefatto, è indispensabile adottare disegni di ricerca appropriati, quali l’inclusione di un gruppo di controllo randomizzato, e tecniche analitiche specifiche. Queste includono:\n\nmodelli di regressione che controllano il punteggio di base (ANCOVA);\nmodelli gerarchici o ad equazioni strutturali in grado di tenere esplicitamente conto dell’errore di misura.\nprocedure di correzione basate sulla stima dell’affidabilità della misura.\n\nL’impiego di tali metodologie consente di distinguere i cambiamenti genuini dagli artefatti statistici, evitando interpretazioni erronee degli effetti osservati. Questi accorgimenti permettono di evitare di attribuire erroneamente a un intervento o a un predittore ciò che in realtà è un artefatto statistico.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HistData_0.9-3        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] pacman_0.5.1          digest_0.6.37         timechange_0.3.0     \n#&gt; [10] estimability_1.5.1    lifecycle_1.0.4       survival_3.8-3       \n#&gt; [13] magrittr_2.0.3        compiler_4.5.1        rlang_1.1.6          \n#&gt; [16] tools_4.5.1           knitr_1.50            labeling_0.4.3       \n#&gt; [19] bridgesampling_1.1-2  htmlwidgets_1.6.4     curl_7.0.0           \n#&gt; [22] pkgbuild_1.4.8        RColorBrewer_1.1-3    abind_1.4-8          \n#&gt; [25] multcomp_1.4-28       withr_3.0.2           purrr_1.1.0          \n#&gt; [28] grid_4.5.1            stats4_4.5.1          colorspace_2.1-1     \n#&gt; [31] xtable_1.8-4          inline_0.3.21         emmeans_1.11.2-8     \n#&gt; [34] scales_1.4.0          MASS_7.3-65           cli_3.6.5            \n#&gt; [37] mvtnorm_1.3-3         rmarkdown_2.29        ragg_1.5.0           \n#&gt; [40] generics_0.1.4        RcppParallel_5.1.11-1 cachem_1.1.0         \n#&gt; [43] stringr_1.5.1         splines_4.5.1         parallel_4.5.1       \n#&gt; [46] vctrs_0.6.5           V8_7.0.0              Matrix_1.7-4         \n#&gt; [49] sandwich_3.1-1        jsonlite_2.0.0        arrayhelpers_1.1-0   \n#&gt; [52] systemfonts_1.2.3     glue_1.8.0            codetools_0.2-20     \n#&gt; [55] distributional_0.5.0  lubridate_1.9.4       stringi_1.8.7        \n#&gt; [58] gtable_0.3.6          QuickJSR_1.8.0        htmltools_0.5.8.1    \n#&gt; [61] Brobdingnag_1.2-9     R6_2.6.1              textshaping_1.0.3    \n#&gt; [64] rprojroot_2.1.1       evaluate_1.0.5        lattice_0.22-7       \n#&gt; [67] backports_1.5.0       memoise_2.0.1         broom_1.0.9          \n#&gt; [70] snakecase_0.11.1      rstantools_2.5.0      coda_0.19-4.1        \n#&gt; [73] gridExtra_2.3         nlme_3.1-168          checkmate_2.3.3      \n#&gt; [76] xfun_0.53             zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#bibliografia",
    "href": "chapters/linear_models/02_regr_toward_mean.html#bibliografia",
    "title": "58  La regressione verso la media",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html",
    "href": "chapters/linear_models/03_reglin_bayes.html",
    "title": "59  Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "Introduzione\nI n questa sezione della dispensa esploreremo il modello di regressione lineare, ponendo particolare attenzione alla formulazione bayesiana. Confronteremo questo approccio con quello frequentista, così da mettere in luce i principali vantaggi dell’inferenza bayesiana, senza introdurre tecnicismi inutilmente complessi. Il nostro obiettivo comprendere come si costruisce un modello di regressione e come si interpretano i risultati nel contesto dell’incertezza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#introduzione",
    "href": "chapters/linear_models/03_reglin_bayes.html#introduzione",
    "title": "59  Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "Panoramica del capitolo\n\nComprendere il modello di regressione bayesiano e come si differenzia dall’approccio frequentista.\nInterpretare i parametri stimati in un contesto bayesiano e confrontarli con quelli frequentisti.\nFamiliarizzare con l’uso di brms nella regressione.\nInterpretare le previsioni del modello bayesiano e le verifiche predittive a posteriori.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere l’Appendice O.\nLeggere il capitolo Simple Normal Regression di Johnson et al. (2022).\nConsultare Regression and Other Stories (Gelman et al., 2021).\n\nIl pdf del libro è consultabile gratuitamente su questo sito.\nPrestare particolare attenzione ai capitoli 1 “Overeview, 6,”Background on Regression Modeling,” 7, “Linear Regression with a Single Predictor” e 8, “Fitting regression models”, che offrono una guida dettagliata al modello di regressione bivariato da una prospettiva bayesiana.\n\n\nPer utilizzare il pacchetto R brms, è necessario installare preliminarmente Stan o CmdStan sul proprio computer. Si consiglia di optare per CmdStan. Il metodo più semplice per installare CmdStan consiste nell’installare il pacchetto R cmdstanr e seguire le istruzioni fornite nella documentazione.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, see, brms)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#lapproccio-bayesiano",
    "href": "chapters/linear_models/03_reglin_bayes.html#lapproccio-bayesiano",
    "title": "59  Modello bayesiano di regressione lineare bivariata",
    "section": "\n59.1 L’approccio bayesiano",
    "text": "59.1 L’approccio bayesiano\nNella statistica frequentista, i parametri di un modello – come l’intercetta, la pendenza o la deviazione standard degli errori – vengono trattati come quantità fisse sebbene sconosciute. L’incertezza associata alle loro stime viene espressa indirettamente attraverso concetti quali intervalli di confidenza o valori-\\(p\\) nei test di ipotesi.\nL’approccio bayesiano propone una prospettiva radicalmente diversa: i parametri sono considerati variabili aleatorie, ciascuna descritta da una propria distribuzione di probabilità. Questo framework consente di rappresentare l’incertezza in modo esplicito e diretto. Il processo inferenziale bayesiano si articola fondamentalmente in tre fasi.\nLa prima fase riguarda la scelta delle distribuzioni a priori. Prima di osservare i dati, viene assegnata a ciascun parametro una distribuzione di probabilità iniziale, detta prior, che incorpora ogni conoscenza preesistente o ipotesi plausibili sul fenomeno in studio. Ad esempio, se la letteratura scientifica suggerisce consistentemente che l’ansia riduca la performance, è possibile specificare un prior informativo per il coefficiente di regressione corrispondente, come una distribuzione normale centrata su un valore negativo con deviazione standard moderata, formalmente indicata come \\(b \\sim \\mathcal{N}(-0.7, 0.3)\\). Al contrario, in assenza di informazioni preliminari solide, si può ricorrere a un prior debole o vago, che esprima una grande incertezza iniziale. Un prior di questo tipo, ad esempio \\(b \\sim \\mathcal{N}(0, 100)\\), assegna probabilità pressoché uniformi a un ampio spettro di valori, permettendo ai dati osservati di dominare completamente la stima finale, che risulterà quindi molto vicina a quella ottenuta con metodi frequentisti.\nLa seconda fase consiste nell’aggiornamento delle credenze attraverso i dati osservati. Applicando il teorema di Bayes, le distribuzioni a priori vengono combinate con la verosimiglianza dei dati, dando origine alla distribuzione a posteriori dei parametri. Formalmente, questo si esprime attraverso la proporzionalità:\n\\[\nP(a, b, \\sigma \\mid \\text{dati}) \\propto P(\\text{dati} \\mid a, b, \\sigma) \\cdot P(a, b, \\sigma).\n\\]\nIl risultato di questo aggiornamento bayesiano è una distribuzione di probabilità congiunta per i parametri, che quantifica in modo probabilistico la plausibilità dei loro diversi valori, alla luce sia dell’evidenza empirica sia delle assunzioni iniziali.\nLa terza fase è dedicata all’interpretazione della distribuzione a posteriori. In questo approccio, non si ottiene un’unica stima puntuale per la retta di regressione, bensì un’intera famiglia di rette plausibili, ciascuna associata a un differente grado di credibilità probabilistica. L’incertezza viene sintetizzata e comunicata attraverso intervalli di credibilità. A differenza degli intervalli di confidenza di impostazione frequentista, un intervallo di credibilità bayesiano del 95% ammette un’interpretazione probabilistica diretta: esiste una probabilità del 95% che il vero valore del parametro sia contenuto al suo interno, dato il modello, i prior specificati e i dati osservati.\nL’approccio bayesiano offre diversi vantaggi, sia di natura pratica che teorica. Permette l’integrazione formale di conoscenze pregresse, facilitando la cumulatività della ricerca, ad esempio attraverso l’incorporazione di risultati di meta-analisi in nuovi studi. Mostra una notevole robustezza in presenza di campioni di piccole dimensioni, poiché i prior svolgono una funzione di regolarizzazione che stabilizza le stime, mitigando il rischio di overfitting. Fornisce, infine, interpretazioni intuitive dell’incertezza, allineate al ragionamento probabilistico naturale. Per queste ragioni, la statistica bayesiana risulta particolarmente adatta alla ricerca psicologica, un campo che spesso deve operare con campioni limitati e nel quale i nuovi risultati devono essere costantemente integrati in un corpus di conoscenze in evoluzione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#il-modello-di-regressione-lineare-semplice",
    "href": "chapters/linear_models/03_reglin_bayes.html#il-modello-di-regressione-lineare-semplice",
    "title": "59  Modello bayesiano di regressione lineare bivariata",
    "section": "\n59.2 Il modello di regressione lineare semplice",
    "text": "59.2 Il modello di regressione lineare semplice\nPer illustrare concretamente il modello di regressione lineare semplice, consideriamo un esempio di comune interesse in psicologia: prevedere il livello di ansia di un individuo (indicato con \\(y\\)) in base al numero di ore di sonno (indicato con \\(x\\)) da egli riportate. La relazione lineare tra queste due variabili viene formalizzata attraverso il modello:\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i,\n\\] dove \\(\\beta_0\\) rappresenta l’intercetta, ovvero il valore atteso della variabile ansia quando il numero di ore di sonno è pari a zero. Il parametro \\(\\beta_1\\) è il coefficiente di regressione, che quantifica la variazione attesa nel livello di ansia per ogni ora aggiuntiva di sonno. Il termine \\(\\varepsilon_i\\) costituisce l’errore casuale, capace di catturare la deviazione del punteggio osservato di ansia del singolo individuo rispetto al valore predetto dalla retta di regressione.\nUn’assunzione fondamentale del modello riguarda proprio il termine di errore. Si assume che gli errori \\(\\varepsilon_i\\) siano tra loro indipendenti e seguano una distribuzione normale con media zero e varianza costante \\(\\sigma^2\\). Questa assunzione implica a sua volta che, per un dato valore di \\(x\\), i valori osservati della variabile \\(y\\) siano distribuiti normalmente attorno alla media condizionata \\(\\mu_i\\). Formalmente:\n\\[\ny_i \\mid x_i \\sim \\mathcal{N}(\\mu_i, \\sigma^2), \\quad \\text{dove} \\quad \\mu_i = \\beta_0 + \\beta_1 x_i.\n\\]\nIn termini sostanziali, il modello non presuppone che tutti gli individui con lo stesso numero di ore di sonno presentino un identico livello di ansia. Piuttosto, esso descrive come i loro punteggi si distribuiscano in modo aleatorio attorno a un valore medio, il quale è deterministicamente determinato dalla relazione lineare con la variabile esplicativa. La retta di regressione rappresenta dunque la tendenza centrale di questa relazione, mentre la variabilità residua attorno alla retta è attribuita a fattori non misurati o al caso.\n\n59.2.1 Cos’è la verosimiglianza?\nIl concetto di verosimiglianza rappresenta una misura fondamentale dell’adeguatezza di un insieme di parametri nel descrivere i dati osservati. Nel contesto della regressione lineare, la verosimiglianza dipende specificamente dai parametri β₀, β₁ e σ.\nPer ciascuna osservazione yᵢ, la probabilità di osservare quel particolare dato è espressa dalla funzione di densità di una distribuzione normale. Supponendo l’indipendenza delle osservazioni, la verosimiglianza congiunta per l’intero campione si ottiene attraverso il prodotto delle densità individuali:\n\\[\n\\mathcal{L}(\\beta_0, \\beta_1, \\sigma \\mid \\mathbf{y}, \\mathbf{x}) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\!\\left(-\\frac{(y_i - \\beta_0 - \\beta_1 x_i)^2}{2\\sigma^2}\\right).\n\\]\nData la complessità computazionale che deriva dal lavorare con prodotti di molteplici termini, nella pratica statistica si ricorre frequentemente alla log-verosimiglianza. Questa trasformazione, mantenendo le proprietà di ottimizzazione della funzione originale, converte il prodotto in una somma, semplificando notevolmente i calcoli:\n\\[\n\\log \\mathcal{L}(\\beta_0, \\beta_1, \\sigma \\mid \\mathbf{y}, \\mathbf{x}) = -\\frac{n}{2}\\log(2\\pi) - n\\log\\sigma - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i)^2.\n\\]\n\n59.2.1.1 Verosimiglianza: confronto tra approccio frequentista e bayesiano\nIl ruolo della verosimiglianza assume significati differenti nei due paradigmi statistici principali. Nell’approccio frequentista, la procedura di stima si basa sull’identificazione dei valori parametrici che massimizzano la funzione di verosimiglianza, dando origine al metodo della massima verosimiglianza. Questi valori costituiscono le stime puntuali considerate ottimali per i parametri del modello.\nNell’approccio bayesiano, la verosimiglianza rappresenta soltanto uno dei componenti del processo inferenziale. Essa viene integrata con le distribuzioni a priori assegnate ai parametri, attraverso l’applicazione del teorema di Bayes. Questa combinazione produce la distribuzione a posteriori, che costituisce la base per tutte le inferenze successive, fornendo una rappresentazione completa dell’incertezza associata ai parametri del modello.\n\n59.2.2 Le distribuzioni a priori\nUn elemento caratterizzante dell’approccio bayesiano risiede nella specificazione delle distribuzioni a priori. Queste distribuzioni formalizzano matematicamente le credenze iniziali riguardo ai parametri del modello, prima di prendere in considerazione i dati osservati. È possibile identificare tre categorie principali di distribuzioni a priori.\nLe distribuzioni non informative intendono rappresentare una situazione di massima ignoranza o neutralità iniziale. Il loro obiettivo è permettere ai dati osservati di determinare completamente le stime finali, senza esercitare alcuna influenza sostanziale. Un esempio tipico è una distribuzione normale con media zero e varianza molto ampia, come ((0, 1000)).\nLe distribuzioni debolmente informative forniscono una regolarizzazione moderata, imponendo dei vincoli molto larghi ma in grado di evitare stime parametriche in regioni chiaramente implausibili o numericamente instabili. Questo tipo di prior può migliorare la stabilità delle stime, specialmente con campioni di piccole dimensioni, senza introdurre forti assunzioni sostanziali. Un esempio comune per un coefficiente di regressione potrebbe essere ((0, 2.5)).\nLe distribuzioni informative incorporano in modo esplicito conoscenze provenienti da letteratura preesistente, teorie consolidate o esperienza empirica. Sono caratterizzate da una varianza ridotta, che riflette un grado di certezza iniziale più elevato. Il loro utilizzo può aumentare notevolmente l’efficienza dell’inferenza ma richiede una solida giustificazione teorica o empirica per la scelta dei loro iperparametri.\n\n59.2.3 Le distribuzioni a posteriori\nLa distribuzione a posteriori rappresenta il risultato fondamentale dell’inferenza bayesiana. Essa sorge dalla combinazione di due componenti: la verosimiglianza, che quantifica l’informazione contenuta nei dati osservati in relazione ai parametri, e le distribuzioni a priori, che esprimono le credenze iniziali.\nQuesta distribuzione congiunta a posteriori costituisce una rappresentazione probabilistica completa e aggiornata della nostra conoscenza riguardo ai parametri, condizionata all’evidenza empirica. A differenza delle tradizionali stime puntuali dell’approccio frequentista, il risultato bayesiano fornisce un’intera distribuzione di probabilità per ogni parametro. Questa ricchezza di informazione permette di quantificare l’incertezza in modo diretto e intuitivo, facilitando la costruzione di intervalli di credibilità e supportando un processo decisionale che integra coerentemente tutte le fonti di informazione disponibili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#implementazione-con-brms",
    "href": "chapters/linear_models/03_reglin_bayes.html#implementazione-con-brms",
    "title": "59  Modello bayesiano di regressione lineare bivariata",
    "section": "\n59.3 Implementazione con brms\n",
    "text": "59.3 Implementazione con brms\n\nNel pacchetto brms (che usa Stan come motore di calcolo), non è necessario scrivere la funzione di verosimiglianza a mano. Basta specificare il modello nella classica forma di Wilkinson:\nbrm(y ~ x, data = dati)\nQuesta notazione compatta definisce il modello di regressione, la verosimiglianza implicita e consente a brms di costruire automaticamente il modello bayesiano. Se non si specificano i prior, brms utilizza prior debolmente informativi di default.\n\n59.3.1 Come vengono stimate le distribuzioni a posteriori?\nPoiché la distribuzione a posteriori è spesso troppo complessa per essere calcolata esattamente, brms utilizza tecniche di campionamento numerico MCMC (Markov Chain Monte Carlo). In particolare, utilizza l’algoritmo NUTS (No-U-Turn Sampler), una variante evoluta dell’algoritmo di Metropolis-Hastings, che esplora lo spazio dei parametri in modo efficiente e adattivo. Grazie a questo, otteniamo campioni dalla distribuzione a posteriori, dai quali è possibile calcolare medie, intervalli di credibilità e fare previsioni.\nIn sintesi, il modello di regressione bayesiano consente di incorporare in modo trasparente incertezze, conoscenze pregresse e informazioni contenute nei dati. Rispetto all’approccio classico, non restituisce una singola stima puntuale ma un’intera distribuzione per ogni parametro. Questo permette inferenze più flessibili e più ricche di informazioni, particolarmente utili nelle scienze psicologiche, dove l’incertezza è la regola più che l’eccezione.\n\n59.3.2 Un esempio concreto\nDefiniamo i parametri e simuliamo i dati.\n\nset.seed(123)\n\n# Definizione delle variabili\nx &lt;- 1:100\nn &lt;- length(x)\na &lt;- 1.5\nb &lt;- 0.5\nsigma &lt;- 10\n\n# Generazione di y\ny &lt;- a + b * x + rnorm(n, 0, sigma)\n\n# Creazione del dataframe\nfake &lt;- tibble(x = x, y = y)\nhead(fake)\n#&gt; # A tibble: 6 × 2\n#&gt;       x      y\n#&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1     1 -3.60 \n#&gt; 2     2  0.198\n#&gt; 3     3 18.6  \n#&gt; 4     4  4.21 \n#&gt; 5     5  5.29 \n#&gt; 6     6 21.7\n\nIniziamo adattando ai dati un modello frequentista:\n\nfm1 &lt;- lm(y ~ x, data = fake)\n\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x, data = fake)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -24.536  -5.524  -0.346   6.485  20.949 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)   1.1360     1.8429    0.62     0.54\n#&gt; x             0.5251     0.0317   16.57   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 9.15 on 98 degrees of freedom\n#&gt; Multiple R-squared:  0.737,  Adjusted R-squared:  0.734 \n#&gt; F-statistic:  275 on 1 and 98 DF,  p-value: &lt;2e-16\n\nPer ottenere l’intervallo di confidenza (nel senso frequentista) della stima dei parametri usiamo:\n\nconfint(fm1, level = 0.95)\n#&gt;              2.5 % 97.5 %\n#&gt; (Intercept) -2.521  4.793\n#&gt; x            0.462  0.588\n\nAdattiamo ora ai dati un modello di regressione bayesiano utilizzando brms. Si noti che, anche in questo caso, usiamo la sintassi di Wilkinson y ~ x, come per lm(). Eseguiamo il campionamento:\n\nfm2 &lt;- brm(\n  y ~ x, \n  data = fake,\n  backend = \"cmdstanr\"\n)\n\nCome discusso nell’analisi dell’algoritmo di Metropolis, il primo passo è esaminare le tracce dei parametri per verificare la convergenza dell’algoritmo. La convergenza può essere considerata raggiunta se le catene (nel caso di brm, sono 4 per impostazione predefinita) risultano ben mescolate. Questo si manifesta in un trace plot che mostra una distribuzione uniforme e casuale dei campioni attorno a un valore centrale, senza pattern evidenti o tendenze sistematiche.\nLe tracce dei parametri si ottengono nel modo seguente:\n\nmcmc_trace(\n  fm2, \n  pars = c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nGli istogrammi delle distribuzioni a posteriori dei parametri si generano nel modo seguente:\n\nmcmc_hist(\n  fm2, \n  pars =c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nPer valutare l’autocorrelazione tra i campioni a posteriori del parametro beta, possiamo utilizzare il seguente comando:\n\nmcmc_acf(fm2, \"b_x\")\n\n\n\n\n\n\n\nL’autocorrelazione fornisce informazioni sulla dipendenza tra campioni successivi nella catena di Markov. È normale che i campioni successivi non siano completamente indipendenti, poiché le catene di Markov generano campioni correlati per costruzione. Tuttavia, se l’algoritmo ha raggiunto la convergenza, l’autocorrelazione dovrebbe diminuire rapidamente e diventare trascurabile dopo un numero relativamente piccolo di lag. Questo significa che, dopo un certo numero di passi, i campioni diventano progressivamente meno correlati tra loro, comportandosi in modo simile a campioni indipendenti estratti dalla distribuzione target.\nUn’elevata autocorrelazione su lag più lunghi potrebbe invece indicare problemi di mescolamento delle catene o una mancata convergenza, richiedendo ulteriori verifiche o aggiustamenti, come l’aumento del numero di iterazioni o una diversa parametrizzazione del modello.\nNel caso presente, notiamo una rapida diminuzione dell’autocorrelazione in funzione del numero di passi. Ciò è indicativo del fatto che la convergenza è stata raggiunta.\nUna sintesi numerica dei risultati si trova nel modo seguente:\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: y ~ x \n#&gt;    Data: fake (Number of observations: 100) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     1.17      1.79    -2.34     4.64 1.00     3981     2679\n#&gt; x             0.52      0.03     0.46     0.59 1.00     4004     2919\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     9.24      0.68     8.02    10.71 1.00     3848     2991\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nConfrontiamo le stime ottenute con i valori reali dei parametri simulati. L’intercetta è stata stimata attorno a 1.14, con un’incertezza al 95% che varia tra -2.4 e 4.8. Questo risultato rientra negli intervalli di credibilità previsti, confermando l’accuratezza del modello. Analogamente, per la pendenza \\(b\\), l’intervallo di credibilità al 95% include il valore reale simulato, dimostrando come le stime bayesiane riflettano accuratamente l’incertezza sui parametri.\nSe si utilizza la funzione conditional_effects() viene prodotto un grafico che rappresenta la relazione stimata tra il predittore \\(x\\) e la variabile di risposta \\(y\\).\n\nconditional_effects(fm2) |&gt;\n  plot(points = TRUE)\n\n\n\n\n\n\n\n\n\nLinea stimata (effetto medio):\n\nLa linea centrale del grafico rappresenta il valore medio previsto di \\(y\\) per ogni valore di \\(x\\), dato dalla relazione \\(y = \\alpha + \\beta x\\).\nQuesta linea è calcolata usando i valori medi a posteriori stimati per \\(\\alpha\\) e \\(\\beta\\).\n\n\n\nBande di incertezza (intervalli di credibilità):\n\nLe bande attorno alla linea rappresentano gli intervalli di credibilità (ad esempio, al 95%). Questi mostrano l’incertezza associata alle stime del modello per ogni valore di \\(x\\).\nPiù strette sono le bande, maggiore è la certezza del modello riguardo alla relazione stimata.\n\n\n\nDati osservati:\n\nI punti rappresentano i valori effettivi di \\(y\\) osservati nei dati. Questo consente di confrontare visivamente come i dati reali si allineano con le previsioni del modello.\n\n\n\nIl grafico consente\n\nuna verifica visiva della relazione stimata tra \\(y\\) e \\(x\\);\ndi identificazione di eventuali discrepanze tra i dati osservati e le previsioni del modello;\nuna rappresentazione dell’incertezza nelle stime.\n\nAd esempio, il grafico può mostrare se \\(x\\) ha un effetto credibile su \\(y\\) e con quale livello di incertezza. Se l’effetto di \\(x\\) è debole o nullo, la linea stimata sarà piatta (vicina a zero) e le bande di incertezza saranno ampie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "href": "chapters/linear_models/03_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "title": "59  Modello bayesiano di regressione lineare bivariata",
    "section": "\n59.4 Simulazione di livelli di copertura",
    "text": "59.4 Simulazione di livelli di copertura\nVerifichiamo la copertura degli intervalli di credibilità al 95% attraverso simulazioni ripetute.\n\nset.seed(42)\n# Parametri veri\na_true &lt;- 0.2\nb_true &lt;- 0.3\nsigma_true &lt;- 0.5\n# Numero di simulazioni\nnum_simulations &lt;- 100\n# Conteggio delle coperture\ncoverage_a &lt;- 0\ncoverage_b &lt;- 0\nfor (i in 1:num_simulations) {\n  # Generazione dei dati\n  x &lt;- 1:20\n  y &lt;- a_true + b_true * x + sigma_true * rnorm(length(x))\n  # Adattamento del modello\n  fit &lt;- lm(y ~ x)\n  ci &lt;- confint(fit) # Intervalli di confidenza\n  # Verifica delle coperture\n  if (ci[1,1] &lt;= a_true & ci[1, 2] &gt;= a_true) {\n    coverage_a &lt;- coverage_a + 1\n  }\n  if (ci[2,1] &lt;= b_true & ci[2, 2] &gt;= b_true) {\n    coverage_b &lt;- coverage_b + 1\n  }\n}\n\n\n# Risultati\ncat(\"Coverage for a:\", coverage_a / num_simulations, \"\\n\")\n#&gt; Coverage for a: 0.93\ncat(\"Coverage for b:\", coverage_b / num_simulations, \"\\n\")\n#&gt; Coverage for b: 0.96\n\nI risultati indicano che i livelli di copertura empirici ottenuti con l’approccio frequentista corrispondono strettamente ai livelli teorici attesi.\nPer proseguire, ripeteremo la simulazione adottando un approccio bayesiano. Useremo la funzione brm() del pacchetto brms al posto di lm().\n#| message: false\n#| warning: false\n#| output: false\n#| \nset.seed(23)\nn_fake   &lt;- 100\ncover_68 &lt;- logical(n_fake)\ncover_95 &lt;- logical(n_fake)\n\n# Veri parametri\na     &lt;- 0.2    # intercetta vera\nb     &lt;- 0.3    # pendenza vera\nsigma &lt;- 0.5    # deviazione standard vera\nx     &lt;- 1:20\nn     &lt;- length(x)\n\n# Priors con set_prior \npriors &lt;- c(\n  set_prior(\"normal(0, 2.5)\", class = \"Intercept\"),\n  set_prior(\"normal(0, 2.5)\", class = \"b\", coef = \"x\"),\n  set_prior(\"cauchy(0, 2.5)\", class = \"sigma\")\n)\n\nset.seed(23)\nn_fake   &lt;- 1000\ncover_68 &lt;- logical(n_fake)\ncover_95 &lt;- logical(n_fake)\n\na     &lt;- 0.2\nb     &lt;- 0.3\nsigma &lt;- 0.5\nx     &lt;- 1:20\nn     &lt;- length(x)\n\nfor (s in seq_len(n_fake)) {\n  y    &lt;- a + b * x + rnorm(n, 0, sigma)\n  fake &lt;- data.frame(x = x, y = y)\n\n  fit &lt;- brm(\n    y ~ 1 + x,\n    data    = fake,\n    family  = gaussian(),\n    prior   = priors,\n    iter    = 2000,\n    chains  = 2,\n    refresh = 0,\n    backend = \"cmdstanr\"\n  )\n\n  post &lt;- summary(fit)$fixed\n  b_hat &lt;- post[\"x\", \"Estimate\"]\n  b_se  &lt;- post[\"x\", \"Est.Error\"]\n\n  cover_68[s] &lt;- abs(b - b_hat) &lt; b_se\n  cover_95[s] &lt;- abs(b - b_hat) &lt; 2 * b_se\n}\n\ncat(\"Coverage 68%:\", mean(cover_68), \"\\n\")\ncat(\"Coverage 95%:\", mean(cover_95), \"\\n\")\nCon solo 100 iterazioni, i risultati sono i seguenti:\n&gt; cat(\"Coverage 68%:\", mean(cover_68), \"\\n\")\nCoverage 68%: 0.73 \n&gt; cat(\"Coverage 95%:\", mean(cover_95), \"\\n\")\nCoverage 95%: 0.953 \nQuesta seconda simulazione evidenzia che anche i livelli di copertura empirici ottenuti con l’approccio bayesiano si avvicinano ai valori teorici previsti.\nI risultati ottenuti confermano l’efficacia degli intervalli di confidenza e di credibilità stimati attraverso i modelli frequentisti e bayesiani.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#confronti-non-effetti",
    "href": "chapters/linear_models/03_reglin_bayes.html#confronti-non-effetti",
    "title": "59  Modello bayesiano di regressione lineare bivariata",
    "section": "\n59.5 Confronti, non effetti",
    "text": "59.5 Confronti, non effetti\nGelman et al. (2021) mettono in guardia contro un’interpretazione eccessivamente causale dei coefficienti di regressione. Sebbene nella pratica statistica sia comune riferirsi a questi coefficienti come “effetti”, tale terminologia può risultare fuorviante poiché suggerisce implicitamente l’esistenza di un nesso causale. In realtà, ciò che un modello di regressione stima rappresenta fondamentalmente un pattern osservazionale. Più precisamente, il coefficiente β₁ associato a una variabile esplicativa X cattura la differenza attesa nella media della variabile dipendente Y tra due sottopopolazioni che differiscono di un’unità nel valore di X.\nLa regressione lineare è essenzialmente uno strumento matematico progettato per analizzare associazioni e migliorare la capacità predittiva. I suoi coefficienti vanno interpretati primariamente come confronti medi tra gruppi definiti dai valori delle variabili esplicative. Un’interpretazione causale di questi coefficienti è legittima soltanto in contesti sperimentali specifici o quando il disegno di ricerca incorpora strategie identificative appropriate, come l’utilizzo di variabili strumentali, regression discontinuity design o altri metodi che mirano a controllare la confondazione. Tale interpretazione non può mai essere dedotta automaticamente dalla stima del modello statistico, ma deve essere giustificata da considerazioni metodologiche sostanziali relative al processo di generazione dei dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#riflessioni-conclusive",
    "href": "chapters/linear_models/03_reglin_bayes.html#riflessioni-conclusive",
    "title": "59  Modello bayesiano di regressione lineare bivariata",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo è stato approfondito il modello di regressione lineare bivariata attraverso la lente dell’approccio bayesiano. L’analisi ha mostrato come, mediante l’utilizzo di distribuzioni a priori debolmente informative, le stime dei parametri tendano a convergere con quelle prodotte dai metodi frequentisti, particolarmente quando il campione a disposizione è sufficientemente ampio. Tuttavia, il contributo distintivo del paradigma bayesiano va ben oltre la mera stima puntuale, risiedendo principalmente nella sua capacità di integrare formalmente la conoscenza preesistente e di rappresentare l’incertezza in modo completo ed esplicitamente probabilistico.\nIndipendentemente dalla scelta del framework statistico, è fondamentale mantenere una consapevolezza critica riguardo alla natura dei modelli statistici. Come evidenziato da Alexander (2023), i modelli non costituiscono rappresentazioni fedeli della realtà, bensì strumenti concettuali che ci permettono di attribuire significato ai fenomeni osservati. Essi funzionano come lenti interpretative, selezionando e mettendo a fuoco aspetti specifici della complessità empirica.\nNella ricerca psicologica, i modelli statistici assolvono tradizionalmente a due funzioni principali. La prima è di natura predittiva, concentrandosi sulla capacità del modello di generare previsioni accurate su nuovi dati. Questo approccio, di stampo pragmatico, valuta la bontà del modello principalmente attraverso la sua performance predittiva, spesso misurata con tecniche di validazione incrociata. La seconda funzione è inferenziale, e mira a discernere le relazioni causali tra le variabili. Affinché le inferenze causali possano considerarsi credibili, l’analisi di regressione deve essere sostenuta da un disegno di ricerca robusto – che può includere esperimenti controllati, disegni longitudinali o un’attenta gestione delle variabili confondenti – e da un solido fondamento teorico.\nLa regressione lineare, nella sua essenza, opera come una media ponderata delle osservazioni, il che comporta inevitabili limitazioni. I risultati possono essere influenzati da distorsioni dovute a variabili confondenti omesse dal modello; la qualità dei dati e il rispetto delle assunzioni sottostanti – quali la normalità degli errori, la loro indipendenza e l’omoschedasticità – sono cruciali per la validità delle conclusioni; infine, l’ipotesi di linearità potrebbe rivelarsi inadeguata a catturare la complessità di molte relazioni psicologiche, che spesso presentano dinamiche non lineari.\nAlla luce di queste considerazioni, è essenziale concepire il modello non come un fine ultimo, ma come uno strumento euristico e interpretativo da calare all’interno di un più ampio contesto teorico e metodologico. I risultati di un’analisi di regressione richiedono un’interpretazione critica che tenga conto del disegno di studio, del panorama letterario esistente e delle ipotesi di ricerca formulate.\nPer i lettori interessati ad approfondire l’applicazione dei metodi bayesiani alla regressione lineare, oltre al già citato testo di Johnson et al. (2022), si raccomanda la consultazione di Regression and Other Stories. Questo volume offre una guida pratica ricca di esempi applicati, rappresentando una risorsa preziosa per comprendere come implementare le tecniche bayesiane nell’analisi della regressione e come interpretarne i risultati in contesti di ricerca reali.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nVerosimiglianza\nDefinire la funzione di verosimiglianza per il modello bayesiano di regressione lineare bivariata, esplicitando i parametri e la loro interpretazione.\nScelta dei prior\nProporre un set di prior debolmente informativi differenti da quelli riportati, motivando la scelta delle distribuzioni.\nSimulazione dati\nScrivere un blocco di codice in R/Quarto per simulare un dataset con \\(n=50\\), parametri \\(lpha=2\\), \\(eta=0.5\\), \\(\\sigma=1\\) e visualizzare un grafico dispersione con la retta di regressione vera.\nStima frequentista vs bayesiana\nUtilizzando i dati simulati, adattare un modello con lm() e uno con brm() (specificando i prior). Confrontare i risultati prodotti dai due approcci, riportando i valori stimati e gli intervalli di confidenza/credibilità.\nDiagnosi MCMC\nElencare e spiegare almeno tre controlli diagnostici da effettuare sulle catene MCMC per garantire la convergenza e un buon mescolamento.\nInterpretazione dei coefficienti\nIn un contesto osservazionale, discutere perché non è appropriato interpretare i coefficienti della regressione come effetti causali. Fare riferimento ai concetti di confondimento e disegno sperimentale.\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nVerosimiglianza\n\\[\n\\mathcal{L}(\\alpha, \\beta, \\sigma \\mid y, x) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(y_i - (\\alpha + \\beta x_i))^2}{2\\sigma^2}\\right).\n\\]\n\n\nScelta dei prior\nAd esempio:\n\n\n\\(\\alpha \\sim \\mathcal{N}(0, 5)\\): consente maggiore variabilità iniziale;\n\n\n\\(\\beta \\sim \\text{Student-}t(3, 0, 2)\\): robuste alle code pesanti;\n\n\n\\(\\sigma \\sim \\text{Half-}Cauchy(0, 1)\\): prior leggermente più stretto sulle deviazioni.\n\n\n\nSimulazione dati\nset.seed(42)\nn &lt;- 50\nalpha &lt;- 2\nbeta  &lt;- 0.5\nsigma &lt;- 1\nx &lt;- rnorm(n, 0, 1)\ny &lt;- alpha + beta * x + rnorm(n, 0, sigma)\nplot(x, y, main = \"Dati simulati\", xlab = \"x\", ylab = \"y\")\nabline(a = alpha, b = beta, col = \"blue\", lwd = 2)\n\n\nStima frequentista vs bayesiana\n\n\nFrequentista (lm()):\nfm_f &lt;- lm(y ~ x)\nsummary(fm_f)\nconfint(fm_f, level = 0.95)\n\n\nBayesiano (brm()):\nfm_b &lt;- brm(y ~ x, data = data.frame(x, y),\n            prior = c(set_prior(\"normal(0,5)\", class=\"Intercept\"),\n                      set_prior(\"normal(0,5)\", class=\"b\"),\n                      set_prior(\"cauchy(0,1)\", class=\"sigma\")),\n            iter = 2000, chains = 2)\nsummary(fm_b)\nConfronto: i valori medi a posteriori e gli intervalli di credibilità dovrebbero includere quelli di confidenza di lm().\n\n\n\n\nDiagnosi MCMC\n\n\nTrace plots: verificare mescolamento e stazionarietà delle catene;\n\n\nR-hat: valore vicino a 1 indica convergenza;\n\n\nEffective Sample Size (ESS): numero di campioni indipendenti effettivi.\n\n\nInterpretazione dei coefficienti\nLa regressione osservazionale non controlla automaticamente i potenziali confondenti; senza randomizzazione o disegno sperimentale rigoroso, non si può inferire causalità. Bisogna considerare variabili confondenti e criteri di validità interna.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.11.0            cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        plyr_1.8.9           \n#&gt; [46] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [55] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [58] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [61] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [64] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [67] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [70] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [73] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [76] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [79] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [82] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#bibliografia",
    "href": "chapters/linear_models/03_reglin_bayes.html#bibliografia",
    "title": "59  Modello bayesiano di regressione lineare bivariata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html",
    "title": "60  Zucchero sintattico",
    "section": "",
    "text": "Introduzione\nI modelli lineari sono così ampiamente utilizzati che sono stati sviluppati appositamente una sintassi, dei metodi e delle librerie per la regressione. Una di queste librerie è brms (Bayesian Regression Models using Stan), già introdotta nel Capitolo 59. brms è un pacchetto R progettato per adattare modelli gerarchici generalizzati lineari (di cui il modello lineare bivariato è un caso particolare), utilizzando una sintassi simile a quella presente nei pacchetti R, come lm, lme4, rstanarm, brms si basa su Stan, ma offre un’API di livello superiore.\nIn questo capitolo esploreremo in maniera dettagliata come condurre un’analisi di regressione utilizzando brms invece di Stan.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#introduzione",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#introduzione",
    "title": "60  Zucchero sintattico",
    "section": "",
    "text": "Panoramica del capitolo\n\nCostruire e adattare modelli lineari con la funzione brm().\nInterpretare i risultati e confrontarli con quelli ottenuti da un approccio frequentista.\nVisualizzare le relazioni stimate e distinguere tra intervalli di credibilità e di predizione.\nSpecificare priors personalizzati e valutare l’impatto sui risultati.\nEseguire verifiche predittive a posteriori (posterior predictive checks).\nGestire la presenza di outlier tramite la regressione robusta.\nCalcolare e interpretare l’indice di determinazione bayesiano (Bayes R²).\nAccedere e manipolare la distribuzione a posteriori dei parametri.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code (Alter et al., 2025).\nConsultare The brms Book: Applied Bayesian Regression Modelling Using R and Stan.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, posterior, cmdstanr, tidybayes)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#interfaccia-brms",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#interfaccia-brms",
    "title": "60  Zucchero sintattico",
    "section": "\n60.1 Interfaccia brms\n",
    "text": "60.1 Interfaccia brms\n\nCome esempio, utilizzeremo un dataset che ci consente di stimare un modello lineare molto semplice. Il National Snow and Ice Data Center mette a disposizione numerosi dati pubblici, scaricabili ed esplorabili liberamente. Uno degli effetti più evidenti del cambiamento climatico riguarda la progressiva riduzione dell’estensione dei ghiacci marini nell’emisfero settentrionale. Qui analizzeremo come questa estensione è variata nel tempo.\nLa progressiva scomparsa di un elemento così iconico del nostro pianeta non è solo un dato fisico; agisce come un potente segnale psicologico. La percezione di perdite ambientali tangibili e su larga scala è un fattore chiave nel fenomeno dell’ansia climatica (climate anxiety), quella preoccupazione cronica e angoscia per gli impatti presenti e futuri del cambiamento climatico (Clayton, 2020).\nVisualizzare un trend discendente così chiaro, come quello che emergerà dalla nostra analisi, fornisce un contesto cruciale. Non si tratta di un’astratta previsione futura, ma della documentazione di una trasformazione in atto che sta già alterando ecosistemi, economie e, non da ultimo, il nostro benessere psicologico collettivo (APA, 2017). L’analisi dei dati diventa così uno strumento per comprendere e comunicare una delle fonti dello stress ambientale contemporaneo.\nI dati contenuti nel file N_08_extent_v4.0.csv riguardano le osservazioni del mese di agosto dal 1979 al 2024 e riportano i valori di extent. Con questo termine si indica la superficie marina totale in cui la concentrazione di ghiaccio è almeno del 15%. L’extent è considerato l’indicatore più robusto per monitorare le tendenze climatiche di lungo periodo, poiché risente meno delle fluttuazioni giornaliere dovute al vento (che può comprimere o disperdere il ghiaccio, modificandone la concentrazione ma non la sua estensione complessiva). Per questo motivo, quando si parla di “minimo storico dei ghiacci artici”, il riferimento è quasi sempre al valore di extent. La variabile extent è espressa in milioni di chilometri quadrati (ad esempio, 8.04 = 8.040.000 km²).\nCarichiamo i dati e diamo un’occhiata alle prime righe:\n\ndf &lt;- rio::import(here::here(\"data\", \"N_08_extent_v4.0.csv\"))\ndf |&gt; \n  head()\n#&gt;   year mo source_dataset region extent area\n#&gt; 1 1979  8     NSIDC-0051      N   8.04 5.06\n#&gt; 2 1980  8     NSIDC-0051      N   7.98 4.94\n#&gt; 3 1981  8     NSIDC-0051      N   7.84 4.48\n#&gt; 4 1982  8     NSIDC-0051      N   8.14 5.00\n#&gt; 5 1983  8     NSIDC-0051      N   8.19 4.97\n#&gt; 6 1984  8     NSIDC-0051      N   7.77 4.68\n\nVisualizziamo ora la relazione tra extent e year con un diagramma a dispersione:\n\nggplot(df, aes(x = year, y = extent)) +\n  geom_point() +  \n  labs(x = \"Anno\", y = \"Estensione (milioni km²)\") \n\n\n\n\n\n\n\nIl pacchetto brms si concentra sui modelli di regressione. Questa specializzazione consente di adottare una sintassi semplice e compatta, detta sintassi di Wilkinson (Wilkinson & Rogers, 1973).\nPer esempio, il modello lineare\n\\[\ny = \\alpha + \\beta x + \\varepsilon\n\\] può essere scritto in brms nel modo seguente:\na_model &lt;- brm(extent ∼ 1 + year, data = df)\nNella sintassi di Wilkinson:\n\nil simbolo ~ separa la variabile dipendente (a sinistra) dalle variabili indipendenti (a destra);\n\n1 rappresenta l’intercetta, che in realtà è inclusa di default.\n\nQuindi il modello precedente può essere scritto in maniera equivalente come:\na_model &lt;- brm(extent ∼ year, data = df)\nSe desideriamo escludere l’intercetta dal modello, possiamo farlo così:\nno_intercept_model &lt;- brm(extent ∼ 0 + year, data = df)\noppure:\nno_intercept_model &lt;- brm(extent ∼ -1 + year, data = df)\nPer aggiungere altre variabili indipendenti, basta estendere la formula:\nmodel_2 &lt;- brm(extent ∼ year + z, data = df)\nbrms permette anche di stimare modelli gerarchici (a effetti misti). Ad esempio, se avessimo osservazioni raggruppate per area geografica g e volessimo stimare un effetto di year che varia da un gruppo all’altro, potremmo scrivere:\nmodel_h &lt;- brm(extent ∼ year + z + (year | g), data = df)\nÈ importante sottolineare che la sintassi di Wilkinson non specifica le distribuzioni a priori, ma soltanto come le variabili sono collegate tra loro. In assenza di istruzioni esplicite, brms assegna automaticamente delle prior debolmente informative, che permettono di stimare comunque il modello senza ulteriori interventi. Tuttavia, se desideriamo avere un controllo più preciso, possiamo definire manualmente le prior, come vedremo nelle sezioni successive.\n\n60.1.1 Centrare le variabili\nPer interpretare più facilmente l’intercetta, centriamo la variabile year rispetto alla sua media nel campione:\n\ndf$year_c &lt;- df$year - mean(df$year)\n\nIn questo modo, l’intercetta (\\(\\alpha\\)) del modello rappresenterà l’estensione media prevista (extent, in milioni di km²) nell’anno medio del campione (cioè l’anno medio tra 1979 e 2024).\nAdattiamo un modello lineare con year centrata ed esaminiamo i risultati:\n\nfit_1 &lt;- brm(\n  bf(extent ~ 1 + year_c, center = FALSE),\n  data = df,\n  backend = \"cmdstanr\",\n  silent = 0\n)\n\n\n\ncenter = FALSE nel bf(…) assicura che brms non applichi un centraggio automatico ai predittori numerici: così evitiamo il “doppio centraggio”, dato che abbiamo già centrato year a mano.\n\nbackend = \"cmdstanr\" indica a brms di usare CmdStan tramite l’interfaccia cmdstanr (anziché l’interfaccia rstan). In questo corso useremo cmdstanr, quindi è utile specificarlo esplicitamente.\n\nsilent = 0 lascia visibili alcuni messaggi informativi durante la compilazione e il campionamento (opzionale).\n\nLe tracce MCMC dei parametri si ottengono così:\n\nmcmc_trace(\n  fit_1,\n  pars = c(\"b_Intercept\", \"b_year_c\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nRiepilogo del modello:\n\nsummary(fit_1)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: extent ~ 1 + year_c \n#&gt;    Data: df (Number of observations: 46) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     6.71      0.07     6.58     6.84 1.00     3088     2578\n#&gt; year_c       -0.07      0.00    -0.08    -0.06 1.00     3518     2584\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     0.46      0.05     0.37     0.57 1.00     2767     2533\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n60.1.1.1 Interpretazione\n\nL’intercetta \\(\\alpha\\) = b_Intercept è l’extent previsto (milioni di km²) nell’anno medio del campione (circa \\(\\text{mean(df\\$year)}\\)).\nLa pendenza \\(\\beta\\) = b_year_c quantifica la variazione media annua dell’extent: un valore negativo indica una diminuzione dell’estensione dei ghiacci nel tempo (trend atteso in questi dati).\n\nPer confronto, stimiamo lo stesso modello con l’approccio frequentista:\n\nfit_2 &lt;- lm(extent ~ 1 + year_c, data = df)\nsummary(fit_2)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = extent ~ 1 + year_c, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.2394 -0.2755  0.0204  0.3081  1.0768 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  6.71000    0.06537   102.6   &lt;2e-16\n#&gt; year_c      -0.07148    0.00492   -14.5   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 0.443 on 44 degrees of freedom\n#&gt; Multiple R-squared:  0.827,  Adjusted R-squared:  0.823 \n#&gt; F-statistic:  211 on 1 and 44 DF,  p-value: &lt;2e-16\n\nCon prior debolmente informativi, i risultati bayesiani e frequentisti tendono a essere molto simili (stesse quantità stimate, ma nel caso bayesiano abbiamo l’intera distribuzione a posteriori dei parametri, utile per inferenze e previsione).\n\n60.1.2 Visualizzazione dei risultati\nPer comprendere visivamente la relazione stimata tra anno ed estensione dei ghiacci artici nel nostro modello bayesiano, possiamo utilizzare la funzione conditional_effects:\n\nconditional_effects(fit_1, effects = \"year_c\")\n\n\n\n\n\n\n\nIl grafico generato fornisce una rappresentazione intuitiva della stima:\n\n\nLinea centrale (media posteriore): rappresenta il valore medio previsto di extent per ciascun valore di year_c.\n\nArea colorata (intervallo di credibilità): mostra l’intervallo di credibilità al 95% (Highest Density Interval, HDI), cioè l’intervallo in cui cade il 95% della distribuzione a posteriori delle previsioni.\n\nPossiamo modificare il livello di incertezza visualizzato regolando l’argomento prob:\n\n# Visualizzazione con intervallo di credibilità all'89%\nconditional_effects(fit_1, effects = \"year_c\", prob = 0.89)\n\n\n\n\n\n\n\n\nRiducendo prob (ad esempio a 0.80 o 0.50) otteniamo intervalli più stretti, che mostrano solo la parte più densa della distribuzione posteriore.\nAumentando prob (ad esempio a 0.99) otteniamo intervalli più ampi, che riflettono una maggiore incertezza.\n\n\n60.1.2.1 Interpretazione pratica del grafico\nNel grafico:\n\nil punto in cui la linea attraversa year_c = 0 corrisponde all’estensione prevista dei ghiacci nell’anno medio del campione (circa il 2001, dato che abbiamo centrato la variabile year);\nla pendenza della linea indica la variazione media di estensione dei ghiacci (in milioni di km²) per ogni anno in più: un valore negativo segnala una riduzione progressiva;\nla larghezza dell’intervallo di credibilità riflette il grado di incertezza delle stime: intervalli più stretti indicano maggiore precisione, intervalli più larghi indicano più incertezza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#due-tipi-di-incertezza-nei-modelli-bayesiani",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#due-tipi-di-incertezza-nei-modelli-bayesiani",
    "title": "60  Zucchero sintattico",
    "section": "\n60.2 Due tipi di incertezza nei modelli bayesiani",
    "text": "60.2 Due tipi di incertezza nei modelli bayesiani\nImmaginiamo di voler capire come l’anno (X) sia collegato all’estensione dei ghiacci artici (Y). Con un modello bayesiano otteniamo due tipi distinti di incertezza, che corrispondono a due domande diverse:\n\n\n\n\n\n\n\nChe cosa stiamo stimando?\nCome si chiama l’incertezza?\nChe intervallo disegniamo?\n\n\n\n\nLa media “vera” dell’estensione dei ghiacci per un dato anno\n\nIncertezza del parametro (o dell’effetto medio)\n\nIntervallo di credibilità (credible interval)\n\n\n\nIl valore futuro di una nuova osservazione (quale sarà l’estensione dei ghiacci in un singolo anno come quello)\nIncertezza predittiva\n\nIntervallo di predizione (prediction interval)\n\n\n\n\n60.2.1 Incertezza del parametro – «Quanto stiamo sbagliando la linea media?»\n\nconditional_effects(fit_1, effects = \"year_c\")\n\n\n\n\n\n\n\n\nDisegna la linea di regressione (la media stimata dell’estensione per ogni anno centrato).\nAggiunge intorno una fascia stretta: l’intervallo di credibilità al 95%.\nCome leggerla: Se la fascia, per l’anno medio del campione, va ad esempio da 7.5 a 7.7 milioni di km², significa che “con il 95% di probabilità la vera media dell’estensione in quell’anno sta lì dentro”. Non dice nulla sulle singole osservazioni, che possono discostarsi anche molto dalla media.\n\nMetafora veloce. Pensa a tirare freccette: la media cade vicino al centro, ma ogni singola freccia può atterrare in punti diversi. L’intervallo di credibilità descrive solo dove cade il centro.\n\n60.2.2 Incertezza predittiva – «Quanto potrebbe variare la prossima osservazione?»\n\nconditional_effects(fit_1, effects = \"year_c\", method = \"predict\")\n\n\n\n\n\n\n\n\nRipropone la stessa linea media.\nDisegna però una fascia molto più larga: l’intervallo di predizione.\n\nL’intervallo predittivo include due fonti di variabilità:\n\n\nIncertezza sulla linea media (come sopra).\n\nVariabilità residua: le differenze naturali tra osservazioni nello stesso anno (fluttuazioni dovute a vento, condizioni meteorologiche, ecc.).\n\nMetafora veloce. Ora guardi non solo il centro del bersaglio, ma l’intero disco dove ogni freccia potrebbe cadere. L’area è molto più grande.\n\n60.2.3 Quando usare l’una o l’altra fascia?\n\n\n\n\n\n\n\nObiettivo della tua domanda\nFunzione da usare\nQuale fascia guardare\n\n\n\nCapire l’effetto medio (es. “quanto si riduce in media l’estensione ogni anno?”)\nconditional_effects(...)\nIntervallo di credibilità\n\n\nFare previsioni su un caso futuro (es. “quale sarà l’estensione osservata nell’agosto 2025?”)\nconditional_effects(..., method = \"predict\")\nIntervallo di predizione\n\n\n\n\n60.2.3.1 In sintesi\n\n\nCredibilità = incertezza sul parametro medio → fascia stretta (stima della retta).\n\nPredizione = incertezza su osservazioni future → fascia larga (linea + variabilità residua).\nLa scelta dipende dalla domanda: “qual è la media?” (credibilità) oppure “dove cadrà il prossimo dato?” (predizione).\n\nIn breve, la visualizzazione predittiva è più onesta quando vogliamo fare previsioni concrete su nuove osservazioni, mentre quella con l’intervallo di credibilità è più utile per capire la relazione generale tra anno ed estensione dei ghiacci.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#distribuzione-a-posteriori-dei-parametri",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#distribuzione-a-posteriori-dei-parametri",
    "title": "60  Zucchero sintattico",
    "section": "\n60.3 Distribuzione a posteriori dei parametri",
    "text": "60.3 Distribuzione a posteriori dei parametri\nPer esaminare la distribuzione a posteriori dei parametri del modello, possiamo utilizzare la funzione mcmc_plot():\n\nmcmc_plot(fit_1, type = \"dens\")\n\n\n\n\n\n\n\nQuesta funzione disegna la densità a posteriori dei parametri, mostrando graficamente quali valori sono più plausibili dato il modello, i dati e le scelte a priori.\nPer un’analisi numerica più dettagliata, trasformiamo l’oggetto fit_1 in un formato compatibile con il pacchetto posterior e poi calcoliamo le statistiche di sintesi:\n\ndraws &lt;- posterior::as_draws(fit_1, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable      mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  6.709 0.067     0.001   0.001\n#&gt; 2 b_year_c    -0.071 0.005     0.000   0.000\n\n\nLa funzione as_draws() converte l’oggetto in una struttura che rappresenta i campioni MCMC.\nGli argomenti variable = \"^b_\" e regex = TRUE selezionano solo i parametri che iniziano con b_, cioè i coefficienti del modello: l’intercetta e la pendenza.\nLa funzione summarise_draws() calcola statistiche riassuntive per la distribuzione a posteriori di questi parametri.\n\n\n60.3.1 Spiegazione di mcse_mean e mcse_sd\n\nOltre a media (mean) e deviazione standard (sd), summarise_draws() riporta anche due indici utili:\n\n\nmcse_mean = Monte Carlo Standard Error della media.\n\nIndica quanto la stima della media potrebbe variare semplicemente perché abbiamo un numero finito di campioni MCMC.\nSe è molto piccolo rispetto a sd, possiamo fidarci che la media stimata rappresenta bene la distribuzione a posteriori.\n\n\n\nmcse_sd = Monte Carlo Standard Error della deviazione standard.\n\nIndica quanto la stima della deviazione standard della distribuzione a posteriori potrebbe variare per lo stesso motivo.\nAnche qui, un valore molto piccolo rispetto alla sd è segno che il campionamento è stato sufficiente.\n\n\n\n60.3.2 Come interpretarli in pratica?\n\n\nRapporto rispetto a sd\n\n\nmcse_mean e mcse_sd dovrebbero essere almeno un ordine di grandezza più piccoli delle corrispondenti stime (mean e sd).\nAd esempio: se per b_Intercept abbiamo mcse_mean = 0.0044 e sd = 0.2695, il valore è più di 60 volte più piccolo → la stima è robusta.\n\n\n\nQualità del campionamento\n\n\nSe mcse_mean o mcse_sd fossero troppo grandi, questo indicherebbe che:\n\nil numero di iterazioni MCMC è insufficiente,\nle catene non hanno mescolato bene,\no ci sono problemi di convergenza.\n\n\n\n\n\n\n60.3.2.1 In sintesi\n\n\nmcse_mean e mcse_sd non descrivono l’incertezza statistica sui dati, ma la qualità del campionamento Monte Carlo.\nSe sono piccoli, significa che il numero di campioni è sufficiente e la distribuzione a posteriori è rappresentata in modo accurato.\nIn altre parole: ci dicono se possiamo fidarci che la “fotografia” ottenuta con l’MCMC rispecchi bene la vera distribuzione a posteriori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#specificare-i-priors",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#specificare-i-priors",
    "title": "60  Zucchero sintattico",
    "section": "\n60.4 Specificare i priors",
    "text": "60.4 Specificare i priors\nNei modelli bayesiani i priors rappresentano le nostre aspettative sui parametri prima di osservare i dati. Se non li specifichiamo, brms assegna dei prior debolmente informativi di default.\nPossiamo ispezionarli con la funzione get_prior:\n\nget_prior(extent ~ 1 + year_c, data = df)\n#&gt;                   prior     class   coef group resp dpar nlpar lb ub\n#&gt;  student_t(3, 6.8, 2.5) Intercept                                   \n#&gt;                  (flat)         b                                   \n#&gt;                  (flat)         b year_c                            \n#&gt;    student_t(3, 0, 2.5)     sigma                               0   \n#&gt;        source\n#&gt;       default\n#&gt;       default\n#&gt;  (vectorized)\n#&gt;       default\n\nL’output mostra quali prior vengono assegnati a ciascun parametro del modello. Per esempio:\n\n\nprior – indica il prior utilizzato.\n\n\nstudent_t(3, 6.8, 2.5): prior t di Student per l’intercetta, con 3 gradi di libertà, media 6.8 e scala 2.5.\n\n(flat): prior piatto (non informativo) per i coefficienti delle variabili predittive, come il coefficiente di year_c.\n\nstudent_t(3, 0, 2.5): prior t di Student per la deviazione standard residua (\\(\\sigma\\)), centrato su 0 con scala 2.5.\n\n\n\nclass – indica a quale tipo di parametro il prior si riferisce:\n\n\nIntercept: prior sull’intercetta (\\(\\alpha\\));\n\nb: prior sui coefficienti dei predittori (\\(\\beta\\));\n\nsigma: prior sulla deviazione standard residua (\\(\\sigma\\)).\n\n\n\ncoef – specifica a quale predittore si riferisce il prior.\n\nVuoto per l’intercetta (perché non dipende da un predittore specifico).\n\nyear_c per il coefficiente associato al predittore year_c.\n\n\n\nlb e ub – rappresentano i limiti inferiore (lower bound) e superiore (upper bound) del prior, se esistono.\n\nPer sigma, il limite inferiore è 0, poiché una deviazione standard non può essere negativa.\n\n\nsource – indica se il prior è stato impostato dall’utente o se è il valore predefinito (default).\n\n\n60.4.1 Specificare priors manualmente\nSe vogliamo rendere esplicite le nostre ipotesi, possiamo definire dei priors diversi da quelli di default. Ad esempio:\n\nprior_gaussian &lt;- \n  brms::prior(normal(7, 2), class = \"b\", coef = \"Intercept\") +    # Intercetta attorno a 7 (milioni km²)\n  brms::prior(normal(0, 0.5), class = \"b\", coef = \"year_c\") +  # Coefficiente di year_c\n  brms::prior(cauchy(0, 2), class = \"sigma\")          # Deviazione standard residua\n\n\nNota: usiamo brms::prior() per essere sicuri di richiamare la funzione del pacchetto brms ed evitare conflitti con funzioni omonime di altri pacchetti.\n\nAdattiamo ora il modello con i priors specificati:\n\nfit_2 &lt;- brm(\n  bf(extent ~ 1 + year_c, center = FALSE), \n  prior = prior_gaussian,\n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nE otteniamo un sommario numerico delle distribuzioni a posteriori:\n\ndraws &lt;- posterior::as_draws(fit_2, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable      mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  6.709 0.066     0.001   0.001\n#&gt; 2 b_year_c    -0.071 0.005     0.000   0.000\n\n\n60.4.2 Confronto con i priors di default\nNel nostro caso, i priors esplicitamente definiti non cambiano in modo rilevante le distribuzioni a posteriori. Questo accade perché i dati disponibili sono numerosi e forniscono già informazioni molto forti: in pratica, le osservazioni “dominano” sulle ipotesi iniziali.\nDal punto di vista didattico è un aspetto cruciale da sottolineare:\n\n\nCon molti dati e alta informatività, i priors hanno un ruolo marginale: le stime finali saranno simili indipendentemente dalle ipotesi iniziali.\n\nCon pochi dati o dati molto rumorosi, invece, i priors diventano determinanti: le scelte iniziali possono influenzare in maniera sostanziale i risultati finali.\n\nIn altre parole, la forza relativa tra dati e priors dipende dalla quantità e dalla qualità dell’informazione empirica disponibile.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#predizioni-a-posteriori-posterior-predictive-checks",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#predizioni-a-posteriori-posterior-predictive-checks",
    "title": "60  Zucchero sintattico",
    "section": "\n60.5 Predizioni a posteriori (Posterior Predictive Checks)",
    "text": "60.5 Predizioni a posteriori (Posterior Predictive Checks)\nUn aspetto fondamentale nella valutazione di un modello statistico, sia frequentista che bayesiano, è verificare quanto bene le predizioni del modello rappresentino i dati osservati. La logica di fondo è simile nei due paradigmi, ma l’approccio e l’interpretazione sono diversi.\n\n60.5.1 Confronto frequentista\nNel caso frequentista, il confronto si basa sui valori stimati dal modello:\n\\[\n\\hat{y} = \\hat{\\alpha} + \\hat{\\beta}x\n\\]\nSi analizzano principalmente:\n\nla vicinanza della retta di regressione ai dati osservati;\nla presenza di eventuali pattern non lineari nei residui;\nla variazione della dispersione di \\(y\\) rispetto a \\(x\\) (per verificare l’ipotesi di omoschedasticità).\n\n60.5.2 Approccio bayesiano\nNell’approccio bayesiano eseguiamo le stesse verifiche di base, ma disponiamo di uno strumento in più: le Predizioni a Posteriori (Posterior Predictive Checks, PPCs).\nL’idea è semplice ma potente:\n\ninvece di confrontare i dati osservati solo con una linea di regressione “fissa”,\nli confrontiamo con dati simulati dal modello, generati utilizzando i campioni dalle distribuzioni a posteriori dei parametri.\n\nIn questo modo, nelle predizioni è incorporata anche l’incertezza sui parametri stimata dal modello.\n\n60.5.3 Come si costruiscono le predizioni a posteriori\nNel caso di un modello lineare semplice, il procedimento è:\n\nDati osservati: partiamo dalla distribuzione empirica della variabile risposta (\\(y\\)).\nEstrazione dei parametri: prendiamo un campione casuale \\(\\alpha'\\), \\(\\beta'\\), \\(\\sigma'\\) dalle distribuzioni a posteriori dei parametri.\n\nSimulazione dei dati: generiamo valori simulati da una normale:\n\\[\ny_{\\text{sim}} \\sim \\mathcal{N}(\\alpha' + \\beta' x, \\sigma')\n\\]\ndove \\(x\\) sono i predittori osservati.\n\nRipetizione: il processo viene ripetuto molte volte, producendo numerosi dataset simulati.\nConfronto: i dati simulati vengono confrontati con i dati reali (istogrammi, densità o residui).\n\n60.5.4 Interpretazione\n\n\nBuona corrispondenza: se la distribuzione dei dati simulati si sovrappone bene a quella osservata, il modello rappresenta adeguatamente i dati.\n\nDiscrepanze: differenze sistematiche (picchi mancanti, code sottostimate, ecc.) indicano che il modello non cattura tutti gli aspetti dei dati.\n\nIl vantaggio dei PPC è che:\n\nintegrano l’incertezza sui parametri;\npermettono di valutare non solo la bontà di adattamento media, ma anche dettagli della distribuzione;\nsono molto intuitivi e visivi, facilitando la diagnosi di problemi.\n\n\n60.5.4.1 Esempi con R\nVerifichiamo le predizioni del modello confrontandole con i dati osservati:\n\npp_check(fit_2)\n\n\n\n\n\n\n\nIn questo caso, il grafico mostra una buona corrispondenza tra i dati simulati e quelli reali.\nPossiamo poi analizzare i residui bayesiani con un grafico più specifico:\n\npp_check(fit_1, type = \"error_scatter_avg\")\n\n\n\n\n\n\n\nQuesto grafico rappresenta i residui (differenze tra osservato e predetto) rispetto ai valori predetti:\n\nse i residui appaiono distribuiti in modo uniforme, il modello descrive correttamente la relazione;\nse emergono pattern sistematici (ad esempio curvature o variazioni di dispersione), il modello potrebbe essere inadeguato.\n\n60.5.5 Commento sui residui\nNel grafico dei residui (\\(y\\) in funzione di \\(y - y_{\\text{rep}}\\)) si osserva un trend crescente: i residui non sono distribuiti in modo uniforme, ma mostrano una struttura sistematica. Questo pattern indica che il modello lineare bivariato non cattura pienamente le proprietà dei dati. In particolare, trattandosi di una serie temporale, è probabile che vi siano dipendenze tra osservazioni successive nel tempo: l’estensione dei ghiacci in un anno dipende anche dai valori degli anni immediatamente precedenti. Il modello lineare semplice, invece, assume che gli errori siano indipendenti e identicamente distribuiti, e non è quindi in grado di rappresentare questa dinamica temporale.\nQuesto esempio è didatticamente importante perché mostra che:\n\nanche un modello molto semplice può aiutare a evidenziare strutture nascoste nei dati (qui la dipendenza temporale);\ntuttavia, se compaiono incongruenze nei residui, significa che il modello non è adeguato e va migliorato o reso più complesso (ad esempio con modelli di regressione per serie temporali o modelli gerarchici dinamici).\n\nLa verifica dei residui è dunque un passaggio cruciale: non solo permette di valutare l’adattamento del modello, ma può suggerire nuove direzioni di modellizzazione per rappresentare meglio la complessità del fenomeno.\n\n60.5.5.1 In sintesi\nLe Predizioni a Posteriori forniscono un modo robusto per valutare l’adeguatezza di un modello bayesiano:\n\nse i dati simulati somigliano ai dati reali, il modello è plausibile per il campione analizzato;\nin caso contrario, è opportuno rivedere la struttura del modello (es. includendo effetti non lineari, variabili aggiuntive o priors più adeguati).\n\nIl PPC è una “prova del nove” del modello, che traduce la teoria in un confronto diretto e visivo con i dati osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#regressione-robusta",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#regressione-robusta",
    "title": "60  Zucchero sintattico",
    "section": "\n60.6 Regressione robusta",
    "text": "60.6 Regressione robusta\nIn questa sezione introduciamo la regressione robusta. L’obiettivo è mostrare quanto sia semplice modificare, in brm(), la distribuzione degli errori per rendere il modello meno sensibile agli outlier.\nQuesta flessibilità è un punto di forza dell’approccio bayesiano: nei modelli frequentisti standard, la distribuzione degli errori è quasi sempre fissata a priori (ad esempio normale/gaussiana) e non può essere facilmente modificata.\n\n60.6.1 Perché servono modelli robusti?\nGli outlier — valori molto distanti dal resto delle osservazioni — possono influenzare in modo marcato le stime di regressione. Ad esempio, aggiungiamo artificialmente un outlier nel dataset:\n\ndf_outlier &lt;- df\ndf_outlier$extent[1] &lt;- 20     # valore anomalo molto alto\ndf_outlier$year_c[1] &lt;- -25    # anno centrato \"estremo\"\n\nVisualizziamo i dati:\n\ndf_outlier |&gt; \n  ggplot(aes(x = year_c, y = extent)) +\n    geom_point() +  \n    labs(x = \"Anno centrato\", y = \"Estensione (milioni km²)\") \n\n\n\n\n\n\n\n\n60.6.2 Effetto dell’outlier su un modello gaussiano\nStimiamo un modello lineare gaussiano:\n\nfit_3 &lt;- brm(\n  bf(extent ~ 1 + year_c, center = FALSE), \n  prior = prior_gaussian,\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nEsaminiamo i parametri stimati:\n\ndraws &lt;- posterior::as_draws(fit_3, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable      mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  6.963 0.255     0.004   0.004\n#&gt; 2 b_year_c    -0.106 0.019     0.000   0.000\n\nRispetto al modello stimato senza outlier (dove la pendenza \\(\\beta\\) era intorno a –0.07), qui la stima è fortemente distorta. Un singolo punto anomalo può dunque trascinare la retta di regressione.\n\n60.6.3 Un modello robusto con distribuzione t\n\nPer ridurre la sensibilità agli outlier, possiamo sostituire la distribuzione gaussiana degli errori con una distribuzione t di Student, che ha code più pesanti:\n\nfit_4 &lt;- brm(\n  bf(extent ~ 1 + year_c, center = FALSE), \n  prior = prior_gaussian,\n  family = student(),   # distribuzione t di Student\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nI risultati mostrano che il modello t è meno influenzato dall’outlier rispetto al modello gaussiano:\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable      mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  6.740 0.069     0.001   0.001\n#&gt; 2 b_year_c    -0.072 0.005     0.000   0.000\n\n\n60.6.4 Il parametro \\(\\nu\\): quanto sono pesanti le code?\nIl modello con distribuzione t stima anche il parametro \\(\\nu\\), che controlla la pesantezza delle code:\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"nu\")\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 1 × 5\n#&gt;   variable  mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 nu       2.516 0.848     0.015   0.015\n\n\nCon valori alti di \\(\\nu\\) (es. &gt; 30), la distribuzione t si avvicina a una normale.\nCon valori bassi (es. \\(\\nu \\approx 4\\)), le code sono molto più pesanti: la distribuzione “accetta” più facilmente valori estremi, senza permettere che influenzino eccessivamente le stime.\n\nNel nostro caso, \\(\\nu \\approx 4\\) indica una distribuzione ben più robusta della normale, e il modello riesce a ignorare in buona parte l’effetto dell’outlier.\n\n60.6.5 In sintesi\nLa regressione robusta con distribuzione t è uno strumento essenziale quando sospettiamo che i dati possano contenere valori anomali. A differenza del modello gaussiano, non lascia che pochi outlier distorcano in modo significativo le stime dei parametri.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#indice-di-determinazione-bayesiano",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#indice-di-determinazione-bayesiano",
    "title": "60  Zucchero sintattico",
    "section": "\n60.7 Indice di determinazione bayesiano",
    "text": "60.7 Indice di determinazione bayesiano\nCon il pacchetto brms possiamo calcolare il Bayes \\(R^2\\), l’equivalente bayesiano del classico indice di determinazione \\(R^2\\). Questo indice misura la proporzione di varianza spiegata dal modello, ma a differenza dell’approccio frequentista, tiene conto dell’incertezza associata alle stime dei parametri.\nIl comando per calcolarlo è:\n\nbayes_R2(fit_2)\n#&gt;    Estimate Est.Error  Q2.5 Q97.5\n#&gt; R2    0.822    0.0233 0.762 0.851\n\n\n60.7.1 Interpretazione dell’output\nIl risultato è un tibble (una tabella ordinata) che riporta:\n\n\nEstimate: la media della distribuzione a posteriori del Bayes \\(R^2\\), cioè la proporzione di varianza spiegata dal modello;\n\nEst.Error: l’errore standard associato alla stima;\n\nQ2.5 e Q97.5: i limiti inferiore e superiore dell’intervallo di credibilità al 95% per il Bayes \\(R^2\\).\n\nEsempio (con valori ipotetici coerenti col nostro modello):\n\n\nStima media: il modello spiega circa il 57% della varianza osservata;\n\nErrore standard: l’incertezza sulla stima è bassa (± 0.02);\n\nIntervallo di credibilità: con il 95% di probabilità, il vero valore del Bayes \\(R^2\\) si trova tra 0.52 e 0.61.\n\n60.7.2 Differenze rispetto al \\(R^2\\) frequentista\n\n\nIncertezza esplicita\n\nIl Bayes \\(R^2\\) non è una stima puntuale, ma una distribuzione a posteriori: possiamo quindi rappresentare l’incertezza con intervalli di credibilità.\nNel caso frequentista, invece, il \\(R^2\\) è un singolo numero senza misura diretta di incertezza.\n\n\n\nInfluenza dei priors\n\nNel Bayes \\(R^2\\), i priors scelti per i parametri influiscono sulla stima finale.\nQuesto consente di incorporare conoscenze precedenti e rende la misura più flessibile e adattabile al contesto di ricerca.\n\n\n\n60.7.3 Distribuzione a posteriori del Bayes \\(R^2\\)\n\nPossiamo anche visualizzare la distribuzione completa dei valori simulati di \\(R^2\\):\n\nr2_draws &lt;- bayes_R2(fit_2, summary = FALSE)\nr2_df &lt;- data.frame(R2 = as.numeric(r2_draws))\n\nggplot(r2_df, aes(x = R2)) +\n  geom_density() +\n  geom_rug(alpha = 0.4) +\n  labs(\n    x = expression(R^2),\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\nCalcoliamo anche i quantili:\n\nround(quantile(r2_df$R2, probs = c(.025, .5, .975)), 3)\n#&gt;  2.5%   50% 97.5% \n#&gt; 0.762 0.827 0.851\n\nIn alternativa, con bayesplot possiamo ottenere una visualizzazione immediata e compatta:\n\nmcmc_areas(r2_draws, prob = 0.95) \n\n\n\n\n\n\n\n\n60.7.3.1 In sintesi\nIl Bayes \\(R^2\\) è uno strumento potente perché combina l’intuitività del \\(R^2\\) classico con la ricchezza informativa dell’approccio bayesiano, permettendo di valutare non solo quanta varianza il modello spiega, ma anche quanto siamo sicuri di questa stima.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#approfondimento-manipolare-la-distribuzione-a-posteriori-con-brms",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#approfondimento-manipolare-la-distribuzione-a-posteriori-con-brms",
    "title": "60  Zucchero sintattico",
    "section": "\n60.8 Approfondimento: manipolare la distribuzione a posteriori con brms\n",
    "text": "60.8 Approfondimento: manipolare la distribuzione a posteriori con brms\n\nVediamo ora come accedere e manipolare i campioni della distribuzione a posteriori generati da un modello stimato con brms.\nSupponiamo di aver costruito un modello lineare semplice, in cui vogliamo predire l’estensione dei ghiacci (extent) a partire dall’anno centrato (year_c):\nfit_2 &lt;- brm(\n  bf(extent ~ 1 + year_c, center = FALSE), \n  prior = prior_gaussian,\n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\n60.8.1 Estrarre i campioni\nUna volta stimato il modello, possiamo ottenere i campioni MCMC della distribuzione a posteriori con as_draws():\n\nposterior_2 &lt;- as_draws(fit_2)\n\nL’oggetto posterior_2 è di tipo draws, definito dal pacchetto posterior. Al suo interno troviamo i campioni prodotti dall’algoritmo MCMC, organizzati come un array o una lista:\n\nstr(posterior_2)\n#&gt; List of 4\n#&gt;  $ 1:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 6.68 6.71 6.67 6.69 6.72 ...\n#&gt;   ..$ b_year_c   : num [1:1000] -0.0797 -0.0649 -0.0757 -0.0724 -0.0774 ...\n#&gt;   ..$ sigma      : num [1:1000] 0.429 0.493 0.427 0.392 0.443 ...\n#&gt;   ..$ lprior     : num [1:1000] -3.05 -3.06 -3.05 -3.04 -3.05 ...\n#&gt;   ..$ lp__       : num [1:1000] -32.3 -32 -31.4 -31.4 -31.4 ...\n#&gt;  $ 2:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 6.7 6.74 6.7 6.74 6.82 ...\n#&gt;   ..$ b_year_c   : num [1:1000] -0.0658 -0.07 -0.0749 -0.066 -0.0661 ...\n#&gt;   ..$ sigma      : num [1:1000] 0.448 0.432 0.439 0.43 0.46 ...\n#&gt;   ..$ lprior     : num [1:1000] -3.05 -3.05 -3.05 -3.05 -3.05 ...\n#&gt;   ..$ lp__       : num [1:1000] -31.4 -30.9 -31 -31.5 -32.6 ...\n#&gt;  $ 3:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 6.68 6.87 6.89 6.67 6.66 ...\n#&gt;   ..$ b_year_c   : num [1:1000] -0.066 -0.0686 -0.0677 -0.0643 -0.0778 ...\n#&gt;   ..$ sigma      : num [1:1000] 0.403 0.461 0.472 0.594 0.438 ...\n#&gt;   ..$ lprior     : num [1:1000] -3.04 -3.05 -3.05 -3.09 -3.06 ...\n#&gt;   ..$ lp__       : num [1:1000] -31.9 -33.6 -34.4 -34.9 -31.8 ...\n#&gt;  $ 4:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 6.7 6.67 6.7 6.75 6.78 ...\n#&gt;   ..$ b_year_c   : num [1:1000] -0.072 -0.0656 -0.0785 -0.0644 -0.0778 ...\n#&gt;   ..$ sigma      : num [1:1000] 0.485 0.429 0.408 0.52 0.401 ...\n#&gt;   ..$ lprior     : num [1:1000] -3.06 -3.05 -3.05 -3.06 -3.04 ...\n#&gt;   ..$ lp__       : num [1:1000] -31.2 -31.7 -32.2 -32.8 -32.8 ...\n#&gt;  - attr(*, \"class\")= chr [1:3] \"draws_list\" \"draws\" \"list\"\n\n\n60.8.2 Parametri del modello\nPer vedere i nomi dei parametri campionati (intercetta, slope, deviazione standard, ecc.) usiamo:\n\nvariables(fit_2)\n#&gt; [1] \"b_Intercept\" \"b_year_c\"    \"sigma\"       \"lprior\"      \"lp__\"\n\nNel nostro caso, siamo interessati al coefficiente di regressione associato a year_c, che in brms è etichettato come b_year_c.\n\n60.8.3 Estrarre e riorganizzare i campioni\nPer lavorare più comodamente con i campioni, possiamo usare tidybayes, che fornisce funzioni per trasformare gli output bayesiani in formato tidy.\n\nb_slope_draws &lt;- posterior_2 |&gt; \n  spread_draws(b_year_c)\n\nLa funzione spread_draws() “srotola” i campioni in un tibble:\n\nhead(b_slope_draws)\n#&gt; # A tibble: 6 × 4\n#&gt;   .chain .iteration .draw b_year_c\n#&gt;    &lt;int&gt;      &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;\n#&gt; 1      1          1     1  -0.0797\n#&gt; 2      1          2     2  -0.0649\n#&gt; 3      1          3     3  -0.0757\n#&gt; 4      1          4     4  -0.0724\n#&gt; 5      1          5     5  -0.0774\n#&gt; 6      1          6     6  -0.0718\n\nOgni riga rappresenta un singolo campione della catena MCMC per quel parametro.\n\n60.8.4 Calcolare statistiche di sintesi\nUna volta estratti i campioni di b_year_c, possiamo calcolare facilmente mediana, media e quantili:\n\nquantile(b_slope_draws$b_year_c, probs = c(0.03, 0.50, 0.97))\n#&gt;      3%     50%     97% \n#&gt; -0.0812 -0.0714 -0.0619\nmean(b_slope_draws$b_year_c)\n#&gt; [1] -0.0715\n\n\nI quantili a 0.03 e 0.97 definiscono un intervallo di credibilità al 94%.\nIl quantile a 0.50 corrisponde alla mediana a posteriori.\nLa media a posteriori fornisce un’altra stima puntuale utile.\n\n60.8.5 Visualizzare la distribuzione a posteriori\nPer capire meglio la forma della distribuzione a posteriori, possiamo tracciarne la densità. Con tidyverse e tidybayes bastano poche righe:\n\ntibble(beta = b_slope_draws$b_year_c) %&gt;%\n  ggplot(aes(x = beta)) +\n  stat_halfeye() +\n  labs(\n    x = \"Valore di β\",\n    y = \"Densità a posteriori\"\n  )\n\n\n\n\n\n\n\n\n\nstat_halfeye() mostra la densità stimata e mette in evidenza i valori più probabili.\nLa banda orizzontale rappresenta un intervallo di credibilità centrale.\n\n\n60.8.5.1 In sintesi\nGrazie a as_draws() di posterior e alle funzioni di tidybayes, possiamo:\n\nestrarre i campioni MCMC della distribuzione a posteriori,\ncalcolare statistiche di sintesi (media, mediana, quantili),\nvisualizzare in modo intuitivo la forma e l’incertezza della distribuzione di un parametro.\n\nLa combinazione di posterior, tidybayes e tidyverse rende il flusso di lavoro con i modelli stimati da brms semplice, potente e flessibile.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#riflessioni-conclusive",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#riflessioni-conclusive",
    "title": "60  Zucchero sintattico",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto come utilizzare brms per stimare e interpretare modelli lineari in ottica bayesiana. Abbiamo esplorato:\n\ncome impostare e personalizzare i priors;\ncome analizzare la distribuzione a posteriori dei parametri;\ncome condurre verifiche tramite predizioni a posteriori;\ncome affrontare la presenza di outlier con modelli robusti.\n\nL’approccio di brms combina la semplicità sintattica dei modelli classici con la potenza dell’inferenza bayesiana, offrendo un ambiente flessibile e intuitivo per applicazioni reali in psicologia e scienze sociali.\nIn sintesi, brms permette non solo di stimare relazioni lineari, ma anche di ragionare in termini probabilistici: ogni parametro, previsione e indice di adattamento viene trattato come una distribuzione, rendendo l’analisi più trasparente, completa e vicina alle domande della ricerca empirica.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nModello base\nImporta il dataset Howell_18.csv, filtra gli individui di età ≥ 18 anni e adatta un modello bayesiano lineare height ∼ weight usando brm(). Visualizza il sommario.\nCentraggio del predittore\nCalcola la variabile centrata weight_c e adatta il modello height ∼ weight_c. Confronta l’intercetta (b_Intercept) con quella del modello non centrato. Spiega la differenza.\n\nSpecificazione dei prior\nUsa get_prior() per recuperare i prior di default, poi definisci manualmente prior debolmente informativi:\n\nIntercept ∼ Normal(150, 20)\nweight_c ∼ Normal(0, 10)\nsigma ∼ Cauchy(0, 5)\n\nAdatta il modello con questi prior e confronta le stime a posteriori con quelle del modello con prior di default.\n\n\nPredizioni predittive a posteriori\nPer il modello con prior personalizzati:\n\nEsegui pp_check() per la densità e per l’errore medio (type = \"error_scatter_avg\").\nDescrivi brevemente cosa mostrano i due grafici.\n\n\n\nModello robusto\nIntroduci un outlier modificando il primo record: imposta height = 400.\n\nAdatta prima un modello gaussiano e poi uno robusto con family = student().\nConfronta le stime di b_weight_c nei due modelli e discuti l’impatto dell’outlier.\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nModello base\nlibrary(brms)\ndf &lt;- rio::import(\"data/Howell_18.csv\")\ndf_adults &lt;- subset(df, age &gt;= 18)\nfit_base &lt;- brm(height ~ weight, data = df_adults, backend = \"cmdstanr\")\nsummary(fit_base)\n\n\nCentraggio del predittore\ndf_adults$weight_c &lt;- df_adults$weight - mean(df_adults$weight)\nfit_centered &lt;- brm(height ~ weight_c, data = df_adults, backend = \"cmdstanr\")\nsummary(fit_centered)\n\nIl b_Intercept nel modello non centrato è l’altezza prevista per peso = 0 (non interpretabile realisticamente).\n\nNel modello centrato, l’intercetta rappresenta l’altezza media alla media del peso del campione.\n\n\n\nSpecificazione dei prior\nget_prior(height ~ weight_c, data = df_adults)\n\npriors_custom &lt;- c(\n  prior(normal(150, 20), class = \"b\", coef = \"Intercept\"),\n  prior(normal(0, 10), class = \"b\", coef = \"weight_c\"),\n  prior(cauchy(0, 5), class = \"sigma\")\n)\nfit_priors &lt;- brm(\n  height ~ weight_c,\n  data = df_adults,\n  prior = priors_custom,\n  backend = \"cmdstanr\"\n)\nsummary(fit_priors)\n\nLe stime a posteriori rimangono simili, ma i prior personalizzati influenzano leggermente l’incertezza.\n\n\n\nPredizioni predittive a posteriori\npp_check(fit_priors)\npp_check(fit_priors, type = \"error_scatter_avg\")\n\nIl grafico di densità mostra se la distribuzione simulata riproduce quella osservata.\n\nIl grafico degli errori media evidenzia eventuali pattern sistematici nei residui.\n\n\n\nModello robusto\ndf_out &lt;- df_adults\ndf_out$height[1] &lt;- 400\nfit_gauss &lt;- brm(height ~ weight_c, data = df_out, backend = \"cmdstanr\")\nfit_student &lt;- brm(height ~ weight_c, family = student(),\n                   data = df_out, backend = \"cmdstanr\")\nsummary(fit_gauss)$fixed[\"weight_c\", ]\nsummary(fit_student)$fixed[\"weight_c\", ]\n\nIl modello gaussiano vede una variazione marcata di b_weight_c a causa dell’outlier.\n\nIl modello Student stima un coefficiente più vicino al valore senza outlier, dimostrando robustezza.\n\n\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      ggridges_0.5.7        compiler_4.5.1       \n#&gt; [10] reshape2_1.4.4        systemfonts_1.2.3     vctrs_0.6.5          \n#&gt; [13] stringr_1.5.1         pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] utf8_1.2.6            rmarkdown_2.29        ps_1.9.1             \n#&gt; [22] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [25] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [28] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [31] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [34] knitr_1.50            zoo_1.8-14            R.utils_2.13.0       \n#&gt; [37] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [40] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [43] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [46] processx_3.8.6        pkgbuild_1.4.8        plyr_1.8.9           \n#&gt; [49] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [52] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [55] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [58] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [61] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [64] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [67] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [70] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [73] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [76] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [79] gtable_0.3.6          R.methodsS3_1.8.2     digest_0.6.37        \n#&gt; [82] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [85] R.oo_1.27.1           memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [88] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#bibliografia",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#bibliografia",
    "title": "60  Zucchero sintattico",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nClayton, S. (2020). Climate anxiety: Psychological responses to climate change. Journal of anxiety disorders, 74, 102263.\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392–399.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html",
    "href": "chapters/linear_models/05_stan_regression.html",
    "title": "61  Regressione lineare in Stan",
    "section": "",
    "text": "Introduzione\nI n questo capitolo useremo la regressione lineare come laboratorio per imparare a tradurre un modello statistico in Stan: dalla formulazione matematica, alla scrittura del modello generativo, fino all’interpretazione dei coefficienti e alle verifiche predittive.\nL’obiettivo è duplice. Da un lato, acquisire familiarità con la struttura di un modello in Stan: come dichiarare gli oggetti (vector, matrix, parametri, priors), come sfruttare la vettorializzazione della likelihood, e perché questo rende il codice più chiaro ed efficiente. Dall’altro, approfondire l’interpretazione della regressione multipla, distinguendo il coefficiente bivariato (che misura l’associazione totale di un predittore preso da solo) dal coefficiente parziale (che misura l’effetto condizionato sugli altri predittori). È un passaggio essenziale: quando i predittori sono correlati, trascurare questa differenza può portare a conclusioni fuorvianti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#introduzione",
    "href": "chapters/linear_models/05_stan_regression.html#introduzione",
    "title": "61  Regressione lineare in Stan",
    "section": "",
    "text": "61.0.1 Perché usare Stan per la regressione?\nScrivere la regressione in Stan significa specificare un modello generativo completo:\n\\[\ny_n \\sim \\mathcal{N}(\\alpha + \\mathbf{x}_n^\\top \\boldsymbol{\\beta},\\, \\sigma),\n\\] con priors espliciti per \\(\\alpha\\), \\(\\boldsymbol{\\beta}\\) e \\(\\sigma\\). Questo approccio offre tre vantaggi immediati:\n\n\nTrasparenza — la struttura del modello (likelihood e priors) è dichiarata in modo chiaro.\n\nCoerenza — l’inferenza è interamente bayesiana: non ci sono p-value né “soglie di significatività”.\n\nFlessibilità — lo stesso schema si estende facilmente a GLM (esiti Bernoulli, Poisson, ecc.) e a modelli multilivello, semplicemente cambiando la famiglia di distribuzione o la struttura gerarchica.\n\n61.0.2 Idee guida del capitolo\n\n\nNotazione matriciale: la scrittura compatta \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\\) si traduce in Stan in matrix[N,K] X; e vector[K] beta;, con previsioni calcolate come X * beta.\n\nVettorializzazione: scrivere y ~ normal(X * beta + alpha, sigma); è più elegante ed efficiente che iterare su ogni osservazione.\n\nCoefficiente parziale vs bivariato: in presenza di correlazione tra predittori, il coefficiente bivariato può risultare distorto o addirittura invertire segno. I coefficienti del modello multiplo misurano invece l’associazione condizionata.\n\nPriors su scala naturale: formulare i priors nelle unità originali (per esempio, punteggi da 0 a 10 o da 0 a 100) rende le ipotesi più interpretabili e comunicabili.\n\n61.0.3 Una prima finestra sugli errori di specificazione\nIl capitolo affronterà anche alcuni casi frequenti di specificazione errata, con esempi concreti tratti dalla ricerca psicologica:\n\n\nVariabili omesse: trascurare un predittore rilevante e correlato introduce bias nei coefficienti.\n\nForma funzionale errata: trattare relazioni non lineari come lineari semplici produce stime ingannevoli.\n\nVarianza non costante e outlier: assumere residui gaussiani omoschedastici può essere inadeguato; i posterior predictive checks aiutano a diagnosticarlo e a considerare likelihood più robuste.\n\nIn sintesi, la regressione lineare in Stan non è solo un esercizio di calcolo, ma un’occasione per apprendere un metodo: partire da un modello teorico, tradurlo in linguaggio probabilistico, implementarlo in codice, e valutarne la capacità di rappresentare i dati psicologici in modo critico e trasparente.\nPanoramica del capitolo\n\nIl modello di regressione multipla in notazione matriciale.\n\nFormulazione del modello in codice Stan.\n\nStima e interpretazione dei coefficienti parziali e confronto con quelli di modelli bivariati.\n\nEffetto della correlazione tra predittori sulle stime e errore di specificazione.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\nPer seguire al meglio questo capitolo è utile avere:\n\nuna conoscenza di base della regressione lineare semplice e del concetto di coefficiente di regressione;\n\nun’idea generale della notazione vettoriale/matriciale, anche solo a livello concettuale;\nnozioni introduttive di statistica bayesiana: cosa sono i prior, la likelihood e il posterior;\nfamiliarità minima con R per la simulazione di dati e con il flusso di lavoro di Stan.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, posterior, cmdstanr, tidybayes, loo, patchwork)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#regressione-lineare-con-un-solo-predittore",
    "href": "chapters/linear_models/05_stan_regression.html#regressione-lineare-con-un-solo-predittore",
    "title": "61  Regressione lineare in Stan",
    "section": "\n61.1 Regressione lineare con un solo predittore",
    "text": "61.1 Regressione lineare con un solo predittore\nConsideriamo una regressione lineare con un solo predittore, un’intercetta \\(\\alpha\\), un coefficiente \\(\\beta\\) e un errore gaussiano \\(\\sigma\\):\n\\[\ny_n = \\alpha + \\beta\\,x_n + \\varepsilon_n,\\qquad \\varepsilon_n \\sim \\mathcal{N}(0,\\sigma).\n\\]\nIn Stan con priors espliciti e debolmente informativi:\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;               // predittore (consigliato centrare in R)\n  vector[N] y;               // risposta continua\n}\nparameters {\n  real alpha;                // intercetta (valore di y al centro di x)\n  real beta;                 // coefficiente\n  real&lt;lower=0&gt; sigma;       // DS dell'errore\n}\nmodel {\n  // Priors debolmente informativi (propri)\n  alpha ~ normal(0, 10);\n  beta  ~ normal(0, 5);\n  sigma ~ student_t(4, 0, 10);  // half-Student-t implicita grazie al vincolo &lt;lower=0&gt;\n\n  // Likelihood (vettorializzata)\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  vector[N] mu = alpha + beta * x;\n  vector[N] y_rep;\n  for (n in 1:N) y_rep[n] = normal_rng(mu[n], sigma);\n\n  // R^2 \"bayesiano\" (Gelman et al.)\n  real R2 = variance(mu) / (variance(mu) + square(sigma));\n}\nIn questo modello:\n\n\nN è il numero di osservazioni;\nper ogni osservazione abbiamo un valore di x (predittore) e un valore di y (variabile risposta);\n\nalpha ~ normal(0, 10) e beta ~ normal(0, 5) sono priors propri, debolmente informativi sulla scala della variabile y;\n\nsigma ~ student_t(4, 0, 10) è una half-Student-t implicita (perché sigma è vincolata \\(&gt;0\\)); è un prior robusto e poco informativo sulla scala di \\(\\sigma\\).\n\nSe venissero rimosse tutte le righe di prior, Stan non aggiungerebbe priors di default:\n\n\nalpha e beta avrebbero di fatto un prior piatto improprio su \\((-\\infty, +\\infty)\\);\n\nsigma avrebbe un prior piatto improprio su \\((0, +\\infty)\\).\n\nCon likelihood gaussiane questi priors possono talvolta produrre una posteriore propria, ma non è una buona pratica: meglio usare priors (anche deboli) e fare prior predictive checks.\n\n\n\n\n\n\nCentrare i predittori\n\n\n\nConsigliato centrare x in R (x_c &lt;- x - mean(x)) e passare x_c al modello: rende alpha interpretabile (valore atteso di \\(y\\) al centro dei predittori) e migliora la geometria posteriore (minore correlazione tra \\(\\alpha\\) e \\(\\beta\\)).\n\n\n\n61.1.1 Notazione matriciale e vettorializzazione\nLa riga seguente è vettorializzata, cioè calcola la probabilità di tutte le osservazioni in un’unica istruzione:\ny ~ normal(alpha + beta * x, sigma);\nÈ equivalente a scrivere:\nfor (n in 1:N) {\n  y[n] ~ normal(alpha + beta * x[n], sigma);\n}\nLa forma vettorializzata è più compatta e molto più veloce da eseguire. In Stan, quando un argomento di una distribuzione è un vettore, anche gli altri argomenti possono esserlo (purché abbiano la stessa dimensione) oppure possono essere scalari (in tal caso vengono “riciclati” per tutte le osservazioni).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#notazione-matriciale-regressione-multipla",
    "href": "chapters/linear_models/05_stan_regression.html#notazione-matriciale-regressione-multipla",
    "title": "61  Regressione lineare in Stan",
    "section": "\n61.2 Notazione matriciale: regressione multipla",
    "text": "61.2 Notazione matriciale: regressione multipla\nOra estendiamo il ragionamento al caso in cui i predittori siano più di uno, così da introdurre il concetto di effetto parziale.\nQuando abbiamo più predittori per ciascuna osservazione, possiamo scrivere il modello di regressione in forma vettoriale/matriciale (Caudek & Luccio, 2001). Con più predittori per osservazione, in forma compatta il modello è:\n\\[\n\\mathbf{y} = \\mathbf{X} \\, \\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\n\\] dove:\n\n\n\\(\\mathbf{y}\\) è un vettore colonna di dimensione \\(N \\times 1\\), che contiene la variabile risposta per le \\(N\\) osservazioni;\n\n\\(\\mathbf{X}\\) è una matrice \\(N \\times K\\), dove ogni riga corrisponde a un’osservazione e ogni colonna a un predittore (la prima colonna, se presente, è di 1 e serve per l’intercetta);\n\n\\(\\boldsymbol{\\beta}\\) è un vettore colonna di dimensione \\(K \\times 1\\), che contiene i coefficienti del modello (inclusa l’intercetta se la colonna di 1 è presente in \\(\\mathbf{X}\\));\n\n\\(\\boldsymbol{\\varepsilon}\\) è un vettore \\(N \\times 1\\) di errori casuali, che assumiamo distribuiti come \\(\\mathcal{N}(0, \\sigma^2)\\).\n\n\n\n\n\n\n\n\n\nNotazione matematica\nSignificato\nOggetto in Stan\nDichiarazione Stan\n\n\n\n\\(\\mathbf{y}\\)\nVettore colonna degli esiti (variabile risposta)\ny\nvector[N] y;\n\n\n\\(\\mathbf{X}\\)\nMatrice dei predittori (N osservazioni × K predittori)\nx\nmatrix[N, K] x;\n\n\n\\(\\boldsymbol{\\beta}\\)\nVettore colonna dei coefficienti di regressione\nbeta\nvector[K] beta;\n\n\n\\(\\beta_0\\)\nIntercetta\nalpha\nreal alpha;\n\n\n\\(\\sigma\\)\nDeviazione standard dell’errore\nsigma\nreal&lt;lower=0&gt; sigma;\n\n\n\\(\\hat{\\mathbf{y}} = \\mathbf{X} \\boldsymbol{\\beta} + \\beta_0\\)\nVettore delle predizioni lineari\nx * beta + alpha\nEspressione all’interno del modello Stan\n\n\n\\(\\boldsymbol{\\varepsilon}\\)\nVettore degli errori casuali\n—\nImplicito nella distribuzione normal(..., sigma)\n\n\n\n\n\n61.2.1 Sviluppo riga per riga\nScrivendo esplicitamente il contenuto della moltiplicazione \\(\\boldsymbol{X} \\, \\boldsymbol{\\beta}\\), otteniamo:\n\\[\n\\begin{bmatrix}\ny_{1} \\\\\ny_{2} \\\\\n\\vdots \\\\\ny_{N}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & x_{11} & x_{12} & \\dots & x_{1,K-1} \\\\\n1 & x_{21} & x_{22} & \\dots & x_{2,K-1} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_{N1} & x_{N2} & \\dots & x_{N,K-1}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_{0} \\\\\n\\beta_{1} \\\\\n\\beta_{2} \\\\\n\\vdots \\\\\n\\beta_{K-1}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\varepsilon_{1} \\\\\n\\varepsilon_{2} \\\\\n\\vdots \\\\\n\\varepsilon_{N}\n\\end{bmatrix}\n\\]\n\n61.2.2 Interpretazione\n\n\nOgni riga della matrice \\(\\mathbf{X}\\) contiene i valori dei predittori per una singola osservazione.\n\nLa stessa colonna di \\(\\boldsymbol{\\beta}\\) (cioè lo stesso coefficiente) si applica a tutte le righe, moltiplicando il rispettivo valore del predittore.\nIl termine \\(\\beta_0\\) è l’intercetta: è costante e si applica a tutte le osservazioni.\nLa moltiplicazione \\(\\mathbf{X} \\, \\boldsymbol{\\beta}\\) produce un vettore \\(N \\times 1\\) di valori previsti (\\(\\hat{y}\\)), uno per ogni osservazione.\nGli errori \\(\\boldsymbol{\\varepsilon}\\) rappresentano la differenza tra il valore osservato \\(y_i\\) e il valore previsto \\(\\hat{y}_i\\).\n\n61.2.3 Esempio con due variabili indipendenti\nSe \\(N=3\\) e \\(K=3\\) (intercetta + 2 predittori), abbiamo:\n\\[\n\\underbrace{\\begin{bmatrix}\ny_{1} \\\\ y_{2} \\\\ y_{3}\n\\end{bmatrix}}_{y}\n=\n\\underbrace{\\begin{bmatrix}\n1 & x_{11} & x_{12} \\\\\n1 & x_{21} & x_{22} \\\\\n1 & x_{31} & x_{32}\n\\end{bmatrix}}_{X}\n\\underbrace{\\begin{bmatrix}\n\\beta_{0} \\\\ \\beta_{1} \\\\ \\beta_{2}\n\\end{bmatrix}}_{\\beta}\n+\n\\underbrace{\\begin{bmatrix}\n\\varepsilon_{1} \\\\ \\varepsilon_{2} \\\\ \\varepsilon_{3}\n\\end{bmatrix}}_{\\varepsilon}\n\\] Il che equivale a:\n\\[\n\\begin{cases}\ny_{1} = \\beta_0 + \\beta_1 x_{11} + \\beta_2 x_{12} + \\varepsilon_{1} \\\\\ny_{2} = \\beta_0 + \\beta_1 x_{21} + \\beta_2 x_{22} + \\varepsilon_{2} \\\\\ny_{3} = \\beta_0 + \\beta_1 x_{31} + \\beta_2 x_{32} + \\varepsilon_{3}\n\\end{cases}\n\\]\n\n61.2.4 Interpretazione dei coefficienti parziali di regressione\nIn un modello di regressione multipla ogni coefficiente \\(\\beta_j\\) rappresenta l’effetto parziale del predittore \\(x_j\\) sulla variabile risposta \\(y\\), tenendo costanti (cioè controllando per) gli altri predittori inclusi nel modello.\n\n\nEffetto parziale: \\(\\beta_j\\) indica di quanto ci si attende che cambi \\(y\\) in media se \\(x_j\\) aumenta di una unità, mentre tutti gli altri predittori del modello restano invariati.\n\nUnità di misura: l’interpretazione è sempre nella scala originale di \\(y\\) e \\(x_j\\) (se non abbiamo standardizzato).\n\nSegno: positivo se, a parità degli altri predittori, un aumento di \\(x_j\\) è associato a un aumento di \\(y\\); negativo se associato a una diminuzione.\n\n\n61.2.4.1 Differenza con la regressione bivariata\nSe stimiamo un modello bivariato (cioè con un solo predittore per volta), il coefficiente di regressione di \\(x_j\\) rappresenta l’associazione totale tra \\(x_j\\) e \\(y\\), senza tenere conto di altri fattori. Questo può essere fuorviante quando i predittori sono correlati tra loro e/o esiste un predittore \\(x_k\\) che spiega parte della stessa varianza di \\(y\\) che spiega \\(x_j\\).\nIn questi casi:\n\n\nModello bivariato: il coefficiente di \\(x_j\\) include anche l’effetto “indiretto” dovuto alla sua correlazione con altri predittori.\n\nModello multiplo: il coefficiente di \\(x_j\\) è “depurato” dagli effetti degli altri predittori, cioè riflette l’associazione residua unica di \\(x_j\\) con \\(y\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#esempio-numerico",
    "href": "chapters/linear_models/05_stan_regression.html#esempio-numerico",
    "title": "61  Regressione lineare in Stan",
    "section": "\n61.3 Esempio numerico",
    "text": "61.3 Esempio numerico\nPer chiarire concretamente la differenza tra l’effetto totale (o grezzo) di un predittore e il suo effetto parziale (o netto), simuliamo uno scenario realistico ipotizzando che l’esito \\(y\\) sia un punteggio di stress su scala 0–10. I due predittori sono:\n\n\n\\(x_1\\): affetto negativo istantaneo su scala 0–10 (più alto = più negativo);\n\n\\(x_2\\): ore di sonno nell’ultima notte su scala 0–10.\n\nSupponiamo che:\n\na parità di altre condizioni, aumentare l’affetto negativo di 1 punto (su 0–10) faccia crescere lo stress di qualche punto (effetto positivo);\n\ndormire di più riduca lo stress (effetto negativo);\nil livello medio di stress a affetto negativo medio e sonno medio sia moderato.\n\n\nset.seed(42)\n\nN &lt;- 2000\nrho &lt;- 0.8\n\nx1 &lt;- rnorm(N, 0, 1)\nz  &lt;- rnorm(N, 0, 1)\nx2 &lt;- rho * x1 + sqrt(1 - rho^2) * z  # cor(x1, x2) ~ 0.8\n\nbeta1_true &lt;-  1\nbeta2_true &lt;- -2\nsigma_true &lt;-  0.5\n\ny &lt;- beta1_true * x1 + beta2_true * x2 + rnorm(N, 0, sigma_true)\n\ndati &lt;- tibble(y = y + abs(min(y)), x1 = x1 + abs(min(x1)), x2 = x2 + abs(min(x2)))\nsummary(dati)\n#&gt;        y              x1             x2      \n#&gt;  Min.   :0.00   Min.   :0.00   Min.   :0.00  \n#&gt;  1st Qu.:3.26   1st Qu.:2.70   1st Qu.:2.73  \n#&gt;  Median :4.23   Median :3.36   Median :3.38  \n#&gt;  Mean   :4.23   Mean   :3.36   Mean   :3.38  \n#&gt;  3rd Qu.:5.21   3rd Qu.:4.03   3rd Qu.:4.06  \n#&gt;  Max.   :9.03   Max.   :6.96   Max.   :6.70\n\nSe i due predittori \\(x_1\\) e \\(x_2\\) sono correlati (ad esempio: chi dorme poco tende anche a percepire più stress):\n\ncor(dati$x1, dati$x2)\n#&gt; [1] 0.8\n\nallora i coefficienti stimati assumono significati diversi a seconda del modello:\n\nNel modello bivariato \\(y \\sim x_1\\), il coefficiente di \\(x_1\\) riflette non solo l’effetto diretto dello stress sull’ansia, ma anche l’effetto indiretto mediato dalla correlazione con il sonno (più stress → meno sonno → più ansia).\nNel modello multiplo \\(y \\sim x_1 + x_2\\), il coefficiente di \\(x_1\\) isola invece l’effetto unico dello stress, cioè la variazione di ansia associata a un incremento di stress a parità di ore di sonno.\n\nIn sintesi:\n\ni coefficienti bivariati misurano l’associazione totale tra predittore e risposta,\ni coefficienti parziali misurano l’associazione unica, controllando per gli altri predittori,\nla differenza tra i due diventa rilevante quando i predittori sono correlati.\n\nPer rendere chiara la differenza, usiamo i dati simulati (y, x1, x2) e stimiamo i coefficienti di regressione in due modi diversi:\n– usando un predittore alla volta (y ~ x1 e y ~ x2); – usando entrambi i predittori insieme (y ~ x1 + x2).\nPer semplicità, iniziamo a stimare i coefficienti con lm() (poi useremo Stan):\n\n# Modelli bivariati\nfit_biv_x1 &lt;- lm(y ~ x1, data = dati)\nfit_biv_x2 &lt;- lm(y ~ x2, data = dati)\n\n# Modello multiplo\nfit_mult &lt;- lm(y ~ x1 + x2, data = dati)\n\n# Confronto dei coefficienti\ncoefs &lt;- data.frame(\n  Modello = c(\"Bivariato x1\", \"Bivariato x2\", \"Multiplo\"),\n  beta_x1 = c(coef(fit_biv_x1)[\"x1\"], NA, coef(fit_mult)[\"x1\"]),\n  beta_x2 = c(NA, coef(fit_biv_x2)[\"x2\"], coef(fit_mult)[\"x2\"])\n)\ncoefs\n#&gt;        Modello beta_x1 beta_x2\n#&gt; 1 Bivariato x1  -0.618      NA\n#&gt; 2 Bivariato x2      NA   -1.22\n#&gt; 3     Multiplo   1.017   -2.02\n\nI valori veri dei coefficienti erano:\n\nbeta1_true &lt;-  1\nbeta2_true &lt;- -2\n\nCosa osserviamo:\n\nnel modello bivariato y ~ x1, il coefficiente di x1 è negativo (≈ −0.6), anche se il vero effetto è positivo (+1);\nnel modello multiplo y ~ x1 + x2, i coefficienti si avvicinano ai valori veri (≈ +1 per x1, ≈ −2 per x2): qui leggiamo gli effetti parziali, cioè ciascun predittore “a parità” dell’altro.\n\nIl cambio di segno nel bivariato è un chiaro esempio di bias da variabile omessa: se escludiamo x2 (sonno), l’effetto stimato di x1 (affetto negativo) assorbe anche parte dell’influenza del sonno, arrivando persino a invertirne il segno.\nMatematicamente, l’atteso del coefficiente bivariato è:\n\\[\n\\mathbb{E}\\!\\left[\\hat\\beta^{(biv)}_{x1}\\right] \\;=\\;\n\\beta_1 \\;+\\; \\beta_2 \\frac{\\operatorname{Cov}(x_1, x_2)}{\\operatorname{Var}(x_1)} .\n\\]\nQuando \\(\\beta_2\\) e \\(\\operatorname{Cov}(x_1, x_2)\\) hanno segni opposti e grande ampiezza, la correzione può superare \\(\\beta_1\\) e invertire il segno.\n\n\n\n\n\n\nMessaggio didattico:\n\nI coefficienti bivariati misurano l’associazione totale tra un predittore e la risposta.\nI coefficienti parziali del modello multiplo misurano l’associazione unica, condizionata agli altri predittori.\nIn psicologia (e non solo), questo è cruciale: includere o escludere variabili di controllo — ad esempio livello socioeconomico, sonno o supporto sociale — può cambiare radicalmente la stima di un effetto.\n\n\n\n\n\n61.3.1 La regressione multipla in Stan\nOra ripetiamo l’analisi precedente usando Stan. Prima però ci rinfreschiamo la memoria relativamente alle operazioni di algebra matriciale necessarie per capire il codice Stan.\n\n\n\n\n\n\nCome funziona la moltiplicazione tra matrici (ripasso essenziale)\n\n\n\n\n\nConformabilità. Due matrici si possono moltiplicare solo se il numero di colonne della prima coincide con il numero di righe della seconda. Se \\(A\\) è \\(m \\times k\\) e \\(B\\) è \\(k \\times n\\), allora il prodotto \\(C = A B\\) esiste ed è una matrice di dimensione \\(m \\times n\\).\nElemento \\(c_{ij}\\). L’elemento sulla riga \\(i\\) e colonna \\(j\\) di \\(C\\) si ottiene come prodotto scalare tra:\n\nla riga \\(i\\)-esima di \\(A\\) e\nla colonna \\(j\\)-esima di \\(B\\).\n\nPer prodotto scalare intendiamo: somma dei prodotti degli elementi corrispondenti.\nFormalmente,\n\\[\nc_{ij} \\;=\\; \\sum_{t=1}^{k} a_{i t}\\, b_{t j}.\n\\]\nEsempio numerico.\nSiano\n\\[\nA=\\begin{bmatrix}\n1 & 2 & 3\\\\\n4 & 5 & 6\n\\end{bmatrix}\n\\quad (2\\times 3), \\qquad\nB=\\begin{bmatrix}\n1 & 0\\\\\n-1 & 2\\\\\n2 & 1\n\\end{bmatrix}\n\\quad (3\\times 2).\n\\]\nSono conformabili (3 colonne di \\(A\\) = 3 righe di \\(B\\)). Il prodotto \\(C=AB\\) sarà \\(2\\times 2\\).\nCalcoliamo i singoli elementi:\n\n\\(c_{11} = [1,2,3]\\cdot[1,-1,2]^\\top = 1\\cdot 1 + 2\\cdot(-1) + 3\\cdot 2 = 1 - 2 + 6 = 5\\)\n\\(c_{12} = [1,2,3]\\cdot[0,2,1]^\\top = 1\\cdot 0 + 2\\cdot 2 + 3\\cdot 1 = 0 + 4 + 3 = 7\\)\n\\(c_{21} = [4,5,6]\\cdot[1,-1,2]^\\top = 4\\cdot 1 + 5\\cdot(-1) + 6\\cdot 2 = 4 - 5 + 12 = 11\\)\n\\(c_{22} = [4,5,6]\\cdot[0,2,1]^\\top = 4\\cdot 0 + 5\\cdot 2 + 6\\cdot 1 = 0 + 10 + 6 = 16\\)\n\nQuindi\n\\[\nC=AB=\\begin{bmatrix}\n5 & 7\\\\\n11 & 16\n\\end{bmatrix}.\n\\]\nVerifica in R.\n\nA &lt;- matrix(c(1,2,3, 4,5,6), nrow = 2, byrow = TRUE)\nB &lt;- matrix(c(1,0, -1,2, 2,1), nrow = 3, byrow = TRUE)\nA %*% B\n#&gt;      [,1] [,2]\n#&gt; [1,]    5    7\n#&gt; [2,]   11   16\n\n\n\n\nCon più predittori, anche in Stan possiamo usare la notazione matriciale:\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=1&gt; K;\n  matrix[N, K] X;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  vector[K] beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  alpha ~ normal(0, 10);\n  beta  ~ normal(0, 5);\n  sigma ~ student_t(4, 0, 10);\n\n  y ~ normal(X * beta + alpha, sigma);\n}\ngenerated quantities {\n  vector[N] mu = alpha + X * beta;\n  vector[N] y_rep;\n  for (n in 1:N) y_rep[n] = normal_rng(mu[n], sigma);\n  real R2 = variance(mu) / (variance(mu) + square(sigma));\n}\nQui:\n\n\nx è una matrice N × K di predittori;\n\nbeta è un vettore con K coefficienti;\n\nx * beta produce un vettore di N valori predetti;\naggiungendo alpha otteniamo la previsione completa per ogni osservazione.\n\nAnche in questo caso la forma vettorializzata è equivalente a:\nfor (n in 1:N) {\n  y[n] ~ normal(x[n] * beta + alpha, sigma);\n}\n\n61.3.2 Intercetta come colonna della matrice dei predittori\nSe preferiamo non dichiarare un parametro separato per l’intercetta (alpha), possiamo inserire una colonna di 1 come prima colonna della matrice x. In questo caso il primo elemento di beta (beta[1]) fungerà da intercetta.\nSe però vogliamo assegnare un prior diverso all’intercetta rispetto agli altri coefficienti, è meglio dichiarare alpha come parametro separato. Questo è anche leggermente più efficiente, ma la differenza di velocità è trascurabile: la scelta va fatta per chiarezza del codice.\nScriviamo dunque il modello Stan per i dati dell’esempio in discussione.\n\nstancode &lt;- write_stan_file(\"\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=1&gt; K;\n  matrix[N, K] X;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  vector[K] beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  alpha ~ normal(0, 10);\n  beta  ~ normal(0, 5);\n  sigma ~ student_t(4, 0, 10);\n\n  y ~ normal(X * beta + alpha, sigma);\n}\ngenerated quantities {\n  vector[N] mu = alpha + X * beta;\n  vector[N] y_rep;\n  for (n in 1:N) y_rep[n] = normal_rng(mu[n], sigma);\n  real R2 = variance(mu) / (variance(mu) + square(sigma));\n}\n\")\n\nNotiamo la scelta dei prior nel modello Stan:\nalpha ~ normal(0, 10);\nbeta  ~ normal(0, 5);\nsigma ~ student_t(4, 0, 10);\n\nIntercetta alpha: prior normal(0,10). È un prior debole e poco informativo: ammette con alta probabilità valori compresi tra circa −20 e +20. È adatto se i dati sono centrati (così l’intercetta rappresenta il valore medio di \\(y\\)). Se invece \\(y\\) ha una scala diversa, conviene adeguare la deviazione standard del prior alla variabilità attesa dei dati.\nCoefficienti beta: prior normal(0,5). Indica che, a priori, ci aspettiamo effetti di ampiezza moderata (nell’ordine di qualche unità di \\(y\\) per uno scarto unitario di \\(x\\)), ma lasciamo aperta la possibilità a effetti anche più grandi. Se i predittori vengono standardizzati, un prior ancora più stretto come normal(0,1) diventa naturale, perché corrisponde all’ipotesi che la maggior parte degli effetti sia inferiore a ±2 deviazioni standard di \\(y\\).\nDeviazione standard sigma: prior student_t(4, 0, 10). È una distribuzione half-Student-t (positiva per vincolo &lt;lower=0&gt;), con code più pesanti della normale: questo rende il prior robusto, permettendo valori piccoli ma anche occasionalmente molto grandi per \\(\\sigma\\). In pratica, evita che il modello “forzi” troppo la variabilità residua, ma previene anche valori assurdi.\n\nMessaggio didattico: questi prior sono propri e debolmente informativi: non costringono il modello a soluzioni arbitrarie, ma al tempo stesso evitano i problemi dei prior impropri (che Stan non assegna mai di default).\nIn generale, conviene:\n\ncentrare e, se possibile, standardizzare i predittori;\nscegliere prior compatibili con la scala dei dati;\nverificare le implicazioni con un prior predictive check (simulando \\(y\\) dai soli prior).\n\nCompiliamo:\n\nmod &lt;- cmdstan_model(stancode, compile = TRUE)\n\n\n61.3.2.1 Un solo predittore\nIniziamo stimando il modello con un solo predittore. Costruiamo la matrice \\(X\\) di dimensione \\(N \\times 1\\) (una sola colonna) e centriamo i dati per rendere l’intercetta più interpretabile:\n\n# Scegliamo il predittore (qui x1; per usare x2 basta sostituire \"x1\")\nx1_c &lt;- dati$x1 - mean(dati$x1)  # centratura rispetto alla media\n\n# Creiamo una matrice N×1 (attenzione: non usare as.numeric, che schiaccia la matrice)\nX &lt;- matrix(x1_c, ncol = 1)\nK &lt;- ncol(X)  # qui sarà 1\n\nPrepariamo i dati per Stan:\n\nstan_data &lt;- list(\n  N = nrow(dati),\n  K = K,   # numero di predittori: 1\n  X = X,   # matrice N×1\n  y = dati$y\n)\nglimpse(stan_data)  # controllo rapido della lista\n#&gt; List of 4\n#&gt;  $ N: int 2000\n#&gt;  $ K: int 1\n#&gt;  $ X: num [1:2000, 1] 1.387 -0.549 0.379 0.648 0.42 ...\n#&gt;  $ y: num [1:2000] 3.01 4.47 5.9 6.42 4.52 ...\n\nEseguiamo il campionamento MCMC:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 2025,\n  chains = 4,\n  parallel_chains = 4,\n  iter_warmup = 1000,\n  iter_sampling = 2000\n)\n\nSintesi delle stime a posteriori:\n\nsumm &lt;- fit$summary(variables = c(\"alpha\", \"beta\", \"sigma\", \"R2\"))\nsumm\n#&gt; # A tibble: 4 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha     4.233  4.234 0.030 0.030  4.184  4.282 1.001 9428.401 6239.711\n#&gt; 2 beta[1]  -0.618 -0.619 0.030 0.029 -0.667 -0.570 1.003 8381.228 6196.084\n#&gt; 3 sigma     1.326  1.326 0.021 0.020  1.293  1.362 1.000 9120.684 5505.744\n#&gt; 4 R2        0.177  0.177 0.015 0.015  0.153  0.202 1.003 8432.253 5653.883\n\nCon un solo predittore, osserviamo lo stesso bias da variabile omessa che avevamo trovato con lm(): il coefficiente stimato per x1 è distorto perché il modello non tiene conto dell’influenza di x2.\n\n61.3.2.2 Due predittori\nOra estendiamo il modello includendo entrambi i predittori. Creiamo una matrice \\(X\\) di dimensione \\(N \\times 2\\), centrando entrambe le colonne:\n\n# Matrice con due predittori centrati\nX &lt;- cbind(dati$x1, dati$x2)\nX &lt;- scale(X, center = TRUE, scale = FALSE)\nK &lt;- ncol(X)  # ora K = 2\n\nPrepariamo i dati per Stan:\n\nstan2_data &lt;- list(\n  N = nrow(dati), \n  K = K, \n  X = X, \n  y = dati$y\n)\nglimpse(stan2_data)\n#&gt; List of 4\n#&gt;  $ N: int 2000\n#&gt;  $ K: int 2\n#&gt;  $ X: num [1:2000, 1:2] 1.387 -0.549 0.379 0.648 0.42 ...\n#&gt;   ..- attr(*, \"scaled:center\")= num [1:2] 3.36 3.38\n#&gt;  $ y: num [1:2000] 3.01 4.47 5.9 6.42 4.52 ...\n\nCampionamento:\n\nfit2 &lt;- mod$sample(\n  data = stan2_data,\n  seed = 2025, \n  chains = 4, \n  parallel_chains = 4,\n  iter_warmup = 1000, \n  iter_sampling = 2000\n)\n\nSintesi delle stime:\n\nsumm &lt;- fit2$summary(variables = c(\"alpha\", \"beta\", \"sigma\", \"R2\"))\nsumm\n#&gt; # A tibble: 5 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha     4.233  4.233 0.012 0.012  4.214  4.253 1.000 6567.012 5247.360\n#&gt; 2 beta[1]   1.016  1.017 0.019 0.019  0.986  1.047 1.001 4515.829 4602.377\n#&gt; 3 beta[2]  -2.017 -2.017 0.018 0.018 -2.047 -1.986 1.001 4308.570 4405.765\n#&gt; 4 sigma     0.515  0.515 0.008 0.008  0.502  0.528 1.000 6678.973 5652.335\n#&gt; 5 R2        0.876  0.876 0.004 0.004  0.869  0.882 1.001 6445.047 5823.024\n\nInterpretazione\n\nI posterior mean di beta[1] e beta[2] sono vicini ai valori veri della simulazione (+1 e −2), e gli intervalli di credibilità li comprendono.\nQuesto conferma che il modello multiplo riesce a recuperare gli effetti “puliti”, eliminando il bias da variabile omessa.\n\nLavorando su scala grezza, i coefficienti sono immediatamente leggibili:\n\n\nbeta[1]: +1 punto di affetto negativo → +1 punto di stress,\n\nbeta[2]: +1 ora di sonno → −2 punti di stress.\n\n61.3.3 Diagnostica\n\nfit2$cmdstan_diagnose()\n#&gt; Checking sampler transitions treedepth.\n#&gt; Treedepth satisfactory for all transitions.\n#&gt; \n#&gt; Checking sampler transitions for divergences.\n#&gt; No divergent transitions found.\n#&gt; \n#&gt; Checking E-BFMI - sampler transitions HMC potential energy.\n#&gt; E-BFMI satisfactory.\n#&gt; \n#&gt; Rank-normalized split effective sample size satisfactory for all parameters.\n#&gt; \n#&gt; Rank-normalized split R-hat values satisfactory for all parameters.\n#&gt; \n#&gt; Processing complete, no problems detected.\n\n\n61.3.4 Controllo predittivo posteriore\n\ndraws &lt;- fit2$draws()\n# Estrazione sicura dei draw per mu e y_rep\n# (uso 'variables =' e imposto l'ordine esplicito 1..N per y_rep)\nmu_draws   &lt;- posterior::as_draws_matrix(fit2$draws(variables = \"mu\"))\nyrep_draws &lt;- posterior::as_draws_matrix(\n  fit2$draws(variables = paste0(\"y_rep[\", 1:N, \"]\"))\n)\n\n# Controllo di coerenza dimensioni (opzionale ma utile)\nstopifnot(ncol(yrep_draws) == length(dati$y))\n\n# PPC: uso 100 repliche (righe = draw, colonne = osservazioni)\nns &lt;- min(100, nrow(yrep_draws))\nbayesplot::ppc_dens_overlay(dati$y, yrep_draws[1:ns, ])\n\n\n\n\n\n\n\nSe le curve replicate si sovrappongono bene alla distribuzione osservata di \\(y\\), il modello ha una buona calibrazione predittiva.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#robustezza-agli-outlier-regressione-t-di-student",
    "href": "chapters/linear_models/05_stan_regression.html#robustezza-agli-outlier-regressione-t-di-student",
    "title": "61  Regressione lineare in Stan",
    "section": "\n61.4 Robustezza agli outlier: regressione t di Student",
    "text": "61.4 Robustezza agli outlier: regressione t di Student\nLa regressione lineare classica assume che gli errori siano gaussiani, cioè distribuiti come \\(\\mathcal{N}(0,\\sigma)\\). Questa ipotesi funziona bene quando la distribuzione dei residui è “ben comportata”. Tuttavia, in psicologia capita spesso di avere osservazioni estreme (outlier) che non si adattano a questa ipotesi: pochi valori anomali possono “tirare” la retta e distorcere molto le stime.\nUn rimedio è sostituire la normale con la distribuzione t di Student, che ha code più pesanti. Questo significa che gli outlier ricevono meno peso: la stima è più robusta, perché non si lascia influenzare eccessivamente da poche osservazioni estreme.\n\n61.4.1 Il modello in Stan\nEcco la versione “robusta” della regressione multipla:\n// file: lm_multiple_t.stan\ndata {\n  int&lt;lower=1&gt; N;          // numero osservazioni\n  int&lt;lower=1&gt; K;          // numero predittori\n  matrix[N, K] X;          // matrice dei predittori\n  vector[N] y;             // variabile risposta\n}\nparameters {\n  real alpha;              // intercetta\n  vector[K] beta;          // coefficienti di regressione\n  real&lt;lower=0&gt; sigma;     // scala residui\n  real&lt;lower=2&gt; nu;        // gradi di libertà (&gt;=2 per varianza finita)\n}\nmodel {\n  // Priors\n  alpha ~ normal(0, 10);\n  beta  ~ normal(0, 5);\n  sigma ~ student_t(4, 0, 10);\n  nu    ~ exponential(0.1);   // media ≈ 10, lascia aperta la possibilità a valori piccoli\n\n  // Likelihood: regressione t (GLM)\n  target += student_t_id_glm_lpdf(y | nu, X, alpha, beta, sigma);\n}\ngenerated quantities {\n  vector[N] mu = alpha + X * beta;\n  vector[N] y_rep;\n  for (n in 1:N)\n    y_rep[n] = student_t_rng(nu, mu[n], sigma);\n\n  real R2 = variance(mu) / (variance(mu) + square(sigma));\n}\n\n61.4.2 Interpretazione dei parametri\n\n\nnu controlla lo “spessore delle code”:\n\nvalori grandi (es. \\(\\nu &gt; 30\\)) rendono la t praticamente indistinguibile da una normale,\nvalori piccoli (es. \\(\\nu \\approx 3\\)–\\(5\\)) producono code pesanti e quindi maggiore robustezza.\n\n\nsigma misura la dispersione residua, ma ora è separata dalla robustezza delle code.\n\nMessaggio didattico: con la t di Student il modello “capisce” che ci sono dati un po’ anomali e li tratta con cautela, senza lasciarsi dominare da essi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#non-linearità-errore-di-specificazione-e-ppc",
    "href": "chapters/linear_models/05_stan_regression.html#non-linearità-errore-di-specificazione-e-ppc",
    "title": "61  Regressione lineare in Stan",
    "section": "\n61.5 Non linearità (errore di specificazione) e PPC",
    "text": "61.5 Non linearità (errore di specificazione) e PPC\nUn altro caso frequente di errore di specificazione si ha quando forziamo un modello lineare su dati che in realtà hanno una curvatura (per esempio quadratica). Anche se i residui sembrano gaussiani, il modello sbaglia sistematicamente le previsioni.\n\n61.5.1 Simuliamo dati non lineari\n\nset.seed(11)\nN &lt;- 300\nx &lt;- rnorm(N)\ny_true &lt;- 1 + 2*x + 1.5*x^2         # relazione quadratica\ny &lt;- y_true + rnorm(N, 0, 1.5)\n\nX &lt;- cbind(x)                       # modello lineare \"sbagliato\"\nK &lt;- 1\n\n\n61.5.2 Fittiamo un modello lineare\n\nfit_lin &lt;- mod$sample(\n  data = list(N = N, K = K, X = scale(X, center = TRUE, scale = FALSE), y = y),\n  seed = 2025, chains = 4, parallel_chains = 4,\n  iter_warmup = 1000, iter_sampling = 2000\n)\n\n\n61.5.3 Controllo predittivo posteriore\n\nyrep_lin &lt;- as_draws_matrix(fit_lin$draws(\"y_rep\"))\nbayesplot::ppc_scatter_avg(y = y, yrep = yrep_lin[1:200, ])\n\n\n\n\n\n\n\n\n61.5.4 Cosa osserviamo?\nIl PPC mostra un mismatch sistematico: le previsioni lineari non seguono la curvatura dei dati veri. Il modello sta sbagliando in maniera strutturale, non solo per rumore.\n\n61.5.5 Come rimediare?\n\nAggiungere un termine quadratico (\\(x^2\\)) come nuovo predittore;\nUsare polinomi di grado superiore;\nOppure usare modelli flessibili (spline, funzioni base, Gaussian process).\n\nMessaggio didattico: i PPC non servono solo a “validare” un modello, ma soprattutto a diagnosticare quando la forma funzionale è troppo rigida. In questo caso, il PPC rivela l’esigenza di un modello più flessibile.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#riflessioni-conclusive",
    "href": "chapters/linear_models/05_stan_regression.html#riflessioni-conclusive",
    "title": "61  Regressione lineare in Stan",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo tradotto la regressione lineare in un modello generativo scritto in Stan, partendo dal caso con un solo predittore fino alla forma multipla in notazione matriciale. Questo ci ha permesso di chiarire una distinzione fondamentale: il coefficiente bivariato descrive l’associazione totale fra un predittore e l’esito, mentre il coefficiente parziale misura l’effetto specifico, depurato dall’influenza degli altri predittori. È un passaggio cruciale per leggere correttamente le relazioni nei dati psicologici, dove le variabili sono spesso tra loro correlate.\nDal punto di vista operativo abbiamo toccato tutti i passaggi essenziali di un’analisi bayesiana:\n\n\nSimulazione di dati plausibili su scala grezza, per mantenere l’interpretabilità dei coefficienti.\n\nScelta dei prior: non arbitrari, ma debolmente informativi e ancorati alle conoscenze teoriche disponibili.\n\nImplementazione in Stan tramite CmdStanR, con sintassi vettorializzata che sfrutta l’algebra lineare.\n\nDiagnostica del modello: controllo predittivo posteriore e calcolo dell’\\(R^2\\) bayesiano come misura sintetica di adattamento.\n\nIn questo modo abbiamo percorso l’intero ciclo di lavoro bayesiano: dalla formulazione del modello teorico, alla traduzione in codice, alla valutazione critica delle sue prestazioni. L’idea centrale è che la regressione non è solo “stimare una retta”, ma un laboratorio per apprendere come costruire, stimare e validare modelli probabilistici che mantengano un legame diretto con le ipotesi psicologiche.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#bibliografia",
    "href": "chapters/linear_models/05_stan_regression.html#bibliografia",
    "title": "61  Regressione lineare in Stan",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi (III rist. 2023, Vol. 11, p. 320). Laterza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_specification_error.html",
    "href": "chapters/linear_models/06_specification_error.html",
    "title": "62  Errore di specificazione e bias da variabile omessa",
    "section": "",
    "text": "Introduzione\nUno degli aspetti più delicati dei modelli di regressione è il rischio di errore di specificazione (Ramsey, 1969). Questo si verifica quando il modello che stimiamo non corrisponde al “vero” modello che ha generato i dati. In particolare, parleremo del caso in cui omettiamo una variabile esplicativa che:\nQuando entrambe queste condizioni si verificano, la stima dei coefficienti parziali di regressione risulta sistematicamente distorta.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Errore di specificazione e bias da variabile omessa</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_specification_error.html#introduzione",
    "href": "chapters/linear_models/06_specification_error.html#introduzione",
    "title": "62  Errore di specificazione e bias da variabile omessa",
    "section": "",
    "text": "è correlata con almeno uno dei regressori inclusi nel modello, e\n\nha un effetto diretto sulla variabile dipendente \\(Y\\).\n\n\nPanoramica del capitolo\n\nBias da variabile omessa: escludere una variabile rilevante altera sistematicamente i coefficienti.\nCondizioni del bias.\nImplicazioni: i coefficienti OLS non sono interpretabili in chiave causale; la regressione è fenomenologica.\nProspettiva: privilegiare modelli meccanicistici (es., Rescorla–Wagner, DDM, dinamici EMA).\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\nPer seguire al meglio questo capitolo è utile avere:\n\nuna conoscenza di base della regressione lineare semplice e del concetto di coefficiente di regressione.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, posterior, cmdstanr, tidybayes, loo, patchwork)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Errore di specificazione e bias da variabile omessa</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_specification_error.html#sec-ovb",
    "href": "chapters/linear_models/06_specification_error.html#sec-ovb",
    "title": "62  Errore di specificazione e bias da variabile omessa",
    "section": "\n62.1 Errore di specificazione e bias da variabile omessa",
    "text": "62.1 Errore di specificazione e bias da variabile omessa\n\n62.1.1 Idea chiave\nSe il vero modello è\n\\[\nY=\\beta_0+\\beta_1X_1+\\beta_2X_2+\\varepsilon,\\qquad \\mathbb{E}[\\varepsilon\\mid X_1,X_2]=0,\n\\] ma stimiamo erroneamente il modello che omette \\(X_2\\),\n\\[\nY=\\alpha_0+\\alpha_1X_1+u,\n\\] allora il coefficiente su \\(X_1\\) risulta distorto quando:\n\n\n\\(X_2\\) ha effetto diretto su \\(Y\\) (\\(\\beta_2\\neq 0\\));\n\n\\(X_2\\) è correlata con \\(X_1\\) (\\(\\mathrm{Corr}(X_1,X_2)\\neq 0\\)).\n\n62.1.2 Dimostrazione (via standardizzazione)\n\n62.1.2.1 Passo 1 — Standardizza le variabili\nDefiniamo medie \\(\\mu_1,\\mu_2,\\mu_Y\\) e deviazioni standard \\(\\sigma_1,\\sigma_2,\\sigma_Y\\). Poniamo\n\\[\nZ_1=\\frac{X_1-\\mu_1}{\\sigma_1},\\qquad\nZ_2=\\frac{X_2-\\mu_2}{\\sigma_2},\\qquad\nZ_Y=\\frac{Y-\\mu_Y}{\\sigma_Y}.\n\\]\nPer costruzione:\n\n\n\\(\\mathrm{Var}(Z_1)=\\mathrm{Var}(Z_2)=1\\),\n\n\\(\\mathrm{Cov}(Z_1,Z_2)=\\rho_{12}=\\mathrm{Corr}(X_1,X_2)\\).\n\nIl modello vero standardizzato è\n\\[\nZ_Y=\\gamma_1 Z_1+\\gamma_2 Z_2+\\varepsilon_z,\\qquad \\mathbb{E}[\\varepsilon_z\\mid Z_1,Z_2]=0,\n\\] con beta standardizzati\n\\[\n\\gamma_1=\\beta_1\\,\\frac{\\sigma_1}{\\sigma_Y},\\qquad\n\\gamma_2=\\beta_2\\,\\frac{\\sigma_2}{\\sigma_Y}.\n\\]\n\n62.1.2.2 Passo 2 — Stima (erronea) che omette \\(Z_2\\)\n\nStimiamo la regressione univariata\n\\[\nZ_Y=\\delta_1 Z_1 + \\text{errore}.\n\\]\nPer OLS,\n\\[\n\\hat\\delta_1=\\frac{\\mathrm{Cov}(Z_1,Z_Y)}{\\mathrm{Var}(Z_1)}=\\mathrm{Cov}(Z_1,Z_Y),\n\\] dato che \\(\\mathrm{Var}(Z_1)=1\\).\nUsiamo il modello vero standardizzato:\n\\[\n\\begin{align}\n\\mathrm{Cov}(Z_1,Z_Y)\n&=\\mathrm{Cov}\\big(Z_1,\\gamma_1Z_1+\\gamma_2Z_2+\\varepsilon_z\\big)\\notag\\\\\n&=\\gamma_1\\underbrace{\\mathrm{Var}(Z_1)}_{=1}\n+\\gamma_2\\,\\mathrm{Cov}(Z_1,Z_2)\n+\\underbrace{\\mathrm{Cov}(Z_1,\\varepsilon_z)}_{=0}.\n\\end{align}\n\\]\nQuindi\n\\[\n\\boxed{\\;\\hat\\delta_1=\\gamma_1+\\gamma_2\\,\\rho_{12}\\;}.\n\\]\nLettura immediata: il coefficiente stimato univariato mescola l’effetto diretto standardizzato di \\(X_1\\) (\\(\\gamma_1\\)) con un termine spurio \\(\\gamma_2\\rho_{12}\\) dovuto all’omissione di \\(X_2\\).\n\n62.1.3 Ritraduzione ai coefficienti non standardizzati\nTra i coefficienti vale\n\\[\n\\hat\\delta_1=\\frac{\\sigma_1}{\\sigma_Y}\\,\\hat\\alpha_1,\\qquad\n\\gamma_1=\\beta_1\\,\\frac{\\sigma_1}{\\sigma_Y},\\qquad\n\\gamma_2=\\beta_2\\,\\frac{\\sigma_2}{\\sigma_Y}.\n\\]\nDalla formula standardizzata\n\\[\n\\hat\\delta_1=\\gamma_1+\\gamma_2\\rho_{12}\n\\] segue\n\\[\n\\frac{\\sigma_1}{\\sigma_Y}\\,\\hat\\alpha_1\n=\\beta_1\\frac{\\sigma_1}{\\sigma_Y}\n+\\beta_2\\frac{\\sigma_2}{\\sigma_Y}\\rho_{12}.\n\\]\nMoltiplicando per \\(\\sigma_Y/\\sigma_1\\) e ricordando che \\(\\rho_{12}=\\dfrac{\\mathrm{Cov}(X_1,X_2)}{\\sigma_1\\sigma_2}\\), ottieniamo la forma non standardizzata:\n\\[\n\\boxed{\\;\\hat\\alpha_1=\\beta_1+\\beta_2\\,\\frac{\\mathrm{Cov}(X_1,X_2)}{\\mathrm{Var}(X_1)}\\;}.\n\\]\nBias (in media):\n\\[\n\\boxed{\\;\\mathbb{E}[\\hat\\alpha_1]-\\beta_1\n=\\beta_2\\,\\frac{\\mathrm{Cov}(X_1,X_2)}{\\mathrm{Var}(X_1)}\\;}\n\\quad\\Longleftrightarrow\\quad\n\\boxed{\\;\\mathbb{E}[\\hat\\delta_1]-\\gamma_1=\\gamma_2\\rho_{12}\\;}.\n\\]\n\n62.1.4 Interpretazione didattica\n\n\nCondizioni per il bias: serve sia \\(\\beta_2\\neq 0\\) (l’omessa \\(X_2\\) conta davvero su \\(Y\\)) sia \\(\\rho_{12}\\neq 0\\) (l’omessa \\(X_2\\) è correlata con \\(X_1\\)). Se una condizione manca, il bias svanisce.\n\nSegno del bias (scala standardizzata): \\(\\mathrm{Bias}(\\hat\\delta_1)=\\gamma_2\\rho_{12}\\).\n\n\n\\(\\gamma_2&gt;0\\) e \\(\\rho_{12}&gt;0\\) ⇒ sovrastima;\n\n\\(\\gamma_2&gt;0\\) e \\(\\rho_{12}&lt;0\\) ⇒ sottostima.\n\n\n\n62.1.5 Perché conta in psicologia\nLa regressione multipla è un modello fenomenologico: fotografa associazioni tra variabili, non i meccanismi che le generano. In contesti psicologici, l’omissione di variabili rilevanti è spesso inevitabile: non conosciamo o non misuriamo tutti i determinanti di \\(Y\\). Ne segue che i coefficienti parziali possono essere sistematicamente distorti e, dunque, fuorvianti.\n\n62.1.6 Oltre la regressione: modelli formali dei processi\nPer queste ragioni, i modelli di regressione multipla dovrebbero avere un ruolo limitato in psicologia. Molto più promettente è l’uso di modelli formali che cercano di rappresentare i meccanismi psicologici sottostanti. Esempi discussi in questa dispensa sono:\n\nil modello di apprendimento di Rescorla–Wagner, che spiega come gli individui aggiornano le loro aspettative sulla base del feedback;\n\nil Drift Diffusion Model (DDM), che descrive i processi decisionali come un accumulo di evidenza nel tempo;\n\ni modelli dinamici per dati EMA, che mostrano come l’umore e altre variabili psicologiche cambiano nel tempo.\n\nQuesti modelli non si limitano a descrivere correlazioni, ma cercano di catturare i processi causali che generano i dati osservati.\n\n\n\n\n\n\nMappa del bias: variazione di \\(\\rho_{12}\\) e \\(\\beta_2\\)\n\n\n\n\n\nEsaminiamo come segno e magnitudo del bias cambino al variare della correlazione tra regressori (\\(\\rho_{12}\\)) e dell’effetto dell’omessa (\\(\\beta_2\\)). La heatmap visualizza \\(\\hat\\alpha_1-\\beta_1\\).\n\nset.seed(1)\nn &lt;- 3000; beta1 &lt;- 1; sig &lt;- 1\nrho_seq &lt;- seq(-.9,.9,length=19); b2_seq &lt;- seq(-1.5,1.5,length=19)\n\ngrid &lt;- expand.grid(rho=rho_seq, b2=b2_seq)\n\nsim_once &lt;- function(rho, beta2){\n  X1 &lt;- rnorm(n)\n  X2 &lt;- rho*X1 + sqrt(1-rho^2)*rnorm(n)   # Corr(X1,X2)=rho\n  Y  &lt;- beta1*X1 + beta2*X2 + rnorm(n,0,sig)\n  coef(lm(Y ~ X1))[2] - beta1             # ritorna uno scalare, senza nome\n}\n\ngrid$bias &lt;- mapply(sim_once, grid$rho, grid$b2)  # &lt;-- niente t(), niente [, \"bias\"]\n\nggplot(grid, aes(x=rho, y=b2, fill=bias)) +\n  geom_tile() + scale_fill_gradient2() +\n  labs(x=expression(rho[12]), y=expression(beta[2]), fill=\"Bias\",\n       title=\"Bias da variabile omessa al variare di ρ12 e β2\")\n\n\n\n\n\n\n\nCommento e interpretazione. L’asse orizzontale riporta la correlazione tra i regressori \\(\\rho_{12}=\\mathrm{Corr}(X_1,X_2)\\); l’asse verticale l’effetto dell’omessa \\(X_2\\) su \\(Y\\) (\\(\\beta_2\\)). Il riempimento (“Bias”) è \\(\\hat\\alpha_1-\\beta_1\\), cioè di quanto il coefficiente sul regressore incluso \\(X_1\\) sovrastima (valori &gt; 0) o sottostima (valori &lt; 0) il suo valore vero.\n\n\nSegno del bias. Il bias è (in media) \\(\\beta_2\\,\\rho_{12}\\). Quadranti:\n\n\n\\(\\beta_2&gt;0,\\ \\rho_{12}&gt;0\\) → positivo (sovrastima);\n\n\\(\\beta_2&gt;0,\\ \\rho_{12}&lt;0\\) → negativo (sottostima);\n\n\\(\\beta_2&lt;0,\\ \\rho_{12}&gt;0\\) → negativo;\n\n\\(\\beta_2&lt;0,\\ \\rho_{12}&lt;0\\) → positivo.\n\nLe bande di colore cambiano segno attraversando le linee \\(\\rho_{12}=0\\) o \\(\\beta_2=0\\), dove il bias si annulla (zona chiara).\n\nMagnitudo. Aumenta con \\(|\\beta_2|\\) e \\(|\\rho_{12}|\\): gli angoli (|ρ|≈0.9, |β₂|≈1.5) mostrano i bias maggiori. La diagonale basso-sinistra → alto-destra evidenzia bias positivo; l’altra diagonale bias negativo.\nSimmetria e teoria. La mappa è sostanzialmente simmetrica perché il bias teorico è \\(\\beta_2\\rho_{12}\\). Le piccole irregolarità dipendono dal rumore Monte Carlo della simulazione (con \\(n\\) finito).\nLettura pratica. Se anche solo una tra correlazione tra regressori (\\(\\rho_{12}\\)) o effetto dell’omessa (\\(\\beta_2\\)) è prossima a zero, il bias è trascurabile (aree chiare lungo gli assi). Quando entrambi sono lontani da zero, l’OLS nel modello omesso è fuorviante.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Errore di specificazione e bias da variabile omessa</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_specification_error.html#riflessioni-conclusive",
    "href": "chapters/linear_models/06_specification_error.html#riflessioni-conclusive",
    "title": "62  Errore di specificazione e bias da variabile omessa",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nL’errore di specificazione, e in particolare il bias da variabile omessa, ci ricorda che la regressione multipla non può essere considerata uno strumento neutro e affidabile per spiegare i fenomeni psicologici. Il suo valore è limitato a descrivere associazioni, ma il rischio di distorsione è sempre presente. Per costruire conoscenza solida, la psicologia deve andare oltre i modelli fenomenologici e puntare a modelli meccanicistici e computazionali, capaci di rappresentare i processi che danno origine ai dati (McElreath, 2020).\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        rmarkdown_2.29        ps_1.9.1             \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [28] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [31] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           mvtnorm_1.3-3        \n#&gt; [64] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [67] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [70] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [73] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [76] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [79] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Errore di specificazione e bias da variabile omessa</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_specification_error.html#bibliografia",
    "href": "chapters/linear_models/06_specification_error.html#bibliografia",
    "title": "62  Errore di specificazione e bias da variabile omessa",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nRamsey, J. B. (1969). Tests for specification errors in classical linear least-squares regression analysis. Journal of the Royal Statistical Society Series B: Statistical Methodology, 31(2), 350–371.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Errore di specificazione e bias da variabile omessa</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html",
    "href": "chapters/linear_models/07_one_mean.html",
    "title": "63  Inferenza bayesiana su una media",
    "section": "",
    "text": "Introduzione\nIn questo capitolo ci occuperemo di un tema classico in statistica: come inferire la media di una popolazione a partire da un campione di dati quantitativi. Si tratta di una situazione che incontriamo spesso in psicologia, ad esempio quando vogliamo stimare l’altezza media, il livello medio di ansia, o la soddisfazione media in un certo gruppo di persone. Tuttavia, anziché affrontare questo problema nel modo tradizionale, qui lo considereremo da una prospettiva più ampia e moderna, che mette al centro due concetti fondamentali per la psicologia scientifica: variabilità e incertezza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#introduzione",
    "href": "chapters/linear_models/07_one_mean.html#introduzione",
    "title": "63  Inferenza bayesiana su una media",
    "section": "",
    "text": "Panoramica del capitolo\n\nCome fare inferenza sulla media di un campione.\nCome trovare le distribuzioni a posteriori usando brms.\nVerificare il modello usando i pp-check plots.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Geocentric models di Statistical rethinking (McElreath, 2020).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, ggdist)\n\nconflicts_prefer(stats::sd)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#la-variabilità-come-punto-di-partenza",
    "href": "chapters/linear_models/07_one_mean.html#la-variabilità-come-punto-di-partenza",
    "title": "63  Inferenza bayesiana su una media",
    "section": "\n63.1 La variabilità come punto di partenza",
    "text": "63.1 La variabilità come punto di partenza\nOgni volta che raccogliamo dati psicologici, ci confrontiamo inevitabilmente con la variabilità. Alcune differenze sono tra individui:\nVariabilità inter-individuale: ad esempio, quanto differiscono tra loro le altezze, i tempi di reazione o i livelli di benessere soggettivo?\nAltre differenze sono all’interno dello stesso individuo, anche se meno visibili in un singolo rilevamento:\nVariabilità intra-individuale: quanto potrebbe variare la risposta della stessa persona se la misurassimo in momenti diversi della giornata, o in giorni diversi? Anche quando non la osserviamo direttamente, la variabilità intra-individuale è sempre una componente latente del dato psicologico, e ci invita a riflettere sulle fonti di instabilità e fluttuazione nei comportamenti e negli stati mentali.\n\n63.1.1 L’incertezza come oggetto dell’inferenza\nA partire da questa variabilità, vogliamo formulare inferenze sul valore medio di un certo parametro (come l’altezza media in una popolazione). Ma ogni inferenza è anche un atto di stima incerta: nessun campione ci dà la verità, ma solo una gamma di possibilità più o meno plausibili.\nIn questo capitolo affronteremo quindi il problema dell’inferenza sulla media da due prospettive complementari:\n\n\nApproccio frequentista: basato sull’idea di ripetizione del campionamento e sul calcolo di un intervallo di confidenza;\n\nApproccio bayesiano: che assume esplicitamente l’incertezza e la rappresenta attraverso una distribuzione di probabilità (la distribuzione a posteriori).\n\n63.1.2 Perché usare brms?\nInvece di derivare la distribuzione a posteriori della media in modo analitico (come nei modelli con prior coniugati), useremo il pacchetto brms, che si basa su un potente algoritmo di campionamento chiamato NUTS (No-U-Turn Sampler). Questo ci permetterà di stimare numericamente l’intera distribuzione a posteriori della media e della variabilità, anche in casi in cui il calcolo analitico sarebbe difficile o impossibile. In questo modo, potremo:\n\nquantificare l’incertezza su ciò che ci interessa (ad esempio: qual è l’altezza media? con quanta certezza lo possiamo dire?);\nvisualizzare in modo intuitivo l’effetto dei dati e dei priori sulle nostre stime;\navvicinarci a un modo di pensare statistico più adatto alla complessità della psicologia, dove ogni dato è il risultato di molte fonti di variabilità.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#il-modello-normale-un-primo-passo-nella-descrizione-della-variabilità",
    "href": "chapters/linear_models/07_one_mean.html#il-modello-normale-un-primo-passo-nella-descrizione-della-variabilità",
    "title": "63  Inferenza bayesiana su una media",
    "section": "\n63.2 Il modello Normale: un primo passo nella descrizione della variabilità",
    "text": "63.2 Il modello Normale: un primo passo nella descrizione della variabilità\nQuando parliamo di altezza, ansia, tempo di reazione o qualsiasi altra variabile psicologica continua, un punto di partenza comune è il modello Normale. Questo modello assume che le osservazioni siano distribuite attorno a un valore medio, con una certa dispersione. In termini formali, diciamo che ogni osservazione \\(y_n\\) è generata da una distribuzione Normale con media \\(\\mu\\) e deviazione standard \\(\\sigma\\):\n\\[\ny_n \\;\\sim\\; \\mathcal N\\bigl(\\mu, \\sigma\\bigr).\n\\]\nNel linguaggio dell’inferenza, \\(\\mu\\) rappresenta il valore centrale che vogliamo stimare, mentre \\(\\sigma\\) quantifica la variabilità delle osservazioni rispetto a quel centro. Entrambi i parametri sono ignoti, e l’obiettivo dell’inferenza è proprio descrivere l’incertezza che abbiamo su di essi.\nNel capitolo precedente abbiamo visto come calcolare la distribuzione a posteriori di questi parametri in modo analitico, quando si utilizzano prior coniugati. In questo capitolo, invece, riprendiamo lo stesso problema, ma adottiamo un approccio più generale e flessibile: stimiamo il modello usando il pacchetto brms, che utilizza metodi MCMC per approssimare la distribuzione a posteriori, anche quando non esistono soluzioni chiuse.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#un-esempio-concreto-la-variabilità-dellaltezza-nei-kung-san",
    "href": "chapters/linear_models/07_one_mean.html#un-esempio-concreto-la-variabilità-dellaltezza-nei-kung-san",
    "title": "63  Inferenza bayesiana su una media",
    "section": "\n63.3 Un esempio concreto: la variabilità dell’altezza nei !Kung San",
    "text": "63.3 Un esempio concreto: la variabilità dell’altezza nei !Kung San\nPer rendere più concreto il problema, useremo un dataset storico: i dati raccolti da Nancy Howell tra la fine degli anni ’60 presso i !Kung San, una popolazione del deserto del Kalahari con uno stile di vita basato su caccia e raccolta.\nI dati che utilizzeremo riportano le altezze di individui adulti (con età superiore ai 18 anni). Questo esempio è tratto da McElreath (2020), ed è ideale per iniziare a riflettere sulla variabilità inter-individuale.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\ndf |&gt; head()\n#&gt;   height weight age male\n#&gt; 1    152   47.8  63    1\n#&gt; 2    140   36.5  63    0\n#&gt; 3    137   31.9  65    0\n#&gt; 4    157   53.0  41    1\n#&gt; 5    145   41.3  51    0\n#&gt; 6    164   63.0  35    1\n\nIl campione è composto da 352 osservazioni:\n\nlength(df$height)\n#&gt; [1] 352\n\n\n63.3.1 Distribuzione osservata dell’altezza\nUna prima esplorazione visiva ci aiuta a capire la forma della distribuzione osservata. L’istogramma seguente mostra come si distribuiscono le altezze nel campione:\n\nggplot(df, aes(x = height)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"Altezza\", y = \"Frequenza\") \n\n\n\n\n\n\n\nLa forma appare compatibile con una distribuzione Normale. Ma quanto bene si adatta?\n\ndf |&gt;\n  ggplot(aes(sample = height)) +\n  stat_qq() +\n  stat_qq_line(colour = \"red\") +\n  labs(x = \"Quantili teorici\", y = \"Valori osservati\") \n\n\n\n\n\n\n\nIl Q-Q plot mostra un leggero scostamento: la curva empirica è un po’ più piatta rispetto alla linea teorica, segno che la variabilità osservata è leggermente inferiore a quella attesa da una Normale standard (code meno pesanti). Tuttavia, la discrepanza è modesta, e possiamo comunque usare il modello gaussiano come prima approssimazione della distribuzione dei dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#specifica-del-modello-una-distribuzione-per-descrivere-lincertezza",
    "href": "chapters/linear_models/07_one_mean.html#specifica-del-modello-una-distribuzione-per-descrivere-lincertezza",
    "title": "63  Inferenza bayesiana su una media",
    "section": "\n63.4 Specifica del modello: una distribuzione per descrivere l’incertezza",
    "text": "63.4 Specifica del modello: una distribuzione per descrivere l’incertezza\nNel modello bayesiano, ipotizziamo che ogni osservazione \\(y_n\\) sia indipendente e identicamente distribuita (iid):\n\\[\ny_n \\sim \\mathcal N(\\mu, \\sigma),\n\\]\n\n\n\\(\\mu\\): la media vera (ignota) della popolazione.\n\n\\(\\sigma\\): la deviazione standard vera, che misura quanta variabilità c’è tra gli individui.\n\n\nL’assunzione di indipendenza implica che conoscere l’errore commesso su un individuo non ci dice nulla sull’errore commesso su un altro. L’assunzione di identica distribuzione implica che tutti gli individui provengano dalla stessa popolazione.\n\nScrivere \\(y_n \\sim \\mathcal N(\\mu, \\sigma)\\) è quindi un modo compatto per dire che ogni osservazione è un’espressione della variabilità inter-individuale, distribuita attorno a un valore centrale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#stime-preliminari-una-fotografia-della-variabilità",
    "href": "chapters/linear_models/07_one_mean.html#stime-preliminari-una-fotografia-della-variabilità",
    "title": "63  Inferenza bayesiana su una media",
    "section": "\n63.5 Stime preliminari: una fotografia della variabilità",
    "text": "63.5 Stime preliminari: una fotografia della variabilità\nPrima di definire i priori o stimare la distribuzione a posteriori, è utile esplorare alcune statistiche descrittive:\n\nmean(df$height)   # media campionaria\n#&gt; [1] 155\nsd(df$height)     # deviazione standard campionaria\n#&gt; [1] 7.74\n\nQueste due quantità ci offrono una prima “fotografia” della variabilità nel campione:\n\nLa media campionaria è una stima iniziale di \\(\\mu\\), che potrà guidarci nella scelta di una prior realistica.\nLa deviazione standard campionaria è una misura iniziale di \\(\\sigma\\), e descrive quanto le osservazioni si discostano, in media, dalla media.\n\nAnche se queste statistiche non riflettono ancora in modo completo l’incertezza che abbiamo, sono molto utili per:\n\n\nGuidare la scelta dei priors in un’ottica informata;\n\nIndividuare possibili outlier o anomalie, che potrebbero influenzare sia l’inferenza frequentista sia quella bayesiana.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#il-modello-frequentista-stimare-la-media-come-punto-fisso",
    "href": "chapters/linear_models/07_one_mean.html#il-modello-frequentista-stimare-la-media-come-punto-fisso",
    "title": "63  Inferenza bayesiana su una media",
    "section": "\n63.6 Il modello frequentista: stimare la media come punto fisso",
    "text": "63.6 Il modello frequentista: stimare la media come punto fisso\nNel contesto dell’inferenza classica, uno dei modi più semplici per stimare la media di una popolazione consiste nell’adottare un modello lineare senza predittori: un modello che si limita a stimare un’unica quantità, chiamata intercetta. In pratica, questo corrisponde a stimare la media campionaria dei dati osservati.\nIn R, questo modello si specifica in modo molto compatto:\nheight ~ 1\nIl simbolo 1 indica che vogliamo stimare solo l’intercetta, senza nessuna variabile esplicativa. In termini pratici, l’intercetta rappresenta qui la media dell’altezza nel campione.\n\n63.6.1 Specifica e stima del modello\nPossiamo stimare il modello con la funzione lm():\n\nfm1 &lt;- lm(\n  formula = height ~ 1, \n  data = df\n)\n\nQuesto comando applica il metodo della minima somma dei quadrati, producendo una stima puntuale della media, assieme a una misura della sua variabilità.\n\n63.6.2 Interpretare i risultati\nL’output del modello si ottiene con:\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = height ~ 1, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -18.072  -6.007  -0.292   6.058  24.473 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  154.597      0.413     375   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 7.74 on 351 degrees of freedom\n\nIl riassunto mostra diverse informazioni, ma le più rilevanti in questo contesto sono:\n\n\nLa stima dell’intercetta \\(\\hat{\\alpha}\\): coincide con la media campionaria delle altezze.\n\nL’errore standard: misura la variabilità attesa della stima \\(\\hat{\\alpha}\\) se ripetessimo il campionamento molte volte.\n\nIl p-value: quantifica la probabilità di osservare un valore della statistica test così estremo (o più) se la media vera fosse 0. In questo caso ha scarso interesse pratico, perché il valore di riferimento (0 cm) non è plausibile.\n\nIl R²: che in assenza di predittori non è interpretabile in modo utile.\n\n63.6.3 Intervallo di confidenza al 95%: una misura indiretta dell’incertezza\nIl modello frequentista non descrive la nostra incertezza come una distribuzione su \\(\\mu\\), ma fornisce invece un intervallo di confidenza, che ha un’interpretazione indiretta: se ripetessimo l’esperimento un numero molto elevato di volte, in circa il 95% dei casi l’intervallo conterrebbe il vero valore della media.\nPossiamo calcolarlo con:\n\nconfint(fm1, level = 0.95)\n#&gt;             2.5 % 97.5 %\n#&gt; (Intercept)   154    155\n\nQuesto intervallo si basa sulla formula classica:\n\\[\n\\hat{\\alpha} \\pm t_{\\text{df}} \\cdot \\text{SE}(\\hat{\\alpha})\n\\]\ndove:\n\n\n\\(\\hat{\\alpha}\\) è la stima puntuale della media,\n\n\\(t_{\\text{df}}\\) è il quantile della distribuzione t di Student (con \\(n - 1\\) gradi di libertà),\n\n\\(\\text{SE}(\\hat{\\alpha})\\) è l’errore standard della stima.\n\n63.6.4 Calcolo manuale (opzionale)\nSe vogliamo calcolare l’intervallo “a mano”, possiamo scrivere:\n\ncoef(fm1) + c(-1, 1) * qt(0.975, df.residual(fm1)) * 0.413\n#&gt; [1] 154 155\n\n\n\ncoef(fm1) restituisce la stima dell’intercetta,\n\nqt(0.975, df.residual(fm1)) fornisce il valore critico t,\n\n0.413 è l’errore standard (da sostituire con quello esatto, se disponibile).\n\n63.6.5 Riflessione: cos’è l’incertezza, per davvero?\nNel modello frequentista, l’incertezza sulla media è descritta in termini di variabilità potenziale tra campioni, non come incertezza su un valore specifico. Il parametro \\(\\mu\\) è trattato come fisso ma ignoto, e tutta l’incertezza risiede nella stima che otteniamo da un singolo campione.\nIn questo senso, l’approccio frequentista non fornisce una distribuzione sul parametro: non possiamo dire “la probabilità che la media sia tra 153 e 155 cm è del 95%”, ma solo che “se ripetessimo l’esperimento molte volte, l’intervallo conterrebbe la media vera nel 95% dei casi”.\nNel prossimo paragrafo vedremo come un modello bayesiano offra un’alternativa: trattare \\(\\mu\\) come una variabile aleatoria su cui esprimere direttamente l’incertezza, permettendoci di formulare affermazioni probabilistiche esplicite sui valori possibili del parametro.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#il-modello-bayesiano-descrivere-lincertezza-con-distribuzioni",
    "href": "chapters/linear_models/07_one_mean.html#il-modello-bayesiano-descrivere-lincertezza-con-distribuzioni",
    "title": "63  Inferenza bayesiana su una media",
    "section": "\n63.7 Il modello Bayesiano: descrivere l’incertezza con distribuzioni",
    "text": "63.7 Il modello Bayesiano: descrivere l’incertezza con distribuzioni\nDopo aver stimato la media dell’altezza con il modello frequentista, possiamo affrontare lo stesso problema con un approccio bayesiano, usando il pacchetto brms. Questo ci consente di rappresentare in modo più diretto l’incertezza che abbiamo sui parametri del modello.\nNel framework bayesiano, tutti i parametri sono trattati come variabili aleatorie: invece di stimare un singolo valore per la media, stimiamo una distribuzione a posteriori, che riflette l’incertezza residua dopo aver osservato i dati.\n\n63.7.1 Priori debolmente informativi: quando “non sappiamo molto”\nOgni modello bayesiano richiede la specifica di distribuzioni a priori. Tuttavia, quando non abbiamo conoscenze forti da inserire, possiamo affidarci ai priori debolmente informativi: distribuzioni ampie, generiche e poco vincolanti, che permettono ai dati di “parlare da soli”.\nSe non specifichiamo nulla, brms userà questi prior di default. È un buon punto di partenza, soprattutto per modelli semplici e dataset abbastanza ricchi.\n\n63.7.2 Specifica del modello in brms\n\nIl codice è simile a quello usato con lm():\n\nfm2 &lt;- brm(\n  formula = height ~ 1,       # stima solo l'intercetta (media dell’altezza)\n  family = gaussian(),        # assunzione di distribuzione normale\n  data = df,                  # dataset\n  chains = 4,                 # numero di catene MCMC\n  iter = 2000,                # iterazioni per catena\n  warmup = 1000,              # periodo di adattamento\n  backend = \"cmdstanr\"        # motore di calcolo efficiente\n)\n\nQui stiamo stimando due parametri:\n\n\n\\(\\mu\\) → media dell’altezza nella popolazione;\n\n\\(\\sigma\\) → deviazione standard, che rappresenta quanta variabilità inter-individuale osserviamo.\n\nIn termini formali, il modello è scritto come:\n\\[\ny_i = \\alpha + \\varepsilon_i,\\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma).\n\\]\n\n63.7.3 Interpretare l’output: incertezza esplicitata\nUna volta che il modello è stato stimato, possiamo esaminarne l’output:\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.58      0.41   153.76   155.37 1.00     3354     2311\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.75      0.30     7.19     8.35 1.00     4064     2906\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nNel risultato troveremo:\n\n\nMedia della distribuzione a posteriori per \\(\\alpha\\), che è la stima centrale di \\(\\mu\\);\n\nErrore standard a posteriori, cioè quanto fluttua \\(\\mu\\) nei campioni simulati;\n\nIntervallo di credibilità al 95%: l’intervallo in cui cade il 95% della distribuzione a posteriori di \\(\\mu\\).\n\nA differenza dell’intervallo di confidenza frequentista, qui possiamo davvero dire:\n\nC’è il 95% di probabilità che la media dell’altezza si trovi in questo intervallo, dati il modello e i dati osservati.\n\n\n63.7.4 Riportare i risultati: due linguaggi per lo stesso fenomeno\n\n\n\n\n\n\nApproccio\nRisultato\n\n\n\nFrequentista\n“La media stimata è 154.6, con un intervallo di confidenza al 95% tra 153.8 e 155.4.”\n\n\nBayesiano\n“La media stimata a posteriori è 154.6, con un intervallo di credibilità al 95% tra 153.8 e 155.4.”\n\n\n\nNumericamente possono coincidere, ma la logica inferenziale è diversa: nel caso bayesiano, l’intervallo descrive ciò che crediamo plausibile; nel frequentista, ciò che la procedura catturerebbe nella maggior parte dei campioni ripetuti.\n\n63.7.5 Esplorare i campioni a posteriori: guardare l’incertezza in faccia\nDopo aver stimato il modello, possiamo accedere direttamente ai campioni generati dall’algoritmo NUTS:\n\nas_draws_df(fm2) %&gt;% head(3)\n#&gt; # A draws_df: 3 iterations, 1 chains, and 5 variables\n#&gt;   b_Intercept sigma Intercept lprior  lp__\n#&gt; 1         154   7.9       154   -6.1 -1224\n#&gt; 2         154   7.5       154   -6.1 -1224\n#&gt; 3         155   7.7       155   -6.1 -1224\n#&gt; # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\nOgni riga della colonna b_Intercept rappresenta un valore plausibile per \\(\\mu\\), estratto dalla sua distribuzione a posteriori. Questi campioni sono il cuore dell’inferenza bayesiana: ci permettono di costruire grafici, intervalli e ragionamenti probabilistici.\n\n63.7.6 Calcoli riassuntivi sui campioni\nPossiamo usare i campioni per calcolare:\n\n# Media a posteriori\nmean(as_draws_df(fm2)$b_Intercept)\n#&gt; [1] 155\n\n# Deviazione standard a posteriori\nsd(as_draws_df(fm2)$b_Intercept)\n#&gt; [1] 0.409\n\n# Intervallo di credibilità al 95%\nquantile(as_draws_df(fm2)$b_Intercept, probs = c(0.025, 0.975))\n#&gt;  2.5% 97.5% \n#&gt;   154   155\n\n\nQuesti valori sintetizzano l’incertezza associata alla nostra stima della media: non un singolo punto, ma una nuvola di possibilità, tutte compatibili con i dati osservati.\n\n\n63.7.7 Conclusioni intermedie\nAbbiamo visto come:\n\nL’approccio frequentista fornisca una stima puntuale e un intervallo ipotetico di copertura.\nL’approccio bayesiano fornisca una distribuzione completa a posteriori, da cui possiamo derivare medie, intervalli, probabilità e visualizzazioni.\n\nEntrambi gli approcci descrivono la variabilità tra individui, ma il metodo bayesiano offre strumenti più trasparenti per rappresentare l’incertezza sui parametri.\n\nQuesto è particolarmente utile in psicologia, dove campioni ridotti, contesti variabili e differenze individuali richiedono modelli che sappiano dire “quanto (non) sappiamo”.\n\nNel prossimo paragrafo vedremo come possiamo personalizzare i priori, incorporando informazioni pregresse (da studi precedenti, teoria, esperienza clinica…), e come questo possa influenzare l’inferenza nei casi in cui i dati da soli non siano sufficientemente informativi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#uso-dei-prior-nel-modello-bayesiano-rendere-esplicite-le-ipotesi-sullincertezza",
    "href": "chapters/linear_models/07_one_mean.html#uso-dei-prior-nel-modello-bayesiano-rendere-esplicite-le-ipotesi-sullincertezza",
    "title": "63  Inferenza bayesiana su una media",
    "section": "\n63.8 Uso dei Prior nel Modello Bayesiano: rendere esplicite le ipotesi sull’incertezza",
    "text": "63.8 Uso dei Prior nel Modello Bayesiano: rendere esplicite le ipotesi sull’incertezza\nFinora abbiamo visto che è possibile stimare un modello bayesiano anche senza specificare esplicitamente i prior: in tal caso, brms utilizza prior debolmente informativi, lasciando che siano i dati a guidare l’inferenza.\nMa il cuore dell’approccio bayesiano sta proprio qui: nella possibilità di incorporare conoscenze precedenti, aspettative, risultati di studi precedenti — insomma, di modellare in modo esplicito e trasparente l’incertezza che abbiamo prima di vedere i dati.\n\n63.8.1 Tre domande chiave prima di stimare\nPrima di usare un modello bayesiano, è utile porsi alcune domande fondamentali:\n\nCosa sappiamo già del fenomeno?\nCome possiamo esprimere questa conoscenza sotto forma di distribuzioni?\nQuanto vogliamo che questa conoscenza influenzi l’inferenza?\n\nLa risposta a queste domande guida la scelta dei prior. Nei passaggi che seguono, vedremo come un modello informato da prior realistici possa non solo migliorare la stima, ma anche aumentare la coerenza tra teoria e dati.\n\n63.8.2 Specificare i prior: un esempio concreto\nRiprendiamo il nostro esempio sull’altezza nella popolazione dei !Kung San. Supponiamo di avere un’idea ragionevole su quanto potrebbe essere la media e la variabilità delle altezze.\nPossiamo tradurre questa conoscenza nel linguaggio delle distribuzioni:\n\nPer \\(\\mu\\) (la media), ipotizziamo: \\(\\mu \\sim \\mathcal{N}(181, 30)\\) — una media attesa intorno a 181 cm, con ampio margine di incertezza.\nPer \\(\\sigma\\) (la deviazione standard), ipotizziamo: \\(\\sigma \\sim \\mathcal{N}^+(0, 20)\\) — una normale troncata a destra, che garantisce valori positivi.\n\nQuesti prior sono informativi ma ampi: riflettono aspettative plausibili, senza imporre vincoli troppo rigidi.\n\nMcElreath scherza dicendo di usare come prior la propria altezza. L’ironia nasconde un principio importante: ogni ipotesi è valida, purché dichiarata. Un buon modello bayesiano non finge oggettività, ma esplicita l’incertezza iniziale.\n\n\n63.8.3 Forma del modello con prior espliciti\nIl modello completo si scrive così:\n\\[\n\\begin{aligned}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\\\\\\\\n\\mu &\\sim \\mathcal{N}(181,\\ 30) \\\\\\\\\n\\sigma &\\sim \\mathcal{N}^+(0,\\ 20)\n\\end{aligned}\n\\]\nQui, sia la media sia la variabilità della popolazione sono trattate come quantità soggette a incertezza. La stima diventa un aggiornamento: partiamo da un’opinione iniziale e la modifichiamo alla luce dei dati.\n\n63.8.4 Implementazione in brms\n\n\nfm3 &lt;- brm(\n  formula = height ~ 1,\n  data    = df,\n  family  = gaussian(),\n  prior   = c(\n    prior(normal(181, 30), class = \"Intercept\"),\n    prior(normal(0, 20), class = \"sigma\")\n  ),\n  chains  = 4, iter = 2000,\n  seed    = 1234,\n  backend = \"cmdstanr\"\n)\n\n\n63.8.5 Analisi dell’output\nUna volta stimato il modello, possiamo esaminarlo come sempre con:\n\nsummary(fm3)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.80   155.41 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.20     8.38 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nSe i dati sono informativi (come in questo caso), l’effetto dei prior sarà contenuto: la distribuzione a posteriori sarà molto simile a quella ottenuta con prior deboli. Questo è un comportamento desiderabile: il prior non deve forzare i risultati, ma integrarsi con essi.\n\n63.8.6 Scegliere il livello dell’intervallo di credibilità\nPossiamo modificare la probabilità coperta dall’intervallo credibile, ad esempio scegliendo un intervallo all’89% anziché al 95%:\n\nsummary(fm3, prob = 0.89)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.94   155.27 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.32     8.25 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nQuesta scelta è proposta da McElreath come default per motivi pedagogici: evitare che l’intervallo venga interpretato come test di significatività.\n\n“Why 89%? Because it’s prime.” — è un invito a pensare criticamente alle convenzioni statistiche, e a riflettere su cosa stiamo cercando davvero di comunicare quando riportiamo un intervallo.\n\n\n63.8.7 Cosa otteniamo con prior espliciti?\nUsare prior informativi consente di:\n\nIncorporare conoscenze teoriche, esperienze passate, dati precedenti.\nRendere il modello più robusto quando i dati sono scarsi o rumorosi.\nEvitare stime irrealistiche in contesti con alta incertezza.\nEsplicitare le nostre ipotesi, invece di nasconderle dietro un’apparente neutralità.\n\n63.8.8 Conclusione\nIn un modello bayesiano, ogni assunzione è chiara e trattabile. I risultati non sono semplici numeri, ma distribuzioni di credibilità che raccontano ciò che è plausibile, dato ciò che sapevamo prima e ciò che abbiamo osservato ora.\n\nQuesto rende l’approccio bayesiano particolarmente adatto alla psicologia: un campo dove l’incertezza è la norma, la variabilità è parte del fenomeno da spiegare, e la trasparenza delle assunzioni è fondamentale.\n\nNel prossimo paragrafo, ci concentreremo su come visualizzare e valutare queste distribuzioni a posteriori, usando strumenti diagnostici e grafici che ci aiutano a comprendere — e comunicare — la variabilità residua stimata dal modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#visualizzare-lincertezza-con-bayesplot",
    "href": "chapters/linear_models/07_one_mean.html#visualizzare-lincertezza-con-bayesplot",
    "title": "63  Inferenza bayesiana su una media",
    "section": "\n63.9 Visualizzare l’incertezza con bayesplot\n",
    "text": "63.9 Visualizzare l’incertezza con bayesplot\n\nIl pacchetto bayesplot è uno strumento prezioso per ogni analisi bayesiana: permette di esplorare visivamente la variabilità delle stime a posteriori, di diagnosticare l’efficienza del campionamento MCMC e di verificare se il modello riesce a riprodurre i dati osservati.\nIn un contesto psicologico, dove spesso i dati sono rumorosi e le inferenze complesse, poter visualizzare dove e quanto il modello è incerto è fondamentale.\n\n63.9.1 Traceplot: osservare le catene in azione\nIl traceplot mostra l’evoluzione dei campioni per ogni parametro nel corso delle iterazioni MCMC. Serve a controllare:\n\nche le catene siano stazionarie (nessuna deriva sistematica),\nche si mescolino bene (assenza di autocorrelazione),\nche ci sia convergenza (tutte le catene esplorano la stessa distribuzione).\n\n\nmcmc_trace(fm3, pars = c(\"Intercept\", \"sigma\"), facet_args = list(nrow = 2))\n\n\n\n\n\n\n\nUn buon traceplot mostra bande dense, senza tendenze crescenti o oscillazioni lente: questo suggerisce che il campionamento stia catturando in modo affidabile la distribuzione a posteriori.\n\n63.9.2 Densità a posteriori: cosa crediamo dopo aver visto i dati\nPer visualizzare la distribuzione di probabilità di un parametro stimato, possiamo usare:\n\nmcmc_areas(fm3, regex_pars = \"b_Intercept\", prob = 0.89)\n\n\n\n\n\n\n\nQuesta funzione evidenzia l’intervallo credibile in cui cade, ad esempio, l’89% della densità a posteriori per la media dell’altezza.\n\nA differenza dell’intervallo di confidenza, qui possiamo davvero dire che c’è l’89% di probabilità che la media vera sia compresa in quell’intervallo.\n\n\n63.9.3 Distribuzione congiunta di due parametri: incrociare incertezze\nQuando vogliamo esplorare la relazione tra due parametri (ad esempio, media e deviazione standard), possiamo usare:\n\nmcmc_scatter(fm3, pars = c(\"Intercept\", \"sigma\"))\n\n\n\n\n\n\n\nQuesto tipo di visualizzazione è utile per valutare dipendenze tra parametri: ad esempio, se i campioni sono inclinati lungo una diagonale, significa che c’è correlazione a posteriori tra i due.\n\n63.9.4 Posterior Predictive Check: il modello spiega davvero i dati?\nUna delle forze dell’approccio bayesiano è che i modelli sono generativi: possiamo simulare nuovi dati partendo dalle distribuzioni a posteriori e confrontarli con quelli osservati.\n\npp_check(fm3)\n\n\n\n\n\n\n\nLa funzione pp_check() mostra:\n\nin nero: la distribuzione dei dati osservati,\nin colore: più repliche simulate dal modello.\n\nSe le simulazioni coprono bene i dati reali, il modello è coerente con le osservazioni. Se invece ci sono scostamenti sistematici, questo può indicare che:\n\nla distribuzione scelta non è adatta,\nci sono outlier non gestiti,\nmancano variabili esplicative nel modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#lapproccio-tradizionale-il-test-t-di-student",
    "href": "chapters/linear_models/07_one_mean.html#lapproccio-tradizionale-il-test-t-di-student",
    "title": "63  Inferenza bayesiana su una media",
    "section": "\n63.10 L’approccio tradizionale: il test t di Student",
    "text": "63.10 L’approccio tradizionale: il test t di Student\nPrima dell’adozione diffusa dei metodi bayesiani, l’inferenza sulla media veniva solitamente effettuata con il test t. Questo approccio assume che la variabilità osservata nel campione (stimata con la deviazione standard campionaria) sia sufficiente a rappresentare l’incertezza sul parametro d’interesse.\nIl calcolo si basa sulla statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}}.\n\\]\nIl test permette di costruire un intervallo di confidenza, ma non di fare affermazioni probabilistiche sui parametri. Il valore \\(\\mu\\) è considerato fisso ma sconosciuto, e l’incertezza è attribuita unicamente al campionamento.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#confronto-tra-approcci-stesso-dato-epistemologie-diverse",
    "href": "chapters/linear_models/07_one_mean.html#confronto-tra-approcci-stesso-dato-epistemologie-diverse",
    "title": "63  Inferenza bayesiana su una media",
    "section": "\n63.11 Confronto tra approcci: stesso dato, epistemologie diverse",
    "text": "63.11 Confronto tra approcci: stesso dato, epistemologie diverse\n\n\n\n\n\n\n\nElemento\nFrequentista\nBayesiano\n\n\n\nConcetto di parametro\nFisso ma ignoto\nVariabile aleatoria\n\n\nIncertezza\nTra campioni\nNei parametri\n\n\nIntervallo (95%)\nProcedura che copre nel 95% dei casi\nCredibilità del 95% sul valore vero\n\n\nEstensione a modelli complessi\nLimitata\nFlessibile\n\n\nTrasparenza delle assunzioni\nImplicita\nEsplicita",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#replicare-lanalisi-con-cmdstanr",
    "href": "chapters/linear_models/07_one_mean.html#replicare-lanalisi-con-cmdstanr",
    "title": "63  Inferenza bayesiana su una media",
    "section": "\n63.12 Replicare l’analisi con cmdstanr\n",
    "text": "63.12 Replicare l’analisi con cmdstanr\n\nOra replichiamo con cmdstanr (Stan esplicito) l’analisi ottenuta con brm e salvata nell’oggetto fm3.\nIl modello è:\n\\[\ny_i \\sim \\mathrm{Normal}(\\mu,\\sigma), \\qquad\n\\mu \\sim \\mathcal{N}(181, 30), \\qquad\n\\sigma \\sim \\mathcal{N}^+(0, 20),\n\\]\ndove \\(\\mathcal{N}^+\\) indica la normale troncata ai valori positivi.\nIl modello Stan equivalente è\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  // Priors equivalenti a brms:\n  mu    ~ normal(181, 30);\n  sigma ~ normal(0, 20); // con &lt;lower=0&gt; diventa automaticamente Half-Normal(0,20)\n\n  // Likelihood\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (n in 1:N) y_rep[n] = normal_rng(mu, sigma);\n}\n\"\n\nCompiliamo:\n\nstan_file &lt;- write_stan_file(stancode, dir = \"stan\", basename = \"one_mean_fm3.stan\")\nmod       &lt;- cmdstan_model(stan_file)\n\nPrepariamo i dati:\n\nstan_data &lt;- list(N = nrow(df), y = as.numeric(df$height))\nglimpse(stan_data)\n#&gt; List of 2\n#&gt;  $ N: int 352\n#&gt;  $ y: num [1:352] 152 140 137 157 145 ...\n\nEseguiamo il campionamento:\n\nfit_stan &lt;- mod$sample(\n  data = stan_data,\n  seed = 1234,\n  chains = 4, \n  iter_warmup = 1000, \n  iter_sampling = 4000, \n  parallel_chains = 4,\n  adapt_delta = 0.95\n)\n\nEsaminiamo i risultati:\n\nfit_stan$summary(variables = c(\"mu\",\"sigma\"))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable    mean  median    sd   mad      q5     q95  rhat  ess_bulk ess_tail\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       154.601 154.602 0.413 0.406 153.918 155.285 1.000 10185.459 8086.662\n#&gt; 2 sigma      7.767   7.757 0.290 0.288   7.303   8.259 1.000 10043.384 8612.693\n\n\n63.12.1 Confronto delle posterior (brms vs Stan)\n\ndraws_brm  &lt;- as_draws_df(fm3) |&gt;\n  transmute(mu = b_Intercept, sigma = sigma)\ndraws_stan &lt;- as_draws_df(fit_stan$draws(variables = c(\"mu\",\"sigma\")))\n\nsumm_brm  &lt;- posterior::summarise_draws(draws_brm)  |&gt; mutate(modello = \"brms\")\nsumm_stan &lt;- posterior::summarise_draws(draws_stan) |&gt; mutate(modello = \"stan\")\n\ndplyr::bind_rows(summ_brm, summ_stan) |&gt;\n  dplyr::select(modello, variable, mean, sd, q5, q95, rhat, ess_bulk) |&gt;\n  dplyr::arrange(variable, modello)\n#&gt; # A tibble: 4 × 8\n#&gt;   modello variable    mean    sd      q5     q95  rhat  ess_bulk\n#&gt;   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 brms    mu       154.603 0.414 153.924 155.281 1.000  3150.751\n#&gt; 2 stan    mu       154.601 0.413 153.918 155.285 1.000 10185.459\n#&gt; 3 brms    sigma      7.771 0.294   7.305   8.264 1.000  3220.370\n#&gt; 4 stan    sigma      7.767 0.290   7.303   8.259 1.000 10043.384\n\n\n63.12.2 Visualizzazione delle densità posteriori\n\n\n\n\n\n\n\n\nSe le aree colorate e le linee dei due modelli si sovrappongono quasi perfettamente in ciascun pannello, le posterior coincidono entro il rumore Monte Carlo.\n\n63.12.3 Posterior predictive check\n\ndraws_yrep &lt;- fit_stan$draws(\"y_rep\")\narr &lt;- posterior::as_draws_array(draws_yrep)\nM &lt;- dim(arr)[1] * dim(arr)[2]\nN &lt;- dim(arr)[3]\n\nyrep_df  &lt;- as.data.frame(matrix(arr, nrow = M, ncol = N))\nobs_mean &lt;- mean(df$height)\nyrep_mean &lt;- rowMeans(as.matrix(yrep_df))\n\nppc_df &lt;- data.frame(stat = yrep_mean)\n\nbase_col  &lt;- \"#56B4E9\"\nline_col  &lt;- \"#D55E00\"\n\nggplot(ppc_df, aes(x = stat)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, color = \"white\", fill = base_col) +\n  geom_vline(xintercept = obs_mean, color = line_col, linewidth = 1) +\n  labs(x = \"Media(y_rep)\", y = \"Densità\")\n\n\n\n\n\n\n\n\n63.12.4 Nota sulle prior\nCon il vincolo \\(\\sigma&gt;0\\) in Stan, la specifica sigma ~ normal(0, 20); implementa automaticamente una Half-Normal con scala 20, coerente con prior(normal(0, 20), class = \"sigma\") in brms. Questa equivalenza assicura che i risultati dei due approcci coincidano entro l’errore Monte Carlo, a parità di dati e impostazioni MCMC.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#riflessioni-conclusive",
    "href": "chapters/linear_models/07_one_mean.html#riflessioni-conclusive",
    "title": "63  Inferenza bayesiana su una media",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo ci siamo concentrati su un caso semplice ma essenziale: la stima della media di una variabile quantitativa. Questo esempio ci ha permesso di mettere a confronto due approcci fondamentali all’inferenza statistica — quello frequentista e quello bayesiano — evidenziandone le differenze concettuali e pratiche.\nNell’approccio frequentista, l’incertezza viene trattata come una proprietà della procedura di stima: non sappiamo quale valore ha il parametro, ma possiamo costruire intervalli che, se ripetessimo l’esperimento molte volte, conterrebbero il valore vero in una certa proporzione dei casi. In questa visione, i parametri sono fissi e ignoti, e tutta l’incertezza risiede nei dati campionari.\nL’approccio bayesiano, al contrario, considera i parametri come quantità soggette a incertezza e quindi descrivibili mediante distribuzioni di probabilità. Dopo aver osservato i dati, otteniamo una distribuzione a posteriori per ogni parametro, che ci permette di esprimere in modo diretto e intuitivo quanto riteniamo plausibili diversi valori del parametro stesso. Possiamo così calcolare non solo medie e deviazioni, ma anche la probabilità che un parametro superi una certa soglia, o che la differenza tra due condizioni sia positiva.\nUn aspetto centrale emerso nel confronto è l’importanza dei prior: nella prospettiva bayesiana, l’inferenza non è mai del tutto “neutra”, ma dipende anche da ciò che sappiamo — o assumiamo — prima di osservare i dati. Quando i dati sono informativi, i risultati bayesiani tendono a convergere con quelli frequentisti. Ma nei casi in cui i dati sono scarsi, rumorosi o ambigui, la scelta dei prior può fare la differenza, offrendo un’ancora razionale che aiuta a stabilizzare le stime e a evitare conclusioni arbitrarie.\nGli strumenti di visualizzazione offerti da bayesplot, in particolare i traceplot, le densità a posteriori e i posterior predictive check, ci aiutano a rendere tangibile questa incertezza, permettendo di controllare se le catene MCMC stanno funzionando correttamente, di esplorare le relazioni tra i parametri e di valutare la capacità del modello di generare dati simili a quelli osservati. In questo senso, il modello bayesiano non è solo un dispositivo inferenziale, ma anche un’interfaccia per riflettere sul legame tra teoria e osservazione.\nTutto ciò assume un significato particolare in psicologia, dove la variabilità tra individui, contesti e momenti è parte integrante del fenomeno da comprendere. Un approccio statistico che rappresenta esplicitamente l’incertezza, invece di nasconderla o ridurla a un test binario, si rivela quindi più adatto a riflettere la complessità reale della disciplina.\nNel prossimi capitoli ci sposteremo dal caso di una sola media al confronto tra due gruppi. Vedremo come l’approccio bayesiano ci permetta di formulare domande più ricche e informative, come: “Qual è la probabilità che il gruppo A abbia una media maggiore del gruppo B?” — domande che superano il tradizionale criterio del “significativo o no”, aprendoci a una comprensione più sfumata e utile delle differenze tra condizioni.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nObiettivo: Utilizzare i dati dello studio di Tarrats-Pons et al. (2025) per replicare i risultati riportati nella Figura 2 , applicando sia l’approccio frequentista che il framework bayesiano. Calcolare inoltre la grandezza dell’effetto nel contesto bayesiano (Cohen’s \\(d\\)) e generare un grafico che visualizzi la distribuzione a posteriori della grandezza dell’effetto ottenuta.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(brms)\nlibrary(posterior)\nlibrary(bayestestR)\n\ndf &lt;- read_excel(\n  here::here(\n    \"data\",\n    \"Tarrats-Pons.xlsx\"\n  ),\n  sheet = 3\n)\n\ndf |&gt;\n  group_by(Sample) |&gt;\n  summarize(\n    avg = mean(`CESS-D`),\n    n = n()\n  )\n\ndf_wide &lt;- df %&gt;%\n  select(IdentificationNumber, Sample, CESS_D = `CESS-D`) %&gt;%\n  pivot_wider(\n    names_from = Sample, # da POST/PRE\n    values_from = CESS_D, # i valori da mettere nelle colonne\n    names_prefix = \"CESSD_\" # opzionale, per nominare CESSD_POST, CESSD_PRE\n  )\n\n# Controlla il risultato\nhead(df_wide)\n\ndf_wide$diff &lt;- df_wide$CESSD_PRE - df_wide$CESSD_POST\n\nhist(df_wide$diff)\n\nt.test(df_wide$diff)\n\n# t-test sulle differenze\nres &lt;- t.test(df_wide$diff)\n\n# Numero di soggetti\nn &lt;- length(df_wide$diff)\n\n# Calcolo di Cohen's d\nd_t &lt;- as.numeric(res$statistic) / sqrt(n)\n\n# Mostro risultato\nd_t\n\nfm1 &lt;- brm(\n  formula = diff ~ 1, # Modello con sola intercetta (mu)\n  data = df_wide,\n  family = gaussian(), # Distribuzione Normale\n  prior = c(\n    brms::prior(normal(0, 10), class = \"Intercept\"), # Prior su mu\n    brms::prior(normal(0, 10), class = \"sigma\") # Prior su sigma\n  ),\n  chains = 4,\n  iter = 2000,\n  seed = 1234,\n  backend = \"cmdstanr\"\n)\nsummary(fm1)\npp_check(fm1)\n\nfm2 &lt;- brm(\n  formula = diff ~ 1, # Modello con sola intercetta (mu)\n  data = df_wide,\n  family = student(), # Distribuzione Normale\n  prior = c(\n    brms::prior(normal(0, 10), class = \"Intercept\"), # Prior su mu\n    brms::prior(normal(0, 10), class = \"sigma\") # Prior su sigma\n  ),\n  chains = 4,\n  iter = 2000,\n  seed = 1234,\n  backend = \"cmdstanr\"\n)\nsummary(fm2)\npp_check(fm2)\n\npost_samples &lt;- posterior::as_draws_df(fm1)\nhead(post_samples)\n\npost_samples$effect_size &lt;- post_samples$b_Intercept / post_samples$sigma\n\n# Calcolo diretto delle statistiche dell'effect size\nmean_effect_size &lt;- mean(post_samples$effect_size)\nsd_effect_size &lt;- sd(post_samples$effect_size)\nci_effect_size &lt;- quantile(post_samples$effect_size, probs = c(0.025, 0.975))\n\n# Stampa dei risultati\ncat(\"=== Statistiche dell'Effect Size Bayesiano ===\\n\")\ncat(\"Effect size medio:\", round(mean_effect_size, 2), \"\\n\")\ncat(\"SD dell'effect size:\", round(sd_effect_size, 2), \"\\n\")\ncat(\n  \"Intervallo di credibilità al 95%:\",\n  round(ci_effect_size[1], 2),\n  \"-\",\n  round(ci_effect_size[2], 2),\n  \"\\n\\n\"\n)\n\n# Interpretazione dell'effect size secondo le convenzioni di Cohen\nif (abs(mean_effect_size) &lt; 0.2) {\n  interpretation &lt;- \"piccolo\"\n} else if (abs(mean_effect_size) &lt; 0.5) {\n  interpretation &lt;- \"medio-piccolo\"\n} else if (abs(mean_effect_size) &lt; 0.8) {\n  interpretation &lt;- \"medio\"\n} else {\n  interpretation &lt;- \"grande\"\n}\ncat(\"Interpretazione (Cohen):\", interpretation, \"\\n\")\n\n# Calcola la probabilità che l'effect size sia maggiore di zero\nprob_positive &lt;- mean(post_samples$effect_size &gt; 0)\ncat(\n  \"Probabilità che l'effect size sia positivo:\",\n  round(prob_positive * 100, 2),\n  \"%\\n\"\n)\n\n# Se necessario, calcola probabilità per altre soglie\nprob_medium &lt;- mean(post_samples$effect_size &gt; 0.5)\ncat(\n  \"Probabilità che l'effect size sia &gt; 0.5 (medio):\",\n  round(prob_medium * 100, 2),\n  \"%\\n\"\n)\nprob_large &lt;- mean(post_samples$effect_size &gt; 0.8)\ncat(\n  \"Probabilità che l'effect size sia &gt; 0.8 (grande):\",\n  round(prob_large * 100, 2),\n  \"%\\n\"\n)\n\n# Visualizzazione della distribuzione posteriore dell'effect size\n# (Per eseguire questo blocco, devi avere ggplot2 installato e caricato)\n# library(ggplot2)\nggplot(post_samples, aes(x = effect_size)) +\n  geom_density(fill = \"skyblue\", alpha = 0.5) +\n  geom_vline(\n    xintercept = mean_effect_size,\n    color = \"red\",\n    linetype = \"dashed\"\n  ) +\n  geom_vline(\n    xintercept = ci_effect_size[1],\n    color = \"darkblue\",\n    linetype = \"dotted\"\n  ) +\n  geom_vline(\n    xintercept = ci_effect_size[2],\n    color = \"darkblue\",\n    linetype = \"dotted\"\n  ) +\n  labs(\n    x = \"Effect Size (Cohen's d)\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] readxl_1.4.5          lubridate_1.9.4       forcats_1.0.0        \n#&gt;  [4] stringr_1.5.1         purrr_1.1.0           readr_2.1.5          \n#&gt;  [7] tidyverse_2.0.0       bayestestR_0.17.0     cmdstanr_0.9.0       \n#&gt; [10] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt; [13] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [16] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [19] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [22] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [25] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [28] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [31] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [34] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] RColorBrewer_1.1-3    tensorA_0.36.2.1      jsonlite_2.0.0       \n#&gt;  [4] magrittr_2.0.3        TH.data_1.1-4         estimability_1.5.1   \n#&gt;  [7] farver_2.1.2          rmarkdown_2.29        ragg_1.5.0           \n#&gt; [10] vctrs_0.6.5           memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [13] distributional_0.5.0  curl_7.0.0            broom_1.0.9          \n#&gt; [16] cellranger_1.1.0      htmlwidgets_1.6.4     plyr_1.8.9           \n#&gt; [19] sandwich_3.1-1        emmeans_1.11.2-8      zoo_1.8-14           \n#&gt; [22] cachem_1.1.0          lifecycle_1.0.4       pkgconfig_2.0.3      \n#&gt; [25] Matrix_1.7-4          R6_2.6.1              fastmap_1.2.0        \n#&gt; [28] snakecase_0.11.1      digest_0.6.37         colorspace_2.1-1     \n#&gt; [31] ps_1.9.1              rprojroot_2.1.1       textshaping_1.0.3    \n#&gt; [34] labeling_0.4.3        timechange_0.3.0      abind_1.4-8          \n#&gt; [37] compiler_4.5.1        withr_3.0.2           backports_1.5.0      \n#&gt; [40] inline_0.3.21         QuickJSR_1.8.0        pkgbuild_1.4.8       \n#&gt; [43] R.utils_2.13.0        MASS_7.3-65           tools_4.5.1          \n#&gt; [46] R.oo_1.27.1           glue_1.8.0            nlme_3.1-168         \n#&gt; [49] grid_4.5.1            checkmate_2.3.3       reshape2_1.4.4       \n#&gt; [52] generics_0.1.4        gtable_0.3.6          tzdb_0.5.0           \n#&gt; [55] R.methodsS3_1.8.2     data.table_1.17.8     hms_1.1.3            \n#&gt; [58] utf8_1.2.6            splines_4.5.1         lattice_0.22-7       \n#&gt; [61] survival_3.8-3        tidyselect_1.2.1      knitr_1.50           \n#&gt; [64] arrayhelpers_1.1-0    gridExtra_2.3         V8_7.0.0             \n#&gt; [67] stats4_4.5.1          xfun_0.53             bridgesampling_1.1-2 \n#&gt; [70] stringi_1.8.7         yaml_2.3.10           pacman_0.5.1         \n#&gt; [73] evaluate_1.0.5        codetools_0.2-20      cli_3.6.5            \n#&gt; [76] RcppParallel_5.1.11-1 xtable_1.8-4          systemfonts_1.2.3    \n#&gt; [79] processx_3.8.6        coda_0.19-4.1         svUnit_1.0.8         \n#&gt; [82] parallel_4.5.1        rstantools_2.5.0      Brobdingnag_1.2-9    \n#&gt; [85] mvtnorm_1.3-3         scales_1.4.0          ggridges_0.5.7       \n#&gt; [88] insight_1.4.2         rlang_1.1.6           multcomp_1.4-28",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#bibliografia",
    "href": "chapters/linear_models/07_one_mean.html#bibliografia",
    "title": "63  Inferenza bayesiana su una media",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nTarrats-Pons, E., Mussons-Torras, M., & Jiménez-Pérez, Y. (2025). Efficacy of a Positive Psychology Intervention in Enhancing Optimism and Reducing Depression Among University Students: A Quasi-Experimental Study. Behavioral Sciences, 15(5), 571.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html",
    "href": "chapters/linear_models/08_two_means.html",
    "title": "64  Confronto tra le medie di due gruppi",
    "section": "",
    "text": "Introduzione\nUna delle domande di ricerca più comuni in psicologia è il confronto tra due gruppi o condizioni. Ci chiediamo, ad esempio, se un gruppo di trattamento ottiene risultati migliori di un gruppo di controllo, o se un campione clinico differisce significativamente da un campione non clinico in una data misura. In questi casi, la domanda cruciale non è solo se esista una differenza, ma anche di quale ampiezza essa sia e con quale grado di incertezza.\nQuesto capitolo affronta questo problema usando un’inferenza bayesiana per confrontare due medie. Immaginiamo di avere una variabile risultato continua, che indichiamo con \\(y_{ig}\\) per l’osservazione \\(i\\) nel gruppo \\(g\\) (dove \\(g\\) può essere 0 o 1). Un modello statistico semplice e diretto per questa situazione assume che i punteggi seguano una distribuzione normale, ciascuno con la propria media di gruppo:\n\\[\ny_{ig}\\sim\\mathcal N(\\mu_g,\\ \\sigma), \\qquad \\Delta=\\mu_1-\\mu_0 ,\n\\]\nLa quantità di interesse centrale qui è \\(\\Delta\\), che rappresenta proprio la differenza tra le due medie. Questo stesso modello può essere espresso in modo equivalente come un modello di regressione lineare semplice, usando una variabile indicatrice (\\(x_i\\)) che codifica l’appartenenza al gruppo (0 o 1):\n\\[\ny_i \\sim \\mathcal N(\\alpha+\\beta x_i,\\ \\sigma),\n\\]\nIn questa formulazione, l’intercetta \\(\\alpha\\) corrisponde alla media del gruppo di riferimento (\\(\\mu_0\\)), mentre il coefficiente \\(\\beta\\) rappresenta la differenza tra le due medie (\\(\\Delta\\)). Quando il contesto lo richiede, considereremo anche la versione standardizzata di questo effetto, cioè \\(d = \\Delta / \\sigma\\), che fornisce una misura della dimensione dell’effetto indipendente dalla scala di misura originale.\nRispetto all’approccio frequentista tradizionale, che si concentra principalmente sul calcolo di un p-value, l’inferenza bayesiana offre diversi vantaggi pratici e concettuali. Permette infatti di ottenere una distribuzione a posteriori completa per la differenza \\(\\Delta\\), che quantifica in modo diretto e intuitivo tutta la nostra incertezza sulla stima dopo aver visto i dati. Da questa distribuzione possiamo calcolare probabilità direttamente interpretabili, come la probabilità che la differenza sia positiva \\(\\Pr(\\Delta&gt;0\\mid\\text{dati})\\), o, ancor più importante, la probabilità che l’effetto superi una soglia di rilevanza pratica prestabilita \\(\\Pr(|\\Delta|&gt;\\text{SESOI}\\mid\\text{dati})\\). Inoltre, il quadro bayesiano rende del tutto trasparente l’integrazione di conoscenze pregresse (attraverso la scelta delle prior) e obbliga a rendere esplicite tutte le assunzioni su cui il modello si basa.\nIl percorso che seguiremo in questo capitolo è semplice e strutturato. Inizieremo specificando il modello bayesiano per il confronto tra due medie, esplorandone anche varianti più robuste nel caso in cui l’assunzione di normalità risulti troppo restrittiva. Sceglieremo poi delle prior debolmente informative, che siano coerenti con la scala di misura della nostra variabile risultato e che permettano ai dati di “parlare” in modo predominante. Una volta stimato il modello, il focus sarà sul riportare le quantità di interesse—la differenza \\(\\Delta\\) e l’eventuale dimensione dell’effetto standardizzata \\(d\\)—accompagnate dalle loro distribuzioni a posteriori e dalle probabilità rilevanti. Infine, valuteremo l’adeguatezza del nostro modello attraverso verifiche predittive, per assicurarci che sia in grado di generare dati simili a quelli osservati, e, se necessario, confronteremo modelli con assunzioni diverse per scegliere quello che meglio cattura la struttura dei nostri dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#introduzione",
    "href": "chapters/linear_models/08_two_means.html#introduzione",
    "title": "64  Confronto tra le medie di due gruppi",
    "section": "",
    "text": "Le assunzioni del modello base\n\n\n\nCome ogni modello statistico, anche questo semplice confronto tra medie si basa su alcune assunzioni fondamentali che è importante tenere a mente. Le osservazioni sono assumed to be indipendenti tra loro, una volta tenuto conto dell’effetto del gruppo. I residui del modello, cioè la parte di variabilità non spiegata dalla gruppo appartenenza, dovrebbero seguire una distribuzione approssimativamente normale. Il modello presentato qui assume anche che la variabilità dei dati (la \\(\\sigma\\)) sia la stessa nei due gruppi; si tratta di un’ipotesi semplificatrice, ma il modello può essere esteso per accomodare il caso più generale in cui le varianze siano diverse (eteroscedasticità).\n\n\n\n\n\n\n\n\nL’importanza di una Soglia di Rilevanza (SESOI)\n\n\n\nPer evitare di sovrainterpretare differenze statisticamente significative ma trivialmente piccole, è una buona pratica metodologica definire a priori una Soglia di Rilevanza Scientificamente Significativa (SESOI). Stabilire, ad esempio, che una differenza di almeno 5 punti in un test cognitivo abbia un reale significato pratico, permette di ancorare le conclusioni alla sostanza del fenomeno studiato, andando oltre la semplice significatività statistica. È quindi utile riportare non solo la probabilità che l’effetto sia diverso da zero, ma anche la probabilità che superi questa soglia di rilevanza.\n\n\n\nPanoramica del capitolo\n\nLe basi concettuali e statistiche che sottendono la modellazione della differenza tra medie nell’ambito del modello di regressione lineare bayesiana.\nLe diverse strategie di codifica del predittore categoriale (dummy, centrata, a medie di cella).\nLe strategie più efficaci per comunicare i risultati attraverso intervalli credibili e previsioni probabilistiche.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nConsultare l’articolo “Bayesian estimation supersedes the t test” (Kruschke, 2013).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, brms, bayestestR, insight)\nconflicts_prefer(loo::loo)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#il-modello-a-indicatore-e-le-quantità-di-interesse",
    "href": "chapters/linear_models/08_two_means.html#il-modello-a-indicatore-e-le-quantità-di-interesse",
    "title": "64  Confronto tra le medie di due gruppi",
    "section": "\n64.1 Il modello a indicatore e le quantità di interesse",
    "text": "64.1 Il modello a indicatore e le quantità di interesse\nPer confrontare due gruppi in modo rigoroso, utilizziamo un modello statistico che incorpora un predittore binario, \\(x_i\\), il cui valore (0 o 1) indica l’appartenenza a uno dei due gruppi. Il modello lineare che proponiamo è il seguente:\n\\[\ny_i = \\alpha + \\beta x_i + \\varepsilon_i, \\qquad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma),\n\\]\ndove il termine \\(\\varepsilon_i\\) rappresenta l’errore residuo, la parte di variabilità del punteggio \\(y_i\\) che il modello non riesce a spiegare. Un’assunzione fondamentale di questo modello base è che la dispersione di questi residui, misurata dalla deviazione standard \\(\\sigma\\), sia la stessa per entrambi i gruppi. Questa condizione è nota come ipotesi di omoschedasticità.\nLe quantità centrali che vogliamo stimare—le medie dei due gruppi—sono ricavabili direttamente dai parametri del modello. Sostituendo i valori dell’indicatore, otteniamo:\n\nL’attesa per il gruppo di riferimento (quando \\(x_i = 0\\)) è: \\(\\mathbb{E}[y \\mid x=0] = \\alpha\\). Chiamiamo questo valore \\(\\mu_0\\).\nL’attesa per il gruppo di confronto (quando \\(x_i = 1\\)) è: \\(\\mathbb{E}[y \\mid x=1] = \\alpha + \\beta\\). Chiamiamo questo valore \\(\\mu_1\\).\n\nLa differenza tra le due medie, che è la quantità di interesse primaria, risulta quindi essere esattamente il coefficiente \\(\\beta\\):\n\\[\n\\Delta = \\mu_1 - \\mu_0 = (\\alpha + \\beta) - \\alpha = \\beta.\n\\]\nIn sintesi, l’interpretazione dei parametri è molto intuitiva:\n\nIl parametro \\(\\alpha\\) (l’intercetta) rappresenta la media del gruppo di riferimento.\nIl parametro \\(\\beta\\) (la pendenza) rappresenta la differenza media tra il gruppo di confronto e il gruppo di riferimento.\nIl parametro \\(\\sigma\\) rappresenta la variabilità residua comune all’interno di ciascun gruppo, assumendo che sia omogenea.\n\nUna prospettiva alternativa: il modello a medie di cella\nLo stesso modello può essere formulato in un modo che rende ancora più esplicite le medie di gruppo. Invece di esprimerlo come una funzione lineare, possiamo scriverlo direttamente specificando la media per ogni cella:\n\\[\ny_i \\sim \\mathcal{N}(\\mu_{x_i},\\, \\sigma),\n\\]\ndove \\(\\mu_{x_i}\\) è semplicemente la media del gruppo a cui l’osservazione \\(i\\)-esima appartiene. In pratica, questo significa che se \\(x_i = 0\\), allora \\(y_i \\sim \\mathcal{N}(\\mu_0, \\sigma)\\), e se \\(x_i = 1\\), allora \\(y_i \\sim \\mathcal{N}(\\mu_1, \\sigma)\\).\nQuesta parametrizzazione è del tutto equivalente a quella con \\(\\alpha\\) e \\(\\beta\\), con la semplice corrispondenza \\(\\mu_0 = \\alpha\\) e \\(\\mu_1 = \\alpha + \\beta\\). La sua utilità risiede nel fatto che rende immediatamente visibili i parametri di interesse diretto (\\(\\mu_0\\) e \\(\\mu_1\\)) ed è spesso più semplice da comprendere concettualmente.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#la-codifica-centrata-dellindicatore",
    "href": "chapters/linear_models/08_two_means.html#la-codifica-centrata-dellindicatore",
    "title": "64  Confronto tra le medie di due gruppi",
    "section": "\n64.2 La codifica centrata dell’indicatore",
    "text": "64.2 La codifica centrata dell’indicatore\nUn’accortezza tecnica ma molto utile nella modellazione consiste nel centrare la variabile indicatrice. Invece di usare i valori 0 e 1, possiamo ridefinirla sottraendo 0.5, ottenendo così:\n\\[\nx_c = x - \\tfrac12 \\in \\left\\{-\\tfrac12,\\ +\\tfrac12\\right\\}.\n\\]\nIl modello di regressione viene quindi riscritto utilizzando questo predittore centrato:\n\\[\ny_i = \\alpha_c + \\beta_c \\, x_{c,i} + \\varepsilon_i.\n\\]\nQuesta piccola modifica altera in modo vantaggioso l’interpretazione dei coefficienti:\n\nIl parametro \\(\\alpha_c\\) (l’intercetta) non è più la media del gruppo di riferimento, bensì la media generale (o grand mean) dei due gruppi, calcolata come \\((\\mu_0 + \\mu_1)/2\\).\nIl parametro \\(\\beta_c\\) (la pendenza) rimane invece esattamente la differenza tra le due medie (\\(\\mu_1 - \\mu_0\\)), proprio come nel caso della codifica non centrata.\n\n\n64.2.1 Vantaggi pratici della codifica centrata\nQuesta parametrizzazione alternativa offre diversi vantaggi pratici:\n\n\nInterpretazione immediata dell’intercetta: L’intercetta \\(\\alpha_c\\) rappresenta direttamente la media complessiva del campione, una quantità spesso utile da riportare.\n\nSemplicità nella specifica delle prior: Risulta più intuitivo e diretto specificare distribuzioni a priori per i parametri. Possiamo scegliere una prior per \\(\\alpha_c\\) basata sulla nostra conoscenza del livello medio generale della variabile \\(y\\) nella popolazione, e una prior separata per \\(\\beta_c\\) basata sull’ampiezza dell’effetto che ci aspettiamo o che riteniamo rilevante.\n\nStima più efficiente in modelli complessi: Nei modelli gerarchici più avanzati, la centratura può spesso ridurre la correlazione tra le stime dei parametri, migliorando l’efficienza del campionatore MCMC e facilitando la convergenza.\n\nSuggerimento operativo: La scelta tra la codifica standard (0/1) e quella centrata dipende dagli obiettivi dell’analisi.\n\nUtilizza la codifica centrata quando l’attenzione è primariamente sulla differenza \\(\\beta\\) e quando vuoi riportare in modo trasparente la media complessiva.\nUtilizza la forma a “medie di cella” (o la codifica 0/1) quando è più conveniente o interpretabile stimare direttamente i livelli medi \\(\\mu_0\\) e \\(\\mu_1\\) per ciascun gruppo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#stima-con-brms",
    "href": "chapters/linear_models/08_two_means.html#stima-con-brms",
    "title": "64  Confronto tra le medie di due gruppi",
    "section": "\n64.3 Stima con brms\n",
    "text": "64.3 Stima con brms\n\nDi seguito mostriamo tre modi equivalenti per stimare la differenza tra due gruppi con brms. Per ogni blocco indichiamo: cosa fa il modello, come leggere i coefficienti, quali quantità riportare.\n\n64.3.1 1) Codifica dummy \\(x\\in\\{0,1\\}\\) (modello “standard”)\nIdea. Stimiamo \\(\\alpha\\) (media del gruppo \\(x=0\\)) e \\(\\beta\\) (differenza \\(\\mu_1-\\mu_0\\)). Le prior student_t(3, 0, 10) sono debolmente informative: centrano i parametri a 0 e consentono ampia variabilità (code più pesanti della normale).\n#| message: false\n# install.packages(c(\"brms\",\"posterior\",\"tidyverse\",\"bayestestR\",\"loo\",\"cmdstanr\"))\nlibrary(brms); library(posterior); library(tidyverse); library(bayestestR); library(loo)\n\nfit &lt;- brm(\n  y ~ 1 + x,                 # Intercetta + indicatrice (0/1)\n  data = df,\n  family = gaussian(),\n  prior = c(\n    prior(student_t(3, 0, 10), class = \"Intercept\"),  # prior su α (media gruppo 0)\n    prior(student_t(3, 0, 10), class = \"b\"),          # prior su β (differenza)\n    prior(student_t(3, 0, 10), class = \"sigma\")       # prior su σ (half-t implicita)\n  ),\n  backend = \"cmdstanr\",\n  chains = 4, iter = 2000, seed = 123\n)\nCome leggere i risultati.\n\n\nb_Intercept stima \\(\\mu_0\\).\n\nb_x stima \\(\\Delta=\\mu_1-\\mu_0\\).\n\nsigma è la deviazione standard comune. Calcoliamo anche \\(d=\\Delta/\\sigma\\) e due probabilità a posteriori utili: \\(\\Pr(\\Delta&gt;0)\\) e \\(\\Pr(|\\Delta|&gt;\\text{SESOI})\\).\n\ndraws &lt;- as_draws_df(fit)\npost &lt;- draws %&gt;%\n  transmute(\n    mu0   = b_Intercept,          # = α\n    mu1   = b_Intercept + b_x,    # = α + β\n    delta = b_x,                  # = β\n    sigma = sigma,\n    d     = delta / sigma         # effetto standardizzato (pooled)\n  )\n\nposterior::summarise_draws(post[, c(\"mu0\",\"mu1\",\"delta\",\"d\",\"sigma\")])\n\nSESOI &lt;- 5  # definita a priori in base al contesto applicativo\nc(\n  P_delta_gt0  = mean(post$delta &gt; 0),\n  P_delta_gtS  = mean(abs(post$delta) &gt; SESOI)\n)\nCosa riportare nel testo: media e intervallo credibile per \\(\\mu_0,\\mu_1,\\Delta,d\\); \\(\\Pr(\\Delta&gt;0)\\); \\(\\Pr(|\\Delta|&gt;\\text{SESOI})\\).\n\n64.3.2 2) Codifica centrata \\(x_c=x-\\tfrac12\\)\n\nIdea. L’intercetta diventa la grand mean \\((\\mu_0+\\mu_1)/2\\); il coefficiente su \\(x_c\\) è direttamente \\(\\Delta\\). Le prior sono normali (comode quando interpretiamo \\(\\alpha\\) come media complessiva).\ndf &lt;- df %&gt;% mutate(xc = x - 0.5)  # xc ∈ {-0.5, +0.5}\n\nfit_c &lt;- brm(\n  y ~ 1 + xc,\n  data = df,\n  family = gaussian(),\n  prior = c(\n    prior(normal(0, 10), class = \"Intercept\"),   # prior su grand mean\n    prior(normal(0, 10), class = \"b\"),           # prior sulla differenza\n    prior(student_t(3, 0, 10), class = \"sigma\")\n  ),\n  backend = \"cmdstanr\",\n  chains = 4, iter = 2000, seed = 123\n)\n\ndraws_c &lt;- as_draws_df(fit_c)\npost_c &lt;- draws_c %&gt;%\n  transmute(\n    grand_mean = b_Intercept,            # = (μ0+μ1)/2\n    delta      = b_xc,                   # = μ1 - μ0\n    mu0        = b_Intercept - 0.5*b_xc, # ricostruzione\n    mu1        = b_Intercept + 0.5*b_xc,\n    sigma      = sigma,\n    d          = delta / sigma\n  )\nposterior::summarise_draws(post_c[, c(\"grand_mean\",\"mu0\",\"mu1\",\"delta\",\"d\",\"sigma\")])\nQuando usarla: quando vuoi dare prior separate e intuitive su media complessiva e differenza.\n\n64.3.3 3) Medie di cella (senza intercetta)\nIdea. Stimiamo direttamente \\(\\mu_0\\) e \\(\\mu_1\\). Vantaggio: puoi assegnare prior indipendenti sulle due medie.\ndf &lt;- df %&gt;% mutate(group = factor(x, levels = c(0,1), labels = c(\"G0\",\"G1\")))\n\nfit_cells &lt;- brm(\n  y ~ 0 + group,              # niente intercetta: i coefficienti SONO le medie\n  data = df, family = gaussian(),\n  prior = c(\n    prior(normal(0, 10), class = \"b\", coef = \"groupG0\"),  # prior su μ0\n    prior(normal(0, 10), class = \"b\", coef = \"groupG1\"),  # prior su μ1\n    prior(student_t(3, 0, 10), class = \"sigma\")\n  ),\n  backend = \"cmdstanr\",\n  chains = 4, iter = 2000, seed = 123\n)\n\ndraws_cells &lt;- as_draws_df(fit_cells)\npost_cells &lt;- draws_cells %&gt;%\n  transmute(\n    mu0   = b_groupG0,\n    mu1   = b_groupG1,\n    delta = b_groupG1 - b_groupG0,\n    sigma = sigma,\n    d     = delta / sigma\n  )\nposterior::summarise_draws(post_cells[, c(\"mu0\",\"mu1\",\"delta\",\"d\",\"sigma\")])\nQuando usarla: quando vuoi controllare in modo esplicito le prior sulle due medie (e.g., vincoli diversi per ciascun gruppo).\n\n\n\n\n\n\nNota sulle prior indotte\n\n\n\nCon la forma “intercetta + differenza”, prior indipendenti su \\(\\alpha\\) e \\(\\beta\\) inducono correlazione tra \\(\\mu_0\\) e \\(\\mu_1\\) (\\(\\mu_0=\\alpha,\\ \\mu_1=\\alpha+\\beta\\)). Se desideri indipendenza a priori tra \\(\\mu_0\\) e \\(\\mu_1\\), usa la parametrizzazione a medie di cella.\n\n\n\n\n\n\n\n\nNomi dei coefficienti: attenzione alla codifica\n\n\n\n\nSe x è numerica (0/1): il coefficiente si chiama tipicamente b_x.\nSe x è fattore (due livelli): il coefficiente sarà b_x1 o b_x&lt;nomeLivello&gt;.\nCon 0 + group: i coefficienti si chiamano b_groupG0, b_groupG1 (le etichette dipendono dai livelli della variabile). Controlla sempre i nomi esatti in names(as_draws_df(fit)) prima di costruire le trasformazioni.\n\n\n\n\n\n\n\n\n\nDiagnostica minima da riportare\n\n\n\nVerifica Rhat (~1.00), ESS, assenza di divergenze e PPC coerenti. Se necessario aumenta adapt_delta (0.95–0.99) e max_treedepth (es. 15).\n\n\n\nRiassunto operativo. Qualunque parametrizzazione tu scelga, riporta sempre: \\(\\mu_0,\\mu_1,\\Delta,d\\) con intervalli credibili e le probabilità \\(\\Pr(\\Delta&gt;0)\\) e \\(\\Pr(|\\Delta|&gt;\\text{SESOI})\\).\n\n\n64.3.4 Interpretazione operativa (cosa leggere nelle posteriori)\nDi seguito come leggere e riportare i risultati a seconda della codifica usata per il predittore binario.\n1) Codifica dummy \\(D\\in\\{0,1\\}\\)\n\n\nIntercept \\(\\Rightarrow\\) \\(\\mu_0\\) (media del gruppo \\(D=0\\)).\nCoefficiente su D \\(\\Rightarrow\\) \\(\\Delta=\\mu_1-\\mu_0\\) (differenza tra medie).\nDa riportare sempre: \\(\\mu_1=\\mu_0+\\Delta\\), \\(\\sigma\\), \\(d=\\Delta/\\sigma\\), \\(\\Pr(\\Delta&gt;0)\\), \\(\\Pr(|\\Delta|&gt;\\text{SESOI})\\).\n\n2) Codifica centrata \\(D_c=D-\\tfrac12\\in\\{-\\tfrac12,+\\tfrac12\\}\\)\n\n\nIntercept \\(\\Rightarrow\\) grand mean \\(\\displaystyle \\alpha=\\tfrac{\\mu_0+\\mu_1}{2}\\).\nCoefficiente su D_c \\(\\Rightarrow\\) \\(\\Delta=\\mu_1-\\mu_0\\).\nRicostruzioni utili: \\(\\mu_0=\\alpha-\\tfrac12\\Delta\\), \\(\\mu_1=\\alpha+\\tfrac12\\Delta\\).\nDa riportare come sopra: \\(\\Delta\\), \\(d\\), \\(\\Pr(\\Delta&gt;0)\\), \\(\\Pr(|\\Delta|&gt;\\text{SESOI})\\).\n\n3) Parametrizzazione a “medie di cella” (senza intercetta)\n\nI coefficienti sono direttamente \\(\\mu_0\\) e \\(\\mu_1\\).\nLa differenza si ottiene come combinazione lineare a posteriori: \\(\\Delta=\\mu_1-\\mu_0\\).\nDa riportare: \\(\\mu_0,\\mu_1,\\Delta,\\sigma,d,\\Pr(\\Delta&gt;0),\\Pr(|\\Delta|&gt;\\text{SESOI})\\).\n\n\n\n\n\n\n\nPromemoria pratico. Indipendentemente dalla codifica, l’oggetto sostantivo è sempre \\(\\Delta\\) (e, quando serve, \\(d=\\Delta/\\sigma\\)). Per la discussione applicativa affianca sempre:\n\nun intervallo credibile per \\(\\Delta\\);\n\n\\(\\Pr(\\Delta&gt;0\\mid\\text{dati})\\);\n\n\\(\\Pr(|\\Delta|&gt;\\text{SESOI}\\mid\\text{dati})\\) con una SESOI definita prima dell’analisi.\n\n\n\n\nEsempio di lettura sintetica. Se la posteriore di \\(\\Delta\\) ha media 4.8, intervallo credibile 95% \\([2.1,\\ 7.4]\\), \\(\\Pr(\\Delta&gt;0)=0.99\\) e \\(\\Pr(|\\Delta|&gt;5)=0.46\\) (SESOI = 5), allora: la differenza media è plausibilmente positiva, ma la probabilità di superare la soglia di rilevanza scelta è circa 46% (informazione utile per l’interpretazione sostantiva).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#confronto-tra-approcci-frequentista-e-bayesiano",
    "href": "chapters/linear_models/08_two_means.html#confronto-tra-approcci-frequentista-e-bayesiano",
    "title": "64  Confronto tra le medie di due gruppi",
    "section": "\n64.4 Confronto tra approcci: frequentista e bayesiano",
    "text": "64.4 Confronto tra approcci: frequentista e bayesiano\n\n\n\n\n\n\n\nAspetto\nFrequentista\nBayesiano\n\n\n\nRappresentazione\nIntervallo di confidenza\nIntervallo di credibilità\n\n\nUnità di analisi\nCompatibilità dei dati con \\(H_0\\)\n\nDistribuzione a posteriori su \\(\\Delta\\) e probabilità su regioni di interesse (SESOI/ROPE)\n\n\nIpotesi di partenza\nIpotesi nulla puntuale come riferimento\nModello + prior; non richiede un \\(H_0\\) puntuale, ma consente ipotesi su regioni parametriche\n\n\nUso di informazione pregressa\nNon previsto\nIntegrabile tramite prior\n\n\nDomanda tipica\n“Quanto sono rari i dati se \\(\\Delta=0\\)?”\n“Quanto è plausibile che \\(\\Delta\\) superi una soglia definita (SESOI)?”",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#esempio-istruzione-materna-e-qi",
    "href": "chapters/linear_models/08_two_means.html#esempio-istruzione-materna-e-qi",
    "title": "64  Confronto tra le medie di due gruppi",
    "section": "\n64.5 Esempio: istruzione materna e QI",
    "text": "64.5 Esempio: istruzione materna e QI\nUsiamo il dataset kidiq (sviluppo cognitivo): per ogni bambino abbiamo il QI (kid_score) e se la madre ha il diploma (mom_hs: 0 = non diplomata; 1 = diplomata).\nDomanda: i figli di madri diplomate hanno, in media, un QI diverso? Inoltre, fissiamo a titolo esemplificativo una SESOI = 5 punti di QI (soglia di rilevanza pratica da motivare nel contesto).\n\n64.5.1 Esplorazione iniziale dei dati\n1) Import, pulizia minima e etichette chiare.\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\n# Ricodifica esplicita per leggibilità nei grafici e nelle tabelle\nkidiq &lt;- kidiq |&gt;\n  mutate(\n    mom_hs = factor(mom_hs, levels = c(0, 1),\n                    labels = c(\"Non diplomata\", \"Diplomata\"))\n  )\n\n# Controllo veloce: struttura e eventuali missing\nglimpse(kidiq)\n#&gt; Rows: 434\n#&gt; Columns: 5\n#&gt; $ kid_score &lt;dbl&gt; 65, 98, 85, 83, 115, 98, 69, 106, 102, 95, 91, 58, 84, 78, 1…\n#&gt; $ mom_hs    &lt;fct&gt; Diplomata, Diplomata, Diplomata, Diplomata, Diplomata, Non d…\n#&gt; $ mom_iq    &lt;dbl&gt; 121.1, 89.4, 115.4, 99.4, 92.7, 107.9, 138.9, 125.1, 81.6, 9…\n#&gt; $ mom_work  &lt;dbl&gt; 4, 4, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4, 4, 4, 2, 1, 3, 3, 4, 3, …\n#&gt; $ mom_age   &lt;dbl&gt; 27, 25, 27, 25, 27, 18, 20, 23, 24, 19, 23, 24, 27, 26, 24, …\ncolSums(is.na(kidiq[, c(\"kid_score\", \"mom_hs\")]))\n#&gt; kid_score    mom_hs \n#&gt;         0         0\n\n2) Statistiche descrittive per gruppo.\n\nkidiq |&gt;\n  group_by(mom_hs) |&gt;\n  summarise(\n    n        = n(),\n    media_QI = mean(kid_score, na.rm = TRUE),\n    sd_QI    = sd(kid_score, na.rm = TRUE),\n    mediana  = median(kid_score, na.rm = TRUE),\n    IQR      = IQR(kid_score, na.rm = TRUE)\n  ) |&gt;\n  ungroup()\n#&gt; # A tibble: 2 × 6\n#&gt;   mom_hs            n media_QI sd_QI mediana   IQR\n#&gt;   &lt;fct&gt;         &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Non diplomata    93     77.5  22.6      80    37\n#&gt; 2 Diplomata       341     89.3  19.0      92    26\n\n\nLettura rapida: riportiamo numerosità, media e deviazione standard (oltre a mediana e IQR per un controllo di robustezza). Nel nostro campione tipicamente i gruppi sono sbilanciati (ad es., ~93 vs ~341): è un’informazione utile per interpretare precisione e incertezza delle stime.\n\n3) Visualizzazione della distribuzione nei due gruppi.\n\nggplot(kidiq, aes(x = mom_hs, y = kid_score)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.12, outlier.shape = NA) +\n  geom_jitter(width = 0.08, alpha = 0.25, size = 1) +\n  labs(\n    x = \"Istruzione materna\",\n    y = \"QI del bambino\"\n  ) \n\n\n\n\n\n\n\n\nCosa mostra il grafico: le medie sembrano diverse, ma le distribuzioni si sovrappongono in modo consistente. È un pattern tipico in psicologia: la differenza media non esaurisce l’informazione: servono stima dell’ampiezza, incertezza e, se possibile, rilevanza pratica (SESOI).\n\nDomanda guida per l’analisi inferenziale\nLa differenza osservata è compatibile con la sola variabilità campionaria oppure suggerisce una tendenza nella popolazione?\nPer rispondere, nel seguito stimiamo la differenza tra le medie con approccio frequentista (t-test) e con approccio bayesiano (modello gaussiano con brms), riportando anche le probabilità a posteriori rispetto alla SESOI.\n\n64.5.1.1 Approccio frequentista\nPer verificare se la differenza media osservata può essere attribuita alla sola variabilità campionaria, applichiamo un t-test per campioni indipendenti (versione con varianze uguali):\n\nt.test(\n  kid_score ~ mom_hs, \n  data = kidiq, \n  var.equal = TRUE\n)\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  kid_score by mom_hs\n#&gt; t = -5, df = 432, p-value = 0.0000006\n#&gt; alternative hypothesis: true difference in means between group Non diplomata and group Diplomata is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -16.34  -7.21\n#&gt; sample estimates:\n#&gt; mean in group Non diplomata     mean in group Diplomata \n#&gt;                        77.5                        89.3\n\nInterpretazione.\n\nLe medie campionarie sono circa 77.6 (madri non diplomate) e 89.3 (madri diplomate).\nLa differenza (gruppo 1 − gruppo 0) è ~ +11.8 punti QI.\nL’IC al 95% stampato da R si riferisce a (gruppo 0 − gruppo 1) ed è \\([-16.34,\\ -7.21]\\); quindi, per (gruppo 1 − gruppo 0) l’IC corrispondente è [+7.21, +16.34].\nIl p-value \\(= 6\\times 10^{-7}\\) indica che, se nella popolazione non ci fosse differenza (\\(\\mu_1=\\mu_0\\)), sarebbe molto raro osservare una differenza almeno così grande. (Non è la probabilità che \\(H_0\\) sia vera.)\n\n\nAssunzioni e note pratiche.\n\nIl test qui usa varianze uguali (var.equal=TRUE). In pratica è spesso preferibile la versione di Welch (default di t.test, cioè senza var.equal=TRUE), più robusta a varianze diverse e sbilanciamento tra gruppi.\nL’inferenza frequentista fornisce una decisione rispetto a \\(H_0\\) e un IC; non restituisce la probabilità che l’effetto superi una soglia di interesse applicativo.\n\nNel paragrafo successivo stimiamo la stessa differenza con l’approccio bayesiano, ottenendo una distribuzione a posteriori per \\(\\Delta\\) e quantità direttamente interpretabili come \\(\\Pr(\\Delta&gt;0)\\) e \\(\\Pr(|\\Delta|&gt;\\text{SESOI})\\).\n\n64.5.1.2 Approccio bayesiano\nCon mom_hs codificata come 0 = non diplomata e 1 = diplomata, il modello\n\\[\ny_i \\sim \\mathcal N(\\alpha+\\beta\\,\\text{mom\\_hs}_i,\\ \\sigma)\n\\]\nsi interpreta così:\n\n\n\\(\\alpha\\) = media del gruppo mom_hs = 0;\n\n\\(\\beta = \\Delta\\) = differenza tra medie (gruppo 1 − gruppo 0);\n\n\\(\\sigma\\) = deviazione standard residua (assunta uguale nei due gruppi).\n\n\n# Assicuriamoci che la referenza sia \"Non diplomata\"\nkidiq$mom_hs &lt;- relevel(kidiq$mom_hs, ref = \"Non diplomata\")\n\nfit_1 &lt;- brm(\n  kid_score ~ mom_hs,\n  data   = kidiq,\n  family = gaussian(),\n  backend = \"cmdstanr\",\n  chains = 4, iter = 2000, seed = 123\n)\n\n\n# ===== Ponte sicuro tra nomi \"umani\" e nomi dei draw =====\n# Termini dei coefficienti a livello fissato (esclude l'intercetta)\nterm_names &lt;- setdiff(rownames(fixef(fit_1)), \"Intercept\")\nstopifnot(length(term_names) == 1)         # qui ci aspettiamo un solo coefficiente: \"mom_hsDiplomata\"\n\nb_name &lt;- paste0(\"b_\", term_names)         # es. \"b_mom_hsDiplomata\"\n\ndr &lt;- as_draws_df(fit_1)\n\n# Quantità di interesse\npost &lt;- dr %&gt;%\n  transmute(\n    mu0   = b_Intercept,         # media del gruppo di riferimento (Non diplomata)\n    delta = .data[[b_name]],     # differenza vs referenza: (Diplomata - Non diplomata)\n    mu1   = b_Intercept + delta, # media del gruppo \"Diplomata\"\n    sigma = sigma,\n    d     = delta / sigma\n  )\n\nSESOI &lt;- 5\nposterior::summarise_draws(post[, c(\"mu0\",\"mu1\",\"delta\",\"d\",\"sigma\")])\n#&gt; # A tibble: 5 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu0      77.570 77.559 2.030 2.016 74.205 80.885 1.000 3811.388 2972.604\n#&gt; 2 mu1      89.308 89.307 1.063 1.066 87.602 91.079 1.000 3931.890 2780.415\n#&gt; 3 delta    11.737 11.787 2.309 2.309  7.911 15.506 1.000 4154.701 3119.643\n#&gt; 4 d         0.591  0.593 0.118 0.120  0.395  0.783 1.000 4130.593 3034.413\n#&gt; 5 sigma    19.894 19.868 0.702 0.709 18.780 21.073 1.000 3713.284 3095.218\n\nc(\n  P_delta_gt0    = mean(post$delta &gt; 0),          # Pr(Δ &gt; 0 | dati)\n  P_absDelta_gtS = mean(abs(post$delta) &gt; SESOI)  # Pr(|Δ| &gt; 5 | dati)\n)\n#&gt;    P_delta_gt0 P_absDelta_gtS \n#&gt;          1.000          0.999\n\nCome leggere i risultati:\n\nmu0 e mu1 sono le medie di gruppo stimate (con incertezza).\ndelta è la differenza media \\((\\mu_1-\\mu_0)\\); d è la versione standardizzata.\n\nLe due probabilità a posteriori rispondono a domande pratiche:\n\n\n\\(\\Pr(\\Delta&gt;0\\mid\\text{dati})\\): quanto è plausibile che i figli di madri diplomate abbiano un QI medio maggiore?\n\n\\(\\Pr(|\\Delta|&gt;\\text{SESOI}\\mid\\text{dati})\\): quanto è plausibile che la differenza superi 5 punti (soglia di rilevanza scelta)?",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#approfondimenti-bayesiani",
    "href": "chapters/linear_models/08_two_means.html#approfondimenti-bayesiani",
    "title": "64  Confronto tra le medie di due gruppi",
    "section": "\n64.6 Approfondimenti bayesiani",
    "text": "64.6 Approfondimenti bayesiani\nFinora abbiamo stimato la differenza tra i gruppi e le relative probabilità a posteriori. Qui vediamo come controllare l’adeguatezza del modello e, se serve, raffinarlo. Usiamo tre strumenti: (1) verifiche predittive a posteriori (PPC), (2) verifiche a priori, (3) confronto predittivo tra modelli.\n\n64.6.1 1) Posterior predictive checks (PPC)\nL’idea è semplice: il modello dovrebbe essere in grado di rigenerare dati simili a quelli osservati.\n\n# Verifica globale (densità osservata vs replicata dal modello)\npp_check(fit_1)   # default: dens_overlay\n\n\n\n\n\n\n\nCosa guardare.\n\n\nForma: la distribuzione simulata copre quella osservata? Ci sono code o asimmetrie non riprodotte?\n\n64.6.2 2) Verifica predittiva a priori\n\nServe a controllare se le prior producono dati plausibili prima di vedere i dati.\n\npri &lt;- c(\n  prior(normal(90, 20), class = \"Intercept\"),  # scala QI\n  prior(normal(0, 15),  class = \"b\"),          # differenza attesa moderata\n  prior(student_t(3, 0, 20), class = \"sigma\")\n)\n\nfit_prior &lt;- brm(\n  kid_score ~ mom_hs,\n  data = kidiq,\n  family = gaussian(),\n  prior = pri,\n  sample_prior = \"only\",       # ignora i dati: simula dai prior\n  backend = \"cmdstanr\",\n  chains = 2, iter = 1000, seed = 123\n)\n\n\npp_check(fit_prior, ndraws = 100)\n\n\n\n\n\n\n\nInterpretazione: se i dati simulati a priori cadono in range irrealistici (es. molti QI &lt; 30 o &gt; 180), le prior vanno allineate alla conoscenza di dominio.\n\n64.6.3 3) Varianti del modello (quando i PPC suggeriscono limiti)\nCode pesanti / outlier → t di Student:\n\nfit_t &lt;- brm(kid_score ~ mom_hs, family = student(), data = kidiq,\n               backend = \"cmdstanr\", chains = 4, iter = 2000, seed = 123)\n\nVarianze diverse per gruppo → eteroscedastico:\n\nfit_het &lt;- brm(bf(kid_score ~ mom_hs, sigma ~ mom_hs),\n                 family = gaussian(),  data = kidiq,\n                 backend = \"cmdstanr\", chains = 4, iter = 2000, seed = 123)\n\nAsimmetria → skew-normal:\n\nfit_sn &lt;- brm(kid_score ~ mom_hs, family = skew_normal(), data = kidiq,\n              backend = \"cmdstanr\", chains = 4, iter = 2000, seed = 123)\n\nDopo l’eventuale rifit, ripeti i PPC (globali e per gruppo).\n\n64.6.4 4) Confronto predittivo tra modelli (LOO/ELPD)\nScegliamo il modello che predice meglio nuovi dati simili a quelli osservati.\n\nloo_fit1  &lt;- loo(fit_1)\nloo_fit_t &lt;- loo(fit_t)\nloo_fit_het &lt;- loo(fit_het)\nloo_fit_sn  &lt;- loo(fit_sn)\n\nloo_compare(loo_fit1, loo_fit_t, loo_fit_het, loo_fit_sn)\n#&gt;         elpd_diff se_diff\n#&gt; fit_sn   0.0       0.0   \n#&gt; fit_het -6.0       5.9   \n#&gt; fit_1   -7.4       5.3   \n#&gt; fit_t   -8.8       5.5\n\nNel confronto tra modelli, un modello migliore è caratterizzato da un valore di ELPD più elevato. Quando la differenza nell’ELPD è paragonabile al suo errore standard (se_diff), il vantaggio predittivo può considerarsi modesto; in tali circostanze, è preferibile adottare il modello più semplice che superi le posterior predictive checks. È inoltre opportuno verificare i parametri di forma Pareto \\(k\\): qualora numerosi valori superino la soglia di 0.7, si raccomanda di impiegare la procedura di reloo o di ricorrere alla validazione incrociata k-fold.\nNel caso in esame, il confronto mediante LOO indica un lieve vantaggio predittivo del modello basato sulla distribuzione skew-normal rispetto alle alternative gaussiane, sia omoscedastiche che eteroscedastiche, nonché rispetto al modello con distribuzione t di Student. Tuttavia, le differenze nell’ELPD sono dell’ordine di grandezza dell’errore standard, pertanto l’evidenza a favore della skew-normal risulta moderata. Le posterior predictive checks mostrano un migliore allineamento delle code e della struttura di asimmetria nel caso della skew-normal; per questo motivo, tale modello viene adottato come specificazione principale, affiancandolo da un’analisi di sensibilità delle stime di \\(\\Delta\\) rispetto alle diverse assunzioni di likelihood. Il modesto vantaggio del modello eteroscedastico rispetto all’omoscedastico suggerisce la presenza di differenze nella variabilità tra gruppi, sebbene l’impatto predittivo di tale eterogeneità sia contenuto.\nIn sintesi, il criterio dell’ELPD favorisce il modello skew-normal, sebbene con differenze esigue rispetto alle alternative. La scelta del modello deve essere giustificata congiuntamente in base a: (i) compatibilità predittiva mediante LOO, (ii) esito delle posterior predictive checks, e (iii) robustezza delle quantità sostantive di interesse, quali \\(\\Delta\\), \\(\\Pr(\\Delta &gt; 0)\\) e \\(\\Pr(|\\Delta| &gt; \\text{SESOI})\\). Quando le differenze predittive sono esigue, la stabilità di \\(\\Delta\\) tra diverse specificazioni diventa un elemento cruciale per l’interpretazione sostantiva dei risultati.\nQuesto approccio consente di mantenere l’analisi trasparente e riproducibile, collegando le stime ottenute a domande di ricerca concrete—attraverso l’uso di smallest effect sizes of interest (SESOI)—senza introdurre soglie arbitrarie di significatività.\n\n\n\n\n\n\nDiagnostica MCMC (workflow minimo)\n\n\n\nControllare sistematicamente: Rhat ≈ 1.00, ESS adeguati, assenza di divergenze e E-BFMI bassi; ispezionare pairs() per funnel. Se necessario, aumentare adapt_delta (es. 0.95–0.99) e max_treedepth (es. 15).\n\n\n\n\n\n\n\n\nApprofondimento statistico (opzionale)\n\n\n\n\n\nConsideriamo ora le basi statistiche su cui si basa l’approccio frequentista. Nel paradigma frequentista, l’inferenza sulla differenza tra due gruppi si basa sulla distribuzione campionaria della differenza tra le medie. L’idea di fondo è che, se ripetessimo il campionamento molte volte, otterremmo valori diversi per la differenza tra le medie campionarie, e questa variabilità può essere descritta attraverso una distribuzione probabilistica.\nSupponiamo di avere due popolazioni normali e indipendenti:\n\\[\nY_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1^2) \\quad \\text{e} \\quad Y_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2^2)\n\\]\ne di osservare due campioni indipendenti, rispettivamente di dimensione \\(n_1\\) e \\(n_2\\).\nSe assumiamo inoltre che le varianze siano uguali (\\(\\sigma_1^2 = \\sigma_2^2 = \\sigma^2\\)), possiamo utilizzare una versione semplificata del modello.\nStatistica di interesse. Il nostro obiettivo è stimare la differenza tra le medie delle due popolazioni, ovvero:\n\\[\n\\mu_1 - \\mu_2.\n\\]\nLa stima di questa quantità è data dalla differenza tra le medie campionarie:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2.\n\\]\nProprietà della statistica campionaria.\nValore atteso. Nel caso di due campioni indipendenti:\n\\[\nE(\\bar{Y}_1 - \\bar{Y}_2) = \\mu_1 - \\mu_2.\n\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nSi parte dalla definizione di media campionaria per ciascun gruppo e si applica la linearità dell’operatore valore atteso:\n\\[\nE(\\bar{Y}_1 - \\bar{Y}_2) = E(\\bar{Y}_1) - E(\\bar{Y}_2) = \\mu_1 - \\mu_2.\n\\]\n\n\n\nVarianza. La varianza della differenza tra le medie campionarie è:\n\\[\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}.\n\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nPoiché i due campioni sono indipendenti, la varianza della differenza si ottiene sommando le varianze delle due medie:\n\\[\n\\operatorname{Var}(\\bar{Y}_1) = \\frac{\\sigma_1^2}{n_1}, \\quad \\operatorname{Var}(\\bar{Y}_2) = \\frac{\\sigma_2^2}{n_2}\n\\]\nquindi:\n\\[\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}.\n\\]\n\n\n\nSe assumiamo varianze uguali (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)), possiamo scrivere:\n\\[\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\sigma^2 \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right).\n\\]\nPoiché \\(\\sigma^2\\) è sconosciuta, la si stima tramite la varianza pooled:\n\\[\ns_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2},\n\\]\ndove \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie:\n\\[\ns_j^2 = \\frac{1}{n_j - 1} \\sum_{i=1}^{n_j} (y_{j,i} - \\bar{y}_j)^2, \\quad j = 1,2.\n\\]\nDistribuzione della statistica. Sotto l’ipotesi di normalità e indipendenza, e assumendo varianze uguali, la statistica \\(\\bar{Y}_1 - \\bar{Y}_2\\) segue (almeno approssimativamente) una distribuzione normale:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2 \\sim \\mathcal{N} \\left( \\mu_1 - \\mu_2,\\ \\sigma \\sqrt{ \\frac{1}{n_1} + \\frac{1}{n_2} } \\right).\n\\]\nQuesta proprietà permette di costruire un intervallo di confidenza al 95% per la differenza tra le medie, oppure di effettuare un test t di Student per due campioni indipendenti, basato sulla seguente statistica:\n\\[\nt = \\frac{(\\bar{Y}_1 - \\bar{Y}_2) - (\\mu_1 - \\mu_2)}{s_p \\sqrt{ \\frac{1}{n_1} + \\frac{1}{n_2} }}.\n\\]\nQuesta statistica segue, sotto l’ipotesi nulla \\(\\mu_1 = \\mu_2\\), una distribuzione t di Student con \\(n_1 + n_2 - 2\\) gradi di libertà.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#per-concludere-oltre-la-media-del-gruppo",
    "href": "chapters/linear_models/08_two_means.html#per-concludere-oltre-la-media-del-gruppo",
    "title": "64  Confronto tra le medie di due gruppi",
    "section": "Per concludere: oltre la media del gruppo",
    "text": "Per concludere: oltre la media del gruppo\nIl confronto tra medie di gruppo, sebbene utile per domande generali a livello di popolazione, si rivela uno strumento insufficiente per descrivere la complessità dei processi psicologici. Questi processi sono intrinsecamente dinamici, evolvono nel tempo e variano in modo significativo da un individuo all’altro. La stima di una semplice differenza media tende a fondere traiettorie individuali eterogenee in un unico valore, confondendo le differenze tra i soggetti con le fluttuazioni interne a ciascuno di essi. La sua interpretazione, inoltre, poggia su assunzioni spesso non verificate, come l’omogeneità degli effetti tra tutti i partecipanti e la stazionarietà delle relazioni nel tempo, presupposti che sono strettamente collegati al concetto di ergodicità.\nAnche l’approccio bayesiano, che pure offre il vantaggio di quantificare l’incertezza attraverso distribuzioni a posteriori e di integrare conoscenze pregresse, non supera questi limiti se applicato in modo riduttivo. Un modello bayesiano che si limiti a riassumere un fenomeno con una singola media di gruppo rimane cieco di fronte all’eterogeneità tra gli individui e alla non-stazionarietà temporale. La letteratura metodologica recente sottolinea infatti come un valore medio possa mascherare una realtà fatta di ampie differenze individuali, dove persino piccoli sottogruppi con effetti marcati e opposti possono coesistere annullandosi a vicenda.\nLa direzione da seguire, pertanto, implica il passaggio a una modellazione più ricca ed esplicita. È metodologicamente opportuno formulare modelli in grado di rappresentare sia le variazioni inter-individuali degli effetti, sia i cambiamenti intra-individuali nel tempo. Nella pratica, questo si traccia in quattro direzioni operative. Primo, la modellazione gerarchica dell’eterogeneità, con intercette e pendenze variabili, affiancata dalla reportazione dell’intera distribuzione degli effetti individuali. Secondo, la rappresentazione della dinamica temporale, che richiede disegni di ricerca longitudinali ad alta risoluzione, come l’EMA, e l’uso di modelli con parametri tempo-varianti. Terzo, una rigorosa valutazione predittiva dei modelli, condotta attraverso strumenti come i posterior predictive checks e il confronto basato sull’ELPD. Quarto, una reportazione trasparente e completa che includa sistematicamente le stime della varianza tra soggetti, la descrizione delle dinamiche temporali e le metriche di performance predittiva.\nIn sintesi, se il confronto tra medie rappresenta un punto di partenza utile per descrivere differenze aggregate, la comprensione delle traiettorie individuali, del ruolo del contesto e del cambiamento nel tempo—temi propri della psicologia—esige l’adozione di modelli gerarchici e dinamici, progettati con un’adeguata risoluzione temporale e valutati in base alla loro capacità predittiva e descrittiva della varianza individuale.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         bayestestR_0.17.0     cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        tzdb_0.5.0            haven_2.5.5          \n#&gt; [22] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [25] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [28] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [31] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [34] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [37] R.utils_2.13.0        pacman_0.5.1          readr_2.1.5          \n#&gt; [40] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [43] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [46] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [49] pkgbuild_1.4.8        plyr_1.8.9            lattice_0.22-7       \n#&gt; [52] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [55] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [58] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [61] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [64] hms_1.1.3             rstantools_2.5.0      scales_1.4.0         \n#&gt; [67] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [70] tools_4.5.1           data.table_1.17.8     forcats_1.0.0        \n#&gt; [73] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [76] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [79] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [82] V8_7.0.0              gtable_0.3.6          R.methodsS3_1.8.2    \n#&gt; [85] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [88] farver_2.1.2          R.oo_1.27.1           memoise_2.0.1        \n#&gt; [91] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#bibliografia",
    "href": "chapters/linear_models/08_two_means.html#bibliografia",
    "title": "64  Confronto tra le medie di due gruppi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_effect_size.html",
    "href": "chapters/linear_models/09_effect_size.html",
    "title": "65  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "",
    "text": "Introduzione\nNel capitolo precedente abbiamo esaminato la differenza nei punteggi di QI tra bambini nati da madri con e senza diploma di scuola superiore. L’analisi bayesiana ci ha permesso di ottenere una distribuzione a posteriori per questa differenza, da cui derivano inferenze probabilistiche ricche e sfumate. Ma un interrogativo cruciale rimane aperto: questa differenza è importante?\nIn psicologia, come in molte scienze applicate, non è sufficiente stabilire che un effetto esiste: bisogna valutare se l’effetto ha una magnitudine sufficiente da avere rilevanza teorica, clinica o sociale. È in questa prospettiva che si introduce il concetto di grandezza dell’effetto (effect size), una misura quantitativa dell’intensità di un risultato.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_effect_size.html#introduzione",
    "href": "chapters/linear_models/09_effect_size.html#introduzione",
    "title": "65  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "",
    "text": "Panoramica del capitolo\n\nChe cosa misuriamo quando parliamo di “grandezza dell’effetto”.\nCome stimarlo con modelli bayesiani in brms.\nCome comunicarlo con intervalli e predizioni.\n\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere “Bayesian estimation supersedes the t test” (Kruschke, 2013).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, brms, bayestestR, insight)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_effect_size.html#perché-stimare-la-grandezza-delleffetto",
    "href": "chapters/linear_models/09_effect_size.html#perché-stimare-la-grandezza-delleffetto",
    "title": "65  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "\n65.1 Perché stimare la grandezza dell’effetto",
    "text": "65.1 Perché stimare la grandezza dell’effetto\nLa grandezza dell’effetto fornisce un ponte tra analisi statistica e interpretazione sostanziale dei dati. Essa consente di rispondere a domande come:\n\nQuanto è marcata la differenza osservata?\nL’effetto ha un impatto concreto nella vita reale o nelle applicazioni cliniche?\nLa variazione osservata è sufficiente a giustificare interventi, cambiamenti o nuove ipotesi teoriche?\n\nL’American Psychological Association (APA) raccomanda di riportare sempre una misura di grandezza dell’effetto, in quanto essa fornisce un’informazione critica che va oltre la mera dicotomia “effetto presente / effetto assente”.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_effect_size.html#standardizzare-le-differenze-il-d-di-cohen",
    "href": "chapters/linear_models/09_effect_size.html#standardizzare-le-differenze-il-d-di-cohen",
    "title": "65  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "\n65.2 Standardizzare le differenze: il d di Cohen",
    "text": "65.2 Standardizzare le differenze: il d di Cohen\nNel confronto tra due gruppi, una delle misure più comuni di grandezza dell’effetto è il d di Cohen, che esprime la differenza tra due medie in unità di deviazione standard:\n\\[\nd = \\frac{\\mu_1 - \\mu_2}{\\sigma},\n\\]\ndove:\n\n\n\\(\\mu_1\\) e \\(\\mu_2\\) sono le medie dei due gruppi,\n\n\\(\\sigma\\) è una stima comune della deviazione standard.\n\nL’interpretazione di d è indipendente dalle unità di misura originali, il che la rende particolarmente utile per confrontare risultati provenienti da diversi studi o contesti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_effect_size.html#il-d-di-cohen-in-unottica-bayesiana",
    "href": "chapters/linear_models/09_effect_size.html#il-d-di-cohen-in-unottica-bayesiana",
    "title": "65  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "\n65.3 Il d di Cohen in un’ottica bayesiana",
    "text": "65.3 Il d di Cohen in un’ottica bayesiana\nNell’approccio bayesiano non ci limitiamo a stimare un singolo valore di d. L’idea è diversa: costruiamo una distribuzione a posteriori di valori plausibili per la grandezza dell’effetto. Questa distribuzione si ottiene combinando i campioni posteriori della differenza tra gruppi con quelli della deviazione standard residua. In questo modo, invece di una stima unica, otteniamo un quadro completo delle incertezze ancora presenti dopo aver osservato i dati.\n\n65.3.1 Esempio pratico con brms\n\nRiprendiamo il modello già stimato nel capitolo precedente:\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\nfit_1 &lt;- brm(\n  kid_score ~ mom_hs, \n  data = kidiq, \n  backend = \"cmdstanr\",\n  silent = 0\n)\n\nDai campioni posteriori estraiamo sia la stima della differenza tra i gruppi (b_mom_hs) sia la stima della deviazione standard residua (sigma). Dividendo i due otteniamo i campioni della distribuzione di Cohen’s d:\n\npost &lt;- as_draws_df(fit_1)\nd_samples &lt;- post$b_mom_hs / post$sigma\n\n\n65.3.2 Visualizzare la distribuzione di d\n\nLa distribuzione a posteriori di d si può esplorare graficamente. Ad esempio:\n\nmcmc_areas(as_draws_df(tibble(d = d_samples)), pars = \"d\", prob = 0.89) \n\n\n\n\n\n\n\nIl grafico mostra l’intero intervallo di valori plausibili per la grandezza dell’effetto, mettendo in evidenza la regione che contiene l’89% degli esiti più credibili. È una rappresentazione diretta dell’incertezza che rimane anche dopo aver osservato i dati.\n\n65.3.3 Statistiche riassuntive\nPer sintetizzare numericamente i risultati si può usare la funzione describe_posterior():\n\nbayestestR::describe_posterior(d_samples, ci = 0.89)\n#&gt; Summary of Posterior Distribution\n#&gt; \n#&gt; Parameter | Median |       89% CI |   pd |          ROPE | % in ROPE\n#&gt; --------------------------------------------------------------------\n#&gt; Posterior |   0.59 | [0.39, 0.79] | 100% | [-0.10, 0.10] |        0%\n\nQuesta funzione restituisce la stima centrale (media o mediana), l’intervallo di credibilità, e la probabilità che la grandezza dell’effetto superi o resti al di sotto di valori soglia rilevanti.\n\n65.3.4 Interpretare la grandezza dell’effetto\nNella tradizione frequentista è comune adottare la classificazione proposta da Cohen:\n\n\nValore di d\n\nInterpretazione convenzionale\n\n\n\n≈ 0.2\nEffetto piccolo\n\n\n≈ 0.5\nEffetto medio\n\n\n≥ 0.8\nEffetto grande\n\n\n\nQueste soglie sono utili come orientamento, ma rischiano di essere applicate in modo meccanico. L’approccio bayesiano offre un vantaggio importante: consente di trasformare queste soglie in domande probabilistiche. Possiamo chiederci, ad esempio, qual è la probabilità che d sia almeno pari a 0.5, oppure la probabilità che resti al di sotto di 0.2. Con i campioni posteriori queste domande trovano risposta diretta:\n\nmean(d_samples &gt; 0.5)  # Probabilità che l'effetto sia almeno medio\n#&gt; [1] 0.772\nmean(d_samples &gt; 0.8)  # Probabilità che l'effetto sia grande\n#&gt; [1] 0.0435\nmean(d_samples &lt; 0.2)  # Probabilità che l'effetto sia trascurabile\n#&gt; [1] 0.00025\n\nIn questo modo non abbiamo un giudizio binario (grande/piccolo), ma una descrizione più sfumata e realistica.\n\n65.3.5 La soglia di rilevanza pratica\nIn applicazioni concrete non è sufficiente stabilire che l’effetto sia diverso da zero: è necessario valutare se supera una soglia di rilevanza pratica (minimum effect of interest, o ROPE — region of practical equivalence).\nSupponiamo, per esempio, che uno psicologo clinico ritenga irrilevante qualsiasi effetto inferiore a d = 0.3. In questo caso, la domanda da porsi è: qual è la probabilità che l’effetto osservato sia superiore a 0.3? La risposta si ottiene immediatamente dai campioni posteriori:\n\nmean(d_samples &gt; 0.3)\n#&gt; [1] 0.992\n\nQuesto numero esprime in modo diretto la probabilità che la differenza osservata abbia una rilevanza clinica concreta, spostando l’attenzione da soglie arbitrarie a valutazioni fondate sulle esigenze specifiche del contesto.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_effect_size.html#riflessioni-conclusive",
    "href": "chapters/linear_models/09_effect_size.html#riflessioni-conclusive",
    "title": "65  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLe linee guida dell’American Psychological Association (APA) sottolineano l’importanza di riportare sistematicamente le stime della dimensione dell’effetto (effect size) nella comunicazione dei risultati della ricerca. Questa raccomandazione nasce dalla consapevolezza che la mera verifica di ipotesi, spesso concentrata su un valore di probabilità, fornisce un’informazione limitata. La stima dell’effect size, al contrario, consente di quantificare la magnitudine di un fenomeno, offrendo una base più solida per valutarne la rilevanza teorica o applicativa. L’identificazione di un effetto statisticamente rilevante rappresenta dunque solo un primo passo; la sua reale interpretazione scientifica richiede una comprensione approfondita della sua entità.\nNell’ambito della statistica frequentista, la dimensione dell’effetto viene tipicamente comunicata attraverso una stima puntuale corredata da un intervallo di confidenza. Quest’ultimo descrive la variabilità attesa della stima in un’ipotetica sequenza di replicazioni dello studio. Sebbene utile, questa rappresentazione può incoraggiare, anche involontariamente, un’interpretazione dicotomica dei risultati, dove l’attenzione si concentra esclusivamente sul superamento di una soglia di significatività.\nL’inferenza bayesiana propone una prospettiva alternativa, trattando la dimensione dell’effetto non come un parametro fisso ma come una variabile aleatoria. La sua incertezza viene rappresentata attraverso una distribuzione di probabilità a posteriori, che sintetizza l’evidenza proveniente dai dati osservati e dalle conoscenze preliminari, formalizzate in una distribuzione a priori. Questo quadro concettuale permette di formulare affermazioni probabilistiche dirette sull’effect size, come calcolare la probabilità che esso superi una determinata soglia di rilevanza clinica o teorica. L’incertezza viene così rappresentata in modo continuo e sfumato, evitando categorizzazioni rigide.\nQuesto approccio si adatta particolarmente bene all’indagine dei processi psicologici, caratterizzati da un’elevata complessità e variabilità. L’obiettivo dell’analisi bayesiana non è quello di giungere a una conclusione definitiva, ma di aggiornare in modo coerente e trasparente il grado di plausibilità associato a diverse ipotesi. In questo contesto, la stima della dimensione dell’effetto assume un ruolo centrale, diventando uno strumento inferenziale per valutare la credibilità e l’importanza pratica dei risultati ottenuti.\nAdottare una prospettiva bayesiana significa quindi abbracciare un paradigma inferenziale che privilegia la valutazione probabilistica e contestualizzata rispetto alla decisione dicotomica. Questo passaggio favorisce una comunicazione scientifica più ricca e meno ambigua, contribuendo a una psicologia maggiormente riflessiva, trasparente e focalizzata sul significato sostanziale dei propri risultati.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         bayestestR_0.17.0     cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      ggridges_0.5.7        compiler_4.5.1       \n#&gt; [10] reshape2_1.4.4        systemfonts_1.2.3     vctrs_0.6.5          \n#&gt; [13] stringr_1.5.1         pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] rmarkdown_2.29        tzdb_0.5.0            haven_2.5.5          \n#&gt; [22] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [25] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [28] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [31] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [34] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [37] R.utils_2.13.0        pacman_0.5.1          readr_2.1.5          \n#&gt; [40] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [43] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [46] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [49] pkgbuild_1.4.8        plyr_1.8.9            lattice_0.22-7       \n#&gt; [52] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [55] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [58] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [61] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [64] hms_1.1.3             rstantools_2.5.0      scales_1.4.0         \n#&gt; [67] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [70] tools_4.5.1           data.table_1.17.8     forcats_1.0.0        \n#&gt; [73] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [76] datawizard_1.2.0      colorspace_2.1-1      nlme_3.1-168         \n#&gt; [79] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [82] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [85] R.methodsS3_1.8.2     digest_0.6.37         TH.data_1.1-4        \n#&gt; [88] htmlwidgets_1.6.4     farver_2.1.2          R.oo_1.27.1          \n#&gt; [91] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [94] MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_effect_size.html#bibliografia",
    "href": "chapters/linear_models/09_effect_size.html#bibliografia",
    "title": "65  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_sample_size.html",
    "href": "chapters/linear_models/10_sample_size.html",
    "title": "66  Pianificazione della dimensione campionaria",
    "section": "",
    "text": "Introduzione\nIn un contesto bayesiano, l’obiettivo principale non è verificare un’ipotesi nulla, ma stimare con quanta incertezza possiamo affermare che un effetto ha una certa ampiezza pratica. Questo approccio è particolarmente rilevante in psicologia, dove l’importanza di un risultato raramente si esaurisce nella sua “significatività statistica”.\nTuttavia, nella pratica scientifica è ancora diffuso l’uso della potenza frequentista. Per completezza, in questo capitolo presentiamo sia la formula classica per la potenza in un confronto tra due medie, sia una sua controparte bayesiana basata su simulazione. Il nostro scopo è mostrare come un approccio bayesiano orientato alla stima e alla simulazione possa offrire strumenti più flessibili, informativi e utili alla pianificazione degli studi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_sample_size.html#introduzione",
    "href": "chapters/linear_models/10_sample_size.html#introduzione",
    "title": "66  Pianificazione della dimensione campionaria",
    "section": "",
    "text": "Panoramica del capitolo\n\nPresentare la definizione frequentista di potenza e il calcolo classico della dimensione campionaria.\nDiscutere i limiti della potenza (soglie arbitrarie, stime imprecise, false certezze).\nIntrodurre l’approccio bayesiano, basato su criteri di precisione e utilità pratica delle stime.\nMostrare l’uso della simulazione generativa per valutare in anticipo l’informatività di uno studio.\nFornire strumenti per pianificare campioni che producano risultati solidi e interpretabili in psicologia.\n\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nConsultare Regression and Other Stories (Gelman et al., 2021).\nPrestare particolare attenzione al capitolo 16, “Design and sample size decisions”, che offrono una guida dettagliata al tema del potere statistico frequentista che spesso genera aspettative irrealistiche sulla rilevabilità degli effetti e conduce alla progettazione di studi con elevata variabilità e scarso valore informativo.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice, brms, cmdstanr)\n\n\n\n\n\n\n\n\n\n\nCollegamento con ROS\n\n\n\n\n\nNel capitolo 16 di Regression and Other Stories (Gelman et al., 2021) viene illustrato l’approccio frequentista alla pianificazione campionaria, basato sul calcolo della potenza. In questo capitolo riprendiamo quel punto di partenza ma allarghiamo la prospettiva:\n\n\ncontinuità: riconosciamo il ruolo della potenza come strumento tradizionale di progettazione degli studi;\n\nestensione: mostriamo come, in ottica bayesiana, la pianificazione si concentri non sul p-value ma sulla precisione delle stime e sulla loro utilità pratica;\n\nstrumenti aggiuntivi: introduciamo la simulazione generativa, che permette di verificare, prima della raccolta dati, se un disegno è in grado di produrre risultati realmente informativi.\n\nIn questo modo gli studenti possono collocare quanto vedranno qui come un passo successivo e complementare rispetto a ROS.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_sample_size.html#lapproccio-frequentista",
    "href": "chapters/linear_models/10_sample_size.html#lapproccio-frequentista",
    "title": "66  Pianificazione della dimensione campionaria",
    "section": "\n66.1 L’approccio frequentista",
    "text": "66.1 L’approccio frequentista\nNel framework frequentista, la potenza è definita come la probabilità, calcolata prima che uno studio venga condotto, che un determinato test statistico produca un p-value inferiore a una soglia prestabilita (tipicamente 0,05), dato un effetto reale ipotizzato.\nIl calcolo della potenza richiede:\n\nuna stima della dimensione dell’effetto atteso,\nuna stima della variabilità nei dati (deviazione standard),\nuna decisione sulla soglia di significatività,\ne infine un calcolo (o simulazione) della probabilità che il p-value sia &lt; 0.05.\n\nSi sconsiglia in genere di condurre studi con potenza bassa, perché hanno una bassa probabilità di produrre risultati “significativi”. Tuttavia, questo ragionamento non considera che il concetto stesso di significatività può essere fuorviante: anche quando un test ha potenza dell’80%, ciò non garantisce che l’effetto stimato sia preciso o utile.\n\n\n\n\n\n\nPerché non basta l’80% di potenza? Uno studio con potenza dell’80% può comunque produrre risultati distorti: gli effetti osservati tendono a essere esagerati (errore di tipo M, magnitude), o addirittura sbagliati nel segno (errore di tipo S, sign). Questo accade perché la potenza misura solo la probabilità di ottenere p &lt; .05, non la precisione né l’utilità pratica delle stime.\n\n\n\n\n66.1.1 La maledizione del vincitore\nUno studio con bassa potenza può produrre risultati statisticamente significativi che sono ingannevoli. In presenza di molto rumore, gli effetti significativi osservati tendono a essere:\n\n\nesagerati (errore di tipo \\(M\\), magnitude),\n\nsbagliati nel segno (errore di tipo \\(S\\), sign).\n\nIn altre parole, anche quando uno studio riesce a “scoprire” un effetto, la stima ottenuta può essere gravemente distorta. Questa è una delle ragioni principali per cui molti risultati pubblicati si rivelano non replicabili (Gelman & Carlin, 2014).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_sample_size.html#un-esempio-concreto",
    "href": "chapters/linear_models/10_sample_size.html#un-esempio-concreto",
    "title": "66  Pianificazione della dimensione campionaria",
    "section": "\n66.2 Un esempio concreto",
    "text": "66.2 Un esempio concreto\nPer rendere il confronto più chiaro, usiamo un esempio con gli stessi dati in entrambi gli approcci:\n\ndifferenza vera tra le medie: \\(\\Delta = 5\\);\ndeviazione standard comune: \\(\\sigma = 10\\);\ndimensione del campione: \\(n = 64\\) per gruppo;\neffetto standardizzato: Cohen’s d = 0.5\n\n\n\n66.2.1 Analisi frequentista: dimensione del campione per potenza dell’80%\nPer stimare la dimensione del campione necessaria a ottenere una potenza dell’80% in un confronto tra due gruppi indipendenti (con varianza uguale), possiamo usare la funzione power.t.test() disponibile in R.\nNel nostro esempio ipotizziamo:\n\nuna differenza attesa tra i gruppi pari a \\(\\Delta = 5\\),\nuna deviazione standard comune pari a \\(\\sigma = 10\\),\nun test bilaterale con livello di significatività \\(\\alpha = 0.05\\).\n\n\n66.2.1.1 Calcolo in R\n\n# Calcolo della dimensione campionaria necessaria per 80% di potenza\npower.t.test(\n  delta = 5,        # differenza attesa tra le medie\n  sd    = 10,       # deviazione standard\n  power = 0.8,      # potenza desiderata\n  sig.level = 0.05, # livello di significatività\n  type = \"two.sample\",\n  alternative = \"two.sided\"\n)\n#&gt; \n#&gt;      Two-sample t test power calculation \n#&gt; \n#&gt;               n = 63.8\n#&gt;           delta = 5\n#&gt;              sd = 10\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.8\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\nIl risultato indica che sono necessari circa 64 partecipanti per gruppo per ottenere l’80% di potenza con questi parametri. Tuttavia, come vedremo nella sezione successiva, questo valore non garantisce necessariamente che la stima dell’effetto sarà sufficientemente precisa o utile dal punto di vista decisionale. L’analisi bayesiana ci offrirà uno strumento più flessibile per valutare l’informatività del disegno proposto.\n\n66.2.2 Analisi bayesiana: informatività a posteriori\nNell’approccio bayesiano, non ci si chiede se l’effetto è “significativo” rispetto a una soglia arbitraria, ma quanto è informativo il risultato per prendere decisioni pratiche. In questo contesto, pianificare uno studio significa domandarsi:\n“Con quanti dati il mio modello bayesiano riuscirà a fornire una stima sufficientemente precisa e utile dell’effetto?”\nPer rispondere, possiamo stabilire dei criteri di informatività che riflettano le esigenze del nostro problema. Due criteri possibili sono:\n\nl’intervallo di credibilità all’89% per Cohen’s d ha larghezza ≤ 0.4 (criterio di precisione);\nla probabilità a posteriori che d &gt; 0.3 è ≥ 90% (criterio di utilità pratica).\n\n\n66.2.2.1 Simulazione generativa di uno studio\nPer verificare se un disegno sperimentale con \\(n = 64\\) per gruppo soddisfa questi criteri, possiamo simulare uno studio 100 volte, ogni volta:\n\ngenerando nuovi dati,\nstimando un modello bayesiano,\nvalutando se il risultato è sufficientemente informativo.\n\nDi seguito definiamo la funzione sim_once() che esegue una singola simulazione.\n\n# Funzione per standardizzare su scala z\nstandardise &lt;- function(x) (x - mean(x)) / sd(x)\n\n# Una singola simulazione bayesiana di uno studio\nsim_once &lt;- function(n = 64, mu0 = 100, delta = 5, sigma = 10) {\n\n  # 1. Generazione dei dati\n  y0 &lt;- rnorm(n, mu0, sigma)         # gruppo controllo\n  y1 &lt;- rnorm(n, mu0 + delta, sigma) # gruppo trattamento\n\n  # 2. Standardizzazione\n  dat &lt;- tibble(score = standardise(c(y0, y1)),\n                group = factor(rep(c(\"ctrl\", \"trt\"), each = n)))\n\n  # 3. Stima del modello bayesiano\n  fit &lt;- brm(score ~ group,\n             data = dat,\n             backend = \"cmdstanr\",\n             chains = 2, iter = 1000, warmup = 500,\n             refresh = 0, silent = 0,\n             prior = c(\n               prior(normal(0, 2), class = \"b\"),\n               prior(exponential(2), class = \"sigma\")\n             ))\n\n  # 4. Estrazione dei campioni posteriori e calcolo di Cohen's d\n  post &lt;- as_draws_df(fit)\n  d_smp &lt;- post$b_grouptrt / post$sigma\n\n  # 5. Output: due indici di informatività\n  tibble(\n    CIw89  = diff(quantile(d_smp, c(.055, .945))),  # larghezza IC 89%\n    p_gt03 = mean(d_smp &gt; 0.3)                      # P(d &gt; 0.3)\n  )\n}\n\nEcco cosa succede passo passo:\n\nSimulazione dei dati\n\n  y0 &lt;- rnorm(n, mu0, sigma)\n  y1 &lt;- rnorm(n, mu0 + delta, sigma)\n\n\nSi generano due gruppi di n = 64 osservazioni:\n\nIl gruppo di controllo ha media mu0 = 100.\nIl gruppo trattamento ha media aumentata di delta = 5.\nEntrambi i gruppi hanno la stessa variabilità (sigma = 10).\n\n\nIn pratica: simula un esperimento in cui il trattamento ha un effetto medio di 5 unità.\n\n\nStandardizzazione dei dati\n\n  score = standardise(c(y0, y1))\n\nLe osservazioni dei due gruppi vengono unite e standardizzate (portate su scala z): media = 0, deviazione standard = 1.\n\nQuesto serve a:\n\nrendere i dati comparabili tra simulazioni,\nsemplificare l’interpretazione dei risultati (si lavora su scala standardizzata).\n\n\n\n\nCreazione del dataset\n\n  dat &lt;- tibble(score = ..., group = ...)\n\n\nSi crea una tabella con le variabili:\n\nscore: i dati standardizzati\ngroup: un’etichetta che indica se il dato appartiene al gruppo controllo (ctrl) o trattamento (trt).\n\n\n\n\nStima del modello bayesiano\n\n  fit &lt;- brm(score ~ group, ...)\n\n\nSi stima un modello bayesiano con brms, dove:\n\nla variabile score è prevista dalla variabile group,\nsi usano priori debolmente informativi su effetto (b) e variabilità (sigma).\n\n\nIl coefficiente b_grouptrt stima la differenza media tra i gruppi (sulla scala standardizzata).\n\n\nEstrazione dei campioni posteriori\n\n  post &lt;- as_draws_df(fit)\n  d_smp &lt;- post$b_grouptrt / post$sigma\n\nSi estraggono i campioni dalla distribuzione a posteriori.\nSi calcola Cohen’s d a posteriori dividendo l’effetto stimato per la deviazione standard stimata: d_smp.\n\n\nOutput: due indicatori di informatività\n\n  tibble(\n    CIw89  = diff(quantile(d_smp, c(.055, .945))),\n    p_gt03 = mean(d_smp &gt; 0.3)\n  )\n\n\nCIw89: larghezza dell’intervallo di credibilità all’89% → misura di precisione.\n\np_gt03: proporzione dei campioni a posteriori in cui d &gt; 0.3 → misura di utilità pratica.\n\nIn sintesi, ogni volta che chiami sim_once():\n\nsimuli un nuovo dataset realistico;\nstimi l’effetto del trattamento con un modello bayesiano;\nmisuri quanto è preciso e informativo il risultato.\n\nQuesta funzione è il mattone fondamentale per la simulazione generativa di uno studio: ti permette di verificare, ad esempio, se con n = 64 per gruppo riesci a stimare d in modo sufficientemente utile.\n\n66.2.2.2 Esecuzione della simulazione\nSimuliamo 100 studi indipendenti con n = 64 per gruppo:\n\nset.seed(123)\nres &lt;- bind_rows(replicate(100, sim_once(), simplify = FALSE))\n\nEsaminiamo i risultati della simulazione:\n\nresum &lt;- summarise(res,\n  mean_CI   = mean(CIw89),\n  sd_CI     = sd(CIw89),\n  prop_good = mean(p_gt03 &gt;= 0.9)\n)\nprint(resum)\n#&gt; # A tibble: 1 × 3\n#&gt;   mean_CI  sd_CI prop_good\n#&gt;     &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1   0.570 0.0204      0.33\n\n\n66.2.2.3 Visualizzazione dei risultati\nIl primo grafico mostra la distribuzione delle larghezze degli intervalli di credibilità all’89%, evidenziando quante simulazioni superano la soglia di 0.4. Il secondo mostra quante simulazioni soddisfano il criterio di utilità.\n\n# Grafico 1: distribuzione della larghezza IC89\nggplot(res, aes(x = CIw89)) +\n  geom_histogram(binwidth = 0.02) +\n  geom_vline(xintercept = 0.4) +\n  labs(\n    x = \"Larghezza IC89\",\n    y = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\n# Grafico 2: classificazione delle simulazioni utili/non utili\nggplot(res, aes(x = p_gt03 &gt;= 0.9)) +\n  geom_bar() +\n  scale_x_discrete(labels = c(\"FALSE\" = \"Non utile\", \"TRUE\" = \"Utile\")) +\n  labs(\n    x = \"Criterio: P(d &gt; 0.3) ≥ 0.9\",\n    y = \"Numero di simulazioni\"\n  ) \n\n\n\n\n\n\n\n\n66.2.2.4 Interpretazione dei risultati\n\n\nmean_CI rappresenta la larghezza media dell’intervallo di credibilità all’89%. Nel nostro caso è circa 0.569, quindi troppo ampio per considerare la stima precisa.\n\nprop_good è la proporzione di simulazioni in cui l’evidenza a favore di un effetto pratico d &gt; 0.3 supera il 90%. Con prop_good = 0.1, solo 1 simulazione su 10 soddisfa questo criterio.\n\nConclusione: con n = 64 per gruppo, lo studio simulato è sottodimensionato: raramente produce una stima precisa e utile. Serve un campione più grande (es. n = 80 o n = 100) per raggiungere criteri più severi di informatività.\n\n66.2.2.5 Confronto con la potenza frequentista\nSecondo l’approccio frequentista, n = 64 per gruppo garantisce circa 80% di potenza per d = 0.5. Ma la simulazione bayesiana mostra che:\n\nl’intervallo di credibilità risulta troppo ampio (≈ 0.57);\nl’evidenza utile (P(d &gt; 0.3) ≥ 0.9) si verifica solo nel 10% dei casi.\n\nQuesto evidenzia i limiti della potenza come unico criterio per pianificare gli studi. Anche uno studio “con potenza adeguata” potrebbe produrre risultati imprecisi o non praticabili, e contribuire agli errori di tipo M (esagerazione della stima) o S (errore nel segno dell’effetto).\nIn sintesi, pianificare uno studio non significa garantire il p &lt; .05, ma garantire che la stima sia abbastanza precisa e utile per informare decisioni.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_sample_size.html#riflessioni-conclusive",
    "href": "chapters/linear_models/10_sample_size.html#riflessioni-conclusive",
    "title": "66  Pianificazione della dimensione campionaria",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\n\nL’approccio bayesiano consente di valutare in modo più trasparente quanto i risultati previsti saranno precisi e utili.\nAnche se un disegno ha potenza dell’80%, potrebbe non produrre stime sufficientemente informative.\nLa simulazione bayesiana è uno strumento efficace per esplorare scenari realistici prima di raccogliere dati.\n\nBuona pratica: non fermarti al calcolo della potenza. Definisci criteri di utilità, simula gli studi e verifica se i dati attesi permetteranno davvero di rispondere alla tua domanda.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        mice_3.18.0           pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              nloptr_2.2.1         \n#&gt; [22] ragg_1.5.0            purrr_1.1.0           jomo_2.7-6           \n#&gt; [25] xfun_0.53             glmnet_4.1-10         cachem_1.1.0         \n#&gt; [28] jsonlite_2.0.0        pan_1.9               broom_1.0.9          \n#&gt; [31] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [34] RColorBrewer_1.1-3    rpart_4.1.24          boot_1.3-32          \n#&gt; [37] lubridate_1.9.4       estimability_1.5.1    iterators_1.0.14     \n#&gt; [40] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [43] nnet_7.3-20           Matrix_1.7-4          splines_4.5.1        \n#&gt; [46] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [49] yaml_2.3.10           codetools_0.2-20      processx_3.8.6       \n#&gt; [52] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [55] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [58] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [61] tensorA_0.36.2.1      checkmate_2.3.3       foreach_1.5.2        \n#&gt; [64] stats4_4.5.1          reformulas_0.4.1      distributional_0.5.0 \n#&gt; [67] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [70] scales_1.4.0          minqa_1.2.8           xtable_1.8-4         \n#&gt; [73] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [76] data.table_1.17.8     lme4_1.1-37           mvtnorm_1.3-3        \n#&gt; [79] grid_4.5.1            rbibutils_2.3         QuickJSR_1.8.0       \n#&gt; [82] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [85] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [88] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [91] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [94] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [97] mitml_0.4-5           MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_sample_size.html#bibliografia",
    "href": "chapters/linear_models/10_sample_size.html#bibliografia",
    "title": "66  Pianificazione della dimensione campionaria",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html",
    "href": "chapters/linear_models/11_anova_1via.html",
    "title": "67  ANOVA ad una via",
    "section": "",
    "text": "Introduzione\nNel Capitolo 64 ci siamo concentrati sul confronto tra due gruppi utilizzando una regressione lineare con variabili dummy. Questo approccio ci ha permesso di modellare in modo semplice l’effetto di un fattore binario e di stimare con incertezza l’ampiezza della differenza. Ora estendiamo quella logica al caso in cui il fattore abbia più di due livelli.\nQuesto passaggio ci introduce al cuore dell’ANOVA a una via, che non è altro che un modello lineare con un fattore categoriale a \\(k\\) livelli. In questo contesto, ci interessa capire quanta variabilità nei dati può essere attribuita alle differenze tra gruppi, e quanto invece rimane all’interno dei gruppi stessi. Come sempre in questo manuale, manterremo una lettura orientata all’incertezza e alla variabilità intra- e inter-individuale, trattando l’inferenza come uno strumento per quantificare la credibilità delle ipotesi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#introduzione",
    "href": "chapters/linear_models/11_anova_1via.html#introduzione",
    "title": "67  ANOVA ad una via",
    "section": "",
    "text": "Panoramica del capitolo\n\nFare inferenza sulla media di un campione.\nTrovare le distribuzioni a posteriori usando brms.\nVerificare il modello usando i pp-check plots.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Geocentric models di Statistical rethinking (McElreath, 2020).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, emmeans)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#codifica-del-modello-con-variabili-dummy",
    "href": "chapters/linear_models/11_anova_1via.html#codifica-del-modello-con-variabili-dummy",
    "title": "67  ANOVA ad una via",
    "section": "\n67.1 Codifica del modello con variabili dummy",
    "text": "67.1 Codifica del modello con variabili dummy\nSupponiamo un esperimento con tre gruppi. Per rappresentare questo fattore all’interno di un modello lineare, usiamo due variabili dummy e consideriamo il terzo gruppo come riferimento implicito. Il modello assume la forma:\n\\[\nY_i = \\alpha + \\gamma_1 D_{i1} + \\gamma_2 D_{i2} + \\varepsilon_i\n\\tag{67.1}\\]\ndove:\n\n\n\\(\\alpha\\) è l’intercetta del modello,\n\n\\(\\gamma_1\\) e \\(\\gamma_2\\) sono i coefficienti associati alle variabili dummy,\n\n\\(D_{i1}\\) e \\(D_{i2}\\) indicano l’appartenenza dell’osservazione \\(i\\) ai gruppi 1 e 2, rispettivamente,\n\n\\(\\varepsilon_i\\) è l’errore aleatorio.\n\nLa codifica delle dummy è la seguente:\n\\[\n\\begin{array}{c|cc}\n\\text{Gruppo} & D_{1} & D_{2} \\\\\n\\hline\n1 & 1 & 0 \\\\\n2 & 0 & 1 \\\\\n3 & 0 & 0\n\\end{array}\n\\tag{67.2}\\]\n\n67.1.1 Interpretazione dei parametri\nCon questa codifica, possiamo esprimere le medie di ciascun gruppo come:\n\\[\n\\begin{aligned}\n\\mu_1 &= \\alpha + \\gamma_1 \\\\\n\\mu_2 &= \\alpha + \\gamma_2 \\\\\n\\mu_3 &= \\alpha\n\\end{aligned}\n\\]\nDa cui otteniamo:\n\\[\n\\alpha = \\mu_3, \\quad \\gamma_1 = \\mu_1 - \\mu_3, \\quad \\gamma_2 = \\mu_2 - \\mu_3.\n\\]\nQuindi:\n\n\n\\(\\alpha\\): media del gruppo 3 (riferimento),\n\n\\(\\gamma_1\\): quanto il gruppo 1 si discosta da \\(\\mu_3\\),\n\n\\(\\gamma_2\\): quanto il gruppo 2 si discosta da \\(\\mu_3\\).\n\nIn un’ottica bayesiana, questi coefficienti possono essere pensati come distribuzioni: esprimono quanto crediamo che ciascuna differenza sia plausibile, date le osservazioni. Passiamo ora a una simulazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#simulazione",
    "href": "chapters/linear_models/11_anova_1via.html#simulazione",
    "title": "67  ANOVA ad una via",
    "section": "\n67.2 Simulazione",
    "text": "67.2 Simulazione\nSimuliamo un esperimento con tre condizioni: controllo, psicoterapia1 e psicoterapia2. Ogni gruppo ha una media diversa ma la stessa deviazione standard. Ci interessa modellare la variabilità tra le condizioni e interpretare le differenze in modo probabilistico.\n\nset.seed(123)\n\nn &lt;- 30  # numero di osservazioni per gruppo\n# Medie di ciascun gruppo\nmean_control &lt;- 30\nmean_psico1  &lt;- 25\nmean_psico2  &lt;- 20\n# Deviazione standard comune\nsd_value &lt;- 5\n\n# Generazione dei dati\ncontrollo     &lt;- rnorm(n, mean_control, sd_value)\npsicoterapia1 &lt;- rnorm(n, mean_psico1,  sd_value)\npsicoterapia2 &lt;- rnorm(n, mean_psico2,  sd_value)\n\n# Creazione del data frame\ndf &lt;- data.frame(\n  condizione = rep(c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\"), each = n),\n  punteggio  = c(controllo, psicoterapia1, psicoterapia2)\n)\n\ndf |&gt; head()\n#&gt;   condizione punteggio\n#&gt; 1  controllo      27.2\n#&gt; 2  controllo      28.8\n#&gt; 3  controllo      37.8\n#&gt; 4  controllo      30.4\n#&gt; 5  controllo      30.6\n#&gt; 6  controllo      38.6\n\n\n67.2.1 Esplorazione iniziale\nVisualizziamo le distribuzioni dei punteggi:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = condizione)) +\n  geom_violin(trim = FALSE, color = css_palette$text_primary, linewidth = 0.3) +\n  geom_boxplot(width = 0.22, outlier.shape = NA,\n               color = css_palette$text_primary, fill = scales::alpha(\"white\", 0.55)) +\n  labs(x = \"Condizione sperimentale\", y = \"Punteggio di depressione\") +\n  scale_fill_manuscript(limits = levels(df$condizione), drop = FALSE) +  \n  theme_manuscript() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nCalcoliamo media e deviazione standard per ogni gruppo:\n\ndf |&gt; \n  group_by(condizione) |&gt; \n  summarize(\n    media = mean(punteggio),\n    sd = sd(punteggio)\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   condizione    media    sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 controllo      29.8  4.91\n#&gt; 2 psicoterapia1  25.9  4.18\n#&gt; 3 psicoterapia2  20.1  4.35",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#modello-lineare-con-variabili-dummy",
    "href": "chapters/linear_models/11_anova_1via.html#modello-lineare-con-variabili-dummy",
    "title": "67  ANOVA ad una via",
    "section": "\n67.3 Modello lineare con variabili dummy",
    "text": "67.3 Modello lineare con variabili dummy\nConvertiamo condizione in fattore e definiamo controllo come categoria di riferimento:\n\ndf$condizione &lt;- factor(df$condizione)\ndf$condizione &lt;- relevel(df$condizione, ref = \"controllo\")\ncontrasts(df$condizione)\n#&gt;               psicoterapia1 psicoterapia2\n#&gt; controllo                 0             0\n#&gt; psicoterapia1             1             0\n#&gt; psicoterapia2             0             1\n\nIl modello di regressione con le variabili dummy sarà:\n\\[\nY_i = \\beta_0 + \\beta_1 \\cdot \\text{psicoterapia1}_i + \\beta_2 \\cdot \\text{psicoterapia2}_i + \\varepsilon_i,\n\\]\ndove:\n\n\n\\(\\beta_0\\) è la media del gruppo di controllo;\n\n\\(\\beta_1\\) e \\(\\beta_2\\) sono le differenze tra le rispettive psicoterapie e il gruppo di controllo.\n\n\n67.3.1 Stima del modello\nEseguiamo una prima analisi usando il metodo di massima verosimiglianza:\n\nfm1 &lt;- lm(punteggio ~ condizione, data = df)\n\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)               29.764      0.819   36.33  &lt; 2e-16\n#&gt; condizionepsicoterapia1   -3.873      1.159   -3.34   0.0012\n#&gt; condizionepsicoterapia2   -9.642      1.159   -8.32  1.1e-12\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n\nVerifica delle medie e differenze tra i gruppi:\n\nout &lt;- tapply(df$punteggio, df$condizione, mean)\nout[2] - out[1]  # psicoterapia1 - controllo\n#&gt; psicoterapia1 \n#&gt;         -3.87\nout[3] - out[1]  # psicoterapia2 - controllo\n#&gt; psicoterapia2 \n#&gt;         -9.64",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#contrasti-personalizzati",
    "href": "chapters/linear_models/11_anova_1via.html#contrasti-personalizzati",
    "title": "67  ANOVA ad una via",
    "section": "\n67.4 Contrasti personalizzati",
    "text": "67.4 Contrasti personalizzati\nI contrasti ci permettono di andare oltre il test globale e formulare ipotesi teoriche mirate. Ad esempio:\n\nla media del gruppo controllo è diversa dalla media delle due psicoterapie?\nle due psicoterapie differiscono tra loro?\n\nA questo fine, specifichiamo la seguente matrice dei contrasti:\n\nmy_contrasts &lt;- matrix(c(\n  0.6667,  0,     # controllo\n -0.3333,  0.5,   # psicoterapia1\n -0.3333, -0.5    # psicoterapia2\n), ncol = 2, byrow = TRUE)\n\ncolnames(my_contrasts) &lt;- c(\"Ctrl_vs_PsicoMean\", \"P1_vs_P2\")\nrownames(my_contrasts) &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\n\ncontrasts(df$condizione) &lt;- my_contrasts\n\nAdattiamo il modello:\n\nmod_custom &lt;- lm(punteggio ~ condizione, data = df)\n\nEsaminiamo i coefficienti:\n\nsummary(mod_custom)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)                   25.259      0.473   53.40  &lt; 2e-16\n#&gt; condizioneCtrl_vs_PsicoMean    6.758      1.003    6.73  1.7e-09\n#&gt; condizioneP1_vs_P2             5.770      1.159    4.98  3.2e-06\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n\nInterpretazione dei coefficienti:\n\n\nIntercetta: non rappresenta più una singola media, ma una combinazione lineare dei gruppi.\n\nCtrl_vs_PsicoMean: confronta la media di controllo con la media combinata delle due psicoterapie.\n\nP1_vs_P2: differenza tra le due psicoterapie.\n\nVerifica manuale:\n\n# Controllo - media delle psicoterapie\nout[1] - (out[2] + out[3]) / 2\n#&gt; controllo \n#&gt;      6.76\n\n\n# Psicoterapia1 - Psicoterapia2\nout[2] - out[3]\n#&gt; psicoterapia1 \n#&gt;          5.77",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#estensione-bayesiana-con-brms-e-emmeans",
    "href": "chapters/linear_models/11_anova_1via.html#estensione-bayesiana-con-brms-e-emmeans",
    "title": "67  ANOVA ad una via",
    "section": "\n67.5 Estensione bayesiana con brms e emmeans\n",
    "text": "67.5 Estensione bayesiana con brms e emmeans\n\nUsiamo ora il modello bayesiano:\n\nmod &lt;- brm(punteggio ~ condizione, data = df, backend = \"cmdstanr\")\n\n\nsummary(mod)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: punteggio ~ condizione \n#&gt;    Data: df (Number of observations: 90) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\n#&gt; Intercept                      25.26      0.48    24.33    26.15 1.00     4321\n#&gt; condizioneCtrl_vs_PsicoMean     6.78      1.04     4.73     8.85 1.00     4260\n#&gt; condizioneP1_vs_P2              5.76      1.16     3.49     8.08 1.00     4598\n#&gt;                             Tail_ESS\n#&gt; Intercept                       2937\n#&gt; condizioneCtrl_vs_PsicoMean     2964\n#&gt; condizioneP1_vs_P2              2785\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     4.54      0.34     3.93     5.26 1.00     4287     3279\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nLe medie marginali e i confronti possono essere ottenuti con il pacchetto emmeans:\n\nem &lt;- emmeans(mod, specs = \"condizione\")\nem\n#&gt;  condizione    emmean lower.HPD upper.HPD\n#&gt;  controllo       29.8      28.1      31.4\n#&gt;  psicoterapia1   25.9      24.3      27.5\n#&gt;  psicoterapia2   20.1      18.4      21.7\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nConfronti tra gruppi:\n\npairs(em)  # confronti a coppie\n#&gt;  contrast                      estimate lower.HPD upper.HPD\n#&gt;  controllo - psicoterapia1         3.90      1.70      6.21\n#&gt;  controllo - psicoterapia2         9.65      7.31     12.03\n#&gt;  psicoterapia1 - psicoterapia2     5.76      3.57      8.14\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nContrasti personalizzati:\n\nmy_list &lt;- list(\n  \"Ctrl_vs_PsicoMean\" = c(\n    \"controllo\" = 1, \"psicoterapia1\" = -0.5, \"psicoterapia2\" = -0.5\n  ),\n  \"P1_vs_P2\" = c(\n    \"controllo\" = 0, \"psicoterapia1\" = 1, \"psicoterapia2\" = -1\n  )\n)\n\n\ncontrast(em, method = my_list)\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.77      4.77      8.88\n#&gt;  P1_vs_P2              5.76      3.57      8.14\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\n\n# Visualizzazione\nplot(em)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#riflessioni-conclusive",
    "href": "chapters/linear_models/11_anova_1via.html#riflessioni-conclusive",
    "title": "67  ANOVA ad una via",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nEcco una proposta rivista delle Riflessioni conclusive, che integra il riferimento storico a Fisher e la riflessione critica di McArdle sull’uso dell’ANOVA in psicologia:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#riflessioni-conclusive-1",
    "href": "chapters/linear_models/11_anova_1via.html#riflessioni-conclusive-1",
    "title": "67  ANOVA ad una via",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nL’ANOVA a una via rappresenta un punto di passaggio fondamentale nella storia della statistica. Fisher la introdusse negli anni ’20 per risolvere problemi molto concreti di agricoltura sperimentale: ad esempio, confrontare le rese di diversi fertilizzanti su parcelle di terreno, in cui le variabili erano chiaramente definite e osservabili. In questo contesto, l’ANOVA si rivelò uno strumento elegante per separare la variabilità “tra trattamenti” dalla variabilità “entro trattamenti”.\nIn psicologia, tuttavia, il quadro è radicalmente diverso. Come ha osservato ripetutamente John J. McArdle (ad es. McArdle, 1994), i nostri oggetti di studio sono in larga misura costrutti latenti — ansia, depressione, intelligenza — che non possono essere osservati direttamente come la crescita di una pianta o il peso di un raccolto. Applicare in modo acritico tecniche nate per l’agricoltura rischia quindi di ridurre la complessità dei fenomeni psicologici a semplici confronti tra medie di punteggi osservati.\nQuesto non significa che l’ANOVA non abbia avuto (e non abbia tuttora) un ruolo didattico e applicativo importante: il modello lineare sottostante resta una base utile per introdurre la logica del confronto tra gruppi. Tuttavia, per affrontare in modo adeguato i problemi della psicologia contemporanea, è spesso più appropriato ricorrere a tecniche che modellano esplicitamente la natura latente delle variabili, come l’analisi fattoriale o i modelli a equazioni strutturali. Questi approcci permettono di connettere in modo più diretto le osservazioni empiriche ai costrutti teorici che ci interessano davvero.\nIn sintesi, l’ANOVA è uno strumento storico e concettualmente utile, ma deve essere vista come un trampolino: una tappa di apprendimento che prepara all’uso di modelli più adatti a catturare la complessità dei dati psicologici.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] emmeans_1.11.2-8      bayestestR_0.17.0     cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          insight_1.4.2        \n#&gt; [58] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [61] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [64] glue_1.8.0            tools_4.5.1           data.table_1.17.8    \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#bibliografia",
    "href": "chapters/linear_models/11_anova_1via.html#bibliografia",
    "title": "67  ANOVA ad una via",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcArdle, J. J. (1994). Structural factor analysis experiments with incomplete data. Multivariate Behavioral Research, 29(4), 409–454. https://doi.org/10.1207/s15327906mbr2904_5\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/glm/introduction_glm.html",
    "href": "chapters/glm/introduction_glm.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione esploreremo i modelli statistici che vanno oltre la regressione lineare, ossia quelli che fanno ipotesi distributive non gaussiane per la componente stocastica del modello, considerano una relazione non lineare tra il valore atteso della variabile di risposta e i predittori, e indeboliscono l’assunzione di indipendenza tra le osservazioni.",
    "crumbs": [
      "GLM",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html",
    "href": "chapters/glm/01_logistic_regr.html",
    "title": "68  Regressione logistica con Stan",
    "section": "",
    "text": "Introduzione\nL a regressione logistica è un modello lineare generalizzato che collega variabili indipendenti, quantitative o categoriali, a un esito dicotomico. A differenza della regressione lineare, non modelliamo direttamente la probabilità di successo, ma il suo logit, ossia il logaritmo del rapporto fra odds di successo e odds di insuccesso. Questo passaggio è essenziale perché consente di trattare il modello in forma lineare e, al tempo stesso, garantisce che le probabilità restino confinate tra 0 e 1.\nIn questo capitolo introduciamo la regressione logistica bivariata, cioè un modello con un solo predittore, che può essere continuo o categoriale. L’obiettivo è comprendere come stimare i coefficienti del modello (con approccio bayesiano) e come interpretarli in termini di probabilità, odds ratio e risk ratio. In particolare, vedremo come lo stesso coefficiente possa essere tradotto su più scale interpretative e come il caso con variabile dummy non sia che una specializzazione del modello con predittore continuo.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#introduzione",
    "href": "chapters/glm/01_logistic_regr.html#introduzione",
    "title": "68  Regressione logistica con Stan",
    "section": "",
    "text": "Panoramica del capitolo\n\nspecificare una regressione logistica con un predittore continuo;\ninterpretare i coefficienti sulla scala dei logit, degli odds e delle probabilità, ricavando in modo chiaro le relazioni algebriche tra \\(RD\\), \\(OR\\) e \\(RR\\);\nstimare il modello con approccio frequentista (glm) e bayesiano (brms/Stan), comprendendo l’effetto dei priori e leggendo le distribuzioni a posteriori;\nprodurre predizioni posteriori su una griglia di valori di \\(x\\) e rappresentare l’incertezza con curve e intervalli credibili;\nvalutare l’adeguatezza del modello attraverso i posterior predictive checks.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo dedicato alla regressione statistica di Applied regression analysis and generalized linear models (Fox, 2015).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, cmdstanr, posterior, brms, bayestestR, insight)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#il-modello-di-regressione-logistica",
    "href": "chapters/glm/01_logistic_regr.html#il-modello-di-regressione-logistica",
    "title": "68  Regressione logistica con Stan",
    "section": "\n68.1 Il modello di regressione logistica",
    "text": "68.1 Il modello di regressione logistica\nSupponiamo di osservare \\(n\\) individui, ciascuno con un esito binario \\(y_i \\in \\{0,1\\}\\) e un predittore continuo \\(x_i\\). La regressione logistica specifica che\n\\[\ny_i \\sim \\text{Bernoulli}(p_i), \\qquad\n\\text{logit}(p_i) = \\alpha + \\beta x_i .\n\\] Qui \\(p_i\\) è la probabilità di successo per l’individuo \\(i\\). L’intercetta \\(\\alpha\\) è il log-odds di successo quando \\(x_i=0\\), mentre il coefficiente \\(\\beta\\) rappresenta il cambiamento nei log-odds per ogni unità di incremento in \\(x\\).\nSulla scala degli odds questo significa che\n\\[\n\\text{odds}(x) = \\frac{p(x)}{1-p(x)} = \\exp(\\alpha + \\beta x).\n\\] Confrontando due valori consecutivi, \\(x=a\\) e \\(x=a+1\\), otteniamo\n\\[\n\\frac{\\text{odds}(a+1)}{\\text{odds}(a)} = e^{\\beta}.\n\\] Quindi l’esponenziale di \\(\\beta\\) è l’odds ratio (OR): il fattore moltiplicativo con cui cambiano gli odds per un incremento unitario in \\(x\\). Ad esempio, se \\(\\beta=1.0\\), allora \\(OR \\approx 2.7\\): ogni unità in più di \\(x\\) rende gli odds di successo circa 2.7 volte maggiori.\n\n\n\n\n\n\nPerché \\(e^{\\beta}\\) è l’odds ratio\n\n\n\n\n\nNel modello logistico \\(\\log\\!\\big(\\tfrac{p(x)}{1-p(x)}\\big)=\\alpha+\\beta x\\), l’odds a livello \\(x\\) è \\(\\tfrac{p(x)}{1-p(x)}=\\exp(\\alpha+\\beta x)\\). Consideriamo due valori qualsiasi del predittore, \\(x=a\\) e \\(x=b\\). L’odds ratio che confronta \\(b\\) con \\(a\\) è definito come\n\\[\nOR(b\\,\\text{vs}\\,a)\n=\\frac{\\tfrac{p(b)}{1-p(b)}}{\\tfrac{p(a)}{1-p(a)}}\n=\\frac{\\exp(\\alpha+\\beta b)}{\\exp(\\alpha+\\beta a)}\n=\\exp\\!\\big(\\beta(b-a)\\big).\n\\]\nSe la variazione è unitaria (\\(b=a+1\\)), segue immediatamente che\n\\[\nOR(a+1\\,\\text{vs}\\,a)=\\exp(\\beta).\n\\]\nQuesta identità mostra due fatti chiave. Primo, l’odds ratio dipende solo dalla differenza \\(b-a\\) e non dal livello di partenza \\(a\\): in un modello logistico bivariato l’OR per un incremento fissato è costante lungo l’asse di \\(x\\). Secondo, la scala di misura di \\(x\\) determina l’interpretazione di \\(\\beta\\): se \\(x\\) è una dummy \\(\\{0,1\\}\\), \\(\\beta\\) è il log-odds ratio tra i due gruppi e \\(\\exp(\\beta)\\) è l’OR gruppi; se \\(x\\) aumenta di 10 unità, allora \\(\\exp(10\\beta)\\) è l’OR per un incremento di dieci unità; se \\(x\\) è standardizzato (ad es. z-score), \\(\\exp(\\beta)\\) è l’OR per un incremento di una deviazione standard.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#risk-difference-odds-ratio-e-risk-ratio",
    "href": "chapters/glm/01_logistic_regr.html#risk-difference-odds-ratio-e-risk-ratio",
    "title": "68  Regressione logistica con Stan",
    "section": "\n68.2 Risk difference, odds ratio e risk ratio",
    "text": "68.2 Risk difference, odds ratio e risk ratio\nConsideriamo due valori qualsiasi del predittore, \\(x=a\\) e \\(x=b\\). Indichiamo con\n\\[\np_a = \\text{logit}^{-1}(\\alpha + \\beta a), \\qquad\np_b = \\text{logit}^{-1}(\\alpha + \\beta b)\n\\] le probabilità corrispondenti. Possiamo descrivere la differenza fra i due livelli in tre modi:\n\nRisk difference (RD):\\[\nRD = p_b - p_a .\n\\] È la differenza assoluta fra le due probabilità.\nOdds ratio (OR):\\[\nOR = \\frac{p_b/(1-p_b)}{p_a/(1-p_a)} = \\exp\\!\\bigl(\\beta(b-a)\\bigr).\n\\] Mostra come gli odds cambiano passando da \\(a\\) a \\(b\\).\nRisk ratio (RR):\\[\nRR = \\frac{p_b}{p_a}.\n\\] È il rapporto diretto fra probabilità, usato spesso in ambito epidemiologico.\n\nLe tre misure sono modi diversi, ma coerenti, di esprimere l’effetto del predittore.\n\n68.2.1 Scala delle probabilità e la regola del “dividere per 4”\nLa funzione logistica che lega \\(x\\) a \\(p(x)\\) è\n\\[\np(x) = \\frac{e^{\\alpha + \\beta x}}{1 + e^{\\alpha + \\beta x}}.\n\\] Se consideriamo la variazione di probabilità per un incremento unitario in \\(x\\),\n\\[\n\\Delta p = p(x+1) - p(x),\n\\] vediamo che l’effetto non è costante ma dipende dal livello di \\(x\\). Ai margini della curva, quando \\(p\\) è vicino a 0 o 1, la variazione è minima; nella zona centrale, quando \\(p \\approx 0.5\\), la curva è più ripida e l’effetto massimo.\nLa derivata della funzione logistica è\n\\[\n\\frac{dp}{dx} = \\beta \\, p(x)\\,[1 - p(x)].\n\\] Il termine \\(p(x)(1-p(x))\\) è massimo quando \\(p=0.5\\), e in quel punto vale \\(0.25\\). Quindi la massima variazione di probabilità per unità di \\(x\\) è\n\\[\n\\max \\frac{dp}{dx} = \\frac{\\beta}{4}.\n\\] Questa è la cosiddetta regola del dividere per 4: un metodo semplice per stimare, in prima approssimazione, l’effetto massimo di \\(\\beta\\) sulla scala delle probabilità. Ad esempio, se \\(\\beta=1.0\\), il massimo incremento di probabilità per unità di \\(x\\) è circa 0.25, cioè 25 punti percentuali, quando \\(p=0.5\\). Questa regola non è esatta in generale, ma fornisce un’intuizione immediata dell’ordine di grandezza dell’effetto di \\(\\beta\\) sulla probabilità.\n\n68.2.2 Sintesi\nIl coefficiente \\(\\beta\\) della regressione logistica ha interpretazioni coerenti su scale diverse:\n\nsulla scala logit è la variazione lineare dei log-odds;\n\nsulla scala odds il suo esponenziale è l’odds ratio, il moltiplicatore degli odds;\n\nsulla scala probabilità descrive variazioni non costanti, con massimo effetto pari a circa \\(\\beta/4\\) quando \\(p=0.5\\).\n\nQueste interpretazioni non sono alternative ma complementari: lo stesso coefficiente viene letto in tre linguaggi diversi, offrendo prospettive complementari sul legame tra \\(x\\) e la probabilità di successo.\n\n68.2.3 Visualizzazione delle tre scale\nPer fissare meglio le idee, possiamo rappresentare graficamente l’effetto del coefficiente \\(\\beta\\) sulle tre scale: logit, odds e probabilità. Useremo valori simulati, così da confrontare direttamente i tre casi.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n68.2.3.1 Come leggere i tre grafici\n\n\nScala logit: la relazione con \\(x\\) è lineare. Ogni unità in più di \\(x\\) aumenta i log-odds di \\(\\beta\\).\n\nScala odds: la crescita è esponenziale. Qui \\(\\exp(\\beta)\\) indica di quanto si moltiplicano gli odds per ogni unità aggiuntiva di \\(x\\).\n\nScala probabilità: la curva è sigmoide e rimane sempre tra 0 e 1. L’effetto di \\(\\beta\\) non è costante: è massimo quando \\(p \\approx 0.5\\), e minimo ai margini (quando la curva è piatta).\n\n68.2.4 Interpretazione didattica\nLa regressione logistica descrive una relazione non lineare fra il predittore \\(x\\) e la probabilità di successo \\(p(x)\\). La curva che ne risulta è una sigmoide: per valori molto bassi di \\(x\\) la probabilità si avvicina a 0, per valori molto alti tende a 1, e nella zona centrale varia rapidamente.\nIl segno del coefficiente \\(\\beta\\) determina la direzione dell’effetto. Se \\(\\beta &gt; 0\\), all’aumentare di \\(x\\) crescono log-odds, odds e probabilità: la curva ha pendenza positiva. Se \\(\\beta &lt; 0\\), accade il contrario e la curva decresce.\nLo stesso effetto può essere letto su scale diverse, che offrono prospettive complementari:\n\nsulla scala delle probabilità, si osserva la variazione assoluta di \\(p(x)\\);\n\nsulla scala degli odds, l’effetto è un moltiplicatore costante \\(OR = e^{\\beta}\\) per ogni incremento unitario di \\(x\\);\n\nsulla scala logit, l’effetto si traduce in un incremento lineare costante di \\(\\beta\\) nei log-odds.\n\nUn ulteriore strumento utile è la risk difference (RD), cioè la differenza di probabilità fra due livelli di \\(x\\), e il risk ratio (RR), cioè il loro rapporto. Queste misure, pur non derivando direttamente dal coefficiente come l’odds ratio, offrono un linguaggio più immediato in molti contesti applicativi (per esempio in epidemiologia o psicologia clinica).\nLa forza della regressione logistica sta proprio in questa unificazione: un unico modello produce tre chiavi di lettura — logit, odds e probabilità — che, se usate insieme, permettono di descrivere in modo chiaro e coerente l’impatto di una variabile indipendente su un esito binario.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#esempio-numerico",
    "href": "chapters/glm/01_logistic_regr.html#esempio-numerico",
    "title": "68  Regressione logistica con Stan",
    "section": "\n68.3 Esempio numerico",
    "text": "68.3 Esempio numerico\nSimuliamo dati con un predittore discreto \\(X\\) e una variabile dicotomica \\(Y\\), in cui la probabilità di successo cresce con \\(X\\). Applichiamo quindi la regressione logistica e tracciamo la curva stimata, confrontandola con le proporzioni empiriche osservate.\n\n# Fissiamo il seme per riproducibilità\nset.seed(42)\n\n# Numero di osservazioni\nn &lt;- 1000\n\n# Predittore X: estraiamo numeri interi fra 0 e 9 con uguale probabilità\nX &lt;- sample(0:9, n, replace = TRUE)\n\n# Definiamo una funzione logistica che restituisce plogis(alpha + beta * x),\n# cioè la trasformazione inversa del logit\nlogistic &lt;- function(x, beta0, beta1) plogis(beta0 + beta1 * x)\n\n# Parametri veri del modello usato per simulare i dati\nbeta0 &lt;- -2   # intercetta\nbeta1 &lt;- 1    # coefficiente\n\n# Calcoliamo la probabilità di successo associata a ciascun valore di X\np &lt;- logistic(X, beta0, beta1)\n\n# Generiamo i dati binari (0/1) da una distribuzione binomiale di Bernoulli\nY &lt;- rbinom(n, size = 1, prob = p)\n\n# Creiamo un data frame con i dati simulati\ndf &lt;- tibble::tibble(X = X, Y = Y)\nhead(df)\n#&gt; # A tibble: 6 × 2\n#&gt;       X     Y\n#&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1     0     0\n#&gt; 2     4     1\n#&gt; 3     0     0\n#&gt; 4     8     1\n#&gt; 5     9     1\n#&gt; 6     3     0\n\nStima del modello di regressione logistica con funzione glm():\n\n# family = binomial(link = \"logit\") specifica che usiamo una regressione logistica\nlogit_model &lt;- glm(Y ~ X, data = df, family = binomial(link = \"logit\"))\n\n\n# Creiamo una griglia di valori di X su cui calcolare le probabilità predette\nx_vals &lt;- seq(min(df$X), max(df$X), length.out = 100)\n\n# Data frame per le predizioni\npred_df &lt;- data.frame(X = x_vals)\n\n# Calcoliamo le probabilità predette dal modello (scala di risposta, cioè probabilità)\npred_df$pred &lt;- predict(logit_model, newdata = pred_df, type = \"response\")\n\nGrafico finale:\n\nggplot(df, aes(x = X, y = Y)) +\n  # Per ogni valore di X mostriamo la proporzione empirica di successi (punti blu)\n  stat_summary(fun = mean, geom = \"point\", color = \"blue\") +\n  # Sovrapponiamo la curva logistica stimata dal modello (linea rossa)\n  geom_line(data = pred_df, aes(x = X, y = pred), color = \"red\") +\n  # Etichette degli assi\n  labs(x = \"X\", y = \"Probabilità stimata\")\n\n\n\n\n\n\n\nIn questo esempio i punti blu rappresentano la proporzione empirica di successi per ciascun valore di \\(X\\), mentre la linea rossa mostra la curva logistica stimata dal modello. La forma sigmoide emerge naturalmente e garantisce che le probabilità rimangano sempre comprese tra 0 e 1.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#stima-bayesiana-con-stan",
    "href": "chapters/glm/01_logistic_regr.html#stima-bayesiana-con-stan",
    "title": "68  Regressione logistica con Stan",
    "section": "\n68.4 Stima bayesiana con Stan",
    "text": "68.4 Stima bayesiana con Stan\nFinora abbiamo stimato i coefficienti \\(\\alpha\\) e \\(\\beta\\) con glm(), ottenendo valori puntuali secondo il metodo della massima verosimiglianza. Con Stan possiamo costruire lo stesso modello in chiave bayesiana, specificando priori debolmente informativi. Questo ci consente di ottenere l’intera distribuzione a posteriori dei parametri, invece di un singolo punto stima, e di quantificare direttamente l’incertezza.\nUn dettaglio importante è che i risultati di Stan possono differire leggermente da quelli di glm(). La ragione è proprio la presenza dei priori: anche se scelti molto larghi (qui normal(0, 2.5)), essi esercitano un piccolo “effetto di contrazione” verso lo zero, soprattutto con campioni finiti. In assenza di priori (o con dati molto abbondanti), le due stime coincidono. Questa differenza è didatticamente preziosa, perché mostra come l’approccio frequentista si possa vedere come un caso limite del bayesiano.\n\n68.4.1 Il modello in Stan\nIl modello di regressione logistica per un predittore continuo si scrive così:\n\nstan_code &lt;- '\ndata {\n  int&lt;lower=0&gt; N;           // numero di osservazioni\n  array[N] int&lt;lower=0, upper=1&gt; y;  // esiti (0/1)\n  vector[N] x;              // predittore\n}\nparameters {\n  real alpha;               // intercetta\n  real beta;                // coefficiente di regressione\n}\nmodel {\n  // prior deboli\n  alpha ~ normal(0, 2.5);\n  beta ~ normal(0, 2.5);\n  \n  // verosimiglianza\n  y ~ bernoulli_logit(alpha + beta * x);\n}\ngenerated quantities {\n  real OR = exp(beta);      // odds ratio\n}\n'\n\nQuesto modello assume gli stessi dati simulati nell’esempio precedente. Prepariamo i dati in R:\n\nstan_data &lt;- list(\n  N = nrow(df),\n  y = df$Y,\n  x = df$X\n)\n\nCompiliamo e stimiamo:\n\nmod &lt;- cmdstan_model(write_stan_file(stan_code))\n\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1000, iter_sampling = 2000\n)\n\n\n68.4.2 Risultati\nEsaminiamo ora i coefficienti stimati dal modello bayesiano:\n\nfit$summary(variables = c(\"alpha\",\"beta\",\"OR\"))\n#&gt; # A tibble: 3 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha    -1.721 -1.716 0.171 0.170 -2.012 -1.447 1.003 2673.568 2761.536\n#&gt; 2 beta      0.901  0.899 0.062 0.062  0.802  1.006 1.004 2687.550 2860.012\n#&gt; 3 OR        2.467  2.457 0.154 0.153  2.231  2.735 1.003 2687.550 2860.012\n\nIn uscita otteniamo per ciascun parametro la media posteriore, la deviazione standard e un intervallo credibile. Ad esempio, il coefficiente \\(\\beta\\) ha un intervallo interamente positivo, coerente con la costruzione dei dati, e l’odds ratio risulta ben al di sopra di 1: segno che all’aumentare di \\(X\\) cresce la probabilità di successo.\n\n68.4.3 Interpretazione sulle tre scale\nLe distribuzioni posteriori di \\(\\alpha\\) e \\(\\beta\\) possono essere tradotte nelle tre scale discusse in precedenza.\nScala dei logit. L’intercetta \\(\\alpha\\) rappresenta i log-odds quando \\(x=0\\). Supponiamo, ad esempio, che la posteriore dia \\(\\alpha \\approx -2\\) con CrI 95% [-2.2, -1.8]. Significa che al livello di riferimento la probabilità è bassa. Il coefficiente \\(\\beta\\), centrato intorno a 1 con CrI 95% [0.9, 1.1], indica che ogni unità in più di \\(x\\) aumenta i log-odds di circa un punto.\nScala degli odds. Esponenziando \\(\\beta\\) otteniamo l’odds ratio. Con \\(\\beta \\approx 1\\), la distribuzione posteriore di \\(OR\\) è centrata su 2.7, con CrI ad esempio [2.5, 3.0]. Questo significa che, con altissima probabilità, un incremento unitario di \\(x\\) moltiplica gli odds di successo di circa 2.5–3 volte.\nScala delle probabilità. Applicando la trasformazione logistica, otteniamo \\(p(x) = \\text{logit}^{-1}(\\alpha + \\beta x)\\). Per ogni draw posteriore possiamo calcolare una curva sigmoide: ne risulta un ventaglio di curve plausibili che descrivono l’incertezza. Intorno a \\(p=0.5\\), la pendenza è massima e vale circa \\(\\beta/4\\). Con \\(\\beta \\approx 1\\), ciò corrisponde a un incremento massimo di probabilità di circa 25 punti percentuali per unità di \\(x\\).\n\n68.4.4 Quantità derivate: RD, OR, RR\nPossiamo anche confrontare due valori specifici del predittore, ad esempio \\(x=0\\) e \\(x=1\\), e derivare da ciascun draw posteriore tre misure di interesse:\n\n# Estrazione dei campioni posteriori\npost &lt;- as_draws_df(fit)\n\n# Confronto tra x=0 e x=1\nx_a &lt;- 0\nx_b &lt;- 1\n\npost &lt;- post %&gt;%\n  mutate(\n    p_a = plogis(alpha + beta * x_a),\n    p_b = plogis(alpha + beta * x_b),\n    RD  = p_b - p_a,            \n    OR  = exp(beta * (x_b - x_a)),\n    RR  = p_b / p_a\n  )\n\nposterior_summary &lt;- tibble(\n  quantity = c(\"p_a (x=0)\", \"p_b (x=1)\", \"RD (p_b - p_a)\", \"OR\", \"RR\"),\n  mean     = c(mean(post$p_a), mean(post$p_b),\n               mean(post$RD), mean(post$OR), mean(post$RR)),\n  q2.5     = c(quantile(post$p_a, .025), quantile(post$p_b, .025),\n               quantile(post$RD, .025), quantile(post$OR, .025), quantile(post$RR, .025)),\n  q97.5    = c(quantile(post$p_a, .975), quantile(post$p_b, .975),\n               quantile(post$RD, .975), quantile(post$OR, .975), quantile(post$RR, .975))\n)\n\nposterior_summary\n#&gt; # A tibble: 5 × 4\n#&gt;   quantity        mean  q2.5 q97.5\n#&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 p_a (x=0)      0.153 0.112 0.198\n#&gt; 2 p_b (x=1)      0.307 0.255 0.359\n#&gt; 3 RD (p_b - p_a) 0.153 0.137 0.170\n#&gt; 4 OR             2.47  2.20  2.80 \n#&gt; 5 RR             2.02  1.79  2.32\n\nQui \\(p_a\\) e \\(p_b\\) sono le probabilità predette per i due valori di \\(x\\), la risk difference è la loro differenza assoluta, l’odds ratio corrisponde a \\(e^\\beta\\), e il risk ratio è il rapporto fra probabilità. Tutte queste quantità hanno ora distribuzioni posteriori con i rispettivi intervalli credibili.\n\n68.4.5 Visualizzazione dell’incertezza\nPer rendere più chiara la variabilità delle predizioni, possiamo tracciare alcune curve campionate dalla posteriore, insieme alla curva media:\n\nx_grid &lt;- seq(0, 9, length.out = 100)\n\npred_curves &lt;- post %&gt;%\n  slice_sample(n = 200) %&gt;%\n  mutate(.draw = row_number()) %&gt;%\n  expand_grid(x = x_grid) %&gt;%\n  mutate(p = plogis(alpha + beta * x))\n\npred_mean &lt;- post %&gt;%\n  expand_grid(x = x_grid) %&gt;%\n  group_by(x) %&gt;%\n  summarise(p = mean(plogis(alpha + beta * x)), .groups = \"drop\")\n\nggplot() +\n  geom_line(data = pred_curves, aes(x = x, y = p, group = .draw),\n            alpha = 0.1, color = \"grey\") +\n  geom_line(data = pred_mean, aes(x = x, y = p),\n            color = \"black\", size = 1) +\n  labs(\n    x = \"X\", y = \"Probabilità stimata\"\n  )\n\n\n\n\n\n\n\nIl grafico mostra come i dati sostengano un’intera famiglia di curve logistiche compatibili: la linea nera è la media posteriore, mentre le linee grigie rendono visibile l’incertezza.\n\n68.4.6 Sintesi\nRispetto a glm(), l’approccio bayesiano con Stan fornisce un quadro più ricco e trasparente. Non abbiamo solo un punto stima e un errore standard, ma distribuzioni posteriori per tutti i parametri e le quantità derivate. Ciò ci permette di dire, ad esempio, che con il 95% di probabilità posteriore l’odds ratio si colloca tra 2.5 e 3.0, o che l’incremento massimo di probabilità per unità di \\(x\\) è di circa 25 punti percentuali.\nIn sintesi, la regressione logistica bayesiana non solo replica quanto già visto con l’approccio frequentista, ma lo arricchisce con una rappresentazione completa dell’incertezza e con inferenze direttamente interpretabili in termini probabilistici.\n\n\n\nRiassunto delle stime posteriori sulle tre scale: logit (α, β), odds (OR), probabilità (p ai due livelli scelti, RD e RR), con intervalli credibili al 95%.\n\n\n\n\n\n\nScala\nQuantità\nMedia [CrI 95%]\n\n\n\nLogit\nα (log-odds a x=0)\n-1.721 [-2.068, -1.399]\n\n\nLogit\nβ (incremento di log-odds per +1 in X)\n0.901 [0.787, 1.031]\n\n\nOdds\nOR = exp(β) per +1 in X\n2.467 [2.196, 2.804]\n\n\nProbabilità\np(x=0)\n0.153 [0.112, 0.198]\n\n\nProbabilità\np(x=1)\n0.307 [0.255, 0.359]\n\n\nProbabilità\nRD = p(x=1) - p(x=0)\n0.153 [0.137, 0.170]\n\n\nProbabilità\nRR = p(x=1) / p(x=0)\n2.020 [1.787, 2.320]\n\n\nProbabilità\nPendenza massima ≈ β/4 (a p≈0.5)\n0.225 [0.197, 0.258]",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#collegamento-con-il-caso-a-due-gruppi",
    "href": "chapters/glm/01_logistic_regr.html#collegamento-con-il-caso-a-due-gruppi",
    "title": "68  Regressione logistica con Stan",
    "section": "\n68.5 Collegamento con il caso a due gruppi",
    "text": "68.5 Collegamento con il caso a due gruppi\nSe il predittore \\(x\\) è una variabile dummy, che assume valore 0 in un gruppo e 1 nell’altro, il modello con predittore continuo si riduce esattamente al caso del confronto tra due proporzioni discusso nel capitolo successivo. In quel contesto avevamo:\n\\[\np_{\\text{ref}} = \\text{logit}^{-1}(\\alpha), \\qquad\np_{\\text{work}} = \\text{logit}^{-1}(\\alpha + \\gamma),\n\\] da cui derivano naturalmente\n\\[\nRD = p_{\\text{work}} - p_{\\text{ref}}, \\qquad\nOR = \\exp(\\gamma), \\qquad\nRR = \\frac{p_{\\text{work}}}{p_{\\text{ref}}}.\n\\] Il confronto fra due gruppi, dunque, non è un modello separato ma un’applicazione particolare della regressione logistica generale. Questo ponte concettuale è importante perché mostra come il caso elementare delle due proporzioni si inserisca nello stesso quadro teorico della regressione logistica con predittori continui. Questo collegamento prepara il terreno per il prossimo capitolo, dove il confronto fra due proporzioni sarà analizzato in dettaglio.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#riflessioni-conclusive",
    "href": "chapters/glm/01_logistic_regr.html#riflessioni-conclusive",
    "title": "68  Regressione logistica con Stan",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo introdotto la regressione logistica con un predittore continuo, mostrando come il coefficiente β controlli la pendenza della curva sigmoide che lega il predittore alla probabilità di successo. Abbiamo chiarito che lo stesso effetto può essere interpretato su tre scale diverse, ma coerenti: sulla scala dei logit, come incremento lineare costante; sulla scala degli odds, come moltiplicatore costante dato da \\(e^{\\beta}\\); sulla scala delle probabilità, come variazione non costante che raggiunge il valore massimo in corrispondenza di \\(p=0,5\\), con un’entità approssimabile da \\(\\beta/4\\).\nLe misure di confronto più utilizzate, ovvero risk difference, odds ratio e risk ratio, non sono quindi strumenti separati, ma diversi modi di interpretare lo stesso meccanismo generato dal modello logit. Ciò rende la regressione logistica una cornice unificata e flessibile, in grado di adattarsi a diversi linguaggi applicativi senza perdere coerenza interna.\nAbbiamo anche notato che il confronto fra due gruppi, pur essendo stato discusso in modo più esteso in un capitolo dedicato, è in realtà un caso particolare della stessa logica: una variabile dummy può essere considerata come una versione semplificata di un predittore continuo. Questo collegamento mette in evidenza l’unità concettuale del modello.\nIn conclusione, la regressione logistica permette di modellare un esito binario e di prevedere probabilità sempre comprese tra 0 e 1, offrendo chiavi interpretative sia sul piano delle probabilità assolute sia su quello degli odds e dei logit. Questa stessa struttura può essere estesa a più predittori e a disegni sperimentali più complessi.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] knitr_1.50            glue_1.8.0            insight_1.4.2        \n#&gt;  [4] bayestestR_0.17.0     cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [7] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt; [10] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [13] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [16] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [19] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [22] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [25] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [28] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    zoo_1.8-14            pacman_0.5.1         \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          emmeans_1.11.2-8     \n#&gt; [61] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [64] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [67] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [70] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [73] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [76] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [79] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#bibliografia",
    "href": "chapters/glm/01_logistic_regr.html#bibliografia",
    "title": "68  Regressione logistica con Stan",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFox, J. (2015). Applied regression analysis and generalized linear models. Sage publications.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_one_proportion.html",
    "href": "chapters/glm/02_one_proportion.html",
    "title": "69  Inferenza sulle proporzioni",
    "section": "",
    "text": "Introduzione\nS pesso ci troviamo ad affrontare la necessità di confrontare due gruppi di dati. Mentre nei capitoli precedenti abbiamo considerato il contronto tra le medie di due gruppi indipendenti, nel caso presente ci concentreremo sul confronto tra le proporzioni di due gruppi indipendenti. Per esempio, potrebbe interessarci sapere se la proporzione di un gruppo è maggiore o diversa rispetto a quella di un altro gruppo. Come in precedenza, per effettuare tale confronto, è fondamentale utilizzare un modello statistico, poiché le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.\nAnche nel caso delle proporzioni, il metodo tradizionale per confrontare statisticamente due o più gruppi consiste nell’utilizzare un test di ipotesi. Questo approccio prevede la definizione di un’ipotesi nulla, che tipicamente afferma l’assenza di differenze tra i gruppi, e l’uso di una statistica test per valutare se i dati osservati sono compatibili con tale ipotesi. Se la statistica test supera una soglia prestabilita, l’ipotesi nulla viene rifiutata, suggerendo che esiste una differenza significativa tra i gruppi.\nTuttavia, i test di ipotesi presentano diverse criticità, come vedremo in seguito. Un approccio alternativo e più informativo è quello basato sulla stima anziché sul test dell’ipotesi nulla, fondato sulla probabilità bayesiana piuttosto che su quella frequentista. In questo caso, l’obiettivo non è semplicemente verificare se esiste una differenza tra i gruppi, ma stimare quanto siano effettivamente diversi. Questo metodo è intrinsecamente più informativo, poiché fornisce una stima diretta della differenza tra i gruppi, accompagnata da una misura dell’incertezza associata. Tale incertezza riflette sia la nostra limitata conoscenza dei parametri del modello (incertezza epistemica) sia la variabilità intrinseca del sistema (incertezza aleatoria).\nIn sintesi, mentre i test di ipotesi si concentrano sul rigetto o meno di un’ipotesi nulla, l’approccio basato sulla stima offre una visione più completa e utile, permettendo di quantificare direttamente la differenza tra i gruppi e di valutare l’incertezza associata a tale stima. Questo rende l’analisi più adatta a supportare decisioni informate e basate sui dati.\nIn questo capitolo approfondiremo l’analisi bayesiana per il confronto tra due proporzioni, utilizzando il pacchetto brms in R. L’approccio bayesiano permette di ottenere una descrizione completa della distribuzione a posteriori del parametro di interesse, fornendo informazioni dettagliate sulla sua incertezza e variabilità, oltre a misure intuitive come intervalli di credibilità e probabilità dirette (es. la probabilità che la proporzione del gruppo A sia maggiore di quella del gruppo B).\nPer illustrare i vantaggi dell’approccio bayesiano, confronteremo i risultati con quelli ottenuti tramite l’analisi frequentista tradizionale. Per facilitare l’apprendimento, inizieremo con un caso più semplice: l’inferenza su una singola proporzione. Questo ci permetterà di familiarizzarci con i concetti fondamentali prima di estenderli al confronto tra due gruppi.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_one_proportion.html#introduzione",
    "href": "chapters/glm/02_one_proportion.html#introduzione",
    "title": "69  Inferenza sulle proporzioni",
    "section": "",
    "text": "Panoramica del capitolo\n\nFondamenti dell’inferenza su una proporzione (modello Beta-Binomiale).\nConfronto tra l’approccio frequentista (test e intervalli di confidenza) con quello bayesiano.\nConcetto di ROPE per valutare la significatività pratica, e non solo statistica, di un effetto.\nEstensione al confronto tra due proporzioni.\nLinee guida per la reportistica e la pianificazione.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Learning about a Binomial Probability del testo di Albert & Hu (2019).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, tidyr, broom, tidybayes, scales)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_one_proportion.html#inferenza-su-una-proporzione",
    "href": "chapters/glm/02_one_proportion.html#inferenza-su-una-proporzione",
    "title": "69  Inferenza sulle proporzioni",
    "section": "\n69.1 Inferenza su una proporzione",
    "text": "69.1 Inferenza su una proporzione\nCome esempio per l’inferenza su una proporzione, utilizzeremo i dati dello studio di Brückner & Bearman (2005), discussi anche da Wagenmakers et al. (2010). Nell’articolo After the promise: the STD consequences of adolescent virginity pledges, Brückner & Bearman (2005) analizzano una serie di interviste condotte nell’ambito del National Longitudinal Study of Adolescent Health (Add Health). Lo studio si concentra sul comportamento sessuale di adolescenti, di età compresa tra 18 e 24 anni, che hanno fatto un “virginity pledge”, ovvero una promessa pubblica o scritta di rimanere vergini fino al matrimonio. Studi scientifici indicano che il comportamento sessuale di questi adolescenti non sia statisticamente diverso da quello di chi non ha fatto tale promessa, con l’unica eccezione che i “pledgers” hanno una minore probabilità di utilizzare il preservativo durante il primo rapporto sessuale.\nI dati rilevanti per la nostra analisi sono i seguenti:\n\nsu 777 adolescenti che hanno fatto il “virginity pledge”, 424 (54.6%) hanno dichiarato di aver usato il preservativo durante il primo rapporto sessuale;\nsu 9072 adolescenti che non hanno fatto la promessa, 5416 (59.7%) hanno dichiarato di aver usato il preservativo.\n\n\n69.1.1 Obiettivo dell’analisi\nNella prima analisi, ci concentreremo sul campione di adolescenti che hanno fatto il “virginity pledge”. Ci chiediamo se sia credibile pensare che questi adolescenti tendano ad avere un rapporto protetto, nel loro primo rapporto sessuale, in una proporzione minore di quella che ci si potrebbe aspettare in caso di casualità (ovvero, una proporzione di 0.5).\n\n69.1.2 Analisi frequentista\nIniziamo con un test frequentista usando la funzione prop.test() per confrontare la proporzione osservata con il valore di riferimento 0.5.\n\nprop_test_freq_vol &lt;- prop.test(\n  x = 424,\n  n = 777,\n  p = 0.5\n)\n\ntidy(prop_test_freq_vol)\n#&gt; # A tibble: 1 × 8\n#&gt;   estimate statistic p.value parameter conf.low conf.high\n#&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1    0.546      6.31  0.0120         1    0.510     0.581\n#&gt;   method                                               alternative\n#&gt;   &lt;chr&gt;                                                &lt;chr&gt;      \n#&gt; 1 1-sample proportions test with continuity correction two.sided\n\nL’intervallo di confidenza frequentista non include il valore di riferimento 0.5, quindi, in base a questa analisi, possiamo concludere che la proporzione osservata (0.546) sia maggiore del valore atteso in caso di casualità (0.5).\n\n69.1.3 Approccio bayesiano\nSe utilizziamo dei prior non informativi, ci aspettiamo di giungere alla stessa conclusione anche con un approccio bayesiano. Tuttavia, l’approccio bayesiano ci permette di ottenere una distribuzione completa della probabilità a posteriori del parametro di interesse, offrendo una visione più ricca e flessibile rispetto all’approccio frequentista.\nIniziamo creando un data frame che sarà utilizzato con la funzione brm().\n\npledge_binomial_df &lt;- tibble(\n  n_yes = 424,\n  n_total = 777\n)\n\n# tiny data\npledge_binomial_df\n#&gt; # A tibble: 1 × 2\n#&gt;   n_yes n_total\n#&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1   424     777\n\n\n69.1.3.1 Modello bayesiano\nUtilizziamo un modello di regressione con una funzione link binomiale. Questo significa che stimeremo la proporzione \\(p\\) con un modello di regressione beta-binomiale bayesiano utilizzando brms. Useremo un prior non informativo \\(\\mathcal{Beta}(1, 1)\\). Questo è un modello solo con intercetta, senza altre covariate, poiché siamo interessati solo alla proporzione sottostante, senza condizionarla su altre variabili.\nIl modello può essere rappresentato come segue:\n\\[\n\\begin{aligned}\ny_{\\text{condom\\_use}} &\\sim \\mathcal{Binomial}(n, \\pi) \\\\\n\\pi &= \\beta_0 \\\\\n\\beta_0 &\\sim \\mathcal{Beta}(1, 1)\n\\end{aligned}\n\\]\nEseguiamo l’analisi bayesiana.\n\nmodel_pledge_binomial &lt;- brm(\n  n_yes | trials(n_total) ~ 1,\n  data = pledge_binomial_df,\n  family = binomial(link = \"identity\"),\n  prior = c(prior(beta(1, 1), class = \"Intercept\", lb = 0, ub = 1)),\n  chains = 4, warmup = 1000, iter = 4000, seed = 123,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n\nPoiché questo è un modello di regressione, si comporta come qualsiasi altro modello brms. Il coefficiente per l’intercetta rappresenta la proporzione stimata di adolescenti tra i 18 e i 24 anni che hanno usato il preservativo durante il primo rapporto sessuale nel campione.\n\nsummary(model_pledge_binomial)\n#&gt;  Family: binomial \n#&gt;   Links: mu = identity \n#&gt; Formula: n_yes | trials(n_total) ~ 1 \n#&gt;    Data: pledge_binomial_df (Number of observations: 1) \n#&gt;   Draws: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 12000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     0.55      0.02     0.51     0.58 1.00     3835     5744\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nSi noti come l’intervallo di credibilità al 95% riproduce l’intervallo frequentista calcolato in precedenza.\n\n69.1.4 Confronto tra i due approcci\nConfrontiamo ora i risultati ottenuti dai due approcci. L’analisi frequentista ha mostrato che la proporzione osservata (0.546) è significativamente maggiore del valore di riferimento 0.5. L’approccio bayesiano conferma questa conclusione, fornendo una distribuzione completa della probabilità a posteriori per la proporzione π. Uno dei vantaggi dell’approccio bayesiano è la possibilità di incorporare informazioni a priori, se disponibili, migliorando così la robustezza delle inferenze. Inoltre, l’intervallo di credibilità bayesiano fornisce una descrizione più completa della distribuzione dei parametri, consentendo una migliore interpretazione dei risultati.\n\n69.1.5 Modello Beta-Binomiale e soluzione analitica\nIn questo contesto, il problema può essere modellato utilizzando una distribuzione beta-binomiale, per la quale esiste una soluzione analitica per la distribuzione a posteriori. Il modello beta-binomiale è particolarmente adatto quando si lavora con dati binomiali (ad esempio, successi e fallimenti) e si desidera incorporare una distribuzione a priori coniugata per la proporzione \\(p\\).\n\n69.1.5.1 Contestualizzazione del modello\nPer il gruppo “pledgers”, abbiamo \\(y_1\\) successi su \\(n_1\\) prove. Se assumiamo una distribuzione a priori Beta(\\(\\alpha\\), \\(\\beta\\)), la distribuzione a posteriori per la proporzione \\(p_1\\) sarà anch’essa una distribuzione Beta, data da:\n\\[\np_1 \\mid y_1, n_1 \\sim \\mathcal{Beta}(\\alpha + y_1, \\beta + n_1 - y_1).\n\\]\nNel nostro caso specifico, scegliamo una prior non informativa \\(\\mathcal{Beta}(1, 1)\\), che equivale a una distribuzione uniforme sull’intervallo [0, 1]. Questa scelta riflette l’assenza di informazioni pregresse sulla proporzione \\(p_1\\). Pertanto, la distribuzione a posteriori per il gruppo “pledgers” diventa:\n\\[\np_1 \\mid y_1, n_1 \\sim \\mathcal{Beta}(1 + 424, 1 + 777 - 424) = \\mathcal{Beta}(425, 354).\n\\]\n\n69.1.5.2 Calcolo dell’intervallo di credibilità\nUtilizziamo R per calcolare l’intervallo di credibilità al 95% basato sulla distribuzione a posteriori derivata analiticamente.\n\n# Parametri della distribuzione Beta\na_post &lt;- 425  # Parametro alpha\nb_post &lt;- 354  # Parametro beta\n\n# Calcolo dell'intervallo centrale al 95%\ncredibility_interval &lt;- qbeta(c(0.025, 0.975), shape1 = a_post, shape2 = b_post)\nprint(credibility_interval)\n#&gt; [1] 0.511 0.580\n\nIl risultato ottenuto dall’analisi bayesiana analitica replica quello ottenuto tramite il modello brm() implementato in precedenza. Questo confronto tra approcci dimostra la coerenza tra le tecniche frequentista, bayesiana numerica e bayesiana analitica.\n\n69.1.6 Discussione e confronto tra approcci\nL’utilizzo della distribuzione beta-binomiale e della soluzione analitica offre diversi vantaggi:\n\n\nSemplicità: La soluzione analitica è spesso più semplice da implementare rispetto ai metodi numerici, come quelli utilizzati in brms.\n\nVelocità: I calcoli sono generalmente più veloci poiché non richiedono iterazioni o campionamenti.\n\nInterpretazione: L’uso di distribuzioni coniugate facilita l’interpretazione dei risultati, fornendo direttamente la distribuzione a posteriori senza bisogno di complessi algoritmi di inferenza.\n\nTuttavia, l’approccio bayesiano numerico tramite brms presenta anche vantaggi significativi:\n\n\nFlessibilità: Può gestire modelli più complessi e includere covariate multiple.\n\nPriori informativi: Permette di incorporare facilmente informazioni a priori, se disponibili.\n\nEstensioni: Facilita l’estensione del modello a casi più complessi, come il confronto tra proporzioni di due gruppi.\n\n\n69.1.6.1 Analisi della distribuzione a posteriori\nEssendo un’analisi bayesiana, possiamo lavorare con l’intera distribuzione a posteriori e calcolare direttamente l’estimando, come la differenza tra la proporzione campionaria e la proporzione di riferimento (0.5).\n\npledge_draws &lt;- model_pledge_binomial |&gt; \n  spread_draws(b_Intercept) |&gt; \n  mutate(diff = b_Intercept - 0.5)\n\nVisualizziamo la distribuzione a posteriori della proporzione.\n\np1 &lt;- ggplot(pledge_draws, aes(x = b_Intercept, y = \"Age 18–24\")) + \n  stat_halfeye(fill = \"gray\") +\n  geom_vline(xintercept = 0.5) +\n  scale_x_continuous(labels = label_percent()) +\n  coord_cartesian(ylim = c(1.5, 1.5)) +\n  labs(x = \"Proportion used a condom at first sex\", y = NULL)\np1\n\n\n\n\n\n\n\nIl valore di riferimento (0.5) non è incluso nella distribuzione a posteriori, il che significa che la differenza tra la proporzione campionaria e la proporzione di riferimento non include lo zero, con un livello di credibilità del 95%. Possiamo quindi concludere, con un livello soggettivo di credibilità del 95%, che l’uso del preservativo durante il primo rapporto sessuale sia maggiore del caso, per gli adolescenti che hanno fatto il “virginity pledge”.\n\n69.1.7 La regione di equivalenza pratica\nL’analisi precedente confronta la proporzione osservata con un singolo valore di riferimento (0.5). Un approccio alternativo è considerare un intervallo di valori attorno a 0.5 che possano essere considerati “praticamente equivalenti” al valore di riferimento. Questo intervallo è chiamato Regione di Equivalenza Pratica (ROPE).\nSecondo Kruschke & Liddell (2018), la ROPE può essere definita come un intervallo attorno al valore nullo (baseline) che corrisponde a un decimo della deviazione standard della distribuzione a posteriori del parametro di interesse. Nel nostro caso, il parametro di interesse è la proporzione \\(p\\), e il valore nullo è 0.5. Per calcolare la ROPE, estraiamo i campioni a posteriori dal modello.\n\nposterior_samples &lt;- as_draws_df(model_pledge_binomial)\n\nCalcoliamo la deviazione standard a posteriori di \\(p\\).\n\nposterior_std_dev &lt;- sd(posterior_samples$b_Intercept)\nposterior_std_dev\n#&gt; [1] 0.018\n\nDefiniamo la ROPE come un intervallo attorno al valore di riferimento 0.5.\n\nbaseline &lt;- 0.5  # Valore nullo (baseline)\nrope_low &lt;- baseline - 0.1 * posterior_std_dev\nrope_high &lt;- baseline + 0.1 * posterior_std_dev\n\nCalcoliamo ora la probabilità che la proporzione \\(p\\) si trovi all’interno della ROPE.\n\nrope_probability &lt;-\n  mean(\n    posterior_samples$b_Intercept &gt;= rope_low &\n      posterior_samples$b_Intercept &lt;= rope_high\n  )\nrope_probability\n#&gt; [1] 0.003\n\nVisualizziamo la distribuzione a posteriori di \\(p\\) insieme alla ROPE.\n\nggplot(posterior_samples, aes(x = b_Intercept)) +\n  geom_density(fill = \"gray\", alpha = 0.5) +\n  annotate(\n    geom = \"rect\", \n    xmin = rope_low, \n    xmax = rope_high, \n    ymin = 0, ymax = Inf, \n    fill = \"lightgray\", alpha = 0.2\n  ) +\n  geom_vline(xintercept = baseline, color = \"lightgray\") +\n  scale_x_continuous(labels = scales::percent) +\n  labs(x = \"Proportion used a condom at first sex\", y = \"Density\")\n\n\n\n\n\n\n\nIn conclusione, dato che solo lo 0.325% (meno dell’uno per cento) della distribuzione a posteriori di \\(p\\) si trova nella ROPE, possiamo concludere che ci sono evidenze credibili che la distribuzione a posteriori del parametro \\(p\\) (la proporzione di adolescenti, di età compresa tra 18 e 24 anni, che hanno fatto il “virginity pledge” e hanno usato il preservativo durante il primo rapporto sessuale) sia diversa dal valore di riferimento 0.5. Nel caso specifico, questa proporzione è più alta, indicando che la tendenza ad avere un rapporto protetto è maggiore rispetto al caso di casualità, per questa popolazione.\n\n69.1.7.1 Discussione\nL’utilizzo della ROPE offre una prospettiva aggiuntiva nell’interpretazione delle inferenze bayesiane. Invece di semplicemente determinare se un parametro è statisticamente significativo rispetto a un valore di riferimento, la ROPE permette di valutare se le differenze osservate siano praticamente rilevanti in termini di impatto reale.\n\n\nSoglia di rilevanza: L’impostazione di una ROPE consente di stabilire una soglia di rilevanza pratica. Se la maggior parte della distribuzione a posteriori cade al di fuori della ROPE, possiamo concludere che la differenza è non solo statistica ma anche pratica.\n\nInterpretazione clinica: Nelle applicazioni pratiche, come in ambito medico o sociale, la ROPE aiuta a distinguere tra risultati statisticamente significativi ma clinicamente insignificanti e quelli che hanno un impatto rilevante.\n\nNel contesto dello studio sui “pledgers”, l’uso della ROPE fornisce una valutazione più completa della tendenza degli adolescenti a utilizzare il preservativo durante il primo rapporto sessuale, dimostrando che questa tendenza è non solo statisticamente diversa dal caso di casualità, ma anche significativa dal punto di vista pratico.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_one_proportion.html#inferenza-sulla-differenza-tra-due-proporzioni",
    "href": "chapters/glm/02_one_proportion.html#inferenza-sulla-differenza-tra-due-proporzioni",
    "title": "69  Inferenza sulle proporzioni",
    "section": "\n69.2 Inferenza sulla differenza tra due proporzioni",
    "text": "69.2 Inferenza sulla differenza tra due proporzioni\nEstendiamo ora l’analisi precedente per confrontare le proporzioni di due gruppi, un compito per il quale non esiste una soluzione analitica semplice. Nello studio in esame, ci poniamo la domanda: Fino a che punto l’analisi statistica supporta l’ipotesi che i “pledgers” abbiano una minore probabilità rispetto ai “non-pledgers” di usare il preservativo durante il primo rapporto sessuale?\nPer testare questa ipotesi utilizzando brms, estendiamo il modello bayesiano includendo due gruppi: i pledgers (che hanno fatto il voto di astinenza) e i non-pledgers (che non lo hanno fatto). L’obiettivo è stimare la differenza tra le due proporzioni e valutare se questa sia credibilmente diversa da zero.\nCostruiamo un tibble con i dati relativi ai due gruppi:\n\npledge_data &lt;- tibble(\n  group = c(\"pledgers\", \"nonpledgers\"),\n  n_yes = c(424, 5416),   # Numero di partecipanti che hanno usato il preservativo\n  n_total = c(777, 9072)  # Totale dei partecipanti per ciascun gruppo\n)\nprint(pledge_data)\n#&gt; # A tibble: 2 × 3\n#&gt;   group       n_yes n_total\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 pledgers      424     777\n#&gt; 2 nonpledgers  5416    9072\n\n\n69.2.1 Modello bayesiano per il confronto tra proporzioni\nIn questo modello, adottiamo un approccio bayesiano per analizzare la differenza nell’utilizzo del preservativo tra due gruppi distinti: i “pledgers” (chi ha sottoscritto l’impegno) e i “non-pledgers” (chi non lo ha sottoscritto). La struttura del modello si basa sulla distribuzione binomiale, appropriata per dati che rappresentano conteggi di successi su un numero fisso di prove.\nSpecifica del modello. Il modello assume che il numero di utilizzi del preservativo in ciascun gruppo segua una distribuzione binomiale:\n\\[\ny_i \\sim \\text{Binomial}(n_i, \\theta_i)\n\\]\ndove:\n\n\n\\(y_i\\) è il numero di utilizzi del preservativo nel gruppo \\(i\\),\n\n\\(n_i\\) è il numero totale di individui nel gruppo \\(i\\),\n\n\\(\\theta_i\\) è la probabilità di utilizzo del preservativo nel gruppo \\(i\\).\n\nModellazione delle probabilità. La relazione tra i gruppi viene modellata attraverso una specificazione lineare sulla probabilità stessa (utilizzando un link identità):\n\\[\n\\theta_i = \\beta_0 + \\beta_1 \\cdot x_i,\n\\]\ndove:\n\n\n\\(x_i\\) è una variabile indicatrice che vale 0 per i non-pledgers e 1 per i pledgers,\n\n\\(\\beta_0\\) rappresenta la probabilità di utilizzo del preservativo nel gruppo di riferimento (non-pledgers),\n\n\\(\\beta_1\\) rappresenta la differenza assoluta nella probabilità di utilizzo tra pledgers e non-pledgers.\n\nScelta dei prior. La specificazione dei prior riflette le nostre conoscenze a priori sui parametri:\n\nPer \\(\\beta_0\\) (probabilità base nei non-pledgers): utilizziamo un prior Beta(1,1), equivalente a una distribuzione uniforme tra 0 e 1, che rappresenta un’assenza di informazioni specifiche sulla probabilità attesa\nPer \\(\\beta_1\\) (differenza tra gruppi): utilizziamo un prior normale con media 0 e deviazione standard 1, che assegna probabilità decrescenti a differenze maggiori in valore assoluto, pur mantenendo la possibilità di effetti in entrambe le direzioni\n\nImplementazione pratica. L’implementazione del modello in brms utilizza la seguente sintassi:\n\nmodel_pledge_diff &lt;- brm(\n  formula = n_yes | trials(n_total) ~ group,  # Specifica della risposta binomiale\n  data = pledge_data,                         # Dataset contenente i dati\n  family = binomial(link = \"identity\"),       # Link identità per interpretazione diretta\n  prior = c(\n    prior(beta(1, 1), class = \"Intercept\", lb = 0, ub = 1),  # Prior per la probabilità base\n    prior(normal(0, 1), class = \"b\")                         # Prior per l'effetto del gruppo\n  ),\n  chains = 4,                 # Quattro catene Markoviane\n  warmup = 1000,              # 1000 iterazioni di burn-in per catena\n  iter = 4000,                # 4000 iterazioni totali per catena\n  seed = 123,                 # Seed per riproducibilità\n  refresh = 0,                # Nessun output intermedio\n  backend = \"cmdstanr\"        # Motore di inferenza efficiente\n)\n\n\n69.2.2 Risultati\nEsaminiamo il sommario del modello per valutare la stima della differenza tra le proporzioni:\n\nsummary(model_pledge_diff)\n#&gt;  Family: binomial \n#&gt;   Links: mu = identity \n#&gt; Formula: n_yes | trials(n_total) ~ group \n#&gt;    Data: pledge_data (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 12000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept         0.60      0.01     0.59     0.61 1.00    13571     9174\n#&gt; grouppledgers    -0.05      0.02    -0.09    -0.01 1.00     3602     4230\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nPer interpretare meglio i risultati, estraiamo i campioni a posteriori per la differenza tra le due proporzioni:\n\npledge_diff_draws &lt;- model_pledge_diff |&gt; \n  spread_draws(b_Intercept, b_grouppledgers) |&gt; \n  mutate(\n    nonpledgers_prop = b_Intercept,  # Stima della proporzione nei non-pledgers\n    pledgers_prop = b_Intercept + b_grouppledgers,  # Stima della proporzione nei pledgers\n    diff = nonpledgers_prop - pledgers_prop  # Differenza tra le due proporzioni\n  )\n\nVisualizziamo la distribuzione a posteriori della differenza:\n\np3 &lt;- ggplot(pledge_diff_draws, aes(x = diff)) + \n  stat_halfeye(fill = \"gray\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  scale_x_continuous(labels = label_percent()) +\n  labs(x = \"Differenza nella proporzione di utilizzo del preservativo\", \n       y = \"Densità a posteriori\") \nprint(p3)\n\n\n\n\n\n\n\nCalcoliamo la probabilità che la differenza tra le proporzioni sia maggiore di zero:\n\ndiff_probability &lt;- mean(pledge_diff_draws$diff &gt; 0)\nprint(diff_probability)\n#&gt; [1] 0.998\n\n\n69.2.2.1 Interpretazione\nLa probabilità calcolata è 0.997; ciò significa che c’è una probabilità del 99.7% che la proporzione di non-pledgers che usano il preservativo sia maggiore rispetto a quella dei pledgers. Questo supporta con elevata credibilità l’ipotesi che i pledgers abbiano meno probabilità di utilizzare il preservativo durante il primo rapporto sessuale.\nPossiamo quindi concludere che la differenza tra le due proporzioni è credibilmente diversa da zero, con un’elevata probabilità a favore dell’ipotesi che i pledgers abbiano una minore propensione all’uso del preservativo rispetto ai non-pledgers. Questi risultati riproducono quelli riportati dalla letteratura precedente, come discusso da Brückner & Bearman (2005).",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_one_proportion.html#riflessioni-conclusive",
    "href": "chapters/glm/02_one_proportion.html#riflessioni-conclusive",
    "title": "69  Inferenza sulle proporzioni",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo esaminato il modello bayesiano binomiale per lo studio delle proporzioni, associato alla distribuzione Beta come prior coniugata. Questa scelta si rivela particolarmente vantaggiosa, in quanto la distribuzione a posteriori mantiene la forma Beta, il che permette di calcolare facilmente medie, varianze, intervalli di credibilità e distribuzioni predittive per le osservazioni future.\nLa distribuzione Beta offre una notevole flessibilità nella specificazione della prior, che può essere calibrata in base al contesto e alle conoscenze preesistenti. La distribuzione \\(\\mathcal{Beta}(1, 1)\\), per esempio, corrisponde a una distribuzione uniforme e rappresenta un approccio deliberatamente non informativo. La distribuzione Beta con parametri 2, 2 concentra la massa di probabilità attorno al valore 0,5 e risulta appropriata quando si prevede una proporzione centrale. Al contrario, la distribuzione Beta con parametri \\(a=0.5\\) e \\(b=0.5\\) attribuisce maggiore probabilità ai valori estremi, vicini cioè a 0 o 1, ed è quindi indicata in contesti in cui sono plausibili eventi rari o frequenze molto elevate. Se sono disponibili dati storici o evidenze precedenti, è possibile determinare i parametri a e b in modo da rispecchiare una stima precedente della proporzione e il grado di certezza associato.\nL’approccio bayesiano permette di basare le decisioni su valutazioni probabilistiche direttamente collegate agli interrogativi della ricerca. In questo modo, è possibile stimare, in termini di probabilità, la superiorità di una proporzione rispetto a una soglia di riferimento, la sua equivalenza pratica entro un intervallo predefinito o la sua non inferiorità rispetto a un margine clinico. Tali probabilità, essendo espresse in modo continuo e intuitivo, forniscono un supporto decisionale più informativo e sfumato rispetto al rigetto o all’accettazione dell’ipotesi nulla.\nIl modello binomiale si basa sull’ipotesi di indipendenza tra le osservazioni e di costanza della probabilità di successo. Qualora i dati mostrino una variabilità superiore a quella prevista (ovvero, sovradispersione) o provengano da popolazioni eterogenee, è necessario considerare delle estensioni del modello, come il modello Beta-Binomiale o i modelli a struttura gerarchica. I posterior predictive check costituiscono uno strumento fondamentale per valutare se le previsioni del modello sono in linea con i dati osservati e offrono un riscontro pratico sulla bontà dell’adattamento.\nUn ulteriore vantaggio dell’impostazione bayesiana emerge nella fase di progettazione dello studio. Attraverso apposite simulazioni, è possibile stimare la probabilità che, a partire da un determinato campione, si riesca a ottenere una conclusione rilevante, come ad esempio che la proporzione superi una determinata soglia con un determinato livello di credibilità. Questa probabilità, nota come “assurance bayesiana”, rappresenta un’alternativa più realistica al concetto di potenza statistica di stampo frequentista, in quanto incorpora esplicitamente l’incertezza sui parametri prima ancora della raccolta dei dati.\nNella comunicazione di un’analisi basata su una proporzione, è opportuno includere tre elementi fondamentali: In primo luogo, è cruciale presentare una stima della proporzione, espressa tramite la media o la mediana della distribuzione a posteriori, corredata da un intervallo di credibilità che ne quantifichi l’incertezza. In secondo luogo, è utile calcolare e riportare la probabilità che la proporzione superi una determinata soglia di interesse clinico o pratico o che ricada all’interno di un intervallo di equivalenza pratica (ROPE). Infine, la distribuzione predittiva a posteriori consente di anticipare i possibili esiti in campioni futuri e di rispondere direttamente alla domanda su cosa ci si possa aspettare dalle osservazioni successive. Questi tre aspetti permettono di superare la logica dicotomica del valore-\\(p\\), offrendo risposte più ricche e pertinenti alle domande della ricerca applicata.\nIn sintesi, l’approccio bayesiano al confronto delle proporzioni supera la logica semplicistica di un verdetto binario, consentendo di stimare direttamente le differenze, quantificare l’incertezza in termini probabilistici, formulare previsioni verificabili e supportare processi decisionali complessi. Per gli psicologi, ciò si traduce nella possibilità di trarre conclusioni più calibrate, più informative e più saldamente ancorate alle reali domande di ricerca.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] scales_1.4.0          broom_1.0.9           bayestestR_0.17.0    \n#&gt;  [4] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [7] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt; [10] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [13] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [16] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [19] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [22] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [25] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [28] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        plyr_1.8.9           \n#&gt; [46] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [55] stats4_4.5.1          insight_1.4.2         distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [61] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [64] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [67] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [70] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [73] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [76] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [79] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [82] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_one_proportion.html#bibliografia",
    "href": "chapters/glm/02_one_proportion.html#bibliografia",
    "title": "69  Inferenza sulle proporzioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBrückner, H., & Bearman, P. (2005). After the promise: The STD consequences of adolescent virginity pledges. Journal of Adolescent Health, 36(4), 271–278.\n\n\nKruschke, J. K., & Liddell, T. M. (2018). Bayesian data analysis for newcomers. Psychonomic Bulletin & Review, 25(1), 155–177.\n\n\nWagenmakers, E.-J., Lodewyckx, T., Kuriyal, H., & Grasman, R. (2010). Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method. Cognitive Psychology, 60(3), 158–189.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html",
    "href": "chapters/glm/03_two_proportions.html",
    "title": "70  Confronto tra due proporzioni con la regressione logistica",
    "section": "",
    "text": "Introduzione\nI mmaginiamo di voler stabilire se due gruppi di persone hanno la stessa probabilità di ottenere un certo risultato, ad esempio la guarigione dopo un trattamento o il superamento di un esame con due diversi metodi di studio. In questi casi l’esito è binario: ogni individuo può avere successo o insuccesso, sì o no, guarito o non guarito. Per analizzare dati di questo tipo possiamo ricorrere alla regressione logistica, un modello che permette di stimare l’effetto del gruppo di appartenenza sulla probabilità di successo.\nQuando i due gruppi sono distinti e indipendenti, il confronto si riduce a una regressione logistica molto semplice, in cui compare un solo predittore binario. In un approccio bayesiano ciò significa che possiamo esprimere in modo esplicito le nostre ipotesi iniziali attraverso distribuzioni a priori e ottenere, come risultato dell’analisi, non un singolo numero ma una distribuzione a posteriori che descrive l’intera gamma dei valori plausibili per i parametri.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#introduzione",
    "href": "chapters/glm/03_two_proportions.html#introduzione",
    "title": "70  Confronto tra due proporzioni con la regressione logistica",
    "section": "",
    "text": "Panoramica del capitolo\n\nComprendere il confronto tra due proporzioni come caso base della regressione logistica.\n\nTradurre i coefficienti logit in probabilità, differenza di rischio, odds ratio e risk ratio.\n\nStimare i parametri con approccio bayesiano tramite brms.\n\nInterpretare le distribuzioni posteriori e l’incertezza delle stime.\n\nEseguire controlli predittivi e visualizzare i risultati.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere l’articolo “Children’s arithmetic skills do not transfer between applied and academic mathematics” (Banerjee et al., 2025).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, cmdstanr, posterior, brms, bayestestR, insight)\n\nconflicts_prefer(dplyr::count)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#perché-usare-la-regressione-logistica-per-confrontare-due-proporzioni",
    "href": "chapters/glm/03_two_proportions.html#perché-usare-la-regressione-logistica-per-confrontare-due-proporzioni",
    "title": "70  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n70.1 Perché usare la regressione logistica per confrontare due proporzioni",
    "text": "70.1 Perché usare la regressione logistica per confrontare due proporzioni\nConfrontare due proporzioni significa chiedersi se la probabilità di successo osservata in un gruppo differisce da quella osservata nell’altro. Se nel gruppo 0 registriamo \\(x_0\\) successi su \\(n_0\\) prove e nel gruppo 1 osserviamo \\(x_1\\) successi su \\(n_1\\) prove, le proporzioni vere possono essere indicate con \\(\\theta_0\\) e \\(\\theta_1\\). La differenza tra le due proporzioni, \\(\\Delta = \\theta_1 - \\theta_0\\), fornisce una misura diretta del divario. Un altro indice spesso utilizzato è l’odds ratio, che confronta il rapporto tra successi e insuccessi in ciascun gruppo.\nLa regressione logistica permette di formalizzare questa idea. Se indichiamo con \\(D_i\\) una variabile che assume valore zero per gli individui del gruppo di riferimento e valore uno per gli individui del gruppo di confronto, possiamo scrivere il modello come\n\\[\ny_i \\sim \\text{Bernoulli}(p_i), \\qquad \\text{logit}(p_i) = \\alpha + \\gamma D_i .\n\\]\nIn questo contesto, l’intercetta \\(\\alpha\\) rappresenta i log-odds del gruppo di riferimento, mentre il coefficiente \\(\\gamma\\) esprime la differenza di log-odds fra i due gruppi, cioè il logaritmo dell’odds ratio. L’esponenziale di \\(\\gamma\\) fornisce infatti l’odds ratio vero e proprio.\nQuesto schema mostra che confrontare due proporzioni equivale a stimare una regressione logistica con un unico predittore dummy, con il vantaggio di ottenere risultati coerenti con modelli più complessi e di poter passare facilmente da una scala all’altra, dalle probabilità agli odds, fino alle differenze o ai rapporti di rischio. In un quadro bayesiano, questo confronto si arricchisce ulteriormente perché le stime vengono fornite sotto forma di distribuzioni a posteriori, permettendo di esprimere direttamente l’incertezza su ciascuna quantità di interesse.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#un-esempio-concreto",
    "href": "chapters/glm/03_two_proportions.html#un-esempio-concreto",
    "title": "70  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n70.2 Un esempio concreto",
    "text": "70.2 Un esempio concreto\nUn’applicazione particolarmente chiara di queste idee si trova nello studio di Banerjee et al. (2025), che ha confrontato le abilità matematiche di due gruppi di bambini in India: da un lato quelli che lavoravano nei mercati di Kolkata e Delhi, dall’altro quelli che frequentavano la scuola senza lavorare. Lo scopo era verificare se le competenze sviluppate nel lavoro quotidiano, come dare il resto o sommare i prezzi, si trasferissero al contesto scolastico e se, viceversa, l’addestramento scolastico potesse essere utile nei problemi pratici del mercato. I risultati hanno mostrato che i bambini lavoratori erano molto abili nei problemi concreti, ma meno preparati in quelli astratti, mentre gli scolarizzati presentavano lo schema opposto.\nConsideriamo i dati relativi ai problemi astratti. Tra i bambini lavoratori si sono registrati 670 successi su 1488 prove, pari a una proporzione di circa 0.45. Tra i bambini scolarizzati i successi sono stati 320 su 542, cioè circa 0.59. La situazione è ancora più marcata nei problemi di mercato: i bambini lavoratori hanno ottenuto 134 successi su 373 prove, pari a 0.36, mentre i bambini scolarizzati hanno risolto solo 3 problemi su 271, cioè appena lo 0.01.\n\n# Successi e denominatori\nx_work   &lt;- 670 ; n_work   &lt;- 1488\nx_non    &lt;- 320 ; n_non    &lt;-  542\n\n# Tabella aggregata per il modello binomiale\ndat_a &lt;- tibble(\n  count = c(x_non,   x_work),   # ordine: riferimento (non-working), poi working\n  tot   = c(n_non,   n_work),\n  group = factor(c(\"non-working\", \"working\"),\n                 levels = c(\"non-working\", \"working\"))\n)\n\ndat_a\n#&gt; # A tibble: 2 × 3\n#&gt;   count   tot group      \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;      \n#&gt; 1   320   542 non-working\n#&gt; 2   670  1488 working",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#un-rapido-controllo",
    "href": "chapters/glm/03_two_proportions.html#un-rapido-controllo",
    "title": "70  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n70.3 Un rapido controllo",
    "text": "70.3 Un rapido controllo\nPrima di impostare il modello bayesiano, può essere utile calcolare in chiave frequentista la differenza osservata fra le due proporzioni, insieme a un intervallo di confidenza. Questo non fa parte del nostro approccio principale, ma consente di verificare che i dati siano coerenti con quelli riportati in letteratura e ci offre un punto di riferimento preliminare.\n\np_non  &lt;- x_non  / n_non\np_work &lt;- x_work / n_work\nrd_obs &lt;- p_non - p_work\n\nalpha  &lt;- 0.05\nse_ci  &lt;- sqrt(p_non*(1-p_non)/n_non + p_work*(1-p_work)/n_work)\nz_crit &lt;- qnorm(1 - alpha/2)\nci_rd  &lt;- c(rd_obs - z_crit*se_ci, rd_obs + z_crit*se_ci)\n\nsprintf(\"Differenza osservata (non-working - working): %.3f (95%% CI: [%.2f, %.2f])\",\n        rd_obs, ci_rd[1], ci_rd[2])\n#&gt; [1] \"Differenza osservata (non-working - working): 0.140 (95% CI: [0.09, 0.19])\"\n\nQuesto rapido controllo conferma che i bambini scolarizzati hanno una proporzione di risposte corrette maggiore rispetto ai bambini lavoratori nei problemi astratti, come già segnalato dagli autori dello studio.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#modello-bayesiano-con-regressione-logistica",
    "href": "chapters/glm/03_two_proportions.html#modello-bayesiano-con-regressione-logistica",
    "title": "70  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n70.4 Modello bayesiano con regressione logistica",
    "text": "70.4 Modello bayesiano con regressione logistica\nPassiamo ora al modello bayesiano. Usiamo il pacchetto brms con backend cmdstanr, in continuità con i capitoli precedenti. Per impostare il modello binomiale con esito aggregato, specifichiamo dei prior debolmente informativi sulla scala logit:\n\npriors &lt;- c(\n  prior(normal(0, 2.5), class = \"Intercept\"),\n  prior(normal(0, 2.5), class = \"b\")\n)\n\nLa stima viene quindi effettuata sul numero di successi in ciascun gruppo, tenendo conto del numero totale di prove, con la variabile categoriale group che distingue fra bambini scolarizzati e bambini lavoratori. Nel gruppo di riferimento, definito come “non-working”, l’intercetta del modello rappresenta i log-odds di successo, mentre il coefficiente associato al predittore misura lo scarto di log-odds del gruppo “working”.\nDopo aver impostato il modello, procediamo alla stima con brms. I dati vengono trattati in forma aggregata, specificando il numero di successi e di prove per ciascun gruppo. Usiamo la famiglia binomiale, fissiamo i prior debolmente informativi sulla scala logit, e chiediamo al campionatore MCMC di esplorare lo spazio dei parametri.\n\nfit_a &lt;- brm(\n  count | trials(tot) ~ group,\n  data         = dat_a,\n  family       = binomial(),\n  prior        = priors,\n  backend      = \"cmdstanr\",\n  seed         = 1234,\n  iter         = 4000, chains = 4, cores = 4,\n  sample_prior = \"yes\",\n  refresh = 0 \n)\n\nUn primo sguardo ai risultati con summary(fit_a) ci mostra i coefficienti stimati sulla scala logit. Tuttavia, per comprendere appieno il significato psicologico e applicativo di questi numeri, è utile trasformarli nelle quantità di maggiore interesse: le probabilità di successo nei due gruppi, la loro differenza, e i rapporti che le mettono a confronto.\n\nsummary(fit_a)\n#&gt;  Family: binomial \n#&gt;   Links: mu = logit \n#&gt; Formula: count | trials(tot) ~ group \n#&gt;    Data: dat_a (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept        0.37      0.09     0.20     0.54 1.00     3230     3722\n#&gt; groupworking    -0.57      0.10    -0.77    -0.37 1.00     3929     3843\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nA partire dall’intercetta otteniamo la probabilità dei bambini scolarizzati (gruppo di riferimento), mentre aggiungendo il coefficiente della variabile dummy otteniamo la probabilità del gruppo dei bambini lavoratori. La differenza fra le due probabilità definisce la risk difference. Il coefficiente della dummy, espresso come esponenziale, corrisponde invece all’odds ratio. Infine, il rapporto fra le probabilità fornisce il risk ratio.\n\npost &lt;- as_draws_df(fit_a) %&gt;%\n  mutate(\n    p_ref   = plogis(b_Intercept),\n    p_work  = plogis(b_Intercept + b_groupworking),\n    RD      = p_work - p_ref,\n    OR      = exp(b_groupworking),\n    RR      = p_work / p_ref\n  )\n\nRiepilogando i valori medi e gli intervalli credibili, possiamo osservare direttamente le stime per ciascuna quantità.\n\npost_summary &lt;- tibble(\n  quantity = c(\"p_ref (non-working)\", \"p_work (working)\", \"RD (work - ref)\", \"OR\", \"RR\"),\n  mean  = c(mean(post$p_ref), mean(post$p_work), mean(post$RD), mean(post$OR), mean(post$RR)),\n  q2.5  = c(quantile(post$p_ref, .025), quantile(post$p_work, .025), quantile(post$RD, .025),\n            quantile(post$OR, .025), quantile(post$RR, .025)),\n  q97.5 = c(quantile(post$p_ref, .975), quantile(post$p_work, .975), quantile(post$RD, .975),\n            quantile(post$OR, .975), quantile(post$RR, .975))\n)\n\npost_summary\n#&gt; # A tibble: 5 × 4\n#&gt;   quantity              mean   q2.5   q97.5\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 p_ref (non-working)  0.591  0.550  0.632 \n#&gt; 2 p_work (working)     0.450  0.425  0.476 \n#&gt; 3 RD (work - ref)     -0.141 -0.188 -0.0918\n#&gt; 4 OR                   0.569  0.465  0.692 \n#&gt; 5 RR                   0.763  0.698  0.834\n\nPer avere un’impressione immediata della direzione degli effetti, possiamo calcolare le probabilità posteriori che le quantità di interesse siano minori o maggiori di valori soglia. In particolare, ci chiediamo con quale probabilità la proporzione dei bambini lavoratori superi quella degli scolarizzati, oppure la differenza di rischio sia negativa, o ancora l’odds ratio e il risk ratio siano inferiori a uno.\n\ntibble(\n  `Pr(p_work &gt; p_ref)` = mean(post$p_work &gt; post$p_ref),\n  `Pr(RD &lt; 0)`         = mean(post$RD &lt; 0),\n  `Pr(OR &lt; 1)`         = mean(post$OR &lt; 1),\n  `Pr(RR &lt; 1)`         = mean(post$RR &lt; 1)\n)\n#&gt; # A tibble: 1 × 4\n#&gt;   `Pr(p_work &gt; p_ref)` `Pr(RD &lt; 0)` `Pr(OR &lt; 1)` `Pr(RR &lt; 1)`\n#&gt;                  &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n#&gt; 1                    0            1            1            1\n\nGli intervalli credibili confermano e quantificano l’incertezza. La probabilità stimata di successo per i bambini scolarizzati ha un intervallo al 95% che si colloca attorno a valori medio-alti, mentre quella dei bambini lavoratori si concentra su valori più bassi. L’intervallo credibile della differenza di rischio è per lo più negativo, suggerendo una minore probabilità di successo nel gruppo dei lavoratori. Lo stesso vale per l’odds ratio, con valori che tendono a collocarsi stabilmente al di sotto dell’unità.\n\nhdi_p_ref   &lt;- bayestestR::hdi(post$p_ref, ci = 0.95)\nhdi_p_work  &lt;- bayestestR::hdi(post$p_work, ci = 0.95)\nhdi_RD_89   &lt;- bayestestR::hdi(post$RD, ci = 0.89)\nhdi_OR_95   &lt;- bayestestR::hdi(post$OR, ci = 0.95)\n\nlist(\n  `95% HDI p_ref`  = hdi_p_ref,\n  `95% HDI p_work` = hdi_p_work,\n  `89% HDI RD`     = hdi_RD_89,\n  `95% HDI OR`     = hdi_OR_95\n)\n#&gt; $`95% HDI p_ref`\n#&gt; 95% HDI: [0.55, 0.63]\n#&gt; \n#&gt; $`95% HDI p_work`\n#&gt; 95% HDI: [0.43, 0.48]\n#&gt; \n#&gt; $`89% HDI RD`\n#&gt; 89% HDI: [-0.18, -0.10]\n#&gt; \n#&gt; $`95% HDI OR`\n#&gt; 95% HDI: [0.46, 0.69]\n\nInterpretare questi risultati significa tradurre le diverse scale. Le proporzioni forniscono una misura intuitiva: nei dati considerati, la probabilità di successo dei bambini scolarizzati si aggira intorno al 59 per cento, mentre quella dei bambini lavoratori è più vicina al 45 per cento. La differenza di rischio, cioè lo scarto fra le due proporzioni, risulta negativa e conferma un divario a sfavore dei lavoratori. L’odds ratio esprime lo stesso fenomeno su un’altra scala: un valore inferiore a uno indica che gli odds di successo dei lavoratori sono più bassi di quelli degli scolarizzati. Il risk ratio, infine, mostra che la probabilità di successo dei lavoratori corrisponde solo a una frazione di quella degli scolarizzati.\nTutte queste trasformazioni raccontano la stessa storia con linguaggi diversi, e lo fanno in modo coerente con quanto osservato nei dati grezzi. Il vantaggio del modello bayesiano è che non ci limita a un’unica stima puntuale, ma ci offre distribuzioni posteriori complete che quantificano l’incertezza e permettono di rispondere a domande probabilistiche dirette, come “quanto è probabile che la differenza di proporzioni sia negativa?” oppure “quanto è probabile che l’odds ratio sia minore di uno?”.\nQuesto capitolo si collega direttamente alla discussione precedente sull’odds ratio. In quel caso avevamo stimato l’indice in modo diretto, come parametro principale di un modello. Qui, invece, vediamo come lo stesso odds ratio emerga naturalmente come trasformazione del coefficiente logit in una regressione con variabile dummy. Le due prospettive non sono in contrasto, ma si integrano: la regressione logistica fornisce un quadro generale dal quale si derivano OR, RR e RD, mentre l’analisi bayesiana dell’odds ratio ci ha mostrato come sia possibile focalizzarsi in modo mirato su un singolo parametro di interesse.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#un-secondo-esempio-i-problemi-di-mercato",
    "href": "chapters/glm/03_two_proportions.html#un-secondo-esempio-i-problemi-di-mercato",
    "title": "70  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n70.5 Un secondo esempio: i problemi di mercato",
    "text": "70.5 Un secondo esempio: i problemi di mercato\nRiprendiamo ora i dati relativi ai problemi di mercato. Qui le differenze tra i due gruppi diventano ancora più evidenti. I bambini lavoratori hanno risolto correttamente 134 problemi su 373, con una proporzione di circa 0.36. I bambini scolarizzati, invece, hanno risposto correttamente solo 3 volte su 271, con una proporzione che sfiora lo zero, appena 0.01. Questo scenario rappresenta una situazione di forte divario, opposta a quella vista nei problemi astratti.\n\n# Dati per i problemi di mercato\nx_work_m &lt;- 134 ; n_work_m &lt;- 373\nx_non_m  &lt;-   3 ; n_non_m  &lt;- 271\n\ndat_m &lt;- tibble(\n  count = c(x_non_m, x_work_m),\n  tot   = c(n_non_m, n_work_m),\n  group = factor(c(\"non-working\", \"working\"),\n                 levels = c(\"non-working\", \"working\"))\n)\n\ndat_m\n#&gt; # A tibble: 2 × 3\n#&gt;   count   tot group      \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;      \n#&gt; 1     3   271 non-working\n#&gt; 2   134   373 working\n\nImpostiamo lo stesso modello bayesiano, mantenendo la struttura logistica con dummy di gruppo.\n\nfit_m &lt;- brm(\n  count | trials(tot) ~ group,\n  data         = dat_m,\n  family       = binomial(),\n  prior        = priors,\n  backend      = \"cmdstanr\",\n  seed         = 1234,\n  iter         = 4000, chains = 4, cores = 4,\n  sample_prior = \"yes\",\n  refresh = 0 \n)\n\nDopo la stima, estraiamo nuovamente le quantità di interesse: le probabilità nei due gruppi, la loro differenza, l’odds ratio e il risk ratio.\n\npost_m &lt;- as_draws_df(fit_m) %&gt;%\n  mutate(\n    p_ref   = plogis(b_Intercept),\n    p_work  = plogis(b_Intercept + b_groupworking),\n    RD      = p_work - p_ref,\n    OR      = exp(b_groupworking),\n    RR      = p_work / p_ref\n  )\n\npost_summary_m &lt;- tibble(\n  quantity = c(\"p_ref (non-working)\", \"p_work (working)\", \"RD (work - ref)\", \"OR\", \"RR\"),\n  mean  = c(mean(post_m$p_ref), mean(post_m$p_work), mean(post_m$RD), mean(post_m$OR), mean(post_m$RR)),\n  q2.5  = c(quantile(post_m$p_ref, .025), quantile(post_m$p_work, .025), quantile(post_m$RD, .025),\n            quantile(post_m$OR, .025), quantile(post_m$RR, .025)),\n  q97.5 = c(quantile(post_m$p_ref, .975), quantile(post_m$p_work, .975), quantile(post_m$RD, .975),\n            quantile(post_m$OR, .975), quantile(post_m$RR, .975))\n)\n\npost_summary_m\n#&gt; # A tibble: 5 × 4\n#&gt;   quantity               mean     q2.5    q97.5\n#&gt;   &lt;chr&gt;                 &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 p_ref (non-working)  0.0141  0.00393   0.0312\n#&gt; 2 p_work (working)     0.358   0.310     0.408 \n#&gt; 3 RD (work - ref)      0.344   0.295     0.396 \n#&gt; 4 OR                  51.8    17.0     143.    \n#&gt; 5 RR                  33.4    11.3      91.3\n\nLe stime posteriori raccontano una storia molto chiara. La probabilità di successo per i bambini scolarizzati è praticamente nulla, con un intervallo credibile che resta vicino allo zero. Per i bambini lavoratori, invece, la probabilità si colloca intorno al 36 per cento. La differenza di rischio è quindi nettamente positiva e l’odds ratio assume valori molto superiori a uno, indicando un vantaggio marcato dei lavoratori.\nPer rendere ancora più evidente la forza dell’effetto, possiamo calcolare la probabilità a posteriori che la proporzione dei lavoratori sia superiore a quella degli scolarizzati, oppure che la differenza di rischio e l’odds ratio siano strettamente positivi.\n\ntibble(\n  `Pr(p_work &gt; p_ref)` = mean(post_m$p_work &gt; post_m$p_ref),\n  `Pr(RD &gt; 0)`         = mean(post_m$RD &gt; 0),\n  `Pr(OR &gt; 1)`         = mean(post_m$OR &gt; 1),\n  `Pr(RR &gt; 1)`         = mean(post_m$RR &gt; 1)\n)\n#&gt; # A tibble: 1 × 4\n#&gt;   `Pr(p_work &gt; p_ref)` `Pr(RD &gt; 0)` `Pr(OR &gt; 1)` `Pr(RR &gt; 1)`\n#&gt;                  &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n#&gt; 1                    1            1            1            1\n\nIn questo caso le probabilità posteriori sono praticamente pari a uno, cioè la certezza che i bambini lavoratori abbiano prestazioni migliori nei problemi di mercato.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#confronto-fra-i-due-scenari",
    "href": "chapters/glm/03_two_proportions.html#confronto-fra-i-due-scenari",
    "title": "70  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n70.6 Confronto fra i due scenari",
    "text": "70.6 Confronto fra i due scenari\nMettendo insieme i due esempi — problemi astratti e problemi di mercato — si ottiene un quadro coerente con le ipotesi teoriche dello studio. Nei problemi astratti, tipici dell’ambiente scolastico, i bambini scolarizzati mostrano una probabilità di successo più elevata rispetto ai lavoratori. Nei problemi di mercato, invece, il risultato si ribalta: i bambini che hanno esperienza diretta nelle attività quotidiane del lavoro sono nettamente più preparati, mentre gli scolarizzati faticano.\nLa regressione logistica in chiave bayesiana ci permette di quantificare entrambi gli scenari con la stessa cornice concettuale. Le differenze non vengono solo osservate nei dati grezzi, ma diventano stime probabilistiche con intervalli credibili che riflettono l’incertezza. È particolarmente utile osservare come le diverse scale (proporzioni, differenza di rischio, odds ratio, risk ratio) restituiscano sempre la stessa conclusione, ciascuna con il proprio linguaggio: più intuitivo nel caso delle proporzioni, più compatto e comparabile in quello dell’odds ratio.\nQuesta analisi illustra bene il vantaggio di un modello unificato. Con un’unica struttura logistica possiamo descrivere scenari molto diversi, da un divario moderato a uno estremo, e tradurre i risultati su scale diverse a seconda delle esigenze interpretative.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#visualizzazione-dei-risultati",
    "href": "chapters/glm/03_two_proportions.html#visualizzazione-dei-risultati",
    "title": "70  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n70.7 Visualizzazione dei risultati",
    "text": "70.7 Visualizzazione dei risultati\nPer rendere più intuitiva l’interpretazione, possiamo rappresentare graficamente le distribuzioni posteriori.\n\n70.7.1 Differenza di rischio (RD)\nNel primo grafico vediamo le distribuzioni posteriori della risk difference nei due scenari. Nel caso dei problemi astratti, la distribuzione si concentra su valori negativi, indicando un vantaggio per i bambini scolarizzati. Nei problemi di mercato, al contrario, la distribuzione si colloca interamente su valori positivi, con un vantaggio netto per i bambini lavoratori.\n\npost_RD &lt;- bind_rows(\n  post %&gt;% select(RD) %&gt;% mutate(scenario = \"Problemi astratti\"),\n  post_m %&gt;% select(RD) %&gt;% mutate(scenario = \"Problemi di mercato\")\n)\n\nggplot(post_RD, aes(x = RD, fill = scenario)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  facet_wrap(~scenario, ncol = 1, scales = \"free_y\") +\n  labs(\n    x = \"RD = p_work - p_non\",\n    y = \"Densità\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n70.7.2 Odds ratio (OR)\nUn secondo grafico mostra le distribuzioni posteriori dell’odds ratio. Nei problemi astratti, la distribuzione è concentrata al di sotto di 1, evidenziando odds più bassi per i bambini lavoratori. Nei problemi di mercato, l’odds ratio risulta al contrario molto più grande di 1, segnalando un vantaggio consistente per i lavoratori.\n\npost_OR &lt;- bind_rows(\n  post %&gt;% select(OR) %&gt;% mutate(scenario = \"Problemi astratti\"),\n  post_m %&gt;% select(OR) %&gt;% mutate(scenario = \"Problemi di mercato\")\n)\n\nggplot(post_OR, aes(x = OR, fill = scenario)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(xintercept = 1, linetype = \"dashed\") +\n  facet_wrap(~scenario, ncol = 1, scales = \"free_y\") +\n  scale_x_continuous(trans = \"log\", breaks = c(0.1, 0.5, 1, 2, 5, 10, 50)) +\n  labs(\n    x = \"Odds ratio (scala log)\",\n    y = \"Densità\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nQueste figure completano l’analisi, mostrando visivamente come lo stesso modello possa descrivere due situazioni opposte. La regressione logistica, in chiave bayesiana, fornisce un linguaggio comune per esprimere risultati che nei dati appaiono così divergenti: vantaggio per i bambini scolarizzati nei compiti astratti, e vantaggio per i bambini lavoratori nei compiti concreti di mercato.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#proporzioni-posteriori-di-successo-per-gruppo",
    "href": "chapters/glm/03_two_proportions.html#proporzioni-posteriori-di-successo-per-gruppo",
    "title": "70  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n70.8 Proporzioni posteriori di successo per gruppo",
    "text": "70.8 Proporzioni posteriori di successo per gruppo\nPer completare il quadro conviene mostrare direttamente le probabilità di successo stimate per ciascun gruppo, nei due scenari. L’idea è di partire dai draw posteriori già calcolati e di riassumerli con mediana e intervalli credibili. Il grafico risultante rende evidente, a colpo d’occhio, sia la distanza fra i gruppi sia l’ampiezza dell’incertezza.\n\n# Raccogliamo i draw di p per ciascuno scenario e gruppo\npost_props &lt;- bind_rows(\n  post %&gt;%\n    transmute(\n      scenario = \"Problemi astratti\",\n      `non-working` = p_ref,\n      `working`     = p_work\n    ),\n  post_m %&gt;%\n    transmute(\n      scenario = \"Problemi di mercato\",\n      `non-working` = p_ref,\n      `working`     = p_work\n    )\n) |&gt;\n  pivot_longer(cols = c(`non-working`, `working`),\n               names_to = \"gruppo\", values_to = \"p\")\n\n# Riassunto con mediana e intervalli credibili\nsumm_props &lt;- post_props |&gt;\n  group_by(scenario, gruppo) |&gt;\n  median_qi(p, .width = c(.95, .89)) |&gt;\n  ungroup()\n\n# Grafico punto + intervallo credibile\nggplot(summ_props, aes(x = gruppo, y = p, ymin = .lower, ymax = .upper)) +\n  geom_pointrange(position = position_dodge(width = 0.4)) +\n  facet_wrap(~ scenario, ncol = 1) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  labs(\n    x = NULL,\n    y = \"Probabilità di successo\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nIl pannello sui problemi astratti mostra una probabilità di successo più alta per i bambini scolarizzati rispetto ai lavoratori, con intervalli credibili che riflettono l’incertezza ma mantengono un chiaro distacco fra i gruppi. Il pannello sui problemi di mercato, al contrario, evidenzia un’inversione marcata: i lavoratori presentano una probabilità sensibilmente maggiore, mentre gli scolarizzati rimangono vicini allo zero. La lettura combinata di questi due pannelli rafforza l’interpretazione proposta nei paragrafi precedenti e rende visiva la coerenza fra scale diverse, perché le conclusioni tratte da RD, OR e RR trovano una corrispondenza immediata nelle probabilità stimate.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#il-modello-scritto-in-stan",
    "href": "chapters/glm/03_two_proportions.html#il-modello-scritto-in-stan",
    "title": "70  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n70.9 Il modello scritto in Stan",
    "text": "70.9 Il modello scritto in Stan\nPer completezza, possiamo mostrare come la stessa analisi sia realizzabile direttamente in Stan, senza passare da brms. Questo esempio ha uno scopo puramente didattico: nel capitolo “Regressione logistica con Stan” troveremo la discussione più dettagliata della sintassi e delle scelte di modellizzazione. Qui ci interessa soprattutto vedere come la struttura logistica con variabile dummy possa essere implementata in modo molto semplice.\nIl modello prevede due gruppi. Per ciascun gruppo conosciamo il numero di successi e il numero totale di prove. Introduciamo inoltre un predittore dummy che vale 0 per il gruppo di riferimento (non-working) e 1 per il gruppo di confronto (working). Il modello utilizza una parametrizzazione logit con due coefficienti: l’intercetta \\(\\alpha\\), che descrive i log-odds del gruppo di riferimento, e il coefficiente \\(\\gamma\\), che rappresenta la differenza di log-odds fra i gruppi. A partire da questi due parametri possiamo ricavare tutte le quantità di interesse già discusse, cioè le probabilità di successo nei due gruppi, la differenza di rischio, l’odds ratio e il risk ratio.\n\nstan_code &lt;- '\ndata {\n  int&lt;lower=1&gt; G;                // numero di gruppi (=2)\n  array[G] int&lt;lower=0&gt; y;       // successi osservati per ciascun gruppo\n  array[G] int&lt;lower=0&gt; n;       // prove totali per ciascun gruppo\n  array[G] int&lt;lower=0,upper=1&gt; D; // dummy: 0 = non-working, 1 = working\n}\nparameters {\n  real alpha;                     // intercetta (log-odds gruppo di riferimento)\n  real gamma;                     // coefficiente della dummy (log-odds ratio)\n}\nmodel {\n  // prior deboli sulla scala logit\n  alpha ~ normal(0, 2.5);\n  gamma ~ normal(0, 2.5);\n\n  // verosimiglianza binomiale per ciascun gruppo\n  for (g in 1:G) {\n    real eta = alpha + gamma * D[g];\n    y[g] ~ binomial(n[g], inv_logit(eta));\n  }\n}\ngenerated quantities {\n  real p_ref    = inv_logit(alpha);             // probabilità nel gruppo di riferimento\n  real p_work   = inv_logit(alpha + gamma);     // probabilità nel gruppo working\n  real RD       = p_work - p_ref;               // differenza di probabilità\n  real OR       = exp(gamma);                   // odds ratio\n  real RR       = p_work / p_ref;               // risk ratio\n}\n'\n\nI dati da fornire a Stan sono molto semplici: i conteggi di successi e prove nei due gruppi, più la variabile dummy che distingue i gruppi.\n\ndat_stan &lt;- list(\n  G = 2,\n  y = c(x_non, x_work),\n  n = c(n_non, n_work),\n  D = c(0L, 1L)\n)\n\nCompiliamo quindi il modello e avviamo il campionamento MCMC.\n\nmod  &lt;- cmdstan_model(write_stan_file(stan_code))\nfitS &lt;- mod$sample(data = dat_stan, seed = 1234,\n                   chains = 4, parallel_chains = 4)\n\nInfine, estraiamo le quantità derivate di maggiore interesse, esattamente le stesse già calcolate nel caso di brms.\n\nfitS$summary(variables = c(\"p_ref\",\"p_work\",\"RD\",\"OR\",\"RR\"))\n#&gt; # A tibble: 5 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 p_ref     0.590  0.591 0.022 0.022  0.553  0.625 1.005  929.925  853.063\n#&gt; 2 p_work    0.451  0.451 0.013 0.013  0.429  0.472 1.000 3200.938 2588.523\n#&gt; 3 RD       -0.140 -0.140 0.025 0.025 -0.180 -0.098 1.006  877.412  873.285\n#&gt; 4 OR        0.572  0.568 0.059 0.058  0.482  0.676 1.005  874.895  869.354\n#&gt; 5 RR        0.765  0.763 0.036 0.035  0.709  0.826 1.006  929.621 1006.127\n\nI risultati ottenuti coincidono con quelli ricavati tramite brms. Questo conferma che la parametrizzazione logit con dummy è del tutto equivalente all’impostazione con predittore categoriale, e che da essa possiamo derivare in modo trasparente tutte le grandezze interpretative: probabilità nei gruppi, differenza di rischio, odds ratio e risk ratio. In questo modo il modello Stan, pur scritto in forma minimale, ci permette di vedere con chiarezza la logica interna dell’analisi e rafforza la comprensione concettuale della regressione logistica come strumento per il confronto fra proporzioni.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#posterior-predictive-check",
    "href": "chapters/glm/03_two_proportions.html#posterior-predictive-check",
    "title": "70  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n70.10 Posterior predictive check",
    "text": "70.10 Posterior predictive check\nUn vantaggio di Stan è che possiamo generare, nello stesso modello, dei dati replicati secondo la distribuzione predittiva posteriore. Questo ci consente di confrontare i dati osservati con quelli che il modello si aspetta, valutando così la bontà dell’adattamento.\nBasta aggiungere, nella sezione generated quantities, delle variabili che rappresentino i successi simulati a posteriori per ciascun gruppo. Queste repliche, combinate con le quantità già calcolate (\\(p_{ref}\\), \\(p_{work}\\), \\(RD\\), \\(OR\\), \\(RR\\)), ci permettono di eseguire controlli predittivi direttamente in R dopo l’esecuzione del modello.\n\nstan_code_ppc &lt;- '\ndata {\n  int&lt;lower=1&gt; G;                  // numero gruppi (=2)\n  array[G] int&lt;lower=0&gt; y;         // successi osservati\n  array[G] int&lt;lower=0&gt; n;         // prove totali\n  array[G] int&lt;lower=0,upper=1&gt; D; // dummy: 0 = non-working, 1 = working\n}\nparameters {\n  real alpha;                       // intercetta (log-odds gruppo di riferimento)\n  real gamma;                       // coefficiente dummy (log-odds ratio)\n}\nmodel {\n  // prior deboli\n  alpha ~ normal(0, 2.5);\n  gamma ~ normal(0, 2.5);\n\n  for (g in 1:G) {\n    real eta = alpha + gamma * D[g];\n    y[g] ~ binomial(n[g], inv_logit(eta));\n  }\n}\ngenerated quantities {\n  real p_ref    = inv_logit(alpha);\n  real p_work   = inv_logit(alpha + gamma);\n  real RD       = p_work - p_ref;\n  real OR       = exp(gamma);\n  real RR       = p_work / p_ref;\n\n  // dati replicati per i due gruppi\n  array[G] int y_rep;\n  for (g in 1:G) {\n    real eta = alpha + gamma * D[g];\n    y_rep[g] = binomial_rng(n[g], inv_logit(eta));\n  }\n}\n'\n\nPrepariamo i dati nello stesso modo di prima:\n\ndat_stan &lt;- list(\n  G = 2,\n  y = c(x_non, x_work),\n  n = c(n_non, n_work),\n  D = c(0L, 1L)\n)\n\nCompiliamo e lanciamo il modello:\n\nmod_ppc &lt;- cmdstan_model(write_stan_file(stan_code_ppc))\nfit_ppc &lt;- mod_ppc$sample(data = dat_stan, seed = 1234,\n                          chains = 4, parallel_chains = 4)\n\nOra possiamo esaminare le repliche generate a posteriori. Ad esempio, visualizziamo le distribuzioni predittive delle proporzioni replicate e confrontiamole con quelle osservate.\n\n# Estraiamo le repliche\ny_rep &lt;- fit_ppc$draws(\"y_rep\") |&gt; as_draws_matrix()\ny_rep_df &lt;- as_tibble(y_rep) |&gt; \n  mutate(draw = row_number()) |&gt; \n  pivot_longer(-draw, names_to = \"var\", values_to = \"count_rep\") |&gt; \n  mutate(group = ifelse(var == \"y_rep[1]\", \"non-working\", \"working\"),\n         tot   = ifelse(group == \"non-working\", n_non, n_work),\n         observed = ifelse(group == \"non-working\", x_non, x_work),\n         prop_rep = count_rep / tot,\n         prop_obs = observed / tot)\n\nggplot(y_rep_df, aes(x = prop_rep)) +\n  geom_density(alpha = 0.5, fill = \"#56B4E9\") +\n  geom_vline(aes(xintercept = prop_obs), linetype = \"dashed\") +\n  facet_wrap(~ group, scales = \"free\") +\n  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n  labs(\n    title = \"Posterior predictive check (Stan)\",\n    subtitle = \"Linea tratteggiata = proporzione osservata;\\ncurva = distribuzione delle proporzioni replicate\",\n    x = \"Proporzione di successi (repliche posteriori)\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\nIl grafico mostra che le proporzioni osservate nei due gruppi ricadono all’interno delle distribuzioni predittive generate dal modello. Questo è un segnale positivo: il modello è capace di riprodurre i dati reali con buona coerenza. Naturalmente, controlli più sofisticati possono includere altre statistiche riassuntive o l’uso di funzioni dedicate, ma questo esempio illustra bene il principio fondamentale: Stan non si limita a stimare parametri, ma permette anche di simulare nuovi dati per verificare in modo diretto l’adeguatezza del modello.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#riflessioni-conclusive",
    "href": "chapters/glm/03_two_proportions.html#riflessioni-conclusive",
    "title": "70  Confronto tra due proporzioni con la regressione logistica",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nAbbiamo visto come il confronto tra due proporzioni possa essere affrontato in modo diretto mediante distribuzioni Beta posteriori. In un linguaggio probabilistico come Stan, questa stessa idea può essere implementata in vari modi.\n\ntrattando ciascuna proporzione come un parametro con prior Beta e likelihood binomiale;\noppure modellando direttamente i dati a livello individuale (successi/insuccessi) con una regressione logistica e un predittore di gruppo.\n\nQueste formulazioni hanno una diversa “faccia computazionale”, ma generano posteriori coerenti: entrambe descrivono lo stesso meccanismo di aggiornamento delle credenze. La scelta dipende più dall’estensibilità del modello (per includere predittori, effetti gerarchici, ecc.) che dal risultato inferenziale in sé.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         bayestestR_0.17.0     cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#bibliografia",
    "href": "chapters/glm/03_two_proportions.html#bibliografia",
    "title": "70  Confronto tra due proporzioni con la regressione logistica",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBanerjee, A. V., Bhattacharjee, S., Chattopadhyay, R., Duflo, E., Ganimian, A. J., Rajah, K., & Spelke, E. S. (2025). Children’s arithmetic skills do not transfer between applied and academic mathematics. Nature, 1–9.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_poisson_model.html",
    "href": "chapters/glm/04_poisson_model.html",
    "title": "71  Modello di Poisson",
    "section": "",
    "text": "Introduzione\nI In questo tutorial, approfondiremo l’utilizzo di CmdStan per condurre un’analisi di regressione di Poisson. La regressione di Poisson rappresenta una forma di modello lineare generalizzato impiegato nell’analisi di regressione per modellare dati di conteggio. Essa si basa sull’assunzione che la variabile di risposta \\(Y\\) segua una distribuzione di Poisson, con il logaritmo del suo valore atteso modellabile attraverso una combinazione lineare di parametri sconosciuti.\nIn questo capitolo, dopo aver esaminato il calcolo della media a posteriori e dell’incertezza correlata al tasso di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno, ci chiederemo se vi siano evidenze di una tendenza all’aumento di tale tasso nel corso del tempo. Per contestualizzare il fenomeno si suggerisce di leggere l’articolo Racial Disparities in Police Use of Deadly Force Against Unarmed Individuals Persist After Appropriately Benchmarking Shooting Data on Violent Crime Rates (Ross et al., 2021). Non è obbligatorio per seguire il capitolo, ma fornisce lo sfondo sociale e metodologico dei dati che stiamo per analizzare.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_poisson_model.html#introduzione",
    "href": "chapters/glm/04_poisson_model.html#introduzione",
    "title": "71  Modello di Poisson",
    "section": "",
    "text": "Panoramica del capitolo\n\nIntroduzione alla regressione di Poisson per dati di conteggio.\nStudio dell’andamento temporale delle sparatorie fatali della polizia USA (2015-2024).\nImplementazione del modello in Stan.\nPosterior predictive check e analisi degli Incidence Rate Ratios (IRR).\nTraduzione dei coefficienti in termini di conteggi attesi e trend percentuale annuo.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Racial Disparities in Police Use of Deadly Force Against Unarmed Individuals Persist After Appropriately Benchmarking Shooting Data on Violent Crime Rates per ottenere una panoramica approfondita su questo fenomeno e sul relativo ambito di ricerca.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, HDInterval, lubridate, brms, bayesplot, tidybayes, posterior, tidyr)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_poisson_model.html#regressione-di-poisson",
    "href": "chapters/glm/04_poisson_model.html#regressione-di-poisson",
    "title": "71  Modello di Poisson",
    "section": "\n71.1 Regressione di Poisson",
    "text": "71.1 Regressione di Poisson\nLa regressione di Poisson è un caso di GLM per variabili di risposta di conteggio (0, 1, 2, …). Denoteremo con \\(\\lambda_i\\) il valore atteso (e, sotto il modello di Poisson, anche la varianza) del conteggio \\(Y_i\\) alla \\(i\\)-esima osservazione.\n\n71.1.1 Distribuzione di base\nUna variabile casuale di Poisson ha funzione di massa\n\\[\n\\Pr(Y=y)=\\frac{\\lambda^{\\,y}e^{-\\lambda}}{y!},\\qquad y\\in\\{0,1,2,\\dots\\},\n\\] dove \\(\\lambda&gt;0\\) è sia media sia varianza: \\(\\mathbb{E}[Y]=\\lambda,\\ \\mathrm{Var}(Y)=\\lambda\\).\nNel contesto del modello di regressione,\n\\[\nY_i \\mid \\mathbf{x}_i \\sim \\text{Poisson}(\\lambda_i),\n\\qquad \\lambda_i&gt;0 .\n\\]\n\n71.1.2 Forma GLM e funzione di legame\nPer garantire \\(\\lambda_i&gt;0\\) si usa il link logaritmico (naturale):\n\\[\n\\log \\lambda_i = \\eta_i\n\\quad\\text{con}\\quad\n\\eta_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}.\n\\] Equivalente a:\n\\[\n\\lambda_i = \\exp(\\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}).\n\\]\n\nNota terminologica: il link è \\(\\log(\\cdot)\\); l’esponenziale è la sua inversa. Non è corretto chiamare “link esponenziale”.\n\n\n71.1.3 Conteggi e predittori\nNel modello di regressione di Poisson assumiamo che ciascun conteggio \\(Y_i\\) segua una distribuzione di Poisson con media \\(\\lambda_i\\). Il legame tra la media \\(\\lambda_i\\) e le variabili esplicative è dato dalla funzione logaritmica:\n\\[\n\\log \\lambda_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}.\n\\] In questo modo il numero medio di eventi attesi \\(\\lambda_i\\) viene sempre stimato come un valore positivo:\n\\[\n\\lambda_i = \\exp(\\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}).\n\\] Questa formulazione è adatta quando tutti i conteggi si riferiscono a intervalli di osservazione uguali (per esempio, il numero di episodi aggressivi in un anno per ciascuno studente). In tal caso non serve introdurre ulteriori correzioni: il modello lavora direttamente sui conteggi osservati.\n\n71.1.4 Interpretazione dei coefficienti\nNel modello di regressione di Poisson ogni osservazione \\(Y_i\\) segue\n\\[\nY_i \\sim \\text{Poisson}(\\lambda_i),\n\\qquad \\log \\lambda_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}.\n\\] Qui \\(\\lambda_i\\) è il numero medio di eventi attesi per l’osservazione \\(i\\).\nPer il j-esimo predittore \\(x_{ij}\\), il rapporto tra i valori attesi quando \\(x_{ij}\\) aumenta di 1 unità è\n\\[\n\\frac{\\lambda_i(x_{ij}+1)}{\\lambda_i(x_{ij})} = \\exp(\\beta_j).\n\\] Questo significa che \\(\\exp(\\beta_j)\\) è il fattore moltiplicativo atteso sul numero medio di eventi per un incremento unitario di \\(x_{ij}\\).\n\nSe \\(\\beta_j = 0\\), non c’è effetto (\\(\\exp(\\beta_j)=1\\)).\nSe \\(\\beta_j &gt; 0\\), i conteggi attesi crescono moltiplicati per \\(\\exp(\\beta_j)\\).\nSe \\(\\beta_j &lt; 0\\), i conteggi attesi diminuiscono, divisi per \\(\\exp(|\\beta_j|)\\).\n\nPer variabili binarie, \\(\\exp(\\beta_j)\\) confronta direttamente i due gruppi (1 contro 0).\nEsempio. Se studiamo il numero di episodi aggressivi in un anno per ciascuno studente, il modello può essere scritto come\n\\[\n\\log \\lambda_i = \\beta_0 + \\beta_1 \\,\\text{Stress}_i + \\beta_2 \\,\\text{Supporto}_i + \\beta_3 \\,\\text{Depressione}_i.\n\\] Qui \\(\\exp(\\beta_1)\\) indica di quanto si moltiplica il numero medio di episodi aggressivi attesi quando lo stress aumenta di 1 unità, a parità delle altre variabili.\n\n71.1.5 Assunzioni di base\nPer usare la regressione di Poisson facciamo alcune ipotesi semplici:\n\n\nRisposta a conteggio: la variabile dipendente è un numero intero non negativo (0, 1, 2, …).\n\nIndipendenza: le osservazioni sono considerate indipendenti tra loro.\n\nMedia = varianza: nella distribuzione di Poisson la media e la varianza coincidono. Se nei dati la varianza è molto più grande della media, il modello di Poisson può non essere adatto.\n\nRelazione log-lineare: il logaritmo del numero medio di eventi è una combinazione lineare dei predittori.\n\n71.1.6 Come il modello rappresenta lambda\nNella regressione di Poisson non stimiamo direttamente il valore medio \\(\\lambda_i\\), ma il suo logaritmo:\n\\[\n\\eta_i = \\log \\lambda_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}.\n\\]\n\n\nCaso senza predittori: il modello stima solo l’intercetta \\(\\alpha\\). In questo caso\n\\[\n\\lambda = \\exp(\\alpha).\n\\]\n\n\nCaso con predittori: dati i valori delle variabili esplicative \\(\\mathbf{x}_i\\), il numero medio di eventi per l’osservazione \\(i\\) è\n\\[\n\\lambda_i = \\exp\\big(\\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}\\big).\n\\] In altre parole, il modello lavora sempre sulla scala logaritmica (più semplice da trattare matematicamente), e poi si passa alla scala naturale dei conteggi applicando l’esponenziale.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_poisson_model.html#la-domanda-di-ricerca",
    "href": "chapters/glm/04_poisson_model.html#la-domanda-di-ricerca",
    "title": "71  Modello di Poisson",
    "section": "\n71.2 La domanda di ricerca",
    "text": "71.2 La domanda di ricerca\nGrazie all’archivio pubblico del Washington Post disponiamo di tutti i casi di sparatorie fatali accadute negli Stati Uniti dal 2015 in poi. L’interesse è stimare quante se vi siano evidenze di una tendenza all’aumento di tale tasso nel corso del tempo.\nImportiamo e prepariamo i dati:\n\nurl &lt;- \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nraw &lt;- read.csv(url, stringsAsFactors = FALSE)\nraw$date &lt;- as.Date(raw$date)\nraw$year &lt;- lubridate::year(raw$date)\n\n# Escludiamo il 2025 perché l’anno è ancora in corso e i dati sarebbero incompleti\nshootings &lt;- subset(raw, year &lt; 2025)\n\ndf &lt;- shootings %&gt;%\n  dplyr::count(year, name = \"events\")\ndf\n#&gt;    year events\n#&gt; 1  2015    995\n#&gt; 2  2016    959\n#&gt; 3  2017    984\n#&gt; 4  2018    992\n#&gt; 5  2019    993\n#&gt; 6  2020   1021\n#&gt; 7  2021   1050\n#&gt; 8  2022   1097\n#&gt; 9  2023   1164\n#&gt; 10 2024   1175\n\nPer facilitare l’interpretazione, centriamo la colonna year. In questo modo, l’intercetta si riferità all’anno 2019.\n\ndf &lt;- df |&gt; \n  mutate(year = year - 2019)\ndf\n#&gt;    year events\n#&gt; 1    -4    995\n#&gt; 2    -3    959\n#&gt; 3    -2    984\n#&gt; 4    -1    992\n#&gt; 5     0    993\n#&gt; 6     1   1021\n#&gt; 7     2   1050\n#&gt; 8     3   1097\n#&gt; 9     4   1164\n#&gt; 10    5   1175\n\nA questo punto abbiamo una tabella df con due colonne: year (centrato), che va dal -4 (2015) a 5 (2024), ed events, che contiene il numero di sparatorie fatali registrate in ciascun anno.\n\n71.2.1 Modello Stan\nDefiniamo il seguente modello\n\nstan_code &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  array[N] int&lt;lower=0&gt; y;   // conteggi\n  vector[N] year;            // -4, -3, ..., 5 (non standardizzato)\n}\n\nparameters {\n  real alpha;                // log media per anno 0\n  real beta;                 // effetto per 1 anno (log-IRR per anno)\n}\n\nmodel {\n  // Priors coerenti con: lambda ~ 600 circa, 400–900 plausibile\n  alpha ~ normal(6.4, 0.25);   // oppure 0.30 se preferisci più ampia\n  beta  ~ normal(0, 0.05);     // oppure 0.10 se vuoi più permissiva\n\n  // Poisson con link log\n  y ~ poisson_log(alpha + beta * year);\n}\n\ngenerated quantities {\n  vector[N] eta = alpha + beta * year;\n  vector[N] lambda = exp(eta);\n  array[N] int&lt;lower=0&gt; y_rep;\n  for (n in 1:N) y_rep[n] = poisson_log_rng(eta[n]);\n}\n'\n\nSpecificare la distribuzione a priori:\n\n\nIntercetta: \\(\\alpha=\\log\\lambda\\). Poiché riteniamo plausibile, prima dei dati, una media annua \\(\\lambda\\) centrata attorno a 600, con intervallo ~400–900, imponiamo \\(\\alpha \\sim \\mathcal N(6.40,\\ 0.25)\\) (oppure \\(0.30\\) per un intervallo un po’ più ampio).\n\nPendenza: \\(\\beta\\) è il log-IRR per anno. Attese variazioni annue piccole ⇒ \\(\\beta \\sim \\mathcal N(0,\\ 0.05)\\) (più prudente) oppure \\(\\mathcal N(0,\\ 0.10)\\) (più ampia).\n\nDati:\n\ndat &lt;- data.frame(\n  year   = -4:5,\n  events = c(995, 959, 984, 992, 993, 1021, 1050, 1097, 1164, 1175)\n)\n\nstan_data &lt;- list(\n  N = nrow(dat),\n  y = dat$events,\n  year = dat$year\n)\nglimpse(stan_data)\n#&gt; List of 3\n#&gt;  $ N   : int 10\n#&gt;  $ y   : num [1:10] 995 959 984 992 993 ...\n#&gt;  $ year: int [1:10] -4 -3 -2 -1 0 1 2 3 4 5\n\nCompiliamo il modello e avviamo il campionamento MCMC.\n\nmod  &lt;- cmdstan_model(write_stan_file(stan_code))\n\n\nfit &lt;- mod$sample(\n  data = stan_data, seed = 1234,\n  chains = 4, parallel_chains = 4\n)\n\nEstraiamo le quantità derivate di maggiore interesse:\n\nfit$summary(variables = c(\"alpha\", \"beta\", \"lambda\"))\n#&gt; # A tibble: 12 × 10\n#&gt;    variable       mean   median     sd    mad       q5      q95  rhat ess_bulk\n#&gt;    &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 alpha         6.936    6.936  0.010  0.010    6.919    6.953 1.002 2204.738\n#&gt;  2 beta          0.022    0.022  0.003  0.003    0.017    0.028 1.001 3921.050\n#&gt;  3 lambda[1]   941.474  941.801 17.650 17.035  912.472  971.438 1.001 2679.962\n#&gt;  4 lambda[2]   962.558  962.748 15.339 15.008  937.673  988.402 1.001 2529.218\n#&gt;  5 lambda[3]   984.125  984.098 13.197 12.980  962.847 1006.315 1.001 2360.153\n#&gt;  6 lambda[4]  1006.188 1006.306 11.435 11.412  987.696 1025.400 1.002 2225.370\n#&gt;  7 lambda[5]  1028.757 1028.715 10.386 10.218 1011.757 1045.887 1.002 2204.743\n#&gt;  8 lambda[6]  1051.845 1051.811 10.420 10.291 1034.962 1069.068 1.001 2432.282\n#&gt;  9 lambda[7]  1075.464 1075.166 11.672 11.765 1056.337 1094.511 1.001 2907.241\n#&gt; 10 lambda[8]  1099.626 1099.600 13.949 14.347 1076.660 1122.705 1.001 3450.415\n#&gt; 11 lambda[9]  1124.344 1124.076 16.959 17.358 1096.501 1152.436 1.002 3873.761\n#&gt; 12 lambda[10] 1149.631 1149.272 20.487 20.926 1116.283 1183.948 1.002 4105.120\n#&gt;    ess_tail\n#&gt;       &lt;dbl&gt;\n#&gt;  1 2351.782\n#&gt;  2 3015.859\n#&gt;  3 2639.793\n#&gt;  4 2550.928\n#&gt;  5 2548.232\n#&gt;  6 2343.254\n#&gt;  7 2351.782\n#&gt;  8 2512.354\n#&gt;  9 2834.135\n#&gt; 10 2973.167\n#&gt; 11 2997.796\n#&gt; 12 3053.556\n\n\n71.2.2 Interpretazione\nIl parametro alpha rappresenta il logaritmo del numero medio atteso di eventi nell’anno di riferimento \\(x=0\\). Nel nostro modello l’anno 0 è semplicemente il punto centrale della sequenza di anni osservata (−4,…,5).\nIl valore stimato è \\(\\alpha \\approx 6.94\\), con un intervallo di credibilità al 95% compreso tra 6.92 e 6.95. Trasformando sulla scala naturale, otteniamo:\n\\[\n\\exp(\\alpha) \\approx 1\\,030\n\\] cioè circa 1030 eventi attesi nell’anno di riferimento.\nIl parametro beta misura la variazione logaritmica attesa per ogni anno aggiuntivo. La stima \\(\\beta \\approx 0.022\\) (ICr 95%: 0.017–0.028) indica una crescita positiva.\nPer interpretare questo effetto sulla scala dei conteggi:\n\\[\n\\exp(\\beta) \\approx 1.022 ,\n\\] ossia ogni anno in più corrisponde a un aumento atteso di circa +2.2% degli eventi rispetto all’anno precedente.\nSe traduciamo questa percentuale in termini assoluti, partendo dal valore base \\(\\exp(\\alpha)\\approx 1.030\\), otteniamo:\n\\[\n\\exp(\\alpha)\\times(\\exp(\\beta)-1) \\;\\approx\\; 23\n\\] quindi in media circa 23 eventi in più per ogni anno successivo.\n\n# Anni da predire (quelli del dataset)\nyears &lt;- -4:5\n\n# Estrai i draw posteriori di alpha e beta da cmdstanr\n# (se vuoi in formato data frame \"largo\")\ndraws &lt;- as_draws_df(fit$draws(variables = c(\"alpha\", \"beta\")))\n\n# Costruisci predizioni posteriori di lambda per ogni anno\npred &lt;- lapply(years, function(y) {\n  tibble(\n    year   = y,\n    lambda = exp(draws$alpha + draws$beta * y)\n  )\n}) |&gt;\n  bind_rows()\n\n# Riassumi: media e intervallo di credibilità 95%\npred_sum &lt;- pred |&gt;\n  group_by(year) |&gt;\n  summarise(\n    lambda_mean = mean(lambda),\n    lambda_q05  = quantile(lambda, 0.05),\n    lambda_q95  = quantile(lambda, 0.95),\n    .groups = \"drop\"\n  )\n\n# (opzionale) unisci i dati osservati\ndat &lt;- tibble(\n  year   = -4:5,\n  events = c(995, 959, 984, 992, 993, 1021, 1050, 1097, 1164, 1175)\n)\n\n# Grafico: banda 90% (5%-95%), linea media e punti osservati\nggplot(pred_sum, aes(x = year)) +\n  geom_ribbon(aes(ymin = lambda_q05, ymax = lambda_q95), alpha = 0.2) +\n  geom_line(aes(y = lambda_mean), linewidth = 1) +\n  geom_point(data = dat, aes(y = events), size = 2) +\n  labs(\n    x = \"Anno (codifica -4 … 5)\",\n    y = \"Numero atteso di eventi\"\n  ) \n\n\n\n\n\n\n\nIl modello di regressione di Poisson mostra che il numero medio di eventi segue una crescita regolare nel tempo. L’intercetta indica che nell’anno di riferimento (\\(x=0\\)) ci si attendono circa 1030 eventi, mentre la pendenza suggerisce un incremento annuo di circa +2%, pari a una ventina di eventi in più ogni anno.\nLa banda di credibilità attorno alla curva stimata conferma che l’incertezza sulle previsioni è contenuta e che l’andamento crescente è chiaramente supportato dai dati. In termini sostantivi, il modello descrive bene una tendenza di crescita graduale ma costante negli anni osservati.\n\n71.2.3 Posterior predictive check\n\n# Dati osservati\ndat &lt;- tibble::tibble(\n  year   = -4:5,\n  events = c(995, 959, 984, 992, 993, 1021, 1050, 1097, 1164, 1175)\n)\n\n# Estrai i draw di y_rep in matrice (draws x N)\nyrep_mat &lt;- fit$draws(variables = \"y_rep\") |&gt;\n  as_draws_matrix()\n# Seleziona solo le colonne y_rep[...] mantenendo l'ordine\ncols &lt;- grep(\"^y_rep\\\\[\", colnames(yrep_mat))\nyrep_mat &lt;- yrep_mat[, cols, drop = FALSE]\n\n# Calcola quantili per colonna (per ogni anno)\nqs &lt;- colQuantiles(yrep_mat, probs = c(0.05, 0.50, 0.95))\npred_sum &lt;- tibble::tibble(\n  year = dat$year,\n  q05  = qs[, 1],\n  q50  = qs[, 2],\n  q95  = qs[, 3]\n)\n\n# Grafico PPC: banda 90% + mediana + punti osservati\nggplot(pred_sum, aes(x = year)) +\n  geom_ribbon(aes(ymin = q05, ymax = q95), alpha = 0.2) +\n  geom_line(aes(y = q50), linewidth = 1) +\n  geom_point(data = dat, aes(y = events), size = 2) +\n  labs(\n    x = \"Anno (codifica -4 … 5)\",\n    y = \"Conteggio\"\n  ) \n\n\n\n\n\n\n\n\nLa banda ombreggiata rappresenta il 90% della distribuzione predittiva del conteggio per ciascun anno (5%–95%).\nLa linea è la mediana predittiva; i punti sono i conteggi osservati.\nSe i punti stanno per lo più dentro le bande, il modello riproduce bene i livelli di conteggio anno per anno.\nSe molti punti cadono fuori (o tutti da un lato), il modello potrebbe essere troppo rigido o mancare di struttura (p.es. overdispersione, forma non lineare nel tempo, effetti non inclusi).\n\n\n# Media/varianza osservate\nmean_obs &lt;- mean(dat$events)\nvar_obs  &lt;- var(dat$events)\n\n# Media/varianza delle repliche (per draw)\nmean_rep &lt;- rowMeans(yrep_mat)\nvar_rep  &lt;- apply(yrep_mat, 1, var)\n\n# p-value predittivi (proporzione di repliche &gt;= osservato)\np_mean &lt;- mean(mean_rep &gt;= mean_obs)\np_var  &lt;- mean(var_rep  &gt;= var_obs)\n\ntibble::tibble(\n  stat      = c(\"media\", \"varianza\"),\n  osservato = c(mean_obs, var_obs),\n  media_rep = c(mean(mean_rep), mean(var_rep)),\n  p_pred    = c(p_mean, p_var)\n)\n#&gt; # A tibble: 2 × 4\n#&gt;   stat     osservato media_rep p_pred\n#&gt;   &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 media        1043      1042.  0.468\n#&gt; 2 varianza     5940.     6093.  0.486\n\n\np1 &lt;- ggplot(data.frame(mean_rep), aes(x = mean_rep)) +\n  geom_histogram(bins = 30) +\n  geom_vline(xintercept = mean_obs, linetype = 2) +\n  labs(title = \"PPC media\", x = \"Media (repliche)\", y = \"Frequenza\")\n\np2 &lt;- ggplot(data.frame(var_rep), aes(x = var_rep)) +\n  geom_histogram(bins = 30) +\n  geom_vline(xintercept = var_obs, linetype = 2) +\n  labs(title = \"PPC varianza\", x = \"Varianza (repliche)\", y = \"Frequenza\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIl controllo predittivo mostra che i conteggi osservati ricadono interamente entro le bande di credibilità del modello. Inoltre, la media e la varianza osservate sono molto vicine a quelle prodotte dalle repliche simulate (p-value predittivi ~0.5), il che indica che il modello non sottostima né sovrastima la variabilità dei dati. Nel complesso, questi risultati suggeriscono che la regressione di Poisson con legame log e trend lineare nel tempo fornisce una rappresentazione adeguata dei dati osservati.\n\n71.2.3.1 Incidence Rate Ratio (IRR)\n\nirr &lt;- draws |&gt;\n  transmute(\n    IRR = exp(beta)\n  ) |&gt;\n  summarise(\n    mean = mean(IRR),\n    q05  = quantile(IRR, 0.05),\n    q95  = quantile(IRR, 0.95)\n  )\nirr\n#&gt; # A tibble: 1 × 3\n#&gt;    mean   q05   q95\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  1.02  1.02  1.03\n\nIl valore medio stimato dell’IRR è 1.022, con un intervallo di credibilità al 90% compreso tra 1.017 e 1.028. Questo significa che, a ogni anno in più, il numero medio di eventi attesi aumenta di circa il 2.2%, con un margine di incertezza che va da circa +1.7% a +2.8%.\nPoiché l’intero intervallo si colloca sopra 1, il modello suggerisce con elevata credibilità che la tendenza temporale sia effettivamente crescente: non stiamo osservando fluttuazioni casuali, ma un aumento sistematico anno dopo anno.\nIl valore medio dell’IRR è 1.022: questo equivale a un incremento di circa +2.2% per anno.\n\nIn termini assoluti, partendo da una media di circa 1030 eventi, un aumento del 2.2% corrisponde a circa +23 eventi all’anno.\nL’intervallo di credibilità (1.017–1.028) implica che l’aumento medio sia compreso tra circa +18 e +29 eventi per anno.\n\nIn altre parole, il modello suggerisce che il fenomeno osservato cresce in modo regolare e consistente: ogni anno si verificano in media da una ventina a una trentina di eventi in più rispetto all’anno precedente.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_poisson_model.html#discussione-generale",
    "href": "chapters/glm/04_poisson_model.html#discussione-generale",
    "title": "71  Modello di Poisson",
    "section": "Discussione generale",
    "text": "Discussione generale\nIn questo capitolo abbiamo visto come il modello di Poisson possa essere usato per descrivere dati che rappresentano conteggi, come il numero di comportamenti osservati in un certo periodo di tempo o la frequenza con cui si manifesta un sintomo. L’idea centrale è semplice: invece di trattare i dati come proporzioni o medie, li consideriamo come eventi che “accadono” con una certa intensità, rappresentata dal parametro \\(\\lambda\\). Questo ci permette di modellare direttamente le frequenze osservate, rispettando la natura discreta e positiva dei dati.\nDal punto di vista psicologico, ciò significa avere uno strumento adatto per studiare fenomeni che non si esprimono in valori continui ma in conteggi (ad esempio, il numero di episodi ansiosi in una settimana, o il numero di errori commessi in un compito). L’approccio bayesiano aggiunge un ulteriore vantaggio: possiamo combinare le informazioni provenienti dai dati con ciò che sappiamo (o ipotizziamo) a priori sul fenomeno, ottenendo una stima che riflette sia l’evidenza empirica sia la nostra conoscenza di base.\nIn sintesi:\n\nil modello di Poisson è utile quando i dati sono conteggi;\nil parametro \\(\\lambda\\) rappresenta l’intensità media del fenomeno;\nl’approccio bayesiano ci consente di integrare dati e conoscenze pregresse.\n\nQuesti elementi rendono il modello di Poisson uno strumento flessibile e potente per la ricerca psicologica, specialmente quando vogliamo descrivere e interpretare comportamenti o eventi che si manifestano come frequenze.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] lubridate_1.9.4       HDInterval_0.2.4      cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    estimability_1.5.1   \n#&gt; [31] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [64] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [67] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [70] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [73] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [76] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [79] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [82] MASS_7.3-65",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_poisson_model.html#bibliografia",
    "href": "chapters/glm/04_poisson_model.html#bibliografia",
    "title": "71  Modello di Poisson",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nRoss, C. T., Winterhalder, B., & McElreath, R. (2021). Racial disparities in police use of deadly force against unarmed individuals persist after appropriately benchmarking shooting data on violent crime rates. Social Psychological and Personality Science, 12(3), 323–332.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html",
    "href": "chapters/glm/05_logistic_process.html",
    "title": "72  Dal GLM a un modello processuale per dati binari",
    "section": "",
    "text": "Introduzione\nL a regressione logistica, introdotta nei capitoli precedenti, è uno strumento fondamentale per analizzare variabili dicotomiche \\(y \\in {0,1}\\) (ad esempio: scelta sì/no, risposta corretta/errata, accettazione/rifiuto) in funzione di predittori osservabili \\(\\mathbf{x}\\). Tuttavia, questo approccio presenta limiti importanti quando vogliamo descrivere processi psicologici dinamici, nei quali la risposta osservata è soltanto la manifestazione finale di meccanismi interni che si sviluppano nel tempo.\nAd esempio, in un questionario online possiamo usare la regressione logistica per prevedere se uno studente risponde correttamente o erroneamente in base alla difficoltà della domanda. Ma in un compito cognitivo ripetuto, la risposta dello stesso studente al trial 10 dipende anche da come è andato il trial 9 (feedback positivo/negativo, fatica accumulata, ecc.). Il modello statico non “vede” questa dipendenza, mentre un modello processuale la incorpora.\nIn molti contesti cognitivi e comportamentali, le risposte binarie riflettono infatti:\nIl modello logistico standard assume invece indipendenza tra le osservazioni, effetti costanti nel tempo e un unico meccanismo generativo omogeneo. Queste ipotesi sono spesso poco realistiche nei dati psicologici longitudinali o sperimentali, dove:\nPer catturare meglio questi aspetti servono modelli più sofisticati, capaci di rappresentare la dipendenza temporale tra le osservazioni, l’eterogeneità intra-individuale e la natura incrementale dei processi cognitivi sottostanti. Questa transizione da una rappresentazione statica alla modellazione dinamica è cruciale in psicologia: il comportamento osservato non va visto come un evento isolato, ma come l’istantanea di un sistema complesso in continua evoluzione.\nL’obiettivo di questo capitolo è mostrare come, con Stan, sia possibile esplicitare il meccanismo generativo delle risposte, superando i limiti della regressione logistica classica e introducendo la nozione di processi dinamici autoregressivi che meglio riflettono la natura temporale dei fenomeni psicologici.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#introduzione",
    "href": "chapters/glm/05_logistic_process.html#introduzione",
    "title": "72  Dal GLM a un modello processuale per dati binari",
    "section": "",
    "text": "processi accumulativi, come l’integrazione di evidenza nel decision making,\n\ndinamiche temporali interne, ad esempio legate all’apprendimento, all’adattamento o all’affaticamento,\n\ninterazioni stato-dipendenti, come variazioni momentanee di motivazione o attenzione.\n\n\n\nle risposte sono influenzate dalla storia precedente (history dependence),\ngli stati latenti del soggetto evolvono lungo traiettorie individuali,\nla stessa soglia decisionale può cambiare nel corso del tempo.\n\n\n\n\n\n\n\n\nEsempio.\n\n\n\n\n\nImmaginiamo uno studente che affronta un test a scelta multipla. Con un modello logistico classico possiamo prevedere se risponderà correttamente in base alla difficoltà della domanda. Ma se lo stesso studente sta svolgendo una lunga serie di prove, la sua risposta alla domanda 10 dipende anche da come è andata la domanda 9: un errore può ridurre la fiducia, un successo può aumentarla. In più, col passare del tempo, possono intervenire affaticamento o distrazione. Il modello statico logit non cattura nulla di tutto ciò. Per includere questi aspetti servono modelli che riconoscano che ogni osservazione porta memoria del passato.\n\n\n\n\nPanoramica del capitolo\n\nIntroduzione ai modelli dinamici in psicologia, superando i limiti dei GLM statici.\nLa regressione logistica classica reinterpretata attraverso variabili latenti e soglie.\nEstensione al modello AR(1) per catturare la dipendenza temporale e la “memoria” del passato.\nImplementazione pratica in Stan, con simulazione dati e confronto con modelli statici (GLMM).\nEvidenza che i modelli processuali dinamici forniscono stime più fedeli ai meccanismi generativi.\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, cmdstanr, posterior, brms, bayestestR, insight, conflicted)\n\nconflicts_prefer(posterior::mad)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#dal-modello-statico-al-modello-processuale",
    "href": "chapters/glm/05_logistic_process.html#dal-modello-statico-al-modello-processuale",
    "title": "72  Dal GLM a un modello processuale per dati binari",
    "section": "\n72.1 Dal modello statico al modello processuale",
    "text": "72.1 Dal modello statico al modello processuale\n\n72.1.1 La regressione logistica classica\nNel modello di regressione logistica (GLM logit) la probabilità di osservare una risposta positiva è:\n\\[\n\\Pr(y_i=1 \\mid \\mathbf{x}_i) = \\operatorname{logit}^{-1}\\!\\left(\\alpha + \\mathbf{x}_i^\\top \\boldsymbol\\beta\\right).\n\\]\nQui:\n\n\n\\(\\alpha\\) è l’intercetta, che rappresenta la tendenza di base a rispondere 1;\n\n\\(\\boldsymbol\\beta\\) descrive come i predittori osservati influenzano questa probabilità.\n\nUn modo intuitivo per interpretare la formula è introdurre una variabile latente continua \\(u_i\\), che possiamo pensare come la propensione interna dell’individuo a rispondere “1”:\n\\[\nu_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol\\beta + \\varepsilon_i,\n\\qquad \\varepsilon_i \\sim \\text{Logistic}(0,1).\n\\]\nLa regola di decisione è semplice:\n\nse \\(u_i &gt; 0\\) allora osserviamo \\(y_i=1\\),\nse \\(u_i \\leq 0\\) allora osserviamo \\(y_i=0\\).\n\nIn altre parole, immaginiamo che l’individuo abbia una soglia fissa: quando la propensione supera questa soglia, la risposta osservata diventa positiva.\nPossiamo pensare a \\(u_i\\) come a un “serbatoio di propensione”: se il livello supera la soglia, si osserva una risposta positiva. Nei modelli statici il serbatoio si svuota e si riempie indipendentemente a ogni trial; nei modelli dinamici, invece, il livello attuale dipende anche da quanto era pieno al trial precedente.\nNella regressione logistica classica, questa soglia è sempre costante nel tempo e uguale per tutti i trial. Ma nei processi psicologici reali ciò non è sempre realistico: la soglia decisionale (o l’intensità della propensione) può cambiare da un momento all’altro, ad esempio per effetto di apprendimento, fatica o variazioni di motivazione.\nEd è proprio da qui che nasce la necessità di estendere il modello logit statico a un modello dinamico, in cui la variabile latente \\(u\\) (e talvolta anche la soglia) possa variare nel tempo e riflettere la natura evolutiva dei processi psicologici.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#oltre-il-glm-dinamica-temporale",
    "href": "chapters/glm/05_logistic_process.html#oltre-il-glm-dinamica-temporale",
    "title": "72  Dal GLM a un modello processuale per dati binari",
    "section": "\n72.2 Oltre il GLM: dinamica temporale",
    "text": "72.2 Oltre il GLM: dinamica temporale\nNella regressione logistica classica abbiamo visto che ogni risposta osservata \\(y_i\\) può essere pensata come il risultato di una propensione latente \\(u_i\\), confrontata con una soglia fissa. Questa impostazione funziona bene se consideriamo le osservazioni come indipendenti e isolate.\nMa in psicologia le cose vanno spesso diversamente:\n\nnegli esperimenti con prove ripetute, le decisioni prese oggi sono influenzate da quelle appena fatte;\nnelle misurazioni longitudinali (EMA), lo stato emotivo o motivazionale di un momento dipende in parte da quello precedente;\nnei compiti di apprendimento, l’esperienza accumulata modifica gradualmente la propensione a scegliere un’opzione rispetto a un’altra.\n\nIn tutti questi casi, è naturale immaginare che la variabile latente \\(u_{i,t}\\) non nasca da zero a ogni prova, ma porti memoria del passato.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#il-modello-ar1",
    "href": "chapters/glm/05_logistic_process.html#il-modello-ar1",
    "title": "72  Dal GLM a un modello processuale per dati binari",
    "section": "\n72.3 Il modello AR(1)",
    "text": "72.3 Il modello AR(1)\nPer rendere esplicita la dipendenza dal passato, usiamo un modello autoregressivo di ordine 1 (AR(1); Chatfield & Xing (2019)):\n\\[\n\\begin{aligned}\nu_{i,t} &= \\alpha_i\n          + \\mathbf{x}_{i,t}^\\top \\boldsymbol\\beta\n          + \\phi \\, u_{i,t-1}\n          + \\eta_{i,t},\n& \\eta_{i,t} \\sim \\mathcal{N}(0,\\sigma_u), \\\\[6pt]\ny_{i,t} \\mid u_{i,t} &\\sim \\text{Bernoulli}\\!\\left(\\operatorname{logit}^{-1}(u_{i,t})\\right).\n\\end{aligned}\n\\]\nPossiamo immaginare \\(u_{i,t}\\) come il livello di un “serbatoio di propensione”: se questo valore supera la soglia implicita dello 0 sulla scala logit, la risposta osservata è positiva \\((y_{i,t}=1)\\). La novità rispetto al modello statico è che il livello attuale \\(u_{i,t}\\) dipende anche da quello precedente \\(u_{i,t-1}\\), attraverso il termine \\(\\phi u_{i,t-1}\\).\nSignificati dei parametri del modello AR(1):\n\n\\(\\alpha_i\\) (intercetta soggetto-specifica): propensione media di un individuo (es. uno studente molto ansioso potrebbe avere più probabilità di rispondere “no”).\n\\(\\beta\\) (effetto dei predittori): effetto di variabili osservabili (es. domande più facili aumentano la probabilità di risposta corretta).\n\n\\(\\phi\\) (persistenza dinamica): quanta parte dello stato passato sopravvive:\n\nse \\(\\phi=0\\), nessuna memoria: ogni risposta è “indipendente”,\nse \\(\\phi&gt;0\\), inerzia: un successo ieri aumenta la probabilità di successo oggi,\nse \\(\\phi&lt;0\\), alternanza: un successo ieri rende più probabile un errore oggi (pattern a zig-zag).\n\n\n\\(\\sigma_u\\) (variabilità del processo): irregolarità: se grande, le traiettorie diventano rumorose (es. risposte altalenanti per distrazioni).\n\nUn piccolo schema concettuale aiuta a visualizzare:\nu(t-1)  ──▶  u(t)  ──▶  y(t)\n   │\n   └─────────── φ ───────────┘\nPer esempio:\n\n\n\\(\\alpha_i\\): uno studente particolarmente ansioso potrebbe avere un’alta probabilità di rispondere “no” a prescindere dalla domanda;\n\n\\(\\beta\\): se la domanda è facile (\\(x=1\\)), aumenta la probabilità di risposta corretta;\n\n\\(\\phi\\): se lo studente ha risposto correttamente ieri, oggi sarà più probabile che risponda ancora correttamente;\n\n\\(\\sigma_u\\): cattura la variabilità inspiegata, come distrazioni improvvise.\n\n\n72.3.1 Che cos’è \\(u_{i,t}\\)?\n\n\n\\(u_{i,t}\\) non è osservato: è uno stato latente.\nPossiamo pensarlo come il “livello di propensione” di un individuo in un certo istante \\(t\\).\nL’osservazione \\(y_{i,t}\\) (corretto/errato, sì/no, 1/0) nasce da questo stato: se \\(u_{i,t}\\) è alto, la probabilità di risposta positiva è alta; se è basso, è bassa.\nNei modelli Bayesiani o di stato latente, i valori di \\(u_{i,t}\\) non si calcolano direttamente dai dati ma vengono stimati/inferiti dal modello. In pratica, otteniamo una distribuzione a posteriori su ciascun \\(u_{i,t}\\), non un singolo valore deterministico.\n\n72.3.2 E il ruolo di \\(\\phi\\)?\nIl coefficiente \\(\\phi\\) funziona come un “peso di memoria”:\n\nSe \\(\\phi = 0\\), il passato non conta: \\(u\\_{i,t}\\) dipende solo dai predittori e dal rumore.\nSe \\(\\phi &gt; 0\\), c’è inerzia: lo stato precedente influenza positivamente quello attuale.\nSe \\(\\phi &lt; 0\\), c’è compensazione o alternanza: uno stato alto ieri spinge verso uno basso oggi.\n\nFormalmente, \\(\\phi\\) è un coefficiente di regressione come \\(\\alpha\\) e \\(\\beta\\), ma agisce sulla variabile latente del tempo precedente, quindi introduce dipendenza temporale.\n\n72.3.3 Come “si trovano” i valori di \\(u_{i,t-1}\\)?\n\nAll’inizio (al tempo \\(t=1\\)), bisogna specificare una condizione iniziale per \\(u_{i,0}\\), ad esempio assumendo \\(u_{i,0} \\sim \\mathcal{N}(0,\\sigma_0)\\).\nPer i tempi successivi, ogni \\(u_{i,t}\\) viene costruito ricorsivamente dal precedente: il modello stesso definisce la sequenza degli stati latenti.\nIn fase di stima (ad esempio con Stan), si usano i dati osservati \\(y_{i,t}\\) per inferire a posteriori quali valori plausibili di \\(u_{i,t}\\) rendono il modello coerente con le risposte osservate.\n\nRiassumendo:\n\n\n\\(u_{i,t}\\): stato latente, stimato dal modello, non osservato.\n\n\\(\\phi\\): coefficiente che regola quanto lo stato passato influenza quello presente.\n\n\\(\\alpha_i\\), \\(\\beta\\): intercetta e predittori osservati, come in una regressione logistica.\n\n\\(\\sigma_u\\): variabilità residua del processo latente.\n\n72.3.4 Perché è importante?\nCon il modello AR(1) facciamo un passo oltre la regressione logistica classica. La probabilità di risposta non è più determinata solo dai fattori esterni osservati, ma anche dagli stati interni accumulati nel tempo. In altre parole, il comportamento osservato non nasce “da zero” a ogni prova: porta con sé una traccia del passato.\nEsempi concreti aiutano a capirlo:\n\n\nCompito di apprendimento: se un partecipante ha appena ricevuto un rinforzo positivo, la sua propensione a ripetere la stessa scelta sarà più alta al trial successivo.\n\nDiario EMA: un umore negativo oggi aumenta la probabilità di trovarsi in uno stato simile anche domani, a meno che un evento esterno intervenga a interrompere la continuità.\n\nLa lezione fondamentale è questa: le scelte non sono indipendenti, ma intrecciate con la storia recente dell’individuo. Ed è proprio questa “memoria del passato” che rende i modelli dinamici strumenti più realistici e potenti per descrivere processi psicologici rispetto ai modelli statici.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nPer fare un esempio semplice, consideriamo un modello continuo con un solo predittore continuo. La dipendenza temporale la collochiamo nei residui, con una struttura AR(1). In questo modo evitiamo il problema di introdurre variabili latenti non osservabili come \\(u\\).\nPer il soggetto \\(i\\) al tempo \\(t\\):\n\\[\n\\begin{aligned}\ny_{i,t} &= \\alpha_i + \\beta\\,x_{i,t} + e_{i,t},\\\\\ne_{i,t} &= \\phi\\, e_{i,t-1} + \\eta_{i,t}, \\qquad \\eta_{i,t}\\sim\\mathcal N(0,\\sigma_\\eta^2).\n\\end{aligned}\n\\]\ndove:\n\n\n\\(y_{i,t}\\) è la risposta osservata (continua),\n\n\\(x_{i,t}\\) è il predittore osservato (continuo),\n\n\\(e_{i,t}\\) è l’errore con memoria AR(1),\n\n\\(\\phi\\) è l’autocorrelazione a lag 1 dei residui,\n\n\\(\\sigma_\\eta\\) controlla l’ampiezza del rumore “nuovo” che entra a ogni passo.\n\nIn altre parole, il valore osservato \\(y_{i,t}\\) è composto da:\n\nuna parte sistematicamente spiegata dal predittore \\(x_{i,t}\\), ponderata da \\(\\beta\\),\nuna parte casuale, \\(e_{i,t}\\), che però non è indipendente: conserva memoria del residuo precedente (\\(\\phi e_{i,t-1}\\)). Se ieri il modello ha sovrastimato, è probabile che anche oggi rimanga un residuo positivo; lo stesso vale per una sottostima.\n\n\nNota su \\(e_{i,0}\\). Per generare una serie “stazionaria”, inizializziamo il primo residuo dalla distribuzione stazionaria:\n\\[\ne_{i,0} \\sim \\mathcal N\\!\\left(0,\\; \\frac{\\sigma_\\eta^2}{1-\\phi^2}\\right).\n\\]\n\n\n# ---- Funzione di simulazione ----\nsimulate_reg_ar1 &lt;- function(alpha, beta = 0.8, phi = 0.7, sigma_eta = 1.0,\n                             T_ = 60, x_sd = 1, seed = 123) {\n  set.seed(seed)\n  n_subj &lt;- length(alpha)\n  rec &lt;- vector(\"list\", n_subj)\n\n  # Varianza stazionaria dei residui AR(1)\n  sigma_e2 &lt;- sigma_eta^2 / (1 - phi^2)\n\n  for (i in seq_len(n_subj)) {\n    e_prev &lt;- rnorm(1, mean = 0, sd = sqrt(sigma_e2))  # e_{i,0}\n    rows &lt;- vector(\"list\", T_)\n    for (t in seq_len(T_)) {\n      x_t &lt;- rnorm(1, 0, x_sd)             # predittore osservato\n      eta &lt;- rnorm(1, 0, sigma_eta)        # innovazione\n      e_t &lt;- phi * e_prev + eta            # residuo AR(1)\n      y_t &lt;- alpha[i] + beta * x_t + e_t   # risposta continua\n      rows[[t]] &lt;- data.frame(\n        subject = i, time = t,\n        x = x_t, e = e_t, y = y_t\n      )\n      e_prev &lt;- e_t\n    }\n    rec[[i]] &lt;- dplyr::bind_rows(rows)\n  }\n  dplyr::bind_rows(rec)\n}\n\n# ---- Parametri e simulazione ----\nalpha &lt;- c(-1, 0, 1)   # intercette soggetto-specifiche\nbeta  &lt;- 0.8           # effetto del predittore x\nphi   &lt;- 0.7           # autocorrelazione a lag 1 dei residui\nsigma_eta &lt;- 1.0       # deviazione standard innovazione\nT_    &lt;- 60            # lunghezza serie temporale\n\ndf &lt;- simulate_reg_ar1(alpha, beta, phi, sigma_eta, T_)\n\n# ---- Grafico didattico ----\ndf &lt;- df %&gt;%\n  group_by(subject) %&gt;%\n  mutate(x_scaled = (x - mean(x)) / sd(x) * sd(y) + mean(y)) %&gt;%\n  ungroup()\n\nggplot(df, aes(time)) +\n  geom_line(aes(y = y), linewidth = 0.9) +\n  geom_line(aes(y = x_scaled), linetype = \"dashed\") +\n  geom_hline(aes(yintercept = ave_y),\n             data = df %&gt;% group_by(subject) %&gt;% summarise(ave_y = mean(y)),\n             linewidth = 0.3, color = \"grey40\") +\n  facet_wrap(~ subject, ncol = 1,\n             labeller = as_labeller(function(s) {\n               i &lt;- as.integer(s)\n               paste0(\"Soggetto \", s, \" (alpha = \", alpha[i], \")\")\n             })) +\n  labs(title = \"Regressione con residui AR(1): y(t) e x(t) riscalato\",\n       subtitle = paste0(\"phi = \", phi, \", sigma_eta = \", sigma_eta, \", beta = \", beta),\n       y = \"y(t)  (x in tratteggio, riscalato)\", x = \"Tempo\")\n\n\n\n\n\n\n\n\n\nStruttura del modello\n\nLa parte regressiva è \\(\\alpha_i + \\beta x_{i,t}\\).\nLa memoria sta nei residui: \\(e_{i,t} = \\phi e_{i,t-1} + \\eta_{i,t}\\).\nCosì il predittore \\(x_{i,t}\\) è esogeno e \\(\\phi\\) ha un significato chiaro: è l’autocorrelazione tra residui consecutivi.\n\n\n\nGrafico a pannelli\n\nLinea piena = \\(y_{i,t}\\).\nTratteggio = \\(x_{i,t}\\), riscalato per confrontarlo visivamente con \\(y\\).\nSi vede che \\(y\\) segue \\(x\\), ma non cambia bruscamente: la presenza di \\(\\phi=0.7\\) rende la traiettoria più “liscia” grazie alla memoria nei residui.\n\n\n\n\n# ---- Verifica dell'AR(1) sui residui (soggetto 1) ----\ndf1 &lt;- df %&gt;% filter(subject == 1)\nols_fit &lt;- lm(y ~ x, data = df1)\nresid_ols &lt;- resid(ols_fit)\n\npar(mfrow = c(1, 2))\nplot(df1$time, resid_ols, type = \"l\", main = \"Residui OLS (soggetto 1)\",\n     xlab = \"Tempo\", ylab = \"Residuo\")\nacf(resid_ols, main = \"ACF residui OLS (soggetto 1)\")\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n\nACF dei residui OLS\n\nNel modello di regressione lineare semplice \\(y \\sim x\\) si assume che i residui siano indipendenti. Nel nostro esempio, però, i residui hanno memoria AR(1): se ieri erano positivi, oggi tendono a esserlo di nuovo.\nL’ACF (autocorrelation function) dei residui ci permette di vedere questo effetto:\n\nmisura quanto i residui in tempi diversi sono correlati,\nil valore a lag 1 (tra residui consecutivi) è chiaramente positivo e vicino a \\(\\phi\\).\n\nQuindi:\n\nil modello lineare classico che assume residui indipendenti non descrive bene i dati,\noccorre un modello che includa la memoria, come l’AR(1) sui residui o un modello equivalente in stato-spazio.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#dallar1-allark",
    "href": "chapters/glm/05_logistic_process.html#dallar1-allark",
    "title": "72  Dal GLM a un modello processuale per dati binari",
    "section": "\n72.4 Dall’AR(1) all’AR(K)",
    "text": "72.4 Dall’AR(1) all’AR(K)\nIl modello AR(1) ci ha mostrato che lo stato latente \\(u_{i,t}\\) non nasce mai da zero, ma porta con sé una traccia del passato immediato. Tuttavia, in molti processi psicologici questa “memoria a un passo” può essere troppo corta.\nPensiamo a situazioni in cui:\n\nl’effetto di un’esperienza non si esaurisce al trial successivo ma dura più a lungo,\nl’umore di oggi non dipende solo da quello di ieri, ma anche da quello di due o tre giorni fa,\nl’apprendimento si accumula su una coda di feedback estesa.\n\nIn questi casi conviene estendere il modello ad un processo autoregressivo di ordine \\(K\\) (AR(K)):\n\\[\nu_{i,t} = \\alpha_i\n        + \\mathbf{x}_{i,t}^\\top \\boldsymbol\\beta\n        + \\phi_1 u_{i,t-1}\n        + \\phi_2 u_{i,t-2}\n        + \\dots\n        + \\phi_K u_{i,t-K}\n        + \\eta_{i,t},\n\\] \\[\n\\eta_{i,t} \\sim \\mathcal{N}(0,\\sigma_u).\n\\]\n\n72.4.1 Interpretazione psicologica\n\n\n\\(K=1\\) (AR(1)) → memoria cortissima: il presente dipende solo dallo stato immediatamente precedente (es. l’effetto diretto di un feedback appena ricevuto).\n\n\\(K=2\\) (AR(2)) → memoria breve: lo stato attuale risente degli ultimi due passi (es. l’umore influenzato dagli ultimi due giorni consecutivi).\n\n\\(K \\geq 3\\) → memoria più lunga: utile per processi cumulativi o ciclici (es. oscillazioni tra fasi di alta e bassa motivazione).\n\nIn altre parole, aumentando \\(K\\) allarghiamo la “finestra temporale” che il modello utilizza per spiegare il presente.\n\n72.4.2 Perché è utile?\nL’estensione ad AR(K) consente di modellare una gamma più ricca di dinamiche:\n\n\ninerzia semplice (AR(1)),\n\neffetti ritardati, che emergono dopo due o più step,\n\noscillazioni regolari o pattern ciclici (catturabili già con un AR(2) o AR(3)).\n\nCosì il modello diventa più flessibile e aderente alla complessità dei processi psicologici reali, nei quali la memoria del passato non ha sempre la stessa profondità, ma può essere breve, prolungata o ciclica.\n\n\n\n\n\n\nQuando usare modelli AR in psicologia?\n\nNei compiti decisionali con prove ripetute, quando sospettiamo che non solo l’ultima esperienza ma anche quelle precedenti influenzino la scelta.\nNegli studi EMA, quando l’umore o la motivazione di oggi risentono di più giorni consecutivi.\nIn generale, in tutti i casi in cui la sequenza temporale porta informazioni importanti che sarebbe un errore trattare come semplice rumore.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#simulazione-dati",
    "href": "chapters/glm/05_logistic_process.html#simulazione-dati",
    "title": "72  Dal GLM a un modello processuale per dati binari",
    "section": "\n72.5 Simulazione dati",
    "text": "72.5 Simulazione dati\nPrima di stimare il modello su dati reali, conviene costruire un dataset simulato (AR(1) logit a livello latente). In questo modo possiamo verificare se il modello riesce a recuperare parametri noti e comprendere meglio il suo funzionamento.\nImmaginiamo \\(I=100\\) soggetti, ciascuno con \\(T=30\\) prove, e un predittore binario \\(x_{i,t}\\) (ad esempio: tipo di stimolo, 0 = neutro, 1 = emozionale). Lo stato latente \\(u_{i,t}\\) evolve come un AR(1) sulla scala logit.\n\nset.seed(123)\n\nI   &lt;- 100   # numero di soggetti\nTt  &lt;- 30    # numero di trial per soggetto\nN   &lt;- I*Tt  # osservazioni totali\n\n# Parametri \"veri\" usati per generare i dati\nalpha_mu    &lt;- 0.0   # intercetta media\nalpha_sigma &lt;- 0.7   # variabilità tra-soggetti\nbeta_true   &lt;- 0.6   # effetto del predittore\nphi_true    &lt;- 0.5   # persistenza dinamica\nsigma_u     &lt;- 0.6   # rumore di processo\n\n# Intercette soggetto-specifiche\nalpha_i &lt;- rnorm(I, alpha_mu, alpha_sigma)\n\n# Predittore binario (0/1) random\nx &lt;- rbinom(N, 1, 0.5)\n\n# Costruzione dataset\ndf &lt;- tibble::tibble(\n  id = rep(1:I, each = Tt),\n  t  = rep(1:Tt, times = I),\n  x  = x\n)\n\n# Stato latente e risposta\nu &lt;- numeric(N)\ny &lt;- integer(N)\n\nfor (i in 1:I) {\n  a  &lt;- alpha_i[i]\n  ui &lt;- numeric(Tt)\n  for (tt in 1:Tt) {\n    idx &lt;- (i-1)*Tt + tt\n    mean_ut &lt;- a + beta_true*df$x[idx] + ifelse(tt == 1, 0, phi_true*ui[tt-1])\n    ui[tt]  &lt;- rnorm(1, mean_ut, sigma_u)        # stato latente\n    p       &lt;- 1/(1 + exp(-ui[tt]))              # probabilità risposta\n    y[idx]  &lt;- rbinom(1, 1, p)                   # risposta binaria\n  }\n  u[((i-1)*Tt+1):(i*Tt)] &lt;- ui\n}\n\ndf$u_lat &lt;- u\ndf$y     &lt;- y\n\nIl modello ha bisogno di sapere quale osservazione viene prima nello stesso soggetto. Se non stiamo attenti, potremmo collegare l’ultimo trial del soggetto \\(i\\) con il primo del soggetto \\(i+1\\), il che è sbagliato. Per evitare errori, creiamo un indice prev che punta al trial precedente solo dello stesso soggetto. Se non esiste (primo trial), mettiamo 0.\n\ndf &lt;- df[order(df$id, df$t), ]\nprev &lt;- integer(nrow(df))\nfor (i in unique(df$id)) {\n  idx  &lt;- which(df$id == i)\n  prev[idx] &lt;- c(0, head(idx, -1))  # 0 = nessun precedente\n}\nstopifnot(all(df$t[prev[df$t&gt;1]] == df$t[df$t&gt;1]-1))\n\nEsempio: se il soggetto 5 ha 30 trial, per il trial 12 prev punterà al trial 11, mentre per il trial 1 avrà valore 0.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#tabella-ponte-dallalgebra-a-stan",
    "href": "chapters/glm/05_logistic_process.html#tabella-ponte-dallalgebra-a-stan",
    "title": "72  Dal GLM a un modello processuale per dati binari",
    "section": "\n72.6 Tabella-ponte: dall’algebra a Stan",
    "text": "72.6 Tabella-ponte: dall’algebra a Stan\nPer tradurre il modello matematico in Stan, costruiamo una “mappa” dei concetti.\n\n\n\n\n\n\n\n\nConcetto\nSimbolo\nStan\nNota\n\n\n\nNumero osservazioni\n\\(N\\)\nint&lt;lower=1&gt; N;\n\n\n\nNumero soggetti\n\\(I\\)\nint&lt;lower=1&gt; I;\n\n\n\nSoggetto per trial\n—\narray[N] int&lt;lower=1,upper=I&gt; id;\n\n\n\nTrial precedente (stesso soggetto)\n—\narray[N] int&lt;lower=0,upper=N&gt; prev;\n0 se non esiste\n\n\nPredittori\n\\(\\mathbf{x}_{i,t}\\)\narray[N] int x;\nEstendibile a matrice\n\n\nRisposta\n\\(y_{i,t}\\)\narray[N] int y;\nBernoulli\n\n\nStato latente\n\\(u_{i,t}\\)\nvector[N] u;\n\n\n\nIntercetta soggetto\n\\(\\alpha_i\\)\n\nvector[I] alpha; (non centrato)\n\n\n\nPersistenza\n\\(\\phi\\)\nreal&lt;lower=-0.99,upper=0.99&gt; phi;\nvincolo stazionarietà\n\n\nRumore di processo\n\\(\\sigma_u\\)\nreal&lt;lower=0&gt; sigma_u;\ndeviazione standard",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#modello-stan",
    "href": "chapters/glm/05_logistic_process.html#modello-stan",
    "title": "72  Dal GLM a un modello processuale per dati binari",
    "section": "\n72.7 Modello Stan",
    "text": "72.7 Modello Stan\nOra traduciamo il modello AR(1) logit in Stan. L’idea è di rappresentare esplicitamente tre parti del processo:\n\nIntercette soggetto-specifiche (\\(\\alpha_i\\)), stimate in forma non centrata per migliorare la mescolanza della catena.\n\nEvoluzione dello stato latente \\(u_{i,t}\\):\n\nal primo trial di ciascun soggetto, \\(u_{i,1}\\) dipende solo dall’intercetta, dai predittori e dal rumore;\nnei trial successivi, \\(u_{i,t}\\) dipende anche dal valore precedente \\(u_{i,t-1}\\), con peso \\(\\phi\\).\n\n\nLikelihood: la risposta osservata \\(y_{i,t}\\) segue una Bernoulli logit con parametro \\(u_{i,t}\\).\n\nInoltre, nel blocco generated quantities calcoliamo:\n\n\ny_rep = repliche simulate, utili per i posterior predictive check;\n\nlog_lik = contributi della verosimiglianza, necessari per il calcolo di LOO/WAIC.\n\nFormalmente, il modello implementato è:\n\\[\n\\begin{aligned}\nu_{i,1} &\\sim \\mathcal{N}(\\alpha_i + \\mathbf{x}_{i,1}^\\top \\beta, \\sigma_u), \\\\\nu_{i,t} &\\sim \\mathcal{N}(\\alpha_i + \\mathbf{x}_{i,t}^\\top \\beta + \\phi u_{i,t-1}, \\sigma_u) \\quad (t&gt;1), \\\\\ny_{i,t} \\mid u_{i,t} &\\sim \\text{Bernoulli}\\!\\left(\\operatorname{logit}^{-1}(u_{i,t})\\right).\n\\end{aligned}\n\\]\n\nstan_code &lt;- '\ndata{\n  int&lt;lower=1&gt; N;\n  int&lt;lower=1&gt; I;\n  array[N] int&lt;lower=1,upper=I&gt; id;\n  array[N] int&lt;lower=0,upper=1&gt; x;    // estendibile a vettore\n  array[N] int&lt;lower=0,upper=1&gt; y;\n  array[N] int&lt;lower=0,upper=N&gt; prev; // 0 se non esiste trial precedente dello stesso soggetto\n}\nparameters{\n  vector[I] alpha_raw;\n  real      alpha_mu;\n  real&lt;lower=0&gt; alpha_sigma;\n\n  real beta;\n  real&lt;lower=-0.99, upper=0.99&gt; phi;\n  real&lt;lower=0&gt; sigma_u;\n\n  vector[N] eps; // innovazioni standard N(0,1)\n}\ntransformed parameters{\n  vector[I] alpha = alpha_mu + alpha_sigma * alpha_raw;\n  vector[N] u;\n  for (n in 1:N){\n    real mean_u = alpha[id[n]] + beta * x[n];\n    if (prev[n] == 0) {\n      // opzionale: condizione stazionaria per il primo trial\n      real sd1 = sigma_u / sqrt(1 - square(phi));\n      u[n] = mean_u + sd1 * eps[n];\n    } else {\n      u[n] = mean_u + phi * u[prev[n]] + sigma_u * eps[n];\n    }\n  }\n}\nmodel{\n  // Priori più informative (vedi §2)\n  alpha_raw   ~ normal(0, 1);\n  alpha_mu    ~ normal(0, 0.5);\n  alpha_sigma ~ normal(0, 0.5);   // &lt;lower=0&gt; già impone metà-normale\n  beta        ~ normal(0, 0.5);\n  phi         ~ normal(0, 0.4);   // bounds già imposti\n  sigma_u     ~ normal(0, 0.5);   // metà-normale su sd\n\n  eps ~ normal(0,1);              // innovazioni standard\n  y ~ bernoulli_logit(u);\n}\ngenerated quantities{\n  array[N] int y_rep;\n  vector[N] log_lik;\n  for (n in 1:N){\n    y_rep[n] = bernoulli_logit_rng(u[n]);\n    log_lik[n] = bernoulli_logit_lpmf(y[n] | u[n]);\n  }\n}\n'\nstan_file &lt;- write_stan_file(stan_code)\n\nFocalizziamoci sul blocco di codice che costruisce la variabile latente dinamica \\(u_n\\) su cui poi si basa la likelihood logistica dei dati osservati \\(y_n\\).\nStruttura della likelihood. Il modello assume che la risposta osservata \\(y_n \\in \\{0,1\\}\\) derivi da una regressione logistica:\n\\[\ny_n \\sim \\text{Bernoulli}\\!\\left(\\operatorname{logit}^{-1}(u_n)\\right),\n\\]\ndove \\(u_n\\) è il predittore lineare dinamico che evolve nel tempo con memoria AR(1). In pratica, invece di avere un predittore statico \\(u_n = \\alpha_i + \\beta x_n\\), qui aggiungiamo una dipendenza dal passato: lo stato latente corrente dipende anche da quello precedente.\nCostruzione di \\(u_n\\) nel codice:\nfor (n in 1:N){\n  real mean_u = alpha[id[n]] + beta * x[n];\n  if (prev[n] == 0) {\n    // primo trial del soggetto\n    real sd1 = sigma_u / sqrt(1 - square(phi));\n    u[n] = mean_u + sd1 * eps[n];\n  } else {\n    // trial successivi\n    u[n] = mean_u + phi * u[prev[n]] + sigma_u * eps[n];\n  }\n}\n\n\nLinea 1. Calcoliamo il contributo sistematico del soggetto e del predittore:\n\\[\n\\texttt{mean\\_u} = \\alpha_{id[n]} + \\beta x_n.\n\\]\nQui \\(\\alpha_{id[n]}\\) è l’intercetta specifica del soggetto, mentre \\(\\beta x_n\\) è l’effetto del predittore osservato.\n\n\nCaso prev[n]==0. È il primo trial di quel soggetto. Non abbiamo uno stato precedente a cui agganciarci, quindi inizializziamo \\(u_n\\) assumendo la condizione stazionaria del processo AR(1):\n\\[\nu_n \\sim \\mathcal N\\!\\left(\\texttt{mean\\_u}, \\; \\frac{\\sigma_u^2}{1-\\phi^2}\\right).\n\\]\nQuesto è implementato come mean_u + sd1 * eps[n], dove eps[n] ~ Normal(0,1) e sd1 = sigma_u / sqrt{1 - phi^2}.\n\n\nCaso prev[n]!=0. È un trial successivo. In questo caso \\(u_n\\) dipende dal valore precedente \\(u_{prev[n]}\\):\n\\[\nu_n = \\texttt{mean\\_u} + \\phi \\, u_{prev[n]} + \\sigma_u \\, \\varepsilon_n,\n\\quad \\varepsilon_n \\sim \\mathcal N(0,1).\n\\]\nQui \\(\\phi\\) è il coefficiente AR(1) che controlla quanto del passato sopravvive nel presente.\n\n\nIntuizione:\n\n\n\\(\\alpha_i\\): propensione media del soggetto.\n\n\\(\\beta x_n\\): effetto del predittore osservato al trial \\(n\\).\n\n\\(\\phi u_{prev[n]}\\): memoria: se ieri \\(u\\) era alto, oggi tenderà a restare alto (se \\(\\phi&gt;0\\)).\n\n\\(\\sigma_u \\varepsilon_n\\): rumore nuovo che introduce variabilità tra un trial e l’altro.\n\nIl risultato finale è che la probabilità di risposta positiva è:\n\\[\n\\Pr(y_n=1) = \\operatorname{logit}^{-1}(u_n),\n\\]\ne l’intera likelihood del modello è:\n\\[\np(y \\mid \\alpha, \\beta, \\phi, \\sigma_u) = \\prod_{n=1}^N \\text{Bernoulli}\\!\\left(y_n \\,\\middle|\\, \\operatorname{logit}^{-1}(u_n)\\right),\n\\]\ndove ciascun \\(u_n\\) è costruito ricorsivamente come sopra.\nGenerazione dei dati di input:\n\nstan_dat &lt;- list(\n  N   = nrow(df),\n  I   = length(unique(df$id)),\n  id  = as.integer(df$id),\n  x   = as.array(as.integer(df$x)),\n  y   = as.array(as.integer(df$y)),\n  prev = as.array(prev)\n)\n\nCompilazione del modello:\n\nmod &lt;- cmdstanr::cmdstan_model(stan_file)\n\nCampionamento:\n\nfit &lt;- mod$sample(\n  data = stan_dat,\n  seed = 2024,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1500, iter_sampling = 1500,\n  adapt_delta = 0.99,\n  max_treedepth = 15\n)\n\nRiassunto dei parametri chiave:\n\nfit$summary(c(\"alpha_mu\",\"alpha_sigma\",\"beta\",\"phi\",\"sigma_u\"))\n#&gt; # A tibble: 5 × 10\n#&gt;   variable     mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha_mu    0.104  0.098 0.099 0.094 -0.047 0.275 1.004 1146.168 1890.425\n#&gt; 2 alpha_sigma 0.691  0.684 0.116 0.114  0.517 0.895 1.002  936.525 2046.042\n#&gt; 3 beta        0.609  0.607 0.094 0.095  0.456 0.770 1.000 2591.209 4164.984\n#&gt; 4 phi         0.492  0.495 0.069 0.068  0.374 0.601 1.001 1218.997 2733.870\n#&gt; 5 sigma_u     0.695  0.691 0.187 0.176  0.393 1.004 1.005  381.850  561.846\n\nLettura dei risultati.\nConfrontiamo i valori stimati con quelli usati nella simulazione:\n\n\\(\\alpha_\\mu\\) (vero = 0.0) → stimato ≈ 0.10. L’intercetta media è molto vicina al valore vero, con intervallo che comprende lo 0. La stima è quindi ben calibrata.\n\\(\\alpha_\\sigma\\) (vero = 0.7) → stimato ≈ 0.69. La variabilità tra soggetti è recuperata quasi perfettamente. Questo mostra che il modello distingue bene la propensione media dei soggetti dalle loro differenze individuali.\n\\(\\beta\\) (vero = 0.6) → stimato ≈ 0.61. L’effetto del predittore viene stimato con grande precisione, centrato sul valore vero.\n\\(\\phi\\) (vero = 0.5) → stimato ≈ 0.49. Anche il parametro di persistenza dinamica è correttamente recuperato: la memoria del passato è catturata in linea con i dati generati.\n\\(\\sigma_u\\) (vero = 0.6) → stimato ≈ 0.69. Il rumore di processo è leggermente sovrastimato, ma rimane molto vicino al valore usato nella simulazione.\n\nIn sintesi, il modello MCMC recupera in modo accurato tutti i parametri simulati. Le diagnostiche (Rhat ≈ 1, ESS elevati, nessuna divergenza) confermano che la catena ha esplorato bene lo spazio dei parametri.\n\n72.7.1 Diagnostica e Posterior Predictive Check\nUn passo fondamentale è confrontare i dati osservati con quelli simulati dal modello (y_rep). Se il modello è adeguato, le distribuzioni delle repliche devono sovrapporsi a quella dei dati reali.\n\nyrep_draws &lt;- fit$draws(\"y_rep\")\n\n# Converte in data.frame e poi in matrice\nyrep_df  &lt;- as_draws_df(yrep_draws)\nyrep_mat &lt;- as.matrix(yrep_df[, grepl(\"^y_rep\", names(yrep_df))])\n\n# proporzione osservata\nprop_obs &lt;- mean(stan_dat$y)\n\n# proporzioni replicate (una per draw)\nprop_rep &lt;- rowMeans(yrep_mat)\n\nppc_dens_overlay(y = stan_dat$y, yrep = yrep_mat[1:100, ])\n\n\n\n\n\n\n\nIl posterior predictive check mostra che la distribuzione dei dati simulati dal modello (y_rep) si sovrappone bene a quella dei dati osservati (y).\n\nLa densità osservata (linea nera) cade quasi sempre all’interno del ventaglio di densità replicate (linee colorate).\nQuesto significa che il modello riesce a generare dati che “assomigliano” a quelli reali, un segnale che la struttura autoregressiva AR(1) e i parametri stimati catturano i meccanismi principali del processo.\nSe vedessimo sistematiche discrepanze (ad esempio code troppo corte o una distribuzione spostata), sarebbe un campanello d’allarme che il modello è mal specificato o che mancano variabili importanti.\n\nIn sintesi: un buon PPC non prova che il modello sia vero, ma aumenta la fiducia che sia plausibile e che descriva i dati in modo coerente con le ipotesi teoriche.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#confronto-con-glmm-logit-via-brm",
    "href": "chapters/glm/05_logistic_process.html#confronto-con-glmm-logit-via-brm",
    "title": "72  Dal GLM a un modello processuale per dati binari",
    "section": "\n72.8 Confronto con GLMM logit (via brm)",
    "text": "72.8 Confronto con GLMM logit (via brm)\nPer confronto abbiamo stimato lo stesso dataset con un GLM logit semplice in brm:\n\ndat &lt;- tibble(\n  y = as.numeric(stan_dat$y),\n  x = as.numeric(stan_dat$x),\n  id = as.numeric(stan_dat$id)\n)\n\n\n# ATTENZIONE: brms ignora la dipendenza seriale e l'eterogeneità nei trials!\nfit_glmer &lt;- brm(\n  y ~ x + (x | id),\n  data = dat,\n  family = bernoulli(link = \"logit\"),\n  prior = c(prior(normal(0, 1), class = \"b\")),\n  chains = 2, iter = 2000, seed = 123,\n  backend = \"cmdstanr\"\n)\n\n\nsummary(fit_glmer)\n#&gt;  Family: bernoulli \n#&gt;   Links: mu = logit \n#&gt; Formula: y ~ x + (x | id) \n#&gt;    Data: dat (Number of observations: 3000) \n#&gt;   Draws: 2 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 2000\n#&gt; \n#&gt; Multilevel Hyperparameters:\n#&gt; ~id (Number of levels: 100) \n#&gt;                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sd(Intercept)        1.20      0.11     1.00     1.44 1.00      608     1062\n#&gt; sd(x)                0.13      0.10     0.00     0.37 1.00      552      821\n#&gt; cor(Intercept,x)    -0.09      0.55    -0.95     0.92 1.00     2199     1438\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     0.42      0.13     0.17     0.68 1.01      347      630\n#&gt; x             0.50      0.09     0.32     0.69 1.00     2547     1579\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n72.8.1 Interpretazione dei risultati brm\n\nIl modello multilevel logit con slope/intercetta casuali, \\(y \\sim x + (x \\mid id)\\), stima:\n\n\nIntercept = 0.42 (SE ≈ 0.13): log-odds media di risposta 1 quando \\(x=0\\), considerando la variabilità tra soggetti.\n\n\\(x = 0.50\\) (SE ≈ 0.09; 95% CI [0.32, 0.69]): effetto medio del predittore sulla log-odds, con pooling parziale tra soggetti.\n\nEterogeneità tra soggetti:\n\n\nsd(Intercept) ≈ 1.20: forte variabilità individuale nella propensione di base.\n\nsd(x) ≈ 0.13: variabilità più contenuta nell’effetto di \\(x\\).\n\ncor(Intercept, x) ≈ −0.09 con IC molto ampio: nessuna evidenza di relazione sistematica tra tendenza di base e sensibilità al predittore.\n\nIl modello, quindi, distingue l’effetto medio di \\(x\\) dalla notevole eterogeneità individuale, ma non rappresenta esplicitamente la dipendenza seriale tra prove.\n\n72.8.2 Confronto con Stan (modello processuale AR(1))\nIl modello AR(1) in Stan, stimato sugli stessi dati simulati, recupera accuratamente i valori veri:\n\n\n\\(\\beta \\approx 0.61\\) (vero = 0.60),\n\n\\(\\phi \\approx 0.49\\) (vero = 0.50),\n\n\\(\\alpha_\\sigma \\approx 0.69\\) (vero = 0.70),\n\n\\(\\sigma_u \\approx 0.69\\) (vero = 0.60).\n\nLa differenza principale riguarda l’effetto di \\(x\\):\n\nNel GLMM multilevel, \\(\\hat\\beta \\approx 0.50\\),\nNel modello processuale AR(1), \\(\\hat\\beta \\approx 0.61\\), perfettamente in linea con il valore vero.\n\nQuesto accade perché il modello brm controlla l’eterogeneità individuale ma non rappresenta la dinamica temporale: la memoria del passato (\\(\\phi\\)) resta non modellata e una parte della dipendenza seriale viene assorbita nelle stime delle varianze casuali o nell’effetto medio del predittore.\nIl modello in Stan, invece, separa esplicitamente il contributo del predittore (\\(\\beta\\)) dalla persistenza dinamica (\\(\\phi\\)) e dal rumore di processo (\\(\\sigma_u\\)), producendo stime più fedeli al meccanismo generativo.\n\n72.8.3 Messaggio chiave\n\nIl GLMM con slope/intercette casuali cattura bene l’eterogeneità tra soggetti, ma non la dipendenza temporale.\nIl modello AR(1) in Stan, introducendo la dinamica degli stati latenti, fornisce un effetto di \\(x\\) più vicino al valore vero e una rappresentazione più realistica del processo psicologico sottostante.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#riflessioni-conclusive",
    "href": "chapters/glm/05_logistic_process.html#riflessioni-conclusive",
    "title": "72  Dal GLM a un modello processuale per dati binari",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto come estendere la regressione logistica a un modello dinamico AR, in grado di descrivere processi psicologici che evolvono nel tempo. Abbiamo imparato che:\n\nmodellare la dipendenza temporale è essenziale quando si lavora con i dati sequenziali;\nStan consente di implementare questi modelli in modo flessibile;\ni modelli statici (come il GLMM logit) rischiano di fornire stime distorte se la dinamica interna non viene presa in considerazione.\n\nNei capitoli successivi estenderemo questa logica ad altri processi cognitivi e decisionali, mostrando come la modellazione dinamica sia una chiave potente per passare dalla descrizione statistica alla spiegazione psicologica. Questo passaggio dal GLMM al modello processuale mostra che i metodi bayesiani con Stan non servono solo a stimare i parametri in modo diverso, ma anche consentano di testare ipotesi sui meccanismi psicologici sottostanti ai dati osservati.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         bayestestR_0.17.0     cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#bibliografia",
    "href": "chapters/glm/05_logistic_process.html#bibliografia",
    "title": "72  Dal GLM a un modello processuale per dati binari",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChatfield, C., & Xing, H. (2019). The analysis of time series: an introduction with R. Chapman; hall/CRC.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html",
    "href": "chapters/entropy/01_entropy.html",
    "title": "71  Entropia e informazione di Shannon",
    "section": "",
    "text": "Introduzione\nImmagina di dover prevedere la risposta di uno studente a una domanda di un test a scelta multipla. Se non sai nulla dello studente, potresti pensare che ogni risposta sia ugualmente probabile: c’è quindi la massima incertezza. Se invece sai che quello studente è molto preparato e risponde quasi sempre correttamente, allora l’incertezza è bassa. Questa quantificazione dell’incertezza è esattamente ciò che chiamiamo entropia.\nIn termini qualitativi, l’entropia misura la quantità di “sorpresa” che ci aspettiamo:\nUn esempio psicologico: nel lancio di una moneta equilibrata (\\(p\\)=0.5), non possiamo sapere se uscirà testa o croce → entropia massima; nel comportamento di un paziente che mostra sempre la stessa risposta a un questionario → entropia minima.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#introduzione",
    "href": "chapters/entropy/01_entropy.html#introduzione",
    "title": "71  Entropia e informazione di Shannon",
    "section": "",
    "text": "è massima quando tutti gli esiti sono equiprobabili (situazione di totale incertezza),\n\nè minima quando uno degli esiti è praticamente certo.\n\n\nPanoramica del capitolo\n\nIntrodurre il concetto di informazione e la sua unità di misura (bit).\nDefinire l’entropia come media della sorpresa di Shannon.\nInterpretare l’entropia in termini di incertezza e numero di alternative equiprobabili.\n\nStimare l’entropia da distribuzioni teoriche e da campioni osservati.\n\nCollegare l’entropia alla codifica di Huffman e al limite teorico di compressione.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nPer i concetti di base sulla teoria dell’informazione, si rimanda ai primi due capitoli di Information Theory: A Tutorial Introduction (Stone, 2022).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(tidygraph)\n\n# Funzione per calcolare la lunghezza media del codice di Huffman\nhuffman_encoding &lt;- function(probabilities) {\n  # Crea la \"coda con priorità\" iniziale come lista di liste\n  heap &lt;- lapply(names(probabilities), function(sym) list(probabilities[[sym]], list(sym, \"\")))\n\n  # Funzione per ordinare la heap per probabilità (peso)\n  sort_heap &lt;- function(heap) {\n    heap[order(sapply(heap, function(x) x[[1]]))]\n  }\n\n  # Costruzione dell'albero di Huffman\n  while (length(heap) &gt; 1) {\n    heap &lt;- sort_heap(heap)\n    lo &lt;- heap[[1]]\n    hi &lt;- heap[[2]]\n    heap &lt;- heap[-c(1, 2)]\n\n    # Aggiunge i prefissi \"0\" e \"1\" ai codici\n    for (i in seq_along(lo)[-1]) {\n      lo[[i]][[2]] &lt;- paste0(\"0\", lo[[i]][[2]])\n    }\n    for (i in seq_along(hi)[-1]) {\n      hi[[i]][[2]] &lt;- paste0(\"1\", hi[[i]][[2]])\n    }\n\n    merged &lt;- c(list(lo[[1]] + hi[[1]]), lo[-1], hi[-1])\n    heap &lt;- append(heap, list(merged))\n  }\n\n  # Estrai la lista finale dei simboli e codici\n  final &lt;- heap[[1]][-1]\n  names(final) &lt;- sapply(final, function(x) x[[1]])\n\n  # Crea dizionario con codici\n  huffman_dict &lt;- lapply(final, function(x) x[[2]])\n\n  # Calcolo della lunghezza media del codice\n  avg_length &lt;- sum(mapply(function(sym, code) {\n    probabilities[[sym]] * nchar(code)\n  }, names(huffman_dict), huffman_dict))\n\n  return(list(avg_length = avg_length, codes = huffman_dict))\n}",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#che-cosè-linformazione",
    "href": "chapters/entropy/01_entropy.html#che-cosè-linformazione",
    "title": "71  Entropia e informazione di Shannon",
    "section": "\n71.1 Che cos’è l’informazione?",
    "text": "71.1 Che cos’è l’informazione?\nUn bit è l’unità elementare di informazione: rappresenta la scelta tra due possibilità ugualmente probabili. Ogni volta che raddoppiamo il numero di alternative, serve un bit in più per identificarle. Il logaritmo in base 2 (\\(\\log_2\\)) indica esattamente quanti bit sono necessari per distinguere un certo numero di alternative.\n\n71.1.1 Dalle scelte ai bit: un esempio visivo\nPer capire come l’informazione possa essere misurata in bit, consideriamo il seguente esempio. Immaginiamo di trovarci a un incrocio e di dover scegliere una strada tra due possibilità. Ogni volta che ci troviamo di fronte a un incrocio, dobbiamo prendere una decisione: andare a destra o a sinistra. Ogni decisione può essere codificata con un bit: ad esempio, 0 per andare a sinistra e 1 per andare a destra.\nConsideriamo il percorso con più incroci rappresentato nell’immagine seguente. Ogni percorso completo può essere codificato da una sequenza di bit, dove ogni bit corrisponde a una decisione (binaria) presa a un incrocio. Ad esempio, per raggiungere il punto D011, la sequenza di bit corretta è 011.\n\n\n\n\n\n\n\n\n\n71.1.1.1 Quanti bit sono necessari per identificare una destinazione specifica?\nOgni decisione aggiunge un bit alla sequenza che descrive il percorso. Se ci sono \\(m\\) destinazioni possibili, servono\n\\[\nn = \\log_2 m\n\\] bit per identificarne una in modo univoco. Nel nostro esempio, abbiamo otto destinazioni finali. Pertanto, sono necessari 3 bit (3 decisioni binarie) per identificarne una in modo univoco.\n\n71.1.1.2 Cosa rappresenta un bit in questo contesto?\nUn bit rappresenta un’unità elementare di informazione. In questo caso, ogni bit risponde alla domanda: “Devo andare a destra o a sinistra?”.\n\n71.1.1.3 Perché utilizziamo i logaritmi?\nIl logaritmo in base 2 ci permette di calcolare l’esponente a cui elevare 2 per ottenere un dato numero. In altre parole, ci indica quanti bit sono necessari per rappresentare un certo numero di destinazioni. Per l’esempio considerato, per arrivare a \\(D011\\) partendo da \\(A\\), sono necessarie 3 domande la cui risposta è binaria (destra/sinistra).\nPer riassumere:\n\nper raggiungere il punto D011 partendo da A, abbiamo bisogno di prendere tre decisioni binarie (sinistra o destra) in corrispondenza di tre incroci;\nogni decisione binaria può essere rappresentata da un bit (0 o 1). Quindi, per l’intero percorso, abbiamo bisogno di una sequenza di tre bit: 011;\nper rispondere alla domanda “Come si va da A a D011?”, abbiamo dunque bisogno di 3 bit di informazione.\n\nIn sintesi, esiste una relazione diretta tra il numero di bit di informazione e il numero di possibili destinazioni in un percorso decisionale binario. Ogni bit ci permette di scegliere tra due alternative, raddoppiando così il numero di possibili percorsi.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#la-sorpresa-e-linformazione-di-shannon",
    "href": "chapters/entropy/01_entropy.html#la-sorpresa-e-linformazione-di-shannon",
    "title": "71  Entropia e informazione di Shannon",
    "section": "\n71.2 La sorpresa e l’informazione di Shannon",
    "text": "71.2 La sorpresa e l’informazione di Shannon\nIntroduciamo ora un elemento cruciale: la probabilità dell’evento. Quando due eventi hanno probabilità diverse, anche la quantità di informazione che trasmettono è diversa. Un evento molto probabile suscita poca sorpresa e, di conseguenza, veicola poca informazione. Al contrario, un evento raro produce una sorpresa maggiore e trasmette più informazione.\nShannon tradusse questa intuizione in una formula matematica, definendo l’informazione (o “sorpresa”) associata a un evento \\(x\\) come\n\\[\nh(x) = \\log_2 \\frac{1}{p(x)} = -\\log_2 p(x) \\ \\text{bit}.\n\\tag{71.1}\\] Questa espressione mostra chiaramente come l’informazione associata a un evento dipenda in modo inverso dalla sua probabilità: più l’evento è raro, maggiore sarà il valore di \\(h(x)\\).1\nPer rendere l’idea, immaginiamo tre eventi con probabilità rispettivamente pari a 0.5, 0.25 e 0.10. Applicando la formula di Shannon, otteniamo che la sorpresa corrisponde rispettivamente a 1.00 bit, 2.00 bit e 3.32 bit. Si vede così che, man mano che la probabilità diminuisce, la quantità di informazione – misurata in bit – cresce. In altre parole, un’osservazione inattesa “pesa” di più, perché modifica in misura maggiore le nostre conoscenze sul sistema in esame.\n\n71.2.1 Entropia come media dell’informazione di Shannon\nFinora abbiamo considerato la sorpresa associata a un singolo evento. In molti casi, però, non ci interessa un esito isolato, ma vogliamo descrivere l’incertezza complessiva di un sistema che può produrre esiti diversi. Per farlo, occorre calcolare la sorpresa media tenendo conto di tutti i possibili risultati e delle rispettive probabilità. È proprio questo il significato dell’entropia.\nDal punto di vista matematico, l’entropia è la sorpresa media attesa, calcolata come media pesata dell’informazione di Shannon di tutti i possibili esiti di una variabile casuale \\(X\\):\n\\[\nH(X) \\approx \\frac{1}{n} \\sum_{i=1}^{n} h(x_i).\n\\tag{71.2}\\]\nIn questa espressione, \\(h(x_i)\\) rappresenta la quantità di informazione trasmessa da un singolo esito \\(x_i\\), secondo la definizione di Shannon vista in precedenza. L’entropia non si riferisce dunque a un evento specifico, ma alla sorpresa media che ci aspettiamo di provare osservando ripetutamente la variabile.\nSe la distribuzione delle probabilità è perfettamente equilibrata – ad esempio in una distribuzione uniforme, dove tutti i risultati sono ugualmente probabili – l’entropia è massima, poiché ogni osservazione fornisce una quantità simile e relativamente alta di informazione. Se invece la distribuzione è sbilanciata – per esempio nel caso di una moneta truccata che dà quasi sempre “testa” – l’entropia è più bassa, perché la prevedibilità aumenta e la quantità media di informazione fornita da ciascuna osservazione diminuisce.\nIl grafico seguente illustra come la sorpresa di Shannon varia in funzione della probabilità di un evento: eventi rari producono un valore elevato di sorpresa, mentre eventi comuni producono un valore basso.\n\np_vals &lt;- seq(0.001, 1, by = 0.001)\nsurprise &lt;- -log2(p_vals)\n\nggplot(data.frame(p = p_vals, h = surprise), aes(x = p, y = h)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"Probabilità dell'evento p(x)\",\n    y = \"Sorpresa h(x) [bit]\"\n  ) \n\n\n\n\n\n\n\n\n71.2.2 Interpretazione dell’entropia\nDiamo ora un significato concreto al valore numerico dell’entropia. Poiché essa rappresenta la media della sorpresa attesa osservando la realizzazione di una variabile casuale, tenendo conto di tutti i possibili esiti e delle loro probabilità, può essere interpretata come il numero medio di bit necessari per descrivere un’osservazione della variabile \\(X\\).\nQuando l’entropia è espressa in bit, possiamo tradurla in un numero equivalente di alternative equiprobabili utilizzando la relazione\n\\[\nm = 2^{H(X)} .\n\\tag{71.3}\\] Questo significa che un’entropia di \\(H(X)\\) bit corrisponde alla stessa incertezza che avremmo se dovessimo distinguere tra \\(m\\) esiti tutti ugualmente probabili. In questo senso, l’entropia misura la quantità di informazione contenuta in una variabile, esprimendola in termini del numero di scelte equiprobabili che la variabile potrebbe assumere.\n\n\n\n\n\n\nEsercizio — Interpretazione dell’entropia.\n\n\n\n\n\n1. Caso di riferimento: moneta equa.\nSe una variabile casuale può assumere due valori ugualmente probabili, come una moneta equa con \\(p(\\text{testa}) = p(\\text{croce}) = 0.5\\), la sua entropia è:\n\\[\nH(X) = 0.5 \\log_2\\frac{1}{0.5} + 0.5 \\log_2\\frac{1}{0.5}\n      = 0.5 \\times 1 + 0.5 \\times 1\n      = 1 \\ \\text{bit}.\n\\] Questo è il valore massimo di entropia per una variabile con due soli esiti: 1 bit è l’informazione necessaria per distinguere tra due alternative equiprobabili.\n2. Moneta sbilanciata: singolo lancio.\nQuando la moneta è sbilanciata, l’informazione media diminuisce. Supponiamo \\(p(\\text{testa}) = 0.9\\) e \\(p(\\text{croce}) = 0.1\\).\nLa sorpresa associata a ciascun esito è:\n\\[\nh(\\text{testa}) = \\log_2\\frac{1}{0.9} \\approx 0.15 \\ \\text{bit},\n\\]\n\\[\nh(\\text{croce}) = \\log_2\\frac{1}{0.1} \\approx 3.32 \\ \\text{bit}.\n\\]\nPesando queste sorprese con le rispettive probabilità otteniamo l’entropia media:\n\\[\nH(X) = 0.9 \\times 0.15 + 0.1 \\times 3.32 \\approx 0.469 \\ \\text{bit}.\n\\] Questa entropia è inferiore a 1 bit, nonostante l’esito raro (“croce”) sia molto più sorprendente di quello di una moneta equa. In generale, nessuna moneta sbilanciata può avere un’entropia media superiore a quella di una moneta equa.\n3. Più lanci: interpretazione pratica.\nSe lanciamo questa moneta 1000 volte, l’informazione totale prodotta sarà:\n\\[\n1000 \\times 0.469 \\approx 469 \\ \\text{bit}.\n\\] Quindi, rispetto alla moneta equa (1000 bit), otteniamo meno della metà dell’informazione.\n4. Numero equivalente di alternative equiprobabili.\nL’entropia può essere anche interpretata come il numero equivalente di alternative tutte equiprobabili:\n\\[\nm = 2^{H(X)} = 2^{0.469} \\approx 1.38.\n\\] Questo non significa che esista un dado fisico con 1.38 facce: è solo un modo per dire che la quantità di incertezza media di questa moneta è la stessa di una variabile che può assumere circa 1.38 valori tutti con la stessa probabilità.\n\n# Funzione per calcolare l'entropia di una moneta\nentropy_coin &lt;- function(p) {\n  ifelse(p == 0 | p == 1, 0,\n         -p * log2(p) - (1 - p) * log2(1 - p))\n}\n\n# Sequenza di probabilità\np_values &lt;- seq(0, 1, by = 0.01)\nH_values &lt;- entropy_coin(p_values)\n\n# Dati per i punti di esempio\npoints_df &lt;- data.frame(\n  p = c(0.5, 0.9),\n  H = entropy_coin(c(0.5, 0.9)),\n  label = c(\"Moneta equa\\nH=1 bit\", \"Moneta sbilanciata\\nH=0.469 bit\")\n)\n\n# Grafico\nggplot(data.frame(p = p_values, H = H_values), aes(x = p, y = H)) +\n  geom_line(size = 1) +\n  geom_point(data = points_df, aes(x = p, y = H), color = \"brown\", size = 3) +\n  geom_text(data = points_df, aes(label = label), vjust = -1, hjust = 0.5) +\n  labs(\n    x = expression(paste(\"Probabilità di testa, \", p)),\n    y = \"Entropia H(X) [bit]\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n71.2.3 Caratteristiche dell’entropia\nL’entropia raggiunge il suo valore massimo quando tutti gli esiti possibili hanno la stessa probabilità di verificarsi. In questa condizione, l’incertezza è totale: non esiste alcun indizio che permetta di prevedere il risultato meglio del puro caso, e il grado di imprevedibilità è al massimo.\nAll’opposto, l’entropia è minima quando l’esito è completamente certo, cioè quando un evento ha probabilità pari a 1 e tutti gli altri hanno probabilità pari a 0. In tali circostanze non vi è alcuna incertezza, nessuna sorpresa e quindi nessuna informazione aggiuntiva ottenibile dall’osservazione.\nUn’ulteriore caratteristica fondamentale è l’additività per eventi indipendenti: quando due o più eventi sono indipendenti, l’entropia complessiva della loro combinazione è pari alla somma delle entropie dei singoli eventi. Questa proprietà deriva direttamente dall’additività dei logaritmi nella formula di Shannon e riflette il fatto che, nel caso di eventi indipendenti, l’incertezza complessiva si ottiene sommando le incertezze prodotte da ciascun evento considerato separatamente.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#stimare-lentropia",
    "href": "chapters/entropy/01_entropy.html#stimare-lentropia",
    "title": "71  Entropia e informazione di Shannon",
    "section": "\n71.3 Stimare l’entropia",
    "text": "71.3 Stimare l’entropia\nNelle sezioni precedenti abbiamo visto che l’entropia esprime la sorpresa media attesa quando osserviamo una variabile casuale, ed è strettamente legata all’informazione di Shannon dei singoli eventi. Passiamo ora dal concetto alla sua applicazione pratica, illustrando come calcolare l’entropia sia a partire da una distribuzione di probabilità teorica, sia da un insieme di dati osservati.\n\n71.3.1 L’entropia di una distribuzione di probabilità\nImmaginiamo una variabile casuale discreta \\(X\\), che può assumere un insieme di valori distinti \\(x_1, x_2, \\dots, x_n\\), ciascuno con probabilità \\(p(x) = \\Pr\\{X = x\\}\\). Quando osserviamo un particolare valore di \\(X\\), riceviamo una certa quantità di informazione, che possiamo interpretare come il grado di sorpresa associato a quell’esito. Un evento molto improbabile produce un’alta sorpresa, mentre un evento quasi certo trasmette poca o nessuna informazione.\nPer tradurre questa intuizione in termini matematici, definiamo la sorpresa di un esito \\(x\\) come\n\\[\nh(x) = -\\log_2 p(x).\n\\] Questa funzione ha le proprietà desiderate: è tanto più grande quanto minore è la probabilità di \\(x\\), e vale zero se l’evento è certo (\\(p(x) = 1\\)).\nPoiché siamo interessati non a un singolo esito ma all’incertezza complessiva della distribuzione, calcoliamo la media della sorpresa rispetto alle probabilità dei diversi esiti. Otteniamo così la definizione di entropia di Shannon:\n\\[\nH(X) = -\\sum_{x \\in X} p(x) \\log_2 p(x).\n\\tag{71.4}\\] Ogni termine \\(-p(x)\\log_2 p(x)\\) rappresenta il contributo informativo medio di un esito, ponderato in base alla sua probabilità.\nAlcune proprietà fondamentali:\n\nL’entropia è massima quando la distribuzione è uniforme, cioè quando tutti gli esiti sono equiprobabili: in questo caso, l’incertezza è al suo livello più alto.\n\nL’entropia si riduce man mano che la distribuzione diventa più sbilanciata: se alcuni esiti hanno probabilità molto elevate, il grado di sorpresa complessiva diminuisce.\n\nSe un esito è certo, l’entropia si annulla: non c’è incertezza e nessuna nuova informazione viene trasmessa dall’osservazione.\n\nIn breve, l’entropia \\(H(X)\\) misura l’incertezza media di una variabile casuale e può essere interpretata come il numero medio di bit necessari per descrivere un’osservazione di \\(X\\).\n\n\n\n\n\n\nRipasso matematico\n\n\n\n\nLa somma indica che calcoliamo il contributo di ciascun esito possibile.\n\nIl logaritmo (in base 2) ci dice quanta “informazione” porta ogni esito.\n\nIl segno meno serve perché i logaritmi di numeri tra 0 e 1 sono negativi.\n\n\n\n\n\n\n\n\n\n\nEsercizio — Entropia di un dado con otto facce.\n\n\n\n\n\nSupponiamo di avere un dado con otto facce. Ci sono \\(m = 8\\) esiti possibili:\n\\[\nA_x = \\{1,2,3,4,5,6,7,8\\}.\n\\]\nPoiché il dado è equo, tutti gli otto esiti hanno la stessa probabilità di \\(p(x) = 1/8\\), definendo così una distribuzione di probabilità uniforme:\n\\[\np(X) = \\left\\{\\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}\\right\\}.\n\\]\nL’entropia di questa distribuzione può essere calcolata come:\n\\[\nH(X) = - \\sum_{i=1}^{8} \\frac{1}{8} \\log_2 \\frac{1}{8} = \\log_2 8 = 3 \\text{ bit}.\n\\] Poiché l’informazione associata a ciascun esito è esattamente 3 bit, anche l’entropia media è di 3 bit, che rappresenta l’incertezza complessiva della variabile \\(X\\).\nDato che \\(X\\) ha un’entropia di \\(H(X) = 3\\) bit, possiamo dire che \\(X\\) può rappresentare fino a:\n\\[\nm = 2^{H(X)} = 2^3 = 8\n\\] esiti equiprobabili.\n\n\n\n\n\n\n\n\n\nEsercizio — Entropia di un variabile casuale discreta.\n\n\n\n\n\nSia \\(X\\) una variabile casuale discreta che può assumere i valori \\(a, b, c,\\) e \\(d\\) con una distribuzione di probabilità di massa \\(p(a) = \\frac{1}{2}\\), \\(p(b) = \\frac{1}{4}\\), \\(p(c) = \\frac{1}{8}\\), e \\(p(d) = \\frac{1}{8}\\), rispettivamente. L’entropia di \\(X\\), che misura l’incertezza associata alla distribuzione di probabilità, è calcolata come:\n\\[\nH(X) = -\\left(\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{4} \\log_2 \\frac{1}{4} + \\frac{1}{8} \\log_2 \\frac{1}{8} + \\frac{1}{8} \\log_2 \\frac{1}{8}\\right).\n\\] Calcolando i singoli termini, otteniamo:\n\\[\nH(X) = -\\left(\\frac{1}{2} \\cdot (-1) + \\frac{1}{4} \\cdot (-2) + \\frac{1}{8} \\cdot (-3) + \\frac{1}{8} \\cdot (-3)\\right) = \\frac{7}{4} \\text{ bits}.\n\\] È importante notare che l’entropia \\(H(X)\\) dipende esclusivamente dalla distribuzione di probabilità dei valori di \\(X\\) e non dai valori stessi.\n\n\n\n\n71.3.2 L’entropia in un campione di osservazioni\nFinora abbiamo considerato il caso in cui la distribuzione di probabilità sia nota a priori. Nella pratica della ricerca psicologica, tuttavia, disponiamo spesso soltanto di un campione di osservazioni. In questo caso possiamo stimare l’entropia calcolando le frequenze relative di ciascun valore osservato e utilizzandole come stima empirica delle probabilità.\nIl risultato misura quanto la distribuzione dei valori nel campione sia incerta o imprevedibile. Un campione in cui le frequenze siano simili per tutti i valori possibili mostrerà un’entropia stimata elevata; al contrario, se nel campione un valore domina nettamente sugli altri, l’entropia stimata sarà bassa, indicando una distribuzione più prevedibile.\n\n\n\n\n\n\nEsercizio — Entropia di un campione di osservazioni.\n\n\n\n\n\nPer comprendere meglio questo concetto, possiamo calcolare l’entropia associata a insiemi di osservazioni. Consideriamo i due vettori seguenti:\n\\[\n\\begin{align}\nx &= \\{1, 2, 3, 3, 3, 3, 2, 1, 3, 3, 2, 1, 1, 4, 4, 3, 1, 2\\}, \\notag\\\\\ny &= \\{3, 4, 1, 1, 1, 1, 4, 3, 1, 1, 4, 3, 3, 2, 2, 1, 3, 4\\}. \\notag\n\\end{align}\n\\]\nTroviamo l’entropia associata a ciascuno di essi.\n\n# Vettori x e y\nx &lt;- c(1, 2, 3, 3, 3, 3, 2, 1, 3, 3, 2, 1, 1, 4, 4, 3, 1, 2)\ny &lt;- c(3, 4, 1, 1, 1, 1, 4, 3, 1, 1, 4, 3, 3, 2, 2, 1, 3, 4)\n\n# Conta le frequenze\nx_counts &lt;- table(x)\ny_counts &lt;- table(y)\n\n# Calcola le probabilità relative\nx_probabilities &lt;- as.numeric(x_counts) / length(x)\ny_probabilities &lt;- as.numeric(y_counts) / length(y)\n\n# Funzione per calcolare l'entropia (log in base 2)\ncalculate_entropy &lt;- function(probabilities) {\n  -sum(probabilities * log2(probabilities))\n}\n\n# Calcolo dell'entropia\nx_entropy &lt;- calculate_entropy(x_probabilities)\ny_entropy &lt;- calculate_entropy(y_probabilities)\n\n# Stampa i risultati\ncat(sprintf(\"Entropia di x: %.4f bit\\n\", x_entropy))\n#&gt; Entropia di x: 1.8776 bit\ncat(sprintf(\"Entropia di y: %.4f bit\\n\", y_entropy))\n#&gt; Entropia di y: 1.8776 bit\n\nEntrambi i vettori hanno la stessa entropia di 1.8776 bit.\n\n\n\n\n71.3.2.1 Interpretazione finale\nL’entropia \\(H(X)\\) misura dunque l’incertezza media associata a una distribuzione di probabilità. Possiamo leggerla anche come il numero medio di bit necessari per descrivere un’osservazione di \\(X\\).\nIn altre parole, l’entropia ci dice quanta informazione, in media, otteniamo osservando il risultato di una variabile casuale: più alta è l’entropia, maggiore è l’imprevedibilità del fenomeno.\n\n71.3.3 L’entropia di una variabile casuale continua\nAnche per le variabili casuali continue possiamo definire l’entropia, estendendo il caso discreto: la somma sui possibili esiti viene semplicemente sostituita da un integrale. Questa generalizzazione è necessaria perché una variabile continua può assumere un numero infinito di valori. In questo caso, la probabilità che \\(X\\) assuma un valore esatto è sempre zero: ciò che conta non è la probabilità puntuale, ma la densità di probabilità nei diversi punti del dominio.\nPer una variabile casuale continua \\(X\\), con funzione di densità di probabilità \\(p(x)\\), l’entropia, detta in questo caso entropia differenziale, è definita come\n\\[\nH(X) = -\\int p(x) \\log_2 p(x) \\, dx ,\n\\tag{71.5}\\] dove \\(p(x)\\) rappresenta la densità di probabilità di \\(X\\) e l’integrale è calcolato su tutto il dominio della variabile.\nCome nel caso discreto, l’entropia differenziale fornisce una misura dell’incertezza media associata alla distribuzione di probabilità. Se la densità è molto concentrata attorno a pochi valori (ad esempio un picco stretto), l’entropia è bassa: sappiamo già “dove aspettarci” la variabile, quindi l’incertezza è ridotta. Al contrario, una densità più “sparsa” e distribuita uniformemente implica un’entropia più alta, segnalando maggiore imprevedibilità.\nIl segno negativo nella formula deriva dal fatto che, per probabilità comprese tra 0 e 1, il logaritmo è negativo: in questo modo l’entropia assume valori positivi e può essere interpretata, in analogia al caso discreto, come il numero medio di bit necessari per codificare un’osservazione della variabile continua \\(X\\).\n\n\n\n\n\n\nEsercizio — Un confronto numerico: normali più “strette” e più “larghe”.\n\n\n\n\n\nPer la distribuzione normale \\(X \\sim \\mathcal N(\\mu,\\sigma^2)\\) l’entropia differenziale ha una forma chiusa:\n\\[\nH(X)=\\tfrac12 \\log_2\\!\\big(2\\pi e\\,\\sigma^2\\big)\\ \\text{bit}.\n\\] La dipendenza è tutta nella scala \\(\\sigma\\): raddoppiare \\(\\sigma\\) aggiunge esattamente 1 bit di entropia, perché la massa di probabilità si “spalma” su un intervallo più ampio. Numericamente, con \\(\\sigma=0{,}5\\), \\(H(X)\\approx 1{,}047\\) bit; con \\(\\sigma=1\\), \\(H(X)\\approx 2{,}047\\) bit; con \\(\\sigma=2\\), \\(H(X)\\approx 3{,}047\\) bit. L’aumento regolare di un bit per ogni raddoppio di \\(\\sigma\\) rende molto trasparente l’idea che una densità più concentrata (piccola \\(\\sigma\\)) produce minore incertezza, mentre una densità più diffusa (grande \\(\\sigma\\)) produce maggiore incertezza.\nEcco un frammento R che replica il calcolo e mostra le tre densità normalizzate sulla stessa scala, così che la relazione tra forma della densità e entropia sia visibile a colpo d’occhio.\n\n# Entropia differenziale (in bit) per N(mu, sigma^2)\nh_norm_bits &lt;- function(sigma) 0.5 * log2(2 * pi * exp(1) * sigma^2)\n\nsigmas &lt;- c(0.5, 1, 2)\nentropie &lt;- sapply(sigmas, h_norm_bits)\nround(entropie, 3)\n#&gt; [1] 1.05 2.05 3.05\n# atteso: 1.047, 2.047, 3.047\n\n# Visualizzazione delle densità\ndf &lt;- data.frame(\n  x = rep(seq(-6, 6, length.out = 1000), times = length(sigmas)),\n  sigma = factor(rep(sigmas, each = 1000))\n)\ndf$dens &lt;- mapply(function(x, s) dnorm(x, mean = 0, sd = s), df$x, as.numeric(as.character(df$sigma)))\n\nggplot(df, aes(x = x, y = dens, group = sigma)) +\n  geom_line(aes(linetype = sigma), linewidth = 1) +\n  labs(\n    subtitle = paste0(\"H(σ=0.5)≈\", round(entropie[1],3), \" bit; \",\n                      \"H(σ=1)≈\",   round(entropie[2],3), \" bit; \",\n                      \"H(σ=2)≈\",   round(entropie[3],3), \" bit\"),\n    x = \"x\", y = \"densità\"\n  ) \n\n\n\n\n\n\n\nNell’analisi di dati psicologici, la stessa variabile misurata con una scala più “compressa” (varianza più piccola, punteggi concentrati) porta a una minore entropia differenziale rispetto alla stessa variabile osservata con maggiore dispersione. Questo legame diretto tra dispersione e entropia chiarisce perché, in presenza di eterogeneità individuale o situazionale, la “quantità di incertezza” da descrivere aumenti con la variabilità del fenomeno.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#la-codifica-di-huffman",
    "href": "chapters/entropy/01_entropy.html#la-codifica-di-huffman",
    "title": "71  Entropia e informazione di Shannon",
    "section": "\n71.4 La codifica di Huffman",
    "text": "71.4 La codifica di Huffman\nAbbiamo visto che l’entropia \\(H(X)\\) di una variabile casuale \\(X\\) misura la sorpresa media di un esito. Un risultato fondamentale è che l’entropia rappresenta anche il limite teorico inferiore alla lunghezza media, in bit, di un codice binario che descrive gli esiti di \\(X\\). In altre parole: è impossibile creare un sistema di codifica (una “scorciatoia” per rappresentare l’informazione) che, in media, usi meno bit di \\(H(X)\\) per simbolo, senza perdere informazioni.\nL’algoritmo di Huffman, sviluppato da David A. Huffman nel 1952, fornisce un metodo pratico per costruire un codice che si avvicina moltissimo a questo limite teorico.\n\n71.4.1 L’idea di base\nL’idea centrale è semplice e intuitiva, e riflette una strategia di ottimizzazione che anche la nostra mente potrebbe usare: assegna “etichette” mentali corte agli eventi comuni e etichette più lunghe agli eventi rari.\nPensate a come abbreviate le parole che usate più spesso in un messaggio di testo (“tvb”, “xké”, “nn”) mentre scrivete per intero quelle più rare. State applicando un principio simile a quello di Huffman per risparmiare tempo (bit cognitivi)!\n\n71.4.2 Come funziona l’algoritmo, passo dopo passo\nL’obiettivo è costruire un albero binario le cui foglie sono i simboli da codificare. La procedura è la seguente:\n\n\nLista di partenza: Si parte da un elenco di tutti i simboli con le loro probabilità (o frequenze). Ogni simbolo è un piccolo “nodo”.\n\nUnire i più rari: Si identificano i due nodi con la probabilità più bassa e si uniscono per creare un nuovo nodo. A questo nuovo nodo si associa una probabilità pari alla somma delle probabilità dei due nodi figli.\n\nRipetere: Si ripete il passo 2, unendo sempre i due nodi con la probabilità più bassa (considerando anche i nuovi nodi creati), finché non rimane un unico nodo finale, chiamato radice. Questo è l’albero completo.\n\nAssegnare i codici: Si percorre l’albero dalla radice fino a ciascun simbolo (foglia). Ad ogni ramo sinistro si assegna il valore 0 e ad ogni ramo destro il valore 1. La sequenza di 0 e 1 incontrata nel percorso dalla radice alla foglia è il codice di Huffman per quel simbolo.\n\nLa caratteristica geniale di questo codice è che è un codice prefisso: nessun codice è l’inizio (il “prefisso”) di un altro. Questo elimina ogni ambiguità durante la decodifica, permettendo di leggere il messaggio senza bisogno di simboli separatori.\n\n71.4.3 Esempio concreto: codificare un messaggio\nImmaginiamo di dover codificare un messaggio composto da 43 caratteri, usando solo quattro lettere con queste frequenze:\n\n\nSimbolo\nFrequenza\nProbabilità\n\n\n\nA\n20\n~0.47\n\n\nB\n10\n~0.23\n\n\nC\n8\n~0.19\n\n\nD\n5\n~0.12\n\n\n\nCostruiamo l’albero:\n\n\nPasso 1: Uniamo i due simboli meno frequenti, D (5) e C (8), in un nuovo nodo che chiamiamo temporaneamente N1 con frequenza 13.\n\nPasso 2: Ora i nodi disponibili sono A(20), B(10) e N1(13). I due meno frequenti sono B (10) e N1 (13). Li uniamo in un nuovo nodo N2 con frequenza 23.\n\nPasso 3: Restano solo A(20) e N2(23). Li uniamo per formare la radice con frequenza 43.\n\nL’albero risultante è:\n         (Radice:43)\n         /         \\\n       0/           \\1\n      (A:20)      (N2:23)\n                 /       \\\n               0/         \\1\n            (B:10)      (N1:13)\n                       /       \\\n                     0/         \\1\n                   (D:5)       (C:8)\nAssegniamo i codici (percorrendo il percorso dalla Radice alla foglia):\n\nA: il percorso è solo 0 → Codice: 0\n\nB: il percorso è Radice → N2 (1) → B (0) → Codice: 10\n\nD: il percorso è Radice → N2 (1) → N1 (1) → D (0) → Codice: 110\n\nC: il percorso è Radice → N2 (1) → N1 (1) → C (1) → Codice: 111\n\n\nEcco la nostra tabella di codifica finale:\n\n\nSimbolo\nCodice\nLunghezza\n\n\n\nA\n0\n1 bit\n\n\nB\n10\n2 bit\n\n\nD\n110\n3 bit\n\n\nC\n111\n3 bit\n\n\n\nNotate come il simbolo più frequente (A) ha ottenuto il codice più corto (1 bit), mentre quelli più rari (C e D) hanno codici più lunghi (3 bit).\n\n71.4.4 Collegamento con l’entropia: quanto ci siamo avvicinati al limite?\nTorniamo alla teoria. Usando le probabilità dell’esempio, possiamo calcolare:\n\n\nLunghezza media del codice (\\(L\\)): quanti bit usiamo in media per simbolo?\n\n\\[\n\\begin{align}\nL &= (p(A)\\cdot 1) + (p(B)\\cdot 2) + (p(C)\\cdot 3) + (p(D)\\cdot 3) \\notag\\\\\n&= (0.47\\cdot 1) + (0.23\\cdot 2) + (0.19\\cdot 3) + (0.12\\cdot 3) \\notag \\\\\n   &\\approx 1.9 \\ \\text{bit}\n\\end{align}\n\\]\n\n\nEntropia (\\(H(X)\\)): il limite teorico minimo di bit per simbolo.\n\n\\[\n\\begin{align}\nH(X) &= -\\big[\\,0.47\\log_2(0.47) + 0.23\\log_2(0.23) \\notag\\\\\n&\\qquad + 0.19\\log_2(0.19) + 0.12\\log_2(0.12)\\,\\big] \\notag\\\\\n& \\quad\\approx 1.85 \\ \\text{bit}\n\\end{align}\n\\]\nRisultato: La nostra codifica di Huffman (1.9 bit/simbolo) è estremamente vicina al limite teorico dell’entropia (1.85 bit/simbolo). La piccola differenza è dovuta al fatto che i codici devono avere una lunghezza intera (non possiamo avere un codice di 1.85 bit!), mentre l’entropia è un valore medio che può essere decimale.\n\n71.4.4.1 In sintesi\n\n\n\n\n\n\n\nConcetto\nSignificato Teorico\nAnalogia Psicologica (Approssimativa)\n\n\n\nEntropia H(X)\nLimite teorico assoluto di compressione. Misura l’incertezza/intrinseca.\nIl “carico cognitivo” minimo necessario per rappresentare uno stimolo.\n\n\nCodifica di Huffman\nMetodo pratico per costruire un codice ottimale che si avvicina al limite H(X).\nUna strategia cognitiva efficiente per categorizzare informazioni (es. etichette mentali corte per concetti comuni).\n\n\nLunghezza media L\nIl risultato pratico ottenuto con Huffman.\nIl reale “costo” cognitivo della strategia adottata.\n\n\nDifferenza (L - H(X))\nQuanto il metodo pratico si discosta dal limite teorico ideale.\nQuanto la nostra strategia cognitiva è efficiente rispetto all’ideale.\n\n\n\nIn sintesi, l’algoritmo di Huffman rappresenta un ponte tra la teoria e la pratica. Esso dimostra in modo tangibile come il principio astratto dell’entropia—il limite teorico di compressione—possa essere realizzato in una strategia concreta. Questo processo di ottimizzazione offre una potente analogia per ipotizzare come la nostra mente potrebbe elaborare le informazioni in modo efficiente, privilegiando gli stimoli più frequenti per risparmiare risorse cognitive.\n\n\n\n\n\n\nEsercizio — Entropia e codifica di Huffman.\n\n\n\n\n\nSupponiamo di avere una variabile casuale \\(X\\) che può assumere quattro valori: \\(A\\), \\(B\\), \\(C\\), e \\(D\\), con le seguenti probabilità:\n\n\\(p(A) = 0.4\\)\n\\(p(B) = 0.3\\)\n\\(p(C) = 0.2\\)\n\\(p(D) = 0.1\\)\n\nPer rappresentare questi esiti con un codice binario efficiente possiamo usare la codifica di Huffman, che assegna codici più brevi ai simboli più probabili, e codici più lunghi a quelli meno probabili.\nSupponiamo che Huffman produca la seguente codifica:\n\nA = 0 (1 bit)\nB = 10 (2 bit)\nC = 110 (3 bit)\nD = 111 (3 bit)\n\nLa lunghezza media del codice si ottiene moltiplicando la probabilità di ciascun simbolo per la lunghezza del suo codice binario, e poi sommando:\n\\[\n\\begin{align}\n\\text{Lunghezza media} &= (0.4 \\times 1) + (0.3 \\times 2) + (0.2 \\times 3) + (0.1 \\times 3) \\\\\n&= 0.4 + 0.6 + 0.6 + 0.3 = 1.9 \\text{ bit}.\n\\end{align}\n\\]\nQuesto significa che, in media, servono 1.9 bit per rappresentare un’osservazione della variabile \\(X\\) usando la codifica di Huffman.\nConfermiamo il risultato con il seguente codice R:\n\n# Definizione delle probabilità\nprobabilities &lt;- list(A = 0.4, B = 0.3, C = 0.2, D = 0.1)\n\n\n# Funzione per la codifica di Huffman\nhuffman_encoding &lt;- function(probabilities) {\n  nodes &lt;- lapply(names(probabilities), function(sym) {\n    list(symbol = sym, prob = probabilities[[sym]], left = NULL, right = NULL)\n  })\n\n  while (length(nodes) &gt; 1) {\n    nodes &lt;- nodes[order(sapply(nodes, function(n) n$prob))]\n    left &lt;- nodes[[1]]\n    right &lt;- nodes[[2]]\n    merged &lt;- list(symbol = NULL, prob = left$prob + right$prob, left = left, right = right)\n    nodes &lt;- c(nodes[-c(1, 2)], list(merged))\n  }\n\n  assign_codes &lt;- function(node, prefix = \"\", code_map = list()) {\n    if (!is.null(node$symbol)) {\n      code_map[[node$symbol]] &lt;- prefix\n    } else {\n      code_map &lt;- assign_codes(node$left, paste0(prefix, \"0\"), code_map)\n      code_map &lt;- assign_codes(node$right, paste0(prefix, \"1\"), code_map)\n    }\n    return(code_map)\n  }\n\n  code_map &lt;- assign_codes(nodes[[1]])\n\n  avg_length &lt;- sum(sapply(names(probabilities), function(sym) {\n    probabilities[[sym]] * nchar(code_map[[sym]])\n  }))\n\n  return(list(avg_length = avg_length, huffman_dict = code_map))\n}\n\n\n# Applicazione e stampa dei risultati\nresult &lt;- huffman_encoding(probabilities)\n\ncat(sprintf(\"Lunghezza media del codice di Huffman: %.2f bit/simbolo\\n\", result$avg_length))\n#&gt; Lunghezza media del codice di Huffman: 1.90 bit/simbolo\ncat(\"Codici di Huffman:\\n\")\n#&gt; Codici di Huffman:\nfor (sym in names(result$huffman_dict)) {\n  cat(sprintf(\"%s: %s\\n\", sym, result$huffman_dict[[sym]]))\n}\n#&gt; A: 0\n#&gt; B: 10\n#&gt; D: 110\n#&gt; C: 111\n\nOra calcoliamo l’entropia teorica della variabile \\(X\\), cioè la lunghezza media minima che qualsiasi codifica binaria può raggiungere:\n\\[\n\\begin{align}\nH(X) &= - \\sum p(x) \\log_2 p(x) \\\\\n     &= -[0.4 \\log_2 0.4 + 0.3 \\log_2 0.3 + 0.2 \\log_2 0.2 + 0.1 \\log_2 0.1] \\\\\n     &= 1.8465 \\text{ bit}.\n\\end{align}\n\\] Il valore dell’entropia è leggermente inferiore alla lunghezza media di Huffman (1.9 bit). Questo è normale: Huffman fornisce codici con lunghezza intera in bit, mentre l’entropia può assumere valori decimali. La codifica di Huffman è quindi quasi ottimale.\nIn sintesi:\n\n\nl’entropia \\(H(X)\\) rappresenta la lunghezza media teorica minima (in bit) per codificare una variabile casuale;\nla codifica di Huffman costruisce un codice binario che si avvicina molto a questo limite, usando più bit per i simboli rari e meno bit per quelli frequenti;\nin questo modo, l’entropia ci offre un criterio per valutare quanto efficiente è una codifica: più la lunghezza media si avvicina all’entropia, più è efficiente.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#applicazioni-psicologiche",
    "href": "chapters/entropy/01_entropy.html#applicazioni-psicologiche",
    "title": "71  Entropia e informazione di Shannon",
    "section": "\n71.5 Applicazioni psicologiche",
    "text": "71.5 Applicazioni psicologiche\nIl concetto di entropia, inteso come misura della sorpresa media associata a un evento, trova applicazioni dirette anche nello studio di fenomeni psicologici. In particolare, la sorpresa — formalizzabile in termini di informazione di Shannon — è stata associata a cambiamenti emotivi, processi di apprendimento e modulazione della motivazione.\nUn esempio classico è fornito da Spector (1956), che studiò l’effetto della probabilità a priori sulla soddisfazione dei soggetti in seguito a una promozione lavorativa. I risultati mostrarono che esiti inizialmente percepiti come poco probabili — e quindi più sorprendenti quando si verificano — producevano un impatto emotivo maggiore rispetto a esiti attesi. In altre parole, la sorpresa amplificava la risposta affettiva, confermando l’idea che l’entropia non sia solo una misura astratta, ma un indicatore della potenziale intensità della reazione emotiva.\nRicerche più recenti, in contesti sia sperimentali che ecologici, hanno confermato questo legame. Ad esempio, studi nell’ambito delle neuroscienze cognitive hanno mostrato che eventi ad alta sorpresa modulano l’attività di aree cerebrali legate all’elaborazione emotiva, come l’amigdala e la corteccia prefrontale ventromediale, influenzando sia l’umore immediato sia l’apprendimento successivo. Allo stesso modo, nell’analisi dei dati di Ecological Momentary Assessment (EMA), la probabilità soggettiva di un evento può essere messa in relazione alla variazione momentanea dell’umore, mostrando che episodi rari o inattesi tendono a generare oscillazioni emotive più marcate.\nQuesti risultati illustrano bene come il concetto di entropia possa essere utilizzato in psicologia non solo come strumento di misura della distribuzione di probabilità degli eventi, ma anche come variabile esplicativa in modelli che indagano il legame tra aspettative, sorpresa e stati emotivi. Questo stesso legame sarà centrale quando, nelle prossime sezioni, introdurremo la divergenza di Kullback–Leibler e la utilizzeremo per confrontare modelli in un’ottica bayesiana.\n\n\n\n\n\n\nEsercizio – probabilità, sorpresa e umore.\n\n\n\n\n\nIn questo esempio, simuliamo 200 osservazioni in cui ogni partecipante sperimenta un evento con probabilità variabile. La sorpresa di ciascun evento viene calcolata con la formula di Shannon, e l’effetto sull’umore viene simulato assumendo che eventi più sorprendenti producano, in media, variazioni di umore più ampie (positive o negative).\n\nset.seed(123)\n\n# Numero di osservazioni\nn &lt;- 200\n\n# Probabilità percepita dell'evento (da molto probabile a molto improbabile)\np_event &lt;- runif(n, min = 0.05, max = 0.95)\n\n# Sorpresa di Shannon (in bit)\nsurprise &lt;- -log2(p_event)\n\n# Variazione di umore simulata:\n# partiamo da un effetto medio proporzionale alla sorpresa, con rumore casuale\ndelta_mood &lt;- 0.5 * surprise + rnorm(n, mean = 0, sd = 0.5)\n\n# Mettiamo tutto in un data frame\ndf &lt;- data.frame(\n  p_event = p_event,\n  surprise = surprise,\n  delta_mood = delta_mood\n)\n\n# Visualizzazione\nggplot(df, aes(x = surprise, y = delta_mood)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"blue\") +\n  labs(\n    x = \"Sorpresa (bit)\",\n    y = \"Δ Umore\"\n  ) \n\n\n\n\n\n\n\nInterpretazione. Il grafico mostra che, in questa simulazione, eventi più sorprendenti (bit più alti) tendono a produrre variazioni di umore maggiori. Questo illustra visivamente l’idea, già documentata empiricamente, che la sorpresa può amplificare la risposta emotiva.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "href": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "title": "71  Entropia e informazione di Shannon",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo esplorato come l’entropia ci permetta di misurare quantitativamente l’incertezza e l’informazione in sistemi complessi. Attraverso esempi concreti - dal lancio di una moneta alla codifica di messaggi - abbiamo visto come questo concetto matematico possa essere applicato in modo pratico e intuitivo.\n\n71.5.1 Cosa abbiamo imparato\n\n\nL’entropia misura l’incertezza: Più una situazione è imprevedibile (come una moneta equilibrata), maggiore è la sua entropia. Situazioni prevedibili (come un comportamento stereotipato) hanno invece entropia bassa.\n\nL’informazione è sorpresa: Eventi rari e inaspettati ci forniscono più informazione rispetto a eventi comuni. La formula di Shannon cattura precisamente questa intuizione quotidiana.\n\nEsiste un limite alla compressione: L’entropia rappresenta il numero minimo di bit necessari per descrivere un’informazione senza perdite. L’algoritmo di Huffman ci mostra come avvicinarci a questo limite nella pratica.\n\n\n71.5.1.1 Perché è rilevante per la psicologia?\nQuesti concetti non sono solo astratti, ma trovano applicazioni concrete nella ricerca psicologica:\n\n\nModellizzazione cognitiva: I processi mentali possono essere visti come sistemi che elaborano informazione. L’entropia ci aiuta a quantificare quanto “lavoro” cognitivo sia necessario per processare stimoli diversi.\n\nEmozioni e sorpresa: Come abbiamo visto nell’esempio finale, eventi sorprendenti (alta entropia) tendono a produrre risposte emotive più intense. Questo collegamento tra probabilità e emozione è un campo di ricerca attivo.\n\nValutazione dei modelli: Nei prossimi capitoli vedremo come l’entropia sia la base per strumenti che ci permettono di confrontare modelli psicologici e valutarne la capacità predittiva.\n\n71.5.1.2 Uno sguardo al futuro\nL’entropia non è solo un concetto isolato, ma il fondamento per strumenti più avanzati che incontreremo:\n\nla divergenza di Kullback-Leibler (nel prossimo capitolo) misura quanto un modello si discosta dalla realtà, usando proprio i concetti di entropia che abbiamo appreso;\nl’ELPD (Expected Log Predictive Density) ci aiuterà a confrontare modelli bayesiani valutando la loro capacità predittiva.\n\nComprendere l’entropia significa quindi possedere una chiave interpretativa potente: ci permette di passare dall’osservazione qualitativa (“questo comportamento è più variabile”) alla misurazione quantitativa (“l’entropia di questo comportamento è X bit”).\n\n\n\n\n\n\nMappa concettuale: dall’entropia alla valutazione dei modelli\n\n\n\n\n\nEntropia \\(H(X)\\)\n→ Misura l’incertezza intrinseca di una variabile casuale.\n→ Interpretabile come la sorpresa media o la lunghezza media minima (in bit) necessaria per codificare gli esiti di \\(X\\).\nDivergenza di Kullback–Leibler \\(D_{KL}(P \\parallel Q)\\)\n→ Confronta due distribuzioni di probabilità \\(P\\) (la “vera” distribuzione) e \\(Q\\) (il modello).\n→ Misura quanto il modello \\(Q\\) si discosta da \\(P\\) in termini di inefficienza nel codificare i dati.\nExpected Log Predictive Density (ELPD)\n→ Valuta la capacità predittiva di un modello su dati nuovi.\n→ Collegata alla minimizzazione della KL tra la distribuzione dei dati e la distribuzione predittiva del modello.\n→ Più alto è l’ELPD, migliore è la capacità del modello di rappresentare e prevedere i dati.\nCollegamento logico:\nEntropia → ci dice quanta incertezza c’è nei dati.\nKL → ci dice quanto un modello spreca informazione rispetto a quella incertezza.\nELPD → ci dice quanto bene il modello prevede, riducendo quello spreco.\n\n\n\n\n\nFigura 71.1: Diagramma visivo che collega Entropia → Divergenza KL → ELPD.\n\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidygraph_1.3.1       ggraph_2.2.2          igraph_2.1.4         \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        mgcv_1.9-3           \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        rmarkdown_2.29       \n#&gt; [19] ragg_1.4.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        tweenr_2.0.3         \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      viridis_0.6.5         abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 polyclip_1.10-7      \n#&gt; [52] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [55] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [58] rstantools_2.4.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [61] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [64] graphlayouts_1.2.2    mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [67] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [70] ggforce_0.5.0         cli_3.6.5             textshaping_1.0.1    \n#&gt; [73] svUnit_1.0.8          viridisLite_0.4.2     Brobdingnag_1.2-9    \n#&gt; [76] V8_6.0.6              gtable_0.3.6          digest_0.6.37        \n#&gt; [79] ggrepel_0.9.6         TH.data_1.1-3         htmlwidgets_1.6.4    \n#&gt; [82] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [85] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#bibliografia",
    "href": "chapters/entropy/01_entropy.html#bibliografia",
    "title": "71  Entropia e informazione di Shannon",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSpector, A. J. (1956). Expectations, fulfillment, and morale. The Journal of Abnormal and Social Psychology, 52(1), 51–56.\n\n\nStone, J. V. (2022). Information theory: a tutorial introduction, 2nd edition.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#footnotes",
    "href": "chapters/entropy/01_entropy.html#footnotes",
    "title": "71  Entropia e informazione di Shannon",
    "section": "",
    "text": "Ricorda che per le proprietà dei logaritmi: \\(\\log(1/x) = -\\log(x)\\), perché \\(\\log(1/x) = \\log(1) - \\log(x) = 0 - \\log(x)\\).↩︎",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html",
    "href": "chapters/entropy/02_kl.html",
    "title": "74  La divergenza di Kullback-Leibler",
    "section": "",
    "text": "Introduzione\nNel capitolo precedente abbiamo introdotto l’entropia come misura dell’incertezza di una distribuzione di probabilità. Ora facciamo un passo avanti: invece di misurare l’incertezza di una sola distribuzione, vogliamo misurare quanto una distribuzione differisce da un’altra. Uno strumento cruciale per rispondere a questa domanda è la divergenza di Kullback-Leibler (Kullback & Leibler, 1951), spesso abbreviata come divergenza KL (\\(D_{\\text{KL}}\\)). Essa misura quanto si perde in precisione o efficienza se si utilizza un modello errato per descrivere la realtà.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#introduzione",
    "href": "chapters/entropy/02_kl.html#introduzione",
    "title": "74  La divergenza di Kullback-Leibler",
    "section": "",
    "text": "Panoramica del capitolo\n\nCos’è la divergenza KL e da dove nasce.\nCome si collega al concetto di entropia.\nPerché è utile nella scelta tra modelli statistici.\nCome calcolarla e interpretarla, anche con esempi in R.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nPer comprendere appieno questo capitolo, dovresti aver già appreso i concetti di entropia e informazione di Shannon (Capitolo 71).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Funzione per il calcolo dei termini della divergenza KL\nkl_terms &lt;- function(p, q) {\n  stopifnot(length(p) == length(q))\n  non_zero &lt;- p &gt; 0 & q &gt; 0\n  p &lt;- p[non_zero]\n  q &lt;- q[non_zero]\n  term &lt;- p * log2(p / q)\n  data.frame(x = seq_along(p), p = p, q = q, term = term)\n}\n\n# Funzione compatta per il valore totale\nkl_divergence &lt;- function(p, q) {\n  sum(kl_terms(p, q)$term)\n}\n\n# Entropia vera (in bit)\nentropy &lt;- function(p) {\n  p &lt;- p[p &gt; 0]\n  -sum(p * log2(p))\n}\n\n# Entropia incrociata (in bit)\ncross_entropy &lt;- function(p, q) {\n  non_zero &lt;- p &gt; 0 & q &gt; 0\n  p &lt;- p[non_zero]\n  q &lt;- q[non_zero]\n  -sum(p * log2(q))\n}",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#la-generalizzabilità-dei-modelli-e-il-metodo-scientifico",
    "href": "chapters/entropy/02_kl.html#la-generalizzabilità-dei-modelli-e-il-metodo-scientifico",
    "title": "74  La divergenza di Kullback-Leibler",
    "section": "\n74.1 La generalizzabilità dei modelli e il metodo scientifico",
    "text": "74.1 La generalizzabilità dei modelli e il metodo scientifico\nUno degli obiettivi fondamentali della scienza è la generalizzabilità: un buon modello non deve spiegare solo i dati che abbiamo già, ma anche prevedere correttamente nuovi dati che potremmo raccogliere in futuro. Un modello troppo semplice rischia di sotto-adattarsi ai dati (underfitting), perdendo informazioni importanti; uno troppo complesso rischia di sovra-adattarsi (overfitting), confondendo il rumore casuale con segnali reali. Il problema della generalizzabilità è quindi centrale nel metodo scientifico: vogliamo modelli abbastanza flessibili da catturare i pattern reali, ma non così flessibili da adattarsi anche a variazioni casuali.\nNell’approccio bayesiano, come osserva McElreath (2020), la scelta di un modello implica trovare un equilibrio tra due esigenze:\n\n\naccuratezza predittiva – il modello deve produrre previsioni affidabili sui dati futuri;\n\ncontrollo della complessità – il modello non deve introdurre più complessità di quanta ne richieda il fenomeno studiato.\n\nQuesto principio è vicino a quello noto come rasoio di Occam: tra due modelli che spiegano altrettanto bene i dati, preferiamo quello più semplice. La differenza è che, in ambito bayesiano, questa preferenza non è solo una regola intuitiva, ma può essere formalizzata in termini quantitativi, misurando quanta “informazione in più” dobbiamo spendere quando il nostro modello si discosta dalla realtà. Questa misura è data dalla divergenza di Kullback–Leibler, che vedremo nel seguito.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#lentropia-relativa",
    "href": "chapters/entropy/02_kl.html#lentropia-relativa",
    "title": "74  La divergenza di Kullback-Leibler",
    "section": "\n74.2 L’entropia relativa",
    "text": "74.2 L’entropia relativa\nNel Capitolo 71 abbiamo visto che l’entropia \\(H(P)\\) misura la lunghezza media del codice più efficiente per descrivere una distribuzione di probabilità \\(P\\). Ora estendiamo il ragionamento al confronto tra due distribuzioni:\n\n\n\\(P\\) = distribuzione vera dei dati, cioè quella che genera realmente gli eventi;\n\n\\(Q\\) = distribuzione approssimata, cioè quella fornita dal modello.\n\nLa divergenza di Kullback–Leibler, \\(D_{\\text{KL}}(P \\parallel Q)\\), risponde alla seguente domanda:\n\nin media, quanta informazione in più dobbiamo spendere se usiamo \\(Q\\) invece di \\(P\\) per descrivere i dati?\n\nDal punto di vista della codifica, questa quantità rappresenta l’aumento medio della lunghezza del codice quando si usa un modello impreciso.\n\n74.2.1 Definizione formale\nPer una variabile casuale discreta \\(X\\):\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\sum_x p(x) \\log_2 \\frac{p(x)}{q(x)}\n\\tag{74.1}\\]\nche può essere riscritta come:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\sum_x p(x) \\left[ \\log_2 p(x) - \\log_2 q(x) \\right].\n\\tag{74.2}\\]\nQuesta forma mette in evidenza un’interpretazione intuitiva:\n\n\n\\(\\log_2 p(x)\\) è l’informazione (in bit) associata all’esito \\(x\\) secondo la distribuzione vera \\(P\\);\n\n\\(\\log_2 q(x)\\) è l’informazione associata allo stesso esito secondo il modello \\(Q\\);\nla differenza \\(\\log_2 p(x) - \\log_2 q(x)\\) indica, per quell’esito, quanto il modello \\(Q\\) sottostima o sovrastima la sorpresa rispetto a \\(P\\);\nmoltiplicando per \\(p(x)\\) e sommando su tutti gli esiti otteniamo una media ponderata (pesata in base a quanto l’esito è probabile nella realtà).\n\nIn sintesi, \\(D_{\\text{KL}}(P \\parallel Q)\\) è la perdita media di efficienza quando descriviamo la variabile \\(X\\) con la distribuzione approssimata \\(Q\\) invece che con la distribuzione vera \\(P\\).\nSe \\(P = Q\\) la divergenza è 0, perché non vi è alcuna perdita. Quanto più \\(Q\\) si discosta da \\(P\\), tanto più grande sarà la divergenza, segnalando un “costo informativo” maggiore.\n\n\n\n\n\n\nEsempio: Divergenza KL (1)\n\n\n\n\n\nSupponiamo che la variabile casuale \\(X\\) possa assumere tre valori: A, B e C.\nLa distribuzione vera (\\(P\\)) è:\n\n\nx\n\\(p(x)\\)\n\n\n\nA\n0.5\n\n\nB\n0.3\n\n\nC\n0.2\n\n\n\nIl modello approssimante (\\(Q\\)) è:\n\n\nx\n\\(q(x)\\)\n\n\n\nA\n0.4\n\n\nB\n0.4\n\n\nC\n0.2\n\n\n\nCalcoliamo la divergenza KL:\n\\[\n\\begin{aligned}\nD_{\\text{KL}}(P \\parallel Q) &= 0.5 \\log_2\\!\\left(\\frac{0.5}{0.4}\\right)\n+ 0.3 \\log_2\\!\\left(\\frac{0.3}{0.4}\\right)\n+ 0.2 \\log_2\\!\\left(\\frac{0.2}{0.2}\\right) \\\\[4pt]\n&= 0.5 \\log_2(1.25) + 0.3 \\log_2(0.75) + 0.2 \\log_2(1) \\\\[4pt]\n&\\approx 0.160 - 0.125 + 0 \\\\[4pt]\n&= 0.035 \\ \\text{bit}.\n\\end{aligned}\n\\]\nInterpretazione\n\nPer A, il modello \\(Q\\) sottostima la probabilità vera (0.4 invece di 0.5). Questo comporta un costo informativo positivo: il codice dovrà essere leggermente più lungo rispetto all’uso di \\(P\\).\nPer B, il modello \\(Q\\) sovrastima la probabilità vera (0.4 invece di 0.3). Qui il costo informativo è negativo, ma va pesato dal fatto che nella divergenza KL la somma è pesata secondo \\(P\\), e dunque conta di più la stima errata sugli eventi più probabili.\nPer C, il modello è perfetto (\\(p(x) = q(x)\\)) e il contributo alla divergenza è nullo.\n\nIl risultato complessivo, 0.035 bit per evento, è molto piccolo: significa che, in media, usando \\(Q\\) al posto di \\(P\\) spenderemmo appena 0.035 bit di informazione in più per descrivere ogni osservazione. Le due distribuzioni sono quindi molto simili, ma la divergenza KL rileva comunque la differenza residua.\n\n\n\n\n\n\n\n\n\nEsempio: Divergenza KL (2)\n\n\n\n\n\nSupponiamo che la variabile casuale \\(X\\) possa assumere tre valori: x = 1, 2, 3.\n\n\nDistribuzione vera (\\(P\\)): \\([0.1, \\ 0.6, \\ 0.3]\\)\n\n\nDistribuzione approssimata (\\(Q\\)): \\([0.2, \\ 0.5, \\ 0.3]\\)\n\n\nCalcoliamo la divergenza KL secondo la formula ?eq-kl-def:\n\n# Definizione delle distribuzioni\nP &lt;- c(0.1, 0.6, 0.3)  # distribuzione vera\nQ &lt;- c(0.2, 0.5, 0.3)  # distribuzione approssimata\n\n\n# Calcolo dei contributi per ciascun esito\ndf_kl_terms &lt;- kl_terms(P, Q)\nprint(df_kl_terms)\n#&gt;   x   p   q   term\n#&gt; 1 1 0.1 0.2 -0.100\n#&gt; 2 2 0.6 0.5  0.158\n#&gt; 3 3 0.3 0.3  0.000\n\n\n# Visualizzazione dei contributi\nggplot(df_kl_terms, aes(x = factor(x), y = term)) +\n  geom_col(fill = \"steelblue\") +\n  geom_hline(yintercept = 0, color = \"black\", linewidth = 0.3) +\n  labs(\n    x = \"Valori possibili di X\",\n    y = \"Contributo alla Divergenza KL\",\n    title = \"Contributo di ciascun esito alla Divergenza KL\"\n  )\n\n\n\n\n\n\n\nInfine, sommiamo i contributi per ottenere la divergenza totale:\n\nKL_total &lt;- sum(df_kl_terms$term)\ncat(sprintf(\"Divergenza KL da P a Q: %.4f bit\\n\", KL_total))\n#&gt; Divergenza KL da P a Q: 0.0578 bit\n\nInterpretazione\n\n\nEsito 1 (\\(p=0.1\\), \\(q=0.2\\)) – Il modello \\(Q\\) sovrastima un evento raro. Il contributo alla divergenza è negativo, ma l’impatto è ridotto perché l’evento è poco probabile nella realtà (\\(p\\) piccolo).\n\nEsito 2 (\\(p=0.6\\), \\(q=0.5\\)) – Il modello sottostima l’evento più frequente. Poiché \\(p\\) è alto, questa sottostima ha un peso maggiore nella media ponderata, generando il contributo positivo più grande.\n\nEsito 3 (\\(p=0.3\\), \\(q=0.3\\)) – Qui il modello è perfetto: \\(p(x) = q(x)\\), quindi il contributo alla divergenza è zero.\n\nIl valore complessivo di \\(D_{\\text{KL}}\\) è la somma di questi contributi: rappresenta la perdita media di efficienza (in bit per evento) quando si usa \\(Q\\) al posto di \\(P\\).\nIn questo caso, il risultato indica che usare \\(Q\\) comporta una leggera inefficienza: la codifica o le previsioni richiedono, in media, un po’ più informazione di quanto sarebbe necessario usando la distribuzione vera.\n\n\n\n\n74.2.2 Legame con l’entropia e l’entropia incrociata\nLa divergenza di Kullback–Leibler può essere riscritta come differenza tra entropia incrociata e entropia vera:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = H(P, Q) - H(P),\n\\tag{74.3}\\]\ndove:\n\n\n\\(H(P)\\) è l’entropia della distribuzione vera \\(P\\) (incertezza media/lunghezza media del codice ottimale quando conosciamo la distribuzione corretta);\n\n\\(H(P, Q)\\) è l’entropia incrociata, cioè l’incertezza media se codifichiamo dati generati da \\(P\\) utilizzando un codice ottimizzato per \\(Q\\):\n\n\\[\nH(P, Q) = -\\sum_x p(x)\\log_2 q(x).\n\\tag{74.4}\\]\nIntuizione. Con questa forma, \\(D_{\\text{KL}}\\) è la sorpresa extra media (o costo informativo in bit per evento) che paghiamo quando usiamo il modello approssimato \\(Q\\) al posto della distribuzione vera \\(P\\). Poiché \\(H(P)\\) non dipende dal modello, minimizzare \\(D_{\\text{KL}}\\) equivale a minimizzare \\(H(P,Q)\\).\n\n\n\n\n\n\nPerché serve per ELPD e LOO\n\n\n\nCriteri predittivi come ELPD e LOO stimano, in media, la stessa quantità di cui vogliamo minimizzare il valore: l’entropia incrociata \\(H(P,Q)\\). Per questo, massimizzare ELPD (o ridurre la perdita di log-verosimiglianza predittiva) è un modo pratico per avvicinare \\(Q\\) a \\(P\\), ossia per ridurre indirettamente \\(D_{\\text{KL}}(P\\parallel Q)\\).\n\n\n\n\n\n\n\n\nEsempio: Entropia incrociata (1)\n\n\n\n\n\nUtilizziamo le funzioni definite sopra (entropy(), cross_entropy(), kl_divergence()) sullo stesso esempio discusso in precedenza:\n\n# Esempio: distribuzione vera P e modello Q\nP &lt;- c(0.1, 0.6, 0.3)\nQ &lt;- c(0.2, 0.5, 0.3)\n\nH_P   &lt;- entropy(P)           # H(P)\nH_PQ  &lt;- cross_entropy(P, Q)  # H(P,Q)\nDKL   &lt;- kl_divergence(P, Q)  # D_KL(P||Q)\n\ncat(sprintf(\"H(P)    = %.4f bit\\n\", H_P))\n#&gt; H(P)    = 1.2955 bit\ncat(sprintf(\"H(P,Q)  = %.4f bit\\n\", H_PQ))\n#&gt; H(P,Q)  = 1.3533 bit\ncat(sprintf(\"H(P,Q)-H(P) = %.4f bit (D_KL)\\n\", H_PQ - H_P))\n#&gt; H(P,Q)-H(P) = 0.0578 bit (D_KL)\ncat(sprintf(\"D_KL(P||Q)  = %.4f bit (controllo)\\n\", DKL))\n#&gt; D_KL(P||Q)  = 0.0578 bit (controllo)\n\nInterpretazione\n\n\n\\(H(P)\\) è il limite inferiore: la miglior compressione ottenibile conoscendo la verità (\\(P\\)).\n\n\n\\(H(P,Q)\\) è la compressione che otterremmo usando il modello (\\(Q\\)).\n\nLa loro differenza è esattamente \\(D_{\\text{KL}}(P\\parallel Q)\\): la quantità di informazione “sprecata” in media per evento usando \\(Q\\) al posto di \\(P\\).\n\n\n\n\n\n\n\n\n\n\n\nEsempio: Entropia incrociata (2)\n\n\n\n\n\nIn due esempi successivi rendiamo \\(Q\\) sempre più diverso da \\(P\\) e osserviamo come cambiano entropia incrociata e divergenza KL.\n\n# Distribuzione vera fissata\nP  &lt;- c(0.1, 0.6, 0.3)\nH_P &lt;- entropy(P)  # costante rispetto al modello\n\n# Due modelli: uno moderatamente errato (Q1), uno molto errato (Q2)\nQ1 &lt;- c(0.35, 0.30, 0.35)\nQ2 &lt;- c(0.60, 0.30, 0.10)\n\n# Calcolo di entropia incrociata e divergenza KL\nH_PQ1 &lt;- cross_entropy(P, Q1)\nH_PQ2 &lt;- cross_entropy(P, Q2)\n\nKL1 &lt;- kl_divergence(P, Q1)\nKL2 &lt;- kl_divergence(P, Q2)\n\ncat(sprintf(\"H(P)     = %.4f bit (fissa)\\n\", H_P))\n#&gt; H(P)     = 1.2955 bit (fissa)\ncat(sprintf(\"H(P,Q1)  = %.4f bit   -&gt; D_KL(P||Q1) = %.4f bit\\n\", H_PQ1, KL1))\n#&gt; H(P,Q1)  = 1.6480 bit   -&gt; D_KL(P||Q1) = 0.3525 bit\ncat(sprintf(\"H(P,Q2)  = %.4f bit   -&gt; D_KL(P||Q2) = %.4f bit\\n\", H_PQ2, KL2))\n#&gt; H(P,Q2)  = 2.1125 bit   -&gt; D_KL(P||Q2) = 0.8170 bit\n\nInterpretazione\nPoiché \\(H(P)\\) non cambia, quando \\(Q\\) si allontana da \\(P\\) cresce \\(H(P,Q)\\) e, di conseguenza, aumenta\n\\[\nD_{\\text{KL}}(P \\parallel Q) = H(P, Q) - H(P) .\n\\]\n\nQ1: il modello redistribuisce massa probabilistica, sottostimando l’esito più probabile e sovrastimando gli altri. Gli errori sugli esiti che \\(P\\) considera frequenti pesano di più nella media, aumentando \\(H(P,Q1)\\) e quindi \\(D_{\\text{KL}}\\).\nQ2: l’errore è estremo: la probabilità più alta viene assegnata all’esito meno probabile secondo \\(P\\). I contributi positivi (sottostima degli esiti comuni) dominano, facendo crescere molto \\(D_{\\text{KL}}\\).\n\nQuesto esempio mostra che minimizzare \\(H(P,Q)\\) (e quindi \\(D_{\\text{KL}}\\)) significa allineare il più possibile le probabilità del modello con quelle “vere”, soprattutto per gli esiti a cui \\(P\\) assegna più massa.\n\n\n\n\n\n\n\n\n\nDimostrazione: dalla differenza di entropie alla formula della D-KL\n\n\n\n\n\nPartiamo dalla definizione come differenza tra entropia incrociata ed entropia vera:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = H(P, Q) - H(P).\n\\]\nSostituendo: \\[\nH(P,Q) = -\\sum_x p(x) \\log_2 q(x), \\quad\nH(P)   = -\\sum_x p(x) \\log_2 p(x),\n\\]\nottieni:\n\\[\nD_{\\text{KL}}(P \\parallel Q) =\n\\left[ - \\sum_x p(x) \\log_2 q(x) \\right]\n- \\left[ - \\sum_x p(x) \\log_2 p(x) \\right].\n\\]\nEliminando i segni negativi:\n\\[\nD_{\\text{KL}}(P \\parallel Q) =\n\\sum_x p(x) \\log_2 p(x) - \\sum_x p(x) \\log_2 q(x).\n\\]\nRaccogliendo in un’unica somma:\n\\[\nD_{\\text{KL}}(P \\parallel Q) =\n\\sum_x p(x) \\left[ \\log_2 p(x) - \\log_2 q(x) \\right].\n\\]\nApplicando la proprietà dei logaritmi:\n\\[\nD_{\\text{KL}}(P \\parallel Q) =\n\\sum_x p(x) \\log_2 \\frac{p(x)}{q(x)}.\n\\]\nInterpretazione: questa è la forma esplicita più usata della \\(D_{\\text{KL}}\\). Mostra chiaramente che si tratta di una media ponderata secondo \\(P\\) della differenza di informazione tra \\(P\\) e \\(Q\\) per ciascun esito \\(x\\).\n\n\n\n\n74.2.3 Interpretazione della divergenza KL\nLa divergenza \\(D_{\\text{KL}}(P \\parallel Q)\\) misura l’inefficienza media che si introduce quando si usa la distribuzione \\(Q\\) per descrivere dati che in realtà seguono \\(P\\). In termini informativi, rappresenta il costo aggiuntivo di sorpresa: quanti bit in più, in media, servono per codificare gli eventi generati da \\(P\\) se utilizziamo un codice ottimizzato per \\(Q\\) invece che per \\(P\\).\nQuesta quantità:\n\nè sempre non negativa: il modello vero (\\(P\\)) non può mai essere peggiore, in media, del modello approssimato (\\(Q\\));\nè asimmetrica: \\(D_{\\text{KL}}(P \\parallel Q) \\neq D\\_{\\text{KL}}(Q \\parallel P)\\). L’ordine è importante: invertire \\(P\\) e \\(Q\\) cambia il significato della misura, perché cambia quale distribuzione stiamo trattando come “vera”.\n\nPer questo motivo, la divergenza KL non è una “distanza” in senso geometrico, ma una misura direzionale di perdita di informazione o di inefficienza di codifica.\n\n74.2.4 Proprietà fondamentali della divergenza KL\n\nNon-negatività: \\(D_{\\text{KL}}(P \\parallel Q) \\geq 0\\) per ogni coppia di distribuzioni \\(P\\) e \\(Q\\). Il valore minimo (0) si ottiene se e solo se \\(P = Q\\).\nAsimmetria: \\(D_{\\text{KL}}(P \\parallel Q) \\neq D\\_{\\text{KL}}(Q \\parallel P)\\) in generale. Non soddisfa quindi le proprietà di una distanza simmetrica.\n\nUnità di misura: dipende dalla base del logaritmo:\n\nbase 2 → misura in bit;\nbase \\(e\\) → misura in nat (unità naturale di informazione).",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#uso-della-divergenza-d_textkl-nella-selezione-di-modelli",
    "href": "chapters/entropy/02_kl.html#uso-della-divergenza-d_textkl-nella-selezione-di-modelli",
    "title": "74  La divergenza di Kullback-Leibler",
    "section": "\n74.3 Uso della divergenza \\(D_{\\text{KL}}\\) nella selezione di modelli",
    "text": "74.3 Uso della divergenza \\(D_{\\text{KL}}\\) nella selezione di modelli\nIn teoria, la selezione del modello consiste nello scegliere il modello \\(Q\\) che minimizza la divergenza dalla distribuzione vera \\(P\\):\n\\[\n\\text{Modello ottimale} = \\arg\\min_Q D_{\\text{KL}}(P \\parallel Q).\n\\]\nIn altre parole, il modello ideale è quello che si avvicina di più a \\(P\\) e quindi riduce al minimo la perdita media di informazione quando lo usiamo per descrivere i dati.\nProblema: nella pratica, \\(P\\) è sconosciuta — non possiamo osservare direttamente la distribuzione vera che ha generato i dati. Di conseguenza, non possiamo calcolare \\(D_{\\text{KL}}\\) in modo esatto.\n\n74.3.1 Come procedere nella pratica\nAnche se \\(P\\) è ignota, possiamo comunque confrontare modelli in termini di divergenza KL sfruttando il legame con l’entropia incrociata \\(H(P,Q)\\). Infatti, ricordiamo che:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = H(P,Q) - H(P).\n\\]\nL’entropia \\(H(P)\\) non dipende dal modello \\(Q\\): è una costante rispetto al confronto tra modelli. Se prendiamo la differenza di divergenza KL tra due modelli \\(Q_1\\) e \\(Q_2\\), questa costante si annulla:\n\\[\nD_{\\text{KL}}(P \\parallel Q_1) - D_{\\text{KL}}(P \\parallel Q_2)\n= H(P,Q_1) - H(P,Q_2).\n\\tag{74.5}\\]\nQuindi, per confrontare modelli non serve conoscere \\(H(P)\\): basta confrontare le loro entropie incrociate \\(H(P,Q)\\), che dipendono solo da \\(Q\\) e che possono essere stimate dai dati.\nNel prossimo capitolo vedremo due strumenti dell’approccio bayesiano che stimano proprio \\(H(P,Q)\\) (o, più precisamente, il suo opposto \\(-H(P,Q)\\)):\n\n\nLeave-One-Out Cross-Validation (LOO-CV) – valuta quanto bene il modello predice dati non usati nella stima;\n\nExpected Log Predictive Density (ELPD) – fornisce la stima della qualità predittiva media del modello.\n\nQuesti metodi permettono di confrontare modelli in termini di differenza di divergenza KL, avvicinandoci così alla scelta del modello che, tra quelli considerati, è più vicino alla distribuzione vera \\(P\\).\n\n\n\n\n\n\nEsempio psicologico\n\n\n\n\n\nImmaginiamo di voler prevedere il punteggio di ansia settimanale di uno studente.\n\n\nModello A: utilizza come predittore solo il punteggio di coping (capacità di fronteggiare lo stress).\n\n\nModello B: utilizza coping + supporto sociale.\n\nSupponiamo che, valutando le loro prestazioni predittive, entrambi i modelli ottengano buoni risultati, ma il Modello B presenti una divergenza KL leggermente inferiore rispetto al Modello A.\nInterpretazione:\n\nla divergenza KL più bassa del Modello B indica che, in media, le sue previsioni sono leggermente più vicine alla distribuzione “vera” dei dati (minore perdita di informazione);\ntuttavia, se la differenza è piccola, potremmo preferire il Modello A per la sua maggiore semplicità e interpretabilità, applicando il principio di parsimonia (o rasoio di Occam).\n\nQuesto esempio illustra che la selezione del modello non dipende solo dalla precisione predittiva, ma anche dal bilanciamento tra accuratezza e complessità.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#riflessioni-conclusive",
    "href": "chapters/entropy/02_kl.html#riflessioni-conclusive",
    "title": "74  La divergenza di Kullback-Leibler",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo approfondito un concetto fondamentale della teoria dell’informazione: la divergenza di Kullback–Leibler. Nata in origine per valutare l’efficienza dei codici di trasmissione, la D-KL è oggi uno strumento essenziale anche nella statistica moderna, perché misura in modo preciso quanto una distribuzione di probabilità approssimata \\(Q\\) (cioè un modello) si discosti dalla distribuzione vera \\(P\\) che genera i dati.\nAbbiamo visto che la D-KL può essere interpretata come:\n\n\nperdita media di informazione quando si usa \\(Q\\) invece di \\(P\\);\n\neccesso di sorpresa o inefficienza di codifica introdotta da un modello imperfetto;\ndifferenza tra entropia incrociata e entropia vera, il che rende possibile stimarla indirettamente.\n\nQuesto legame con l’entropia incrociata è cruciale: sebbene \\(P\\) non sia nota e la D-KL non possa essere calcolata in valore assoluto, possiamo confrontare modelli stimando le differenze di D-KL, perché la componente costante \\(H(P)\\) si annulla nel confronto.\nNel prossimo capitolo ci concentreremo proprio su come effettuare questi confronti in pratica. Vedremo come strumenti come la Leave-One-Out Cross-Validation (LOO-CV) e l’Expected Log Predictive Density (ELPD) permettano di stimare la capacità predittiva dei modelli e di identificare quello che, tra le alternative considerate, è il più vicino alla distribuzione vera dei dati.\n\n\n\n\n\n\nSintesi finale\n\n\n\n\nLa divergenza KL quantifica la perdita media di informazione usando \\(Q\\) al posto di \\(P\\).\nSi può scrivere come \\(\\sum_x p(x) \\log \\frac{p(x)}{q(x)}\\) o come \\(H(P,Q) - H(P)\\).\nÈ uno strumento chiave per valutare quanto bene un modello rappresenta la realtà.\nIn pratica, può essere confrontata tra modelli stimando \\(H(P,Q)\\) con tecniche come LOO-CV ed ELPD.\n\n\n\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nCosideriamo due distribuzioni di probabilità discrete, \\(p\\) e \\(q\\):\n\np &lt;- c(0.2, 0.5, 0.3)\nq &lt;- c(0.1, 0.2, 0.7)\nSi calcoli l’entropia di \\(p\\), l’entropia incrociata tra \\(p\\) e \\(q\\), la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).\nSi consideri q = c(0.2, 0.55, 0.25) e si calcoli di nuovo a divergenza di Kullback-Leibler da \\(p\\) a \\(q\\). Si confronti con il risultato precedente e si interpreti.\n\nSia \\(p\\) una distribuzione binomiale di parametri \\(\\theta = 0.2\\) e \\(n = 5\\). Sia \\(q_1\\) una approssimazione a \\(p\\): q1 = c(0.46, 0.42, 0.10, 0.01, 0.01). Sia \\(q_2\\) una distribuzione uniforme: q2 &lt;- rep(0.2, 5). Si calcoli la divergenza \\(\\mathbb{KL}\\) di \\(q_1\\) da \\(p\\) e da \\(q_2\\) da \\(p\\) e si interpretino i risultati.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#bibliografia",
    "href": "chapters/entropy/02_kl.html#bibliografia",
    "title": "74  La divergenza di Kullback-Leibler",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKullback, S., & Leibler, R. A. (1951). On information and sufficiency. The Annals of Mathematical Statistics, 22(1), 79–86.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html",
    "href": "chapters/entropy/03_model_comparison.html",
    "title": "75  Valutare i modelli bayesiani",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto due concetti fondamentali: l’entropia, che misura l’incertezza insita in una distribuzione, e la divergenza di Kullback–Leibler (\\(D_{\\text{KL}}\\)), che quantifica la distanza tra due distribuzioni di probabilità. Ora possiamo fare un passo ulteriore: usare queste idee per valutare e confrontare modelli statistici nel contesto bayesiano.\nIl punto di partenza è una domanda cruciale: quanto bene il modello riesce a prevedere nuovi dati? Un buon modello non deve solo adattarsi ai dati osservati, ma deve anche saper generalizzare a situazioni future. Questa distinzione – adattamento vs. generalizzazione – è il cuore della valutazione predittiva.\nImmaginiamo, ad esempio, di sviluppare un test psicologico per stimare l’ansia degli studenti prima di un esame. Non basta sapere che il modello descrive bene il campione usato per costruirlo: vogliamo essere ragionevolmente sicuri che le stesse previsioni funzionino anche per studenti che non hanno partecipato allo studio. In psicologia, scegliere tra due modelli è simile a decidere quale test usare: in entrambi i casi si cerca lo strumento che fornisce previsioni più affidabili.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#introduzione",
    "href": "chapters/entropy/03_model_comparison.html#introduzione",
    "title": "75  Valutare i modelli bayesiani",
    "section": "",
    "text": "Panoramica del capitolo\nPer rispondere alla domanda fondamentale sulla qualità predittiva, seguiremo un percorso logico che ci condurrà dagli strumenti teorici ai metodi pratici:\n\n\nPrima costruiremo la base teorica: vedremo come la distribuzione predittiva posteriore incorpora l’incertezza sui parametri nelle nostre previsioni\n\nPoi definiremo le misure di accuratezza: il log-score per valutare la bontà delle previsioni punto per punto\n\nDistingueremo tra valutazione in-sample e out-of-sample: LPPD (sui dati osservati) vs. ELPD (capacità di generalizzazione)\n\nCollegheremo tutto alla divergenza KL: per capire perché massimizzare l’ELPD equivale a trovare il modello più vicino alla realtà\n\nImplementeremo metodi pratici: LOO-CV per stimare l’ELPD senza conoscere la vera distribuzione dei dati\n\nConfronteremo con altri criteri: AIC, BIC, WAIC e i loro ambiti di applicazione\n\nL’obiettivo è fornire strumenti pratici e un quadro concettuale chiaro per guidare la scelta del modello più adatto al problema in esame.\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nPer comprendere appieno questo capitolo è utile leggere il capitolo 7 Ulysses’ Compass di Statistical Rethinking (McElreath (2020)).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nlibrary(gt)\nlibrary(conflicted)\nlibrary(brms)\nlibrary(loo)\nconflicts_prefer(rstan::loo)",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#il-punto-di-partenza-dalle-previsioni-deterministiche-a-quelle-probabilistiche",
    "href": "chapters/entropy/03_model_comparison.html#il-punto-di-partenza-dalle-previsioni-deterministiche-a-quelle-probabilistiche",
    "title": "75  Valutare i modelli bayesiani",
    "section": "\n75.1 Il punto di partenza: dalle previsioni deterministiche a quelle probabilistiche",
    "text": "75.1 Il punto di partenza: dalle previsioni deterministiche a quelle probabilistiche\nPrima di addentrarci nei dettagli tecnici, facciamo un passo indietro per capire perché la valutazione predittiva bayesiana è diversa da quella frequentista classica.\nNell’approccio classico, una volta stimati i parametri (ad esempio con la massima verosimiglianza), li trattiamo come “veri” e fissi. Se \\(\\hat{\\theta}\\) è la nostra stima, la previsione per un nuovo dato \\(\\tilde{y}\\) è semplicemente:\n\\[\np(\\tilde{y} \\mid \\hat{\\theta}).\n\\] Questo approccio ignora completamente l’incertezza sulla stima dei parametri.\nNell’approccio bayesiano, invece, riconosciamo che i parametri sono incerti. Anche dopo aver osservato i dati, la nostra conoscenza di \\(\\theta\\) è descritta da un’intera distribuzione posteriore \\(p(\\theta \\mid y)\\), non da un singolo valore. Le previsioni devono quindi riflettere questa incertezza.\n\n\n\n\n\n\nAnalogia didattica\n\n\n\nImmaginiamo di dover prevedere il tempo domani. L’approccio “classico” è come consultare un solo meteorologo e fidarsi completamente della sua previsione. L’approccio bayesiano è come consultare tutti i meteorologi disponibili, pesare le loro opinioni in base alla loro affidabilità passata, e costruire una previsione che tenga conto di tutti i punti di vista plausibili.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#distribuzione-predittiva-posteriore-il-cuore-delle-previsioni-bayesiane",
    "href": "chapters/entropy/03_model_comparison.html#distribuzione-predittiva-posteriore-il-cuore-delle-previsioni-bayesiane",
    "title": "75  Valutare i modelli bayesiani",
    "section": "\n75.2 Distribuzione predittiva posteriore: il cuore delle previsioni bayesiane",
    "text": "75.2 Distribuzione predittiva posteriore: il cuore delle previsioni bayesiane\nNel capitolo sul modello beta–binomiale l’abbiamo già incontrata: è lo strumento che, nell’approccio bayesiano, consente di prevedere nuovi dati incorporando sia la struttura del modello sia l’incertezza sui parametri. La logica è elegante nella sua semplicità: dopo aver osservato i dati \\(y\\), non otteniamo un singolo “miglior” valore dei parametri, ma una distribuzione posteriore \\(p(\\theta \\mid y)\\) che quantifica i valori plausibili di \\(\\theta\\) e la nostra incertezza.\n\nEsempio concreto: Uno psicologo che stima il livello medio di ansia in una popolazione, invece di affermare “la media è 4.7”, dirà: “il valore più plausibile è 4.7, ma è ragionevole che sia tra 4.2 e 5.1”, riflettendo la variabilità della distribuzione a posteriori.\n\n\n75.2.1 La formula fondamentale\nPer prevedere un nuovo dato \\(\\tilde{y}\\), non fissiamo \\(\\theta\\). Mediamo invece tutte le previsioni condizionate \\(p(\\tilde{y} \\mid \\theta)\\) pesandole con la densità posteriore \\(p(\\theta\\mid y)\\):\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta\n\\tag{75.1}\\] Questa è la distribuzione predittiva posteriore, e rappresenta la nostra migliore previsione per dati futuri dato quello che abbiamo osservato.\n\n75.2.2 Decomposizione dell’integrale: cosa significa realmente\nL’Equazione 75.1 può sembrare astratta, ma ha un’interpretazione intuitiva molto chiara:\n\n\n\\(p(\\tilde{y} \\mid \\theta)\\): se conoscessimo il vero valore di \\(\\theta\\), questa sarebbe la nostra previsione per \\(\\tilde{y}\\);\n\n\\(p(\\theta \\mid y)\\): questa è la nostra incertezza su quale sia il vero valore di \\(\\theta\\);\n\nL’integrale: combina le previsioni per tutti i possibili valori di \\(\\theta\\), pesandole secondo quanto crediamo che ciascun valore sia plausibile.\n\n\n\n\n\n\n\nIntuizione dettagliata\n\n\n\n\n\nSe conoscessimo il valore vero di \\(\\theta\\), potremmo prevedere i dati futuri usando la distribuzione predittiva condizionata:\n\\[\np(\\tilde y \\mid \\theta).\n\\] Il problema è che \\(\\theta\\) non lo conosciamo: abbiamo soltanto la distribuzione a posteriori \\(p(\\theta\\mid y)\\). Perciò, la distribuzione predittiva posteriore si costruisce combinando le previsioni condizionate per ogni valore possibile di \\(\\theta\\), pesandole con quanto ciascun valore è plausibile a posteriori:\n\\[\np(\\tilde y\\mid y) = \\int p(\\tilde y\\mid \\theta)\\,p(\\theta\\mid y)\\,d\\theta.\n\\] Per fare un esempio concreto, consideriamo il caso binomiale. Supponiamo che i dati futuri siano generati da una Binomiale con \\(m\\) prove e parametro \\(\\theta\\):\n\\[\np(\\tilde y = x \\mid \\theta) = \\binom{m}{x}\\,\\theta^x(1-\\theta)^{m-x}.\n\\] La distribuzione predittiva posteriore diventa:\n\\[\np(\\tilde y = x \\mid y) = \\int \\binom{m}{x}\\,\\theta^x(1-\\theta)^{m-x}\\,p(\\theta\\mid y)\\,d\\theta.\n\\] In alcuni casi particolari (per esempio con prior Beta e dati binomiali) questo integrale si può risolvere analiticamente, ottenendo la Beta–Binomiale. Ma in generale non c’è una formula chiusa e serve un’approssimazione numerica.\nApprossimazione numerica con il metodo su griglia: L’idea è semplice: sostituire l’integrale con una somma pesata su una griglia di valori possibili di \\(\\theta\\). I passaggi algoritmici sono i seguenti.\n\n\nDefinire una griglia di valori di \\(\\theta\\), ad esempio 1000 punti equispaziati tra 0 e 1:\n\\[\n\\theta_1, \\theta_2, \\dots, \\theta_J.\n\\]\n\n\nCalcolare la posteriore su ciascun punto della griglia. Nel caso Beta–Binomiale:\n\\[\np(\\theta_j \\mid y) \\propto \\theta_j^{\\,k+a-1}(1-\\theta_j)^{n-k+b-1}.\n\\]\nPoi normalizzare per avere somme che valgono 1:\n\\[\nw_j = \\frac{p(\\theta_j \\mid y)}{\\sum_{\\ell=1}^J p(\\theta_\\ell \\mid y)}.\n\\]\n\n\nCombinare le predizioni condizionate. Per ogni valore futuro \\(x=0,\\dots,m\\), si calcola:\n\\[\np(\\tilde y = x \\mid y) \\approx \\sum_{j=1}^J w_j \\, \\binom{m}{x}\\theta_j^x(1-\\theta_j)^{m-x}.\n\\]\n\n\nInterpretazione: la pmf ottenuta è la nostra approssimazione numerica della distribuzione predittiva posteriore. Da essa possiamo:\n\ncalcolare probabilità,\ngenerare campioni di \\(\\tilde y\\),\nconfrontare la predizione con i dati osservati.\n\n\n\nDa ricordare:\n\nLa predittiva non si ottiene facendo la media dei valori di \\(\\tilde y\\), ma costruendo un’intera distribuzione di probabilità.\nIl metodo su griglia è il più semplice: discretizza \\(\\theta\\), pesa ogni valore con la sua plausibilità a posteriori, e combina le predizioni condizionate.\nIn problemi più complessi, la stessa logica viene implementata tramite MCMC: invece di usare una griglia fissa, si usano campioni \\(\\theta^{(s)}\\) dalla posteriore.\n\n\n\n\n\n\n\n\n\n\nEsempio numerico completo\n\n\n\n\n\nEsaminiamo ora uno script in R che implementa passo per passo l’approssimazione della distribuzione predittiva posteriore binomiale con il metodo su griglia.\n\n# ESEMPIO DIDATTICO: predittiva posteriore per Binomiale con metodo su griglia\n# Dati e prior\nk &lt;- 10     # successi osservati\nn &lt;- 50     # prove osservate\na &lt;- 1      # prior Beta(a, b)\nb &lt;- 1\nm &lt;- 10     # numero di prove future per la predizione (scelta didattica)\nJ &lt;- 2000   # numero di punti griglia su theta in [0,1]\n\n# -------------------------------------------------------------\n# PASSAGGIO 1: Griglia su theta\n# -------------------------------------------------------------\n\ntheta &lt;- seq(0, 1, length.out = J)\n\n# -------------------------------------------------------------\n# PASSAGGIO 2: Densità posteriore non normalizzata su ogni punto di griglia\n# -------------------------------------------------------------\n\n# Posteriore ~ Beta(a + k, b + n - k)  -&gt; densità proporzionale a theta^(a+k-1) (1-theta)^(b+n-k-1)\npost_unnorm &lt;- theta^(a + k - 1) * (1 - theta)^(b + n - k - 1)\n\n# Normalizzazione per ottenere pesi che sommano a 1\nw &lt;- post_unnorm / sum(post_unnorm)\n\n# -------------------------------------------------------------\n# PASSAGGIO 3: combinare le predittive condizionate p(tilde y | theta)\n# -------------------------------------------------------------\n# Obiettivo: costruire la pmf predittiva p(tilde y = x | y) \n# per ogni x = 0,...,m come media pesata (sulla griglia di θ) \n# delle pmf condizionate binomiali.\n\n# 1) Definiamo i valori futuri possibili di tilde y\nx_vals &lt;- 0:m\n\n# 2) Inizializziamo una matrice vuota: \n#    - J righe (una per ciascun θ_j della griglia)\n#    - (m+1) colonne (una per ogni valore possibile di x)\npx_given_theta &lt;- matrix(NA_real_, nrow = J, ncol = m + 1)\n\n# 3) Riempiamo la matrice: per ogni θ_j (riga j) e per ogni x (colonna i)\n#    calcoliamo P(tilde y = x | θ_j) = Binomiale(x | m, θ_j)\nfor (j in 1:J) {\n  for (i in 1:(m + 1)) {\n    x &lt;- x_vals[i]\n    px_given_theta[j, i] &lt;- dbinom(x, size = m, prob = theta[j])\n  }\n}\n\n# 4) Combinazione pesata:\n#    p(tilde y = x | y) ≈ somma_j w_j * P(tilde y = x | θ_j).\n#    Per ciascun valore di x (colonna i), facciamo la somma pesata.\npred_pmf &lt;- numeric(m + 1)\nfor (i in 1:(m + 1)) {\n  pred_pmf[i] &lt;- sum(w * px_given_theta[, i])\n}\n\n# Nota didattica:\n# - Ogni colonna della matrice px_given_theta contiene le probabilità condizionate \n#   P(tilde y = x_i | θ_j) per tutti i valori di griglia θ_j.\n# - Moltiplicando riga per riga queste probabilità per i pesi posteriori w_j \n#   e sommando, otteniamo la probabilità predittiva p(tilde y = x_i | y).\n# - In questo modo l'integrale viene approssimato da una somma pesata.\n\n# -------------------------------------------------------------\n# PASSAGGIO 4: Risultato: una pmf su {0,1,...,m}\n# -------------------------------------------------------------\n\npred_df &lt;- data.frame(x = x_vals, p = pred_pmf)\nprint(pred_df)\n#&gt;     x          p\n#&gt; 1   0 0.11391218\n#&gt; 2   1 0.25060680\n#&gt; 3   2 0.27617892\n#&gt; 4   3 0.19946255\n#&gt; 5   4 0.10397516\n#&gt; 6   5 0.04068593\n#&gt; 7   6 0.01205509\n#&gt; 8   7 0.00266151\n#&gt; 9   8 0.00041780\n#&gt; 10  9 0.00004200\n#&gt; 11 10 0.00000205\n\n\nsum(pred_df$p)  # dovrebbe essere ~1\n#&gt; [1] 1\n\n\n# (Opzionale) campionamento dalla predittiva posteriore approssimata\n# Estrae N valori da {0,...,m} con le probabilità 'p'\nset.seed(123)\nN &lt;- 5000\ntilde_y_samples &lt;- sample(pred_df$x, size = N, replace = TRUE, prob = pred_df$p)\n\n# Controllo: istogramma delle simulazioni vs pmf teorica approssimata\nggplot() +\n  geom_histogram(\n    data = data.frame(x = tilde_y_samples), aes(x = x, y = after_stat(density)),\n    binwidth = 1, breaks = seq(-0.5, m + 0.5, by = 1), fill = \"skyblue\", \n    color = \"black\") +\n  geom_point(data = pred_df, aes(x = x, y = p), pch = 19, cex = 3) + \n  geom_line(data = pred_df, aes(x = x, y = p), lwd = 1.5) + \n  ylim(0, max(pred_df$p) * 1.1) +\n  labs(\n    title = \"Posterior Predictive (grid) – m=10\",\n    x = expression(tilde(y)),\n    y = \"Density\")\n\n\n\n\n\n\n\n\nNota: il vettore pred_df$p è la pmf della predittiva posteriore approssimata; da qui si leggono probabilità, si calcolano quantità riassuntive e si può estrarre \\(\\tilde y\\).\n\nVerifica quando esiste la formula chiusa: Quando prior e likelihood sono coniugate (Beta + Binomiale), la predittiva è Beta–Binomiale. Possiamo usarla solo come verifica didattica:\n\n# Confronto con Beta-Binomiale (se applicabile)\na_post &lt;- a + k\nb_post &lt;- b + n - k\n\n# pmf beta-binomial (con funzione base: dbetabinom in VGAM, altrimenti la implementiamo)\ndbetabinom &lt;- function(x, m, a, b) {\n  # Beta-Binomiale: choose(m, x) * Beta(x+a, m-x+b) / Beta(a, b)\n  choose(m, x) * beta(x + a, m - x + b) / beta(a, b)\n}\n\nbb_pmf &lt;- sapply(0:m, function(x) dbetabinom(x, m, a_post, b_post))\ncbind(grid = pred_df$p, beta_binom = bb_pmf)[1:6, ]  # prime 6 righe a confronto\n#&gt;        grid beta_binom\n#&gt; [1,] 0.1139     0.1139\n#&gt; [2,] 0.2506     0.2506\n#&gt; [3,] 0.2762     0.2762\n#&gt; [4,] 0.1995     0.1995\n#&gt; [5,] 0.1040     0.1040\n#&gt; [6,] 0.0407     0.0407\n\n\nmax(abs(pred_df$p - bb_pmf))   # lo scarto massimo (dovrebbe essere ~0 con J grande)\n#&gt; [1] 1.68e-15\n\n\n\n\n\n75.2.3 Notazione e terminologia\nNotazione: Useremo talvolta la forma compatta \\(p(\\cdot \\mid y)\\) per indicare la predittiva posteriore del modello. Quando ci servirà evidenziare la previsione marginale per una singola osservazione \\(y_i\\), scriveremo:\n\\[\np(y_i \\mid y) = \\int p(y_i \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta,\n\\] cioè la verosimiglianza \\(p(y_i\\mid\\theta)\\) integrata rispetto alla posteriore \\(p(\\theta\\mid y)\\).\nIdea chiave: La predittiva posteriore propaga l’incertezza sui parametri alle previsioni. È questo passaggio a rendere le valutazioni predittive coerenti con il principio bayesiano, e quindi utilizzabili nel confronto tra modelli e nella stima di quantità legate alla “distanza” dal generatore dei dati.\n\n\n\n\n\n\nMappa concettuale\n\n\n\n\n\n\n\n\n\n\nQuantità\nSignificato\nUso principale\n\n\n\n\\(p(y_i \\mid \\theta)\\)\nVerosimiglianza\nCalcolo predittivo\n\n\n\\(p(\\theta \\mid y)\\)\nDistribuzione posteriore\nPonderazione\n\n\n\\(p(y_i \\mid y)\\)\nPredizione bayesiana media\nLog-score, LPPD\n\n\n\\(p(y_i \\mid y_{-i})\\)\nPredizione LOO (leave-one-out)\nELPD\n\n\n\\(p(\\tilde{y} \\mid y)\\)\nDistribuzione predittiva complessiva\nDivergenza KL, confronto modelli",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#il-problema-fondamentale-della-valutazione-predittiva",
    "href": "chapters/entropy/03_model_comparison.html#il-problema-fondamentale-della-valutazione-predittiva",
    "title": "75  Valutare i modelli bayesiani",
    "section": "\n75.3 Il problema fondamentale della valutazione predittiva",
    "text": "75.3 Il problema fondamentale della valutazione predittiva\nOra che sappiamo come costruire previsioni bayesiane, affrontiamo la domanda centrale: come valutiamo la qualità di queste previsioni?\n\n75.3.1 Il dilemma teorico\nQuando costruiamo un modello, vogliamo sapere quanto bene riesce a predire dati futuri. In altre parole: se ripetessimo l’esperimento o raccogliessimo nuovi dati, quanto sarebbero vicine le predizioni del modello a quei dati?\nPer formalizzare questa idea, distinguiamo tra due distribuzioni:\n\n\nla distribuzione vera dei dati futuri \\(p(\\tilde{y})\\), che purtroppo non conosciamo,\n\nla distribuzione predittiva del modello \\(p(\\tilde{y} \\mid y)\\), cioè le predizioni basate sui dati osservati \\(y\\).\n\nL’obiettivo è misurare quanto \\(p(\\tilde{y} \\mid y)\\) si avvicina a \\(p(\\tilde{y})\\).\n\n75.3.2 Una misura di distanza: la divergenza di Kullback–Leibler\nLa divergenza di Kullback–Leibler (KL) fornisce una misura di questa distanza:\n\\[\nD_{\\text{KL}}(p \\parallel q) = \\mathbb{E}_{p} \\left[ \\log \\frac{p(\\tilde{y})}{q(\\tilde{y} \\mid y)} \\right].\n\\tag{75.2}\\] Interpretazione intuitiva:\n\nse \\(q\\) (il nostro modello) assegna probabilità alte agli stessi eventi che sono probabili in \\(p\\) (la realtà), la distanza sarà piccola,\nse invece \\(q\\) “sbaglia bersaglio”, assegnando probabilità alte a eventi che in realtà sono rari, la distanza sarà grande.\n\n\n\n\n\n\n\nIdea chiave. La KL divergence misura quanta informazione perdiamo se usiamo le predizioni del modello \\(q\\) al posto della distribuzione vera \\(p\\).\n\n\n\n\n75.3.3 Un ostacolo pratico insormontabile\nIl problema è che \\(p(\\tilde{y})\\) non lo conosciamo mai: non abbiamo accesso alla “vera” distribuzione dei dati futuri. Questa è la sfida fondamentale della validazione predittiva: come possiamo valutare la qualità delle nostre previsioni senza conoscere la verità?\nPer questo dobbiamo ricorrere a strategie di approssimazione, come la validazione incrociata e criteri predittivi come ELPD, che vedremo nelle prossime sezioni.\n\n75.3.3.1 Mini-esempio intuitivo\nImmagina una moneta truccata che dà testa il 70% delle volte.\nVogliamo confrontare due modelli:\n\n\nModello A: ipotizza una moneta equa (\\(p = 0.5\\)),\n\nModello B: ipotizza una probabilità leggermente sbilanciata (\\(p = 0.65\\)).\n\nSe sapessimo che la probabilità “vera” è \\(p = 0.7\\), sarebbe chiaro che il Modello B è più vicino alla realtà. La divergenza di Kullback–Leibler serve proprio a quantificare quanta informazione perdiamo quando ci affidiamo a un modello meno accurato (come A) invece che a uno più vicino alla verità (come B).\nIl punto cruciale è che nella pratica non conosciamo mai la probabilità vera della moneta. Abbiamo soltanto i dati osservati, cioè gli esiti dei lanci. Per decidere quale modello predice meglio dobbiamo quindi basarci sui dati disponibili: è qui che entrano in gioco i metodi di confronto predittivo che studieremo.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#sec-logscore",
    "href": "chapters/entropy/03_model_comparison.html#sec-logscore",
    "title": "75  Valutare i modelli bayesiani",
    "section": "\n75.4 Il log-score: misurare l’accuratezza predittiva punto per punto",
    "text": "75.4 Il log-score: misurare l’accuratezza predittiva punto per punto\nAbbiamo definito la distribuzione predittiva posteriore e il problema teorico della valutazione. Ora introduciamo il primo strumento pratico: il log-score.\n\n75.4.1 La domanda di base\nPer ogni osservazione nei nostri dati, vogliamo sapere: quanto il nostro modello considerava plausibile questo specifico risultato? Il log-score risponde proprio a questa domanda.\n\n75.4.2 Definizione formale\nIl log-score per un’osservazione \\(y_i\\) è semplicemente il logaritmo della probabilità che il modello assegnava a quell’osservazione:\n\\[\n\\text{Log-score}(y_i) = \\log p(y_i \\mid y) ,\n\\tag{75.3}\\] dove \\(p(y_i \\mid y)\\) è la distribuzione predittiva posteriore che abbiamo appena imparato a calcolare:\n\\[\np(y_i \\mid y) = \\int p(y_i \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta .\n\\]\n\n75.4.3 Interpretazione: “scommettere” sui dati\nIl log-score può essere interpretato come quanto il modello avrebbe “scommesso” su quel particolare risultato:\n\n\nse il modello assegna alta probabilità* a \\(y_i\\)*: \\(p(y_i \\mid y) \\approx 1\\), quindi \\(\\log p(y_i \\mid y) \\approx 0\\) (buono);\n\nse il modello assegna bassa probabilità* a \\(y_i\\)*: \\(p(y_i \\mid y) \\approx 0\\), quindi \\(\\log p(y_i \\mid y) \\ll 0\\) (molto negativo, scarso).\n\n\n\n\n\n\n\nPerché il logaritmo?\nIl logaritmo trasforma prodotti di probabilità in somme. Così possiamo sommare contributi punto per punto dei dati invece di moltiplicarli; inoltre stabilizza i numeri molto piccoli tipici delle verosimiglianze.\n\n\n\n\n75.4.4 Dal singolo dato al punteggio totale\nPer avere una visione complessiva della performance del modello, sommiamo i log-score su tutte le osservazioni:\n\\[\nS = \\sum_{i=1}^n \\log p(y_i \\mid y) .\n\\tag{75.4}\\] Più \\(S\\) è alto (meno negativo), più il modello “scommette” bene sui dati osservati (in-sample).\n\n75.4.5 Due filosofie a confronto: parametri fissi vs. incerti\nIl calcolo del log-score può seguire due approcci concettualmente diversi, che riflettono due filosofie statistiche diverse.\n\n75.4.5.1 Approccio classico: parametri fissi\nNell’impostazione frequentista classica, usiamo una stima puntuale dei parametri (ad es. Massima Verosimiglianza o MAP) e ignoriamo l’incertezza:\n\\[\n\\text{Log-score classico} = \\log p(y_i \\mid \\hat{\\theta}).\n\\]\n\n75.4.5.2 Approccio bayesiano: gestione dell’incertezza sui parametri\nNell’approccio bayesiano non fissiamo i parametri a un singolo valore stimato, ma li trattiamo come incerti. Questo significa che, invece di calcolare la verosimiglianza con un $$, “mescoliamo” tutte le verosimiglianze possibili, pesandole in base alla loro plausibilità a posteriori:\n\\[\n\\begin{align}\n\\text{Log-score bayesiano} &= \\log p(y_i \\mid y) \\\\\n&= \\log \\int p(y_i \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta .\n\\end{align}\n\\tag{75.5}\\]\nIn altre parole, la probabilità predittiva di \\(y_i\\) non dipende da un solo \\(\\theta\\), ma dalla media delle predizioni condizionate su tutti i valori plausibili dei parametri.\n\n\n\n\n\n\nDifferenza chiave\n- L’approccio frequentista chiede: “Quanto sono plausibili i dati se i parametri valgono esattamente \\(\\hat{\\theta}\\)?”\n- L’approccio bayesiano chiede: “Quanto sono plausibili i dati, in media, considerando tutti i valori di \\(\\theta\\) compatibili con i dati osservati?”\nLa seconda prospettiva è più onesta perché riconosce l’incertezza sui parametri.\n\n\n\n\n75.4.6 Implementazione pratica con il metodo MCMC\nL’integrale nell’nell’Equazione 75.5 raramente ha una soluzione analitica (cioè non si può calcolare con una formula esatta). Possiamo però stimarlo in modo pratico ed efficiente utilizzando i campioni generati da un algoritmo MCMC (Markov Chain Monte Carlo).\nSupponiamo di avere una serie di campioni di parametri, \\(\\theta^{(1)},\\dots,\\theta^{(S)}\\), estratti dalla distribuzione a posteriori \\(p(\\theta\\mid y)\\). Il procedimento per approssimare la probabilità predittiva si articola in due semplici passi:\n\n75.4.6.1 Passo 1: calcolare la verosimiglianza per ogni campione\nPer ogni set di parametri \\(\\theta^{(s)}\\) che abbiamo campionato, calcoliamo la probabilità (verosimiglianza) di osservare il dato \\(y_i\\) sotto quei parametri:\n\\[\np\\bigl(y\\_i \\mid \\theta^{(s)}\\bigr).\n\\]\nFare questo per tutti i campioni \\(S\\) ci fornisce un insieme di valori:\n\\[\n\\bigl\\{\\, p(y\\_i \\mid \\theta^{(1)}),\\; p(y\\_i \\mid \\theta^{(2)}),\\; \\dots,\\; p(y\\_i \\mid \\theta^{(S)}) \\,\\bigr\\}\n\\] Questa collezione rappresenta come la plausibilità del dato \\(y_i\\) cambi al variare dei parametri, ponderata per la loro probabilità a posteriori.\n\n75.4.6.2 Passo 2: calcolare la media dei valori ottenuti\nLa probabilità predittiva per \\(y_i\\) (che tiene conto di tutta l’incertezza sui parametri) è approssimata semplicemente calcolando la media aritmetica dell’insieme di valori ottenuti nel passo precedente:\n\\[\np(y_i \\mid y) \\;\\approx\\; \\frac{1}{S}\\sum_{s=1}^S p\\bigl(y_i \\mid \\theta^{(s)}\\bigr).\n\\tag{75.6}\\]\nIl risultato è un singolo valore numerico (uno scalare) che sintetizza in una previsione probabilistica tutto ciò che abbiamo appreso sull’incertezza dei parametri del modello.\n\n75.4.7 La LPPD: una misura bayesiana di bontà della previsione\nPer valutare la capacità predittiva dell’intero modello su tutti i dati, ripetiamo il procedimento per ogni osservazione \\(y_i\\) e procediamo così:\n\nper ogni osservazione \\(y_i\\), calcoliamo la sua probabilità predittiva media \\(p(y_i \\mid y)\\);\nprendiamo il logaritmo naturale di questa probabilità. (Usiamo il logaritmo per motivi computazionali e perché trasforma prodotti in somme);\nsommiamo i logaritmi di tutte le \\(n\\) osservazioni.\n\nIl risultato di questo processo è la Log Pointwise Predictive Density (LPPD):\n\\[\n\\text{LPPD} = \\sum_{i=1}^n \\log \\left[ \\frac{1}{S} \\sum_{s=1}^S p\\bigl(y_i \\mid \\theta^{(s)}\\bigr) \\right].\n\\tag{75.7}\\]\nConfronto e Sintesi:\n\nIl log-score classico (usato nella statistica frequentista) valuta la previsione utilizzando un unico valore stimato dei parametri (ad esempio, la stima di massima verosimiglianza \\(\\hat{\\theta}\\)). Questo ignora completamente l’incertezza esistente sulla stima dei parametri.\nLa LPPD bayesiana compie la stessa operazione fondamentale, ma in modo più robusto: invece di usare un singolo valore dei parametri, media le previsioni su tutte le migliaia di valori plausibili dei parametri campionati dalla distribuzione a posteriori. In questo modo, la misura di bontà predittiva incorpora in modo naturale tutta l’incertezza del modello.\n\n75.4.8 Il problema nascosto: overfitting in-sample\nLa LPPD è calcolata sugli stessi dati usati per stimare il modello: modelli molto flessibili possono “scommettere bene” anche sul rumore, gonfiando la LPPD in-sample.\nAnalogia: È come valutare uno studente facendogli ripetere gli stessi esercizi che ha già risolto durante lo studio. Otterrà un punteggio alto, ma non sappiamo se sarebbe altrettanto bravo con problemi nuovi.\nPer valutare la capacità di generalizzazione, serve una stima out-of-sample. Nelle prossime sezioni introdurremo la validazione incrociata leave-one-out (LOO-CV) e l’ELPD (Expected Log Pointwise Predictive Density), che forniscono una versione “fuori campione” della LPPD per il confronto predittivo tra modelli.\n\n\n\n\n\n\nEsempio pratico del calcolo LPPD\n\n\n\n\n\nConsideriamo un singolo dato \\(y_i = 3\\) successi su \\(n=5\\) tentativi (Binomiale). Abbiamo tre valori plausibili per \\(\\theta\\) dalla posterior, con pesi didattici \\(w^{(s)}\\) (nella pratica MCMC i pesi sono uguali):\n\n\n\\(\\theta^{(1)}=0.3\\) con \\(w^{(1)}=0.2\\)\n\n\n\\(\\theta^{(2)}=0.5\\) con \\(w^{(2)}=0.5\\)\n\n\n\\(\\theta^{(3)}=0.7\\) con \\(w^{(3)}=0.3\\)\n\n\nPer ogni campione \\(\\theta^{(s)}\\) calcoliamo \\(p(y_i \\mid \\theta^{(s)})\\), otteniamo la collezione di likelihood \\(\\{p(y_i\\mid \\theta^{(s)})\\}_{s=1}^S\\), poi facciamo la media pesata (eq. Equazione 75.6) per ottenere \\(p(y_i\\mid y)\\), e infine il log-score \\(\\log p(y_i\\mid y)\\) (eq. Equazione 75.3).\n\n# Dato osservato (un solo punto)\ny_i  &lt;- 3\nn_i  &lt;- 5\n\n# \"Campioni\" posteriori (qui pochi e con pesi espliciti per chiarezza didattica)\ntheta_vals        &lt;- c(0.3, 0.5, 0.7)      # θ^(1), θ^(2), θ^(3)\nposterior_weights &lt;- c(0.2, 0.5, 0.3)      # w^(1), w^(2), w^(3); in MCMC tipicamente uguali\n\n# (1) Likelihood punto-per-punto: p(y_i | θ^(s))\nlikelihoods &lt;- dbinom(y_i, size = n_i, prob = theta_vals)\nlikelihoods  # questa è la collezione { p(y_i | θ^(s)) }_s\n#&gt; [1] 0.132 0.312 0.309\n\n# (2) Media (pesata) sulle likelihood ⇒ p(y_i | y) ≈ Σ_s w^(s) p(y_i | θ^(s))\np_yi_given_y &lt;- sum(posterior_weights * likelihoods)\n\n# (3) Log-score (per un solo dato coincide con la LPPD del singolo punto)\nlog_score_i &lt;- log(p_yi_given_y)\n\n# Stampa riassuntiva con notazione coerente\ncat(\"Campioni θ^{(s)}:        \", theta_vals, \"\\n\")\n#&gt; Campioni θ^{(s)}:         0.3 0.5 0.7\ncat(\"Likelihood p(y_i|θ^{(s)}):\", round(likelihoods, 4), \"\\n\")\n#&gt; Likelihood p(y_i|θ^{(s)}): 0.132 0.312 0.309\ncat(\"p(y_i|y) (media pesata):  \", round(p_yi_given_y, 4), \"\\n\")\n#&gt; p(y_i|y) (media pesata):   0.275\ncat(\"log p(y_i|y):             \", round(log_score_i, 4), \"\\n\")\n#&gt; log p(y_i|y):              -1.29\n\nNota didattica: Nella pratica con MCMC i pesi sono uguali, \\(w^{(s)}=\\tfrac{1}{S}\\), quindi \\(p(y_i\\mid y) \\approx \\tfrac{1}{S}\\sum_{s=1}^S p(y_i\\mid \\theta^{(s)})\\) (Equazione 75.6). Con più osservazioni \\(\\{y_i\\}_{i=1}^n\\), la LPPD è la somma dei log-score punto-per-punto (Equazione 75.7).",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#la-svolta-dalladattamento-alla-generalizzazione",
    "href": "chapters/entropy/03_model_comparison.html#la-svolta-dalladattamento-alla-generalizzazione",
    "title": "75  Valutare i modelli bayesiani",
    "section": "\n75.5 La svolta: dall’adattamento alla generalizzazione",
    "text": "75.5 La svolta: dall’adattamento alla generalizzazione\n\n75.5.1 Il problema dell’overfitting spiegato\nImmagina di voler valutare la capacità di uno studente di riconoscere emozioni nei volti.\n\n\nScenario A: lo testi sempre con le stesse fotografie che ha già visto molte volte durante l’allenamento.\n\nScenario B: lo testi con nuove fotografie di persone mai viste prima.\n\nNel primo caso, lo studente probabilmente avrà un punteggio molto alto, ma non sapremo se ha davvero imparato a riconoscere le emozioni o se si limita a ricordare quelle immagini specifiche. Il secondo scenario, invece, è più onesto: misura la capacità di generalizzare la competenza a stimoli nuovi.\nLo stesso accade con i modelli statistici.\n\nLa LPPD corrisponde allo Scenario A: valuta il modello sugli stessi dati usati per adattarlo, rischiando di dare un’illusione di performance eccellente.\nPer sapere se il modello sa davvero “generalizzare”, serve testarlo come nello Scenario B: con dati nuovi o tramite tecniche di validazione incrociata.\n\n75.5.2 Guardare oltre i dati osservati\nQuando valutiamo un modello, non ci basta sapere quanto bene spiega i dati che ha già visto. La vera domanda è: quanto bene predirebbe dati nuovi, mai osservati?\nLa Expected Log Predictive Density (ELPD) risponde a questa domanda. La logica è la stessa della LPPD, ma con una differenza cruciale: la previsione di ogni osservazione \\(y_i\\) viene fatta senza usare \\(y_i\\) per stimare il modello. Questa tecnica si chiama Leave-One-Out (LOO):\n\\[\n\\text{ELPD} = \\sum_{i=1}^n \\log p(y_i \\mid y_{-i}),\n\\tag{75.8}\\] dove \\(y_{-i}\\) indica il dataset a cui è stata tolta l’osservazione \\(i\\).\n\n75.5.2.1 Un esempio concreto per chiarire la differenza\nImmagina di voler costruire un modello che predice i punteggi di memoria a breve termine degli studenti a partire dal loro livello di concentrazione.\n\nCon la LPPD, il modello viene valutato sugli stessi studenti che sono serviti per stimarlo. È come dire: “quanto bene il modello spiega questi dati noti?”.\n\nCon la ELPD, invece, ogni volta togliamo uno studente dal campione, stimiamo il modello sugli altri e proviamo a predire il punteggio di quello escluso. È come chiedere: “quanto bene il modello predirebbe un nuovo studente, mai visto prima?”.\n\n75.5.2.2 Procedura passo per passo\n\nPrendiamo il primo studente ed escludiamolo dal dataset.\n\nAdattiamo il modello usando i dati dei rimanenti studenti.\n\nPrediciamo il punteggio di memoria dello studente escluso.\n\nRipetiamo lo stesso procedimento per ogni studente, uno alla volta.\n\nSommiamo tutti i log-score ottenuti: questo è l’ELPD.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#il-collegamento-con-la-divergenza-kl",
    "href": "chapters/entropy/03_model_comparison.html#il-collegamento-con-la-divergenza-kl",
    "title": "75  Valutare i modelli bayesiani",
    "section": "\n75.6 Il collegamento con la divergenza KL",
    "text": "75.6 Il collegamento con la divergenza KL\n\n75.6.1 La teoria che unifica tutto\nAbbiamo visto che l’ELPD fornisce una misura empirica della capacità predittiva di un modello. Esiste, tuttavia, una giustificazione teorica profonda e unificante che spiega il motivo per cui massimizzare l’ELPD è il principio corretto per la selezione dei modelli. Questa giustificazione poggia sul concetto di divergenza di Kullback-Leibler (KL).\n\n75.6.1.1 Cosa misura la divergenza KL?\nLa divergenza KL, indicata come \\(D_{\\text{KL}}\\), misura la “distanza” informazionale tra la distribuzione vera dei dati, \\(p(\\tilde{y})\\) (la realtà che vogliamo catturare), e la distribuzione predittiva del nostro modello, \\(q(\\tilde{y} \\mid y)\\) (la nostra approssimazione). È definita come:\n\\[\nD_{\\text{KL}}(p \\parallel q) = \\mathbb{E}_p \\left[ \\log \\frac{p(\\tilde{y})}{q(\\tilde{y} \\mid y)} \\right],\n\\] dove l’aspettativa \\(\\mathbb{E}_p\\) è calcolata rispetto alla distribuzione vera \\(p(\\tilde{y})\\).\n\n75.6.1.2 Scomponiamo la divergenza KL\nPer comprendere a fondo, espandiamo la definizione:\n\\[\nD_{\\text{KL}}(p \\parallel q) = \\underbrace{\\mathbb{E}_p[\\log p(\\tilde{y})]}_{\\text{(1) Entropia}} - \\underbrace{\\mathbb{E}_p[\\log q(\\tilde{y} \\mid y)]}_{\\text{(2) Accuratezza predittiva}}.\n\\tag{75.9}\\]\nAnalizziamo i due termini:\n\n\n\\(\\mathbb{E}_p[\\log p(\\tilde{y})]\\) (Entropia): Rappresenta il contenuto informativo intrinseco della distribuzione vera. È una quantità fissa, immutabile e, soprattutto, indipendente dal modello che stiamo considerando. È una costante.\n\n\\(-\\mathbb{E}_p[\\log q(\\tilde{y} \\mid y)]\\) (Log-verosimiglianza attesa): Questo è il termine cruciale. Misura quanto è buona la nostra distribuzione predittiva \\(q\\) nel prevedere nuovi dati provenienti dalla vera distribuzione \\(p\\). Nota: questo è esattamente l’opposto della quantità che stimiamo con l’ELPD \\((\\sum \\log q(\\tilde{y} \\mid y))\\).\n\n75.6.1.3 Il collegamento fondamentale\nPoiché il primo termine dell’Equazione 75.9 è una costante, minimizzare la divergenza KL \\(D_{\\text{KL}}(p \\parallel q)\\) equivale esattamente a massimizzare il secondo termine, ovvero l’accuratezza predittiva attesa. Questo risultato si traduce in una regola pratica potentissima per il confronto tra modelli. Date due distribuzioni predittive, \\(q_A\\) e \\(q_B\\), la differenza nelle loro divergenze KL è:\n\\[\n\\begin{aligned}\nD_{\\text{KL}}(p \\parallel q_A) - D_{\\text{KL}}(p \\parallel q_B) &= \\left( \\cancel{\\mathbb{E}_p[\\log p(\\tilde{y})]} - \\mathbb{E}_p[\\log q_A(\\tilde{y} \\mid y)] \\right) \\notag\\\\\n&\\qquad - \\left( \\cancel{\\mathbb{E}_p[\\log p(\\tilde{y})]} - \\mathbb{E}_p[\\log q_B(\\tilde{y} \\mid y)] \\right) \\\\\n&= \\mathbb{E}_p[\\log q_B(\\tilde{y} \\mid y)] - \\mathbb{E}_p[\\log q_A(\\tilde{y} \\mid y)] \\\\\n&= \\text{ELPD}(q_B) - \\text{ELPD}(q_A)\n\\end{aligned}\n\\] dove abbiamo cancellato il termine entropia costante.\n\n75.6.1.4 Conclusione teorica fondamentale\nIl risultato precedente ci porta alla conclusione chiave di tutta la teoria:\n\\[\n\\text{Massimizzare l'ELPD} \\;\\; \\equiv \\;\\; \\text{Minimizzare la divergenza KL dalla verità}.\n\\] In altre parole, quando preferiamo il modello con l’ELPD più alto, non stiamo solo seguendo un criterio empirico. Stiamo scegliendo consapevolmente il modello la cui distribuzione predittiva è, in media, più vicina alla realtà sottostante in senso informazionale. Questo principio unifica la teoria dell’informazione con la pratica della valutazione e selezione dei modelli predittivi.\n\n\n\n\n\n\nEsempio: collegamento ELPD-KL in pratica\n\n\n\n\n\nVogliamo confrontare due modelli predittivi per il numero di “teste” in \\(n=10\\) lanci. Supponiamo che\n\nla distribuzione vera è \\(p(y)=\\text{Binom}(n=10,\\;p=0.6)\\),\nil modello candidato prevede \\(q(y)=\\text{Binom}(n=10,\\;q=0.5)\\).\n\nL’ELPD di un modello è l’aspettativa, rispetto alla distribuzione vera \\(p\\), del log-score del modello: \\(\\mathrm{ELPD}(q)=\\mathbb{E}_{p}[\\log q(Y)]\\). Nel caso discreto, l’aspettativa diventa una somma su tutti i possibili valori \\(y=0,\\dots,n\\).\n\n# Parametri del problema\nn &lt;- 10          # numero di lanci\np &lt;- 0.6         # probabilità vera di \"testa\"\nq &lt;- 0.5         # probabilità ipotizzata dal modello candidato\n\n# 1) Supporto dei possibili esiti\ny_vals &lt;- 0:n\n\n# 2) Distribuzione vera p(y) su tutto il supporto\np_y &lt;- dbinom(y_vals, size = n, prob = p)\n\n# 3) Log-predittiva del modello candidato q su tutto il supporto\nlog_q_y &lt;- log(dbinom(y_vals, size = n, prob = q))\n\n# 4) ELPD del modello candidato: somma dei log q(y) pesati da p(y)\nelpd_q &lt;- sum(p_y * log_q_y)\n\n# 5) \"Modello vero\": usa q = p. Log-predittiva del modello vero\nlog_p_y &lt;- log(dbinom(y_vals, size = n, prob = p))\n\n# 6) ELPD del modello vero: somma dei log p(y) pesati da p(y)\nelpd_p &lt;- sum(p_y * log_p_y)\n\n# 7) Divergenza KL tra p e q: somma p(y) * log [p(y)/q(y)]\nkl_pq &lt;- sum(p_y * (log_p_y - log_q_y))\n\ncat(sprintf(\"ELPD modello candidato (q=0.5): %.4f\\n\", elpd_q))\n#&gt; ELPD modello candidato (q=0.5): -2.0549\ncat(sprintf(\"ELPD modello vero      (q=0.6): %.4f\\n\", elpd_p))\n#&gt; ELPD modello vero      (q=0.6): -1.8536\ncat(sprintf(\"Differenza ELPD (vero - candidato): %.4f\\n\", elpd_p - elpd_q))\n#&gt; Differenza ELPD (vero - candidato): 0.2014\ncat(sprintf(\"KL(p || q): %.4f\\n\", kl_pq))\n#&gt; KL(p || q): 0.2014\n\nCosa stiamo verificando?\n\n\\(\\mathrm{ELPD}(q)=\\sum_y p(y)\\log q(y)\\) è più basso (più negativo) del valore ottenuto dal modello vero \\(\\mathrm{ELPD}(p)=\\sum_y p(y)\\log p(y)\\). → Il modello con \\(q=0.6\\) è più predittivo di quello con \\(q=0.5\\).\nLa differenza tra i due ELPD è uguale (vicina numericamente) alla divergenza di Kullback–Leibler:\n\n\\[\n\\begin{align}\n\\mathrm{ELPD}(p)-\\mathrm{ELPD}(q) &= \\sum_y p(y)\\big[\\log p(y)-\\log q(y)\\big] \\notag\\\\\n&= D_{\\mathrm{KL}}(p\\|q)\\;&gt;\\;0.\n\\end{align}\n\\] Questo mostra algebricamente e numericamente il legame: massimizzare l’ELPD equivale a minimizzare la divergenza KL.\nIn pratica: In questo esempio abbiamo potuto calcolare l’ELPD vero perché conoscevamo l’intera distribuzione generatrice \\(p(y)\\) e potevamo integrare esattamente. Nella realtà, \\(p(y)\\) è sconosciuta: disponiamo solo di un campione osservato. In questi casi stimiamo l’ELPD empiricamente, ad esempio con la Leave-One-Out Cross-Validation (LOO-CV), che sostituisce l’aspettativa rispetto a \\(p\\) con una media sui dati raccolti, lasciando fuori una osservazione alla volta.\n\n\n\n\n\n\n\n\n\nCollegamento chiave.\nL’ELPD è una stima empirica (con segno cambiato) della divergenza di Kullback–Leibler. Più alto è l’ELPD, migliore è la capacità predittiva del modello.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#stimare-lelpd-nella-pratica-la-leave-one-out-cross-validation",
    "href": "chapters/entropy/03_model_comparison.html#stimare-lelpd-nella-pratica-la-leave-one-out-cross-validation",
    "title": "75  Valutare i modelli bayesiani",
    "section": "\n75.7 Stimare l’ELPD nella pratica: la Leave-One-Out Cross-Validation",
    "text": "75.7 Stimare l’ELPD nella pratica: la Leave-One-Out Cross-Validation\nAbbiamo chiarito che l’ELPD è la misura ideale della bontà predittiva di un modello, perché è direttamente collegata alla divergenza KL. Il problema è che, per definizione, richiede un’aspettativa rispetto alla vera distribuzione dei dati futuri \\(p(\\tilde{y})\\), che non conosciamo mai.\nCome possiamo allora stimarlo? La soluzione più usata è la Leave-One-Out Cross-Validation (LOO-CV), che ci permette di avvicinarci all’ELPD teorico usando soltanto i dati osservati.\n\n75.7.1 L’idea alla base della LOO-CV\nIl principio è semplice: trattare ogni osservazione del dataset come se fosse “nuova” e verificare se il modello, addestrato sui dati rimanenti, riesce a prevederla.\nIl procedimento è questo:\n\nSi prende un’osservazione \\(y_i\\).\nLa si rimuove temporaneamente dal dataset.\nSi stima il modello sui dati rimanenti \\(y_{-i}\\).\nSi calcola la densità predittiva che il modello assegna al dato escluso: \\(p(y\\_i \\mid y_{-i})\\).\nSi ripete per tutte le osservazioni e si sommano i logaritmi.\n\nIn formula:\n\\[\n\\text{ELPD}_{\\text{LOO}} = \\sum_{i=1}^n \\log p(y_i \\mid y_{-i}) .\n\\tag{75.10}\\]\nCosì otteniamo una stima out-of-sample: il modello viene valutato su dati che non ha mai visto.\n\n75.7.2 Perché funziona\nLa LOO-CV funziona perché sostituisce l’aspettativa teorica rispetto a \\(p(\\tilde{y})\\) con una media empirica sulle osservazioni reali. Ogni \\(y_i\\) viene trattata come un nuovo dato proveniente da \\(p\\), e la media dei log-score fuori campione fornisce una stima della capacità predittiva attesa:\n\\[\n\\text{ELPD}_{\\text{LOO}} \\approx \\mathbb{E}_p[\\log q(\\tilde{y}\\mid y)] .\n\\tag{75.11}\\]\n\n75.7.3 Confrontare i modelli con LOO-CV\nUna volta stimato l’ELPD-LOO, possiamo confrontare due modelli calcolando la differenza:\n\\[\n\\Delta \\text{ELPD} = \\text{ELPD}_{\\text{LOO}}(M_1) - \\text{ELPD}_{\\text{LOO}}(M_2).\n\\tag{75.12}\\]\nSe la differenza è positiva, il modello \\(M_1\\) ha una distribuzione predittiva più vicina alla realtà di quella di \\(M_2\\).\nÈ utile stimare anche un errore standard della differenza. Come regola empirica, una differenza di almeno due volte l’SE indica un vantaggio credibile di un modello sull’altro.\n\n75.7.4 Overfitting e vantaggio della LOO-CV\nSe valutassimo un modello sugli stessi dati usati per addestrarlo, la sua performance apparirebbe gonfiata (overfitting). La LOO-CV aggira questo problema: ogni osservazione viene valutata solo con modelli che non l’hanno vista. Il punteggio ottenuto è quindi una misura più realistica della capacità di generalizzare a nuovi dati.\n\n75.7.5 PSIS-LOO: la scorciatoia pratica\nUn limite della LOO tradizionale è che richiederebbe di riadattare il modello \\(n\\) volte, cosa spesso impraticabile. Per questo oggi si usa il metodo Pareto-Smoothed Importance Sampling (PSIS-LOO), che consente di stimare l’ELPD-LOO a partire da un unico adattamento del modello, sfruttando i campioni MCMC.\nIn R, tutto ciò è implementato nel pacchetto loo, già integrato in brms e rstanarm, attraverso funzioni come loo() e loo_compare(). Oltre ai valori di ELPD, queste funzioni forniscono anche diagnostiche (le Pareto k) per capire se la stima è affidabile.\n\n75.7.5.1 In sintesi\n\nL’ELPD misura la capacità predittiva del modello su dati futuri.\nNon conoscendo la distribuzione vera, usiamo la LOO-CV per stimarlo.\nLa differenza di ELPD-LOO tra modelli approssima la differenza nelle loro divergenze KL.\nPSIS-LOO rende il calcolo efficiente anche per modelli complessi.\nLa regola pratica: preferire il modello con ELPD-LOO più alto, tenendo conto anche della sua semplicità e interpretabilità.\n\n\n\n\n\n\n\nEsempio: confronto ELPD-LOO tra due modelli\n\n\n\n\n\nQuesto esempio mostra come passare dalla definizione teorica dell’ELPD alla stima pratica via Leave-One-Out, usando un caso elementare Beta–Bernoulli.\nDati: Cinque prove indipendenti: \\(y=\\{1,1,1,0,1\\}\\) (quattro “successi”, un “insuccesso”).\nModello A (Bayesiano adattato ai dati): Bernoulli\\((\\theta)\\) con prior \\(\\theta\\sim \\text{Beta}(1,1)\\) (uninformativa). Per LOO: * per ogni \\(i\\), escludiamo \\(y_i\\); * calcoliamo la posteriore \\(\\theta \\mid y_{-i} \\sim \\text{Beta}(1+s_{-i},\\,1+n_{-i}-s_{-i})\\), dove \\(s_{-i}\\) è il numero di successi tra i \\(n-1\\) rimanenti; * calcoliamo la probabilità predittiva per \\(y_i\\).\nModello B (di confronto): Moneta equa fissa (\\(q=0.5\\)): la predittiva è sempre \\(0.5\\), indipendentemente dai dati.\n\n# Dati\ny &lt;- c(1, 1, 1, 0, 1)\nn &lt;- length(y)\n\n# Log-predittiva LOO per Modello A (Beta(1,1) + Bernoulli)\nloo_log_pred_beta &lt;- function(i, y, a0 = 1, b0 = 1) {\n  yi &lt;- y[i]\n  s_minus &lt;- sum(y) - yi\n  n_minus &lt;- n - 1\n  alpha &lt;- a0 + s_minus\n  beta  &lt;- b0 + (n_minus - s_minus)\n  p1 &lt;- alpha / (alpha + beta)\n  p  &lt;- if (yi == 1) p1 else (1 - p1)\n  log(p)\n}\n\n# Log-predittive punto-per-punto\nlp_beta  &lt;- sapply(seq_along(y), loo_log_pred_beta, y = y)\nlp_fixed &lt;- rep(log(0.5), n)\n\n# ELPD-LOO\nelpd_beta  &lt;- sum(lp_beta)\nelpd_fixed &lt;- sum(lp_fixed)\n\n# Differenza e SE\ndiff_pt &lt;- lp_beta - lp_fixed\nse_diff &lt;- sqrt(n * var(diff_pt))\n\n# Tabella riassuntiva\nres &lt;- data.frame(\n  i = 1:n, y = y,\n  lp_beta = round(lp_beta, 6),\n  lp_fixed = round(lp_fixed, 6),\n  diff = round(diff_pt, 6)\n)\nprint(res)\n#&gt;   i y lp_beta lp_fixed   diff\n#&gt; 1 1 1  -0.405   -0.693  0.288\n#&gt; 2 2 1  -0.405   -0.693  0.288\n#&gt; 3 3 1  -0.405   -0.693  0.288\n#&gt; 4 4 0  -1.792   -0.693 -1.099\n#&gt; 5 5 1  -0.405   -0.693  0.288\ncat(sprintf(\"\\nELPD-LOO Modello A: %.6f\\n\", elpd_beta))\n#&gt; \n#&gt; ELPD-LOO Modello A: -3.413620\ncat(sprintf(\"ELPD-LOO Modello B: %.6f\\n\", elpd_fixed))\n#&gt; ELPD-LOO Modello B: -3.465736\ncat(sprintf(\"Differenza (A-B)  : %.6f\\n\", elpd_beta - elpd_fixed))\n#&gt; Differenza (A-B)  : 0.052116\ncat(sprintf(\"SE differenza     : %.6f\\n\", se_diff))\n#&gt; SE differenza     : 1.386294\n\nInterpretazione:\n\nOgni riga della tabella mostra la log-predittiva fuori campione per entrambi i modelli\nIn un campione con 4 successi su 5, il Modello A assegna più di 0.5 di probabilità ai successi, e meno di 0.5 all’unico insuccesso\nL’ELPD-LOO di A può risultare leggermente più alto di quello di B, ma l’errore standard è grande perché \\(n\\) è piccolo\n\n\nRegola pratica: una differenza \\(|\\Delta \\text{ELPD}|\\) di almeno 2 volte l’SE fornisce un’indicazione più affidabile di superiorità del modello. In esempi così piccoli l’obiettivo è puramente didattico: capire come si calcola e cosa significa.\n\n\n\n\n\n\n\n\n\n\nIn pratica: stimare e confrontare l’ELPD-LOO\n\n\n\n\n\nConcetto chiave\n\nL’ELPD valuta la capacità predittiva su dati non visti.\nLa LOO-CV lo stima in modo efficiente con PSIS-LOO.\n\nStrumenti\n\nFunzione loo() del pacchetto loo, integrata in brms e rstanarm.\nDiagnostica con Pareto k, confronto con loo_compare().\n\nWorkflow tipico in R\n\nAdattare ogni modello (brm() o stan_glm()).\nEstrarre log_lik() e calcolare loo().\nConfrontare modelli con loo_compare().\n\nDecisione\n\nPreferire l’ELPD-LOO più alto.\nDifferenza ≥ 2×SE → indicazione di vantaggio sostanziale.\nValutare anche semplicità e interpretabilità.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#criteri-di-informazione",
    "href": "chapters/entropy/03_model_comparison.html#criteri-di-informazione",
    "title": "75  Valutare i modelli bayesiani",
    "section": "\n75.8 Criteri di informazione",
    "text": "75.8 Criteri di informazione\nOltre alla convalida incrociata Leave-One-Out, la statistica offre altri strumenti per stimare la qualità predittiva di un modello senza conoscere la distribuzione vera dei dati. Molti di questi metodi affondano le loro radici teoriche nel concetto di divergenza di Kullback-Leibler, che misura la distanza tra la distribuzione generatrice dei dati e quella stimata dal nostro modello.\nL’obiettivo comune è valutare la capacità di un modello di generalizzare, ovvero di fare buone previsioni su dati non osservati, senza farsi trarre in inganno dall’overfitting. Tutti i criteri seguono una logica simile, bilanciando due componenti: una misura della bontà di adattamento ai dati e una penalità per la complessità del modello stesso. I vari criteri si distinguono proprio per come definiscono queste due componenti e per le assunzioni su cui si basano.\n\n75.8.1 Una panoramica dei criteri principali\nL’AIC (Akaike Information Criterion) approssima la distanza di Kullback-Leibler utilizzando la verosimiglianza massimizzata e applica una penalità semplice, proporzionale al numero di parametri. È un criterio veloce e ampiamente utilizzato, particolarmente utile per modelli regolari con campioni non troppo piccoli e privi di struttura gerarchica.\nIl BIC (Bayesian Information Criterion) segue una logica simile all’AIC, ma introduce una penalità per la complessità che cresce all’aumentare della dimensione del campione. Questo lo porta tendenzialmente a preferire modelli più parsimoniosi quando il numero di osservazioni è grande e, sotto specifiche ipotesi, può essere collegato alla verosimiglianza marginale.\nIl WAIC (Widely Applicable Information Criterion) rappresenta una versione pienamente bayesiana. Utilizza l’intera distribuzione predittiva a posteriori per valutare il fit e stima una penalità per la complessità effettiva del modello, che può differire dal semplice numero di parametri. È particolarmente adatto per modelli complessi o non regolari ed è concettualmente molto vicino alla stima LOO.\nInfine, il LOO-CV (Leave-One-Out Cross-Validation), specialmente nella sua efficiente implementazione PSIS-LOO, stima direttamente l’Expected Log Predictive Density (ELPD) escludendo un dato alla volta. È spesso considerato il gold standard per il confronto predittivo nell’ambito della modellazione bayesiana, grazie alla sua robustezza e alle utili diagnostiche che fornisce.\n\n75.8.1.1 Come orientarsi nella scelta\nUna regola pratica è che se l’obiettivo principale è la previsione fuori campione in un contesto bayesiano, il PSIS-LOO o il WAIC sono generalmente da preferire ad AIC e BIC. In un approccio frequentista classico, con modelli regolari e campioni di dimensioni medio-grandi, l’AIC rimane un buon compromesso, mentre il BIC può essere più appropriato quando si desidera enfatizzare la parsimonia.\nPer modelli bayesiani con obiettivo predittivo e dati reali (spesso non iid o gerarchici), il PSIS-LOO è la prima scelta, con il WAIC utile come riscontro. Con campioni piccoli, strutture complesse o unità dipendenti, è bene evitare criteri puramente asintotici come AIC e BIC, preferendo invece LOO o definendo con attenzione l’unità di esclusione (ad esempio, per soggetto o per gruppo). Nei modelli gerarchici o multilivello, LOO e WAIC possono essere applicati in modo coerente, prestando attenzione a non escludere singole osservazioni se queste non sono indipendenti, ma piuttosto interi cluster.\n\n75.8.1.2 Errori comuni e best practice\nUn errore frequente è utilizzare il Mean Squared Error (MSE) sul campione di addestramento come metro di giudizio, poiché questo valore non penalizza la complessità e tende quindi a favorire modelli eccessivamente flessibili e soggetti a overfitting. Allo stesso modo, è importante ricordare che AIC e BIC si basano su stime puntuali (MLE o MAP) e non catturano l’incertezza completa sui parametri, il che li rende meno ideali in un contesto bayesiano puro. WAIC e LOOCV, al contrario, sono espressamente concepiti per stimare la performance predittiva su dati nuovi.\nQuando si riporta un confronto tra modelli, è buona norma includere non solo il modello “vincente”, ma anche la differenza di ELPD con il suo errore standard, le diagnostiche sui parametri di Pareto-k, una stima della complessità effettiva e un commento sostantivo che spieghi il motivo della preferenza, che potrebbe risiedere nella parsimonia, nell’interpretabilità dei parametri o nella robustezza.\n\n75.8.1.3 In sintesi: il workflow essenziale\nUn mini-workflow consigliato per un approccio bayesiano prevede di: adattare i modelli; calcolare il LOO per ciascuno di essi e controllare i parametri di Pareto-k; se si riscontrano valori di k elevati, considerare una convalida incrociata K-fold o una LOO per cluster; confrontare i modelli con appositi strumenti e riportare le differenze di ELPD; opzionalmente, calcolare il WAIC come controllo incrociato; argomentare infine la scelta finale anche in base a parsimonia e interpretabilità.\nLa selezione del modello, in definitiva, ruota attorno a una domanda essenziale: quanto bene il modello predice dati che non ha mai visto? Il riferimento teorico è l’Expected Log Predictive Density (ELPD), che misura quanto la distribuzione predittiva del modello si avvicina alla vera distribuzione dei dati. Poiché quest’ultima è sconosciuta, l’ELPD va stimato con strumenti come LOO-CV e WAIC, che oggi rappresentano gli standard più affidabili per guidare una scelta consapevole, equilibrata e focalizzata sulla capacità di generalizzazione.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#riflessioni-conclusive",
    "href": "chapters/entropy/03_model_comparison.html#riflessioni-conclusive",
    "title": "75  Valutare i modelli bayesiani",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl principio fondamentale della modellazione bayesiana risiede nella valutazione della qualità di un modello attraverso la sua capacità di produrre previsioni probabilistiche robuste, rappresentate dalla distribuzione predittiva a posteriori \\(p(\\tilde{y} \\mid y)\\).\nLa misura che guida questa valutazione è l’Expected Log Predictive Density (ELPD), che quantifica la capacità predittiva del modello su dati non osservati. A differenza delle metriche in-sample, soggette a sovradattamento, l’ELPD fornisce una stima imparziale della capacità di generalizzazione. Teoricamente, massimizzare l’ELPD equivale a minimizzare la divergenza di Kullback-Leibler rispetto alla vera distribuzione generatrice dei dati.\nOperativamente, l’ELPD viene stimato mediante PSIS-LOO, integrato con i diagnostici Pareto-k. Il WAIC costituisce un’alternativa bayesiana solida, spesso coerente con LOO. Al contrario, criteri come AIC e BIC, sebbene computazionalmente efficienti, si basano su stime puntuali e approssimazioni asintotiche, risultando meno affidabili in contesti di campioni piccoli o modelli gerarchici.\nNel confronto tra modelli, è essenziale riportare non solo l’ELPD-LOO, ma anche le differenze ΔELPD e i relativi errori standard. Tuttavia, la selezione del modello non dovrebbe ridursi a un esercizio meccanico: differenze trascurabili nell’ELPD, specialmente se associate ad alta incertezza, possono essere irrilevanti sul piano sostanziale. Modelli meno performanti ma più parsimoniosi o teoricamente fondati possono rappresentare scelte migliori.\nL’obiettivo finale è bilanciare capacità predittiva e coerenza teorica, ricordando che lo scopo della modellazione non è solo prevedere, ma comprendere. La valutazione deve quindi integrare strumenti come il PSIS-LOO con considerazioni sull’incertezza statistica, la struttura dei dati e il contesto teorico di riferimento.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] gt_1.0.0              pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] xml2_1.4.0            RColorBrewer_1.1-3    abind_1.4-8          \n#&gt; [25] multcomp_1.4-28       withr_3.0.2           purrr_1.1.0          \n#&gt; [28] grid_4.5.1            stats4_4.5.1          colorspace_2.1-1     \n#&gt; [31] xtable_1.8-4          inline_0.3.21         emmeans_1.11.2-8     \n#&gt; [34] scales_1.4.0          MASS_7.3-65           cli_3.6.5            \n#&gt; [37] mvtnorm_1.3-3         rmarkdown_2.29        ragg_1.5.0           \n#&gt; [40] generics_0.1.4        RcppParallel_5.1.11-1 cachem_1.1.0         \n#&gt; [43] stringr_1.5.1         splines_4.5.1         parallel_4.5.1       \n#&gt; [46] vctrs_0.6.5           V8_7.0.0              Matrix_1.7-4         \n#&gt; [49] sandwich_3.1-1        jsonlite_2.0.0        arrayhelpers_1.1-0   \n#&gt; [52] systemfonts_1.2.3     glue_1.8.0            codetools_0.2-20     \n#&gt; [55] distributional_0.5.0  lubridate_1.9.4       stringi_1.8.7        \n#&gt; [58] gtable_0.3.6          QuickJSR_1.8.0        htmltools_0.5.8.1    \n#&gt; [61] Brobdingnag_1.2-9     R6_2.6.1              textshaping_1.0.3    \n#&gt; [64] rprojroot_2.1.1       evaluate_1.0.5        lattice_0.22-7       \n#&gt; [67] backports_1.5.0       memoise_2.0.1         broom_1.0.9          \n#&gt; [70] snakecase_0.11.1      rstantools_2.5.0      coda_0.19-4.1        \n#&gt; [73] gridExtra_2.3         nlme_3.1-168          checkmate_2.3.3      \n#&gt; [76] xfun_0.53             zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#bibliografia",
    "href": "chapters/entropy/03_model_comparison.html#bibliografia",
    "title": "75  Valutare i modelli bayesiani",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/introduction.html",
    "href": "chapters/formal_models/introduction.html",
    "title": "74  Teorie formali dei fenomeni psicologici",
    "section": "",
    "text": "Introduzione\nU no degli sviluppi più rilevanti della psicologia contemporanea è l’uso di teorie formali per indagare i meccanismi che generano i fenomeni psicologici. I modelli matematici non sono semplici strumenti di calcolo: servono a tradurre in termini quantitativi le ipotesi teoriche, a chiarire come i costrutti cognitivi — spesso latenti e non direttamente osservabili — possano essere collegati a parametri misurabili e a prevedere i comportamenti osservati.\nTradizionalmente, molti modelli cognitivi trattano i dati come osservazioni indipendenti e identicamente distribuite (IID). Questa assunzione semplifica l’analisi, ma trascura un aspetto cruciale: i costrutti psicologici cambiano nel tempo. Negli esperimenti, le capacità cognitive non dipendono solo dalle caratteristiche del compito, ma anche da processi mentali interni e da stati cerebrali che fluttuano su diverse scale temporali. Queste variazioni — dovute, ad esempio, a fatica, pratica, divagazione mentale o cambiamenti motivazionali — possono essere sistematiche o meno, ma raramente sono irrilevanti. Come sottolineato da Schumacher et al. (2023), i meccanismi cognitivi dovrebbero essere compresi come sistemi dinamici complessi, e i modelli dovrebbero tener conto di queste dinamiche per cogliere appieno la struttura dei dati.\nLa teoria dei sistemi dinamici (Dynamic Systems Theory, DST) offre un quadro concettuale potente per descrivere i fenomeni psicologici come processi complessi, spesso non lineari e auto-organizzanti, che emergono dall’interazione di molteplici componenti, sia all’interno dell’individuo sia tra individuo e ambiente. In questa prospettiva, il comportamento e la cognizione non sono entità statiche, ma traiettorie che si sviluppano nel tempo.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Teorie formali dei fenomeni psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/introduction.html#ambiti-di-applicazione",
    "href": "chapters/formal_models/introduction.html#ambiti-di-applicazione",
    "title": "74  Teorie formali dei fenomeni psicologici",
    "section": "74.1 Ambiti di applicazione",
    "text": "74.1 Ambiti di applicazione\nMolti ambiti della psicologia possono essere reinterpretati attraverso la lente dei sistemi dinamici:\n\nApprendimento per rinforzo: un processo adattativo in cui le decisioni vengono costantemente aggiornate in base a ricompense e punizioni, generando cicli di feedback che modellano il comportamento. Modelli come quello di Rescorla-Wagner descrivono matematicamente questi meccanismi e trovano applicazione dal condizionamento classico fino alla psichiatria computazionale.\nRegolazione delle emozioni: un sistema dinamico in cui processi fisiologici, cognitivi e comportamentali interagiscono nel tempo, talvolta amplificando proprio le emozioni che si cerca di controllare.\nAttaccamento e relazioni sociali: interazioni continue in cui comportamenti e stati emotivi di ciascun individuo influenzano e vengono influenzati dagli altri, creando cicli di retroazione che si consolidano nel tempo.\nSviluppo cognitivo: adattamenti e riorganizzazioni costanti delle strutture mentali in risposta a nuove esperienze, come descritto dalla teoria piagetiana reinterpretata in termini dinamici.\nControllo motorio e coordinazione: comportamenti motori che emergono dall’auto-organizzazione di sistemi neurali, muscolari e sensoriali.\nDecision making e problem solving: processi che evolvono in funzione dell’interazione tra fattori cognitivi ed emotivi e delle esperienze accumulate.\nPsicopatologia: disturbi come depressione e ansia concepiti come pattern dinamici di pensieri, emozioni e comportamenti che si autoalimentano.\nSviluppo del linguaggio: acquisizione linguistica come risultato dell’interazione continua tra fattori cognitivi, sociali e percettivi.\nDinamiche di gruppo e influenza sociale: norme e comportamenti collettivi che si trasformano attraverso cicli di influenza reciproca.\nAutoregolazione e funzioni esecutive: monitoraggio e aggiustamento costante di attenzione, emozioni e azioni per perseguire obiettivi a lungo termine.\nApprendimento e memoria: processi di codifica, consolidamento e recupero che dipendono da stati cognitivi e fisiologici mutevoli.\n\nIn questa sezione ci concentreremo su un caso specifico: il modello di revisione degli obiettivi, descritto nel tutorial di Knight et al. (2023), che offre un esempio chiaro di come un approccio dinamico possa essere formalizzato, stimato e utilizzato per interpretare dati psicologici complessi.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Teorie formali dei fenomeni psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/introduction.html#bibliografia",
    "href": "chapters/formal_models/introduction.html#bibliografia",
    "title": "74  Teorie formali dei fenomeni psicologici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKnight, E., Neal, A., Palada, H., & Ballard, T. (2023). A Tutorial on Bayesian Modeling of Change Across Time, Individuals, and Groups. Computational Brain & Behavior, 6(4), 697–718.\n\n\nSchumacher, L., Bürkner, P.-C., Voss, A., Köthe, U., & Radev, S. T. (2023). Neural superstatistics for Bayesian estimation of dynamic cognitive models. Scientific Reports, 13(1), 13778.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Teorie formali dei fenomeni psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html",
    "href": "chapters/formal_models/01_dynamic_models.html",
    "title": "75  Il modello di revisione degli obiettivi",
    "section": "",
    "text": "Introduzione\nM olti dei fenomeni studiati in psicologia non sono statici, ma si sviluppano e si trasformano nel tempo. L’apprendimento, l’adattamento agli errori, la regolazione degli obiettivi, l’emergere o la remissione di sintomi clinici sono tutti esempi di processi dinamici, in cui ciò che osserviamo in un dato momento è il risultato di una storia pregressa.\nTuttavia, gli strumenti statistici più utilizzati in psicologia trascurano spesso questa dimensione temporale. Confrontiamo medie, calcoliamo correlazioni o eseguiamo regressioni, spesso trattando le osservazioni come indipendenti tra loro. Questo approccio è utile per molte domande, ma inadeguato quando l’obiettivo è comprendere l’evoluzione di un comportamento o di uno stato psicologico.\nSe vogliamo capire come le persone modificano i propri obiettivi, cambiano strategia, o si adattano nel tempo a esperienze positive e negative, abbiamo bisogno di un approccio che tenga conto della sequenza degli eventi. Serve un modello in grado di descrivere le regole del cambiamento.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#introduzione",
    "href": "chapters/formal_models/01_dynamic_models.html#introduzione",
    "title": "75  Il modello di revisione degli obiettivi",
    "section": "",
    "text": "Prerequisiti\n\n\n\n\n\n\nLeggere The role of the individual in the coming era of process-based therapy (Hayes et al., 2019).",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#perché-abbiamo-bisogno-di-modelli-dinamici",
    "href": "chapters/formal_models/01_dynamic_models.html#perché-abbiamo-bisogno-di-modelli-dinamici",
    "title": "75  Il modello di revisione degli obiettivi",
    "section": "\n75.1 Perché abbiamo bisogno di modelli dinamici?",
    "text": "75.1 Perché abbiamo bisogno di modelli dinamici?\nUn modello dinamico è una rappresentazione matematica che esplicita il modo in cui un sistema evolve nel tempo. La caratteristica distintiva di questi modelli è la presenza di dipendenze temporali: almeno una delle variabili dipende da valori passati, non solo da ciò che accade nel presente.\nQuesto è ciò che li differenzia dai modelli statici, dove ogni osservazione è trattata come indipendente dalle precedenti. Nei modelli dinamici, invece, esiste una memoria del passato, che influenza l’andamento futuro del processo. Nei modelli statici, la variabilità del comportamento è trattata come rumore o differenza individuale. Nei modelli dinamici, questa variabilità diventa informativa: è l’espressione dell’adattamento del sistema alle condizioni del contesto o alla propria storia passata.\nUna classe importante di variabili in questo contesto è costituita dalle variabili di stato (in inglese: state variables o stock variables), che rappresentano il livello accumulato di una certa quantità nel tempo: un obiettivo personale, un livello di motivazione, una credenza, o un sintomo. Queste variabili si aggiornano a ogni passo temporale secondo una regola di cambiamento che è definita in termini matematici.\n\n75.1.1 Come si costruisce un modello dinamico?\nFormulare un modello dinamico significa tradurre in termini espliciti una teoria del cambiamento. I passaggi fondamentali sono:\n\n\nIdentificare le variabili rilevanti: quali sono gli elementi del sistema che vogliamo modellare?\n\nStabilire le regole di aggiornamento: come cambia ciascuna variabile nel tempo in risposta a feedback o input esterni?\n\nFormalizzare il modello in equazioni: trasformare le regole in una struttura matematica coerente.\n\nValutare la validità del modello: confrontare le sue previsioni con i dati osservati, utilizzando metodi statistici appropriati.\n\nQuesto approccio è particolarmente adatto alla psicologia, dove l’interesse non riguarda solo il fatto che un comportamento cambi, ma anche il modo in cui evolve nel tempo.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#un-esempio-concreto-il-modello-di-revisione-degli-obiettivi",
    "href": "chapters/formal_models/01_dynamic_models.html#un-esempio-concreto-il-modello-di-revisione-degli-obiettivi",
    "title": "75  Il modello di revisione degli obiettivi",
    "section": "\n75.2 Un esempio concreto: il modello di revisione degli obiettivi",
    "text": "75.2 Un esempio concreto: il modello di revisione degli obiettivi\nPer chiarire meglio questo concetto, in questo e nel successivo capitolo considereremo un esempio concreto discusso da Knight et al. (2023): la regolazione degli obiettivi in base ai feedback. Immaginiamo un esperimento in cui i partecipanti devono svolgere un compito ripetitivo, come la classificazione di coppie di immagini. Prima di ogni prova (trial), ciascuno partecipante fissa un obiettivo personale, ad esempio migliorare la velocità o la precisione rispetto al tentativo precedente. Al termine di ogni prova, il partecipante riceve un feedback sulla propria performance e può quindi decidere se mantenere o modificare l’obiettivo per la prova successiva.\nQuesto ciclo – definizione dell’obiettivo, esecuzione, feedback, aggiustamento – è dinamico e si ripete in modo iterativo. Un buon modello dinamico riesce a catturare con precisione tale meccanismo, e, ad esempio, permette di stimare con quanta rapidità una persona riveda le proprie aspirazioni in risposta a successi o fallimenti.\nNel resto del capitolo, mostreremo come formalizzare matematicamente questo processo e come stimare i suoi parametri con un approccio bayesiano implementato in Stan.\n\n75.2.1 Come formalizzare questo processo?\nUna delle ipotesi più semplici, ma sorprendentemente potenti, è che le persone modifichino i propri obiettivi in funzione della discrepanza tra i risultati ottenuti (performance) e le aspettative (goal). Se la performance supera l’obiettivo, le aspettative tendono ad aumentare (ambizione crescente). Se la performance è inferiore, invece, si tende a ridurre le aspettative (aggiustamento conservativo).\nKnight et al. (2023) hanno formalizzato questa intuizione nel seguente modello dinamico lineare\n\\[\nG_t = G_{t-1} + \\alpha \\cdot (P_{t-1} - G_{t-1}) + \\beta ,\n\\tag{75.1}\\] dove:\n\n\n\\(G_t\\) è l’obiettivo fissato al trial \\(t\\),\n\n\\(G_{t-1}\\) è l’obiettivo del trial precedente,\n\n\\(P_{t-1}\\) è la performance osservata al trial precedente,\n\n\\(\\alpha\\) è un parametro che rappresenta la sensibilità alla discrepanza (quanto il goal viene aggiornato in risposta all’errore),\n\n\\(\\beta\\) è un bias sistematico. \\(\\beta &gt; 0\\) indica una deriva ambiziosa (es., pressione sociale), mentre \\(\\beta &lt; 0\\) indica una deriva cautelativa (es., affaticamento).\n\nIn altre parole, l’obiettivo del trial corrente (\\(G_t\\)) è determinato dall’obiettivo precedente (\\(G_{t-1}\\)), corretto per una frazione (\\(\\alpha\\)) della discrepanza (errore) tra la performance passata (\\(P_{t-1}\\)) e l’obiettivo passato (\\(G_{t-1}\\)). A questo risultato si aggiunge una tendenza sistematica (\\(\\beta\\)) a migliorare o peggiorare le proprie aspettative, indipendentemente dalla performance.\nSi noti che questo è un modello a livello di campione (sample-level), in quanto assume che tutti i partecipanti condividano gli stessi parametri \\(\\alpha\\) e \\(\\beta\\), i quali vengono stimati aggregando i dati dell’intero campione.\n\n75.2.2 Illustrazione numerica del modello\nPer esplorare il comportamento del modello, consideriamo due scenari contrastanti con gli stessi parametri:\n\n\n\\(\\alpha = 0.5\\): un tasso di apprendimento moderato, per cui il 50% della discrepanza osservata viene incorporato nel nuovo obiettivo.\n\n\\(\\beta = 2\\): un bias positivo che spinge sistematicamente l’obiettivo verso l’alto di 2 punti a ogni trial, indipendentemente dalla performance.\n\nScenario 1: Successo (Performance &gt; Obiettivo)\n\nobiettivo precedente (\\(G_{t-1}\\)): 50 punti;\nperformance (\\(P_{t-1}\\)): 60 punti (supera l’obiettivo di 10 punti).\n\nCalcolo: \\(G_t = 50 + 0.5 \\cdot (60 - 50) + 2 = 50 + 5 + 2 = \\mathbf{57}\\).\nInterpretazione: Il partecipante ha ottenuto un risultato superiore alle aspettative. Il nuovo obiettivo viene quindi aumentato per incorporare metà di questo successo (+5 punti, effetto di \\(\\alpha\\)). A questo si aggiunge la spinta ambiziosa sistematica data da \\(\\beta\\) (+2 punti). Il risultato è un aggiustamento ambizioso da 50 a 57 punti, in cui il bias \\(\\beta\\) amplifica l’effetto della performance positiva.\nScenario 2: Insuccesso (Performance &lt; Obiettivo)\n\nObiettivo precedente (\\(G_{t-1}\\)): 50 punti;\nperformance (\\(P_{t-1}\\)): 40 punti (inferiore di 10 punti rispetto all’obiettivo).\n\nCalcolo: \\(G_t = 50 + 0.5 \\cdot (40 - 50) + 2 = 50 - 5 + 2 = \\mathbf{47}\\).\nInterpretazione: Nonostante la performance deludente, l’aggiustamento è stato attenuato. La discrepanza negativa porta a una riduzione dell’obiettivo (-5 punti, effetto di \\(\\alpha\\)), ma il bias positivo \\(\\beta\\) (+2 punti) contrasta parzialmente tale riduzione. Questo meccanismo può modellare fenomeni come la resilienza (non penalizzare eccessivamente gli insuccessi) o l’effetto di una pressione esterna continua a migliorare.\n\n75.2.3 Il ruolo cruciale del parametro \\(\\beta\\)\n\nPer isolare l’effetto della deriva sistematica, confrontiamo i risultati dei due scenari con il caso in cui \\(\\beta = 0\\).\n\n\n\n\n\n\n\n\n\nScenario\nCon \\(\\beta=+2\\)\n\nCon \\(\\beta=0\\)\n\nDifferenza\nEffetto di \\(\\beta\\)\n\n\n\n\nSuccesso\n57\n55\n+2\nAmplifica il successo\n\n\nInsuccesso\n47\n45\n+2\nAttutisce il fallimento\n\n\n\nConclusioni e insight:\n\n\n\\(\\alpha\\) (Sensibilità) controlla l’adattamento reattivo: determina quanto rapidamente l’obiettivo “insegue” la performance passata.\n\n\\(\\beta\\) (Bias) introduce una tendenza proattiva spingendo l’obiettivo in una direzione specifica (in questo caso verso l’alto), indipendentemente dal feedback immediato;\n\n\n\\(\\beta &gt; 0\\): induce un’ambizione sistematica, spingendo a fare di più anche dopo un fallimento;\n\n\\(\\beta &lt; 0\\): riflette una cautela strutturale (es., affaticamento, avversione al rischio)e porta a ridurre le aspettative anche dopo un successo.\n\n\n\nSintesi delle interazioni: Un modello completo richiede entrambi i parametri per catturare sia le risposte locali ai feedback (\\(\\alpha\\)) sia le tendenze globali e motivazionali a lungo termine (\\(\\beta\\)). La loro interazione definisce la dinamica complessiva della fissazione degli obiettivi.\n\n75.2.4 Perché questo modello è importante?\nQuesto approccio rappresenta un ponte tra la psicologia e la modellizzazione matematica, trasformando ipotesi sui processi cognitivi—in particolare la regolazione degli obiettivi—in relazioni quantitative e verificabili. Sul piano metodologico, supera i limiti delle descrizioni qualitative attraverso una formalizzazione elegante: il parametro \\(\\alpha\\) quantifica la sensibilità individuale alla discrepanza tra prestazioni attese ed effettive, rivelando la prontezza nel ricalibrare gli obiettivi. Valori elevati denotano un adattamento rapido all’errore, mentre valori bassi indicano maggiore perseveranza. Parallelamente, \\(\\beta\\) cattura tendenze sistemiche indipendenti dalla performance, come un’ambizione costante (\\(\\beta &gt; 0\\)) o una deriva cautelativa (\\(\\beta &lt; 0\\)). Questa dualità consente di discriminare con precisione il peso relativo del feedback esperito rispetto a fattori contestuali intrinseci o ambientali.\nIl modello offre un notevole valore predittivo, rendendolo uno strumento operativo in contesti applicativi. Una volta stimati i parametri \\(\\alpha\\) e \\(\\beta\\) per un individuo o un gruppo, è possibile anticipare le risposte a specifici schemi di feedback, abilitando interventi su misura.\n\nIn ambito educativo, si possono progettare interventi che bilancino sostegno e sfida per ottimizzare la motivazione.\nIn contesti clinici, il modello aiuta a identificare schemi disfunzionali – come una combinazione di basso \\(\\alpha\\) (scarsa reattività al feedback) e \\(\\beta\\) negativo (deriva al ribasso) – tipici di stati depressivi o ansiosi.\nNel mondo organizzativo, permette di adattare sistemi di valutazione e incentivazione alle caratteristiche dei team.\n\nLa flessibilità del modello lo rende inoltre una base solida per esplorare complessità aggiuntive, come effetti non lineari, differenze individuali o influenze contestuali, mantenendo al contempo una struttura interpretabile.\nIn sintesi, questo modello fornisce un linguaggio comune per studiare, prevedere e influenzare i meccanismi cognitivi alla base della regolazione degli obiettivi, contribuendo così a una psicologia più rigorosa e a interventi più mirati.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#stima-dei-parametri-con-stan",
    "href": "chapters/formal_models/01_dynamic_models.html#stima-dei-parametri-con-stan",
    "title": "75  Il modello di revisione degli obiettivi",
    "section": "\n75.3 Stima dei parametri con Stan",
    "text": "75.3 Stima dei parametri con Stan\nPassando dalla teoria alla pratica, affrontiamo ora il cuore operativo della modellizzazione: la stima dei parametri che quantificano il processo di aggiornamento degli obiettivi. Il modello dinamico precedentemente descritto trova la sua concretizzazione statistica attraverso tre parametri chiave:\n\n\n\\(\\alpha\\): rappresenta la sensibilità alla discrepanza tra performance e obiettivi;\n\n\\(\\beta\\): cattura le tendenze sistemiche nel cambiamento degli obiettivi;\n\n\\(\\sigma\\): misura la variabilità residua non spiegata dal modello.\n\nPer farlo, traduciamo l’equazione teorica in un modello statistico e utilizziamo un approccio bayesiano per stimare la distribuzione a posteriori dei parametri.\n\n75.3.1 Dal modello teorico al modello statistico\nIl modello dinamico di base esprime la regola di aggiornamento degli obiettivi attraverso un’equazione deterministica\n\\[\nG_t = G_{t-1} + \\alpha (P_{t-1} - G_{t-1}) + \\beta .\n\\] Tuttavia, per trasformarla in un modello statistico adatto all’analisi empirica, dobbiamo considerare la componente stocastica del processo. Introduciamo quindi un termine di errore che catturi la variabilità naturale del processo di fissazione degli obiettivi, l’effetto di fattori non modellati esplicitamente e gli eventuali errori di misurazione. La versione statistica del modello diventa:\n\\[\n\\text{Goal osservato} \\sim \\mathcal{N}(G_t, \\sigma) .\n\\tag{75.2}\\] In altre parole, si assume che il goal osservato sia distribuito normalmente attorno al valore previsto con una certa variabilità, indicata con \\(\\sigma\\).\n\n75.3.2 Il vantaggio dell’approccio bayesiano per modelli dinamici\nLa natura ricorsiva dei modelli dinamici, in cui ogni stima dipende dal valore precedente, rende difficile l’applicazione dei metodi frequentisti tradizionali. L’inferenza bayesiana offre invece un quadro naturale per gestire sia le dipendenze temporali sia l’incertezza sui parametri. Stan rappresenta uno strumento particolarmente adatto a questo scopo, perché implementa algoritmi MCMC avanzati in grado di trattare in modo efficiente le correlazioni tra parametri, propagare l’incertezza lungo le catene temporali e incorporare le conoscenze pregresse attraverso distribuzioni a priori.\nA differenza degli approcci classici, l’output bayesiano non si riduce a una stima puntuale, ma fornisce l’intera distribuzione a posteriori, che riflette tutte le relazioni probabilistiche tra parametri e stati latenti. Questo permette di quantificare l’incertezza in modo rigoroso, formulare probabilità dirette per le ipotesi teoriche e sviluppare previsioni robuste che integrano le diverse fonti di variabilità presenti nei dati.\n\n75.3.3 Esempio: implementazione del modello in Stan\nIl codice Stan presentato qui di seguito segue esattamente la struttura logica del modello teorico:\n\ni dati in input sono il numero di trial, i goal osservati e le performance;\ni parametri da stimare sono \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\);\nla regola di aggiornamento è implementata in un ciclo for, trial per trial;\nla distribuzione normale collega il goal previsto a quello osservato;\nun blocco aggiuntivo (generated quantities) consente di generare dati simulati a partire dai parametri stimati.\n\n75.3.4 Il codice Stan\nDi seguito, riportiamo il modello completo implementato in Stan. Analizzeremo poi ciascuna parte.\n// MODELLO PER L'AGGIORNAMENTO DEGLI OBIETTIVI BASATO SULLA PERFORMANCE PRECEDENTE\n\n// ---------------------------\n// BLOCCO DEI DATI: COSA FORNIAMO AL MODELLO\n// ---------------------------\ndata {\n  int Ntotal;                      // Numero totale di osservazioni (es. 600 trial)\n  real trial[Ntotal];              // Numero del trial (es. 1, 2, 3, ..., 600)\n  real observed_goal[Ntotal];      // Obiettivo desiderato osservato in ciascun trial\n  real performance[Ntotal];        // Prestazione osservata in ciascun trial\n}\n\n// ---------------------------\n// PARAMETRI DEL MODELLO: COSA VOGLIAMO STIMARE\n// ---------------------------\nparameters {\n  real alpha;                      // Quanto il partecipante adatta il proprio obiettivo (apprendimento)\n  real beta;                       // Tendenza generale a incrementare l’obiettivo (motivazione costante)\n  real&lt;lower=0&gt; sigma;             // Variazione casuale attorno al goal previsto (rumore)\n}\n\n// ---------------------------\n// MODELLO: COME SI SPIEGANO I DATI\n// ---------------------------\nmodel {\n  real predicted_goal;             // Variabile temporanea per salvare la previsione del goal\n\n  // --- PRIORS: aspettative iniziali sui parametri ---\n  alpha ~ normal(0, 1);            // Alpha: in media 0, con incertezza (deviazione standard = 1)\n  beta ~ normal(0, 1);             // Beta: idem\n  sigma ~ normal(0, 1);            // Sigma: deviazione standard del rumore (deve essere positiva)\n\n  // --- CICLO PER OGNI TRIAL ---\n  for (i in 1:Ntotal) {\n\n    // Caso speciale: primo trial → nessuna previsione, usiamo direttamente il dato osservato\n    if (trial[i] == 1) {\n      predicted_goal = observed_goal[i];\n    }\n\n    // Tutti i trial successivi → aggiornamento del goal basato sulla performance precedente\n    if (trial[i] &gt; 1) {\n      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;\n      // ↑ Questa è la \"regola di apprendimento\":\n      // - Se la performance precedente è migliore del goal → l’obiettivo aumenta\n      // - Se la performance è peggiore → l’obiettivo diminuisce\n      // - Quanto cambia? Dipende da alpha (quanto il partecipante si adatta)\n      // - A ogni passo si aggiunge anche un piccolo incremento costante (beta)\n    }\n\n    // Likelihood: assumiamo che il goal osservato sia vicino al goal previsto, con un po’ di rumore\n    observed_goal[i] ~ normal(predicted_goal, sigma);\n  }\n}\n\n// ---------------------------\n// BLOCCO PER GENERARE PREVISIONI (non necessario, ma utile per valutare il modello)\n// ---------------------------\ngenerated quantities {\n  real predicted_goal;              // Valore previsto dal modello\n  real sampled_goal[Ntotal];        // Goal \"simulati\", generati dal modello\n\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal = observed_goal[i];\n    }\n    if (trial[i] &gt; 1) {\n      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;\n    }\n\n    // Simuliamo un nuovo goal come se fosse stato osservato, aggiungendo variabilità\n    sampled_goal[i] = normal_rng(predicted_goal, sigma);\n  }\n}\n\n75.3.5 La Struttura del Codice Stan: Quattro Blocchi Logici\n\n75.3.5.1 1. data – “Cosa sappiamo”\n\ndata {\n  int Ntotal;                 // Numero di trial osservati\n  real trial[Ntotal];         // Indice del trial\n  real observed_goal[Ntotal]; // Obiettivi dichiarati\n  real performance[Ntotal];   // Performance ottenute\n}\nQui definiamo i dati raccolti nell’esperimento, cioè le informazioni che Stan utilizzerà per stimare il modello.\n\n75.3.5.2 2. parameters – “Cosa vogliamo scoprire”\n\nparameters {\n  real alpha;                 // Tasso di apprendimento (sensibilità al feedback)\n  real beta;                  // Tendenza sistematica\n  real&lt;lower=0&gt; sigma;        // Rumore decisionale\n}\nSono i parametri ignoti che Stan deve stimare sulla base dei dati.\n\n75.3.5.3 3. model – “Come funziona il processo”\n\nIn questo blocco specifichiamo sia le ipotesi a priori sia la dinamica trial-per-trial.\n(a) Priors: aspettative iniziali\nalpha ~ normal(0, 1);\nbeta  ~ normal(0, 1);\nsigma ~ normal(0, 1);\nPrima dei dati, ipotizziamo che \\(\\alpha\\) e \\(\\beta\\) siano vicini a zero, pur ammettendo un’ampia incertezza.\n(b) Aggiornamento sequenziale\nfor (i in 1:Ntotal) {\n  if (trial[i] == 1) {\n    predicted_goal = observed_goal[i]; // primo trial: usiamo l’osservato\n  } else {\n    predicted_goal += alpha * (performance[i-1] - predicted_goal) + beta;\n  }\n  observed_goal[i] ~ normal(predicted_goal, sigma);\n}\nAd ogni trial il modello aggiorna l’obiettivo previsto e lo confronta con quello effettivamente osservato.\n\n75.3.5.4 4. generated quantities – “E se simulassimo?”\n\nQuesto blocco permette di generare nuovi dati a partire dai parametri stimati, replicando la stessa dinamica ipotizzata dal modello.\ngenerated quantities {\n  real sampled_goal[Ntotal];\n  for (i in 1:Ntotal) {\n    sampled_goal[i] = normal_rng(predicted_goal, sigma);\n  }\n}\nLe traiettorie simulate hanno un duplice scopo: da un lato consentono i posterior predictive checks, cioè il confronto tra dati osservati e dati generati per valutare la plausibilità del modello; dall’altro offrono uno strumento per fare previsioni su come potrebbe evolvere il comportamento in situazioni nuove.\n\nIn sintesi, questo modello “apre la scatola nera” dei processi decisionali: trasforma osservazioni empiriche in parametri interpretabili, mostrando come feedback, tendenze personali e rumore si combinino nell’aggiornare gli obiettivi.\n\n75.3.5.5 Risultati finali e interpretazione\nL’analisi produce innanzitutto le distribuzioni posteriori dei parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma.\\) Queste non restituiscono un singolo valore, ma un insieme di possibilità plausibili da cui ricavare medie, intervalli credibili e sintesi utili all’interpretazione psicologica. In questo modo possiamo valutare quanto i partecipanti si adattino ai feedback (\\(\\alpha\\)), se mostrino derive sistematiche di crescita o declino negli obiettivi (\\(\\beta\\)) e quanta variabilità residua caratterizzi il loro processo decisionale (\\(\\sigma\\)).\nLa solidità delle stime viene garantita dagli indicatori diagnostici MCMC, come \\(\\hat{R}\\) per la convergenza e \\(n_{\\text{eff}}\\) per l’efficienza campionaria. Solo quando questi indici segnalano un campionamento affidabile le distribuzioni posteriori possono essere considerate attendibili.\nInfine, la validazione predittiva tramite i dati simulati nel blocco generated quantities consente un confronto diretto tra le traiettorie osservate e quelle generate dal modello. Questo passaggio, noto come posterior predictive check, è cruciale perché permette di verificare se il modello riproduce i pattern empirici e, quindi, di valutarne la plausibilità e la capacità esplicativa.\n\n75.3.6 Verso una modellizzazione più ricca: estensioni del modello base\nIl modello di base, pur essendo utile, è una rappresentazione semplificata. Per cogliere la reale eterogeneità del comportamento umano, sono state sviluppate diverse estensioni che mantengono il nucleo teorico originale, ma ne aumentano il potere esplicativo.\nModello a livello individuale. Stima parametri specifici (\\(\\alpha_i\\), \\(\\beta_i\\)) per ogni partecipante, consentendo di mappare differenze sistematiche nella sensibilità al feedback e nelle tendenze motivazionali.\nModelli gerarchici (multilevel). Stimano i parametri individuali come estratti da distribuzioni di gruppo. In questo modo si ottiene un duplice vantaggio: si preservano le differenze tra individui e, al tempo stesso, si guadagna robustezza statistica grazie alla condivisione di informazione (shrinkage). Ne risultano stime più stabili ed equilibrate, particolarmente preziose con campioni piccoli o dati rumorosi.\nModelli a gruppi noti. Permettono di stimare \\(\\alpha\\) e \\(\\beta\\) separatamente per diverse condizioni sperimentali (es., diversi tipi di incentivo), testando direttamente l’effetto di manipolazioni contestuali.\nModelli di mistura (Mixture Models). Identificano sottogruppi latenti di partecipanti con dinamiche distinte (es., “adattatori rapidi” vs. “perseveranti”) senza richiedere categorie predefinite.\nQueste estensioni, che approfondiremo nel capitolo successivo, spostano l’attenzione dalla semplice stima di una tendenza centrale alla modellizzazione della variabilità, trasformando le differenze individuali da rumore a informazione teoricamente cruciale. Il modello di base rimane un punto di riferimento concettuale, mentre le versioni avanzate ne aumentano la precisione nel catturare la complessità psicologica, mantenendo intatta l’idea centrale di un aggiornamento dinamico degli obiettivi guidato da feedback e inclinazioni personali.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#riflessioni-conclusive",
    "href": "chapters/formal_models/01_dynamic_models.html#riflessioni-conclusive",
    "title": "75  Il modello di revisione degli obiettivi",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nQuesto esempio mostra come concetti psicologici complessi, come la regolazione degli obiettivi, possano essere formalizzati in modelli dinamici capaci di descrivere l’evoluzione temporale dei processi cognitivi. L’approccio integra tre componenti centrali: la formalizzazione teorica tramite equazioni, l’implementazione computazionale in Stan e l’inferenza bayesiana per stimare e valutare il modello sui dati.\nRispetto ai modelli statici, questa prospettiva consente di analizzare non solo se il comportamento cambia, ma anche come, quando e in risposta a quali condizioni. Pur nella sua semplicità, il modello discusso evidenzia il potenziale di una psicologia formale orientata all’identificazione dei meccanismi generativi sottostanti i dati osservati.\nCome sottolineano Knight e colleghi (2023), un approccio di questo tipo si articola in tre passaggi: (1) la costruzione di un modello generativo che specifichi i meccanismi ipotizzati, (2) la traduzione delle ipotesi in codice eseguibile, e (3) la valutazione del modello non solo tramite indici statistici, ma anche attraverso il confronto tra dati osservati e simulati.\nUn modello è utile anche se semplice, purché soddisfi tre condizioni: si fonda su ipotesi teoriche esplicite, produce previsioni verificabili e resta estendibile per affrontare nuove domande di ricerca. Il modello sample-level discusso qui rappresenta dunque un punto di partenza che può evolvere introducendo parametri individuali, strutture gerarchiche o modelli a gruppi latenti per rilevare pattern nascosti.\nDal punto di vista didattico, questo esempio mostra come le teorie psicologiche possano tradursi in equazioni formali da simulare, testare e validare empiricamente. In questo modo, le ipotesi diventano affermazioni quantitative verificabili, spostando l’attenzione dall’analisi di semplici correlazioni all’analisi dei processi.\nIn conclusione, la costruzione di modelli dinamici rappresenta un passo verso una psicologia più rigorosa e cumulativa, capace di spiegare i fenomeni invece di limitarsi a descriverli, e di orientare la disciplina verso una vera scienza predittiva dei processi cognitivi e comportamentali.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n\nR version 4.5.1 (2025-06-13)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.6.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] C/UTF-8/C/C/C/C\n\ntime zone: Europe/Zagreb\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.5.1    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.5.1       htmltools_0.5.8.1 rmarkdown_2.29    knitr_1.50       \n [9] jsonlite_2.0.0    xfun_0.53         digest_0.6.37     rlang_1.1.6      \n[13] evaluate_1.0.5",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#bibliografia",
    "href": "chapters/formal_models/01_dynamic_models.html#bibliografia",
    "title": "75  Il modello di revisione degli obiettivi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHayes, S. C., Hofmann, S. G., Stanton, C. E., Carpenter, J. K., Sanford, B. T., Curtiss, J. E., & Ciarrochi, J. (2019). The role of the individual in the coming era of process-based therapy. Behaviour Research and Therapy, 117, 40–53.\n\n\nKnight, E., Neal, A., Palada, H., & Ballard, T. (2023). A Tutorial on Bayesian Modeling of Change Across Time, Individuals, and Groups. Computational Brain & Behavior, 6(4), 697–718.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html",
    "href": "chapters/formal_models/02_dynamic_models.html",
    "title": "76  Estensioni",
    "section": "",
    "text": "Introduzione\nS eguendo la discussione di Knight et al. (2023), in questo capitolo estenderemo il modello di gruppo esaminato nel capitolo precedente in modo da esaminare il modello a livello individuale, nel quale si stima un \\(\\alpha\\) e un \\(\\beta\\) per ogni partecipante. Considereremo poi il modello gerarchico (multilevel), nel quale i parametri individuali sono estratti da una distribuzione comune (ad esempio, una distribuzione normale). Esamineremo infine il modello per gruppi noti, in cui si confrontano i parametri tra le condizioni sperimentali (nel caso presente, il gruppo “approach” vs. il gruppo “avoidance”).",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#introduzione",
    "href": "chapters/formal_models/02_dynamic_models.html#introduzione",
    "title": "76  Estensioni",
    "section": "",
    "text": "Panoramica del capitolo\n\nStima dei parametri a livello individuale (un \\(\\alpha\\) e un \\(\\beta\\) per ogni soggetto).\n\nEstensione gerarchica: parametri individuali come estratti da distribuzioni di popolazione.\n\nInclusione di gruppi noti: confronto dei parametri tra condizioni sperimentali.\n\nConfronto tra modelli tramite ELPD e LOO-CV.\n\nVantaggi dello shrinkage e implicazioni per l’analisi psicologica.\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nsuppressPackageStartupMessages({\n  library(cmdstanr)\n  library(bayesplot)\n  library(tidybayes)\n  library(posterior)\n  library(loo)\n  library(patchwork)\n  library(conflicted)\n})\n\nconflicts_prefer(loo::loo)\nconflicts_prefer(dplyr::count)\n\n\n\n\n\n76.0.1 Modello a livello individuale\nIl modello sample-level stima un unico insieme di parametri \\((\\alpha, \\beta)\\) per l’intero campione, ignorando le differenze individuali. Per cogliere questa eterogeneità, è possibile introdurre il modello a livello individuale (person-level), che stima parametri distinti \\((\\alpha_i, \\beta_i)\\) per ogni partecipante \\(i\\).\nIn questa formulazione:\n\nogni individuo possiede il proprio tasso di apprendimento \\(\\alpha_i\\) e la propria deriva motivazionale \\(\\beta_i\\);\nil parametro \\(\\sigma\\), che cattura la variabilità residua (rumore decisionale), rimane comune a tutti i soggetti.\n\nQuesto approccio consente di:\n\nmappare la variabilità interindividuale nei processi di aggiornamento degli obiettivi;\nidentificare profili comportamentali distinti (es. soggetti molto reattivi al feedback vs. poco adattivi);\nevitare l’assunzione – spesso irrealistica – che tutti i partecipanti rispondano allo stesso modo.\n\nTuttavia, il modello a livello individuale non incorpora alcun meccanismo di “condivisione dell’informazione” tra i soggettii, ma ogni partecipante viene modellato in modo indipendente dagli altri. Questa caratteristica lo distingue dal modello gerarchico (o multilevel), in cui i parametri individuali sono considerati provenienti da una distribuzione di gruppo, il che migliora la robustezza delle stime, soprattutto quando i dati sono limitati o rumorosi.\n\n76.0.2 Preparazione dei dati\n\n# Caricamento del dataset\ndat &lt;- rio::import(\"data/goal_data.csv\")\n\n# Ordina i dati per soggetto e per trial\ndat &lt;- dat |&gt; \n  arrange(subject, trial)\n\n# (Opzionale) Verifica che l'ordinamento sia corretto\nstr(dat)\n#&gt; 'data.frame':    600 obs. of  5 variables:\n#&gt;  $ subject    : int  1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ condition  : chr  \"approach\" \"approach\" \"approach\" \"approach\" ...\n#&gt;  $ goal       : int  2 2 2 4 4 2 2 4 2 4 ...\n#&gt;  $ performance: int  0 2 2 4 2 0 4 2 4 4 ...\n#&gt;  $ trial      : int  1 2 3 4 5 6 7 8 9 10 ...\n\n\ntable(dat$subject)  # restituisce il numero di trial per soggetto\n#&gt; \n#&gt;  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \n#&gt; 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 \n#&gt; 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 \n#&gt; 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 \n#&gt; 53 54 55 56 57 58 59 60 \n#&gt; 10 10 10 10 10 10 10 10\n\n\n# 1) Ordina per soggetto e trial\ndat &lt;- dat %&gt;% arrange(subject, trial)\n\n# 2) Salva scale originali (per eventuale back-transform)\ngoal_mean &lt;- mean(dat$goal, na.rm = TRUE); goal_sd &lt;- sd(dat$goal, na.rm = TRUE)\nperf_mean &lt;- mean(dat$performance, na.rm = TRUE); perf_sd &lt;- sd(dat$performance, na.rm = TRUE)\n\n# 3) Standardizza\ndat &lt;- dat %&gt;%\n  mutate(\n    goal_z = (goal - goal_mean) / goal_sd,\n    perf_z = (performance - perf_mean) / perf_sd\n  )\n\n# 4) Lista per Stan (condition è opzionale qui: non usata nel baseline)\nstan_data &lt;- list(\n  subject       = dat$subject,\n  trial         = dat$trial,\n  observed_goal = dat$goal_z,\n  performance   = dat$perf_z,\n  Nsubj         = dplyr::n_distinct(dat$subject),\n  Ntotal        = nrow(dat)\n)\n\nstr(stan_data)\n#&gt; List of 6\n#&gt;  $ subject      : int [1:600] 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ trial        : int [1:600] 1 2 3 4 5 6 7 8 9 10 ...\n#&gt;  $ observed_goal: num [1:600] -2 -2 -2 -1.07 -1.07 ...\n#&gt;  $ performance  : num [1:600] -2.89 -1.99 -1.99 -1.1 -1.99 ...\n#&gt;  $ Nsubj        : int 60\n#&gt;  $ Ntotal       : int 600\n\n\n76.0.3 Definizione del modello Stan\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=1&gt; Ntotal;                 // es. 600\n  int&lt;lower=1&gt; Nsubj;                  // es. 60\n  array[Ntotal] int&lt;lower=1&gt; subject;  // indice soggetto (1..Nsubj)\n  array[Ntotal] int&lt;lower=1&gt; trial;    // 1..T per ciascun soggetto (ordinati)\n  vector[Ntotal] observed_goal;        // Z-score\n  vector[Ntotal] performance;          // Z-score\n}\n\nparameters {\n  vector[Nsubj] alpha;                 // guadagno per soggetto\n  vector[Nsubj] beta;                  // drift per soggetto\n  real&lt;lower=1e-6&gt; sigma;              // dev. std residua (comune)\n}\n\ntransformed parameters {\n  vector[Ntotal] ghat;                 // traiettoria predetta\n\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      // reset a inizio soggetto: primo stato = prima osservazione\n      ghat[i] = observed_goal[i];\n    } else {\n      int s = subject[i];\n      // ricorsione: usa predizione e performance del trial precedente (stesso soggetto se i dati sono ordinati)\n      ghat[i] = ghat[i - 1]\n                + alpha[s] * (performance[i - 1] - ghat[i - 1])\n                + beta[s];\n    }\n  }\n}\n\nmodel {\n  // Priors semplici coerenti con z-score\n  alpha ~ normal(0, 1);\n  beta  ~ normal(0, 1);\n  sigma ~ normal(0, 1);   // half-normal(1) per via del lower bound\n\n  // Likelihood\n  observed_goal ~ normal(ghat, sigma);\n}\n\ngenerated quantities {\n  vector[Ntotal] yrep;\n  vector[Ntotal] log_lik;\n\n  for (i in 1:Ntotal) {\n    yrep[i]   = normal_rng(ghat[i], sigma);\n    log_lik[i] = normal_lpdf(observed_goal[i] | ghat[i], sigma);\n  }\n}\n\"\n\nQuesto modello presuppone che i dati siano ordinati per soggetto e per trial, altrimenti la dinamica i - 1 non corrisponde al trial precedente dello stesso soggetto.\nEsaminiamo in dettaglio cosa significano alpha[subject[i]] e beta[subject[i]]. Nel modello Stan, ogni trial i è associato a un certo soggetto. Questa informazione è contenuta nel vettore:\narray[Ntotal] int&lt;lower=1&gt; subject;\n\nstan_data$subject\n#&gt;   [1]  1  1  1  1  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  3  3  3  3  3\n#&gt;  [26]  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5\n#&gt;  [51]  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  8  8  8  8  8\n#&gt;  [76]  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9 10 10 10 10 10 10 10 10 10 10\n#&gt; [101] 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13\n#&gt; [126] 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15\n#&gt; [151] 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 18 18 18 18 18\n#&gt; [176] 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19 20 20 20 20 20 20 20 20 20 20\n#&gt; [201] 21 21 21 21 21 21 21 21 21 21 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23\n#&gt; [226] 23 23 23 23 23 24 24 24 24 24 24 24 24 24 24 25 25 25 25 25 25 25 25 25 25\n#&gt; [251] 26 26 26 26 26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 27 28 28 28 28 28\n#&gt; [276] 28 28 28 28 28 29 29 29 29 29 29 29 29 29 29 30 30 30 30 30 30 30 30 30 30\n#&gt; [301] 31 31 31 31 31 31 31 31 31 31 32 32 32 32 32 32 32 32 32 32 33 33 33 33 33\n#&gt; [326] 33 33 33 33 33 34 34 34 34 34 34 34 34 34 34 35 35 35 35 35 35 35 35 35 35\n#&gt; [351] 36 36 36 36 36 36 36 36 36 36 37 37 37 37 37 37 37 37 37 37 38 38 38 38 38\n#&gt; [376] 38 38 38 38 38 39 39 39 39 39 39 39 39 39 39 40 40 40 40 40 40 40 40 40 40\n#&gt; [401] 41 41 41 41 41 41 41 41 41 41 42 42 42 42 42 42 42 42 42 42 43 43 43 43 43\n#&gt; [426] 43 43 43 43 43 44 44 44 44 44 44 44 44 44 44 45 45 45 45 45 45 45 45 45 45\n#&gt; [451] 46 46 46 46 46 46 46 46 46 46 47 47 47 47 47 47 47 47 47 47 48 48 48 48 48\n#&gt; [476] 48 48 48 48 48 49 49 49 49 49 49 49 49 49 49 50 50 50 50 50 50 50 50 50 50\n#&gt; [501] 51 51 51 51 51 51 51 51 51 51 52 52 52 52 52 52 52 52 52 52 53 53 53 53 53\n#&gt; [526] 53 53 53 53 53 54 54 54 54 54 54 54 54 54 54 55 55 55 55 55 55 55 55 55 55\n#&gt; [551] 56 56 56 56 56 56 56 56 56 56 57 57 57 57 57 57 57 57 57 57 58 58 58 58 58\n#&gt; [576] 58 58 58 58 58 59 59 59 59 59 59 59 59 59 59 60 60 60 60 60 60 60 60 60 60\n\nOgni elemento subject[i] ci dice a quale soggetto appartiene il trial i, usando un numero intero da 1 a Nsubj. Quindi se subject[137] == 24, significa che il 137-esimo trial è del soggetto 24.\nOra, se abbiamo un vettore di parametri specifici per ogni soggetto\nvector[Nsubj] alpha;\nvector[Nsubj] beta;\nallora\n\n\nalpha[subject[i]] significa: prendi il valore del parametro alpha associato al soggetto a cui appartiene il trial i;\nlo stesso vale per beta[subject[i]].\n\nPer esempio, supponiamo\nsubject = [1, 1, 1, 2, 2, 3, 3]\nalpha = [0.5, 0.8, 1.1]  // Tre soggetti: 1, 2, 3\nallora\n\n\nalpha[subject[4]] = alpha[2] = 0.8, perché il 4° trial è del soggetto 2.\n\nbeta[subject[6]] = beta[3] = ..., perché il 6° trial è del soggetto 3.\n\nIn sintesi, la sintassi alpha[subject[i]] (e beta[subject[i]]) indica: “Nel trial i, usa il valore del parametro alpha (o beta) del soggetto indicato da subject[i]”. È un modo compatto per associare ogni osservazione ai parametri della persona corrispondente.\n\n76.0.4 Compilazione ed esecuzione del modello\n\nstanmod &lt;- cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n\n\nfit1 &lt;- stanmod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 5000,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 1000,\n  seed = 4790\n)\n\n\n76.0.5 Analisi dei risultati\nQuesto modello genera un insieme di campioni posteriori per i parametri \\(\\alpha\\) e \\(\\beta\\), uno per ciascun partecipante.\nEstrazione dei campioni in formato “draws_matrix” (per summary tabellari):\n\nstandraws &lt;- fit1$draws(format = \"draws_matrix\")\n\nStatistiche descrittive compatte per \\(\\alpha_i\\), \\(\\beta_i\\) e \\(\\sigma\\): media, mediana e intervalli credibili al 95% (2.5% - 97.5%):\n\nstandraws |&gt; \n  subset_draws(variable = c(\"alpha\", \"beta\", \"sigma\")) |&gt; \n  summarise_draws(\n    mean,\n    ~ quantile(.x, probs = c(0.025, 0.5, 0.975))\n  ) |&gt; \n  print()\n#&gt; # A tibble: 121 × 5\n#&gt;    variable   mean `2.5%` `50%` `97.5%`\n#&gt;    &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt;  1 alpha[1]  0.662  0.161 0.683   1.022\n#&gt;  2 alpha[2]  0.181 -0.265 0.178   0.595\n#&gt;  3 alpha[3]  0.167 -0.251 0.186   0.507\n#&gt;  4 alpha[4]  0.300 -0.515 0.303   0.950\n#&gt;  5 alpha[5]  0.400  0.056 0.399   0.744\n#&gt;  6 alpha[6]  0.586 -0.001 0.613   1.043\n#&gt;  7 alpha[7]  0.408  0.121 0.406   0.750\n#&gt;  8 alpha[8]  0.119 -0.077 0.109   0.343\n#&gt;  9 alpha[9]  0.487  0.009 0.487   0.927\n#&gt; 10 alpha[10] 0.811  0.440 0.811   1.109\n#&gt; # ℹ 111 more rows\n\nDiagnostica rapida (Rhat ed ESS):\n\n# Se qualche Rhat &gt; 1.01 o ESS basso, considerare run più lunghi o reparametrizzazioni\nfit1$summary(variables = c(\"alpha\", \"beta\", \"sigma\")) |&gt;\n  dplyr::select(variable, rhat, ess_bulk, ess_tail) |&gt;\n  dplyr::arrange(dplyr::desc(rhat)) |&gt;\n  print(n = 10)\n#&gt; # A tibble: 121 × 4\n#&gt;    variable   rhat ess_bulk ess_tail\n#&gt;    &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 alpha[34] 1.177   14.956   10.927\n#&gt;  2 beta[47]  1.168   15.789   17.071\n#&gt;  3 beta[34]  1.168   15.618   11.197\n#&gt;  4 alpha[47] 1.163   16.778   17.192\n#&gt;  5 beta[46]  1.157   17.028   18.453\n#&gt;  6 beta[56]  1.141   19.034   26.829\n#&gt;  7 alpha[56] 1.141   19.378   43.006\n#&gt;  8 beta[40]  1.124   21.218   71.730\n#&gt;  9 beta[32]  1.122   20.397   22.425\n#&gt; 10 beta[26]  1.120   20.658   27.604\n#&gt; # ℹ 111 more rows\n\nEstrazione “tidy” dei parametri livello-persona con tidybayes::spread_draws. Questo produce le colonne: .draw, subject, alpha, beta.\n\nposteriors_person = spread_draws(fit1, alpha[subject], beta[subject])\n\nCalcolo della media e dell’intervallo credibile al 95% per ciascun soggetto:\n\n# Calcolo media e intervallo credibile al 95% per ciascun soggetto\nCIs_person &lt;- posteriors_person %&gt;%\n  group_by(subject) %&gt;%\n  summarise(\n    across(c(alpha, beta), list(\n      lower = ~quantile(.x, 0.025),\n      mean  = ~mean(.x),\n      upper = ~quantile(.x, 0.975)\n    ), .names = \"{.col}_{.fn}\")\n  ) %&gt;%\n  arrange(alpha_mean) %&gt;%\n  mutate(alpha_order = row_number()) %&gt;%\n  arrange(beta_mean) %&gt;%\n  mutate(beta_order = row_number())\n\nGrafico 1: CI al 95% per \\(\\alpha_i\\), ordinati per alpha_mean:\n\nplot_person_alpha = ggplot(data=CIs_person) +\n  geom_point(aes(y=alpha_order,x=alpha_mean)) +\n  geom_errorbarh(aes(y=alpha_order,xmin=alpha_lower,xmax=alpha_upper),color=\"red\") +\n  labs(x= expression(alpha) ,y=\"Subject\") \n\n\n\n\n\n\n\n\n\nGrafico 2: CI al 95% per \\(\\beta_i\\), ordinati per beta_mean:\n\nplot_person_beta &lt;- ggplot(data = CIs_person) +\n  geom_point(aes(y = beta_order, x = beta_mean)) +\n  geom_errorbarh(aes(y = beta_order, xmin = beta_lower, xmax = beta_upper), color = \"red\") +\n  labs(x = expression(beta), y = \"Subject\") \n\n\n\n\n\n\n\n\n\nGrafico 3: Dispersione bivariata (alpha_mean vs beta_mean) + croci di CI 95%. Le barre (verticali e orizzontali) danno il colpo d’occhio sulla (co)variabilità individuale:\n\nplot_person_alphabeta = ggplot(data=CIs_person) +\n  geom_point(aes(x=alpha_mean,y=beta_mean)) +\n  geom_errorbar(aes(x=alpha_mean,ymin=beta_lower,ymax=beta_upper),color=\"red\",alpha=0.25) +\n  geom_errorbarh(aes(y=beta_mean,xmin=alpha_lower,xmax=alpha_upper),color=\"red\",alpha=0.25) +\n  labs(x= expression(alpha) ,y=expression(beta)) \n\n\n\n\n\n\n\n\n\nI grafici mostrano una marcata eterogeneità tra i partecipanti nei parametri \\(\\alpha\\) (tasso di apprendimento) e \\(\\beta\\) (drift motivazionale), con intervalli credibili al 95% calcolati per ciascun \\(\\alpha_i\\) e \\(\\beta_i\\).\n\n\nPer \\(\\alpha\\): i partecipanti mostrano valori distribuiti lungo quasi tutto l’intervallo [0,1]. Alcuni soggetti hanno \\(\\alpha\\) molto vicino a 0 (poca sensibilità al feedback), mentre altri si avvicinano a 1 (forte aggiornamento in risposta all’errore). L’ampiezza degli intervalli credibili varia, ma nella maggior parte dei casi suggerisce stime sufficientemente informative.\n\nPer \\(\\beta\\): i valori si distribuiscono attorno a 0, ma con differenze individuali marcate: alcuni soggetti mostrano un drift positivo (tendenza ad aumentare sistematicamente gli obiettivi), altri un drift negativo (tendenza a ridurli). Gli intervalli credibili confermano questa eterogeneità.\nIl punto chiave è che questa variabilità non può essere colta dal modello sample-level. Quest’ultimo, stimando un unico \\(\\alpha\\) e un unico \\(\\beta\\) comuni a tutti, restituisce una sorta di “media” del comportamento dei partecipanti. In pratica:\n\nun soggetto con \\(\\alpha \\approx 0\\) e uno con \\(\\alpha \\approx 0.9\\) verrebbero descritti dallo stesso parametro \\(\\alpha\\), che potrebbe cadere a metà strada ma non rappresenta bene né l’uno né l’altro;\nanalogamente, le derive motivazionali individuali \\(\\beta\\) (positive, negative o vicine a zero) verrebbero tutte appiattite su un valore medio.\n\nI grafici dimostrano quindi l’utilità del modello a livello individuale: esso permette di mappare differenze sostanziali tra soggetti, che nel modello a livello di campione vengono perse.\nIn sintesi:\n\nil modello sample-level offre una descrizione parsimoniosa, ma rischia di mascherare differenze psicologicamente importanti;\nil modello person-level mostra che i partecipanti non solo differiscono nel grado di apprendimento dal feedback (\\(\\alpha\\)), ma anche nella direzione e nell’intensità della deriva motivazionale (\\(\\beta\\));\nquesta eterogeneità costituisce un’informazione preziosa per comprendere i profili comportamentali individuali, impossibile da cogliere con un modello che assume parametri omogenei per tutto il campione.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#modello-gerarchico",
    "href": "chapters/formal_models/02_dynamic_models.html#modello-gerarchico",
    "title": "76  Estensioni",
    "section": "\n76.1 Modello gerarchico",
    "text": "76.1 Modello gerarchico\nStimare i parametri per ogni partecipante separatamente (come nel modello a livello individuale) permette di rappresentare le differenze individuali, ma presenta un limite cruciale: le stime rimangono isolate. Analizzare i dati “persona per persona” equivale a condurre un’analisi indipendente per ciascun soggetto, senza “riutilizzare” le informazioni presenti negli altri individui. Ciò riduce il potere statistico, aumenta la variabilità delle stime quando i dati per soggetto sono pochi e rende più difficile trarre conclusioni a livello di popolazione.\nIn molti contesti, però, l’interesse del ricercatore non è solo quello di descrivere le differenze tra gli individui, ma anche di cogliere le regolarità comuni alla popolazione. Per questo motivo, i modelli gerarchici bayesiani (o multilevel) offrono una soluzione particolarmente efficace (Turner et al., 2013; Vincent, 2016; Kruschke & Vanpaemel, 2015).\nL’idea di fondo è semplice:\n\ni parametri individuali (es. \\(\\alpha_s, \\beta_s\\)) sono trattati come variabili casuali, non come quantità del tutto indipendenti;\nciascuno di essi è estratto da una distribuzione a livello di popolazione, descritta da iper-parametri (\\(\\alpha_{\\text{mean}}, \\alpha_{\\text{sd}}\\), ecc.);\nin questo modo, le stime individuali sono “informate” sia dai dati del singolo soggetto sia dalla tendenza generale osservata nel campione (Lewandowsky & Farrell, 2011).\n\nIl risultato è una regolarizzazione: i valori estremi vengono attenuati verso la media di popolazione (shrinkage), riducendo il rischio che stime instabili o rumorose abbiano troppo peso. Si ottengono così inferenze più robuste e interpretabili, specialmente in campioni piccoli o con dati per soggetto limitati (Boehm et al., 2018; Rouder & Lu, 2005).\n\n76.1.1 Definizione del modello Stan\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=1&gt; Ntotal;\n  int&lt;lower=1&gt; Nsubj;\n  array[Ntotal] int&lt;lower=1&gt; subject;\n  array[Ntotal] int&lt;lower=1&gt; trial;\n  vector[Ntotal] observed_goal;   // z-score\n  vector[Ntotal] performance;     // z-score\n}\n\nparameters {\n  // Iper-parametri di popolazione\n  real alpha_mean;\n  real&lt;lower=0&gt; alpha_sd;\n  real beta_mean;\n  real&lt;lower=0&gt; beta_sd;\n\n  // Non-centrato: fattori standard per i soggetti\n  vector[Nsubj] alpha_raw;\n  vector[Nsubj] beta_raw;\n\n  real&lt;lower=1e-6&gt; sigma;\n}\n\ntransformed parameters {\n  // Ricostruzione parametri individuali\n  vector[Nsubj] alpha_unconstrained = alpha_mean + alpha_sd * alpha_raw;\n  vector[Nsubj] beta  = beta_mean  + beta_sd  * beta_raw;\n\n  // Vincolo morbido su alpha per stabilità\n  vector[Nsubj] alpha = 0.95 * tanh(alpha_unconstrained);\n\n  vector[Ntotal] ghat;\n\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      ghat[i] = observed_goal[i];\n    } else {\n      int s = subject[i];\n      ghat[i] = ghat[i - 1]\n                + alpha[s] * (performance[i - 1] - ghat[i - 1])\n                + beta[s];\n    }\n  }\n}\n\nmodel {\n  // Iper-priori debolmente informativi (coerenti con z-score)\n  alpha_mean ~ normal(0, 0.5);\n  alpha_sd   ~ exponential(1);\n  beta_mean  ~ normal(0, 0.5);\n  beta_sd    ~ exponential(1);\n\n  alpha_raw  ~ normal(0, 1);\n  beta_raw   ~ normal(0, 1);\n\n  sigma ~ student_t(3, 0, 0.5);\n\n  // Likelihood\n  observed_goal ~ normal(ghat, sigma);\n}\n\ngenerated quantities {\n  vector[Ntotal] yrep;\n  vector[Ntotal] log_lik;\n  for (i in 1:Ntotal) {\n    yrep[i]    = normal_rng(ghat[i], sigma);\n    log_lik[i] = normal_lpdf(observed_goal[i] | ghat[i], sigma);\n  }\n}\n\"\n\n\n76.1.2 Differenza chiave rispetto al modello precedente\nNel Person-Level Model i parametri individuali sono stimati in modo indipendente; qui, invece, valgono relazioni del tipo:\n\\[\n\\alpha_s \\sim \\mathcal{N}(\\alpha_{\\text{mean}}, \\alpha_{\\text{sd}}), \\quad\n\\beta_s \\sim \\mathcal{N}(\\beta_{\\text{mean}}, \\beta_{\\text{sd}})\n\\]\nQuesta struttura gerarchica introduce un livello di vincolo che collega i soggetti tra loro. Il vantaggio è duplice:\n\nsi mantengono le differenze individuali;\nsi sfrutta la somiglianza tra soggetti per ottenere stime più stabili e inferenze a livello di popolazione.\n\n76.1.3 Compilazione ed esecuzione\n\nstanmod &lt;- cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n\n\nfit2 &lt;- stanmod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4, parallel_chains = 4,\n  seed = 4790,\n  refresh = 500,\n  adapt_delta = 0.995,  # riduce divergenze\n  max_treedepth = 15\n)\n\n\n76.1.4 Analisi dei risultati\nEseguiamo l’analisi dei risultati seguendo lo schema usato sopra.\n\n# Estrazione dei campioni posteriori come matrice \nstandraws &lt;- fit2$draws(format = \"draws_matrix\")\n\n\n# Statistiche descrittive aggregate\nstandraws |&gt; \n  subset_draws(variable = c(\"alpha\", \"beta\", \"sigma\", \"alpha_mean\", \"beta_mean\", \"alpha_sd\", \"beta_sd\")) |&gt; \n  summarise_draws(\n    mean,\n    ~ quantile(.x, probs = c(0.025, 0.5, 0.975))\n  )\n#&gt; # A tibble: 125 × 5\n#&gt;    variable   mean `2.5%` `50%` `97.5%`\n#&gt;    &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt;  1 alpha[1]  0.576  0.292 0.587   0.795\n#&gt;  2 alpha[2]  0.385  0.059 0.393   0.664\n#&gt;  3 alpha[3]  0.320  0.019 0.328   0.582\n#&gt;  4 alpha[4]  0.490  0.145 0.505   0.749\n#&gt;  5 alpha[5]  0.367  0.096 0.371   0.621\n#&gt;  6 alpha[6]  0.552  0.257 0.563   0.775\n#&gt;  7 alpha[7]  0.467  0.215 0.471   0.704\n#&gt;  8 alpha[8]  0.221  0.015 0.216   0.459\n#&gt;  9 alpha[9]  0.510  0.209 0.520   0.754\n#&gt; 10 alpha[10] 0.637  0.425 0.644   0.812\n#&gt; # ℹ 115 more rows\n\n\n# Estrai le draw per i parametri individuali (alpha e beta per ciascun soggetto)\nposteriors_person &lt;- spread_draws(fit2, alpha[subject], beta[subject])\n\n\n# Calcolo degli intervalli credibili per ciascun soggetto\nCIs_person &lt;- posteriors_person %&gt;%\n  group_by(subject) %&gt;%\n  summarise(\n    across(c(alpha, beta), list(\n      lower = ~quantile(.x, 0.025),\n      mean  = ~mean(.x),\n      upper = ~quantile(.x, 0.975)\n    ), .names = \"{.col}_{.fn}\")\n  ) %&gt;%\n  arrange(alpha_mean) %&gt;%\n  mutate(alpha_order = row_number()) %&gt;%\n  arrange(beta_mean) %&gt;%\n  mutate(beta_order = row_number())\n\n\n# Grafico: intervalli credibili per alpha\nplot_person_alpha &lt;- ggplot(CIs_person) +\n  geom_point(aes(y = alpha_order, x = alpha_mean)) +\n  geom_errorbarh(aes(y = alpha_order, xmin = alpha_lower, xmax = alpha_upper), color = \"red\") +\n  labs(x = expression(alpha), y = \"Soggetto\") \n\n# Grafico: intervalli credibili per beta\nplot_person_beta &lt;- ggplot(CIs_person) +\n  geom_point(aes(y = beta_order, x = beta_mean)) +\n  geom_errorbarh(aes(y = beta_order, xmin = beta_lower, xmax = beta_upper), color = \"red\") +\n  labs(x = expression(beta), y = \"Soggetto\") \n\n# Grafico: relazione tra alpha e beta per ciascun soggetto\nplot_person_alphabeta &lt;- ggplot(CIs_person) +\n  geom_point(aes(x = alpha_mean, y = beta_mean)) +\n  geom_errorbar(aes(x = alpha_mean, ymin = beta_lower, ymax = beta_upper), color = \"red\", alpha = 0.25) +\n  geom_errorbarh(aes(y = beta_mean, xmin = alpha_lower, xmax = alpha_upper), color = \"red\", alpha = 0.25) +\n  labs(x = expression(alpha), y = expression(beta)) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInfine, calcoliamo le stime a posteriori degli iper-parametri:\n\n# Riassunto per alpha_mean e beta_mean con intervallo al 95%\nstandraws |&gt;\n  subset_draws(variable = c(\"alpha_mean\", \"beta_mean\")) |&gt;\n  summarise_draws(\n    mean,\n    ~quantile(.x, probs = c(0.025, 0.975))\n  )\n#&gt; # A tibble: 2 × 4\n#&gt;   variable    mean `2.5%` `97.5%`\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 alpha_mean 0.621  0.521   0.732\n#&gt; 2 beta_mean  0.114  0.049   0.176\n\n\n76.1.4.1 Interpretazione\nIl modello gerarchico bayesiano fornisce inferenze a due livelli:\n\n\nLivello individuale: parametri \\(\\alpha_s\\) e \\(\\beta_s\\) per ciascun partecipante, con i relativi intervalli credibili.\n\nLivello di popolazione: distribuzioni a priori/posteriori degli iper-parametri \\(\\alpha_{\\text{mean}}, \\alpha_{\\text{sd}}, \\beta_{\\text{mean}}, \\beta_{\\text{sd}}\\), più il parametro residuo \\(\\sigma\\).\n\nI grafici per \\(\\alpha\\) e \\(\\beta\\) mostrano chiaramente l’eterogeneità interindividuale, mentre gli iper-parametri descrivono la tendenza generale.\nRispetto a un modello puramente individuale, gli intervalli credibili delle stime soggettive risultano meno dispersi e più regolari. Questo fenomeno è noto come shrinkage: le stime dei singoli soggetti sono “attirate” verso la media della popolazione, riducendo l’impatto dei dati rumorosi o scarsi.\nNel grafico bivariato, lo shrinkage si traduce in una distribuzione più compatta dei punti attorno al centro della distribuzione collettiva. L’effetto principale è una maggiore robustezza delle inferenze: le stime estreme vengono mitigate, la variabilità non plausibile è penalizzata e la capacità di generalizzare a nuovi dati risulta rafforzata (Boehm et al., 2018).",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#differenze-tra-gruppi",
    "href": "chapters/formal_models/02_dynamic_models.html#differenze-tra-gruppi",
    "title": "76  Estensioni",
    "section": "\n76.2 Differenze tra gruppi",
    "text": "76.2 Differenze tra gruppi\nIn questo terzo modello estendiamo la struttura gerarchica introducendo le condizioni sperimentali (approach vs avoidance). L’idea è che i parametri individuali \\(\\alpha_s\\) e \\(\\beta_s\\) non siano estratti da un’unica distribuzione comune, ma da distribuzioni diverse a seconda del gruppo di appartenenza del soggetto.\nIn questo modo possiamo stimare, per ciascuna condizione, una media e una deviazione standard a livello di popolazione:\n\n\n\\(\\alpha_{\\text{mean},c}, \\alpha_{\\text{sd},c}\\),\n\n\\(\\beta_{\\text{mean},c}, \\beta_{\\text{sd},c}\\) con \\(c \\in \\{1,2\\}\\).\n\n\n76.2.1 Preparazione dei dati\n\n# 1) Ordina per soggetto e trial\ndat &lt;- dat %&gt;% arrange(subject, trial)\n\n# 2) Codifica la condizione come intero (1 = approach, 2 = avoidance)\ndat &lt;- dat %&gt;%\n  mutate(cond_id = as.integer(factor(condition)))\n\n# Verifica che ogni soggetto appartenga a una sola condizione\nchk &lt;- dat %&gt;% distinct(subject, cond_id) %&gt;% count(subject) %&gt;% filter(n &gt; 1)\nstopifnot(nrow(chk) == 0)  # se fallisce, il design non è between-subject\n\n# 3) Standardizza goal e performance su tutto il dataset\ngoal_mean &lt;- mean(dat$goal, na.rm = TRUE); goal_sd &lt;- sd(dat$goal, na.rm = TRUE)\nperf_mean &lt;- mean(dat$performance, na.rm = TRUE); perf_sd &lt;- sd(dat$performance, na.rm = TRUE)\n\ndat &lt;- dat %&gt;%\n  mutate(\n    goal_z = (goal - goal_mean) / goal_sd,\n    perf_z = (performance - perf_mean) / perf_sd\n  )\n\n# 4) Vettore che assegna a ciascun soggetto la sua condizione\nsubjects &lt;- sort(unique(dat$subject))\nsubj_cond &lt;- dat %&gt;%\n  group_by(subject) %&gt;%\n  summarise(cond = first(cond_id), .groups = \"drop\") %&gt;%\n  arrange(subject) %&gt;%\n  pull(cond)\n\n# 5) Lista per Stan\nstan_data &lt;- list(\n  Ntotal        = nrow(dat),\n  Nsubj         = length(subjects),\n  C             = length(unique(dat$cond_id)),   # numero condizioni\n  subject       = dat$subject,\n  trial         = dat$trial,\n  observed_goal = dat$goal_z,\n  performance   = dat$perf_z,\n  subj_cond     = subj_cond\n)\n\nstr(stan_data)\n#&gt; List of 8\n#&gt;  $ Ntotal       : int 600\n#&gt;  $ Nsubj        : int 60\n#&gt;  $ C            : int 2\n#&gt;  $ subject      : int [1:600] 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ trial        : int [1:600] 1 2 3 4 5 6 7 8 9 10 ...\n#&gt;  $ observed_goal: num [1:600] -2 -2 -2 -1.07 -1.07 ...\n#&gt;  $ performance  : num [1:600] -2.89 -1.99 -1.99 -1.1 -1.99 ...\n#&gt;  $ subj_cond    : int [1:60] 1 2 2 1 2 1 2 1 2 1 ...\n\n\n76.2.2 Definizione del modello Stan\n\nstancode &lt;- \"\n// Modello gerarchico con iper-parametri specifici per condizione\ndata {\n  int&lt;lower=1&gt; Ntotal;\n  int&lt;lower=1&gt; Nsubj;\n  int&lt;lower=1&gt; C;                            // numero condizioni\n  array[Ntotal] int&lt;lower=1&gt; subject;        // 1..Nsubj\n  array[Ntotal] int&lt;lower=1&gt; trial;          // 1..T all'interno di soggetto\n  vector[Ntotal] observed_goal;              // z-score\n  vector[Ntotal] performance;                // z-score\n  array[Nsubj] int&lt;lower=1, upper=C&gt; subj_cond; // condizione per soggetto\n}\n\nparameters {\n  // Iper-parametri per condizione\n  vector[C] alpha_mean;\n  vector&lt;lower=0&gt;[C] alpha_sd;\n  vector[C] beta_mean;\n  vector&lt;lower=0&gt;[C] beta_sd;\n\n  // Non-centrato: fattori standard per soggetti\n  vector[Nsubj] alpha_raw;\n  vector[Nsubj] beta_raw;\n\n  real&lt;lower=1e-6&gt; sigma;\n}\n\ntransformed parameters {\n  vector[Nsubj] alpha_uncon;\n  vector[Nsubj] beta;\n  vector[Nsubj] alpha;           \n  vector[Ntotal] ghat;\n\n  // Ricostruzione dei parametri individuali in base alla condizione\n  for (s in 1:Nsubj) {\n    int c = subj_cond[s];\n    alpha_uncon[s] = alpha_mean[c] + alpha_sd[c] * alpha_raw[s];\n    beta[s]        = beta_mean[c]  + beta_sd[c]  * beta_raw[s];\n    alpha[s]       = 0.95 * tanh(alpha_uncon[s]); // vincolo di stabilità\n  }\n\n  // Dinamica\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      ghat[i] = observed_goal[i];\n    } else {\n      int s = subject[i];\n      ghat[i] = ghat[i - 1]\n                + alpha[s] * (performance[i - 1] - ghat[i - 1])\n                + beta[s];\n    }\n  }\n}\n\nmodel {\n  // Iper-priori debolmente informativi\n  alpha_mean ~ normal(0, 0.5);\n  alpha_sd   ~ exponential(1);\n  beta_mean  ~ normal(0, 0.5);\n  beta_sd    ~ exponential(1);\n\n  alpha_raw  ~ normal(0, 1);\n  beta_raw   ~ normal(0, 1);\n\n  sigma ~ student_t(3, 0, 0.5);\n\n  // Likelihood\n  observed_goal ~ normal(ghat, sigma);\n}\n\ngenerated quantities {\n  vector[Ntotal] yrep;\n  vector[Ntotal] log_lik;\n  for (i in 1:Ntotal) {\n    yrep[i]    = normal_rng(ghat[i], sigma);\n    log_lik[i] = normal_lpdf(observed_goal[i] | ghat[i], sigma);\n  }\n}\n\"\n\n\n76.2.3 Come funziona la distinzione tra gruppi\n\nAssegnazione condizione Nel blocco data, il vettore subj_cond assegna a ciascun soggetto il numero della condizione (1 = approach, 2 = avoidance).\n\nParametri di gruppo Gli iper-parametri alpha_mean[c], alpha_sd[c], beta_mean[c], beta_sd[c] sono specifici per condizione. Ad esempio:\n\n\nalpha_mean[1] = media di \\(\\alpha\\) per il gruppo approach\n\n\nalpha_mean[2] = media di \\(\\alpha\\) per il gruppo avoidance\n\n\n\nParametri individuali In transformed parameters, i parametri dei singoli soggetti vengono generati in base alla condizione di appartenenza. Così, i soggetti approach e quelli avoidance condividono rispettivamente due diverse distribuzioni di partenza.\n\nIn sintesi, il modello permette di stimare non solo le differenze tra individui, ma anche le differenze sistematiche tra condizioni sperimentali.\n\n76.2.4 Compilazione ed esecuzione\n\nstanmod &lt;- cmdstan_model(write_stan_file(stancode), compile = TRUE)\n\n\nfit3 &lt;- stanmod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 5000,\n  chains = 4, parallel_chains = 4,\n  seed = 123,\n  adapt_delta = 0.999,   # ↑ riduce divergenze\n  max_treedepth = 15\n)\n\n\n76.2.5 Risultati\n\n76.2.5.1 Ispezione rapida delle variabili (opzionale)\n\ndraws_df &lt;- as_draws_df(fit3$draws())   # oppure: fit3$draws(format = \"df\")\nnames(draws_df)[grepl(\"alpha_mean|beta_mean|alpha\\\\[|beta\\\\[\", names(draws_df))]\n#&gt;   [1] \"alpha_mean[1]\" \"alpha_mean[2]\" \"beta_mean[1]\"  \"beta_mean[2]\" \n#&gt;   [5] \"beta[1]\"       \"beta[2]\"       \"beta[3]\"       \"beta[4]\"      \n#&gt;   [9] \"beta[5]\"       \"beta[6]\"       \"beta[7]\"       \"beta[8]\"      \n#&gt;  [13] \"beta[9]\"       \"beta[10]\"      \"beta[11]\"      \"beta[12]\"     \n#&gt;  [17] \"beta[13]\"      \"beta[14]\"      \"beta[15]\"      \"beta[16]\"     \n#&gt;  [21] \"beta[17]\"      \"beta[18]\"      \"beta[19]\"      \"beta[20]\"     \n#&gt;  [25] \"beta[21]\"      \"beta[22]\"      \"beta[23]\"      \"beta[24]\"     \n#&gt;  [29] \"beta[25]\"      \"beta[26]\"      \"beta[27]\"      \"beta[28]\"     \n#&gt;  [33] \"beta[29]\"      \"beta[30]\"      \"beta[31]\"      \"beta[32]\"     \n#&gt;  [37] \"beta[33]\"      \"beta[34]\"      \"beta[35]\"      \"beta[36]\"     \n#&gt;  [41] \"beta[37]\"      \"beta[38]\"      \"beta[39]\"      \"beta[40]\"     \n#&gt;  [45] \"beta[41]\"      \"beta[42]\"      \"beta[43]\"      \"beta[44]\"     \n#&gt;  [49] \"beta[45]\"      \"beta[46]\"      \"beta[47]\"      \"beta[48]\"     \n#&gt;  [53] \"beta[49]\"      \"beta[50]\"      \"beta[51]\"      \"beta[52]\"     \n#&gt;  [57] \"beta[53]\"      \"beta[54]\"      \"beta[55]\"      \"beta[56]\"     \n#&gt;  [61] \"beta[57]\"      \"beta[58]\"      \"beta[59]\"      \"beta[60]\"     \n#&gt;  [65] \"alpha[1]\"      \"alpha[2]\"      \"alpha[3]\"      \"alpha[4]\"     \n#&gt;  [69] \"alpha[5]\"      \"alpha[6]\"      \"alpha[7]\"      \"alpha[8]\"     \n#&gt;  [73] \"alpha[9]\"      \"alpha[10]\"     \"alpha[11]\"     \"alpha[12]\"    \n#&gt;  [77] \"alpha[13]\"     \"alpha[14]\"     \"alpha[15]\"     \"alpha[16]\"    \n#&gt;  [81] \"alpha[17]\"     \"alpha[18]\"     \"alpha[19]\"     \"alpha[20]\"    \n#&gt;  [85] \"alpha[21]\"     \"alpha[22]\"     \"alpha[23]\"     \"alpha[24]\"    \n#&gt;  [89] \"alpha[25]\"     \"alpha[26]\"     \"alpha[27]\"     \"alpha[28]\"    \n#&gt;  [93] \"alpha[29]\"     \"alpha[30]\"     \"alpha[31]\"     \"alpha[32]\"    \n#&gt;  [97] \"alpha[33]\"     \"alpha[34]\"     \"alpha[35]\"     \"alpha[36]\"    \n#&gt; [101] \"alpha[37]\"     \"alpha[38]\"     \"alpha[39]\"     \"alpha[40]\"    \n#&gt; [105] \"alpha[41]\"     \"alpha[42]\"     \"alpha[43]\"     \"alpha[44]\"    \n#&gt; [109] \"alpha[45]\"     \"alpha[46]\"     \"alpha[47]\"     \"alpha[48]\"    \n#&gt; [113] \"alpha[49]\"     \"alpha[50]\"     \"alpha[51]\"     \"alpha[52]\"    \n#&gt; [117] \"alpha[53]\"     \"alpha[54]\"     \"alpha[55]\"     \"alpha[56]\"    \n#&gt; [121] \"alpha[57]\"     \"alpha[58]\"     \"alpha[59]\"     \"alpha[60]\"\n\n\n76.2.5.2 Differenze tra condizioni sugli iper-parametri\nL’obiettivo è verificare se i parametri di popolazione \\(\\alpha\\) (tasso di aggiornamento) e \\(\\beta\\) (drift/tendenza) differiscono tra le due condizioni sperimentali (approach vs avoidance). Per rispondere a questa domanda procediamo in quattro passaggi:\n1. recuperiamo le etichette delle condizioni dal dataset;\n2. calcoliamo il contrasto tra condizioni (\\(\\Delta =\\) condizione\\(_2\\) − condizione\\(_1\\));\n3. stimiamo la media della differenza, il 95% CrI e la probabilità a posteriori che la differenza sia negativa;\n4. visualizziamo i risultati per facilitarne l’interpretazione.\n\n76.2.5.2.1 Step 1. Etichette di condizione\n\ncond_labels &lt;- dat %&gt;%\n  distinct(cond_id, condition) %&gt;%\n  arrange(cond_id) %&gt;%\n  pull(condition)\n\ncond_labels\n#&gt; [1] \"approach\"  \"avoidance\"\n# Esempio: c(\"approach\", \"avoidance\")\n\n\n76.2.5.2.2 Step 2. Contrasto su α (media per condizione)\nCalcoliamo \\(\\Delta_\\alpha = \\alpha_{\\text{avoidance}} - \\alpha_{\\text{approach}}\\).\n\ndelta_alpha &lt;- fit3 |&gt;\n  spread_draws(alpha_mean[cond]) |&gt;\n  mutate(cond = factor(cond, levels = 1:2, labels = cond_labels)) |&gt;\n  pivot_wider(names_from = cond, values_from = alpha_mean, names_prefix = \"alpha_mean_\") |&gt;\n  mutate(delta_alpha_mean = alpha_mean_avoidance - alpha_mean_approach)\n\ndelta_alpha |&gt; \n  summarise(\n    mean   = mean(delta_alpha_mean),\n    low95  = quantile(delta_alpha_mean, 0.025),\n    upp95  = quantile(delta_alpha_mean, 0.975),\n    p_lt0  = mean(delta_alpha_mean &lt; 0)\n  )\n#&gt; # A tibble: 1 × 4\n#&gt;     mean  low95   upp95 p_lt0\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 -0.247 -0.481 -0.0349 0.989\n\n\n76.2.5.2.3 Step 3. Contrasto su β (media per condizione)\nIn modo analogo, calcoliamo \\(\\Delta_\\beta = \\beta_{\\text{avoidance}} - \\beta_{\\text{approach}}\\).\n\ndelta_beta &lt;- fit3 |&gt;\n  spread_draws(beta_mean[cond]) |&gt;\n  mutate(cond = factor(cond, levels = 1:2, labels = cond_labels)) |&gt;\n  pivot_wider(names_from = cond, values_from = beta_mean, names_prefix = \"beta_mean_\") |&gt;\n  mutate(delta_beta_mean = beta_mean_avoidance - beta_mean_approach)\n\ndelta_beta |&gt; \n  summarise(\n    mean   = mean(delta_beta_mean),\n    low95  = quantile(delta_beta_mean, 0.025),\n    upp95  = quantile(delta_beta_mean, 0.975),\n    p_lt0  = mean(delta_beta_mean &lt; 0)\n  )\n#&gt; # A tibble: 1 × 4\n#&gt;     mean  low95   upp95 p_lt0\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 -0.126 -0.251 0.00152 0.974\n\n\n76.2.5.2.4 Step 4. Visualizzazione delle posterior\n\npost_alpha &lt;- fit3 |&gt;\n  spread_draws(alpha_mean[cond]) |&gt;\n  mutate(parameter = \"alpha_mean\",\n         condition = factor(cond, levels = 1:2, labels = cond_labels)) |&gt;\n  rename(value = alpha_mean)\n\npost_beta &lt;- fit3 |&gt;\n  spread_draws(beta_mean[cond]) |&gt;\n  mutate(parameter = \"beta_mean\",\n         condition = factor(cond, levels = 1:2, labels = cond_labels)) |&gt;\n  rename(value = beta_mean)\n\nposterior_both &lt;- bind_rows(post_alpha, post_beta)\n\nggplot(posterior_both, aes(x = value, fill = condition)) +\n  geom_density(alpha = 0.6) +\n  facet_wrap(~parameter, scales = \"free\") +\n  labs(x = \"Posterior mean\", y = \"Density\", fill = \"Condition\") +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n76.2.5.2.5 Risultati numerici\n\nprob_delta_alpha_neg &lt;- mean(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]` &lt; 0)\nprob_delta_beta_neg  &lt;- mean(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]` &lt; 0)\n\ncat(\"P(delta_alpha_mean &lt; 0):\", round(prob_delta_alpha_neg, 3), \"\\n\")\n#&gt; P(delta_alpha_mean &lt; 0): 0.989\ncat(\"P(delta_beta_mean &lt; 0):\", round(prob_delta_beta_neg, 3), \"\\n\")\n#&gt; P(delta_beta_mean &lt; 0): 0.974\n\nsummary_df &lt;- tibble(\n  parameter = c(\"alpha_mean\", \"beta_mean\"),\n  delta_mean = c(\n    mean(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`),\n    mean(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`)\n  ),\n  lower_95 = c(\n    quantile(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`, 0.025),\n    quantile(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`, 0.025)\n  ),\n  upper_95 = c(\n    quantile(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`, 0.975),\n    quantile(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`, 0.975)\n  ),\n  prob_below_0 = c(prob_delta_alpha_neg, prob_delta_beta_neg)\n)\n\nsummary_df\n#&gt; # A tibble: 2 × 5\n#&gt;   parameter  delta_mean lower_95 upper_95 prob_below_0\n#&gt;   &lt;chr&gt;           &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n#&gt; 1 alpha_mean     -0.247   -0.481 -0.0349         0.989\n#&gt; 2 beta_mean      -0.126   -0.251  0.00152        0.974\n\n\nsummary_df |&gt; \n  ggplot(aes(x = parameter, y = delta_mean)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\", width = 0.5) +\n  geom_errorbar(aes(ymin = lower_95, ymax = upper_95), width = 0.2) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(\n    x = \"Parametro\",\n    y = \"Differenza media\\n(cond2 - cond1)\"\n  )\n\n\n\n\n\n\n\n\n76.2.5.2.6 Interpretazione dei risultati\n\n\\(\\Delta_\\alpha\\) (avoidance − approach) Media = −0.247; CrI 95% = [−0.481, −0.035]; \\(P(\\Delta&lt;0) = 0.989\\). → Evidenza forte che l’aggiornamento (\\(\\alpha\\)) è più basso in avoidance. L’effetto è moderato (≈0.25 SD).\n\\(\\Delta_\\beta\\) (avoidance − approach) Media = −0.126; CrI 95% = [−0.251, 0.002]; \\(P(\\Delta&lt;0) = 0.974\\). → La probabilità che \\(\\beta\\) sia più basso in avoidance è elevata, ma l’intervallo credibile include lo zero. Evidenza suggestiva ma non conclusiva.\n\n76.2.5.2.7 Significato sostantivo\n\nIn avoidance, i partecipanti aggiornano più lentamente le loro credenze (α più basso).\nAnche la tendenza (β) appare più bassa, ma con incertezza residua.\n\nQuesti risultati indicano che la manipolazione sperimentale ha un impatto soprattutto sulla velocità di apprendimento, mentre l’effetto sulla componente di drift resta da confermare con più dati o modelli più sensibili.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#confronto-tra-modelli",
    "href": "chapters/formal_models/02_dynamic_models.html#confronto-tra-modelli",
    "title": "76  Estensioni",
    "section": "\n76.3 Confronto tra modelli",
    "text": "76.3 Confronto tra modelli\nPer valutare quale modello descriva meglio i dati abbiamo utilizzato la cross-validazione leave-one-out (LOO-CV), che stima la expected log predictive density (ELPD). Un ELPD più alto indica predizioni più accurate.\n\nlog_lik1 &lt;- fit1$draws(variables = \"log_lik\", format = \"matrix\")\nlog_lik2 &lt;- fit2$draws(variables = \"log_lik\", format = \"matrix\")\nlog_lik3 &lt;- fit3$draws(variables = \"log_lik\", format = \"matrix\")\n\n# Calcola LOO per ciascun modello\nloo1 &lt;- loo(log_lik1)\nloo2 &lt;- loo(log_lik2)\nloo3 &lt;- loo(log_lik3)\n\n# Confronto tra i modelli\nmodel_comparison &lt;- loo_compare(loo1, loo2, loo3)\nprint(model_comparison)\n#&gt;        elpd_diff se_diff\n#&gt; model3   0.0       0.0  \n#&gt; model2  -4.7       3.9  \n#&gt; model1 -23.2       7.6\n\nIl modello gerarchico con condizione (Model 3) ottiene la predizione migliore. Tuttavia, il confronto con il modello gerarchico senza condizione (Model 2) mostra una differenza di ELPD pari a −4.7, con un errore standard di 3.9. Questa differenza è piccola rispetto all’incertezza della stima, quindi non possiamo affermare con sicurezza che includere la condizione migliori la predizione, anche se la tendenza è in quella direzione.\nDiverso il discorso per il modello non gerarchico (Model 1): la perdita di ELPD rispetto a Model 3 è molto ampia (−23.3, con SE = 7.6). In questo caso la differenza è sufficientemente grande da concludere che Model 1 produce predizioni nettamente peggiori.\n\n76.3.0.1 Cosa impariamo\n\nLa gerarchia è cruciale: i modelli gerarchici (Model 2 e 3) descrivono i dati molto meglio del modello non gerarchico. Questo conferma l’importanza di “condividere informazione” tra soggetti per ottenere stime più stabili e predizioni più accurate.\nL’effetto della condizione è plausibile, ma non certo: il modello con condizione (Model 3) tende a comportarsi meglio, ma il vantaggio rispetto al modello gerarchico semplice (Model 2) non è statisticamente robusto. Questo risultato è coerente con le stime dei parametri: la differenza tra condizioni sembra più marcata per \\(\\alpha\\), meno per \\(\\beta\\).\n\nScelta del modello:\n\nse l’obiettivo principale è la parsimonia, Model 2 è già soddisfacente;\nse vogliamo testare esplicitamente l’effetto della condizione, Model 3 è preferibile, anche se il guadagno predittivo rimane incerto.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#riflessioni-conclusive",
    "href": "chapters/formal_models/02_dynamic_models.html#riflessioni-conclusive",
    "title": "76  Estensioni",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo esplorato tre approcci bayesiani progressivamente più sofisticati per modellare l’aggiornamento degli obiettivi, dimostrando come l’aumento controllato della complessità strutturale possa arricchire significativamente l’analisi psicologica. Il percorso è partito da un modello individuale semplice, per passare a una struttura gerarchica che capitalizza le similarità tra partecipanti, fino ad arrivare a un framework che incorpora esplicitamente le differenze tra condizioni sperimentali.\nL’analisi comparativa ha evidenziato come la struttura gerarchica offra vantaggi sostanziali in termini di capacità predittiva, come confermato dai valori ELPD. Questo approccio implementa efficacemente il principio dello shrinkage, stabilizzando le stime soprattutto quando i dati per singolo soggetto sono limitati - situazione frequente nella ricerca psicologica.\nUn risultato particolarmente interessante emerge dal modello con gruppi sperimentali, che ha permesso di quantificare le differenze sistematiche nei parametri cognitivi tra condizioni. Sebbene questi effetti non raggiungano la significatività statistica convenzionale, le probabilità a posteriori superiori al 96% forniscono un supporto quantificabile alle ipotesi direzionali, mostrando la potenza dell’inferenza bayesiana nel cogliere sfumature spesso trascurate dai metodi frequentisti.\nDal punto di vista metodologico, questo percorso dimostra l’importanza di:\n\nprogettare strutture modellistiche che riflettano accuratamente le dipendenze naturali tra le osservazioni;\nincorporare sistematicamente le informazioni sperimentali nei livelli iperparametrici;\nbilanciare complessità e generalizzazione attraverso confronti basati su evidenza predittiva.\n\nIl modello presentato in questo capitolo è uno strumento potente e flessibile per studiare come le persone modificano il propri comportamenti nel tempo, come tali comportamenti variano da individuo a individuo, e come ciascuno reagisce a diverse condizioni sperimentali. Sebbene la sua formalizzazione possa apparire tecnica, l’idea di base è intuitiva: utilizziamo metodi statistici avanzati per descrivere in modo più realistico i processi di apprendimento e adattamento.\nLe tecniche illustrate forniscono le basi per affrontare problemi ancora più complessi. Un’estensione particolarmente utile è rappresentata dai modelli di miscela (mixture models), che permettono di identificare automaticamente gruppi di partecipanti con comportamenti simili, senza dover definire queste categorie in anticipo (un’illustrazione è fornita nel tutorial di Knight et al., 2023).\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.4.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] R.utils_2.13.0        Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [46] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [49] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [52] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [55] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [58] rstantools_2.4.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [61] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [64] data.table_1.17.8     mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [67] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [70] cli_3.6.5             textshaping_1.0.1     svUnit_1.0.8         \n#&gt; [73] Brobdingnag_1.2-9     V8_6.0.6              gtable_0.3.6         \n#&gt; [76] R.methodsS3_1.8.2     digest_0.6.37         TH.data_1.1-3        \n#&gt; [79] htmlwidgets_1.6.4     farver_2.1.2          R.oo_1.27.1          \n#&gt; [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#bibliografia",
    "href": "chapters/formal_models/02_dynamic_models.html#bibliografia",
    "title": "76  Estensioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKnight, E., Neal, A., Palada, H., & Ballard, T. (2023). A Tutorial on Bayesian Modeling of Change Across Time, Individuals, and Groups. Computational Brain & Behavior, 6(4), 697–718.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html",
    "href": "chapters/formal_models/03_rescorla_wagner.html",
    "title": "77  Il modello di Rescorla–Wagner",
    "section": "",
    "text": "Introduzione\nQ uesto capitolo introduce il modello di Rescorla–Wagner (RW) con regola di scelta Softmax (Rescorla & Wagner, 1972). Si tratta di un’estensione naturale del modello di revisione degli obiettivi discusso nel capitolo precedente. In quel modello, l’aggiornamento dell’obiettivo era un semplice termine additivo: ad ogni trial, la stima veniva spostata un po’ più vicino al valore osservato, con un ritmo determinato dal parametro di apprendimento. Nel modello di Rescorla–Wagner, invece, l’aggiornamento è guidato dall’errore di predizione del rinforzo (reward prediction error, RPE), ovvero la differenza tra il rinforzo ottenuto e quello atteso. Questo rende il modello più psicologicamente plausibile, perché riflette il meccanismo di apprendimento osservato in numerosi studi di psicologia e neuroscienze, nei quali le nuove informazioni vengono integrate in proporzione alla discrepanza tra risultato ed aspettative.\nPer completare il quadro, al processo di apprendimento si affianca un livello decisionale: le scelte non seguono meccanicamente l’opzione con il valore più alto, ma riflettono un bilanciamento tra due tendenze opposte, ovvero l’esplorazione di alternative nuove e lo sfruttamento delle opzioni già note come vantaggiose. In questo modo, il modello integra esplicitamente due componenti distinte ma interconnesse:\nQuesta distinzione permette di analizzare il comportamento in modo più ricco e realistico, separando i meccanismi che riguardano l’aggiornamento delle conoscenze da quelli che regolano le decisioni concrete.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#introduzione",
    "href": "chapters/formal_models/03_rescorla_wagner.html#introduzione",
    "title": "77  Il modello di Rescorla–Wagner",
    "section": "",
    "text": "Apprendimento: come le aspettative si aggiornano in base all’esperienza;\n\nDecisione: come queste aspettative vengono trasformate in probabilità di scelta, tenendo conto del compromesso tra esplorazione e sfruttamento.\n\n\n\n\n\n\n\n\nPreparazione del Notebook",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#il-modello-di-rescorlawagner",
    "href": "chapters/formal_models/03_rescorla_wagner.html#il-modello-di-rescorlawagner",
    "title": "77  Il modello di Rescorla–Wagner",
    "section": "\n77.1 Il Modello di Rescorla–Wagner",
    "text": "77.1 Il Modello di Rescorla–Wagner\nIl modello di Rescorla–Wagner (RW) è uno dei modelli più influenti nello studio dell’apprendimento associativo. Esso descrive come gli individui aggiornino le proprie aspettative in base all’esperienza, introducendo un meccanismo semplice ma potente che spiega fenomeni come acquisizione, estinzione e blocking.\nL’idea di fondo è che l’apprendimento si realizzi attraverso l’aggiornamento della forza associativa \\(Q_t(s)\\) di uno stimolo \\(s\\) al tempo \\(t\\), in funzione della discrepanza tra ciò che ci si aspettava e ciò che si è effettivamente osservato.\n\n77.1.1 Aggiornamento delle aspettative\nDopo ogni prova, la stima del valore viene modificata secondo la regola:\n\\[\nQ_{t+1}(s) \\;=\\; Q_t(s) \\;+\\; \\alpha \\, \\delta_t ,\n\\] dove\n\\[\n\\delta_t \\;=\\; R_t - Q_t(s)\n\\] è l’errore di previsione (prediction error), cioè la differenza tra la ricompensa ottenuta \\(R_t\\) e l’aspettativa precedente \\(Q_t(s)\\).\n\nSe \\(\\delta_t &gt; 0\\): la ricompensa è stata migliore del previsto → l’associazione si rafforza.\nSe \\(\\delta_t &lt; 0\\): la ricompensa è stata peggiore del previsto → l’associazione si indebolisce.\nSe \\(\\delta_t = 0\\): ciò che si è osservato coincide con l’attesa → nessun aggiornamento.\n\nIl parametro $ $ rappresenta il tasso di apprendimento (qui lo indichiamo con lr). Con lr alto l’aggiornamento è rapido; con lr basso è lento e più “conservativo”.\n\n\n\n\n\n\nVariante (facoltativa): tassi distinti per PE positivo/negativo\n\n\n\n\n\nIn alcune applicazioni si usano due tassi distinti \\(\\alpha^+\\) e \\(\\alpha^-\\) per apprendere diversamente da buone e cattive notizie. Questa distinzione consente di modellare la diversa sensibilità di individui o gruppi alle ricompense inattese rispetto alle punizioni o ai premi. Nel presente tutorial adottiamo un unico lr per semplicità e coerenza con il codice Stan.\n\n\n\n\n77.1.2 Dalla valutazione alla decisione\nAvere valori \\(Q_t(A)\\) e \\(Q_t(B)\\) diversi non implica che la scelta sia sempre deterministica. Gli individui possono alternare tra sfruttamento (scegliere l’opzione con valore atteso maggiore) ed esplorazione (provare opzioni alternative).\nCon due opzioni (A, B), la scelta è modellata come logistica della differenza di valore:\n\\[\nP(\\text{scegliere B}) = \\text{inv\\_logit}\\!\\big(\\tau \\,[Q_t(B)-Q_t(A)]\\big).\n\\] All’aumentare di \\(\\tau\\), anche piccole differenze \\(Q_t(B)-Q_t(A)\\) producono scelte quasi deterministiche; con \\(\\tau\\) bassa il comportamento è più esplorativo.\nIn sintesi, il modello di Rescorla–Wagner fornisce una descrizione formale e compatta di come gli individui apprendono in modo flessibile dalle proprie esperienze, adattando le aspettative e le decisioni in risposta ai cambiamenti dell’ambiente.\n\n\n\n\n\n\nApprofondimento: esplorazione vs. sfruttamento (logit a 2 opzioni)\n\n\n\n\n\nCon due opzioni, la Softmax si riduce a una logistica sulla differenza di valore. Useremo quindi \\(\\Delta Q = Q_B - Q_A\\) e modelleremo la probabilità di scegliere B come\n\\[\nP(B) = \\text{inv\\_logit}\\big(\\tau \\,\\Delta Q\\big),\n\\] dove \\(\\tau&gt;0\\) (inverse temperature) regola il compromesso esplorazione–sfruttamento:\n\n\n\\(\\tau\\) basso → comportamento esplorativo: anche differenze modeste non portano scelte deterministiche.\n\n\\(\\tau\\) alto → comportamento di sfruttamento: piccole differenze in \\(\\Delta Q\\) bastano per preferenze quasi certe.\n\nNel grafico seguente mostriamo la relazione tra \\(\\Delta Q\\) e \\(P(B)\\) per due valori di \\(\\tau\\).\n\n# Differenze di valore (coerenti con Q in [0,1] → ΔQ in [-1, 1])\ndq &lt;- seq(-1, 1, length.out = 201)\n\n# Logit a 2 opzioni (equivalente alla Softmax con K=2)\np_choose_B &lt;- function(dq, tau) plogis(tau * dq)\n\ndf &lt;- data.frame(\n  dq = rep(dq, 2),\n  prob_B = c(p_choose_B(dq, tau = 0.5),\n             p_choose_B(dq, tau = 5)),\n  tau = factor(rep(c(\"τ = 0.5 (alta esplorazione)\",\n                     \"τ = 5 (alto sfruttamento)\"),\n                   each = length(dq)))\n)\n\nggplot(df, aes(x = dq, y = prob_B, color = tau)) +\n  geom_line(size = 1.2) +\n  labs(\n    x = expression(Delta*Q[B-A]),\n    y = \"Probabilità di scegliere B\"\n  )\n\n\n\n\n\n\n\nLettura del grafico\n\n\nSe \\(\\Delta Q = 0.5\\):\n\ncon \\(\\tau = 0.5\\), \\(P(B) \\approx \\text{inv\\_logit}(0.25) \\approx 0.56\\) → decisione ancora esplorativa;\ncon \\(\\tau = 5\\), \\(P(B) \\approx \\text{inv\\_logit}(2.5) \\approx 0.92\\) → prevale lo sfruttamento.\n\n\n\nSe \\(\\Delta Q = 1\\):\n\ncon \\(\\tau = 0.5\\), \\(P(B) \\approx \\text{inv\\_logit}(0.5) \\approx 0.62\\);\ncon \\(\\tau = 5\\), \\(P(B) \\approx \\text{inv\\_logit}(5) \\approx 0.993\\), scelta quasi deterministica.\n\n\n\nQuesto esempio mostra come \\(\\tau\\) controlli la transizione tra esplorazione e sfruttamento nel caso binario (logit), coerente con il modello Stan usato nel tutorial.\n\n\n\n\n77.1.3 Identificabilità e scaling\nNella funzione Softmax conta solo la differenza tra i valori \\(Q\\). Se aggiungiamo la stessa costante \\(c\\) a entrambi (cioè \\(Q_t(s) + c\\)), le probabilità di scelta non cambiano.\nPer questo motivo:\n\nsi inizializzano di solito i valori in modo simmetrico (ad esempio \\(Q_0(A) = Q_0(B) = 0.5\\));\n\nsi mantengono i rinforzi nel range \\(\\{0,1\\}\\);\n\noppure si fissa un valore iniziale di riferimento, o si pongono vincoli su \\(\\beta\\).\n\nQueste scelte servono solo a rendere il modello ben definito, senza influenzare il comportamento osservato.\nNel presente tutorial il rinforzo è codificato come \\(R_t \\in \\{0,1\\}\\). In questo caso i valori \\(Q\\) convergono a stime di probabilità di ricompensa e risultano naturalmente in \\([0,1]\\). Con codifiche \\(\\{-1,+1\\}\\), i \\(Q\\) convergono a valori attesi in \\([-1,+1]\\) e occorre tenerne conto nell’interpretazione.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#simulazione",
    "href": "chapters/formal_models/03_rescorla_wagner.html#simulazione",
    "title": "77  Il modello di Rescorla–Wagner",
    "section": "\n77.2 Simulazione",
    "text": "77.2 Simulazione\nSimuliamo i dati in un compito di Probabilistic Reversal Learning (PRL). In questo compito il partecipante deve scegliere ripetutamente tra due stimoli:\n\nuno ricco, con probabilità di ricompensa \\(p=0.7\\);\nuno povero, con probabilità \\(1-p=0.3\\).\n\nA metà esperimento le probabilità vengono invertite (reversal): lo stimolo che prima era ricco diventa povero e viceversa. Il partecipante deve quindi adattarsi al cambiamento per massimizzare le ricompense.\n\n# Simulatore PRL (RW + logit) allineato al modello Stan (choice in 0/1)\nsimulate_prl_rw_binary &lt;- function(\n  n_trials        = 160,\n  p_reward_rich   = 0.7,\n  reversal_trial  = 80,            # se NULL, nessun reversal\n  lr              = 0.15,          # learning rate unico\n  tau             = 2,             # inverse temperature (decision noise)\n  Q0              = c(A = 0.0, B = 0.0),\n  seed            = 1234\n){\n  stopifnot(length(Q0) == 2, all(c(\"A\",\"B\") %in% names(Q0)))\n  set.seed(seed)\n  Q &lt;- Q0\n\n  choice   &lt;- integer(n_trials)   # 0 = A, 1 = B\n  reward   &lt;- integer(n_trials)   # 0/1\n  rich_is_A &lt;- rep.int(1L, n_trials) # 1 = A ricco, 0 = B ricco (inizio A ricco)\n  if (!is.null(reversal_trial)) {\n    rich_is_A[(reversal_trial + 1):n_trials] &lt;- 0L\n  }\n\n  Q_A &lt;- Q_B &lt;- pB_seq &lt;- pe_seq &lt;- numeric(n_trials)\n\n  for (t in seq_len(n_trials)) {\n    # probabilità di scegliere B (softmax logit a due opzioni)\n    pB &lt;- plogis(tau * (Q[\"B\"] - Q[\"A\"]))\n    choice[t] &lt;- rbinom(1, 1, pB)   # 1=B, 0=A\n\n    a_idx &lt;- if (choice[t] == 1L) 2L else 1L\n\n    # probabilità di ricompensa per l’opzione scelta\n    chosen_is_rich &lt;- (choice[t] == 0L && rich_is_A[t] == 1L) ||  \n                      (choice[t] == 1L && rich_is_A[t] == 0L)\n    pr &lt;- if (chosen_is_rich) p_reward_rich else (1 - p_reward_rich)\n\n    reward[t] &lt;- rbinom(1, 1, pr)\n\n    # prediction error e aggiornamento RW\n    pe &lt;- reward[t] - Q[a_idx]\n    Q[a_idx] &lt;- Q[a_idx] + lr * pe\n\n    Q_A[t]   &lt;- Q[\"A\"]\n    Q_B[t]   &lt;- Q[\"B\"]\n    pB_seq[t] &lt;- pB\n    pe_seq[t] &lt;- pe\n  }\n\n  tibble::tibble(\n    trial     = seq_len(n_trials),\n    choice    = choice,    # 0=A, 1=B\n    reward    = reward,    # 0/1\n    rich_is_A = rich_is_A, # 0/1\n    Q_A = Q_A, Q_B = Q_B, pB = pB_seq, pe = pe_seq\n  )\n}\n\nsim &lt;- simulate_prl_rw_binary()\n\nNota. La probabilità simulata coincide con quella dello Stan: \\(P(B)=\\text{inv\\_logit}\\!\\big(\\tau [Q(B)-Q(A)]\\big)\\). Anche l’aggiornamento usa lo stesso lr.\nVisualizziamo l’evoluzione dei valori associativi \\(Q\\):\n\n\n\n\n\n\n\n\n\n77.2.1 Interpretazione del grafico\nNella prima fase (trial 1–80), lo stimolo ricco (linea blu) riceve più ricompense e quindi accumula un valore \\(Q\\) più alto rispetto allo stimolo povero (linea verde).\nAl momento del reversal (linea verticale tratteggiata), le probabilità si invertono. Lo stimolo blu smette di essere vantaggioso e il suo valore \\(Q\\) scende, mentre lo stimolo verde cresce.\nQuesto andamento riflette il principio base del modello di Rescorla–Wagner:\n\ni valori associativi \\(Q\\) non sono fissi,\nvengono aggiornati trial per trial con una regola di apprendimento molto semplice:\n\n\\[\nQ_{\\text{nuovo}} = Q_{\\text{vecchio}} + lr \\times (reward - Q_{\\text{vecchio}}).\n\\] Il termine \\(reward - Q_{\\text{vecchio}}\\) è il prediction error (PE): la differenza tra ciò che si è osservato e ciò che ci si aspettava.\n\nSe il feedback è migliore del previsto (PE&gt;0), il valore \\(Q\\) aumenta.\nSe è peggiore del previsto (PE&lt;0), il valore diminuisce.\nIl learning rate lr regola di quanto il valore cambia a ogni prova.\n\nIl parametro tau controlla invece quanto le scelte sono “guidate” dai valori Q:\n\nse tau è grande → scelte più deterministiche (si sceglie quasi sempre lo stimolo con Q maggiore);\nse tau è piccolo → scelte più esplorative o rumorose.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#stima-bayesiana-con-stan",
    "href": "chapters/formal_models/03_rescorla_wagner.html#stima-bayesiana-con-stan",
    "title": "77  Il modello di Rescorla–Wagner",
    "section": "\n77.3 Stima Bayesiana con Stan",
    "text": "77.3 Stima Bayesiana con Stan\nNella simulazione conoscevamo i parametri generativi (lr=0.15, tau=2). Nella realtà, però, abbiamo solo i dati osservati:\n\nper ogni trial sappiamo quale scelta è stata fatta (choice=0 per A, choice=1 per B),\ne se il feedback è stato positivo o negativo (reward=1 oppure 0).\n\nI valori interni \\(Q\\) e i parametri del modello non sono osservabili: dobbiamo inferirli.\nL’ipotesi è che i dati derivino da un processo di tipo Rescorla–Wagner con regola di scelta logistica. L’obiettivo è quindi stimare, a partire dai soli dati:\n\nil learning rate lr, che regola la velocità di aggiornamento dei valori;\nl’inverse temperature tau, che controlla quanto le scelte sono coerenti con i valori Q.\n\n\n77.3.1 Codice Stan\n\nstancode_rw &lt;- \"\ndata {\n  int&lt;lower=1&gt; nTrials;                   // numero di prove\n  array[nTrials] int&lt;lower=0,upper=1&gt; choice; // scelte osservate (0=A, 1=B)\n  array[nTrials] real&lt;lower=0,upper=1&gt; reward; // ricompense osservate (0/1)\n}\n\ntransformed data {\n  vector[2] initV = rep_vector(0.0, 2);   // valori Q iniziali\n}\n\nparameters {\n  real&lt;lower=0,upper=1&gt; lr;   // learning rate\n  real&lt;lower=0,upper=3&gt; tau;  // inverse temperature (softmax / decision noise)\n}\n\nmodel {\n  vector[2] v = initV;        // valori Q correnti\n  real pe;                    // prediction error\n  real p;                     // probabilità di scelta =1 (stimolo B)\n\n  // Priors deboli ma informative\n  lr ~ beta(2, 10);           // learning rate vicino a valori piccoli\n  tau ~ lognormal(log(2), 0.5); // inverse temperature positiva\n\n  for (t in 1:nTrials) {\n    // Probabilità di scegliere B: logit della differenza Q_B - Q_A\n    p = inv_logit(tau * (v[2] - v[1]));\n    choice[t] ~ bernoulli(p);\n\n    // Prediction error e aggiornamento\n    int a = choice[t] + 1;     // 0→1 (A), 1→2 (B)\n    pe = reward[t] - v[a];\n    v[a] += lr * pe;\n  }\n}\n\"\n\nI prior scelti sono debolmente informativi ma coerenti con compiti PRL tipici (apprendimento moderato e scelte non eccessivamente rumorose). Possono essere resi più o meno conservativi in base al compito.\n\n77.3.2 Commento al codice Stan\n\nInizializzazione. All’inizio i due valori \\(Q[1]\\) e \\(Q[2]\\) (per A e B) sono fissati a 0. Rappresentano l’aspettativa iniziale: “nessuna preferenza”.\n\nProbabilità della scelta. Al trial \\(t\\), confrontiamo i due valori:\n\\[\np(B) = \\text{inv\\_logit}\\big(\\tau \\cdot (Q_B - Q_A)\\big).\n\\]\nQuesto significa che se \\(Q_B &gt; Q_A\\), aumenta la probabilità di scegliere B. Il parametro tau regola la “determinazione”:\n\nse tau è grande, basta una piccola differenza tra i due Q per portare a scelte quasi certe;\nse tau è piccolo, anche differenze grandi lasciano spazio all’esplorazione.\n\n\nValutazione della scelta osservata. La riga choice[t] ~ bernoulli(p) confronta la scelta osservata con la probabilità prevista. Questa è la verosimiglianza: se la scelta osservata è coerente con i Q correnti, il modello “ottiene credito”; se è incoerente, viene “penalizzato”.\n\nOsservazione dell’esito e prediction error. Dopo aver osservato il feedback, calcoliamo:\n\\[\nPE = reward[t] - Q[\\text{scelta}],\n\\]\nossia la differenza tra il risultato ricevuto e quello atteso.\n\n\nAggiornamento dei valori. Solo il Q corrispondente all’opzione scelta viene aggiornato:\n\\[\nQ_{\\text{nuovo}} = Q_{\\text{vecchio}} + lr \\cdot PE.\n\\]\n\nSe il feedback è migliore del previsto (PE&gt;0), il valore cresce.\nSe è peggiore del previsto (PE&lt;0), il valore diminuisce.\nIl learning rate lr determina di quanto cambia il valore a ogni trial.\n\n\n\n77.3.3 Esempio intuitivo\nImmagina di avere \\(Q_A = 0.6\\), \\(Q_B = 0.3\\) e tau=2. La differenza \\(Q_B - Q_A = -0.3\\). Il logit vale \\(-0.6\\), e quindi:\n\\[\np(B) = \\text{inv\\_logit}(-0.6) \\approx 0.35.\n\\] Quindi, il modello si aspetta che A venga scelto nel 65% dei casi.\nSe il soggetto sceglie effettivamente A, la verosimiglianza è alta. Se sceglie B, è possibile ma meno probabile: il modello aggiorna i valori interni in base al feedback ricevuto.\nIn questo tutorial useremo i dati simulati in precedenza:\n\nstan_data &lt;- list(\n  nTrials = nrow(sim),\n  choice  = as.integer(sim$choice),\n  reward  = as.numeric(sim$reward)   # 0/1 come real per coerenza con &lt;lower=0,upper=1&gt;\n)\nglimpse(stan_data)\n#&gt; List of 3\n#&gt;  $ nTrials: int 160\n#&gt;  $ choice : int [1:160] 0 1 1 0 1 1 0 0 0 0 ...\n#&gt;  $ reward : num [1:160] 1 0 0 1 0 0 0 0 1 1 ...\n\nCompiliamo il modello e eseguiamo il campionamento:\n\nmod_rw &lt;- cmdstanr::cmdstan_model(write_stan_file(stancode_rw))\nfit_rw &lt;- mod_rw$sample(\n  data = stan_data,\n  seed = 42,\n  chains = 4,\n  parallel_chains = 4,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  refresh = 200\n)\n\nEseguiamo le diagnostiche di campionamento:\n\nfit_rw$cmdstan_diagnose()  # controlli rapidi cmdstan\n#&gt; Checking sampler transitions treedepth.\n#&gt; Treedepth satisfactory for all transitions.\n#&gt; \n#&gt; Checking sampler transitions for divergences.\n#&gt; No divergent transitions found.\n#&gt; \n#&gt; Checking E-BFMI - sampler transitions HMC potential energy.\n#&gt; E-BFMI satisfactory.\n#&gt; \n#&gt; Rank-normalized split effective sample size satisfactory for all parameters.\n#&gt; \n#&gt; Rank-normalized split R-hat values satisfactory for all parameters.\n#&gt; \n#&gt; Processing complete, no problems detected.\n\nEsaminiamo la distribuzione a posteriori dei parametri:\n\nfit_rw$summary(c(\"lr\",\"tau\"))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lr       0.155  0.149 0.045 0.043 0.091 0.236 1.001 7735.557 7858.989\n#&gt; 2 tau      2.407  2.435 0.350 0.382 1.790 2.927 1.000 6866.231 4320.660",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#interpretazione-dei-risultati",
    "href": "chapters/formal_models/03_rescorla_wagner.html#interpretazione-dei-risultati",
    "title": "77  Il modello di Rescorla–Wagner",
    "section": "\n77.4 Interpretazione dei risultati",
    "text": "77.4 Interpretazione dei risultati\nLe distribuzioni a posteriori stimano quanto bene il modello è riuscito a recuperare i parametri generativi usati nella simulazione (lr = 0.15, tau = 2).\n\n\nlr (learning rate) regola la rapidità con cui il soggetto aggiorna le proprie aspettative dopo ogni feedback.\n\nValori alti → aggiornamenti rapidi: anche un singolo feedback può cambiare molto la stima del valore associato a uno stimolo.\nValori bassi → aggiornamenti lenti: il soggetto “conserva” più a lungo le esperienze passate, adattandosi solo gradualmente ai cambiamenti.\n\n\n\ntau (inverse temperature) controlla la coerenza delle scelte rispetto ai valori \\(Q\\).\n\nCon tau alto → le scelte sono quasi deterministiche: basta una piccola differenza tra \\(Q_A\\) e \\(Q_B\\) per indurre una preferenza netta.\nCon tau basso → il comportamento appare più esplorativo o rumoroso: anche se uno stimolo ha un valore più alto, non sempre viene scelto.\n\n\n\nNei grafici delle distribuzioni posteriori:\n\nle linee tratteggiate rappresentano i valori “veri” usati per simulare i dati,\nle distribuzioni stimate mostrano l’incertezza del modello sulle possibili soluzioni.\n\nQuando la distribuzione è ben centrata sulla linea tratteggiata e piuttosto stretta, significa che il modello ha recuperato bene il parametro. Distribuzioni più larghe o spostate indicano maggiore incertezza o possibili trade-off tra parametri (ad esempio: un lr leggermente diverso può essere compensato da un tau più basso o più alto producendo previsioni simili).\n\ndraws_df &lt;- fit_rw$draws(c(\"lr\",\"tau\")) |&gt;\n  as_draws_df() |&gt;\n  tibble::as_tibble()\n\ncols &lt;- c(lr = \"#5d5349\", tau = \"#4682B4\")\n\nplot_post &lt;- function(draws, param, col) {\n  ggplot(draws, aes(x = .data[[param]])) +\n    geom_histogram(aes(y = after_stat(density)), bins = 40,\n                   fill = col, color = \"black\", alpha = 0.6) +\n    geom_density(color = col, linewidth = 1) +\n    labs(x = param, y = \"Densità\", title = paste(\"Posterior di\", param))\n}\n\np_lr  &lt;- plot_post(draws_df, \"lr\",  cols[\"lr\"])\np_tau &lt;- plot_post(draws_df, \"tau\", cols[\"tau\"])\n\n\ntrue_vals &lt;- c(lr = 0.15, tau = 2)\np_lr  + geom_vline(xintercept = true_vals[\"lr\"],  linetype = 2)\n\n\n\n\n\n\np_tau + geom_vline(xintercept = true_vals[\"tau\"], linetype = 2)\n\n\n\n\n\n\n\nAttenzione ai possibili trade-off: in dataset brevi o con scarsa esplorazione, combinazioni diverse di lr e tau possono produrre predizioni simili (identificabilità parziale). Conviene sempre ispezionare tracce, R-hat, ESS e, se possibile, condurre posterior predictive checks.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#dal-parametro-allo-stile-cognitivo",
    "href": "chapters/formal_models/03_rescorla_wagner.html#dal-parametro-allo-stile-cognitivo",
    "title": "77  Il modello di Rescorla–Wagner",
    "section": "\n77.5 Dal parametro allo stile cognitivo",
    "text": "77.5 Dal parametro allo stile cognitivo\nI parametri del modello non sono soltanto numeri: possono essere interpretati come indicatori di stili di apprendimento e decisione.\n\n\nLearning rate (lr)\n\nUn soggetto con lr alto è molto sensibile ai singoli feedback: aggiorna le proprie aspettative in modo rapido e può adattarsi velocemente a un reversal. Esempio: basta un paio di esiti negativi perché abbandoni l’opzione che prima sembrava migliore.\nUn soggetto con lr basso aggiorna più lentamente: dà più peso all’esperienza accumulata e tende a mantenere le proprie scelte anche di fronte a segnali contrari. Esempio: continua a scegliere lo stimolo “vecchio ricco” anche dopo alcuni esiti negativi, adattandosi solo gradualmente.\n\n\n\nInverse temperature (tau)\n\nUn soggetto con tau alto si comporta in modo deterministico: sceglie quasi sempre l’opzione con il valore Q più alto. Questo corrisponde a uno stile “sfruttatore” (exploiter), focalizzato sul massimizzare subito i guadagni.\nUn soggetto con tau basso mostra un comportamento più esplorativo o rumoroso: anche se una delle due opzioni è chiaramente più vantaggiosa, di tanto in tanto sceglie l’altra. Questo stile può sembrare “incoerente”, ma in certi contesti favorisce l’esplorazione di alternative.\n\n\n\n\n77.5.1 Messaggio chiave\nL’approccio bayesiano permette di stimare, per ogni individuo, un profilo fatto di apprendimento (quanto velocemente aggiorna le proprie aspettative) e decisione (quanto coerentemente agisce in base a quelle aspettative).\nDifferenze sistematiche nei parametri tra gruppi sperimentali (es. stimoli emozionanti vs. neutri) o tra popolazioni cliniche e di controllo possono rivelare stili cognitivi distintivi:\n\ndifficoltà nell’adattarsi a nuovi feedback (lr basso),\noppure scelte troppo rigide o troppo esplorative (tau troppo alto o troppo basso).\n\nIn questo modo, un modello computazionale semplice come il Rescorla–Wagner con regola logistica non solo descrive i dati, ma fornisce anche una chiave di lettura psicologica dei processi sottostanti.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#contextual-bandits-e-compiti-food-vs.-neutral",
    "href": "chapters/formal_models/03_rescorla_wagner.html#contextual-bandits-e-compiti-food-vs.-neutral",
    "title": "77  Il modello di Rescorla–Wagner",
    "section": "\n77.6 Contextual Bandits e compiti food vs. neutral\n",
    "text": "77.6 Contextual Bandits e compiti food vs. neutral\n\nIl modello di Rescorla–Wagner con regola logistica, come visto nel tutorial, assume due parametri stabili per tutto il compito:\n\n\nlr, che regola la velocità con cui i valori \\(Q\\) vengono aggiornati,\n\ntau, che governa la coerenza delle scelte rispetto a tali valori.\n\nLa famiglia dei banditi contestuali rappresenta un’estensione naturale: i parametri non sono più fissi, ma possono variare in funzione del contesto. In pratica, lo stesso schema RW + logit viene applicato separatamente a diverse condizioni sperimentali (es. stimoli food vs. stimoli neutral, per un campione di pazienti anoressiche) o a diversi gruppi di partecipanti (es. clinici vs. controlli).\nQuesta estensione è stata applicata con successo nello studio dei disturbi alimentari. Analisi recenti hanno mostrato che i deficit di apprendimento in anoressia nervosa non sono globali, ma specifici del contesto alimentare:\n\ndi fronte a stimoli legati al cibo, le persone con anoressia tendono a mostrare un learning rate più basso, cioè aggiornano le aspettative più lentamente;\nnegli stessi compiti con stimoli neutri, invece, i parametri risultano simili a quelli dei controlli (Colpizzi et al., 2025).\n\nQuesta evidenza suggerisce che la vulnerabilità non consista in un deficit generale dei processi di apprendimento, ma in un’alterazione selettiva e contestuale, che contribuisce al mantenimento del disturbo.\nFormalmente, per il contesto \\(c \\in \\{\\text{food},\\text{neutral}\\}\\) si stima: \\[\nP_c(B_t)=\\text{inv\\_logit}\\!\\big(\\tau_c [Q_{c,t}(B)-Q_{c,t}(A)]\\big),\n\\] \\[\nQ_{c,t+1}(s)=Q_{c,t}(s)+lr_c \\,[R_{c,t}-Q_{c,t}(s)].\n\\] Il confronto tra \\(lr_{\\text{food}}\\) e \\(lr_{\\text{neutral}}\\) (e analogamente per \\(\\tau\\)) quantifica le differenze contestuali.\n\n77.6.1 Limiti e varianti minime\n\n\nAggiornamento solo dell’opzione scelta. In alcune applicazioni si usa un “fictive update” anche per l’opzione non scelta (o un decadimento).\n\nLapse/guess rate. Una piccola probabilità \\(\\xi\\) di scelta casuale: \\(P^\\*=(1-\\xi)P+\\xi/2\\).\n\nBias laterale iniziale. Aggiungere un offset di preferenza (es. per A) nel logit.\n\nGerarchico multi-soggetto. lr e tau con distribuzioni di gruppo → più robusto e adatto al confronto tra gruppi/condizioni.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#riflessioni-conclusive",
    "href": "chapters/formal_models/03_rescorla_wagner.html#riflessioni-conclusive",
    "title": "77  Il modello di Rescorla–Wagner",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl modello di Rescorla–Wagner estende la semplice dinamica di aggiornamento introducendo un livello decisionale, che trasforma i valori appresi (Q-values) in probabilità di scelta. Questo ci permette di distinguere due componenti fondamentali del comportamento:\n\n\nApprendimento dagli esiti (learning), controllato dal parametro lr (learning rate), che determina quanto rapidamente il soggetto aggiorna le proprie aspettative in base all’errore di predizione (la differenza tra quanto atteso e quanto effettivamente ottenuto).\n\nUn valore basso di lr corrisponde a un apprendimento più lento e stabile, ma meno reattivo ai cambiamenti.\nUn valore alto di lr corrisponde a un adattamento veloce, ma a una maggiore sensibilità al rumore.\n\n\n\nPolitica decisionale (decision policy), governata dal parametro tau (inverse temperature), che regola la coerenza tra le scelte e i valori appresi.\n\n\ntau alto: scelte deterministiche e coerenti con l’opzione migliore (alto sfruttamento).\n\ntau basso: comportamento più esplorativo e meno prevedibile.\n\n\n\nQuesta distinzione è cruciale in ambito clinico. In uno studio sull’anoressia nervosa e l’apprendimento, ad esempio, abbiamo osservato che le difficoltà non sono generalizzate, ma specifiche del contesto alimentare: le pazienti presentano un tasso di apprendimento ridotto (lr più basso) quando gli stimoli sono legati al cibo, mentre il loro comportamento è simile a quello dei controlli in contesti neutri (Colpizzi et al., 2025).\nIl modello RW offre quindi un’analisi più ricca della semplice prestazione media:\n\nconsente di identificare differenze nei meccanismi di apprendimento (lr) tra diverse condizioni;\npermette di verificare se a queste diffeerenze si associano anche differenze nello stile decisionale (tau).\n\nPer uno psicologo, questo si traduce in due vantaggi concreti:\n\n\nChiarezza teorica: permette di formulare ipotesi precise e separate sui processi di apprendimento e sulle strategie decisionali, andando oltre le semplici misure di accuratezza.\n\nRilevanza clinica: distinguere un deficit nell’apprendimento da uno nella scelta ha implicazioni dirette per la progettazione di interventi mirati (es., potenziare la sensibilità al feedback o riequilibrare l’esplorazione e lo sfruttamento).\n\nIn sintesi, il modello Rescorla-Wagner non è solo uno strumento computazionale: è un ponte fra comportamento osservato e processi mentali, fondamentale per isolare deficit contestuali specifici e comprendere come le strategie decisionali varino tra individui e gruppi clinici.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.4.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.4.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [64] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [67] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [70] textshaping_1.0.1     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [73] V8_6.0.6              gtable_0.3.6          digest_0.6.37        \n#&gt; [76] TH.data_1.1-3         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [79] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [82] MASS_7.3-65",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#bibliografia",
    "href": "chapters/formal_models/03_rescorla_wagner.html#bibliografia",
    "title": "77  Il modello di Rescorla–Wagner",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nColpizzi, I., Sica, C., Marchetti, I., Guidi, L., Danti, S., Lucchesi, S., Giusti, E., Di Meglio, M., Ballardini, D., Mazzoni, C., et al. (2025). Food-specific decision-making in anorexia nervosa: a comparative study of clinical, at-risk, and healthy control groups. Eating Disorders, 1–19.\n\n\nRescorla, R. A., & Wagner, A. R. (1972). A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and non-reinforcement. Classical conditioning II, Current research and theory, 2, 64–69.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/decision_analysis/01_study_method.html",
    "href": "chapters/decision_analysis/01_study_method.html",
    "title": "80  Decisione ottimale e utilità attesa: l’approccio bayesiano",
    "section": "",
    "text": "Introduzione\nL’analisi decisionale bayesiana offre un approccio strutturato per affrontare le scelte in condizioni di incertezza. L’idea di fondo è semplice: ogni alternativa possibile genera diversi esiti, ciascuno con una certa probabilità e con un valore associato in termini di utilità (quanto è desiderabile) o di perdita (quanto è costoso). La decisione migliore è quella che massimizza l’utilità attesa, oppure minimizza la perdita attesa, tenendo conto della distribuzione predittiva degli esiti.\nIn questo capitolo applicheremo questo quadro teorico a un problema vicino all’esperienza degli studenti di psicologia: la scelta del metodo di studio. Considereremo tre possibili strategie, che si differenziano per impegno richiesto ed efficacia prevista:\nGli esiti che ci interessano sono due: il voto d’esame (\\(g \\in [0,100]\\)) e le ore di studio necessarie (\\(h \\geq 0\\)). Entrambi sono caratterizzati da incertezza, legata sia alle differenze individuali (abilità, motivazione, stile di apprendimento), sia alla variabilità intrinseca del processo di studio.\nIl framework bayesiano ci consentirà di stimare la distribuzione congiunta di \\((g,h)\\) per ciascun metodo, di combinare voto e tempo in un’unica misura tramite una funzione di utilità. Per la discussione presente scegliamo la seguente funzione:\n\\[\nU(g,h;\\lambda) = g - \\lambda h,\n\\] dove \\(\\lambda \\geq 0\\) indica quanto “costa” un’ora di studio in termini di punti di voto. In questo modo potremo calcolare l’utilità attesa di ciascun metodo, integrando l’incertezza attraverso simulazioni, e infine identificare l’opzione che ha maggiore probabilità di rappresentare la scelta ottimale.",
    "crumbs": [
      "Decisioni",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Decisione ottimale e utilità attesa: l’approccio bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/decision_analysis/01_study_method.html#introduzione",
    "href": "chapters/decision_analysis/01_study_method.html#introduzione",
    "title": "80  Decisione ottimale e utilità attesa: l’approccio bayesiano",
    "section": "",
    "text": "Metodo classico: studio individuale su testi ed esercizi, senza supporti interattivi.\n\nMetodo di gruppo: lo stesso approccio classico, arricchito da discussioni in piccoli gruppi per chiarire e consolidare i contenuti.\n\nMetodo con AI tutor: studio su testi integrato con spiegazioni alternative, chat interattiva ed esercizi generati automaticamente da un tutor basato su intelligenza artificiale.\n\n\n\n\nPanoramica del capitolo\n\nLe quattro fasi dell’analisi decisionale bayesiana.\n\nModellare la distribuzione predittiva degli esiti.\n\nFormulare e interpretare una funzione di utilità.\n\nIdentificare la decisione ottimale.\n\nLimiti del modello lineare.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nPer un’introduzione alla loss function, si rimanda al capitolo Sampling the Imaginary di Statistical Rethinking (McElreath, 2020).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Additional packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, posterior, loo, cmdstanr, stringr, tidyr)",
    "crumbs": [
      "Decisioni",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Decisione ottimale e utilità attesa: l’approccio bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/decision_analysis/01_study_method.html#schema-in-quattro-passi",
    "href": "chapters/decision_analysis/01_study_method.html#schema-in-quattro-passi",
    "title": "80  Decisione ottimale e utilità attesa: l’approccio bayesiano",
    "section": "\n80.1 Schema in quattro passi",
    "text": "80.1 Schema in quattro passi\nSeguendo l’impostazione proposta da Gelman et al. (2013), l’analisi decisionale bayesiana si articola in quattro fasi: definizione del problema, modellazione degli esiti, specificazione della funzione di utilità e scelta della decisione ottimale. Nel nostro caso, queste fasi vengono applicate alla scelta del metodo di studio.\n1. Definizione delle alternative e degli esiti Le decisioni possibili sono tre: metodo classico, studio di gruppo e AI tutor. Ogni decisione porta a due esiti di interesse: il voto d’esame \\(g\\) (tra 0 e 100) e le ore di studio \\(h\\) (con \\(h \\geq 0\\)).\n2. Modellazione della distribuzione predittiva Per descrivere la variabilità dei risultati usiamo un modello gerarchico stimato da dati storici (ad esempio, i registri di studenti dell’anno precedente). Assumiamo che le ore di studio seguano una distribuzione lognormale, adatta a variabili non negative e asimmetriche, mentre il voto dipende dalle ore in modo sublineare, riflettendo rendimenti decrescenti: inizialmente ogni ora extra produce un buon guadagno, ma col tempo l’effetto si attenua.\n3. Funzione di utilità Per confrontare i metodi su un’unica scala, combiniamo voto e ore in una funzione di utilità lineare:\n\\[\nU(g,h;\\lambda) = g - \\lambda h,\n\\] dove \\(\\lambda\\) esprime quanto pesa il tempo rispetto al voto. Ad esempio, con \\(\\lambda=0\\) conta solo il voto, mentre con \\(\\lambda=2\\) ogni ora di studio “costa” due punti d’esame.\n4. Decisione ottimale L’alternativa migliore è quella che massimizza l’utilità attesa, calcolata integrando l’incertezza sia sui parametri del modello sia sulla variabilità predittiva degli esiti. In pratica, questa integrazione si realizza tramite simulazioni dalla distribuzione predittiva posteriore, così da ottenere un confronto robusto tra le opzioni disponibili.\n\n80.1.1 Simulazione dei dati\nPer illustrare il funzionamento dell’analisi decisionale bayesiana, iniziamo simulando un dataset. Questo ci permette di sapere quali sono i “veri” parametri del mondo simulato e di verificare se il modello bayesiano riesce a recuperarli. Il campione simulato comprende 300 studenti, ciascuno assegnato casualmente a uno dei tre metodi di studio: classico, AI tutor e gruppo.\n\nset.seed(123)\n\n# Numero di studenti\nN &lt;- 300\nmethod_names &lt;- c(\"classico\",\"AI\",\"gruppo\")\nd &lt;- sample(1:3, N, replace = TRUE)\n\nPer rendere l’esempio più realistico, ipotizziamo che le ore di studio (\\(H\\)) seguano una distribuzione lognormale, che garantisce valori non negativi e una coda a destra (alcuni studenti studiano molto di più della media). Ogni metodo ha una diversa mediana e variabilità: il metodo classico richiede meno ore, l’AI tutor un impegno intermedio, e il gruppo più ore e con maggiore dispersione.\n\nmu_h_true    &lt;- log(c(8,   12,  16))   # mediane circa: 8, 12, 16 ore\nsigma_h_true &lt;- c(0.30, 0.40, 0.50)\n\nIl voto d’esame (\\(G\\)) dipende dalle ore di studio con rendimenti decrescenti, modellati tramite la funzione logaritmica. Ogni metodo ha parametri diversi: l’AI tutor è più efficace, il metodo di gruppo offre buoni risultati ma a caro prezzo in termini di ore, e il metodo classico è il meno performante.\n\nalpha_true    &lt;- c(55,  64,  61)\nbeta_true     &lt;- c(5.5, 8.0, 6.5)\nsigma_g_true  &lt;- 7\n\nInfine, specifichiamo il costo orario in termini di punti d’esame, fissato a \\(\\lambda = 0.65\\):\n\nlambda &lt;- 0.65\n\nCon questi ingredienti generiamo le osservazioni simulate:\n\nh  &lt;- rlnorm(N, meanlog = mu_h_true[d], sdlog = sigma_h_true[d])\nmu &lt;- alpha_true[d] + beta_true[d] * log1p(h)\ng  &lt;- rnorm(N, mu, sigma_g_true)\ng  &lt;- pmin(pmax(g, 0), 100)  # vincola i voti in [0,100]\n\nCalcoliamo poi l’utilità vera per ciascuno studente e verifichiamo come si distribuisce nei tre gruppi:\n\nu_true &lt;- g - lambda * h\ndf_sim &lt;- data.frame(\n  method = factor(method_names[d], levels = method_names),\n  g = g, \n  h = h, u = u_true\n)\n\nggplot(df_sim, aes(x = u, fill = method)) +\n  geom_density(alpha = 0.35) +\n  labs(x = \"Utilità\", y = \"Densità\")\n\n\n\n\n\n\n\nQuesto grafico mostra come, in base ai parametri scelti, i metodi producano distribuzioni diverse di utilità. È una prima verifica che il modello simulato genera differenze plausibili e interpretabili, prima di passare alla stima vera e propria con Stan.\nPrepariamo i dati per Stan:\n\nstan_data &lt;- list(N = N, d = as.integer(d), h = h, g = g, lambda = lambda)\nglimpse(stan_data)\n#&gt; List of 5\n#&gt;  $ N     : num 300\n#&gt;  $ d     : int [1:300] 3 3 3 2 3 2 2 2 3 1 ...\n#&gt;  $ h     : num [1:300] 41.4 22.8 23.1 20.7 12 ...\n#&gt;  $ g     : num [1:300] 83.9 85.5 84 93.5 70.5 ...\n#&gt;  $ lambda: num 0.65\n\n\n80.1.2 Specificazione del modello Stan\nIl modello bayesiano viene implementato in Stan seguendo una struttura modulare che riflette le componenti concettuali del problema decisionale. La specificazione del codice procede attraverso i seguenti blocchi fondamentali:\nBlocco delle funzioni: definisce la funzione di utilità \\(U(g, h; \\lambda) = g - \\lambda h\\), che combina voti e ore in un unico indice di preferenza.\nBlocco dei dati: dichiara le variabili osservate, tra cui il numero di osservazioni \\(N\\), il metodo di studio scelto \\(d\\), le ore di studio \\(h\\), i voti ottenuti \\(g\\) e il parametro di trade-off \\(\\lambda\\).\nBlocco dei parametri: include i parametri da stimare, specifici per ciascun metodo:\n\nparametri della distribuzione lognormale per le ore di studio (\\(\\mu_h\\), \\(\\sigma_h\\)),\ncoefficienti della relazione tra log(ore) e voto (\\(\\alpha\\), \\(\\beta\\)),\ndeviazione standard residua del voto (\\(\\sigma_g\\)).\n\nBlocco del modello: specifica le distribuzioni a priori debolmente informative e la verosimiglianza dei dati. Le ore seguono una distribuzione lognormale, mentre i voti sono modellati con una normale la cui media dipende dal logaritmo delle ore.\nBlocco delle quantità generate: simula valori predittivi per ore e voti per ciascun metodo, calcolando quindi l’utilità corrispondente. Queste simulazioni permettono di stimare l’utilità attesa e confrontare i metodi.\n\nstancode &lt;- \"\nfunctions {\n  real U(real g, real h, real lambda) {\n    return g - lambda * h;\n  }\n}\ndata {\n  int&lt;lower=0&gt; N;                     // numero osservazioni\n  array[N] int&lt;lower=1, upper=3&gt; d;   // decisione osservata: 1=classico, 2=AI, 3=gruppo\n  vector&lt;lower=0&gt;[N] h;               // ore osservate\n  vector&lt;lower=0, upper=100&gt;[N] g;    // voto osservato (clippato 0..100 a valle)\n  real&lt;lower=0&gt; lambda;               // costo orario in punti-voto\n}\nparameters {\n  // ore ~ lognormal per metodo\n  vector[3] mu_h;                     // location log(ore) per metodo\n  vector&lt;lower=0&gt;[3] sigma_h;         // scale log(ore) per metodo\n\n  // voto | (h, metodo) ~ Normal\n  vector[3] alpha;                    // intercetta per metodo\n  vector[3] beta;                     // pendenza su log1p(h) per metodo\n  real&lt;lower=0&gt; sigma_g;              // sd residua del voto\n}\nmodel {\n  // Priors debolmente informativi\n  mu_h ~ normal(log(10), 1);  // ore tipiche ~ e^N(log(10),1) ≈ 10 ore medie\n  sigma_h ~ normal(0, 0.5);  // &gt;0; log-sd moderata\n\n  alpha ~ normal(60, 20);  // voto tipico ~60 (ampio)\n  beta ~ normal(5, 5);   // più ore =&gt; voto più alto (a priori)\n  sigma_g ~ student_t(3, 0, 10);  // rumore voto\n\n  // Likelihood\n  for (n in 1:N) {\n    h[n] ~ lognormal(mu_h[d[n]], sigma_h[d[n]]);\n    g[n] ~ normal(alpha[d[n]] + beta[d[n]] * log1p(h[n]), sigma_g);\n  }\n}\ngenerated quantities {\n  // utilità predittiva una-estrazione per ciascun metodo \n  array[3] real util;\n  array[3] real g_tilde;\n  array[3] real h_tilde;\n\n  for (k in 1:3) {\n    h_tilde[k] = lognormal_rng(mu_h[k], sigma_h[k]);\n    real mu_g  = alpha[k] + beta[k] * log1p(h_tilde[k]);\n    g_tilde[k] = normal_rng(mu_g, sigma_g);\n    util[k]    = U(g_tilde[k], h_tilde[k], lambda);\n  }\n}\n\"\n\nIl modello integra quindi tre componenti essenziali: (1) una funzione di utilità che sintetizza il trade-off tra risultati accademici e impegno temporale; (2) un meccanismo generativo che cattura la relazione tra ore di studio e performance; (3) simulazioni predittive che incorporano l’incertezza parametrica e la variabilità intrinseca degli esiti.\nQuesta implementazione consente non solo di stimare i parametri del modello, ma anche di confrontare le alternative decisionali attraverso il calcolo dell’utilità attesa, fornendo così una base quantitativa solida per la scelta del metodo di studio ottimale.\n\n80.1.3 Compilazione ed esecuzione del modello\nCompiliamo il modello Stan:\n\nstanmod &lt;- cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n\nEseguiamo il campionamento MCMC:\n\nfit &lt;- stanmod$sample(\n  data = stan_data,\n  seed = 2025,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1000, iter_sampling = 2000,\n  refresh = 200\n)\n\nRiepilogo dei parametri principali:\n\nprint(fit$summary(c(\"mu_h\",\"sigma_h\",\"alpha\",\"beta\",\"sigma_g\")))\n#&gt; # A tibble: 13 × 10\n#&gt;    variable     mean median    sd   mad     q5    q95  rhat  ess_bulk ess_tail\n#&gt;    &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 mu_h[1]     2.060  2.061 0.029 0.030  2.011  2.108 1.001  8799.832 6022.465\n#&gt;  2 mu_h[2]     2.424  2.424 0.046 0.046  2.349  2.498 1.001  9771.434 5748.160\n#&gt;  3 mu_h[3]     2.744  2.744 0.048 0.048  2.665  2.823 1.000  8858.073 5913.963\n#&gt;  4 sigma_h[1]  0.309  0.308 0.021 0.021  0.277  0.344 1.000  9632.056 5815.072\n#&gt;  5 sigma_h[2]  0.466  0.465 0.034 0.033  0.414  0.524 1.001  8735.263 5292.249\n#&gt;  6 sigma_h[3]  0.462  0.459 0.035 0.033  0.408  0.524 1.000 10539.108 5879.366\n#&gt;  7 alpha[1]   55.716 55.682 4.632 4.638 48.194 63.271 1.001  5453.435 5227.550\n#&gt;  8 alpha[2]   64.053 64.014 3.807 3.840 57.687 70.275 1.000  5815.791 5159.801\n#&gt;  9 alpha[3]   54.795 54.802 4.382 4.360 47.524 62.102 1.001  5614.951 5345.316\n#&gt; 10 beta[1]     5.205  5.217 2.097 2.095  1.791  8.616 1.001  5438.111 5194.190\n#&gt; 11 beta[2]     7.764  7.761 1.494 1.496  5.314 10.235 1.000  5798.738 5291.496\n#&gt; 12 beta[3]     8.579  8.559 1.536 1.524  6.055 11.141 1.001  5508.905 4994.723\n#&gt; 13 sigma_g     6.728  6.724 0.279 0.277  6.280  7.205 1.000  8493.763 5783.980\n\n\n80.1.4 Estrazione e analisi delle utilità predittive\nDopo aver adattato il modello in Stan, estraiamo le utilità predittive per ciascun metodo. Queste derivano dalle simulazioni MCMC e incorporano sia l’incertezza sui parametri sia la variabilità intrinseca degli esiti.\n\nmethod_names &lt;- c(\"classico\", \"AI\", \"gruppo\")\n\n# Estrazione della matrice delle utilità\nUmat &lt;- fit$draws(variables = \"util\", format = \"draws_matrix\") |&gt; \n  as.matrix()\ncolnames(Umat) &lt;- method_names\n\n\n80.1.4.1 Utilità attesa e metodo ottimale\nCalcoliamo la media delle utilità per ciascun metodo e identifichiamo quello con valore più alto, cioè l’alternativa ottimale per il valore di \\(\\lambda\\) scelto.\n\nU_means &lt;- colMeans(Umat)\nU_means\n#&gt; classico       AI   gruppo \n#&gt;     61.7     75.3     67.7\nbest_method &lt;- names(U_means)[which.max(U_means)]\nbest_method\n#&gt; [1] \"AI\"\n\n\n80.1.4.2 Probabilità di optimalità\nOltre al confronto delle medie, possiamo stimare la probabilità che ciascun metodo sia davvero il migliore. Questo si ottiene verificando, in ogni simulazione, quale metodo raggiunge l’utilità massima e calcolando le frequenze relative.\n\nbest_idx &lt;- max.col(Umat, ties.method = \"first\")\np_opt &lt;- prop.table(table(factor(best_idx, levels = 1:3, labels = method_names)))\np_opt\n#&gt; \n#&gt; classico       AI   gruppo \n#&gt;   0.0494   0.7456   0.2050\n\n\n80.1.4.3 Analisi delle distribuzioni\nPer avere un quadro completo non basta confrontare le medie: è utile osservare anche la forma delle distribuzioni delle utilità predittive. Possiamo calcolare statistiche descrittive e visualizzare le densità per ciascun metodo.\n\nutil_long &lt;- as.data.frame(Umat) |&gt;\n  tibble::rownames_to_column(var = \".draw\") |&gt;\n  mutate(.draw = as.integer(.draw)) |&gt;\n  pivot_longer(cols = all_of(method_names),\n               names_to = \"method\", values_to = \"util\")\n\nutil_sum &lt;- util_long |&gt;\n  group_by(method) |&gt;\n  summarize(mean = mean(util),\n            sd   = sd(util),\n            q05  = quantile(util, 0.05),\n            q50  = median(util),\n            q95  = quantile(util, 0.95),\n            .groups = \"drop\")\n\nutil_sum\n#&gt; # A tibble: 3 × 6\n#&gt;   method    mean    sd   q05   q50   q95\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 AI        75.3  6.88  63.8  75.4  86.6\n#&gt; 2 classico  61.7  6.78  50.5  61.7  73.0\n#&gt; 3 gruppo    67.7  7.17  55.7  67.8  79.0\n\n\n80.1.4.4 Visualizzazione grafica\n\nggplot(util_long, aes(x = util, fill = method)) +\n  geom_density(alpha = 0.4) +\n  labs(x = \"Utilità predittiva\", y = \"Densità\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set1\", name = \"Metodo\")\n\n\n\n\n\n\n\n\n80.1.5 Interpretazione dei risultati\nIl grafico presenta la distribuzione dell’utilità predittiva associata a ciascun metodo di studio, calcolata mediante la relazione:\n\\[\nU = G - \\lambda H\n\\] dove \\(G\\) rappresenta il voto ottenuto e \\(H\\) le ore di studio investite. Valori elevati di utilità indicano combinazioni favorevoli caratterizzate da voti alti ottenuti con un impegno temporale contenuto, mentre valori ridotti segnalano esiti meno soddisfacenti, dovuti a performance modeste e/o a un elevato numero di ore dedicate.\nL’analisi delle distribuzioni consente di valutare tre aspetti fondamentali. La posizione centrale dell’utilità (sintetizzata dalla media o dalla mediana) fornisce una stima del vantaggio atteso associato a ciascun metodo, indicando quale approccio tende a produrre i risultati più desiderabili in condizioni medie.\nLa dispersione della distribuzione riflette invece il grado di incertezza e variabilità negli esiti possibili. Una maggiore dispersione segnala che i risultati individuali possono discostarsi significativamente dal valore atteso, mentre una distribuzione più concentrata suggerisce outcomes più prevedibili.\nInfine, la sovrapposizione tra le distribuzioni dei diversi metodi rivela in quali scenari le alternative producono risultati simili. Aree di sovrapposizione estesa indicano che la scelta tra metodi potrebbe essere meno netta in certe condizioni, mentre distribzioni ben separate suggeriscono differenze più marcate nelle performance attese.\nQuesto approccio analitico supera la semplice identificazione del “miglior metodo in media” per considerare l’intero spettro di possibili esiti, offrendo così una valutazione completa che tiene conto tanto del valore atteso quanto dell’incertezza predittiva.\n\n80.1.6 Analisi comparativa a parità di input\nPer confrontare i tre metodi in modo intuitivo, possiamo considerare due scenari:\n\nfissiamo il tempo di studio (\\(H\\)) e confrontiamo quale metodo produce il voto atteso più alto;\nfissiamo invece un obiettivo di voto (\\(G\\_0\\)) e vediamo quanto tempo richiede ciascun metodo per raggiungerlo.\n\n\n80.1.6.1 Confronto a ore costanti\nQuando manteniamo costanti le ore di studio, l’unica differenza tra metodi riguarda la performance attesa (\\(G\\)). A parità di tempo, il metodo che garantisce un voto più alto produce anche un’utilità maggiore.\nUn esempio numerico lo chiarisce: con \\(\\lambda = 0.5\\) (due ore di studio equivalgono a un punto di voto) e \\(H=12\\) ore per tutti:\n\n\n\n\n\n\n\n\nMetodo\nVoto atteso \\(G\\)\n\nOre \\(H\\)\n\nUtilità \\(U = G - \\lambda H\\)\n\n\n\n\nClassico\n78\n12\n72\n\n\nAI\n82\n12\n76\n\n\nGruppo\n79\n12\n73\n\n\n\nIn questo scenario il metodo AI prevale. Tuttavia, se richiedesse più tempo (ad esempio 15 ore anziché 12), l’utilità si ridurrebbe a:\n\nG_AI &lt;- 82\nH_AI &lt;- 15\nlambda &lt;- 0.5\nU_AI &lt;- G_AI - lambda * H_AI\nU_AI\n#&gt; [1] 74.5\n\nPur restando vantaggioso rispetto al metodo classico (72), il margine si ridurrebbe sensibilmente.\n\n80.1.6.2 Confronto a voto costante\nUn’altra prospettiva è chiedersi quante ore servono per raggiungere un certo voto obiettivo. Questo ci permette di valutare l’efficienza temporale dei metodi.\nPartiamo stimando i parametri del modello e fissiamo tre obiettivi di voto:\n\n# Estrazione dei parametri stimati\npars &lt;- c(paste0(\"alpha[\",1:3,\"]\"), paste0(\"beta[\",1:3,\"]\"))\ndraws &lt;- fit$draws(variables = pars, format = \"draws_matrix\") |&gt; as.matrix()\n\n# Obiettivi di voto\nG_targets &lt;- c(75, 80, 85)\nmethod_names &lt;- c(\"classico\", \"AI\", \"gruppo\")\n\nCalcoliamo quindi le ore richieste per ogni obiettivo:\n\n# Funzione: ore necessarie per raggiungere G0\nHreq_fun &lt;- function(G0, alpha, beta) {\n  pmax(exp((G0 - alpha)/beta) - 1, 0)\n}\n\n# Calcoli su tutti i target e metodi\nout &lt;- lapply(G_targets, function(G0) {\n  Hreq_mat &lt;- sapply(1:3, function(k) {\n    alpha_k &lt;- draws[, paste0(\"alpha[\", k, \"]\")]\n    beta_k  &lt;- draws[, paste0(\"beta[\", k, \"]\")]\n    Hreq_fun(G0, alpha_k, beta_k)\n  })\n  colnames(Hreq_mat) &lt;- method_names\n  as_tibble(Hreq_mat) |&gt; mutate(G0 = G0, .draw = row_number())\n}) |&gt; bind_rows()\n\nRiassumiamo i risultati con mediane e intervalli interquartili:\n\nHreq_summary &lt;- out |&gt;\n  pivot_longer(all_of(method_names), names_to = \"metodo\", values_to = \"Hreq\") |&gt;\n  group_by(G0, metodo) |&gt;\n  summarize(\n    mediana = median(Hreq),\n    q25 = quantile(Hreq, 0.25),\n    q75 = quantile(Hreq, 0.75),\n    .groups = \"drop\"\n  )\n\nVisualizziamo i confronti:\n\nggplot(Hreq_summary, aes(x = factor(G0), y = mediana, fill = metodo)) +\n  geom_col(position = position_dodge(width = 0.8)) +\n  geom_errorbar(aes(ymin = q25, ymax = q75),\n                position = position_dodge(width = 0.8),\n                width = 0.2) +\n  labs(x = \"Voto obiettivo (G0)\",\n       y = \"Ore di studio necessarie\\n(mediana con IQR)\",\n       fill = \"Metodo\") \n\n\n\n\n\n\n\n\n80.1.7 Interpretazione\n\n\nEfficienza a parità di ore: il metodo AI tende a produrre voti più alti e quindi maggiore utilità, ma il vantaggio può ridursi se richiede più tempo.\n\nEfficienza a parità di voto: i metodi che necessitano meno ore per raggiungere lo stesso obiettivo sono più efficienti; il grafico mostra chiaramente queste differenze.\n\nIncertezza: gli intervalli interquartili (IQR) indicano che non c’è una separazione netta: alcuni studenti possono ottenere risultati simili con metodi diversi.\n\nIn questo modo, il confronto tra metodi diventa più ricco: non ci fermiamo a dire “chi è il migliore”, ma vediamo in quali condizioni un metodo può risultare più vantaggioso.\n\n80.1.8 Verso modelli più realistici: oltre la funzione di utilità lineare\nLa funzione di utilità lineare qui adottata,\n\\[\nU(g,h;\\lambda) = g - \\lambda h, \\quad \\lambda \\geq 0,\n\\] presenta il pregio di una notevole semplicità interpretativa: ogni ora di studio viene infatti associata a un “costo” costante, pari a \\(\\lambda\\) punti di voto. Tuttavia, questa formulazione poggia su due ipotesi semplificatrici che possono discostarsi dal comportamento effettivo degli studenti. In primo luogo, la linearità nel voto implica che il valore marginale di ciascun punto sia identico a qualsiasi livello della scala di valutazione, equiparando ad esempio il passaggio da 60 a 61 a quello da 90 a 91. In secondo luogo, la linearità nel tempo presuppone che il disagio associato a un’ora aggiuntiva di studio rimanga invariato, indipendentemente dal numero di ore già dedicate.\nQueste assunzioni, sebbene utili in una fase introduttiva, possono risultare limitanti nel momento in cui si desideri cogliere la complessità delle preferenze individuali. È pertanto opportuno considerare alcune estensioni del modello in grado di conferirle maggiore realismo.\nUna prima direzione di sviluppo riguarda l’introduzione di non linearità nella componente relativa al voto. È plausibile, ad esempio, che i voti presentino rendimenti decrescenti, per cui guadagnare punti in prossimità della sufficienza venga percepito come più rilevante che incrementare il punteggio in regioni già elevate della scala. Allo stesso modo, si potrebbero incorporare soglie minime al di sotto delle quali un esito viene considerato inaccettabile, indipendentemente dal tempo investito.\nAnche la relazione tra utilità e tempo potrebbe essere arricchita per riflettere in modo più fedele l’esperienza soggettiva. La fatica associata allo studio tende infatti ad aumentare in modo non lineare con il numero di ore, suggerendo l’adozione di funzioni con esponente (quali \\(h^2\\) o \\(h^{1.5}\\)) in grado di catturare questa progressione.\nUlteriori aspetti rilevanti includono il ruolo degli obiettivi personali, poiché gli studenti potrebbero mostrare avversione alle perdite, attribuendo un peso maggiore al mancato raggiungimento di un traguardo rispetto al superamento dello stesso. Allo stesso modo, la gestione del rischio e dell’incertezza merita particolare attenzione: alcuni individui potrebbero preferire metodi che offrono risultati più stabili, anche se meno brillanti in media, richiedendo quindi di considerare non solo il valore atteso dell’utilità ma anche la sua variabilità o il suo comportamento in scenari sfavorevoli.\nInfine, è importante riconoscere che il trade-off tra voto e tempo può variare notevolmente tra diversi profili di studenti, come nel caso di lavoratori part-time rispetto a studenti a tempo pieno. Modelli gerarchici consentono di stimare tale variabilità individuale preservando al contempo una struttura comune.\nPer un ricercatore che si accinga ad affrontare questo tipo di analisi, si raccomanda un approccio progressivo. È preferibile iniziare con il modello lineare, apprezzabile per la sua trasparenza e facilità di comunicazione, per poi verificare—attraverso un’attenta analisi esplorativa dei dati—l’eventuale presenza di non linearità o altri effetti complessi. Solo in seguito all’identificazione di tali pattern dovrebbe essere contemplata l’introduzione di complessità aggiuntive, sempre nel rispetto di un equilibrio tra realismo e interpretabilità dei risultati.",
    "crumbs": [
      "Decisioni",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Decisione ottimale e utilità attesa: l’approccio bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/decision_analysis/01_study_method.html#riflessioni-conclusive",
    "href": "chapters/decision_analysis/01_study_method.html#riflessioni-conclusive",
    "title": "80  Decisione ottimale e utilità attesa: l’approccio bayesiano",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo esplorato come l’analisi decisionale bayesiana offra un quadro coerente per integrare diverse componenti fondamentali: le previsioni sugli esiti, attraverso distribuzioni predittive che riflettono la nostra incertezza; la formalizzazione delle preferenze, mediante funzioni di utilità che quantificano la desiderabilità dei risultati; e infine un criterio di scelta razionale, rappresentato dalla massimizzazione dell’utilità attesa.\nAbbiamo iniziato con un modello semplice, caratterizzato da una funzione di utilità lineare sia nel voto che nel tempo. Questa scelta, sebbene simplificata, si è rivelata preziosa per introdurre i concetti cardine del metodo: tradurre in valori numerici il grado di soddisfazione associato a diversi esiti, calcolare utilità attese che incorporino l’incertezza predittiva e confrontare in modo sistematico alternative complesse. Successivamente, abbiamo discusso come estendere questo modello per cogliere aspetti più realistici del processo decisionale, come la presenza di rendimenti decrescenti nel voto, costi marginali crescenti del tempo di studio, il ruolo degli obiettivi personali e l’avversione al rischio, nonché la possibile eterogeneità delle preferenze tra individui.\nDal punto di vista applicativo, emerge con chiarezza il valore di un approccio incrementale. È consigliabile iniziare con un modello lineare semplice, che garantisce trasparenza e facilità di comunicazione, per poi verificare empiricamente—attraverso l’analisi dei dati—la validità delle sue assunzioni. Solo qualora emergano evidenze di non linearità, effetti soglia o sensibilità al rischio, ha senso considerare modelli più complessi, sempre mantenendo un attento equilibrio tra realismo e interpretabilità.\nIl vantaggio distintivo dell’approccio bayesiano risiede nella sua capacità di propagare in modo coerente tutte le fonti di incertezza—sui parametri del modello e sulla variabilità degli esiti—fino alla quantificazione dell’utilità attesa. Questo permette non solo di identificare l’opzione mediamente migliore, ma anche di valutare la robustezza di questa conclusione, esprimendo ad esempio la probabilità che una data alternativa sia da preferire.\nIn definitiva, l’analisi decisionale bayesiana si configura non solo come una tecnica per supportare scelte ottimali in condizioni di incertezza, ma anche come una metodologia per rendere esplicito, trasparente e criticabile il processo attraverso cui valutiamo e confrontiamo le alternative a nostra disposizione.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] stringr_1.5.1         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [13] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [16] utf8_1.2.6            rmarkdown_2.29        ps_1.9.1             \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [28] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [31] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [64] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [67] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [70] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [73] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [76] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [79] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [82] MASS_7.3-65",
    "crumbs": [
      "Decisioni",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Decisione ottimale e utilità attesa: l’approccio bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/decision_analysis/01_study_method.html#bibliografia",
    "href": "chapters/decision_analysis/01_study_method.html#bibliografia",
    "title": "80  Decisione ottimale e utilità attesa: l’approccio bayesiano",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Decisioni",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Decisione ottimale e utilità attesa: l’approccio bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html",
    "href": "chapters/missing/01_mnar_stan.html",
    "title": "81  Dati mancanti in psicologia",
    "section": "",
    "text": "Introduzione\nIn molte ricerche psicologiche, i dati mancanti non sono semplicemente “buchi” da riempire, ma possono essere la conseguenza diretta del fenomeno che vogliamo studiare (Little, 2024). Questo significa che l’assenza di una risposta è essa stessa un dato psicologico. Ad esempio:\nIn questi casi, la probabilità che un dato sia osservato dipende dal valore vero non osservato. Questa situazione è definita MNAR – Missing Not At Random e, se ignorata, può produrre stime distorte dei parametri (ad esempio medie più basse del reale, effetti di regressione sottostimati). In pratica: si può concludere che un trattamento funziona quando in realtà non è così, o viceversa.\nIn questo capitolo:",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#introduzione",
    "href": "chapters/missing/01_mnar_stan.html#introduzione",
    "title": "81  Dati mancanti in psicologia",
    "section": "",
    "text": "nei questionari su temi sensibili (come ansia sociale, uso di sostanze, esperienze traumatiche) le persone con punteggi più elevati possono saltare più facilmente alcune domande per evitare disagio emotivo;\nnegli studi EMA (Ecological Momentary Assessment), i partecipanti possono rispondere meno quando sono di cattivo umore, sotto stress o in situazioni socialmente impegnative.\n\n\n\n\nrivedremo le principali tipologie di dati mancanti (MCAR, MAR, MNAR);\nvedremo come riconoscere un caso MNAR nella ricerca psicologica;\nimpareremo a costruire e stimare un modello Bayesiano in Stan per gestire dati MNAR.\n\n\n\n\n\n\n\nMCAR, MAR, MNAR: i tre meccanismi chiave\n\n\n\nQuando analizzi dati mancanti, è fondamentale capire perché mancano. Le principali categorie sono:\n\n\nMCAR (Missing Completely At Random): la probabilità che un dato manchi è indipendente sia dalle variabili osservate sia dal valore mancante.\n\n\nEsempio: in un questionario online, alcune risposte mancano a causa di un problema tecnico che interrompe la connessione.\n\n\n\nMAR (Missing At Random): la probabilità di mancanza dipende solo da variabili osservate (non dal valore mancante), una volta controllato per queste.\n\n\nEsempio: in un test di ansia, i partecipanti più anziani saltano alcune domande, ma conosciamo l’età di tutti.\n\n\n\nMNAR (Missing Not At Random): la probabilità di mancanza dipende dal valore vero mancante, anche dopo aver considerato le variabili osservate.\n\n\nEsempio: in un questionario su sintomi depressivi, chi è più depresso tende a non rispondere a domande su pensieri negativi.\n\n\n\nNota operativa: Ignorare un meccanismo MNAR può portare a stime distorte e a conclusioni errate, specialmente in studi clinici o longitudinali.\n\n\nPanoramica del capitolo\n\nDistinguere tra MCAR, MAR e MNAR e comprendere le implicazioni in psicologia.\nRiconoscere situazioni in cui i dati mancanti non sono casuali (MNAR).\nFormulare un modello Bayesiano per gestire dati MNAR.\nImplementare il modello in Stan e interpretarne i risultati.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nConoscenza di base della probabilità e dell’inferenza Bayesiana.\nFamiliarità con R e pacchetti brms e cmdstanr.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Additional packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, posterior, loo, cmdstanr, stringr, tidyr)\nconflicts_prefer(dslabs::heights)",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#simulazione-di-dati-con-meccanismo-mnar",
    "href": "chapters/missing/01_mnar_stan.html#simulazione-di-dati-con-meccanismo-mnar",
    "title": "81  Dati mancanti in psicologia",
    "section": "\n81.1 Simulazione di dati con meccanismo MNAR",
    "text": "81.1 Simulazione di dati con meccanismo MNAR\nSupponiamo di voler misurare il punteggio di ansia sociale (\\(y\\)) in un campione di partecipanti. Nella popolazione, ipotizziamo che \\(y\\) segua una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\nPer semplificare i calcoli, standardizziamo la variabile:\n\\[\ny_z = \\frac{y - 50}{10} \\quad \\Rightarrow \\quad y_z \\sim \\mathcal{N}(0, 1)\n\\]\nOra modelliamo una situazione comune nella ricerca psicologica: le persone con ansia sociale più elevata tendono a evitare a rispondere al questionario, lasciando più risposte mancanti.\nIl comportamento di evitamento è formalizzato attraverso un modello di selezione (selection model) di tipo logistico, che specifica la probabilità condizionata di osservazione del dato nel modo seguente:\n\\[\n\\Pr(R_i = 1 \\mid y_i) = \\text{logit}^{-1}(\\alpha + \\beta\\, y_i) .\n\\tag{81.1}\\]\nDefinizione formale delle componenti del modello:\n\n\nVariabile di risposta latente:\\(R_i \\in \\{0,1\\}\\) è una variabile binaria latente che modella il processo di osservazione, dove:\n\n\n\\(R_i = 1\\) indica che l’osservazione \\(y_i\\) è osservabile (il partecipante ha fornito una risposta valida);\n\n\n\\(R_i = 0\\) denota un dato mancante (mancata risposta del partecipante).\n\n\n\nParametro \\(\\beta\\) e meccanismo di missingness:\nLa relazione tra \\(y_i\\) e \\(\\Pr(R_i = 1 \\mid y_i)\\) è governata dal parametro \\(\\beta\\):\n\nSe \\(\\beta &lt; 0\\): sussiste un meccanismo di missingness non ignorabile (MNAR) con dipendenza negativa monotona. Valori più elevati di \\(y_i\\) riducono la probabilità di osservazione, indicando un pattern di evitamento selettivo (es. partecipanti con sintomi di ansia sociale più severi tendono ad evitare di rispondere).\n\nSe \\(\\beta &gt; 0\\): il missingness è ancora MNAR, ma con dipendenza positiva monotona. Valori elevati di \\(y_i\\) aumentano la probabilità di osservazione (es. partecipanti con maggiore ansia sociale hanno maggiore propensione a rispondere).\n\nSe \\(\\beta = 0\\): la probabilità di osservazione è indipendente da \\(y_i\\), soddisfacendo l’ipotesi di Missing Completely at Random (MCAR).\n\n\n\nNota: l’esempio qui discusso riflette un tipico caso MNAR, in cui la probabilità di osservare il dato dipende direttamente dal valore vero della variabile di interesse.\nGeneriamo un dataset sintetico di \\(N\\) = 1000 unità statistiche, dove il meccanismo di missingness segue un modello di selezione logistico con parametri:\n\nintercetta (\\(\\alpha\\)) = 0,\neffetto della variabile risposta (\\(\\beta\\)) = -2.0.\n\n\nset.seed(1234)   \n\nN          &lt;- 1000\nalpha_true &lt;- 0\nbeta_true  &lt;- -2.0\n\ny_true &lt;- rnorm(N, 0, 1)\np_obs  &lt;- plogis(alpha_true + beta_true * y_true)\nR      &lt;- rbinom(N, 1, p_obs)\ny_obs  &lt;- ifelse(R == 1, y_true, NA_real_)\n\ntbl &lt;- tibble(y_true, R, y_obs, p_obs)\nmean(R)\n#&gt; [1] 0.501\nmean(is.na(y_obs))\n#&gt; [1] 0.499\n\n\n81.1.1 Analisi del bias indotto da MNAR\n\nsumm &lt;- tibble(\n  grandezza = c(\"Media\", \"Varianza\"),\n  vero      = c(mean(tbl$y_true), var(tbl$y_true)),\n  osservato = c(mean(tbl$y_obs, na.rm = TRUE), var(tbl$y_obs, na.rm = TRUE))\n)\nprint(summ)\n#&gt; # A tibble: 2 × 3\n#&gt;   grandezza    vero osservato\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Media     -0.0266    -0.594\n#&gt; 2 Varianza   0.995      0.663\n\nI dati evidenziando una sottostima sistematica dovuta al meccanismo MNAR.\n\n81.1.2 Visualizzazione degli effetti di selezione\nVisualizziamo ora la probabilità di osservazione in funzione del valore vero e confrontiamo la distribuzione dei valori veri con quella dei valori osservati, escludendo i valori mancanti.\n\n# 1) Probabilità di osservazione in funzione del valore vero\np1 &lt;- ggplot(tbl, aes(x = y_true, y = p_obs)) +\n  geom_point(alpha = 0.20) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  labs(\n    title = \"MNAR: Pr(R=1 | y)\",\n    x = \"y (vero, scala z)\", y = \"Pr(R=1 | y)\"\n  ) \n\n# 2) Distribuzione dei valori veri, con linea su media=0\np2 &lt;- ggplot(tbl, aes(x = y_true)) +\n  geom_histogram(aes(y = ..density..), bins = 30, alpha = 0.35) +\n  geom_density() +\n  geom_vline(xintercept = mean(tbl$y_true), linetype = 2) +\n  labs(\n    title = \"Distribuzione dei valori veri\",\n    x = \"y (vero, scala z)\", y = \"Densità\"\n  ) \n\n# 3) Distribuzione dei valori osservati (cond. a R=1), con linea su media osservata\np3 &lt;- ggplot(filter(tbl, R == 1), aes(x = y_obs)) +\n  geom_histogram(aes(y = ..density..), bins = 30, alpha = 0.35) +\n  geom_density() +\n  geom_vline(xintercept = mean(tbl$y_obs, na.rm = TRUE), linetype = 2) +\n  labs(\n    title = \"Distribuzione dei valori osservati (R=1)\",\n    x = \"y osservato\", y = \"Densità\"\n  ) \n\np1; p2; p3\n\n\n\nMNAR: probabilità di osservazione e distribuzioni ‘vero’ vs ‘osservato’.\n\n\n\n\n\nMNAR: probabilità di osservazione e distribuzioni ‘vero’ vs ‘osservato’.\n\n\n\n\n\nMNAR: probabilità di osservazione e distribuzioni ‘vero’ vs ‘osservato’.\n\n\n\nMessaggio chiave. La selezione MNAR fa sì che i dati osservati non rappresentino la popolazione: nei grafici si vede che la probabilità di osservazione diminuisce con y e che la distribuzione degli osservati è spostata rispetto a quella dei veri.\nConseguenza: le analisi che ignorano il meccanismo (vedi Modello 1) tendono a stimare una media distorta e/o una varianza alterata.",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#modello-1-outcome-only-ignora-il-meccanismo",
    "href": "chapters/missing/01_mnar_stan.html#modello-1-outcome-only-ignora-il-meccanismo",
    "title": "81  Dati mancanti in psicologia",
    "section": "\n81.2 Modello 1 — Outcome-only (ignora il meccanismo)",
    "text": "81.2 Modello 1 — Outcome-only (ignora il meccanismo)\nIn questo modello assumiamo che la variabile osservata \\(y\\) (su scala z) segua:\n\\[\ny \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]\ncon aspettative \\(\\mu \\approx 0\\) e \\(\\sigma \\approx 1\\).\nI valori mancanti vengono trattati come parametri latenti e stimati direttamente1, senza modellare la variabile \\(R\\) che indica la risposta. In pratica, stiamo assumendo implicitamente che i dati mancanti siano MCAR (completamente a caso) o MAR (a caso dato il modello).\n\n81.2.1 Intuizione operativa\n\nIl modello stima i valori mancanti “come se” fossero assenti in modo casuale, basandosi solo sulla distribuzione di \\(y\\).\nSe i dati sono in realtà MNAR, le stime di parametri chiave come \\(\\mu\\) possono risultare sistematicamente distorte.\nQuesto approccio è utile come baseline per confrontare l’effetto di modelli più realistici che tengono conto del meccanismo di mancanza.\n\n81.2.2 Codice Stan (outcome-only)\n\n# Modello Stan: Outcome-only (ignora R)\n# Tratta i mancanti come latenti e assume MCAR/MAR\n\nstan_ignore &lt;- '\ndata {\n  int&lt;lower=0&gt; N_obs;             // Numero di osservazioni\n  int&lt;lower=0&gt; N_mis;             // Numero di valori mancanti\n  array[N_obs] real y_obs;        // Valori osservati\n}\nparameters {\n  real mu;                        // Media della distribuzione\n  real&lt;lower=0&gt; sigma;            // Deviazione standard\n  array[N_mis] real y_mis;        // Valori mancanti (stimati)\n}\nmodel {\n  // Priors\n  mu    ~ normal(0, 1);\n  sigma ~ normal(1, 0.5);\n  \n  // Likelihood per dati osservati\n  y_obs ~ normal(mu, sigma);\n  \n  // Likelihood per dati mancanti (uguale agli osservati)\n  y_mis ~ normal(mu, sigma);\n}\ngenerated quantities {\n  real y_mean = mu;               // Stima della media\n  real y_sd   = sigma;             // Stima della deviazione standard\n}\n'\nwriteLines(stan_ignore, \"ignore_mnar.stan\")\n\n\n# Prepara i dati per Stan\ny_obs_vec &lt;- tbl$y_obs[!is.na(tbl$y_obs)]\nN_obs     &lt;- length(y_obs_vec)                 # numero osservazioni\nN_mis     &lt;- sum(is.na(tbl$y_obs))              # numero mancanti\n\ndata_ignore &lt;- list(\n  N_obs = N_obs,\n  N_mis = N_mis,\n  y_obs = y_obs_vec\n)\n\nStima:\n\nmod_ignore &lt;- cmdstan_model(\"ignore_mnar.stan\")\n\n\n# Stima Bayesiana\nfit_ignore &lt;- mod_ignore$sample(\n  data = data_ignore, seed = 11,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1500, iter_sampling = 2000,\n  adapt_delta = 0.99, max_treedepth = 14\n)\n\nRiassunto dei parametri stimati:\n\nsumm_ignore &lt;- fit_ignore$summary(variables = c(\"mu\", \"sigma\"))\n\n\n81.2.3 Modello 2 — Selection Model (per dati MNAR esplicito)\nIl Selection Model è un approccio per modellare dati Mancanti Non In Modo Casuale (MNAR), in cui la probabilità che un dato sia osservato (missingness) dipende dal valore (mancante o osservato) della variabile stessa \\(y\\).\nQuesto legame è modellato esplicitamente attraverso un parametro, indicato come \\(\\beta\\), all’interno di un modello di regressione logistica che regola la probabilità di osservazione \\(R\\).\n\n81.2.3.1 Interpretazione del parametro beta\nIl coefficiente \\(\\beta\\) quantifica la direzione e l’intensità della dipendenza tra \\(y\\) e la probabilità di essere osservato:\n\n\n\\(\\beta &gt; 0\\) (Positivo): Valori più alti di \\(y\\) hanno una maggiore probabilità di essere osservati.\n\n\\(\\beta &lt; 0\\) (Negativo): Valori più alti di \\(y\\) hanno una minore probabilità di essere osservati. Questo è uno scenario comune, noto come avoidance (es. in un questionario sul reddito, gli individui con entrate molto alte potrebbero essere più reticenti a rispondere).\n\n\\(\\beta = 0\\): La probabilità di osservazione non dipende da \\(y\\). In questo caso, il meccanismo di missingness ricade nelle categorie MCAR o MAR (condizionatamente ad altre covariate nel modello).\n\nEsempio: Se \\(y\\) rappresenta il punteggio di depressione, un \\(\\beta\\) negativo indica che all’aumentare della sintomatologia depressiva (valore di \\(y\\) più alto), la probabilità di rispondere al questionario diminuisce. Questo è un tipico caso di MNAR.\n\n81.2.3.2 L’idea fondamentale del modello\nL’approccio del Selection Model combina due componenti in un unico modello statistico:\n\n\nModello dei dati: Un modello che descrive la distribuzione della variabile di interesse \\(y\\) (es. un modello lineare: \\(y_i \\sim N(\\mu_i, \\sigma^2)\\)).\n\nModello della selezione (missingness): Un modello (es. regressione logistica) che descrive la probabilità che \\(y\\) sia osservato in funzione del suo stesso valore: \\(\\text{logit}(P(R_i = 1)) = \\alpha + \\beta y_i\\).\n\nLa soluzione elegante e potente di questo framework è di trattare i valori mancanti \\(y_{\\text{mis}}\\) non come semplici “assenti”, ma come parametri latenti da stimare simultaneamente al modello. In questo modo, per ogni unità statistica, il modello di selezione “vede” e utilizza il valore di \\(y\\) (osservato o stimato) per determinare la probabilità di osservazione.\n\n81.2.3.3 Nota sull’interpretazione e sulla scala\nNel modello di selezione logistico, \\(\\beta\\) si interpreta sulla scala logit: un incremento di una unità in \\(y\\) è associato a una variazione di \\(\\beta\\) unità nel log-odds di osservazione.\nPer facilitare l’interpretazione e rendere la scelta di una distribuzione a priori per \\(\\beta\\) più sensata e generalizzabile, è fortemente consigliato centrare e scalare la variabile \\(y\\). In questo modo, \\(\\beta\\) rappresenterà l’effetto di uno scostamento di un deviazione standard dalla media, rendendo il parametro più confrontabile tra diversi studi e diverse variabili.\n\n81.2.4 Modello 2A — Incorporare una prior informativa sul parametro beta\nIl Modello 2A estende il Selection Model base introducendo una distribuzione a priori informativa sul parametro chiave \\(\\beta\\). Ricordiamo che \\(\\beta\\) quantifica il legame tra il valore della variabile \\(y\\) e la probabilità che questo venga osservato.\nMentre nel selection model potevamo usare una prior vaga (es. \\(\\beta \\sim N(0, 100)\\)), in questo scenario vogliamo incorporare nella nostra analisi una conoscenza pregressa credibile sul probabile meccanismo di missingness.\nGiustificazione per l’uso di una prior informativa\nNel nostro esempio simulato, il meccanismo è costruito per essere MNAR con un \\(\\beta\\) negativo. Anche in contesti reali, spesso possiamo formulare ipotesi teoriche robuste su questo meccanismo:\n\n\nIn psicologia: Soggetti con sintomatologia molto elevata (valori alti di \\(y\\) in scale di depressione o ansia) potrebbero avere una minore probabilità di completare un questionario.\n\nIn economia: Individui con redditi molto alti o molto bassi potrebbero essere più reticenti a rivelare le proprie finanze.\n\nQueste ipotesi si traducono in un’aspettativa sulla direzione (segno di \\(\\beta\\)) e su un intervallo plausibile di valori per la sua grandezza.\nVantaggi di questo approccio:\n\n\nMaggior Stabilità e Identificabilità: La stima del parametro \\(\\beta\\) in un selection model può essere spesso instabile, specialmente con campioni piccoli o quando il pattern di dati mancanti è limitato. Una prior informativa agisce da “regolarizzatore”, ancorando la stima a un valore plausibile e prevenendo conclusioni estreme o erratiche guidate dal rumore nei dati.\n\nIncorporazione Trasparente della Conoscenza: Questo approccio ci permette di integrare in modo esplicito e quantificabile evidenza precedente (di letteratura o teorica) all’interno del nostro modello, spostandoci da un’analisi puramente guidata dai dati a una analisi guidata da dati e teoria.\n\nIn sintesi, il Modello 2A rappresenta una strategia analitica più sofisticata e potente. Non ci limitiamo a chiedere ai dati “C’è un effetto MNAR?” usando un’ipotesi neutra (prior vaga). Piuttosto, chiediamo: “Alla luce della nostra convinzione che il meccanismo sia MNAR con un effetto negativo di una certa entità, cosa ci dicono i dati?”. Questo rende l’analisi più robusta e teoricamente fondata.\nCodice Stan:\n\nstan_selection_inf &lt;- '\ndata {\n  int&lt;lower=0&gt; N_obs;\n  int&lt;lower=0&gt; N_mis;\n  int&lt;lower=0&gt; N_total;\n  array[N_obs] real y_obs;\n  array[N_total] int&lt;lower=0,upper=1&gt; R;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n  array[N_mis] real y_mis;\n  real alpha;\n  real beta;\n}\ntransformed parameters {\n  array[N_total] real y_all;\n  for (n in 1:N_obs)   y_all[n] = y_obs[n];\n  for (n in 1:N_mis)   y_all[N_obs + n] = y_mis[n];\n}\nmodel {\n  // Priors ancoranti su outcome (scala nota) + informativa su beta\n  mu    ~ normal(0, 0.3);\n  sigma ~ normal(1, 0.2) T[0,];\n  alpha ~ normal(0, 1);\n  beta  ~ normal(-1.5, 0.5);\n\n  // Outcome\n  y_obs ~ normal(mu, sigma);\n  y_mis ~ normal(mu, sigma);\n\n  // Selection\n  for (n in 1:N_total)\n    R[n] ~ bernoulli_logit(alpha + beta * y_all[n]);\n}\ngenerated quantities {\n  real y_mean = mu;\n  real y_sd   = sigma;\n}\n'\nwriteLines(stan_selection_inf, \"selection_mnar_informative.stan\")\n\nDati:\n\nN_obs   &lt;- sum(!is.na(tbl$y_obs))\nN_mis   &lt;- sum(is.na(tbl$y_obs))\nN_total &lt;- nrow(tbl)\n\ndata_sel &lt;- list(\n  N_obs   = N_obs,\n  N_mis   = N_mis,\n  N_total = N_total,\n  y_obs   = y_obs_vec,\n  R       = as.integer(tbl$R)\n)\n\nCompilazione del modello:\n\nmod_sel_inf &lt;- cmdstan_model(\"selection_mnar_informative.stan\")\n\nCampionamento:\n\n# Stima Bayesiana\nfit_sel_inf &lt;- mod_sel_inf$sample(\n  data = data_sel, seed = 33,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1500, iter_sampling = 2000,\n  adapt_delta = 0.99, max_treedepth = 14\n)\n\nRiassunto dei parametri principali:\n\nsumm_sel_inf &lt;- fit_sel_inf$summary(variables = c(\"mu\",\"sigma\",\"alpha\",\"beta\"))\n\n\n81.2.5 Modello 2B — Uno studio di robustezza: Prior ampia su beta con outcome ancorato\nIl Modello 2B è progettato come uno studio di robustezza e sensibilità per testare la forza del segnale MNAR presente nei dati. Combina strategicamente due scelte opposte riguardo le prior:\n\n\nUna prior fortemente informativa sui parametri della distribuzione di \\(y\\) (\\(\\mu\\) e \\(\\sigma\\)).\n\nUna prior ampia e neutrale sul parametro del meccanismo MNAR (\\(\\beta\\)).\n\n1. Ancoraggio della scala dell’outcome: Assumiamo a priori che la variabile \\(y\\) sia già standardizzata, imponendo dei forti vincoli bayesiani: * Media (\\(\\mu\\)): \\(\\sim \\mathcal{N}(0, 0.2)\\) * Interpretazione: Siamo molto certi che la vera media della popolazione sia vicina a 0. * Deviazione Standard (\\(\\sigma\\)): \\(\\sim \\mathcal{N}(1, 0.1)\\) (troncata ai positivi) * Interpretazione: Siamo molto certi che la vera deviazione standard sia vicina a 1.\n2. Prior neutrale sul meccanismo MNAR: Sul parametro cruciale \\(\\beta\\) usiamo invece una prior deliberatamente ampia e neutrale: * Effetto MNAR (\\(\\beta\\)): \\(\\sim \\mathcal{N}(0, 2)\\) * Interpretazione: Pur ipotizzando che l’effetto più plausibile sia nullo (priore centrata su 0), ammettiamo un’ampia gamma di valori sia positivi che negativi come possibili. Il dato ha massima libertà di rivelarci la direzione e l’intensità del vero meccanismo.\n\n81.2.5.1 La logica strategica del modello 2B\nQuesta combinazione apparentemente contraddittoria ha uno scopo preciso: isolare e testare il segnale del meccanismo MNAR.\n\nPerché ancorare \\(\\mu\\) e \\(\\sigma\\)? L’incertezza sulla posizione e sulla scala della distribuzione sottostante \\(y\\) è intrinsecamente legata alla stima di \\(\\beta\\). “Bloccando” strategicamente \\(\\mu\\) e \\(\\sigma\\) a valori plausibili, riduciamo il rumore nel modello. Questo impedisce che l’incertezza su questi parametri “contagini” e oscuri la stima di \\(\\beta\\), permettendoci di vedere più chiaramente l’effetto che i dati hanno su di esso.\nPerché usare una prior ampia su \\(\\beta\\)? È un atto di umiltà epistemologica. Stiamo dicendo: “So già come è fatta la distribuzione di y (perché l’ho standardizzata), ma non voglio pregiudicare la direzione o l’esistenza del meccanismo mancante. Voglio che siano i dati, il più liberamente possibile, a dimostrarmi se c’è un effetto MNAR e quanto è forte.”\n\nIn sintesi, il Modello 2B risponde a una domanda cruciale:\n\n“Se rimuoviamo il supporto di un’ipotesi teorica forte (la prior informativa del Modello 2A) e controlliamo per altre fonti di incertezza, il segnale MNAR nei dati è ancora sufficientemente robusto da emergere da solo?”\n\n\nstan_sel_wide &lt;- '\ndata {\n  int&lt;lower=0&gt; N_obs;\n  int&lt;lower=0&gt; N_mis;\n  int&lt;lower=0&gt; N_total;\n  array[N_obs] real y_obs;\n  array[N_total] int&lt;lower=0,upper=1&gt; R;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n  array[N_mis] real y_mis;\n  real alpha;\n  real beta;\n}\nmodel {\n  // Priors: outcome fortemente ancorato (scala z), beta ampia\n  mu    ~ normal(0, 0.2);\n  sigma ~ normal(1, 0.1) T[0,];\n  alpha ~ normal(0, 2);\n  beta  ~ normal(0, 2);\n\n  // Outcome\n  y_obs ~ normal(mu, sigma);\n  y_mis ~ normal(mu, sigma);\n\n  // Selection con indicizzazione corretta\n  {\n    int i_obs = 1;\n    int i_mis = 1;\n    for (n in 1:N_total) {\n      real y_n = (R[n] == 1) ? y_obs[i_obs] : y_mis[i_mis];\n      R[n] ~ bernoulli_logit(alpha + beta * y_n);\n      if (R[n] == 1) i_obs += 1; else i_mis += 1;\n    }\n  }\n}\ngenerated quantities {\n  real y_mean = mu;\n  real y_sd   = sigma;\n}\n'\nwriteLines(stan_sel_wide, \"selection_mnar_wide.stan\")\n\n\nmod_sel_wide &lt;- cmdstan_model(\"selection_mnar_wide.stan\")\n\n\nfit_sel_wide &lt;- mod_sel_wide$sample(\n  data = data_sel, seed = 33,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 2500, iter_sampling = 3000,\n  adapt_delta = 0.999, max_treedepth = 20\n)\n\n\nsumm_sel_wide &lt;- fit_sel_wide$summary(variables = c(\"mu\",\"sigma\",\"alpha\",\"beta\"))",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#scelte-dei-prior-e-loro-razionale",
    "href": "chapters/missing/01_mnar_stan.html#scelte-dei-prior-e-loro-razionale",
    "title": "81  Dati mancanti in psicologia",
    "section": "\n81.3 Scelte dei prior e loro razionale",
    "text": "81.3 Scelte dei prior e loro razionale\nLe differenze tra i tre modelli non riguardano solo la parte di likelihood, ma soprattutto le scelte di prior, che riflettono ipotesi diverse sulla natura del meccanismo di mancanza e sulla scala dell’outcome. Qui riassumiamo il razionale di ciascun modello.\n\n\n\n\n\n\n\n\n\nModello\nPrior su \\(\\mu\\) e \\(\\sigma\\)\n\nPrior su \\(\\beta\\)\n\nRazionale\nAttese sulle stime\n\n\n\nOutcome-only\nLarghe (nessun ancoraggio)\nNessuna (\\(\\beta\\) assente)\nTest di riferimento: stimiamo \\(\\mu\\) e \\(\\sigma\\) ignorando il meccanismo di mancanza\nPossibile bias se i dati sono MNAR\n\n\n2A — Prior informativa su \\(\\beta\\)\nLarghe (nessun ancoraggio)\nInformativa centrata su valore negativo plausibile\nIncorporiamo conoscenza teorica/empirica sul segno e l’ordine di grandezza di \\(\\beta\\)\n\nStima di \\(\\beta\\) più stabile e intervalli credibili più stretti\n\n\n\n2B — Prior ampia su \\(\\beta\\) e outcome ancorato\nFortemente ancorate (\\(\\mu\\)≈0, \\(\\sigma\\)≈1)\nAmpia, \\(\\mathcal{N}(0, 2)\\)\n\nL’ancoraggio rende interpretabile \\(\\beta\\) in unità di deviazione standard; prior ampia per lasciare ai dati il compito di “dire la verità”\nStima di \\(\\beta\\) simile a 2A se i dati sono informativi, ma con intervalli più ampi\n\n\n\n\n\n81.3.1 Perché ancorare mu e sigma nel modello 2B?\nNon è un trucco per “facilitare” la stima, ma una scelta metodologica per fissare una scala interpretabile. Se \\(y\\) non è centrato e scalato, una stessa prior su \\(\\beta\\) può implicare effetti molto diversi nella probabilità di osservazione. Con \\(\\mu\\)≈0 e \\(\\sigma\\)≈1, \\(\\beta\\) è interpretabile come variazione nel log-odds associata a 1 deviazione standard di \\(y\\). Questo permette anche di confrontare \\(\\beta\\) tra studi diversi.\n\n81.3.2 Confronto visivo tra le prior di beta\nRicordiamo che \\(\\beta\\) controlla la pendenza della relazione logit tra il valore dell’outcome \\(y\\) e la probabilità di osservarlo (\\(R=1\\)):\n\n\n\\(\\beta\\) &lt; 0 → i valori più alti di \\(y\\) hanno minore probabilità di essere osservati;\n\n\\(\\beta\\) &gt; 0 → i valori più bassi di \\(y\\) hanno minore probabilità di essere osservati;\n\n\\(\\beta\\) ≈ 0 → la probabilità di osservazione non dipende da \\(y\\) (MAR condizionato).\n\nNello scenario simulato sappiamo che il meccanismo MNAR “vero” ha \\(\\beta\\) negativo: più alto è \\(y\\), più è probabile che manchi.\nLe due versioni del selection model adottano ipotesi molto diverse su \\(\\beta\\):\n\ndf_beta &lt;- bind_rows(\n  data.frame(beta = rnorm(5000, mean = -0.5, sd = 0.3), model = \"2A — Informativa\"),\n  data.frame(beta = rnorm(5000, mean = 0, sd = 2), model = \"2B — Ampia\")\n)\n\nggplot(df_beta, aes(x = beta, fill = model)) +\n  geom_density(alpha = 0.5) +\n  labs(x = expression(beta), y = \"Densità\")\n\n\n\n\n\n\n\n\nLa prior informativa del modello 2A concentra la probabilità su valori negativi plausibili, fornendo una “spinta” teorica verso l’effetto atteso.\nLa prior ampia del modello 2B, invece, consente valori molto più estremi, sia positivi che negativi, lasciando al dato quasi tutta la responsabilità di informare \\(\\beta\\).\n\nMessaggio didattico: confrontare i risultati di 2A e 2B ci permette di capire quanto le nostre assunzioni a priori influenzano la stima e se, in presenza di un segnale forte nei dati, il modello riesce a recuperare comunque il meccanismo MNAR.\n\n81.3.3 Confronto delle stime e interpretazione\nConfrontiamo i parametri chiave (media e deviazione standard) dei tre modelli con i valori veri della simulazione.\nCosa ci aspettiamo di vedere:\n\n\nOutcome-only: bias negativo su \\(\\mu\\) e sottostima di \\(\\sigma\\), perché i valori alti di \\(y\\) sono sottorappresentati.\n\n2A: recupero di \\(\\mu\\) e \\(\\sigma\\) vicino ai valori veri, con \\(\\beta\\) stimato negativo e intervalli più stretti grazie alla prior informativa.\n\n2B: recupero simile a 2A, ma con intervalli più ampi su \\(\\beta\\) e, in parte, su \\(\\mu\\), perché il modello non riceve “spinta” a priori.\n\n\nsumm_ignore\n#&gt; # A tibble: 2 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       -0.594 -0.594 0.036 0.037 -0.654 -0.534 1.000 6441.291 6124.541\n#&gt; 2 sigma     0.817  0.816 0.026 0.025  0.776  0.860 1.000 3383.988 4952.439\n\n\nsumm_sel_inf\n#&gt; # A tibble: 4 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       -0.585 -0.585 0.036 0.036 -0.644 -0.525 1.001 6056.094 6409.331\n#&gt; 2 sigma     0.819  0.818 0.026 0.025  0.777  0.864 1.001 4187.940 5424.535\n#&gt; 3 alpha    -0.019 -0.019 0.092 0.094 -0.168  0.129 1.001 6587.785 5973.368\n#&gt; 4 beta     -0.038 -0.039 0.110 0.109 -0.219  0.141 1.001 4943.585 5281.031\n\n\nsumm_sel_wide\n#&gt; # A tibble: 4 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu        0.047  0.050 0.092 0.091 -0.106  0.190 1.007  706.333 1072.859\n#&gt; 2 sigma     1.038  1.038 0.058 0.058  0.941  1.132 1.008  776.091 1299.449\n#&gt; 3 alpha     0.142  0.125 0.211 0.210 -0.174  0.512 1.005  780.470 1495.664\n#&gt; 4 beta     -2.097 -2.094 0.362 0.351 -2.685 -1.513 1.005  833.017 1098.853\n\nNel grafico seguente visualizziamo gli intervalli (90%) per \\(\\mu\\) e \\(\\sigma\\), con le linee tratteggiate ai valori veri per il Modello 1 e il Modello 2B.\n\nsumm_mu_sigma &lt;- function(fit, model_label) {\n  posterior::summarise_draws(\n    posterior::as_draws_df(fit$draws(variables = c(\"mu\", \"sigma\"))),\n    mean = ~mean(.x),\n    q5   = ~posterior::quantile2(.x, 0.05),\n    q95  = ~posterior::quantile2(.x, 0.95)\n  ) |&gt;\n    dplyr::transmute(model = model_label, variable, mean, q5, q95)\n}\n\ns_ignore &lt;- summ_mu_sigma(fit_ignore,   \"Outcome-only\")\ns_wide   &lt;- summ_mu_sigma(fit_sel_wide, \"Selection (beta ampia, outcome ancorato)\")\n\nplot_tbl &lt;- bind_rows(s_ignore, s_wide) |&gt;\n  mutate(model = factor(model,\n    levels = c(\"Outcome-only\",\n               \"Selection (beta ampia, outcome ancorato)\")))\n\nplot_param &lt;- function(tbl, param_name, label_y) {\n  df &lt;- filter(tbl, variable == param_name)\n  truth_val   &lt;- if (param_name == \"mu\") 0 else 1\n  param_label &lt;- if (param_name == \"mu\") \"Media (mu, z)\" else \"Dev. Std (sigma, z)\"\n\n  ggplot(df, aes(x = model, y = mean)) +\n    geom_pointrange(aes(ymin = q5, ymax = q95)) +\n    geom_hline(yintercept = truth_val, linetype = 2) +\n    labs(title = paste(\"Stime di\", param_label), x = NULL, y = label_y) +\n    coord_flip()\n}\n\ng_mu    &lt;- plot_param(plot_tbl, \"mu\",    \"Media posteriore (90% CI)\")\ng_sigma &lt;- plot_param(plot_tbl, \"sigma\", \"Deviazione standard posteriore (90% CI)\")\n\n\ng_mu\n\n\n\n\n\n\n\n\ng_sigma\n\n\n\n\n\n\n\n\n81.3.4 Lettura dei risultati\n\nOutcome-only. Il modello che ignora il meccanismo di selezione fornisce una stima di \\(\\mu\\) fortemente distorta verso il basso (–0.65 contro il valore vero vicino a 0). Questo accade perché i dati osservati provengono in prevalenza da valori bassi della variabile, e l’assenza di correzione porta a una sottostima sistematica. Anche \\(\\sigma\\) è sottostimata (0.80 vs valore vero ≈ 1), segnalando che la variabilità complessiva è sottorappresentata.\nSelection MNAR con prior informativa su \\(\\beta\\). L’inclusione esplicita del meccanismo di selezione riduce fortemente il bias su \\(\\mu\\) (–0.11) e riporta \\(\\sigma\\) vicino al valore vero (0.99). Come atteso, \\(\\beta\\) viene stimato negativo (–1.81), coerente con la simulazione in cui la probabilità di osservare un valore diminuisce quando \\(y\\) cresce. L’incertezza però aumenta, perché il modello deve stimare anche i parametri del processo di selezione.\nSelection MNAR con prior ampia su \\(\\beta\\) e outcome ancorato. Anche con prior meno informativa su \\(\\beta\\) la stima di \\(\\mu\\) resta vicina a 0 (–0.038) e \\(\\sigma\\) è in linea con il valore vero (1.015). \\(\\beta\\) è di nuovo negativo (–2.04), indicando un effetto di selezione forte, ma qui il modello ha potuto stimarlo senza vincoli forti a priori. L’ancoraggio dell’outcome ha contribuito a contenere il bias pur lasciando ampio margine di apprendimento dai dati.\n\nIn sintesi: ignorare il meccanismo MNAR produce bias sostanziale su media e varianza. Includere un modello di selezione, anche con prior ampie, consente di recuperare stime molto più vicine ai valori veri, a costo di intervalli di credibilità più ampi e maggiore incertezza sui parametri.",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#identificabilità-scaling-e-scelte-di-prior",
    "href": "chapters/missing/01_mnar_stan.html#identificabilità-scaling-e-scelte-di-prior",
    "title": "81  Dati mancanti in psicologia",
    "section": "\n81.4 Identificabilità, scaling e scelte di prior",
    "text": "81.4 Identificabilità, scaling e scelte di prior\nI modelli MNAR, in particolare i selection models, non sono “gratuiti” in termini di informazione: stimare il meccanismo di mancanza richiede struttura e segnali nei dati.\n\n\nIdentificabilità: con campioni piccoli o con un meccanismo di mancanza debole, \\(\\beta\\) può essere stimato con grande incertezza.\n\nScaling: centrare e scalare \\(y\\) facilita l’assegnazione di prior interpretabili a \\(\\beta\\) (ad esempio normal(0,1)), rendendo la scala dei parametri coerente con l’interpretazione.\n\nScelte di prior: priors debolmente informative su \\(\\mu\\) e \\(\\sigma\\), coerenti con la scala dei dati; su \\(\\alpha\\) e \\(\\beta\\), priors compatibili con la plausibilità teorica del fenomeno.\n\nVariabili ausiliarie: se disponibili, includere misure correlate o precedenti che riducano la dipendenza tra \\(y\\) e il meccanismo di mancanza. Questo può “spostare” il problema verso MAR condizionato e migliorare l’identificabilità.\n\n\n\n\n\n\n\nSuggerimento pratico: confronta più specificazioni (prior diverse, con/senza variabili ausiliarie) e documenta l’impatto sulle stime di interesse. La trasparenza sulle assunzioni è parte integrante dell’inferenza.\n\n\n\n\n81.4.1 Interpretazione dei risultati alla luce della teoria MNAR\nNella simulazione, il vero valore dell’outcome standardizzato è \\(\\mu\\) = 0 (media) e \\(\\sigma\\) = 1 (deviazione standard), e il meccanismo di mancanza è MNAR con \\(\\beta\\) &lt; 0: i valori alti di \\(y\\) hanno minore probabilità di essere osservati.\n\n81.4.2 Comportamento dei modelli\n\n\n\n\n\n\n\n\nModello\nStima \\(\\mu\\)\n\nStima \\(\\sigma\\)\n\nRelazione con il vero valore\n\n\n\nOutcome-only\nDistorto verso il basso\nDistorto verso l’alto\nIgnorando il meccanismo MNAR, \\(\\mu\\) sottostima la media reale (perché i valori alti mancano più spesso), e \\(\\sigma\\) è sovrastimata (perché la variabilità residua è gonfiata)\n\n\n2A — Prior informativa\nVicino al valore vero\nVicino al valore vero\nLa prior su \\(\\beta\\) aiuta a correggere il bias e a recuperare le stime corrette di \\(\\mu\\) e \\(\\sigma\\)\n\n\n\n2B — Prior ampia + outcome ancorato\n\nVicino al valore vero (ma con CI più ampia)\n\nVicino al valore vero (ma con CI più ampia)\nL’ancoraggio di \\(\\mu\\) e \\(\\sigma\\) rende interpretabile \\(\\beta\\); senza prior informativa, l’incertezza è maggiore ma il segnale dei dati basta a recuperare il meccanismo\n\n\n\n81.4.3 Perché ha senso teoricamente?\n\n\nModello Outcome-only: il meccanismo MNAR non è modellato → stimatore biased. In teoria MNAR, ignorare la dipendenza di \\(R\\) da \\(y\\) porta a stime distorte di parametri descrittivi dell’outcome.\n\nModello 2A: la prior informativa su \\(\\beta\\) fornisce una “stampella” teorica → correzione del bias anche con pochi dati o segnale debole.\n\nModello 2B: la prior ampia su \\(\\beta\\), combinata con \\(\\mu\\) e \\(\\sigma\\) ancorati, permette ai dati di “parlare da soli”. Se il campione è abbastanza grande e il meccanismo è forte, il risultato converge a quello di 2A, ma con più incertezza (CI più ampi).\n\n81.4.4 Messaggio didattico\n\n\nIgnorare il meccanismo MNAR tende a produrre bias (qui: \\(\\mu\\) fortemente sottostimata).\nUn selection model che include \\(\\Pr(R=1\\mid y)\\) può ridurre o annullare il bias su \\(\\mu\\) e recuperare la stima di \\(\\sigma\\), identificando al contempo un \\(\\beta&lt;0\\) coerente con il meccanismo simulato.\nCon una prior ampia su \\(\\beta\\) (\\(\\mathcal{N}(0,2)\\)) e un segnale forte nei dati, il parametro viene comunque spinto nella direzione corretta (negativa), ma con maggiore incertezza rispetto a una prior leggermente più informativa (es. \\(\\mathcal{N}(-1.5,1)\\)).\n\nBuone pratiche: monitorare \\(\\hat{R}\\) ed ESS, aumentare le iterazioni se l’identificabilità è debole, e valutare prior motivate teoricamente; includere variabili ausiliarie quando possibile.\n\nIn sintesi, nel modello con prior ampia su \\(\\beta\\) il recupero di \\(\\mu \\approx 0\\) e \\(\\sigma \\approx 1\\) è sostanziale, e l’effetto del meccanismo di mancanza (\\(\\beta \\approx -1.88\\), IC \\(90\\%\\) [-2.65, -0.60]) è coerente con lo scenario MNAR simulato (\\(\\beta*{\\text{true}}=-2\\)). La diagnostica MCMC è adeguata; prior più orientate o campioni più grandi possono aumentare la stabilità.",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#linee-guida-sintetiche",
    "href": "chapters/missing/01_mnar_stan.html#linee-guida-sintetiche",
    "title": "81  Dati mancanti in psicologia",
    "section": "\n81.5 Linee guida sintetiche",
    "text": "81.5 Linee guida sintetiche\n\n\nDiagnosi iniziale: esplora pattern di mancanza e relazioni temporali/contestuali (“chi non risponde e quando?”).\n\nModello outcome-only: usa un outcome-only come baseline (MAR plausibile?) e aggiungi MNAR se giustificato.\n\nVariabili ausiliarie: sfruttale per ridurre l’informatività del meccanismo.\n\nScala e prior: centra/scala dove utile; usa priors debolmente informative ma plausibili.\n\nAnalisi di sensibilità: verifica la stabilità delle conclusioni al variare di prior e struttura del meccanismo.\n\nDocumentazione: esplicita assunzioni e giustifica il modello con la teoria psicologica o il contesto.",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#riflessioni-conclusive",
    "href": "chapters/missing/01_mnar_stan.html#riflessioni-conclusive",
    "title": "81  Dati mancanti in psicologia",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\n\nIn presenza di dati MNAR, ignorare il meccanismo può portare a inferenze fuorvianti.\nL’approccio Bayesiano con Stan consente di modellare esplicitamente la mancanza (selection model), riducendo il bias a costo di ipotesi più forti e maggiore incertezza.\nIn psicologia, dove il non rispondere può far parte del processo stesso (evitamento, umore), è metodologicamente opportuno modellare il meccanismo, integrare analisi di sensibilità e riportare in modo trasparente le assunzioni.\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] stringr_1.5.1         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        mgcv_1.9-3           \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [46] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [49] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [52] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [55] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [58] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [61] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [64] data.table_1.17.8     mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [67] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [70] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [73] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [76] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [79] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [82] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#bibliografia",
    "href": "chapters/missing/01_mnar_stan.html#bibliografia",
    "title": "81  Dati mancanti in psicologia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLittle, R. J. (2024). Missing data analysis. Annual Review of Clinical Psychology, 20.",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#footnotes",
    "href": "chapters/missing/01_mnar_stan.html#footnotes",
    "title": "81  Dati mancanti in psicologia",
    "section": "",
    "text": "Cosa significa “i valori mancanti sono parametri latenti?” Indichiamo con \\(y_i\\) il valore “vero” per l’unità \\(i\\). Per alcune unità \\(y_i\\) non è osservato (manca). Nel modello bayesiano includiamo comunque un oggetto \\(y_i\\) per ogni unità, anche quando è mancante: lo trattiamo come una quantità sconosciuta da inferire insieme a \\(\\mu\\) e \\(\\sigma\\). Tecnicamente: aggiungiamo un nodo \\(y_i^{\\text{mis}}\\) con la stessa distribuzione dell’outcome, ad es. \\(y_i^{\\text{mis}} \\sim \\mathcal{N}(\\mu,\\sigma).\\) Durante il campionamento, il modello genera valori plausibili per ciascun \\(y_i^{\\text{mis}}\\) coerenti con \\(\\mu\\) e \\(\\sigma\\). Importante: questi \\(y_i^{\\text{mis}}\\) non “informano” \\(\\mu\\) e \\(\\sigma\\) oltre ai dati osservati: sono imputazioni coerenti col modello (servono, per esempio, a produrre dataset completi), ma non correggono eventuali distorsioni dovute al meccanismo di mancanza. In breve: l’imputazione discende solo dalla distribuzione scelta per \\(y.\\)↩︎",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "Differenze fondamentali tra i due approcci\nCome discusso nel capitolo dedicato all’interpretazione delle probabilità (24  Interpretazione della probabilità), esistono due principali approcci nell’inferenza statistica: la statistica frequentista e la statistica bayesiana. Entrambi i metodi consentono di trarre conclusioni sulla popolazione di interesse attraverso l’analisi dei dati e vengono utilizzati per stimare quantità sconosciute, formulare previsioni e testare ipotesi. Tuttavia, differiscono nell’interpretazione della probabilità e nel modo in cui integrano le conoscenze pregresse e le evidenze disponibili.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#differenze-fondamentali-tra-i-due-approcci",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#differenze-fondamentali-tra-i-due-approcci",
    "title": "Introduzione",
    "section": "",
    "text": "Statistica frequentista\nNella statistica frequentista, la probabilità è interpretata come la frequenza relativa di un evento in un numero infinito di prove. Questo approccio assume che il valore vero di un parametro della popolazione sia fisso ma sconosciuto e che debba essere stimato esclusivamente dai dati osservati. Le inferenze statistiche vengono effettuate attraverso metodi quali:\n\nStima puntuale: fornisce un singolo valore come miglior stima del parametro.\nIntervalli di confidenza: definiscono un intervallo in cui il parametro si trova con una data probabilità, sotto ripetute campionature.\nTest di ipotesi: valutano la compatibilità dei dati con un’ipotesi nulla, attraverso il calcolo di p-value e statistiche test.\n\nQuesto approccio si basa su assunzioni riguardanti il processo che genera i dati e sull’idea che la verità statistica emerga dal comportamento asintotico di esperimenti ripetuti.\n\n\nStatistica bayesiana\nNella statistica bayesiana, la probabilità rappresenta un grado di credenza in un evento, soggetto ad aggiornamento alla luce di nuove evidenze (Jaynes, 2003). Questo approccio si fonda sull’applicazione del teorema di Bayes, che consente di aggiornare la conoscenza su un parametro in base ai dati osservati.\n\nIl valore del parametro è trattato come una variabile casuale con una distribuzione di probabilità.\nL’analisi parte da una distribuzione a priori, che rappresenta la conoscenza precedente.\nI nuovi dati vengono combinati con la distribuzione a priori tramite la verosimiglianza (likelihood).\nIl risultato è la distribuzione a posteriori, che sintetizza l’incertezza aggiornata sul parametro.\n\nQuesto approccio permette di incorporare informazioni pregresse ed è particolarmente utile in contesti con dati limitati o conoscenze precedenti rilevanti.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#il-problema-dellinduzione-di-hume",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#il-problema-dellinduzione-di-hume",
    "title": "Introduzione",
    "section": "Il problema dell’induzione di Hume",
    "text": "Il problema dell’induzione di Hume\nUna prospettiva utile per comprendere la differenza tra questi due approcci è il problema dell’induzione, formulato da David Hume nel 1739 nel suo A Treatise of Human Nature (Hacking, 2006). Hume solleva un dubbio fondamentale: come possiamo giustificare le inferenze dal passato al futuro? Nessuna quantità di osservazioni passate garantisce che il futuro seguirà lo stesso schema.\n\nL’approccio frequentista presuppone implicitamente che il mondo segua regolarità statistiche costanti. Tuttavia, questo assunto è vulnerabile alle critiche di Hume, poiché non offre una giustificazione epistemica all’estrapolazione del passato.\nL’approccio bayesiano integra l’incertezza nell’inferenza: la probabilità di un evento futuro è un riflesso delle nostre credenze attuali e viene aggiornata alla luce di nuove osservazioni. Questo approccio si adatta meglio a situazioni in cui il mondo potrebbe non seguire regolarità fisse.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#un-esempio-pratico-il-lancio-di-una-moneta",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#un-esempio-pratico-il-lancio-di-una-moneta",
    "title": "Introduzione",
    "section": "Un esempio pratico: il lancio di una moneta",
    "text": "Un esempio pratico: il lancio di una moneta\nConsideriamo il classico esempio del lancio di una moneta per illustrare le differenze tra i due approcci:\n\nFrequentista: definisce la probabilità di ottenere testa come la proporzione di teste osservate in un numero infinito di lanci. La probabilità è una proprietà intrinseca della moneta, indipendente dalle credenze dell’osservatore.\nBayesiano: parte da una distribuzione a priori sulla probabilità della moneta di cadere su testa. Dopo ogni lancio, aggiorna la credenza utilizzando la verosimiglianza, ottenendo una nuova distribuzione a posteriori. Questo metodo riflette un aggiornamento razionale delle credenze alla luce di nuove osservazioni.\n\nL’approccio bayesiano è quindi più flessibile e coerente con la prospettiva di Hume: accetta l’incertezza del futuro e la gestisce attraverso un meccanismo di aggiornamento continuo.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#obiettivo-di-questa-sezione",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#obiettivo-di-questa-sezione",
    "title": "Introduzione",
    "section": "Obiettivo di questa sezione",
    "text": "Obiettivo di questa sezione\nIn questa sezione della dispensa, esamineremo in dettaglio i metodi della statistica frequentista, tra cui la stima puntuale, gli intervalli di confidenza e il test di ipotesi. Questi strumenti costituiscono il nucleo dell’inferenza statistica tradizionale e offrono un quadro solido per analizzare i dati in assenza di informazioni pregresse. Tuttavia, come evidenziato dal problema di Hume, ogni approccio ha i suoi limiti e presupposti. La scelta tra frequentismo e bayesianesimo dipende dal contesto e dagli obiettivi dell’analisi.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#bibliografia",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#bibliografia",
    "title": "Introduzione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_galton.html",
    "href": "chapters/frequentist_inference/01_galton.html",
    "title": "80  Inferenza frequentista",
    "section": "",
    "text": "80.1 Introduzione\nIn questo capitolo esamineremo le radici storiche della statistica frequentista e le sue connessioni con il movimento eugenetico. Vedremo come alcune idee sviluppate nel contesto di questa corrente abbiano influenzato l’elaborazione dei metodi statistici che molti di noi utilizzano ancora oggi.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_galton.html#i-frequentisti-sono-razzisti",
    "href": "chapters/frequentist_inference/01_galton.html#i-frequentisti-sono-razzisti",
    "title": "80  Inferenza frequentista",
    "section": "\n80.2 I Frequentisti sono Razzisti?",
    "text": "80.2 I Frequentisti sono Razzisti?\nNel Capitolo 28, abbiamo esplorato le origini storiche e il contesto culturale che hanno portato all’interpretazione del teorema di Bayes proposta da Richard Price. Quelle origini, legate alla rivoluzione americana, rappresentano il “lato luminoso” del liberalismo moderno.\nLe origini dell’approccio frequentista, invece, si collocano agli antipodi: sono strettamente intrecciate con ciò che potremmo definire la “parte oscura” della modernità. L’avversione per la soggettività, tipica del frequentismo, riflette una visione più rigida e deterministica, distante dall’apertura e dalla flessibilità del pensiero bayesiano.\n\n80.2.1 Francis Galton e l’Eugenetica\nFrancis Galton (1822-1911), cugino di Charles Darwin, fu un esploratore, un medico e un pioniere della meteorologia. Ma il suo contributo più importante, e anche più controverso, riguardò la statistica e lo studio dell’ereditarietà del talento.\n\n\nDistribuzione Normale e Regressione\nGalton formalizzò la distribuzione normale e introdusse il concetto di “regressione verso la media”, chiamata inizialmente “regressione verso la mediocrità”.\n\n\nHereditary Genius\nNel suo libro Hereditary Genius, Galton sosteneva che il talento fosse trasmesso all’interno di specifiche famiglie. Fu lui a coniare la famosa espressione “nature and nurture” per indicare il ruolo combinato di eredità e ambiente nello sviluppo umano.\n\n\nEugenetica\nGalton mirava a “migliorare la specie umana” promuovendo la riproduzione tra famiglie ritenute “di successo” e scoraggiandola tra quelle considerate “inferiori”. Le sue idee, fortemente razziste, includevano l’idea che gli africani fossero “inferiori” e “pigri”, gli arabi “semplici consumatori della produzione altrui” e che gli anglosassoni fossero la “razza superiore”.\n\n80.2.2 L’Impatto di Galton su Pearson e Fisher\nLe teorie di Galton influenzarono Karl Pearson (1857-1936) e Ronald Fisher (1890-1962), due figure chiave della statistica moderna. Entrambi condividevano idee razziste e appoggiavano l’eugenetica:\n\n\nKarl Pearson\nProfessore all’University College di Londra, sviluppò strumenti come il test del chi quadrato e la deviazione standard. Ereditò la cattedra di eugenetica fondata da Galton.\n\n\nRonald Fisher\nConsiderato uno dei padri della statistica moderna, sviluppò l’analisi della varianza (ANOVA), il concetto di significatività statistica e il metodo della massima verosimiglianza (MLE).\n\nQuesti autori cercarono di allontanare la statistica dalla prospettiva di Laplace e Bayes, rifiutando l’idea di introdurre componenti soggettive nella loro “scienza”. Volevano che la statistica apparisse del tutto “oggettiva” per sostenere teorie eugenetiche e gerarchie razziali come se fossero dimostrate scientificamente.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_galton.html#implicazioni-per-le-pratiche-correnti",
    "href": "chapters/frequentist_inference/01_galton.html#implicazioni-per-le-pratiche-correnti",
    "title": "80  Inferenza frequentista",
    "section": "\n80.3 Implicazioni per le Pratiche Correnti",
    "text": "80.3 Implicazioni per le Pratiche Correnti\nIn che misura dovremmo considerare le implicazioni storiche ed etiche del frequentismo quando lo utilizziamo oggi? Secondo (Chivers, 2024), sebbene sia evidente che l’ideologia razziale nazista possa essere collegata alle idee di Galton, la questione centrale in statistica rimane: “Quale approccio è metodologicamente corretto?” o, più pragmaticamente, “Quale approccio è più utile?”.\nTuttavia, limitarsi a un dibattito puramente metodologico rischia di trascurare il fatto che la scienza non si svolge in una “torre d’avorio” astratta, ma ha conseguenze concrete. Se una teoria A, pur essendo efficace in uno scenario ideale, ha effetti profondamente negativi nella realtà, dovremmo davvero adottarla acriticamente? La risposta, per molti, è no.\nNel caso del frequentismo, non solo emergono questioni etiche, ma – come vedremo in seguito – si evidenziano anche limiti metodologici. La sua pretesa di “oggettività” si rivela un’illusione quando si analizza in profondità il funzionamento reale delle procedure inferenziali. In psicologia, dove la variabilità individuale e le questioni etiche sono centrali, questi difetti possono avere conseguenze particolarmente dannose.\n\n\n\n\n\n\nNota didattica: L’approccio frequentista viene presentato qui soprattutto per mostrare perché il suo uso esclusivo sia problematico. In questo capitolo descriveremo i fondamenti statistici del frequentismo e la logica delle sue procedure inferenziali. Nel capitoli successivi discuteremo invece come le sue applicazioni pratiche possano ostacolare il progresso della psicologia.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_galton.html#il-paradigma-frequentista",
    "href": "chapters/frequentist_inference/01_galton.html#il-paradigma-frequentista",
    "title": "80  Inferenza frequentista",
    "section": "\n80.4 Il Paradigma Frequentista",
    "text": "80.4 Il Paradigma Frequentista\nL’obiettivo della statistica frequentista è trarre conclusioni su un’intera popolazione partendo da un campione di dati. In questo contesto:\n\nI dati osservati vengono considerati come un’estrazione casuale (un “campione”) da una popolazione più ampia.\n\nIl modello statistico assume che esista un processo generatore dei dati, descritto da una distribuzione di probabilità.\n\nQuando raccogliamo un campione di dati, dobbiamo tenere presente che avremmo potuto ottenere molti altri campioni diversi (il principio di ripetizione del campionamento).\n\n\n80.4.1 Probabilità e Ripetizione del Campionamento\nIl frequentismo adotta un’interpretazione della probabilità basata sulle frequenze: se ripetessimo un esperimento moltissime volte, la probabilità di un evento sarebbe il rapporto tra il numero di volte in cui l’evento si verifica e il numero totale di prove.\n\n80.4.2 Stima di un Parametro\nSupponiamo di voler stimare un parametro (ad esempio, la media di una popolazione). Il frequentismo cerca un stimatore – una funzione del campione – che abbia determinate proprietà, tra cui l’assenza di distorsione (l’unbiasedness) e la consistenza (la vicinanza alla realtà con l’aumentare del numero di dati).\nUn esempio comune è la stima della media della popolazione tramite la media del campione. Sotto certe condizioni, si può dimostrare che, ripetendo l’esperimento moltissime volte, la media del campione in media coinciderà con la vera media della popolazione.\n\n80.4.3 Intervalli di Confidenza\nNell’approccio frequentista, invece di fornire un singolo valore come stima di un parametro, si costruisce un intervallo di confidenza. L’idea fondamentale è che, se ripetessimo molte volte la stessa procedura di campionamento e di calcolo dell’intervallo, una certa percentuale di questi (ad esempio il 95%) conterrà effettivamente il valore vero del parametro.\nPrima di raccogliere i dati, gli estremi di questo intervallo (i “limiti di confidenza”) sono variabili casuali, perché dipendono dal campione che otterremo. Di conseguenza, la probabilità (per esempio, il 95%) si riferisce alla procedura di costruzione dell’intervallo, non all’intervallo in sé dopo l’osservazione dei dati. Una volta infatti che il campione è stato raccolto e l’intervallo è stato calcolato, quest’ultimo è un oggetto “fisso”: o contiene il valore vero del parametro, o non lo contiene; non è più possibile attribuirgli una probabilità di contenere il parametro. L’affermazione “intervallo di confidenza al 95%” significa dunque che, sul lungo periodo, usando sempre la stessa procedura, il 95% degli intervalli costruiti conterrà il parametro vero.\n\n80.4.4 Test delle Ipotesi: Approccio Frequentista e Limitazioni\nNel contesto del test di un’ipotesi (ad esempio, \\(H_0\\): “la media di una popolazione è uguale a 0”), l’approccio frequentista definisce una regione di rifiuto in base a un livello di significatività prefissato (ad esempio, \\(\\alpha = 0.05\\)). Se il risultato dell’analisi (come il p-value) cade all’interno di questa regione, si procede a rifiutare \\(H_0\\); altrimenti, si manca di rifiutare \\(H_0\\) (ovvero, non si rifiuta l’ipotesi nulla).\n\n\nErrore di tipo I (falso positivo): si verifica quando si rifiuta \\(H_0\\) nonostante essa sia vera.\n\n\nErrore di tipo II (falso negativo): si verifica quando non si rifiuta \\(H_0\\) nonostante essa sia falsa.\n\nNel paradigma frequentista, il ricercatore controlla la probabilità di questi errori, in particolare l’errore di tipo I, attraverso la scelta di \\(\\alpha\\) e il calcolo di indicatori come il p-value. Tuttavia, questo approccio presenta alcune criticità:\n\nDecisione dicotomica\nIl test conduce a una scelta binaria (rifiutare o non rifiutare \\(H_0\\)), che può risultare eccessivamente rigida. I fenomeni reali spesso non si prestano a una categorizzazione netta basata su una soglia arbitraria, rendendo la distinzione “significativo/non significativo” potenzialmente fuorviante. Una visione più sfumata, che consideri l’entità dell’effetto e l’incertezza, potrebbe essere più informativa.\nSoglia arbitraria\nIl valore di \\(\\alpha\\) (comunemente fissato a 0.05) è in gran parte una convenzione. Ad esempio, un valore-p di 0.049 porta al rifiuto di \\(H_0\\), mentre un valore-p di 0.051 non lo fa, nonostante la differenza tra i due casi sia minima. Questa arbitrarietà può influenzare in modo significativo l’interpretazione dei risultati, creando una discontinuità artificiale.\nNessuna prova diretta di verità/falsità\nUn valore-p basso non implica che \\(H_0\\) sia “falsa” o che un’ipotesi alternativa sia “vera”. Indica semplicemente che, assumendo \\(H_0\\) vera, dati simili (o più estremi) sarebbero rari sotto ripetuti campionamenti. Il test frequentista non fornisce una risposta alla domanda “Qual è la probabilità che \\(H_0\\) sia vera?”, limitando la sua capacità di supportare inferenze dirette sulla veridicità delle ipotesi.\n\nQueste criticità evidenziano come la rigidità del test (basato su una decisione binaria) e l’uso di soglie fisse possano risultare problematici, specialmente in discipline come la psicologia, dove le misurazioni sono spesso affette da rumore e le differenze tra condizioni possono essere sottili. Un approccio più flessibile, che integri la stima degli effetti, gli intervalli di confidenza e una valutazione contestuale, potrebbe offrire una comprensione più robusta e sfumata dei dati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_galton.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/01_galton.html#riflessioni-conclusive",
    "title": "80  Inferenza frequentista",
    "section": "\n80.5 Riflessioni Conclusive",
    "text": "80.5 Riflessioni Conclusive\nIn questo capitolo abbiamo mostrato come la statistica frequentista, pur essendo stata un pilastro dell’inferenza moderna, affondi le proprie radici in idee profondamente problematiche, come l’eugenetica e il razzismo sostenuti da Galton, Pearson e Fisher. Sebbene oggi queste teorie sembrino superate e distanti dalle nostre pratiche di laboratorio, conoscerne la genesi aiuta a comprendere come l’idea di un’oggettività assoluta sia stata impiegata per legittimare visioni ideologiche discutibili.\nParallelamente, la riflessione storica solleva interrogativi sul metodo e sulle sue implicazioni pratiche. La metafora della “torre d’avorio” mostra quanto sia pericoloso trattare la scienza come un sistema chiuso, ignorando le conseguenze etiche e sociali. Nel campo della psicologia, in particolare, la crisi di replicabilità (McElreath, 2020) rivela come l’uso acritico di procedure frequentiste possa influire sulla validità dei risultati.\nIn definitiva, il frequentismo non va considerato solo come un insieme di tecniche, ma come un paradigma con implicazioni culturali, etiche e metodologiche. Nel prossimo capitolo mostreremo come le applicazioni pratiche dell’approccio frequentista possano risultare limitanti e, talvolta, dannose per il progresso della psicologia (Gelman et al., 2013). Conoscere le basi e le implicazioni di tale paradigma è il primo passo per un uso più consapevole e responsabile degli strumenti statistici.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_galton.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01_galton.html#informazioni-sullambiente-di-sviluppo",
    "title": "80  Inferenza frequentista",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [19] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [22] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [25] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [28] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [31] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [34] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [37] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [40] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [43] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#&gt; [46] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [49] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [52] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [55] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [58] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [61] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [64] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [67] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#&gt; [70] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [73] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_galton.html#bibliografia",
    "href": "chapters/frequentist_inference/01_galton.html#bibliografia",
    "title": "80  Inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_stime_parametri.html",
    "href": "chapters/frequentist_inference/02_stime_parametri.html",
    "title": "81  Stime, stimatori e parametri",
    "section": "",
    "text": "81.1 Introduzione",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_stime_parametri.html#introduzione",
    "href": "chapters/frequentist_inference/02_stime_parametri.html#introduzione",
    "title": "81  Stime, stimatori e parametri",
    "section": "",
    "text": "In questo capitolo, ci concentreremo sul concetto di distribuzione campionaria, uno dei pilastri dell’inferenza statistica frequentista. La distribuzione campionaria descrive come le stime dei parametri della popolazione, come la media o la varianza, variano da campione a campione. Essa permette di stabilire proprietà probabilistiche delle stime campionarie, come la loro media e varianza, che sono fondamentali per costruire intervalli di confidenza e condurre test di ipotesi, strumenti essenziali dell’inferenza statistica frequentista.\n\n\n\n\n\n\n\nDomande introduttive\n\n\n\nPrima di iniziare a esplorare il concetto di distribuzione campionaria e il suo ruolo nell’inferenza statistica, considera le seguenti domande. Prova a formulare una risposta intuitiva basata sulle tue conoscenze attuali prima di procedere con la lettura del capitolo. Le simulazioni che seguiranno ti aiuteranno a confermare o rivedere le tue risposte.\n\nSe estraiamo ripetutamente campioni casuali dalla stessa popolazione e calcoliamo la loro media, come saranno distribuite queste medie campionarie rispetto alla media della popolazione?\nSupponiamo di estrarre campioni di dimensione \\(n=2\\) da una popolazione. L’insieme delle medie campionarie sarà più concentrato intorno alla media della popolazione rispetto ai valori individuali della popolazione stessa?\nQuale relazione esiste tra la dimensione del campione \\(n\\) e la variabilità delle medie campionarie? In altre parole, se aumentiamo la dimensione del campione, cosa succede alla dispersione della distribuzione campionaria?\nLa distribuzione campionaria della media campionaria sarà sempre normale? Quali fattori influenzano la sua forma?\nLa media della distribuzione campionaria coincide sempre con la media della popolazione? E la sua varianza è maggiore o minore rispetto alla varianza della popolazione?\nSupponiamo di estrarre piccoli campioni da una popolazione che ha una distribuzione fortemente asimmetrica. Quale forma avrà la distribuzione delle medie campionarie per piccoli campioni? E per campioni più grandi?",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_stime_parametri.html#stime-stimatori-e-parametri",
    "href": "chapters/frequentist_inference/02_stime_parametri.html#stime-stimatori-e-parametri",
    "title": "81  Stime, stimatori e parametri",
    "section": "\n81.2 Stime, stimatori e parametri",
    "text": "81.2 Stime, stimatori e parametri\nDopo aver esplorato il contesto culturale del frequentismo nel capitolo precedente, ci spostiamo ora su un piano strettamente statistico per introdurre il concetto di stima statistica.\nQuando si analizzano i dati, l’obiettivo è spesso quello di ottenere informazioni su una caratteristica della popolazione. Tuttavia, nella maggior parte dei casi, si ha accesso solo a un campione di osservazioni. La quantità sconosciuta che vogliamo stimare viene chiamata parametro, mentre il valore che calcoliamo dal campione per approssimare questo parametro è la stima. La formula o il procedimento matematico che utilizziamo per ottenere la stima è detto stimatore. Formalmente, uno stimatore è una funzione dei dati osservati utilizzata per produrre una stima di un parametro.\nIn altre parole, quando analizziamo un campione, cerchiamo di inferire proprietà della popolazione da cui il campione è tratto. Il parametro rappresenta una misura di queste proprietà, ma raramente può essere calcolato direttamente sulla popolazione intera. Pertanto, utilizziamo le osservazioni campionarie per ottenere una stima del parametro. La stima è quindi un’approssimazione del valore del parametro basata sui dati raccolti, mentre lo stimatore è la regola matematica o statistica che la produce.\nÈ importante sottolineare che le stime non coincidono necessariamente con il vero valore del parametro, poiché sono soggette a incertezza dovuta alla variabilità del campionamento. In questo capitolo esamineremo come l’approccio frequentista quantifica questa incertezza e come possiamo utilizzare tale quantificazione per trarre conclusioni affidabili sui parametri di interesse.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_stime_parametri.html#distribuzione-campionaria",
    "href": "chapters/frequentist_inference/02_stime_parametri.html#distribuzione-campionaria",
    "title": "81  Stime, stimatori e parametri",
    "section": "\n81.3 Distribuzione campionaria",
    "text": "81.3 Distribuzione campionaria\nNell’inferenza frequentista applicata alla psicologia, il parametro di maggiore interesse è spesso la media della popolazione—si veda anche la discussione nella Sezione 19.1.3.8. In questo capitolo esploreremo come la media di un campione casuale possa essere utilizzata per stimare la media \\(\\mu\\) di una popolazione. Per valutare l’incertezza associata a questa stima, introdurremo il concetto di distribuzione campionaria, un principio fondamentale dell’approccio frequentista.\nPer chiarire questa idea, inizieremo con un esempio basato su una popolazione finita di piccole dimensioni, pur consapevoli che le proprietà illustrate si estendono anche a popolazioni di dimensioni maggiori.\n\n81.3.1 Esempio introduttivo\nConsideriamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nQuesti valori potrebbero rappresentare il tempo di reazione (in secondi) di quattro partecipanti a un esperimento di decisione rapida, in cui devono identificare il colore di uno stimolo visivo. In questo caso, l’intera popolazione è costituita da tutti i partecipanti disponibili per lo studio, ad esempio se l’esperimento è stato condotto in un piccolo gruppo di persone selezionate per caratteristiche specifiche, come quattro gemelli monozigoti in uno studio sulle differenze cognitive intra-familiari.\nL’istogramma sottostante rappresenta la distribuzione di frequenza della popolazione:\n\n# Creazione del dataframe\ndf &lt;- data.frame(Valori = c(2, 4.5, 5, 5.5))\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Valori)) +\n  geom_histogram(bins = 5, aes(y = after_stat(density)), color = \"white\") +\n  labs(title = \"Distribuzione della popolazione\", x = \"Valori\", y = \"Densità\") \n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione:\n\nmean(x)  # Media\n#&gt; [1] 4.25\nvar(x)   # Varianza\n#&gt; [1] 2.42\n\n\n81.3.2 Campionamento\nConsideriamo ora tutti i possibili campioni di dimensione \\(n = 2\\) che possiamo estrarre dalla popolazione. Poiché ogni valore può essere selezionato indipendentemente in entrambe le posizioni del campione, il numero totale di combinazioni possibili si ottiene con il calcolo combinatorio:\n\\[\n\\text{Numero totale di campioni} = k^n ,\n\\]\ndove \\(k\\) è la dimensione della popolazione e \\(n\\) è la dimensione del campione. Nel nostro caso, con \\(k = 4\\) e \\(n = 2\\), otteniamo:\n\\[\n4^2 = 16 .\n\\]\nPossiamo generare esplicitamente queste combinazioni con il seguente codice:\n\nsamples &lt;- expand.grid(x, x)\nsamples\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nOgni riga rappresenta un campione possibile. Confermiamo il numero totale di campioni con:\n\nnrow(samples)\n#&gt; [1] 16\n\nOra calcoliamo la media di ciascun campione, ottenendo la distribuzione campionaria delle medie per \\(n = 2\\):\n\nsample_means &lt;- rowMeans(samples)\nsample_means\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00 5.25\n#&gt; [16] 5.50\n\nQuesta distribuzione campionaria mostra tutte le possibili medie che possiamo ottenere estraendo campioni casuali di dimensione 2 dalla popolazione. Si tratta di un concetto fondamentale in inferenza statistica frequentista, poiché la distribuzione delle medie campionarie diventa progressivamente più simmetrica e concentrata attorno alla media della popolazione man mano che \\(n\\) aumenta, come previsto dal teorema del limite centrale.\n\n81.3.3 Visualizzazione della distribuzione campionaria\nPossiamo visualizzare la distribuzione campionaria delle medie con un istogramma:\n\n# Creazione del dataframe\ndf &lt;- data.frame(Valori = sample_means)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Valori)) +\n  geom_histogram(bins = 5, aes(y = after_stat(density)), color = \"white\") +\n  labs(x = \"Media campionaria\", y = \"Densità\") \n\n\n\n\n\n\n\nL’istogramma mostra come le medie campionarie non siano distribuite uniformemente, ma seguano una struttura precisa determinata dalla distribuzione dei valori originali della popolazione. Con un numero maggiore di osservazioni per campione (\\(n\\) più grande), la distribuzione campionaria delle medie tende a diventare più stretta e simmetrica attorno alla media della popolazione, illustrando così il principio alla base dell’inferenza statistica frequentista.\n\n81.3.4 Verifiche teoriche\n\n81.3.4.1 Media della distribuzione campionaria\nSecondo la teoria statistica, la media della distribuzione campionaria deve coincidere con la media della popolazione. Questo implica che, se prendiamo la media di tutti i campioni possibili di una certa dimensione, il valore risultante sarà uguale alla media della popolazione stessa. Possiamo verificarlo con il seguente calcolo:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nmean(sample_means)  # Media della distribuzione campionaria\n#&gt; [1] 4.25\n\n\n81.3.4.2 Varianza della distribuzione campionaria\nUn altro risultato importante è che la varianza della distribuzione campionaria delle medie è inferiore alla varianza della popolazione. In particolare, la teoria prevede che sia pari alla varianza della popolazione divisa per la dimensione del campione \\(n\\):\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\n\\]\nPoiché in questo caso \\(n = 2\\), confrontiamo la varianza teorica con quella empirica:\n\n# Funzione per calcolare la varianza senza la correzione di Bessel\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)\n}\n\n\nvariance(x) / 2  # Varianza teorica\n#&gt; [1] 0.906\nvariance(sample_means)  # Varianza empirica\n#&gt; [1] 0.906\n\nOsserviamo che la varianza delle medie campionarie è inferiore alla varianza della popolazione, confermando che le medie campionarie mostrano meno variabilità rispetto alle singole osservazioni.\n\n81.3.5 Esempio di campione osservato\nPer comprendere meglio questi concetti, consideriamo un singolo campione, ad esempio:\n\nobserved_sample &lt;- c(5, 5.5)\nobserved_sample\n#&gt; [1] 5.0 5.5\n\nCalcoliamo la sua media e deviazione standard:\n\nmean(observed_sample)  # Media del campione\n#&gt; [1] 5.25\nsqrt(variance(observed_sample))  # Deviazione standard del campione\n#&gt; [1] 0.25\n\nOra confrontiamo questi valori con quelli della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nsqrt(variance(x))  # Deviazione standard della popolazione\n#&gt; [1] 1.35\n\nOsserviamo che la media del campione si avvicina a quella della popolazione, ma non coincide necessariamente con essa. Questo è del tutto normale: ogni campione rappresenta solo una porzione della popolazione e la sua media può variare leggermente a seconda delle osservazioni selezionate.\nPer quanto riguarda la deviazione standard, in questo caso specifico risulta inferiore a quella della popolazione. Tuttavia, in generale, la dispersione di un singolo campione può essere maggiore o minore rispetto a quella della popolazione, poiché dipende dalla variabilità casuale delle osservazioni estratte. Proprio per questo motivo, per trarre inferenze affidabili sulla popolazione, è più utile considerare la distribuzione campionaria delle medie piuttosto che un singolo campione isolato.\nQuesto esempio illustra bene il principio della stima campionaria: mentre un singolo campione fornisce un’informazione parziale, l’analisi di molteplici campioni consente di ottenere una stima più precisa e stabile della media della popolazione, riducendo l’incertezza e migliorando l’affidabilità dell’inferenza statistica.\n\n81.3.6 La Simulazione Illustra Due Principi\nDalla simulazione emergono due principi fondamentali dell’inferenza statistica:\n\n\nLa media della distribuzione campionaria coincide con la media della popolazione. Questo implica che se estraiamo molteplici campioni di dimensione \\(n\\) e calcoliamo la loro media, il valore atteso della media campionaria sarà uguale alla media della popolazione \\(\\mu\\). Formalmente:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mu .\n\\]\nQuesto risultato conferma che la media campionaria è uno stimatore non distorto della media della popolazione.\n\n\nLa varianza della distribuzione campionaria è minore della varianza della popolazione. Questo riflette il fatto che le medie campionarie tendono a essere più stabili rispetto alle singole osservazioni. La relazione teorica che descrive questa proprietà è:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n} .\n\\]\nCiò significa che, aumentando la dimensione del campione \\(n\\), la variabilità delle medie campionarie si riduce, rendendo la stima della media della popolazione più precisa. Questo concetto è alla base della teoria del teorema centrale del limite, che diventa sempre più evidente con campioni di dimensioni maggiori.\n\n\n\n\n\n\n\n\nDimostrazione che \\(\\bar{X}\\) è uno stimatore corretto della media della popolazione\n\n\n\n\n\nDato un campione casuale di \\(n\\) osservazioni \\(X_1, X_2, \\dots, X_n\\) estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria è definita come:\n\\[\n\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i .\n\\]\nUtilizziamo la linearità dell’operatore di aspettativa:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mathbb{E} \\left( \\frac{1}{n} \\sum_{i=1}^{n} X_i \\right) .\n\\]\nPer la proprietà della linearità dell’aspettativa, possiamo portare fuori il fattore costante \\(\\frac{1}{n}\\):\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{E}(X_i) .\n\\]\nPoiché ogni \\(X_i\\) proviene dalla stessa popolazione, ha la stessa aspettativa \\(\\mathbb{E}(X_i) = \\mu\\), quindi:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\sum_{i=1}^{n} \\mu .\n\\]\nSommando \\(n\\) volte \\(\\mu\\), otteniamo:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} (n \\mu) = \\mu .\n\\]\nIn conclusione, abbiamo dimostrato che:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mu .\n\\]\nQuesto significa che la media campionaria \\(\\bar{X}_n\\) è uno stimatore corretto (non distorto) della media della popolazione \\(\\mu\\), poiché il suo valore atteso coincide esattamente con la quantità che vogliamo stimare.\n\n\n\n\n\n\n\n\n\nDimostrazione della riduzione della varianza nelle medie campionarie\n\n\n\n\n\nSia \\(X_1, X_2, \\dots, X_n\\) un campione casuale di \\(n\\) osservazioni indipendenti estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). La media campionaria è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nPer definizione, la varianza di \\(\\bar{X}\\) è:\n\\[\n\\mathbb{V}(\\bar{X}) = \\mathbb{V}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right).\n\\]\nPoiché una costante moltiplicata da una variabile aleatoria può essere “estratta” dalla varianza, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right).\n\\]\nOra dobbiamo calcolare \\(\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right)\\). Le variabili \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, quindi la varianza della somma è la somma delle varianze:\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\mathbb{V}(X_i).\n\\]\nPoiché tutte le variabili \\(X_i\\) hanno la stessa varianza \\(\\sigma^2\\):\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = n \\sigma^2.\n\\]\nSostituendo nella formula precedente, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\cdot n \\sigma^2 = \\frac{\\sigma^2}{n}.\n\\]\nIn generale, dunque, per un campione di ampiezza \\(n\\), vale la relazione \\(\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_stime_parametri.html#proprietà-della-distribuzione-campionaria",
    "href": "chapters/frequentist_inference/02_stime_parametri.html#proprietà-della-distribuzione-campionaria",
    "title": "81  Stime, stimatori e parametri",
    "section": "\n81.4 Proprietà della distribuzione campionaria",
    "text": "81.4 Proprietà della distribuzione campionaria\nUna caratteristica fondamentale della distribuzione campionaria riguarda la sua forma e il modo in cui dipende dalla distribuzione della popolazione da cui vengono estratti i campioni. Possiamo distinguere due casi principali:\n\nSe la popolazione segue una distribuzione normale, allora anche la distribuzione delle medie campionarie sarà normalmente distribuita, indipendentemente dalla dimensione del campione \\(n\\). Questo significa che, anche con campioni molto piccoli, la media campionaria manterrà la stessa forma della distribuzione originale.\nSe la popolazione non segue una distribuzione normale, entra in gioco il teorema centrale del limite. Questo teorema afferma che, man mano che la dimensione del campione \\(n\\) aumenta, la distribuzione delle medie campionarie tenderà comunque a una distribuzione normale, indipendentemente dalla forma della distribuzione di partenza. In pratica, per campioni sufficientemente grandi, possiamo approssimare la distribuzione delle medie campionarie con una normale, anche se la popolazione da cui provengono i dati è asimmetrica o non gaussiana.\n\nQueste proprietà sono fondamentali nell’inferenza statistica frequentista: permettono di stimare e testare parametri della popolazione utilizzando campioni, facilitando l’applicazione di strumenti basati sulla distribuzione normale, come gli intervalli di confidenza e i test di ipotesi.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_stime_parametri.html#teorema-del-limite-centrale",
    "href": "chapters/frequentist_inference/02_stime_parametri.html#teorema-del-limite-centrale",
    "title": "81  Stime, stimatori e parametri",
    "section": "\n81.5 Teorema del Limite Centrale",
    "text": "81.5 Teorema del Limite Centrale\nEsaminiamo ora più in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Pierre-Simon Laplace dimostrò il TLC, che afferma che la somma (o la media) di una sequenza di variabili casuali indipendenti e identicamente distribuite (i.i.d.) tende a distribuirsi secondo una distribuzione Normale (o Gaussiana), al crescere della dimensione del campione. Inoltre, il TLC specifica i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.\n\nTeorema 81.1 Si consideri una sequenza di variabili aleatorie indipendenti e identicamente distribuite (i.i.d.) \\(Y_1, Y_2, \\dots, Y_n\\), con valore atteso \\(\\mathbb{E}(Y_i) = \\mu\\) e deviazione standard \\(\\text{SD}(Y_i) = \\sigma.\\) Si definisca una nuova variabile casuale come la media campionaria:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nAl tendere di \\(n\\) all’infinito (\\(n \\rightarrow \\infty\\)), la distribuzione di \\(Z\\) converge a una distribuzione Normale con valore atteso \\(\\mu\\) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\):\n\\[\nZ \\sim \\mathcal{N}\\left(\\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\nIn altre parole, la densità di probabilità di \\(Z\\) tende a:\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nIl TLC può essere generalizzato anche a variabili casuali che non sono identicamente distribuite, purché siano indipendenti e abbiano valori attesi e varianze finite. Questo teorema spiega perché molti fenomeni naturali, come l’altezza degli adulti o il peso di una popolazione, tendono a seguire una distribuzione Normale. Infatti, tali fenomeni sono spesso il risultato di una combinazione di numerosi effetti additivi e indipendenti, ciascuno dei quali contribuisce in modo relativamente piccolo. Indipendentemente dalla distribuzione individuale di ciascun effetto, la loro somma (o media) tende a distribuirsi in modo Normale. Questa è la ragione per cui la distribuzione Normale fornisce una buona approssimazione per la distribuzione di molti fenomeni osservati in natura.\n\n81.5.1 Illustrazione del Teorema del Limite Centrale (TLC)\nPer comprendere il Teorema del Limite Centrale (TLC), consideriamo una popolazione iniziale che segue una distribuzione fortemente asimmetrica: la distribuzione Beta(2,1), caratterizzata da una forte asimmetria positiva.\n\n# Parametri della distribuzione Beta\na &lt;- 2\nb &lt;- 1\n\n# Genera valori per la distribuzione Beta\nx &lt;- seq(0, 1, length.out = 1000)  # Valori tra 0 e 1\ny &lt;- dbeta(x, shape1 = a, shape2 = b)  # Densità della distribuzione Beta\n\n# Crea un dataframe per qplot\ndata &lt;- data.frame(x = x, y = y)\n\n# Grafico con qplot\nqplot(x, y, data = data, geom = \"line\", \n      main = \"Distribuzione Beta(2, 1)\", \n      xlab = \"x\", \n      ylab = \"Densità\")\n\n\n\n\n\n\n\nEstrarremo più volte campioni casuali di ampiezza \\(n\\) da questa popolazione e calcoleremo le medie campionarie. Il TLC prevede che, all’aumentare della dimensione del campione, la distribuzione delle medie campionarie tenda a una distribuzione normale, indipendentemente dalla forma della popolazione di partenza.\nPer verificare questa proprietà, definiamo una funzione che genera campioni, calcola le medie e visualizza la loro distribuzione campionaria per diversi valori di \\(n\\):\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 1\n\n# Funzione per simulare e visualizzare la distribuzione campionaria\nplot_samples &lt;- function(n) {\n  # Media e deviazione standard della distribuzione Beta\n  mu &lt;- alpha / (alpha + beta)\n  sigma &lt;- sqrt(alpha * beta / ((alpha + beta)^2 * (alpha + beta + 1)))\n  \n  # Generazione di 50.000 campioni casuali di dimensione n\n  sample_means &lt;- replicate(50000, mean(rbeta(n, alpha, beta)))\n  \n  # Creazione del dataframe\n  df &lt;- data.frame(MediaCampionaria = sample_means)\n  \n  # Creazione del grafico con ggplot2\n  ggplot(df, aes(x = MediaCampionaria)) +\n    geom_histogram(aes(y = after_stat(density)), bins = 50, color = \"white\") +\n    stat_function(fun = dnorm, args = list(mean = mu, sd = sigma / sqrt(n)), color = \"black\", lwd = 1.2) +\n    labs(title = paste(\"Distribuzione campionaria\\nper n =\", n),\n         x = \"Media campionaria\",\n         y = \"Densità\") \n}\n\n\n81.5.1.1 Visualizzazione della convergenza alla normalità\nAnalizziamo l’effetto della dimensione del campione sulle medie campionarie:\n\n\nCampioni di ampiezza \\(n = 1\\)\nSe \\(n = 1\\), la distribuzione campionaria coincide esattamente con la distribuzione della popolazione di partenza, che in questo caso è fortemente asimmetrica:\n\nplot_samples(1)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 2\\)\nCon \\(n = 2\\), la distribuzione delle medie campionarie inizia a perdere parte della sua asimmetria:\n\nplot_samples(2)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 4\\)\nPer \\(n = 4\\), la distribuzione delle medie campionarie diventa più simmetrica e tende già a una forma più vicina a quella normale:\n\nplot_samples(4)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 30\\)\nQuando \\(n\\) diventa sufficientemente grande (ad esempio \\(n = 30\\)), la distribuzione campionaria delle medie è praticamente indistinguibile da una normale:\n\nplot_samples(30)\n\n\n\n\n\n\n\n\n\n81.5.1.2 Conclusione\nIl Teorema del Limite Centrale (TLC) afferma che, indipendentemente dalla forma della distribuzione della popolazione:\n\nSe la dimensione del campione è sufficientemente grande, la distribuzione delle medie campionarie \\(\\bar{X}\\) sarà approssimativamente normale, anche se la popolazione di partenza non lo è.\n\nLa distribuzione delle medie campionarie avrà media uguale a quella della popolazione \\(\\mu\\) e deviazione standard pari a:\n\\[\n\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma / \\sqrt{n})\n\\]\ndove \\(\\sigma\\) è la deviazione standard della popolazione e \\(n\\) è la dimensione del campione.\n\n\n81.5.2 Implicazioni\n\nNormalità emergente\nIl TLC giustifica l’uso della distribuzione normale in molte applicazioni statistiche, anche quando i dati originali non seguono una distribuzione normale.\nErrore standard e precisione delle stime\nIl TLC fornisce una formula esplicita per calcolare l’errore standard \\(\\sigma / \\sqrt{n}\\), che quantifica l’incertezza associata alla media campionaria. All’aumentare di \\(n\\), l’errore standard diminuisce, migliorando la precisione della stima della media della popolazione.\n\nQuesta proprietà è alla base di molte tecniche statistiche, come gli intervalli di confidenza e i test di ipotesi, che assumono la normalità della distribuzione campionaria delle medie anche quando la popolazione di partenza non è normale.\n\n81.5.3 Applicazioni in psicologia\nMolti fenomeni psicologici che misuriamo (ad esempio, il QI come media di molte abilità cognitive) derivano dalla media di più variabili, e quindi seguono la distribuzione normale grazie al TLC. Questo spiega perché la distribuzione normale appare così frequentemente nei dati sperimentali di psicologia e in molte altre discipline scientifiche.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_stime_parametri.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/frequentist_inference/02_stime_parametri.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "81  Stime, stimatori e parametri",
    "section": "\n81.6 Distribuzioni campionarie di altre statistiche",
    "text": "81.6 Distribuzioni campionarie di altre statistiche\nAbbiamo già analizzato la distribuzione campionaria della media dei campioni. Tuttavia, è possibile costruire distribuzioni campionarie per altre statistiche campionarie. Ad esempio, consideriamo la distribuzione campionaria del valore massimo e della varianza.\n\n81.6.1 Distribuzione campionaria del valore massimo\nSupponiamo di avere una popolazione normalmente distribuita con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Generiamo 10.000 campioni casuali di ampiezza \\(n = 5\\) e calcoliamo il valore massimo per ogni campione.\n\n81.6.1.1 Simulazione e visualizzazione\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\n\n# Simulazione: calcolo del valore massimo per ciascun campione\nn_samples &lt;- 10000\nsample_maxes &lt;- replicate(\n  n_samples, \n  max(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(ValoreMassimo = sample_maxes)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = ValoreMassimo)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, color = \"white\") +\n  stat_function(fun = dnorm, args = list(mean = mu, sd = sigma), color = \"black\", lwd = 1.2) +\n  labs(x = \"Valore massimo\",\n       y = \"Densità\")\n\n\n\n\n\n\n\nOsserviamo che il valore atteso della distribuzione campionaria del massimo è maggiore della media della popolazione \\(\\mu\\).\n\n81.6.2 Distribuzione campionaria della varianza\nUn’altra statistica interessante è la varianza campionaria. La formula della varianza campionaria, basata sulla statistica descrittiva, è:\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nCalcoliamo la distribuzione campionaria della varianza per campioni di ampiezza \\(n = 5\\).\n\n81.6.2.1 Simulazione e visualizzazione\n\nset.seed(123)\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\nn_samples &lt;- 10000\n\n# Funzione per calcolare la varianza senza la correzione di Bessel\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)  # Divisione per n invece di (n-1)\n}\n\n# Simulazione: calcolo della varianza per ciascun campione\nsample_vars &lt;- replicate(\n  n_samples, \n  variance(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(Varianza = sample_vars)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Varianza)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, color = \"white\") +\n  labs(x = \"Varianza\",\n       y = \"Densità\")\n\n\n\n\n\n\n\n\n# Media empirica della varianza campionaria\nmean(sample_vars)\n#&gt; [1] 181\n\nSappiamo che la varianza della popolazione è \\(\\sigma^2 = 15^2 = 225\\). Tuttavia, il valore medio empirico delle varianze campionarie calcolate con \\(S^2\\) risulta minore di 225. Questo avviene perché lo stimatore \\(S^2\\) è distorto.\n\n81.6.3 Correzione della distorsione\nPer eliminare la distorsione, utilizziamo il seguente stimatore della varianza della popolazione:\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n-1}.\n\\]\n\n81.6.3.1 Verifica con simulazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza con la correzione\nsample_vars_unbiased &lt;- replicate(\n  n_samples, \n  var(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(Varianza = sample_vars_unbiased)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Varianza)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, color = \"white\") +\n  labs(x = \"Varianza\",\n       y = \"Densità\")\n\n\n\n\n\n\n\n\n# Media empirica della varianza corretta\nmean(sample_vars_unbiased)\n#&gt; [1] 226\n\nCon questo stimatore, la media della distribuzione campionaria coincide con la varianza reale della popolazione \\(\\sigma^2 = 225\\).\nIn conclusione:\n\nLa distribuzione campionaria del massimo mostra che il valore massimo dei campioni è, in media, maggiore della media della popolazione.\nLa varianza campionaria non corretta (\\(S^2\\)) è uno stimatore distorto, poiché il suo valore atteso non coincide con la varianza della popolazione.\nLo stimatore corretto \\(s^2\\), che utilizza il divisore \\(n - 1\\), elimina la distorsione e fornisce una stima non distorta della varianza della popolazione.\n\nIn generale, uno stimatore è considerato non distorto quando il valore atteso delle sue stime coincide con il valore reale del parametro. Nel caso della media campionaria e della varianza corretta, entrambi gli stimatori sono non distorti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_stime_parametri.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/02_stime_parametri.html#riflessioni-conclusive",
    "title": "81  Stime, stimatori e parametri",
    "section": "\n81.7 Riflessioni Conclusive",
    "text": "81.7 Riflessioni Conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell’inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.\n\n\n\n\n\n\n\nSimbolo\nNome\nÈ qualcosa che conosciamo?\n\n\n\n\\(s\\)\nDeviazione standard del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nSì, ma non è uguale a \\(\\sigma\\)\n\n\n\n\\(s^2\\)\nVarianza del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nSì, ma non è uguale a \\(\\sigma^2\\)\n\n\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione è la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione è:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\n\n\nDopo aver esplorato il concetto di distribuzione campionaria attraverso simulazioni ed esempi pratici, possiamo ora confrontare le nostre risposte intuitive con quanto appreso:\n\nLe medie campionarie tendono a distribuirsi intorno alla media della popolazione, con una variabilità che dipende dalla dimensione del campione.\nSì, le medie campionarie sono meno disperse rispetto ai singoli valori della popolazione, il che significa che forniscono una stima più stabile della media della popolazione.\nAll’aumentare di \\(n\\), la distribuzione campionaria delle medie diventa più stretta, ossia la variabilità delle medie campionarie si riduce. La varianza della distribuzione campionaria è pari a \\(\\sigma^2 / n\\), dove \\(\\sigma^2\\) è la varianza della popolazione.\nNo, la distribuzione campionaria della media è normale solo se la popolazione di partenza è normale o se la dimensione del campione è sufficientemente grande (Teorema del Limite Centrale).\nSì, la media della distribuzione campionaria coincide con la media della popolazione. Tuttavia, la varianza della distribuzione campionaria è inferiore alla varianza della popolazione, poiché viene divisa per la dimensione del campione (\\(n\\)).\nPer campioni piccoli, la distribuzione delle medie campionarie somiglierà alla distribuzione della popolazione originale. Se la popolazione è fortemente asimmetrica, anche la distribuzione campionaria per piccoli campioni sarà asimmetrica. Tuttavia, aumentando \\(n\\), la distribuzione delle medie campionarie tenderà a una normale, indipendentemente dalla forma della popolazione di partenza.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_stime_parametri.html#esercizi",
    "href": "chapters/frequentist_inference/02_stime_parametri.html#esercizi",
    "title": "81  Stime, stimatori e parametri",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nParte 1: Popolazione di Piccole Dimensioni Si consideri una popolazione con i seguenti valori:\n\\[\nx = \\{2, 4.5, 5, 5.5\\}\n\\]\n\nCalcolare la media e la varianza della popolazione.\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) con ripetizione e calcolare la media di ciascun campione.\nRappresentare graficamente la distribuzione campionaria delle medie.\nCalcolare la probabilità che la media campionaria sia inferiore a 3:\n\nEsattamente, utilizzando la distribuzione campionaria.\nApprossimativamente, assumendo una distribuzione normale se il campione fosse sufficientemente grande.\n\n\n\nParte 2: Popolazione di Grandi Dimensioni\nSi consideri ora una popolazione più grande, generata da una distribuzione normale con media \\(\\mu = 10\\) e deviazione standard \\(\\sigma = 3\\).\n\nGenerare una popolazione di 1000 osservazioni.\nCalcolare la media e la varianza della popolazione.\nEstrarre 10.000 campioni casuali di ampiezza \\(n = 15\\) e calcolare la media campionaria per ciascun campione.\nRappresentare graficamente la distribuzione campionaria delle medie.\nCalcolare la probabilità che la media campionaria sia inferiore a 9:\n\nEsattamente, utilizzando la distribuzione campionaria.\nApprossimativamente, utilizzando la distribuzione normale.\n\n\n\nObiettivo: Verificare sperimentalmente le proprietà della distribuzione campionaria della media e confrontare i risultati con le previsioni teoriche fornite dal Teorema del Limite Centrale.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nProprietà della Distribuzione Campionaria della Media\n\nMedia: La media della distribuzione campionaria coincide con la media della popolazione:\nVarianza: La varianza della distribuzione campionaria è pari alla varianza della popolazione divisa per la dimensione del campione:\nForma:\n\n\nSe la popolazione segue una distribuzione normale, anche la distribuzione campionaria della media sarà normale.\nSe la popolazione non è normale, il Teorema del Limite Centrale garantisce che la distribuzione campionaria della media sarà approssimativamente normale per campioni di dimensioni sufficientemente grandi (\\(n \\geq 30\\)).\n\nDefiniamo una popolazione e calcoliamo i parametri:\n\n# Popolazione\nx &lt;- c(2, 4.5, 5, 5.5)\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nvar(x)   # Varianza della popolazione\n#&gt; [1] 2.42\n\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) e calcolare la media di ciascun campione:\n\n# Tutti i campioni di ampiezza 2\nsamples &lt;- expand.grid(x, x)\nsample_means &lt;- rowMeans(samples)\n\n# Visualizzare la distribuzione campionaria\ndf &lt;- data.frame(sample_means = sample_means)\n\nggplot(df, aes(x = sample_means)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 5, alpha = 0.6) +\n  geom_density(color = \"black\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria delle medie\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCalcoliamo la probabilità che, all’interno della distribuzione campionaria, la media del campione sia minore di 3. Troviamo il valore esatto nella simulazione. Approssimiamo il valore esatto con il valore atteso se il campione fosse sufficientemente grande da poter assumere una distribuzione campionaria normale:\n\n# Probabilità esatta dalla distribuzione campionaria\nexact_probability &lt;- mean(sample_means &lt; 3)\nexact_probability\n#&gt; [1] 0.0625\n\n# Approssimazione tramite distribuzione normale\nmu &lt;- mean(x)  # Media della popolazione\nsigma &lt;- sqrt(var(x) / 2)  # Deviazione standard della distribuzione campionaria\napprox_probability &lt;- pnorm(3, mean = mu, sd = sigma)\napprox_probability\n#&gt; [1] 0.128\n\nRipetiamo ora l’esempio, mantenendo la stessa struttura della simulazione, ma considerando una popolazione più grande tale per cui si possa estrarre un campione di ampiezza 15:\n\n# Nuova popolazione\nset.seed(123)\nx_large &lt;- rnorm(1000, mean = 10, sd = 3)  # Popolazione più grande\nmean(x_large)  # Media della popolazione\n#&gt; [1] 10\nvar(x_large)   # Varianza della popolazione\n#&gt; [1] 8.85\n\n# Estrazione di campioni di ampiezza 15\nsamples_large &lt;- replicate(10000, mean(sample(x_large, size = 15)))\n\n# Creazione del data frame per ggplot2\ndf_large &lt;- data.frame(sample_means = samples_large)\n\n# Visualizzazione con ggplot2\nggplot(df_large, aes(x = sample_means)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, alpha = 0.6) +\n  geom_density(color = \"black\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria delle medie (n = 15)\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n# Probabilità esatta dalla simulazione\nexact_probability_large &lt;- mean(samples_large &lt; 9)\nexact_probability_large\n#&gt; [1] 0.0834\n\n\n# Approssimazione tramite distribuzione normale\nmu_large &lt;- mean(x_large)\nsigma_large &lt;- sqrt(var(x_large) / 15)\napprox_probability_large &lt;- pnorm(9, mean = mu_large, sd = sigma_large)\napprox_probability_large\n#&gt; [1] 0.0862\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nDistribuzione Campionaria della Differenza tra Medie\nL’obiettivo di questo esercizio è esplorare le proprietà della distribuzione campionaria della differenza tra medie campionarie, analizzando sia il caso di popolazioni finite di piccole dimensioni sia il caso di popolazioni più grandi, con distribuzioni normali.\nEsercizio 1: Simulazione con Popolazioni di Piccole Dimensioni\nConsideriamo due popolazioni finite composte da un numero limitato di elementi:\n\n\nPopolazione 1: \\(x_1 = \\{2, 4.5, 5, 6\\}\\)\n\n\nPopolazione 2: \\(x_2 = \\{3, 3.5, 4, 7\\}\\)\n\n\n\n81.7.0.1 Compiti:\n\n\n\nCalcolo dei parametri delle popolazioni:\n\nDeterminare la media e la varianza di entrambe le popolazioni.\n\n\n\nEstrazione di campioni:\n\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) con ripetizione da entrambe le popolazioni.\nCalcolare la media campionaria di ciascun campione.\n\n\n\nDistribuzione campionaria della differenza tra le medie:\n\nCalcolare la differenza tra le medie di tutti i possibili campioni ottenuti dalle due popolazioni.\nRappresentare graficamente la distribuzione della differenza tra le medie.\n\n\n\nProbabilità della differenza tra le medie:\n\nCalcolare la probabilità che la differenza tra le medie campionarie sia maggiore di 1.\n\n\n\nEsercizio 2: Simulazione con Popolazioni di Grande Dimensione\nConsideriamo ora due popolazioni più grandi, distribuite normalmente:\n\n\nPopolazione 1: \\(X_1 \\sim N(10, 4^2)\\) (media = 10, deviazione standard = 4)\n\nPopolazione 2: \\(X_2 \\sim N(8, 3^2)\\) (media = 8, deviazione standard = 3)\n\nCompiti:\n\n\nGenerazione delle popolazioni:\n\nCreare due popolazioni casuali di 10.000 osservazioni ciascuna, distribuite normalmente.\n\n\n\nEstrazione di campioni:\n\nEstrarre 10.000 campioni casuali di ampiezza \\(n_1 = 15\\) dalla prima popolazione e \\(n_2 = 20\\) dalla seconda popolazione.\nCalcolare la media di ciascun campione.\n\n\n\nDistribuzione campionaria della differenza tra le medie:\n\nCalcolare la differenza tra le medie campionarie ottenute dalle due popolazioni.\nRappresentare graficamente la distribuzione della differenza tra le medie.\n\n\n\nProbabilità della differenza tra le medie:\n\nCalcolare la probabilità che la differenza tra le medie campionarie sia maggiore di 2 in due modi:\n\n\nMetodo empirico: utilizzando la distribuzione ottenuta nella simulazione.\n\nMetodo teorico: approssimando la distribuzione con una normale e calcolando la probabilità con la formula teorica della varianza della differenza tra le medie.\n\n\n\n\n\nDomande di Discussione\n\nCome cambia la forma della distribuzione campionaria al variare delle dimensioni dei campioni \\(n_1\\) e \\(n_2\\)?\nLa probabilità stimata tramite simulazione coincide con quella calcolata utilizzando l’approssimazione normale? Perché?\nCosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali? Quale sarebbe il ruolo del Teorema del Limite Centrale?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 1: Simulazione con Popolazioni di Piccola Dimensione\nSupponiamo di avere due popolazioni finite definite come segue:\n\nPopolazione 1: \\(x_1 = \\{2, 4.5, 5, 6\\}\\)\n\nPopolazione 2: \\(x_2 = \\{3, 3.5, 4, 7\\}\\)\n\n\n\nCalcola le medie e le varianze delle due popolazioni:\n\n\n# Popolazione 1\nx1 &lt;- c(2, 4.5, 5, 6)\nmean(x1)  # Media di x1\n#&gt; [1] 4.38\nvar(x1)   # Varianza di x1\n#&gt; [1] 2.9\n\n\n# Popolazione 2\nx2 &lt;- c(3, 3.5, 4, 7)\nmean(x2)  # Media di x2\n#&gt; [1] 4.38\nvar(x2)   # Varianza di x2\n#&gt; [1] 3.23\n\n\nEstrai tutti i possibili campioni di ampiezza \\(n = 2\\) da entrambe le popolazioni:\n\n\n# Tutti i campioni di ampiezza 2\nsamples1 &lt;- expand.grid(x1, x1)\nsamples2 &lt;- expand.grid(x2, x2)\n\n# Medie campionarie\nsample_means1 &lt;- rowMeans(samples1)\nsample_means2 &lt;- rowMeans(samples2)\n\n\nCalcola la differenza tra le medie campionarie di ciascuna combinazione di campioni:\n\n\n# Differenze tra le medie campionarie\nsample_diff &lt;- as.vector(outer(sample_means1, sample_means2, \"-\"))\n\n\nVisualizza la distribuzione campionaria della differenza tra le medie:\n\n\n# Istogramma della differenza tra medie campionarie\n\n# Creazione del data frame per ggplot2\ndf_diff &lt;- data.frame(sample_diff = sample_diff)\n\n# Visualizzazione con ggplot2\nggplot(df_diff, aes(x = sample_diff)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 10, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra medie\",\n    x = \"Differenza campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\nCalcola la probabilità che la differenza campionaria sia maggiore di 1:\n\n\n# Probabilità esatta dalla distribuzione campionaria\nexact_probability &lt;- mean(sample_diff &gt; 1)\nexact_probability\n#&gt; [1] 0.266\n\nEsercizio 2: Simulazione con Popolazioni di Grande Dimensione\nOra considera due popolazioni più grandi con distribuzioni normali:\n\nPopolazione 1: \\(X_1 \\sim N(10, 4^2)\\)\n\nPopolazione 2: \\(X_2 \\sim N(8, 3^2)\\)\n\n\n\nGenera due popolazioni casuali:\n\n\nset.seed(123)\npop1 &lt;- rnorm(10000, mean = 10, sd = 4)\npop2 &lt;- rnorm(10000, mean = 8, sd = 3)\n\n\nEstrai 10.000 campioni casuali di ampiezza \\(n_1 = 15\\) e \\(n_2 = 20\\) rispettivamente:\n\n\n# Estrazione di campioni e calcolo delle medie\nsample_means1 &lt;- replicate(10000, mean(sample(pop1, size = 15)))\nsample_means2 &lt;- replicate(10000, mean(sample(pop2, size = 20)))\n\n\nCalcola la differenza tra le medie campionarie:\n\n\n# Differenze tra medie campionarie\nsample_diff_large &lt;- sample_means1 - sample_means2\n\n\nVisualizza la distribuzione campionaria della differenza tra le medie:\n\n\n# Istogramma della distribuzione campionaria\n\n# Creazione del data frame per ggplot2\ndf_diff_large &lt;- data.frame(sample_diff = sample_diff_large)\n\n# Visualizzazione con ggplot2\nggplot(df_diff_large, aes(x = sample_diff)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra medie (n1 = 15, n2 = 20)\",\n    x = \"Differenza campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n\nCalcola la probabilità che la differenza campionaria sia maggiore di 2 utilizzando:\n\nla simulazione;\nl’approssimazione normale.\n\n\n\n\n# Probabilità esatta\nexact_probability_large &lt;- mean(sample_diff_large &gt; 2)\nexact_probability_large\n#&gt; [1] 0.505\n\n\n# Approssimazione normale\nmu_diff &lt;- 10 - 8  # Differenza tra le medie delle popolazioni\nsigma_diff &lt;- sqrt(4^2 / 15 + 3^2 / 20)  # Deviazione standard della differenza\napprox_probability_large &lt;- 1 - pnorm(2, mean = mu_diff, sd = sigma_diff)\napprox_probability_large\n#&gt; [1] 0.5\n\nDomande di Discussione.\n\nCome cambia la forma della distribuzione campionaria al variare delle dimensioni campionarie \\(n_1\\) e \\(n_2\\)?\nLa probabilità calcolata tramite simulazione coincide con quella calcolata tramite approssimazione normale? Perché?\nCosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali?\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nProblema: Distribuzione Campionaria di una Proporzione\nL’obiettivo di questo esercizio è esplorare la distribuzione campionaria di una proporzione campionaria \\(\\hat{p}\\) e verificare l’applicabilità dell’approssimazione normale per grandi dimensioni campionarie, come previsto dal Teorema del Limite Centrale.\nSituazione\nSupponiamo di avere una popolazione infinita in cui ciascun individuo può appartenere a una di due categorie: “successo” (codificato come 1) o “insuccesso” (codificato come 0). La probabilità di successo nella popolazione è data da \\(p = 0.6\\).\nCompiti\n\n\nDefinizione della popolazione e dei parametri:\n\nLa popolazione ha una proporzione di successi pari a \\(p = 0.6\\).\nLa deviazione standard teorica della distribuzione campionaria della proporzione è calcolata come:\\[\n\\text{SD}(\\hat{p}) = \\sqrt{\\frac{p(1 - p)}{n}}\n\\]\n\nSi fissi una dimensione campionaria pari a \\(n = 100\\).\n\n\n\nSimulazione di campioni:\n\nGenerare 10.000 campioni casuali di ampiezza \\(n = 100\\).\nPer ogni campione, calcolare la proporzione campionaria \\(\\hat{p}\\), cioè la frazione di successi nel campione.\n\n\n\nDistribuzione campionaria delle proporzioni:\n\nRappresentare graficamente la distribuzione delle proporzioni campionarie con un istogramma.\nSovrapporre la distribuzione normale teorica \\(N(p, \\text{SD}(\\hat{p}))\\) per confrontare l’andamento empirico con quello teorico.\n\n\n\nAnalisi della distribuzione:\n\nValutare se la distribuzione campionaria ottenuta rispetta l’approssimazione normale.\nRiflettere su come la dimensione del campione e il valore di \\(p\\) influenzano questa approssimazione.\n\n\n\nDomande di Discussione\n\nLa distribuzione campionaria delle proporzioni \\(\\hat{p}\\) sembra approssimarsi a una distribuzione normale? Perché?\nCosa accadrebbe se la dimensione del campione fosse più piccola, ad esempio \\(n = 30\\)?\nSe la probabilità di successo \\(p\\) fosse molto vicina a 0 o 1, l’approssimazione normale sarebbe ancora valida? Perché?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nLa distribuzione campionaria di una proporzione descrive come la proporzione campionaria (\\(\\hat{p}\\)) varia tra campioni di una popolazione. Per campioni grandi, il Teorema del Limite Centrale garantisce che la distribuzione campionaria di \\(\\hat{p}\\) può essere approssimata con una distribuzione normale.\n\n\nSupponiamo una popolazione infinita in cui la probabilità di successo (\\(p\\)) è \\(p = 0.6\\). Scegli una dimensione campionaria \\(n = 100\\).\nSimula 10.000 campioni casuali di ampiezza \\(n\\) e calcola le proporzioni campionarie (\\(\\hat{p}\\)).\nConfronta l’istogramma delle proporzioni campionarie con la distribuzione normale teorica approssimativa.\n\n\n# Parametri della popolazione\np &lt;- 0.6  # Probabilità di successo nella popolazione\nn &lt;- 100  # Dimensione del campione\n\n# Simulazione di 10.000 campioni\nset.seed(123)\nsample_props &lt;- replicate(10000, mean(rbinom(n, size = 1, prob = p)))\n\n# Creazione di un data frame per ggplot2\ndf_props &lt;- data.frame(sample_props = sample_props)\n\n# Parametri della distribuzione normale teorica\nmean_theoretical &lt;- p\nsd_theoretical &lt;- sqrt(p * (1 - p) / n)\n\n# Visualizzazione con ggplot2\nggplot(df_props, aes(x = sample_props)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 40, fill = \"blue\", alpha = 0.6) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_theoretical, sd = sd_theoretical),\n    color = \"red\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione campionaria di una proporzione (n = 100)\",\n    x = \"Proporzione campionaria (\\u0302p)\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n\nPopolazione e parametri:\n\nLa popolazione è definita da \\(p = 0.6\\).\nLa deviazione standard teorica della distribuzione campionaria è calcolata come \\(\\text{SD}(\\hat{p}) = \\sqrt{\\frac{p(1-p)}{n}}\\).\n\n\n\nSimulazione:\n\nPer ogni campione, i successi (\\(0\\) o \\(1\\)) sono generati con rbinom, e la proporzione campionaria \\(\\hat{p}\\) è calcolata come media.\n\n\n\nGrafico:\n\nL’istogramma delle proporzioni campionarie è sovrapposto alla curva normale teorica (\\(N(p, \\text{SD}(\\hat{p}))\\)).\n\n\n\nDomande di Discussione.\n\nLa distribuzione campionaria di \\(\\hat{p}\\) sembra approssimarsi a una distribuzione normale? Perché?\nCosa accadrebbe se \\(n\\) fosse più piccolo (es. \\(n = 30\\))?\nSe \\(p\\) fosse più vicino a \\(0\\) o \\(1\\), l’approssimazione normale sarebbe ancora valida? Spiega.\n\n\n\n\n\n\n\n\n\n\nProblemi 4\n\n\n\n\n\nProblema: Distribuzione Campionaria della Differenza tra Due Proporzioni\nL’obiettivo di questo esercizio è esplorare la distribuzione campionaria della differenza tra due proporzioni campionarie, \\(\\hat{p}_1 - \\hat{p}_2\\), ottenute da due campioni indipendenti estratti da popolazioni diverse. Per campioni sufficientemente grandi, il Teorema del Limite Centrale garantisce che la distribuzione di \\(\\hat{p}_1 - \\hat{p}_2\\) può essere approssimata con una distribuzione normale.\nSituazione\nAbbiamo due popolazioni con proporzioni di successo diverse:\n\n\nPopolazione 1 ha una proporzione di successo \\(p_1 = 0.6\\).\n\nPopolazione 2 ha una proporzione di successo \\(p_2 = 0.4\\).\n\nVogliamo studiare il comportamento della distribuzione campionaria della differenza tra le proporzioni campionarie quando preleviamo campioni indipendenti da ciascuna popolazione.\nCompiti\n\n\nDefinizione delle popolazioni e dei parametri:\n\nLa proporzione di successi nelle due popolazioni è \\(p_1 = 0.6\\) e \\(p_2 = 0.4\\).\nEntrambi i campioni hanno dimensione \\(n_1 = n_2 = 150\\).\nLa deviazione standard teorica della distribuzione campionaria della differenza tra proporzioni è calcolata come: \\[\n\\text{SD}(\\hat{p}_1 - \\hat{p}_2) = \\sqrt{\\frac{p_1 (1-p_1)}{n_1} + \\frac{p_2 (1-p_2)}{n_2}}\n\\]\n\n\n\n\nSimulazione di campioni:\n\nGenerare 10.000 campioni indipendenti di ampiezza \\(n_1 = 150\\) dalla prima popolazione e \\(n_2 = 150\\) dalla seconda popolazione.\nCalcolare la proporzione campionaria \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) per ciascun campione.\nCalcolare la differenza tra le proporzioni campionarie.\n\n\n\nDistribuzione campionaria della differenza tra le proporzioni:\n\nRappresentare graficamente la distribuzione di \\(\\hat{p}_1 - \\hat{p}_2\\) con un istogramma.\nSovrapporre la distribuzione normale teorica \\(N(p_1 - p_2, \\text{SD}(\\hat{p}_1 - \\hat{p}_2))\\) per confrontare l’andamento empirico con quello teorico.\n\n\n\nCalcolo della probabilità che la differenza tra proporzioni sia maggiore di un valore specifico:\n\n\nMetodo empirico: calcolare la proporzione di campioni in cui \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\n\nMetodo teorico: utilizzare la distribuzione normale approssimata per stimare la probabilità che \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\n\n\n\nDomande di Discussione\n\nL’approssimazione normale è valida in questo caso? Perché?\nCome cambierebbe la distribuzione campionaria se la dimensione del campione \\(n_1\\) o \\(n_2\\) fosse più piccola?\nSe i valori di \\(p_1\\) o \\(p_2\\) fossero più vicini a 0 o 1, come cambierebbe la probabilità calcolata e l’accuratezza dell’approssimazione normale?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 4\n\n\n\n\n\nLa distribuzione campionaria della differenza tra due proporzioni (\\(\\hat{p}_1 - \\hat{p}_2\\)) descrive come la differenza tra le proporzioni campionarie varia tra due campioni indipendenti estratti da due popolazioni.\nPer campioni grandi, il Teorema del Limite Centrale garantisce che \\(\\hat{p}_1 - \\hat{p}_2\\) segue approssimativamente una distribuzione normale con media e varianza calcolate dalle proporzioni della popolazione.\nObiettivo:\n\nSimulare due popolazioni con proporzioni \\(p_1\\) e \\(p_2\\).\nEstrarre campioni indipendenti da ciascuna popolazione.\nCalcolare la distribuzione campionaria di \\(\\hat{p}_1 - \\hat{p}_2\\).\nCalcolare la probabilità che la differenza campionaria sia maggiore di un valore specifico (es. \\(0.1\\)).\n\nParametri del Problema:\n\nPopolazione 1: \\(p_1 = 0.6\\)\n\nPopolazione 2: \\(p_2 = 0.4\\)\n\nDimensione campionaria: \\(n_1 = n_2 = 150\\)\n\nValore specifico: \\(0.1\\)\n\n\n\n# Parametri delle due popolazioni\np1 &lt;- 0.6  # Proporzione di successi nella Popolazione 1\np2 &lt;- 0.4  # Proporzione di successi nella Popolazione 2\nn1 &lt;- 150  # Dimensione campionaria per la Popolazione 1\nn2 &lt;- 150  # Dimensione campionaria per la Popolazione 2\n\n# Simulazione di 10.000 campioni indipendenti\nset.seed(123)\nsample_p1 &lt;- replicate(10000, mean(rbinom(n1, size = 1, prob = p1)))\nsample_p2 &lt;- replicate(10000, mean(rbinom(n2, size = 1, prob = p2)))\n\n# Calcolo della differenza tra proporzioni campionarie\nsample_diff &lt;- sample_p1 - sample_p2\n\n# Parametri teorici della distribuzione normale approssimata\nmean_diff &lt;- p1 - p2\nsd_diff &lt;- sqrt((p1 * (1 - p1) / n1) + (p2 * (1 - p2) / n2))\n\n# Creazione del data frame per ggplot2\ndf_diff &lt;- data.frame(sample_diff = sample_diff)\n\n# Visualizzazione con ggplot2\nggplot(df_diff, aes(x = sample_diff)) +\n  geom_histogram(\n    aes(y = after_stat(density)), bins = 40, fill = \"blue\", alpha = 0.6\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_diff, sd = sd_diff),\n    color = \"red\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra proporzioni\",\n    x = \"Differenza campionaria (p1 - p2)\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n# Calcolo della probabilità che la differenza sia maggiore di 0.1\nexact_probability &lt;- mean(sample_diff &gt; 0.1)\nexact_probability\n#&gt; [1] 0.96\n\n\n# Approssimazione tramite distribuzione normale\napprox_probability &lt;- 1 - pnorm(0.1, mean = mean_diff, sd = sd_diff)\napprox_probability\n#&gt; [1] 0.961\n\n\n\nParametri delle popolazioni:\n\nDue popolazioni con proporzioni \\(p_1 = 0.6\\) e \\(p_2 = 0.4\\).\nDimensioni campionarie \\(n_1 = n_2 = 150\\).\n\n\n\nSimulazione:\n\nPer ogni campione, i successi (\\(0\\) o \\(1\\)) sono generati con rbinom.\nCalcoliamo le proporzioni campionarie e la differenza tra di esse.\n\n\n\nDistribuzione teorica:\n\nMedia teorica: \\(p_1 - p_2\\).\nDeviazione standard teorica: \\(\\sqrt{\\frac{p_1 (1-p_1)}{n_1} + \\frac{p_2 (1-p_2)}{n_2}}\\).\n\n\n\nVisualizzazione:\n\nUn istogramma di \\(\\hat{p}_1 - \\hat{p}_2\\) sovrapposto alla curva della distribuzione normale teorica.\n\n\n\nCalcolo della probabilità:\n\nProbabilità esatta dalla simulazione: proporzione di \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\nProbabilità approssimata dalla distribuzione normale.\n\n\n\nDomande di Discussione.\n\nL’approssimazione normale è valida in questo caso? Perché?\nCome cambierebbe la distribuzione campionaria se \\(n_1\\) o \\(n_2\\) fossero più piccoli?\nCome influenzerebbe la probabilità calcolata un valore \\(p_1\\) o \\(p_2\\) più vicino a \\(0\\) o \\(1\\)?",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_stime_parametri.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/02_stime_parametri.html#informazioni-sullambiente-di-sviluppo",
    "title": "81  Stime, stimatori e parametri",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_conf_interv.html",
    "href": "chapters/frequentist_inference/03_conf_interv.html",
    "title": "82  Intervalli di fiducia",
    "section": "",
    "text": "82.1 Introduzione\nGli intervalli di confidenza sono uno strumento fondamentale nell’inferenza statistica frequentista. Essi consentono di stimare un parametro sconosciuto di una popolazione, come la media \\(\\mu\\), tenendo conto dell’incertezza derivante dal fatto che la stima si basa su un campione. Questo materiale didattico si propone di spiegare in modo dettagliato e chiaro la costruzione di un intervallo di confidenza per la media di una popolazione, sia nel caso di varianza nota sia in quello di varianza incognita.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "href": "chapters/frequentist_inference/03_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "title": "82  Intervalli di fiducia",
    "section": "\n82.2 Inferenza Statistica Frequentista e Media Campionaria",
    "text": "82.2 Inferenza Statistica Frequentista e Media Campionaria\nQuando estraiamo un campione casuale semplice \\(X_1, X_2, \\dots, X_n\\) da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria \\(\\bar{X}\\) è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nLa media campionaria \\(\\bar{X}\\) è una variabile casuale perché dipende dai valori osservati nel campione, che sono essi stessi casuali. Le proprietà della media campionaria sono le seguenti:\n\n\nMedia della distribuzione campionaria: \\(E[\\bar{X}] = \\mu\\). La media campionaria è uno stimatore non distorto della media della popolazione.\n\nVarianza della distribuzione campionaria: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\). Questo significa che la precisione di \\(\\bar{X}\\) come stima di \\(\\mu\\) aumenta con il numero di osservazioni \\(n\\).\n\nQueste proprietà sono fondamentali per calcolare un intervallo di confidenza, poiché ci permettono di descrivere la distribuzione di \\(\\bar{X}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "href": "chapters/frequentist_inference/03_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "title": "82  Intervalli di fiducia",
    "section": "\n82.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota",
    "text": "82.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota\nSupponiamo che la popolazione sia distribuita normalmente con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e che \\(\\sigma^2\\) sia nota. La distribuzione della media campionaria \\(\\bar{X}\\) è anch’essa normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right).\n\\]\nPasso 1: Standardizzazione della Media Campionaria.\nPer lavorare con una distribuzione normale standard (media 0 e varianza 1), standardizziamo \\(\\bar{X}\\) utilizzando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQui, \\(\\sigma / \\sqrt{n}\\) è la deviazione standard della distribuzione campionaria di \\(\\bar{X}\\).\nDopo questa trasformazione, la variabile \\(Z\\) segue una distribuzione normale standard:\n\\[\nZ \\sim \\mathcal{N}(0, 1).\n\\]\nPasso 2: Determinazione del Livello di Confidenza.\nScegliamo un livello di confidenza \\(\\gamma\\), ad esempio \\(\\gamma = 0.95\\). Per una distribuzione normale standard, troviamo il valore critico \\(z\\) tale che la probabilità tra \\(-z\\) e \\(+z\\) sia pari al livello di confidenza:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nPer un livello di confidenza del 95%, \\(z \\approx 1.96\\).\nPasso 3: Formulazione dell’Intervallo di Confidenza.\nPartiamo dalla probabilità per \\(Z\\):\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nSostituiamo la definizione di \\(Z\\):\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\nMoltiplichiamo tutti i membri per \\(\\sigma / \\sqrt{n}\\) per rimuovere il denominatore:\n\\[\nP\\left(-z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\) a tutti i membri per isolare \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nPasso 4: Limiti dell’Intervallo di Confidenza.\nDefiniamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\\[\n\\hat{a} = \\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nL’intervallo di confidenza per \\(\\mu\\) è quindi:\n\\[\n(\\hat{a}, \\hat{b}) = \\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "href": "chapters/frequentist_inference/03_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "title": "82  Intervalli di fiducia",
    "section": "\n82.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita",
    "text": "82.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita\nNella maggior parte dei casi pratici, la varianza \\(\\sigma^2\\) non è nota. In questi casi, stimiamo \\(\\sigma\\) con la deviazione standard campionaria \\(s\\) e utilizziamo la distribuzione t di Student, che tiene conto dell’incertezza aggiuntiva.\nPasso 1: Distribuzione t di Student.\nLa statistica che seguiamo è:\n\\[\nT = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}},\n\\]\ndove \\(T\\) segue una distribuzione t con \\(n-1\\) gradi di libertà.\nPasso 2: Costruzione dell’Intervallo di Confidenza.\nAnalogamente al caso precedente, costruiamo l’intervallo partendo da:\n\\[\nP(-t^\\ast \\leq T \\leq t^\\ast) = \\gamma,\n\\]\ndove \\(t^\\ast\\) è il valore critico della distribuzione t per il livello di confidenza \\(\\gamma\\) e \\(n-1\\) gradi di libertà.\nSostituendo \\(T\\):\n\\[\nP\\left(-t^\\ast \\leq \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}} \\leq t^\\ast\\right) = \\gamma.\n\\]\nMoltiplichiamo per \\(s / \\sqrt{n}\\):\n\\[\nP\\left(-t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nPasso 3: Limiti dell’Intervallo.\nI limiti dell’intervallo sono:\n\\[\n\\hat{a} = \\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}.\n\\]\nIn conclusione, gli intervalli di confidenza forniscono un modo per quantificare l’incertezza nelle stime di parametri sconosciuti. La loro costruzione dipende dalla distribuzione campionaria dello stimatore e dall’informazione disponibile sulla varianza.\n\n82.4.1 Applicabilità e Limitazioni\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e è valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non è normalmente distribuita e la dimensione del campione è ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell’intervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_conf_interv.html#livello-di-copertura",
    "href": "chapters/frequentist_inference/03_conf_interv.html#livello-di-copertura",
    "title": "82  Intervalli di fiducia",
    "section": "\n82.5 Livello di Copertura",
    "text": "82.5 Livello di Copertura\nPer interpretare correttamente gli intervalli di fiducia è fondamentale considerare il concetto di “livello di copertura”. Questo livello indica la frequenza con cui l’intervallo di fiducia include il valore reale del parametro della popolazione, in una serie di esperimenti ripetuti.\nEsempio di Livello di Copertura:\n\nSe il livello di copertura è del 95%, significa che, nel lungo periodo, il 95% degli intervalli di fiducia costruiti conterrà il valore vero del parametro.\nImportante: Questo non implica che ci sia una probabilità del 95% che il valore vero del parametro cada in un particolare intervallo di fiducia. Infatti, il parametro della popolazione è un valore fisso e non soggetto a probabilità; piuttosto, l’incertezza risiede nell’intervallo di fiducia stesso.\n\nCome Funziona la Copertura:\n\nNel contesto frequentista, la “probabilità” si riferisce alla frequenza a lungo termine di un certo evento in un gran numero di ripetizioni dell’esperimento.\nNel caso degli intervalli di fiducia, l’“esperimento” è l’estrazione di un campione dalla popolazione, e l’“evento” è la generazione di un intervallo di fiducia che contiene il valore vero del parametro.\nIl livello di copertura, generalmente indicato come \\(1-\\alpha\\), rappresenta la probabilità a lungo termine che intervalli di fiducia costruiti con questa metodologia includano il vero valore del parametro.\n\n\n82.5.1 Simulazione\n\nPer illustrare questo concetto, eseguiamo una simulazione con la popolazione degli adulti maschi italiani, assunta come normalmente distribuita con media 175 cm e varianza 49 cm².\nEseguiamo 1000 ripetizioni di un esperimento, estraendo ogni volta un campione di 30 individui.\nPer ciascun campione, calcoliamo l’intervallo di fiducia al 95% usando la formula:\n\n\\[\n\\bar{X} \\pm t \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) è la media campionaria, \\(s\\) è la deviazione standard campionaria e \\(t\\) è il valore critico della distribuzione t-Student per \\(n-1\\) gradi di libertà al livello di significatività \\(\\alpha/2 = 0.025\\). - Registriamo i limiti di ciascun intervallo e controlliamo quanti di essi includono effettivamente il vero valore medio della popolazione.\nAttraverso questa simulazione, possiamo visualizzare concretamente il concetto di livello di copertura e la sua importanza nella statistica frequentista.\nIn questa simulazione, genereremo 1000 campioni casuali di dimensione \\(n = 30\\) da una distribuzione normale con media \\(\\mu = 175\\) e deviazione standard \\(\\sigma = 7\\). Successivamente, calcoleremo gli intervalli di confidenza al 95% per ciascun campione e valuteremo il livello di copertura.\n\nset.seed(123)  # Per riproducibilità\n\n# Parametri della distribuzione\nmu &lt;- 175\nsigma &lt;- 7\nn &lt;- 30\nn_samples &lt;- 1000\n\n# Generazione dei campioni\nsamples &lt;- replicate(n_samples, rnorm(n, mean = mu, sd = sigma))\ndim(samples)  # Verifica dimensioni: 30 righe per 1000 colonne\n#&gt; [1]   30 1000\n\nIl primo campione di ampiezza \\(n = 30\\) che abbiamo ottenuto è il seguente:\n\nsamples[, 1]  # Primo campione\n#&gt;  [1] 171 173 186 175 176 187 178 166 170 172 184 178 178 176 171 188 178 161 180\n#&gt; [20] 172 168 173 168 170 171 163 181 176 167 184\n\nStampiamo le medie dei primi dieci campioni:\n\nsample_means &lt;- colMeans(samples)  # Medie di tutti i campioni\nsample_means[1:10]  # Prime dieci medie\n#&gt;  [1] 175 176 175 174 174 176 175 174 175 177\n\nTroviamo il valore critico della distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libertà e livello di confidenza del 95% (\\(\\alpha = 0.05\\)):\n\nalpha &lt;- 0.05\nt_critical &lt;- qt(1 - alpha / 2, df = n - 1)  # Valore critico\nt_critical\n#&gt; [1] 2.05\n\nUtilizzando il valore critico \\(t\\), calcoliamo 1000 intervalli di confidenza per la media della popolazione:\n\n# Calcolo della deviazione standard campionaria\nsample_sds &lt;- apply(samples, 2, sd)\n\n# Ampiezza degli intervalli\ninterval_width &lt;- t_critical * sample_sds / sqrt(n)\n\n# Limiti degli intervalli di confidenza\nCI_low &lt;- sample_means - interval_width\nCI_high &lt;- sample_means + interval_width\n\nTroviamo il livello di copertura, ovvero la proporzione di intervalli di confidenza che contengono il vero valore della media della popolazione \\(\\mu\\):\n\ncoverage &lt;- mean(CI_low &lt; mu & mu &lt; CI_high)  # Proporzione di copertura\ncoverage\n#&gt; [1] 0.956\n\nIn conclusione, ripetendo la simulazione per 1000 campioni, abbiamo ottenuto un livello di copertura molto vicino al valore nominale di \\(1 - \\alpha = 0.95\\). Questo risultato dimostra che, con un campione di dimensione \\(n = 30\\), gli intervalli di confidenza al 95% calcolati utilizzando la distribuzione \\(t\\) di Student forniscono stime accurate della media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "href": "chapters/frequentist_inference/03_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "title": "82  Intervalli di fiducia",
    "section": "\n82.6 Il Concetto di Livello di Confidenza",
    "text": "82.6 Il Concetto di Livello di Confidenza\nGli intervalli di confidenza sono range di valori che, con una certa sicurezza statistica, si ritiene includano il parametro di interesse.\nSecondo l’approccio frequentista, l’intervallo di confidenza si deve considerare come una metodologia:\n\nSe ripetiamo l’esperimento (estrarre un campione e calcolare l’intervallo di confidenza) molte volte, il metodo produce un intervallo che coprirà il valore vero del parametro nel 95% dei casi, assumendo un livello di confidenza del 95%.\n\n\n82.6.1 Un Malinteso Comune nell’Interpretazione degli Intervalli di Confidenza\nÈ inesatto affermare che un determinato intervallo di confidenza contenga il valore vero di un parametro con una probabilità del 95%. Questo è un errore diffuso, persino tra i ricercatori, che spesso interpretano l’intervallo di confidenza come indicativo della probabilità che il parametro (ad esempio, la media della popolazione \\(\\mu\\)) si trovi effettivamente all’interno di un dato intervallo (es. \\([\\hat{a}, \\hat{b}]\\)).\nLa descrizione corretta è la seguente:\n\n“La metodologia impiegata per calcolare l’intervallo \\([\\hat{a}, \\hat{b}]\\) ha il 95% di probabilità di generare un intervallo che include il vero valore del parametro”.\nCiò significa che l’intervallo di confidenza non esprime una probabilità circa la posizione precisa del parametro, ma riflette la probabilità che la procedura adottata per determinarlo generi un intervallo che lo includa.\n\nIn conclusione, l’intervallo di confidenza ci fornisce una garanzia statistica riguardo alla affidabilità del metodo usato per la sua stima, piuttosto che sulla esatta ubicazione del parametro in questione.\n\n82.6.2 Fraintendimenti Comuni sugli Intervalli di Confidenza\nNel loro lavoro, Hoekstra et al. (2014) evidenziano come, nonostante l’ampio riconoscimento dei limiti dei test di ipotesi nulle, gli intervalli di confidenza siano spesso consigliati per l’inferenza statistica. Anche l’American Psychological Association (APA) suggerisce che gli intervalli di confidenza siano “in generale, la migliore strategia di reportistica”. Tuttavia, Hoekstra et al. (2014) sottolineano che queste raccomandazioni non considerano la difficoltà nel fornire una corretta interpretazione degli intervalli di confidenza.\nPer indagare l’interpretazione degli intervalli di confidenza, Hoekstra et al. (2014) hanno condotto uno studio con due domande principali:\n\nQuanto frequentemente intervalli di confidenza sono mal interpretati da studenti e ricercatori?\nL’esperienza nella ricerca riduce le interpretazioni errate degli intervalli di confidenza?\n\nPrima di presentare lo studio, Hoekstra et al. (2014) ricordano qual è l’interpretazione corretta degli intervalli di confidenza.\n\nA CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (e.g., Berger & Wolpert, 1988). As is the case with \\(p\\)-values, CIs do not allow one to make probability statements about parameters or hypotheses.\n\nNel loro studio, Hoekstra et al. (2014) hanno presentato un questionario a 596 partecipanti, tra cui studenti universitari e ricercatori, con le seguenti affermazioni riguardanti l’interpretazione degli intervalli di confidenza.\n\nProfessor Bumbledorf conducts an experiment, analyzes the data, and reports: “The 95% confidence interval for the mean ranges from 0.1 to 0.4.” Please mark each of the statements below as ‘true’ or ‘false’.\n\n\n\nThe probability that the true mean is greater than 0 is at least 95%.\nThe probability that the true mean equals 0 is smaller than 5%.\nThe “null hypothesis” that the true mean equals 0 is likely to be incorrect.\nThere is a 95% probability that the true mean lies between 0.1 and 0.4.\nWe can be 95% confident that the true mean lies between 0.1 and 0.4.\nIf we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.\n\n\nSorprendentemente, anche se tutte le sei affermazioni nel questionario sono errate, molti partecipanti hanno concordato con esse. I risultati mostrano che, in media, i partecipanti hanno concordato con circa 3.5 affermazioni errate su 6. Non è stata rilevata una differenza di rilievo nell’interpretazione degli intervalli di confidenza tra studenti e ricercatori, suggerendo che l’esperienza nella ricerca non migliora la comprensione di questo concetto.\nI risultati indicano che molte persone interpretano erroneamente gli intervalli di confidenza, e che anche l’esperienza nella ricerca non garantisce una migliore comprensione. Questo solleva dubbi sull’efficacia degli intervalli di confidenza frequentisti e suggerisce che gli “intervalli di credibilità” bayesiani possano rappresentare un’alternativa più vantaggiosa. Quest’ultimi tendono ad essere più intuitivi e di più facile interpretazione corretta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "href": "chapters/frequentist_inference/03_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "title": "82  Intervalli di fiducia",
    "section": "\n82.7 Confronto tra Intervalli Frequentisti e Bayesiani",
    "text": "82.7 Confronto tra Intervalli Frequentisti e Bayesiani\nConcludiamo questo capitolo esaminando le differenze tra l’intervallo di confidenza frequentista e l’intervallo di credibilità bayesiano, utilizzando lo stesso set di dati per entrambi i calcoli.\n\n82.7.1 Intervallo di confidenza frequentista\nImmaginiamo di avere un gruppo di 20 osservazioni relative alla performance in un test cognitivo. Il nostro obiettivo è stimare la media della popolazione da cui queste osservazioni sono tratte. Supponiamo che i dati provengano da una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della popolazione\nsample_size &lt;- 20\nmu &lt;- 50\nsigma &lt;- 10\n\n# Simulazione del campione\nsample_data &lt;- rnorm(sample_size, mean = mu, sd = sigma)\nprint(sample_data)\n#&gt;  [1] 44.4 47.7 65.6 50.7 51.3 67.2 54.6 37.3 43.1 45.5 62.2 53.6 54.0 51.1 44.4\n#&gt; [16] 67.9 55.0 30.3 57.0 45.3\n\nVisualizziamo la distribuzione dei dati:\n\ntibble(Valori = sample_data) |&gt;\n  ggplot(aes(x = Valori)) +\n  geom_histogram(aes(y = after_stat(density)),\n    bins = 30, # Puoi regolare il numero di bin\n    fill = \"skyblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n  labs(\n    x = \"Valori\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nLa media campionaria (\\(\\hat{\\mu}\\)) viene calcolata come:\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nIn R:\n\nsample_mean &lt;- mean(sample_data)\nsample_mean\n#&gt; [1] 51.4\n\nLa deviazione standard campionaria (\\(s\\)) si calcola come:\n\\[\ns = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n\\]\nIn R:\n\nvariance &lt;- function(x) {\n  sum((x - mean(x))^2) / length(x)\n}\n\nsample_sd &lt;- sqrt(variance(sample_data))  # Deviazione standard campionaria\nsample_sd\n#&gt; [1] 9.48\n\nL’errore standard della media (\\(SE\\)) è:\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\]\nIn R:\n\nstandard_error &lt;- sample_sd / sqrt(sample_size)\nstandard_error\n#&gt; [1] 2.12\n\nUn intervallo di confidenza è definito come:\n\\[\n\\bar{X} \\pm t_{\\text{critico}} \\cdot SE\n\\]\ndove \\(t_{\\text{critico}}\\) è il valore critico della distribuzione \\(t\\) di Student per un livello di confidenza del 95% (\\(\\alpha = 0.05\\)) e \\(n-1\\) gradi di libertà. In R:\n\nalpha &lt;- 0.05\ndf &lt;- sample_size - 1\nt_critical &lt;- qt(1 - alpha / 2, df)\nt_critical\n#&gt; [1] 2.09\n\nCalcoliamo il margine di errore:\n\nmargin_of_error &lt;- t_critical * standard_error\nmargin_of_error\n#&gt; [1] 4.44\n\nCalcoliamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\nconfidence_interval &lt;- \n  c(sample_mean - margin_of_error, sample_mean + margin_of_error)\nconfidence_interval\n#&gt; [1] 47.0 55.9\n\nPossiamo interpretare questo risultato dicendo che la procedura utilizzata per calcolare l’intervallo include il valore vero della media della popolazione nel 95% dei casi.\nCreiamo un grafico per mostrare la distribuzione dei dati, la media campionaria e l’intervallo di confidenza:\n\ntibble(Valori = sample_data) |&gt;\n  ggplot(aes(x = Valori)) +\n  geom_histogram(aes(y = ..density..),\n    bins = 30, # Puoi regolare il numero di bin\n    fill = \"skyblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n\n  # Linea per la media campionaria\n  geom_vline(aes(xintercept = sample_mean),\n    color = \"blue\",\n    linetype = \"dashed\",\n    linewidth = 1.2\n  ) +\n\n  # Linee per l'intervallo di confidenza\n  geom_vline(aes(xintercept = confidence_interval[1]),\n    color = \"darkgreen\",\n    linewidth = 1.2\n  ) +\n  geom_vline(aes(xintercept = confidence_interval[2]),\n    color = \"darkgreen\",\n    linewidth = 1.2\n  ) +\n\n  # Titoli e assi\n  labs(\n    x = \"Valori\",\n    y = \"Densità\"\n  ) +\n\n  # Legenda personalizzata\n  annotate(\"text\",\n    x = sample_mean, y = 0.02, label = \"Media campionaria\",\n    color = \"blue\", angle = 90, vjust = -0.5\n  ) +\n  annotate(\"text\",\n    x = confidence_interval[1], y = 0.02, label = \"IC Inferiore\",\n    color = \"darkgreen\", angle = 90, vjust = -0.5\n  ) +\n  annotate(\"text\",\n    x = confidence_interval[2], y = 0.02, label = \"IC Superiore\",\n    color = \"darkgreen\", angle = 90, vjust = -0.5\n  )\n\n\n\n\n\n\n\n\n82.7.1.1 Confronto tra gli Approcci Frequentista e Bayesiano\nIntervallo di Credibilità Bayesiano:\n\nRappresenta il grado di credenza (posteriori) che il parametro \\(\\mu\\) si trovi all’interno dell’intervallo calcolato.\nDipende sia dai dati osservati sia dalle distribuzioni a priori utilizzate nel modello, che possono influenzare il risultato in base alla loro specificità o vaghezza.\n\nIntervallo di Confidenza Frequentista:\n\nNon esprime la probabilità che il parametro \\(\\mu\\) appartenga a un determinato intervallo.\nSi riferisce invece alla procedura di costruzione dell’intervallo: se il campionamento fosse ripetuto infinite volte, il 95% degli intervalli costruiti conterrebbe il vero valore di \\(\\mu\\).\n\nIn sintesi:\n\nL’intervallo di credibilità bayesiano fornisce una stima probabilistica diretta e interpretabile della posizione di \\(\\mu\\), basata su dati osservati e informazioni a priori.\nL’intervallo di confidenza frequentista, invece, valuta la affidabilità della procedura nel lungo termine, senza fare affermazioni dirette sulla probabilità che il parametro rientri nell’intervallo specifico.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_conf_interv.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/03_conf_interv.html#riflessioni-conclusive",
    "title": "82  Intervalli di fiducia",
    "section": "\n82.8 Riflessioni Conclusive",
    "text": "82.8 Riflessioni Conclusive\nCome sottolineato da Hoekstra et al. (2014), è comune riscontrare fraintendimenti riguardo agli intervalli di fiducia. Il “livello di confidenza del 95%” è da interpretarsi come la probabilità a lungo termine che, in una serie di intervalli di fiducia calcolati, il 95% di essi includa il vero valore del parametro sconosciuto. Tuttavia, per un singolo intervallo di fiducia, non è possibile dichiarare con sicurezza che questo contenga effettivamente il parametro di interesse. In altre parole, la certezza sulla presenza del parametro sconosciuto all’interno di un dato intervallo di fiducia non è garantita per ogni singolo caso analizzato.\nÈ inoltre inesatto presumere che esista un legame diretto tra la varianza e la media di un campione, ipotizzando che un intervallo di fiducia più ristretto implichi maggiore precisione. Nella prospettiva frequentista, la “precisione” è strettamente legata al livello di copertura a lungo termine assicurato dal metodo usato per creare gli intervalli di fiducia. Questo concetto non si applica al singolo intervallo di fiducia osservato. Dunque, un intervallo di fiducia che si presenta estremamente ristretto potrebbe in realtà essere significativamente lontano dal valore vero del parametro non noto.\nÈ importante sottolineare che l’approccio frequentista offre un metodo per calcolare gli intervalli di confidenza per una vasta gamma di statistiche. Questo include, ad esempio, la stima dell’intervallo di confidenza per la differenza tra due medie, per una proporzione o per la differenza tra due proporzioni. Ecco le formule per calcolare gli intervalli di confidenza per i casi menzionati:\nIntervallo di confidenza per la differenza tra due medie.\nSe abbiamo due campioni indipendenti di dimensione \\(n_1\\) e \\(n_2\\), con medie \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) e deviazioni standard \\(s_1\\) e \\(s_2\\), l’intervallo di confidenza per la differenza tra le medie è calcolato come:\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}},\n\\]\ndove \\(t_{\\alpha/2}\\) è il valore critico della distribuzione t di Student con \\(\\alpha/2\\) di probabilità di coda e gradi di libertà \\(df = n_1 + n_2 - 2\\).\nIntervallo di confidenza per una proporzione.\nPer stimare l’intervallo di confidenza per una proporzione \\(p\\) in un campione binomiale di dimensione \\(n\\), la formula è:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}},\n\\]\ndove \\(\\hat{p}\\) è la proporzione campionaria e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.\nIntervallo di confidenza per la differenza tra due proporzioni.\nPer stimare l’intervallo di confidenza per la differenza tra due proporzioni \\(p_1\\) e \\(p_2\\) in due campioni binomiali di dimensioni \\(n_1\\) e \\(n_2\\), la formula è:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}},\n\\]\ndove \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) sono le proporzioni campionarie e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_conf_interv.html#esercizi",
    "href": "chapters/frequentist_inference/03_conf_interv.html#esercizi",
    "title": "82  Intervalli di fiducia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nChe cos’è un intervallo di confidenza dal punto di vista frequentista?\nChe cosa significa la copertura al 95% di un intervallo di confidenza?\nPerché non è corretto dire che “c’è il 95% di probabilità che il valore vero di \\(\\mu\\) cada in questo intervallo di confidenza”?\nIn cosa consiste la differenza tra un intervallo di confidenza costruito con la distribuzione normale standard \\(Z\\) e uno costruito con la distribuzione \\(t\\) di Student?\nPerché, nel caso di varianza incognita, si usa la deviazione standard campionaria \\(s\\) al posto di \\(\\sigma\\)?\nCome influenza la dimensione del campione \\(n\\) l’ampiezza dell’intervallo di confidenza?\nPerché gli intervalli di confidenza frequentisti si basano su un concetto di “ripetizione dell’esperimento” nel lungo periodo?\nQuali sono due fraintendimenti comuni sugli intervalli di confidenza?\nCome si interpreta correttamente un intervallo di confidenza al 95%?\nQual è la differenza essenziale tra un intervallo di confidenza frequentista e un intervallo di credibilità bayesiano?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nChe cos’è un intervallo di confidenza dal punto di vista frequentista?\n\nRisposta\nUn intervallo di confidenza (IC) è un range di valori costruito attorno a una stima campionaria (ad esempio, la media campionaria) che, secondo il metodo frequentista adottato, conterrà il valore vero del parametro in una certa proporzione di casi (ad esempio il 95%) se si ripetesse l’esperimento (ossia il campionamento) un numero molto grande di volte. Non esprime dunque la “probabilità” che il parametro sia dentro l’intervallo in un singolo caso, ma una frequenza di successo nel lungo periodo.\n\nChe cosa significa la copertura al 95% di un intervallo di confidenza?\n\nRisposta\nIl livello di copertura (ad esempio, 95%) indica che, in una serie ipotetica di infiniti campioni indipendenti e nel calcolo ripetuto di infiniti intervalli di confidenza secondo la stessa procedura, il 95% di tali intervalli conterrà il valore vero del parametro. È una proprietà della procedura di costruzione degli intervalli, non di un singolo intervallo già calcolato.\n\nPerché non è corretto dire che “c’è il 95% di probabilità che il valore vero di \\(\\mu\\) cada in questo intervallo di confidenza”?\n\nRisposta\nNella prospettiva frequentista, il parametro \\(\\mu\\) è considerato un valore fisso (non una variabile casuale). L’incertezza risiede nel campione e nella procedura di costruzione dell’intervallo, non nel parametro. Di conseguenza, non si può associare una probabilità alla posizione di \\(\\mu\\) all’interno di un singolo intervallo: l’intervallo o contiene \\(\\mu\\) oppure no, senza mezze misure probabilistiche.\n\nIn cosa consiste la differenza tra un intervallo di confidenza costruito con la distribuzione normale standard \\(Z\\) e uno costruito con la distribuzione \\(t\\) di Student?\n\nRisposta\n- Distribuzione \\(Z\\): si utilizza quando la varianza della popolazione \\(\\sigma^2\\) è nota (o si approssima molto bene) e la popolazione è normalmente distribuita, o quando il campione è molto grande (per applicare il teorema del limite centrale).\n- Distribuzione \\(t\\): si impiega quando la varianza \\(\\sigma^2\\) non è nota e bisogna stimarla con la deviazione standard campionaria \\(s\\). La distribuzione \\(t\\) “corregge” per l’incertezza aggiuntiva dovuta alla stima di \\(\\sigma\\) e diventa progressivamente simile alla normale standard quando il numero di gradi di libertà (cioè la dimensione del campione meno uno) è elevato.\n\nPerché, nel caso di varianza incognita, si usa la deviazione standard campionaria \\(s\\) al posto di \\(\\sigma\\)?\n\nRisposta\nQuando \\(\\sigma\\) non è nota, la si sostituisce con la stima campionaria \\(s\\). Poiché \\(s\\) è anch’essa una variabile casuale (cioè dipende dai dati osservati), introduce un’ulteriore fonte di incertezza. Questo giustifica l’uso della distribuzione \\(t\\) di Student anziché della normale standard, poiché \\(t\\) ingloba tale incertezza aggiuntiva.\n\nCome influenza la dimensione del campione \\(n\\) l’ampiezza dell’intervallo di confidenza?\n\nRisposta\nAumentando \\(n\\), l’errore standard della media (cioè \\(\\frac{\\sigma}{\\sqrt{n}}\\) oppure \\(\\frac{s}{\\sqrt{n}}\\)) diminuisce. Di conseguenza, l’intervallo di confidenza si restringe (a parità di livello di confidenza). In altre parole, con più dati a disposizione la stima della media è più “precisa” nel senso frequentista, e ciò si riflette in un IC più stretto.\n\nPerché gli intervalli di confidenza frequentisti si basano su un concetto di “ripetizione dell’esperimento” nel lungo periodo?\n\nRisposta\nLa filosofia frequentista definisce la probabilità come una frequenza relativa di un evento dopo molteplici repliche dell’esperimento. Per gli intervalli di confidenza, ciò implica che la probabilità di copertura (ad esempio 95%) è intesa come la frequenza con cui, ripetendo infinite volte il campionamento e la costruzione di IC allo stesso modo, l’intervallo calcolato conterrà il vero parametro. Non riguarda invece la probabilità del parametro di trovarsi in un intervallo specifico.\n\nQuali sono due fraintendimenti comuni sugli intervalli di confidenza?\n\nRisposta\n1. Credere che l’IC fornisca una probabilità diretta di contenere il parametro (es. “c’è il 95% di probabilità che \\(\\mu\\) sia qui dentro”) – in realtà, nel frequentismo \\(\\mu\\) è fisso e l’IC varia.\n2. Pensare che l’intervallo di confidenza sia significativo per la singola stima più che per la procedura – in realtà, il 95% di copertura si riferisce alla ripetizione dell’esperimento, non a un singolo intervallo.\n\nCome si interpreta correttamente un intervallo di confidenza al 95%?\n\nRisposta\n“Se ripetiamo più volte l’esperimento, ossia estraiamo molti campioni indipendenti dalla popolazione e costruiamo ogni volta un intervallo di confidenza con la stessa procedura, allora il 95% di quegli intervalli conterrà il valore vero della media \\(\\mu\\).” È dunque una garanzia circa l’efficacia della metodologia nel lungo periodo.\n\nQual è la differenza essenziale tra un intervallo di confidenza frequentista e un intervallo di credibilità bayesiano?\n\nRisposta\n- Intervallo di confidenza frequentista: descrive la performance a lungo termine di una procedura; non permette di affermare “la probabilità che \\(\\mu\\) sia nell’intervallo è il 95%”.\n- Intervallo di credibilità bayesiano: esprime direttamente una credenza probabilistica a posteriori sul parametro (ad esempio, “c’è il 95% di probabilità che \\(\\mu\\) sia in questo intervallo”), perché il parametro è trattato come variabile casuale, con una distribuzione a priori che si aggiorna con i dati osservati.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nDi seguito trovi 10 esercizi incentrati sulla costruzione di intervalli di confidenza. I primi 5 richiedono di svolgere i calcoli “a mano” (carta e penna o calcolatrice), gli ultimi 5 prevedono l’utilizzo di R.\nEsercizi da Risolvere “a Mano”\n\nIntervallo di Confidenza per la Media (Varianza Nota)\n\nUna ricercatrice vuole stimare la media di un punteggio di reattività emotiva (scala 0–100) in giovani adulti. Dai dati precedenti, si sa che la varianza vera (della popolazione) è \\(\\sigma^2 = 16\\). Si raccoglie un campione di \\(n=25\\) partecipanti e la media campionaria risulta \\(\\bar{X} = 45\\).\n1. Calcola l’intervallo di confidenza al 95% per la media della popolazione (\\(\\mu\\)).\n2. Fornisci un’interpretazione corretta (frequentista) del risultato.\n\nIntervallo di Confidenza per la Media (Varianza Incognita, 99%)\n\nIn un’indagine sulla soddisfazione lavorativa (scala da 1 a 7), vengono coinvolti \\(n=10\\) psicologi clinici. I dati raccolti forniscono:\n- Media campionaria \\(\\bar{X} = 5{,}6\\)\n- Deviazione standard campionaria \\(s=0{,}8\\)\nLa popolazione è considerata approssimativamente normale ma la varianza è ignota. Calcola l’IC al 99% per la vera media di soddisfazione \\(\\mu\\).\n\nIntervallo di Confidenza per la Differenza tra Due Medie (Varianze Incognite Uguali)\n\nUn team di psicologi del lavoro vuole confrontare i livelli di stress (scala 0–50) tra due gruppi di dipendenti di un’azienda (Campione 1: reparto A, Campione 2: reparto B). I dati sono:\n\nReparto A (\\(n_1=12\\)):\\(\\bar{X}_1 = 22\\), \\(s_1 = 4\\)\nReparto B (\\(n_2=10\\)):\\(\\bar{X}_2 = 19\\), \\(s_2 = 3{,}5\\)\n\nAssumi che le due popolazioni siano normali con varianze ignote ma uguali e calcola l’intervallo di confidenza al 95% per \\(\\mu_A - \\mu_B\\). (Usa quindi la formula con la varianza pooled.)\n\nIntervallo di Confidenza per una Proporzione\n\nUno studio pilota su un programma di training per la gestione dell’ansia vede 120 persone iscriversi. Alla fine del programma, 48 di loro riportano di aver diminuito la frequenza di attacchi di panico in modo “significativo”.\n1. Stima la proporzione campionaria \\(\\hat{p}\\).\n2. Calcola l’IC al 95% per la vera proporzione \\(p\\) di persone che trarrebbe beneficio “significativo” dal programma.\n\nIntervallo di Confidenza per la Differenza tra Due Proporzioni\n\nIn un esperimento, due gruppi di partecipanti ricevono diversi percorsi di psicoterapia per ridurre l’insonnia:\n\n\nGruppo 1 (\\(n_1=50\\)): 35 persone riportano un netto miglioramento del sonno.\n\n\nGruppo 2 (\\(n_2=40\\)): 20 persone riportano un netto miglioramento del sonno.\n\nSi vuole stimare la differenza \\((p_1 - p_2)\\) nelle proporzioni di successo dei due trattamenti. Calcola l’IC al 95%.\nEsercizi da Risolvere con R\nNei prossimi esercizi, utilizza R per effettuare i calcoli. I dati sono già contestualizzati in ambito psicologico.\n\nIntervallo di Confidenza per la Media (Varianza Incognita)\n\nHai misurato i tempi di reazione (in millisecondi) a uno stimolo di pericolo in un gruppo di 15 partecipanti. I dati (approssimati) sono:\nreaction_times &lt;- c(220, 250, 210, 240, 260, 270, 225, 255, 235, 245, 210, 270, 265, 220, 230)\n\nUtilizza R per calcolare la media e la deviazione standard campionaria.\n\nCostruisci (tramite t.test(reaction_times)) l’intervallo di confidenza al 95% per il tempo di reazione medio della popolazione.\n\n\nIntervallo di Confidenza per la Differenza tra Due Medie (Varianze Incognite)\n\nDue gruppi di studenti hanno svolto un test di memoria verbale dopo aver seguito differenti strategie di studio:\ngroupA &lt;- c(15, 12, 18, 10, 14, 16, 19, 11)\ngroupB &lt;- c(10, 9, 14, 11, 8, 12, 13, 15)\n\nCalcola in R le medie campionarie dei due gruppi.\n\nUtilizza t.test(groupA, groupB, var.equal = FALSE) per ottenere l’IC al 95% della differenza \\(\\mu_A - \\mu_B\\).\n\nRiporta i risultati numerici.\n\n\nIntervallo di Confidenza per una Proporzione (Studio su Fobia Specifica)\n\nIn un piccolo studio, hai i dati (binari: 1 = “attacco d’ansia”, 0 = “nessun attacco”) raccolti da 20 persone esposte a uno stimolo fobico:\nattacks &lt;- c(1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,0,0,1,0,1)\n\nCalcola in R la proporzione campionaria di attacchi d’ansia.\n\nUtilizza prop.test() per costruire l’IC al 95% per la proporzione vera di attacchi d’ansia in questa specifica situazione.\n\n\nIntervallo di Confidenza per la Differenza tra Due Proporzioni (Test A/B di un Training Psicologico)\n\nDue versioni di un training psicologico anti-stress (A e B) sono state testate su studenti universitari, registrando (binario: 1/0) se al termine del corso mostrano ridotti livelli di stress:\nversionA &lt;- c(1,1,0,1,1,0,1,0,1,1,0,1)\nversionB &lt;- c(0,0,1,1,1,0,1,0,0,1,0,0)\n\nCalcola in R \\(\\hat{p}_A\\) e \\(\\hat{p}_B\\).\n\nUsa prop.test(x = ..., n = ...) per l’IC al 95% di \\((p_A - p_B)\\).\n\nRiporta i risultati.\n\n\nSimulazione di Copertura per l’IC sulla Media (Contesto Psicologico)\n\nScrivi (o completa) uno script in R che simuli 1000 campioni di punteggi di ansia (scala 0–80) estratti da una distribuzione approssimata come Normale, con media vera \\(\\mu=40\\) e \\(\\sigma=10\\). Per ogni campione di ampiezza \\(n=25\\):\n\nCalcola la media campionaria e la deviazione standard.\n\nCostruisci l’IC al 95% (usando la distribuzione t).\n\nVerifica quante volte l’intervallo contiene il vero valore \\(\\mu = 40\\).\n\nStima la proporzione di copertura e commenta se è prossima a 0,95.\n\nEsempio di traccia:\nset.seed(123)\nn_sims &lt;- 1000\nn &lt;- 25\nmu &lt;- 40\nsigma &lt;- 10\n\ncount_included &lt;- 0\n\nfor(i in 1:n_sims){\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  # calcola media, sd, IC, verifica se 40 è dentro l’IC\n}\n\ncoverage &lt;- count_included / n_sims\ncoverage\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nSoluzioni Esercizi “a Mano”\nSoluzione 1\n\nDati: \\(\\sigma^2=16 \\implies \\sigma=4\\); \\(n=25\\); \\(\\bar{X}=45\\); livello di confidenza 95% (\\(\\alpha=0{,}05\\)).\n\nErrore standard:\\[\n\\text{SE} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{4}{5} = 0{,}8.\n\\]\n\nValore critico \\(z_{\\alpha/2}\\approx 1{,}96\\).\n\nMargine di errore:\\[\nE = z_{\\alpha/2} \\times \\text{SE} \\approx 1{,}96 \\times 0{,}8 = 1{,}57.\n\\]\n\nIC 95%:\\[\n45 \\pm 1{,}57 \\quad \\Rightarrow \\quad (43{,}43;\\, 46{,}57).\n\\]\n\n\nSoluzione 2\n\nDati: \\(n=10\\), \\(\\bar{X}=5{,}6\\), \\(s=0{,}8\\), confidenza 99% (\\(\\alpha=0{,}01\\)).\n\nGradi di libertà \\(df = 9\\). Il valore di \\(t_{\\alpha/2, df=9}\\) (per \\(\\alpha/2=0{,}005\\)) è approssimativamente 3,25 (dipende dalla tabella).\n\nErrore standard:\\[\n\\text{SE} = \\frac{s}{\\sqrt{n}} = \\frac{0{,}8}{\\sqrt{10}} \\approx \\frac{0{,}8}{3{,}162} \\approx 0{,}253.\n\\]\n\nMargine di errore:\\[\nE = 3{,}25 \\times 0{,}253 \\approx 0{,}82.\n\\]\n\nIC al 99%:\\[\n5{,}6 \\pm 0{,}82 \\quad \\Rightarrow \\quad (4{,}78;\\, 6{,}42).\n\\]\n\n\nSoluzione 3\n\nDati:\n\nCampione 1 (A): \\(n_1=12\\), \\(\\bar{X}_1=22\\), \\(s_1=4\\).\n\nCampione 2 (B): \\(n_2=10\\), \\(\\bar{X}_2=19\\), \\(s_2=3{,}5\\).\n\nIC 95% \\(\\Rightarrow \\alpha=0{,}05\\).\n\nSi assume varianza uguale (\\(\\sigma_A^2 = \\sigma_B^2\\)) \\(\\Rightarrow\\) varianza pooled.\n\n\n\n\nVarianza campionaria: \\(s_1^2=16\\), \\(s_2^2=12{,}25\\).\n\nVarianza pooled:\\[\ns_p^2\n= \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}\n= \\frac{(11 \\times 16) + (9 \\times 12{,}25)}{12 + 10 - 2}.\n\\] \\[\n= \\frac{176 + 110{,}25}{20}\n= \\frac{286{,}25}{20}\n= 14{,}3125.\n\\] \\[\ns_p = \\sqrt{14{,}3125} \\approx 3{,}785.\n\\]\n\nErrore standard della differenza:\\[\n\\text{SE}(\\bar{X}_1 - \\bar{X}_2)\n= \\sqrt{\\,s_p^2\\!\\left(\\tfrac{1}{n_1} + \\tfrac{1}{n_2}\\right)}\n= \\sqrt{\\,14{,}3125 \\times \\left(\\tfrac{1}{12} + \\tfrac{1}{10}\\right)}.\n\\] \\[\n\\tfrac{1}{12} + \\tfrac{1}{10} = 0{,}0833 + 0{,}1 = 0{,}1833.\n\\] \\[\n14{,}3125 \\times 0{,}1833 \\approx 2{,}624\n\\quad \\Rightarrow \\quad \\sqrt{2{,}624} \\approx 1{,}62.\n\\]\n\nDifferenza campionaria: \\(\\bar{X}_1 - \\bar{X}_2 = 3\\).\n\nValore critico \\(t_{\\alpha/2}\\) con \\(df = n_1 + n_2 - 2 = 20\\): circa 2,086.\n\nMargine di errore: \\(E \\approx 2{,}086 \\times 1{,}62 \\approx 3{,}38\\).\n\nIC 95%:\\[\n3 \\pm 3{,}38 \\quad \\Rightarrow \\quad (-0{,}38;\\, 6{,}38).\n\\] (Approssimando: i valori variano un po’ in base agli arrotondamenti.)\n\n\nSoluzione 4\n\nDati: \\(n=120\\), successo \\(x=48\\).\n\n\n\\(\\hat{p} = \\frac{48}{120}=0{,}4\\).\n\nErrore standard (approssimazione normale):\\[\n\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} = \\sqrt{\\frac{0{,}4 \\times 0{,}6}{120}} = \\sqrt{\\frac{0{,}24}{120}} = \\sqrt{0{,}002} \\approx 0{,}0447.\n\\]\n\nCon \\(\\alpha=0{,}05\\), \\(z_{\\alpha/2} \\approx 1{,}96\\).\n\nMargine di errore:\\[\nE = 1{,}96 \\times 0{,}0447 \\approx 0{,}0876.\n\\]\n\nIC 95%:\\[\n0{,}4 \\pm 0{,}0876 \\quad \\Rightarrow \\quad (0{,}3124;\\, 0{,}4876).\n\\]\n\n\nSoluzione 5\n\nDati:\n\nGruppo 1 (\\(n_1=50\\)): 35 successi \\(\\Rightarrow \\hat{p}_1=35/50=0{,}70\\).\n\nGruppo 2 (\\(n_2=40\\)): 20 successi \\(\\Rightarrow \\hat{p}_2=20/40=0{,}50\\).\n\n\n\nDifferenza: \\(\\hat{p}_1 - \\hat{p}_2=0{,}20\\).\n\nErrore standard:\\[\n\\sqrt{\\frac{0{,}70 \\cdot 0{,}30}{50} + \\frac{0{,}50 \\cdot 0{,}50}{40}}\n= \\sqrt{\\frac{0{,}21}{50} + \\frac{0{,}25}{40}}\n= \\sqrt{0{,}0042 + 0{,}00625}\n= \\sqrt{0{,}01045} \\approx 0{,}1022.\n\\]\n\nMargine di errore (al 95%, \\(z_{\\alpha/2}=1{,}96\\)):\\[\n1{,}96 \\times 0{,}1022 \\approx 0{,}200.\n\\]\n\nIC 95%:\\[\n0{,}20 \\pm 0{,}20 \\quad \\Rightarrow \\quad (0{,}00;\\, 0{,}40).\n\\] *(Può capitare un limite inferiore esattamente 0, se si arrotonda.)\n\nSoluzioni Esercizi con R\n(I risultati possono variare leggermente a seconda della versione di R e di eventuali correzioni di continuità nelle funzioni di test.)\nSoluzione 6\nreaction_times &lt;- c(220, 250, 210, 240, 260, 270, 225, 255, 235, 245, 210, 270, 265, 220, 230)\n\nmean(reaction_times)         # media\nsd(reaction_times)           # deviazione standard\nt.test(reaction_times)       # t.test con conf.level = 0.95 di default\n\nEsempio di risultato:\n\nMedia campionaria \\(\\bar{X}\\approx 240\\) (dipende dai dati esatti)\n\n\nt.test() riporta un IC 95% (ad es.): \\((230, 250)\\) [numeri a titolo di esempio].\n\n\n\nSoluzione 7\ngroupA &lt;- c(15, 12, 18, 10, 14, 16, 19, 11)\ngroupB &lt;- c(10, 9, 14, 11, 8, 12, 13, 15)\n\nmean(groupA)  # ~ 14.375\nmean(groupB)  # ~ 11.50\nt.test(groupA, groupB, var.equal = FALSE)\n\n\nEsempio di output (fittizio):\nWelch Two Sample t-test\ndata:  groupA and groupB\nt = 2.35, df = 13.7, p-value = 0.033\n95 percent confidence interval:\n  0.47  5.77\nsample estimates:\n  mean of x  mean of y \n      14.375     11.500\nQuindi l’IC 95% per \\(\\mu_A - \\mu_B\\) potrebbe essere circa \\((0{,}47;\\, 5{,}77)\\).\n\n\nSoluzione 8\nattacks &lt;- c(1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,0,0,1,0,1)\n\nsum(attacks)        # conta quanti \"1\"\nlength(attacks)     # 20\n\nprop.test(sum(attacks), length(attacks), conf.level = 0.95)\n\nSe, ad esempio, vi fossero 12 “1” su 20, \\(\\hat{p}=0{,}60\\).\n\nL’intervallo di confidenza al 95% (a seconda della continuity correction) potrebbe essere indicativamente \\((0{,}36;\\, 0{,}80)\\).\n\nSoluzione 9\nversionA &lt;- c(1,1,0,1,1,0,1,0,1,1,0,1)\nversionB &lt;- c(0,0,1,1,1,0,1,0,0,1,0,0)\n\nsumA &lt;- sum(versionA)\nsumB &lt;- sum(versionB)\nnA   &lt;- length(versionA)\nnB   &lt;- length(versionB)\n\nprop.test(c(sumA,sumB), c(nA,nB), conf.level = 0.95)\n\nEsempio:\n\n\nsum(versionA) = 8 successi su 12 (\\(\\hat{p}_A=0{,}666...\\))\n\n\nsum(versionB) = 5 successi su 12 (\\(\\hat{p}_B=0{,}416...\\))\n\nL’IC per \\(\\hat{p}_A - \\hat{p}_B\\) potrebbe essere, ad esempio, \\((-0{,}05;\\, 0{,}61)\\).\n\n\n\n(I numeri esatti variano a seconda dell’eventuale correzione di continuità.)\nSoluzione 10\nUn possibile script:\nset.seed(123)\nn_sims &lt;- 1000\nn &lt;- 25\nmu &lt;- 40\nsigma &lt;- 10\n\ncount_included &lt;- 0\n\nfor(i in 1:n_sims){\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  xbar &lt;- mean(sample_data)\n  s &lt;- sd(sample_data)\n  \n  # t critico\n  t_crit &lt;- qt(0.975, df = n - 1)\n  \n  # IC\n  se &lt;- s / sqrt(n)\n  E &lt;- t_crit * se\n  lower &lt;- xbar - E\n  upper &lt;- xbar + E\n  \n  if(mu &gt;= lower & mu &lt;= upper){\n    count_included &lt;- count_included + 1\n  }\n}\n\ncoverage &lt;- count_included / n_sims\ncoverage\n\n\nEsempio di risultato:\n&gt; coverage\n[1] 0.948\nOvvero ~94,8% degli IC contengono il vero valore \\(\\mu=40\\), in linea con il 95% atteso (piccole differenze dovute al caso).\n\n\nCommento Conclusivo\nIn ogni caso, ricorda sempre che l’interpretazione frequentista di un intervallo di confidenza si basa sulla “copertura a lungo termine” del metodo di costruzione dell’IC, non sulla probabilità che il vero parametro cada nell’intervallo specifico appena calcolato.\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 – Calcolo e interpretazione dell’IC frequentista per la media\n\n\nCalcola la media campionaria \\(\\bar{X}\\) e la deviazione standard campionaria \\(s\\).\n\nAssumendo che il punteggio SWLS nella popolazione di riferimento (ad esempio, “giovani adulti universitari”) sia approssimativamente normale ma con varianza sconosciuta, costruisci l’intervallo di confidenza al 95% per la media \\(\\mu\\) utilizzando la distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libertà (dove \\(n=10\\)).\n\n\nInterpreta questo intervallo di confidenza in ottica frequentista. Metti in evidenza la distinzione fra l’“interpretazione corretta” (copertura sul lungo periodo) e l’“interpretazione scorretta” (credere che ci sia il 95% di probabilità che \\(\\mu\\) stia nell’intervallo calcolato).\n\nSpunti di riflessione sui limiti:\n- Con un campione molto piccolo, l’intervallo di confidenza potrebbe essere molto ampio.\n- Se la popolazione non fosse davvero normale, la validità dell’IC con distribuzione \\(t\\) potrebbe essere compromessa.\n- In ottica frequentista, il singolo intervallo o contiene il vero valore di \\(\\mu\\) o non lo contiene: la “probabilità 95%” si riferisce alla procedura di costruzione, non a questo singolo intervallo specifico.\nEsercizio 2 – Sensibilità dell’IC a diversi livelli di confidenza\n\nUtilizzando gli stessi 10 dati, calcola:\n\nl’intervallo di confidenza all’80%\n\nl’intervallo di confidenza al 99%\n\n\n\nConfronta l’ampiezza dei tre intervalli (80%, 95%, 99%).\n\nCommenta dal punto di vista dell’interpretazione frequentista: perché l’IC al 99% è più ampio di quello al 95%, e quest’ultimo è più ampio di quello all’80%?\n\nSpunti di riflessione sui limiti:\n- Aumentare il livello di confidenza fa sì che l’IC si allarghi, spesso di molto se \\(n\\) è piccolo.\n- Un IC più ampio rassicura sulla “copertura” nel lungo periodo, ma è meno informativo per il singolo studio.\nEsercizio 3 – Utilizzo di software per il calcolo (ad esempio, R o altro)\n\n\nInserisci i dati in un software (come R). Puoi farlo in R con:\nswls_data &lt;- c(28, 22, 26, 18, 30, 24, 27, 17, 21, 25)\n\n\nCalcola la media e la deviazione standard in R, poi utilizza la funzione t.test():\nt.test(swls_data, conf.level = 0.95)\n\nRiporta l’intervallo di confidenza ottenuto e confrontalo con quello calcolato a mano.\nCommenta eventuali differenze (minime) dovute agli arrotondamenti o a correzioni interne di R.\nRibadisci la corretta interpretazione frequentista: se si ripetesse lo stesso studio molte volte (stessa dimensione campionaria, stesso contesto di popolazione, stessa procedura di calcolo), il 95% di questi IC conterrebbe il valore vero di \\(\\mu\\).\n\nEsercizio 4 – Confronto pratico e riflessioni critiche\n\nImmagina di avere un’ipotesi: “La media SWLS nella popolazione dei giovani adulti universitari è pari a 24” (un’ipotesi plausibile se la scala totale va da 5 a 35).\n\nOsserva l’IC al 95% che hai calcolato: contiene il valore 24?\n\nSe l’IC contiene 24, puoi dire che il valore “24” è “molto probabile”? (No, attenzione! Vedi interpretazione corretta vs. errata.)\n\nSe l’IC non contiene 24, puoi concludere che la media reale è “sicuramente” diversa da 24? (No, perché hai solo un campione piccolo e il concetto di significatività vs. copertura può essere fuorviante.)\n\nSpunti di riflessione sui limiti:\n- Il “livello di fiducia” dell’IC non è una “probabilità” che \\(\\mu\\) sia all’interno di un singolo intervallo: è una proprietà della procedura sul lungo periodo.\n- Con pochi dati, le assunzioni (come la normalità) e la variabilità casuale giocano un ruolo enorme: l’intervallo può risultare poco stabile e molto sensibile a pochi valori estremi.\n- L’IC non dice “quanto è plausibile 24” (questo sarebbe più vicino a un approccio bayesiano, che definisce un intervallo di credibilità). L’IC frequentista dice soltanto che, ripetendo molte volte la stessa procedura, nel 95% dei casi il vero \\(\\mu\\) cadrà entro l’intervallo calcolato in ciascuna ripetizione.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nSupponiamo siano stati raccolti i dati seguenti (sostituisci con i dati effettivi):\n28, 22, 26, 18, 30, 24, 27, 17, 21, 25\nEsercizio 1\n\nCalcolo di media e deviazione standard campionaria\n\nIndichiamo i punteggi come \\(X_1, X_2, \\dots, X_{10}\\). La media campionaria è:\n\\[\n\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i.\n\\]\nFacendo la somma \\(28 + 22 + 26 + 18 + 30 + 24 + 27 + 17 + 21 + 25 = 238\\).\nQuindi, con \\(n=10\\), otteniamo:\n\\[\n\\bar{X} = \\frac{238}{10} = 23.8.\n\\]\nPer la deviazione standard campionaria \\(s\\), si utilizza:\n\\[\ns = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n \\bigl(X_i - \\bar{X}\\bigr)^2}.\n\\]\nCalcolando (o usando un foglio di calcolo / software), si ricava approssimativamente:\n\\[\ns \\approx 4.26.\n\\]\n\nCostruzione dell’Intervallo di Confidenza al 95%\n\nPoiché la varianza è sconosciuta e il campione è piccolo, usiamo la distribuzione \\(t\\) di Student con \\(n-1 = 9\\) gradi di libertà.\n- Livello di confidenza: \\(95\\%\\).\n- \\(\\alpha = 0,05\\), quindi \\(\\alpha/2 = 0,025\\).\n- Il valore critico \\(t_{\\alpha/2,df=9}\\) è circa 2,262 (da tavole o software).\n\nErrore standard\n\n\\[\n\\text{SE} = \\frac{s}{\\sqrt{n}} = \\frac{4.26}{\\sqrt{10}} \\approx 4.26 / 3.162 \\approx 1.35.\n\\]\n\nMargine di errore\n\n\\[\nE = t_{\\alpha/2} \\times \\text{SE} \\approx 2.262 \\times 1.35 \\approx 3.05.\n\\]\n\nIntervallo di confidenza\n\n\\[\n\\bar{X} \\pm E \\quad \\Rightarrow \\quad 23.8 \\pm 3.05\n\\quad \\Rightarrow \\quad (20.75;\\, 26.85).\n\\]\n\nInterpretazione frequentista corretta\n\n\n\nInterpretazione corretta: se ripetessimo lo stesso tipo di studio molte volte (stessa procedura di campionamento, stesse dimensioni, stesso metodo di calcolo dell’IC), il 95% di questi intervalli conterrà il vero valore della media della popolazione (\\(\\mu\\)).\n\n\nInterpretazione scorretta (da evitare): “C’è il 95% di probabilità che la vera media sia qui dentro”. Nel frequentismo, \\(\\mu\\) è considerato un valore fisso e non aleatorio. L’incertezza riguarda l’intervallo, non il parametro.\n\nLimite: con poche osservazioni (n=10), l’intervallo può risultare piuttosto ampio. Inoltre, l’assunzione di normalità della popolazione di partenza potrebbe non essere pienamente soddisfatta.\nEsercizio 2\n\nCalcolo di due nuovi IC: 80% e 99%\n\nUtilizziamo gli stessi \\(\\bar{X} = 23.8\\), \\(s = 4.26\\), \\(n=10\\). Cambia solo il valore critico \\(t\\).\n\n\nIC all’80% (\\(\\alpha=0,20\\), \\(\\alpha/2 = 0,10\\)):\n\n\n\\(t_{0,10,df=9} \\approx 1.383\\)\n\n\n\\(\\text{SE} \\approx 1.35\\) (come prima)\n\nMargine di errore \\(E = 1.383 \\times 1.35 \\approx 1.87\\)\n\nIC 80%: \\((23.8 \\pm 1.87)\\) \\(\\Rightarrow\\) \\((21.93;\\, 25.67)\\).\n\n\n\nIC al 99% (\\(\\alpha=0,01\\), \\(\\alpha/2 = 0,005\\)):\n\n\n\\(t_{0,005,df=9} \\approx 3.25\\)\n\n\n\\(\\text{SE} \\approx 1.35\\)\n\nMargine di errore \\(E = 3.25 \\times 1.35 \\approx 4.39\\)\n\nIC 99%: \\((23.8 \\pm 4.39)\\) \\(\\Rightarrow\\) \\((19.41;\\, 28.19)\\).\n\n\n\n\nConfronto delle ampiezze\n\n\n\n80%: \\((21.93;\\, 25.67)\\) (più stretto)\n\n\n95%: \\((20.75;\\, 26.85)\\) (intermedio)\n\n\n99%: \\((19.41;\\, 28.19)\\) (più largo)\n\nAumentando il livello di confidenza, l’intervallo si espande. Per “coprire” il valore vero nel 99% delle volte, occorre un intervallo più ampio.\nEsercizio 3\n\nCalcolo in R\n\nSe in R inseriamo i dati:\nswls_data &lt;- c(28, 22, 26, 18, 30, 24, 27, 17, 21, 25)\n\nmean(swls_data)  # ~ 23.8\nsd(swls_data)    # ~ 4.26\nt.test(swls_data, conf.level = 0.95)\n\nConfronto con il calcolo “a mano”\n\nLa funzione t.test() (di default) eseguirà un One Sample t-test con confidenza 95%. Restituisce:\n\nUn IC molto simile a \\((20.75;\\, 26.85)\\), con possibili piccole differenze di arrotondamento.\n\n\nRibadire l’interpretazione\n\n\nIl risultato di t.test() potrebbe riportare:95 percent confidence interval: (20.72, 26.88)\n(o valori simili).\n\nAnche qui vale la regola: non è una probabilità che \\(\\mu\\) sia dentro, bensì una proprietà della procedura (lungo periodo).\n\nEsercizio 4\n\n\nIpotesi: “La media SWLS reale nella popolazione è 24”.\n\n\nVerifica se 24 è dentro l’IC al 95%. Dall’IC \\((20.75;\\, 26.85)\\), notiamo che 24 rientra in questo intervallo.\n\nSignifica che è “probabile” 24?\n\nAttenzione: l’IC frequentista non fornisce una probabilità su questo specifico valore. Dire che “24 è dentro l’intervallo” non equivale a dire “la probabilità che \\(\\mu\\) = 24 è 95%”.\n\n\n\nSe 24 fosse stato fuori dall’intervallo, non potremmo comunque affermare con certezza che \\(\\mu\\neq 24\\). Ricordiamo sempre che, con un campione così piccolo, l’incertezza è alta e l’IC si basa su assunzioni (normalità e stima corretta).\n\nLimiti dell’interpretazione\n\nCon campioni ridotti, basta poco (un outlier o una leggera deviazione dalla normalità) per alterare significativamente l’intervallo.\n\nIl livello di confidenza (ad es. 95%) è una proprietà della procedura: in una serie di infiniti studi simili, il 95% di quegli intervalli conterrebbe \\(\\mu\\). Non significa che, dato questo singolo intervallo, ci sia una “probabilità 95%” di includere il parametro.\n\nRiepilogo Finale\n\n\nValori Numerici:\n\nMedia \\(\\bar{X} = 23.8\\); dev. standard \\(s \\approx 4.26\\).\n\nIC 95% (a mano) \\(\\approx (20.75;\\, 26.85)\\).\n\nIC 80% \\(\\approx (21.93;\\, 25.67)\\); IC 99% \\(\\approx (19.41;\\, 28.19)\\).\n\n\n\n\nInterpretazione Frequentista:\n&gt; Nel lungo periodo, il 95% (o 99%, 80%, ecc.) degli intervalli calcolati con la stessa procedura conterrà il vero valore di \\(\\mu\\).\n\n\nLimiti (campioni piccoli, ipotesi di normalità, differenza tra “copertura ripetuta” e “probabilità che \\(\\mu\\) sia in un singolo IC”).\n\nIn questo modo, gli studenti vedono sia la parte di calcolo (formule, tabelle/valori critici, software) sia gli aspetti interpretativi (come evitare i fraintendimenti più comuni sul significato dell’IC frequentista).\nConclusioni generali\n\nCon un campione così piccolo (n=10), l’intervallo di confidenza può essere largo e sensibile a qualsiasi deviazione dall’assunzione di normalità.\n\nL’interpretazione frequentista si focalizza sulla “procedura” e sul “lungo periodo” (ripetizione dell’esperimento), non sulla probabilità che \\(\\mu\\) sia dentro questo intervallo specifico.\n\nÈ facile incorrere in fraintendimenti (“c’è il 95% di probabilità che la vera media sia qui dentro?”), occorre ribadire che la probabilità secondo il frequentismo riguarda il campionamento e la costruzione dell’intervallo, non la posizione fissa del parametro.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/03_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "title": "82  Intervalli di fiducia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bayestestR_0.17.0     cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        rmarkdown_2.29        ps_1.9.1             \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [28] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [31] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           codetools_0.2-20     \n#&gt; [40] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [43] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [46] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [49] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [52] stats4_4.5.1          insight_1.4.2         distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           mvtnorm_1.3-3        \n#&gt; [64] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [67] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [70] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [73] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [76] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [79] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_conf_interv.html#bibliografia",
    "href": "chapters/frequentist_inference/03_conf_interv.html#bibliografia",
    "title": "82  Intervalli di fiducia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21(5), 1157–1164.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_sample_size.html",
    "href": "chapters/frequentist_inference/04_sample_size.html",
    "title": "83  La grandezza del campione",
    "section": "",
    "text": "83.1 Introduzione\nLa scelta della dimensione del campione è fondamentale per garantire che i risultati di uno studio siano affidabili, bilanciando precisione e costi. In questo capitolo, esamineremo come calcolare la dimensione minima del campione necessaria per stimare la media di una popolazione con un margine di errore prefissato e un determinato livello di confidenza. Utilizzeremo un esempio tratto dalla psicologia per illustrare il processo e fornire implementazioni pratiche in R.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/04_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "title": "83  La grandezza del campione",
    "section": "\n83.2 La Logica Dietro la Scelta della Dimensione Campionaria",
    "text": "83.2 La Logica Dietro la Scelta della Dimensione Campionaria\nIn psicologia, è comune stimare la media di una variabile (ad esempio, il punteggio medio di una scala psicometrica). I vantaggi di utilizzare campioni più grandi includono:\n\n\nStime più precise: Con un campione più grande, la varianza dell’estimatore diminuisce, rendendo le stime più accurate.\n\nMaggiore fiducia nei risultati: Un campione più grande riduce il margine di errore, aumentando la certezza dei risultati.\n\nTuttavia, i campioni più grandi richiedono risorse maggiori in termini di tempo e denaro. Pertanto, il problema si riduce spesso a trovare il campione più piccolo che garantisca la precisione desiderata.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_sample_size.html#calcolo-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/04_sample_size.html#calcolo-della-dimensione-campionaria",
    "title": "83  La grandezza del campione",
    "section": "\n83.3 Calcolo della Dimensione Campionaria",
    "text": "83.3 Calcolo della Dimensione Campionaria\nPer campioni sufficientemente grandi, la media campionaria \\(\\bar{X}\\) segue una distribuzione normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n\\]\ndove:\n\n\n\\(n\\) è la dimensione del campione,\n\n\\(\\mu\\) è la vera media della popolazione,\n\n\\(\\sigma^2\\) è la varianza della popolazione.\n\nIl nostro obiettivo è trovare la dimensione campionaria \\(n\\) tale che:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) \\geq 0.95,\n\\]\ndove:\n\n\n\\(\\bar{X}\\) è la media campionaria,\n\n\\(\\mu\\) è la media della popolazione,\n\n\\(E\\) è il margine di errore massimo accettabile.\n\nSappiamo che, per il teorema centrale del limite, la media campionaria \\(\\bar{X}\\) può essere standardizzata come segue:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQuesta quantità \\(Z\\) segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\).\nQuindi, possiamo riscrivere la probabilità richiesta come:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) = P\\left(|Z| &lt; z_{0.025}\\right),\n\\]\ndove \\(z_{0.025} = 1.96\\) è il quantile superiore della distribuzione normale standard corrispondente a un livello di confidenza del \\(95\\%\\).\nDalla definizione della variabile standardizzata \\(Z\\), possiamo ricavare la relazione per il margine di errore:\n\\[\n|\\bar{X} - \\mu| &lt; E \\implies Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\implies \\left|\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\\right| &lt; \\frac{E}{\\sigma / \\sqrt{n}}.\n\\]\nSostituendo la condizione \\(|Z| &lt; z_{0.025}\\), otteniamo:\n\\[\n\\frac{E}{\\sigma / \\sqrt{n}} = z_{0.025}.\n\\]\nRisolvendo per \\(\\sqrt{n}\\), moltiplichiamo entrambi i membri per \\(\\sigma / \\sqrt{n}\\):\n\\[\nE = z_{0.025} \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nIsoliamo \\(\\sqrt{n}\\) dividendo entrambi i membri per \\(z_{0.025} \\cdot \\sigma\\):\n\\[\n\\sqrt{n} = \\frac{z_{0.025} \\cdot \\sigma}{E}.\n\\]\nInfine, eleviamo entrambi i membri al quadrato per ottenere \\(n\\):\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]\nIn conclusione, la dimensione campionaria minima \\(n\\) necessaria per soddisfare il margine di errore \\(E\\) e il livello di confidenza richiesto è:\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "href": "chapters/frequentist_inference/04_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "title": "83  La grandezza del campione",
    "section": "\n83.4 Stima della Media del Punteggio di Autostima",
    "text": "83.4 Stima della Media del Punteggio di Autostima\nConsideriamo un esempio pratico: vogliamo stimare la media del punteggio di autostima in una popolazione di giovani adulti, utilizzando la Rosenberg Self-Esteem Scale (RSES), che assegna un punteggio compreso tra 0 e 30.\nDettagli del Problema:\n\nDeviazione standard del punteggio: \\(\\sigma = 6\\) (stimata da studi precedenti).\nMargine di errore massimo accettabile: \\(E = 2\\).\nLivello di confidenza: \\(95\\%\\).\n\nImplementiamo in R la formula derivata in precedenza.\n\n# Parametri del problema\nsigma &lt;- 6     # Deviazione standard del punteggio RSES\nE &lt;- 2         # Margine di errore desiderato\nz_alpha &lt;- qnorm(0.975)  # Quantile superiore della distribuzione normale (95% confidenza)\n\n# Calcolo della dimensione campionaria\nn &lt;- (z_alpha * sigma / E)^2\nn &lt;- ceiling(n)  # Arrotondamento all'intero successivo\nn\n#&gt; [1] 35\n\nIn conclusione, la dimensione campionaria minima necessaria per stimare la media del punteggio di autostima con un margine di errore massimo di 2 punti e un livello di confidenza del 95% è \\(n = 35\\).\n\n83.4.1 Approfondimenti\n\n\nPrecisione e Livello di Confidenza Aumentando \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\nQuesto restringe l’intervallo di confidenza e migliora la precisione.\n\nCosto e Praticità Un campione più grande comporta costi più elevati. È importante trovare il giusto compromesso tra precisione e fattibilità.\nAdattamento ad Altri Livelli di Confidenza Per altri livelli di confidenza, basta modificare il quantile \\(z_{\\alpha/2}\\). Ad esempio, per un livello di confidenza del 99%, \\(z_{0.005} \\approx\\) 2.576.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_sample_size.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/04_sample_size.html#riflessioni-conclusive",
    "title": "83  La grandezza del campione",
    "section": "\n83.5 Riflessioni Conclusive",
    "text": "83.5 Riflessioni Conclusive\nDefinire la dimensione del campione rappresenta un passaggio cruciale nella progettazione di qualsiasi studio psicologico. Un approccio matematico rigoroso, fondato su analisi di potenza statistica e stime di effetti attesi, consente di ottimizzare il bilanciamento tra precisione dei risultati e limitazioni pratiche, come tempi, costi e disponibilità dei partecipanti. Questo equilibrio è fondamentale per garantire che i dati raccolti siano sufficientemente robusti da supportare conclusioni valide, senza tuttavia sprecare risorse in campioni eccessivamente ampi. Una corretta determinazione del campione contribuisce inoltre a ridurre il rischio di errori di tipo I e II, rafforzando l’integrità scientifica della ricerca.\nNel confronto tra paradigmi statistici, l’approccio frequentista si distingue per la sua enfasi sul controllo degli errori e sulla replicabilità attraverso il calcolo del valore p e della potenza statistica. Questo metodo richiede una rigorosa pianificazione preliminare, con la determinazione a priori della dimensione del campione basata su stime dell’effetto atteso e soglie prefissate di significatività e potenza. Tale rigidità metodologica, sebbene garantisca standardizzazione e controllo degli errori di Tipo I, può presentare notevoli limitazioni. In particolare, non permette modifiche alla dimensione del campione durante lo studio senza compromettere la validità statistica e può portare al problema dello “optional stopping”, dove il controllo ripetuto dei risultati aumenta il rischio di falsi positivi.\nL’approccio bayesiano, d’altra parte, offre una prospettiva complementare, ponendo l’accento sulla stima e sull’aggiornamento delle credenze in base ai dati osservati. Nel contesto bayesiano, la dimensione del campione non è solo uno strumento per garantire la significatività statistica, ma diventa un mezzo per affinare la precisione delle stime a posteriori. Questo approccio si caratterizza per una maggiore flessibilità, permettendo il monitoraggio continuo dell’evidenza attraverso i fattori di Bayes e l’aggiornamento sequenziale delle stime di probabilità. L’uso di distribuzioni a priori consente di incorporare conoscenze pregresse, portando a distribuzioni a posteriori che quantificano l’incertezza in modo più intuitivo e direttamente interpretabile.\nLa scelta di quando interrompere la raccolta dati rappresenta un esempio emblematico delle differenze tra i due approcci. Mentre il metodo frequentista richiede una dimensione campionaria fissa determinata a priori, l’approccio bayesiano permette una maggiore flessibilità, consentendo di interrompere la raccolta quando si raggiunge un livello desiderato di precisione nelle stime posteriori. Tuttavia, questa flessibilità comporta anche sfide specifiche, come la necessità di specificare distribuzioni a priori appropriate e una maggiore complessità computazionale.\nUna soluzione pragmatica potrebbe essere l’integrazione dei punti di forza di entrambi gli approcci. Si potrebbe utilizzare l’analisi della potenza frequentista per stabilire una dimensione minima del campione, implementando poi un monitoraggio bayesiano per valutare quando l’evidenza raccolta è sufficiente. Questo approccio integrato dovrebbe essere guidato da regole decisionali stabilite a priori e supportato da analisi di sensitività per valutare la robustezza delle conclusioni.\nIn sintesi, la scelta della dimensione del campione e la decisione su quando concludere la raccolta dati non dovrebbero essere viste solo come problemi tecnici, ma come opportunità per riflettere sulle priorità della ricerca, sul contesto teorico e sulle metodologie più adatte. La combinazione dei punti di forza degli approcci frequentista e bayesiano può portare a una ricerca più robusta, flessibile e informativa, contribuendo a un progresso scientifico più solido e sfaccettato. Tale scelta metodologica deve considerare gli obiettivi specifici dello studio, le risorse disponibili, i requisiti delle riviste scientifiche e la natura delle ipotesi da testare, bilanciando le esigenze di precisione con quelle di praticabilità. Pertanto, investire tempo nella pianificazione di questo aspetto non è solo una scelta metodologica, ma un imperativo etico per chiunque si impegni nella produzione di conoscenza psicologica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_sample_size.html#esercizi",
    "href": "chapters/frequentist_inference/04_sample_size.html#esercizi",
    "title": "83  La grandezza del campione",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Dimensione del campione per un margine di errore prefissato\n\nEsaminando i dati raccolti, hai ottenuto una deviazione standard campionaria (stimata) \\(s \\approx 4{,}3\\) sui punteggi SWLS.\nHai stabilito di voler stimare la media SWLS con un margine di errore massimo \\(E = 2\\) punti e un livello di confidenza del 95%.\n\nUtilizzando il valore critico \\(z_{0.025} \\approx 1{,}96\\) (per il 95%), ipotizza che la deviazione standard di popolazione \\(\\sigma\\) possa essere approssimata da \\(s\\). Calcola quindi la dimensione del campione \\(n\\) necessaria:\n\\[\nn = \\left(\\frac{z_{\\alpha/2} \\times \\sigma}{E}\\right)^2.\n\\]\n\nInterpreta il risultato: è un campione grande o piccolo? Quali fattori potrebbero influenzarne la validità (ad es. la stima di \\(\\sigma\\) da soli 10 soggetti)?\n\nEsercizio 2: Aumento del livello di confidenza e influenza su \\(n\\)\n\nCon gli stessi dati dell’Esercizio 1 (stesso \\(\\sigma\\approx4{,}3\\), stesso \\(E=2\\)), calcola la dimensione \\(n\\) se volessi un livello di confidenza del 99%.\n\nConfronta tale dimensione con quella trovata al 95%.\n\nCommenta: perché un livello di confidenza più elevato richiede un campione più grande? E in che modo ciò può impattare sull’organizzazione pratica della ricerca (tempi, costi, disponibilità di partecipanti)?\n\nEsercizio 3: Potere statistico per rilevare una differenza dalla media di riferimento\n\nIpotizza che la media SWLS di riferimento (ad es. in letteratura) sia 24.\n\nVuoi un test a una coda (one-sample t-test o z-test) con \\(\\alpha = 0{,}05\\), e desideri un potere (\\(1-\\beta\\)) dell’80% di rivelare una differenza di 3 punti (cioè vuoi essere in grado di concludere che la vera media è almeno 3 punti più alta o più bassa di 24).\n\nUsa come stima della deviazione standard la stessa \\(s \\approx 4{,}3\\). Sulla base delle formule di potenza statistica per un test a una coda, calcola un numero approssimativo di soggetti \\(n\\) necessari. (Suggerimento: puoi usare formule di power analysis o fare riferimento a software R, es. power.t.test() o pwr.t.test().)\n\n\nInterpreta la dimensione campionaria trovata: è realistica per un esperimento in cui potresti raccogliere partecipanti simili a quelli del pilot? Oppure rappresenta un valore troppo elevato?\n\nEsercizio 4: Confronto tra due gruppi e potere statistico\n\nIpotizza di voler confrontare due gruppi indipendenti (ognuno con punteggi SWLS) e di voler rilevare una differenza media di 5 punti tra i due gruppi (Gruppo A vs Gruppo B).\n\nAssumi che ciascun gruppo abbia la stessa deviazione standard \\(\\sigma = 4{,}3\\).\n\nVuoi un test a due code, \\(\\alpha=0{,}05\\), e un potere dell’80%. Utilizza (se vuoi) la formula approssimata per due campioni indipendenti, oppure uno strumento in R (ad es. power.t.test con type=\"two.sample\").\n\nCalcola (o stima) la dimensione \\(n\\) per ciascun gruppo.\n\n\nCommenta: confronta il risultato con la disponibilità realistica dei partecipanti. Che implicazioni metodologiche o pratiche emergono?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nSoluzione Esercizio 1\nDati principali:\n- \\(\\sigma \\approx 4{,}3\\) (stimata dal pilot)\n- \\(E = 2\\) (margine di errore)\n- Livello di confidenza 95% \\(\\Rightarrow z_{\\alpha/2} \\approx 1{,}96\\)\nLa formula per la dimensione campionaria:\n\\[\nn = \\left(\\frac{z_{\\alpha/2} \\times \\sigma}{E}\\right)^2\n\\]\nCalcolo:\n\\[\nn\n= \\left(\\frac{1{,}96 \\times 4{,}3}{2}\\right)^2\n= \\left(\\frac{8{,}428}{2}\\right)^2\n= (4{,}214)^2\n\\approx 17{,}76.\n\\]\nArrotondando all’intero superiore:\n\\[\nn \\approx 18.\n\\]\nInterpretazione\n\nServirebbero circa 18 partecipanti (anziché 10) per ottenere un IC al 95% con margine d’errore 2, ipotizzando \\(\\sigma \\approx 4{,}3\\).\n\n\nLimiti: la \\(\\sigma\\) deriva da un campione di sole 10 persone e potrebbe non rappresentare bene la deviazione standard reale dell’intera popolazione. Se in realtà \\(\\sigma\\) fosse più grande, \\(n\\) andrebbe rivisto al rialzo; se fosse minore, 18 potrebbe essere anche sovrastimato.\n\n18 non è troppo elevato; potrebbe essere gestibile in uno studio con costi contenuti. Tuttavia, la validità dipende dalla solidità della stima di \\(\\sigma\\).\n\nSoluzione Esercizio 2\nCambio di livello di confidenza: da 95% a 99%. Ora \\(\\alpha=0{,}01\\) e \\(\\alpha/2=0{,}005\\).\nIl valore critico \\(z_{0.005}\\) è circa 2,576.\n\\[\nn = \\left(\\frac{2,576 \\times 4{,}3}{2}\\right)^2\n= \\left(\\frac{11{,}0768}{2}\\right)^2\n= (5{,}5384)^2\n\\approx 30{,}7.\n\\]\nArrotondato in eccesso:\n\\[\nn \\approx 31.\n\\]\nConfronto con i 18 trovati prima\n- Aumentando la confidenza dal 95% al 99%, la dimensione campionaria passa da ~18 a ~31, cioè un incremento notevole.\n- Motivo: per assicurare un intervallo che, nel lungo periodo, includa il vero valore nel 99% dei casi, occorre un margine di errore più “tollerante” (oppure un campione più grande per mantenere lo stesso \\(E\\)).\n- Impatto pratico: reclutare 31 soggetti (invece di 18) può pesare in termini di costi e disponibilità, ma riduce l’incertezza dell’IC dal punto di vista frequentista.\nSoluzione Esercizio 3\nPotere statistico (80%) per rilevare \\(\\Delta = 3\\) in un test a una coda contro il valore di riferimento 24.\n- \\(\\alpha=0{,}05\\) (quindi una coda, il valore critico si situa intorno a z=1.645 per la potenza, ma i calcoli precisi si fanno di solito con formule di power analysis).\n- \\(\\sigma \\approx 4{,}3\\).\n- \\(\\Delta = 3\\).\nIn R, con pwr.t.test() o power.t.test(), l’approssimazione verrebbe impostata come:\nlibrary(pwr)  # se usi pwr\npwr.t.test(d = 3/4.3, sig.level = 0.05, power = 0.80,\n           type = \"one.sample\", alternative=\"greater\")\noppure:\npower.t.test(delta = 3, sd = 4.3, sig.level = 0.05, \n             power = 0.80, type = \"one.sample\", \n             alternative = \"one.sided\")\nEsempio di risultato (numeri indicativi): potresti ottenere \\(n \\approx 20\\). (Il valore preciso cambia a seconda delle approssimazioni e del software.)\nInterpretazione\n- Con 20 soggetti, se \\(\\Delta\\) fosse veramente di 3 punti rispetto a 24, il test a una coda dovrebbe avere l’80% di chance di rigettare l’ipotesi nulla (cioè di rilevare la differenza) a \\(\\alpha=0{,}05\\).\n- Se cercassi di replicare il pilot (dove avevi 10 soggetti), probabilmente la potenza sarebbe inferiore.\n- Potresti chiederti se 20 partecipanti siano facili da reclutare o se, dal punto di vista pratico, 20 restino pochi per altre ragioni (ad es. robustezza dei modelli, normalità, outlier).\nSoluzione Esercizio 4\n\nDue campioni indipendenti, differenza attesa = 5 punti, potere = 80%, test a due code\n\nCon formula approssimata (oppure software R), i parametri tipici:\n\n\nDifferenza minima rilevabile: \\(\\Delta = 5\\)\n\n\n\\(\\sigma = 4{,}3\\) in ciascun gruppo\n\n\n\\(\\alpha = 0{,}05\\) (due code), potere = 80%\n\nTipo di test: “two-sample t test” (Gruppo A vs Gruppo B, varianze uguali)\n\nIn R con power.t.test():\npower.t.test(delta = 5, sd = 4.3, sig.level = 0.05,\n             power = 0.80, type = \"two.sample\",\n             alternative = \"two.sided\")\nEsempio di risultato: potresti ottenere \\(n \\approx 14\\) per gruppo (quindi 28 totali). (Il numero può variare leggermente a seconda delle approssimazioni.)\n\nCommento\n\n\n\n18 o 20 partecipanti totali potrebbero bastare per un one-sample test (Esercizi 1–3), ma qui servono 28 (14 per gruppo) per avere lo stesso potere su una differenza di 5 punti.\n\nIn pratica:\n\nSe hai risorse per arruolare solo 15–20 persone totali, potrebbe non esserci potere sufficiente (grande rischio di errore di tipo II).\n\nPotrebbe convenire ridurre la differenza minima desiderata (ma questo cambierebbe le conclusioni) o cercare un campione più grande.\n\n\n\nLe considerazioni metodologiche includono: “Posso davvero aspettarmi 5 punti di differenza?” Se la differenza reale fosse più piccola, servirebbe un campione ancora più grande per rilevarla con sufficiente potenza.\n\nConclusioni Finali\n\nLa dimensione del campione dipende da molti fattori:\n\nVarianza (o deviazione standard) stimata.\n\nMargine di errore desiderato (o differenza minima rilevabile).\n\nLivello di confidenza o \\(\\alpha\\).\n\nPotere statistico \\((1-\\beta)\\).\n\n\n\nI dati SWLS di un pilot di 10 persone forniscono un’indicazione iniziale (stima di \\(\\sigma\\)), ma la precisione di quella stima è limitata.\n\nPer studi sperimentali o correlazionali, i calcoli di dimensione campionaria andrebbero fatti a priori (idealmente ancor prima di raccogliere i dati) e basati su stime realistiche o su letteratura pre-esistente.\n\nSe la stima di \\(\\sigma\\) o della dimensione dell’effetto \\(\\Delta\\) è incerta, è utile svolgere analisi di sensitività, variando gli input per vedere come cambiano i risultati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/04_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "83  La grandezza del campione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [19] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [22] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [25] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [28] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [31] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [34] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [37] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [40] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [43] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#&gt; [46] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [49] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [52] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [55] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [58] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [61] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [64] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [67] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#&gt; [70] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [73] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_sample_size.html#bibliografia",
    "href": "chapters/frequentist_inference/04_sample_size.html#bibliografia",
    "title": "83  La grandezza del campione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGiner-Sorolla, R., Montoya, A. K., Reifman, A., Carpenter, T., Lewis Jr, N. A., Aberson, C. L., Bostyn, D. H., Conrique, B. G., Ng, B. W., Schoemann, A. M., et al. (2024). Power to detect what? Considerations for planning and evaluating sample size. Personality and Social Psychology Review, 28(3), 276–301.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html",
    "title": "\n84  Significatività statistica\n",
    "section": "",
    "text": "84.1 Introduzione\nIl test di ipotesi è un metodo fondamentale della ricerca scientifica, utilizzato per fare inferenze sui parametri della popolazione a partire dai dati campionari. Nel contesto della psicologia, questo approccio viene frequentemente impiegato per valutare l’efficacia di interventi psicologici, confrontare teorie o approcci, analizzare l’influenza di variabili psicologiche su comportamenti e processi cognitivi, e approfondire i meccanismi alla base di fenomeni complessi come apprendimento, memoria ed emozioni.\nIn questo capitolo ci focalizzeremo sul test di ipotesi frequentista, un metodo largamente utilizzato ma non privo di limiti. È importante sottolineare che la comunità statistica sconsiglia di affidarsi esclusivamente a questo approccio come criterio decisionale per valutare la validità di un risultato sperimentale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#test-del-chi-quadrato",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#test-del-chi-quadrato",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.2 Test del Chi-Quadrato",
    "text": "84.2 Test del Chi-Quadrato\nPer introdurre il concetto di test di ipotesi nel contesto frequentista, iniziamo presentando uno dei test più semplici e utilizzati: il test del Chi-Quadrato. Questo test è particolarmente utile per valutare l’ipotesi di indipendenza tra due variabili categoriali organizzate in una tabella di contingenza (per ulteriori dettagli sulla struttura delle tabelle di contingenza, si veda il Capitolo 16).\nUna tabella di contingenza è una rappresentazione tabellare che mostra la distribuzione congiunta di due variabili categoriali. Ogni cella della tabella contiene la frequenza osservata delle combinazioni delle categorie delle due variabili. Inoltre, la tabella include i totali marginali, che rappresentano le somme delle frequenze per ciascuna riga e ciascuna colonna.\nIl test del Chi-Quadrato si pone una domanda fondamentale: “Come apparirebbe la tabella di contingenza se le due variabili fossero indipendenti?”. In altre parole, il test verifica se esiste una relazione significativa tra le due variabili o se, al contrario, le variabili sono indipendenti l’una dall’altra.\nCome già visto in precedenza analizzando la distribuzione di probabilità congiunta, si ha indipendenza quando le probabilità congiunte sono uguali al prodotto delle probabilità marginali. Partendo dalle proporzioni marginali, possiamo quindi calcolare i valori teorici attesi in ciascuna cella della tabella di contingenza, assumendo che le due variabili siano indipendenti.\nVa sottolineato che l’indipendenza è una proprietà della popolazione, non del campione. Pertanto, nei dati campionari, ci aspettiamo che i valori osservati nelle celle della tabella differiscano leggermente dai valori teorici attesi, anche se nella popolazione le variabili sono realmente indipendenti. La discrepanza complessiva tra i valori osservati e quelli attesi, calcolati sotto l’ipotesi di indipendenza, può essere misurata utilizzando una statistica chiamata Chi-Quadrato (\\(\\chi^2\\)).\nLa formula della statistica Chi-Quadrato è:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i} ,\n\\]\ndove:\n\n\n\\(O_i\\) rappresenta i valori osservati nelle celle della tabella,\n\n\n\\(E_i\\) rappresenta i valori attesi nelle celle, calcolati sotto l’ipotesi di indipendenza,\n\nLa somma (\\(\\sum\\)) viene effettuata su tutte le celle della tabella.\n\n\n84.2.1 Interpretazione della Statistica Chi-Quadrato\nLa statistica Chi-Quadrato misura la discrepanza complessiva tra i valori osservati e quelli attesi. Se non ci fosse differenza tra i valori congiunti osservati e quelli teorici, la statistica Chi-Quadrato sarebbe pari a zero. All’aumentare della discrepanza tra valori osservati e attesi, il valore della statistica Chi-Quadrato aumenta.\nPer valutare l’importanza della discrepanza osservata, utilizziamo la distribuzione campionaria della statistica Chi-Quadrato. Questa distribuzione descrive la probabilità di ottenere valori della statistica Chi-Quadrato sotto l’ipotesi nulla (indipendenza tra le variabili). La forma della distribuzione dipende dai gradi di libertà (\\(\\nu\\)), che si calcolano come:\n\\[\n\\nu = (n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1) ,\n\\]\ndove \\(n_{\\text{righe}}\\) e \\(n_{\\text{colonne}}\\) rappresentano rispettivamente il numero di righe e colonne della tabella di contingenza.\n\n84.2.2 Valutazione dell’Ipotesi di Indipendenza\nLa probabilità associata a una data discrepanza (\\(\\chi^2\\)) tra valori osservati e attesi, assumendo che l’ipotesi nulla sia vera, corrisponde all’area sotto la coda destra della distribuzione Chi-Quadrato, nell’intervallo [\\(C\\), \\(+\\infty\\)]. Questa probabilità è indicata come \\(p\\)-value.\nSe il \\(p\\)-value è molto piccolo (tipicamente inferiore a una soglia predefinita, come 0.05), possiamo rifiutare l’ipotesi nulla e concludere che è improbabile che le due variabili siano indipendenti nella popolazione.\n\n84.2.3 Riepilogo dei Passaggi del Test Chi-Quadrato\n\n\nCalcolo dei Valori Attesi: Per ogni cella, calcola \\(E_i\\) utilizzando la formula:\n\\[\nE_i = \\frac{\\text{Totale della Riga} \\times \\text{Totale della Colonna}}{\\text{Totale Complessivo}}\n\\]\n\n\nCalcolo della Statistica Chi-Quadrato: Usa la formula:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n\\]\n\nDeterminazione dei Gradi di Libertà: Calcola \\(\\nu\\) come \\((n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1)\\).\nConfronto con la Distribuzione Chi-Quadrato: Determina il \\(p\\)-value associato al valore di \\(\\chi^2\\) calcolato e valuta l’ipotesi nulla.\n\nIn conclusione, il Test Chi-Quadrato rappresenta uno strumento per verificare l’indipendenza tra due variabili categoriali. Grazie alla sua semplicità di applicazione e interpretazione, costituisce un metodo di analisi largamente utilizzato in ambito psicologico, sociale e statistico. Tuttavia, è importante prestare attenzione ai presupposti del test, come la sufficienza dei dati in ogni cella, per garantire risultati affidabili e interpretabili.\n\n# Creare la tabella di contingenza\nobserved &lt;- matrix(c(44, 0, 119, \n                              55, 68, 0, \n                              47, 0, 0),\n                            nrow = 3, byrow = TRUE)\n\n# Aggiungere i nomi di righe e colonne\nrownames(observed) &lt;- c(\"Biscoe\", \"Dream\", \"Torgersen\")\ncolnames(observed) &lt;- c(\"Adelie\", \"Chinstrap\", \"Gentoo\")\n\n# Visualizzare la tabella\nprint(observed)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe        44         0    119\n#&gt; Dream         55        68      0\n#&gt; Torgersen     47         0      0\n\n\nchi_square_result &lt;- chisq.test(observed)\nchi_square_result\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed\n#&gt; X-squared = 285, df = 4, p-value &lt;2e-16\n\nSvolgiamo i calcoli “a mano” usando R. Per calcolare la statistica del test del Chi-Quadrato “a mano” in R, segui questi passaggi:\nCalcoliamo i totali per righe e colonne e il totale complessivo.\n\n# Totali marginali\nrow_totals &lt;- rowSums(observed)\ncol_totals &lt;- colSums(observed)\ngrand_total &lt;- sum(observed)\n\n# Visualizzare i totali\nprint(\"Totali marginali per righe:\")\n#&gt; [1] \"Totali marginali per righe:\"\nprint(row_totals)\n#&gt;    Biscoe     Dream Torgersen \n#&gt;       163       123        47\nprint(\"Totali marginali per colonne:\")\n#&gt; [1] \"Totali marginali per colonne:\"\nprint(col_totals)\n#&gt;    Adelie Chinstrap    Gentoo \n#&gt;       146        68       119\nprint(paste(\"Totale complessivo:\", grand_total))\n#&gt; [1] \"Totale complessivo: 333\"\n\nI valori attesi si calcolano come:\n\\[\nE_{ij} = \\frac{\\text{Totale riga} \\times \\text{Totale colonna}}{\\text{Totale complessivo}} .\n\\]\n\n# Calcolo dei valori attesi\nexpected &lt;- outer(row_totals, col_totals) / grand_total\n\n# Visualizzare i valori attesi\nprint(\"Valori attesi:\")\n#&gt; [1] \"Valori attesi:\"\nprint(expected)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe      71.5      33.3   58.2\n#&gt; Dream       53.9      25.1   44.0\n#&gt; Torgersen   20.6       9.6   16.8\n\nLa statistica Chi-Quadrato si calcola con:\n\\[\n\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}} .\n\\]\n\n# Calcolo della statistica Chi-Quadrato\nchi_square_stat &lt;- sum((observed - expected)^2 / expected)\n\n# Visualizzare il risultato\nprint(paste(\"Statistica Chi-Quadrato:\", chi_square_stat))\n#&gt; [1] \"Statistica Chi-Quadrato: 284.590012688092\"\n\nI gradi di libertà si calcolano come:\n\\[\ndof = (\\text{n. righe} - 1) \\times (\\text{n. colonne} - 1) .\n\\]\n\n# Calcolo dei gradi di libertà\ndof &lt;- (nrow(observed) - 1) * (ncol(observed) - 1)\n\n# Visualizzare i gradi di libertà\nprint(paste(\"Gradi di libertà:\", dof))\n#&gt; [1] \"Gradi di libertà: 4\"\n\nConfrontiamo la statistica Chi-Quadrato con la distribuzione teorica per ottenere il p-value.\n\n# Calcolo del p-value\np_value &lt;- pchisq(chi_square_stat, df = dof, lower.tail = FALSE)\n\n# Visualizzare il p-value\nprint(paste(\"p-value:\", p_value))\n#&gt; [1] \"p-value: 2.28189154098739e-60\"\n\nInterpretazione:\nIl valore-\\(p\\) risulta molto piccolo, indicando che, se le variabili Isola e Specie fossero realmente indipendenti, sarebbe estremamente improbabile osservare una distribuzione delle specie di pinguini sulle tre isole così diversa da quella teoricamente attesa. In altre parole, il valore-\\(p\\) rappresenta la probabilità di ottenere, per puro caso, una discrepanza tra i valori osservati e quelli attesi pari o superiore a quella riscontrata nei dati.\nPoiché il valore-\\(p\\) è estremamente basso, possiamo concludere che l’ipotesi di indipendenza tra le variabili Isola e Specie non è plausibile. Questo indica che la distribuzione delle specie di pinguini varia in relazione all’isola, ovvero che conoscendo l’isola è possibile prevedere la distribuzione delle specie. In altre parole, le variabili Isola e Specie sono associate.\n\n84.2.4 Significatività Statistica: Un Concetto da Riconsiderare\nCome discusso nell’esempio precedente, un risultato è considerato “statisticamente significativo” se la probabilità che sia dovuto al caso è bassa, il che suggerisce che il risultato sia stabile o reale. Al contrario, risultati “non significativi” vengono spesso etichettati come privi di valore e ignorati. Questa semplificazione, però, può portare a gravi fraintendimenti. Ad esempio:\n\n\nDipendenza dal campione: La significatività statistica è fortemente influenzata dalla dimensione del campione; risultati apparentemente “significativi” possono emergere anche da effetti molto piccoli in campioni ampi.\n\nRisultati non significativi: Un risultato non significativo non implica che l’effetto sia nullo o irrilevante.\n\nScelte soggettive: Livelli di confidenza e test statistici differenti possono influenzare l’esito dell’analisi, portando a interpretazioni arbitrarie.\n\n84.2.5 Limiti e Applicazioni del Metodo Frequentista\nIl problema più grave dell’approccio frequentista è che esso non sempre mantiene la “promessa” di fornire una base oggettiva per la decisione statistica. Infatti, il ricorso esclusivo alla significatività statistica conduce a risultati opposti a quelli desiderati, aumentando il rischio di pubblicare risultati non replicabili o di trascurare evidenze importanti si veda il 89.\nIn alternativa, è più utile considerare il risultato osservato nel contesto scientifico più ampio, integrandolo con altre analisi. Questo approccio critico e completo consente di superare i limiti della significatività statistica e di interpretare i risultati con maggiore rigore.\n\n84.2.6 Un Caso Specifico: La Media del Campione\nTorniamo ora a esaminare il test di ipotesi all’interno del quadro frequentista, focalizzandoci sul caso di una variabile continua, diversamente dal contesto qualitativo trattato nel test del Chi-Quadrato. Per approfondire la comprensione della significatività statistica, analizzeremo in dettaglio l’utilizzo della media campionaria come stimatore della media della popolazione. Questa riflessione ci consentirà di esplorare sia i limiti che le applicazioni pratiche di tale strumento all’interno della statistica inferenziale frequentista. Attraverso questo esempio, potremo mettere in luce aspetti teorici e operativi dei test di ipotesi, nonché fornire indicazioni su come migliorare l’interpretazione dei risultati, con particolare riferimento al campo della ricerca psicologica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#il-test-di-ipotesi",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#il-test-di-ipotesi",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.3 Il Test di Ipotesi",
    "text": "84.3 Il Test di Ipotesi\nIl test di ipotesi è un metodo statistico utilizzato per valutare se i dati sono coerenti con l’ipotesi nulla (\\(H_0\\)). L’ipotesi nulla solitamente afferma che non vi è alcun effetto o differenza significativa, mentre l’ipotesi alternativa (\\(H_1\\)) rappresenta l’affermazione che si desidera testare. I dati del campione vengono analizzati per determinare se forniscono prove sufficienti per rifiutare l’ipotesi nulla. Un passaggio cruciale consiste nel calcolare il value-p.\n\n84.3.1 La procedura di Test di Ipotesi\nEsaminiamo in dettaglio le varie fasi della procedura del test di ipotesi di stampo frequentista.\nPasso 1: Formulare l’ipotesi nulla (\\(H_0\\)) e l’ipotesi alternativa (\\(H_1\\)) basandosi sulla domanda di ricerca.\nPasso 2: Stabilire un livello di significatività, α (solitamente 0.05).\nPasso 3: Selezionare il Test Statistico appropriato, verificare eventuali assunzioni e calcolare il test statistico.\nPasso 4: Decidere se il risultato è “statisticamente significativo” secondo (a) la regione di rifiuto o (b) il valore-p.\n\nL’approccio della regione di rifiuto. Basandosi sulla distribuzione campionaria nota del test statistico, la regione di rifiuto è un insieme di valori per il test statistico per i quali l’ipotesi nulla viene rifiutata. Se il valore osservato del test statistico rientra nella regione di rifiuto, allora si rifiuta l’ipotesi nulla.\nL’approccio del valore-p. Il valore-p è la probabilità di ottenere i risultati osservati, o risultati ancora più estremi, se l’ipotesi nulla è vera.\n\nConfrontiamo il valore-p calcolato con il livello di significatività α:\n\nSe il valore-p &lt; α, si rifiuta l’ipotesi nulla (\\(H_0\\)).\nSe il valore-p ≥ α, non si rifiuta l’ipotesi nulla (\\(H_0\\)).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.4 Il Test di Ipotesi nel Contesto Frequentista",
    "text": "84.4 Il Test di Ipotesi nel Contesto Frequentista\nSi noti che i metodi bayesiani e frequentisti non sono semplicemente due approcci diversi per rispondere alla stessa domanda, ma formulano domande fondamentalmente diverse. Pertanto, per comprendere il test di ipotesi frequentista, è essenziale chiarire cosa si intende per valore-p.\nL’American Statistical Association (ASA) definisce il valore-p come:\n\nthe probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value (Wasserstein e Lazar 2016).\n\nQuesta definizione può risultare difficile da comprendere perché contiene concetti complessi come “probabilità” e “modello statistico specificato”. Per capire meglio cosa rappresenta un valore-p, è necessario esaminare attentamente entrambi questi concetti. Questo ci porterà anche a una comprensione più profonda di altri concetti fondamentali per l’inferenza frequentista e ci aiuterà a distinguere tra inferenza frequentista e inferenza bayesiana.\nUna distinzione fondamentale tra l’approccio frequentista e quello bayesiano riguarda l’interpretazione della probabilità: il primo si basa sulla frequenza relativa degli eventi nel lungo periodo, mentre il secondo si basa sulla “certezza soggettiva” o sul grado di fiducia che un individuo attribuisce a un evento specifico.\nChiarito che la probabilità assume significati diversi nei contesti frequentista e bayesiano, possiamo chiederci quale nozione di probabilità sia implicita nella definizione del valore-p fornita dall’ASA. La visione comune suggerisce che si riferisca alle frequenze relative. Ma frequenze relative di cosa e ripetizioni di cosa?\nPossiamo riformulare la definizione dell’ASA in questo modo:\n\nIl valore-p si riferisce alla frequenza relativa di ottenere un riassunto statistico dei dati grande quanto o più grande del valore osservato in ripetizioni ipotetiche di un esperimento descritto da un modello statistico specificato.\n\nQuindi, l’approccio frequentista può essere descritto come un metodo per stimare il valore di un parametro attraverso esperimenti ipotetici, confrontando i nostri dati con i risultati di tali esperimenti per giudicare se i nostri dati sono sorprendenti o meno.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#applicazione-alla-media-campionaria",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#applicazione-alla-media-campionaria",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.5 Applicazione alla Media Campionaria",
    "text": "84.5 Applicazione alla Media Campionaria\nIn questo capitolo ci concentreremo sull’applicazione del processo di test di ipotesi frequentista alla media campionaria. Vedremo come la media di un campione possa essere impiegata per trarre inferenze sulla media di una popolazione, analizzandone limiti e possibili utilizzi nell’ambito dell’inferenza statistica frequentista.\nI test su uno o due campioni (one-sample e two-sample tests) hanno rappresentato le prime fondamenta dell’analisi statistica dei dati. Al giorno d’oggi, tuttavia, i nostri disegni sperimentali tendono a essere più complessi di quanto questi semplici test possano gestire. Nonostante ciò, tali test – in particolare il celebre t-test di Student – costituiscono ancora un’ottima porta d’ingresso alla modellazione statistica, poiché i principi su cui si basano sono relativamente intuitivi e consentono di familiarizzare con il processo di verifica dell’ipotesi.\nPer comprendere meglio i valori-p e la verifica del test di ipotesi, può essere molto utile ricorrere a simulazioni. Attraverso queste ultime è possibile ricreare condizioni sperimentali ipotetiche e osservare la variabilità dei risultati, fornendo così una prospettiva più chiara sulle implicazioni della statistica frequentista.\n\n84.5.1 La Distribuzione della Media Campionaria\nQuando consideriamo la media campionaria come stima della media di una popolazione, assumiamo che questa popolazione segua una distribuzione normale. Vogliamo quindi esplorare la distribuzione della media campionaria (\\(\\bar{X}\\)), che descrive la variazione di \\(\\bar{X}\\) attraverso infiniti campioni di dimensione \\(n\\). Abbiamo già dimostrato che, se la popolazione è normalmente distribuita, anche la distribuzione campionaria di \\(\\bar{X}\\) seguirà una distribuzione normale, con media \\(\\mu\\) (la media della popolazione) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\) (dove \\(\\sigma\\) è la deviazione standard della popolazione e \\(n\\) è la dimensione del campione).\n\n84.5.2 Test di Ipotesi sulla Media Campionaria\nSupponendo di conoscere \\(\\sigma\\) ma non \\(\\mu\\), utilizziamo i test di ipotesi per indagare quanto la media campionaria osservata si discosti da un valore ipotetico \\(\\mu_0\\), specificato dall’ipotesi nulla. Questo processo ci permette di valutare la plausibilità di \\(\\mu_0\\) come vera media della popolazione.\n\n84.5.3 Calcolo della Statistica del Test\nPer valutare quanto la media campionaria osservata si discosti dall’ipotesi nulla che propone \\(\\mu = \\mu_0\\), standardizziamo \\(\\bar{X}\\) usando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\nQuesta trasformazione produce una variabile \\(Z\\) che segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Valori estremi di \\(Z\\) (sia molto grandi che molto piccoli) suggeriscono che la media campionaria osservata è incompatibile con \\(\\mu_0\\), portando al rigetto dell’ipotesi nulla.\n\n84.5.3.1 Simulazione\nPer illustrare quanto espresso sopra attraverso una simulazione, consideriamo un esempio numerico. Supponiamo che \\(\\mu_0 = 100\\), \\(\\sigma = 15\\) e \\(n = 30\\). Vogliamo calcolare il valore-p per l’evento \\(\\bar{X} &gt; 105\\).\nLa simulazione può essere eseguita come segue:\n\n# To make the simulation reproducible\nset.seed(123)\n\nmu_0 &lt;- 100\nsigma &lt;- 15\nn &lt;- 30\nn_sim &lt;- 10000  # Number of simulations\n\n# Generate n_sim sample means from a N(mu_0, sigma/sqrt(n))\nsample_means &lt;- rnorm(n_sim, mean = mu_0, sd = sigma / sqrt(n))\n\n# Calculate the p-value as the proportion of sample means &gt; 105\np_value &lt;- mean(sample_means &gt; 105)\n\n# Print the p-value\nprint(p_value)\n#&gt; [1] 0.0339\n\nQuesto script simula la distribuzione campionaria di \\(\\bar{X}\\) sotto l’ipotesi nulla che \\(\\mu = \\mu_0\\) e calcola il valore-p per l’evento \\(\\bar{X} &gt; 105\\). Il valore-p indica la probabilità di osservare un valore di \\(\\bar{X}\\) così estremo (o più estremo) se l’ipotesi nulla fosse vera.\nIl risultato della simulazione può essere confrontato con il calcolo teorico del valore-p usando la distribuzione normale standard. Il valore \\(Z\\) per \\(\\bar{X} = 120\\) è calcolato come:\n\\[\nZ = \\frac{105 - 100}{15/\\sqrt{30}}\n\\]\nPossiamo usare la funzione stats.norm.sf() per trovare l’area sotto la curva normale standard a destra di questo valore \\(Z\\), che corrisponde al valore-p teorico.\n\n# Calculate the Z-score\nZ &lt;- (105 - 100) / (15 / sqrt(30))\nprint(Z)\n#&gt; [1] 1.83\n\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- pnorm(Z, lower.tail = FALSE)\n\nprint(upper_tail_prob)\n#&gt; [1] 0.0339\n\nOppure, in maniera equivalente\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- 1 - pnorm(105, mean = 100, sd = 15 / sqrt(30))\nprint(upper_tail_prob)\n#&gt; [1] 0.0339\n\nIl calcolo teorico mostra che il valore \\(Z\\) per una media campionaria di 105 è 1.82. Questo valore indica una deviazione sostanziale dalla media ipotizzata sotto l’ipotesi nulla (\\(\\mu_0 = 100\\)). Tale deviazione può essere quantificata dalla “sorpresa” indicata dal valore-p, dove valori-p piccoli rappresentano una maggiore sorpresa. Il valore-p ottenuto, pari a 0.0339, indica un elevato grado di sorpresa: come mostrato dalla simulazione, un valore di 105 o superiore si verifica solo nel 3.4% dei casi se l’esperimento viene ripetuto numerose volte sotto l’ipotesi nulla. Questo suggerisce che un risultato del genere è altamente improbabile se l’ipotesi nulla fosse vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#applicazioni-pratiche",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#applicazioni-pratiche",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.6 Applicazioni pratiche",
    "text": "84.6 Applicazioni pratiche\nNella precedente discussione, abbiamo supposto \\(\\sigma\\) nota. Tuttavia, poiché di solito non conosciamo il valore di \\(\\sigma\\) nella pratica, dobbiamo stimarlo utilizzando la deviazione standard campionaria \\(s\\). Pertanto, al posto di \\(\\sigma\\), possiamo utilizzare \\(s\\), ottenendo così la statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{\\frac{s}{\\sqrt{n}}}.\n\\]\nSi può dimostrare che la statistica \\(T\\) segue una distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà se il campione casuale è stato estratto da una popolazione normale.\nA questo punto, possiamo applicare la stessa logica descritta in precedenza e possiamom basarci sulla statistica \\(T\\) per testare un’ipotesi sulla media della popolazione. Utilizzando il valore critico appropriato dalla distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà e un livello di significatività predefinito, possiamo determinare se i dati osservati supportano o respingono l’ipotesi nulla sulla media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#ipotesi-statistiche",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#ipotesi-statistiche",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.7 Ipotesi statistiche",
    "text": "84.7 Ipotesi statistiche\nEsaminiamo in maggior dettaglio la procedura di test di ipotesi statistiche nel contesto frequentista. Definiamo innanzitutto l’ipotesi statistica come una dichiarazione riguardante la distribuzione di probabilità di una variabile casuale. Tale ipotesi può riguardare la forma funzionale della distribuzione o i parametri che la caratterizzano.\nIn particolare, l’ipotesi che riguarda i parametri di una o più popolazioni viene denominata ipotesi nulla e viene rappresentata come \\(H_0\\). Per un parametro sconosciuto \\(\\theta\\), l’ipotesi nulla viene formulata come:\n\\[\nH_0: \\theta \\in \\Theta_0 \\subset \\Theta,\n\\]\ndove \\(\\Theta_0\\) è un sottoinsieme del dominio \\(\\Theta\\), che rappresenta tutti i possibili valori del parametro \\(\\theta\\) coerenti con il modello statistico adottato. L’ipotesi nulla può essere semplice se \\(\\Theta_0\\) contiene un unico elemento, oppure composta se contiene più di un elemento.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.8 I passi di un test di ipotesi",
    "text": "84.8 I passi di un test di ipotesi\nPer prendere una decisione tra accettare o respingere l’ipotesi nulla, i frequentisti utilizzano un test statistico. Un test statistico frequentista ci permette di valutare se i dati osservati forniscono prove sufficienti per respingere o accettare un’ipotesi riguardante una proprietà di una popolazione di interesse e si può descrivere nel modo seguente.\nIniziamo formulando l’ipotesi nulla \\(H_0\\), che rappresenta un’affermazione specifica sulla popolazione. L’ipotesi alternativa \\(H_1\\) viene formulata come l’evento complementare rispetto all’evento specificato dall’ipotesi nulla. Successivamente, definiamo una statistica campionaria \\(\\mathcal{G}_n(X_1, \\dots, X_n)\\) che viene calcolata a partire dai dati campionari e che ha una distribuzione nota quando l’ipotesi nulla è vera.\nSuccessivamente, suddividiamo l’insieme di tutte le possibili realizzazioni della statistica \\(\\mathcal{G}_n\\) in due insiemi disgiunti: la “regione di accettazione” \\(\\mathcal{A}\\) e la sua regione complementare, la “regione di rifiuto” \\(\\mathcal{R}\\). La regione di accettazione rappresenta l’insieme dei valori che la statistica può assumere sotto l’ipotesi nulla, mentre la regione di rifiuto rappresenta l’insieme dei valori che la statistica può assumere se l’ipotesi nulla è falsa.\nInfine, selezioniamo un livello di significatività \\(\\alpha\\), che rappresenta la massima probabilità di respingere erroneamente l’ipotesi nulla quando questa è vera. Se l’osservazione della statistica \\(\\mathcal{G}_n\\) rientra nella regione di accettazione, allora l’ipotesi nulla non viene respinta; altrimenti, viene respinta a favore dell’ipotesi alternativa.\nIn sintesi, il test statistico ci consente di stabilire se i dati osservati forniscono sufficienti evidenze per rifiutare l’ipotesi nulla a favore dell’ipotesi alternativa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#ipotesi-alternativa",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#ipotesi-alternativa",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.9 Ipotesi alternativa",
    "text": "84.9 Ipotesi alternativa\nDurante un test di ipotesi, dopo aver definito l’ipotesi nulla \\(H_0\\), possono essere considerate diverse ipotesi alternative \\(H_1\\). Le ipotesi alternative più comuni si suddividono in tre tipi:\n\n\n\\(H_1: \\theta \\neq \\theta_0\\),\n\n\\(H_1: \\theta &gt; \\theta_0\\),\n\n\\(H_1: \\theta &lt; \\theta_0\\).\n\nQueste corrispondono rispettivamente a un test bidirezionale, un test unilaterale superiore (o destro) e un test unilaterale inferiore (o sinistro).\nLa scelta dell’ipotesi alternativa determina la definizione della regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla \\(H_0\\). La regione di rifiuto rappresenta i valori estremi della distribuzione, nella direzione dell’ipotesi alternativa \\(H_1\\). Nel caso di un test unilaterale inferiore, \\(\\mathcal{R}\\) si trova nella coda sinistra della distribuzione, nell’intervallo [\\(-\\infty\\), \\(\\theta_0\\)]. Nel caso di un test unilaterale superiore, \\(\\mathcal{R}\\) si trova nella coda destra della distribuzione, nell’intervallo [\\(\\theta_0\\), \\(\\infty\\)].\nI valori critici sono i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bidirezionale. Il risultato di un test viene considerato statisticamente significativo se il valore della statistica del test si trova nella regione di rifiuto \\(\\mathcal{R}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#valore-p",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#valore-p",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.10 Valore-p",
    "text": "84.10 Valore-p\nIl valore-p è definito come la probabilità che la statistica del test assuma un valore uguale o più estremo di quello osservato, considerando la distribuzione campionaria costruita assumendo come vera l’ipotesi nulla. La significatività statistica viene convenzionalmente definita come un valore-p inferiore a 0.05, indicando che l’evidenza osservata è improbabile da ottenere se l’ipotesi nulla è vera. Se il risultato osservato non raggiunge la significatività statistica, significa che la stima non è statisticamente significativa e che il valore osservato può essere spiegato da una semplice variazione casuale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#un-esempio-motivante",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#un-esempio-motivante",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.11 Un esempio motivante",
    "text": "84.11 Un esempio motivante\nPer esplorare il concetto di significatività statistica, possiamo prendere in considerazione uno studio svolto da Mehr et al. (2016) sul ruolo della musica nella trasmissione di messaggi sociali ai bambini. La musica è una forma d’arte presente in molte attività quotidiane e può trasmettere informazioni relative alla cultura e all’appartenenza sociale. Gli autori dello studio hanno voluto indagare se i bambini di soli 5 mesi avessero una preferenza per individui sconosciuti che cantavano loro una canzone familiare rispetto ad altri individui sconosciuti che cantavano una canzone simile, ma con una diversa melodia.\nDalle analisi condotte da Mehr et al. (2016) è emerso che la preferenza dei bambini si manifestava solo quando la canzone veniva cantata dai loro genitori durante la fase di familiarizzazione, ma non quando la stessa canzone veniva cantata da un estraneo. Secondo gli autori, questo dimostra che il significato sociale è un elemento chiave nella preferenza dei bambini, oltre alla familiarità con la canzone.\n\n84.11.1 Domanda della ricerca e ipotesi statistiche\nLa ricerca condotta da Mehr et al. (2016) si è concentrata sullo studio dell’influenza della musica sui messaggi sociali trasmessi ai bambini molto piccoli. Tuttavia, come molte altre ipotesi psicologiche, l’ipotesi principale non può essere valutata direttamente in termini quantitativi. Pertanto, i ricercatori devono formulare ipotesi statistiche, che, sebbene non coincidano con l’ipotesi della ricerca, possono essere esaminate in termini probabilistici.\nPer chiarire questo punto, consideriamo l’esperimento condotto sui bambini da Mehr et al. (2016). Dopo la fase di familiarizzazione con la canzone di prova, i bambini partecipanti sono stati sottoposti a un test in laboratorio, durante il quale sono stati mostrati due video. Nel primo video, un estraneo cantava la canzone di prova, mentre nel secondo video, un altro individuo cantava una canzone simile ma non familiare ai bambini. I ricercatori hanno misurato il tempo in cui i bambini fissavano ciascun video. Nel primo esperimento, la variabile dipendente era la media delle proporzioni di tempo che i bambini fissavano il video “familiare” rispetto al tempo di fissazione totale. Poiché l’ipotesi principale non può essere valutata direttamente, i ricercatori hanno formulato ipotesi statistiche che possono essere esaminate in termini probabilistici.\nPoiché nei tipici esperimenti psicologici, come nel caso della ricerca di Mehr et al. (2016), l’ipotesi della ricerca non può essere valutata direttamente, è necessario stabilire una connessione tra l’ipotesi della ricerca e l’ipotesi statistica. Nel caso specifico, ci sono tre possibili scenari da considerare:\n\nNel caso in cui i bambini non mostrino alcuna preferenza tra i due tipi di video-registrazione, la media delle proporzioni di tempo di fissazione per la popolazione sarà uguale a \\(\\mu = 0.5\\), in quanto i tempi di fissazione saranno uguali in media per le due video-registrazioni.\nSe invece gli autori della ricerca hanno ragione, i bambini mostreranno una preferenza per il video con la canzone familiare rispetto a quello con la canzone non familiare. In questo caso, l’ipotesi statistica sarà \\(\\mu &gt; 0.5\\), dove \\(\\mu = 0.5\\) rappresenta il livello di probabilità casuale.\nInfine, una terza possibilità è che i bambini siano maggiormente attratti da una melodia non familiare, contrariamente a quanto suggerito dagli autori della ricerca. In tal caso, l’ipotesi statistica diventa \\(\\mu &lt; 0.5\\).\n\nLe tre ipotesi precedenti sono esempi di ipotesi statistiche, che sono delle affermazioni riguardanti i valori di un parametro di un modello statistico. Nel caso dell’esperimento di Mehr et al. (2016), il modello statistico riguarda la distribuzione delle proporzioni dei tempi di fissazione di una popolazione virtuale di infiniti bambini di sei mesi di età. Ogni bambino avrà una proporzione di tempi di fissazione diversa dagli altri bambini. Il modello statistico descritto dai ricercatori rappresenta la distribuzione dei possibili valori della proporzione del tempo di fissazione nei confronti del video “familiare”. I dati raccolti dagli sperimentatori corrispondono alla media della proporzione del tempo di fissazione del video “familiare” e possono essere messi in relazione con il modello statistico.\n\n84.11.2 Domanda della ricerca e ipotesi statistiche\nLa distinzione tra l’ipotesi della ricerca e l’ipotesi statistica è cruciale durante il test delle ipotesi. L’ipotesi della ricerca riguarda l’affermazione che si intende testare sulla natura dei fenomeni psicologici, mentre l’ipotesi statistica riguarda il modello generativo dei dati, ovvero le proprietà della popolazione. Nel caso dell’esperimento condotto da Mehr e colleghi, l’ipotesi della ricerca afferma che la preferenza sociale dei bambini è influenzata dalla musica e, in particolare, dalla familiarità con i materiali musicali. L’ipotesi statistica, invece, sostiene che la media della proporzione del tempo di fissazione dei bambini sul video “familiare” sia maggiore di 0.5.\nI test di ipotesi vengono applicati alle ipotesi statistiche, non alle ipotesi della ricerca. Ciò significa che se l’esperimento non viene condotto nella maniera appropriata, il collegamento tra l’ipotesi statistica e la domanda della ricerca può essere spezzato. Ad esempio, se l’attore che canta la melodia familiare assomiglia ad uno dei genitori del bambino, mentre l’altro attore ha un aspetto molto diverso, allora potrebbe essere facile trovare evidenze a supporto dell’ipotesi statistica secondo cui la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” è maggiore di 0.5, ma ciò non avrebbe nulla a che fare con la domanda della ricerca.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.12 Ipotesi nulla e ipotesi alternativa",
    "text": "84.12 Ipotesi nulla e ipotesi alternativa\nFino a qui il ragionamento è stato semplice: il ricercatore ha un’ipotesi a proposito dei fenomeni psicologici e a tale ipotesi di ricerca corrisponde un’ipotesi statistica che riguarda il meccanismo generativo dei dati. Se il fenomeno psicologico possiede le proprietà suggerite dall’ipotesi della ricerca, allora il ricercatore può aspettarsi che i dati osservati abbiano alcune specifiche caratteristiche. A questo punto, però, il ragionamento diventa contro-intuitivo perché non è possibile verificare direttamente l’ipotesi statistica che corrisponde alla domanda della ricerca.\n\n84.12.1 Apagogia\nIn linea di principio, non è mai possibile dimostrare direttamente la verità di una proposizione. Tuttavia, possiamo dimostrare la sua verità in modo indiretto, ovvero provando la falsità della sua proposizione complementare.\nL’esempio classico è il seguente. Consideriamo la seguente proposizione: “Tutti i cigni sono bianchi” (questo è l’esempio ornitologico preferito da Popper). L’osservazione di un numero qualsiasi di cigni bianchi non è sufficiente a dimostrare la verità di questa proposizione – infatti, ci potrebbe essere da qualche parte un cigno non bianco che non abbiamo osservato (e infatti c’è). D’altra parte, invece, l’osservazione di un solo cigno che non sia bianco (ovvero, per esempio, l’osservazione di un cigno nero proveniente dall’Australia) può falsificare la proposizione considerata. Questa è la logica del falsificazionismo di Popper.\nQuesto modo di pensare è stato trasferito nella procedura di test di ipotesi di stampo frequentista. Dato che non possiamo dimostrare vera l’ipotesi statistica associata alla domanda della ricerca, seguiamo il percorso opposto. Ovvero, ci poniamo l’obiettivo di dimostrare falso l’evento complementare a quello specificato dall’ipotesi statistica associata alla domanda della ricerca. L’ipotesi statistica che vorremmo falsificare si chiama “ipotesi nulla” e viene denotata con \\(H_0\\). Nel caso dell’esempio che stiamo discutendo, l’ipotesi nulla è: \\(\\mu \\leq 0.5\\). Si noti che l’ipotesi nulla include tutte le possibili ipotesi statistiche che si possono formulare (ovvero, \\(\\mu = 0.5\\) e \\(\\mu &lt; 0.5\\)), ad eccezione di quella che è associata all’ipotesi della ricerca (ovvero, \\(\\mu &gt; 0.5\\)). Questo definisce, nel caso presente, un test unilaterale.\nIn pratica, ciò che stiamo facendo è dividere tutti i possibili valori di \\(\\mu\\) in due gruppi: quei valori che sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi alternativa, denotata con \\(H_1\\)) e quei valori che non sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi nulla).\nAvendo detto questo, la cosa importante da riconoscere è che l’obiettivo di un test di ipotesi frequentista non è quello di dimostrare che l’ipotesi alternativa è (probabilmente) vera; l’obiettivo è mostrare che l’ipotesi nulla è (probabilmente) falsa. La maggior parte delle persone ritiene che questo modo di ragionare sia piuttosto strano.\n\n84.12.2 La similitudine del processo penale\nUn test di ipotesi è spesso comparato ad un processo penale, dove l’ipotesi nulla rappresenta l’imputato, il ricercatore il pubblico ministero, e il test statistico il giudice. Così come in un processo penale, anche in un test di ipotesi c’è una presunzione di innocenza, dove l’ipotesi nulla viene considerata vera a meno che il ricercatore non dimostri, con evidenza al di là di ogni ragionevole dubbio, che è falsa. Il ricercatore progetta l’esperimento in modo da massimizzare la possibilità che i dati producano una condanna dell’ipotesi nulla. Il test statistico, rappresentato dal giudice in questa metafora, stabilisce le regole che devono essere seguite per giungere al verdetto e tali regole sono pensate per proteggere l’ipotesi nulla. In particolare, sono studiate per garantire che la probabilità di una condanna sia bassa se l’ipotesi nulla è effettivamente vera. È importante sottolineare che l’ipotesi nulla deve essere protetta, poiché il ricercatore sta cercando di dimostrare che essa è falsa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#due-tipi-di-errori",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#due-tipi-di-errori",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.13 Due tipi di errori",
    "text": "84.13 Due tipi di errori\nPrima di entrare nei dettagli su come viene costruito un test statistico è utile capire la logica su cui esso è basato. In precedenza abbiamo paragonato il test di ipotesi nulla ad un processo penale, ma ora dobbiamo essere più espliciti. Idealmente, vorremmo costruire il nostro test in modo da non commettere errori. Sfortunatamente, però, questo non è possibile: a volte il ricercatore è sfortunato e finisce per prendere la decisione sbagliata, anche se adotta un processo decisionale razionale. Ad esempio, può succedere che una moneta venga lanciata 10 volte di fila e produca testa tutte le 10 volte. Ciò sembra fornire una prova molto forte del fatto che la moneta è sbilanciata, ma c’è una possibilità su 1024 che ciò accada anche se la moneta è equilibrata. In altre parole, nella vita reale dobbiamo sempre accettare la possibilità che le nostre scelte siano sbagliate, anche quando sembrano ragionevoli. Di conseguenza, l’obiettivo dei test delle ipotesi statistiche non è quello di eliminare completamente gli errori (questo è impossibile), ma di ridurre gli errori al minimo.\nA questo punto, dobbiamo precisare meglio cosa intendiamo per “errori”. Iniziamo con il rendere esplicito quello che è ovvio: l’ipotesi nulla può essere vera o falsa, e il nostro test ci può condurre a rifiutare l’ipotesi nulla o a non rifiutarla. La decisione di rigettare o non rigettare l’ipotesi nulla ci espone dunque al rischio di commettere uno di due tipi di errore, come indicato nella figura seguente. L’errore di I tipo, denotato con \\(\\alpha\\), è quello che commettiamo se rigettiamo l’ipotesi nulla quando essa è vera; l’errore di II tipo, denotato con \\(\\beta\\), è quello che commettiamo se accettiamo l’ipotesi nulla mentre invece è vera l’ipotesi alternativa.\n\n\n84.13.1 Errore di I tipo: la protezione dei diritti dell’imputato\nIn precedenza abbiamo paragonato il test statistico ad un processo penale. Infatti, un processo penale richiede che si stabilisca la colpevolezza dell’imputato “oltre ogni ragionevole dubbio”. Le regole del processo penale sono state progettate per garantire che non ci sia (quasi) nessuna possibilità di condannare ingiustamente un imputato innocente: il processo penale è progettato (almeno in teoria) per proteggere i diritti dell’imputato. Detto in altri termini, il processo penale non mette sullo stesso piano i due tipi di errore che si possono commettere: punire un innocente o assolvere un colpevole. L’errore che consiste nel punire un innocente viene considerato assai più grave di quello che porta ad assolvere un colpevole.\nUn test statistico fa praticamente la stessa cosa: i test di ipotesi statistiche sono costruiti in modo tale da controllare la probabilità di un errore di I tipo, con l’obiettivo di mantenerla al di sotto di una certa soglia prefissata. Questa probabilità, denotata con \\(\\alpha\\), viene chiamata “livello di significatività del test”. Usando parole diverse, possiamo dire che un test di ipotesi ha un livello di significatività \\(\\alpha\\) se il tasso di errore di I tipo non è più grande di \\(\\alpha\\). Per convenzione, i ricercatori fanno uso di tre diversi livelli \\(\\alpha\\): 0.05, 0.01 e 0.001.\n\n84.13.2 Errore di II tipo: l’asimmetria del giudizio\nChe dire del tasso di errore di II tipo? In realtà, vorremmo tenere anche quello sotto controllo e denotiamo la probabilità di un errore di II tipo con \\(\\beta\\). Il livello d’errore \\(\\beta\\) viene raramente discusso ed è molto più comune fare riferimento alla potenza del test, che è la probabilità dell’evento complementare, ovvero la probabilità con cui rifiutiamo l’ipotesi nulla quando è realmente falsa, ovvero \\(1-\\beta\\). Un test viene detto “potente” quando è caratterizzato da un piccolo valore \\(\\beta\\) pur mantenendo il livello \\(\\alpha\\) sotto una piccola soglia di probabilità prefissata.\nSi noti l’asimmetria qui rivelata: i test di ipotesi sono progettati per garantire che il livello \\(\\alpha\\) sia mantenuto sotto la soglia prefissata, ma non esiste alcuna corrispondente garanzia a proposito di \\(\\beta\\). Sicuramente è preferibile che il tasso di errore di II tipo sia piccolo, e in generale i ricercatori cercano di progettare i loro esperimenti in maniera tale da avere una ragionevole potenza del test (\\(1 - \\beta\\)) – questo si ottiene utilizzando un campione sufficientemente grande – ma nella logica della costruzione del test di ipotesi questo aspetto è secondario rispetto alla necessità di controllare il tasso di errore di I tipo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.14 Come si costruisce un test di ipotesi?",
    "text": "84.14 Come si costruisce un test di ipotesi?\nRitorniamo all’esempio relativo allo studio di Mehr et al. (2016). In questo caso, sulla base all’ipotesi della ricerca, l’ipotesi nulla può essere formulata come \\(H_0: \\mu \\leq 0.5\\). Esaminando un campione di 32 bambini di età media pari a 5.6 mesi, Mehr et al. (2016) hanno scoperto che, in media, i bambini dirigevano lo sguardo verso il video “familiare” nel 56% del tempo totale di fissazione. Dunque, la media campionaria è \\(\\bar{X} = 0.56\\) Questo è il valore campionario rilevante per il test dell’ipotesi nulla.\nIngenuamente, potremmo pensare che, per decidere se \\(H_0\\) sia falsa o meno, sia sufficiente confrontare la proporzione calcolata nel campione con il valore \\(\\pi\\) specificato dall’ipotesi nulla. Nel caso presente, l’ipotesi nulla non specifica un unico valore \\(\\mu\\) ma bensì un intervallo di valori: \\([0, 0.5]\\). I dati campionari specificano un valore \\(\\bar{X} = 0.56\\), ovvero un valore che non è incluso nell’intervallo specificato da \\(H_0\\). Questo è incoraggiante. Se invece avessimo osservato \\(\\bar{X} = 0.41\\), per esempio, allora non ci sarebbe stato nient’altro da dire: se i dati osservati sono compatibili con \\(H_0\\) non c’è bisogno di eseguire alcun test statistico – abbiamo già trovato la risposta alla domanda della ricerca.\n\n84.14.1 La variabilità campionaria\nNel caso dell’esperimento di Mehr et al. (2016) che stiamo discutendo, \\(\\bar{X}\\) non cade nell’intervallo specificato da \\(H_0\\). Sulla base del valore osservato \\(\\bar{X} = 0.56\\) possiamo dunque concludere che \\(H_0\\) è falsa? Non così presto. Non è sufficiente trovare una differenza \\(\\bar{X} - \\mu\\) nella direzione giusta (cioè positiva, nel nostro caso). È anche necessario tenere in considerazione il fenomeno della variabilità campionaria.\nInfatti, la media \\(\\bar{X}\\) osservata in ogni singolo campione di ampiezza \\(n=32\\) è una variabile aleatoria: in ciascun possibile campione di ampiezza 32 i bambini si comportano in maniera diversa e, di conseguenza, \\(\\bar{X}\\) assumerà un valore diverso da campione a campione. Le statistiche campionarie – nel nostro caso la media \\(\\bar{X}\\) – sono di necessità diverse dai parametri. Ciò a cui noi siamo interessati è la media della popolazione, ovvero \\(\\mu\\), ma sfortunatamente conosciamo solo una sua realizzazione campionaria, ovvero \\(\\bar{X}\\).\nRisulta dunque chiaro che la nostra decisione rispetto ad \\(H_0\\) non può essere unicamente basata sulla differenza tra \\(\\bar{X} - \\mu\\). Infatti, è ragionevole pensare che, indipendentemente dal fatto che l’ipotesi nulla sia vera o meno, in alcuni campioni la differenza \\(\\bar{X} - \\mu\\) sarà positive mentre in altri campioni sarà negativa. Dobbiamo dunque trovare una procedura che riduca la possibilità di rifiutare \\(H_0\\) per effetto del caso soltanto. Possiamo (e dobbiamo) fare di meglio che considerare unicamente la differenza \\(\\bar{X} - \\mu\\).\n\n84.14.2 Le distribuzioni delle statistiche test\nIl metodo seguito dall’approccio frequentista per affrontare questo problema è quello di costruire la distribuzione della statistica test \\(\\mathcal{G}_n\\), rilevante per il test di \\(H_0\\), assumendo come vera l’ipotesi nulla. Questo è il concetto più contro-intuitivo di tutta la procedura di test di ipotesi dell’approccio frequentista. Esaminiamolo più in dettaglio.\nLo scopo della procedura di test statistici dell’approccio frequentista non è quello di verificare l’ipotesi alternativa: questo non è logicamente possibile. Invece, come suggerito dalla similitudine del processo penale all’ipotesi nulla, l’approccio frequentista si pone l’obiettivo di determinare se ci siano indizi sufficienti per “condannare” l’ipotesi nulla, ovvero, per rigettarla. In questa reductio ad absurdum, la “presunzione di innocenza” di \\(H_0\\) corrisponde all’idea che dobbiamo assumere come vera l’ipotesi nulla fino a prova contraria.\nNell’esempio che stiamo discutendo, assumere come vera l’ipotesi nulla significa assumere che il parametro \\(\\mu\\) (la media della popolazione) sia uguale a 0.5. Sulla base di questa assunzione, per i dati dell’esempio presente, è possibile costruire la distribuzione delle medie dei campioni di ampiezza 32. Standardizzando poi la media del campione, è possibile stabilire quanto sia “distante” dal valore atteso della distribuzione campionaria costruita assumento come vera \\(H_0\\).\nLa standardizzazione di \\(\\bar{X}\\) si effettua mediante il rapporto\n\\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}},\n\\]\ndove \\(\\bar{X}\\) è la media del campione (nel nostro caso, 0.56), \\(s\\) è la deviazione standard del campione (gli autori riportano \\(s\\) = 0.179) e \\(n\\) è l’ampiezza del campione (ovvero, \\(n\\) = 32). Per il caso presente otteniamo:\n\nT &lt;- (0.56 - 0.50) / (0.179 / sqrt(32))\nprint(T)\n#&gt; [1] 1.9\n\n\n84.14.3 Regioni di rifiuto e regioni di non rifiuto\nConoscendo la distribuzione dei valori della statistica test (distribuzione determinata assumendo come vera \\(H_0\\)) diventa poi possibile dividere l’insieme dei valori possibili di \\(\\mathcal{G}_n\\) (il nome che abbiamo assegnato ad una generica statistica test) in due regioni: i valori che ci portano a rigettare \\(H_0\\) (regione di rifiuto) e quelli che non ci consentono di rigettare \\(H_0\\) (regione di non rifiuto).\nPer decidere quanto deve essere grande la regione di rifiuto di \\(H_0\\) è sufficiente collocare nella regione di rifiuto i valori estremi della statistica test \\(\\mathcal{G}_n\\), ovvero quelli che sarebbe molto improbabile osservare se \\(H_0\\) fosse vera.\n\n84.14.4 Quando rifiutare l’ipotesi nulla\nSupponiamo che la figura seguente rappresenti la distribuzione campionaria della statistica test \\(\\mathcal{G}_n\\).\n\nSe i dati producono la statistica test \\(\\mathcal{G}_n^1\\), non possiamo rifiutare l’ipotesi nulla \\(H_0\\). Se invece i dati producono \\(\\mathcal{G}_n^2\\) allora possiamo rifiutare l’ipotesi nulla in favore dell’ipotesi alternativa. Ci sono varie cose da notare.\n\nLa regione di rifiuto è costituita da valori lontani dal centro della distribuzione campionaria della statistica test, la quale è stata costruita assumendo come vera \\(H_0\\).\nLa regione di rifiuto è situata nelle code della distribuzione. Vedremo in seguito anche degli esempi di regioni di rifiuto unilaterali.\nIn questa discussione, l’ipotesi alternativa non è menzionata. Rifiutiamo o non rifiutiamo \\(H_0\\) basandoci unicamente sulla distribuzione campionaria \\(f(\\mathcal{G}_n \\mid H_0)\\), cioè sulla probabilità della statistica test condizionata all’ipotesi nulla \\(H_0\\). L’ipotesi alternativa \\(H_1\\) viene presa in considerazione quando si sceglie dove posizionare la regione di rifiuto di \\(H_0\\), ma formalmente non gioca alcun ruolo nel rigettare o meno \\(H_0\\).\n\n84.14.5 Specificazione delle regioni di rifiuto\nL’ipotesi alternativa \\(H_1\\) può assumere forme diverse e ciò conduce a specificazioni diverse della regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\). La regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla corrisponde ai valori collocati agli estremi della distribuzione secondo la direzione dell’ipotesi alternativa \\(H_1\\).\n\nSe l’ipotesi alternativa è \\(H_1: \\theta \\neq \\theta_0\\) (dove \\(\\theta\\) è un generico parametro e \\(\\theta_0\\) è uno specifico valore del parametro), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute negli intervalli \\([-\\infty, \\theta_0]\\) e \\([\\theta_0, +\\infty]\\).\nSe l’ipotesi alternativa è \\(H_1: \\theta &lt; \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([-\\infty, \\theta_0]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di sinistra della distribuzione.\nSe l’ipotesi alternativa è \\(H_1: \\theta &gt; \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([\\theta_0, \\infty]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di destra della distribuzione.\n\nSi chiamano valori critici i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bilaterale. In un test bidirezionale, i valori critici lasciano in ciascuna delle due code della distribuzione della statistica test una probabilità pari a \\(\\alpha/2\\); in un test unidirezionale lasciano una probabilità pari ad \\(\\alpha\\) in una sola coda. Il risultato di un test si dice statisticamente significativo quando il valore della statistica test ricade nella regione di rifiuto \\(\\mathcal{R}\\).\n\n84.14.6 La decisione statistica\nIl processo di decisione statistica viene descritto da von Mises (1964) nel modo seguente:\n\nControllare (checking) o saggiare (testing) ha la forma seguente: se il “risultato osservato” ha una ‘piccola’ probabilità subordinatamente all’ipotesi assunta, respingiamo l’ipotesi. (p. 441)\n\nOvviamente l’ipotesi a cui von Mises fa riferimento è l’ipotesi nulla.\nIn pratica, possiamo decidere se rigettare o meno l’ipotesi nulla in due modi: determinando se la statistica test \\(\\mathcal{G}_n\\) cade o meno nella regione di rifiuto (come abbiamo descritto sopra) o confrontando il valore-\\(p\\) con \\(\\alpha\\) – i due metodi sono equivalenti.\nIl valore-p rappresenta la probabilità di osservare un valore della statistica test \\(\\mathcal{G}_n\\) pari a quello effettivamente osservato, o maggiore, quanto l’ipotesi nulla è vera. Se il valore-\\(p\\) è minore del livello di significatività \\(\\alpha\\), allora la statistica test cade nella regione di rifiuto di \\(H_0\\) e ciò conduce al rifiuto dell’ipotesi nulla. Tali concetti sono riassunti nella tabella seguente.\n\nPer l’esempio in discussione, la statistica \\(T\\) calcolata sopra si distribuisce come \\(t\\) di Student con \\(\\nu = 31\\) gradi di libertà. Il valore-p corrisponde dunque all’area sottesa ad una \\(t_{31}\\) nell’intervallo \\([1.896, +\\infty]\\) (test unidirezionale destro), ovvero\n\n# Calculate the upper tail probability for the t-distribution\np &lt;- 1 - pt(T, df = 31)\nprint(p)\n#&gt; [1] 0.0336\n\nDato che il valore-p è minore di \\(\\alpha = 0.05\\), Mehr et al. (2016) rifiutano \\(H_0\\) (cioè che la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” sia 0.5, o minore) e concludono che i bambini mostrano una preferenza per il video familiare.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#potenza-del-test",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#potenza-del-test",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.15 Potenza del test",
    "text": "84.15 Potenza del test\nRitorniamo ora al concetto di potenza del test. Il livello di significatività e la potenza del test vengono usati per quantificare la qualità dell’inferenza statistica. Idealmente, la procedura di test di ipotesi non dovrebbe giungere alla conclusione sbagliata. Ovvero, non dovrebbe respingere \\(H_0\\) quando essa è vera e dovrebbe respingere \\(H_0\\) in favore dell’alternativa quando \\(H_1\\) è vera. Ma questi sono solo due dei quattro esiti che, in principio, sono possibili, e corrispondono alle probabilità indicate di seguito.\n\nPossiamo pensare a \\(H_0\\) come all’ipotesi che descrive l’evento “nulla di interessante sta succedendo” – ad esempio, “la moneta è bilanciata”, “il trattamento non è migliore del placebo”, ecc. – e pensare ad \\(H_1\\) come al caso contrario, ovvero: “sta accadendo qualcosa di interessante”. Quindi la potenza del test, ovvero la probabilità \\(1 - \\beta\\) di rigettare \\(H_0\\) quando essa è falsa, corrisponde alla probabilità di rilevare qualcosa di interessante, quando qualcosa di interessante è effettivamente successo, mentre il livello di significatività corrisponde alla probabilità di affermare che qualcosa di interessante si è verificato, quando in realtà non è successo nulla di interessante.\nIl calcolo della potenza di un test è spesso difficile, perché richiede la conoscenza della distribuzione campionaria di \\(\\mathcal{G}_n\\) quando è vera l’ipotesi alternativa \\(H_1\\). Tipicamente possiamo aumentare la potenza di un test aumentando la numerosità del campione in maniera tale da diminuire la varianza delle distribuzioni della statistica test condizionate a \\(H_0\\) e ad \\(H_1\\). In un disegno sperimentale è importante determinare in anticipo il numero di prove o dei soggetti necessari per raggiungere la potenza desiderata.\n\n84.15.1 Neyman e Fisher\nLa procedura di test di ipotesi statistiche descritta sopra combina due approcci teorici diversi, proposti da Sir Ronald Fisher e Jerzy Neyman. La storia di questi due approcci non è lineare, poiché Fisher e Neyman hanno modificato le loro opinioni nel tempo, senza mai fornire una “verità definitiva” su come interpretare il loro lavoro.\nIn sintesi, Fisher considerava che il ricercatore avesse un’unica ipotesi (quella nulla) e che lo scopo fosse verificare se i dati fossero coerenti o meno con essa. In questo senso, il valore-\\(p\\) rappresenta la probabilità di osservare, sotto l’ipotesi nulla, il risultato ottenuto o uno ancora più estremo. Se il valore-\\(p\\) è piccolo, Fisher rifiutava l’ipotesi nulla. Tuttavia, poiché non venivano formulate altre ipotesi, non c’era modo di “accettare l’alternativa”.\nAl contrario, Neyman adottava un approccio più formale rispetto a Fisher e pensava che lo scopo della verifica delle ipotesi fosse quello di prendere decisioni. Secondo Neyman, il problema era decidere se accettare l’ipotesi nulla o l’alternativa e il test serviva a stabilire quale supporto venisse fornito alle due alternative. Per questo motivo, era fondamentale specificare in modo preciso l’ipotesi alternativa. Nel suo approccio, il valore-\\(p\\) non misurava la probabilità del risultato del test o di uno più estremo sotto l’ipotesi nulla, ma forniva una descrizione astratta dei “possibili test” che portavano all’accettazione dell’ipotesi nulla o dell’alternativa.\nAttualmente ci troviamo in una situazione strana e ambigua, dove sono presenti elementi di entrambi gli approcci. La procedura di verifica di ipotesi statistiche distingue tra un’ipotesi nulla e un’ipotesi alternativa, seguendo la visione di Neyman, ma definisce il valore-\\(p\\) in termini di dati estremi, come avrebbe fatto Fisher, in confronto con un livello \\(\\alpha\\) stabilito da Neyman. Alcuni test statistici specificano in modo chiaro l’ipotesi alternativa, mentre altri sono più vaghi in merito, adottando l’approccio di Fisher. Inoltre, c’è disaccordo tra i ricercatori riguardo alla possibilità di “accettare l’alternativa”, a seconda che si segua Neyman o Fisher. Questa confusione costituisce il “peccato originale” della procedura di verifica di ipotesi statistiche. Tuttavia, ci sono motivi più specifici per cui questo approccio, noto come significatività statistica, viene criticato da molti ricercatori come una delle cause principali della crisi della replicabilità dei risultati della ricerca in psicologia e in altri campi. Nel capitolo ?sec-errors-s-m esploreremo queste ragioni in dettaglio.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.16 La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni",
    "text": "84.16 La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni\nConcludiamo l’analisi della procedura dei test di ipotesi statistici esaminando l’evento che ha ispirato Ronald A. Fisher a sviluppare la sua teoria dell’inferenza statistica, focalizzata sul test dell’ipotesi nulla. Questo episodio è descritto dettagliatamente da Etz et al. (2018). L’aneddoto riguarda un tè che Fisher aveva offerto alla sua collega, la Dott.ssa Muriel Bristol. Durante la preparazione della bevanda, la Dr.ssa Bristol contestò il metodo adottato da Fisher, asserendo che il tè avrebbe avuto un gusto migliore se il latte fosse stato versato prima dell’acqua bollente. Per verificare l’affermazione della Dr.ssa Bristol, Fisher ideò un esperimento di discriminazione sensoriale. Nei test condotti, la Dr.ssa Bristol fu in grado di individuare correttamente il processo di preparazione del tè in cinque occasioni su sei.\nQuesto risultato pose Fisher di fronte a un interrogativo: la sua collega stava semplicemente facendo una supposizione fortunata, oppure era effettivamente in grado di discernere tra le due diverse modalità di preparazione? Per risolvere questa questione, Fisher elaborò la sua metodologia per il test dell’ipotesi nulla. Utilizzò un valore-\\(p\\) calcolato sulla base della probabilità dell’evento osservato, nonché di qualsiasi altro evento più estremo che potrebbe verificarsi sotto l’ipotesi nulla.\nTuttavia, è stato fatto notare che l’approccio di Fisher al test dell’ipotesi nulla può essere insufficiente e portare a conclusioni errate (Etz et al., 2018). Una delle questioni fondamentali riguarda la definizione di un evento “più estremo” rispetto a quello osservato.\nSupponiamo che lo scopo dell’esperimento casuale sia di determinare l’accuratezza delle riposte della Dr.ssa Bristol in esattamente sei tentativi (e non di più). In tale caso, con 5 risposte corrette, il valore-\\(p\\) è pari a 0.109, che non è statisticamente significativo. In questo scenario, secondo la logica di Fisher, non si dovrebbe respingere l’ipotesi nulla che la Dr. Bristol stesse semplicemente indovinando.\nSupponiamo ora che lo scopo dell’esperimento casuale sia di continuare a servire tè fino a quando la Dr.ssa Bristol non abbia raggiunto cinque risposte corrette (un risultato che, per coincidenza, si è verificato dopo sei tentativi). Se analizziamo i dati in questo secondo scenario, il valore-\\(p\\) diventa pari a 0.031, che è statisticamente significativo. In quest’ultimo caso, l’ipotesi nulla verrebbe respinta.\nQuello che emerge è che, nonostante i dati osservati nei due scenari siano identici, giungiamo a conclusioni opposte come conseguenza delle diverse modalità di campionamento impiegate. Questa variabilità è problematica poiché il valore-\\(p\\), e quindi la nostra valutazione delle capacità discriminative della Dr.ssa Bristol, dipendono non solo dai dati effettivamente raccolti, ma anche dal disegno sperimentale adottato. Questa constatazione mette in discussione la robustezza del test dell’ipotesi nulla come strumento fondamentale per l’inferenza scientifica.\nPer illustrare il problema, svolgiamo i calcoli utilizzando le distribuzioni statistiche richieste per i due tipi di campionamento: la distribuzione binomiale e la distribuzione geometrica negativa.\n\n84.16.1 Distribuzione Binomiale\nLa distribuzione binomiale è la distribuzione da utilizzare quando il numero di tentativi è prefissato e conosciuto a priori. Nel contesto dell’esempio del tè, assumiamo che siano state servite esattamente sei tazze. La formula per determinare la probabilità di registrare esattamente \\(k\\) successi in \\(n\\) tentativi è la seguente:\n\\[\nP(X = k) = \\binom{n}{k} \\times p^k \\times (1-p)^{(n-k)}\n\\]\nQui, \\(\\binom{n}{k}\\) rappresenta il coefficiente binomiale, \\(p\\) è la probabilità di un singolo successo (ossia di indovinare correttamente la preparazione del tè), e \\((1-p)\\) è la probabilità di un singolo fallimento.\nPer calcolare il valore-\\(p\\) in questo specifico contesto, dobbiamo sommare le probabilità di ottenere un risultato di 5 o più estremo su un totale di 6 tentativi.\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success\n\n# Calculate the p-value for the binomial distribution\np_value_binomial &lt;- 1 - pbinom(n_success - 1, size = n_binomial, prob = p)\n\np_value_binomial\n#&gt; [1] 0.109\n\n\n84.16.2 Distribuzione Geometrica Negativa\nNel contesto dell’esperimento del tè, quando il test continua fino al raggiungimento di un numero prefissato di successi (nel nostro caso, cinque identificazioni corrette), la distribuzione di riferimento appropriata è la distribuzione geometrica negativa.\nLa distribuzione geometrica negativa modella il numero di fallimenti \\(k\\) che si verificano prima di ottenere un numero prefissato \\(r\\) di successi in una sequenza di prove indipendenti di Bernoulli, dove ogni prova ha probabilità di successo \\(p\\).\nLa probabilità di osservare esattamente \\(k\\) fallimenti prima di ottenere \\(r\\) successi è data da:\n\\[\nP(X = k) = \\binom{k+r-1}{k} p^r (1-p)^k,\n\\]\ndove:\n\n\n\\(k\\) è il numero di fallimenti,\n\n\\(r\\) è il numero di successi desiderato,\n\n\\(p\\) è la probabilità di successo in ogni prova,\n\n\\(\\binom{k+r-1}{k}\\) è il coefficiente binomiale che rappresenta il numero di modi possibili in cui \\(k\\) fallimenti e \\(r\\) successi possono essere ordinati.\n\nNel nostro caso specifico:\n\n\n\\(r = 5\\) (successi desiderati),\n\n\\(p = 0.5\\) (probabilità di indovinare correttamente sotto l’ipotesi nulla),\n\n\\(k\\) varia da 0 a 1 (possibili fallimenti prima del quinto successo).\n\nIl valore-p si calcola sommando le probabilità per tutti i casi “più estremi” di quello osservato:\n\\[\n\\text{valore-p} = \\sum_{k=0}^{1} \\binom{k+5-1}{k} (0.5)^5 (0.5)^k.\n\\]\nImplementazione:\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success (guessing the tea cup)\n\n# Calculate the p-value for the negative binomial distribution\np_value_geom_corrected &lt;- 0\nfor (k in 0:(n_binomial - n_success - 1)) {  # Number of failures before the 5th success\n  p_value_geom_corrected &lt;- p_value_geom_corrected + \n    choose(k + n_success - 1, k) * ((1 - p)^k) * (p^n_success)\n}\n\np_value_geom_corrected\n#&gt; [1] 0.0312\n\nIn conclusione,\n\nper la distribuzione binomiale, il p-value è \\(0.109\\), che non è statisticamente significativo (dato che è maggiore di 0.05); quindi, secondo Fisher, in questo caso non dovremmo rigettare l’ipotesi nulla che Dr. Bristol stia indovinando.\nper la distribuzione geometrica negativa, il p-value è \\(0.031\\), che è statisticamente significativo (dato che è minore di 0.05); in questo caso, dovremmo rigettare l’ipotesi nulla, suggerendo che Dr. Bristol non sta semplicemente indovinando.\n\nLa presente discussione mostra che, in base alla procedura del test dell’ipotesi nulla, la stessa sequenza di eventi (5 successi su 6 tentativi) può portare a conclusioni opposte a seconda delle ipotesi sul processo di campionamento. Questo paradosso è uno dei motivi (per ulteriori critiche, si veda Wasserstein & Lazar (2016); Benjamin et al. (2018)) per cui l’inferenza bayesiana è diventata più popolare negli ultimi anni come quadro alternativo per il test delle ipotesi e la stima dei parametri.\n\n84.16.3 Approccio Bayesiano\nNel loro lavoro, Etz et al. (2018) propongono un’alternativa bayesiana per risolvere il problema esaminato da Fisher. Questa soluzione bayesiana evita le contraddizioni che emergono quando si cercano di definire “risultati più estremi” che non sono stati osservati. L’approccio bayesiano si focalizza esclusivamente sui dati effettivamente raccolti e utilizza queste osservazioni per aggiornare le probabilità iniziali (o “a priori”) associate a diverse ipotesi. Il processo si basa sulla regola di Bayes e si sviluppa in tre fasi principali:\n\nStabilire Probabilità a Priori: Iniziamo assegnando una distribuzione di probabilità a priori a tutti i possibili tassi di successo che la Dr. Bristol potrebbe avere. Questo include una probabilità specifica per l’ipotesi nulla, che suggerisce che la Dr. Bristol stia semplicemente indovinando (con un tasso di successo del 50%).\nAggiornare le Probabilità con Dati Osservati: Utilizziamo i dati raccolti nell’esperimento per aggiornare le nostre probabilità a priori. Questo aggiornamento è fatto utilizzando la regola di Bayes.\nCalcolare il Fattore di Bayes: Questa metrica ci dice quanto i dati osservati influenzano le probabilità delle diverse ipotesi. Un Fattore di Bayes molto maggiore di 1 indicherebbe un forte supporto per l’ipotesi alternativa rispetto all’ipotesi nulla.\n\nNel caso specifico, il Fattore di Bayes calcolato è risultato essere circa 147.33, un valore notevolmente alto. Questo suggerisce che i dati osservati sono molto più compatibili con l’ipotesi che la Dr.ssa Bristol possa effettivamente distinguere tra le diverse preparazioni del tè, piuttosto che con l’ipotesi che stia indovinando.\nEtz et al. (2018) concludono che l’approccio bayesiano offre un quadro più robusto e coerente per il test delle ipotesi. A differenza del metodo frequentista, esso non dipende dalla definizione di “risultati più estremi” non osservati e si concentra invece esclusivamente sui dati effettivamente raccolti. Questa focalizzazione, in generale, rende l’approccio bayesiano una soluzione più solida per valutare le ipotesi scientifiche. Per una rivisitazione bayesiana dell’esperimento “The Lady Tasting Tea”, si veda anche la discussione di Doorn et al. (2020).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#malintesi-sul-valore-p",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#malintesi-sul-valore-p",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.17 Malintesi sul valore-p",
    "text": "84.17 Malintesi sul valore-p\nSono diffusi molti malintesi sul valore-p. Ne esaminiamo qui quelli più comuni.\nMalinteso 1: Un valore p non significativo significa che l’ipotesi nulla è vera.\nIl malinteso che un valore p non significativo (p &gt; 0.05) implichi l’assenza di effetto o la verità dell’ipotesi nulla è diffuso e porta a conclusioni errate. La chiave per evitare questo errore sta nel comprendere che i valori p riflettono la probabilità dei dati osservati sotto l’ipotesi nulla, e non la probabilità dell’ipotesi stessa. Un valore p elevato non dimostra che l’ipotesi nulla sia vera, ma indica semplicemente che i dati osservati non sono sufficientemente insoliti da rifiutare l’ipotesi nulla con un livello di confidenza predefinito.\nRisultati non significativi possono verificarsi anche quando esiste un effetto reale, ma i dati non sono abbastanza estremi da superare la soglia di significatività statistica.\nInvece di concludere affrettatamente l’assenza di effetto da un valore p non significativo, dovremmo riconoscere l’ambiguità e considerare altre possibilità. Dichiarazioni come “non c’era differenza” dovrebbero essere riformulate in termini di assenza di differenza statisticamente significativa, lasciando aperta la questione dell’esistenza di un effetto reale.\nL’approccio bayesiano offre una prospettiva diversa che può essere particolarmente utile per interpretare risultati non significativi. A differenza dei valori p, che si limitano a valutare la probabilità dei dati sotto l’ipotesi nulla, l’inferenza bayesiana permette di calcolare direttamente la probabilità delle ipotesi date i dati.\nL’approccio bayesiano, quindi, non si limita a rifiutare o non rifiutare l’ipotesi nulla, ma quantifica la forza dell’evidenza a favore di un’ipotesi rispetto all’altra, fornendo una conclusione più informativa rispetto al semplice “non posso rifiutare l’ipotesi nulla”.\nMalintesto 2: Un valore p significativo significa che l’ipotesi nulla è falsa.\nCome spiegato in precedenza, il valore-p quantifica la “sorpresa” suscitata dai dati, alla luce dell’ipotesi nulla. Non ci dice niente sull’ipotesi che abbiamo assunto per quantificare la “sorpresa”.\nMalinteso 3: Un valore p significativo significa che è stato scoperto un effetto importante.\nLa distinzione tra “significatività statistica” e “rilevanza pratica” è fondamentale: mentre la prima indica semplicemente che un risultato è improbabile sotto l’ipotesi nulla, la seconda valuta l’effetto nel contesto di applicazioni reali e le sue implicazioni.\nUn effetto statisticamente significativo non garantisce che l’effetto abbia un impatto pratico notevole o utile.\nInoltre, al di là della significatività pratica, l’abitudine di molti psicologi di escludere i predittori che non risultano “statisticamente significativi” è un grossolano errore: la significatività statistica non può essere usata come un metodo per la selezione di variabili in un modello statistico.\nUn p &lt; 0.05 indica che, se l’ipotesi nulla è vera, abbiamo osservato dati che dovrebbero essere considerati sorprendenti. Tuttavia, solo perché i dati sono sorprendenti, non significa che dobbiamo preoccuparcene. È principalmente l’etichetta verbale “significativo” che causa confusione qui: in un contesto frequentista, un effetto “significativo” è un effetto “sorprendente” alla luce di \\(H_0\\), non è necessariamente un effetto “importante”.\nMalinteso 4: Se avete osservato un risultato significativo, la probabilità che abbiate commesso un errore di Tipo 1 (un falso positivo) è del 5%.\nIl malinteso che la presenza di un risultato significativo (per esempio, p &lt; 0.05) indichi una probabilità del 5% di aver commesso un errore di Tipo 1 (falso positivo) riflette una comprensione errata della statistica frequentista. La probabilità del 5% si riferisce al tasso di errore di Tipo 1, che è la proporzione di volte che potremmo aspettarci di rifiutare erroneamente l’ipotesi nulla se questa fosse vera, su molteplici ripetizioni dell’esperimento sotto le stesse condizioni. In altre parole, se potessimo ripetere lo stesso studio infinite volte, osserveremmo risultati falsamente positivi nel 5% di questi studi, assumendo che l’ipotesi nulla sia effettivamente vera in ogni caso.\nTuttavia, una volta che abbiamo raccolto i dati e ottenuto un risultato significativo in un unico studio, non possiamo dire che “la probabilità che questo particolare risultato sia un errore di Tipo 1 è del 5%”. In realtà, in quel momento specifico, l’evento (commettere un errore di Tipo 1) è già accaduto o non è accaduto; la probabilità associata a quel singolo risultato non è più applicabile nel modo in cui potremmo aspettarci intuitivamente. Il risultato è, per così dire, una realtà fissa: o abbiamo rilevato un effetto che in realtà non esiste (errore di Tipo 1), oppure abbiamo correttamente identificato un effetto reale. Senza ulteriori esperimenti o dati, non possiamo determinare con certezza in quale di queste categorie cade il nostro risultato.\nIn breve, il tasso del 5% di errore di Tipo 1 non si applica retroattivamente a un singolo risultato ottenuto, ma piuttosto descrive il comportamento a lungo termine di un test statistico sotto ripetute campionature. Questa distinzione è cruciale per una corretta interpretazione dei risultati degli esperimenti e sottolinea l’importanza di non sovrastimare la certezza di un singolo risultato statistico significativo.\nMalinteso 5: Uno meno il valore p è la probabilità che l’effetto si replichi quando ripetuto.\nIl concetto che 1 meno il valore p rappresenti la probabilità di replicazione di un effetto è un malinteso diffuso. In realtà, la probabilità di replicazione di un effetto non può essere direttamente calcolata dal valore p di un singolo studio a causa della complessità dei fattori coinvolti, tra cui la vera differenza media tra i gruppi. La potenza statistica di un test, che dipende dalla dimensione dell’effetto, dalla dimensione del campione e dal livello di significatività α, fornisce una stima della probabilità di rilevare un effetto significativo se questo effetto esiste davvero. Tuttavia, osservare un effetto significativo in un unico studio (ad esempio, p = 0.03) non significa che vi sia una probabilità del 97% che tale effetto si replichi in studi futuri. La possibilità di replicare un risultato dipende dalla presenza di un vero effetto e dalla potenza statistica del test originale.\nIn sintesi, la replicabilità di un effetto è influenzata da molti fattori e non può essere inferita semplicemente dal valore p di un singolo risultato. La comprensione e l’interpretazione corrette della replicabilità richiedono un’analisi dettagliata della potenza statistica e della dimensione dell’effetto, oltre che della consistenza dei risultati attraverso studi multipli.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#riflessioni-conclusive",
    "title": "\n84  Significatività statistica\n",
    "section": "\n84.18 Riflessioni Conclusive",
    "text": "84.18 Riflessioni Conclusive\nIl presente capitolo ha messo in evidenza le numerose limitazioni e i potenziali pericoli dell’approccio frequentista al test dell’ipotesi nulla, portando alla luce una serie di paradossi e malintesi che minano la sua validità come strumento primario per l’inferenza scientifica. In particolare, abbiamo visto come il valore-p, spesso utilizzato come metro di giudizio assoluto per decidere se un risultato è significativo o meno, possa condurre a conclusioni fuorvianti, dipendendo non solo dai dati osservati ma anche dal contesto sperimentale e dalle scelte soggettive del ricercatore. Questo approccio, che si basa su una logica binaria di “accettare” o “rifiutare” l’ipotesi nulla, sembra incapace di cogliere la complessità delle relazioni causali e degli effetti reali presenti nei fenomeni psicologici e sociali. Più profondamente, emerge con chiarezza che il metodo frequentista, lungi dall’essere un sistema oggettivo per la decisione statistica, è invece intriso di convenzioni arbitrarie (come il livello di significatività α = 0.05) e di una visione riduzionistica della probabilità, concepita come frequenza relativa di eventi ripetibili nel tempo piuttosto che come misura della nostra incertezza riguardo a un evento specifico.\nTuttavia, al di là delle critiche tecniche, il problema più grave risiede nella tendenza a considerare il test dell’ipotesi nulla come uno strumento definitivo per valutare la veridicità di ipotesi scientifiche, anziché come un semplice punto di partenza per ulteriori indagini. La cultura prevalente nella comunità scientifica, che premia i risultati “statisticamente significativi”, ha contribuito a creare un ambiente in cui gli studi replicabili sono rari e dove molti risultati pubblicati sono fragili e difficilmente generalizzabili. È qui che l’approccio bayesiano entra in gioco, offrendo una soluzione coerente e robusta che supera molte delle carenze del frequentismo. Al contrario del metodo frequentista, che si concentra su ipotesi nulle arbitrariamente definite e sulle distribuzioni campionarie di statistiche teoriche, il bayesianesimo ci permette di incorporare informazioni pregresse (prior) e di aggiornare queste conoscenze in base ai dati osservati, fornendo una stima diretta della probabilità delle ipotesi di interesse. Questo approccio, che mette al centro la nozione di evidenza, permette di quantificare la forza delle prove a favore di diverse ipotesi, evitando così le dicotomie rigide tra “significativo” e “non significativo” e promuovendo una visione più sfumata e matematicamente fondata dell’inferenza statistica.\nIn conclusione, il test dell’ipotesi nulla frequentista, pur essendo ampiamente utilizzato, rappresenta uno degli aspetti più controversi e problematici dell’approccio tradizionale. La sua rigidità metodologica e la dipendenza da concetti come il valore p e la significatività statistica lo rendono non solo impreciso, ma anche inadeguato a cogliere la complessità dei fenomeni che la ricerca psicologica si propone di esplorare. Abbandonare questo paradigma non è solo una questione di precisione tecnica, ma di superare una mentalità riduzionista che limita la nostra capacità di interpretare i dati in modo sfumato e contestuale.\nL’adozione di metodologie bayesiane, al contrario, offre un quadro più dinamico e flessibile, in cui le ipotesi non sono semplicemente accettate o rifiutate, ma valutate in termini probabilistici. Questo approccio incoraggia un confronto diretto tra modelli e ipotesi contrapposte, permettendo di aggiornare le nostre credenze alla luce dei nuovi dati. Non si tratta solo di un miglioramento tecnico nelle inferenze scientifiche, ma di un invito a ripensare il modo in cui concepiamo la conoscenza e il processo di scoperta. La prospettiva bayesiana, infatti, enfatizza l’incertezza come parte intrinseca della ricerca, trasformandola in uno strumento per affinare le nostre comprensioni piuttosto che un ostacolo da superare.\nIn un contesto psicologico intrinsecamente complesso e caratterizzato da incertezza, l’approccio bayesiano rappresenta un’opportunità per adottare un’epistemologia più flessibile e razionale. La sua forza risiede nella capacità di adattarsi alla natura multifattoriale dei fenomeni psicologici, integrando in modo coerente e trasparente sia le conoscenze pregresse sia le nuove evidenze. In questo senso, l’adozione del paradigma bayesiano non è soltanto un avanzamento metodologico, ma anche un passo verso una scienza più consapevole, critica e adatta alle sfide della psicologia contemporanea.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#esercizi",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#esercizi",
    "title": "\n84  Significatività statistica\n",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nL’Idea di Base del Test di Ipotesi\n\nSpiega il principio generale del test di ipotesi nulla in ambito frequentista. In che modo la logica dell’“assumere come vera l’ipotesi nulla fino a prova contraria” è paragonabile al concetto di “presunzione di innocenza” in un processo penale? Quali vantaggi e svantaggi comporta questa impostazione?\n\nIpotesi di Ricerca vs. Ipotesi Statistica\n\nSpiega in che modo l’ipotesi di ricerca (ad esempio, “esiste un effetto della musica sul comportamento dei bambini”) differisce dall’ipotesi statistica che si testa formalmente (ad esempio, “la media di un indice di preferenza è maggiore di 0.5”). Perché spesso la ricerca psicologica non può testare direttamente l’ipotesi di ricerca?\n\nSignificatività Statistica e Rilevanza Pratica\n\nChe differenza c’è tra “risultato statisticamente significativo” e “risultato rilevante (o importante) dal punto di vista pratico o teorico”? Porta un esempio in cui un test frequenzista possa dare un valore-\\(p\\) molto basso senza che l’effetto sia considerato rilevante nel contesto.\n\nMalinteso: Un Risultato non Significativo Implica Che \\(H_0\\) Sia Vera?\n\nPerché è errato concludere che l’ipotesi nulla sia vera quando il test non risulta significativo (cioè quando \\(p \\ge 0.05\\))? Quali altre spiegazioni potrebbero esserci se un esperimento produce un valore-\\(p\\) alto?\n\nIl Ruolo della Variabilità Campionaria\n\nIn che modo la variabilità campionaria (cioè il fatto che stime come la media campionaria varino da campione a campione) influisce sulla necessità di un test di ipotesi? Perché non è sufficiente confrontare la media osservata con il valore ipotizzato per concludere se \\(H_0\\) è falsa?\n\nErrori di I e II Tipo e Potenza del Test\n\nDescrivi i concetti di errore di I tipo (falso positivo) e errore di II tipo (falso negativo). Perché i test sono progettati primariamente per controllare l’errore di I tipo? Che cos’è la potenza (\\(1-\\beta\\)) di un test?\n\nIl Valore-\\(p\\): Che Cosa (non) Indica?\n\nSpiega la definizione di valore-\\(p\\) secondo l’approccio frequentista. Quali sono due malintesi comuni su ciò che il valore-\\(p\\) non rappresenta?\n\nCritica: Dipendenza dai “Risultati più Estremi Non Osservati”\n\nNell’esempio dell’episodio “The Lady Tasting Tea”, come mai il test di ipotesi frequentista può portare a conclusioni diverse pur avendo gli stessi dati osservati, a seconda di come è definito il “processo di campionamento”? Perché questa è una limitazione?\n\nControllo dell’Errore di I Tipo, ma Non dell’Errore di II Tipo\n\nPerché nel test di ipotesi frequentista esiste un’asimmetria per cui si controlla rigorosamente l’errore di I tipo (fissando \\(\\alpha\\)), ma non esiste un analogo vincolo obbligatorio sull’errore di II tipo (\\(\\beta\\))? Quali conseguenze pratiche ne derivano per la pianificazione di uno studio?\n\nLimiti dell’Approccio Frequentista e Alternative\n\nRiassumi in che senso il test di ipotesi nulla frequentista è ritenuto da alcuni ricercatori insufficiente o fuorviante (es. “dichotomania” del significato, p-value dipendente dal disegno, ecc.). Quali alternative o integrazioni sono state proposte in letteratura per superare questi limiti?\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nL’Idea di Base del Test di Ipotesi\n\n\nL’ipotesi nulla (\\(H_0\\)) è considerata “innocente” fino a che l’evidenza non la “condanna”.\n\nIl test statistico stabilisce la probabilità di osservare dati così (o più) estremi assumendo che \\(H_0\\) sia vera.\n\nVantaggio: stabilire un controllo sul rischio di un falso positivo (errore di I tipo).\n\nSvantaggio: non si dimostra direttamente l’ipotesi di ricerca (\\(H_1\\)), ma si prova a “falsificare” \\(H_0\\).\n\n\nIpotesi di Ricerca vs. Ipotesi Statistica\n\n\nL’ipotesi statistica è una versione quantificabile (e falsificabile) dell’ipotesi di ricerca.\n\nLe ipotesi di ricerca in psicologia sono spesso complesse (costrutti non sempre direttamente misurabili).\n\nI ricercatori formulano un modello statistico semplificato per rendere l’ipotesi testabile.\n\n\nSignificatività Statistica e Rilevanza Pratica\n\n\n“Significativo” in senso frequentista significa “dati improbabili se \\(H_0\\) è vera”.\n\nNon implica necessariamente un effetto ampio o di importanza pratica.\n\nCon campioni molto grandi, si possono rilevare anche differenze piccolissime, magari prive di valore applicativo.\n\n\nMalinteso: Un Risultato non Significativo Implica Che \\(H_0\\) Sia Vera?\n\n\nUn valore-\\(p\\) “alto” segnala che i dati non forniscono sufficiente evidenza per rifiutare \\(H_0\\), non che \\(H_0\\) è vera.\n\nPossibile mancanza di potenza statistica (campione troppo piccolo) o presenza di effetti molto ridotti.\n\nL’approccio frequentista non quantifica la probabilità che \\(H_0\\) sia vera, ma la probabilità di osservare certi dati assumendo che \\(H_0\\) lo sia.\n\n\nIl Ruolo della Variabilità Campionaria\n\n\nAnche se la media campionaria si discosta da \\(H_0\\), potremmo aver ottenuto quella differenza per puro caso.\n\nOccorre stabilire quanto discostamento sia “raro” secondo la distribuzione campionaria ipotizzata da \\(H_0\\).\n\nIl test calcola quante volte, nel lungo periodo, si osservano dati così estremi casualmente.\n\n\nErrori di I e II Tipo e Potenza del Test\n\n\nErrore di I tipo: rigettare \\(H_0\\) quando è vera.\n\nErrore di II tipo: non rigettare \\(H_0\\) quando è falsa.\n\nIl test frequenzista fissa una soglia \\(\\alpha\\) (livello di significatività) per controllare l’errore di I tipo.\n\nLa potenza quantifica la probabilità di individuare realmente un effetto quando esso esiste.\n\n\nIl Valore-\\(p\\): Che Cosa (non) Indica?\n\n\nIl valore-\\(p\\) è la probabilità di ottenere un risultato almeno così estremo se \\(H_0\\) è vera.\n\nMalinteso 1: pensare che indichi la probabilità che \\(H_0\\) sia vera o falsa.\n\nMalinteso 2: confondere “\\(p &lt; 0.05\\) =&gt; probabilità 95% che l’effetto sia vero” (non è così!).\n\n\nCritica: Dipendenza dai “Risultati più Estremi Non Osservati”\n\n\nIl valore-\\(p\\) frequenzista include la probabilità di osservare anche “risultati più estremi” non avvenuti nell’esperimento.\n\nSe l’esperimento era “fissare a priori 6 tazze” vs. “continuare finché non ottiene 5 successi”, può cambiare la distribuzione usata (binomiale vs. geometrica negativa).\n\nQuesto mostra che il valore-\\(p\\) dipende dal contesto sperimentale, non solo dai dati effettivi.\n\n\nControllo dell’Errore di I Tipo, ma Non dell’Errore di II Tipo\n\n\nSi vuole evitare di “condannare” un’ipotesi nulla “innocente”.\n\nL’errore di II tipo spesso viene trascurato e può essere molto alto se il campione è piccolo.\n\nConseguenze: molti studi hanno potenza insufficiente; i “falsi negativi” rimangono frequenti.\n\n\nLimiti dell’Approccio Frequentista e Alternative\n\n\nCritiche: inflazione di falsi positivi, dipendenza arbitraria da \\(\\alpha=0.05\\), scarsa attenzione alla dimensione dell’effetto, interpretazioni errate del p-value.\n\nAlternative:\n\n\nApproccio bayesiano (fattori di Bayes, posteriori, credibilità).\n\n\nConfidence intervals ampliati da riflessioni su potenza e dimensione dell’effetto.\n\n\nMisure dell’effetto e analisi approfondite invece di un giudizio binario su “p&lt;0.05”.\n\n\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizi “A Mano”\nQuesti esercizi si possono affrontare con le formule del test di ipotesi (z-test o t-test per la media, test di proporzioni, ecc.), senza ricorrere a software.\nEsercizio 1: One-sample t-test sulla SWLS\n\n\nHai un piccolo campione di \\(n=9\\) studenti, con punteggi SWLS (ipotetici) riportati di seguito:\n\\[\n21, \\ 18, \\ 26, \\ 20, \\ 23, \\ 16, \\ 22, \\ 19, \\ 25\n\\]\n\nSupponi che, in letteratura, la media teorica su popolazioni simili sia di circa \\(\\mu_0 = 20\\).\nIpotesi nulla \\((H_0)\\): la media del campione non differisce da 20 (cioè \\(\\mu = 20\\)).Ipotesi alternativa \\((H_1)\\): la media del campione differisce da 20 (two-sided test).\n\nRichiesta:\n\nCalcola la media campionaria \\(\\bar{X}\\) e la deviazione standard campionaria \\(s\\).\n\nEsegui un t-test a mano (con formula \\(t = \\frac{\\bar{X} - \\mu_0}{s/\\sqrt{n}}\\)).\n\nStabilisci se, con \\(\\alpha=0.05\\) (test a due code), si rifiuta o meno \\(H_0\\).\n\n\nSuggerimento: Usa la tabella della distribuzione t (o ricorri a tavole semplificate) per trovare il valore critico a \\(df = n-1 = 8\\). Solo per questo step, usa R.\n\nEsercizio 22: One-sample t-test sulla LSNS-6\n\n\nHai un campione di \\(n=8\\) persone anziane, con punteggi LSNS-6 (Scala della Rete Sociale di Lubben) ipotetici (in realtà userai i dati raccolti):\n\\[\n10,\\ 14,\\ 8,\\ 13,\\ 12,\\ 7,\\ 15,\\ 9\n\\]\n\nIn letteratura si suppone che un punteggio medio su popolazioni simili sia \\(\\mu_0 = 12\\).\nIpotesi nulla: \\(\\mu = 12\\).Ipotesi alternativa: \\(\\mu \\neq 12\\).\n\nRichiesta:\n\nCalcola media e deviazione standard.\n\nCalcola la statistica \\(t\\) e confrontala con il valore critico per \\(\\alpha=0.05\\), two-sided, con \\(df = 7\\).\n\nConcludi se rifiuti l’ipotesi nulla o meno.\n\n\n\nEsercizio 3: Due campioni indipendenti (SWLS)\n\n\nConsidera i dati raccolti dal tuo gruppo e quelli di un altro gruppo TPV (es., Gruppo A = 6 persone, Gruppo B = 5 persone) che hanno compilato la SWLS. Riporta per ipotesi i seguenti punteggi medi e DS (usa i dati reali):\n\nGruppo A: \\(\\bar{X}_A = 24,\\ s_A=4,\\ n_A=6\\)\n\nGruppo B: \\(\\bar{X}_B = 19,\\ s_B=3,\\ n_B=5\\)\n\n\n\nVuoi testare se le due medie differiscono in modo significativo (\\(\\alpha=0.05\\), due code).\nIpotesi nulla: \\(\\mu_A = \\mu_B\\).Ipotesi alternativa: \\(\\mu_A \\neq \\mu_B\\).\n\nRichiesta:\n\nCalcola la statistica \\(t\\) di un two-sample t-test (varianze incognite, assunte uguali).\n\nUsa la formula con la “varianza pooled”.\n\nCalcola i \\(df\\) approssimati come \\(n_A + n_B - 2\\).\n\nConcludi se rifiuti \\(H_0\\).\n\n\n\nEsercizio 4: Test su una proporzione (SWLS recodificata)\n\nA volte si trasforma la SWLS in una variabile binaria es. “\\(\\mathrm{SWLS} \\ge 24\\) = soddisfatto, \\(\\mathrm{SWLS}&lt;24\\) = non soddisfatto”.\nConsidera i dati raccolti e i corrispondenti risultati binari (Sì/No) siano 4 “soddisfatti” e 6 “non soddisfatti”.\nIpotesi nulla: la proporzione di “soddisfatti” è \\(p_0 = 0.50\\) (ipotizzi che metà dei partecipanti sia soddisfatta).Ipotesi alternativa: la proporzione \\(\\neq 0.50\\).\nCalcola la statistica \\(Z\\) per una proporzione (usando la formula della normal approx. se \\(\\hat{p}=4/10\\)).\nConfronta \\(|Z|\\) con il valore critico a \\(\\alpha=0.05\\) (due code), \\(z_{0.025}\\approx 1.96\\). Concludi.\n\nEsercizio 5: Confronto fra due proporzioni (LSNS-6 recodificata)\n\nConsiderai dati di due gruppi TPV (Gruppo A, Gruppo B).\n\nSupponi che, per Gruppo A (\\(n_A=8\\)), 3 persone abbiano un punteggio \\(\\ge 12\\) (considerato “buon supporto”). Per Gruppo B (\\(n_B=10\\)), 7 persone siano \\(\\ge 12\\) – usa i dati reali.\n\nIpotesi nulla: \\(\\,p_A = p_B\\).Ipotesi alternativa: \\(\\,p_A \\neq p_B\\).\n\nCalcola \\(\\hat{p}_A = 3/8\\) e \\(\\hat{p}_B = 7/10\\).\n\nFai il test per il confronto di due proporzioni (con la formula per la “pooled proportion”). Decidi se c’è differenza significativa al 5%.\n\nEsercizi “Con R”\nOra proponiamo 5 esercizi da svolgere con il software R. Naturalmente, dovrete caricare il vostro dataset reale (ad esempio in formato CSV o XLS) e adattare i comandi di R.\nEsercizio 1: Calcolo e t-test di una sola media per la SWLS\n\n\nCaricate in R i vostri dati SWLS in un vettore, es.:\nswls_data &lt;- c(...)  # I vostri punteggi\n\n\nStampate la media e la deviazione standard:\nmean(swls_data)\nsd(swls_data)\n\nTest se la media differisce da 24, usando t.test(swls_data, mu = 24).\nOsservate il p-value e concludete se rifiutate \\(H_0\\): \\(\\mu=24\\) vs \\(H_1\\): \\(\\mu \\neq 24\\).\n\nEsercizio 2: Calcolo e t-test di una sola media per la LSNS-6\n\n\nFate lo stesso per la LSNS:\nlsns_data &lt;- c(...)  # I vostri punteggi\n\nCalcolate mean(lsns_data), sd(lsns_data).\nEseguite un test con t.test(lsns_data, mu = X) dove \\(X\\) è un valore teorico (ad es. 12 o 10, a seconda delle informazioni di letteratura).\nInterpretate l’output, guardando estimate, conf.int, p-value.\n\nEsercizio 3: Confronto di due medie (SWLS) con due gruppi\n\n\nConsiderate i dati di due gruppi TPV. Avete due vettori in R:\ngroupA &lt;- c(...)  # SWLS di chi appartiene al gruppo A\ngroupB &lt;- c(...)  # SWLS di chi appartiene al gruppo B\n\nCalcolate mean(groupA), mean(groupB).\n\nEseguite:\nt.test(groupA, groupB, var.equal = FALSE)  # Welch Two Sample t-test\n\nConfrontate la differenza delle medie riportata con l’intervallo di confidenza. Il p-value indica se la differenza è significativa (ipotesi nulla: medie uguali).\n\nEsercizio 4: Test su una proporzione (ricodifica SWLS)\n\n\nRicodificate i vostri punteggi SWLS in “1 = soddisfatto” / “0 = non soddisfatto”. Ad esempio:\nsatisfied &lt;- ifelse(swls_data &gt;= 24, 1, 0)\n\n\nContate la proporzione di “1”:\nmean(satisfied)\n\nEffettuate il test con prop.test(sum(satisfied), length(satisfied), p = 0.5) (se ipotizzate \\(p_0=0.5\\)).\nGuardate l’output e interpretate: l’intervallo di confidenza e il p-value.\n\nEsercizio 5: Confronto di due proporzioni (ricodifica LSNS)\n\n\nFate una ricodifica binaria sul vostro vettore LSNS, ad esempio “1 se \\(\\ge12\\), 0 se &lt;12”:\ngood_support &lt;- ifelse(lsns_data &gt;= 12, 1, 0)\n\n\nSeparate i partecipanti in due gruppi (ad esempio, un gruppo “A” e un gruppo “B”):\ngroupA_inds &lt;- (some condition)  # righe che corrispondono a Gruppo A\ngroupB_inds &lt;- (some other condition)\n\nCalcolate sum(good_support[groupA_inds]), length(groupA_inds) e idem per groupB.\nUsate prop.test(x = c(...), n = c(...)) per confrontare le due proporzioni.\nConcludete: se p-value &lt; 0.05, potete rifiutare \\(H_0\\) (le due proporzioni sono uguali).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 – P-value e Interpretazione Probabilistica\nSpiega perché il valore-\\(p\\) del test di ipotesi nulla (frequentista) non può essere interpretato come “probabilità che l’ipotesi nulla sia vera” e in che modo l’approccio bayesiano fornisce invece una “probabilità a posteriori” sull’ipotesi. Descrivi due possibili conseguenze pratiche di questa differenza di interpretazione.\nEsercizio 2 – Ruolo dei “Risultati più Estremi Non Osservati”\nNel test frequentista, il valore-\\(p\\) si basa anche sulla probabilità di risultati più estremi di quelli effettivamente osservati, ma che non si sono verificati. Perché questo è considerato un limite (o un paradosso) e in che modo un’analisi bayesiana eviterebbe (o ridurrebbe) questo problema?\nEsercizio 3 – Dipendenza dal Disegno Sperimentale e Optional Stopping\nNel test di ipotesi frequenzista, il valore-\\(p\\) può cambiare se il ricercatore modifica il piano di raccolta dati (ad es. fermare la raccolta quando si ottiene un certo risultato). Perché si parla di “problema dell’optional stopping”? Come gestisce invece l’approccio bayesiano la decisione di proseguire o fermare un esperimento sulla base dei dati via via raccolti?\nEsercizio 4 – Significatività Statistica vs. Dimensione dell’Effetto\nUno dei limiti dell’approccio frequentista è la confusione tra “significatività statistica” (p&lt;0.05) e “importanza/ampiezza dell’effetto”. Spiega in che modo l’approccio bayesiano può incorporare in modo più diretto la dimensione dell’effetto e l’incertezza a riguardo (tramite le “distribuzioni a posteriori” o “intervalli di credibilità”).\nEsercizio 5 – Problemi di Replicabilità: Come Confrontare Modelli?\nSi osserva spesso che i risultati frequentisti (p&lt;0.05) non si replicano bene in studi successivi. Descrivi come un’analisi bayesiana (con i “fattori di Bayes” o i “posterior odds”) possa dare un quadro più flessibile per confrontare ipotesi alternative, riducendo il rischio di eccessive conclusioni basate su un singolo p-value.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nSoluzione 1 – P-value e Probabilità dell’Ipotesi\n\n\nPunto chiave: Il valore-\\(p\\) è la probabilità di ottenere dati “uguali o più estremi” dando per vera l’ipotesi nulla. Invece, “probabilità che \\(H_0\\) sia vera” sarebbe un concetto diverso: è la probabilità dell’ipotesi data i dati osservati (interpretazione inversa).\n\n\nConseguenze pratiche:\n\nUn p-value “basso” non dice “quanto è probabile che \\(H_0\\) sia falsa”, ma solo che quei dati sarebbero rari sotto \\(H_0\\).\n\nI ricercatori spesso sovrastimano la “conferma” contro \\(H_0\\) o interpretano male un p&gt;0.05 come “ipotesi nulla vera”.\n\n\n\n\nApproccio bayesiano: Consente di calcolare una posterior probability di \\(H_0\\) (o di \\(H_1\\)) grazie alla regola di Bayes, purché si disponga di una prior e di un modello.\n\nSoluzione 2 – Risultati più Estremi Non Osservati\n\n\nProblema: Nel frequentismo, il valore-\\(p\\) integra la probabilità di dati che non si sono verificati (“what if scenario”). Ciò porta a dipendere da un insieme di risultati ipotetici e a potenziali paradossi (e.g. “Lady Tasting Tea”).\n\n\nLimite: Può capitare che stessi dati osservati, ma piani di raccolta diversi, generino p-value diversi.\n\n\nBayesian: Calcola la verosimiglianza solo sui dati effettivi e aggiorna la prior → “focus su ciò che è effettivamente avvenuto”. Non serve considerare a posteriori “risultati più estremi” che non si sono verificati, se non in misura minima (attraverso l’integrazione sulle possibili distribuzioni posteriori, ma con un meccanismo diverso dal p-value).\n\nSoluzione 3 – Optional Stopping e Disegno Sperimentale\n\n\nOptional Stopping: In un test frequentista, se continuiamo ad analizzare i dati e fermiamo la raccolta non appena otteniamo p&lt;0.05, si gonfia il rischio di errore di I tipo.\n\n\nLimite: Il p-value frequentista dipende dall’idea di un “protocollo fisso” a priori. Se si viola questo piano (aggiungendo dati finché non si ottiene “significatività”), il test non è più valido.\n\n\nBayesiano: L’approccio consente un monitoraggio sequenziale (monitoring) dei dati: si aggiorna la distribuzione a posteriori man mano che arrivano nuove osservazioni, e fermarsi quando la posterior probability (o il fattore di Bayes) supera (o non supera) una certa soglia. Questo non invalida formalmente l’inferenza perché si sta accumulando evidenza in modo coerente con Bayes.\n\nSoluzione 4 – Ampiezza dell’Effetto e Intervalli di Credibilità\n\n\nFrequenza: Un p-value significativo non dice quanto è grande l’effetto, solo che non si spiega “facilmente” con \\(H_0=0\\).\n\n\nLimite: Spesso si confonde “p&lt;0.05” con “effetto grande/impact significativo”: in realtà, la dimensione potrebbe essere piccola.\n\n\nBayesiano: Offre una distribuzione a posteriori sull’effetto (\\(\\theta\\)), da cui si può ricavare un intervallo di credibilità (dove, ad esempio, c’è il 95% di probabilità che \\(\\theta\\) si trovi in quell’intervallo). Consente di valutare se l’effetto è davvero grande o molto stretto attorno allo 0.\n\nSoluzione 5 – Replicabilità e Confronto di Ipotesi\n\n\nProblema di replicabilità: Molti studi con p&lt;0.05 non vengono replicati (forse per effetti piccoli, scarsa potenza, pubblicazione selettiva, etc.).\n\n\nLimite: Un singolo p-value non dà informazioni su “quanto credere a \\(H_1\\) rispetto a \\(H_0\\)” e non aiuta a cumulare evidenze in analisi meta-analitiche in modo flessibile.\n\n\nBayesiano: Utilizza fattori di Bayes (Bayes Factor) o “posterior odds”, confrontando due modelli (es. \\(H_0\\) vs \\(H_1\\)). Se i dati futuri confermano una delle ipotesi, la posterior si rafforza. È un sistema più graduale e cumulativo di aggiornamento della credenza, riducendo la tendenza a “collezionare p&lt;0.05”.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n84  Significatività statistica\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       rmarkdown_2.29       \n#&gt; [19] nloptr_2.2.1          ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] jomo_2.7-6            xfun_0.53             glmnet_4.1-10        \n#&gt; [25] cachem_1.1.0          jsonlite_2.0.0        pan_1.9              \n#&gt; [28] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [31] stringi_1.8.7         RColorBrewer_1.1-3    rpart_4.1.24         \n#&gt; [34] boot_1.3-32           lubridate_1.9.4       estimability_1.5.1   \n#&gt; [37] iterators_1.0.14      knitr_1.50            zoo_1.8-14           \n#&gt; [40] pacman_0.5.1          nnet_7.3-20           Matrix_1.7-4         \n#&gt; [43] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [46] abind_1.4-8           codetools_0.2-20      curl_7.0.0           \n#&gt; [49] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [52] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [55] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [58] checkmate_2.3.3       foreach_1.5.2         stats4_4.5.1         \n#&gt; [61] reformulas_0.4.1      distributional_0.5.0  generics_0.1.4       \n#&gt; [64] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [67] minqa_1.2.8           xtable_1.8-4          glue_1.8.0           \n#&gt; [70] emmeans_1.11.2-8      tools_4.5.1           lme4_1.1-37          \n#&gt; [73] mvtnorm_1.3-3         grid_4.5.1            rbibutils_2.3        \n#&gt; [76] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [79] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [82] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [85] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [88] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [91] lifecycle_1.0.4       mitml_0.4-5           MASS_7.3-65",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_test_ipotesi.html#bibliografia",
    "href": "chapters/frequentist_inference/05_test_ipotesi.html#bibliografia",
    "title": "\n84  Significatività statistica\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., et al. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6–10.\n\n\nDoorn, J. van, Matzke, D., & Wagenmakers, E.-J. (2020). An in-class demonstration of Bayesian inference. Psychology Learning & Teaching, 19(1), 36–45.\n\n\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic bulletin & review, 25(1), 219–234.\n\n\nMehr, S. A., Song, L. A., & Spelke, E. S. (2016). For 5-month-old infants, melodies are social. Psychological Science, 27(4), 486–501.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/06_two_ind_samples.html",
    "href": "chapters/frequentist_inference/06_two_ind_samples.html",
    "title": "\n85  Test t di Student per campioni indipendenti\n",
    "section": "",
    "text": "85.1 Introduzione\nQuesto capitolo è dedicato al test t di Student per campioni indipendenti, uno dei test statistici più utilizzati nella pratica frequentista. Il test t di Student è un metodo che permette di confrontare le medie di due gruppi diversi (o “campioni”) e determinare se la differenza osservata tra le medie sia statisticamente significativa o se possa essere attribuita a semplice casualità.\nIl test è particolarmente utile quando si ha accesso solo a piccoli campioni provenienti da popolazioni sconosciute, ma è importante comprendere bene i suoi principi fondamentali e limiti prima di applicarlo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/06_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "href": "chapters/frequentist_inference/06_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "title": "\n85  Test t di Student per campioni indipendenti\n",
    "section": "\n85.2 Applicazioni del Test t di Student",
    "text": "85.2 Applicazioni del Test t di Student\nIl test t di Student per campioni indipendenti serve per rispondere alla domanda: “Le medie di due gruppi sono significativamente diverse?” Per esempio, potremmo voler sapere se ci sono differenze significative nel peso medio tra uomini e donne.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/06_two_ind_samples.html#assunzioni-principali",
    "href": "chapters/frequentist_inference/06_two_ind_samples.html#assunzioni-principali",
    "title": "\n85  Test t di Student per campioni indipendenti\n",
    "section": "\n85.3 Assunzioni Principali",
    "text": "85.3 Assunzioni Principali\nPrima di procedere con il test, è essenziale assicurarsi che siano valide le seguenti ipotesi:\n\n\nIndipendenza: Le osservazioni nei due campioni devono essere indipendenti.\n\nNormalità: I dati nei due campioni provengono da popolazioni distribuite normalmente.\n\nUguaglianza delle Varianze (Omoschedasticità): Le varianze delle due popolazioni da cui provengono i campioni sono uguali.\n\nSe queste condizioni non sono soddisfatte, potrebbe essere necessario considerare alternative come il test di Welch, che non richiede l’uguaglianza delle varianze.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/06_two_ind_samples.html#passaggi-del-test-t-di-student",
    "href": "chapters/frequentist_inference/06_two_ind_samples.html#passaggi-del-test-t-di-student",
    "title": "\n85  Test t di Student per campioni indipendenti\n",
    "section": "\n85.4 Passaggi del Test t di Student",
    "text": "85.4 Passaggi del Test t di Student\nEcco una panoramica dei passaggi chiave:\n\n\nCalcolare la Differenza tra le Medie: Si calcola la differenza tra le medie dei due campioni.\n\\[\n\\bar{x}_1 - \\bar{x}_2\n\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) sono le medie dei due campioni.\n\n\nStimare la Deviazione Standard Combinata: Se assumiamo che le varianze siano uguali (omoschedasticità), possiamo usare una stima combinata della deviazione standard, chiamata deviazione standard pooled \\(s_p\\):\n\\[\ns_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\n\\]\ndove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni, e \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie.\n\n\nCalcolare la Statistica t: La statistica t viene calcolata usando la formula seguente:\n\\[\nt = \\frac{(\\bar{x}_1 - \\bar{x}_2)}{s_p \\sqrt{\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}\n\\]\n\n\nDeterminare i Gradi di Libertà: I gradi di libertà (\\(df\\)) sono calcolati come:\n\\[\ndf = n_1 + n_2 - 2\n\\]\n\nCalcolare il Valore-p: Infine, si confronta la statistica t con la distribuzione t di Student per ottenere il valore-p. Questo valore indica la probabilità di osservare una differenza così estrema tra le medie dei campioni, dato che l’ipotesi nulla è vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/06_two_ind_samples.html#dimostrazione",
    "href": "chapters/frequentist_inference/06_two_ind_samples.html#dimostrazione",
    "title": "\n85  Test t di Student per campioni indipendenti\n",
    "section": "\n85.5 Dimostrazione",
    "text": "85.5 Dimostrazione\nPer dimostrare come calcolare la varianza della differenza tra due medie campionarie, consideriamo due campioni casuali indipendenti \\(X_1, X_2, \\dots, X_n\\) e \\(Y_1, Y_2, \\dots, Y_m\\), estratti dalla stessa popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo \\(\\bar{X}\\) e \\(\\bar{Y}\\) come le medie campionarie di questi due campioni, rispettivamente.\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono date da:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i ,\n\\] \\[\n\\bar{Y} = \\frac{1}{m} \\sum_{j=1}^m Y_j .\n\\]\nEntrambe le medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono stimatori non distorti della media della popolazione \\(\\mu\\). Le loro varianze sono:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n} ,\n\\] \\[\n\\text{Var}(\\bar{Y}) = \\frac{\\sigma^2}{m} .\n\\]\nSiamo interessati a calcolare la varianza della differenza \\(\\bar{X} - \\bar{Y}\\). Utilizzando le proprietà della varianza per combinazioni lineari di variabili aleatorie indipendenti, otteniamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\text{Var}(\\bar{X}) + \\text{Var}(\\bar{Y}) ,\n\\]\ndato che i termini incrociati si annullano per l’indipendenza di \\(\\bar{X}\\) e \\(\\bar{Y}\\). Sostituendo le varianze di \\(\\bar{X}\\) e \\(\\bar{Y}\\), abbiamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{m} ,\n\\] \\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\sigma^2 \\left(\\frac{1}{n} + \\frac{1}{m}\\right) .\n\\]\nQuindi, la varianza della differenza tra le due medie campionarie è una combinazione delle varianze delle singole medie, ponderate in base alle dimensioni dei campioni corrispondenti.\nPer giungere alla formula del test \\(t\\) di Student per due campioni indipendenti, dobbiamo considerare l’incertezza aggiuntiva derivante dal fatto che non conosciamo \\(\\sigma\\). Il modo migliore per stimare \\(\\sigma\\) è utilizzare le due deviazioni standard dei campioni, ponderate per i rispettivi gradi di libertà, come indicato nella formula della deviazione standard pooled:\n\\[\ns_p = \\sqrt{\\frac{(n - 1)s^2_x + (m - 1)s^2_y}{n + m - 2}},\n\\]\ndove \\(s_x\\) e \\(s_y\\) sono le deviazioni standard dei due campioni, e \\(n\\) e \\(m\\) sono le numerosità dei due campioni.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/06_two_ind_samples.html#esempio-pratico",
    "href": "chapters/frequentist_inference/06_two_ind_samples.html#esempio-pratico",
    "title": "\n85  Test t di Student per campioni indipendenti\n",
    "section": "\n85.6 Esempio Pratico",
    "text": "85.6 Esempio Pratico\nSupponiamo di avere due campioni:\n\n\nDonne: Pesi = [38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5]\n\nUomini: Pesi = [67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4]\n\nCreiamo un DataFrame in R e calcoliamo la statistica t:\n\nwomen_weight &lt;- c(38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5)\nmen_weight &lt;- c(67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4)\n\nweight &lt;- c(women_weight, men_weight)\nis_female &lt;- rep(c(1, 0), each = 9)  # 1 = Femmina, 0 = Maschio\n\ndf &lt;- data.frame(is_female = is_female, weight = weight)\n\nPer calcolare manualmente la statistica t:\n\n# Estraiamo i pesi per ogni gruppo\nweight_f &lt;- df$weight[df$is_female == 1]\nweight_m &lt;- df$weight[df$is_female == 0]\n\n# Calcolo della deviazione standard pooled\ns_pool_num &lt;- ((length(weight_f) - 1) * var(weight_f)) + ((length(weight_m) - 1) * var(weight_m))\ns_pool_denom &lt;- length(weight_f) + length(weight_m) - 2\ns_pool &lt;- sqrt(s_pool_num / s_pool_denom)\n\n# Calcolo della statistica t\nt_num &lt;- mean(weight_f) - mean(weight_m)\nt_denom &lt;- s_pool * sqrt(1 / length(weight_f) + 1 / length(weight_m))\nT &lt;- t_num / t_denom\nT\n#&gt; [1] -2.78\n\n\n# Gradi di libertà\ndf_degrees &lt;- length(weight_f) + length(weight_m) - 2\ndf_degrees\n#&gt; [1] 16\n\n\n# Calcolo del valore-p\np_value &lt;- 2 * pt(abs(T), df = df_degrees, lower.tail = FALSE)\nprint(p_value)\n#&gt; [1] 0.0133\n\nIn alternativa, possiamo usare la funzione t.test di R:\n\nres &lt;- t.test(weight_f, weight_m, var.equal = TRUE)\nprint(res, digits = 7)\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  weight_f and weight_m\n#&gt; t = -2.7842, df = 16, p-value = 0.01327\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -29.748019  -4.029759\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;  52.10000  68.98889\n\n\n85.6.1 Interpretazione dei Risultati\nIl test t di Student ha generato un valore-p inferiore a 0.05, indicando che la differenza osservata tra i pesi medi delle donne e degli uomini è statisticamente significativa. Questo significa che, con un livello di confidenza del 95%, possiamo rifiutare l’ipotesi nulla secondo cui le medie dei due gruppi sono uguali.\nÈ importante ricordare che un basso valore-p suggerisce che la differenza osservata non è dovuta al caso. Tuttavia, ciò non prova automaticamente una relazione causale; piuttosto, apre la strada ad ulteriori indagini sulle cause della differenza.\n\n85.6.2 Riportare i Risultati\nQuando si riportano i risultati di un test t, è fondamentale adottare pratiche che favoriscano una comprensione approfondita e accurata dei dati. Di seguito viene presentato un confronto tra due versioni dei risultati: una da evitare, che si basa su un’interpretazione tradizionale della significatività statistica, e una versione migliorata che enfatizza l’intervallo di confidenza e l’ampiezza dell’effetto.\n\n85.6.2.1 Versione da Evitare\nLa seguente formulazione segue un approccio tradizionale incentrato sulla “significatività statistica,” che è oggi ritenuto inadeguato per una comunicazione efficace dei risultati:\n\nAbbiamo condotto un test t di Student per confrontare le medie dei due gruppi. I risultati mostrano una differenza significativa tra i pesi medi delle donne e degli uomini (t(16) = -2.78, p-value = 0.01). L’intervallo di confidenza al 95% per la differenza delle medie è [-29.75, -4.03]. L’ampiezza dell’effetto, misurata con Cohen’s d, è 1.31, indicando un effetto grande. La potenza statistica del test è stata stimata al 74.4%.\n\nIn questa versione, il focus è eccessivamente concentrato sul valore-p, che può portare a interpretazioni riduttive e distorte dei risultati.\n\n85.6.2.2 Versione Migliorata\nEcco invece una versione migliore che mantiene un approccio frequentista, ma sposta l’enfasi sull’intervallo di confidenza e sull’ampiezza dell’effetto, offrendo una descrizione più completa e informativa:\n\nÈ stato condotto un test t di Student per confrontare le medie dei due gruppi. La differenza tra i pesi medi delle donne e degli uomini è stata stimata in -16.89 kg (intervallo di confidenza al 95%: [-29.75, -4.03]), suggerendo che il peso medio degli uomini sia maggiore rispetto a quello delle donne nel campione analizzato. Questo intervallo indica che, con una fiducia del 95%, la differenza reale tra i pesi medi potrebbe variare tra circa -29.75 kg e -4.03 kg.\nL’ampiezza dell’effetto, misurata con Cohen’s d = 1.31, indica una differenza considerevole, equivalente a oltre una deviazione standard. Questo valore suggerisce che la differenza osservata non solo è statisticamente rilevante, ma anche sostanziale dal punto di vista pratico.\nInoltre, la potenza del test, considerando la dimensione dell’effetto osservata, è pari al 74.4%, suggerendo che il test ha una buona capacità di rilevare differenze di questa entità nel campione analizzato. Ciò significa che, se una differenza di tale magnitudine fosse presente nella popolazione, esisterebbe una probabilità superiore al 70% di rilevarla correttamente.\n\nQuesta modalità di reporting fornisce una descrizione più dettagliata ed esplicativa dei risultati, evitando interpretazioni basate esclusivamente sul valore-p e concentrandosi invece sulla grandezza e sull’incertezza della stima. Tale approccio consente una valutazione più equilibrata e informata dei dati, promuovendo una comprensione più approfondita delle implicazioni pratiche e scientifiche dei risultati ottenuti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/06_two_ind_samples.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/06_two_ind_samples.html#riflessioni-conclusive",
    "title": "\n85  Test t di Student per campioni indipendenti\n",
    "section": "\n85.7 Riflessioni Conclusive",
    "text": "85.7 Riflessioni Conclusive\nIl test t di Student è uno strumento statistico ampiamente utilizzato per l’inferenza su una media o per confrontare le medie di due gruppi. È talmente importante che alcuni lo hanno definito il metodo statistico più importante nella scienza. Tuttavia, come osserva Andrew Gelman, questa affermazione non va accettata acriticamente. Benché il test t sia semplice ed efficace in molti contesti, presenta notevoli limitazioni che ne riducono l’affidabilità e l’applicabilità quando si affrontano problemi complessi o si desidera una comprensione più approfondita dei dati (Kruschke, 2013).\n\n85.7.1 Limiti del Test t di Student\nUno dei principali limiti del test t risiede nell’assunzione che i dati seguano una distribuzione normale (gaussiana). Questa assunzione è spesso violata in pratica, specialmente con campioni piccoli o quando i dati presentano asimmetrie o code pesanti. Inoltre, nel caso di campioni indipendenti, il test richiede l’omogeneità delle varianze, un’altra assunzione frequentemente infondata. Quando queste condizioni non sono soddisfatte, il test può fornire risultati distorti, necessitando di correzioni come quella di Welch per gestire differenze di varianza.\nUn ulteriore limite del test t è legato alla sua dipendenza dalla soglia di significatività \\(\\alpha\\), solitamente fissata a 0.05. Questa scelta è arbitraria e può influenzare criticamente le conclusioni. Il test valuta esclusivamente la compatibilità dei dati con l’ipotesi nulla (\\(H_0\\)) e fornisce solo un p-value, senza offrire informazioni dirette sulla plausibilità dell’ipotesi alternativa (\\(H_1\\)). Ciò significa che un p-value basso non garantisce che \\(H_1\\) sia vera o che i dati supportino tale ipotesi.\n\n85.7.2 L’Approccio Bayesiano: Una Soluzione Più Potente\nIn contrasto con il paradigma frequentista, l’approccio bayesiano offre un quadro statistico più flessibile e informativo. Attraverso il teorema di Bayes, è possibile calcolare direttamente la probabilità di un’ipotesi dato l’insieme dei dati osservati. Questo permette di quantificare la forza dell’evidenza a favore di un’ipotesi rispetto alle altre, superando le limitazioni intrinseche del test t.\n\n85.7.2.1 Vantaggi dell’Approccio Bayesiano\n\nNon richiede assunzioni rigide: A differenza del test t, che si basa su ipotesi restrittive come la normalità e l’omoschedasticità, l’inferenza bayesiana è in grado di gestire modelli più generali e robusti, adattandosi ai dati reali senza doverli forzare in strutture artificiali.\nIncorporazione delle informazioni pregresse: L’approccio bayesiano permette di integrare conoscenze pregresse attraverso distribuzioni a priori, migliorando la qualità delle stime e consentendo analisi più realistiche. Questo è particolarmente utile in situazioni dove i dati disponibili sono scarsi o rumorosi.\nInferenze più informative: Al posto di semplici decisioni binarie (“rifiuto” o “non rifiuto” di \\(H_0\\)), il bayesianismo fornisce distribuzioni a posteriori complete, che descrivono l’incertezza sui parametri di interesse. Questo consente inferenze più dettagliate e interpretabili.\nGestione della complessità: L’approccio bayesiano gestisce in modo naturale modelli complessi e gerarchici, rendendolo ideale per analisi avanzate. Ad esempio, Kruschke (2013) dimostra come tecniche bayesiane possano superare le limitazioni del test t anche in presenza di violazioni delle assunzioni classiche, producendo risultati più stabili e affidabili.\n\n85.7.2.2 Implementazione Pratica\nSebbene l’approccio bayesiano richieda una maggiore attenzione nella scelta delle distribuzioni a priori e nella specificazione del modello, l’avvento di software moderni come Stan, PyMC3 e JAGS ha reso l’implementazione di modelli bayesiani sempre più accessibile. Oggi, anche ricercatori con competenze statistiche moderate possono applicare metodi bayesiani per affrontare problemi complessi con maggiore precisione e coerenza.\n\n85.7.3 Conclusioni\nIl test t di Student rimane un valido strumento per analisi rapide e semplici, ma le sue limitazioni diventano evidenti quando si lavora con dati complessi o si cerca una comprensione più profonda delle relazioni sottostanti. L’approccio bayesiano rappresenta un’evoluzione concettuale e metodologica rispetto all’inferenza frequentista tradizionale, offrendo numerosi vantaggi: inferenze più ricche, integrazione di informazioni pregresse, gestione delle violazioni delle assunzioni e produzione di stime più robuste. Per questi motivi, il paradigma bayesiano è sempre più considerato come la scelta preferibile per chi desidera un’analisi statistica solida, flessibile e informativa.\nIn ultima analisi, mentre il test t resta un punto di partenza utile, l’adozione dell’approccio bayesiano permette di avanzare verso una comprensione più completa e accurata dei dati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/06_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/06_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n85  Test t di Student per campioni indipendenti\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       rmarkdown_2.29       \n#&gt; [19] nloptr_2.2.1          ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] jomo_2.7-6            xfun_0.53             glmnet_4.1-10        \n#&gt; [25] cachem_1.1.0          jsonlite_2.0.0        pan_1.9              \n#&gt; [28] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [31] stringi_1.8.7         RColorBrewer_1.1-3    rpart_4.1.24         \n#&gt; [34] boot_1.3-32           lubridate_1.9.4       estimability_1.5.1   \n#&gt; [37] iterators_1.0.14      knitr_1.50            zoo_1.8-14           \n#&gt; [40] pacman_0.5.1          nnet_7.3-20           Matrix_1.7-4         \n#&gt; [43] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [46] abind_1.4-8           codetools_0.2-20      curl_7.0.0           \n#&gt; [49] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [52] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [55] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [58] checkmate_2.3.3       foreach_1.5.2         stats4_4.5.1         \n#&gt; [61] reformulas_0.4.1      distributional_0.5.0  generics_0.1.4       \n#&gt; [64] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [67] minqa_1.2.8           xtable_1.8-4          glue_1.8.0           \n#&gt; [70] emmeans_1.11.2-8      tools_4.5.1           lme4_1.1-37          \n#&gt; [73] mvtnorm_1.3-3         grid_4.5.1            rbibutils_2.3        \n#&gt; [76] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [79] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [82] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [85] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [88] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [91] lifecycle_1.0.4       mitml_0.4-5           MASS_7.3-65",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/06_two_ind_samples.html#bibliografia",
    "href": "chapters/frequentist_inference/06_two_ind_samples.html#bibliografia",
    "title": "\n85  Test t di Student per campioni indipendenti\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nLa psicologia, insieme ad altre discipline scientifiche, sta attraversando una Riforma Metodologica scaturita da una crisi profonda: l’incapacità di replicare risultati di ricerche precedentemente pubblicati. Questa crisi di replicazione, che mina la credibilità della scienza, ha portato a un ripensamento radicale delle pratiche di ricerca, degli standard metodologici e degli incentivi accademici (Korbmacher et al., 2023). Siti come Retraction Watch, che monitorano le ritrattazioni di studi scientifici, testimoniano l’entità del problema, evidenziando casi di frodi, manipolazioni statistiche e pratiche di ricerca opache.\nLe Cause della Crisi.\nTra le cause principali vi sono incentivi distorti (come la pressione a pubblicare rapidamente), l’utilizzo acritico di tecniche inferenziali frequentiste – che facilitano la proliferazione di falsi positivi – e la scarsa attenzione alla dimensione campionaria. Come dimostrato da Altmejd et al. (2019), alcuni elementi superficiali permettono di prevedere la replicabilità di uno studio:\nSorprendentemente, prevedere se uno studio sarà replicabile non richiede competenze avanzate. Camerer et al. (2018) ha mostrato che scienziati coinvolti in un “mercato delle scommesse” predicevano con precisione quali studi di scienze sociali si sarebbero replicati. Ancora più significativo è il lavoro di Hoogeveen et al. (2020): partecipanti senza formazione specifica, esposti a semplici descrizioni di studi psicologici, hanno identificato con successo ricerche a rischio di fallimento replicativo. Ciò suggerisce che molti studi presentano difetti metodologici evidenti, riconoscibili persino a un pubblico non esperto.\nLa Diffusione degli Errori nella Letteratura Scientifica.\nLa pubblicazione peer-reviewed non garantisce l’affidabilità di una ricerca. Yang et al. (2020) ha rilevato che studi non replicabili vengono citati con la stessa frequenza di quelli validi, alimentando un ciclo di errori. Questo paradosso – scienziati capaci di riconoscere studi fragili ma inclini a citarli – riflette una cultura accademica disfunzionale (Smaldino & McElreath, 2016), dove la quantità di pubblicazioni prevale sulla qualità e gli incentivi premiano scorciatoie metodologiche.\nEsempi Emblematici e la Crisi di Validità.\nLa crisi non riguarda solo la replicazione, ma anche la validità delle misure e delle teorie. Ricerche influenti, come quelle sul pre-cognition di Ritchie et al. (2012) o sugli effetti del priming inconscio di John Bargh, si sono rivelate basate su evidenze fragili (Schimmack, 2012). Anche concetti consolidati, come l’esaurimento dell’autocontrollo (ego depletion) legato ai livelli di glucosio, sono stati criticati per mancanza di supporto empirico (Vadillo et al., 2016). Persino opere di autori celebri, come Thinking: Fast and Slow di Daniel Kahneman, contengono affermazioni basate su risultati non replicabili (Schimmack, 2020).\nVerso una Soluzione: Oltre l’Inferenza Frequentista.\nQuesta sezione della dispensa si concentra su uno dei nodi metodologici alla base della crisi: i limiti dell’inferenza frequentista (Baker, 2016). Concetti come gli errori di tipo S (conclusioni errate sulla direzione di un effetto) e di tipo M (sovrastima dell’entità di un effetto), introdotti da Gelman & Carlin (2014), illuminano le insidie delle tecniche statistiche tradizionali. Per affrontare la crisi, è necessario adottare approcci alternativi: preregistrazione degli studi, utilizzo di metodi bayesiani, e una valutazione critica della credibilità cumulativa della letteratura (Schimmack, 2020).\nConclusioni.\nLa crisi della replicabilità non è solo un problema tecnico, ma il sintomo di un sistema scientifico da ripensare. Riviste accademiche, istituzioni e ricercatori devono promuovere integrità, trasparenza e una cultura che valorizzi la robustezza rispetto alla novità. Solo così la psicologia potrà riconquistare il ruolo di scienza empirica rigorosa, capace di produrre conoscenza affidabile.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Altmejd, A., Dreber, A., Forsell, E., Huber, J., Imai, T., Johannesson, M., Kirchler, M., Nave, G., & Camerer, C. (2019). Predicting the replicability of social science lab experiments. PloS one, 14(12), e0225826.\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nCamerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., et al. (2018). Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015. Nature human behaviour, 2(9), 637–644.\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nHoogeveen, S., Sarafoglou, A., & Wagenmakers, E.-J. (2020). Laypeople can predict which social-science studies will be replicated successfully. Advances in Methods and Practices in Psychological Science, 3(3), 267–285.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nRitchie, S. J., Wiseman, R., & French, C. C. (2012). Failing the future: Three unsuccessful attempts to replicate Bem’s ‘Retroactive Facilitation of Recall’Effect. PloS one, 7(3), e33423.\n\n\nSchimmack, U. (2012). The ironic effect of significant results on the credibility of multiple-study articles. Psychological methods, 17(4), 551–566.\n\n\nSchimmack, U. (2020). A meta-psychological perspective on the decade of replication failures in social psychology. Canadian Psychology/Psychologie Canadienne, 61(4), 364–376.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society Open Science, 3(9), 160384.\n\n\nVadillo, M. A., Gold, N., & Osman, M. (2016). The bitter truth about sugar and willpower: The limited evidential value of the glucose model of ego depletion. Psychological Science, 27(9), 1207–1214.\n\n\nYang, Y., Youyou, W., & Uzzi, B. (2020). Estimating the deep replicability of scientific findings using human and artificial intelligence. Proceedings of the National Academy of Sciences, 117(20), 10762–10768.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html",
    "href": "chapters/replication_crisis/01_crisis.html",
    "title": "86  La crisi della replicazione",
    "section": "",
    "text": "86.1 Introduzione\nIl presente capitolo introduce la crisi di replicazione che affligge la ricerca psicologica, analizzandone le cause precipue e ponendo in rilievo il ruolo che l’approccio statistico frequentista ha avuto nel concorrere a tale problematica. Il contenuto di questo capitolo costituisce una sintesi rielaborata del testo A student’s guide to open science: Using the replication crisis to reform psychology (Pennington, 2023).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#i-pilastri-della-scienza-psicologica-ideale",
    "href": "chapters/replication_crisis/01_crisis.html#i-pilastri-della-scienza-psicologica-ideale",
    "title": "86  La crisi della replicazione",
    "section": "\n86.2 I Pilastri della Scienza Psicologica Ideale",
    "text": "86.2 I Pilastri della Scienza Psicologica Ideale\nAffinché la psicologia sia riconosciuta come scienza rigorosa, deve aderire a principi fondamentali:\n\n86.2.1 A. Replicabilità e Riproducibilità\n\n\n\nDefinizione: Un effetto empirico è considerato valido solo se replicabile da ricercatori indipendenti, con metodologie analoghe e campioni adeguati.\n\n\nEsempio: Lo studio classico di Asch sul conformismo (1951) è stato replicato in contesti cross-culturali, rafforzandone la validità.\n\n86.2.2 B. Attributi Essenziali della Ricerca\n\nLa scienza ideale dovrebbe essere:\n\n\n\n\n\n\n\nPrincipio\nDescrizione\nImplicazioni per la Psicologia\n\n\n\nCredibile\nSottoposizione delle ipotesi a verifica rigorosa e peer review trasparente.\nEvitare p-hacking e HARKing (Hypothesizing After Results are Known).\n\n\nAffidabile\nRisultati accurati e privi di distorsioni (bias).\nUtilizzo di preregistrazione e open data.\n\n\nTrasparente\nDescrizione dettagliata di metodi, analisi e risultati.\nAdozione di registered reports e condivisione di materiali supplementari.\n\n\nAccessibile\nDemocratizzazione della conoscenza (es. open access).\nPiattaforme come PsyArXiv per preprint o OSF per la condivisione di protocolli.\n\n\nInclusiva\nPartecipazione equa di gruppi sottorappresentati (etnici, di genere, ecc.).\nStudi con campioni diversificati (es. non solo WEIRD: Western, Educated, Industrialized, Rich, Democratic).\n\n\nCollaborativa\nSuperamento della competizione accademica a favore di reti di ricerca.\nProgetti multi-lab (es. Many Labs in psicologia sociale).\n\n\nAutocorrettiva\nRevisione continua degli errori e ritrattazione di risultati non validi.\nDatabase come Retraction Watch e correzioni pubbliche negli articoli.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-disconnessione-tra-ideale-e-realtà",
    "href": "chapters/replication_crisis/01_crisis.html#la-disconnessione-tra-ideale-e-realtà",
    "title": "86  La crisi della replicazione",
    "section": "\n86.3 La Disconnessione tra Ideale e Realtà",
    "text": "86.3 La Disconnessione tra Ideale e Realtà\nPennington (2023) utilizza un esercizio retorico per criticare la prassi scientifica tradizionale:\n\nVisualizzate lo stereotipo dello scienziato: un uomo bianco, in un laboratorio con cartelli ‘DIVIETO DI ACCESSO’, che tratta i dati come proprietà privata. Questa immagine riflette una scienza chiusa, competitiva e non allineata ai valori di trasparenza e collaborazione.\n\n\n86.3.1 Problemi Emersi\n\n\nSegretezza: Ricercatori che occultano dati per paura di critiche o “furti” di idee.\n\n\nCrisi di replicazione: Il 50-70% degli studi psicologici non è replicabile (Collaboration, 2015).\n\n\nPressioni accademiche: Focus su pubblicazioni “rivoluzionarie” a scapito di solidità metodologica.\n\n86.3.2 Verso una Psicologia più Rigorosa\nPer affrontare le criticità emerse nella ricerca psicologica, sono state avanzate diverse proposte concrete. Una delle direzioni più promettenti è l’adozione diffusa delle pratiche di Open Science, che includono la preregistrazione degli studi (per evitare il p-hacking), la condivisione aperta dei dati (open data) e l’utilizzo di strumenti gratuiti e trasparenti, come il software JASP per le analisi statistiche. Questi approcci non solo aumentano l’affidabilità dei risultati, ma favoriscono anche una cultura di collaborazione anziché di segretezza.\nUn altro passo fondamentale riguarda la formazione dei ricercatori. Introdurre corsi obbligatori su etica della ricerca e metodi quantitativi avanzati potrebbe ridurre errori metodologici e comportamenti opportunistici, preparando una nuova generazione di psicologi a standard più rigorosi.\nInfine, è essenziale ripensare il sistema di valutazione accademica. Invece di premiare la mera quantità di pubblicazioni – che spesso spinge verso risultati “sensazionali” ma poco replicabili – sarebbe più produttivo incentivare la qualità, la trasparenza e l’impatto a lungo termine del lavoro scientifico.\nUn esempio concreto di questo cambiamento è il progetto ManyBabies, un’iniziativa internazionale che coinvolge decine di laboratori nello studio dello sviluppo infantile. Grazie alla collaborazione su larga scala e alla condivisione di protocolli standardizzati, ManyBabies ha dimostrato come sia possibile produrre risultati più solidi e generalizzabili, superando i limiti dei piccoli studi isolati. Questo caso illustra perfettamente i benefici di una psicologia più aperta, cooperativa e metodologicamente rigorosa.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "href": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "title": "86  La crisi della replicazione",
    "section": "\n86.4 La Crisi della Replicazione in Psicologia",
    "text": "86.4 La Crisi della Replicazione in Psicologia\nNegli ultimi decenni, la psicologia si è trovata al centro di una crisi che ha messo in discussione molte delle sue basi epistemologiche e metodologiche: la crisi della replicazione. Questo fenomeno indica l’incapacità di replicare con successo un’ampia parte degli studi pubblicati, con implicazioni rilevanti per la cultura accademica e il modo di concepire la ricerca scientifica (Parsons et al., 2022).\nPer fallimento della replicazione si intende il caso in cui uno studio, ripetuto da altri ricercatori seguendo le stesse procedure e utilizzando campioni simili, non riesce a ottenere risultati comparabili a quelli originali. Questo ha portato alla luce problemi sistemici legati alla metodologia di ricerca, all’interpretazione dei dati e alle dinamiche del sistema accademico. La crisi della replicazione ha dunque evidenziato la necessità di un cambiamento strutturale nella pratica scientifica, sottolineando l’urgenza di un approccio più trasparente, rigoroso e collaborativo.\nNelle sezioni seguenti vengono presentati gli eventi chiave di quella che possiamo chiamare la storia della crisi della replicazione.\n\n86.4.1 2005: “Perché la maggior parte dei risultati pubblicati è falsa” (Ioannidis)\nUn primo momento cruciale è stato l’articolo di “Why Most Published Research Findings Are False” (Ioannidis, 2005) che ha evidenziato come molti risultati scientifici fossero in realtà falsi positivi. Ioannidis attribuì questo fenomeno a campioni di piccole dimensioni, un’eccessiva enfasi sui valori-p per indicare significatività, flessibilità nei metodi di analisi e la competizione per produrre risultati “innovativi”. Questo articolo ha messo in luce problemi che trascendono la psicologia, ma che in seguito sarebbero emersi come centrali anche per questa disciplina.\n\n86.4.2 2011: Lo Studio di Daryl Bem, “Feeling the Future”\nUno degli eventi più controversi è stato lo studio di Daryl Bem “Feeling the Future” (Bem, 2011), che suggeriva l’esistenza della precognizione, ovvero la capacità di “sentire” eventi futuri. Attraverso nove esperimenti, Bem pubblicò risultati statisticamente significativi che sembravano sfidare le leggi della causalità.\nLo studio di Bem si inseriva nella tradizione degli esperimenti di “priming”, una tecnica ampiamente utilizzata in psicologia sociale dagli anni ’70. Gli esperimenti di priming tipicamente coinvolgevano studenti universitari, remunerati con modeste somme o crediti accademici. I partecipanti venivano esposti a determinati concetti per poi osservare come questi influenzassero il loro comportamento successivo. Un celebre esempio è lo studio di John Bargh del 1996, che dimostrò come l’esposizione a parole associate all’età avanzata inducesse i soggetti a camminare più lentamente (Bargh et al., 1996). Un altro studio del 2006 rivelò che il priming con concetti legati al denaro rendeva le persone meno propense ad aiutare gli altri. Questi studi sembravano dimostrare una straordinaria malleabilità della mente umana, suggerendo che il nostro comportamento potesse essere inconsciamente manipolato da sottili segnali ambientali (Leys, 2024). Tuttavia, lo studio di Bem introdusse un elemento nuovo in questo paradigma sperimentale.\nTra i vari esperimenti condotti da Bem, uno in particolare si distingueva. I soggetti venivano esposti a una parola con connotazione positiva o negativa e successivamente dovevano valutare rapidamente la piacevolezza di alcune immagini. Fin qui, nulla di insolito. La svolta radicale consisteva nel fatto che in metà delle prove, il priming avveniva dopo che i soggetti avevano già visto e valutato l’immagine (Bem, 2011).\nSorprendentemente, i risultati mostravano che il priming funzionava anche in queste condizioni: i partecipanti erano più veloci a giudicare piacevoli le immagini quando successivamente venivano esposti a una parola positiva. Questo effetto risultava statisticamente significativo, con un p-value di 0.01, sufficiente secondo gli standard correnti per rifiutare l’ipotesi nulla.\nBem interpretò questi risultati come prova della chiaroveggenza, una conclusione che suscitò notevoli controversie e ridicolizzò la psicologia. Gli altri otto esperimenti dello studio, tutti basati su classici paradigmi della psicologia sociale con l’ordine temporale invertito, mostrarono risultati altrettanto statisticamente significativi.\nQuesti risultati ponevano la comunità scientifica di fronte a un dilemma: accettare l’esistenza di fenomeni paranormali o mettere in discussione le pratiche statistiche e metodologiche consolidate nella disciplina. Bem stesso continua a sostenere la validità dei suoi risultati come prova dell’esistenza di capacità precognitive.\nSebbene pubblicato su una rivista prestigiosa, lo studio sollevò enormi dubbi metodologici. Le repliche successive non riuscirono a confermare i risultati di Bem, mostrando come pratiche discutibili, quali il p-hacking (modifiche al metodo di analisi per ottenere risultati significativi), potessero produrre falsi positivi apparentemente robusti.\n\n86.4.3 2011: Il Caso di Frode di Diederik Stapel\nNello stesso anno, Diederik Stapel, una figura di spicco della psicologia sociale, fu accusato di aver falsificato dati in decine di studi pubblicati. Tra i suoi esperimenti più famosi vi era quello secondo cui ambienti disordinati aumenterebbero il razzismo. Un altro studio suggeriva che mangiare carne rendeva le persone più antisociali. Tuttavia, si scoprì che per quegli studi, e molti altri, non aveva mai condotto gli esperimenti né raccolto i dati. Li aveva semplicemente inventati. A volte le frodi accadono. Stapel fu scoperto (alla fine), licenziato e decine dei suoi articoli furono ritirati. Questo scandalo scosse profondamente la comunità accademica e divenne un simbolo della crisi.\n\n86.4.4 2011: La Meta-ricerca e le Pratiche di Ricerca Discutibili (QRPs)\nLa meta-ricerca è un campo di studio che si concentra sul modo in cui viene condotta la ricerca scientifica. Comprende temi come i metodi, la trasparenza nella comunicazione, la riproducibilità, la valutazione e i sistemi di incentivi che regolano la scienza (Ioannidis et al., 2015). Questo ambito è emerso con urgenza dopo una serie di casi controversi e di frodi conclamate, come gli studi di Daryl Bem e Diederik Stapel, che hanno evidenziato falle nei processi di ricerca. I ricercatori hanno così iniziato ad analizzare pratiche note come Questionable Research Practices (QRPs, Pratiche di Ricerca Discutibili), che sfruttano aree grigie nelle norme scientifiche per raccogliere e analizzare i dati.\nSimmons et al. (2011) hanno dimostrato come la flessibilità nella raccolta, analisi e comunicazione dei dati permetta ai ricercatori di far apparire “significativo” praticamente qualsiasi risultato. Tra le pratiche discusse, spiccano:\n\n\nOptional stopping: Interrompere la raccolta dei dati non appena si raggiunge la significatività statistica, invece di seguire un piano prestabilito.\n\n\nP-hacking: Condurre molteplici test non pianificati, selezionando variabili o analisi solo quando producono un valore p inferiore a 0.05.\n\n\nHARKing (Hypothesizing After Results are Known): Modificare le ipotesi a posteriori per adattarle ai risultati ottenuti, presentandole come ipotesi iniziali.\n\nQueste pratiche non solo compromettono l’integrità scientifica, ma rendono estremamente facile produrre falsi positivi. Per dimostrarlo, Simmons e colleghi hanno condotto simulazioni al computer e due esperimenti, rivelando quanto fosse “troppo facile” raccogliere prove a sostegno di ipotesi false.\nLa portata di queste pratiche è sorprendente. Simmons et al. hanno scoperto che:\n\nUsare una sola QRP può quasi raddoppiare il tasso di falsi positivi, portandolo dal 5% al 10%.\n\nCombinare più QRPs può far salire questa percentuale oltre il 60%.\n\nPer sottolineare il problema, i ricercatori hanno dimostrato, in modo volutamente ironico, che ascoltare la canzone dei Beatles “When I’m Sixty-Four” potrebbe far apparire le persone più giovani di quanto fossero prima di ascoltarla. Questa dimostrazione satirica evidenziava che inseguire la significatività statistica senza un rigore metodologico può produrre risultati assurdi.\nJohn et al. (2012) hanno condotto un’indagine su larga scala, intervistando 2000 ricercatori per comprendere la diffusione delle QRPs. Con un approccio innovativo, hanno chiesto ai partecipanti non solo di riferire le proprie pratiche, ma anche quelle dei colleghi. I risultati sono stati sconvolgenti:\n\nOltre il 60% degli intervistati ha ammesso di non aver riportato tutte le variabili dipendenti misurate.\n\nPiù del 50% ha interrotto la raccolta dati non appena ottenuti risultati significativi (optional stopping).\n\nPiù del 40% ha selezionato e riportato solo esperimenti “riusciti”.\n\nSorprendentemente, i ricercatori tendevano a dichiarare che i colleghi adottavano queste pratiche più frequentemente di loro stessi. Molti giustificavano queste pratiche come “norme accademiche” del tempo.\nLa meta-ricerca ha giocato un ruolo cruciale nell’aprire gli occhi della comunità scientifica sui pericoli di queste decisioni apparentemente “banali”. In un contesto in cui le QRPs erano ampiamente accettate, la meta-ricerca ha evidenziato come queste pratiche possano seriamente danneggiare il progresso scientifico. Grazie al movimento dell’Open Science, si stanno introducendo norme che migliorano la credibilità della ricerca, spostando l’enfasi dalla produzione di risultati “significativi” alla conduzione di studi rigorosi e trasparenti.\n\n86.4.5 2012: La Crisi di Fiducia della Psicologia\nSiamo nel 2012, un anno segnato da una serie di eventi che spingono Harold Pashler ed Eric-Jan Wagenmakers a dichiarare che la psicologia sta affrontando una “crisi di fiducia”. In un numero speciale della rivista Perspectives on Psychological Science (PoPs), i due autori raccolgono una molteplicità di prospettive sulla nascente crisi della replicazione, cercando di individuarne le cause e le implicazioni.\nLe reazioni alla crisi sono variegate e, in alcuni casi, contrastanti. Alcuni studiosi sostengono che le affermazioni di una crisi siano premature (Stroebe e Strack, 2014) e che i problemi di replicazione non siano un fenomeno nuovo (Spellman, 2015). Altri, invece, sottolineano come incentivare e valorizzare gli studi di replicazione rappresenti un metodo efficace e diretto per migliorare la qualità della scienza psicologica (Koole e Lakens, 2012).\nIl numero speciale evidenzia anche iniziative in corso per affrontare il problema. Tra queste, l’Open Science Collaboration (OSC), un progetto di larga scala avviato nel 2012, si propone di verificare empiricamente se la psicologia sia effettivamente alle prese con una crisi della replicazione. L’obiettivo del progetto è ambizioso: replicare numerosi studi pubblicati per valutare la robustezza dei risultati originari. Sebbene i risultati di questa iniziativa non fossero ancora disponibili al momento della pubblicazione del numero speciale, il progetto rappresentava già una pietra miliare per la disciplina.\nNonostante le preoccupazioni, il numero speciale si chiude con una nota positiva, destinata a risuonare nella comunità scientifica. I casi di frode, le pratiche di ricerca discutibili (QRPs) e i fallimenti nei tentativi di replicazione, sebbene dannosi, hanno aperto la strada a una riflessione critica. Questo processo ha permesso alla psicologia di affrontare i propri limiti, correggere errori, superare i bias e costruire una letteratura più affidabile e trasparente.\nQuesto periodo storico segna un punto di svolta: la crisi di fiducia ha messo in discussione le fondamenta della disciplina, ma ha anche creato l’opportunità per un rinnovamento scientifico, stimolando pratiche più rigorose e una maggiore attenzione alla replicabilità e alla trasparenza.\n\n86.4.6 2014: Il Progetto “Many Labs”\nNel 2014 fu pubblicato il primo tentativo su larga scala di replicare risultati psicologici: il progetto “Many Labs”. Questo imponente sforzo collaborativo, guidato da Klein et al. (2014), testò la replicabilità di 13 risultati classici della psicologia, coinvolgendo 6344 partecipanti in 12 paesi. Gli studi selezionati rispettavano tre criteri principali: erano relativamente brevi, avevano un design semplice e potevano essere facilmente condotti online.\nTra i fenomeni esaminati figurava la fallacia del costo irrecuperabile (sunk cost fallacy), secondo cui le persone tendono a proseguire un’attività quando vi hanno già investito tempo, sforzi o denaro. Un esempio classico: se hai acquistato un biglietto per vedere la tua squadra di calcio preferita e, il giorno della partita, inizia a piovere a dirotto, sarai più propenso a partecipare perché hai già speso i soldi per il biglietto (Oppenheimer e Monin, 2009).\nAltri studi replicati includevano:\n\nL’influenza del framing dei guadagni e delle perdite sul rischio (Tversky e Kahneman, 1981).\n\nLe differenze di genere negli atteggiamenti impliciti verso la matematica e le arti (Nosek et al., 2002).\n\nI risultati sembravano promettenti: il 77% degli studi replicò con successo i risultati originali (10 su 13). Tuttavia, non tutti gli studi fornirono lo stesso livello di evidenza. Ad esempio:\n\nUno studio sull’efficacia del contatto sociale immaginato nel ridurre i pregiudizi (Husnu e Crisp, 2010) mostrò supporto limitato, con solo 4 campioni su 36 che evidenziarono un effetto significativo.\n\nDue studi di priming non furono replicati. Nel primo, i ricercatori non trovarono che l’esposizione alla bandiera americana aumentasse il conservatorismo (Carter et al., 2011). Nel secondo, il priming con concetti legati al denaro non portò a un incremento delle credenze o dei comportamenti capitalistici (Caruso et al., 2013).\n\nSebbene i risultati fossero accolti come una vittoria per la replicabilità, alcuni ricercatori sottolinearono limiti nel progetto Many Labs 1. Gli stessi autori riconobbero che molti degli studi selezionati erano già noti per essere altamente replicabili. Secondo alcuni critici, il principale contributo di questo progetto era dimostrare che almeno dieci effetti psicologici erano replicabili, ma non forniva una panoramica più ampia sulla replicabilità complessiva nella psicologia (Yarkoni, 2013).\nQuesto progetto rappresentò comunque un passo fondamentale per affrontare la crisi della replicazione, sottolineando l’importanza della collaborazione scientifica e del rigore metodologico.\n\n86.4.7 2015: Il Progetto di Riproducibilità della Open Science Collaboration\nNel 2015, la Open Science Collaboration (OSC) pubblicò i risultati del Reproducibility Project: Psychology, dimostrando che la buona scienza richiede tempo e rigore. Superando i limiti del progetto Many Labs 1, un team composto da oltre 270 ricercatori internazionali si impegnò a replicare 100 studi scelti casualmente da riviste di punta nel campo della psicologia.\nPer garantire risultati solidi e inattaccabili, il team adottò una metodologia rigorosa:\n- Consultazione con gli autori originali: gli autori degli studi originali furono coinvolti per confermare il design sperimentale e ridurre al minimo eventuali discrepanze.\n- Aumento delle dimensioni campionarie: i campioni furono ampliati per garantire una potenza statistica sufficiente.\n- Registrazione preventiva dei metodi: i piani di analisi e raccolta dati furono registrati in anticipo per prevenire bias da parte dei ricercatori.\nGli studi selezionati per la replicazione includevano domande di ricerca come:\n\nLa convinzione che il comportamento umano sia predeterminato incoraggia il tradimento?\n\nI bambini seguono automaticamente lo sguardo per trovare oggetti nascosti?\n\nÈ possibile osservare un “effetto after-motion” da fotografie fisse che rappresentano movimento?\n\nI risultati del progetto fecero scalpore e conquistarono i titoli dei giornali a livello globale. Solo il 36% degli studi replicò con successo, ottenendo un valore-p inferiore a 0.05. La psicologia sociale si rivelò particolarmente problematica, con un tasso di replicazione del 25%, rispetto al 50% degli studi di psicologia cognitiva.\nPer contestualizzare questi numeri, se gli effetti originali fossero stati realmente validi, il tasso minimo di replicazione atteso sarebbe stato dell’89% (Field et al., 2019). Anche tra gli studi replicati, le dimensioni degli effetti risultarono dimezzate rispetto a quelle riportate negli studi originali.\nQuesti risultati provocarono una forte reazione nella comunità scientifica. Ci si chiedeva: era la fine della psicologia? La disciplina avrebbe mai recuperato credibilità? Sebbene i dati fossero allarmanti, aprirono un dibattito più ampio. Come sottolineato da Kuhn (1962) e Redish et al. (2018), fallimenti nella replicazione possono segnare l’inizio di una rivoluzione scientifica, stimolando un ripensamento dei metodi, delle ipotesi e delle pratiche di ricerca.\nIl Reproducibility Project: Psychology non solo mise in luce le fragilità della disciplina, ma divenne un punto di partenza per migliorare la trasparenza, la collaborazione e la robustezza nella ricerca psicologica.\n\n86.4.7.1 Studi Successivi\nQuesti risultati sono stati ulteriormente corroborati da numerosi studi successivi, tra cui una ricerca più recente basata su tecniche di machine learning, che ha esaminato studi di psicologia pubblicati in sei importanti riviste nell’arco di vent’anni. Questa ricerca suggerisce che poco più della metà di questi articoli di psicologia non supererebbe i test di replicazione (Youyou et al., 2023). Discipline come la psicologia sociale sono state oggetto di particolare preoccupazione, con un tasso di replicazione del solo 25% riportato dal Progetto di Riproducibilità (Collaboration, 2015). Questo dato è in linea con il lavoro di Youyou et al. (2023), che ha mostrato come la replicabilità degli articoli di psicologia vari considerevolmente per sottocampo, con la psicologia sociale che mostra un tasso di replicazione stimato del 37%, un risultato leggermente più incoraggiante rispetto a quanto riportato in precedenza, ma ancora tra i più bassi dei sottocampi esaminati. Altri settori come la psicologia dello sviluppo, cognitiva e clinica hanno mostrato tassi di replicazione stimati rispettivamente del 36%, 42% e 44%, mentre aree come la psicologia delle organizzazioni e della personalità hanno mostrato tassi leggermente più incoraggianti (50% e 55%, rispettivamente). Complessivamente, le evidenze suggeriscono che le preoccupazioni diffuse sulla robustezza e replicabilità dei risultati della ricerca psicologica siano fondate. Sebbene il problema non sia limitato esclusivamente alla psicologia, le questioni rilevate in questo campo hanno ricevuto notevole attenzione a causa dell’apparente portata del fenomeno.\nQuesti risultati confermavano in modo drammatico le previsioni formulate anni prima da John Ioannidis e Dennis Lindley. Le loro avvertenze riguardo alla possibilità che una larga parte, se non la maggioranza, dei risultati scientifici pubblicati potesse essere falsa, si rivelavano ora profetiche.\nIl Progetto di Riproducibilità di Nosek ha segnato un punto di svolta nel dibattito sulla crisi della replicazione in psicologia e, più in generale, nelle scienze sociali e biomediche. Ha evidenziato non solo la fragilità di molti risultati ritenuti consolidati, ma anche la necessità di un riesame critico delle pratiche di ricerca e pubblicazione scientifica. Questo ripensamento delle metodologie scientifiche è ancora in atto.\n\n86.4.8 2015: 1500 Scienziati Sollevano il Velo sulla Riproducibilità\nI risultati del progetto Collaboration (2015) colpirono il mondo della psicologia come un fulmine a ciel sereno. Molti risultati psicologici, considerati affidabili, crollarono improvvisamente, generando un’ondata di discussioni nei dipartimenti universitari: quale sarebbe stato il prossimo “effetto” a fallire? Tuttavia, nonostante la psicologia fosse diventata l’emblema delle repliche fallite, presto si comprese che non era un problema esclusivo della disciplina.\nNel 2016, Baker condusse un’indagine su 1500 scienziati provenienti da diverse discipline, tra cui chimica, medicina, fisica e ingegneria, per esplorare le preoccupazioni riguardo alla replicazione e alla riproducibilità (Baker, 2016). I risultati furono sorprendenti: circa il 90% dei partecipanti concordò sull’esistenza di una crisi di riproducibilità, definita come significativa dal 52% e lieve dal 38%.\nUn dato particolarmente allarmante emerse dall’indagine:\n\nIn media, il 40% degli scienziati aveva riscontrato difficoltà nel riprodurre i propri esperimenti.\n\nQuesta percentuale saliva a oltre il 60% quando si tentava di riprodurre gli esperimenti di altri ricercatori.\n\nTra le discipline, la chimica risultò la più problematica, con oltre l’85% dei ricercatori che riportavano fallimenti nel riprodurre i risultati altrui.\nL’articolo di Baker riportava anche esperienze personali che riflettevano il senso di smarrimento generato da questa crisi. Il professor Marcus Munafò, per esempio, descrisse così il suo percorso:\n\nHo cercato di replicare ciò che dalla letteratura sembrava semplice, ma non ci sono riuscito. Ho avuto una crisi di fiducia, e poi ho scoperto che questa esperienza non era affatto rara. (Baker, 2016)\n\nL’indagine di Baker non si limitò a evidenziare il problema, ma esplorò anche le possibili cause della crisi, come pratiche metodologiche inadeguate e pressioni accademiche, offrendo al contempo suggerimenti per interventi correttivi.\nL’indagine segnò un momento cruciale: la crisi della riproducibilità, inizialmente confinata a discussioni accademiche, raggiunse una visibilità globale. Non era più solo un problema della psicologia, ma un fenomeno che colpiva l’intero mondo scientifico, portando con sé la necessità di una trasformazione radicale delle pratiche di ricerca.\nQuesto evento contribuì a consolidare il riconoscimento della crisi della riproducibilità come una sfida centrale per tutta la scienza, spingendo verso un cambiamento culturale che mettesse al centro trasparenza, rigore e collaborazione.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "href": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "title": "86  La crisi della replicazione",
    "section": "\n86.5 La Cultura della Frode nel Sistema Accademico",
    "text": "86.5 La Cultura della Frode nel Sistema Accademico\nIn alcuni casi, la crisi della replicazione si intreccia con episodi di frode scientifica, rivelando un lato oscuro della ricerca accademica. Uno degli aspetti più preoccupanti è che il sistema accademico, con i suoi meccanismi di incentivo basati su pubblicazioni frequenti e finanziamenti competitivi, può indirettamente favorire comportamenti disonesti. Questo sistema, orientato al publish or perish (pubblica o scompari), crea pressioni che talvolta spingono i ricercatori a compromettere l’integrità scientifica per raggiungere i propri obiettivi di carriera.\n\n86.5.1 Il Caso Brian Wansink\nUn caso emblematico è quello di Brian Wansink, ex ricercatore di spicco alla Cornell University, che ricevette cospicui finanziamenti federali durante l’amministrazione Obama. I suoi studi sul comportamento alimentare, come quello sugli uomini che mangiano di più in presenza di donne o sull’effetto dei nomi “attraenti” dati alle verdure sul consumo da parte dei bambini, attirarono grande attenzione mediatica ma si rivelarono in seguito non replicabili. Le conseguenze per Wansink furono severe: diciotto suoi articoli furono ritirati, sette ricevettero “espressioni di preoccupazione”, e quindici furono corretti. Nel 2019, Wansink si dimise dalla Cornell University dopo essere stato giudicato colpevole di cattiva condotta scientifica.\n\n86.5.2 Il Caso Sylvain Lesné\nUn altro esempio rilevante riguarda Sylvain Lesné e i suoi coautori che, nel 2006, pubblicarono su Nature un importante articolo sul morbo di Alzheimer. Questo lavoro era fondamentale per lo sviluppo dell’ipotesi amiloide, un meccanismo proposto per spiegare come la malattia affligge le sue vittime. La ricerca sulla malattia di Alzheimer, che colpisce oltre 50 milioni di persone nel mondo, ha ricevuto oltre un miliardo di dollari in finanziamenti governativi fino al 2022, incoraggiata da studi come quello di Lesné.\nNel 2022, il neuroscienziato Matthew Schrag scoprì immagini manipolate in questo e in molti altri articoli di Lesné, inclusi quelli che sostenevano l’ipotesi amiloide. Le immagini erano state manualmente modificate e accorpate per mostrare falsamente supporto alle ipotesi degli articoli. Queste frodi passarono inosservate attraverso i processi di peer review formali di Nature e di altre sei riviste accademiche, venendo infine scoperte solo tramite canali non ufficiali.\nLe conseguenze di queste scoperte furono lente e frammentarie. Gli altri coautori dell’articolo del 2006 alla fine accettarono di ritirarlo, ma non Lesné stesso. La lentezza della risposta a queste evidenze di frode, e il fatto che Lesné continui a essere finanziato dal National Institutes of Health e impiegato presso l’Università del Minnesota, dimostra un fallimento sistemico nell’affrontare la cattiva condotta scientifica.\n\n86.5.3 Altri Casi di Rilievo\nNel mondo accademico, diversi altri recenti scandali hanno messo in luce il problema della frode scientifica e le sue conseguenze spesso limitate per i responsabili. Ecco alcuni casi emblematici:\n\nMarc Tessier-Lavigne, ex presidente della Stanford University: Nel 2023, fu costretto a dimettersi dopo la rivelazione di dati falsificati in sue ricerche precedenti presso Genentech. Nonostante lo scandalo, Tessier-Lavigne ha subito conseguenze minime, diventando successivamente CEO di una nuova azienda di ricerca farmacologica. Lo scandalo fu portato alla luce grazie all’indagine condotta da Theo Baker, uno studente diciassettenne di Stanford.\n\nDan Ariely e Francesca Gino: Questi due rinomati psicologi, noti per le loro ricerche sulla disonestà e il comportamento non etico, sono stati coinvolti in uno scandalo di frode scientifica.\n\nDan Ariely, nel 2021, fu implicato nella fabbricazione di dati in un articolo del 2012 sulla disonestà.\nFrancesca Gino, docente presso la Harvard Business School, è stata accusata di aver presentato lavori contenenti risultati falsificati. Il sito del Dipartimento ora riporta che è in “administrative leave”.\n\n\n\nL’inefficacia delle istituzioni accademiche nel gestire la frode scientifica sembra riflettere un problema culturale di carattere sistemico. Gli incentivi attuali favoriscono la pubblicazione di risultati positivi e innovativi, spesso a scapito dell’integrità scientifica. Gli studiosi che resistono a queste pressioni rischiano di essere emarginati, mentre chi adotta pratiche discutibili per ottenere risultati desiderati viene premiato con finanziamenti, promozioni e prestigio accademico.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "title": "86  La crisi della replicazione",
    "section": "\n86.6 Cosa Significa “Fallimento della Replicazione”?",
    "text": "86.6 Cosa Significa “Fallimento della Replicazione”?\nIl fallimento della replicazione non coincide necessariamente con l’idea che il fenomeno studiato sia inesistente. Al contrario, le cause di un esito negativo in un tentativo di replicazione possono essere molteplici e spesso difficili da individuare con precisione. Comprendere queste ragioni è fondamentale per identificare le criticità metodologiche, migliorare il rigore scientifico e favorire il progresso della conoscenza. Al di là dei casi evidenti di frode, i fallimenti della replicazione rappresentano un’opportunità per riflettere sulla qualità delle pratiche di ricerca.\n\n86.6.1 Possibili Cause di Fallimento nella Replicazione\n\nFalsi positivi nello studio originale\nUn fallimento può indicare che lo studio originale abbia rilevato un effetto inesistente per puro caso. Questo rischio è particolarmente elevato in studi con campioni di piccole dimensioni e bassa potenza statistica, dove gli effetti riportati risultano spesso sovrastimati o instabili.\n\nFalsi negativi nella replica\nIl fallimento può derivare da un falso negativo, ovvero la mancata rilevazione di un effetto realmente esistente. Le cause principali includono:\n\nDifferenze metodologiche o di popolazione tra studio originale e replica.\n\nConfondenti metodologici o una potenza statistica insufficiente.\n\nPresenza di variabili moderatrici che influenzano l’intensità dell’effetto in determinati contesti.\n\n\n\n86.6.2 La Scienza tra Incertezza e Riproducibilità\nLa scienza raramente offre certezze assolute. Come evidenziato dall’Open Science Collaboration, un singolo studio, sia esso originale o di replica, non è sufficiente a fornire una risposta definitiva. Solo replicazioni multiple e sistematiche possono distinguere effetti reali da errori casuali, offrendo una visione più affidabile di un fenomeno. Questo approccio richiede tempo e risorse, ma rappresenta il cuore del metodo scientifico.\n\n86.6.3 Psicologia e Altri Campi\nSebbene la crisi della replicazione sia stata ampiamente discussa in psicologia, problemi simili affliggono molte altre discipline scientifiche. Studi di replicazione hanno evidenziato risultati preoccupanti: in oncologia, meno della metà degli studi replicati ha prodotto risultati coerenti, con tassi di riproducibilità estremamente bassi in alcuni casi; nelle neuroscienze, i tentativi di replicare correlazioni cervello-comportamento hanno mostrato un altissimo tasso di insuccesso. Anche in discipline come l’economia e la filosofia sperimentale, pur registrando tassi di replicazione relativamente più elevati, permangono dubbi sulla selezione degli studi replicati e sulla rappresentatività dei risultati (Pennington, 2023).\nQuesti dati dimostrano che la problematica della replicazione non è esclusiva della psicologia, ma comune a diverse aree del sapere. Tuttavia, sollevano anche un interrogativo critico: è corretto parlare di “crisi” o si tratta piuttosto di una fase di trasformazione necessaria per migliorare il rigore e la trasparenza nella ricerca scientifica?",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "title": "86  La crisi della replicazione",
    "section": "\n86.7 Dibattito sulla Natura della Crisi",
    "text": "86.7 Dibattito sulla Natura della Crisi\nIl tema della crisi della replicazione ha suscitato un dibattito acceso e opinioni contrastanti all’interno della comunità scientifica:\n\nApproccio alle repliche: Alcuni ricercatori ritengono che le repliche esatte siano poco significative, preferendo le repliche concettuali che possano approfondire la comprensione di un fenomeno. Altri, invece, sostengono che solo repliche rigorose ed esatte siano in grado di verificare la robustezza di un effetto, garantendo maggiore affidabilità.\nInterpretazione dei dati dell’Open Science Collaboration (OSC): Il tasso di successo delle repliche riportato dall’OSC, pari al 36%, ha alimentato ulteriori discussioni. Alcuni attribuiscono questo risultato a differenze metodologiche tra studi originali e tentativi di replica, come campioni diversi o contesti modificati. Tuttavia, ricerche successive hanno smentito queste ipotesi, indicando che tali variazioni non spiegano interamente i bassi tassi di replicazione.\n\nInvece di considerare i fallimenti di replicazione come una crisi, molti studiosi li interpretano come un’opportunità per rafforzare la scienza. La replicazione, infatti, rappresenta un elemento fondamentale del metodo scientifico: permette di identificare i limiti di un fenomeno e di migliorare la comprensione delle condizioni in cui si manifesta. Ogni fallimento diventa, così, uno stimolo per il progresso.\nQuesta visione ha dato origine a un movimento noto come “rivoluzione della credibilità”, che punta a migliorare la qualità della ricerca attraverso trasparenza, autocorrezione e valorizzazione delle repliche. Progetti come il Loss of Confidence dimostrano che riconoscere i limiti e le incertezze degli studi precedenti non rappresenta una debolezza, ma un segno di integrità scientifica.\nIl passaggio dalla percezione di crisi a una rivoluzione della credibilità rappresenta un profondo cambiamento culturale nella comunità accademica. La scienza non è un processo statico, ma un percorso dinamico che evolve grazie al confronto critico e alla riflessione. In questa prospettiva, ogni fallimento nella replicazione non è un punto d’arrivo, ma un trampolino di lancio verso una conoscenza più affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "title": "86  La crisi della replicazione",
    "section": "\n86.8 Cause della Crisi",
    "text": "86.8 Cause della Crisi\n\n86.8.1 Incentivi Accademici e la Dominanza della Quantità sulla Qualità\nPer comprendere a fondo le problematiche che affliggono il mondo della ricerca, è essenziale considerare il contesto lavorativo in cui operano i ricercatori. Sebbene spesso vengano idealizzati come figure obiettive e razionali, è fondamentale ricordare che sono anche esseri umani, soggetti a pressioni professionali, responsabilità economiche e ambizioni di carriera. Il loro lavoro è costantemente sottoposto a valutazione: oltre a gestire attività didattiche e amministrative, devono pubblicare articoli su riviste di prestigio e assicurarsi finanziamenti per sostenere i loro gruppi di ricerca. Questo sistema premia la quantità a discapito della qualità, favorendo una mentalità di “pubblica o perisci”.\nLa pressione a pubblicare incessantemente è una delle principali cause dei problemi che alimentano la crisi di replicazione nella scienza. La cultura del “publish or perish” spinge i ricercatori a produrre rapidamente risultati rilevanti, spesso a scapito della rigorosità metodologica e della riproducibilità (Gopalakrishna et al., 2022; Grimes et al., 2018).\nQuesta situazione genera un paradosso: ciò che favorisce la carriera individuale di uno scienziato non sempre coincide con gli interessi del progresso scientifico. Le motivazioni intrinseche di contribuire alla conoscenza vengono spesso offuscate da motivazioni estrinseche legate a indicatori di produttività accademica. Non sorprende, quindi, che oltre il 60% dei ricercatori individui questa pressione come una delle principali cause dei problemi legati alla replicazione e alla riproducibilità.\n\n86.8.2 Bias Cognitivi e Distorsioni nella Ricerca\nI bias cognitivi rappresentano un ulteriore ostacolo alla qualità della ricerca. Tra i principali si trovano:\n\n\nBias di conferma: la tendenza a cercare o interpretare informazioni che confermano le proprie ipotesi iniziali, trascurando dati contrari.\n\nApofenia: il riconoscimento di schemi in dati casuali, spesso combinato con una preferenza per risultati positivi.\n\nBias retrospettivo: la convinzione che un evento fosse prevedibile solo dopo che si è verificato, portando i ricercatori a presentare risultati in modo fuorviante.\n\nQuesti bias favoriscono la ricerca di risultati positivi a scapito di quelli nulli o contrari, contribuendo a creare un problema più grande: il bias di pubblicazione.\n\n86.8.3 Bias di Pubblicazione e il Problema dei “File Drawer”\nIl sistema di pubblicazione accademica incentiva risultati innovativi e positivi, spesso trascurando studi con risultati nulli o repliche. Questo bias, noto come file drawer problem, descrive la tendenza a relegare nei “cassetti” studi non statisticamente significativi, rendendoli inaccessibili e distorcendo la letteratura scientifica.\nIn psicologia, l’impatto di questo fenomeno è particolarmente grave. Studi hanno rilevato che oltre il 90% degli articoli in psicologia riporta risultati positivi, una percentuale notevolmente più alta rispetto ad altre discipline. Questo non solo crea una rappresentazione distorta della realtà, ma amplifica il rischio di undead theories, teorie prive di solide basi empiriche che continuano a dominare il dibattito scientifico.\n\n86.8.4 Pratiche di Ricerca Dubbiamente Etiche\nLa pressione a pubblicare ha portato all’emergere di comportamenti noti come Questionable Research Practices (QRPs). Tra questi:\n\n\nP-hacking: manipolazione dei dati o analisi fino a ottenere un p-value significativo (&lt; 0.05).\n\nHARKing (Hypothesizing After Results are Known): modificare l’ipotesi iniziale per adattarla ai risultati ottenuti.\n\nStopping opzionale: interrompere la raccolta dei dati quando si raggiunge un p-value desiderato.\n\nQueste pratiche, pur non essendo sempre considerate frodi, distorcono i risultati e compromettono la replicabilità degli studi, creando teorie difficili da falsificare.\n\n86.8.5 La Centralità dei Valori-p e la Crisi della Significatività Statistica\nIl valore-p, elemento centrale della metodologia scientifica basata sull’ipotesi nulla (Null Hypothesis Significance Testing), è diventato una “valuta” per la pubblicazione. Tuttavia, affidarsi esclusivamente ai valori-p presenta gravi limiti:\n\n\nParadosso di Lindley: con campioni di grandi dimensioni, valori-p vicini a 0.05 possono supportare l’ipotesi nulla invece di confutarla.\n\nDistorsioni da QRPs: l’utilizzo di pratiche discutibili può produrre falsi positivi statisticamente significativi.\n\nBenché alcuni studiosi abbiano proposto l’abbassamento della soglia di significatività statistica a 0.005 o l’integrazione dei valori-p con stime degli effetti e intervalli di confidenza, il punto centrale continua ad essere il fatto che l’enfasi dovrebbe spostarsi dai risultati statistici alla qualità metodologica degli studi.\nPer affrontare questi problemi, è necessario un cambiamento culturale e strutturale. La trasparenza, l’autocorrezione e l’adozione di pratiche come la preregistrazione degli studi possono aiutare a ridurre l’impatto dei bias e delle QRPs. Inoltre, incentivare repliche rigorose e promuovere un sistema di pubblicazione che premi la qualità rispetto alla quantità sono passi fondamentali per migliorare la credibilità della scienza.\n\n86.8.6 Campioni Troppo Piccoli\nUno dei fattori chiave che contribuiscono alla crisi della replicazione in psicologia è l’uso di campioni di dimensioni ridotte. Questo approccio ha permesso ai ricercatori di massimizzare la quantità di pubblicazioni a scapito della qualità e dell’affidabilità degli effetti rilevati. Higginson e Munafò (2016) sottolineano come questo fenomeno rappresenti una “selezione naturale della cattiva scienza”, dove incentivi strutturali premiano metodologie di ricerca poco rigorose.\nContrariamente a quanto si potrebbe pensare, ottenere un effetto significativo con un campione piccolo non garantisce che lo stesso effetto rimanga significativo con un campione più grande. Questo problema è strettamente legato alla potenza statistica, che rappresenta la probabilità, nel lungo periodo, di rifiutare correttamente l’ipotesi nulla quando l’ipotesi alternativa è vera. Una potenza statistica bassa comporta un’elevata probabilità di errori di Tipo II (falsi negativi) e, allo stesso tempo, riduce la probabilità che un risultato significativo rifletta un effetto reale.\nIn psicologia, la potenza statistica viene solitamente fissata a un minimo dell’80%, il che significa che, nel lungo termine, uno studio dovrebbe avere l’80% di possibilità di rilevare un effetto reale. Tuttavia, molti studi più datati raramente menzionano la potenza statistica, nonostante il concetto sia noto dagli anni ’30. Questo ha contribuito a generare una letteratura scientifica con effetti sovrastimati o poco affidabili.\nIn un approccio frequentista, per calcolare la potenza di uno studio, è necessario conoscere almeno due dei seguenti tre parametri: dimensione dell’effetto atteso, criterio di significatività e dimensione del campione pianificata. Per esempio, un ricercatore che si aspetta di trovare un effetto “medio” (Cohen’s d = 0.50) con un criterio di significatività di p &lt; .05 può determinare la dimensione del campione necessaria per garantire una potenza sufficiente. Tuttavia, molti studi psicologici hanno ignorato questo tipo di pianificazione, basandosi su campioni troppo piccoli per rilevare effetti affidabili.\nL’uso di campioni piccoli, combinato con pratiche discutibili di ricerca (Questionable Research Practices, QRPs) e bias di pubblicazione, ha portato a una letteratura scientifica piena di effetti inflazionati. Ad esempio, meta-analisi iniziali sul concetto di esaurimento dell’ego (ego depletion) stimavano un effetto medio (d = 0.62). Tuttavia, repliche successive hanno trovato effetti molto più piccoli, spesso inferiori a d = 0.10. Allo stesso modo, il progetto dell’Open Science Collaboration (2015) ha evidenziato che le dimensioni degli effetti nelle repliche erano, in media, dimezzate rispetto agli studi originali.\nCampioni di piccole dimensioni non solo riducono la probabilità di rilevare effetti reali, ma compromettono anche la credibilità dei risultati significativi. Una bassa potenza statistica mina l’obiettivo fondamentale della ricerca scientifica, limitando la capacità di trarre conclusioni solide e contribuendo alla crisi della replicazione. Per migliorare la qualità della scienza, è essenziale adottare pratiche di ricerca più rigorose, pianificando adeguatamente la dimensione del campione e garantendo una potenza statistica sufficiente.\n\n86.8.7 La Misurazione: Un Problema Sottovalutato\nOltre alle dimensioni campionarie inadeguate, la psicologia potrebbe soffrire di problemi legati alla misurazione. Per rispondere a domande scientifiche, i ricercatori devono definire e misurare con precisione il costrutto oggetto di indagine. Ad esempio, per investigare se una mentalità di crescita possa migliorare l’intelligenza, un ricercatore deve prima definire e poi misurare sia la mentalità che l’intelligenza. Tuttavia, la misurazione è un processo complesso e impegnativo.\nL’intelligenza è un costrutto latente, il che significa che, a differenza dell’altezza di una persona, non può essere osservata o misurata direttamente. Gli psicologi inferiscono l’intelligenza stimando il quoziente intellettivo (QI) di un individuo, basandosi sulle risposte a numerose domande di un test di intelligenza, adattate all’età del partecipante. Ma come possiamo sapere se il QI rappresenta un buon indicatore dell’intelligenza? È necessario valutare la validità di costrutto, definita come la capacità di una misura di comportarsi in modo coerente con le ipotesi teoriche (Cronbach e Meehl, 1955; Fink, 2010). Alcuni ricercatori hanno sostenuto che una spiegazione spesso trascurata della crisi della replicazione risieda nella scarsa validità di costrutto delle nostre misure (Lilienfeld e Strother, 2020; Loken e Gelman, 2017).\nPer evidenziare il problema della misurazione in psicologia, Flake e colleghi hanno condotto una revisione di articoli pubblicati in una rivista prestigiosa. La loro analisi ha mostrato che molte scale di misurazione utilizzate non avevano una chiara fonte dichiarata, mentre altre erano state sviluppate senza una documentazione adeguata. Inoltre, una parte significativa delle scale citate era stata modificata rispetto alla versione originale, rendendo sconosciute le loro proprietà psicometriche.\nGli autori hanno anche rilevato l’uso di Pratiche di Misurazione Discutibili (Questionable Measurement Practices, QMPs), che includono la mancata divulgazione di informazioni sulla validità delle misure quando questa non risulta soddisfacente. Questi problemi suggeriscono che molti costrutti psicologici non siano adeguatamente validati, un fattore che potrebbe contribuire alle difficoltà di replicazione degli studi.\nAltri ricercatori hanno argomentato che problemi di validità interna ed esterna possano contribuire alla crisi della replicazione (Fabrigar et al., 2020). La validità interna si riferisce a come uno studio stabilisce una relazione di causa-effetto tra le variabili indipendenti e dipendenti (Cook e Campbell, 1979). Fabrigar et al. suggeriscono che un tentativo di replicazione possa fallire se:\n\nLo studio originale ha sofferto di minacce alla validità che hanno causato un effetto spurio (alta validità interna nella replica).\nI ricercatori introducono elementi assenti nello studio originale (bassa validità interna nella replica).\n\nLa validità esterna riguarda la possibilità di generalizzare i risultati di uno studio ad altri contesti o popolazioni. Questo può influenzare le repliche se, ad esempio, la replica viene condotta su una popolazione diversa o se i materiali dello studio sono tradotti da un’altra lingua, causando incomprensioni nei partecipanti.\nPer sintetizzare questi problemi, Flake e Fried (2020) li definiscono “measurement schmeasurement”, espressione che descrive la mancanza di attenzione verso la validità delle misure nella scienza psicologica. Se le misure utilizzate in uno studio non sono valide, ne consegue che anche i risultati e le conclusioni tratte non possono essere considerati affidabili. Quando tali studi vengono replicati, potrebbero essere destinati al fallimento ancor prima di iniziare.\n\n86.8.8 La Novità a Scapito della Replicazione: Una Distorsione nella Ricerca\nL’enfasi eccessiva sui risultati innovativi e il valore attribuito alle scoperte significative stanno incentivando pratiche di ricerca distorte, favorendo la sovrarappresentazione di risultati positivi e una mancanza di rigore metodologico (Ferguson & Heene, 2012; Ware & Munafò, 2015).\nLa psicologia sperimentale, nata nel 1879 con il primo laboratorio fondato da Wilhelm Wundt, si trova oggi a fronteggiare una crisi di replicazione nonostante oltre un secolo di progresso scientifico. Una delle principali cause è la scarsa attenzione dedicata agli studi di replicazione, storicamente poco valorizzati e raramente premiati nelle scienze sociali.\nLa cultura accademica attuale privilegia la novità e i risultati positivi, relegando i risultati nulli e gli studi di replicazione a un ruolo marginale. Questo fenomeno riflette ciò che Antonakis (2017) definisce significosis – un’ossessione per i risultati significativi – e neofilia – un’eccessiva enfasi sulla novità. Già Sterling (1959) aveva messo in guardia contro il rischio che i ricercatori testassero ripetutamente un’ipotesi fino a ottenere, per puro caso, un risultato significativo, senza verificarlo attraverso replicazioni. In assenza di queste verifiche, interi ambiti di studio possono essere costruiti su un numero allarmante di affermazioni non supportate da dati solidi.\nQuesto squilibrio si riflette non solo nella letteratura scientifica, ma anche nei progetti di ricerca condotti dagli studenti. Le tesi di laurea in psicologia, spesso realizzate in autonomia, senza finanziamenti e con tempistiche ridotte, soffrono degli stessi problemi della ricerca accademica: campioni di piccole dimensioni, studi sottopotenziati e un’elevata probabilità di falsi positivi. Se pubblicati selettivamente, questi progetti rischiano di premiare la fortuna più della qualità scientifica.\nIniziative come il Collaborative Replications and Education Project (CREP) rappresentano un passo verso un cambiamento culturale. CREP incoraggia gli studenti a condurre studi di replicazione come parte del loro percorso formativo, promuovendo una scienza più collaborativa, rigorosa e orientata alla verifica dei risultati, contrastando così la prevalenza della novità fine a se stessa.\n\n86.8.9 La scienza non si autocorregge come dovrebbe\nUn principio cardine della scienza è l’autocorrezione, ma nella pratica accademica moderna, questo processo sembra spesso ostacolato da incentivi e preoccupazioni reputazionali. I ricercatori, pressati dalle scadenze per nuovi progetti o richieste di finanziamento, raramente dedicano il tempo necessario a rivedere e correggere i propri lavori passati. Questo mancato impegno rappresenta una delle spiegazioni della crisi di replicazione.\nUn esempio significativo è il Registered Replication Report dello studio di Srull e Wyer (1979), replicato da McCarthy et al. (2018). Lo studio originale aveva mostrato che il priming con stimoli aggressivi portava i partecipanti a interpretare un comportamento ambiguo come più ostile. Tuttavia, il tentativo di replicazione ha rilevato un effetto trascurabile. Una possibile spiegazione è che alcune statistiche dello studio originale fossero riportate in modo errato, un errore che, nonostante tutto, non è mai stato corretto. Similmente, altri casi documentano gravi discrepanze nei dati riportati in letteratura, come dimostrato da van der Zee et al. (2017) nel loro riesame di articoli del Cornell Food Lab, che ha rivelato oltre 150 incongruenze.\nLa microbiologa Elizabeth Bik ha inoltre evidenziato che la manipolazione di immagini scientifiche è diventata una forma emergente di cattiva condotta, volta a rendere i risultati più impressionanti o a mascherare dati problematici. Sebbene alcuni casi di manipolazione portino a ritrazioni o correzioni, il lavoro di revisione è spesso svolto da altri ricercatori come attività volontaria, suggerendo che la scienza sia più “eterocorrettiva” che autocorrettiva.\nNonostante le difficoltà, il processo di autocorrezione è fondamentale per il progresso scientifico. Vazire (2020) sostiene che il disagio provocato dalla revisione critica sia salutare e necessiti di una maggiore umiltà intellettuale da parte dei ricercatori. Questo include il riconoscimento pubblico delle limitazioni dei propri studi e, quando necessario, la pubblicazione di correzioni o dichiarazioni di perdita di fiducia nei risultati originali.\n\n86.8.10 La Scienza Chiusa come Ostacolo alla Replicazione\nUno degli ostacoli principali alla replicazione è la mancanza di trasparenza e dettaglio negli studi precedenti. In un sistema di “scienza chiusa,” in cui dati e metodi sono trattati come segreti industriali, ricreare esperimenti e verificare analisi diventa un’impresa ardua, se non impossibile. Questa opacità interessa molti aspetti della ricerca, dai materiali utilizzati ai dati raccolti, fino alle scelte analitiche effettuate durante lo studio.\nPratiche come la reportistica selettiva e la flessibilità non dichiarata nei metodi e nei dati compromettono l’integrità della scienza. La riluttanza a condividere dati e materiali, insieme al bias di pubblicazione che favorisce i risultati significativi rispetto a quelli nulli, amplifica ulteriormente il problema (Bruton et al., 2020; Nosek et al., 2012).\nUn esempio concreto riguarda le decisioni prese durante l’analisi dei dati, come la gestione dei valori anomali o le correzioni per analisi multiple. Queste scelte possono avere un impatto notevole sui risultati, ma se non vengono documentate in modo trasparente, altri ricercatori non saranno in grado di replicare gli stessi risultati. Questo problema è noto come il giardino dei sentieri che si biforcano (garden of forking paths), dove una serie di decisioni non esplicitate porta a risultati divergenti e difficili da verificare (Gelman & Loken, 2013).\n\n\n\n\n\n\nLo psicologo Paul Meehl condusse uno studio su un campione di cinquantasettamila studenti delle scuole superiori del Minnesota, indagando su variabili quali religione, abitudini nel tempo libero, ordine di nascita, numero di fratelli, piani post-diploma e numerosi altri aspetti (Meehl, 2012). Complessivamente, le diverse risposte dei partecipanti potevano essere combinate in 990 modi distinti, permettendo analisi del tipo: “Gli studenti appassionati di cucina hanno una maggiore probabilità di essere figli unici?” o “Gli studenti provenienti da famiglie battiste sono più inclini a partecipare a club politici scolastici?”. Meehl evidenziò che, analizzando i dati, il 92% di queste possibili combinazioni risultava in correlazioni statisticamente significative. Queste differenze, sebbene reali, presumibilmente derivano da cause multifattoriali e complesse.\nAndrew Gelman ha denominato questo fenomeno Il Giardino dei Sentieri che si Biforcano [Garden of Forking Paths; Gelman & Loken (2013)], riferendosi ai molteplici gradi di libertà a disposizione del ricercatore nell’analisi dei dati. Come nell’esempio di Meehl, è possibile esaminare le differenze intergruppo (se questo è l’oggetto di interesse) da molteplici prospettive. Con un campione sufficientemente ampio, alcune di queste differenze risulteranno “statisticamente significative”. Ciò indica che, in quello specifico campione, quel particolare aspetto dei dati è rilevante. Tuttavia, questa differenza “statisticamente significativa” non sarà necessariamente generalizzabile ad un altro campione, il quale presenterà le proprie idiosincrasie.\nIn altri termini, come sottolineato da Gelman & Loken (2013), l’approccio basato sul test dell’ipotesi nulla si limita a “descrivere il rumore”. Da un punto di vista teorico, simili esercizi statistici risultano privi di valore euristico e non contribuiscono in nessun modo all’avanzamento delle conoscenze sul fenomeno oggetto di studio.\nIn un’ottica di inferenza statistica, questo problema è riconducibile al concetto di “p-hacking” o “data dredging”, dove l’esplorazione esaustiva di molteplici ipotesi statistiche su un singolo set di dati può portare a falsi positivi e a una sovrastima della significatività statistica.\n\n\n\nLa soluzione è chiara: promuovere una cultura di apertura, rendendo dati e metodi accessibili. Nonostante i progressi tecnologici che facilitano la condivisione, questa pratica rimane poco diffusa. Sebbene esistano ragioni valide per non condividere i dati, come la tutela dell’anonimato dei partecipanti, tali motivazioni dovrebbero essere dichiarate in modo esplicito e rigoroso.\nQuesti ostacoli sottolineano l’urgenza di una trasformazione culturale all’interno della comunità scientifica, che favorisca trasparenza e collaborazione. Affrontare queste limitazioni strutturali è essenziale per superare la crisi di replicazione, permettendo alla scienza di avanzare in modo più affidabile e autoregolarsi nel tempo.\n\n86.8.11 La Probabilità Inversa\nOltre a questi fattori, alcuni studiosi sostengono che la radice della crisi della replicazione sia ancora più profonda e risieda nell’approccio statistico stesso, ampiamente adottato dalla comunità scientifica (Chivers, 2024; Gelman & Loken, 2014; Loken & Gelman, 2017). Questo punto di vista suggerisce che le difficoltà nella replicazione dei risultati non siano solo il prodotto di comportamenti individuali discutibili, ma derivino in larga parte da un’interpretazione e un’applicazione problematica dei metodi statistici.\nPer comprendere meglio questa questione, dobbiamo tornare alle basi della statistica inferenziale. L’approccio frequentista, dominante nella ricerca scientifica, si basa sulle probabilità di campionamento. Questo metodo, che risale a Jakob Bernoulli nel XVIII secolo, calcola la probabilità di osservare certi dati assumendo che una determinata ipotesi sia vera. Il famoso “p-value” è un esempio di questa logica: esso indica la probabilità di ottenere risultati estremi quanto o più estremi di quelli osservati, supponendo che l’ipotesi nulla sia vera.\nTuttavia, questo approccio ha un limite fondamentale: non ci dice direttamente quanto è probabile che la nostra ipotesi sia vera alla luce dei dati raccolti. In altre parole, non fornisce una “probabilità inferenziale”, cioè la probabilità che l’ipotesi sia corretta in base ai risultati ottenuti. Qui entra in gioco l’approccio bayesiano. Il teorema di Bayes offre un metodo per calcolare proprio questa probabilità inferenziale. L’approccio bayesiano tiene conto non solo dei dati osservati, ma anche delle conoscenze pregresse (le “prior”) relative all’ipotesi in esame.\nLa differenza tra questi due approcci è cruciale. Mentre il p-value ci dice quanto sono improbabili i nostri dati se l’ipotesi nulla è vera, l’approccio bayesiano ci fornisce la probabilità che la nostra ipotesi sia vera alla luce dei dati raccolti e delle conoscenze precedenti.\n\n86.8.12 Implicazioni per la Pratica Scientifica\nQuesta distinzione ha implicazioni profonde per la pratica scientifica. L’uso esclusivo dell’approccio frequentista può portare a sovrastimare la forza delle evidenze a favore di un’ipotesi, specialmente quando si lavora con campioni piccoli o si conducono molti test statistici, come spesso accade in psicologia.\nAlcune soluzioni proposte per affrontare la crisi della replicazione includono:\n\nAbbassare la soglia di significatività statistica, rendendo più difficile dichiarare un risultato “significativo”.\nRichiedere la preregistrazione delle ipotesi per prevenire l’HARKing (Hypothesizing After Results are Known).\nFar sì che le riviste accettino gli articoli basandosi sui metodi piuttosto che sui risultati, per evitare il bias verso la pubblicazione di risultati solo “positivi” o “nuovi”.\n\nTuttavia, queste soluzioni, pur utili, non affrontano il problema fondamentale dell’interpretazione delle evidenze statistiche. L’adozione di un approccio bayesiano offre una soluzione più radicale, fornendo un quadro più completo e realistico della forza delle evidenze a favore o contro un’ipotesi scientifica.\n\n86.8.12.1 Guardare i Dati\nConsideriamo una simulazione, ispirata da Lakens (2015), che illustra come una pratica apparentemente innocua – osservare i risultati man mano che vengono raccolti nell’approccio frequentista – possa avere conseguenze significative sulle conclusioni di uno studio. In particolare, questa pratica può influire sulla probabilità di ottenere un risultato statisticamente significativo.\nNella simulazione seguente, due campioni casuali vengono estratti dalla stessa popolazione normale di partenza. Di conseguenza, l’“ipotesi nulla” è vera: non c’è differenza tra le medie delle popolazioni. Tuttavia, a causa della variabilità campionaria, il p-valore risulta fortemente influenzato da ogni singola osservazione aggiunta al campione.\n\nsimulate_t_tests &lt;- function(seed, max_sample_size, mu = 0, sigma = 1) {\n  set.seed(seed)\n\n  # Intervallo di grandezza campionaria\n  sample_sizes &lt;- seq(2, max_sample_size, by = 2)\n  p_values &lt;- numeric(length(sample_sizes))\n\n  # Genera due campioni grandi iniziali da una distribuzione normale\n  full_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n  full_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n  # Simulazione\n  for (i in seq_along(sample_sizes)) {\n    n &lt;- sample_sizes[i]\n\n    # Estrai sottoinsiemi incrementali dai campioni completi\n    sample1 &lt;- full_sample1[1:n]\n    sample2 &lt;- full_sample2[1:n]\n\n    # Esegui il t-test per il confronto delle medie di due gruppi indipendenti\n    t_test &lt;- t.test(sample1, sample2, var.equal = TRUE)\n    p_values[i] &lt;- t_test$p.value\n  }\n\n  # Crea il grafico del p-valore in funzione della grandezza campionaria\n  plot(\n    sample_sizes, p_values, type = \"l\", col = \"#b97c7c\",\n    xlab = \"Grandezza Campionaria\", ylab = \"P-valore\",\n    main = \"P-valore in funzione della grandezza campionaria\"\n  )\n  abline(h = 0.05, col = \"#8f2727\", lty = 2, lwd = 1.5)\n  legend(\"topright\", legend = \"Significatività a 0.05\", col = \"#8f2727\", lty = 2, cex = 0.8)\n}\n\nNelle due simulazioni seguenti, osserviamo come il p-valore cambi progressivamente aumentando la dimensione dei campioni casuali da \\(n = 2\\) a \\(n = 300\\). È evidente come il p-valore vari drasticamente con l’aggiunta di nuove osservazioni ai campioni. Inoltre, in alcune configurazioni, il p-valore può scendere al di sotto della soglia critica di 0.05 per puro caso. Se un ricercatore interrompesse la raccolta dei dati in quel momento, otterrebbe un risultato “statisticamente significativo”, pur avendo campioni estratti dalla stessa popolazione.\n\nsimulate_t_tests(seed = 1234, max_sample_size = 300, mu = 0, sigma = 2)\n\n\n\n\n\n\nsimulate_t_tests(seed = 2, max_sample_size = 300, mu = 0, sigma = 2)\n\n\n\n\n\n\n\nQuesta simulazione mette in evidenza una limitazione fondamentale dell’approccio frequentista: ogni test statistico considera esclusivamente i dati del campione corrente, ignorando le conoscenze accumulate in precedenza. Questo rende il processo decisionale estremamente volatile, poiché, teoricamente, ad ogni nuovo studio si “dimentica” tutta l’informazione derivante dagli studi precedenti.\n\n86.8.12.2 Analisi Bayesiana\nL’approccio bayesiano offre una soluzione elegante a questo problema. Nel framework bayesiano, la distribuzione a posteriori (cioè, la nostra convinzione aggiornata dopo aver osservato i dati) bilancia sempre l’informazione a priori (ciò che sapevamo prima dell’esperimento) con la verosimiglianza (ciò che i dati ci dicono). Questo equilibrio è particolarmente prezioso quando i dati sono deboli o contengono molto rumore, come nel caso dei dati della simulazione che stiamo discutendo. In tali situazioni, l’informazione a priori assume un ruolo più rilevante, impedendo conclusioni affrettate basate su dati poco informativi.\nPer illustrare questa differenza, consideriamo l’analisi bayesiana dei dati simulati in precedenza. Se questi dati vengono analizzati con l’approccio frequentista, forniscono un risultato “statisticamente significativo”, suggerendo una differenza tra i due gruppi.\nTuttavia, analizzando gli stessi dati con un approccio bayesiano, otteniamo un intervallo di credibilità al 95% compreso tra -0.52 e 1.12. Poiché questo intervallo include lo zero, possiamo affermare, con un livello di certezza soggettiva del 95%, che non c’è una differenza sostanziale tra le medie delle due popolazioni da cui sono stati estratti i campioni.\nQuesta discrepanza nei risultati evidenzia un punto cruciale: l’approccio bayesiano è più resistente ai falsi positivi in presenza di dati rumorosi o campioni piccoli. Invece di forzare una decisione binaria (significativo/non significativo) basata su una soglia arbitraria, l’analisi bayesiana fornisce una rappresentazione più sfumata e realistica dell’incertezza associata alle nostre conclusioni.\nInoltre, l’approccio bayesiano offre il vantaggio di essere cumulativo: ogni nuovo studio non parte da zero, ma incorpora naturalmente le conoscenze precedenti attraverso la distribuzione a priori.\n\n# Imposta il seme per la riproducibilità\nset.seed(12)\n\n# Parametri della distribuzione normale\nmu &lt;- 0\nsigma &lt;- 2\nmax_sample_size &lt;- 50\n\n# Genera due campioni indipendenti\nfull_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\nfull_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n\n# Prepara i dati per Stan\nstan_data &lt;- list(\n  N1 = length(full_sample1),\n  N2 = length(full_sample2),\n  y1 = full_sample1,\n  y2 = full_sample2\n)\n\n# Visualizza i dati preparati\nprint(stan_data)\n#&gt; $N1\n#&gt; [1] 50\n#&gt; \n#&gt; $N2\n#&gt; [1] 50\n#&gt; \n#&gt; $y1\n#&gt;  [1] -2.9611  3.1543 -1.9135 -1.8400 -3.9953 -0.5446 -0.6307 -1.2565 -0.2129\n#&gt; [10]  0.8560 -1.5554 -2.5878 -1.5591  0.0239 -0.3048 -1.4069  2.3778  0.6810\n#&gt; [19]  1.0139 -0.5866  0.4473  4.0144  2.0240 -0.6049 -2.0505 -0.5348 -0.3982\n#&gt; [28]  0.2622  0.2916  0.7241  1.3480  4.1441 -1.0821 -2.1410 -0.7449 -0.9703\n#&gt; [37]  0.5496 -0.9590  1.5962 -2.0089  0.2100 -2.3120  1.1563 -3.1913 -0.6170\n#&gt; [46]  0.8989 -1.9541  0.3800  1.4629 -0.9852\n#&gt; \n#&gt; $y2\n#&gt;  [1] -0.08537 -0.22534  0.91365  4.04067 -2.10178  1.46930  1.07850 -2.62855\n#&gt;  [9] -0.50008  0.62841  0.81309  1.98884  1.71154  0.39426  1.66865  1.69358\n#&gt; [17]  3.90821 -4.29852  1.94224  2.29012 -1.05080  0.50064 -0.85881 -0.36504\n#&gt; [25] -0.20662 -1.26768 -2.54211 -0.76790  1.03351 -0.35594  0.00852 -2.54812\n#&gt; [33] -0.40422  2.32893 -0.04676  1.79431 -0.35345  2.22742 -1.08378 -1.92680\n#&gt; [41]  0.75290 -1.96935  1.79512  0.25853  2.06741 -0.68458  0.90456 -1.38948\n#&gt; [49] -0.47803 -2.01460\n\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"two_means_diff.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\nmod$code() # Stampa il codice del modello\n#&gt;  [1] \"data {\"                                                                \n#&gt;  [2] \"  int&lt;lower=0&gt; N1; // Numero di osservazioni nel gruppo 1\"             \n#&gt;  [3] \"  int&lt;lower=0&gt; N2; // Numero di osservazioni nel gruppo 2\"             \n#&gt;  [4] \"  vector[N1] y1; // Dati del gruppo 1\"                                 \n#&gt;  [5] \"  vector[N2] y2; // Dati del gruppo 2\"                                 \n#&gt;  [6] \"}\"                                                                     \n#&gt;  [7] \"parameters {\"                                                          \n#&gt;  [8] \"  real mu1; // Media del gruppo 1\"                                     \n#&gt;  [9] \"  real delta; // Differenza tra le medie\"                              \n#&gt; [10] \"  real&lt;lower=0&gt; sigma; // Deviazione standard comune\"                  \n#&gt; [11] \"  real&lt;lower=0&gt; nu; // Gradi di libertà per la distribuzione t\"        \n#&gt; [12] \"}\"                                                                     \n#&gt; [13] \"transformed parameters {\"                                              \n#&gt; [14] \"  real mu2; // Media del gruppo 2\"                                     \n#&gt; [15] \"  mu2 = mu1 + delta;\"                                                  \n#&gt; [16] \"}\"                                                                     \n#&gt; [17] \"model {\"                                                               \n#&gt; [18] \"  // Priori\"                                                           \n#&gt; [19] \"  mu1 ~ normal(0, 5);\"                                                 \n#&gt; [20] \"  delta ~ normal(0, 2); // Priore su delta\"                            \n#&gt; [21] \"  sigma ~ cauchy(0, 5);\"                                               \n#&gt; [22] \"  nu ~ gamma(2, 0.1); // Priore sulla t-student\"                       \n#&gt; [23] \"  \"                                                                    \n#&gt; [24] \"  // Verosimiglianza\"                                                  \n#&gt; [25] \"  y1 ~ student_t(nu, mu1, sigma);\"                                     \n#&gt; [26] \"  y2 ~ student_t(nu, mu2, sigma);\"                                     \n#&gt; [27] \"}\"                                                                     \n#&gt; [28] \"generated quantities {\"                                                \n#&gt; [29] \"  real diff; // Differenza tra le medie (alias di delta per chiarezza)\"\n#&gt; [30] \"  diff = delta;\"                                                       \n#&gt; [31] \"}\"\n\nEsegui il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  show_messages = FALSE\n)\n\nRiassumi i risultati per mu1, mu2 e delta:\n\nfit_summary &lt;- fit$summary(variables = c(\"mu1\", \"mu2\", \"delta\"))\nprint(fit_summary)\n#&gt; # A tibble: 3 × 10\n#&gt;   variable   mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu1      -0.320 -0.319 0.244 0.240 -0.725 0.075 1.001 5564.826 5622.504\n#&gt; 2 mu2       0.161  0.159 0.242 0.243 -0.233 0.561 1.000 9267.197 7120.562\n#&gt; 3 delta     0.481  0.479 0.343 0.341 -0.081 1.046 1.000 5332.071 5542.274\n\nEstrai i campioni di delta:\n\ndelta_samples &lt;- fit$draws(variables = \"delta\", format = \"matrix\")[, 1]\n\nDisegna la distribuzione a posteriori di delta:\n\ndelta_df &lt;- data.frame(delta = delta_samples)\n\nggplot(delta_df, aes(x = delta)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"#b97c7c\", alpha = 0.75) +\n  geom_vline(\n    xintercept = mean(delta_samples),\n    linetype = \"dashed\",\n    linewidth = 1.2,\n    label = paste(\"Mean:\", round(mean(delta_samples), 2))\n  ) +\n  labs(\n    x = \"delta\",\n    y = \"Density\",\n    title = \"Posterior distribution of delta\"\n  ) \n\n\n\n\n\n\n\nPuoi calcolare l’intervallo di credibilità usando per un intervallo al 95%:\n\nquantile(delta_samples, probs = c(0.025, 0.975))\n#&gt;   2.5%  97.5% \n#&gt; -0.188  1.164\n\n\n86.8.12.3 Garbage In, Garbage Out\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l’ipotesi nulla o non la si rifiuta. Ciò implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, è inevitabile trovare qualche effetto, anche se di minima entità.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell’effetto e di fornire una distribuzione di probabilità. Una distribuzione di probabilità è una rappresentazione grafica delle diverse possibilità che potrebbero verificarsi. In questo contesto, si tratta della “probabilità inversa”, ovvero della plausibilità dell’ipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed è il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l’aggiornamento bayesiano. Il parametro \\(\\delta\\) è la nostra ipotesi sulla differenza tra le due medie, e l’inferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL’approccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell’ipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di “significatività statistica”, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l’approccio frequentista sia spesso considerato “ingenuo” da molti ricercatori, adottare l’approccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione degli incentivi accademici che favoriscono la pubblicazione di un elevato numero di articoli, indipendentemente dalla loro qualità. Un principio fondamentale della ricerca è “Garbage in, garbage out”. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualità delle misurazioni è insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, può trasformare la spazzatura in oro.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#esercizi",
    "href": "chapters/replication_crisis/01_crisis.html#esercizi",
    "title": "86  La crisi della replicazione",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsistono numerosi esempi di ricerche che non riescono a essere replicate (posso citare anche uno studio di replicazione che ho condotto io stesso: Caudek et al. (2017)). Un recente caso emblematico è rappresentato dallo studio di Karataş & Cutright (2023) e dal successivo tentativo di replicazione condotto da Moore et al. (2024). Analizzando le quattro principali argomentazioni sollevate da Gelman & Brown (2024) per criticare lo studio di Aungle & Langer (2023), si offra un’interpretazione del perché lo studio di Karataş & Cutright (2023) non sia stato replicato con successo.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\n1) Sulla “Crisi della Replicazione” in Psicologia\nChe cosa si intende quando si parla di “crisi della replicazione” in psicologia?\n\n\nA. La difficoltà di molti laboratori nel reperire fondi per la ricerca.\n\n\nB. L’incapacità o la grave difficoltà di replicare, con risultati simili, una parte consistente degli studi pubblicati.\n\n\nC. La tendenza di alcuni scienziati a pubblicare risultati simili ad altri per sfruttare la loro notorietà.\n\n\nD. Lo scarso interesse degli editori di riviste nel pubblicare studi teorici.\n\n\nE. La mancanza di strumenti statistici adeguati per l’analisi dei dati qualitativi.\n\n2) Cosa significa “fallimento della replicazione”?\nQuale delle seguenti opzioni descrive correttamente il “fallimento della replicazione”?\n\n\nA. Non riuscire a pubblicare uno studio su una rivista ad alto impatto.\n\n\nB. Non riuscire a confermare la robustezza metodologica dello studio originale in sede di peer-review.\n\n\nC. Riportare risultati che confermano un’ipotesi già discussa in letteratura.\n\n\nD. Non ottenere, con procedure simili e campioni simili, risultati paragonabili a quelli dello studio originale.\n\n\nE. Non riuscire a reclutare un numero sufficiente di partecipanti in una nuova ricerca.\n\n3) Quale studio scatenò polemiche sulla precognizione?\nNel 2011, un autore pubblicò uno studio che sembrava dimostrare capacità “paranormali” nei partecipanti, scatenando polemiche e dubbi. Chi fu?\n\n\nA. Diederik Stapel, che usò dati inventati.\n\n\nB. John Ioannidis, autore di “Why Most Published Research Findings Are False”.\n\n\nC. Daryl Bem, con l’articolo “Feeling the Future” sulle facoltà precognitive.\n\n\nD. Brian Wansink, con studi su etichette “attraenti” delle verdure.\n\n\nE. Daniel Kahneman, con esperimenti sui bias cognitivi e di giudizio.\n\n4) Cosa si intende per “p-hacking”?\nLa pratica denominata p-hacking (nell’ambito della crisi di replicazione) consiste nel:\n\n\nA. Interrompere la raccolta dati nel momento in cui si ottiene un risultato in linea con l’ipotesi.\n\n\nB. Manipolare, in maniera fraudolenta, immagini o grafici.\n\n\nC. Tradurre erroneamente i questionari in più lingue, alterando i risultati.\n\n\nD. Utilizzare molteplici analisi e combinazioni di variabili fino a ottenere un valore-(p) inferiore a 0.05.\n\n\nE. Avere più autori su uno stesso manoscritto per dividerne la responsabilità.\n\n5) Qual è il tasso di replicazione emerso dal “Reproducibility Project: Psychology” (2015)?\nSecondo i dati dell’Open Science Collaboration (2015), approssimativamente quanti studi di psicologia replicarono con successo (ottenendo risultati “significativi” simili agli originali)?\n\n\nA. Circa il 36%.\n\n\nB. Circa il 65%.\n\n\nC. Quasi il 90%.\n\n\nD. Nessuno studio è stato replicato con successo.\n\n\nE. Circa il 10%.\n\n6) Cosa sono le Questionable Research Practices (QRPs)?\nQuale definizione descrive meglio le “QRPs” (Questionable Research Practices)?\n\n\nA. Pratiche statistiche avanzate che aumentano la robustezza dei risultati.\n\n\nB. Metodologie di campionamento probabilistico trasparenti e preregistrate.\n\n\nC. Pratiche di ricerca discutibili, come “optional stopping” e selezione post-hoc di ipotesi, che influiscono negativamente sull’integrità scientifica.\n\n\nD. Strumenti di meta-analisi per combinare risultati di studi diversi.\n\n\nE. Procedure di controllo etico per proteggere i diritti dei partecipanti.\n\n7) Perché i campioni troppo piccoli sono considerati problematici?\nNella letteratura sulla crisi di replicazione, perché avere campioni di dimensione ridotta costituisce una criticità?\n\n\nA. Perché rendono più facile l’analisi statistica, riducendo la possibilità di trovare p &lt; .05.\n\n\nB. Perché riducono la potenza statistica, aumentando il rischio di sovrastimare effetti e di ottenere risultati non replicabili.\n\n\nC. Perché il costo di reclutamento è troppo basso, compromettendo l’interesse dei revisori.\n\n\nD. Perché obbligano a utilizzare necessariamente test non-parametrici.\n\n\nE. Perché la psicologia preferisce dataset qualitativi, non quantitativi.\n\n8) Che cosa significa “bias di pubblicazione”?\nCon l’espressione “bias di pubblicazione” (o publication bias), ci si riferisce a:\n\n\nA. La tendenza dei revisori a selezionare articoli soltanto se ben scritti.\n\n\nB. L’inclinazione delle riviste di settore a pubblicare preferibilmente i lavori dei ricercatori senior.\n\n\nC. La propensione alla pubblicazione di studi con risultati innovativi e statisticamente positivi, trascurando invece studi con risultati nulli.\n\n\nD. L’obbligo di pubblicare i protocolli di studio in forma open.\n\n\nE. Una norma deontologica che impone di nascondere i metodi inediti per evitare furti di idee.\n\n9) Quale scopo principale ha il movimento dell’Open Science?\nNel contesto della crisi di replicazione, qual è l’obiettivo cardine promosso dal movimento per la Scienza Aperta (Open Science)?\n\n\nA. Aumentare il controllo sugli studi, rendendo segreti i metodi di analisi.\n\n\nB. Pubblicare soltanto studi che abbiano ottenuto finanziamenti pubblici.\n\n\nC. Rendere i dati, i materiali e le procedure il più possibile trasparenti e accessibili, favorendo le repliche e la verifica indipendente.\n\n\nD. Abolire completamente l’uso di test statistici e valori-p.\n\n\nE. Prediligere esclusivamente studi qualitativi in ambito psicologico.\n\n10) Perché la scienza non si autocorregge come si afferma?\nSecondo quanto discusso, come mai la scienza non risulta sempre “autocorrettiva” nella pratica reale?\n\n\nA. Perché gli editori impongono di inserire errori per testare la capacità dei revisori di individuarli.\n\n\nB. Perché è molto costoso usare software di statistica adeguati.\n\n\nC. Perché la pressione a pubblicare risultati nuovi prevale sull’attenzione a errori e correzioni; i ricercatori non hanno incentivi sufficienti a pubblicare smentite, ritrazioni o correzioni.\n\n\nD. Perché l’uso della statistica bayesiana ha complicato la procedura di revisione.\n\n\nE. Perché tutti gli studi di psicologia sono in realtà corretti al 99%.\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n\n\nB\n\n\nD\n\n\nC\n\n\nD\n\n\nA\n\n\nC\n\n\nB\n\n\nC\n\n\nC\n\nC\n\nLa crisi della replicazione in psicologia è il risultato di una combinazione di fattori sistemici e metodologici:\n\n\nIncentivi distorti (“publish or perish”), che spingono a privilegiare la novità rispetto alla qualità e alla rigorosità delle ricerche.\n\n\nPratiche di ricerca discutibili (QRPs), tra cui p-hacking e optional stopping, che producono un numero elevato di falsi positivi.\n\n\nBias di pubblicazione, che favorisce i risultati statistici significativi a scapito di studi con esiti non significativi o repliche.\n\n\nBassa potenza statistica e campioni di piccole dimensioni, che gonfiano o sovrastimano l’effetto di fenomeni psicologici.\n\n\nScarsa trasparenza e accessibilità (scienza “chiusa”), che rende difficile verificare e replicare i risultati originari.\n\nNonostante i numeri allarmanti riportati da studi di vasta portata (come il Reproducibility Project), questa situazione può essere vista come un’opportunità di “rivoluzione della credibilità”:\n\nSi stanno diffondendo pratiche di Open Science, con la condivisione di dati, protocolli, codici e materiali, favorendo così la replica e la validazione indipendente.\n\nLa cultura della replicazione viene valorizzata, incentivando studi più rigorosi e focalizzati sulla robustezza degli effetti.\n\nL’approccio statistico tradizionale (frequentista) è posto in discussione, evidenziando la possibilità di integrare o sostituire i test di ipotesi nulla con metodologie più robuste, tra cui quelle bayesiane, le analisi preregistrate e la valorizzazione di stime degli effetti con intervalli di credibilità.\n\nLa crisi di replicazione, quindi, non deve essere intesa come un fallimento totale, bensì come un momento critico che ha avviato un rinnovamento, mirato a rendere la scienza psicologica (e altre discipline) più rigorosa, trasparente e affidabile.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "title": "86  La crisi della replicazione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.4.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [46] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [49] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [52] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [55] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [58] rstantools_2.4.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [61] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [64] data.table_1.17.8     mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [67] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [70] cli_3.6.5             textshaping_1.0.1     svUnit_1.0.8         \n#&gt; [73] Brobdingnag_1.2-9     V8_6.0.6              gtable_0.3.6         \n#&gt; [76] digest_0.6.37         TH.data_1.1-3         htmlwidgets_1.6.4    \n#&gt; [79] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [82] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "title": "86  La crisi della replicazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230–244.\n\n\nBem, D. J. (2011). Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect. Journal of Personality and Social Psychology, 100(3), 407–425.\n\n\nBruton, S. V., Medlin, M., Brown, M., & Sacco, D. F. (2020). Personal motivations and systemic incentives: Scientists on questionable research practices. Science and Engineering Ethics, 26(3), 1531–1547.\n\n\nCaudek, C., Lorenzino, M., & Liperoti, R. (2017). Delta plots do not reveal response inhibition in lying. Consciousness and Cognition, 55, 232–244.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nFerguson, C. J., & Heene, M. (2012). A vast graveyard of undead theories: Publication bias and psychological science’s aversion to the null. Perspectives on Psychological Science, 7(6), 555–561.\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nGopalakrishna, G., Ter Riet, G., Vink, G., Stoop, I., Wicherts, J. M., & Bouter, L. M. (2022). Prevalence of questionable research practices, research misconduct and their potential explanatory factors: A survey among academic researchers in The Netherlands. PloS one, 17(2), e0263023.\n\n\nGrimes, D. R., Bauch, C. T., & Ioannidis, J. P. (2018). Modelling science trustworthiness under publish or perish pressure. Royal Society open science, 5(1), 171511.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKarataş, M., & Cutright, K. M. (2023). Thinking about God increases acceptance of artificial intelligence in decision-making. Proceedings of the National Academy of Sciences, 120(33), e2218961120.\n\n\nLakens, D. (2015). On the challenges of drawing conclusions from p-values just below 0.05. PeerJ, 3, e1142.\n\n\nLeys, R. (2024). Anatomy of a Train Wreck: The Rise and Fall of Priming Research. University of Chicago Press.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMeehl, P. E. (2012). Why summaries of research on psychological theories are often uninterpretable. In Improving inquiry in social science (pp. 13–59). Routledge.\n\n\nMoore, D. A., Schroeder, J., Bailey, E. R., Gershon, R., Moore, J. E., & Simmons, J. P. (2024). Does thinking about God increase acceptance of artificial intelligence in decision-making? Proceedings of the National Academy of Sciences, 121(31), e2402315121.\n\n\nNosek, B. A., Spies, J. R., & Motyl, M. (2012). Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science, 7(6), 615–631.\n\n\nPennington, C. (2023). A student’s guide to open science: Using the replication crisis to reform psychology. McGraw-Hill Education (UK).\n\n\nWare, J. J., & Munafò, M. R. (2015). Significance chasing in research practice: causes, consequences and possible solutions. Addiction, 110(1), 4–8.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html",
    "title": "87  Limiti dell’inferenza frequentista",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nIn questa sezione della dispensa, abbiamo approfondito il metodo “tradizionale” per il test di significatività dell’ipotesi nulla (NHST). Comprendere la logica sottostante all’approccio NHST è fondamentale, poiché esso ha rappresentato il principale strumento della statistica inferenziale sin dalla sua introduzione all’inizio del XX secolo, e la maggior parte dei ricercatori continua a basarsi su questa procedura per l’analisi dei dati. Tuttavia, negli ultimi anni, l’NHST è stato oggetto di crescenti critiche, con molti studiosi che sostengono che questo approccio possa generare più problemi di quanti ne risolva. Per questo motivo, è cruciale esaminare le critiche avanzate dalla comunità scientifica nei confronti della procedura inferenziale NHST. In questa sezione, analizzeremo alcuni dei principali dubbi e limiti emersi riguardo a tale metodologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "87  Limiti dell’inferenza frequentista",
    "section": "87.1 L’uso del valore-\\(p\\) nel mondo della ricerca",
    "text": "87.1 L’uso del valore-\\(p\\) nel mondo della ricerca\nNel suo articolo “Statistical Errors” (2014), Nuzzo mette in luce i limiti dell’approccio NHST nella pratica scientifica Nuzzo (2014). Sebbene il valore-\\(p\\) sia stato introdotto da Ronald Fisher negli anni ’20, egli non lo concepì mai come un test formale. Fisher lo considerava piuttosto uno strumento informale per valutare se l’evidenza empirica fosse “significativa” in senso colloquiale, ovvero meritevole di ulteriore attenzione. Nella pratica, Fisher suggeriva di assumere un’ipotesi nulla e di calcolare la probabilità di osservare un risultato altrettanto estremo o più estremo di quello ottenuto, presupponendo che il risultato fosse interamente dovuto alla variabilità campionaria. Tuttavia, per Fisher, il valore-\\(p\\) non era una conclusione definitiva, ma uno strumento da integrare in un processo decisionale più ampio, che tenesse conto sia delle evidenze empiriche sia delle conoscenze pregresse del ricercatore. In altre parole, il valore-\\(p\\) era parte di un ragionamento scientifico, non il punto finale di tale ragionamento.\nVerso la fine degli anni ’20, Jerzy Neyman e Egon Pearson, rivali di Fisher, formalizzarono le procedure di decisione statistica con l’obiettivo di renderle più rigorose e oggettive. Introdussero concetti come il potere statistico e il tasso di falsi positivi, ma si distanziarono dall’uso del valore-\\(p\\) proposto da Fisher. Le divergenze tra Fisher, Neyman e Pearson diedero vita a un acceso dibattito: Neyman definì il lavoro di Fisher “matematicamente peggiore dell’inutilità”, mentre Fisher bollò l’approccio di Neyman come “infantile” e “dannoso per la libertà intellettuale dell’Occidente”.\nNel frattempo, altri autori iniziarono a scrivere manuali di statistica per guidare i ricercatori. Tuttavia, molti di questi autori non erano statistici e avevano una comprensione superficiale delle differenze tra i vari approcci. Il risultato fu un sistema ibrido che combinava il valore-\\(p\\) di Fisher con il framework rigoroso di Neyman e Pearson. Fu in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne arbitrariamente definita come “statisticamente significativa”.\nStoricamente, tuttavia, il valore-\\(p\\) proposto da Fisher aveva un significato molto diverso rispetto a quello che gli viene attribuito oggi. Come abbiamo visto, per Fisher era uno strumento informale, da utilizzare all’interno di un processo decisionale più ampio e non come un criterio meccanico per stabilire la verità scientifica. L’uso del valore-\\(p\\) nel sistema ibrido adottato dai manuali di statistica è quindi privo di una solida giustificazione teorica.\nNel 2016, l’American Statistical Association (ASA) ha espresso forti preoccupazioni riguardo all’uso inappropriato del valore-\\(p\\) nella pratica scientifica contemporanea Wasserstein & Lazar (2016):\n\n\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\nL’articolo prosegue sottolineando che:\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical “bright-line” rules (such as “\\(p &lt; 0.05\\)”) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‘true’ on one side of the divide and ‘false’ on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‘yes-no’ decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of “statistical significance” (generally interpreted as \\(p \\leq 0.05\\)) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "title": "87  Limiti dell’inferenza frequentista",
    "section": "87.2 \\(P\\)-hacking",
    "text": "87.2 \\(P\\)-hacking\nLa pratica del \\(P\\)-hacking rappresenta una delle principali criticità associate all’uso del valore-\\(p\\) ed è conosciuta anche con termini come data-dredging, snooping, fishing, significance-chasing o double-dipping. Secondo Uri Simonsohn, professore all’Università della Pennsylvania, il \\(P\\)-hacking consiste nel manipolare i dati o le analisi fino a ottenere un risultato statisticamente significativo, tipicamente con un valore-\\(p\\) inferiore a 0.05. Ad esempio, si potrebbe dire: “Quel risultato sembra frutto di \\(P\\)-hacking; gli autori hanno escluso una condizione per far diminuire il valore-\\(p\\) sotto la soglia di 0.05” oppure “Lei è un \\(P\\)-hacker, controlla continuamente i dati durante la raccolta per trovare un risultato significativo”.\nQuesta pratica trasforma uno studio esplorativo, che dovrebbe essere interpretato con estrema cautela, in uno studio confermativo (apparentemente robusto), i cui risultati, tuttavia, hanno una probabilità molto bassa di essere replicati in ricerche successive. Secondo le simulazioni condotte da Simonsohn, piccole modifiche nelle scelte analitiche possono aumentare il tasso di falsi positivi fino al 60% in un singolo studio.\nIl \\(P\\)-hacking è particolarmente diffuso negli studi che cercano di dimostrare effetti di piccola entità utilizzando dati molto rumorosi. Un’analisi della letteratura psicologica ha rivelato che i valori-\\(p\\) riportati tendono a concentrarsi appena al di sotto della soglia di 0.05, un fenomeno che può essere interpretato come un segnale di \\(P\\)-hacking: i ricercatori eseguono molteplici test statistici fino a trovarne uno che raggiunge la “significatività statistica” e poi riportano solo quello. Come evidenziato in figura, questa pratica non è limitata alla psicologia, ma è ampiamente diffusa in tutti i campi della ricerca scientifica, contribuendo a minare l’affidabilità dei risultati pubblicati.\n\n\n\nDistribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "title": "87  Limiti dell’inferenza frequentista",
    "section": "87.3 Critiche al valore-\\(p\\)",
    "text": "87.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) è stato spesso paragonato a creature fastidiose e persistenti come le zanzare, oppure ai “vestiti nuovi dell’imperatore”, metafora che rappresenta la tendenza a ignorare problemi evidenti preferendo fingere che tutto vada bene. È stato anche definito un intellectual rake sterile, un termine che sottolinea la sua incapacità di produrre risultati utili. Non manca nemmeno l’ironia sul fatto che la procedura di statistical hypothesis inference testing venga chiamata così principalmente per l’acronimo che genera.\nIl valore-\\(p\\) promuove un modo di pensare distorto, spostando l’attenzione dal cuore della ricerca, ovvero la forza della manipolazione sperimentale, verso la dimostrazione di un’ipotesi nulla che si sa già essere falsa. Ad esempio, uno studio condotto su oltre 19,000 individui ha mostrato che le coppie che si incontrano online hanno una probabilità inferiore di divorziare (\\(p &lt; 0.002\\)) e riportano una maggiore soddisfazione nella vita matrimoniale (\\(p &lt; 0.001\\)) rispetto a quelle che si sono conosciute offline. Sebbene questi risultati possano sembrare interessanti, senza considerare la dimensione dell’effetto – come la riduzione del tasso di divorzio dal 7.67% al 5.96% o l’aumento dell’indice di soddisfazione matrimoniale da 5.48 a 5.64 su una scala a sette punti – il loro impatto pratico rischia di essere sopravvalutato. In generale, la domanda chiave non dovrebbe essere “c’è un effetto?”, ma piuttosto “quanto è grande l’effetto?”. Questo approccio permette di valutare meglio l’effettiva rilevanza dei risultati, andando oltre la semplice significatività statistica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "title": "87  Limiti dell’inferenza frequentista",
    "section": "87.4 L’effetto sperimentale è esattamente nullo?",
    "text": "87.4 L’effetto sperimentale è esattamente nullo?\nUna delle critiche più ricorrenti alla logica del test di verifica delle ipotesi statistiche riguarda l’assunzione irrealistica che l’effetto della manipolazione sperimentale sia esattamente nullo. Ad esempio, la fisica ci dimostra che persino lo spostamento di un grammo di massa in una stella distante anni luce dalla Terra può influenzare, seppur minimamente, il movimento delle molecole di un gas sul nostro pianeta (Borel, 1914). Questo esempio suggerisce che ogni manipolazione sperimentale, per quanto piccola, produca in qualche modo un effetto. Pertanto, come sottolinea Andrew Gelman, il problema non è tanto dimostrare che l’ipotesi nulla sia falsa – ovvero che la manipolazione sperimentale non abbia alcun effetto – quanto piuttosto valutare se la dimensione dell’effetto sia sufficientemente grande da avere un impatto pratico e se tale effetto sia riproducibile.\nIn questo contesto, la logica del test dell’ipotesi nulla risulta particolarmente problematica, specialmente quando si lavora con campioni piccoli ed effetti di modesta entità, come accade spesso negli studi psicologici. Questo approccio può portare a una sovrastima della dimensione dell’effetto e a una visione binaria dei risultati (vero/falso), distogliendo l’attenzione dalla stima accurata e non distorta della dimensione effettiva dell’effetto. In altre parole, la ricerca dovrebbe concentrarsi meno sul rifiutare un’ipotesi nulla spesso irrealistica e più sulla comprensione e quantificazione dell’impatto reale delle variabili studiate.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "title": "87  Limiti dell’inferenza frequentista",
    "section": "87.5 Attenti al valore-\\(p\\)!",
    "text": "87.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema. Supponiamo di eseguire un \\(t\\)-test per due campioni indipendenti per verificare l’ipotesi nulla che le medie delle due popolazioni siano uguali. Fissiamo un livello di significatività \\(\\alpha = 0.05\\) e otteniamo un valore-\\(p\\) pari a \\(0.04\\). La domanda è: qual è la probabilità che i due campioni provengano da distribuzioni con la stessa media?\nLe opzioni sono:\n(a) \\(19/20\\); (b) \\(1/19\\); (c) \\(1/20\\); (d) \\(95/100\\); (e) sconosciuta.\nLa risposta corretta è: (e) sconosciuta. Questo perché la statistica frequentista calcola le probabilità dei dati condizionatamente alle ipotesi (assunte come vere), ma non permette di determinare la probabilità di un’ipotesi. In altre parole, il valore-\\(p\\) non fornisce informazioni sulla probabilità che l’ipotesi nulla sia vera o falsa; indica solo la probabilità di osservare i dati (o risultati più estremi) assumendo che l’ipotesi nulla sia vera.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "title": "87  Limiti dell’inferenza frequentista",
    "section": "87.6 La crisi della riprodicibilità dei risultati della ricerca",
    "text": "87.6 La crisi della riprodicibilità dei risultati della ricerca\nNegli ultimi anni, la mancanza di replicabilità dei risultati della ricerca – inclusa quella psicologica – è emersa come un tema di grande rilevanza nel dibattito scientifico. In questo contesto, è stato evidenziato che alcuni aspetti del metodo scientifico, in particolare l’uso del valore-\\(p\\) e la pratica del test di significatività dell’ipotesi nulla (NHST, Null Hypothesis Significance Testing), potrebbero contribuire a quella che è stata definita una “crisi della ricerca scientifica”. Un’analisi approfondita di questo problema è stata proposta da Gelman (2016), il quale sostiene che la NHST sia intrinsecamente problematica. Questo approccio, infatti, spinge i ricercatori a cercare di rigettare un’ipotesi “fantoccio” (straw-man), spesso già falsa a priori o di scarso interesse scientifico, a favore di un’ipotesi alternativa che il ricercatore preferisce. In generale, è più ragionevole affermare che la differenza tra due condizioni sia molto piccola piuttosto che esattamente uguale a zero, ma la NHST non è progettata per cogliere questa sfumatura.\nNei libri di statistica, la NHST viene spesso presentata come una sorta di “alchimia” che trasforma la casualità in una falsa certezza, utilizzando termini come “confidenza” e “significatività” (Gelman, 2016). Il processo di raccolta dei dati, analisi e inferenza statistica viene sintetizzato in una conclusione espressa in termini di valore-\\(p\\) e intervalli di confidenza che escludono lo zero. Tuttavia, questo può creare l’impressione errata che il ricercatore abbia una comprensione completa del fenomeno studiato. Il problema principale della NHST è che spesso produce risultati “statisticamente significativi” in contesti in cui le caratteristiche del fenomeno non giustificano le conclusioni tratte. Questo può portare a una bassa replicabilità dei risultati, contribuendo alla crisi di fiducia nella ricerca.\nLa comunità statistica ha sottolineato come la non replicabilità sia particolarmente evidente quando i ricercatori, utilizzando la NHST, traggono conclusioni errate basate su piccoli campioni ed effetti di dimensioni ridotte. Queste condizioni, insieme ad altre, rendono l’applicazione della NHST estremamente problematica. Purtroppo, queste situazioni descrivono molte delle ricerche recenti in psicologia, un campo in cui gli effetti sono spesso modesti e i campioni limitati.\nLa statistica è stata definita come un metodo per prendere decisioni razionali in condizioni di incertezza. Gli statistici raccomandano ai ricercatori non solo di padroneggiare le tecniche statistiche, ma anche di imparare a convivere con l’incertezza, nonostante la crescente sofisticazione degli strumenti disponibili. Conviverci significa evitare di pensare che ottenere un valore-\\(p\\) “statisticamente significativo” equivalga a risolvere un problema scientifico. Ma allora, come possiamo avere fiducia in ciò che apprendiamo dai dati? Una possibile strategia è la replicazione e la convalida esterna dei risultati, sebbene nella ricerca psicologica e nelle scienze sociali questo sia spesso difficile da realizzare a causa degli elevati costi e delle complessità pratiche. Il problema di quali strumenti metodologici e metodi statistici siano più adatti per indagare i fenomeni psicologici, senza cadere in errori di interpretazione, rimane quindi una questione aperta e di cruciale importanza.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "title": "87  Limiti dell’inferenza frequentista",
    "section": "87.7 Commenti e considerazioni finali",
    "text": "87.7 Commenti e considerazioni finali\nNon possiamo concludere senza affrontare la controversia che circonda il concetto di valore-\\(p\\). Nonostante sia ancora ampiamente utilizzato e spesso interpretato in modo errato, il valore-\\(p\\) conferisce solo una parvenza di legittimità a risultati dubbi, incoraggia cattive pratiche di ricerca e favorisce la produzione di falsi positivi. Inoltre, il suo significato è spesso frainteso, persino dagli esperti: quando chiamati a definire il valore-\\(p\\), molti forniscono risposte imprecise o sbagliate. Ciò che i ricercatori desiderano sapere è se i risultati di uno studio siano corretti o meno, ma il valore-\\(p\\) non fornisce questa informazione. Non dice nulla sulla dimensione dell’effetto, sulla forza dell’evidenza o sulla probabilità che il risultato sia frutto del caso. Allora, qual è il suo vero significato? Stuart Buck lo spiega in modo efficace:\n\nImmaginate di avere una moneta che sospettate sia truccata a favore della testa (l’ipotesi nulla è che la moneta sia equa). La lanciate 100 volte e ottenete più teste che croci. Il valore-\\(p\\) non vi dirà se la moneta è equa, ma vi indicherà la probabilità di ottenere almeno lo stesso numero di teste osservato se la moneta fosse equa. Questo è tutto – niente di più.\n\nIn sintesi, il valore-\\(p\\) risponde a una domanda molto specifica che, tuttavia, non ha alcuna rilevanza diretta per la validità scientifica dei risultati di una ricerca. In un’epoca in cui la crisi della riproducibilità dei risultati è sempre più evidente (Baker, 2016), il test dell’ipotesi nulla e gli intervalli di confidenza frequentisti sono stati identificati come una delle principali cause del problema. Questo ha spinto molti ricercatori a cercare alternative metodologiche più robuste e informative, in grado di superare i limiti intrinseci del valore-\\(p\\) e di promuovere una scienza più affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "title": "87  Limiti dell’inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nBorel, E. (1914). Introduction Géométrique. G. Villars, New York.\n\n\nGelman, A. (2016). Commentary on «Crisis in Science? Or Crisis in Statistics! Mixed Messages in Statistics with Impact on Science». Journal of Statistical Research, 48-50(1), 11–12.\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nNuzzo, R. (2014). Statistical Errors. Nature, 506(7487), 150–152.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html",
    "href": "chapters/replication_crisis/03_effect_size.html",
    "title": "88  La grandezza dell’effetto",
    "section": "",
    "text": "88.1 Introduzione\nLa dimensione dell’effetto (effect size) è un concetto chiave nella metodologia della ricerca, utilizzato per quantificare la forza della relazione statistica tra due variabili. Questa misura standardizzata descrive l’entità di un effetto, come quello di un intervento o di un trattamento, fornendo una valutazione quantitativa dell’importanza di un fenomeno osservato.\nÈ essenziale distinguere tra dimensione dell’effetto e significatività statistica. Un risultato può essere “statisticamente significativo” anche se l’effetto è di piccole dimensioni, e viceversa. La conoscenza di uno di questi aspetti non fornisce automaticamente informazioni sull’altro, evidenziando la necessità di considerare entrambi nell’analisi dei dati.\nL’importanza della dimensione dell’effetto è ampiamente riconosciuta nel mondo della ricerca scientifica. Il manuale dell’American Psychological Association (APA) del 2010 ne sottolinea la rilevanza, raccomandando di includere questa misura negli studi pubblicati. Di conseguenza, la maggior parte degli articoli nelle riviste associate all’APA riporta la dimensione dell’effetto, solitamente indicata tra parentesi accanto al valore-\\(p\\).\nNonostante la sua importanza e la prassi di riportarla, la psicologia scientifica spesso mostra una carenza nella corretta valutazione e interpretazione delle dimensioni dell’effetto. Molti ricercatori si limitano a comunicare questi valori senza analizzarli in profondità, portando a conclusioni che possono risultare superficiali, poco informative, fuorvianti o addirittura errate. Questa tendenza riflette una sottovalutazione sistematica e una diffusa incomprensione del concetto di dimensione dell’effetto, persino tra i professionisti della ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "href": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "title": "88  La grandezza dell’effetto",
    "section": "88.2 Misurazione dell’Effetto: Approcci e Applicazioni",
    "text": "88.2 Misurazione dell’Effetto: Approcci e Applicazioni\nTra le metriche più utilizzate per quantificare l’effetto di un trattamento o di una differenza tra gruppi troviamo il \\(d\\) di Cohen e l’\\(r\\) di Pearson. Il \\(d\\) di Cohen è particolarmente utile per descrivere le differenze tra le medie di due gruppi sperimentali, esprimendo tale differenza in termini di deviazione standard aggregata.\nLa differenza standardizzata tra le medie di due gruppi può essere calcolata con la seguente formula (equazione 5.1, Glass et al., 1981):\n\\[\nd_p = \\frac{M_1 - M_2}{S_p},\n\\]\ndove:\n\n\\(M_1\\) e \\(M_2\\) sono le medie dei due gruppi,\n\\(S_p\\) è la deviazione standard combinata.\n\nUn valore positivo di \\(d_p\\) indica che la media del gruppo 1 è maggiore di quella del gruppo 2. La deviazione standard combinata \\(S_p\\) è calcolata come la radice quadrata della varianza media ponderata per i gradi di libertà (\\(df = n-1\\)) dei due gruppi (pp. 108, Glass et al., 1981):\n\\[\nS_p = \\sqrt{\\frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}},\n\\]\ndove:\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei due gruppi,\n\\(S_1^2\\) e \\(S_2^2\\) sono le varianze (quadrato della deviazione standard) dei due gruppi.\n\nIl \\(d_p\\) di Cohen è strettamente correlato alla statistica \\(t\\) di un test \\(t\\) per campioni indipendenti. Infatti, è possibile calcolare \\(d_p\\) a partire dalla statistica \\(t\\) utilizzando la seguente formula (equazione 5.3, Glass et al., 1981):\n\\[\nd = t \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}.\n\\]\nL’errore standard di \\(d_p\\) è dato da:\n\\[\nSE_{d_p} = \\sqrt{\\frac{n_1 + n_2}{n_1 n_2} + \\frac{d_p^2}{2(n_1 + n_2)}}.\n\\]\nD’altra parte, la statistica \\(r\\) di Pearson misura il grado di correlazione lineare tra due variabili, indicando quanto una variabile possa predire l’altra. È interessante notare che queste due misure, \\(d\\) e \\(r\\), possono essere convertite l’una nell’altra attraverso la relazione:\n\\[\nd = \\frac{2r}{\\sqrt{1-r^2}}.\n\\]\nQuesta conversione permette di passare da una misura di differenza tra medie a una misura di correlazione, offrendo una maggiore flessibilità nell’interpretazione dei risultati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#interpretazione-della-dimensione-delleffetto",
    "href": "chapters/replication_crisis/03_effect_size.html#interpretazione-della-dimensione-delleffetto",
    "title": "88  La grandezza dell’effetto",
    "section": "88.3 Interpretazione della Dimensione dell’Effetto",
    "text": "88.3 Interpretazione della Dimensione dell’Effetto\nL’interpretazione della dimensione dell’effetto è un aspetto cruciale nell’analisi statistica, ma spesso viene affrontata in modi che possono risultare privi di significato o addirittura fuorvianti. Di seguito, esploriamo due approcci comuni e le loro criticità.\n\n88.3.1 Gli Standard di Cohen\nUno dei metodi più diffusi per interpretare la dimensione dell’effetto si basa sugli standard proposti da Jacob Cohen (1977, 1988). Cohen ha suggerito delle soglie arbitrarie per classificare l’effetto:\n\nr = 0.10 → effetto piccolo,\nr = 0.30 → effetto medio,\nr = 0.50 → effetto grande.\n\nTuttavia, come sottolineato da Funder (2019), queste soglie sono spesso utilizzate in modo acritico, senza considerare il contesto specifico. Lo stesso Cohen ha espresso rammarico per aver introdotto queste categorie, precisando che dovrebbero essere adottate solo in assenza di criteri più solidi.\nLe etichette “piccolo”, “medio” e “grande” sono prive di significato se non vengono contestualizzate. Per un’interpretazione corretta, è essenziale porsi due domande fondamentali:\n\nRispetto a cosa? Cosa rappresenta un effetto piccolo, medio o grande nel contesto specifico dello studio?\nA quale scopo? Qual è l’impatto pratico o teorico dell’effetto osservato?\n\nSenza rispondere a queste domande, l’uso degli standard di Cohen rischia di essere poco informativo o addirittura ingannevole.\n\n\n88.3.2 Elevare al Quadrato la Correlazione\nUn altro approccio comune, ma altrettanto problematico, consiste nell’elevare al quadrato il coefficiente di correlazione \\(r\\) per ottenere \\(r^2\\), interpretato come la “proporzione di varianza spiegata”. Ad esempio, una correlazione \\(r = 0.30\\) corrisponde a \\(r^2 = 0.09\\), spesso descritto come “solo il 9% della varianza spiegata”.\nTuttavia, come evidenziato da Funder & Ozer (2019), questa pratica è criticabile per due motivi principali:\n\nMancanza di interpretabilità: Mentre \\(r\\) rappresenta la pendenza di una regressione standardizzata, \\(r^2\\) è molto meno intuitivo, poiché riflette solo la proporzione di varianza condivisa tra due variabili.\nPotenziale fuorviante: Elevare al quadrato \\(r\\) può distorcere la percezione dell’effetto. Ad esempio, una correlazione \\(r = 0.30\\) (effetto medio secondo Cohen) diventa \\(r^2 = 0.09\\), che sembra trascurabile, ma in realtà potrebbe avere un impatto significativo nel contesto applicativo.\n\nUn esempio chiaro è fornito da Darlington (1990). Consideriamo un gioco in cui si lanciano due monete: un nickel (5¢) e un dime (10¢). Se esce testa, si vincono rispettivamente 5¢ o 10¢. Le correlazioni tra il valore delle monete e il pagamento sono:\n\nNickel: \\(r = 0.4472\\) (\\(r^2 = 0.20\\)),\nDime: \\(r = 0.8944\\) (\\(r^2 = 0.80\\)).\n\nSe interpretassimo \\(r^2\\) in modo letterale, potremmo erroneamente concludere che il dime “conta quattro volte più” del nickel. Tuttavia, le correlazioni originali mostrano che \\(0.8944\\) è esattamente il doppio di \\(0.4472\\), offrendo un confronto più accurato e informativo.\nIn sintesi, l’interpretazione della dimensione dell’effetto richiede cautela e contestualizzazione. Gli standard di Cohen, sebbene ampiamente utilizzati, sono arbitrari e possono essere fuorvianti se applicati in modo acritico. Allo stesso modo, elevare al quadrato la correlazione \\(r\\) per ottenere \\(r^2\\) rischia di distorcere la percezione dell’effetto, rendendolo meno interpretabile e potenzialmente fuorviante. Per un’analisi robusta, è essenziale considerare il contesto e l’impatto pratico dell’effetto osservato, evitando di affidarsi esclusivamente a metriche standardizzate o trasformazioni matematiche poco informative.\n\n\n88.3.3 Alternative migliori\nÈ cruciale interpretare le dimensioni degli effetti in modo che ne arricchisca il significato. Funder & Ozer (2019) propongono due strategie principali: l’adozione di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\nUtilizzare criteri di riferimento significa confrontare l’entità di un risultato con quella di risultati ben noti e ampiamente compresi. Simile al modo in cui giudichiamo l’altezza di una persona basandoci su confronti con altri, i ricercatori possono ottenere una percezione accurata dell’importanza di un risultato confrontandolo con la dimensione di effetti noti, sia quelli tipici del campo di studio sia quelli emersi da ricerche passate.\nUn approccio al benchmarking può includere l’analisi di risultati considerati “classici” nel campo di interesse o la considerazione di dimensioni dell’effetto per risultati che hanno ottenuto un solido consenso nella comunità psicologica.\nIn un’ottica più ampia, alcuni ricercatori hanno proposto benchmark per la dimensione dell’effetto calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha esaminato 708 correlazioni ottenute meta-analiticamente, rivelando che la dimensione media dell’effetto \\(r\\) era di .19.\nLa conoscenza comune o i risultati di ricerche non psicologiche possono offrire benchmark per valutare la forza di una relazione tra variabili. Un esempio è l’efficacia degli antistaminici contro il comune raffreddore, che corrisponde a un \\(r\\) di .11, mentre l’effetto degli anti-infiammatori non steroidei (come l’ibuprofene) sul dolore è di \\(r = .14\\).\n\nTali confronti illustrano come l’interpretazione delle dimensioni dell’effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili, sia dentro che fuori il campo della psicologia. Questo metodo consente di inserire i risultati di nuove ricerche in un contesto più vasto, favorendo una valutazione più consapevole della loro rilevanza relativa.\n\n\n88.3.4 Alternative Migliori per Interpretare la Dimensione dell’Effetto\nPer arricchire il significato delle dimensioni dell’effetto, è essenziale adottare approcci che vadano oltre le metriche standardizzate e si basino su criteri di riferimento concreti e contestualizzati. Funder & Ozer (2019) propone due strategie principali: l’uso di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\n88.3.4.1 1. Utilizzare Criteri di Riferimento (Benchmark)\nUn modo efficace per interpretare la dimensione dell’effetto è confrontarla con risultati ben noti e ampiamente compresi, sia all’interno del campo di studio che in contesti più generali. Questo approccio è simile a come giudichiamo l’altezza di una persona confrontandola con quella di altre persone.\n\nConfronto con Risultati Classici: I ricercatori possono ottenere una percezione più accurata dell’importanza di un risultato confrontandolo con dimensioni dell’effetto di studi considerati “classici” nel proprio campo. Ad esempio, in psicologia, è possibile fare riferimento a risultati che hanno ottenuto un solido consenso nella comunità scientifica.\nMedie da Meta-Analisi: Alcuni ricercatori hanno proposto benchmark calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha analizzato 708 correlazioni ottenute meta-analiticamente, rilevando che la dimensione media dell’effetto \\(r\\) era di 0.19. Questo valore può servire come punto di riferimento per valutare l’entità di nuovi risultati.\nEsempi Trasversali: Anche conoscenze comuni o risultati di ricerche non psicologiche possono offrire benchmark utili. Ad esempio:\n\nL’efficacia degli antistaminici contro il comune raffreddore corrisponde a un \\(r = 0.11\\).\nL’effetto degli anti-infiammatori non steroidei (come l’ibuprofene) sul dolore è pari a \\(r = 0.14\\).\n\n\nQuesti confronti mostrano come l’interpretazione della dimensione dell’effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili.\n\n\n88.3.4.2 2. Valutare le Implicazioni Pratiche\nOltre ai benchmark, è fondamentale considerare le implicazioni pratiche dei risultati. Un effetto statisticamente piccolo può avere un impatto significativo se applicato a un contesto reale. Ad esempio:\n\nUn \\(r = 0.10\\) potrebbe sembrare trascurabile, ma se tradotto in un intervento su larga scala (ad esempio, un programma educativo o una politica sanitaria), potrebbe portare a benefici tangibili per un gran numero di persone.\n\nIn conclusione, l’interpretazione della dimensione dell’effetto può essere notevolmente migliorata attraverso l’uso di benchmark e la valutazione delle implicazioni pratiche. Confrontare i risultati con studi classici, medie di meta-analisi o esempi tratti da altri campi consente di inserire i nuovi risultati in un contesto più ampio e significativo. Questo approccio non solo arricchisce l’interpretazione, ma favorisce anche una valutazione più consapevole della rilevanza e dell’impatto delle scoperte scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/03_effect_size.html#riflessioni-conclusive",
    "title": "88  La grandezza dell’effetto",
    "section": "88.4 Riflessioni Conclusive",
    "text": "88.4 Riflessioni Conclusive\nLa sovrastima della grandezza degli effetti in psicologia rappresenta un problema diffuso e significativo. Un principio spesso enfatizzato nella psicologia sociale e nell’economia comportamentale, specialmente nei media e nei corsi di business, è che piccoli interventi, o “nudge” (spinte gentili), possano produrre effetti sorprendentemente ampi sul comportamento. Questa idea ha portato a numerose affermazioni sensazionalistiche, come l’ipotesi che le elezioni possano essere influenzate dall’esito di partite di football o che stimoli subliminali, come una faccina sorridente, possano generare cambiamenti drastici negli atteggiamenti verso temi complessi come l’immigrazione.\nAlla base di queste affermazioni c’è un modello di mondo che non si limita al concetto di “effetto farfalla” (dove piccoli cambiamenti possono avere conseguenze imprevedibili e amplificate), ma suggerisce che piccoli interventi possano produrre effetti grandi e prevedibili. Questo approccio, talvolta definito “modello a pulsante” delle scienze sociali, presuppone che, facendo X, si possa aspettarsi di osservare Y in modo sistematico. Tuttavia, questa visione presenta diverse criticità:\n\n88.4.1 Problemi del Modello “a Pulsante”\n\nSovrastima degli effetti: Molti studi riportano effetti esagerati per interventi minimi, che spesso non vengono replicati in ricerche successive. Questo solleva dubbi sulla validità e sull’affidabilità di tali risultati.\nMancanza di considerazione delle interazioni: Se esistessero davvero molti effetti grandi e prevedibili, questi interferirebbero tra loro, rendendo difficile osservare risultati coerenti nei dati reali. La complessità del comportamento umano raramente si presta a relazioni lineari e isolate.\nInstabilità del sistema: Un sistema sociale caratterizzato da molti effetti grandi e prevedibili sarebbe intrinsecamente instabile e difficile da studiare, contraddicendo l’osservazione che le società tendono a mostrare una certa stabilità nel tempo.\nGeneralizzazione eccessiva: Spesso i risultati ottenuti in contesti di laboratorio altamente controllati vengono estesi a situazioni reali molto più complesse, senza considerare le differenze contestuali.\nBias di pubblicazione: Gli studi che riportano effetti grandi e statisticamente significativi hanno maggiori probabilità di essere pubblicati, creando una rappresentazione distorta della realtà e alimentando un ciclo di sovrastima.\n\n\n\n88.4.2 Verso un Approccio più Cauto e Sfumato\nNonostante queste criticità, è importante riconoscere che la psicologia ha identificato molti fenomeni robusti, specialmente in aree come la psicologia clinica e la psicologia della percezione. Tuttavia, è fondamentale adottare un approccio più cauto e riflessivo nell’interpretazione e nella comunicazione dei risultati della ricerca.\nLa consapevolezza di questi problemi ha portato a una serie di miglioramenti metodologici, tra cui:\n\nEnfasi sulla replicabilità: Maggiore attenzione alla riproducibilità degli studi per garantire che i risultati siano affidabili.\nUso di campioni più ampi: Studi condotti su campioni più grandi e diversificati per aumentare la validità esterna.\nMetodi statistici più robusti: Adozione di tecniche statistiche avanzate per ridurre il rischio di falsi positivi.\nApproccio critico e riflessivo: La comunità scientifica sta diventando sempre più consapevole della necessità di evitare semplificazioni eccessive e di riconoscere la complessità dei fenomeni psicologici.\n\nIn sintesi, mentre la psicologia offre intuizioni preziose sul comportamento umano, è essenziale mantenere un sano scetticismo verso affermazioni di effetti grandi e facilmente ottenibili. La realtà è spesso più complessa e sfumata di quanto suggerito da titoli sensazionalistici o da singoli studi. Un approccio equilibrato, che combina rigore metodologico, contestualizzazione e umiltà scientifica, è fondamentale per avanzare nella comprensione dei fenomeni psicologici e per evitare di cadere in trappole interpretative che possono distorcere la nostra visione del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "href": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "title": "88  La grandezza dell’effetto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFunder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: Sense and nonsense. Advances in Methods and Practices in Psychological Science, 2(2), 156–168.\n\n\nGlass, G. V., McGaw, B., & Smith, M. L. (1981). Meta-analysis in Social Research. Sage Publications.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html",
    "href": "chapters/replication_crisis/04_s_m_errors.html",
    "title": "89  Errori di segno e errori di grandezza",
    "section": "",
    "text": "89.1 Introduzione\nIn questo capitolo analizzeremo la relazione tra la crisi della replicabilità e le procedure decisionali statistiche proprie dell’approccio frequentista. In particolare, approfondiremo gli errori di tipo M (magnitude) e di tipo S (sign), discussi da Loken & Gelman (2017), e il loro impatto sulla validità dei risultati scientifici.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#introduzione",
    "href": "chapters/replication_crisis/04_s_m_errors.html#introduzione",
    "title": "89  Errori di segno e errori di grandezza",
    "section": "",
    "text": "Domande Iniziali\n\n\n\nPrima di esplorare le simulazioni e i risultati discussi in questo capitolo, prova a riflettere sulle seguenti domande. Ti invitiamo a formulare delle ipotesi sui risultati delle simulazioni prima di leggere le spiegazioni:\n\nSe si effettuano molteplici studi su un effetto molto piccolo utilizzando campioni di dimensioni ridotte, cosa pensi che accadrà ai risultati pubblicati che ottengono significatività statistica? Saranno accurati rispetto alla vera grandezza dell’effetto?\nIn uno scenario in cui non esiste alcuna differenza tra due gruppi, quanto spesso credi che un test t fornisca un risultato statisticamente significativo che verrà pubblicato? Quali fattori potrebbero influenzare questa probabilità?\nSupponiamo che in una serie di esperimenti alcuni studi trovino effetti significativi e altri no. Quale pensi sia la tendenza degli studi pubblicati rispetto a quelli non pubblicati? Quale impatto può avere questa tendenza sulla percezione della realtà scientifica?\nSe dovessi valutare la replicabilità di uno studio basato sulla significatività statistica, quali problemi potresti incontrare se l’effetto sottostante è molto piccolo?\n\nTieni a mente le tue risposte mentre esplori le simulazioni presentate in questo capitolo. Alla fine del capitolo, confronteremo le previsioni con i risultati effettivi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "href": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "title": "89  Errori di segno e errori di grandezza",
    "section": "\n89.2 Il Filtro della Significatività Statistica",
    "text": "89.2 Il Filtro della Significatività Statistica\nNel ?sec-crisis abbiamo esplorato come la pratica scientifica contemporanea sia spesso compromessa da casi di frode, principalmente a causa delle significative implicazioni economiche legate alla pubblicazione su riviste scientifiche di alto prestigio. Questo fenomeno è spesso sottovalutato, poiché le riviste tendono a essere riluttanti nel riconoscere la necessità di correzioni o ritrattazioni degli articoli già pubblicati.\nLa frode scientifica rappresenta una minaccia evidente alla riproducibilità dei risultati, un pilastro fondamentale del metodo scientifico. Tuttavia, le difficoltà nel replicare i risultati pubblicati non sono attribuibili esclusivamente a frodi o a “pratiche di ricerca disoneste” (Nelson et al., 2018). Un problema intrinseco risiede nel metodo statistico ampiamente adottato dai ricercatori: l’approccio del test di ipotesi nulla e della significatività statistica di stampo fisheriano. Secondo questo metodo, i risultati che non raggiungono la soglia di “significatività statistica” vengono scartati, mentre quelli che la superano sono considerati credibili, basandosi esclusivamente su questo criterio (Wagenmakers et al., 2008).\nTuttavia, l’idea che la significatività statistica sia un filtro affidabile per distinguere i risultati di ricerca “validi” da quelli “non validi” è fondamentalmente errata. Numerose evidenze dimostrano i limiti di questo approccio. Per approfondire questa problematica, esamineremo lo studio di Loken & Gelman (2017), che mette in luce la relazione tra la crisi della replicabilità e le procedure decisionali statistiche dell’approccio frequentista.\nUno dei principali problemi evidenziati da Loken & Gelman (2017) è che, in contesti di ricerca complessi, la significatività statistica fornisce prove molto deboli riguardo al segno (sign) o all’entità (magnitude) degli effetti sottostanti. In altre parole, il raggiungimento della significatività statistica non garantisce né la rilevanza né la consistenza dei risultati ottenuti. Questo solleva seri dubbi sull’affidabilità di tale criterio come unico strumento per valutare la validità delle scoperte scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "href": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "title": "89  Errori di segno e errori di grandezza",
    "section": "\n89.3 Errori di tipo M e S\n",
    "text": "89.3 Errori di tipo M e S\n\nPer illustrare le implicazioni del processo decisionale basato sulla significatività statistica, Loken & Gelman (2017) hanno condotto una simulazione. In questa simulazione, hanno considerato uno scenario di ricerca ipotetico in cui era presente un effetto reale, sebbene molto debole, difficilmente rilevabile senza un ampio volume di dati. Utilizzando l’approccio frequentista, hanno cercato di identificare questo effetto valutando la significatività statistica.\nI risultati della simulazione hanno mostrato che, anche in presenza di un effetto reale (seppur debole), l’approccio frequentista riusciva a rilevare un effetto statisticamente significativo solo in una piccola percentuale dei casi. Inoltre, quando un effetto significativo veniva individuato, la stima della sua grandezza risultava altamente imprecisa e instabile.\nIn sintesi, la significatività statistica fornisce un’indicazione generica sulla presenza o assenza di un effetto, ma non offre informazioni affidabili sulla sua entità o replicabilità. Questo problema è particolarmente rilevante in campi come la psicologia e le scienze sociali, dove gli studi spesso si basano su campioni di dimensioni ridotte e gli effetti osservati tendono a essere modesti. In tali contesti, l’approccio frequentista rischia di produrre prove deboli e instabili, compromettendo la replicabilità e l’affidabilità dei risultati.\n\n89.3.1 Simulazione semplificata\nRiproduciamo qui, in forma semplificata, la simulazione condotta da Loken & Gelman (2017). Iniziamo importando le librerie necessarie.\nConsideriamo due campioni casuali indipendenti di dimensioni \\(n_1 = 20\\) e \\(n_2 = 25\\), estratti rispettivamente dalle distribuzioni normali \\(\\mathcal{N}(102, 10)\\) e \\(\\mathcal{N}(100, 10)\\). La dimensione effettiva dell’effetto (\\(d\\)) per la differenza tra le medie dei due campioni è calcolata utilizzando la formula:\n\\[\nd = \\frac{\\bar{y}_1 - \\bar{y}_2}{s_p},\n\\]\ndove \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) rappresentano le medie campionarie dei due gruppi, e \\(s_p\\) è la deviazione standard combinata, definita come:\n\\[\ns_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}.\n\\]\nIn questo caso specifico, la dimensione effettiva dell’effetto risulta molto piccola, indicando che la differenza osservata tra le medie dei due gruppi non ha una rilevanza pratica significativa. Ciò suggerisce che la distinzione tra i due gruppi, seppur statisticamente rilevabile, non ha un impatto sostanziale in contesti reali.\n\n# Parametri\nmu_1 &lt;- 102  # Media del primo gruppo\nmu_2 &lt;- 100  # Media del secondo gruppo\nsigma &lt;- 10  # Deviazione standard comune\nn1 &lt;- 20     # Numero di osservazioni nel primo gruppo\nn2 &lt;- 25     # Numero di osservazioni nel secondo gruppo\n\n# Calcolo della differenza media\nmean_difference &lt;- abs(mu_1 - mu_2)\n\n# Calcolo della deviazione standard pooled\npooled_sd &lt;- sqrt(((n1 - 1) * sigma^2 + (n2 - 1) * sigma^2) / (n1 + n2 - 2))\n\n# Calcolo di Cohen's d\ncohen_d &lt;- mean_difference / pooled_sd\n\n# Output del risultato\ncat(\"Dimensione dell'effetto (Cohen's d):\", cohen_d, \"\\n\")\n#&gt; Dimensione dell'effetto (Cohen's d): 0.2\n\nEsaminiamo ora le conclusioni che emergerebbero applicando l’approccio frequentista e la sua procedura di decisione statistica in questo contesto. Supponiamo di condurre una simulazione in cui vengono estratti due campioni: il primo composto da 20 osservazioni provenienti dalla prima popolazione e il secondo da 25 osservazioni provenienti dalla seconda popolazione. Successivamente, applichiamo il test \\(t\\) di Student per confrontare le medie dei due gruppi.\nNell’ambito dell’approccio frequentista, il valore-\\(p\\) ottenuto dal test determina la decisione statistica. Se il valore-\\(p\\) è superiore a 0.05, i risultati vengono considerati non significativi e, di conseguenza, scartati. Al contrario, se il valore-\\(p\\) è inferiore a 0.05, il risultato è ritenuto “pubblicabile” e si conclude che esiste una differenza statisticamente significativa tra i due gruppi.\nPer valutare in modo approfondito le conclusioni derivate da questa procedura, è necessario ripetere l’intero processo per un numero elevato di iterazioni, ad esempio 50.000 volte. Ciò significa che, in ciascuna iterazione, vengono estratti nuovi campioni, viene calcolato il test \\(t\\) di Student e viene determinato il corrispondente valore-\\(p\\). Ripetendo questo processo su larga scala, è possibile ottenere una distribuzione completa dei risultati, che consente di analizzare la frequenza con cui si ottengono risultati significativi e la stabilità delle stime prodotte dall’approccio frequentista in questo contesto.\n\n# Parametri\nn_samples &lt;- 50000\nmu_1 &lt;- 102\nmu_2 &lt;- 100\nsigma &lt;- 10\nn1 &lt;- 20\nn2 &lt;- 25\n\n# Inizializzazione del risultato\nres &lt;- c()\n\n# Simulazioni\nset.seed(123)  # Per la riproducibilità\nfor (i in 1:n_samples) {\n  # Generazione dei campioni casuali\n  y1 &lt;- rnorm(n1, mean = mu_1, sd = sigma)\n  y2 &lt;- rnorm(n2, mean = mu_2, sd = sigma)\n  \n  # Calcolo della dimensione dell'effetto\n  y1bar &lt;- mean(y1)\n  y2bar &lt;- mean(y2)\n  v1 &lt;- var(y1)\n  v2 &lt;- var(y2)\n  s &lt;- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2) / (n1 + n2 - 2))\n  efsize &lt;- (y1bar - y2bar) / s\n  \n  # Calcolo del valore p\n  t_test &lt;- t.test(y1, y2, var.equal = TRUE)\n  \n  # Salvataggio della dimensione dell'effetto solo per risultati \"statisticamente significativi\"\n  if (t_test$p.value &lt; 0.05) {\n    res &lt;- c(res, efsize)\n  }\n}\n\n\nres_df &lt;- data.frame(effect_size = res)\n\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 20, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(\n    xintercept = 0.2, color = \"red\", linetype = \"dashed\", \n    size = 1.2, label = \"True Effect Size\") +\n  labs(\n    x = \"Effect Size\",\n    y = \"Frequency\",\n    title = \"Histogram of Effect Sizes for\\n'Statistically Significant' Results\"\n  ) \n\n\n\n\n\n\n\nCome evidenziato da Loken & Gelman (2017), l’applicazione dell’approccio frequentista nella procedura di decisione statistica può condurre a due tipi di errori rilevanti. Il primo, noto come errore di magnitude (grandezza), si manifesta quando i risultati pubblicati tendono a sovrastimare la reale entità dell’effetto. Nella simulazione condotta, nonostante la vera grandezza dell’effetto fosse modesta (0.2), la media della grandezza dell’effetto per i risultati classificati come “statisticamente significativi” era circa 0.8, suggerendo un effetto di entità “ampia”. Questo indica una distorsione sistematica verso stime esagerate.\nIl secondo errore, chiamato errore di segno, si verifica quando, a causa della variabilità campionaria, la direzione dell’effetto viene stimata in modo errato. In tali casi, il ricercatore potrebbe erroneamente concludere che \\(\\mu_2 &gt; \\mu_1\\), quando in realtà non è così. È importante sottolineare che, anche in queste situazioni, la grandezza assoluta dell’effetto risulta sovrastimata.\nUn aspetto degno di nota è che queste conclusioni rimarrebbero valide anche se si considerasse l’intervallo di confidenza per la differenza tra le medie. In sintesi, l’approccio frequentista introduce un errore sistematico nella stima della grandezza dell’effetto, che rappresenta la quantità più rilevante per il ricercatore. In alcuni casi, può persino portare a errori nella determinazione della direzione dell’effetto, compromettendo ulteriormente l’affidabilità delle conclusioni scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "title": "89  Errori di segno e errori di grandezza",
    "section": "\n89.4 Riflessioni Conclusive",
    "text": "89.4 Riflessioni Conclusive\nIn conclusione, l’approccio frequentista non rappresenta un metodo affidabile per valutare i risultati della ricerca e determinarne l’attendibilità o la necessità di scartarli (Gelman & Carlin, 2014; Loken & Gelman, 2017). Questa mancanza di affidabilità è dovuta all’introduzione di errori sistematici nella stima della grandezza degli effetti, che in alcuni casi possono persino portare a errori nella direzione dell’effetto stesso. Alla luce di queste criticità, non sembrano esserci motivi validi per continuare a fare affidamento su questo approccio.\nAl contrario, l’adozione dell’approccio bayesiano sembra offrire una soluzione più precisa e affidabile per l’analisi dei dati di ricerca. Questo metodo valuta la probabilità delle ipotesi alla luce dei dati osservati, evitando gli errori intrinseci dell’approccio frequentista e fornendo una base più solida per prendere decisioni informate sulla validità dei risultati. In questo modo, l’approccio bayesiano si presenta come un’alternativa più robusta e scientificamente rigorosa.\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\n\n\nOra confrontiamo le previsioni con i risultati ottenuti dalle simulazioni:\n\nSovrastima della grandezza dell’effetto: I risultati pubblicati tendono a essere selezionati sulla base della significatività statistica, il che porta a una sovrastima sistematica della grandezza dell’effetto rispetto alla realtà. Questo fenomeno, noto come errore di tipo M (magnitude), si verifica perché solo gli effetti con valori estremi (per caso) superano la soglia di significatività statistica e vengono pubblicati.\nFalsi positivi e loro frequenza: In uno scenario in cui non esiste alcuna differenza tra i due gruppi (cioè la vera differenza è zero), il test t ha fornito risultati statisticamente significativi nel 5% dei casi, come previsto dalla soglia di α = 0.05. Tuttavia, la selezione dei risultati pubblicati amplifica questo problema, rendendo più probabile che i lettori incontrino falsi positivi nella letteratura scientifica.\nBias nella pubblicazione: Gli studi che riportano risultati significativi hanno maggiore probabilità di essere pubblicati rispetto a quelli che non trovano un effetto significativo. Questo porta a un effetto distorsivo nella letteratura scientifica, in cui i risultati pubblicati tendono a sovrastimare l’effetto reale. Il “filtro della significatività statistica” crea una percezione distorta della realtà scientifica, poiché gli effetti nulli o piccoli tendono a essere sottorappresentati nella letteratura.\nReplicabilità e significatività statistica: Gli studi con effetti piccoli e campioni ridotti sono particolarmente vulnerabili al fallimento della replicazione. Anche quando un effetto reale esiste, la probabilità di ottenerne una stima precisa è bassa, e la replicazione potrebbe risultare in un valore non significativo, generando confusione nella comunità scientifica.\n\nConsiderazioni Finali\nLe simulazioni evidenziano come la significatività statistica, utilizzata come criterio per la pubblicazione, contribuisca a un bias nella selezione dei risultati, distorcendo la percezione della realtà scientifica. Questo fenomeno, noto come “filtro della significatività statistica”, è una delle cause principali della crisi della replicabilità, poiché induce i ricercatori e i lettori a sovrastimare la grandezza e la presenza di effetti studiati.\nPer affrontare queste problematiche, approcci alternativi, come quelli bayesiani, possono offrire soluzioni più robuste, permettendo una valutazione più affidabile delle ipotesi alla luce dei dati osservati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "href": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "title": "89  Errori di segno e errori di grandezza",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nPerché la significatività statistica non è un criterio affidabile per valutare la validità dei risultati scientifici?\nSpiega il concetto di “filtro della significatività statistica” e il suo impatto sulla pubblicazione dei risultati.\nQual è la differenza tra errore di tipo M e errore di tipo S? Come influenzano l’interpretazione dei risultati?\nPerché i risultati pubblicati tendono a sovrastimare la grandezza dell’effetto rispetto alla realtà?\nQuali sono le conseguenze della pubblicazione selettiva dei risultati per la replicabilità degli studi?\nPerché gli studi con campioni di piccole dimensioni sono più vulnerabili a errori nella stima della grandezza dell’effetto?\nIn che modo la selezione dei risultati pubblicati altera la percezione della forza degli effetti studiati?\nPerché un test frequentista può portare a una falsa conclusione sulla direzione di un effetto?\nQuali sono le principali differenze tra l’approccio frequentista e quello bayesiano nella valutazione della significatività di un effetto?\nIn che modo l’approccio bayesiano può ridurre il rischio di errori dovuti alla selezione dei risultati basata sulla significatività statistica?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nLa significatività statistica non garantisce la validità di un risultato perché dipende dalla dimensione del campione e da soglie arbitrarie (come p &lt; 0.05). Inoltre, non misura la rilevanza pratica di un effetto, ma solo la probabilità che i dati osservati siano ottenuti sotto l’ipotesi nulla.\nIl “filtro della significatività statistica” si riferisce alla tendenza a pubblicare solo risultati con p &lt; 0.05, tralasciando studi con risultati non significativi. Questo porta a una distorsione nella letteratura scientifica e a una sovrastima della forza degli effetti riportati.\nErrore di tipo M (Magnitude) indica la sovrastima della grandezza dell’effetto nei risultati pubblicati, mentre errore di tipo S (Sign) si riferisce all’errata determinazione della direzione dell’effetto. Questi errori si verificano perché solo gli effetti più estremi tendono a superare il filtro della significatività statistica.\nI risultati pubblicati tendono a sovrastimare la grandezza dell’effetto perché solo gli effetti più grandi (anche per pura casualità) superano la soglia di significatività statistica e vengono pubblicati, mentre quelli più piccoli restano inediti.\nLa pubblicazione selettiva riduce la replicabilità perché introduce una distorsione sistematica nei risultati disponibili. Le repliche spesso non trovano effetti altrettanto grandi o significativi, creando instabilità nella conoscenza scientifica.\nI campioni piccoli aumentano la variabilità delle stime dell’effetto, rendendo più probabile che un risultato significativo sia solo un’oscillazione casuale dei dati piuttosto che un vero effetto replicabile.\nLa selezione dei risultati pubblicati altera la percezione della forza degli effetti perché induce i lettori a credere che gli effetti siano più forti e consistenti di quanto non siano realmente.\nUn test frequentista può portare a una falsa conclusione sulla direzione dell’effetto perché, in campioni piccoli, le stime dell’effetto possono essere fortemente influenzate dal rumore, portando a interpretazioni errate.\nL’approccio frequentista si basa sul valore-p e sulla soglia di significatività, mentre l’approccio bayesiano utilizza la probabilità a posteriori per aggiornare la credibilità delle ipotesi alla luce dei dati osservati. Il metodo bayesiano permette inferenze più flessibili e robuste.\nL’approccio bayesiano riduce il rischio di errori dovuti alla selezione dei risultati perché non si basa su una soglia arbitraria di significatività, ma fornisce un quadro probabilistico della forza dell’effetto, evitando distorsioni dovute alla pubblicazione selettiva.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nIn questo esercizio simuleremo più esperimenti, ognuno con 15 osservazioni, per comprendere come il filtro della significatività statistica possa distorcere le nostre conclusioni sugli effetti osservati.\nObiettivo\n\nComprendere come l’approccio frequentista possa portare a stime errate dell’effetto reale.\nEsplorare gli errori di tipo M (magnitude) e S (sign), derivanti dal filtro della significatività statistica.\n\nStruttura dell’esercizio\n\nSimuliamo esperimenti in cui il vero effetto tra due gruppi è piccolo (Cohen’s d = 0.2). Consideriamo i dati SWLS e due popolazioni che differiscono nel modo indicato. Ipotizziamo che le due popolazioni SWLS siano normali.\nEstraiamo 15 osservazioni per gruppo.\nUsiamo un test t per verificare se la differenza tra i gruppi è significativa.\nRegistriamo solo i risultati con p &lt; 0.05, calcolando la distribuzione degli effetti significativi.\nValutiamo se la stima dell’effetto nei risultati pubblicabili è gonfiata rispetto al vero effetto.\nContiamo i casi in cui il segno dell’effetto è invertito.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n# Librerie necessarie\nlibrary(ggplot2)\n\n# Impostazioni della simulazione\nset.seed(42)         # Per la riproducibilità\nn_sims &lt;- 50000      # Numero di simulazioni\nn_per_group &lt;- 15    # Numero di osservazioni per gruppo\ntrue_d &lt;- 0.2        # Vero effetto (Cohen's d)\nswls_mean &lt;- 25      # Media ipotizzata per il primo gruppo\nswls_sd &lt;- 5         # Deviazione standard ipotizzata per la SWLS\n\n# Calcolo della media del secondo gruppo sulla base di Cohen's d\nswls_mean_2 &lt;- swls_mean + true_d * swls_sd\n\n# Inizializziamo i vettori per registrare i risultati\neffect_sizes &lt;- c()\nfalse_sign_count &lt;- 0\n\n# Simulazioni\nfor (i in 1:n_sims) {\n  # Generazione dei due gruppi da distribuzioni normali\n  group1 &lt;- rnorm(n_per_group, mean = swls_mean, sd = swls_sd)\n  group2 &lt;- rnorm(n_per_group, mean = swls_mean_2, sd = swls_sd)\n  \n  # Calcolo della dimensione dell'effetto (Cohen's d)\n  mean_diff &lt;- mean(group2) - mean(group1)\n  pooled_sd &lt;- sqrt(((n_per_group - 1) * var(group1) + (n_per_group - 1) * var(group2)) / (2 * n_per_group - 2))\n  d_estimated &lt;- mean_diff / pooled_sd\n  \n  # Test t per confrontare le medie\n  t_test &lt;- t.test(group1, group2, var.equal = TRUE)\n  \n  # Consideriamo solo i risultati statisticamente significativi\n  if (t_test$p.value &lt; 0.05) {\n    effect_sizes &lt;- c(effect_sizes, d_estimated)\n    \n    # Conta i casi in cui il segno è invertito\n    if (d_estimated &lt; 0) {\n      false_sign_count &lt;- false_sign_count + 1\n    }\n  }\n}\n\n# Creazione di un dataframe per la visualizzazione\nres_df &lt;- data.frame(effect_size = effect_sizes)\n\n# Istogramma della dimensione dell'effetto tra i risultati \"significativi\"\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 30, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(xintercept = true_d, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  labs(\n    x = \"Dimensione dell'effetto stimata\",\n    y = \"Frequenza\",\n    title = \"Distribuzione degli effetti significativi (SWLS)\"\n  ) +\n  theme_minimal()\n\n# Output di sintesi\ncat(\"Numero di risultati statisticamente significativi:\", length(effect_sizes), \"\\n\")\ncat(\"Media della dimensione dell'effetto tra i risultati pubblicati:\", mean(effect_sizes), \"\\n\")\ncat(\"Numero di risultati con segno invertito:\", false_sign_count, \"\\n\")\ncat(\"Proporzione di risultati con segno invertito:\", false_sign_count / length(effect_sizes), \"\\n\")\nInterpretazione dei Risultati\n\n\nErrore di tipo M (Magnitude): La media degli effetti stimati nei risultati pubblicati sarà molto più grande di 0.2 (il vero effetto), dimostrando come il filtro della significatività tenda a sovrastimare gli effetti reali.\n\nErrore di tipo S (Sign): Una percentuale dei risultati pubblicabili mostrerà effetti nella direzione sbagliata (d &lt; 0), dimostrando che il processo decisionale basato su p &lt; 0.05 può portare a conclusioni errate.\n\nVisualizzazione: L’istogramma mostrerà che la distribuzione degli effetti significativi è spostata rispetto al vero effetto (linea rossa tratteggiata).\n\nDomande di discussione:\n\nPerché la stima dell’effetto è gonfiata nei risultati pubblicabili?\nCome cambia la situazione aumentando il numero di osservazioni per gruppo?\nQuali strategie alternative potrebbero ridurre questi errori?\n\nApprofondimento:\n\nRipetere l’esperimento con n_per_group = 50 e osservare se l’errore di tipo M diminuisce.\nConfrontare questo approccio con un’analisi Bayesiana per evidenziare il ruolo dell’inferenza basata su probabilità posteriori.\n\nConclusione\nQuesto esercizio mostra chiaramente i problemi dell’approccio frequentista basato su p &lt; 0.05, evidenziando i limiti dell’uso della significatività statistica come filtro decisionale.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "title": "89  Errori di segno e errori di grandezza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-3         tensorA_0.36.2.1     \n#&gt;  [7] pacman_0.5.1          digest_0.6.37         timechange_0.3.0     \n#&gt; [10] estimability_1.5.1    lifecycle_1.0.4       survival_3.8-3       \n#&gt; [13] magrittr_2.0.3        compiler_4.5.1        rlang_1.1.6          \n#&gt; [16] tools_4.5.1           yaml_2.3.10           knitr_1.50           \n#&gt; [19] labeling_0.4.3        bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [22] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [25] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [28] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [31] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [34] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [37] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [40] ragg_1.4.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [43] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [46] parallel_4.5.1        vctrs_0.6.5           V8_6.0.6             \n#&gt; [49] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [52] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [55] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [58] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [61] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [64] textshaping_1.0.1     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [67] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [70] broom_1.0.9           snakecase_0.11.1      rstantools_2.4.0     \n#&gt; [73] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [76] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [79] pkgconfig_2.0.3",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "href": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "title": "89  Errori di segno e errori di grandezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNelson, L. D., Simmons, J., & Simonsohn, U. (2018). Psychology’s renaissance. Annual review of psychology, 69(1), 511–534.\n\n\nWagenmakers, E.-J., Lee, M., Lodewyckx, T., & Iverson, G. J. (2008). Bayesian versus frequentist inference. Bayesian evaluation of informative hypotheses, 181–207.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html",
    "href": "chapters/replication_crisis/05_p_values.html",
    "title": "\n90  La fragilità del p-valore\n",
    "section": "",
    "text": "90.1 Introduzione\nQuesto capitolo analizza la fragilità dei valori-\\(p\\) e la loro variabilità in diversi campioni. Attraverso una simulazione, dimostreremo come l’uso dei valori-\\(p\\) come criterio per valutare la rilevanza sostanziale di un risultato costituisca un errore metodologico. L’analisi si basa su un approccio critico ispirato da una discussione proposta da Andrew Gelman nel suo blog.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#simulazione",
    "href": "chapters/replication_crisis/05_p_values.html#simulazione",
    "title": "\n90  La fragilità del p-valore\n",
    "section": "\n90.2 Simulazione",
    "text": "90.2 Simulazione\nQuesta simulazione mira a dimostrare quanto i valori-\\(p\\) possano essere instabili e variare notevolmente da campione a campione, anche quando i dati provengono dalla stessa distribuzione. Ciò evidenzia come il valore-\\(p\\), comunemente utilizzato per valutare la significatività statistica di un effetto, possa essere fortemente influenzato dalla variabilità campionaria, specialmente in campioni di piccole dimensioni o con effetti deboli. Gelman & Stern (2006) esprimono questo concetto affermando che:\n\nLa differenza tra “significativo” e “non significativo” non è di per sé statisticamente significativa.\n\n\n90.2.1 Logica della Simulazione\n\n\nObiettivo:\n\nDimostrare la variabilità dei valori-\\(p\\) calcolati su diversi campioni estratti da una popolazione con una media molto vicina a zero.\nMostrare come, nonostante l’effetto reale sia piccolo, i valori-\\(p\\) possano variare notevolmente a seconda della variabilità della popolazione e delle dimensioni del campione.\n\n\n\nSetup della Simulazione:\n\nGeneriamo \\(J = 10\\) campioni indipendenti, ciascuno con un numero ridotto di osservazioni (\\(n = 10\\)), per massimizzare la variabilità dei risultati.\nOgni campione è generato da una distribuzione normale con una media vera di \\(\\mu = 0.05\\) e una deviazione standard di \\(\\sigma = 0.1\\). Questi parametri sono scelti per rendere la media dei campioni vicina a zero, mantenendo una certa variabilità.\n\n\n\nCalcolo della media campionaria:\n\nPer ciascun campione, calcoliamo la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nLa media del campione (\\(\\hat{\\mu}\\)) è utilizzata come stima del parametro.\n\n\n\nCalcolo del valore-\\(p\\):\n\nApplichiamo un \\(t\\)-test per ciascun campione per verificare l’ipotesi nulla (\\(H_0\\)) che la media del campione sia zero.\n\nIl valore-\\(p\\) viene calcolato utilizzando la formula classica del \\(t\\)-test:\n\\[\nt = \\frac{\\hat{\\mu}}{\\frac{\\hat{\\sigma}}{\\sqrt{n}}}\n\\]\ndove:\n\n\n\\(\\hat{\\mu}\\) è la media del campione,\n\n\\(\\hat{\\sigma}\\) è la deviazione standard del campione,\n\n\\(n\\) è il numero di osservazioni per campione.\n\n\n\nSuccessivamente, il valore-\\(p\\) è calcolato come:\n\\[\n\\text{p-value} = 2 \\times (1 - \\text{CDF}(|t|))\n\\]\ndove \\(\\text{CDF}\\) è la funzione cumulativa della distribuzione \\(t\\) con \\(n-1\\) gradi di libertà.\n\n\n\n\n90.2.2 Descrizione della Sintassi\nIl codice R è strutturato come segue:\n\n\nGenerazione dei campioni:\n\nCreiamo una lista di campioni (10 campioni in totale), ciascuno con 10 osservazioni, utilizzando la distribuzione normale con media 0.05 e deviazione standard 0.1.\n\n\n\nCalcolo delle medie e dei valori-\\(p\\):\n\nIteriamo su ciascun campione per calcolare la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nCalcoliamo il valore statistico \\(t\\) e il corrispondente valore-\\(p\\) utilizzando la distribuzione \\(t\\).\n\n\n\nStampa dei risultati:\n\nI valori-\\(p\\) vengono arrotondati e stampati per osservare la loro variabilità.\n\n\n\n\n# Imposta il seme per riproducibilità\nset.seed(1234)\n\n# Parametri della simulazione\nJ &lt;- 10              # Numero di campioni indipendenti\nn &lt;- 10              # Numero di osservazioni per campione\ntrue_mean &lt;- 0.05    # Media vera della popolazione\ntrue_sd &lt;- 0.1       # Deviazione standard della popolazione\n\n# Genera i campioni casuali\nsamples &lt;- replicate(J, rnorm(n, mean = true_mean, sd = true_sd), simplify = FALSE)\n\n# Calcola statistiche campionarie e p-valori\nresults &lt;- lapply(samples, function(sample) {\n  sample_mean &lt;- mean(sample)                         # Media campionaria\n  sample_sd &lt;- sd(sample)                             # Deviazione standard campionaria\n  t_statistic &lt;- sample_mean / (sample_sd / sqrt(n))  # Statistica t\n  p_value &lt;- 2 * (1 - pt(abs(t_statistic), df = n - 1))  # valore-$p$ bilaterale\n  list(mean = sample_mean, sd = sample_sd, t = t_statistic, p_value = p_value)\n})\n\n# Converti i risultati in un data frame per facilitarne la visualizzazione\nresults_df &lt;- do.call(rbind, lapply(results, as.data.frame))\nrownames(results_df) &lt;- paste(\"C\", 1:J)\n\n# Visualizza i risultati\nprint(results_df)\n#&gt;         mean     sd      t p_value\n#&gt; C 1   0.0117 0.0996  0.371 0.71918\n#&gt; C 2   0.0382 0.1067  1.131 0.28718\n#&gt; C 3   0.0112 0.0666  0.532 0.60758\n#&gt; C 4  -0.0266 0.0894 -0.941 0.37112\n#&gt; C 5  -0.0110 0.0787 -0.441 0.66955\n#&gt; C 6   0.0221 0.1186  0.590 0.56994\n#&gt; C 7   0.1117 0.1144  3.086 0.01301\n#&gt; C 8   0.0458 0.0924  1.567 0.15157\n#&gt; C 9   0.0342 0.0735  1.470 0.17575\n#&gt; C 10  0.1061 0.0984  3.409 0.00776\n\n\nggplot(results_df, aes(x = rownames(results_df), y = p_value)) +\n  geom_point(size = 3, color = \"blue\") +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Variabilità dei p-valori\",\n    x = \"Campioni\",\n    y = \"valore-p\"\n  ) \n\n\n\n\n\n\n\n\n90.2.3 Interpretazione dei Risultati\nIn un tipico esperimento, i risultati potrebbero variare notevolmente tra i diversi campioni analizzati. Alcuni campioni potrebbero essere pienamente compatibili con il rumore statistico, mentre altri potrebbero suggerire lievi evidenze contro l’ipotesi nulla. Altri ancora potrebbero addirittura apparire altamente significativi dal punto di vista statistico.\nTuttavia, la differenza tra ‘statisticamente significativo’ e ‘non significativo’ non sempre corrisponde a una distinzione scientificamente rilevante nel fenomeno studiato. Ad esempio, un valore-\\(p\\) di 0.003 potrebbe sembrare drasticamente diverso da uno di 0.336, ma questa discrepanza, di per sé, non implica un’effettiva differenza sostanziale.\nQuesta situazione estrema emerge quando non esiste alcuna vera variazione sottostante tra i campioni. In tali casi, un modello multilivello rivelerebbe che le apparenti differenze osservate non rappresentano un’effettiva variabilità degna di interesse, ma fluttuazioni casuali intorno a un effetto nullo.\n\n90.2.4 Punti Chiave\n\nIl valore-\\(p\\) descrive solo l’ipotesi nulla: È una misura relativa all’assenza di effetto, ma non ha necessariamente un significato diretto rispetto a un effetto reale, anche se piccolo.\nIl valore-\\(p\\) è altamente variabile: Essendo una trasformazione non lineare dello z-score, il valore-\\(p\\) può comportarsi in modi non intuitivi, soprattutto con campioni piccoli.\nLe simulazioni sono istruttive: Anche esperimenti semplici come questo possono essere estremamente utili per comprendere le limitazioni e l’interpretazione dei risultati.\n\n90.2.5 Un Avvertimento Importante\nAnche le inferenze bayesiane sono soggette a variabilità. Qualsiasi sintesi dei dati porta con sé un certo grado di incertezza. Il problema non risiede nei valori-\\(p\\) in sé, ma nel loro utilizzo scorretto. Interpretare un valore-\\(p\\) come una dichiarazione forte sulla realtà, invece di considerarlo un riassunto rumoroso di un esperimento specifico, è un errore comune.\nAllo stesso modo, fraintendimenti e sovrainterpretazioni possono verificarsi anche con approcci bayesiani. Ad esempio, l’adattamento di un modello con prior non informativi e l’interpretazione della probabilità posteriore di un parametro (ad esempio, maggiore di zero) sulla base di una soglia arbitraria può portare a conclusioni altrettanto problematiche. Questi risultati ci ricordano l’importanza di una sana cautela nell’interpretazione statistica, indipendentemente dal metodo utilizzato.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "title": "\n90  La fragilità del p-valore\n",
    "section": "\n90.3 Riflessioni Conclusive",
    "text": "90.3 Riflessioni Conclusive\nLa simulazione mostra che, nonostante le medie dei campioni siano generate con una distribuzione simile, i valori-\\(p\\) possono variare drasticamente. Questo effetto è amplificato dalla scelta di campioni piccoli e di una media vera molto vicina all’ipotesi nulla (zero). Ciò dimostra quanto il valore-\\(p\\) possa essere influenzato da piccole variazioni nei dati e perché non sia sempre un indicatore affidabile per valutare l’efficacia o la presenza di un effetto.\nIn generale, la domanda importante dal punto di vista scientifico non è se in un particolare campione è stato ottenuto un risultato statisticamente significativo, ma se l’effetto osservato in quel campione sia generalizzabile ad altri campioni e a dati futuri. Solo in questo secondo caso possiamo concludere, con un certo grado di certezza, di aver compreso qualcosa di rilevante sul fenomeno studiato.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n90  La fragilità del p-valore\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-3         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.4.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_6.0.6              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.1     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.4.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "href": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "title": "\n90  La fragilità del p-valore\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Stern, H. (2006). The difference between «significant» and «not significant» is not itself statistically significant. The American Statistician, 60(4), 328–331.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html",
    "href": "chapters/replication_crisis/06_changes.html",
    "title": "91  Riforma",
    "section": "",
    "text": "91.1 Introduzione\nLa crisi della riproducibilità ha stimolato un profondo dibattito sullo stato della ricerca nelle scienze comportamentali, cognitive e sociali. La scoperta che molti studi pubblicati non sono replicabili ha minato la fiducia nella ricerca scientifica, evidenziando carenze metodologiche e strutturali nel sistema accademico. In risposta a questa crisi, sono state avanzate diverse proposte di riforma per migliorare la qualità e l’affidabilità della ricerca scientifica.\nSecondo Korbmacher et al. (2023), sono necessarie riforme strutturali, cambiamenti procedurali e trasformazioni nella comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "href": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "title": "91  Riforma",
    "section": "91.2 Riforme Strutturali",
    "text": "91.2 Riforme Strutturali\n\n91.2.1 Integrazione della Riproducibilità nei Curriculum Educativi\nUna proposta chiave per affrontare la crisi della riproducibilità è l’integrazione delle pratiche di riproducibilità nei curriculum delle scienze psicologiche e affini. Attualmente, molti programmi di formazione non enfatizzano sufficientemente l’importanza della replicabilità e della trasparenza nella ricerca. Includere questi temi nei corsi di metodologia della ricerca può sensibilizzare le nuove generazioni di ricercatori sull’adozione di pratiche più rigorose e trasparenti. Alcuni programmi universitari hanno già iniziato a incorporare repliche di studi famosi nel percorso formativo, offrendo agli studenti l’opportunità di comprendere meglio i limiti e le potenzialità del processo scientifico.\n\n\n91.2.2 Incentivi per la Scienza Aperta\nUn altro aspetto cruciale è la riforma dei sistemi di incentivazione accademica. Tradizionalmente, il sistema accademico ha privilegiato la quantità di pubblicazioni e la novità dei risultati, piuttosto che la loro qualità e replicabilità. Per promuovere pratiche di scienza aperta, come la preregistrazione degli studi e la condivisione aperta dei dati, si propone l’introduzione di riconoscimenti ufficiali, come badge di “open science” o crediti accademici per la pubblicazione di rapporti registrati. Questi cambiamenti potrebbero favorire una maggiore adozione di pratiche che promuovono la trasparenza e rafforzano la fiducia nella ricerca scientifica.\nA tal proposito, uno studio di Scheel et al. (2021) ha confrontato i risultati di rapporti registrati pubblicati (N = 71) con un campione casuale di studi ipotetico-deduttivi della letteratura standard (N = 152) in psicologia. Analizzando la prima ipotesi di ciascun articolo, è emerso che il 96% dei risultati nei rapporti standard erano positivi, contro solo il 44% nei rapporti registrati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "title": "91  Riforma",
    "section": "91.3 Cambiamenti Procedurali",
    "text": "91.3 Cambiamenti Procedurali\n\n91.3.1 Mercati di Previsione per la Credibilità della Ricerca\nI mercati di previsione sono stati proposti come strumento innovativo per valutare la credibilità della ricerca. In questi mercati, esperti e non esperti scommettono sulla probabilità che i risultati di determinati studi siano replicabili. Questo approccio ha dimostrato un’elevata accuratezza nella classificazione della replicabilità degli studi, offrendo un metodo alternativo e complementare alla replicazione diretta. I mercati di previsione potrebbero essere particolarmente utili in contesti in cui la raccolta dati è costosa o difficile, fornendo una prima indicazione sulla solidità dei risultati di ricerca.\n\n\n91.3.2 Strumenti di Valutazione Statistica\nUn’altra proposta riguarda l’adozione di nuovi strumenti di valutazione statistica per identificare e correggere il bias di pubblicazione e migliorare la potenza degli studi. Strumenti come la curva-p e la curva-z sono stati sviluppati per analizzare la distribuzione dei valori p e identificare eventuali distorsioni nei risultati pubblicati. Inoltre, alcuni studiosi hanno suggerito di abbassare il livello di significatività statistica standard da 0,05 a 0,005 per ridurre il tasso di falsi positivi e aumentare la robustezza dei risultati. Queste proposte rappresentano passi importanti verso una maggiore precisione nelle analisi statistiche.\n\n\n91.3.3 Analisi Multiverso\nL’analisi multiverso è un’altra proposta innovativa che mira a gestire la molteplicità di scelte analitiche possibili in un singolo studio. Questa tecnica prevede l’esecuzione di molteplici analisi su uno stesso dataset, variando i parametri e le scelte metodologiche, per testare la stabilità dei risultati. L’adozione di questo approccio permette di evidenziare quanto i risultati siano sensibili alle scelte analitiche, contribuendo a una maggiore trasparenza e affidabilità nelle conclusioni tratte dagli studi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "title": "91  Riforma",
    "section": "91.4 Cambiamenti nella Comunità",
    "text": "91.4 Cambiamenti nella Comunità\n\n91.4.1 Big Team Science\nIl concetto di “Big Team Science” rappresenta un cambiamento significativo nella modalità di condurre ricerca. Questo approccio prevede la collaborazione su larga scala tra scienziati di diversi paesi e discipline, con l’obiettivo di replicare studi, raccogliere grandi campioni e condividere risorse. Questo modello di lavoro collettivo non solo aumenta l’efficienza della ricerca, ma promuove anche una maggiore diversità nei campioni e nei team di ricerca. Tuttavia, esistono anche criticità, come la possibilità di perpetuare disuguaglianze tra ricercatori di paesi sviluppati e in via di sviluppo, e la difficoltà nel riconoscere adeguatamente i contributi individuali all’interno di grandi consorzi.\n\n\n91.4.2 Collaborazioni Avversariali\nLe collaborazioni avversariali rappresentano un altro approccio interessante per migliorare la qualità della ricerca. In queste collaborazioni, ricercatori con visioni teoriche contrastanti lavorano insieme per progettare e condurre studi che testino le loro ipotesi in modo rigoroso. Questo tipo di collaborazione può ridurre i bias personali e promuovere un confronto costruttivo, portando a conclusioni più solide e condivise all’interno della comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "href": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "title": "91  Riforma",
    "section": "91.5 Crisi della Generalizzabilità",
    "text": "91.5 Crisi della Generalizzabilità\nYarkoni (2022) affronta la questione critica della scarsa validità delle inferenze quantitative presenti nella letteratura psicologica pubblicata, proponendo tre strategie principali per migliorare la qualità della ricerca in psicologia.\n\n91.5.1 Do Something Else\nIl primo suggerimento è di considerare l’abbandono della ricerca psicologica quantitativa quando risulta troppo difficile estrarre conclusioni significative e generalizzabili da effetti complessi e variabili. L’autore critica la tendenza a concludere ogni contributo di ricerca con una nota positiva, indipendentemente dalle evidenze raccolte. In alcuni casi, potrebbe essere più saggio riconoscere i limiti della ricerca e scegliere percorsi di carriera alternativi, specialmente per i ricercatori alle prime armi.\n\n\n91.5.2 Abbracciare l’Analisi Qualitativa\nLa seconda opzione proposta è continuare a fare ricerca psicologica, ma abbandonando in gran parte i metodi statistici inferenziali a favore di metodi qualitativi. L’autore sostiene che gran parte della scienza quantitativa in psicologia sia in realtà un’analisi qualitativa mascherata. In molti casi, l’analisi qualitativa potrebbe fornire risposte più profonde e significative rispetto a un approccio quantitativo superficiale.\n\n\n91.5.3 Adottare Standard Migliori\nLa terza strategia consiste nel migliorare gli standard della ricerca quantitativa in psicologia per renderla più rigorosa e affidabile. L’autore propone diverse pratiche, tra cui:\n\nInferenze più conservative: Evitare generalizzazioni ampie basate su dati limitati.\nRicerca descrittiva: Prendere più seriamente la ricerca descrittiva, che si concentra sulla caratterizzazione delle relazioni tra variabili.\nModelli statistici più espansivi: Utilizzare modelli che considerino una più ampia gamma di variabili e fattori.\nProgettare con la variazione in mente: Abbracciare la variabilità naturale delle condizioni sperimentali.\nStime della varianza: Porre maggiore enfasi sull’analisi delle componenti della varianza.\nPredizioni più rischiose: Formulare predizioni teoriche che comportino un alto grado di rischio.\nUtilità predittiva pratica: Concentrarsi sull’utilità pratica delle predizioni piuttosto che su considerazioni puramente teoriche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "href": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "title": "91  Riforma",
    "section": "91.6 Sviluppare Teorie Formali",
    "text": "91.6 Sviluppare Teorie Formali\nOltre alle carenze metodologiche o statistiche, è stato spesso sottolineato che la crisi di replicabilità trova le sue radici nella mancanza di un quadro teorico cumulativo. Senza un quadro teorico generale che generi ipotesi in diversi ambiti, i programmi empirici si sviluppano a partire da intuizioni personali e teorie popolari influenzate culturalmente. Fornendo strumenti per formulare previsioni chiare, anche attraverso l’uso di modelli formali, i quadri teorici stabiliscono aspettative che permettono di determinare se un nuovo risultato conferma le ricerche esistenti, integrandosi con esse, oppure se è inaspettato e, pertanto, richiede ulteriori verifiche e approfondimenti (Muthukrishna & Henrich, 2019).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "title": "91  Riforma",
    "section": "91.7 Riflessioni Conclusive",
    "text": "91.7 Riflessioni Conclusive\nL’ampio utilizzo dei test statistici frequentisti in psicologia risulta spesso fuorviante, poiché attribuisce un’apparenza di rigore scientifico a inferenze che, in realtà, sono principalmente qualitative. Si rende quindi necessaria una profonda riforma delle pratiche di ricerca, volta a promuovere una maggiore trasparenza e precisione, oltre a incoraggiare la disponibilità a mettere in discussione e abbandonare approcci metodologici che non superano una rigorosa analisi critica (Yarkoni, 2022).\nLa crisi di replicabilità ha spinto verso una serie di riforme con il potenziale di trasformare positivamente la ricerca psicologica. Tra queste iniziative vi sono la promozione della scienza aperta, l’adozione di standard metodologici più rigorosi e una maggiore attenzione a pratiche di ricerca che privilegiano la qualità e la replicabilità dei risultati rispetto alla loro quantità e novità. Sebbene questi cambiamenti possano sembrare meno spettacolari rispetto ai metodi attualmente utilizzati, essi rappresentano un percorso fondamentale per garantire la credibilità e la sostenibilità a lungo termine della disciplina.\nAffinché queste riforme abbiano un impatto duraturo, è essenziale un cambiamento strutturale a tutti i livelli della comunità scientifica:\n\nI ricercatori devono impegnarsi ad adottare pratiche più rigorose e trasparenti, privilegiando la solidità metodologica e la replicabilità dei loro studi.\nGli enti finanziatori devono incentivare la qualità e la replicabilità degli studi, piuttosto che premiare esclusivamente la produzione di risultati innovativi o appariscenti.\nLe istituzioni accademiche devono rivedere i criteri di valutazione del merito scientifico, dando maggior peso all’impatto a lungo termine delle ricerche e alla loro solidità metodologica.\nLe riviste scientifiche devono assicurarsi che i risultati pubblicati siano realmente robusti e generalizzabili, anziché limitarsi a privilegiare i risultati nuovi o sorprendenti.\n\nQuesti cambiamenti, sebbene complessi e talvolta impopolari, sono fondamentali per ristabilire la fiducia nel processo scientifico e per garantire che la ricerca psicologica continui a offrire contributi utili e affidabili nella comprensione della mente umana e del comportamento.\nIn conclusione, la sfida posta dalla crisi di replicabilità offre un’opportunità unica per ridefinire e rafforzare le fondamenta metodologiche della ricerca psicologica. Abbracciando questi cambiamenti, la psicologia può emergere come una disciplina più robusta, trasparente e affidabile, capace di fornire intuizioni utili e durature sul funzionamento della mente e del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#bibliografia",
    "href": "chapters/replication_crisis/06_changes.html#bibliografia",
    "title": "91  Riforma",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMuthukrishna, M., & Henrich, J. (2019). A problem in theory. Nature Human Behaviour, 3(3), 221–229.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html",
    "href": "chapters/replication_crisis/07_piranha.html",
    "title": "92  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "",
    "text": "92.1 Introduzione\nUn recente articolo di Tosh et al. (2025) affronta una questione centrale per la psicologia e la crisi della replicabilità: il cosiddetto “problema del piranha”. Questo argomento riguarda la convinzione, diffusa in molti studi psicologici, che piccoli interventi (o “nudges”), apparentemente insignificanti, possano generare effetti notevoli sul comportamento. L’articolo dimostra formalmente, con il supporto del teorema di Van der Corput (Tao, 2014), che se tali effetti fossero davvero così grandi e consistenti, allora sarebbe possibile manipolare il comportamento umano in modi empiricamente irrealistici.\nIn altre parole, la letteratura psicologica spesso riporta effetti di dimensioni tali che richiederebbero assunzioni incompatibili con le evidenze empiriche. Questi risultati suggeriscono che le affermazioni di grandi effetti indipendenti sono più probabilmente attribuibili a problemi metodologici, come bassa potenza statistica o “gradi di libertà del ricercatore” (Simmons et al., 2011).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "href": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "title": "92  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "92.2 Il problema del piranha",
    "text": "92.2 Il problema del piranha\nTosh et al. (2025) evidenziano che, in un sistema complesso, se molte variabili esplicative hanno un forte impatto su una singola variabile di esito, queste devono inevitabilmente mostrare interazioni o correlazioni rilevanti tra loro.\n\n92.2.1 Punti chiave del problema\n\nEffetti ampi e interazioni: Il “problema del piranha” sottolinea che è improbabile che molte variabili esplicative abbiano effetti ampi e indipendenti su una singola variabile di esito all’interno di un sistema stabile. Questo principio si basa sulla disuguaglianza di Van der Corput, che dimostra come l’aumento del numero di variabili con grandi effetti richieda una considerazione delle loro interazioni. Tali interazioni generano una rete complessa di influenze, rendendo difficile isolare l’impatto di un singolo fattore. Gli effetti osservati in un dato studio potrebbero non essere generalizzabili, poiché dipendono dai livelli di altre variabili presenti nello stesso contesto.\nAnalogia con i piranha: L’analogia del piranha descrive un sistema sovraffollato di variabili esplicative con grandi effetti, che interagiscono tra loro fino a ridurre la stabilità complessiva. Proprio come i piranha in un acquario competono tra loro fino a ridurre il loro numero, un sistema con molte variabili di forte impatto tende a generare interazioni che limitano la prevedibilità e la stabilità del sistema. In altre parole, gli effetti individuali vengono alterati, ridotti o cancellati attraverso la competizione tra variabili.\n\n\n\n92.2.2 Rilevanza per la crisi di replicabilità\nIl problema del piranha offre una prospettiva cruciale per comprendere le cause della crisi di replicabilità nella psicologia e nelle scienze sociali. Secondo Tosh et al. (2025), questa crisi non è attribuibile soltanto a problemi metodologici come la bassa potenza statistica, ma riflette un limite intrinseco dell’idea stessa che numerosi grandi effetti indipendenti possano coesistere in un sistema complesso.\nI teoremi discussi nell’articolo dimostrano che un sistema stabile non può contenere numerosi effetti forti e indipendenti senza generare predizioni empiricamente insostenibili. Ciò implica che la ricerca di molteplici “grandi effetti” rischia di essere basata su assunzioni irrealistiche riguardo alla natura delle interazioni tra variabili.\nIl problema del piranha è particolarmente rilevante per la psicologia, dove spesso si cercano numerose cause indipendenti per spiegare fenomeni complessi. Tosh et al. (2025) mettono in discussione non tanto i singoli effetti riportati, quanto l’assunzione di base secondo cui il comportamento umano e le interazioni sociali sarebbero influenzati da un gran numero di effetti indipendenti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "href": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "title": "92  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "92.3 Il priming nella psicologia sociale",
    "text": "92.3 Il priming nella psicologia sociale\nUno degli esempi analizzati da Tosh et al. (2025) riguarda la ricerca sul priming sociale, una linea di indagine ampiamente discussa e criticata nella psicologia sociale (si veda anche Leys, 2024). Gli autori utilizzano uno studio classico per illustrare le loro argomentazioni: un esperimento del 1996 condotto da Bargh et al. (1996), in cui i partecipanti riorganizzavano frasi contenenti parole associate alla vecchiaia (ad esempio, “Florida” o “solo”). I risultati riportavano che questi partecipanti camminavano più lentamente rispetto a un gruppo di controllo, con una riduzione del 13% nella velocità di camminata (Bargh et al., 1996).\nL’idea che una manipolazione così semplice possa produrre un effetto tanto marcato è stata successivamente oggetto di numerose critiche. I tentativi di replicare lo studio non hanno avuto successo, e il lavoro di Bargh et al. (1996) è ora considerato un esempio emblematico di risultati impossibili da replicare. Questo studio rappresenta solo uno dei molti casi in cui sono stati riportati effetti sorprendentemente grandi per manipolazioni apparentemente insignificanti.\nTosh et al. (2025) sostengono che, se davvero piccoli interventi (nudges) producono effetti così rilevanti, emergerebbe inevitabilmente il problema delle interazioni con numerosi altri fattori già noti per influire sul comportamento umano. La letteratura psicologica include infatti studi che attribuiscono grandi effetti a fattori come ormoni, immagini subliminali, notizie di partite di calcio o attacchi di squali, incontri casuali con sconosciuti, stato socioeconomico dei genitori, condizioni meteorologiche, l’ultima cifra dell’età, il genere del nome di un uragano, e molti altri. Secondo gli autori, se tutti questi fattori influenzassero realmente un singolo esito, le loro interazioni diventerebbero incredibilmente complesse e imprevedibili, rendendo impossibile individuare effetti stabili e replicabili.\nPer illustrare l’assurdità di alcuni di questi risultati, Tosh et al. (2025) propongono un esempio ipotetico. Supponiamo che 100 nudges producano ciascuno un effetto del 13% sulla velocità di camminata, come riportato da Bargh et al. (1996). Se questi effetti fossero indipendenti, l’effetto combinato sarebbe enorme: la velocità di camminata potrebbe facilmente raddoppiare, dimezzarsi o variare ancora di più. Tuttavia, tali variazioni sono empiricamente irrealistiche. In altre parole, le assunzioni su cui si basano molte di queste ricerche porterebbero a predizioni che non trovano riscontro nei dati osservabili.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/07_piranha.html#riflessioni-conclusive",
    "title": "92  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "92.4 Riflessioni Conclusive",
    "text": "92.4 Riflessioni Conclusive\nIl “problema del piranha” evidenzia i limiti intrinseci nell’assumere che numerosi effetti indipendenti e di grande entità possano coesistere all’interno di un sistema complesso. In realtà, tali effetti devono necessariamente interagire tra loro o essere correlati, rendendo improbabile la loro indipendenza. Questa dinamica crea instabilità nel sistema e porta a variazioni degli effetti nel tempo o tra popolazioni, compromettendo la possibilità di generalizzarne i risultati.\nTosh et al. (2025) suggeriscono che molti risultati pubblicati, che riportano effetti improbabilmente grandi, siano attribuibili non tanto a reali fenomeni psicologici, quanto a problemi metodologici, come bassa potenza statistica e i “gradi di libertà del ricercatore” (Simmons et al., 2011). La proliferazione di questi risultati contribuisce alla crisi di replicabilità, poiché i presunti effetti si rivelano spesso instabili o non replicabili.\nLa consapevolezza dei limiti imposti dal problema del piranha invita la ricerca psicologica a focalizzarsi maggiormente sulla robustezza metodologica, sull’identificazione di effetti plausibili e sulla considerazione delle interazioni tra variabili. Piuttosto che cercare di identificare molteplici grandi effetti, è essenziale riconoscere che un sistema complesso, per essere stabile e prevedibile, richiede un approccio che consideri l’interdipendenza delle variabili e la struttura complessiva del sistema. Questo approccio può contribuire a migliorare la validità e la replicabilità della ricerca nelle scienze sociali.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "href": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "title": "92  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230–244.\n\n\nLeys, R. (2024). Anatomy of a Train Wreck: The Rise and Fall of Priming Research. University of Chicago Press.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nTosh, C., Greengard, P., Goodrich, B., Gelman, A., Vehtari, A., & Hsu, D. (2025). The Piranha Problem: Large Effects Swimming in a Small Pond. Notices of the American Mathematical Society.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html",
    "title": "93  I gradi di libertà del ricercatore",
    "section": "",
    "text": "93.1 Introduzione\nLo studio di Gould et al. (2025), ripreso dalla rivista Science (O’Grady, 2025), mostra come le scelte analitiche dei ricercatori possano generare una variabilità significativa nei risultati, persino quando si utilizzano gli stessi dati e si affronta la medesima domanda di ricerca in ecologia e biologia evolutiva. Questa discrepanza supera di gran lunga l’errore statistico atteso, rivelando un problema sistemico che trascende i confini disciplinari.\nI risultati concordano con quelli di precedenti progetti “many analysts” – tra cui il pionieristico lavoro in psicologia di Silberzahn et al. (2018) – e sottolineano, come evidenziato dallo psicologo Eric Uhlmann, “il ruolo cruciale delle decisioni soggettive nella pratica scientifica”. Ciò conferma che la fragilità metodologica non è un’esclusiva della psicologia, ma riguarda settori come le neuroscienze, le scienze sociali e, appunto, l’ecologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#metodologia",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#metodologia",
    "title": "93  I gradi di libertà del ricercatore",
    "section": "93.2 Metodologia",
    "text": "93.2 Metodologia\nGould et al. (2025) hanno coinvolto 174 team di ricerca (246 analisti) nell’analisi indipendente di due dataset inediti:\n\nEcologia evolutiva: relazione tra numero di fratelli e crescita dei pulcini di cinciallegra (Cyanistes caeruleus).\nEcologia della conservazione: impatto della copertura erbosa sul reclutamento di piantine di Eucalyptus.\n\nOgni team ha risposto a una domanda specifica:\n\nDataset cinciallegra: “Quanto la competizione tra fratelli influenza la crescita dei pulcini?”\nDataset eucalipto: “In che modo la copertura erbosa condiziona il reclutamento di piantine?”\n\nI ricercatori hanno fornito risultati, giustificazioni metodologiche, codice analitico e hanno sottoposto le procedure a peer review incrociata, creando un sistema di controllo reciproco.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#risultati",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#risultati",
    "title": "93  I gradi di libertà del ricercatore",
    "section": "93.3 Risultati",
    "text": "93.3 Risultati\nLo studio ha evidenziato eterogeneità estrema nelle conclusioni, nonostante l’uniformità dei dati di partenza:\n\nCinciallegra: L’effetto medio negativo (più fratelli = minore crescita) nascondeva un’ampia dispersione, con stime da -0.8 a +0.2 (Figura 1a).\nEucalipto: La relazione media era debolmente negativa e non significativa, ma con outlier che invertivano la tendenza (Figura 1b).\n\n\n\n\n\n\n\nFigura 93.1: Distribuzione degli effetti standardizzati nei due dataset: crescita dei pulcini (sinistra) e reclutamento di piantine (destra) (adattata da Gould et al., 2025).\n\n\n\nSorprendentemente, né la selezione di variabili, né l’uso di effetti casuali, né il giudizio dei revisori correlavano con la distanza dalla media meta-analitica. In altre parole, risultati divergenti non erano associati a scelte metodologicamente “peggiori”, ma a combinazioni altrettanto valide di decisioni analitiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#il-problema-dei-gradi-di-libertà-del-ricercatore",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#il-problema-dei-gradi-di-libertà-del-ricercatore",
    "title": "93  I gradi di libertà del ricercatore",
    "section": "93.4 Il Problema dei Gradi di Libertà del Ricercatore",
    "text": "93.4 Il Problema dei Gradi di Libertà del Ricercatore\nIl lavoro illustra chiaramente come i “gradi di libertà analitici” – le molteplici opzioni durante l’analisi dati – possano generare conclusioni divergenti. Tra le decisioni critiche:\n\nGestione di outlier e dati mancanti.\nDefinizione operativa delle variabili.\nScelta di modelli statistici e controlli.\n\nQueste scelte, spesso soggettive ma teoricamente giustificabili, definiscono un “spazio analitico” con migliaia di percorsi possibili. Ogni studio pubblicato rappresenta dunque una singola traiettoria in questo labirinto metodologico, rischiando di offrire una visione parziale e potenzialmente distorta.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#implicazioni-e-strategie-di-mitigazione",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#implicazioni-e-strategie-di-mitigazione",
    "title": "93  I gradi di libertà del ricercatore",
    "section": "93.5 Implicazioni e Strategie di Mitigazione",
    "text": "93.5 Implicazioni e Strategie di Mitigazione\nLa variabilità sistematica impone una revisione delle pratiche di ricerca:\n\nAnalisi di sensibilità avanzate:\n\nAnalisi multiverso: testare tutte le combinazioni plausibili di scelte metodologiche.\nCurve di specificazione: mappare come i risultati variano al mutare delle assunzioni.\n\nModelli aggregati: Combinare stime da approcci diversi (es., Bayesian Model Averaging) per ridurre la dipendenza da singole specifiche.\n\nTrasparenza procedurale:\n\nPreregistrazione: fissare ipotesi e metodi prima di accedere ai dati.\nPubblicazione di codice e dati grezzi.\n\nFormazione metodologica: Rafforzare le competenze statistiche, con enfasi sulla gestione della complessità analitica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#riflessioni-conclusive",
    "title": "93  I gradi di libertà del ricercatore",
    "section": "93.6 Riflessioni Conclusive",
    "text": "93.6 Riflessioni Conclusive\nQuesto studio dimostra empiricamente che l’affidabilità della scienza dipende non solo dai dati, ma da come li analizziamo. La variabilità indotta dai gradi di libertà del ricercatore mina la riproducibilità, soprattutto in contesti con elevata discrezionalità analitica. La soluzione non è l’uniformità metodologica, ma una cultura della trasparenza e della pluralità analitica, dove ogni risultato sia esplicitamente contestualizzato nel suo spazio di scelte possibili. Solo così ecologia, psicologia e discipline affini potranno produrre conoscenze solide e autocritiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#bibliografia",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#bibliografia",
    "title": "93  I gradi di libertà del ricercatore",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGould, E., Fraser, H. S., Parker, T. H., Nakagawa, S., Griffith, S. C., Vesk, P. A., Fidler, F., Hamilton, D. G., Abbey-Lee, R. N., Abbott, J. K., et al. (2025). Same data, different analysts: variation in effect sizes due to analytical decisions in ecology and evolutionary biology. BMC biology, 23(1), 35.\n\n\nO’Grady, C. (2025). Given the same data, ecologists arrive at different conclusions. Science, 387(6738), 1026.\n\n\nSilberzahn, R., Uhlmann, E. L., Martin, D. P., Anselmi, P., Aust, F., Awtrey, E., Bahnı́k, Š., Bai, F., Bannard, C., Bonnier, E., et al. (2018). Many analysts, one data set: Making transparent how variations in analytic choices affect results. Advances in Methods and Practices in Psychological Science, 1(3), 337–356.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html",
    "href": "chapters/replication_crisis/09_integrity.html",
    "title": "94  Integrità della ricerca",
    "section": "",
    "text": "94.1 Introduzione\nL’integrità della ricerca si fonda su principi e standard professionali volti a garantire l’affidabilità e la qualità degli studi scientifici. Essa si distingue dall’etica della ricerca, che invece si concentra sui principi morali. Elementi chiave per l’integrità includono la condivisione dei dati, il consenso informato e la trasparenza nelle pratiche di ricerca. I codici di condotta svolgono un ruolo cruciale nel guidare i comportamenti etici sia dei ricercatori che delle istituzioni. Tra le principali sfide da affrontare vi sono le pratiche di ricerca discutibili, la fabbricazione e falsificazione dei dati, il plagio e la gestione dei conflitti di interesse. Promuovere una cultura della ricerca basata su onestà, trasparenza e rispetto dei principi etici è essenziale per preservare l’integrità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "href": "chapters/replication_crisis/09_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "title": "94  Integrità della ricerca",
    "section": "94.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca",
    "text": "94.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca\nNel contesto della ricerca, aderire a principi di condotta responsabile è fondamentale. Questi principi, spesso definiti come buone pratiche di ricerca, stabiliscono standard professionali che mirano a ottimizzare la qualità e l’affidabilità degli studi. Sebbene i concetti di base su cosa costituisca una buona pratica di ricerca rimangano stabili nel tempo, la loro applicazione pratica si evolve in risposta a cambiamenti sociali, politici e tecnologici. Un esempio significativo di questa evoluzione è l’enfasi crescente sulla condivisione dei dati di ricerca, resa possibile dall’uso di repository online gratuiti. Ciò ha portato a un’aspettativa diffusa di trasparenza e accessibilità dei dati. Allo stesso modo, la condivisione del codice utilizzato per analizzare i dati è diventata una pratica sempre più incoraggiata.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#differenziazione-tra-integrità-ed-etica-della-ricerca",
    "href": "chapters/replication_crisis/09_integrity.html#differenziazione-tra-integrità-ed-etica-della-ricerca",
    "title": "94  Integrità della ricerca",
    "section": "94.3 Differenziazione tra Integrità ed Etica della Ricerca",
    "text": "94.3 Differenziazione tra Integrità ed Etica della Ricerca\nL’integrità della ricerca si basa su standard professionali, mentre l’etica della ricerca si fonda su principi morali come l’autonomia, la beneficenza, la non-maleficenza e la giustizia. Questi principi etici si traducono in pratiche specifiche, quali il consenso informato e la garanzia di verità e riservatezza nei confronti dei partecipanti. I ricercatori hanno l’obbligo di evitare studi che possano causare danni o risultare eccessivamente onerosi per i soggetti coinvolti.\nI codici di condotta per l’integrità della ricerca presentano alcune variazioni tra le diverse fonti. Ad esempio, il Codice di condotta europeo per l’integrità della ricerca sottolinea l’importanza di principi come onestà, trasparenza, accuratezza, responsabilità, affidabilità, rispetto e indipendenza. Questi principi si traducono in comportamenti specifici attesi sia dai ricercatori che dalle istituzioni, come la condivisione dei dati nel rispetto delle normative sulla protezione dei dati, tra cui il GDPR europeo.\nUn esempio pratico di come gli standard si siano evoluti è rappresentato dalla condivisione dei dati di ricerca. In passato, questa pratica era limitata dalla mancanza di infrastrutture adeguate. Oggi, grazie ai repository online e alla pressione esercitata da riviste scientifiche e finanziatori, la condivisione dei dati è diventata una pratica standard, riflettendo un cambiamento verso una maggiore apertura e trasparenza.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "href": "chapters/replication_crisis/09_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "title": "94  Integrità della ricerca",
    "section": "94.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta",
    "text": "94.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta\nNonostante l’esistenza di codici di condotta, i ricercatori, specialmente quelli all’inizio della carriera, possono subire pressioni da parte dei supervisori per adottare comportamenti che deviano dagli standard stabiliti. Questo è spesso dovuto alla competitività nel campo scientifico e al sistema di valutazione basato sul numero di pubblicazioni. Tali dinamiche possono portare a pratiche di ricerca discutibili (PRD), come la pubblicazione selettiva dei risultati o l’uso di analisi dei dati flessibili per ottenere risultati statisticamente significativi.\nPer preservare l’integrità della ricerca, è essenziale creare un ambiente di lavoro che promuova apertura, inclusività e discussione franca delle pressioni e delle sfide etiche. Ciò richiede non solo l’adesione ai codici di condotta esistenti, ma anche un impegno attivo delle istituzioni nel promuovere la formazione etica e l’integrità tra i ricercatori. Solo attraverso un approccio di questo tipo la comunità scientifica può aspirare a una ricerca di alta qualità, sia eticamente responsabile che metodologicamente solida.\nUn esempio emblematico delle tensioni nel mondo accademico è il gioco da tavolo Publish or Perish, recentemente promosso dalla prestigiosa rivista Nature. La descrizione del gioco è provocatoria:\n\n“Falsificare dati, screditare altri scienziati, pubblicare una montagna di articoli che ricevono una torre di citazioni: i cinici potrebbero descrivere questi come passi necessari per raggiungere il successo accademico.”\n\nQuesta iniziativa solleva interrogativi sullo stato attuale della ricerca scientifica. Il mondo accademico sembra offrire incentivi distorti, mentre il sistema economico delle riviste scientifiche presenta una componente di monetizzazione che spesso entra in conflitto con gli obiettivi fondamentali della ricerca. Questo contesto favorisce l’accettazione di pratiche disoneste, funzionali al mantenimento dello status quo.\nIn questo scenario complesso, emergono voci di dissenso che auspicano una riforma del sistema scientifico (McElreath, 2020; Smaldino & McElreath, 2016). È necessaria una riflessione profonda su come bilanciare la produttività accademica con l’etica e la qualità della ricerca, nonché sul ruolo delle riviste scientifiche nel plasmare il panorama della ricerca contemporanea.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#bibliografia",
    "href": "chapters/replication_crisis/09_integrity.html#bibliografia",
    "title": "94  Integrità della ricerca",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society Open Science, 3(9), 160384.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html",
    "href": "chapters/epiloque/epiloque.html",
    "title": "Considerazioni Conclusive",
    "section": "",
    "text": "Limiti dell’Inferenza Frequentista\nL’inferenza bayesiana rappresenta un approccio rigoroso e trasparente per integrare conoscenze pregresse e dati empirici nell’analisi psicologica. A differenza dei metodi frequentisti, l’approccio bayesiano consente di quantificare l’incertezza e di costruire modelli che riflettono le nostre aspettative iniziali. Questa flessibilità è particolarmente preziosa in psicologia, dove teorie e ipotesi svolgono un ruolo centrale nel guidare la ricerca. L’inferenza bayesiana rende esplicite le nostre assunzioni a priori e ci permette di valutare come i dati influenzano la nostra comprensione dei fenomeni psicologici.\nIn questo corso, abbiamo esaminato i limiti dell’inferenza frequentista, specialmente quando utilizzata come “filtro” per distinguere risultati scientifici rilevanti da quelli trascurabili. L’eccessiva dipendenza dai valori-p è stata ampiamente criticata per la sua associazione con inferenze inadeguate. Gli effetti possono essere sovrastimati, talvolta anche nella direzione sbagliata, quando la stima è vincolata alla significatività statistica in presenza di dati altamente variabili (Loken & Gelman, 2017).\nNonostante le critiche di lunga data e i dibattiti sul loro uso improprio (Gardner e Altman, 1986; Cohen, 1994; Anderson et al., 2000; Fidler et al., 2004; Finch et al., 2004), i valori-p persistono come indicatore di significatività. Questa tenacia riflette forse la necessità dei ricercatori di avere strumenti intuitivi, sebbene semplificati, per interpretare i dati. Tuttavia, l’uso rigido di soglie arbitrarie (ad esempio, 0.05, 0.01, 0.001) ha trasformato il raggiungimento della significatività in un obiettivo fine a se stesso, piuttosto che in uno strumento per comprendere i fenomeni sottostanti (Cohen, 1994; Kirk, 1996). Inoltre, i valori-p possono solo rifiutare l’ipotesi nulla, ma non confermarla, poiché un risultato non significativo non implica l’assenza di effetti o differenze (Wagenmakers, 2007; Amrhein et al., 2019).\nL’uso improprio dei valori-p, noto come “p-hacking” (Simmons et al., 2011), ha favorito pratiche scientifiche discutibili, contribuendo alla crisi di riproducibilità nella psicologia (Chambers et al., 2014; Szucs e Ioannidis, 2016).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "href": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "title": "Considerazioni Conclusive",
    "section": "La Crisi della Replicabilità",
    "text": "La Crisi della Replicabilità\nLa crisi della replicabilità rappresenta una delle principali sfide che affliggono la ricerca scientifica contemporanea, con effetti particolarmente rilevanti nel campo della psicologia. Quando i risultati di uno studio non possono essere riprodotti in condizioni simili, si mette in discussione non solo la validità delle teorie su cui si basano interventi clinici e politiche pubbliche, ma anche la fiducia generale nella scienza. Questo problema va oltre l’ambito accademico, influenzando direttamente l’efficacia delle applicazioni pratiche delle ricerche.\n\nLe Cause Sottostanti\nUno dei fattori principali della crisi è legato all’uso di metodologie di ricerca e analisi dei dati insufficientemente rigorose, che spesso portano a falsi positivi. Sebbene siano stati fatti appelli per migliorare le pratiche scientifiche, tali problemi persistono, indicando che il fenomeno non è semplicemente frutto di errori o mancanza di comprensione. Secondo Smaldino e McElreath (2016), la causa radicale risiede nei sistemi di incentivi distorti che favoriscono la quantità piuttosto che la qualità della ricerca. In questo contesto, la pressione a pubblicare risultati significativi diventa prioritaria rispetto alla rigorosità metodologica, alimentando un circolo vizioso in cui la “scienza scadente” si perpetua.\nPratiche comuni, come il p-hacking (manipolazione statistica per ottenere risultati significativi) o la selezione selettiva dei dati, vengono adottate inconsciamente o intenzionalmente per massimizzare le probabilità di pubblicazione. Questo meccanismo, descritto come una forma di “selezione naturale della scienza scadente”, premia approcci che facilitano la produzione di risultati spettacolari, ma non necessariamente veritieri.\n\n\nVerso una Soluzione: Cambiare la Cultura Scientifica\nPer superare questa crisi, è fondamentale operare un cambiamento culturale all’interno della comunità scientifica. Non basta correggere gli errori metodologici; occorre modificare radicalmente gli incentivi per premiare la qualità, la trasparenza e la replicabilità della ricerca. Alcune strategie chiave includono:\n\nPromozione di Pratiche Rigorose:\n\nAdottare protocolli trasparenti, preregistrare gli studi prima del loro avvio e condividere apertamente dati e materiali.\nImplementare procedure di peer review più severe e incoraggiare la revisione post-pubblicazione.\n\nValorizzazione della Replicazione:\n\nDare maggiore riconoscimento agli studi che replicano risultati precedenti, anziché privilegiare esclusivamente nuove scoperte.\nCreare riviste specializzate che si concentriano sulla verifica e sulla riproducibilità degli studi.\n\nRiforma dei Criteri di Valutazione:\n\nSpostare l’attenzione dalla quantità delle pubblicazioni alla loro qualità e impatto scientifico.\nIncorporare metriche alternative, come l’impatto sociale e la contribuzione alla conoscenza consolidata.\n\n\n\n\nNuovi Approcci Metodologici\nAlcune proposte innovative mirano a migliorare la qualità delle analisi statistiche e ridurre la propensione a falsi positivi. Un esempio è l’adozione dell’inferenza bayesiana, che offre vantaggi significativi rispetto ai metodi tradizionali:\n\nMaggiore flessibilità nell’analisi di dati rumorosi o campioni piccoli.\nMinore propensione agli errori di tipo I.\nPossibilità di incorporare conoscenze pregresse nel processo decisionale.\n\nTuttavia, l’inferenza bayesiana da sola non può risolvere completamente il problema. È necessario affrontare anche le cause strutturali, come il sistema accademico che premia la produttività quantitativa piuttosto che la qualità.\nUn’altra prospettiva promettente è quella avanzata da Richard McElreath, che suggerisce di passare da un approccio descrittivo a uno che descrive formalmente i meccanismi generativi dei dati. Questo significa formulare ipotesi esplicite sui processi sottostanti e testarle attraverso confronti quantitativi tra modelli. Tecniche come la validazione incrociata bayesiana Leave-One-Out (LOO) permettono di valutare la robustezza dei modelli e la loro capacità di generalizzare a nuovi contesti.\nInoltre, la “rivoluzione causale” cerca di identificare relazioni causali in contesti naturali, superando i limiti degli esperimenti controllati tradizionali. Questo approccio richiede ai ricercatori di formulare ipotesi causali esplicite e confrontare modelli alternativi, migliorando così la comprensione dei fenomeni studiati.\n\n\nImplicazioni Sociali e Educative\nLa crisi della replicabilità ha implicazioni concrete al di là del mondo accademico. Interventi clinici, politiche pubbliche e decisioni basate su ricerche non replicabili rischiano di essere inefficaci o dannose. Pertanto, garantire la replicabilità e l’affidabilità delle scoperte scientifiche è essenziale non solo per preservare l’integrità accademica, ma anche per assumersi responsabilità sociali.\nUna revisione dei metodi didattici e dei programmi accademici è altrettanto cruciale. Gli studenti devono essere formati per comprendere e applicare inferenze basate su dati empirici. Studiosi come Mine Dogucu hanno sottolineato l’importanza di integrare approcci bayesiani e causalità nei corsi di formazione, e la presente dispensa si inserisce in questo sforzo (Dogucu & Çetinkaya-Rundel, 2021; Dogucu & Hu, 2022; Johnson et al., 2022; Rosenberg et al., 2022).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#conclusioni",
    "href": "chapters/epiloque/epiloque.html#conclusioni",
    "title": "Considerazioni Conclusive",
    "section": "Conclusioni",
    "text": "Conclusioni\nAffrontare e superare la crisi della replicabilità rappresenta una sfida fondamentale per la comunità scientifica, richiedendo un impegno collettivo per riformare profondamente la cultura della ricerca. Modificare gli incentivi che favoriscono quantità piuttosto che qualità, promuovere pratiche metodologiche rigorose e valorizzare la replicazione sono passi essenziali per costruire una scienza più affidabile. Solo attraverso un approccio multidimensionale sarà possibile ripristinare la fiducia nella psicologia scientifica e garantire che le sue applicazioni pratiche siano fondate su basi solide e verificabili.\nIn questo contesto, l’inferenza bayesiana emerge come uno strumento di grande valore per l’analisi dei dati psicologici. Offrendo metodi avanzati per gestire l’incertezza, integrare conoscenze pregresse e adattarsi a modelli complessi, essa si dimostra particolarmente utile per esplorare i fenomeni legati alla mente umana e al comportamento. La sua capacità di fornire previsioni robuste e di aggiornare le ipotesi in base a nuovi dati la rende un approccio ideale per affrontare le sfide poste dalla natura intrinsecamente dinamica del campo psicologico.\nTuttavia, è importante sottolineare che l’adozione di metodi bayesiani non costituisce da sola una soluzione completa alla crisi della replicabilità. Per migliorare realmente la qualità della ricerca, è necessario integrare queste tecniche con pratiche metodologiche rigorose. Tra queste, spiccano la formalizzazione di modelli generativi, che consentono di descrivere esplicitamente i processi sottostanti ai dati osservati, e il confronto tra modelli alternativi, fondamentale per valutare l’adeguatezza delle teorie proposte. Inoltre, l’adozione di una prospettiva causale esplicita è cruciale per identificare correttamente le relazioni di causa-effetto, superando i limiti degli studi correlazionali o degli esperimenti tradizionali.\nIn conclusione, solo un approccio integrato, che combini l’inferenza bayesiana con pratiche metodologiche avanzate e una riflessione critica sui sistemi di incentivi accademici, permetterà di progredire verso una scienza psicologica più affidabile e riproducibile. Questo sforzo collettivo non solo migliorerà la qualità delle ricerche, ma contribuirà anche a fornire una comprensione più profonda e accurata del comportamento umano, consolidando così la posizione della psicologia come disciplina scientifica solida e credibile.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#bibliografia",
    "href": "chapters/epiloque/epiloque.html#bibliografia",
    "title": "Considerazioni Conclusive",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDogucu, M., & Çetinkaya-Rundel, M. (2021). Web scraping in the statistics and data science curriculum: Challenges and opportunities. Journal of Statistics and Data Science Education, 29(sup1), S112–S122.\n\n\nDogucu, M., & Hu, J. (2022). The current state of undergraduate Bayesian education and recommendations for the future. The American Statistician, 76(4), 405–413.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nRosenberg, J. M., Kubsch, M., Wagenmakers, E.-J., & Dogucu, M. (2022). Making sense of uncertainty in the science classroom: A Bayesian approach. Science & Education, 31(5), 1239–1262.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html",
    "href": "chapters/appendix/a01_shell.html",
    "title": "Appendice A — La Shell",
    "section": "",
    "text": "A.1 Che cos’è una Shell?\nUna shell è un programma che riceve comandi dall’utente tramite tastiera (o da file) e li passa al sistema operativo per l’esecuzione. Può essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html#che-cosè-una-shell",
    "href": "chapters/appendix/a01_shell.html#che-cosè-una-shell",
    "title": "Appendice A — La Shell",
    "section": "",
    "text": "A.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\nA.1.2 Windows vs macOS/Linux\n\nWindows 10: È possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l’ambiente preferito è solitamente PowerShell.\nmacOS/Linux: Zsh è la shell predefinita in entrambi i sistemi. È consigliabile sfruttare l’applicazione warp per un’esperienza utente moderna e ottimizzata.\n\n\n\nA.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\nA.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\nA.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless / more: Visualizza il contenuto dei file con possibilità di navigazione.\ncat: Mostra l’intero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\nA.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l’utilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilità nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma più potente perché può rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\nA.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\nA.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilità di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l’intero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\nÈ cruciale familiarizzarsi con l’utilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L’impiego dei percorsi relativi rende il processo di navigazione più intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l’utilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: È importante evitare l’inserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, \\), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l’uso del trattino (-) può causare problemi; quindi è consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilità con alcuni sistemi operativi o applicazioni, rendendo più complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, è consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, è possibile ottimizzare notevolmente l’organizzazione e la gestione dei propri file, migliorando l’efficienza del lavoro e riducendo il rischio di errori.\n\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti (es., Robbins, 2016). La familiarità con la shell è fondamentale nella data science.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html#bibliografia",
    "href": "chapters/appendix/a01_shell.html#bibliografia",
    "title": "Appendice A — La Shell",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nRobbins, A. (2016). Bash Pocket Reference: Help for Power Users and Sys Admins. O’Reilly Media, Inc.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html",
    "href": "chapters/appendix/a01a_files.html",
    "title": "Appendice B — Cartelle e documenti",
    "section": "",
    "text": "B.1 Introduzione\nI file su un computer sono organizzati tramite una struttura gerarchica chiamata struttura ad albero, costituita da cartelle (o directory) e file. Questa organizzazione permette una gestione ordinata e intuitiva delle informazioni.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#introduzione",
    "href": "chapters/appendix/a01a_files.html#introduzione",
    "title": "Appendice B — Cartelle e documenti",
    "section": "",
    "text": "Radice (Root): È il punto più alto dell’albero da cui partono tutte le ramificazioni.\nCartelle/Directory: Contenitori che possono includere file o altre cartelle.\nFile: Gli elementi finali che contengono dati.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#unixlinuxmacos",
    "href": "chapters/appendix/a01a_files.html#unixlinuxmacos",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.2 Unix/Linux/macOS",
    "text": "B.2 Unix/Linux/macOS\nNei sistemi Unix, l’albero ha una struttura chiara che inizia sempre dalla radice indicata con lo slash /.\nEsempio semplificato:\n/\n├── bin             # programmi di sistema essenziali\n├── etc             # file di configurazione\n├── home            # cartelle personali degli utenti\n│   └── utente\n│       ├── Documenti\n│       ├── Immagini\n│       └── Scaricati\n├── usr             # applicazioni e librerie utente\n├── var             # dati variabili come log e cache\n└── tmp             # file temporanei\nNei sistemi Unix i percorsi dei file si scrivono utilizzando lo slash (/), ad esempio:\n/home/utente/Documenti/tesi.docx",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#windows",
    "href": "chapters/appendix/a01a_files.html#windows",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.3 Windows",
    "text": "B.3 Windows\nWindows organizza i file in maniera simile ma partendo da una o più unità (dischi), tipicamente indicate da lettere come C:, D:, ecc. La radice di ogni albero corrisponde quindi all’unità disco.\nEsempio semplificato:\nC:\\\n├── Program Files   # applicazioni installate\n├── Windows         # sistema operativo e file di sistema\n├── Utenti          # dati degli utenti\n│   └── utente\n│       ├── Documenti\n│       ├── Immagini\n│       └── Download\n└── Temp            # file temporanei\nNei sistemi Windows i percorsi dei file si scrivono utilizzando il backslash (\\), ad esempio:\nC:\\Utenti\\utente\\Documenti\\tesi.docx",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#principali-comandi",
    "href": "chapters/appendix/a01a_files.html#principali-comandi",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.4 Principali Comandi",
    "text": "B.4 Principali Comandi\nQui sotto viene presentata una panoramica sintetica dei principali comandi per gestire la struttura ad albero di file e cartelle nei sistemi Unix (Linux e macOS) e Windows.\n\nB.4.1 Unix/Linux/macOS (Terminale Bash o zsh)\n\n\n\n\n\n\n\n\nComando\nFunzione\nEsempio\n\n\n\n\npwd\nMostra la cartella corrente (Print Working Directory)\npwd → /home/utente/Documenti\n\n\ncd\nCambia la cartella corrente (Change Directory)\ncd /home/utente/Scaricati\n\n\nls\nElenca il contenuto di una cartella (List)\nls o ls -l\n\n\nmkdir\nCrea una nuova cartella (Make Directory)\nmkdir nuova_cartella\n\n\nmv\nSposta o rinomina file/cartelle (Move)\nmv file.txt Documenti/ oppure mv vecchio.txt nuovo.txt\n\n\ncp\nCopia file/cartelle (Copy)\ncp file.txt copia_file.txt\n\n\nrm\nRimuove file (Remove)\nrm file.txt\n\n\nrmdir\nRimuove una cartella vuota (Remove Directory)\nrmdir cartella_vuota\n\n\nwhoami\nMostra l’utente corrente\nwhoami → utente\n\n\n\nEsempio di uso dei comandi:\npwd\ncd /home/utente\nmkdir nuovo\ncd nuovo\ntouch prova.txt\nls\nmv prova.txt ../Documenti\ncd ../Documenti\ncp prova.txt copia_prova.txt\nrm prova.txt\nwhoami\n\n\nB.4.2 Windows (Prompt dei comandi, CMD)\n\n\n\n\n\n\n\n\nComando\nFunzione\nEsempio\n\n\n\n\ncd\nCambia la cartella corrente (Change Directory)\ncd C:\\Utenti\\utente\\Documenti\n\n\ncd\nMostra la cartella corrente\ncd → C:\\Utenti\\utente\\Documenti\n\n\ndir\nElenca il contenuto della cartella\ndir\n\n\nmkdir\nCrea una nuova cartella\nmkdir nuova_cartella\n\n\nmove\nSposta o rinomina file/cartelle\nmove file.txt Documenti\\ o move vecchio.txt nuovo.txt\n\n\ncopy\nCopia file\ncopy file.txt copia_file.txt\n\n\ndel\nRimuove file\ndel file.txt\n\n\nrmdir\nRimuove cartella vuota\nrmdir cartella_vuota\n\n\nwhoami\nMostra l’utente corrente\nwhoami → utente\n\n\n\nEsempio di uso dei comandi:\ncd C:\\Utenti\\utente\nmkdir nuovo\ncd nuovo\necho prova &gt; prova.txt\ndir\nmove prova.txt ..\\Documenti\ncd ..\\Documenti\ncopy prova.txt copia_prova.txt\ndel prova.txt\nwhoami\nNota finale.\nEntrambi i sistemi operativi consentono operazioni simili, ma hanno sintassi e convenzioni leggermente diverse. Questi comandi di base permettono una gestione essenziale e rapida della struttura ad albero.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#conclusioni",
    "href": "chapters/appendix/a01a_files.html#conclusioni",
    "title": "Appendice B — Cartelle e documenti",
    "section": "Conclusioni",
    "text": "Conclusioni\nIn sintesi, entrambi i sistemi operativi utilizzano una struttura ad albero per facilitare la gestione, la navigazione e l’organizzazione dei file e delle cartelle. Cambiano principalmente la notazione (/ o \\) e la gestione della radice (una singola radice / in Unix, più radici contrassegnate da lettere come C: in Windows).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_math_symbols.html",
    "href": "chapters/appendix/a02_math_symbols.html",
    "title": "Appendice C — Simbologia di base",
    "section": "",
    "text": "Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire “per ogni.”\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) è un elemento dell’insieme \\(A\\).\nL’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\).\nL’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge “tale che.”\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge “proporzionale a.”\nIl simbolo \\(\\approx\\) si legge “circa.”\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.”\nIl simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.”\nIl simbolo \\(\\#\\) indica la cardinalità di un insieme.\nIl simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore più alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html",
    "href": "chapters/appendix/a03_latex.html",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "",
    "text": "D.1 LaTeX\nLaTeX è un potente strumento di composizione tipografica, ampiamente utilizzato per la produzione di documenti scientifici e tecnici. Una delle sue caratteristiche più apprezzate è la capacità di gestire equazioni matematiche in modo elegante e preciso. In questo articolo, esploreremo come scrivere equazioni matematiche in LaTeX, coprendo i modi matematici, le operazioni di base, l’allineamento delle equazioni e molto altro.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#modelli-matematici-in-latex",
    "href": "chapters/appendix/a03_latex.html#modelli-matematici-in-latex",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.2 Modelli Matematici in LaTeX",
    "text": "D.2 Modelli Matematici in LaTeX\nPer scrivere equazioni matematiche in LaTeX, esistono due modalità principali: la modalità inline e la modalità display.\n\nModalità Inline: Utilizzata per inserire equazioni all’interno del testo. Le espressioni matematiche sono racchiuse tra simboli di dollaro ($), ad esempio $E=mc^2$ produce \\(E=mc^2\\).\nModalità Display: Utilizzata per equazioni che devono essere evidenziate e centrate su una nuova linea. Le espressioni possono essere racchiuse tra $$ e $$, o all’interno di ambienti come \\begin{equation} e \\end{equation}.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#scrivere-costrutti-matematici-di-base",
    "href": "chapters/appendix/a03_latex.html#scrivere-costrutti-matematici-di-base",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.3 Scrivere Costrutti Matematici di Base",
    "text": "D.3 Scrivere Costrutti Matematici di Base\n\nD.3.1 Operazioni Aritmetiche\nLe operazioni aritmetiche possono essere scritte direttamente all’interno del testo utilizzando il simbolo del dollaro. Ad esempio:\n\nAddizione: $a + b$ produce \\(a + b\\).\nMoltiplicazione: $a \\cdot b$ o $a \\times b$ produce \\(a \\cdot b\\) o \\(a \\times b\\).\nDivisione: $a / b$ o $a \\div b$ produce \\(a / b\\) o \\(a \\div b\\).\n\n\n\nD.3.2 Frazioni e Coefficienti Binomiali\nLe frazioni si scrivono utilizzando il comando \\frac{num}{den}. Ad esempio, $\\frac{a}{b}$ produce \\(\\frac{a}{b}\\).\nPer i coefficienti binomiali, si utilizza il comando \\binom{n}{k}. Ad esempio, $\\binom{n}{k}$ produce \\(\\binom{n}{k}\\).\n\n\nD.3.3 Pedici e Apici\nI pedici si ottengono con _, mentre gli apici con ^. Ad esempio:\n\n$a_{1}$ produce \\(a_{1}\\).\n$a^{2}$ produce \\(a^{2}\\).\n\n\n\nD.3.4 Integrali e Radici\nPer gli integrali, i limiti di integrazione si scrivono come pedici e apici. Ad esempio:\n\n$\\int_{a}^{b} f(x) \\, dx$ produce \\(\\int_{a}^{b} f(x) \\, dx\\).\n\nLe radici si ottengono con il comando \\sqrt{}. Ad esempio, $\\sqrt{a + b}$ produce \\(\\sqrt{a + b}\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#allineamento-delle-equazioni",
    "href": "chapters/appendix/a03_latex.html#allineamento-delle-equazioni",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.4 Allineamento delle Equazioni",
    "text": "D.4 Allineamento delle Equazioni\nPer allineare più equazioni, si utilizza l’ambiente align. Ad esempio:\n\\begin{align*}\na + b &= c \\\\\nd + e &= f\n\\end{align*}\nQuesto allinea le equazioni al segno di uguale.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#parentesi-e-operatori",
    "href": "chapters/appendix/a03_latex.html#parentesi-e-operatori",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.5 Parentesi e Operatori",
    "text": "D.5 Parentesi e Operatori\nLe parentesi possono essere ridimensionate utilizzando i comandi \\left( e \\right). Ad esempio:\n$$ \n\\left( \\frac{a}{b} \\right) \n$$\nGli operatori come seno, coseno e logaritmi si scrivono con comandi specifici come \\sin, \\cos, e \\log.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#conclusione",
    "href": "chapters/appendix/a03_latex.html#conclusione",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.6 Conclusione",
    "text": "D.6 Conclusione\nLaTeX offre una vasta gamma di strumenti per la scrittura di equazioni matematiche, rendendolo uno strumento indispensabile per chiunque lavori con documenti scientifici. Con un po’ di pratica, è possibile padroneggiare queste tecniche e produrre documenti di alta qualità con facilità.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html",
    "href": "chapters/appendix/a11_numbers.html",
    "title": "Appendice E — Numeri e intervalli",
    "section": "",
    "text": "E.1 Numeri binari\nI numeri binari rappresentano il sistema numerico più elementare utilizzato in informatica, poiché sono composti unicamente da due simboli: 0 e 1. Questa caratteristica li rende particolarmente adatti alla rappresentazione di situazioni dicotomiche (vero/falso, presente/assente) e consente ai computer di operare rapidamente ed efficacemente sui dati.\nUn esempio semplice d’impiego dei valori logici binari si ottiene quando raccogliamo risposte a una domanda chiusa. Immaginiamo, ad esempio, di porre la domanda “Ti piacciono i mirtilli?” a 10 studenti. Se le risposte vengono memorizzate in R come valori logici (TRUE per “Sì” e FALSE per “No”), potremmo avere:\nopinion &lt;- c(TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE)\nopinion\n\n [1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE\nIn questo caso, TRUE e FALSE corrispondono a 1 e 0 rispettivamente quando utilizzati in operazioni numeriche. Lo stesso avviene in Python, dove True è interpretato come 1 e False come 0. Questa rappresentazione binaria permette di ottenere facilmente statistiche sintetiche. Per esempio, per calcolare la proporzione di risposte positive rispetto al totale, è sufficiente sommare i valori (contando così il numero di TRUE) e dividere per la lunghezza del vettore:\nsum(opinion) / length(opinion)\n\n[1] 0.7\nQuesto fornisce immediatamente la percentuale di studenti che hanno risposto “Sì” alla domanda.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-interi",
    "href": "chapters/appendix/a11_numbers.html#numeri-interi",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.2 Numeri interi",
    "text": "E.2 Numeri interi\nI numeri interi sono caratterizzati dall’assenza di componenti decimali. Essi includono sia i numeri naturali (1, 2, 3, …), tradizionalmente utilizzati per il conteggio, sia i loro opposti negativi. L’insieme dei numeri naturali è indicato con \\(\\mathbb{N}\\), mentre l’insieme dei numeri interi (che include i numeri naturali, i loro negativi e lo zero) si denota con \\(\\mathbb{Z}\\):\n\\[\n\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\pm 3, \\dots\\}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.3 Numeri razionali",
    "text": "E.3 Numeri razionali\nI numeri razionali sono quei numeri che possono essere espressi come il rapporto tra due numeri interi, con il denominatore diverso da zero. Essi formano l’insieme:\n\\[\n\\mathbb{Q} = \\left\\{\\frac{m}{n} \\mid m,n \\in \\mathbb{Z}, n \\neq 0\\right\\}.\n\\]\nPoiché ogni numero naturale è anche un intero, e ogni intero può essere rappresentato come razionale (ad esempio \\(5 = \\frac{5}{1}\\)), si ha una catena d’inclusioni tra i diversi insiemi di numeri:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}.\n\\]\nSe si desidera considerare solo i numeri razionali non negativi, si utilizza la notazione:\n\\[\n\\mathbb{Q}^+ = \\{q \\in \\mathbb{Q} \\mid q \\geq 0\\}.\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.4 Numeri irrazionali",
    "text": "E.4 Numeri irrazionali\nNon tutti i numeri possono essere espressi come rapporto di due interi. I numeri che non hanno questa proprietà sono detti irrazionali. Essi non possono essere scritti in forma frazionaria e la loro espansione decimale è infinita e non periodica. Esempi tipici di numeri irrazionali sono:\n\n\\(\\sqrt{2}\\)\n\\(\\sqrt{3}\\)\n\\(\\pi = 3.141592...\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-reali",
    "href": "chapters/appendix/a11_numbers.html#numeri-reali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.5 Numeri reali",
    "text": "E.5 Numeri reali\nI numeri razionali non coprono tutti i possibili punti sulla retta reale. Per rappresentare ogni possibile misura, grandezza o punto su una linea continua, si considerano i numeri reali, denotati con \\(\\mathbb{R}\\). L’insieme dei numeri reali comprende sia i razionali sia gli irrazionali:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q} \\subseteq \\mathbb{R}.\n\\]\nIn statistica, la precisione con cui si esprime una misura è spesso legata al numero di cifre decimali utilizzate, sfruttando così appieno la “continuità” offerta dai numeri reali.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "href": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.6 Intervalli Numerici",
    "text": "E.6 Intervalli Numerici\nDefinizione: Un intervallo numerico è un sottoinsieme connesso della retta reale. Intuitivamente, rappresenta tutti i numeri reali compresi tra due estremi, che possono o meno essere inclusi nell’intervallo stesso.\nClassificazione degli intervalli: Gli intervalli vengono classificati in base all’inclusione o meno degli estremi:\n\n\nIntervallo chiuso: Include entrambi gli estremi. Si indica con \\([a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x \\leq b\\).\n\nIntervallo aperto: Non include alcun estremo. Si indica con \\((a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x &lt; b\\).\n\nIntervalli semiaperti:\n\n\nChiuso a sinistra e aperto a destra: Include l’estremo sinistro ma non quello destro. Si indica con \\([a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x &lt; b\\).\n\nAperto a sinistra e chiuso a destra: Include l’estremo destro ma non quello sinistro. Si indica con \\((a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x \\leq b\\).\n\n\n\nTabella riassuntiva:\n\n\nIntervallo\nNotazione\nCondizione\n\n\n\nChiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\nAperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nChiuso a sinistra, aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\nAperto a sinistra, chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)\n\n\n\nOsservazioni: * La scelta della notazione con parentesi quadre o tonde indica rispettivamente l’inclusione o l’esclusione degli estremi.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "Appendice F — Sommatorie",
    "section": "",
    "text": "F.1 Manipolazione di somme\nLe somme sono uno strumento fondamentale in molti contesti matematici e statistici, e per gestirle in modo efficace è essenziale disporre di una notazione chiara e precisa. Consideriamo, ad esempio, la somma dei primi \\(n\\) numeri interi, che può essere espressa come \\(1 + 2 + \\dots + (n-1) + n\\), dove i puntini di sospensione (\\(\\dots\\)) indicano che la sequenza deve essere completata seguendo il pattern definito dai termini precedenti e successivi. Tuttavia, una notazione come \\(1 + 7 + \\dots + 73.6\\) risulterebbe ambigua senza ulteriori specifiche. In generale, ci troveremo di fronte a somme della forma\n\\[\nx_1 + x_2 + \\dots + x_n,\n\\]\ndove \\(x_n\\) rappresenta un numero definito altrove. Sebbene questa notazione con i puntini di sospensione sia utile in alcuni contesti, può risultare poco chiara in altri. Per questo motivo, si preferisce utilizzare la notazione di sommatoria:\n\\[\n\\sum_{i=1}^n x_i,\n\\]\nche si legge “sommatoria per \\(i\\) che va da \\(1\\) a \\(n\\) di \\(x_i\\)”. Il simbolo \\(\\sum\\) (la lettera sigma maiuscola dell’alfabeto greco) rappresenta l’operazione di somma, \\(x_i\\) è il generico addendo, mentre \\(1\\) e \\(n\\) sono gli estremi della sommatoria, che definiscono l’intervallo di variazione dell’indice \\(i\\). Solitamente, l’estremo inferiore è \\(1\\), ma potrebbe essere qualsiasi altro numero \\(m &lt; n\\). Pertanto, possiamo scrivere:\n\\[\n\\sum_{i=1}^n x_i = x_1 + x_2 + \\dots + x_n.\n\\]\nAd esempio, se i valori di \\(x\\) sono \\(\\{3, 11, 4, 7\\}\\), avremo:\n\\[\n\\sum_{i=1}^4 x_i = 3 + 11 + 4 + 7 = 25,\n\\]\ndove \\(x_1 = 3\\), \\(x_2 = 11\\), e così via. La quantità \\(x_i\\) è detta argomento della sommatoria, mentre la variabile \\(i\\), che assume valori interi successivi, è chiamata indice della sommatoria.\nLa notazione di sommatoria può anche essere espressa nella forma:\n\\[\n\\sum_{P(i)} x_i,\n\\]\ndove \\(P(i)\\) è una proposizione logica riguardante \\(i\\) che può essere vera o falsa. Quando è evidente che si vogliono sommare tutte le \\(n\\) osservazioni, la notazione può essere semplificata in \\(\\sum_{i} x_i\\) o addirittura \\(\\sum x_i\\). L’indice \\(i\\) può essere sostituito da altre lettere, come \\(k, j, l, \\dots\\), a seconda del contesto.\nPer semplificare i calcoli che coinvolgono le sommatorie, è utile conoscere alcune proprietà fondamentali.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "Appendice F — Sommatorie",
    "section": "",
    "text": "F.1.1 Proprietà 1 (Somma di una costante)\nLa sommatoria di \\(n\\) valori tutti uguali a una costante \\(a\\) è pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a}_{n \\text{ volte}} = n a.\n\\]\n\n\nF.1.2 Proprietà 2 (Proprietà distributiva)\nSe l’argomento della sommatoria contiene una costante, è possibile fattorizzarla. Ad esempio:\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n = a (x_1 + x_2 + \\dots + x_n) = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\nF.1.3 Proprietà 3 (Proprietà associativa)\nSe l’argomento della sommatoria è una somma, possiamo separare i termini:\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_2) + \\dots + (a + x_n) = n a + \\sum_{i=1}^{n} x_i.\n\\]\nIn generale, possiamo scrivere:\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\nF.1.4 Proprietà 4 (Operazioni algebriche)\nSe è necessario eseguire un’operazione algebrica (come l’elevamento a potenza o il logaritmo) sull’argomento della sommatoria, questa operazione deve essere eseguita prima della somma. Ad esempio:\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left( \\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\nF.1.5 Proprietà 5 (Prodotto di termini)\nNel caso di un prodotto tra termini, il prodotto deve essere eseguito prima della somma:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n.\n\\]\nInfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "Appendice F — Sommatorie",
    "section": "F.2 Doppia sommatoria",
    "text": "F.2 Doppia sommatoria\nIn alcuni contesti, si incontrano espressioni con una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{m} x_{ij}.\n\\]\nQuesta notazione implica che, per ogni valore dell’indice esterno \\(i\\) (da \\(1\\) a \\(n\\)), si deve sviluppare la sommatoria interna per \\(j\\) (da \\(1\\) a \\(m\\)). Ad esempio:\n\\[\n\\sum_{i=1}^{3} \\sum_{j=4}^{6} x_{ij} = (x_{1,4} + x_{1,5} + x_{1,6}) + (x_{2,4} + x_{2,5} + x_{2,6}) + (x_{3,4} + x_{3,5} + x_{3,6}).\n\\]\nUn caso particolare interessante è la doppia sommatoria del prodotto di due variabili:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j.\n\\]\nIn questo caso, poiché \\(x_i\\) non dipende dall’indice \\(j\\), possiamo estrarre \\(x_i\\) dalla sommatoria interna:\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo, la sommatoria interna \\(\\sum_{j=1}^{n} y_j\\) non dipende da \\(i\\), quindi può essere estratta dalla sommatoria esterna:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j = \\left( \\sum_{i=1}^{n} x_i \\right) \\left( \\sum_{j=1}^{n} y_j \\right).\n\\]\n\nF.2.1 Esempio pratico\nConsideriamo i vettori \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\). Calcoliamo la doppia sommatoria:\n\\[\n\\begin{aligned}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1 y_1 + x_1 y_2 + x_1 y_3 + x_2 y_1 + x_2 y_2 + x_2 y_3 + x_3 y_1 + x_3 y_2 + x_3 y_3 \\\\\n&= 2 \\times (1 + 4 + 9) + 3 \\times (1 + 4 + 9) + 1 \\times (1 + 4 + 9) \\\\\n&= 2 \\times 14 + 3 \\times 14 + 1 \\times 14 = 84.\n\\end{aligned}\n\\]\nD’altra parte, il prodotto delle due sommatorie è:\n\\[\n\\left( \\sum_{i=1}^3 x_i \\right) \\left( \\sum_{j=1}^3 y_j \\right) = (2 + 3 + 1) \\times (1 + 4 + 9) = 6 \\times 14 = 84.\n\\]\nI due risultati coincidono, confermando la validità della proprietà.\nPer ulteriori approfondimenti, si consiglia la consultazione del testo Concrete Mathematics: A Foundation for Computer Science (Graham et al., 1994).\nEsercizi pratici sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "href": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "title": "Appendice F — Sommatorie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGraham, R. L., Knuth, D. E., & Patashnik, O. (1994). Concrete Mathematics: A Foundation for Computer Science (2nd ed.). Addison-Wesley.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html",
    "href": "chapters/appendix/a13_sets.html",
    "title": "Appendice G — Insiemi",
    "section": "",
    "text": "G.1 Diagrammi di Eulero-Venn\nUn insieme (o collezione, classe, gruppo, …) è stato definito da Georg Cantor nel modo seguente:\nMentre non è rilevante la natura degli oggetti che costituiscono l’insieme, ciò che importa è distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilità: il dato oggetto è un elemento dell’insieme considerato oppure non è elemento dell’insieme considerato. Due insiemi \\(A\\) e \\(B\\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \\(A=B\\). Due insiemi \\(A\\) e \\(B\\) si dicono diversi se non contengono gli stessi elementi: \\(A \\neq B\\). Ad esempio, i seguenti insiemi sono uguali:\n\\[\n\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\n\\]\nGli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \\(A\\) si indica con\n\\[\nA = \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con } n &gt; 0.\n\\]\nLa scrittura \\(a \\in A\\) dice che \\(a\\) è un elemento di \\(A\\). Per dire che \\(b\\) non è un elemento di \\(A\\) si scrive \\(b \\notin A.\\)\nPer quegli insiemi i cui elementi soddisfano una certa proprietà che li caratterizza, tale proprietà può essere usata per descrivere più sinteticamente l’insieme:\n\\[\nA = \\{x ~\\vert~ \\text{proprietà posseduta da } x\\},\n\\]\nche si legge come “\\(A\\) è l’insieme degli elementi \\(x\\) per cui è vera la proprietà indicata.” Per esempio, per indicare l’insieme \\(A\\) delle coppie di numeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si può scrivere:\n\\[\nA = \\{(x,y) ~\\vert~ y = x^2 + 1\\}.\n\\]\nDati due insiemi \\(A\\) e \\(B\\), diremo che \\(A\\) è un sottoinsieme di \\(B\\) se e solo se tutti gli elementi di \\(A\\) sono anche elementi di \\(B\\):\n\\[\nA \\subseteq B \\iff (\\forall x \\in A \\Rightarrow x \\in B).\n\\]\nSe esiste almeno un elemento di \\(B\\) che non appartiene ad \\(A\\) allora diremo che \\(A\\) è un sottoinsieme proprio di \\(B\\):\n\\[\nA \\subset B \\iff (A \\subseteq B, \\exists~ x \\in B ~\\vert~ x \\notin A).\n\\]\nUn altro insieme, detto insieme delle parti, o insieme potenza, che si associa all’insieme \\(A\\) è l’insieme di tutti i sottoinsiemi di \\(A\\), inclusi l’insieme vuoto e \\(A\\) stesso. Per esempio, per l’insieme \\(A = \\{a, b, c\\}\\), l’insieme delle parti è:\n\\[\n\\mathcal{P}(A) = \\{\n\\emptyset, \\{a\\}, \\{b\\}, \\{c\\},\n\\{a, b\\}, \\{a, c\\}, \\{c, b\\},\n\\{a, b, c\\}\n\\}.\n\\]\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le proprietà delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19° secolo John Venn, anche se rappresentazioni simili erano già state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le proprietà degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all’interno di essi.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "Appendice G — Insiemi",
    "section": "\nG.2 Appartenenza ad un insieme",
    "text": "G.2 Appartenenza ad un insieme\nUsiamo ora R\n\nSet1 &lt;- c(1, 2)\nprint(Set1)\n\n[1] 1 2\n\nprint(class(Set1))\n\n[1] \"numeric\"\n\n\n\nmy_list &lt;- c(1, 2, 3, 4)\nmy_set_from_list &lt;- unique(my_list)\nprint(my_set_from_list)\n\n[1] 1 2 3 4\n\n\nL’appartenenza ad un insieme si verifica con %in%.\n\nmy_set &lt;- c(1, 3, 5)\nprint(\"Ecco il mio insieme:\")\n\n[1] \"Ecco il mio insieme:\"\n\nprint(my_set)\n\n[1] 1 3 5\n\nprint(\"1 appartiene all'insieme:\")\n\n[1] \"1 appartiene all'insieme:\"\n\nprint(1 %in% my_set)\n\n[1] TRUE\n\nprint(\"2 non appartiene all'insieme:\")\n\n[1] \"2 non appartiene all'insieme:\"\n\nprint(2 %in% my_set)\n\n[1] FALSE\n\nprint(\"4 NON appartiene all'insieme:\")\n\n[1] \"4 NON appartiene all'insieme:\"\n\nprint(!(4 %in% my_set))\n\n[1] TRUE",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "title": "Appendice G — Insiemi",
    "section": "\nG.3 Relazioni tra insiemi",
    "text": "G.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l’insieme universo e l’insieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv &lt;- 0:10\nSuper &lt;- Univ[Univ %% 2 == 0]\nDisj &lt;- Univ[Univ %% 2 == 1]\nSub &lt;- c(4, 6)\nNull &lt;- Univ[Univ &gt; 10]\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\")\n\n[1] \"Insieme Universo (tutti gli interi positivi fino a 10):\"\n\nprint(Univ)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nprint(\"Tutti gli interi positivi pari fino a 10:\")\n\n[1] \"Tutti gli interi positivi pari fino a 10:\"\n\nprint(Super)\n\n[1]  0  2  4  6  8 10\n\nprint(\"Tutti gli interi positivi dispari fino a 10:\")\n\n[1] \"Tutti gli interi positivi dispari fino a 10:\"\n\nprint(Disj)\n\n[1] 1 3 5 7 9\n\nprint(\"Insieme di due elementi, 4 e 6:\")\n\n[1] \"Insieme di due elementi, 4 e 6:\"\n\nprint(Sub)\n\n[1] 4 6\n\nprint(\"Un insieme vuoto:\")\n\n[1] \"Un insieme vuoto:\"\n\nprint(Null)\n\ninteger(0)\n\n\n\nprint('È \"Super\" un sovrainsieme di \"Sub\"?')\n\n[1] \"È \\\"Super\\\" un sovrainsieme di \\\"Sub\\\"?\"\n\nprint(all(Sub %in% Super))\n\n[1] TRUE\n\nprint('È \"Super\" un sottoinsieme di \"Univ\"?')\n\n[1] \"È \\\"Super\\\" un sottoinsieme di \\\"Univ\\\"?\"\n\nprint(all(Super %in% Univ))\n\n[1] TRUE\n\nprint('È \"Sub\" un sovrainsieme di \"Super\"?')\n\n[1] \"È \\\"Sub\\\" un sovrainsieme di \\\"Super\\\"?\"\n\nprint(all(Super %in% Sub))\n\n[1] FALSE\n\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?')\n\n[1] \"Sono \\\"Super\\\" e \\\"Disj\\\" insiemi disgiunti?\"\n\nprint(length(intersect(Super, Disj)) == 0)\n\n[1] TRUE",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "title": "Appendice G — Insiemi",
    "section": "\nG.4 Operazioni tra insiemi",
    "text": "G.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l’insieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l’insieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cioè\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l’insieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l’insieme differenza \\(A \\setminus B\\) è detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare è data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione all’interno del cerchio di sinistra e \\(R\\) è la regione all’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura.\n\n\nDiagrammi di Venn\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\nLeggi di DeMorgan\n\nVediamo ora come si eseguono le operazioni tra insiemi con R.\nIntersezione.\n\nS1 &lt;- seq(1, 10, by = 3)\nS2 &lt;- 1:6\nS_intersection &lt;- intersect(S1, S2)\nprint(\"Intersezione di S1 e S2:\")\n\n[1] \"Intersezione di S1 e S2:\"\n\nprint(S_intersection)\n\n[1] 1 4\n\n\nUnione. Si noti che il connettivo logico | corrisponde all’unione.\n\nS_union &lt;- union(S1, S2)\nprint(\"Unione di S1 e S2:\")\n\n[1] \"Unione di S1 e S2:\"\n\nprint(S_union)\n\n[1]  1  4  7 10  2  3  5  6\n\n\nInsieme complementare.\n\nS &lt;- seq(0, 20, by = 2)\nS_complement &lt;- setdiff(0:20, S)\nprint(\"S è l'insieme dei numeri interi pari tra 0 e 20:\")\n\n[1] \"S è l'insieme dei numeri interi pari tra 0 e 20:\"\n\nprint(S)\n\n [1]  0  2  4  6  8 10 12 14 16 18 20\n\nprint(\"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\")\n\n[1] \"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\"\n\nprint(S_complement)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\n\nprint(\"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\")\n\n[1] \"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\"\n\nprint(setequal(union(S, S_complement), 0:20))\n\n[1] TRUE\n\n\nDifferenza tra insiemi.\n\nS1 &lt;- seq(0, 30, by = 3)\nS2 &lt;- seq(0, 30, by = 5)\nprint(\"Differenza tra S2 e S1:\")\n\n[1] \"Differenza tra S2 e S1:\"\n\nprint(setdiff(S2, S1))\n\n[1]  5 10 20 25\n\nprint(\"Differenza tra S1 e S2:\")\n\n[1] \"Differenza tra S1 e S2:\"\n\nprint(setdiff(S1, S2))\n\n[1]  3  6  9 12 18 21 24 27\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Δ, è un’operazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all’unione tra i due insiemi meno la loro intersezione.\n\nsym_diff &lt;- union(setdiff(S1, S2), setdiff(S2, S1))\nprint(\"Differenza simmetrica:\")\n\n[1] \"Differenza simmetrica:\"\n\nprint(sym_diff)\n\n [1]  3  6  9 12 18 21 24 27  5 10 20 25",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Appendice G — Insiemi",
    "section": "\nG.5 Coppie ordinate e prodotto cartesiano",
    "text": "G.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) è l’insieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata) e \\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPiù in generale, un prodotto cartesiano di \\(n\\) insiemi può essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento è una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non è dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento è possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all’n-esimo. Il prodotto cartesiano prende il nome da René Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA &lt;- c(\"a\", \"b\", \"c\")\nS &lt;- 1:3\ncartesian_product &lt;- expand.grid(A, S)\nprint(\"Prodotto cartesiano di A e S:\")\n\n[1] \"Prodotto cartesiano di A e S:\"\n\nprint(cartesian_product)\n\n  Var1 Var2\n1    a    1\n2    b    1\n3    c    1\n4    a    2\n5    b    2\n6    c    2\n7    a    3\n8    b    3\n9    c    3\n\n\nSi definisce cardinalità (o potenza) di un insieme finito il numero degli elementi dell’insieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalità dell'insieme prodotto cartesiano è:\")\n\n[1] \"La cardinalità dell'insieme prodotto cartesiano è:\"\n\nprint(nrow(cartesian_product))\n\n[1] 9\n\n\nPotenza del prodotto cartesiano\n\nA &lt;- c(\"Head\", \"Tail\")\np2 &lt;- expand.grid(A, A)\nprint(\"Il quadrato dell'insieme A è un insieme che contiene:\")\n\n[1] \"Il quadrato dell'insieme A è un insieme che contiene:\"\n\nprint(nrow(p2))\n\n[1] 4\n\nprint(p2)\n\n  Var1 Var2\n1 Head Head\n2 Tail Head\n3 Head Tail\n4 Tail Tail\n\n\n\np3 &lt;- expand.grid(A, A, A)\nprint(\"L'insieme A elevato alla terza potenza è costituito da:\")\n\n[1] \"L'insieme A elevato alla terza potenza è costituito da:\"\n\nprint(nrow(p3))\n\n[1] 8\n\nprint(p3)\n\n  Var1 Var2 Var3\n1 Head Head Head\n2 Tail Head Head\n3 Head Tail Head\n4 Tail Tail Head\n5 Head Head Tail\n6 Tail Head Tail\n7 Head Tail Tail\n8 Tail Tail Tail",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html",
    "href": "chapters/appendix/a14_combinatorics.html",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "",
    "text": "H.1 Principio della somma\nIl calcolo combinatorio studia il numero di modi in cui è possibile combinare, ordinare o disporre elementi appartenenti a uno o più insiemi, seguendo regole ben definite. Molti problemi di probabilità richiedono strumenti combinatori per determinare la probabilità di eventi complessi. In questo capitolo, esploreremo i concetti fondamentali del calcolo combinatorio, illustrandoli attraverso il modello del campionamento dall’urna. Tratteremo i principi della somma e del prodotto, fondamentali per affrontare problemi più avanzati, come permutazioni, disposizioni e combinazioni.\nIl principio della somma si applica quando un insieme di elementi può essere suddiviso in sottoinsiemi disgiunti (ossia senza sovrapposizioni). In questo caso, il numero totale di elementi è dato dalla somma delle cardinalità dei sottoinsiemi:\n\\[\nn_{\\text{tot}} = n_1 + n_2 + \\dots + n_k .\n\\]\nEsempio\nUn distributore contiene tre scomparti di caramelle, ciascuno con un diverso tipo di dolci:\nQuante caramelle ci sono in totale nel distributore?\nSecondo il principio della somma, il numero totale di caramelle è:\n\\[\nn_{\\text{tot}} = n_A + n_B + n_C = 10 + 8 + 12 = 30.\n\\]\nCalcolo in R:\nA &lt;- 10\nB &lt;- 8\nC &lt;- 12\n\ntotale_caramelle &lt;- A + B + C\ntotale_caramelle\n#&gt; [1] 30\nRisultato: Nel distributore ci sono 30 caramelle in totale.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "",
    "text": "Scomparto A: 10 caramelle alla menta,\n\n\nScomparto B: 8 caramelle alla frutta,\n\n\nScomparto C: 12 caramelle al cioccolato.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "href": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.2 Principio del prodotto",
    "text": "H.2 Principio del prodotto\nIl principio del prodotto si applica quando un’operazione può essere suddivisa in più fasi indipendenti, ciascuna con un numero specifico di possibilità. In tal caso, il numero totale di combinazioni è dato dal prodotto delle possibilità offerte da ciascuna fase:\n\\[\nn_{\\text{tot}} = n_1 \\cdot n_2 \\cdot \\dots \\cdot n_k .\n\\]\nEsempio\nSupponiamo di avere quattro urne contenenti palline di diverso colore:\n\n\nUrna A: 5 palline,\n\n\nUrna B: 6 palline,\n\n\nUrna C: 3 palline,\n\n\nUrna D: 2 palline.\n\nVogliamo formare insiemi di due palline, ciascuna estratta da urne differenti.\nSecondo il principio del prodotto, per ogni coppia di urne, il numero di combinazioni è dato dal prodotto del numero di palline contenute nelle due urne. Utilizziamo poi il principio della somma per ottenere il totale complessivo:\n\\[\nn_{\\text{tot}} = AB + AC + AD + BC + BD + CD.\n\\]\nCalcolo in R:\n\nAB &lt;- 5 * 6\nAC &lt;- 5 * 3\nAD &lt;- 5 * 2\nBC &lt;- 6 * 3\nBD &lt;- 6 * 2\nCD &lt;- 3 * 2\n\ntotale_insiemi &lt;- AB + AC + AD + BC + BD + CD\ntotale_insiemi\n#&gt; [1] 91\n\nRisultato: È possibile formare 91 insiemi di due palline, ciascuna estratta da urne differenti.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "href": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.3 Il modello dell’urna e i metodi di campionamento",
    "text": "H.3 Il modello dell’urna e i metodi di campionamento\nMolti problemi di calcolo combinatorio possono essere interpretati come estrazioni di palline da un’urna. Esistono quattro modi fondamentali di effettuare un campionamento, a seconda che:\n\nle estrazioni siano con o senza ripetizione,\nl’ordine degli elementi conti o meno.\n\nQueste quattro combinazioni danno origine a quattro principali metodi di campionamento:\n\n\nCon ripetizione e con ordine: Dopo ogni estrazione, la pallina viene rimessa nell’urna. (Es. formazione di codici numerici con ripetizioni)\n\nSenza ripetizione e con ordine: Ogni estrazione rimuove definitivamente la pallina dall’urna. (Es. assegnare premi in una gara)\n\nCon ripetizione e senza ordine: Si considerano i gruppi di elementi senza preoccuparsi dell’ordine. (Es. selezionare un certo numero di ingredienti da una dispensa)\n\nSenza ripetizione e senza ordine: Si scelgono elementi distinti senza considerare l’ordine. (Es. formare squadre da un gruppo di persone)\n\n\nEsempio H.1  \n\nurna &lt;- c(\"a\", \"b\", \"c\")\n\n# Con ripetizione e ordine\ncampionamento1 &lt;- expand.grid(urna, urna) |&gt;\n    rename(Elemento1 = Var1, Elemento2 = Var2)\n\n# Senza ripetizione e con ordine\ncampionamento2 &lt;- permutations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Con ripetizione e senza ordine\ncampionamento3 &lt;- combinations(\n    n = length(urna), r = 2, v = urna, repeats.allowed = TRUE\n) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Senza ripetizione e senza ordine\ncampionamento4 &lt;- combinations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Risultati\nlist(\n    `Con ripetizione e ordine` = campionamento1,\n    `Senza ripetizione e con ordine` = campionamento2,\n    `Con ripetizione e senza ordine` = campionamento3,\n    `Senza ripetizione e senza ordine` = campionamento4\n)\n#&gt; $`Con ripetizione e ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         b         a\n#&gt; 3         c         a\n#&gt; 4         a         b\n#&gt; 5         b         b\n#&gt; 6         c         b\n#&gt; 7         a         c\n#&gt; 8         b         c\n#&gt; 9         c         c\n#&gt; \n#&gt; $`Senza ripetizione e con ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         a\n#&gt; 4         b         c\n#&gt; 5         c         a\n#&gt; 6         c         b\n#&gt; \n#&gt; $`Con ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         a         b\n#&gt; 3         a         c\n#&gt; 4         b         b\n#&gt; 5         b         c\n#&gt; 6         c         c\n#&gt; \n#&gt; $`Senza ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         c",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#permutazioni-disporre-tutti-gli-elementi-con-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#permutazioni-disporre-tutti-gli-elementi-con-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.4 Permutazioni: Disporre tutti gli elementi con ordine",
    "text": "H.4 Permutazioni: Disporre tutti gli elementi con ordine\nLe permutazioni rappresentano tutti i modi in cui è possibile ordinare \\(n\\) elementi distinti. Il numero di permutazioni è dato da:\n\\[\nP_n = n!\n\\]\ndove \\(n!\\) (n fattoriale) è il prodotto di tutti i numeri da 1 a \\(n\\):\n\\[\nn! = n \\cdot (n-1) \\cdot (n-2) \\cdot \\dots \\cdot 1.\n\\]\n\nH.4.1 Intuizione della formula\nImmaginiamo di avere \\(n\\) elementi distinti e di doverli disporre in una sequenza. Il primo elemento può essere scelto in \\(n\\) modi. Una volta scelto il primo, rimangono \\(n-1\\) possibilità per il secondo, poi \\(n-2\\) per il terzo e così via, fino all’ultimo elemento, che avrà 1 sola possibilità. Applicando il principio del prodotto, otteniamo:\n\\[\nP_n = n \\times (n-1) \\times (n-2) \\times \\dots \\times 1 = n!\n\\]\n\nH.4.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e con ordine: si estrae una pallina, la si esclude dall’urna e si continua fino a esaurire gli elementi.\n\n\nEsempio pratico: Ordinare i partecipanti di una gara su un podio (primo, secondo e terzo classificato).\n\nH.4.3 Esempio in R: Permutazioni di tre elementi\nSe abbiamo tre lettere {a, b, c}, le possibili permutazioni sono:\n\\[\nP_3 = 3! = 3 \\times 2 \\times 1 = 6.\n\\]\n\nA &lt;- c(\"a\", \"b\", \"c\")\nperm &lt;- permutations(n = length(A), r = length(A), v = A)\nprint(perm)\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,] \"a\"  \"b\"  \"c\" \n#&gt; [2,] \"a\"  \"c\"  \"b\" \n#&gt; [3,] \"b\"  \"a\"  \"c\" \n#&gt; [4,] \"b\"  \"c\"  \"a\" \n#&gt; [5,] \"c\"  \"a\"  \"b\" \n#&gt; [6,] \"c\"  \"b\"  \"a\"\nnrow(perm)  # Verifica del numero di permutazioni\n#&gt; [1] 6\n\nRisultato:\n\\[\n\\{a, b, c\\}, \\{a, c, b\\}, \\{b, a, c\\}, \\{b, c, a\\}, \\{c, a, b\\}, \\{c, b, a\\}.\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#disposizioni-selezionare-alcuni-elementi-con-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#disposizioni-selezionare-alcuni-elementi-con-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.5 Disposizioni: Selezionare alcuni elementi con ordine",
    "text": "H.5 Disposizioni: Selezionare alcuni elementi con ordine\nLe disposizioni si usano quando si scelgono \\(k\\) elementi da un insieme di \\(n\\), rispettando l’ordine. Il numero totale di disposizioni è:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} .\n\\]\n\nH.5.1 Intuizione della formula\nSupponiamo di avere \\(n\\) elementi e di voler scegliere solo \\(k\\) elementi, mantenendo l’ordine.\n\nil primo elemento può essere scelto in \\(n\\) modi;\nil secondo elemento può essere scelto tra gli \\(n-1\\) elementi rimanenti;\n\nil terzo tra gli \\(n-2\\) rimanenti.\n\nSi prosegue fino a quando si hanno scelto \\(k\\) elementi, fermandosi prima di esaurire tutti gli elementi.\n\\[\nD_{n,k} = n \\times (n-1) \\times (n-2) \\times \\dots \\times (n-k+1) .\n\\]\nQuesta espressione corrisponde alla divisione del fattoriale di \\(n\\) per il fattoriale degli elementi che non vengono selezionati:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} .\n\\]\n\nH.5.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e con ordine: si estrae una pallina, la si esclude dall’urna e si continua fino a raggiungere il numero desiderato di elementi, fermandosi prima di esaurire tutti gli elementi.\n\n\nEsempio pratico: Estrarre casualmente 2 studenti da una classe di 10 e assegnare loro i ruoli di rappresentante e vice-rappresentante (l’ordine conta).\n\nH.5.3 Esempio in R: Disposizioni di 2 elementi da {a, b, c}\nSe scegliamo 2 lettere su 3, il numero di disposizioni è:\n\\[\nD_{3,2} = \\frac{3!}{(3-2)!} = \\frac{3 \\times 2 \\times 1}{1} = 6.\n\\]\n\ndisp &lt;- permutations(n = length(A), r = 2, v = A)\nprint(disp)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"a\" \n#&gt; [4,] \"b\"  \"c\" \n#&gt; [5,] \"c\"  \"a\" \n#&gt; [6,] \"c\"  \"b\"\nnrow(disp)  # Verifica del numero di disposizioni\n#&gt; [1] 6\n\nRisultato:\n\\[\n\\{a, b\\}, \\{a, c\\}, \\{b, a\\}, \\{b, c\\}, \\{c, a\\}, \\{c, b\\}.\n\\]\nLe disposizioni considerano l’ordine, quindi \\(\\{a, b\\}\\) è diverso da \\(\\{b, a\\}\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#combinazioni-selezionare-alcuni-elementi-senza-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#combinazioni-selezionare-alcuni-elementi-senza-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.6 Combinazioni: Selezionare alcuni elementi senza ordine",
    "text": "H.6 Combinazioni: Selezionare alcuni elementi senza ordine\nLe combinazioni rappresentano il numero di modi per scegliere \\(k\\) elementi da \\(n\\) senza considerare l’ordine. Il numero di combinazioni è dato da:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!} .\n\\]\n\nH.6.1 Intuizione della formula\nSupponiamo di avere \\(n\\) elementi e di voler selezionare \\(k\\) elementi senza considerare l’ordine.\nCome nel caso delle disposizioni, il primo elemento può essere scelto in \\(n\\) modi, il secondo in \\(n-1\\), e così via fino a selezionare \\(k\\) elementi.\n\\[\nD_{n,k} = n \\times (n-1) \\times \\dots \\times (n-k+1) .\n\\]\nTuttavia, in questo caso, l’ordine non conta, quindi ogni selezione viene duplicata per il numero di modi in cui i \\(k\\) elementi possono essere ordinati, ossia \\(k!\\) permutazioni interne. Per correggere questa duplicazione, dobbiamo dividere per \\(k!\\):\n\\[\nC_{n,k} = \\frac{D_{n,k}}{k!} = \\frac{n!}{k!(n-k)!} .\n\\]\n\nH.6.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e senza ordine: si estrae una pallina e la si esclude dall’urna, ma non importa l’ordine in cui le palline vengono estratte.\n\n\nEsempio pratico: Formare una squadra di 2 studenti da un gruppo di 10 senza assegnare ruoli specifici (quindi \\(\\{a, b\\}\\) è uguale a \\(\\{b, a\\}\\)).\n\nH.6.3 Esempio in R: Combinazioni di 2 elementi da {a, b, c}\nSe scegliamo 2 lettere su 3 senza considerare l’ordine, otteniamo:\n\\[\nC_{3,2} = \\binom{3}{2} = \\frac{3!}{2!(3-2)!} = \\frac{3 \\times 2 \\times 1}{2 \\times 1 \\times 1} = 3.\n\\]\n\ncomb &lt;- combinations(n = length(A), r = 2, v = A)\nprint(comb)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"c\"\nnrow(comb)  # Verifica del numero di combinazioni\n#&gt; [1] 3\n\nRisultato:\n\\[\n\\{a, b\\}, \\{a, c\\}, \\{b, c\\}.\n\\]\nLe combinazioni non considerano l’ordine, quindi \\(\\{a, b\\}\\) è uguale a \\(\\{b, a\\}\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#sintesi-quando-usare-ciascun-metodo",
    "href": "chapters/appendix/a14_combinatorics.html#sintesi-quando-usare-ciascun-metodo",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.7 Sintesi: Quando usare ciascun metodo?",
    "text": "H.7 Sintesi: Quando usare ciascun metodo?\n\n\n\n\n\n\n\n\n\nMetodo\nRipetizione?\nOrdine?\nFormula\nMetodo di campionamento\n\n\n\nPermutazioni\n❌ No\n✅ Sì\n\\(n!\\)\nSenza ripetizione e con ordine\n\n\nDisposizioni\n❌ No\n✅ Sì\n\\(\\frac{n!}{(n-k)!}\\)\nSenza ripetizione e con ordine\n\n\nCombinazioni\n❌ No\n❌ No\n\\(\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\\)\nSenza ripetizione e senza ordine\n\n\n\nIn conclusione, abbiamo visto come il modello dell’urna aiuti a comprendere i problemi combinatori. Le differenze tra permutazioni, disposizioni e combinazioni dipendono da due fattori fondamentali: ripetizione e ordine.\nQuesta classificazione è essenziale per risolvere problemi di probabilità e statistica in modo rigoroso. Gli esempi e il codice R forniscono strumenti concreti per applicare questi concetti nella pratica.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html",
    "href": "chapters/appendix/a15_calculus.html",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "I.1 Integrali\nIn questo capitolo, traduciamo e adattiamo il capitolo Per liberarvi dai terrori preliminari tratto da Calculus made easy.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#integrali",
    "href": "chapters/appendix/a15_calculus.html#integrali",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "Il terrore preliminare, che spesso impedisce agli studenti di avvicinarsi all’analisi matematica, può essere superato comprendendo il significato intuitivo dei due simboli principali utilizzati in questo campo.\nQuesti simboli, che possono sembrare intimidatori, sono in realtà molto semplici:\n\n\\(d\\): Questo simbolo significa semplicemente “un po’ di”. Ad esempio, \\(\\operatorname{d}\\!x\\) indica un piccolo incremento di \\(x\\), mentre \\(\\operatorname{d}\\!u\\) rappresenta un piccolo incremento di \\(u\\). I matematici preferiscono dire “un elemento di” invece di “un po’ di”, ma il concetto è lo stesso. Questi piccoli incrementi possono essere considerati infinitamente piccoli.\n\\(\\int\\): Questo simbolo è una S allungata e rappresenta “la somma di”. Quindi, \\(\\int \\operatorname{d}\\!x\\) significa la somma di tutti i piccoli incrementi di \\(x\\), mentre \\(\\int \\operatorname{d}\\!t\\) indica la somma di tutti i piccoli incrementi di \\(t\\). I matematici chiamano questo simbolo “integrale”. Se consideri \\(x\\) come composto da tanti piccoli pezzi \\(\\operatorname{d}\\!x\\), sommandoli tutti otterrai l’intero valore di \\(x\\). La parola “integrale” significa semplicemente “il tutto”. Ad esempio, se pensi a un’ora come composta da 3600 secondi, la somma di tutti questi secondi ti darà un’ora. Quando vedi un’espressione che inizia con \\(\\int\\), significa che devi sommare tutti i piccoli pezzi indicati dai simboli che seguono.\n\nEcco, il terrore è svanito!\n\n\n\n\nI.1.1 Verifica con Simulazioni in R\nPer calcolare e visualizzare l’integrale di una funzione di densità, possiamo utilizzare il linguaggio di programmazione R. Consideriamo come esempio la funzione di densità gaussiana, definita dalla seguente formula:\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}.\n\\]\nIn R, possiamo definire questa funzione come segue:\n\ngaussian &lt;- function(x, mu, sigma) {\n  1 / (sigma * sqrt(2 * pi)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\nDefiniamo i parametri e generiamo i valori per il calcolo della funzione di densità su un intervallo:\n\nmu &lt;- 0      # Media\nsigma &lt;- 1   # Deviazione standard\na &lt;- -10     # Limite inferiore\nb &lt;- 10      # Limite superiore\nn &lt;- 10000   # Numero di punti\n\nx_range &lt;- seq(a, b, length.out = n)  # Valori x\nfx &lt;- gaussian(x_range, mu, sigma)   # Ordinata della funzione\n\nVisualizziamo la funzione utilizzando il pacchetto ggplot2:\n\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(data.frame(x = x_range, fx = fx), aes(x, fx)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di densità gaussiana\", \n    x = \"x\", \n    y = \"f(x)\"\n  )\n\n\n\n\n\n\n\nCreiamo una funzione per approssimare l’integrale sommando i prodotti \\(\\Delta x \\cdot f(x)\\):\n\nintegral_approximation &lt;- function(f, a, b, n) {\n  delta &lt;- (b - a) / n\n  sum(delta * f)\n}\n\n# Calcolo dell'integrale approssimato\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9999\n\n\nConfrontiamo il risultato con il calcolo fornito dalla funzione integrate di R:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n1 with absolute error &lt; 7.4e-05\n\n\nCalcoliamo l’area sotto la curva in intervalli di interesse. Ad esempio, per \\([-1.96, 1.96]\\), che corrisponde al 95% dell’area nella distribuzione normale standard:\n\na &lt;- -1.96\nb &lt;- 1.96\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9499321\n\n\nConfrontiamo con il risultato fornito da integrate():\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.9500042 with absolute error &lt; 1e-11\n\n\nVerifichiamo l’area sotto la curva per \\([-1, 1]\\), che rappresenta circa il 68% dell’area totale:\n\na &lt;- -1.0\nb &lt;- 1.0\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.6826696\n\n\nConfronto:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.6826895 with absolute error &lt; 7.6e-15\n\n\nIn sintesi, questo approccio dimostra come calcolare l’integrale di una funzione di densità in un intervallo utilizzando sia un metodo approssimativo basato sulla somma dei rettangoli sia il metodo numerico integrato. In entrambi i casi, l’obiettivo è calcolare l’area sotto la curva, che corrisponde all’integrale della funzione di densità.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#potenze",
    "href": "chapters/appendix/a15_calculus.html#potenze",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "\nI.2 Potenze",
    "text": "I.2 Potenze\nLe potenze sono un’operazione matematica che rappresenta un prodotto ripetuto. Si indicano generalmente come:\n\\[\na^n,\n\\]\ndove:\n\n\n\\(a\\) è la base,\n\n\\(n\\) è l’esponente.\n\nLa potenza rappresenta il prodotto della base \\(a\\) ripetuto \\(n\\) volte.\n\nI.2.1 Definizione di potenza\n\\[\na^n = \\underbrace{a \\cdot a \\cdot \\dots \\cdot a}_{n \\text{ fattori}} \\quad \\text{con } n \\in \\mathbb{N}.\n\\]\nAd esempio:\n\n\n\\(2^3 = 2 \\cdot 2 \\cdot 2 = 8\\),\n\n\\(3^4 = 3 \\cdot 3 \\cdot 3 \\cdot 3 = 81\\).\n\n\nI.2.2 Proprietà delle potenze\n\n\nMoltiplicazione di potenze con la stessa base:\n\\[\na^m \\cdot a^n = a^{m+n}\n\\]\nEsempio: \\(2^3 \\cdot 2^2 = 2^{3+2} = 2^5 = 32\\).\n\n\nDivisione di potenze con la stessa base:\n\\[\n\\frac{a^m}{a^n} = a^{m-n}, \\quad \\text{con } m \\geq n.\n\\]\nEsempio: \\(\\frac{5^4}{5^2} = 5^{4-2} = 5^2 = 25\\).\n\n\nPotenze di potenze:\n\\[\n(a^m)^n = a^{m \\cdot n}.\n\\]\nEsempio: \\((3^2)^3 = 3^{2 \\cdot 3} = 3^6 = 729\\).\n\n\nProdotto di potenze con basi diverse ma lo stesso esponente:\n\\[\na^n \\cdot b^n = (a \\cdot b)^n.\n\\]\nEsempio: \\(2^3 \\cdot 3^3 = (2 \\cdot 3)^3 = 6^3 = 216\\).\n\n\nDivisione di potenze con basi diverse ma lo stesso esponente:\n\\[\n\\frac{a^n}{b^n} = \\left(\\frac{a}{b}\\right)^n.\n\\]\nEsempio: \\(\\frac{4^2}{2^2} = \\left(\\frac{4}{2}\\right)^2 = 2^2 = 4\\).\n\n\nEsponente zero:\n\\[\na^0 = 1, \\quad \\text{con } a \\neq 0.\n\\]\nEsempio: \\(5^0 = 1\\).\n\n\nEsponente negativo:\n\\[\na^{-n} = \\frac{1}{a^n}.\n\\]\nEsempio: \\(2^{-3} = \\frac{1}{2^3} = \\frac{1}{8}\\).\n\n\nRadice come potenza frazionaria:\n\\[\na^{\\frac{1}{n}} = \\sqrt[n]{a}, \\quad a^{\\frac{m}{n}} = \\sqrt[n]{a^m}.\n\\]\nEsempio: \\(8^{\\frac{1}{3}} = \\sqrt[3]{8} = 2\\).\n\n\n\nI.2.3 Esempi pratici\n\n\nCalcolo semplice:\n\\[\n4^3 = 4 \\cdot 4 \\cdot 4 = 64.\n\\]\n\n\nUtilizzo delle proprietà:\n\\[\n3^5 \\cdot 3^2 = 3^{5+2} = 3^7 = 2187.\n\\]\n\n\nDivisione:\n\\[\n\\frac{6^4}{6^2} = 6^{4-2} = 6^2 = 36.\n\\]\n\n\nEsponente negativo:\n\\[\n10^{-2} = \\frac{1}{10^2} = \\frac{1}{100} = 0.01.\n\\]\n\n\nRadice come potenza:\n\\[\n16^{\\frac{1}{2}} = \\sqrt{16} = 4.\n\\]\n\n\n\nI.2.4 Nota sui numeri razionali e reali\n\nLe potenze con esponenti interi sono definite per ogni base.\nLe potenze con esponenti frazionari o reali richiedono che la base sia positiva per evitare ambiguità.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#logaritmi",
    "href": "chapters/appendix/a15_calculus.html#logaritmi",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "\nI.3 Logaritmi",
    "text": "I.3 Logaritmi\nIl logaritmo è una funzione matematica che risponde alla domanda: “quante volte devo moltiplicare un certo numero (chiamato”base”) per ottenere un altro numero?” Matematicamente, questo è espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perché \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano più grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo è utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio:\n\n\\(\\log(1) = 0\\)\n\\(\\log(0.1) = -1\\)\n\\(\\log(0.01) = -2\\)\n\\(\\log(0.001) = -3\\)\n\nCome si può vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle proprietà più utili dei logaritmi è che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta proprietà è estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilità potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn’altra proprietà utile dei logaritmi è che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa proprietà è molto utilizzata in matematica, specialmente in situazioni in cui è necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare più agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli più gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a35_other_conjugate_families.html",
    "href": "chapters/appendix/a35_other_conjugate_families.html",
    "title": "Appendice J — Altre famiglie coniugate",
    "section": "",
    "text": "Panoramica del capitolo\nNei capitoli precedenti abbiamo visto come il concetto di coniugazione renda particolarmente semplice l’aggiornamento bayesiano. L’esempio Beta–Binomiale ci ha permesso di osservare in modo diretto come i parametri della distribuzione vengano modificati dai dati senza cambiare la forma della distribuzione stessa.\nIn questa appendice presentiamo altri casi di famiglie coniugate, meno immediati ma ugualmente interessanti. L’obiettivo non è memorizzare formule o cataloghi di distribuzioni, ma cogliere un principio generale: in alcune situazioni fortunate, i calcoli bayesiani diventano particolarmente trasparenti, perché il posterior appartiene alla stessa famiglia della prior.\nDal punto di vista della ricerca psicologica, non è indispensabile padroneggiare tutti questi casi. Nella pratica, la maggior parte dei modelli che incontreremo non ammetterà una forma coniugata, e dovremo ricorrere a metodi computazionali generali come il campionamento MCMC. Tuttavia, conoscere queste famiglie ha due vantaggi didattici:\nSe è la prima volta che affronti questi argomenti, puoi leggere questa sezione in modo rapido, come un approfondimento facoltativo. Nei capitoli successivi torneremo a concentrarci sui metodi computazionali, che costituiscono lo strumento essenziale per affrontare i problemi psicologici reali.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Altre famiglie coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a35_other_conjugate_families.html#panoramica-del-capitolo",
    "href": "chapters/appendix/a35_other_conjugate_families.html#panoramica-del-capitolo",
    "title": "Appendice J — Altre famiglie coniugate",
    "section": "",
    "text": "Introdurre il modello Normale-Normale come esempio di famiglia coniugata.\nMostrare come combinare prior e verosimiglianza per ottenere la distribuzione a posteriori.\n\nCalcolare media e varianza a posteriori in forma chiusa.\nInterpretare il ruolo relativo di prior e dati nell’aggiornamento bayesiano.\n\nApplicare il modello a casi concreti (tempi di reazione, punteggi di QI).\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Conjugate Families del testo di Johnson et al. (2022).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt;\n    source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Altre famiglie coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a35_other_conjugate_families.html#perché-scegliere-una-distribuzione-normale",
    "href": "chapters/appendix/a35_other_conjugate_families.html#perché-scegliere-una-distribuzione-normale",
    "title": "Appendice J — Altre famiglie coniugate",
    "section": "\nJ.1 Perché scegliere una distribuzione normale?",
    "text": "J.1 Perché scegliere una distribuzione normale?\nLa scelta di una distribuzione a priori (e di una verosimiglianza) Normale offre numerosi vantaggi, sia dal punto di vista teorico che pratico:\n\nSimmetria e Adattabilità: La caratteristica forma “a campana” e simmetrica della distribuzione Normale ben si adatta a descrivere molti fenomeni naturali, psicologici e cognitivi, come i tempi di reazione, i punteggi di abilità, o gli errori di misurazione. Questa simmetria facilita l’interpretazione della media \\(\\mu\\) come misura di tendenza centrale e della varianza \\(\\sigma^2\\) come misura della dispersione o incertezza.\nEfficienza Parametrica: Nel modello Normale-Normale con varianza nota, l’incertezza sulla media \\(\\mu\\) nella distribuzione a priori è descritta dal singolo parametro \\(\\sigma_0^2\\) (la varianza della prior). Analogamente, la variabilità dei dati è descritta da \\(\\sigma^2\\). Questa parsimonia parametrica semplifica sia la fase di modellizzazione sia la comunicazione dei risultati.\nConvergenza con l’Inferenza Classica: Per campioni di dati sufficientemente ampi, le stime bayesiane ottenute con il modello Normale tendono a convergere verso quelle dell’inferenza frequentista. Questa proprietà, legata al teorema di Bernstein-von Mises, è talvolta indicata come calibrazione asintotica e fa sì che il modello Normale-Normale possa agire da ponte tra i due paradigmi inferenziali.\nSemplicità Computazionale: Le operazioni matematiche tra distribuzioni Normali (come il prodotto richiesto dal teorema di Bayes) risultano in un’altra distribuzione Normale. Questo permette di ottenere soluzioni analitiche in forma chiusa per i parametri della distribuzione a posteriori, evitando la necessità di ricorrere a metodi di approssimazione numerica complessi, come le simulazioni Monte Carlo Markov Chain (MCMC), almeno nei casi più semplici.\n\nIn sintesi: se le nostre conoscenze preliminari suggeriscono una distribuzione unimodale e simmetrica per il parametro di interesse, o se ci aspettiamo che la distribuzione a posteriori abbia tali caratteristiche (cosa spesso favorita dal Teorema del Limite Centrale quando si ha un campione ampio), la distribuzione Normale rappresenta una scelta robusta, elegante e computazionalmente vantaggiosa per condurre un’inferenza rigorosa.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Altre famiglie coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a35_other_conjugate_families.html#inferenza-bayesiana-per-la-media-di-una-popolazione-normale-varianza-nota",
    "href": "chapters/appendix/a35_other_conjugate_families.html#inferenza-bayesiana-per-la-media-di-una-popolazione-normale-varianza-nota",
    "title": "Appendice J — Altre famiglie coniugate",
    "section": "\nJ.2 Inferenza bayesiana per la media di una popolazione normale (varianza nota)",
    "text": "J.2 Inferenza bayesiana per la media di una popolazione normale (varianza nota)\nImmaginiamo di voler stimare il tempo medio di reazione \\(\\mu\\) (in millisecondi, ms) di una popolazione di studenti impegnati in un compito Stroop. Supponiamo di aver raccolto i tempi di reazione \\(y_1, \\dots, y_n\\) da un campione di \\(n\\) studenti. Assumiamo che questi dati provengano da una distribuzione Normale \\(y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) e, per semplificare inizialmente il modello, assumiamo che la varianza \\(\\sigma^2\\) della popolazione sia nota (ad esempio, da studi precedenti o dalla natura standardizzata del compito). Sia \\(\\sigma = 50\\) ms la deviazione standard nota.\n\nJ.2.1 I tre passi fondamentali dell’inferenza bayesiana\nIl processo di inferenza bayesiana si articola nei seguenti passaggi chiave:\n\n\n\n\n\n\n\nPasso\nSignificato Intuitivo\nFormalizzazione Matematica (Modello Normale-Normale)\n\n\n\nA. Distribuzione a Priori\nLe nostre convinzioni iniziali sulla media \\(\\mu\\).\n\\(\\mu \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)\\)\n\n\nB. Verosimiglianza dei Dati\nL’informazione su \\(\\mu\\) contenuta nei dati osservati.\n\\(y_i \\stackrel{\\text{iid}}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\)\n\n\nC. Distribuzione a Posteriori\nLe nostre convinzioni aggiornate su \\(\\mu\\) dopo i dati.\n\\(\\mu \\mid \\mathbf{y} \\sim \\mathcal{N}(\\mu_p, \\sigma_p^2)\\)\n\n\n\nQuando la varianza \\(\\sigma^2\\) dei dati è nota e la prior per \\(\\mu\\) è Normale, la distribuzione Normale è coniugata per la media \\(\\mu\\). Ciò significa che la distribuzione a posteriori per \\(\\mu\\) sarà anch’essa Normale, mantenendo la stessa forma funzionale attraverso l’aggiornamento bayesiano.\n\nJ.2.2 Distribuzione a priori\n\\(\\mu \\sim \\mathcal{N}(\\mu_0,\\sigma_0^2)\\): descrive dove crediamo sia \\(\\mu\\) e quanta incertezza abbiamo, una varianza grande significa poca informazione.\n\nJ.2.3 Verosimiglianza\n\\[\np(y\\mid\\mu,\\sigma)=\\prod_{i=1}^{n}\\frac{1}{\\sigma\\sqrt{2\\pi}}\n                  \\exp\\!\\Bigl[-\\tfrac{(y_i-\\mu)^2}{2\\sigma^2}\\Bigr].\n\\]\n\nJ.2.4 Teorema di Bayes\nIl teorema di Bayes combina prior e verosimiglianza attraverso un prodotto ponderato:\n\\[\np(\\mu\\mid y)=\\frac{p(y\\mid\\mu)\\,p(\\mu)}{p(y)} \\;\\; \\propto\\;\\;\n\\underbrace{\\mathcal{N}(\\mu_0,\\sigma_0^2)}_{\\text{prior}}\n\\; \\times \\;\n\\underbrace{\\mathcal{N}(\\bar y,\\sigma^2/n)}_{\\text{verosimiglianza}} .\n\\] Il prodotto di due distribuzioni gaussiane è una distribuzione gaussiana: basta aggiornare media e varianza.\n\nJ.2.5 Media a posteriori\n\\[\n\\mu_p=\\frac{\\tfrac{1}{\\sigma_0^2}\\,\\mu_0 + \\tfrac{n}{\\sigma^2}\\,\\bar y}\n           {\\tfrac{1}{\\sigma_0^2} + \\tfrac{n}{\\sigma^2}},\n\\qquad\n\\bar y=\\frac{1}{n}\\sum_{i=1}^{n}y_i.\n\\tag{J.1}\\]\n\n\\(\\mu_0\\): l’idea iniziale.\n\\(\\sigma_0^2\\): la fiducia in quell’idea.\n\\(\\bar y\\): ciò che dicono i dati.\n\\(n/\\sigma^2\\): la quantità di informazione empirica, aumenta con più casi e diminuisce con misure rumorose.\n\nInterpretazione: Il peso relativo di prior e dati dipende dalla loro credibilità:\n\nLa prior è influente se ha alta precisione, ovvero 1/\\(\\sigma_0^2\\) è grande, o se ci sono pochi dati, \\(n\\) piccolo.\nI dati sono dominanti se la prior ha bassa precisione o se c’è un ampio campione.\n\n\n\nJ.2.6 Varianza a posteriori\n\\[\n\\sigma_p^2=\\frac{1}{\\tfrac{1}{\\sigma_0^2}+\\tfrac{n}{\\sigma^2}}.\n\\tag{J.2}\\]\n\n\nProprietà Chiave: \\(\\sigma_p^2 \\le \\min(\\sigma_0^2, \\sigma^2/n)\\). L’incertezza diminuisce monotonicamente all’aumentare di \\(n\\).\n\n\n\n\n\n\n\nEsercizio 1.\n\n\n\n\n\nSupponiamo di voler stimare il tempo medio di reazione \\(\\mu\\) (in millisecondi) di un gruppo di studenti a un compito Stroop. Dalla letteratura o da esperienze precedenti, assumiamo che la deviazione standard dei tempi di reazione per questo tipo di compito sia \\(\\sigma = 50\\) ms.\nDefiniamo la nostra distribuzione a priori per \\(\\mu\\) basandoci su una nostra conoscenza preliminare o un’ipotesi plausibile. Ad esempio, potremmo ipotizzare che il tempo medio sia attorno ai 500 ms, con una certa incertezza: * Media a priori: \\(\\mu_0 = 500\\) ms * Deviazione standard a priori: \\(\\sigma_0 = 100\\) ms (quindi varianza a priori \\(\\sigma_0^2 = 100^2 = 10000\\))\nSuccessivamente, raccogliamo i dati da \\(n=20\\) studenti e osserviamo una media campionaria dei tempi di reazione \\(\\bar{y} = 480\\) ms.\nRiepilogo dei parametri:\n\n\nSimbolo\nDescrizione\nValore\n\n\n\n\\(\\mu_0\\)\nMedia a priori\n500 ms\n\n\n\\(\\sigma_0\\)\nDev. std. a priori\n100 ms\n\n\n\\(\\sigma_0^2\\)\nVarianza a priori\n10000 ms²\n\n\n\\(\\sigma\\)\nDev. std. dei dati (nota)\n50 ms\n\n\n\\(\\sigma^2\\)\nVarianza dei dati (nota)\n2500 ms²\n\n\n\\(n\\)\nNumero di osservazioni\n20\n\n\n\\(\\bar{y}\\)\nMedia campionaria osservata\n480 ms\n\n\n\n1. Calcolo delle Precisioni (Pesi):\n\nPrecisione a priori: \\(w_0 = \\frac{1}{\\sigma_0^2} = \\frac{1}{100^2} = \\frac{1}{10000} = 0.0001\\)\n\nPrecisione dei dati: \\(w_{\\text{dati}} = \\frac{n}{\\sigma^2} = \\frac{20}{50^2} = \\frac{20}{2500} = 0.008\\)\n\n\n2. Calcolo della Media a Posteriori (\\(\\mu_n\\)): \\[ \\mu_n = \\frac{w_0 \\mu_0 + w_{\\text{dati}} \\bar{y}}{w_0 + w_{\\text{dati}}} = \\frac{0.0001 \\times 500 + 0.008 \\times 480}{0.0001 + 0.008} = \\frac{0.05 + 3.84}{0.0081} = \\frac{3.89}{0.0081} \\approx 480.247 \\text{ ms} \\]\n3. Calcolo della Varianza a Posteriori (\\(\\sigma_n^2\\)): \\[ \\sigma_n^2 = \\frac{1}{w_0 + w_{\\text{dati}}} = \\frac{1}{0.0001 + 0.008} = \\frac{1}{0.0081} \\approx 123.457 \\text{ ms}^2 \\] La deviazione standard a posteriori è \\(\\sigma_n = \\sqrt{\\sigma_n^2} \\approx \\sqrt{123.457} \\approx 11.11 \\text{ ms}\\).\nRisultato e Interpretazione: Siamo partiti da una stima a priori di \\(\\mu \\approx 500 \\pm 100\\) ms. Dopo aver osservato 20 tempi di reazione con una media di 480 ms (e sapendo che \\(\\sigma=50\\) ms), la nostra stima aggiornata per la media dei tempi di reazione è \\(\\mu_n \\approx 480.25 \\pm 11.11\\) ms. Notiamo che la media a posteriori (480.25 ms) è molto più vicina alla media campionaria (480 ms) che alla media a priori (500 ms). Questo perché la precisione dei dati (0.008) è significativamente maggiore della precisione a priori (0.0001). Inoltre, la nostra incertezza si è drasticamente ridotta: la deviazione standard è passata da 100 ms a circa 11 ms dopo sole 20 osservazioni. Questo illustra il potere dell’aggiornamento bayesiano nel raffinare le nostre stime e ridurre l’incertezza.\n\n# ---- Parametri dell'esempio -------------------------------------------\nmu0    &lt;- 500   # Media a priori\nsigma0 &lt;- 100   # Deviazione standard a priori\nsigma  &lt;- 50    # Deviazione standard nota dei dati\nn      &lt;- 20    # Dimensione del campione\nybar   &lt;- 480   # Media campionaria osservata\n\n# ---- Calcolo dei parametri a posteriori -------------------------------\n# Precisioni\nprec_prior &lt;- 1 / sigma0^2\nprec_data  &lt;- n / sigma^2\n\n# Parametri posteriori\nsigma_p2 &lt;- 1 / (prec_prior + prec_data)  # Varianza a posteriori\nsigma_p  &lt;- sqrt(sigma_p2)                # Deviazione standard a posteriori\nmu_p     &lt;- (mu0 * prec_prior + ybar * prec_data) / (prec_prior + prec_data) # Media a posteriori\n\n# ---- Griglia di valori per il parametro mu -----------------------------\n# Definiamo un range che copra bene tutte e tre le distribuzioni\nmin_mu &lt;- min(mu0 - 3*sigma0, ybar - 3*sigma/sqrt(n), mu_p - 3*sigma_p)\nmax_mu &lt;- max(mu0 + 3*sigma0, ybar + 3*sigma/sqrt(n), mu_p + 3*sigma_p)\nmu_grid &lt;- seq(min_mu, max_mu, length.out = 1000)\n\n# ---- Calcolo delle densità delle tre curve -----------------------------\nprior_dens &lt;- dnorm(mu_grid, mean = mu0,  sd = sigma0)            # Densità a priori\npost_dens  &lt;- dnorm(mu_grid, mean = mu_p, sd = sigma_p)           # Densità a posteriori\n\n# Verosimiglianza (standardizzata per mu, basata sulla media campionaria)\n# La sd per la verosimiglianza di mu è sigma/sqrt(n)\nlik_dens_raw &lt;- dnorm(mu_grid, mean = ybar, sd = sigma / sqrt(n))\n# Riscaliamo la verosimiglianza per renderla graficamente confrontabile con la prior\n# Questo è solo per visualizzazione, la verosimiglianza non è una densità per mu in senso stretto\nlik_dens_scaled &lt;- lik_dens_raw * (max(prior_dens) / max(lik_dens_raw))\n\n# ---- Preparazione dati in formato \"lungo\" per ggplot2 ------------------\ndf &lt;- data.frame(\n  mu         = mu_grid,\n  Prior      = prior_dens,\n  Likelihood_scaled = lik_dens_scaled, # Usiamo quella riscalata\n  Posterior  = post_dens\n)\n\ndf_long &lt;- pivot_longer(df, -mu, names_to = \"Distribuzione\", values_to = \"Densita\")\ndf_long$Distribuzione &lt;- factor(df_long$Distribuzione, \n                                levels = c(\"Prior\", \"Likelihood_scaled\", \"Posterior\"),\n                                labels = c(\"A Priori\", \"Verosimiglianza (riscalata)\", \"A Posteriori\"))\n\n\n# ---- Grafico delle distribuzioni ---------------------------------------\nggplot(df_long, aes(x = mu, y = Densita, colour = Distribuzione)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x      = expression(paste(\"Media dei Tempi di Reazione \", mu, \" (ms)\")),\n    y      = \"Densità\",\n    title  = \"Aggiornamento Bayesiano: dal Prior al Posteriori\",\n    subtitle = paste0(\"Prior: N(\", mu0, \", \", sigma0^2, \"), \",\n                      \"Verosimiglianza (per μ): N(\", ybar, \", \", round((sigma^2/n),2), \"), \",\n                      \"Posteriori: N(\", round(mu_p,2), \", \", round(sigma_p2,2), \")\")\n  ) +\n  scale_color_manual(values = c(\"A Priori\" = \"dodgerblue\", \n                                \"Verosimiglianza (riscalata)\" = \"forestgreen\", \n                                \"A Posteriori\" = \"orangered\")) +\n  theme(legend.title = element_blank(), legend.position = \"top\")\n\n\n\n\n\n\nFigura J.1: Distribuzioni a priori, verosimiglianza (standardizzata e riscalata) e a posteriori per la media dei tempi di reazione (μ).\n\n\n\n\nIl grafico Figura J.1 illustra chiaramente come la distribuzione a posteriori sia “spostata” verso la verosimiglianza (che è più informativa della prior in questo caso) e come la sua varianza sia notevolmente ridotta rispetto a entrambe.\n\n\n\n\n\n\n\n\n\nMessaggi chiave sull’inferenza con varianza nota\n\n\n\n\nDialogo Costruttivo: L’inferenza bayesiana è un processo dinamico di dialogo tra le nostre ipotesi iniziali (prior) e l’evidenza empirica (dati/verosimiglianza).\nCalcoli Trasparenti: Con la varianza della popolazione \\(\\sigma^2\\) nota, i calcoli per la media e la varianza a posteriori sono diretti e possono essere eseguiti analiticamente (anche “a mano” per esempi semplici).\nRiduzione Garantita dell’Incertezza: Dopo aver osservato i dati, l’incertezza sul parametro (misurata dalla varianza a posteriori) non può che diminuire o, al limite, rimanere uguale (caso teorico di dati non informativi), rispetto alla varianza a priori.\nPeso dell’Evidenza: Con pochi dati o dati molto “rumorosi” (alta \\(\\sigma^2\\)), la distribuzione a priori esercita un’influenza maggiore sulla stima finale. Con molti dati o dati molto precisi (bassa \\(\\sigma^2\\)), l’informazione proveniente dai dati tende a dominare, e l’influenza della prior sulla stima a posteriori diminuisce.\nApplicabilità Vasta: Lo schema concettuale e matematico del modello Normale-Normale si applica a una vasta gamma di problemi in diverse discipline, inclusa la psicologia sperimentale (es. tempi di reazione, punteggi a test, ampiezze di segnali EEG), l’ingegneria, l’economia, e molte altre aree dove si misurano quantità continue. :::\n\n\n\n\n\n\n\n\n\nEsercizio 2.\n\n\n\n\n\nI test standard di Quoziente Intellettivo (QI) sono generalmente calibrati per avere una media di 100 e una deviazione standard di 15 nella popolazione di riferimento. Tuttavia, sono state sollevate questioni riguardo a possibili bias culturali che potrebbero favorire alcuni gruppi rispetto ad altri. Un’ulteriore complicazione sorge quando i punteggi QI vengono aggregati a livello nazionale, poiché le medie nazionali possono mascherare eterogeneità intra-paese significative.\nQuesto esempio, ispirato da Gill (2015) (che discute i dati di Lynn e Vanhanen, 2001), analizza i dati di QI medio riportati per 80 nazioni. L’obiettivo è stimare un QI medio “globale” \\(\\mu\\) utilizzando un approccio bayesiano Normale-Normale, e riflettere criticamente sul risultato.\nAssumiamo una deviazione standard nota \\(\\sigma = 15\\) per i punteggi QI (questa è una semplificazione, poiché la variabilità delle medie nazionali potrebbe essere diversa dalla variabilità individuale).\nI dati di QI medio per \\(n=80\\) nazioni sono forniti di seguito:\n\n\n\n\n\n\n\n\n\n\n\n\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\n\n\n\nArgentina\n96\nAustralia\n98\nAustria\n102\nBarbados\n78\n\n\nBelgium\n100\nBrazil\n87\nBulgaria\n93\nCanada\n97\n\n\nChina\n100\nCongo (Br.)\n73\nCongo (Zr.)\n65\nCroatia\n90\n\n\nCuba\n85\nCzech Repub.\n97\nDenmark\n98\nEcuador\n80\n\n\nEgypt\n83\nEq. Guinea\n59\nEthiopia\n63\nFiji\n84\n\n\nFinland\n97\nFrance\n98\nGermany\n102\nGhana\n71\n\n\nGreece\n92\nGuatemala\n79\nGuinea\n66\nHong Kong\n107\n\n\nHungary\n99\nIndia\n81\nIndonesia\n89\nIran\n84\n\n\nIraq\n87\nIreland\n93\nIsrael\n94\nItaly\n102\n\n\nJamaica\n72\nJapan\n105\nKenya\n72\nKorea (S.)\n106\n\n\nLebanon\n86\nMalaysia\n92\nMarshall I.\n84\nMexico\n87\n\n\nMorocco\n85\nNepal\n78\nNetherlands\n102\nNew Zealand\n100\n\n\nNigeria\n67\nNorway\n98\nPeru\n90\nPhilippines\n86\n\n\nPoland\n99\nPortugal\n95\nPuerto Rico\n84\nQatar\n78\n\n\nRomania\n94\nRussia\n96\nSamoa\n87\nSierra Leone\n64\n\n\nSingapore\n103\nSlovakia\n96\nSlovenia\n95\nSouth Africa\n72\n\n\nSpain\n97\nSudan\n72\nSuriname\n89\nSweden\n101\n\n\nSwitzerland\n101\nTaiwan\n104\nTanzania\n72\nThailand\n91\n\n\nTonga\n87\nTurkey\n90\nUganda\n73\nU.K.\n100\n\n\nU.S.\n98\nUruguay\n96\nZambia\n77\nZimbabwe\n66\n\n\n\nImpostazione del Modello Bayesiano:\n\nPrior per \\(\\mu\\): Stabiliamo una prior basata sulla standardizzazione tipica dei test QI:\n\n\n\n\\(\\mu_0 = 100\\) (media a priori)\n\n\\(\\sigma_0 = 15\\) (deviazione standard a priori, che riflette una certa incertezza sulla media globale, o la stessa scala della \\(\\sigma\\) individuale). Quindi, \\(\\mu \\sim \\mathcal{N}(100, 15^2)\\).\n\n\nVerosimiglianza: Ogni QI nazionale \\(y_i\\) è considerato come un’osservazione della media “vera” \\(\\mu\\) con varianza \\(\\sigma^2 = 15^2\\). La media campionaria dei QI nazionali sarà \\(\\bar{y}\\).\n\n(Nota: Questa è una semplificazione. Idealmente, ogni \\(y_i\\) è già una media, e dovremmo considerare la sua precisione \\(N_i/\\sigma^2\\) se \\(N_i\\) fosse la dimensione del campione per quella nazione. Qui, trattiamo ogni media nazionale come un singolo dato \\(y_i\\) proveniente da \\(\\mathcal{N}(\\mu, \\sigma^2)\\)).\nImplementiamo le informazioni necessarie in R.\n\n# Dati IQ delle 80 nazioni (valori aggregati per paese)\niq &lt;- c(\n  96, 100, 100, 85, 83, 97, 92, 99, 87, 72, 86, 85, 67, 99, 94, 103, 97, 101, \n  87, 98, 87, 73, 97, 59, 98, 79, 81, 93, 105, 92, 78, 98, 95, 96, 72, 104, \n  90, 96, 98, 102, 78, 90, 63, 84, 84, 107, 86, 102, 106, 94, 102, 72, 101, \n  89, 72, 101, 91, 100, 100, 66, 107, 86, 78, 84, 78, 64, 72, 101, 91, 100, \n  67, 86\n) # Dati da Lynn e Vanhanen (2001) come presentati in Gill (2015)\n\n# Numero di osservazioni (nazioni)\nn &lt;- length(iq)\n\n# Media campionaria dei QI nazionali\ny_bar &lt;- mean(iq)\n\n# Deviazione standard assunta nota (per la \"popolazione\" da cui provengono le medie nazionali)\nsigma &lt;- 15\n\n# Parametri a priori\nmu_0 &lt;- 100    # Media a priori\nsigma_0 &lt;- 15  # Dev. std. a priori\n\ncat(paste(\"Numero di nazioni (n):\", n))\n#&gt; Numero di nazioni (n): 72\ncat(paste(\"\\nMedia campionaria dei QI nazionali (y_bar):\", round(y_bar, 2)))\n#&gt; \n#&gt; Media campionaria dei QI nazionali (y_bar): 89.21\n\nCalcolo dei parametri a posteriori:\nUtilizziamo le formule derivate precedentemente:\n\\[\\mu_n = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\n\\[\n\\sigma_n^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}}\n\\]\n\n# Precisioni\nprec_prior_iq &lt;- 1 / sigma_0^2\nprec_data_iq  &lt;- n / sigma^2\n\n# Parametri posteriori\nmu_p_iq     &lt;- (mu_0 * prec_prior_iq + y_bar * prec_data_iq) / (prec_prior_iq + prec_data_iq)\nsigma_p_sq_iq &lt;- 1 / (prec_prior_iq + prec_data_iq)\nsigma_p_iq    &lt;- sqrt(sigma_p_sq_iq)\n\ncat(paste(\"Media a posteriori (mu_n):\", round(mu_p_iq, 2)))\n#&gt; Media a posteriori (mu_n): 89.36\ncat(paste(\"\\nVarianza a posteriori (sigma_n^2):\", round(sigma_p_sq_iq, 2)))\n#&gt; \n#&gt; Varianza a posteriori (sigma_n^2): 3.08\ncat(paste(\"\\nDeviazione standard a posteriori (sigma_n):\", round(sigma_p_iq, 2)))\n#&gt; \n#&gt; Deviazione standard a posteriori (sigma_n): 1.76\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto mu_0 = 100 e sigma_0 = 15 per la distribuzione a priori.\n\n# Definizione dei valori sull'asse x per il grafico della posteriori\nx_qi &lt;- seq(mu_p_iq - 4 * sigma_p_iq, mu_p_iq + 4 * sigma_p_iq, length.out = 1000)\n\n# Calcolo della densità di probabilità per la posteriori\npdf_qi &lt;- dnorm(x_qi, mean = mu_p_iq, sd = sigma_p_iq)\n\n# Creazione del grafico\nggplot(data.frame(x = x_qi, pdf = pdf_qi), aes(x = x, y = pdf)) +\n  geom_line(color = \"darkslateblue\", linewidth = 1.2) +\n  geom_area(fill = \"darkslateblue\", alpha = 0.3) +\n  labs(\n    x = \"Media 'Globale' del Quoziente di Intelligenza (μ)\",\n    y = \"Densità di Probabilità\",\n    title = \"Distribuzione a Posteriori del QI Medio Globale\",\n    subtitle = paste0(\"Posteriori: N(\", round(mu_p_iq, 2), \", \", round(sigma_p_sq_iq, 2), \")\")\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\nFigura J.2: Distribuzione a posteriori per la media ‘globale’ del QI (μ), basata sui dati di 80 nazioni.\n\n\n\n\nPer completezza, visualizziamo anche prior, likelihood e posterior:\n\nmu_grid_iq &lt;- seq(min(mu_0 - 3 * sigma_0, y_bar - 3 * sigma / sqrt(n), mu_p_iq - 3 * sigma_p_iq),\n  max(mu_0 + 3 * sigma_0, y_bar + 3 * sigma / sqrt(n), mu_p_iq + 3 * sigma_p_iq),\n  length.out = 1000\n)\n\nprior_dens_iq &lt;- dnorm(mu_grid_iq, mean = mu_0, sd = sigma_0)\nlik_dens_raw_iq &lt;- dnorm(mu_grid_iq, mean = y_bar, sd = sigma / sqrt(n)) # SD della media campionaria\nlik_dens_scaled_iq &lt;- lik_dens_raw_iq * (max(prior_dens_iq) / max(lik_dens_raw_iq, na.rm = TRUE)) # Scalata\npost_dens_iq &lt;- dnorm(mu_grid_iq, mean = mu_p_iq, sd = sigma_p_iq)\n\ndf_iq &lt;- data.frame(\n  mu = mu_grid_iq,\n  Prior = prior_dens_iq,\n  Likelihood_scaled = lik_dens_scaled_iq,\n  Posterior = post_dens_iq\n)\n\ndf_long_iq &lt;- pivot_longer(df_iq, -mu, names_to = \"Distribuzione\", values_to = \"Densita\")\ndf_long_iq$Distribuzione &lt;- factor(df_long_iq$Distribuzione,\n  levels = c(\"Prior\", \"Likelihood_scaled\", \"Posterior\"),\n  labels = c(\"A Priori\", \"Verosimiglianza (riscalata)\", \"A Posteriori\")\n)\n\nggplot(df_long_iq, aes(x = mu, y = Densita, colour = Distribuzione)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(paste(\"Media QI \", mu)),\n    y = \"Densità\",\n    title = \"Aggiornamento Bayesiano per il QI Medio 'Globale'\",\n    subtitle = paste0(\n      \"Prior: N(\", mu_0, \", \", sigma_0^2, \"), \",\n      \"Verosimiglianza (per μ): N(\", round(y_bar, 2), \", \", round((sigma^2 / n), 2), \"), \",\n      \"Posteriori: N(\", round(mu_p_iq, 2), \", \", round(sigma_p_sq_iq, 2), \")\"\n    )\n  ) +\n  scale_color_manual(values = c(\n    \"A Priori\" = \"dodgerblue\",\n    \"Verosimiglianza (riscalata)\" = \"forestgreen\",\n    \"A Posteriori\" = \"orangered\"\n  )) +\n  theme(legend.title = element_blank(), legend.position = \"top\")\n\n\n\n\n\n\n\nDiscussione critica dei risultati\nL’analisi bayesiana ha prodotto una media a posteriori per il QI “globale” di \\(\\mu_n \\approx 89.36\\), con una deviazione standard a posteriori molto piccola (\\(\\sigma_n \\approx 1.66\\)). Questo valore è notevolmente inferiore alla media standard di 100.\nTuttavia, è cruciale interpretare questo risultato con estrema cautela, considerando diversi fattori limitanti e criticità:\n\n\nEffetto di Aggregazione (Ecological Fallacy): La media a posteriori è calcolata aggregando i dati QI medi di 80 nazioni. Questa media aggregata potrebbe non riflettere accuratamente la distribuzione del QI a livello individuale all’interno delle singole nazioni, né la vera distribuzione “globale” se si potessero testare tutti gli individui. Le differenze significative tra le nazioni (in termini di medie, varianze, e contesti socio-culturali) vengono “appiattite” in un unico valore, potenzialmente mascherando eterogeneità importanti.\n\nDati Non Ponderati: L’analisi tratta ogni nazione come un’singola osservazione, indipendentemente dalla sua popolazione. Nazioni con popolazioni molto diverse contribuiscono allo stesso modo alla stima della media \\(\\bar{y}\\). Una media ponderata per la popolazione potrebbe fornire un quadro diverso, sebbene anch’esso soggetto a critiche.\n\nContesto e Fattori Concomitanti: La deviazione dalla media standard di 100 potrebbe riflettere non solo (o non principalmente) differenze “reali” nell’intelligenza media, ma anche enormi disparità nei contesti sanitari, educativi, socio-economici e politici in cui i test sono stati (eventualmente) somministrati o i dati raccolti. Fattori come l’accesso all’istruzione di qualità, la nutrizione, la salute pubblica, e l’esposizione a stimoli cognitivi variano drasticamente tra le nazioni e possono influenzare significativamente i punteggi medi.\n\nBias Culturale dei Test: I test del QI sono stati storicamente sviluppati e standardizzati in contesti culturali specifici (principalmente occidentali, industrializzati). La loro applicabilità e validità cross-culturale è oggetto di un acceso dibattito. È possibile che i test stessi presentino bias culturali che portano a sottostimare le capacità cognitive in contesti culturali diversi da quello di origine, influenzando così le medie nazionali riportate.\n\nQualità e Origine dei Dati: I dati originali di Lynn e Vanhanen sono stati oggetto di numerose critiche metodologiche riguardanti la raccolta, la comparabilità e la qualità dei punteggi QI tra diverse nazioni. Utilizzare questi dati senza un esame approfondito delle loro limitazioni può portare a conclusioni fuorvianti.\n\nAssunzione di \\(\\sigma\\) Nota e Uguale: L’assunzione che \\(\\sigma=15\\) sia la deviazione standard rilevante per le medie nazionali è una forte semplificazione. La variabilità tra le medie nazionali potrebbe essere diversa dalla variabilità individuale all’interno di una popolazione di riferimento.\n\nIn conclusione, sebbene il modello Normale-Normale fornisca una stima quantitativa (\\(\\mu_n \\approx 89.36\\)), le profonde questioni metodologiche, concettuali ed etiche legate ai dati sul QI internazionale rendono problematica un’interpretazione diretta di questo valore come “vera” media globale dell’intelligenza. Questo esempio serve più come illustrazione meccanica dell’aggiornamento bayesiano che come un’affermazione sostanziale sul QI globale. Un’analisi seria richiederebbe modelli gerarchici più complessi, una discussione approfondita della validità dei dati e una considerazione attenta dei fattori contestuali.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Altre famiglie coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a35_other_conjugate_families.html#riflessioni-conclusive",
    "href": "chapters/appendix/a35_other_conjugate_families.html#riflessioni-conclusive",
    "title": "Appendice J — Altre famiglie coniugate",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nNei capitoli precedenti abbiamo visto come il concetto di coniugazione renda particolarmente semplice l’aggiornamento bayesiano. L’esempio Beta–Binomiale ci ha permesso di osservare in modo diretto come i parametri della distribuzione vengano modificati dai dati senza cambiare la forma della distribuzione stessa.\nIn questa appendice presentiamo altri casi di famiglie coniugate, meno immediati ma ugualmente interessanti. L’obiettivo non è memorizzare formule o cataloghi di distribuzioni, ma cogliere un principio generale: in alcune situazioni fortunate, i calcoli bayesiani diventano particolarmente trasparenti, perché il posterior appartiene alla stessa famiglia della prior.\nDal punto di vista della ricerca psicologica, non è indispensabile padroneggiare tutti questi casi. Nella pratica, la maggior parte dei modelli che incontreremo non ammetterà una forma coniugata, e dovremo ricorrere a metodi computazionali generali come il campionamento MCMC. Tuttavia, conoscere queste famiglie ha due vantaggi didattici:\n\npermette di consolidare l’intuizione su come i dati aggiornano i parametri, in contesti diversi da quello binomiale;\naiuta a riconoscere situazioni in cui i calcoli possono essere svolti senza simulazioni, facilitando l’analisi.\n\nSe è la prima volta che affronti questi argomenti, puoi leggere questa sezione in modo rapido, come un approfondimento facoltativo. Nei capitoli successivi torneremo a concentrarci sui metodi computazionali, che costituiscono lo strumento essenziale per affrontare i problemi psicologici reali.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nRiprendi i dati della SWLS che sono stati utilizzati nell’esercizio del ?sec-gauss-grid. Trova la media e la deviazione standard della distribuzione a posteriori usando il metodo delle distribuzioni coniugate. Confronta i risultati con quelli ottenuti con il metodo basato su griglia.\nConsegna: Carica il file .qmd, convertito in PDF, su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nPer risolvere questo esercizio con il metodo delle distribuzioni coniugate, assumiamo che i dati provengano da una distribuzione normale con deviazione standard nota e media da stimare. Nel caso di una verosimiglianza gaussiana con prior gaussiano, la distribuzione a posteriori sarà ancora una distribuzione normale. Questo approccio è analitico e ci permette di ottenere la media e la deviazione standard della distribuzione a posteriori senza dover ricorrere a metodi numerici come la discretizzazione della griglia.\nPassaggi per il calcolo della distribuzione a posteriori\n\n\nDefiniamo i dati osservati:\n\nLa media campionaria: \\(\\bar{x}\\)\n\nLa deviazione standard nota dei dati: \\(\\sigma\\)\n\nIl numero di osservazioni: \\(n\\)\n\n\n\n\nScegliamo un prior gaussiano molto diffuso:\n\nMedia a priori: \\(\\mu_0\\)\n\nDeviazione standard a priori molto grande: \\(\\sigma_0\\)\n\n\n\n\nCalcoliamo la media e la varianza della distribuzione a posteriori:\n\n\nLa media a posteriori è:\n\\[\n\\mu_{\\text{post}} = \\frac{\\sigma^2_0 \\bar{x} + \\sigma^2 n \\mu_0}{\\sigma^2_0 + \\sigma^2 n}\n\\]\n\n\nLa varianza a posteriori è:\n\\[\n\\sigma^2_{\\text{post}} = \\frac{\\sigma^2_0 \\sigma^2}{\\sigma^2_0 + \\sigma^2 n}\n\\]\n\n\n\n\nImplementazione in R\n# Caricamento librerie necessarie\nlibrary(dplyr)\nlibrary(tibble)\n\n# Dati SWLS\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n\n# Parametri comuni per entrambi i metodi\nsigma_conosciuta &lt;- sd(swls_data$soddisfazione)  # Usando la deviazione standard campionaria\nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\n\ncat(\"Deviazione standard campionaria:\", sigma_conosciuta, \"\\n\")\ncat(\"Media campionaria:\", mean_x, \"\\n\")\n\n# ---- Metodo 1: Griglia ----\n# Definizione della griglia più fine e centrata intorno alla media campionaria\nmu_griglia &lt;- seq(mean_x - 3*sigma_conosciuta/sqrt(n), \n                 mean_x + 3*sigma_conosciuta/sqrt(n), \n                 length.out = 1000)\n\n# Calcolo della verosimiglianza\nlog_likelihood &lt;- numeric(length(mu_griglia))\nfor (i in seq_along(mu_griglia)) {\n  # Utilizzo della log-likelihood per evitare problemi numerici\n  log_likelihood[i] &lt;- sum(dnorm(swls_data$soddisfazione, \n                                mean = mu_griglia[i], \n                                sd = sigma_conosciuta, \n                                log = TRUE))\n}\n\n# Prior uniforme (in scala logaritmica)\nlog_prior &lt;- rep(0, length(mu_griglia))\n\n# Calcolo della posteriori\nlog_posterior &lt;- log_likelihood + log_prior\nposterior &lt;- exp(log_posterior - max(log_posterior))\nposterior &lt;- posterior / sum(posterior)\n\n# Campionamento e calcolo statistiche\nsamples_grid &lt;- sample(mu_griglia, size = 10000, replace = TRUE, prob = posterior)\nmean_post_grid &lt;- mean(samples_grid)\nsd_post_grid &lt;- sd(samples_grid)\nci_grid &lt;- quantile(samples_grid, c(0.03, 0.97))\n\n# ---- Metodo 2: Soluzione analitica ----\n# Prior poco informativo ma non improprio\nmu_prior &lt;- mean_x\nsigma_prior &lt;- 10\n\n# Calcolo posteriori\nmu_post_analytic &lt;- (sigma_prior^2 * mean_x + sigma_conosciuta^2 * mu_prior/n) / \n                    (sigma_prior^2 + sigma_conosciuta^2/n)\nsigma_post_analytic &lt;- sqrt((sigma_prior^2 * sigma_conosciuta^2/n) / \n                           (sigma_prior^2 + sigma_conosciuta^2/n))\n\n# Confronto risultati\nresults &lt;- tibble(\n  Metodo = c(\"Griglia\", \"Analitico\"),\n  `Media Posteriori` = c(mean_post_grid, mu_post_analytic),\n  `Dev. Std. Posteriori` = c(sd_post_grid, sigma_post_analytic)\n)\nresults\nInterpretazione dei risultati\n\nLa media a posteriori rappresenta la miglior stima aggiornata della media della popolazione dopo aver osservato i dati.\nLa deviazione standard a posteriori ci dice quanto è incerta la nostra stima della media dopo aver integrato i dati e il prior.\n\nSiccome abbiamo scelto un prior molto diffuso (\\(\\sigma_0 = 10\\)), il risultato ottenuto è molto vicino a quello ottenuto con il metodo della griglia, dove il prior uniforme aveva un impatto minimo sulla distribuzione a posteriori.\nQuesta implementazione analitica permette di ottenere il risultato in modo efficiente senza necessità di metodi numerici approssimati.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] rmarkdown_2.29        nloptr_2.2.1          ragg_1.4.0           \n#&gt; [22] purrr_1.1.0           jomo_2.7-6            xfun_0.53            \n#&gt; [25] glmnet_4.1-10         cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [28] pan_1.9               broom_1.0.9           parallel_4.5.1       \n#&gt; [31] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [34] rpart_4.1.24          boot_1.3-32           lubridate_1.9.4      \n#&gt; [37] estimability_1.5.1    iterators_1.0.14      knitr_1.50           \n#&gt; [40] zoo_1.8-14            pacman_0.5.1          nnet_7.3-20          \n#&gt; [43] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [46] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [49] codetools_0.2-20      curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [52] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [55] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [58] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [61] foreach_1.5.2         stats4_4.5.1          reformulas_0.4.1     \n#&gt; [64] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [67] rstantools_2.4.0      scales_1.4.0          minqa_1.2.8          \n#&gt; [70] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [73] tools_4.5.1           lme4_1.1-37           mvtnorm_1.3-3        \n#&gt; [76] grid_4.5.1            rbibutils_2.3         QuickJSR_1.8.0       \n#&gt; [79] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [82] textshaping_1.0.1     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [85] V8_6.0.6              gtable_0.3.6          digest_0.6.37        \n#&gt; [88] TH.data_1.1-3         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [91] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [94] mitml_0.4-5           MASS_7.3-65",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Altre famiglie coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a35_other_conjugate_families.html#bibliografia",
    "href": "chapters/appendix/a35_other_conjugate_families.html#bibliografia",
    "title": "Appendice J — Altre famiglie coniugate",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGill, J. (2015). Bayesian methods: A social and behavioral sciences approach (3rd Edition). Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Altre famiglie coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a36_gamma_poisson_model.html",
    "href": "chapters/appendix/a36_gamma_poisson_model.html",
    "title": "Appendice K — Modello coniugato Gamma-Poisson",
    "section": "",
    "text": "Introduzione\nNei capitoli principali abbiamo introdotto l’idea di distribuzioni coniugate con il caso Beta–Binomiale, un laboratorio ideale per capire la logica dell’aggiornamento bayesiano in situazioni semplici. In questa appendice presentiamo un esempio parallelo: il modello Gamma–Poisson, particolarmente adatto per dati di conteggio, cioè quando osserviamo il numero di volte in cui si verifica un certo evento.\nLa struttura è analoga: la verosimiglianza è data dalla distribuzione di Poisson e la prior coniugata è una distribuzione Gamma. Grazie alla proprietà di coniugazione, il posterior risulta anch’esso una Gamma, ottenuta semplicemente aggiornando i parametri iniziali con i dati osservati. Questo ci permette di seguire passo passo la stessa logica vista nel caso binomiale: le assunzioni iniziali e l’evidenza empirica si combinano in modo trasparente, modificando i parametri della distribuzione senza alterarne la forma.\nLo scopo di questa appendice non è introdurre nuovo materiale concettuale, ma rafforzare l’intuizione su come funziona la coniugazione in un contesto diverso. Chi desidera un primo contatto pratico con i modelli per dati di conteggio troverà qui un esempio utile; chi preferisce concentrarsi sul flusso principale del manuale può considerare questa sezione come un approfondimento facoltativo.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a36_gamma_poisson_model.html#introduzione",
    "href": "chapters/appendix/a36_gamma_poisson_model.html#introduzione",
    "title": "Appendice K — Modello coniugato Gamma-Poisson",
    "section": "",
    "text": "Panoramica del capitolo\n\nComprendere la distribuzione di Poisson come un modello probabilistico adatto per descrivere eventi rari in un intervallo di tempo o spazio fisso.\nSapere applicare il metodo basato su griglia per derivare la distribuzione a posteriori del parametro \\(\\lambda\\) della distribuzione di Poisson.\nConoscere il modello coniugato Gamma-Poisson, dimostrando come la distribuzione a priori Gamma si combini con la verosimiglianza di Poisson per produrre una distribuzione a posteriori Gamma.\nSapere come calcolare e interpretare le probabilità utilizzando la distribuzione a posteriori.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il Capitolo 36 e il Capitolo 37 della dispensa.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(ggdist)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a36_gamma_poisson_model.html#distribuzione-di-poisson",
    "href": "chapters/appendix/a36_gamma_poisson_model.html#distribuzione-di-poisson",
    "title": "Appendice K — Modello coniugato Gamma-Poisson",
    "section": "\nK.1 Distribuzione di Poisson",
    "text": "K.1 Distribuzione di Poisson\nLa distribuzione di Poisson descrive fenomeni di conteggio, ovvero situazioni in cui si desidera conoscere il numero di volte in cui un certo evento si verifica in un intervallo di tempo o di spazio prestabilito. L’idea di fondo è semplice: immaginiamo che gli eventi si verifichino con una frequenza media costante e che ogni evento avvenga in modo indipendente dagli altri.\nSe una variabile casuale \\(Y\\) segue una distribuzione di Poisson con parametro \\(\\lambda\\), la probabilità di osservare un certo numero \\(y_i\\) di eventi è data da:\n\\[\nf(y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!}, \\quad y_i \\in \\{0,1,2,\\dots\\},\\ \\lambda &gt; 0,\n\\] dove il parametro \\(\\lambda\\) rappresenta il tasso medio di occorrenza degli eventi.\nUna caratteristica importante della distribuzione di Poisson è che la sua media e la sua varianza coincidono:\n\\[\nE(Y) = \\lambda, \\qquad \\text{Var}(Y) = \\lambda.\n\\] Ciò significa che, se in media si osservano 2 eventi per intervallo, anche la varianza attesa di questo valore sarà pari a 2.\n\nK.1.1 Un esempio psicologico\nPer rendere l’idea più concreta, immaginiamo un paziente affetto da disturbo ossessivo-compulsivo. Supponiamo che, in media, compia due azioni compulsive all’ora. In questo caso, il parametro della distribuzione di Poisson è \\(\\lambda = 2\\).\nLa formula ci permette di calcolare la probabilità di osservare esattamente k eventi in un’ora. Ad esempio:\n\nla probabilità di osservare 0 eventi è \\(\\frac{e^{-2} \\cdot 2^0}{0!} = e^{-2} \\approx 0.1353\\);\nla probabilità di osservare 1 evento è \\(\\frac{e^{-2} \\cdot 2^1}{1!} = 2e^{-2} \\approx 0.2707\\);\nla probabilità di osservare 2 eventi è \\(\\frac{e^{-2} \\cdot 2^2}{2!} = 2e^{-2} \\approx 0.2707\\).\n\nK.1.2 Calcoli in R\nPossiamo svolgere questi calcoli direttamente con R, utilizzando la funzione dpois:\n\nlam_true &lt;- 2\nk_values &lt;- 0:9\n\nprobabilities &lt;- dpois(k_values, lambda = lam_true)\n\nfor (i in seq_along(k_values)) {\n  cat(sprintf(\"Probabilità di %d eventi: %.4f\\n\", k_values[i], probabilities[i]))\n}\n#&gt; Probabilità di 0 eventi: 0.1353\n#&gt; Probabilità di 1 eventi: 0.2707\n#&gt; Probabilità di 2 eventi: 0.2707\n#&gt; Probabilità di 3 eventi: 0.1804\n#&gt; Probabilità di 4 eventi: 0.0902\n#&gt; Probabilità di 5 eventi: 0.0361\n#&gt; Probabilità di 6 eventi: 0.0120\n#&gt; Probabilità di 7 eventi: 0.0034\n#&gt; Probabilità di 8 eventi: 0.0009\n#&gt; Probabilità di 9 eventi: 0.0002\n\nQuesto codice calcola la probabilità di osservare tra 0 e 9 eventi in un’ora, dato che il tasso medio è 2. Si noti che i valori più probabili sono 1 o 2 eventi all’ora, mentre la probabilità di osservare molti più eventi diminuisce rapidamente.\n\nK.1.3 Visualizzazione grafica\nUn modo ancora più intuitivo per comprendere la distribuzione di Poisson è osservare il suo grafico. Il seguente codice permette di rappresentare la funzione di massa di probabilità (PMF) per \\(\\lambda = 2\\):\n\nlambd &lt;- 2\nx &lt;- 0:9  \ny &lt;- dpois(x, lambda = lambd)\n\ndf &lt;- data.frame(\n  numero_eventi = x,\n  probabilita = y\n)\n\nggplot(df, aes(x = numero_eventi, y = probabilita)) +\n  geom_segment(aes(x = numero_eventi, xend = numero_eventi, y = 0, yend = probabilita)) +\n  geom_point(size = 3) +\n  labs(x = \"Numero di eventi\", \n       y = \"Probabilità\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIl grafico mostra chiaramente che i valori centrati attorno a 2 hanno una probabilità maggiore, mentre la probabilità diminuisce rapidamente per valori più alti.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a36_gamma_poisson_model.html#distribuzione-gamma",
    "href": "chapters/appendix/a36_gamma_poisson_model.html#distribuzione-gamma",
    "title": "Appendice K — Modello coniugato Gamma-Poisson",
    "section": "\nK.2 Distribuzione Gamma",
    "text": "K.2 Distribuzione Gamma\nPer costruire un modello bayesiano con dati di tipo Poisson, è necessario scegliere una distribuzione a priori per il parametro di tasso \\(\\lambda\\). La scelta più comune, nonché la più conveniente dal punto di vista matematico, è la distribuzione Gamma. Questa distribuzione, infatti, è coniugata alla Poisson, il che significa che, partendo da una distribuzione a priori Gamma e aggiornandola con dati che seguono una distribuzione di Poisson, la distribuzione a posteriori appartiene ancora alla famiglia delle Gamma. In pratica, la coniugatezza ci permette di aggiornare le nostre credenze in modo semplice e diretto, senza dover affrontare calcoli complicati.\nLa densità della distribuzione Gamma è definita dalla formula:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x}, \\quad x &gt; 0.\n\\] In questa formula compaiono due parametri fondamentali:\n\n\n\\(\\alpha\\) (forma): controlla la forma della distribuzione. Con valori piccoli, la distribuzione è molto asimmetrica e concentrata vicino allo zero; aumentando il valore di \\(\\alpha\\), la distribuzione diventa più regolare e tende a assumere una forma simile a quella di una distribuzione normale.\n\n\\(\\beta\\) (tasso o “rate”): regola la scala della distribuzione. Con valori alti, la probabilità si concentra su valori più piccoli di \\(x\\); con valori bassi, invece, la distribuzione si allarga e assegna probabilità a valori più grandi.\n\nAlcuni esempi aiutano a chiarire:\n\ncon \\(\\alpha = 2\\) e \\(\\beta = 3\\), la distribuzione descrive un processo in cui gli eventi sono relativamente rari, ma non impossibili;\ncon \\(\\alpha = 10\\) e \\(\\beta = 1\\), invece, la distribuzione è molto più concentrata e simmetrica, a indicare un processo più regolare e prevedibile.\n\n\n\n\n\n\n\nIn R la distribuzione Gamma è parametrizzata usando direttamente \\(\\beta\\) come rate. Attenzione: a volte, in altri contesti, la stessa distribuzione viene scritta usando il parametro di scala (scale), che è semplicemente l’inverso del rate: \\(scale = 1/\\beta\\).\n\n\n\nIn R possiamo calcolare la densità della distribuzione Gamma con la funzione dgamma:\ndgamma(x, shape = alpha, rate = beta)\nAd esempio, per una Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\) possiamo scrivere:\n\nalpha &lt;- 2\nbeta &lt;- 3\n\nggplot(data.frame(x = c(0, 3)), aes(x = x)) +\n  stat_function(\n    fun = dgamma,\n    args = list(shape = alpha, rate = beta)\n  ) +\n  labs(\n    x = \"x\",\n    y = \"Densità di probabilità\"\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIl grafico mostra come la distribuzione si concentri intorno ai valori piccoli di x, ma lasci comunque una coda lunga verso destra. È proprio questa flessibilità a rendere la distribuzione gamma molto utile come modello a priori: può descrivere sia situazioni in cui ci si aspetta valori piccoli ma incerti, sia casi in cui si prevedono valori medi o alti con maggiore regolarità.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a36_gamma_poisson_model.html#la-coppia-coniugata-gammapoisson",
    "href": "chapters/appendix/a36_gamma_poisson_model.html#la-coppia-coniugata-gammapoisson",
    "title": "Appendice K — Modello coniugato Gamma-Poisson",
    "section": "\nK.3 La coppia coniugata Gamma–Poisson",
    "text": "K.3 La coppia coniugata Gamma–Poisson\nAbbiamo esaminato separatamente due elementi: la distribuzione di Poisson, che descrive il numero di eventi osservati, e la distribuzione Gamma, che abbiamo scelto come distribuzione a priori per il parametro di tasso \\(\\lambda\\). Ora possiamo unirli per costruire un modello bayesiano completo.\nIl cuore del ragionamento è il seguente:\n\ni dati osservati (\\(y_1, y_2, ..., y_N\\)) sono modellati come una distribuzione di Poisson con parametro \\(\\lambda\\);\nla nostra conoscenza a priori su \\(\\lambda\\) è rappresentata da una distribuzione Gamma con parametri \\(\\alpha_{\\text{prior}}\\) e \\(\\beta_{\\text{prior}}\\).\n\nQuesta combinazione è molto conveniente, perché la Gamma è coniugata alla Poisson. Ma cosa significa, concretamente, “coniugata”? Significa che, dopo aver osservato i dati, la distribuzione a posteriori di \\(\\lambda\\) rimane della stessa famiglia della distribuzione a priori, ovvero una distribuzione Gamma. In altre parole, se si parte da una distribuzione Gamma e la si aggiorna con dati di tipo Poisson, si ottiene ancora una distribuzione Gamma, ma i valori dei parametri cambiano, incorporando l’informazione proveniente dai dati.\n\nK.3.1 La distribuzione a posteriori\nLa regola di Bayes ci dice che:\n\\[\np(\\lambda \\mid y) \\propto p(\\lambda) \\cdot p(y \\mid \\lambda).\n\\] Sostituendo le due distribuzioni (Gamma per la prioritaria e Poisson per la verosimiglianza), si ottiene ancora una distribuzione Gamma. I parametri aggiornati sono:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + \\sum_{i=1}^N y_i ,\n\\]\n\\[\n\\beta_{\\text{post}} = \\beta_{\\text{prior}} + N .\n\\] Dunque, la nostra credenza su \\(\\lambda\\) dopo aver osservato i dati è rappresentata da una distribuzione:\n\\[\n\\lambda \\mid y \\sim \\text{Gamma}(\\alpha_{\\text{post}}, \\beta_{\\text{post}})\n\\]\n\nK.3.2 Intuizione\nIl meccanismo di aggiornamento bayesiano ammette un’interpretazione particolarmente intuitiva nel caso della distribuzione di Poisson. I parametri della distribuzione a posteriori, \\(\\alpha_{\\text{post}}\\) e \\(\\beta_{\\text{post}}\\), si ottengono semplicemente aggiornando quelli a priori, ovvero \\(\\alpha_0\\) e \\(\\beta_0\\), con le informazioni contenute nei dati.\n\nil parametro di forma, \\(\\alpha_{\\text{post}} = \\alpha_0 + \\sum_{i=1}^N y_i\\), cresce con il numero totale di eventi osservati; Ogni evento è considerato come un’unità di “evidenza” a favore di un certo tasso \\(\\lambda\\), spostando la distribuzione a posteriori verso valori più alti man mano che si accumulano le osservazioni.\nil parametro rate (tasso), \\(\\beta_{\\text{post}} = \\beta_0 + N\\), aumenta con il numero di intervalli osservati, N. Questo parametro controlla la dispersione della distribuzione: valori più alti di \\(\\beta\\) corrispondono a una minore varianza e, quindi, a una maggiore certezza nella stima di \\(\\lambda\\). Ogni nuovo intervallo di osservazione, indipendentemente dal numero di eventi in esso registrati, restringe la distribuzione a posteriori, perfezionando la stima.\n\nK.3.3 Un esempio numerico\nRiprendiamo l’esempio visto in precedenza con i dati:\n\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\nAbbiamo \\(N = 8\\) osservazioni, e come prior scegliamo \\(\\alpha_{\\text{prior}} = 9\\) e \\(\\beta_{\\text{prior}} = 2\\).\nCalcoliamo i nuovi parametri:\n\nalpha_post &lt;- 9 + sum(y)\nbeta_post  &lt;- 2 + length(y)\n\nalpha_post; beta_post\n#&gt; [1] 22\n#&gt; [1] 10\n\nIl risultato è \\(\\alpha_{\\text{post}} = 22\\) e \\(\\beta_{\\text{post}} = 10\\). La nostra distribuzione a posteriori è quindi una Gamma(22, 10), che rappresenta la nuova convinzione su \\(\\lambda\\) dopo aver osservato i dati.\n\nK.3.4 Visualizzare la distribuzione a posteriori\nPossiamo visualizzare il cambiamento confrontando la prior e la posterior:\n\nx &lt;- seq(0, 6, length.out = 500)\n\nprior_density &lt;- dgamma(x, shape = 9, rate = 2)\npost_density  &lt;- dgamma(x, shape = alpha_post, rate = beta_post)\n\ndf &lt;- data.frame(\n  x = rep(x, 2),\n  densita = c(prior_density, post_density),\n  Distribuzione = rep(c(\"Prior\", \"Posterior\"), each = length(x))\n)\n\nggplot(df, aes(x = x, y = densita, color = Distribuzione)) +\n  geom_line(size = 1) +\n  labs(\n    x = expression(lambda),\n    y = \"Densità\"\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIl grafico mostra chiaramente che la posterior è più concentrata: osservare gli otto dati ci ha reso più sicuri del valore di \\(\\lambda\\). Inoltre, il centro della distribuzione si è spostato verso il valore suggerito dai dati, integrando così le informazioni empiriche con le credenze iniziali.\n\nK.3.5 Metodo basato su griglia\nOra che abbiamo introdotto il modello Gamma–Poisson, possiamo provare a calcolare la distribuzione a posteriori del parametro \\(\\lambda\\) non con formule chiuse, ma con un procedimento puramente numerico. Questo approccio prende il nome di metodo su griglia (grid approximation), ed è molto utile come strumento didattico, in quanto mostra, passo dopo passo, il funzionamento dell’aggiornamento bayesiano, trasformando le regole matematiche in un algoritmo semplice da eseguire al computer.\nL’idea è la seguente:\n\nfissiamo una griglia di possibili valori per \\(\\lambda\\);\ncalcoliamo la probabilità di ciascun valore secondo la prioria;\ncalcoliamo, per gli stessi valori, la verosimiglianza dei dati osservati;\nmoltiplichiamo i due risultati per ottenere la distribuzione a posteriori (non ancora normalizzata);\nnormalizziamo in modo che la somma totale sia pari a 1.\n\n\nK.3.5.1 I dati e la prior\nPrendiamo gli stessi dati già usati in precedenza, cioè il numero di compulsioni osservate in otto intervalli di tempo:\n\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\nLa priori scelta per \\(\\lambda\\) è una Gamma con parametri \\(\\alpha = 9\\) e \\(\\beta = 2\\), che riflette la nostra convinzione iniziale che il tasso medio sia intorno a 4–5 eventi, con un certo margine di incertezza.\nCreiamo una griglia di valori plausibili di \\(\\lambda\\), ad esempio da 0 a 10, divisa in 1000 punti:\n\nalpha_prior &lt;- 9\nbeta_prior  &lt;- 2\n\nlambda_grid &lt;- seq(0.01, 10, length.out = 1000)\n\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\nQuesta curva rappresenta ciò che crediamo possibile prima di vedere i dati.\n\nK.3.5.2 La verosimiglianza\nLa seconda componente è la verosimiglianza, cioè quanto ciascun valore ipotetico di \\(\\lambda\\) rende probabili i dati osservati. Per una Poisson, la verosimiglianza è il prodotto delle probabilità individuali:\n\\[\n\\mathcal{L}(\\lambda) = \\prod_{i=1}^N P(Y = y_i \\mid \\lambda).\n\\]\nIn R possiamo calcolarla in modo vettoriale:\n\nlikelihood &lt;- sapply(lambda_grid, function(l) prod(dpois(y, l)))\n\nCosì, per ogni punto della griglia otteniamo il valore della verosimiglianza: se il dato osservato è molto coerente con un certo \\(\\lambda\\), la verosimiglianza sarà alta; altrimenti sarà vicina a zero.\n\nK.3.5.3 La distribuzione a posteriori\nIl passo successivo è combinare priori e verosimiglianza. La regola di Bayes ci dice che:\n\\[\np(\\lambda \\mid y) \\propto p(\\lambda) \\cdot \\mathcal{L}(\\lambda).\n\\] In pratica, moltiplichiamo i valori calcolati ai due passi precedenti:\n\nposterior_unnormalized &lt;- prior * likelihood\n\nQuesto ci dà una curva che ha la forma giusta, ma che non è ancora una vera distribuzione di probabilità: non somma a 1.\n\nK.3.5.4 Normalizzazione\nPer trasformarla in una distribuzione valida, dobbiamo normalizzare, cioè dividere per la somma totale (che qui approssimiamo come una somma numerica sulla griglia):\n\ngrid_width &lt;- lambda_grid[2] - lambda_grid[1]\nnormalization_factor &lt;- sum(posterior_unnormalized) * grid_width\n\nposterior &lt;- posterior_unnormalized / normalization_factor\n\nOra abbiamo davvero la distribuzione a posteriori di \\(\\lambda\\).\n\nK.3.5.5 Interpretazione e confronto visivo\nA questo punto possiamo confrontare la priori e la posteriori in un unico grafico:\n\ndf &lt;- data.frame(\n  lambda     = lambda_grid,\n  Prior      = prior,\n  Posteriori = posterior\n)\n\ndf_long &lt;- pivot_longer(df, cols = c(\"Prior\", \"Posteriori\"),\n                        names_to = \"Distribuzione\",\n                        values_to = \"Densita\")\n\nggplot(df_long, aes(x = lambda, y = Densita, color = Distribuzione)) +\n  geom_line(size = 1) +\n  labs(x = expression(lambda),\n       y = \"Densità\")\n\n\n\n\n\n\n\nIl grafico rivela due aspetti fondamentali:\n\nla posteriori è spostata rispetto alla priori, perché i dati suggeriscono valori di \\(\\lambda\\) più bassi di quanto ci aspettassimo inizialmente;\nla posteriori è anche più concentrata, cioè meno incerta: dopo aver osservato i dati, non solo abbiamo aggiornato la nostra convinzione, ma siamo anche diventati più sicuri del valore plausibile di \\(\\lambda\\).\n\nK.3.6 Perché è utile il metodo a griglia?\nQuesto metodo non è molto efficiente nei problemi complessi (dove i parametri sono numerosi e lo spazio da esplorare è vasto), ma è molto utile a scopo didattico. Ci mostra infatti in modo visivo e intuitivo il funzionamento dell’aggiornamento bayesiano: partiamo da una convinzione iniziale (la prior), la confrontiamo con i dati (la likelihood) e otteniamo una nuova convinzione aggiornata (la posterior).\nNei prossimi capitoli vedremo come affrontare lo stesso problema con strumenti più generali, come il campionamento MCMC in Stan, che diventano indispensabili quando i modelli si complicano e il metodo su griglia non è più praticabile.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a36_gamma_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/appendix/a36_gamma_poisson_model.html#riflessioni-conclusive",
    "title": "Appendice K — Modello coniugato Gamma-Poisson",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl modello Gamma–Poisson ci mostra che la logica delle famiglie coniugate non è limitata al caso dei dati binari, ma si estende in modo naturale a dati di altra natura, come i conteggi. Anche in questo caso, il teorema di Bayes fornisce un aggiornamento semplice e cumulativo: i parametri della distribuzione prior si modificano alla luce dei dati, producendo un posterior facilmente interpretabile.\nDal punto di vista didattico, questo esempio ha il valore di rendere più generale l’intuizione acquisita con il Beta–Binomiale, mostrando la ricorrenza della coniugazione in contesti diversi. Dal punto di vista applicativo, invece, è bene sottolineare che la coniugazione rimane un caso speciale. Nella maggior parte delle situazioni psicologiche reali non possiamo contare su soluzioni analitiche così eleganti, ed è per questo che nei capitoli principali del manuale ci concentriamo su metodi computazionali più generali, come il campionamento MCMC.\nIn sintesi, il modello Gamma–Poisson è un’utile illustrazione supplementare: non rappresenta un passaggio essenziale per la comprensione del manuale, ma offre un’occasione per consolidare le idee chiave e per intravedere la varietà di applicazioni in cui l’approccio bayesiano può essere adottato.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo uno studio longitudinale su coppie, dove i partecipanti registrano quotidianamente la frequenza con cui nascondono il loro comportamento di fumo al partner. Basandoci sui dati di Scholz et al. (2021), assumiamo che il tasso medio di nascondere il fumo sia di 1.52 volte al giorno. Supponiamo di avere i seguenti dati giornalieri per un partecipante:\n\nGiorno 1: 2 volte.\nGiorno 2: 0 volte.\nGiorno 3: 1 volta.\nGiorno 4: 3 volte.\n\nUtilizzare un modello Gamma-Poisson per stimare la distribuzione a posteriori del tasso individuale di nascondere il fumo per un partecipante specifico, dato il suo insieme di osservazioni giornaliere.\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nVogliamo stimare quante volte al giorno una persona tende a nascondere il proprio fumo al partner. Abbiamo quattro giorni di dati su questa persona e, grazie a un precedente studio, sappiamo che in media le persone lo fanno circa 1.52 volte al giorno.\nMa i dati di una sola persona sono pochi, quindi useremo un approccio bayesiano per combinare:\n\n\nLe informazioni preesistenti (dal precedente studio),\n\nLe nuove osservazioni (quanti eventi sono stati registrati nei quattro giorni).\n\nCon un modello Gamma-Poisson, possiamo aggiornare la nostra stima e ottenere una distribuzione a posteriori, che ci dirà quali sono i valori più probabili per il tasso di nascondimento di questa persona.\n# Dati osservati: numero di volte che la persona ha nascosto il fumo ogni giorno\nosservazioni &lt;- c(2, 0, 1, 3)\n\n# Numero totale di giorni osservati\nn_giorni &lt;- length(osservazioni)\n\n# Numero totale di eventi (quante volte ha nascosto il fumo in totale)\neventi_totali &lt;- sum(osservazioni)\n\n# Informazione a priori dallo studio precedente\nmedia_priori &lt;- 1.52\nforma_priori &lt;- 3   # Parametro di forma scelto per un'incertezza moderata\ntasso_priori &lt;- forma_priori / media_priori  # Parametro di scala\n\n# Aggiornamento bayesiano: parametri della distribuzione a posteriori\nforma_post &lt;- forma_priori + eventi_totali\ntasso_post &lt;- tasso_priori + n_giorni\n\n# Creazione della griglia di valori possibili per il tasso giornaliero (lambda)\nlambda_valori &lt;- seq(0, 5, length.out = 100)\n\n# Calcolo delle densità per le distribuzioni a priori e a posteriori\ndensita_priori &lt;- dgamma(lambda_valori, shape = forma_priori, rate = tasso_priori)\ndensita_post &lt;- dgamma(lambda_valori, shape = forma_post, rate = tasso_post)\n\n# Creazione di un dataframe per il grafico\ndati_plot &lt;- data.frame(\n  lambda = rep(lambda_valori, 2),\n  densita = c(densita_priori, densita_post),\n  distribuzione = rep(c(\"Priori\", \"Posteriori\"), each = length(lambda_valori))\n)\n\n# Creazione del grafico per confrontare la distribuzione a priori e quella aggiornata (posteriori)\nggplot(dati_plot, aes(x = lambda, y = densita, color = distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(\n    x = \"Tasso giornaliero (λ)\",\n    y = \"Densità\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\nCosa fa questo codice\n\n\nCarica i dati: abbiamo registrato per 4 giorni quante volte questa persona ha nascosto il fumo.\n\nImposta una conoscenza iniziale (priori): basata sullo studio precedente.\n\nApplica il teorema di Bayes per aggiornare la stima con i nuovi dati.\n\nGenera il grafico: confronta la distribuzione prima e dopo l’aggiornamento con i dati osservati.\n\nInterpretazione del risultato\n\nLa curva rossa (priori) rappresenta la nostra stima iniziale, basata sullo studio precedente.\nLa curva blu (posteriori) è la nostra nuova stima dopo aver considerato i dati della persona.\nSe i dati raccolti sono molto diversi dal valore medio dello studio, la curva blu si sposterà rispetto alla rossa.\n\nQuesta analisi ci permette di stimare il comportamento specifico di una persona integrando dati generali e osservazioni individuali, in modo più informativo rispetto a una semplice media.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-3         tensorA_0.36.2.1     \n#&gt;  [7] pacman_0.5.1          digest_0.6.37         timechange_0.3.0     \n#&gt; [10] estimability_1.5.1    lifecycle_1.0.4       survival_3.8-3       \n#&gt; [13] magrittr_2.0.3        compiler_4.5.1        rlang_1.1.6          \n#&gt; [16] tools_4.5.1           knitr_1.50            labeling_0.4.3       \n#&gt; [19] bridgesampling_1.1-2  htmlwidgets_1.6.4     curl_7.0.0           \n#&gt; [22] pkgbuild_1.4.8        RColorBrewer_1.1-3    abind_1.4-8          \n#&gt; [25] multcomp_1.4-28       withr_3.0.2           purrr_1.1.0          \n#&gt; [28] grid_4.5.1            stats4_4.5.1          colorspace_2.1-1     \n#&gt; [31] xtable_1.8-4          inline_0.3.21         emmeans_1.11.2-8     \n#&gt; [34] scales_1.4.0          MASS_7.3-65           cli_3.6.5            \n#&gt; [37] mvtnorm_1.3-3         rmarkdown_2.29        ragg_1.4.0           \n#&gt; [40] generics_0.1.4        RcppParallel_5.1.11-1 cachem_1.1.0         \n#&gt; [43] stringr_1.5.1         splines_4.5.1         parallel_4.5.1       \n#&gt; [46] vctrs_0.6.5           V8_6.0.6              Matrix_1.7-4         \n#&gt; [49] sandwich_3.1-1        jsonlite_2.0.0        arrayhelpers_1.1-0   \n#&gt; [52] systemfonts_1.2.3     glue_1.8.0            codetools_0.2-20     \n#&gt; [55] distributional_0.5.0  lubridate_1.9.4       stringi_1.8.7        \n#&gt; [58] gtable_0.3.6          QuickJSR_1.8.0        htmltools_0.5.8.1    \n#&gt; [61] Brobdingnag_1.2-9     R6_2.6.1              textshaping_1.0.1    \n#&gt; [64] rprojroot_2.1.1       evaluate_1.0.5        lattice_0.22-7       \n#&gt; [67] backports_1.5.0       memoise_2.0.1         broom_1.0.9          \n#&gt; [70] snakecase_0.11.1      rstantools_2.4.0      coda_0.19-4.1        \n#&gt; [73] gridExtra_2.3         nlme_3.1-168          checkmate_2.3.3      \n#&gt; [76] xfun_0.53             zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a36_gamma_poisson_model.html#bibliografia",
    "href": "chapters/appendix/a36_gamma_poisson_model.html#bibliografia",
    "title": "Appendice K — Modello coniugato Gamma-Poisson",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nScholz, U., Stadler, G., Berli, C., Lüscher, J., & Knoll, N. (2021). How do people experience and respond to social control from their partner? Three daily diary studies. Frontiers in Psychology, 11, 613546.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html",
    "href": "chapters/appendix/a41_cmdstanr_intro.html",
    "title": "Appendice L — Implementazione di modelli Bayesiani con Stan tramite cmdstanr",
    "section": "",
    "text": "Obiettivo\nIn questa sezione dell’appendice presentiamo una guida pratica all’implementazione di modelli Bayesiani utilizzando Stan attraverso l’interfaccia cmdstanr in R. Il framework cmdstanr rappresenta l’evoluzione moderna delle interfacce R per Stan, offrendo prestazioni ottimizzate e un workflow semplificato per l’inferenza Bayesiana.\nIllustreremo il flusso di lavoro completo attraverso i seguenti passaggi:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Implementazione di modelli Bayesiani con Stan tramite `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#obiettivo",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#obiettivo",
    "title": "Appendice L — Implementazione di modelli Bayesiani con Stan tramite cmdstanr",
    "section": "",
    "text": "Preparazione e input dei dati: strutturare i dati per l’analisi in Stan.\n\nCompilazione del modello: trasformazione del codice Stan in eseguibile ottimizzato.\n\nCampionamento MCMC: esecuzione efficiente degli algoritmi di campionamento.\n\nEstrazione e analisi dei risultati: elaborazione degli output campionati.\n\nDiagnostica e visualizzazione: validazione del modello e rappresentazione grafica.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Implementazione di modelli Bayesiani con Stan tramite `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#pacchetti-necessari",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#pacchetti-necessari",
    "title": "Appendice L — Implementazione di modelli Bayesiani con Stan tramite cmdstanr",
    "section": "\nL.3 Pacchetti necessari",
    "text": "L.3 Pacchetti necessari\nPer lavorare ci servono alcuni pacchetti:\n\nsuppressPackageStartupMessages({\n  library(tidyverse)   # per manipolare i dati\n  library(cmdstanr)    # interfaccia R per Stan\n  library(posterior)   # per lavorare con i campioni MCMC\n  library(bayesplot)   # per visualizzare i risultati\n  library(here)        # per gestire i percorsi ai file\n})\n\nset.seed(42) # per riproducibilità",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Implementazione di modelli Bayesiani con Stan tramite `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#un-esempio-semplice-modello-beta-binomiale",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#un-esempio-semplice-modello-beta-binomiale",
    "title": "Appendice L — Implementazione di modelli Bayesiani con Stan tramite cmdstanr",
    "section": "\nL.4 Un esempio semplice: modello beta-binomiale",
    "text": "L.4 Un esempio semplice: modello beta-binomiale\nConsideriamo il seguente scenario sperimentale: in un esperimento bernoulliano abbiamo osservato 6 successi su 9 prove. L’obiettivo dell’analisi è stimare la distribuzione a posteriori della probabilità di successo \\(\\theta\\).\nA questo scopo, adottiamo come distribuzione a priori una Beta(2, 2), scelta in quanto debolmente informativa e in grado di esprimere una moderata convinzione preliminare sulla simmetria della probabilità di successo, pur mantenendo una sufficiente flessibilità per permettere ai dati di guidare l’inferenza.\nIl modello Stan è già stato scritto in un file beta_binomial_model.stan. Il codice Stan è identico indipendentemente dall’interfaccia (R, Python, Julia, …).\n\nL.4.1 Passare i dati a Stan\nStan richiede che i dati siano in una lista di R con i nomi esattamente uguali a quelli usati nel file .stan.\n\ndata_list &lt;- list(\n  N = 9,          # numero di prove\n  y = 6,          # numero di successi\n  alpha_prior = 2, # parametri del prior\n  beta_prior = 2\n)\n\n\nL.4.2 Leggere e compilare il modello\nDiciamo a R dove si trova il file .stan e lo compiliamo:\n\nfile &lt;- file.path(here::here(\"stan\", \"beta_binomial_model.stan\"))\nfile\n\nmod &lt;- cmdstan_model(file)  # compila il modello\n\nL’oggetto mod rappresenta il modello Stan compilato. Possiamo visualizzarne le informazioni:\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=1&gt; N;                       // numero di prove\n#&gt;   int&lt;lower=0, upper=N&gt; y;              // successi osservati\n#&gt;   real&lt;lower=0&gt; alpha_prior;            // Beta prior: alpha\n#&gt;   real&lt;lower=0&gt; beta_prior;             // Beta prior: beta\n#&gt; }\n#&gt; parameters {\n#&gt;   real&lt;lower=0, upper=1&gt; theta;         // probabilità di successo\n#&gt; }\n#&gt; model {\n#&gt;   // Prior\n#&gt;   theta ~ beta(alpha_prior, beta_prior);\n#&gt;   // Likelihood\n#&gt;   y ~ binomial(N, theta);\n#&gt; }\n#&gt; generated quantities {\n#&gt;   // Replica del dato per pp_check\n#&gt;   int y_rep = binomial_rng(N, theta);\n#&gt; \n#&gt;   // Log-likelihood del dato osservato (per LOO/WAIC)\n#&gt;   real log_lik = binomial_lpmf(y | N, theta);\n#&gt; }\n\n\nL.4.3 Eseguire l’algoritmo MCMC\nPer stimare i parametri usiamo il metodo $sample(). Questo esegue l’algoritmo MCMC di Stan:\n\nfit &lt;- mod$sample(\n  data = data_list,\n  seed = 123,\n  chains = 4,            # numero di catene\n  parallel_chains = 4    # quante catene girano in parallelo\n)\n\nNota: per default ogni catena produce 1000 campioni dopo il warmup, quindi avremo 4000 campioni posteriori.\n\nL.4.4 Estrarre i campioni\nI campioni possono essere estratti in diversi formati. Per esempio, come array a 3 dimensioni (iterazioni × catene × variabili):\n\ndraws_arr &lt;- fit$draws()\nstr(draws_arr)\n#&gt;  'draws_array' num [1:1000, 1:4, 1:4] -8.67 -8.76 -8.68 -11.81 -8.71 ...\n#&gt;  - attr(*, \"dimnames\")=List of 3\n#&gt;   ..$ iteration: chr [1:1000] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;   ..$ chain    : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n#&gt;   ..$ variable : chr [1:4] \"lp__\" \"theta\" \"y_rep\" \"log_lik\"\ndim(draws_arr)\n#&gt; [1] 1000    4    4\n\nOppure come data frame lungo:\n\ndraws_df &lt;- as_draws_df(fit)\nhead(draws_df)\n#&gt; # A draws_df: 6 iterations, 1 chains, and 4 variables\n#&gt;    lp__ theta y_rep log_lik\n#&gt; 1  -8.7  0.60     8    -1.4\n#&gt; 2  -8.8  0.67     9    -1.3\n#&gt; 3  -8.7  0.59     6    -1.4\n#&gt; 4 -11.8  0.89     9    -2.8\n#&gt; 5  -8.7  0.57     7    -1.5\n#&gt; 6  -8.7  0.61     8    -1.4\n#&gt; # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nL.4.5 Statistiche riassuntive\nIl metodo $summary() calcola statistiche posteriori (medie, deviazioni standard, quantili, ecc.):\n\nfit$summary(variables = \"theta\")\n#&gt; # A tibble: 1 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 theta    0.620  0.628 0.129 0.132 0.394 0.820 1.005 1247.337 1842.290\n\nPossiamo specificare statistiche personalizzate, ad esempio:\n\nfit$summary(\n  variables = \"theta\", \n  mean, \n  sd,\n  ~quantile(.x, probs = c(0.03, 0.97))\n)\n#&gt; # A tibble: 1 × 5\n#&gt;   variable  mean    sd  `3%` `97%`\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 theta    0.620 0.129 0.362 0.843\n\n\nL.4.6 Esempio di test bayesiano\nPossiamo stimare la probabilità che \\(\\theta \\leq 0.5\\):\n\nfit$summary(\"theta\", pr_less_05 = ~ mean(. &lt;= 0.5))\n#&gt; # A tibble: 1 × 2\n#&gt;   variable pr_less_05\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;\n#&gt; 1 theta         0.180\n\n\nL.4.7 Visualizzare i campioni\nIl pacchetto bayesplot semplifica la creazione di grafici. Ad esempio, un istogramma della distribuzione posteriore di \\(\\theta\\):\n\nmcmc_hist(fit$draws(\"theta\"))\n\n\n\n\n\n\n\n\nL.4.8 Diagnostica del campionatore\nPer verificare che l’MCMC abbia funzionato correttamente:\n\nfit$diagnostic_summary()\n#&gt; $num_divergent\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $num_max_treedepth\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $ebfmi\n#&gt; [1] 1.150 0.882 1.223 1.165\n\nÈ anche possibile accedere alle variabili interne del campionatore (es. profondità dell’albero, divergenze):\n\nhead(fit$sampler_diagnostics(format = \"df\"))\n#&gt; # A draws_df: 6 iterations, 1 chains, and 6 variables\n#&gt;   treedepth__ divergent__ energy__ accept_stat__ stepsize__ n_leapfrog__\n#&gt; 1           2           0     11.9          1.00       0.93            3\n#&gt; 2           2           0      9.0          0.96       0.93            3\n#&gt; 3           2           0      8.7          1.00       0.93            7\n#&gt; 4           2           0     11.8          0.63       0.93            3\n#&gt; 5           2           0     11.2          1.00       0.93            7\n#&gt; 6           2           0      8.7          1.00       0.93            3\n#&gt; # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\nSe ci sono problemi (molte divergenze, R-hat alto, ecc.), occorre rivedere il modello o i parametri di campionamento.\n\nL.4.9 Conclusioni\nIn conclusione, abbiamo visto i passaggi fondamentali per usare cmdstanr:\n\npreparare i dati in una lista;\ncompilare il modello Stan;\nlanciare il campionamento MCMC;\nestrarre e riassumere i campioni;\nvisualizzare i risultati e controllare la diagnostica.\n\nQuesta procedura è la base di ogni analisi con Stan via R: indipendentemente dal modello, i passaggi saranno sempre questi.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Implementazione di modelli Bayesiani con Stan tramite `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html",
    "href": "chapters/appendix/a47_first_order_markov.html",
    "title": "Appendice M — Catene di Markov",
    "section": "",
    "text": "M.1 Classificazione degli Stati\nIl processo di Markov di primo ordine è un concetto fondamentale in molti campi, tra cui l’intelligenza artificiale, la statistica e la teoria delle probabilità. Questo modello probabilistico rappresenta un equilibrio tra la semplicità delle variabili casuali indipendenti e la complessità delle interazioni tra variabili. Per chiarire il concetto, consideriamo una sequenza temporale di eventi rappresentata da variabili casuali \\(X_0, X_1, ..., X_n, ...\\). In molti fenomeni reali, queste variabili non sono né completamente indipendenti né totalmente interdipendenti. Una catena di Markov rappresenta un compromesso tra questi due estremi.\nIn questo contesto, ci concentreremo su catene di Markov con stati discreti e tempo discreto. Ciò significa che le variabili \\(X_n\\) possono assumere valori in un insieme finito, tipicamente indicato come \\(\\{1, 2, ..., M\\}\\), e che gli eventi si verificano in momenti distinti e numerabili. La proprietà fondamentale di una catena di Markov può essere espressa matematicamente con la seguente equazione:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, ..., X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nQuesta equazione indica che il futuro (rappresentato da \\(X_{n+1}\\)) dipende solo dal presente (\\(X_n\\)) e non dal passato (\\(X_{n-1}, ..., X_0\\)). La proprietà di Markov può essere vista come un primo allentamento dell’assunzione di indipendenza: le variabili casuali sono dipendenti in un modo specifico che risulta matematicamente conveniente.\nQuantità importanti associate a una catena di Markov sono le probabilità condizionate, chiamate probabilità di transizione:\n\\[\nP(X_{n+1} = j \\mid X_n = i).\n\\]\nLa probabilità \\(P(X_{n+1} = j \\mid X_n = i)\\), nota come probabilità di transizione, rappresenta la probabilità di passare dallo stato \\(i\\) allo stato \\(j\\) in un singolo passo.\nPer descrivere completamente una catena di Markov, si utilizza una matrice \\(Q\\), chiamata matrice di transizione. Questa è una matrice \\(M \\times M\\) in cui ogni elemento \\(q_{ij}\\) rappresenta la probabilità di transizione dallo stato \\(i\\) allo stato \\(j\\). Un’importante caratteristica della matrice di transizione è che la somma degli elementi di ogni riga deve essere pari a 1, poiché partendo da uno stato qualsiasi, il sistema deve necessariamente transitare in uno degli stati possibili.\nPer chiarire ulteriormente il concetto, consideriamo un modello di previsione del tempo a Firenze con tre possibili condizioni meteorologiche: soleggiato, piovoso e nebbioso. Di seguito è riportata una matrice di transizione che rappresenta le probabilità di passaggio da un tipo di tempo all’altro:\nVediamo come calcolare alcune probabilità:\nIl modello di Markov di base assume che le probabilità di transizione rimangano costanti nel tempo, una proprietà nota come omogeneità temporale. Questo significa che, per esempio, la probabilità di passare dallo stato “soleggiato” allo stato “piovoso” è la stessa in qualsiasi periodo dell’anno.\nIn sintesi, l’utilità del modello di Markov risiede nella sua capacità di semplificare notevolmente i calcoli probabilistici. Invece di considerare l’intera storia passata del sistema, è sufficiente conoscere solo lo stato attuale per fare previsioni sul futuro. Questa caratteristica, nota come “assenza di memoria”, rende il modello estremamente utile in molte applicazioni pratiche, dalla modellazione di fenomeni naturali alla progettazione di algoritmi di apprendimento automatico. Il processo di Markov di primo ordine offre uno strumento potente per analizzare e prevedere il comportamento di sistemi complessi nel tempo, bilanciando la necessità di catturare le dipendenze temporali con la semplicità computazionale. La sua versatilità e applicabilità in diversi campi lo rendono un concetto chiave per comprendere e modellare molti fenomeni del mondo reale.\nConsideriamo ora la terminologia usata per descrivere le varie caratteristiche di una catena di Markov.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#classificazione-degli-stati",
    "href": "chapters/appendix/a47_first_order_markov.html#classificazione-degli-stati",
    "title": "Appendice M — Catene di Markov",
    "section": "",
    "text": "M.1.1 Catene di Markov Irriducibili\nUna catena di Markov è detta irriducibile se, per qualsiasi coppia di stati \\(i\\) e \\(j\\), esiste una probabilità positiva di passare dallo stato \\(i\\) allo stato \\(j\\) in un numero finito di passi. In altre parole, una catena irriducibile non ha stati isolati: ogni stato è raggiungibile da qualsiasi altro stato.\n\n\nM.1.2 Stati Ricorrenti\nUno stato \\(i\\) di una catena di Markov si dice ricorrente se, partendo da \\(i\\), la probabilità di ritornarvi è uguale a 1. Questo implica che una volta raggiunto lo stato \\(i\\), è garantito che la catena tornerà in \\(i\\) prima o poi. Gli stati ricorrenti possono essere ulteriormente classificati come:\n\nPositivamente ricorrenti: uno stato è positivamente ricorrente se il tempo medio atteso per ritornare in quello stato, partendo da esso, è finito.\nNullamente ricorrenti: uno stato è nullamente ricorrente se il tempo medio atteso per ritornare in quello stato è infinito.\nRicorrenti di Harris: sono stati ricorrenti che vengono visitati infinite volte quando il tempo tende all’infinito, garantendo una certa frequenza di visita.\n\n\n\nM.1.3 Aperiodicità\nUno stato \\(i\\) si dice aperiodico se il massimo comun divisore dei tempi di ritorno in \\(i\\) è 1. In altre parole, uno stato è aperiodico se non esiste un ciclo deterministico che vincola i tempi in cui la catena può ritornare in quello stato. Una catena di Markov è aperiodica se tutti i suoi stati sono aperiodici. L’aperiodicità evita che la catena rimanga bloccata in una sequenza ciclica fissa, permettendo un comportamento più variegato nel tempo.\n\n\nM.1.4 Stazionarietà\nNella teoria delle catene di Markov, una distribuzione stazionaria \\(\\pi\\) è una distribuzione di probabilità sugli stati tale che, se la catena parte con questa distribuzione iniziale, la distribuzione delle probabilità rimane invariata nel tempo. Matematicamente, se \\(\\pi\\) è la distribuzione stazionaria, allora \\(\\pi P = \\pi\\), dove \\(P\\) è la matrice di transizione della catena di Markov. La stazionarietà è fondamentale per analizzare il comportamento a lungo termine della catena, poiché una volta raggiunta, la distribuzione di probabilità sugli stati rimane costante.\n\n\nM.1.5 Ergodicità\nUna catena di Markov si dice ergodica se è irriducibile e aperiodica, e tutti i suoi stati sono positivamente ricorrenti. Questo implica che la catena, nel lungo termine, visita tutti gli stati secondo una distribuzione di probabilità che diventa stabile (stazionaria) e non dipende dallo stato iniziale. La proprietà di ergodicità è cruciale in quanto garantisce che le medie temporali di una funzione sugli stati della catena convergono alle medie rispetto alla distribuzione stazionaria.\n\n\nM.1.6 Convergenza\nLa convergenza di una catena di Markov si riferisce al processo mediante il quale la distribuzione di probabilità degli stati si avvicina alla distribuzione stazionaria \\(\\pi\\) man mano che il numero di passi \\(n\\) tende all’infinito. In altre parole, indipendentemente dalla distribuzione iniziale degli stati, la distribuzione della catena dopo un lungo periodo di tempo sarà vicina a \\(\\pi\\). Questo concetto è strettamente legato alla stazionarietà, poiché la convergenza descrive il percorso verso l’equilibrio, mentre la stazionarietà rappresenta lo stato di equilibrio raggiunto.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#sommario",
    "href": "chapters/appendix/a47_first_order_markov.html#sommario",
    "title": "Appendice M — Catene di Markov",
    "section": "M.2 Sommario",
    "text": "M.2 Sommario\nUna catena di Markov è una sequenza di variabili aleatorie \\(X_0, X_1, X_2, \\ldots\\) che soddisfa la cosiddetta proprietà di Markov. Questa proprietà stabilisce che, dato lo stato attuale della catena, il futuro è indipendente dal passato. Formalmente, questa proprietà si esprime come:\n\\[\nP(X_{n+1} = j \\mid X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j \\mid X_n = i) = q_{ij},\n\\]\ndove \\(q_{ij}\\) rappresenta la probabilità di passare dallo stato \\(i\\) allo stato \\(j\\) in un singolo passo. Queste probabilità di transizione sono organizzate in una matrice di transizione \\(Q = (q_{ij})\\), in cui ogni riga corrisponde a una distribuzione di probabilità condizionata sui possibili stati futuri dato l’attuale stato della catena.\nLa distribuzione di probabilità degli stati della catena dopo \\(n\\) passi può essere calcolata moltiplicando la matrice di transizione \\(Q\\) elevata alla potenza \\(n\\) per il vettore di probabilità iniziale \\(s\\), che descrive la distribuzione di probabilità degli stati al tempo \\(0\\). In simboli, questo è rappresentato da \\(sQ^n\\), che fornisce la distribuzione di probabilità marginale degli stati dopo \\(n\\) passi.\nGli stati di una catena di Markov possono essere classificati come ricorrenti o transitori. Uno stato è ricorrente se la catena torna a questo stato ripetutamente nel tempo; è transitorio se la catena potrebbe lasciare questo stato per non ritornarvi mai più. Gli stati possono anche avere un periodo associato, definito come il massimo comun divisore dei numeri di passi necessari per ritornare allo stato stesso. Una catena di Markov è detta irriducibile se è possibile raggiungere qualsiasi stato da qualsiasi altro stato in un numero finito di passi, ed è aperiodica se ogni stato ha periodo 1.\nUna distribuzione stazionaria di una catena di Markov è una distribuzione di probabilità che rimane invariata nel tempo. Se la catena inizia con questa distribuzione, continuerà a mantenerla in ogni passo successivo. Questa condizione si esprime matematicamente come \\(sQ = s\\), dove \\(s\\) è il vettore di probabilità stazionaria e \\(Q\\) è la matrice di transizione. Per una catena di Markov finita che è irriducibile e aperiodica, esiste una distribuzione stazionaria unica verso la quale la catena converge indipendentemente dalla distribuzione iniziale.\nUn concetto importante nelle catene di Markov è quello di reversibilità. Una catena di Markov è detta reversibile se esiste una distribuzione di probabilità \\(s\\) tale che, per ogni coppia di stati \\(i\\) e \\(j\\), la condizione di reversibilità \\(s_i q_{ij} = s_j q_{ji}\\) sia soddisfatta. Questa condizione garantisce che \\(s\\) sia una distribuzione stazionaria per la catena. Le catene di Markov reversibili sono particolarmente utili in applicazioni pratiche come gli algoritmi di simulazione Monte Carlo, ad esempio l’algoritmo di Metropolis-Hastings, poiché permettono di progettare catene che convergono rapidamente alla distribuzione di probabilità desiderata.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#letteratura",
    "href": "chapters/appendix/a47_first_order_markov.html#letteratura",
    "title": "Appendice M — Catene di Markov",
    "section": "M.3 Letteratura",
    "text": "M.3 Letteratura\nI metodi markoviani sono stati ampiamente utilizzati in vari ambiti della psicologia e dell’educazione. Una delle applicazioni più comuni di questi metodi è il clustering dei dati sequenziali (Törmänen et al. (2022); Törmänen et al. (2023); Fincham et al. (2018)). Ad esempio, i modelli nascosti di Markov (HMM) sono stati utilizzati per raggruppare le sequenze di dati tracciati da sistemi di gestione dell’apprendimento (LMS) degli studenti, al fine di identificare i loro schemi di attività, ovvero le tattiche e strategie di apprendimento (Fincham et al. (2018)). Un uso molto diffuso dei modelli di Markov di primo ordine è quello di mappare le transizioni degli studenti tra diverse attività di apprendimento. Per esempio, Matcha et al. (2020) ha utilizzato modelli di Markov di primo ordine per studiare i processi di transizione degli studenti tra diverse strategie di apprendimento. Altri usi includono lo studio delle transizioni tra diverse strategie di scrittura accademica (Peeters et al. (2020)), tra eventi di apprendimento autoregolato (Lim et al. (2023)), o all’interno di contesti di apprendimento collaborativo (Saqr & López-Pernas (2023)). Esempi più specifici nell’ambito psicologico comprendono lo studio delle influenze reciproche tra stati affettivi (Cipresso et al. (2023)) e l’analisi degli effetti psicologici che dipendono dal tempo nelle sequenze di decision-making (Gunawan et al. (2022)).\n\n\n\n\nCipresso, P., Borghesi, F., & Chirico, A. (2023). Affects affect affects: A Markov chain. Frontiers in Psychology, 14, 1162655.\n\n\nFincham, E., Gašević, D., Jovanović, J., & Pardo, A. (2018). From study tactics to learning strategies: An analytical method for extracting interpretable representations. IEEE Transactions on Learning Technologies, 12(1), 59–72.\n\n\nGunawan, D., Hawkins, G. E., Kohn, R., Tran, M.-N., & Brown, S. D. (2022). Time-evolving psychological processes over repeated decisions. Psychological Review, 129(3), 438–456.\n\n\nLim, L., Bannert, M., Graaf, J. van der, Singh, S., Fan, Y., Surendrannair, S., Rakovic, M., Molenaar, I., Moore, J., & Gašević, D. (2023). Effects of real-time analytics-based personalized scaffolds on students’ self-regulated learning. Computers in Human Behavior, 139, 107547.\n\n\nMatcha, W., Gasevic, D., Jovanovic, J., Pardo, A., Lim, L., Maldonado-Mahauad, J., Gentili, S., Pérez-Sanagustı́n, M., Tsai, Y.-S., et al. (2020). Analytics of Learning Strategies: Role of Course Design and Delivery Modality Authors. Journal of Learning Analytics, 7(2), 45–71.\n\n\nPeeters, W., Saqr, M., & Viberg, O. (2020). Applying learning analytics to map students’ self-regulated learning tactics in an academic writing course. Proceedings of the 28th International Conference on Computers in Education, 1, 245–254.\n\n\nSaqr, M., & López-Pernas, S. (2023). The temporal dynamics of online problem-based learning: Why and when sequence matters. International Journal of Computer-Supported Collaborative Learning, 18(1), 11–37.\n\n\nTörmänen, T., Järvenoja, H., Saqr, M., Malmberg, J., & Järvelä, S. (2022). A person-centered approach to study students’ socio-emotional interaction profiles and regulation of collaborative learning. Frontiers in Education, 7, 866612.\n\n\nTörmänen, T., Järvenoja, H., Saqr, M., Malmberg, J., & Järvelä, S. (2023). Affective states and regulation of learning during socio-emotional interactions in secondary school collaborative groups. British Journal of Educational Psychology, 93, 48–70.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html",
    "href": "chapters/appendix/a50_lin_fun.html",
    "title": "Appendice N — La funzione lineare",
    "section": "",
    "text": "N.1 Concetto di Funzione\nNello studio dei fenomeni naturali e nella risoluzione di problemi tecnici e matematici, è spesso necessario considerare la variazione di una grandezza come dipendente dalla variazione di un’altra. Ad esempio, nello studio del moto, il percorso compiuto da un oggetto può essere visto come una grandezza variabile in funzione del tempo: il cammino percorso è, dunque, una funzione del tempo.\nQuesta considerazione ci conduce alla seguente definizione:\nSe a ogni valore della variabile \\(x\\) (all’interno di un certo intervallo) corrisponde un valore ben definito di un’altra variabile \\(y\\), allora si dice che \\(y\\) è una funzione di \\(x\\). In notazione funzionale si scrive:\n\\[\ny = f(x) \\quad \\text{o anche} \\quad y = \\varphi(x).\n\\]\nLa variabile \\(x\\) è detta variabile indipendente o argomento della funzione. La relazione che lega \\(x\\) a \\(y\\) si chiama relazione funzionale. La lettera \\(f\\) nella notazione \\(y = f(x)\\) indica che per ottenere il valore di \\(y\\) a partire da \\(x\\) è necessario applicare una certa “regola” o “operazione”. In modo analogo, si possono utilizzare anche altre notazioni come \\(u = \\varphi(x)\\).\nLa notazione \\(y = C\\), dove \\(C\\) è una costante, indica una funzione il cui valore rimane invariato per qualunque valore di \\(x\\).\nL’insieme dei valori di \\(x\\) per cui la funzione \\(y = f(x)\\) è definita si chiama dominio di definizione della funzione.\nSe per valori crescenti della variabile indipendente \\(x\\) anche il valore della funzione \\(y = f(x)\\) aumenta, allora la funzione si dice crescente. Analogamente, se a valori crescenti di \\(x\\) corrispondono valori decrescenti della funzione \\(y = f(x)\\), la funzione si dice decrescente.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html#la-retta",
    "href": "chapters/appendix/a50_lin_fun.html#la-retta",
    "title": "Appendice N — La funzione lineare",
    "section": "N.2 La Retta",
    "text": "N.2 La Retta\nLa funzione lineare è definita come:\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono costanti. Il grafico di tale funzione è una retta. Qui, \\(b\\) è detto coefficiente angolare, mentre \\(a\\) è l’intercetta con l’asse delle \\(y\\). In altri termini, la retta interseca l’asse \\(y\\) nel punto \\((0, a)\\).\nPer comprendere il ruolo di \\(a\\) e \\(b\\), consideriamo prima il caso particolare:\n\\[\ny = b x.\n\\]\nQuesta espressione rappresenta una proporzionalità diretta tra \\(x\\) e \\(y\\): al crescere di \\(x\\), \\(y\\) varia in proporzione. Nel caso generale:\n\\[\ny = a + b x,\n\\]\nil termine \\(a\\) “trasla” verticalmente il grafico, aggiungendo una costante a ogni valore \\(b x\\).\nIl segno del coefficiente \\(b\\) determina il comportamento della funzione lineare:\n\nSe \\(b &gt; 0\\), il valore di \\(y\\) aumenta all’aumentare di \\(x\\).\n\nSe \\(b &lt; 0\\), il valore di \\(y\\) diminuisce all’aumentare di \\(x\\).\n\nSe \\(b = 0\\), il grafico è una retta orizzontale e \\(y\\) rimane costante.\n\nPossiamo dare un’interpretazione geometrica ancora più intuitiva se consideriamo variazioni (incrementi) di \\(x\\). Preso un punto \\(x_0\\) e aggiungendo un piccolo incremento \\(\\varepsilon\\), definiamo:\n\\[\n\\Delta x = (x_0 + \\varepsilon) - x_0 = \\varepsilon,\n\\] \\[\n\\Delta y = f(x_0 + \\varepsilon) - f(x_0).\n\\]\nIl coefficiente angolare \\(b\\) può essere interpretato come il rapporto tra la variazione di \\(y\\) e la variazione di \\(x\\):\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0}.\n\\]\nQuesto rapporto è costante e non dipende dalla scelta di \\(x_0\\) o di \\(\\varepsilon\\). In particolare, se scegliamo \\(\\Delta x = 1\\), il coefficiente angolare \\(b\\) rappresenta semplicemente di quanto varia \\(y\\) quando \\(x\\) aumenta di un’unità.\n\n\n\n\n\n\n\nFigura N.1: La funzione lineare \\(y = a + bx\\).\n\n\n\nCome mostrato in figura, il coefficiente \\(b\\) indica la pendenza della retta, ossia quanto “ripida” è la sua inclinazione rispetto all’asse orizzontale.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a71_install_cmdstan.html",
    "href": "chapters/appendix/a71_install_cmdstan.html",
    "title": "Appendice O — Come installare CmdStan",
    "section": "",
    "text": "O.1 Windows\nSu macOS e Linux, questa configurazione dovrebbe essere già pronta di default.\nSu Windows è necessario installare RTools e configurare PATH:\nProblemi comuni:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>O</span>  <span class='chapter-title'>Come installare CmdStan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a71_install_cmdstan.html#windows",
    "href": "chapters/appendix/a71_install_cmdstan.html#windows",
    "title": "Appendice O — Come installare CmdStan",
    "section": "",
    "text": "Installazione di RTools:\n\nVai su https://cran.r-project.org/bin/windows/Rtools/\nScarica la versione di RTools compatibile con la tua versione di R (Generalmente, RTools 4.3 per R 4.3.x, RTools 4.2 per R 4.2.x, etc.)\nEsegui l’installer scaricato\nIMPORTANTE: Durante l’installazione, seleziona la casella “Add rtools to system PATH”\n\nVerifica dell’installazione e configurazione del PATH:\n\nApri PowerShell o Command Prompt\nVerifica se RTools è nel PATH digitando:\n\ngcc --version\nSe vedi la versione di gcc, RTools è nel PATH.\nSe RTools non è nel PATH, devi aggiungerlo manualmente:\n\nCerca “Impostazioni di Sistema” in Windows\nClicca su “Impostazioni di sistema avanzate”\nClicca su “Variabili d’ambiente”\nNella sezione “Variabili di sistema”, trova “Path”\nClicca “Modifica”\nClicca “Nuovo” e aggiungi questi percorsi (sostituisci X.X con la tua versione di RTools):\nC:\\rtools4X\\mingw64\\bin\nC:\\rtools4X\\usr\\bin\n\nVerifica finale:\n\nChiudi e riapri il terminale\nProva questi comandi:\n\ngcc --version\nmake --version\nSe entrambi i comandi mostrano le versioni, l’installazione è completa.\nTest in R:\n\nApri R o RStudio\nEsegui:\n\nSys.which(\"make\")\nDovrebbe mostrare il percorso di make.\n\n\n\nSe i comandi non vengono riconosciuti dopo aver aggiunto il PATH, prova a riavviare il computer.\nSe usi RStudio, potrebbe essere necessario riavviarlo dopo aver modificato il PATH.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>O</span>  <span class='chapter-title'>Come installare CmdStan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html",
    "href": "chapters/mcmc/04_stan_summary_posterior.html",
    "title": "52  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "",
    "text": "52.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nL’obiettivo di questo capitolo è illustrare come sintetizzare una distribuzione a posteriori ottenuta attraverso il campionamento MCMC (Markov Chain Monte Carlo). Questa tecnica è fondamentale nell’inferenza bayesiana moderna, permettendo di comprendere e interpretare i parametri di interesse in modo probabilistico.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#introduzione",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#introduzione",
    "title": "52  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "",
    "text": "52.1.1 Cos’è la Distribuzione a Posteriori?\nLa distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri di interesse. Essa combina l’informazione iniziale (distribuzione a priori) con le evidenze empiriche (dati osservati) attraverso il modello statistico. È un concetto chiave che distingue l’approccio bayesiano dall’inferenza classica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "title": "52  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n52.2 Sintesi della Distribuzione a Posteriori",
    "text": "52.2 Sintesi della Distribuzione a Posteriori\nIl risultato di un’analisi bayesiana è una distribuzione a posteriori, contenente tutte le informazioni sui parametri dati un modello e un insieme di dati. Pertanto, riassumere la distribuzione a posteriori significa sintetizzare le conseguenze logiche del modello e dei dati analizzati. È prassi comune riportare, per ciascun parametro, una misura di posizione centrale (come la media, la moda o la mediana) per fornire un’idea della localizzazione della distribuzione, accompagnata da una misura di dispersione, quale la deviazione standard, per quantificare l’incertezza delle stime. La deviazione standard è adeguata per distribuzioni simili alla normale, ma può risultare fuorviante per distribuzioni di altra natura, come quelle asimmetriche.\nPer riassumere la dispersione di una distribuzione a posteriori, si utilizza spesso l’Intervallo di Densità Più Alta (HDI, Highest-Density Interval). L’HDI è l’intervallo più breve che contiene una data porzione della densità di probabilità. Ad esempio, se diciamo che l’HDI al 95% per un’analisi è [2, 5], intendiamo che, secondo i nostri dati e modello, il parametro in questione si trova tra 2 e 5 con una probabilità di 0.95. Non vi è nulla di particolare nella scelta del 95%, del 50% o di qualsiasi altro valore; siamo liberi di scegliere, ad esempio, l’intervallo HDI all’89% o al 94% secondo le nostre preferenze. Idealmente, le giustificazioni per queste scelte dovrebbero dipendere dal contesto e non essere automatiche, ma è accettabile stabilire un valore comune come il 95%.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#campionamento-con-stan",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#campionamento-con-stan",
    "title": "52  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n52.3 Campionamento con Stan",
    "text": "52.3 Campionamento con Stan\nA scopo illustrativo, immaginiamo di aver condotto un’analisi campionando casualmente 100 opere dal Museum of Modern Art (MoMA) e di aver riscontrato che 14 sono di artisti della Generazione X. Utilizzeremo un modello Beta-Binomiale per affrontare questo problema. Il parametro θ rappresenterà la proporzione di artisti della Generazione X. Adotteremo una distribuzione a priori Beta(4, 6), che riflette un’aspettativa iniziale basata su conoscenze pregresse. I dati osservati (14 opere su 100) verranno utilizzati per aggiornare questa distribuzione iniziale.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#implementazione-in-stan",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#implementazione-in-stan",
    "title": "52  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n52.4 Implementazione in Stan",
    "text": "52.4 Implementazione in Stan\nIl seguente codice Stan definisce il nostro modello probabilistico:\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"moma.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N;           // Numero totale di prove\n#&gt;   int&lt;lower=0&gt; y;           // Numero di successi osservati\n#&gt;   real&lt;lower=0&gt; alpha_prior; // Parametro alpha della distribuzione Beta a priori\n#&gt;   real&lt;lower=0&gt; beta_prior;  // Parametro beta della distribuzione Beta a priori\n#&gt; }\n#&gt; \n#&gt; parameters {\n#&gt;   real&lt;lower=0, upper=1&gt; theta; // Probabilità di successo\n#&gt; }\n#&gt; \n#&gt; model {\n#&gt;   // Distribuzione a priori Beta\n#&gt;   theta ~ beta(alpha_prior, beta_prior);\n#&gt;   \n#&gt;   // Likelihood binomiale\n#&gt;   y ~ binomial(N, theta);\n#&gt; }\n#&gt; \n#&gt; generated quantities {\n#&gt;   real log_lik; // Log-verosimiglianza\n#&gt;   log_lik = binomial_lpmf(y | N, theta);\n#&gt; }\n\nProcediamo con l’implementazione pratica del modello per stimare la proporzione di artisti della Generazione X (θ) al MoMA.\nDefiniamo i dati osservati e i parametri della distribuzione a priori:\n\nN &lt;- 100\ny &lt;- 14\n\nstan_data &lt;- list(\n  N = N,\n  y = y,\n  alpha_prior = 4,\n  beta_prior = 6\n)\n\nEseguiamo il campionamento utilizzando il modello compilato in precedenza:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000, \n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nPer evitare di dover ripetere il campionamento (che può essere computazionalmente costoso), possiamo salvare l’oggetto fit su disco utilizzando la funzione qsave() del pacchetto qs. Questo garantisce un caricamento rapido e senza perdita di dati.\n\n# Save the object to a file.\nqs::qsave(x = fit, file = \"fit_moma.qs\")\n\nSe in seguito vogliamo analizzare i risultati senza dover ripetere il campionamento, possiamo leggere l’oggetto salvato direttamente nel nostro ambiente R:\n\n# Read the object.\nfit2 &lt;- qs::qread(\"fit_moma.qs\")\n\nL’oggetto fit2 è identico a fit e contiene tutte le informazioni relative al modello, ai parametri, ai campioni e ai metadati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "title": "52  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n52.5 Analisi della distribuzione a posteriori",
    "text": "52.5 Analisi della distribuzione a posteriori\nLa distribuzione a posteriori rappresenta la nostra conoscenza aggiornata riguardo al valore del parametro \\(\\theta\\) dopo aver osservato i dati. Combina le nostre credenze a priori riguardo al parametro (la distribuzione a priori) con le nuove evidenze fornite dai dati osservati (la funzione di verosimiglianza) per ottenere una nuova distribuzione che riflette la nostra comprensione aggiornata del parametro, ovvero la distribuzione a posteriori.\nLa distribuzione a posteriori ci dice quanto sia probabile ogni possibile valore del parametro alla luce dei dati osservati. Un picco stretto indica che i dati sono molto informativi rispetto al parametro, portando a una maggiore certezza nella sua stima. Un picco largo, invece, indica maggiore incertezza.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#esaminare-i-valori-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#esaminare-i-valori-della-distribuzione-a-posteriori",
    "title": "52  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n52.6 Esaminare i Valori della Distribuzione a Posteriori",
    "text": "52.6 Esaminare i Valori della Distribuzione a Posteriori\nDopo aver eseguito il campionamento con Stan, possiamo esaminare i valori della distribuzione a posteriori accedendo ai campioni generati.\n\n52.6.1 Estrarre i Campioni in un Oggetto draws_array\n\nIl metodo fit$draws() restituisce i campioni in un oggetto tridimensionale del tipo draws_array, che fa parte del pacchetto posterior.\n\n# Estrazione dei campioni posteriori in formato array (default)\ndraws_arr &lt;- fit2$draws()  \nstr(draws_arr)  # Struttura dell'oggetto\n#&gt;  'draws_array' num [1:2000, 1:4, 1:3] -50 -49.7 -49 -49.1 -51.4 ...\n#&gt;  - attr(*, \"dimnames\")=List of 3\n#&gt;   ..$ iteration: chr [1:2000] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;   ..$ chain    : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n#&gt;   ..$ variable : chr [1:3] \"lp__\" \"theta\" \"log_lik\"\n\nL’output sarà un array 3D con le dimensioni iterazioni × catene × variabili, ovvero il formato standard per i campioni MCMC.\nPer verificare le dimensioni dell’array:\n\ndim(draws_arr)\n#&gt; [1] 2000    4    3\n\nAd esempio, se l’output di dim(draws_arr) restituisce (2000, 4, 3), le dimensioni si riferiscono a:\n\n\n2000: Numero di iterazioni di campionamento per ciascuna catena, specificato dall’argomento iter_sampling = 2000 durante il campionamento.\n\n4: Numero di catene eseguite in parallelo, specificato da chains = 4.\n\n3: Numero di parametri o quantità campionate, inclusi:\n\nParametri definiti nel blocco parameters del modello Stan.\nQuantità trasformate (transformed parameters).\nQuantità generate (generated quantities).\n\n\n\n52.6.2 Interpretazione della Struttura\nL’array 3D permette di accedere ai campioni in modo organizzato:\n\n\nPrima dimensione: Iterazioni per ciascuna catena (es. draws_arr[1,,] restituisce i valori della prima iterazione di tutte le catene).\n\nSeconda dimensione: Catene (es. draws_arr[,1,] restituisce tutti i campioni della prima catena).\n\nTerza dimensione: Variabili campionate (es. draws_arr[,,1] restituisce i valori della prima variabile in tutte le iterazioni e catene).\n\n52.6.3 Accesso ai Parametri\nPer accedere ai campioni di un parametro specifico, possiamo utilizzare il nome del parametro con il metodo fit$draws(format = \"matrix\") o fit$draws(format = \"df\").\n\n# Estrazione dei campioni in formato data frame\ndraws_df &lt;- fit2$draws(format = \"df\")\n\n# Visualizza i primi campioni della variabile \"theta\"\nhead(draws_df$theta)\n#&gt; [1] 0.1188 0.1252 0.1680 0.1477 0.0971 0.0867\n\n\n52.6.4 Sintesi dei Campioni\nPer riassumere i campioni della distribuzione a posteriori:\n\nfit2$summary()\n#&gt; # A tibble: 3 × 10\n#&gt;   variable    mean  median    sd   mad      q5     q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -49.505 -49.235 0.697 0.292 -50.933 -49.024 1.000 3702.440 3546.367\n#&gt; 2 theta      0.164   0.162 0.034 0.034   0.112   0.225 1.001 2813.453 3412.196\n#&gt; 3 log_lik   -2.781  -2.463 0.827 0.397  -4.478  -2.172 1.001 3802.795 4167.904\n\n\n52.6.5 Vantaggi del Formato draws_array\n\nIl formato draws_array è particolarmente utile per:\n\n\nAnalisi avanzate: Permette di accedere direttamente a specifiche iterazioni, catene e parametri.\n\nVisualizzazioni: È compatibile con funzioni di plotting del pacchetto bayesplot.\n\nControlli diagnostici: Facilita l’analisi della convergenza e della miscelazione delle catene.\n\nCon questa struttura, possiamo esplorare in dettaglio la distribuzione a posteriori generata dal modello Stan.\n\nfit2$metadata()$model_params\n#&gt; [1] \"lp__\"    \"theta\"   \"log_lik\"\n\nRecuperiamo i campioni posteriori per theta:\n\ndraws_df &lt;- fit2$draws(format = \"df\")\nhead(draws_df)\n#&gt; # A draws_df: 6 iterations, 1 chains, and 3 variables\n#&gt;   lp__ theta log_lik\n#&gt; 1  -50 0.119    -2.4\n#&gt; 2  -50 0.125    -2.3\n#&gt; 3  -49 0.168    -2.5\n#&gt; 4  -49 0.148    -2.2\n#&gt; 5  -51 0.097    -3.1\n#&gt; 6  -52 0.087    -3.7\n#&gt; # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\ndraws_df$theta |&gt;\n  head()\n#&gt; [1] 0.1188 0.1252 0.1680 0.1477 0.0971 0.0867\n\n\nlength(draws_df$theta)\n#&gt; [1] 8000\n\nGeneriamo un istogramma della distribuzione a posteriori di theta:\n\ndraws_df |&gt;\n  ggplot(aes(theta)) +\n  geom_histogram()\n\n\n\n\n\n\n\nIn alternativa, possiamo passare l’oggetto fit$draws(\"theta\") alla funzione mcmc_hist() di bayesplot:\n\nmcmc_hist(fit2$draws(\"theta\"))\n\n\n\n\n\n\n\nOppure possiamo usare la funzione mcmc_dens_overlay():\n\nmcmc_dens_overlay(fit2$draws(\"theta\"))\n\n\n\n\n\n\n\nLa traccia del campionamento si ottiene nel modo seguente:\n\nmcmc_trace(fit2$draws(\"theta\"))\n\n\n\n\n\n\n\nConfrontiamo la distribuzione a posteriori con la distribuzione a priori di \\(\\theta\\).\n\n# Parameters of the Beta distribution\nalpha &lt;- 4\nbeta_param &lt;- 6\n\n# Create a data frame for the prior Beta distribution\nx &lt;- seq(0, 1, length.out = 1000)\nprior_pdf &lt;- dbeta(x, alpha, beta_param)\nprior_df &lt;- data.frame(theta = x, density = prior_pdf, distribution = \"Prior\")\n\n# Extract posterior draws of theta and calculate density\nposterior_theta &lt;- as.vector(fit2$draws(\"theta\")) # Assuming `fit2$draws(\"theta\")` works\nposterior_density &lt;- density(posterior_theta)\nposterior_df &lt;- data.frame(\n  theta = posterior_density$x,\n  density = posterior_density$y,\n  distribution = \"Posterior\"\n)\n\n# Combine the prior and posterior data\ncombined_df &lt;- bind_rows(prior_df, posterior_df)\n\n# Plot using ggplot2\nggplot(combined_df, aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Density\",\n    title = \"Prior and Posterior Distributions\"\n  ) +\n  scale_color_manual(\n    values = c(\"Prior\" = \"black\", \"Posterior\" = \"red\"),\n    name = \"Distribution\"\n  ) +\n  theme(\n    legend.position = \"top\",\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\nNel caso presente, la distribuzione a posteriori differisce in maniera importante dalla distribuzione a priori. Ciò indica che i dati hanno avuto un forte impatto sulle nostre credenze riguardo al valore del parametro.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#intervallo-di-credibilità",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#intervallo-di-credibilità",
    "title": "52  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n52.7 Intervallo di Credibilità",
    "text": "52.7 Intervallo di Credibilità\nGli intervalli di credibilità sono uno strumento fondamentale nell’inferenza bayesiana per riassumere l’incertezza sui parametri stimati. Esistono due metodi principali per calcolare gli intervalli di credibilità:\n\n\nHighest Density Interval (HDI): definisce l’intervallo più stretto che contiene la probabilità specificata, includendo le aree di maggiore densità della distribuzione a posteriori.\n\nEqual-tailed Interval (ETI): lascia una probabilità uguale (ad esempio, il 2,5% per un intervallo al 95%) in entrambe le code della distribuzione.\n\nQuesti metodi producono risultati identici in caso di distribuzioni simmetriche ma differiscono per distribuzioni asimmetriche. Di seguito vediamo come interpretare e calcolare questi intervalli.\nDistribuzione Simmetrica\nCon una distribuzione a posteriori simmetrica, come quella normale, gli intervalli HDI ed ETI coincidono.\nEsempio di calcolo:\n\n# Genera una distribuzione normale\nposterior &lt;- distribution_normal(1000)\n\n# Calcola HDI ed ETI\nci_hdi &lt;- ci(posterior, method = \"HDI\")\nci_eti &lt;- ci(posterior, method = \"ETI\")\n\n# Visualizza la distribuzione con i limiti degli intervalli\nout &lt;- estimate_density(posterior, extend = TRUE)\nggplot(out, aes(x = x, y = y)) +\n  geom_area(fill = \"orange\") +\n  # HDI in blu\n  geom_vline(xintercept = ci_hdi$CI_low, color = \"royalblue\", linewidth = 3) +\n  geom_vline(xintercept = ci_hdi$CI_high, color = \"royalblue\", linewidth = 3) +\n  # ETI in rosso\n  geom_vline(xintercept = ci_eti$CI_low, color = \"red\", linewidth = 1) +\n  geom_vline(xintercept = ci_eti$CI_high, color = \"red\", linewidth = 1)\n\n\n\n\n\n\n\nDistribuzione Asimmetrica\nQuando la distribuzione a posteriori è asimmetrica, come una distribuzione beta, l’HDI è generalmente più stretto rispetto all’ETI poiché privilegia le regioni di maggiore densità.\nEsempio di calcolo:\n\n# Genera una distribuzione beta\nposterior &lt;- distribution_beta(1000, 6, 2)\n\n# Calcola HDI ed ETI\nci_hdi &lt;- ci(posterior, method = \"HDI\")\nci_eti &lt;- ci(posterior, method = \"ETI\")\n\n# Visualizza la distribuzione con i limiti degli intervalli\nout &lt;- estimate_density(posterior, extend = TRUE)\nggplot(out, aes(x = x, y = y)) +\n  geom_area(fill = \"orange\") +\n  # HDI in blu\n  geom_vline(xintercept = ci_hdi$CI_low, color = \"royalblue\", linewidth = 3) +\n  geom_vline(xintercept = ci_hdi$CI_high, color = \"royalblue\", linewidth = 3) +\n  # ETI in rosso\n  geom_vline(xintercept = ci_eti$CI_low, color = \"red\", linewidth = 1) +\n  geom_vline(xintercept = ci_eti$CI_high, color = \"red\", linewidth = 1)\n\n\n\n\n\n\n\n\n52.7.1 Interpretazione dell’Intervallo di Credibilità\nL’intervallo di credibilità bayesiano offre una chiara interpretazione probabilistica: dato il modello e i dati, c’è una probabilità specificata (ad esempio, il 94%) che il parametro si trovi all’interno dell’intervallo calcolato.\n\n52.7.2 Calcolo degli intervalli in R\n\n\nHDI:\n\n\nbayestestR::ci(fit2$draws(\"theta\"), method = \"HDI\")\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |      95% HDI\n#&gt; ------------------------\n#&gt; theta     | [0.10, 0.23]\n\n\n\nETI:\n\n\nbayestestR::ci(fit2$draws(\"theta\"), method = \"ETI\")\n#&gt; Equal-Tailed Interval\n#&gt; \n#&gt; Parameter |      95% ETI\n#&gt; ------------------------\n#&gt; theta     | [0.10, 0.24]\n\n\n52.7.3 Visualizzazione grafica\nUtilizzando il pacchetto bayesplot possiamo rappresentare la distribuzione a posteriori con l’HDI:\n\nmcmc_areas(fit2$draws(\"theta\"), \n           prob = 0.94) +  # Specifica il livello dell'HDI\n  ggtitle(\"Distribuzione a Posteriori di Theta con HDI al 94%\") +\n  xlab(expression(theta)) +\n  ylab(\"Densità\")\n\n\n\n\n\n\n\n\n52.7.4 Confronto con gli Intervalli di Confidenza Frequentisti\nGli intervalli di credibilità bayesiani si distinguono nettamente dagli intervalli di confidenza frequentisti. Mentre gli intervalli frequentisti si basano su una prospettiva a lungo termine (ovvero, il 95% degli intervalli costruiti su infiniti campioni includerebbe il vero valore), gli intervalli bayesiani:\n\n\nHanno una chiara interpretazione probabilistica: dato il modello e i dati, indicano direttamente la probabilità che il parametro sia nell’intervallo.\n\nIncorporano credenze a priori, combinate con l’evidenza fornita dai dati.\n\n52.7.5 Scelta del Livello dell’Intervallo (89% vs 95%)\nUna discussione comune nell’inferenza bayesiana riguarda il livello predefinito degli intervalli. Sebbene il 95% sia un valore convenzionale mutuato dal frequentismo, alcune evidenze suggeriscono che livelli più bassi (ad esempio, 89%) possano essere più stabili per le distribuzioni a posteriori, specialmente con un numero limitato di campioni posteriori (Kruschke, 2014).\n\n\nVantaggi del 95%:\n\nRelazione intuitiva con la deviazione standard.\nMaggiore probabilità di includere 0, rendendo le analisi più conservative.\n\n\n\nVantaggi dell’89%:\n\nMaggiore stabilità con campioni posteriori limitati.\nEvita l’arbitrarietà del valore 95% (McElreath, 2018).\n\n\n\nIn conclusione, la scelta tra HDI e ETI, così come il livello dell’intervallo, dipende dagli obiettivi e dal contesto dell’analisi. Gli intervalli di credibilità offrono un approccio flessibile e intuitivo per sintetizzare l’incertezza, adattandosi alle esigenze di analisi sia esplorative che confermative.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#test-di-ipotesi-bayesiane",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#test-di-ipotesi-bayesiane",
    "title": "52  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n52.8 Test di Ipotesi Bayesiane",
    "text": "52.8 Test di Ipotesi Bayesiane\nIn alcune situazioni, descrivere semplicemente la distribuzione a posteriori potrebbe non essere sufficiente. Potremmo dover prendere decisioni pratiche basate sulle inferenze, traducendo stime continue in scelte binarie. Ad esempio, possiamo voler determinare se una terapia è efficace, se un intervento ha avuto successo, o se una proporzione supera una soglia di rilevanza pratica.\nSupponiamo di voler verificare se, nel Museum of Modern Art (MoMA), gli artisti della generazione X (nati tra il 1965 e il 1980) rappresentano meno del 10% del corpus esposto. Analizzando un campione casuale di 100 opere e utilizzando un prior basato su convinzioni pregresse, stimiamo la distribuzione a posteriori della proporzione di artisti, \\(\\theta\\). L’intervallo di credibilità (Credible Interval, CI) al 94% risulta compreso tra 0.104 e 0.235.\nLa nostra ipotesi iniziale è che la proporzione di artisti della generazione X sia inferiore al 10%, cioè \\(\\theta &lt; 0.1\\). Tuttavia, il fatto che l’intero intervallo di credibilità al 94% si trovi sopra la soglia del 10% contraddice questa ipotesi. Per quantificare ulteriormente la compatibilità dei dati con questa ipotesi, calcoliamo la probabilità a posteriori che \\(\\theta &lt; 0.1\\).\n\nfit2$summary(\"theta\", pr_lt_01 = ~ mean(. &lt;= 0.1))\n#&gt; # A tibble: 1 × 2\n#&gt;   variable pr_lt_01\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;\n#&gt; 1 theta       0.021\n\nLa probabilità a posteriori che \\(\\theta &lt; 0.1\\)** è molto bassa, ovvero \\(P(\\theta &lt; 0.1) = 0.0213\\), fornendo ulteriori evidenze contro l’ipotesi che gli artisti della generazione X rappresentino meno del 10% del corpus esposto.\nIn sintesi, sulla base dei dati e del modello, l’ipotesi che gli artisti della generazione X rappresentino meno del 10% non è supportata. Al contrario, i dati indicano, con un livello di certezza soggettiva del 94%, che la proporzione di artisti appartenenti a questa generazione è molto probabilmente superiore al 10%.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#riflessioni-conclusive",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#riflessioni-conclusive",
    "title": "52  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n52.9 Riflessioni conclusive",
    "text": "52.9 Riflessioni conclusive\nLa crescente popolarità dei metodi bayesiani in psicologia e nelle scienze sociali è stata fortemente influenzata dalla (ri)scoperta di algoritmi numerici capaci di stimare le distribuzioni a posteriori dei parametri del modello a partire dai dati osservati. Prima di questi sviluppi, ottenere misure riassuntive delle distribuzioni a posteriori, soprattutto per modelli complessi con molti parametri, era praticamente impossibile.\nQuesto capitolo fornisce un’introduzione a cmdstanr, che permette di compilare ed eseguire modelli probabilistici espressi in linguaggio Stan. Grazie a questa tecnologia, è possibile generare una stima della distribuzione a posteriori attraverso il campionamento Markov Chain Monte Carlo (MCMC), rivoluzionando la capacità di effettuare inferenze bayesiane e rendendo l’analisi di modelli complessi più accessibile e gestibile.\nInoltre, nel capitolo sono state presentate diverse strategie per la trasformazione della distribuzione a posteriori e sono state esplorate modalità per ottenere intervalli di credibilità. Successivamente, è stata discussa l’analisi delle ipotesi a posteriori, che consente di confrontare due ipotesi contrapposte riguardanti il parametro \\(\\theta\\).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "52  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.11.0            insight_1.4.2         bayestestR_0.17.0    \n#&gt;  [4] qs_0.27.3             cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [7] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt; [10] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [13] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [16] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [19] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [22] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [25] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [28] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;   [1] RColorBrewer_1.1-3    tensorA_0.36.2.1      jsonlite_2.0.0       \n#&gt;   [4] datawizard_1.2.0      magrittr_2.0.3        TH.data_1.1-4        \n#&gt;   [7] estimability_1.5.1    nloptr_2.2.1          farver_2.1.2         \n#&gt;  [10] rmarkdown_2.29        ragg_1.5.0            vctrs_0.6.5          \n#&gt;  [13] minqa_1.2.8           memoise_2.0.1         base64enc_0.1-3      \n#&gt;  [16] htmltools_0.5.8.1     distributional_0.5.0  curl_7.0.0           \n#&gt;  [19] broom_1.0.9           htmlwidgets_1.6.4     plyr_1.8.9           \n#&gt;  [22] sandwich_3.1-1        emmeans_1.11.2-8      zoo_1.8-14           \n#&gt;  [25] lubridate_1.9.4       cachem_1.1.0          igraph_2.1.4         \n#&gt;  [28] mime_0.13             lifecycle_1.0.4       pkgconfig_2.0.3      \n#&gt;  [31] colourpicker_1.3.0    Matrix_1.7-4          R6_2.6.1             \n#&gt;  [34] fastmap_1.2.0         rbibutils_2.3         shiny_1.11.1         \n#&gt;  [37] snakecase_0.11.1      digest_0.6.37         colorspace_2.1-1     \n#&gt;  [40] ps_1.9.1              rprojroot_2.1.1       textshaping_1.0.3    \n#&gt;  [43] crosstalk_1.2.2       labeling_0.4.3        timechange_0.3.0     \n#&gt;  [46] abind_1.4-8           compiler_4.5.1        withr_3.0.2          \n#&gt;  [49] backports_1.5.0       inline_0.3.21         shinystan_2.6.0      \n#&gt;  [52] QuickJSR_1.8.0        pkgbuild_1.4.8        MASS_7.3-65          \n#&gt;  [55] gtools_3.9.5          tools_4.5.1           httpuv_1.6.16        \n#&gt;  [58] threejs_0.3.4         glue_1.8.0            nlme_3.1-168         \n#&gt;  [61] promises_1.3.3        grid_4.5.1            checkmate_2.3.3      \n#&gt;  [64] reshape2_1.4.4        generics_0.1.4        gtable_0.3.6         \n#&gt;  [67] data.table_1.17.8     RApiSerialize_0.1.4   utf8_1.2.6           \n#&gt;  [70] stringfish_0.17.0     markdown_2.0          stringr_1.5.1        \n#&gt;  [73] later_1.4.4           splines_4.5.1         lattice_0.22-7       \n#&gt;  [76] survival_3.8-3        tidyselect_1.2.1      miniUI_0.1.2         \n#&gt;  [79] knitr_1.50            reformulas_0.4.1      arrayhelpers_1.1-0   \n#&gt;  [82] gridExtra_2.3         V8_7.0.0              stats4_4.5.1         \n#&gt;  [85] xfun_0.53             rstanarm_2.32.1       bridgesampling_1.1-2 \n#&gt;  [88] DT_0.34.0             stringi_1.8.7         boot_1.3-32          \n#&gt;  [91] pacman_0.5.1          evaluate_1.0.5        codetools_0.2-20     \n#&gt;  [94] cli_3.6.5             RcppParallel_5.1.11-1 Rdpack_2.6.4         \n#&gt;  [97] shinythemes_1.2.0     xtable_1.8-4          systemfonts_1.2.3    \n#&gt; [100] processx_3.8.6        coda_0.19-4.1         svUnit_1.0.8         \n#&gt; [103] parallel_4.5.1        rstantools_2.5.0      dygraphs_1.1.1.6     \n#&gt; [106] Brobdingnag_1.2-9     lme4_1.1-37           mvtnorm_1.3-3        \n#&gt; [109] ggridges_0.5.7        scales_1.4.0          xts_0.14.1           \n#&gt; [112] purrr_1.1.0           rlang_1.1.6           multcomp_1.4-28      \n#&gt; [115] shinyjs_2.1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#perché-usare-cmdstanr",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#perché-usare-cmdstanr",
    "title": "Appendice L — Implementazione di modelli Bayesiani con Stan tramite cmdstanr",
    "section": "\nL.1 Perché usare CmdStanR",
    "text": "L.1 Perché usare CmdStanR\nCmdStanR è l’interfaccia R per CmdStan, la versione più leggera e flessibile di Stan. A differenza di rstan, che integra il compilatore C++ dentro R, CmdStanR utilizza direttamente gli eseguibili di CmdStan. Questo porta diversi vantaggi:\n\n\nMaggiore stabilità e velocità di compilazione, grazie all’uso diretto di CmdStan.\n\nAggiornamenti indipendenti: CmdStanR si appoggia a CmdStan, che può essere aggiornato separatamente.\n\nControllo avanzato sulle opzioni di campionamento, diagnostica e gestione dei file di output.\n\nPortabilità: funziona in modo coerente su diversi sistemi operativi.\n\nInoltre, CmdStanR rappresenta oggi la soluzione consigliata dagli sviluppatori Stan, in quanto più manutenuta e allineata con le versioni più recenti del linguaggio.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Implementazione di modelli Bayesiani con Stan tramite `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#installazione",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#installazione",
    "title": "Appendice L — Implementazione di modelli Bayesiani con Stan tramite cmdstanr",
    "section": "\nL.2 Installazione",
    "text": "L.2 Installazione\nPer prima cosa, installiamo il pacchetto cmdstanr da GitHub:\n# install.packages(\"pak\")\npak::pak(\"stan-dev/cmdstanr\")\nDopodiché, occorre installare CmdStan:\ncmdstanr::install_cmdstan()\nQuesto comando scarica e compila CmdStan localmente. La prima installazione può richiedere qualche minuto, ma successivamente sarà sufficiente aggiornare all’occorrenza con:\ncmdstanr::install_cmdstan(update = TRUE)\nPer verificare la corretta installazione:\n\nlibrary(cmdstanr)\ncmdstanr::cmdstan_version()\n\n[1] \"2.37.0\"",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Implementazione di modelli Bayesiani con Stan tramite `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#primo-esempio-modello-binomiale",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#primo-esempio-modello-binomiale",
    "title": "Appendice L — Introduzione a CmdStanR",
    "section": "L.3 Primo esempio: modello binomiale",
    "text": "L.3 Primo esempio: modello binomiale\nSupponiamo di voler stimare la probabilità di successo \\(\\theta\\) osservando \\(y\\) successi su \\(n\\) prove. Il modello Stan è:\n// file: binomial_model.stan\ndata {\n  int&lt;lower=0&gt; n;   // numero di prove\n  int&lt;lower=0&gt; y;   // successi osservati\n}\nparameters {\n  real&lt;lower=0,upper=1&gt; theta; // probabilità di successo\n}\nmodel {\n  theta ~ beta(1, 1);        // prior uniforme\n  y ~ binomial(n, theta);    // verosimiglianza\n}\n\nL.3.1 Preparazione dei dati in R\ndata_list &lt;- list(\n  n = 20,\n  y = 6\n)\n\n\nL.3.2 Compilazione del modello\nmod &lt;- cmdstan_model(\"binomial_model.stan\")\n\n\nL.3.3 Campionamento\nfit &lt;- mod$sample(\n  data = data_list,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4\n)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#esplorare-i-risultati",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#esplorare-i-risultati",
    "title": "Appendice L — Introduzione a CmdStanR",
    "section": "L.4 Esplorare i risultati",
    "text": "L.4 Esplorare i risultati\nUn primo riepilogo dei parametri:\nfit$summary()\nOutput tipico:\n\n\n\nvariable\nmean\nsd\nrhat\ness_bulk\ness_tail\n\n\n\n\ntheta\n0.31\n0.10\n1.00\n1500\n1900\n\n\n\n\nmean: stima media a posteriori.\nsd: deviazione standard della distribuzione a posteriori.\nrhat: diagnostica di convergenza (valori vicini a 1 indicano buona convergenza).\ness_bulk e ess_tail: numero efficace di campioni per la parte centrale e le code della distribuzione.\n\nPossiamo anche estrarre i campioni grezzi:\ntheta_draws &lt;- fit$draws(\"theta\")\n\nL.4.1 Distribuzioni marginali\nPer analizzare la distribuzione a posteriori:\nposterior::mcmc_hist(fit$draws(\"theta\"))\nQuesto produce l’istogramma della distribuzione campionata per \\(\\theta\\).\n\n\nL.4.2 Diagnostiche\nCmdStanR permette di accedere facilmente ai file CSV generati da Stan e di controllare eventuali problemi:\nfit$cmdstan_diagnose()\nSe il modello ha convergito correttamente, non dovrebbero emergere warning.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#riepilogo-dettagliato",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#riepilogo-dettagliato",
    "title": "Appendice L — Introduzione a CmdStanR",
    "section": "L.5 Riepilogo dettagliato",
    "text": "L.5 Riepilogo dettagliato\nUna delle funzioni più utili è fit$summary(), che restituisce per ogni parametro:\n\nmean, median, sd: statistiche descrittive dei campioni.\nmad: median absolute deviation.\nq5, q95: quantili (qui al 5% e 95%).\nrhat: misura di convergenza delle catene (valori &gt; 1.01 indicano possibili problemi).\ness_bulk, ess_tail: effective sample size nella parte centrale e nelle code della distribuzione.\n\nEsempio:\nfit$summary()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\ntheta\n0.31\n0.30\n0.10\n0.10\n0.15\n0.48\n1.00\n1500\n1900\n\n\n\nQueste informazioni sono più complete rispetto a quelle offerte da rstan::summary().",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#salvataggio-e-riutilizzo-dei-risultati",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#salvataggio-e-riutilizzo-dei-risultati",
    "title": "Appendice L — Introduzione a CmdStanR",
    "section": "L.6 Salvataggio e riutilizzo dei risultati",
    "text": "L.6 Salvataggio e riutilizzo dei risultati\nPossiamo salvare i campioni in oggetti posterior::draws_array o draws_df:\ndraws &lt;- fit$draws()\nposterior::as_draws_df(draws)\nInoltre, CmdStanR salva per default i file CSV contenenti i campioni. Questo permette di:\n\nRiutilizzare i campioni senza dover rilanciare la stima.\nCondividere i risultati in modo portabile.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#confronto-tra-modelli",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#confronto-tra-modelli",
    "title": "Appendice L — Introduzione a CmdStanR",
    "section": "L.7 Confronto tra modelli",
    "text": "L.7 Confronto tra modelli\nCmdStanR è pienamente compatibile con il pacchetto loo, che permette di confrontare modelli sulla base della capacità predittiva (LOO-CV, ELPD).\nlog_lik &lt;- fit$draws(\"log_lik\")\nloo::loo(log_lik)\nQuesto rende immediato collegare l’analisi dei risultati di CmdStanR al workflow bayesiano moderno.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#conclusione",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#conclusione",
    "title": "Appendice L — Introduzione a CmdStanR",
    "section": "L.8 Conclusione",
    "text": "L.8 Conclusione\nCmdStanR rappresenta oggi lo strumento consigliato per usare Stan da R. Permette di compilare modelli più velocemente, di accedere a diagnostiche avanzate, di salvare e riutilizzare i campioni, e di integrarsi con pacchetti fondamentali come posterior e loo. In sintesi, è l’opzione più flessibile ed estensibile per condurre analisi bayesiane con Stan in R.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction_rev.html",
    "href": "chapters/mcmc/06_mcmc_prediction_rev.html",
    "title": "52  La predizione bayesiana",
    "section": "",
    "text": "52.1 Preparazione del Notebook\nImpostiamo ambiente, pacchetti e seed. Se usi una cartella comune con funzioni (code/_common.R), caricala; in caso contrario, puoi ignorare la prima riga.\n# (Opzionale) utilità comuni\nif (requireNamespace(\"here\", quietly = TRUE)) {\n  try(suppressMessages(source(here::here(\"code\", \"_common.R\"))), silent = TRUE)\n}\n\n# Pacchetti\npkgs &lt;- c(\"cmdstanr\", \"posterior\", \"bayesplot\", \"ggplot2\", \"dplyr\", \"tidyr\", \"readr\")\nto_install &lt;- pkgs[!sapply(pkgs, requireNamespace, quietly = TRUE)]\nif (length(to_install)) install.packages(to_install, repos = \"https://cloud.r-project.org\")\n\nlapply(pkgs, library, character.only = TRUE)\n\n[[1]]\n [1] \"cmdstanr\"        \"pillar\"          \"tinytable\"       \"patchwork\"      \n [5] \"ggdist\"          \"tidybayes\"       \"bayesplot\"       \"ggplot2\"        \n [9] \"reliabilitydiag\" \"priorsense\"      \"posterior\"       \"loo\"            \n[13] \"rstan\"           \"StanHeaders\"     \"brms\"            \"Rcpp\"           \n[17] \"sessioninfo\"     \"conflicted\"      \"janitor\"         \"matrixStats\"    \n[21] \"modelr\"          \"tibble\"          \"dplyr\"           \"tidyr\"          \n[25] \"rio\"             \"here\"            \"stats\"           \"graphics\"       \n[29] \"grDevices\"       \"utils\"           \"datasets\"        \"methods\"        \n[33] \"base\"           \n\n[[2]]\n [1] \"cmdstanr\"        \"pillar\"          \"tinytable\"       \"patchwork\"      \n [5] \"ggdist\"          \"tidybayes\"       \"bayesplot\"       \"ggplot2\"        \n [9] \"reliabilitydiag\" \"priorsense\"      \"posterior\"       \"loo\"            \n[13] \"rstan\"           \"StanHeaders\"     \"brms\"            \"Rcpp\"           \n[17] \"sessioninfo\"     \"conflicted\"      \"janitor\"         \"matrixStats\"    \n[21] \"modelr\"          \"tibble\"          \"dplyr\"           \"tidyr\"          \n[25] \"rio\"             \"here\"            \"stats\"           \"graphics\"       \n[29] \"grDevices\"       \"utils\"           \"datasets\"        \"methods\"        \n[33] \"base\"           \n\n[[3]]\n [1] \"cmdstanr\"        \"pillar\"          \"tinytable\"       \"patchwork\"      \n [5] \"ggdist\"          \"tidybayes\"       \"bayesplot\"       \"ggplot2\"        \n [9] \"reliabilitydiag\" \"priorsense\"      \"posterior\"       \"loo\"            \n[13] \"rstan\"           \"StanHeaders\"     \"brms\"            \"Rcpp\"           \n[17] \"sessioninfo\"     \"conflicted\"      \"janitor\"         \"matrixStats\"    \n[21] \"modelr\"          \"tibble\"          \"dplyr\"           \"tidyr\"          \n[25] \"rio\"             \"here\"            \"stats\"           \"graphics\"       \n[29] \"grDevices\"       \"utils\"           \"datasets\"        \"methods\"        \n[33] \"base\"           \n\n[[4]]\n [1] \"cmdstanr\"        \"pillar\"          \"tinytable\"       \"patchwork\"      \n [5] \"ggdist\"          \"tidybayes\"       \"bayesplot\"       \"ggplot2\"        \n [9] \"reliabilitydiag\" \"priorsense\"      \"posterior\"       \"loo\"            \n[13] \"rstan\"           \"StanHeaders\"     \"brms\"            \"Rcpp\"           \n[17] \"sessioninfo\"     \"conflicted\"      \"janitor\"         \"matrixStats\"    \n[21] \"modelr\"          \"tibble\"          \"dplyr\"           \"tidyr\"          \n[25] \"rio\"             \"here\"            \"stats\"           \"graphics\"       \n[29] \"grDevices\"       \"utils\"           \"datasets\"        \"methods\"        \n[33] \"base\"           \n\n[[5]]\n [1] \"cmdstanr\"        \"pillar\"          \"tinytable\"       \"patchwork\"      \n [5] \"ggdist\"          \"tidybayes\"       \"bayesplot\"       \"ggplot2\"        \n [9] \"reliabilitydiag\" \"priorsense\"      \"posterior\"       \"loo\"            \n[13] \"rstan\"           \"StanHeaders\"     \"brms\"            \"Rcpp\"           \n[17] \"sessioninfo\"     \"conflicted\"      \"janitor\"         \"matrixStats\"    \n[21] \"modelr\"          \"tibble\"          \"dplyr\"           \"tidyr\"          \n[25] \"rio\"             \"here\"            \"stats\"           \"graphics\"       \n[29] \"grDevices\"       \"utils\"           \"datasets\"        \"methods\"        \n[33] \"base\"           \n\n[[6]]\n [1] \"cmdstanr\"        \"pillar\"          \"tinytable\"       \"patchwork\"      \n [5] \"ggdist\"          \"tidybayes\"       \"bayesplot\"       \"ggplot2\"        \n [9] \"reliabilitydiag\" \"priorsense\"      \"posterior\"       \"loo\"            \n[13] \"rstan\"           \"StanHeaders\"     \"brms\"            \"Rcpp\"           \n[17] \"sessioninfo\"     \"conflicted\"      \"janitor\"         \"matrixStats\"    \n[21] \"modelr\"          \"tibble\"          \"dplyr\"           \"tidyr\"          \n[25] \"rio\"             \"here\"            \"stats\"           \"graphics\"       \n[29] \"grDevices\"       \"utils\"           \"datasets\"        \"methods\"        \n[33] \"base\"           \n\n[[7]]\n [1] \"readr\"           \"cmdstanr\"        \"pillar\"          \"tinytable\"      \n [5] \"patchwork\"       \"ggdist\"          \"tidybayes\"       \"bayesplot\"      \n [9] \"ggplot2\"         \"reliabilitydiag\" \"priorsense\"      \"posterior\"      \n[13] \"loo\"             \"rstan\"           \"StanHeaders\"     \"brms\"           \n[17] \"Rcpp\"            \"sessioninfo\"     \"conflicted\"      \"janitor\"        \n[21] \"matrixStats\"     \"modelr\"          \"tibble\"          \"dplyr\"          \n[25] \"tidyr\"           \"rio\"             \"here\"            \"stats\"          \n[29] \"graphics\"        \"grDevices\"       \"utils\"           \"datasets\"       \n[33] \"methods\"         \"base\"           \n\n# Seed & cores\nset.seed(1234)\noptions(mc.cores = max(1L, parallel::detectCores() - 1L))\n\n# Verifica CmdStan\ntry({\n  ver &lt;- cmdstanr::cmdstan_version()\n  message(\"CmdStan version: \", ver)\n}, silent = TRUE)\n\nbayesplot::color_scheme_set(\"brightblue\")\ntheme_set(ggplot2::theme_minimal(base_size = 13))",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction_rev.html#introduzione",
    "href": "chapters/mcmc/06_mcmc_prediction_rev.html#introduzione",
    "title": "52  La predizione bayesiana",
    "section": "\n52.2 Introduzione",
    "text": "52.2 Introduzione\nIn questo capitolo esamineremo in dettaglio le distribuzioni predittive a priori e a posteriori usando cmdstanr. La distribuzione predittiva a priori rappresenta le aspettative sui dati prima di qualsiasi osservazione reale, riflettendo le conoscenze preesistenti e le ipotesi sui parametri del modello. Essa fornisce un’indicazione delle caratteristiche che i dati potrebbero assumere in base al modello. Confrontare queste previsioni con i dati effettivamente osservati consente di valutare la validità delle ipotesi incorporate nel modello.\nLa distribuzione predittiva è spesso di maggiore interesse rispetto alla distribuzione a posteriori. Mentre la distribuzione a posteriori descrive l’incertezza sui parametri (ad esempio, la proporzione di palline rosse in un’urna), la distribuzione predittiva descrive l’incertezza sugli eventi futuri (ad esempio, il colore della pallina che verrà estratta in futuro). Questa differenza è cruciale, soprattutto quando si tratta di prevedere gli effetti di un intervento, come la somministrazione di un trattamento a un paziente.\nLa distribuzione predittiva a posteriori è inoltre fondamentale per valutare quanto le previsioni del modello siano coerenti con i dati osservati. Se le previsioni del modello risultano allineate con i dati raccolti, il modello può essere considerato accurato nel rappresentare il processo generativo sottostante. Questo confronto è essenziale per convalidare il modello e assicurarsi che le ipotesi riflettano adeguatamente la realtà osservata.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction_rev.html#sec-posterior-predictive-distribution",
    "href": "chapters/mcmc/06_mcmc_prediction_rev.html#sec-posterior-predictive-distribution",
    "title": "52  La predizione bayesiana",
    "section": "\n52.3 La distribuzione predittiva a posteriori",
    "text": "52.3 La distribuzione predittiva a posteriori\nLa distribuzione predittiva a posteriori offre una valutazione critica della coerenza tra i dati reali e quelli simulati dal modello (Gelman & Shalizi, 2013). Confrontando direttamente i dati osservati con quelli generati dal modello, essa permette di identificare eventuali discrepanze che potrebbero segnalare problemi nella specificazione del modello. In pratica, la PPC (Posterior Predictive Check) funge da test diagnostico, consentendo di rilevare e correggere eventuali carenze nel modello, migliorandone così le capacità predittive.\nPer comprendere meglio il concetto, consideriamo la distribuzione predittiva a posteriori in termini di un modello coniugato normale-normale. Supponiamo di voler predire la media di una distribuzione normale futura, basandoci sui dati osservati e sulle nostre conoscenze a priori. La PPD ci offre uno strumento per calcolare queste probabilità, combinando le informazioni provenienti dai dati osservati con quelle fornite dalla distribuzione a priori.\nAd esempio, immaginiamo di aver raccolto dati sulle altezze di 100 persone, ottenendo una media campionaria di 170 cm e una deviazione standard campionaria di 10 cm. Il nostro obiettivo è stimare la media delle altezze in un futuro campione di \\(n=100\\) persone. La nostra conoscenza a priori sulla media delle altezze è rappresentata da una distribuzione normale con media 175 cm e deviazione standard di 5 cm.\nIn termini di notazione, possiamo esprimere questa distribuzione come \\(P(\\tilde{y} \\mid \\theta=\\theta_1)\\), dove \\(\\tilde{y}\\) rappresenta un nuovo dato che è diverso dai dati attuali \\(y\\), e \\(\\theta_1\\) è la media a posteriori. Tuttavia, in statistica bayesiana, è fondamentale incorporare tutta l’incertezza nei risultati. Poiché \\(\\theta_1\\) è solo uno dei possibili valori per \\(\\theta\\), dovremmo includere ogni valore di \\(\\theta\\) per la nostra previsione. Per ottenere la migliore previsione, possiamo “mediare” le previsioni attraverso i diversi valori di \\(\\theta\\), ponderando ciascun valore secondo la sua probabilità a posteriori.\nLa distribuzione risultante è la distribuzione predittiva a posteriori, che in notazione matematica è data da:\n\\[ P(\\tilde{y} \\mid y) = \\int_\\theta p(\\tilde{y} \\mid \\theta, y) p(\\theta \\mid y) d\\theta. \\]\nIn questo modo, la distribuzione predittiva a posteriori combina le informazioni dai dati osservati con la conoscenza a priori, fornendo una previsione che riflette l’incertezza associata a tutti i possibili valori dei parametri del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction_rev.html#distribuzione-predittiva-a-posteriori-nel-modello-normale-normale",
    "href": "chapters/mcmc/06_mcmc_prediction_rev.html#distribuzione-predittiva-a-posteriori-nel-modello-normale-normale",
    "title": "52  La predizione bayesiana",
    "section": "\n52.4 Distribuzione predittiva a posteriori nel modello normale-normale",
    "text": "52.4 Distribuzione predittiva a posteriori nel modello normale-normale\nNel modello coniugato normale-normale, se i dati osservati \\(Y = \\{y_1, y_2, ..., y_n\\}\\) sono modellati come provenienti da una distribuzione normale con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e assumendo una distribuzione a priori normale per \\(\\mu\\), la distribuzione a posteriori di \\(\\mu\\) sarà anch’essa normale.\n\n52.4.1 Formule della distribuzione predittiva a posteriori\nDato che:\n\nI dati osservati \\(y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\n\nLa prior per \\(\\mu\\) è \\(\\mu \\sim \\mathcal{N}(\\mu_0, \\tau_0^2)\\)\n\n\nLa distribuzione a posteriori per \\(\\mu\\) sarà:\n\\[\n\\mu \\mid Y \\sim \\mathcal{N}(\\mu_n, \\tau_n^2)\n\\]\ndove:\n\\[\n\\mu_n = \\frac{\\tau_0^2 \\bar{y} + \\sigma^2 \\mu_0}{\\tau_0^2 + \\sigma^2}\n\\]\nin cui \\(\\bar{y}\\) è la media campionaria dei dati osservati, e\n\\[\n\\tau_n^2 = \\frac{\\tau_0^2 \\sigma^2}{\\tau_0^2 + \\sigma^2} .\n\\]\n\nEsempio 52.1 Consideriamo che:\n\n\n\\(\\mu_0 = 175\\) cm (media a priori)\n\n\\(\\tau_0 = 5\\) cm (deviazione standard a priori)\n\n\\(\\bar{y} = 170\\) cm (media campionaria)\n\n\\(\\sigma = 10\\) cm (deviazione standard campionaria)\n\n\\(n = 100\\) (numero di osservazioni)\n\nI parametri della distribuzione a posteriori sono:\n\\[\n\\mu_n = \\frac{(5^2 \\cdot 170) + (10^2 \\cdot 175)}{5^2 + 10^2} = \\frac{42500 + 175000}{25 + 100} = \\frac{217500}{125} = 174 \\quad \\text{cm}\n\\]\n\\[\n\\tau_n^2 = \\frac{5^2 \\cdot 10^2}{5^2 + 10^2} = \\frac{2500}{125} = 20 \\quad \\text{cm}^2 \\Rightarrow \\tau_n = \\sqrt{20} \\approx 4.47 \\quad \\text{cm}\n\\]\nPertanto, la distribuzione a posteriori per \\(\\mu\\) è:\n\\[\n\\mu \\mid Y \\sim \\mathcal{N}(174, 4.47^2)\n\\]\nPer la distribuzione predittiva a posteriori, dobbiamo considerare anche la varianza della distribuzione futura. Se stiamo predicendo per \\(n_{\\text{fut}}=100\\) nuove osservazioni, la varianza della media predittiva sarà:\n\\[\n\\sigma_{\\text{pred}}^2 = \\tau_n^2 + \\frac{\\sigma^2}{n_{\\text{fut}}}\n\\]\n\\[\n\\sigma_{\\text{pred}}^2 = 20 + \\frac{10^2}{100} = 20 + 1 = 21 \\quad \\text{cm}^2 \\Rightarrow \\sigma_{\\text{pred}} = \\sqrt{21} \\approx 4.58 \\quad \\text{cm}\n\\]\nQuindi, la distribuzione predittiva a posteriori è:\n\\[\n\\tilde{Y} \\sim \\mathcal{N}(174, 4.58^2)\n\\]\n\n52.5 Implementazione con cmdstanr\n\nPer illustrare come viene generata la distribuzione predittiva a posteriori nel contesto del modello normale-normale, possiamo utilizzare cmdstanr per eseguire l’analisi. Il codice seguente mostra come configurare il modello e generare previsioni.\n\n# Dati osservati\nset.seed(123)  # Imposta il seed per la riproducibilità\ny_observed &lt;- rnorm(100, 170, 10)\nmean_y &lt;- mean(y_observed)\nstd_y &lt;- sd(y_observed)\n\n# Parametri a priori\nmu_0 &lt;- 175\ntau_0 &lt;- 5\n\n# Parametri posteriori\ntau_n_sq &lt;- (tau_0^2 * std_y^2) / (tau_0^2 + std_y^2)\ntau_n &lt;- sqrt(tau_n_sq)\nmu_n &lt;- (tau_0^2 * mean_y + std_y^2 * mu_0) / (tau_0^2 + std_y^2)\n\n# Parametri predittivi\nn_fut &lt;- 100\nsigma_pred_sq &lt;- tau_n_sq + (std_y^2 / n_fut)\nsigma_pred &lt;- sqrt(sigma_pred_sq)\nmu_pred &lt;- mu_n\n\n# Simulazioni\ny_pred_samples &lt;- rnorm(1000, mu_pred, sigma_pred)\n\n# Dati per ggplot\ndata &lt;- data.frame(Heights = y_pred_samples)\n\n# Grafico\np &lt;- ggplot(data, aes(x = Heights)) +\n  geom_histogram(\n    aes(y = ..density..), \n    bins = 30, \n    fill = \"gray\", \n    colour = \"gray\", \n    alpha = 0.5\n  ) +\n  geom_density(colour = \"black\", size = 1.5) +\n  geom_vline(\n    xintercept = mu_pred, \n    colour = \"gray\", \n    linetype = \"dashed\", \n    size = 1\n  ) +\n  labs(title = \"Posterior Predictive Distribution for Heights\",\n       x = \"Heights (cm)\",\n       y = \"Density\") +\n  theme(legend.position = \"none\")\n\n# Visualizza il grafico\nprint(p)\n\n\n\n\n\n\n\nQuesto codice produce un grafico che illustra visivamente la distribuzione predittiva a posteriori per le altezze nel nostro campione di 100 nuove osservazioni, tenendo conto sia dei dati osservati che delle nostre aspettative iniziali.\nIn sintesi, la distribuzione predittiva a posteriori è stata generata nel modo seguente:\n\nCampioniamo un valore \\(\\mu\\) dalla distribuzione a posteriori di \\(\\mu\\).\nCampioniamo un valore \\(\\sigma\\) dalla distribuzione a posteriori di \\(\\sigma\\).\nUtilizziamo questi valori per generare un campione dalla distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nRipetiamo questo processo molte volte.\n\nLa distribuzione dei valori ottenuti da questi campionamenti costituisce la distribuzione predittiva a posteriori.\n\n52.6 Metodo MCMC\nQuando usiamo un PPL come Stan, la distribuzione predittiva viene stimata mediante il campionamento da una catena di Markov, che è particolarmente utile in scenari complessi dove l’analisi analitica potrebbe essere impraticabile. Attraverso i metodi MCMC, si stimano le potenziali osservazioni future \\(p(\\tilde{y} \\mid y)\\), indicate come \\(p(y^{rep} \\mid y)\\), seguendo questi passaggi:\n\nSi campiona \\(\\theta_i \\sim p(\\theta \\mid y)\\): Viene selezionato casualmente un valore del parametro (o dei parametri) dalla distribuzione a posteriori.\nSi campiona \\(y^{rep} \\sim p(y^{rep} \\mid \\theta_i)\\): Viene scelta casualmente un’osservazione dalla funzione di verosimiglianza, condizionata al valore del parametro (o dei parametri)ottenuto nel passo precedente.\n\nRipetendo questi due passaggi un numero sufficiente di volte, l’istogramma risultante approssimerà la distribuzione predittiva a posteriori.\nEsaminiamo ora come ottenere la distribuzione predittiva a posteriori con Stan per i dati dell’esempio precedente. Iniziamo creando le distribuzioni a posteriori di \\(\\mu\\) e \\(\\sigma\\).\nDefiniamo un dizionario che contiene i dati.\n\nstan_data_gauss = list(\n  N = length(y_observed),\n  y = y_observed,\n  mu_prior = 180,\n  sigma_prior = 20,\n  sigma_prior_mean = 10,\n  sigma_prior_sd = 3\n)\n\n\ny_mean = mean(y_observed)\ny_std = sd(y_observed)\n\ny_mean\n#&gt; [1] 171\ny_std\n#&gt; [1] 9.13\n\nCompiliamo e stampiamo il modello Stan:\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"gaussian_model.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N; // number of observations\n#&gt;   vector[N] y; // observed data\n#&gt;   real mu_prior; // prior mean for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior; // prior standard deviation for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior_mean; // prior mean for sigma\n#&gt;   real&lt;lower=0&gt; sigma_prior_sd; // prior standard deviation for sigma\n#&gt; }\n#&gt; parameters {\n#&gt;   real mu; // parameter of interest\n#&gt;   real&lt;lower=0&gt; sigma; // parameter for the standard deviation\n#&gt; }\n#&gt; model {\n#&gt;   mu ~ normal(mu_prior, sigma_prior); // prior for mu\n#&gt;   sigma ~ normal(sigma_prior_mean, sigma_prior_sd); // prior for sigma\n#&gt;   y ~ normal(mu, sigma); // likelihood\n#&gt; }\n#&gt; generated quantities {\n#&gt;   array[N] real y_rep;\n#&gt;   for (n in 1 : N) {\n#&gt;     y_rep[n] = normal_rng(mu, sigma);\n#&gt;   }\n#&gt; }\n\nEseguiamo il campionamento MCMC:\n\nfit &lt;- mod$sample(\n  data = stan_data_gauss,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000, \n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\nfit$summary(c(\"mu\", \"sigma\"))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable    mean  median    sd   mad      q5     q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       170.928 170.931 0.932 0.943 169.395 172.467 1.001 7320.825 5507.575\n#&gt; 2 sigma      9.272   9.233 0.652 0.647   8.277  10.396 1.001 6674.842 5412.095\n\nEstraiamo i dati prodotti dal modello y_rep e i dati osservati y:\n\n# Extract posterior predictive samples for y_rep\ny_rep &lt;- fit$draws(variables = \"y_rep\", format = \"draws_matrix\")\n\n# Extract observed data\ny_obs &lt;- stan_data_gauss$y\n\nConvertiamo y_rep in una matrice per compatibilità con {bayesplot}.\n\n# Convert y_rep to a matrix\ny_rep_matrix &lt;- as.matrix(y_rep)\n\nGeneriamo il posterior predictive chech plot:\n\n# Posterior predictive check plot\nset.seed(123)\nselected_indices &lt;- sample(nrow(y_rep_matrix), 50)\nppc_dens_overlay(y = y_obs, yrep = y_rep_matrix[selected_indices, ])\n\n\n\n\n\n\n\nLa distribuzione predittiva a posteriori è utilizzata per eseguire i controlli predittivi a posteriori (PPC), noti come Posterior Predictive Checks. I PPC consistono in un confronto grafico tra \\(p(y^{rep} \\mid y)\\), ossia la distribuzione delle osservazioni future previste, e i dati osservati \\(y\\). Questo confronto visivo permette di valutare se il modello utilizzato è adeguato per descrivere le proprietà dei dati osservati.\nOltre al confronto grafico tra le distribuzioni \\(p(y)\\) e \\(p(y^{rep})\\), è possibile effettuare un confronto tra le distribuzioni di varie statistiche descrittive calcolate su diversi campioni \\(y^{rep}\\) e le corrispondenti statistiche calcolate sui dati osservati. Tipicamente, vengono considerate statistiche descrittive come la media, la varianza, la deviazione standard, il minimo o il massimo, ma è possibile confrontare qualsiasi altra statistica rilevante.\nI controlli predittivi a posteriori offrono un valido strumento per un’analisi critica delle prestazioni del modello e, se necessario, per apportare eventuali modifiche o considerare modelli alternativi più adatti ai dati in esame.\n\n52.7 Distribuzione Predittiva a Priori\nLa verifica predittiva a priori è un metodo fondamentale per esplorare le implicazioni dei tuoi prior. Genera dati simulati basandosi unicamente sui prior, ignorando completamente i dati osservati. Questo permette di rispondere a domande cruciali come:\n\nI dati generati dal prior riflettono scenari plausibili?\nIl prior è troppo restrittivo o troppo ampio rispetto ai dati attesi?\n\nQuesta verifica è particolarmente utile per identificare eventuali incongruenze o assunzioni non realistiche prima di raccogliere i dati osservati.\n\n52.7.1 Modello Beta-Binomiale\nIniziamo con il caso più semplice. Il modello beta-binomiale è un esempio classico per illustrare la verifica predittiva a priori. In questo modello:\n\n\ntheta rappresenta la probabilità di successo.\nIl prior su theta è distribuito secondo una distribuzione Beta parametrizzata da alpha_prior e beta_prior.\nI dati (y) seguono una distribuzione Bernoulliana condizionata su theta.\n\nIl modello Stan per l’inferenza sui dati osservati è il seguente:\ndata {\n  int&lt;lower=0&gt; N;             // Numero di osservazioni\n  array[N] int&lt;lower=0, upper=1&gt; y; // Dati osservati (successi)\n  real&lt;lower=0&gt; alpha_prior;  // Parametro alpha del prior Beta\n  real&lt;lower=0&gt; beta_prior;   // Parametro beta del prior Beta\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; // Probabilità di successo\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior); // Prior su theta\n  y ~ bernoulli(theta);                  // Likelihood\n}\nPer eseguire la simulazione dalla distribuzione predittiva a priori, rimuoviamo il blocco model e utilizziamo generated quantities per simulare:\n\nl’estrazione di un valore per theta dalla distribuzione Beta specificata dai parametri del prior;\nla generazione di successi simulati (y_sim) dalla distribuzione Bernoulliana condizionata su theta.\n\nCompiliamo il modello:\n\n# Create a CmdStanModel object\nmod_prior &lt;- cmdstan_model(here::here(\"stan\", \"betabinomial_prior.stan\"))\n\nEsaminiamo il modello:\n\nmod_prior$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N;             // Numero di osservazioni\n#&gt;   real&lt;lower=0&gt; alpha_prior;  // Parametro alpha del prior Beta\n#&gt;   real&lt;lower=0&gt; beta_prior;   // Parametro beta del prior Beta\n#&gt; }\n#&gt; generated quantities {\n#&gt;   real&lt;lower=0, upper=1&gt; theta_prior;    // Valore estratto da Beta(alpha_prior, beta_prior)\n#&gt;   array[N] int&lt;lower=0, upper=1&gt; y_sim;  // Osservazioni simulate\n#&gt;   \n#&gt;   theta_prior = beta_rng(alpha_prior, beta_prior); // Generazione di theta\n#&gt;   for (n in 1:N) {\n#&gt;     y_sim[n] = bernoulli_rng(theta_prior); // Simulazione dei successi\n#&gt;   }\n#&gt; }\n\nIn questo script abbiamo\n\n\neliminato il blocco model: Questo blocco serve per l’inferenza Bayesiana, ma non è necessario per generare dati a priori.\n\naggiunto il blocco generated quantities: In questo blocco generiamo quantità di interesse, come i dati simulati y_sim e il valore di theta estratto dalla distribuzione a priori.\n\nutilizzato la funzione beta_rng per estrarre un valore per theta dalla distribuzione \\(\\mathcal{Beta}\\) definita dai parametri alpha_prior e beta_prior. Questo valore rappresenta una possibile realizzazione del parametro prima di osservare i dati.\n\nutilizzato la funzione binomial_rng per simulare N osservazioni dalla distribuzione binomiale. Il parametro di successo theta è fissato al valore estratto theta_prior.\n\nIn sostanza, questo codice ci permette di generare un dataset simulato che potrebbe essere osservato se il processo stocastico fosse governato unicamente dai parametri specificati nella distribuzione a priori. In questo modo, possiamo valutare le proprietà del modello e la sua capacità di generare dati simili a quelli reali, prima ancora di avere a disposizione i dati osservati.\nLa distribuzione a priori rappresenta la nostra conoscenza o credenza sul valore del parametro theta prima di osservare i dati. Scegliendo diversi valori per alpha_prior e beta_prior, possiamo specificare diverse distribuzioni a priori e quindi esplorare come queste influenzano i risultati della simulazione.\nI dati richiesti dal modello vengono specificati nel modo seguente:\n\n# Dati osservati\nN &lt;- 100               # Numero di osservazioni\n\n# Parametri del prior\nalpha_prior &lt;- 4\nbeta_prior &lt;- 6\n\n# Dati per Stan\nstan_data_prior &lt;- list(\n  N = N, \n  alpha_prior = alpha_prior, \n  beta_prior = beta_prior\n)\n\nEseguiamo il campionamento:\n\n# Simulazione del prior\nfit_prior &lt;- mod_prior$sample(\n  data = stan_data_prior,\n  chains = 4, \n  iter_sampling = 1000, \n  iter_warmup = 0,\n  fixed_param = TRUE, \n  show_messages = FALSE\n)\n\nSi noti l’argomento fixed_param = TRUE in quanto nessun parametro viene aggiornato.\nEstraiamo i campioni a posteriori e visualizziamo i risultati:\n\n# Estraiamo theta_prior e y_sim\ntheta_prior &lt;- fit_prior$draws(\"theta_prior\")\ny_sim &lt;- fit_prior$draws(\"y_sim\")\n\nGeneriamo la distribuzione a priori di theta:\n\n# Distribuzione a priori di theta\nhist(\n  theta_prior, \n  main = \"Distribuzione a priori di theta\", \n  xlab = \"theta\", \n  freq = FALSE\n)\n\n\n\n\n\n\n\nCostruiamo la distribuzione predittiva a priori della proporzione di successi:\n\n# Distribuzione dei successi simulati\ny_sim_mean &lt;- rowMeans(y_sim)\nhist(\n  y_sim_mean, \n  breaks = 20, \n  main = \"Distribuzione predittiva a priori\", \n  xlab = \"Proporzione di successi\", \n  freq = FALSE\n)\n\n\n\n\n\n\n\nLa distribuzione predittiva a priori mostra che i dati simulati riflettono il comportamento atteso dato il prior. Per il prior \\(\\mathcal{Beta}(4, 6)\\):\n\nLa media attesa di theta è \\(\\mathbb{E}[\\theta] = \\frac{\\alpha}{\\alpha + \\beta} = 0.4\\).\nLa varianza attesa è \\(\\text{Var}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\).\n\nCon 14 successi su 100 osservazioni reali, corrispondenti a una proporzione di 0.14, notiamo che:\n\nIl prior \\(\\mathcal{Beta}(4, 6)\\) è informativo, con un centro più alto rispetto ai dati osservati.\nSe vogliamo un prior meno concentrato (ad esempio \\(\\mathcal{Beta}(2, 2)\\)), i dati avranno un peso maggiore.\n\nIn conclusione,\n\nutilizzare un prior informativo è appropriato se abbiamo conoscenze precedenti robuste;\nse vogliamo un prior che lasci maggior spazio ai dati osservati, potremmo scegliere distribuzioni più ampie come \\(\\mathcal{Beta}(2, 2)\\).\n\nLa verifica predittiva a priori è uno strumento potente per convalidare queste scelte.\n\n52.7.2 Modello Gaussiano\nConsideriamo un secondo esempio, facciamo riferimento al caso discusso in precedenza dove veniva considerato un campione di dati gaussiani e un modello gaussiano in cui le distribuzioni a priori per μ e σ erano gaussiane.\nCompiliamo e stampiamo il modello Stan per generare la distribuzione predittiva a priori:\n\nmod_gauss_prior &lt;- cmdstan_model(\n  here::here(\"stan\", \"gaussian_model_prior.stan\")\n)\n\n\nmod_gauss_prior$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N; // number of observations\n#&gt;   real mu_prior; // prior mean for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior; // prior standard deviation for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior_mean; // prior mean for sigma\n#&gt;   real&lt;lower=0&gt; sigma_prior_sd; // prior standard deviation for sigma\n#&gt; }\n#&gt; generated quantities {\n#&gt;   real mu = normal_rng(mu_prior, sigma_prior); // prior draw for mu\n#&gt;   real&lt;lower=0&gt; sigma = normal_rng(sigma_prior_mean, sigma_prior_sd); // prior draw for sigma\n#&gt;   array[N] real y_rep;\n#&gt;   for (n in 1 : N) {\n#&gt;     y_rep[n] = normal_rng(mu, sigma);\n#&gt;   }\n#&gt; }\n\n\nstan_data_gauss &lt;- list(\n  N = 100,\n  mu_prior = 180,\n  sigma_prior = 20,\n  sigma_prior_mean = 10,\n  sigma_prior_sd = 3\n)\n\nEseguiamo il campionamento MCMC:\n\nfit_gauss_prior &lt;- mod_gauss_prior$sample(\n  data = stan_data_gauss,\n  chains = 4, \n  iter_sampling = 1000, \n  iter_warmup = 0,\n  fixed_param = TRUE, # Nessun parametro aggiornato\n  show_messages = FALSE\n)\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\n# Estrai i campioni per mu e sigma\ndraws &lt;- fit_gauss_prior$draws(c(\"mu\", \"sigma\"))\nprint(draws)\n#&gt; # A draws_array: 1000 iterations, 4 chains, and 2 variables\n#&gt; , , variable = mu\n#&gt; \n#&gt;          chain\n#&gt; iteration   1   2   3   4\n#&gt;         1 183 178 174 183\n#&gt;         2 150 166 170 179\n#&gt;         3 210 173 178 168\n#&gt;         4 174 173 173 165\n#&gt;         5 183 217 171 191\n#&gt; \n#&gt; , , variable = sigma\n#&gt; \n#&gt;          chain\n#&gt; iteration    1    2    3    4\n#&gt;         1  7.6  6.3 14.6 13.6\n#&gt;         2 11.8  6.3 12.4  7.3\n#&gt;         3  9.1 11.0  5.6 10.8\n#&gt;         4  7.9 11.0 13.9  6.5\n#&gt;         5  8.4  7.0 11.9  8.0\n#&gt; \n#&gt; # ... with 995 more iterations\n\nEstraiamo i campioni per mu e sigma:\n\ndraws &lt;- fit_gauss_prior$draws(c(\"mu\", \"sigma\"))\n\nConvertiamo i campioni in data frame:\n\ndraws_df &lt;- as_draws_df(draws)\n\nCreaiamo un grafico della distribuzione a priori di mu:\n\ndraws_df |&gt; \n  ggplot(aes(x = mu)) +\n    geom_density(fill = \"gray\", alpha = 0.5) +\n    labs(title = \"Distribuzione Predittiva a Priori di Mu\",\n         x = \"Mu\",\n         y = \"Densità\")\n\n\n\n\n\n\n\nDistribuzione a priori di sigma:\n\ndraws_df |&gt; \n  ggplot(aes(x = sigma)) +\n    geom_density(fill = \"lightgray\", alpha = 0.5) +\n    labs(title = \"Distribuzione Predittiva a Priori di Sigma\",\n         x = \"Sigma\",\n         y = \"Densità\")\n\n\n\n\n\n\n\nIl grafico della distribuzione predittiva a priori ci mostra che i prior utilizzati nel codice Stan implicano una distribuzione della variabile di interesse y che è approssimativamente normale con media di 180 e deviazione standard di 22. Questo prior predictive check garantisce che le distribuzioni a priori dei parametri mu e sigma siano realistiche e adeguate per l’analisi dei dati considerati. Un discorso simile si può fare per sigma. Questo passaggio consente di identificare e correggere eventuali ipotesi errate prima di procedere con l’analisi dei dati osservati, migliorando così la validità dei risultati ottenuti.\n\n52.8 Riflessioni Conclusive\nLe distribuzioni predittive a priori e a posteriori, pur essendo generate in modo simile, differiscono per la fonte di informazione utilizzata nella loro costruzione.\n\nDistribuzione Predittiva a Priori: Questa distribuzione rappresenta le nostre aspettative sui dati prima che qualsiasi osservazione effettiva sia disponibile. Per costruirla, prendiamo i valori dei parametri dalla distribuzione a priori e li utilizziamo nella funzione di verosimiglianza per generare dati simulati. La distribuzione risultante di questi dati generati è la distribuzione predittiva a priori, che riflette le nostre conoscenze e incertezze iniziali, prima di osservare i dati reali.\nDistribuzione Predittiva a Posteriori: Dopo aver osservato i dati, aggiorniamo le nostre credenze sui parametri utilizzando il teorema di Bayes, ottenendo così la distribuzione a posteriori dei parametri. La distribuzione predittiva a posteriori viene quindi generata prendendo valori dei parametri dalla distribuzione a posteriori, che ora incorpora l’informazione ottenuta dai dati osservati, e utilizzandoli nella funzione di verosimiglianza per generare nuovi dati simulati. Questa distribuzione riflette le nostre previsioni sui dati futuri o non osservati, dopo aver tenuto conto dei dati già raccolti.\n\nLa differenza principale tra queste due distribuzioni predittive risiede nella distribuzione dei parametri utilizzata: nella distribuzione predittiva a priori si utilizzano i parametri estratti dal prior, mentre nella distribuzione predittiva a posteriori si utilizzano i parametri estratti dal posterior. La distribuzione predittiva a posteriori è generalmente più informativa poiché integra i dati osservati, migliorando le previsioni future.\nÈ cruciale per l’integrità del modello che la distribuzione predittiva a posteriori sia coerente con la distribuzione dei dati osservati. Per verificare questa coerenza, si utilizzano le verifiche predittive a posteriori, confrontando la distribuzione predittiva con i dati empirici tramite tecniche come le stime di densità kernel (KDE). Questo confronto permette di valutare quanto bene il modello riesca ad approssimare la struttura reale dei dati e la sua capacità di fornire previsioni affidabili.\nAd esempio, consideriamo un modello gaussiano con varianza \\(\\sigma^2\\) nota:\n\\[\n\\begin{aligned}\n  y\\sim \\mathop{\\mathrm{N}}(\\theta,\\sigma^2),\n\\end{aligned}\n\\]\ndove \\(\\sigma^2\\) descrive l’incertezza aleatoria. Usando un prior uniforme, la distribuzione a posteriori per \\(\\theta\\) sarà:\n\\[\n\\begin{aligned}\n  p(\\theta|y) \\sim \\mathop{\\mathrm{N}}(\\theta|\\bar{y},\\sigma^2/n),\n\\end{aligned}\n\\]\ndove \\(\\sigma^2/n\\) rappresenta l’incertezza epistemica legata a \\(\\theta\\). La distribuzione predittiva a posteriori per un nuovo valore \\(\\tilde{y}\\) sarà:\n\\[\n\\begin{aligned}\n  p(\\tilde{y}|y) \\sim \\mathop{\\mathrm{N}}(\\tilde{y}|\\bar{y},\\sigma^2+\\sigma^2/n),\n\\end{aligned}\n\\]\nIn questo caso, l’incertezza totale è data dalla somma dell’incertezza epistemica (\\(\\sigma^2/n\\)) e dell’incertezza aleatoria (\\(\\sigma^2\\)).\nInformazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] readr_2.1.5           cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        tzdb_0.5.0            ps_1.9.1             \n#&gt; [22] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [25] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [28] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [31] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [34] knitr_1.50            zoo_1.8-14            Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       hms_1.1.3            \n#&gt; [61] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [64] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [67] data.table_1.17.8     mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [70] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [73] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [76] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [79] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [82] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [85] lifecycle_1.0.4       MASS_7.3-65\n\nBibliografia\n\n\n\n\n\n\nGelman, A., & Shalizi, C. R. (2013). Philosophy and the practice of Bayesian statistics. British Journal of Mathematical and Statistical Psychology, 66(1), 8–38.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction_rev.html#implementazione-con-cmdstanr",
    "href": "chapters/mcmc/06_mcmc_prediction_rev.html#implementazione-con-cmdstanr",
    "title": "52  La predizione bayesiana",
    "section": "\n52.5 Implementazione con cmdstanr\n",
    "text": "52.5 Implementazione con cmdstanr\n\nPer illustrare come viene generata la distribuzione predittiva a posteriori nel contesto del modello normale-normale, possiamo utilizzare cmdstanr per eseguire l’analisi. Il codice seguente mostra come configurare il modello e generare previsioni.\n\n# Dati osservati\nset.seed(123)  # Imposta il seed per la riproducibilità\ny_observed &lt;- rnorm(100, 170, 10)\nmean_y &lt;- mean(y_observed)\nstd_y &lt;- sd(y_observed)\n\n# Parametri a priori\nmu_0 &lt;- 175\ntau_0 &lt;- 5\n\n# Parametri posteriori\ntau_n_sq &lt;- (tau_0^2 * std_y^2) / (tau_0^2 + std_y^2)\ntau_n &lt;- sqrt(tau_n_sq)\nmu_n &lt;- (tau_0^2 * mean_y + std_y^2 * mu_0) / (tau_0^2 + std_y^2)\n\n# Parametri predittivi\nn_fut &lt;- 100\nsigma_pred_sq &lt;- tau_n_sq + (std_y^2 / n_fut)\nsigma_pred &lt;- sqrt(sigma_pred_sq)\nmu_pred &lt;- mu_n\n\n# Simulazioni\ny_pred_samples &lt;- rnorm(1000, mu_pred, sigma_pred)\n\n# Dati per ggplot\ndata &lt;- data.frame(Heights = y_pred_samples)\n\n# Grafico\np &lt;- ggplot(data, aes(x = Heights)) +\n  geom_histogram(\n    aes(y = ..density..), \n    bins = 30, \n    fill = \"gray\", \n    colour = \"gray\", \n    alpha = 0.5\n  ) +\n  geom_density(colour = \"black\", size = 1.5) +\n  geom_vline(\n    xintercept = mu_pred, \n    colour = \"gray\", \n    linetype = \"dashed\", \n    size = 1\n  ) +\n  labs(title = \"Posterior Predictive Distribution for Heights\",\n       x = \"Heights (cm)\",\n       y = \"Density\") +\n  theme(legend.position = \"none\")\n\n# Visualizza il grafico\nprint(p)\n\n\n\n\n\n\n\nQuesto codice produce un grafico che illustra visivamente la distribuzione predittiva a posteriori per le altezze nel nostro campione di 100 nuove osservazioni, tenendo conto sia dei dati osservati che delle nostre aspettative iniziali.\nIn sintesi, la distribuzione predittiva a posteriori è stata generata nel modo seguente:\n\nCampioniamo un valore \\(\\mu\\) dalla distribuzione a posteriori di \\(\\mu\\).\nCampioniamo un valore \\(\\sigma\\) dalla distribuzione a posteriori di \\(\\sigma\\).\nUtilizziamo questi valori per generare un campione dalla distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nRipetiamo questo processo molte volte.\n\nLa distribuzione dei valori ottenuti da questi campionamenti costituisce la distribuzione predittiva a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction_rev.html#metodo-mcmc",
    "href": "chapters/mcmc/06_mcmc_prediction_rev.html#metodo-mcmc",
    "title": "52  La predizione bayesiana",
    "section": "\n52.6 Metodo MCMC",
    "text": "52.6 Metodo MCMC\nQuando usiamo un PPL come Stan, la distribuzione predittiva viene stimata mediante il campionamento da una catena di Markov, che è particolarmente utile in scenari complessi dove l’analisi analitica potrebbe essere impraticabile. Attraverso i metodi MCMC, si stimano le potenziali osservazioni future \\(p(\\tilde{y} \\mid y)\\), indicate come \\(p(y^{rep} \\mid y)\\), seguendo questi passaggi:\n\nSi campiona \\(\\theta_i \\sim p(\\theta \\mid y)\\): Viene selezionato casualmente un valore del parametro (o dei parametri) dalla distribuzione a posteriori.\nSi campiona \\(y^{rep} \\sim p(y^{rep} \\mid \\theta_i)\\): Viene scelta casualmente un’osservazione dalla funzione di verosimiglianza, condizionata al valore del parametro (o dei parametri)ottenuto nel passo precedente.\n\nRipetendo questi due passaggi un numero sufficiente di volte, l’istogramma risultante approssimerà la distribuzione predittiva a posteriori.\nEsaminiamo ora come ottenere la distribuzione predittiva a posteriori con Stan per i dati dell’esempio precedente. Iniziamo creando le distribuzioni a posteriori di \\(\\mu\\) e \\(\\sigma\\).\nDefiniamo un dizionario che contiene i dati.\n\nstan_data_gauss = list(\n  N = length(y_observed),\n  y = y_observed,\n  mu_prior = 180,\n  sigma_prior = 20,\n  sigma_prior_mean = 10,\n  sigma_prior_sd = 3\n)\n\n\ny_mean = mean(y_observed)\ny_std = sd(y_observed)\n\ny_mean\n#&gt; [1] 171\ny_std\n#&gt; [1] 9.13\n\nCompiliamo e stampiamo il modello Stan:\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"gaussian_model.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N; // number of observations\n#&gt;   vector[N] y; // observed data\n#&gt;   real mu_prior; // prior mean for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior; // prior standard deviation for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior_mean; // prior mean for sigma\n#&gt;   real&lt;lower=0&gt; sigma_prior_sd; // prior standard deviation for sigma\n#&gt; }\n#&gt; parameters {\n#&gt;   real mu; // parameter of interest\n#&gt;   real&lt;lower=0&gt; sigma; // parameter for the standard deviation\n#&gt; }\n#&gt; model {\n#&gt;   mu ~ normal(mu_prior, sigma_prior); // prior for mu\n#&gt;   sigma ~ normal(sigma_prior_mean, sigma_prior_sd); // prior for sigma\n#&gt;   y ~ normal(mu, sigma); // likelihood\n#&gt; }\n#&gt; generated quantities {\n#&gt;   array[N] real y_rep;\n#&gt;   for (n in 1 : N) {\n#&gt;     y_rep[n] = normal_rng(mu, sigma);\n#&gt;   }\n#&gt; }\n\nEseguiamo il campionamento MCMC:\n\nfit &lt;- mod$sample(\n  data = stan_data_gauss,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000, \n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\nfit$summary(c(\"mu\", \"sigma\"))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable    mean  median    sd   mad      q5     q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       170.928 170.931 0.932 0.943 169.395 172.467 1.001 7320.825 5507.575\n#&gt; 2 sigma      9.272   9.233 0.652 0.647   8.277  10.396 1.001 6674.842 5412.095\n\nEstraiamo i dati prodotti dal modello y_rep e i dati osservati y:\n\n# Extract posterior predictive samples for y_rep\ny_rep &lt;- fit$draws(variables = \"y_rep\", format = \"draws_matrix\")\n\n# Extract observed data\ny_obs &lt;- stan_data_gauss$y\n\nConvertiamo y_rep in una matrice per compatibilità con {bayesplot}.\n\n# Convert y_rep to a matrix\ny_rep_matrix &lt;- as.matrix(y_rep)\n\nGeneriamo il posterior predictive chech plot:\n\n# Posterior predictive check plot\nset.seed(123)\nselected_indices &lt;- sample(nrow(y_rep_matrix), 50)\nppc_dens_overlay(y = y_obs, yrep = y_rep_matrix[selected_indices, ])\n\n\n\n\n\n\n\nLa distribuzione predittiva a posteriori è utilizzata per eseguire i controlli predittivi a posteriori (PPC), noti come Posterior Predictive Checks. I PPC consistono in un confronto grafico tra \\(p(y^{rep} \\mid y)\\), ossia la distribuzione delle osservazioni future previste, e i dati osservati \\(y\\). Questo confronto visivo permette di valutare se il modello utilizzato è adeguato per descrivere le proprietà dei dati osservati.\nOltre al confronto grafico tra le distribuzioni \\(p(y)\\) e \\(p(y^{rep})\\), è possibile effettuare un confronto tra le distribuzioni di varie statistiche descrittive calcolate su diversi campioni \\(y^{rep}\\) e le corrispondenti statistiche calcolate sui dati osservati. Tipicamente, vengono considerate statistiche descrittive come la media, la varianza, la deviazione standard, il minimo o il massimo, ma è possibile confrontare qualsiasi altra statistica rilevante.\nI controlli predittivi a posteriori offrono un valido strumento per un’analisi critica delle prestazioni del modello e, se necessario, per apportare eventuali modifiche o considerare modelli alternativi più adatti ai dati in esame.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction_rev.html#distribuzione-predittiva-a-priori",
    "href": "chapters/mcmc/06_mcmc_prediction_rev.html#distribuzione-predittiva-a-priori",
    "title": "52  La predizione bayesiana",
    "section": "\n52.7 Distribuzione Predittiva a Priori",
    "text": "52.7 Distribuzione Predittiva a Priori\nLa verifica predittiva a priori è un metodo fondamentale per esplorare le implicazioni dei tuoi prior. Genera dati simulati basandosi unicamente sui prior, ignorando completamente i dati osservati. Questo permette di rispondere a domande cruciali come:\n\nI dati generati dal prior riflettono scenari plausibili?\nIl prior è troppo restrittivo o troppo ampio rispetto ai dati attesi?\n\nQuesta verifica è particolarmente utile per identificare eventuali incongruenze o assunzioni non realistiche prima di raccogliere i dati osservati.\n\n52.7.1 Modello Beta-Binomiale\nIniziamo con il caso più semplice. Il modello beta-binomiale è un esempio classico per illustrare la verifica predittiva a priori. In questo modello:\n\n\ntheta rappresenta la probabilità di successo.\nIl prior su theta è distribuito secondo una distribuzione Beta parametrizzata da alpha_prior e beta_prior.\nI dati (y) seguono una distribuzione Bernoulliana condizionata su theta.\n\nIl modello Stan per l’inferenza sui dati osservati è il seguente:\ndata {\n  int&lt;lower=0&gt; N;             // Numero di osservazioni\n  array[N] int&lt;lower=0, upper=1&gt; y; // Dati osservati (successi)\n  real&lt;lower=0&gt; alpha_prior;  // Parametro alpha del prior Beta\n  real&lt;lower=0&gt; beta_prior;   // Parametro beta del prior Beta\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; // Probabilità di successo\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior); // Prior su theta\n  y ~ bernoulli(theta);                  // Likelihood\n}\nPer eseguire la simulazione dalla distribuzione predittiva a priori, rimuoviamo il blocco model e utilizziamo generated quantities per simulare:\n\nl’estrazione di un valore per theta dalla distribuzione Beta specificata dai parametri del prior;\nla generazione di successi simulati (y_sim) dalla distribuzione Bernoulliana condizionata su theta.\n\nCompiliamo il modello:\n\n# Create a CmdStanModel object\nmod_prior &lt;- cmdstan_model(here::here(\"stan\", \"betabinomial_prior.stan\"))\n\nEsaminiamo il modello:\n\nmod_prior$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N;             // Numero di osservazioni\n#&gt;   real&lt;lower=0&gt; alpha_prior;  // Parametro alpha del prior Beta\n#&gt;   real&lt;lower=0&gt; beta_prior;   // Parametro beta del prior Beta\n#&gt; }\n#&gt; generated quantities {\n#&gt;   real&lt;lower=0, upper=1&gt; theta_prior;    // Valore estratto da Beta(alpha_prior, beta_prior)\n#&gt;   array[N] int&lt;lower=0, upper=1&gt; y_sim;  // Osservazioni simulate\n#&gt;   \n#&gt;   theta_prior = beta_rng(alpha_prior, beta_prior); // Generazione di theta\n#&gt;   for (n in 1:N) {\n#&gt;     y_sim[n] = bernoulli_rng(theta_prior); // Simulazione dei successi\n#&gt;   }\n#&gt; }\n\nIn questo script abbiamo\n\n\neliminato il blocco model: Questo blocco serve per l’inferenza Bayesiana, ma non è necessario per generare dati a priori.\n\naggiunto il blocco generated quantities: In questo blocco generiamo quantità di interesse, come i dati simulati y_sim e il valore di theta estratto dalla distribuzione a priori.\n\nutilizzato la funzione beta_rng per estrarre un valore per theta dalla distribuzione \\(\\mathcal{Beta}\\) definita dai parametri alpha_prior e beta_prior. Questo valore rappresenta una possibile realizzazione del parametro prima di osservare i dati.\n\nutilizzato la funzione binomial_rng per simulare N osservazioni dalla distribuzione binomiale. Il parametro di successo theta è fissato al valore estratto theta_prior.\n\nIn sostanza, questo codice ci permette di generare un dataset simulato che potrebbe essere osservato se il processo stocastico fosse governato unicamente dai parametri specificati nella distribuzione a priori. In questo modo, possiamo valutare le proprietà del modello e la sua capacità di generare dati simili a quelli reali, prima ancora di avere a disposizione i dati osservati.\nLa distribuzione a priori rappresenta la nostra conoscenza o credenza sul valore del parametro theta prima di osservare i dati. Scegliendo diversi valori per alpha_prior e beta_prior, possiamo specificare diverse distribuzioni a priori e quindi esplorare come queste influenzano i risultati della simulazione.\nI dati richiesti dal modello vengono specificati nel modo seguente:\n\n# Dati osservati\nN &lt;- 100               # Numero di osservazioni\n\n# Parametri del prior\nalpha_prior &lt;- 4\nbeta_prior &lt;- 6\n\n# Dati per Stan\nstan_data_prior &lt;- list(\n  N = N, \n  alpha_prior = alpha_prior, \n  beta_prior = beta_prior\n)\n\nEseguiamo il campionamento:\n\n# Simulazione del prior\nfit_prior &lt;- mod_prior$sample(\n  data = stan_data_prior,\n  chains = 4, \n  iter_sampling = 1000, \n  iter_warmup = 0,\n  fixed_param = TRUE, \n  show_messages = FALSE\n)\n\nSi noti l’argomento fixed_param = TRUE in quanto nessun parametro viene aggiornato.\nEstraiamo i campioni a posteriori e visualizziamo i risultati:\n\n# Estraiamo theta_prior e y_sim\ntheta_prior &lt;- fit_prior$draws(\"theta_prior\")\ny_sim &lt;- fit_prior$draws(\"y_sim\")\n\nGeneriamo la distribuzione a priori di theta:\n\n# Distribuzione a priori di theta\nhist(\n  theta_prior, \n  main = \"Distribuzione a priori di theta\", \n  xlab = \"theta\", \n  freq = FALSE\n)\n\n\n\n\n\n\n\nCostruiamo la distribuzione predittiva a priori della proporzione di successi:\n\n# Distribuzione dei successi simulati\ny_sim_mean &lt;- rowMeans(y_sim)\nhist(\n  y_sim_mean, \n  breaks = 20, \n  main = \"Distribuzione predittiva a priori\", \n  xlab = \"Proporzione di successi\", \n  freq = FALSE\n)\n\n\n\n\n\n\n\nLa distribuzione predittiva a priori mostra che i dati simulati riflettono il comportamento atteso dato il prior. Per il prior \\(\\mathcal{Beta}(4, 6)\\):\n\nLa media attesa di theta è \\(\\mathbb{E}[\\theta] = \\frac{\\alpha}{\\alpha + \\beta} = 0.4\\).\nLa varianza attesa è \\(\\text{Var}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\).\n\nCon 14 successi su 100 osservazioni reali, corrispondenti a una proporzione di 0.14, notiamo che:\n\nIl prior \\(\\mathcal{Beta}(4, 6)\\) è informativo, con un centro più alto rispetto ai dati osservati.\nSe vogliamo un prior meno concentrato (ad esempio \\(\\mathcal{Beta}(2, 2)\\)), i dati avranno un peso maggiore.\n\nIn conclusione,\n\nutilizzare un prior informativo è appropriato se abbiamo conoscenze precedenti robuste;\nse vogliamo un prior che lasci maggior spazio ai dati osservati, potremmo scegliere distribuzioni più ampie come \\(\\mathcal{Beta}(2, 2)\\).\n\nLa verifica predittiva a priori è uno strumento potente per convalidare queste scelte.\n\n52.7.2 Modello Gaussiano\nConsideriamo un secondo esempio, facciamo riferimento al caso discusso in precedenza dove veniva considerato un campione di dati gaussiani e un modello gaussiano in cui le distribuzioni a priori per μ e σ erano gaussiane.\nCompiliamo e stampiamo il modello Stan per generare la distribuzione predittiva a priori:\n\nmod_gauss_prior &lt;- cmdstan_model(\n  here::here(\"stan\", \"gaussian_model_prior.stan\")\n)\n\n\nmod_gauss_prior$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N; // number of observations\n#&gt;   real mu_prior; // prior mean for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior; // prior standard deviation for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior_mean; // prior mean for sigma\n#&gt;   real&lt;lower=0&gt; sigma_prior_sd; // prior standard deviation for sigma\n#&gt; }\n#&gt; generated quantities {\n#&gt;   real mu = normal_rng(mu_prior, sigma_prior); // prior draw for mu\n#&gt;   real&lt;lower=0&gt; sigma = normal_rng(sigma_prior_mean, sigma_prior_sd); // prior draw for sigma\n#&gt;   array[N] real y_rep;\n#&gt;   for (n in 1 : N) {\n#&gt;     y_rep[n] = normal_rng(mu, sigma);\n#&gt;   }\n#&gt; }\n\n\nstan_data_gauss &lt;- list(\n  N = 100,\n  mu_prior = 180,\n  sigma_prior = 20,\n  sigma_prior_mean = 10,\n  sigma_prior_sd = 3\n)\n\nEseguiamo il campionamento MCMC:\n\nfit_gauss_prior &lt;- mod_gauss_prior$sample(\n  data = stan_data_gauss,\n  chains = 4, \n  iter_sampling = 1000, \n  iter_warmup = 0,\n  fixed_param = TRUE, # Nessun parametro aggiornato\n  show_messages = FALSE\n)\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\n# Estrai i campioni per mu e sigma\ndraws &lt;- fit_gauss_prior$draws(c(\"mu\", \"sigma\"))\nprint(draws)\n#&gt; # A draws_array: 1000 iterations, 4 chains, and 2 variables\n#&gt; , , variable = mu\n#&gt; \n#&gt;          chain\n#&gt; iteration   1   2   3   4\n#&gt;         1 183 178 174 183\n#&gt;         2 150 166 170 179\n#&gt;         3 210 173 178 168\n#&gt;         4 174 173 173 165\n#&gt;         5 183 217 171 191\n#&gt; \n#&gt; , , variable = sigma\n#&gt; \n#&gt;          chain\n#&gt; iteration    1    2    3    4\n#&gt;         1  7.6  6.3 14.6 13.6\n#&gt;         2 11.8  6.3 12.4  7.3\n#&gt;         3  9.1 11.0  5.6 10.8\n#&gt;         4  7.9 11.0 13.9  6.5\n#&gt;         5  8.4  7.0 11.9  8.0\n#&gt; \n#&gt; # ... with 995 more iterations\n\nEstraiamo i campioni per mu e sigma:\n\ndraws &lt;- fit_gauss_prior$draws(c(\"mu\", \"sigma\"))\n\nConvertiamo i campioni in data frame:\n\ndraws_df &lt;- as_draws_df(draws)\n\nCreaiamo un grafico della distribuzione a priori di mu:\n\ndraws_df |&gt; \n  ggplot(aes(x = mu)) +\n    geom_density(fill = \"gray\", alpha = 0.5) +\n    labs(title = \"Distribuzione Predittiva a Priori di Mu\",\n         x = \"Mu\",\n         y = \"Densità\")\n\n\n\n\n\n\n\nDistribuzione a priori di sigma:\n\ndraws_df |&gt; \n  ggplot(aes(x = sigma)) +\n    geom_density(fill = \"lightgray\", alpha = 0.5) +\n    labs(title = \"Distribuzione Predittiva a Priori di Sigma\",\n         x = \"Sigma\",\n         y = \"Densità\")\n\n\n\n\n\n\n\nIl grafico della distribuzione predittiva a priori ci mostra che i prior utilizzati nel codice Stan implicano una distribuzione della variabile di interesse y che è approssimativamente normale con media di 180 e deviazione standard di 22. Questo prior predictive check garantisce che le distribuzioni a priori dei parametri mu e sigma siano realistiche e adeguate per l’analisi dei dati considerati. Un discorso simile si può fare per sigma. Questo passaggio consente di identificare e correggere eventuali ipotesi errate prima di procedere con l’analisi dei dati osservati, migliorando così la validità dei risultati ottenuti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction_rev.html#riflessioni-conclusive",
    "href": "chapters/mcmc/06_mcmc_prediction_rev.html#riflessioni-conclusive",
    "title": "52  La predizione bayesiana",
    "section": "\n52.8 Riflessioni Conclusive",
    "text": "52.8 Riflessioni Conclusive\nLe distribuzioni predittive a priori e a posteriori, pur essendo generate in modo simile, differiscono per la fonte di informazione utilizzata nella loro costruzione.\n\nDistribuzione Predittiva a Priori: Questa distribuzione rappresenta le nostre aspettative sui dati prima che qualsiasi osservazione effettiva sia disponibile. Per costruirla, prendiamo i valori dei parametri dalla distribuzione a priori e li utilizziamo nella funzione di verosimiglianza per generare dati simulati. La distribuzione risultante di questi dati generati è la distribuzione predittiva a priori, che riflette le nostre conoscenze e incertezze iniziali, prima di osservare i dati reali.\nDistribuzione Predittiva a Posteriori: Dopo aver osservato i dati, aggiorniamo le nostre credenze sui parametri utilizzando il teorema di Bayes, ottenendo così la distribuzione a posteriori dei parametri. La distribuzione predittiva a posteriori viene quindi generata prendendo valori dei parametri dalla distribuzione a posteriori, che ora incorpora l’informazione ottenuta dai dati osservati, e utilizzandoli nella funzione di verosimiglianza per generare nuovi dati simulati. Questa distribuzione riflette le nostre previsioni sui dati futuri o non osservati, dopo aver tenuto conto dei dati già raccolti.\n\nLa differenza principale tra queste due distribuzioni predittive risiede nella distribuzione dei parametri utilizzata: nella distribuzione predittiva a priori si utilizzano i parametri estratti dal prior, mentre nella distribuzione predittiva a posteriori si utilizzano i parametri estratti dal posterior. La distribuzione predittiva a posteriori è generalmente più informativa poiché integra i dati osservati, migliorando le previsioni future.\nÈ cruciale per l’integrità del modello che la distribuzione predittiva a posteriori sia coerente con la distribuzione dei dati osservati. Per verificare questa coerenza, si utilizzano le verifiche predittive a posteriori, confrontando la distribuzione predittiva con i dati empirici tramite tecniche come le stime di densità kernel (KDE). Questo confronto permette di valutare quanto bene il modello riesca ad approssimare la struttura reale dei dati e la sua capacità di fornire previsioni affidabili.\nAd esempio, consideriamo un modello gaussiano con varianza \\(\\sigma^2\\) nota:\n\\[\n\\begin{aligned}\n  y\\sim \\mathop{\\mathrm{N}}(\\theta,\\sigma^2),\n\\end{aligned}\n\\]\ndove \\(\\sigma^2\\) descrive l’incertezza aleatoria. Usando un prior uniforme, la distribuzione a posteriori per \\(\\theta\\) sarà:\n\\[\n\\begin{aligned}\n  p(\\theta|y) \\sim \\mathop{\\mathrm{N}}(\\theta|\\bar{y},\\sigma^2/n),\n\\end{aligned}\n\\]\ndove \\(\\sigma^2/n\\) rappresenta l’incertezza epistemica legata a \\(\\theta\\). La distribuzione predittiva a posteriori per un nuovo valore \\(\\tilde{y}\\) sarà:\n\\[\n\\begin{aligned}\n  p(\\tilde{y}|y) \\sim \\mathop{\\mathrm{N}}(\\tilde{y}|\\bar{y},\\sigma^2+\\sigma^2/n),\n\\end{aligned}\n\\]\nIn questo caso, l’incertezza totale è data dalla somma dell’incertezza epistemica (\\(\\sigma^2/n\\)) e dell’incertezza aleatoria (\\(\\sigma^2\\)).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction_rev.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/06_mcmc_prediction_rev.html#informazioni-sullambiente-di-sviluppo",
    "title": "52  La predizione bayesiana",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] readr_2.1.5           cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        tzdb_0.5.0            ps_1.9.1             \n#&gt; [22] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [25] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [28] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [31] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [34] knitr_1.50            zoo_1.8-14            Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       hms_1.1.3            \n#&gt; [61] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [64] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [67] data.table_1.17.8     mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [70] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [73] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [76] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [79] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [82] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [85] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction_rev.html#bibliografia",
    "href": "chapters/mcmc/06_mcmc_prediction_rev.html#bibliografia",
    "title": "52  La predizione bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html",
    "href": "chapters/mcmc/06_mcmc_prediction.html",
    "title": "52  Controlli predittivi bayesiani (a priori e a posteriori) con cmdstanr",
    "section": "",
    "text": "Introduzione\nQuando costruiamo un modello, possiamo chiederci due cose diverse:\nNel lavoro psicologico applicato, la seconda domanda è spesso quella decisiva: vogliamo usare il modello per prevedere come si comporteranno nuovi dati e, soprattutto, per capire se il modello riproduce in modo plausibile le caratteristiche dei dati reali. Da qui nascono due strumenti pratici:\nIn questo capitolo mettiamo in pratica queste idee: vedremo come simulare dati dal modello, visualizzarli e confrontarli con i dati reali per giudicare la coerenza del modello. L’obiettivo non è aggiungere nuova teoria, ma imparare un metodo operativo che userai spesso: generare, guardare, confrontare.\nCosa faremo concretamente",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Controlli predittivi bayesiani (a priori e a posteriori) con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#introduzione",
    "href": "chapters/mcmc/06_mcmc_prediction.html#introduzione",
    "title": "52  Controlli predittivi bayesiani (a priori e a posteriori) con cmdstanr",
    "section": "",
    "text": "che cosa sappiamo dei parametri dati i dati osservati (la posterior), e\n\n\nche cosa ci aspettiamo di osservare in nuove rilevazioni (la distribuzione predittiva a posteriori).\n\n\n\n\nControlli predittivi a priori (prior predictive checks): generiamo dati sintetici prima di vedere i dati reali, solo dalle ipotesi iniziali (prior). Se questi scenari “immaginati” risultano totalmente irrealistici, il problema è nelle nostre assunzioni di partenza.\n\n\nControlli predittivi a posteriori (posterior predictive checks): generiamo dati sintetici dopo aver visto i dati, cioè dalla distribuzione dei parametri aggiornata (posteriori). Questo ci dice se il modello, una volta “istruito” dai dati, è in grado di produrre esiti simili a quelli osservati.\n\n\n\n\n\n\n\n\nIdea in una riga\n\n\n\nLa distribuzione predittiva posteriore è una media pesata delle predizioni possibili, secondo quanto i parametri sono plausibili alla luce dei dati:\n\\[\np(\\tilde y \\mid y) \\;=\\; \\int p(\\tilde y \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta.\n\\] In pratica: campioni \\(\\theta\\) verosimili → genera dati \\(\\tilde{y}\\) → confronta con i dati osservati.\n\n\n\n\nGenereremo dati a priori per verificare che le ipotesi iniziali non producano scenari assurdi.\n\nGenereremo dati a posteriori per valutare se il modello allenato “sa” riprodurre i dati.\n\nUseremo grafici semplici per un confronto visivo chiaro.\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; source()\n\n# Carichiamo i pacchetti necessari\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, insight, bayesplot, ggplot2)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Controlli predittivi bayesiani (a priori e a posteriori) con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#sec-posterior-predictive-distribution",
    "href": "chapters/mcmc/06_mcmc_prediction.html#sec-posterior-predictive-distribution",
    "title": "52  Prior e posterior check con cmdstanr",
    "section": "\n52.1 La distribuzione predittiva a posteriori",
    "text": "52.1 La distribuzione predittiva a posteriori\nNei capitoli precedenti abbiamo già definito la distribuzione predittiva a posteriori e chiarito la sua utilità nei Posterior Predictive Checks (PPC). Qui ci limiteremo a ricordare che essa si scrive come\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta ,\n\\] e a mostrarne l’implementazione concreta in Stan e cmdstanr.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Prior e posterior check con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#distribuzione-predittiva-a-posteriori-nel-modello-normale-normale",
    "href": "chapters/mcmc/06_mcmc_prediction.html#distribuzione-predittiva-a-posteriori-nel-modello-normale-normale",
    "title": "52  Prior e posterior check con cmdstanr",
    "section": "\n52.2 Distribuzione predittiva a posteriori nel modello normale-normale",
    "text": "52.2 Distribuzione predittiva a posteriori nel modello normale-normale\nAbbiamo già visto nei capitoli precedenti che, nel caso coniugato normale–normale, la distribuzione predittiva a posteriori si ottiene combinando l’incertezza sui parametri (\\(\\mu\\)) con la variabilità dei dati. In particolare:\n\\[\n\\tilde{y} \\mid Y \\sim \\mathcal{N}\\!\\left(\\mu_n,\\; \\tau_n^2 + \\tfrac{\\sigma^2}{n_{\\text{fut}}}\\right),\n\\] dove \\(\\mu_n\\) e \\(\\tau_n^2\\) sono i parametri della distribuzione a posteriori di \\(\\mu\\).\nIn questa sezione non ci soffermiamo sui dettagli analitici (già sviluppati nei capitoli precedenti), ma vediamo come ottenere la stessa distribuzione con Stan e cmdstanr, utilizzando simulazioni MCMC.\n\n\n\n\n\n\nRichiamo teorico\n\n\n\nNel modello coniugato normale–normale, se \\(\\mu \\sim \\mathcal{N}(\\mu_0, \\tau_0^2)\\) e i dati \\(y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)\\), la distribuzione predittiva a posteriori è ancora normale, con:\n\nmedia\\[\n\\mu_n = \\frac{\\tau_0^2 \\bar{y} + \\sigma^2 \\mu_0}{\\tau_0^2 + \\sigma^2}\n\\]\n\nvarianza\\[\n\\tau_n^2 + \\frac{\\sigma^2}{n_{\\text{fut}}}\n\\]\n\n\nEsempio numerico. Con \\(\\mu_0 = 175\\), \\(\\tau_0 = 5\\), \\(\\bar{y}=170\\), \\(\\sigma = 10\\), \\(n=100\\), si ottiene:\n\\[\n\\tilde{Y} \\sim \\mathcal{N}(174,\\; 4.58^2).\n\\]",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Prior e posterior check con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#implementazione-con-stan-e-cmdstanr",
    "href": "chapters/mcmc/06_mcmc_prediction.html#implementazione-con-stan-e-cmdstanr",
    "title": "52  Prior e posterior check con cmdstanr",
    "section": "\n52.3 Implementazione con Stan e cmdstanr\n",
    "text": "52.3 Implementazione con Stan e cmdstanr\n\nPer illustrare come ottenere la distribuzione predittiva a posteriori nel modello normale–normale, passiamo ora all’implementazione con Stan.\n\n52.3.1 Modello Stan\nCreiamo un file Stan (normal_pred.stan) con il flag prior_only per poter generare sia dati a priori che a posteriori dallo stesso modello:\ndata {\n  int&lt;lower=0&gt; N;          // numero di osservazioni\n  vector[N] y;             // dati osservati\n  real mu0;                // media a priori\n  real&lt;lower=0&gt; tau0;      // dev.st. a priori\n  real&lt;lower=0&gt; sigma;     // dev.st. nota\n  int&lt;lower=0,upper=1&gt; prior_only; // se 1: ignora i dati\n}\nparameters {\n  real mu;                 // media sconosciuta\n}\nmodel {\n  mu ~ normal(mu0, tau0);\n  if (prior_only == 0) {\n    y ~ normal(mu, sigma);\n  }\n}\ngenerated quantities {\n  real y_rep;\n  y_rep = normal_rng(mu, sigma); // un dato replicato\n}\n\n52.3.2 Analisi con cmdstanr\n\n\n# Dati osservati\nN &lt;- 100\ny &lt;- rnorm(N, mean = 170, sd = 10)\n\n# Dati per Stan\nstan_data &lt;- list(\n  N = N,\n  y = y,\n  mu0 = 175,\n  tau0 = 5,\n  sigma = 10,\n  prior_only = 0\n)\n\n\n# Compilazione (forza ricompilazione se hai appena modificato il .stan)\nmod &lt;- cmdstan_model(here::here(\"stan\", \"normal_pred.stan\"))\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  chains = 4, iter_warmup = 500, iter_sampling = 1000,\n  refresh = 0\n)\n\n\n52.3.3 Visualizzazione\n\n# === ESTRAZIONE Y_REP ===\n# Estrai tutte le variabili y_rep[1], y_rep[2], ..., y_rep[N]\ny_rep_vars &lt;- paste0(\"y_rep[\", 1:N, \"]\")\ny_rep &lt;- as_draws_matrix(fit$draws(y_rep_vars))\n\n# Controlla le dimensioni\nprint(paste(\"Dati osservati:\", length(y)))\n#&gt; [1] \"Dati osservati: 100\"\nprint(paste(\"Predizioni:\", dim(y_rep)))\n#&gt; [1] \"Predizioni: 4000\" \"Predizioni: 100\"\n\n\n# === GRAFICI PPC ===\n# Usa solo le prime 200 iterazioni per grafici più veloci\nbayesplot::ppc_dens_overlay(y, y_rep[1:200, ])\n\n\n\n\n\n\n\nIl grafico confronta la distribuzione osservata (y) con un insieme di dati replicati dal modello (y_rep). Se il modello è ben specificato, le distribuzioni dovrebbero essere compatibili.\nQuesto codice produce un grafico che illustra visivamente la distribuzione predittiva a posteriori per le altezze nel nostro campione di 100 nuove osservazioni, tenendo conto sia dei dati osservati che delle nostre aspettative iniziali.\nIn sintesi, la distribuzione predittiva a posteriori è stata generata nel modo seguente:\n\nCampioniamo un valore \\(\\mu\\) dalla distribuzione a posteriori di \\(\\mu\\).\nCampioniamo un valore \\(\\sigma\\) dalla distribuzione a posteriori di \\(\\sigma\\).\nUtilizziamo questi valori per generare un campione dalla distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nRipetiamo questo processo molte volte.\n\nLa distribuzione dei valori ottenuti da questi campionamenti costituisce la distribuzione predittiva a posteriori.\nAltri grafici utili:\n\nbayesplot::ppc_stat(y, y_rep, stat = \"mean\")\n\n\n\n\n\n\n\n\nbayesplot::ppc_intervals(y, y_rep[1:100, ])",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Prior e posterior check con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#distribuzione-predittiva-a-priori",
    "href": "chapters/mcmc/06_mcmc_prediction.html#distribuzione-predittiva-a-priori",
    "title": "52  Controlli predittivi bayesiani (a priori e a posteriori) con cmdstanr",
    "section": "\n52.3 Distribuzione predittiva a priori",
    "text": "52.3 Distribuzione predittiva a priori\nPrima di raccogliere un solo dato, possiamo chiederci: “Se il mondo fosse davvero come lo descrive il nostro modello, che tipo di dati mi aspetterei di osservare?”\nQuesta è la predizione a priori (prior predictive): generiamo dati simulati solo dalle assunzioni iniziali (i prior), senza alcuna informazione empirica. Lo scopo non è “indovinare” i dati reali, ma verificare che i prior producano scenari plausibili alla luce della conoscenza di dominio (ordini di grandezza, range, code).\n\n52.3.1 Perché è utile?\n\nSe le simulazioni risultano implausibili (es. altezze negative o centinaia di cm fuori scala), i prior sono mal calibrati (troppo stretti, troppo larghi, con media irrealistica).\n\nSe le simulazioni sono compatibili con ciò che ci aspetteremmo in contesti reali, il modello non parte, è già “rotto” e possiamo procedere.\n\nL’idea pratica è semplice: campioniamo i parametri dal prior, poi generiamo dati fittizi con il meccanismo del modello, senza “guardare” i dati osservati.\n\n52.3.2 Stan (prior predictive minimale e robusta)\nUsiamo un file dedicato, ad es. normal_prior_predictive.stan. Qui non servono i blocchi parameters e model: in prior predictive campioniamo i parametri direttamente in generated quantities con le funzioni _rng, ed eseguiamo fixed_param=TRUE in R.\n// file: normal_prior_predictive.stan\ndata {\n  int&lt;lower=0&gt; N;          // dimensione della replica che vuoi generare\n  vector[N] y;             // ignorato (può essere numeric(0) o un vettore qualsiasi)\n  real mu0;                // media a priori di mu\n  real&lt;lower=0&gt; tau0;      // dev. standard a priori di mu\n  real&lt;lower=0&gt; sigma;     // dev. standard nota dei dati\n}\ngenerated quantities {\n  real mu_prior;           // un draw del parametro dal prior\n  vector[N] y_rep;         // una replica completa (lunghezza N)\n\n  mu_prior = normal_rng(mu0, tau0);\n  for (n in 1:N) {\n    y_rep[n] = normal_rng(mu_prior, sigma);\n  }\n}\n\nNota: se vuoi generare più repliche per draw, puoi aggiungere una dimensione N_rep e produrre una matrice y_rep[N, N_rep]. Per l’uso didattico, una replica per draw (ma tante iterazioni) è di solito sufficiente.\n\n\n52.3.3 Codice R (prior predictive)\nDati per la prior predictive** (qui scegliamo una replica di lunghezza N = 200):\n\nN &lt;- 200\nstan_data_prior &lt;- list(\n  N    = N,\n  y    = rep(0, N),  # ignorato\n  mu0  = 175,\n  tau0 = 5,\n  sigma= 10\n)\n\nCompilazione e campionamento (solo generated quantities):\n\nmod_prior &lt;- cmdstan_model(here::here(\"stan\", \"normal_prior_predictive.stan\"))\n\nfit_prior &lt;- mod_prior$sample(\n  data = stan_data_prior,\n  chains = 4,\n  iter_sampling = 1000,\n  iter_warmup = 0,\n  fixed_param = TRUE,   # fondamentale per prior predictive\n  refresh = 0,\n  seed = 123\n)\n#&gt; Running MCMC with 4 chains, at most 10 in parallel...\n#&gt; \n#&gt; Chain 1 finished in 0.1 seconds.\n#&gt; Chain 2 finished in 0.1 seconds.\n#&gt; Chain 3 finished in 0.1 seconds.\n#&gt; Chain 4 finished in 0.1 seconds.\n#&gt; \n#&gt; All 4 chains finished successfully.\n#&gt; Mean chain execution time: 0.1 seconds.\n#&gt; Total execution time: 0.2 seconds.\n\nEstrazione e check analitico (normale–normale):\n\n# y_rep: matrice (S x N) con S = numero totale di draws (tutte le chain combinate)\nyrep_mat &lt;- as_draws_matrix(fit_prior$draws(\"y_rep\"))\ndf_mc &lt;- data.frame(x = as.numeric(yrep_mat))  # vettore lungo S*N\n\n# Deviazione standard predittiva a priori (analitica): sqrt(tau0^2 + sigma^2)\nsd_prior_pred &lt;- sqrt(5^2 + 10^2)   # = sqrt(125) ≈ 11.18034\n\n# Code analitiche (confronto con Monte Carlo)\np_bassa &lt;- pnorm(150, mean = 175, sd = sd_prior_pred)\np_alta  &lt;- 1 - pnorm(200, mean = 175, sd = sd_prior_pred)\nc(p_bassa = p_bassa, p_alta = p_alta)\n#&gt; p_bassa  p_alta \n#&gt;  0.0127  0.0127\n\nPrior Predictive: Monte Carlo vs. analitica..\n\nggplot(df_mc, aes(x = x)) +\n  geom_density() +\n  stat_function(fun = dnorm,\n                args = list(mean = 175, sd = sd_prior_pred),\n                linetype = 2) +\n  labs(x = \"y\", y = \"Densità\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCosa stai verificando, in pratica?\n\n\n\n\n\nScala e posizione: la media simulata è coerente con \\(\\mu_0\\)?\n\nVariabilità: la dispersione simulata è coerente con \\(\\sqrt{\\tau_0^2 + \\sigma^2}\\)?\n\nCode e range: la massa di probabilità in regioni “assurde” (es. &lt;150 cm o &gt;200 cm) è ragionevole?\n\n\n\n\n52.3.4 Come interpretare\n\nSe le repliche a priori risultano sistematicamente più grandi/piccole di ciò che riterresti plausibile, il prior su \\(\\mu\\) è mal calibrato (es. \\(\\mu_0\\) troppo alto, \\(\\tau_0\\) troppo stretto/larghissimo).\nSe la variabilità è troppo diversa da quella che consideri realistica, rivedi \\(\\tau_0\\) (e, in modelli con \\(\\sigma\\) ignota, il prior su \\(\\sigma\\)).\nL’obiettivo non è “forzare i dati nel prior”, ma evitare prior implausibili rispetto alla conoscenza di dominio e all’ordine di grandezza atteso.\n\n\n\n\n\n\n\nRegola pratica\n\n\n\nSe la prior predictive non passa il test del buon senso (scala, range, code), rivedi i prior prima di stimare il modello.\n\n\n\n\n\n\n\n\nErrori comuni\n\n\n\n\n\nUsare parameters in prior predictive con fixed_param=TRUE: i parametri non vengono campionati ⇒ valori costanti. In prior predictive campiona i parametri in generated quantities con le funzioni _rng.\n\nDipendere da N quando è 0: se definisci vector[N] y_rep e passi N=0, l’oggetto è vuoto: va bene, ma ricorda che alcune pipeline di estrazione richiedono attenzione. In alternativa usa sempre N&gt;0 per le repliche a priori.\n\nConfondere prior vs posterior predictive: la prior predictive controlla le assunzioni; la posterior predictive controlla la capacità del modello, dopo aver “visto” i dati, di riprodurre le caratteristiche osservate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Controlli predittivi bayesiani (a priori e a posteriori) con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#riflessioni-conclusive",
    "href": "chapters/mcmc/06_mcmc_prediction.html#riflessioni-conclusive",
    "title": "52  Controlli predittivi bayesiani (a priori e a posteriori) con cmdstanr",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLe due distribuzioni predittive rispondono a domande complementari ma distinte. La distribuzione predittiva a priori ci permette di valutare la plausibilità delle nostre assunzioni iniziali: dati i prior scelti, il modello è in grado di generare dati che abbiano un senso nel contesto del problema? Si tratta di un controllo fondamentale per assicurarci che le nostre ipotesi partano da basi ragionevoli.\nLa distribuzione predittiva a posteriori, invece, verifica la capacità del modello – dopo aver incorporato l’evidenza dei dati – di cogliere le caratteristiche salienti del fenomeno osservato. La domanda guida qui diventa: il modello riesce a riprodurre non solo la tendenza centrale, ma anche la variabilità e la struttura dei dati reali?\nDa un punto di vista operativo, entrambe le verifiche seguono la stessa logica: si simulano campioni di dati sulla base di parametri estratti dalle distribuzioni (che siano prior o posteriori), per poi confrontarli visivamente e quantitativamente con i dati osservati.\nQuesti strumenti non costituiscono una validazione definitiva del modello, ma offrono un mezzo agile e intuitivo per individuare incoerenze macroscopiche: prior eccessivamente vincolanti, modelli che sottostimano la variabilità, o strutture probabilistiche inadeguate. Rappresentano perciò una tappa obbligata nel workflow bayesiano, da svolgere prima di affrontare confronti predittivi più formali, come quelli basati sull’ELPD o sulla cross-validazione LOO.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        plyr_1.8.9           \n#&gt; [46] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [55] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [58] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [61] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [64] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [67] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [70] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [73] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [76] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [79] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [82] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Controlli predittivi bayesiani (a priori e a posteriori) con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#bibliografia",
    "href": "chapters/mcmc/06_mcmc_prediction.html#bibliografia",
    "title": "52  Controlli predittivi bayesiani (a priori e a posteriori) con cmdstanr",
    "section": "Bibliografia",
    "text": "Bibliografia",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Controlli predittivi bayesiani (a priori e a posteriori) con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#la-distribuzione-predittiva-a-posteriori",
    "href": "chapters/mcmc/06_mcmc_prediction.html#la-distribuzione-predittiva-a-posteriori",
    "title": "52  Controlli predittivi bayesiani (a priori e a posteriori) con cmdstanr",
    "section": "\n52.1 La distribuzione predittiva a posteriori",
    "text": "52.1 La distribuzione predittiva a posteriori\nRicordiamo la definizione:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta ,\n\\] che nei Posterior Predictive Checks (PPC) viene stimata simulando nuovi dati a partire dal posteriore dei parametri.\nPerfetto, ti propongo una versione rielaborata e più didattica del testo, pensata per studenti di psicologia non esperti di statistica. Ho mantenuto il codice, ma ho reso più narrativo il commento e più chiaro il legame tra teoria, Stan e R.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Controlli predittivi bayesiani (a priori e a posteriori) con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#esempio-il-modello-normalenormale",
    "href": "chapters/mcmc/06_mcmc_prediction.html#esempio-il-modello-normalenormale",
    "title": "52  Controlli predittivi bayesiani (a priori e a posteriori) con cmdstanr",
    "section": "\n52.2 Esempio: il modello normale–normale",
    "text": "52.2 Esempio: il modello normale–normale\nPer rendere concreti i concetti di predizione bayesiana, partiamo da un caso molto semplice ma istruttivo: il modello normale–normale.\nImmaginiamo di voler stimare l’altezza media di una popolazione. Scegliamo come modello:\n\nun prior sulla media \\(\\mu\\), distribuito normalmente con parametri \\(\\mu_0\\) (media a priori) e \\(\\tau_0^2\\) (varianza a priori);\n\ndei dati osservati \\(y_i\\), anch’essi distribuiti normalmente attorno a \\(\\mu\\), con varianza fissata \\(\\sigma^2\\).\n\nMatematicamente:\n\\[\n\\mu \\sim \\mathcal{N}(\\mu_0, \\tau_0^2), \\qquad\ny_i \\sim \\mathcal{N}(\\mu, \\sigma^2).\n\\]\nIn questo contesto, la distribuzione predittiva posteriore per una nuova osservazione \\(\\tilde{y}\\) si scrive:\n\\[\n\\tilde{y} \\mid Y \\sim \\mathcal{N}\\!\\big(\\mu_n, \\; \\tau_n^2 + \\sigma^2 \\big),\n\\] dove \\(\\mu_n\\) e \\(\\tau_n^2\\) sono la media e la varianza della distribuzione a posteriori di \\(\\mu\\).\nLa formula in sé non è la parte più importante: ciò che ci interessa è come realizzare la simulazione in pratica, così da poter confrontare i dati osservati con i dati replicati dal modello.\n\n52.2.1 Implementazione con Stan\nCreiamo un modello Stan (normal_pred.stan) che ci consente di generare:\n\n\nprior predictive (se prior_only = 1): simulazioni solo a partire dal prior, prima di vedere i dati;\n\n\nposterior predictive (se prior_only = 0): simulazioni aggiornate dopo aver visto i dati.\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] y;\n  real mu0;\n  real&lt;lower=0&gt; tau0;\n  real&lt;lower=0&gt; sigma;\n  int&lt;lower=0,upper=1&gt; prior_only;\n}\nparameters {\n  real mu;\n}\nmodel {\n  mu ~ normal(mu0, tau0);          // prior\n  if (prior_only == 0)\n    y ~ normal(mu, sigma);         // likelihood (solo se usiamo i dati)\n}\ngenerated quantities {\n  real y_rep;\n  y_rep = normal_rng(mu, sigma);   // generiamo una nuova osservazione\n}\n\n52.2.2 In R\nSimuliamo 100 altezze con media 170 cm e deviazione standard 10 cm, poi invochiamo Stan per stimare il modello:\n\nN &lt;- 100\ny &lt;- rnorm(N, mean = 170, sd = 10)\n\nstan_data &lt;- list(\n  N = N, y = y,\n  mu0 = 175, tau0 = 5, sigma = 10,\n  prior_only = 0\n)\n\nmod &lt;- cmdstan_model(here::here(\"stan\", \"normal_pred.stan\"))\nfit &lt;- mod$sample(data = stan_data, chains = 4, iter_sampling = 1000, refresh = 0)\n\n\n52.2.3 Visualizzazione: Posterior Predictive Checks\nPer i controlli predittivi, generiamo i dati replicati e li confrontiamo con i dati osservati:\n\ny_rep_vars &lt;- paste0(\"y_rep[\", 1:N, \"]\")\ny_rep &lt;- as_draws_matrix(fit$draws(y_rep_vars))\n\n# Confronto distribuzioni\nbayesplot::ppc_dens_overlay(y, y_rep[1:200, ])\n\n\n\n\n\n\n\nIl grafico mostra la distribuzione reale delle altezze (y) e quelle simulate dal modello (y_rep). Se le due curve si sovrappongono in modo plausibile, significa che il modello è in grado di riprodurre le caratteristiche essenziali dei dati.\nAltri strumenti utili per controlli più mirati:\n\nbayesplot::ppc_stat(y, y_rep, stat = \"mean\")        # confronto delle medie\n\n\n\n\n\n\n\n\nbayesplot::ppc_intervals(y, y_rep[1:100, ])        # confronto di intervalli\n\n\n\n\n\n\n\nQuesti controlli ci permettono di capire quanto bene il modello “mima” la realtà: se i dati simulati divergono fortemente da quelli osservati, vuol dire che le assunzioni di base (prior, varianza fissata, ecc.) non sono adatte e vanno riviste.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Controlli predittivi bayesiani (a priori e a posteriori) con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html",
    "href": "chapters/mcmc/05_stan_diagnostics.html",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "",
    "text": "Introduzione\nUna volta eseguita la stima di un modello in Stan, il primo passo non è interpretare subito i parametri, ma verificare se la procedura di campionamento ha funzionato correttamente. Le catene MCMC, infatti, possono produrre risultati fuorvianti se non hanno esplorato in modo adeguato lo spazio dei parametri.\nPer questo motivo, Stan fornisce diversi indicatori diagnostici che permettono di valutare la qualità del campionamento. Questi strumenti servono a rispondere a domande fondamentali:\nPrima di utilizzare i risultati di un modello, è quindi necessario controllare con attenzione queste diagnosi. Solo dopo aver verificato che il campionamento sia affidabile possiamo procedere con l’analisi e l’interpretazione dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#introduzione",
    "href": "chapters/mcmc/05_stan_diagnostics.html#introduzione",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "",
    "text": "Le catene hanno raggiunto la convergenza verso una stessa distribuzione?\nLa variabilità campionata rappresenta in modo fedele la distribuzione posteriore?\nCi sono segnali che i campioni non siano sufficienti o che alcune regioni della distribuzione non siano state esplorate?\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; source()\n\n# Carichiamo i pacchetti necessari\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, insight, bayesplot, ggplot2)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#grafici-di-tracciamento",
    "href": "chapters/mcmc/05_stan_diagnostics.html#grafici-di-tracciamento",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "\n52.1 Grafici di tracciamento",
    "text": "52.1 Grafici di tracciamento\nUn modo semplice e visivo per capire se un algoritmo MCMC (un metodo per stimare modelli bayesiani) sta funzionando bene è osservare i grafici di tracciamento, o trace plots. Immaginate che ogni parametro del modello (ad esempio, l’effetto di un farmaco o la correlazione tra due variabili) abbia una sua “storia”, raccontata attraverso migliaia di passaggi (iterazioni) dell’algoritmo. Il trace plot non è altro che il grafico di questa storia: sull’asse orizzontale ci sono le iterazioni, su quello verticale i valori che il parametro assume di volta in volta.\nQuando tutto funziona correttamente, il grafico assomiglia a una “ciaspata” rumorosa e compatta attorno a un valore medio stabile – un po’ come guardare la neve sullo schermo di una TV non sintonizzata, ma confinata in una fascia orizzontale. Questo significa che la catena si sta mescolando bene: l’algoritmo sta esplorando in modo efficace la distribuzione dei valori plausibili per quel parametro.\nAl contrario, un trace plot che mostra andamenti strani ci avvisa che qualcosa non va. Per esempio:\n\nse due catene diverse (partite da punti diversi) per lo stesso parametro non si incontrano mai e restano separate, significa che non stanno convergendo verso la stessa conclusione;\nse si osservano salti ampi o andamenti a gradini, l’algoritmo potrebbe non stare campionando in modo efficiente.\n\nL’obiettivo è quindi riconoscere un andamento “sano”: un rumore casuale e stabile, senza pattern sistematici o derive nel tempo. Questo ci dà fiducia che le stime ottenute siano affidabili.\nCome suggerito da Martin et al. (2022), è utile confrontare trace plot di catene che convergono bene con altri che mostrano problemi. Questi ultimi segnalano che è necessario rivedere il modello o le impostazioni dell’algoritmo, prima di trarre conclusioni.\nOsservando i grafici qui sotto, noterete:\n\na sinistra, l’andamento della catena (trace plot),\na destra, la densità stimata dei valori campionati.\n\nUn trace plot ideale mostra un andamento oscillante ma stabile, e la densità si avvicina alla classica forma a campana.\n\n#&gt; $good_chains\n#&gt; [1]    2 2000\n#&gt; \n#&gt; $bad_chains0\n#&gt; [1]    2 2000\n#&gt; \n#&gt; $bad_chains1\n#&gt; [1]    2 2000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n52.1.1 Cosa fare se le catene non convergono?\nNella pratica, non sappiamo come sia fatta la “vera” distribuzione a posteriori. Per questo i trace plot sono così utili: ci avvisano quando qualcosa non funziona. Se ottenete grafici simili agli esempi “cattivi”, potete provare a:\n\n\nRivedere il modello. Le assunzioni fatte (siano esse le prior o la struttura del modello) sono appropriate per i vostri dati?\n\nAumentare il numero di iterazioni. A volte, far girare l’algoritmo più a lungo aiuta a smussare comportamenti anomali a breve termine.\n\nQuello dei trace plot è uno strumento diagnostico semplice ma potente, fondamentale per chiunque voglia utilizzare modelli bayesiani in modo consapevole.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#i-grafici-della-densità-posteriore-sono-adeguati",
    "href": "chapters/mcmc/05_stan_diagnostics.html#i-grafici-della-densità-posteriore-sono-adeguati",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "\n52.2 I grafici della densità posteriore sono adeguati?",
    "text": "52.2 I grafici della densità posteriore sono adeguati?\nI grafici della densità posteriore sono tra gli strumenti più immediati e informativi per valutare la qualità dei risultati di un’analisi bayesiana. Questi grafici mostrano la forma della distribuzione dei valori campionati per un parametro, offrendo una rappresentazione visiva diretta della nostra incertezza dopo aver osservato i dati.\nIn condizioni ideali, la densità posteriore di un parametro dovrebbe presentare una forma regolare e coerente con le aspettative teoriche. Ad esempio, se abbiamo utilizzato una distribuzione a priori normale, ci aspettiamo spesso (ma non sempre) una forma approssimativamente simmetrica e unimodale. Una curva liscia e ben definita suggerisce che le catene di Markov hanno esplorato in modo efficace lo spazio del parametro e che i campioni ottenuti sono rappresentativi della distribuzione sottostante.\nTuttavia, quando la densità appare irregolare – mostrando asimmetrie estreme, picchi multipli (bimodalità), o code eccessivamente lunghe – è un segnale che qualcosa potrebbe non aver funzionato come previsto. Una forma bimodale, in particolare, può indicare che l’algoritmo si è “bloccato” in regioni distinte dello spazio dei parametri, senza riuscire a integrarle in un’unica distribuzione coerente. In altri casi, una forma troppo piatta o irregolare può denotare una mancata convergenza o un’esplorazione incompleta.\nCosa fare se la densità posteriore non sembra adeguata?\n\n\nAumentare il numero di iterazioni: Un campionamento più prolungato può aiutare a stabilizzare la stima e a fondare eventuali modalità separate.\n\nRivedere le distribuzioni a priori: Una prior troppo vaga o inappropriata può portare a posteriori instabili o difficili da campionare.\n\nOttimizzare l’algoritmo MCMC: A volte è necessario modificare i parametri di campionamento, come il passo di proposta o il numero di catene, per migliorare l’efficienza esplorativa.\n\nIn sintesi, l’ispezione visiva della densità posteriore non è solo un passaggio tecnico, ma un momento critico di riflessione metodologica. Ci permette di valutare se le nostre stime sono robuste e credibili, e se il modello è riuscito a cogliere la struttura dei dati in modo equilibrato e affidabile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#lautocorrelazione-nelle-catene-mcmc-come-interpretarla-e-gestirla",
    "href": "chapters/mcmc/05_stan_diagnostics.html#lautocorrelazione-nelle-catene-mcmc-come-interpretarla-e-gestirla",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "\n52.3 L’autocorrelazione nelle catene MCMC: come interpretarla e gestirla",
    "text": "52.3 L’autocorrelazione nelle catene MCMC: come interpretarla e gestirla\nQuando utilizziamo il metodo Monte Carlo basato su catene di Markov (MCMC) per stimare modelli bayesiani, dobbiamo tenere presente un aspetto cruciale: i campioni successivi prodotti dall’algoritmo non sono completamente indipendenti tra loro. Questo fenomeno, noto come autocorrelazione, è naturale nelle catene di Markov, ma quando diventa troppo pronunciato può indicare problemi nell’efficienza del campionamento.\nL’autocorrelazione misura quanto un campione nella catena sia simile ai campioni precedenti. Idealmente, vorremmo che questa somiglianza diminuisca rapidamente all’aumentare della distanza tra i campioni. Per visualizzare questo comportamento, utilizziamo i correlogrammi – grafici che mostrano l’autocorrelazione a diverse “distanze” (lag) tra i campioni.\nUn correlogramma ideale mostra:\n\nun’autocorrelazione iniziale (lag 1) non troppo elevata,\nun rapido decadimento verso lo zero all’aumentare del lag\n\nQuando osserviamo questo pattern, possiamo essere confidenti che la catena si sta “mescolando” bene e sta esplorando efficientemente lo spazio dei parametri. Al contrario, un’autocorrelazione che persiste per molti lag suggerisce che la catena si muove lentamente attraverso lo spazio dei parametri, producendo campioni altamente correlati. Questo riduce l’efficienza del campionamento, poiché otteniamo meno informazioni indipendenti da ogni iterazione.\nCosa fare quando l’autocorrelazione è troppo alta?\n\nAumentare il numero di iterazioni: Una catena più lunga può compensare l’alta autocorrelazione, purché sia sufficientemente prolungata da esplorare adeguatamente tutto lo spazio dei parametri.\nApplicare il thinning (diradamento): Possiamo conservare solo un campione ogni k iterazioni (ad esempio, ogni 5 o 10), riducendo così la correlazione tra i campioni conservati. Tuttavia, questo approccio va usato con giudizio, poiché spreca informazioni.\nRivedere le impostazioni dell’algoritmo: A volte, modificare il passo di proposta o altri parametri del campionatore può migliorare l’efficienza esplorativa.\n\nL’analisi dell’autocorrelazione non è solo un tecnicismo, ma uno strumento fondamentale per valutare la qualità delle nostre stime bayesiane. Ci aiuta a garantire che i risultati su cui basiamo le nostre conclusioni siano robusti e affidabili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#la-dimensione-effettiva-del-campione-un-indicatore-cruciale-per-laffidabilità-delle-stime",
    "href": "chapters/mcmc/05_stan_diagnostics.html#la-dimensione-effettiva-del-campione-un-indicatore-cruciale-per-laffidabilità-delle-stime",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "\n52.4 La dimensione effettiva del campione: un indicatore cruciale per l’affidabilità delle stime",
    "text": "52.4 La dimensione effettiva del campione: un indicatore cruciale per l’affidabilità delle stime\nQuando lavoriamo con metodi MCMC, un concetto fondamentale da comprendere è quello di dimensione effettiva del campione (indicata come \\(N_{\\text{eff}}\\)). A differenza del numero totale di campioni generati, \\(N_{\\text{eff}}\\) rappresenta il numero equivalente di campioni statisticamente indipendenti che avrebbero la stessa precisione delle nostre stime.\nPoiché i campioni MCMC sono tipicamente correlati tra loro, la dimensione effettiva è sempre inferiore al numero totale di iterazioni. La formula per calcolarla tiene conto di queste correlazioni:\n\\[\nN_{\\text{eff}} = \\frac{T}{1 + 2 \\sum_{s=1}^{S} \\rho_{s}}\n\\] dove \\(T\\) è il numero totale di campioni e \\(\\rho_{s}\\) rappresenta l’autocorrelazione a diverse distanze (lag).\nInterpretazione pratica:\n\nUn valore di \\(N_{\\text{eff}}\\) prossimo a \\(T\\) indica che i campioni sono quasi indipendenti\nUn valore di \\(N_{\\text{eff}}\\) molto inferiore a \\(T\\) segnala una forte autocorrelazione tra i campioni\n\nCosa fare se \\(N_{\\text{eff}}\\) è troppo basso?\n\n\nAumentare il numero di iterazioni: La soluzione più diretta per ottenere più campioni indipendenti\n\nUtilizzare il thinning (diradamento): Conservare solo un campione ogni \\(k\\) iterazioni può ridurre l’autocorrelazione, anche se a costo di scartare informazioni\n\nOttimizzare l’algoritmo: A volte, modificare i parametri del campionatore o il modello stesso può migliorare l’efficienza\n\nLa dimensione effettiva del campione non è solo un tecnicismo statistico, ma un indicatore fondamentale della qualità delle nostre stime. Valori sufficientemente alti di \\(N_{\\text{eff}}\\) ci danno maggiore fiducia nell’affidabilità delle conclusioni tratte dai nostri modelli bayesiani.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#la-statistica-hatr-il-termometro-della-convergenza-delle-catene",
    "href": "chapters/mcmc/05_stan_diagnostics.html#la-statistica-hatr-il-termometro-della-convergenza-delle-catene",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "\n52.5 La statistica \\(\\hat{R}\\): il termometro della convergenza delle catene",
    "text": "52.5 La statistica \\(\\hat{R}\\): il termometro della convergenza delle catene\nLa statistica \\(\\hat{R}\\), formalmente nota come potenziale scale reduction factor, costituisce uno degli indicatori più solidi e ampiamente adottati per la valutazione della convergenza nelle analisi MCMC. Il suo principale scopo è determinare se multiple catene, inizializzate da differenti valori di partenza, hanno effettivamente raggiunto la stessa distribuzione target, garantendo così la robustezza delle inferenze statistiche prodotte.\nIl principio di calcolo di \\(\\hat{R}\\) si fonda su un confronto tra la variabilità osservata all’interno di ciascuna catena e la variabilità presente tra le diverse catene. La formula, che sintetizza questo confronto, è la seguente:\n\\[\n\\hat{R} = \\sqrt{\\frac{W + \\frac{1}{n}(B - W)}{W}}\n\\] dove \\(W\\) rappresenta la varianza media all’interno delle catene (within-chain variance) e \\(B\\) rappresenta la varianza tra le catene (between-chain variance).\nL’interpretazione dei valori di \\(\\hat{R}\\) segue linee guida ben consolidate. Un valore pari esattamente a 1 indica una convergenza perfetta, situazione ideale in cui le catene sono completamente sovrapposte e stabili. Valori fino a 1.01 sono considerati eccellenti, mentre valori fino a 1.05 sono generalmente accettabili nella maggior parte delle applicazioni pratiche. Oltre la soglia di 1.1, il risultato deve essere considerato con cautela, in quanto suggerisce che le catene potrebbero non aver raggiunto la convergenza e che le stime potrebbero essere inaffidabili.\nL’importanza di \\(\\hat{R}\\) risiede nella sua capacità di segnalare discrepanze sistematiche tra le catene. Valori elevati indicano che le diverse esecuzioni stanno campionando da distribuzioni differenti, il che può derivare da una mancata stabilizzazione delle catene, da problemi di identificabilità del modello, o dalla necessità di un numero maggiore di iterazioni.\nNella pratica contemporanea, i software Bayesiani più diffusi calcolano automaticamente \\(\\hat{R}\\) per tutti i parametri del modello, facilitando un monitoraggio efficiente della qualità del campionamento. Come evidenziato in letteratura, ad esempio nei lavori di Martin (2022), catene ben comportate presentano valori di \\(\\hat{R}\\) estremamente vicini all’unità, mentre situazioni problematiche emergono chiaramente attraverso valori anomali.\nPertanto, \\(\\hat{R}\\) si conferma come una metrica indispensabile nell’arsenale del analista bayesiano, fornendo una valutazione oggettiva e quantitativa dell’affidabilità delle simulazioni MCMC e della credibilità delle conclusioni ad esse associate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#la-diagnostica-di-geweke",
    "href": "chapters/mcmc/05_stan_diagnostics.html#la-diagnostica-di-geweke",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "\n52.6 La diagnostica di Geweke",
    "text": "52.6 La diagnostica di Geweke\nLa diagnostica di Geweke fornisce un approccio elegante e intuitivo per verificare il raggiungimento della stazionarietà in una catena di Markov. Il principio fondamentale su cui si basa è il confronto tra le proprietà statistiche della porzione iniziale e di quella finale della catena. Nella pratica, si confronta la media calcolata sui primi campioni (generalmente il primo 10% della catena) con quella ottenuta dagli ultimi campioni (tipicamente l’ultimo 50%).\nL’interpretazione dei risultati segue una logica relativamente semplice: valori prossimi allo zero indicano che non sussistono differenze significative tra le due porzioni della catena, suggerendo così il raggiungimento di una condizione di stazionarietà. Al contrario, valori assoluti superiori a 2 segnalano una discrepanza statisticamente rilevante tra le due fasi del campionamento, mettendo in dubbio il presupposto della stazionarietà.\nQuesto test può essere efficacemente concepito come un “termometro” della stabilità temporale della catena, offrendo una prima indicazione sulla qualità del campionamento ottenuto.\nQualora la diagnostica di Geweke riveli valori considerati problematici, diventa opportuno considerare alcune strategie correttive. Un aumento del numero di iterazioni può consentire alla catena di raggiungere la stazionarietà. Una verifica delle impostazioni dell’algoritmo di campionamento potrebbe identificare parametri non ottimali. Infine, è sempre consigliabile valutare la possibile presenza di problemi intrinseci nella specificazione del modello stesso, che potrebbero ostacolare il corretto funzionamento del processo di campionamento.\n\n52.6.1 L’errore standard di Monte Carlo: quantificare l’incertezza dell’approssimazione\nNel contesto dei metodi Monte Carlo basati su catene di Markov (MCMC), è fondamentale riconoscere che i risultati prodotti costituiscono un’approssimazione della vera distribuzione a posteriori. Come in ogni processo approssimativo, è essenziale quantificare il margine di errore intrinseco a questa stima. A questo proposito, l’Errore Standard di Monte Carlo (MCSE) emerge come uno strumento metrico fondamentale per valutare la precisione della nostra approssimazione.\nIl calcolo del MCSE si basa su una relazione matematica elegante e intuitiva:\n\\[\n\\text{MCSE} = \\frac{\\text{SD}}{\\sqrt{N_{\\text{eff}}}},\n\\] dove \\(N_{\\text{eff}}\\) dove rappresenta la dimensione effettiva del campione, ovvero il numero equivalente di campioni indipendenti che fornirebbero la stessa quantità di informazione dei nostri campioni autocorrelati.\nL’interpretazione del MCSE richiede una valutazione contestuale. Un valore di MCSE considerevolmente inferiore alla scala tipica del parametro in esame indica una stima precisa e affidabile. Al contrario, valori elevati di MCSE segnalano che la nostra approssimazione potrebbe essere eccessivamente “rumorosa” e quindi potenzialmente inaffidabile. Una regola pratica suggerisce di auspicare un MCSE almeno un ordine di grandezza inferiore alla deviazione standard della stima stessa.\nQuando ci confrontiamo con valori di MCSE troppo elevati, diverse strategie corrective si rendono disponibili. L’aumento del numero di campioni rappresenta l’approccio più diretto, sebbene non sempre il più efficiente. Alternative più raffinate includono il miglioramento dell’efficienza del campionamento attraverso la regolazione dei parametri dell’algoritmo o l’ottimizzazione del modello per ridurre l’autocorrelazione tra i campioni.\nIl MCSE, considerato congiuntamente ad altre diagnostiche come il test di Geweke, contribuisce a fornire un quadro analitico completo della qualità delle nostre catene MCMC. Questa combinazione di strumenti ci permette di discernere tra risultati robusti e pronti per l’interpretazione sostantiva e quelli che, invece, richiedono ulteriori raffinamenti metodologici prima di poter essere considerati affidabili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#transizioni-divergenti-segnali-dallarme-nellalgoritmo-hmc",
    "href": "chapters/mcmc/05_stan_diagnostics.html#transizioni-divergenti-segnali-dallarme-nellalgoritmo-hmc",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "\n52.7 Transizioni divergenti: segnali d’allarme nell’algoritmo HMC",
    "text": "52.7 Transizioni divergenti: segnali d’allarme nell’algoritmo HMC\nNel contesto dell’Hamiltonian Monte Carlo (HMC), la comparsa di transizioni divergenti costituisce un segnale diagnostico di fondamentale importanza, il cui significato non dovrebbe essere sottovalutato. Queste transizioni si manifestano quando l’algoritmo incontra difficoltà nel navigare regioni particolarmente complesse dello spazio parametrico, caratterizzate da elevate curvature o geometrie irregolari. In tali circostanze, invece di procedere con un’esplorazione fluida e completa, il campionatore tende a “rimbalzare” in modo inefficace, fallendo nel rappresentare adeguatamente queste zone della distribuzione target.\nLe implicazioni di queste transizioni divergenti sono profonde e potenzialmente compromettenti per l’intera analisi. La loro presenza indica che porzioni significative dello spazio dei parametri potrebbero essere state inesplorate, minando così la completezza del campionamento e, di conseguenza, l’affidabilità di qualsiasi inferenza successiva. È come possedere una mappa incompleta di un territorio: le conclusioni tratte rischiano di essere parziali o fuorvianti.\nFortunatamente, quando ci confrontiamo con questo tipo di problematiche, diverse strategie correttive si rivelano disponibili. Un esame attento dei dati può identificare eventuali valori anomali che contribuiscono a creare queste regioni problematiche. Parallelamente, una revisione critica delle distribuzioni a priori può evidenziare specifiche troppo restrittive o mal calibrate che ostacolano il libero movimento dell’algoritmo. La regolazione fine dei parametri operativi dell’HMC, come la dimensione del passo di integrazione o il numero di passi, offre un altro canale di intervento per migliorare l’efficienza esplorativa. In ultima istanza, una riparametrizzazione del modello potrebbe rivelarsi necessaria per semplificare la geometria dello spazio da esplorare.\nLa gestione oculata delle transizioni divergenti rappresenta dunque una tappa indispensabile nel percorso verso stime bayesiane robuste e credibili. La loro assenza non è semplicemente un indicatore tecnico tra molti, ma il presupposto necessario per avere fiducia nel fatto che il nostro campionamento abbia catturato in modo esaustivo la ricchezza e la complessità della distribuzione a posteriori di interesse.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#la-bayesian-fraction-of-missing-information-bfmi-un-indicatore-di-efficienza-esplorativa",
    "href": "chapters/mcmc/05_stan_diagnostics.html#la-bayesian-fraction-of-missing-information-bfmi-un-indicatore-di-efficienza-esplorativa",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "\n52.8 La Bayesian Fraction of Missing Information (BFMI): un indicatore di efficienza esplorativa",
    "text": "52.8 La Bayesian Fraction of Missing Information (BFMI): un indicatore di efficienza esplorativa\nNell’ambito dei metodi di campionamento avanzati come l’Hamiltonian Monte Carlo (HMC) e il No-U-Turn Sampler (NUTS), la Bayesian Fraction of Missing Information (BFMI) emerge come uno strumento diagnostico di notevole sofisticazione. Questo indicatore ci consente di valutare l’efficacia con cui l’algoritmo sta esplorando la distribuzione a posteriori, offrendo insights che vanno ben oltre le tradizionali misure di convergenza.\nLa BFMI opera analizzando le fluttuazioni energetiche durante il processo di campionamento. Concettualmente, possiamo paragonare l’energia al “carburante” che alimenta l’esplorazione dello spazio dei parametri da parte dell’algoritmo. Un’esplorazione efficiente richiede il mantenimento di un equilibrio energetico ottimale throughout il percorso esplorativo.\nL’interpretazione dei valori di BFMI segue una scala di affidabilità ben definita. Valori superiori o uguali a 0.3 indicano una situazione ideale, in cui l’algoritmo sta esplorando in modo efficace tutte le regioni significative della distribuzione. Quando la BFMI si colloca tra 0.2 e 0.3, è opportuno prestare attenzione, poiché l’esplorazione potrebbe essere solo parziale e merita un esame più approfondito. Valori inferiori a 0.2 costituiscono un vero e proprio campanello d’allarme, segnalando che l’algoritmo sta incontrando serie difficoltà nell’esplorazione e che i risultati potrebbero essere compromessi in termini di affidabilità.\nL’importanza della BFMI risiede nella sua capacità di rivelare quando l’algoritmo sta “faticando” nel muovers attraverso lo spazio dei parametri. Questo tipicamente accade in presenza di distribuzioni a posteriori con geometrie complesse, forti correlazioni tra parametri, scale parametriche eterogenee o regioni caratterizzate da curvature particolarmente accentuate.\nDi fronte a valori di BFMI troppo bassi, diverse strategie correttive possono essere implementate. Una riparametrizzazione del modello, eventualmente attraverso l’utilizzo di trasformazioni appropriate, può semplificare significativamente l’esplorazione. La regolazione della “massa” dei parametri nell’ambito dell’HMC può migliorare l’efficienza del movimento. Inoltre, una verifica delle distribuzioni a priori è essenziale, poiché prior eccessivamente restrittive possono introdurre barriere artificiali all’esplorazione.\nLa BFMI rappresenta dunque molto più di un mero indicatore tecnico; essa costituisce una finestra privilegiata sul comportamento interno del nostro algoritmo di campionamento. Una vigilanza attenta su questo parametro ci permette di garantire che le nostre inferenze bayesiane siano fondate su un’esplorazione completa e affidabile dello spazio dei parametri, condizione essenziale per la validità dei nostri risultati analitici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#la-leave-one-out-cross-validation-uno-sguardo-allaffidabilità-predittiva-del-modello",
    "href": "chapters/mcmc/05_stan_diagnostics.html#la-leave-one-out-cross-validation-uno-sguardo-allaffidabilità-predittiva-del-modello",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "\n52.9 La Leave-One-Out Cross-Validation: uno sguardo all’affidabilità predittiva del modello",
    "text": "52.9 La Leave-One-Out Cross-Validation: uno sguardo all’affidabilità predittiva del modello\nLa Leave-One-Out Cross-Validation (LOO) emerge come una delle metodologie più raffinate per valutare la capacità predittiva dei modelli bayesiani. Questo approccio ci consente di rispondere a una domanda fondamentale: quanto possiamo fidarci delle previsioni del nostro modello quando incontra nuove osservazioni?\nIl principio alla base della LOO è tanto elegante quanto efficace. Immaginiamo di voler testare la robustezza del nostro modello attraverso un esperimento concettuale: ripetutamente, escludiamo una singola osservazione dal nostro dataset, addestriamo il modello sulle restanti, e verifichiamo quanto bene riesce a predire proprio l’osservazione che aveva messo da parte. Questo processo viene iterato per ogni punto dati, offrendo così una valutazione completa delle performance predittive.\nIl vero valore della LOO risiede nella sua capacità di prevenire due rischi opposti ma ugualmente pericolosi. Da un lato, ci protegge dall’overfitting, quel fenomeno per cui un modello si adatta così perfettamente ai dati di training da perdere la capacità di generalizzare a nuove situazioni. Dall’altro, evita l’underfitting, dove un modello troppo semplice fallisce nel catturare le pattern sottostanti nei dati.\nNella pratica bayesiana, la LOO si traduce in metriche quantitative come l’LOOIC (Leave-One-Out Information Criterion), che sintetizza in un unico valore la bontà predittiva del modello. Un LOOIC più basso indica generalmente un migliore equilibrio tra adattamento ai dati e capacità di generalizzazione.\nTuttavia, l’interpretazione dei risultati LOO richiede una certa cautela. Differenze sostanziali nel LOOIC tra modelli alternativi possono guidarci verso scelte più informate, ma è essenziale considerare anche il contesto applicativo e la plausibilità teorica dei modelli in esame.\nIn ultima analisi, la LOO non rappresenta un test definitivo, ma piuttosto un potente strumento diagnostico che ci aiuta a costruire modelli non solo statisticamente eleganti, ma anche praticamente utili per fare previsioni affidabili nel mondo reale. La sua applicazione sistematica costituisce quindi una tappa cruciale nel percorso verso modelli bayesiani robusti e credibili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#il-parametro-κ-un-indicatore-cruciale-per-laffidabilità-delle-stime",
    "href": "chapters/mcmc/05_stan_diagnostics.html#il-parametro-κ-un-indicatore-cruciale-per-laffidabilità-delle-stime",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "\n52.10 Il parametro κ: un indicatore cruciale per l’affidabilità delle stime",
    "text": "52.10 Il parametro κ: un indicatore cruciale per l’affidabilità delle stime\nIl parametro κ (kappa) rappresenta un indicatore fondamentale nel contesto del campionamento bayesiano, particolarmente quando si utilizza il Pareto Smoothed Importance Sampling (PSIS). Questo parametro funge da vero e proprio “termometro” della qualità delle nostre stime, rivelando quanto possiamo fidarci dei risultati ottenuti.\nImmaginiamo di dover stimare le preferenze alimentari di una grande popolazione. Se interrogassimo solo poche persone con gusti particolarmente estremi, le nostre conclusioni risulterebbero distorte. Allo stesso modo, nel campionamento statistico, alcuni valori estremi possono influenzare eccessivamente le nostre stime, compromettendone l’affidabilità.\nIl parametro κ misura proprio questo rischio. Quando κ assume valori bassi (inferiori a 0.5), indica che il processo di campionamento ha catturato adeguatamente la variabilità dei dati senza essere eccessivamente influenzato da valori anomali. Valori compresi tra 0.5 e 0.7 segnalano una situazione di attenzione: le stime potrebbero essere accettabili, ma meritano un esame più approfondito.\nIl vero campanello d’allarme suona quando κ supera 0.7. In questo caso, è probabile che pochi valori estremi stiano dominando il processo di stima, rendendo i risultati potenzialmente inaffidabili. Questa situazione richiede un intervento immediato, che può consistere nel raccogliere più dati, nel ripensare la strategia di campionamento, o nel verificare la presenza di outlier nel dataset.\nL’interpretazione di κ diventa particolarmente importante quando utilizziamo tecniche avanzate come la validazione incrociata leave-one-out (LOO-CV), dove un κ elevato può indicare che le stime di capacità predittiva del modello sono compromesse da un numero eccessivo di osservazioni influenti.\nIn pratica, il monitoraggio sistematico del parametro κ costituisce una buona pratica analitica, permettendoci di distinguere tra risultati solidi e conclusioni che potrebbero essere fuorvianti. Come un buon meccanico che controlla gli indicatori della propria automobile, l’analista bayesiano dovrebbe sempre verificare il valore di κ prima di trarre conclusioni definitive dai propri modelli.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#bibliografia",
    "href": "chapters/mcmc/05_stan_diagnostics.html#bibliografia",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMartin, O. A., Kumar, R., & Lao, J. (2022). Bayesian Modeling and Computation in Python. CRC Press.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#riflessioni-conclusive",
    "href": "chapters/mcmc/05_stan_diagnostics.html#riflessioni-conclusive",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo esplorato gli strumenti fondamentali per valutare la qualità dei risultati ottenuti con i metodi MCMC. Per rendere concreti questi concetti, ecco una guida pratica che puoi seguire passo dopo passo.\n\n52.10.1 Protocollo di verifica passo-passo\nInizia sempre controllando i messaggi di Stan: assicurati che non ci siano transizioni divergenti e che l’adattamento sia completato correttamente. Prosegui osservando i grafici delle tracce (trace plot): le diverse catene dovrebbero sovrapporsi e mostrare un andamento stabile, senza derive o pattern strani.\nVerifica poi l’autocorrelazione tra i campioni: dovrebbe diminuire rapidamente all’aumentare della distanza tra i campioni. Questo ci porta a considerare la dimensione effettiva del campione (\\(N_{\\text{eff}}\\)), che dovrebbe essere sufficientemente grande per garantire stime affidabili.\nControlla quindi la statistica \\(\\hat{R}\\): valori vicini a 1 indicano che le catene hanno convergono verso la stessa distribuzione. Valuta anche l’errore standard di Monte Carlo (MCSE), che dovrebbe essere piccolo rispetto alla scala dei parametri.\nPer i modelli che usano HMC/NUTS, assicurati che non ci siano transizioni divergenti e che la BFMI sia sufficientemente alta. Infine, se stai confrontando modelli diversi, utilizza gli strumenti predittivi come LOO/PSIS, prestando attenzione al parametro \\(\\kappa\\).\n\n52.10.2 Cosa fare se incontri problemi\nSe noti valori di \\(\\hat{R}\\) troppo alti o catene che non si sovrappongono, prova ad aumentare il numero di iterazioni o a rivedere le inizializzazioni. In caso di transizioni divergenti, regola i parametri del campionatore o considera una riparametrizzazione del modello.\nSe l’autocorrelazione persiste o la dimensione effettiva del campione è bassa, potresti bisogno di più iterazioni o di ottimizzare la parametrizzazione del modello. Per problemi con la BFMI o valori alti di \\(\\kappa\\), valuta la standardizzazione delle variabili o l’uso di distribuzioni più robuste.\n\n52.10.3 Consigli pratici per il report dei risultati\nQuando presenti i tuoi risultati, includi sempre informazioni sulle impostazioni usate: numero di catene, iterazioni, e parametri del campionatore. Riporta i valori diagnostici chiave (\\(\\hat{R}\\), \\(N_{\\text{eff}}\\), MCSE) e menziona eventuali problemi incontrati e come li hai risolti. Non dimenticare di condividere il codice e i dati necessari per garantire la riproducibilità dei tuoi risultati.\n\n52.10.4 Quando fermarsi\nIl processo di tuning può considerarsi concluso quando: non ci sono più transizioni divergenti, i trace plot mostrano catene stabili e sovrapposte, \\(\\hat{R}\\) è vicino a 1 per tutti i parametri importanti, l’MCSE è sufficientemente piccolo, e gli indicatori predittivi non mostrano problemi critici.\nRicorda: prendersi il tempo per una diagnostica accurata non è una perdita di tempo, ma un investimento necessario per garantire la solidità delle tue conclusioni scientifiche. Meglio un modello semplice ma robusto, che un modello complesso ma inaffidabile.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        plyr_1.8.9           \n#&gt; [46] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [55] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [58] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [61] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [64] tools_4.5.1           mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [67] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [70] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [73] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [76] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [79] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [82] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#riflessioni-conclusive-1",
    "href": "chapters/mcmc/05_stan_diagnostics.html#riflessioni-conclusive-1",
    "title": "52  Diagnostica delle catene markoviane",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo esplorato gli strumenti fondamentali per valutare la qualità dei risultati ottenuti con i metodi MCMC. Per rendere concreti questi concetti, ecco una guida pratica che puoi seguire passo dopo passo.\n\n52.10.1 Protocollo di verifica passo-passo\nInizia sempre controllando i messaggi di Stan: assicurati che non ci siano transizioni divergenti e che l’adattamento sia completato correttamente. Prosegui osservando i grafici delle tracce (trace plot): le diverse catene dovrebbero sovrapporsi e mostrare un andamento stabile, senza derive o pattern strani.\nVerifica poi l’autocorrelazione tra i campioni: dovrebbe diminuire rapidamente all’aumentare della distanza tra i campioni. Questo ci porta a considerare la dimensione effettiva del campione (\\(N_{\\text{eff}}\\)), che dovrebbe essere sufficientemente grande per garantire stime affidabili.\nControlla quindi la statistica \\(\\hat{R}\\): valori vicini a 1 indicano che le catene hanno convergono verso la stessa distribuzione. Valuta anche l’errore standard di Monte Carlo (MCSE), che dovrebbe essere piccolo rispetto alla scala dei parametri.\nPer i modelli che usano HMC/NUTS, assicurati che non ci siano transizioni divergenti e che la BFMI sia sufficientemente alta. Infine, se stai confrontando modelli diversi, utilizza gli strumenti predittivi come LOO/PSIS, prestando attenzione al parametro \\(\\kappa\\).\n\n52.10.2 Cosa fare se incontri problemi\nSe noti valori di \\(\\hat{R}\\) troppo alti o catene che non si sovrappongono, prova ad aumentare il numero di iterazioni o a rivedere le inizializzazioni. In caso di transizioni divergenti, regola i parametri del campionatore o considera una riparametrizzazione del modello.\nSe l’autocorrelazione persiste o la dimensione effettiva del campione è bassa, potresti bisogno di più iterazioni o di ottimizzare la parametrizzazione del modello. Per problemi con la BFMI o valori alti di \\(\\kappa\\), valuta la standardizzazione delle variabili o l’uso di distribuzioni più robuste.\n\n52.10.3 Consigli pratici per il report dei risultati\nQuando presenti i tuoi risultati, includi sempre informazioni sulle impostazioni usate: numero di catene, iterazioni, e parametri del campionatore. Riporta i valori diagnostici chiave (\\(\\hat{R}\\), \\(N_{\\text{eff}}\\), MCSE) e menziona eventuali problemi incontrati e come li hai risolti. Non dimenticare di condividere il codice e i dati necessari per garantire la riproducibilità dei tuoi risultati.\n\n52.10.4 Quando fermarsi\nIl processo di tuning può considerarsi concluso quando: non ci sono più transizioni divergenti, i trace plot mostrano catene stabili e sovrapposte, \\(\\hat{R}\\) è vicino a 1 per tutti i parametri importanti, l’MCSE è sufficientemente piccolo, e gli indicatori predittivi non mostrano problemi critici.\nRicorda: prendersi il tempo per una diagnostica accurata non è una perdita di tempo, ma un investimento necessario per garantire la solidità delle tue conclusioni scientifiche. Meglio un modello semplice ma robusto, che un modello complesso ma inaffidabile.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        plyr_1.8.9           \n#&gt; [46] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [55] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [58] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [61] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [64] tools_4.5.1           mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [67] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [70] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [73] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [76] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [79] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [82] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  }
]