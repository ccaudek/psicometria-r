---
execute:
  freeze: auto
---

# Esplorare i dati numerici {#sec-eda-exploring-num-data}

::: callout-important
## In questo capitolo imparerai a

- costruire e interpretare distribuzioni di frequenza;
- rappresentare e comprendere istogrammi tradizionali e “lisciati”;
- realizzare e interpretare boxplot e violin plot.
:::

::: callout-tip
## Prerequisiti

- Leggere l'Appendice @sec-apx-sums prima di procedere con la lettura di questo capitolo.
- Leggere il capitolo [Exploring numerical data](https://openintro-ims.netlify.app/explore-numerical) di [Introduction to Modern Statistics (2e)](https://openintro-ims.netlify.app) di Mine Çetinkaya-Rundel e Johanna Hardin.
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(ggbeeswarm, dslabs, gridExtra)
```
:::

## Introduzione {.unnumbered}

In questo capitolo ci concentreremo sull'analisi dei dati numerici. In particolare, esamineremo le distribuzioni di frequenza e i quantili, insieme alle tecniche di visualizzazione più comuni, come l'istogramma, l'istogramma smussato e il box-plot. Tratteremo sia gli aspetti computazionali che quelli interpretativi di queste misure, fornendo strumenti utili non solo per una comprensione personale, ma anche per la comunicazione efficace dei risultati, in particolare con chi utilizza questi dati per prendere decisioni pratiche nel mondo reale.

## I dati sulle aspettative negative nella depressione

Consideriamo i dati relativi alle aspettative negative, individuate come un meccanismo chiave nel mantenimento della depressione [@zetsche_2019future]. Supponiamo di voler analizzare la distribuzione di una singola variabile quantitativa.

Importiamo i dati:

```{r}
df <- rio::import(here::here("data", "data.mood.csv"))
```

Per questo esercizio, ci concentreremo sulle variabili `esm_id` (il codice del soggetto), `group` (il gruppo) e `bdi` (il valore BDI-II).

```{r}
df <- df |> 
  dplyr::select("esm_id", "group", "bdi")
df |> 
  head()
```

Se elenchiamo le modalità presenti in `group` utilizzando il metodo `unique()`, scopriamo che corrispondono a `mdd` (pazienti) e `ctl` (controlli sani).

```{r}
df$group |> 
  unique()
```

Rimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:

```{r}
df <- df[!duplicated(df), ]
```

Verifichiamo di avere ottenuto il risultato desiderato.

```{r}
dim(df)
```

```{r}
head(df)
```

Si noti che il nuovo DataFrame (con 67 righe) conserva il "nome" delle righe (ovvero, l'indice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga è 15. Questo non ha nessuna conseguenza perché non useremo l'indice di riga nelle analisi seguenti.

Eliminiamo eventuali valori mancanti:

```{r}
df <- df[!is.na(df$bdi), ]
```

Otteniamo così il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):

```{r}
dim(df)
```

Stampiamo i valori BDI-II presentandoli ordinati dal più piccolo al più grande:

```{r}
df$bdi |> 
  sort()
```

Nel linguaggio statistico, un'osservazione rappresenta l'informazione raccolta da un singolo individuo o entità che partecipa allo studio. Nel caso del dataset utilizzato da @zetsche_2019future, l'unità di osservazione è costituita dai partecipanti allo studio. Ogni riga del DataFrame, denominato `df`, corrisponde quindi a un individuo distinto incluso nell'analisi.

Le variabili, invece, riflettono le diverse caratteristiche degli individui o delle entità considerate. Per i dati in esame, questo concetto si esprime così:

- Ogni colonna di `df` rappresenta una variabile che descrive una specifica proprietà comune ai partecipanti.
- Le variabili sono identificate da etichette nelle colonne, come `esa_id` (l'identificativo del soggetto), `mdd` (il gruppo di appartenenza), e `bdi` (il punteggio del test BDI-II).

In termini simbolisi, per indicare una singola osservazione della variabile generica $X$, si utilizza la notazione $X_i$, dove $i$ rappresenta l'indice dell'osservazione. Questo implica che abbiamo un valore diverso di $X$ per ogni differente $i$. Nel caso presente, con 67 osservazioni, $i$ varia da 1 a 67. Così, per rappresentare la seconda osservazione (quella con $i=2$), useremo la notazione $X_2$. 

## Distribuzioni di frequenza

Come osservato nell'output della sezione precedente, i dati grezzi non forniscono un'interpretazione immediata. Per rendere i dati più comprensibili e sintetici, è utile costruire una **distribuzione di frequenza**.

Una distribuzione di frequenza mostra quante volte i valori di una variabile si verificano all'interno di intervalli specifici. Nel caso dei punteggi BDI-II, possiamo raggruppare i punteggi in quattro classi:

- 0–13: depressione minima
- 14–19: depressione lieve-moderata
- 20–28: depressione moderata-severa
- 29–63: depressione severa

Ogni classe, denotata come $\Delta_i$, rappresenta un intervallo di valori, definito come $[a_i, b_i)$ (aperto a destra) o $(a_i, b_i]$ (aperto a sinistra), dove $a_i$ e $b_i$ sono rispettivamente il limite inferiore e superiore della classe. A ciascuna classe si associa un'ampiezza, data da $b_i - a_i$, e un valore centrale, indicato con $\bar{x}_i$. Poiché ogni osservazione $x_i$ appartiene a una sola classe $\Delta_i$, possiamo calcolare le seguenti quantità:

- **Frequenza assoluta** $n_i$: il numero di osservazioni che rientrano nella classe $\Delta_i$.
  - Proprietà: $n_1 + n_2 + \dots + n_m = n$, dove $n$ è il numero totale di osservazioni.
  
- **Frequenza relativa** $f_i$: la proporzione di osservazioni in ciascuna classe, calcolata come $f_i = n_i/n$.
  - Proprietà: $f_1 + f_2 + \dots + f_m = 1$.

- **Frequenza cumulata** $N_i$: il numero totale di osservazioni che rientrano nelle classi fino alla $i$-esima inclusa, calcolata come $N_i = \sum_{j=1}^i n_j$.

- **Frequenza cumulata relativa** $F_i$: la somma delle frequenze relative fino alla $i$-esima classe, data da $F_i = \frac{N_i}{n} = \sum_{j=1}^i f_j$.

Queste misure permettono di riassumere in modo efficace la distribuzione dei punteggi e facilitano l'interpretazione delle caratteristiche del campione.

### Frequenze Assolute e Relative

Per ottenere la distribuzione di frequenza assoluta e relativa dei valori BDI-II nel dataset di @zetsche_2019future, è necessario aggiungere al DataFrame `df` una colonna contenente una variabile categoriale che classifichi ciascuna osservazione in una delle quattro classi che descrivono la gravità della depressione. Questo risultato si ottiene utilizzando la funzione `cut()`.

Nella funzione `cut()`:

- Il primo argomento, `x`, è un vettore unidimensionale (ad esempio, un vettore di tipo `numeric` o una colonna di un DataFrame) che contiene i dati da classificare.
- Il secondo argomento, `breaks`, definisce gli intervalli delle classi, specificandone i limiti inferiori e superiori.
- L'argomento `include.lowest = TRUE` garantisce che il limite inferiore dell'intervallo più basso sia incluso nella classificazione. Nel nostro caso, questo è particolarmente utile per assicurare che i valori uguali al limite inferiore siano assegnati correttamente.

Di seguito, il codice per aggiungere la variabile categoriale al DataFrame:

```{r}
# Creare una variabile categoriale per classi di depressione
df <- df %>% 
  mutate(
    bdi_class = cut(
      bdi, 
      breaks = c(0, 13.5, 19.5, 28.5, 63),
      include.lowest = TRUE
    )
  )
```

Questo codice suddivide i valori della variabile `bdi` in quattro intervalli corrispondenti ai livelli di gravità della depressione: 

- 0–13: depressione minima
- 14–19: depressione lieve-moderata
- 20–28: depressione moderata-severa
- 29–63: depressione severa

Ogni osservazione verrà assegnata al corrispondente intervallo, creando così una nuova colonna `bdi_class` nel DataFrame `df`.

#### Frequenze assolute

```{r}
table(df$bdi_class)
```

#### Frequenze relative

```{r}
prop.table(table(df$bdi_class))
```

### Distribuzioni congiunte

Le variabili possono anche essere analizzate insieme tramite le *distribuzioni congiunte di frequenze*. Queste distribuzioni rappresentano l'insieme delle frequenze assolute o relative ad ogni possibile combinazione di valori delle variabili. Ad esempio, se l'insieme di variabili $V$ è composto da due variabili, $X$ e $Y$, ciascuna delle quali può assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per $V$ potrebbe essere espressa come $f(X = 1, Y = 1) = 0.2$, $f(X = 1, Y = 2) = 0.1$, $f(X = 2, Y = 1) = 0.5$, e $f(X = 2, Y = 2) = 0.2$. Come nel caso delle distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare a 1.

Per i dati dell'esempio precedente, la funzione `prop.table()` può essere utilizzata anche per produrre questo tipo di tabella: basta indicare le serie corrispondenti alle variabili considerate come valori degli argomenti `bdi_class` e `group`.

```{r}
prop.table(table(df$bdi_class, df$group))
```

### La Distribuzione Cumulativa Empirica

La **distribuzione cumulativa empirica** (eCDF, *empirical Cumulative Distribution Function*) è un modo utile per rappresentare la distribuzione di dati numerici. Questa funzione indica la proporzione di dati che sono inferiori o uguali a un certo valore $a$, per tutti i possibili valori di $a$. Matematicamente, la eCDF è definita come:

$$
F(a) = \text{Proporzione dei dati con valore} \leq a.
$$

In altre parole, la eCDF ci dice quale frazione dei dati osservati è minore o uguale a un determinato valore $a$. Questo è particolarmente utile per comprendere come i dati sono distribuiti e per identificare pattern o caratteristiche specifiche della distribuzione, come la presenza di bimodalità (cioè, due picchi distinti nella distribuzione).

#### Esempio con i dati di @zetsche_2019future

Nel contesto dei dati di @zetsche_2019future, possiamo utilizzare la eCDF per visualizzare la distribuzione dei punteggi BDI-II. Ecco come viene rappresentata la eCDF per l'intero dataset:

```{r}
df |> 
  ggplot(aes(bdi)) + 
  stat_ecdf() +
  labs(x = "BDI", y = "F(BDI)")
```

In questo grafico:

- L'asse $x$ rappresenta i valori del BDI-II.
- L'asse $y$ rappresenta la proporzione cumulativa dei dati, cioè $F(a)$.

#### Interpretazione del grafico

1. **Crescita della curva**: La curva della eCDF parte da 0 (nessun dato è inferiore al valore minimo osservato) e cresce gradualmente fino a 1 (tutti i dati sono inferiori o uguali al valore massimo osservato).
2. **Bimodalità**: Se la curva presenta dei "gradini" o delle aree con una pendenza più ripida, questo può indicare la presenza di bimodalità, ovvero due gruppi distinti di dati con caratteristiche diverse. Nel caso dei dati BDI-II, la bimodalità potrebbe riflettere la presenza di due sottogruppi di partecipanti con livelli di depressione diversi.

#### Filtrare i dati per il campione clinico

Se vogliamo analizzare solo i dati relativi al campione clinico (ad esempio, i pazienti con depressione maggiore), possiamo filtrare i dati e rappresentare la eCDF solo per questo gruppo:

```{r}
df |> dplyr::filter(group == "mdd") |> 
  ggplot(aes(bdi)) + 
  stat_ecdf() +
  labs(x = "a", y = "F(a)")
```

In questo caso, la eCDF ci mostrerà come i punteggi BDI-II sono distribuiti tra i pazienti con depressione maggiore, permettendoci di identificare eventuali pattern specifici per questo gruppo.

#### Vantaggi della eCDF

- **Visualizzazione chiara**: La eCDF fornisce una rappresentazione visiva immediata della distribuzione dei dati, evidenziando caratteristiche come la bimodalità o la presenza di outlier.
- **Non parametrica**: La eCDF non assume alcuna forma specifica per la distribuzione dei dati, rendendola adatta per analizzare dati con distribuzioni complesse o non standard.
- **Facilità di interpretazione**: La proporzione cumulativa è intuitiva e permette di capire rapidamente quanti dati si trovano al di sotto di un certo valore.

In sintesi, la eCDF è uno strumento potente per analizzare e visualizzare la distribuzione di dati numerici, specialmente quando si vogliono identificare pattern specifici o confrontare distribuzioni tra diversi gruppi.

## Istogramma

Sebbene il concetto di Funzione di Distribuzione Empirica Cumulativa (eCDF) venga ampiamente discusso nei testi di statistica, in pratica tale rappresentazione non è molto diffusa. Il motivo principale è che l'eCDF non rende immediatamente visibili alcune caratteristiche fondamentali della distribuzione, come il valore intorno al quale essa è centrata, se la distribuzione sia simmetrica o quali intervalli contengano il 95% dei dati, ad esempio. Gli istogrammi, invece, sono molto più utilizzati perché facilitano notevolmente la comprensione di queste proprietà, sacrificando solo un po' di informazione per fornire una rappresentazione più intuitiva.

Un **istogramma** è un grafico che rappresenta la distribuzione delle frequenze di una variabile. Sull’asse orizzontale (ascisse) vengono indicati i limiti delle classi $\Delta_i$, mentre sull’asse verticale (ordinate) si riporta la densità della frequenza relativa della variabile $X$ per ciascuna classe $\Delta_i$.

Per descrivere formalmente la densità della frequenza relativa, si utilizza una funzione costante a tratti definita come:

$$
\varphi_n(x) = \frac{f_i}{b_i - a_i},
$$

dove:

- $f_i$ è la frequenza relativa della classe $\Delta_i$,
- $b_i - a_i$ è l’ampiezza della classe $\Delta_i$.

In questo modo, l’area del rettangolo corrispondente a $\Delta_i$ in un istogramma risulta proporzionale alla frequenza relativa $f_i$. Poiché la somma delle frequenze relative deve essere pari a 1, l’area totale di un istogramma delle frequenze relative risulta anch’essa uguale a 1, corrispondendo alla somma delle aree di tutti i rettangoli.

Gli istogrammi costituiscono quindi uno strumento essenziale per visualizzare e comprendere le principali caratteristiche di una distribuzione, agevolando l’analisi della sua forma, della sua tendenza centrale e della sua dispersione.

Per fare un esempio, costruiamo un istogramma per i valori BDI-II di @zetsche_2019future. Con i quattro intervalli individuati dai cut-off del BDI-II creiamo una prima versione dell'istogramma -- si notino le frequenze assolute sull'asse delle ordinate.

```{r}
ggplot(df, aes(x = bdi)) +
  geom_histogram(
    breaks = c(0, 13.5, 19.5, 28.5, 63),
    aes(y = after_stat(density)),
  ) +
  labs(
    title = "Istogramma delle frequenze relative", 
    x = "BDI-II", 
    y = "Densità"
  ) 
```

Anche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un'ampiezza uguale. 

```{r}
ggplot(df, aes(x = bdi)) +
  geom_histogram(
    aes(y = after_stat(density)),
  ) +
  labs(
    title = "Istogramma delle frequenze relative", 
    x = "BDI-II", 
    y = "Densità"
  )
```

## Kernel Density Plot

Un limite evidente degli istogrammi è che la loro forma dipende da scelte arbitrarie: il numero e l’ampiezza delle classi (o *bin*) può infatti influenzare in modo sostanziale l’aspetto finale del grafico, rendendo più difficile l’interpretazione della distribuzione dei dati. Una soluzione a questo problema è offerta dalla **stima della densità kernel** (*Kernel Density Estimation*, KDE), un metodo che fornisce un profilo continuo e smussato della distribuzione, meno condizionato dall’arbitrarietà delle classi.

### Differenza tra Istogramma e KDE

Nell’istogramma, dividiamo l’asse orizzontale in intervalli di ampiezza prefissata (i *bin*) e costruiamo rettangoli la cui altezza è proporzionale alla frequenza (o densità) dei dati che ricadono in ciascun intervallo. Se cambiamo il numero o la larghezza dei bin, la forma dell’istogramma può variare sensibilmente.

La KDE, invece, non suddivide i dati in intervalli fissi. Al contrario, “appoggia” una piccola curva (il *kernel*) su ogni singola osservazione. Le curve utilizzate (ad esempio di tipo gaussiano) hanno una larghezza, detta *bandwidth*, che controlla il grado di **smussamento**: con un bandwidth molto piccolo, la stima segue da vicino le singole osservazioni, generando un profilo più frastagliato; con un bandwidth più ampio, la curva risultante è più liscia, ma rischia di nascondere dettagli importanti.

Per comprendere in modo intuitivo il concetto di KDE, possiamo partire da un esempio semplice. Immaginiamo di costruire un istogramma con classi di ampiezza sempre più piccola. Se avessimo a disposizione un numero *enorme* di dati (ad esempio, un milione di misurazioni dell'altezza di individui) e li rappresentassimo con bin sempre più stretti (0.1, 0.01, ecc.), l'istogramma diventerebbe sempre più levigato, avvicinandosi a una curva continua. Questo processo illustra l'idea alla base della KDE, che approssima la distribuzione dei dati in modo fluido e continuo.

La KDE, tuttavia, opera in modo più elegante e senza richiedere un numero enorme di punti: posiziona un piccolo “dosso di campana” (o un altro tipo di kernel) su ciascun punto dati e somma tutte queste curve in un’unica curva finale.

::: {.callout-note}
## Che cosa vuol dire “dosso di campana”?

Possiamo immaginarlo come una piccola curva gaussiana: una curva simile alla forma di una campana che si innalza e poi discende dolcemente.

- Ogni singolo dato viene “coperto” da questa mini-campana.
- L’ampiezza (o “larghezza”) della campana è regolata dal bandwidth, che stabilisce se la curva sarà più o meno “distesa” sul grafico.
- Sommando tutte le piccole campane (una per ogni osservazione), otteniamo una curva di densità liscia e continua che rappresenta la distribuzione dei dati senza i “salti” tipici dell’istogramma.
:::

Il risultato è una **curva di densità** che:

1. **È continua**: a differenza degli istogrammi, non presenta bruschi salti di altezza tra i bin: la curva scorre in modo uniforme lungo tutto l’asse orizzontale.
2. **Mostra la proporzione di dati in ogni intervallo**: l'area sotto la curva in un determinato range corrisponde alla percentuale (o probabilità) di dati che cadono in quell'intervallo.
3. **Dipende dal bandwidth**: 
    - Un bandwidth **piccolo** produce una curva più ondulata e “frastagliata” (poiché segue da vicino ogni singolo dato).
    - Un bandwidth **grande** genera una curva più liscia e arrotondata, ma rischia di “coprire” troppi dettagli della distribuzione originaria.

Si noti che la stima della densità kernel introduce, tuttavia, un’ipotesi di fondo: che la distribuzione dei dati “reali” sia “liscia” e non presenti discontinuità improvvise. Questo è spesso ragionevole (ad esempio per dati fisiologici come l’altezza), ma in altri casi potrebbe non esserlo. È quindi importante scegliere un bandwidth che rifletta adeguatamente il livello di dettaglio che vogliamo mostrare.

Inoltre, l’asse delle ordinate (l’asse *y*) rappresenta la densità, non la frequenza assoluta. È possibile costruire un istogramma in cui l’altezza dei rettangoli mostra quante osservazioni ricadono in ciascun bin. Nella KDE, l’altezza della curva è tale che l’area totale sotto di essa sia pari a 1, rispecchiando la natura di una funzione di densità di probabilità.

Di seguito esaminiamo un esempio che mostra la costruzione passo dopo passo di istogrammi con diversi valori di binwidth, fino a passare a una stima di densità. Consideriemo un dataset con un numero di osservazioni molto elevato (i valori di altezza, `heights`, riportati da 1050 partecipanti, estratti dal pacchetto `dslabs`), suddiviso in due gruppi: maschi e femmine. Ecco come potremmo prima costruire un istogramma di altezze per i maschi, per poi tracciare una curva di densità smussata:

```{r}
# Istogramma con bin di ampiezza 1
ggplot(heights |> dplyr::filter(sex == "Male"), aes(height)) +
  geom_histogram(binwidth = 1, color = "black", alpha = 0.5)

# Aggiunta della curva di densità sopra l'istogramma
ggplot(heights |> dplyr::filter(sex == "Male"), aes(height)) +
  geom_histogram(
    aes(y = after_stat(density)), binwidth = 1, color = "black", alpha = 0.5
  ) +
  geom_line(stat = 'density')
```

Variando il parametro di regolazione (*adjust* o *bandwidth*) nella funzione `geom_density()`, possiamo modificare il livello di smussamento:

```{r}
# Esempio di smoothing differente
p <- ggplot(heights |> filter(sex == "Male"), aes(height)) +
  geom_histogram(aes(y = after_stat(density)), binwidth = 1, alpha = 0.5)

# Più ondulato (bandwidth minore)
p1 <- p + geom_line(stat = 'density', adjust = 0.5)

# Più liscio (bandwidth maggiore)
p2 <- p + geom_line(stat = 'density', adjust = 2)

grid.arrange(p1, p2, ncol = 2)
```

Per illustrare ulteriormente l’uso della KDE, ora consideriamo i punteggi BDI-II di  @zetsche_2019future. Con il codice seguente creiamo due curve di densità, una per ogni gruppo:

```{r}
ggplot(df, aes(x = bdi, fill = group)) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Curva di densità (KDE) per i punteggi BDI-II",
    x = "BDI-II",
    y = "Densità"
  )
```

Qui, la sovrapposizione delle due curve ci consente di confrontare la distribuzione dei punteggi BDI-II tra i due gruppi in maniera molto più *fluida* e intuitiva rispetto a quanto faremmo con due istogrammi separati o con un istogramma combinato. Inoltre, non siamo più vincolati alla scelta dei bin: l’aspetto delle curve dipende soltanto dalla funzione kernel utilizzata e dal parametro di smussamento. 

In conclusione, 

- l’**istogramma** rimane uno strumento rapido e intuitivo, *privo di assunzioni*, ma sensibile alla scelta di numero e ampiezza dei bin;
- la **stima della densità kernel (KDE)** offre una rappresentazione continua della distribuzione dei dati, fornendo un quadro più “morbido” e spesso più informativo. Tuttavia, introduce alcune assunzioni e richiede la scelta del bandwidth ottimale.

In definitiva, è consigliabile usare entrambe le tecniche per ottenere una panoramica completa dei propri dati: l’istogramma permette di dare un primo sguardo alla loro distribuzione “grezza” (senza presupposti), mentre la KDE aiuta a comprenderne l’eventuale struttura “liscia” di fondo.

### Area Sottesa alla Curva di Densità: Un'Interpretazione Probabilistica

Quando si lavora con una curva di densità, è importante capire che l'area totale sotto la curva rappresenta la probabilità totale, che è sempre pari a 1 (o 100%). Questo significa che l'area sotto la curva in un determinato intervallo corrisponde alla probabilità che un dato valore cada in quell'intervallo.

#### Come Interpretare l'Asse Y

L'asse y di un grafico di densità non rappresenta direttamente la probabilità, ma è scalato in modo che l'area totale sotto la curva sia uguale a 1. Se immaginiamo di creare un "bin" (un intervallo) con una base di 1 unità di lunghezza, il valore sull'asse y ci indica la proporzione di valori che cadono in quel bin. Tuttavia, questa interpretazione è valida solo per bin di dimensione 1. Per intervalli di altre dimensioni, il modo migliore per determinare la proporzione di dati in quell'intervallo è calcolare la proporzione dell'area totale sotto la curva che cade in quell'intervallo.

#### Esempio Pratico

Consideriamo un esempio con i dati delle altezze degli uomini. Supponiamo di voler sapere quale proporzione di uomini ha un'altezza compresa tra 65 e 68 pollici. Per farlo, calcoliamo l'area sotto la curva di densità in quell'intervallo.

Ecco come appare graficamente:

```{r summaries-area-under-curve, echo = FALSE}
d <- with(heights, density(height[sex == "Male"]))
tmp <- data.frame(height = d$x, density = d$y)
tmp |> ggplot(aes(height,density)) + geom_line() + 
  geom_area(
    aes(
      x = height, 
      y = density), 
    data = dplyr::filter(tmp, between(height, 65, 68)), 
    alpha = 0.2, fill = "#00BFC4"
  )
```

L'area evidenziata in azzurro rappresenta la proporzione di uomini con altezza tra 65 e 68 pollici. Calcolando questa area, troviamo che circa il `r round(mean(dplyr::between(heights$height[heights$sex=="Male"], 65, 68)), 2)` (ovvero il `r noquote(paste0(round(mean(dplyr::between(heights$height[heights$sex=="Male"], 65, 68)), 2)*100, '%'))` degli uomini ha un'altezza in questo intervallo.

#### Utilizzo della Curva di Densità come Riepilogo

Comprendendo questo concetto, possiamo utilizzare la curva di densità come un efficace strumento di riepilogo. Per questo dataset, l'assunzione di smoothness (lisciatura) della curva è ragionevole, e possiamo condividere questa rappresentazione grafica per comunicare in modo chiaro e intuitivo la distribuzione delle altezze degli uomini.

Ecco un esempio di come appare la curva di densità smooth per le altezze degli uomini:

```{r summaries-example-of-smoothed-density-2, echo = FALSE}
heights |> 
  dplyr::filter(sex == "Male") |> 
  ggplot(aes(height)) + 
  geom_density(alpha = 0.2, fill = "#00BFC4")
```

In sintesi, l'area sotto la curva di densità in un determinato intervallo rappresenta la probabilità che un valore casuale cada in quell'intervallo, rendendo la curva di densità uno strumento potente per comprendere e comunicare la distribuzione dei dati.

## Consigli per Creare Visualizzazioni di Dati Efficaci

Ecco alcuni suggerimenti per creare visualizzazioni di dati esplicative, efficaci e di qualità adatta alle presentazioni:

1. **Messaggio chiaro**: Assicurati che il grafico trasmetta un messaggio chiaro e immediato (ad esempio, "Il livello di benessere psicologico dei partecipanti aumenta nel tempo").
2. **Uso del colore**:
   - Utilizza i colori in modo ponderato e con moderazione.
   - Non eccedere nell'uso dei colori solo perché è possibile farlo.
   - Limita l'uso a non più di cinque o sei colori in una singola figura.
   - Verifica che le scelte cromatiche non distorcano le conclusioni della figura.
   - Evita l'uso contemporaneo di rosso e verde nello stesso grafico, poiché queste tonalità sono difficili da distinguere per le persone daltoniche.
3. **Guidare l'attenzione**:
   - Utilizza dimensioni, colori e testo per guidare l'attenzione del pubblico.
   - Evidenzia elementi particolari del grafico per enfatizzare punti chiave.
4. **Gestione del sovraccarico visivo**:
   - Utilizza la trasparenza per ridurre il "sovrapplotting" (che si verifica quando ci sono molti elementi sovrapposti nel grafico, come punti o linee, rendendo difficile individuare i pattern).
   - Questa tecnica è particolarmente utile quando si visualizza una grande quantità di dati.
   - Se il dataset è molto ampio e l'aggiunta di trasparenza non è sufficiente, considera la visualizzazione di un sottocampione dei dati (un campione casuale di punti dati, scelto *senza sostituzione*). Questa tecnica è nota come **sottocampionamento**.
5. **Elementi testuali**:
   - I titoli, le etichette degli assi e il testo delle legende devono essere chiari e facilmente comprensibili.
   - Gli elementi della legenda dovrebbero essere ordinati in modo logico e coerente.

## Forma di una Distribuzione

In statistica, la forma di una distribuzione descrive come i dati sono distribuiti intorno ai valori centrali. Si distingue tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali e multimodali. Un'illustrazione grafica è fornita nella figura seguente. Nel pannello 1, la distribuzione è unimodale con asimmetria negativa; nel pannello 2, la distribuzione è unimodale con asimmetria positiva; nel pannello 3, la distribuzione è simmetrica e unimodale; nel pannello 4, la distribuzione è bimodale.

![Distribuzioni](../../figures/shape_distribution.png){width="55%"}

Il grafico della densità di kernel (Kernel Density Plot) dei valori BDI-II nel campione di @zetsche_2019future è bimodale. Questo indica che le osservazioni della distribuzione si raggruppano in due cluster distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l'altro gruppo tende ad avere valori BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da @zetsche_2019future.

## Indici di posizione

### Quantili

La distribuzione dei valori BDI-II di @zetsche_2019future può essere sintetizzata attraverso l'uso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, $q_1$, divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, $q_2$, corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.

Inoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.

Per calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di $np$, dove $n$ è la dimensione del campione e $p$ è l'ordine del quantile. Se $np$ non è un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di $np$. Se $np$ è un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni $k$ e $k+1$, dove $k$ è la parte intera di $np$.

Gli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che è molto popolare e può essere utilizzata in alternativa ad un istogramma.

Ad esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di @zetsche_2019future, si determina il valore di $np = 9 \cdot 0.5 = 4.5$, che non è un intero. Pertanto, il valore del secondo quartile è pari al valore del dato che si trova alla posizione successiva alla parte intera di $np$, ovvero $q_2 = x_{4 + 1} = 27$. Per calcolare il quantile di ordine $2/3$, si determina il valore di $np = 9 \cdot 2/3 = 6$, che è un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni $6$ e $7$, ovvero $q_{\frac{2}{3}} = \frac{1}{2} (x_{6} + x_{7}) = \frac{1}{2} (33 + 33) = 33$.

Usiamo `quantile()` per trovare la soluzione dell'esercizio precedente.

```{r}
x = c(19, 26, 27, 28, 28, 33, 33, 41, 43)
quantile(x, 2 / 3)
```

## Mostrare i dati

### Diagramma a scatola

Il box plot è uno strumento grafico che visualizza la dispersione di una distribuzione. I **boxplot** forniscono una rappresentazione visiva sintetica di cinque valori caratteristici: **minimo**, **primo quartile (25%)**, **mediana (50%)**, **terzo quartile (75%)** e **massimo**. Spesso però, i boxplot “ignorano” i valori considerati anomali (*outlier*), segnalandoli con punti isolati. 

Per creare un box plot, si disegna un rettangolo (la "scatola") di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile ($q_{0.75}$) e il primo quartile ($q_{0.25}$). La mediana ($q_{0.5}$) è rappresentata da una linea all'interno del rettangolo.

Ai lati della scatola, vengono tracciati due segmenti di retta, detti "baffi", che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore è il valore più basso tra le osservazioni che è maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore è il valore più alto tra le osservazioni che è minore o uguale al terzo quartile più 1.5 volte la distanza interquartile.

Se ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati "valori anomali" e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.

![](../../figures/boxplot.png){width="80%"}

### Stratificazione

Nell'analisi dei dati, è comune suddividere le osservazioni in gruppi in base ai valori di una o più variabili associate a tali osservazioni. Questo processo è chiamato **stratificazione**, e i gruppi risultanti sono detti **strati**. Ad esempio, nella sezione successiva, dividiamo i valori dei punteggi BDI-II in due gruppi in base alla condizione sperimentale: campione clinico e campione di controllo. 

La stratificazione è particolarmente utile nella visualizzazione dei dati, poiché spesso siamo interessati a comprendere come la distribuzione di una variabile differisca tra diversi sottogruppi. 

Per esempio, per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo, possiamo utilizzare un box-plot. Questo tipo di grafico ci permette di confrontare visivamente la distribuzione dei punteggi tra i due gruppi, evidenziando eventuali differenze.

```{r}
ggplot(df, aes(x = group, y = bdi)) +
  geom_boxplot() +
  labs(
    title = "Box plot per gruppo", 
    x = "Gruppo", 
    y = "BDI-II"
  )
```

In questo grafico:

- L'asse **x** rappresenta i due gruppi (pazienti e controllo).
- L'asse **y** rappresenta i punteggi BDI-II.
- I box (scatole) mostrano la distribuzione dei punteggi, con la linea centrale che indica la mediana e i "baffi" che rappresentano la variabilità dei dati.

La stratificazione ci aiuta a identificare rapidamente se ci sono differenze nella distribuzione dei punteggi BDI-II tra i due gruppi. Nel caso presente, il grafico mostra come non vi sia alcuna sovrapposizione tra le due distribuzioni.

Un risultato migliore si ottiene utilizzando un grafico a violino (*violin plot*) e includendo anche i dati grezzi.

### Grafico a Violino

I grafici a violino combinano le caratteristiche dei box plot e dei grafici di densità di kernel (KDE plot) per offrire una rappresentazione più dettagliata dei dati. A questi grafici vengono sovrapposti i dati grezzi, fornendo una visione completa della distribuzione e delle caratteristiche dei dati.

```{r}
ggplot(df, aes(x = group, y = bdi, fill = group)) +
  geom_violin() +
  geom_dotplot(
    binaxis = "y",
    stackdir = "center",
    dotsize = 0.5,
    fill = 1
  ) +
  labs(
    title = "Violin plot con overlay dei punti grezzi",
    x = "Gruppo",
    y = "BDI-II"
  )
```

### Grafico Beeswarm

Il pacchetto *{ggbeeswarm}* include una funzione chiamata `geom_beeswarm`, che può essere utilizzata per creare un grafico beeswarm in ggplot2.

Un grafico beeswarm è una variazione del grafico a punti che disperde i dati in modo che non si sovrappongano, rendendo visibili tutti i singoli punti dati. Questo tipo di visualizzazione è particolarmente utile quando si desidera esaminare la distribuzione e la densità di un set di dati, senza ricorrere all'uso di barre d'errore o di scatole e baffi (boxplot), mantenendo un'alta leggibilità anche quando i set di dati sono densi.

```{r}
ggplot(df, aes(x = group, y = bdi, color = group)) +
  geom_beeswarm(cex = 3) +
  labs(
    title = "Violin plot con overlay dei punti grezzi",
    x = "Gruppo",
    y = "BDI-II"
  ) 
```

## Riflessioni Conclusive

Abbiamo esplorato diverse tecniche per sintetizzare e visualizzare i dati, includendo distribuzioni di frequenze, istogrammi e grafici di densità. Questi strumenti sono essenziali per comprendere meglio i dati e presentare risultati in modo chiaro e informativo. La **visualizzazione dei dati** ci aiuta a individuare possibili anomalie o situazioni inaspettate, prima di applicare modelli o interpretazioni statistiche.

## Informazioni sull'Ambiente di Sviluppo {.unnumbered}

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

