# Sintesi a posteriori {#sec-bayesian-inference-summary-posterior}

::: callout-important
## In questo capitolo imparerai a

- verificare, pulire e trasformare i dati 
- applicare regole coerenti per denominazione e codifica
:::

::: callout-tip
## Prerequisiti

- Leggere il capitolo *Posterior Inference & Prediction* del testo di  @Johnson2022bayesrules.
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(mice)
```
:::


## Introduzione {.unnumbered .unlisted}

::: {.dropcap}
In questo capitolo, concentriamo la nostra attenzione sulla sintesi dell'informazione racchiusa nella distribuzione a posteriori, la quale rappresenta il nostro livello di incertezza riguardo al parametro o ai parametri incogniti oggetto dell'inferenza.
:::

## Riepilogo numerico

La distribuzione a posteriori contiene in s√© tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico $p(\theta \mid y)$.

Tuttavia, quando ci troviamo di fronte a vettori di parametri con pi√π di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori:

- stima puntuale;
- intervallo di credibilit√†.


## Stima puntuale  

Nel contesto dell‚Äô*inferenza bayesiana*, stimare il valore pi√π credibile di un parametro $\theta$ a partire dalla distribuzione a posteriori pu√≤ avvenire attraverso tre statistiche principali: *moda, mediana e media*. La scelta tra queste dipende dalla forma della distribuzione a posteriori.  

Queste statistiche forniscono una *stima puntuale* della tendenza centrale della distribuzione, ossia il valore a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sia sui dati osservati sia sulle credenze a priori.  

### 1. Moda (*Massimo a Posteriori*, MAP) {.unnumbered}

La *moda* √® il valore pi√π probabile del parametro, ovvero quello che *massimizza la distribuzione a posteriori*. Questo valore √® noto come *massimo a posteriori (MAP)*.  

Il concetto di MAP deriva dalla *stima di massima verosimiglianza (MLE)*, che individua il valore di $\theta$ che massimizza la funzione di verosimiglianza:  

$$ 
\hat{\theta}_{ML} = \arg \max_\theta L(\theta \mid y).  
$$  

Nell‚Äôinferenza bayesiana, consideriamo $\theta$ come una variabile casuale con una distribuzione a priori $p(\theta)$. Incorporando questa informazione nella funzione di verosimiglianza, otteniamo la *stima MAP*:  

$$ 
\hat{\theta}_{MAP} = \arg \max_\theta L(\theta \mid y)p(\theta).  
$$  

Questa formula mostra che il MAP √® il valore che massimizza la densit√† a posteriori di $\theta$ dato il set di dati osservati $y$.  

**Limitazioni della stima MAP:** 

- *Difficolt√† computazionali*: con metodi MCMC, √® complesso individuare con precisione il MAP nello spazio delle distribuzioni posteriori.  
- *Sensibilit√† alla forma della distribuzione*: se la distribuzione a posteriori √® *asimmetrica o multimodale*, il MAP potrebbe non rappresentare adeguatamente la tendenza centrale.  
- *Minor robustezza rispetto ad altre misure*: il MAP si basa esclusivamente sul valore massimo della distribuzione e non tiene conto della distribuzione complessiva della probabilit√†.  


### 2. Media a posteriori  {.unnumbered}

La *media a posteriori* √® il valore atteso di $\theta$ secondo la distribuzione a posteriori:  

$$ 
E(\theta \mid y) = \int_{-\infty}^{\infty} \theta \, p(\theta \mid y) \, d\theta.  
$$  

Questa stima √® spesso preferita perch√© considera *l‚Äôintera distribuzione* e minimizza l‚Äôerrore quadratico medio (*Mean Squared Error*, MSE). Tuttavia, se la distribuzione a posteriori √® asimmetrica, la media potrebbe non rappresentare bene la posizione della maggior parte della probabilit√†.  

### 3. Mediana a posteriori  {.unnumbered}

La *mediana a posteriori* √® il valore che divide la distribuzione a posteriori in due parti uguali, con il 50% della probabilit√† a sinistra e il 50% a destra.  

La mediana √® una stima robusta della tendenza centrale ed √® particolarmente utile in *distribuzioni asimmetriche o multimodali*, dove la moda e la media potrebbero risultare fuorvianti.  

### Misurare l'incertezza: varianza a posteriori  {.unnumbered}

Oltre a stimare la tendenza centrale, √® utile valutare l‚Äô*incertezza associata alla stima di $\theta$*. La varianza a posteriori misura la dispersione della distribuzione:  

$$ 
V(\theta|y) = E[((\theta - E[(\theta|y)])^2 |y) = \int_{-\infty}^{\infty} (\theta - E[\theta | y])^2 p(\theta | y) d\theta = E[\theta^2 |y] - E[\theta|y]^2.  
$$  

La *deviazione standard a posteriori* (radice quadrata della varianza) esprime l‚Äôincertezza sulla stima $\theta$ con la stessa unit√† di misura dei dati.  

In sintesi, la *moda (MAP), la media e la mediana a posteriori* offrono diverse prospettive sulla *stima puntuale* di un parametro $\theta$. Ciascuna ha vantaggi e limiti, e la scelta migliore dipende dalla forma della distribuzione a posteriori e dal contesto applicativo.  

Insieme alla *varianza a posteriori*, queste statistiche forniscono un quadro completo della distribuzione a posteriori, permettendo di esprimere non solo la stima pi√π credibile, ma anche *l‚Äôincertezza associata*.

## Intervallo di credibilit√†

Nell'inferenza bayesiana, l'intervallo di credibilit√† √® uno strumento utilizzato per definire un intervallo che contiene una determinata percentuale della massa della distribuzione a posteriori del parametro $\theta$. Questo intervallo riflette l'incertezza associata alla stima del parametro: un intervallo pi√π ampio suggerisce una maggiore incertezza. Lo scopo principale dell'intervallo di credibilit√† √® fornire una misura quantitativa dell'incertezza riguardante $\theta$.

A differenza degli intervalli di confidenza frequentisti, non esiste un unico intervallo di credibilit√† per un dato livello di confidenza $(1 - \alpha) \cdot 100\%$. In effetti, √® possibile costruire un numero infinito di tali intervalli. Per questo motivo, √® necessario stabilire criteri aggiuntivi per selezionare l'intervallo di credibilit√† pi√π appropriato. Tra le opzioni pi√π comuni ci sono l'intervallo di credibilit√† simmetrico e l'intervallo di massima densit√† posteriore (HPD).

### 1. Intervallo di Credibilit√† Simmetrico {.unnumbered}

Questo tipo di intervallo √® centrato rispetto al punto di stima puntuale. Se $\hat{\theta}$ rappresenta la stima del parametro, l'intervallo simmetrico avr√† la forma $(\hat{\theta} - a, \hat{\theta} + a)$, dove $a$ √® un valore positivo scelto in modo tale che la massa totale inclusa sia pari a $(1 - \alpha)$. Pi√π formalmente, un intervallo di credibilit√† simmetrico al livello $\alpha$ pu√≤ essere espresso come:

$$ 
I_{\alpha} = [q_{\alpha/2}, q_{1 - \alpha/2}], 
$$

dove $q_z$ rappresenta il quantile $z$ della distribuzione a posteriori. Ad esempio, un intervallo di credibilit√† simmetrico al 94% sar√†:

$$ 
I_{0.06} = [q_{0.03}, q_{0.97}], 
$$

dove il 3% della massa a posteriori si trova in ciascuna delle due code della distribuzione.

### 2. Intervallo di Credibilit√† Pi√π Stretto (Intervallo di Massima Densit√† Posteriore, HPD) {.unnumbered}

L'intervallo di massima densit√† posteriore (HPD) √® l'intervallo pi√π stretto possibile che contiene il $(1 - \alpha) \cdot 100\%$ della massa a posteriori. A differenza dell'intervallo simmetrico, l'HPD include tutti i valori di $\theta$ che hanno la maggiore densit√† a posteriori. Per costruirlo, si disegna una linea orizzontale sulla distribuzione a posteriori e si regola l'altezza della linea in modo che l'area sotto la curva corrisponda a $(1 - \alpha)$. L'HPD risulta essere il pi√π stretto tra tutti gli intervalli possibili per lo stesso livello di confidenza. Nel caso di una distribuzione a posteriori unimodale e simmetrica, l'HPD coincide con l'intervallo di credibilit√† simmetrico.

### Interpretazione

Il calcolo degli *intervalli di credibilit√†*‚Äîin particolare dell‚Äô*intervallo di massima densit√† posteriore* (HPD)‚Äîrichiede quasi sempre l‚Äôutilizzo di software statistici specializzati. Questo perch√©, nei modelli bayesiani con distribuzioni posteriori articolate o che richiedono simulazioni numeriche (ad esempio tramite Markov Chain Monte Carlo), ricavare a mano i confini dell‚Äôintervallo pu√≤ risultare molto laborioso.

#### 1. Incertezza nel paradigma frequentista  
- *Parametro fisso*: nel contesto frequentista, il parametro di interesse (ad esempio la media di popolazione $\mu$) √® un valore costante ma sconosciuto.  
- *Ripetizione ipotetica*: immaginiamo di ripetere all‚Äôinfinito il prelievo di campioni dalla popolazione. Per ciascun campione otteniamo una media $\bar{x}$ e costruendo un intervallo di confidenza al $100(1-\alpha)\%$ avremo che, nel lungo periodo, il $100(1-\alpha)\%$ di questi intervalli conterr√† il vero $\mu$.  
- *Interpretazione del singolo intervallo*: per un singolo intervallo calcolato, la probabilit√† che contenga effettivamente $\mu$ √® formalmente 0 o 1, perch√© $\mu$ non √® soggetto a variabilit√† stocastica‚Äîsiamo semplicemente ignari del suo valore reale.

#### 2. Incertezza nel paradigma bayesiano  
- *Parametro come variabile aleatoria*: qui $\mu$ non √® pi√π un valore fisso, ma possiede una distribuzione di probabilit√† che riflette sia l‚Äôinformazione a priori sia quella fornita dai dati osservati.  
- *Campionamento dalla distribuzione a posteriori*: grazie a tecniche di simulazione (ad es. MCMC), otteniamo un insieme di possibili valori di $\mu$ che segue la distribuzione posteriore.  
- *Costruzione diretta dell‚Äôintervallo*: scegliendo i quantili al $2.5\%$ e al $97.5\%$ di questa distribuzione, otteniamo un intervallo di credibilit√† al 95%. In termini intuitivi, possiamo affermare che ¬´c‚Äô√® una probabilit√† del 95% che $\mu$ cada all‚Äôinterno di questo intervallo, dati i dati e le ipotesi a priori¬ª.

#### 3. Confronto e considerazioni  
- *Frequentista*: l‚Äôintervallo di confidenza √® un costrutto legato alla frequenza di lungo periodo di un procedimento ipotetico di campionamento.  
- *Bayesiano*: l‚Äôintervallo di credibilit√† fornisce una misura puntuale dell‚Äôincertezza sul parametro, direttamente comprensibile come probabilit√† condizionata sui dati osservati.  
- *Intuizione*: per molti, l‚Äôinterpretazione bayesiana risulta pi√π aderente al senso comune, perch√© traduce immediatamente il grado di fiducia che possiamo riporre nei valori ipotizzati per il parametro.

In sintesi, mentre la teoria frequentista quantifica l‚Äôaffidabilit√† del metodo di stima nel lungo periodo, l‚Äôapproccio bayesiano esprime senza ambiguit√† la probabilit√† attuale che il parametro si trovi in un certo intervallo, alla luce delle evidenze e delle conoscenze pregresse.

## Verifica di ipotesi bayesiana

L'inferenza bayesiana pu√≤ essere applicata anche nel contesto della verifica di ipotesi, in un approccio noto come *verifica di ipotesi bayesiana*. In questo tipo di inferenza, l'obiettivo √® valutare la plausibilit√† che un parametro $\theta$ assuma valori all'interno di un determinato intervallo. Ad esempio, possiamo voler sapere quanto √® probabile che $\theta$ sia maggiore di 0.5 o che rientri in un intervallo specifico, come [0.5, 1.0].

In questo approccio, si calcola la *probabilit√† a posteriori* che $\theta$ si trovi all'interno dell'intervallo di interesse. Questa probabilit√† viene ottenuta integrando la distribuzione a posteriori su tale intervallo. Quindi, invece di rifiutare o accettare un'ipotesi come nel test di ipotesi frequentista, la verifica di ipotesi bayesiana fornisce una misura diretta della probabilit√† che un parametro rientri in un intervallo specifico, dato l'evidenza osservata e le informazioni a priori.

In altre parole, questo approccio consente di quantificare la nostra incertezza rispetto all'affermazione che $\theta$ rientri in un certo intervallo, fornendo una probabilit√† che rappresenta direttamente la plausibilit√† di quell'ipotesi.

::: {#exm-}
Per illustrare l'approccio bayesiano, consideriamo i dati relativi ai punteggi del BDI-II (*Beck Depression Inventory - Second Edition*) di 30 soggetti clinici, come riportato nello studio condotto da @zetsche_2019future. Il BDI-II √® uno strumento per valutare la gravit√† dei sintomi depressivi.

I punteggi del BDI-II per i 30 soggetti sono:

```{r}
# Dati del BDI-II
bdi <- c(
  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 
  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, 
  41, 36, 26, 35, 33, 28, 27, 34, 27, 22
)
bdi
```

Un punteggio BDI-II $\geq 30$ indica un livello grave di depressione. Nel nostro campione, 17 pazienti su 30 manifestano un livello grave:

```{r}
# Conteggio di depressione grave
sum(bdi >= 30)
```

Stima della distribuzione a posteriori.

Supponiamo di voler stimare la probabilit√† $\theta$ di depressione grave nei pazienti clinici utilizzando una distribuzione a priori $Beta(8, 2)$. I dati possono essere visti come una sequenza di prove Bernoulliane indipendenti, dove la presenza di depressione grave √® un "successo". La verosimiglianza √® quindi binomiale con parametri $n = 30$ e $y = 17$.

Con una distribuzione a priori $Beta(8, 2)$, la distribuzione a posteriori di $\theta$ sar√†:

$$
\text{Beta}(\alpha = 8 + 17, \beta = 2 + 30 - 17) = \text{Beta}(25, 15).
$$

Tracciamo la distribuzione a posteriori.

```{r}
# Parametri della distribuzione Beta
alpha <- 25
beta <- 15

# Calcolo della densit√† per valori di theta
theta <- seq(0, 1, length.out = 200)
posterior_density <- dbeta(theta, alpha, beta)

# Grafico della distribuzione a posteriori
ggplot(data = data.frame(theta, posterior_density), aes(x = theta, y = posterior_density)) +
  geom_line() +
  labs(
    title = "Distribuzione a Posteriori Beta(25, 15)",
    x = expression(theta),
    y = "Densit√† di probabilit√†"
  ) 
```

**Stime puntuali.**

1. **Media a Posteriori**  
La media della distribuzione a posteriori √® calcolata come:

$$
\mathbb{E}(\theta | y = 17) = \frac{\alpha}{\alpha + \beta} = \frac{25}{25 + 15} = 0.625.
$$

In R:

```{r}
# Calcolo della media a posteriori
posterior_mean <- alpha / (alpha + beta)
posterior_mean
```

2. **Moda a Posteriori (MAP)**  
La moda della distribuzione a posteriori √®:

$$
Mo(\theta | y = 17) = \frac{\alpha - 1}{\alpha + \beta - 2} = \frac{25 - 1}{25 + 15 - 2} = 0.6316.
$$

In R:

```{r}
# Calcolo della moda a posteriori
posterior_mode <- (alpha - 1) / (alpha + beta - 2)
posterior_mode
```

3. **Mediana a Posteriori**  
La mediana si ottiene utilizzando la funzione di distribuzione cumulativa inversa:

```{r}
# Calcolo della mediana a posteriori
posterior_median <- qbeta(0.5, alpha, beta)
posterior_median
```

**Intervallo di credibilit√†.**

1. **Intervallo di credibilit√† simmetrico.**

L'intervallo di credibilit√† simmetrico al 94% √® dato dai percentili 3% e 97%:

```{r}
# Intervallo di credibilit√† simmetrico al 94%
cred_interval <- qbeta(c(0.03, 0.97), alpha, beta)
cred_interval
```

Possiamo interpretare questo intervallo come segue: c'√® una certezza soggettiva del 94% che $\theta$ sia compreso tra 0.478 e 0.761.

**Verifica di ipotesi bayesiana.**

Infine, calcoliamo la probabilit√† che $\theta > 0.5$:

$$
P(\theta > 0.5 | y = 17) = \int_{0.5}^1 f(\theta | y = 17) d\theta.
$$

In R:

```{r}
# Probabilit√† P(theta > 0.5)
prob_theta_greater_0_5 <- pbeta(0.5, alpha, beta, lower.tail = FALSE)
prob_theta_greater_0_5
```

In conclusione, utilizzando un approccio bayesiano, abbiamo stimato la distribuzione a posteriori di $\theta$, ottenuto stime puntuali e costruito intervalli di credibilit√†. Abbiamo inoltre calcolato la probabilit√† che $\theta$ superi una soglia specifica, mostrando la flessibilit√† e l'interpretabilit√† delle analisi bayesiane.
:::

## Sintesi della distribuzione a posteriori: questioni multivariate

Quando si affronta un'analisi bayesiana con pi√π parametri, la complessit√† aumenta. Le principali difficolt√† riguardano le interazioni tra i parametri e il modo in cui queste influenzano le distribuzioni marginali. Questi fattori possono complicare notevolmente la sintesi della distribuzione a posteriori e, se non considerati attentamente, possono portare a interpretazioni errate.

### Correlazioni nascoste e distribuzioni marginali

Un problema comune nelle analisi con pi√π parametri √® rappresentato dalle *correlazioni tra i parametri*. Le distribuzioni marginali a posteriori, spesso riportate nei riassunti statistici, possono essere *molto fuorvianti* se considerate isolatamente. Quando i parametri sono fortemente correlati, le distribuzioni marginali possono apparire piatte o poco informative, inducendo a pensare che non ci sia molta informazione nella verosimiglianza.

Tuttavia, le correlazioni tra parametri possono restringere notevolmente lo spazio delle combinazioni plausibili, escludendo vaste aree dello spazio dei parametri. Questo significa che, nonostante le marginali possano sembrare non informative, l'analisi congiunta dei parametri pu√≤ rivelare una struttura sottostante che riduce l'incertezza su specifiche combinazioni. Pertanto, √® essenziale esaminare le correlazioni congiunte tra i parametri per ottenere una visione pi√π completa dell'incertezza.

Con un numero maggiore di parametri, anche i grafici di correlazione bidimensionali possono diventare limitati, poich√© potrebbero esistere correlazioni di ordine superiore che non emergono in rappresentazioni a due dimensioni.

### Correlazioni non lineari

Un'altra difficolt√† significativa riguarda le *correlazioni non lineari* tra i parametri. Quando queste correlazioni sono presenti, il massimo delle distribuzioni marginali non coincide necessariamente con il massimo della distribuzione congiunta. Per esempio, se due parametri presentano una correlazione complessa, come una forma a "banana", il massimo delle distribuzioni marginali potrebbe trovarsi in una posizione diversa rispetto al massimo globale della distribuzione congiunta.

Questo fenomeno rende pi√π difficile sintetizzare correttamente la distribuzione a posteriori. In tali casi, la stima del *massimo a posteriori (MAP)* o altri riassunti, come gli *intervalli di credibilit√† (CI)* o gli *intervalli di massima densit√† a posteriori (HPD)*, calcolati sulle marginali, potrebbero essere fuorvianti. Quando la distribuzione a posteriori √® asimmetrica nello spazio multivariato, le distribuzioni marginali non catturano adeguatamente le relazioni tra i parametri. Questa √® una fonte comune di confusione, poich√© si tende a sottovalutare l'importanza della struttura multivariata nella distribuzione a posteriori.

### Strategie per affrontare queste sfide

1. **Confronto tra distribuzioni predittive**:

   - Confrontare la distribuzione predittiva a priori con quella a posteriori offre una visione pi√π completa della riduzione dell'incertezza.
   - Questo approccio √® particolarmente utile in presenza di parametri multipli e correlazioni complesse, poich√© la distribuzione predittiva a posteriori incorpora le interazioni tra i parametri, fornendo una rappresentazione pi√π accurata della plausibilit√† dei diversi valori parametrici.

2. **Analisi congiunta**:

   - Esaminare le distribuzioni congiunte dei parametri, oltre alle distribuzioni marginali.
   - Utilizzare grafici di dispersione bivariati o multivariati per visualizzare le relazioni tra i parametri.
   - Tecniche avanzate di visualizzazione, come i *pair plots* o le *heatmap*, possono essere utili per esplorare relazioni in spazi ad alta dimensionalit√†.

3. **Misure di dipendenza**:

   - Utilizzare misure di dipendenza non lineare, come la *correlazione di Spearman* o l'*informazione mutua*, che possono catturare relazioni complesse che le misure lineari tradizionali potrebbero non rilevare.

4. **Analisi di sensibilit√†**:

   - Condurre un'analisi di sensibilit√† per valutare come i cambiamenti in un parametro influenzano gli altri parametri e le previsioni del modello. Questo permette di capire meglio le relazioni tra i parametri e il loro impatto sulle inferenze.

5. **Tecniche di riduzione della dimensionalit√†**:

   - Quando ci sono molti parametri, l'uso di metodi come l'*analisi delle componenti principali (PCA)* pu√≤ aiutare a identificare strutture latenti e ridurre la complessit√† del problema, facilitando l'interpretazione dei risultati.

In sintesi, l'analisi multivariata in un contesto bayesiano richiede particolare attenzione nella sintesi delle distribuzioni a posteriori. Le distribuzioni marginali possono fornire informazioni utili, ma spesso nascondono importanti correlazioni e strutture di dipendenza tra i parametri. Un'analisi completa dovrebbe combinare l'esame delle marginali con una valutazione attenta delle relazioni congiunte tra i parametri, utilizzando tecniche di visualizzazione e misure di dipendenza adeguate. Questo approccio integrato permette di comprendere pi√π a fondo la distribuzione a posteriori e di trarre inferenze pi√π robuste e accurate.


## Riflessioni conclusive {.unnumbered .unlisted}

In conclusione, la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri sconosciuti. L'impiego delle statistiche descrittive e l'analisi degli intervalli di credibilit√† contribuiscono a tracciare un quadro completo della distribuzione a posteriori e delle nostre inferenze riguardo al parametro di interesse.

Le stime puntuali, ottenute attraverso statistiche descrittive come media, mediana o moda a posteriori, offrono una singola valutazione numerica del parametro ignoto. Gli intervalli di credibilit√† forniscono un intervallo di valori all'interno del quale si ritiene, con un certo grado di probabilit√† soggettiva, che il parametro incognito possa rientrare. Questi intervalli quantificano l'incertezza associata al parametro e consentono di esprimere il livello di fiducia soggettiva riguardo ai possibili valori del parametro dopo l'analisi dei dati. Abbiamo inoltre esaminato il concetto di test di ipotesi bayesiano, il quale pu√≤ essere condotto agevolmente calcolando l'area appropriata sotto la distribuzione a posteriori, in accordo con l'ipotesi in questione.


## Esercizi {.unnumbered .unlisted}

::: {.callout-important title="Problemi" collapse="true"}
**1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?**

   - Spiega le differenze tra **moda (MAP)**, **media a posteriori** e **mediana**.
   - In quali contesti √® preferibile utilizzare una di queste statistiche rispetto alle altre?

**2. Qual √® la differenza tra un intervallo di credibilit√† bayesiano e un intervallo di confidenza frequentista?**

   - Spiega le differenze concettuali tra i due approcci.
   - Quale dei due √® pi√π intuitivo in termini di incertezza sui parametri?

**3. Cos‚Äô√® un intervallo di massima densit√† posteriore (HPD) e in cosa si differenzia dall‚Äôintervallo di credibilit√† simmetrico?**

   - Spiega il concetto di HPD e perch√© √® pi√π informativo in alcuni casi.
   - In quali situazioni l‚ÄôHPD √® preferibile rispetto all‚Äôintervallo di credibilit√† simmetrico?

**4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?**

   - Perch√© il **MAP** pu√≤ essere meno affidabile rispetto ad altre statistiche?
   - Quali problemi si possono incontrare nei modelli bayesiani complessi?

**5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di pi√π parametri incogniti?**

   - Quali sono le principali difficolt√† nell‚Äôinterpretare la distribuzione congiunta di pi√π parametri?
   - Come si possono visualizzare e sintetizzare distribuzioni posteriori multivariate?

**Domande applicative in R**

Per queste domande, usa il dataset basato sulla **Satisfaction with Life Scale (SWLS)**, supponendo che i dati seguano una distribuzione normale.

**1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa.**
   - Usa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.

**2. Costruisci un intervallo di credibilit√† simmetrico al 94% per la media SWLS.**

   - Usa la distribuzione normale a posteriori per calcolare l‚Äôintervallo.


**3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densit√†.**

   - Genera un campione dalla distribuzione a posteriori e rappresentalo con **ggplot2**.

**4. Confronta l‚Äôintervallo di credibilit√† simmetrico con l‚Äôintervallo di massima densit√† posteriore (HPD).**

   - Usa la funzione **hdi()** del pacchetto **bayestestR** per calcolare l‚ÄôHPD.


**5. Calcola la probabilit√† a posteriori che la media SWLS sia minore di 23.**

   - Usa la distribuzione a posteriori per calcolare questa probabilit√†.

:::

::: {.callout-tip title="Soluzioni" collapse="true"}
**1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?**


Le tre principali statistiche usate per ottenere una **stima puntuale** del parametro $\theta$ nella distribuzione a posteriori sono:

1. **Moda (Massimo a Posteriori, MAP)**  
   - √à il valore di $\theta$ che massimizza la distribuzione a posteriori $p(\theta \mid y)$.  
   - Se la distribuzione √® unimodale e simmetrica, il MAP coincide con la media a posteriori.  
   - Il MAP √® spesso simile alla stima di massima verosimiglianza (MLE) quando il prior √® uniforme.  

2. **Media a Posteriori**  
   - √à il valore atteso della distribuzione a posteriori:  
     $$
     E(\theta \mid y) = \int \theta \, p(\theta \mid y) \, d\theta
     $$
   - √à la stima pi√π utile quando si vuole minimizzare l'errore quadratico medio (MSE).  
   - Risente dell'eventuale asimmetria della distribuzione, spostandosi verso le code.

3. **Mediana a Posteriori**  
   - √à il valore che divide la distribuzione a posteriori in due parti uguali:  
     $$
     P(\theta \leq \theta_{\text{mediana}} \mid y) = 0.5
     $$
   - √à pi√π robusta agli outlier rispetto alla media ed √® utile quando la distribuzione √® fortemente asimmetrica.

üí° **Quando usarle?**
- Se la distribuzione √® **simmetrica**, tutte e tre le statistiche coincidono.
- Se la distribuzione √® **asimmetrica**, la **mediana** √® pi√π robusta, la **media** pu√≤ essere influenzata dalle code e il **MAP** √® utile se si vuole un valore pi√π probabile.

**2. Qual √® la differenza tra un intervallo di credibilit√† bayesiano e un intervallo di confidenza frequentista?**


| Caratteristica                 | Intervallo di Credibilit√† (Bayesiano) | Intervallo di Confidenza (Frequentista) |
|--------------------------------|--------------------------------------|----------------------------------------|
| **Significato** | Esprime la probabilit√† che il parametro sia nell'intervallo, dati i dati osservati. | √à una propriet√† di un metodo di campionamento: se si ripetesse l‚Äôesperimento infinite volte, il $(1 - \alpha)100\%$ degli intervalli conterrebbe il vero valore del parametro. |
| **Approccio** | Assume che il parametro sia una variabile casuale con una distribuzione di probabilit√†. | Assume che il parametro sia fisso e sconosciuto, mentre i dati sono casuali. |
| **Interpretazione** | "C'√® il 95% di probabilit√† che il parametro sia tra questi valori." | "Se ripetessimo l'esperimento molte volte, il 95% degli intervalli conterrebbe il vero parametro." |

üí° **Differenza fondamentale:**  

- L'intervallo di credibilit√† √® **probabilistico** e pi√π intuitivo: si pu√≤ direttamente dire che il parametro ha il 95% di probabilit√† di trovarsi nell'intervallo.  
- L'intervallo di confidenza √® **basato sulla ripetizione ipotetica** dell'esperimento e non pu√≤ essere interpretato in termini probabilistici sul singolo intervallo.

**3. Cos‚Äô√® un intervallo di massima densit√† posteriore (HPD) e in cosa si differenzia dall‚Äôintervallo di credibilit√† simmetrico?**
 
L‚Äô**intervallo di massima densit√† posteriore (HPD)** √® l‚Äôintervallo pi√π stretto che contiene una percentuale fissata (es. 94%) della distribuzione a posteriori. Si distingue dall'intervallo di credibilit√† simmetrico perch√©:

| Caratteristica | Intervallo HPD | Intervallo di Credibilit√† Simmetrico |
|--------------|-------------|--------------------------------|
| **Definizione** | Contiene il  $(1 - \alpha)100\%$ della probabilit√† a posteriori, minimizzando la lunghezza dell‚Äôintervallo. | √à centrato attorno alla mediana e copre una frazione fissa della distribuzione. |
| **Forma** | Pu√≤ essere asimmetrico e discontinuo se la distribuzione √® multimodale. | √à sempre simmetrico. |
| **Vantaggio** | √à pi√π informativo se la distribuzione √® asimmetrica o multimodale. | √à pi√π facile da calcolare, specialmente per distribuzioni unimodali. |

üí° **Quando usarli?**  

- Se la distribuzione √® **simmetrica**, entrambi gli intervalli danno risultati simili.  
- Se la distribuzione √® **asimmetrica o multimodale**, l‚ÄôHPD √® pi√π informativo.

**4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?**
 
Sebbene il **MAP** sia un concetto intuitivo (il valore pi√π probabile della distribuzione a posteriori), presenta alcune limitazioni:

1. **Difficolt√† computazionale con MCMC**  
   - Con metodi di campionamento come **Markov Chain Monte Carlo (MCMC)**, trovare il massimo della distribuzione a posteriori √® difficile perch√© la funzione viene stimata in modo discreto.
   - Spesso si preferisce stimare **media** o **mediana**, pi√π facili da calcolare con MCMC.

2. **Sensibilit√† ai dati e al prior**  
   - Il MAP dipende fortemente dal **prior** scelto.
   - Se il prior √® informativo, il MAP pu√≤ spostarsi troppo rispetto ai dati.

3. **Problemi con distribuzioni multimodali**  
   - Se la distribuzione a posteriori ha pi√π di un massimo (moda), il MAP potrebbe non essere una buona rappresentazione della distribuzione.

üí° **Quando evitarlo?**  
- Se la distribuzione a posteriori √® **asimmetrica o multimodale**.
- Se si usa un **metodo MCMC**, dove la media o la mediana sono pi√π semplici da stimare.

**5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di pi√π parametri incogniti?**
 
Quando l'inferenza bayesiana coinvolge pi√π parametri (es. $\mu$ e $\sigma$), l'analisi diventa pi√π complessa per diversi motivi:

1. **Interazioni tra parametri**  
   - I parametri spesso non sono indipendenti: la distribuzione a posteriori congiunta pu√≤ mostrare **correlazioni** che non emergono dalle distribuzioni marginali.

2. **Difficolt√† di visualizzazione**  
   - Per un parametro si usa un istogramma o una funzione di densit√†.
   - Per due parametri si usa un **contour plot** o un **grafico 3D**.
   - Con pi√π di due parametri, si ricorre a **pair plots** o **matrici di correlazione**.

3. **Stimare margine e congiunta**  
   - La distribuzione marginale di un parametro si ottiene integrando la distribuzione congiunta rispetto agli altri parametri:
     $$
     p(\theta_1) = \int p(\theta_1, \theta_2) d\theta_2
     $$
   - Se i parametri sono fortemente correlati, le marginali possono **nascondere informazioni importanti**.

4. **Rischio di correlazioni non lineari**  
   - Le correlazioni non lineari tra i parametri possono portare a distribuzioni con forme complesse (es. a banana), rendendo difficile la sintesi con MAP o media.

üí° **Strategie per affrontare il problema:**  
- **Visualizzare le correlazioni** tra i parametri con scatter plot o heatmap.  
- **Usare tecniche di riduzione della dimensionalit√†** come PCA (Analisi delle Componenti Principali).  
- **Utilizzare il MCMC** per campionare direttamente dalla distribuzione congiunta.

**Esercizio in R con i dati SWLS**

Nell'esercizio, usa i dati della SWLS che sono stati raccolti. Qui useremo i dati seguenti:

```r
swls_data <- data.frame(
  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)
)
```

**1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa.**

   - Usa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.

```r
library(tibble)

# Dati
n <- nrow(swls_data)
mean_x <- mean(swls_data$soddisfazione)
sigma <- 1  # Deviazione standard nota

# Prior diffuso
mu_prior <- 4.5    
sigma_prior <- 10  

# Media a posteriori
mu_post <- (sigma_prior^2 * mean_x + sigma^2 * n * mu_prior) / (sigma_prior^2 + sigma^2 * n)

# Deviazione standard a posteriori
sigma_post <- sqrt((sigma_prior^2 * sigma^2) / (sigma_prior^2 + sigma^2 * n))

# Moda (MAP)
posterior_mode <- mu_post  # Per una distribuzione normale, MAP coincide con la media

# Mediana (simile alla media in una distribuzione normale)
posterior_median <- mu_post

tibble("Media a Posteriori" = mu_post,
       "Moda (MAP)" = posterior_mode,
       "Mediana" = posterior_median)
```

**2. Costruisci un intervallo di credibilit√† simmetrico al 94% per la media SWLS.**

   - Usa la distribuzione normale a posteriori per calcolare l‚Äôintervallo.

```r
cred_interval <- qnorm(c(0.03, 0.97), mean = mu_post, sd = sigma_post)
cred_interval
```

**3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densit√†.**

   - Genera un campione dalla distribuzione a posteriori e rappresentalo con **ggplot2**.

```r
library(ggplot2)

# Campionamento dalla distribuzione a posteriori
set.seed(123)
samples <- rnorm(1000, mean = mu_post, sd = sigma_post)

# Creazione del dataframe
samples_df <- tibble(media_campionata = samples)

# Grafico della distribuzione a posteriori
ggplot(samples_df, aes(x = media_campionata)) +
  geom_density(fill = "blue", alpha = 0.5) +
  labs(title = "Distribuzione a Posteriori della Media SWLS",
       x = "Media", y = "Densit√†")
```

**4. Confronta l‚Äôintervallo di credibilit√† simmetrico con l‚Äôintervallo di massima densit√† posteriore (HPD).**

   - Usa la funzione **hdi()** del pacchetto **bayestestR** per calcolare l‚ÄôHPD.

```r
library(bayestestR)

# Calcolo intervallo HPD al 94%
hpd_interval <- hdi(samples, ci = 0.94)
hpd_interval
```

**5. Calcola la probabilit√† a posteriori che la media SWLS sia minore di 23 -- per fare un esempio, qui caloleremo per i dati simulati la probabilit√† a posteriori per la media SWLS maggiore di 4.7.**

   - Usa la distribuzione a posteriori per calcolare questa probabilit√†.

```r
prob_greater_4_7 <- 1 - pnorm(4.7, mean = mu_post, sd = sigma_post)
prob_greater_4_7
```
:::

## Informazioni sull'Ambiente di Sviluppo {.unnumbered .unlisted}

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered .unlisted}



