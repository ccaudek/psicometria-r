# Il modello di revisione degli obiettivi {#sec-dynamic-models-goal-updating}


Molti dei fenomeni studiati in psicologia non sono statici, ma si sviluppano e si trasformano nel tempo. L’apprendimento, l’adattamento agli errori, la regolazione degli obiettivi, l’emergere o la remissione di sintomi clinici sono tutti esempi di *processi dinamici*, in cui ciò che osserviamo in un dato momento è il risultato di una storia pregressa.

Eppure, la maggior parte degli strumenti statistici impiegati in psicologia tende a ignorare questa dimensione temporale. Confrontiamo medie, calcoliamo correlazioni o eseguiamo regressioni, spesso trattando le osservazioni come indipendenti tra loro. Questo approccio è utile per molte domande, ma inadeguato quando l’obiettivo è *comprendere l’evoluzione* di un comportamento o di uno stato psicologico.

Se vogliamo capire *come* le persone modificano i propri obiettivi, cambiano strategia, o si adattano nel tempo a esperienze positive e negative, abbiamo bisogno di un approccio che tenga conto della sequenza degli eventi. Serve un modello in grado di descrivere *le regole del cambiamento*.


## Perché abbiamo bisogno di modelli dinamici?

Un *modello dinamico* è una rappresentazione matematica che esplicita il modo in cui un sistema evolve nel tempo. La caratteristica distintiva di questi modelli è la presenza di *dipendenze temporali*: almeno una delle variabili dipende da valori passati, non solo da ciò che accade nel presente.

Questo è ciò che li differenzia dai modelli statici, dove ogni osservazione è trattata come indipendente dalle precedenti. Nei modelli dinamici, invece, esiste una *memoria* del passato, che influenza l’andamento futuro del processo.

Una classe importante di variabili in questo contesto è costituita dalle *variabili di stato* (in inglese: *state variables* o *stock variables*), che rappresentano il livello accumulato di una certa quantità nel tempo: un obiettivo personale, un livello di motivazione, una credenza, o un sintomo. Queste variabili si aggiornano a ogni passo temporale secondo una *regola di cambiamento*, definita in termini matematici.


### Come si costruisce un modello dinamico?

Formulare un modello dinamico significa tradurre in termini espliciti una teoria del cambiamento. I passaggi fondamentali sono:

1. **Identificare le variabili rilevanti**: quali sono gli elementi del sistema che vogliamo modellare?
2. **Stabilire le regole di aggiornamento**: come cambia ciascuna variabile nel tempo, in risposta a feedback o input esterni?
3. **Formalizzare il modello in equazioni**: trasformare le regole in una struttura matematica coerente.
4. **Valutare la validità del modello**: confrontare le sue previsioni con i dati osservati, usando metodi statistici appropriati.

Questo tipo di approccio è particolarmente utile in psicologia, dove spesso vogliamo spiegare *come* i comportamenti si modificano in seguito a un’esperienza, e non soltanto se due variabili sono associate.


## Un esempio concreto: il modello di revisione degli obiettivi

Per rendere più tangibile il concetto, consideriamo un caso molto studiato: la regolazione degli obiettivi in risposta al feedback.

Immaginiamo un esperimento in cui i partecipanti devono svolgere un compito ripetuto, come classificare correttamente coppie di immagini. Prima di ogni prova (trial), ciascun partecipante stabilisce un obiettivo soggettivo – ad esempio, essere più veloce o più preciso rispetto al tentativo precedente. Dopo ogni trial, riceve un feedback sulla performance ottenuta, che può portarlo a rivedere il proprio obiettivo per il tentativo successivo.

Questo processo – definizione dell’obiettivo, esecuzione, feedback, revisione dell’obiettivo – è iterativo e naturalmente dinamico. Un modello dinamico ben costruito può catturare con precisione questo ciclo di regolazione, permettendoci di stimare, ad esempio, quanto rapidamente una persona adatta le proprie aspirazioni in risposta al successo o al fallimento.

Nel resto del capitolo, vedremo come formalizzare questo tipo di processo e stimare i suoi parametri utilizzando un approccio bayesiano, con implementazione in Stan.


### Come formalizzare questo processo?

Una delle ipotesi più semplici – ma già molto utile – è che le persone modifichino i propri obiettivi in funzione della discrepanza tra ciò che hanno ottenuto (performance) e ciò che si erano prefissate (goal). Se la performance supera l’obiettivo, si tende ad alzare le aspettative; se è inferiore, si tende a ridurle.

Un modello dinamico lineare che cattura questa idea è stato proposto da @knight2023tutorial e si esprime con l’equazione:

$$
G_t = G_{t-1} + \alpha \cdot (P_{t-1} - G_{t-1}) + \beta
$$

dove:

* $G_t$ è il nuovo obiettivo fissato al trial $t$,
* $P_{t-1}$ è la performance osservata al trial precedente,
* $\alpha$ rappresenta la sensibilità alla discrepanza (quanto il goal viene aggiornato in risposta all’errore),
* $\beta$ rappresenta una spinta costante al cambiamento (es. una tendenza progressiva all’ambizione o una pressione esterna).

Questo modello è detto sample-level perché assume che tutti i partecipanti condividano gli stessi parametri $\alpha$ e $\beta$, stimati sull’intero campione.


### Illustrazione numerica del modello

Per chiarire il funzionamento del modello, consideriamo due scenari ipotetici.

**Caso 1:** Performance superiore all'obiettivo.

* Obiettivo precedente: $G_{t-1} = 50$ punti.
* Performance effettiva: $P_{t-1} = 60$ punti.
* Parametri: $\alpha = 0.5$ (apprendimento moderato), $\beta = 2$ (lieve tendenza all'aumento).

Calcolo:

$$
G_t = 50 + 0.5 \cdot (60 - 50) + 2 = 50 + 5 + 2 = \mathbf{57}.
$$

*Interpretazione:* il partecipante ha ottenuto più di quanto si aspettava. Di conseguenza, aumenta l’obiettivo, adattandosi alle proprie capacità.

**Caso 2:** Performance inferiore all'obiettivo.

* Obiettivo precedente: $G_{t-1} = 50$ punti.
* Performance effettiva: $P_{t-1} = 40$ punti.
* Parametri invariati: $\alpha = 0.5$, $\beta = 2$.

Calcolo:

$$
G_t = 50 + 0.5 \cdot (40 - 50) + 2 = 50 - 5 + 2 = \mathbf{47}.
$$

*Interpretazione:* nonostante la performance deludente, l’obiettivo non crolla del tutto. La spinta costante $\beta$ impedisce una regressione troppo marcata, riflettendo potenziali meccanismi di resilienza o auto-protezione motivazionale.


### Perché questo modello è importante?

Questo approccio modellistico è particolarmente rilevante nella ricerca psicologica, in quanto consente di tradurre processi cognitivi complessi in relazioni matematiche verificabili. La struttura dinamica proposta consente di indagare sistematicamente i meccanismi di regolazione degli obiettivi e offre diversi vantaggi sia dal punto di vista metodologico che da quello teorico.

In primo luogo, il modello consente di accertare se e in che misura gli individui modificano le proprie aspettative in risposta ai feedback ricevuti. Attraverso il parametro $\alpha$ è possibile quantificare con precisione la sensibilità individuale alle discrepanze tra le performance attese e quelle reali: valori più elevati indicano una maggiore prontezza nell'adeguare gli obiettivi.

Il parametro $\beta$ aggiunge un ulteriore livello di comprensione, rivelando eventuali tendenze sistemiche nella revisione degli obiettivi indipendenti dalla performance. Un valore costante e positivo di β potrebbe, ad esempio, riflettere una progressiva crescita dell'ambizione o l'effetto di fattori motivazionali esterni.

Oltre a descrivere il comportamento osservato, il modello si rivela prezioso anche per la sua capacità predittiva. Una volta stimati i parametri individuali, è possibile prevedere come un soggetto modificherà i propri obiettivi in risposta a specifici schemi di feedback, il che ha importanti implicazioni per la progettazione di interventi formativi o terapeutici.

Dal punto di vista teorico, consente di passare da affermazioni generiche (“le persone si adattano”) a *ipotesi formali* che possono essere confrontate con i dati.

Dal punto di vista applicativo, può essere utile in contesti educativi, clinici o lavorativi, per progettare interventi personalizzati volti a favorire un migliore adattamento agli errori o a incoraggiare una progressione realistica degli obiettivi.


## Estensioni del modello

Il modello sample-level fornisce un primo passo per descrivere il processo di aggiornamento degli obiettivi. Tuttavia, le sue assunzioni sono semplificative: tutti i partecipanti seguono *la stessa regola* con gli *stessi parametri*. In realtà, è probabile che le persone differiscano nel modo in cui regolano i propri obiettivi.

Per affrontare questa complessità, @knight2023tutorial propongono una serie di estensioni che aggiungono livelli di realismo e flessibilità.

* **Modello a livello individuale.** Si stima un valore distinto di $\alpha$ e $\beta$ per ogni partecipante:

  * permette di confrontare quanto i singoli siano più o meno sensibili al feedback,
  * offre una rappresentazione più fine delle differenze individuali.

* **Modello gerarchico (*multilevel*).** I parametri individuali $\alpha_i$, $\beta_i$ sono modellati come estratti da una distribuzione comune (es. una normale):

  * cattura sia la variabilità individuale sia la tendenza generale del gruppo,
  * offre stime più stabili, grazie alla *condivisione d'informazione* (*shrinkage*).

* **Modello per gruppi noti.** I parametri sono stimati separatamente per gruppi sperimentali distinti (es. "approach" vs. "avoidance"):

  * permette di verificare se diverse condizioni influenzano il modo in cui gli obiettivi vengono aggiornati.

* **Modello con gruppi latenti (mixture model).** Non si assumono gruppi a priori, ma il modello cerca *sottogruppi nascosti* che seguono dinamiche diverse:

  * utile per scoprire profili distinti di regolazione (es. adattatori rapidi vs. rigidi).

Queste estensioni non sono trattate nel presente capitolo, ma rappresentano evoluzioni naturali del modello base. Il lettore interessato può approfondirle nel capitoli successivi.

In sintesi: il modello sample-level è il punto di partenza. Le estensioni successive permettono di incorporare differenze individuali, confronti tra gruppi, e strutture latenti, mantenendo intatta la logica dinamica di base: gli obiettivi cambiano nel tempo in risposta all’esperienza.


## Stima dei parametri con Stan

Abbiamo visto che il modello dinamico proposto descrive come le persone aggiornano i propri obiettivi in funzione delle performance precedenti. Ma per trasformare questa idea in uno strumento utile per la ricerca empirica, dobbiamo *stimare* i parametri del modello – in particolare:

* $\alpha$: sensibilità alla discrepanza,
* $\beta$: tendenza sistematica al cambiamento,
* $\sigma$: variabilità residua non spiegata.

Per farlo, traduciamo l’equazione teorica in un *modello statistico* e utilizziamo un approccio bayesiano per stimare la distribuzione a posteriori dei parametri.

### Dal modello teorico al modello statistico

Partiamo dall’equazione di aggiornamento:

$$
G_t = G_{t-1} + \alpha (P_{t-1} - G_{t-1}) + \beta .
$$

Per renderla statistica, aggiungiamo un termine di errore, assumendo che l’obiettivo osservato sia *una realizzazione rumorosa* del valore previsto:

$$
\text{Goal osservato} \sim \mathcal{N}(G_t, \sigma) .
$$

In altre parole, assumiamo che il goal osservato sia distribuito normalmente attorno al valore previsto, con una certa variabilità $\sigma$.


### Perché usare l’inferenza bayesiana?

Il modello è *ricorsivo*: ogni valore dipende da quello precedente. Questo rende difficile (e spesso impossibile) stimare i parametri con metodi frequentisti standard. L’approccio bayesiano, invece, consente di trattare in modo naturale le dipendenze temporali e le incertezze nei parametri.

Per stimare i parametri utilizzeremo Stan, che permette di: specificare esplicitamente il modello, definire le distribuzioni a priori e ottenere le distribuzioni a posteriori mediante algoritmi MCMC (Markov Chain Monte Carlo).


### Come funziona Stan?

Il motore MCMC di Stan genera migliaia di valori plausibili per ogni parametro, integrando sia i dati osservati che le distribuzioni a priori. Questo processo produce una *distribuzione a posteriori* che ci consente di derivare medie e intervalli credibili, effettuare inferenze robuste sui parametri e generare nuove osservazioni attraverso posterior predictive checks per valutare l'adeguatezza del modello.


### Esempio: implementazione del modello in Stan

Il codice Stan presentato nel capitolo segue esattamente la struttura logica del modello teorico:

* i dati in input sono il numero dei trial, i goal osservati e le performance;
* i parametri da stimare sono $\alpha$, $\beta$ e $\sigma$;
* la regola di aggiornamento è implementata in un ciclo `for`, trial per trial;
* la distribuzione normale collega il goal previsto a quello osservato;
* un blocco aggiuntivo (`generated quantities`) consente di generare dati simulati a partire dai parametri stimati.

L’obiettivo non è solo stimare parametri, ma verificare se il modello è capace di riprodurre i dati osservati.


### Il codice Stan

Di seguito, riportiamo il modello completo implementato in Stan. Analizzeremo poi ciascuna parte.

```stan
// MODELLO PER L'AGGIORNAMENTO DEGLI OBIETTIVI BASATO SULLA PERFORMANCE PRECEDENTE

// ---------------------------
// BLOCCO DEI DATI: COSA FORNIAMO AL MODELLO
// ---------------------------
data {
  int Ntotal;                      // Numero totale di osservazioni (es. 600 trial)
  real trial[Ntotal];              // Numero del trial (es. 1, 2, 3, ..., 600)
  real observed_goal[Ntotal];      // Obiettivo desiderato osservato in ciascun trial
  real performance[Ntotal];        // Prestazione osservata in ciascun trial
}

// ---------------------------
// PARAMETRI DEL MODELLO: COSA VOGLIAMO STIMARE
// ---------------------------
parameters {
  real alpha;                      // Quanto il partecipante adatta il proprio obiettivo (apprendimento)
  real beta;                       // Tendenza generale a incrementare l’obiettivo (motivazione costante)
  real<lower=0> sigma;             // Variazione casuale attorno al goal previsto (rumore)
}

// ---------------------------
// MODELLO: COME SI SPIEGANO I DATI
// ---------------------------
model {
  real predicted_goal;             // Variabile temporanea per salvare la previsione del goal

  // --- PRIORS: aspettative iniziali sui parametri ---
  alpha ~ normal(0, 1);            // Alpha: in media 0, con incertezza (deviazione standard = 1)
  beta ~ normal(0, 1);             // Beta: idem
  sigma ~ normal(0, 1);            // Sigma: deviazione standard del rumore (deve essere positiva)

  // --- CICLO PER OGNI TRIAL ---
  for (i in 1:Ntotal) {

    // Caso speciale: primo trial → nessuna previsione, usiamo direttamente il dato osservato
    if (trial[i] == 1) {
      predicted_goal = observed_goal[i];
    }

    // Tutti i trial successivi → aggiornamento del goal basato sulla performance precedente
    if (trial[i] > 1) {
      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;
      // ↑ Questa è la "regola di apprendimento":
      // - Se la performance precedente è migliore del goal → l’obiettivo aumenta
      // - Se la performance è peggiore → l’obiettivo diminuisce
      // - Quanto cambia? Dipende da alpha (quanto il partecipante si adatta)
      // - A ogni passo si aggiunge anche un piccolo incremento costante (beta)
    }

    // Likelihood: assumiamo che il goal osservato sia vicino al goal previsto, con un po’ di rumore
    observed_goal[i] ~ normal(predicted_goal, sigma);
  }
}

// ---------------------------
// BLOCCO PER GENERARE PREVISIONI (non necessario, ma utile per valutare il modello)
// ---------------------------
generated quantities {
  real predicted_goal;              // Valore previsto dal modello
  real sampled_goal[Ntotal];        // Goal "simulati", generati dal modello

  for (i in 1:Ntotal) {
    if (trial[i] == 1) {
      predicted_goal = observed_goal[i];
    }
    if (trial[i] > 1) {
      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;
    }

    // Simuliamo un nuovo goal come se fosse stato osservato, aggiungendo variabilità
    sampled_goal[i] = normal_rng(predicted_goal, sigma);
  }
}
```


### Il problema che vogliamo risolvere

Ora, poniamoci il problema di capire la logica del modello. Per farci un'idea di come funziona il modello, consideriamo il seguente esempio. Immaginiamo di essere in palestra e di voler capire come una persona decide il peso da sollevare nella prossima serie di esercizi. Osserviamo che:

- trial 1: si prefigge di sollevare 50 kg, riesce a sollevarne 52 kg;
- trial 2: si prefigge di sollevare 55 kg, ma riesce a sollevarne solo 53;
- trial 3: si prefigge di sollevare 54 kg e riesce a sollevarne 56.

Ci chiediamo se esista un modello logico nel modo in cui questa persona aggiorna i propri obiettivi.

Il modello Stan cerca di rispondere a questa domanda, identificando le "regole mentali" che guidano l'aggiornamento degli obiettivi.


### La logica del modello: tre ingredienti fondamentali

Il nostro modello si basa su un'idea semplice: quando una persona decide il suo prossimo obiettivo, considera:

1. Alpha ($\alpha$): il tasso di apprendimento. "Quanto mi faccio influenzare dalla mia performance precedente?"

  - *$\alpha$ positivo e alto:* "se ho fatto meglio del previsto, alzo molto l'obiettivo";
  - *$\alpha$ positivo e basso:* "anche se ho fatto bene, non cambio molto l'obiettivo";
  - *$\alpha$ vicino a 0:* "ignoro completamente la performance passata".

2. Beta ($\beta$): la tendenza costante. "Indipendentemente da come è andata, tendo sempre ad alzare/abbassare l'obiettivo?"

  - *$\beta$ negativo:* pessimismo - "ogni volta punto un po' più in basso";
  - *$\beta$ positivo:* ottimismo cronico - "ogni volta punto un po' più in alto".
  - *$\beta$ negativo:* pessimismo, "ogni volta punto un po' più in basso";
  - *$\beta$ vicino a zero:* nessuna tendenza sistematica.

3. Sigma ($\sigma$): il rumore.  "Quanto sono imprevedibile nelle mie decisioni?"

  - *$\sigma$ basso:* decisioni molto coerenti e prevedibili;
  - *$\sigma$ alto:* decisioni più casuali e difficili da prevedere.


### La formula 

Ad ogni trial (eccetto il primo), l'obiettivo viene aggiornato così:

```
Nuovo Obiettivo = Vecchio Obiettivo + 
                  alpha × (Performance Precedente - Vecchio Obiettivo) + 
                  beta + 
                  Un Po' di Casualità
```

Esempio pratico. Supponiamo che $\alpha$ valga 0.6 e che $\beta$ valga 2. Nel trial precedente, l'obiettivo era di 50 kg e la performance ottenuta era di 55 kg.

**Calcolo del nuovo obiettivo:**

```
Nuovo Obiettivo = 50 + 0.6 × (55 - 50) + 2
                = 50 + 0.6 × 5 + 2  
                = 50 + 3 + 2
                = 55 kg
```

La persona ha superato l'obiettivo di 5 kg, quindi lo aumenta del 60% di questa differenza (3 kg) più la sua tendenza ottimistica (+2 kg).


### La Struttura del Codice Stan: Quattro Blocchi Logici

#### Blocco 1: DATA - "Cosa Sappiamo"

```stan
data {
  int Ntotal;                    // Quanti trial abbiamo osservato?
  real trial[Ntotal];            // Quale numero di trial è ciascuna osservazione?
  real observed_goal[Ntotal];    // Quali obiettivi ha dichiarato?
  real performance[Ntotal];      // Quali performance ha ottenuto?
}
```

**In parole semplici**: "Ecco i dati che abbiamo raccolto dall'esperimento."

#### Blocco 2: PARAMETERS - "Cosa Vogliamo Scoprire"

```stan
parameters {
  real alpha;                    // Il tasso di apprendimento
  real beta;                     // La tendenza costante
  real<lower=0> sigma;           // Quanto rumore c'è nei dati
}
```

**In parole semplici**: "Questi sono i valori ignoti che vogliamo stimare dai dati."


#### Blocco 3: MODEL - "Come Funziona il Cervello"

Questo è il cuore del modello. Qui diciamo a Stan: "Ecco come pensiamo che funzioni il processo mentale."

##### Passo 1: Le Nostre Aspettative Iniziali (Prior).

```stan
alpha ~ normal(0, 1);
beta ~ normal(0, 1);  
sigma ~ normal(0, 1);
```

**Traduzione**: "Prima di vedere i dati, pensiamo che $\alpha$ e $\beta$ siano attorno allo zero, ma non ne siamo sicuri."

##### Passo 2: Il Processo Trial-per-Trial.

```stan
for (i in 1:Ntotal) {
    if (trial[i] == 1) {
        // Primo trial: non abbiamo performance precedenti
        predicted_goal = observed_goal[i];
    } else {
        // Trial successivi: applichiamo la formula
        predicted_goal += alpha * (performance[i-1] - predicted_goal) + beta;
    }
    
    // Confrontiamo la previsione con quello che abbiamo osservato
    observed_goal[i] ~ normal(predicted_goal, sigma);
}
```

**Spiegazione del ciclo FOR**:

Immaginate di avere 10 trial. Il ciclo dice: "Ora analizziamo il trial 1, poi il trial 2, poi il trial 3, e così via fino al trial 10".

Per ogni trial:

1. Se si tratta del primo trial: non possiamo fare previsioni (non abbiamo performance precedenti), quindi prendiamo l'obiettivo osservato così com'è.
2. Se si tratta di un trial successivo, applichiamo la nostra formula per prevedere quale dovrebbe essere l'obiettivo.
3. Confronto: vediamo quanto la nostra previsione si avvicina a quanto dichiarato dalla persona.


#### Blocco 4: GENERATED QUANTITIES - "Simuliamo Nuovi Dati"

```stan
generated quantities {
    // Qui generiamo dati "finti" usando i parametri che abbiamo stimato
    real sampled_goal[Ntotal];
    
    // Stesso processo del blocco MODEL, ma generiamo nuovi dati
    for (i in 1:Ntotal) {
        // ... stessa logica di sopra ...
        sampled_goal[i] = normal_rng(predicted_goal, sigma);
    }
}
```

**A cosa serve?**

1. Controllo di qualità: i dati simulati assomigliano a quelli reali? Se sì, il modello è credibile.
2. Previsioni future: come si comporterebbe una nuova persona con le stesse caratteristiche?


### Il Processo di Stima: Come Stan Trova i Parametri

Stan non trova un singolo valore per $\alpha$, $\beta$ e $\sigma$. Invece, trova una distribuzione di valori possibili per ciascun parametro.

Esempio di risultati.

```
alpha: media = 0.7, intervallo credibile = [0.5, 0.9]
beta: media = 1.2, intervallo credibile = [0.8, 1.6]  
siagma: media = 3.1, intervallo credibile = [2.7, 3.5]
```

*Interpretazione*:

- questa persona si adatta abbastanza bene alle performance passate ($\alpha$ = 0.7);
- ha una leggera tendenza ottimistica ($\beta$ = 1.2);
- le sue decisioni presentano una moderata variabilità  ($\sigma$ = 3.1).


### Vantaggi di questo approccio

1. Interpretabilità: ogni parametro ha un significato psicologico chiaro;
2. Flessibilità: il modello si adatta a diversi pattern di comportamento.
3. Incertezza quantificata: non diciamo "$\alpha$ = 0.7", ma "$\alpha$ è probabilmente tra 0.5 e 0.9".
4. Predizioni testabili: possiamo generare nuovi dati e verificare se sono simili a quelli reali.


## Riassunto finale

| **Elemento**           | **Significato**                                                                                                             |
| ---------------------- | --------------------------------------------------------------------------------------------------------------------------- |
| $\alpha$               | Sensibilità all’errore: quanto il partecipante modifica l’obiettivo in base alla discrepanza tra performance e aspettativa. |
| $\beta$                | Spinta costante al cambiamento: riflette una tendenza sistematica (es. ambizione crescente).                                |
| $\sigma$               | Rumore residuo: variabilità non spiegata dal modello.                                                                       |
| `sampled_goal`         | Goal simulati dal modello, usati per verificare la bontà delle previsioni.                                                  |
| `generated quantities` | Blocchi che permettono di generare dati sintetici secondo le regole del modello. 

In sintesi, questo modello ci permette di "aprire la scatola nera" del processo decisionale umano, trasformando osservazioni comportamentali in parametri psicologici interpretabili. È un esempio di come la modellazione statistica possa illuminare i meccanismi cognitivi sottostanti al comportamento umano.


### Risultati finali dell'analisi

Al termine della modellazione in Stan, otteniamo tre componenti fondamentali per l'interpretazione.

* Le distribuzioni posteriori dei parametri ($\alpha$, $\beta$ e $\sigma$) rappresentano l'insieme completo dei valori plausibili per ciascun parametro, ottenuti integrando le informazioni ricavate dai dati osservati con le nostre conoscenze a priori. Queste distribuzioni ci permettono di quantificare l'incertezza delle nostre stime.

* Gli indicatori di qualità della stima, come l'R-hat (che valuta la convergenza delle catene MCMC) e l'`n_eff` (che misura l'efficienza del campionamento), forniscono importanti metriche diagnostiche per valutare l'affidabilità dei risultati. Un `R-hat` vicino a 1 e un `n_eff` sufficientemente alto indicano stime robuste.

* Infine, tramite il blocco "generated quantities", otteniamo dati simulati che ci permettono di verificare la capacità predittiva del modello. Queste simulazioni, insieme ai valori di sampled_goal, sono fondamentali per verificare se il modello è in grado di riprodurre pattern simili a quelli osservati nei dati reali, fornendo una validazione aggiuntiva della sua adeguatezza.


### Interpretazione e utilità dei risultati  

Le distribuzioni a posteriori forniscono risposte concrete alle nostre domande di ricerca. Esaminando i valori stimati di $\alpha$ possiamo valutare quanto i partecipanti si adattino alle performance precedenti, mentre l'analisi di $\beta$ rivela eventuali tendenze sistematiche ad aumentare o diminuire l'ambizione. Il parametro $\sigma$, d'altra parte, ci informa sul grado di variabilità nel processo di aggiornamento degli obiettivi.  

Attraverso i dati simulati possiamo condurre posterior predictive checks, un potente strumento diagnostico che confronta i dati generati dal modello con quelli effettivamente osservati, permettendoci di valutare la bontà e la plausibilità del nostro modello.


### Limitazioni e Sviluppi Futuri  

L'attuale implementazione presenta alcune semplificazioni: assume che i parametri $\alpha$, $\beta$ e $\sigma$ rimangano costanti nel tempo, non tiene conto di possibili differenze individuali e adotta una struttura puramente lineare, che potrebbe risultare troppo rigida per catturare relazioni complesse.  

Per aumentare la flessibilità del modello, sarebbe possibile introdurre una struttura gerarchica che contempli parametri specifici per ciascun individuo, consentire una variazione temporale dei parametri o incorporare termini non lineari per descrivere in modo più accurato la relazione tra performance e definizione degli obiettivi.


## Riflessioni Conclusive

Questo esempio mostra come i concetti psicologici complessi, come la regolazione degli obiettivi, possano essere formalizzati tramite modelli dinamici che rappresentano l’evoluzione temporale dei processi cognitivi. L’approccio adottato integra tre elementi essenziali: la formalizzazione teorica tramite equazioni, l’implementazione computazionale in Stan e l’inferenza bayesiana per stimare e valutare il modello in relazione ai dati.

Rispetto ai modelli statici, questa prospettiva consente non solo di verificare se un comportamento cambia, ma anche come, quando e in risposta a quali condizioni. Pur nella sua semplicità, il modello presentato illustra il potenziale di una psicologia formale e meccanicistica orientata all'identificazione dei processi generativi sottostanti i dati osservati.

Come sottolineato da @knight2023tutorial, questo paradigma si articola in tre fasi cruciali. In primo luogo, la costruzione di un modello generativo che specifichi esplicitamente i meccanismi ipotizzati. In secondo luogo, le ipotesi vengono tradotte in codice eseguibile, solitamente utilizzando linguaggi formali come Stan. Terzo, la valutazione della bontà del modello non solo mediante indicatori statistici, ma anche attraverso un confronto sistematico tra i dati osservati e quelli simulati.

Anche un modello apparentemente semplice, come quello presentato in questo articolo, può rivelarsi utile se soddisfa tre requisiti fondamentali: (1) poggia su basi teoriche esplicite e plausibili, (2) genera previsioni empiricamente verificabili e (3) può essere esteso per indagare nuove questioni di ricerca.

Il modello *sample-level* rappresenta infatti un punto di partenza che può essere arricchito in diverse direzioni: introducendo parametri individuali per catturare le differenze tra i soggetti, incorporando strutture gerarchiche per conciliare i diversi livelli di analisi o implementando modelli a gruppi latenti per identificare pattern non immediatamente evidenti nei dati.

Dal punto di vista didattico, questo esempio mostra come le teorie psicologiche possano essere tradotte in equazioni formali che possono essere simulate, testate e validate empiricamente. Questo approccio trasforma le ipotesi teoriche in affermazioni quantitative verificabili, superando l'analisi delle sole associazioni per abbracciare l'analisi dei processi.

In definitiva, la costruzione di modelli dinamici rappresenta un passo avanti verso una psicologia più rigorosa, che mira a spiegare i fenomeni anziché limitarsi a descriverli, contribuendo così allo sviluppo cumulativo della disciplina. Questo approccio spinge i ricercatori a considerare i meccanismi e i processi sottostanti, gettando le basi per una scienza psicologica più matura e predittiva.


## Bibliografia {.unnumbered}

