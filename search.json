[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psicometria",
    "section": "",
    "text": "Benvenuti\nBenvenuti nel sito web dell’insegnamento di Psicometria, parte del Corso di Laurea in Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#descrizione",
    "href": "index.html#descrizione",
    "title": "Psicometria",
    "section": "Descrizione",
    "text": "Descrizione\nIl corso offre una formazione teorico-pratica nell’analisi dei dati psicologici, con particolare attenzione alle applicazioni in R. Vengono affrontati temi come analisi descrittiva, esplorazione dei dati, flusso di lavoro, organizzazione di progetti e modelli statistici di base, sia bayesiani che frequentisti. Grande enfasi è posta sulle buone pratiche di Open Science, promuovendo trasparenza e riproducibilità nelle analisi.\n\nAnno Accademico: 2024-2025\nCodice Insegnamento: B000286\nOrario e Luogo: Lunedì e Martedì (8:30-10:30), Giovedì (11:30-13:30), Plesso didattico La Torretta.\n\n\n\n\n\n\n\nQuesto sito web ospita la dispensa ufficiale dell’insegnamento B000286 - Psicometria (L-Z), che include tutte le note e i materiali relativi alle lezioni.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#struttura-dellinsegnamento",
    "href": "index.html#struttura-dellinsegnamento",
    "title": "Psicometria",
    "section": "Struttura dell’Insegnamento",
    "text": "Struttura dell’Insegnamento\nIl corso è strutturato per fornire una solida base teorica e pratica nell’analisi dei dati psicologici, combinando approcci metodologici, applicazioni pratiche ed esercitazioni mirate.\n\nIntroduzione a R: Approccio pratico all’utilizzo di R per l’analisi dei dati, con enfasi sulla scrittura di script replicabili e sulla creazione di workflow efficienti.\n\nGestione di Progetti di Analisi: Strategie per organizzare, documentare e comunicare progetti di data analysis, seguendo le buone pratiche della Open Science e della ricerca trasparente.\n\nStatistica Descrittiva: Esplorazione dei dati attraverso misure descrittive, distribuzioni statistiche e visualizzazioni grafiche.\n\nFondamenti di Probabilità: Introduzione ai concetti di probabilità, distribuzioni e incertezza, come base essenziale per l’inferenza statistica.\n\nInferenza Frequentista e Bayesiana: Panoramica sui due principali approcci all’inferenza statistica, con esempi pratici e confronto tra i metodi.\n\nVisualizzazione e Comunicazione: Tecniche avanzate per rappresentare risultati statistici in modo chiaro, efficace e persuasivo, includendo la creazione di report e grafici professionali.\n\nIl corso integra questi argomenti in un percorso didattico coerente, che combina lezioni teoriche, esercitazioni pratiche e momenti di riflessione critica. Gli studenti saranno così preparati ad applicare l’analisi dei dati sia in contesti accademici che pratici.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Psicometria",
    "section": "Syllabus",
    "text": "Syllabus\nConsulta il syllabus completo per ulteriori dettagli.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "prefazione.html",
    "href": "prefazione.html",
    "title": "Prefazione",
    "section": "",
    "text": "Bibliografia\nCome possiamo migliorare l’analisi dei dati psicologici per renderla più affidabile e robusta? È possibile affrontare questa sfida semplicemente applicando una serie di algoritmi o procedure standard? L’analisi dei dati in psicologia può davvero essere ridotta a un insieme di “ricette” preconfezionate (McElreath, 2020)?\nQueste domande ci portano a riflettere sulla natura stessa dell’analisi dei dati psicologici. A differenza di ciò che suggerisce l’approccio frequentista del test dell’ipotesi nulla, l’analisi dei dati non è una disciplina che si esaurisce con l’applicazione meccanica di metodi predefiniti. Anzi, considerare l’analisi dei dati come un insieme di procedure automatiche contribuisce a uno dei problemi più gravi della psicologia contemporanea: la crisi della replicabilità dei risultati (Korbmacher et al., 2023).\nMa perché la replicabilità è così cruciale? Se i risultati delle ricerche psicologiche non sono replicabili, significa che la nostra comprensione dei fenomeni psicologici è superficiale e inaffidabile. Questo non è solo un problema teorico o accademico; ha implicazioni dirette sulle applicazioni pratiche della psicologia. Se le basi scientifiche sono incerte, anche le strategie di intervento psicologico rischiano di essere inefficaci o addirittura dannose (Funder et al., 2014; Ioannidis, 2019; Shrout & Rodgers, 2018; Tackett et al., 2019).\nPerché le pratiche di analisi dei dati derivanti dal frequentismo potrebbero contribuire a questa crisi? In che modo gli incentivi accademici influenzano la qualità della ricerca psicologica? E, soprattutto, quali alternative abbiamo per migliorare l’affidabilità e la validità delle nostre conclusioni?\nL’analisi bayesiana emerge come una delle proposte per superare i limiti dell’approccio frequentista (Gelman et al., 1995). Tuttavia, è sufficiente abbandonare l’inferenza frequentista per risolvere i problemi della psicologia? Come possiamo integrare metodi robusti e flessibili, come quelli bayesiani, con una comprensione più approfondita e trasparente dei fenomeni psicologici?\nIn questo corso, esploreremo queste domande, cercando di identificare le “buone pratiche” dell’analisi dei dati psicologici. Discuteremo i limiti delle metodologie attuali, esamineremo le cause sottostanti della crisi della replicabilità e valuteremo come l’adozione di metodi avanzati, come l’inferenza bayesiana e la modellazione causale, possa offrire soluzioni efficaci (Oberauer & Lewandowsky, 2019; Wagenmakers et al., 2018; Yarkoni, 2022). Il nostro obiettivo è fornire una visione critica e costruttiva, che non solo identifichi le sfide della ricerca psicologica, ma proponga anche percorsi concreti per migliorare la qualità e l’affidabilità della scienza psicologica.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "prefazione.html#bibliografia",
    "href": "prefazione.html#bibliografia",
    "title": "Prefazione",
    "section": "",
    "text": "Funder, D. C., Levine, J. M., Mackie, D. M., Morf, C. C., Sansone, C., Vazire, S., & West, S. G. (2014). Improving the dependability of research in personality and social psychology: Recommendations for research and educational practice. Personality and Social Psychology Review, 18(1), 3–12.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nIoannidis, J. P. (2019). What have we (not) learnt from millions of scientific papers with P values? The American Statistician, 73(sup1), 20–25.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nShrout, P. E., & Rodgers, J. L. (2018). Psychology, science, and knowledge construction: Broadening perspectives from the replication crisis. Annual Review of Psychology, 69(1), 487–510.\n\n\nTackett, J. L., Brandes, C. M., King, K. M., & Markon, K. E. (2019). Psychology’s replication crisis and clinical psychological science. Annual Review of Clinical Psychology, 15(1), 579–604.\n\n\nWagenmakers, E.-J., Marsman, M., Jamil, T., Ly, A., Verhagen, J., Love, J., Selker, R., Gronau, Q. F., Šmı́ra, M., Epskamp, S., et al. (2018). Bayesian inference for psychology. Part I: Theoretical advantages and practical ramifications. Psychonomic Bulletin & Review, 25, 35–57.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "programmazione2024.html",
    "href": "programmazione2024.html",
    "title": "Programma didattico e dettaglio del corso",
    "section": "",
    "text": "Calendario delle Relazioni in Itinere\nIl corso comprende un totale di 32 incontri, pianificati per affrontare tutti gli argomenti del programma. Tre incontri in presenza saranno riservati agli esami parziali dedicati agli studenti frequentanti.\nLe relazioni di avanzamento del progetto per il Tirocinio Pratico Valutativo (TPV) PSIC-01/C – Psicometria dovranno essere consegnate rispettando le scadenze previste. Ogni gruppo TPV è tenuto a presentare un unico elaborato, risultato del lavoro collaborativo tra i membri del gruppo.\nCalendario delle Relazioni in Itinere\n\n\n\n\n\nData di Scadenza\nContenuto della Relazione\n\n\n\n24 marzo\nRelazione 1: Importazione dei dati, data wrangling, data tidying, dizionario dei dati, statistiche descrittive\n\n\n28 aprile\nRelazione 2: Priori coniugati e metodo basato su griglia\n\n\n5 maggio\nRelazione 3: Regressione lineare, inferenza bayesiana su una media\nOgni relazione costituisce una fase cruciale nello sviluppo del progetto del TPV e fornisce le basi per la presentazione finale, che si terrà durante l’esame conclusivo del TPV.",
    "crumbs": [
      "Calendario",
      "Programma didattico e dettaglio del corso"
    ]
  },
  {
    "objectID": "chapters/key_notions/introduction_key_notions.html",
    "href": "chapters/key_notions/introduction_key_notions.html",
    "title": "Fondamenti",
    "section": "",
    "text": "La data science è un campo che si sviluppa all’intersezione tra la statistica e l’informatica. La statistica fornisce una serie di metodologie per analizzare i dati e ottenere informazioni significative, mentre l’informatica si occupa dello sviluppo di software e strumenti per implementare tali metodologie. In questa sezione della dispensa, approfondiremo alcuni concetti fondamentali della statistica e della misurazione psicologica. Considereremo anche in termini generali quali sono gli obiettivi e i limiti dell’analisi dei dati psicologici.",
    "crumbs": [
      "Fondamenti"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html",
    "href": "chapters/key_notions/02_key_notions.html",
    "title": "1  Concetti chiave",
    "section": "",
    "text": "1.1 Introduzione\nNella ricerca scientifica, la formulazione di risposte a specifiche domande di indagine avviene attraverso l’applicazione di metodologie rigorose e l’esecuzione di osservazioni accurate e controllate. Le informazioni raccolte mediante diverse tecniche di indagine—come ricerche sul campo, indagini campionarie e protocolli sperimentali—vengono definite con il termine tecnico di dati. Questo capitolo introduce i principi fondamentali dell’analisi dei dati, concentrandosi sia sulle caratteristiche dei dati stessi sia sui metodi di raccolta.\nL’analisi dei dati permette di sintetizzare grandi quantità di informazioni e di verificare le previsioni avanzate dalle teorie. Tuttavia, senza una teoria che dia significato ai dati, le osservazioni rimangono mere descrizioni prive di un contesto esplicativo. È attraverso l’integrazione tra dati e teoria che si raggiunge una comprensione profonda dei fenomeni e si favorisce l’avanzamento scientifico.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#introduzione",
    "href": "chapters/key_notions/02_key_notions.html#introduzione",
    "title": "1  Concetti chiave",
    "section": "",
    "text": "Statistica\n\n\n\nIl termine “statistica” può assumere diversi significati a seconda del contesto:\n\nPrimo significato: La statistica è una scienza che si occupa dello studio e dell’applicazione di metodi per la raccolta, organizzazione, analisi, interpretazione e presentazione dei dati.\nSecondo significato: Il termine si riferisce a una misura o valore numerico calcolato a partire da un campione di dati, come la media campionaria, la deviazione standard campionaria o il coefficiente di correlazione campionario.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#la-spiegazione-scientifica",
    "href": "chapters/key_notions/02_key_notions.html#la-spiegazione-scientifica",
    "title": "1  Concetti chiave",
    "section": "1.2 La Spiegazione Scientifica",
    "text": "1.2 La Spiegazione Scientifica\nLa scienza non si limita a descrivere o prevedere i fenomeni: il suo obiettivo principale è spiegare il perché degli eventi, offrendo una comprensione approfondita delle cause e dei meccanismi che li regolano. La spiegazione scientifica è cruciale per costruire teorie capaci non solo di descrivere e prevedere, ma anche di chiarire le dinamiche causali e le connessioni tra i fenomeni, contribuendo a un controllo più consapevole e informato su di essi.\nConsideriamo, ad esempio, il rapporto tra il background familiare e il rendimento scolastico. Numerose ricerche evidenziano una forte correlazione tra il livello di istruzione dei genitori e il successo accademico dei figli. Una prospettiva puramente descrittiva potrebbe limitarsi a constatare che: “Gli studenti provenienti da famiglie con basso livello di istruzione hanno minori probabilità di conseguire un titolo universitario”. Tuttavia, la vera sfida scientifica consiste nell’andare oltre questa previsione, ponendosi domande più profonde:\n\nQuali meccanismi causali determinano questa disparità?\n\nQuali interventi possono efficacemente ridurre tali disuguaglianze?\n\nPer superare il livello di semplice previsione, la ricerca deve identificare i fattori causali alla base del fenomeno, esplorare come l’azione su questi fattori possa modificare gli esiti e valutare le incertezze e le dinamiche temporali degli interventi.\nNel caso dell’esempio sul rapporto tra background familiare e rendimento scolastico, ciò implica comprendere, ad esempio:\n\nse e in che modo il sostegno finanziario possa favorire il percorso degli studenti svantaggiati;\nquali politiche educative possano produrre effetti positivi sul lungo termine;\ncome i meccanismi sociali e individuali influenzino il processo educativo.\n\nAcquisire una conoscenza approfondita dei meccanismi causali permette di andare oltre la semplice previsione, rendendo possibile la progettazione di interventi mirati e strategici che possano realmente incidere sui fenomeni in modo efficace e duraturo.\n\n1.2.1 Elementi Fondamentali della Spiegazione Scientifica\nLa filosofia della scienza riconosce tre componenti fondamentali che definiscono una spiegazione scientifica:\n\nExplanandum: il fenomeno da spiegare, ossia ciò di cui cerchiamo di comprendere le ragioni o i meccanismi sottostanti. Un esempio potrebbe essere: “Gli studenti con livelli elevati di ansia da prestazione ottengono punteggi inferiori nei test scolastici rispetto ai loro coetanei.”\nExplanans: l’insieme di fattori in grado di fornire la spiegazione del fenomeno. Nel caso dell’ansia da prestazione, l’explanans potrebbe essere: “L’ansia compromette la capacità di concentrazione e la memoria di lavoro, influenzando negativamente la prestazione nei test.”\nLegame esplicativo: i principi o i meccanismi che mostrano come l’explanans produca l’explanandum. Proseguendo con l’esempio precedente, il legame esplicativo potrebbe essere: “Elevati livelli di ansia attivano il sistema nervoso simpatico, aumentando lo stress fisiologico e riducendo l’efficienza dei processi cognitivi necessari per svolgere compiti complessi.”\n\nQuesti tre elementi si integrano all’interno di modelli scientifici, che costituiscono strumenti metodologici per formulare e verificare spiegazioni. In psicologia, i modelli scientifici mirano a includere il fenomeno da spiegare (es. prestazioni scolastiche), i fattori causali che lo influenzano (es. ansia, regolazione emotiva) e i meccanismi sottostanti che collegano cause ed effetti (es. attivazione fisiologica, memoria di lavoro compromessa).\nPer illustrare, un modello psicologico sull’ansia da prestazione potrebbe considerare variabili come il livello di ansia percepita, la capacità di regolazione emotiva e la loro relazione con la memoria di lavoro. A differenza di modelli puramente descrittivi o predittivi, modelli esplicativi di questo tipo rispondono a domande causali: non si limitano a registrare la correlazione tra ansia e prestazioni, ma spiegano come e perché l’ansia comprometta il rendimento. Inoltre, forniscono indicazioni su come intervenire per ridurre l’impatto dell’ansia (ad esempio, potenziando la regolazione emotiva o lavorando su tecniche di gestione dello stress).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#modelli-psicologici",
    "href": "chapters/key_notions/02_key_notions.html#modelli-psicologici",
    "title": "1  Concetti chiave",
    "section": "1.3 Modelli Psicologici",
    "text": "1.3 Modelli Psicologici\nUn modello è una rappresentazione concettuale e matematica semplificata di un fenomeno reale, fondata su un insieme di equazioni e ipotesi che descrivono le relazioni tra variabili e la struttura probabilistica del fenomeno. Lo scopo è coglierne gli aspetti essenziali senza includere ogni dettaglio, e formulare predizioni quantitative testabili. Poiché spesso esistono più modelli possibili per uno stesso problema, il compito della ricerca è scegliere quello che meglio descrive i dati e che soddisfa criteri di validità, accuratezza e parsimonia.\nI modelli psicologici, in particolare, sono strumenti teorici finalizzati a descrivere, spiegare e prevedere il comportamento umano e i processi mentali. Un modello ben costruito dovrebbe possedere le seguenti caratteristiche fondamentali:\n\nCoerenza descrittiva\nIl modello deve rappresentare il fenomeno in modo logico e coerente, catturando gli elementi chiave del processo psicologico e organizzando le osservazioni in una struttura comprensibile.\nCapacità predittiva\nDeve essere in grado di formulare previsioni verificabili sull’evoluzione del fenomeno, consentendo di testare la validità delle ipotesi attraverso la raccolta e l’analisi dei dati.\nSupporto empirico\nLe ipotesi e le previsioni del modello devono essere confermate dai dati ottenuti con ricerche sistematiche e rigorose.\nFalsificabilità\nUn modello scientifico deve poter essere testato empiricamente e, se necessario, confutato sulla base di nuove osservazioni o di risultati sperimentali.\nParsimonia\nDeve fornire una spiegazione del fenomeno quanto più semplice e lineare possibile, evitando elementi superflui o ridondanti.\nGeneralizzabilità\nDeve poter essere applicato a diverse situazioni e contesti, superando i limiti di specifiche condizioni sperimentali.\nUtilità pratica\nDeve offrire indicazioni utili per interventi clinici, programmi di prevenzione, terapie o altre applicazioni pratiche nel mondo reale.\n\nUna delle sfide più complesse nella modellazione psicologica deriva dalla natura soggettiva, dinamica e variabile dell’esperienza umana. È necessario quindi trovare un equilibrio tra la precisione teorica – spesso supportata da formalizzazioni matematiche o computazionali – e la flessibilità richiesta per cogliere l’eterogeneità dei fenomeni psicologici. A ciò si aggiungono i limiti etici della sperimentazione e le possibili implicazioni sociali.\nL’analisi quantitativa dei dati riveste un ruolo centrale nella validazione dei modelli psicologici: grazie a metodologie statistiche e computazionali avanzate, i ricercatori possono verificare se le predizioni del modello rispecchiano i dati empirici e se sono in grado di generalizzare a contesti nuovi. Questo processo non solo rende più solida la comprensione del fenomeno studiato, ma permette anche di predire e, in alcuni casi, influenzare il comportamento e i processi mentali. In tal senso, un modello formulato in modo preciso e testabile diventa un potente strumento per la crescita teorica e per lo sviluppo di interventi efficaci.\n\n1.3.1 Rappresentare i Fenomeni per Ragionare e Comunicare\nLa spiegazione scientifica non si limita a chiarire i meccanismi causali, ma offre anche un linguaggio formale per analizzare e condividere conoscenze sui fenomeni. In psicologia, i modelli scientifici rappresentano strumenti fondamentali per descrivere i processi attraverso variabili, funzioni e parametri, fornendo una struttura utile a individuare relazioni e proprietà essenziali. Un modello efficace semplifica la complessità del fenomeno, agevolando sia la comunicazione tra studiosi sia la comprensione intuitiva.\nI modelli non solo organizzano informazioni, ma favoriscono anche nuove intuizioni, generando ulteriori domande di ricerca. Una rappresentazione chiara consente di formulare ipotesi innovative, collegare concetti apparentemente distanti e trasferire conoscenze tra diverse discipline, ampliando così il potenziale campo d’indagine.\n\n\n1.3.2 Il Ruolo dell’Analisi dei Dati\nL’analisi dei dati è un elemento centrale del metodo scientifico e, in psicologia, svolge due funzioni fondamentali:\n\nSemplificare e sintetizzare informazioni complesse\nAttraverso statistiche descrittive, visualizzazioni grafiche e altre tecniche di sintesi, l’analisi dei dati consente di individuare schemi, tendenze e anomalie nei fenomeni psicologici. Questo processo facilita l’esplorazione delle differenze tra individui o gruppi e aiuta a formulare ipotesi più precise.\nValutare le predizioni dei modelli\nL’analisi dei dati consente di confrontare le predizioni teoriche con le osservazioni empiriche, testando così la validità delle ipotesi di un modello. Questo confronto è essenziale per confermare, affinare o rivedere le teorie, guidando il progresso della conoscenza scientifica.\n\nTuttavia, l’analisi dei dati da sola non è sufficiente per comprendere a fondo un fenomeno. L’identificazione di correlazioni o schemi nei dati, se non ancorata a un modello teorico esplicativo, offre una visione parziale e limitata. È quindi essenziale integrare i dati in un quadro teorico che ne interpreti il significato e proponga meccanismi causali in grado di spiegare le relazioni osservate.\nSolo attraverso la combinazione di modelli teorici formalizzati e analisi quantitative rigorose è possibile andare oltre la mera descrizione dei fenomeni, formulando spiegazioni solide, generando nuove predizioni e sviluppando interventi mirati per influenzare il comportamento e i processi psicologici.\n\n\n1.3.3 Carattere Multidisciplinare dell’Analisi dei Dati\nL’analisi dei dati è un processo essenziale per la scienza e, in particolare, per la psicologia quantitativa, in quanto consente di validare i modelli teorici, testarne le predizioni e raffinare le ipotesi. Per affrontare questa complessità, l’analisi dei dati si basa su un’integrazione di tre discipline fondamentali: statistica, teoria della probabilità e informatica. Ciascuna di queste fornisce strumenti indispensabili per comprendere i dati, estrarre conoscenze utili e sviluppare modelli predittivi testabili.\n\nStatistica\nFornisce metodi per raccogliere, organizzare e interpretare i dati, consentendo di sintetizzare informazioni, identificare schemi e valutare empiricamente le ipotesi dei modelli psicologici.\nTeoria della probabilità\nCostituisce il fondamento matematico della statistica e della modellazione scientifica, permettendo di quantificare l’incertezza, descrivere la variabilità delle osservazioni e costruire modelli predittivi formalmente rigorosi.\nInformatica\nOffre strumenti per la gestione, l’elaborazione e la visualizzazione di dati complessi e di grandi dimensioni. Inoltre, consente l’implementazione di modelli computazionali avanzati, che sono essenziali per simulare e testare le dinamiche dei processi psicologici.\n\nQuesta natura multidisciplinare riflette l’esigenza di integrare competenze diverse per affrontare in modo rigoroso l’analisi dei fenomeni psicologici. In particolare, l’approccio quantitativo e computazionale ai modelli consente non solo di descrivere e interpretare i dati, ma anche di formulare predizioni precise e verificabili, contribuendo così al progresso della scienza psicologica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "href": "chapters/key_notions/02_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "title": "1  Concetti chiave",
    "section": "1.4 Concetti Chiave nell’Analisi dei Dati",
    "text": "1.4 Concetti Chiave nell’Analisi dei Dati\nPer condurre un’analisi dei dati efficace, è fondamentale comprendere alcuni concetti chiave che guidano il processo di indagine, dall’identificazione del fenomeno alla formulazione di inferenze.\n\n1.4.1 Popolazioni e Campioni\nL’analisi dei dati inizia con l’identificazione della popolazione di interesse, che rappresenta l’insieme completo degli individui o delle entità coinvolte nel fenomeno studiato. Poiché studiare un’intera popolazione è spesso impraticabile, si ricorre ai campioni, sottoinsiemi rappresentativi della popolazione. La qualità e la rappresentatività del campione sono cruciali: un campione non rappresentativo può portare a conclusioni errate, limitando la generalizzabilità dei risultati.\n\n\n\n\n\n\nParametri e Statistiche\n\n\n\nUn parametro è una caratteristica numerica della popolazione (es. media \\(\\mu\\), deviazione standard \\(\\sigma\\)). Una statistica è una caratteristica numerica calcolata sul campione (es. media campionaria \\(\\bar{x}\\), deviazione standard campionaria \\(s\\)). L’inferenza statistica si occupa di stimare i parametri della popolazione a partire dalle statistiche campionarie.\n\n\n\n\n1.4.2 Bias nella Raccolta Dati\nI bias nella raccolta e interpretazione dei dati possono compromettere l’accuratezza dei risultati. Comprendere chi ha raccolto i dati, come e con quali scopi è essenziale per una corretta interpretazione (Johnson et al., 2022). I dati non sono mai completamente neutri; i metodi e gli obiettivi di raccolta influenzano i risultati. Ad esempio, selezionare partecipanti da una popolazione di studenti universitari potrebbe introdurre un bias sistematico, limitando la generalizzabilità ad altri contesti (Murray & Carr, 2024; Nobles, 2000).\n\n\n1.4.3 Variabili e Costanti\nNell’analisi statistica, le variabili rappresentano le caratteristiche osservate che possono assumere diversi valori (numerici o categorici). Le costanti, al contrario, rimangono fisse in un determinato contesto. Le variabili si distinguono in:\n\nvariabili indipendenti (o predittive): influenzano altri fenomeni;\n\nvariabili dipendenti: rappresentano gli esiti di interesse influenzati dalle variabili indipendenti.\n\nAd esempio, in uno studio sugli effetti della terapia cognitivo-comportamentale, la variabile indipendente potrebbe essere la partecipazione alla terapia, mentre la variabile dipendente sarebbe la riduzione dei sintomi di ansia.\n\n\n1.4.4 Studi Osservazionali ed Esperimenti\nEsistono due principali metodi di raccolta dati.\n\nEsperimenti: I ricercatori manipolano una o più variabili per valutare il loro effetto su altre variabili, controllando per i fattori confondenti. Ad esempio, per valutare l’efficacia di un trattamento, i partecipanti possono essere assegnati casualmente a un gruppo di controllo (placebo) e a un gruppo sperimentale (trattamento attivo). La randomizzazione riduce il rischio di bias sistematici.\nStudi osservazionali: I dati vengono raccolti senza interferire con il fenomeno osservato. Ad esempio, un’indagine su come lo stress influenza la produttività lavorativa potrebbe basarsi su questionari senza manipolare lo stress dei partecipanti. Questi studi forniscono correlazioni tra variabili, ma non dimostrano relazioni causali.\n\n\n\n1.4.5 Effetti\nIn statistica, un effetto rappresenta il cambiamento osservato nella variabile dipendente in relazione a una variabile indipendente. Questo cambiamento può indicare un’associazione tra le due variabili, ma la sua interpretazione come relazione causale dipende strettamente dal disegno sperimentale con cui i dati sono stati raccolti.\nAd esempio, se si osserva una riduzione dei sintomi tra la fase pre-trattamento e quella post-trattamento in un gruppo di pazienti sottoposti a una terapia, è possibile identificare un effetto della terapia. Tuttavia, senza un disegno sperimentale adeguato – come un esperimento controllato randomizzato (RCT) – non è possibile stabilire con certezza che la riduzione dei sintomi sia causata dalla terapia e non da altri fattori, come il decorso naturale della malattia o l’effetto placebo (Huntington-Klein, 2021).\nI modelli statistici, da soli, non possono determinare relazioni causali: possono quantificare l’entità di un effetto e valutare la forza dell’associazione tra variabili, ma la causalità può essere inferita solo se i dati provengono da un disegno sperimentale che isola il meccanismo di interesse, controllando per possibili fattori di confondimento. Pertanto, per trarre conclusioni causali robuste, è essenziale integrare l’analisi statistica con un approccio metodologico rigoroso basato su strategie di manipolazione sperimentale, assegnazione casuale o tecniche avanzate per il controllo dei bias nei dati osservazionali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#parametri-e-statistiche",
    "href": "chapters/key_notions/02_key_notions.html#parametri-e-statistiche",
    "title": "1  Concetti chiave",
    "section": "1.5 Parametri e Statistiche",
    "text": "1.5 Parametri e Statistiche\nUn parametro è una caratteristica numerica della popolazione (es. media μ, deviazione standard σ). Una statistica è una caratteristica numerica calcolata sul campione (es. media campionaria x̄, deviazione standard campionaria s). L’inferenza statistica si occupa di stimare i parametri della popolazione a partire dalle statistiche campionarie.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "href": "chapters/key_notions/02_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "title": "1  Concetti chiave",
    "section": "1.7 Le Sfide dell’Inferenza Statistica in Psicologia",
    "text": "1.7 Le Sfide dell’Inferenza Statistica in Psicologia\nIn psicologia e nelle scienze sociali, l’applicazione dell’inferenza statistica si scontra con specifiche problematiche, spesso legate alla complessità dei fenomeni studiati (Gelman et al., 2021). Tra le sfide principali figurano:\n\nGeneralizzazione dai campioni alla popolazione target\nI campioni possono non essere rappresentativi a causa di limitazioni pratiche (ad esempio, l’uso di studenti universitari come soggetti), rendendo difficile estendere i risultati a popolazioni più ampie e diversificate.\nGeneralizzazione dal trattamento al gruppo di controllo (validità esterna)\nNegli studi sperimentali, è cruciale stabilire se gli effetti osservati in un contesto specifico (o su uno specifico campione) siano replicabili in contesti diversi, popolazioni differenti o condizioni sperimentali variate.\nInferenza su costrutti latenti\nMolti costrutti di interesse (come l’ansia, l’autostima o l’intelligenza) non sono direttamente osservabili. Sono invece misurati indirettamente, ad esempio tramite questionari o test, introducendo possibili errori di misurazione o distorsioni legate allo strumento di valutazione. L’inferenza statistica deve pertanto tenere conto di questa complessità, collegando le osservazioni empiriche ai costrutti teorici sottostanti.\n\nIn sintesi, la stima e l’inferenza statistica sono strategie fondamentali per trasformare i dati campionari in conoscenza generalizzabile, soprattutto in contesti come la psicologia, caratterizzati da un’ampia variabilità dei comportamenti e dei processi mentali. Se da un lato la metodologia quantitativa offre un solido quadro teorico e pratico per gestire l’incertezza e testare ipotesi, dall’altro occorre sempre considerare la qualità del campione, la validità degli strumenti di misura e la complessità intrinseca dei costrutti indagati.\nUn uso consapevole dell’inferenza statistica, in combinazione con adeguati disegni di ricerca e modelli psicologici ben fondati, consente di avanzare spiegazioni robuste, di generare nuove ipotesi e di fornire indicazioni utili per interventi e applicazioni pratiche.\n\n1.7.1 L’Incertezza\nLe considerazioni introduttive di questo capitolo fanno capire come un aspetto cruciale della stima e dell’inferenza sia la gestione e la quantificazione dell’incertezza. Ogni stima derivata da un campione è intrinsecamente soggetta a errore, in quanto il campione rappresenta solo una parte della popolazione. L’inferenza statistica fornisce gli strumenti per quantificare tale incertezza, ad esempio attraverso gli intervalli di confidenza (nell’approccio frequentista) o le distribuzioni a posteriori (nell’approccio bayesiano), consentendo di esprimere il grado di fiducia nelle conclusioni tratte.\nIn conclusione, la stima e l’inferenza statistica sono strumenti indispensabili per trasformare i dati empirici in conoscenza utile e rilevante. Tuttavia, è fondamentale applicare queste metodologie con rigore e consapevolezza delle loro limitazioni, prestando particolare attenzione alla rappresentatività del campione, alla validità delle misurazioni e alla corretta interpretazione dei risultati, al fine di evitare generalizzazioni inappropriate e conclusioni errate.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#riflessioni-conclusive",
    "href": "chapters/key_notions/02_key_notions.html#riflessioni-conclusive",
    "title": "1  Concetti chiave",
    "section": "1.8 Riflessioni Conclusive",
    "text": "1.8 Riflessioni Conclusive\nL’analisi dei dati acquisisce valore solo quando è integrata con una solida teoria scientifica, che fornisce il contesto e il quadro interpretativo necessario per attribuire senso ai risultati. Ad esempio, osservare che un trattamento psicologico riduce i sintomi è un’osservazione empirica che, senza una teoria che chiarisca i meccanismi sottostanti, rimane priva di potere esplicativo. È la teoria che orienta il processo analitico, formulando ipotesi verificabili e offrendo interpretazioni che si inseriscono in un modello più ampio.\nIn definitiva, la relazione tra teoria e analisi dei dati è intrinsecamente circolare e dinamica: le teorie guidano la raccolta, l’analisi e l’interpretazione dei dati, mentre i dati, a loro volta, stimolano il perfezionamento e l’evoluzione delle teorie. Questo dialogo continuo è ciò che permette un progresso costante nella comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#esercizi",
    "href": "chapters/key_notions/02_key_notions.html#esercizi",
    "title": "1  Concetti chiave",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nChe cos’è una spiegazione scientifica e in che modo si differenzia da una mera descrizione o previsione di un fenomeno?\nPerché, quando si parla di popolazione e campione, è fondamentale assicurarsi che il campione sia rappresentativo, e quali conseguenze possono derivare da un campione non rappresentativo?\nChe differenza c’è tra un parametro e una statistica, e perché in inferenza statistica si cerca di stimare il parametro sconosciuto a partire dalla statistica campionaria?\nCosa si intende per bias nella raccolta e interpretazione dei dati, e in che modo la consapevolezza dei possibili bias può migliorare la qualità della ricerca?\nPerché in psicologia e nelle scienze sociali risulta essenziale integrare l’analisi dei dati con un quadro teorico solido e coerente?\nQual è la differenza principale tra uno studio osservazionale e un esperimento, e perché la distinzione è importante per comprendere la causalità?\nChe ruolo svolgono i modelli scientifici in psicologia, e quali caratteristiche fondamentali dovrebbero possedere per essere considerati validi e utili?\nIn che modo l’analisi dei dati aiuta a passare dalle semplici correlazioni o tendenze osservate all’elaborazione di ipotesi e spiegazioni più profonde?\nChe differenza c’è tra variabili indipendenti e variabili dipendenti, e perché questa distinzione è cruciale per disegnare uno studio e interpretarne i risultati?\nPerché parlare di incertezza è inevitabile quando si utilizzano i dati di un campione, e come la statistica (frequentista o bayesiana) ci aiuta a gestirla?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Che cos’è una spiegazione scientifica e in che modo si differenzia da una mera descrizione o previsione di un fenomeno?\nUna spiegazione scientifica mira a individuare le cause e i meccanismi che generano o influenzano un fenomeno. Non si limita quindi a descrivere cosa accade o a prevedere ciò che potrebbe accadere (come una semplice correlazione o un modello predittivo), ma cerca di chiarire perché il fenomeno si verifica. Ad esempio, dire “i bambini con genitori laureati hanno migliori prestazioni scolastiche” è una descrizione (o previsione) utile; spiegare che ciò avviene a causa di un maggior sostegno nel percorso di studi, di un ambiente più ricco di stimoli culturali, o di un contesto socioeconomico facilitante, fornisce invece una spiegazione che va oltre la pura correlazione statistica.\n2. Perché, quando si parla di popolazione e campione, è fondamentale assicurarsi che il campione sia rappresentativo, e quali conseguenze possono derivare da un campione non rappresentativo?\nIl campione è il sottoinsieme di individui selezionati da una popolazione più ampia. Affinché i risultati di uno studio siano validi e generalizzabili, il campione deve rispecchiare le principali caratteristiche della popolazione (ad esempio in termini di età, genere, livello socioeconomico, ecc.). Se il campione non è rappresentativo (per esempio, se si reclutano solo studenti universitari per uno studio su tutta la popolazione italiana), possono emergere bias di selezione che rendono impossibile estendere correttamente i risultati a gruppi sociali diversi. Conseguenze tipiche di un campione non rappresentativo includono stime distorte dei parametri d’interesse, conclusioni fuorvianti e ridotta validità esterna della ricerca.\n3. Che differenza c’è tra un parametro e una statistica, e perché in inferenza statistica si cerca di stimare il parametro sconosciuto a partire dalla statistica campionaria?\n\nUn parametro è una caratteristica numerica della popolazione (ad esempio la media reale di un determinato tratto o la proporzione di individui con una certa caratteristica).\n\nUna statistica è una misura analoga, ma calcolata sul campione (ad esempio la media o la proporzione campionaria).\n\nPoiché in genere è impossibile o molto costoso misurare l’intera popolazione, si raccoglie un campione più piccolo e gestibile. La statistica del campione (ad es. la media campionaria) è quindi usata per stimare il parametro (ad es. la media della popolazione). L’obiettivo dell’inferenza statistica è fornire, insieme a questa stima, una misura dell’incertezza associata (per esempio un intervallo di confidenza), così da comprendere quanto la statistica campionaria potrebbe “avvicinarsi” al vero valore del parametro.\n4. Cosa si intende per bias nella raccolta e interpretazione dei dati, e in che modo la consapevolezza dei possibili bias può migliorare la qualità della ricerca?\nIl bias è un errore sistematico che altera i risultati di uno studio in una direzione specifica, dovuto a scelte o condizioni nel disegno della ricerca, nella selezione del campione, nella misurazione o nell’interpretazione dei dati. Ad esempio, se reclutiamo solo volontari particolarmente motivati a partecipare a una ricerca, potremmo ottenere risultati che sovrastimano un certo fenomeno e non rispecchiano la popolazione generale.\nEssere consapevoli di come i bias possano nascere aiuta i ricercatori a mitigarli (ad esempio, bilanciando il reclutamento dei partecipanti o rendendo anonima la compilazione di un questionario) e a tenere conto dei loro effetti quando si interpretano i risultati. Così, la ricerca risulta più affidabile e validamente interpretata.\n5. Perché in psicologia e nelle scienze sociali risulta essenziale integrare l’analisi dei dati con un quadro teorico solido e coerente?\nNelle scienze sociali e in psicologia, i fenomeni studiati sono spesso complessi e influenzati da molte variabili. I dati da soli, senza una teoria, forniscono soltanto una descrizione o una misurazione di ciò che accade in un dato momento. La teoria invece permette di:\n\nIdentificare le variabili rilevanti e formulare ipotesi specifiche;\n\nInterpretare i risultati, attribuendo un senso e un contesto alle relazioni osservate;\n\nComprendere i meccanismi causali e sviluppare spiegazioni che vadano oltre la pura descrizione.\n\nSenza un quadro teorico di riferimento, sarebbe difficile capire perché si osservano determinate relazioni e come possano cambiare in contesti diversi o in situazioni sperimentali alternative.\n6. Qual è la differenza principale tra uno studio osservazionale e un esperimento, e perché la distinzione è importante per comprendere la causalità?\n\nStudio osservazionale: Il ricercatore raccoglie i dati senza intervenire né manipolare alcuna variabile. Ad esempio, si misura il livello di stress delle persone e la loro produttività sul lavoro, senza modificare artificialmente il livello di stress. Questi studi mostrano correlazioni, ma è difficile stabilire con certezza relazioni di causa-effetto.\n\nEsperimento: Il ricercatore manipola una o più variabili (variabili indipendenti) e controlla le condizioni, ad esempio assegnando in modo casuale i partecipanti a un gruppo di trattamento e a uno di controllo. Ciò facilita la comprensione di eventuali nessi causali, perché la randomizzazione e il controllo degli altri fattori riducono il rischio che variabili esterne influenzino i risultati.\n\nLa distinzione è cruciale perché, nei fenomeni complessi della psicologia, gli studi osservazionali possono suggerire ipotesi di relazione, ma di solito occorre un disegno sperimentale (quando possibile) per trarre conclusioni più solide sulla causalità.\n7. Che ruolo svolgono i modelli scientifici in psicologia, e quali caratteristiche fondamentali dovrebbero possedere per essere considerati validi e utili?\nI modelli scientifici in psicologia forniscono una struttura concettuale e spesso formale (matematica o simulativa) per rappresentare e spiegare processi mentali e comportamentali. Servono a:\n\nOrganizzare osservazioni ed evidenze in un sistema coerente;\n\nFare previsioni verificabili empiricamente;\n\nGuidare l’interpretazione di nuovi dati e la progettazione di futuri studi.\n\nCaratteristiche di un buon modello sono:\n\nCoerenza descrittiva (rappresenta fedelmente il fenomeno);\n\nCapacità predittiva (prevede correttamente i risultati di situazioni nuove);\n\nSupporto empirico (confermato dai dati raccolti rigorosamente);\n\nFalsificabilità (dev’essere possibile smentirlo con evidenze contrarie);\n\nParsimonia (non dev’essere inutilmente complicato);\n\nGeneralizzabilità (applicabile a diversi contesti e situazioni);\n\nUtilità pratica (fornisce indicazioni utili per interventi o comprensione teorica).\n\n8. In che modo l’analisi dei dati aiuta a passare dalle semplici correlazioni o tendenze osservate all’elaborazione di ipotesi e spiegazioni più profonde?\nL’analisi dei dati non si limita a segnalare che “due variabili sono associate” (correlazioni), ma offre:\n\nStrumenti per isolare l’effetto di una variabile sulle altre (regressioni multiple, modelli a effetti misti, ecc.);\n\nMetodologie per la verifica di ipotesi specifiche sulla direzione e sulla natura delle relazioni (ad es. test statistici o modelli di mediazione-moderazione in psicologia);\n\nIndicatori dell’incertezza e della robustezza dei risultati (intervalli di confidenza, analisi della potenza, analisi bayesiane).\n\nCon questi strumenti, i ricercatori possono integrare i risultati quantitativi con le teorie esistenti, sviluppare nuove ipotesi su meccanismi causali e proporre spiegazioni più articolate su come e perché le variabili si influenzino reciprocamente.\n9. Che differenza c’è tra variabili indipendenti e variabili dipendenti, e perché questa distinzione è cruciale per disegnare uno studio e interpretarne i risultati?\n\nVariabile indipendente (VI): è quella che si sospetta abbia un effetto su un’altra variabile, o che si desidera manipolare in un disegno sperimentale (per esempio, l’introduzione di un nuovo metodo di studio).\n\nVariabile dipendente (VD): è la variabile che si misura per valutare l’eventuale effetto della variabile indipendente (ad esempio, i risultati di un test di apprendimento).\nLa distinzione è basilare perché chiarisce la direzione del rapporto di interesse e permette di formulare ipotesi come “VI → VD” (es. “il nuovo metodo di studio migliora i risultati del test”). Sbagliare a identificare quali sono le variabili indipendenti e dipendenti può portare a disegni di ricerca confusi e interpretazioni errate.\n\n10. Perché parlare di incertezza è inevitabile quando si utilizzano i dati di un campione, e come la statistica (frequentista o bayesiana) ci aiuta a gestirla?\nQuando raccogliamo dati da un campione (necessariamente limitato), non possiamo osservare l’intera popolazione. Questo introduce un margine di incertezza su quanto la misura campionaria (statistica) rispecchi il parametro reale della popolazione. Inoltre, possono sempre esserci fattori non controllati o errori di misurazione.\n\nNell’approccio frequentista, l’incertezza è gestita tramite concetti come gli intervalli di confidenza e i valori p, che quantificano la probabilità di osservare determinati risultati assumendo determinate ipotesi (per es. l’ipotesi nulla).\n\nNell’approccio bayesiano, l’incertezza è modellata tramite distribuzioni di probabilità (posteriori) che incorporano sia i dati osservati sia le informazioni pregresse (priors).\n\nEntrambi gli approcci forniscono metodologie per valutare quanto ci si possa fidare di una data conclusione, riconoscendo il carattere aleatorio e parziale dei dati e rendendo esplicito il grado di incertezza.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#bibliografia",
    "href": "chapters/key_notions/02_key_notions.html#bibliografia",
    "title": "1  Concetti chiave",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMurray, E. J., & Carr, K. C. (2024). Measuring Racial Sentiment Using Social Media Is Harder Than It Seems. Epidemiology, 35(1), 60–63.\n\n\nNobles, M. (2000). Shades of citizenship: Race and the census in modern politics. Stanford University Press.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html",
    "href": "chapters/key_notions/03_design.html",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "",
    "text": "2.1 Introduzione\nQuesto capitolo si propone di approfondire i concetti introdotti in precedenza, concentrandosi in particolare sul processo di campionamento e sull’importanza delle diverse metodologie di ricerca in psicologia. Dopo aver compreso il ruolo fondamentale dei dati nella verifica delle teorie, emerge una questione cruciale: come vengono raccolti questi dati?\nLa raccolta dei dati non è un’attività neutra o priva di conseguenze metodologiche. I dati, infatti, non hanno lo stesso valore scientifico a seconda di come vengono ottenuti. Alcune modalità di raccolta generano informazioni preziose e utili per testare le teorie, mentre altre possono produrre risultati fuorvianti, distorti o addirittura dannosi per la validità della ricerca.\nIl metodo scientifico fornisce un quadro di riferimento che delinea le caratteristiche ideali di un processo di raccolta dati in grado di produrre informazioni valide e affidabili. Tuttavia, le prescrizioni del metodo scientifico sono per loro natura generali e astratte. Tradurre questi principi in procedure concrete e applicarli efficacemente in un contesto di ricerca specifico rappresenta una sfida significativa.\nQuesto passaggio, che collega la teoria alla pratica, dipende dalle risorse disponibili, dalla competenza metodologica e dalla creatività del ricercatore. La capacità di ideare e attuare strategie di raccolta dati adeguate al contesto specifico della ricerca è fondamentale per garantire la qualità e la validità dei risultati ottenuti. In questo capitolo, approfondiremo i principi del campionamento e introdurremo i concetti chiave relativi ai disegni di ricerca.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#popolazioni-e-campioni",
    "href": "chapters/key_notions/03_design.html#popolazioni-e-campioni",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.2 Popolazioni e Campioni",
    "text": "2.2 Popolazioni e Campioni\nNella ricerca scientifica, è essenziale distinguere tra popolazione e campione.\n\nPopolazione: rappresenta l’insieme completo di unità che condividono una o più caratteristiche specifiche oggetto di studio. La dimensione della popolazione è indicata con N.\nCampione: è un sottoinsieme della popolazione, di dimensione n. L’obiettivo del campionamento è ottenere un campione rappresentativo, ovvero un sottoinsieme che rifletta accuratamente le caratteristiche della popolazione di riferimento.\n\n\n2.2.1 Metodi di Campionamento\nEsistono diverse strategie per selezionare un campione rappresentativo da una popolazione. Queste strategie si dividono principalmente in due categorie: campionamento probabilistico e campionamento non probabilistico.\n\n2.2.1.1 Campionamento Probabilistico\nNel campionamento probabilistico, ogni unità della popolazione ha una probabilità nota e non nulla di essere inclusa nel campione. Questo approccio minimizza il rischio di distorsioni sistematiche (bias) e consente di stimare l’errore di campionamento.\n\nCampionamento Casuale Semplice (CCS):\nOgni unità della popolazione ha la stessa probabilità di essere inclusa nel campione. Questo metodo richiede una lista completa di tutte le unità della popolazione, nota come frame di campionamento. La selezione può avvenire con o senza reinserimento. Il CCS senza reinserimento è il più comune nella pratica, ma nelle ricerche psicologiche è raramente utilizzabile a causa della difficoltà di ottenere un frame completo della popolazione.\nCampionamento Stratificato:\nLa popolazione viene divisa in strati (H), ovvero sottogruppi omogenei in base a una o più variabili rilevanti (es. età, genere, regione geografica). Da ogni strato h viene estratto un campione casuale semplice di dimensione nh. Questo metodo può essere:\n\nProporzionale: la dimensione del campione in ogni strato è proporzionale alla dimensione dello strato nella popolazione.\nNon proporzionale: utilizzato per sovra-campionare gruppi minoritari, consentendo analisi dettagliate di sottogruppi altrimenti poco rappresentati.\nNelle ricerche psicologiche, il campionamento stratificato è utile per garantire che variabili come il genere o l’età siano adeguatamente rappresentate, ma può essere complesso da implementare.\n\nCampionamento a Grappolo (Cluster Sampling):\nLa popolazione viene suddivisa in grappoli (cluster), che rappresentano gruppi eterogenei (es. scuole, ospedali, quartieri). Vengono selezionati casualmente alcuni grappoli, includendo tutte le unità al loro interno. Questo metodo è economico e pratico, specialmente in contesti dove accedere all’intera popolazione è difficile. Tuttavia, la precisione può essere ridotta se i grappoli differiscono notevolmente tra loro.\nCampionamento Multistadio:\nCombinazione di campionamento a grappolo e CCS. Vengono selezionati casualmente alcuni grappoli e, successivamente, all’interno di ciascun grappolo, si estrae un campione casuale di unità. Questo metodo bilancia costi e precisione, risultando particolarmente adatto a studi su larga scala, ad esempio a livello nazionale.\n\n\n\n2.2.1.2 Campionamento Non Probabilistico\nNel campionamento non probabilistico, la probabilità di inclusione di ogni unità nel campione non è nota. Questo approccio è spesso adottato per ragioni di praticità o quando non è disponibile un frame di campionamento. Tuttavia, aumenta il rischio di distorsioni e limita la generalizzabilità dei risultati alla popolazione.\n\nCampionamento di Convenienza:\nÈ il metodo più diffuso nella ricerca psicologica. I partecipanti vengono selezionati in base alla loro facile accessibilità (es., studenti universitari, volontari). Questo metodo è rapido ed economico, ma introduce significativi bias di selezione, poiché il campione non è rappresentativo della popolazione generale.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#il-campionamento-nella-ricerca-psicologica",
    "href": "chapters/key_notions/03_design.html#il-campionamento-nella-ricerca-psicologica",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.3 Il Campionamento nella Ricerca Psicologica",
    "text": "2.3 Il Campionamento nella Ricerca Psicologica\nIl tema del campionamento nella ricerca psicologica è cruciale perché influisce in modo diretto sulla validità esterna e sulla generalizzabilità dei risultati. Nella pratica, però, l’ideale metodologico del campionamento probabilistico è spesso difficile da perseguire, a causa di vincoli di tempo, di risorse economiche e di accessibilità ai partecipanti (Henrich et al., 2010a). Per queste ragioni, molti studi in psicologia fanno ricorso al campionamento di convenienza, che prevede la selezione dei partecipanti sulla base della loro facile reperibilità, come studenti universitari o volontari reclutati online.\n\n2.3.1 Perché il Campionamento di Convenienza è così Diffuso?\n\nVincoli di Risorse\nLa ricerca psicologica, specie in ambito accademico, spesso non dispone di finanziamenti sufficienti per condurre campionamenti su larga scala. Reclutare partecipanti rappresentativi di un’intera popolazione richiederebbe budget, logistica e tempo ben superiori a quelli generalmente disponibili (Peterson & Merunka, 2014). Il campionamento di convenienza diventa quindi un compromesso “necessario” per poter portare avanti gli studi.\nAccessibilità ai Partecipanti\nNel contesto universitario, gli studenti rappresentano il bacino più facilmente accessibile e motivato a partecipare a studi psicologici, talvolta in cambio di crediti formativi o rimborsi simbolici (Sears, 1986). In altri contesti, si ricorre a piattaforme online che forniscono volontari in tempi brevi, consentendo di raccogliere dati in modo rapido e a costi contenuti.\nRapidità di Raccolta Dati\nIl vantaggio principale del campionamento di convenienza è la possibilità di raccogliere dati in tempi molto più ridotti rispetto a strategie di campionamento probabilistico. Tale rapidità può risultare essenziale per studi pilota o ricerche che richiedono analisi preliminari di fenomeni ancora poco esplorati.\n\n\n\n2.3.2 Limiti e Implicazioni\nIl ricorso al campionamento di convenienza comporta inevitabilmente dei limiti in termini di rappresentatività del campione. Gli individui che si prestano a partecipare a uno studio potrebbero avere caratteristiche socio-demografiche, cognitive o motivazionali peculiari (ad esempio, essere più giovani, con livelli di istruzione più alti, culturalmente più omogenei), portando ad un fenomeno noto come “campioni WEIRD” [Western, Educated, Industrialized, Rich, Democratic; Henrich et al. (2010b)]. Ciò significa che i risultati ottenuti potrebbero non riflettere adeguatamente l’intera variabilità della popolazione umana.\n\nGeneralizzabilità Ridotta: Uno studio condotto su studenti di psicologia in un’università europea può non essere applicabile a individui di diverse fasce di età, provenienti da altre aree geografiche o con retroterra socio-culturali differenti.\nBias di Selezione: I partecipanti volontari, specialmente online, possono essere attratti dallo studio per ragioni specifiche (ad esempio, curiosità verso la psicologia, tempo libero a disposizione, motivazione a ottenere un compenso), introducendo distorsioni non presenti nella popolazione più ampia.\nLimitazioni nei Risultati: Se i processi psicologici oggetto di indagine sono influenzati da cultura, età o altre variabili, lo studio potrebbe non catturare in modo esaustivo la complessità del fenomeno.\n\n\n\n2.3.3 Perché in Psicologia è (in Parte) Accettabile\nSebbene il campionamento di convenienza costituisca un limite, è bene ricordare che molti fenomeni psicologici presentano elementi di base che sono relativamente generali o universali nell’essere umano [ad esempio, i processi di percezione, l’apprendimento di base, alcune dinamiche emotive e motivazionali; cfr. Tooby & Cosmides (2005)]. Ciò significa che, entro certi confini, studiare un campione di convenienza può comunque fornire indicazioni utili e trasferibili ad altre popolazioni. Inoltre, buona parte delle ricerche in psicologia mira ad approfondire meccanismi e processi interna corporis – cioè aspetti di natura cognitiva, emotiva o sociale che, pur potendo variare in intensità o manifestazione, hanno basi comuni tra gli individui.\nIn altre parole, esiste un trade-off tra la necessità di disporre di campioni rappresentativi per garantire la massima generalizzabilità e la specificità dei fenomeni psicologici, che talvolta risiedono in processi considerati “universali”. Se lo scopo di uno studio è quello di testare meccanismi cognitivi di base (per esempio, l’elaborazione di stimoli visivi o di memoria), un campione di studenti potrebbe comunque fornire dati sufficientemente robusti, purché si riconoscano i limiti del contesto di raccolta.\n\n2.3.3.1 Considerazioni Etiche e Pratiche\nTalvolta, per ragioni etiche, non è semplice reperire partecipanti da particolari fasce di popolazione (ad esempio minori, pazienti clinici, soggetti in contesti istituzionali). In alcune ricerche, poi, l’uso di questionari lunghi o procedure sperimentali intense rende difficile attrarre volontari al di fuori dell’ambiente universitario. Da questo punto di vista, avere un bacino di partecipanti noti (ad es. studenti di psicologia) agevola la raccolta dei dati.\n\nRicompense: Spesso i dipartimenti offrono crediti formativi o piccoli compensi ai partecipanti, innescando un circolo virtuoso di interesse per la ricerca.\nLibertà di rifiuto: Le università dispongono di comitati etici che tutelano i diritti dei partecipanti, garantendo che anche i reclutamenti “di comodo” rispettino i principi etici fondamentali (consenso informato, anonimato, diritto al recesso, ecc.).\n\n\n\n\n2.3.4 Come Mitigare i Limiti del Campionamento di Convenienza\n\nReplicazione Incrociata (Cross-Replication)\nUn metodo efficace per aumentare la validità dei risultati è replicare lo stesso studio su campioni differenti, di età diversa o provenienti da contesti socio-culturali eterogenei. Ripetere la ricerca in più contesti e ottenere risultati simili fornisce evidenza della generalizzabilità del fenomeno.\nCampionamento Diversificato\nAnche se si ricorre a un campionamento di convenienza, si può tentare di diversificare la provenienza dei partecipanti (ad esempio, includendo studenti di diverse facoltà o atenei, oppure reclutando volontari su piattaforme online internazionali). Un campione che rifletta almeno in parte una maggiore varietà di background socio-culturali è comunque preferibile alla selezione di un solo gruppo omogeneo.\nCaratterizzazione Dettagliata del Campione\nÈ fondamentale fornire informazioni precise su età, genere, livello di istruzione, estrazione socio-culturale e altre variabili rilevanti. Questo permette ai lettori di valutare in che misura i risultati dello studio possano essere trasferiti ad altre popolazioni.\nIntegrazione di Metodi di Campionamento Misti\nAlcuni ricercatori scelgono di integrare campionamenti non probabilistici con piccole porzioni di campionamento più stratificato o di selezionare sotto-campioni rappresentativi per determinati sottogruppi. Non si tratta di un vero e proprio campionamento probabilistico, ma può comunque migliorare la robustezza dei risultati rispetto al puro campionamento di convenienza.\n\n\n\n2.3.5 Considerazioni Economiche e Future Prospettive\nAlla luce di questi punti, appare chiaro che il ricorso a metodi di campionamento probabilistici più rigorosi (campionamento casuale semplice, stratificato o a grappolo) richiederebbe aumenti significativi nei finanziamenti e un impegno logistico maggiore. Ciò non è sempre fattibile in contesti di ricerca accademica o quando i progetti sono condotti con budget limitati.\nD’altro canto, i finanziamenti aggiuntivi permetterebbero di:\n\nReclutare campioni più ampi e diversificati, ad esempio attraverso agenzie di rilevazione professionali o sondaggi a livello nazionale.\n\nImplementare studi longitudinali su popolazioni geograficamente distribuite, riducendo il rischio di raccogliere dati esclusivamente da aree limitrofe ai centri di ricerca.\nSostenere progetti multicentrici a livello internazionale, che consentono di testare l’universalità o la specificità culturale dei fenomeni psicologici.\n\nFino a quando queste risorse non saranno disponibili su larga scala, il campionamento di convenienza rimarrà la soluzione più diffusa e “realistica” nella ricerca psicologica. Tuttavia, non bisogna considerarlo esclusivamente un limite: la specificità dei fenomeni psicologici, legati a processi condivisi tra gli individui, talvolta permette di estrarre conclusioni valide anche da campioni meno rappresentativi, purché si utilizzino adeguate cautele nell’interpretazione e si persegua la replicazione come prassi consolidata.\nIn sintesi, il campionamento di convenienza è una strategia inevitabile nell’attuale panorama della ricerca psicologica, caratterizzato da forti limitazioni di risorse, ma in molti casi risulta comunque sufficiente per investigare dinamiche e processi psicologici di base. L’auspicio per il futuro è di poter disporre di finanziamenti e collaborazioni che permettano di ampliare il raggio d’azione e la diversità dei partecipanti, rafforzando la validità e la generalizzabilità della produzione scientifica in psicologia.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#metodologia-sperimentale",
    "href": "chapters/key_notions/03_design.html#metodologia-sperimentale",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.4 Metodologia Sperimentale",
    "text": "2.4 Metodologia Sperimentale\n\n2.4.1 Principi Fondamentali del Disegno Sperimentale\n\nControllo\nL’obiettivo è ridurre l’influenza di variabili confondenti (Z) sulla relazione tra la variabile indipendente (X) e quella dipendente (Y). Utilizzare un gruppo di controllo consente di stabilire un riferimento per valutare l’effetto del trattamento.\nRandomizzazione\nL’assegnazione casuale dei partecipanti ai gruppi sperimentali distribuisce le variabili confondenti in modo equilibrato tra i gruppi, aumentando la credibilità dell’inferenza causale tra X e Y. Questo approccio garantisce che eventuali differenze osservate siano attribuibili al trattamento e non a fattori esterni.\n\n\n\n2.4.2 Strategie di Mitigazione dei Bias\n\nCecità (Blinding)\nStrumento chiave per minimizzare l’influenza di aspettative e pregiudizi, sia nei partecipanti che nei ricercatori. Le principali modalità includono:\n\nCecità singola: I partecipanti non sono consapevoli del trattamento assegnato.\nCecità doppia: Sia i partecipanti che i ricercatori che interagiscono direttamente con loro non conoscono l’assegnazione dei trattamenti.\nCecità tripla: Né i partecipanti, né i ricercatori, né gli analisti dei dati sono a conoscenza dei trattamenti durante la raccolta e l’analisi dei dati.\n\nGruppo di Controllo\nL’introduzione di un gruppo che riceve un trattamento inerte (controllo) consente di isolare gli effetti psicologici legati alle aspettative dei partecipanti, distinguendoli dagli effetti specifici del trattamento.\nStandardizzazione delle Procedure\nGarantire che tutte le condizioni sperimentali, eccetto la variabile manipolata, siano mantenute costanti tra i gruppi. Questo riduce la variabilità non controllata, migliorando la comparabilità dei risultati.\n\n\n\n2.4.3 Nota sulla Replicazione\nLa replicazione degli esperimenti non è una caratteristica intrinseca del metodo sperimentale, ma rappresenta una pratica fondamentale nella scienza per verificare l’affidabilità e la generalizzabilità dei risultati. Si distingue in:\n\nReplicazione diretta: Ripetere lo stesso studio con le stesse condizioni.\nReplicazione concettuale: Ripetere lo studio modificando aspetti specifici per testare la robustezza del risultato.\n\n\n\n2.4.4 Tipologie di Disegni Sperimentali\n\nDisegno a Gruppi Indipendenti (Between-Subjects):\nI partecipanti vengono assegnati a un unico gruppo e sono esposti a una sola condizione sperimentale. Questo disegno è utile quando l’esposizione multipla potrebbe introdurre confondenti, ma richiede un campione più ampio per raggiungere lo stesso livello di precisione.\nDisegno a Misure Ripetute (Within-Subjects):\nGli stessi partecipanti vengono esposti a tutte le condizioni sperimentali. Questo approccio riduce la variabilità tra soggetti, migliorando la precisione delle stime. Tuttavia, richiede attenzione nel controllare gli effetti di ordine, come affaticamento o apprendimento, spesso attraverso il bilanciamento dell’ordine di presentazione dei trattamenti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#studi-osservazionali",
    "href": "chapters/key_notions/03_design.html#studi-osservazionali",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.5 Studi Osservazionali",
    "text": "2.5 Studi Osservazionali\nGli studi osservazionali possono essere classificati in:\n\nStudi Trasversali (Cross-Sectional)\nI dati vengono raccolti in un singolo momento. Utili per stimare la prevalenza di una condizione, ma non permettono di stabilire relazioni causali.\nStudi di Coorte (Cohort Studies)\nUn gruppo di individui (coorte) viene seguito nel tempo per osservare l’incidenza di un evento. Permettono di studiare la relazione tra esposizione e outcome, ma possono essere costosi e richiedere molto tempo.\nStudi Caso-Controllo (Case-Control Studies)\nVengono confrontati individui con una determinata condizione (casi) con individui senza la condizione (controlli) per identificare possibili fattori di rischio. Utili per studiare malattie rare, ma soggetti a bias di selezione e di ricordo.\n\nLe principali limitazioni degli studi osservazionali sono la presenza di variabili confondenti e la difficoltà di stabilire relazioni causali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#i-metodi-di-campionamento-in-psicologia",
    "href": "chapters/key_notions/03_design.html#i-metodi-di-campionamento-in-psicologia",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.6 I metodi di Campionamento in Psicologia",
    "text": "2.6 I metodi di Campionamento in Psicologia\nAggiungo qui alcune considerazioni relative alla specificità della ricerca psicologica in relazione ai metodi di campionamento.\nIn generale, possiamo dire che, anche nella ricerca psicologica, la questione del campionamento è cruciale per la validità esterna (o generalizzabilità) dei risultati. In linea di principio, l’obiettivo sarebbe quello di avere un campione probabilistico, rappresentativo di una popolazione target ben definita. Tuttavia, nella pratica, soprattutto negli studi accademici, molti ricercatori ricorrono a campioni di comodo—tipicamente studenti universitari, volontari reclutati online oppure persone facilmente accessibili all’autore dello studio (Sears, 1986). Questo tipo di scelta presenta indubbiamente limiti metodologici, ma è anche legato a ragioni pragmatiche ed esistono alcune motivazioni psicologiche (e non solo pratiche) che possono giustificare, almeno in parte, il suo utilizzo.\n\n2.6.1 Vantaggi e Limiti\n\nCampionamento probabilistico: Idealmente, per trarre conclusioni generalizzabili sull’intera popolazione, i ricercatori dovrebbero estrarre un campione in maniera casuale da una lista esaustiva di tutti i potenziali partecipanti (ad es., tutti gli adulti di un dato Paese). In questo modo, ogni individuo avrebbe la stessa probabilità di essere selezionato. Ciò rende i risultati potenzialmente estendibili all’intera popolazione.\nProblemi pratici: Il campionamento probabilistico è spesso molto costoso, richiede molte risorse e può essere di difficile attuazione (difficoltà di contatto, tassi di rifiuto elevati, vincoli di tempo e budget, ecc.). Inoltre, in psicologia sperimentale, dove si svolgono studi di laboratorio, reperire un campione probabilistico per ricerche controllate (ad esempio sugli effetti di un training cognitivo, su specifici bias attentivi, ecc.) risulta complesso.\n\n\n\n2.6.2 Giustificazioni\n\n2.6.2.1 Accessibilità e Risorse Disponibili\nLa ragione più evidente per cui gli studi psicologici ricorrono a campioni di comodo è l’accesso facilitato ai partecipanti. Gli studenti universitari, ad esempio, sono spesso disponibili, facilmente reclutabili e motivati a partecipare (anche grazie a crediti formativi o piccole ricompense).\n\nVantaggio pratico: Consente di condurre studi numerosi e con costi ridotti.\nConseguenza metodologica: Il campione non è rappresentativo (età media bassa, livello di istruzione relativamente elevato, background culturale simile).\n\n\n\n2.6.2.2 Universalità di Alcuni Processi Psicologici\nUn argomento a difesa dell’uso di campioni di comodo è che molti processi psicologici di base, in particolare i processi cognitivi e percettivi, presentano meccanismi considerati largamente “universali” nell’essere umano (Sternberg & Sternberg, 2006). Se si studiano processi cognitivi elementari—come la percezione visiva, la memoria di lavoro o le funzioni esecutive—la variabilità individuale legata a fattori demografici (come età, cultura, estrazione sociale) potrebbe essere meno rilevante per i risultati di base, soprattutto se l’obiettivo è comprendere i meccanismi fondamentali.\n\nEsempio: Studi classici su tempi di reazione, capacità di memoria a breve termine, modelli di attenzione selettiva e processi di apprendimento associativo spesso mostrano pattern simili in differenti popolazioni.\nLimite di questa giustificazione: Anche se i processi di base sono simili, differenze di età, cultura, e istruzione possono influenzare le performance cognitive. Inoltre, se la ricerca è orientata a processi più complessi (emozionali, motivazionali, sociali), l’universalità non è più scontata (Henrich et al., 2010b).\n\n\n\n2.6.2.3 La Replicabilità come Criterio di Robustezza\nNegli ultimi anni, la psicologia sta attraversando una “crisi di replicazione” (Collaboration, 2015). Un modo per arginare questa crisi è puntare sulla replicabilità dei risultati in contesti diversi. Anche se ogni singolo studio utilizza un campione di comodo, la convergenza di più studi condotti in luoghi e tempi differenti, su campioni diversi (anche se non perfettamente rappresentativi), può aumentare la fiducia nella robustezza dei risultati.\n\nEsempio: Un effetto cognitivo robusto (es. l’effetto Stroop) è stato replicato innumerevoli volte in diversi laboratori, con popolazioni differenti.\nLimite di questa giustificazione: Se il campione tipico rimane comunque molto simile (ad esempio studenti occidentali), la varietà non è poi così ampia. Questa “ristrettezza” della base di campionamento è stata definita “WEIRD” (Western, Educated, Industrialized, Rich, Democratic), sottolineando i limiti della generalizzabilità (Henrich et al., 2010b).\n\n\n\n2.6.2.4 Studi Preliminari e Proof-of-Concept\nSpesso, i progetti di ricerca iniziano con studi esplorativi o proof-of-concept su piccola scala. In questa fase, un campione di comodo può essere sufficiente per una prima verifica teorica, per testare un nuovo paradigma sperimentale o per mettere a punto le procedure di laboratorio. Una volta stabilita l’esistenza di un determinato fenomeno, studi più ampi e campioni più diversificati possono essere pianificati (Anderson-Cook, 2005).\n\nBeneficio: Rapidità nello sviluppo di ipotesi e paradigmi di ricerca.\nProspettiva futura: Se i risultati preliminari sono promettenti, è auspicabile passare a campioni più ampi e/o più diversificati.\n\n\n\n2.6.2.5 Considerazioni Etiche e Pratiche\nTalvolta, per ragioni etiche, non è semplice reperire partecipanti da particolari fasce di popolazione (ad esempio minori, pazienti clinici, soggetti in contesti istituzionali). In alcune ricerche, poi, l’uso di questionari lunghi o procedure sperimentali intense rende difficile attrarre volontari al di fuori dell’ambiente universitario. Da questo punto di vista, avere un bacino di partecipanti noti (ad es. studenti di psicologia) agevola la raccolta dei dati.\n\nRicompense: Spesso i dipartimenti offrono crediti formativi o piccoli compensi ai partecipanti, innescando un circolo virtuoso di interesse per la ricerca.\nLibertà di rifiuto: Le università dispongono di comitati etici che tutelano i diritti dei partecipanti, garantendo che anche i reclutamenti “di comodo” rispettino i principi etici fondamentali (consenso informato, anonimato, diritto al recesso, ecc.).\n\n\n\n\n2.6.3 Conclusioni\nSebbene la dipendenza dai campioni di comodo rappresenti un limite sostanziale per la generalizzabilità delle conclusioni, la pratica comune in psicologia ne risulta parzialmente giustificata:\n\nCosti e accessibilità: Il campionamento probabilistico è oneroso. Lavorare con studenti o gruppi disponibili riduce drasticamente costi e tempi.\nUniversalità di alcuni processi: Molti paradigmi di psicologia sperimentale si concentrano su processi cognitivi di base, che appaiono relativamente simili tra individui di diverse culture (anche se non sempre).\nStudi preliminari: La ricerca esplorativa spesso non richiede campioni probabilistici, ma test rapidi di ipotesi per poi estendere successivamente la ricerca a campioni più ampi.\nReplicabilità: La diffusione di più repliche, anche con diversi campioni (anche se non probabilistici), rafforza la robustezza dei risultati.\nVincoli etici e pratici: Non sempre è possibile o eticamente opportuno accedere a popolazioni particolari; spesso i contesti accademici offrono procedure eticamente codificate.\n\nRiconoscendo i limiti intrinseci del campionamento di comodo, la comunità scientifica incoraggia, tuttavia, a diversificare il più possibile i campioni, a promuovere la replicabilità in altri contesti e culture, e a non trascurare le variabili demografiche che potrebbero moderare i risultati. Solo in questo modo la psicologia può aspirare a una reale generalizzabilità dei propri modelli e a una maggiore solidità empirica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#riflessioni-conclusive",
    "href": "chapters/key_notions/03_design.html#riflessioni-conclusive",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.6 Riflessioni Conclusive",
    "text": "2.6 Riflessioni Conclusive\nNel corso di questo capitolo, abbiamo esplorato l’importanza del campionamento e delle diverse strategie di ricerca in psicologia, mettendo in luce i vincoli metodologici e le implicazioni derivanti da scelte spesso guidate dalle risorse a disposizione. Se da un lato i metodi di campionamento probabilistico garantiscono maggiore controllo sulla rappresentatività del campione, dall’altro, la realtà accademica e il contesto operativo di molti studi psicologici spingono verso soluzioni di comodo, inevitabilmente limitanti ma non per questo prive di valore scientifico.\nLe complessità intrinseche nello studio di fenomeni psicologici – spesso universali e al tempo stesso influenzati da variabili culturali e individuali – ci ricordano quanto sia importante mantenere un equilibrato senso critico. Da un punto di vista metodologico, l’esigenza di replicare gli studi in più contesti rimane la prassi fondamentale per rafforzare la credibilità dei risultati. Altrettanto cruciale è la volontà di caratterizzare in modo trasparente i propri campioni, rendendo chiaro in che misura siano (o non siano) rappresentativi della popolazione d’interesse. In tal modo, la comunità scientifica può valutare con maggiore consapevolezza la trasferibilità delle conclusioni a contesti diversi.\nUn ulteriore spunto di riflessione riguarda la tensione tra la desiderabilità di disegni di ricerca ideali (con campioni estesi e probabilistici) e le inevitabili restrizioni di tempo e budget. Se l’implementazione di studi su larga scala o a livello multicentrico consentirebbe di cogliere le sfumature culturali e socio-demografiche dei fenomeni, è altrettanto vero che, nel panorama attuale, molte ricerche non potrebbero essere realizzate senza ricorrere a partecipanti di più facile accesso, come gli studenti universitari o i volontari online. Tale flessibilità operativa può comunque produrre conoscenza significativa, a condizione che il ricercatore rimanga vigile rispetto ai possibili bias introdotti.\nIn definitiva, l’invito a chiunque conduca ricerche psicologiche è quello di coltivare una mentalità aperta, volta a bilanciare i limiti contingenti (economici, logistici, etici) con la necessità di mantenere standard metodologici solidi. Ciò implica sfruttare le potenzialità dell’integrazione tra disegni sperimentali e osservazionali, prestare attenzione alle forme di bias e, soprattutto, adottare la replicazione come pratica sistematica. Solo attraverso questa sinergia fra rigore scientifico e consapevolezza delle risorse disponibili è possibile far progredire la disciplina su basi empiriche sempre più solide e generalizzabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#esercizi",
    "href": "chapters/key_notions/03_design.html#esercizi",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nPerché la fase di raccolta dei dati è considerata “non neutrale” e quali conseguenze può avere sull’affidabilità dei risultati di una ricerca psicologica?\nIn che modo i diversi metodi di campionamento (probabilistico vs. non probabilistico) influiscono sulla generalizzabilità delle conclusioni di uno studio e quali situazioni giustificano l’uso dell’uno o dell’altro?\nQuali sono i principali rischi nell’adottare un campionamento di convenienza in ricerche psicologiche, e quali strategie si possono utilizzare per mitigare questi rischi?\nIn che modo la randomizzazione e l’uso di gruppi di controllo supportano l’inferenza causale in un disegno sperimentale, e perché queste caratteristiche sono spesso più difficili da mantenere negli studi osservazionali?\nQuali sono i principali criteri da considerare quando si valuta la validità di uno studio in termini di campionamento, disegno di ricerca e replicabilità?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Perché la fase di raccolta dei dati è considerata “non neutrale” e quali conseguenze può avere sull’affidabilità dei risultati di una ricerca psicologica?\nLa raccolta dei dati non è mai un processo completamente neutrale perché comporta scelte metodologiche e pratiche che possono influenzare la qualità e la natura delle informazioni ottenute. Ad esempio:\n\nSelezione del campione: Scegliere chi includere o escludere nella ricerca incide sulla rappresentatività del campione. Un campione non rappresentativo può produrre risultati distorti e difficilmente generalizzabili.\n\nModalità di somministrazione degli strumenti: La maniera in cui vengono somministrati questionari, test o interviste può influire sulle risposte dei partecipanti (per esempio, differenze tra somministrazione online vs. cartacea, questionari anonimi vs. non anonimi, ecc.).\n\nContesto e tempistiche: Il contesto ambientale (es., rumori, distrazioni) o il momento in cui i dati vengono raccolti (es., in prossimità di esami universitari) possono influenzare lo stato emotivo o motivazionale dei partecipanti.\n\nCome conseguenza, tutte queste variabili possono introdurre bias – ossia distorsioni sistematiche – che compromettono l’affidabilità e la validità dei risultati, rendendo l’interpretazione dei dati più complessa e potenzialmente fuorviante. In altre parole, se la fase di raccolta dati non è accuratamente progettata e condotta, la ricerca potrebbe fornire conclusioni scorrette o di limitata utilità scientifica.\n2. In che modo i diversi metodi di campionamento (probabilistico vs. non probabilistico) influiscono sulla generalizzabilità delle conclusioni di uno studio e quali situazioni giustificano l’uso dell’uno o dell’altro?\n\nCampionamento probabilistico:\n\nOgni unità della popolazione ha una probabilità nota e non nulla di essere selezionata.\n\nMetodi come il campionamento casuale semplice, stratificato o a grappolo forniscono un quadro più solido per stimare l’errore di campionamento e minimizzare i bias.\n\nI risultati ottenuti sono, in linea di massima, più facilmente generalizzabili all’intera popolazione di riferimento.\n\nÈ preferibile in studi di larga scala, in cui esiste un buon frame di campionamento (lista esaustiva della popolazione) e le risorse (tempo, fondi) consentono di implementare un disegno rigoroso.\n\nCampionamento non probabilistico:\n\nLa probabilità di inclusione di un’unità non è nota, per cui non si possono calcolare in modo rigoroso le stime di errore.\n\nIl metodo più comune è il campionamento di convenienza, in cui vengono reclutate persone facilmente accessibili (es., studenti universitari, volontari, piattaforme online).\n\nLa generalizzabilità dei risultati è ridotta, poiché il campione potrebbe non rispecchiare le caratteristiche della popolazione di interesse.\n\nÈ spesso utilizzato per studi esplorativi, ricerche a budget limitato o quando non si dispone di un elenco completo della popolazione.\n\n\nIn sintesi, il campionamento probabilistico è preferibile quando si mira a ottenere risultati solidi e generalizzabili a una popolazione più ampia e le condizioni logistiche lo consentono. Il campionamento non probabilistico, invece, è giustificato in studi preliminari, in situazioni in cui la popolazione non è ben definita o difficilmente accessibile, o quando si hanno vincoli di risorse che rendono impraticabile un campionamento probabilistico.\n3. Quali sono i principali rischi nell’adottare un campionamento di convenienza in ricerche psicologiche, e quali strategie si possono utilizzare per mitigare questi rischi?\n\nPrincipali rischi:\n\nBias di selezione: I partecipanti reclutati con metodi di convenienza (ad es. studenti di psicologia) potrebbero non rispecchiare l’eterogeneità della popolazione generale, limitando la generalizzabilità dei risultati.\n\nOmogeneità del campione: Se il campione è molto omogeneo (per età, livello di istruzione, contesto culturale), diventa difficile estendere le conclusioni a gruppi con caratteristiche diverse.\n\nAutoselezione: I volontari che si offrono di partecipare potrebbero differire sistematicamente da coloro che non partecipano (ad esempio, maggiore interesse per il tema della ricerca o per la ricompensa economica offerta).\n\nStrategie di mitigazione:\n\nSovra-campionamento: Includere deliberatamente più partecipanti appartenenti a gruppi minoritari o sottorappresentati, per disporre di sottocampioni più completi.\n\nReplicazione: Ripetere l’esperimento con campioni diversi (per età, contesto geografico, cultura) per verificare se i risultati si mantengono coerenti.\n\nDescrizione dettagliata del campione: Fornire informazioni precise sulle caratteristiche sociodemografiche (età, genere, livello di istruzione, ecc.) in modo che altri ricercatori o lettori possano valutare la trasferibilità dei risultati.\n\nCautela nell’interpretazione: Esplicitare nelle conclusioni i limiti relativi alla natura del campionamento e invitare a considerare possibili fattori confondenti legati alla non rappresentatività del campione.\n\n\n4. In che modo la randomizzazione e l’uso di gruppi di controllo supportano l’inferenza causale in un disegno sperimentale, e perché queste caratteristiche sono spesso più difficili da mantenere negli studi osservazionali?\n\nRandomizzazione:\n\nAssegna i partecipanti ai gruppi sperimentali (condizione sperimentale vs. condizione di controllo) in maniera casuale.\n\nGarantisce che variabili potenzialmente confondenti vengano distribuite equamente tra i gruppi, aumentando la probabilità che eventuali differenze nelle misure di esito (variabile dipendente) siano dovute esclusivamente alla manipolazione sperimentale (variabile indipendente).\n\nQuesto processo riduce l’influenza di fattori esterni non misurati o non conosciuti, favorendo un’inferenza causale più solida.\n\nGruppi di controllo:\n\nConsentono di confrontare i risultati di chi riceve il trattamento/intervento con chi non lo riceve (o riceve un trattamento placebo).\n\nAiutano a isolare l’effetto “vero” del trattamento dalle variazioni dovute a effetti psicologici (ad es. effetto placebo), al passare del tempo o a eventi esterni.\n\nDifficoltà negli studi osservazionali:\n\nNon prevedono la manipolazione diretta di una variabile indipendente né l’assegnazione casuale dei partecipanti: le persone “si assegnano da sole” alle condizioni.\n\nManca il controllo sperimentale: non è sempre possibile includere un gruppo di controllo o applicare procedure di randomizzazione.\n\nLe variabili confondenti possono agire in modo non controllabile e compromettere l’interpretazione causale: anche con analisi statistiche sofisticate, è difficile escludere del tutto la presenza di fattori esterni che influenzano la relazione tra esposizione e outcome.\n\n\nPer questi motivi, gli studi sperimentali (con randomizzazione e controllo) rimangono il metodo privilegiato per stabilire nessi di causalità, mentre gli studi osservazionali servono principalmente a generare ipotesi, descrivere fenomeni, o analizzare relazioni di associazione più che di causalità.\n5. Quali sono i principali criteri da considerare quando si valuta la validità di uno studio in termini di campionamento, disegno di ricerca e replicabilità?\n\nRappresentatività del campione:\n\nIl campione rispecchia realmente le caratteristiche della popolazione di interesse?\n\nÈ stato usato un metodo di campionamento appropriato (probabilistico vs. non probabilistico)?\n\nControllo e randomizzazione (validità interna):\n\nLo studio ha previsto un disegno sperimentale con assegnazione casuale e gruppo di controllo?\n\nQuanto è efficace il controllo delle variabili confondenti (bias di selezione, aspettative, effetto placebo, ecc.)?\n\nGeneralizzabilità o validità esterna:\n\nI risultati dello studio sono applicabili oltre il contesto specifico in cui è stato condotto?\n\nVi sono limitazioni dovute all’uso di un campione di convenienza o di un contesto culturale molto particolare?\n\nStandardizzazione delle procedure:\n\nLe istruzioni, i tempi di raccolta dati, i materiali utilizzati sono stati gestiti in modo uniforme per tutti i partecipanti?\n\nReplicabilità:\n\nÈ possibile ripetere lo studio (replicazione diretta o concettuale) e ottenere risultati simili?\n\nGli autori forniscono informazioni sufficienti (materiali, protocolli, analisi) per consentire la replicazione?\n\nChiarezza nell’esposizione dei limiti:\n\nGli autori discutono apertamente le limitazioni del metodo di campionamento o del disegno di ricerca e suggeriscono possibili miglioramenti per studi futuri?\n\n\nNel complesso, una valutazione critica di uno studio deve integrare tutti questi aspetti (campionamento, disegno, replicabilità) per stabilire in che misura i risultati siano solidi, attendibili e utilmente generalizzabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#bibliografia",
    "href": "chapters/key_notions/03_design.html#bibliografia",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010a). Most people are not WEIRD. Nature, 466(7302), 29–29.\n\n\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010b). The weirdest people in the world? Behavioral and Brain Sciences, 33(2-3), 61–83.\n\n\nPeterson, R. A., & Merunka, D. R. (2014). Convenience samples of college students and research reproducibility. Journal of Business Research, 67(5), 1035–1041.\n\n\nTooby, J., & Cosmides, L. (2005). Evolutionary psychology: Conceptual foundations. In D. M. Buss (A c. Di), The Handbook of Evolutionary Psychology (pp. 5–67). Wiley.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html",
    "href": "chapters/key_notions/04_measurement.html",
    "title": "3  La misurazione in psicologia",
    "section": "",
    "text": "3.1 Introduzione\nLa scienza si avvale di modelli per interpretare i dati, ma opera sempre con teorie incomplete e misurazioni soggette a errori. Di conseguenza, è fondamentale riconoscere le incertezze quando si cerca di estrarre informazioni dalle misurazioni utilizzando i nostri modelli. Nessuna misurazione, spiegazione o previsione è perfettamente accurata e precisa, e non possiamo mai conoscere con esattezza l’entità dei loro errori. Questo riconoscimento è alla base della teoria della misurazione, che cerca di quantificare e gestire queste incertezze per migliorare la qualità delle nostre conclusioni scientifiche.\nQuesta incertezza viene catturata in tre equazioni fondamentali. La prima è l’Equazione di Misurazione, che riconosce l’errore osservativo:\n\\[\ny = z + \\varepsilon_y,\n\\]\ndove \\(y\\) rappresenta il valore misurato, \\(z\\) il valore reale e \\(\\varepsilon_y\\) l’errore di misurazione. La seconda è l’Equazione di Modellazione, che esprime la presenza di un diverso tipo di errore:\n\\[\nz = f(x, \\theta) + \\varepsilon_\\text{model},\n\\]\ndove \\(f\\) è il modello, \\(x\\) sono le condizioni ambientali per cui eseguiamo il modello, \\(\\theta\\) sono i valori dei parametri del modello e \\(\\varepsilon_\\text{model}\\) rappresenta l’errore del modello, che sorge perché \\(f\\), \\(x\\) e \\(\\theta\\) saranno tutti in qualche misura imprecisi.\nCombinando queste due equazioni, otteniamo l’Equazione della Scienza:\n\\[\ny = f(x, \\theta) + \\varepsilon_\\text{model} + \\varepsilon_y.\n\\]\nLa scienza è il tentativo di spiegare le osservazioni \\(y\\) utilizzando un modello \\(f\\), cercando di minimizzare l’errore di misurazione \\(\\varepsilon_y\\) e l’errore del modello \\(\\varepsilon_\\text{model}\\), in modo che il modello possa essere utilizzato per fare previsioni sul mondo reale (\\(z\\)). L’approccio bayesiano alla scienza riconosce e quantifica le incertezze su tutti e sei gli elementi dell’Equazione della Scienza: \\(y\\), \\(f\\), \\(x\\), \\(\\theta\\), \\(\\varepsilon_\\text{model}\\) e \\(\\varepsilon_y\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#la-teoria-della-misurazione",
    "href": "chapters/key_notions/04_measurement.html#la-teoria-della-misurazione",
    "title": "3  La misurazione in psicologia",
    "section": "3.2 La teoria della Misurazione",
    "text": "3.2 La teoria della Misurazione\nLa teoria della misurazione, oggetto di questo capitolo, si concentra sull’errore di misurazione e sull’equazione fondamentale \\(y = z + \\varepsilon_y\\). Questa equazione può essere esaminata da tre prospettive distinte. La prima concerne l’affidabilità della misura, rappresentata dal termine \\(\\varepsilon_y\\). La psicometria, branca dedicata alla teoria della misurazione psicologica, si occupa di quantificare l’affidabilità delle misure psicologiche attraverso metodi come la Teoria Classica dei Test e la Teoria di Risposta all’Item.\nLa seconda prospettiva riguarda la validità delle misure psicologiche, ovvero quanto adeguatamente la misura \\(y\\) rappresenti il costrutto \\(z\\). Questo aspetto, più complesso dell’affidabilità, non può essere risolto meramente con metodi statistici, ma richiede una profonda comprensione delle teorie psicologiche e della loro capacità di descrivere e prevedere i fenomeni psicologici.\nLa terza prospettiva si concentra sulle procedure di assegnazione dei valori a \\(y\\), esplorando quali metodi (questionari, interviste, esperimenti) siano più appropriati e come valutarne l’adeguatezza.\n\n3.2.1 Costrutti Psicologici\nLa teoria della misurazione sottolinea l’importanza di distinguere tra la procedura di misurazione e il costrutto che si intende misurare. Ad esempio, mentre la temperatura è un costrutto, il termometro è lo strumento di misurazione. Analogamente, l’abilità matematica è un costrutto, mentre un test di matematica è la procedura per misurarla.\nNelle scienze psicologiche e sociali, la misurazione presenta sfide uniche rispetto alle scienze fisiche, poiché i costrutti in esame sono spesso astratti e non direttamente osservabili. Ciò richiede una particolare attenzione alla validità e all’affidabilità degli strumenti di misurazione, nonché una costante riflessione sulle limitazioni e le potenziali fonti di errore.\nIl capitolo introduce concetti fondamentali relativi alla misurazione quantitativa delle caratteristiche psicologiche, con un focus sulla teoria delle scale di misura di Stevens (1946). Questa teoria fornisce un quadro concettuale per comprendere i diversi tipi di scale di misurazione e le operazioni matematiche appropriate per ciascuna. Inoltre, vengono esplorate alcune procedure di scaling psicologico, ovvero l’assegnazione di numeri all’intensità di fenomeni psicologici.\n\n\n3.2.2 Scaling Psicologico\nLo scaling psicologico si occupa della trasformazione dei dati empirici raccolti durante uno studio psicologico in misure o punteggi che rappresentino accuratamente le caratteristiche psicologiche oggetto di indagine.\nScaling di Guttman. Uno dei metodi di scaling più noti è lo «Scaling di Guttman», che viene utilizzato per rappresentare relazioni ordinate tra gli elementi di una scala. Ad esempio, in un questionario sui sintomi dell’ansia, le domande possono essere disposte in ordine di intensità crescente dei sintomi. Secondo il modello di Guttman, se un partecipante risponde “sì” a una domanda che riflette un sintomo più intenso, ci si aspetta che abbia risposto “sì” anche a tutte le domande precedenti, che rappresentano sintomi di intensità minore. Questo approccio consente di costruire una scala che riflette in modo sistematico e coerente la gravità dei sintomi.\nScaling Thurstoniano. Lo «Scaling Thurstoniano» è un metodo utilizzato per misurare preferenze o giudizi soggettivi. Ad esempio, per valutare la preferenza tra diversi tipi di cibi, i partecipanti confrontano due cibi alla volta ed esprimono una preferenza. Le risposte vengono poi utilizzate per assegnare punteggi che riflettono la preferenza media per ciascun cibo.\nQuestionari Likert. I questionari Likert richiedono ai partecipanti di esprimere il loro grado di accordo con una serie di affermazioni su una scala a più livelli, che va da «fortemente in disaccordo» a «fortemente d’accordo». I punteggi ottenuti vengono sommati per rappresentare la posizione complessiva dell’individuo rispetto all’oggetto di studio.\n\n\n3.2.3 Metodi di Valutazione delle Scale Psicologiche\nPer valutare le proprietà delle scale psicologiche, vengono utilizzati vari metodi. Ad esempio, l’affidabilità delle misure può essere analizzata utilizzando il coefficiente alpha di Cronbach o il coefficiente Omega di McDonald, entrambi utilizzati per misurare la coerenza interna delle risposte ai diversi item di un questionario. Inoltre, la validità delle scale può essere esaminata confrontando i risultati ottenuti con misure simili o attraverso analisi statistiche che verificano se la scala cattura accuratamente il costrutto psicologico che si intende misurare. La validità di costrutto è particolarmente cruciale, poiché riguarda la capacità della scala di misurare effettivamente il concetto psicologico che si intende esplorare.\n\n\n3.2.4 Prospettive Moderne\nNegli ultimi anni, il dibattito sulla misurazione psicologica si è arricchito di nuove prospettive, grazie all’avvento di tecnologie avanzate e all’integrazione di approcci interdisciplinari. Ecco alcune delle tendenze più rilevanti.\nTeoria della Risposta agli Item. La Teoria della Risposta agli Item (IRT) ha guadagnato popolarità per la sua capacità di fornire stime più precise delle abilità latenti rispetto ai modelli classici. La IRT considera la probabilità che un individuo risponda correttamente a un item in funzione della sua abilità e delle caratteristiche dell’item stesso, offrendo una visione più dettagliata delle proprietà psicometriche degli strumenti di misurazione.\nApprocci Bayesiani. Gli approcci bayesiani stanno rivoluzionando il campo della psicometria, permettendo di incorporare informazioni a priori nelle stime e di aggiornare le credenze sulla base di nuovi dati. Questi metodi sono particolarmente utili per affrontare la complessità e l’incertezza inerenti alla misurazione psicologica.\nAnalisi di Rete. L’analisi di rete è un’altra metodologia emergente che vede i costrutti psicologici non come variabili latenti indipendenti, ma come reti di sintomi interconnessi. Questo approccio può offrire nuove intuizioni sulla struttura delle psicopatologie e sulla dinamica dei sintomi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#le-scale-di-misurazione",
    "href": "chapters/key_notions/04_measurement.html#le-scale-di-misurazione",
    "title": "3  La misurazione in psicologia",
    "section": "3.3 Le scale di misurazione",
    "text": "3.3 Le scale di misurazione\nLe scale di misurazione sono strumenti fondamentali per assegnare numeri ai dati osservati, rappresentando le proprietà psicologiche. La teoria delle scale di Stevens (1946) identifica quattro tipi di scale di misurazione: nominali, ordinali, a intervalli e di rapporti. Ognuna di queste scale consente di effettuare operazioni aritmetiche diverse, poiché ciascuna di esse è in grado di “catturare” solo alcune delle proprietà dei fenomeni psicologici che si intende misurare.\n\n\n\nScale di misurazione.\n\n\n\n3.3.1 Scala nominale\nLa scala nominale è il livello di misurazione più semplice e corrisponde ad una tassonomia o classificazione delle categorie che utilizziamo per descrivere i fenomeni psicologici. I simboli o numeri che costituiscono questa scala rappresentano i nomi delle categorie e non hanno alcun valore numerico intrinseco. Con la scala nominale possiamo solo distinguere se una caratteristica psicologica è uguale o diversa da un’altra.\nI dati raccolti con la scala nominale sono suddivisi in categorie qualitative e mutuamente esclusive, in cui ogni dato appartiene ad una sola categoria. In questa scala, esiste solo la relazione di equivalenza tra le misure delle unità di studio: gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti.\nL’unica operazione algebrica consentita dalla scala nominale è quella di contare le unità di studio che appartengono ad ogni categoria e il numero totale di categorie. Di conseguenza, la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nDalla scala nominale è possibile costruire altre scale nominali equivalenti alla prima, trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle categorie, ma lasciando inalterata la suddivisione delle unità di studio nelle medesime classi di equivalenza. In altre parole, cambiando i nomi delle categorie di una variabile misurata su scala nominale, si ottiene una nuova variabile esattamente equivalente alla prima.\n\n\n3.3.2 Scala ordinale\nLa scala ordinale mantiene la caratteristica della scala nominale di classificare ogni unità di misura all’interno di una singola categoria, ma introduce la relazione di ordinamento tra le categorie. In quanto basata su una relazione di ordine, una scala ordinale descrive solo il rango di ordine tra le categorie e non fornisce informazioni sulla distanza tra di esse. Non ci dice, ad esempio, se la distanza tra le categorie \\(a\\) e \\(b\\) è uguale, maggiore o minore della distanza tra le categorie \\(b\\) e \\(c\\).\nUn esempio classico di scala ordinale è quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed è scalfito da quello di livello superiore.\n\n\n\nLa scala di durezza dei minerali di Mohs. Un oggetto è considerato più duro di X se graffia X. Sono incluse anche misure di durezza relativa utilizzando uno sclerometro, da cui emerge la non linearità della scala di Mohs (Burchard, 2004).\n\n\n\n\n3.3.3 Scala ad intervalli\nLa scala ad intervalli di misurazione include le proprietà della scala nominale e della scala ordinale e permette di misurare le distanze tra le coppie di unità statistiche in termini di un intervallo costante, chiamato “unità di misura”, a cui viene attribuito il valore “1”. L’origine della scala, ovvero il punto zero, è scelta arbitrariamente e non indica l’assenza della proprietà che si sta misurando. Ciò significa che la scala ad intervalli consente anche valori negativi e lo zero non viene attribuito all’unità statistica in cui la proprietà risulta assente.\nLa scala ad intervalli equivalenti consente l’esecuzione di operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non possibili con le scale di misura nominale o ordinale. Tuttavia, il limite della scala ad intervalli è che non consente di calcolare il rapporto tra coppie di misure. È possibile affermare la differenza tra \\(a\\) e \\(b\\) come la metà della differenza tra \\(c\\) e \\(d\\) o che le due differenze sono uguali, ma non è possibile affermare che \\(a\\) abbia una proprietà misurata in quantità doppia rispetto a \\(b\\). In altre parole, non è possibile stabilire rapporti diretti tra le misure ottenute. Solo le differenze tra le modalità permettono tutte le operazioni aritmetiche, come la somma, l’elevazione a potenza o la divisione, che sono alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l’unità di misura è arbitraria e può essere cambiata attraverso una dilatazione, ovvero la moltiplicazione di tutti i valori della scala per una costante positiva. Inoltre, la traslazione, ovvero l’aggiunta di una costante a tutti i valori della scala, è ammessa poiché non altera le differenze tra i valori della scala. La scala rimane invariata rispetto a traslazioni e dilatazioni e dunque le uniche trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b &gt; 0.\n\\]\nInfatti, l’uguaglianza dei rapporti fra gli intervalli rimane invariata a seguito di una trasformazione lineare.\nEsempio di scala ad intervalli è la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è possibile stabilire se due modalità sono uguali o diverse: \\(30^\\circ C \\neq 20^\\circ C\\). Come per la scala ordinale è possibile mettere due modalità in una relazione d’ordine: \\(30^\\circ C &gt; 20^\\circ C\\). In aggiunta ai casi precedenti, però, è possibile definire una unità di misura per cui è possibile dire che tra \\(30^\\circ C\\) e \\(20^\\circ C\\) c’è una differenza di \\(30^\\circ - 20^\\circ = 10^\\circ C\\). I valori di temperatura, oltre a poter essere ordinati secondo l’intensità del fenomeno, godono della proprietà che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di \\(80^\\circ C\\) non è il doppio di una di \\(40^\\circ C\\). Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, \\(20^\\circ C = 68^\\circ F\\) e \\(40^\\circ C = 104^\\circ F\\). Questo significa che la relazione “il doppio di” che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla proprietà misurata (cioè la temperatura). La decisione di che scala usare (Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realtà empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\nÈ facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n\n3.3.4 Scala di rapporti\nNella scala a rapporti equivalenti, lo zero non è arbitrario e rappresenta l’elemento che ha intensità nulla rispetto alla proprietà misurata. Per costruire questa scala, si associa il numero 0 all’elemento con intensità nulla e si sceglie un’unità di misura \\(u\\). Ad ogni elemento si assegna un numero \\(a\\) definito come \\(a = d / u\\), dove \\(d\\) rappresenta la distanza dall’origine. In questo modo, i numeri assegnati riflettono le differenze e i rapporti tra le intensità della proprietà misurata.\nIn questa scala, è possibile effettuare operazioni aritmetiche non solo sulle differenze tra i valori della scala, ma anche sui valori stessi della scala. L’unica scelta arbitraria è l’unità di misura, ma lo zero deve sempre rappresentare l’intensità nulla della proprietà considerata.\nLe trasformazioni ammissibili in questa scala sono chiamate trasformazioni di similarità e sono del tipo \\(y' = by\\), dove \\(b &gt; 0\\). In questa scala, i rapporti tra i valori rimangono invariati dopo le trasformazioni. In altre parole, se rapportiamo due valori originali e due valori trasformati, il rapporto rimane lo stesso: \\(\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "href": "chapters/key_notions/04_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "title": "3  La misurazione in psicologia",
    "section": "3.4 Gerarchia dei livelli delle scale di misurazione",
    "text": "3.4 Gerarchia dei livelli delle scale di misurazione\nSecondo Stevens (1946), esiste una gerarchia dei livelli delle scale di misurazione, denominati “livelli di scala”. Questi livelli sono organizzati in modo gerarchico, in cui la scala nominale rappresenta il livello più basso della misurazione, mentre la scala a rapporti equivalenti rappresenta il livello più alto.\n\nScala nominale: Classifica le categorie senza un ordine specifico.\nScala ordinale: Classifica le categorie in un ordine specifico, ma senza una misura precisa delle distanze.\nScala a intervalli: Misura le distanze tra le categorie con un intervallo costante, ma senza un punto zero assoluto.\nScala di rapporti: Misura le distanze con un intervallo costante e un punto zero assoluto.\n\n\n\n\nRelazioni tra i livelli di misurazione.\n\n\nPassando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala.\n\n3.4.1 Variabili Discrete e Continue\nLe variabili possono essere classificate come variabili a livello di intervalli o di rapporti e possono essere sia discrete che continue.\n\nVariabili discrete: Assumono valori specifici ma non possono assumere valori intermedi.\nVariabili continue: Possono assumere qualsiasi valore all’interno di un intervallo specificato.\n\n\n\n\nVariabili discrete e continue.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#relazione-tra-misurazione-e-teoria-sostanziale-unanalisi-critica",
    "href": "chapters/key_notions/04_measurement.html#relazione-tra-misurazione-e-teoria-sostanziale-unanalisi-critica",
    "title": "3  La misurazione in psicologia",
    "section": "3.5 Relazione tra Misurazione e Teoria Sostanziale: Un’Analisi Critica",
    "text": "3.5 Relazione tra Misurazione e Teoria Sostanziale: Un’Analisi Critica\nUn esempio di come condurre una lettura critica di un articolo scientifico è rappresentato dall’analisi di uno studio pubblicato su Nature sul tema del mind-body healing (Aungle & Langer, 2023). Lo studio presenta risultati empirici che suggeriscono un legame tra pratiche di guarigione mente-corpo e miglioramenti nella salute fisica. Tuttavia, la validità di queste conclusioni è stata fortemente contestata da Andrew Gelman, un noto statistico e ricercatore, in un post sul suo blog Statistical Modeling.\n\n3.5.1 L’Importanza di una Teoria Sostanziale Solida\nGelman sottolinea un aspetto cruciale della ricerca scientifica: l’importanza di una teoria sostanziale solida e convincente. Secondo il suo punto di vista, lo studio analizzato presenta una carenza significativa in questo ambito. In assenza di una teoria ben fondata che spieghi in modo plausibile i meccanismi causali attraverso cui le pratiche mente-corpo potrebbero influenzare la salute fisica, i risultati empirici ottenuti rimangono privi di significato. Senza una cornice teorica coerente, lo studio rischia di essere classificato come ciò che Gelman definisce “junk science” – scienza di scarso valore, incapace di offrire vere e proprie intuizioni.\nUna teoria sostanziale non deve solo essere plausibile, ma deve anche integrarsi in modo coerente con altre teorie scientifiche consolidate. Quando una ricerca non riesce a inserirsi in una rete più ampia di conoscenze, i suoi risultati diventano inevitabilmente discutibili. È proprio questo il caso dello studio esaminato da Gelman: l’assenza di una teoria chiara e ben articolata rende i risultati empirici poco credibili e difficilmente generalizzabili.\n\n\n3.5.2 Problemi di Misurazione\nOltre alla debolezza teorica, lo studio presenta anche notevoli problemi legati alla misurazione. Le variabili utilizzate per quantificare sia gli interventi mente-corpo che gli esiti sanitari sono soggette a diverse criticità. Ad esempio, la misurazione dell’efficacia delle pratiche mente-corpo potrebbe essere influenzata da fattori confondenti, come le aspettative dei partecipanti o l’effetto placebo. Allo stesso modo, la valutazione degli esiti sanitari può risultare problematica se non vengono impiegate scale di misurazione affidabili e valide.\nPer un approfondimento su questi temi, si rimanda alle riflessioni conclusive nel Capitolo 33, dove vengono discusse criticamente le questioni legate alla misurazione, con particolare attenzione alla distinzione tra precisione e bias. In generale, uno degli aspetti più critici della misurazione riguarda la validità interna ed esterna negli studi psicologici. La qualità delle misure adottate influisce direttamente sulla solidità delle conclusioni scientifiche: una misurazione imprecisa o distorta può compromettere la validità dei risultati e limitarne la generalizzabilità.\n\n\n3.5.3 La Necessità di una Valutazione Bilanciata\nL’esempio dello studio sul mind-body healing illustra in modo efficace come una lettura critica debba necessariamente passare attraverso due dimensioni fondamentali: la teoria e la misurazione. Una teoria debole compromette la capacità di attribuire significato ai dati raccolti, riducendo lo studio a una mera raccolta di numeri privi di valore scientifico. Allo stesso tempo, problemi di misurazione possono distorcere i risultati, portando a conclusioni errate o fuorvianti. Solo attraverso una valutazione attenta di entrambi questi aspetti è possibile distinguere tra ricerche scientificamente valide e “junk science”.\nIn definitiva, una lettura critica di un articolo psicologico richiede non solo competenze tecniche, ma anche una profonda consapevolezza dei limiti e delle sfide insite nella misurazione psicologica e nel rapporto tra misurazione e teorie scientifiche. Questo approccio consente di valutare in modo equilibrato la qualità e l’affidabilità delle conclusioni proposte. Solo attraverso una rigorosa analisi di entrambi questi aspetti è possibile distinguere tra ricerche scientificamente valide e quelle che, invece, rischiano di essere considerate “junk science”.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#riflessioni-conclusive",
    "href": "chapters/key_notions/04_measurement.html#riflessioni-conclusive",
    "title": "3  La misurazione in psicologia",
    "section": "3.6 Riflessioni Conclusive",
    "text": "3.6 Riflessioni Conclusive\nLa misurazione in psicologia non è un semplice atto di raccolta di dati, ma un processo fondamentale per garantire che le osservazioni empiriche siano interpretabili alla luce di modelli teorici solidi. Una buona misurazione non si limita a ridurre l’errore, ma consente di attribuire un significato coerente ai punteggi ottenuti, facilitando così il progresso della conoscenza scientifica. Senza strumenti adeguati per la misurazione, il rischio è quello di costruire teorie su basi incerte, compromettendo la validità delle conclusioni tratte.\nDue pilastri sostengono una ricerca psicologica rigorosa: la teoria e la misurazione. La teoria fornisce il quadro concettuale entro cui si interpretano i dati, definendo le ipotesi e orientando le analisi. La misurazione, invece, è il ponte tra i costrutti astratti e le osservazioni empiriche, traducendo concetti complessi in variabili operative affidabili. Nessuna delle due componenti può reggersi senza l’altra: una teoria senza misurazione adeguata rischia di rimanere speculativa, mentre una misurazione priva di un solido fondamento teorico può portare a dati privi di significato.\nNella valutazione di un qualsiasi studio psicologico, un approccio critico richiede quindi di esaminare sia la solidità del quadro teorico sia la qualità degli strumenti di misurazione adottati. Il progresso della ricerca dipende dalla capacità di integrare questi due elementi, attraverso metodologie sempre più sofisticate che riducano l’incertezza e migliorino la precisione delle inferenze. Le moderne tecniche di analisi dei dati, i modelli psicometrici avanzati e le tecnologie digitali stanno ampliando le possibilità di misurazione, offrendo strumenti più sensibili e adattabili alla complessità dei fenomeni psicologici. Tuttavia, la sfida principale rimane la stessa: garantire che la misurazione sia non solo accurata, ma anche teoricamente fondata, affinché le conoscenze acquisite possano davvero contribuire alla comprensione della mente e del comportamento umano.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#esercizi",
    "href": "chapters/key_notions/04_measurement.html#esercizi",
    "title": "3  La misurazione in psicologia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Identificazione del Livello di Misurazione\nObiettivo: Comprendere i diversi livelli di misurazione applicati alla psicologia.\n\nIdentifica il livello di misurazione (nominale, ordinale, intervalli, rapporti) per ciascuna delle seguenti variabili psicologiche:\n\n\nTipo di terapia psicologica (Cognitivo-comportamentale, Psicodinamica, Umanistica)\n\n\nLivello di ansia auto-riferito su una scala da 1 a 10\n\n\nNumero di episodi depressivi in un anno\n\n\nTempo di reazione in millisecondi in un test cognitivo\n\n\n\nEsercizio 2: Confronto tra Scale\nObiettivo: Comprendere le differenze tra le scale di misurazione.\n\nSpiega la differenza tra una scala ordinale e una scala a intervalli utilizzando l’esempio della soddisfazione lavorativa.\nPerché il punteggio QI è misurato su una scala a intervalli e non su una scala a rapporti?\nIn che modo il punteggio di una scala di autostima su una scala Likert differisce da una misurazione su una scala di rapporti?\n\nEsercizio 3: Operazioni Aritmetiche Consentite\nObiettivo: Comprendere le operazioni matematiche consentite per ciascun livello di misurazione.\n\nQuali operazioni aritmetiche sono ammissibili per una scala nominale?\nPuò avere senso calcolare la media di punteggi su una scala ordinale? Perché?\nSe hai misurato il tempo di reazione in secondi, quali operazioni aritmetiche puoi eseguire?\n\nEsercizio 4: Trasformazioni Ammissibili\nObiettivo: Comprendere le trasformazioni possibili per ogni scala di misurazione.\n\nSe una variabile è misurata su una scala nominale, quale tipo di trasformazione è consentita?\nPer una scala a intervalli, quali trasformazioni matematiche sono permesse senza alterare le proprietà della scala?\nQuale tipo di trasformazione è consentita su una scala di rapporti?\n\nEsercizio 5: Applicazione delle Scale a Dati Psicologici\nObiettivo: Applicare i concetti a contesti psicologici reali.\n\nUna scala di ansia clinica fornisce punteggi compresi tra 0 e 100. Quale livello di misurazione è più appropriato e perché?\nUn esperimento misura la memoria dichiarativa chiedendo ai partecipanti di ricordare un elenco di parole. Come dovrebbe essere misurata la variabile “numero di parole ricordate”?\nIn uno studio sulla personalità, i tratti vengono classificati come “estroverso” e “introverso”. Qual è il livello di misurazione?\n\nEsercizio 6: Valutazione della Scala di Misurazione\nObiettivo: Identificare la corretta scala di misurazione per vari fenomeni psicologici.\n\nIl livello di aggressività misurato su una scala da 1 a 5 è nominale, ordinale, intervalli o rapporti? Giustifica la tua risposta.\nIl numero di attacchi di panico in una settimana può essere considerato su scala ordinale? Perché sì o perché no?\nUn test di intelligenza misura il QI con una media di 100 e una deviazione standard di 15. Qual è il livello di misurazione e quali sono le implicazioni per l’analisi statistica?\n\nEsercizio 7: Costruzione di una Scala Psicologica\nObiettivo: Creare una scala di misurazione per una variabile psicologica.\n\nSe dovessi costruire una scala per misurare la resilienza, quale livello di misurazione sceglieresti e perché?\nCome potresti trasformare una scala nominale di preferenza musicale in una scala ordinale?\nUn questionario sulla qualità della vita chiede ai partecipanti di valutare la loro felicità su una scala da 1 a 10. È una scala a intervalli o ordinale? Giustifica.\n\nEsercizio 8: Interpretazione Statistica dei Dati\nObiettivo: Collegare il livello di misurazione alle tecniche statistiche appropriate.\n\nPerché una mediana è più appropriata della media per dati ordinali?\nQuale test statistico sarebbe più adatto per confrontare due gruppi su una variabile nominale?\nQuali analisi possono essere condotte su dati raccolti su una scala a rapporti?\n\nEsercizio 9: Misurazione e Inferenze Psicologiche\nObiettivo: Riflettere su come il livello di misurazione influisce sulle conclusioni di una ricerca.\n\nSe un test di personalità usa una scala Likert da 1 a 7, quali precauzioni devono essere prese nell’interpretare le differenze tra punteggi?\nUn questionario di benessere assegna punteggi tra 0 e 100, ma non ha uno zero assoluto. Quale scala è questa e quali sono le limitazioni?\nIn uno studio sulla depressione, i sintomi vengono codificati come “assenti”, “moderati” o “gravi”. Che tipo di scala è questa e quali statistiche possono essere usate per analizzarla?\n\nEsercizio 10: Esperimenti Psicologici e Misurazione\nObiettivo: Applicare la teoria della misurazione nella progettazione di esperimenti psicologici.\n\nSe un esperimento misura la memoria a breve termine con un compito di richiamo di parole, quale scala di misurazione utilizzeresti?\nCome la scelta della scala di misurazione può influenzare le inferenze che si possono trarre da un esperimento?\nQuali tipi di analisi statistica sono appropriati per dati misurati su scala ordinale rispetto a scala di rapporti?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Identificazione del Livello di Misurazione\nObiettivo: Comprendere i diversi livelli di misurazione applicati alla psicologia.\n\nIdentifica il livello di misurazione (nominale, ordinale, intervalli, rapporti) per ciascuna delle seguenti variabili psicologiche:\n\n\nNominale (Tipo di terapia psicologica è una classificazione senza ordine)\n\n\nOrdinale (Scala da 1 a 10, con ordine ma senza distanze uguali)\n\n\nRapporti (Numero di episodi depressivi ha uno zero assoluto e si possono fare rapporti tra valori)\n\n\nRapporti (Tempo di reazione ha uno zero assoluto e permette operazioni di rapporto)\n\n\n\nEsercizio 2: Confronto tra Scale\nObiettivo: Comprendere le differenze tra le scale di misurazione.\n\nLa scala ordinale fornisce un ordine ma non permette di calcolare differenze precise, mentre la scala a intervalli ha differenze costanti tra i valori. Ad esempio, “soddisfazione lavorativa” su una scala da 1 a 5 è ordinale, mentre il punteggio di un test psicologico è a intervalli.\nIl punteggio QI è a intervalli perché la differenza tra punteggi è significativa, ma non ha uno zero assoluto che rappresenta l’assenza di intelligenza.\nUna scala Likert misura il livello di accordo con una dichiarazione, quindi è generalmente considerata ordinale, nonostante sia trattata spesso come una scala a intervalli.\n\nEsercizio 3: Operazioni Aritmetiche Consentite\nObiettivo: Comprendere le operazioni matematiche consentite per ciascun livello di misurazione.\n\nNella scala nominale si può solo contare la frequenza delle categorie (ad es., il numero di partecipanti che usano un tipo di terapia).\nNo, la media su dati ordinali può essere fuorviante perché le distanze tra le categorie non sono necessariamente uguali. Meglio usare la mediana.\nSul tempo di reazione si possono eseguire tutte le operazioni aritmetiche, inclusa la media, la moltiplicazione e i rapporti tra valori.\n\nEsercizio 4: Trasformazioni Ammissibili\nObiettivo: Comprendere le trasformazioni possibili per ogni scala di misurazione.\n\nSulla scala nominale, solo le trasformazioni di ricodifica (ad esempio, cambiare i nomi delle categorie) sono permesse.\nPer una scala a intervalli, si possono effettuare trasformazioni lineari della forma y’ = a + by con b &gt; 0.\nPer una scala di rapporti, sono consentite trasformazioni di similarità della forma y’ = by, dove b &gt; 0.\n\nEsercizio 5: Applicazione delle Scale a Dati Psicologici\nObiettivo: Applicare i concetti a contesti psicologici reali.\n\nScala a intervalli, perché ha differenze costanti tra i punteggi ma nessuno zero assoluto.\nScala di rapporti, perché il numero di parole ricordate ha uno zero assoluto e consente operazioni di rapporto.\nNominale, perché non vi è un ordine gerarchico tra le categorie “estroverso” e “introverso”.\n\nEsercizio 6: Valutazione della Scala di Misurazione\nObiettivo: Identificare la corretta scala di misurazione per vari fenomeni psicologici.\n\nOrdinale, perché il livello di aggressività segue un ordine, ma le differenze tra i livelli non sono necessariamente uguali.\nNo, perché il numero di attacchi di panico è una variabile discreta e misurabile su scala di rapporti.\nIntervalli, perché il punteggio QI ha distanze costanti tra i valori, ma non ha uno zero assoluto.\n\nEsercizio 7: Costruzione di una Scala Psicologica\nObiettivo: Creare una scala di misurazione per una variabile psicologica.\n\nOrdinale o a intervalli, a seconda della precisione della misurazione della resilienza.\nSi potrebbe assegnare un valore numerico crescente alle categorie di preferenza musicale per ottenere una scala ordinale.\nÈ una scala ordinale, perché la differenza tra livelli non è necessariamente costante.\n\nEsercizio 8: Interpretazione Statistica dei Dati\nObiettivo: Collegare il livello di misurazione alle tecniche statistiche appropriate.\n\nPerché la mediana è meno sensibile ai valori estremi rispetto alla media.\nUn test chi-quadrato è adatto per confrontare frequenze di dati nominali tra gruppi.\nSi possono calcolare media, deviazione standard e utilizzare test parametrici come t-test o ANOVA.\n\nEsercizio 9: Misurazione e Inferenze Psicologiche\nObiettivo: Riflettere su come il livello di misurazione influisce sulle conclusioni di una ricerca.\n\nI punteggi Likert sono ordinali, quindi confronti tra differenze di punteggio devono essere interpretati con cautela.\nIntervalli, perché non ha uno zero assoluto, il che limita l’uso di operazioni moltiplicative.\nOrdinale, e si possono usare test non parametrici come il test di Kruskal-Wallis o il test di Mann-Whitney.\n\nEsercizio 10: Esperimenti Psicologici e Misurazione\nObiettivo: Applicare la teoria della misurazione nella progettazione di esperimenti psicologici.\n\nRapporti, perché il numero di parole ricordate è una variabile discreta con uno zero assoluto.\nSe si usa una scala ordinale, bisogna essere cauti nell’uso della media e della deviazione standard.\nScala ordinale → test non parametrici (Mann-Whitney); scala di rapporti → test parametrici (t-test, ANOVA).\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio 1 – Teoria Sostanziale e “Junk Science”\nObiettivo: Riconoscere il ruolo di una teoria sostanziale solida e comprendere come la sua assenza possa compromettere uno studio.\n\nLeggi la sezione in cui Gelman critica l’assenza di una teoria solida nello studio sulle pratiche mente-corpo.\n\nSpiega, in massimo 10 righe, perché secondo Gelman la mancanza di una teoria coerente rende i risultati del suddetto studio “poco significativi” o addirittura “junk science”.\n\nProponi un esempio ipotetico (non correlato al mind-body healing) di uno studio psicologico che, pur presentando dati numerosi e analizzati con metodi statistici sofisticati, risulti privo di una teoria solida. Descrivi sinteticamente perché questo potrebbe rientrare nel concetto di “junk science”.\n\nEsercizio 2 – Problemi di Misurazione\nObiettivo: Identificare le criticità più comuni nella misurazione dei fenomeni psicologici.\n\nElenca almeno tre possibili fattori confondenti che potrebbero influenzare la misurazione dell’efficacia di un intervento psicologico (ad esempio, l’effetto placebo, le aspettative dei partecipanti, ecc.).\n\nSpiega come questi fattori confondenti potrebbero compromettere la validità interna dello studio.\n\nIndica almeno due caratteristiche fondamentali che una buona scala di misurazione (per una variabile psicologica) dovrebbe possedere per essere ritenuta affidabile e valida.\n\nEsercizio 3 – Precisione e Bias\nObiettivo: Chiarire la distinzione tra precisione e distorsione (bias) e come questi aspetti si riflettano nella validità delle conclusioni.\n\nDefinisci, con parole tue, i concetti di precisione e bias in ambito psicometrico.\nFornisci un esempio concreto di uno strumento di misura preciso ma distorto (bias elevato) e di uno strumento poco preciso ma non distorto (bias basso).\n\nSpiega come la combinazione di scarsa precisione e alto bias possa influire sulla possibilità di trarre conclusioni affidabili in uno studio psicologico.\n\nEsercizio 4 – Validità Interna ed Esterna\nObiettivo: Approfondire come le scelte di misurazione influiscano sulla validità interna ed esterna di uno studio.\n\nIn riferimento allo studio sul mind-body healing discusso nel capitolo, identifica due fattori che potrebbero compromettere la validità interna e due fattori che potrebbero limitarne la validità esterna.\n\nDescrivi in 5-8 righe le differenze principali tra validità interna e validità esterna, utilizzando esempi presi sia dal contesto della guarigione mente-corpo sia da altri contesti psicologici (ad esempio, studi sull’apprendimento o sulla motivazione).\n\nProponi una modifica al disegno di ricerca (ipotetico) che potrebbe migliorare la validità interna dello studio originale. Spiega brevemente come questa modifica ne influenzerebbe anche la validità esterna.\n\nEsercizio 5 – Integrare Teoria e Misurazione: Breve Progetto di Ricerca\nObiettivo: Mettere in pratica i concetti di teoria e misurazione attraverso la progettazione di uno studio.\n\nImmagina di voler condurre uno studio su un intervento di “training di rilassamento mentale” finalizzato a ridurre l’ansia negli studenti universitari.\n\nSviluppa una breve traccia di progetto (massimo 15 righe) rispondendo ai seguenti punti:\n\nTeoria di base: Qual è la teoria sostanziale dietro l’efficacia del training di rilassamento? Quali meccanismi psicologici verrebbero attivati?\n\nIpotesi: Quale effetto prevedi sull’ansia degli studenti?\n\nMisurazione: Che tipo di strumento useresti per valutare il livello di ansia e perché (ad esempio, questionari self-report validati, misure fisiologiche come battito cardiaco, ecc.)?\n\nControllo dei confondenti: Quali variabili secondarie possono influire sui risultati e come intendi gestirle?\n\nValidità: Come assicureresti una buona validità interna? Che strategie adotteresti per aumentare la validità esterna?\n\nSpiega brevemente in che modo la combinazione di un solido quadro teorico e di una misurazione accurata permette di evitare che lo studio venga etichettato come “junk science”.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 1 – Teoria Sostanziale e “Junk Science”\n\nPerché la mancanza di una teoria solida rende i risultati poco significativi?\n\n\nGelman critica lo studio sul mind-body healing perché non vi è un modello teorico convincente che spieghi il meccanismo causale tra pratiche mente-corpo e miglioramenti di salute.\n\nSenza un quadro teorico robusto, i risultati sono interpretati in modo esplorativo e rischiano di essere attribuiti a variabili non controllate (effetto placebo, regressione alla media, ecc.).\n\nUna teoria ben formulata aiuta a delimitare le ipotesi, guidare il disegno di ricerca e interpretare correttamente i dati. In assenza di ciò, i numeri raccolti potrebbero essere viziati da fattori confondenti o da semplici correlazioni spurious.\n\n\n“Junk science” in massimo 10 righe\n\n\nEsempio di testo in 10 righe (circa)\n**Lo studio sul mind-body healing viene talvolta definito “junk science” da Gelman perché, in mancanza di una teoria sostanziale solida, i dati raccolti non forniscono indicazioni chiare sui processi psicologici o fisiologici coinvolti. Una ricerca classificata come “junk science” è priva di rigore metodologico o teorico, e può presentare gravi problemi di replicabilità o di interpretazione dei risultati. In particolare, se non vi è un modello plausibile che colleghi in modo coerente la pratica mente-corpo ai cambiamenti in variabili biologiche e comportamentali, i risultati empirici rischiano di essere semplici coincidenze. L’assenza di un costrutto ben definito e di ipotesi derivanti da una teoria coerente rende difficile capire se i cambiamenti osservati siano reali, casuali o dovuti ad altre cause non considerate (per esempio, l’effetto placebo). Infine, senza un’adeguata cornice teorica, gli studiosi non sanno come interpretare o generalizzare i dati, e la scienza non progredisce realmente.*\n\n\nEsempio di uno studio privo di teoria solida (ipotesi di “junk science”)\n\n\nSituazione ipotetica: Uno studio che raccoglie decine di variabili sulla personalità e sul benessere, poi usa tecniche statistiche sofisticate (analisi di big data, reti neurali, ecc.) per trovare correlazioni fra i tratti di personalità e centinaia di indicatori fisici.\nPerché “junk science”: Se lo studio non definisce a priori quali ipotesi testare e non ha una teoria chiara che spieghi perché certe caratteristiche di personalità dovrebbero correlarsi con determinati parametri fisici, i risultati trovati potrebbero essere frutto di coincidenze casuali. Inoltre, in assenza di un modello teorico solido, anche risultati statisticamente significativi possono essere privi di significato dal punto di vista psicologico.\n\nEsercizio 2 – Problemi di Misurazione\n\nTre possibili fattori confondenti nell’efficacia di un intervento psicologico\n\n\nEffetto placebo: I partecipanti migliorano perché si aspettano di migliorare, non per l’effettiva efficacia dell’intervento.\n\nAspettative dei partecipanti: Se sanno di partecipare a uno studio, potrebbero modificare il proprio comportamento (effetto Hawthorne).\n\nDesiderabilità sociale: I partecipanti forniscono risposte che ritengono socialmente desiderabili, falsando i risultati (ad esempio, sottostimando i livelli di ansia o stress).\n\n\nCome questi fattori confondenti compromettono la validità interna\n\n\nLa validità interna riguarda il grado in cui è possibile concludere che sia effettivamente la variabile indipendente (l’intervento) a causare le modifiche osservate nella variabile dipendente (es. livelli di ansia).\n\nSe subentrano l’effetto placebo, aspettative non controllate o tendenze alla desiderabilità sociale, diventa difficile stabilire un nesso causale chiaro. Esiste sempre il dubbio che altri processi cognitivi o sociali (non l’intervento in sé) abbiano prodotto il risultato.\n\n\nDue caratteristiche fondamentali di una buona scala di misurazione\n\n\nAffidabilità: Capacità dello strumento di fornire misure stabili e coerenti nel tempo (ad esempio, coerenza interna, stabilità test-retest).\n\nValidità: Capacità dello strumento di misurare effettivamente ciò che si propone di misurare (validità di contenuto, di costrutto, di criterio).\n\nEsercizio 3 – Precisione e Bias\n\nDefinizioni di precisione e bias\n\n\nPrecisione: Indica il grado di dispersione (o variabilità) delle misurazioni. Uno strumento preciso produce misure molto simili fra loro se ripetute nelle stesse condizioni (bassa varianza).\n\nBias (distorsione): Indica l’errore sistematico, ossia la tendenza a sovra- o sottostimare sistematicamente il fenomeno in esame. Uno strumento può essere molto coerente nelle misure, ma se è “tarato” male, darà sempre un risultato distorto.\n\n\nEsempio concreto di misura “precisa ma distorta” e “poco precisa ma non distorta”\n\n\nPrecisa ma distorta: Un cronometro che, a causa di un difetto di fabbricazione, parte sempre con 2 secondi di ritardo ma poi misura i tempi con estrema coerenza. Risultato: tutte le misure saranno molto simili (alta precisione), ma sempre sfasate di 2 secondi (alto bias).\n\nPoco precisa ma non distorta: Un termometro vecchio che a volte segna 36,2°C, altre 36,7°C, altre 37,1°C, senza un pattern sistematico. In media potrebbe risultare vicino ai 36,5°C, quindi senza un bias chiaro, ma con un’alta variabilità tra una misurazione e l’altra (bassa precisione).\n\n\nConseguenze di scarsa precisione e alto bias\n\n\nSe uno strumento è poco preciso (alta variabilità) e altamente distorto (bias elevato), i risultati ottenuti non solo oscillano in modo imprevedibile, ma sono costantemente lontani dal valore “vero”.\n\nIn queste condizioni, le conclusioni diventano inaffidabili, poiché è quasi impossibile distinguere l’effetto reale (casuale o causale) dalle deformazioni introdotte dallo strumento e dall’errore di misura.\n\nEsercizio 4 – Validità Interna ed Esterna\n\nDue fattori che compromettono la validità interna e due fattori che compromettono la validità esterna (nell’esempio del mind-body healing)\n\n\nValidità interna:\n\nAssegnazione non casuale ai gruppi: se i partecipanti scelgono autonomamente di aderire alle pratiche mente-corpo, potrebbero essere più motivati o avere caratteristiche iniziali diverse.\n\nMancata o inadeguata gestione dell’effetto placebo: non sapere se l’intervento “mente-corpo” sia stato percepito come particolarmente “speciale” dai partecipanti può introdurre differenze di aspettativa.\n\nValidità esterna:\n\nCampione non rappresentativo: se lo studio è condotto solo su persone che frequentano un determinato tipo di centro di benessere, i risultati potrebbero non essere generalizzabili all’intera popolazione.\n\nContesto specifico: pratiche mente-corpo svolte in un ambiente estremamente controllato (es. un laboratorio o un ritiro speciale) potrebbero non replicarsi nella vita quotidiana di chiunque.\n\n\n\nDifferenze tra validità interna ed esterna (5-8 righe di esempio)\n\n\nLa validità interna si riferisce alla correttezza del disegno di ricerca nel dimostrare un effetto causale. Un alto livello di validità interna implica che i ricercatori siano ragionevolmente sicuri che l’intervento (ad esempio, una tecnica mente-corpo) abbia causato i risultati osservati (miglioramento della salute). La validità esterna, invece, riguarda la possibilità di generalizzare i risultati a contesti, persone e tempi differenti. Se un intervento è stato testato in condizioni molto specifiche, potrebbe funzionare bene solo in quel contesto e con quel particolare campione. Per esempio, un intervento sul mind-body healing con individui altamente motivati potrebbe non dare gli stessi risultati in una popolazione generalizzata. Allo stesso modo, uno studio sull’apprendimento condotto in un laboratorio altamente controllato potrebbe non riflettere le reali dinamiche di un’aula scolastica.\n\n\nModifica al disegno di ricerca per migliorare la validità interna e conseguenze sulla validità esterna\n\n\nProposta: Introdurre un gruppo di controllo con un intervento placebo o un’attività simile ma priva di contenuto “mente-corpo” (ad es. sessioni di lettura rilassante). In questo modo, si può confrontare l’effetto “specífico” dell’intervento.\nCome influenza la validità interna: Con un gruppo di controllo placebo, diventa più semplice escludere che il miglioramento sia dovuto solo alle aspettative dei partecipanti. Questo riduce il rischio di confondenti e aumenta la validità interna.\nCome influenza la validità esterna: Potrebbe rendere il contesto dello studio più artificiale (un gruppo fa “meditazione”, l’altro legge in silenzio), il che potrebbe ridurre la naturalezza della situazione e potenzialmente limitare la generalizzabilità ad ambienti reali (validità esterna).\n\nEsercizio 5 – Integrare Teoria e Misurazione: Breve Progetto di Ricerca\n\nBreve traccia di progetto: “Training di rilassamento mentale per ridurre l’ansia negli studenti universitari”\n\n\nTeoria di base\nIl training di rilassamento mentale si fonda sul presupposto teorico che le tecniche di riduzione dello stress (es. respirazione consapevole, rilassamento muscolare progressivo) possano agire sui livelli di attivazione fisiologica e sui pensieri intrusivi. Riducendo l’iperattivazione del sistema nervoso simpatico e favorendo uno stato di calma, diminuisce l’ansia percepita.\nIpotesi\nGli studenti che seguono il training di rilassamento per 4 settimane mostreranno una riduzione significativa nei punteggi di ansia, rispetto a un gruppo di controllo che non partecipa al training.\nMisurazione\nUtilizzo di una scala validata come lo STAI (State-Trait Anxiety Inventory) per misurare il livello di ansia pre e post intervento. Possibile integrazione con misure fisiologiche (battito cardiaco a riposo) per avere dati oggettivi.\nControllo dei confondenti\n\nRegistrare la storia clinica dei partecipanti (per escludere coloro che assumono farmaci ansiolitici).\n\nRichiedere che i partecipanti non modifichino drasticamente le proprie abitudini di studio o di vita durante l’intervento.\n\nAssicurarsi che i valutatori non sappiano chi fa parte del gruppo di training o del gruppo di controllo (blinding parziale).\n\nValidità\n\nValidità interna: Uso di un gruppo di controllo e assegnazione casuale (randomizzazione) per assicurare che i due gruppi siano comparabili.\n\nValidità esterna: Inclusione di studenti provenienti da diverse facoltà, così da riflettere una maggiore eterogeneità di popolazione.\n\n\n\nCome teoria solida e misurazione accurata evitano la “junk science”\n\n\nUna solida cornice teorica spiega i meccanismi psicologici e fisiologici che legano l’intervento (training di rilassamento) all’esito (riduzione dell’ansia).\n\nUna misurazione accurata e validata (STAI, misure fisiologiche) riduce errori e distorsioni. Se le misure sono ripetute nel tempo (pre e post), si possono confrontare i cambiamenti effettivi.\n\nIntegrando teoria e misurazione, i risultati assumono un significato scientifico più robusto. Non basta osservare un miglioramento: occorre dimostrare come e perché tale miglioramento avvenga, evitando di cadere in semplici correlazioni prive di spiegazione (e quindi potenzialmente “junk science”).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 – Trasformazioni in Scala Nominale\nSituazione\nUn ricercatore vuole indagare la percezione di appartenenza sociale tra studenti universitari di Psicologia. A ciascuno studente viene chiesto di rispondere alla domanda: “Qual è il gruppo studentesco a cui ritieni di appartenere maggiormente?”, scegliendo una tra le seguenti categorie:\n\n\nGruppo A (focalizzato su ricerca e studio)\n\n\n\nGruppo B (focalizzato su attività ricreative)\n\n\n\nGruppo C (focalizzato su volontariato e progetti sociali)\n\n\nIstruzioni\n\nIdentifica la scala di misurazione utilizzata per classificare gli studenti (nominale, ordinale, a intervalli o di rapporti).\n\nIndica quali trasformazioni sono ammissibili su questa scala e spiega perché non è possibile applicare operazioni di tipo aritmetico (somme, differenze, etc.).\n\nProponi un esempio di nuova scala nominale equivalente, ossia una nuova denominazione delle categorie che rispetti la suddivisione originale. (Esempio: rinominarle in Gruppo X, Gruppo Y, Gruppo Z, oppure usare colori, animali-simbolo, ecc.). Spiega perché questa trasformazione non altera i risultati dell’indagine.\n\nEsercizio 2 – Trasformazioni in Scala Ordinale\nSituazione\nIn un questionario sul benessere psicologico, agli studenti viene chiesto di classificare il loro stato di motivazione allo studio su una scala da 1 (bassa motivazione) a 5 (alta motivazione). Si ottiene così un dato ordinalmente misurato.\nIstruzioni\n\nSpiega perché tale variabile (“livello di motivazione”) rappresenta una scala ordinale. Quali proprietà la rendono diversa da una semplice scala nominale?\n\nDescrivi in che modo è possibile ridenominare i valori della scala (ad esempio, da [1,2,3,4,5] a [“Molto bassa”, “Bassa”, “Media”, “Alta”, “Molto alta”]) senza alterare il rapporto d’ordine tra le categorie.\n\nProponi un esempio di trasformazione non ammissibile: qual è un’operazione aritmetica che non avrebbe senso applicare su una scala ordinale e perché (ad esempio, calcolare “il doppio di motivazione”)?\n\nEsercizio 3 – Trasformazioni in Scala ad Intervalli\nSituazione\nUn gruppo di ricercatori in Psicometria vuole confrontare i punteggi di un test d’intelligenza (misurati secondo la scala tradizionale del QI, con media 100 e deviazione standard 15) con un nuovo test sperimentale. Come ben noto, la scala del QI è considerata, nelle sue approssimazioni psicometriche, una scala ad intervalli.\nIstruzioni\n\nSpiega in cosa consiste la trasformazione lineare ammessa (del tipo \\(y' = a + b y\\), con \\(b &gt; 0\\)) e perché tale trasformazione preserva le differenze tra i punteggi.\n\nFai un esempio concreto di trasformazione lineare: supponi di voler “riscalare” i punteggi del QI in modo che la nuova media sia 50. Definisci i valori di \\(a\\) e \\(b\\) (indicando un’ipotesi di calcolo) e mostra come viene modificato il punteggio di un individuo con QI = 115.\n\nDiscuta perché, nonostante la somiglianza con le scale ordinale e nominale (puoi comunque distinguere punteggi e ordinarli), una scala ad intervalli consente operazioni matematiche più complesse (ad esempio, differenze) che non sarebbero valide negli altri due livelli.\n\nEsercizio 4 – Trasformazioni in Scala di Rapporti\nSituazione\nUn laboratorio di psicofisiologia misura i tempi di reazione (in millisecondi) a uno stimolo luminoso. Poiché il tempo di reazione pari a 0 ms significa realmente assenza di risposta (ovvero, impossibile da misurare in pratica, ma concettualmente corrisponde a intensità nulla del fenomeno “tempo di reazione”), ci troviamo in una scala di rapporti.\nIstruzioni\n\nSpiega perché il tempo di reazione soddisfa i requisiti di una scala di rapporti, inclusa la presenza di uno zero assoluto e la possibilità di confrontare i punteggi con rapporti (ad esempio, “il tempo di reazione del partecipante A è il doppio di quello del partecipante B”).\n\nQuali sono le trasformazioni ammissibili su una scala di rapporti? Fornisci un esempio numerico (per esempio, se moltiplichi tutti i tempi di reazione per 2, che cosa accade al rapporto tra i punteggi di due partecipanti?).\n\nDescrivi il motivo per cui è possibile dire che A ha una latenza doppia di B usando i millisecondi, ma non è sempre possibile fare asserzioni analoghe usando scale ad intervalli. Fai un parallelo, ad esempio, con le temperature in Celsius.\n\nEsercizio 5 – Riconoscere e Applicare le Trasformazioni nei Quattro Livelli di Scala\nSituazione\nUn docente di Psicologia sperimentale ha raccolto quattro serie di dati su vari aspetti:\n\nOrientamento politico (liberale, conservatore, centrista, ecc.).\n\nClassifica di soddisfazione sul tirocinio (1° posto, 2° posto, 3° posto, etc.).\n\nPunteggi di un test di personalità su un fattore (con media = 100, deviazione standard = 10) trattato come scala ad intervalli.\n\nFrequenza cardiaca a riposo misurata in battiti al minuto (bpm).\n\nIstruzioni\n\nIdentifica per ciascuno dei quattro insiemi di dati il livello di scala (nominale, ordinale, intervalli, rapporti).\n\nPer ognuno dei quattro livelli di scala elenca almeno una trasformazione ammessa (ad es. ridenominazione delle categorie per la nominale, traslazione e dilatazione per l’intervalli, ecc.) e una non ammessa (esempio: non puoi sommare categorie nominali, non puoi calcolare la radice quadrata di un rango ordinale dandogli significato, ecc.).\n\nRifletti in breve (2-3 righe) su come queste differenze nelle trasformazioni ammissibili incidano sull’interpretazione dei dati e sulle analisi statistiche che il docente potrà validamente utilizzare (ad esempio, test non parametrici per variabili ordinarie, test parametrici per scale ad intervalli/rapporti).\n\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nEsercizio 1 – Trasformazioni in Scala Nominale\n\nIdentificazione della scala La classificazione degli studenti in “Gruppo A/B/C” è scala nominale. Non esiste alcun ordine intrinseco tra le categorie; si tratta semplicemente di etichette qualitative.\nTrasformazioni ammissibili\n\n\nTrasformazioni ammissibili: ridenominare o rinominare le categorie senza modificare la partizione del campione (esempio: A → “Studio”, B → “Ricreazione”, C → “Volontariato”).\n\nL’unica operazione aritmetica consentita è il conteggio delle frequenze nelle varie categorie.\n\n\nOperazioni non consentite: non è possibile sommare o sottrarre etichette, né confrontare categorie in termini di “più/meno grande” o “rapporto”.\n\n\nEsempio di nuova scala nominale equivalente\n\n\nPotresti chiamare i gruppi: “Alpha, Beta, Gamma” (oppure con colori: “Rosso, Blu, Verde”).\n\nQuesta trasformazione non altera la classificazione in sé: tutti gli studenti del Gruppo A rimangono nel “nuovo” gruppo Alpha, e così via.\n\nNon cambia la struttura dei dati e di conseguenza non altera i risultati della ricerca (restano invariate le frequenze e la suddivisione nelle categorie).\n\nEsercizio 2 – Trasformazioni in Scala Ordinale\n\nPerché è una scala ordinale? La variabile “livello di motivazione” da 1 (bassa) a 5 (alta) indica:\n\n\nClassificazione in categorie (come in una scala nominale).\n\nRelazione d’ordine chiara (1 &lt; 2 &lt; 3 &lt; 4 &lt; 5).\n\nNon fornisce alcuna informazione sulle distanze reali tra i punti (non è detto che la differenza tra 1 e 2 sia uguale a quella tra 3 e 4).\nÈ quindi una scala ordinale e non semplicemente nominale.\n\n\nRidenominazione dei valori mantenendo l’ordine\n\n\nPuoi sostituire i numeri con etichette testuali rispettando lo stesso ordine:\n1 → “Molto bassa”\n2 → “Bassa”\n3 → “Media”\n4 → “Alta”\n5 → “Molto alta”\n\nL’ordine rimane lo stesso: “Molto bassa” &lt; “Bassa” &lt; … &lt; “Molto alta”.\n\n\nEsempio di trasformazione non ammissibile\n\n\nCalcolare “il doppio di motivazione”: dire che la categoria 4 è “il doppio” della categoria 2 non ha senso, perché non c’è un’unità di misura fissa che quantifichi la differenza tra i livelli. Le categorie ordinali servono solo a ordinare, non a quantificare in modo assoluto.\n\nEsercizio 3 – Trasformazioni in Scala ad Intervalli\n\nTrasformazione lineare ammessa\n\n\nForma generale: \\(y' = a + b y\\), con \\(b &gt; 0\\).\n\nPreserva le differenze tra i valori (ad esempio, \\((y_2 - y_1) = (y'_2 - y'_1) / b\\)), perché la traslazione aggiunge una costante a tutti i punteggi e la dilatazione (moltiplicazione per \\(b\\)) mantiene le proporzioni fra gli intervalli.\n\n\nEsempio concreto\n\n\nScala QI: media = 100, deviazione standard = 15.\n\nVuoi che la nuova media sia 50.\n\nPer semplificare, supponiamo di voler “spostare” ogni valore verso una nuova scala centrata a 50, mantenendo una deviazione standard proporzionale.\n\nUna possibile trasformazione lineare:\n\\[\n  y' = (y - 100) + 50 = y - 50.\n\\]\nIn questo caso, \\(a = -50\\), \\(b = 1\\).\n\nSe un individuo ha QI = 115, allora \\(y' = 115 - 50 = 65\\).\n\n\nSe invece volessi anche cambiare la deviazione standard, potresti usare un fattore \\(b \\neq 1\\). Ad esempio, se desideri una deviazione standard = 10, potresti usare \\(b = \\frac{10}{15} \\approx 0.67\\).\n\n\nDifferenze rispetto alle scale nominali/ordinali\n\n\nCon una scala ad intervalli puoi:\n\nOrdinare i punteggi.\n\nStabilire differenze (es. un individuo A ha 15 punti in più di B).\n\n\nNon puoi invece stabilire rapporti (es. “A ha il doppio di X rispetto a B” non è lecito), perché lo zero è arbitrario e la distanza “0” non rappresenta l’assenza del fenomeno (come invece avviene nella scala di rapporti).\n\nEsercizio 4 – Trasformazioni in Scala di Rapporti\n\nPerché il tempo di reazione è in una scala di rapporti?\n\n\nZero assoluto: un tempo di reazione (teoricamente) pari a 0 ms significherebbe nessun tempo trascorso → totale assenza del fenomeno misurato (impossibile nella pratica, ma concettualmente definisce uno zero non arbitrario).\n\nPuoi confrontare i punteggi con rapporti: “il tempo di reazione di A è il doppio di quello di B” (200 ms vs. 100 ms).\n\n\nTrasformazioni ammissibili\n\n\nTrasformazione di similarità: \\(y' = b y\\) con \\(b &gt; 0\\).\n\nSe hai due tempi di reazione \\(y_1\\) e \\(y_2\\), il rapporto \\(\\frac{y_1}{y_2}\\) rimane invariato anche dopo la trasformazione:\n\\[\n  \\frac{y'_1}{y'_2} = \\frac{b y_1}{b y_2} = \\frac{y_1}{y_2}.\n\\]\nEsempio numerico: se i tempi di reazione di due partecipanti sono 100 ms e 200 ms, il rapporto è 2. Se moltiplichi entrambi per 2, ottieni 200 ms e 400 ms, e il rapporto rimane 2.\n\n\nConfronto con scala ad intervalli (esempio delle temperature)\n\n\nIn una scala di rapporti puoi dire “A ha una latenza doppia di B” perché lo zero non è arbitrario.\n\nCon la temperatura (scala ad intervalli) lo zero (es. 0°C) non rappresenta l’assenza di calore, quindi non ha senso dire che 80°C è “il doppio” di 40°C. Cambiando la scala (ad es. Fahrenheit) il rapporto cambia.\n\nEsercizio 5 – Riconoscere e Applicare le Trasformazioni nei Quattro Livelli di Scala\n\nIdentificazione del livello di scala\n\n\nOrientamento politico: scala nominale (categorie qualitative prive di ordine).\n\nClassifica di soddisfazione (1°, 2°, 3°, …): scala ordinale (c’è un ordine, ma non si conosce la “distanza” fra i posti).\n\nPunteggi di un test di personalità (con media=100, dev.st=10), considerati approssimazione di una scala ad intervalli (si assumono le differenze significative, lo zero è arbitrario).\n\nFrequenza cardiaca a riposo (bpm): scala di rapporti (zero assoluto e rapporti confrontabili).\n\n\nTrasformazioni ammesse e non ammesse\n\n\nNominale:\n\nAmmessa: cambiare etichette (A → “Liberale”, B → “Conservatore” ecc.).\n\nNon ammessa: sommare categorie, ordinare, calcolare media delle categorie.\n\n\nOrdinale:\n\nAmmessa: rietichettare i ranghi (1° → “Migliore”, 2° → “Secondo posto”…).\n\nNon ammessa: calcolare rapporti (il 2° posto non è “il doppio” del 1°), sommare posizioni in modo significativo.\n\n\nA intervalli:\n\nAmmessa: trasformazione lineare (traslazione + dilatazione).\n\nNon ammessa: dire che un punteggio è “tre volte” un altro; lo zero è arbitrario.\n\n\nA rapporti:\n\nAmmessa: trasformazione di similarità (\\(y' = b y\\)), in cui i rapporti rimangono invariati.\n\nNon ammessa: aggiunta di una costante a tutti i valori (questa sposterebbe lo zero, rendendolo arbitrario e trasformando la scala in una scala ad intervalli).\n\n\n\nImplicazioni per l’interpretazione e le analisi\n\n\nUna variabile nominale consente solo frequenze e test non parametrici basati su conteggi (es. Chi-quadrato).\n\nUna variabile ordinale permette test di ordinamento (es. test di rank, come il Wilcoxon), ma non calcoli di media con significato forte.\n\nUna scala ad intervalli permette di usare statistiche parametriche (calcolo di media, varianza, test come t-test, ANOVA), assumendo che l’interpretazione delle differenze sia coerente.\n\nUna scala di rapporti permette, in più, il confronto di rapporti (ad esempio, si possono applicare modelli parametrici che includano il concetto di proporzioni o slope logico su dati che abbiano senso a zero assoluto).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#bibliografia",
    "href": "chapters/key_notions/04_measurement.html#bibliografia",
    "title": "3  La misurazione in psicologia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nLilienfeld, S. O., & Strother, A. N. (2020). Psychological measurement and the replication crisis: Four sacred cows. Canadian Psychology/Psychologie Canadienne, 61(4), 281–288.\n\n\nMaul, A., Irribarra, D. T., & Wilson, M. (2016). On the philosophical foundations of psychological measurement. Measurement, 79, 311–320.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html",
    "href": "chapters/key_notions/05_data_analysis.html",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "",
    "text": "Introduzione\nNegli ultimi vent’anni, le scienze sociali e la psicologia hanno vissuto una profonda trasformazione metodologica ed epistemologica. Questo cambiamento, spesso definito come “Credibility Revolution” (Angrist & Pischke, 2010), “Causal Revolution” (Pearl & Mackenzie, 2018) e “Replication Crisis” (Collaboration, 2015; Nosek et al., 2022), ha portato a un ripensamento delle pratiche di ricerca, specialmente in psicologia (Korbmacher et al., 2023). Questa transizione verso quella che Munger (2023) chiama “Science versione 2” è stata motivata dalla consapevolezza di lacune metodologiche passate e ha spinto verso l’adozione di approcci più rigorosi e replicabili.\nLe origini di questa riforma risiedono nel riconoscimento di problemi metodologici diffusi, come la proliferazione di falsi positivi (Simmons et al., 2011), l’abuso dei “gradi di libertà dei ricercatori” (Gelman & Loken, 2013), e l’inadeguatezza delle pratiche statistiche tradizionali (Gelman & Loken, 2014). Fenomeni come il p-hacking, l’uso di campioni di piccole dimensioni (Button et al., 2013), e la mancanza di trasparenza nei metodi di ricerca hanno contribuito a minare la credibilità delle scoperte psicologiche (Ioannidis, 2005; Meehl, 1967), portando alla cosiddetta “Replication Crisis” (Baker, 2016; Bishop, 2019) — si veda il Capitolo 73.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html#lapproccio-bayesiano",
    "href": "chapters/key_notions/05_data_analysis.html#lapproccio-bayesiano",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "4.1 L’Approccio Bayesiano",
    "text": "4.1 L’Approccio Bayesiano\nIn risposta a queste sfide, l’approccio bayesiano è emerso come un paradigma statistico chiave nella “Credibility Revolution”. A differenza dell’inferenza frequentista, che si basa sul Test dell’Ipotesi Nulla, la statistica bayesiana offre un framework più flessibile e intuitivo per l’analisi dei dati e l’inferenza causale. Il principio fondamentale dell’approccio bayesiano è l’aggiornamento delle distribuzioni di probabilità a priori (priors) alla luce di nuove evidenze, un processo che si allinea con l’obiettivo di una scienza cumulativa e auto-correttiva.\nL’adozione di metodi bayesiani in psicologia presenta numerosi vantaggi:\n\nQuantificazione dell’incertezza: L’inferenza bayesiana fornisce distribuzioni di probabilità posteriori complete per i parametri di interesse, offrendo una rappresentazione più ricca e sfumata dell’incertezza rispetto agli intervalli di confidenza frequentisti.\nIncorporazione di conoscenze pregresse: Le priors bayesiane permettono di integrare formalmente conoscenze precedenti nel processo inferenziale, promuovendo un approccio cumulativo alla ricerca.\nRobustezza alle pratiche di ricerca discutibili: I metodi bayesiani sono meno suscettibili a pratiche come il p-hacking, poiché l’inferenza si basa sull’intera distribuzione posteriore piuttosto che su soglie arbitrarie di significatività.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html#lapproccio-bayesiano-nella-ricerca-psicologica",
    "href": "chapters/key_notions/05_data_analysis.html#lapproccio-bayesiano-nella-ricerca-psicologica",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "4.2 L’Approccio Bayesiano nella Ricerca Psicologica",
    "text": "4.2 L’Approccio Bayesiano nella Ricerca Psicologica\nL’uso delle statistiche bayesiane nella ricerca psicologica offre vantaggi significativi rispetto ai metodi statistici tradizionali, come il test di significatività dell’ipotesi nulla. Uno dei punti di forza principali è la sua indipendenza dalla teoria dei grandi campioni, rendendolo particolarmente adatto per studi che spesso si basano su campioni di dimensioni ridotte (Larson et al., 2023).\nLa ricerca psicologica è spesso caratterizzata da campioni limitati, dovuti a fattori come la bassa prevalenza di determinate condizioni, difficoltà nel reclutamento dei partecipanti e complessità nelle procedure di valutazione. Questi campioni di piccole dimensioni sono intrinsecamente soggetti a una maggiore eterogeneità, che si manifesta nella variabilità del fenotipo comportamentale delle condizioni psicologiche esaminate e nella discrepanza tra le stime degli effetti in diversi studi. Tale eterogeneità può portare a stime degli effetti distorte e scarsamente riproducibili.\nL’approccio bayesiano offre una soluzione efficace a queste problematiche. In primo luogo, consente di valutare l’adeguatezza della dimensione del campione attraverso un’analisi della sensibilità dei risultati rispetto alla specificazione delle distribuzioni a priori. In secondo luogo, permette di ottenere risultati precisi anche con campioni ridotti, a condizione che le conoscenze a priori siano accurate e ben definite.\nUn ulteriore vantaggio è la capacità dell’approccio bayesiano di ottimizzare l’uso dei campioni di partecipanti, favorendo un’inclusione equa delle popolazioni diversificate. Questo è particolarmente rilevante per gruppi spesso sottorappresentati, come le minoranze etniche. Le statistiche bayesiane aiutano a superare questa sfida evitando di esercitare una pressione eccessiva su questi gruppi per aumentarne la partecipazione, permettendo così una ricerca più equa e rappresentativa.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html#modellazione-formale-e-data-science",
    "href": "chapters/key_notions/05_data_analysis.html#modellazione-formale-e-data-science",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "4.3 Modellazione Formale e Data Science",
    "text": "4.3 Modellazione Formale e Data Science\nLa “Credibility Revolution” ha favorito l’integrazione della Data Science nelle pratiche di ricerca psicologica. L’adozione di pipeline di analisi dei dati riproducibili, l’uso di controllo di versione e la condivisione di dati e codice sono diventati standard de facto nella comunità scientifica. Questi strumenti non solo migliorano la trasparenza e la replicabilità della ricerca, ma facilitano anche la collaborazione e l’accumulo di conoscenze nel campo.\nParallelamente, si è osservato un rinnovato interesse per la modellazione formale in psicologia, che consente non solo la verifica ma anche lo sviluppo di modelli dei meccanismi sottostanti ai fenomeni psicologici (Oberauer & Lewandowsky, 2019; Van Dongen et al., 2024). Questo approccio supera la mera descrizione delle associazioni tra variabili, tipica della pratica dominante dell’ANOVA nel contesto pre-riforma.\nLa modellazione bayesiana si presta particolarmente bene a questo approccio, offrendo un framework unificato per la specificazione di modelli formali, l’incorporazione di incertezza parametrica e la valutazione dell’evidenza empirica. Attraverso tecniche come il confronto tra modelli bayesiano e l’analisi di sensibilità, i ricercatori possono valutare rigorosamente la plausibilità relativa di diverse teorie psicologiche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html#riflessioni-epistemologiche",
    "href": "chapters/key_notions/05_data_analysis.html#riflessioni-epistemologiche",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "4.4 Riflessioni Epistemologiche",
    "text": "4.4 Riflessioni Epistemologiche\nL’adozione di metodi bayesiani e della Data Science in psicologia deve essere accompagnata da una profonda riflessione epistemologica. Come sottolineato da George Box:\n\nTutti i modelli sono sbagliati, ma alcuni sono utili.\n\nQuesta massima risuona particolarmente nel contesto della ricerca psicologica, dove i fenomeni di interesse sono spesso complessi e multifattoriali.\nL’approccio bayesiano, con la sua enfasi sull’aggiornamento iterativo delle credenze alla luce di nuove evidenze, si allinea naturalmente con una visione della scienza come processo di apprendimento continuo piuttosto che come ricerca di verità assolute. Questa prospettiva riconosce i limiti intrinseci dei nostri modelli e delle nostre teorie, pur valorizzandone l’utilità euristica e predittiva.\nIn particolare, McElreath (2020) sottolinea l’importanza di riconoscere la dualità tra il “mondo del modello” e il mondo reale più ampio che cerchiamo di comprendere. Questa consapevolezza è cruciale per evitare la reificazione dei nostri modelli statistici e per mantenere una prospettiva critica sulle nostre inferenze.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html#riflessioni-conclusive",
    "href": "chapters/key_notions/05_data_analysis.html#riflessioni-conclusive",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "4.5 Riflessioni Conclusive",
    "text": "4.5 Riflessioni Conclusive\nL’integrazione dell’approccio bayesiano e della Data Science nella ricerca psicologica rappresenta una risposta promettente alle sfide poste dalla “Replication Crisis”. Offrendo un framework coerente per la modellazione formale, l’inferenza statistica e l’incorporazione di conoscenze pregresse, questi approcci promettono di elevare il rigore e la credibilità della ricerca psicologica. Tuttavia, è fondamentale che l’adozione di questi metodi sia accompagnata da una adeguata consapevolezza metodologica ed epistemologica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html#esercizi",
    "href": "chapters/key_notions/05_data_analysis.html#esercizi",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQuali sono i principali fattori che hanno portato alla “Credibility Revolution” in psicologia e in che modo le nuove metodologie — in particolare l’approccio bayesiano e le buone pratiche di Data Science — mirano a superare i limiti che hanno contribuito alla “Replication Crisis”?\nIn che modo il paradigma bayesiano differisce dall’approccio frequentista nella gestione dell’incertezza e nell’aggiornamento della conoscenza, e quali vantaggi pratici offre quando si lavora con campioni di piccole dimensioni e popolazioni eterogenee?\nQual è il ruolo delle distribuzioni a priori nelle analisi bayesiane e come ci si assicura che l’uso di priors non introduca bias indesiderati, specialmente in un contesto come quello psicologico dove le teorie e i dati pregressi possono essere incompleti o controversi?\nPerché la modellazione formale e le buone pratiche di Data Science (ad es. condivisione di codice, controllo di versione, pipeline riproducibili) risultano fondamentali per una scienza cumulativa e per mitigare gli errori sistematici nella ricerca psicologica?\nDal punto di vista epistemologico, in che modo il principio “tutti i modelli sono sbagliati, ma alcuni sono utili” influenza la costruzione, la valutazione e l’interpretazione dei modelli in psicologia, e come si integra con la prospettiva bayesiana di scienza come processo iterativo di apprendimento?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sono i principali fattori che hanno portato alla “Credibility Revolution” in psicologia e in che modo le nuove metodologie — in particolare l’approccio bayesiano e le buone pratiche di Data Science — mirano a superare i limiti che hanno contribuito alla “Replication Crisis”?\nNegli ultimi decenni, la psicologia ha attraversato una “Replication Crisis” a causa di diverse pratiche di ricerca problematiche, tra cui l’utilizzo di campioni di piccole dimensioni, l’uso eccessivo di test di significatività frequentisti con p &lt; .05 come soglia rigida, il fenomeno del p-hacking (cioè l’adattamento delle analisi per ottenere risultati “significativi”), e la carenza di trasparenza e condivisione dei dati. Questi fattori hanno portato alla pubblicazione di molti falsi positivi e a un’erosione della fiducia nelle conclusioni psicologiche.\nLa “Credibility Revolution” nasce dalla presa di coscienza di questi problemi e dall’introduzione di nuove metodologie che offrono maggior rigore e trasparenza. L’approccio bayesiano, in particolare, consente di superare alcuni limiti della statistica frequentista, poiché fornisce distribuzioni posteriori di plausibilità per i parametri e non si affida a soglie arbitrarie di significatività. Inoltre, la Data Science ha promosso la diffusione di pipeline analitiche riproducibili (tramite il controllo di versione, la condivisione del codice e dei dati), contribuendo a ridurre errori, bias e a favorire la replicabilità. Insieme, queste innovazioni mirano a creare una scienza più aperta, solida e cumulativa.\n2. In che modo il paradigma bayesiano differisce dall’approccio frequentista nella gestione dell’incertezza e nell’aggiornamento della conoscenza, e quali vantaggi pratici offre quando si lavora con campioni di piccole dimensioni e popolazioni eterogenee?\nIl paradigma frequentista si basa sull’idea di ripetizione ipotetica degli esperimenti e sull’applicazione di test di significatività, focalizzandosi su p-value e intervalli di confidenza che rispondono a domande “se si ripetesse infinite volte l’esperimento, in media cosa accadrebbe?”. L’inferenza bayesiana, al contrario, concepisce la probabilità come uno stato di conoscenza (o di credenza) e integra le informazioni precedenti (priors) con i dati osservati per produrre una distribuzione posteriore. Ciò consente un aggiornamento continuo e iterativo delle ipotesi alla luce delle nuove evidenze.\nQuesta impostazione risulta particolarmente utile quando i campioni sono ridotti e le popolazioni indagate sono eterogenee. In tali condizioni, il paradigma frequentista rischia di generare stime instabili o intervalli di confidenza molto ampi. L’approccio bayesiano, invece, permette di incorporare informazioni pregresse e di ottenere stime più precise, a patto che le priors siano giustificate e non eccessivamente informative. L’attenzione alla distribuzione posteriore rende inoltre più chiaro il grado di incertezza associato ai parametri di interesse e favorisce la formulazione di inferenze più calibrate.\n3. Qual è il ruolo delle distribuzioni a priori nelle analisi bayesiane e come ci si assicura che l’uso di priors non introduca bias indesiderati, specialmente in un contesto come quello psicologico dove le teorie e i dati pregressi possono essere incompleti o controversi?\nNell’approccio bayesiano, le distribuzioni a priori (priors) rappresentano la conoscenza o le ipotesi iniziali di cui si dispone sui parametri in esame prima di raccogliere i dati. Se ben specificate, contribuiscono a rendere l’analisi più informativa, soprattutto quando il campione è di piccole dimensioni. Tuttavia, un uso improprio delle priors può introdurre bias, poiché priors troppo “forti” (ossia eccessivamente vincolanti) possono spingere i risultati verso determinate conclusioni.\nPer evitare questi rischi, i ricercatori devono adottare priors ben motivate e trasparenti. In psicologia, dove le teorie possono essere ancora in fase di sviluppo e i dati pregressi non sempre affidabili, è spesso utile iniziare con priors non informative o debolmente informative, per ridurre il rischio di forzare troppo il modello. È anche fondamentale effettuare analisi di sensibilità: testare differenti specificazioni di priors per verificare se i risultati sono robusti oppure fortemente dipendenti da particolari assunzioni iniziali. La documentazione delle scelte fatte (e le relative ragioni) è parte integrante di una buona pratica di ricerca trasparente.\n4. Perché la modellazione formale e le buone pratiche di Data Science (ad es. condivisione di codice, controllo di versione, pipeline riproducibili) risultano fondamentali per una scienza cumulativa e per mitigare gli errori sistematici nella ricerca psicologica?\nLa modellazione formale consente di superare la mera descrizione delle relazioni tra variabili (tipica dell’ANOVA o dei modelli lineari tradizionali) e di entrare nel merito dei meccanismi sottostanti i fenomeni psicologici, costruendo teorie più articolate e fondate. Questa prospettiva rende più esplicite le assunzioni e le ipotesi su cui si basa la ricerca, permettendo un confronto chiaro tra diverse spiegazioni concorrenti.\nParallelamente, l’adozione di strumenti e pratiche di Data Science come la condivisione di codice (in repository pubblici), l’uso del controllo di versione (es. Git) e pipeline analitiche riproducibili riducono gli errori e favoriscono la verifica indipendente dei risultati. Ciò aumenta la trasparenza, poiché altri ricercatori possono ispezionare i passaggi compiuti, e consente la replicazione degli studi. In una scienza cumulativa, infatti, la possibilità di riprodurre, criticare e migliorare i risultati di lavori precedenti è essenziale per costruire un corpus di conoscenze solido e affidabile.\n5. Dal punto di vista epistemologico, in che modo il principio “tutti i modelli sono sbagliati, ma alcuni sono utili” influenza la costruzione, la valutazione e l’interpretazione dei modelli in psicologia, e come si integra con la prospettiva bayesiana di scienza come processo iterativo di apprendimento?\nLa celebre frase di George Box (“tutti i modelli sono sbagliati, ma alcuni sono utili”) evidenzia come i modelli statistici e teorici non possano mai rappresentare perfettamente la realtà, specialmente in un campo complesso come la psicologia, in cui le variabili spesso interagiscono in modo non lineare e multi-dimensionale. Ciò non significa che i modelli siano inutili; anzi, se ben costruiti, possono offrire uno strumento potente per interpretare e prevedere i fenomeni.\nNell’ottica bayesiana, la costruzione dei modelli è un processo iterativo in cui le ipotesi iniziali (priors) vengono continuamente aggiornate alla luce di nuove evidenze (la distribuzione posteriore). Questo ciclo di apprendimento riflette un’idea di scienza non come ricerca della “verità assoluta”, ma come progressivo affinamento delle teorie. Il principio di Box ricorda ai ricercatori che qualsiasi modello deve essere costantemente messo alla prova, confrontato con altri modelli, e aggiornato o abbandonato se i dati non lo supportano più. In questo senso, la prospettiva bayesiana favorisce una mentalità flessibile e aperta, pronta a rivedere i propri presupposti e a migliorare progressivamente la comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html#bibliografia",
    "href": "chapters/key_notions/05_data_analysis.html#bibliografia",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAngrist, J. D., & Pischke, J.-S. (2010). The credibility revolution in empirical economics: How better research design is taking the con out of econometrics. Journal of economic perspectives, 24(2), 3–30.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBishop, D. (2019). The psychology of experimental psychologists: Overcoming cognitive constraints to improve research.\n\n\nButton, K. S., Ioannidis, J. P., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S., & Munafò, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365–376.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nLabatut, B. (2021). Quando abbiamo smesso di capire il mondo. Adelphi Edizioni spa.\n\n\nLarson, C., Kaplan, D., Girolamo, T., Kover, S. T., & Eigsti, I.-M. (2023). A Bayesian statistics tutorial for clinical research: Prior distributions and meaningful results for small clinical samples. Journal of Clinical Psychology, 79(11), 2602–2624.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMeehl, P. E. (1967). Theory-testing in psychology and physics: A methodological paradox. Philosophy of science, 34(2), 103–115.\n\n\nMunger, K. (2023). Temporal validity as meta-science. Research & Politics, 10(3), 20531680231187271.\n\n\nNosek, B. A., Hardwicke, T. E., Moshontz, H., Allard, A., Corker, K. S., Dreber, A., Fidler, F., Hilgard, J., Kline Struhl, M., Nuijten, M. B., et al. (2022). Replicability, robustness, and reproducibility in psychological science. Annual Review of Psychology, 73(1), 719–748.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nPearl, J., & Mackenzie, D. (2018). The book of why: the new science of cause and effect. Basic books.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nVan Dongen, N., Bork, R. van, Finnemann, A., Haslbeck, J., Maas, H. L. van der, Robinaugh, D. J., Ron, J. de, Sprenger, J., & Borsboom, D. (2024). Productive explanation: A framework for evaluating explanations in psychological science. Psychological Review.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html",
    "href": "chapters/R/introduction_r_lang.html",
    "title": "R",
    "section": "",
    "text": "Livello Algoritmico\nLa programmazione richiede un approccio strutturato e logico per risolvere problemi, articolato in due livelli interconnessi: algoritmico e sintattico.\nSi inizia con l’analisi del problema e la descrizione astratta della soluzione, indipendente dal linguaggio di programmazione. Ad esempio, per calcolare la media di un insieme di valori:",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#livello-algoritmico",
    "href": "chapters/R/introduction_r_lang.html#livello-algoritmico",
    "title": "R",
    "section": "",
    "text": "Input: Valori numerici.\n\nOutput: Media aritmetica.\n\nAlgoritmo: Somma dei valori divisa per il numero di osservazioni:\n\\[\n\\text{media} = \\frac{\\sum_{i=1}^{n} x_i}{n}\n\\]\nStrutture dati come i vettori sono ideali per memorizzare e accedere ai valori in modo ordinato.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#livello-sintattico",
    "href": "chapters/R/introduction_r_lang.html#livello-sintattico",
    "title": "R",
    "section": "Livello Sintattico",
    "text": "Livello Sintattico\nSi traduce l’algoritmo in un linguaggio specifico. Ad esempio:\n\nIn R:\nmedia &lt;- sum(x) / length(x)\nIn Python:\nmedia = sum(x) / len(x)\nLa logica rimane invariata, ma la sintassi dipende dal linguaggio scelto.\n\nIn conclusione, la programmazione richiede due competenze chiave:\n\nPensiero algoritmico: Capacità di astrarre e definire la logica computazionale.\nConoscenza sintattica: Traduzione della logica in codice eseguibile.\n\nIl livello algoritmico è fondamentale, poiché la logica è universale, mentre la sintassi può essere appresa o automatizzata. Questo approccio è particolarmente rilevante nell’era dell’AI, dove la chiarezza nella descrizione algoritmica è essenziale per formulare dei prompt efficaci (Cooper et al., 2024).\nQuesta distinzione riflette il framework di Marr (2010) sulla visione artificiale, che separa:\n\nLivello computazionale: Cosa e perché.\n\nLivello algoritmico: Come.\n\nLivello implementativo: Realizzazione pratica.\n\nNella programmazione, il livello algoritmico rappresenta il fondamento per risolvere problemi in modo efficace, a prescindere dal linguaggio di programmazione scelto. In questo insegnamento, l’attenzione sarà focalizzata principalmente sul livello algoritmico, piuttosto che su quello sintattico.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#r-uno-strumento-per-lanalisi-dei-dati",
    "href": "chapters/R/introduction_r_lang.html#r-uno-strumento-per-lanalisi-dei-dati",
    "title": "R",
    "section": "R: Uno Strumento per l’Analisi dei Dati",
    "text": "R: Uno Strumento per l’Analisi dei Dati\nPer trovare la soluzione concreta a un problema di analisi dei dati, è necessario implementare l’algoritmo desiderato in un linguaggio di programmazione. In questo insegnamento, utilizzeremo R, uno dei linguaggi più utilizzati per l’analisi dei dati, apprezzato per la sua flessibilità, potenza e il supporto offerto da una vasta comunità di utenti e sviluppatori.\n\nPerché R?\n\nNato per l’analisi statistica: R è stato concepito specificamente per rispondere alle esigenze di analisi statistica e visualizzazione grafica, diventando rapidamente uno strumento essenziale nel panorama accademico e scientifico.\nGestione dei dati: R offre strumenti avanzati per gestire, manipolare e analizzare grandi quantità di dati, coprendo un’ampia gamma di tecniche statistiche, dalla modellazione lineare all’analisi delle serie temporali.\nVisualizzazione grafica: Con pacchetti come ggplot2 e plotly, R permette di creare grafici e visualizzazioni di alta qualità, fondamentali per comunicare risultati in modo efficace.\nComunità e pacchetti: L’ecosistema di R è arricchito da una vasta libreria di pacchetti, che estendono le capacità del linguaggio per soddisfare necessità specifiche e settoriali.\n\n\n\nR in Psicologia e Scienze Sociali\nIn psicologia e nelle scienze sociali, R è particolarmente utile grazie alle sue capacità avanzate di analisi statistica e visualizzazione. Permette di affrontare analisi sofisticate, come modelli di regressione, analisi fattoriale e metodi per dati longitudinali, rendendolo uno strumento indispensabile per la ricerca.\nIn conclusione, imparare R non significa solo acquisire competenze tecniche, ma anche aprire le porte a nuove possibilità di analisi e ricerca. Tuttavia, è fondamentale ricordare che la vera sfida nella programmazione non è padroneggiare la sintassi di un linguaggio specifico, ma comprendere la logica algoritmica che sta alla base della soluzione di un problema. L’intelligenza artificiale può aiutarci a trovare la sintassi corretta, ma spetta a noi decidere quale algoritmo implementare. Pertanto, i nostri sforzi devono essere rivolti a capire la logica del problema, piuttosto che concentrarci esclusivamente sull’implementazione sintattica.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#bibliografia",
    "href": "chapters/R/introduction_r_lang.html#bibliografia",
    "title": "R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCooper, N., Clark, A. T., Lecomte, N., Qiao, H., & Ellison, A. M. (2024). Harnessing large language models for coding, teaching and inclusion to empower research in ecology and evolution. Methods in Ecology and Evolution.\n\n\nMarr, D. (2010). Vision: A computational investigation into the human representation and processing of visual information. MIT press.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html",
    "href": "chapters/R/01_r_syntax.html",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "",
    "text": "5.1 Introduzione\nNegli ultimi anni, la data science è emersa come uno dei domini più rilevanti nel panorama tecnologico e scientifico. Questa crescita è guidata dalla necessità sempre maggiore di analizzare grandi quantità di dati per supportare processi decisionali più efficaci. In questo contesto, R si è affermato come uno degli strumenti più potenti e versatili, particolarmente apprezzato da statistici e data scientist.\nR è un linguaggio di programmazione specializzato nel calcolo statistico, che eccelle nell’analisi dei dati e nel data mining. La sua piattaforma offre capacità straordinarie per l’analisi, l’elaborazione e la visualizzazione dei dati, rendendolo uno strumento fondamentale nel panorama della data science moderna.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#trasparenza-e-riproducibilità",
    "href": "chapters/R/01_r_syntax.html#trasparenza-e-riproducibilità",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.2 Trasparenza e Riproducibilità",
    "text": "5.2 Trasparenza e Riproducibilità\nLa scelta di R come strumento per la data science assume particolare rilevanza nel contesto della “crisi della replicabilità” in psicologia, un problema che ha evidenziato come molte analisi dei dati non siano facilmente riproducibili (Obels et al., 2020). R affronta questa sfida offrendo tre vantaggi fondamentali:\n\n\nDocumentazione Trasparente attraverso lo Scripting\n\nOgni analisi viene documentata attraverso script espliciti\nIl codice può essere salvato, condiviso e rivisto\nLe analisi possono essere facilmente replicate con nuovi dati\n\n\n\nFlessibilità e Personalizzazione\n\nAmbiente adattabile a diverse esigenze analitiche\nVasta collezione di pacchetti per metodi statistici avanzati\nPossibilità di sviluppare soluzioni personalizzate\n\n\n\nReporting Integrato\n\nIntegrazione con strumenti come R Markdown e Quarto\nCreazione di documenti dinamici che combinano codice e risultati\nGenerazione automatica di report aggiornabili\n\n\n\nA differenza dei software con interfacce grafiche, l’approccio basato sul codice di R elimina le ambiguità e aumenta la verificabilità delle analisi. Questo non solo migliora la qualità della ricerca, ma contribuisce anche a costruire una comunità scientifica più trasparente e affidabile.\nL’utilizzo di R rappresenta quindi non solo una scelta tecnica, ma l’adozione di una metodologia che promuove rigore scientifico, trasparenza e riproducibilità nella ricerca moderna.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#installare-r-e-rstudio",
    "href": "chapters/R/01_r_syntax.html#installare-r-e-rstudio",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.3 Installare R e RStudio",
    "text": "5.3 Installare R e RStudio\n\nScarica e installa R\nVai al sito ufficiale di CRAN (https://cran.r-project.org/), scegli la versione per il tuo sistema operativo (Windows, Mac o Linux) e segui le istruzioni di installazione.\nScarica e installa RStudio\nDopo aver installato R, scarica RStudio dal sito ufficiale (https://posit.co/download/rstudio-desktop/). Scegli la versione gratuita “RStudio Desktop” e segui le istruzioni per il tuo sistema operativo.\n\nUna spiegazione dettagliata del processo di installazione di R e RStudio è disponibile in Okoye & Hosseini (2024).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#panoramica-sullinterfaccia-di-rstudio",
    "href": "chapters/R/01_r_syntax.html#panoramica-sullinterfaccia-di-rstudio",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.4 Panoramica sull’interfaccia di RStudio",
    "text": "5.4 Panoramica sull’interfaccia di RStudio\nRStudio rende l’uso di R più intuitivo grazie alla sua interfaccia divisa in quattro pannelli principali:\n\n\nPannello degli script: Qui puoi scrivere e modificare i tuoi script, cioè sequenze di comandi salvabili per analisi ripetibili e organizzate.\n\nConsole: Esegue i comandi scritti direttamente o lanciati dagli script, mostrando risultati, messaggi e errori.\n\nPannello dell’ambiente: Mostra i dataset, le variabili e gli oggetti caricati nella sessione di lavoro, permettendoti di gestire facilmente i dati.\n\nPannello grafici/aiuto/file: Visualizza grafici, fornisce accesso alla documentazione di R e consente di navigare tra file e cartelle sul tuo sistema.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#creare-un-nuovo-progetto-in-rstudio",
    "href": "chapters/R/01_r_syntax.html#creare-un-nuovo-progetto-in-rstudio",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.5 Creare un Nuovo Progetto in RStudio",
    "text": "5.5 Creare un Nuovo Progetto in RStudio\nAvviare un nuovo progetto\nDal menu di RStudio, seleziona File &gt; New Project… per creare un nuovo progetto. I progetti in RStudio sono uno strumento efficace per organizzare il lavoro relativo a una specifica analisi o domanda di ricerca. All’interno di un progetto puoi raccogliere script, file di dati e output, mantenendo tutto ben strutturato.\nScegliere la posizione del progetto\nPuoi creare una nuova directory dedicata al progetto oppure associare il progetto a una directory esistente. Organizzare i progetti in cartelle dedicate aiuta a mantenere i file in ordine e a utilizzare percorsi relativi, rendendo il tuo lavoro più facile da condividere con collaboratori e più portabile tra diversi sistemi.\nQuesta organizzazione è particolarmente utile per evitare confusione e assicurarsi che tutti i file necessari siano facilmente accessibili e collegati al progetto corretto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#concetti-di-base-nella-programmazione-in-r",
    "href": "chapters/R/01_r_syntax.html#concetti-di-base-nella-programmazione-in-r",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.6 Concetti di Base nella Programmazione in R",
    "text": "5.6 Concetti di Base nella Programmazione in R\nIniziare a usare R, soprattutto per chi si avvicina per la prima volta a questo linguaggio nel contesto della psicologia, significa comprendere i concetti fondamentali che ne costituiscono la base. Questo capitolo introduce i principi essenziali della programmazione in R, tra cui:\n\nLa comprensione della sintassi di R.\nLa familiarizzazione con i principali tipi di dati e strutture.\nL’acquisizione delle operazioni di base.\n\nQuesti concetti sono fondamentali per manipolare efficacemente i dati e condurre analisi statistiche, rappresentando il punto di partenza per sfruttare al meglio le potenzialità di R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#oggetti-in-r",
    "href": "chapters/R/01_r_syntax.html#oggetti-in-r",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.7 Oggetti in R",
    "text": "5.7 Oggetti in R\nIn R, tutto è un oggetto: dai numeri o stringhe di testo semplici, fino a strutture più complesse come grafici, riassunti di analisi statistiche o script che eseguono compiti specifici. Creare e assegnare valori agli oggetti è fondamentale per lavorare in R.\n\n5.7.1 Creare oggetti\nPer creare un oggetto, basta assegnargli un nome e un valore usando l’operatore di assegnazione &lt;-:\n\nmy_obj &lt;- 48\n\nIn questo esempio, abbiamo creato un oggetto chiamato my_obj e gli abbiamo assegnato il valore 48. Anche l’operatore = può essere usato, ma è considerato una cattiva pratica.\nPer visualizzare il valore di un oggetto, basta scriverne il nome:\n\nmy_obj\n#&gt; [1] 48\n\nGli oggetti creati vengono memorizzati nell’ambiente di lavoro. In RStudio, puoi visualizzarli nella scheda Environment e ottenere dettagli come tipo, lunghezza e valore.\nÈ possibile assegnare a un oggetto anche una stringa di testo, racchiudendola tra virgolette:\n\nmy_obj2 &lt;- \"R è fantastico\"\nmy_obj2\n#&gt; [1] \"R è fantastico\"\n\nSe dimentichi le virgolette, R mostrerà un errore.\nPer modificare il valore di un oggetto esistente, basta riassegnarlo:\n\nmy_obj2 &lt;- 1024\n\nOra il tipo di my_obj2 è cambiato da carattere a numerico. È anche possibile usare oggetti per crearne di nuovi:\n\nmy_obj3 &lt;- my_obj + my_obj2\nmy_obj3\n#&gt; [1] 1072\n\nSe provi a sommare oggetti di tipo diverso, R restituirà un errore:\nchar_obj &lt;- \"ciao\"\nchar_obj2 &lt;- \"mondo\"\nchar_obj3 &lt;- char_obj + char_obj2\n#&gt; Error in char_obj + char_obj2 : non-numeric argument to binary operator\nQuando incontri errori come questo, chiedi a AI la spiegazione del messaggio, per esempio: “non-numeric argument to binary operator error + r”. Un errore comune è anche:\nmy_obj &lt;- 48\nmy_obj4 &lt;- my_obj + no_obj\n#&gt; Error: object 'no_obj' not found\nR segnala che no_obj non è stato definito e, di conseguenza, l’oggetto my_obj4 non è stato creato.\n\n5.7.2 Nomi degli Oggetti\nAttribuire nomi agli oggetti potrebbe sembrare un dettaglio secondario, ma è fondamentale scegliere nomi brevi e informativi. Un buon nome migliora la leggibilità del codice e ne facilita la manutenzione. È importante adottare uno stile coerente, come uno dei seguenti:\n\n\nSnake case: output_summary\n\n\nDot case: output.summary\n\n\nCamel case: outputSummary\n\n\nIn questo corso useremo lo stile più diffuso, Snake Case, che separa le parole con il carattere di sottolineatura _.\nCi sono alcune regole fondamentali da rispettare nella scelta dei nomi:\n\nNon possono iniziare con un numero (ad esempio, 2my_variable non è valido).\n\nNon possono contenere caratteri speciali come &, ^, /, ecc.\n\nEvita di usare parole riservate (ad esempio, TRUE, NA) o nomi di funzioni esistenti (ad esempio, data).\n\nEsempio di cosa non fare:\ndata &lt;- read.table(\"mydatafile\", header = TRUE) # `data` è già una funzione!\n\n5.7.3 Commenti\nI commenti sono uno strumento essenziale per rendere il codice più chiaro e comprensibile, sia per te stesso sia per altri. Nel linguaggio R, i commenti iniziano con il simbolo #, e tutto ciò che lo segue sulla stessa riga viene ignorato dall’interprete durante l’esecuzione.\n\n5.7.3.1 Perché commentare?\nI commenti servono a spiegare perché il codice è scritto in un certo modo, non solo come funziona (questo è evidente leggendo il codice). Una buona pratica consiste nel commentare le decisioni o i passaggi che non risultano immediatamente evidenti.\nAd esempio, invece di scrivere un commento ridondante come:\n\n# Assegno 42 alla variabile x\nx &lt;- 42\n\nè più utile fornire un contesto:\n\n# Valore iniziale scelto per semplificare i calcoli successivi\nx &lt;- 42\n\n\n5.7.3.2 Vantaggi\nCommentare in modo appropriato aiuta a:\n\n\nRidurre il tempo necessario per comprendere o modificare il codice, anche mesi o anni dopo averlo scritto.\n\nFacilitare la collaborazione con altri, rendendo il codice leggibile e accessibile.\n\nMigliorare la manutenibilità e il riutilizzo del codice.\n\nUn codice ben commentato non è solo più facile da leggere, ma anche più professionale e robusto nel lungo termine.\n\n5.7.4 Usare R come Calcolatore\nR può essere utilizzato come un semplice calcolatore digitando direttamente nella console numeri e operatori aritmetici per eseguire operazioni come somma, sottrazione, moltiplicazione e divisione (+, -, *, /). Questo lo rende uno strumento immediato e versatile per calcoli di base e avanzati.\n\nEsempio 5.1 La Satisfaction With Life Scale (SWLS) contiene 5 item, ciascuno valutato con una scala Likert a 7 punti, dove:\n1 = “completamente in disaccordo” e 7 = “completamente d’accordo”.\nGli item sono:\n\nPer la maggior parte, la mia vita si avvicina al mio ideale.\n\nLe mie condizioni di vita sono eccellenti.\n\nSono soddisfatto della mia vita.\n\nFino ad ora, ho ottenuto le cose importanti che voglio nella vita.\n\nSe potessi vivere la mia vita di nuovo, non cambierei quasi nulla.\n\nSupponiamo che un individuo risponda nel seguente modo:\n\nItem 1: 5\n\nItem 2: 3\n\nItem 3: 4\n\nItem 4: 2\n\nItem 5: 2\n\nIl punteggio totale sulla SWLS si calcola sommando i punteggi di ciascun item:\n\nsogg1 &lt;- 5 + 3 + 4 + 2 + 2 \nsogg1\n#&gt; [1] 16\n\n\n\nEsempio 5.2 Il Body Mass Index (BMI) si calcola dividendo il peso, in chilogrammi, per il quadrato dell’altezza, in metri.\nLa formula è:\n\\[\n\\text{BMI} = \\frac{\\text{Peso (kg)}}{\\text{Altezza (m)}^2} .\n\\]\nSupponiamo che un individuo pesi 79000 grammi (79 kg) e sia alto 176 cm. Il calcolo in R sarà:\n\nbmi &lt;- (79000 / 1000) / (176 / 100)^2\nbmi\n#&gt; [1] 25.5\n\n\nNota. L’uso di parentesi è fondamentale per garantire che le operazioni vengano eseguite nell’ordine corretto. In R, come in matematica, le operazioni racchiuse tra parentesi hanno la precedenza rispetto ad altre operazioni. Ad esempio, nel calcolo del BMI, abbiamo usato le parentesi per calcolare prima la conversione dei valori nell’unità di misura appropriata.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#ordine-di-precedenza-degli-operatori",
    "href": "chapters/R/01_r_syntax.html#ordine-di-precedenza-degli-operatori",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.8 Ordine di precedenza degli operatori",
    "text": "5.8 Ordine di precedenza degli operatori\nLe operazioni algebriche vengono eseguite in una particolare sequenza in R, nota come ordine di precedenza degli operatori. Questo ordine determina quali operazioni vengono eseguite per prime quando un’espressione include più operatori. In assenza di parentesi, l’ordine di precedenza è il seguente (dal più alto al più basso):\n\n\nParentesi: Le operazioni racchiuse tra parentesi () vengono eseguite per prime. Questo permette di sovrascrivere l’ordine naturale delle operazioni.\n\nresult &lt;- (2 + 3) * 4  # Risultato: 20\n\n\n\nEsponenziazione: L’operatore ^ viene eseguito dopo le parentesi.\n\nresult &lt;- 2^3  # Risultato: 8\n\n\n\nSegni unari: Il segno meno - o più + applicato a un singolo valore.\n\nresult &lt;- -3 + 5  # Risultato: 2\n\n\n\nMoltiplicazione, divisione e modulo: Gli operatori *, /, %/% (divisione intera) e %% (resto) hanno la stessa precedenza e vengono eseguiti da sinistra a destra.\n\nresult &lt;- 10 / 2 * 3  # Risultato: 15\nresult &lt;- 10 %% 3     # Risultato: 1\n\n\n\nAddizione e sottrazione: Gli operatori + e - vengono eseguiti dopo quelli di moltiplicazione/divisione.\n\nresult &lt;- 5 + 3 - 2  # Risultato: 6\n\n\n\nOperatori di assegnazione: Gli operatori &lt;-, -&gt;, =, che assegnano valori a variabili, vengono valutati per ultimi.\n\nx &lt;- 2 + 3 * 4  # Risultato: 14\n\n\n\nNote importanti:\n\n\nAssociazione a sinistra: La maggior parte degli operatori in R viene valutata da sinistra a destra (ad esempio, +, *, /).\n\nUso delle parentesi: Quando l’ordine di precedenza non è immediatamente chiaro o si vuole assicurare un ordine specifico, è sempre buona pratica usare le parentesi.\n\nCapire l’ordine di precedenza è fondamentale per evitare errori logici e garantire che il codice funzioni come previsto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#usare-le-funzioni-in-r",
    "href": "chapters/R/01_r_syntax.html#usare-le-funzioni-in-r",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.9 Usare le funzioni in R",
    "text": "5.9 Usare le funzioni in R\nFino ad ora abbiamo creato oggetti semplici assegnando loro direttamente un valore. Con l’aumento dell’esperienza in R, potresti voler creare oggetti più complessi. Per aiutarti, R offre numerose funzioni già disponibili nella sua installazione di base, e altre possono essere aggiunte installando pacchetti. Una funzione è un insieme di istruzioni che eseguono un compito specifico. Inoltre, è possibile creare funzioni personalizzate.\n\n5.9.1 La funzione c() per creare vettori\nLa prima funzione utile da imparare è c(), che serve a concatenare valori in un vettore. Ad esempio:\n\nmy_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\n\nQuesto codice crea un oggetto chiamato my_vec che contiene una sequenza di numeri. Alcuni concetti fondamentali sulle funzioni in R:\n\n\nNome e parentesi: Le funzioni in R sono sempre seguite da parentesi tonde ().\n\nArgomenti: Gli elementi passati alla funzione (tra le parentesi) ne personalizzano il comportamento e sono separati da virgole.\n\nPer vedere il contenuto del vettore:\n\nmy_vec\n#&gt; [1] 2 3 1 6 4 3 3 7\n\n\n5.9.2 Funzioni per analizzare vettori\nPuoi utilizzare altre funzioni per calcolare statistiche sul vettore:\n\nmean(my_vec)    # Media\n#&gt; [1] 3.625\n\n\nvar(my_vec)     # Varianza\n#&gt; [1] 3.982\n\n\nsd(my_vec)      # Deviazione standard\n#&gt; [1] 1.996\n\n\nlength(my_vec)  # Numero di elementi\n#&gt; [1] 8\n\nPuoi anche salvare i risultati in nuovi oggetti per riutilizzarli:\n\nvec_mean &lt;- mean(my_vec)\nvec_mean\n#&gt; [1] 3.625\n\n\n\n\n\n\n\nConcetto Chiave\n\n\n\n\n\nLa varianza e la deviazione standard sono misure statistiche descrittive che sintetizzano in un unico valore numerico la variabilità di un insieme di dati. Questi indici, che verranno approfonditi nel Capitolo 18, forniscono informazioni su quanto i valori di un dataset siano simili o diversi tra loro.\nIn particolare:\n\nla varianza e la deviazione standard sono pari a 0 quando tutti i valori nel dataset sono identici, indicando assenza di variabilità;\nassumono valori più elevati all’aumentare delle differenze tra i dati, segnalando una maggiore dispersione.\n\nPer i nostri scopi attuali, è sufficiente comprendere che queste misure descrivono il grado di diversità o omogeneità dei dati.\n\n\n\n\n5.9.3 Creare sequenze regolari\nPer creare sequenze di numeri in passi regolari, puoi usare i seguenti comandi.\nSimbolo : per sequenze semplici:\n\nmy_seq &lt;- 1:10\nmy_seq\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\nFunzione seq() per maggiore controllo:\n\nmy_seq2 &lt;- seq(from = 1, to = 5, by = 0.5)\nmy_seq2\n#&gt; [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0\n\n\n5.9.4 Ripetere valori\nPuoi ripetere valori o sequenze con la funzione rep().\nRipetere un valore:\n\nmy_seq3 &lt;- rep(2, times = 10)\nmy_seq3\n#&gt;  [1] 2 2 2 2 2 2 2 2 2 2\n\nRipetere una sequenza:\n\nmy_seq5 &lt;- rep(1:5, times = 3)\n\nRipetere ogni elemento di una sequenza:\n\nmy_seq6 &lt;- rep(1:5, each = 3)\nmy_seq6\n#&gt;  [1] 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5\n\n\n5.9.5 Annidare funzioni\nÈ possibile combinare funzioni per creare comandi più complessi, come nell’esempio:\n\nmy_seq7 &lt;- rep(c(3, 1, 10, 7), each = 3)\nmy_seq7\n#&gt;  [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\nPer maggiore leggibilità, puoi separare i passaggi:\n\nin_vec &lt;- c(3, 1, 10, 7)\nmy_seq7 &lt;- rep(in_vec, each = 3)\nmy_seq7\n#&gt;  [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\nQuesta pratica facilita la comprensione del codice e lo rende più chiaro.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#lavorare-con-i-vettori-in-r",
    "href": "chapters/R/01_r_syntax.html#lavorare-con-i-vettori-in-r",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.10 Lavorare con i vettori in R",
    "text": "5.10 Lavorare con i vettori in R\nIn R, i vettori sono uno degli elementi fondamentali per manipolare, riassumere e ordinare i dati. Qui trovi una panoramica su come estrarre, sostituire, ordinare, lavorare con dati mancanti e sfruttare la vettorizzazione dei vettori.\n\n5.10.1 Estrarre elementi da un vettore\nPuoi estrarre uno o più elementi da un vettore usando le parentesi quadre [ ].\nPer posizione: Specifica la posizione degli elementi.\n\nmy_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\nmy_vec[3]  # Terzo elemento\n#&gt; [1] 1\n\n\nmy_vec[c(1, 5, 6)]  # Elementi 1°, 5° e 6°\n#&gt; [1] 2 4 3\n\n\nmy_vec[3:8]  # Da 3° a 8°\n#&gt; [1] 1 6 4 3 3 7\n\nCon condizioni logiche: Usa espressioni logiche per selezionare elementi.\n\nmy_vec[my_vec &gt; 4]  # Elementi &gt; 4\n#&gt; [1] 6 7\n\n\nmy_vec[my_vec &lt;= 4]  # Elementi ≤ 4\n#&gt; [1] 2 3 1 4 3 3\n\n\nmy_vec[my_vec != 4]  # Elementi diversi da 4\n#&gt; [1] 2 3 1 6 3 3 7\n\nOperatori logici: Combina condizioni con & (AND) e | (OR).\n\nmy_vec[my_vec &gt; 2 & my_vec &lt; 6]  # Tra 2 e 6\n#&gt; [1] 3 4 3 3\n\n\n5.10.2 Sostituire elementi in un vettore\nPuoi modificare i valori di un vettore usando [ ] e l’operatore &lt;-.\nUn singolo elemento:\n\nmy_vec[4] &lt;- 500  # Cambia il 4° elemento\nmy_vec\n#&gt; [1]   2   3   1 500   4   3   3   7\n\nPiù elementi:\n\nmy_vec[c(6, 7)] &lt;- 100  # Cambia il 6° e 7° elemento\nmy_vec\n#&gt; [1]   2   3   1 500   4 100 100   7\n\nCon condizioni logiche:\n\nmy_vec[my_vec &lt;= 4] &lt;- 1000  # Cambia valori ≤ 4\nmy_vec\n#&gt; [1] 1000 1000 1000  500 1000  100  100    7\n\n\n5.10.3 Ordinare un vettore\nDal più piccolo al più grande:\n\nvec_sort &lt;- sort(my_vec)\nvec_sort\n#&gt; [1]    7  100  100  500 1000 1000 1000 1000\n\nDal più grande al più piccolo:\n\nvec_sort2 &lt;- sort(my_vec, decreasing = TRUE)\nvec_sort2\n#&gt; [1] 1000 1000 1000 1000  500  100  100    7\n\nOrdinare un vettore in base a un altro:\n\nheight &lt;- c(180, 155, 160, 167, 181)\np.names &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\", \"Karen\", \"Amy\")\nheight_ord &lt;- order(height)\nnames_ord &lt;- p.names[height_ord]\nnames_ord\n#&gt; [1] \"Charlotte\" \"Helen\"     \"Karen\"     \"Joanna\"    \"Amy\"",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#operazioni-vettoriali-e-vettorizzazione-in-r",
    "href": "chapters/R/01_r_syntax.html#operazioni-vettoriali-e-vettorizzazione-in-r",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.11 Operazioni Vettoriali e Vettorizzazione in R",
    "text": "5.11 Operazioni Vettoriali e Vettorizzazione in R\nLa vettorializzazione è una delle caratteristiche più potenti di R, che consente di applicare operazioni o funzioni direttamente a tutti gli elementi di un vettore in modo simultaneo, senza dover ricorrere a cicli espliciti. Questo approccio rende il codice più conciso, leggibile ed efficiente, sfruttando al meglio le capacità intrinseche del linguaggio.\n\n5.11.1 Operazioni Aritmetiche su Vettori\nLe operazioni algebriche in R, come addizione, sottrazione, moltiplicazione e divisione, sono vettorizzate. Questo significa che ogni operazione viene applicata “elemento per elemento” al vettore.\nConsideriamo ad esempio il seguente vettore:\n\nmy_vec &lt;- c(3, 5, 7, 1, 9, 20)\n\nSe vogliamo moltiplicare ciascun elemento di my_vec per 5, possiamo scrivere:\n\nmy_vec * 5\n#&gt; [1]  15  25  35   5  45 100\n\nAnalogamente, possiamo effettuare altre operazioni algebriche, come divisione o elevamento a potenza:\n\nmy_vec / 2\n#&gt; [1]  1.5  2.5  3.5  0.5  4.5 10.0\n\n\nmy_vec^2\n#&gt; [1]   9  25  49   1  81 400\n\nQueste operazioni vengono applicate automaticamente a ciascun elemento del vettore, senza dover iterare su di essi.\n\n5.11.2 Operazioni Elemento per Elemento tra Due Vettori\nLa vettorializzazione consente anche di eseguire operazioni tra due vettori, applicandole elemento per elemento. Supponiamo di avere un secondo vettore:\n\nmy_vec2 &lt;- c(17, 15, 13, 19, 11, 0)\n\nSe vogliamo sommare i due vettori, possiamo scrivere:\n\nmy_vec + my_vec2\n#&gt; [1] 20 20 20 20 20 20\n\nIn questo caso, il primo elemento di my_vec viene sommato al primo elemento di my_vec2, il secondo elemento al secondo, e così via.\n\nEsempio 5.3 Di seguito mostriamo come calcolare i punteggi totali per 10 individui che hanno risposto ai 5 item della Satisfaction With Life Scale (SWLS), utilizzando le formule e l’aritmetica vettorializzata di R.\nStep 1: Definiamo i punteggi per ciascun item. Ogni vettore contiene i punteggi dati dai 10 individui a uno specifico item della scala:\n\n# Punteggi dei 10 individui per ciascun item\nitem1 &lt;- c(5, 4, 6, 7, 3, 2, 5, 6, 4, 7)\nitem2 &lt;- c(3, 2, 4, 6, 2, 1, 4, 5, 3, 6)\nitem3 &lt;- c(4, 5, 6, 5, 3, 2, 5, 7, 4, 5)\nitem4 &lt;- c(2, 3, 4, 3, 2, 1, 3, 4, 2, 5)\nitem5 &lt;- c(2, 2, 3, 4, 1, 1, 3, 3, 2, 4)\n\nI valori 5, 3, 4, 2, 2 sono i punteggi del primo individuo sui 5 item; i punteggio 4, 2, 5, 3, 2 sono i punteggi del secondo individuo sui 5 item, e così via.\nStep 2: Sommiamo i punteggi per calcolare il totale. Il punteggio totale di ciascun individuo è la somma dei punteggi relativi ai 5 item. Formalmente, per l’individuo \\(i\\) (\\(i = 1, 2, \\ldots, 10\\)), il punteggio totale è calcolato come:\n\\[\n\\text{PunteggioTotale}_i = \\text{item1}_i + \\text{item2}_i + \\text{item3}_i + \\text{item4}_i + \\text{item5}_i .\n\\]\nIn R, possiamo sommare i vettori direttamente grazie all’aritmetica vettorializzata:\n\n# Calcolo dei punteggi totali per ciascun individuo\ntotal_scores &lt;- item1 + item2 + item3 + item4 + item5\ntotal_scores\n#&gt;  [1] 16 16 23 25 11  7 20 25 15 27\n\nIl risultato è un vettore con i punteggi totali per ciascun individuo.\nStep 3: Mostriamo i risultati. Per organizzare meglio i dati, creiamo una tabella che associa i punteggi totali agli individui:\n\n# Creiamo una tabella con i punteggi totali\nindividui &lt;- paste(\"Individuo\", 1:10)\nrisultati_swls &lt;- data.frame(Individuo = individui, PunteggioTotale = total_scores)\nprint(risultati_swls)\n#&gt;       Individuo PunteggioTotale\n#&gt; 1   Individuo 1              16\n#&gt; 2   Individuo 2              16\n#&gt; 3   Individuo 3              23\n#&gt; 4   Individuo 4              25\n#&gt; 5   Individuo 5              11\n#&gt; 6   Individuo 6               7\n#&gt; 7   Individuo 7              20\n#&gt; 8   Individuo 8              25\n#&gt; 9   Individuo 9              15\n#&gt; 10 Individuo 10              27\n\nSpiegazione delle operazioni:\n\nOgni vettore contiene i punteggi di 10 individui per un dato item. Ad esempio, il vettore item1 contiene i punteggi relativi al primo item, e così via.\n\nGrazie all’aritmetica vettorializzata, quando sommiamo i vettori \\(\\text{item1}\\), \\(\\text{item2}\\), \\(\\text{item3}\\), \\(\\text{item4}\\), \\(\\text{item5}\\), R somma elemento per elemento:\n\\[\n\\text{total\\_scores}_i = \\text{item1}_i + \\text{item2}_i + \\text{item3}_i + \\text{item4}_i + \\text{item5}_i\n\\]\n\nQuesta tecnica consente di calcolare rapidamente i punteggi totali per tutti gli individui senza dover scrivere un ciclo esplicito, rendendo il codice più semplice e leggibile.\n\nQuesto esempio illustra come R semplifichi operazioni complesse grazie al calcolo vettorializzato, migliorando l’efficienza e la chiarezza del codice.\n\n\n5.11.3 Attenzione al Riciclo dei Vettori\nSe i due vettori hanno lunghezze diverse, R applicherà il meccanismo di riciclo: gli elementi del vettore più corto verranno ripetuti ciclicamente per abbinarsi alla lunghezza del vettore più lungo. Questo comportamento, sebbene utile, richiede attenzione per evitare risultati inattesi.\nAd esempio:\n\nshort_vec &lt;- c(1, 2)\nmy_vec + short_vec\n#&gt; [1]  4  7  8  3 10 22\n\nIn questo caso, gli elementi di short_vec vengono riciclati per abbinarsi alla lunghezza di my_vec. Il risultato è:\n(3+1, 5+2, 7+1, 1+2, 9+1, 20+2)\n\n5.11.4 Applicazione di Funzioni su Vettori\nLa vettorializzazione non si limita alle operazioni algebriche, ma si estende anche all’uso di funzioni. Supponiamo di voler calcolare il logaritmo naturale di ciascun elemento di un vettore:\n\nlog(my_vec)\n#&gt; [1] 1.099 1.609 1.946 0.000 2.197 2.996\n\nLa funzione log() viene applicata automaticamente a ogni elemento del vettore. Analogamente, possiamo utilizzare altre funzioni predefinite di R, come:\n\nsqrt(my_vec)  # Calcola la radice quadrata di ciascun elemento\n#&gt; [1] 1.732 2.236 2.646 1.000 3.000 4.472\nexp(my_vec)   # Eleva e alla potenza specificata da ciascun elemento\n#&gt; [1] 2.009e+01 1.484e+02 1.097e+03 2.718e+00 8.103e+03 4.852e+08\n\nIn conclusione, la vettorializzazione in R rappresenta un approccio elegante ed efficiente per gestire calcoli su vettori. Che si tratti di operazioni algebriche, operazioni tra vettori o applicazione di funzioni, la possibilità di evitare cicli espliciti migliora la leggibilità e la velocità del codice. Tuttavia, è importante prestare attenzione al riciclo dei vettori per evitare errori non intenzionali.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#gestire-dati-mancanti-na",
    "href": "chapters/R/01_r_syntax.html#gestire-dati-mancanti-na",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.12 Gestire dati mancanti (NA)",
    "text": "5.12 Gestire dati mancanti (NA)\nR rappresenta i dati mancanti con NA. La gestione dei dati mancanti dipende dalla funzione utilizzata.\nCalcolo con dati mancanti:\n\ntemp &lt;- c(7.2, NA, 7.1, 6.9, 6.5, 5.8, 5.8, 5.5, NA, 5.5)\nmean(temp)  # Restituisce NA\n#&gt; [1] NA\n\n\nmean(temp, na.rm = TRUE)  # Ignora i valori mancanti\n#&gt; [1] 6.287\n\nNota: na.rm = TRUE è un argomento comune per ignorare i NA, ma non tutte le funzioni lo supportano. Consulta la documentazione della funzione per verificare come gestisce i dati mancanti.\nIn conclusione, manipolare vettori è un’abilità essenziale in R. Dalla selezione e modifica degli elementi all’ordinamento e gestione di dati mancanti, queste tecniche sono alla base dell’analisi dei dati in R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#i-dati-in-r",
    "href": "chapters/R/01_r_syntax.html#i-dati-in-r",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.13 I dati in R",
    "text": "5.13 I dati in R\nIn R, i dati possono essere rappresentati in diversi tipi e strutture. Comprendere come gestirli è fondamentale per manipolare, analizzare e riassumere i dataset più complessi.\n\n5.13.1 Tipi di dati in R\nR supporta diversi tipi di dati:\n\n\nNumeric: Numeri decimali (es. 2.5).\n\nInteger: Numeri interi (es. 3).\n\nLogical: Valori booleani (TRUE o FALSE) e NA per dati mancanti.\n\nCharacter: Stringhe di testo (es. \"hello\").\n\nFactor: Variabili categoriche (es. livelli come \"low\", \"medium\", \"high\").\n\nPuoi verificare il tipo di un oggetto con class() e controllare se appartiene a un tipo specifico con funzioni come is.numeric(). È anche possibile convertire un tipo in un altro con funzioni come as.character().\n\n5.13.2 Strutture di dati in R\nVettori: Contengono dati dello stesso tipo (es. numeri, stringhe o logici).\n\nmy_vec &lt;- c(1, 2, 3)\nmy_vec\n#&gt; [1] 1 2 3\n\nMatrici e array: Strutture bidimensionali (matrici) o multidimensionali (array) con dati dello stesso tipo.\nCreare una matrice:\n\nmy_mat &lt;- matrix(1:12, nrow = 3, byrow = TRUE)\nmy_mat\n#&gt;      [,1] [,2] [,3] [,4]\n#&gt; [1,]    1    2    3    4\n#&gt; [2,]    5    6    7    8\n#&gt; [3,]    9   10   11   12\n\nOperazioni utili:\n\n\nTrasposizione: t(my_mat)\n\n\nDiagonale: diag(my_mat)\n\n\nMoltiplicazione matriciale: mat1 %*% mat2\n\n\nListe: Possono contenere elementi di tipi diversi, inclusi vettori, matrici o altre liste.\n\nmy_list &lt;- list(\n  numbers = c(1, 2), \n  text = \"hello\", \n  mat = matrix(1:4, nrow = 2)\n)\nmy_list$numbers  # Accedi agli elementi con il nome\n#&gt; [1] 1 2\n\nData frame: Strutture bidimensionali che possono contenere colonne di tipi diversi. Ideale per dataset strutturati.\nCreare un data frame:\n\nheight &lt;- c(180, 155, 160)\nweight &lt;- c(65, 50, 52)\nnames &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\")\n\ndataf &lt;- data.frame(height = height, weight = weight, names = names)\nstr(dataf)  # Mostra la struttura del data frame\n#&gt; 'data.frame':    3 obs. of  3 variables:\n#&gt;  $ height: num  180 155 160\n#&gt;  $ weight: num  65 50 52\n#&gt;  $ names : chr  \"Joanna\" \"Charlotte\" \"Helen\"\n\nPer convertire le stringhe in fattori durante la creazione:\n\ndataf &lt;- data.frame(\n  height = height, \n  weight = weight, \n  names = names, \n  stringsAsFactors = TRUE\n)\n\ndataf\n#&gt;   height weight     names\n#&gt; 1    180     65    Joanna\n#&gt; 2    155     50 Charlotte\n#&gt; 3    160     52     Helen\n\n\n5.13.3 Operazioni utili sui data frame\n\n\nVerificare dimensioni: dim(dataf)\n\n\nVisualizzare struttura: str(dataf)\n\n\nAccedere a colonne: dataf$height",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#operazioni-di-base-in-r",
    "href": "chapters/R/01_r_syntax.html#operazioni-di-base-in-r",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.14 Operazioni di Base in R",
    "text": "5.14 Operazioni di Base in R\n\n5.14.1 Operazioni Aritmetiche\nCome abbiamo visto in precedenza, R supporta le classiche operazioni aritmetiche come somma (+), sottrazione (-), moltiplicazione (*), divisione (/) ed esponenziazione (^).\n\n5.14.2 Operazioni Logiche\nLe operazioni logiche in R includono:\n\n\n&: “and” logico\n\n\n|: “or” logico\n\n\n!: “not” logico\n\n\n&gt;: maggiore di\n\n\n&lt;: minore di\n\n\n==: uguale a\n\n\n!=: diverso da\n\nPer esempio:\n\n# Maggiore di\n3 &gt; 2\n#&gt; [1] TRUE\n# Uguale a\n3 == 2\n#&gt; [1] FALSE\n\n\nEsempio 5.4 Consideriamo l’esempio precedente, in cui abbiamo calcolato i punteggi totali dei 10 individui sulla Satisfaction With Life Scale (SWLS). Ora vogliamo determinare la proporzione di individui nel campione che ha ottenuto un punteggio totale maggiore di 15.\nI punteggi totali dei 10 individui sono memorizzati nella colonna PunteggioTotale del data frame risultati_swls:\n\nrisultati_swls$PunteggioTotale\n#&gt;  [1] 16 16 23 25 11  7 20 25 15 27\n\nPossiamo creare un vettore logico che indica, per ciascun individuo, se il suo punteggio totale supera 15. In R, l’operatore di confronto &gt; restituisce un valore TRUE se la condizione è soddisfatta e FALSE altrimenti:\n\nrisultati_swls$PunteggioTotale &gt; 15\n#&gt;  [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE\n\nIn R, i valori TRUE e FALSE possono essere trattati come numeri: TRUE equivale a 1 e FALSE equivale a 0. Questo ci permette di sommare i valori logici per contare quante volte la condizione è soddisfatta. Per calcolare la proporzione, dividiamo questa somma per il numero totale di individui:\n\nsum(risultati_swls$PunteggioTotale &gt; 15) / length(risultati_swls$PunteggioTotale)\n#&gt; [1] 0.7\n\nLa proporzione è calcolata come:\n\\[\n\\text{Proporzione} = \\frac{\\sum_{i=1}^{n} I(\\text{PunteggioTotale}_i &gt; 15)}{n} ,\n\\]\ndove:\n\n\n\\(n\\) è il numero totale di individui (in questo caso, 10),\n\n\\(I(\\text{PunteggioTotale}_i &gt; 15)\\) è una funzione indicatrice che vale 1 se il punteggio dell’individuo \\(i\\) è maggiore di 15, e 0 altrimenti.\n\nNel nostro esempio, la proporzione degli individui con punteggio totale maggiore di 15 è 0.7, cioè il 70% del campione soddisfa questa condizione.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#estrazione-di-sottoinsiemi-di-oggetti-in-r",
    "href": "chapters/R/01_r_syntax.html#estrazione-di-sottoinsiemi-di-oggetti-in-r",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.15 Estrazione di Sottoinsiemi di Oggetti in R",
    "text": "5.15 Estrazione di Sottoinsiemi di Oggetti in R\nIn R esistono tre operatori principali per estrarre sottoinsiemi di oggetti:\n\nOperatore [ ]\nQuesto operatore restituisce sempre un oggetto della stessa classe dell’originale. È utile per selezionare più elementi da un oggetto. È importante chiudere l’estrazione con ].\nOperatore [[ ]]\nQuesto operatore viene utilizzato per estrarre elementi da liste o data frame. A differenza di [ ], permette di estrarre un solo elemento alla volta e la classe dell’oggetto restituito non sarà necessariamente una lista o un data frame. L’estrazione va chiusa con ]].\nOperatore $\nCome visto in precedenza, questo operatore serve per estrarre elementi da una lista o un data frame utilizzando il loro nome letterale. Il comportamento semantico è simile a quello di [[ ]].\n\n\n5.15.1 Gli Indici di un Data Frame in R\nIn R, gli indici di un data frame sono utilizzati per selezionare righe e colonne. La sintassi generale è:\ndf[i, j]\ndove:\n\n\ni rappresenta l’indice o gli indici delle righe,\n\n\nj rappresenta l’indice o gli indici delle colonne.\n\nSe uno degli indici viene omesso, si considerano tutte le righe o tutte le colonne, a seconda della dimensione omessa.\n\n5.15.1.1 Esempi Pratici\n\n\nSelezione di righe specifiche su tutte le colonne\nSe vogliamo estrarre solo alcune righe, possiamo specificare gli indici delle righe nel primo argomento e lasciare vuoto il secondo. Ad esempio:\ndf[c(2, 3, 5), ]\nQuesto seleziona la seconda, terza e quinta riga del data frame df, includendo tutte le colonne.\n\n\nSelezione di colonne specifiche su tutte le righe\nPer selezionare solo alcune colonne, specifichiamo i loro indici nel secondo argomento e lasciamo vuoto il primo. Ad esempio:\ndf[, c(2, 3, 5)]\nQuesto seleziona la seconda, terza e quinta colonna del data frame df, includendo tutte le righe.\n\n\nSelezione di righe e colonne specifiche\nPossiamo combinare gli indici per selezionare una sotto-matrice specifica. Ad esempio:\ndf[c(2, 4), c(1, 3)]\nQuesto seleziona le righe 2 e 4 e le colonne 1 e 3.\n\n\n5.15.1.2 Ulteriori Dettagli\n\n\nSelezione singola di riga o colonna\nSe vogliamo estrarre una singola riga o colonna, possiamo specificare un solo valore per i o j. Ad esempio:\ndf[1, ]  # Prima riga, tutte le colonne\ndf[, 2]  # Seconda colonna, tutte le righe\n\n\nUso di nomi invece di indici\nSe il data frame ha nomi per righe o colonne, possiamo utilizzarli per la selezione. Ad esempio:\ndf[\"nome_riga\", ]        # Seleziona la riga con nome \"nome_riga\"\ndf[, \"nome_colonna\"]     # Seleziona la colonna con nome \"nome_colonna\"\n\n\nSelezione logica\nPossiamo utilizzare un vettore logico per selezionare righe o colonne. Ad esempio, per selezionare le righe dove il valore nella prima colonna è maggiore di 10:\ndf[df[, 1] &gt; 10, ]\n\n\n5.15.1.3 Sintesi Visiva\n\n\n\n\n\n\nSintassi\nDescrizione\n\n\n\ndf[i, ]\nSeleziona la riga i con tutte le colonne.\n\n\ndf[, j]\nSeleziona la colonna j con tutte le righe.\n\n\ndf[c(i1, i2), c(j1, j2)]\nSeleziona righe e colonne specifiche.\n\n\ndf[i, j]\nSeleziona l’intersezione di righe e colonne.\n\n\ndf[ , ]\nRestituisce l’intero data frame.\n\n\n\nQuesta flessibilità rende l’indicizzazione dei data frame in R potente ed efficace per manipolare e analizzare i dati.\n\nEsempio 5.5 Consideriamo il data frame iris incluso di default in base R.\n\niris |&gt; head()\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 2          4.9         3.0          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\n#&gt; 4          4.6         3.1          1.5         0.2  setosa\n#&gt; 5          5.0         3.6          1.4         0.2  setosa\n#&gt; 6          5.4         3.9          1.7         0.4  setosa\n\nUsiamo la funzione head() per stampare le prime 6 righe del data frame.\nL’istruzione seguente restituisce le prime tre colonne del dataset iris.\n\niris[, 1:3] |&gt; head()\n#&gt;   Sepal.Length Sepal.Width Petal.Length\n#&gt; 1          5.1         3.5          1.4\n#&gt; 2          4.9         3.0          1.4\n#&gt; 3          4.7         3.2          1.3\n#&gt; 4          4.6         3.1          1.5\n#&gt; 5          5.0         3.6          1.4\n#&gt; 6          5.4         3.9          1.7\n\nSelezione di colonne specifiche per nome:\n\niris[, c('Sepal.Length', 'Petal.Length')] |&gt; \n  head()  \n#&gt;   Sepal.Length Petal.Length\n#&gt; 1          5.1          1.4\n#&gt; 2          4.9          1.4\n#&gt; 3          4.7          1.3\n#&gt; 4          4.6          1.5\n#&gt; 5          5.0          1.4\n#&gt; 6          5.4          1.7\n\nSelezione di una singola colonna:\n\niris[, 'Petal.Length'] \n#&gt;   [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3\n#&gt;  [18] 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4\n#&gt;  [35] 1.5 1.2 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7\n#&gt;  [52] 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1\n#&gt;  [69] 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5\n#&gt;  [86] 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1\n#&gt; [103] 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9\n#&gt; [120] 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1\n#&gt; [137] 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1\n\noppure\n\niris$Petal.Length\n#&gt;   [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3\n#&gt;  [18] 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4\n#&gt;  [35] 1.5 1.2 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7\n#&gt;  [52] 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1\n#&gt;  [69] 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5\n#&gt;  [86] 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1\n#&gt; [103] 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9\n#&gt; [120] 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1\n#&gt; [137] 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1\n\nPer selezionare righe specifiche, definiamo gli indici corrispondenti. Per esempio, l’istruzione seguente restituisce le righe 1 e 3.\n\niris[c(1, 3), ]\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\n\nFiltraggio logico di righe:\n\niris[iris$Species == 'versicolor', ] |&gt; head()\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; 51          7.0         3.2          4.7         1.4 versicolor\n#&gt; 52          6.4         3.2          4.5         1.5 versicolor\n#&gt; 53          6.9         3.1          4.9         1.5 versicolor\n#&gt; 54          5.5         2.3          4.0         1.3 versicolor\n#&gt; 55          6.5         2.8          4.6         1.5 versicolor\n#&gt; 56          5.7         2.8          4.5         1.3 versicolor\n\nRestituisce le righe con Species uguale a “versicolor”. Numero di righe e colonne del sottoinsieme:\n\ndim(iris[iris$Species == 'versicolor', ])\n#&gt; [1] 50  5\n\n\n\n5.15.2 Filtraggio Avanzato con Operatori Logici\nGli operatori logici & (AND), | (OR) e ! (NOT) permettono un filtraggio più sofisticato.\nEsempio: Filtrare le osservazioni di specie “versicolor” con lunghezza del sepalo non superiore a 5.0:\n\niris[(iris$Species == 'versicolor') & (iris$Sepal.Length &lt;= 5.0), ]\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; 58          4.9         2.4          3.3           1 versicolor\n#&gt; 61          5.0         2.0          3.5           1 versicolor\n#&gt; 94          5.0         2.3          3.3           1 versicolor\n\nNumero di osservazioni trovate:\n\ndim(iris[(iris$Species == 'versicolor') & (iris$Sepal.Length &lt;= 5.0), ])\n#&gt; [1] 3 5",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#riflessioni-conclusive",
    "href": "chapters/R/01_r_syntax.html#riflessioni-conclusive",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n5.16 Riflessioni Conclusive",
    "text": "5.16 Riflessioni Conclusive\nR non è soltanto un linguaggio di programmazione per la statistica, ma rappresenta una filosofia che si fonda su tre principi chiave: apertura, collaborazione e avanzamento della conoscenza scientifica.\nPer chi si avvicina a R, sia nel campo della comunicazione sia in altri ambiti, cogliere questa filosofia è essenziale per apprezzarne appieno il valore. R promuove non solo competenze tecniche, ma anche un impegno verso pratiche di ricerca trasparente e riproducibile, che costituiscono un pilastro fondamentale per una scienza rigorosa e affidabile.\nOpen Source\nR è un software open source, liberamente accessibile a tutti. Questo significa che chiunque può visualizzarne, modificarne e distribuirne il codice sorgente, promuovendo un ambiente trasparente e collaborativo. Essendo gratuito, R garantisce accessibilità a ricercatori di tutto il mondo, indipendentemente dal budget o dal supporto istituzionale. Inoltre, grazie alla sua natura aperta, R beneficia del contributo collettivo di una comunità globale eterogenea.\nContributi della Comunità\nLa comunità di R è uno dei suoi punti di forza principali. Statistici, ricercatori e data scientist di diverse discipline arricchiscono continuamente R sviluppando pacchetti: raccolte di funzioni, dati e codice che ampliano le sue funzionalità. Questa collaborazione ha portato alla creazione di migliaia di pacchetti che coprono tecniche statistiche, metodi grafici e strumenti per la manipolazione dei dati, rendendo R uno strumento sempre più versatile e adatto a un’ampia gamma di esigenze di ricerca.\nRicerca Riproducibile\nLa ricerca riproducibile consiste nel condurre studi in modo tale che altri possano replicarne i risultati utilizzando gli stessi dati e seguendo la stessa metodologia. Questo approccio è cruciale per la validazione delle scoperte scientifiche, permettendo la verifica dei risultati e la costruzione di nuove conoscenze su basi solide.\nR facilita la ricerca riproducibile grazie a:\n\nUn ecosistema completo di pacchetti per l’analisi dei dati e la generazione di report dinamici.\n\nStrumenti come R Markdown e Quarto, che permettono di integrare testo descrittivo e codice R in un unico documento. Questa integrazione consente di documentare ogni fase del processo di ricerca—dalla pulizia dei dati all’analisi e alla presentazione dei risultati—garantendo trasparenza e replicabilità.\n\nIn conclusione, comprendere la filosofia open source di R e il suo ruolo nella promozione della ricerca riproducibile fornisce un quadro chiaro del motivo per cui R è diventato uno strumento essenziale per ricercatori e statistici di diverse discipline. Per chi opera in psicologia, sfruttare le potenzialità di R significa produrre risultati di ricerca più trasparenti, replicabili e credibili, contribuendo alla robustezza e affidabilità della conoscenza scientifica nel settore.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#esercizi",
    "href": "chapters/R/01_r_syntax.html#esercizi",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nSvolgere gli esercizi da 1 a 38, sia in modo manuale che utilizzando R. Gli esercizi sono disponibili al seguente link:Esercizi su Summation Notation.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nIn questo esercizio, lavorerai con i dati della Satisfaction With Life Scale (SWLS) raccolti da ciascuno degli studenti del gruppo TPV di appartenenza.\nIstruzioni SWLS: Di seguito sono riportate alcune affermazioni con cui puoi descrivere la tua soddisfazione rispetto alla tua vita. Indica quanto sei d’accordo con ciascuna affermazione utilizzando la scala di risposta fornita.\n\nIl più delle volte la mia vita è vicina al mio ideale di vita.\nLe condizioni della mia vita sono eccellenti.\nSono soddisfatto/a della mia vita.\nFinora ho ottenuto le cose importanti che voglio dalla vita.\nSe io potessi rivivere la mia vita, non cambierei quasi nulla.\n\nLa SWLS utilizza una scala Likert a 7 punti, con i seguenti ancoraggi:\n\nFortemente in disaccordo\nDisaccordo\nLeggermente in disaccordo\nNé d’accordo né in disaccordo\nLeggermente d’accordo\nD’accordo\nFortemente d’accordo\n\nIl tuo compito sarà analizzare i dati raccolti sia manualmente su carta che utilizzando R.\nParte 1: Calcolo Manuale\n\n\nCalcolo del punteggio totale\n\nLa SWLS è composta da 5 item, ciascuno valutato su una scala Likert da 1 a 7.\nSomma i punteggi dei 5 item per ciascun partecipante per ottenere il punteggio totale.\n\nRegistra i punteggi totali su carta.\n\n\n\nDeterminazione della media del campione\n\nCalcola la media aritmetica dei punteggi totali dei 10 studenti.\nScrivi il calcolo e il risultato.\n\n\n\nCalcolo della deviazione standard\n\n\nCalcola la deviazione standard dei punteggi totali manualmente utilizzando la formula:\n\\[\ns^2 = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1}}.\n\\]\n\nRegistra il risultato.\n\n\n\nParte 2: Analisi con R\n\n\nCreazione del dataset in R\n\nInserisci i dati in R come un vettore chiamato swls_scores.\n\n\n\nCalcolo della media e della deviazione standard in R\n\nUsa le funzioni mean() e sd() per ottenere la media e la deviazione standard dei punteggi totali.\n\n\n\nVisualizzazione dei dati\n\nCrea un istogramma per visualizzare la distribuzione dei punteggi totali utilizzando hist(). Se non conosci l’istogramma, fai una ricerca su web; commenta il risultato ottenuto.\n\n\n\nIdentificazione dei punteggi superiori a 20\n\nUtilizza un’operazione logica per contare quanti partecipanti hanno un punteggio totale maggiore di 20.\n\n\n\nFiltraggio dei dati\n\nEstrai e visualizza solo i punteggi superiori alla media del campione.\n\n\n\nEsportazione dei risultati\n\nSalva i punteggi totali in un file CSV utilizzando la funzione write.csv().\n\n\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nParte 1: Calcolo Manuale\n\n\nCalcolo del punteggio totale\n\n\nSupponiamo che i punteggi per 10 studenti siano:\n\n\nStudente\nItem 1\nItem 2\nItem 3\nItem 4\nItem 5\nTotale\n\n\n\n1\n5\n4\n6\n3\n2\n20\n\n\n2\n4\n2\n5\n3\n2\n16\n\n\n3\n6\n4\n6\n4\n3\n23\n\n\n4\n7\n6\n5\n3\n4\n25\n\n\n5\n3\n2\n3\n2\n1\n11\n\n\n6\n2\n1\n2\n1\n1\n7\n\n\n7\n5\n4\n5\n3\n3\n20\n\n\n8\n6\n5\n7\n4\n3\n25\n\n\n9\n4\n3\n4\n2\n2\n15\n\n\n10\n7\n6\n5\n5\n4\n27\n\n\n\n\n\n\n\nDeterminazione della media\n\n\nMedia:\n\\[\n\\bar{x} = \\frac{20+16+23+25+11+7+20+25+15+27}{10} = 18.9\n\\]\n\n\n\n\nCalcolo della deviazione standard\n\n\nLa deviazione standard è:\n\\[\ns = \\sqrt{\\frac{1}{9} \\sum (x_i - 18.9)^2} \\approx 6.56\n\\]\n\n\n\n\nParte 2: Analisi con R\n\n\nCreazione del dataset in R\nswls_scores &lt;- c(20, 16, 23, 25, 11, 7, 20, 25, 15, 27)\n\n\nCalcolo della media e della deviazione standard\nmean(swls_scores)  # Media\nsd(swls_scores)    # Deviazione standard\n\n\nVisualizzazione dei dati\nhist(swls_scores, main=\"Distribuzione SWLS\", xlab=\"Punteggi\", col=\"lightblue\", border=\"black\")\n\n\nIdentificazione dei punteggi superiori a 20\nsum(swls_scores &gt; 20)  # Numero di studenti con punteggio &gt; 20\n\n\nFiltraggio dei dati\nswls_scores[swls_scores &gt; mean(swls_scores)]\n\n\nEsportazione dei risultati\nwrite.csv(data.frame(Student=1:10, Score=swls_scores), \"swls_results.csv\", row.names=FALSE)\n\n\nConclusione Questi esercizi hanno permesso di confrontare il calcolo manuale con l’automatizzazione tramite R, facilitando l’analisi statistica della SWLS.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/01_r_syntax.html#informazioni-sullambiente-di-sviluppo",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#bibliografia",
    "href": "chapters/R/01_r_syntax.html#bibliografia",
    "title": "5  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A. (2020). Analysis of open data and computational reproducibility in registered reports in psychology. Advances in Methods and Practices in Psychological Science, 3(2), 229–237.\n\n\nOkoye, K., & Hosseini, S. (2024). Introduction to R Programming and RStudio Integrated Development Environment (IDE). In R Programming: Statistical Data Analysis in Research (pp. 3–24). Springer.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html",
    "href": "chapters/R/02_utility_functions.html",
    "title": "6  Utility functions in R",
    "section": "",
    "text": "6.1 Introduzione\nIn questo capitolo esamineremo le principali funzioni di utilità di R per raccogliere statistiche descrittive e altre informazioni generali sui data frame.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Utility functions in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#introduzione",
    "href": "chapters/R/02_utility_functions.html#introduzione",
    "title": "6  Utility functions in R",
    "section": "",
    "text": "6.1.1 Funzioni principali e loro utilizzo\n\n\n\n\n\n\nFunzione\nDescrizione\n\n\n\nsummary()\nRestituisce statistiche descrittive di base per ogni colonna di un data frame. Per le colonne numeriche, calcola valori come il minimo, massimo, media, mediana, primo e terzo quartile, e il numero di valori mancanti (se presenti). Per le colonne non numeriche, restituisce il tipo di dati (carattere, logico) e il conteggio delle categorie. Esempio: summary(iris) restituisce una sintesi delle colonne del dataset iris.\n\n\n\nstr() e glimpse()\n\nForniscono una rappresentazione sintetica delle informazioni di un data frame, come dimensione, nomi delle colonne, tipi di dati e valori iniziali. La funzione str() fa parte della configurazione base di R (pacchetto utils), mentre glimpse() è inclusa in dplyr (pacchetto tidyverse). Esempio: str(mtcars) o glimpse(mtcars).\n\n\n\nhead() e tail()\n\nPermettono di visualizzare rispettivamente le prime o ultime righe di un data frame. Utile per una rapida ispezione del contenuto. Si può specificare il numero di righe da mostrare (es. head(df, 10)), altrimenti il valore predefinito è sei righe. Esempio: head(iris) per vedere le prime righe del dataset iris.\n\n\n\nView() e view()\n\nVisualizzano un data frame in una finestra grafica tipo foglio di calcolo all’interno di RStudio. La funzione View() è parte della configurazione base di R, mentre view() è un alias fornito da tibble (pacchetto tidyverse). Utile per piccoli data frame, ma poco pratico per dataset di grandi dimensioni. Esempio: View(iris) apre il dataset iris nel visualizzatore di RStudio.\n\n\nunique()\nRestituisce i valori unici presenti in una colonna o in un vettore. Esempio: unique(iris$Species) restituisce le specie uniche nel dataset iris.\n\n\nnames()\nRestituisce i nomi delle colonne di un data frame. Esempio: names(mtcars) restituisce i nomi delle colonne del dataset mtcars.\n\n\nclass()\nIndica il tipo di dato di un oggetto in R, come numeric, character, logical, o data.frame. Esempio: class(iris) restituisce data.frame.\n\n\nlength()\nRestituisce il numero di elementi di un oggetto. Per i data frame, restituisce il numero di colonne. Esempio: length(iris) restituisce 5 (colonne).\n\n\n\nnrow() e ncol()\n\nRestituiscono rispettivamente il numero di righe e colonne di un data frame. Esempio: nrow(iris) restituisce 150 (righe), mentre ncol(iris) restituisce 5 (colonne).\n\n\n\nQuesti strumenti rappresentano la base per esplorare rapidamente i dati e comprenderne la struttura prima di passare a manipolazioni più avanzate.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Utility functions in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#un-esempio-concreto",
    "href": "chapters/R/02_utility_functions.html#un-esempio-concreto",
    "title": "6  Utility functions in R",
    "section": "\n6.2 Un Esempio Concreto",
    "text": "6.2 Un Esempio Concreto\nImportiamo il dataset msleep contenuto nel pacchetto ggplot2 che abbiamo caricato in precedenza:\n\ndata(msleep)\n\nEsaminiamo la struttura del data frame usando str():\n\nstr(msleep)\n#&gt; tibble [83 × 11] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ name        : chr [1:83] \"Cheetah\" \"Owl monkey\" \"Mountain beaver\" \"Greater short-tailed shrew\" ...\n#&gt;  $ genus       : chr [1:83] \"Acinonyx\" \"Aotus\" \"Aplodontia\" \"Blarina\" ...\n#&gt;  $ vore        : chr [1:83] \"carni\" \"omni\" \"herbi\" \"omni\" ...\n#&gt;  $ order       : chr [1:83] \"Carnivora\" \"Primates\" \"Rodentia\" \"Soricomorpha\" ...\n#&gt;  $ conservation: chr [1:83] \"lc\" NA \"nt\" \"lc\" ...\n#&gt;  $ sleep_total : num [1:83] 12.1 17 14.4 14.9 4 14.4 8.7 7 10.1 3 ...\n#&gt;  $ sleep_rem   : num [1:83] NA 1.8 2.4 2.3 0.7 2.2 1.4 NA 2.9 NA ...\n#&gt;  $ sleep_cycle : num [1:83] NA NA NA 0.133 0.667 ...\n#&gt;  $ awake       : num [1:83] 11.9 7 9.6 9.1 20 9.6 15.3 17 13.9 21 ...\n#&gt;  $ brainwt     : num [1:83] NA 0.0155 NA 0.00029 0.423 NA NA NA 0.07 0.0982 ...\n#&gt;  $ bodywt      : num [1:83] 50 0.48 1.35 0.019 600 ...\n\noppure usando glimpse():\n\nglimpse(msleep)\n#&gt; Rows: 83\n#&gt; Columns: 11\n#&gt; $ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater …\n#&gt; $ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", …\n#&gt; $ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"…\n#&gt; $ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", …\n#&gt; $ conservation &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"…\n#&gt; $ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.…\n#&gt; $ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0…\n#&gt; $ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.1333, 0.6667, 0.7667, 0.3833, NA, 0.333…\n#&gt; $ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.…\n#&gt; $ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.0700…\n#&gt; $ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, …\n\nStampiamo le prime righe del data frame:\n\nhead(msleep)\n#&gt; # A tibble: 6 × 11\n#&gt;   name                genus      vore  order        conservation sleep_total\n#&gt;   &lt;chr&gt;               &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 Cheetah             Acinonyx   carni Carnivora    lc                  12.1\n#&gt; 2 Owl monkey          Aotus      omni  Primates     &lt;NA&gt;                17  \n#&gt; 3 Mountain beaver     Aplodontia herbi Rodentia     nt                  14.4\n#&gt; 4 Greater short-tail… Blarina    omni  Soricomorpha lc                  14.9\n#&gt; 5 Cow                 Bos        herbi Artiodactyla domesticated         4  \n#&gt; 6 Three-toed sloth    Bradypus   herbi Pilosa       &lt;NA&gt;                14.4\n#&gt; # ℹ 5 more variables: sleep_rem &lt;dbl&gt;, sleep_cycle &lt;dbl&gt;, awake &lt;dbl&gt;,\n#&gt; #   brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt;\n\noppure le ultime righe:\n\ntail(msleep)\n#&gt; # A tibble: 6 × 11\n#&gt;   name                 genus    vore  order        conservation sleep_total\n#&gt;   &lt;chr&gt;                &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 Tenrec               Tenrec   omni  Afrosoricida &lt;NA&gt;                15.6\n#&gt; 2 Tree shrew           Tupaia   omni  Scandentia   &lt;NA&gt;                 8.9\n#&gt; 3 Bottle-nosed dolphin Tursiops carni Cetacea      &lt;NA&gt;                 5.2\n#&gt; 4 Genet                Genetta  carni Carnivora    &lt;NA&gt;                 6.3\n#&gt; 5 Arctic fox           Vulpes   carni Carnivora    &lt;NA&gt;                12.5\n#&gt; 6 Red fox              Vulpes   carni Carnivora    &lt;NA&gt;                 9.8\n#&gt; # ℹ 5 more variables: sleep_rem &lt;dbl&gt;, sleep_cycle &lt;dbl&gt;, awake &lt;dbl&gt;,\n#&gt; #   brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt;\n\nEsaminiamo le modalità della variabile qualitativa vore:\n\nunique(msleep$vore)\n#&gt; [1] \"carni\"   \"omni\"    \"herbi\"   NA        \"insecti\"\n\nSe vogliamo la numerosità di ciascuna categoria, possiamo usare table():\n\ntable(msleep$vore)\n#&gt; \n#&gt;   carni   herbi insecti    omni \n#&gt;      19      32       5      20\n\nSi noti che table() esclude i dati mancanti.\nStampiamo i nomi delle colonne del data frame:\n\nnames(msleep)\n#&gt;  [1] \"name\"         \"genus\"        \"vore\"         \"order\"       \n#&gt;  [5] \"conservation\" \"sleep_total\"  \"sleep_rem\"    \"sleep_cycle\" \n#&gt;  [9] \"awake\"        \"brainwt\"      \"bodywt\"\n\nEsaminiamo il tipo di variabile della colonna vore:\n\nclass(msleep$vore)\n#&gt; [1] \"character\"\n\nLe dimensioni del data frame sono date da:\n\ndim(msleep)\n#&gt; [1] 83 11\n\nladdove il primo valore è il numero di righe e il secondo valore è il numero di colonne.\nIl numero di elementi di un vettore è dato da:\n\nlength(msleep$vore)\n#&gt; [1] 83\n\nIn alternativa, possiamo usare nrow()\n\nnrow(msleep)\n#&gt; [1] 83\n\nper il numero di righe e ncol()\n\nncol(msleep)\n#&gt; [1] 11\n\nper il numero di colonne. In maniera equivalente:\n\ndim(msleep)[2]\n#&gt; [1] 11",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Utility functions in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#esercizi",
    "href": "chapters/R/02_utility_functions.html#esercizi",
    "title": "6  Utility functions in R",
    "section": "\n6.3 Esercizi",
    "text": "6.3 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, utilizzerai R per esplorare i dati raccolti con il questionario Satisfaction With Life Scale (SWLS) dagli studenti del tuo gruppo TPV. L’obiettivo è familiarizzare con le funzioni di base di R per caricare, visualizzare e manipolare i dati.\nParte 1: Operazioni Manuali\n\n\nCreazione e gestione degli oggetti in R\n\nScrivi su carta i comandi R che creerebbero un oggetto chiamato swls_scores contenente i punteggi di 10 studenti.\nQuali sono le regole per assegnare un nome a un oggetto in R?\n\n\n\nVisualizzazione dei dati\n\nScrivi il comando R per visualizzare il contenuto dell’oggetto swls_scores.\nCome puoi visualizzare solo i primi 5 valori del vettore?\n\n\n\nEsplorazione della struttura dei dati\n\nScrivi i comandi R per verificare il tipo di dati contenuti in swls_scores.\nCome puoi verificare quanti elementi contiene?\n\n\n\nParte 2: Esecuzione in R\n\n\nCreazione del dataset in R\n\nInserisci i dati in un oggetto chiamato swls_scores in R.\n\n\n\nVerifica della struttura dei dati\n\nUsa le funzioni str(), class(), length(), nrow(), ncol() su swls_scores.\nAnnota i risultati e spiega a parole loro significato.\n\n\n\nVisualizzazione dei dati\n\nUsa head() e tail() per esplorare i dati.\n\nQual è la differenza tra le due funzioni?\n\n\n\nIdentificazione dei valori unici\n\nUsa unique(swls_scores) per individuare i punteggi distinti.\n\n\n\nCreazione di una tabella con i dati\n\nTrasforma swls_scores in un data frame con una colonna \"Punteggio\" e una colonna \"Studente\" (numerata da 1 a 10).\n\n\n\nEsportazione dei dati\n\nSalva il data frame in un file CSV chiamato \"swls_data.csv\" usando write.csv().\n\n\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nParte 1: Operazioni Manuali\n\n\nCreazione e gestione degli oggetti in R\n\n\nConsideriamo dei valori di risposta arbitrari. Il comando per creare l’oggetto swls_scores è:\nswls_scores &lt;- c(20, 16, 23, 25, 11, 7, 20, 25, 15, 27)\n\n\nRegole per assegnare un nome a un oggetto in R:\n\nNon può iniziare con un numero.\nNon può contenere spazi o caratteri speciali (tranne _ e .).\nNon deve avere lo stesso nome di funzioni già esistenti.\n\n\n\n\n\nVisualizzazione dei dati\n\n\nPer visualizzare il contenuto:\nswls_scores\n\n\nPer visualizzare solo i primi 5 valori:\nhead(swls_scores, 5)\n\n\n\n\nEsplorazione della struttura dei dati\n\n\nPer verificare il tipo di dati:\nclass(swls_scores)\n\n\nPer verificare il numero di elementi:\nlength(swls_scores)\n\n\n\n\nParte 2: Esecuzione in R\n\n\nCreazione del dataset in R\nswls_scores &lt;- c(20, 16, 23, 25, 11, 7, 20, 25, 15, 27)\n\n\nVerifica della struttura dei dati\nstr(swls_scores)\nclass(swls_scores)\nlength(swls_scores)\n\n\nstr() mostra che swls_scores è un vettore numerico.\n\nclass() conferma che è di tipo \"numeric\".\n\nlength() indica che il vettore ha 10 elementi.\n\n\n\nVisualizzazione dei dati\nhead(swls_scores)\ntail(swls_scores)\n\n\nhead() mostra i primi 6 elementi, tail() gli ultimi 6.\n\n\n\nIdentificazione dei valori unici\nunique(swls_scores)\n\nRestituisce: 7, 11, 15, 16, 20, 23, 25, 27.\n\n\n\nCreazione di una tabella con i dati\ndf_swls &lt;- data.frame(Studente = 1:10, Punteggio = swls_scores)\ndf_swls\n\n\nEsportazione dei dati\nwrite.csv(df_swls, \"swls_data.csv\", row.names=FALSE)\n\n\nConclusione\nQuesti esercizi hanno introdotto i comandi di base per creare, visualizzare e manipolare dati in R.\n\n\n\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#&gt;  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3   \n#&gt;  [9] grid_4.4.2        timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    mnormt_2.1.1      cli_3.6.4         rlang_1.1.5      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-167      rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Utility functions in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#bibliografia",
    "href": "chapters/R/02_utility_functions.html#bibliografia",
    "title": "6  Utility functions in R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Utility functions in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html",
    "href": "chapters/R/03_r_programming.html",
    "title": "7  Programmazione in R",
    "section": "",
    "text": "7.1 Introduzione\nIn questo capitolo esploreremo tre strumenti fondamentali per la scrittura di codice in R: le funzioni, le istruzioni condizionali e i cicli. Questi elementi costituiscono la base per sviluppare script flessibili, efficienti e riutilizzabili, essenziali per ogni programmatore o analista che utilizza R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#funzioni",
    "href": "chapters/R/03_r_programming.html#funzioni",
    "title": "7  Programmazione in R",
    "section": "\n7.2 Funzioni",
    "text": "7.2 Funzioni\nR offre un’ampia gamma di funzioni integrate per supportare l’analisi statistica, la manipolazione dei dati e la visualizzazione grafica, rendendolo uno strumento estremamente versatile per diverse esigenze.\nEsempi di funzioni comuni includono:\n\n# Sommare numeri\nsum(1, 2, 3)  # Restituisce la somma dei numeri\n#&gt; [1] 6\n\n\n# Creare un grafico semplice\nplot(1:10, 1:10)  # Crea un grafico a dispersione dei valori\n\n\n\n\n\n\n\nIn sostanza, una funzione è un blocco di codice progettato per svolgere un’operazione specifica. Puoi pensare a una funzione come a una “black box”: fornisci un input (i dati), la funzione elabora l’informazione attraverso le sue istruzioni e restituisce un output (il risultato). Questo approccio modulare semplifica il lavoro, permettendo di riutilizzare e combinare facilmente diverse operazioni.\n\n7.2.1 Creare Funzioni Personalizzate\nLa creazione di funzioni personalizzate in R è uno strumento essenziale per migliorare la programmazione, soprattutto per gestire operazioni ripetitive o complesse. Le funzioni consentono di rendere il codice più leggibile, efficiente e riutilizzabile, promuovendo un approccio organizzato e chiaro alla risoluzione dei problemi.\n\n7.2.1.1 Vantaggi delle Funzioni Personalizzate\nL’uso di funzioni personalizzate offre numerosi benefici:\n\n\nChiarezza e leggibilità: Un nome descrittivo permette di comprendere immediatamente lo scopo della funzione, anche a distanza di tempo o per altri utenti che leggono il codice.\n\n\nManutenzione semplificata: Modificare il codice all’interno di una funzione aggiorna automaticamente tutte le sue occorrenze, riducendo il rischio di errori e semplificando il debugging.\n\n\nRiduzione degli errori: Si evitano gli errori tipici del copia-e-incolla, come omissioni o incoerenze nei programmi complessi.\n\n\nRiutilizzabilità: Una funzione ben progettata può essere utilizzata in più contesti o progetti, risparmiando tempo e sforzi.\n\n7.2.1.2 Quando Creare una Funzione?\nUn buon criterio per decidere se creare una funzione è osservare se il medesimo blocco di codice viene copiato più volte. Se ti trovi a ripetere lo stesso codice più di due volte, probabilmente è il momento di creare una funzione. Questo aiuta a scrivere codice più pulito, scalabile e professionale, migliorando anche la sostenibilità del lavoro a lungo termine.\n\n7.2.2 Sintassi di una Funzione\nLa struttura base di una funzione in R è la seguente:\nnome_funzione &lt;- function(argomenti) {\n  # Corpo della funzione\n  codice\n  return(risultato)  # Facoltativo: restituisce il valore calcolato\n}\n\n\nnome_funzione: Nome della funzione, scelto per descrivere chiaramente la sua finalità.\n\n\nargomenti: Parametri necessari per eseguire le operazioni all’interno della funzione.\n\n\ncodice: Le istruzioni che definiscono il comportamento della funzione.\n\n\nrisultato: Il valore restituito dalla funzione. Se non si usa return(), R restituisce l’ultimo valore calcolato.\n\n\nEsempio 7.1 Immaginiamo di voler creare una funzione per sommare due numeri.\nsomma_due &lt;- function(a, b) {\n  a + b  # Restituisce la somma dei due numeri\n}\nPer utilizzarla, basta richiamarla specificando i parametri:\nsomma_due(5, 3)  # Restituisce 8\nQuesto approccio aiuta a scrivere codice più leggibile e facile da gestire. Ad esempio, se in futuro volessi modificare il comportamento della somma (ad esempio, aggiungere un messaggio di log), basterà intervenire solo all’interno della funzione.\n\n\nEsempio 7.2 Immaginiamo di avere un dataset con i punteggi di 10 individui su 3 subscale di un test psicometrico. L’obiettivo è:\n\nCreare una funzione per calcolare il punteggio totale di un individuo.\nCreare una funzione per trovare il massimo punteggio totale nel campione.\nCreare una funzione per individuare chi ha ottenuto il massimo punteggio.\n\nPasso 1: Simulazione dei Dati. Simuliamo i punteggi di 10 individui su 3 subscale:\n\n# Simulazione dei punteggi\nset.seed(123)\npunteggi &lt;- data.frame(\n  individuo = paste(\"Individuo\", 1:10),\n  subscale1 = sample(30:50, 10, replace = TRUE),\n  subscale2 = sample(40:60, 10, replace = TRUE),\n  subscale3 = sample(35:55, 10, replace = TRUE)\n)\nprint(punteggi)\n#&gt;       individuo subscale1 subscale2 subscale3\n#&gt; 1   Individuo 1        44        44        48\n#&gt; 2   Individuo 2        48        58        51\n#&gt; 3   Individuo 3        43        48        45\n#&gt; 4   Individuo 4        32        42        41\n#&gt; 5   Individuo 5        39        47        55\n#&gt; 6   Individuo 6        47        46        46\n#&gt; 7   Individuo 7        40        49        49\n#&gt; 8   Individuo 8        34        48        44\n#&gt; 9   Individuo 9        49        58        47\n#&gt; 10 Individuo 10        43        43        41\n\nLa funzione sample() in R è utilizzata per estrarre casualmente un sottoinsieme di valori da un vettore. Nell’esempio sopra, sample() viene utilizzata per generare casualmente i punteggi delle subscale dei test psicometrici.\nNell’istruzione subscale1 &lt;- sample(30:50, 10, replace = TRUE)\n\n\n30:50: Rappresenta il vettore di numeri interi da cui vengono estratti i punteggi (valori possibili tra 30 e 50).\n\n10: Indica che vogliamo estrarre 10 valori.\n\nreplace = TRUE: Consente che lo stesso valore possa essere estratto più volte (estrazione con ripetizione).\n\nPasso 2: Creazione delle Funzioni.\n\n\nCalcolo del punteggio totale per ogni individuo\nQuesta funzione somma i punteggi delle subscale di un individuo:\n\ncalcola_totale &lt;- function(subscale1, subscale2, subscale3) {\n  return(subscale1 + subscale2 + subscale3)\n}\n\n\n\nTrovare il punteggio massimo nel campione\nQuesta funzione accetta un vettore di punteggi totali e restituisce il valore massimo:\n\ntrova_massimo &lt;- function(punteggi_totali) {\n  return(max(punteggi_totali))\n}\n\n\n\nIndividuare l’individuo con il punteggio massimo\nQuesta funzione accetta un data frame con i punteggi e restituisce il nome dell’individuo con il punteggio più alto:\n\ntrova_individuo_massimo &lt;- function(punteggi) {\n  punteggi_totali &lt;- rowSums(punteggi[, c(\"subscale1\", \"subscale2\", \"subscale3\")])\n  indice_massimo &lt;- which.max(punteggi_totali)\n  return(punteggi$individuo[indice_massimo])\n}\n\nLa funzione which.max() restituisce l’indice della posizione in cui si trova il valore massimo in un vettore.\n\n\nPasso 3: Applicazione delle Funzioni\n\n\nCalcolo dei punteggi totali per ogni individuo\nApplichiamo la funzione ai dati simulati:\n\npunteggi$punteggio_totale &lt;- with(\n  punteggi, calcola_totale(subscale1, subscale2, subscale3)\n )\nprint(punteggi)\n#&gt;       individuo subscale1 subscale2 subscale3 punteggio_totale\n#&gt; 1   Individuo 1        44        44        48              136\n#&gt; 2   Individuo 2        48        58        51              157\n#&gt; 3   Individuo 3        43        48        45              136\n#&gt; 4   Individuo 4        32        42        41              115\n#&gt; 5   Individuo 5        39        47        55              141\n#&gt; 6   Individuo 6        47        46        46              139\n#&gt; 7   Individuo 7        40        49        49              138\n#&gt; 8   Individuo 8        34        48        44              126\n#&gt; 9   Individuo 9        49        58        47              154\n#&gt; 10 Individuo 10        43        43        41              127\n\n\n\nTroviamo il punteggio massimo nel campione\n\nmassimo &lt;- trova_massimo(punteggi$punteggio_totale)\nprint(massimo)\n#&gt; [1] 157\n\n\n\nTroviamo chi ha il punteggio massimo\n\nindividuo_massimo &lt;- trova_individuo_massimo(punteggi)\nprint(individuo_massimo)\n#&gt; [1] \"Individuo 2\"\n\n\n\n\n\n7.2.3 Stile\nÈ consigliato di usare nomi di funzioni chiari e descrittivi, preferibilmente verbi (es. compute_mean()). Inoltre, è importante mantenere una struttura leggibile, con spazi coerenti e indentazione.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#istruzioni-condizionali-in-r",
    "href": "chapters/R/03_r_programming.html#istruzioni-condizionali-in-r",
    "title": "7  Programmazione in R",
    "section": "\n7.3 Istruzioni Condizionali in R",
    "text": "7.3 Istruzioni Condizionali in R\nLe istruzioni condizionali permettono di introdurre logica nel tuo codice. Ad esempio, l’operazione x * y si limita a moltiplicare i valori di x e y, senza alcuna logica aggiunta. Con le istruzioni condizionali, puoi dire al programma di eseguire diverse operazioni a seconda che una condizione sia vera (TRUE) o falsa (FALSE).\nL’istruzione condizionale più comune in R è if. Può essere letta come: “Se la condizione è vera, esegui un’azione”. Con else, si estende la logica: “Se la condizione è vera, fai qualcosa; altrimenti fai qualcos’altro”.\nLa struttura generale è questa:\nif (condizione) {\n  # Codice eseguito se la condizione è TRUE\n} else {\n  # Codice eseguito se la condizione è FALSE\n}\nImmagina questa situazione:\n\n“Se un partecipante al test psicologico riporta un punteggio elevato sulla scala di ansia (es. &gt; 15), consigliagli un esercizio di rilassamento. Altrimenti, non è necessario.”\n\nVediamo come rappresentare questa situazione in R.\n\nanxiety_score &lt;- 18 # Punteggio riportato dal partecipante\n\nif (anxiety_score &gt; 15) {\n    exercise &lt;- \"rilassamento\"\n} else {\n    exercise &lt;- \"nessun esercizio\"\n}\n\nexercise\n#&gt; [1] \"rilassamento\"\n\nSe il punteggio è maggiore di 15, il risultato sarà:\n[1] \"rilassamento\"\nSe il punteggio è inferiore o uguale a 15, il risultato sarà:\n[1] \"nessun esercizio\"\n\n7.3.1 Uso di ifelse()\n\nUn’alternativa più compatta a if e else è la funzione ifelse(), utile soprattutto per vettori. Ad esempio, supponiamo di avere i punteggi di ansia di un gruppo di partecipanti e vogliamo decidere se assegnare un esercizio di rilassamento a ciascuno:\n\nanxiety_scores &lt;- c(12, 18, 9, 22, 15)\nexercises &lt;- ifelse(anxiety_scores &gt; 15, \"rilassamento\", \"nessun esercizio\")\n\nIl risultato sarà:\n\nexercises\n#&gt; [1] \"nessun esercizio\" \"rilassamento\"     \"nessun esercizio\"\n#&gt; [4] \"rilassamento\"     \"nessun esercizio\"\n\n\n7.3.2 Creare una Funzione con Istruzioni Condizionali\nLe istruzioni condizionali possono essere racchiuse in una funzione per rendere il codice più flessibile e riutilizzabile. Ad esempio, supponiamo di voler personalizzare un feedback per un partecipante in base al punteggio ottenuto in un questionario:\n\nfeedback &lt;- function(score) {\n    if (score &gt; 15) {\n        \"Consigliamo un esercizio di rilassamento.\"\n    } else if (score &gt; 10) {\n        \"Monitoriamo la situazione, ma non è necessario alcun intervento.\"\n    } else {\n        \"Nessun intervento necessario.\"\n    }\n}\n\n\nfeedback(18)\n#&gt; [1] \"Consigliamo un esercizio di rilassamento.\"\n\n\nfeedback(12)\n#&gt; [1] \"Monitoriamo la situazione, ma non è necessario alcun intervento.\"\n\n\nfeedback(8)\n#&gt; [1] \"Nessun intervento necessario.\"\n\nIn conclusione, le istruzioni condizionali come if, else e ifelse() sono strumenti fondamentali per introdurre logica e controllo nel tuo codice. Puoi usarle per prendere decisioni, gestire errori e rendere il tuo codice più flessibile ed efficiente. Creare funzioni che incorporano queste istruzioni è un passo fondamentale per scrivere codice ordinato e riutilizzabile in contesti psicologici e non solo.\n\n7.3.3 Combinare Operatori Logici in R\nFinora abbiamo creato funzioni abbastanza semplici e mirate. Ora proviamo a realizzare una funzione leggermente più complessa. Immaginiamo di voler determinare se una persona ha avuto una buona giornata basandoci su due criteri:\n\n\nLivello di stress: basso (TRUE) o alto (FALSE).\n\nLivello di supporto sociale percepito: alto (TRUE) o basso (FALSE).\n\nVogliamo creare una funzione che prenda questi due fattori e restituisca un messaggio che descrive come potrebbe essere stata la giornata della persona.\nEcco come possiamo costruire la funzione:\n\ngood_day &lt;- function(low_stress, high_support) {\n    if (low_stress == TRUE && high_support == TRUE) {\n        \"Giornata fantastica! Ti senti calmo e supportato.\"\n    } else if (low_stress == FALSE && high_support == TRUE) {\n        \"Il supporto sociale ti aiuta a gestire lo stress elevato.\"\n    } else if (low_stress == TRUE && high_support == FALSE) {\n        \"Nonostante lo stress sia basso, la mancanza di supporto sociale pesa.\"\n    } else if (low_stress == FALSE && high_support == FALSE) {\n        \"Giornata difficile: stress elevato e poco supporto sociale.\"\n    }\n}\n\nEsempi di utilizzo.\nCaso 1: Stress basso e supporto sociale alto\n\ngood_day(low_stress = TRUE, high_support = TRUE)\n#&gt; [1] \"Giornata fantastica! Ti senti calmo e supportato.\"\n\nCaso 2: Stress elevato e supporto sociale alto.\n\ngood_day(FALSE, TRUE)\n#&gt; [1] \"Il supporto sociale ti aiuta a gestire lo stress elevato.\"\n\nCaso 3: Stress basso e supporto sociale basso.\n\ngood_day(TRUE, FALSE)\n#&gt; [1] \"Nonostante lo stress sia basso, la mancanza di supporto sociale pesa.\"\n\nCaso 4: Stress elevato e supporto sociale basso.\n\ngood_day(FALSE, FALSE)\n#&gt; [1] \"Giornata difficile: stress elevato e poco supporto sociale.\"\n\nLa funzione considera tutte le combinazioni di stress e supporto sociale:\n\n\nStress basso e supporto alto: giornata ideale.\n\nStress elevato e supporto alto: il supporto aiuta a mitigare lo stress.\n\nStress basso e supporto basso: la mancanza di supporto rovina una situazione potenzialmente buona.\n\nStress elevato e supporto basso: la situazione peggiore.\n\nNell’esempio abbiamo usato i seguenti operatori logici:\n\n\n&& (AND logico): Entrambe le condizioni devono essere vere.\n\n== (uguale a): Verifica se una variabile è vera o falsa.\n\nAd esempio, questa condizione:\nif (low_stress == TRUE && high_support == TRUE)\nverifica se il livello di stress è basso e il supporto sociale è alto.\nIn conclusione, questa funzione dimostra come combinare condizioni logiche complesse utilizzando operatori logici come && (AND) e || (OR). Grazie a questi strumenti, possiamo gestire facilmente logiche più articolate, mantenendo il codice leggibile e funzionale.\n\n7.3.4 Gli operatori Logici in R\nGli operatori logici sono essenziali per definire le condizioni nelle istruzioni if. Ecco una tabella riassuntiva con i principali operatori:\n\n\n\n\n\n\n\n\nOperatore\nDescrizione tecnica\nSignificato\nEsempio\n\n\n\n&&\nAND logico\nEntrambe le condizioni devono essere vere\nif(cond1 == test && cond2 == test)\n\n\n||\nOR logico\nAlmeno una condizione deve essere vera\nif(cond1 == test || cond2 == test)\n\n\n&lt;\nMinore di\nX è minore di Y\nif(X &lt; Y)\n\n\n&gt;\nMaggiore di\nX è maggiore di Y\nif(X &gt; Y)\n\n\n&lt;=\nMinore o uguale a\nX è minore o uguale a Y\nif(X &lt;= Y)\n\n\n&gt;=\nMaggiore o uguale a\nX è maggiore o uguale a Y\nif(X &gt;= Y)\n\n\n==\nUguale a\nX è uguale a Y\nif(X == Y)\n\n\n!=\nDiverso da\nX è diverso da Y\nif(X != Y)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#cicli-in-r",
    "href": "chapters/R/03_r_programming.html#cicli-in-r",
    "title": "7  Programmazione in R",
    "section": "\n7.4 Cicli in R",
    "text": "7.4 Cicli in R\nR è particolarmente efficace nell’eseguire attività ripetitive. Quando dobbiamo ripetere un’operazione più volte, possiamo utilizzare un ciclo. I cicli eseguono un insieme di istruzioni per un numero specifico di volte o fino a quando una determinata condizione non è soddisfatta.\nIn R esistono tre tipi principali di cicli:\n\n\nCiclo for: ripete un’operazione per un numero definito di iterazioni.\n\nCiclo while: continua a eseguire le istruzioni fino a quando una condizione logica è soddisfatta.\n\nCiclo repeat: itera indefinitamente fino a quando non viene esplicitamente interrotto con un’istruzione break.\n\nI cicli sono strumenti essenziali in tutti i linguaggi di programmazione, ma in R il loro utilizzo dovrebbe essere valutato attentamente, poiché spesso esistono alternative più efficienti come le funzioni della famiglia apply.\n\n7.4.1 Il ciclo for\n\nIl ciclo for è il più utilizzato per eseguire un’operazione un numero definito di volte. Ecco un esempio base:\n\nfor (i in 1:5) {\n    print(i)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nCome funziona?\n\nL’indice i prende il primo valore della sequenza 1:5 (cioè 1).\nIl corpo del ciclo, ovvero il codice tra { }, viene eseguito.\nAl termine di ogni iterazione, i assume il valore successivo nella sequenza, e il processo si ripete fino all’ultimo valore (5 in questo caso).\n\nAggiungere logica nel corpo del ciclo\nPossiamo aggiungere operazioni all’interno del ciclo, come ad esempio sommare 1 a ogni valore:\n\nfor (i in 1:5) {\n    print(i + 1)\n}\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n#&gt; [1] 6\n\n\n7.4.2 Il ciclo while\n\nIl ciclo while continua a eseguire le istruzioni fino a quando una condizione logica è soddisfatta. Ecco un esempio:\n\ni &lt;- 0\nwhile (i &lt;= 4) {\n    i &lt;- i + 1\n    print(i)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nCome funziona?\n\nLa condizione logica (i &lt;= 4) viene verificata prima di ogni iterazione.\nSe la condizione è vera, il ciclo esegue il codice tra { }.\nQuando la condizione diventa falsa (i &gt; 4), il ciclo si interrompe.\n\n7.4.3 Ciclo repeat\n\nIl ciclo repeat esegue il codice indefinitamente, a meno che non venga interrotto con un’istruzione break:\n\ni &lt;- 0\nrepeat {\n    i &lt;- i + 1\n    print(i)\n    if (i &gt;= 5) {\n        break\n    }\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nQuando usarlo?\nIl ciclo repeat è raro e viene utilizzato solo in situazioni molto particolari. Nella maggior parte dei casi, for o while sono più adatti.\n\n7.4.4 Evitare i cicli: la famiglia di funzioni apply\n\nI cicli in R sono relativamente lenti, specialmente con dataset di grandi dimensioni. Quando possibile, è preferibile usare funzioni della famiglia apply per ottenere lo stesso risultato in modo più efficiente e con meno rischi di errore.\n\n7.4.4.1 La funzione lapply()\n\nlapply() esegue una funzione su ciascun elemento di una lista o vettore e restituisce una lista con i risultati.\nEsempio:\n\nlapply(0:4, function(a) {\n    a + 1\n})\n#&gt; [[1]]\n#&gt; [1] 1\n#&gt; \n#&gt; [[2]]\n#&gt; [1] 2\n#&gt; \n#&gt; [[3]]\n#&gt; [1] 3\n#&gt; \n#&gt; [[4]]\n#&gt; [1] 4\n#&gt; \n#&gt; [[5]]\n#&gt; [1] 5\n\n\n7.4.4.2 La funzione sapply()\n\nlapply() restituisce una lista, ma se vuoi un vettore come output, usa sapply():\n\nsapply(0:4, function(a) {\n    a + 1\n})\n#&gt; [1] 1 2 3 4 5\n\n\n7.4.5 Quando usare i cicli?\nI cicli sono utili quando:\n\nDevi simulare modelli complessi (es. modelli ricorsivi).\nHai bisogno di operazioni che dipendono dai risultati delle iterazioni precedenti.\n\nIn tutti gli altri casi, considera alternative come apply(), lapply() o funzioni simili per un codice più efficiente e meno soggetto a errori.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#linee-guida-per-scrivere-codice",
    "href": "chapters/R/03_r_programming.html#linee-guida-per-scrivere-codice",
    "title": "7  Programmazione in R",
    "section": "\n7.5 Linee Guida per Scrivere Codice",
    "text": "7.5 Linee Guida per Scrivere Codice\nDi seguito trovi alcune linee guida per scrivere codice chiaro, conciso e riutilizzabile:\n\nEvita di ripeterti: Segui il principio Don’t Repeat Yourself (DRY). Scrivi funzioni e utilizza funzioni come map (per applicare un pezzo di codice iterativamente a tutti gli elementi di un oggetto) per evitare di copiare e incollare variazioni minime dello stesso codice in più parti del progetto.\nSegui uno stile coerente: Adotta una guida di stile per mantenere uniformità nel tuo codice. Per R, raccomandiamo la guida di stile del “tidyverse”, scritta da Hadley Wickham. Questa guida, derivata dalla Google R Style Guide, fornisce istruzioni dettagliate su sintassi del codice, nomi delle variabili, spaziature, indentazioni, commenti, convenzioni per scrivere funzioni, utilizzo delle pipe (metodo per concatenare funzioni), e altro ancora.\nCommenta abbondantemente: Usa i commenti (ad esempio, con #) per spiegare perché ogni parte del codice è necessaria e cosa fa. I commenti rendono il codice più leggibile e facilitano la manutenzione futura.\nTesta il tuo codice: Ogni volta che scrivi codice, verifica che funzioni come previsto. Puoi farlo scrivendo funzioni di test specifiche o controllando manualmente che l’output corrisponda alle aspettative. Abituati a pensare a eventuali edge cases (casi limite) in cui il tuo codice potrebbe non comportarsi come previsto.\nEsegui una revisione del codice: Quando possibile, fai revisionare il tuo codice da un’altra persona per individuare errori e incoerenze. Se non hai nessuno a disposizione, puoi rivedere il tuo codice autonomamente: rileggendo con attenzione, è sorprendente il numero di errori che si possono individuare!\n\nSeguendo queste linee guida, potrai scrivere codice più robusto, leggibile e facile da mantenere nel tempo.1",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#riflessioni-conclusive",
    "href": "chapters/R/03_r_programming.html#riflessioni-conclusive",
    "title": "7  Programmazione in R",
    "section": "\n7.6 Riflessioni Conclusive",
    "text": "7.6 Riflessioni Conclusive\nScrivere funzioni è un passaggio essenziale per migliorare la leggibilità, l’efficienza e la riutilizzabilità del codice. Funzioni ben progettate semplificano le modifiche, riducono errori e rendono il lavoro più chiaro, sia per te stesso che per i collaboratori futuri. Se trovi che stai copiando e incollando codice più volte, è il momento di pensare a creare una funzione.\nLe istruzioni condizionali, come if, else e ifelse(), sono fondamentali per introdurre logica e controllo nel codice. Permettono di gestire scenari diversi e prendere decisioni dinamiche, migliorando la flessibilità e l’efficienza dei tuoi script. Combinando queste istruzioni con operatori logici come && e ||, puoi affrontare situazioni complesse con un codice chiaro e leggibile.\nI cicli sono potenti strumenti per eseguire operazioni ripetitive, ma in R il loro utilizzo dovrebbe essere limitato ai casi in cui non esistono alternative più efficienti. Le funzioni apply() e simili rappresentano spesso un’opzione migliore per manipolare dati in modo più rapido e leggibile.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#esercizi",
    "href": "chapters/R/03_r_programming.html#esercizi",
    "title": "7  Programmazione in R",
    "section": "\n7.7 Esercizi",
    "text": "7.7 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, utilizzerai R per praticare la creazione di funzioni, l’uso delle istruzioni condizionali e l’applicazione dei cicli. L’obiettivo è comprendere come scrivere codice più strutturato, riutilizzabile ed efficiente.\nParte 1: Comprensione Teorica\n\n\nCos’è una funzione in R?\n\nDescrivi con parole tue cosa fa una funzione e perché è utile.\n\n\n\nSintassi delle funzioni\n\nScrivi la struttura generale di una funzione in R.\n\n\n\nUso di istruzioni condizionali\n\nQual è la differenza tra if, else e ifelse()? Fornisci un esempio per ciascuno.\n\n\n\nCicli in R\n\nQual è la differenza tra for, while e repeat?\n\n\n\nParte 2: Creazione ed Esecuzione in R\n\n\nCreazione di una funzione per calcolare il punteggio totale SWLS\n\nScrivi una funzione in R chiamata calcola_SWLS() che accetta un vettore con 5 punteggi SWLS e restituisce il totale.\n\n\n\nCondizione per determinare la soddisfazione\n\nScrivi una funzione valuta_soddisfazione() che prende un punteggio SWLS totale e restituisce:\n\n\n\"Alta soddisfazione\" se il punteggio è sopra 24.\n\n\"Soddisfazione moderata\" se è tra 15 e 24.\n\n\"Bassa soddisfazione\" se è inferiore a 15.\n\n\n\n\n\nApplicare una funzione a più individui\n\nScrivi un ciclo for che calcola la soddisfazione per un gruppo di 5 persone e stampa il risultato.\n\n\n\nUso di ifelse()\n\nUsa ifelse() per determinare rapidamente se i punteggi di 5 individui indicano soddisfazione alta (&gt; 24) o bassa (≤ 24).\n\n\n\nCiclo while per controllare input\n\nScrivi un ciclo while che continua a chiedere all’utente di inserire un punteggio SWLS fino a quando non inserisce un valore valido (compreso tra 5 e 35).\n\n\n\nEsportazione dei dati\n\n\n\nSalva in un file CSV \"swls_results.csv\" un data frame contenente i punteggi SWLS e la valutazione della soddisfazione.\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nParte 1: Comprensione Teorica\n\n\nCos’è una funzione in R?\n\nUna funzione è un blocco di codice che esegue un’operazione specifica. Permette di scrivere codice riutilizzabile e più organizzato.\n\n\n\nSintassi delle funzioni\nnome_funzione &lt;- function(argomenti) {\n  # Corpo della funzione\n  return(risultato)\n}\n\n\nUso di istruzioni condizionali\n\n\nif: Controlla una condizione e esegue codice solo se è vera.\n\nif (x &gt; 10) { print(\"Maggiore di 10\") }\n\n\nelse: Esegue codice alternativo se la condizione è falsa.\n\nif (x &gt; 10) { print(\"Maggiore di 10\") } else { print(\"10 o meno\") }\n\n\nifelse(): Alternativa vettorializzata a if.\n\ny &lt;- ifelse(x &gt; 10, \"Alto\", \"Basso\")\n\n\nCicli in R\n\n\nfor: Itera su una sequenza.\n\nfor (i in 1:5) { print(i) }\n\n\nwhile: Continua fino a quando una condizione è vera.\n\ni &lt;- 1\nwhile (i &lt;= 5) { print(i); i &lt;- i + 1 }\n\n\nrepeat: Ripete fino a un break.\n\ni &lt;- 1\nrepeat { print(i); i &lt;- i + 1; if (i &gt; 5) break }\n\n\nParte 2: Creazione ed Esecuzione in R\n\n\nCreazione della funzione per il punteggio totale SWLS\ncalcola_SWLS &lt;- function(punteggi) {\n  return(sum(punteggi))\n}\n\n\nCondizione per determinare la soddisfazione\nvaluta_soddisfazione &lt;- function(score) {\n  if (score &gt; 24) {\n    return(\"Alta soddisfazione\")\n  } else if (score &gt;= 15) {\n    return(\"Soddisfazione moderata\")\n  } else {\n    return(\"Bassa soddisfazione\")\n  }\n}\n\n\nApplicazione della funzione a più individui\npunteggi_lista &lt;- list(c(25, 27, 22, 24, 28), c(18, 20, 17, 16, 19))\nfor (punteggi in punteggi_lista) {\n  print(valuta_soddisfazione(calcola_SWLS(punteggi)))\n}\n\n\nUso di ifelse()\npunteggi_totali &lt;- c(28, 19, 15, 10, 25)\nsoddisfazione &lt;- ifelse(punteggi_totali &gt; 24, \"Alta\", \"Bassa\")\nprint(soddisfazione)\n\n\nCiclo while per controllare input\nscore &lt;- 0\nwhile (score &lt; 5 || score &gt; 35) {\n  score &lt;- as.numeric(readline(prompt = \"Inserisci un punteggio SWLS (5-35): \"))\n}\n\nEsportazione dei dati\n\ndf &lt;- data.frame(Punteggio = punteggi_totali, Soddisfazione = soddisfazione)\nwrite.csv(df, \"swls_results.csv\", row.names = FALSE)\nConclusione\nQuesti esercizi hanno mostrato come scrivere funzioni, utilizzare condizioni e cicli per strutturare meglio il codice in R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/03_r_programming.html#informazioni-sullambiente-di-sviluppo",
    "title": "7  Programmazione in R",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#bibliografia",
    "href": "chapters/R/03_r_programming.html#bibliografia",
    "title": "7  Programmazione in R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#footnotes",
    "href": "chapters/R/03_r_programming.html#footnotes",
    "title": "7  Programmazione in R",
    "section": "",
    "text": "Un’ottima introduzione alle regole di stile per un progetto di analisi dei dati è fornita in questo capitolo.↩︎",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html",
    "href": "chapters/R/04_r_packages.html",
    "title": "8  Pacchetti in R",
    "section": "",
    "text": "8.1 Introduzione\nI pacchetti R sono estensioni del linguaggio di programmazione statistica R. Questi pacchetti forniscono una raccolta di risorse che possono essere utilizzate per ampliare le funzionalità di base di R. Ogni pacchetto generalmente include:\nI pacchetti R sono distribuiti e installati attraverso repository centralizzati, il più noto dei quali è CRAN (Comprehensive R Archive Network). CRAN garantisce la qualità e l’affidabilità dei pacchetti, sottoponendoli a controlli rigorosi prima della pubblicazione.\nLa vasta disponibilità di pacchetti è una delle ragioni principali della popolarità di R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#introduzione",
    "href": "chapters/R/04_r_packages.html#introduzione",
    "title": "8  Pacchetti in R",
    "section": "",
    "text": "Codice: funzioni e script scritti in R (e talvolta in altri linguaggi come C++ o Fortran) che implementano specifiche analisi o strumenti.\nDati: dataset di esempio o utili per testare e dimostrare le funzionalità del pacchetto.\nDocumentazione: file descrittivi che spiegano come utilizzare il pacchetto, spesso in formato manuale o vignette (tutorial pratici).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#installare-i-pacchetti-r",
    "href": "chapters/R/04_r_packages.html#installare-i-pacchetti-r",
    "title": "8  Pacchetti in R",
    "section": "8.2 Installare i Pacchetti R",
    "text": "8.2 Installare i Pacchetti R\nQuando installi R, vengono installati automaticamente alcuni pacchetti base. Tuttavia, hai la possibilità di aggiungere ulteriori pacchetti che trovi utili per i tuoi scopi. Questi pacchetti sono memorizzati sui server di R (mirror), e l’installazione di un nuovo pacchetto richiede una connessione internet al mirror CRAN che hai scelto durante l’installazione di R.\nPer installare un pacchetto, utilizza il comando:\ninstall.packages(\"&lt;nome_pacchetto&gt;\")\nSostituisci &lt;nome_pacchetto&gt; con il nome del pacchetto che desideri installare. Ad esempio, se vuoi installare il pacchetto rio (utile per importare i dati in R), puoi digitare:\ninstall.packages(\"rio\")   # Non dimenticare le virgolette!",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#caricamento-di-un-pacchetto",
    "href": "chapters/R/04_r_packages.html#caricamento-di-un-pacchetto",
    "title": "8  Pacchetti in R",
    "section": "8.3 Caricamento di un pacchetto",
    "text": "8.3 Caricamento di un pacchetto\nOgni volta che avvii una nuova sessione di R, se desideri utilizzare un pacchetto, devi caricarlo manualmente. Questo si fa con il comando library(). Ad esempio, dopo aver installato rio, per utilizzarlo digita:\nlibrary(rio)   # Nota: le virgolette non sono necessarie, ma puoi usarle se preferisci.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#utilizzo-delle-funzioni-di-un-pacchetto-senza-caricarlo",
    "href": "chapters/R/04_r_packages.html#utilizzo-delle-funzioni-di-un-pacchetto-senza-caricarlo",
    "title": "8  Pacchetti in R",
    "section": "8.4 Utilizzo delle funzioni di un pacchetto senza caricarlo",
    "text": "8.4 Utilizzo delle funzioni di un pacchetto senza caricarlo\nSe hai bisogno di utilizzare una funzione specifica di un pacchetto, ma sai che la userai solo una volta, puoi evitare di caricare l’intero pacchetto con library(). Ad esempio, invece di scrivere:\nlibrary(nome_pacchetto)\nfunzione_specifica(x = 2, sd = 3)\npuoi accedere direttamente alla funzione usando l’operatore ::, come indicato di segtuito:\nnome_pacchetto::funzione_specifica(x = 2, sd = 3)\nQuesto approccio è utile per funzioni che usi raramente o una sola volta. Personalmente, utilizzo :: anche quando ho già caricato il pacchetto, per ricordare ad un “me futuro” da quale pacchetto proviene una determinata funzione. Questo può rendere il codice più leggibile e comprensibile nel tempo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#bibliografia",
    "href": "chapters/R/04_r_packages.html#bibliografia",
    "title": "8  Pacchetti in R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html",
    "href": "chapters/R/05_dplyr.html",
    "title": "9  Introduzione a dplyr",
    "section": "",
    "text": "9.1 Introduzione\nL’obiettivo di questo capitolo è fornire un’introduzione alle funzioni principali del pacchetto dplyr per le operazioni di data wrangling, cioè per il preprocessing e la pulizia dei dati. In R, queste operazioni sono strettamente legate al concetto di “data tidying”, che si riferisce all’organizzazione sistematica dei dati per facilitare l’analisi.\nPer comprendere meglio il concetto di “data tidying”, possiamo rifarci a una citazione tratta dal testo di riferimento R for Data Science (2e):\nL’essenza del “data tidying” è organizzare i dati in un formato che sia facile da gestire e analizzare. Anche se gli stessi dati possono essere rappresentati in vari modi, non tutte le rappresentazioni sono ugualmente efficienti o facili da usare. Un dataset “tidy” segue tre principi fondamentali che lo rendono particolarmente pratico:\nIl pacchetto R {dplyr} e gli altri pacchetti del tidyverse sono progettati specificamente per lavorare con dati in formato “tidy”, permettendo agli utenti di eseguire operazioni di manipolazione e visualizzazione in modo più intuitivo ed efficiente.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#introduzione",
    "href": "chapters/R/05_dplyr.html#introduzione",
    "title": "9  Introduzione a dplyr",
    "section": "",
    "text": "“Happy families are all alike; every unhappy family is unhappy in its own way.” — Leo Tolstoy\n\n\n“Tidy datasets are all alike, but every messy dataset is messy in its own way.” — Hadley Wickham\n\n\n\n\nOgni variabile è una colonna: ogni colonna nel dataset rappresenta una singola variabile.\n\nOgni osservazione è una riga: ogni riga nel dataset rappresenta un’unica osservazione.\n\nOgni valore è una cella: ogni cella del dataset contiene un singolo valore.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#pipe",
    "href": "chapters/R/05_dplyr.html#pipe",
    "title": "9  Introduzione a dplyr",
    "section": "\n9.2 Pipe",
    "text": "9.2 Pipe\nIl pacchetto dplyr, così come l’intero ecosistema tidyverse, fa largo uso dell’operatore pipe, che consente di concatenare una sequenza di operazioni in modo leggibile ed efficiente. In R, esistono due principali notazioni per il pipe:\n\n\n|&gt;: introdotto nativamente a partire dalla versione 4.1.0 di R.\n\n%&gt;%: introdotto dal pacchetto magrittr, ed è una delle componenti centrali del tidyverse.\n\nEntrambi gli operatori permettono di ottenere risultati simili e, per la maggior parte degli utilizzi, possono essere considerati intercambiabili. Tuttavia, è importante sottolineare alcune differenze:\n\n\n|&gt; è integrato nel linguaggio R e non richiede pacchetti aggiuntivi.\n\n%&gt;%, essendo parte di magrittr, richiede che il pacchetto sia installato e caricato (library(magrittr) o automaticamente tramite tidyverse).\n\nConsideriamo l’esempio seguente (che anticipa l’uso della funzione filter() che descriveremo in seguito). Un’operazione comune è filtrare un data frame e calcolare la media di una colonna. Con il pipe, questa sequenza di operazioni diventa più leggibile:\n\n# Usando %&gt;%\niris %&gt;%\n  dplyr::filter(Species == \"setosa\") |&gt; \n  summarise(\n    mean_sepal_length = mean(Sepal.Length)\n  ) \n#&gt;   mean_sepal_length\n#&gt; 1             5.006\n\n\n# Usando |&gt;\niris |&gt; \n  dplyr::filter(Species == \"setosa\") |&gt; \n  summarise(\n    mean_sepal_length = mean(Sepal.Length)\n  ) \n#&gt;   mean_sepal_length\n#&gt; 1             5.006\n\n\n9.2.1 Cosa Fa la Pipe?\nLa pipe è uno strumento potente che permette di collegare in modo diretto l’output di una funzione come input della funzione successiva. Questo approccio:\n\nRiduce la necessità di creare variabili intermedie.\nMigliora la leggibilità del codice.\nRende il flusso delle operazioni più chiaro e lineare.\n\nOgni funzione applicata con la pipe riceve automaticamente l’output della funzione precedente come suo primo argomento. Ciò consente di scrivere sequenze di operazioni in un formato compatto e intuitivo.\nEcco un altro esempio:\n\n# Utilizzo della pipe per trasformare un dataset\ndf &lt;- data.frame(\n  id = 1:5,\n  value = c(10, 20, 30, 40, 50)\n)\n\n# Filtra i dati, seleziona colonne e calcola nuovi valori\ndf_clean &lt;- df |&gt;\n  dplyr::filter(value &gt; 20) |&gt;\n  dplyr::select(id, value) |&gt;\n  mutate(squared_value = value^2)\n\nIn questa sequenza, il dataset originale df viene filtrato, le colonne desiderate vengono selezionate e viene aggiunta una nuova colonna con il valore al quadrato.\n\nhead(df_clean)\n#&gt;   id value squared_value\n#&gt; 1  3    30           900\n#&gt; 2  4    40          1600\n#&gt; 3  5    50          2500\n\nIn sintesi, la pipe è uno strumento fondamentale per scrivere codice R moderno e leggibile, indipendentemente dal fatto che si utilizzi |&gt; o %&gt;%.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#verbi",
    "href": "chapters/R/05_dplyr.html#verbi",
    "title": "9  Introduzione a dplyr",
    "section": "\n9.3 Verbi",
    "text": "9.3 Verbi\nLe funzioni principali (“verbi) di dplyr sono le seguenti:\n\n\n\n\n\n\nVerbo dplyr\nDescrizione\n\n\n\nselect()\nSeleziona colonne\n\n\nfilter()\nFiltra righe\n\n\narrange()\nRiordina o organizza le righe\n\n\nmutate()\nCrea nuove colonne\n\n\nsummarise()\nRiassume i valori\n\n\ngroup_by()\nConsente di eseguire operazioni di gruppo\n\n\n\nI verbi di dplyr sono suddivisi in quattro gruppi, in base all’elemento su cui operano: righe, colonne, gruppi o tabelle.\nInoltre, le diverse funzioni bind_ e _joins permettono di combinare più tibbles (ovvero, data frame) in uno solo.\nPer fare un esempio prarico, usiamo nuovamente il dataset msleep.\n\ndata(msleep)\ndim(msleep)\n#&gt; [1] 83 11\n\nEsaminiamo i dati:\n\nglimpse(msleep)\n#&gt; Rows: 83\n#&gt; Columns: 11\n#&gt; $ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater …\n#&gt; $ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", …\n#&gt; $ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"…\n#&gt; $ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", …\n#&gt; $ conservation &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"…\n#&gt; $ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.…\n#&gt; $ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0…\n#&gt; $ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.1333, 0.6667, 0.7667, 0.3833, NA, 0.333…\n#&gt; $ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.…\n#&gt; $ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.0700…\n#&gt; $ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, …\n\nLe colonne, nell’ordine, corrispondono a quanto segue:\n\n\nNome colonna\nDescrizione\n\n\n\nname\nNome comune\n\n\ngenus\nRango tassonomico\n\n\nvore\nCarnivoro, onnivoro o erbivoro?\n\n\norder\nRango tassonomico\n\n\nconservation\nStato di conservazione del mammifero\n\n\nsleep_total\nQuantità totale di sonno, in ore\n\n\nsleep_rem\nSonno REM, in ore\n\n\nsleep_cycle\nDurata del ciclo di sonno, in ore\n\n\nawake\nQuantità di tempo trascorso sveglio, in ore\n\n\nbrainwt\nPeso del cervello, in chilogrammi\n\n\nbodywt\nPeso corporeo, in chilogrammi",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#righe",
    "href": "chapters/R/05_dplyr.html#righe",
    "title": "9  Introduzione a dplyr",
    "section": "\n9.4 Righe",
    "text": "9.4 Righe\nI verbi più importanti che operano sulle righe di un dataset sono filter(), che seleziona le righe da includere senza modificarne l’ordine, e arrange(), che cambia l’ordine delle righe senza alterare la selezione delle righe presenti.\n\nmsleep |&gt;\n  dplyr::filter(sleep_total &lt; 4) |&gt;\n  arrange(sleep_total)\n#&gt; # A tibble: 9 × 11\n#&gt;   name             genus         vore  order          conservation\n#&gt;   &lt;chr&gt;            &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;       \n#&gt; 1 Giraffe          Giraffa       herbi Artiodactyla   cd          \n#&gt; 2 Pilot whale      Globicephalus carni Cetacea        cd          \n#&gt; 3 Horse            Equus         herbi Perissodactyla domesticated\n#&gt; 4 Roe deer         Capreolus     herbi Artiodactyla   lc          \n#&gt; 5 Donkey           Equus         herbi Perissodactyla domesticated\n#&gt; 6 African elephant Loxodonta     herbi Proboscidea    vu          \n#&gt; 7 Caspian seal     Phoca         carni Carnivora      vu          \n#&gt; 8 Sheep            Ovis          herbi Artiodactyla   domesticated\n#&gt; 9 Asian elephant   Elephas       herbi Proboscidea    en          \n#&gt; # ℹ 6 more variables: sleep_total &lt;dbl&gt;, sleep_rem &lt;dbl&gt;,\n#&gt; #   sleep_cycle &lt;dbl&gt;, awake &lt;dbl&gt;, brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt;\n\nPossiamo usare filter() speficicano più di una condizione logica.\n\nmsleep |&gt;\n  dplyr::filter((sleep_total &lt; 4 & bodywt &gt; 100) | brainwt &gt; 1) |&gt;\n  arrange(sleep_total)\n#&gt; # A tibble: 7 × 11\n#&gt;   name             genus         vore  order          conservation\n#&gt;   &lt;chr&gt;            &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;       \n#&gt; 1 Giraffe          Giraffa       herbi Artiodactyla   cd          \n#&gt; 2 Pilot whale      Globicephalus carni Cetacea        cd          \n#&gt; 3 Horse            Equus         herbi Perissodactyla domesticated\n#&gt; 4 Donkey           Equus         herbi Perissodactyla domesticated\n#&gt; 5 African elephant Loxodonta     herbi Proboscidea    vu          \n#&gt; 6 Asian elephant   Elephas       herbi Proboscidea    en          \n#&gt; 7 Human            Homo          omni  Primates       &lt;NA&gt;        \n#&gt; # ℹ 6 more variables: sleep_total &lt;dbl&gt;, sleep_rem &lt;dbl&gt;,\n#&gt; #   sleep_cycle &lt;dbl&gt;, awake &lt;dbl&gt;, brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt;",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#colonne",
    "href": "chapters/R/05_dplyr.html#colonne",
    "title": "9  Introduzione a dplyr",
    "section": "\n9.5 Colonne",
    "text": "9.5 Colonne\nEsistono quattro verbi principali che modificano le colonne di un dataset senza cambiare le righe:\n\n\nrelocate() cambia la posizione delle colonne;\n\nrename() modifica i nomi delle colonne;\n\nselect() seleziona le colonne da includere o escludere;\n\nmutate() crea nuove colonne a partire da quelle esistenti.\n\n\nmsleep2 &lt;- msleep |&gt;\n  mutate(\n    rem_prop = sleep_rem / sleep_total * 100\n  ) |&gt;\n  dplyr::select(name, vore, rem_prop, sleep_total) |&gt;\n  arrange(desc(rem_prop))\n\nglimpse(msleep2)\n#&gt; Rows: 83\n#&gt; Columns: 4\n#&gt; $ name        &lt;chr&gt; \"European hedgehog\", \"Thick-tailed opposum\", \"Giant ar…\n#&gt; $ vore        &lt;chr&gt; \"omni\", \"carni\", \"insecti\", \"omni\", \"carni\", \"omni\", \"…\n#&gt; $ rem_prop    &lt;dbl&gt; 34.65, 34.02, 33.70, 29.21, 28.71, 27.22, 26.37, 26.21…\n#&gt; $ sleep_total &lt;dbl&gt; 10.1, 19.4, 18.1, 8.9, 10.1, 18.0, 9.1, 10.3, 12.5, 8.…\n\nIn questo esempio, utilizziamo mutate() per creare una nuova colonna rem_prop che rappresenta la percentuale di sonno REM sul totale del sonno. Successivamente, select() viene utilizzato per scegliere solo alcune colonne del dataset, e infine desc(rem_prop) ordina i valori di rem_prop in ordine decrescente, dal valore maggiore a quello minore.\nPer cambiare il nome di una colonna possiamo usare rename(). Inoltre, possiamo cambiare l’ordine delle variabili con relocate().\n\nmsleep2 |&gt;\n  rename(rem_perc = rem_prop) |&gt;\n  relocate(rem_perc, .before = name)\n#&gt; # A tibble: 83 × 4\n#&gt;    rem_perc name                   vore    sleep_total\n#&gt;       &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;         &lt;dbl&gt;\n#&gt;  1     34.7 European hedgehog      omni           10.1\n#&gt;  2     34.0 Thick-tailed opposum   carni          19.4\n#&gt;  3     33.7 Giant armadillo        insecti        18.1\n#&gt;  4     29.2 Tree shrew             omni            8.9\n#&gt;  5     28.7 Dog                    carni          10.1\n#&gt;  6     27.2 North American Opossum omni           18  \n#&gt;  7     26.4 Pig                    omni            9.1\n#&gt;  8     26.2 Desert hedgehog        &lt;NA&gt;           10.3\n#&gt;  9     25.6 Domestic cat           carni          12.5\n#&gt; 10     25   Eastern american mole  insecti         8.4\n#&gt; # ℹ 73 more rows",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#gruppi",
    "href": "chapters/R/05_dplyr.html#gruppi",
    "title": "9  Introduzione a dplyr",
    "section": "\n9.6 Gruppi",
    "text": "9.6 Gruppi\nIl verbo group_by() viene utilizzato per suddividere un dataset in gruppi, in base a una o più variabili, che siano rilevanti per l’analisi. Questo permette di eseguire operazioni di sintesi su ciascun gruppo separatamente, ottenendo informazioni aggregate.\nAd esempio, nel codice seguente:\n\nmsleep |&gt;\n  group_by(order) |&gt;\n  summarise(\n    avg_sleep = mean(sleep_total),\n    min_sleep = min(sleep_total),\n    max_sleep = max(sleep_total),\n    total = n()\n  ) |&gt;\n  arrange(desc(avg_sleep))\n#&gt; # A tibble: 19 × 5\n#&gt;    order           avg_sleep min_sleep max_sleep total\n#&gt;    &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n#&gt;  1 Chiroptera          19.8       19.7      19.9     2\n#&gt;  2 Didelphimorphia     18.7       18        19.4     2\n#&gt;  3 Cingulata           17.8       17.4      18.1     2\n#&gt;  4 Afrosoricida        15.6       15.6      15.6     1\n#&gt;  5 Pilosa              14.4       14.4      14.4     1\n#&gt;  6 Rodentia            12.5        7        16.6    22\n#&gt;  7 Diprotodontia       12.4       11.1      13.7     2\n#&gt;  8 Soricomorpha        11.1        8.4      14.9     5\n#&gt;  9 Primates            10.5        8        17      12\n#&gt; 10 Erinaceomorpha      10.2       10.1      10.3     2\n#&gt; 11 Carnivora           10.1        3.5      15.8    12\n#&gt; 12 Scandentia           8.9        8.9       8.9     1\n#&gt; 13 Monotremata          8.6        8.6       8.6     1\n#&gt; 14 Lagomorpha           8.4        8.4       8.4     1\n#&gt; 15 Hyracoidea           5.67       5.3       6.3     3\n#&gt; 16 Artiodactyla         4.52       1.9       9.1     6\n#&gt; 17 Cetacea              4.5        2.7       5.6     3\n#&gt; 18 Proboscidea          3.6        3.3       3.9     2\n#&gt; 19 Perissodactyla       3.47       2.9       4.4     3\n\n\ngroup_by(order) suddivide il dataset msleep in gruppi, ciascuno corrispondente a un valore distinto della variabile order.\n\nSuccessivamente, summarise() calcola diverse statistiche per ogni gruppo:\n\n\navg_sleep è la media del totale del sonno (sleep_total) all’interno di ciascun gruppo.\n\nmin_sleep è il valore minimo di sleep_total in ogni gruppo.\n\nmax_sleep è il valore massimo di sleep_total in ogni gruppo.\n\ntotal è il numero di osservazioni (o righe) per ciascun gruppo, calcolato con la funzione n().\n\n\nInfine, arrange(desc(avg_sleep)) ordina i risultati in ordine decrescente in base alla media del sonno totale (avg_sleep), mostrando prima i gruppi con la media di sonno più alta.\n\nQuesto tipo di approccio è utile quando si vuole analizzare come cambiano le caratteristiche dei dati a seconda dei gruppi specifici, fornendo una visione più dettagliata e utile.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#considerazioni-conclusive",
    "href": "chapters/R/05_dplyr.html#considerazioni-conclusive",
    "title": "9  Introduzione a dplyr",
    "section": "\n9.7 Considerazioni Conclusive",
    "text": "9.7 Considerazioni Conclusive\nIl data wrangling è una delle fasi più importanti in qualsiasi pipeline di analisi dei dati. In questo capitolo abbiamo introdotto l’uso del pacchetto tidyverse di R per la manipolazione dei dati e il suo utilizzo in scenari di base. Tuttavia, il tidyverse è un ecosistema ampio e qui abbiamo trattato solo gli elementi fondamentali. Per approfondire, si consiglia di consultare ulteriori risorse come quelle disponibili sul sito web del tidyverse e il libro R for Data Science (2e), di cui esiste anche una traduzione italiana.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#esercizi",
    "href": "chapters/R/05_dplyr.html#esercizi",
    "title": "9  Introduzione a dplyr",
    "section": "\n9.8 Esercizi",
    "text": "9.8 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, utilizzerai il pacchetto dplyr per imparare a manipolare e trasformare i dati della SWLS (Satisfaction With Life Scale). Gli esercizi ti aiuteranno a consolidare la conoscenza dei principali verbi di dplyr, inclusi filter(), select(), mutate(), arrange() e group_by().\nParte 1: Comprensione Teorica\n\n\nCos’è un dataset “tidy”?\n\nDescrivi con parole tue cosa significa avere un dataset “tidy” e quali sono le sue tre caratteristiche principali.\n\n\n\nCos’è la pipe (%&gt;% o |&gt;) e perché è utile?\n\nSpiega a cosa serve l’operatore pipe e fornisci un esempio di utilizzo.\n\n\n\nQuali sono i verbi principali di dplyr?\n\nElenca e spiega brevemente i sei verbi principali di dplyr per la manipolazione dei dati.\n\n\n\nCosa fa il verbo group_by()?\n\nSpiega il suo scopo e come viene utilizzato in combinazione con summarise().\n\n\n\nParte 2: Applicazione Pratica con i Dati SWLS\n\n\nCaricamento dei dati SWLS\n\nCrea un data frame in R contenente i punteggi SWLS che hai raccolto.\n\n\n\nSelezione delle colonne\n\nUsa select() per mantenere solo le colonne con i punteggi degli item.\n\n\n\nFiltraggio dei dati\n\nUsa filter() per selezionare solo gli individui che hanno un punteggio totale superiore a 20.\n\n\n\nCreazione di una nuova colonna\n\nUsa mutate() per calcolare il punteggio totale della SWLS per ciascun individuo e salvarlo in una nuova colonna chiamata punteggio_totale.\n\n\n\nRiordinamento dei dati\n\nUsa arrange() per ordinare il dataset in base al punteggio totale, dal più alto al più basso.\n\n\n\nRaggruppamento e sintesi dei dati\n\n\n\nUsa group_by() e summarise() per calcolare la media e la deviazione standard del punteggio SWLS totale nel dataset.\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nParte 1: Comprensione Teorica\n\n\nCos’è un dataset “tidy”?\n\nUn dataset “tidy” è un dataset organizzato in modo sistematico per facilitare l’analisi. Le sue tre caratteristiche principali sono:\n\nOgni variabile è una colonna.\nOgni osservazione è una riga.\nOgni valore è una cella.\n\n\n\n\n\nCos’è la pipe (%&gt;% o |&gt;) e perché è utile?\n\nLa pipe (%&gt;% o |&gt;) permette di concatenare più operazioni di manipolazione dati in modo leggibile ed efficiente.\n\nEsempio:\ndf |&gt; \n  filter(score &gt; 20) |&gt; \n  select(name, score)\n\n\n\n\nQuali sono i verbi principali di dplyr?\n\n\nselect(): Seleziona colonne.\n\nfilter(): Filtra righe.\n\narrange(): Riordina le righe.\n\nmutate(): Crea nuove colonne.\n\nsummarise(): Riassume i dati.\n\ngroup_by(): Permette di raggruppare i dati.\n\n\n\nCosa fa il verbo group_by()?\n\ngroup_by() suddivide i dati in gruppi, permettendo di applicare funzioni di aggregazione con summarise().\n\nEsempio:\ndf |&gt; \n  group_by(gruppo) |&gt; \n  summarise(media = mean(score), sd = sd(score))\n\n\n\n\nParte 2: Applicazione Pratica con i Dati SWLS\n\n\nCaricamento dei dati SWLS Per svolgere l’esercizio, simuliamo i dati di 10 individui su 5 item (numeri casuali da 1 a 7):\nset.seed(123)\nswls &lt;- data.frame(\n  id = 1:10,\n  item1 = sample(1:7, 10, replace = TRUE),\n  item2 = sample(1:7, 10, replace = TRUE),\n  item3 = sample(1:7, 10, replace = TRUE),\n  item4 = sample(1:7, 10, replace = TRUE),\n  item5 = sample(1:7, 10, replace = TRUE)\n)\nprint(swls)\n\n\nSelezione delle colonne\nswls_selected &lt;- swls |&gt; select(item1:item5)\n\n\nFiltraggio dei dati\nswls_filtered &lt;- swls |&gt; filter(rowSums(select(swls, item1:item5)) &gt; 20)\n\n\nCreazione di una nuova colonna\nswls &lt;- swls |&gt; mutate(punteggio_totale = rowSums(select(swls, item1:item5)))\n\n\nRiordinamento dei dati\nswls_sorted &lt;- swls |&gt; arrange(desc(punteggio_totale))\n\nRaggruppamento e sintesi dei dati\n\nswls_summary &lt;- swls |&gt; \n  summarise(media = mean(punteggio_totale), sd = sd(punteggio_totale))\nConclusione\nQuesti esercizi hanno mostrato come usare dplyr per manipolare dati in modo efficace e leggibile.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/05_dplyr.html#informazioni-sullambiente-di-sviluppo",
    "title": "9  Introduzione a dplyr",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] missForest_1.5   mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.10.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt; [13] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         fastmap_1.2.0       \n#&gt;  [4] pacman_0.5.1         digest_0.6.37        rpart_4.1.24        \n#&gt;  [7] timechange_0.3.0     lifecycle_1.0.4      survival_3.8-3      \n#&gt; [10] magrittr_2.0.3       compiler_4.4.2       rngtools_1.5.2      \n#&gt; [13] rlang_1.1.5          tools_4.4.2          utf8_1.2.4          \n#&gt; [16] doRNG_1.8.6.1        htmlwidgets_1.6.4    mnormt_2.1.1        \n#&gt; [19] withr_3.0.2          itertools_0.1-3      nnet_7.3-20         \n#&gt; [22] grid_4.4.2           jomo_2.7-6           colorspace_2.1-1    \n#&gt; [25] iterators_1.0.14     MASS_7.3-64          cli_3.6.4           \n#&gt; [28] rmarkdown_2.29       reformulas_0.4.0     generics_0.1.3      \n#&gt; [31] rstudioapi_0.17.1    tzdb_0.4.0           minqa_1.2.8         \n#&gt; [34] splines_4.4.2        parallel_4.4.2       vctrs_0.6.5         \n#&gt; [37] boot_1.3-31          glmnet_4.1-8         Matrix_1.7-2        \n#&gt; [40] jsonlite_1.8.9       hms_1.1.3            mitml_0.4-5         \n#&gt; [43] foreach_1.5.2        glue_1.8.0           nloptr_2.1.1        \n#&gt; [46] pan_1.9              codetools_0.2-20     stringi_1.8.4       \n#&gt; [49] shape_1.4.6.1        gtable_0.3.6         lme4_1.1-36         \n#&gt; [52] munsell_0.5.1        pillar_1.10.1        htmltools_0.5.8.1   \n#&gt; [55] randomForest_4.7-1.2 R6_2.6.1             Rdpack_2.6.2        \n#&gt; [58] rprojroot_2.0.4      evaluate_1.0.3       lattice_0.22-6      \n#&gt; [61] rbibutils_2.3        backports_1.5.0      broom_1.0.7         \n#&gt; [64] Rcpp_1.0.14          nlme_3.1-167         xfun_0.50           \n#&gt; [67] pkgconfig_2.0.3",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#bibliografia",
    "href": "chapters/R/05_dplyr.html#bibliografia",
    "title": "9  Introduzione a dplyr",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html",
    "href": "chapters/R/06_quarto.html",
    "title": "10  Quarto",
    "section": "",
    "text": "10.1 Introduzione\nLa crisi della riproducibilità scientifica rappresenta una delle sfide più importanti della ricerca contemporanea. Con questo termine ci si riferisce alla difficoltà, riscontrata in diverse discipline, di replicare i risultati degli studi scientifici. Sebbene le definizioni di riproducibilità varino tra i diversi ambiti, un’interpretazione ampiamente condivisa la identifica come la capacità di ottenere gli stessi risultati utilizzando i medesimi dati di input e seguendo gli stessi passaggi computazionali nei metodi e nelle analisi.\nLa pratica scientifica è profondamente radicata nella formazione accademica: ciò che viene insegnato nelle aule universitarie si riflette direttamente nel lavoro svolto nei laboratori, sul campo e nell’analisi dei dati. Riconoscendo questo stretto legame tra didattica e ricerca, molti studiosi sostengono l’importanza di integrare i metodi di riproducibilità nei corsi universitari di data science, sia a livello undergraduate che graduate (Dogucu, 2024). L’educazione alla data science che incorpora la riproducibilità nell’analisi dei dati viene infatti considerata la “controffensiva statistica” alla crisi della riproducibilità.\nIn questo contesto si inserisce Quarto, uno strumento innovativo che affronta direttamente le sfide della crisi della riproducibilità. Quarto si colloca nella tradizione del literate programming, un approccio pioneristico introdotto da Donald Knuth negli anni ’80. Questa metodologia nasce dalla visione di unificare codice e testo descrittivo in un unico documento, rendendo i programmi non solo eseguibili ma anche comprensibili agli esseri umani. L’obiettivo è superare la tradizionale separazione tra codice e documentazione, permettendo di spiegare non solo il funzionamento tecnico di un programma, ma anche le ragioni delle scelte implementative.\nQuesta filosofia risulta particolarmente pertinente nell’ambito della data science e dell’analisi statistica, dove riproducibilità e trasparenza sono requisiti imprescindibili. Quarto eccelle in questo contesto, offrendo la possibilità di integrare in codice, risultati e narrazione. La sua versatilità si manifesta nella capacità di produrre diversi tipi di output - dai report agli articoli scientifici, dalle presentazioni ai documenti tecnici - in vari formati come HTML, PDF e Word, combinando efficacemente testo interpretativo, risultati numerici e visualizzazioni grafiche.\nUn punto di forza distintivo di Quarto è la sua flessibilità nel supportare molteplici linguaggi di programmazione, tra cui R, Python e Julia. Lo strumento può essere utilizzato secondo tre modalità principali: per presentare conclusioni condividendo i risultati senza esporre il codice sottostante; per documentare il processo analitico includendo sia il codice che i risultati, garantendo così piena trasparenza e riproducibilità; e per annotare l’analisi, integrando interpretazioni e motivazioni delle decisioni prese durante il processo analitico.\nNonostante Quarto sia tecnicamente uno strumento da riga di comando (CLI), l’integrazione con RStudio ne semplifica notevolmente l’utilizzo, rendendo l’installazione e l’operatività accessibili anche agli utenti meno esperti nell’uso del terminale. Questa caratteristica, unita alle sue potenti funzionalità, rende Quarto una naturale evoluzione del literate programming, offrendo un ambiente di lavoro che bilancia efficacemente praticità d’uso e rigore scientifico. In questo modo, Quarto si configura come una risposta concreta alle sfide della riproducibilità nella ricerca contemporanea, fornendo gli strumenti necessari per una scienza più trasparente e verificabile. L’obiettivo di questo capitolo è quello di fornire un’introduzione pratica a Quarto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#introduzione",
    "href": "chapters/R/06_quarto.html#introduzione",
    "title": "10  Quarto",
    "section": "",
    "text": "10.1.1 Creare un documento Quarto\nUn file Quarto ha estensione .qmd e segue questa struttura:\n\nQuesto file include:\n\nUn’intestazione YAML (metadati del documento).\nBlocchi di codice delimitati da ```.\nTesto scritto in Markdown con formattazioni semplici come titoli (# Titolo), corsivi (*testo*), ecc.\n\n10.1.2 Editor visivo e sorgente\n\n\nEditor visivo: simile a Google Docs, offre un’interfaccia WYSIWYM (What You See Is What You Mean). Consente di inserire facilmente immagini, tabelle, citazioni e altro.\n\nEditor sorgente: consente un controllo diretto sul Markdown, utile per debug e personalizzazioni avanzate.\n\n10.1.3 Blocchi di codice\nI blocchi di codice (chiamati “chunks”) eseguono codice e visualizzano i risultati. Ogni chunk è delimitato da ``` e può includere opzioni specifiche:\n#| label: esempio\n#| echo: false\n1 + 1\nLe opzioni più comuni includono:\n\n\necho: false (nasconde il codice nel report),\n\neval: false (non esegue il codice),\n\nmessage: false e warning: false (nasconde messaggi o avvisi).\n\n10.1.4 Figure\nLe figure possono essere generate tramite codice (es. ggplot()) o inserite come file esterni. Le opzioni più comuni per il controllo delle dimensioni sono:\n\n\nfig-width e fig-height (dimensioni della figura in pollici),\n\nout-width (percentuale di larghezza del documento),\n\nfig-asp (rapporto d’aspetto, es. 0.618 per il rapporto aureo).\n\nEsempio:\n#| fig-width: 6\nggplot(data, aes(x, y)) + geom_point()\n\n10.1.5 Equazioni\nLe equazioni possono essere scritte in \\(\\LaTeX\\), così come spiegato nell’Appendice C.\n\n10.1.6 Tabelle\nLe tabelle possono essere stampate direttamente o personalizzate con funzioni come knitr::kable() o pacchetti come gt:\n\nknitr::kable(head(mtcars))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\n10.1.7 Caching\nPer velocizzare i documenti con calcoli complessi, Quarto supporta la memorizzazione dei risultati:\n\n\ncache: true salva i risultati di un chunk, evitando di ricalcolarli se il codice non cambia.\n\ndependson specifica dipendenze tra chunk.\n\n10.1.8 Gestione delle Citazioni e delle Bibliografie in Quarto\nQuarto offre un supporto avanzato per la generazione automatica di citazioni e bibliografie, consentendo l’applicazione di formati personalizzati come lo stile APA. Per includere riferimenti bibliografici, è necessario creare un file .bib (ad esempio, references.bib) contenente le citazioni nel formato BibTeX. Queste citazioni possono essere ottenute direttamente da Google Scholar o altri database accademici.\nEcco un esempio di una citazione in formato BibTeX:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect: Evidence from a visual search task},\n  author={Ceccarini, Francesco and Colpizzi, Ilaria and Caudek, Corrado},\n  journal={Psychonomic Bulletin \\& Review},\n  pages={1--10},\n  year={2024},\n  publisher={Springer}\n}\nQuesta citazione deve essere inserita in un file .bib, ad esempio, references.bib. Tale file dovrà poi essere specificato nell’intestazione del documento Quarto.\n\n10.1.8.1 Configurazione dell’Intestazione YAML\nNel file .qmd, è necessario aggiungere le seguenti righe all’intestazione YAML per collegare il file references.bib e configurare lo stile della bibliografia:\nbibliography: references.bib\nbiblio-style: apalike\ncsl: apa.csl\n\n\nbibliography: Specifica il percorso del file .bib. In questo esempio, si assume che il file si trovi nella stessa cartella del documento Quarto.\n\nbiblio-style: Imposta lo stile delle citazioni. Ad esempio, apalike è uno stile simile allo stile APA.\n\ncsl: Consente di utilizzare uno stile di citazione personalizzato, come apa.csl. Puoi scaricare facilmente questi stili dal Zotero Style Repository.\n\n10.1.8.2 Esempio Completo\nDi seguito è riportato un esempio completo di un documento Quarto che include una citazione e genera automaticamente la bibliografia:\n---\ntitle: \"Articolo di Esempio\"\nauthor: \"Autore di Esempio\"\ndate: \"2025-02-23\"\nbibliography: references.bib\nbiblio-style: apalike\ncsl: apa.csl\n---\n\n## Introduzione\n\nIn questo articolo, discutiamo i cambiamenti dipendenti dall'età nell'anger-superiority effect [@ceccarini2024age].\n\n## Risultati\n\nI risultati mostrano che...\n\n## Riferimenti\nIn questo esempio, l’identificatore @ceccarini2024age viene utilizzato per fare riferimento alla citazione contenuta nel file references.bib. Al momento della compilazione, Quarto genererà automaticamente la lista dei riferimenti bibliografici in base al formato specificato.\n\n10.1.8.3 Citazioni Inline\nAll’interno di un documento .qmd, le citazioni vengono aggiunte utilizzando il simbolo @ seguito dall’identificativo della citazione specificato nel file .bib. Ad esempio:\n... come evidenziato da @ceccarini2024age, si osserva che...\nQuarto genera automaticamente la bibliografia, includendo solo i riferimenti effettivamente citati nel documento. La bibliografia viene aggiunta alla fine del file renderizzato (ad esempio, in formato HTML o PDF).\nAd esempio, nel caso di un documento .qmd, il testo sopra sarà visualizzato così:\n\n… come evidenziato da Ceccarini et al. (2024), si osserva che…\n\nLa citazione completa sarà inclusa automaticamente nella bibliografia, posizionata alla fine della pagina web o del documento finale. Si noti che Quarto gestisce automaticamente la formattazione e la posizione della bibliografia, garantendo coerenza e precisione.\n\nEsempio 10.1 Per fare un esempio pratico, possiamo inserire la citazione @ceccarini2024age direttamente nel file .qmd di questa pagina web. Quando il documento viene compilato, Quarto renderà la citazione in modo appropriato, come mostrato qui: Ceccarini et al. (2024).\nSi noti che, in fondo a questa pagina web, è presente un riferimento bibliografico corrispondente. Questo riferimento è stato aggiunto automaticamente da Quarto in risposta all’uso della citazione @ceccarini2024age nel testo del documento. Questo processo automatizzato semplifica la gestione delle citazioni e garantisce che tutti i riferimenti siano correttamente inclusi e formattati.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#riflessioni-conclusive",
    "href": "chapters/R/06_quarto.html#riflessioni-conclusive",
    "title": "10  Quarto",
    "section": "\n10.2 Riflessioni Conclusive",
    "text": "10.2 Riflessioni Conclusive\nQuarto è uno strumento potente per la creazione di documenti riproducibili e ben strutturati, integrando codice, risultati e testo descrittivo in un unico file. Questa introduzione dovrebbe essere sufficiente per iniziare a lavorare con Quarto, ma c’è ancora molto da imparare. Il modo migliore per rimanere aggiornati è consultare il sito ufficiale di Quarto: https://quarto.org.\nUn argomento importante che non abbiamo trattato qui riguarda i dettagli di come comunicare in modo accurato le proprie idee agli altri. Per migliorare le proprie capacità di scrittura, Wickham et al. (2023) consigliano due libri: Style: Lessons in Clarity and Grace di Joseph M. Williams & Joseph Bizup, e The Sense of Structure: Writing from the Reader’s Perspective di George Gopen. Una serie di brevi articoli sulla scrittura sono offerti da George Gopen e sono disponibili su https://www.georgegopen.com/litigation-articles.html.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#esercizi",
    "href": "chapters/R/06_quarto.html#esercizi",
    "title": "10  Quarto",
    "section": "\n10.3 Esercizi",
    "text": "10.3 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio esplorerai l’importanza della riproducibilità nella scienza dei dati e le funzionalità principali di Quarto.\n1. Concetti di base sulla riproducibilità\n\nCos’è la crisi della riproducibilità e perché è rilevante nella scienza dei dati?\nIn che modo Quarto può aiutare ad affrontare la crisi della riproducibilità?\nSpiega il concetto di literate programming e come si collega a Quarto.\n\n2. Struttura di un file Quarto\n\nQual è l’estensione di un file Quarto e quali sono le sue tre sezioni principali?\nQual è la differenza tra editor visivo ed editor sorgente in Quarto?\nQual è la funzione dell’intestazione YAML in un file .qmd?\n\n3. Blocchi di codice e opzioni\n\nCome si scrive un blocco di codice in Quarto?\nQuali opzioni puoi utilizzare nei blocchi di codice per controllare l’esecuzione e la visualizzazione del codice e dei risultati?\nScrivi un blocco di codice Quarto che calcola la media di un vettore di numeri e stampa il risultato senza mostrare il codice.\n\n4. Figure e Tabelle\n\nQuali opzioni di formattazione delle figure offre Quarto?\nCome puoi creare una tabella formattata in Quarto usando knitr::kable()?\n\n5. Citazioni e Bibliografia\n\nCome si aggiunge una citazione bibliografica in Quarto?\nQuali file devono essere inclusi per gestire una bibliografia in Quarto?\nScrivi un esempio di citazione in formato BibTeX e mostra come collegarla a un documento .qmd.\n\n6. Considerazioni Finali\n\nQuali sono i vantaggi di usare Quarto rispetto a strumenti più tradizionali come Word per la creazione di report scientifici?\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Concetti di base sulla riproducibilità\n\nLa crisi della riproducibilità è il fenomeno per cui molti studi scientifici non possono essere replicati con gli stessi metodi e dati. Questo mina la fiducia nella scienza e può portare a risultati non affidabili.\nQuarto aiuta la riproducibilità integrando codice, testo e risultati in un unico documento, rendendo più semplice verificare e riprodurre le analisi.\n\nLiterate programming è un approccio introdotto da Donald Knuth che combina codice e spiegazioni testuali nello stesso file, migliorando la comprensione e documentazione delle analisi. Quarto segue questa filosofia.\n\n2. Struttura di un file Quarto\n\n\nL’estensione di un file Quarto è .qmd. Le tre sezioni principali sono:\n\nL’intestazione YAML (metadati),\nIl codice (chunks),\nIl testo scritto in Markdown.\n\n\nL’editor visivo è un’interfaccia intuitiva simile a Google Docs, mentre l’editor sorgente permette di scrivere direttamente in Markdown e codice.\nL’intestazione YAML definisce le proprietà del documento come titolo, autore, formato di output e opzioni di rendering.\n\n3. Blocchi di codice e opzioni\n\n\nUn blocco di codice in Quarto si scrive con tripli backtick (```) e un linguaggio specificato:\n#| echo: true\nprint(\"Esempio di codice in Quarto\")\n\n\nAlcune opzioni utili nei blocchi di codice sono:\n\n\necho: false per nascondere il codice,\n\neval: false per non eseguire il codice,\n\nwarning: false e message: false per nascondere messaggi e avvisi.\n\n\n\nEsempio di blocco di codice che calcola una media senza mostrare il codice:\n#| echo: false\nmean(c(1, 2, 3, 4, 5))\n\n\n\n10.4 4. Figure e Tabelle\n\n\nLe opzioni principali per le figure includono:\n\n\nfig-width e fig-height per le dimensioni,\n\nout-width per la larghezza relativa,\n\nfig-asp per il rapporto d’aspetto.\n\n\n\nPer creare una tabella formattata con knitr::kable():\nknitr::kable(head(mtcars))\n\n\n5. Citazioni e Bibliografia\n\nLe citazioni in Quarto si aggiungono usando il simbolo @ seguito dal riferimento BibTeX (es. @ceccarini2024age).\n\nPer gestire la bibliografia in Quarto servono:\n\nUn file .bib con le citazioni,\nUn’intestazione YAML che collega il file .bib e specifica lo stile (csl).\n\n\n\nEsempio di citazione BibTeX e collegamento in YAML:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect},\n  author={Ceccarini, Francesco et al.},\n  journal={Psychonomic Bulletin & Review},\n  year={2024}\n}\nYAML:\nbibliography: references.bib\nbiblio-style: apalike\n\n\n6. Considerazioni Finali\n\n\nI vantaggi di Quarto rispetto a Word includono:\n\nmaggiore riproducibilità e trasparenza,\npossibilità di integrare codice ed esecuzione in un unico documento,\nfacilità di gestione delle citazioni automatiche,\nsupporto per diversi formati di output (HTML, PDF, Word).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#figure-e-tabelle",
    "href": "chapters/R/06_quarto.html#figure-e-tabelle",
    "title": "10  Quarto",
    "section": "\n10.4 4. Figure e Tabelle",
    "text": "10.4 4. Figure e Tabelle\n\n\nLe opzioni principali per le figure includono:\n\n\nfig-width e fig-height per le dimensioni,\n\nout-width per la larghezza relativa,\n\nfig-asp per il rapporto d’aspetto.\n\n\n\nPer creare una tabella formattata con knitr::kable():\nknitr::kable(head(mtcars))\n\n\n5. Citazioni e Bibliografia\n\nLe citazioni in Quarto si aggiungono usando il simbolo @ seguito dal riferimento BibTeX (es. @ceccarini2024age).\n\nPer gestire la bibliografia in Quarto servono:\n\nUn file .bib con le citazioni,\nUn’intestazione YAML che collega il file .bib e specifica lo stile (csl).\n\n\n\nEsempio di citazione BibTeX e collegamento in YAML:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect},\n  author={Ceccarini, Francesco et al.},\n  journal={Psychonomic Bulletin & Review},\n  year={2024}\n}\nYAML:\nbibliography: references.bib\nbiblio-style: apalike\n\n\n6. Considerazioni Finali\n\n\nI vantaggi di Quarto rispetto a Word includono:\n\nmaggiore riproducibilità e trasparenza,\npossibilità di integrare codice ed esecuzione in un unico documento,\nfacilità di gestione delle citazioni automatiche,\nsupporto per diversi formati di output (HTML, PDF, Word).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/06_quarto.html#informazioni-sullambiente-di-sviluppo",
    "title": "10  Quarto",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#bibliografia",
    "href": "chapters/R/06_quarto.html#bibliografia",
    "title": "10  Quarto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCeccarini, F., Colpizzi, I., & Caudek, C. (2024). Age-dependent changes in the anger superiority effect: Evidence from a visual search task. Psychonomic Bulletin & Review, 1–10.\n\n\nDogucu, M. (2024). Reproducibility in the Classroom. Annual Review of Statistics and Its Application, 12.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html",
    "href": "chapters/R/07_environment.html",
    "title": "11  L’ambiente di programmazione in R",
    "section": "",
    "text": "11.1 Introduzione\nProgrammare presuppone necessariamente un ambiente di programmazione. Una cattiva gestione di questo ambiente può causare il malfunzionamento degli script, rendendo fondamentale imparare a gestirlo correttamente.\nL’ambiente può influenzare persino il comportamento delle funzioni più basilari. Considera il seguente esempio:\nQuesto potrebbe produrre il seguente output:\nTuttavia, modificando l’opzione di larghezza in R, il comportamento cambia:\nIn questo caso, l’output potrebbe essere:\nLa differenza è dovuta a un’opzione dell’ambiente, width, che regola il numero massimo di caratteri visualizzati per ogni riga.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#introduzione",
    "href": "chapters/R/07_environment.html#introduzione",
    "title": "11  L’ambiente di programmazione in R",
    "section": "",
    "text": "Nota: In R, il termine “ambiente” ha un significato specifico, riferendosi allo spazio di lavoro in cui gli oggetti vengono memorizzati durante una sessione. In questo capitolo, tuttavia, il termine si riferisce allo stato complessivo del tuo computer mentre programmi, inclusa l’organizzazione dei file, la versione di R che stai usando e altre impostazioni.\n\n\nprint(1:9)\n\n[1] 1 2 3 4 5 6 7 8 9\n\n# Dopo aver modificato options(width)\noptions(width = 10)\nprint(1:9)\n\n[1] 1 2 3\n[4] 4 5 6\n[7] 7 8 9",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#file-system",
    "href": "chapters/R/07_environment.html#file-system",
    "title": "11  L’ambiente di programmazione in R",
    "section": "\n11.2 File system",
    "text": "11.2 File system\nPrima di iniziare a organizzare un progetto in R, è fondamentale seguire alcune linee guida per strutturare e nominare i file in modo efficace. Spesso si tende a sottovalutare l’importanza di una buona organizzazione, ma adottare un sistema coerente può far risparmiare tempo prezioso nella ricerca e gestione dei progetti passati. Danielle Navarro ha creato una presentazione sulla struttura dei progetti, nella quale propone tre principi fondamentali per la gestione dei file:\n\nessere gentili con le macchine;\nessere gentili con gli esseri umani;\nfacilitare l’ordinamento e la ricerca.\n\n\n11.2.1 Essere gentili con le macchine\nLe macchine possono confondersi con spazi, caratteri speciali (come ^.*?+|$\"), e lettere accentate. Per evitare problemi:\n\nusa solo lettere minuscole, numeri, trattini _ o -;\nevita caratteri speciali e spazi nei nomi dei file;\nevita le lettere accentate;\nusa estensioni coerenti, come .R per gli script R.\n\nEsempi:\n# Buono\nprogetto01_analisi_dati.R\n\n# Cattivo\nProgetto \"Analisi Dati\".R\n\n11.2.2 Essere gentili con gli umani\nGli esseri umani hanno bisogno di contesto. Evita nomi vaghi e usa descrizioni significative.\n# Buono\nanalisi01_statistiche_descrittive.R\nnote02_intro_modello.docx\n\n# Cattivo\n01.R\nappunti.docx\n\n\n\n\n\n\nEvitate categoricamente l’uso di spazi nei nomi di file, cartelle o oggetti in R. Anche se il sistema operativo potrebbe consentirlo, questa pratica può generare problemi futuri, complicare il debugging e rendere il codice meno leggibile e portabile. Per evitare questi inconvenienti, adottate sempre nomi privi di spazi, preferendo separatori come trattini bassi (_) o trattini (-).\n\n\n\n\n11.2.3 Facilitare l’ordinamento e la ricerca\nSe i nomi dei file includono date, usa sempre il formato YYYY-MM-DD per permettere un ordinamento automatico.\n# Buono\n2024-01-01_analisi.R\n2024-02-15_riassunto.docx\n\n# Cattivo\n1-gennaio-2024.R\nriassunto-15-02-2024.docx\nSe devi ordinare i file in base a qualcosa di diverso dalle date, usa numeri con lo zero iniziale per mantenere l’ordine.\nreading01_shakespeare_romeo-and-juliet.docx\nreading02_shakespeare_romeo-and-juliet.docx\n...\nreading11_shakespeare_romeo-and-juliet.docx\nnotes01_shakespeare_romeo-and-juliet.docx\n...",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#versioni-di-r-e-pacchetti",
    "href": "chapters/R/07_environment.html#versioni-di-r-e-pacchetti",
    "title": "11  L’ambiente di programmazione in R",
    "section": "\n11.3 Versioni di R e pacchetti",
    "text": "11.3 Versioni di R e pacchetti\nAggiornare regolarmente R e i pacchetti è essenziale per evitare bug e sfruttare le nuove funzionalità. Ecco alcune buone pratiche:\n\nEsegui update.packages() ogni poche settimane per aggiornare i pacchetti.\nAggiorna la versione di R ogni pochi mesi. Su Windows puoi usare il pacchetto installr, mentre su altri sistemi puoi scaricare l’ultima versione dal sito ufficiale di R.\nMantieni aggiornato anche il sistema operativo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#progetti-in-r",
    "href": "chapters/R/07_environment.html#progetti-in-r",
    "title": "11  L’ambiente di programmazione in R",
    "section": "\n11.4 Progetti in R",
    "text": "11.4 Progetti in R\nSe hai seguito i consigli finora, avrai creato una cartella per tutti i tuoi progetti di programmazione e la tua installazione di R sarà aggiornata. Ora è il momento di organizzare i tuoi progetti in R.\n\n11.4.1 Percorsi Assoluti e Relativi\nUn percorso assoluto parte dalla directory principale del tuo computer (ad esempio, / su Linux/MacOS o C:/ su Windows) e indica in modo completo e univoco la posizione di un file o di una cartella. Un percorso relativo, invece, parte dalla directory corrente del progetto o dalla directory di lavoro impostata e descrive la posizione di un file in relazione a questa.\nAd esempio, il percorso assoluto del file utilizzato per generare questa pagina HTML potrebbe essere ottenuto così:\n\nfs::path_abs(\"05_environment.qmd\")\n#&gt; /Users/corrado/_repositories/psicometria-r/chapters/R/05_environment.qmd",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#funzione-here",
    "href": "chapters/R/07_environment.html#funzione-here",
    "title": "11  L’ambiente di programmazione in R",
    "section": "\n11.5 Funzione here()\n",
    "text": "11.5 Funzione here()\n\nSe il progetto si trova nella cartella psicometria-r, possiamo utilizzare la funzione here() del pacchetto here per indicare la posizione del file 05_environment.qmd in modo relativo. Ecco un esempio:\n\nfile.exists(here::here(\"chapters\", \"R\", \"07_environment.qmd\"))\n#&gt; [1] TRUE\n\nIn questo caso, il file 07_environment.qmd è contenuto nella cartella chapters/R, che si trova all’interno della directory principale del progetto. Grazie a here(), non è necessario specificare manualmente la posizione del progetto: questa funzione identifica automaticamente la directory principale e consente di indicare solo il percorso relativo del file rispetto ad essa. In altre parole, puoi riferirti al file 07_environment.qmd semplicemente fornendo il percorso relativo all’interno della struttura del progetto, lasciando a here() il compito di gestire il contesto globale.\n\n11.5.1 Perché preferire i percorsi relativi?\nL’utilizzo di percorsi relativi con here() offre numerosi vantaggi:\n\n\nPortabilità: Il codice diventa più semplice da condividere, poiché non dipende dalla struttura delle directory specifica del computer su cui è stato scritto.\n\nOrganizzazione: Favorisce una struttura chiara e coerente all’interno del progetto, rendendo più facile individuare e accedere ai file.\n\nAffidabilità: Riduce il rischio di errori dovuti a percorsi assoluti errati, soprattutto quando il progetto viene spostato o condiviso.\n\n11.5.2 Buone pratiche\n\n\nUsare sempre percorsi relativi: Questo assicura che il progetto sia facilmente eseguibile su altri sistemi senza necessità di modifiche ai percorsi.\n\nImpostare una struttura coerente del progetto: Organizzare i file in cartelle ben definite (ad esempio, data, scripts, outputs) facilita l’uso di percorsi relativi.\n\nIn sintesi, specificare i percorsi relativi rispetto alla directory principale del progetto è una buona pratica essenziale per garantire portabilità, organizzazione e riproducibilità del lavoro.\n\n11.5.3 Creare un progetto in R\nUn progetto R è semplicemente una cartella con un file .Rproj. Puoi crearne uno con RStudio o con il pacchetto usethis.\nIn RStudio:\n\nVai su File &gt; New Project.\nSeleziona New Directory &gt; New Project.\nDai un nome al progetto e scegli la sua posizione.\n\nCon usethis:\nusethis::create_project(\"path/alla/cartella\")\nEsempio:\nusethis::create_project(\"/Users/corrado/_repositories/psicometria-r\")\nVedremo nel Capitolo 13 come organizzare i file all’interno di un progetto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/07_environment.html#informazioni-sullambiente-di-sviluppo",
    "title": "11  L’ambiente di programmazione in R",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         crayon_1.5.3      rlang_1.1.5      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   fs_1.6.5          htmlwidgets_1.6.4\n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      glue_1.8.0       \n#&gt; [33] xfun_0.50         tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-167      rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#bibliografia",
    "href": "chapters/R/07_environment.html#bibliografia",
    "title": "11  L’ambiente di programmazione in R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html",
    "href": "chapters/R/08_ai.html",
    "title": "12  Utilizzo di strumenti AI per la programmazione",
    "section": "",
    "text": "12.1 Introduzione\nIl panorama della programmazione sta attraversando una trasformazione radicale, guidata dall’avvento degli strumenti di intelligenza artificiale (AI). Questi assistenti innovativi stanno rivoluzionando il modo in cui sviluppatori, ricercatori e studenti scrivono, comprendono e ottimizzano il codice. Grazie a una nuova generazione di strumenti che vanno oltre i tradizionali ambienti di sviluppo, l’intelligenza artificiale sta aprendo possibilità inedite. Piattaforme come ChatGPT, Google Gemini, Claude.ai, DeepSeek e Qwen sono in grado di generare codice, spiegare concetti complessi e fornire supporto agli sviluppatori in modi che, fino a poco tempo fa, erano impensabili.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#potenzialità-e-sfide-dellai-nella-programmazione",
    "href": "chapters/R/08_ai.html#potenzialità-e-sfide-dellai-nella-programmazione",
    "title": "12  Utilizzo di strumenti AI per la programmazione",
    "section": "12.2 Potenzialità e Sfide dell’AI nella Programmazione",
    "text": "12.2 Potenzialità e Sfide dell’AI nella Programmazione\nGli strumenti di intelligenza artificiale (AI) stanno trasformando radicalmente il modo in cui si programma, inclusa l’elaborazione di codice in linguaggi come R. Tuttavia, accanto alle immense potenzialità, emergono anche sfide significative. I modelli di linguaggio di grandi dimensioni (LLM, Large Language Models) possono ottimizzare e accelerare i flussi di lavoro, ma non sono privi di limitazioni. Tra queste, la possibilità di generare codice impreciso, introdurre bias involontari o produrre output che richiedono una verifica approfondita da parte dell’utente.\nNonostante queste sfide, gli strumenti di AI offrono un supporto prezioso in diverse aree chiave:\n\nSupporto Concettuale:\nGli LLM si dimostrano particolarmente efficaci nel rispondere a domande complesse su metodi statistici, algoritmi e tecniche di analisi dei dati. La qualità delle risposte migliora notevolmente quando le domande sono formulate in modo chiaro, specifico e dettagliato.\nGenerazione e Completamento del Codice:\nQuesti strumenti possono aiutare gli sviluppatori a scrivere codice più rapidamente, suggerendo completamenti automatici, identificando potenziali errori e persino generando interi script a partire da descrizioni testuali. Questo riduce il tempo dedicato alla scrittura manuale e permette di concentrarsi su aspetti più creativi o complessi del progetto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#panoramica-comparativa-dei-principali-strumenti-ai",
    "href": "chapters/R/08_ai.html#panoramica-comparativa-dei-principali-strumenti-ai",
    "title": "12  Utilizzo di strumenti AI per la programmazione",
    "section": "12.3 Panoramica Comparativa dei Principali Strumenti AI",
    "text": "12.3 Panoramica Comparativa dei Principali Strumenti AI\nCome scegliere il modello linguistico più adatto per un determinato compito? Nell’articolo di Gibney (2025), ricercatori condividono i loro strumenti preferiti attualmente in uso, offrendo una guida pratica a chi ha bisogno di orientarsi tra le varie opzioni.\n\n12.3.1 o3-mini (il ragionatore)\nOpenAI ha lanciato o3-mini, un modello di ragionamento gratuito per gli utenti registrati, sviluppato in risposta alla crescente concorrenza di DeepSeek. Questo modello si distingue per l’utilizzo di un processo di ragionamento a catena (chain-of-thought reasoning), che gli permette di affrontare problemi complessi in ambito matematico e scientifico con precisione. Oltre a eccellere nell’analisi tecnica e nella riformattazione dei dati, o3-mini è particolarmente efficace nel scomporre concetti intricati in passaggi più semplici. Tuttavia, nonostante le sue capacità avanzate, non è ancora in grado di eguagliare il ragionamento umano in contesti che richiedono creatività o intuizione profonda.\n\n\n12.3.2 DeepSeek (il tuttofare)\nDeepSeek-R1 è un modello open-weight paragonabile a o1 di OpenAI, ma disponibile a un costo inferiore attraverso API. La sua natura trasparente lo rende particolarmente attraente per i ricercatori, che possono adattarlo ai propri progetti specifici. DeepSeek è utile per generare ipotesi, migliorare la diagnostica medica e supportare attività di ricerca avanzate. Tuttavia, presenta alcuni limiti: il suo processo di ragionamento è più lento rispetto ad altri modelli e offre meno filtri contro output potenzialmente dannosi. Inoltre, OpenAI ha sollevato dubbi sulla legittimità del suo processo di addestramento, alimentando un dibattito sulla trasparenza e l’etica degli LLM.\n\n\n12.3.3 Llama (il cavallo di battaglia)\nSviluppato da Meta, Llama è uno dei modelli LLM più utilizzati nella ricerca grazie alla sua natura open-weight, che consente agli scienziati di personalizzarlo e impiegarlo in ambienti controllati. È stato applicato con successo in una vasta gamma di ambiti, dalla predizione delle strutture cristalline ai calcoli quantistici, dimostrando una grande versatilità. Tuttavia, l’accesso a Llama richiede un’autorizzazione specifica, rendendolo meno immediato rispetto ad altri modelli open-source emergenti che sono disponibili senza restrizioni.\n\n\n12.3.4 Claude (lo sviluppatore)\nClaude 3.5 Sonnet, prodotto da Anthropic, è particolarmente apprezzato per la sua capacità di scrivere codice e interpretare dati visivi. Questo modello si distingue per la sua abilità nel mantenere il significato tecnico anche durante la semplificazione del linguaggio, rendendolo ideale per redigere proposte di ricerca, annotare codice e supportare attività di sviluppo software. Tuttavia, l’accesso completo alle sue funzionalità richiede un’API a pagamento, il che lo rende meno competitivo rispetto ai modelli open-source in rapida crescita, soprattutto per utenti con budget limitati.\n\n\n12.3.5 OLMo (il veramente open)\nOLMo 2 rappresenta un passo avanti nella trasparenza degli LLM. Questo modello non solo fornisce i pesi del modello, ma anche i dati di addestramento e il codice di sviluppo, offrendo una visione completa del suo funzionamento. Questa apertura lo rende ideale per ricercatori e sviluppatori che desiderano analizzare bias, ottimizzare le prestazioni o comprendere a fondo il processo di creazione di un LLM. L’unico svantaggio è che richiede competenze tecniche avanzate per l’implementazione, sebbene il numero di risorse educative e tutorial disponibili stia crescendo rapidamente.\nOgni modello presenta punti di forza e limiti specifici, rendendoli adatti a contesti diversi. Mentre o3-mini e DeepSeek si concentrano su ragionamento e analisi tecnica, Llama e OLMo offrono maggiore flessibilità e trasparenza per la ricerca. Claude, d’altra parte, si distingue per le sue capacità di sviluppo e interpretazione di dati complessi. La scelta del modello dipende dalle esigenze specifiche dell’utente, dal budget disponibile e dalle competenze tecniche.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#considerazioni-etiche-e-pratiche",
    "href": "chapters/R/08_ai.html#considerazioni-etiche-e-pratiche",
    "title": "12  Utilizzo di strumenti AI per la programmazione",
    "section": "12.4 Considerazioni Etiche e Pratiche",
    "text": "12.4 Considerazioni Etiche e Pratiche\nL’adozione di strumenti di intelligenza artificiale (AI) solleva questioni etiche e pratiche che richiedono un’attenta riflessione e un approccio responsabile.\n\nTrasparenza\nI dataset utilizzati per addestrare i modelli di AI sono spesso poco documentati e opachi, rendendo difficile valutarne la qualità e l’equità. Questo solleva interrogativi sulla presenza di bias involontari e sulla rappresentatività dei dati, con notevoli implicazioni per l’affidabilità dei risultati.\nEquità di Accesso\nNonostante le potenzialità rivoluzionarie degli strumenti di AI, l’accesso a queste tecnologie non è uniformemente distribuito. Disparità economiche, geografiche e infrastrutturali possono creare disuguaglianze, limitando l’adozione di queste risorse in contesti meno privilegiati e ampliando il divario digitale.\nResponsabilità\nUno dei dilemmi più complessi riguarda l’attribuzione della responsabilità per i risultati generati dai sistemi di AI. In caso di errori, bias o conseguenze indesiderate, non è sempre chiaro chi debba assumersi la responsabilità: gli sviluppatori del modello, gli utenti o le organizzazioni che lo implementano.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#riflessioni-conclusive",
    "href": "chapters/R/08_ai.html#riflessioni-conclusive",
    "title": "12  Utilizzo di strumenti AI per la programmazione",
    "section": "12.5 Riflessioni Conclusive",
    "text": "12.5 Riflessioni Conclusive\nGli strumenti di intelligenza artificiale stanno rivoluzionando il mondo della programmazione, offrendo un supporto senza precedenti per la risoluzione di problemi complessi, la generazione di codice e l’ottimizzazione dei flussi di lavoro. Tuttavia, il loro utilizzo deve essere accompagnato da un approccio critico e consapevole. È essenziale verificare i risultati, valutare le implicazioni etiche e garantire che l’adozione di queste tecnologie avvenga in modo equo e responsabile.\nL’intelligenza artificiale non sostituirà gli sviluppatori, ma si affermerà come un alleato indispensabile, ampliando la creatività e le competenze umane. Questa collaborazione tra uomo e macchina ridefinirà il modo in cui affrontiamo le sfide del futuro, aprendo nuove opportunità e trasformando il panorama della tecnologia e della ricerca (Bonnefon et al., 2024; Liu & Li, 2024).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#bibliografia",
    "href": "chapters/R/08_ai.html#bibliografia",
    "title": "12  Utilizzo di strumenti AI per la programmazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBonnefon, J.-F., Rahwan, I., & Shariff, A. (2024). The moral psychology of Artificial Intelligence. Annual Review of Psychology, 75(1), 653–675.\n\n\nGibney, E. (2025). What are the best AI tools for research? Nature’s guide. Nature, 578(7795), 123–125. https://doi.org/10.1038/d41586-025-00437-0\n\n\nLiu, J., & Li, S. (2024). Toward Artificial Intelligence-Human Paired Programming: A Review of the Educational Applications and Research on Artificial Intelligence Code-Generation Tools. Journal of Educational Computing Research, 07356331241240460.\n\n\nMeskó, B. (2023). Prompt engineering as an important emerging skill for medical professionals: tutorial. Journal of Medical Internet Research, 25, e50638.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html",
    "href": "chapters/eda/introduction_eda.html",
    "title": "EDA",
    "section": "",
    "text": "Dopo aver acquisito un dataset, è fondamentale comprendere a fondo le caratteristiche dei dati in esso contenuti. Sebbene le statistiche descrittive e altre misure numeriche siano spesso efficaci per ottenere una visione d’insieme, talvolta è un’immagine a valere più di mille parole.\nIn questa sezione della dispensa, esploreremo alcuni concetti chiave della statistica descrittiva. Oltre a fornire definizioni teoriche, presenteremo istruzioni pratiche in R per condurre analisi statistiche su dati reali. Il capitolo si concluderà con una riflessione critica sui limiti di un approccio epistemologico basato esclusivamente sull’analisi delle associazioni tra variabili, evidenziando l’importanza di indagare le cause sottostanti ai fenomeni osservati.",
    "crumbs": [
      "EDA"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html",
    "href": "chapters/eda/01_project_structure.html",
    "title": "13  Le fasi del progetto di analisi dei dati",
    "section": "",
    "text": "13.1 Introduzione\nUna gestione accurata ed efficace dei dati è fondamentale in molte discipline, inclusa la psicologia, dove l’analisi di dataset complessi rappresenta un aspetto centrale della ricerca. Garantire che i dati siano raccolti con precisione, organizzati in modo chiaro e facilmente accessibili per analisi e verifiche è essenziale per preservare l’integrità del lavoro scientifico e promuoverne la riproducibilità. Una gestione rigorosa dei dati assicura qualità e affidabilità in tutte le fasi di un progetto, dalla raccolta alla documentazione dei processi di elaborazione e delle eventuali modifiche apportate.\nDati ben organizzati e documentati non solo semplificano e rendono più efficiente il processo di analisi, ma riducono anche il rischio di errori, migliorando l’utilizzabilità e l’interpretazione delle informazioni. Questo è particolarmente rilevante quando si lavora con dataset provenienti da fonti eterogenee o con strutture complesse. Inoltre, la trasparenza e la completezza nella gestione dei dati rappresentano una condizione imprescindibile per garantire la riproducibilità della ricerca, un pilastro fondamentale della scienza. La possibilità per altri ricercatori di replicare i risultati utilizzando gli stessi dati e metodi rafforza la credibilità delle conclusioni e contribuisce a costruire un progresso scientifico condiviso e solido. Di conseguenza, una gestione dei dati responsabile non è solo una buona pratica, ma una necessità per la produzione di conoscenze affidabili e sostenibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#capacità-di-gestione-dei-dati-in-r",
    "href": "chapters/eda/01_project_structure.html#capacità-di-gestione-dei-dati-in-r",
    "title": "13  Le fasi del progetto di analisi dei dati",
    "section": "\n13.3 Capacità di Gestione dei Dati in R",
    "text": "13.3 Capacità di Gestione dei Dati in R\nUna volta compresi i benefici di una pianificazione strategica, è importante disporre di strumenti adeguati per gestire, analizzare e documentare i dati. In questo capitolo ci concentreremo sul ruolo di R in un workflow efficiente di analisi dei dati. R è uno strumento potente e versatile, pensato per supportare tutte le fasi del ciclo di vita dei dati, dalla raccolta alla documentazione, risultando così un alleato indispensabile per chiunque lavori con dataset complessi. Le sue principali funzionalità includono:\n\n\nImportazione ed esportazione dei dati: Pacchetti come readr e rio semplificano l’importazione di dati da fonti diverse (file CSV, database, API web) e l’esportazione in formati adatti a svariati utilizzi.\n\n\nPulizia e preparazione dei dati: Grazie a pacchetti come dplyr, tidyr e stringr, R offre strumenti intuitivi per manipolare, trasformare e preparare i dati in modo efficiente, rendendoli pronti per l’analisi.\n\n\nEsplorazione e sintesi: Con pacchetti come dplyr e ggplot2, R permette di calcolare statistiche descrittive, individuare pattern significativi e visualizzare distribuzioni e relazioni in modo chiaro e informativo.\n\n\nDocumentazione dinamica: Strumenti come R Markdown e Quarto consentono di integrare in un unico documento codice, analisi, testo esplicativo e risultati, facilitando la riproducibilità e la trasparenza del lavoro.\n\n\nControllo delle versioni: L’integrazione di Git in RStudio offre un sistema di gestione delle versioni che consente di monitorare modifiche, collaborare con altri e garantire la tracciabilità del processo analitico.\n\nLa combinazione di pianificazione strategica e strumenti avanzati come R rappresenta un approccio vincente per affrontare progetti complessi. Le funzionalità di R, se utilizzate in modo appropriato, riducono al minimo il rischio di errori e massimizzano l’efficienza e l’affidabilità dei risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#configurare-lambiente-r",
    "href": "chapters/eda/01_project_structure.html#configurare-lambiente-r",
    "title": "13  Le fasi del progetto di analisi dei dati",
    "section": "\n13.4 Configurare l’Ambiente R",
    "text": "13.4 Configurare l’Ambiente R\nPer sfruttare al meglio le potenzialità di R è essenziale configurare correttamente RStudio e integrare i pacchetti fondamentali per la gestione dei dati. Una configurazione adeguata favorisce la riproducibilità e l’organizzazione del lavoro.\n\n13.4.1 Workspace e Cronologia\nAccedi a Tools &gt; Global Options &gt; General e modifica le seguenti impostazioni:\n\nDisabilita l’opzione Restore .RData into workspace at startup.\n\nImposta Save workspace to .RData on exit su Never.\n\nQueste scelte incoraggiano una gestione basata sugli script, rendendo il lavoro più trasparente e riducendo possibili conflitti tra sessioni diverse. Ogni analisi sarà così chiaramente documentata nel codice, evitando dipendenze da file temporanei o precedenti sessioni di lavoro.\n\n13.4.2 Pacchetti Essenziali\nR è composto da un modulo base che fornisce le funzionalità fondamentali del linguaggio, ma il suo potere deriva dall’ampio ecosistema di pacchetti. Per questo corso (e in generale per un workflow efficiente), utilizzeremo regolarmente i seguenti pacchetti:\n\n\nhere: per la gestione ordinata dei percorsi relativi, evitando problemi con i percorsi assoluti.\n\n\ntidyverse: una raccolta di pacchetti (tra cui dplyr, tidyr, ggplot2) essenziali per la manipolazione, l’analisi e la visualizzazione dei dati.\n\nAssicurati di installarli e caricarli all’inizio di ogni script con i comandi:\n# install.packages(c(\"here\", \"tidyverse\"))\n# installali solo la prima volta\nlibrary(here)\nlibrary(tidyverse)\n\n13.4.3 Gestione dei Progetti\nI progetti in RStudio rappresentano uno strumento chiave per mantenere il lavoro ben organizzato. Sfruttare i progetti consente di creare ambienti separati, in cui ogni progetto ha la propria directory dedicata.\nPer creare un nuovo progetto:\n\nVai su File &gt; New Project.\n\nSeleziona la directory dove verrà creato il tuo progetto.\n\nSalva tutti i file correlati (script, dati, risultati) all’interno di questa directory.\n\nQuesto approccio previene confusione e facilita la navigazione, in quanto ogni progetto diventa un’unità autonoma, ideale per mantenere ordine e coerenza nel lavoro.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#il-ciclo-di-vita-di-un-progetto-di-data-science",
    "href": "chapters/eda/01_project_structure.html#il-ciclo-di-vita-di-un-progetto-di-data-science",
    "title": "13  Le fasi del progetto di analisi dei dati",
    "section": "\n13.5 Il Ciclo di Vita di un Progetto di Data Science",
    "text": "13.5 Il Ciclo di Vita di un Progetto di Data Science\nUna volta configurato un ambiente stabile, organizzato e pronto per l’analisi, è possibile affrontare in modo sistematico le diverse fasi che caratterizzano tipicamente un progetto di Data Science. Secondo la proposta di (Yu & Barter, 2024), queste fasi sono:\n\n\nFormulazione del problema e raccolta dei dati: Definizione delle domande di ricerca e acquisizione dei dataset.\n\n\nPulizia, preprocessing e analisi esplorativa: Preparazione dei dati per l’analisi attraverso trasformazioni e sintesi.\n\n\nAnalisi predittiva e/o inferenziale (opzionale): Modelli statistici o predittivi per rispondere alle domande di ricerca.\n\n\nValutazione dei risultati: Interpretazione e verifica delle conclusioni tratte.\n\n\nComunicazione dei risultati: Presentazione dei risultati in forma visiva e narrativa.\n\nNon tutti i progetti prevedono la fase di analisi predittiva, ma quasi tutti attraversano le altre fasi. Mantenere un approccio organizzato e ben strutturato lungo tutto il ciclo di vita riduce il rischio di errori e favorisce la riproducibilità.\n\n13.5.1 Fase 1: Formulazione del Problema e Raccolta dei Dati\nLa definizione di una domanda di ricerca chiara e precisa rappresenta la base di qualunque progetto di data science. È cruciale stabilire con attenzione l’ambito dell’analisi:\n\nAmbito Applicativo\nIn un contesto applicativo, l’obiettivo principale è spesso la realizzazione di un report descrittivo su un intervento o un’attività specifica (ad esempio, valutare l’efficacia di un programma di educazione sessuale rivolto agli adolescenti). In questo caso, l’attenzione si focalizza sulla descrizione dei risultati ottenuti, senza necessariamente approfondire i fondamenti teorici.\nAmbito della Ricerca Psicologica\nIn un contesto di ricerca, invece, diventa essenziale giustificare le scelte metodologiche, la selezione degli strumenti di misura e la formulazione delle domande di ricerca sulla base della letteratura esistente e di teorie consolidate. (Questo è oggetto di approfondimento nel Capitolo 3.)\n\n\n13.5.1.1 Caratteristiche di una Buona Domanda di Ricerca\nLa domanda di ricerca deve essere formulata in modo che sia possibile rispondervi analizzando i dati a disposizione. Talvolta, la domanda iniziale può risultare troppo ampia o irrealistica rispetto ai dati disponibili, rendendo necessario un processo di revisione. L’obiettivo è assicurare che i dati raccolti (o da raccogliere) siano appropriati e sufficienti a fornire una risposta solida al quesito di partenza.\n\n13.5.1.2 Raccolta dei Dati\nIn questa fase, è altrettanto cruciale identificare chiaramente i dati da utilizzare e comprenderne la provenienza. Esistono principalmente due scenari:\n\nUtilizzo di Dati Esistenti\nAlcuni progetti si basano su dataset già disponibili, reperiti da repository pubblici, database aziendali o esperimenti precedenti.\nNuova Raccolta di Dati\nAltri progetti richiedono la raccolta di dati ex novo. In entrambi i casi, è importante pianificare con cura le analisi prima di avviare la raccolta, onde evitare di ritrovarsi con dataset incompleti o non adatti agli obiettivi.\n\nÈ inoltre essenziale documentare accuratamente le tecniche e procedure utilizzate per la raccolta dati, nonché valutare e dichiarare eventuali limitazioni che possano inficiare l’interpretazione dei risultati.\n\n13.5.2 Fase 2: Pulizia dei Dati e Analisi Esplorativa\n\n13.5.2.1 Importazione ed Esportazione dei Dati in R\nUna volta individuati i dati, occorre importarli in R in un formato adatto all’analisi, tipicamente in un data frame. Il pacchetto rio fornisce la funzione universale import(), che rende superfluo l’uso di funzioni specifiche per ciascun formato (es. .csv, .xlsx, .json, ecc.). Per organizzare al meglio i file, si consiglia di creare una struttura di cartelle chiara (es. data/raw per i dati grezzi e data/processed per i dati elaborati) e di usare percorsi relativi attraverso il pacchetto here.\nEsempio di importazione:\nlibrary(here)\nlibrary(rio)\n\ndf &lt;- import(here(\"data\", \"raw\", \"my_data.csv\"))\nPer esportare i dati elaborati:\nexport(df, here(\"data\", \"processed\", \"my_data_processed.csv\"))\nQuesta strategia migliora la portabilità (il progetto può essere facilmente trasferito su altri computer) e la riproducibilità (poiché non è necessario modificare manualmente i percorsi dei file).\n\n13.5.2.2 Pulizia dei Dati\nDopo avere definito la domanda di ricerca e recuperato i dati, il passo successivo è la pulizia. Un dataset “pulito” è ordinato, coerente e privo di ambiguità, così che sia comprensibile sia per il computer sia per l’analista. La pulizia dei dati implica l’individuazione di valori anomali, formattazioni errate, duplicati, incongruenze e valori mancanti, per poi sistemarli in modo appropriato (con codice, senza alterare i file dei dati grezzi originali).\nLa pulizia dei dati è una fase cruciale: aiuta a sviluppare una comprensione più approfondita del dataset e delle sue eventuali limitazioni. L’obiettivo è creare una versione dei dati che rifletta il più fedelmente possibile la realtà e che sia interpretata correttamente dal computer.\n\n13.5.2.3 Preprocessing\nIl preprocessing consiste nell’effettuare quelle trasformazioni sui dati puliti che sono richieste da specifici algoritmi di analisi o di modellazione. Ad esempio, alcuni modelli possono richiedere variabili su scale comparabili oppure l’assenza di valori mancanti. Durante il preprocessing, si possono anche generare nuove variabili ritenute utili all’analisi.\nNon esiste una procedura di preprocessing “universale”: ogni scelta va documentata e motivata, poiché implica decisioni soggettive che influiscono sull’interpretazione finale dei risultati.\n\n13.5.2.4 Analisi Esplorativa dei Dati\nDopo l’importazione, la pulizia e il preprocessing, è il momento di esplorare il dataset. L’Analisi Esplorativa dei Dati (Exploratory Data Analysis, EDA) comprende:\n\nCalcolo di statistiche descrittive (misure di tendenza centrale, dispersione, etc.)\n\nIdentificazione di pattern e distribuzioni insolite\n\nCreazione di tabelle di contingenza e diagrammi (istogrammi, boxplot, scatterplot, ecc.)\n\nL’obiettivo principale è far familiarizzare il ricercatore con la struttura dei dati e fornire ipotesi da verificare nelle fasi successive.\n\n13.5.3 Fase 3: Analisi Predittiva e Inferenziale\nA seconda degli obiettivi del progetto, l’analisi può includere modelli statistici o algoritmi di machine learning orientati all’inferenza e/o alla previsione. In psicologia, ciò può tradursi nell’uso di modelli di regressione, test statistici, modelli misti o metodi di classificazione e clustering. L’obiettivo è rispondere a domande di ricerca specifiche o fare inferenze su una popolazione più ampia. Nei contesti applicativi, può riguardare la costruzione di modelli predittivi per stimare il comportamento di variabili di interesse sulla base dei dati storici.\n\n13.5.4 Fase 4: Valutazione dei Risultati\nIn questa fase si valuta la bontà dei risultati ottenuti, sia dal punto di vista quantitativo (applicando metriche appropriate o test statistici) sia qualitativo (interpretazione teorica o pratica dei risultati). È il momento di ricollegarsi alla domanda di ricerca iniziale, per verificare se gli obiettivi sono stati raggiunti e quali implicazioni emergono.\n\n13.5.5 Fase 5: Comunicazione dei Risultati\nL’ultima fase consiste nella comunicazione dei risultati a un pubblico più ampio, che può essere composto da ricercatori, committenti, stakeholder o utenti finali. È essenziale presentare i risultati in maniera chiara e accessibile, evitando di dare per scontata una profonda conoscenza del progetto o del gergo tecnico. Si può optare per:\n\n\nArticoli scientifici: per condividere le scoperte con la comunità accademica.\n\n\nReport interni: per informare un team di lavoro o un ente finanziatore.\n\n\nPresentazioni: per trasmettere rapidamente i risultati a un pubblico non specialistico.\n\nUna comunicazione efficace richiede di spiegare in modo comprensibile le analisi e le figure mostrate, fornendo una guida interpretativa. L’uso di grafici e diagrammi ben curati può facilitare molto la fruizione delle informazioni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "href": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "title": "13  Le fasi del progetto di analisi dei dati",
    "section": "\n13.6 Organizzazione del Progetto",
    "text": "13.6 Organizzazione del Progetto\nUn aspetto fondamentale per il successo e la riproducibilità di un progetto di analisi dati è l’organizzazione efficiente dei file, che include dati, codice e documentazione. Questi file dovrebbero essere riuniti all’interno di una singola cartella (o directory) dedicata al progetto.\n\n13.6.1 Home Directory\nIn RStudio, è possibile creare un file nome_del_progetto.Rproj, che definisce la cartella principale (home directory) da cui R avvia il lavoro. Basta aprire RStudio cliccando su questo file per lavorare automaticamente all’interno dell’ambiente del progetto, rendendo più agevole l’uso di percorsi relativi e la gestione di script, dati e output.\n\n13.6.2 Struttura di un Progetto\nYu & Barter (2024) propone un template per organizzare in modo chiaro un progetto di analisi dati:\nnome_progetto/\n├── nome_progetto.Rproj\n├── data/\n│   ├── raw/\n│   │   └── my_data.csv\n│   ├── processed/\n├── dslc_documentation/\n│   ├── 01_data_cleaning.qmd\n│   ├── 02_analysis.qmd\n│   └── functions/\n└── README.md\n\n\ndata/:\n\n\nraw/: contiene i dati grezzi, mai modificati;\n\n\nprocessed/: ospita i dati puliti ed elaborati, pronti per l’analisi;\n\nImportante inserire un codebook per documentare il significato delle variabili e le unità di misura.\n\n\n\ndslc_documentation/:\n\nContiene i file necessari per l’analisi (in Quarto .qmd, Jupyter Notebook .ipynb, o altro).\n\nPuò includere una sottocartella functions/ con script .R o .py contenenti funzioni personalizzate.\n\n\n\nREADME.md:\n\nDescrive la struttura del progetto, gli obiettivi e i passaggi per replicare le analisi.\n\n\n\n\n13.6.2.1 Vantaggi di questa struttura\n\n\nOrganizzazione Chiara: separare i dati grezzi da quelli elaborati riduce la confusione e il rischio di modifiche involontarie ai dati originali.\n\n\nRiproducibilità: la presenza di documentazione completa (codebook, file di analisi, README) consente di comprendere e replicare i risultati anche a distanza di tempo o da parte di terzi.\n\n\nPortabilità: lavorando con percorsi relativi (es. grazie al pacchetto here in R), l’intero progetto può essere trasferito da un computer all’altro senza bisogno di modificare il codice.\n\n\nEfficienza: la sottocartella functions/ permette di riutilizzare codice e funzioni personalizzate, evitando duplicazioni negli script principali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "href": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "title": "13  Le fasi del progetto di analisi dei dati",
    "section": "\n13.7 Riflessioni Conclusive",
    "text": "13.7 Riflessioni Conclusive\nLa forza e la bellezza del codice risiedono nella sua riusabilità: una volta scritto, può essere eseguito infinite volte per ottenere risultati coerenti. Se l’ambiente di lavoro è configurato correttamente, lo stesso codice applicato agli stessi dati fornirà sempre gli stessi output. Questo principio, chiamato riproducibilità computazionale, è essenziale per garantire trasparenza e affidabilità nel lavoro scientifico.\nLa riproducibilità offre numerosi benefici:\n\nMonitorare le modifiche del progetto\nLa capacità di riprodurre il lavoro facilita il monitoraggio dell’evoluzione del progetto e delle scelte implementative nel tempo.\nRiprodurre il proprio lavoro\nIl primo vero vantaggio della riproducibilità è per chi ha sviluppato il codice: tornare a distanza di mesi (o anni) su un progetto e ritrovare un flusso di lavoro chiaro e replicabile agevola enormemente la revisione o l’estensione delle analisi.\nCondivisione e crescita collettiva\nMettere a disposizione il proprio lavoro in forma riproducibile consente ad altri ricercatori di validare e ampliare i risultati, stimolando un progresso scientifico collettivo e robusto.\n\nRendere il proprio lavoro riproducibile richiede attenzione alla documentazione, un’organizzazione solida del progetto e l’uso di strumenti adeguati per garantire la stabilità dell’ambiente. I metodi e le tecniche esplorate in questo capitolo – dalla pianificazione strategica alla pulizia dei dati, dalla struttura delle cartelle al controllo di versione – sono tutti tasselli fondamentali per realizzare analisi rigorose, verificabili e di valore duraturo.\nIn sintesi, un progetto di Data Science di successo richiede sia un’accurata pianificazione strategica – per evitare debiti tecnici e massimizzare l’efficacia del proprio lavoro – sia l’uso di strumenti adeguati, come R e i relativi pacchetti, in un ambiente ben configurato. Seguire un ciclo di vita del progetto ben definito e mantenere un’organizzazione logica di dati, codice e documentazione consente di promuovere l’efficienza, ridurre i rischi di errore e favorire la riproducibilità, un valore fondante della scienza moderna.\n\n\n\n\n\n\nUn problema cruciale nella psicologia contemporanea è la crisi di replicabilità, che evidenzia come molti risultati di ricerca non siano replicabili (Collaboration, 2015). La riproducibilità computazionale, pur avendo un obiettivo più ristretto, si concentra sulla possibilità di ottenere gli stessi risultati applicando lo stesso codice agli stessi dati. Questo approccio, sebbene non risolva interamente la crisi, rappresenta un passo fondamentale verso una scienza più trasparente e rigorosa.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#esercizi",
    "href": "chapters/eda/01_project_structure.html#esercizi",
    "title": "13  Le fasi del progetto di analisi dei dati",
    "section": "\n13.8 Esercizi",
    "text": "13.8 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nL’obiettivo di questo esercizio è comprendere il ciclo di vita di un progetto di analisi dei dati, l’organizzazione del progetto e la gestione della riproducibilità.\n\n\nGestione del progetto di analisi\n\nQuali sono le fasi principali di un progetto di analisi dei dati secondo Yu (2024)?\nSpiega il ruolo della fase di formulazione del problema e raccolta dei dati.\n\n\n\nOrganizzazione del workspace in R\n\nQuali impostazioni devono essere modificate in RStudio per favorire la riproducibilità?\nPerché è importante usare percorsi relativi nei progetti in RStudio?\nDescrivi il ruolo del pacchetto here nella gestione dei percorsi dei file.\n\n\n\nStruttura dei progetti in R\n\nQuali sono i vantaggi dell’utilizzo dei progetti in RStudio?\nQuali sono le cartelle principali in una struttura organizzata di un progetto?\nPerché è utile separare i dati grezzi dai dati processati?\n\n\n\nImportazione ed esportazione dei dati\n\nQuali pacchetti di R possono essere utilizzati per importare ed esportare dati?\n\nScrivi un esempio di codice per importare un file CSV usando rio e il pacchetto here.\n\nCome puoi esportare un dataset modificato in una cartella dedicata ai dati processati?\n\n\n\nPulizia e preprocessing dei dati\n\nQual è la differenza tra pulizia e preprocessing dei dati?\n\nQuali strumenti di dplyr sono comunemente usati per pulire e trasformare i dati?\n\n\n\nAnalisi esplorativa dei dati (EDA)\n\nQuali sono alcuni strumenti utilizzati in R per effettuare un’analisi esplorativa dei dati?\n\nScrivi un breve esempio di codice in R per calcolare statistiche descrittive di base su un dataset.\n\n\n\nRiproducibilità e comunicazione dei risultati\n\nPerché la riproducibilità è un elemento chiave nella scienza dei dati?\n\nQuali strumenti offre Quarto per la documentazione e la condivisione dei risultati di un’analisi?\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Gestione del progetto di analisi\n\n\nFasi principali del progetto di analisi dei dati (Yu, 2024):\n\nFormulazione del problema e raccolta dei dati\n\nPulizia, preprocessing e analisi esplorativa\n\nAnalisi predittiva e/o inferenziale (se applicabile)\n\nValutazione dei risultati\n\nComunicazione dei risultati\n\n\n\nRuolo della fase di formulazione del problema:\nAiuta a definire gli obiettivi dell’analisi e a selezionare le fonti di dati adeguate. Una domanda di ricerca ben definita garantisce che i dati siano pertinenti e che le analisi siano mirate.\n\n2. Organizzazione del workspace in R\n\n\nImpostazioni da modificare in RStudio:\n\nDisabilitare Restore .RData into workspace at startup\n\nImpostare Save workspace to .RData on exit su “Never”\n\n\nImportanza dei percorsi relativi:\nPermettono di rendere il progetto portabile e riproducibile, evitando problemi di percorsi assoluti specifici per un computer.\nRuolo del pacchetto here\nAiuta a gestire i percorsi relativi all’interno del progetto senza dover specificare percorsi assoluti.\n\n3. Struttura dei progetti in R\n\nVantaggi dell’uso dei progetti in RStudio:\nMantengono ambienti separati, organizzano i file e facilitano la riproducibilità.\n\nCartelle principali in una struttura organizzata:\n\n\ndata/raw/ → Dati grezzi\n\n\ndata/processed/ → Dati elaborati\n\n\ndslc_documentation/ → Documentazione e script\n\n\nfunctions/ → Funzioni personalizzate\n\n\nSeparare dati grezzi da dati processati:\nEvita di modificare accidentalmente i dati originali, garantendo riproducibilità.\n\n4. Importazione ed esportazione dei dati\n\n\nPacchetti per importazione/esportazione:\n\n\nrio: unifica funzioni di import/export\n\n\nreadr: specifico per CSV e altri formati di testo\n\n\nhere: gestisce percorsi relativi\n\n\n\nEsempio di codice per importare dati CSV:\nlibrary(here)\nlibrary(rio)\ndf &lt;- rio::import(here(\"data\", \"raw\", \"my_data.csv\"))\n\n\nEsportare dati modificati:\nrio::export(df, here(\"data\", \"processed\", \"my_data_processed.csv\"))\n\n\n5. Pulizia e preprocessing dei dati\n\n\nDifferenza tra pulizia e preprocessing:\n\nPulizia: rimozione di errori, gestione dei dati mancanti, formattazione\n\nPreprocessing: trasformazione dei dati per adattarli a modelli specifici\n\n\n\nStrumenti di dplyr per pulizia e trasformazione:\n\n\nmutate(), filter(), select(), rename(), relocate()\n\n\n\n\n6. Analisi esplorativa dei dati (EDA)\n\n\nStrumenti comuni:\n\n\nsummary(), str(), glimpse(), ggplot2 per visualizzazione\n\n\n\nEsempio di codice per statistiche descrittive:\nsummary(df)\n\n\n7. Riproducibilità e comunicazione dei risultati\n\n\nImportanza della riproducibilità:\n\nFacilita la verifica e il miglioramento degli studi\n\nPreviene errori accidentali\n\nConsente a terzi di replicare e costruire su ricerche precedenti\n\n\n\nStrumenti di Quarto:\n\nPermette di combinare testo, codice e output in documenti riproducibili\n\nSupporta citazioni automatiche e gestione delle bibliografie",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "title": "13  Le fasi del progetto di analisi dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#bibliografia",
    "href": "chapters/eda/01_project_structure.html#bibliografia",
    "title": "13  Le fasi del progetto di analisi dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBerkun, S. (2005). The art of project management. O’reilly Sebastopol.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nGillespie, C., & Lovelace, R. (2016). Efficient R programming. O’Reilly Media, Incorporated.\n\n\nKruchten, P., Nord, R. L., & Ozkaya, I. (2012). Technical debt: From metaphor to theory and practice. Ieee software, 29(6), 18–21.\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html",
    "href": "chapters/eda/02_data_cleaning.html",
    "title": "14  Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "14.1 Introduzione\nNonostante la fase più interessante di un progetto di analisi dei dati sia quella in cui si riesce a rispondere alla domanda che ha dato avvio all’indagine, gran parte del tempo di un analista è in realtà dedicata a una fase preliminare: la pulizia e il preprocessing dei dati, operazioni che vengono svolte ancor prima dell’analisi esplorativa.\nIn questo capitolo, esamineremo un caso concreto di data cleaning e preprocessing, seguendo il tutorial di Crystal Lewis. Il problema viene presentato come segue:\nCrystal Lewis elenca i seguenti passaggi da seguire nel processo di data cleaning:\nSebbene l’ordine di questi passaggi sia flessibile e possa essere adattato alle esigenze specifiche, c’è un passaggio che non dovrebbe mai essere saltato: il primo, ovvero la revisione dei dati. Senza una revisione preliminare, l’analista rischia di sprecare ore a pulire i dati per poi scoprire che mancano dei partecipanti, che i dati non sono organizzati come previsto o, peggio ancora, che si sta lavorando con i dati sbagliati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#introduzione",
    "href": "chapters/eda/02_data_cleaning.html#introduzione",
    "title": "14  Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "I am managing data for a longitudinal randomized controlled trial (RCT) study. For this RCT, schools are randomized to either a treatment or control group. Students who are in a treatment school receive a program to boost their math self-efficacy. Data is collected on all students in two waves (wave 1 is in the fall of a school year, and wave 2 is collected in the spring). At this point in time, we have collected wave 1 of our student survey on a paper form and we set up a data entry database for staff to enter the information into. Data has been double-entered, checked for entry errors, and has been exported in a csv format (“w1_mathproj_stu_svy_raw.csv”) to a folder (called “data”) where it is waiting to be cleaned.\n\n\n\nRevisione dei dati.\nRegolazione del numero di casi.\nDe-identificazione dei dati.\nEliminazione delle colonne irrilevanti.\nDivisione delle colonne, se necessario.\nRidenominazione delle variabili.\nTrasformazione/normalizzazione delle variabili.\nStandardizzazione delle variabili.\nAggiornamento dei tipi di variabili, se necessario.\nRicodifica delle variabili.\nCreazione di eventuali variabili necessarie.\nGestione dei valori mancanti, se necessario.\nAggiunta di metadati, se necessario.\nValidazione dei dati.\nFusione e/o unione dei dati, se necessario.\nTrasformazione dei dati, se necessario.\nSalvataggio dei dati puliti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#tutorial",
    "href": "chapters/eda/02_data_cleaning.html#tutorial",
    "title": "14  Flusso di lavoro per la pulizia dei dati",
    "section": "\n14.2 Tutorial",
    "text": "14.2 Tutorial\nQuesto tutorial segue i passaggi descritti da Crystal Lewis per illustrare le buone pratiche nella gestione e pulizia dei dati.\n\n14.2.1 Organizzazione dei Dati\nUn principio fondamentale nella gestione dei dati è preservare l’integrità dei dati grezzi. I dati originali non devono mai essere modificati direttamente. È quindi consigliabile strutturare i dati in una directory denominata data, suddivisa in due sottocartelle:\n\n\nraw: contiene i dati originali, mantenuti inalterati.\n\n\nprocessed: destinata ai dati ripuliti e preprocessati.\n\nAd esempio, importiamo i dati da un file denominato w1_mathproj_stu_svy_raw.csv per avviare il processo di pulizia. Tutte le operazioni dovranno essere effettuate utilizzando percorsi relativi alla home directory del progetto, che definiremo come primo passo.\n\n14.2.2 Passaggi del Tutorial\n\n14.2.2.1 Importare e Esaminare i Dati\nImportiamo i dati utilizzando la funzione import() della libreria rio e visualizziamo i primi valori di ciascuna colonna per verificarne la corretta importazione:\n\n# Importa i dati\nsvy &lt;- rio::import(here::here(\"data\", \"w1_mathproj_stu_svy_raw.csv\"))\n\n# Esamina la struttura del dataset\nglimpse(svy)\n#&gt; Rows: 6\n#&gt; Columns: 7\n#&gt; $ stu_id      &lt;int&gt; 1347, 1368, 1377, 1387, 1347, 1399\n#&gt; $ svy_date    &lt;IDate&gt; 2023-02-13, 2023-02-13, 2023-02-13, 2023-02-13, 2023-0…\n#&gt; $ grade_level &lt;int&gt; 9, 10, 9, 11, 9, 12\n#&gt; $ math1       &lt;int&gt; 2, 3, 4, 3, 2, 4\n#&gt; $ math2       &lt;chr&gt; \"1\", \"2\", \"\\n4\", \"3\", \"2\", \"1\"\n#&gt; $ math3       &lt;int&gt; 3, 2, 4, NA, 4, 3\n#&gt; $ math4       &lt;int&gt; 3, 2, 4, NA, 2, 1\n\nPer controllare visivamente i dati, possiamo esaminare le prime e le ultime righe del data frame:\n\n# Visualizza le prime righe\nsvy |&gt; \n  head()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n# Visualizza le ultime righe\nsvy |&gt; \n  tail()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n\n14.2.2.2 Individuare e Rimuovere i Duplicati\nIn questa fase, eseguiamo alcune modifiche necessarie al data frame, come rimuovere duplicati e ordinare i dati:\n\n\nVerifica duplicati: controlliamo i record duplicati nel dataset.\n\nRimuovi duplicati: manteniamo solo la prima occorrenza.\n\nOrdina per data: organizziamo i record in ordine crescente rispetto alla variabile svy_date.\n\nEsamina i dati puliti: controlliamo il risultato delle modifiche.\n\n\n# Identifica i duplicati basati su 'stu_id'\nduplicates &lt;- \n  svy[duplicated(svy$stu_id) | duplicated(svy$stu_id, fromLast = TRUE), ]\n\n\n# Visualizza i duplicati trovati\nduplicates\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n\n\n# Ordina per 'svy_date' in ordine crescente\nsvy &lt;- svy[order(svy$svy_date), ]\n\n\n# Rimuove i duplicati mantenendo la prima occorrenza\nsvy &lt;- svy[!duplicated(svy$stu_id), ]\n\n\n# Esamina il dataset finale\nprint(svy)\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\nVerifichiamo le dimensioni del dataset pulito per assicurarci che le operazioni siano state eseguite correttamente:\n\n# Controlla il numero di righe e colonne\nsvy |&gt; \n  dim()\n#&gt; [1] 5 7\n\n\n14.2.2.3 De-identificazione dei Dati\n\n# Rimuovi la colonna 'svy_date'\nsvy &lt;- svy |&gt;\n  dplyr::select(-svy_date)\n\n# Mostra i nomi delle colonne rimaste\nnames(svy)\n#&gt; [1] \"stu_id\"      \"grade_level\" \"math1\"       \"math2\"       \"math3\"      \n#&gt; [6] \"math4\"\n\n\n14.2.2.4 Rimuovere le Colonne non Necessarie\nNel caso presente, la rimozione di colonne non è necessaria. Tuttavia, in molti progetti di analisi dei dati, soprattutto quando i dati vengono raccolti utilizzando software di terze parti o strumenti specifici per esperimenti psicologici, è comune trovarsi con colonne che non sono pertinenti allo studio in corso.\nQueste colonne possono includere dati come identificatori interni, timestamp generati automaticamente, informazioni di debug, o variabili che non sono rilevanti per l’analisi che si intende condurre. Quando tali colonne sono irrilevanti per la ricerca, possono essere rimosse per semplificare il dataset e ridurre il rischio di confusione o errori durante l’analisi. Rimuovere le colonne non necessarie non solo rende il dataset più gestibile, ma aiuta anche a focalizzare l’analisi sulle variabili che realmente importano per rispondere alle domande di ricerca.\n\n14.2.2.5 Dividere le Colonne Secondo Necessità\nNel caso presente, questa operazione non è necessaria. Tuttavia, se si lavora con un dataset che include una colonna chiamata “NomeCompleto”, contenente sia il nome che il cognome di uno studente, per esempio, è buona pratica separare questa colonna in due colonne distinte, “Nome” e “Cognome”. Questa suddivisione facilita l’analisi e la manipolazione dei dati, rendendoli più organizzati e accessibili.\n\n14.2.2.6 Rinominare le Colonne\nÈ importante assegnare nomi chiari alle colonne del dataset. Utilizzare nomi di variabili comprensibili aiuta a rendere l’analisi dei dati più intuitiva e a ridurre il rischio di errori interpretativi.\nEsempi di buone pratiche:\n\nEvita nomi di colonne come “x” o acronimi incomprensibili. Questi possono creare confusione durante l’analisi, specialmente se il dataset viene condiviso con altri ricercatori o se viene ripreso dopo un lungo periodo di tempo.\nInvece, cerca di utilizzare nomi di variabili che descrivano chiaramente il contenuto della colonna. Ad esempio, invece di “x1” o “VAR123”, un nome come “ansia_base” o “liv_autoefficacia” è molto più comprensibile e immediato.\nPer i nomi composti, utilizza un separatore come il trattino basso _. Ad esempio, se stai lavorando con dati relativi a un test psicologico, potresti avere colonne chiamate “test_ansia_pre” e “test_ansia_post” per indicare i risultati del test di ansia prima e dopo un intervento.\n\nEsempi di nomi di colonne ben scelti:\n\n\nNome generico: TS, AE\n\n\nNome migliore: tempo_studio, auto_efficacia\n\n\n\n\nNome generico: S1, S2\n\n\nNome migliore: stress_situazione1, stress_situazione2\n\n\n\n\nNome generico: Q1, Q2\n\n\nNome migliore: qualità_sonno_sett1, qualità_sonno_sett2\n\n\n\n\n14.2.2.7 Trasformare le Variabili\nNel caso presente non si applica, ma è un passo importante in molte analisi dei dati.\nEsempi di trasformazione delle variabili:\n\nLogaritmo di una variabile: Immaginiamo di avere una variabile che misura i tempi di reazione dei partecipanti a un esperimento. Se i tempi di reazione hanno una distribuzione fortemente asimmetrica (con alcuni valori molto elevati), potrebbe essere utile applicare una trasformazione logaritmica per rendere la distribuzione più simmetrica e migliorare l’interpretabilità dei risultati.\nCodifica delle variabili categoriche: Se è presente una variabile categorica come il “tipo di intervento” con valori come “cognitivo”, “comportamentale” e “farmacologico”, potrebbe essere necessario trasformare questa variabile in variabili dummy (ad esempio, intervento_cognitivo, intervento_comportamentale, intervento_farmacologico), dove ogni variabile assume il valore 0 o 1 a seconda della presenza o meno di quel tipo di intervento. Questo è utile quando si utilizzano tecniche di regressione.\n\n14.2.2.8 Standardizzazione delle Variabili\nLa standardizzazione è utile quando si desidera rendere comparabili variabili misurate su scale diverse, ad esempio per confronti tra gruppi o per inclusione in modelli di regressione.\nEsempio. Supponiamo di avere una variabile che misura il livello di ansia su una scala da 0 a 100. Per standardizzarla:\n\n\nSottrai la media del campione dalla variabile.\n\n\nDividi per la deviazione standard.\n\nIl risultato è una variabile con media pari a 0 e deviazione standard pari a 1.\nVantaggi della standardizzazione:\n\nfacilita l’interpretazione dei coefficienti in un modello di regressione;\npermette un confronto diretto tra variabili che hanno unità di misura diverse.\n\n14.2.2.9 Normalizzazione delle Variabili\n\nLa normalizzazione consiste nel ridimensionare i dati su una scala predefinita, spesso compresa tra 0 e 1. Questo processo è particolarmente utile in analisi multivariate, dove variabili con scale molto diverse potrebbero influenzare in modo sproporzionato i risultati.\nEsempio. Hai dati su:\n\n\nOre di sonno (misurate in ore, da 0 a 24).\n\n\nLivello di stress (misurato su una scala da 1 a 50).\n\n\nAuto-efficacia (misurata su una scala da 0 a 100).\n\nPer garantire che ogni variabile abbia lo stesso peso nell’analisi, puoi normalizzarle usando una formula come:\n\\[\nx_{\\text{norm}} = \\frac{x - \\text{min}(x)}{\\text{max}(x) - \\text{min}(x)} .\n\\]\nPerché Standardizzare o Normalizzare?\nTrasformare le variabili è cruciale per:\n\n\nGestire scale diverse: Riduce il rischio che variabili con valori numericamente più grandi dominino i risultati.\n\n\nGarantire validità e interpretabilità: Facilita il confronto tra dati provenienti da fonti o gruppi diversi.\n\n\nEvitare problemi numerici nei modelli statistici: Alcuni algoritmi di machine learning o tecniche di ottimizzazione richiedono che i dati siano su scale simili per funzionare correttamente.\n\nIn conclusione, la scelta tra standardizzazione e normalizzazione dipende dal contesto dell’analisi e dagli obiettivi specifici. Entrambi i processi sono strumenti indispensabili per garantire che i dati siano trattati in modo adeguato, portando a risultati robusti e facilmente interpretabili.\n\n14.2.2.10 Aggiornare i Tipi delle Variabili\nNel caso presente non è necessario. Supponiamo invece di avere una colonna in un dataset psicologico che contiene punteggi di un questionario, ma i dati sono stati importati come stringhe (testo) invece che come numeri. Per eseguire calcoli statistici, sarà necessario convertire questa colonna da stringa a numerico.\nIn R, si potrebbe usare il seguente codice:\n\n# Supponiamo di avere un data frame chiamato 'df' con una colonna 'punteggio' importata come carattere\ndf$punteggio &lt;- as.numeric(df$punteggio)\n\n# Ora la colonna 'punteggio' è stata convertita in un tipo numerico ed è possibile eseguire calcoli su di essa\n\nIn questo esempio, la funzione as.numeric() viene utilizzata per convertire la colonna punteggio in un formato numerico, permettendo di eseguire analisi quantitative sui dati.\nUn altro caso molto comune si verifica quando si importano dati da file Excel. Spesso capita che, all’interno di una cella di una colonna che dovrebbe contenere solo valori numerici, venga inserito erroneamente uno o più caratteri alfanumerici. Di conseguenza, l’intera colonna viene interpretata come di tipo alfanumerico, anche se i valori dovrebbero essere numerici. In questi casi, è fondamentale individuare la cella problematica, correggere manualmente il valore errato, e poi riconvertire l’intera colonna da alfanumerica a numerica.\n\n14.2.2.11 Ricodificare le Variabili\nAnche se in questo caso non è necessario, la ricodifica delle variabili è una pratica molto comune nelle analisi dei dati psicologici.\nPer esempio, consideriamo una variabile categoriale con modalità descritte da stringhe poco comprensibili, che vengono ricodificate con nomi più chiari e comprensibili.\nSupponiamo di avere un DataFrame chiamato df con una colonna tipo_intervento che contiene le modalità \"CT\", \"BT\", e \"MT\" per rappresentare rispettivamente “Terapia Cognitiva”, “Terapia Comportamentale” e “Terapia Mista”. Queste abbreviazioni potrebbero non essere immediatamente chiare a chiunque analizzi i dati, quindi decidiamo di ricodificarle con nomi più espliciti. Ecco come farlo in R:\n\n# Tibble chiamato 'df' con una colonna 'tipo_intervento'\ndf &lt;- tibble(tipo_intervento = c(\"CT\", \"BT\", \"MT\", \"CT\", \"BT\"))\ndf\n#&gt; # A tibble: 5 × 1\n#&gt;   tipo_intervento\n#&gt;   &lt;chr&gt;          \n#&gt; 1 CT             \n#&gt; 2 BT             \n#&gt; 3 MT             \n#&gt; 4 CT             \n#&gt; 5 BT\n\n\n# Ricodifica delle modalità della variabile 'tipo_intervento' in nomi più comprensibili\ndf &lt;- df %&gt;%\n  mutate(tipo_intervento_ricodificato = dplyr::recode(\n    tipo_intervento,\n    \"CT\" = \"Terapia Cognitiva\",\n    \"BT\" = \"Terapia Comportamentale\",\n    \"MT\" = \"Terapia Mista\"\n  ))\n\n# Mostra il tibble con la nuova colonna ricodificata\ndf\n#&gt; # A tibble: 5 × 2\n#&gt;   tipo_intervento tipo_intervento_ricodificato\n#&gt;   &lt;chr&gt;           &lt;chr&gt;                       \n#&gt; 1 CT              Terapia Cognitiva           \n#&gt; 2 BT              Terapia Comportamentale     \n#&gt; 3 MT              Terapia Mista               \n#&gt; 4 CT              Terapia Cognitiva           \n#&gt; 5 BT              Terapia Comportamentale\n\n\n14.2.2.12 Aggiungere Nuove Variabili nel Data Frame\nNel caso presente non è richiesto, ma aggiungere nuove variabili a un DataFrame è un’operazione comune durante l’analisi dei dati. Un esempio è il calcolo dell’indice di massa corporea (BMI).\nSupponiamo di avere un DataFrame chiamato df che contiene le colonne peso_kg (peso in chilogrammi) e altezza_m (altezza in metri) per ciascun partecipante a uno studio psicologico. Per arricchire il dataset, possiamo calcolare il BMI per ogni partecipante e aggiungerlo come una nuova variabile.\nIl BMI si calcola con la formula:\n\\[ \\text{BMI} = \\frac{\\text{peso in kg}}{\\text{altezza in metri}^2} .\\]\nEcco come aggiungere la nuova colonna.\n\n# Supponiamo di avere un tibble chiamato 'df' con le colonne 'peso_kg' e 'altezza_m'\ndf &lt;- tibble(\n  peso_kg = c(70, 85, 60, 95),\n  altezza_m = c(1.75, 1.80, 1.65, 1.90)\n)\ndf\n#&gt; # A tibble: 4 × 2\n#&gt;   peso_kg altezza_m\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1      70      1.75\n#&gt; 2      85      1.8 \n#&gt; 3      60      1.65\n#&gt; 4      95      1.9\n\n\n# Calcola il BMI e aggiungilo come una nuova colonna 'BMI'\ndf &lt;- df %&gt;%\n  mutate(BMI = peso_kg / (altezza_m^2))\n\n# Mostra il tibble con la nuova variabile aggiunta\ndf\n#&gt; # A tibble: 4 × 3\n#&gt;   peso_kg altezza_m   BMI\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1      70      1.75  22.9\n#&gt; 2      85      1.8   26.2\n#&gt; 3      60      1.65  22.0\n#&gt; 4      95      1.9   26.3\n\n\n14.2.3 Affrontare il Problema dei Dati Mancanti\nI dati mancanti sono un problema comune nelle ricerche psicologiche e in molte altre discipline. Quando mancano delle informazioni in un dataset, possono verificarsi gravi problemi per l’analisi statistica, come risultati distorti, riduzione della precisione delle stime o, in alcuni casi, l’impossibilità di applicare alcuni algoritmi.\n\n14.2.3.1 Perché i Dati Mancanti Sono un Problema?\nImmagina di voler capire il rendimento medio di una classe in un test, ma alcuni studenti hanno lasciato delle risposte in bianco. Se ignoriamo le risposte mancanti o eliminiamo gli studenti con dati incompleti, rischiamo di ottenere una stima che non rappresenta correttamente la realtà. Questo succede perché:\n\n\nBias dei risultati: Se i dati mancanti non sono casuali (ad esempio, i dati mancanti sono presenti più spesso in studenti con basso rendimento), le conclusioni possono essere errate.\n\nRiduzione della potenza statistica: Eliminare dati incompleti riduce il numero totale di osservazioni, rendendo più difficile trovare risultati significativi.\n\nImpossibilità di applicare alcuni metodi: Molti algoritmi statistici richiedono dati completi e non funzionano con valori mancanti.\n\n14.2.3.2 Come Gestire i Dati Mancanti?\nCi sono diversi modi per affrontare i dati mancanti. Vediamo prima i metodi più semplici e poi quelli più avanzati.\nEsaminiamo il data frame iniziale:\n\nsvy |&gt; \n  summary()\n#&gt;      stu_id      grade_level       math1        math2          \n#&gt;  Min.   :1347   Min.   : 9.0   Min.   :2.0   Length:5          \n#&gt;  1st Qu.:1368   1st Qu.: 9.0   1st Qu.:3.0   Class :character  \n#&gt;  Median :1377   Median :10.0   Median :3.0   Mode  :character  \n#&gt;  Mean   :1376   Mean   :10.2   Mean   :3.2                     \n#&gt;  3rd Qu.:1387   3rd Qu.:11.0   3rd Qu.:4.0                     \n#&gt;  Max.   :1399   Max.   :12.0   Max.   :4.0                     \n#&gt;                                                                \n#&gt;      math3          math4     \n#&gt;  Min.   :2.00   Min.   :1.00  \n#&gt;  1st Qu.:2.75   1st Qu.:1.75  \n#&gt;  Median :3.00   Median :2.50  \n#&gt;  Mean   :3.00   Mean   :2.50  \n#&gt;  3rd Qu.:3.25   3rd Qu.:3.25  \n#&gt;  Max.   :4.00   Max.   :4.00  \n#&gt;  NA's   :1      NA's   :1\n\nSi noti la presenza di dati mancanti sulle variabili math3 e math4.\n\ndim(svy)\n#&gt; [1] 5 6\n\n\n\nEsclusione dei Casi Incompleti (Complete Case Analysis).\nUn approccio comune, ma spesso non ideale, è quello di analizzare solo i casi completi, eliminando tutte le righe con valori mancanti. In R, questo si può fare con il seguente comando:\n\nsvy_comp &lt;- svy |&gt;\n  drop_na()\n\nIn questo modo abbiamo escluso tutte le righe nelle quali sono presenti dei dati mancanti (in questo caso, una sola riga).\n\ndim(svy_comp)\n#&gt; [1] 4 6\n\nLimite: Questo metodo può introdurre bias se i dati mancanti non sono casuali e riduce il campione, compromettendo l’affidabilità delle analisi.\n\n\nImputazione Semplice\nSostituire i valori mancanti con stime semplici:\n\n\nMedia o mediana: Per le variabili numeriche, sostituire i valori mancanti con la media o la mediana. Questo metodo è facile da implementare, ma può ridurre la variabilità nei dati.\n\nModa: Per le variabili categoriche, sostituire i valori mancanti con il valore più frequente. Tuttavia, può introdurre distorsioni se i dati sono molto eterogenei.\n\n\n\nImputazione Multipla\nUn approccio più avanzato è l’imputazione multipla, che utilizza modelli statistici per stimare i valori mancanti in modo iterativo. L’idea di base è semplice: ogni valore mancante viene stimato tenendo conto delle relazioni con tutte le altre variabili.\nVantaggi:\n\nMantiene la variabilità dei dati.\nPreserva le relazioni tra le variabili.\nRiduce il rischio di bias rispetto ai metodi semplici.\n\n\n\n14.2.3.3 Applicazione Pratica: Imputazione Multipla con mice in R\nSupponiamo di avere un dataset con alcune colonne numeriche che contengono valori mancanti. Possiamo utilizzare il pacchetto mice per imputare i dati mancanti.\nSelezioniamo le colonne numeriche da imputare.\n\nnumeric_columns &lt;- c(\"math1\", \"math2\", \"math3\", \"math4\")\nsvy &lt;- svy %&gt;%\n  mutate(across(all_of(numeric_columns), as.numeric))\n\nEseguiamo l’imputazione multipla.\n\nimputed &lt;- mice(\n  svy[numeric_columns], \n  m = 1, \n  maxit = 10, \n  method = \"norm.predict\", \n  seed = 123\n)\n#&gt; \n#&gt;  iter imp variable\n#&gt;   1   1  math3  math4\n#&gt;   2   1  math3  math4\n#&gt;   3   1  math3  math4\n#&gt;   4   1  math3  math4\n#&gt;   5   1  math3  math4\n#&gt;   6   1  math3  math4\n#&gt;   7   1  math3  math4\n#&gt;   8   1  math3  math4\n#&gt;   9   1  math3  math4\n#&gt;   10   1  math3  math4\n\nOttieniamo il dataset con i valori imputati.\n\nsvy_imputed &lt;- complete(imputed)\n\nArrotondiamo i valori imputati (se necessario).\n\nsvy_imputed &lt;- svy_imputed %&gt;%\n  mutate(across(everything(), round))\n\nSostituiamo i valori imputati nel dataset originale.\n\nsvy[numeric_columns] &lt;- svy_imputed\n\nEsaminiamo il risultato ottenuto.\n\nsvy |&gt; \n  summary()\n#&gt;      stu_id      grade_level       math1         math2         math3    \n#&gt;  Min.   :1347   Min.   : 9.0   Min.   :2.0   Min.   :1.0   Min.   :2.0  \n#&gt;  1st Qu.:1368   1st Qu.: 9.0   1st Qu.:3.0   1st Qu.:1.0   1st Qu.:3.0  \n#&gt;  Median :1377   Median :10.0   Median :3.0   Median :2.0   Median :3.0  \n#&gt;  Mean   :1376   Mean   :10.2   Mean   :3.2   Mean   :2.2   Mean   :3.2  \n#&gt;  3rd Qu.:1387   3rd Qu.:11.0   3rd Qu.:4.0   3rd Qu.:3.0   3rd Qu.:4.0  \n#&gt;  Max.   :1399   Max.   :12.0   Max.   :4.0   Max.   :4.0   Max.   :4.0  \n#&gt;      math4    \n#&gt;  Min.   :1.0  \n#&gt;  1st Qu.:2.0  \n#&gt;  Median :3.0  \n#&gt;  Mean   :2.8  \n#&gt;  3rd Qu.:4.0  \n#&gt;  Max.   :4.0\n\n\n14.2.3.4 Come Funziona l’Imputazione Multipla?\n\nOgni variabile con valori mancanti viene modellata come funzione delle altre variabili.\nI valori mancanti vengono stimati iterativamente. In ogni iterazione, si utilizza l’output precedente come input per migliorare le stime.\nDopo un numero sufficiente di iterazioni, le stime si stabilizzano (convergenza).\n\nIn conclusione, l’imputazione multipla è una tecnica avanzata che permette di gestire i dati mancanti preservando la qualità delle analisi. Rispetto ai metodi semplici, consente di mantenere la variabilità e ridurre il rischio di bias, rendendola una scelta ideale per analisi psicologiche e di ricerca.\n\n14.2.3.5 Aggiungere i Metadati\nI metadati sono informazioni che descrivono i dati stessi, come etichette di variabili, etichette di valori, informazioni sull’origine dei dati, unità di misura e altro ancora. Questi metadati sono essenziali per comprendere, documentare e condividere correttamente un dataset.\nIn R, i metadati sono gestiti in modo molto dettagliato e strutturato attraverso pacchetti come haven, labelled, e Hmisc. Questi pacchetti consentono di associare etichette ai dati, come etichette di variabili e di valori, e persino di gestire i valori mancanti con etichette specifiche.\n\n\nEtichette di variabili: Si possono aggiungere direttamente alle colonne di un DataFrame usando funzioni come labelled::set_variable_labels().\n\nEtichette di valori: Possono essere aggiunte a variabili categoriali utilizzando labelled::labelled().\n\nValori mancanti: In R, è possibile etichettare specifici valori come mancanti usando labelled::na_values&lt;-.\n\nQuesti strumenti rendono molto facile documentare un dataset all’interno del processo di analisi, assicurando che tutte le informazioni critiche sui dati siano facilmente accessibili e ben documentate.\nEsaminiamo un esempio pratico. Consideriamo nuovamente il data set svy:\n\nglimpse(svy)\n#&gt; Rows: 5\n#&gt; Columns: 6\n#&gt; $ stu_id      &lt;int&gt; 1347, 1368, 1377, 1387, 1399\n#&gt; $ grade_level &lt;int&gt; 9, 10, 9, 11, 12\n#&gt; $ math1       &lt;dbl&gt; 2, 3, 4, 3, 4\n#&gt; $ math2       &lt;dbl&gt; 1, 2, 4, 3, 1\n#&gt; $ math3       &lt;dbl&gt; 3, 2, 4, 4, 3\n#&gt; $ math4       &lt;dbl&gt; 3, 2, 4, 4, 1\n\nSi noti che la variabile math2 contiene un valore inamissibile, probabilmente un errore di battitura. Questo fa in modo che math2 sia di tipo char mentre dovrebbe essere una variabile numerica. Correggiamo.\n\n# Correzione di `math2`: Rimuovi valori non validi e converti in numerico\nsvy$math2 &lt;- gsub(\"\\\\n\", \"\", svy$math2)  # Rimuovi caratteri non validi come '\\n'\nsvy$math2 &lt;- as.numeric(svy$math2)      # Converte la variabile in numerico\n\n# Visualizzazione del dataset corretto\nprint(svy)\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\nDefiniamo le etichette di valore per le variabili math1:math4.\n\nvalue_labels_math &lt;- set_names(\n  as.numeric(names(c(\n    `1` = \"strongly disagree\",\n    `2` = \"disagree\",\n    `3` = \"agree\",\n    `4` = \"strongly agree\"\n  ))),\n  c(\"strongly disagree\", \"disagree\", \"agree\", \"strongly agree\")\n)\n\nAggiungiamo le etichette di valore alle colonne math1:math4.\n\nsvy &lt;- svy %&gt;%\n  mutate(across(starts_with(\"math\"), ~ labelled(., labels = value_labels_math)))\n\nVerifica delle etichette.\n\nval_labels(svy$math1)\n#&gt; strongly disagree          disagree             agree    strongly agree \n#&gt;                 1                 2                 3                 4\n\n\nsvy\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\n\n14.2.3.5.1 Utilizzo delle Etichette in R con Variabili Numeriche\nLe etichette dei valori (value labels) vengono utilizzate per rendere più leggibili e interpretabili le variabili numeriche, associando ad ogni valore un’etichetta descrittiva. Questo approccio è particolarmente utile in ambiti come la ricerca psicologica, dove le risposte ai questionari sono spesso codificate con numeri (ad esempio, 1 = “Strongly Disagree”, 2 = “Disagree”, ecc.) ma rappresentano concetti qualitativi.\nVantaggi dell’Uso delle Etichette\n\n\nChiarezza nelle Analisi: Le etichette descrittive rendono i dati più facilmente comprensibili senza dover ricordare il significato numerico di ciascun valore.\n\n\nDocumentazione Integrata: Permettono di incorporare metadati direttamente nelle variabili, migliorando la trasparenza e riducendo il rischio di interpretazioni errate.\n\nCompatibilità con Software Statistici: Molti strumenti (ad esempio, SPSS o Stata) utilizzano etichette di valori. Il pacchetto haven in R consente di gestire facilmente i dati etichettati esportati/importati da questi software.\n\nManipolazione di Variabili Etichettate\nAnche se una variabile numerica è etichettata con labelled (ad esempio, tramite il pacchetto haven), essa conserva la sua natura numerica e può essere utilizzata in calcoli, modelli statistici, e trasformazioni. Le etichette non alterano il valore sottostante, ma lo arricchiscono con informazioni aggiuntive.\nIn conclusione, le etichette dei valori migliorano l’interpretabilità dei dati senza comprometterne la manipolabilità. Questo approccio è ideale per mantenere le variabili numeriche pienamente funzionali per analisi statistiche, mentre le etichette descrittive forniscono un contesto chiaro e leggibile.\n\n14.2.3.6 Validazione dei Dati\nLa validazione dei dati è un passaggio fondamentale per garantire che il dataset soddisfi i criteri previsti e sia pronto per le analisi successive. Questo processo include il controllo della coerenza e della correttezza dei dati in base a specifiche regole definite dal dizionario dei dati. Alcune verifiche comuni includono:\n\n\nUnicità delle righe: Assicurarsi che ogni riga sia unica, verificando l’assenza di ID duplicati.\n\nValidità degli ID: Controllare che gli ID rientrino in un intervallo previsto (es. numerico).\n\nValori accettabili nelle variabili categoriali: Verificare che variabili come grade_level, int e le colonne math contengano esclusivamente valori appartenenti a un set di valori validi.\n\nIl pacchetto pointblank fornisce strumenti flessibili e intuitivi per eseguire verifiche di validazione e generare report dettagliati. Questo pacchetto consente di:\n\n\nDefinire le regole di validazione: Specificare controlli come unicità, intervalli di valori e appartenenza a insiemi predefiniti.\n\nEseguire i controlli: Applicare le regole di validazione su un dataset per identificare eventuali discrepanze.\n\nGenerare report interattivi: Creare un riepilogo chiaro e visivo dei controlli, evidenziando eventuali errori o anomalie.\n\nCon pointblank, è possibile integrare la validazione dei dati come parte di un workflow strutturato, garantendo la qualità dei dati in modo sistematico e ripetibile.\n\ncreate_agent(svy) %&gt;%\n  rows_distinct(columns = vars(stu_id)) %&gt;%\n  col_vals_between(columns = c(stu_id), \n                   left = 1300, right = 1400, na_pass = TRUE) %&gt;%\n  col_vals_in_set(columns = c(grade_level), \n                  set = c(9, 10, 11, 12, NA)) %&gt;%\n  col_vals_in_set(columns = c(int),\n                  set = c(0, 1, NA)) %&gt;%\n  col_vals_in_set(columns = c(math1:math4),\n                  set = c(1, 2, 3, 4, NA)) %&gt;%\n  interrogate()\n\n\n\n\n\n\nPointblank Validation\n\n\n\n\n[2025-02-22|11:11:59]\n\n\ndata frame svy\n\n\n\n\n\n\nSTEP\nCOLUMNS\nVALUES\nTBL\nEVAL\nUNITS\nPASS\nFAIL\nW\nS\nN\nEXT\n\n\n\n\n\n1\n\n\n\nrows_distinct\n\n\n\n rows_distinct()\n\n\n▮stu_id\n\n—\n\n\n✓\n5\n\n51\n\n\n00\n\n—\n—\n—\n—\n\n\n\n2\n\n\n\ncol_vals_between\n\n\n\n col_vals_between()\n\n\n▮stu_id\n\n\n[1,300, 1,400]\n\n\n\n✓\n5\n\n51\n\n\n00\n\n—\n—\n—\n—\n\n\n\n3\n\n\n\ncol_vals_in_set\n\n\n\n col_vals_in_set()\n\n\n▮grade_level\n\n\n9, 10, 11, 12, NA\n\n\n\n✓\n5\n\n51\n\n\n00\n\n—\n—\n—\n—\n\n\n\n4\n\n\n\ncol_vals_in_set\n\n\n\n col_vals_in_set()\n\n\n▮int\n\n\n0, 1, NA\n\n\n\n💥\n—\n—\n—\n—\n—\n—\n—\n\n\n\n5\n\n\n\ncol_vals_in_set\n\n\n\n col_vals_in_set()\n\n\n▮math1\n\n\n1, 2, 3, 4, NA\n\n\n\n✓\n5\n\n51\n\n\n00\n\n—\n—\n—\n—\n\n\n\n6\n\n\n\ncol_vals_in_set\n\n\n\n col_vals_in_set()\n\n\n▮math2\n\n\n1, 2, 3, 4, NA\n\n\n\n✓\n5\n\n51\n\n\n00\n\n—\n—\n—\n—\n\n\n\n7\n\n\n\ncol_vals_in_set\n\n\n\n col_vals_in_set()\n\n\n▮math3\n\n\n1, 2, 3, 4, NA\n\n\n\n✓\n5\n\n51\n\n\n00\n\n—\n—\n—\n—\n\n\n\n8\n\n\n\ncol_vals_in_set\n\n\n\n col_vals_in_set()\n\n\n▮math4\n\n\n1, 2, 3, 4, NA\n\n\n\n✓\n5\n\n51\n\n\n00\n\n—\n—\n—\n—\n\n\n\n\n2025-02-22 11:11:59 CET &lt; 1 s 2025-02-22 11:11:59 CET\n\n\n\n\n\n\nIl dataset ripulito soddisfa tutte le aspettative delineate da Crystal Lewis.\n\n\nCompleto: Tutti i dati raccolti sono stati inseriti e/o recuperati. Non dovrebbero esserci dati estranei che non appartengono al dataset (come duplicati o partecipanti non autorizzati).\n\nValido: Le variabili rispettano i vincoli definiti nel tuo dizionario dei dati. Ricorda che il dizionario dei dati specifica i nomi delle variabili, i tipi, i range, le categorie e altre informazioni attese.\n\nAccurato: Sebbene non sia sempre possibile determinare l’accuratezza dei valori durante il processo di pulizia dei dati (ovvero, se un valore è realmente corretto o meno), in alcuni casi è possibile valutarla sulla base della conoscenza pregressa riguardante quel partecipante o caso specifico.\n\nCoerente: I valori sono allineati tra le varie fonti. Ad esempio, la data di nascita raccolta attraverso un sondaggio studentesco dovrebbe avere un formato corrispondere alla data di nascita raccolta dal distretto scolastico.\n\nUniforme: I dati sono standardizzati attraverso i moduli e nel tempo. Ad esempio, lo stato di partecipazione ai programmi di pranzo gratuito o a prezzo ridotto è sempre fornito come una variabile numerica con la stessa rappresentazione, oppure il nome della scuola è sempre scritto in modo coerente in tutto il dataset.\n\nDe-identificato: Tutte le informazioni personali identificabili (PII) sono state rimosse dal dataset per proteggere la riservatezza dei partecipanti (se richiesto dal comitato etico/consenso informato).\n\nInterpretabile: I dati hanno nomi di variabili leggibili sia da umani che dal computer, e sono presenti etichette di variabili e valori laddove necessario per facilitare l’interpretazione.\n\nAnalizzabile: Il dataset è in un formato rettangolare (righe e colonne), leggibile dal computer e conforme alle regole di base della struttura dei dati.\n\nUna volta completati i 14 passaggi precedenti, è possibile esportare questo dataset ripulito nella cartella processed per le successive analisi statistiche.\n\n14.2.3.7 Unire e/o aggiungere dati se necessario\nIn questo passaggio, è possibile unire o aggiungere colonne o righe presenti in file diversi. È importante eseguire nuovamente i controlli di validazione dopo l’unione/aggiunta di nuovi dati.\n\n14.2.3.8 Trasformare i dati se necessario\nEsistono vari motivi per cui potrebbe essere utile memorizzare i dati in formato long o wide. In questo passaggio, è possibile ristrutturare i dati secondo le esigenze.\n\n14.2.3.9 Salvare il dataset pulito finale\nL’ultimo passaggio del processo di pulizia consiste nell’esportare o salvare il dataset pulito. Come accennato in precedenza, può essere utile esportare/salvare il dataset in più di un formato di file (ad esempio, un file .csv e un file .parquet).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "href": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "title": "14  Flusso di lavoro per la pulizia dei dati",
    "section": "\n14.3 Organizzazione dei file e informazioni aggiuntive",
    "text": "14.3 Organizzazione dei file e informazioni aggiuntive\nInfine, è essenziale includere una documentazione adeguata per garantire che le informazioni siano interpretate correttamente, sia da altri utenti che da te stesso, se dovessi tornare a lavorare su questo progetto in futuro. La documentazione minima da fornire dovrebbe includere:\n\n\nDocumentazione a livello di progetto: Questa sezione fornisce informazioni contestuali sul perché e come i dati sono stati raccolti. È utile per chiunque voglia comprendere lo scopo e la metodologia del progetto.\n\nMetadati a livello di progetto: Se condividi i dati in un repository pubblico o privato, è importante includere metadati a livello di progetto. Questi metadati forniscono informazioni dettagliate che facilitano la ricerca, la comprensione e la consultabilità dei dati. I metadati a livello di progetto possono includere descrizioni generali del progetto, parole chiave, e riferimenti bibliografici.\n\nDizionario dei dati: Un documento che descrive tutte le variabili presenti nel dataset, inclusi i loro nomi, tipi, range di valori, categorie e qualsiasi altra informazione rilevante. Questo strumento è fondamentale per chiunque voglia comprendere o analizzare i dati.\n\nREADME: Un file che fornisce una panoramica rapida dei file inclusi nel progetto, spiegando cosa contengono e come sono interconnessi. Il README è spesso il primo documento consultato e serve a orientare l’utente tra i vari file e risorse del progetto. Questa documentazione non solo aiuta a mantenere il progetto organizzato, ma è anche cruciale per facilitare la collaborazione e l’archiviazione a lungo termine.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "href": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "title": "14  Flusso di lavoro per la pulizia dei dati",
    "section": "\n14.4 Dizionario dei Dati",
    "text": "14.4 Dizionario dei Dati\nApprofondiamo qui il problema della creazione del Dizionario dei dati.\nUn dizionario dei dati è un documento che descrive le caratteristiche di ciascuna variabile in un dataset. Include informazioni come il nome della variabile, il tipo di dato, il range di valori, le categorie (per le variabili categoriche), e altre informazioni rilevanti. Questo strumento è essenziale per comprendere e analizzare correttamente il dataset.\nSi presti particolare attenzione alle guide di stile per la denominazione delle variabili e la codifica dei valori delle risposte.\n\n14.4.1 Esempio in R\n\nEcco come tradurre i passi per creare un dizionario dei dati in R, utilizzando il pacchetto tibble per creare il dizionario e writexl o readr per esportarlo in formato .xlsx o .csv.\n\n\nIdentificare le variabili: Elencare tutte le variabili presenti nel dataset.\n\nDescrivere ogni variabile: Per ciascuna variabile, definire il tipo (ad esempio, integer, numeric, character), il range di valori accettabili o le categorie, e fornire una descrizione chiara.\n\nSalvare il dizionario dei dati: Il dizionario può essere salvato in un file .csv o .xlsx per una facile consultazione.\n\n\nsvy\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\nCreeremo un dizionario dei dati per un dataset di esempio e lo salveremo sia in formato CSV che Excel.\n\nlibrary(tibble)\nlibrary(readr)\nlibrary(writexl)\n\n# Creazione del Dizionario dei Dati\ndata_dict &lt;- tibble(\n  `Variable Name` = c(\n    \"stu_id\",\n    \"svy_date\",\n    \"grade_level\",\n    \"math1\",\n    \"math2\",\n    \"math3\",\n    \"math4\"\n  ),\n  `Type` = c(\n    \"integer\",\n    \"datetime\",\n    \"integer\",\n    \"integer\",\n    \"integer\",\n    \"numeric\",\n    \"numeric\"\n  ),\n  `Description` = c(\n    \"Student ID\",\n    \"Survey Date\",\n    \"Grade Level\",\n    \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\"\n  ),\n  `Range/Values` = c(\n    \"1347-1399\",\n    \"2023-02-13 to 2023-02-14\",\n    \"9-12\",\n    \"1-4\",\n    \"1-4\",\n    \"1.0-4.0 (NA allowed)\",\n    \"1.0-4.0 (NA allowed)\"\n  )\n)\n\n# Visualizza il Dizionario dei Dati\nprint(data_dict)\n#&gt; # A tibble: 7 × 4\n#&gt;   `Variable Name` Type     Description                       `Range/Values` \n#&gt;   &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;                             &lt;chr&gt;          \n#&gt; 1 stu_id          integer  Student ID                        1347-1399      \n#&gt; 2 svy_date        datetime Survey Date                       2023-02-13 to …\n#&gt; 3 grade_level     integer  Grade Level                       9-12           \n#&gt; 4 math1           integer  Math Response 1 (1: Strongly Dis… 1-4            \n#&gt; 5 math2           integer  Math Response 2 (1: Strongly Dis… 1-4            \n#&gt; 6 math3           numeric  Math Response 3 (1: Strongly Dis… 1.0-4.0 (NA al…\n#&gt; 7 math4           numeric  Math Response 4 (1: Strongly Dis… 1.0-4.0 (NA al…\n\n# Salva il Dizionario dei Dati in un file CSV\nwrite_csv(data_dict, here::here(\"data\", \"processed\", \"data_dictionary.csv\"))\n\n# Salva il Dizionario dei Dati in un file Excel\nwrite_xlsx(data_dict, here::here(\"data\", \"processed\", \"data_dictionary.xlsx\"))\n\nOutput Atteso: file CSV (data_dictionary.csv).\n\ndata_dict &lt;- rio::import(\n  here::here(\"data\", \"processed\", \"data_dictionary.csv\")\n)\n\n\nprint(data_dict)\n#&gt;   Variable Name     Type\n#&gt; 1        stu_id  integer\n#&gt; 2      svy_date datetime\n#&gt; 3   grade_level  integer\n#&gt; 4         math1  integer\n#&gt; 5         math2  integer\n#&gt; 6         math3  numeric\n#&gt; 7         math4  numeric\n#&gt;                                                 Description\n#&gt; 1                                                Student ID\n#&gt; 2                                               Survey Date\n#&gt; 3                                               Grade Level\n#&gt; 4 Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt; 5 Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt; 6 Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt; 7 Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt;               Range/Values\n#&gt; 1                1347-1399\n#&gt; 2 2023-02-13 to 2023-02-14\n#&gt; 3                     9-12\n#&gt; 4                      1-4\n#&gt; 5                      1-4\n#&gt; 6     1.0-4.0 (NA allowed)\n#&gt; 7     1.0-4.0 (NA allowed)\n\n\n14.4.1.1 Uso del pacchetto dataMeta\n\nIl pacchetto dataMeta è progettato per generare metadati e dizionari dei dati in modo strutturato.\n\nlibrary(dataMeta)\nlibrary(tibble)\n\n# Descrizioni delle variabili\nvariable_descriptions &lt;- c(\n  \"Student ID\",\n  \"Grade Level\",\n  \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\"\n)\n\nvar_type &lt;- c(1, 0, 0, 0, 0, 0)\n\nlinker &lt;- build_linker(\n  svy, \n  variable_description = variable_descriptions, \n  variable_type = var_type\n)\n\ndict &lt;- build_dict(\n  my.data = svy, \n  linker = linker, \n  option_description = NULL, \n  prompt_varopts = FALSE\n)\n\nkable(dict, format = \"html\", caption = \"Data dictionary for original dataset\")\n\n\nData dictionary for original dataset\n\nvariable_name\nvariable_description\nvariable_options\n\n\n\ngrade_level\nGrade Level\n9 to 12\n\n\nmath1\nMath Response 1 (1: Strongly Disagree, 4: Strongly Agree)\n2 to 4\n\n\nmath2\nMath Response 2 (1: Strongly Disagree, 4: Strongly Agree)\n1 to 4\n\n\nmath3\nMath Response 3 (1: Strongly Disagree, 4: Strongly Agree)\n2 to 4\n\n\nmath4\nMath Response 4 (1: Strongly Disagree, 4: Strongly Agree)\n1 to 4\n\n\nstu_id\nStudent ID\n1347\n\n\n\n\n1368\n\n\n\n\n1377\n\n\n\n\n1387\n\n\n\n\n1399\n\n\n\n\n\n\n14.4.1.2 Uso del pacchetto skimr\n\nIl pacchetto skimr è utile per generare riassunti dettagliati delle variabili, che possono essere utilizzati come base per un dizionario.\n\nlibrary(skimr)\n\n# Riassunto del dataset\nskim_dict &lt;- skim(svy)\n\nkable(skim_dict, format = \"html\", caption = \"Data dictionary for original dataset\")\n\n\nData dictionary for original dataset\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\nnumeric\nstu_id\n0\n1\n1375.6\n19.7180\n1347\n1368\n1377\n1387\n1399\n▃▁▇▃▃\n\n\nnumeric\ngrade_level\n0\n1\n10.2\n1.3038\n9\n9\n10\n11\n12\n▇▃▁▃▃\n\n\nnumeric\nmath1\n0\n1\n3.2\n0.8367\n2\n3\n3\n4\n4\n▃▁▇▁▇\n\n\nnumeric\nmath2\n0\n1\n2.2\n1.3038\n1\n1\n2\n3\n4\n▇▃▁▃▃\n\n\nnumeric\nmath3\n0\n1\n3.2\n0.8367\n2\n3\n3\n4\n4\n▃▁▇▁▇\n\n\nnumeric\nmath4\n0\n1\n2.8\n1.3038\n1\n2\n3\n4\n4\n▃▃▁▃▇",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "href": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "title": "14  Flusso di lavoro per la pulizia dei dati",
    "section": "\n14.5 Riflessioni Conclusive",
    "text": "14.5 Riflessioni Conclusive\nNel processo di analisi dei dati, la fase di pulizia e pre-elaborazione è cruciale per garantire la qualità e l’integrità dei risultati finali. Sebbene questa fase possa sembrare meno interessante rispetto all’analisi vera e propria, essa costituisce la base su cui si costruiscono tutte le successive elaborazioni e interpretazioni. Attraverso una serie di passaggi strutturati, come quelli illustrati in questo capitolo, è possibile trasformare dati grezzi e disordinati in un dataset pulito, coerente e pronto per l’analisi. La cura nella gestione dei dati, dalla rimozione di duplicati alla creazione di un dizionario dei dati, è fondamentale per ottenere risultati affidabili e riproducibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#esercizi",
    "href": "chapters/eda/02_data_cleaning.html#esercizi",
    "title": "14  Flusso di lavoro per la pulizia dei dati",
    "section": "\n14.6 Esercizi",
    "text": "14.6 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, applicherai le tecniche di pulizia e preprocessing dei dati utilizzando il dataset SWLS. Il tuo compito è seguire i passaggi descritti per trasformare il dataset in una forma pronta per l’analisi.\nIstruzioni\n\n\nImporta i dati SWLS (Survey of Life Satisfaction Scale). Introduci almeno due dati mancanti nei dati e almeno un duplicato.\n\nControlla i dati: verifica la struttura e individua eventuali anomalie.\n\nPulisci i dati:\n\nRimuovi eventuali duplicati.\nGestisci i valori mancanti in modo appropriato.\nRinomina le variabili per una maggiore chiarezza.\nStandardizza alcune variabili per l’analisi.\n\n\n\nDocumenta le modifiche effettuate.\n\nEsporta il dataset pulito.\n\nConsegna\n\nSalva il tuo file Quarto con il nome swls_cleaning.qmd.\n\nUsa questo header YAML:\n---\ntitle: \"Assegnamento: Pulizia e Preprocessing dei Dati SWLS\"\nauthor: \"Nome Studente\"\ndate: \"2025-02-22\"\nformat: html\n---\n\nAssicurati che il codice sia commentato e spiegato chiaramente.\nEsporta il dataset pulito e allegalo alla consegna.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "title": "14  Flusso di lavoro per la pulizia dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] skimr_2.1.5       dataMeta_0.1.1    writexl_1.5.1     pointblank_0.12.2\n#&gt;  [5] haven_2.5.4       labelled_2.14.0   mice_3.17.0       thematic_0.1.6   \n#&gt;  [9] MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.10.0        gridExtra_2.3    \n#&gt; [13] patchwork_1.3.0   bayesplot_1.11.1  psych_2.4.12      scales_1.3.0     \n#&gt; [17] markdown_1.13     knitr_1.49        lubridate_1.9.4   forcats_1.0.0    \n#&gt; [21] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#&gt; [25] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#&gt; [29] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.2      mnormt_2.1.1      rlang_1.1.5       magrittr_2.0.3   \n#&gt;  [5] compiler_4.4.2    vctrs_0.6.5       pkgconfig_2.0.3   shape_1.4.6.1    \n#&gt;  [9] crayon_1.5.3      fastmap_1.2.0     backports_1.5.0   utf8_1.2.4       \n#&gt; [13] blastula_0.3.5    rmarkdown_2.29    tzdb_0.4.0        nloptr_2.1.1     \n#&gt; [17] bit_4.5.0.1       xfun_0.50         glmnet_4.1-8      jomo_2.7-6       \n#&gt; [21] jsonlite_1.8.9    pan_1.9           broom_1.0.7       parallel_4.4.2   \n#&gt; [25] R6_2.6.1          stringi_1.8.4     boot_1.3-31       rpart_4.1.24     \n#&gt; [29] Rcpp_1.0.14       iterators_1.0.14  base64enc_0.1-3   pacman_0.5.1     \n#&gt; [33] R.utils_2.12.3    Matrix_1.7-2      splines_4.4.2     nnet_7.3-20      \n#&gt; [37] timechange_0.3.0  tidyselect_1.2.1  rstudioapi_0.17.1 codetools_0.2-20 \n#&gt; [41] lattice_0.22-6    withr_3.0.2       evaluate_1.0.3    survival_3.8-3   \n#&gt; [45] xml2_1.3.6        pillar_1.10.1     foreach_1.5.2     reformulas_0.4.0 \n#&gt; [49] generics_0.1.3    vroom_1.6.5       rprojroot_2.0.4   hms_1.1.3        \n#&gt; [53] munsell_0.5.1     commonmark_1.9.2  minqa_1.2.8       glue_1.8.0       \n#&gt; [57] tools_4.4.2       data.table_1.16.4 lme4_1.1-36       grid_4.4.2       \n#&gt; [61] rbibutils_2.3     colorspace_2.1-1  nlme_3.1-167      repr_1.1.7       \n#&gt; [65] cli_3.6.4         gt_0.11.1         gtable_0.3.6      R.methodsS3_1.8.2\n#&gt; [69] sass_0.4.9        digest_0.6.37     htmlwidgets_1.6.4 farver_2.1.2     \n#&gt; [73] htmltools_0.5.8.1 R.oo_1.27.0       lifecycle_1.0.4   mitml_0.4-5      \n#&gt; [77] bit64_4.6.0-1     MASS_7.3-64",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#bibliografia",
    "href": "chapters/eda/02_data_cleaning.html#bibliografia",
    "title": "14  Flusso di lavoro per la pulizia dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBuchanan, E. M., Crain, S. E., Cunningham, A. L., Johnson, H. R., Stash, H., Papadatou-Pastou, M., Isager, P. M., Carlsson, R., & Aczel, B. (2021). Getting started creating data dictionaries: How to create a shareable data set. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920928007.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html",
    "href": "chapters/eda/04_exploring_qualitative_data.html",
    "title": "15  Esplorare i dati qualitativi",
    "section": "",
    "text": "15.1 Introduzione\nIn questo capitolo ci concentreremo sull’analisi dei dati qualitativi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "href": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "title": "15  Esplorare i dati qualitativi",
    "section": "\n15.2 Il dataset penguins\n",
    "text": "15.2 Il dataset penguins\n\nPer fornire esempi pratici, in questo capitolo utilizzeremo il dataset palmerpenguins, messo a disposizione da Allison Horst. I dati sono stati raccolti e resi disponibili da Dr. Kristen Gorman e dalla Palmer Station, parte del programma di ricerca ecologica a lungo termine Long Term Ecological Research Network. Il dataset contiene informazioni su 344 pinguini, appartenenti a 3 diverse specie, raccolte su 3 isole dell’arcipelago di Palmer, in Antartide. Per semplicità, i dati sono organizzati nel file penguins.csv.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "href": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "title": "15  Esplorare i dati qualitativi",
    "section": "\n15.3 Importare i Dati",
    "text": "15.3 Importare i Dati\nPossiamo caricare i dati grezzi dal file penguins.csv in un DataFrame con il seguente comando:\n\nd &lt;- rio::import(here::here(\"data\", \"penguins.csv\"))\n\nEsaminiamo i dati.\n\nglimpse(d)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;chr&gt; \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\"…\n#&gt; $ island            &lt;chr&gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgerse…\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34…\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18…\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190,…\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 34…\n#&gt; $ sex               &lt;chr&gt; \"male\", \"female\", \"female\", NA, \"female\", \"male\"…\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, …\n\nPer semplicità, rimuoviamo le righe con valori mancanti con la seguente istruzione:\n\ndf &lt;- d |&gt;\n  drop_na()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "href": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "title": "15  Esplorare i dati qualitativi",
    "section": "\n15.4 Tabelle di Contingenza",
    "text": "15.4 Tabelle di Contingenza\nUna tabella di contingenza è uno strumento utilizzato per riassumere i dati di due variabili categoriali, ovvero variabili qualitative che assumono valori all’interno di un insieme finito di categorie. In una tabella di contingenza, ogni cella mostra quante volte si è verificata una combinazione specifica di categorie per le due variabili considerate.\nPer esempio, se prendiamo in esame due variabili categoriali come “island” e “species” all’interno di un DataFrame df, ciascuna delle quali rappresenta rispettivamente l’isola di provenienza e la specie dei pinguini, possiamo costruire una tabella che mostra quante volte ciascuna combinazione di “island” e “species” appare nel nostro campione. In altre parole, la tabella di contingenza ci permette di vedere quante osservazioni ci sono per ogni combinazione di categorie tra queste due variabili. Usiamo la funzione tably() del pacchetto janitor.\n\ndf |&gt; \n  tabyl(island, species) |&gt; \n  adorn_totals(c(\"row\", \"col\")) \n#&gt;     island Adelie Chinstrap Gentoo Total\n#&gt;     Biscoe     44         0    119   163\n#&gt;      Dream     55        68      0   123\n#&gt;  Torgersen     47         0      0    47\n#&gt;      Total    146        68    119   333\n\nQuesta tabella di contingenza mostra la distribuzione di tre specie di pinguini (Adelie, Chinstrap, Gentoo) rispetto a tre isole (Biscoe, Dream, Torgersen). Ogni cella rappresenta il numero di pinguini di una determinata specie presenti su ciascuna isola. Ecco un’interpretazione dettagliata:\n\n\nIsola Biscoe: Qui troviamo 44 pinguini della specie Adelie e 119 pinguini della specie Gentoo, mentre non sono presenti pinguini Chinstrap.\n\nIsola Dream: Questa isola ospita 55 pinguini Adelie e 68 pinguini Chinstrap, ma nessun pinguino della specie Gentoo.\n\nIsola Torgersen: Su quest’isola sono presenti solo 47 pinguini della specie Adelie, e nessun pinguino delle specie Chinstrap o Gentoo.\n\nPossiamo commentare dicendo:\n\nLa specie Adelie è distribuita su tutte e tre le isole, con numeri notevoli sia su Biscoe (44), Dream (55), che Torgersen (47).\nLa specie Chinstrap si trova solo sull’isola Dream (68 esemplari) e non è presente sulle altre due isole.\nLa specie Gentoo si trova esclusivamente sull’isola Biscoe (119 esemplari), non essendo presente su Dream e Torgersen.\n\nQuesto suggerisce una distribuzione geografica specifica delle diverse specie di pinguini, con alcune specie limitate a determinate isole e altre distribuite più ampiamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "href": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "title": "15  Esplorare i dati qualitativi",
    "section": "\n15.5 Grafico a barre",
    "text": "15.5 Grafico a barre\n\n15.5.1 Grafico a Barre con una Singola Variabile\nUn grafico a barre è uno strumento comunemente utilizzato per rappresentare visivamente una singola variabile categoriale. Questo tipo di grafico mostra le diverse categorie su uno degli assi (solitamente l’asse orizzontale) e utilizza barre di altezza proporzionale per rappresentare la frequenza o il conteggio di ciascuna categoria sull’altro asse (solitamente l’asse verticale).\nAd esempio, in un dataset che contiene informazioni su diverse specie di pinguini, un grafico a barre potrebbe mostrare il numero di pinguini per ciascuna specie. Le specie vengono visualizzate come etichette lungo l’asse delle ascisse, mentre l’altezza delle barre rappresenta il numero di pinguini osservati per ciascuna specie.\nIl grafico a barre consente di confrontare le dimensioni delle categorie in modo semplice e intuitivo.\nPer i dati in esame, creiamo un grafico a barre che rappresenta il numero totale di pinguini per isola.\n\nggplot(df, aes(x = island)) +\n  geom_bar(fill = \"lightblue\") +\n  ggtitle(\"Numero totale di pinguini per isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") \n\n\n\n\n\n\n\nUn secondo grafico a barre mostra il numero totale di pinguini per specie.\n\nggplot(df, aes(x = species)) +\n  geom_bar(fill = \"lightblue\") +\n  ggtitle(\"Numero totale di pinguini per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\")\n\n\n\n\n\n\n\n\n15.5.2 Grafico a Barre con Due Variabili\nÈ possibile visualizzare contemporaneamente le distribuzioni di due variabili categoriali utilizzando un grafico a barre. Questo tipo di grafico è particolarmente utile per esaminare la relazione tra due variabili categoriali.\nIn un grafico a barre con due variabili, una delle variabili viene rappresentata sull’asse orizzontale come categoria principale, mentre la seconda variabile è distinta tramite colori diversi o barre impilate. In questo modo, possiamo confrontare facilmente le frequenze o le proporzioni delle categorie della prima variabile, osservando allo stesso tempo come sono distribuite le categorie della seconda variabile all’interno di ciascuna categoria principale.\nAd esempio, visualizziamo il numero di pinguini per specie e isola. A qusto fine possiamo creare un grafico a barre dove le isole sono rappresentate sull’asse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle specie su ciascuna isola. Questo approccio consente di esplorare come le due variabili categoriali (specie e isola) interagiscono visivamente.\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"stack\") +\n  ggtitle(\"Numero di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Specie\") \n\n\n\n\n\n\n\nIn alternativa, è possibile creare un grafico a barre dove le specie sono rappresentate sull’asse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle isole per ciascuna specie.\n\nggplot(df, aes(x = species, fill = island)) +\n  geom_bar(position = \"stack\") +\n  ggtitle(\"Numero di pinguini per isola e specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Isola\")\n\n\n\n\n\n\n\nIn alternativa all’uso delle frequenze assolute, possiamo rappresentare i dati utilizzando le frequenze relative. Questo approccio permette di confrontare meglio le categorie indipendentemente dal numero totale di osservazioni. Nella figura seguente, ad esempio, viene mostrata la proporzione di pinguini di ciascuna specie per ogni isola, evidenziando la distribuzione relativa delle specie su ogni isola, anziché il conteggio assoluto. Questa rappresentazione aiuta a visualizzare le differenze nella composizione delle specie, anche se il numero complessivo di pinguini varia tra le isole.\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\") +\n  ggtitle(\"Proporzione di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Proporzione\") +\n  labs(fill = \"Specie\")",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "href": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "title": "15  Esplorare i dati qualitativi",
    "section": "\n15.6 Mosaic plots",
    "text": "15.6 Mosaic plots\nIl Mosaic plot è una tecnica di visualizzazione particolarmente adatta per rappresentare tabelle di contingenza. Questo tipo di grafico somiglia a un grafico a barre impilate standard, ma con un vantaggio importante: oltre a visualizzare la suddivisione interna delle categorie, permette di vedere anche le dimensioni relative dei gruppi della variabile principale.\nIn altre parole, il Mosaic plot non solo mostra come si distribuiscono le categorie di una variabile secondaria all’interno di ogni gruppo della variabile principale, ma fornisce anche un’idea visiva della grandezza complessiva dei gruppi. Questo lo rende uno strumento utile per analizzare e interpretare le relazioni tra due variabili categoriali, evidenziando sia la proporzione all’interno di ciascun gruppo, sia la grandezza relativa tra i gruppi stessi.\n\nmosaic(\n  ~ species + island, \n  data = df, \n  main = \"Mosaic Plot of Species and Island\",\n  shade = TRUE\n)\n\n\n\n\n\n\n\n\n\nisland: Variabile rappresentata come suddivisione orizzontale all’interno di ogni gruppo di species (variabile principale).\n\nspecies: Variabile rappresentata lungo l’asse verticale (variabile secondaria suddivisa all’interno di ogni gruppo di island).\n\n\n15.6.0.1 Interpretazione\n\n\nDimensione dei Rettangoli:\n\nLa larghezza dei rettangoli corrisponde alla dimensione relativa dei gruppi della variabile island.\nL’altezza dei rettangoli rappresenta la proporzione delle categorie di species all’interno di ciascun gruppo di island.\n\n\n\nColorazione (se shade = TRUE):\n\nI colori indicano deviazioni rispetto all’indipendenza statistica tra le variabili.\nUn rettangolo scuro rappresenta una frequenza maggiore o minore di quella attesa in caso di indipendenza tra species e island.\n\n\n\nOsservazioni Specifiche:\n\n\nRettangoli alti e larghi: Indicano una categoria di species molto rappresentata su un’isola specifica.\n\nRettangoli sottili o stretti: Indicano una rappresentazione meno significativa o assente di una specie su un’isola.\n\n\n\nIn conclusione, il Mosaic plot è uno strumento grafico efficace per analizzare le relazioni tra due variabili categoriali. Ti permette di esplorare:\n\nLa proporzione interna delle categorie.\nLe dimensioni relative dei gruppi della variabile principale.\n\nQuesto grafico è particolarmente utile per individuare schemi o associazioni, come una specie predominante su un’isola specifica o una distribuzione equilibrata tra gruppi. La sua rappresentazione intuitiva lo rende ideale per ricerche in psicologia, scienze sociali e biologia.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "href": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "title": "15  Esplorare i dati qualitativi",
    "section": "\n15.7 Proporzioni di Riga e Colonna",
    "text": "15.7 Proporzioni di Riga e Colonna\nNelle sezioni precedenti abbiamo esaminato la visualizzazione di due variabili categoriali utilizzando grafici a barre e Mosaic plot. Tuttavia, non abbiamo ancora discusso come vengono calcolate le proporzioni mostrate in questi grafici. In questa sezione ci concentreremo sulla suddivisione frazionaria di una variabile rispetto a un’altra, esplorando come possiamo modificare la nostra tabella di contingenza per ottenere una visione più dettagliata delle proporzioni.\nQuesto ci permetterà di comprendere meglio le relazioni tra le due variabili, visualizzando non solo i conteggi assoluti, ma anche le proporzioni relative per riga o per colonna. Le proporzioni di riga mostrano la distribuzione di una variabile all’interno delle categorie di un’altra, mentre le proporzioni di colonna evidenziano la distribuzione inversa.\nCalcoliamo le proporzioni di specie per isola.\n\ndf %&gt;%\n  tabyl(island, species) %&gt;%  # Crea la tabella di contingenza\n  adorn_percentages(\"row\") %&gt;%  # Calcola le proporzioni per riga\n  adorn_totals(\"col\") %&gt;%  # Aggiunge la colonna dei totali\n  adorn_pct_formatting(digits = 2)  # Formatta le percentuali con 2 decimali\n#&gt;     island  Adelie Chinstrap Gentoo   Total\n#&gt;     Biscoe  26.99%     0.00% 73.01% 100.00%\n#&gt;      Dream  44.72%    55.28%  0.00% 100.00%\n#&gt;  Torgersen 100.00%     0.00%  0.00% 100.00%\n\nCalcoliamo nuovamente le proporzioni, ma questa volta in funzione delle colonne (per isola).\n\ndf |&gt; \n  tabyl(island, species) |&gt; \n  adorn_percentages(\"col\") |&gt; \n  adorn_totals(\"row\") |&gt; \n  adorn_pct_formatting(digits = 2) # Formatta le percentuali con 2 decimali\n#&gt;     island  Adelie Chinstrap  Gentoo\n#&gt;     Biscoe  30.14%     0.00% 100.00%\n#&gt;      Dream  37.67%   100.00%   0.00%\n#&gt;  Torgersen  32.19%     0.00%   0.00%\n#&gt;      Total 100.00%   100.00% 100.00%",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "href": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "title": "15  Esplorare i dati qualitativi",
    "section": "\n15.8 Confronto tra Gruppi",
    "text": "15.8 Confronto tra Gruppi\nAlcune delle analisi più interessanti emergono confrontando i dati numerici tra diversi gruppi. In questa sezione approfondiremo alcune delle tecniche che abbiamo già esplorato per visualizzare i dati numerici di più gruppi su uno stesso grafico e introdurremo nuovi metodi per confrontare i dati numerici tra gruppi. Queste tecniche ci permetteranno di osservare meglio le differenze e le somiglianze tra gruppi, mettendo in evidenza tendenze, variazioni e altre caratteristiche rilevanti.\nQui consideriamo due variabili qualitative. Creiamo un grafico a barre per confrontare la distribuzione del genere per specie.\n\nggplot(df, aes(x = species, fill = sex)) +\n  geom_bar(position = \"dodge\") +\n  ggtitle(\"Distribuzione del genere per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Conteggio\")\n\n\n\n\n\n\n\nSpesso, i confronti più interessanti riguardano come una variabile numerica varia in base a una o più categorie. Questo tipo di analisi ci aiuta a capire differenze tra gruppi e a individuare modelli o tendenze.\nNel grafico seguente, confrontiamo la distribuzione del peso corporeo (body_mass_g) in base alla specie e al genere. Le aree colorate rappresentano come si distribuisce il peso per maschi e femmine all’interno di ciascuna specie. Le linee più strette al centro delle aree colorate aggiungono ulteriori dettagli, mostrando i valori più comuni e come si concentrano i dati per ciascun gruppo.\n\nggplot(df, aes(x = species, y = body_mass_g, fill = sex)) +\n  geom_violin(\n    position = position_dodge(width = 0.9), alpha = 0.5\n  ) +\n  geom_boxplot(\n    position = position_dodge(width = 0.9), width = 0.2, alpha = 0.8\n  ) +\n  ggtitle(\n    \"Distribuzione della massa corporea\\nin base alla specie e al genere\"\n  ) +\n  xlab(\"Specie\") +\n  ylab(\"Massa corporea (g)\") +\n  labs(fill = \"Genere\")\n\n\n\n\n\n\n\n\n\nAree colorate (grafico a violino):\n\nRappresentano l’intera distribuzione dei pesi per ogni gruppo (specie e genere). Più l’area è larga in un punto, maggiore è il numero di pinguini con quel peso.\n\n\n\nLinee strette al centro (boxplot):\n\nForniscono un riassunto visivo dei dati, mostrando dove i pesi si concentrano maggiormente e quanto variano all’interno di ciascun gruppo.\n\n\n\nCosa possiamo osservare:\n\nPossiamo vedere facilmente se i maschi e le femmine di una stessa specie tendono ad avere pesi simili o differenti, e se c’è una certa sovrapposizione tra i due gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#esercizi",
    "href": "chapters/eda/04_exploring_qualitative_data.html#esercizi",
    "title": "15  Esplorare i dati qualitativi",
    "section": "\n15.9 Esercizi",
    "text": "15.9 Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nIn questo esercizio analizzerai i dati qualitativi raccolti mediante la scala SWLS, concentrandoti su due variabili categoriali:\n\n\nGenere (gender): maschio / femmina.\n\nTipo di scuola superiore (school_type): liceo classico o scientifico vs tutto il resto.\n\nDovrai creare tabelle di contingenza e rappresentazioni grafiche per esplorare le relazioni tra queste variabili.\nImportazione dei dati\nImporta i dati da un file CSV e visualizza la loro struttura.\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(here)\n\n# Importa i dati\nswls_data &lt;- read_csv(here(\"data\", \"swls_students.csv\"))\n\n# Esamina i dati\nglimpse(swls_data)\nTabelle di Contingenza\n\nCrea una tabella di contingenza tra gender e school_type.\nCalcola le proporzioni di riga e colonna.\n\n# Tabella di contingenza\nswls_data |&gt; \n  tabyl(gender, school_type) |&gt; \n  adorn_totals(c(\"row\", \"col\"))\nCalcola ora le proporzioni relative.\n# Proporzioni di riga\nswls_data |&gt; \n  tabyl(gender, school_type) |&gt; \n  adorn_percentages(\"row\") |&gt; \n  adorn_pct_formatting(digits = 2)\n# Proporzioni di colonna\nswls_data |&gt; \n  tabyl(gender, school_type) |&gt; \n  adorn_percentages(\"col\") |&gt; \n  adorn_pct_formatting(digits = 2)\nVisualizzazione Grafica\n\nCrea un grafico a barre per visualizzare il numero di studenti per tipo di scuola.\nCrea un grafico a barre per la distribuzione del genere per tipo di scuola.\n\nggplot(swls_data, aes(x = school_type)) +\n  geom_bar() +\n  ggtitle(\"Numero di studenti per tipo di scuola\") +\n  xlab(\"Tipo di scuola\") +\n  ylab(\"Numero di studenti\")\nggplot(swls_data, aes(x = school_type, fill = gender)) +\n  geom_bar(position = \"dodge\") +\n  ggtitle(\"Distribuzione del genere per tipo di scuola\") +\n  xlab(\"Tipo di scuola\") +\n  ylab(\"Numero di studenti\") +\n  labs(fill = \"Genere\")\nDomande per la riflessione\n\nQuale tipo di scuola ha il maggior numero di studenti?\nCi sono differenze nella distribuzione del genere tra i tipi di scuola?\n\nConsegna\n\nCompila il file .qmd con il tuo codice e commenti.\nEsporta il documento in formato HTML o PDF.\nCarica il file su Moodle.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "15  Esplorare i dati qualitativi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] janitor_2.2.1     vcd_1.4-13        viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] thematic_0.1.6    MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.10.0       \n#&gt;  [9] gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1  psych_2.4.12     \n#&gt; [13] scales_1.3.0      markdown_1.13     knitr_1.49        lubridate_1.9.4  \n#&gt; [17] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4      \n#&gt; [21] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n#&gt; [25] tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.50         htmlwidgets_1.6.4 lattice_0.22-6   \n#&gt;  [5] tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2       generics_0.1.3   \n#&gt;  [9] parallel_4.4.2    pacman_0.5.1      R.oo_1.27.0       pkgconfig_2.0.3  \n#&gt; [13] data.table_1.16.4 lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      snakecase_0.11.1  htmltools_0.5.8.1\n#&gt; [21] yaml_2.3.10       pillar_1.10.1     MASS_7.3-64       R.utils_2.12.3   \n#&gt; [25] nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [29] labeling_0.4.3    rprojroot_2.0.4   fastmap_1.2.0     colorspace_2.1-1 \n#&gt; [33] cli_3.6.4         magrittr_2.0.3    withr_3.0.2       timechange_0.3.0 \n#&gt; [37] rmarkdown_2.29    zoo_1.8-12        R.methodsS3_1.8.2 hms_1.1.3        \n#&gt; [41] evaluate_1.0.3    lmtest_0.9-40     rlang_1.1.5       glue_1.8.0       \n#&gt; [45] rstudioapi_0.17.1 jsonlite_1.8.9    R6_2.6.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html",
    "href": "chapters/eda/05_exploring_numeric_data.html",
    "title": "16  Esplorare i dati numerici",
    "section": "",
    "text": "Introduzione\nIn questo capitolo ci concentreremo sull’analisi dei dati numerici. In particolare, esamineremo le distribuzioni di frequenza e i quantili, insieme alle tecniche di visualizzazione più comuni, come l’istogramma, l’istogramma smussato e il box-plot. Tratteremo sia gli aspetti computazionali che quelli interpretativi di queste misure, fornendo strumenti utili non solo per una comprensione personale, ma anche per la comunicazione efficace dei risultati, in particolare con chi utilizza questi dati per prendere decisioni pratiche nel mondo reale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "href": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "title": "16  Esplorare i dati numerici",
    "section": "\n16.1 I dati sulle aspettative negative nella depressione",
    "text": "16.1 I dati sulle aspettative negative nella depressione\nConsideriamo i dati relativi alle aspettative negative, individuate come un meccanismo chiave nel mantenimento della depressione (Zetsche et al., 2019). Supponiamo di voler analizzare la distribuzione di una singola variabile quantitativa.\nImportiamo i dati:\n\ndf &lt;- rio::import(here::here(\"data\", \"data.mood.csv\"))\n\nPer questo esercizio, ci concentreremo sulle variabili esm_id (il codice del soggetto), group (il gruppo) e bdi (il valore BDI-II).\n\ndf &lt;- df |&gt; \n  dplyr::select(\"esm_id\", \"group\", \"bdi\")\ndf |&gt; \n  head()\n#&gt;   esm_id group bdi\n#&gt; 1     10   mdd  25\n#&gt; 2     10   mdd  25\n#&gt; 3     10   mdd  25\n#&gt; 4     10   mdd  25\n#&gt; 5     10   mdd  25\n#&gt; 6     10   mdd  25\n\nSe elenchiamo le modalità presenti in group utilizzando il metodo unique(), scopriamo che corrispondono a mdd (pazienti) e ctl (controlli sani).\n\ndf$group |&gt; \n  unique()\n#&gt; [1] \"mdd\" \"ctl\"\n\nRimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:\n\ndf &lt;- df[!duplicated(df), ]\n\nVerifichiamo di avere ottenuto il risultato desiderato.\n\ndim(df)\n#&gt; [1] 67  3\n\n\nhead(df)\n#&gt;    esm_id group bdi\n#&gt; 1      10   mdd  25\n#&gt; 15      9   mdd  30\n#&gt; 30      6   mdd  26\n#&gt; 46      7   mdd  35\n#&gt; 65     12   mdd  44\n#&gt; 83     16   mdd  30\n\nSi noti che il nuovo DataFrame (con 67 righe) conserva il “nome” delle righe (ovvero, l’indice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga è 15. Questo non ha nessuna conseguenza perché non useremo l’indice di riga nelle analisi seguenti.\nEliminiamo eventuali valori mancanti:\n\ndf &lt;- df[!is.na(df$bdi), ]\n\nOtteniamo così il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):\n\ndim(df)\n#&gt; [1] 66  3\n\nStampiamo i valori BDI-II presentandoli ordinati dal più piccolo al più grande:\n\ndf$bdi |&gt; \n  sort()\n#&gt;  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1\n#&gt; [25]  1  2  2  2  2  3  3  3  5  7  9 12 19 22 22 24 25 25 26 26 26 27 27 28\n#&gt; [49] 28 30 30 30 31 31 33 33 34 35 35 35 36 39 41 43 43 44\n\nNel linguaggio statistico, un’osservazione rappresenta l’informazione raccolta da un singolo individuo o entità che partecipa allo studio. Nel caso del dataset utilizzato da Zetsche et al. (2019), l’unità di osservazione è costituita dai partecipanti allo studio. Ogni riga del DataFrame, denominato df, corrisponde quindi a un individuo distinto incluso nell’analisi.\nLe variabili, invece, riflettono le diverse caratteristiche degli individui o delle entità considerate. Per i dati in esame, questo concetto si esprime così:\n\nOgni colonna di df rappresenta una variabile che descrive una specifica proprietà comune ai partecipanti.\nLe variabili sono identificate da etichette nelle colonne, come esa_id (l’identificativo del soggetto), mdd (il gruppo di appartenenza), e bdi (il punteggio del test BDI-II).\n\nIn termini simbolisi, per indicare una singola osservazione della variabile generica \\(X\\), si utilizza la notazione \\(X_i\\), dove \\(i\\) rappresenta l’indice dell’osservazione. Questo implica che abbiamo un valore diverso di \\(X\\) per ogni differente \\(i\\). Nel caso presente, con 67 osservazioni, \\(i\\) varia da 1 a 67. Così, per rappresentare la seconda osservazione (quella con \\(i=2\\)), useremo la notazione \\(X_2\\).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "href": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "title": "16  Esplorare i dati numerici",
    "section": "\n16.2 Distribuzioni di frequenza",
    "text": "16.2 Distribuzioni di frequenza\nCome osservato nell’output della sezione precedente, i dati grezzi non forniscono un’interpretazione immediata. Per rendere i dati più comprensibili e sintetici, è utile costruire una distribuzione di frequenza.\nUna distribuzione di frequenza mostra quante volte i valori di una variabile si verificano all’interno di intervalli specifici. Nel caso dei punteggi BDI-II, possiamo raggruppare i punteggi in quattro classi:\n\n0–13: depressione minima\n14–19: depressione lieve-moderata\n20–28: depressione moderata-severa\n29–63: depressione severa\n\nOgni classe, denotata come \\(\\Delta_i\\), rappresenta un intervallo di valori, definito come \\([a_i, b_i)\\) (aperto a destra) o \\((a_i, b_i]\\) (aperto a sinistra), dove \\(a_i\\) e \\(b_i\\) sono rispettivamente il limite inferiore e superiore della classe. A ciascuna classe si associa un’ampiezza, data da \\(b_i - a_i\\), e un valore centrale, indicato con \\(\\bar{x}_i\\). Poiché ogni osservazione \\(x_i\\) appartiene a una sola classe \\(\\Delta_i\\), possiamo calcolare le seguenti quantità:\n\n\nFrequenza assoluta \\(n_i\\): il numero di osservazioni che rientrano nella classe \\(\\Delta_i\\).\n\nProprietà: \\(n_1 + n_2 + \\dots + n_m = n\\), dove \\(n\\) è il numero totale di osservazioni.\n\n\n\nFrequenza relativa \\(f_i\\): la proporzione di osservazioni in ciascuna classe, calcolata come \\(f_i = n_i/n\\).\n\nProprietà: \\(f_1 + f_2 + \\dots + f_m = 1\\).\n\n\nFrequenza cumulata \\(N_i\\): il numero totale di osservazioni che rientrano nelle classi fino alla \\(i\\)-esima inclusa, calcolata come \\(N_i = \\sum_{j=1}^i n_j\\).\nFrequenza cumulata relativa \\(F_i\\): la somma delle frequenze relative fino alla \\(i\\)-esima classe, data da \\(F_i = \\frac{N_i}{n} = \\sum_{j=1}^i f_j\\).\n\nQueste misure permettono di riassumere in modo efficace la distribuzione dei punteggi e facilitano l’interpretazione delle caratteristiche del campione.\n\n16.2.1 Frequenze Assolute e Relative\nPer ottenere la distribuzione di frequenza assoluta e relativa dei valori BDI-II nel dataset di Zetsche et al. (2019), è necessario aggiungere al DataFrame df una colonna contenente una variabile categoriale che classifichi ciascuna osservazione in una delle quattro classi che descrivono la gravità della depressione. Questo risultato si ottiene utilizzando la funzione cut().\nNella funzione cut():\n\nIl primo argomento, x, è un vettore unidimensionale (ad esempio, un vettore di tipo numeric o una colonna di un DataFrame) che contiene i dati da classificare.\nIl secondo argomento, breaks, definisce gli intervalli delle classi, specificandone i limiti inferiori e superiori.\nL’argomento include.lowest = TRUE garantisce che il limite inferiore dell’intervallo più basso sia incluso nella classificazione. Nel nostro caso, questo è particolarmente utile per assicurare che i valori uguali al limite inferiore siano assegnati correttamente.\n\nDi seguito, il codice per aggiungere la variabile categoriale al DataFrame:\n\n# Creare una variabile categoriale per classi di depressione\ndf &lt;- df %&gt;% \n  mutate(\n    bdi_class = cut(\n      bdi, \n      breaks = c(0, 13.5, 19.5, 28.5, 63),\n      include.lowest = TRUE\n    )\n  )\n\nQuesto codice suddivide i valori della variabile bdi in quattro intervalli corrispondenti ai livelli di gravità della depressione:\n\n0–13: depressione minima\n14–19: depressione lieve-moderata\n20–28: depressione moderata-severa\n29–63: depressione severa\n\nOgni osservazione verrà assegnata al corrispondente intervallo, creando così una nuova colonna bdi_class nel DataFrame df.\n\n16.2.1.1 Frequenze assolute\n\ntable(df$bdi_class)\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;          36           1          12          17\n\n\n16.2.1.2 Frequenze relative\n\nprop.table(table(df$bdi_class))\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;     0.54545     0.01515     0.18182     0.25758\n\n\n16.2.2 Distribuzioni congiunte\nLe variabili possono anche essere analizzate insieme tramite le distribuzioni congiunte di frequenze. Queste distribuzioni rappresentano l’insieme delle frequenze assolute o relative ad ogni possibile combinazione di valori delle variabili. Ad esempio, se l’insieme di variabili \\(V\\) è composto da due variabili, \\(X\\) e \\(Y\\), ciascuna delle quali può assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per \\(V\\) potrebbe essere espressa come \\(f(X = 1, Y = 1) = 0.2\\), \\(f(X = 1, Y = 2) = 0.1\\), \\(f(X = 2, Y = 1) = 0.5\\), e \\(f(X = 2, Y = 2) = 0.2\\). Come nel caso delle distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare a 1.\nPer i dati dell’esempio precedente, la funzione prop.table() può essere utilizzata anche per produrre questo tipo di tabella: basta indicare le serie corrispondenti alle variabili considerate come valori degli argomenti bdi_class e group.\n\nprop.table(table(df$bdi_class, df$group))\n#&gt;              \n#&gt;                   ctl     mdd\n#&gt;   [0,13.5]    0.54545 0.00000\n#&gt;   (13.5,19.5] 0.00000 0.01515\n#&gt;   (19.5,28.5] 0.00000 0.18182\n#&gt;   (28.5,63]   0.00000 0.25758\n\n\n16.2.3 La Distribuzione Cumulativa Empirica\nLa distribuzione cumulativa empirica (eCDF, empirical Cumulative Distribution Function) è un modo utile per rappresentare la distribuzione di dati numerici. Questa funzione indica la proporzione di dati che sono inferiori o uguali a un certo valore \\(a\\), per tutti i possibili valori di \\(a\\). Matematicamente, la eCDF è definita come:\n\\[\nF(a) = \\text{Proporzione dei dati con valore} \\leq a.\n\\]\nIn altre parole, la eCDF ci dice quale frazione dei dati osservati è minore o uguale a un determinato valore \\(a\\). Questo è particolarmente utile per comprendere come i dati sono distribuiti e per identificare pattern o caratteristiche specifiche della distribuzione, come la presenza di bimodalità (cioè, due picchi distinti nella distribuzione).\n\n16.2.3.1 Esempio con i dati di Zetsche et al. (2019)\n\nNel contesto dei dati di Zetsche et al. (2019), possiamo utilizzare la eCDF per visualizzare la distribuzione dei punteggi BDI-II. Ecco come viene rappresentata la eCDF per l’intero dataset:\n\ndf |&gt; \n  ggplot(aes(bdi)) + \n  stat_ecdf() +\n  labs(x = \"BDI\", y = \"F(BDI)\")\n\n\n\n\n\n\n\nIn questo grafico:\n\nL’asse \\(x\\) rappresenta i valori del BDI-II.\nL’asse \\(y\\) rappresenta la proporzione cumulativa dei dati, cioè \\(F(a)\\).\n\n16.2.3.2 Interpretazione del grafico\n\n\nCrescita della curva: La curva della eCDF parte da 0 (nessun dato è inferiore al valore minimo osservato) e cresce gradualmente fino a 1 (tutti i dati sono inferiori o uguali al valore massimo osservato).\n\nBimodalità: Se la curva presenta dei “gradini” o delle aree con una pendenza più ripida, questo può indicare la presenza di bimodalità, ovvero due gruppi distinti di dati con caratteristiche diverse. Nel caso dei dati BDI-II, la bimodalità potrebbe riflettere la presenza di due sottogruppi di partecipanti con livelli di depressione diversi.\n\n16.2.3.3 Filtrare i dati per il campione clinico\nSe vogliamo analizzare solo i dati relativi al campione clinico (ad esempio, i pazienti con depressione maggiore), possiamo filtrare i dati e rappresentare la eCDF solo per questo gruppo:\n\ndf |&gt; dplyr::filter(group == \"mdd\") |&gt; \n  ggplot(aes(bdi)) + \n  stat_ecdf() +\n  labs(x = \"a\", y = \"F(a)\")\n\n\n\n\n\n\n\nIn questo caso, la eCDF ci mostrerà come i punteggi BDI-II sono distribuiti tra i pazienti con depressione maggiore, permettendoci di identificare eventuali pattern specifici per questo gruppo.\n\n16.2.3.4 Vantaggi della eCDF\n\n\nVisualizzazione chiara: La eCDF fornisce una rappresentazione visiva immediata della distribuzione dei dati, evidenziando caratteristiche come la bimodalità o la presenza di outlier.\n\nNon parametrica: La eCDF non assume alcuna forma specifica per la distribuzione dei dati, rendendola adatta per analizzare dati con distribuzioni complesse o non standard.\n\nFacilità di interpretazione: La proporzione cumulativa è intuitiva e permette di capire rapidamente quanti dati si trovano al di sotto di un certo valore.\n\nIn sintesi, la eCDF è uno strumento potente per analizzare e visualizzare la distribuzione di dati numerici, specialmente quando si vogliono identificare pattern specifici o confrontare distribuzioni tra diversi gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "href": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "title": "16  Esplorare i dati numerici",
    "section": "\n16.3 Istogramma",
    "text": "16.3 Istogramma\nSebbene il concetto di Funzione di Distribuzione Empirica Cumulativa (eCDF) venga ampiamente discusso nei testi di statistica, in pratica tale rappresentazione non è molto diffusa. Il motivo principale è che l’eCDF non rende immediatamente visibili alcune caratteristiche fondamentali della distribuzione, come il valore intorno al quale essa è centrata, se la distribuzione sia simmetrica o quali intervalli contengano il 95% dei dati, ad esempio. Gli istogrammi, invece, sono molto più utilizzati perché facilitano notevolmente la comprensione di queste proprietà, sacrificando solo un po’ di informazione per fornire una rappresentazione più intuitiva.\nUn istogramma è un grafico che rappresenta la distribuzione delle frequenze di una variabile. Sull’asse orizzontale (ascisse) vengono indicati i limiti delle classi \\(\\Delta_i\\), mentre sull’asse verticale (ordinate) si riporta la densità della frequenza relativa della variabile \\(X\\) per ciascuna classe \\(\\Delta_i\\).\nPer descrivere formalmente la densità della frequenza relativa, si utilizza una funzione costante a tratti definita come:\n\\[\n\\varphi_n(x) = \\frac{f_i}{b_i - a_i},\n\\]\ndove:\n\n\n\\(f_i\\) è la frequenza relativa della classe \\(\\Delta_i\\),\n\n\\(b_i - a_i\\) è l’ampiezza della classe \\(\\Delta_i\\).\n\nIn questo modo, l’area del rettangolo corrispondente a \\(\\Delta_i\\) in un istogramma risulta proporzionale alla frequenza relativa \\(f_i\\). Poiché la somma delle frequenze relative deve essere pari a 1, l’area totale di un istogramma delle frequenze relative risulta anch’essa uguale a 1, corrispondendo alla somma delle aree di tutti i rettangoli.\nGli istogrammi costituiscono quindi uno strumento essenziale per visualizzare e comprendere le principali caratteristiche di una distribuzione, agevolando l’analisi della sua forma, della sua tendenza centrale e della sua dispersione.\nPer fare un esempio, costruiamo un istogramma per i valori BDI-II di Zetsche et al. (2019). Con i quattro intervalli individuati dai cut-off del BDI-II creiamo una prima versione dell’istogramma – si notino le frequenze assolute sull’asse delle ordinate.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    color = \"black\",\n    fill = \"lightblue\",\n    breaks = c(0, 13.5, 19.5, 28.5, 63),\n    aes(y = after_stat(density)),\n  ) +\n  labs(\n    title = \"Istogramma delle frequenze relative\", \n    x = \"BDI-II\", \n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\nAnche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un’ampiezza uguale.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    color = \"black\",\n    fill = \"lightblue\",\n    aes(y = after_stat(density)),\n  ) +\n  labs(\n    title = \"Istogramma delle frequenze relative\", \n    x = \"BDI-II\", \n    y = \"Densità\"\n  )",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "href": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "title": "16  Esplorare i dati numerici",
    "section": "\n16.4 Kernel Density Plot",
    "text": "16.4 Kernel Density Plot\nUn limite evidente degli istogrammi è che la loro forma dipende da scelte arbitrarie: il numero e l’ampiezza delle classi (o bin) può infatti influenzare in modo sostanziale l’aspetto finale del grafico, rendendo più difficile l’interpretazione della distribuzione dei dati. Una soluzione a questo problema è offerta dalla stima della densità kernel (Kernel Density Estimation, KDE), un metodo che fornisce un profilo continuo e smussato della distribuzione, meno condizionato dall’arbitrarietà delle classi.\n\n16.4.1 Differenza tra Istogramma e KDE\nNell’istogramma, dividiamo l’asse orizzontale in intervalli di ampiezza prefissata (i bin) e costruiamo rettangoli la cui altezza è proporzionale alla frequenza (o densità) dei dati che ricadono in ciascun intervallo. Se cambiamo il numero o la larghezza dei bin, la forma dell’istogramma può variare sensibilmente.\nLa KDE, invece, non suddivide i dati in intervalli fissi. Al contrario, “appoggia” una piccola curva (il kernel) su ogni singola osservazione. Le curve utilizzate (ad esempio di tipo gaussiano) hanno una larghezza, detta bandwidth, che controlla il grado di smussamento: con un bandwidth molto piccolo, la stima segue da vicino le singole osservazioni, generando un profilo più frastagliato; con un bandwidth più ampio, la curva risultante è più liscia, ma rischia di nascondere dettagli importanti.\nPer comprendere in modo intuitivo il concetto di KDE, possiamo partire da un esempio semplice. Immaginiamo di costruire un istogramma con classi di ampiezza sempre più piccola. Se avessimo a disposizione un numero enorme di dati (ad esempio, un milione di misurazioni dell’altezza di individui) e li rappresentassimo con bin sempre più stretti (0.1, 0.01, ecc.), l’istogramma diventerebbe sempre più levigato, avvicinandosi a una curva continua. Questo processo illustra l’idea alla base della KDE, che approssima la distribuzione dei dati in modo fluido e continuo.\nLa KDE, tuttavia, opera in modo più elegante e senza richiedere un numero enorme di punti: posiziona un piccolo “dosso di campana” (o un altro tipo di kernel) su ciascun punto dati e somma tutte queste curve in un’unica curva finale.\n\n\n\n\n\n\nChe cosa vuol dire “dosso di campana”?\n\n\n\nPossiamo immaginarlo come una piccola curva gaussiana: una curva simile alla forma di una campana che si innalza e poi discende dolcemente.\n\nOgni singolo dato viene “coperto” da questa mini-campana.\nL’ampiezza (o “larghezza”) della campana è regolata dal bandwidth, che stabilisce se la curva sarà più o meno “distesa” sul grafico.\nSommando tutte le piccole campane (una per ogni osservazione), otteniamo una curva di densità liscia e continua che rappresenta la distribuzione dei dati senza i “salti” tipici dell’istogramma.\n\n\n\nIl risultato è una curva di densità che:\n\n\nÈ continua: a differenza degli istogrammi, non presenta bruschi salti di altezza tra i bin: la curva scorre in modo uniforme lungo tutto l’asse orizzontale.\n\nMostra la proporzione di dati in ogni intervallo: l’area sotto la curva in un determinato range corrisponde alla percentuale (o probabilità) di dati che cadono in quell’intervallo.\n\nDipende dal bandwidth:\n\nUn bandwidth piccolo produce una curva più ondulata e “frastagliata” (poiché segue da vicino ogni singolo dato).\nUn bandwidth grande genera una curva più liscia e arrotondata, ma rischia di “coprire” troppi dettagli della distribuzione originaria.\n\n\n\nSi noti che la stima della densità kernel introduce, tuttavia, un’ipotesi di fondo: che la distribuzione dei dati “reali” sia “liscia” e non presenti discontinuità improvvise. Questo è spesso ragionevole (ad esempio per dati fisiologici come l’altezza), ma in altri casi potrebbe non esserlo. È quindi importante scegliere un bandwidth che rifletta adeguatamente il livello di dettaglio che vogliamo mostrare.\nInoltre, l’asse delle ordinate (l’asse y) rappresenta la densità, non la frequenza assoluta. È possibile costruire un istogramma in cui l’altezza dei rettangoli mostra quante osservazioni ricadono in ciascun bin. Nella KDE, l’altezza della curva è tale che l’area totale sotto di essa sia pari a 1, rispecchiando la natura di una funzione di densità di probabilità.\nDi seguito esaminiamo un esempio che mostra la costruzione passo dopo passo di istogrammi con diversi valori di binwidth, fino a passare a una stima di densità. Consideriemo un dataset con un numero di osservazioni molto elevato (i valori di altezza, heights, riportati da 1050 partecipanti, estratti dal pacchetto dslabs), suddiviso in due gruppi: maschi e femmine. Ecco come potremmo prima costruire un istogramma di altezze per i maschi, per poi tracciare una curva di densità smussata:\n\n# Istogramma con bin di ampiezza 1\nggplot(heights |&gt; dplyr::filter(sex == \"Male\"), aes(height)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill=\"lightblue\")\n\n\n\n\n\n\n\n\n# Aggiunta della curva di densità sopra l'istogramma\nggplot(heights |&gt; dplyr::filter(sex == \"Male\"), aes(height)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    binwidth = 1, color = \"black\", fill=\"lightblue\"\n  ) +\n  geom_line(stat = 'density')\n\n\n\n\n\n\n\nVariando il parametro di regolazione (adjust o bandwidth) nella funzione geom_density(), possiamo modificare il livello di smussamento:\n\n# Esempio di smoothing differente\np &lt;- ggplot(heights |&gt; filter(sex == \"Male\"), aes(height)) +\n  geom_histogram(aes(y = after_stat(density)), binwidth = 1, alpha = 0.5)\n\n# Più ondulato (bandwidth minore)\np1 &lt;- p + geom_line(stat = 'density', adjust = 0.5)\n\n# Più liscio (bandwidth maggiore)\np2 &lt;- p + geom_line(stat = 'density', adjust = 2)\n\ngrid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\nPer illustrare ulteriormente l’uso della KDE, ora consideriamo i punteggi BDI-II di Zetsche et al. (2019). Con il codice seguente creiamo due curve di densità, una per ogni gruppo:\n\nggplot(df, aes(x = bdi, fill = group)) +\n  geom_density(alpha = 0.5) +\n  labs(\n    title = \"Curva di densità (KDE) per i punteggi BDI-II\",\n    x = \"BDI-II\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nQui, la sovrapposizione delle due curve ci consente di confrontare la distribuzione dei punteggi BDI-II tra i due gruppi in maniera molto più fluida e intuitiva rispetto a quanto faremmo con due istogrammi separati o con un istogramma combinato. Inoltre, non siamo più vincolati alla scelta dei bin: l’aspetto delle curve dipende soltanto dalla funzione kernel utilizzata e dal parametro di smussamento.\nIn conclusione,\n\nl’istogramma rimane uno strumento rapido e intuitivo, privo di assunzioni, ma sensibile alla scelta di numero e ampiezza dei bin;\nla stima della densità kernel (KDE) offre una rappresentazione continua della distribuzione dei dati, fornendo un quadro più “morbido” e spesso più informativo. Tuttavia, introduce alcune assunzioni e richiede la scelta del bandwidth ottimale.\n\nIn definitiva, è consigliabile usare entrambe le tecniche per ottenere una panoramica completa dei propri dati: l’istogramma permette di dare un primo sguardo alla loro distribuzione “grezza” (senza presupposti), mentre la KDE aiuta a comprenderne l’eventuale struttura “liscia” di fondo.\n\n16.4.2 Area Sottesa alla Curva di Densità: Un’Interpretazione Probabilistica\nQuando si lavora con una curva di densità, è importante capire che l’area totale sotto la curva rappresenta la probabilità totale, che è sempre pari a 1 (o 100%). Questo significa che l’area sotto la curva in un determinato intervallo corrisponde alla probabilità che un dato valore cada in quell’intervallo.\n\n16.4.2.1 Come Interpretare l’Asse Y\nL’asse y di un grafico di densità non rappresenta direttamente la probabilità, ma è scalato in modo che l’area totale sotto la curva sia uguale a 1. Se immaginiamo di creare un “bin” (un intervallo) con una base di 1 unità di lunghezza, il valore sull’asse y ci indica la proporzione di valori che cadono in quel bin. Tuttavia, questa interpretazione è valida solo per bin di dimensione 1. Per intervalli di altre dimensioni, il modo migliore per determinare la proporzione di dati in quell’intervallo è calcolare la proporzione dell’area totale sotto la curva che cade in quell’intervallo.\n\n16.4.2.2 Esempio Pratico\nConsideriamo un esempio con i dati delle altezze degli uomini. Supponiamo di voler sapere quale proporzione di uomini ha un’altezza compresa tra 65 e 68 pollici. Per farlo, calcoliamo l’area sotto la curva di densità in quell’intervallo.\nEcco come appare graficamente:\n\n\n\n\n\n\n\n\nL’area evidenziata in azzurro rappresenta la proporzione di uomini con altezza tra 65 e 68 pollici. Calcolando questa area, troviamo che circa il 0.3 (ovvero il 30% degli uomini ha un’altezza in questo intervallo.\n\n16.4.2.3 Utilizzo della Curva di Densità come Riepilogo\nComprendendo questo concetto, possiamo utilizzare la curva di densità come un efficace strumento di riepilogo. Per questo dataset, l’assunzione di smoothness (lisciatura) della curva è ragionevole, e possiamo condividere questa rappresentazione grafica per comunicare in modo chiaro e intuitivo la distribuzione delle altezze degli uomini.\nEcco un esempio di come appare la curva di densità smooth per le altezze degli uomini:\n\n\n\n\n\n\n\n\nIn sintesi, l’area sotto la curva di densità in un determinato intervallo rappresenta la probabilità che un valore casuale cada in quell’intervallo, rendendo la curva di densità uno strumento potente per comprendere e comunicare la distribuzione dei dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "href": "chapters/eda/05_exploring_numeric_data.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "title": "16  Esplorare i dati numerici",
    "section": "\n16.5 Consigli per Creare Visualizzazioni di Dati Efficaci",
    "text": "16.5 Consigli per Creare Visualizzazioni di Dati Efficaci\nEcco alcuni suggerimenti per creare visualizzazioni di dati esplicative, efficaci e di qualità adatta alle presentazioni:\n\n\nMessaggio chiaro: Assicurati che il grafico trasmetta un messaggio chiaro e immediato (ad esempio, “Il livello di benessere psicologico dei partecipanti aumenta nel tempo”).\n\nUso del colore:\n\nUtilizza i colori in modo ponderato e con moderazione.\nNon eccedere nell’uso dei colori solo perché è possibile farlo.\nLimita l’uso a non più di cinque o sei colori in una singola figura.\nVerifica che le scelte cromatiche non distorcano le conclusioni della figura.\nEvita l’uso contemporaneo di rosso e verde nello stesso grafico, poiché queste tonalità sono difficili da distinguere per le persone daltoniche.\n\n\n\nGuidare l’attenzione:\n\nUtilizza dimensioni, colori e testo per guidare l’attenzione del pubblico.\nEvidenzia elementi particolari del grafico per enfatizzare punti chiave.\n\n\n\nGestione del sovraccarico visivo:\n\nUtilizza la trasparenza per ridurre il “sovrapplotting” (che si verifica quando ci sono molti elementi sovrapposti nel grafico, come punti o linee, rendendo difficile individuare i pattern).\nQuesta tecnica è particolarmente utile quando si visualizza una grande quantità di dati.\nSe il dataset è molto ampio e l’aggiunta di trasparenza non è sufficiente, considera la visualizzazione di un sottocampione dei dati (un campione casuale di punti dati, scelto senza sostituzione). Questa tecnica è nota come sottocampionamento.\n\n\n\nElementi testuali:\n\nI titoli, le etichette degli assi e il testo delle legende devono essere chiari e facilmente comprensibili.\nGli elementi della legenda dovrebbero essere ordinati in modo logico e coerente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "href": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "title": "16  Esplorare i dati numerici",
    "section": "\n16.6 Forma di una Distribuzione",
    "text": "16.6 Forma di una Distribuzione\nIn statistica, la forma di una distribuzione descrive come i dati sono distribuiti intorno ai valori centrali. Si distingue tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali e multimodali. Un’illustrazione grafica è fornita nella figura seguente. Nel pannello 1, la distribuzione è unimodale con asimmetria negativa; nel pannello 2, la distribuzione è unimodale con asimmetria positiva; nel pannello 3, la distribuzione è simmetrica e unimodale; nel pannello 4, la distribuzione è bimodale.\n\n\nDistribuzioni\n\nIl grafico della densità di kernel (Kernel Density Plot) dei valori BDI-II nel campione di Zetsche et al. (2019) è bimodale. Questo indica che le osservazioni della distribuzione si raggruppano in due cluster distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l’altro gruppo tende ad avere valori BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "href": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "title": "16  Esplorare i dati numerici",
    "section": "\n16.7 Indici di posizione",
    "text": "16.7 Indici di posizione\n\n16.7.1 Quantili\nLa distribuzione dei valori BDI-II di Zetsche et al. (2019) può essere sintetizzata attraverso l’uso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, \\(q_1\\), divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, \\(q_2\\), corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.\nInoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.\nPer calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di \\(np\\), dove \\(n\\) è la dimensione del campione e \\(p\\) è l’ordine del quantile. Se \\(np\\) non è un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\). Se \\(np\\) è un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(k\\) e \\(k+1\\), dove \\(k\\) è la parte intera di \\(np\\).\nGli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che è molto popolare e può essere utilizzata in alternativa ad un istogramma.\nAd esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di Zetsche et al. (2019), si determina il valore di \\(np = 9 \\cdot 0.5 = 4.5\\), che non è un intero. Pertanto, il valore del secondo quartile è pari al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\), ovvero \\(q_2 = x_{4 + 1} = 27\\). Per calcolare il quantile di ordine \\(2/3\\), si determina il valore di \\(np = 9 \\cdot 2/3 = 6\\), che è un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(6\\) e \\(7\\), ovvero \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\nUsiamo quantile() per trovare la soluzione dell’esercizio precedente.\n\nx = c(19, 26, 27, 28, 28, 33, 33, 41, 43)\nquantile(x, 2 / 3)\n#&gt; 66.66667% \n#&gt;        33",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "href": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "title": "16  Esplorare i dati numerici",
    "section": "\n16.8 Mostrare i dati",
    "text": "16.8 Mostrare i dati\n\n16.8.1 Diagramma a scatola\nIl box plot è uno strumento grafico che visualizza la dispersione di una distribuzione. I boxplot forniscono una rappresentazione visiva sintetica di cinque valori caratteristici: minimo, primo quartile (25%), mediana (50%), terzo quartile (75%) e massimo. Spesso però, i boxplot “ignorano” i valori considerati anomali (outlier), segnalandoli con punti isolati.\nPer creare un box plot, si disegna un rettangolo (la “scatola”) di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile (\\(q_{0.75}\\)) e il primo quartile (\\(q_{0.25}\\)). La mediana (\\(q_{0.5}\\)) è rappresentata da una linea all’interno del rettangolo.\nAi lati della scatola, vengono tracciati due segmenti di retta, detti “baffi”, che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore è il valore più basso tra le osservazioni che è maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore è il valore più alto tra le osservazioni che è minore o uguale al terzo quartile più 1.5 volte la distanza interquartile.\nSe ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati “valori anomali” e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.\n\n\n16.8.2 Stratificazione\nNell’analisi dei dati, è comune suddividere le osservazioni in gruppi in base ai valori di una o più variabili associate a tali osservazioni. Questo processo è chiamato stratificazione, e i gruppi risultanti sono detti strati. Ad esempio, nella sezione successiva, dividiamo i valori dei punteggi BDI-II in due gruppi in base alla condizione sperimentale: campione clinico e campione di controllo.\nLa stratificazione è particolarmente utile nella visualizzazione dei dati, poiché spesso siamo interessati a comprendere come la distribuzione di una variabile differisca tra diversi sottogruppi.\nPer esempio, per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo, possiamo utilizzare un box-plot. Questo tipo di grafico ci permette di confrontare visivamente la distribuzione dei punteggi tra i due gruppi, evidenziando eventuali differenze.\n\nggplot(df, aes(x = group, y = bdi)) +\n  geom_boxplot() +\n  labs(\n    title = \"Box plot per gruppo\", \n    x = \"Gruppo\", \n    y = \"BDI-II\"\n  )\n\n\n\n\n\n\n\nIn questo grafico:\n\nL’asse x rappresenta i due gruppi (pazienti e controllo).\nL’asse y rappresenta i punteggi BDI-II.\nI box (scatole) mostrano la distribuzione dei punteggi, con la linea centrale che indica la mediana e i “baffi” che rappresentano la variabilità dei dati.\n\nLa stratificazione ci aiuta a identificare rapidamente se ci sono differenze nella distribuzione dei punteggi BDI-II tra i due gruppi. Nel caso presente, il grafico mostra come non vi sia alcuna sovrapposizione tra le due distribuzioni.\nUn risultato migliore si ottiene utilizzando un grafico a violino (violin plot) e includendo anche i dati grezzi.\n\n16.8.3 Grafico a Violino\nI grafici a violino combinano le caratteristiche dei box plot e dei grafici di densità di kernel (KDE plot) per offrire una rappresentazione più dettagliata dei dati. A questi grafici vengono sovrapposti i dati grezzi, fornendo una visione completa della distribuzione e delle caratteristiche dei dati.\n\nggplot(df, aes(x = group, y = bdi, fill = group)) +\n  geom_violin() +\n  geom_dotplot(\n    binaxis = \"y\",\n    stackdir = \"center\",\n    dotsize = 0.5,\n    fill = 1\n  ) +\n  labs(\n    title = \"Violin plot con overlay dei punti grezzi\",\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  )\n\n\n\n\n\n\n\n\n16.8.4 Grafico Beeswarm\nIl pacchetto {ggbeeswarm} include una funzione chiamata geom_beeswarm, che può essere utilizzata per creare un grafico beeswarm in ggplot2.\nUn grafico beeswarm è una variazione del grafico a punti che disperde i dati in modo che non si sovrappongano, rendendo visibili tutti i singoli punti dati. Questo tipo di visualizzazione è particolarmente utile quando si desidera esaminare la distribuzione e la densità di un set di dati, senza ricorrere all’uso di barre d’errore o di scatole e baffi (boxplot), mantenendo un’alta leggibilità anche quando i set di dati sono densi.\n\nggplot(df, aes(x = group, y = bdi, color = group)) +\n  geom_beeswarm(cex = 2) +\n  labs(\n    title = \"Violin plot con overlay dei punti grezzi\",\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  )",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#riflessioni-conclusive",
    "href": "chapters/eda/05_exploring_numeric_data.html#riflessioni-conclusive",
    "title": "16  Esplorare i dati numerici",
    "section": "\n16.9 Riflessioni Conclusive",
    "text": "16.9 Riflessioni Conclusive\nAbbiamo esplorato diverse tecniche per sintetizzare e visualizzare i dati, includendo distribuzioni di frequenze, istogrammi e grafici di densità. Questi strumenti sono essenziali per comprendere meglio i dati e presentare risultati in modo chiaro e informativo. La visualizzazione dei dati ci aiuta a individuare possibili anomalie o situazioni inaspettate, prima di applicare modelli o interpretazioni statistiche.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#esercizi",
    "href": "chapters/eda/05_exploring_numeric_data.html#esercizi",
    "title": "16  Esplorare i dati numerici",
    "section": "\n16.10 Esercizi",
    "text": "16.10 Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nIn questo esercizio, gli studenti raccoglieranno e analizzeranno dati relativi alla Satisfaction With Life Scale (SWLS) (Diener et al., 1985) e alla Scala della Rete Sociale di Lubben (LSNS-6) (Lubben et al., 2006). L’obiettivo è comprendere la relazione tra la soddisfazione di vita e la qualità delle relazioni sociali, esplorando la distribuzione delle variabili e le possibili associazioni tra di esse.\nLa Scala della Rete Sociale di Lubben a 6 item (LSNS-6) è uno strumento utilizzato per valutare l’isolamento sociale negli adulti più anziani, misurando il supporto sociale percepito sia da parte dei familiari che degli amici. La scala comprende sei domande suddivise in due sezioni:\nFAMIGLIA: Considerando le persone a cui sei legato per nascita, matrimonio, adozione, ecc.\n\nQuanti parenti vedi o senti almeno una volta al mese?\nCon quanti parenti ti senti a tuo agio nel parlare di questioni personali?\nCon quanti parenti ti senti così vicino da poter chiedere loro aiuto?\n\nAMICIZIE: Considerando tutti i tuoi amici, inclusi quelli che vivono nel tuo quartiere\n\nQuanti dei tuoi amici vedi o senti almeno una volta al mese?\nCon quanti amici ti senti a tuo agio nel parlare di questioni personali?\nCon quanti amici ti senti così vicino da poter chiedere loro aiuto?\n\nLa scala di risposta è:\n\n0 = nessuno\n1 = uno\n2 = due\n3 = tre o quattro\n4 = da cinque a otto\n5 = nove o più\n\nIl punteggio totale della LSNS-6 si ottiene sommando i punteggi dei sei item, con un range che va da 0 a 30. Un punteggio di 12 o inferiore indica un rischio di isolamento sociale.\nDati da Raccogliere\nOgni studente dovrà raccogliere i seguenti dati su se stesso e sui membri del proprio gruppo TPV:\n\n\nstudent_id: Identificativo univoco dello studente.\n\n\ngroup: Gruppo di appartenenza (es. Gruppo 1, Gruppo 2, ecc.).\n\n\nswls: Punteggio totale sulla Satisfaction With Life Scale (SWLS).\n\n\ngender: Genere (M, F).\n\n\nlsns_total: Punteggio totale della Scala della Rete Sociale di Lubben (LSNS-6).\n\n\nlsns_family: Punteggio della sottoscala engagement with family members (somma degli item 1-3).\n\n\nlsns_friends: Punteggio della sottoscala engagement with friends (somma degli item 4-6).\n\nQueste variabili permetteranno di investigare come la soddisfazione di vita sia associata alla quantità e qualità delle relazioni sociali, distinguendo tra contatti con la famiglia e con gli amici.\nObiettivi dell’Analisi\nL’esercizio è strutturato in tre parti:\n\n\nEsplorazione dei dati e distribuzione delle variabili\n\n\nVisualizzazione e confronto tra gruppi\n\nAnalisi delle possibili associazioni tra SWLS e le componenti della rete sociale\n\nParte 1: Esplorazione dei Dati\n1.1 Caricamento e preparazione del dataset\n\nImporta il dataset swls_lsns_students.csv.\n\nSeleziona le variabili indicate sopra.\n\nControlla ed elimina eventuali duplicati.\n\nControlla ed elimina eventuali valori mancanti.\n\n# Caricamento del dataset\ndf &lt;- rio::import(here::here(\"data\", \"swls_lsns_students.csv\"))\n\n# Selezione delle variabili\ndf &lt;- df |&gt; dplyr::select(student_id, group, swls, gender, \n                          lsns_total, lsns_family, lsns_friends)\n\n# Rimozione dei duplicati\ndf &lt;- df[!duplicated(df$student_id), ]\n\n# Rimozione dei valori mancanti\ndf &lt;- df[complete.cases(df), ]\n1.2 Distribuzione delle variabili\n\nCalcola la distribuzione di frequenza per swls, lsns_total, lsns_family e lsns_friends:\n\nFrequenze assolute e relative\n\nFrequenze cumulative\n\n\n\n# Frequenze assolute e relative\ntable(df$swls)\nprop.table(table(df$swls))\n\ntable(df$lsns_total)\nprop.table(table(df$lsns_total))\n\nCrea un istogramma della distribuzione delle variabili.\n\nggplot(df, aes(x = swls)) +\n  geom_histogram(bins = 10, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione dei punteggi SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"Frequenza\")\nggplot(df, aes(x = lsns_total)) +\n  geom_histogram(bins = 10, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione dei punteggi LSNS-6 (totale)\",\n       x = \"Punteggio LSNS-6\",\n       y = \"Frequenza\")\n\nCostruisci la funzione di distribuzione empirica cumulativa (eCDF).\n\nggplot(df, aes(x = swls)) +\n  stat_ecdf(geom = \"step\", color = \"blue\") +\n  labs(title = \"Funzione di distribuzione empirica cumulativa SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"F(x)\")\n\nGenera la curva di densità kernel (KDE) per ogni variabile.\n\nggplot(df, aes(x = swls)) +\n  geom_density(fill = \"lightblue\", alpha = 0.5) +\n  labs(title = \"Curva di densità dei punteggi SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"Densità\")\nggplot(df, aes(x = lsns_total)) +\n  geom_density(fill = \"lightblue\", alpha = 0.5) +\n  labs(title = \"Curva di densità LSNS-6 (totale)\",\n       x = \"Punteggio LSNS-6\",\n       y = \"Densità\")\nParte 2: Confronto tra Gruppi\n\nCostruisci una tabella di contingenza per gender e livello di rete sociale (alta o bassa, separando sopra e sotto la mediana di lsns_total).\n\ndf &lt;- df |&gt; \n  mutate(lsns_level = ifelse(lsns_total &gt;= median(lsns_total), \"Alto\", \"Basso\"))\n\ntable(df$gender, df$lsns_level)\nprop.table(table(df$gender, df$lsns_level), margin = 1)\n\nCrea un grafico a barre per la distribuzione di lsns_level per genere.\n\nggplot(df, aes(x = lsns_level, fill = gender)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Distribuzione del livello di rete sociale per genere\",\n       x = \"Livello LSNS\",\n       y = \"Conteggio\",\n       fill = \"Genere\")\n\nCostruisci un box plot per confrontare swls tra i gruppi di rete sociale.\n\nggplot(df, aes(x = lsns_level, y = swls, fill = lsns_level)) +\n  geom_boxplot() +\n  labs(title = \"Distribuzione dei punteggi SWLS per livello di rete sociale\",\n       x = \"Livello di rete sociale\",\n       y = \"Punteggio SWLS\")\n\nUsa un violin plot per visualizzare la distribuzione dettagliata.\n\nggplot(df, aes(x = lsns_level, y = swls, fill = lsns_level)) +\n  geom_violin(alpha = 0.5) +\n  geom_jitter(width = 0.1, alpha = 0.5) +\n  labs(title = \"Violin plot con dati grezzi sovrapposti\",\n       x = \"Livello di rete sociale\",\n       y = \"Punteggio SWLS\")\nParte 3: Analisi delle Associazioni tra SWLS e la Rete Sociale\nIl concetto di correlazione verrà approfondito nel Capitolo 20. Per i nostri scopi attuali, possiamo considerarlo come un indice numerico che misura l’intensità e la direzione dell’associazione tra due variabili. Un valore di 0 indica l’assenza di una relazione lineare tra le variabili, mentre i valori +1 e -1 indicano una relazione lineare perfetta, positiva o negativa rispettivamente. I valori intermedi tra -1 e +1 rappresentano associazioni più deboli o forti, a seconda della loro vicinanza agli estremi.\n\n\nCorrelazioni tra SWLS e le sottoscale della LSNS.\n\ncor(df$swls, df$lsns_total, method = \"pearson\")\ncor(df$swls, df$lsns_family, method = \"pearson\")\ncor(df$swls, df$lsns_friends, method = \"pearson\")\nSpiega in maniera inuitiva il significato dei valori ottenuti.\n\n\nGrafico di dispersione tra SWLS e LSNS-6 totale.\n\nUn grafico di dispersione è un diagramma cartesiano in cui ogni punto rappresenta un’osservazione (nel caso attuale, uno studente). Le coordinate dei punti sui due assi, X e Y, indicano i valori delle due variabili considerate per ciascuno studente.\nggplot(df, aes(x = lsns_total, y = swls)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(title = \"Relazione tra rete sociale totale e SWLS\",\n       x = \"Punteggio LSNS-6 Totale\",\n       y = \"Punteggio SWLS\")\nPer ogni grafico generato, includi una descrizione chiara e concisa del suo significato in relazione ai dati analizzati.\nConclusioni\nL’obiettivo è analizzare se e come la soddisfazione di vita degli studenti universitari è influenzata dalle relazioni sociali, distinguendo tra engagement con la famiglia e con gli amici.\nConsegna\nConsegna il file .qmd contenente il codice, le visualizzazioni e le interpretazioni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "16  Esplorare i dati numerici",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] dslabs_0.8.0     ggbeeswarm_0.7.2 thematic_0.1.6   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.10.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt; [13] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     R.oo_1.27.0       rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    R.utils_2.12.3    mnormt_2.1.1      cli_3.6.4        \n#&gt; [17] rlang_1.1.5       R.methodsS3_1.8.2 munsell_0.5.1     withr_3.0.2      \n#&gt; [21] tools_4.4.2       parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1 \n#&gt; [25] pacman_0.5.1      vctrs_0.6.5       R6_2.6.1          lifecycle_1.0.4  \n#&gt; [29] htmlwidgets_1.6.4 vipor_0.4.7       beeswarm_0.4.0    pkgconfig_2.0.3  \n#&gt; [33] pillar_1.10.1     gtable_0.3.6      data.table_1.16.4 glue_1.8.0       \n#&gt; [37] xfun_0.50         tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2     \n#&gt; [41] htmltools_0.5.8.1 nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29   \n#&gt; [45] compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#bibliografia",
    "href": "chapters/eda/05_exploring_numeric_data.html#bibliografia",
    "title": "16  Esplorare i dati numerici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDiener, E., Emmons, R. A., Larsen, R. J., & Griffin, S. (1985). The Satisfaction With Life Scale. Journal of Personality Assessment, 49(1), 71–75. https://doi.org/10.1207/s15327752jpa4901_13\n\n\nLubben, J., Blozik, E., Gillmann, G., Iliffe, S., Renteln Kruse, W. von, Beck, J. C., & Stuck, A. E. (2006). Performance of an abbreviated version of the Lubben Social Network Scale among three European community-dwelling older adult populations. The Gerontologist, 46(4), 503–513. https://doi.org/10.1093/geront/46.4.503\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html",
    "href": "chapters/eda/06_data_visualization.html",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "",
    "text": "Introduzione\nIn questo capitolo saranno introdotti i principi fondamentali della visualizzazione dei dati, accompagnati da una descrizione sintetica. Per un approfondimento su ciascun principio, si consiglia di consultare il capitolo Data Visualization del libro Introduction to Data Science.\nUn altro aspetto che verrà affrontato riguarda gli errori, i bias, le imprecisioni sistematiche e altri problemi inattesi che spesso influenzano i dati. Questi elementi richiedono una gestione accurata e, poiché possono risultare difficili o impossibili da individuare direttamente in un dataset, la visualizzazione dei dati diventa uno strumento essenziale.\nL’aumento della disponibilità di dataset informativi e di strumenti software ha reso la visualizzazione dei dati sempre più rilevante in numerosi ambiti. La visualizzazione dei dati non solo consente di comunicare in modo efficace risultati basati sui dati, ma aiuta anche a motivare ulteriori analisi e a rilevare eventuali errori o imperfezioni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#unimmagine-vale-più-di-mille-parole",
    "href": "chapters/eda/06_data_visualization.html#unimmagine-vale-più-di-mille-parole",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "\n17.1 Un’immagine Vale Più di Mille Parole",
    "text": "17.1 Un’immagine Vale Più di Mille Parole\nOsservare numeri e stringhe di caratteri che definiscono un dataset raramente è utile. Per convincerci di questo, stampiamo e osserviamo la tabella dei dati sugli omicidi con armi da fuoco negli Stati Uniti:\n\nhead(murders)\n#&gt;        state abb region population total\n#&gt; 1    Alabama  AL  South    4779736   135\n#&gt; 2     Alaska  AK   West     710231    19\n#&gt; 3    Arizona  AZ   West    6392017   232\n#&gt; 4   Arkansas  AR  South    2915918    93\n#&gt; 5 California  CA   West   37253956  1257\n#&gt; 6   Colorado  CO   West    5029196    65\n\nCosa impariamo guardando questa tabella? Quanto velocemente riusciamo a determinare quali stati hanno le popolazioni più numerose? E quali hanno le più piccole? Quanto è grande uno stato “tipico”? Esiste una relazione tra la dimensione della popolazione e il numero totale di omicidi? Come variano i tassi di omicidio tra le diverse regioni del paese? Per la maggior parte di noi, è piuttosto difficile estrarre queste informazioni semplicemente guardando i numeri. Al contrario, le risposte a tutte queste domande sono immediatamente evidenti osservando questo grafico:\n\n\n\n\n\n\n\n\nQuesto ci ricorda il detto “un’immagine vale più di mille parole”. La visualizzazione dei dati offre un modo potente per comunicare una scoperta basata sui dati. In alcuni casi, la visualizzazione è così convincente che non è necessario alcun follow-up analitico.\n\nEsempio 17.1 Rispondiamo alle domande precedenti sulla base della visualizzazione dei dati.\n\nQuali stati hanno le popolazioni più numerose? Guardando il grafico, possiamo notare immediatamente che gli stati con le popolazioni più alte si trovano verso il lato destro dell’asse x (poiché la scala è logaritmica). Gli stati con le popolazioni più numerose sono California, Texas, e New York.\nQuali stati hanno le popolazioni più piccole? Gli stati con le popolazioni più piccole si trovano verso il lato sinistro dell’asse x. Questi includono Wyoming, Vermont, e Alaska.\nQuanto è grande uno stato “tipico”? Un modo per stimare una dimensione “tipica” è guardare la densità delle osservazioni sull’asse x. La maggior parte degli stati si trova intorno a un milione di abitanti, ma ci sono anche molti stati con popolazioni comprese tra 5 e 10 milioni di abitanti. Quindi, uno stato “tipico” potrebbe avere una popolazione di circa 5-10 milioni di persone.\nEsiste una relazione tra la dimensione della popolazione e il numero totale di omicidi? Sì, esiste una chiara relazione positiva tra la dimensione della popolazione e il numero totale di omicidi. Lo si può vedere dal fatto che gli stati con popolazioni più grandi tendono ad avere un numero maggiore di omicidi. Tuttavia, questa relazione non è perfetta: alcuni stati con popolazioni simili mostrano differenze significative nel numero di omicidi, suggerendo che altri fattori oltre alla popolazione influenzano i tassi di omicidio.\n\nCome variano i tassi di omicidio tra le diverse regioni del paese? Il grafico utilizza colori diversi per rappresentare le regioni geografiche degli stati. Osservando la distribuzione dei punti per colore, possiamo notare alcune differenze:\n\n\nSud: Gli stati del Sud tendono ad avere tassi di omicidio più alti rispetto alle altre regioni.\n\nNord-Est: Gli stati del Nord-Est mostrano una variazione moderata nei tassi di omicidio, ma in generale sono inferiori a quelli del Sud.\n\nOvest: Gli stati dell’Ovest presentano una vasta gamma di tassi di omicidio, con alcuni stati come California e Texas che registrano numeri elevati a causa della loro grande popolazione.\n\nMidwest: I tassi di omicidio nei stati del Midwest sembrano essere generalmente bassi o moderati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "href": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "\n17.2 Codificare i dati attraverso segnali visivi",
    "text": "17.2 Codificare i dati attraverso segnali visivi\nIniziamo con una panoramica dei principali segnali visivi utilizzati per codificare i dati: posizione, lunghezza, angoli, area, luminosità e tonalità del colore. Tra questi, posizione e lunghezza sono i segnali visivi più efficaci e intuitivi, poiché il cervello umano è particolarmente abile nel riconoscere variazioni spaziali. Questo rende la posizione e la lunghezza strumenti potenti per la rappresentazione quantitativa. In altre parole, le persone riescono a confrontare con maggiore precisione altezze e lunghezze (come le barre in un barplot) rispetto ad angoli o aree (come in un grafico a torta).\nAngoli e aree, sebbene comunemente usati, sono segnali visivi meno efficaci. Grafici come i pie chart, che si basano su angoli e aree per rappresentare quantità, risultano spesso meno precisi e più difficili da interpretare, specialmente quando le differenze sono piccole. Anche l’uso dell’area, ad esempio nei bubble plot, può distorcere la percezione delle differenze tra i dati, a meno che non venga gestita correttamente. Anche se l’area di una bolla può essere proporzionale al valore rappresentato, la percezione umana tende a sovrastimare le differenze tra aree più grandi.\nLuminosità e tonalità del colore sono utili per rappresentare variabili qualitative o categoriali, ma possono risultare difficili da interpretare quando si tratta di confrontare quantità precise. Tuttavia, il colore gioca un ruolo cruciale nelle visualizzazioni multidimensionali, come le heatmap, dove è necessario rappresentare più di due variabili contemporaneamente. È importante, però, usare il colore con attenzione, soprattutto per garantire l’accessibilità a persone con problemi di daltonismo.\nLe tabelle sono utili quando si ha una quantità limitata di dati e si richiede una precisione numerica rigorosa. Tuttavia, per set di dati più grandi o per evidenziare tendenze e differenze, i grafici (come i barplot) sono generalmente più efficaci. Le tabelle non offrono lo stesso impatto visivo immediato e rendono più difficile l’individuazione di pattern complessi.\n\n17.2.1 Ulteriori considerazioni sulla scelta della visualizzazione\nLa scelta della visualizzazione più appropriata dipende sia dalla natura dei dati che dallo scopo della comunicazione. Per esempio:\n\n\nBarplot o dot plot sono ideali per confrontare valori quantitativi tra categorie.\n\nIstogrammi, boxplot e raincloud plots sono più adatti per descrivere la distribuzione di dati continui e fare confronti tra categorie.\n\nGrafici di dispersione (scatter plot) sono eccellenti per esplorare relazioni tra due variabili continue.\n\nLa chiarezza e la leggibilità sono principi fondamentali nella creazione di visualizzazioni efficaci. L’aggiunta di elementi visivi eccessivi, come decorazioni superflue o troppi colori, può distrarre dal messaggio principale. Un buon grafico deve essere semplice, ma allo stesso tempo completo, includendo solo gli elementi visivi necessari per trasmettere il messaggio desiderato.\nIn conclusione, scegliere i segnali visivi adeguati e il tipo di grafico più appropriato non solo migliora l’accuratezza della comunicazione, ma rende le informazioni più accessibili e comprensibili per il pubblico.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#quando-includere-lo-zero",
    "href": "chapters/eda/06_data_visualization.html#quando-includere-lo-zero",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "\n17.3 Quando includere lo zero",
    "text": "17.3 Quando includere lo zero\nQuando si usa la lunghezza come segnale visivo, come nei barplot, è essenziale che l’asse parta da zero. Non farlo può essere fuorviante e far sembrare le differenze più grandi di quanto non siano in realtà. Questo errore viene spesso sfruttato nei media per esagerare differenze apparentemente significative.\nTuttavia, quando si usa la posizione (ad esempio in un grafico a dispersione), non è sempre necessario includere lo zero, soprattutto se l’interesse principale è il confronto tra gruppi rispetto alla variabilità interna.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-le-distorsioni",
    "href": "chapters/eda/06_data_visualization.html#evitare-le-distorsioni",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "\n17.4 Evitare le distorsioni",
    "text": "17.4 Evitare le distorsioni\nUna distorsione comune si verifica quando le differenze tra quantità sono rappresentate utilizzando aree, come nei bubble plot, dove il raggio dei cerchi è proporzionale al dato. Il problema è che, poiché l’area di un cerchio è proporzionale al quadrato del raggio, le differenze sembrano molto più ampie di quanto siano realmente. Per evitare queste distorsioni, è meglio utilizzare la posizione o la lunghezza, come in un grafico a barre, per confrontare direttamente le quantità.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#ordinare-le-categorie",
    "href": "chapters/eda/06_data_visualization.html#ordinare-le-categorie",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "\n17.5 Ordinare le categorie",
    "text": "17.5 Ordinare le categorie\nQuando si visualizzano categorie, come nei barplot o nei boxplot, è opportuno ordinarle in base al valore della variabile di interesse, anziché in ordine alfabetico. Questo aiuta a evidenziare pattern significativi e facilita il confronto tra categorie.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-i-dynamite-plots",
    "href": "chapters/eda/06_data_visualization.html#evitare-i-dynamite-plots",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "\n17.6 Evitare i Dynamite Plots",
    "text": "17.6 Evitare i Dynamite Plots\nI dynamite plots, che mostrano la media e l’errore standard (o la deviazione standard), sono spesso utilizzati in psicologia ma sono fuorvianti. Questi grafici tendono a esagerare le differenze e possono indurre false interpretazioni. È preferibile mostrare tutti i dati, ad esempio tramite un dot plot, che fornisce un’immagine più chiara della distribuzione dei dati (Butler, 2022).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#facilitare-i-confronti",
    "href": "chapters/eda/06_data_visualization.html#facilitare-i-confronti",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "\n17.7 Facilitare i confronti",
    "text": "17.7 Facilitare i confronti\nQuando si confrontano due distribuzioni, come in un istogramma, è fondamentale mantenere gli stessi assi per entrambi i grafici. Se le distribuzioni sono presentate su assi con scale diverse, il confronto diventa difficile e potrebbe portare a conclusioni errate. Allineare i grafici verticalmente o orizzontalmente consente di percepire più facilmente le differenze tra i gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#trasformazioni-logaritmiche",
    "href": "chapters/eda/06_data_visualization.html#trasformazioni-logaritmiche",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "\n17.8 Trasformazioni logaritmiche",
    "text": "17.8 Trasformazioni logaritmiche\nLe trasformazioni logaritmiche sono utili quando si lavora con dati distribuiti su più ordini di grandezza o quando le variazioni tra le quantità sono moltiplicative (West, 2022). L’uso della scala logaritmica in un grafico a barre o a dispersione può ridurre le distorsioni visive e migliorare l’interpretazione dei dati. Questo approccio è particolarmente utile quando alcuni valori estremi potrebbero dominare il grafico, nascondendo dettagli rilevanti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#codificare-una-terza-variabile",
    "href": "chapters/eda/06_data_visualization.html#codificare-una-terza-variabile",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "\n17.9 Codificare una terza variabile",
    "text": "17.9 Codificare una terza variabile\nPer rappresentare tre variabili, è possibile utilizzare un grafico di dispersione con variabili codificate attraverso dimensioni aggiuntive come il colore, la dimensione o la forma dei punti. Ad esempio, in un grafico che confronta aspettativa di vita e reddito, la dimensione dei punti potrebbe rappresentare la popolazione e il colore la regione geografica. Quando si utilizza il colore per rappresentare una variabile, è importante scegliere palette cromatiche accessibili anche per chi è affetto da daltonismo, evitando combinazioni problematiche come rosso-verde.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-pseudo-tre-dimensioni",
    "href": "chapters/eda/06_data_visualization.html#evitare-pseudo-tre-dimensioni",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "\n17.10 Evitare pseudo-tre dimensioni",
    "text": "17.10 Evitare pseudo-tre dimensioni\nGrafici tridimensionali, come barre o pie chart 3D, spesso aggiungono confusione senza fornire informazioni aggiuntive significative. Sebbene visivamente accattivanti, questi grafici distorcono la percezione e rendono difficile l’interpretazione accurata dei dati. È preferibile mantenere le visualizzazioni bidimensionali, a meno che la terza dimensione non rappresenti effettivamente una variabile aggiuntiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#scegliere-il-numero-giusto-di-cifre-significative",
    "href": "chapters/eda/06_data_visualization.html#scegliere-il-numero-giusto-di-cifre-significative",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "\n17.11 Scegliere il numero giusto di cifre significative",
    "text": "17.11 Scegliere il numero giusto di cifre significative\nÈ importante evitare l’uso di troppe cifre decimali nelle tabelle e nei grafici. Spesso, una o due cifre significative sono sufficienti per rappresentare accuratamente i dati, mentre l’aggiunta di cifre inutili può confondere il lettore e dare un falso senso di precisione. Limitiamoci a mostrare solo le cifre necessarie per trasmettere il messaggio in modo chiaro.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#conoscere-il-pubblico",
    "href": "chapters/eda/06_data_visualization.html#conoscere-il-pubblico",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "\n17.12 Conoscere il pubblico",
    "text": "17.12 Conoscere il pubblico\nInfine, è fondamentale adattare la visualizzazione dei dati al pubblico di riferimento. Grafici progettati per l’analisi esplorativa interna possono contenere dettagli tecnici complessi, ma quando si comunica a un pubblico più ampio o non specializzato, è necessario semplificare. Ad esempio, utilizzare una scala logaritmica può essere utile per un pubblico esperto, ma confondere un pubblico generale. In questi casi, mantenere la scala lineare e spiegare chiaramente i dati aiuta a evitare malintesi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#riflessioni-conclusive",
    "href": "chapters/eda/06_data_visualization.html#riflessioni-conclusive",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "\n17.13 Riflessioni Conclusive",
    "text": "17.13 Riflessioni Conclusive\nI principi di visualizzazione dei dati presentati in questo capitolo rappresentano strumenti essenziali per garantire chiarezza, precisione e trasparenza nella rappresentazione delle informazioni. La corretta applicazione di questi principi non solo migliora la comprensione dei dati, ma riduce anche il rischio di distorsioni e interpretazioni errate.\nEcco le linee guida principali da seguire nella creazione di visualizzazioni efficaci:\n\n\nEvitare distorsioni: Scegliere grafici semplici, come i barplot, evitando rappresentazioni che possono alterare la percezione delle proporzioni, ad esempio cerchi o pie chart.\n\n\nIncludere lo zero: Nei barplot, l’asse verticale deve sempre partire da zero, altrimenti si rischia di trasmettere informazioni fuorvianti.\n\n\nOrdinare le categorie: Le categorie dovrebbero essere ordinate in base ai valori (non alfabeticamente), per facilitare il confronto visivo.\n\n\nMostrare i dati: Sostituire grafici come i dynamite plots con rappresentazioni che evidenzino tutti i dati disponibili, ad esempio dot plot o strip chart.\n\n\nFacilitare i confronti: Quando si confrontano distribuzioni, è importante utilizzare assi comuni per garantire una corretta interpretazione.\n\n\nUtilizzare trasformazioni logaritmiche: Queste trasformazioni sono utili quando i dati coprono diversi ordini di grandezza, rendendoli più interpretabili.\n\n\nCodificare una terza variabile: Nei grafici a dispersione, si possono rappresentare ulteriori informazioni utilizzando colore, dimensione o forma dei punti.\n\n\nEvitare pseudo-3D: I grafici tridimensionali spesso confondono e distorcono i dati; è preferibile mantenere rappresentazioni bidimensionali.\n\n\nLimitare le cifre significative: Ridurre il numero di decimali presentati per evitare complessità inutili e migliorare la leggibilità.\n\n\nAdattarsi al pubblico: Semplificare le visualizzazioni in base al livello di competenza e conoscenza del pubblico, per garantire un messaggio chiaro e comprensibile.\n\nLa scelta appropriata di grafici, segnali visivi e trasformazioni è cruciale per comunicare i risultati in modo efficace e responsabile. Seguendo questi principi, è possibile creare visualizzazioni che non solo rappresentano i dati in modo accurato, ma supportano anche un’interpretazione informata e consapevole.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#esercizi",
    "href": "chapters/eda/06_data_visualization.html#esercizi",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "\n17.14 Esercizi",
    "text": "17.14 Esercizi\n\n\n\n\n\n\nEsercizi\n\n\n\n\n\nIn questo esercizio analizzerai i dati raccolti dagli studenti sulla Satisfaction With Life Scale (SWLS) e sulla Lubben Social Network Scale (LSNS-6). Le variabili incluse sono:\n\n\nSWLS: Punteggio totale della Scala di Soddisfazione per la Vita.\n\nLSNS-6: Punteggio totale sulla scala della rete sociale.\n\nGenere: Maschio/Femmina.\n\nTipo di scuola superiore: Liceo classico o scientifico vs. altro.\n\nNumero di amici: Auto-riferito.\n\nNumero di uscite settimanali con gli amici.\n\nUtilizzerai questi dati per esplorare le distribuzioni, creare visualizzazioni efficaci e interpretare i risultati.\nEsercizi Teorici\n\n\nPrincipi della visualizzazione\n\nQuali sono i principali segnali visivi utilizzati nella visualizzazione dei dati? Fornisci un esempio pratico per ognuno.\nPerché la posizione e la lunghezza sono considerati segnali visivi più efficaci rispetto all’area e agli angoli?\nSpiega perché i grafici tridimensionali (3D) sono spesso inutili o fuorvianti.\n\n\n\nScelta della visualizzazione\n\nQuale tipo di grafico useresti per mostrare la distribuzione della variabile SWLS? Giustifica la tua risposta.\nSe volessi confrontare la distribuzione della SWLS tra due gruppi (ad esempio, in base al genere), quale grafico useresti? Perché?\n\n\n\nErrori comuni nella visualizzazione\n\nPerché i dynamite plots (grafici a barre con errore standard) sono considerati una cattiva pratica?\nSpiega perché è importante iniziare l’asse Y da zero in un barplot.\nPerché è preferibile ordinare le categorie in base ai valori invece che alfabeticamente?\n\n\n\nEsercizi Pratici in R\n1. Caricamento e ispezione dei dati\nCarica il dataset raccolto dagli studenti (dati_SWLS_LSNS.csv) e stampa un’anteprima dei dati.\n# Caricamento dei dati\ndf &lt;- read.csv(\"dati_SWLS_LSNS.csv\")\n\n# Esamina le prime righe\nhead(df)\nRispondi alle seguenti domande:\n\nQuante osservazioni ci sono nel dataset?\nCi sono valori mancanti? Se sì, quanti?\n\n2. Distribuzione delle variabili\nCrea le seguenti visualizzazioni per analizzare la distribuzione di SWLS e LSNS-6:\n\n\nIstogramma con sovrapposta la curva di densità.\n\nFunzione di distribuzione cumulativa empirica (eCDF).\n\nBox plot per la variabile SWLS.\n\n3. Confronto tra gruppi\n\nCrea un box plot della SWLS per genere.\nCrea un violin plot della LSNS-6 in base al tipo di scuola superiore.\n\n4. Relazioni tra variabili\n\nCrea un grafico di dispersione (scatter plot) per verificare se c’è una relazione tra il punteggio SWLS e il numero di amici.\nAggiungi una linea di regressione al grafico per facilitare l’interpretazione.\n\nggplot(df, aes(x = numero_amici, y = SWLS)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Relazione tra SWLS e numero di amici\",\n       x = \"Numero di amici\",\n       y = \"Satisfaction With Life Scale (SWLS)\")\nDomande:\n\nQuale relazione osservi tra il numero di amici e la SWLS?\nIl numero di amici è un buon predittore della soddisfazione per la vita?\n\n5. Esplorazione della rete sociale\n\nCrea un barplot per mostrare la distribuzione delle risposte medie ai sei item della LSNS-6.\nEsplora la relazione tra la frequenza delle uscite settimanali e il punteggio totale LSNS-6 utilizzando un box plot.\n\nConsegna\nSalva i grafici creati e rispondi alle domande in forma scritta. Carica il file su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Risposte alle domande teoriche\nPrincipi della visualizzazione\n\nI segnali visivi principali sono posizione, lunghezza, angoli, area, luminosità e colore.\nLa posizione e lunghezza sono i segnali più efficaci perché l’occhio umano è molto preciso nel confrontare distanze e altezze, mentre è meno efficace nel confrontare angoli e aree.\nI grafici tridimensionali (3D) spesso aggiungono confusione senza migliorare la leggibilità.\n\nScelta della visualizzazione\n\nPer mostrare la distribuzione della SWLS, è preferibile usare istogrammi e box plot perché evidenziano la forma della distribuzione e la presenza di outlier.\nPer confrontare la SWLS tra generi, un box plot o violin plot è l’opzione migliore, perché mostra la distribuzione completa.\n\nErrori comuni\n\nI dynamite plots nascondono la distribuzione dei dati e non mostrano la variabilità interna ai gruppi.\nIn un barplot, l’asse Y deve iniziare da zero per evitare distorsioni visive.\nLe categorie nei barplot devono essere ordinate per valore per facilitare il confronto.\n\n2. Soluzioni pratiche in R\nCaricamento dei dati\ndf &lt;- read.csv(\"dati_SWLS_LSNS.csv\")\n\n# Esamina il dataset\ndim(df)  # Numero di righe e colonne\nsum(is.na(df))  # Conteggio valori mancanti\nDistribuzione delle variabili\nggplot(df, aes(x = SWLS)) +\n  geom_histogram(\n  aes(y = after_stat(density)), bins = 10, fill = \"blue\", alpha = 0.5\n  ) +\n  geom_density(color = \"red\", size = 1.2)\nggplot(df, aes(SWLS)) +\n  stat_ecdf(geom = \"step\")\nggplot(df, aes(x = \"\", y = SWLS)) +\n  geom_boxplot() +\n  coord_flip()\nConfronto tra gruppi\nggplot(df, aes(x = genere, y = SWLS, fill = genere)) +\n  geom_boxplot()\nggplot(df, aes(x = scuola, y = LSNS6, fill = scuola)) +\n  geom_violin()\nRelazioni tra variabili\nggplot(df, aes(x = numero_amici, y = SWLS)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\nggplot(df, aes(x = uscite_settimanali, y = LSNS6)) +\n  geom_boxplot()\nConclusioni\n(Ad esempio) Le visualizzazioni mostrano che:\n\nSWLS e LSNS-6 variano in base al genere e al tipo di scuola.\nIl numero di amici ha un impatto positivo sulla SWLS, ma la relazione è moderata.\nIl numero di uscite settimanali è correlato positivamente con la rete sociale (LSNS-6).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#bibliografia",
    "href": "chapters/eda/06_data_visualization.html#bibliografia",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nButler, R. C. (2022). Popularity leads to bad habits: Alternatives to «the statistics» routine of significance,«alphabet soup» and dynamite plots. In Annals of Applied Biology (Fasc. 2; Vol. 180, pp. 182–195). Wiley Online Library.\n\n\nHealy, K. (2018). Data visualization: a practical introduction. Princeton University Press.\n\n\nWest, R. M. (2022). Best practice in statistics: The use of log transformation. Annals of Clinical Biochemistry, 59(3), 162–165.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".\n\n\nWilke, C. O. (2019). Fundamentals of data visualization: a primer on making informative and compelling figures. O’Reilly Media.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html",
    "href": "chapters/eda/07_loc_scale.html",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "",
    "text": "18.1 Introduzione\nLa visualizzazione grafica dei dati rappresenta il pilastro fondamentale di ogni analisi quantitativa. Grazie alle rappresentazioni grafiche adeguate, è possibile individuare importanti caratteristiche di una distribuzione, quali la simmetria o l’asimmetria, nonché la presenza di una o più mode. Successivamente, al fine di descrivere sinteticamente le principali caratteristiche dei dati, si rende necessario l’utilizzo di specifici indici numerici. In questo capitolo, verranno presentati i principali indicatori della statistica descrittiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "href": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.2 Indici di Tendenza Centrale",
    "text": "18.2 Indici di Tendenza Centrale\nGli indici di tendenza centrale sono misure statistiche che cercano di rappresentare un valore tipico o centrale all’interno di un insieme di dati. Sono utilizzati per ottenere una comprensione immediata della distribuzione dei dati senza dover analizzare l’intero insieme. Gli indici di tendenza centrale sono fondamentali nell’analisi statistica, in quanto forniscono una sintesi semplice e comprensibile delle caratteristiche principali di un insieme di dati. I principali indici di tendenza centrale sono:\n\n\nMedia: La media è la somma di tutti i valori divisa per il numero totale di valori. È spesso utilizzata come misura generale di tendenza centrale, ma è sensibile agli estremi (valori molto alti o molto bassi).\n\nMediana: La mediana è il valore che divide l’insieme di dati in due parti uguali. A differenza della media, non è influenzata da valori estremi ed è quindi più robusta in presenza di outlier.\n\nModa: La moda è il valore che appare più frequentemente in un insieme di dati. In alcuni casi, può non essere presente o esserci più di una moda.\n\nLa scelta dell’indice di tendenza centrale appropriato dipende dalla natura dei dati e dall’obiettivo dell’analisi. Ad esempio, la mediana potrebbe essere preferita alla media se l’insieme di dati contiene valori anomali che potrebbero distorcere la rappresentazione centrale. La conoscenza e l’applicazione corretta di questi indici possono fornire una preziosa intuizione sulle caratteristiche centrali di una distribuzione di dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#moda",
    "href": "chapters/eda/07_loc_scale.html#moda",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.3 Moda",
    "text": "18.3 Moda\nLa moda (\\(\\text{Mo}\\)) rappresenta il valore della variabile che compare con maggiore frequenza in una distribuzione. In altre parole, è il valore più ricorrente nei dati.\n\nNelle distribuzioni unimodali, esiste una sola moda, che coincide con il valore centrale della distribuzione più frequente.\n\nTuttavia, in alcune distribuzioni, possono emergere più di una moda, rendendole multimodali. In questi casi, la moda perde il suo significato di indicatore unico di tendenza centrale, poiché la presenza di più valori con frequenze elevate rende difficile individuare un singolo punto di riferimento.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#mediana",
    "href": "chapters/eda/07_loc_scale.html#mediana",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.4 Mediana",
    "text": "18.4 Mediana\nLa mediana (\\(\\tilde{x}\\)) corrisponde al valore che divide il campione in due metà: il 50% dei dati è inferiore o uguale alla mediana e il restante 50% è superiore o uguale. A differenza della media, la mediana è meno influenzata dai valori estremi, rendendola una misura particolarmente robusta in presenza di dati asimmetrici o outlier.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#media",
    "href": "chapters/eda/07_loc_scale.html#media",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.5 Media",
    "text": "18.5 Media\nLa media aritmetica di un insieme di valori rappresenta il punto centrale o il baricentro della distribuzione dei dati. È calcolata come la somma di tutti i valori divisa per il numero totale di valori, ed è espressa dalla formula:\n\\[\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i,\n\\tag{18.1}\\]\ndove \\(x_i\\) rappresenta i valori nell’insieme, \\(n\\) è il numero totale di valori, e \\(\\sum\\) indica la sommatoria.\n\n18.5.1 Proprietà della Media\nUna proprietà fondamentale della media è che la somma degli scarti di ciascun valore dalla media è zero:\n\\[\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\tag{18.2}\\]\nInfatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]\nQuesta proprietà implica che i dati sono equamente distribuiti intorno alla media.\n\n18.5.2 La media come Centro di Gravità dell’Istogramma\nLa media aritmetica può essere interpretata come il centro di gravità o il punto di equilibrio della distribuzione dei dati. In termini fisici, il centro di gravità è il punto in cui la massa di un sistema è equilibrata o concentrata.\nIn termini statistici, possiamo considerare la media come il punto in cui la distribuzione dei dati è in equilibrio. Ogni valore dell’insieme di dati può essere visto come un punto materiale con una massa proporzionale al suo valore. Se immaginiamo questi punti disposti su una linea, con valori più grandi a destra e più piccoli a sinistra, la media corrisponderà esattamente al punto in cui la distribuzione sarebbe in equilibrio.\n\n18.5.3 Principio dei Minimi Quadrati\nLa posizione della media minimizza la somma delle distanze quadrate dai dati, un principio noto come “metodo dei minimi quadrati”. Matematicamente, questo si traduce nel fatto che la somma dei quadrati degli scarti tra ciascun valore e la media è minima. Questo principio è alla base dell’analisi statistica dei modelli di regressione e conferma l’interpretazione della media come centro di gravità dell’istogramma.\n\n18.5.4 Calcolo della Media con R\n\nPer calcolare la media di un piccolo numero di valori in R, possiamo utilizzare la somma di questi valori e dividerla per il numero totale di elementi. Consideriamo ad esempio i valori 12, 44, 21, 62, 24:\n\n(12 + 44 + 21 + 62 + 24) / 5\n#&gt; [1] 32.6\n\novvero\n\nx &lt;- c(12, 44, 21, 62, 24)\nmean(x)\n#&gt; [1] 32.6\n\n\n18.5.5 Le Proporzioni Sono Medie\nSe una collezione consiste solo di uni e zeri, allora la somma della collezione è il numero di uni in essa, e la media della collezione è la proporzione di uni.\n\nzero_one &lt;- c(1, 1, 1, 0)\nresult &lt;- mean(zero_one)\nresult\n#&gt; [1] 0.75\n\nÈ possibile sostituire 1 con il valore booleano True e 0 con False:\n\nmean(c(TRUE, TRUE, TRUE, FALSE))\n#&gt; [1] 0.75\n\n\n18.5.6 Limiti della Media Aritmetica\nLa media aritmetica, tuttavia, ha alcune limitazioni: non sempre è l’indice più adeguato per descrivere accuratamente la tendenza centrale della distribuzione, specialmente quando si verificano asimmetrie o valori anomali (outlier). In queste situazioni, è più indicato utilizzare la mediana o la media spuntata (come spiegheremo successivamente).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#come-descrivere-la-tendenza-centrale-in-distribuzioni-asimmetriche",
    "href": "chapters/eda/07_loc_scale.html#come-descrivere-la-tendenza-centrale-in-distribuzioni-asimmetriche",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.6 Come Descrivere la Tendenza Centrale in Distribuzioni Asimmetriche",
    "text": "18.6 Come Descrivere la Tendenza Centrale in Distribuzioni Asimmetriche\nIl diverso significato degli indici di tendenza centrale – moda, media e mediana – diventa evidente quando si analizzano distribuzioni asimmetriche. Per illustrare questo concetto, utilizzeremo i dati del Progetto Natsal, contenuti nel file sexual-partners.csv.\nNegli anni ’80, con la crescente preoccupazione per l’AIDS, le autorità sanitarie del Regno Unito si resero conto della mancanza di dati affidabili sui comportamenti sessuali della popolazione. In particolare, vi erano dubbi sulla frequenza con cui le persone cambiavano partner, sul numero di partner simultanei e sulle pratiche sessuali adottate. Questa conoscenza era essenziale per prevedere la diffusione delle malattie sessualmente trasmissibili nella società e per pianificare adeguatamente i servizi sanitari. Tuttavia, si faceva ancora riferimento ai dati raccolti da Alfred Kinsey negli Stati Uniti negli anni ’40, che non tenevano conto della rappresentatività del campione.\nA partire dalla fine degli anni ’80, vennero dunque avviati nel Regno Unito e negli Stati Uniti ampi e rigorosi studi sui comportamenti sessuali, nonostante una forte opposizione in alcuni ambienti. Nel Regno Unito, il governo guidato da Margaret Thatcher ritirò il proprio sostegno a un’importante indagine sui comportamenti sessuali all’ultimo momento. Fortunatamente, i ricercatori riuscirono a ottenere finanziamenti da enti benefici, dando vita al National Sexual Attitudes and Lifestyles Survey (Natsal). Da allora, questa indagine viene condotta ogni dieci anni, a partire dal 1990. La terza rilevazione, denominata Natsal-3, è stata effettuata intorno al 2010.\nPoniamoci il problema di descrivere la tendenza centrale per i dati contenuti nel file sexual-partners.csv, separatamente per maschi e femmine. Il dataset fornisce la distribuzione del numero totale dichiarato di partner sessuali di sesso opposto nella vita per uomini e donne di età compresa tra 35 e 44 anni. I dati provengono dal sondaggio Natsal-3 e corrispondono a un totale di 796 uomini e 1193 donne.\nProcediamo all’importazione dei dati per iniziare l’analisi.\n\ndf &lt;- rio::import(here::here(\"data\", \"sexual-partners.csv\"))\n\nEsaminiamo alcune righe prese a caso dal data frame df:\n\ndf[sample(1:nrow(df), size = 10, replace = FALSE), ]\n#&gt;      Gender NumPartners\n#&gt; 561     Man          15\n#&gt; 321     Man           6\n#&gt; 1177  Woman           3\n#&gt; 1098  Woman           2\n#&gt; 1252  Woman           4\n#&gt; 1170  Woman           3\n#&gt; 634     Man          21\n#&gt; 49      Man           1\n#&gt; 1152  Woman           3\n#&gt; 1327  Woman           5\n\nLa colonna Gender riporta il genere del rispondente e la colonna NumPartners il numero di partner sessuali di sesso opposto dichiarati.\nEsaminiamo la numerosità di ciascun gruppo.\n\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarize(count = n())\n#&gt; # A tibble: 2 × 2\n#&gt;   Gender count\n#&gt;   &lt;chr&gt;  &lt;int&gt;\n#&gt; 1 Man      796\n#&gt; 2 Woman   1193\n\nPoniamoci innnanzitutto il problema di visualizzare i dati con un istogramma, separatamente per maschi e femmine. Per ragioni di spazio ci limiteremo ad un numero massimo di partner sessuali di 50 (ma in questo campione il numero massimo arriva a 501 per gli uomini e 550 per le donne):\n\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarize(maximum = max(NumPartners))\n#&gt; # A tibble: 2 × 2\n#&gt;   Gender maximum\n#&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1 Man        501\n#&gt; 2 Woman      550\n\nIniziamo calcolando la percentuale di intervistati per ciascun valore possibile della variabile “numero di partner sessuali”, compreso tra 0 e 50. Il calcolo verrà svolto in due passaggi:\n\nConteggio delle frequenze assolute: Per ogni valore della variabile “numero di partner sessuali” e per ciascun gruppo di genere (uomini e donne), contiamo quante volte quel valore compare nei dati.\nCalcolo delle percentuali relative: Per ciascun gruppo di genere, dividiamo il conteggio di ogni valore per il totale delle osservazioni nel gruppo e moltiplichiamo per 100 per ottenere la percentuale.\n\n\n# Filtra i dati troncando il numero di partner a 50\ndf_truncated &lt;- df[df$NumPartners &lt;= 50, ]\n\n# Calcola il conteggio per ciascun genere e numero di partner\ncounts_data &lt;- df_truncated %&gt;%\n  group_by(Gender, NumPartners) %&gt;%  # Raggruppa per genere e numero di partner\n  summarise(Count = n(), .groups = \"drop\")  # Conta le occorrenze\n\n# Aggiunge la percentuale relativa per ciascun genere\npercentage_data &lt;- counts_data %&gt;%\n  group_by(Gender) %&gt;%  # Raggruppa nuovamente per genere\n  mutate(Percentage = Count / sum(Count) * 100)  # Calcola la percentuale\n\nhead(percentage_data)\n#&gt; # A tibble: 6 × 4\n#&gt; # Groups:   Gender [1]\n#&gt;   Gender NumPartners Count Percentage\n#&gt;   &lt;chr&gt;        &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n#&gt; 1 Man              0     6      0.789\n#&gt; 2 Man              1   100     13.2  \n#&gt; 3 Man              2    44      5.79 \n#&gt; 4 Man              3    39      5.13 \n#&gt; 5 Man              4    58      7.63 \n#&gt; 6 Man              5    51      6.71\n\nPossiamo ora creare gli istogrammi per maschi e femmine:\n\n# Crea l'istogramma separato per maschi e femmine\ngender_labels &lt;- c(\"Man\" = \"Uomini 35-44\", \"Woman\" = \"Donne 35-44\")\n\n# Trova il massimo valore di Percentage per impostare lo stesso limite\ny_max &lt;- max(percentage_data$Percentage)\n\n# Grafico con limiti dell'asse y uguali nei due pannelli\npercentage_data |&gt;\n  ggplot(aes(NumPartners, Percentage, fill = Gender)) +\n  geom_col(position = \"dodge\", color = \"black\") +\n  facet_wrap(~Gender, labeller = labeller(Gender = gender_labels)) +\n  scale_y_continuous(limits = c(0, y_max)) +  # Imposta i limiti dell'asse y\n  labs(\n    x = \"Numero di partner sessuali opposti dichiarati nella vita\",\n    y = \"Percentuale\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nNotiamo che la distribuzione è altamente asimmetrica positiva. Come possiamo descrivere la tendenza centrale di questi dati?\nCalcoliamo gli indici di tendenza centrale all’interno dei due gruppi. Per la moda utilizziamo una funzione personalizzata:\n\n# Funzione personalizzata per calcolare la moda\nget_mode &lt;- function(x) {\n  # Calcola la tabella di frequenza e restituisce il valore con frequenza massima\n  tbl &lt;- table(x)\n  as.numeric(names(tbl)[which.max(tbl)])\n}\n\n# Calcolo delle statistiche per Gender\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarise(\n    mean_sex_partner = mean(NumPartners, na.rm = TRUE),\n    median_sex_partner = median(NumPartners, na.rm = TRUE),\n    mode_sex_partner = get_mode(NumPartners)  # Usa la funzione personalizzata per la moda\n  )\n#&gt; # A tibble: 2 × 4\n#&gt;   Gender mean_sex_partner median_sex_partner mode_sex_partner\n#&gt;   &lt;chr&gt;             &lt;dbl&gt;              &lt;dbl&gt;            &lt;dbl&gt;\n#&gt; 1 Man               17.0                   8                1\n#&gt; 2 Woman              8.23                  5                1\n\nÈ evidente che, quando la distribuzione dei dati è altamente asimmetrica, come nel caso attuale, gli indici di tendenza centrale – media, mediana e moda – possono fornire risultati molto diversi, rendendo difficile individuare una misura rappresentativa della tendenza centrale.\n\nLa media risulta più elevata rispetto alla mediana e alla moda. Questo è tipico di una distribuzione asimmetrica positiva, caratterizzata da una lunga coda destra: pochi individui con valori estremamente alti influenzano la media, spostandola verso destra.\n\nLa mediana, invece, rappresenta il valore centrale della distribuzione e risulta meno influenzata dai valori estremi. Per questo motivo, è spesso più vicina alla “realtà” dei dati, offrendo una stima più robusta della tendenza centrale per la maggior parte degli individui.\n\nLa moda, infine, corrisponde al valore più frequente nella distribuzione (in questo caso, 1 partner). Tuttavia, in presenza di un’elevata dispersione dei dati, la moda può risultare poco rappresentativa della distribuzione complessiva.\n\nIn conclusione, quando la distribuzione è fortemente asimmetrica, la mediana è generalmente l’indice di tendenza centrale più appropriato. Essendo insensibile ai valori estremi, fornisce una rappresentazione più robusta della “posizione centrale” dei dati. Tuttavia, è utile integrare la mediana con la media e la moda per offrire un quadro più completo della distribuzione.\nPer una descrizione efficace della tendenza centrale in distribuzioni asimmetriche, si consiglia dunque di seguire questa procedura:\n\nutilizzare la mediana come misura principale della tendenza centrale;\n\nriportare media e moda come complemento per confrontare i risultati e interpretare eventuali differenze.\n\nÈ comunque fondamentale visualizzare la distribuzione dei dati attraverso grafici appropriati, come istogrammi o boxplot. Questi strumenti consentono di evidenziare chiaramente l’asimmetria, identificare valori estremi e comprendere meglio la struttura dei dati.\nInoltre, per arricchire i sommari numerici, è importante associare indici di dispersione che tratteremo in seguito.\n\n18.6.1 Media Spuntata\nLa media spuntata, indicata come \\(\\bar{x}_t\\) o trimmed mean, è un metodo di calcolo della media che prevede l’eliminazione di una determinata percentuale di dati estremi prima di effettuare la media aritmetica. Solitamente, viene eliminato il 10% dei dati, ovvero il 5% all’inizio e alla fine della distribuzione. Per ottenere la media spuntata, i dati vengono ordinati in modo crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), e quindi viene eliminato il primo 5% e l’ultimo 5% dei dati nella sequenza ordinata. Infine, la media spuntata è calcolata come la media aritmetica dei dati rimanenti. Questo approccio è utile quando ci sono valori anomali o quando la distribuzione è asimmetrica e la media aritmetica non rappresenta adeguatamente la tendenza centrale dei dati.\n\nEsempio 18.1 A titolo di esempio, procediamo al calcolo della media spuntata dei valori NumPartners per i due gruppi definiti dalla variabile Gender, escludendo il 10% dei valori più estremi.\n\nglimpse(df)\n#&gt; Rows: 1,989\n#&gt; Columns: 2\n#&gt; $ Gender      &lt;chr&gt; \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\"…\n#&gt; $ NumPartners &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\nUomini:\n\nsex_partners_men &lt;- df[df$Gender == \"Man\", \"NumPartners\"]\nmean(sex_partners_men, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 10.6\n\nDonne:\n\nsex_partners_women &lt;- df[df$Gender == \"Woman\", \"NumPartners\"]\nmean(sex_partners_women, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 6.013\n\n\n\n18.6.2 Quando Usare Media, Media Spuntata, Moda e Mediana\nLa scelta della misura di tendenza centrale più appropriata dipende dal tipo di dati, dalla distribuzione e dalla presenza di valori anomali o asimmetrie.\n\n18.6.2.1 Moda\nLa moda è il valore che compare con maggiore frequenza nei dati ed è l’unica misura di tendenza centrale utilizzabile per dati a livello nominale (categorie senza ordine) o ordinale (categorie ordinate ma senza distanza definita). Tuttavia:\n- In una distribuzione unimodale, la moda può rappresentare un indicatore significativo della tendenza centrale.\n- In distribuzioni multimodali (con più valori ricorrenti), la moda diventa meno interpretabile, poiché l’esistenza di più “picchi” rende difficile individuare un singolo valore rappresentativo.\n- Nei dati continui, la moda può non essere definita o risultare meno informativa, soprattutto in presenza di valori unici.\n\n18.6.2.2 Media\nLa media aritmetica è una misura efficace di tendenza centrale se la distribuzione è simmetrica e priva di valori anomali. In tali condizioni, la media rappresenta il “baricentro” della distribuzione, equilibrando i valori a sinistra e a destra. Tuttavia:\n\nIn distribuzioni asimmetriche o con outlier, la media è fortemente influenzata dai valori estremi e tende a spostarsi nella direzione della coda più lunga (asimmetria positiva o negativa).\n\nIn questi casi, la media potrebbe non essere rappresentativa della tendenza centrale reale.\n\n18.6.2.3 Media Spuntata\nLa media spuntata è una versione modificata della media, calcolata dopo aver rimosso una certa percentuale di valori estremi (generalmente il 5% o il 10%) sia dalla coda inferiore che da quella superiore della distribuzione. Questa misura è particolarmente utile quando:\n- La distribuzione è asimmetrica o contiene outlier, ma si desidera comunque una stima della tendenza centrale che consideri gran parte dei dati.\n- La media spuntata è meno sensibile ai valori anomali rispetto alla media tradizionale, pur mantenendo il vantaggio di considerare un’ampia porzione dei dati.\n\n18.6.2.4 Mediana\nLa mediana è il valore centrale che divide il campione in due metà: il 50% dei dati è inferiore e il restante 50% è superiore. È una misura robusta della tendenza centrale, particolarmente adatta quando:\n- La distribuzione è asimmetrica o contiene valori anomali. Poiché si basa sulla posizione dei dati e non sulle loro dimensioni, la mediana non è influenzata da valori estremi.\n- Nei dati ordinali, la mediana è spesso più appropriata della media, poiché non richiede una scala numerica con distanze precise.\n\n18.6.2.5 Quale Misura Scegliere?\n\nDistribuzioni Simmetriche:\nLa media è la scelta più appropriata, poiché riflette bene la tendenza centrale.\nDistribuzioni Asimmetriche o con Outlier:\nLa mediana è preferibile perché è robusta e meno influenzata dai valori estremi. In alternativa, si può utilizzare la media spuntata per ottenere un compromesso tra media e mediana.\nDati Categoriali:\nLa moda è l’unica misura applicabile, ma è interpretabile solo in distribuzioni unimodali.\nDistribuzioni Multimodali:\nIn questo caso, è importante visualizzare i dati (ad esempio con un istogramma) e descrivere ciascun “picco” separatamente, poiché nessuna delle misure tradizionali (media, mediana, moda) sarà sufficiente da sola per rappresentare la tendenza centrale.\n\nIn conclusione\n\nLa media è ideale per distribuzioni simmetriche senza valori estremi.\n\nLa mediana è più robusta e appropriata in caso di asimmetria o outlier.\n\nLa media spuntata rappresenta una soluzione intermedia utile nei casi con pochi valori anomali.\n\nLa moda è rilevante solo per dati nominali o ordinale, ma perde significato in distribuzioni multimodali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-variabilità-nei-dati-psicologici",
    "href": "chapters/eda/07_loc_scale.html#la-variabilità-nei-dati-psicologici",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.7 La Variabilità nei Dati Psicologici",
    "text": "18.7 La Variabilità nei Dati Psicologici\nSe misuriamo il livello di stress percepito da una persona dieci volte in un solo giorno, è improbabile ottenere esattamente lo stesso valore ogni volta, anche utilizzando la stessa scala. Se valutiamo il punteggio di autostima in un campione di studenti universitari utilizzando un questionario standardizzato, otterremo valori differenti per ciascun partecipante. Allo stesso modo, se registriamo il tempo di reazione in un compito cognitivo somministrato a un gruppo di persone, noteremo una variabilità nei tempi di risposta anche tra prove dello stesso individuo. La variazione è una caratteristica intrinseca dei fenomeni psicologici e comportamentali, e comprenderne a fondo la natura, le cause e i modi per descriverla è essenziale. In effetti, attribuire la variazione a determinati fattori causali – come differenze individuali, influenze ambientali o variabilità di misurazione – è uno degli obiettivi principali dell’analisi statistica. In questa sezione, esamineremo come la variazione può essere suddivisa, i due tipi principali di variazione (spiegata e non spiegata) e i metodi per descriverla sia visivamente sia numericamente.\nIn questa sezione, esamineremo come la variazione può essere suddivisa, i due tipi principali di variazione (spiegata e non spiegata) e i metodi per descriverla sia visivamente sia numericamente. Comprendere la variabilità è cruciale in psicologia, poiché molti fenomeni, come le differenze individuali o le fluttuazioni dell’umore, dipendono proprio dall’analisi della dispersione dei dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#quantili",
    "href": "chapters/eda/07_loc_scale.html#quantili",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.8 Quantili",
    "text": "18.8 Quantili\nI quantili sono valori che dividono la distribuzione dei dati in intervalli proporzionali, fornendo informazioni sulla loro variabilità e sui punti critici della distribuzione. Il quantile non interpolato di ordine \\(p\\) (\\(0 &lt; p &lt; 1\\)) è definito come il valore al di sotto del quale si trova una frazione \\(p\\) dei dati.\nLa formula per calcolare il quantile non interpolato è:\n\\[\nq_p = x_{(k)},\n\\]\ndove \\(x_{(k)}\\) è il valore \\(k\\)-esimo dell’insieme di dati ordinati in modo crescente. L’indice \\(k\\) è determinato come:\n\\[\nk = \\lceil p \\cdot n \\rceil,\n\\]\ndove \\(n\\) è il numero totale di osservazioni e \\(\\lceil \\cdot \\rceil\\) rappresenta la funzione di arrotondamento all’intero successivo.\n\nEsempio 18.2 Consideriamo il seguente insieme di dati:\n\\[\n\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}.\n\\]\nSupponiamo di voler calcolare il quantile di ordine 0.3 (30° percentile):\n\nI dati sono già ordinati in ordine crescente.\n\nCalcoliamo \\(k\\) come:\n\\[\nk = \\lceil 0.3 \\cdot 10 \\rceil = \\lceil 3 \\rceil = 3.\n\\]\n\n\nIl quantile corrisponde al terzo valore nell’insieme ordinato:\n\\[\nq_{0.3} = x_{(3)} = 23.\n\\]\n\n\n\n\n18.8.1 Quantile Interpolato\nPer valori di \\(p\\) che non corrispondono esattamente a una posizione nell’insieme di dati ordinati, si utilizza il quantile interpolato. Questo metodo stima il valore attraverso un’interpolazione lineare tra i dati adiacenti. È particolarmente utile per set di dati numerosi e viene calcolato automaticamente tramite software statistici come R o Python.\n\n18.8.2 Interpretazione dei Quantili\nI quantili completano le misure di tendenza centrale (media, mediana, moda), permettendo di esplorare la distribuzione dei dati e identificare i valori critici. In particolare:\n\nI quantili bassi (ad esempio il 10° percentile) forniscono informazioni sui valori minimi o nella parte inferiore della distribuzione.\n\nI quantili alti (ad esempio il 90° percentile) aiutano a esplorare i valori massimi o nella parte superiore della distribuzione.\n\nLa mediana è un caso particolare di quantile, corrispondente al quantile di ordine 0.5: divide la distribuzione in due parti uguali.\n\n18.8.3 Importanza dei Quantili\nL’uso congiunto di quantili e misure di tendenza centrale è fondamentale per ottenere una descrizione completa e robusta di una distribuzione, soprattutto in presenza di asimmetrie o valori anomali. Mentre la media e la mediana descrivono il comportamento “centrale” dei dati, i quantili permettono di analizzare la dispersione e identificare aree di particolare interesse nella distribuzione.\n\nEsempio 18.3 Consideriamo ora la variabile NumPartners per due gruppi definiti dalla variabile Gender (“Man” e “Woman”). Calcoleremo i quantili di ordine 0.1 e 0.9 per ciascun gruppo:\n\nIl quantile di ordine 0.1 rappresenta il valore al di sotto del quale si trova il 10% dei dati.\n\nIl quantile di ordine 0.9 rappresenta il valore al di sotto del quale si trova il 90% dei dati.\n\nCalcolo per il Gruppo “Man”:\n\n# Quantili di ordine 0.1 e 0.9 per i maschi\nquantile(df[df$Gender == \"Man\", \"NumPartners\"], probs = c(0.1, 0.9))\n#&gt;  10%  90% \n#&gt;  1.0 34.5\n\n\n10° percentile (0.1): \\(1.0\\) → Il 10% degli uomini ha dichiarato al massimo 1 partner sessuale.\n\n90° percentile (0.9): \\(34.5\\) → Il 10% degli uomini con i valori più alti ha dichiarato più di 34 partner sessuali.\n\nCalcolo per il Gruppo “Woman”:\n\n# Quantili di ordine 0.1 e 0.9 per le femmine\nquantile(df[df$Gender == \"Woman\", \"NumPartners\"], probs = c(0.1, 0.9))\n#&gt; 10% 90% \n#&gt;   1  18\n\n\n10° percentile (0.1): \\(1.0\\) → Anche per le donne, il 10% dei valori più bassi corrisponde a 1 partner sessuale.\n\n90° percentile (0.9): \\(18.0\\) → Il 10% delle donne con i valori più alti ha dichiarato più di 18 partner sessuali.\n\nI quantili calcolati forniscono una descrizione chiara della dispersione e della variabilità dei dati nei due gruppi:\n\nIl fatto che il 10° percentile sia identico per entrambi i gruppi suggerisce che una porzione simile di intervistati dichiara un numero molto basso di partner sessuali.\n\nLa differenza nel 90° percentile tra uomini e donne è significativa:\n\nPer gli uomini, il valore è più alto (\\(34.5\\)), indicando una maggiore presenza di valori estremi nella coda superiore della distribuzione.\n\nPer le donne, il valore (\\(18.0\\)) è inferiore, suggerendo una minore dispersione nella parte alta della distribuzione.\n\n\n\nQuesta differenza evidenzia una asimmetria positiva più pronunciata nel gruppo degli uomini, dove pochi individui con valori elevati “tirano” la coda della distribuzione verso destra.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#percentili",
    "href": "chapters/eda/07_loc_scale.html#percentili",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.9 Percentili",
    "text": "18.9 Percentili\nPrima di procedere, chiarifichiamo alcuni termini comunemente usati nell’analisi esplorativa.\nI percentili sono casi particolari di quantili: invece di \\((0.05, 0.10, ...)\\), immaginiamo di suddividere l’intervallo \\([0,1]\\) in \\((0.01, 0.02, ...)\\).\nAd esempio, il 25° percentile (o primo quartile) è il valore sotto il quale cade il 25% dei dati, il 50° percentile è anche detto mediana, e il 75° percentile (terzo quartile) è il valore sotto il quale cade il 75% dei dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#intervallo-di-variazione",
    "href": "chapters/eda/07_loc_scale.html#intervallo-di-variazione",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.10 Intervallo di variazione",
    "text": "18.10 Intervallo di variazione\nL’intervallo di variazione è il più semplice tra gli indici di dispersione. Si calcola come la differenza tra il valore massimo e il valore minimo di una distribuzione:\n\\[\n\\text{Intervallo di variazione} = \\text{valore massimo} - \\text{valore minimo}.\n\\]\nTuttavia, l’intervallo di variazione presenta due limiti principali:\n\nSi basa esclusivamente su due valori della distribuzione, ignorando tutte le altre osservazioni.\nÈ altamente sensibile ai valori anomali (ad esempio, un adolescente con un punteggio di autostima molto più basso o più alto rispetto alla maggior parte del campione).\n\n\nEsempio 18.4 Supponiamo di misurare il punteggio di autostima in un campione di adolescenti. Se il punteggio massimo è 35 e il minimo è 12, l’intervallo di variazione sarà:\n\\[\n\\text{Intervallo di variazione} = 35 - 12 = 23.\n\\]",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#differenza-interquartile",
    "href": "chapters/eda/07_loc_scale.html#differenza-interquartile",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.11 Differenza interquartile",
    "text": "18.11 Differenza interquartile\nUn’altra misura basata sull’ordinamento è la differenza interquartile (IQR), calcolata come la differenza tra il terzo quartile (\\(Q_3\\)) e il primo quartile (\\(Q_1\\)):\n\\[\n\\text{IQR} = Q_3 - Q_1.\n\\]\nL’IQR considera solo il 50% centrale dei dati, ignorando gli estremi, rendendolo meno sensibile ai valori anomali rispetto all’intervallo di variazione.\n\nEsempio 18.5 Supponiamo di analizzare il livello di ansia percepita in un gruppo di studenti universitari. Se il primo quartile (\\(Q_1\\)) è 25 (25% degli studenti ha un livello di ansia pari o inferiore a 25) e il terzo quartile (\\(Q_3\\)) è 40 (75% degli studenti ha un livello di ansia pari o inferiore a 40), allora:\n\\[\n\\text{IQR} = 40 - 25 = 15.\n\\]",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-varianza",
    "href": "chapters/eda/07_loc_scale.html#la-varianza",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.12 La Varianza",
    "text": "18.12 La Varianza\nPer ottenere una misura di dispersione che consideri tutte le osservazioni, l’indice più utilizzato è la varianza. Questa misura valuta la dispersione dei dati rispetto alla media e si calcola come la media dei quadrati degli scarti di ciascun valore (\\(x_i\\)) dalla media (\\(\\bar{x}\\)):\n\\[\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2.\n\\tag{18.3}\\]\n\nEsempio 18.6 Supponiamo di calcolare il numero di ore dedicate allo studio quotidiano da un gruppo di partecipanti a un esperimento di psicologia. Se la media delle ore studiate è 4 (\\(\\bar{x} = 4\\)), la varianza misura quanto i dati si discostano da questa media. I dati con una varianza maggiore indicano una maggiore diversità nei comportamenti di studio, mentre una varianza minore suggerisce un gruppo più omogeneo.\n\n\n18.12.1 Proprietà della varianza\n\n\nUnità di misura: La varianza è espressa nell’unità di misura al quadrato dei dati originali (es. ore quadrate nel caso precedente), rendendola meno intuitiva da interpretare.\n\nSensibilità agli outlier: Poiché ogni scarto viene elevato al quadrato, i valori estremi influenzano significativamente la varianza.\n\n18.12.2 Variazione Sistematica e Non Sistematica\nNell’analisi dei dati psicologici, la variabilità può essere suddivisa in due componenti principali:\n\n\nVariazione non sistematica (rumore):\nÈ la variabilità casuale, non attribuibile a una causa specifica. Si manifesta come errori di misurazione o fluttuazioni imprevedibili che non seguono uno schema chiaro. Esempi includono:\n\nErrori casuali nel completare un test (ad esempio, distrazione momentanea).\n\nFluttuazioni dell’umore durante la giornata.\n\n\n\nVariazione sistematica (segnale):\nÈ la variabilità attribuibile a fattori specifici che influiscono in modo prevedibile sui dati. Questa componente rappresenta il “segnale” utile nell’analisi statistica. Esempi includono:\n\nIl miglioramento nei punteggi di un test di attenzione dopo una sessione di meditazione.\n\nLe differenze individuali nei livelli di self-compassion misurati da una scala psicologica.\n\n\n\nPer esempio, supponiamo di misurare il livello di stress prima e dopo una sessione di rilassamento:\n\nLa variazione sistematica rappresenta la riduzione del livello di stress dovuta all’effetto del rilassamento.\n\nLa variazione non sistematica comprende fattori casuali, come distrazioni, stanchezza momentanea o condizioni personali dei partecipanti.\n\n18.12.3 Calcolo della Varianza in R\nPer illustrare come quantificare la variabilità, utilizziamo i punteggi totali della Self-Compassion Scale su un campione di studenti universitari, forniti nel file scs_scores.csv.\nPassaggio 1: Importazione dei dati\n\nscs_df &lt;- rio::import(here::here(\"data\", \"scs_scores.csv\")) |&gt; \n  dplyr::rename(ts = scs_total_score)\nglimpse(scs_df)\n#&gt; Rows: 121\n#&gt; Columns: 7\n#&gt; $ self_kindness       &lt;int&gt; 14, 15, 19, 10, 11, 9, 19, 13, 23, 5, 14, 22, …\n#&gt; $ common_humanity     &lt;int&gt; 11, 9, 16, 11, 10, 8, 12, 12, 19, 4, 13, 18, 6…\n#&gt; $ mindfulness         &lt;int&gt; 10, 10, 16, 9, 9, 10, 8, 12, 20, 8, 15, 15, 6,…\n#&gt; $ self_judgment       &lt;int&gt; 15, 16, 13, 15, 18, 19, 11, 15, 9, 25, 17, 11,…\n#&gt; $ isolation           &lt;int&gt; 16, 11, 12, 14, 13, 16, 11, 11, 5, 20, 14, 11,…\n#&gt; $ over_identification &lt;int&gt; 14, 11, 8, 11, 14, 17, 20, 15, 7, 20, 15, 16, …\n#&gt; $ ts                  &lt;int&gt; 68, 74, 96, 68, 63, 53, 75, 74, 119, 30, 74, 9…\n\nLa colonna ts contiene i punteggi totali della scala.\nPassaggio 2: Calcolo della varianza\nUtilizzando la formula della varianza:\n\nsum((scs_df$ts - mean(scs_df$ts))^2) / length(scs_df$ts)\n#&gt; [1] 405.3\n\nCon la funzione var() corretta per il campione:\n\nvar(scs_df$ts) * (length(scs_df$ts) - 1) / length(scs_df$ts)\n#&gt; [1] 405.3\n\n\n18.12.4 Interpretazione della Varianza\nLa varianza misura la dispersione totale dei dati, che può essere scomposta in:\n\nVariazione sistematica:\nNel caso della Self-Compassion Scale, la varianza sistematica riflette le differenze tra individui nei livelli di self-compassion. Alcuni individui mostrano livelli elevati (fattore protettivo contro il disagio psicologico), mentre altri livelli più bassi.\nVariazione non sistematica:\nQuesta componente è dovuta a errori di misurazione e altre cause casuali. La psicometria presuppone che il punteggio osservato sia la somma di:\\[\n\\text{Punteggio osservato} = \\text{Punteggio vero} + \\text{Errore di misurazione}.\n\\] Esempi di errori includono distrazioni o stanchezza dei partecipanti; limitazioni della scala psicologica nella misurazione accurata del costrutto.\n\n18.12.5 Affidabilità e Rapporto Segnale-Rumore\nPerché uno strumento psicometrico sia considerato affidabile, almeno l’80% della varianza osservata deve essere attribuibile alla componente vera del costrutto. Questo requisito si traduce in un coefficiente di affidabilità di almeno 0.8.\n\nUn alto rapporto segnale-rumore indica che la maggior parte della variabilità osservata è dovuta a fattori sistematici (segnale) e non a errori casuali (rumore).\n\nUn basso rapporto segnale-rumore suggerisce che la variabilità casuale (rumore) è predominante e lo strumento potrebbe non essere sufficientemente preciso.\n\nLa psicometria fornisce strumenti per:\n\n\nvalutare l’affidabilità delle scale psicologiche (es. Alpha di Cronbach);\n\nprogettare strumenti più accurati per minimizzare la variabilità non sistematica (rumore).\n\nUno strumento affidabile assicura che i risultati riflettano con precisione le differenze reali tra gli individui e non siano influenzati da errori casuali.\nSupponiamo di valutare l’efficacia di un nuovo metodo di studio misurando il miglioramento in un test di comprensione:\n\nun alto rapporto segnale-rumore (ovvero, un’alta affidabilità) indica che il miglioramento osservato è chiaramente attribuibile al metodo;\nun basso rapporto segnale-rumore (bassa affidabilità) implica che la variabilità è prevalentemente casuale e l’effetto del metodo non è distinguibile dal rumore.\n\nIn conclusione, la distinzione tra variazione sistematica e non sistematica è fondamentale per l’analisi dei dati psicologici:\n\nla variazione sistematica rappresenta il “segnale”, ossia l’effetto reale o il fattore di interesse;\nla variazione non sistematica rappresenta il “rumore”, ossia la variabilità casuale o l’errore di misurazione.\n\nL’obiettivo è massimizzare il segnale e minimizzare il rumore, garantendo strumenti affidabili che consentano di ottenere risultati precisi e interpretabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#stima-della-varianza-della-popolazione",
    "href": "chapters/eda/07_loc_scale.html#stima-della-varianza-della-popolazione",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.13 Stima della Varianza della Popolazione",
    "text": "18.13 Stima della Varianza della Popolazione\nSi noti il denominatore della formula della varianza. Nell’Equazione 18.3, ho utilizzato \\(n\\) come denominatore (l’ampiezza campionaria, ovvero il numero di osservazioni nel campione). In questo modo, otteniamo la varianza come statistica descrittiva del campione. Tuttavia, è possibile utilizzare \\(n-1\\) come denominatore alternativo:\n\\[\n\\begin{equation}\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2\n\\end{equation}\n\\tag{18.4}\\]\nIn questo secondo caso, otteniamo la varianza come stimatore della varianza della popolazione. Si può dimostrare che l’Equazione 18.4 fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre l’Equazione 18.3 fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: \\(S^2\\) rappresenta la varianza come statistica descrittiva, mentre \\(s^2\\) rappresenta la varianza come stimatore.\nPer illustrare questo punto, svolgiamo una simulazione. Consideriamo la distribuzione dei punteggi del quoziente di intelligenza (QI). I valori del QI seguono una particolare distribuzione chiamata distribuzione normale, con media 100 e deviazione standard 15. La forma di questa distribuzione è illustrata nella figura seguente.\n\n# Define parameters\nx &lt;- seq(100 - 4 * 15, 100 + 4 * 15, by = 0.001)\nmu &lt;- 100\nsigma &lt;- 15\n\n# Compute the PDF\npdf &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Plot using ggplot2\ndata &lt;- tibble(x = x, pdf = pdf)\nggplot(data, aes(x = x, y = pdf)) +\n  geom_line() +\n  labs(\n    x = \"QI\", \n    y = \"Densità\", \n    title = \"Distribuzione del QI nella popolazione\"\n  ) \n\n\n\n\n\n\n\nSupponiamo di estrarre un campione casuale di 4 osservazioni dalla popolazione del quoziente di intelligenza – in altre parole, supponiamo di misurare il quoziente di intelligenza di 4 persone prese a caso dalla popolazione.\n\nset.seed(123) \nx &lt;- rnorm(4, mean = 100, sd = 15)\nprint(x)\n#&gt; [1]  91.59  96.55 123.38 101.06\n\nCalcoliamo la varianza usando \\(n\\) al denominatore. Si noti che la vera varianza del quoziente di intelligenza è \\(15^2\\) = 225.\n\nvar(x)\n#&gt; [1] 196.9\n\nConsideriamo ora 10 campioni casuali del QI, ciascuno di ampiezza 4.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10\nrandom_samples &lt;- list()\n\nset.seed(123) \n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nIl primo campione è\n\nrandom_samples[1]\n#&gt; [[1]]\n#&gt; [1]  91.59  96.55 123.38 101.06\n\nIl decimo campione è\n\nrandom_samples[10]\n#&gt; [[1]]\n#&gt; [1] 108.31  99.07  95.41  94.29\n\nStampiamo i valori di tutti i 10 campioni.\n\nrs &lt;- do.call(rbind, random_samples)\nrs\n#&gt;         [,1]   [,2]   [,3]   [,4]\n#&gt;  [1,]  91.59  96.55 123.38 101.06\n#&gt;  [2,] 101.94 125.73 106.91  81.02\n#&gt;  [3,]  89.70  93.32 118.36 105.40\n#&gt;  [4,] 106.01 101.66  91.66 126.80\n#&gt;  [5,] 107.47  70.50 110.52  92.91\n#&gt;  [6,]  83.98  96.73  84.61  89.07\n#&gt;  [7,]  90.62  74.70 112.57 102.30\n#&gt;  [8,]  82.93 118.81 106.40  95.57\n#&gt;  [9,] 113.43 113.17 112.32 110.33\n#&gt; [10,] 108.31  99.07  95.41  94.29\n\nPer ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando la formula con \\(n\\) al denominatore. Otteniamo così 10 stime della varianza della popolazione del QI.\n\nx_var &lt;- apply(rs, 1, var)  # Applica la funzione var su ciascuna riga\nprint(x_var)\n#&gt;  [1] 196.940 337.536 168.547 218.684 333.476  34.520 264.378 234.081   1.971\n#&gt; [10]  40.468\n\nNotiamo due cose:\n\nle stime sono molto diverse tra loro; questo fenomeno è noto con il nome di variabilità campionaria;\nin media le stime sono troppo piccole.\n\nPer aumentare la sicurezza riguardo al secondo punto menzionato in precedenza, ripeteremo la simulazione utilizzando un numero di iterazioni maggiore.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nset.seed(123) # Replace 123 with your desired seed for reproducibility\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var) * (size - 1) / size  # Adjust for population variance (ddof = 0)\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\n# Create a data frame for plotting\ndata &lt;- data.frame(x_var = x_var)\n\n# Plot the histogram using ggplot2\nggplot(data, aes(x = x_var)) +\n  geom_histogram(fill = \"lightblue\") +\n  labs(\n    x = \"Varianza\", \n    y = \"Frequenza\", \n    title = \"Varianza del QI in campioni di n = 4\"\n  )\n\n\n\n\n\n\n\nLa stima più verosimile della varianza del QI è dato dalla media di questa distribuzione.\n\nmean(x_var)\n#&gt; [1] 168.9\n\nSi noti che il nostro spospetto è stato confermato: il valore medio della stima della varianza ottenuta con l’Equazione 18.3 è troppo piccolo rispetto al valore corretto di \\(15^2 = 225\\).\nRipetiamo ora la simulazione usando la formula della varianza con \\(n-1\\) al denominatore.\n\nset.seed(123) \n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var)  # ddof = 1 is default for var in R\n\nmean(x_var)\n#&gt; [1] 225.2\n\nNel secondo caso, se utilizziamo \\(n-1\\) come denominatore per calcolare la stima della varianza, il valore atteso di questa stima è molto vicino al valore corretto di 225. Se il numero di campioni fosse infinito, i due valori sarebbero identici.\nIn conclusione, le due formule della varianza hanno scopi diversi. La formula della varianza con \\(n\\) al denominatore viene utilizzata come statistica descrittiva per descrivere la variabilità di un particolare campione di osservazioni. D’altro canto, la formula della varianza con \\(n-1\\) al denominatore viene utilizzata come stimatore per ottenere la migliore stima della varianza della popolazione da cui quel campione è stato estratto.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#deviazione-standard",
    "href": "chapters/eda/07_loc_scale.html#deviazione-standard",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.14 Deviazione Standard",
    "text": "18.14 Deviazione Standard\nPer interpretare la varianza in modo più intuitivo, si può calcolare la deviazione standard (o scarto quadratico medio o scarto tipo) prendendo la radice quadrata della varianza. La deviazione standard è espressa nell’unità di misura originaria dei dati, a differenza della varianza che è espressa nel quadrato dell’unità di misura dei dati. La deviazione standard fornisce una misura della dispersione dei dati attorno alla media, rendendo più facile la comprensione della variabilità dei dati.\nLa deviazione standard (o scarto quadratico medio, o scarto tipo) è definita come:\n\\[\ns^2 = \\sqrt{(n-1)^{-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}.\n\\tag{18.5}\\]\nQuando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s &gt; 0\\).\n\n\n\n\n\n\nIl termine standard deviation è stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca \\(\\sigma\\) che lo rappresenta. Il termine italiano “deviazione standard” ne è la traduzione più utilizzata nel linguaggio comune; il termine dell’Ente Nazionale Italiano di Unificazione è tuttavia “scarto tipo”, definito come la radice quadrata positiva della varianza.\n\n\n\nLa deviazione standard \\(s\\) dovrebbe essere utilizzata solo quando la media è una misura appropriata per descrivere il centro della distribuzione, ad esempio nel caso di distribuzioni simmetriche. Tuttavia, è importante tener conto che, come la media \\(\\bar{x}\\), anche la deviazione standard è fortemente influenzata dalla presenza di dati anomali, ovvero pochi valori che si discostano notevolmente dalla media rispetto agli altri dati della distribuzione. In presenza di dati anomali, la deviazione standard può risultare ingannevole e non rappresentare accuratamente la variabilità complessiva della distribuzione. Pertanto, è fondamentale considerare attentamente il contesto e le caratteristiche dei dati prima di utilizzare la deviazione standard come misura di dispersione. In alcune situazioni, potrebbe essere più appropriato ricorrere a misure di dispersione robuste o ad altre statistiche descrittive per caratterizzare la variabilità dei dati in modo più accurato e affidabile.\n\nEsempio 18.7 Calcoliamo la deviazione standard per i valori di self-compassion del campione di dati esaminato in precedenza. Applicando l’Equazione 18.5, per tutto il campione abbiamo\n\nsd(scs_df$ts)\n#&gt; [1] 20.22\n\n\n\n18.14.1 Interpretazione\nLa deviazione standard misura la dispersione dei dati rispetto alla media aritmetica. In termini semplici, indica quanto, in media, ciascun valore osservato si discosta dalla media del campione. Anche se è simile allo scarto semplice medio campionario (la media dei valori assoluti degli scarti rispetto alla media), la deviazione standard utilizza lo scarto quadratico medio e produce un valore leggermente diverso.\nPer esempio, consideriamo i punteggi di self-compassione di un campione di individui:\n\nEsempio 18.8 Per verificare l’interpretazione della deviazione standard, utilizziamo i valori della self-compassione.\n\nsd(scs_df$ts)\n#&gt; [1] 20.22\n\nLa deviazione standard calcolata è 20.2. Questo valore ci dice che, in media, ciascun punteggio si discosta di circa 20.2 punti dalla media aritmetica dei punteggi.\n\nValore più alto: indica maggiore dispersione dei dati intorno alla media.\nValore più basso: i dati sono più concentrati vicino alla media.\n\nSe calcoliamo anche lo scarto semplice medio campionario per confronto, otteniamo:\n\nmean(abs(scs_df$ts - mean(scs_df$ts, na.rm = TRUE)), na.rm = TRUE)\n#&gt; [1] 16.18\n\nI due valori (deviazione standard e scarto semplice medio) sono simili ma non identici, a causa delle diverse definizioni matematiche.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#deviazione-mediana-assoluta",
    "href": "chapters/eda/07_loc_scale.html#deviazione-mediana-assoluta",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.15 Deviazione Mediana Assoluta",
    "text": "18.15 Deviazione Mediana Assoluta\nLa deviazione mediana assoluta (MAD) è una misura robusta di dispersione basata sulla mediana. È definita come la mediana dei valori assoluti delle deviazioni dei dati rispetto alla mediana:\n\\[\n\\text{MAD} = \\text{median} \\left( |X_i - \\text{median}(X)| \\right)\n\\tag{18.6}\\]\nLa MAD è particolarmente utile per analizzare dati contenenti outlier o distribuzioni asimmetriche, poiché è meno influenzata dai valori estremi rispetto alla deviazione standard.\n\n18.15.1 Relazione tra MAD e Deviazione Standard in una Distribuzione Normale\nQuando i dati seguono una distribuzione normale (gaussiana), esiste una relazione approssimativa tra MAD e deviazione standard. La MAD può essere convertita in una stima della deviazione standard moltiplicandola per una costante di 1.4826:\n\\[\n\\sigma \\approx k \\times \\text{MAD},\n\\]\ndove:\n\n\n\\(\\sigma\\) è la deviazione standard.\nMAD è la Mediana della Deviazione Assoluta.\n\n\\(k\\) è una costante che, per una distribuzione normale, è tipicamente presa come circa 1.4826.\n\nQuesta costante deriva dalla proprietà della distribuzione normale, in cui circa il 50% dei valori si trova entro 0.6745 deviazioni standard dalla media.\nLa formula completa per convertire la MAD in una stima della deviazione standard in una distribuzione normale è:\n\\[\n\\sigma \\approx 1.4826 \\times \\text{MAD}\n\\]\nQuesta relazione è utile per stimare la deviazione standard in modo più robusto, specialmente quando si sospetta la presenza di outlier o si ha a che fare con campioni piccoli. Di conseguenza, molti software restituiscono il valore MAD moltiplicato per questa costante per fornire un’indicazione più intuitiva della variabilità dei dati. Tuttavia, è importante notare che questa relazione si mantiene accurata solo per le distribuzioni che sono effettivamente normali. In presenza di distribuzioni fortemente asimmetriche o con elevati outlier, la deviazione standard e la MAD possono fornire indicazioni molto diverse sulla variabilità dei dati.\n\nEsempio 18.9 Per verificare questo principio, calcoliamo la deviazione mediana assoluta dei valori di self-compassion del campione esaminato:\n\n1.4826 * median(abs(scs_df$ts - median(scs_df$ts, na.rm = TRUE)), na.rm = TRUE)\n#&gt; [1] 22.24\n\nOtteniamo un valore che è simile alla deviazione standard calcolata con:\n\nsd(scs_df$ts)\n#&gt; [1] 20.22\n\nSe verifichiamo la distribuzione dei dati con un grafico della densità, possiamo osservare che i punteggi sono approssimativamente normali:\n\nggplot(scs_df, aes(x = ts)) +\n  geom_density(fill = \"lightblue\") +\n  labs(\n    x = \"math\", \n    y = \"Frequenza\", \n    title = \"Distribuzione dei punteggi di self-compassion\"\n  )\n\n\n\n\n\n\n\nPer ulteriori verifiche, possiamo estrarre un campione di dati da una distribuzione normale con media 100 e deviazione standard 15:\n\nset.seed(123) \nx &lt;- rnorm(10000, mean = 100, sd = 15)\n1.4826 * median(abs(x - median(x)))\n#&gt; [1] 14.92\n\nAnche in questo caso, il valore ottenuto è molto vicino alla deviazione standard reale (15), confermando la relazione tra MAD e deviazione standard in distribuzioni gaussiane.\n\n\n18.15.2 Quando Usare Deviazione Standard e MAD\n\nDeviazione standard: È la misura più appropriata per dati normalmente distribuiti e situazioni in cui l’obiettivo è descrivere la dispersione dei dati rispetto alla media. Tuttavia, è sensibile ai valori anomali (outlier).\nDeviazione mediana assoluta (MAD): È ideale quando i dati sono non normali, asimmetrici o contengono outlier. La MAD è più robusta poiché utilizza la mediana anziché la media e non è influenzata da valori estremi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-variabilità-relativi",
    "href": "chapters/eda/07_loc_scale.html#indici-di-variabilità-relativi",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.16 Indici di Variabilità Relativi",
    "text": "18.16 Indici di Variabilità Relativi\nA volte può essere necessario confrontare la variabilità di grandezze incommensurabili, ovvero di caratteri misurati con differenti unità di misura. In queste situazioni, le misure di variabilità descritte in precedenza diventano inadeguate poiché dipendono dall’unità di misura utilizzata. Per superare questo problema, si ricorre a specifici numeri adimensionali chiamati indici relativi di variabilità.\nIl più importante di questi indici è il coefficiente di variazione (\\(C_v\\)), definito come il rapporto tra la deviazione standard (\\(\\sigma\\)) e la media dei dati (\\(\\bar{x}\\)):\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}.\n\\tag{18.7}\\]\nIl coefficiente di variazione è un numero puro e permette di confrontare la variabilità di distribuzioni con unità di misura diverse.\nUn altro indice relativo di variabilità è la differenza interquartile rapportata a uno dei tre quartili (primo quartile, terzo quartile o mediana). Questo indice è definito come:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]\nQuesti indici relativi di variabilità forniscono una misura adimensionale della dispersione dei dati, rendendo possibile il confronto tra grandezze con diverse unità di misura e facilitando l’analisi delle differenze di variabilità tra i dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-fallacia-ergodica",
    "href": "chapters/eda/07_loc_scale.html#la-fallacia-ergodica",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.17 La Fallacia Ergodica",
    "text": "18.17 La Fallacia Ergodica\nSebbene il concetto di “media” possa sembrare chiaro, ciò non implica che il suo utilizzo non presenti delle problematiche nell’ambito della pratica psicologica. Un aspetto su cui vale la pena soffermarsi è ciò che viene definito “fallacia ergodica”.\nIl concetto di “fallacia ergodica” (Speelman et al., 2024) si riferisce all’errore compiuto dai ricercatori quando assumono che le caratteristiche medie di un gruppo di individui possano essere applicate a ciascun individuo all’interno di quel gruppo, senza considerare le differenze individuali o le variazioni nel tempo. Questa fallacia emerge dalla pratica comune nella ricerca psicologica di raccogliere dati aggregati da gruppi di persone per stimare parametri della popolazione, al fine di confrontare comportamenti in condizioni diverse o esplorare associazioni tra diverse misurazioni della stessa persona.\nIl problema di questo approccio è che l’uso dei risultati basati sul gruppo per caratterizzare le caratteristiche degli individui o per estrapolare a persone simili a quelle del gruppo è ingiustificato, poiché le medie di gruppo possono fornire informazioni solo sui risultati collettivi, come la performance media del gruppo, e non consentono di fare affermazioni accurate sugli individui che compongono quel gruppo. La fallacia ergodica si basa sull’assunzione che per utilizzare legittimamente una statistica aggregata (ad esempio, la media) derivata da un gruppo per descrivere un individuo di quel gruppo, due condizioni devono essere soddisfatte: gli individui devono essere così simili da essere praticamente interscambiabili, e le caratteristiche degli individui devono essere temporalmente stabili.\nTuttavia, i fenomeni e i processi psicologici di interesse per i ricercatori sono per natura non uniformi tra gli individui e variabili nel tempo, sia all’interno degli individui che tra di loro. Di conseguenza, i risultati ottenuti dalla media di misure di comportamenti, cognizioni o stati emotivi di più individui non descrivono accuratamente nessuno di quegli individui in un dato momento, né possono tenere conto dei cambiamenti in quelle variabili per un individuo nel tempo.\nSpeelman et al. (2024) osservano che la stragrande maggioranza degli articoli che hanno analizzato include conclusioni nelle sezioni degli Abstract e/o delle Discussioni che implicano che i risultati trovati con dati aggregati di gruppo si applichino anche agli individui in quei gruppi e/o si applichino agli individui nella popolazione. Questa pratica riflette la fallacia ergodica, che consiste nell’assumere che i campioni siano sistemi ergodici quando non lo sono.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "href": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "\n18.18 Riflessioni Conclusive",
    "text": "18.18 Riflessioni Conclusive\nLe statistiche descrittive ci permettono di ottenere indicatori sintetici che riassumono i dati di una popolazione o di un campione estratto da essa. Questi indicatori includono misure di tendenza centrale, come la media, la mediana e la moda, che ci forniscono informazioni sulla posizione centrale dei dati rispetto alla distribuzione. Inoltre, ci sono gli indici di dispersione, come la deviazione standard e la varianza, che ci indicano quanto i dati si disperdono attorno alla tendenza centrale. Questi indici ci aiutano a comprendere quanto i valori si discostano dalla media, e quindi ci forniscono un’idea della variabilità dei dati. In conclusione, le statistiche descrittive ci offrono un quadro sintetico delle caratteristiche principali dei dati, consentendoci di comprendere meglio la loro distribuzione e variabilità.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#esercizi",
    "href": "chapters/eda/07_loc_scale.html#esercizi",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nParte 1: Domande Teoriche\n\n\nDefinizione e comprensione dei concetti\n\nSpiega la differenza tra media, mediana e moda.\nIn quali situazioni la mediana fornisce una misura della tendenza centrale migliore rispetto alla media?\nPerché la media è sensibile ai valori estremi?\nQuali sono i vantaggi della deviazione mediana assoluta (MAD) rispetto alla deviazione standard?\n\n\n\nInterpretazione della variabilità\n\nSpiega il concetto di varianza e la sua interpretazione.\nQual è la differenza tra varianza e deviazione standard?\nDescrivi in quali casi l’utilizzo del coefficiente di variazione è più appropriato rispetto alla deviazione standard.\nQuali sono i limiti della moda come indice di tendenza centrale?\n\n\n\nParte 2: Calcoli Manuali\n\n\nCalcolo della media, mediana e moda\n\n\nConsidera i seguenti punteggi totali della SWLS che sono stati raccolti in un campione di studenti. Calcola manualmente:\n\nLa media\nLa mediana\nLa moda\nIl range\n\n\n\n\n\nCalcolo della varianza e della deviazione standard\n\nUsando gli stessi dati dell’esercizio precedente, calcola:\n\nLa varianza\nLa deviazione standard\nLa deviazione mediana assoluta (MAD)\n\n\n\n\n\nParte 3: Esercizi con R\n\n\nAnalisi descrittiva con R\n\nCarica il dataset swls_scores.csv contenente i punteggi SWLS degli studenti.\nCalcola media, mediana e moda utilizzando R.\nCalcola la varianza e la deviazione standard utilizzando le funzioni appropriate in R.\n\nCodice suggerito:\nlibrary(tidyverse)\nlibrary(rio)\n\n# Caricamento del dataset\ndf &lt;- import(\"swls_scores.csv\")\n\n# Calcolo delle statistiche descrittive\nmean(df$swls_total)\nmedian(df$swls_total)\n\n# Moda (funzione personalizzata)\nget_mode &lt;- function(x) {\n  tbl &lt;- table(x)\n  as.numeric(names(tbl)[which.max(tbl)])\n}\nget_mode(df$swls_total)\n\n# Varianza e deviazione standard\nvar(df$swls_total)\nsd(df$swls_total)\n\n# Deviazione mediana assoluta\nmad(df$swls_total)\n\n\nVisualizzazione della distribuzione dei dati\n\nCrea un istogramma dei punteggi totali della SWLS.\nAggiungi una linea verticale che rappresenti la media e una che rappresenti la mediana.\n\nCodice suggerito:\nggplot(df, aes(x = swls_total)) +\n  geom_histogram(binwidth = 2, fill = \"blue\", alpha = 0.5, color = \"black\") +\n  geom_vline(aes(xintercept = mean(swls_total)), color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_vline(aes(xintercept = median(swls_total)), color = \"green\", linetype = \"dotted\", size = 1) +\n  labs(title = \"Distribuzione dei punteggi SWLS\", x = \"Punteggio SWLS\", y = \"Frequenza\")\n\n\nParte 4: Domande di Comprensione\n\n\nAnalisi concettuale\n\nPerché la media aritmetica può essere considerata il “baricentro” della distribuzione dei dati?\nSe aggiungiamo un valore estremo al dataset, quale delle misure di tendenza centrale subirà il maggior impatto?\nIn quali situazioni la varianza campionaria è preferibile rispetto alla varianza della popolazione?\nQual è la relazione tra la deviazione standard e la varianza?\nFornisci un’interpretazione intuitiva della deviazione standard.\nDiscuti le differenze e le somiglianze tra la deviazione standard e MAD. Usa queste informazioni per ridescrivere in maniera intuitiva il significato di deviazione standard.\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nPoniamo che i valori SWLS siano [ 18, 22, 26, 19, 24, 30, 26, 22, 18, 28, 21 ].\n\nMedia: \\[ \\bar{x} = \\frac{18 + 22 + 26 + 19 + 24 + 30 + 26 + 22 + 18 + 28 + 21}{11} = 23.36 \\]\nMediana: Ordinando i dati: [ 18, 18, 19, 21, 22, 22, 24, 26, 26, 28, 30 ] La mediana è il valore centrale: \\(22\\)\nModa: Il valore più frequente è 22 (appare due volte).\nVarianza: \\[ s^2 = \\frac{\\sum (x_i - \\bar{x})^2}{n-1} = 13.96 \\]\nDeviazione Standard: \\[ s = \\sqrt{13.96} = 3.73 \\]\nMAD: \\[ \\text{MAD} = \\text{mediana}(|X_i - \\text{mediana}(X)|) = 4 \\]\n\nSoluzioni con R\nI risultati eseguendo il codice R:\n\n\nMedia: 23.36\n\nMediana: 22\n\nModa: 22\n\nVarianza: 13.96\n\nDeviazione standard: 3.73\n\nMAD: 4\n\nSoluzioni alle Domande di Comprensione\n\nLa media è il baricentro poiché minimizza la somma degli scarti quadrati.\nLa media è più influenzata dai valori estremi rispetto alla mediana.\nLa varianza campionaria corregge la sottostima della varianza popolazionale.\nLa deviazione standard è la radice quadrata della varianza, consentendo un’interpretazione del risultato sulla scala dei dati grezzi.\nLa deviazione standard è simile, ma non identica, al valore medio degli scarti assoluti tra ciascun valore della distribuzione e la media. In altre parole, rappresenta la “distanza tipica” media tra le osservazioni e il valore medio della distribuzione.\nLa deviazione standard e il MAD (Median Absolute Deviation, o scarto medio assoluto) sono entrambi misure di variabilità che descrivono quanto i valori in un insieme di dati si discostino dal centro della distribuzione. Tuttavia, presentano alcune importanti differenze e somiglianze.\n\nSomiglianze\n\nEntrambe le misure quantificano la dispersione dei dati attorno a un punto centrale.\nSia la deviazione standard che il MAD utilizzano lo scarto (la differenza tra ciascun valore e un punto centrale) per calcolare la variabilità.\n\nDifferenze\n\n\nPunto centrale usato: La deviazione standard si basa sulla media aritmetica, mentre il MAD si basa sulla mediana.\n\nTrattamento degli scarti: Nella deviazione standard, gli scarti vengono elevati al quadrato prima di essere mediati, quindi la radice quadrata viene applicata al risultato finale. Questo processo penalizza maggiormente gli scarti più grandi, rendendo la deviazione standard più sensibile agli outlier. Il MAD, invece, considera semplicemente il valore assoluto degli scarti, rendendolo meno influenzato dagli estremi.\n\nSensibilità agli outlier: Poiché la deviazione standard dipende dai quadrati degli scarti, è più sensibile alle osservazioni estreme (outlier). Il MAD, essendo basato sulla mediana, è una misura più robusta e resiste meglio alla presenza di valori anomali.\n\nRidescrizione Intuitiva della Deviazione Standard\n\nLa deviazione standard può essere vista come una misura della “dispersione tipica” dei dati attorno alla media, ma con un’enfasi particolare sugli scarti più grandi. Immagina di prendere ogni valore del dataset, calcolarne la distanza dalla media, amplificare queste distanze attraverso il quadrato, poi trovare una sorta di “distanza media” ponderata. Questo processo dà maggiore peso agli scarti più grandi, fornendo così una visione della variabilità che tiene conto sia delle fluttuazioni ordinarie sia di eventuali valori estremi. In sintesi, mentre il MAD offre una visione più resistente e diretta della variabilità centrata sulla mediana, la deviazione standard fornisce una misura più dettagliata e sensibile alla forma complessiva della distribuzione, inclusi i suoi possibili outliers.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] vcd_1.4-13        viridis_0.6.5     viridisLite_0.4.2 thematic_0.1.6   \n#&gt;  [5] MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.10.0        gridExtra_2.3    \n#&gt;  [9] patchwork_1.3.0   bayesplot_1.11.1  psych_2.4.12      scales_1.3.0     \n#&gt; [13] markdown_1.13     knitr_1.49        lubridate_1.9.4   forcats_1.0.0    \n#&gt; [17] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#&gt; [21] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#&gt; [25] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.50         htmlwidgets_1.6.4 lattice_0.22-6   \n#&gt;  [5] tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2       generics_0.1.3   \n#&gt;  [9] parallel_4.4.2    pacman_0.5.1      pkgconfig_2.0.3   R.oo_1.27.0      \n#&gt; [13] data.table_1.16.4 lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      htmltools_0.5.8.1 pillar_1.10.1    \n#&gt; [21] MASS_7.3-64       R.utils_2.12.3    nlme_3.1-167      tidyselect_1.2.1 \n#&gt; [25] digest_0.6.37     stringi_1.8.4     labeling_0.4.3    rprojroot_2.0.4  \n#&gt; [29] fastmap_1.2.0     colorspace_2.1-1  cli_3.6.4         magrittr_2.0.3   \n#&gt; [33] utf8_1.2.4        withr_3.0.2       timechange_0.3.0  rmarkdown_2.29   \n#&gt; [37] zoo_1.8-12        R.methodsS3_1.8.2 hms_1.1.3         evaluate_1.0.3   \n#&gt; [41] lmtest_0.9-40     rlang_1.1.5       glue_1.8.0        rstudioapi_0.17.1\n#&gt; [45] jsonlite_1.8.9    R6_2.6.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#bibliografia",
    "href": "chapters/eda/07_loc_scale.html#bibliografia",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSpeelman, C. P., Parker, L., Rapley, B. J., & McGann, M. (2024). Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals. Collabra: Psychology, 10(1).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html",
    "href": "chapters/eda/07a_introduction_normal_distribution.html",
    "title": "19  Introduzione alla distribuzione normale",
    "section": "",
    "text": "Introduzione\nIn questo capitolo forniremo un primo sguardo alla distribuzione normale, che sarà trattata in modo più approfondito nel Capitolo 36. Introduciamo la distribuzione normale a questo punto poiché essa spiega in modo chiaro perché, in molte analisi, media e deviazione standard siano impiegate come principali descrittori di una distribuzione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#sec-normal-distribution",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#sec-normal-distribution",
    "title": "19  Introduzione alla distribuzione normale",
    "section": "\n19.1 La distribuzione normale",
    "text": "19.1 La distribuzione normale\nNel Capitolo 16, abbiamo visto come gli istogrammi e i grafici di densità forniscano utili riassunti visivi di una distribuzione. In questo capitolo, ci chiediamo se sia possibile riassumere una distribuzione in modo ancora più sintetico. Spesso si fa riferimento a media e deviazione standard come statistiche riassuntive fondamentali: in sostanza, un riassunto in due numeri. Per comprendere appieno il ruolo di questi valori, dobbiamo prima capire come è definita la distribuzione normale.\nLa distribuzione normale, nota anche come curva a campana o distribuzione gaussiana, è uno dei concetti matematici più conosciuti (si veda il Capitolo 36). Uno dei motivi della sua fama è che numerose variabili nella realtà seguono, almeno approssimativamente, una distribuzione normale. Esempi includono le vincite nel gioco d’azzardo, l’altezza e il peso delle persone, la pressione sanguigna, i punteggi di alcuni test standardizzati e gli errori di misura negli esperimenti. I motivi matematici e probabilistici di queste approssimazioni verranno discussi in seguito; qui ci concentreremo sul come la distribuzione normale aiuti a riassumere i dati.\nAnziché partire da dati empirici, la distribuzione normale si definisce tramite una formula matematica. Per un intervallo generico \\((a,b)\\), la proporzione di valori che cade in tale intervallo si ottiene mediante:\n\\[\n\\text{Pr}(a &lt; x \\leq b) \\;=\\; \\int_a^b \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\, e^{-\\tfrac12\\,\\bigl(\\tfrac{x - \\mu}{\\sigma}\\bigr)^2}\\, dx .\n\\tag{19.1}\\]\nNon è necessario memorizzare o padroneggiare i dettagli di questa formula, ma è importante sapere che la distribuzione normale è completamente determinata da due soli parametri: \\(\\mu\\) e \\(\\sigma\\). Gli altri simboli nella formula (\\(\\pi\\), \\(e\\), \\(a\\), \\(b\\)) rappresentano costanti matematiche o gli estremi dell’intervallo. In particolare, \\(\\mu\\) è il valore medio (o media) e \\(\\sigma\\) è la deviazione standard.\nQuesta distribuzione è simmetrica, centrata sulla media \\(\\mu\\), e la maggior parte dei valori (circa il 95%) si trova entro 2 deviazioni standard dalla media, cioè nell’intervallo \\(\\mu \\pm 2\\sigma\\). Ecco un esempio di come appare la distribuzione normale quando \\(\\mu = 0\\) e \\(\\sigma = 1\\):\n\nm &lt;- 0; s &lt;- 1\nnorm_dist &lt;- tibble(x = seq(-4, 4, length.out = 50)*s + m) |&gt; \n  mutate(density = dnorm(x, m, s))\nnorm_dist |&gt; \n  ggplot(aes(x, density)) + geom_line()\n\n\n\n\n\n\n\nIl fatto che la distribuzione sia descritta da due parametri implica che, se un insieme di dati reali si approssima bene a una distribuzione normale, due soli numeri (media e deviazione standard) possono fornire un riassunto sintetico della distribuzione. Vediamo ora come si calcolano, in pratica, questi due parametri per una lista di valori arbitraria.\nSupponiamo di avere un vettore x che contiene una serie di valori numerici. Abbiamo visto come, in R, la media si trova come:\nm &lt;- sum(x) / length(x)\ne la deviazione standard è:\ns &lt;- sqrt(sum((x - m)^2) / length(x))\nLa deviazione standard si può interpretare come la distanza media dei valori dalla loro media.\n\n19.1.1 Un esempio con i dati di altezza\nPer calcolare media e deviazione standard dell’altezza maschile in un dataset, ipotizziamo che il vettore heights$height contenga le altezze di alcuni individui, mentre heights$sex contenga il genere corrispondente. Se vogliamo estrarre solo i valori relativi ai maschi, possiamo scrivere:\n\nindex &lt;- heights$sex == \"Male\"\nx &lt;- heights$height[index]\n\nQuindi usiamo le funzioni predefinite di R:\n\nm &lt;- mean(x)\ns &lt;- sd(x)\n\n\n\n\n\n\n\nNota: Per motivi che verranno chiariti in seguito, la funzione sd(x) effettua una divisione per \\(\\text{length}(x) - 1\\) invece che per \\(\\text{length}(x)\\). Tuttavia, se il numero di osservazioni è elevato, questa differenza è trascurabile.\n\n\n\nPossiamo ora mettere a confronto la curva di densità osservata dei dati (in blu) con quella teorica (in nero) della distribuzione normale con media e deviazione standard stimate:\n\nnorm_dist &lt;- tibble(\n  x = seq(-4, 4, length.out = 50)*s + m) |&gt; \n  mutate(density = dnorm(x, m, s))\n\nheights |&gt; \n  dplyr::filter(sex == \"Male\") |&gt; \n  ggplot(aes(height)) +\n  geom_density(fill = \"lightblue\") +\n  geom_line(aes(x, density), linewidth=1.5, data = norm_dist)\n\n\n\n\n\n\n\nCome si vede, la curva normale fornisce una buona approssimazione per i dati sull’altezza maschile. Vedremo ora come verificare l’aderenza di una distribuzione ai dati, osservando le proporzioni di valori entro intervalli specifici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#unità-standard",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#unità-standard",
    "title": "19  Introduzione alla distribuzione normale",
    "section": "\n19.2 Unità standard",
    "text": "19.2 Unità standard\nPer i dati che seguono (o quasi) una distribuzione normale, è molto comodo utilizzare le cosiddette unità standard (Standard Units). Un valore \\(x\\) viene convertito in unità standard tramite la formula:\n\\[\nz = \\frac{x - m}{s} ,\n\\]\ndove \\(m\\) e \\(s\\) sono la media e la deviazione standard della distribuzione. Questa trasformazione ci dice di quante deviazioni standard un particolare valore si discosta dalla media. Ad esempio, se \\(z=0\\), il valore \\(x\\) corrisponde esattamente alla media; se \\(z = 2\\), il valore \\(x\\) si trova a due deviazioni standard sopra la media; se \\(z = -2\\), a due deviazioni standard sotto la media, e così via.\nIn R, possiamo calcolare le unità standard con la funzione:\n\nz &lt;- scale(x) |&gt; as.numeric()\nhead(z)\n#&gt; [1]  1.5744  0.1898 -0.3641  1.2975 -2.3026 -0.6410\n\nSe vogliamo sapere, ad esempio, quale frazione di individui si trova entro 2 deviazioni standard dalla media (cioè \\(|z| &lt; 2\\)), basta scrivere:\n\nmean(abs(z) &lt; 2)\n#&gt; [1] 0.9495\n\nVedremo, in molti casi, un valore intorno al 95%, in linea con quanto previsto dalla distribuzione normale. Per confermare la bontà dell’approssimazione, si usano spesso i grafici quantile-quantile, detti anche qqplot.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#grafici-quantile-quantile-qqplot",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#grafici-quantile-quantile-qqplot",
    "title": "19  Introduzione alla distribuzione normale",
    "section": "\n19.3 Grafici quantile-quantile (qqplot)",
    "text": "19.3 Grafici quantile-quantile (qqplot)\nUn modo sistematico per verificare quanto la distribuzione normale descriva bene i dati osservati consiste nel confrontare i quantili empirici con quelli teorici di una normale. Se i due insiemi di quantili sono molto simili, abbiamo un’ulteriore conferma dell’aderenza alla normalità.\n\nLa funzione di ripartizione della distribuzione normale standard si indica spesso con \\(\\Phi(x)\\). Ad esempio, \\(\\Phi(-1.96) \\approx 0.025\\) e \\(\\Phi(1.96) \\approx 0.975\\).\n\nL’inversa di \\(\\Phi\\), indicata come \\(\\Phi^{-1}(p)\\), ci dà il quantile corrispondente a una determinata probabilità \\(p\\). In R, pnorm calcola \\(\\Phi(x)\\) e qnorm calcola \\(\\Phi^{-1}(p)\\). Di default, pnorm e qnorm si riferiscono alla normale standard (media 0, deviazione standard 1), ma possiamo specificare valori diversi di media e deviazione standard tramite gli argomenti mean e sd.\n\nPer ottenere il quantile empirico da un vettore di dati in R, possiamo usare la funzione quantile. Ad esempio, se abbiamo un vettore x, il quantile associato alla probabilità \\(p\\) è il valore \\(q\\) per il quale mean(x &lt;= q) = p.\nEcco lo schema logico per costruire un qqplot:\n\nDefiniamo un vettore di proporzioni \\(p_1, p_2, \\dots, p_m\\).\n\nCalcoliamo i relativi quantili empirici dei nostri dati \\(\\{q_1, \\dots, q_m\\}\\) usando quantile(x, p_i).\n\nCalcoliamo i quantili teorici della normale (con la stessa media e la stessa deviazione standard dei dati) usando qnorm(p_i, mean, sd).\n\nRappresentiamo i punti \\((\\text{quantile teorico}, \\text{quantile empirico})\\). Se i dati sono davvero normali, tali punti si disporranno approssimativamente lungo la retta diagonale y = x.\n\nEsempio in R:\n\np &lt;- seq(0.05, 0.95, 0.05)\nsample_quantiles &lt;- quantile(x, p)\ntheoretical_quantiles &lt;- qnorm(p, mean = mean(x), sd = sd(x))\n\nqplot(theoretical_quantiles, sample_quantiles) + geom_abline()\n\n\n\n\n\n\n\nSe però abbiamo già convertito in unità standard (quindi \\(\\mu = 0\\) e \\(\\sigma = 1\\)), il confronto si semplifica:\n\nsample_quantiles &lt;- quantile(z, p)\ntheoretical_quantiles &lt;- qnorm(p)\nqplot(theoretical_quantiles, sample_quantiles) + geom_abline()\n\n\n\n\n\n\n\nIn pratica, per creare rapidamente un qqplot si usa spesso ggplot2 con la geometria geom_qq:\n\nheights |&gt; filter(sex == \"Male\") |&gt;\n  ggplot(aes(sample = scale(height))) + \n  geom_qq() +\n  geom_abline()\n\n\n\n\n\n\n\nCome abbiamo sottolineato, se i punti nel qqplot si dispongono lungo una retta, significa che la distribuzione dei dati è in accordo con la distribuzione teorica considerata (in questo caso, la normale). I qqplot possono essere usati anche per confrontare qualsiasi coppia di distribuzioni, non solo dati e normale teorica.\nQuesto indica che l’approssimazione normale è accurata per il gruppo maschile (nel nostro dataset).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#media-e-deviazione-standard-come-statistiche-descrittive-della-distribuzione",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#media-e-deviazione-standard-come-statistiche-descrittive-della-distribuzione",
    "title": "19  Introduzione alla distribuzione normale",
    "section": "\n19.4 Media e Deviazione Standard come Statistiche Descrittive della Distribuzione",
    "text": "19.4 Media e Deviazione Standard come Statistiche Descrittive della Distribuzione\nLa media e la deviazione standard sono due delle statistiche più comunemente utilizzate per descrivere la distribuzione di un insieme di dati. Queste misure sono particolarmente utili quando i dati seguono una distribuzione normale. In questo caso, la media e la deviazione standard contengono tutte le informazioni necessarie per caratterizzare completamente la forma della distribuzione.\n\n19.4.1 Distribuzione Normale e Statistiche Descrittive\nLa distribuzione normale è definita dalla sua media (\\(\\mu\\)) e dalla sua deviazione standard (\\(\\sigma\\)). La formula della densità di probabilità della distribuzione normale è data dall’Equazione 19.1. Questa formula mostra che, conoscendo solo \\(\\mu\\) e \\(\\sigma\\), possiamo ricostruire l’intera curva di densità. Pertanto, se i dati empirici sono ben approssimati da una distribuzione normale, la media e la deviazione standard sono sufficienti per descrivere la distribuzione.\nSupponiamo di avere un dataset che segue una distribuzione normale con media 50 e deviazione standard 10. Possiamo generare dati casuali e visualizzare la curva di densità in R:\n\n# Generiamo dati da una distribuzione normale\nset.seed(123)\ndati &lt;- rnorm(1000, mean = 50, sd = 10)\n\n# Calcoliamo media e deviazione standard\nmedia &lt;- mean(dati)\ndeviazione_standard &lt;- sd(dati)\n\n# Visualizziamo la curva di densità\nggplot(data.frame(dati), aes(x = dati)) +\n  geom_density(fill = \"lightblue\") +\n  geom_vline(xintercept = media, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Curva di Densità di una Distribuzione Normale\",\n       x = \"Valori\",\n       y = \"Densità\") +\n  annotate(\"text\", x = media + 5, y = 0.03, label = paste(\"Media =\", round(media, 2)), color = \"red\") +\n  annotate(\"text\", x = media + 5, y = 0.025, label = paste(\"Deviazione Standard =\", round(deviazione_standard, 2)), color = \"blue\")\n\n\n\n\n\n\n\nIn questo esempio:\n\nLa curva di densità è centrata attorno alla media (\\(\\mu = 50\\)).\nLa deviazione standard (\\(\\sigma = 10\\)) determina la dispersione dei dati attorno alla media.\n\n19.4.2 Quando Media e Deviazione Standard Non Sono Sufficienti\nSebbene media e deviazione standard siano strumenti estremamente utili per descrivere distribuzioni normali, non sempre bastano a cogliere tutte le caratteristiche di un insieme di dati. In particolare, ci sono situazioni in cui la forma della distribuzione rende necessario ricorrere a misure aggiuntive. Di seguito presentiamo alcuni casi tipici.\n\n\nDistribuzioni Asimmetriche\nUna distribuzione si dice asimmetrica (o skewed) quando una coda è più “estesa” dell’altra.\n\nSe la coda più lunga è a destra, la distribuzione è asimmetrica positiva (o a destra).\n\nSe la coda più lunga è a sinistra, la distribuzione è asimmetrica negativa (o a sinistra).\nIn queste circostanze, la media tende a spostarsi verso la coda più lunga, mentre la mediana rimane più stabile e rappresentativa del valore centrale.\n\n\nDistribuzioni Multimodali\nUna distribuzione è multimodale quando presenta più picchi (o “modi”). Ciò significa che i dati si concentrano attorno a più di un valore, formando veri e propri sotto-gruppi. In questi casi, media e deviazione standard possono risultare poco significative, poiché non colgono la presenza di più poli di concentrazione.\n\nKurtosi\nLa kurtosi descrive quanto una distribuzione sia “appuntita” o “piatta” rispetto a una normale.\n\n\nAlta kurtosi indica picchi molto accentuati e code più lunghe, con una maggiore probabilità di valori estremi.\n\n\nBassa kurtosi segnala una forma più appiattita, con code ridotte e meno outlier.\n\n\n\nQuando le distribuzioni mostrano una di queste peculiarità, altre statistiche possono rivelarsi più informative:\n\nLa mediana, insensibile ai valori estremi, fornisce una descrizione più robusta del centro.\n\nI quartili, e in particolare l’intervallo interquartile, danno un’idea della dispersione principale trascurando le code.\n\nL’indice di asimmetria (skewness) misura il grado di sbilanciamento della distribuzione.\n\nL’indice di curtosi (kurtosis) quantifica la “pesantezza” delle code.\n\nNel seguente esempio, generiamo dati da una distribuzione esponenziale, notoriamente asimmetrica:\n\n# Generiamo dati da una distribuzione esponenziale\nset.seed(123)\ndati_esponenziali &lt;- rexp(1000, rate = 0.5)\n\n# Calcoliamo media e deviazione standard\nmedia_esp &lt;- mean(dati_esponenziali)\ndeviazione_standard_esp &lt;- sd(dati_esponenziali)\n\n# Visualizziamo la curva di densità\nggplot(data.frame(dati_esponenziali), aes(x = dati_esponenziali)) +\n  geom_density(fill = \"#F8766D\", alpha = 0.6) +\n  geom_vline(xintercept = media_esp, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Curva di Densità di una Distribuzione Esponenziale\",\n       x = \"Valori\",\n       y = \"Densità\") +\n  annotate(\"text\", x = media_esp + 1, y = 0.2, \n           label = paste(\"Media =\", round(media_esp, 2)), \n           color = \"red\") +\n  annotate(\"text\", x = media_esp + 1, y = 0.18, \n           label = paste(\"Deviazione Standard =\", round(deviazione_standard_esp, 2)), \n           color = \"blue\")\n\n\n\n\n\n\n\nL’istogramma (o la densità) mostra chiaramente una coda lunga a destra, con molti valori piccoli e pochi valori grandi. In questo contesto:\n\nLa media tende a seguire la coda, diventando meno rappresentativa del “centro”.\n\nLa deviazione standard non descrive in modo efficace la variabilità, perché non considera adeguatamente la forte asimmetria.\n\nMisure alternative, come la mediana e i quartili, forniscono informazioni più affidabili:\n\n# Calcoliamo mediana e quartili\nmediana &lt;- median(dati_esponenziali)\nquartili &lt;- quantile(dati_esponenziali, probs = c(0.25, 0.75))\n\ncat(\"Mediana:\", mediana, \"\\n\")\n#&gt; Mediana: 1.462\ncat(\"Primo Quartile (Q1):\", quartili[1], \"\\n\")\n#&gt; Primo Quartile (Q1): 0.6134\ncat(\"Terzo Quartile (Q3):\", quartili[2], \"\\n\")\n#&gt; Terzo Quartile (Q3): 2.853\n\nIn conclusione, quando i dati non presentano una forma vicina alla normalità (ad esempio perché asimmetrici, multimodali o con kurtosi anomala), media e deviazione standard possono risultare fuorvianti o poco utili. In questi casi, è fondamentale adottare misure alternative o complementari (mediana, quartili, skewness, kurtosis) per ottenere una descrizione più accurata della distribuzione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#riflessioni-conclusive",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#riflessioni-conclusive",
    "title": "19  Introduzione alla distribuzione normale",
    "section": "\n19.5 Riflessioni Conclusive",
    "text": "19.5 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato alcuni concetti fondamentali per l’analisi dei dati e consolidato le basi per un’interpretazione più approfondita delle distribuzioni. In particolare, abbiamo:\n\n\nStudiato la distribuzione normale, una delle distribuzioni più importanti in statistica, e compreso perché la media e la deviazione standard siano parametri cruciali per descriverla. Questi indicatori ci permettono di riassumere in modo efficace le caratteristiche centrali e la variabilità dei dati.\n\nImparato a standardizzare i dati convertendoli in unità standard (z-score), il che ci consente di confrontare variabili con scale diverse o di valutare quanto un dato specifico si discosti dalla media in termini di deviazioni standard.\n\nIntrodotto il grafico quantile-quantile (QQ-plot), uno strumento visivo prezioso per verificare se i nostri dati seguono una distribuzione normale. Attraverso il QQ-plot, possiamo confrontare i quantili empirici dei nostri dati con quelli teorici della distribuzione normale, identificando eventuali deviazioni.\n\nGli strumenti descritti in questo capitolo rappresentano il primo passo essenziale nell’analisi esplorativa dei dati. Essi ci aiutano a formulare ipotesi solide e a riconoscere potenziali problemi o caratteristiche peculiari dei dati prima di applicare metodi statistici più avanzati, che approfondiremo nei prossimi capitoli.\nL’analisi esplorativa, combinando grafici intuitivi e statistiche descrittive appropriate, riveste quindi un ruolo fondamentale nel processo analitico. Essa non solo ci aiuta a comprendere meglio la natura dei dati, ma ci fornisce anche una base solida su cui costruire conclusioni statistiche attendibili e informate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#esercizi",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#esercizi",
    "title": "19  Introduzione alla distribuzione normale",
    "section": "\n19.6 Esercizi",
    "text": "19.6 Esercizi\n\n\n\n\n\n\nEsercizi\n\n\n\n\n\nEsercizi Teorici\n📌 Rispondi alle seguenti domande per consolidare la comprensione teorica della distribuzione normale e dei suoi concetti chiave.\n\n\nCaratteristiche della distribuzione normale\n\nQuali sono i due parametri principali della distribuzione normale?\n\nPerché la distribuzione normale è utilizzata così frequentemente in statistica?\n\nIn quali situazioni reali possiamo aspettarci che una variabile segua una distribuzione normale?\n\n\n\nMedia e deviazione standard\n\nQual è il significato della media in una distribuzione normale?\n\nCosa rappresenta la deviazione standard?\n\nIn che modo la deviazione standard influenza la forma della curva normale?\n\n\n\nZ-score e standardizzazione\n\nCos’è uno z-score e come si calcola?\n\nQual è il significato di un valore z=2? E di un valore z=-1.5?\n\nDopo la standardizzazione, quali saranno la media e la deviazione standard della variabile?\n\n\n\nVerifica della normalità\n\nSe hai un piccolo campione di dati (circa 15 osservazioni), quali metodi grafici puoi utilizzare per valutare se segue una distribuzione normale?\n\nQuali strumenti statistici puoi impiegare per testare la normalità?\n\nIn un QQ-plot, come puoi riconoscere se i dati seguono una distribuzione normale?\n\n\n\nEsercizi Pratici in R\n📌 Obiettivo: Analizzare i dati raccolti dagli studenti sulla Satisfaction With Life Scale (SWLS), comprendere la loro distribuzione e confrontarli con una distribuzione normale teorica.\n💾 Dati disponibili:\nUsa i dati della SWLS. I dati contengono anche informazioni sul genere e su un indice di rete sociale (LSNS).\n1. Esplorazione e Visualizzazione dei Dati SWLS\n\n\nCarica i dati raccolti dagli studenti e verifica la struttura del dataset.\n\n\nCalcola i valori di base: media, deviazione standard, minimo, massimo, e quantili della SWLS.\n\n\nCrea una rappresentazione visiva dei dati:\n\nIstogramma con sovrapposta una curva di densità.\n\nBoxplot per identificare eventuali outlier.\n\nViolin plot per osservare la distribuzione.\n\n\n\n2. Confronto con la Distribuzione Normale\n\n\nSovrapponi ai dati osservati una curva normale teorica basata su media e deviazione standard stimate dal campione.\n\n\nConfronta i quantili empirici con quelli teorici mediante un QQ-plot.\n\n\nCommenta il risultato: i dati SWLS seguono approssimativamente una normale? Se no, quali differenze noti?\n\n3. Standardizzazione dei Punteggi SWLS\n\n\nTrasforma i dati della SWLS in z-score per analizzarli in unità standardizzate.\n\nVerifica la nuova media e deviazione standard: dovrebbero essere 0 e 1 rispettivamente.\n\n\nConta quanti punteggi standardizzati si trovano entro 1, 2 e 3 deviazioni standard dalla media e confronta i valori attesi di 68%, 95% e 99.7%.\n\n4. Relazione tra SWLS e Interazione Sociale (LSNS)\n\n\nEsplora la relazione tra SWLS e il punteggio della Scala della Rete Sociale di Lubben (LSNS-6).\n\n\nCostruisci un grafico a dispersione per osservare la correlazione tra le due variabili.\n\n\nCalcola il coefficiente di correlazione di Pearson e commenta il risultato. Esiste una relazione tra soddisfazione della vita e supporto sociale?\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Caratteristiche della distribuzione normale\na. Quali sono i due parametri principali della distribuzione normale?\nI due parametri principali che definiscono una distribuzione normale sono:\n\n\nLa media (μ): Indica il centro della distribuzione. Tutte le osservazioni si raggruppano attorno a questo valore.\n\nLa deviazione standard (σ): Descrive la dispersione o la variabilità dei dati attorno alla media.\n\nb. Perché la distribuzione normale è utilizzata così frequentemente in statistica?\nLa distribuzione normale è ampiamente usata per diversi motivi:\n\n\nTeorema del limite centrale: Afferma che, quando si sommano molte variabili casuali indipendenti, la loro distribuzione tende ad avvicinarsi a una normale, indipendentemente dalla forma originale delle singole distribuzioni.\n\nSemplicità matematica: La normale ha proprietà matematiche ben definite e permette di calcolare probabilità e intervalli con facilità.\n\nModellizzazione naturale: Molte variabili naturali e sociali (ad esempio, altezze, pesi, punteggi standardizzati) seguono approssimativamente una distribuzione normale.\n\nc. In quali situazioni reali possiamo aspettarci che una variabile segua una distribuzione normale?\nSi può aspettare una distribuzione normale in situazioni in cui:\n\nLe osservazioni sono influenzate da molti fattori casuali indipendenti (es. altezza di un individuo, errore di misurazione).\nI dati derivano da fenomeni naturali o biologici (es. pressione sanguigna, peso corporeo).\nSi analizzano medie campionarie di grandi dimensioni (grazie al teorema del limite centrale).\n\n2. Media e deviazione standard\na. Qual è il significato della media in una distribuzione normale?\nNella distribuzione normale, la media rappresenta il punto centrale della curva, ovvero il valore più probabile. È anche il punto di simmetria della distribuzione, dove metà delle osservazioni si trova a sinistra e l’altra metà a destra.\nb. Cosa rappresenta la deviazione standard?\nLa deviazione standard misura quanto i dati si discostano in media dalla media. Una deviazione standard bassa indica che i dati sono raggruppati strettamente attorno alla media, mentre una deviazione standard alta indica una maggiore dispersione.\nc. In che modo la deviazione standard influenza la forma della curva normale?\n\nUna deviazione standard piccola produce una curva alta e stretta, indicando una bassa variabilità.\nUna deviazione standard grande produce una curva bassa e larga, indicando una maggiore variabilità.\n\n3. Z-score e standardizzazione\na. Cos’è uno z-score e come si calcola?\nUno z-score misura quante deviazioni standard un dato si discosta dalla media. Viene calcolato come:\n\\[\nz = \\frac{x - \\mu}{\\sigma}\n\\]\ndove \\(x\\) è il valore osservato, \\(\\mu\\) è la media e \\(\\sigma\\) è la deviazione standard.\nb. Qual è il significato di un valore z=2? E di un valore z=-1.5?\n\nUn \\(z = 2\\) significa che il dato è posizionato a 2 deviazioni standard sopra la media.\nUn \\(z = -1.5\\) significa che il dato è posizionato a 1.5 deviazioni standard sotto la media.\n\nc. Dopo la standardizzazione, quali saranno la media e la deviazione standard della variabile?\nDopo la standardizzazione:\n\nLa media diventa \\(0\\).\nLa deviazione standard diventa \\(1\\).\n\n4. Verifica della normalità\na. Se hai un piccolo campione di dati (circa 15 osservazioni), quali metodi grafici puoi utilizzare per valutare se segue una distribuzione normale?\nPer piccoli campioni, i metodi grafici più utili sono:\n\n\nQQ-plot (Quantile-Quantile plot): Confronta i quantili dei dati con quelli di una distribuzione normale. Se i punti seguono una retta diagonale, i dati sono normali.\n\nIstogramma: Mostra la distribuzione dei dati, ma con campioni piccoli può essere meno preciso.\n\nb. Quali strumenti statistici puoi impiegare per testare la normalità?\nGli strumenti statistici più comuni per verificare la normalità sono:\n\n\nTest di Shapiro-Wilk: Ideale per piccoli campioni.\n\nTest di Kolmogorov-Smirnov: Usato per confrontare la distribuzione empirica con una normale.\n\nTest di Anderson-Darling: Sensibile alle code della distribuzione.\n\nc. In un QQ-plot, come puoi riconoscere se i dati seguono una distribuzione normale?\nIn un QQ-plot:\n\nSe i dati seguono una distribuzione normale, i punti si allineeranno lungo una retta diagonale.\nDeviazioni dalla retta indicano departi dalla normalità:\n\nCode pesanti: Punti esterni alla retta suggeriscono outlier.\nAsimmetria: Punti curvati suggeriscono skewness (asimmetria).\n\n\n\nEsplorazione e Visualizzazione dei Dati SWLS\nCaricamento e struttura dei dati\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Supponiamo che i dati siano i seguenti\nset.seed(42)\nswls &lt;- data.frame(\n  ID = 1:15,\n  SWLS = c(18, 22, 25, 21, 26, 19, 20, 23, 24, 17, 22, 27, 28, 21, 19),\n  Genere = c(\"M\", \"F\", \"F\", \"M\", \"F\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"F\", \"M\", \"M\"),\n  LSNS = c(16, 20, 22, 14, 19, 18, 17, 25, 23, 12, 21, 28, 26, 19, 15)\n)\n\nstr(swls)\nsummary(swls$SWLS)\nVisualizzazioni\n# Istogramma con curva di densità\nggplot(swls, aes(x = SWLS)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 6, fill = \"blue\", alpha = 0.5) +\n  geom_density(color = \"red\", size = 1) +\n  ggtitle(\"Distribuzione dei punteggi SWLS\")\n\n# Boxplot\nggplot(swls, aes(y = SWLS)) +\n  geom_boxplot(fill = \"cyan\") +\n  ggtitle(\"Boxplot dei punteggi SWLS\")\n2. Confronto con la Distribuzione Normale\n# QQ-plot per valutare la normalità\nggplot(swls, aes(sample = SWLS)) +\n  geom_qq() +\n  geom_abline() +\n  ggtitle(\"QQ-plot dei punteggi SWLS\") +\n  theme_minimal()\nOsservazione:\n\nSe i punti si allineano lungo la diagonale, i dati sono approssimativamente normali.\nSe ci sono deviazioni marcate, la distribuzione potrebbe essere asimmetrica o presentare code pesanti.\n\n3. Standardizzazione dei punteggi SWLS\nswls$Z_SWLS &lt;- scale(swls$SWLS)\n\nmean(swls$Z_SWLS)  # Dovrebbe essere circa 0\nsd(swls$Z_SWLS)    # Dovrebbe essere circa 1\n\n# Proporzione entro 1, 2, 3 deviazioni standard\nmean(abs(swls$Z_SWLS) &lt; 1)  # Atteso ~68%\nmean(abs(swls$Z_SWLS) &lt; 2)  # Atteso ~95%\nmean(abs(swls$Z_SWLS) &lt; 3)  # Atteso ~99.7%\n4. Relazione tra SWLS e LSNS\n# Grafico di dispersione\nggplot(swls, aes(x = LSNS, y = SWLS)) +\n  geom_point(color = \"blue\", size = 3) +\n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n  ggtitle(\"Relazione tra SWLS e LSNS\") \n\n# Calcolo della correlazione\ncor(swls$SWLS, swls$LSNS)\nInterpretazione:\n\nUn valore di correlazione positivo indica che livelli più alti di supporto sociale (LSNS) sono associati a una maggiore soddisfazione della vita (SWLS).\n\nSe la correlazione è debole, il supporto sociale potrebbe non essere un predittore forte della soddisfazione della vita in questo campione ristretto.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#informazioni-sullambiente-di-sviluppo",
    "title": "19  Introduzione alla distribuzione normale",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] dslabs_0.8.0     ggbeeswarm_0.7.2 thematic_0.1.6   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.10.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt; [13] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 vipor_0.4.7       beeswarm_0.4.0   \n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      glue_1.8.0       \n#&gt; [33] xfun_0.50         tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29   \n#&gt; [41] compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#bibliografia",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#bibliografia",
    "title": "19  Introduzione alla distribuzione normale",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html",
    "href": "chapters/eda/08_correlation.html",
    "title": "20  Relazioni tra variabili",
    "section": "",
    "text": "20.1 Introduzione\nNonostante sia un’operazione di base, l’analisi delle associazioni tra variabili rappresenta uno degli aspetti più controversi nell’ambito dell’analisi dei dati psicologici. Sebbene possa sembrare un passaggio naturale dopo l’analisi univariata, questo processo solleva numerose questioni metodologiche e concettuali.\nTradizionalmente, in psicologia, l’analisi delle associazioni tra variabili è stata considerata come l’obiettivo finale del processo di ricerca. Questa visione si basa sull’idea che la descrizione delle relazioni tra variabili fornisca una spiegazione esaustiva dei fenomeni psicologici. Tale approccio trova le sue radici storiche nel pensiero di Karl Pearson (1911), il quale sosteneva che la spiegazione scientifica si esaurisse una volta delineate le associazioni tra le variabili osservate:\nSebbene sia indubbio che rispondere alla seconda domanda posta da Pearson sia relativamente semplice, è altresì evidente che la nostra comprensione di un fenomeno non può dipendere unicamente dalle informazioni fornite dalle correlazioni.\nIn contrasto con questa visione tradizionale, la “Causal Revolution” propone un paradigma radicalmente diverso secondo il quale le associazioni tra variabili sono considerate come epifenomeni, mentre l’obiettivo principale della ricerca è l’identificazione e la comprensione delle relazioni causali: per comprendere veramente i fenomeni psicologici è essenziale indagare le cause sottostanti, andando oltre la mera descrizione delle associazioni.\nLa discussione dei metodi utilizzati per individuare le relazioni causali sarà trattata successivamente. In questo capitolo, ci concentreremo sui concetti statistici fondamentali necessari per descrivere le associazioni lineari tra variabili. È importante sottolineare che, sebbene esistano indici statistici per quantificare associazioni non lineari, la maggior parte degli psicologi si limita all’utilizzo di indici lineari.\nNel linguaggio comune, termini come “dipendenza”, “associazione” e “correlazione” vengono spesso usati in modo intercambiabile. Tuttavia, da un punto di vista tecnico, è importante distinguere questi concetti:\nÈ cruciale comprendere che non tutte le associazioni sono correlazioni e, soprattutto, che la correlazione non implica necessariamente causalità. Questa distinzione è fondamentale per interpretare correttamente i dati e evitare conclusioni errate sulle relazioni tra variabili.\nIn questo capitolo, esamineremo due misure statistiche fondamentali per valutare la relazione lineare tra due variabili: la covarianza e la correlazione. Questi indici ci permettono di descrivere il grado e la direzione dell’associazione lineare tra variabili, quantificando come queste variano congiuntamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#introduzione",
    "href": "chapters/eda/08_correlation.html#introduzione",
    "title": "20  Relazioni tra variabili",
    "section": "",
    "text": "Quanto spesso, quando è stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‘qual è la sua causa?’. Questa è una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, può essere più facile rispondere alla domanda: ‘in che misura altri fenomeni sono associati con esso?’. Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze.\n\n\n\n\n\n\n\nAssociazione: questo termine indica una relazione generale tra variabili, dove la conoscenza del valore di una variabile fornisce informazioni su un’altra.\n\nCorrelazione: descrive una relazione specifica e quantificabile, indicando se due variabili tendono a variare insieme in modo sistematico. Ad esempio, in una correlazione positiva, se \\(X &gt; \\mu_X\\), è probabile che anche \\(Y &gt; \\mu_Y\\). La correlazione specifica il segno e l’intensità di una relazione lineare.\n\nDipendenza: indica una relazione causale tra le variabili, dove la variazione della variabile causale porta probabilisticamente alla variazione della variabile dipendente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#i-dati-grezzi",
    "href": "chapters/eda/08_correlation.html#i-dati-grezzi",
    "title": "20  Relazioni tra variabili",
    "section": "\n20.2 I dati grezzi",
    "text": "20.2 I dati grezzi\nPer illustrare la correlazione e la covarianza, analizzeremo i dati raccolti da Zetsche et al. (2019) in uno studio che indaga le aspettative negative come meccanismo chiave nel mantenimento e nella reiterazione della depressione. Nello specifico, i ricercatori si sono proposti di determinare se gli individui depressi sviluppano aspettative accurate riguardo al loro umore futuro o se tali aspettative sono distortamente negative.\nUno dei loro studi ha coinvolto un campione di 30 soggetti con almeno un episodio depressivo maggiore, confrontati con un gruppo di controllo composto da 37 individui sani. La misurazione del livello di depressione è stata effettuata tramite il Beck Depression Inventory (BDI-II).\nIl BDI-II è uno strumento di autovalutazione utilizzato per valutare la gravità della depressione in adulti e adolescenti. Il test è stato sviluppato per identificare e misurare l’intensità dei sintomi depressivi sperimentati nelle ultime due settimane. I 21 item del test sono valutati su una scala a 4 punti, dove 0 rappresenta il grado più basso e 3 il grado più elevato di sintomatologia depressiva.\nNell’esercizio successivo, ci proponiamo di analizzare i punteggi di depressione BDI-II nel campione di dati fornito da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#definizione-delle-relazioni-tra-variabili",
    "href": "chapters/eda/08_correlation.html#definizione-delle-relazioni-tra-variabili",
    "title": "20  Relazioni tra variabili",
    "section": "\n20.3 Definizione delle relazioni tra variabili",
    "text": "20.3 Definizione delle relazioni tra variabili\nNel contesto delle indagini statistiche, spesso non ci limitiamo a esaminare la distribuzione di una singola variabile. Invece, il nostro interesse si concentra sulla relazione che emerge nei dati tra due o più variabili. Ma cosa significa esattamente quando diciamo che due variabili hanno una relazione?\nPer comprendere ciò, prendiamo ad esempio l’altezza e l’età tra un gruppo di bambini. In generale, è possibile notare che all’aumentare dell’età di un bambino, aumenta anche la sua altezza. Pertanto, conoscere l’età di un bambino, ad esempio tredici anni, e l’età di un altro, sei anni, ci fornisce un’indicazione su quale dei due bambini sia più alto.\nNel linguaggio statistico, definiamo questa relazione tra altezza e età come positiva, il che significa che all’aumentare dei valori di una delle variabili (in questo caso, l’età), ci aspettiamo di vedere valori più elevati anche nell’altra variabile (l’altezza). Tuttavia, esistono anche relazioni negative, in cui l’aumento di una variabile è associato a un diminuzione dell’altra (ad esempio, più età è correlata a meno pianto).\nNon si tratta solo di relazioni positive o negative; ci sono anche situazioni in cui le variabili non hanno alcuna relazione tra loro, definendo così una relazione nulla. Inoltre, le relazioni possono variare nel tempo, passando da positive a negative o da fortemente positive a appena positiva. In alcuni casi, una delle variabili può essere categorica, rendendo difficile parlare di “maggioranza” o “minoranza” ma piuttosto di “differente” (ad esempio, i bambini più grandi potrebbero semplicemente avere diverse preferenze rispetto ai bambini più piccoli, senza necessariamente essere “migliori” o “peggiori”).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#sec-scatter-plot",
    "href": "chapters/eda/08_correlation.html#sec-scatter-plot",
    "title": "20  Relazioni tra variabili",
    "section": "\n20.4 Grafico a dispersione",
    "text": "20.4 Grafico a dispersione\nIl metodo più diretto per visualizzare la relazione tra due variabili continue è tramite un grafico a dispersione, comunemente noto come “scatterplot”. Questo tipo di diagramma rappresenta le coppie di dati ottenute da due variabili, posizionandole sull’asse delle ascisse (orizzontale) e delle ordinate (verticale).\nPer rendere l’idea più chiara, consideriamo i dati dello studio condotto da Zetsche et al. (2019), in cui i ricercatori hanno utilizzato due scale psicometriche, il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D), per misurare il livello di depressione nei partecipanti. Il BDI-II è uno strumento di autovalutazione che valuta la presenza e l’intensità dei sintomi depressivi in pazienti adulti e adolescenti con diagnosi psichiatrica, mentre la CES-D è una scala di autovalutazione progettata per misurare i sintomi depressivi sperimentati nella settimana precedente nella popolazione generale, in particolare negli adolescenti e nei giovani adulti. Poiché entrambe le scale misurano lo stesso costrutto, ovvero la depressione, ci aspettiamo una relazione tra i punteggi ottenuti dal BDI-II e dalla CES-D. Un diagramma a dispersione ci consente di esaminare questa relazione in modo visuale e intuitivo.\n\n# Leggi i dati dal file CSV\ndf &lt;- rio::import(here::here(\"data\", \"data.mood.csv\"))\n\n# Seleziona le colonne di interesse\ndf &lt;- df |&gt;\n  dplyr::select(\"esm_id\", \"group\", \"bdi\", \"cesd_sum\")\n\n# Rimuovi le righe duplicate\ndf &lt;- df[!duplicated(df), ]\n\n# Rimuovi le righe con valori mancanti nella colonna \"bdi\"\ndf &lt;- df[!is.na(df$bdi), ]\n\nPosizionando i valori del BDI-II sull’asse delle ascisse e quelli del CES-D sull’asse delle ordinate, ogni punto sul grafico rappresenta un individuo, di cui conosciamo il livello di depressione misurato dalle due scale. È evidente che i valori delle scale BDI-II e CES-D non possono coincidere per due motivi principali: (1) la presenza di errori di misurazione e (2) l’utilizzo di unità di misura arbitrarie per le due variabili. L’errore di misurazione è una componente inevitabile che influisce in parte su qualsiasi misurazione, ed è particolarmente rilevante in psicologia, dove la precisione degli strumenti di misurazione è generalmente inferiore rispetto ad altre discipline, come la fisica. Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere identici è che l’unità di misura della depressione è una questione arbitraria e non standardizzata. Tuttavia, nonostante le differenze dovute agli errori di misurazione e all’uso di unità di misura diverse, ci aspettiamo che, se le due scale misurano lo stesso costrutto (la depressione), i valori prodotti dalle due scale dovrebbero essere associati linearmente tra di loro. Per comprendere meglio il concetto di “associazione lineare”, è possibile esaminare i dati attraverso l’utilizzo di un diagramma a dispersione.\n\n\n\n\n\n\n\n\nOsservando il grafico a dispersione, è evidente che i dati mostrano una tendenza a distribuirsi in modo approssimativamente lineare. In termini statistici, ciò suggerisce una relazione di associazione lineare tra i punteggi CES-D e BDI-II.\nTuttavia, è importante notare che la relazione lineare tra le due variabili è lontana dall’essere perfetta. In una relazione lineare perfetta, tutti i punti nel grafico sarebbero allineati in modo preciso lungo una retta. Nella realtà, la dispersione dei punti dal comportamento lineare ideale è evidente.\nDi conseguenza, sorge la necessità di quantificare numericamente la forza e la direzione della relazione lineare tra le due variabili e di misurare quanto i punti si discostino da una relazione lineare ideale. Esistono vari indici statistici a disposizione per raggiungere questo obiettivo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#covarianza",
    "href": "chapters/eda/08_correlation.html#covarianza",
    "title": "20  Relazioni tra variabili",
    "section": "\n20.5 Covarianza",
    "text": "20.5 Covarianza\nIniziamo a considerare il più importante di tali indici, chiamato covarianza. In realtà la definizione di questo indice non ci sorprenderà più di tanto in quanto, in una forma solo apparentemente diversa, l’abbiamo già incontrata in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) è definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\]\nLa varianza viene talvolta descritta come la “covarianza di una variabile con sé stessa”. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, ci chiediamo come due variabili \\(X\\) e \\(Y\\) “variano insieme” (co-variano). È facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{20.1}\\]\nL’Equazione 20.1 ci fornisce la definizione della covarianza.\n\n20.5.1 Interpretazione\nPer capire il significato dell’Equazione 20.1, supponiamo di dividere il grafico riportato nella Sezione 20.4 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avrà un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza avrà segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avrà un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza avrà segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l’associazione lineare si dice positiva se la covarianza è positiva, negativa se la covarianza è negativa.\n\nEsempio 20.1 Implementiamo l’Equazione 20.1 in R.\n\ncov_value &lt;- function(x, y) {\n  mean_x &lt;- sum(x) / length(x)\n  mean_y &lt;- sum(y) / length(y)\n\n  sub_x &lt;- x - mean_x\n  sub_y &lt;- y - mean_y\n\n  sum_value &lt;- sum(sub_y * sub_x)\n  denom &lt;- length(x)\n\n  cov &lt;- sum_value / denom\n  return(cov)\n}\n\nPer i dati mostrati nel diagramma, la covarianza tra BDI-II e CESD è 207.4\n\nx &lt;- df$bdi\ny &lt;- df$cesd_sum\n\ncov_value(x, y)\n#&gt; [1] 207.4\n\nOppure, in maniera più semplice:\n\nmean((x - mean(x)) * (y - mean(y)))\n#&gt; [1] 207.4\n\nLo stesso risultato si ottiene con la funzione cov:\n\ncov(x, y) * (length(x) - 1) / length(x)\n#&gt; [1] 207.4\n\nLa funzione cov(x, y) calcola la covarianza tra due array, x e y utilizzando \\(n-1\\) al denominatore.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione",
    "href": "chapters/eda/08_correlation.html#correlazione",
    "title": "20  Relazioni tra variabili",
    "section": "\n20.6 Correlazione",
    "text": "20.6 Correlazione\nLa direzione della relazione tra le variabili è indicata dal segno della covarianza, ma il valore assoluto di questo indice non fornisce informazioni utili poiché dipende dall’unità di misura delle variabili. Ad esempio, considerando l’altezza e il peso delle persone, la covarianza sarà più grande se l’altezza è misurata in millimetri e il peso in grammi, rispetto al caso in cui l’altezza è in metri e il peso in chilogrammi. Pertanto, per descrivere la forza e la direzione della relazione lineare tra due variabili in modo adimensionale, si utilizza l’indice di correlazione.\nLa correlazione è ottenuta standardizzando la covarianza tramite la divisione delle deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr = \\frac{S_{XY}}{S_X S_Y}.\n\\tag{20.2}\\]\nLa quantità che si ottiene dall’Equazione 20.2 viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l’uno dall’altro, l’hanno introdotta).\nIn maniera equivalente, per una lista di coppie di valori \\((x_1, y_1), \\dots, (x_n, y_n)\\), il coefficiente di correlazione è definito come la media del prodotto dei valori standardizzati:\n\\[\nr = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{\\sigma_x} \\right) \\left( \\frac{y_i - \\bar{y}}{\\sigma_y} \\right),\n\\tag{20.3}\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) rappresentano, rispettivamente, le medie dei valori \\(x\\) e \\(y\\), e \\(\\sigma_x\\) e \\(\\sigma_y\\) sono le rispettive deviazioni standard.\nNell’Equazione 20.3, i valori \\(x_i\\) e \\(y_i\\) vengono prima standardizzati sottraendo la media e dividendo per la deviazione standard, e poi si calcola la media del prodotto di questi valori standardizzati.\n\n20.6.1 Proprietà\nIl coefficiente di correlazione ha le seguenti proprietà:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\nè un numero puro, cioè non dipende dall’unità di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\n20.6.2 Interpretazione\nAll’indice di correlazione possiamo assegnare la seguente interpretazione:\n\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\n\\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensità diversa;\n\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\n\nEsempio 20.2 Per i dati riportati nel diagramma della sezione {ref}sec-zetsche-scatter, la covarianza è 207.4. Il segno positivo della covarianza ci dice che tra le due variabili c’è un’associazione lineare positiva. Per capire quale sia l’intensità della relazione lineare calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore è prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva.\nTroviamo la correlazione con la funzione corrcoef():\n\ncor(x, y)\n#&gt; [1] 0.9041\n\nReplichiamo il risultato implementando l’Equazione 20.2:\n\ns_xy &lt;- mean((x - mean(x)) * (y - mean(y)))\ns_x &lt;- sqrt(mean((x - mean(x))^2)) # Deviazione standard popolazione\ns_y &lt;- sqrt(mean((y - mean(y))^2)) # Deviazione standard popolazione\nr_xy &lt;- s_xy / (s_x * s_y)\nprint(r_xy)\n#&gt; [1] 0.9041\n\nUn altro modo ancora per trovare la correlazione tra i punteggi BDI-II e CESD è quello di applicare l’Equazione 20.3:\n\nz_x &lt;- (x - mean(x)) / sqrt(mean((x - mean(x))^2)) \n# Standardizzazione con deviazione standard popolazione\nz_y &lt;- (y - mean(y)) / sqrt(mean((y - mean(y))^2)) \n# Standardizzazione con deviazione standard popolazione\nmean(z_x * z_y)\n#&gt; [1] 0.9041\n\n\n\nEsempio 20.3 Un uso interessante delle correlazioni viene fatto in un recente articolo di Guilbeault et al. (2024). Il concetto di “gender bias” si riferisce alla tendenza sistematica di favorire un sesso rispetto all’altro, spesso a scapito delle donne. Lo studio di Guilbeault et al. (2024) analizza come le immagini online influenzino la diffusione su vasta scala di questo preconcetto di genere.\nAttraverso un vasto insieme di immagini e testi raccolti online, gli autori dimostrano che sia le misurazioni basate sulle immagini che quelle basate sui testi catturano la frequenza con cui varie categorie sociali sono associate a rappresentazioni di genere, valutate su una scala da -1 (femminile) a 1 (maschile), con 0 che indica una neutralità di genere. Questo consente di quantificare il preconcetto di genere come una forma di bias statistico lungo tre dimensioni: la tendenza delle categorie sociali ad associarsi a un genere specifico nelle immagini e nei testi, la rappresentazione relativa delle donne rispetto agli uomini in tutte le categorie sociali nelle immagini e nei testi, e il confronto tra le associazioni di genere nei dati delle immagini e dei testi con la distribuzione empirica delle donne e degli uomini nella società. Il lavoro di Guilbeault et al. (2024) evidenzia che il preconcetto di genere è molto più evidente nelle immagini rispetto ai testi, come mostrato nella {numref}gender-bias-1-fig C.\nSi noti che, nel grafico della {numref}gender-bias-1-fig C, ogni punto può essere interpretato come una misura di correlazione. La misura utilizzata da Guilbeault et al. (2024) riflette il grado di associazione tra le categorie sociali e le rappresentazioni di genere presenti nelle immagini e nei testi analizzati. Quando la misura è vicina a +1, indica una forte associazione positiva tra una categoria sociale specifica e una rappresentazione di genere maschile, mentre un valore vicino a -1 indica una forte associazione negativa con una rappresentazione di genere femminile. Un valore di 0, invece, suggerisce che non vi è alcuna associazione tra la categoria sociale considerata e un genere specifico, indicando una sorta di neutralità di genere. In sostanza, questa misura di frequenza può essere interpretata come una correlazione che riflette la tendenza delle categorie sociali a essere rappresentate in un modo o nell’altro nelle immagini e nei testi analizzati, rispetto ai concetti di genere femminile e maschile.\n\n\nIl preconcetto di genere è più prevalente nelle immagini online (da Google Immagini) e nei testi online (da Google News). A. La correlazione tra le associazioni di genere nelle immagini da Google Immagini e nei testi da Google News per tutte le categorie sociali (n = 2.986), organizzate per decili. B. La forza dell’associazione di genere in queste immagini e testi online per tutte le categorie (n = 2.986), suddivisa in base al fatto che queste categorie siano inclinate verso il femminile o il maschile. C. Le associazioni di genere per un campione di occupazioni secondo queste immagini e testi online; questo campione è stato selezionato manualmente per evidenziare i tipi di categorie sociali e preconcetti di genere esaminati. (Figura tratta da Guilbeault et al. (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "href": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "title": "20  Relazioni tra variabili",
    "section": "\n20.7 Correlazione di Spearman",
    "text": "20.7 Correlazione di Spearman\nUn’alternativa per valutare la relazione lineare tra due variabili è il coefficiente di correlazione di Spearman, che si basa esclusivamente sull’ordine dei dati e non sugli specifici valori. Questo indice di associazione è particolarmente adatto quando gli psicologi sono in grado di misurare solo le relazioni di ordine tra diverse modalità di risposta dei soggetti, ma non l’intensità della risposta stessa. Tali variabili psicologiche che presentano questa caratteristica sono definite come “ordinali”.\n\n\n\n\n\n\nÈ importante ricordare che, nel caso di una variabile ordinale, non è possibile utilizzare le statistiche descrittive convenzionali come la media e la varianza per sintetizzare le osservazioni. Tuttavia, è possibile riassumere le osservazioni attraverso una distribuzione di frequenze delle diverse modalità di risposta. Come abbiamo appena visto, la direzione e l’intensità dell’associazione tra due variabili ordinali possono essere descritte utilizzando il coefficiente di correlazione di Spearman.\n\n\n\nPer fornire un esempio, consideriamo due variabili di scala ordinale e calcoliamo la correlazione di Spearman tra di esse.\n\ncor.test(c(1, 2, 3, 4, 5), c(5, 6, 7, 8, 7), method = \"spearman\")\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  c(1, 2, 3, 4, 5) and c(5, 6, 7, 8, 7)\n#&gt; S = 3.6, p-value = 0.09\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt;    rho \n#&gt; 0.8208",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#oltre-la-correlazione-e-la-covarianza-quando-lassociazione-tra-variabili-è-più-complessa",
    "href": "chapters/eda/08_correlation.html#oltre-la-correlazione-e-la-covarianza-quando-lassociazione-tra-variabili-è-più-complessa",
    "title": "20  Relazioni tra variabili",
    "section": "\n20.8 Oltre la correlazione e la covarianza: quando l’associazione tra variabili è più complessa",
    "text": "20.8 Oltre la correlazione e la covarianza: quando l’associazione tra variabili è più complessa\nIn questo capitolo abbiamo introdotto due misure fondamentali per descrivere la relazione tra due variabili: covarianza e correlazione. La covarianza fornisce un’indicazione del modo in cui due variabili si discostano congiuntamente dalle proprie medie, mentre la correlazione ne standardizza i valori, permettendo un confronto più immediato tra diverse coppie di variabili e garantendo un indice compreso tra -1 e +1. Una correlazione vicina a +1 indica una forte relazione lineare positiva, vicina a -1 una forte relazione lineare negativa, mentre un valore vicino a 0 segnala l’assenza di una chiara relazione lineare.\nTuttavia, è cruciale comprendere che la correlazione descrive esclusivamente la dimensione lineare della relazione tra due variabili. Questo significa che una correlazione nulla (pari a zero) non implica affatto che non vi sia alcuna relazione tra le variabili, ma semplicemente che non esiste una relazione lineare. Possono esistere relazioni non lineari anche molto forti, non catturate da questo indice. Inoltre, altre situazioni possono trarre in inganno, come nei casi in cui i dati siano raggruppati in sottogruppi con proprietà differenti o siano frutto di particolari processi di selezione.\n\n20.8.1 Correlazione nulla e relazioni non lineari\nUna correlazione pari a zero può nascondere relazioni non lineari anche molto marcate. Per esempio, se una variabile Y aumenta solo quando X è molto alta o molto bassa, ma rimane costante per valori intermedi di X, questa curva a “U” può generare una correlazione vicina allo zero, pur esistendo un forte legame non lineare.\nUn esempio illustrativo è fornito dal cosiddetto Datasaurus Dozen, un insieme di tredici dataset con la stessa media, deviazione standard e correlazione tra le variabili, ma con distribuzioni visivamente e strutturalmente molto diverse. In ognuno di questi dataset la correlazione di Pearson è pari a zero, ma l’ispezione grafica rivela pattern e forme ben definite. Questo ci ricorda che è sempre bene accompagnare le misure numeriche con una visualizzazione grafica dei dati.\n\ndatasaurus_data &lt;- read.csv(\"../../data/datasaurus.csv\")\n\ndatasaurus_summary &lt;- datasaurus_data %&gt;%\n  group_by(dataset) %&gt;%\n  summarise(\n    x_count = n(),\n    x_mean = mean(x, na.rm = TRUE),\n    x_std = sd(x, na.rm = TRUE),\n    y_count = n(),\n    y_mean = mean(y, na.rm = TRUE),\n    y_std = sd(y, na.rm = TRUE)\n  )\n\ndatasaurus_summary\n#&gt; # A tibble: 13 × 7\n#&gt;    dataset    x_count x_mean x_std y_count y_mean y_std\n#&gt;    &lt;chr&gt;        &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt;  1 away           142   54.3  16.8     142   47.8  26.9\n#&gt;  2 bullseye       142   54.3  16.8     142   47.8  26.9\n#&gt;  3 circle         142   54.3  16.8     142   47.8  26.9\n#&gt;  4 dino           142   54.3  16.8     142   47.8  26.9\n#&gt;  5 dots           142   54.3  16.8     142   47.8  26.9\n#&gt;  6 h_lines        142   54.3  16.8     142   47.8  26.9\n#&gt;  7 high_lines     142   54.3  16.8     142   47.8  26.9\n#&gt;  8 slant_down     142   54.3  16.8     142   47.8  26.9\n#&gt;  9 slant_up       142   54.3  16.8     142   47.8  26.9\n#&gt; 10 star           142   54.3  16.8     142   47.8  26.9\n#&gt; 11 v_lines        142   54.3  16.8     142   47.8  26.9\n#&gt; 12 wide_lines     142   54.3  16.8     142   47.8  26.9\n#&gt; 13 x_shape        142   54.3  16.8     142   47.8  26.9\n\n\ndatasaurus_data |&gt;\n  ggplot(aes(x = x, y = y)) +\n  geom_point(alpha = 0.7) +\n  facet_wrap(~dataset, nrow = 4, ncol = 4) +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n\nTutti questi esempi rafforzano l’idea che l’assenza di correlazione lineare non significa assenza di relazione: potremmo avere strutture curve, pattern complessi o punti anomali (outlier) capaci di modificare radicalmente la forma della relazione tra le variabili.\nOltre alle relazioni non lineari, esistono situazioni in cui la correlazione, da sola, può fornire un’immagine distorta dei dati. Tra queste ricordiamo due fenomeni noti come il paradosso di Simpson e il paradosso di Berkson.\n\n20.8.2 Paradosso di Simpson\nIl paradosso di Simpson si verifica quando, guardando i dati raggruppati per sottogruppi, si osserva una certa relazione tra due variabili, ma aggregando i dati di tutti i sottogruppi insieme emerge una relazione opposta. In altre parole, la tendenza che appare quando si considerano i dati divisi per gruppi scompare o si inverte quando si esamina l’intero campione senza tenere conto della suddivisione in sottogruppi.\nImmaginiamo di avere due dipartimenti universitari, A e B. All’interno di ciascun dipartimento, la relazione tra il voto di laurea (X) e la performance in un successivo programma di specializzazione (Y) è positiva: all’aumentare del voto di laurea aumenta, in media, la performance nella scuola di specializzazione.\nTuttavia, supponiamo che il Dipartimento A abbia in generale voti di laurea mediamente più bassi, ma ottime performance nella specializzazione; mentre il Dipartimento B abbia voti di laurea mediamente più alti, ma performance alla specializzazione un po’ più basse. Se uniamo tutti gli studenti dei due dipartimenti senza considerarne l’appartenenza, potremmo osservare una relazione negativa tra voto di laurea e performance, sovvertendo le conclusioni tratte guardando ai singoli sottogruppi.\nEcco come possiamo simulare questi dati in R:\n\nset.seed(123)\n\n# Numero di osservazioni per dipartimento\nn &lt;- 100\n\n# Dipartimento A:\n# Voti di laurea (X) più bassi, ma performance (Y) più alta.\n# Creiamo un legame positivo tra X e Y all'interno di A.\nX_A &lt;- rnorm(n, mean = 50, sd = 5)    # Voti laurea mediamente più bassi\nY_A &lt;- X_A + rnorm(n, mean = 20, sd = 5) # Performance alta e correlata positivamente con X\n\n# Dipartimento B:\n# Voti di laurea (X) più alti, ma performance (Y) più bassa.\n# Anche qui creiamo un legame positivo tra X e Y all'interno di B, \n# ma con un offset tale che globalmente i voti alti coincidano con performance minori.\nX_B &lt;- rnorm(n, mean = 60, sd = 5)    # Voti laurea mediamente più alti\nY_B &lt;- X_B - rnorm(n, mean = 10, sd = 5) # Performance più bassa ma comunque correlata positivamente con X all’interno di B\n\n# Creiamo un dataframe con tutti i dati\ndipartimento &lt;- c(rep(\"A\", n), rep(\"B\", n))\nX &lt;- c(X_A, X_B)\nY &lt;- c(Y_A, Y_B)\ndati &lt;- data.frame(dipartimento, X, Y)\n\n# Correlazioni all'interno dei dipartimenti\ncat(\"Correlazione nel Dipartimento A:\", cor(X_A, Y_A), \"\\n\")\n#&gt; Correlazione nel Dipartimento A: 0.6671\ncat(\"Correlazione nel Dipartimento B:\", cor(X_B, Y_B), \"\\n\")\n#&gt; Correlazione nel Dipartimento B: 0.6926\n\n# Correlazione sull'intero dataset (senza distinguere i dipartimenti)\ncat(\"Correlazione globale:\", cor(X, Y), \"\\n\")\n#&gt; Correlazione globale: -0.3353\n\n\n# Visualizziamo i dati\nggplot(dati, aes(x = X, y = Y, color = dipartimento)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  scale_fill_okabeito() + \n  labs(\n    title = \"Paradosso di Simpson\",\n    x = \"Voto di laurea\", \n    y = \"Performance nella specializzazione\",\n    color = \"Dipartimento\"\n  )\n\n\n\n\n\n\n\n\nAll’interno del Dipartimento A: la correlazione tra voto di laurea (X) e performance (Y) è positiva. Ciò significa che, per gli studenti di A, avere un voto di laurea più alto è associato a una performance maggiore nella specializzazione.\nAll’interno del Dipartimento B: la correlazione tra X e Y è anch’essa positiva, indicando che anche nel secondo dipartimento voti più alti tendono ad accompagnarsi a performance più alte.\nConsiderando entrambi i dipartimenti insieme: a causa delle differenze nei livelli medi di X e Y tra i dipartimenti, unendo i dati senza distinguere il gruppo di appartenenza otteniamo una correlazione globale negativa. Questo significa che, ignorando la suddivisione in dipartimenti, sembra che aumentare il voto di laurea sia associato a una diminuzione della performance nella specializzazione — una conclusione opposta a quella tratta dall’analisi separata dei due sottogruppi.\n\nQuesto è un esempio concreto del paradosso di Simpson: la relazione osservata in sottogruppi omogenei si inverte quando si aggregano i dati, mettendo in guardia sulla necessità di considerare con attenzione la struttura dei dati e i fattori confondenti prima di trarre conclusioni.\n\n20.8.3 Paradosso di Berkson\nIl paradosso di Berkson è un fenomeno legato alla selezione del campione. Se il dataset non è rappresentativo della popolazione generale, la relazione osservata può risultare artificiale o opposta a quella esistente su un campione più ampio. Per esempio, analizzando solo ciclisti professionisti, potremmo non vedere alcuna relazione tra VO2 max e probabilità di vincere una gara, poiché tutti hanno già superato una certa soglia di VO2 max. Considerando la popolazione generale, invece, potrebbe emergere chiaramente una relazione positiva tra questi due fattori. Questo paradosso evidenzia l’importanza di considerare il processo di selezione dei dati e di chiedersi se il campione analizzato sia adeguato a rispondere alla domanda di ricerca.\n\n20.8.4 Limiti delle statistiche riassuntive semplici\nUn esempio particolarmente famoso che dimostra i limiti delle semplici statistiche descrittive — come media, deviazione standard e correlazione — è il quartetto di Anscombe. Questo insieme di quattro piccoli dataset possiede identiche medie, varianze e correlazioni tra variabili, ma rappresenta relazioni estremamente differenti tra X e Y (Anscombe, 1973).\nImportiamo il dataset anscombe già disponibile nel pacchetto datasets di R:\n\ndata(\"anscombe\")\n\nanscombe |&gt; \n  head()\n#&gt;   x1 x2 x3 x4   y1   y2    y3   y4\n#&gt; 1 10 10 10  8 8.04 9.14  7.46 6.58\n#&gt; 2  8  8  8  8 6.95 8.14  6.77 5.76\n#&gt; 3 13 13 13  8 7.58 8.74 12.74 7.71\n#&gt; 4  9  9  9  8 8.81 8.77  7.11 8.84\n#&gt; 5 11 11 11  8 8.33 9.26  7.81 8.47\n#&gt; 6 14 14 14  8 9.96 8.10  8.84 7.04\n\nIl dataset anscombe contiene quattro serie di dati (x1, y1), (x2, y2), (x3, y3) e (x4, y4), ognuna costituita da 11 coppie di valori (x, y). Per comprendere meglio le loro caratteristiche, iniziamo calcolando alcune statistiche descrittive. La funzione apply() consente di applicare una funzione (ad esempio, mean) a tutte le colonne di un data frame. Usandola sulle colonne di anscombe, otteniamo le medie di ciascuna delle otto variabili (le quattro x e le quattro y):\n\napply(anscombe, MARGIN = 2, mean)\n#&gt;    x1    x2    x3    x4    y1    y2    y3    y4 \n#&gt; 9.000 9.000 9.000 9.000 7.501 7.501 7.500 7.501\n\nOsserviamo che le medie delle quattro variabili x sono identiche fino a sei cifre decimali, e le medie delle quattro variabili y differiscono solo in modo trascurabile (circa lo 0.01%). Analogamente, se calcoliamo le deviazioni standard per ciascuna variabile, notiamo una notevole somiglianza:\n\napply(anscombe, MARGIN = 2, sd)\n#&gt;    x1    x2    x3    x4    y1    y2    y3    y4 \n#&gt; 3.317 3.317 3.317 3.317 2.032 2.032 2.030 2.031\n\nAnche in questo caso, le deviazioni standard per le x coincidono fino alla sesta cifra decimale, mentre quelle delle y differiscono di meno dello 0.06%. Inoltre, se calcoliamo i coefficienti di correlazione tra x e y in ognuno dei quattro dataset, scopriamo che sono quasi identici:\n\n# Calcoliamo la correlazione per ciascuna coppia (x1,y1), (x2,y2), (x3,y3), (x4,y4)\nfor (i in 1:4) {\n  x_var &lt;- anscombe[[paste0(\"x\", i)]]\n  y_var &lt;- anscombe[[paste0(\"y\", i)]]\n  \n  corr_value &lt;- cor(x_var, y_var)\n  cat(\"Correlazione tra x\", i, \"e y\", i, \":\", corr_value, \"\\n\")\n}\n#&gt; Correlazione tra x 1 e y 1 : 0.8164 \n#&gt; Correlazione tra x 2 e y 2 : 0.8162 \n#&gt; Correlazione tra x 3 e y 3 : 0.8163 \n#&gt; Correlazione tra x 4 e y 4 : 0.8165\n\nSe ci limitassimo a guardare queste statistiche (media, deviazione standard, correlazione), potremmo facilmente essere indotti a concludere che i quattro dataset sono tra loro sostanzialmente indistinguibili. Tuttavia, la realtà è molto diversa. Le statistiche descrittive, prese da sole, non offrono una visione completa e possono nascondere importanti differenze nella struttura dei dati.\nQuesta differenza diventa evidente non appena decidiamo di visualizzare i dati. La rappresentazione grafica fornisce informazioni che non emergono dalle sole statistiche riassuntive:\n\nanscombe_m &lt;- tibble()\n\nfor (i in 1:4) {\n  anscombe_m &lt;- rbind(\n    anscombe_m, tibble(set = i, x = anscombe[, i], y = anscombe[, i + 4])\n  )\n}\n\nggplot(anscombe_m, aes(x, y)) +\n  geom_point(size = 3, color = \"red\", fill = \"orange\", shape = 21) +\n  geom_smooth(method = \"lm\", fill = NA, fullrange = TRUE) +\n  facet_wrap(~set, ncol = 2)\n\n\n\n\n\n\n\nOsservando i grafici, notiamo subito che i quattro dataset sono profondamente diversi:\n\n\nDataset 1: Qui la relazione tra x e y è approssimativamente lineare, e la correlazione riflette in modo appropriato il legame tra le due variabili.\n\nDataset 2: Sebbene la correlazione sia simile a quella del Dataset 1, i dati mostrano una relazione curvilinea e non lineare. La semplice correlazione lineare non ne cattura la forma.\n\nDataset 3: La presenza di un singolo outlier distorce la percezione della relazione tra le variabili, altrimenti lineare. La correlazione alta è influenzata in modo sproporzionato da questo punto anomalo.\n\nDataset 4: Qui i dati non mostrano alcuna relazione lineare. La correlazione elevata è il frutto di un pattern fortemente atipico (ad esempio, una sola coppia di punti allineata).\n\nIl quartetto di Anscombe mette in luce un principio fondamentale: statistiche descrittive come media, deviazione standard e correlazione non sono sempre sufficienti per comprendere la natura dei dati. La visualizzazione grafica è essenziale per cogliere relazioni, pattern non lineari, outlier e altre caratteristiche che le semplici statistiche non riescono a rivelare. In definitiva, questo esempio dimostra che analizzare i dati soltanto attraverso poche statistiche di sintesi può portare a conclusioni fuorvianti, mentre l’integrazione con la rappresentazione grafica fornisce una visione più completa e accurata.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#riflessioni-conclusive",
    "href": "chapters/eda/08_correlation.html#riflessioni-conclusive",
    "title": "20  Relazioni tra variabili",
    "section": "\n20.9 Riflessioni Conclusive",
    "text": "20.9 Riflessioni Conclusive\nLa covarianza e la correlazione sono strumenti preziosi per capire l’intensità e la direzione lineare di una relazione tra due variabili. Tuttavia, non dobbiamo confondere la loro semplicità con completezza d’informazione. Una correlazione nulla non implica assenza di relazione, ma solo assenza di una relazione lineare. Inoltre, il paradosso di Simpson e il paradosso di Berkson dimostrano che la semplice osservazione di correlazioni può essere fuorviante se non si tiene conto della struttura dei dati o del processo di selezione del campione.\nInfine, esempi come il quartetto di Anscombe sottolineano quanto sia fondamentale accompagnare le statistiche riassuntive con analisi grafiche e un’attenzione costante ai possibili pattern non lineari, agli outlier e alle caratteristiche peculiari del dataset. Nel prossimo capitolo esamineremo approcci che consentono di avvicinarsi alla comprensione causale dei fenomeni, andando oltre la semplice osservazione dell’associazione tra variabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#esercizi",
    "href": "chapters/eda/08_correlation.html#esercizi",
    "title": "20  Relazioni tra variabili",
    "section": "\n20.10 Esercizi",
    "text": "20.10 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizi Teorici\n\n\nDefinizioni fondamentali\n\nQual è la differenza tra associazione, correlazione e dipendenza?\n\nPerché la correlazione non implica causalità? Fai un esempio.\n\nIn quali situazioni la correlazione di Spearman è preferibile rispetto alla correlazione di Pearson?\n\n\n\nInterpretazione della correlazione\n\nQual è il range dei valori che può assumere la correlazione di Pearson?\n\nSe il coefficiente di correlazione tra due variabili è 0.85, come interpreteresti la loro relazione?\n\nSe il coefficiente di correlazione è -0.60, che tipo di relazione esiste tra le due variabili?\n\nQuali fattori potrebbero influenzare il valore della correlazione?\n\n\n\nCovarianza vs Correlazione\n\nQual è la differenza tra covarianza e correlazione?\n\nPerché la covarianza non è sempre interpretabile come misura della forza della relazione tra due variabili?\n\nQuali sono i vantaggi di usare la correlazione al posto della covarianza?\n\n\n\nGrafico a dispersione e correlazione\n\nOsservando un grafico a dispersione, quali caratteristiche ti permettono di identificare una relazione lineare positiva o negativa?\n\nDisegna (o descrivi verbalmente) un esempio di un dataset con una correlazione di circa 0, ma con una chiara relazione non lineare tra le variabili.\n\n\n\nEsercizi Pratici in R\n📌 Obiettivo: Analizzare le relazioni tra Satisfaction With Life Scale (SWLS) e Scala della Rete Sociale di Lubben (LSNS-6), calcolare covarianza e correlazione, e visualizzare i dati per individuare pattern.\nDati disponibili:\nUsa i dati raccolti per le variabili SWLS e LSNS, oltre al genere dei partecipanti.\n1. Esplorazione e Visualizzazione della Relazione tra SWLS e LSNS\n\n\nCarica i dati raccolti dagli studenti e verifica la struttura del dataset.\n\n\nCalcola le statistiche descrittive: media, deviazione standard, minimo, massimo e quartili delle variabili SWLS e LSNS.\n\n\nCrea un grafico a dispersione tra SWLS e LSNS:\n\nColora i punti in base al genere del partecipante.\n\nAggiungi una linea di regressione per evidenziare il trend della relazione.\n\n\n\n2. Calcolo della Covarianza e della Correlazione tra SWLS e LSNS\n\n\nCalcola la covarianza tra SWLS e LSNS usando la formula matematica della covarianza e confrontala con il valore ottenuto con cov().\n\n\nCalcola la correlazione di Pearson e commenta il risultato:\n\nLa relazione è forte o debole?\n\nHa segno positivo o negativo?\n\nÈ coerente con quanto osservato nel grafico a dispersione?\n\n\n\n\nCalcola la correlazione di Spearman e confrontala con quella di Pearson. Quale delle due è più appropriata per questi dati?\n\n3. Analisi delle Associazioni per Gruppi\n\n\nCalcola la correlazione separatamente per i partecipanti di genere maschile e femminile.\n\n\nConfronta i risultati: la relazione tra SWLS e LSNS è simile nei due gruppi o ci sono differenze?\n\n\nVisualizza i dati con due grafici a dispersione distinti per maschi e femmine.\n\n4. Correlazione Nulla e Pattern Non Lineari\n\n\nSimula un dataset in cui la correlazione di Pearson è vicina a 0, ma esiste una chiara relazione non lineare tra le variabili.\n\n\nCostruisci un grafico a dispersione per osservare il pattern nei dati.\n\n\nCalcola la correlazione di Spearman e confrontala con quella di Pearson. Quale delle due cattura meglio la relazione nei dati?\n\nConsegna il file .qmd compilato in PDF contenente il codice, le visualizzazioni e le interpretazioni.\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Definizioni fondamentali\n1.1 Differenza tra associazione, correlazione e dipendenza:\n\n\nAssociazione: Indica una relazione generica tra due variabili, senza specificare la natura o la direzione della relazione.\n\nCorrelazione: Misura la forza e la direzione di una relazione lineare tra due variabili. Può essere positiva (variabili aumentano insieme) o negativa (una variabile aumenta mentre l’altra diminuisce).\n\nDipendenza: Indica che una variabile è influenzata da un’altra, ma non implica necessariamente una relazione lineare. La dipendenza può essere causale o statistica.\n\n1.2 Perché la correlazione non implica causalità:\nLa correlazione misura solo la relazione lineare tra due variabili, ma non indica se una variabile causa l’altra. Un esempio classico è la correlazione tra il consumo di gelati e il numero di annegamenti: entrambi aumentano in estate, ma non c’è un nesso causale diretto. Un terzo fattore (il caldo) influenza entrambe le variabili.\n1.3 Quando preferire la correlazione di Spearman rispetto a quella di Pearson:\n\nQuando i dati non sono distribuiti normalmente.\nQuando ci sono outlier che potrebbero distorcere la correlazione di Pearson.\nQuando la relazione tra le variabili è monotona (sempre crescente o decrescente) ma non lineare.\n\n2. Interpretazione della correlazione\n2.1 Range dei valori della correlazione di Pearson:\nLa correlazione di Pearson assume valori compresi tra -1 e 1: - 1: Correlazione lineare positiva perfetta. - -1: Correlazione lineare negativa perfetta. - 0: Nessuna correlazione lineare.\n2.2 Interpretazione di un coefficiente di 0.85:\nUn coefficiente di 0.85 indica una forte relazione lineare positiva tra le due variabili. All’aumentare di una variabile, l’altra tende ad aumentare in modo consistente.\n2.3 Interpretazione di un coefficiente di -0.60:\nUn coefficiente di -0.60 indica una relazione lineare negativa moderata. All’aumentare di una variabile, l’altra tende a diminuire.\n2.4 Fattori che influenzano la correlazione:\n\n\nOutlier: Possono distorcere il valore della correlazione.\n\nDistribuzione non lineare: La correlazione di Pearson non cattura relazioni non lineari.\n\nRange ristretto delle variabili: Se i dati coprono solo una piccola parte del range possibile, la correlazione potrebbe essere sottostimata.\n\n3. Covarianza vs Correlazione\n3.1 Differenza tra covarianza e correlazione:\n\n\nCovarianza: Misura la direzione della relazione tra due variabili, ma il suo valore dipende dalle unità di misura delle variabili.\n\nCorrelazione: Standardizza la covarianza, rendendola adimensionale e consentendo confronti tra diverse coppie di variabili.\n\n3.2 Perché la covarianza non è sempre interpretabile:\nLa covarianza non è standardizzata, quindi il suo valore non fornisce informazioni sulla forza della relazione. Ad esempio, una covarianza di 1000 potrebbe indicare una relazione forte o debole, a seconda delle unità di misura.\n3.3 Vantaggi della correlazione rispetto alla covarianza:\n\nÈ adimensionale, quindi può essere confrontata tra diverse coppie di variabili.\nAssume valori compresi tra -1 e 1, facilitando l’interpretazione della forza e della direzione della relazione.\n\n4. Grafico a dispersione e correlazione\n4.1 Caratteristiche di un grafico a dispersione per identificare relazioni lineari:\n\n\nRelazione lineare positiva: I punti si dispongono lungo una linea retta con pendenza positiva.\n\nRelazione lineare negativa: I punti si dispongono lungo una linea retta con pendenza negativa.\n\nNessuna relazione lineare: I punti sono sparsi senza un pattern evidente.\n\n4.2 Esempio di dataset con correlazione circa 0 ma relazione non lineare:\nImmagina un dataset in cui una variabile \\(x\\) assume valori simmetrici intorno a 0 (ad esempio, da -5 a 5), e la variabile \\(y\\) è uguale a \\(x^2\\). In questo caso:\n\nLa correlazione di Pearson sarà circa 0, perché non c’è una relazione lineare.\nTuttavia, esiste una chiara relazione non lineare (quadratica) tra \\(x\\) e \\(y\\).\n\nDescrizione verbale:\nI punti formano una parabola, con \\(y\\) che aumenta sia quando \\(x\\) è positivo che negativo. La correlazione di Pearson non cattura questa relazione, mentre la correlazione di Spearman potrebbe farlo.\n1. Esplorazione e Visualizzazione della Relazione tra SWLS e LSNS\n1.1 Carica i dati raccolti dagli studenti e verifica la struttura del dataset Simuliamo un dataset con 100 partecipanti, includendo le variabili SWLS (Soddisfazione di Vita), LSNS (Rete Sociale), e Genere.\n# Simulazione dei dati\nset.seed(123)\nn &lt;- 100\ngenere &lt;- sample(c(\"Maschio\", \"Femmina\"), n, replace = TRUE)\nswls &lt;- round(rnorm(n, mean = 20, sd = 5), 1)  # SWLS: Scala 5-35\nlsns &lt;- round(rnorm(n, mean = 12, sd = 4), 1)   # LSNS: Scala 0-30\n\n# Creazione del dataset\ndati &lt;- data.frame(Genere = genere, SWLS = swls, LSNS = lsns)\n\n# Verifica della struttura\nstr(dati)\nhead(dati)\n1.2 Calcola le statistiche descrittive\n# Statistiche descrittive per SWLS e LSNS\nsummary(dati$SWLS)\nsummary(dati$LSNS)\n\n# Media e deviazione standard\nmean(dati$SWLS)\nsd(dati$SWLS)\nmean(dati$LSNS)\nsd(dati$LSNS)\n1.3 Crea un grafico a dispersione\nlibrary(ggplot2)\n\nggplot(dati, aes(x = SWLS, y = LSNS, color = Genere)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") +\n  labs(title = \"Relazione tra SWLS e LSNS\",\n       x = \"Soddisfazione di Vita (SWLS)\",\n       y = \"Rete Sociale (LSNS)\") +\n  theme_minimal()\n2. Calcolo della Covarianza e della Correlazione tra SWLS e LSNS\n2.1 Calcola la covarianza\n# Covarianza manuale\ncov_manual &lt;- sum((dati$SWLS - mean(dati$SWLS)) * (dati$LSNS - mean(dati$LSNS))) / (n - 1)\ncov_manual\n\n# Covarianza con funzione R\ncov(dati$SWLS, dati$LSNS)\n2.2 Calcola la correlazione di Pearson\ncor_pearson &lt;- cor(dati$SWLS, dati$LSNS, method = \"pearson\")\ncor_pearson\n\n\nCommento: La correlazione è [valore], indicando una relazione [forte/debole] e [positiva/negativa]. Questo è coerente con il grafico a dispersione.\n\n2.3 Calcola la correlazione di Spearman\ncor_spearman &lt;- cor(dati$SWLS, dati$LSNS, method = \"spearman\")\ncor_spearman\n\n\nConfronto: La correlazione di Spearman è più appropriata se i dati non sono distribuiti normalmente o presentano outlier.\n\n3. Analisi delle Associazioni per Gruppi\n3.1 Calcola la correlazione separatamente per genere\n# Maschi\ncor_maschi &lt;- cor(dati$SWLS[dati$Genere == \"Maschio\"], dati$LSNS[dati$Genere == \"Maschio\"], method = \"pearson\")\n\n# Femmine\ncor_femmine &lt;- cor(dati$SWLS[dati$Genere == \"Femmina\"], dati$LSNS[dati$Genere == \"Femmina\"], method = \"pearson\")\n\ncor_maschi\ncor_femmine\n3.2 Confronta i risultati\n\n\nCommento: La correlazione è [simile/diversa] tra maschi e femmine, suggerendo [presenza/assenza] di differenze di genere.\n\n3.3 Visualizza i dati con grafici distinti\nggplot(dati, aes(x = SWLS, y = LSNS, color = Genere)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~ Genere) +\n  labs(title = \"Relazione tra SWLS e LSNS per Genere\",\n       x = \"Soddisfazione di Vita (SWLS)\",\n       y = \"Rete Sociale (LSNS)\") +\n  theme_minimal()\n4. Correlazione Nulla e Pattern Non Lineari\n4.1 Simula un dataset con correlazione nulla ma relazione non lineare\nset.seed(123)\nx &lt;- rnorm(100, mean = 0, sd = 1)\ny &lt;- x^2 + rnorm(100, mean = 0, sd = 0.5)  # Relazione quadratica\ndati_non_lineari &lt;- data.frame(x = x, y = y)\n\n# Correlazione di Pearson\ncor_pearson_non_lineare &lt;- cor(dati_non_lineari$x, dati_non_lineari$y, method = \"pearson\")\ncor_pearson_non_lineare  # Dovrebbe essere vicina a 0\n4.2 Costruisci un grafico a dispersione\nggplot(dati_non_lineari, aes(x = x, y = y)) +\n  geom_point(size = 3) +\n  labs(title = \"Relazione Non Lineare con Correlazione Nulla\",\n       x = \"Variabile X\",\n       y = \"Variabile Y\") +\n  theme_minimal()\n4.3 Calcola la correlazione di Spearman\ncor_spearman_non_lineare &lt;- cor(dati_non_lineari$x, dati_non_lineari$y, method = \"spearman\")\ncor_spearman_non_lineare  # Dovrebbe catturare la relazione non lineare\n\n\nConfronto: La correlazione di Spearman è più adatta per catturare relazioni non lineari.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "title": "20  Relazioni tra variabili",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#&gt;  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3   \n#&gt;  [9] grid_4.4.2        timechange_0.3.0  fastmap_1.2.0     Matrix_1.7-2     \n#&gt; [13] R.oo_1.27.0       rprojroot_2.0.4   jsonlite_1.8.9    R.utils_2.12.3   \n#&gt; [17] mgcv_1.9-1        mnormt_2.1.1      cli_3.6.4         rlang_1.1.5      \n#&gt; [21] R.methodsS3_1.8.2 splines_4.4.2     munsell_0.5.1     withr_3.0.2      \n#&gt; [25] yaml_2.3.10       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [29] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [33] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [37] gtable_0.3.6      data.table_1.16.4 glue_1.8.0        xfun_0.50        \n#&gt; [41] tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [45] nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#bibliografia",
    "href": "chapters/eda/08_correlation.html#bibliografia",
    "title": "20  Relazioni tra variabili",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAnscombe, F. J. (1973). Graphs in statistical analysis. The American Statistician, 27(1), 17–21.\n\n\nHamaker, E. (2024). The curious case of the cross-sectional correlation. Multivariate Behavioral Research, 59(6), 1111–1122.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html",
    "href": "chapters/eda/09_causality.html",
    "title": "21  Causalità dai dati osservazionali",
    "section": "",
    "text": "21.1 Introduzione\nLa pura osservazione dei dati può rivelare correlazioni e pattern nei dati, ma senza un’indagine sulle cause che stanno alla base di tali correlazioni, le conclusioni tratte possono essere fuorvianti o incomplete.\nRichard McElreath, nel suo libro “Statistical Rethinking” (McElreath, 2020), utilizza l’analogia dei Golem - creature potenti ma prive di saggezza - per descrivere un approccio metodologico che è stato a lungo predominante in psicologia. Questo approccio si basa esclusivamente sull’analisi delle associazioni statistiche tra variabili, trascurando considerazioni più profonde sulla causalità.\nIl metodo in questione si concentra principalmente sul test delle ipotesi nulle, senza stabilire una chiara connessione tra le domande di ricerca riguardanti relazioni causali e i test statistici impiegati. Questa disconnessione è evidente nella figura successiva, tratta da un manuale di analisi dati di impostazione frequentista, che illustra la procedura raccomandata dai sostenitori di questo approccio per descrivere le associazioni tra variabili.\nÈ importante notare come tale procedura non fornisca strumenti utili per identificare le effettive cause sottostanti ai fenomeni osservati. Questa limitazione metodologica è stata identificata come uno dei fattori principali che hanno contribuito alla crisi di replicabilità nella ricerca psicologica, come approfondito nel ?sec-crisis. L’approccio descritto, pur essendo potente nell’individuare correlazioni, manca della “saggezza” necessaria per distinguere tra semplici associazioni e vere relazioni causali, analogamente ai Golem della metafora di McElreath.\nUn problema evidenziato da McElreath (2020) è che processi causali completamente distinti possono generare la stessa distribuzione di risultati osservati. Pertanto, un approccio focalizzato esclusivamente sull’analisi delle associazioni mediante il test dell’ipotesi nulla non è in grado di distinguere tra questi diversi scenari, come spiegato nel ?sec-causal-inference-regr.\nL’approccio frequentista, che si limita a descrivere le associazioni tra le variabili, ha una scarsa capacità di rilevare le caratteristiche cruciali dei fenomeni studiati e tende a produrre un alto tasso di falsi positivi (Zwet et al., 2023). È invece necessario utilizzare una metodologia che non si limiti a confutare ipotesi nulle, ma sia in grado di sviluppare modelli causali che rispondano direttamente alle domande di ricerca. In questo capitolo, ci concentreremo sull’introduzione dei concetti fondamentali dell’analisi causale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#introduzione",
    "href": "chapters/eda/09_causality.html#introduzione",
    "title": "21  Causalità dai dati osservazionali",
    "section": "",
    "text": "Esempio di albero decisionale per la selezione di una procedura statistica appropriata. Iniziando dall’alto, l’utente risponde a una serie di domande riguardanti la misurazione e l’intento, arrivando infine al nome di una procedura. Sono possibili molti alberi decisionali simili. (Figura tratta da McElreath (2020)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#cosè-la-causalità",
    "href": "chapters/eda/09_causality.html#cosè-la-causalità",
    "title": "21  Causalità dai dati osservazionali",
    "section": "21.2 Cos’è la causalità?",
    "text": "21.2 Cos’è la causalità?\nHardt & Recht (2022) introducono il concetto di causalità distinguendo tra osservazione e azione. Ciò che vediamo nell’osservazione passiva è il modo in cui le persone seguono i loro comportamenti abituali, le loro inclinazioni naturali, proiettando lo stato del mondo su un insieme di caratteristiche che abbiamo scelto di evidenziare. Tuttavia, le domande più importanti spesso non riguardano semplici osservazioni.\n\nNon ci basta sapere che le persone che praticano regolarmente attività fisica soffrono meno d’ansia; vogliamo capire se l’attività fisica riduce effettivamente i livelli d’ansia.\nNon ci accontentiamo di osservare che chi segue una terapia cognitivo-comportamentale (CBT) presenta meno sintomi depressivi; desideriamo verificare se la CBT riduce realmente questi sintomi.\nNon ci limitiamo a constatare che l’uso frequente dei social media è associato a un calo del benessere mentale; vogliamo determinare se l’uso intensivo dei social media causa effettivamente una diminuzione del benessere mentale.\n\nAlla base, il ragionamento causale è un quadro concettuale per affrontare domande sugli effetti di azioni o interventi ipotetici. Una volta compreso quale sia l’effetto di un’azione, possiamo invertire la domanda e chiederci quale azione plausibile abbia causato un determinato evento.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#effetto-causale",
    "href": "chapters/eda/09_causality.html#effetto-causale",
    "title": "21  Causalità dai dati osservazionali",
    "section": "21.3 Effetto Causale",
    "text": "21.3 Effetto Causale\nSebbene non esista una definizione univoca di causalità, possiamo concettualizzarla in modo pratico: diciamo che X causa Y se, intervenendo e modificando il valore di X (il trattamento), la distribuzione di Y cambia di conseguenza. Questa definizione sottolinea l’importanza cruciale dell’azione o dell’intervento nel determinare una relazione causale.\nQuando X è una variabile binaria, rappresentante la presenza o l’assenza del trattamento, la conseguenza dell’intervento su X è denominata effetto medio del trattamento. Questo ci indica quanto il trattamento (azione X = 1) aumenta l’aspettativa di Y rispetto all’assenza di trattamento (azione X = 0).\nÈ importante notare che gli effetti causali sono quantità relative alla popolazione. Si riferiscono a effetti mediati sull’intera popolazione in esame. Tuttavia, spesso l’effetto del trattamento può variare notevolmente da un individuo all’altro o tra gruppi di individui. In questi casi, parliamo di effetti di trattamento eterogenei.\nPer chiarire questo concetto, consideriamo un esempio concreto: supponiamo che la terapia cognitivo-comportamentale (CBT) riduca l’ansia. Se un gruppo di persone ansiose non riceve alcun trattamento, i loro livelli d’ansia rimarranno presumibilmente invariati. Se invece interveniamo introducendo la CBT (modificando così il valore di X), i livelli d’ansia nel gruppo tenderanno a diminuire (cambiando quindi il valore di Y). Questo esempio illustra la distinzione tra semplice correlazione, basata sull’osservazione passiva, e causalità, che implica un’azione o un intervento.\nLa definizione di causalità può essere applicata anche per collegare variabili apparentemente distanti. Ad esempio, l’autoefficacia potrebbe non avere un effetto causale diretto sulle prestazioni accademiche. Tuttavia, se aumentiamo l’autoefficacia attraverso interventi mirati, è probabile che osserviamo un miglioramento nell’impegno allo studio. Questo aumento dell’impegno, a sua volta, tende a migliorare le prestazioni accademiche. Di conseguenza, possiamo affermare che l’autoefficacia influisce indirettamente sulle prestazioni accademiche attraverso una catena causale.\nÈ importante precisare che esiste una relazione causale tra X e Y anche quando modificare X non porta necessariamente a un cambiamento immediato o deterministico in Y, ma altera la probabilità che Y si verifichi in un certo modo, modificando quindi la distribuzione di Y. Questa prospettiva probabilistica della causalità è particolarmente rilevante in campi come la psicologia, dove le relazioni tra variabili sono spesso complesse e influenzate da molteplici fattori.\n\n21.3.1 I Limiti dell’Osservazione\nPer comprendere i limiti dell’osservazione passiva, e quindi la necessità di comprendere le relazioni causali sottostanti, Hardt & Recht (2022) si riferiscono all’esempio storico delle ammissioni ai corsi di laurea dell’Università della California, Berkeley, nel 1973. In quell’anno, 12,763 candidati furono considerati per l’ammissione in uno dei 101 dipartimenti o major interdipartimentali. Di questi, 4,321 erano donne e 8,442 erano uomini. I dati mostrano che circa il 35% delle donne fu ammesso, rispetto al 44% degli uomini. Test di significatività statistica indicano che questa differenza non è attribuibile al caso, suggerendo una disparità nei tassi di ammissione tra i generi.\nUna tendenza simile si osserva quando si analizzano le decisioni aggregate di ammissione nei sei maggiori dipartimenti. Il tasso di ammissione complessivo per gli uomini era di circa il 44%, mentre per le donne era solo il 30%, un’altra differenza statisticamente significativa. Tuttavia, poiché i dipartimenti hanno autonomia nelle loro decisioni di ammissione, è utile esaminare il possibile bias di genere a livello di singolo dipartimento.\nUomini\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n825\n62\n\n\nB\n520\n60\n\n\nC\n325\n37\n\n\nD\n417\n33\n\n\nE\n191\n28\n\n\nF\n373\n6\n\n\n\nDonne\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n108\n82\n\n\nB\n25\n68\n\n\nC\n593\n34\n\n\nD\n375\n35\n\n\nE\n393\n24\n\n\nF\n341\n7\n\n\n\nDall’osservazione di questi dati, emerge che quattro dei sei maggiori dipartimenti mostrano un tasso di ammissione più elevato per le donne, mentre due mostrano un tasso più elevato per gli uomini. Tuttavia, questi due dipartimenti non possono giustificare la sostanziale differenza nei tassi di ammissione osservata nei dati aggregati. Questo suggerisce che la tendenza generale di un tasso di ammissione più alto per gli uomini sembra invertita quando i dati sono disaggregati per dipartimento.\nQuesto fenomeno è noto come paradosso di Simpson, un paradosso statistico in cui una tendenza che appare in sottopopolazioni si inverte o scompare quando i dati vengono aggregati. Nel contesto attuale, il paradosso di Simpson si manifesta nel fatto che, mentre i dati aggregati sembrano indicare una discriminazione di genere contro le donne, l’analisi dei dati disaggregati per dipartimento rivela che in alcuni casi le donne sono favorite in termini di ammissioni.\nLa domanda fondamentale è se questi dati indicano effettivamente un problema di discriminazione di genere o se, come suggerito dallo studio originale, il bias di genere nelle ammissioni fosse principalmente dovuto al fatto che “le donne sono indirizzate dalla loro socializzazione e istruzione verso campi di studio generalmente più affollati, meno produttivi in termini di completamento dei diplomi, meno finanziati e che spesso offrono prospettive professionali peggiori.” In altre parole, il problema risiederebbe in differenze sistemiche e strutturali tra i campi di studio scelti dalle donne e quelli scelti dagli uomini.\nIl paradosso di Simpson crea disagio proprio perché l’intuizione suggerisce che una tendenza valida per tutte le sottopopolazioni dovrebbe esserlo anche a livello aggregato. Tuttavia, questo paradosso evidenzia un errore comune nell’interpretazione delle probabilità condizionate: confondere l’osservazione passiva con l’analisi causale. I dati che abbiamo rappresentano solo un’istantanea del comportamento normale di uomini e donne che si candidavano per l’ammissione a UC Berkeley nel 1973.\nNon possiamo trarre conclusioni definitive da questi dati. Possiamo solo riconoscere che l’analisi iniziale solleva ulteriori domande, come ad esempio la necessità di progettare nuovi studi per raccogliere dati più completi, che potrebbero portare a conclusioni più definitive. In alternativa, potremmo discutere su quale scenario sia più verosimile in base alle nostre convinzioni e alle notre ipotesi sul mondo.\nL’inferenza causale può essere utile in entrambi i casi. Da un lato, può guidare la progettazione di nuovi studi, aiutandoci a scegliere quali variabili includere, quali escludere e quali mantenere costanti. Dall’altro, i modelli causali possono fungere da meccanismo per incorporare le conoscenze scientifiche del dominio e passare da ipotesi plausibili a conclusioni plausibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#variabili-confondenti",
    "href": "chapters/eda/09_causality.html#variabili-confondenti",
    "title": "21  Causalità dai dati osservazionali",
    "section": "21.4 Variabili Confondenti",
    "text": "21.4 Variabili Confondenti\nSebbene gli esperimenti controllati siano considerati il metodo più affidabile per identificare relazioni causali, molte domande di ricerca non possono essere affrontate sperimentalmente a causa di vincoli etici o pratici. In tali situazioni, i ricercatori si rivolgono a disegni osservazionali, che garantiscono maggiore flessibilità e adattabilità ai contesti reali. Tuttavia, l’utilizzo di dati osservazionali introduce una sfida cruciale: la difficoltà di stabilire conclusioni causali solide e affidabili.\nAl centro di questa complessità si trovano le variabili confondenti. Una variabile confondente è presente quando l’associazione osservata tra due variabili, X e Y, non riflette accuratamente la vera relazione causale tra di esse. In altre parole, la variabile confondente influenza sia X che Y, creando l’apparenza di una relazione diretta tra le due che potrebbe essere fuorviante o inesatta.\nNegli studi osservazionali, se le variabili confondenti non vengono misurate e controllate adeguatamente, possono distorcere le stime degli effetti causali, introducendo bias nei risultati e impedendo di riflettere il vero valore dell’effetto. In pratica, la presenza di variabili confondenti può portare a conclusioni errate quando si confrontano semplicemente i risultati osservati in diversi gruppi. Ciò che si osserva nei dati potrebbe non corrispondere a ciò che accadrebbe se si potesse manipolare direttamente la variabile di interesse in un esperimento controllato.\n\n21.4.1 Approcci per il Controllo delle Variabili Confondenti\nUn approccio apparentemente semplice per affrontare questo problema potrebbe essere quello di controllare statisticamente tutte le variabili confondenti. Questo metodo prevede di stimare l’effetto di X su Y separatamente in ogni segmento della popolazione definito da una condizione Z = z per ogni possibile valore di z. Successivamente, si calcola la media di questi effetti stimati nelle sottopopolazioni, ponderandoli per la probabilità di Z = z nella popolazione. Tuttavia, questo metodo presenta due difficoltà fondamentali:\n\nConoscenza di tutte le variabili confondenti: Richiede la conoscenza di tutte le possibili variabili confondenti.\nMisurazione delle variabili confondenti: Richiede la capacità di misurare ciascuna di esse, cosa che spesso non è praticabile.\n\nIl controllo delle variabili confondenti è cruciale per stabilire relazioni causali, poiché permette di isolare gli effetti delle variabili indipendenti da quelli delle variabili confondenti che potrebbero influenzare le variabili dipendenti. Esistono due principali metodologie di controllo:\n\nControllo Sperimentale: Implementato attraverso il disegno sperimentale e basato principalmente sulla randomizzazione.\nControllo Statistico: Applicato durante l’analisi dei dati, con l’obiettivo di neutralizzare o quantificare l’influenza delle variabili estranee.\n\n\n\n21.4.2 Inferenza Causale nei Dati Osservazionali\nA causa di queste difficoltà, l’inferenza causale basata su dati osservazionali è spesso considerata problematica, dando origine al famoso detto “la correlazione non implica causalità”.\nAnche se il metodo preferito per l’inferenza causale in molte scienze è l’esperimento controllato e randomizzato, tali esperimenti non sono, e non sono mai stati, lo stile dominante di inferenza causale nelle scienze umane. Una ragione è che molte delle domande più importanti sul comportamento umano non possono essere studiate sperimentalmente. Alla fine, il comportamento deve essere studiato negli ambienti naturali che le persone costruiscono, poiché questi ambienti sono sia cause che conseguenze del comportamento. Senza studiare le persone nelle loro comunità, non sapremmo nemmeno cosa stiamo cercando di spiegare.\nL’inferenza causale è possibile anche in contesti osservazionali, e gli statistici hanno sviluppato metodi specializzati per progettare analisi che affrontano specifici obiettivi di inferenza causale (Pearl et al., 2016).\n\n\n21.4.3 Strumenti Moderni per l’Analisi Causale\nL’obiettivo dell’analisi causale moderna è proprio quello di fornire gli strumenti concettuali e metodologici per affrontare queste sfide. Attraverso l’uso di tecniche avanzate come i modelli causali strutturali, i grafi aciclici diretti (DAG) e i metodi di identificazione degli effetti causali, i ricercatori possono spesso superare le limitazioni dei dati osservazionali e trarre conclusioni causali più robuste.\nIn sintesi, mentre le variabili confondenti rappresentano una sfida significativa nell’analisi dei dati osservazionali, i progressi metodologici nell’analisi causale offrono strumenti potenti per mitigare questi problemi e migliorare l’affidabilità delle inferenze causali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "href": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "title": "21  Causalità dai dati osservazionali",
    "section": "21.5 Modelli Causali Strutturali",
    "text": "21.5 Modelli Causali Strutturali\nI modelli causali sono strumenti essenziali per l’analisi dei dati osservazionali, poiché consentono di rappresentare il processo sottostante a un fenomeno e di prevedere gli effetti di un intervento. Questi modelli non solo permettono di anticipare le conseguenze di una causa, ma offrono anche la possibilità di esplorare scenari controfattuali, immaginando esiti alternativi che si sarebbero potuti verificare in presenza di decisioni diverse.\nUn modello causale strutturale (Structural Causal Model, SCM) è un approccio che rappresenta le relazioni causali tra variabili. Esso si basa su una serie di assegnazioni che, partendo da variabili di rumore indipendenti (note anche come variabili esogene), generano una distribuzione di probabilità congiunta.\nLe variabili di rumore indipendenti svolgono un ruolo cruciale negli SCM. Esse rappresentano fonti di incertezza o variabilità all’interno del sistema e non sono influenzate da altre variabili del modello. Queste variabili sono mutuamente indipendenti, il che significa che il loro valore non fornisce informazioni sul valore delle altre.\nLa costruzione di un SCM segue una sequenza specifica: si parte dalle variabili di rumore indipendenti, si applicano una serie di assegnazioni che descrivono gli effetti causali delle variabili esogene su altre variabili, e si genera progressivamente un insieme di variabili casuali che dà origine a una distribuzione congiunta.\nIl principale vantaggio di un SCM risiede nella sua duplice natura: da un lato, fornisce una distribuzione di probabilità congiunta delle variabili, e dall’altro, descrive il processo generativo che porta alla formazione di tale distribuzione, partendo dalle variabili di rumore elementari.\nQuesta struttura consente non solo di modellare le relazioni probabilistiche tra le variabili, ma anche di rappresentare in modo esplicito i meccanismi causali che le governano.\nI SCM possono essere rappresentati graficamente attraverso Grafi Aciclici Direzionati (Directed Acyclic Graphs, DAG). Questi DAG visualizzano le relazioni causali tra le variabili all’interno di un SCM, facilitando l’identificazione delle variabili confondenti e il loro impatto sull’analisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "href": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "title": "21  Causalità dai dati osservazionali",
    "section": "21.6 Bias da Variabile Omessa",
    "text": "21.6 Bias da Variabile Omessa\nPossiamo introdurre i DAG facendo riferiento al bias da variabile omessa (Omitted Variable Bias, o OVB; Wilms et al. (2021)). Come discusso da Byrnes & Dee (2024), l’omissione dall’analisi statistica di variabili confondenti note ma non misurate, o sconosciute e non misurate, può portare a stime errate della magnitudine degli effetti, errori nel segno delle stime (stimatori distorti), correlazioni spurie, e al mascheramento delle vere relazioni causali.\nUn illustrazione di questa situazione è fornita nella Figura 21.1. La figura mostra tre DAG che illustrano diversi scenari in cui le variabili non osservate non influenzano i risultati del modello o potrebbero creare problemi a causa della confusione. Una variabile di risposta di interesse (Y) è causata sia da una variabile misurata (X) che da una variabile non misurata (U). Nel pannello di sinistra, la variabile non osservata (U) non è una variabile confondente. Nel pannello centrale, la variabile non osservata (U) è una variabile confondente e causa il bias da variabile omessa. Nel pannello di destra la variabile non osservata (U) causa il bias da variabile omessa in maniera indiretta.\n\n\n\n\n\n\nFigura 21.1: Nel pannello di sinistra, X e U sono non correlate, quindi la mancata inclusione di U in un modello statistico aumenterebbe l’errore standard della stima (riducendo la precisione del modello) ma non porterebbe a bias nella stima dell’effetto di X su Y. Tuttavia, se U influenza anche X come nel pannello centrale, o se U e X sono influenzati da un fattore comune Z come nel pannello di destra, allora omettere U da un modello statistico causa il bias da variabile omessa nella stima dell’effetto di X su Y. I casi illustrati dal pannello centrale e dal pannello di destra sono esempi di sistemi in cui le cause comuni di confusione (U e Z rispettivamente) devono essere controllate per effettuare inferenze causali non distorte (la figura è ispirata da Byrnes & Dee (2024)).\n\n\n\nAffrontare i problemi creati dalle variabili confondenti non misurate rappresenta una sfida primaria nell’inferenza causale dai dati osservazionali. A differenza dell’errore di misurazione nelle variabili predittive, che produce un bias costante verso lo zero e può essere corretto o modellato (McElreath, 2020; Schennach, 2016), con l’OVB non possiamo conoscere la grandezza o la direzione del bias senza conoscere tutte le possibili variabili confondenti e le loro relazioni nel sistema.\nNonostante queste sfide, non è necessario abbandonare l’uso dei dati osservazionali per l’inferenza causale in psicologia. È invece necessario ricorrere all’adozione delle tecniche dei SCM per potere comunque svolgere l’inferenza causale.\nÈ evidente che questo approccio porterà a conclusioni inevitabilmente parziali, destinate ad essere perfezionate da studi successivi. Tuttavia, tale metodologia offre il vantaggio di esplicitare il “modello generativo dei dati”, ovvero la struttura causale sottostante ai fenomeni psicologici oggetto di studio.\nI progressi nella ricerca empirica conducono a una maggiore comprensione e, di conseguenza, a modifiche nelle ipotesi sui meccanismi causali. Questo processo rappresenta un’evoluzione della conoscenza scientifica. Tale sviluppo è reso possibile proprio perché le ipotesi causali sono formulate in termini di modelli formali, che descrivono in modo preciso i meccanismi ipotizzati.\nAl contrario, limitarsi alla mera descrizione delle associazioni tra variabili non consente questo tipo di avanzamento conoscitivo. La formulazione di modelli causali espliciti permette infatti di testare, raffinare e, se necessario, rivedere le ipotesi sui meccanismi sottostanti ai fenomeni osservati, portando a una comprensione più profonda e dinamica dei processi psicologici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "href": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "title": "21  Causalità dai dati osservazionali",
    "section": "21.7 Grafi Aciclici Diretti",
    "text": "21.7 Grafi Aciclici Diretti\nI DAG sono uno strumento fondamentale per l’inferenza causale, offrendo una rappresentazione visiva delle relazioni causali ipotizzate tra variabili. Questi grafi sono definiti “diretti” perché le variabili, rappresentate da nodi, sono collegate da frecce orientate anziché da semplici linee. Sono inoltre chiamati “aciclici” poiché non è possibile tornare a un nodo di partenza seguendo il percorso delle frecce.\nIn un DAG, una freccia che va da X a Y indica un’influenza probabilistica di X su Y. La terminologia delle relazioni all’interno del grafo è importante: il nodo di origine di una freccia è chiamato “genitore”, mentre il nodo di destinazione è detto “figlio”. Quando è possibile raggiungere un nodo B partendo da un nodo A seguendo una successione di frecce, A è definito “antenato” di B, e B è considerato “discendente” di A.\nI DAG consentono di distinguere chiaramente tra cause dirette e indirette. Una causa diretta è rappresentata da un nodo genitore, mentre una causa indiretta può essere qualsiasi antenato di un nodo nel grafo causale. Questa struttura permette di differenziare efficacemente causa ed effetto basandosi sulla posizione relativa dei nodi all’interno del grafo, ovvero se un nodo è antenato o discendente di un altro.\nQuesti grafi sono particolarmente utili per identificare variabili confondenti, basandosi sulla teoria sviluppata da Judea Pearl (Pearl, 2009). È cruciale rappresentare in un DAG tutte le possibili relazioni causali, poiché l’assenza di una freccia tra due nodi implica la certezza dell’assenza di una relazione causale diretta tra le variabili corrispondenti.\nNella teoria dei DAG, due concetti fondamentali sono la d-separazione e il criterio del back-door.\n\n21.7.1 La d-separazione\nLa d-separazione ci aiuta a determinare quando due variabili in un grafo causale sono indipendenti condizionatamente a un insieme di altre variabili. Questo concetto è cruciale per comprendere come l’informazione o l’influenza si propaga tra le variabili in un modello causale.\nIn termini più semplici, la d-separazione ci permette di identificare se esiste un “blocco” nel flusso di informazioni tra due variabili, dato un certo insieme di altre variabili (che chiameremo Λ). Quando due variabili sono d-separate da Λ, significa che non c’è flusso di informazioni tra di loro, condizionatamente a Λ.\nPer comprendere meglio la d-separazione, consideriamo tre situazioni principali che possono verificarsi in un DAG:\n\nCatena (X → Z → Y): In questo caso, Z è un mediatore tra X e Y. Se Z appartiene all’insieme Λ (cioè, se controlliamo o condizioniamo su Z), blocchiamo il flusso di informazioni da X a Y attraverso questo percorso. Per esempio, se X è “esercizio fisico”, Z è “pressione sanguigna” e Y è “rischio di malattie cardiache”, controllando per la pressione sanguigna (Z) blocchiamo il percorso attraverso il quale l’esercizio fisico influenza il rischio di malattie cardiache.\nFork (X ← Z → Y): Qui, Z è una causa comune sia di X che di Y. Se Z appartiene a Λ, blocchiamo la correlazione spuria tra X e Y che deriva dalla loro causa comune. Per esempio, se Z è “status socioeconomico”, X è “livello di istruzione” e Y è “stato di salute”, controllando per lo status socioeconomico (Z) eliminiamo la correlazione apparente tra istruzione e salute che potrebbe derivare dal fatto che entrambe sono influenzate dallo status socioeconomico.\nCollider (X → Z ← Y): In questa situazione, Z è un effetto comune di X e Y. Sorprendentemente, se né Z né i suoi discendenti appartengono a Λ, il percorso è già bloccato. Controllare per Z (o i suoi discendenti) in realtà aprirebbe un percorso tra X e Y, creando una correlazione spuria. Per esempio, se X è “intelligenza”, Y è “bellezza” e Z è “successo in una carriera di attore”, controllare per il successo nella carriera di attore (Z) creerebbe una correlazione apparente tra intelligenza e bellezza, anche se queste potrebbero essere indipendenti nella popolazione generale.\n\nIn sintesi, la d-separazione ci permette di determinare, dato un certo insieme di variabili Λ, se due variabili X e Y sono indipendenti condizionatamente a Λ. Questo ci aiuta a identificare quali variabili dobbiamo controllare (e quali non dobbiamo controllare) per ottenere stime causali non distorte, facilitando così l’inferenza causale corretta. La d-separazione è quindi uno strumento potente che ci permette di leggere le indipendenze condizionali direttamente dal grafo, senza dover fare calcoli probabilistici complessi.\n\n\n21.7.2 Il criterio del back-door\nIl criterio del back-door consente di identificare un insieme di variabili che, se controllate adeguatamente, permettono di stimare gli effetti causali in modo non distorto. L’obiettivo principale di questo criterio è eliminare l’influenza di percorsi non causali tra la variabile di esposizione (causa potenziale) e l’outcome (effetto), mantenendo aperto solo il percorso causale diretto di interesse.\nIn questo contesto, due variabili sono considerate “confuse” se esiste tra di esse un percorso di tipo back-door. Un back-door path da X a Y è definito come qualsiasi percorso che inizia da X con una freccia entrante in X. Per esempio, consideriamo il seguente percorso:\nX ← A → B ← C → Y\nIn questo caso, il percorso rappresenta un flusso di informazioni da X a Y che non è causale, ma potrebbe creare l’apparenza di una relazione causale.\nPer “deconfondere” una coppia di variabili, è necessario selezionare un insieme di variabili (chiamato back-door set) che “blocchi” tutti i back-door paths tra i due nodi di interesse. Il blocco di questi percorsi avviene in modi diversi a seconda della struttura del percorso:\n\nUn back-door path che coinvolge una catena di variabili (ad esempio, A → B → C) può essere bloccato controllando per la variabile intermedia (in questo caso, B).\nUn percorso che coinvolge un “collider” (una variabile che riceve frecce da entrambe le direzioni, come in A → B ← C) è naturalmente bloccato e non permette il flusso di informazioni.\n\nÈ importante notare che bisogna prestare attenzione a non aprire involontariamente un flusso di informazioni attraverso un collider. Questo può accadere se si condiziona l’analisi sul collider stesso o su un suo discendente, il che potrebbe erroneamente aprire il percorso e introdurre bias nell’analisi.\n\n\n\n\n\n\nPunti chiave\n\n\n\n\nIl criterio del back-door aiuta a identificare il set minimale di variabili da controllare.\nNon tutte le variabili associate sia all’esposizione che all’outcome devono essere controllate; solo quelle che creano percorsi back-door.\nIn alcuni casi, potrebbe non essere necessario controllare alcuna variabile (se non ci sono percorsi back-door aperti).\nIn altri casi, potrebbe essere impossibile bloccare tutti i percorsi back-door con le variabili disponibili, indicando che l’effetto causale non può essere identificato con i dati a disposizione.\n\nUtilizzando il criterio del back-door in combinazione con i DAG, i ricercatori possono fare scelte più informate su quali variabili includere nelle loro analisi, migliorando così la validità delle loro inferenze causali.\n\n\n\n\n21.7.3 Applicazioni\nConsideriamo nuovamente la struttura causale illustrata nella Figura 21.1, pannello centrale. Dopo aver costruito un DAG come descritto nella sezione precedente, è possibile identificare le potenziali fonti di bias da variabili omesse, inclusi i confondenti non misurati (ad esempio, U). Non controllare per le variabili confondenti apre una “back-door” permettendo alla variazione confondente di influenzare la relazione tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl, 2009). In altre parole, omettere una variabile confondente come U nella Figura 21.1 (pannello centrale) in un’analisi statistica significa che questa viene incorporata nel termine di errore del modello statistico, insieme alle fonti di errore casuali. La Figura 21.2 illustra le conseguenze di un confondente U che ha un effetto positivo su X ma un effetto negativo su Y. Se adattiamo un modello come mostrato nella Figura 21.2 bi, l’effetto stimato di X su Y è positivo quando si controlla per U. Tuttavia, se non si controlla per U, come mostrato nella Figura 21.2 bii, U viene incorporato nel termine di errore, inducendo una correlazione tra l’errore e X, come illustrato nella Figura 21.2 biii, portando a una stima errata. Pertanto, il termine di errore del modello e X risultano correlati, il che viola un’assunzione fondamentale dei modelli lineari (ovvero, il teorema di Gauss-Markov; Abdallah et al., 2015; Antonakis et al., 2010). Questo produce una stima errata, evidenziata in blu.\n\n\n\n\n\n\nFigura 21.2: Una visualizzazione del bias da variabile omessa e delle conseguenze per l’inferenza causale. (A) mostra un DAG di un sistema in cui X ha un effetto positivo su Y, e una variabile confondente U ha un effetto positivo su Y ma un effetto negativo su X. Le variabili non osservate (cioè non misurate) sono rappresentate in ellissi, come la variabile U e il termine di errore e nel pannello B. (B) illustra diverse stime del DAG in (A) utilizzando un’analisi del percorso. Vedi Box 1 per una breve spiegazione delle principali differenze tra DAG e diagrammi dei percorsi. Presumiamo che U non sia misurata. In (Bi), presumiamo di poter misurare e controllare U, rappresentata dalla freccia a doppia testa tra U e X, che rappresenta la correlazione tra le due variabili considerata dal modello. La variabile non misurata e è la fonte residua di variazione che si presume non sia correlata con nessun predittore. La freccia rossa rappresenta il percorso stimato. Al contrario, (Bii) e (Biii) rappresentano la realtà, dove non abbiamo una misurazione di U e non la controlliamo nel modello dei percorsi. Il ricercatore pensa di adattare il modello in (Bii) ma in realtà sta adattando il modello in (Biii), dove il termine di errore non è solo e, ma la somma di e e la variazione dovuta alla variabile omessa U. A causa di ciò, c’è un percorso diretto dal termine di errore del modello a X (e quindi X è endogeno). (C) mostra le relazioni stimate risultanti dai modelli in (Bi) rispetto a (Bii). Le linee rappresentano la relazione stimata tra X e Y dai rispettivi modelli. La linea rossa è la vera relazione causale, stimata da (Bi), mentre la linea blu contiene il bias da variabile omessa, poiché non si tiene conto della variabile confondente U, come stimato dal modello in Bii/Biii (Figura tratta da Byrnes & Dee (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#le-pratiche-scientifiche-per-inferire-la-causalità",
    "href": "chapters/eda/09_causality.html#le-pratiche-scientifiche-per-inferire-la-causalità",
    "title": "21  Causalità dai dati osservazionali",
    "section": "21.8 Le Pratiche Scientifiche per Inferire la Causalità",
    "text": "21.8 Le Pratiche Scientifiche per Inferire la Causalità\nCome visto in precedenza, in qualsiasi sistema complesso, consideriamo due variabili, X e Y. Sebbene possiamo osservare la loro distribuzione di probabilità congiunta \\(p(x, y)\\), stabilire se X causa Y, Y causa X, o se una terza variabile Z influenzi entrambe, rimane un problema complesso (Salmon, 1984). Questa difficoltà è al centro del dibattito filosofico sulla causalità, ma è anche il motore che spinge lo sviluppo di metodi scientifici per decifrare il funzionamento del mondo. Ad esempio, per capire se una terapia cognitivo-comportamentale (TCC) riduce effettivamente i sintomi di ansia, se la lettura di un articolo scientifico influenza le opinioni dei lettori riguardo a un tema controverso, o se l’attivazione di un neurone in una specifica area cerebrale influenza il comportamento o l’attività di un altro neurone, dobbiamo affrontare queste questioni con rigore scientifico.\n\n21.8.1 Il Framework Interventista di Judea Pearl\nCome discusso sopra, il lavoro di Judea Pearl ha rivoluzionato la formalizzazione dell’inferenza causale. Mettiamo qui in evidenza il ruolo che l’intervento attivo ha nella comprensione della causalità (ricordiamo il punto di vista di Hardt & Recht, 2022 descritto in precedenza). Nella tradizionale probabilità bayesiana, consideriamo \\(p(y \\mid x)\\) — la probabilità di Y dato X. Tuttavia, Pearl ha introdotto l’operatore “do”, che permette di esprimere il risultato di un intervento attivo, scritto come \\(p(y \\mid do(x))\\). Questo rappresenta la probabilità di Y quando X viene impostato artificialmente a un certo valore (Pearl, 2009). Questo approccio si concentra sugli interventi piuttosto che sulle sole osservazioni, permettendo di isolare l’effetto causale di X su Y senza necessariamente conoscere i meccanismi sottostanti.\nPer esempio, supponiamo di voler studiare se la terapia cognitivo-comportamentale (TCC) riduce i sintomi di ansia. Osservare una correlazione tra la partecipazione alla TCC e il miglioramento dei sintomi non è sufficiente per stabilire una relazione causale. Utilizzando l’operatore “do”, possiamo simulare un intervento ipotetico: “Cosa accadrebbe se forzassimo tutti i pazienti a seguire la TCC?” Questo approccio ci permette di isolare l’effetto della TCC sui sintomi di ansia, eliminando l’influenza di fattori confondenti come lo stato socioeconomico o la predisposizione genetica.\n\n\n21.8.2 Tre Fonti di Conoscenza Causale Pragmatica\nAlla luce delle considerazioni precedenti, possiamo individuare tre fonti di conoscenza che ci informano sui meccanismi causali.\n\n21.8.2.1 Esperimenti Randomizzati Controllati (RCT)\nGli RCT sono considerati lo standard aureo per stimare gli effetti causali. Assegnando casualmente i partecipanti a gruppi di trattamento e controllo, gli RCT minimizzano l’influenza di variabili confondenti, fornendo stime non distorte dell’effetto di un intervento. Ad esempio, numerosi esperimenti dimostrano che attivare un interruttore causa l’accensione di una luce:\n\\[\np(\\text{luce accesa}|do(\\text{interruttore acceso})) \\approx 1, \\quad p(\\text{luce spenta}|do(\\text{interruttore spento})) \\approx 1\n\\]\nQuesto approccio è particolarmente utile in psicologia, dove fattori confondenti possono facilmente distorcere i risultati.\nPer esempio, immaginiamo uno studio in cui alcuni volontari vengono assegnati casualmente a dormire 8 ore o a restare svegli tutta la notte prima di un test di memoria. Gli RCT permettono di stabilire se il sonno causa un miglioramento delle prestazioni cognitive, eliminando l’influenza di fattori come l’età o lo stress.\n\n\n21.8.2.2 Comprensione Specifica del Dominio\nIn discipline come la psicologia, le neuroscienze o l’elettronica, la conoscenza specialistica consente agli esperti di basarsi su principi consolidati per formulare ipotesi causali e progettare esperimenti significativi. Ad esempio, anche se un semplice movimento della mano non causa direttamente l’accensione di una luce, la nostra comprensione dei circuiti elettrici ci informa che chiudere un interruttore completa un circuito, producendo luce. Queste intuizioni, basate su conoscenze approfondite del dominio, raffinano i nostri modelli causali e migliorano la progettazione sperimentale. Tale comprensione deriva spesso da esperimenti randomizzati precedenti e permette l’uso di quasi-esperimenti per produrre risultati causali convincenti.\nUn esempio rilevante in psicologia e neuroscienze è il ruolo dell’amigdala nella risposta alla paura. Grazie a studi clinici e sperimentali, sappiamo che l’amigdala è una struttura cerebrale chiave nel processamento delle emozioni, in particolare della paura. Pazienti con danni all’amigdala, ad esempio, mostrano una ridotta capacità di riconoscere espressioni facciali di paura e di rispondere a stimoli minacciosi. Questa conoscenza specifica del dominio ci permette di formulare ipotesi causali precise, come “L’attività nell’amigdala influenza la risposta emotiva alla paura.”\nUn altro esempio è il legame tra l’area di Broca e la produzione del linguaggio. Studi clinici su pazienti con lesioni in questa area hanno dimostrato che danni specifici portano a deficit nella produzione del linguaggio, un disturbo noto come afasia di Broca. Questa conoscenza deriva da decenni di ricerca neuroscientifica e ci permette di affermare con sicurezza che “L’attività nell’area di Broca è necessaria per la produzione fluente del linguaggio.”\nLa comprensione specifica del dominio non solo aiuta a formulare ipotesi causali, ma guida anche la progettazione degli esperimenti. Ad esempio, se vogliamo studiare l’effetto di un farmaco sulla riduzione dell’ansia, la conoscenza dei meccanismi neurobiologici alla base dell’ansia (come il ruolo del sistema limbico e dei neurotrasmettitori come la serotonina) ci permette di identificare i parametri rilevanti da misurare e di controllare per possibili fattori confondenti. Questo approccio è particolarmente utile quando non è possibile condurre esperimenti randomizzati, come nel caso di studi su pazienti con condizioni cliniche specifiche.\nIn sintesi, la comprensione specifica del dominio è un pilastro fondamentale per l’inferenza causale in psicologia e neuroscienze. Essa non solo fornisce le basi per formulare ipotesi precise, ma migliora anche la qualità e l’affidabilità della ricerca, permettendo di trarre conclusioni causali anche in contesti complessi e non sperimentali.\n\n\n21.8.2.3 Testimonianze Scientifiche e Prove Cumulative\nL’avanzamento della conoscenza scientifica dipende dalla validazione collettiva dei risultati. Quando numerosi studi indipendenti e randomizzati giungono a conclusioni causali simili, la comunità scientifica acquisisce una comprensione pragmatica, se non definitiva, dei meccanismi causali sottostanti. Questo approccio si giustifica grazie ai successi passati nella descrizione della causalità.\nPer esempio, numerosi studi indicano che le relazioni sociali positive aumentano il benessere psicologico. Benché nessuno studio singolo possa offrire una prova definitiva, l’accumulo di prove da diverse fonti conferma l’esistenza di un legame causale tra socializzazione e benessere.\n\n\n\n21.8.3 Conciliare Pragmatismo con Scetticismo Filosofico\nNonostante i metodi sperimentali, come gli esperimenti randomizzati controllati (RCT), e gli strumenti teorici, come l’operatore “do” introdotto da Judea Pearl, abbiano dimostrato una grande efficacia nella pratica scientifica, essi non risolvono completamente le sfide epistemologiche sollevate da filosofi come David Hume. Hume ha argomentato che la causalità non è qualcosa che possiamo osservare direttamente; piuttosto, è un concetto inferito attraverso l’esperienza. Questo scetticismo radicale ci ricorda che la nostra comprensione causale del mondo è sempre mediata da assunzioni e interpretazioni.\nTuttavia, ciò non significa che dobbiamo abbandonare il concetto di causalità. Al contrario, i metodi scientifici moderni forniscono uno strumento pragmatico estremamente potente per navigare nei sistemi complessi e fare previsioni affidabili. Secondo Woodward (2003), la causalità in scienza non deve essere vista come una finestra diretta ipotetiche verità metafisiche, ma piuttosto come uno strumento pratico per manipolare il mondo e prevedere i risultati delle nostre azioni. Questa prospettiva pragmatica ci permette di superare le limitazioni teoriche e concentrarci sui risultati concreti.\nConsideriamo due esempi concreti.\n\nOgni volta che saliamo su un aereo, ci affidiamo implicitamente alle leggi della fisica e all’ingegneria aeronautica. Sappiamo, grazie a studi rigorosi e prove empiriche, che le forze aerodinamiche e i principi di propulsione consentono agli aerei di volare. Questa fiducia non deriva da una certezza assoluta, ma dalla robustezza delle evidenze accumulate nel tempo. La causalità tra il disegno dell’aereo e il suo funzionamento è stata testata e confermata milioni di volte, rendendo questo mezzo di trasporto sicuro e affidabile.\nAnalogamente, quando scegliamo di seguire un trattamento psicologico, come la terapia cognitivo-comportamentale (TCC), lo facciamo basandoci su una vasta quantità di ricerche scientifiche che dimostrano l’efficacia di tali interventi. Gli studi randomizzati hanno mostrato che la TCC modifica i processi mentali e comportamentali, riducendo in maniera rilevante i sintomi di ansia e depressione. Anche qui, la nostra fiducia non deriva da una prova definitiva della causalità, ma da un corpus consistente di evidenze empiriche.\n\nLa chiave del successo del pragmatismo scientifico sta nella sua capacità di fornire risultati misurabili e replicabili. Non dobbiamo risolvere il problema filosofico della causalità per utilizzarla efficacemente. Ciò che conta è la sua applicabilità pratica: se un’intervento produce risultati coerenti e prevedibili, allora possiamo considerarlo causa di quei risultati, almeno per tutti gli scopi pratici. Questo approccio ci permette di progredire senza rimanere bloccati dalle domande metafisiche irrisolte.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#riflessioni-conclusive",
    "href": "chapters/eda/09_causality.html#riflessioni-conclusive",
    "title": "21  Causalità dai dati osservazionali",
    "section": "21.9 Riflessioni Conclusive",
    "text": "21.9 Riflessioni Conclusive\nIl dibattito filosofico sulla natura della causalità rimane un campo ricco e dinamico, ma i progressi metodologici degli ultimi decenni hanno fornito strumenti pratici e robusti per affrontare le complessità dell’inferenza causale. Esperimenti randomizzati controllati (RCT), diagrammi causali (DAG) e l’operatore “do” introdotto da Judea Pearl rappresentano esempi concreti di come, pur senza pretendere di risolvere le questioni metafisiche sulla natura ultima della causalità, la ricerca empirica sia in grado di offrire modelli affidabili per comprendere e intervenire su fenomeni complessi.\nI DAG si distinguono come uno degli strumenti più potenti per rappresentare e analizzare le relazioni causali. Essi mettono in luce le influenze dirette e indirette tra variabili, rendendo esplicite le assunzioni alla base di ogni ricerca. Tuttavia, la loro efficacia dipende in modo cruciale dalla qualità delle conoscenze del dominio: senza una comprensione approfondita del contesto, anche il DAG più raffinato rischia di omettere variabili rilevanti o di rappresentare in modo fuorviante i rapporti causali. Nonostante ciò, i DAG promuovono la trasparenza scientifica, poiché rendono visibile il processo decisionale e aiutano a identificare potenziali fonti di bias, contribuendo a una maggiore chiarezza metodologica.\nL’approccio pragmatico, che accetta di lavorare con concetti causali anche in assenza di risposte definitive ai grandi interrogativi metafisici, è al cuore del progresso scientifico. La nostra fiducia nel viaggiare in aereo o nel ricorrere a terapie come quella cognitivo-comportamentale si basa sull’evidenza empirica accumulata e confermata innumerevoli volte, non su una certezza assoluta. Questo pragmatismo non è solo utile, ma indispensabile per la ricerca scientifica e per la vita quotidiana.\nTuttavia, strumenti come i DAG non sono infallibili. Se le loro premesse sono scorrette o incomplete, le inferenze causali che ne derivano possono risultare distorte. Per mantenere la credibilità di queste tecniche, è essenziale un rigoroso controllo metodologico, accompagnato da una riflessione critica costante sulle assunzioni sottostanti. Solo questa vigilanza epistemologica permette di evitare semplificazioni eccessive e di confrontarsi in modo costruttivo con i limiti intrinseci dell’inferenza causale.\nIn definitiva, l’indagine causale contemporanea richiede un bilanciamento tra pragmatismo — che valorizza e applica i risultati empirici in modo concreto — e scetticismo filosofico, che stimola un’analisi continua delle nostre ipotesi e premesse. Questa prospettiva equilibrata è essenziale per l’avanzamento delle conoscenze. Pur rimanendo consapevoli che la “vera natura” della causalità possa restare, almeno in parte, un mistero irrisolvibile, possiamo comunque costruire strumenti sufficientemente robusti per prevedere con accuratezza i fenomeni di interesse e prendere decisioni informate. È questa combinazione di umiltà epistemologica e fiducia pragmatica a permetterci di avanzare nella comprensione del mondo, pur senza pretendere di esaurirne tutta la complessità.\nUn sommario ironico di questi concetti è fornito nella vignetta di xkcd.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#esercizi",
    "href": "chapters/eda/09_causality.html#esercizi",
    "title": "21  Causalità dai dati osservazionali",
    "section": "21.10 Esercizi",
    "text": "21.10 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizi teorici\nEsercizio 1: Concetti chiave della causalità\nPer ciascuna delle seguenti affermazioni, indica se è vera o falsa e spiega il motivo della tua risposta.\n\nSe X e Y sono correlate, allora X causa Y.\n\nSe condizioniamo su una variabile collider, la correlazione tra X e Y aumenta.\n\nIl paradosso di Simpson dimostra che i risultati osservati in gruppi disaggregati devono sempre essere preferiti a quelli aggregati.\n\nGli esperimenti randomizzati controllati eliminano completamente il problema della confusione.\n\nUn DAG può rappresentare relazioni causali solo se tutte le variabili sono misurate.\n\nEsercizio 2: Interpretazione di un DAG\nConsidera il seguente DAG che rappresenta l’effetto dell’esercizio fisico (X) sulla salute cardiaca (Y):\n    X → Y\n    Z → X\n    Z → Y\ndove:\n\nX = Esercizio fisico\n\nY = Salute cardiaca\n\nZ = Predisposizione genetica\n\n\nQuale ruolo svolge Z in questo DAG? È una variabile confondente, collider o mediatore?\nPer stimare correttamente l’effetto causale di X su Y, è necessario controllare per Z? Spiega il perché.\n\nSe aggiungiamo un’altra variabile W che influenza sia Z che X, ma non direttamente Y, come cambierebbe il DAG?\n\nEsercizio 3: Causalità nei dati osservazionali\nLeggi le seguenti situazioni e identifica quale problema potrebbe invalidare l’inferenza causale:\n\nUno studio osservazionale mostra che le persone che bevono caffè vivono più a lungo. Tuttavia, chi beve caffè tende ad avere un reddito più alto e accesso a migliori cure mediche.\nUn’azienda scopre che i dipendenti che frequentano corsi di formazione hanno salari più alti. Ma i corsi sono aperti solo a coloro che già hanno più esperienza lavorativa.\n\nUna ricerca mostra che gli studenti che usano di più il tablet per studiare hanno punteggi più bassi nei test. Tuttavia, gli studenti con difficoltà di apprendimento tendono a usare di più il tablet.\n\nPer ogni caso, identifica una possibile variabile confondente e suggerisci un metodo per controllare il bias.\nEsercizi pratici in R\nEsercizio 4: Paradosso di Simpson con dati reali\nUtilizziamo i dati delle ammissioni di UC Berkeley per verificare il paradosso di Simpson.\n# Dati di UC Berkeley\ndata(UCBAdmissions)\ndf &lt;- as.data.frame(UCBAdmissions)\n\n# Convertiamo i dati in formato long\ndf_long &lt;- df |&gt; tidyr::pivot_wider(names_from = \"Admit\", values_from = \"Freq\") \n\n# Calcoliamo il tasso di ammissione per uomini e donne aggregati\ntotal_admitted_m &lt;- sum(df$Freq[df$Admit == \"Admitted\" & df$Gender == \"Male\"])\ntotal_applicants_m &lt;- sum(df$Freq[df$Gender == \"Male\"])\n\ntotal_admitted_f &lt;- sum(df$Freq[df$Admit == \"Admitted\" & df$Gender == \"Female\"])\ntotal_applicants_f &lt;- sum(df$Freq[df$Gender == \"Female\"])\n\nadmit_rate_m &lt;- total_admitted_m / total_applicants_m\nadmit_rate_f &lt;- total_admitted_f / total_applicants_f\n\nc(admit_rate_m, admit_rate_f)\n\n# Calcoliamo il tasso di ammissione per ogni dipartimento\ndf_long$rate_m &lt;- df_long$Admitted / (df_long$Admitted + df_long$Rejected)\n\ndf_long |&gt; dplyr::group_by(Dept) |&gt; dplyr::summarize(mean_rate_m = mean(rate_m))\n\n# Visualizziamo il tasso di ammissione per genere e dipartimento\nggplot(df_long, aes(x = Dept, y = rate_m, fill = Gender)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Tasso di Ammissione per Genere nei Dipartimenti UC Berkeley\",\n       x = \"Dipartimento\", y = \"Tasso di Ammissione\")\nDomande:\n\nDai dati aggregati, sembra che le donne siano discriminate. Questo è confermato dall’analisi per dipartimento?\n\nQuale variabile confondente è responsabile del paradosso di Simpson in questo caso?\n\nCome potrebbe essere interpretato male un modello che considera solo i dati aggregati?\n\nEsercizio 5: Analisi causale con DAG\nUsiamo il pacchetto dagitty per costruire e analizzare un DAG.\nlibrary(dagitty)\n\ndag &lt;- dagitty(\"dag {\n    E -&gt; H\n    G -&gt; E\n    G -&gt; H\n}\")\n\nplot(graphLayout(dag))\nDomande:\n\nQuali sono le variabili confondenti nel DAG?\n\nQuali percorsi sono back-door paths?\n\nQuale set di variabili dovremmo controllare per ottenere una stima non distorta dell’effetto di E su H?\n\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nEsercizio 1: Concetti chiave della causalità\n\nFalso – La correlazione non implica causalità. Potrebbero esserci variabili confondenti o una relazione di causalità inversa tra X e Y.\n\nVero – Condizionare su un collider introduce un’associazione spuriosa tra X e Y, aumentando la correlazione.\n\nFalso – Il paradosso di Simpson mostra che i dati aggregati possono essere fuorvianti, ma non significa che i dati disaggregati siano sempre più affidabili. È necessario analizzare il contesto e le possibili variabili confondenti.\n\nFalso – Gli RCT minimizzano i problemi di confondimento grazie alla randomizzazione, ma possono comunque avere limitazioni dovute a bias di selezione, mancate assegnazioni casuali, e problemi etici.\n\nFalso – Un DAG può rappresentare le relazioni causali anche se alcune variabili non sono misurate. Tuttavia, la validità dell’inferenza dipende dalla correttezza del DAG.\n\nEsercizio 2: Interpretazione di un DAG\n\nZ è una variabile confondente, poiché influenza sia X che Y, creando un percorso di back-door.\n\nSì, per stimare correttamente l’effetto di X su Y dobbiamo controllare per Z. Se non lo facciamo, la relazione osservata tra X e Y includerà l’influenza di Z.\n\nSe aggiungiamo una variabile W che influenza Z e X, il DAG diventa:\n    W → Z → X → Y\n    W → X\n    Z → Y\nOra W è una variabile a monte di X e Z, ma non confonde direttamente la relazione tra X e Y.\n\nEsercizio 3: Causalità nei dati osservazionali\n\nConfondente: reddito – Le persone con un reddito più alto possono avere accesso a cure migliori, che a loro volta migliorano la salute. Soluzione: Propensity Score Matching (PSM) o regressione con controllo per il reddito.\n\nConfondente: esperienza lavorativa – Chi ha più esperienza può già avere salari più alti. Soluzione: Matching o modello di regressione con controllo per esperienza lavorativa.\n\nConfondente: difficoltà di apprendimento – Studenti con difficoltà possono usare più il tablet e avere punteggi più bassi. Soluzione: Includere il livello di abilità di partenza nei modelli statistici.\n\nSoluzioni esercizi pratici in R\nEsercizio 4: Paradosso di Simpson con dati reali\n\nDifferenza nei tassi di ammissione aggregati:\nadmit_rate_m &lt;- total_admitted_m / total_applicants_m\nadmit_rate_f &lt;- total_admitted_f / total_applicants_f\nRisultato:\n\nTasso di ammissione uomini: ~44%\n\nTasso di ammissione donne: ~35%\n→ Sembra che le donne siano discriminate.\n\nAnalisi per dipartimento:\ndf_long |&gt; dplyr::group_by(Dept) |&gt; dplyr::summarize(mean_rate_m = mean(rate_m))\n\nNei singoli dipartimenti, le donne hanno tassi di ammissione uguali o superiori rispetto agli uomini.\n→ Il problema non è discriminazione diretta, ma la distribuzione delle domande nei dipartimenti.\n\nConclusione: Il paradosso di Simpson mostra che le donne tendono a candidarsi più spesso a dipartimenti molto competitivi con bassi tassi di ammissione, mentre gli uomini si candidano di più in dipartimenti con tassi di ammissione più alti.\n\nMoralità: Non sempre una differenza aggregata indica un bias. Bisogna analizzare i sottogruppi.\nEsercizio 5: Analisi causale con DAG\n\nVariabili confondenti\n\nG è una variabile confondente perché influenza sia E (esposizione) che H (esito).\n\nBack-door paths\n\nIl percorso E ← G → H è un back-door path che deve essere bloccato.\n\nSoluzione: controllare per G\nadjustmentSets(dag)\nOutput: {G}\n→ Controllare per G permette di ottenere una stima causale non distorta di E su H.\n\nConclusioni\n\nLa correlazione non implica causalità. Abbiamo visto come variabili confondenti possano generare relazioni spurie.\n\nIl paradosso di Simpson dimostra che i dati aggregati possono essere fuorvianti. Bisogna sempre analizzare i sottogruppi.\n\nI DAG aiutano a identificare le variabili da controllare per ottenere stime causali corrette.\n\nL’analisi causale è fondamentale per evitare inferenze errate e migliorare la qualità della ricerca.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bibliografia",
    "href": "chapters/eda/09_causality.html#bibliografia",
    "title": "21  Causalità dai dati osservazionali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nByrnes, J. E., & Dee, L. E. (2024). Causal inference with observational data and unobserved confounding variables. bioRxiv, 2024–2002.\n\n\nHardt, M., & Recht, B. (2022). Patterns, Predictions, and Actions: Foundations of Machine Learning. Princeton University Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPearl, J. (2009). Causality. Cambridge University Press.\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal inference in statistics: A primer. John Wiley & Sons.\n\n\nRiederer, E. (2021). Causal design patterns for data analysts. https://emilyriederer.netlify.app/post/causal-design-patterns/\n\n\nSchennach, S. M. (2016). Recent advances in the measurement error literature. Annual Review of Economics, 8(1), 341–377.\n\n\nWilms, R., Mäthner, E., Winnen, L., & Lanwehr, R. (2021). Omitted variable bias: A threat to estimating causal relationships. Methods in Psychology, 5, 100075.\n\n\nZwet, E. van, Gelman, A., Greenland, S., Imbens, G., Schwab, S., & Goodman, S. N. (2023). A New Look at P Values for Randomized Clinical Trials. NEJM Evidence, 3(1), EVIDoa2300003.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html",
    "href": "chapters/eda/10_estimand.html",
    "title": "22  Estimandi teorici e estimandi empirici",
    "section": "",
    "text": "22.1 Introduzione\nNei capitoli precedenti abbiamo esplorato diverse tecniche di analisi esplorativa dei dati, strumenti fondamentali per sintetizzare informazioni, rappresentare le distribuzioni delle variabili e descriverne le relazioni. Tuttavia, queste tecniche presuppongono che le variabili siano state misurate in modo appropriato rispetto alla domanda teorica di ricerca. È quindi essenziale chiarire il legame tra le quantità che intendiamo stimare (estimandi) e il quadro teorico che guida l’analisi.\nPer approfondire questa relazione tra teoria e misurazione, esamineremo il contributo di Lundberg et al. (2021), What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory. Questo lavoro evidenzia l’importanza di una precisa definizione dell’estimando in uno studio e della distinzione tra estimando teorico ed estimando empirico, cruciale per interpretare correttamente i risultati statistici nel contesto della teoria sottostante.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#definizione-di-estimando",
    "href": "chapters/eda/10_estimand.html#definizione-di-estimando",
    "title": "22  Estimandi teorici e estimandi empirici",
    "section": "22.2 Definizione di Estimando",
    "text": "22.2 Definizione di Estimando\nIn epistemologia e metodologia della ricerca, il concetto di estimando si riferisce alla quantità che desideriamo stimare attraverso l’osservazione e l’inferenza. Nelle scienze psicologiche, dove molti fenomeni di interesse non sono direttamente osservabili, è fondamentale distinguere tra:\n\nEstimando teorico – il costrutto latente definito dalla teoria.\nEstimando empirico – la misura numerica ottenuta da dati osservabili.\n\n\n22.2.1 Estimando Teorico: Il Costrutto Latente\nL’estimando teorico è la quantità di interesse che un modello teorico definisce, ma che non può essere direttamente osservata. Nelle scienze psicologiche, la maggior parte dei costrutti – come intelligenza, ansia, personalità, autoefficacia – rientra in questa categoria.\n\nEsempio 22.1 Consideriamo il livello di ansia di tratto di un individuo, ovvero la sua tendenza stabile a sperimentare stati ansiosi in diverse situazioni:\n\nL’ansia di tratto è un costrutto teorico formulato nella teoria della personalità.\nNon possiamo osservarla direttamente, né esiste un singolo indicatore oggettivo che la rappresenti perfettamente.\nL’ansia di tratto è quindi un estimando teorico, inferibile solo tramite indicatori osservabili.\n\n\n\n\n22.2.2 Estimando Empirico: La Misura Osservabile\nL’estimando empirico è la misura quantitativa che usiamo per approssimare l’estimando teorico. È ottenuto attraverso strumenti di misurazione come test psicometrici, scale di valutazione o indicatori fisiologici.\n\nEsempio 22.2 Per stimare l’ansia di tratto, possiamo utilizzare il State-Trait Anxiety Inventory (STAI-T), un questionario i cui item includono affermazioni come:\n\n“Mi sento spesso nervoso senza motivo apparente.”\n“Tendo a preoccuparmi molto anche per piccole cose.”\n\nLe risposte fornite dal soggetto vengono aggregate in un punteggio complessivo, che rappresenta un estimando empirico dell’ansia di tratto. Tuttavia:\n\nQuesto punteggio è solo una proxy quantitativa dell’ansia di tratto.\nNon corrisponde all’ansia di tratto in sé, ma è una stima basata su dati osservabili.\n\n\n\n\n22.2.3 Differenze tra Estimando Teorico ed Empirico\n\n\n\n\n\n\n\n\nAspetto\nEstimando Teorico\nEstimando Empirico\n\n\n\n\nDefinizione\nCostrutto latente, concettuale\nMisura osservabile, numerica\n\n\nEsempi\nIntelligenza, ansia, personalità\nPunteggi a test, risposte a questionari\n\n\nMisurabilità\nNon direttamente osservabile\nDerivato da dati empirici\n\n\nDipendenza dai dati\nDefinito dalla teoria\nDerivato da strumenti di misura",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#le-sfide-della-stima-degli-estimandi",
    "href": "chapters/eda/10_estimand.html#le-sfide-della-stima-degli-estimandi",
    "title": "22  Estimandi teorici e estimandi empirici",
    "section": "22.3 Le Sfide della Stima degli Estimandi",
    "text": "22.3 Le Sfide della Stima degli Estimandi\nL’uso di estimandi empirici per inferire estimandi teorici presenta diverse sfide metodologiche:\n\nValidità della Misura\n\nIl test STAI-T misura veramente l’ansia di tratto o cattura solo un aspetto superficiale dell’ansia?\nIndicatori fisiologici come il cortisolo o la conduttanza cutanea possono offrire altre proxy dell’ansia, ma con significati differenti.\n\nAffidabilità della Misura\n\nIl punteggio ottenuto è stabile nel tempo?\nSe un soggetto compila il test in momenti diversi, ottiene risultati simili?\n\nDistorsioni e Errori di Misura\n\nGli item del questionario potrebbero influenzare le risposte?\nI soggetti rispondono in modo onesto o sono condizionati da desiderabilità sociale?\n\nModelli Statistici e Inferenza Bayesiana\n\nI modelli fattoriali, le equazioni strutturali (SEM) e i modelli bayesiani sono strumenti essenziali per inferire estimandi teorici dai dati empirici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#il-modello-fattoriale-latente",
    "href": "chapters/eda/10_estimand.html#il-modello-fattoriale-latente",
    "title": "22  Estimandi teorici e estimandi empirici",
    "section": "22.4 Il Modello Fattoriale Latente",
    "text": "22.4 Il Modello Fattoriale Latente\nL’ansia di tratto (\\(\\theta\\)) può essere modellata come una variabile latente tramite l’analisi fattoriale. Il modello assume la seguente forma:\n\\[\ny_i = \\lambda_i \\theta + \\epsilon_i ,\n\\tag{22.1}\\]\ndove:\n\n\\(y_i\\) è la risposta osservabile al singolo item (estimando empirico),\n\\(\\theta\\) è il livello latente di ansia di tratto (estimando teorico),\n\\(\\lambda_i\\) è il peso fattoriale dell’item, che indica quanto l’item misura il costrutto latente.\n\\(\\epsilon_i\\) è l’errore di misurazione.\n\nL’analisi fattoriale permette di:\n\nidentificare la struttura del costrutto,\nquantificare il contributo di ciascun item attraverso i pesi fattoriali (\\(\\lambda_i\\)),\nseparare la variabilità spiegata dalla variabilità attribuibile all’errore (\\(\\epsilon_i\\)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#framework-di-lundberg2021your-il-collegamento-tra-teoria-e-dati",
    "href": "chapters/eda/10_estimand.html#framework-di-lundberg2021your-il-collegamento-tra-teoria-e-dati",
    "title": "22  Estimandi teorici e estimandi empirici",
    "section": "22.5 Framework di Lundberg et al. (2021): Il Collegamento tra Teoria e Dati",
    "text": "22.5 Framework di Lundberg et al. (2021): Il Collegamento tra Teoria e Dati\nLundberg et al. (2021) propongono un approccio metodologico in tre fasi:\n\ndefinire l’estimando teorico, ancorandolo esplicitamente alla teoria di riferimento,\ntradurre l’estimando teorico in un estimando empirico, ovvero una misura osservabile,\nstimare l’estimando empirico, applicando procedure statistiche adeguate.\n\n\nEsempio 22.3 Un esempio concreto è fornito dal modello di Rescorla-Wagner, applicato a compiti di Probabilistic Reversal Learning (PRL): l’estimando empirico potrebbe corrispondere a parametri come il tasso di apprendimento \\(\\alpha\\) o la temperatura inversa \\(\\beta\\). Questi parametri riflettono quanto i partecipanti modifichino i valori associati agli stimoli o regolino la strategia di scelta (esplorazione rispetto a sfruttamento).\nÈ importante notare che l’estimando empirico può essere stimato in modi diversi, utilizzando modelli, metodi di stima e disegni sperimentali vari. Il modello di Rescorla-Wagner è solo una possibile rappresentazione dell’apprendimento associativo, e i suoi parametri possono essere ricavati con procedure differenti. Di conseguenza, il valore numerico che descrive la capacità di apprendimento associativo dipende dal modello, dalla tecnica di stima e dal contesto sperimentale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#conclusioni",
    "href": "chapters/eda/10_estimand.html#conclusioni",
    "title": "22  Estimandi teorici e estimandi empirici",
    "section": "22.6 Conclusioni",
    "text": "22.6 Conclusioni\nDefinire chiaramente l’estimando teorico è un passo fondamentale per garantire la validità delle inferenze scientifiche. Il framework di Lundberg et al. (2021) fornisce un metodo rigoroso per legare teoria e dati, migliorando la replicabilità e la coerenza degli studi psicologici.\nL’adozione di un approccio strutturato nella definizione degli estimandi consente di:\n\nChiarire gli obiettivi della ricerca.\nGarantire la coerenza tra teoria e dati.\nMigliorare la qualità e l’interpretazione delle inferenze statistiche.\n\nIn questo modo, la ricerca quantitativa può produrre risultati più solidi e generalizzabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#esercizi",
    "href": "chapters/eda/10_estimand.html#esercizi",
    "title": "22  Estimandi teorici e estimandi empirici",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nEsercizio 1: Distinguere Estimando Teorico ed Empirico\n\nObiettivo: Comprendere la differenza tra costrutti latenti e misure osservabili.\n\nAttività: Scegli tre costrutti psicologici (es. autostima, ansia di tratto, empatia). Per ciascuno:\n\nDescrivi l’estimando teorico (cioè il costrutto latente).\n\nIdentifica un possibile estimando empirico (es. punteggio a un questionario).\n\nSpiega in che modo il passaggio dal costrutto latente alla misura osservabile potrebbe introdurre errori o distorsioni.\n\n\nEsercizio 2: Validità e Affidabilità di una Scala di Misura\n\nObiettivo: Riflettere sugli aspetti di validità (contenuto, costrutto) e affidabilità (stabilità delle misure) di uno strumento.\n\nAttività: Immagina di dover stimare il costrutto “ansia di prestazione” in atleti. Proponi:\n\nUn questionario o scala con 5 item, descrivendo i contenuti di ciascun item.\n\nUna strategia per valutare la validità (es. confrontare con un altro test già validato, definire i criteri di inclusione degli item).\n\nUna procedura per valutare l’affidabilità (es. test-retest, consistenza interna).\n\nUna breve discussione su possibili fonti di errore di misurazione (desiderabilità sociale, bias di risposta).\n\n\nEsercizio 3: Modello Fattoriale Latente\n\nObiettivo: Comprendere come un modello fattoriale colleghi risposte osservate a un costrutto latente.\n\nAttività: Supponi di avere 4 item che misurano il costrutto “senso di autoefficacia”. I punteggi di ogni item vanno da 1 (per niente d’accordo) a 5 (molto d’accordo). Ti vengono forniti dati fittizi per 10 persone (es. risposte in tabella).\n\nProva a ipotizzare come si potrebbe rappresentare l’equazione di un modello fattoriale (simile all’esempio nel testo con \\(y_i = \\lambda_i \\theta + \\epsilon_i\\)).\n\nIndica in parole semplici che cosa rappresentano \\(\\theta\\), \\(\\lambda_i\\) ed \\(\\epsilon_i\\) nel tuo esempio.\n\nElenca due vantaggi che un modello fattoriale offre rispetto al calcolo semplice di una media su tutti gli item.\n\n\nEsercizio 4: Definire l’Estimando per un Compito di Apprendimento\n\nObiettivo: Legare un esperimento e un modello a un preciso estimando teorico ed empirico.\n\nAttività: Immagina uno studio sperimentale di apprendimento in cui i partecipanti devono imparare la regola di associazione tra uno stimolo visivo e una ricompensa. Hai deciso di usare il modello di Rescorla-Wagner per stimare il tasso di apprendimento (\\(\\alpha\\)) di ciascun partecipante.\n\nDescrivi l’estimando teorico che ti interessa (es. “capacità di aggiornare le aspettative in base al feedback”).\n\nSpiega in che modo l’estimando empirico (\\(\\alpha\\)) è derivato dai dati osservati (scelte del partecipante, errori, risposte corrette).\n\nElenca due possibili ragioni per cui il valore di \\(\\alpha\\) ottenuto può essere diverso in base alla procedura di stima (es. tipo di algoritmo, impostazioni iniziali).\n\n\nEsercizio 5: Criticità nell’Interpretazione degli Estimandi\n\nObiettivo: Riflettere sui possibili fattori che rendono complessa l’interpretazione del punteggio stimato.\n\nAttività: Scegli un qualsiasi costrutto psicologico (es. impulsività, motivazione al successo, stile di attaccamento). Immagina di avere uno strumento (questionario, test computerizzato o altro) che fornisce un punteggio finale come estimando empirico.\n\nSpiega come l’errore di misurazione (rumore, bias di risposta, item poco chiari) può influire sull’interpretazione del punteggio.\n\nDescrivi una situazione in cui il punteggio osservato potrebbe non riflettere correttamente il costrutto latente (es. persona che risponde in modo poco sincero).\n\nProponi due strategie per migliorare la validità della misura (es. aggiungere item, utilizzare misurazioni multiple, integrazione con misure fisiologiche, controlli statistici, ecc.).\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nEsercizio 1: Distinguere Estimando Teorico ed Empirico\n\nAutostima\n\nEstimando teorico: L’idea di “auto-valutazione globale positiva o negativa di sé” (construct della psicologia della personalità). Non si misura direttamente, ma è un concetto chiave per spiegare comportamenti di auto-efficacia, soddisfazione, ecc.\n\nEstimando empirico: Punteggio ottenuto dal Rosenberg Self-Esteem Scale (RSES), una scala di 10 item con punteggi da 0 a 30.\n\nErrori/distorsioni: Possibile desiderabilità sociale: il partecipante potrebbe tendere a rispondere in modo da apparire migliore; eventuale variazione linguistica nella comprensione degli item.\n\nAnsia di tratto\n\nEstimando teorico: Tendenza stabile a sperimentare preoccupazione, nervosismo, e tensione in varie situazioni (componente relativamente stabile).\n\nEstimando empirico: Punteggio della sezione Trait (T) del State-Trait Anxiety Inventory (STAI-T).\n\nErrori/distorsioni: Bias di risposta (es. risposte casuali, eccessiva fretta), scarsa onestà, influenza dell’umore momentaneo (che dovrebbe riflettere l’ansia di stato, non di tratto).\n\nEmpatia\n\nEstimando teorico: Capacità di comprendere e condividere lo stato emotivo altrui, distinta in componente cognitiva e affettiva.\n\nEstimando empirico: Punteggio al Davis Interpersonal Reactivity Index (IRI) o un’altra scala self-report sull’empatia.\n\nErrori/distorsioni: Limitazione del formato self-report nel catturare l’aspetto empatico reale in situazioni quotidiane, possibili misunderstanding di alcuni item.\n\n\nEsercizio 2: Validità e Affidabilità di una Scala di Misura\n\nQuestionario a 5 item (risposte su scala Likert 1–5):\n\n“Prima di una gara, mi preoccupo di non riuscire a gestire la pressione.”\n\n“Penso spesso a come potrei sbagliare durante la competizione.”\n\n“Mi sento nervoso/a e teso/a molto tempo prima di iniziare la performance.”\n\n“Ho la sensazione di non essere all’altezza di ciò che ci si aspetta da me.”\n\n“Faccio fatica a concentrare l’attenzione sui miei obiettivi sportivi.”\n\nStrategia per valutare la validità\n\nValidità di contenuto: confrontare gli item con la letteratura specialistica sull’ansia di prestazione (chiedere feedback a esperti in psicologia dello sport).\n\nValidità concorrente: somministrare il questionario insieme a un altro strumento già validato per l’ansia di prestazione (o con una misura fisiologica di stress, come frequenza cardiaca a riposo).\n\nValidità di costrutto: correlare i punteggi con scale simili (es. STAI) e verificare che siano più alti in atleti di sport ad alta pressione (es. gare individuali).\n\nProcedura per valutare l’affidabilità\n\nTest-retest: somministrare la scala a un gruppo di atleti a distanza di 2 settimane, verificando la correlazione tra i punteggi.\n\nConsistenza interna: calcolare l’α di Cronbach per stimare in che misura gli item misurano un costrutto coerente.\n\nPossibili fonti di errore\n\nBias di desiderabilità sociale (l’atleta potrebbe minimizzare la propria ansia).\n\nStato emotivo contingente (per es., stress esterno non legato allo sport).\n\nSituazione specifica dell’atleta il giorno della compilazione (stanchezza, problemi personali, ecc.).\n\n\nEsercizio 3: Modello Fattoriale Latente\n\nEquazione di un modello fattoriale (semplificata)\n\\[\ny_i = \\lambda_i \\,\\theta + \\epsilon_i \\quad\\quad (i=1,2,3,4),\n\\]\ndove\n\n\\(y_i\\) è la risposta all’item \\(i\\),\n\n\\(\\theta\\) è il livello latente di autoefficacia,\n\n\\(\\lambda_i\\) è il peso fattoriale per l’item \\(i\\),\n\n\\(\\epsilon_i\\) è l’errore di misurazione per l’item \\(i\\).\n\nDescrizione dei termini:\n\n\\(\\theta\\): il “vero” senso di autoefficacia che non possiamo osservare direttamente.\n\n\\(\\lambda_i\\): indica quanto ciascun item riflette il costrutto; se \\(\\lambda_i\\) è alto, l’item è molto rappresentativo.\n\n\\(\\epsilon_i\\): comprende errori casuali, interpretazioni errate, ecc.\n\nDue vantaggi del modello fattoriale:\n\nGestione dell’errore: il modello separa la parte di variabilità dovuta al costrutto da quella dovuta all’errore (mentre la media “mescola” entrambe).\n\nIndagine del peso di ciascun item: possiamo capire se un item è fortemente o debolmente collegato al costrutto, migliorando la validità dello strumento.\n\n\nEsercizio 4: Definire l’Estimando per un Compito di Apprendimento\n\nEstimando teorico\n\nL’“abilità di adeguare il comportamento in funzione degli esiti passati” corrisponde al grado di plasticità dell’apprendimento. Non osserviamo “direttamente” questa abilità, che resta un costrutto astratto.\n\nEstimando empirico (\\(\\alpha\\))\n\nNel modello di Rescorla-Wagner, dopo ogni prova la stima del valore dello stimolo si aggiorna in base all’errore di predizione.\n\nDati osservati: scelte del partecipante, premio o penalità ricevuti, differenze tra aspettative e risultati effettivi.\n\n\\(\\alpha\\) si stima applicando un metodo di ottimizzazione (per es. regressione non lineare, massima verosimiglianza, o un approccio bayesiano) che riduce lo scarto tra le previsioni del modello e il comportamento (scelte corrette/errate) del partecipante.\n\nDue ragioni per cui \\(\\alpha\\) varia\n\nDifferenti procedure di ottimizzazione: alcuni algoritmi convergono a un valore locale invece che globale, oppure usano penali diverse per la complessità del modello.\n\nVarie formulazioni del modello: si potrebbero introdurre parametri addizionali (ad es. \\(\\beta\\) per la “temperatura inversa” o funzioni di apprendimento leggermente diverse) che modificano il valore ottimale di \\(\\alpha\\).\n\n\nEsercizio 5: Criticità nell’Interpretazione degli Estimandi\n\nCostrutto: Impulsività\n\nStrumento: Una scala di autovalutazione (es. Barratt Impulsiveness Scale)\n\n\nInfluenza dell’errore di misurazione\n\nSe un individuo compila la scala in un momento di forte stress o fretta, le sue risposte possono enfatizzare un aspetto temporaneo invece che stabile.\n\nPiccoli errori (item poco chiari, interpretazioni ambigue) si sommano, distorcendo il punteggio finale.\n\nSituazione in cui il punteggio non rispecchia il costrutto latente\n\nUna persona tende a presentarsi in modo socialmente desiderabile, dunque minimizza i comportamenti impulsivi. Di fatto, il punteggio osservato sarà basso, ma non rappresenta il vero livello di impulsività.\n\nDue strategie per migliorare la validità\n\nAggiungere item e fonti multiple: utilizzare più item su diverse sfaccettature dell’impulsività e integrare dati osservazionali o indicatori oggettivi (per es. tempi di reazione in un test computerizzato).\n\nRidurre la desiderabilità sociale: rendere le risposte anonime, istruendo i partecipanti sull’importanza di risposte autentiche, o aggiungere un indice di tendenza alla risposta “socialmente accettabile”.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#bibliografia",
    "href": "chapters/eda/10_estimand.html#bibliografia",
    "title": "22  Estimandi teorici e estimandi empirici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLundberg, I., Johnson, R., & Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532–565.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html",
    "href": "chapters/eda/11_outlier.html",
    "title": "23  Outlier",
    "section": "",
    "text": "23.1 Introduzione\nQuando analizziamo dati reali, ci imbattiamo spesso in osservazioni che sembrano molto diverse dalla maggior parte delle altre. Questi valori anomali, chiamati outlier, possono avere origini diverse. Ad esempio, potrebbero derivare da errori di misura o inserimento dati, oppure essere casi estremi ma comunque validi.\nIdentificare e trattare gli outlier in modo appropriato è importante per evitare che distorcano i risultati dell’analisi. Tuttavia, non esiste una definizione universale di outlier: dipende dal contesto e dall’obiettivo dell’analisi.\nIn questo capitolo, esploreremo diversi metodi per individuare gli outlier, concentrandoci su tecniche robuste che minimizzano l’influenza di questi valori anomali sulle statistiche descrittive (Simmons et al., 2011).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#come-identificare-gli-outlier",
    "href": "chapters/eda/11_outlier.html#come-identificare-gli-outlier",
    "title": "23  Outlier",
    "section": "\n23.2 Come Identificare gli Outlier",
    "text": "23.2 Come Identificare gli Outlier\n\n23.2.1 Un primo metodo: i boxplot\nUno strumento semplice e intuitivo per individuare gli outlier è il boxplot. Il boxplot riassume la distribuzione di una variabile mostrando la mediana, il primo e il terzo quartile (Q1 e Q3) e due estremi, detti “whiskers”. I punti al di fuori di questi whiskers sono considerati potenziali outlier.\nEsempio in R:\n\ndata &lt;- data.frame(\n  value = c(rnorm(100, mean = 10, sd = 2), 30)\n  ) # Aggiungiamo un outlier\n\nggplot(data, aes(y = value)) +\n  geom_boxplot() +\n  coord_flip()\n\n\n\n\n\n\n\nSe il boxplot mostra un punto isolato lontano dagli altri dati, potrebbe essere un outlier.\n\n23.2.2 Metodi basati sulla variabilità\n\n23.2.2.1 Intervallo interquartile (IQR)\nJohn Tukey ha introdotto una definizione operativa di outlier basata sull’Interquartile Range (IQR), ovvero la differenza tra il terzo e il primo quartile:\n\nI valori inferiori a \\(Q1 - 1.5 \\times IQR\\) o superiori a \\(Q3 + 1.5 \\times IQR\\) sono considerati outlier moderati.\nI valori oltre \\(Q1 - 3 \\times IQR\\) o \\(Q3 + 3 \\times IQR\\) sono definiti far out outliers.\n\nEsempio in R:\n\nQ1 &lt;- quantile(data$value, 0.25)\nQ3 &lt;- quantile(data$value, 0.75)\nIQR_value &lt;- Q3 - Q1\nlower_bound &lt;- Q1 - 1.5 * IQR_value\nupper_bound &lt;- Q3 + 1.5 * IQR_value\n\noutliers &lt;- data$value[data$value &lt; lower_bound | data$value &gt; upper_bound]\noutliers\n#&gt; [1]  4.687  4.014 30.000\n\nQuesto metodo è efficace per distribuzioni simmetriche, ma potrebbe non funzionare bene con dati asimmetrici.\n\n23.2.2.2 Median Absolute Deviation (MAD)\nUn metodo più robusto rispetto all’IQR è il Median Absolute Deviation (MAD), che utilizza la mediana anziché la media per stimare la dispersione:\n\nmad_value &lt;- mad(data$value)\nthreshold &lt;- 3 * mad_value # Soglia classica per gli outlier\n\noutliers_mad &lt;- data$value[abs(data$value - median(data$value)) &gt; threshold]\noutliers_mad\n#&gt; [1]  4.014 30.000\n\nIl MAD è meno sensibile agli outlier rispetto alla deviazione standard ed è spesso preferito per dati con distribuzioni non normali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#outlier-multivariati",
    "href": "chapters/eda/11_outlier.html#outlier-multivariati",
    "title": "23  Outlier",
    "section": "\n23.3 Outlier Multivariati",
    "text": "23.3 Outlier Multivariati\nQuando si considerano più variabili contemporaneamente, un valore potrebbe non apparire anomalo su una singola variabile, ma esserlo nel contesto dell’intero dataset. Un metodo comune per individuare questi outlier è la Distanza di Mahalanobis, che tiene conto delle correlazioni tra variabili.\nPer comprendere intuitivamente la distanza di Mahalanobis, immaginate di avere una nube di punti che rappresentano individui, ciascuno con i propri valori di altezza e peso. Il “centro” di questa nube è un punto ideale che rappresenta una sorta di media multivariata (tenendo conto sia dell’altezza sia del peso). La distanza di Mahalanobis misura quanto ogni singolo individuo si allontana da questo centro, considerando la variabilità congiunta delle variabili (ad esempio, la correlazione tra altezza e peso). Se un individuo presenta caratteristiche molto diverse rispetto alla maggioranza, la sua distanza di Mahalanobis sarà elevata, segnalando un potenziale outlier.\n\n\n\n\n\nFigura 23.1: Soglie per la detezione degli outliers nel caso di una metrica unidimensionale (pannello di sinistra) e nel caso di una rappresentazione multivariata della varianza (pannello di destra) – figura creata da Sergen Cansiz.\n\n\nEsempio in R:\n\nX &lt;- as.matrix(mtcars[, c(\"mpg\", \"hp\")])\ncenter &lt;- colMeans(X)\ncov_matrix &lt;- cov(X)\nmahal_dist &lt;- mahalanobis(X, center, cov_matrix)\n\nthreshold &lt;- qchisq(0.975, df = ncol(X)) # Soglia al 97.5%\noutliers_mahal &lt;- X[mahal_dist &gt; threshold, ]\noutliers_mahal\n#&gt; mpg  hp \n#&gt;  15 335\n\nQuesto metodo è utile per dataset con più variabili correlate, come misure biometriche (altezza e peso).\nTuttavia, la versione classica di questa misura non è particolarmente robusta: la presenza stessa di outlier può distorcere il calcolo del “centro” e della variabilità complessiva, rendendo meno affidabile l’individuazione di altri valori anomali. Per questo motivo, si preferisce utilizzare una variante più resistente, la Minimum Covariance Determinant (MCD), che diminuisce l’influenza degli outlier stessi nel processo di identificazione.\nAll’interno del pacchetto {performance} in R, è possibile applicare questa variante robusta utilizzando la funzione check_outliers() con l’argomento method = \"mcd\". In questo modo, è possibile individuare gli outlier multivariati in maniera più solida e coerente, anche quando si lavora con dati fortemente influenzati da valori estremi.\n\nd &lt;- mtcars[, c(\"mpg\", \"hp\")]\noutliers &lt;- performance::check_outliers(d, method = \"mcd\", verbose = FALSE)\noutliers\n#&gt; 2 outliers detected: cases 20, 31.\n#&gt; - Based on the following method and threshold: mcd (13.816).\n#&gt; - For variables: mpg, hp.\n\nSi possono poi visualizzare questi outlier:\n\nplot(outliers)\n\n\n\n\n\n\n\nSono disponibili anche altre varianti multivariate documentate nella help page della funzione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#cosa-fare-con-gli-outlier",
    "href": "chapters/eda/11_outlier.html#cosa-fare-con-gli-outlier",
    "title": "23  Outlier",
    "section": "\n23.4 Cosa Fare con gli Outlier?",
    "text": "23.4 Cosa Fare con gli Outlier?\nUna volta identificati gli outlier, dobbiamo decidere se rimuoverli, correggerli o mantenerli (Leys et al., 2019). Alcuni approcci comuni includono:\n\n\nVerificare la fonte del dato: un errore di inserimento può essere corretto.\n\nRimuovere gli outlier estremi: utile se il valore è chiaramente un errore di misura.\n\nUsare metodi robusti: strumenti come la mediana o il MAD sono meno influenzati dagli outlier.\n\nTrasformare i dati: applicare logaritmi o altre trasformazioni può ridurre l’impatto degli outlier.\n\nWinsorizzazione: invece di rimuovere gli outlier, possiamo limitarli a un massimo accettabile.\n\nNel pacchetto easystats, la funzione winsorize() di {datawizard} semplifica il compito di Winsorizzazione:\nwinsorized_data &lt;- \n  winsorize(data$value, method = \"zscore\", robust = TRUE, threshold = 3)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#importanza-della-trasparenza",
    "href": "chapters/eda/11_outlier.html#importanza-della-trasparenza",
    "title": "23  Outlier",
    "section": "\n23.5 Importanza della Trasparenza",
    "text": "23.5 Importanza della Trasparenza\nQualunque decisione va documentata chiaramente: quanti outlier sono stati individuati, con quale metodo, a quale threshold, come sono stati gestiti, e preferibilmente con il codice R utilizzato. La preregistrazione e la condivisione dei dati e del codice (ad es. su OSF) sono pratiche consigliate per garantire riproducibilità e trasparenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#riflessioni-conclusive",
    "href": "chapters/eda/11_outlier.html#riflessioni-conclusive",
    "title": "23  Outlier",
    "section": "\n23.6 Riflessioni Conclusive",
    "text": "23.6 Riflessioni Conclusive\nAbbiamo mostrato come identificare gli outlier in modo coerente e trasparente, allineandoci alle buone pratiche correnti. Tuttavia, la buona pratica non si limita alla scelta degli algoritmi: è fondamentale anche preregistrare le decisioni, essere coerenti, trasparenti e fornire giustificazioni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#esercizi",
    "href": "chapters/eda/11_outlier.html#esercizi",
    "title": "23  Outlier",
    "section": "\n23.7 Esercizi",
    "text": "23.7 Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nDomande teoriche\n\nCos’è un outlier?\nPerché è importante identificare e trattare correttamente gli outlier?\nDescrivi brevemente il metodo del boxplot per identificare gli outlier.\nCosa si intende per Interquartile Range (IQR) e come viene utilizzato per individuare gli outlier?\nQual è la differenza tra il metodo IQR e il Median Absolute Deviation (MAD) per l’identificazione degli outlier?\nCos’è la distanza di Mahalanobis e in che modo può aiutare nell’identificazione degli outlier multivariati?\nPerché la distanza di Mahalanobis classica potrebbe non essere robusta? Come si può migliorare l’approccio?\nQuali sono le opzioni per gestire gli outlier una volta identificati?\nCos’è la Winsorizzazione e in quali casi potrebbe essere utile?\nPerché è importante la trasparenza nelle decisioni riguardanti gli outlier?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\n\nCos’è un outlier?\n\nUn outlier è un’osservazione che si discosta significativamente dalla maggior parte delle altre osservazioni in un insieme di dati. Può essere dovuto ad errori di misura, errori di inserimento dati o a casi estremi ma validi.\n\n\n\nPerché è importante identificare e trattare correttamente gli outlier?\n\nGli outlier possono distorcere i risultati dell’analisi statistica, portando a conclusioni errate. Identificarli e trattarli correttamente aiuta a ridurre l’effetto di questi valori anomali sulle statistiche descrittive e sulle inferenze statistiche.\n\n\n\nDescrivi brevemente il metodo del boxplot per identificare gli outlier.\n\nIl boxplot visualizza la distribuzione di una variabile, mostrando la mediana, il primo e il terzo quartile, e due estremi (“whiskers”). I punti al di fuori di questi whiskers sono considerati potenziali outlier.\n\n\n\nCosa si intende per Interquartile Range (IQR) e come viene utilizzato per individuare gli outlier?\n\nL’IQR è la differenza tra il terzo e il primo quartile di un insieme di dati. Valori inferiori a \\(Q1 - 1.5 \\times IQR\\) o superiori a \\(Q3 + 1.5 \\times IQR\\) sono considerati outlier moderati. Valori oltre \\(Q1 - 3 \\times IQR\\) o \\(Q3 + 3 \\times IQR\\) sono definiti “far out” outliers.\n\n\n\nQual è la differenza tra il metodo IQR e il Median Absolute Deviation (MAD) per l’identificazione degli outlier?\n\nIl metodo IQR si basa sulla differenza tra il terzo e il primo quartile, mentre il MAD utilizza la mediana delle deviazioni assolute dalla mediana per stimare la dispersione. Il MAD è meno sensibile agli outlier rispetto all’IQR e alla deviazione standard, rendendolo preferibile per dati con distribuzioni non normali.\n\n\n\nCos’è la distanza di Mahalanobis e in che modo può aiutare nell’identificazione degli outlier multivariati?\n\nLa distanza di Mahalanobis misura quanto un punto si discosta dal centro della distribuzione di un set di dati multivariato, tenendo conto della correlazione tra le variabili. Valori con distanze di Mahalanobis elevate sono potenziali outlier multivariati.\n\n\n\nPerché la distanza di Mahalanobis classica potrebbe non essere robusta? Come si può migliorare l’approccio?\n\nLa distanza di Mahalanobis classica può essere distorta dalla presenza di outlier, che influenzano il calcolo del centro e della variabilità complessiva. Un approccio più robusto è la Minimum Covariance Determinant (MCD), che riduce l’influenza degli outlier nel processo di identificazione.\n\n\n\nQuali sono le opzioni per gestire gli outlier una volta identificati?\n\nLe opzioni includono: verificare la fonte del dato per possibili errori, rimuovere gli outlier estremi, usare metodi robusti come la mediana o il MAD, trasformare i dati (ad esempio, logaritmi), e limitare gli outlier attraverso la Winsorizzazione.\n\n\n\nCos’è la Winsorizzazione e in quali casi potrebbe essere utile?\n\nLa Winsorizzazione è una tecnica che consiste nel sostituire gli outlier estremi con il valore massimo o minimo accettabile. È utile quando si vuole mantenere la dimensione del dataset e ridurre l’impatto degli outlier senza rimuoverli completamente.\n\n\nPerché è importante la trasparenza nelle decisioni riguardanti gli outlier?\n\n\nLa trasparenza aiuta a garantire la riproducibilità e la validità dell’analisi. Documentare le decisioni, inclusi i metodi e i threshold utilizzati, consente ad altri di capire e valutare l’impatto di queste decisioni sui risultati dell’analisi.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio: Gestione degli Outlier nella Scala di Soddisfazione di Vita (SWLS)\nScopo:\nImparare a individuare e correggere gli outlier in un dataset che misura la soddisfazione di vita (SWLS). L’esercizio prevede l’inserimento artificiale di due outlier (uno molto alto e uno molto basso) nei dati raccolti, per poi gestirli con i metodi discussi nel capitolo. Infine, bisognerà consegnare:\n\nUn file .qmd (Quarto) con tutto il codice e i commenti delle operazioni svolte.\n\nUn file CSV finale con i dati “puliti” (ossia senza i due outlier anomali) o con i valori modificati mediante il metodo scelto (winsorizzazione, rimozione, correzione, ecc.).\n\nFasi e Istruzioni\n\n\nScarica o carica il dataset SWLS\n\nNominare il dataset originale, ad esempio SWLS_raw.csv, contenente i punteggi dei partecipanti sulla Scala di Soddisfazione di Vita (SWLS).\n\nAssicurati di avere nel dataset almeno le colonne:\n\n\nid (identificatore univoco del partecipante)\n\n\nswls_score (punteggio totale alla scala SWLS)\n\n\n\n\n\nCrea due outlier artificiali\n\nScegli un partecipante al quale assegnare un valore estremamente basso di swls_score (es. -999) e un altro partecipante con un valore estremamente alto (es. 999).\n\nSpiega brevemente nel .qmd dove e come hai inserito questi valori.\n\n\n\nAnalizza i dati alla ricerca di outlier\n\nVisualizza la distribuzione tramite un boxplot e/o un istogramma.\n\nCalcola i valori soglia utilizzando almeno uno dei metodi visti:\n\nIQR (intervallo interquartile)\n\nMAD (Median Absolute Deviation)\n\n\n\nMostra quali osservazioni vengono segnalate come potenziali outlier.\n\n\n\nDecidi come gestire gli outlier\n\nScegli se rimuoverli, winsorizzarli o correggerli.\n\nGiustifica la tua scelta: spiega perché quel metodo è appropriato per questi dati o perché preferisci un approccio rispetto a un altro.\n\n\n\nGenera i dati “puliti”\n\nApplica il metodo selezionato.\n\nSalva il dataset risultante (senza i valori anomali o con i valori modificati) in un file CSV chiamato SWLS_clean.csv.\n\n\n\nDocumenta tutto in un file .qmd\n\nIncludi codice R, commenti e brevi spiegazioni testuali dei vari passaggi.\n\nMostra i risultati rilevanti (boxplot, calcolo dei soglie IQR/MAD, elenco degli outlier individuati, ecc.).\n\nAssicurati di eseguire il rendering del .qmd in modo che l’istruttore possa vedere sia l’output che il codice.\n\n\n\nConsegnare i file\n\n\nFile .qmd: deve contenere tutto il codice e i passaggi effettuati (inclusi grafici, calcoli e spiegazioni).\n\n\nFile CSV “pulito” (SWLS_clean.csv): con i dati finali dopo il trattamento degli outlier.\n\n\n\nSuggerimenti\n\n\nStruttura il tuo .qmd in sezioni (ad es. Caricamento dati, Creazione outlier artificiali, Identificazione outlier, Gestione outlier, Salvataggio dati puliti).\n\n\nMotiva sempre le scelte, soprattutto se rimuovi o modifichi i dati originali: spiega perché il valore appare come un errore di misura o un valore estremo.\n\n\nFai controlli incrociati: potresti usare più di un metodo (boxplot, IQR, MAD) per vedere se l’outlier viene segnalato in tutti i casi.\n\n\nDocumenta la tua strategia di trasparenza nell’analisi: note sull’eventuale preregistrazione di come avresti gestito gli outlier o su come hai deciso i threshold.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/11_outlier.html#informazioni-sullambiente-di-sviluppo",
    "title": "23  Outlier",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-64        datawizard_1.0.0   performance_0.13.0\n#&gt;  [4] thematic_0.1.6     MetBrewer_0.2.0    ggokabeito_0.1.0  \n#&gt;  [7] see_0.10.0         gridExtra_2.3      patchwork_1.3.0   \n#&gt; [10] bayesplot_1.11.1   psych_2.4.12       scales_1.3.0      \n#&gt; [13] markdown_1.13      knitr_1.49         lubridate_1.9.4   \n#&gt; [16] forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n#&gt; [19] purrr_1.0.4        readr_2.1.5        tidyr_1.3.1       \n#&gt; [22] tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0   \n#&gt; [25] rio_1.2.3          here_1.0.1        \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] viridisLite_0.4.2 mnormt_2.1.1      cli_3.6.4         rlang_1.1.5      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 insight_1.0.2    \n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      glue_1.8.0       \n#&gt; [33] xfun_0.50         tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29   \n#&gt; [41] compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#bibliografia",
    "href": "chapters/eda/11_outlier.html#bibliografia",
    "title": "23  Outlier",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLeys, C., Delacre, M., Mora, Y. L., Lakens, D., & Ley, C. (2019). How to classify, detect, and manage univariate and multivariate outliers, with emphasis on pre-registration. International Review of Social Psychology, 32(1).\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nThériault, R., Ben-Shachar, M. S., Patil, I., Lüdecke, D., Wiernik, B. M., & Makowski, D. (2024). Check your outliers! An introduction to identifying statistical outliers in R with easystats. Behavior Research Methods, 56(4), 4162–4172.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/probability/introduction_probability.html",
    "href": "chapters/probability/introduction_probability.html",
    "title": "Probabilità",
    "section": "",
    "text": "Questa sezione della dispensa introduce la teoria della probabilità, una componente essenziale per la ricerca scientifica. Nell’ambito della scienza, l’inferenza induttiva è di fondamentale importanza, e la probabilità svolge un ruolo cruciale in questo processo. Sebbene non possiamo ottenere una certezza assoluta riguardo alla veridicità di un’ipotesi o teoria, possiamo assegnare loro un grado di certezza probabilistica. L’approccio bayesiano utilizza la probabilità per quantificare il grado di fiducia che possiamo attribuire a una determinata proposizione.\nL’inferenza statistica bayesiana mira a quantificare la fiducia nell’ipotesi \\(H\\) dopo aver osservato un dato di evidenza \\(O\\). Per affrontare adeguatamente l’inferenza statistica bayesiana, è quindi essenziale avere una solida comprensione della teoria delle probabilità, almeno nei suoi concetti fondamentali.\nIn questa sezione esamineremo le definizioni di probabilità, la probabilità condizionale e il teorema di Bayes. Approfondiremo inoltre le proprietà delle variabili casuali e le principali distribuzioni di massa e densità di probabilità. Concluderemo presentando la funzione di verosimiglianza, un concetto fondamentale sia nell’inferenza bayesiana sia nell’inferenza frequentista.",
    "crumbs": [
      "Probabilità"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html",
    "href": "chapters/probability/01_intro_prob.html",
    "title": "24  Interpretazione della probabilità",
    "section": "",
    "text": "24.1 Introduzione\nNel corso di questo capitolo, esploreremo varie concezioni della probabilità, tra cui la visione classica, frequentista e bayesiana. Inoltre, introdurremo la simulazione con R per una migliore comprensione della legge dei grandi numeri, un concetto fondamentale nell’ambito della probabilità. Iniziamo introducendo il concetto di causalità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#il-concetto-di-casualità-e-la-teoria-della-probabilità",
    "href": "chapters/probability/01_intro_prob.html#il-concetto-di-casualità-e-la-teoria-della-probabilità",
    "title": "24  Interpretazione della probabilità",
    "section": "\n24.2 Il Concetto di Casualità e la Teoria della Probabilità",
    "text": "24.2 Il Concetto di Casualità e la Teoria della Probabilità\nDavid Spiegelhalter, in un recente articolo pubblicato su Nature, introduce il concetto di probabilità partendo dall’idea di incertezza:\n\nLife is uncertain. None of us know what is going to happen. We know little of what has happened in the past, or is happening now outside our immediate experience. Uncertainty has been called the ‘conscious awareness of ignorance’ — be it of the weather tomorrow, the next Premier League champions, the climate in 2100 or the identity of our ancient ancestors (Spiegelhalter, 2024).\n\nL’incertezza può essere interpretata come una manifestazione della casualità, che non rappresenta solo un fenomeno, ma anche un modello concettuale utile per affrontare l’imprevedibilità della realtà. Attraverso il concetto di casualità, è possibile gestire e quantificare eventi che, pur essendo imprevedibili singolarmente, seguono schemi regolari e riconoscibili. Questo rende la casualità uno strumento cruciale per comprendere il mondo e prendere decisioni.\n\nAttempts to put numbers on chance and uncertainty take us into the mathematical realm of probability, which today is used confidently in any number of fields (Spiegelhalter, 2024).\n\nLa teoria della probabilità offre una risposta matematica all’incertezza, permettendo di esprimere in termini numerici il grado di possibilità associato a un evento. Grazie a questa formalizzazione, possiamo modellare fenomeni complessi e applicare il concetto di probabilità in ambiti che spaziano dalla ricerca scientifica alla vita quotidiana.\n\n24.2.1 L’Urna come Modello della Casualità\nUno degli esempi più classici per rappresentare la casualità è il modello dell’urna. Immaginiamo un’urna contenente palline identiche, ciascuna numerata in modo univoco. Se ogni pallina ha la stessa probabilità di essere estratta, l’estrazione è considerata casuale. Sebbene non possiamo prevedere quale pallina verrà estratta, sappiamo che tutte hanno uguali possibilità di essere selezionate.\nQuesto modello, nella sua semplicità, incarna l’essenza della casualità. La sua applicazione non si limita all’estrazione di palline, ma si estende a scenari più complessi. Ad esempio, il modello dell’urna rappresenta un concetto di base utilizzato per comprendere processi che si ritrovano in statistica, scienze naturali e psicologia.\n\n24.2.1.1 Applicazioni del Modello della Casualità\n\nIndagini statistiche: Il campionamento casuale è essenziale per ottenere campioni rappresentativi di una popolazione più ampia, riducendo il rischio di bias di selezione e aumentando la generalizzabilità delle conclusioni.\nSperimentazione scientifica: La randomizzazione è uno strumento fondamentale per controllare le variabili confondenti, consentendo di attribuire le differenze osservate tra gruppi al trattamento, minimizzando l’influenza di fattori esterni.\n\n\nOpen any science journal, for example, and you’ll find papers liberally sprinkled with P values, confidence intervals and possibly Bayesian posterior distributions, all of which are dependent on probability (Spiegelhalter, 2024).\n\n\n\nSimulazioni: In fisica, psicologia e altre discipline, le simulazioni basate sulla casualità permettono di analizzare sistemi complessi e formulare previsioni, offrendo strumenti indispensabili per la ricerca scientifica.\n\nIl modello dell’urna, sebbene semplice, costituisce un pilastro per comprendere e applicare il concetto di casualità in una vasta gamma di contesti.\n\n24.2.2 Dalla Casualità alla Teoria della Probabilità\nLa teoria della probabilità si sviluppa a partire dal concetto di casualità, fornendo strumenti matematici per analizzare e quantificare rigorosamente l’incertezza. Questo approccio consente di tradurre intuizioni intuitive in un linguaggio formale e preciso, attraverso cui è possibile:\n\nQuantificare l’incertezza: Assegnare valori numerici agli esiti possibili permette di esprimere in modo preciso la probabilità di ciascun evento.\nCombinare informazioni: Utilizzando regole come la somma e il prodotto delle probabilità, possiamo calcolare la probabilità di eventi complessi partendo da eventi più semplici.\nAggiornare le credenze: La teoria della probabilità, in particolare nella sua formulazione bayesiana, offre metodi per aggiornare le stime di probabilità alla luce di nuove informazioni.\nPrendere decisioni informate: Valutando rischi e benefici attesi, la probabilità guida scelte razionali in condizioni di incertezza.\n\nIn sintesi, casualità e probabilità rappresentano strumenti essenziali per affrontare fenomeni non deterministici caratterizzati dall’imprevedibilità.\n\n24.2.3 L’Incertezza nei Fenomeni Non Deterministici\nL’incertezza, caratteristica fondamentale dei fenomeni non deterministici, può essere ricondotta a due principali fonti:\n\nIncertezza epistemica\nQuesta forma di incertezza deriva dalla nostra conoscenza limitata o incompleta. Ad esempio, in un esperimento scientifico complesso, l’impossibilità di controllare o osservare tutte le variabili coinvolte può introdurre incertezza nei risultati. In questi casi, l’incertezza non è una proprietà intrinseca del fenomeno studiato, ma riflette i limiti della nostra capacità di misurare, modellare o comprendere pienamente la realtà.\nIncertezza ontologica\nQuesta forma di incertezza è intrinseca al fenomeno stesso, indipendentemente dal livello di conoscenza o controllo che possiamo esercitare. Ad esempio, in fisica quantistica, il principio di indeterminazione di Heisenberg ci ricorda che l’indeterminazione è una caratteristica fondamentale della realtà fisica. Un esempio intuitivo è il lancio di un dado: anche se conoscessimo tutte le condizioni iniziali (forza applicata, angolo di lancio, ecc.), non potremmo mai prevedere con assoluta certezza il risultato finale, poiché il sistema stesso è intrinsecamente casuale.\n\nIl fisico danese Niels Bohr ha espresso una visione illuminante su questo tema: secondo Bohr, l’obiettivo della fisica non è tanto quello di rivelare una verità assoluta sulla natura, quanto piuttosto di comprendere ciò che possiamo dire su di essa. Questa prospettiva mette in luce il fatto che l’incertezza, sia epistemica che ontologica, rappresenta i limiti del nostro linguaggio, dei nostri strumenti di misura e delle nostre conoscenze.\n\n24.2.4 Probabilità e Interpretazione Soggettiva\nQuesto approccio si allinea bene con l’interpretazione soggettiva della probabilità. Secondo questa visione, la probabilità non è una proprietà oggettiva degli eventi, ma rappresenta il grado di fiducia o convinzione di un individuo riguardo al verificarsi di un evento, sulla base delle informazioni di cui dispone. Ad esempio, stimare che ci sia il 70% di probabilità che piova domani riflette non una certezza oggettiva, ma il livello di confidenza che attribuiamo a tale previsione, considerati i dati disponibili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#la-storia-della-probabilità",
    "href": "chapters/probability/01_intro_prob.html#la-storia-della-probabilità",
    "title": "24  Interpretazione della probabilità",
    "section": "\n24.3 La Storia della Probabilità",
    "text": "24.3 La Storia della Probabilità\n\n24.3.1 La Dualità della Probabilità\nCome sottolinea Hacking (2006), il concetto di probabilità si sviluppa attorno a due principali dimensioni:\n\nEpistemologico: La probabilità come misura della credibilità o plausibilità di una proposizione, basata sulle evidenze disponibili. In questa accezione, la probabilità è uno strumento per quantificare la nostra conoscenza e per ragionare in condizioni di incertezza.\nFrequenziale: La probabilità come tendenza osservabile nei fenomeni aleatori, in cui frequenze relative stabili emergono nel lungo termine. Questo approccio descrive la probabilità come un fenomeno naturale oggettivo, osservabile attraverso esperimenti ripetuti.\n\nQuesta dualità — probabilità come misura della conoscenza e probabilità come proprietà del mondo naturale — è stata formalizzata solo a partire dal XVII secolo, grazie al lavoro pionieristico di Blaise Pascal e Pierre de Fermat.\n\n24.3.2 Le Origini della Probabilità Moderna\nIl gioco d’azzardo, una pratica antica e universale, ha rappresentato per secoli uno dei pochi ambiti in cui venivano esplorati concetti rudimentali di probabilità. Resti di dadi e altri strumenti di gioco sono stati rinvenuti in siti sumeri, assiri ed egizi, a testimonianza di una lunga tradizione di interazione con l’alea. Tuttavia, fu solo nel 1654 che il matematico Antoine Gombaud, conosciuto come Chevalier de Méré, sollevò una questione che portò allo sviluppo della probabilità moderna.\nL’aneddoto più celebre riguarda la sua domanda a Blaise Pascal:\n\nDue giocatori, A e B, stanno partecipando a un gioco in cui il primo a vincere sei round consecutivi ottiene il premio. Dopo sei round, A ha vinto cinque round e B uno. Poiché il gioco viene interrotto, come si dovrebbe dividere il premio in modo equo?\n\nQuesto problema spinse Pascal e Fermat a sviluppare i primi strumenti matematici per calcolare la probabilità degli eventi futuri, dando vita a un metodo rigoroso per affrontare l’incertezza. Stimando, ad esempio, che A avesse il 97% di probabilità di vincere e B il 3%, sembrava equo dividere il premio nella stessa proporzione.\nLa soluzione di questo problema ispirò Christian Huygens, che nel 1657 pubblicò il trattato De Ratiociniis in Ludo Aleae. Quest’opera, fondamentale per lo studio della probabilità, rimase il riferimento principale per almeno cinquant’anni.\n\n24.3.3 Contributi Successivi\nParallelamente, altri studiosi iniziarono a sviluppare idee legate ai due aspetti della probabilità:\n\n\nChristian Huygens: concentrò il suo lavoro su problemi legati al gioco d’azzardo e alla casualità.\n\n\nLeibniz: esplorò la probabilità come misura epistemologica, applicandola alla logica e al diritto.\n\n\nJohn Graunt (1662): studiò le frequenze stabili nella demografia, introducendo concetti proto-statistici legati alla probabilità frequenziale.\n\n\nAntoine Arnauld e il gruppo di Port-Royal: approfondirono la probabilità come strumento per valutare la credibilità e il ragionamento.\n\nNel 1713, Jacob Bernoulli pubblicò postumo L’Arte della Congettura, introducendo la legge dei grandi numeri. Quest’opera formalizzò il legame tra la probabilità epistemologica e quella frequenziale, ampliandone le applicazioni a contesti quali la mortalità, la giustizia penale e le decisioni economiche.\n\n24.3.4 La Dualità nella Filosofia della Probabilità\nLa dualità intrinseca del concetto di probabilità non è solo una questione terminologica o tecnica, ma riflette due prospettive fondamentali sul modo in cui interpretiamo e modelliamo l’incertezza.\nDa un lato, la probabilità epistemologica si focalizza su ciò che sappiamo o possiamo sapere, descrivendo il grado di fiducia o credibilità di una proposizione data l’evidenza disponibile. Dall’altro, la probabilità frequenziale cerca di catturare l’aleatorietà intrinseca del mondo naturale, identificando schemi ricorrenti e frequenze stabili nei fenomeni osservati.\nQuesta dualità emerge chiaramente anche nel dibattito filosofico che ha coinvolto figure come Poisson, Cournot, Carnap e altri. Ad esempio, distinguendo tra “chance” e “probabilità”, Poisson e Cournot hanno sottolineato come la probabilità possa essere usata sia per descrivere eventi aleatori oggettivi sia per quantificare il grado di conoscenza soggettiva su tali eventi.\nNella seconda metà del XX secolo, i filosofi della scienza come Carnap hanno approfondito ulteriormente questa distinzione, proponendo un modello duale di probabilità:\n\n\nProbabilità induttiva: un modo per ragionare su ipotesi ed evidenze, essenzialmente epistemologico.\n\n\nProbabilità statistica: uno strumento per descrivere i fenomeni aleatori, principalmente frequenziale.\n\nLa tensione tra questi due approcci ha portato allo sviluppo di teorie e metodi distinti, spesso con implicazioni pratiche e metodologiche profondamente diverse.\n\n24.3.5 La Dualità Riflessa nei Metodi Bayesiani e Frequentisti\nLa distinzione tra probabilità epistemologica e frequenziale si riflette chiaramente nei due principali paradigmi della statistica moderna: l’approccio bayesiano e quello frequentista.\n\n24.3.5.1 Approccio Bayesiano\nL’approccio bayesiano, basato su principi epistemologici, considera la probabilità come una misura soggettiva del grado di fiducia o convinzione. Attraverso il teorema di Bayes, le stime di probabilità vengono aggiornate in modo iterativo, integrando nuove informazioni con le conoscenze preesistenti (probabilità a priori). Questo approccio permette di modellare l’incertezza in modo dinamico e flessibile, rendendolo particolarmente utile in contesti in cui i dati sono limitati o l’incertezza è complessa.\nAd esempio, in psicologia, un terapeuta potrebbe iniziare con una probabilità a priori basata sulla propria esperienza clinica riguardo alla probabilità che un paziente soffra di un determinato disturbo (ad esempio, disturbo d’ansia). Man mano che il terapeuta raccoglie nuove informazioni durante le sessioni (ad esempio, osservazioni comportamentali o risposte a questionari), aggiorna la sua valutazione iniziale, calcolando una probabilità a posteriori più accurata. Questo processo riflette l’idea che la conoscenza si evolve con l’accumularsi di nuove evidenze.\n\n24.3.5.2 Approccio Frequentista\nL’approccio frequentista, invece, si concentra sull’aspetto oggettivo della probabilità, definendola come la frequenza relativa di un evento in una serie molto ampia (idealmente infinita) di prove ripetute. In questo contesto, la probabilità non è influenzata da credenze soggettive, ma è vista come una proprietà intrinseca del fenomeno studiato.\nUn esempio psicologico potrebbe essere la valutazione dell’efficacia di una terapia comportamentale per ridurre i sintomi di ansia. Un ricercatore frequentista potrebbe condurre uno studio sperimentale con un gran numero di partecipanti, misurando la frequenza con cui i sintomi migliorano nel gruppo che riceve la terapia rispetto a un gruppo di controllo. La probabilità di successo della terapia sarebbe quindi stimata esclusivamente in base ai risultati osservati, senza considerare ipotesi o convinzioni preliminari. Questo approccio è particolarmente utile in contesti sperimentali in cui è possibile ripetere le osservazioni sotto condizioni controllate.\n\n24.3.6 Differenze, Complementarità e Critiche\nGli approcci bayesiano e frequentista presentano differenze fondamentali, ma non devono essere necessariamente considerati in conflitto. In determinati contesti applicativi, possono persino essere visti come complementari:\n\n\nApproccio bayesiano: si distingue per la sua capacità di affrontare situazioni caratterizzate da elevata incertezza o dati limitati. Grazie all’integrazione esplicita di conoscenze pregresse mediante distribuzioni a priori, il paradigma bayesiano è particolarmente efficace nell’analisi di problemi complessi che richiedono un continuo aggiornamento delle stime alla luce di nuove evidenze.\n\n\nApproccio frequentista: offre strumenti consolidati e più semplici da applicare, risultando particolarmente adatto in situazioni in cui sono disponibili grandi quantità di dati indipendenti e si richiedono procedure standardizzate per l’inferenza statistica.\n\nTuttavia, entrambi gli approcci sono stati oggetto di critiche:\n\nCritiche all’approccio bayesiano:\nLa scelta delle distribuzioni a priori è stata spesso considerata un elemento soggettivo, che potrebbe influenzare i risultati dell’analisi. Tuttavia, questa critica ha perso parte della sua rilevanza con l’evoluzione dell’approccio bayesiano moderno, che fa ampio uso di prior debolmente informativi per ridurre l’impatto delle scelte iniziali e garantire inferenze più robuste. Un’altra critica riguarda la complessità computazionale. Nonostante i progressi tecnologici abbiano notevolmente ridotto i costi computazionali, l’approccio bayesiano può ancora rappresentare una sfida in contesti applicativi, specialmente quando si utilizzano modelli particolarmente sofisticati o grandi volumi di dati.\nCritiche all’approccio frequentista:\nL’inferenza frequentista è stata criticata per la sua forte dipendenza dal test dell’ipotesi nulla (NHST), un metodo spesso applicato in modo meccanico e senza un’adeguata contestualizzazione. Il NHST è stato identificato come uno dei fattori chiave alla base della crisi di replicabilità che ha interessato diverse discipline scientifiche, tra cui la psicologia. Inoltre, l’approccio frequentista mostra limiti nella gestione di modelli complessi o situazioni in cui le ipotesi fondamentali (ad esempio, l’indipendenza delle osservazioni o la normalità delle distribuzioni) non sono realistiche. Questa rigidità può rendere difficile l’applicazione in contesti reali, dove i dati spesso presentano strutture più articolate o violano le assunzioni di base.\n\nIn sintesi, mentre l’approccio bayesiano affronta sfide legate alla soggettività iniziale e alla complessità computazionale, l’approccio frequentista è criticato per la sua dipendenza da metodologie rigide e per la difficoltà di adattarsi a scenari complessi o non ideali.\nNegli ultimi anni, l’approccio bayesiano ha guadagnato una crescente popolarità, soprattutto per la sua capacità di affrontare modelli complessi e di fornire inferenze più flessibili rispetto alle procedure frequentiste. La forza del paradigma bayesiano risiede nella sua natura adattabile, che consente di incorporare conoscenze pregresse e di aggiornare continuamente le stime in base a nuove informazioni. Questo lo rende particolarmente utile in ambiti come l’intelligenza artificiale, la data science e la psicologia, dove l’analisi richiede spesso un’interpretazione dinamica e multidimensionale dell’incertezza.\nIn conclusione, sebbene l’approccio frequentista abbia costituito per decenni il pilastro dell’analisi statistica tradizionale, il paradigma bayesiano si è affermato come una soluzione più avanzata e flessibile, capace di rispondere alle esigenze della ricerca contemporanea. Questa evoluzione rappresenta non solo un progresso metodologico, ma anche un cambiamento culturale e scientifico, che richiede strumenti più solidi e versatili per affrontare la complessità intrinseca dei fenomeni oggetto di studio.\n\n24.3.7 Implicazioni Filosofiche e Pratiche\nLa dualità della probabilità, tra epistemologia e frequenza, riflette una tensione fondamentale nel pensiero scientifico e filosofico: il tentativo di bilanciare una descrizione oggettiva della realtà con la soggettività inevitabile del processo interpretativo. Questa tensione non è solo teorica, ma influenza profondamente il modo in cui i metodi statistici vengono applicati nei diversi ambiti del sapere.\nCon questo in mente, esploriamo ora come il concetto di probabilità si sia evoluto storicamente e come continui a influenzare il progresso scientifico.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#levoluzione-del-concetto-di-probabilità",
    "href": "chapters/probability/01_intro_prob.html#levoluzione-del-concetto-di-probabilità",
    "title": "24  Interpretazione della probabilità",
    "section": "\n24.4 L’Evoluzione del Concetto di Probabilità",
    "text": "24.4 L’Evoluzione del Concetto di Probabilità\nLa storia della probabilità offre un contesto ricco per comprendere le diverse interpretazioni e applicazioni del concetto di probabilità. Le definizioni classiche e frequentiste, sebbene centrali nello sviluppo iniziale della statistica, hanno rivelato limiti concettuali e pratici che hanno spinto verso approcci più generali e flessibili.\n\n24.4.1 Interpretazione Classica\nLa definizione classica di probabilità fu proposta da Pierre-Simon Laplace (1749-1827), che basò il concetto sul calcolo combinatorio. Secondo Laplace, la probabilità di un evento è data dal rapporto tra i casi favorevoli e il numero totale di casi possibili, assumendo che tutti siano equiprobabili. Ad esempio, la probabilità di ottenere un “3” lanciando un dado è \\(\\frac{1}{6}\\), poiché solo uno dei sei risultati è favorevole.\nQuesto approccio, pur utile per scenari semplici, è limitato dalla sua dipendenza da ipotesi spesso irrealistiche (es., l’assunzione che ogni evento sia equiprobabile) e da una formulazione implicitamente circolare (poiché presuppone una conoscenza implicita del concetto di probabilità).\n\n24.4.2 Interpretazione Frequentista\nPer superare tali limiti, il frequentismo definisce la probabilità come il limite della frequenza relativa con cui un evento si verifica in una serie infinita di prove. Per esempio, la probabilità di ottenere “testa” in un lancio di moneta può essere stimata come la frequenza relativa di “testa” sul totale dei lanci, quando il numero di lanci tende all’infinito. Questa definizione è utile, ma impraticabile in molte situazioni, poiché richiede un numero infinito di ripetizioni e assume che gli eventi futuri siano identici a quelli passati.\nLa figura seguente illustra la proporzione di risultati “testa” in una sequenza di lanci di una moneta equa. Si può osservare come la frequenza relativa dei risultati “testa” converga progressivamente verso il valore della probabilità teorica.\n\n\n\n\n\n\n\n\n\n24.4.2.1 La Legge dei Grandi Numeri\nUn pilastro fondamentale dell’approccio frequentista è la Legge dei Grandi Numeri (LLN, dall’inglese Law of Large Numbers), che garantisce la convergenza delle frequenze empiriche ai valori teorici al crescere del numero di osservazioni (per un approfondimento, si veda la Sezione 33.6). Questo principio è essenziale per comprendere come la variabilità casuale si riduca e come le stime empiriche diventino sempre più affidabili con l’aumentare della dimensione del campione. La LLN fornisce un ponte tra la teoria della probabilità e le applicazioni pratiche, dimostrando che, sotto condizioni appropriate, i dati osservati riflettono con precisione crescente le proprietà teoriche della popolazione.\nIn termini semplici, la Legge dei Grandi Numeri afferma che, all’aumentare del numero di prove, la media dei risultati osservati si avvicina progressivamente al valore atteso della variabile casuale. Anche se i risultati individuali possono variare in modo casuale, la media di un gran numero di osservazioni riflette con sempre maggiore precisione la probabilità teorica. Questo principio è alla base della validità delle stime empiriche e della loro affidabilità nel lungo periodo.\n\n24.4.2.2 Implicazioni della Legge dei Grandi Numeri\n\nAffidabilità delle stime empiriche:\nCon un numero sufficiente di osservazioni, le stime empiriche delle probabilità diventano sempre più precise e affidabili. Questo è particolarmente importante in contesti applicativi, dove la precisione delle stime è cruciale per prendere decisioni informate.\nValidità dei modelli probabilistici:\nLa LLN fornisce un fondamento teorico per l’uso di modelli probabilistici nella descrizione e previsione di fenomeni reali. Anche se le osservazioni singole possono essere imprevedibili, la media di un gran numero di osservazioni tende a stabilizzarsi attorno al valore teorico, rendendo possibile l’uso di modelli probabilistici per rappresentare la realtà.\nConvergenza delle medie campionarie:\nLa media di un gran numero di osservazioni converge al valore teorico della popolazione. Questo rende le medie campionarie strumenti affidabili per stimare la media della popolazione, purché il campione sia sufficientemente ampio.\n\n\nEsempio 24.1 Consideriamo il classico esempio del lancio di una moneta. Supponiamo che la probabilità teorica di ottenere testa sia \\(p\\) = 0.5. Quando effettuiamo un numero limitato di lanci, è possibile osservare una proporzione di teste che si discosta significativamente dal valore teorico di 0.5, a causa della variabilità intrinseca del fenomeno casuale. Tuttavia, aumentando progressivamente il numero di lanci, la Legge dei Grandi Numeri entra in gioco: la proporzione di teste osservate tenderà gradualmente a convergere verso il valore teorico di 0.5. Questo esempio illustra intuitivamente come le frequenze relative delle osservazioni si avvicinino alle probabilità teoriche al crescere del numero di prove, fornendo un fondamento empirico alla stessa legge.\n\n\n24.4.2.3 Limiti e Considerazioni\nSebbene la Legge dei Grandi Numeri sia un principio potente, è importante tenere presente alcune limitazioni:\n\nCampioni piccoli:\nIn presenza di un numero limitato di osservazioni, la variabilità casuale può ancora giocare un ruolo significativo, rendendo le stime empiriche meno affidabili. In questi casi, la media campionaria potrebbe non riflettere accuratamente il valore teorico.\nDati non rappresentativi:\nSe i dati non sono raccolti in modo appropriato o non sono rappresentativi della popolazione, la convergenza potrebbe non verificarsi come previsto. Ad esempio, un campione distorto o non casuale può portare a stime errate, indipendentemente dal numero di osservazioni.\n\nIn conclusione, la Legge dei Grandi Numeri è un risultato fondamentale che collega la teoria della probabilità alle applicazioni pratiche. Essa garantisce che, con un numero sufficientemente grande di osservazioni, le stime empiriche riflettano i valori teorici con elevata precisione. Questo principio non solo giustifica l’uso delle medie campionarie in statistica, ma fornisce anche una base teorica per l’inferenza statistica e la modellizzazione dei fenomeni reali. Tuttavia, è essenziale considerare l’incertezza residua nei casi di campioni piccoli o dati non rappresentativi, poiché la LLN non elimina completamente la variabilità intrinseca dei fenomeni casuali.\n\n24.4.2.4 Collegamento tra Probabilità e Statistica\nLa probabilità intesa come frequenza relativa costituisce il fondamento del framework teorico per l’inferenza statistica proposto durante gli anni ’20 del Novecento da Ronald A. Fisher. Fisher introdusse concetti chiave come la massima verosimiglianza, i test di significatività, i metodi di campionamento, l’analisi della varianza e il disegno sperimentale.\nFisher assunse una prospettiva critica nei confronti della “probabilità inversa” (ossia, i metodi bayesiani), nonostante questa fosse stata la metodologia predominante per l’inferenza statistica per quasi un secolo e mezzo. Il suo approccio frequentista ebbe un profondo impatto sullo sviluppo della statistica sia teorica che sperimentale, contribuendo a un decremento nell’utilizzo dell’inferenza basata sul metodo della probabilità inversa, originariamente proposto da Laplace.\nNegli anni ’30, Jerzy Neyman ed Egon Pearson fecero ulteriori progressi nel campo con lo sviluppo di una teoria della decisione statistica, basata sul principio della verosimiglianza e sull’interpretazione frequentista della probabilità. Definirono due tipologie di errori decisionali e utilizzarono il test di significatività di Fisher, interpretando i valori-\\(p\\) come indicatori dei tassi di errore a lungo termine.\n\n24.4.2.5 Limiti\nL’approccio frequentista è robusto in contesti ripetibili, ma si scontra con difficoltà concettuali e pratiche nell’analisi di eventi singolari e non ripetibili.\nAd esempio, la probabilità che un atleta vinca una specifica competizione, o che un determinato evento atmosferico si verifichi in un giorno particolare, non può essere rigorosamente quantificata dal punto di vista frequentista, in quanto il frequentismo richiede un esperimento ripetibile per definire la probabilità. Questo limite ha alimentato l’interesse verso l’approccio bayesiano, che consente di esprimere la probabilità come una misura soggettiva del grado di fiducia basato su informazioni disponibili.\n\n24.4.3 Interpretazione Bayesiana\nNel 1939, il libro di Jeffreys (1998) intitolato “Theory of Probability” rappresentò una delle prime esposizioni moderne dei metodi bayesiani. Tuttavia, la rinascita del framework bayesiano fu rinviata fino alla scoperta dei metodi Monte Carlo Markov chain alla fine degli anni ’80. Questi metodi hanno reso fattibile il calcolo di risultati precedentemente non ottenibili, consentendo un rinnovato interesse e sviluppo nei metodi bayesiani. Per una storia dell’approccio bayesiano, si veda Bayesian Methods: General Background oppure Philosophy of Statistics.\n\n24.4.3.1 Interpretazione Soggettivista della Probabilità\nBruno de Finetti sintetizzò l’essenza della probabilità bayesiana con l’affermazione provocatoria: “La probabilità non esiste”. Questo approccio concepisce la probabilità non come una proprietà intrinseca degli eventi, ma come una misura del grado di fiducia razionale basata su informazioni incomplete e soggette a revisione.\nLa definizione soggettivista, tuttavia, non implica arbitrarietà. Attraverso il teorema di Bayes, la probabilità soggettiva è costantemente aggiornata per incorporare nuove evidenze, garantendo coerenza logica e rigore matematico. Tale prospettiva rende la probabilità uno strumento dinamico e adattabile per descrivere l’incertezza.\nUn recente articolo su Nature ne ribadisce la rilevanza contemporanea, sottolineando l’essenza soggettiva della probabilità:\n\n[…] any numerical probability, I will argue — whether in a scientific paper, as part of weather forecasts, predicting the outcome of a sports competition or quantifying a health risk — is not an objective property of the world, but a construction based on personal or collective judgements and (often doubtful) assumptions. Furthermore, in most circumstances, it is not even estimating some underlying ‘true’ quantity. Probability, indeed, can only rarely be said to ‘exist’ at all (Spiegelhalter, 2024).\n\n\n24.4.3.2 Origini e Sviluppo della Prospettiva Soggettivista\nLe radici dell’interpretazione soggettivista risalgono al lavoro pionieristico di Frank P. Ramsey nel 1926, che definì la probabilità come il grado di credenza individuale (Ramsey, 1926). Questa concezione, inizialmente relegata a una posizione marginale, ha gettato le basi per un approccio profondamente innovativo alla teoria della probabilità.\nSuccessivamente, una rigorosa formalizzazione matematica degli assiomi della probabilità soggettiva è stata proposta da Fishburn (Fishburn, 1986), che ha fornito una struttura teorica robusta per il trattamento della probabilità come costruzione soggettiva. Approfondimenti metodologici e applicativi si trovano nei lavori di Press (Press, 2009), che hanno ampliato l’ambito di applicazione della prospettiva soggettivista, consolidandola come uno strumento essenziale per affrontare l’incertezza in ambito scientifico.\nQuesta interpretazione sposta il focus dalla realtà oggettiva alla costruzione umana della probabilità, enfatizzando il ruolo di giudizi, ipotesi e informazioni disponibili. La probabilità non è dunque una proprietà intrinseca del mondo, ma una misura del grado di fiducia razionale attribuito da un soggetto idealizzato.\n\n24.4.3.3 La Probabilità come Grado di Credenza Razionale\nSecondo l’interpretazione soggettivista bayesiana, la probabilità rappresenta una misura del grado di fiducia che un soggetto razionale assegna alla validità di un’affermazione, basandosi su informazioni disponibili, spesso incomplete. Questo concetto si applica non a un individuo specifico, ma a un’idealizzazione di razionalità: un agente che opera esclusivamente sulla base della logica e delle evidenze, privo di emozioni, pregiudizi o bias cognitivi.\nE.T. Jaynes, nel suo Probability Theory: The Logic of Science (Jaynes, 2003), propone un esperimento mentale che esemplifica questa concezione:\n\nSi immagini un robot razionale dotato di un insieme di informazioni \\(I\\), ritenute vere e complete.\nSi presenti un’affermazione \\(A\\), che nella realtà può essere solo vera o falsa.\nIl robot deve quantificare l’incertezza sulla validità di \\(A\\), basandosi esclusivamente sulle informazioni \\(I\\).\n\nIn questo contesto, la probabilità di \\(A\\) dato \\(I\\), espressa come \\(P(A \\mid I)\\), è definita secondo i seguenti principi fondamentali:\n\n\nIntervallo numerico: \\(P(A \\mid I)\\) è un numero reale compreso tra 0 e 1, dove:\n\n\n\\(P(A \\mid I) = 0\\) rappresenta la certezza che \\(A\\) sia falsa.\n\n\\(P(A \\mid I) = 1\\) rappresenta la certezza che \\(A\\) sia vera.\n\n\n\nCoerenza logica: La probabilità deve rispettare i postulati della teoria della probabilità, garantendo un quadro logico rigoroso e internamente consistente.\n\nIn conclusione, l’interpretazione soggettivista della probabilità rappresenta un cambio di paradigma, trasformando la probabilità da una proprietà oggettiva a uno strumento flessibile e razionale per affrontare l’incertezza. Essa fornisce un quadro teorico che combina rigore matematico e adattabilità pratica, rendendo la probabilità uno strumento essenziale per descrivere e modellare il mondo in presenza di informazioni incomplete.\n\n\n\n\n\n\nTerminologia\n\n\n\nIl termine probabilità soggettiva può suggerire una connotazione di imprecisione o mancanza di rigore scientifico. Per evitare tali fraintendimenti, sono state proposte alternative terminologiche:\n\n\nLindley (2013) suggerisce il termine probabilità personale, per enfatizzare l’aspetto individuale ma razionale di questa concezione.\n\nHowson & Urbach (2006) propone invece probabilità epistemica, evidenziando il legame con la conoscenza e l’incertezza derivanti da informazioni incomplete.\n\nQueste alternative, adottate da autori come Kaplan (2023), offrono una descrizione più neutrale, particolarmente utile nei contesti scientifici.\n\n\n\n\n\n\n\n\nPer chi desidera approfondire, il primo capitolo del testo Bernoulli’s Fallacy (Clayton, 2021) offre un’introduzione molto leggibile alle tematiche della definizione della probabilità nella storia della scienza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/01_intro_prob.html#riflessioni-conclusive",
    "title": "24  Interpretazione della probabilità",
    "section": "\n24.5 Riflessioni Conclusive",
    "text": "24.5 Riflessioni Conclusive\nIn questo capitolo è stata condotta un’analisi filosofica del concetto di probabilità, esplorandone le principali interpretazioni: da un lato, come proprietà intrinseca e oggettiva degli eventi, e dall’altro, come espressione di convinzioni soggettive in condizioni di incertezza. Questa duplice prospettiva ha messo in luce come la probabilità possa essere concepita sia come un elemento del mondo reale, sia come uno strumento epistemico per rappresentare il grado di fiducia razionale.\nInoltre, è stato approfondito il ruolo della simulazione come strumento metodologico essenziale per approssimare probabilità empiriche in contesti complessi, dove soluzioni analitiche risultano impraticabili. Questa tecnica si è dimostrata particolarmente rilevante nei campi di ricerca più avanzati, in cui la crescente complessità dei modelli matematici rende indispensabile l’utilizzo di algoritmi numerici sofisticati. La simulazione non solo amplia le possibilità di analisi, ma funge anche da ponte tra le teorie probabilistiche e le loro applicazioni pratiche.\nSulla base di queste premesse, i capitoli successivi saranno dedicati a un’analisi matematica della probabilità. Verranno esaminati i teoremi e le leggi fondamentali che costituiscono il nucleo formale della disciplina, evidenziando come tali strumenti possano estendere l’applicabilità del concetto di probabilità oltre le speculazioni teoriche, verso ambiti pratici. Questo approccio quantitativo fornirà un quadro più preciso e affidabile per quantificare e gestire l’incertezza, gettando le basi per una comprensione più completa e rigorosa delle dinamiche probabilistiche.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#esercizi",
    "href": "chapters/probability/01_intro_prob.html#esercizi",
    "title": "24  Interpretazione della probabilità",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQuali sono le principali concezioni della probabilità esplorate nel capitolo?\nCome viene definita l’incertezza secondo David Spiegelhalter?\nQual è il ruolo della casualità nella teoria della probabilità?\nCome funziona il modello dell’urna per rappresentare la casualità?\nQuali sono alcune applicazioni del modello della casualità?\nQuali sono le due principali fonti di incertezza nei fenomeni non deterministici?\nCome viene interpretata la probabilità secondo l’approccio soggettivista?\nQuali sono le due dimensioni principali del concetto di probabilità secondo Hacking?\nQual è stato il contributo di Pascal e Fermat alla teoria della probabilità?\nQuali sono le differenze tra l’approccio bayesiano e frequentista nella teoria della probabilità?\nQual è la Legge dei Grandi Numeri e come si applica?\nQuali sono i limiti dell’interpretazione frequentista della probabilità?\nCome ha influenzato Fisher lo sviluppo della statistica frequentista?\nQual è stato il ruolo di Jeffreys nella rinascita dell’approccio bayesiano?\nCome definisce Bruno de Finetti la probabilità?\nQuali sono i principi fondamentali della probabilità soggettivista secondo Jaynes?\nQuali sono le alternative terminologiche proposte per la “probabilità soggettiva”?\nQual è l’importanza della simulazione nella comprensione della probabilità?\nQuali sono le implicazioni filosofiche della dualità della probabilità?\nQuali sono i principali contributi storici alla teoria della probabilità?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nLe principali concezioni della probabilità esplorate nel capitolo sono la visione classica, frequentista e bayesiana.\nSecondo David Spiegelhalter, l’incertezza è definita come la “consapevolezza cosciente dell’ignoranza”, riguardante eventi futuri o passati che non possiamo conoscere con certezza.\nLa casualità è un modello concettuale che aiuta a gestire e quantificare eventi imprevedibili, ma che seguono schemi regolari e riconoscibili.\nIl modello dell’urna rappresenta la casualità attraverso l’estrazione di palline numerate da un’urna, dove ogni pallina ha la stessa probabilità di essere estratta.\nAlcune applicazioni del modello della casualità includono indagini statistiche, sperimentazione scientifica e simulazioni in fisica e psicologia.\nLe due principali fonti di incertezza sono l’incertezza epistemica (derivante dalla conoscenza limitata) e l’incertezza ontologica (intrinseca al fenomeno stesso).\nSecondo l’approccio soggettivista, la probabilità è una misura del grado di fiducia o convinzione di un individuo riguardo al verificarsi di un evento, basata sulle informazioni disponibili.\nSecondo Hacking, le due dimensioni principali del concetto di probabilità sono quella epistemologica (misura della credibilità) e quella frequenziale (tendenza osservabile nei fenomeni aleatori).\nPascal e Fermat hanno sviluppato i primi strumenti matematici per calcolare la probabilità degli eventi futuri, risolvendo problemi legati al gioco d’azzardo.\nL’approccio bayesiano considera la probabilità come una misura soggettiva del grado di fiducia, mentre l’approccio frequentista la definisce come la frequenza relativa di un evento in una serie infinita di prove.\nLa Legge dei Grandi Numeri afferma che al crescere del numero di prove, la media dei risultati osservati si avvicina al valore atteso teorico.\nI limiti dell’interpretazione frequentista includono la difficoltà di applicarla a eventi singolari e non ripetibili, e la necessità di un numero infinito di prove per definire la probabilità.\nFisher ha introdotto concetti chiave come la massima verosimiglianza, i test di significatività e l’analisi della varianza, contribuendo allo sviluppo della statistica frequentista.\nJeffreys ha contribuito alla rinascita dell’approccio bayesiano con il suo libro “Theory of Probability”, che ha riportato l’attenzione sui metodi bayesiani.\nBruno de Finetti definisce la probabilità come una misura del grado di fiducia razionale basata su informazioni incomplete, affermando che “la probabilità non esiste” come proprietà oggettiva.\nSecondo Jaynes, i principi fondamentali della probabilità soggettivista includono l’intervallo numerico (0-1) e la coerenza logica, basandosi su informazioni disponibili.\nLe alternative terminologiche proposte per la “probabilità soggettiva” includono “probabilità personale” e “probabilità epistemica”.\nLa simulazione è importante per approssimare probabilità empiriche in contesti complessi, dove soluzioni analitiche non sono praticabili, e per comprendere fenomeni probabilistici attraverso modelli numerici.\nLe implicazioni filosofiche della dualità della probabilità riflettono la tensione tra una descrizione oggettiva della realtà e la soggettività del processo interpretativo.\nI principali contributi storici alla teoria della probabilità includono i lavori di Pascal, Fermat, Huygens, Bernoulli, Fisher, Jeffreys e de Finetti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#bibliografia",
    "href": "chapters/probability/01_intro_prob.html#bibliografia",
    "title": "24  Interpretazione della probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nClayton, A. (2021). Bernoulli’s Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press.\n\n\nFishburn, P. C. (1986). The axioms of subjective probability. Statistical Science, 1(3), 335–345.\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nHowson, C., & Urbach, P. (2006). Scientific reasoning: the Bayesian approach. Open Court Publishing.\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.\n\n\nJeffreys, H. (1998). The theory of probability. OuP Oxford.\n\n\nKaplan, D. (2023). Bayesian statistics for the social sciences. Guilford Publications.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.\n\n\nPress, S. J. (2009). Subjective and objective Bayesian statistics: Principles, models, and applications. John Wiley & Sons.\n\n\nRamsey, F. P. (1926). Truth and probability. In Readings in Formal Epistemology: Sourcebook (pp. 21–45). Springer.\n\n\nSpiegelhalter, D. (2024). Why probability probably doesn’t exist (but it is useful to act like it does). Nature, 636(8043), 560–563.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html",
    "href": "chapters/probability/02_probability_models.html",
    "title": "25  Modelli probabilistici",
    "section": "",
    "text": "25.1 Introduzione\nDopo un’introduzione al significato “filosofico” del concetto di probabilità, presentata nella Capitolo 24, questo capitolo sviluppa la discussione in modo più formale, introducendo i concetti fondamentali del calcolo delle probabilità a partire dalla nozione di esperimento casuale. Mostreremo come la modellazione matematica di un esperimento casuale permetta di calcolare diverse proprietà di interesse relative a tali esperimenti. In particolare, esploreremo le nozioni di spazio campionario, eventi e le proprietà della probabilità, fornendo gli strumenti necessari per comprendere e applicare questi concetti in contesti pratici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#esperimenti-casuali",
    "href": "chapters/probability/02_probability_models.html#esperimenti-casuali",
    "title": "25  Modelli probabilistici",
    "section": "\n25.2 Esperimenti Casuali",
    "text": "25.2 Esperimenti Casuali\nIl concetto cardine della probabilità è quello dell’esperimento casuale: un procedimento il cui esito non può essere determinato in anticipo, pur essendo suscettibile di analisi quantitativa. Alcuni esempi di esperimenti casuali sono:\n\nLanciare un dado e osservare il numero riportato sulla faccia superiore.\nEstrarre una carta a caso da un mazzo e verificarne il seme e il valore.\nMisurare il livello di stress percepito da un gruppo di individui in un determinato periodo (ad esempio, durante un esame o un evento stressante).\nContare il numero di risposte corrette fornite dai partecipanti a un test di memoria entro un intervallo di tempo prestabilito.\nSelezionare casualmente 50 persone e registrare quante di esse mostrano una predisposizione alla creatività, misurata tramite un questionario standardizzato.\nScegliere a caso dieci persone e valutare il loro grado di introversione attraverso uno strumento di autovalutazione psicologica.\nSelezionare casualmente 50 persone e contare quante sono mancine.\nScegliere a caso dieci individui e misurarne l’altezza.\n\nLo scopo dell’analisi probabilistica è comprendere il comportamento di tali esperimenti tramite la formulazione di modelli matematici. Una volta rappresentato matematicamente un esperimento casuale, è possibile calcolare grandezze d’interesse, come le probabilità e le aspettative. Questi modelli, implementabili anche al computer, consentono di simulare l’esperimento. Inoltre, i modelli matematici che descrivono gli esperimenti casuali costituiscono la base della statistica, la cui finalità è stabilire quale tra diversi modelli concorrenti risulti più adeguato ai dati osservati.\n\n25.2.1 Il Lancio di una Moneta\nUno degli esperimenti casuali più elementari è il lancio ripetuto di una moneta. Gran parte della teoria della probabilità si può infatti fondare su questo semplice esperimento. Per approfondire il comportamento di questo esperimento, è possibile simularlo al computer utilizzando, ad esempio, il linguaggio R. Il seguente programma R simula 100 lanci di una moneta equa (cioè con probabilità uguali per Testa e Croce) e rappresenta graficamente i risultati mediante un diagramma a barre.\n\nset.seed(123) # Imposta il seed per garantire la riproducibilità\nx &lt;- runif(100) &lt; 0.5 # Genera 100 numeri casuali; verifica se sono minori di 0.5\nt &lt;- 1:100 # Indice sequenziale dei lanci\n\n# Creazione del dataframe per ggplot2\ndata &lt;- data.frame(Lancio = t, Risultato = ifelse(x, \"Testa\", \"Croce\"))\n\n# Creazione del grafico a barre\nggplot(data, aes(x = Risultato)) +\n  geom_bar() +\n  labs(title = \"Distribuzione dei risultati del lancio della moneta\",\n       x = \"Risultato\",\n       y = \"Frequenza\")\n\n\n\n\n\n\n\nNel codice, la funzione runif genera 100 numeri casuali distribuiti uniformemente nell’intervallo \\([0, 1]\\). Confrontando ciascun numero estratto con il valore 0.5, si ottiene un vettore logico (vero/falso) che rappresenta, ad esempio, l’esito di un lancio di moneta (Testa o Croce). I risultati tipici di una simulazione di questo esperimento sono mostrati nella figura seguente, dove viene illustrato l’andamento della media delle Teste al variare del numero di lanci.\n\ny &lt;- cumsum(x)/t # Calcola la media cumulativa delle Teste\n\n# Creazione del dataframe per il grafico della media mobile\ndata_mean &lt;- data.frame(Lancio = t, Media_Testa = y)\n\n# Creazione del grafico a linea\nggplot(data_mean, aes(x = Lancio, y = Media_Testa)) +\n  geom_line() +\n  labs(title = \"Media mobile del numero di Teste\",\n       x = \"Numero di lanci\",\n       y = \"Media di Teste\")\n\n\n\n\n\n\n\nIl grafico risultante mostra come la media delle Teste sembri convergere verso 0.5, nonostante le fluttuazioni dovute alla natura casuale dell’esperimento. Alcune domande tipiche che si pongono in questo contesto sono:\n\nQual è la probabilità di ottenere un certo numero x di Teste in 100 lanci?\nQual è il numero atteso di Teste?\nQuanto tempo occorre in media per ottenere la prima Testa?\nCon quale rapidità la media cumulativa delle Teste converge al valore p?\n\nNel contesto statistico, dove si osservano i dati di un esperimento (ad esempio, i risultati di 100 lanci), si possono porre domande quali:\n\nLa moneta è davvero equa?\nQual è il metodo migliore per stimare la probabilità p dalla sequenza osservata di Teste e Croci?\nQual è l’accuratezza o la precisione della stima ottenuta?\n\n25.2.2 I Tre Elementi Fondamentali del Modello\nI modelli matematici per descrivere un esperimento casuale si basano su tre componenti principali:\n\nlo spazio campionario,\n\ngli eventi,\n\nla probabilità.\n\nEsaminiamo di seguito ciascuno di questi elementi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#spazio-campionario",
    "href": "chapters/probability/02_probability_models.html#spazio-campionario",
    "title": "25  Modelli probabilistici",
    "section": "\n25.3 Spazio Campionario",
    "text": "25.3 Spazio Campionario\nPur non potendo prevedere l’esito di un esperimento casuale, possiamo generalmente identificare l’insieme di tutti i possibili risultati. Questo insieme è definito come lo spazio campionario.\n\nDefinizione 25.1 Lo spazio campionario \\(\\Omega\\) di un esperimento casuale è l’insieme di tutti i possibili esiti dell’esperimento.\n\n\nEsempio 25.1 Consideriamo lo spazio campionario di alcuni esperimenti casuali.\n\nLancio di due dadi consecutivi:\\[\n\\Omega = \\{(1,1), (1,2), \\dots, (6,6)\\}.\n\\]\nTempo di reazione a uno stimolo visivo:\\[\\Omega = \\mathbb{R}^+,\\]\novvero l’insieme dei numeri reali positivi.\nNumero di errori in un test di memoria a breve termine:\\[\\Omega = \\{0, 1, 2, \\dots\\}.\\]\nMisurazione delle altezze di dieci persone:\\[\\Omega = \\{(x_1, \\dots, x_{10}) : x_i \\ge 0, \\; i=1,\\dots,10\\} \\subset \\mathbb{R}^{10}.\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#eventi",
    "href": "chapters/probability/02_probability_models.html#eventi",
    "title": "25  Modelli probabilistici",
    "section": "\n25.4 Eventi",
    "text": "25.4 Eventi\nSolitamente non siamo interessati ad un singolo esito, ma ad un insieme di essi. Un evento è un sottoinsieme dello spazio campionario a cui possiamo assegnare una probabilità.\n\nDefinizione 25.2 Un evento è un sottoinsieme \\(A \\subseteq \\Omega\\) al quale viene assegnata una probabilità. Indichiamo gli eventi con le lettere maiuscole \\(A, B, C, \\dots\\). Diciamo che l’evento \\(A\\) si verifica se l’esito dell’esperimento appartiene a \\(A\\).\n\n\nEsempio 25.2 Consideriamo alcuni possibili eventi definiti sugli spazi campionari dell’Esempio 25.1.\n\nLancio di due dadi consecutivi.Evento: “La somma dei due dadi è uguale a 7”.\\(A = \\{(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\\}\\).\nTempo di reazione a uno stimolo visivo.Evento: “Il tempo di reazione è inferiore a 2 secondi”.\\(A = [0, 2)\\).\nNumero di errori in un test di memoria a breve termine.Evento: “Il numero di errori è al massimo 3”.\\(A = \\{0, 1, 2, 3\\}\\).\nMisurazione delle altezze di dieci persone.Evento: “Almeno due persone hanno un’altezza superiore a 180 cm”.\\(A = \\{(x_1, \\dots, x_{10}) : \\text{almeno due } x_i &gt; 180\\}\\).\n\nQuesti esempi mostrano come gli eventi possano essere definiti in modo diverso a seconda della natura dello spazio campionario e del contesto di interesse.\n\n\nEsempio 25.3 Supponiamo di lanciare una moneta tre volte e di annotare se esce Testa (H) o Croce (T) in ogni lancio. Lo spazio campionario può essere rappresentato come:\n\\[\n\\Omega = \\{HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\\},\n\\]\ndove, ad esempio, \\(HTH\\) indica che il primo lancio dà Testa, il secondo Croce e il terzo Testa. Un’alternativa equivalente è considerare lo spazio campionario come l’insieme dei vettori binari di lunghezza 3, \\(\\{0, 1\\}^3\\), dove ad esempio \\(HTH\\) corrisponde a \\((1, 0, 1)\\).\nL’evento \\(A\\) che il terzo lancio sia Testa si esprime come:\n\\[\nA = \\{HHH, HTH, THH, TTH\\}.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#operazioni-sugli-eventi",
    "href": "chapters/probability/02_probability_models.html#operazioni-sugli-eventi",
    "title": "25  Modelli probabilistici",
    "section": "\n25.5 Operazioni sugli Eventi",
    "text": "25.5 Operazioni sugli Eventi\nPoiché gli eventi sono definiti come insiemi, è naturale applicare loro le classiche operazioni insiemistiche. Le principali operazioni sugli eventi sono:\n\nIntersezione (\\(A \\cap B\\)): Rappresenta l’evento in cui si verificano sia \\(A\\) che \\(B\\).\nAd esempio, se \\(A\\) è “piove” e \\(B\\) è “fa freddo”, allora \\(A \\cap B\\) è “piove e fa freddo”.\nUnione (\\(A \\cup B\\)): Rappresenta l’evento in cui si verifica almeno uno tra \\(A\\) e \\(B\\).\nContinuando con l’esempio precedente, \\(A \\cup B\\) è “piove oppure fa freddo (o entrambi)”.\nComplemento (\\(A^c\\)): Rappresenta l’evento in cui \\(A\\) non si verifica.\nSe \\(A\\) è “piove”, allora \\(A^c\\) è “non piove”.\nSottoinsieme (\\(B \\subseteq A\\)): Se \\(B\\) è un sottoinsieme di \\(A\\), allora il verificarsi di \\(B\\) implica il verificarsi di \\(A\\).\nAd esempio, se \\(A\\) è “piove” e \\(B\\) è “piove forte”, allora \\(B \\subseteq A\\).\n\nDue eventi \\(A\\) e \\(B\\) sono detti disgiunti (o mutualmente esclusivi) se non condividono alcun elemento, ovvero se \\(A \\cap B = \\emptyset\\). In altre parole, il verificarsi di uno esclude il verificarsi dell’altro. Ad esempio, se \\(A\\) è “esce testa” e \\(B\\) è “esce croce” in un lancio di moneta, allora \\(A\\) e \\(B\\) sono disgiunti.\n\nEsempio 25.4 Consideriamo l’esperimento del lancio di due dadi. Lo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili coppie di risultati che possono verificarsi. Ogni dado ha 6 facce, quindi lo spazio campionario è:\n\\[\n\\Omega = \\{(1,1), (1,2), \\dots, (6,6)\\},\n\\]\nper un totale di \\(6 \\times 6 = 36\\) esiti possibili.\nSiamo interessati all’evento \\(A\\): “la somma dei due dadi è almeno 10”. Questo evento include tutte le coppie di risultati la cui somma è 10, 11 o 12. Gli esiti che soddisfano questa condizione sono:\n\\[\nA = \\{(4,6), (5,5), (5,6), (6,4), (6,5), (6,6)\\}.\n\\]\nEcco come generare lo spazio campionario in R in modo algoritmico e definire l’evento “la somma dei due dadi è almeno 10”:\nLo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili coppie di risultati del lancio di due dadi. In R, possiamo generarlo utilizzando la funzione expand.grid, che crea tutte le combinazioni possibili tra i valori dei due dadi.\n\n# Generazione dello spazio campionario Omega\ndado &lt;- 1:6  # Facce di un dado\nOmega &lt;- expand.grid(Dado1 = dado, Dado2 = dado)  # Tutte le combinazioni possibili\n\nL’output sarà una tabella con 36 righe, una per ogni combinazione possibile:\n\n# Visualizzazione dello spazio campionario\nprint(Omega)\n#&gt;    Dado1 Dado2\n#&gt; 1      1     1\n#&gt; 2      2     1\n#&gt; 3      3     1\n#&gt; 4      4     1\n#&gt; 5      5     1\n#&gt; 6      6     1\n#&gt; 7      1     2\n#&gt; 8      2     2\n#&gt; 9      3     2\n#&gt; 10     4     2\n#&gt; 11     5     2\n#&gt; 12     6     2\n#&gt; 13     1     3\n#&gt; 14     2     3\n#&gt; 15     3     3\n#&gt; 16     4     3\n#&gt; 17     5     3\n#&gt; 18     6     3\n#&gt; 19     1     4\n#&gt; 20     2     4\n#&gt; 21     3     4\n#&gt; 22     4     4\n#&gt; 23     5     4\n#&gt; 24     6     4\n#&gt; 25     1     5\n#&gt; 26     2     5\n#&gt; 27     3     5\n#&gt; 28     4     5\n#&gt; 29     5     5\n#&gt; 30     6     5\n#&gt; 31     1     6\n#&gt; 32     2     6\n#&gt; 33     3     6\n#&gt; 34     4     6\n#&gt; 35     5     6\n#&gt; 36     6     6\n\nL’evento \\(A\\) è definito come “la somma dei due dadi è almeno 10”. Per identificare queste combinazioni, aggiungiamo una colonna che calcola la somma dei due dadi e filtriamo le righe in cui la somma è maggiore o uguale a 10.\n\n# Aggiunta di una colonna per la somma dei due dadi\nOmega$Somma &lt;- Omega$Dado1 + Omega$Dado2\n\n# Definizione dell'evento A: somma dei due dadi almeno 10\nA &lt;- Omega[Omega$Somma &gt;= 10, ]\n\nL’output sarà una tabella con le combinazioni in cui la somma è almeno 10:\n\n# Visualizzazione dell'evento A\nprint(A)\n#&gt;    Dado1 Dado2 Somma\n#&gt; 24     6     4    10\n#&gt; 29     5     5    10\n#&gt; 30     6     5    11\n#&gt; 34     4     6    10\n#&gt; 35     5     6    11\n#&gt; 36     6     6    12\n\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) è stato generato algoritmicamente utilizzando expand.grid;\nl’evento \\(A\\) è stato definito filtrando le combinazioni in cui la somma dei due dadi è almeno 10;\nl’evento \\(A\\) è stato rappresentato sia come dataframe che come lista di vettori, a seconda delle esigenze.\n\n\n\nEsempio 25.5 Consideriamo un esperimento in cui lanciamo una moneta tre volte consecutivamente. Ogni lancio può risultare in Testa (H) o Croce (T). Lo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili sequenze di risultati dei tre lanci. Ci sono \\(2^3 = 8\\) possibili esiti, che possono essere rappresentati come:\n\\[\n\\Omega = \\{\\text{HHH}, \\text{HHT}, \\text{HTH}, \\text{HTT}, \\text{THH}, \\text{THT}, \\text{TTH}, \\text{TTT}\\}.\n\\]\nVogliamo definire in R l’evento \\(A\\): “Il terzo lancio della moneta dia Testa (H)”. Questo evento include tutte le sequenze in cui il terzo carattere è “H”.\nIn R, possiamo rappresentare lo spazio campionario \\(\\Omega\\) come un vettore di stringhe, dove ogni stringa corrisponde a una sequenza di risultati.\n\n# Definizione dello spazio campionario Omega\nomega &lt;- c(\"HHH\", \"HHT\", \"HTH\", \"HTT\", \"THH\", \"THT\", \"TTH\", \"TTT\")\n\nL’output sarà:\n\n# Visualizzazione dello spazio campionario\nprint(omega)\n#&gt; [1] \"HHH\" \"HHT\" \"HTH\" \"HTT\" \"THH\" \"THT\" \"TTH\" \"TTT\"\n\nL’evento \\(A\\) è costituito da tutte le sequenze in cui il terzo lancio è Testa (H). Per identificare queste sequenze, utilizziamo la funzione substr, che estrae il terzo carattere da ciascuna stringa e verifica se è uguale a “H”.\n\n# Definizione dell'evento A: terzo lancio è Testa (H)\nA &lt;- omega[substr(omega, 3, 3) == \"H\"]\n\nSpiegazione del codice:\n\n\nsubstr(omega, 3, 3) estrae il terzo carattere da ciascuna stringa nel vettore omega.\n\nsubstr(omega, 3, 3) == \"H\" crea un vettore logico (vero/falso) che indica se il terzo carattere è “H”.\n\nomega[...] filtra il vettore omega, mantenendo solo le sequenze che soddisfano la condizione.\n\nL’output sarà:\n\n# Visualizzazione dell'evento A\nprint(A)\n#&gt; [1] \"HHH\" \"HTH\" \"THH\" \"TTH\"\n\nQueste sono le sequenze in cui il terzo lancio è Testa (H).\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) è stato definito come un vettore di stringhe in R;\nl’evento \\(A\\) è stato costruito filtrando le sequenze in cui il terzo carattere è “H”, utilizzando la funzione substr(x, start, stop);\nl’evento \\(A\\) è stato visualizzato e corrisponde alle sequenze: HHH, HTH, THH, TTH.\n\nQuesto esercizio illustra come definire e manipolare eventi in R, utilizzando operazioni di base su stringhe e vettori.\n\n\nEsempio 25.6 Vogliamo verificare in R se due eventi \\(A\\) e \\(B\\) sono disgiunti. Per farlo, controlliamo se la loro intersezione è un insieme vuoto.\nSupponiamo di avere i due seguenti eventi:\n\n\\(A = \\{1, 2, 3\\}\\)\n\\(B = \\{4, 5, 6\\}\\)\n\nIn R, definiamo questi eventi come vettori numerici:\n\n# Definizione degli eventi A e B\nA &lt;- c(1, 2, 3)\nB &lt;- c(4, 5, 6)\n\nL’output sarà:\n\n# Visualizzazione degli eventi\nprint(\"Evento A:\")\n#&gt; [1] \"Evento A:\"\nprint(A)\n#&gt; [1] 1 2 3\n\n\nprint(\"Evento B:\")\n#&gt; [1] \"Evento B:\"\nprint(B)\n#&gt; [1] 4 5 6\n\nPer verificare se \\(A\\) e \\(B\\) sono disgiunti, utilizziamo la funzione intersect, che calcola l’intersezione tra due insiemi. Se l’intersezione è vuota, i due eventi sono disgiunti.\n\n# Calcolo dell'intersezione tra A e B\nintersezione &lt;- intersect(A, B)\n\n# Verifica se l'intersezione è vuota\nif (length(intersezione) == 0) {\n  print(\"A e B sono disgiunti: l'intersezione è vuota.\")\n} else {\n  print(\"A e B non sono disgiunti: l'intersezione non è vuota.\")\n}\n#&gt; [1] \"A e B sono disgiunti: l'intersezione è vuota.\"\n\nSpiegazione del codice:\n\n\nintersect(A, B) calcola l’intersezione tra i vettori \\(A\\) e \\(B\\);\n\nlength(intersezione) == 0 verifica se l’intersezione è vuota (cioè se non ci sono elementi in comune);\nse l’intersezione è vuota, i due eventi sono disgiunti; altrimenti, non lo sono;\n\nnumeric(0) indica che l’intersezione è un insieme vuoto;\nil messaggio conferma che \\(A\\) e \\(B\\) sono disgiunti.\n\n\n\nEsempio 25.7 Consideriamo l’esperimento del lancio consecutivo di due dadi. Lo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili coppie di risultati:\n\\[\n\\Omega = \\{(1, 1), (1, 2), \\dots, (6, 6)\\}.\n\\]\nDefiniamo due eventi:\n\nEvento \\(A\\): “Il primo dado mostra un 6”.\nQuesto evento include tutte le coppie in cui il primo dado è 6:\\[\nA = \\{(6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)\\}.\n\\]\nEvento \\(B\\): “Il secondo dado mostra un 6”.\nQuesto evento include tutte le coppie in cui il secondo dado è 6:\\[\nB = \\{(1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 6)\\}.\n\\]\n\nL’intersezione \\(A \\cap B\\) rappresenta l’evento in cui entrambi i dadi mostrano un 6:\n\\[\nA \\cap B = \\{(6, 6)\\}.\n\\]\nImplementazione in R\nUtilizziamo la funzione expand.grid per generare tutte le possibili combinazioni dei risultati dei due dadi.\n\n# Generazione dello spazio campionario Omega\ndado &lt;- 1:6  # Facce di un dado\nOmega &lt;- expand.grid(Dado1 = dado, Dado2 = dado)  # Tutte le combinazioni possibili\n\nL’output sarà una tabella con 36 righe, una per ogni combinazione possibile:\n\n# Visualizzazione dello spazio campionario\nprint(Omega)\n#&gt;    Dado1 Dado2\n#&gt; 1      1     1\n#&gt; 2      2     1\n#&gt; 3      3     1\n#&gt; 4      4     1\n#&gt; 5      5     1\n#&gt; 6      6     1\n#&gt; 7      1     2\n#&gt; 8      2     2\n#&gt; 9      3     2\n#&gt; 10     4     2\n#&gt; 11     5     2\n#&gt; 12     6     2\n#&gt; 13     1     3\n#&gt; 14     2     3\n#&gt; 15     3     3\n#&gt; 16     4     3\n#&gt; 17     5     3\n#&gt; 18     6     3\n#&gt; 19     1     4\n#&gt; 20     2     4\n#&gt; 21     3     4\n#&gt; 22     4     4\n#&gt; 23     5     4\n#&gt; 24     6     4\n#&gt; 25     1     5\n#&gt; 26     2     5\n#&gt; 27     3     5\n#&gt; 28     4     5\n#&gt; 29     5     5\n#&gt; 30     6     5\n#&gt; 31     1     6\n#&gt; 32     2     6\n#&gt; 33     3     6\n#&gt; 34     4     6\n#&gt; 35     5     6\n#&gt; 36     6     6\n\nFiltriamo lo spazio campionario per definire gli eventi \\(A\\) e \\(B\\).\n\n# Definizione dell'evento A: primo dado mostra un 6\nA &lt;- Omega[Omega$Dado1 == 6, ]\n\n# Definizione dell'evento B: secondo dado mostra un 6\nB &lt;- Omega[Omega$Dado2 == 6, ]\n\nL’output sarà:\n\nprint(\"Evento A:\")\n#&gt; [1] \"Evento A:\"\nprint(A)\n#&gt;    Dado1 Dado2\n#&gt; 6      6     1\n#&gt; 12     6     2\n#&gt; 18     6     3\n#&gt; 24     6     4\n#&gt; 30     6     5\n#&gt; 36     6     6\n\n\nprint(\"Evento B:\")\n#&gt; [1] \"Evento B:\"\nprint(B)\n#&gt;    Dado1 Dado2\n#&gt; 31     1     6\n#&gt; 32     2     6\n#&gt; 33     3     6\n#&gt; 34     4     6\n#&gt; 35     5     6\n#&gt; 36     6     6\n\nL’intersezione \\(A \\cap B\\) è l’evento in cui entrambi i dadi mostrano un 6. Possiamo calcolarla utilizzando la funzione merge.\n\n# Calcolo dell'intersezione A ∩ B\nA_intersezione_B &lt;- merge(A, B)\n\nL’output sarà:\n\nprint(A_intersezione_B)\n#&gt;   Dado1 Dado2\n#&gt; 1     6     6\n\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) è stato generato algoritmicamente in R;\ngli eventi \\(A\\) e \\(B\\) sono stati definiti filtrando lo spazio campionario;\nl’intersezione \\(A \\cap B\\) è stata calcolata e corrisponde all’evento in cui entrambi i dadi mostrano un 6: \\(\\{(6, 6)\\}\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#probabilità",
    "href": "chapters/probability/02_probability_models.html#probabilità",
    "title": "25  Modelli probabilistici",
    "section": "\n25.6 Probabilità",
    "text": "25.6 Probabilità\nIl terzo elemento del modello è la specificazione della probabilità, che quantifica la possibilità che un determinato evento si verifichi.\n\nDefinizione 25.3 Una probabilità \\(P\\) è una funzione che assegna a ciascun evento un valore compreso tra 0 e 1, e che soddisfa i seguenti assiomi:\n\n\n\\(0 \\leq P(A) \\leq 1\\) per ogni evento \\(A\\).\n\n\\(P(\\Omega) = 1\\).\nSe \\(A_1, A_2, \\dots\\) sono eventi mutuamente esclusivi, allora vale la regola della somma: \\[\nP\\left(\\bigcup_{i} A_i\\right) = \\sum_{i} P(A_i).\n\\tag{25.1}\\]\n\n\n\n\nL’assioma 1 stabilisce che la probabilità associata all’esito di un esperimento è sempre un valore compreso tra 0 e 1.\n\nL’assioma 2 implica che l’evento certo, ossia l’insieme di tutti i possibili esiti dell’esperimento (lo spazio campionario \\(\\Omega\\)), ha probabilità pari a 1.\n\nInfine, l’assioma 3 afferma che, se un evento può verificarsi attraverso diverse modalità tra loro incompatibili, la probabilità complessiva dell’evento è pari alla somma delle probabilità delle singole modalità.\n\n\n25.6.1 Proprietà della Probabilità\nIl seguente teorema sintetizza alcune proprietà essenziali delle probabilità, conseguenti direttamente dagli assiomi sopra esposti.\nTeorema 1.2 (Proprietà di una Probabilità).\nSiano \\(A\\) e \\(B\\) due eventi e \\(P\\) una probabilità. Allora:\n\n\n\\(P(\\emptyset) = 0\\).\nSe \\(A \\subseteq B\\), allora \\(P(A) \\leq P(B)\\).\n\n\\(P(A^c) = 1 - P(A)\\).\n\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\).\n\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\n\n\nPoiché \\(\\Omega = \\Omega \\cup \\emptyset\\) e \\(\\Omega \\cap \\emptyset = \\emptyset\\), dalla regola della somma segue:\n\\[\nP(\\Omega) = P(\\Omega) + P(\\emptyset),\n\\]\ne, dato che \\(P(\\Omega) = 1\\), si deduce che \\(P(\\emptyset) = 0\\).\n\n\nSe \\(A \\subseteq B\\), possiamo scrivere \\(B = A \\cup (B \\cap A^c)\\), dove \\(A\\) e \\(B \\cap A^c\\) sono eventi disgiunti. Quindi:\n\\[\nP(B) = P(A) + P(B \\cap A^c).\n\\]\nPoiché \\(P(B \\cap A^c) \\geq 0\\), segue che \\(P(B) \\geq P(A)\\).\n\n\nDal fatto che \\(\\Omega = A \\cup A^c\\) (con \\(A\\) e \\(A^c\\) disgiunti) si ottiene:\n\\[\nP(\\Omega) = P(A) + P(A^c),\n\\]\ne dunque \\(P(A^c) = 1 - P(A)\\).\n\n\nScriviamo \\(A \\cup B\\) come l’unione disgiunta di \\(A\\) e \\(B \\cap A^c\\):\n\\[\nP(A \\cup B) = P(A) + P(B \\cap A^c).\n\\]\nConsiderando che \\(B = (A \\cap B) \\cup (B \\cap A^c)\\) (con i due insiemi disgiunti), si ha:\n\\[\nP(B) = P(A \\cap B) + P(B \\cap A^c).\n\\]\nSottraendo \\(P(A \\cap B)\\) da entrambi i membri, otteniamo:\n\\[\nP(B \\cap A^c) = P(B) - P(A \\cap B),\n\\]\ne, sostituendo nella precedente espressione per \\(P(A \\cup B)\\):\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n\\]\n\n\n\n\n\n\n25.6.2 Esempio\nConsideriamo l’esperimento del lancio di un dado equilibrato. In questo caso:\n\nLo spazio campionario è: \\[\n\\Omega = \\{1, 2, 3, 4, 5, 6\\}.\n\\]\n\nUna scelta ragionevole per definire la probabilità \\(P\\) è: \\[\nP(A) = \\frac{|A|}{6}, \\quad \\text{per ogni } A \\subseteq \\Omega,\n\\] dove \\(|A|\\) denota il numero di elementi di \\(A\\). Ad esempio, la probabilità di ottenere un numero pari è: \\[\nP(\\{2, 4, 6\\}) = \\frac{3}{6} = \\frac{1}{2}.\n\\]\n\n\nIn molte applicazioni, lo spazio campionario è discreto, cioè si può scrivere come \\[\n\\Omega = \\{a_1, a_2, \\dots, a_n\\} \\quad \\text{oppure} \\quad \\Omega = \\{a_1, a_2, \\dots\\}.\n\\] In tal caso, il metodo più semplice per definire \\(P\\) consiste nell’assegnare una probabilità \\(p_i\\) all’evento elementare \\(\\{a_i\\}\\) e poi definire, per ogni \\(A \\subseteq \\Omega\\): \\[\nP(A) = \\sum_{i: a_i \\in A} p_i.\n\\] Questa rappresentazione è illustrata graficamente in Figura 1.6: a ciascun elemento \\(a_i\\) viene associato un “peso” \\(p_i\\) (la dimensione del punto può essere usata per rappresentare l’entità di \\(p_i\\)). La probabilità di un evento \\(A\\) si ottiene sommando i pesi degli elementi in \\(A\\).\nQuando tutti gli eventi elementari sono equiprobabili, si ha che \\[\nP(A) = \\frac{|A|}{|\\Omega|},\n\\] dove \\(|\\Omega|\\) è il numero totale di esiti possibili (con \\(|\\Omega|\\) finito). In questo modo, il calcolo delle probabilità si riduce a un problema di conteggio (vedi Problema 1.6).\nSe, invece, lo spazio campionario non è numerabile, ad esempio \\[\n\\Omega = \\mathbb{R}^+,\n\\] si parla di spazio campionario continuo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#dalle-definizioni-fondamentali-alle-proprietà-della-probabilità",
    "href": "chapters/probability/02_probability_models.html#dalle-definizioni-fondamentali-alle-proprietà-della-probabilità",
    "title": "25  Modelli probabilistici",
    "section": "\n25.7 Dalle Definizioni Fondamentali alle Proprietà della Probabilità",
    "text": "25.7 Dalle Definizioni Fondamentali alle Proprietà della Probabilità\nAbbiamo visto come un esperimento casuale possa essere descritto matematicamente attraverso tre elementi fondamentali:\n\nLo spazio campionario (\\(\\Omega\\)), che rappresenta l’insieme di tutti i possibili esiti dell’esperimento.\nGli eventi, che sono sottoinsiemi dello spazio campionario e corrispondono a insiemi di esiti di interesse.\nLa probabilità, una funzione che assegna un valore compreso tra 0 e 1 agli eventi, quantificando il loro grado di incertezza.\n\nDopo aver definito questi concetti, possiamo sviluppare ulteriormente la teoria introducendo alcune proprietà fondamentali della probabilità. Queste proprietà ci permettono di calcolare la probabilità di eventi complessi a partire da probabilità più semplici e di comprendere le relazioni tra eventi diversi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#regola-della-somma",
    "href": "chapters/probability/02_probability_models.html#regola-della-somma",
    "title": "25  Modelli probabilistici",
    "section": "\n25.8 Regola della Somma",
    "text": "25.8 Regola della Somma\nUna delle prime proprietà fondamentali della probabilità è la regola della somma, che ci permette di determinare la probabilità che si verifichi almeno uno tra due eventi.\nLa formula varia a seconda che i due eventi siano mutuamente esclusivi o meno.\n\n\nSe due eventi non possono verificarsi simultaneamente (ovvero sono mutuamente esclusivi, cioè \\(A \\cap B = \\varnothing\\)), la loro probabilità combinata si ottiene semplicemente sommando le probabilità individuali:\n\\[ P(A \\cup B) = P(A) + P(B). \\]\n\n\nSe invece gli eventi possono verificarsi contemporaneamente, dobbiamo sottrarre la probabilità della loro intersezione, per evitare di contarla due volte:\n\\[ P(A \\cup B) = P(A) + P(B) - P(A \\cap B). \\]\n\n\nQuesta proprietà deriva direttamente dalla definizione di spazio campionario e di evento: gli eventi sono insiemi e la probabilità è una funzione definita su di essi. La regola della somma è quindi una conseguenza delle operazioni insiemistiche applicate alla probabilità.\n\nEsempio 25.8 In uno studio sulla salute mentale, supponiamo di avere i seguenti dati relativi a un campione di partecipanti:\n\nLa probabilità che un individuo soffra di ansia è \\(P(A) = 0.30\\).\n\nLa probabilità che un individuo soffra di depressione è \\(P(B) = 0.25\\).\n\nLa probabilità che un individuo soffra contemporaneamente di ansia e depressione è \\(P(A \\cap B) = 0.15\\).\n\nVogliamo calcolare la probabilità che un individuo soffra di almeno uno dei due disturbi (ansia o depressione), ovvero \\(P(A \\cup B)\\).\nUtilizziamo la regola della somma per eventi non mutuamente esclusivi:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\nOra implementiamo questo calcolo in R:\n\n# Definiamo le probabilità\nP_A &lt;- 0.30  # Probabilità di soffrire di ansia\nP_B &lt;- 0.25  # Probabilità di soffrire di depressione\nP_A_intersect_B &lt;- 0.15  # Probabilità di soffrire di entrambi i disturbi\n\n# Applichiamo la formula della regola della somma\nP_A_union_B &lt;- P_A + P_B - P_A_intersect_B\n\n# Stampiamo il risultato\ncat(\"La probabilità che un individuo soffra di almeno un disturbo (ansia o depressione) è:\", P_A_union_B, \"\\n\")\n#&gt; La probabilità che un individuo soffra di almeno un disturbo (ansia o depressione) è: 0.4\n\nInterpretazione: il 40% dei partecipanti soffre di almeno uno tra ansia e depressione. L’intersezione \\(P(A \\cap B) = 0.15\\) è fondamentale, poiché senza sottrarla avremmo contato due volte i soggetti che soffrono contemporaneamente di entrambi i disturbi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#probabilità-e-struttura-matematica-degli-esperimenti-casuali",
    "href": "chapters/probability/02_probability_models.html#probabilità-e-struttura-matematica-degli-esperimenti-casuali",
    "title": "25  Modelli probabilistici",
    "section": "\n25.9 Probabilità e Struttura Matematica degli Esperimenti Casuali",
    "text": "25.9 Probabilità e Struttura Matematica degli Esperimenti Casuali\nLe proprietà discusse in precedenza non sono semplici regole algebriche, ma derivano dalla struttura del modello probabilistico che abbiamo definito. In particolare:\n\nLo spazio campionario ci permette di identificare tutti gli esiti possibili di un esperimento.\n\nLa definizione di evento ci consente di formulare domande su insiemi di esiti, e non solo su singoli risultati.\n\nLa probabilità, grazie alle sue proprietà, ci fornisce strumenti per combinare eventi e determinare la probabilità complessiva di osservare determinati fenomeni.\n\nL’introduzione di operazioni sugli eventi (unione, intersezione, complemento) e delle proprietà della probabilità (regola della somma, probabilità condizionata e legge della probabilità totale (che approfondiremo nel Capitolo 28)) ci consente di costruire modelli probabilistici più complessi e applicabili a problemi reali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#probabilità-calcolo-combinatorio-e-simulazioni",
    "href": "chapters/probability/02_probability_models.html#probabilità-calcolo-combinatorio-e-simulazioni",
    "title": "25  Modelli probabilistici",
    "section": "\n25.10 Probabilità, Calcolo Combinatorio e Simulazioni",
    "text": "25.10 Probabilità, Calcolo Combinatorio e Simulazioni\nMolti problemi di probabilità scolastici si basano sul calcolo combinatorio per determinare la probabilità di un evento. La struttura generale di questi problemi consiste nel:\n\n\nDefinire gli eventi di successo: identificare tutte le configurazioni compatibili con l’evento di interesse.\n\nContare le possibilità: calcolare il numero di eventi di successo e rapportarlo al numero totale di eventi nello spazio campionario.\n\n\nEsempio 25.9 Supponiamo di avere una scatola con 10 palline numerate da 1 a 10 e di voler calcolare la probabilità di estrarre una pallina con un numero pari:\n\n\nEventi di successo: {2, 4, 6, 8, 10} (5 casi).\n\nEventi totali: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} (10 casi).\n\nLa probabilità è quindi:\n\\[\nP(\\text{numero pari}) = \\frac{\\text{numero di eventi di successo}}{\\text{numero totale di eventi}} = \\frac{5}{10} = 0.5.\n\\]\n\nPer problemi più complessi, come il calcolo della probabilità di ottenere una determinata combinazione di carte o di formare gruppi specifici da una popolazione, utilizziamo tecniche combinatorie più avanzate, come permutazioni e combinazioni (si veda il Capitolo 86 dell’appendice).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#simulazioni-monte-carlo",
    "href": "chapters/probability/02_probability_models.html#simulazioni-monte-carlo",
    "title": "25  Modelli probabilistici",
    "section": "\n25.11 Simulazioni Monte Carlo",
    "text": "25.11 Simulazioni Monte Carlo\nUno degli aspetti più impegnativi della probabilità è che molti problemi non si prestano a soluzioni immediate o intuitive. Per affrontarli, si possono adottare due approcci principali. Il primo consiste nell’applicare i teoremi della teoria della probabilità, un metodo rigoroso ma spesso controintuitivo. Il secondo approccio è quello della simulazione Monte Carlo, che permette di ottenere una soluzione approssimata, ma molto vicina al valore reale, seguendo una procedura più accessibile e intuitiva. Questo metodo prende il nome dal famoso Casinò di Monte Carlo a Monaco, anche se può essere semplicemente definito come “metodo di simulazione.”\nLa simulazione Monte Carlo appartiene a una classe generale di metodi stocastici, che si contrappongono ai metodi deterministici. Questi metodi consentono di risolvere approssimativamente problemi analitici attraverso la generazione casuale delle quantità di interesse. Tra le tecniche comunemente utilizzate troviamo il campionamento con reinserimento, in cui la stessa unità può essere selezionata più volte, e il campionamento senza reinserimento, dove ogni unità può essere selezionata una sola volta. Questi strumenti rappresentano un mezzo potente e pratico per affrontare problemi complessi.\n\n25.11.1 Il Problema dei Complenni\nUn esempio classico di applicazione del metodo Monte Carlo è il calcolo delle probabilità relative a vari eventi definiti attraverso il modello dell’urna. Tra questi, abbiamo il celebre problema dei compleanni.\nIl problema dei compleanni esplora la probabilità che, in un gruppo di \\(n\\) persone, almeno due persone condividano la stessa data di nascita. Supponendo che i compleanni siano distribuiti uniformemente su 365 giorni (ignorando anni bisestili), il problema sorprende molte persone per il fatto che già con 23 persone la probabilità di una coincidenza è superiore al 50%.\n\n25.11.1.1 Soluzione analitica\nQuesto problema può essere risolto utilizzando il concetto di probabilità complementari. Infatti, il problema può essere visto da due prospettive complementari:\n\ncaso 1: tutti i compleanni sono diversi (nessuna persona condivide il compleanno con un’altra);\ncaso 2: almeno due persone condividono lo stesso compleanno.\n\nQuesti due casi sono mutuamente esclusivi (non possono verificarsi contemporaneamente) ed esaustivi (coprono tutte le possibilità). Pertanto, la somma delle loro probabilità deve essere uguale a 1:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nIn altre parole, per calcolare la probabilità che almeno due persone abbiano lo stesso compleanno, possiamo prima calcolare la probabilità che tutti i compleanni siano diversi e poi sottrarre questo valore da 1.\nCaso 1: probabilità che tutti i compleanni siano diversi.\nPer calcolare \\(P(\\text{nessun compleanno in comune})\\), seguiamo questo ragionamento:\n\nPrima persona: Può scegliere liberamente un giorno del calendario. Ci sono 365 possibilità (ignoriamo gli anni bisestili per semplicità).\nSeconda persona: Deve avere un compleanno diverso dalla prima persona. Quindi, ci sono 364 giorni disponibili.\nTerza persona: Deve avere un compleanno diverso dai primi due. Ci sono 363 giorni disponibili.\n\nQuesto processo continua fino alla \\(n\\)-esima persona, che avrà \\(365 - n + 1\\) giorni disponibili.\nLa probabilità che tutti i compleanni siano diversi si ottiene moltiplicando le probabilità individuali di ogni persona di avere un compleanno diverso dai precedenti. Poiché ogni scelta è indipendente, possiamo scrivere:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365}{365} \\cdot \\frac{364}{365} \\cdot \\frac{363}{365} \\cdot \\ldots \\cdot \\frac{365-n+1}{365}.\n\\]\nQuesto prodotto può essere espresso in forma compatta utilizzando il fattoriale:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-n)! \\cdot 365^n} ,\n\\]\ndove:\n\n\n\\(365!\\) è il fattoriale di 365 (il prodotto di tutti i numeri interi da 1 a 365).\n\n\\((365-n)!\\) è il fattoriale di \\(365 - n\\).\n\n\\(365^n\\) rappresenta tutte le possibili combinazioni di compleanni per \\(n\\) persone.\n\nCaso 2. Probabilità di almeno un compleanno in comune.\nOra che abbiamo calcolato la probabilità che tutti i compleanni siano diversi, possiamo trovare la probabilità che almeno due persone abbiano lo stesso compleanno come il complemento:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nSostituendo l’espressione precedente, otteniamo:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - \\frac{365!}{(365-n)! \\cdot 365^n}.\n\\]\nOra che abbiamo le formule per i due eventi complementari, come funzione di \\(n\\), applichiamole al caso specifico in cui \\(n\\) = 23. Questo è un valore interessante perché, come vedremo, la probabilità che almeno due persone su 23 condividano lo stesso compleanno supera il 50%.\nLa formula per la probabilità che tutti i compleanni siano diversi è:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-n)! \\cdot 365^n}.\n\\]\nPer \\(n = 23\\), sostituiamo il valore nella formula:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-23)! \\cdot 365^{23}}.\n\\]\nSemplifichiamo:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{342! \\cdot 365^{23}}.\n\\]\nUtilizzando R, troviamo:\n\n# Calcola il prodotto dei numeri da 365 a 343\nprodotto &lt;- prod(365:343)\n\n# Calcola 365^23\ndenominatore &lt;- 365^23\n\n# Calcola il risultato\nrisultato &lt;- prodotto / denominatore\n\n# Stampa il risultato\nprint(risultato)\n#&gt; [1] 0.4927\n\n\\[\nP(\\text{nessun compleanno in comune}) \\approx 0.4927.\n\\]\nCiò significa che la probabilità che tutte le 23 persone abbiano compleanni diversi è circa 0.4927.\nLa probabilità che almeno due persone su 23 condividano lo stesso compleanno è il complemento della probabilità calcolata sopra:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nSostituendo il valore trovato:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - 0.4927 = 0.5073.\n\\]\nCiò significa che la probabilità che almeno due persone su 23 abbiano lo stesso compleanno è circa 0.5073.\nCon \\(n\\) = 23, dunque, la probabilità che almeno due persone condividano lo stesso compleanno supera il 50%. Questo risultato è spesso controintuitivo, poiché molte persone si aspettano che servano molte più persone per raggiungere una probabilità così alta. Tuttavia, grazie alla natura combinatoria del problema, bastano 23 persone per avere una probabilità superiore al 50%.\n\n25.11.1.2 Soluzione con Simulazione in R\nPer risolvere il problema tramite simulazione, possiamo generare gruppi casuali di \\(n\\) persone, assegnando loro un compleanno casuale tra 1 e 365. Per ogni gruppo, verifichiamo se almeno due persone condividono lo stesso compleanno.\nEcco il codice R:\n\n# Numero di simulazioni\nnum_simulazioni &lt;- 10000\n\n# Funzione per simulare il problema del compleanno\nsimula_compleanno &lt;- function(n) {\n  # Conta il numero di successi (almeno un compleanno in comune)\n  successi &lt;- 0\n  \n  # Loop per il numero di simulazioni\n  for (i in 1:num_simulazioni) {\n    # Genera n compleanni casuali\n    compleanni &lt;- sample(1:365, n, replace = TRUE)\n    \n    # Verifica se ci sono duplicati\n    if (any(duplicated(compleanni))) {\n      successi &lt;- successi + 1\n    }\n  }\n  \n  # Calcola la probabilità stimata\n  return(successi / num_simulazioni)\n}\n\nProviamo con diversi valori di n.\n\nset.seed(123)  # Fissiamo il seme per la riproducibilità\nrisultati &lt;- sapply(1:50, simula_compleanno)\n\n# Creiamo un data frame con i risultati\ndf &lt;- data.frame(\n  n = 1:50,\n  prob = risultati\n)\n\n# Creiamo il grafico\nggplot(df, aes(x = n, y = prob)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"blue\") +\n  geom_hline(yintercept = 0.5, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Numero di persone (n)\",\n    y = \"Probabilità stimata\",\n    title = \"Problema del Compleanno (Simulazione)\"\n  ) \n\n\n\n\n\n\n\n\n\nSimulazioni: Per ogni gruppo di \\(n\\), si eseguono 10.000 simulazioni, in cui si generano \\(n\\) compleanni casuali tra 1 e 365.\n\nDuplicati: La funzione duplicated() verifica se ci sono compleanni ripetuti.\n\nCalcolo della probabilità: La proporzione di simulazioni in cui si verifica almeno un compleanno condiviso rappresenta la probabilità stimata.\n\nVisualizzazione: Si tracciano le probabilità per diversi valori di \\(n\\), evidenziando il punto in cui la probabilità supera il 50%.\n\nRisultati attesi:\n\ncon circa 23 persone, la probabilità stimata sarà superiore a 0.5;\nil grafico mostra una curva crescente con un rapido aumento della probabilità per \\(n\\) piccoli e un asintoto vicino a 1 per \\(n\\) grandi.\n\nQuesto approccio permette di comprendere intuitivamente il problema e di verificare i risultati teorici con la simulazione.\n\n25.11.1.3 Assunzioni\nIl problema dei compleanni evidenzia non solo l’efficacia dell’approccio simulativo nel semplificare la soluzione rispetto all’analisi formale, ma anche l’importanza delle assunzioni che entrambi i metodi condividono. In questo caso, l’assunzione è che la probabilità di nascita sia uniformemente distribuita nei 365 giorni dell’anno — un’ipotesi semplificativa che non rispecchia la realtà.\nQuesto esempio sottolinea un principio fondamentale dei modelli probabilistici (e scientifici in generale): ogni modello si basa su un insieme di ipotesi che ne delimitano la validità e l’applicabilità. Valutare criticamente la plausibilità di tali ipotesi è dunque essenziale per garantire che il modello fornisca una rappresentazione coerente e utile del fenomeno in studio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#riflessioni-conclusive",
    "href": "chapters/probability/02_probability_models.html#riflessioni-conclusive",
    "title": "25  Modelli probabilistici",
    "section": "\n25.12 Riflessioni Conclusive",
    "text": "25.12 Riflessioni Conclusive\nLa teoria della probabilità fornisce un quadro rigoroso per descrivere e analizzare fenomeni caratterizzati dall’incertezza. In questo capitolo abbiamo introdotto i concetti fondamentali del calcolo delle probabilità, evidenziando come la modellazione matematica degli esperimenti casuali consenta di quantificare e prevedere eventi incerti. Abbiamo esplorato strumenti essenziali come la definizione di spazio campionario, la nozione di evento e le regole della probabilità, illustrando il loro utilizzo sia attraverso esempi teorici sia mediante simulazioni computazionali.\nUn aspetto cruciale della modellazione probabilistica è il ruolo delle assunzioni su cui si basano i modelli. Ogni modello probabilistico si fonda su ipotesi specifiche riguardanti la natura del fenomeno studiato e il modo in cui gli esiti vengono generati. Queste ipotesi determinano non solo la validità del modello, ma anche il tipo di risposte che esso può fornire. Ad esempio, nel problema del compleanno, abbiamo ipotizzato che i compleanni siano distribuiti in modo uniforme nei 365 giorni dell’anno. Sebbene questa assunzione semplifichi notevolmente i calcoli, sappiamo che nella realtà esistono fluttuazioni stagionali nelle nascite che possono influenzare le probabilità effettive.\nQuesto ci porta a una considerazione più ampia: la probabilità non è solo un insieme di formule, ma uno strumento per rappresentare l’incertezza e prendere decisioni informate. Tuttavia, l’accuratezza di qualsiasi modello probabilistico dipende strettamente dalla plausibilità delle ipotesi adottate. Modelli diversi, basati su ipotesi differenti, possono portare a risultati diversi, e l’interpretazione dei risultati deve sempre tenere conto di queste assunzioni.\nIn definitiva, lo studio della probabilità non si limita alla manipolazione di formule, ma richiede un’attenta riflessione sulla relazione tra modelli teorici e fenomeni reali. Una comprensione critica delle assunzioni alla base di un modello è essenziale per applicare correttamente i concetti probabilistici in contesti pratici, sia in ambito scientifico che nelle decisioni quotidiane.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#esercizi",
    "href": "chapters/probability/02_probability_models.html#esercizi",
    "title": "25  Modelli probabilistici",
    "section": "\n25.13 Esercizi",
    "text": "25.13 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nQui di seguito sono presentati una serie di esercizi sbasati sulla Satisfaction with Life Scale (SWLS).\nEsercizi sullo Spazio Campionario e Eventi\n\n\nDefinizione dello Spazio Campionario\nSupponiamo che i punteggi della Satisfaction with Life Scale (SWLS) siano numeri interi compresi tra 5 e 35.\n\nQual è lo spazio campionario \\(\\Omega\\) per questo esperimento?\nSe hai raccolto i dati di 15 studenti, come potresti rappresentare lo spazio campionario con i loro punteggi osservati?\n\n\n\nDefinizione di un Evento\nConsideriamo l’evento A: “Uno studente ha un punteggio SWLS superiore a 25”.\n\nEsprimi l’evento A come un sottoinsieme dello spazio campionario.\nSe tra i 15 studenti osservati, 4 hanno punteggi superiori a 25, qual è la proporzione sperimentale per l’evento A?\n\n\n\nEventi Complementari\nDefiniamo l’evento B: “Uno studente ha un punteggio SWLS inferiore o uguale a 25”.\n\nScrivi l’evento B in relazione all’evento A.\nQual è la probabilità empirica di B, sapendo che 4 studenti hanno punteggi superiori a 25?\n\n\n\nEsercizi sulle Operazioni tra Eventi\n\n\nUnione di Eventi\nDefiniamo due eventi:\n\n\nA: “Il punteggio SWLS è superiore a 25”.\n\n\nC: “Il punteggio SWLS è inferiore a 15”.\n\nScrivi l’evento A ∪ C (“Lo studente ha un punteggio maggiore di 25 o minore di 15”).\nSe nel campione di 15 studenti, 4 studenti hanno punteggi superiori a 25 e 3 hanno punteggi inferiori a 15, qual è la proporzione empirica di A ∪ C?\n\n\n\nIntersezione di Eventi e Eventi Disgiunti\nSupponiamo che l’evento D sia: “Uno studente ha un punteggio pari a 20”.\n\nL’evento D e l’evento A sono disgiunti?\nSe nessuno degli studenti ha ottenuto esattamente 20, qual è la probabilità empirica di A ∩ D?\n\n\n\nEsercizi sulle Regole della Probabilità 6. Probabilità dell’Unione di Eventi\nSupponiamo di avere:\n\n\nP(A) = 0.3 (probabilità che un punteggio sia superiore a 25).\n\n\nP(C) = 0.2 (probabilità che un punteggio sia inferiore a 15).\n\n\nP(A ∩ C) = 0 (perché un punteggio non può essere contemporaneamente superiore a 25 e inferiore a 15).\n\nUsa la regola dell’unione per calcolare P(A ∪ C).\n\n\n\nProbabilità Condizionata\nConsideriamo:\n\n\nP(A) = 0.3 (probabilità che un punteggio sia superiore a 25).\n\n\nP(E) = 0.5 (probabilità che uno studente abbia più di 20 anni).\n\n\nP(A | E) = 0.4 (probabilità che un soggetto con più di 20 anni abbia un punteggio superiore a 25).\n\nUsa la formula della probabilità condizionata per calcolare P(A ∩ E).\n\n\n\nEsercizi su Permutazioni e Combinazioni\n\n\nSelezione Casuale di Studenti\nDal campione di 15 studenti, supponiamo di voler selezionare casualmente 3 studenti per partecipare a un’intervista sulla loro soddisfazione di vita.\n\nQuanti modi ci sono per selezionare 3 studenti su 15?\n\n\n\nOrdinare gli Studenti per Discussione\nSupponiamo di voler formare un piccolo gruppo di discussione con 3 studenti, scegliendoli in ordine di intervento.\n\nQuante diverse sequenze di 3 studenti possiamo ottenere?\n\n\nFormare Coppie di Studenti\nSe vogliamo formare coppie di studenti per un esercizio collaborativo, senza considerare l’ordine, quanti modi ci sono per farlo?\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Definizione dello Spazio Campionario\n\n\nLo spazio campionario \\(\\Omega\\) per questo esperimento è l’insieme di tutti i possibili punteggi della Satisfaction with Life Scale (SWLS), quindi:\n\\[ \\Omega = \\{5, 6, 7, ..., 35\\} \\]\n\nSe abbiamo raccolto i dati di 15 studenti con punteggi osservati \\(\\{27, 21, 15, 30, 18, 23, 26, 35, 20, 22, 19, 25, 32, 29, 28\\}\\), possiamo considerare \\(\\Omega\\) come questo insieme specifico.\n\n2. Definizione di un Evento\n\n\nL’evento \\(A\\) “Uno studente ha un punteggio SWLS superiore a 25” è il sottoinsieme:\n\\[ A = \\{27, 30, 26, 35, 32, 29, 28\\}\\]\n\n\nSe 7 studenti su 15 hanno punteggi superiori a 25, la probabilità empirica è:\n\\[ P(A) = \\frac{7}{15} = 0.467 \\]\n\n\n3. Eventi Complementari\n\n\nL’evento complementare \\(B\\) “Uno studente ha un punteggio SWLS inferiore o uguale a 25” è:\n\\[ B = \\{21, 15, 18, 23, 20, 22, 19, 25\\}\\]\n\n\nSe 8 studenti su 15 rientrano in \\(B\\), la probabilità empirica è:\n\\[ P(B) = 1 - P(A) = \\frac{8}{15} = 0.533 \\]\n\n\nSoluzioni agli Esercizi sulle Operazioni tra Eventi\n4. Unione di Eventi\n\n\nL’evento \\(A \\cup C\\) (“Lo studente ha un punteggio maggiore di 25 o minore di 15”) è:\n\\[ A \\cup C = \\{27, 30, 26, 35, 32, 29, 28, 15\\}\\]\n\n\nSe 8 studenti su 15 appartengono a \\(A \\cup C\\), la probabilità empirica è:\n\\[ P(A \\cup C) = \\frac{8}{15} = 0.533 \\]\n\n\n5. Intersezione di Eventi e Eventi Disgiunti\n\nL’evento \\(D\\) “Uno studente ha un punteggio pari a 20” è \\(D = \\{20\\}\\).\n\nL’evento \\(A \\cap D\\) è l’insieme degli elementi comuni a \\(A\\) e \\(D\\), ma \\(D\\) non ha elementi in \\(A\\), quindi:\n\\[ A \\cap D = \\emptyset \\]\n\nEssendo \\(A \\cap D = \\emptyset\\), gli eventi sono disgiunti e \\(P(A \\cap D) = 0\\).\n\nSoluzioni agli Esercizi sulle Regole della Probabilità\n6. Probabilità dell’Unione di Eventi\nUsiamo la formula:\n\\[ P(A \\cup C) = P(A) + P(C) - P(A \\cap C) \\]\nDato che \\(P(A \\cap C) = 0\\), abbiamo:\n\\[ P(A \\cup C) = 0.3 + 0.2 - 0 = 0.5 \\]\n7. Probabilità Condizionata\nLa probabilità congiunta \\(P(A \\cap E)\\) si calcola con:\n\\[ P(A \\cap E) = P(A | E) \\cdot P(E) \\]\nSostituendo i valori:\n\\[ P(A \\cap E) = 0.4 \\times 0.5 = 0.2 \\]\nSoluzioni agli Esercizi su Permutazioni e Combinazioni\n8. Selezione Casuale di Studenti\nIl numero di modi per scegliere 3 studenti su 15 (combinazioni) è:\n\\[ C_{15,3} = \\frac{15!}{3!(15-3)!} = \\frac{15!}{3!12!} = \\frac{15 \\times 14 \\times 13}{3 \\times 2 \\times 1} = 455 \\]\n9. Ordinare gli Studenti per Discussione\nIl numero di modi per scegliere e ordinare 3 studenti su 15 (disposizioni) è:\n\\[ D_{15,3} = \\frac{15!}{(15-3)!} = \\frac{15!}{12!} = 15 \\times 14 \\times 13 = 2730 \\]\n10. Formare Coppie di Studenti\nIl numero di modi per formare coppie (combinazioni di 2 studenti su 15) è:\n\\[ C_{15,2} = \\frac{15!}{2!(15-2)!} = \\frac{15 \\times 14}{2 \\times 1} = 105 \\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#bibliografia",
    "href": "chapters/probability/02_probability_models.html#bibliografia",
    "title": "25  Modelli probabilistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html",
    "href": "chapters/probability/03_prob_spaces.html",
    "title": "26  Misura di Probabilità",
    "section": "",
    "text": "26.1 Introduzione\nNel capitolo Capitolo 25 abbiamo definito la probabilità come una funzione che assegna a ciascun evento un valore compreso tra 0 e 1, rispettando i seguenti principi:\nTuttavia, non abbiamo ancora approfondito il significato dei numeri che chiamiamo “probabilità”. In questo capitolo, adotteremo un’interpretazione bayesiana, in cui la probabilità rappresenta il grado di certezza soggettiva che attribuiamo al verificarsi di un evento o alla veridicità di una proposizione. In altre parole, immagineremo di avere una certezza totale, pari a 1, da distribuire tra i possibili esiti di una situazione. Questo approccio ci permetterà di dare un’interpretazione formale alle idee introdotte nel Capitolo 24.\nPer questa trattazione, faremo riferimento al lavoro di Michael Betancourt. Il testo che segue rappresenta una versione semplificata del suo approccio e si articola in due parti principali: la prima parte è dedicata alla nozione di spazio campionario e di eventi, mentre la seconda si concentra sull’interpretazione della probabilità come distribuzione della nostra certezza soggettiva.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#introduzione",
    "href": "chapters/probability/03_prob_spaces.html#introduzione",
    "title": "26  Misura di Probabilità",
    "section": "",
    "text": "per ogni evento \\(A\\), vale \\(0 \\leq P(A) \\leq 1\\);\nla probabilità dell’intero spazio campionario è 1: \\(P(\\Omega) = 1\\);\nse \\(A_1, A_2, \\dots\\) sono eventi disgiunti (cioè, senza elementi in comune), allora \\[\nP\\Bigl(\\bigcup_{i} A_i\\Bigr) = \\sum_{i} P(A_i).\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#insiemi-finiti",
    "href": "chapters/probability/03_prob_spaces.html#insiemi-finiti",
    "title": "26  Misura di Probabilità",
    "section": "26.2 Insiemi Finiti",
    "text": "26.2 Insiemi Finiti\nPer semplificare le idee iniziali, consideriamo uno spazio campionario composto da un numero finito di elementi.\nUn insieme finito è costituito da un numero limitato di elementi distinti:\n\\[\nX = \\{x_1, \\dots, x_N\\}.\n\\]\nL’indice numerico serve semplicemente a distinguere i \\(N\\) elementi, senza implicare alcun ordine particolare. Ad esempio, per evitare ogni presunzione di ordinamento, si può utilizzare il seguente insieme arbitrario di cinque elementi:\n\\[\nX = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}.\n\\]\n\n\n\n\n\n\nFigura 26.1: Un insieme finito contiene un numero finito di elementi. Questo particolare insieme ne contiene cinque.\n\n\n\nNelle applicazioni, gli elementi astratti \\(x_n\\) rappresentano oggetti concreti. Quando l’insieme \\(X\\) include tutti gli oggetti di interesse in una data situazione, lo definiamo spazio campionario. Una volta definito, possiamo organizzare e manipolare i suoi elementi in diversi modi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#sottoinsiemi",
    "href": "chapters/probability/03_prob_spaces.html#sottoinsiemi",
    "title": "26  Misura di Probabilità",
    "section": "26.3 Sottoinsiemi",
    "text": "26.3 Sottoinsiemi\nUn sottoinsieme di \\(X\\) è una collezione (cioè, un insieme) di alcuni degli elementi di \\(X\\). Per evitare ambiguità, useremo le lettere romane minuscole \\(x\\) per indicare un elemento variabile in \\(X\\), mentre useremo caratteri sans serif, ad esempio \\(\\mathsf{x}\\), per indicare un sottoinsieme variabile.\nAd esempio, se\n\\[\n\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\},\n\\]\nallora \\(\\mathsf{x}\\) è un sottoinsieme di\n\\[\nX = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}.\n\\]\nÈ importante notare che nel concetto di sottoinsieme non si parla di molteplicità: un elemento può appartenere o non appartenere al sottoinsieme, ma non può essere contato più volte.\n\n\n\n\n\n\nFigura 26.2: Un sottoinsieme \\(\\mathsf{x} \\subset X\\) è qualsiasi collezione di elementi dallo spazio campionario \\(X\\). Qui \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) contiene solo tre dei cinque elementi in \\(X\\).\n\n\n\nSe \\(\\mathsf{x}\\) è un sottoinsieme di \\(X\\), scriviamo \\(\\mathsf{x} \\subset X\\). Quando \\(\\mathsf{x}\\) coincide con l’intero insieme, ovvero \\(\\mathsf{x} = X\\), possiamo anche scrivere \\(\\mathsf{x} \\subseteq X\\).\nIndipendentemente dal numero di elementi di \\(X\\), esistono alcuni sottoinsiemi particolari: - insieme vuoto: \\(\\emptyset = \\{\\}\\), che non contiene alcun elemento; - sottoinsiemi atomici: insiemi che contengono un solo elemento, scritti ad esempio come \\(\\{x_n\\}\\); - l’intero insieme: \\(X\\) stesso.\nInoltre, sappiamo che il numero di modi per scegliere \\(n\\) elementi da un insieme finito di \\(N\\) elementi è dato dal coefficiente binomiale\n\\[\n{N \\choose n} = \\frac{N!}{n!(N - n)!}.\n\\]\nAd esempio:\n\nEsiste un solo sottoinsieme di dimensione zero (l’insieme vuoto):\n\\[\n{N \\choose 0} = 1.\n\\]\nEsiste un solo sottoinsieme di dimensione \\(N\\) (l’insieme \\(X\\)):\n\\[\n{N \\choose N} = 1.\n\\]\nEsistono \\(N\\) sottoinsiemi atomici (ognuno contenente un solo elemento):\n\\[\n{N \\choose 1} = N.\n\\]\n\nContando tutti i sottoinsiemi (per ogni possibile dimensione \\(n = 0, 1, \\dots, N\\)) si ottiene\n\\[\n\\sum_{n=0}^{N} {N \\choose n} = 2^N.\n\\]\nLa collezione di tutti i sottoinsiemi di \\(X\\), detta insieme potenza e indicata con \\(2^X\\), è a sua volta un insieme finito con \\(2^N\\) elementi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "href": "chapters/probability/03_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "title": "26  Misura di Probabilità",
    "section": "26.4 Operazioni sui Sottoinsiemi",
    "text": "26.4 Operazioni sui Sottoinsiemi\nOltre a costruire sottoinsiemi “elemento per elemento”, possiamo ottenere nuovi sottoinsiemi combinando quelli già esistenti.\n\n26.4.1 Complemento\nIl complemento di un sottoinsieme \\(\\mathsf{x} \\subset X\\) è l’insieme di tutti gli elementi di \\(X\\) che non appartengono a \\(\\mathsf{x}\\). Ad esempio, se\n\\[\n\\mathsf{x} = \\{ \\diamondsuit \\},\n\\]\nallora il complemento è\n\\[\n\\mathsf{x}^c = \\{ \\Box, \\clubsuit, \\heartsuit, \\spadesuit \\}.\n\\]\nPer definizione, il complemento dell’insieme vuoto è l’intero insieme (\\(\\emptyset^c = X\\)), mentre il complemento di \\(X\\) è l’insieme vuoto (\\(X^c = \\emptyset\\)).\n\n\n\n\n\n\nFigura 26.3: Il complemento di un sottoinsieme \\(\\mathsf{x}\\) è il sottoinsieme \\(\\mathsf{x}^{c}\\) costituito da tutti gli elementi dello spazio campionario che non sono in \\(\\mathsf{x}\\).\n\n\n\n\n\n26.4.2 Unione e Intersezione\nData una collezione di sottoinsiemi, possiamo combinarli in altri modi.\n\nUnione:\nL’unione di due sottoinsiemi \\(\\mathsf{x}_1\\) e \\(\\mathsf{x}_2\\) è l’insieme di tutti gli elementi che appartengono ad almeno uno dei due:\n\\[\n\\mathsf{x}_1 \\cup \\mathsf{x}_2.\n\\]\nAd esempio, se\n\\[\n\\mathsf{x}_1 = \\{\\Box, \\heartsuit\\} \\quad \\text{e} \\quad \\mathsf{x}_2 = \\{\\Box, \\spadesuit\\},\n\\]\nallora\n\\[\n\\mathsf{x}_1 \\cup \\mathsf{x}_2 = \\{\\Box, \\heartsuit, \\spadesuit\\}.\n\\]\nIntersezione:\nL’intersezione di due sottoinsiemi è l’insieme degli elementi che appartengono a entrambi:\n\\[\n\\mathsf{x}_1 \\cap \\mathsf{x}_2.\n\\]\nNell’esempio precedente,\n\\[\n\\mathsf{x}_1 \\cap \\mathsf{x}_2 = \\{\\Box\\}.\n\\]\n\n\n\nDue sottoinsiemi sono disgiunti se non hanno elementi in comune, cioè\n\\[\n\\mathsf{x}_1 \\cap \\mathsf{x}_2 = \\emptyset.\n\\]\nInoltre, si osserva che:\n\nL’unione (o intersezione) di un sottoinsieme con se stesso è il sottoinsieme stesso:\n\\[\n\\mathsf{x} \\cup \\mathsf{x} = \\mathsf{x} \\quad \\text{e} \\quad \\mathsf{x} \\cap \\mathsf{x} = \\mathsf{x}.\n\\]\nL’unione di un sottoinsieme con l’insieme vuoto lascia inalterato il sottoinsieme:\n\\[\n\\mathsf{x} \\cup \\emptyset = \\emptyset \\cup \\mathsf{x} = \\mathsf{x},\n\\]\nmentre la sua intersezione con l’insieme vuoto è sempre l’insieme vuoto:\n\\[\n\\mathsf{x} \\cap \\emptyset = \\emptyset \\cap \\mathsf{x} = \\emptyset.\n\\]\nL’unione di un sottoinsieme con l’intero insieme \\(X\\) dà \\(X\\), mentre l’intersezione di un sottoinsieme con \\(X\\) restituisce il sottoinsieme stesso:\n\\[\n\\mathsf{x} \\cup X = X, \\qquad \\mathsf{x} \\cap X = \\mathsf{x}.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#distribuzione-della-certezza-soggettiva-sugli-elementi",
    "href": "chapters/probability/03_prob_spaces.html#distribuzione-della-certezza-soggettiva-sugli-elementi",
    "title": "26  Misura di Probabilità",
    "section": "26.5 Distribuzione della Certezza Soggettiva sugli Elementi",
    "text": "26.5 Distribuzione della Certezza Soggettiva sugli Elementi\nIn un approccio bayesiano la probabilità rappresenta il grado di certezza soggettiva che attribuiamo al verificarsi di un certo evento. Immaginiamo di possedere una certezza totale pari a 1, che corrisponde alla nostra convinzione complessiva che, tra tutti gli esiti possibili, qualcosa avverrà. Questa certezza totale deve essere ripartita tra i diversi eventi.\nConsideriamo nuovamente lo spazio campionario dimostrativo:\n\\[\nX = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}.\n\\]\nAd ogni elemento \\(x_n \\in X\\) associamo un valore \\(p_n \\geq 0\\), interpretato come la frazione della nostra certezza totale che assegnamo a quell’evento. Poiché la certezza complessiva è 1, la somma dei valori deve essere:\n\\[\np_{\\Box} + p_{\\clubsuit} + p_{\\diamondsuit} + p_{\\heartsuit} + p_{\\spadesuit} = 1.\n\\]\nQuesta collezione \\(\\{ p_{\\Box}, p_{\\clubsuit}, p_{\\diamondsuit}, p_{\\heartsuit}, p_{\\spadesuit} \\}\\), in cui ciascun valore è compreso tra 0 e 1, è quella che chiamiamo distribuzione di probabilità. Ogni \\(p_n\\) esprime il grado di certezza (in termini relativi) che attribuiamo all’evento corrispondente a \\(x_n\\).\n\n\n\n\n\n\nFigura 26.4: Un’allocazione proporzionale è anche conosciuta come distribuzione di probabilità.\n\n\n\nQuesta visione ci permette di passare da una certezza assoluta (1) a una distribuzione in cui la certezza è divisa in porzioni proporzionali tra i vari eventi. Per esempio, se siamo particolarmente convinti che l’evento \\(\\Box\\) si verifichi, potremmo assegnargli un valore alto, mentre a un evento meno probabile corrisponderà un valore più basso.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#distribuzione-della-certezza-sugli-sottoinsiemi",
    "href": "chapters/probability/03_prob_spaces.html#distribuzione-della-certezza-sugli-sottoinsiemi",
    "title": "26  Misura di Probabilità",
    "section": "26.6 Distribuzione della Certezza Sugli Sottoinsiemi",
    "text": "26.6 Distribuzione della Certezza Sugli Sottoinsiemi\nUna volta che abbiamo assegnato un grado di certezza soggettiva a ciascun elemento di \\(X\\), possiamo estendere questa assegnazione a qualsiasi sottoinsieme di \\(X\\). In altre parole, se ad ogni elemento \\(x_n \\in X\\) assegniamo la probabilità (cioè, il grado di certezza) \\(p_n\\), la certezza complessiva che un sottoinsieme \\(\\mathsf{x} \\subset X\\) si realizzi è data dalla somma dei gradi di certezza dei suoi elementi:\n\\[\nP(\\mathsf{x}) = \\sum_{x_n \\in \\mathsf{x}} p_n.\n\\]\nPer costruzione, valgono le seguenti proprietà:\n\nLa certezza associata all’insieme vuoto è zero:\n\\[\nP(\\emptyset) = 0.\n\\]\nLa certezza associata all’intero spazio campionario è 1:\n\\[\nP(X) = \\sum_{n} p_n = 1.\n\\]\n\nQueste proprietà sono in linea con l’idea che la nostra certezza totale (pari a 1) venga completamente distribuita tra tutti gli eventi possibili.\n\n26.6.1 Additività\nSe un sottoinsieme può essere suddiviso in parti che non si sovrappongono, il grado di certezza dell’intero sottoinsieme è la somma dei gradi di certezza delle parti. Ad esempio, se \\(\\mathsf{x}_1\\) e \\(\\mathsf{x}_2\\) sono sottoinsiemi disgiunti (cioè, non hanno elementi in comune), allora:\n\\[\nP(\\mathsf{x}_1 \\cup \\mathsf{x}_2) = P(\\mathsf{x}_1) + P(\\mathsf{x}_2).\n\\]\nIn particolare, se \\(\\mathsf{x}\\) è un sottoinsieme di \\(X\\), il complemento \\(\\mathsf{x}^c\\) (cioè, tutti gli elementi non in \\(\\mathsf{x}\\)) è disgiunto da \\(\\mathsf{x}\\) e la loro unione dà \\(X\\). Quindi:\n\\[\nP(\\mathsf{x}) + P(\\mathsf{x}^c) = 1 \\quad \\Longrightarrow \\quad P(\\mathsf{x}^c) = 1 - P(\\mathsf{x}).\n\\]\n\n\n26.6.2 Sovrapposizione di Sottoinsiemi\nQuando due sottoinsiemi si sovrappongono, la certezza degli elementi comuni viene conteggiata in entrambe le somme. Per chiarire, consideriamo:\n\n\\(\\mathsf{x}_1 = \\{\\Box, \\heartsuit\\}\\),\n\\(\\mathsf{x}_2 = \\{\\Box, \\spadesuit\\}\\).\n\nAllora:\n\nLa certezza di \\(\\mathsf{x}_1\\) è \\(P(\\mathsf{x}_1) = p_{\\Box} + p_{\\heartsuit}\\).\nLa certezza di \\(\\mathsf{x}_2\\) è \\(P(\\mathsf{x}_2) = p_{\\Box} + p_{\\spadesuit}\\).\nL’intersezione è \\(\\mathsf{x}_1 \\cap \\mathsf{x}_2 = \\{\\Box\\}\\), con certezza \\(p_{\\Box}\\).\nL’unione è \\(\\mathsf{x}_1 \\cup \\mathsf{x}_2 = \\{\\Box, \\heartsuit, \\spadesuit\\}\\), con certezza\n\\[\nP(\\mathsf{x}_1 \\cup \\mathsf{x}_2) = p_{\\Box} + p_{\\heartsuit} + p_{\\spadesuit}.\n\\]\n\nNotiamo che:\n\\[\nP(\\mathsf{x}_1) + P(\\mathsf{x}_2) = P(\\mathsf{x}_1 \\cup \\mathsf{x}_2) + p_{\\Box} = P(\\mathsf{x}_1 \\cup \\mathsf{x}_2) + P(\\mathsf{x}_1 \\cap \\mathsf{x}_2).\n\\]\nQuesto è un esempio del principio di inclusione-esclusione, che garantisce che non contiamo più volte la certezza degli elementi comuni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#costruzione-delle-distribuzioni-di-certezza",
    "href": "chapters/probability/03_prob_spaces.html#costruzione-delle-distribuzioni-di-certezza",
    "title": "26  Misura di Probabilità",
    "section": "26.7 Costruzione delle Distribuzioni di Certezza",
    "text": "26.7 Costruzione delle Distribuzioni di Certezza\nEsistono diversi modi per “costruire” una distribuzione di certezza (cioè, una distribuzione di probabilità) su uno spazio finito \\(X\\):\n\nDistribuzione globale:\nPossiamo assegnare simultaneamente il grado di certezza a tutti gli elementi di \\(X\\). In questo approccio si specifica direttamente la distribuzione \\(\\{p(x_n)\\}\\) per ciascun \\(x_n \\in X\\), in modo tale che\n\\[\n\\sum_{x_n \\in X} p(x_n) = 1.\n\\]\n\n\n\n\n\n\n\nFigura 26.5: Le misure possono essere costruite specificando le allocazioni degli elementi individuali tutte insieme.\n\n\n\n\nDistribuzione locale:\nPossiamo assegnare il grado di certezza a ciascun elemento uno alla volta, procedendo in maniera sequenziale. Questo metodo ci permette di “costruire” la distribuzione gradualmente, concentrandoci su un elemento alla volta.\n\n\n\n\n\n\n\nFigura 26.6: Le misure possono essere costruite specificando le allocazioni degli elementi individuali uno alla volta.\n\n\n\n\nDistribuzione iterativa:\nUn altro metodo consiste nel suddividere lo spazio campionario in sottoinsiemi disgiunti, assegnare ad ognuno un certo grado di certezza, e poi ripartire iterativamente la certezza all’interno di ciascun sottoinsieme fino a raggiungere gli elementi individuali.\n\n\n\n\n\n\n\nFigura 26.7: Le misure possono essere costruite allocando la misura totale a sottoinsiemi disgiunti e poi raffinando iterativamente tale allocazione a sottoinsiemi sempre più piccoli.\n\n\n\n\n\nQuesta flessibilità consente di adattare l’approccio alle esigenze specifiche del problema in esame.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#riflessioni-conclusive",
    "href": "chapters/probability/03_prob_spaces.html#riflessioni-conclusive",
    "title": "26  Misura di Probabilità",
    "section": "26.8 Riflessioni Conclusive",
    "text": "26.8 Riflessioni Conclusive\nL’interpretazione della probabilità come grado di certezza soggettiva ci offre un modo intuitivo per ragionare su eventi incerti. La nostra certezza totale, pari a 1, viene distribuita tra i vari possibili esiti secondo una distribuzione di probabilità:\n\\[\n\\{p_1, p_2, \\dots, p_N\\} \\quad \\text{con} \\quad 0 \\leq p_n \\leq 1 \\quad \\text{e} \\quad \\sum_{n=1}^{N} p_n = 1.\n\\]\nOgni valore \\(p_n\\) rappresenta la frazione della nostra certezza che attribuiamo all’evento corrispondente a \\(x_n\\). Questo approccio è particolarmente utile in statistica bayesiana, dove le probabilità vengono interpretate non come frequenze oggettive, ma come gradi di convinzione soggettivi basati sulle informazioni a nostra disposizione.\nComprendere questi concetti è essenziale per applicare in modo coerente la teoria della probabilità e per interpretare correttamente i modelli statistici, soprattutto in contesti in cui le informazioni sono incomplete o incerte.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#esercizi",
    "href": "chapters/probability/03_prob_spaces.html#esercizi",
    "title": "26  Misura di Probabilità",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nEsercizi\n\n\n\n\n\nDal testo di Blitzstein & Hwang (2019), svolgere i seguenti esercizi: 1.4.3, 1.4.4, 1.4.5, 1.4.6, 1.4.9, 1.4.12, 1.4.13.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#bibliografia",
    "href": "chapters/probability/03_prob_spaces.html#bibliografia",
    "title": "26  Misura di Probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html",
    "href": "chapters/probability/04_sigma-algebra.html",
    "title": "27  Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov",
    "section": "",
    "text": "27.1 Introduzione\nNel Capitolo 26 abbiamo visto come definire la probabilità su insiemi finiti, ossia in situazioni dove ci sono un numero limitato di esiti (ad esempio, i risultati di un lancio di dado). In quel contesto, la probabilità di ogni evento veniva spesso assegnata contando i casi favorevoli su quelli totali.\nTuttavia, in molti casi reali, lo spazio degli esiti non è finito, ma infinito (ad esempio, l’insieme degli interi, o addirittura la retta reale). In queste situazioni, la somma dei casi favorevoli su quelli totali non ha più senso o diventa tecnicamente inapplicabile. Per passare dal caso discreto a quello continuo, abbiamo quindi bisogno di strumenti più sofisticati.\nUno di questi strumenti è la \\(\\sigma\\)-algebra, che ci aiuta a definire in maniera rigorosa quali sottoinsiemi di uno spazio possiamo considerare “misurabili” e a cui possiamo assegnare una probabilità. In combinazione con gli assiomi di Kolmogorov, la \\(\\sigma\\)-algebra permette di estendere la teoria della probabilità dal caso discreto (già discusso) al caso continuo, dove la situazione è più delicata e non tutti i sottoinsiemi possono ricevere una probabilità.\nIn questo capitolo, dunque, approfondiremo:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#introduzione",
    "href": "chapters/probability/04_sigma-algebra.html#introduzione",
    "title": "27  Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov",
    "section": "",
    "text": "perché non possiamo sempre “misurare tutto” nello spazio continuo;\ncome la \\(\\sigma\\)-algebra di Borel ci fornisce un metodo standard per assegnare probabilità negli spazi continui;\nin che modo la struttura di \\(\\sigma\\)-algebra è cruciale per soddisfare gli assiomi di Kolmogorov;\nle differenze principali rispetto al caso discreto.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#le-proprietà-di-una-sigma-algebra",
    "href": "chapters/probability/04_sigma-algebra.html#le-proprietà-di-una-sigma-algebra",
    "title": "27  Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov",
    "section": "\n27.2 Le Proprietà di una \\(\\sigma\\)-Algebra",
    "text": "27.2 Le Proprietà di una \\(\\sigma\\)-Algebra\nLa \\(\\sigma\\)-algebra è un insieme di sottoinsiemi (chiamati eventi) che soddisfa alcune proprietà fondamentali e che rende possibile l’assegnazione di probabilità in modo coerente.\n\nSpazio campionario: chiamiamo \\(\\Omega\\) l’insieme di tutti i possibili esiti (o risultati) di un esperimento.\n\n\\(\\sigma\\)-algebra: chiamiamo \\(\\mathcal{F}\\) una collezione di sottoinsiemi di \\(\\Omega\\) (eventi) tale che:\n\nInclusione dello spazio campionario:\\[\n\\Omega \\in \\mathcal{F}.\n\\]\nSignifica che l’evento “qualcosa accade” è sempre misurabile.\nChiusura rispetto al complemento:\\[\n\\text{Se } A \\in \\mathcal{F} \\text{ allora } A^c = \\Omega \\setminus A \\in \\mathcal{F}.\n\\]\nSe possiamo misurare la probabilità di un evento, dobbiamo anche poter misurare la probabilità che l’evento non accada.\nChiusura rispetto a unioni (anche numerabili):\\[\n\\text{Se } A_1, A_2, \\dots \\in \\mathcal{F}, \\text{ allora } \\bigcup_{i=1}^{\\infty} A_i \\in \\mathcal{F}.\n\\]\nSe possiamo misurare una collezione (anche infinita) di eventi, dobbiamo poter misurare anche l’evento “almeno uno di essi si verifica”.\n\n\n\nTali proprietà non sono un semplice dettaglio tecnico, ma garantiscono la coerenza del sistema probabilistico: ci assicurano che certe operazioni sugli eventi (complementi, unioni) non producano risultati “senza senso” per la probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#relazione-tra-la-sigma-algebra-e-gli-assiomi-di-kolmogorov",
    "href": "chapters/probability/04_sigma-algebra.html#relazione-tra-la-sigma-algebra-e-gli-assiomi-di-kolmogorov",
    "title": "27  Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov",
    "section": "\n27.3 Relazione tra la \\(\\sigma\\)-algebra e gli Assiomi di Kolmogorov",
    "text": "27.3 Relazione tra la \\(\\sigma\\)-algebra e gli Assiomi di Kolmogorov\nPer definire rigorosamente una probabilità, abbiamo bisogno di una funzione \\[\nP: \\mathcal{F} \\to [0,1]\n\\] che soddisfi gli assiomi di Kolmogorov:\n\nNon negatività:\\[\nP(A) \\ge 0 \\quad \\text{per tutti } A \\in \\mathcal{F}.\n\\]\nNormalizzazione:\\[\nP(\\Omega) = 1.\n\\]\nAdditività numerabile:\\[\n\\text{Se } A_1, A_2, \\dots \\in \\mathcal{F} \\text{ sono eventi a due a due disgiunti, allora }\nP\\Bigl(\\bigcup_{i=1}^{\\infty} A_i \\Bigr)\n= \\sum_{i=1}^{\\infty} P(A_i).\n\\]\n\nQuesti assiomi si basano sul fatto che tutti gli insiemi (eventi) menzionati devono appartenere a \\(\\mathcal{F}\\). In particolare, l’additività numerabile richiede di poter fare operazioni di unione infinita fra insiemi che sono (o dovrebbero essere) misurabili. Se non imponessimo le proprietà della \\(\\sigma\\)-algebra (specie la chiusura per unioni numerabili), non potremmo neanche parlare di \\(P\\bigl(\\bigcup_i A_i\\bigr)\\) per unioni infinite, perché non saremmo certi che tale unione appartenga ancora alla collezione degli eventi “ammissibili”.\nIn sintesi:\n\nLa \\(\\sigma\\)-algebra stabilisce quali eventi sono “ammissibili”, cioè per quali insiemi \\(P(\\cdot)\\) è definita.\nGli assiomi di Kolmogorov fissano le proprietà che questa funzione \\(P\\) deve avere, ma per far sì che \\(P\\) possa essere coerentemente definita su tutte le possibili combinazioni (unioni, complementi, ecc.) degli eventi, dobbiamo essere sicuri che tali combinazioni siano ancora “nell’elenco” degli eventi ammessi. Questo è esattamente il ruolo della chiusura delle \\(\\sigma\\)-algebre.\n\nSenza la struttura di \\(\\sigma\\)-algebra, l’assioma di additività numerabile — punto cardine del formalismo di Kolmogorov — non potrebbe neanche venire enunciato in modo rigoroso.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#spazio-misurabile",
    "href": "chapters/probability/04_sigma-algebra.html#spazio-misurabile",
    "title": "27  Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov",
    "section": "\n27.4 Spazio Misurabile",
    "text": "27.4 Spazio Misurabile\nUno spazio misurabile è una coppia \\((\\Omega, \\mathcal{F})\\) dove:\n\n\n\\(\\Omega\\) è lo spazio campionario (insieme di tutti i possibili esiti);\n\n\\(\\mathcal{F}\\) è una \\(\\sigma\\)-algebra su \\(\\Omega\\), ossia un insieme di “eventi ammissibili” che rispettano le proprietà viste sopra.\n\nUna volta definito lo spazio misurabile, possiamo introdurre la funzione di probabilità \\(P\\) che associa a ciascun evento in \\(\\mathcal{F}\\) un valore compreso tra 0 e 1, in accordo con gli assiomi di Kolmogorov.\n\n27.4.1 Esempio: Costruzione di una \\(\\sigma\\)-Algebra Discreta\nCaso discreto: \\(\\Omega = \\{1,2,3\\}\\).\n\nLa \\(\\sigma\\)-algebra discreta coincide con l’insieme di tutte le parti di \\(\\Omega\\): \\[\n  \\mathcal{F} = \\bigl\\{\\varnothing, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\Omega \\bigr\\}.\n\\]\n\nVerifiche:\n\n\n\\(\\Omega\\in\\mathcal{F}\\) e \\(\\varnothing\\in\\mathcal{F}\\).\n\nSe \\(\\{1,2\\}\\in \\mathcal{F}\\), allora il suo complemento \\(\\{3\\}\\) è in \\(\\mathcal{F}\\). Stessa cosa per tutti gli altri sottoinsiemi.\n\nL’unione di sottoinsiemi di \\(\\Omega\\) è ancora un sottoinsieme di \\(\\Omega\\), e quindi appartiene a \\(\\mathcal{F}\\).\n\n\nInterpretazione: qualunque sottoinsieme di \\(\\{1,2,3\\}\\) è un evento misurabile. Ad esempio, “esce \\(1\\) o \\(2\\)” oppure “non esce \\(3\\)”.\nFunzione di probabilità: un esempio è “dado equo”: \\[\nP(\\{1\\}) = P(\\{2\\}) = P(\\{3\\}) = \\tfrac13,\n\\quad\nP(\\{1,2\\}) = \\tfrac23,\n\\quad\nP(\\Omega) = 1,\n\\quad\nP(\\varnothing)=0.\n\\]\n\nNel caso discreto, la costruzione della \\(\\sigma\\)-algebra è abbastanza semplice: includere tutti i sottoinsiemi non crea alcun problema, e anzi risulta “naturale” per poter applicare gli assiomi di Kolmogorov a qualunque evento si desideri.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#dal-discreto-al-continuo-differenze-fondamentali",
    "href": "chapters/probability/04_sigma-algebra.html#dal-discreto-al-continuo-differenze-fondamentali",
    "title": "27  Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov",
    "section": "\n27.5 Dal Discreto al Continuo: Differenze Fondamentali",
    "text": "27.5 Dal Discreto al Continuo: Differenze Fondamentali\nDopo aver introdotto il concetto di \\(\\sigma\\)-algebra e aver discusso il suo ruolo chiave per gli assiomi di Kolmogorov, possiamo ora esplorare le differenze fondamentali tra il caso discreto e quello continuo.\n\n27.5.1 Caso Discreto\nQuando lo spazio campionario \\(\\Omega\\) è finito o infinitamente numerabile (ad esempio, \\(\\{1, 2, 3, \\dots\\}\\)), è possibile includere tutti i sottoinsiemi di \\(\\Omega\\) nella \\(\\sigma\\)-algebra (ossia prendere l’intera algebra delle parti di \\(\\Omega\\)). In questo contesto, ogni singolo punto può essere misurato, e le proprietà della \\(\\sigma\\)-algebra sono sempre rispettate. Gli assiomi di Kolmogorov possono quindi essere applicati senza difficoltà.\n\n27.5.2 Caso Continuo\nNel caso continuo, ad esempio quando \\(\\Omega = [0,1]\\) o \\(\\Omega = \\mathbb{R}\\), la situazione è più complessa. Non è sempre possibile includere tutti i sottoinsiemi di \\(\\Omega\\) nella \\(\\sigma\\)-algebra senza incorrere in contraddizioni logiche o paradossi. Un esempio celebre è il paradosso di Vitali, che dimostra come alcuni sottoinsiemi non possano essere misurati in modo coerente.\n\n27.5.3 \\(\\sigma\\)-algebra di Borel\nPer evitare tali paradossi, nel caso continuo si utilizza la \\(\\sigma\\)-algebra di Borel. Questa \\(\\sigma\\)-algebra include solo i sottoinsiemi di \\(\\Omega\\) che sono “ben misurabili”, escludendo quelli che potrebbero portare a contraddizioni. Ad esempio, l’insieme di Vitali non è misurabile secondo questa definizione.\n\n27.5.4 Tabella di Confronto\n\n\n\n\n\n\n\nCaratteristica\nCaso Discreto\nCaso Continuo\n\n\n\nStruttura di \\(\\Omega\\)\nFinito o enumerabile \\(\\{1,2,\\dots\\}\\)\n\nNon numerabile \\(\\mathbb{R}\\), \\([0,1]\\), ecc.\n\n\n\\(\\sigma\\)-algebra “naturale”\nL’insieme di tutte le parti di \\(\\Omega\\)\n\n\n\\(\\sigma\\)-algebra di Borel (non include ogni sottoinsieme)\n\n\nEsempio di evento tipico\n\n\\(\\{\\omega\\}\\), \\(\\{\\omega_1,\\omega_2\\}\\)\n\n\n\\([a,b]\\), \\((-\\infty, 0]\\), unione di intervalli, ecc.\n\n\nProb. di un singolo punto\nPuò essere &gt; 0 (ad es. \\(P(\\{\\omega\\})=1/6\\))\nSpesso 0 (se il fenomeno è “continuo”)\n\n\nParadossi/Problemi di misura\nRaramente si presentano\nNecessari concetti di misurabilità (es. insiemi di Vitali)\n\n\n\n\n\n\n\n\n\nDifficoltà nel Caso Continuo\n\n\n\n\n\nIl paradosso di Vitali illustra una delle principali difficoltà nel caso continuo. Consideriamo l’intervallo \\([0,1]\\) e raggruppiamo i suoi punti in classi di equivalenza basate sulla relazione: “due numeri sono equivalenti se la loro differenza è un numero razionale”. Selezionando un rappresentante da ogni classe di equivalenza, formiamo un insieme \\(V\\). Traslando \\(V\\) di tutte le possibili quantità razionali comprese in \\([-1,1]\\), otteniamo una contraddizione: le varie copie di \\(V\\) dovrebbero avere la stessa misura, ma la loro unione copre un intervallo di lunghezza 2, mentre la somma delle loro misure dovrebbe essere infinita o nulla. Questo dimostra che \\(V\\) non può essere misurabile.\n\n\n\n\n27.5.5 Costruzione della \\(\\sigma\\)-algebra di Borel\nPer costruire la \\(\\sigma\\)-algebra di Borel in \\([0,1]\\) o in \\(\\mathbb{R}\\), si parte dagli intervalli e si aggiungono tutte le unioni e intersezioni numerabili di questi intervalli. Questa procedura genera la più piccola collezione di sottoinsiemi che soddisfa le proprietà di una \\(\\sigma\\)-algebra.\n\n\nInclusi: Intervalli aperti, chiusi, segmenti, unioni di segmenti, ecc.\n\nEsclusi: Strutture “patologiche” come l’insieme di Vitali, che non possono essere misurate in modo coerente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#riflessioni-conclusive",
    "href": "chapters/probability/04_sigma-algebra.html#riflessioni-conclusive",
    "title": "27  Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov",
    "section": "\n27.6 Riflessioni Conclusive",
    "text": "27.6 Riflessioni Conclusive\n\n\nDal discreto al continuo\n\n\nCaso discreto: \\(\\Omega\\) è finito o numerabile; tutti i sottoinsiemi possono essere inclusi nella \\(\\sigma\\)-algebra, e ogni singolo punto può avere probabilità maggiore di zero.\n\n\nCaso continuo: \\(\\Omega\\) è infinito e non numerabile; per evitare paradossi, si lavora con \\(\\sigma\\)-algebre più ristrette (come quella di Borel). Non tutti i sottoinsiemi sono misurabili, e la probabilità di un punto singolo è zero.\n\n\nRuolo della \\(\\sigma\\)-algebra\nLa \\(\\sigma\\)-algebra garantisce la coerenza delle operazioni fondamentali (complementi, unioni, intersezioni) anche infinite. Se un evento è “ammissibile”, anche il suo complementare e le sue unioni con altri eventi ammissibili devono restare tali. Senza questa chiusura, il terzo assioma (additività numerabile) non potrebbe essere formalizzato correttamente.\nAssiomi di Kolmogorov\nQuesti assiomi definiscono un sistema di regole per calcolare le probabilità. Funzionano sia nel caso discreto sia in quello continuo, a patto di limitarsi agli eventi misurabili (ovvero ai sottoinsiemi inclusi nella \\(\\sigma\\)-algebra).\n\nApplicazioni pratiche\n\n\nCaso discreto: Lancio di dadi, urne con palline, processi di conteggio (ad esempio, il numero di risposte corrette in un test cognitivo).\n\n\nCaso continuo: Studio di variabili come altezza, peso, tempo di reazione in un compito cognitivo. In questo contesto, si parla più spesso di densità di probabilità (integrali, funzioni di ripartizione) anziché di probabilità “puntuali”.\n\n\n\nIn sintesi, la teoria della probabilità moderna si fonda sulla nozione di \\(\\sigma\\)-algebra e sugli assiomi di Kolmogorov. Questi strumenti permettono di trattare in maniera coerente sia i casi discreti più semplici, sia gli spazi continui più complessi. La \\(\\sigma\\)-algebra è la “base” che definisce quali eventi sono ammissibili, mentre gli assiomi di Kolmogorov ci dicono come calcolare la probabilità di tali eventi in modo da evitare contraddizioni (come i paradossi di misura) e costruire modelli probabilistici affidabili in una vasta gamma di contesti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#esercizi",
    "href": "chapters/probability/04_sigma-algebra.html#esercizi",
    "title": "27  Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov",
    "section": "\n27.7 Esercizi",
    "text": "27.7 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsidera i seguenti esercizi basati sulla Satisfaction with Life Scale (SWLS).\n\n\nQuali sottoinsiemi sono eventi ammissibili?\nSupponiamo che i punteggi SWLS raccolti siano numeri interi tra 5 e 35.\n\nTra i seguenti insiemi, quali potrebbero essere inclusi in una \\(\\sigma\\)-algebra su questo spazio campionario?\n\n\nA: Tutti gli studenti con punteggio pari o superiore a 25.\n\n\nB: Studenti con punteggio pari.\n\n\nC: Studenti con punteggio multiplo di 3.\n\n\nD: Studenti con punteggio superiore all’altezza media degli unicorni.\n\n\n\nQuale criterio potremmo usare per decidere se un insieme è ammissibile in una \\(\\sigma\\)-algebra?\n\n\n\nChiusura rispetto al complemento\nSe l’evento A rappresenta gli studenti con punteggio SWLS ≥ 25, quale sarà l’evento complementare Aᶜ?\n\nEsprimilo in termini di punteggi.\n\nSe il 40% degli studenti ha punteggi ≥ 25, qual è la probabilità empirica dell’evento Aᶜ?\n\n\n\nEsercizi sulle Operazioni tra Eventi 3. Unione di Eventi\nConsideriamo i seguenti eventi:\n\n\nB: “Studente ha un punteggio SWLS pari”.\n\n\nC: “Studente ha un punteggio multiplo di 3”.\n\nElenca i punteggi che appartengono a B ∪ C (cioè lo studente ha un punteggio pari o multiplo di 3).\n\nSe nel campione di 15 studenti, 8 hanno un punteggio in B e 5 in C, e 3 di essi appartengono a entrambi gli insiemi, calcola la probabilità empirica di B ∪ C usando la formula dell’unione.\n\n\n\nIntersezione e additività numerabile\n\nSe un evento D rappresenta gli studenti con punteggio ≥20 e ≤30, possiamo dire che è incluso nella \\(\\sigma\\)-algebra se B e C lo sono? Perché?\nCalcola l’intersezione B ∩ C e verifica se i dati raccolti rispettano l’additività.\n\n\n\nEsercizi sugli Assiomi di Kolmogorov 5. Assioma della Normalizzazione\n\nSupponiamo di assegnare probabilità a eventi definiti sui punteggi SWLS dei 15 studenti.\n\nSe la somma delle probabilità di tutti gli eventi possibili non è 1, cosa significa?\n\nDai un esempio di una distribuzione di probabilità su SWLS che rispetti la normalizzazione.\n\n\n\nAssioma dell’Additività\n\nSupponiamo che P(A) = 0.4 e P(Aᶜ) = 0.6.\n\nVerifica se questa distribuzione soddisfa l’assioma di Kolmogorov.\n\nSe introduciamo un terzo evento E (punteggi tra 15 e 20), come possiamo calcolare P(A ∪ E) rispettando gli assiomi?\n\n\n\nEsercizi su Spazi Misurabili e Applicazioni\n\n\nDefinire uno Spazio Misurabile\n\n\nConsideriamo lo spazio campionario \\(\\Omega\\) dei punteggi SWLS e la \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) formata dai sottoinsiemi:\n\n{Punteggi pari}\n\n{Punteggi multipli di 5}\n\n{Punteggi ≥ 25}\n\n\n\nQuesta collezione rispetta le condizioni di una \\(\\sigma\\)-algebra? Perché?\n\n\n\nEsempio di Probabilità in un Caso Continuo\n\nSe invece di punteggi discreti avessimo misurato il tempo di risposta a un questionario SWLS (espresso in secondi con valori reali), il modello discreto funzionerebbe?\n\nProva a descrivere un possibile evento misurabile in un caso continuo e spiega perché sarebbe più complesso da gestire rispetto al caso discreto.\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sottoinsiemi sono eventi ammissibili?\n\nGli insiemi che possono essere inclusi in una \\(\\sigma\\)-algebra devono essere chiusi rispetto a unioni, intersezioni e complementi.\n\nA (punteggi ≥ 25), B (punteggi pari), e C (punteggi multipli di 3) possono essere inclusi in una \\(\\sigma\\)-algebra, perché sono definiti su criteri chiari e permettono operazioni insiemistiche.\n\nD (punteggi superiori alla media degli unicorni) non è un evento misurabile, poiché dipende da valori soggettivi e non da una regola fissa applicabile all’intero spazio campionario.\n\n2. Chiusura rispetto al complemento\n\nL’evento complementare di A (punteggi ≥ 25) è Aᶜ (punteggi &lt; 25).\nSe la probabilità empirica di A è 0.4, la probabilità empirica di Aᶜ è: \\[ P(Aᶜ) = 1 - P(A) = 1 - 0.4 = 0.6 \\]\n\n\nSoluzioni agli Esercizi sulle Operazioni tra Eventi\n3. Unione di Eventi\n\nI punteggi in B sono {6, 8, 10, 12, …, 34} e quelli in C sono {6, 9, 12, …, 33}.\n\nB ∪ C è l’insieme {6, 8, 9, 10, 12, …, 34}.\nApplicando la formula dell’unione: \\[ P(B ∪ C) = P(B) + P(C) - P(B ∩ C) \\] \\[ P(B ∪ C) = \\frac{8}{15} + \\frac{5}{15} - \\frac{3}{15} = \\frac{10}{15} = 0.667 \\]\n\n\n4. Intersezione e additività numerabile\n\nL’evento D (20 ≤ SWLS ≤ 30) è un sottoinsieme di B ∪ C, quindi se B e C sono inclusi in una \\(\\sigma\\)-algebra, anche D lo sarà.\n\nB ∩ C (punteggi pari e multipli di 3) = {6, 12, 18, …}.\nDalla distribuzione empirica, P(B ∩ C) = \\(\\frac{3}{15} = 0.2\\).\n\nSoluzioni agli Esercizi sugli Assiomi di Kolmogorov\n5. Assioma della Normalizzazione\n\nSe la somma delle probabilità degli eventi possibili non è 1, significa che il sistema di probabilità è mal definito.\nEsempio corretto di distribuzione: \\[ P(A) = 0.4, P(B) = 0.3, P(Aᶜ) = 0.6, P(Bᶜ) = 0.7 \\] Tutti gli eventi coprono l’intero spazio campionario senza sovrapposizioni non gestite.\n\n6. Assioma dell’Additività\n\nSe P(A) = 0.4 e P(Aᶜ) = 0.6, allora: \\[ P(A) + P(Aᶜ) = 1 \\] Quindi gli assiomi di Kolmogorov sono rispettati.\nSe introduciamo un evento E (SWLS tra 15 e 20) con P(E) = 0.2, possiamo usare la formula dell’unione per calcolare P(A ∪ E) se A ed E non sono disgiunti.\n\nSoluzioni agli Esercizi su Spazi Misurabili e Applicazioni\n7. Definire uno Spazio Misurabile\n\nL’insieme \\(\\mathcal{F}\\) con {Punteggi pari, Punteggi multipli di 5, Punteggi ≥ 25} rispetta:\n\nInclusione di \\(\\Omega\\).\nChiusura rispetto al complemento.\nChiusura rispetto all’unione.\n\n\nQuindi è una \\(\\sigma\\)-algebra valida.\n\n8. Probabilità nel Caso Continuo\n\nSe misurassimo tempo di risposta al questionario SWLS in secondi (con valori reali), avremmo bisogno di una densità di probabilità anziché probabilità discrete.\nUn evento misurabile potrebbe essere: “Tempo di risposta compreso tra 10 e 15 secondi”.\nLa probabilità di un singolo valore (es. esattamente 12 secondi) sarebbe zero nel caso continuo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/04_sigma-algebra.html#informazioni-sullambiente-di-sviluppo",
    "title": "27  Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] VennDiagram_1.7.3   futile.logger_1.4.3 reshape2_1.4.4     \n#&gt;  [4] thematic_0.1.6      MetBrewer_0.2.0     ggokabeito_0.1.0   \n#&gt;  [7] see_0.10.0          gridExtra_2.3       patchwork_1.3.0    \n#&gt; [10] bayesplot_1.11.1    psych_2.4.12        scales_1.3.0       \n#&gt; [13] markdown_1.13       knitr_1.49          lubridate_1.9.4    \n#&gt; [16] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [19] purrr_1.0.4         readr_2.1.5         tidyr_1.3.1        \n#&gt; [22] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [25] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3       futile.options_1.0.1 stringi_1.8.4       \n#&gt;  [4] lattice_0.22-6       hms_1.1.3            digest_0.6.37       \n#&gt;  [7] magrittr_2.0.3       evaluate_1.0.3       timechange_0.3.0    \n#&gt; [10] fastmap_1.2.0        plyr_1.8.9           rprojroot_2.0.4     \n#&gt; [13] jsonlite_1.8.9       formatR_1.14         mnormt_2.1.1        \n#&gt; [16] cli_3.6.4            rlang_1.1.5          munsell_0.5.1       \n#&gt; [19] withr_3.0.2          tools_4.4.2          parallel_4.4.2      \n#&gt; [22] tzdb_0.4.0           colorspace_2.1-1     pacman_0.5.1        \n#&gt; [25] lambda.r_1.2.4       vctrs_0.6.5          R6_2.6.1            \n#&gt; [28] lifecycle_1.0.4      htmlwidgets_1.6.4    pkgconfig_2.0.3     \n#&gt; [31] pillar_1.10.1        gtable_0.3.6         Rcpp_1.0.14         \n#&gt; [34] glue_1.8.0           xfun_0.50            tidyselect_1.2.1    \n#&gt; [37] rstudioapi_0.17.1    farver_2.1.2         htmltools_0.5.8.1   \n#&gt; [40] nlme_3.1-167         rmarkdown_2.29       compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#bibliografia",
    "href": "chapters/probability/04_sigma-algebra.html#bibliografia",
    "title": "27  Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Dal Discreto al Continuo: Misurabilità e Assiomi di Kolmogorov</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html",
    "href": "chapters/probability/05_conditional_prob.html",
    "title": "28  Probabilità condizionata",
    "section": "",
    "text": "28.1 Introduzione\nLa probabilità condizionata si riferisce al calcolo della probabilità di un evento, tenendo conto che un altro evento si è già verificato. Questo concetto è cruciale perché riflette come aggiorniamo le nostre credenze alla luce di nuove evidenze o informazioni. Per esempio, immaginiamo di voler stimare la probabilità di pioggia per domani. La nostra stima iniziale cambia se oggi osserviamo un cielo nuvoloso. Il fatto che oggi sia nuvoloso “condiziona” la nostra valutazione della probabilità di pioggia per domani.\nQuesto processo di aggiornamento delle nostre credenze in base a nuove osservazioni è continuo. Una nuova evidenza coerente con una credenza esistente potrebbe rafforzarla, mentre un’osservazione inaspettata potrebbe metterla in discussione. La probabilità condizionata non è solo un concetto teorico, ma ha applicazioni pratiche sia nella vita quotidiana che in ambito scientifico. In realtà, si potrebbe argomentare che tutte le probabilità sono in qualche modo condizionate da un certo contesto o da informazioni preesistenti, anche se non sempre lo specifichiamo esplicitamente.\nIn sintesi, la probabilità condizionata ci fornisce un framework per comprendere e quantificare come le nostre credenze dovrebbero evolversi man mano che acquisiamo nuove informazioni, rendendo il concetto di probabilità uno strumento dinamico e potente per gestire l’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#indipendenza-stocastica",
    "href": "chapters/probability/05_conditional_prob.html#indipendenza-stocastica",
    "title": "28  Probabilità condizionata",
    "section": "\n28.2 Indipendenza Stocastica",
    "text": "28.2 Indipendenza Stocastica\nIl concetto di indipendenza è cruciale nel contesto della probabilità condizionata, facilitando notevolmente i calcoli in numerosi problemi e indicando come la presenza di un evento non influenzi l’occorrenza di un altro.\n\n28.2.1 Indipendenza di Due Eventi\nDue eventi, \\(A\\) e \\(B\\), sono considerati indipendenti se la realizzazione di uno non altera la probabilità di occorrenza dell’altro. Formalmente, questa relazione è espressa come:\n\\[P(A \\cap B) = P(A) P(B),\\]\ndove \\(P(A \\cap B)\\) è la probabilità che \\(A\\) e \\(B\\) si verifichino contemporaneamente. Se questa condizione è verificata, denotiamo \\(A \\text{ ⫫ } B\\), indicando che \\(A\\) è indipendente da \\(B\\).\n\n28.2.2 Indipendenza di un Insieme di Eventi\nL’indipendenza stocastica è un principio fondamentale nell’applicazione statistica della probabilità. Un insieme di eventi \\(\\{ A_i : i \\in I \\}\\) è definito indipendente se per ogni sottoinsieme finito \\(J\\) di \\(I\\), la probabilità dell’intersezione degli eventi in \\(J\\) equivale al prodotto delle loro probabilità individuali:\n\\[P \\left( \\bigcap_{i \\in J} A_i \\right) = \\prod_{i \\in J} P(A_i).\\]\nQuesto implica che ogni combinazione finita di eventi nell’insieme agisce in maniera indipendente.\nL’indipendenza può essere assunta o derivata, a seconda del contesto. In alcuni modelli o situazioni, assumiamo l’indipendenza per semplificare i calcoli o per riflettere una conoscenza preesistente. In altri contesti, l’indipendenza può emergere dai dati o da altre proprietà del modello.\n\n28.2.3 Eventi Disgiunti e Indipendenza\nEventi disgiunti, o mutuamente esclusivi, sono quelli che non possono verificarsi contemporaneamente, ossia \\(\\mathbb{P}(A \\cap B) = 0\\). Se due eventi disgiunti hanno probabilità positive, essi non possono essere indipendenti, poiché l’equazione \\(P(A \\cap B) = P(A) P(B)\\) non può essere soddisfatta; \\(P(A \\cap B) = 0\\) non uguaglia \\(P(A) P(B) &gt; 0\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#probabilità-condizionata",
    "href": "chapters/probability/05_conditional_prob.html#probabilità-condizionata",
    "title": "28  Probabilità condizionata",
    "section": "\n28.3 Probabilità Condizionata",
    "text": "28.3 Probabilità Condizionata\nLa probabilità di un evento è sempre contestualizzata e varia a seconda del nostro stato di informazione. Con un insieme di informazioni disponibile, attribuiamo una probabilità specifica a un evento. Se lo stato informativo cambia, anche la probabilità associata deve essere aggiornata. In sostanza, tutte le probabilità possono essere considerate condizionate, anche se l’evento condizionante non è esplicitato.\nLa probabilità condizionata di un evento \\(A\\) dato un altro evento \\(B\\), con \\(P(B) &gt; 0\\), è definita come:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)},\n\\tag{28.1}\\]\ndove \\(P(A \\cap B)\\) è la probabilità congiunta di \\(A\\) e \\(B\\). Questa relazione permette di derivare la regola della moltiplicazione:\n\\[\nP(A \\cap B) = P(A \\mid B)P(B) = P(B \\mid A)P(A),\n\\]\ne una forma alternativa della legge della probabilità totale:\n\\[\nP(A) = P(A \\mid B)P(B) + P(A \\mid B^c)P(B^c),\n\\]\ndove \\(B^c\\) rappresenta il complemento di \\(B\\).\nPer spazi campionari discreti, possiamo esprimere la probabilità condizionata come:\n\\[\nP(A \\mid B) = \\frac{| A \\cap B |}{| B |}.\n\\]\nLa probabilità condizionata ricalibra lo spazio campionario, riducendolo da \\(S\\) a \\(B\\), e non è definita se \\(P(B) = 0\\).\n\nEsempio 28.1 Lanciamo due dadi equilibrati consecutivamente.\nDato che la somma dei dadi è 10, qual è la probabilità che uno dei due dadi mostri un 6?\nDefiniamo:\n\n\nB come l’evento che la somma sia 10:\\[ B = \\{(4, 6), (5, 5), (6, 4)\\}. \\]\n\n\nA come l’evento che uno dei due dadi mostri un 6:\\[ A = \\{(1, 6), \\dots, (5, 6), (6, 1), \\dots, (6, 5)\\}. \\]\n\n\nL’intersezione tra A e B è:\\[ A \\cap B = \\{(4, 6), (6, 4)\\}. \\]\nPoiché in questo esperimento tutti gli eventi elementari sono equiprobabili, la probabilità condizionata \\(P(A | B)\\) è data da:\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{\\frac{2}{36}}{\\frac{3}{36}} = \\frac{2}{3}.\n\\]\nQuindi, la probabilità che uno dei due dadi mostri un 6, sapendo che la somma è 10, è \\(\\frac{2}{3}\\).\n\n\nEsempio 28.2 Lanciamo due dadi equilibrati e vogliamo calcolare la probabilità che la somma dei punteggi ottenuti sia minore di 8.\nInizialmente, quando non abbiamo ulteriori informazioni, possiamo calcolare la probabilità in modo tradizionale. Ci sono 21 risultati possibili con somma minore di 8. Poiché ci sono 36 possibili combinazioni di lancio dei due dadi, la probabilità di ottenere una somma minore di 8 è 21/36, che equivale a circa 0.58.\nSupponiamo ora di sapere che la somma del lancio di due dadi ha prodotto un risultato dispari. In questo caso, ci sono solo 18 possibili combinazioni di lancio dei due dadi (dato che abbiamo escluso i risultati pari). Tra essi, vi sono 12 risultati che soddisfano la condizione per cui la somma è minore di 8. Quindi, la probabilità di ottenere una somma minore di 8 cambia da circa 0.58 a 12/18, ovvero 0.67 quando consideriamo l’informazione aggiuntiva del risultato dispari.\nSvolgiamo il problema in R:\n\nr &lt;- 1:6\nsample &lt;- expand.grid(i = r, j = r)\nsample\n#&gt;    i j\n#&gt; 1  1 1\n#&gt; 2  2 1\n#&gt; 3  3 1\n#&gt; 4  4 1\n#&gt; 5  5 1\n#&gt; 6  6 1\n#&gt; 7  1 2\n#&gt; 8  2 2\n#&gt; 9  3 2\n#&gt; 10 4 2\n#&gt; 11 5 2\n#&gt; 12 6 2\n#&gt; 13 1 3\n#&gt; 14 2 3\n#&gt; 15 3 3\n#&gt; 16 4 3\n#&gt; 17 5 3\n#&gt; 18 6 3\n#&gt; 19 1 4\n#&gt; 20 2 4\n#&gt; 21 3 4\n#&gt; 22 4 4\n#&gt; 23 5 4\n#&gt; 24 6 4\n#&gt; 25 1 5\n#&gt; 26 2 5\n#&gt; 27 3 5\n#&gt; 28 4 5\n#&gt; 29 5 5\n#&gt; 30 6 5\n#&gt; 31 1 6\n#&gt; 32 2 6\n#&gt; 33 3 6\n#&gt; 34 4 6\n#&gt; 35 5 6\n#&gt; 36 6 6\n\n\nevent &lt;- subset(sample, i + j &lt; 8)\ncat(nrow(event), \"/\", nrow(sample), \"\\n\")\n#&gt; 21 / 36\n\n\nsample_odd &lt;- subset(sample, (i + j) %% 2 != 0)\nsample_odd\n#&gt;    i j\n#&gt; 2  2 1\n#&gt; 4  4 1\n#&gt; 6  6 1\n#&gt; 7  1 2\n#&gt; 9  3 2\n#&gt; 11 5 2\n#&gt; 14 2 3\n#&gt; 16 4 3\n#&gt; 18 6 3\n#&gt; 19 1 4\n#&gt; 21 3 4\n#&gt; 23 5 4\n#&gt; 26 2 5\n#&gt; 28 4 5\n#&gt; 30 6 5\n#&gt; 31 1 6\n#&gt; 33 3 6\n#&gt; 35 5 6\n\n\nevent &lt;- subset(sample_odd, i + j &lt; 8)\ncat(nrow(event), \"/\", nrow(sample_odd), \"\\n\")\n#&gt; 12 / 18\n\nSe applichiamo l’Equazione 28.1, abbiamo: \\(P(A \\cap B)\\) = 12/36, \\(P(B)\\) = 18/36 e\n\\[\nP(A \\mid B) = \\frac{12}{18}.\n\\]\nQuesto esempio illustra come la probabilità di un evento possa variare in base alle informazioni aggiuntive di cui disponiamo. Nel secondo caso, avendo l’informazione che la somma è dispari, la probabilità di ottenere una somma minore di 8 aumenta notevolmente rispetto al caso iniziale in cui non avevamo questa informazione.\n\n\nEsempio 28.3 Consideriamo uno screening per la diagnosi precoce del tumore mammario utilizzando un test con determinate caratteristiche:\n\nSensibilità del test: 90%. Questo significa che il test classifica correttamente come positivo il 90% delle donne colpite dal cancro al seno.\nSpecificità del test: 90%. Ciò indica che il test classifica correttamente come negativo il 90% delle donne che non hanno il cancro al seno.\nPrevalenza del cancro al seno nella popolazione sottoposta allo screening: 1% (0.01). Questo è il 1% delle donne che ha effettivamente il cancro al seno, mentre il restante 99% (0.99) non ne è affetto.\n\nOra cerchiamo di rispondere alle seguenti domande:\n\nQual è la probabilità che una donna scelta a caso ottenga una mammografia positiva? Poiché il 1% delle donne ha il cancro al seno, la probabilità di ottenere una mammografia positiva (test positivo) è pari alla sensibilità del test, ovvero 0.90 (cioè 90%).\nSe la mammografia è positiva, qual è la probabilità che vi sia effettivamente un tumore al seno?\n\nPer risolvere questo problema, consideriamo un campione di 1000 donne sottoposte al test di screening per il tumore al seno. Di queste 1000 donne:\n\n10 donne (1% del campione) hanno effettivamente il cancro al seno. Per queste 10 donne con il cancro, il test darà un risultato positivo (vera positività) in 9 casi (90%).\nPer le restanti 990 donne (99% del campione) che non hanno il cancro al seno, il test darà un risultato positivo (falsa positività) in 99 casi (10%).\n\nQuesta situazione può essere rappresentata graficamente nel seguente modo:\n\n\n\n\n\nFigura 28.1: Esiti della mammografia per 1000 donne.\n\n\nCombinando i due risultati precedenti, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non lo hanno, per un totale di 108 risultati positivi su 1000. Pertanto, la probabilità di ottenere un risultato positivo al test è \\(\\frac{108}{1000}\\) = 0.108.\nTuttavia, tra le 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno effettivamente il cancro al seno. Quindi, la probabilità di avere il cancro al seno, dato un risultato positivo al test, è pari a \\(\\frac{9}{108}\\) = 0.083, corrispondente all’8.3%.\nIn questo esempio, la probabilità dell’evento “ottenere un risultato positivo al test” è una probabilità non condizionata, poiché calcoliamo semplicemente la proporzione di risultati positivi nel campione totale. D’altra parte, la probabilità dell’evento “avere il cancro al seno, dato che il test ha prodotto un risultato positivo” è una probabilità condizionata, poiché calcoliamo la proporzione delle donne con il cancro al seno tra quelle che hanno ottenuto un risultato positivo al test.\nQuesto esempio illustra come la conoscenza di ulteriori informazioni (il risultato positivo al test) può influenzare la probabilità di un evento (avere il cancro al seno), mostrando chiaramente la differenza tra probabilità condizionate e non condizionate.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#il-problema-di-monty-hall",
    "href": "chapters/probability/05_conditional_prob.html#il-problema-di-monty-hall",
    "title": "28  Probabilità condizionata",
    "section": "\n28.4 Il Problema di Monty Hall",
    "text": "28.4 Il Problema di Monty Hall\nIl problema di Monty Hall è un famoso quesito di teoria della probabilità che illustra in modo efficace il concetto di probabilità condizionata. Questo problema è diventato celebre grazie a una rubrica tenuta da Marilyn vos Savant nella rivista Parade, in cui rispose a una lettera pubblicata il 9 settembre 1990:\n\n“Supponiamo di partecipare a un quiz televisivo e di dover scegliere tra tre porte. Dietro una di esse c’è un’auto, mentre dietro le altre due ci sono delle capre. Scegli una porta, ad esempio la numero 1, e il conduttore, che sa cosa c’è dietro ogni porta, ne apre un’altra, diciamo la numero 3, rivelando una capra. A questo punto, ti chiede se vuoi cambiare la tua scelta e passare alla porta numero 2. È vantaggioso cambiare porta?” Craig. F. Whitaker, Columbia, MD\n\nLa situazione descritta ricorda quella del popolare quiz televisivo degli anni ’70 Let’s Make a Deal, condotto da Monty Hall e Carol Merrill. Marilyn vos Savant rispose che il concorrente dovrebbe cambiare porta, poiché la probabilità di vincere l’auto raddoppia passando da 1/3 a 2/3. Tuttavia, la sua risposta suscitò un acceso dibattito, con molte persone, inclusi alcuni matematici, che sostenevano che cambiare porta non avrebbe offerto alcun vantaggio. Questo episodio ha reso il problema di Monty Hall uno dei più famosi esempi di come l’intuizione possa portare a conclusioni errate in ambito probabilistico.\n\n28.4.1 Chiarire il Problema\nLa lettera originale di Craig Whitaker è piuttosto vaga, quindi per analizzare il problema in modo rigoroso è necessario fare alcune ipotesi:\n\n\nPosizione dell’auto: L’auto è nascosta in modo casuale ed equiprobabile dietro una delle tre porte.\n\nScelta iniziale del giocatore: Il giocatore sceglie una porta in modo casuale, indipendentemente dalla posizione dell’auto.\n\nAzione del conduttore: Dopo la scelta del giocatore, il conduttore apre una delle due porte rimanenti, rivelando una capra, e offre al giocatore la possibilità di cambiare porta.\n\nScelta del conduttore: Se il conduttore ha la possibilità di scegliere tra due porte (entrambe con capre), ne apre una in modo casuale.\n\nCon queste assunzioni, possiamo rispondere alla domanda: Qual è la probabilità che il giocatore vinca l’auto se decide di cambiare porta?\nDi seguito, esploreremo tre metodi per risolvere il problema di Monty Hall: il diagramma ad albero, l’analisi delle probabilità e una simulazione.\n\n28.4.2 Metodo 1: Diagramma ad Albero\nIl diagramma ad albero è uno strumento utile per visualizzare tutti i possibili esiti di un esperimento probabilistico. Nel caso del problema di Monty Hall, possiamo suddividere il processo in tre fasi:\n\n\nPosizione dell’auto: L’auto può trovarsi dietro una delle tre porte (A, B o C), ciascuna con probabilità 1/3.\n\nScelta del giocatore: Il giocatore sceglie una porta in modo casuale, indipendentemente dalla posizione dell’auto.\n\nAzione del conduttore: Il conduttore apre una delle due porte rimanenti, rivelando una capra.\n\nIl diagramma ad albero mostra tutte le possibili combinazioni di questi eventi. Ad esempio, se l’auto è dietro la porta A e il giocatore sceglie la porta B, il conduttore aprirà la porta C (l’unica porta rimanente con una capra).\nPasso 1: Identificare lo spazio campionario\nLo spazio campionario è composto da 12 esiti possibili, rappresentati dalle combinazioni di:\n\nPosizione dell’auto (A, B, C).\nScelta iniziale del giocatore (A, B, C).\nPorta aperta dal conduttore (una delle due rimanenti con una capra).\n\nEcco un diagramma ad albero che rappresenta questa situazione:\n\n\n\n\n\nFigura 28.2: Il diagramma ad albero per il Problema di Monty Hall mostra le probabilità associate a ogni possibile esito. I pesi sugli archi rappresentano la probabilità di seguire quel particolare percorso, dato che ci troviamo nel nodo padre. Ad esempio, se l’auto si trova dietro la porta A, la probabilità che il giocatore scelga inizialmente la porta B è pari a 1/3. La colonna più a destra del diagramma mostra la probabilità di ciascun esito finale. Ogni probabilità di esito è calcolata moltiplicando le probabilità lungo il percorso che parte dalla radice (auto dietro una certa porta) e termina alla foglia (esito finale) (Figura tratta da Lehman, Leighton e Meyer, 2018).\n\n\nPasso 2: Definire l’evento di interesse\nL’evento di interesse è “il giocatore vince cambiando porta”. Questo si verifica quando la porta inizialmente scelta dal giocatore non nasconde l’auto, e il giocatore decide di cambiare porta.\nGli esiti che soddisfano questa condizione sono:\n\n(Auto A, Scelta B, Apertura C)\n(Auto A, Scelta C, Apertura B)\n(Auto B, Scelta A, Apertura C)\n(Auto B, Scelta C, Apertura A)\n(Auto C, Scelta A, Apertura B)\n(Auto C, Scelta B, Apertura A)\n\nQuesti esiti sono in totale 6.\nPasso 3: Calcolare le probabilità degli esiti\nOgni esito ha una probabilità specifica, calcolata moltiplicando le probabilità lungo il percorso nel diagramma ad albero.\nEsempio di calcolo per l’esito (Auto A, Scelta B, Apertura C):\n\nLa probabilità che l’auto sia dietro la porta A è \\(\\frac{1}{3}\\).\nLa probabilità che il giocatore scelga la porta B è \\(\\frac{1}{3}\\).\nLa probabilità che il conduttore apra la porta C (che contiene una capra) è \\(1\\) (poiché il conduttore deve aprire una porta con una capra, e la porta C è l’unica possibile).\n\nLa probabilità totale per questo esito è:\n\\[\nP(\\text{Auto A, Scelta B, Apertura C}) = \\frac{1}{3} \\times \\frac{1}{3} \\times 1 = \\frac{1}{9}.\n\\]\nProcedendo in modo simile per tutti gli altri esiti, otteniamo le probabilità per tutti i 12 esiti.\nPasso 4: Calcolare la probabilità dell’evento\nLa probabilità di vincere cambiando porta è la somma delle probabilità degli esiti favorevoli.\n\\[\n\\begin{aligned}\nP&(\\text{vincere cambiando porta}) = \\notag \\\\\n&\\quad P(\\text{Auto A, Scelta B, Apertura C}) + P(\\text{Auto A, Scelta C, Apertura B}) + \\notag\\\\  \n&\\quad P(\\text{Auto B, Scelta A, Apertura C}) + \\dots \\notag\n\\end{aligned}\n\\]\n\\[\n= \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} = \\frac{6}{9} = \\frac{2}{3}.\n\\]\nLa probabilità di vincere mantenendo la scelta originale è il complemento:\n\\[\nP(\\text{vincere mantenendo la scelta}) = 1 - P(\\text{vincere cambiando porta}) = 1 - \\frac{2}{3} = \\frac{1}{3}.\n\\]\nLa conclusione è che il giocatore ha una probabilità di vincere pari a \\(\\frac{2}{3}\\) se cambia porta, contro una probabilità di \\(\\frac{1}{3}\\) se mantiene la sua scelta iniziale. Cambiare porta è quindi la strategia vincente.\n\n28.4.3 Metodo 2: Analisi delle Probabilità\nIl problema di Monty Hall può essere chiarito analizzando i tre scenari possibili, immaginando di essere osservatori esterni che sanno cosa si nasconde dietro ogni porta:\n\n\nPrimo scenario:\n\nIl giocatore sceglie inizialmente la porta con una capra (chiamiamola “capra 1”).\n\nIl conduttore apre l’altra porta con la “capra 2”.\n\nSe il giocatore cambia porta, vince l’automobile.\n\n\n\nSecondo scenario:\n\nIl giocatore sceglie inizialmente la porta con l’altra capra (“capra 2”).\n\nIl conduttore apre la porta con la “capra 1”.\n\nSe il giocatore cambia porta, vince l’automobile.\n\n\n\nTerzo scenario:\n\nIl giocatore sceglie inizialmente la porta con l’automobile.\n\nIl conduttore apre una delle due porte con una capra (non importa quale).\n\nSe il giocatore cambia porta, perde l’automobile.\n\n\n\nAll’inizio del gioco, il giocatore ha:\n\n\n1/3 di probabilità di scegliere l’automobile.\n\n\n2/3 di probabilità di scegliere una capra.\n\nDopo la scelta iniziale, il conduttore apre una porta con una capra, ma questa azione non altera le probabilità iniziali. Il giocatore si trova quindi con due porte chiuse: quella scelta inizialmente e una rimanente.\n\nSe il giocatore ha scelto l’automobile inizialmente (1/3 di probabilità), cambiando porta perde.\n\nSe il giocatore ha scelto una capra inizialmente (2/3 di probabilità), cambiando porta vince l’automobile.\n\nIn sintesi, cambiando porta, il giocatore ha 2/3 di probabilità di vincere l’automobile, mentre mantenendo la scelta iniziale ha solo 1/3 di probabilità. Pertanto, la strategia migliore è cambiare porta per massimizzare le possibilità di vittoria.\n\n28.4.4 Metodo 3: Simulazione\nPer confermare il risultato, possiamo eseguire una simulazione. Ripetendo il gioco migliaia di volte, possiamo confrontare la frequenza con cui il giocatore vince cambiando porta rispetto a quando mantiene la scelta iniziale.\nEcco un esempio di codice in R per la simulazione:\n\nB &lt;- 10000\nmonty_hall &lt;- function(strategy){\n  doors &lt;- as.character(1:3)\n  prize &lt;- sample(c(\"car\", \"goat\", \"goat\"))\n  prize_door &lt;- doors[prize == \"car\"]\n  my_pick  &lt;- sample(doors, 1)\n  show &lt;- sample(doors[!doors %in% c(my_pick, prize_door)],1)\n  stick &lt;- my_pick\n  stick == prize_door\n  switch &lt;- doors[!doors %in% c(my_pick, show)]\n  choice &lt;- ifelse(strategy == \"stick\", stick, switch)\n  choice == prize_door\n}\n\n\nstick &lt;- replicate(B, monty_hall(\"stick\"))\nmean(stick)\n#&gt; [1] 0.3278\n\n\nswitch &lt;- replicate(B, monty_hall(\"switch\"))\nmean(switch)\n#&gt; [1] 0.6678\n\nSpiegazione del codice.\n\n\nFunzione monty_hall:\n\n\ndoors &lt;- as.character(1:3): Definisce le tre porte.\n\nprize &lt;- sample(c(\"car\", \"goat\", \"goat\")): Assegna casualmente l’auto e le capre alle porte.\n\nprize_door &lt;- doors[prize == \"car\"]: Identifica la porta con l’auto.\n\nmy_pick &lt;- sample(doors, 1): Il giocatore sceglie una porta a caso.\n\nshow &lt;- sample(doors[!doors %in% c(my_pick, prize_door)],1): Il conduttore apre una porta con una capra.\n\nstick &lt;- my_pick: Mantiene la scelta iniziale.\n\nswitch &lt;- doors[!doors %in% c(my_pick, show)]: Cambia porta.\n\nchoice &lt;- ifelse(strategy == \"stick\", stick, switch): Decide se mantenere o cambiare porta in base alla strategia.\n\nchoice == prize_door: Verifica se la scelta finale è la porta con l’auto.\n\n\n\nSimulazione per Mantenere la Scelta Iniziale:\n\n\nstick &lt;- replicate(B, monty_hall(\"stick\")): Ripete il gioco 10.000 volte mantenendo la scelta iniziale.\n\nmean(stick): Calcola la frequenza di vittoria.\n\n\n\nSimulazione per Cambiare Porta:\n\n\nswitch &lt;- replicate(B, monty_hall(\"switch\")): Ripete il gioco 10.000 volte cambiando porta.\n\nmean(switch): Calcola la frequenza di vittoria.\n\n\n\nRisultati attesi:\n\n\nMantenere la Scelta Iniziale: La frequenza di vittoria dovrebbe essere circa 1/3 (33.3%).\n\nCambiare Porta: La frequenza di vittoria dovrebbe essere circa 2/3 (66.6%).\n\nLa simulazione conferma che cambiare porta aumenta la probabilità di vincere da 1/3 a 2/3, dimostrando che la strategia ottimale nel problema di Monty Hall è quella di cambiare porta dopo che il conduttore ha rivelato una capra.\nIn sintesi, il problema di Monty Hall mette in luce come l’intuizione possa trarci in inganno quando ci confrontiamo con scenari probabilistici. Attraverso l’uso del diagramma ad albero, un’analisi delle probabilità e l’esecuzione di simulazioni, abbiamo dimostrato che cambiare porta raddoppia le possibilità di vincita, facendole passare da 1/3 a 2/3. Questo risultato, in apparente contrasto con ciò che potrebbe sembrare intuitivo, costituisce un esempio emblematico dell’importanza di adottare un approccio formale nella valutazione delle probabilità, anziché affidarsi esclusivamente a impressioni iniziali che spesso si rivelano fuorvianti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#sec-simpson-paradox",
    "href": "chapters/probability/05_conditional_prob.html#sec-simpson-paradox",
    "title": "28  Probabilità condizionata",
    "section": "\n28.5 Il paradosso di Simpson",
    "text": "28.5 Il paradosso di Simpson\nNel contesto della probabilità condizionata, un fenomeno particolarmente interessante e, al tempo stesso, controintuitivo è il paradosso di Simpson. Questo paradosso si verifica quando una tendenza osservata in diversi gruppi di dati separati scompare o addirittura si inverte una volta che i gruppi vengono combinati.\nIl paradosso di Simpson evidenzia l’importanza di considerare le variabili confondenti e di analizzare i dati con grande attenzione per evitare di trarre conclusioni errate o fuorvianti. È un esempio emblematico di come l’interpretazione dei dati statistici richieda non solo strumenti matematici, ma anche una profonda comprensione del contesto e delle relazioni tra le variabili coinvolte.\nConsideriamo il paradosso di Simpson nella forma seguente. Due psicoterapeuti, Rossi e Bianchi, praticano due tipi di terapie: terapia per disturbi d’ansia e coaching per migliorare le prestazioni lavorative. Ogni terapia può avere un esito positivo o negativo.\nI rispettivi bilanci dei due terapeuti sono riportati nelle seguenti tabelle.\nRossi\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\nDisturbi d’ansia\n70\n20\n\n\nCoaching lavorativo\n10\n0\n\n\nTotale\n80\n20\n\n\n\nBianchi\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\nDisturbi d’ansia\n2\n8\n\n\nCoaching lavorativo\n81\n9\n\n\nTotale\n83\n17\n\n\n\nRossi ha un tasso di successo superiore a Bianchi nella terapia per i disturbi d’ansia: 70 su 90 rispetto a 2 su 10. Anche nel coaching lavorativo, Rossi ha un tasso di successo superiore: 10 su 10 rispetto a 81 su 90. Tuttavia, se aggregiamo i dati dei due tipi di terapia per confrontare i tassi di successo globali, Rossi è efficace in 80 su 100 terapie, mentre Bianchi in 83 su 100: il tasso di successo globale di Bianchi risulta superiore!\nQuesto fenomeno è un esempio del paradosso di Simpson, dove una tendenza osservata in diversi gruppi si inverte quando i gruppi sono combinati.\nPer essere più precisi, possiamo calcolare i tassi di successo per ciascun terapeuta e per ciascun tipo di terapia, oltre al tasso di successo globale.\n\n\nRossi\n\nTasso di successo in terapia per disturbi d’ansia: \\(\\frac{70}{70+20} = \\frac{70}{90} \\approx 0.778\\)\n\nTasso di successo in coaching lavorativo: \\(\\frac{10}{10+0} = \\frac{10}{10} = 1\\)\n\nTasso di successo globale: \\(\\frac{70+10}{70+20+10+0} = \\frac{80}{100} = 0.8\\)\n\n\n\n\nBianchi\n\nTasso di successo in terapia per disturbi d’ansia: \\(\\frac{2}{2+8} = \\frac{2}{10} = 0.2\\)\n\nTasso di successo in coaching lavorativo: \\(\\frac{81}{81+9} = \\frac{81}{90} \\approx 0.9\\)\n\nTasso di successo globale: \\(\\frac{2+81}{2+8+81+9} = \\frac{83}{100} = 0.83\\)\n\n\n\n\nQuello che sta succedendo è che Rossi, presumibilmente a causa della sua reputazione come terapeuta più esperto, sta effettuando un numero maggiore di terapie per disturbi d’ansia, che sono intrinsecamente più complesse e con una probabilità di successo variabile rispetto al coaching lavorativo. Il suo tasso di successo globale è inferiore non a causa di una minore abilità in un particolare tipo di terapia, ma perché una frazione maggiore delle sue terapie riguarda casi più complessi.\nL’aggregazione dei dati tra diversi tipi di terapia presenta un quadro fuorviante delle abilità dei terapeuti perché perdiamo l’informazione su quale terapeuta tende a effettuare quale tipo di terapia. Quando sospettiamo la presenza di variabili di confondimento, come ad esempio il tipo di terapia in questo contesto, è fondamentale analizzare i dati in modo disaggregato per comprendere con precisione la dinamica in atto.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#indipendenza-e-probabilità-condizionata",
    "href": "chapters/probability/05_conditional_prob.html#indipendenza-e-probabilità-condizionata",
    "title": "28  Probabilità condizionata",
    "section": "\n28.6 Indipendenza e Probabilità Condizionata",
    "text": "28.6 Indipendenza e Probabilità Condizionata\nL’indipendenza tra due eventi \\(A\\) e \\(B\\) può essere interpretata intuitivamente attraverso la probabilità condizionata. Due eventi sono indipendenti se il verificarsi di uno non influenza la probabilità di verificarsi dell’altro. In altre parole, conoscere che \\(B\\) è accaduto non modifica la probabilità di \\(A\\), e viceversa.\nQuesta relazione può essere formalizzata con le seguenti equazioni:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = P(B).\n\\]\nPertanto, \\(A\\) e \\(B\\) sono indipendenti se e solo se:\n\\[\nP(A \\mid B) = P(A),\n\\]\n\\[\nP(B \\mid A) = P(B).\n\\]\nQueste condizioni significano che la probabilità di \\(A\\) non cambia, indipendentemente dal fatto che \\(B\\) sia accaduto, e lo stesso vale per \\(B\\).\n\n28.6.1 Indipendenza di Tre Eventi\nLa definizione di indipendenza si estende naturalmente a tre eventi \\(A\\), \\(B\\), e \\(C\\), ma con condizioni aggiuntive. Tre eventi sono indipendenti se:\n\n\nOgni coppia di eventi è indipendente:\n\\[\n\\begin{align}\nP(A \\cap B) &= P(A) P(B), \\\\\nP(A \\cap C) &= P(A) P(C), \\\\\nP(B \\cap C) &= P(B) P(C).\n\\end{align}\n\\]\n\n\nLa probabilità congiunta di tutti e tre gli eventi è uguale al prodotto delle loro probabilità individuali:\n\\[\nP(A \\cap B \\cap C) = P(A) P(B) P(C).\n\\]\n\n\nLe prime tre condizioni verificano l’indipendenza a coppie (indipendenza a due a due), mentre l’ultima condizione garantisce che i tre eventi siano completamente indipendenti. È importante notare che l’indipendenza a due a due non implica necessariamente l’indipendenza completa: per essere indipendenti nel senso completo, tutte e quattro le condizioni devono essere soddisfatte.\nIn sintesi, l’indipendenza tra eventi implica che il verificarsi di uno di essi non fornisce alcuna informazione sulla probabilità del verificarsi degli altri. Nel caso di due eventi, questa proprietà si traduce nell’invarianza della probabilità condizionata. Per tre o più eventi, l’indipendenza richiede sia l’indipendenza a coppie sia la condizione più forte sull’intersezione di tutti gli eventi.\nQuesti concetti sono fondamentali nella probabilità e nella statistica, poiché semplificano molti calcoli e forniscono una base per modelli più complessi.\n\nEsempio 28.4 Consideriamo un esempio utilizzando un mazzo di 52 carte. Ogni seme contiene 13 carte e ci sono 4 regine in totale. Definiamo i seguenti eventi:\n\nEvento A: pescare una carta di picche,\nEvento B: pescare una regina.\n\nProbabilità con un mazzo completo\nIn un mazzo completo, la probabilità di pescare una carta di picche (\\(P(A)\\)) è \\(\\frac{13}{52} = \\frac{1}{4}\\), poiché ci sono 13 picche su 52 carte totali. La probabilità di pescare una regina (\\(P(B)\\)) è \\(\\frac{4}{52} = \\frac{1}{13}\\), poiché ci sono 4 regine su 52 carte.\nOra consideriamo la probabilità congiunta di pescare la regina di picche (\\(P(AB)\\)). Poiché esiste solo una regina di picche nel mazzo, la probabilità di pescare questa specifica carta è \\(\\frac{1}{52}\\).\nSecondo la definizione di indipendenza, se gli eventi \\(A\\) e \\(B\\) sono indipendenti, allora:\n\\[ P(AB) = P(A)P(B) \\]\nCalcoliamo \\(P(A)P(B)\\):\n\\[ P(A)P(B) = \\left( \\frac{1}{4} \\right) \\left( \\frac{1}{13} \\right) = \\frac{1}{52} \\]\nPoiché \\(P(AB) = \\frac{1}{52}\\) è uguale a \\(P(A)P(B)\\), possiamo affermare che gli eventi \\(A\\) e \\(B\\) sono indipendenti con un mazzo completo di 52 carte.\nProbabilità dopo la rimozione di una carta\nConsideriamo ora un mazzo con una carta in meno, ad esempio il due di quadri, riducendo il numero totale di carte a 51. Ricalcoliamo le probabilità con questo mazzo ridotto:\nLa probabilità di pescare la regina di picche (\\(P(AB)\\)) è ora \\(\\frac{1}{51}\\), poiché ci sono 51 carte nel mazzo.\nRicalcoliamo anche \\(P(A)\\) e \\(P(B)\\):\n\n\n\\(P(A)\\) diventa \\(\\frac{13}{51}\\), poiché ci sono ancora 13 picche, ma su 51 carte.\n\n\\(P(B)\\) diventa \\(\\frac{4}{51}\\), poiché ci sono ancora 4 regine, ma su 51 carte.\n\nOra calcoliamo il prodotto \\(P(A)P(B)\\) con queste nuove probabilità:\n\\[ P(A)P(B) = \\left( \\frac{13}{51} \\right) \\left( \\frac{4}{51} \\right) = \\frac{52}{2601} \\]\nConfrontiamo \\(P(AB)\\) e \\(P(A)P(B)\\):\n\\[ \\frac{1}{51} \\neq \\frac{52}{2601} \\]\nPoiché \\(\\frac{1}{51} \\neq \\frac{52}{2601}\\), gli eventi \\(A\\) e \\(B\\) non sono più indipendenti dopo la rimozione del due di quadri.\nQuesto esempio mostra come l’indipendenza tra due eventi dipenda dal contesto. Con un mazzo completo, i due eventi sono indipendenti. Tuttavia, rimuovendo una carta dal mazzo, le probabilità cambiano e gli eventi non sono più indipendenti. Questo evidenzia l’importanza di considerare la composizione e le condizioni iniziali quando si analizzano probabilità e indipendenza. Modifiche nella composizione del mazzo possono alterare le probabilità, influenzando le relazioni di indipendenza tra eventi specifici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#teorema-del-prodotto",
    "href": "chapters/probability/05_conditional_prob.html#teorema-del-prodotto",
    "title": "28  Probabilità condizionata",
    "section": "\n28.7 Teorema del Prodotto",
    "text": "28.7 Teorema del Prodotto\nIl Teorema del Prodotto, noto anche come teorema della probabilità composta, regola moltiplicativa o regola della catena, consente di calcolare la probabilità congiunta di due o più eventi a partire dalle loro probabilità marginali e condizionate. Tale teorema deriva direttamente dalla definizione di probabilità condizionata.\nPer due eventi \\(A\\) e \\(B\\), la probabilità congiunta \\(P(A \\cap B)\\) può essere espressa tramite la seguente relazione:\n\\[\nP(A \\cap B) = P(B) \\, P(A \\mid B) = P(A) \\, P(B \\mid A).\n\\tag{28.2}\\]\nQuesta formula indica che la probabilità che entrambi gli eventi \\(A\\) e \\(B\\) si verifichino è data dalla probabilità che uno degli eventi si realizzi, moltiplicata per la probabilità che l’altro evento accada, condizionatamente al verificarsi del primo.\nÈ possibile generalizzare questo risultato al caso di \\(n\\) eventi, ovvero alla probabilità congiunta \\(P(A_1 \\cap A_2 \\cap \\cdots \\cap A_n)\\) (abbreviata in \\(P(A_1 A_2 \\cdots A_n)\\)). Questa generalizzazione corrisponde alla regola del prodotto della probabilità:\nTeorema 1.3 (Regola del Prodotto).\nSiano \\(A_1, A_2, \\dots, A_n\\) una sequenza di eventi per cui \\(P(A_1 \\cap A_2 \\cap \\cdots \\cap A_{n-1}) &gt; 0\\). Allora:\n\\[\n\\begin{align}\nP(A_1 \\cap A_2 \\cap \\cdots \\cap A_n) &= P(A_1) \\, P(A_2 \\mid A_1) \\, P(A_3 \\mid A_1 \\cap A_2) \\, \\cdots \\notag\\\\\n& \\quad\\cdot P(A_n \\mid A_1 \\cap A_2 \\cap \\cdots \\cap A_{n-1})\\notag\n\\end{align}\n\\tag{28.3}\\]\nIn altre parole, per calcolare la probabilità congiunta di \\(n\\) eventi, si procede nel seguente modo:\n\nSi considera la probabilità incondizionata del primo evento \\(P(A_1)\\).\nSi moltiplica per la probabilità del secondo evento, condizionata al verificarsi del primo \\(P(A_2 \\mid A_1)\\).\nSi moltiplica per la probabilità del terzo evento, condizionata al verificarsi dei primi due \\(P(A_3 \\mid A_1 \\cap A_2)\\).\nE così via, fino al \\(n\\)-esimo evento, la cui probabilità è calcolata condizionata al verificarsi di tutti gli eventi precedenti \\(P(A_n \\mid A_1 \\cap A_2 \\cap \\cdots \\cap A_{n-1})\\).\n\n\nEsempio 28.5 Esempio.\nConsideriamo quattro eventi \\(A_1, A_2, A_3, A_4\\). La probabilità congiunta si esprime come:\n\\[\nP(A_1 \\cap A_2 \\cap A_3 \\cap A_4) = P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot P(A_3 \\mid A_1 \\cap A_2) \\cdot P(A_4 \\mid A_1 \\cap A_2 \\cap A_3).\n\\]\nIn questa espressione:\n\n\n\\(P(A_1)\\) rappresenta la probabilità incondizionata del primo evento.\n\n\\(P(A_2 \\mid A_1)\\) è la probabilità del secondo evento dato il verificarsi del primo.\n\n\\(P(A_3 \\mid A_1 \\cap A_2)\\) è la probabilità del terzo evento, condizionata al verificarsi sia del primo che del secondo.\n\n\\(P(A_4 \\mid A_1 \\cap A_2 \\cap A_3)\\) è la probabilità del quarto evento, condizionata al verificarsi dei tre eventi precedenti.\n\n\nIl Teorema del Prodotto rappresenta uno dei fondamenti teorici più importanti della probabilità e trova applicazioni in numerosi contesti, quali:\n\nLa modellazione di processi sequenziali o temporali.\nLa scomposizione di problemi complessi in calcoli più semplici e gestibili.\nLa teoria delle reti bayesiane e l’analisi della probabilità condizionata.\n\nGrazie a questo teorema, è possibile affrontare problemi complessi suddividendoli in passaggi progressivi, in cui ogni probabilità condizionata contribuisce alla costruzione della soluzione complessiva in maniera sistematica.\n\nEsempio 28.6 Da un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento: “esce una pallina bianca alla \\(i\\)-esima estrazione” e con \\(N_i\\) l’estrazione di una pallina nera. L’evento: “escono due palline bianche nelle prime due estrazioni” è rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l’Equazione 28.2, la sua probabilità vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche, per l’Equazione 28.3, vale\n\\[\n\\begin{aligned}\nP(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\\n&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\\n&= \\frac{1}{6}.\n\\end{aligned}\n\\]\nLa probabilità dell’estrazione di tre palline nere è invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\\n&= \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#teorema-della-probabilità-totale",
    "href": "chapters/probability/05_conditional_prob.html#teorema-della-probabilità-totale",
    "title": "28  Probabilità condizionata",
    "section": "\n28.8 Teorema della Probabilità Totale",
    "text": "28.8 Teorema della Probabilità Totale\nIn letteratura, l’insieme di regole che ci permette di calcolare la probabilità di un evento \\(A\\) attraverso la somma delle probabilità condizionate su una partizione dello spazio campionario è noto come teorema della probabilità totale (o legge della probabilità totale).\nIl principio generale afferma che, se lo spazio campionario \\(\\Omega\\) è suddiviso in sottoinsiemi (o eventi) mutuamente esclusivi e la cui unione corrisponde all’intero \\(\\Omega\\)—cioè formano una partizione—allora la probabilità di un evento \\(A \\subseteq \\Omega\\) può essere scomposta come somma (o “somma pesata” in termini di probabilità condizionata) delle probabilità di \\(A\\) su ciascun sottoinsieme della partizione.\nIn formula, se \\(B_1, B_2, \\dots, B_n\\) costituiscono una partizione dello spazio campionario (\\(B_i \\cap B_j = \\varnothing\\) per \\(i \\neq j\\) e \\(\\bigcup_{i=1}^n B_i = \\Omega\\)), abbiamo:\n\\[\nP(A) \\;=\\; \\sum_{i=1}^n P(A \\cap B_i)\n\\;=\\; \\sum_{i=1}^n P(A \\mid B_i)\\, P(B_i).\n\\tag{28.4}\\]\nQuesta formula è chiamata teorema della probabilità totale.\n\n28.8.1 Due Partizioni\nNel caso più semplice, si consideri \\(\\Omega\\) diviso in due parti: \\(B\\) e il suo complementare \\(B^c\\). Essendo mutuamente esclusivi e la cui unione è \\(\\Omega\\), vale:\n\\[\nP(A) = P(A \\cap B) + P(A \\cap B^c)\n\\;=\\; P(A \\mid B)\\,P(B) + P(A \\mid B^c)\\,P(B^c).\n\\]\nQuesta forma è la versione a due sottoinsiemi del medesimo principio.\n\n28.8.2 Applicazioni\n\nProblemi con più categorie o scenari\nSe abbiamo diverse “categorie” (\\(B_1, B_2, \\dots, B_n\\)) che coprono l’intera popolazione o l’intero spazio degli esiti, e vogliamo calcolare la probabilità di un evento \\(A\\), possiamo scomporre il calcolo in base alla probabilità di ciascuna categoria, ottenendo: \\[\nP(A) = \\sum_{i=1}^n P(A \\mid B_i)\\,P(B_i).\n\\] Questo risulta utile, per esempio, in ambito medico o psicologico, quando si suddivide un campione in sottogruppi (ad esempio, per caratteristiche demografiche, cliniche o comportamentali).\nTeorema di Bayes\nIn statistica inferenziale, il denominatore del Teorema di Bayes si esprime mediante la probabilità totale, poiché spesso \\(P(E)\\) (la probabilità dei dati osservati) si calcola sommando i contributi dei vari modelli o ipotesi (una partizione di ipotesi statistiche), ciascuna con la propria probabilità a priori e la propria verosimiglianza.\n\nIn sintesi, il teorema della probabilità totale si riferisce al seguente principio: data una partizione di \\(\\Omega\\), la probabilità di un evento si ottiene sommando le sue probabilità condizionate per ciascuna parte della partizione, pesate dalla probabilità di quella parte. Questo strumento è di fondamentale importanza per semplificare il calcolo delle probabilità in contesti complessi e con spazi campionari articolati.\n\nEsempio 28.7 Un team di psicologi desidera stimare la probabilità complessiva di soffrire di depressione nella popolazione generale, distinguendo tre fasce d’età: giovani (18–30 anni), adulti (31–50 anni) e anziani (51+ anni).\nI dati raccolti mostrano che: - Il 30% della popolazione è giovane, il 40% è adulta e il 30% è anziana.\n- Le probabilità condizionate di soffrire di depressione nelle tre fasce sono:\\[\n  P(D \\mid G) = 0.10, \\quad\n  P(D \\mid A) = 0.20, \\quad\n  P(D \\mid Z) = 0.35.\n  \\]\nPer ottenere la probabilità totale di soffrire di depressione (\\(P(D)\\)) nella popolazione, si applica la legge della probabilità totale:\n\\[\nP(D) = P(D \\mid G)\\,P(G) + P(D \\mid A)\\,P(A) + P(D \\mid Z)\\,P(Z).\n\\]\nDi seguito il codice R per effettuare il calcolo:\n\n# Probabilità di ciascuna fascia d'età\nP_G &lt;- 0.30\nP_A &lt;- 0.40\nP_Z &lt;- 0.30\n\n# Probabilità condizionate di depressione\nP_D_given_G &lt;- 0.10\nP_D_given_A &lt;- 0.20\nP_D_given_Z &lt;- 0.35\n\n# Calcolo della probabilità totale\nP_D &lt;- (P_D_given_G * P_G) + (P_D_given_A * P_A) + (P_D_given_Z * P_Z)\n\ncat(\"La probabilità totale di soffrire di depressione è:\", P_D, \"\\n\")\n#&gt; La probabilità totale di soffrire di depressione è: 0.215\n\nInterpretazione\nDal risultato, circa il 21.5% della popolazione soffre di depressione. Questo calcolo è particolarmente utile quando i dati derivano da sottopopolazioni distinte, in quanto fornisce una stima complessiva combinando i contributi di ciascun gruppo.\n\n\nEsempio 28.8 Abbiamo tre urne, ciascuna delle quali contiene 100 palline:\n\nUrna 1: 75 palline rosse e 25 palline blu,\nUrna 2: 60 palline rosse e 40 palline blu,\nUrna 3: 45 palline rosse e 55 palline blu.\n\nUna pallina viene estratta a caso da un’urna anch’essa scelta a caso. Qual è la probabilità che la pallina estratta sia di colore rosso?\nSia \\(R\\) l’evento “la pallina estratta è rossa” e sia \\(U_i\\) l’evento che corrisponde alla scelta dell’\\(i\\)-esima urna. Sappiamo che\n\\[\nP(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n\\]\nGli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campione in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilità totale, la probabilità di estrarre una pallina rossa è dunque\n\\[\n\\begin{split}\nP(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n&=0.60.\n\\end{split}\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/05_conditional_prob.html#riflessioni-conclusive",
    "title": "28  Probabilità condizionata",
    "section": "\n28.9 Riflessioni Conclusive",
    "text": "28.9 Riflessioni Conclusive\nLa probabilità condizionata è uno dei concetti fondamentali della statistica, poiché fornisce il quadro teorico necessario per comprendere l’indipendenza statistica e molte altre relazioni tra eventi e variabili.\nUn punto chiave è che l’indipendenza implica l’assenza di una associazione tra due variabili. Nei capitoli successivi esploreremo strumenti per misurare la correlazione correlazione, ovvero la presenza e l’intensità di una relazione lineare tra di esse.\nLa probabilità condizionata ha inoltre permesso di riformulare la legge della probabilità totale, che consente di scomporre probabilità complesse utilizzando partizioni dello spazio campionario. Questa legge si rivela cruciale per il teorema di Bayes, uno degli strumenti cardine dell’inferenza statistica.\nIn particolare, nel contesto dell’inferenza bayesiana, il condizionamento assume un ruolo fondamentale. Grazie a questo principio, è possibile aggiornare continuamente le credenze o le incertezze riguardo a ipotesi, integrando nuove informazioni man mano che diventano disponibili. Questa capacità di adattamento rende l’inferenza bayesiana uno strumento estremamente flessibile e potente, capace di modellare situazioni complesse e dinamiche.\nIn sintesi, la probabilità condizionata non solo è essenziale per comprendere l’indipendenza statistica, ma costituisce anche la base di metodi inferenziali avanzati, come l’inferenza bayesiana. Attraverso di essa, possiamo costruire modelli che evolvono e migliorano con l’aggiunta di nuove informazioni, rendendo l’analisi statistica uno strumento dinamico e versatile per interpretare il mondo reale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#esercizi",
    "href": "chapters/probability/05_conditional_prob.html#esercizi",
    "title": "28  Probabilità condizionata",
    "section": "\n28.10 Esercizi",
    "text": "28.10 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizio 1: Soddisfazione con la Vita e Stress Accademico\nUn gruppo di studenti ha compilato la Satisfaction with Life Scale (SWLS) e un questionario sullo stress accademico. Dai dati raccolti emerge che:\n\nIl 40% degli studenti ha riportato un alto livello di stress accademico.\nIl 60% degli studenti ha riportato un basso livello di stress accademico.\nTra gli studenti con alto stress, il 30% ha riportato una soddisfazione con la vita elevata.\nTra gli studenti con basso stress, il 70% ha riportato una soddisfazione con la vita elevata.\n\nCalcola la probabilità che uno studente scelto a caso abbia:\n\nUn alto livello di stress e una soddisfazione elevata.\nUna soddisfazione elevata.\nUn alto livello di stress, dato che ha una soddisfazione elevata.\n\nEsercizio 2: Studio del Paradosso di Simpson\nUn’università vuole valutare la relazione tra la frequenza di partecipazione alle lezioni e il successo negli esami finali. I dati raccolti mostrano che:\n\n\n\n\n\n\n\n\nGruppo\nStudenti con alta frequenza\nSuperano l’esame\nNon superano l’esame\n\n\n\nA\n40\n30\n10\n\n\nB\n60\n20\n40\n\n\n\n\nCalcola la probabilità di superare l’esame per ciascun gruppo separatamente.\nCalcola la probabilità totale di superare l’esame.\nSpiega se il Paradosso di Simpson si manifesta in questi dati.\n\nEsercizio 3: Il Problema di Monty Hall\nIn un quiz televisivo, un concorrente deve scegliere tra tre porte: dietro una c’è un’auto e dietro le altre due ci sono capre. Dopo la scelta iniziale, il conduttore, che sa cosa c’è dietro ogni porta, apre una delle due porte rimanenti rivelando una capra. Il concorrente ha ora la possibilità di cambiare la sua scelta.\n\nQual è la probabilità di vincere l’auto se il concorrente non cambia la sua scelta?\nQual è la probabilità di vincere l’auto se il concorrente cambia la sua scelta?\nSpiega perché cambiare porta è la strategia migliore.\n\nEsercizio 4: Teorema della Probabilità Totale\nUn’università ha tre dipartimenti: Psicologia, Economia e Ingegneria. Le proporzioni di studenti iscritti sono:\n\nPsicologia: 40%\nEconomia: 35%\nIngegneria: 25%\n\nLa probabilità di laurearsi in tempo varia per ogni dipartimento:\n\nPsicologia: 70%\nEconomia: 60%\nIngegneria: 80%\n\nCalcola la probabilità che uno studente scelto a caso si laurei in tempo.\nEsercizio 5: Urne e Palline\nUn’urna contiene 5 palline rosse e 7 blu. Si estrae una pallina, si osserva il colore e poi la pallina viene rimessa nell’urna. Quindi si estrae una seconda pallina.\n\nQual è la probabilità di estrarre due palline rosse?\nQual è la probabilità di estrarre almeno una pallina blu?\nQual è la probabilità di estrarre una pallina rossa alla seconda estrazione, dato che la prima estratta era blu?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nEsercizio 1: Soddisfazione con la Vita e Stress Accademico\n\n\nLa probabilità che uno studente abbia alto stress e soddisfazione elevata si calcola moltiplicando la probabilità condizionata di avere soddisfazione elevata dato l’alto stress per la probabilità di avere alto stress:\n\\[\nP(S \\cap V) = P(V | S) P(S) = 0.30 \\times 0.40 = 0.12.\n\\]\n\n\nLa probabilità che uno studente abbia una soddisfazione elevata, indipendentemente dal livello di stress, si ottiene applicando la legge della probabilità totale:\n\\[\nP(V) = P(V | S) P(S) + P(V | \\neg S) P(\\neg S)\n\\]\n\\[\n= (0.30 \\times 0.40) + (0.70 \\times 0.60) = 0.12 + 0.42 = 0.54.\n\\]\n\n\nLa probabilità che uno studente abbia alto stress sapendo che ha una soddisfazione elevata si calcola utilizzando la formula della probabilità condizionata:\n\\[\nP(S | V) = \\frac{P(S \\cap V)}{P(V)} = \\frac{0.12}{0.54} \\approx 0.22.\n\\]\n\n\nEsercizio 2: Studio del Paradosso di Simpson\n\n\n\\(P(E | A) = \\frac{30}{40} = 0.75\\), \\(P(E | B) = \\frac{20}{60} = 0.33\\)\n\n\\(P(E) = P(E | A) P(A) + P(E | B) P(B) = (0.75 \\times 0.40) + (0.33 \\times 0.60) = 0.30 + 0.198 = 0.498\\)\nSe i tassi di successo aggregati mostrano una relazione invertita, il Paradosso di Simpson si manifesta.\n\nEsercizio 3: Il Problema di Monty Hall\n\n\\(P(V | S) = \\frac{1}{3}\\)\n\\(P(V | C) = \\frac{2}{3}\\)\nCambiare porta aumenta le probabilità di vincita da \\(1/3\\) a \\(2/3\\), quindi conviene sempre cambiare.\n\nEsercizio 4: Teorema della Probabilità Totale\n\\(P(L) = (0.70 \\times 0.40) + (0.60 \\times 0.35) + (0.80 \\times 0.25) = 0.28 + 0.21 + 0.20 = 0.69\\)\nEsercizio 5: Urne e Palline\n\n\\(P(R_1 \\cap R_2) = (5/12) \\times (5/12) = 25/144\\)\n\\(1 - P(R_1 \\cap R_2) = 1 - 25/144 = 119/144\\)\n\\(P(R_2 | B_1) = 5/12\\)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/05_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "28  Probabilità condizionata",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-167      rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#bibliografia",
    "href": "chapters/probability/05_conditional_prob.html#bibliografia",
    "title": "28  Probabilità condizionata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html",
    "href": "chapters/probability/06_bayes_theorem.html",
    "title": "29  Il teorema di Bayes",
    "section": "",
    "text": "29.1 Introduzione\nIl teorema di Bayes offre una soluzione ottimale ai problemi induttivi, che spaziano dall’identificazione della struttura tridimensionale del mondo basata su dati sensoriali limitati, all’inferenza dei pensieri altrui a partire dal loro comportamento. Questa regola si rivela particolarmente utile in situazioni in cui i dati osservati sono insufficienti per distinguere in modo definitivo tra diverse ipotesi.\nNonostante ciò, tutte le previsioni basate su questo metodo mantengono un certo grado di incertezza. Anche se l’universo fosse completamente deterministico, la nostra conoscenza di esso rimarrebbe imperfetta: non possiamo conoscere la posizione e lo stato di ogni singola particella che lo compone. Le informazioni a nostra disposizione sono inevitabilmente parziali e imprecise, ottenute attraverso i nostri sensi limitati.\nLa vita reale non è paragonabile a una partita di scacchi, un gioco con informazioni perfette che può essere “risolto” in linea di principio. Assomiglia piuttosto al poker, dove le decisioni vengono prese utilizzando le informazioni limitate a disposizione dei giocatori. Questo capitolo si concentra sull’equazione che ci permette di fare proprio questo: il teorema di Bayes. Esso descrive come modifichiamo le nostre convinzioni riguardo a un’ipotesi in una situazione in cui i dati disponibili non consentono una decisione certa.\nQuesto processo è noto come inferenza induttiva, che ci permette di trarre conclusioni generali da dati specifici e limitati. Il teorema di Bayes fornisce quindi un framework matematico per aggiornare le nostre credenze alla luce di nuove evidenze, permettendoci di prendere decisioni informate in un mondo caratterizzato dall’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#una-rivoluzione-nel-pensiero-probabilistico",
    "href": "chapters/probability/06_bayes_theorem.html#una-rivoluzione-nel-pensiero-probabilistico",
    "title": "29  Il teorema di Bayes",
    "section": "\n29.2 Una Rivoluzione nel Pensiero Probabilistico",
    "text": "29.2 Una Rivoluzione nel Pensiero Probabilistico\nNel cuore del XVIII secolo, un ecclesiastico presbiteriano di nome Thomas Bayes gettò le basi per una delle più importanti rivoluzioni nel campo della statistica e del calcolo delle probabilità. Il suo contributo, noto oggi come teorema di Bayes, non solo ha trasformato il modo in cui comprendiamo e applichiamo la probabilità, ma continua a influenzare profondamente la scienza moderna e la tecnologia, inclusa l’intelligenza artificiale (Chivers, 2024).\nThomas Bayes nacque in una famiglia benestante e ricevette un’educazione di alto livello, studiando teologia a Edimburgo per prepararsi alla vita da ecclesiastico. Come nota il suo biografo Bellhouse, Bayes “non sembrava un accademico moderno. Era più un dilettante, un virtuoso. Lo faceva per il proprio piacere piuttosto che avere un’agenda di ricerca.”\nBayes pubblicò due opere principali durante la sua vita:\n\nUna di teologia, “Divine benevolence: Or, an attempt to prove that the principal end of the divine providence and government is the happiness of his creatures”, nel 1731.\nUna difesa del calcolo newtoniano, “An Introduction to the Doctrine of Fluxions”, in risposta a una critica del filosofo George Berkeley.\n\nTuttavia, fu il suo lavoro postumo, “An Essay towards Solving a Problem in the Doctrine of Chances”, pubblicato nel 1763 nella rivista Philosophical Transactions, a cambiare per sempre il corso della teoria della probabilità.\nBellhouse nota che l’interesse di Bayes per la matematica era tipico del suo tempo: “Nel XVIII secolo, i ricchi si dedicavano alla scienza. È un po’ come i ricchi di oggi che si dedicano agli sport.” Ma forse Bellhouse si riferiva solo al suo tempo: oggi i ricchi sembrano interessarsi solo ai social media.\nIl contributo di Bayes non fu tanto matematico quanto filosofico. David Spiegelhalter, ex presidente della Royal Statistical Society, spiega che per Bayes “la probabilità è un’espressione della nostra mancanza di conoscenza sul mondo.” Questa visione introduce l’idea rivoluzionaria che la probabilità sia soggettiva, un’espressione della nostra conoscenza limitata e delle nostre supposizioni sulla verità, piuttosto che una proprietà oggettiva della realtà.\nPer illustrare questo concetto, Bayes utilizzò l’esempio di un tavolo nascosto alla vista su cui vengono lanciate delle palle. Una palla bianca viene lanciata in modo tale che la sua posizione finale sia completamente casuale. Quando la palla bianca si ferma, viene rimossa e si traccia una linea sul tavolo nel punto in cui si trovava. La posizione della linea non è nota. Successivamente, un certo numero di palle rosse viene lanciato sul tavolo. Viene comunicato solo quante palle si trovano a sinistra della linea e quante a destra. Il compito è stimare la posizione della linea. La soluzione proposta da Bayes utilizza non solo i dati osservati (il numero di palle rosse a sinistra e a destra della linea), ma anche le convinzioni iniziali (il “prior”).\nRichard Price (1723-1791), un altro ecclesiastico nonconformista, ebbe un ruolo cruciale nella diffusione del lavoro di Thomas Bayes. Molto più noto del suo amico, Price era ben inserito nei circoli intellettuali dell’epoca. Era in contatto con diversi Padri Fondatori della Rivoluzione Americana, tra cui Thomas Jefferson e Benjamin Franklin, così come John Adams, il secondo presidente degli Stati Uniti. Supportava attivamente la rivoluzione americana, pubblicando un influente opuscolo Observations on the Nature of Civil Liberty, the Principles of Government, and the Justice and Policy of the War with America nel 1776. Era amico di filosofi come David Hume e Adam Smith.\nPrice è importante in questa storia come colui che portò all’attenzione pubblica il lavoro di Bayes: mostrò il saggio al fisico John Canton nel 1761, dopo la morte di Bayes, e lo fece pubblicare nelle Philosophical Transactions della Royal Society due anni dopo. Parte del motivo per cui ci volle tanto tempo per pubblicarlo era che Price non si limitò a correggere refusi e virgole fuori posto. Price aveva una visione propria del lavoro: mentre Bayes scrisse la prima metà del saggio, la seconda metà, contenente tutte le possibili applicazioni pratiche del teorema, fu tutta opera di Price. Bayes non aveva interesse per le statistiche applicate: il suo lavoro, in questo e in tutti gli altri articoli, era “tutta teoria senza alcun accenno di applicazione.” Ma Price fu – come dice lo storico della statistica Stephen Stigler – “il primo bayesiano.”\nSebbene il lavoro di Bayes sia rimasto nell’ombra per decenni, con Pierre-Simon Laplace che giunse indipendentemente a conclusioni simili nel 1774 e le espanse nella sua “Théorie analytique des probabilités” del 1812, l’importanza del teorema di Bayes è oggi indiscutibile. Esso fornisce un meccanismo matematico per aggiornare le probabilità di un’ipotesi in base a nuove evidenze, riflettendo un approccio dinamico e iterativo alla conoscenza.\nNel panorama contemporaneo, il teorema di Bayes trova applicazioni in ogni campo della scienza e della tecnologia. È particolarmente rilevante nel campo dell’intelligenza artificiale, dove modelli linguistici avanzati come ChatGPT e Claude utilizzano principi bayesiani per fare previsioni e prendere decisioni.\nIn conclusione, il teorema di Bayes, nato dalle riflessioni di un ministro presbiteriano del XVIII secolo, ha trasformato il nostro modo di comprendere la probabilità e di aggiornare le nostre conoscenze. La sua rilevanza universale nella comprensione e previsione dei fenomeni è tale che, come afferma Brian Clegg nel suo libro “Everything is predictable: how bayesian statistics explain our world”, la statistica bayesiana è diventata uno strumento fondamentale per spiegare il nostro mondo (Chivers, 2024).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#la-regola-di-bayes",
    "href": "chapters/probability/06_bayes_theorem.html#la-regola-di-bayes",
    "title": "29  Il teorema di Bayes",
    "section": "\n29.3 La Regola di Bayes",
    "text": "29.3 La Regola di Bayes\nL’inferenza bayesiana si basa su una formula fondamentale nota come regola di Bayes. Sebbene sia un semplice risultato della teoria delle probabilità, la sua applicazione ha implicazioni profonde in molti campi, inclusi la scienza cognitiva e l’apprendimento automatico. Supponiamo di avere due variabili casuali, \\(A\\) e \\(B\\). Un principio della probabilità, chiamato regola della catena, ci consente di esprimere la probabilità congiunta di queste due variabili \\(P(A, B)\\) come il prodotto della probabilità condizionale di \\(A\\) dato \\(B\\) e della probabilità marginale di \\(B\\). In termini formali:\n\\[\nP(A, B) = P(A \\mid B) P(B).\n\\tag{29.1}\\]\nNon vi è nulla di speciale nel trattare \\(A\\) prima di \\(B\\); possiamo infatti scrivere anche:\n\\[\nP(A, B) = P(B \\mid A) P(A).\n\\tag{29.2}\\]\nDalle due equazioni precedenti possiamo derivare la regola di Bayes riorganizzando i termini:\n\\[\nP(B \\mid A) = \\frac{P(A \\mid B) P(B)}{P(A)}.\n\\tag{29.3}\\]\nQuesta espressione, nota come regola di Bayes, ci permette di calcolare la probabilità condizionale di \\(B\\) dato \\(A\\), usando la probabilità condizionale opposta \\(P(A \\mid B)\\), la probabilità a priori \\(P(B)\\) e la probabilità marginale \\(P(A)\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#applicazioni-della-regola-di-bayes",
    "href": "chapters/probability/06_bayes_theorem.html#applicazioni-della-regola-di-bayes",
    "title": "29  Il teorema di Bayes",
    "section": "\n29.4 Applicazioni della Regola di Bayes",
    "text": "29.4 Applicazioni della Regola di Bayes\nLa forza della regola di Bayes si manifesta pienamente quando viene applicata al contesto dell’inferenza. Supponiamo di avere un agente che cerca di inferire quale processo ha generato alcuni dati \\(D\\). Indichiamo con \\(H\\) un’ipotesi su tale processo. L’agente usa le probabilità per rappresentare il grado di credenza in \\(H\\) e nelle ipotesi alternative \\(H'\\). La probabilità a priori \\(P(H)\\) rappresenta la credenza che l’agente attribuisce a \\(H\\) prima di osservare i dati.\nQuando l’agente osserva i nuovi dati \\(D\\), aggiorna la credenza ottenendo la probabilità a posteriori \\(P(H \\mid D)\\). La regola di Bayes permette di calcolare questa probabilità come segue:\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) P(H)}{P(D)}.\n\\tag{29.4}\\]\nIn questa equazione:\n\n\n\\(P(D \\mid H)\\): la verosimiglianza, ovvero la probabilità di osservare i dati \\(D\\) assumendo che l’ipotesi \\(H\\) sia vera. Questa componente valuta quanto l’ipotesi predice i dati osservati.\n\n\\(P(H)\\): la probabilità a priori di \\(H\\).\n\n\\(P(D)\\): la probabilità marginale dei dati, calcolata sommando (o integrando) le probabilità congiunte per tutte le ipotesi \\(H'\\).\n\n\n29.4.1 La Marginalizzazione\nLa probabilità marginale di \\(D\\), necessaria per normalizzare la distribuzione a posteriori, si ottiene considerando tutte le ipotesi possibili \\(H'\\). Per ipotesi discrete, la somma è:\n\\[\nP(D) = \\sum_{H' \\in H} P(D \\mid H') P(H').\n\\]\nSostituendo questa espressione nella regola di Bayes otteniamo:\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) P(H)}{\\sum_{H' \\in H} P(D \\mid H') P(H')}.\n\\tag{29.5}\\]\nNel caso continuo, la somma è sostituita da un integrale:\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) P(H)}{\\int P(D \\mid H') P(H') \\, dH'}.\n\\tag{29.6}\\]\n\n29.4.2 Componenti Chiave della Formula di Bayes\nLa regola di Bayes si basa su tre componenti principali:\n\n\nProbabilità a Priori \\(P(H)\\): La credenza iniziale sull’ipotesi \\(H\\), basata su informazioni preesistenti.\n\nVerosimiglianza \\(P(D \\mid H)\\): La probabilità dei dati osservati \\(D\\), dato che \\(H\\) sia vera. Misura quanto \\(H\\) spiega \\(D\\).\n\nProbabilità a Posteriori \\(P(H \\mid D)\\): La credenza aggiornata in \\(H\\) dopo aver osservato \\(D\\).\n\nGrazie alla regola di Bayes, possiamo aggiornare costantemente le nostre credenze man mano che nuove informazioni diventano disponibili. Questo processo dinamico di aggiornamento ci permette di affinare le nostre convinzioni e le nostre previsioni, rendendo il modello bayesiano particolarmente utile nelle situazioni in cui le informazioni sono incomplete o incerte. Questo approccio non solo ci consente di prendere decisioni più informate, ma ci permette anche di sviluppare modelli più accurati della realtà basati sulle evidenze.\n\n29.4.3 Applicazioni dei modelli bayesiani\nCome discusso da Griffiths et al. (2024), negli ultimi anni, i modelli bayesiani hanno acquisito un’importanza crescente in vari campi delle scienze cognitive. Questi modelli sono stati applicati allo studio dell’apprendimento animale (Courville, Daw, & Touretzky, 2006), dell’apprendimento induttivo umano e della generalizzazione (Tenenbaum, Griffiths, & Kemp, 2006), della percezione visiva (Yuille & Kersten, 2006), del controllo motorio (Kording & Wolpert, 2006), della memoria semantica (Steyvers, Griffiths, & Dennis, 2006), dell’acquisizione e del processamento del linguaggio (Chater & Manning, 2006; Xu & Tenenbaum, in press), del ragionamento simbolico (Oaksford & Chater, 2001), dell’apprendimento causale (Steyvers, Tenenbaum, Wagenmakers, & Blum, 2003; Griffiths & Tenenbaum, 2005, 2007a), e della cognizione sociale (Baker, Tenenbaum, & Saxe, 2007), tra molti altri argomenti.\nDietro questi diversi programmi di ricerca emerge una domanda centrale: come fa la mente umana ad andare oltre i dati dell’esperienza? In altre parole, come riesce la mente a costruire modelli complessi e astratti del mondo, partendo solo da dati sparsi e rumorosi, osservati attraverso i nostri sensi? La risposta proposta dall’approccio bayesiano è che la mente umana utilizza un processo di inferenza probabilistica per aggiornare le proprie credenze sulla base delle nuove evidenze, creando così modelli del mondo sempre più accurati e raffinati.\n\nEsempio 29.1 Il problema di Monty Hall può essere risolto utilizzando il Teorema di Bayes, che permette di aggiornare la probabilità di un evento in base a nuove informazioni. Vediamo come applicarlo passo dopo passo.\nCi sono tre porte:\n\ndietro una porta c’è un’automobile (il premio);\ndietro le altre due porte ci sono delle capre.\n\nIl giocatore sceglie una porta (ad esempio, la porta 1). Successivamente, il conduttore (che sa cosa c’è dietro ogni porta) apre una delle due porte rimanenti, rivelando una capra (ad esempio, apre la porta 3). A questo punto, il giocatore può decidere se mantenere la scelta iniziale o cambiare porta.\nVogliamo calcolare la probabilità che l’automobile sia dietro la porta 2, sapendo che il conduttore ha aperto la porta 3.\nDefinizione degli eventi.\n\nA1, A2, A3: l’automobile si trova dietro la porta 1, 2 o 3, rispettivamente.\nP3: il conduttore apre la porta 3, rivelando una capra.\n\nVogliamo calcolare la probabilità condizionata \\(P(A2 \\mid P3)\\), ovvero la probabilità che l’automobile sia dietro la porta 2, sapendo che il conduttore ha aperto la porta 3. La formula di Bayes è:\n\\[\nP(A2 \\mid P3) = \\frac{P(P3 \\mid A2) \\cdot P(A2)}{P(P3)}\n\\]\n\n\n\\(P(A2)\\): probabilità iniziale che l’automobile sia dietro la porta 2.\n\nPoiché ci sono tre porte e solo un’automobile, \\(P(A2) = \\frac{1}{3}\\).\n\n\n\n\\(P(P3 \\mid A2)\\): probabilità che il conduttore apra la porta 3, sapendo che l’automobile è dietro la porta 2.\n\nSe l’automobile è dietro la porta 2, il conduttore deve aprire la porta 3 (non può aprire la porta 1, scelta dal giocatore, né la porta 2, dove c’è l’automobile). Quindi, \\(P(P3 \\mid A2) = 1\\).\n\n\n\n\\(P(P3)\\): probabilità che il conduttore apra la porta 3.\n\nIl conduttore può aprire la porta 3 in due casi:\n\nSe l’automobile è dietro la porta 2 (con probabilità \\(\\frac{1}{3}\\)).\nSe l’automobile è dietro la porta 1 (con probabilità \\(\\frac{1}{3}\\)), e il conduttore sceglie casualmente tra la porta 2 e la porta 3 (con probabilità \\(\\frac{1}{2}\\)).\n\n\nQuindi: \\[\n\\begin{align}\nP(P3) &= P(P3 \\mid A2) \\cdot P(A2) + P(P3 \\mid A1) \\cdot P(A1) \\notag\\\\\n&= 1 \\cdot \\frac{1}{3} + \\frac{1}{2} \\cdot \\frac{1}{3} = \\frac{1}{3} + \\frac{1}{6} = \\frac{1}{2}.\\notag\n\\end{align}\n\\]\n\n\n\n\nSostituendo i valori calcolati:\n\\[\nP(A2 \\mid P3) = \\frac{1 \\cdot \\frac{1}{3}}{\\frac{1}{2}} = \\frac{\\frac{1}{3}}{\\frac{1}{2}} = \\frac{2}{3}.\n\\]\nIn conclusione, la probabilità che l’automobile sia dietro la porta 2, sapendo che il conduttore ha aperto la porta 3, è \\(\\frac{2}{3}\\) (circa 66.7%). Questo significa che cambiando porta, il giocatore ha una probabilità di vincita del 66.7%, mentre mantenendo la scelta iniziale la probabilità è solo del 33.3%.\nQuesto esempio mostra come il Teorema di Bayes permetta di aggiornare le probabilità in base a nuove informazioni. Nel contesto del problema di Monty Hall, cambiare porta raddoppia le possibilità di vincere l’automobile.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#test-medici",
    "href": "chapters/probability/06_bayes_theorem.html#test-medici",
    "title": "29  Il teorema di Bayes",
    "section": "\n29.5 Test medici",
    "text": "29.5 Test medici\nIl modo più comune per spiegare il teorema di Bayes è attraverso i test medici.\n\nEsempio 29.2 Prendiamo come esempio il caso della mammografia e la diagnosi del cancro al seno che abbiamo già discusso in precedenza. Supponiamo di avere un test di mammografia con una sensibilità del 90% e una specificità del 90%. Questo significa che:\n\nIn presenza di cancro al seno, la probabilità che il test lo rilevi correttamente è del 90%.\nIn assenza di cancro al seno, la probabilità che il test confermi correttamente l’assenza della malattia è del 90%.\n\nIn altri termini, il test ha un tasso di falsi negativi del 10% e un tasso di falsi positivi anch’esso del 10%.\nDefiniamo due ipotesi:\n\n\n\\(M^+\\): presenza della malattia\n\n\\(M^-\\): assenza della malattia\n\nL’evidenza è rappresentata dal risultato positivo di un test di mammografia, che indichiamo con \\(T^+\\).\nApplicando il teorema di Bayes, possiamo calcolare la probabilità di avere il cancro al seno dato un risultato positivo al test, come segue:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)},\n\\]\ndove:\n\n\\(P(M^+ \\mid T^+)\\) è la probabilità di avere il cancro (\\(M^+\\)) dato un risultato positivo al test (\\(T^+\\)).\n\\(P(T^+ \\mid M^+)\\) rappresenta la sensibilità del test, ovvero la probabilità che il test risulti positivo in presenza effettiva del cancro. In questo caso, è pari a 0.90.\n\\(P(M^+)\\) è la probabilità a priori che una persona abbia il cancro, ovvero la prevalenza della malattia nella popolazione.\n\n\\(P(T^+ \\mid M^-)\\) indica la probabilità di un falso positivo, cioè la probabilità che il test risulti positivo in assenza di cancro. Con una specificità del 90%, questa probabilità si calcola come:\n\\[\nP(T^+ \\mid M^-) = 1 - \\text{Specificità} = 1 - 0.90 = 0.10\n\\]\nQuesto significa che c’è una probabilità del 10% che il test diagnostichi erroneamente la presenza del cancro in una persona sana.\n\n\\(P(M^-)\\) è la probabilità a priori che una persona non sia affetta da cancro prima di effettuare il test.\n\nQuesta formulazione del teorema di Bayes ci permette di calcolare la probabilità effettiva di avere il cancro al seno, dato un risultato positivo al test di mammografia, tenendo conto sia della sensibilità e specificità del test, sia della prevalenza della malattia nella popolazione.\nInserendo nella formula i del problema, otteniamo:\n\\[\n\\begin{align}\nP(M^+ \\mid T^+) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n&= \\frac{9}{108} \\notag\\\\\n&\\approx 0.083.\\notag\n\\end{align}\n\\]\nI calcoli effettuati evidenziano come, in presenza di una mammografia positiva ottenuta con un test avente sensibilità e specificità pari al 90%, la probabilità di effettiva positività al tumore al seno si attesta intorno all’8.3%. Tale risultato conferma quanto precedentemente ottenuto nel ?sec-cond-prob, attraverso un metodo di calcolo alternativo.\n\n\n29.5.1 Il Valore Predittivo di un Test di Laboratorio\nPer semplicità, possiamo riscrivere il teorema di Bayes in due modi distinti per calcolare ciò che viene chiamato valore predittivo del test positivo e valore predittivo del test negativo.\nLa comprensione di tre elementi è fondamentale per questo calcolo: la prevalenza della malattia, la sensibilità e la specificità del test.\n\nPrevalenza: Si riferisce alla percentuale di individui in una popolazione affetti da una certa malattia in un determinato momento. Viene espressa come percentuale o frazione della popolazione. Per esempio, una prevalenza dello 0,5% indica che su mille persone, cinque sono affette dalla malattia.\n\nSensibilità: Indica la capacità del test di identificare correttamente la malattia negli individui malati. Viene calcolata come la frazione di veri positivi (individui malati correttamente identificati) sul totale degli individui malati. La formula della sensibilità (\\(Sens\\)) è la seguente:\n\\[ \\text{Sensibilità} = \\frac{TP}{TP + FN}, \\]\ndove \\(TP\\) rappresenta i veri positivi e \\(FN\\) i falsi negativi. Pertanto, la sensibilità misura la probabilità che il test risulti positivo se la malattia è effettivamente presente.\n\n\nSpecificità: Misura la capacità del test di riconoscere gli individui sani, producendo un risultato negativo per chi non è affetto dalla malattia. Si calcola come la frazione di veri negativi (individui sani correttamente identificati) sul totale degli individui sani. La specificità (\\(Spec\\)) si definisce come:\n\\[ \\text{Specificità} = \\frac{TN}{TN + FP}, \\]\ndove \\(TN\\) sono i veri negativi e \\(FP\\) i falsi positivi. Così, la specificità rappresenta la probabilità che il test risulti negativo in assenza della malattia.\n\n\nQuesta tabella riassume la terminologia:\n\n\n\n\n\n\n\n\n\n\\(T^+\\)\n\\(T^-\\)\nTotale\n\n\n\n\\(M^+\\)\n\n\\(P(T^+ \\cap M^+)\\)  (Sensibilità)\n\n\\(P(T^- \\cap M^+)\\)  (1 - Sensibilità)\n\\(P(M^+)\\)\n\n\n\\(M^-\\)\n\n\\(P(T^+ \\cap M^-)\\)  (1 - Specificità)\n\n\\(P(T^- \\cap M^-)\\)  (Specificità)\n\\(P(M^-)\\)\n\n\nTotale\n\\(P(T^+)\\)\n\\(P(T^-)\\)\n1\n\n\n\ndove \\(T^+\\) e \\(T^-\\) indicano rispettivamente un risultato positivo o negativo del test, mentre \\(M^+\\) e \\(M^-\\) la presenza o assenza effettiva della malattia. In questa tabella, i totali marginali rappresentano:\n\n\nTotale per \\(M^+\\) e \\(M^-\\) (ultima colonna): La probabilità totale di avere la malattia (\\(P(M^+)\\)) e la probabilità totale di non avere la malattia (\\(P(M^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilità all’interno di ciascuna riga.\n\nTotale per \\(T^+\\) e \\(T^-\\) (ultima riga): La probabilità totale di un risultato positivo al test (\\(P(T^+)\\)) e la probabilità totale di un risultato negativo al test (\\(P(T^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilità all’interno di ciascuna colonna.\n\nTotale generale (angolo in basso a destra): La somma di tutte le probabilità, che per definizione è 1, rappresentando l’intera popolazione o il set di casi considerati.\n\nMediante il teorema di Bayes, possiamo usare queste informazioni per stimare la probabilità post-test di avere o non avere la malattia basandoci sul risultato del test.\nIl valore predittivo positivo (VPP) del test, cioè la probabilità post-test che un individuo sia malato dato un risultato positivo del test, è calcolato come:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)}.\n\\]\novvero,\n\\[ VPP = \\frac{(\\text{Sensibilità} \\times \\text{Prevalenza})}{(\\text{Sensibilità} \\times \\text{Prevalenza}) + (1 - \\text{Specificità}) \\times (1 - \\text{Prevalenza})} \\]\nAnalogamente, il valore predittivo negativo (VPN), che è la probabilità che un individuo non sia malato dato un risultato negativo del test, si calcola come:\n\\[\nP(M^- \\mid T^-) = \\frac{P(T^- \\mid M^-) \\cdot (1 - P(M^+))}{P(T^- \\mid M^-) \\cdot (1 - P(M^+)) + P(T^- \\mid M^+) \\cdot P(M^+)}.\n\\]\novvero,\n\\[ NPV = \\frac{\\text{Specificità} \\cdot (1 - \\text{Prevalenza})}{\\text{Specificità} \\cdot (1 - \\text{Prevalenza}) + (1 - \\text{Sensibilità}) \\cdot \\text{Prevalenza}}. \\]\n\nEsempio 29.3 Implementiamo le formule del valore predittivo positivo e del valore predittivo negativo del test in R e usiamo gli stessi dati dell’esercizio precedente.\n\npositive_predictive_value_of_diagnostic_test &lt;- function(sens, spec, prev) {\n  (sens * prev) / (sens * prev + (1 - spec) * (1 - prev))\n}\n\nnegative_predictive_value_of_diagnostic_test &lt;- function(sens, spec, prev) {\n  (spec * (1 - prev)) / (spec * (1 - prev) + (1 - sens) * prev)\n}\n\nInseriamo i dati del problema.\n\nsens = 0.9  # sensibilità\nspec = 0.9  # specificità\nprev = 0.01  # prevalenza\n\nIl valore predittivo del test positivo è:\n\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.083\n\nIl valore predittivo del test negativo è:\n\nres_neg &lt;- negative_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M- | T-) = %.3f\\n\", res_neg))\n#&gt; P(M- | T-) = 0.999\n\n\n\nEsempio 29.4 La simulazione seguente ha lo scopo di aiutare a visualizzare il teorema di Bayes, utilizzando come esempio gli stessi dati della mammografia che abbiamo analizzato in precedenza.\n\n# Parametri\nsensitivity &lt;- 0.90  # Sensibilità del test (P(T+ | M+))\nspecificity &lt;- 0.90  # Specificità del test (P(T- | M-))\nprev_cancer &lt;- 0.01  # Prevalenza (P(M+))\n\n# Simulazione per una popolazione di 100.000 persone\nN_mammography &lt;- 100000\n\n# Generazione del campione casuale\nset.seed(123)\noutcome_mammography &lt;- sample(\n  c(\"Cancer\", \"Healthy\"), \n  N_mammography, \n  replace = TRUE, \n  prob = c(prev_cancer, 1 - prev_cancer)\n)\n\n# Conteggio delle persone con e senza cancro\nN_C &lt;- sum(outcome_mammography == \"Cancer\")\nN_H &lt;- sum(outcome_mammography == \"Healthy\")\n\n# Simulazione dei risultati del test\ntest_mammography &lt;- character(N_mammography)\ntest_mammography[outcome_mammography == \"Cancer\"] &lt;- sample(\n  c(\"+\", \"-\"), \n  N_C, \n  replace = TRUE, \n  prob = c(sensitivity, 1 - sensitivity)\n)\ntest_mammography[outcome_mammography == \"Healthy\"] &lt;- sample(\n  c(\"-\", \"+\"), \n  N_H, \n  replace = TRUE, \n  prob = c(specificity, 1 - specificity)\n)\n\n# Creazione di un data frame per memorizzare i risultati\ndf_mammography &lt;- tibble(\n  outcome = outcome_mammography,\n  test = test_mammography\n)\n\n# Creazione di una tabella di contingenza\ncontingency_table_mammography &lt;- df_mammography %&gt;%\n  count(outcome, test) %&gt;%\n  pivot_wider(names_from = test, values_from = n, values_fill = 0)\n\ncontingency_table_mammography\n#&gt; # A tibble: 2 × 3\n#&gt;   outcome   `+`   `-`\n#&gt;   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1 Cancer    911   114\n#&gt; 2 Healthy  9897 89078\n\n\n# Calcolo delle probabilità basate sulla tabella di contingenza\n\n# Veri positivi (cancro e risultato positivo al test)\ntrue_positives &lt;- contingency_table_mammography %&gt;%\n  filter(outcome == \"Cancer\") %&gt;%\n  pull(`+`)\n\n# Falsi positivi (sani e risultato positivo al test)\nfalse_positives &lt;- contingency_table_mammography %&gt;%\n  filter(outcome == \"Healthy\") %&gt;%\n  pull(`+`)\n\n# Frequenza totale dei risultati positivi\ntotal_positives &lt;- true_positives + false_positives\n\n# Applicazione del teorema di Bayes sui dati simulati\nP_M_given_T &lt;- true_positives / total_positives\nP_M_given_T\n#&gt; [1] 0.08429\n\nUtilizzando i dati della simulazione, la probabilità che una persona abbia il cancro al seno dato un risultato positivo al test è molto vicina al valore teorico calcolato in precedenza (circa 8.3%). Se eseguissimo la simulazione nuovamente, il valore ottenuto potrebbe variare leggermente a causa della casualità intrinseca nel campionamento. Tuttavia, ripetendo la simulazione molte volte, i risultati tenderanno a convergere verso il valore teorico, grazie alla legge dei grandi numeri. Questo conferma che il modello teorico è coerente con i risultati simulati.\n\n\nEsempio 29.5 Poniamoci il problema di capire quanto sia affidabile un test per l’HIV. Per fare questo, utilizzeremo le seguenti informazioni (Petersen, 2024):\n\n\nTasso di base dell’HIV (P(HIV)): 0.3% (0.003). Questa è la probabilità che una persona nella popolazione generale abbia l’HIV.\n\nSensibilità del test (P(Test+ HIV)): 95% (0.95). Questa è la probabilità che il test risulti positivo se la persona ha effettivamente l’HIV.\n\nSpecificità del test (P(Test- ¬HIV)): 99.28% (0.9928). Questa è la probabilità che il test risulti negativo se la persona non ha l’HIV.\n\nCalcolo della probabilità di HIV dato un test positivo.\nPer calcolare la probabilità di avere l’HIV dato un test positivo (P(HIV Test+)), utilizziamo il teorema di Bayes:\n\\[\nP(HIV \\mid Test+) = \\frac{P(Test+ \\mid HIV) \\times P(HIV)}{P(Test+)}.\n\\]\nAbbiamo bisogno di calcolare il denominatore, ovvero la probabilità complessiva di ottenere un test positivo (P(Test+)). Questo valore include sia i veri positivi che i falsi positivi:\n\\[\nP(Test+) = P(Test+ \\mid HIV) \\times P(HIV) + P(Test+ \\mid \\neg HIV) \\times P(\\neg HIV),\n\\]\ndove:\n\n\n\\(P(Test+ \\mid \\neg HIV) = 1 - P(Test- \\mid \\neg HIV) = 1 - 0.9928 = 0.0072\\) (tasso di falsi positivi),\n\n\\(P(\\neg HIV) = 1 - P(HIV) = 1 - 0.003 = 0.997\\).\n\nCalcoliamo \\(P(Test+)\\):\n\\[\nP(Test+) = (0.95 \\times 0.003) + (0.0072 \\times 0.997) \\approx 0.010027.\n\\]\nOra possiamo calcolare \\(P(HIV \\mid Test+)\\):\n\\[\nP(HIV \\mid Test+) = \\frac{0.95 \\times 0.003}{0.010027} \\approx 0.2844 \\text{ o 28.44\\%}.\n\\]\nQuindi, se il test risulta positivo, la probabilità di avere l’HIV è circa il 28.44%.\nCalcolo della probabilità di un secondo test positivo.\nDopo un primo test positivo, la probabilità di avere l’HIV è aumentata al 28.44%. Ora calcoleremo la probabilità che un secondo test risulti positivo e la conseguente probabilità di avere l’HIV dopo due test positivi consecutivi.\nPer calcolare \\(P(\\text{Secondo Test+})\\), consideriamo due scenari:\n\nLa persona ha effettivamente l’HIV:\n\nProbabilità: \\(P(HIV \\mid Test+) = 0.2844\\).\nProbabilità di un test positivo: \\(P(\\text{Test+} \\mid HIV) = 0.95\\) (sensibilità del test).\n\n\nLa persona non ha l’HIV:\n\nProbabilità: \\(P(\\neg HIV \\mid Test+) = 1 - P(HIV \\mid Test+) = 0.7156\\).\nProbabilità di un test positivo: \\(P(\\text{Test+} \\mid \\neg HIV) = 0.0072\\) (tasso di falsi positivi).\n\n\n\nUtilizziamo la formula della probabilità totale:\n\\[\n\\begin{aligned}\nP(\\text{Secondo Test+}) &= P(\\text{Test+} \\mid HIV) \\times P(HIV \\mid Test+) + \\\\\n&\\quad P(\\text{Test+} \\mid \\neg HIV) \\times P(\\neg HIV \\mid Test+).\n\\end{aligned}\n\\]\nSostituendo i valori:\n\\[\nP(\\text{Secondo Test+}) = (0.95 \\times 0.2844) + (0.0072 \\times 0.7156) \\approx 0.2753.\n\\]\nApplichiamo nuovamente il teorema di Bayes per calcolare la probabilità di avere l’HIV dopo un secondo test positivo:\n\\[\nP(HIV \\mid \\text{Secondo Test+}) = \\frac{P(\\text{Secondo Test+} \\mid HIV) \\times P(HIV \\mid Test+)}{P(\\text{Secondo Test+})}.\n\\]\nSostituendo i valori:\n\\[\nP(HIV \\mid \\text{Secondo Test+}) = \\frac{0.95 \\times 0.2844}{0.2753} \\approx 0.981.\n\\]\nDopo un secondo test positivo, la probabilità di avere l’HIV aumenta significativamente, passando dal 28.44% al 98.1%. Questo aumento drastico dimostra l’importanza di:\n\nConsiderare il tasso di base (prevalenza) nella popolazione.\nAggiornare progressivamente le probabilità con nuove evidenze.\nInterpretare i risultati di test diagnostici multipli in modo bayesiano.\n\nL’analisi evidenzia come l’accumulo di evidenze attraverso test ripetuti, in linea con i principi del teorema di Bayes, possa portare a una stima molto più accurata della probabilità di avere una condizione medica, riducendo significativamente l’incertezza iniziale.\n\n\nEsempio 29.6 Consideriamo ora un altro esempio relativo ai test medici e analizziamo i risultati del test antigenico rapido per il virus SARS-CoV-2 alla luce del teorema di Bayes. Questo test può essere eseguito mediante tampone nasale, tampone naso-orofaringeo o campione di saliva. L’Istituto Superiore di Sanità, nel documento pubblicato il 5 novembre 2020, sottolinea che, fino a quel momento, i dati disponibili sui vari test erano quelli forniti dai produttori: la sensibilità varia tra il 70% e l’86%, mentre la specificità si attesta tra il 95% e il 97%.\nPrendiamo un esempio specifico: nella settimana tra il 17 e il 23 marzo 2023, in Italia, il numero di individui positivi al virus è stato stimato essere di 138.599 (fonte: Il Sole 24 Ore). Questo dato corrisponde a una prevalenza di circa lo 0,2% su una popolazione totale di circa 59 milioni di persone.\n\n prev = 138599 / 59000000\n prev\n#&gt; [1] 0.002349\n\nL’obiettivo è determinare la probabilità di essere effettivamente affetti da Covid-19, dato un risultato positivo al test antigenico rapido, ossia \\(P(M^+ \\mid T^+)\\). Per raggiungere questo scopo, useremo la formula relativa al valore predittivo positivo del test.\n\n# Calcolo della sensibilità e specificità medie\nsens &lt;- (0.7 + 0.86) / 2  # sensibilità\nspec &lt;- (0.95 + 0.97) / 2 # specificità\n\n# Calcolo del valore predittivo positivo\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.044\n\nPertanto, se il risultato del tampone è positivo, la probabilità di essere effettivamente affetti da Covid-19 è solo del 4.4%.\nSe la prevalenza fosse 100 volte superiore (cioè, pari al 23.5%), la probabilità di avere il Covid-19, dato un risultato positivo del tampone, aumenterebbe notevolmente e sarebbe pari a circa l’86%.\n\n# Calcolo della prevalenza aumentata di 100 volte\nprev &lt;- 138599 / 59000000 * 100\n\n# Calcolo del valore predittivo positivo\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.857\n\nSe il risultato del test fosse negativo, considerando la prevalenza stimata del Covid-19 nella settimana dal 17 al 23 marzo 2023, la probabilità di non essere infetto sarebbe del 99.9%.\n\n# Calcolo della sensibilità, specificità e prevalenza\nsens &lt;- (0.7 + 0.86) / 2  # sensibilità\nspec &lt;- (0.95 + 0.97) / 2  # specificità\nprev &lt;- 138599 / 59000000  # prevalenza\n\n# Calcolo del valore predittivo negativo\nres_neg &lt;- negative_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M- | T-) = %.3f\\n\", res_neg))\n#&gt; P(M- | T-) = 0.999\n\nTuttavia, un’esito del genere non dovrebbe sorprenderci, considerando che la prevalenza della malattia è molto bassa; in altre parole, il risultato negativo conferma una situazione già presunta prima di sottoporsi al test. Il vero ostacolo, specialmente nel caso di malattie rare come il Covid-19 in quel periodo specifico, non risiede tanto nell’asserire l’assenza della malattia quanto piuttosto nel confermarne la presenza.\n\n\nEsempio 29.7 Consideriamo le persone in attesa di un figlio. Il teorema di Bayes gioca un ruolo cruciale nell’interpretazione dei test prenatali non invasivi (NIPT), un esame del sangue materno usato per rilevare anomalie cromosomiche fetali. Sebbene il NIPT sia spesso pubblicizzato con un’accuratezza del 99%, la sua affidabilità varia significativamente a seconda della condizione testata e della popolazione esaminata.\nParametri chiave del NIPT:\n\n\nSensibilità:\n\nSindrome di Down: 99%\nSindrome di Edwards: 97%\nSindrome di Patau: 91%\n\n\nSpecificità: circa 99.9% per tutte le condizioni citate\n\nPrevalenza nelle nascite:\n\nSindrome di Down: 1 su 700 (0.14%)\nSindrome di Edwards: 1 su 5,000 (0.02%)\nSindrome di Patau: 1 su 10,000 (0.01%)\n\n\n\nNonostante l’alta sensibilità e specificità, il VPP può essere sorprendentemente basso, soprattutto nella popolazione generale. Questo implica che molti risultati positivi potrebbero essere falsi positivi, in particolare per le condizioni più rare.\nPer calcolare il VPP, utilizziamo il teorema di Bayes:\n\\[ VPP = \\frac{(\\text{Sensibilità} \\times \\text{Prevalenza})}{(\\text{Sensibilità} \\times \\text{Prevalenza}) + (1 - \\text{Specificità}) \\times (1 - \\text{Prevalenza})} \\]\nApplicando questa formula alla popolazione generale:\n\nSindrome di Down: \\[ VPP = \\frac{(0.99 \\times 0.0014)}{(0.99 \\times 0.0014) + (1 - 0.999) \\times (1 - 0.0014)} \\approx 58\\% \\]\nSindrome di Edwards: \\[ VPP = \\frac{(0.97 \\times 0.0002)}{(0.97 \\times 0.0002) + (1 - 0.999) \\times (1 - 0.0002)} \\approx 16.2\\% \\]\nSindrome di Patau: \\[ VPP = \\frac{(0.91 \\times 0.0001)}{(0.91 \\times 0.0001) + (1 - 0.999) \\times (1 - 0.0001)} \\approx 8.3\\% \\]\n\nQuesti calcoli rivelano VPP molto bassi, specialmente per condizioni molto rare come la sindrome di Patau. Anche in questo caso, dunque, il teorema di Bayes ci mostra che la probabilità che un risultato positivo sia effettivamente corretto dipende non solo dall’accuratezza del test, ma anche dalla prevalenza della condizione nella popolazione testata. Per questo motivo, il NIPT risulta più affidabile nelle categorie ad alto rischio.\nIn conclusione, mentre il NIPT è uno strumento prezioso per lo screening prenatale, è fondamentale interpretare i risultati con cautela, considerando il contesto specifico di ogni paziente e la prevalenza della condizione nella popolazione di riferimento.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#la-fallacia-del-procuratore",
    "href": "chapters/probability/06_bayes_theorem.html#la-fallacia-del-procuratore",
    "title": "29  Il teorema di Bayes",
    "section": "\n29.6 La Fallacia del Procuratore",
    "text": "29.6 La Fallacia del Procuratore\nIl teorema di Bayes non è rilevante solo in ambito medico; è altrettanto cruciale nel contesto legale, dove un errore logico noto come fallacia del procuratore può avere conseguenze significative. Questa fallacia si verifica quando si confonde la probabilità di un risultato dato un evento con la probabilità dell’evento dato il risultato. In ambito giudiziario, ciò accade spesso quando si scambia la probabilità di ottenere una corrispondenza del DNA se una persona è innocente con la probabilità che una persona sia innocente dato che il test del DNA ha prodotto una corrispondenza.\n\nEsempio 29.8 Supponiamo che un test del DNA venga utilizzato per identificare un sospetto in una popolazione di 65 milioni di persone. Consideriamo i seguenti parametri:\n\n\nSensibilità: \\(P(T^+ \\mid C) = 99\\%\\), ovvero la probabilità che il test identifichi correttamente il colpevole.\n\nSpecificità: \\(P(T^- \\mid I) = 99.99997\\%\\), ovvero la probabilità che il test identifichi correttamente un innocente.\n\nPrevalenza: \\(P(C) = \\frac{1}{65.000.000}\\), ovvero la probabilità a priori che una persona qualsiasi sia il colpevole.\n\nUn campione di DNA è stato trovato sulla scena del crimine e confrontato con quello di una persona nel database. Determiniamo la probabilità che questa persona sia effettivamente il colpevole, dato che il test è positivo (\\(T^+\\)).\nPasso 1: Calcolo della Probabilità del Test Positivo \\(P(T^+)\\).\nLa probabilità di ottenere un test positivo (\\(T^+\\)) è data dalla somma delle probabilità di un risultato positivo per un colpevole e per un innocente:\n\\[\nP(T^+) = P(T^+ \\mid C) \\cdot P(C) + P(T^+ \\mid I) \\cdot P(I),\n\\]\ndove \\(P(I) = 1 - P(C)\\) è la probabilità che una persona sia innocente e \\(P(T^+ \\mid I) = 1 - \\text{Specificità}\\).\nSostituiamo i valori noti:\n\\[\nP(T^+) = 0.99 \\cdot \\frac{1}{65.000.000} + (1 - 0.9999997) \\cdot \\frac{64.999.999}{65.000.000}.\n\\]\nEseguiamo i calcoli:\n\\[\nP(T^+) \\approx 0.99 \\cdot 1.5385 \\times 10^{-8} + 0.0000003 \\cdot 0.9999999,\n\\]\n\\[\nP(T^+) \\approx 1.5231 \\times 10^{-8} + 2.9999997 \\times 10^{-7},\n\\]\n\\[\nP(T^+) \\approx 3.1523 \\times 10^{-7}.\n\\]\nPasso 2: Probabilità Condizionale che il Sospetto sia Colpevole Dato un Test Positivo.\nUtilizzando il teorema di Bayes, la probabilità a posteriori che il sospetto sia colpevole, dato un test positivo, è:\n\\[\nP(C \\mid T^+) = \\frac{P(T^+ \\mid C) \\cdot P(C)}{P(T^+)}.\n\\]\nSostituiamo i valori calcolati:\n\\[\nP(C \\mid T^+) = \\frac{0.99 \\cdot \\frac{1}{65.000.000}}{3.1523 \\times 10^{-7}},\n\\]\n\\[\nP(C \\mid T^+) = \\frac{0.99 \\cdot 1.5385 \\times 10^{-8}}{3.1523 \\times 10^{-7}},\n\\]\n\\[\nP(C \\mid T^+) \\approx 0.0483.\n\\]\nLa probabilità che il sospetto sia effettivamente il colpevole, dato che il test del DNA è positivo, è quindi circa 4.83%, nonostante la specificità estremamente elevata del test.\nQuesto risultato dimostra quanto sia importante considerare la bassa prevalenza del colpevole nella popolazione. Affermare, ad esempio, che “c’è solo una probabilità su 3 milioni che il sospetto sia innocente” confonde la specificità del test (\\(P(T^- \\mid I)\\)) con la probabilità condizionale di colpevolezza (\\(P(C \\mid T^+)\\)).\nIn realtà, la probabilità che il sospetto sia colpevole dato un test positivo è molto più bassa, a causa della prevalenza estremamente ridotta. Questo errore logico può portare a gravi ingiustizie, poiché non si considera che i falsi positivi diventano statisticamente più rilevanti quando il numero di innocenti testati è molto alto.\nPer chiarire, confondere \\(P(T^+ \\mid I)\\) con \\(P(I \\mid T^+)\\) è analogo a confondere “Quanto è probabile che il DNA di una persona corrisponda al campione, se è innocente?” con “Quanto è probabile che una persona sia innocente, dato che il suo DNA corrisponde al campione?”.\nIn conclusione, la fallacia del procuratore mette in evidenza l’importanza di interpretare correttamente i risultati dei test probabilistici in contesti legali. L’uso del teorema di Bayes è essenziale per evitare errori logici e per garantire che le decisioni siano basate su una comprensione accurata delle probabilità condizionali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#probabilità-inversa",
    "href": "chapters/probability/06_bayes_theorem.html#probabilità-inversa",
    "title": "29  Il teorema di Bayes",
    "section": "\n29.7 Probabilità Inversa",
    "text": "29.7 Probabilità Inversa\nGli esempi precedenti evidenziano la differenza tra due domande fondamentali. La prima è: “Qual è la probabilità di osservare un determinato risultato, supponendo che una certa ipotesi sia vera?” La seconda, invece, è: “Qual è la probabilità che un’ipotesi sia vera, dato il risultato osservato?”\nUn esempio che risponde alla prima domanda potrebbe essere questo: supponiamo che la probabilità di ottenere testa nel lancio di una moneta sia 0.5 (ipotesi). Qual è la probabilità di ottenere 0 teste in cinque lanci?\nPer la seconda domanda, un esempio potrebbe essere: supponiamo di aver ottenuto 0 teste in 5 lanci di una moneta (evidenza). Qual è la probabilità che la moneta sia effettivamente bilanciata, alla luce di questa osservazione?\nPer molto tempo, lo studio della probabilità si è concentrato principalmente sulla prima domanda. Tuttavia, nel XVIII secolo, il reverendo Thomas Bayes iniziò a riflettere sulla seconda domanda, dando origine a quello che oggi chiamiamo probabilità inversa.\nQuesto approccio ha generato numerose controversie nella storia della statistica, in gran parte perché influenza molti ambiti. Ad esempio, possiamo chiederci: quanto è probabile che un’ipotesi scientifica sia vera, dato il risultato di un esperimento? Per stimare questa probabilità — un compito che molti scienziati ritengono essenziale per la statistica moderna — è necessario fare uso del teorema di Bayes e delle probabilità a priori.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#riflessioni-conclusive",
    "href": "chapters/probability/06_bayes_theorem.html#riflessioni-conclusive",
    "title": "29  Il teorema di Bayes",
    "section": "\n29.8 Riflessioni Conclusive",
    "text": "29.8 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato vari esempi, principalmente nel campo medico e forense, per illustrare come il teorema di Bayes permetta di combinare le informazioni derivate dalle osservazioni con le conoscenze precedenti (priori), aggiornando così il nostro grado di convinzione rispetto a un’ipotesi. Il teorema di Bayes fornisce un meccanismo razionale, noto come “aggiornamento bayesiano”, che ci consente di ricalibrare le nostre convinzioni iniziali alla luce di nuove evidenze.\nUna lezione fondamentale che il teorema di Bayes ci insegna, sia nella ricerca scientifica che nella vita quotidiana, è che spesso non ci interessa tanto conoscere la probabilità che qualcosa accada assumendo vera un’ipotesi, quanto piuttosto la probabilità che un’ipotesi sia vera, dato che abbiamo osservato una certa evidenza. In altre parole, la forza del teorema di Bayes sta nella sua capacità di affrontare direttamente il problema inverso, cioè come dedurre la verità di un’ipotesi a partire dalle osservazioni.\nIl framework bayesiano per l’inferenza probabilistica offre un approccio generale per comprendere come i problemi di induzione possano essere risolti in linea di principio e, forse, anche come possano essere affrontati dalla mente umana.\nIn questo capitolo ci siamo concentrati sull’applicazione del teorema di Bayes utilizzando probabilità puntuali. Tuttavia, il teorema esprime pienamente il suo potenziale quando sia l’evidenza che i gradi di certezza a priori delle ipotesi sono rappresentati attraverso distribuzioni di probabilità continue. Questo sarà l’argomento centrale nella prossima sezione della dispensa, dove approfondiremo il flusso di lavoro bayesiano e l’uso di distribuzioni continue nell’aggiornamento bayesiano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/06_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "title": "29  Il teorema di Bayes",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#&gt;  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3   \n#&gt;  [9] grid_4.4.2        timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    mnormt_2.1.1      cli_3.6.4         rlang_1.1.5      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       yaml_2.3.10       tools_4.4.2      \n#&gt; [21] parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1     \n#&gt; [25] vctrs_0.6.5       R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4\n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      glue_1.8.0       \n#&gt; [33] xfun_0.50         tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-167      rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#bibliografia",
    "href": "chapters/probability/06_bayes_theorem.html#bibliografia",
    "title": "29  Il teorema di Bayes",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nGriffiths, T. L., Chater, N., & Tenenbaum, J. B. (2024). Bayesian models of cognition: reverse engineering the mind. MIT Press.\n\n\nPetersen, I. T. (2024). Principles of psychological assessment: With applied examples in R. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html",
    "href": "chapters/probability/07_random_var.html",
    "title": "30  Variabili casuali",
    "section": "",
    "text": "30.1 Introduzione\nFino ad ora abbiamo studiato le probabilità associate a eventi, come la possibilità di vincere il gioco di Monty Hall o di avere una rara condizione medica in seguito a un test positivo. Tuttavia, in molte situazioni pratiche vogliamo conoscere aspetti più dettagliati. Ad esempio, potremmo chiederci:\nPer rispondere a tali domande è necessario lavorare con le variabili casuali. In questo capitolo introdurremo il concetto di variabile casuale e ne analizzeremo le proprietà fondamentali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#introduzione",
    "href": "chapters/probability/07_random_var.html#introduzione",
    "title": "30  Variabili casuali",
    "section": "",
    "text": "Quanti tentativi occorrono affinché, in un gioco simile a Monty Hall, un concorrente vinca?\nQuanto durerà un determinato evento o condizione?\nQual è la perdita attesa giocando d’azzardo con un dado sbilanciato per molte ore?",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#definizione-di-variabile-casuale",
    "href": "chapters/probability/07_random_var.html#definizione-di-variabile-casuale",
    "title": "30  Variabili casuali",
    "section": "\n30.2 Definizione di Variabile Casuale",
    "text": "30.2 Definizione di Variabile Casuale\nUna variabile casuale è una funzione che associa ogni elemento di uno spazio campionario a un valore numerico. Questo strumento permette di trasformare esiti qualitativi (ad esempio, il risultato di un lancio di carte, come cuori, quadri, fiori, picche) in valori numerici, facilitando così l’analisi matematica.\nDefinizione. Sia \\(S\\) lo spazio campionario di un esperimento aleatorio. Una variabile casuale \\(X\\) è una funzione\\[\nX: S \\longrightarrow \\mathbb{R},\n\\] che associa ad ogni esito \\(s \\in S\\) un numero reale \\(X(s)\\).\n\nEsempio 30.1 Un esempio è la variabile casuale \\(X\\), che rappresenta la somma dei risultati del lancio di due dadi. Se definiamo \\(X\\) come la somma dei valori ottenuti dai due dadi, abbiamo trasformato un’osservazione fisica (il lancio dei dadi) in un valore numerico che rappresenta un evento specifico. Ad esempio, se il primo dado mostra 4 e il secondo dado mostra 4, allora \\(X = 8\\).\n\n\nLa variabile aleatoria \\(X\\) rappresenta la somma di due dadi (figura tratta da Chan & Kroese, 2025).\n\n\n\nEsempio 30.2 Lanciamo due dadi equilibrati e annotiamo la somma dei valori delle loro facce. Se lanciamo i dadi consecutivamente e osserviamo entrambi i risultati, lo spazio campionario è:\\[\n\\Omega = \\{(1, 1), \\dots, (6, 6)\\}.\n\\]\nLa funzione \\(X\\), definita come \\(X(i, j) = i + j\\), è una variabile aleatoria che associa l’esito \\((i, j)\\) alla somma \\(i + j\\), come illustrato nella figura dell’esempio precedente.\nNotiamo che cinque esiti nello spazio campionario sono mappati al valore 8. Una notazione naturale per indicare l’insieme di questi esiti è \\(\\{X = 8\\}\\). Poiché tutti gli esiti in \\(\\Omega\\) sono equiprobabili, la probabilità di ottenere una somma pari a 8 è:\\[\nP(\\{X = 8\\}) = \\frac{5}{36}.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#tipologie-di-variabili-casuali",
    "href": "chapters/probability/07_random_var.html#tipologie-di-variabili-casuali",
    "title": "30  Variabili casuali",
    "section": "\n30.3 Tipologie di Variabili Casuali",
    "text": "30.3 Tipologie di Variabili Casuali\nLe variabili casuali si dividono in due categorie principali:\n\n30.3.1 Variabili Casuali Discrete\nUna variabile casuale discreta assume un insieme finito o numerabile di valori. Gli esempi includono il numero di teste ottenute in lanci di moneta o la somma dei risultati di due dadi. Per queste variabili, la funzione di massa di probabilità (PMF) assegna a ciascun valore \\(x\\) la probabilità \\(P(X = x)\\).\n\nEsempio 30.3 Nel lancio di due dadi, la variabile \\(X\\) (somma dei punti) può assumere valori interi da 2 a 12. La distribuzione di \\(X\\) si ottiene contando i casi favorevoli per ciascun valore e dividendo per il numero totale di esiti (36).\n\n\n30.3.2 Variabili Casuali Continue\nUna variabile casuale continua può assumere infiniti valori in un intervallo (ad esempio, l’altezza di una persona). In questo caso non si assegna una probabilità a un singolo valore (che risulterebbe essere zero), ma si definisce una funzione di densità di probabilità (PDF), tale che l’integrale della funzione su un intervallo fornisce la probabilità che la variabile cada in quell’intervallo.\n\nEsempio 30.4 Considera una variabile \\(X\\) che rappresenta l’altezza in centimetri. Invece di \\(P(X = 170)\\), calcoliamo probabilità come \\(P(170 \\leq X \\leq 180)\\) mediante l’integrale della PDF in quell’intervallo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#notazione-convenzionale",
    "href": "chapters/probability/07_random_var.html#notazione-convenzionale",
    "title": "30  Variabili casuali",
    "section": "\n30.4 Notazione Convenzionale",
    "text": "30.4 Notazione Convenzionale\nNella letteratura di probabilità si adotta una convenzione per distinguere la variabile casuale dal suo valore specifico:\n\nSi utilizza la lettera maiuscola (es. \\(X\\)) per indicare la variabile casuale.\nLa lettera minuscola (es. \\(x\\)) rappresenta un particolare valore che \\(X\\) può assumere.\n\nQuesta distinzione aiuta a chiarire quando si parla del concetto generale rispetto a un’osservazione specifica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#variabili-casuali-multiple",
    "href": "chapters/probability/07_random_var.html#variabili-casuali-multiple",
    "title": "30  Variabili casuali",
    "section": "\n30.5 Variabili Casuali Multiple",
    "text": "30.5 Variabili Casuali Multiple\nSpesso si studiano esperimenti in cui più variabili casuali interagiscono. Ad esempio, nel lancio di una moneta per tre volte possiamo definire tre variabili casuali indipendenti \\(X_1\\), \\(X_2\\) e \\(X_3\\), dove:\n\\[\nP(X_n = 1) = 0.5 \\quad (\\text{testa}), \\qquad P(X_n = 0) = 0.5 \\quad (\\text{croce}), \\quad n = 1, 2, 3.\n\\]\nSi può poi definire una nuova variabile casuale, ad esempio: \\[\nZ = X_1 + X_2 + X_3,\n\\] che rappresenta il numero totale di teste ottenute. In questo caso, \\(Z\\) è una variabile discreta che può assumere i valori 0, 1, 2 o 3.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#distribuzione-di-probabilità",
    "href": "chapters/probability/07_random_var.html#distribuzione-di-probabilità",
    "title": "30  Variabili casuali",
    "section": "\n30.6 Distribuzione di Probabilità",
    "text": "30.6 Distribuzione di Probabilità\nLa distribuzione di probabilità di una variabile casuale descrive come le probabilità sono assegnate ai possibili valori (o intervalli di valori) della variabile.\n\n30.6.1 Funzione di Massa di Probabilità (PMF) per Variabili Discrete\nPer una variabile discreta \\(X\\), la distribuzione è definita attraverso la PMF, \\(f(x)\\), dove: \\[\nf(x) = P(X = x).\n\\]\nUna volta nota la PMF, è possibile calcolare la probabilità di qualsiasi evento correlato a \\(X\\). Ad esempio, per un insieme \\(B\\) di valori: \\[\nP(X \\in B) = \\sum_{x \\in B} f(x).\n\\]\n\nEsempio 30.5 Consideriamo di nuovo il lancio di due dadi con \\(X\\) definita come la somma dei loro valori. La tabella seguente riassume i casi favorevoli, il numero di occorrenze e la probabilità associata a ciascun valore:\n\n\n\n\n\n\n\n\n\\(X\\)\nCasi Favoriti\nNumero di Casi\n\\(P(X = x)\\)\n\n\n\n2\n\\((1,1)\\)\n1\n\\(\\frac{1}{36}\\)\n\n\n3\n\\((1,2), (2,1)\\)\n2\n\\(\\frac{2}{36} = \\frac{1}{18}\\)\n\n\n4\n\\((1,3), (2,2), (3,1)\\)\n3\n\\(\\frac{3}{36} = \\frac{1}{12}\\)\n\n\n5\n\\((1,4), (2,3), (3,2), (4,1)\\)\n4\n\\(\\frac{4}{36} = \\frac{1}{9}\\)\n\n\n6\n\\((1,5), (2,4), (3,3), (4,2), (5,1)\\)\n5\n\\(\\frac{5}{36}\\)\n\n\n7\n\\((1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\\)\n6\n\\(\\frac{6}{36} = \\frac{1}{6}\\)\n\n\n8\n\\((2,6), (3,5), (4,4), (5,3), (6,2)\\)\n5\n\\(\\frac{5}{36}\\)\n\n\n9\n\\((3,6), (4,5), (5,4), (6,3)\\)\n4\n\\(\\frac{4}{36} = \\frac{1}{9}\\)\n\n\n10\n\\((4,6), (5,5), (6,4)\\)\n3\n\\(\\frac{3}{36} = \\frac{1}{12}\\)\n\n\n11\n\\((5,6), (6,5)\\)\n2\n\\(\\frac{2}{36} = \\frac{1}{18}\\)\n\n\n12\n\\((6,6)\\)\n1\n\\(\\frac{1}{36}\\)\n\n\n\nQuesta tabella descrive in maniera completa la distribuzione di \\(X\\): ad esempio, la probabilità di ottenere una somma pari a 7 è \\(\\frac{1}{6}\\) perché esistono 6 combinazioni favorevoli su 36 possibili.\n\n\n30.6.2 Funzione di Distribuzione Cumulativa (CDF)\nLa funzione di distribuzione cumulativa (CDF) di una variabile casuale \\(X\\) è definita da: \\[\nF(x) = P(X \\leq x).\n\\] Questa funzione fornisce la probabilità che \\(X\\) assuma un valore minore o uguale a \\(x\\). In altre parole, la CDF rappresenta la probabilità cumulata dalla parte inferiore dello spazio di probabilità fino al punto \\(x\\).\n\n30.6.2.1 Proprietà della CDF\n\nMonotonia non decrescente:\nSe \\(x_1 &lt; x_2\\), allora \\(F(x_1) \\leq F(x_2)\\). La funzione non diminuisce mai al crescere di \\(x\\).\nNormalizzazione:\\[\n\\lim_{x \\to -\\infty} F(x) = 0 \\quad \\text{e} \\quad \\lim_{x \\to +\\infty} F(x) = 1.\n\\] Questo significa che la probabilità cumulata parte da 0 e, all’infinito, raggiunge 1.\nContinuità a destra:\nPer ogni \\(x\\), vale \\(F(x) = \\lim_{h \\downarrow 0} F(x+h)\\).\n\nPer una variabile discreta, la CDF si calcola sommando le probabilità dei valori minori o uguali a \\(x\\): \\[\nF(x) = \\sum_{x_i \\le x} P(X = x_i).\n\\]\n\nEsempio 30.6 Utilizzando la variabile casuale \\(Z\\) definita come la somma dei due dadi, possiamo costruire una tabella che riassuma sia la PMF che la CDF:\n\n\n\\(z\\)\n\\(P(Z = z)\\)\n\\(F(z)\\)\n\n\n\n2\n\\(\\frac{1}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n3\n\\(\\frac{2}{36}\\)\n\\(\\frac{1+2}{36} = \\frac{3}{36}\\)\n\n\n4\n\\(\\frac{3}{36}\\)\n\\(\\frac{1+2+3}{36} = \\frac{6}{36}\\)\n\n\n5\n\\(\\frac{4}{36}\\)\n\\(\\frac{10}{36}\\)\n\n\n6\n\\(\\frac{5}{36}\\)\n\\(\\frac{15}{36}\\)\n\n\n7\n\\(\\frac{6}{36}\\)\n\\(\\frac{21}{36}\\)\n\n\n8\n\\(\\frac{5}{36}\\)\n\\(\\frac{26}{36}\\)\n\n\n9\n\\(\\frac{4}{36}\\)\n\\(\\frac{30}{36}\\)\n\n\n10\n\\(\\frac{3}{36}\\)\n\\(\\frac{33}{36}\\)\n\n\n11\n\\(\\frac{2}{36}\\)\n\\(\\frac{35}{36}\\)\n\n\n12\n\\(\\frac{1}{36}\\)\n\\(\\frac{36}{36} = 1\\)\n\n\n\nAd esempio, \\(F(7) = \\frac{21}{36}\\) significa che la probabilità di ottenere una somma minore o uguale a 7 è \\(\\frac{21}{36}\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#distribuzioni-per-variabili-continue",
    "href": "chapters/probability/07_random_var.html#distribuzioni-per-variabili-continue",
    "title": "30  Variabili casuali",
    "section": "\n30.7 Distribuzioni per Variabili Continue",
    "text": "30.7 Distribuzioni per Variabili Continue\nPer le variabili casuali continue, non si usa la PMF ma la funzione di densità di probabilità (PDF). Una variabile casuale \\(X\\) si dice avere una distribuzione continua se esiste una funzione \\(f\\) positiva, tale che:\n\nL’integrale totale di \\(f\\) risulta pari a 1: \\[\n\\int_{-\\infty}^{+\\infty} f(x) \\, dx = 1.\n\\]\n\nLa probabilità che \\(X\\) cada in un intervallo \\((a, b]\\) è data da: \\[\nP(a &lt; X \\leq b) = \\int_a^b f(x) \\, dx.\n\\]\n\n\nAnche se usiamo lo stesso simbolo \\(f\\) per indicare la funzione di probabilità sia nel caso discreto che in quello continuo, il significato è adattato al contesto. Nel caso continuo la probabilità di un valore specifico è zero, mentre è l’integrale della PDF su un intervallo a fornire la probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#simulazione-della-distribuzione-di-probabilità",
    "href": "chapters/probability/07_random_var.html#simulazione-della-distribuzione-di-probabilità",
    "title": "30  Variabili casuali",
    "section": "\n30.8 Simulazione della Distribuzione di Probabilità",
    "text": "30.8 Simulazione della Distribuzione di Probabilità\nSpesso, anche se è possibile calcolare analiticamente la distribuzione di probabilità (come nel caso dei due dadi), può essere utile ottenere una stima empirica attraverso la simulazione. Questo approccio prevede di ripetere l’esperimento molte volte e di analizzare le frequenze relative dei risultati ottenuti.\n\n30.8.1 Esempio di Simulazione in R\nVediamo come implementare in R una simulazione per il lancio di due dadi e ottenere la distribuzione empirica della somma dei loro valori.\n\n\nDefinire una funzione per il lancio di un dado:\n\n# Funzione per simulare il lancio di un dado a sei facce\nroll_die &lt;- function() {\n  sample(1:6, size = 1)\n}\n\n\n\nDefinire una funzione per simulare il lancio di due dadi:\n\n# Funzione per simulare il lancio di due dadi per n volte\nroll_two_dice &lt;- function(n) {\n  purrr::map_dbl(1:n, ~ roll_die() + roll_die())\n}\n\n\n\nSimulare 100,000 lanci e visualizzare i primi 20 risultati:\n\n# Numero di simulazioni\nnrolls &lt;- 100000\n\n# Simula i risultati del lancio di due dadi\nres &lt;- roll_two_dice(nrolls)\n\n# Visualizza i primi 20 risultati\ncat(res[1:20], \"\\n\")\n#&gt; 6 2 6 4 5 6 10 4 4 4 9 10 6 7 3 8 9 6 10 7\n\n\n\nCalcolare la distribuzione empirica:\nUtilizzando il pacchetto tidyverse, creiamo un DataFrame e calcoliamo le frequenze relative per ciascun valore (da 2 a 12):\n\n# Converti i risultati in un DataFrame (tibble)\ndf &lt;- tibble(y = res)\n\n# Calcola la distribuzione empirica delle probabilità\nempirical_probs &lt;- df |&gt; \n  count(y) |&gt; # Calcola le frequenze assolute\n  complete(y = 2:12, fill = list(n = 0)) |&gt; # Assicura che siano presenti tutti i valori\n  mutate(prob = n / nrolls)  # Calcola le probabilità relative\n\n# Visualizza la distribuzione empirica\nempirical_probs |&gt; \n  dplyr::select(y, prob)\n#&gt; # A tibble: 11 × 2\n#&gt;        y   prob\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt;  1     2 0.0282\n#&gt;  2     3 0.0566\n#&gt;  3     4 0.0849\n#&gt;  4     5 0.111 \n#&gt;  5     6 0.139 \n#&gt;  6     7 0.165 \n#&gt;  7     8 0.138 \n#&gt;  8     9 0.110 \n#&gt;  9    10 0.0830\n#&gt; 10    11 0.0546\n#&gt; 11    12 0.0285\n\n\n\nIl risultato finale è una tabella che mostra per ogni valore (da 2 a 12) la frequenza relativa stimata. Con un numero elevato di simulazioni, questa distribuzione empirica convergerà a quella teorica, confermando la validità del modello analitico.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#conclusioni",
    "href": "chapters/probability/07_random_var.html#conclusioni",
    "title": "30  Variabili casuali",
    "section": "\n30.9 Conclusioni",
    "text": "30.9 Conclusioni\nIl concetto di variabile casuale ci consente di rappresentare numericamente i risultati di processi aleatori, trasformando osservazioni qualitative in dati quantitativi.\n\nLe variabili discrete utilizzano la funzione di massa di probabilità (PMF) per assegnare una probabilità a ciascun valore possibile.\nLe variabili continue sono descritte attraverso la funzione di densità di probabilità (PDF), e le probabilità sono calcolate integrando su intervalli.\n\nLa funzione di distribuzione cumulativa (CDF) è un ulteriore strumento che consente di esprimere in forma cumulata la probabilità di ottenere valori minori o uguali a un certo punto.\nInfine, le simulazioni numeriche rappresentano un metodo pratico per verificare le distribuzioni teoriche, rendendo questi concetti più tangibili e applicabili anche in situazioni complesse.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/07_random_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "30  Variabili casuali",
    "section": "\n30.10 Informazioni sull’Ambiente di Sviluppo",
    "text": "30.10 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-167      rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#bibliografia",
    "href": "chapters/probability/07_random_var.html#bibliografia",
    "title": "30  Variabili casuali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html",
    "href": "chapters/probability/08_prob_distributions.html",
    "title": "31  Distribuzioni di massa e di densità",
    "section": "",
    "text": "31.1 Introduzione\nNel Capitolo 30 abbiamo introdotto il concetto di variabile casuale, distinguendo tra variabili casuali discrete e continue. Per le prime, abbiamo descritto formalmente come assegnare una distribuzione di massa di probabilità, mentre per le seconde abbiamo introdotto la nozione di funzione di densità di probabilità. Fino a questo punto, i concetti di distribuzione di massa e densità sono stati trattati in termini prevalentemente formali e matematici.\nLo scopo di questo capitolo è quello di approfondire queste idee, fornendo un’interpretazione più intuitiva e concreta di tali concetti. Attraverso esempi ed analisi pratiche, cercheremo di chiarire il significato sottostante alle distribuzioni di probabilità, rendendo più accessibili queste fondamentali strutture della teoria delle probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#variabili-casuali-discrete-e-continue",
    "href": "chapters/probability/08_prob_distributions.html#variabili-casuali-discrete-e-continue",
    "title": "31  Distribuzioni di massa e di densità",
    "section": "\n31.2 Variabili Casuali Discrete e Continue",
    "text": "31.2 Variabili Casuali Discrete e Continue\nUn elemento fondamentale nella comprensione delle distribuzioni di probabilità è la distinzione tra variabili casuali discrete e continue, poiché le distribuzioni di probabilità associate differiscono in modo sostanziale.\n\n\nVariabili Casuali Discrete: assumono un numero finito o numerabile di valori. Ad esempio, il numero di successi in una serie di esperimenti o il risultato del lancio di un dado.\n\nVariabili Casuali Continue: possono assumere un numero infinito di valori all’interno di un intervallo. Esempi includono il tempo di attesa per un evento o il quoziente intellettivo (QI) di una persona.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#distribuzioni-di-probabilità-discrete",
    "href": "chapters/probability/08_prob_distributions.html#distribuzioni-di-probabilità-discrete",
    "title": "31  Distribuzioni di massa e di densità",
    "section": "\n31.3 Distribuzioni di Probabilità Discrete",
    "text": "31.3 Distribuzioni di Probabilità Discrete\nLe distribuzioni di probabilità discrete descrivono fenomeni aleatori con un numero finito o numerabile di esiti possibili. Queste distribuzioni sono rappresentate da una funzione di massa di probabilità (PMF), che assegna una probabilità a ciascun valore della variabile casuale.\n\nEsempio 31.1 Consideriamo un dado sbilanciato con la seguente distribuzione di probabilità:\n\n\nValore di \\(X\\)\n\nProbabilità \\(p(x)\\)\n\n\n\n\n1\n0.10\n\n\n2\n0.15\n\n\n3\n0.20\n\n\n4\n0.25\n\n\n5\n0.20\n\n\n6\n0.10\n\n\n\nPer visualizzare questa distribuzione, possiamo simulare 1000 lanci del dado e creare un diagramma a barre che rappresenta le frequenze relative osservate. In R:\n\n# Dati\nset.seed(123)\nprob &lt;- c(0.10, 0.15, 0.20, 0.25, 0.20, 0.10)\nlanci &lt;- sample(1:6, size = 1000, replace = TRUE, prob = prob)\n\n# Creazione di un data frame\ndf &lt;- data.frame(Valore = factor(lanci))\n\n# Creazione del diagramma a barre\nggplot(df, aes(x = Valore)) +\n  geom_bar(aes(y = after_stat(count) / sum(after_stat(count))), fill = \"skyblue\") +\n  labs(\n    title = \"Distribuzione empirica dei lanci\",\n    x = \"Valore\",\n    y = \"Frequenza relativa\"\n  )\n\n\n\n\n\n\n\nCon un numero sufficientemente grande di osservazioni, la distribuzione empirica si avvicina alla distribuzione teorica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#distribuzioni-di-probabilità-continue",
    "href": "chapters/probability/08_prob_distributions.html#distribuzioni-di-probabilità-continue",
    "title": "31  Distribuzioni di massa e di densità",
    "section": "\n31.4 Distribuzioni di Probabilità Continue",
    "text": "31.4 Distribuzioni di Probabilità Continue\nLe distribuzioni di probabilità continue descrivono variabili casuali che possono assumere un numero infinito di valori in un intervallo. In questo caso, la probabilità è rappresentata da una funzione di densità di probabilità (PDF), che descrive la probabilità che la variabile assuma valori in un dato intervallo.\n\n31.4.1 Probabilità come Area Sotto la Curva\nPer una variabile casuale continua \\(X\\), la probabilità che \\(X\\) assuma un valore compreso tra \\(a\\) e \\(b\\) è data dall’area sotto la curva della PDF tra \\(a\\) e \\(b\\):\n\\[\nP(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx.\n\\]\n\nEsempio 31.2 Il quoziente intellettivo (QI) è spesso modellato come una variabile casuale continua con distribuzione normale, con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Possiamo simulare questa distribuzione e confrontare l’istogramma dei dati con la PDF teorica.\nSimulazione con 50 osservazioni.\n\n# Parametri della distribuzione normale\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 50\n\n# Generare i dati\nset.seed(123)\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Istogramma e densità\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = sigma)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 25,\n    fill = \"blue\",\n    alpha = 0.6\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione del QI (50 osservazioni)\",\n    x = \"Valori del QI\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCon un campione piccolo, l’istogramma non corrisponde perfettamente alla PDF teorica. Tuttavia, aumentando il numero di osservazioni, l’approssimazione migliora.\nSimulazione con 20000 osservazioni.\n\n# Generare un campione più grande\nsize &lt;- 20000\nset.seed(123)\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Aggiornare media e deviazione standard\nmu &lt;- mean(x)\nsigma &lt;- sd(x)\n\n# Creare il grafico\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = sigma)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 25,\n    fill = \"blue\",\n    alpha = 0.6\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    title = sprintf(\"Distribuzione del QI (%d osservazioni)\", size),\n    x = \"Valori del QI\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCon un campione di grandi dimensioni, l’istogramma riflette molto meglio la PDF teorica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#interpretazione-della-funzione-di-densità",
    "href": "chapters/probability/08_prob_distributions.html#interpretazione-della-funzione-di-densità",
    "title": "31  Distribuzioni di massa e di densità",
    "section": "\n31.5 Interpretazione della Funzione di Densità",
    "text": "31.5 Interpretazione della Funzione di Densità\nLa funzione di densità di probabilità (PDF) rappresenta un’astrazione continua dell’istogramma. Quando il numero di osservazioni tende a infinito e la larghezza degli intervalli tende a zero, il profilo dell’istogramma si avvicina alla PDF.\n\n31.5.1 Proprietà della PDF\n\n\nArea Totale: L’area totale sotto la curva della PDF è uguale a 1, poiché rappresenta la probabilità totale.\n\nProbabilità per Intervalli: La probabilità che la variabile assuma un valore in un intervallo \\([a, b]\\) è data dall’area sotto la curva tra \\(a\\) e \\(b\\).\n\nProbabilità per Singoli Valori: Per una variabile continua, la probabilità di un singolo valore è sempre zero, poiché corrisponde all’area sotto la curva in un punto.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#parametri-delle-distribuzioni-di-probabilità",
    "href": "chapters/probability/08_prob_distributions.html#parametri-delle-distribuzioni-di-probabilità",
    "title": "31  Distribuzioni di massa e di densità",
    "section": "\n31.6 Parametri delle Distribuzioni di Probabilità",
    "text": "31.6 Parametri delle Distribuzioni di Probabilità\nLe distribuzioni di probabilità, sia discrete che continue, sono definite da parametri che ne determinano le proprietà fondamentali. Questi parametri consentono di adattare il modello probabilistico ai dati osservati.\n\n31.6.1 Proprietà Influenzate dai Parametri\n\n\nPosizione (Tendenza Centrale): Indica il valore attorno al quale si concentra la distribuzione. Ad esempio, nella distribuzione normale, la media (\\(\\mu\\)) rappresenta il centro della distribuzione.\n\nDispersione: Misura quanto i valori della distribuzione si allontanano dalla posizione centrale. Nella distribuzione normale, la deviazione standard (\\(\\sigma\\)) controlla la larghezza della curva.\n\nForma: Determina l’asimmetria o la curtosi della distribuzione. Alcune distribuzioni, come quella gamma o beta, hanno parametri specifici per regolare la forma.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#il-paradosso-delle-variabili-casuali-continue",
    "href": "chapters/probability/08_prob_distributions.html#il-paradosso-delle-variabili-casuali-continue",
    "title": "31  Distribuzioni di massa e di densità",
    "section": "\n31.7 Il Paradosso delle Variabili Casuali Continue",
    "text": "31.7 Il Paradosso delle Variabili Casuali Continue\nUn aspetto, inizialmente controintuitivo, delle variabili casuali continue è che la probabilità di osservare esattamente un determinato valore è sempre pari a zero. Per esempio, se consideriamo una variabile continua che rappresenta il QI, la probabilità che il QI sia esattamente 100 è espressa da\n\\[\nP(X = 100) = 0.\n\\]\nQuesto risultato, che può sembrare paradossale, non indica che l’evento “QI uguale a 100” sia impossibile. In realtà, il significato di probabilità in un contesto continuo è diverso da quello nel caso discreto, e va interpretato correttamente.\n\n31.7.1 Probabilità e Intervalli nelle Variabili Continue\nPer le variabili casuali continue, il concetto di probabilità si applica agli intervalli di valori piuttosto che ai singoli punti. Infatti, se volessimo attribuire una probabilità positiva a ogni singolo valore, sommando infinite quantità positive (anche se infinitesimali) otterremmo un totale che supererebbe 1, violando i principi fondamentali della teoria della probabilità.\nPer chiarire questo concetto, consideriamo l’intervallo attorno al valore 100. Ad esempio, la probabilità che il QI sia compreso tra 95 e 105 è data dall’area sotto la funzione di densità di probabilità (PDF) \\(f(x)\\) nell’intervallo \\([95, 105]\\):\n\\[\nP(95 \\leq X \\leq 105) = \\int_{95}^{105} f(x) \\, dx.\n\\]\nQui, l’integrale calcola l’area sotto la curva della PDF nell’intervallo specificato. Anche se la probabilità assegnata a un singolo punto, come \\(x = 100\\), è zero (perché l’area di un “punto” è zero), l’area totale su un intervallo non trascurabile risulta invece in una probabilità finita e significativa.\n\n31.7.2 Conseguenze Fondamentali\nQuesto modo di definire la probabilità nelle variabili continue comporta due implicazioni chiave:\n\nCalcolo della probabilità su intervalli:\nLe probabilità vengono definite e calcolate per intervalli di valori, non per singoli punti. Ciò significa che, in pratica, ci si interessa alla probabilità che la variabile assuma valori all’interno di un certo range.\nEventi con probabilità zero:\nIl fatto che un evento (ad esempio, \\(X = 100\\)) abbia probabilità zero non implica che l’evento sia impossibile. In altre parole, eventi con probabilità zero possono, in effetti, verificarsi; la probabilità zero in un contesto continuo indica semplicemente che, nel “tessuto” continuo della distribuzione, un singolo punto ha contributo infinitesimale rispetto all’intera area sotto la curva.\n\n31.7.3 Il Paradosso della Probabilità Zero\nQuesto ragionamento porta a un apparente paradosso: se la probabilità che il QI sia esattamente 100 è zero, come possiamo mai osservare un valore specifico, come 100, nella realtà? Da qui sorgono due domande fondamentali:\n\nConfronto tra eventi di probabilità zero:\nÈ possibile comparare “le possibilità” di eventi che, per definizione, hanno tutti probabilità zero? La risposta sta nel riconoscere che, in un contesto continuo, la probabilità è solo un modo per misurare l’area (cioè la “massa” della densità) su un intervallo, non il valore in un punto specifico.\nUnione di infiniti eventi a probabilità zero:\nCome si fa in modo che l’unione di infiniti eventi, ciascuno con probabilità zero, possa dare luogo a un evento complessivo con probabilità positiva (ad esempio, “il QI assume un valore compreso in un intervallo”)?\n\nLa chiave per risolvere questi quesiti risiede nell’uso dell’integrazione. Anche se ogni singolo valore contribuisce con una probabilità “infinitesimale” (in termini di area, zero), la somma di tutti questi contributi lungo un intervallo (che è il risultato dell’integrazione) dà luogo a un’area finita, corrispondente a una probabilità positiva.\n\n31.7.4 Un’Analogia: Il Paradosso di Zenone\nUna metafora utile per comprendere questo fenomeno è data dal celebre paradosso di Zenone della freccia. Nel paradosso, si sostiene che, in ogni istante, la freccia sia immobile, e dunque non si dovrebbe mai muovere. Analogamente, anche se in ogni punto specifico la probabilità è zero, la “somma” degli infiniti contributi infinitesimali lungo un intervallo determina un risultato complessivo positivo.\nQuesta analogia evidenzia come la somma di una quantità infinita di “nulla” (ossia contributi infinitesimali) possa, in realtà, costituire un qualcosa di concreto e significativo (l’area sotto la curva).\n\n31.7.5 La Prospettiva degli Infinitesimi\nNegli anni ’60, il matematico Abraham Robinson sviluppò una teoria rigorosa degli infinitesimi, ovvero numeri infinitamente piccoli ma non esattamente nulli. Applicando questa idea alle variabili casuali continue, possiamo reinterpretare il concetto di probabilità zero nel modo seguente:\n\nProbabilità infinitesimale per un singolo valore:\nIn questa prospettiva, la probabilità associata a un singolo valore non è propriamente zero, ma è un numero infinitamente piccolo (un infinitesimo). Anche se, nell’analisi classica, tale valore viene trattato come zero, la teoria degli infinitesimi offre un modo per concettualizzare queste quantità.\nSomma di infinitesimi:\nL’unione (o, più formalmente, l’integrazione) di infiniti eventi, ciascuno con probabilità infinitesimale, porta alla formazione di una probabilità finita e positiva per l’intero intervallo. Questo spiega come un insieme infinito di “punti” ciascuno di probabilità infinitesimale possa dare origine a un evento con probabilità significativa.\n\nIn conclusione, il cosiddetto “paradosso della probabilità zero” non rappresenta un vero paradosso, ma evidenzia piuttosto i limiti delle nostre intuizioni quando affrontiamo concetti inerenti variabili continue. La chiave per la comprensione risiede nella distinzione tra il contributo di un singolo punto (infinitesimale o zero, nell’analisi classica) e l’area complessiva calcolata mediante l’integrazione.\nGrazie agli strumenti forniti dall’analisi matematica e, in alcuni contesti, dalla teoria degli infinitesimi, riusciamo a interpretare correttamente questi fenomeni: la probabilità non è concentrata in punti isolati, ma distribuita in modo continuo lungo un intervallo. Questa visione ci permette di superare la difficoltà concettuale di assegnare probabilità a eventi infinitamente piccoli, mantenendo la coerenza con i principi fondamentali della teoria della probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "chapters/probability/08_prob_distributions.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "31  Distribuzioni di massa e di densità",
    "section": "\n31.8 La Funzione di Ripartizione per una Variabile Casuale Continua",
    "text": "31.8 La Funzione di Ripartizione per una Variabile Casuale Continua\nLa funzione di ripartizione, nota anche come distribuzione cumulativa, è uno strumento fondamentale per descrivere il comportamento di una variabile casuale, sia essa discreta o continua. Per una variabile casuale continua \\(\\Theta\\), la funzione di ripartizione \\(F_{\\Theta}(\\theta)\\) è definita come:\n\\[\nF_{\\Theta}(\\theta) = P(\\Theta \\leq \\theta).\n\\]\nIn altre parole, \\(F_{\\Theta}(\\theta)\\) rappresenta la probabilità che la variabile \\(\\Theta\\) assuma un valore minore o uguale a \\(\\theta\\). Questa definizione è identica a quella utilizzata per le variabili casuali discrete, ma nel caso continuo assume un significato particolare a causa della natura continua della variabile.\n\n31.8.1 Proprietà della Funzione di Ripartizione\nLa funzione di ripartizione per una variabile casuale continua gode di alcune proprietà importanti:\n\n\nMonotonicità Crescente: \\(F_{\\Theta}(\\theta)\\) è una funzione non decrescente. Ciò significa che, all’aumentare di \\(\\theta\\), la probabilità \\(P(\\Theta \\leq \\theta)\\) non diminuisce.\n\nLimiti agli Estremi:\n\nQuando \\(\\theta \\to -\\infty\\), \\(F_{\\Theta}(\\theta) \\to 0\\).\nQuando \\(\\theta \\to +\\infty\\), \\(F_{\\Theta}(\\theta) \\to 1\\).\n\n\n\nContinuità: Per una variabile casuale continua, \\(F_{\\Theta}(\\theta)\\) è una funzione continua. Questo differisce dal caso discreto, dove la funzione di ripartizione è a gradini.\n\n31.8.2 Calcolo delle Probabilità per Intervalli\nUna delle applicazioni più utili della funzione di ripartizione è il calcolo della probabilità che la variabile casuale \\(\\Theta\\) assuma valori all’interno di un intervallo specifico. Dati due valori \\(\\theta_1\\) e \\(\\theta_2\\) (con \\(\\theta_1 &lt; \\theta_2\\)), la probabilità che \\(\\Theta\\) sia compreso tra \\(\\theta_1\\) e \\(\\theta_2\\) è data da:\n\\[\nP(\\theta_1 &lt; \\Theta \\leq \\theta_2) = F_{\\Theta}(\\theta_2) - F_{\\Theta}(\\theta_1).\n\\]\nQuesta formula è particolarmente utile perché, nel caso delle variabili continue, la probabilità di un singolo punto è sempre zero. Pertanto, per calcolare probabilità significative, è necessario considerare intervalli di valori.\n\n31.8.3 Relazione con la Funzione di Densità di Probabilità (PDF)\nLa funzione di ripartizione è strettamente legata alla funzione di densità di probabilità (PDF), \\(f(\\theta)\\). Mentre la PDF descrive la densità di probabilità in ogni punto, la funzione di ripartizione rappresenta l’area sotto la curva della PDF fino a un certo valore \\(\\theta\\). Formalmente, la funzione di ripartizione si ottiene integrando la PDF:\n\\[\nF_{\\Theta}(\\theta) = \\int_{-\\infty}^{\\theta} f(t) \\, dt.\n\\]\nQuesta relazione evidenzia come la funzione di ripartizione sia una rappresentazione cumulativa della probabilità, ottenuta sommando (o integrando) i contributi della densità di probabilità fino al valore \\(\\theta\\).\n\nEsempio 31.3 Consideriamo una variabile casuale \\(\\Theta\\) con distribuzione normale standard (media \\(\\mu = 0\\) e deviazione standard \\(\\sigma = 1\\)). La PDF è data da:\n\\[\nf(\\theta) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\theta^2 / 2}.\n\\]\nLa funzione di ripartizione \\(F_{\\Theta}(\\theta)\\) è l’integrale di questa funzione da \\(-\\infty\\) a \\(\\theta\\):\n\\[\nF_{\\Theta}(\\theta) = \\int_{-\\infty}^{\\theta} \\frac{1}{\\sqrt{2\\pi}} e^{-t^2 / 2} \\, dt.\n\\]\nQuesta funzione non ha una forma chiusa semplice, ma può essere calcolata numericamente o consultata in tabelle statistiche. Ad esempio, per \\(\\theta = 1\\), \\(F_{\\Theta}(1) \\approx 0.8413\\), il che significa che la probabilità che \\(\\Theta\\) sia minore o uguale a 1 è circa l’84.13%.\n\n\n31.8.4 Interpretazione Grafica\nGraficamente, la funzione di ripartizione rappresenta l’area sotto la curva della PDF a sinistra del valore \\(\\theta\\). Ad esempio, se consideriamo la distribuzione normale standard:\n\nPer \\(\\theta = 0\\), \\(F_{\\Theta}(0) = 0.5\\), poiché la media della distribuzione è 0 e la curva è simmetrica.\nPer \\(\\theta = 1\\), \\(F_{\\Theta}(1) \\approx 0.8413\\), come visto sopra.\nPer \\(\\theta = -1\\), \\(F_{\\Theta}(-1) \\approx 0.1587\\), poiché la coda sinistra della distribuzione contiene il 15.87% della probabilità.\n\n\n# Definisci i parametri della distribuzione normale standard\nmu &lt;- 0\nsigma &lt;- 1\n\n# Definisci i valori di theta\ntheta_values &lt;- c(-1, 0, 1)\n\n# Crea un data frame per la PDF e la CDF\nx &lt;- seq(-4, 4, length.out = 1000)  # Valori sull'asse x\npdf_values &lt;- dnorm(x, mean = mu, sd = sigma)  # Valori della PDF\ncdf_values &lt;- pnorm(x, mean = mu, sd = sigma)  # Valori della CDF\n\ndata &lt;- data.frame(x = x, PDF = pdf_values, CDF = cdf_values)\n\n# Crea il grafico\nggplot(data, aes(x = x)) +\n  # Plot della PDF\n  geom_line(aes(y = PDF), color = \"blue\", linewidth = 1) +\n  # Aggiungi aree sotto la PDF per i valori di theta\n  geom_area(data = subset(data, x &lt;= theta_values[1]), aes(y = PDF), fill = \"red\", alpha = 0.5) +\n  geom_area(data = subset(data, x &lt;= theta_values[2]), aes(y = PDF), fill = \"green\", alpha = 0.5) +\n  geom_area(data = subset(data, x &lt;= theta_values[3]), aes(y = PDF), fill = \"purple\", alpha = 0.5) +\n  # Plot della CDF\n  geom_line(aes(y = CDF), color = \"black\", linewidth = 1, linetype = \"dashed\") +\n  # Aggiungi linee verticali per i valori di theta\n  geom_vline(xintercept = theta_values, color = \"gray\", linetype = \"dotted\") +\n  # Aggiungi annotazioni per i valori di theta\n  annotate(\"text\", x = theta_values[1], y = 0, label = paste(\"θ =\", theta_values[1]), vjust = 2, hjust = 1.2, color = \"red\") +\n  annotate(\"text\", x = theta_values[2], y = 0, label = paste(\"θ =\", theta_values[2]), vjust = 2, hjust = 1.2, color = \"green\") +\n  annotate(\"text\", x = theta_values[3], y = 0, label = paste(\"θ =\", theta_values[3]), vjust = 2, hjust = -0.2, color = \"purple\") +\n  # Aggiungi titoli e etichette\n  labs(\n    title = \"Funzione di Densità di Probabilità (PDF) e\\nFunzione di Ripartizione (CDF)\",\n    subtitle = \"Distribuzione Normale Standard\",\n    x = \"Valori di θ\",\n    y = \"Densità / Probabilità Cumulativa\"\n  )\n\n\n\n\n\n\n\nIn conclusione, la funzione di ripartizione è uno strumento essenziale per comprendere e lavorare con variabili casuali continue. Essa non solo fornisce una rappresentazione cumulativa della probabilità, ma permette anche di calcolare probabilità per intervalli e di collegare la PDF alla distribuzione complessiva della variabile. Attraverso la sua relazione con la PDF, la funzione di ripartizione offre un ponte tra la descrizione locale (densità) e quella globale (probabilità cumulativa) di una variabile casuale continua.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#interpretazioni-bayesiana-e-frequentista-della-pdf",
    "href": "chapters/probability/08_prob_distributions.html#interpretazioni-bayesiana-e-frequentista-della-pdf",
    "title": "31  Distribuzioni di massa e di densità",
    "section": "\n31.9 Interpretazioni Bayesiana e Frequentista della PDF",
    "text": "31.9 Interpretazioni Bayesiana e Frequentista della PDF\nIn questo capitolo, abbiamo introdotto la funzione di densità di probabilità come limite del profilo di un istogramma, una descrizione intuitiva e utile per comprendere il concetto di densità. Questa interpretazione corrisponde, tuttavia, alla visione frequentista della densità di probabilità. Nella statistica Bayesiana, l’interpretazione è diversa e merita una spiegazione separata.\n\n31.9.1 Interpretazione Frequentista\nConcetto di ripetizione degli esperimenti:\n\nIdea di frequenza relativa:\nNel paradigma frequentista la probabilità è intesa come il limite della frequenza relativa di un evento ottenuto al ripetere un esperimento un numero molto elevato di volte. Immaginiamo di eseguire un esperimento molte volte, ad ogni ripetizione si ottiene un valore di \\(x\\). Se costruiamo un istogramma di questi valori, questo istogramma diventa sempre più “liscio” man mano che il numero delle ripetizioni aumenta, fino a convergere alla PDF \\(p(x)\\).\nPDF come istogramma limite:\nLa PDF rappresenta la distribuzione dei valori osservati in una serie di ripetizioni dell’esperimento. In altre parole, essa descrive quanto frequentemente, in una ipotetica serie infinita di esperimenti, il valore \\(x\\) assume un determinato intervallo.\nEsempio intuitivo:\nSe misuriamo l’altezza degli individui in una popolazione, nel contesto frequentista, la PDF ci dice quale frazione di individui cade in un certo intervallo di altezza se potessimo misurare ogni possibile individuo (o eseguire ripetutamente misurazioni indipendenti in una popolazione “ideale”).\n\n31.9.2 Interpretazione Bayesiana\nConcetto di incertezza e credenza:\n\n\nParametro come variabile casuale:\nIn statistica bayesiana, i parametri non sono visti come quantità fisse, ma come incerti. Si assume che ogni parametro (o dato osservato) abbia una propria distribuzione che riflette la nostra incertezza su di esso.\n\nAd esempio, se stiamo stimando un parametro \\(\\theta\\) (ad esempio la media di una distribuzione), in un approccio bayesiano attribuiamo a \\(\\theta\\) una distribuzione di probabilità che esprime quanto sia plausibile ciascun valore di \\(\\theta\\), dati i dati osservati e le nostre conoscenze pregresse.\n\n\n\nPDF come distribuzione di credenze:\nLa PDF, in questo contesto, non descrive una frequenza relativa osservabile sperimentalmente (perché l’esperimento non viene ripetuto infinite volte, o perché \\(x\\) è un valore fisso ma incerto), ma esprime il grado di fiducia o la plausibilità che il valore “vero” di \\(x\\) (o di un parametro) si trovi in un certo intervallo.\n\nÈ come “spalmare” la nostra incertezza su tutti i valori possibili: la sfumatura lungo l’asse \\(x\\) rappresenta la distribuzione delle nostre credenze.\n\n\nAnalogia con la densità di materia:\nUn’utile analogia è quella della densità di materia \\(\\rho(x)\\) in meccanica classica: la densità non descrive la posizione precisa di ogni atomo, ma come la materia (o, in questo caso, la probabilità) è distribuita lungo l’asse \\(x\\). Allo stesso modo, in una PDF bayesiana, non sono i “valori di \\(x\\)” ad essere distribuiti (in termini di frequenza osservabile), ma è la nostra “incertezza” a essere distribuita sui possibili valori.\nEsempio intuitivo:\nImmagina di dover stimare la probabilità che una certa ipotesi sia vera, ad esempio la media dell’altezza in una popolazione. Invece di pensare a misurazioni ripetute, consideri il valore medio come fisso ma incerto. La PDF bayesiana esprime il grado di credenza per ciascun possibile valore della media, in base ai dati raccolti e alle informazioni a priori.\n\n31.9.3 Confronto\n\n\nFrequentista:\n\n\nFocus: Distribuzione dei dati.\n\nInterpretazione: La PDF descrive come i valori di \\(x\\) sarebbero distribuiti se ripetessimo l’esperimento infinite volte.\n\nEsempio: L’istogramma dei dati osservati in una lunga serie di esperimenti.\n\n\n\nBayesiano:\n\n\nFocus: Distribuzione della nostra incertezza o credenza.\n\nInterpretazione: La PDF riflette quanto sia plausibile ciascun valore di \\(x\\) (o di un parametro) dato l’informazione disponibile, senza necessità di ripetere l’esperimento.\n\nEsempio: La distribuzione a posteriori di un parametro dopo aver combinato dati osservati e informazioni a priori.\n\n\n\n\n\n\n\n\nFigura 31.1: Interpretazioni frequentista e bayesiana di una PDF (curva blu) per una quantità reale \\(x\\). A sinistra: interpretazione frequentista come istogramma limite dei valori di \\(x\\) nelle ripetizioni; i valori di \\(x\\) sono distribuiti secondo la PDF. A destra: interpretazione bayesiana, con \\(x\\) che assume un valore fisso ma incerto per il caso specifico (rappresentato dal punto sull’asse \\(x\\)), con la probabilità distribuita sui valori possibili (raffigurata con una sfumatura lungo l’asse \\(x\\)). (Figura tratta da Loredo & Wolpert, 2024)\n\n\nIn sintesi, questa distinzione tra interpretazioni non è solo una questione di semantica, ma ha implicazioni pratiche nella formulazione di modelli statistici e nell’interpretazione dei risultati. Mentre l’approccio frequentista è spesso utilizzato quando si può concettualmente pensare a ripetizioni infinite dell’esperimento, l’approccio bayesiano è particolarmente utile quando si vuole esprimere e aggiornare la propria incertezza su una quantità basandosi sia su dati che su conoscenze pregresse.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#riflessioni-conclusive",
    "href": "chapters/probability/08_prob_distributions.html#riflessioni-conclusive",
    "title": "31  Distribuzioni di massa e di densità",
    "section": "\n31.10 Riflessioni Conclusive",
    "text": "31.10 Riflessioni Conclusive\nLa funzione di densità di probabilità (PDF) costituisce il fondamento per la descrizione delle variabili casuali continue, consentendo di associare le probabilità ad intervalli, tramite il calcolo dell’area sottesa alla curva. In questo contesto, la probabilità di osservare un valore esatto risulta zero, non per impossibilità dell’evento, ma perché in un insieme continuo ogni singolo punto contribuisce con un’area infinitesimale.\nIl paradosso apparente, secondo cui la somma di infiniti contributi nulli porta a una probabilità totale positiva, si risolve grazie alla teoria dell’integrazione. Integrando i contributi infinitesimali lungo un intervallo, si ottiene una quantità finita che rappresenta la probabilità complessiva dell’evento. Un’interpretazione alternativa, fornita dalla teoria degli infinitesimi di Abraham Robinson, consente di attribuire a tali eventi probabilità infinitesimali, distinguendo tra diverse “grandezze” e chiarendo ulteriormente il processo di aggregazione verso un valore unitario.\nNel campo della data science, le distribuzioni di probabilità—formalmente rappresentate da \\(p(x)\\)—sono strumenti indispensabili per modellare la variabilità osservabile in una popolazione. Queste distribuzioni non mirano a riprodurre in maniera dettagliata ogni aspetto della realtà, ma offrono un modello semplificato che consente di generalizzare i dati osservati e di formulare previsioni rigorose sui fenomeni futuri. In altre parole, \\(p(x)\\) non rappresenta la popolazione nel suo complesso, bensì un’astrazione matematica che cattura l’incertezza e la variabilità del fenomeno studiato.\nInfine, la PDF si pone come un ponte concettuale tra il discreto e il continuo, collegando la dimensione finita degli esperimenti alla struttura infinita degli spazi di probabilità. Comprendere questa struttura non solo risolve problemi tecnici, ma arricchisce anche l’intuizione sui meccanismi sottostanti alla teoria della probabilità e alla matematica continua.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#esercizi",
    "href": "chapters/probability/08_prob_distributions.html#esercizi",
    "title": "31  Distribuzioni di massa e di densità",
    "section": "\n31.11 Esercizi",
    "text": "31.11 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizio 1: Variabili Casuali Discrete e Continue\nUtilizzando i dati raccolti sulla Satisfaction with Life Scale (SWLS) e sulla Scala della Rete Sociale di Lubben a 6 item (LSNS-6), classifica le seguenti variabili come discrete o continue:\n\nIl punteggio totale della SWLS.\nIl numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali.\nIl tempo (in minuti) che uno studente trascorre con amici durante una settimana.\nIl numero di volte che uno studente ha contattato un parente nell’ultimo mese.\nIl livello di soddisfazione della vita misurato su una scala da 1 a 7.\n\nSpiega il motivo della tua classificazione per ciascuna variabile.\nEsercizio 2: Distribuzioni di Probabilità Discrete\nConsideriamo la distribuzione del numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali, misurata attraverso la LSNS-6. Supponiamo che la distribuzione sia la seguente (ma nell’esercizio usa le frequenze relative trovate nel campione di dati raccolto):\n\n\nNumero di amici\nProbabilità\n\n\n\n0\n0.05\n\n\n1\n0.15\n\n\n2\n0.25\n\n\n3\n0.30\n\n\n4\n0.15\n\n\n5\n0.10\n\n\n\n\nVerifica che questa sia una distribuzione di probabilità valida.\nQual è la probabilità che uno studente abbia almeno 3 amici con cui si sente a proprio agio nel parlare di questioni personali?\nQual è la probabilità che abbia meno di 2 amici?\nCalcola il valore atteso (media) e la varianza di questa distribuzione.\n\nEsercizio 3: Distribuzioni di Probabilità Continue\nIl punteggio totale della SWLS può essere approssimato da una distribuzione normale con media 20 e deviazione standard 5.\n\nQual è la probabilità che un individuo scelto a caso abbia un punteggio superiore a 25?\nQual è la probabilità che un individuo abbia un punteggio compreso tra 15 e 25?\nQual è il valore del punteggio che delimita il 10% superiore della distribuzione?\n\n(Suggerimento: utilizza la funzione di ripartizione della distribuzione normale standard per calcolare queste probabilità.)\nEsercizio 4: Legge della Probabilità Totale\nSi sa che il 60% degli studenti proviene da un ambiente con un forte supporto sociale, mentre il 40% ha un supporto sociale limitato. Inoltre, si sa che: - La probabilità che uno studente con forte supporto sociale abbia un punteggio SWLS superiore a 20 è 0.75. - La probabilità che uno studente con supporto sociale limitato abbia un punteggio SWLS superiore a 20 è 0.50.\nQual è la probabilità che uno studente scelto a caso abbia un punteggio SWLS superiore a 20?\nEsercizio 5: Teorema di Bayes e Supporto Sociale\nRiprendendo l’esercizio precedente, calcola la probabilità che uno studente provenga da un ambiente con forte supporto sociale dato che il suo punteggio SWLS è superiore a 20.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nEsercizio 1: Variabili Casuali Discrete e Continue\nUtilizzando i dati raccolti sulla Satisfaction with Life Scale (SWLS) e sulla Scala della Rete Sociale di Lubben a 6 item (LSNS-6), classifica le seguenti variabili come discrete o continue:\n\nIl punteggio totale della SWLS. (Continuo)\nIl numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali. (Discreto)\nIl tempo (in minuti) che uno studente trascorre con amici durante una settimana. (Continuo)\nIl numero di volte che uno studente ha contattato un parente nell’ultimo mese. (Discreto)\nIl livello di soddisfazione della vita misurato su una scala da 1 a 7. (Discreto)\n\nEsercizio 2: Distribuzioni di Probabilità Discrete\nConsideriamo la distribuzione del numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali, misurata attraverso la LSNS-6. Supponiamo che la distribuzione sia la seguente:\n\n\nNumero di amici\nProbabilità\n\n\n\n0\n0.05\n\n\n1\n0.15\n\n\n2\n0.25\n\n\n3\n0.30\n\n\n4\n0.15\n\n\n5\n0.10\n\n\n\n\n\nVerifica della distribuzione: La somma delle probabilità deve essere 1:\n\\[ 0.05 + 0.15 + 0.25 + 0.30 + 0.15 + 0.10 = 1.00 \\]\nPoiché la somma è 1, la distribuzione è valida.\n\n\nProbabilità di almeno 3 amici:\n\\[ P(X \\geq 3) = P(3) + P(4) + P(5) = 0.30 + 0.15 + 0.10 = 0.55 \\]\n\n\nProbabilità di meno di 2 amici:\n\\[ P(X &lt; 2) = P(0) + P(1) = 0.05 + 0.15 = 0.20 \\]\n\n\nValore atteso e varianza:\n\\[ E(X) = \\sum x P(x) = (0 \\times 0.05) + (1 \\times 0.15) + (2 \\times 0.25) + (3 \\times 0.30) + (4 \\times 0.15) + (5 \\times 0.10) = 2.65 \\]\n\\[ Var(X) = E(X^2) - (E(X))^2 \\]\n\\[ E(X^2) = (0^2 \\times 0.05) + (1^2 \\times 0.15) + (2^2 \\times 0.25) + (3^2 \\times 0.30) + (4^2 \\times 0.15) + (5^2 \\times 0.10) = 8.05 \\]\n\\[ Var(X) = 8.05 - (2.65)^2 = 1.06 \\]\n\n\nEsercizio 3: Distribuzioni di Probabilità Continue\nIl punteggio totale della SWLS può essere approssimato da una distribuzione normale con media 20 e deviazione standard 5.\n\n\nProbabilità che il punteggio sia superiore a 25:\n\\[ P(X &gt; 25) = 1 - P(X \\leq 25) \\]\nStandardizziamo:\n\\[ Z = \\frac{25 - 20}{5} = 1 \\]\nUsando le tabelle della distribuzione normale:\n\\[ P(Z \\leq 1) = 0.8413 \\Rightarrow P(X &gt; 25) = 1 - 0.8413 = 0.1587 \\]\n\n\nProbabilità che il punteggio sia tra 15 e 25:\n\\[ P(15 \\leq X \\leq 25) = P(Z \\leq 1) - P(Z \\leq -1) \\]\n\\[ = 0.8413 - 0.1587 = 0.6826 \\]\n\n\nPercentile 90 della distribuzione:\nIl valore di Z per il 90% è 1.28.\n\\[ X = 20 + (1.28 \\times 5) = 26.4 \\]\n\n\nEsercizio 4: Legge della Probabilità Totale\n\\[ P(SWLS &gt; 20) = P(SWLS &gt; 20 | S) P(S) + P(SWLS &gt; 20 | \\neg S) P(\\neg S) \\]\n\\[ = (0.75 \\times 0.60) + (0.50 \\times 0.40) \\]\n\\[ = 0.45 + 0.20 = 0.65 \\]\nEsercizio 5: Teorema di Bayes e Supporto Sociale\n\\[ P(S | SWLS &gt; 20) = \\frac{P(SWLS &gt; 20 | S) P(S)}{P(SWLS &gt; 20)} \\]\n\\[ = \\frac{(0.75 \\times 0.60)}{0.65} \\]\n\\[ = \\frac{0.45}{0.65} = 0.6923 \\]\nQuindi, la probabilità che uno studente provenga da un ambiente con forte supporto sociale dato che il suo punteggio SWLS è superiore a 20 è circa 69.2%.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/08_prob_distributions.html#informazioni-sullambiente-di-sviluppo",
    "title": "31  Distribuzioni di massa e di densità",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#bibliografia",
    "href": "chapters/probability/08_prob_distributions.html#bibliografia",
    "title": "31  Distribuzioni di massa e di densità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nLoredo, T. J., & Wolpert, R. L. (2024). Bayesian inference: more than Bayes’s theorem. Frontiers in Astronomy and Space Sciences, 11, 1326926.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html",
    "href": "chapters/probability/09_expval_var.html",
    "title": "32  Proprietà delle variabili casuali",
    "section": "",
    "text": "32.1 Introduzione\nÈ spesso molto utile sintetizzare la distribuzione di una variabile casuale attraverso indicatori caratteristici. Questi indicatori consentono di cogliere le principali proprietà della distribuzione, come la posizione centrale (ovvero il “baricentro”) e la variabilità (ossia la dispersione attorno al centro). In questo modo, è possibile ottenere una descrizione sintetica e significativa della distribuzione di probabilità della variabile casuale.\nIn questo capitolo, introdurremo i concetti fondamentali di valore atteso e varianza di una variabile casuale, che sono strumenti essenziali per comprendere e riassumere le proprietà di una distribuzione probabilistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#tendenza-centrale",
    "href": "chapters/probability/09_expval_var.html#tendenza-centrale",
    "title": "32  Proprietà delle variabili casuali",
    "section": "\n32.2 Tendenza Centrale",
    "text": "32.2 Tendenza Centrale\nQuando vogliamo comprendere il comportamento tipico di una variabile casuale, ci interessa spesso determinare il suo “valore tipico”. Tuttavia, questa nozione può essere interpretata in diversi modi:\n\n\nMedia: La somma dei valori divisa per il numero dei valori.\n\nMediana: Il valore centrale della distribuzione, quando i dati sono ordinati in senso crescente o decrescente.\n\nModa: Il valore che si verifica con maggiore frequenza.\n\nAd esempio, per il set di valori \\(\\{3, 1, 4, 1, 5\\}\\), la media è \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana è 3, e la moda è 1. Tuttavia, quando ci occupiamo di variabili casuali, anziché di semplici sequenze di numeri, diventa necessario chiarire cosa intendiamo per “valore tipico” in questo contesto. Questo ci porta alla definizione formale del valore atteso.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#valore-atteso",
    "href": "chapters/probability/09_expval_var.html#valore-atteso",
    "title": "32  Proprietà delle variabili casuali",
    "section": "\n32.3 Valore Atteso",
    "text": "32.3 Valore Atteso\n\nDefinizione 32.1 Sia \\(X\\) una variabile casuale discreta che assume i valori \\(x_1, \\dots, x_n\\) con probabilità \\(P(X = x_i) = p(x_i)\\). Il valore atteso di \\(X\\), denotato con \\(\\mathbb{E}(X)\\), è definito come:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n x_i \\cdot p(x_i).\n\\]\n\nIn altre parole, il valore atteso (noto anche come speranza matematica o aspettazione) di una variabile casuale è la somma di tutti i valori che la variabile può assumere, ciascuno ponderato dalla probabilità con cui esso si verifica.\n\nEsempio 32.1 Calcoliamo il valore atteso della variabile casuale \\(X\\) corrispondente al lancio di una moneta equilibrata, dove testa corrisponde a \\(X = 1\\) e croce corrisponde a \\(X = 0\\):\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{2} x_i \\cdot P(x_i) = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = 0.5.\n\\]\n\n\nEsempio 32.2 Calcoliamo il valore atteso della variabile casuale \\(X\\) che rappresenta la somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\nLa variabile casuale \\(X\\) può assumere i seguenti valori:\n\\[\n\\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\\}.\n\\]\nLa probabilità associata a ciascun valore è data dalla distribuzione di massa di probabilità. Ad esempio, il valore \\(X = 2\\) si ottiene solo se entrambi i dadi mostrano 1, quindi ha probabilità:\n\\[\nP(X = 2) = \\frac{1}{36}.\n\\]\nAnalogamente, \\(X = 7\\) può essere ottenuto con sei combinazioni diverse: (1,6), (2,5), (3,4), (4,3), (5,2), (6,1), quindi:\n\\[\nP(X = 7) = \\frac{6}{36}.\n\\]\nLa distribuzione di massa di probabilità completa è:\n\\[\nP(X) = \\left\\{\\frac{1}{36}, \\frac{2}{36}, \\frac{3}{36}, \\frac{4}{36}, \\frac{5}{36}, \\frac{6}{36}, \\frac{5}{36}, \\frac{4}{36}, \\frac{3}{36}, \\frac{2}{36}, \\frac{1}{36}\\right\\}.\n\\]\nIl valore atteso \\(\\mathbb{E}[X]\\) è definito come:\n\\[\n\\mathbb{E}[X] = \\sum_{x} x \\cdot P(X = x).\n\\]\nApplicando questa formula:\n\\[\n\\mathbb{E}[X] = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + 4 \\cdot \\frac{3}{36} + \\cdots + 12 \\cdot \\frac{1}{36} = 7.\n\\]\nEcco come calcolarlo utilizzando R:\n\n# Valori di X e le loro probabilità\nvalori &lt;- 2:12\nprob &lt;- c(1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1) / 36\n\n# Calcolo del valore atteso\nvalore_atteso &lt;- sum(valori * prob)\nvalore_atteso\n#&gt; [1] 7\n\nIl risultato sarà: \\[\n\\mathbb{E}[X] = 7.\n\\]\nPer rappresentare graficamente la distribuzione di massa di probabilità:\n\n# Creazione di un data frame\ndati &lt;- data.frame(Valore = valori, Probabilità = prob)\n\n# Plot\nggplot(dati, aes(x = Valore, y = Probabilità)) +\n  geom_col() +\n  labs(\n    title = \"Distribuzione di Massa di Probabilità per X\",\n    x = \"Valore della Somma (X)\",\n    y = \"Probabilità\"\n  ) \n\n\n\n\n\n\n\n\n\n32.3.1 Interpretazione\nNel suo Ars conjectandi, Bernoulli introduce la nozione di valore atteso con le seguenti parole:\n\nil termine “aspettativa” non deve essere inteso nel suo significato comune […], bensì come la speranza di ottenere il meglio diminuita dalla paura di ottenere il peggio. Pertanto, il valore della nostra aspettativa rappresenta sempre qualcosa di intermedio tra il meglio che possiamo sperare e il peggio che possiamo temere (Hacking, 2006).\n\nIn termini moderni, questa intuizione può essere rappresentata in modo più chiaro attraverso una simulazione. Possiamo affermare, infatti, che il valore atteso di una variabile casuale corrisponde alla media aritmetica di un gran numero di realizzazioni indipendenti della variabile stessa.\nPer fare un esempio concreto, consideriamo nuovamente il caso del lancio di due dadi bilanciati a sei facce, dove la variabile casuale \\(X\\) rappresenta la “somma dei due dadi”. Simuliamo un numero elevato di realizzazioni indipendenti di \\(X\\).\n\nset.seed(123)  \nx_samples &lt;- sample(valori, size = 1e6, replace = TRUE, prob = prob)\n\nL’istruzione sample(x, size = 1e6, replace = TRUE, prob = px)) utilizza R per generare un array di 1.000.000 di elementi (specificato dal parametro size), selezionati casualmente dall’array x secondo le probabilità specificate nell’array px.\nQuando il numero di realizzazioni indipendenti è sufficientemente grande, la media aritmetica dei campioni generati si avvicina al valore atteso della variabile casuale:\n\nmean(x_samples)\n#&gt; [1] 6.998\n\nQuesto risultato conferma che il valore atteso \\(\\mathbb{E}[X] = 7\\) rappresenta la somma media dei punti ottenuti nel lancio di due dadi equilibrati su un numero elevato di prove. Anche se ogni singola somma può variare tra 2 e 12, in media ci aspettiamo una somma di 7.\nL’aspettativa può anche essere interpretata come un centro di massa. Immagina che delle masse puntiformi con pesi \\(p_1, p_2, \\dots, p_n\\) siano posizionate alle posizioni \\(x_1, x_2, \\dots, x_n\\) sulla retta reale. Il centro di massa—il punto in cui i pesi sono bilanciati—è dato da:\n\\[\n\\text{centro di massa} = x_1 p_1 + x_2 p_2 + \\dots + x_n p_n,\n\\]\nche corrisponde esattamente all’aspettativa della variabile discreta \\(X\\), che assume valori \\(x_1, \\dots, x_n\\) con probabilità \\(p_1, \\dots, p_n\\). Una conseguenza ovvia di questa interpretazione è che, per una funzione di densità di probabilità (pdf) simmetrica, l’aspettativa coincide con il punto di simmetria (a patto che l’aspettativa esista).\n\n\n\n\n\nFigura 32.1: L’aspettativa come centro di massa (figura tratta da Chan & Kroese, 2025).\n\n\n\n32.3.2 Proprietà del Valore Atteso\nUna delle proprietà più importanti del valore atteso è la sua linearità: il valore atteso della somma di due variabili casuali è uguale alla somma dei loro rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{32.1}\\]\nQuesta proprietà, espressa dalla formula sopra, è intuitiva quando \\(X\\) e \\(Y\\) sono variabili casuali indipendenti, ma è valida anche nel caso in cui \\(X\\) e \\(Y\\) siano correlate.\nInoltre, se moltiplichiamo una variabile casuale per una costante \\(c\\), il valore atteso del prodotto è uguale alla costante moltiplicata per il valore atteso della variabile casuale:\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{32.2}\\]\nQuesta proprietà ci dice che una costante può essere “estratta” dall’operatore di valore atteso, e si applica a qualunque numero di variabili casuali.\nUn’altra proprietà significativa riguarda il prodotto di variabili casuali indipendenti. Se \\(X\\) e \\(Y\\) sono indipendenti, allora il valore atteso del loro prodotto è uguale al prodotto dei loro valori attesi:\n\\[\n\\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{32.3}\\]\nInfine, consideriamo la media aritmetica \\(\\bar{X} = \\frac{X_1 + \\ldots + X_n}{n}\\) di \\(n\\) variabili casuali indipendenti con la stessa distribuzione e con valore atteso \\(\\mu\\). Il valore atteso della media aritmetica è:\n\\[\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\left(\\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n)\\right) = \\frac{1}{n} \\cdot n \\cdot \\mathbb{E}(X) = \\mu.\n\\]\nQuesto risultato conferma che la media aritmetica di un campione di variabili casuali indipendenti ha lo stesso valore atteso della distribuzione originaria, rendendo il valore atteso uno strumento cruciale per l’analisi statistica e probabilistica.\n\nEsempio 32.3 Consideriamo il seguente esperimento casuale. Sia \\(Y\\) il numero che si ottiene dal lancio di un dado equilibrato a sei facce e \\(Y\\) il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di \\(X+Y\\).\nPer risolvere il problema iniziamo a costruire lo spazio campione dell’esperimento casuale.\n\n\n\n\n\n\n\n\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avrà la stessa probabilità di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) è dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nSi ottiene lo stesso risultato usando l’Equazione 32.1:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\n\n\nEsempio 32.4 Svolgiamo ora l’esercizio in R\n\ncoin &lt;- 0:1  # Valori della moneta: testa (0) e croce (1)\ndie &lt;- 1:6   # Valori del dado: da 1 a 6\n\n# Creazione del campione come combinazione di valori (moneta, dado)\nsample &lt;- expand.grid(coin = coin, die = die)\nprint(sample)\n#&gt;    coin die\n#&gt; 1     0   1\n#&gt; 2     1   1\n#&gt; 3     0   2\n#&gt; 4     1   2\n#&gt; 5     0   3\n#&gt; 6     1   3\n#&gt; 7     0   4\n#&gt; 8     1   4\n#&gt; 9     0   5\n#&gt; 10    1   5\n#&gt; 11    0   6\n#&gt; 12    1   6\n\n\npx &lt;- numeric()  # Vettore per memorizzare le probabilità\n\nfor (i in 1:7) {\n  # Filtrare le combinazioni in cui la somma è uguale a 'i'\n  event &lt;- subset(sample, coin + die == i)\n  # Calcolare la probabilità\n  prob &lt;- nrow(event) / nrow(sample)\n  px &lt;- c(px, prob)\n  \n  # Stampare la probabilità\n  cat(sprintf(\"P(X + Y = %d) = %d / %d\\n\", i, nrow(event), nrow(sample)))\n}\n#&gt; P(X + Y = 1) = 1 / 12\n#&gt; P(X + Y = 2) = 2 / 12\n#&gt; P(X + Y = 3) = 2 / 12\n#&gt; P(X + Y = 4) = 2 / 12\n#&gt; P(X + Y = 5) = 2 / 12\n#&gt; P(X + Y = 6) = 2 / 12\n#&gt; P(X + Y = 7) = 1 / 12\n\n\nx &lt;- 1:7  # Valori della variabile casuale (somma di moneta e dado)\nexpected_value &lt;- sum(x * px)\nexpected_value\n#&gt; [1] 4\n\n\n\nEsempio 32.5 Consideriamo le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso di \\(Z = X \\cdot Y\\).\nLa distribuzione di probabilità congiunta \\(P(X, Y)\\) è fornita nella tabella seguente.\n\n\n\\(x /\\ y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l’Equazione 32.3. Infatti, il valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) è\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerciò\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\n\n\n32.3.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(X\\), il valore atteso è definito come:\n\\[\n\\mathbb{E}(X) = \\int_{-\\infty}^{+\\infty} x \\cdot p(x) \\, \\mathrm{d}x.\n\\]\nAnche in questo contesto, il valore atteso rappresenta una media ponderata dei valori di \\(x\\), dove ogni possibile valore di \\(x\\) è ponderato in base alla densità di probabilità \\(p(x)\\).\nL’integrale può essere interpretato analogamente a una somma continua, in cui \\(x\\) rappresenta la posizione delle barre infinitamente strette di un istogramma, e \\(p(x)\\) rappresenta l’altezza di tali barre. La notazione \\(\\int_{-\\infty}^{+\\infty}\\) indica che si sta sommando il contributo di ogni valore possibile di \\(x\\) lungo l’intero asse reale.\nQuesta interpretazione rende chiaro come l’integrale calcoli una somma ponderata che si estende su tutti i possibili valori di \\(x\\), fornendo una misura centrale della distribuzione della variabile casuale continua. Per ulteriori dettagli sulla notazione dell’integrale, si veda l’?sec-calculus.\n\n32.3.3.1 Moda\nUn’altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda di \\(Y\\) individua il valore \\(y\\) più plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densità \\(p(y)\\):\n\\[\nMo(Y) = \\text{argmax}_y p(y).\n\\tag{32.4}\\]\n\n\n\n\n\n\nLa notazione \\(\\text{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#varianza",
    "href": "chapters/probability/09_expval_var.html#varianza",
    "title": "32  Proprietà delle variabili casuali",
    "section": "\n32.4 Varianza",
    "text": "32.4 Varianza\nDopo il valore atteso, la seconda proprietà più importante di una variabile casuale è la varianza.\n\nDefinizione 32.2 Se \\(X\\) è una variabile casuale discreta con distribuzione \\(p(x)\\), la varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), è definita come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\tag{32.5}\\]\n\nIn altre parole, la varianza misura la deviazione media quadratica dei valori della variabile rispetto alla sua media. Se denotiamo il valore atteso di \\(X\\) con \\(\\mu = \\mathbb{E}(X)\\), la varianza \\(\\mathbb{V}(X)\\) diventa il valore atteso di \\((X - \\mu)^2\\).\n\n32.4.1 Interpretazione della Varianza\nLa varianza rappresenta una misura della “dispersione” dei valori di \\(X\\) intorno al suo valore atteso. Quando calcoliamo la varianza, stiamo effettivamente misurando quanto i valori di \\(X\\) tendono a differire dalla media \\(\\mu\\).\nPer capire meglio, consideriamo la variabile casuale \\(X - \\mathbb{E}(X)\\), detta scarto o deviazione dalla media. Questa variabile rappresenta le “distanze” tra i valori di \\(X\\) e il valore atteso \\(\\mathbb{E}(X)\\). Tuttavia, poiché lo scarto può essere positivo o negativo, la media dello scarto è sempre zero, il che lo rende inadatto a quantificare la dispersione.\nPer risolvere questo problema, eleviamo al quadrato gli scarti, ottenendo \\((X - \\mathbb{E}(X))^2\\), che rende tutte le deviazioni positive. La varianza è quindi la media di questi scarti al quadrato, fornendo una misura efficace della dispersione complessiva dei valori di \\(X\\) rispetto alla sua media.\nQuesto concetto è fondamentale per comprendere la variabilità di una distribuzione e per applicare strumenti statistici che richiedono una conoscenza approfondita della distribuzione dei dati.\n\nEsempio 32.6 Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\nLa variabile casuale \\(S\\) ha la seguente distribuzione di probabilità:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n\\]\n\n\nEsempio 32.7 Svolgiamo l’esercizio in R\n\n# Definire i valori di x e le loro probabilità px\nx &lt;- 2:12\npx &lt;- c(\n  1 / 36, 2 / 36, 3 / 36, 4 / 36, 5 / 36, 6 / 36,\n  5 / 36, 4 / 36, 3 / 36, 2 / 36, 1 / 36\n)\n\n# Calcolare il valore atteso\nex &lt;- sum(x * px)\nex\n#&gt; [1] 7\n\nApplichiamo l’Equazione 32.5:\n\n# Calcolo della varianza utilizzando la definizione\nvariance &lt;- sum((x - ex)^2 * px)\nvariance\n#&gt; [1] 5.833\n\nUsiamo la funzione var() di rv_discrete:\n\n# Calcolo della varianza con pesi\nvariance_check &lt;- weighted.mean((x - ex)^2, w = px)\nvariance_check\n#&gt; [1] 5.833\n\n\n\n32.4.2 Formula Alternativa per la Varianza\nEsiste un metodo più semplice e diretto per calcolare la varianza di una variabile casuale \\(X\\):\n\\[\n\\begin{align}\n\\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big] &= \\mathbb{E}\\big(X^2 - 2Y\\mathbb{E}(X) + \\mathbb{E}(X)^2\\big) \\notag\\\\\n&= \\mathbb{E}(X^2) - 2\\mathbb{E}(Y)\\mathbb{E}(X) + \\mathbb{E}(X)^2,\n\\end{align}\n\\]\ndove \\(\\mathbb{E}(X)\\) è una costante. Semplificando ulteriormente, otteniamo:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(X)\\big)^2.\n\\tag{32.6}\\]\nIn altre parole, la varianza è data dalla differenza tra la media dei quadrati dei valori di \\(X\\) e il quadrato della media di \\(X\\).\nQuesta formula è utile perché permette di calcolare la varianza senza dover prima determinare lo scarto quadratico medio per ciascun valore di \\(X\\). Invece, si può calcolare direttamente la media dei quadrati e sottrarre il quadrato della media, il che spesso semplifica i calcoli e riduce il rischio di errori.\n\nEsempio 32.8 Consideriamo la variabile casuale \\(X\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\nIl valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(X) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(X^2\\) è\n\\[\n\\mathbb{E}(X^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\n\n\nEsempio 32.9 Svolgiamo l’esercizio in R:\n\n# Definire i valori di x e le probabilità px\nx &lt;- c(0, 1)\npx &lt;- c(0.2, 0.8)\n\n# Calcolare il risultato\nresult &lt;- sum(x^2 * px) - (sum(x * px))^2\nresult\n#&gt; [1] 0.16\n\n\n\n32.4.3 Proprietà\nSegno della varianza. La varianza di una variabile aleatoria non è mai negativa, ed è zero solamente quando la variabile assume un solo valore.\nInvarianza per traslazione. La varianza è invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n\\[\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n\\]\nDimostrazione. Iniziamo a scrivere\n\\[\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n\\]\nQuindi\n\\[\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n\\]\nEsaminiamo una dimostrazione numerica.\n\n# Definire i valori di x\nx &lt;- c(2, 1, 4, 7)\n\n# Calcolare y\ny &lt;- 100 + 2 * x\n\n# Verificare la relazione tra le varianze\nresult &lt;- var(y) == 2^2 * var(x)\nresult\n#&gt; [1] TRUE\n\nVarianza della somma di due variabili indipendenti. La varianza della somma di due variabili indipendenti o anche solo incorrelate è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione. Se \\(\\mathbb{E}(X) = \\mathbb{E}(Y) = 0\\), allora \\(\\mathbb{E}(X+Y) = 0\\) e\n\\[\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).\\]\nSiccome le variabili sono indipendenti risulta \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0\\).\nVarianza della differenza di due variabili indipendenti. La varianza della differenza di due variabili indipendenti è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione.\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nVarianza della somma di due variabili non indipendenti. Se \\(X\\) e \\(Y\\) non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n\\]\ndove \\(Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nUna dimostrazione numerica di questo principio è fornita sotto.\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolare la varianza di x + y con ddof = 0\nvar_x_y &lt;- mean((x + y - mean(x + y))^2)\nvar_x_y\n#&gt; [1] 35.25\n\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolo della varianza combinata\nresult &lt;- mean((x - mean(x))^2) + \n          mean((y - mean(y))^2) + \n          2 * cov(x, y) * (length(x) - 1) / length(x)\nresult\n#&gt; [1] 35.25\n\nVarianza della media di variabili indipendenti. La media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione, ha varianza\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n\\]\nIl principio precedente è illustrato dalla seguente simulazione.\n\n# Creare la popolazione\nset.seed(123)  # Per riproducibilità\npopulation &lt;- rnorm(10000, mean = 50, sd = 10)\n\n# Definire dimensione del campione e numero di campioni\nsample_size &lt;- 30\nnum_samples &lt;- 100000\n\n# Creare un vettore per memorizzare le medie campionarie\nsample_means &lt;- numeric(num_samples)\n\n# Generare i campioni e calcolare le medie\nfor (i in 1:num_samples) {\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  sample_means[i] &lt;- mean(sample)\n}\n\n# Calcolare la varianza delle medie campionarie\nsampling_dist_mean_var &lt;- var(sample_means) * ((num_samples - 1) / num_samples)  # ddof = 0\nsampling_dist_mean_var\n#&gt; [1] 3.331\n\nIl valore teorico della varianza della distribuzione campionaria della media è\n\n10^2 / 30\n#&gt; [1] 3.333\n\n\n32.4.4 Variabili casuali continue\nPer una variabile casuale continua \\(X\\), la varianza è definita come:\n\\[\n\\mathbb{V}(X) = \\int_{-\\infty}^{+\\infty} \\large[x - \\mathbb{E}(X)\\large]^2 p(x) \\,\\operatorname {d}\\!x.\n\\tag{32.7}\\]\nAnalogamente al caso discreto, la varianza di una variabile casuale continua \\(X\\) una misura della dispersione, ovvero la “distanza” media quadratica attesa dei valori \\(x\\) rispetto alla loro media \\(\\mathbb{E}(X)\\). In altre parole, la varianza quantifica quanto i valori della variabile casuale si discostano tipicamente dal loro valore medio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#deviazione-standard",
    "href": "chapters/probability/09_expval_var.html#deviazione-standard",
    "title": "32  Proprietà delle variabili casuali",
    "section": "\n32.5 Deviazione Standard",
    "text": "32.5 Deviazione Standard\nQuando si lavora con le varianze, i valori sono elevati al quadrato, il che può rendere i numeri significativamente più grandi (o più piccoli) rispetto ai dati originali. Per riportare questi valori all’unità di misura della scala originale, si prende la radice quadrata della varianza. Il risultato ottenuto è chiamato deviazione standard ed è comunemente indicato con la lettera greca \\(\\sigma\\).\n\nDefinizione 32.3 La deviazione standard, o scarto quadratico medio, è definita come la radice quadrata della varianza:\n\\[\n\\sigma_X = \\sqrt{\\mathbb{V}(X)}.\n\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale fornisce una misura della dispersione, ossia la “distanza” tipica o prevista dei valori \\(x\\) rispetto alla loro media.\n\nEsempio 32.10 Per i dadi equilibrati dell’esempio precedente, la deviazione standard della variabile casuale \\(S\\) è pari a \\(\\sqrt{5.833} = 2.415\\). Questo valore indica quanto i risultati della somma dei due dadi tendono a variare attorno alla loro media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#standardizzazione",
    "href": "chapters/probability/09_expval_var.html#standardizzazione",
    "title": "32  Proprietà delle variabili casuali",
    "section": "\n32.6 Standardizzazione",
    "text": "32.6 Standardizzazione\n\nDefinizione 32.4 Data una variabile casuale \\(X\\), si dice variabile standardizzata di \\(X\\) l’espressione\n\\[\nZ = \\frac{X - \\mathbb{E}(X)}{\\sigma_X}.\n\\tag{32.8}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#il-teorema-di-chebyshev",
    "href": "chapters/probability/09_expval_var.html#il-teorema-di-chebyshev",
    "title": "32  Proprietà delle variabili casuali",
    "section": "\n32.7 Il Teorema di Chebyshev",
    "text": "32.7 Il Teorema di Chebyshev\nIl Teorema di Chebyshev ci permette di stimare la probabilità che una variabile aleatoria si discosti dal suo valore atteso (media) di una certa quantità. In altre parole, ci fornisce un limite superiore alla probabilità che una variabile aleatoria assuma valori “estremi”.\nIl teorema di Chebyshev afferma che, per qualsiasi variabile aleatoria X con media E(X) e varianza Var(X), e per qualsiasi numero reale k &gt; 0, si ha:\n\\[\nP(|X - E(X)| ≥ kσ) ≤ 1/k^2,\n\\]\ndove:\n\nP(|X - E(X)| ≥ kσ) è la probabilità che lo scarto assoluto tra X e la sua media sia maggiore o uguale a k volte la deviazione standard (σ).\nσ è la radice quadrata della varianza, ovvero la deviazione standard.\n\nCosa ci dice questo teorema?\n\n\nLimite superiore: Il teorema ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di più di k deviazioni standard.\n\nQualsiasi distribuzione: La bellezza di questo teorema è che vale per qualsiasi distribuzione di probabilità, a patto che la media e la varianza esistano.\n\nUtilizzo: Il teorema di Chebyshev è molto utile quando non conosciamo la distribuzione esatta di una variabile aleatoria, ma conosciamo la sua media e la sua varianza.\n\nIn sintesi, il teorema di Chebyshev ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di una certa quantità, in base alla sua varianza. Il teorema di Chebyshev ci permette quindi di fare inferenze sulla distribuzione di una variabile aleatoria anche quando abbiamo informazioni limitate.\n\nEsempio 32.11 Supponiamo di avere una variabile aleatoria X con media 100 e varianza 25. Vogliamo stimare la probabilità che X assuma valori al di fuori dell’intervallo [90, 110]. In questo caso, k = 2 (poiché 10 è uguale a 2 volte la deviazione standard, che è 5). Applicando il teorema di Chebyshev, otteniamo:\nP(|X - 100| ≥ 10) ≤ 1/2^2 = 0.25\nQuindi, possiamo affermare con certezza che al massimo il 25% dei valori di X saranno al di fuori dell’intervallo [90, 110].",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#momenti-di-variabili-casuali",
    "href": "chapters/probability/09_expval_var.html#momenti-di-variabili-casuali",
    "title": "32  Proprietà delle variabili casuali",
    "section": "\n32.8 Momenti di variabili casuali",
    "text": "32.8 Momenti di variabili casuali\n\nDefinizione 32.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densità \\(p(x)\\), la quantità\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{32.9}\\]\nSe \\(X\\) è una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i),\n\\tag{32.10}\\]\ndove:\n\n\n\\(E(X^q)\\) rappresenta il valore atteso di \\(X\\) elevato alla \\(q\\)-esima potenza.\n\n\\(x_i\\) sono i possibili valori della variabile discreta.\n\n\\(P(x_i)\\) è la probabilità associata a ciascun valore discreto.\n\n\nI momenti sono parametri statistici che forniscono informazioni importanti sulle caratteristiche di una variabile casuale. Tra questi, i più noti e utilizzati sono:\n\nIl momento del primo ordine (\\(q\\) = 1): corrisponde al valore atteso (o media) della variabile casuale \\(X\\).\nIl momento del secondo ordine (\\(q\\) = 2): quando calcolato rispetto alla media, corrisponde alla varianza.\n\nPer i momenti di ordine superiore al primo, è comune calcolarli rispetto al valore medio di \\(X\\). Questo si ottiene applicando una traslazione: \\(x_0 = x − \\mathbb{E}(X)\\), dove \\(x_0\\) rappresenta lo scarto dalla media. In particolare, il momento centrale del secondo ordine, calcolato con questa traslazione, corrisponde alla definizione di varianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#alcuni-esempi-in-r",
    "href": "chapters/probability/09_expval_var.html#alcuni-esempi-in-r",
    "title": "32  Proprietà delle variabili casuali",
    "section": "\n32.9 Alcuni esempi in R",
    "text": "32.9 Alcuni esempi in R\nIn R, possiamo calcolare il valore atteso e la varianza di variabili casuali discrete utilizzando vettori di valori e probabilità.\nConsideriamo una variabile casuale \\(X\\) che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilità: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\nx &lt;- 0:6\nprint(x)\n#&gt; [1] 0 1 2 3 4 5 6\n\nIl vettore px conterrà le probabilità associate ai valori x:\n\npx &lt;- c(0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)\nprint(px)\n#&gt; [1] 0.1 0.2 0.3 0.1 0.1 0.0 0.2\n\nControlliamo che la somma sia 1:\n\nsum(px)\n#&gt; [1] 1\n\nCalcoliamo il valore atteso di \\(X\\) implementando la formula del valore atteso utilizzando i vettori x e px:\n\nx_ev &lt;- sum(x * px)\nx_ev\n#&gt; [1] 2.7\n\nCalcoliamo la varianza di \\(X\\) usando i vettori x e px:\n\nx_var &lt;- sum((x - x_ev)^2 * px)\nx_var\n#&gt; [1] 3.81\n\nCalcoliamo la deviazione standard di \\(X\\) prendendo la radice quadrata della varianza:\n\nx_sd &lt;- sqrt(x_var)\nx_sd\n#&gt; [1] 1.952\n\nPer rappresentare graficamente la distribuzione di massa, possiamo usare ggplot2:\n\ndf &lt;- data.frame(x = x, pmf = px)\nggplot(df, aes(x = x, y = pmf)) +\n  geom_point(color = \"#832F2B\", size = 3) +\n  geom_segment(aes(xend = x, yend = 0), linewidth = 1) +\n  labs(title = \"Distribuzione di massa di probabilità\", \n       x = \"Valori\", y = \"Probabilità\")\n\n\n\n\n\n\n\nQuesto codice calcola il valore atteso, la varianza e la deviazione standard di una variabile casuale discreta e rappresenta graficamente la distribuzione di massa, tutto in R.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#riflessioni-conclusive",
    "href": "chapters/probability/09_expval_var.html#riflessioni-conclusive",
    "title": "32  Proprietà delle variabili casuali",
    "section": "\n32.10 Riflessioni Conclusive",
    "text": "32.10 Riflessioni Conclusive\nIn conclusione, i concetti di valore atteso e varianza sono fondamentali per comprendere il comportamento delle variabili casuali. Il valore atteso fornisce una misura centrale, rappresentando il “valore tipico” che ci si aspetta di osservare, mentre la varianza quantifica la dispersione dei valori attorno a questa media, offrendo una visione più completa della distribuzione. Questi strumenti sono essenziali per l’analisi e la modellizzazione statistica, fornendo le basi per valutare e interpretare la variabilità nei fenomeni aleatori.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#esercizi",
    "href": "chapters/probability/09_expval_var.html#esercizi",
    "title": "32  Proprietà delle variabili casuali",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Calcolo del Valore Atteso per Variabili Discrete\nUtilizzando i dati raccolti dagli studenti sulla SWLS, calcola il valore atteso della soddisfazione con la vita (\\(X\\)). Organizza i dati come nell’esempio seguente e interpretalo come se fosse la distribuzione di probabilità nella popolazione:\n\n\nSWLS Score\nProbabilità \\(P(X)\\)\n\n\n\n\n5\n0.05\n\n\n10\n0.10\n\n\n15\n0.20\n\n\n20\n0.30\n\n\n25\n0.20\n\n\n30\n0.10\n\n\n35\n0.05\n\n\n\n\nCalcola il valore atteso di \\(X\\), \\(\\mathbb{E}(X)\\).\nInterpreta il risultato ottenuto.\n\nEsercizio 2: Varianza e Deviazione Standard\nData la stessa distribuzione della SWLS utilizzata nell’esercizio precedente:\n\nCalcola la varianza \\(\\mathbb{V}(X)\\).\nCalcola la deviazione standard \\(\\sigma_X\\).\nCommenta il significato della dispersione dei valori rispetto alla media.\n\nEsercizio 3: Proprietà del Valore Atteso\nUtilizzando la distribuzione della LSNS-6:\n\nDefinisci una nuova variabile casuale \\(Y = 2X + 3\\).\nCalcola il valore atteso di \\(Y\\), \\(\\mathbb{E}(Y)\\), utilizzando la linearità dell’operatore di aspettazione.\nVerifica il risultato calcolando direttamente \\(\\mathbb{E}(Y)\\) dalla distribuzione di probabilità di \\(Y\\).\n\nUtilizza una distribuzione della LSNS-6 organizzata come segue (sostituisci i valori presenti con quelli del campione):\n\n\nLSNS-6 Score\nProbabilità \\(P(Y)\\)\n\n\n\n\n5\n0.10\n\n\n10\n0.15\n\n\n15\n0.25\n\n\n20\n0.25\n\n\n25\n0.15\n\n\n30\n0.10\n\n\n\nEsercizio 4: Applicazione del Teorema di Chebyshev\nSia la soddisfazione con la vita (SWLS) distribuita con media \\(\\mu = 3.2\\) e deviazione standard \\(\\sigma = 0.8\\).\n\nUsa il teorema di Chebyshev per trovare un limite superiore alla probabilità che un valore di SWLS sia oltre due deviazioni standard dalla media.\nConfronta questo risultato con la probabilità empirica calcolata utilizzando i dati raccolti.\n\nEsercizio 5: Standardizzazione e Distribuzione Normale\n# Definizione dei dati osservati della LSNS-6 (sostituisci con i dati reali se disponibili)\nlsns6_scores &lt;- c(5, 8, 10, 12, 15, 18, 20, 22, 25, 28)\n\n# Parametri della distribuzione\nmu &lt;- 12   # Media della LSNS-6\nsigma &lt;- 4  # Deviazione standard della LSNS-6\n\n# Standardizzazione dei valori osservati\nz_scores &lt;- (lsns6_scores - mu) / sigma\n\n# Creazione dell'istogramma della distribuzione standardizzata\nhist(z_scores, \n     breaks = 10, \n     col = \"lightblue\", \n     main = \"Istogramma della distribuzione standardizzata di LSNS-6\", \n     xlab = \"Z-score\", \n     ylab = \"Frequenza\",\n     probability = TRUE)\n\n# Sovrapposizione della curva normale standard\ncurve(dnorm(x, mean = 0, sd = 1), col = \"red\", lwd = 2, add = TRUE)\n\nStandardizzazione: La trasformazione dei punteggi della LSNS-6 in Z-score permette di esprimere ogni valore in termini di deviazioni standard rispetto alla media. Un valore \\(Z = 1\\) significa che il punteggio di LSNS-6 è una deviazione standard sopra la media, mentre \\(Z = -1\\) significa che è una deviazione standard sotto la media.\nIstogramma della distribuzione standardizzata: Il grafico mostra la distribuzione dei punteggi standardizzati. Se la distribuzione originale è simile a una normale, l’istogramma dei punteggi standardizzati dovrebbe assomigliare a una distribuzione normale standard.\nConfronto con la distribuzione normale standard: La curva rossa rappresenta la densità di una normale standard (((0,1))). Se i dati sono approssimativamente normali, l’istogramma dei punteggi standardizzati dovrebbe seguire la forma della curva normale standard. Differenze marcate potrebbero indicare asimmetria o curtosi anomale nella distribuzione dei punteggi LSNS-6.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Calcolo del Valore Atteso della SWLS\nLa Satisfaction With Life Scale (SWLS) è composta da 5 item, ciascuno valutato su una scala Likert da 1 a 7. Supponiamo di avere la seguente distribuzione di probabilità per il punteggio totale della SWLS basata su un campione di studenti:\n\n\nSWLS Score\nProbabilità \\(P(X)\\)\n\n\n\n\n5\n0.05\n\n\n10\n0.10\n\n\n15\n0.20\n\n\n20\n0.30\n\n\n25\n0.20\n\n\n30\n0.10\n\n\n35\n0.05\n\n\n\nDomanda:\nCalcola il valore atteso \\(\\mathbb{E}[X]\\) del punteggio SWLS.\nSoluzione: Il valore atteso si calcola come:\n\\[\n\\mathbb{E}[X] = \\sum x_i P(x_i)\n\\]\nCalcoliamo in R:\n# Definizione dei valori SWLS e delle probabilità\nswls_scores &lt;- c(5, 10, 15, 20, 25, 30, 35)\nprob_swls &lt;- c(0.05, 0.10, 0.20, 0.30, 0.20, 0.10, 0.05)\n\n# Calcolo del valore atteso\nexpected_swls &lt;- sum(swls_scores * prob_swls)\nexpected_swls\nRisultato:\\[\n\\mathbb{E}[X] = 20\n\\]\nIl valore atteso rappresenta la media teorica della soddisfazione con la vita nella popolazione, assumendo che la distribuzione dei punteggi SWLS segua esattamente le probabilità fornite. In altre parole, se prendessimo un numero molto grande di individui con questa distribuzione di probabilità, il punteggio medio atteso sarebbe 20. Questo suggerisce che, nella popolazione considerata, il livello medio di soddisfazione con la vita si colloca al centro della scala SWLS.\nEsercizio 2: Calcolo della Varianza e Deviazione Standard della SWLS\n# Definizione dei dati\nswls_scores &lt;- c(5, 10, 15, 20, 25, 30, 35)\nprobabilities &lt;- c(0.05, 0.10, 0.20, 0.30, 0.20, 0.10, 0.05)\n\n# Calcolo del valore atteso (media attesa)\nexpected_value &lt;- sum(swls_scores * probabilities)\n\n# Calcolo della varianza\nvariance &lt;- sum((swls_scores - expected_value)^2 * probabilities)\n\n# Calcolo della deviazione standard\nstd_deviation &lt;- sqrt(variance)\n\n# Stampa dei risultati\ncat(\"Valore atteso (E[X]):\", expected_value, \"\\n\")\ncat(\"Varianza (Var[X]):\", variance, \"\\n\")\ncat(\"Deviazione standard (σ_X):\", std_deviation, \"\\n\")\n\n\nVarianza: Misura la dispersione dei punteggi SWLS rispetto alla media attesa. Se la varianza è alta, significa che i punteggi sono molto variabili; se è bassa, significa che i punteggi sono più concentrati attorno al valore atteso.\n\nDeviazione standard: È la radice quadrata della varianza e ha la stessa unità di misura dei dati originali. Fornisce un’indicazione della dispersione media dei punteggi rispetto alla media.\n\nSe la deviazione standard è elevata, significa che nella popolazione ci sono sia individui con livelli di soddisfazione molto bassi sia individui con livelli molto alti. Se è bassa, i punteggi sono più omogenei intorno alla media.\nEsercizio 3: Calcolo del Valore Atteso della Scala della Rete Sociale di Lubben (LSNS-6)\n# Definizione dei dati della LSNS-6\nlsns_scores &lt;- c(5, 10, 15, 20, 25, 30)\nprobabilities &lt;- c(0.10, 0.15, 0.25, 0.25, 0.15, 0.10)\n\n# Definizione della trasformazione della variabile casuale Y = 2X + 3\ny_values &lt;- 2 * lsns_scores + 3\n\n# Calcolo del valore atteso di X\nexpected_x &lt;- sum(lsns_scores * probabilities)\n\n# Utilizzo della linearità dell'operatore di aspettazione: E[Y] = 2E[X] + 3\nexpected_y_from_x &lt;- 2 * expected_x + 3\n\n# Calcolo diretto del valore atteso di Y\nexpected_y_direct &lt;- sum(y_values * probabilities)\n\n# Stampa dei risultati\ncat(\"Valore atteso di X (E[X]):\", expected_x, \"\\n\")\ncat(\"Valore atteso di Y calcolato con la linearità (E[Y] = 2E[X] + 3):\", expected_y_from_x, \"\\n\")\ncat(\"Valore atteso di Y calcolato direttamente dalla distribuzione di probabilità di Y:\", expected_y_direct, \"\\n\")\n\n\nLinearità dell’operatore di aspettazione: Questo principio afferma che se una variabile casuale \\(X\\) viene trasformata linearmente in \\(Y = aX + b\\), allora il valore atteso di \\(Y\\) è dato da:\n\\[\n\\mathbb{E}(Y) = a \\mathbb{E}(X) + b\n\\]\nQuesto semplifica il calcolo senza dover ridefinire una nuova distribuzione di probabilità.\n\nVerifica del risultato: Dopo aver calcolato \\(\\mathbb{E}(Y)\\) con la proprietà di linearità, lo confrontiamo con il calcolo diretto utilizzando la distribuzione trasformata. Se i due valori coincidono, confermiamo che la proprietà di linearità è rispettata.\nSignificato pratico: La trasformazione lineare di una variabile casuale può rappresentare un’operazione reale come la conversione di punteggi da una scala all’altra. Il valore atteso si comporta linearmente, il che è utile per interpretare trasformazioni senza dover ricalcolare completamente la distribuzione.\n\nEsercizio 4: Probabilità secondo il Teorema di Chebyshev\nIl Teorema di Chebyshev afferma che per qualsiasi distribuzione, la probabilità che un valore sia oltre \\(k\\) deviazioni standard dalla media è al massimo:\n\\[\nP(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}\n\\]\nSostituendo \\(k = 2\\):\n\\[\nP(|X - 3.2| \\geq 2 \\cdot 0.8) \\leq \\frac{1}{2^2} = \\frac{1}{4} = 0.25\n\\]\nQuindi, il Teorema di Chebyshev fornisce un limite superiore del 25% alla probabilità che un valore di SWLS sia oltre due deviazioni standard dalla media.\nPer confrontare questo risultato con la probabilità empirica, è necessaro usare i dati raccolti sulla SWLS.\nEsercizio 5: Standardizzazione del Punteggio LSNS-6\nDomanda:\nStandardizza il punteggio LSNS-6 trasformandolo nella variabile standardizzata \\(Z\\).\n\\[\nZ = \\frac{Y - \\mathbb{E}(Y)}{\\sigma_Y}\n\\]\nSoluzione: Calcoliamo in R:\n# Standardizzazione dei punteggi LSNS-6\nz_lsns &lt;- (lsns_scores - expected_lsns) / sd_lsns\nz_lsns\nRisultato:\n\n\nLSNS-6 Score\nZ-Score\n\n\n\n5\n-2.23\n\n\n10\n-1.34\n\n\n15\n-0.45\n\n\n20\n0.45\n\n\n25\n1.34\n\n\n30\n2.23\n\n\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio 6: Personalizzazione degli Interventi Basati sulla Probabilità Condizionata\nUno psicologo scolastico vuole identificare quali studenti potrebbero trarre maggiore beneficio da un programma di supporto psicologico. Dalla letteratura, si sa che la probabilità di avere livelli bassi di soddisfazione con la vita (SWLS ≤ 15) è più alta tra gli studenti che riportano elevati livelli di stress accademico.\nDai dati raccolti su un campione di studenti:\n\n\\(P(\\text{SWLS} \\leq 15) = 0.35\\)\n\\(P(\\text{Stress Alto}) = 0.40\\)\n\\(P(\\text{SWLS} \\leq 15 \\mid \\text{Stress Alto}) = 0.60\\)\n\nDomanda Se uno studente è scelto a caso, qual è la probabilità che abbia un alto livello di stress dato che il suo punteggio SWLS è ≤ 15?\nEsercizio 7: Prevedere il Successo di un Intervento Psicologico Uno psicologo clinico sta valutando l’efficacia di un intervento sulla riduzione dell’ansia. Ha raccolto i dati di 100 pazienti e ha osservato che il miglioramento medio nei punteggi di ansia (misurati con DASS-21) è di 5 punti con una deviazione standard di 2.5.\nSupponiamo che il miglioramento sia una variabile aleatoria normale con media 5 e deviazione standard 2.5.\nDomanda Qual è la probabilità che un paziente scelto a caso migliori di almeno 7 punti?\nEsercizio 8: Allocazione Ottimale delle Risorse in un Programma di Prevenzione Uno psicologo organizza un programma di sensibilizzazione sulla salute mentale in diverse scuole. Ha raccolto dati sulla frequenza con cui gli studenti si rivolgono allo sportello di ascolto, con la seguente distribuzione:\n\n\nNumero di Visite\nProbabilità\n\n\n\n0\n0.40\n\n\n1\n0.30\n\n\n2\n0.15\n\n\n3+\n0.15\n\n\n\nDomanda Se lo psicologo ha risorse per organizzare colloqui individuali solo per il 30% degli studenti, quale soglia può usare per selezionare gli studenti più bisognosi in base alla distribuzione delle visite?\nEsercizio 9: Misurare la Variabilità della Risposta a un Trattamento Uno psicologo somministra un trattamento per la depressione e misura la variazione nei punteggi di depressione su un campione di pazienti prima e dopo l’intervento.\nLe variazioni seguono questa distribuzione:\n\n\nΔ Punteggio DASS-21\nProbabilità\n\n\n\n-10\n0.10\n\n\n-5\n0.20\n\n\n0\n0.40\n\n\n+5\n0.20\n\n\n+10\n0.10\n\n\n\nDomanda Qual è la deviazione standard della variazione nei punteggi di depressione?\nEsercizio 10: Probabilità di un Fallimento in un Programma di Sensibilizzazione Uno psicologo organizza un programma per ridurre il pregiudizio sulla salute mentale. Dai dati precedenti, la probabilità di successo di ogni evento di sensibilizzazione è del 70%. Se organizza 5 eventi indipendenti, qual è la probabilità che almeno 1 fallisca?\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 6: Personalizzazione degli Interventi Basati sulla Probabilità Condizionata\nUtilizziamo la formula della probabilità condizionata:\n\\[\nP(\\text{Stress Alto} \\mid \\text{SWLS} \\leq 15) = \\frac{P(\\text{SWLS} \\leq 15 \\mid \\text{Stress Alto}) P(\\text{Stress Alto})}{P(\\text{SWLS} \\leq 15)}\n\\]\nCalcoliamo in R:\np_swls_low &lt;- 0.35\np_stress_high &lt;- 0.40\np_swls_given_stress &lt;- 0.60\n\np_stress_given_swls &lt;- (p_swls_given_stress * p_stress_high) / p_swls_low\np_stress_given_swls\nRisultato Lo psicologo può usare questa informazione per identificare studenti con alta probabilità di avere stress elevato, anche se non hanno segnalato direttamente il problema, e offrire supporto mirato.\nEsercizio 7: Prevedere il Successo di un Intervento Psicologico\nUsiamo la normalizzazione:\n\\[\nZ = \\frac{X - \\mu}{\\sigma}\n\\]\ne calcoliamo la probabilità corrispondente:\nmean_improvement &lt;- 5\nsd_improvement &lt;- 2.5\nthreshold &lt;- 7\n\np_improve_7 &lt;- 1 - pnorm(threshold, mean = mean_improvement, sd = sd_improvement)\np_improve_7\nRisultato Questo aiuta lo psicologo a comunicare ai pazienti la probabilità di ottenere miglioramenti significativi e ad adattare le aspettative dell’intervento.\nEsercizio 8: Allocazione Ottimale delle Risorse in un Programma di Prevenzione\nSoluzione Calcoliamo la probabilità cumulativa:\nvisits &lt;- c(0, 1, 2, 3)\nprobabilities &lt;- c(0.40, 0.30, 0.15, 0.15)\ncumulative_prob &lt;- cumsum(probabilities)\n\n# Determinare la soglia per il 30% più bisognoso\nthreshold &lt;- visits[min(which(cumulative_prob &gt;= 0.70))]\nthreshold\nRisultato Lo psicologo può decidere di offrire supporto prioritario a studenti con almeno 2 visite, massimizzando l’impatto con risorse limitate.\nEsercizio 9: Misurare la Variabilità della Risposta a un Trattamento\nSoluzione Calcoliamo la varianza e la deviazione standard:\nscore_changes &lt;- c(-10, -5, 0, 5, 10)\nprobabilities &lt;- c(0.10, 0.20, 0.40, 0.20, 0.10)\n\n# Media attesa\nexpected_change &lt;- sum(score_changes * probabilities)\n\n# Varianza\nvariance_change &lt;- sum((score_changes - expected_change)^2 * probabilities)\n\n# Deviazione standard\nsd_change &lt;- sqrt(variance_change)\nsd_change\nRisultato Se la deviazione standard è grande, significa che l’effetto del trattamento è molto variabile e potrebbero essere necessarie strategie personalizzate.\nEsercizio 10: Probabilità di un Fallimento in un Programma di Sensibilizzazione\nUsiamo la distribuzione binomiale:\np_success &lt;- 0.70\nn_events &lt;- 5\n\np_failure_at_least_one &lt;- 1 - dbinom(5, n_events, p_success)\np_failure_at_least_one\nRisultato Lo psicologo può pianificare strategie di miglioramento sapendo la probabilità di un fallimento.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/09_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "32  Proprietà delle variabili casuali",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#bibliografia",
    "href": "chapters/probability/09_expval_var.html#bibliografia",
    "title": "32  Proprietà delle variabili casuali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html",
    "href": "chapters/probability/10_sampling_distr.html",
    "title": "33  Stime, stimatori e parametri",
    "section": "",
    "text": "33.1 Introduzione\nIn psicologia, è comune voler comprendere determinate caratteristiche di una popolazione, ma spesso non è possibile raccogliere dati su tutti i suoi membri a causa di vincoli di tempo, budget o accessibilità. Ad esempio, potremmo essere interessati a stimare la percentuale di persone che soffrono di un particolare disturbo d’ansia o la media di un punteggio di memoria a breve termine in una data popolazione, ma non possiamo testare ogni singolo individuo. In questi casi, ricorriamo a un campione di partecipanti selezionati in modo casuale, dai quali estraiamo informazioni per inferire la caratteristica dell’intera popolazione, con un certo grado di incertezza.\nNel linguaggio statistico:\nSupponiamo, per esempio, di voler conoscere la proporzione di adulti che manifestano un determinato sintomo ansioso. Denotiamo questa proporzione come \\(p\\). Poiché non possiamo (o non vogliamo) valutare l’intera popolazione di adulti, estraiamo un campione casuale di \\(N\\) individui e registriamo quanti di loro presentano il sintomo. Il rapporto tra chi mostra il sintomo e il totale del campione diventa la nostra stima \\(\\hat{p}\\) (la “stima campionaria” dell’incognita \\(p\\)). È intuitivo aspettarsi che \\(\\hat{p}\\) non coincida esattamente con \\(p\\); tuttavia, la teoria probabilistica mostra che con buona probabilità \\(\\hat{p}\\) non se ne discosterà troppo (in assenza di distorsioni sistematiche).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#introduzione",
    "href": "chapters/probability/10_sampling_distr.html#introduzione",
    "title": "33  Stime, stimatori e parametri",
    "section": "",
    "text": "Popolazione: l’insieme completo degli individui (o unità) di interesse. Ad esempio, tutte le persone che soddisfano determinati criteri diagnostici oppure tutti gli studenti di una scuola.\n\nParametro: la quantità (sconosciuta) che descrive una caratteristica d’interesse della popolazione (ad es. la vera proporzione di soggetti con un certo disturbo, oppure la vera media di un test cognitivo).\n\nCampione: un sottoinsieme (idealmente casuale) di individui della popolazione.\n\nStima: il valore numerico, calcolato dal campione, che fornisce un’approssimazione del parametro.\n\nStimatore: la regola o funzione matematica applicata ai dati del campione per ottenere la stima.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#popolazione-e-campione",
    "href": "chapters/probability/10_sampling_distr.html#popolazione-e-campione",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.2 Popolazione e campione",
    "text": "33.2 Popolazione e campione\nPer concretezza, immaginiamo di voler quantificare la frequenza di un certo sintomo (per es. un indicatore di ansia) in una grande popolazione, come l’insieme di tutti gli studenti universitari di un paese. Poiché sarebbe impossibile valutare tutti gli studenti, selezioniamo un gruppo più piccolo di individui in modo idealmente casuale (il nostro campione). Poniamo a ciascuno di essi un questionario standardizzato per valutare la presenza/assenza del sintomo. Alla fine, vogliamo utilizzare il dato raccolto nel campione per stimare la reale proporzione di studenti con tale sintomo nella popolazione complessiva.\nIn statistica, questo processo di selezione di un sottogruppo rappresentativo è chiamato campionamento, mentre la proporzione di individui con il sintomo d’ansia all’interno del campione è la stima campionaria \\(\\bar{X}\\). Se il nostro campione riflette bene la popolazione, \\(\\bar{X}\\) sarà un buon surrogato di \\(p\\), il parametro che davvero ci interessa.\n\n33.2.1 Lo stimatore: la proporzione campionaria\nSe consideriamo un modello “urna” in cui la popolazione è come un’urna contenente “biglie” di due colori (ad esempio, “blu” per presenza del sintomo, “rosso” per assenza), possiamo immaginare di estrarre a caso \\(N\\) biglie dall’urna per ottenere il nostro campione. Definiamo \\(X_i=1\\) se l’individuo \\(i\\)-esimo riporta il sintomo (biglia blu) e \\(X_i=0\\) se non lo riporta (biglia rossa). La proporzione campionaria è allora \\[\n\\bar{X} = \\frac{1}{N}\\sum_{i=1}^N X_i.\n\\] In questo contesto:\n\n\n\\(p\\) è la vera proporzione di studenti con il sintomo nella popolazione.\n\n\\(\\bar{X}\\) è la proporzione osservata nel campione (ossia la stima empirica di \\(p\\)).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#distribuzione-campionaria-varianza-e-valore-atteso-di-uno-stimatore",
    "href": "chapters/probability/10_sampling_distr.html#distribuzione-campionaria-varianza-e-valore-atteso-di-uno-stimatore",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.3 Distribuzione campionaria: varianza e valore atteso di uno stimatore",
    "text": "33.3 Distribuzione campionaria: varianza e valore atteso di uno stimatore\nIl passaggio cruciale per il ragionamento inferenziale è comprendere come \\(\\bar{X}\\) (o un qualsiasi altro indice calcolato dal campione) varia se ripetiamo lo stesso tipo di campionamento molte volte. Questo comportamento probabilistico di \\(\\bar{X}\\) è noto come distribuzione campionaria.\n\n33.3.1 Valore atteso della media (o proporzione) campionaria\nSe \\(X_1, X_2, \\dots, X_n\\) sono variabili aleatorie indipendenti e identicamente distribuite (iid), e ciascuna ha valore atteso \\(\\mathbb{E}[X_i] = \\mu\\), allora la media campionaria \\[\n\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i\n\\] ha a sua volta un valore atteso \\[\n\\mathbb{E}[\\bar{X}] = \\mu.\n\\] Ciò significa che \\(\\bar{X}\\) è uno stimatore non distorto del vero parametro \\(\\mu\\). Nel caso di variabili 0-1 (sintomo assente/presente), \\(\\mu\\equiv p\\). In parole semplici, se rifacessimo infinite volte lo stesso campionamento, la media di tutte le nostre stime campionarie coinciderebbe con la vera proporzione di interesse.\n\n33.3.2 Varianza della media (o proporzione) campionaria\nLa variabilità di \\(\\bar{X}\\) attorno a \\(\\mu\\) si misura con la varianza: \\[\n\\mathrm{Var}(\\bar{X}) = \\frac{\\sigma^2}{n},\n\\] dove \\(\\sigma^2\\) è la varianza individuale di ciascun \\(X_i\\). Per il caso Bernoulliano (0-1) con \\(\\mathbb{E}[X_i]=p\\), si ha \\(\\sigma^2 = p(1-p)\\). Quindi: \\[\n\\mathrm{Var}(\\bar{X}) = \\frac{p(1-p)}{n}.\n\\] La radice quadrata della varianza di \\(\\bar{X}\\) è l’errore standard (o SE), ossia \\[\n\\mathrm{SE}(\\bar{X}) = \\sqrt{\\frac{p(1-p)}{n}}.\n\\] Più \\(n\\) è grande, più si riduce la varianza (e quindi l’incertezza) della nostra stima: ecco perché, in psicologia come in molti altri campi, campioni di maggiori dimensioni danno stime più precise.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#la-distribuzione-campionaria-della-media",
    "href": "chapters/probability/10_sampling_distr.html#la-distribuzione-campionaria-della-media",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.4 La Distribuzione Campionaria della Media",
    "text": "33.4 La Distribuzione Campionaria della Media\nPer illustrare il concetto di distribuzione campionaria, consideriamo un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, è fondamentale notare che le proprietà e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\nLa distribuzione campionaria ci dà una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all’intera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di \\(\\mu\\). Tuttavia, un altro campione fornirà una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell’incertezza legata al processo di stima.\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nL’istogramma seguente descrive la distribuzione della popolazione.\n\nggplot(data.frame(x = x), aes(x)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density))\n  )\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione. Media:\n\nmean_x &lt;- mean(x) # Media della popolazione\nmean_x\n#&gt; [1] 4.25\n\nVarianza:\n\nvar_x &lt;- var(x) * ((length(x) - 1) / length(x)) # Varianza popolazione\nvar_x\n#&gt; [1] 1.812\n\nConsideriamo tutti i possibili campioni di dimensione \\(n = 2\\) che possono essere estratti dalla popolazione rappresentata dal vettore x. Per generare questi campioni, utilizziamo la funzione expand.grid in R, che consente di creare tutte le combinazioni possibili di valori, includendo le ripetizioni.\nIl risultato sarà un data frame con 16 righe e 2 colonne, dove ogni riga rappresenta una coppia possibile di valori estratti dal vettore x. Questo risultato è in linea con il principio del calcolo combinatorio: quando selezioniamo \\(n\\) elementi da un insieme di \\(k\\) elementi e permettiamo ripetizioni, il numero totale di combinazioni è dato da \\(k^n\\). Nel nostro caso, con \\(k = 4\\) e \\(n = 2\\), otteniamo:\n\\[\n4^2 = 16 \\text{ combinazioni}.\n\\]\nUtilizzando expand.grid, possiamo verificare questo risultato in R:\n\n# Generazione delle combinazioni con ripetizione\nsamples &lt;- expand.grid(x, x)\n\n# Visualizzazione del risultato\nprint(samples)\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nIl data frame risultante mostrerà tutte le possibili coppie \\((x_1, x_2)\\), dove \\(x_1\\) e \\(x_2\\) possono essere scelti indipendentemente dalla popolazione \\(x = \\{2, 4.5, 5, 5.5\\}\\).\nPer calcolare la media di ogni campione di ampiezza \\(n = 2\\), possiamo utilizzare la funzione rowMeans, che calcola la media per ogni riga di una matrice. In questo modo, otteniamo un vettore contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la distribuzione campionaria delle medie dei campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media di ciascun campione\nsample_means &lt;- rowMeans(samples)\nprint(sample_means)\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\nUna rappresentazione grafica della distribuzione campionaria delle medie dei campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x è fornita qui sotto.\n\n# Istogramma delle medie campionarie\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density))\n)\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\n# Creare un data frame con i campioni e le loro medie\ndf &lt;- data.frame(\n  Samples = apply(samples, 1, paste, collapse = \", \"),\n  x_bar = rowMeans(samples)\n)\nprint(df)\n#&gt;     Samples x_bar\n#&gt; 1      2, 2  2.00\n#&gt; 2    4.5, 2  3.25\n#&gt; 3      5, 2  3.50\n#&gt; 4    5.5, 2  3.75\n#&gt; 5    2, 4.5  3.25\n#&gt; 6  4.5, 4.5  4.50\n#&gt; 7    5, 4.5  4.75\n#&gt; 8  5.5, 4.5  5.00\n#&gt; 9      2, 5  3.50\n#&gt; 10   4.5, 5  4.75\n#&gt; 11     5, 5  5.00\n#&gt; 12   5.5, 5  5.25\n#&gt; 13   2, 5.5  3.75\n#&gt; 14 4.5, 5.5  5.00\n#&gt; 15   5, 5.5  5.25\n#&gt; 16 5.5, 5.5  5.50\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media delle medie campionarie\nmean(sample_means)\n#&gt; [1] 4.25\n\nSi noti che questo valore coincide con la media della popolazione.\nEcco una versione corretta e migliorata del testo:\nLa varianza delle medie campionarie, calcolata empiricamente, può essere ottenuta direttamente dai dati utilizzando la seguente formula:\n\nvar(x) * (length(x) - 1) / length(x) / length(x)\n#&gt; [1] 0.4531\n\nQuesto calcolo riflette la formula teorica per la varianza della media campionaria, definita come la varianza dei dati divisa per la dimensione del campione \\(n\\). Tuttavia, poiché la funzione var() in R utilizza \\(n-1\\) al denominatore per fornire una stima non distorta della varianza della popolazione, è necessario applicare un fattore di correzione \\(\\frac{n-1}{n}\\) per ottenere la varianza campionaria corretta. Successivamente, questa varianza viene divisa per \\(n\\) per ottenere la varianza della media campionaria.\nIn alternativa, possiamo calcolare lo stesso valore prendendo la varianza delle medie di tutti i campioni (16 in questo caso):\n\nvar(sample_means) * ((length(sample_means) - 1) / length(sample_means))\n#&gt; [1] 0.9062\n\nAnche in questo caso applichiamo il fattore di correzione \\(\\frac{n-1}{n}\\) per ottenere il calcolo corretto della varianza usando la funzione var() in R.\nEntrambi i calcoli forniscono risultati coerenti con la teoria, dimostrando che la varianza delle medie campionarie è inferiore a quella della popolazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#dimostrazioni-formali",
    "href": "chapters/probability/10_sampling_distr.html#dimostrazioni-formali",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.5 Dimostrazioni Formali",
    "text": "33.5 Dimostrazioni Formali\n\n33.5.1 Valore Atteso della Media Campionaria\nApplichiamo le proprietà della speranza matematica per calcolare \\(\\mathbb{E}(\\bar{X})\\):\n\\[\n\\begin{align*}\n\\mathbb{E}(\\bar{X}) & = \\mathbb{E}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) & \\text{(definizione di media campionaria)} \\\\\n& = \\frac{1}{n} \\mathbb{E}\\left(\\sum_{i=1}^n X_i\\right) & \\text{(linearità della speranza)} \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}(X_i) & \\text{(speranza della somma)} \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mu & \\text{(tutte le $X_i$ hanno valore atteso $\\mu$)} \\\\\n& = \\frac{1}{n} \\cdot n \\cdot \\mu & \\text{(semplificazione della somma)} \\\\\n& = \\mu.\n\\end{align*}\n\\]\nAbbiamo dimostrato che il valore atteso della media campionaria è uguale al valore atteso delle singole variabili. In termini pratici, ciò implica che la media campionaria è un stimatore non distorto del valore atteso della popolazione: anche se la media campionaria può variare a seconda del campione, in media si avvicina sempre al valore atteso della popolazione, \\(\\mu\\).\nQuesta proprietà è una delle basi della statistica inferenziale. La media campionaria è uno degli stimatori più utilizzati in pratica proprio perché, oltre a essere non distorta, presenta altre proprietà utili, come l’efficienza (soprattutto per \\(n\\) grande).\n\n33.5.2 Varianza della Media Campionaria\nDato che le variabili \\(X_1, X_2, \\ldots, X_n\\) sono indipendenti ed identicamente distribuite (iid) con valore atteso \\(\\mu\\) e varianza \\(\\sigma^2\\), possiamo calcolare la varianza della media campionaria \\(\\bar{X}\\) come segue:\n\\[\n\\begin{align*}\n\\text{Var}(\\bar{X}) & = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(X_i) \\quad \\text{(dato che le $X_i$ sono indipendenti, i termini incrociati si annullano)} \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 \\\\\n& = \\frac{1}{n^2} \\cdot n \\cdot \\sigma^2 \\\\\n& = \\frac{\\sigma^2}{n}\n\\end{align*}\n\\]\nQuindi, la varianza della media campionaria di \\(n\\) variabili iid è uguale alla varianza di ciascuna variabile singola divisa per \\(n\\), che in questo caso è \\(\\sigma^2/n\\).\nQuesto risultato riflette un’importante proprietà statistica:\n\nall’aumentare di \\(n\\), la varianza della media campionaria diminuisce, rendendo la media campionaria una stima più precisa del valore atteso \\(\\mu\\). La riduzione della varianza è proporzionale a \\(1/n\\), quindi raddoppiare il campione riduce la varianza della media campionaria di un fattore 2.\n\nIn conclusione, la formula \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\) mostra che la precisione della media campionaria aumenta con la dimensione del campione, poiché la varianza diminuisce. Questo principio è alla base dell’importanza di campioni più grandi nella stima statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#sec-lln",
    "href": "chapters/probability/10_sampling_distr.html#sec-lln",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.6 Legge dei Grandi Numeri",
    "text": "33.6 Legge dei Grandi Numeri\nLa Legge dei Grandi Numeri (LLN, dall’inglese Law of Large Numbers) è uno dei pilastri fondamentali della teoria della probabilità. Essa descrive come, all’aumentare del numero di osservazioni, la media campionaria si avvicini stabilmente al valore atteso teorico. In termini formali, se \\(\\bar{X}_n\\) rappresenta la media di \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) con valore atteso \\(\\mu\\), allora \\(\\bar{X}_n \\to \\mu\\) quando \\(n \\to \\infty\\). Questo principio è cruciale per comprendere la relazione tra dati empirici e modelli teorici, come discusso nella sezione sull’interpretazione della probabilità (Capitolo 24).\nEsistono due versioni principali della Legge dei Grandi Numeri:\n\nLegge Forte: La media campionaria \\(\\bar{X}_n\\) converge quasi certamente a \\(\\mu\\), il che significa che, con probabilità 1, la media osservata si avvicina indefinitamente al valore teorico al crescere di \\(n\\).\n\nLegge Debole: La media campionaria \\(\\bar{X}_n\\) converge a \\(\\mu\\) in probabilità, ovvero, per ogni \\(\\varepsilon &gt; 0\\), la probabilità che la differenza tra \\(\\bar{X}_n\\) e \\(\\mu\\) superi \\(\\varepsilon\\) tende a zero al crescere di \\(n\\). Formalmente:\n\\[\n\\Pr\\bigl(| \\bar{X}_n - \\mu| &gt; \\varepsilon\\bigr) \\to 0 \\quad \\text{al crescere di }n.\n\\]\n\n\n\n33.6.1 Applicazioni in Psicologia\nIn psicologia, la Legge dei Grandi Numeri ha implicazioni significative. Ad esempio, se si vuole stimare con precisione la proporzione di individui che manifestano un determinato comportamento o la media di un test cognitivo in una popolazione, è necessario raccogliere un numero sufficiente di osservazioni. Solo con un campione ampio la media campionaria si avvicinerà alla media “vera” della popolazione, riducendo l’incertezza e migliorando l’affidabilità delle stime.\n\n33.6.2 Forma Debole della Legge dei Grandi Numeri\nLa forma debole della LGN, dimostrata per la prima volta da Jacob Bernoulli nel suo lavoro Ars Conjectandi, afferma che la media campionaria converge in probabilità alla media teorica (Hacking, 2006). In termini pratici, questo significa che, man mano che il numero di osservazioni aumenta, la probabilità che la differenza tra la media osservata e la media teorica superi un margine di errore \\(\\varepsilon\\) diventa sempre più piccola. Formalmente:\n\\[\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^n X_i - \\mu\\right| \\geq \\varepsilon\\right) = 0,\n\\]\ndove:\n\n\n\\(X_1, X_2, \\ldots, X_n\\) sono variabili casuali indipendenti e identicamente distribuite (i.i.d.),\n\n\\(\\mu\\) è la media teorica,\n\n\\(\\varepsilon\\) è un numero positivo arbitrariamente piccolo.\n\n33.6.3 Forma Forte della Legge dei Grandi Numeri\nLa forma forte della LGN, sviluppata successivamente da matematici come Kolmogorov, è un enunciato più potente. Essa stabilisce che la media campionaria converge quasi sicuramente alla media teorica. Questo implica che, con probabilità 1, la media osservata si avvicina indefinitamente al valore teorico man mano che il numero di prove tende all’infinito. Formalmente:\n\\[\nP\\left(\\lim_{{n \\to \\infty}} \\frac{1}{n} \\sum_{i=1}^n X_i = \\mu\\right) = 1.\n\\]\n\n33.6.4 Importanza e Critiche\nLa Legge dei Grandi Numeri è fondamentale per garantire la validità delle stime empiriche, ma la sua applicazione pratica richiede attenzione. Ad esempio, in psicologia, la raccolta di un numero sufficiente di osservazioni può essere costosa o difficile, specialmente quando si studiano fenomeni rari o popolazioni specifiche. Inoltre, l’assunzione di indipendenza e identica distribuzione delle osservazioni potrebbe non essere sempre realistica in contesti applicativi complessi. Nonostante queste sfide, la LGN rimane un principio essenziale per comprendere come i dati empirici possano avvicinarsi alle proprietà teoriche di una popolazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#teorema-del-limite-centrale",
    "href": "chapters/probability/10_sampling_distr.html#teorema-del-limite-centrale",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.7 Teorema del Limite Centrale",
    "text": "33.7 Teorema del Limite Centrale\nOltre alla convergenza, un ulteriore risultato importante è che la distribuzione di \\(\\bar{X}_n\\) si approssima alla normale man mano che \\(n\\) cresce, anche se i singoli \\(X_i\\) non sono distribuiti normalmente. Questo è il Teorema del Limite Centrale (TLC):\n\nEnunciato (informale)\nSe \\(X_1, X_2, \\ldots, X_n\\) sono variabili iid con media \\(\\mu\\) e deviazione standard \\(\\sigma\\), la distribuzione di \\[\n\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i\n\\] diventa approssimativamente normale con media \\(\\mu\\) e deviazione standard \\(\\tfrac{\\sigma}{\\sqrt{n}}\\) quando \\(n\\) è sufficientemente grande.\n\nPer il caso 0-1 (presenza/assenza di un tratto), \\(\\bar{X}\\) è quindi circa normale con media \\(p\\) e varianza \\(\\frac{p(1-p)}{n}\\). Il TLC consente, tra l’altro, di costruire intervalli di confidenza e di calcolare probabilità che la stima si discosti di una certa quantità dal vero valore.\n\nEsempio 33.1 Per visualizzare il Teorema del Limite Centrale (TLC) in azione, possiamo condurre una simulazione. Immaginiamo una popolazione distribuita in modo uniforme. Estraiamo 300 campioni di dimensione \\(n = 30\\) da questa popolazione e osserviamo come la distribuzione campionaria delle medie di questi campioni converga a una distribuzione normale. Questa simulazione fornirà un’illustrazione concreta dell’efficacia del TLC nell’approssimare distribuzioni reali.\n\n# Impostiamo il seed per la riproducibilità dei risultati\nset.seed(42)\n\n# Generiamo una popolazione con distribuzione uniforme\npopulation &lt;- runif(5000, min = 0, max = 1)\n\n# Passo 1: Visualizziamo l'istogramma della popolazione utilizzando ggplot2\nggplot(data.frame(population), aes(x = population)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30, fill = \"lightblue\", color = \"black\"\n  ) +\n  labs(title = \"Distribuzione della Popolazione\", x = \"Valore\", y = \"Densità\")\n\n\n\n\n\n\n\n\n# Passo 2 e 3: Estraiamo campioni casuali e calcoliamo le medie campionarie\nsample_size &lt;- 30\nnum_samples &lt;- 300\n\n# Vettore vuoto per memorizzare le medie campionarie\nsample_means &lt;- c()\n\nfor (i in 1:num_samples) {\n  # Estraiamo un campione casuale\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  \n  # Calcoliamo la media del campione\n  sample_means[i] &lt;- mean(sample)\n}\n\n# Calcoliamo media e varianza delle medie campionarie\nx_bar &lt;- mean(sample_means)\nstd &lt;- sd(sample_means)\n\nprint('Media e Varianza delle Medie Campionarie')\n#&gt; [1] \"Media e Varianza delle Medie Campionarie\"\nprint(x_bar)\n#&gt; [1] 0.501\nprint(std**2)\n#&gt; [1] 0.002745\n\n\n# Calcoliamo media e varianza della popolazione\nmu &lt;- mean(population)\nsigma &lt;- sd(population)\n\nprint('Media e Varianza della Popolazione')\n#&gt; [1] \"Media e Varianza della Popolazione\"\nprint(mu)\n#&gt; [1] 0.5032\nprint((sigma**2)/sample_size)\n#&gt; [1] 0.002824\n\n\n# Passo 4: Visualizziamo l'istogramma delle medie campionarie utilizzando ggplot2\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30, fill = \"lightgreen\", color = \"black\"\n  ) +\n  stat_function(\n    fun = dnorm, args = list(mean = x_bar, sd = std), color = \"black\", size = 1\n  ) +\n  labs(\n    title = \"Distribuzione delle Medie Campionarie\", x = \"Media Campionaria\", y = \"Densità\"\n  ) +\n  theme(legend.position = \"top\") \n\n\n\n\n\n\n\nSpiegazione del codice e dei risultati\n\nPopolazione: Abbiamo generato una popolazione di 5000 osservazioni distribuite uniformemente tra 0 e 1. La distribuzione uniforme è stata scelta perché è chiaramente non normale, il che rende più evidente l’effetto del TLC.\nCampionamento: Abbiamo estratto 300 campioni casuali, ciascuno di dimensione \\(n = 30\\), dalla popolazione. Per ogni campione, abbiamo calcolato la media.\nDistribuzione delle Medie Campionarie: Le medie dei campioni sono state raccolte e la loro distribuzione è stata visualizzata tramite un istogramma. Nonostante la popolazione originale non fosse normale, la distribuzione delle medie campionarie si avvicina a una distribuzione normale, dimostrando il TLC.\nConfronto tra Popolazione e Campioni: Abbiamo confrontato la media e la varianza della popolazione con quelle delle medie campionarie. Come previsto dal TLC, la media delle medie campionarie è molto vicina alla media della popolazione, mentre la varianza delle medie campionarie è ridotta di un fattore pari alla dimensione del campione (\\(n = 30\\)).\n\nQuesta simulazione illustra chiaramente come il TLC permetta di approssimare la distribuzione delle medie campionarie a una distribuzione normale, anche quando la popolazione originale non è normale. Questo risultato è fondamentale per molte applicazioni pratiche della statistica inferenziale.\n\n\nEsempio 33.2 Sebbene i risultati teorici siano solidi, è comune utilizzare la simulazione Monte Carlo per verificarne la validità in contesti pratici. Supponiamo, ad esempio, che la proporzione reale di individui che soffrono di un certo sintomo in una popolazione sia \\(p = 0.45\\). Possiamo simulare campioni di dimensione \\(n\\) e calcolare la media campionaria \\(\\bar{X}\\) (ovvero la proporzione osservata in ciascun campione). Ripetendo questo processo molte volte, otteniamo una distribuzione empirica delle \\(\\bar{X}\\). Se l’approssimazione normale fornita dal Teorema del Limite Centrale (TLC) è valida, ci aspettiamo che:\n\nLa media delle \\(\\bar{X}\\) sia molto vicina al valore teorico \\(p = 0.45\\).\nLa varianza delle \\(\\bar{X}\\) sia approssimativamente uguale a \\(p(1-p)/n\\), come previsto dalla teoria.\n\nUn esempio di codice in R per questa simulazione è il seguente:\n\np &lt;- 0.45  # Proporzione reale nella popolazione\nn &lt;- 1000  # Dimensione del campione\nB &lt;- 10000 # Numero di campioni simulati\n\n# Simulazione Monte Carlo: generiamo B campioni e calcoliamo le medie campionarie\nx_hat &lt;- replicate(B, {\n  x &lt;- sample(c(0, 1), size = n, replace = TRUE, prob = c(1-p, p))\n  mean(x)\n})\n\n# Media delle medie campionarie (dovrebbe essere vicina a p)\nmean(x_hat)  # Risultato atteso: ~ 0.45\n#&gt; [1] 0.4501\n\n# Deviazione standard delle medie campionarie (dovrebbe essere vicina a sqrt(p*(1-p)/n))\nsd(x_hat)    # Risultato atteso: ~ sqrt(0.45 * 0.55 / 1000)\n#&gt; [1] 0.0157\n\nRisultati attesi e interpretazione:\n\n\nMedia delle medie campionarie: Il valore medio di x_hat dovrebbe essere molto vicino a \\(0.45\\), confermando che la media campionaria è uno stimatore non distorto della proporzione reale \\(p\\).\n\nDeviazione standard delle medie campionarie: La deviazione standard di x_hat dovrebbe avvicinarsi a \\(\\sqrt{0.45 \\times 0.55 / 1000} \\approx 0.0157\\), in linea con la formula teorica \\(\\sqrt{p(1-p)/n}\\). Questo valore rappresenta l’incertezza associata alla stima della proporzione.\n\nEffetto della dimensione del campione:\n\nAumentando la dimensione del campione \\(n\\), l’ampiezza della distribuzione delle medie campionarie (e quindi l’incertezza di \\(\\bar{X}\\)) diminuisce. Questo è coerente con la teoria, poiché la varianza delle medie campionarie è inversamente proporzionale a \\(n\\). In altre parole, campioni più grandi forniscono stime più precise del parametro della popolazione.\n\nQuesta simulazione dimostra concretamente come il Teorema del Limite Centrale garantisca che, anche per popolazioni non normali (come in questo caso, dove i dati sono binari), la distribuzione delle medie campionarie si avvicini a una distribuzione normale con media \\(p\\) e varianza \\(p(1-p)/n\\), purché \\(n\\) sia sufficientemente grande.\n\n\n33.7.1 Margine di errore e intervalli di confidenza\nSe \\(\\bar{X}\\) è approssimato da \\(\\mathcal{N}(p, \\frac{p(1-p)}{n})\\), allora \\[\nZ = \\frac{\\bar{X} - p}{\\sqrt{p(1-p)/n}}\n\\] segue (approssimativamente) la distribuzione normale standard \\(\\mathcal{N}(0,1)\\). In pratica, non conoscendo \\(p\\), possiamo sostituirlo con \\(\\bar{X}\\) nello stimatore di errore standard (\\(\\mathrm{plug\\text{-}in}\\)): \\[\n\\hat{\\mathrm{SE}}(\\bar{X}) = \\sqrt{\\frac{\\bar{X}(1-\\bar{X})}{n}}.\n\\] Spesso si costruisce un intervallo di confidenza approssimato al 95% come: \\[\n\\bar{X} \\,\\pm\\, 1.96 \\times \\hat{\\mathrm{SE}}(\\bar{X}),\n\\] dove 1.96 deriva dal fatto che circa il 95% della distribuzione normale standard sta nell’intervallo \\([-1.96,+1.96]\\). Questo intervallo rappresenta la fascia di incertezza attorno alla stima, che si restringe all’aumentare di \\(n\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#oltre-la-media-altre-distribuzioni-campionarie",
    "href": "chapters/probability/10_sampling_distr.html#oltre-la-media-altre-distribuzioni-campionarie",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.8 Oltre la Media: Altre Distribuzioni Campionarie",
    "text": "33.8 Oltre la Media: Altre Distribuzioni Campionarie\nFinora ci siamo concentrati sulla media campionaria (o proporzione), ma in molti casi di interesse psicologico o più in generale statistico, potremmo voler studiare altre statistiche tratte da un campione. Due esempi importanti sono il massimo campionario (utile per analisi di eventi estremi, punteggi massimi nei test, tempi di reazione record, ecc.) e la varianza campionaria (fondamentale per misurare la variabilità dei punteggi in un test psicometrico, ad esempio).\n\n33.8.1 Massimo campionario\nQuando siamo interessati a misurare la performance “estrema” di un gruppo (ad esempio il punteggio più elevato in un test cognitivo, oppure la latenza di reazione più veloce se si ragiona in termini di minimi), la statistica di riferimento è il massimo (o il minimo) nel campione.\n\n33.8.1.1 Teoria e concetti chiave\n\nDefinizione: Dato un campione \\(\\{X_1, X_2, \\dots, X_n\\}\\), il massimo campionario è \\[\nM = \\max\\{X_1, X_2, \\dots, X_n\\}.\n\\] Questa variabile casuale dipende ovviamente dalla distribuzione dei singoli \\(X_i\\).\n\nProprietà:\n\nLa distribuzione di \\(M\\) spesso risulta asimmetrica e “spostata a destra” rispetto alla distribuzione di partenza. Anche se la popolazione originaria fosse normalmente distribuita, la distribuzione del massimo non sarà normale.\n\nIl valore atteso \\(E[M]\\) supera la media \\(\\mu\\) della popolazione perché, fra i \\(n\\) individui osservati, “vince” sempre il più grande.\n\n\n\nImplicazioni pratiche:\n\nAnalizzare i massimi (o i minimi) è cruciale nello studio di fenomeni estremi (per esempio, individuare il picco di stress in un compito cognitivo o la più alta temperatura registrata in una sperimentazione ambientale).\nLa cosiddetta teoria degli estremi si fonda proprio sull’analisi di come i massimi (o minimi) si distribuiscono al crescere di \\(n\\). Questa ha applicazioni in diverse discipline: dalla psicologia (prestazione massima) all’ingegneria (carichi estremi) fino alla finanza (rischi estremi).\n\n\n\n\nEsempio 33.3 Nel seguente esempio, simuliamo 10.000 esperimenti. In ognuno:\n\nGeneriamo 5 osservazioni da una popolazione normale con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\).\n\nNe calcoliamo il massimo campionario.\n\nInfine, confrontiamo la distribuzione di questi massimi con la densità della distribuzione di partenza (cioè la normale \\(\\mathcal{N}(100, 15^2)\\)).\n\n# Impostazioni iniziali\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulazione di 10.000 esperimenti con campioni di 5 osservazioni\nset.seed(123)  # Per riproducibilità\nsample_maxes &lt;- replicate(10000, max(rnorm(5, mean = mu, sd = sigma)))\n\n# Creiamo un data frame per il grafico\ndata &lt;- data.frame(SampleMaxes = sample_maxes)\ndensity_data &lt;- data.frame(x = x, y = y)\n\n# Grafico con ggplot2\nggplot(data, aes(x = SampleMaxes)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30,\n    fill = \"lightblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n  geom_line(data = density_data, aes(x = x, y = y), size = 1, color = \"red\") +\n  labs(\n    title = \"Distribuzione dei massimi campionari\",\n    subtitle = \"Confronto con la distribuzione originale\",\n    x = \"Massimo campionario\",\n    y = \"Densità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\nOsservazioni:\n\nL’istogramma, che rappresenta la distribuzione dei massimi campionari, è spostato a destra rispetto alla distribuzione della popolazione (tracciata in rosso).\nCiò evidenzia che \\(M\\) tende a fornire valori più alti della media \\(\\mu = 100\\). Se ripetessimo l’esperimento con campioni di dimensione maggiore di 5, questo effetto si accentuerebbe ulteriormente.\n\n\n\n33.8.2 2. Varianza campionaria\nLo studio della varianza (o in generale della variabilità) è un altro esempio cruciale in contesti psicologici. Se vogliamo descrivere quanto differiscono i punteggi di un test di personalità, o di un test cognitivo, non basta guardare solo alla media campionaria: ci interessa anche la dispersione.\n\n33.8.2.1 Teoria e concetti chiave\n\nStima della varianza:\nStimare la varianza \\(\\sigma^2\\) di una popolazione non è banale. La formula \\[\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (Y_i - \\bar{Y})^2\n\\] tende a sottostimare \\(\\sigma^2\\). Per ottenere uno stimatore non distorto, si usa invece: \\[\nS^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\] L’uso di \\(n-1\\) serve a correggere la perdita di un grado di libertà (poiché \\(\\bar{Y}\\) è calcolata sui dati) e garantisce che \\(E[S^2] = \\sigma^2\\).\nConcetto di distorsione:\nChiamiamo uno stimatore \\(\\hat{\\theta}\\) non distorto se il suo valore atteso è uguale al parametro vero \\(\\theta\\): \\(E[\\hat{\\theta}] = \\theta\\). Con la formula a denominatore \\(n-1\\), la varianza campionaria risulta appunto non distorta.\n\n\nEsempio 33.4 Simuliamo 10.000 esperimenti, ognuno con \\(n=5\\) osservazioni generate da \\(\\mathcal{N}(100, 15^2)\\). Per ciascun campione, calcoliamo: 1. La varianza “distorta” \\(\\frac{1}{n}\\sum_i (X_i - \\bar{X})^2\\). 2. La varianza “corretta” con \\(n-1\\).\n\nset.seed(123)  # Per riproducibilità\n\n# Funzione per calcolare varianze con n e con n-1\ncalc_vars &lt;- function(n = 5, mu = 100, sigma = 15) {\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  var_n &lt;- sum((sample_data - mean(sample_data))^2) / n\n  var_n_minus_1 &lt;- var(sample_data)  # In R, var() usa di default n-1\n  c(var_n, var_n_minus_1)\n}\n\n# Simuliamo 10.000 campioni\nB &lt;- 10000\nvars_matrix &lt;- replicate(B, calc_vars())\nsample_vars_n &lt;- vars_matrix[1, ]\nsample_vars_n_minus_1 &lt;- vars_matrix[2, ]\n\n# Confrontiamo graficamente\ndata_n &lt;- data.frame(SampleVars = sample_vars_n, Type = \"Con n\")\ndata_n_minus_1 &lt;- data.frame(SampleVars = sample_vars_n_minus_1, Type = \"Con n-1\")\ncombined_data &lt;- rbind(data_n, data_n_minus_1)\n\nggplot(combined_data, aes(x = SampleVars, color = Type)) +\n  geom_density(size = 1.1) +\n  labs(\n    title = \"Distribuzione delle varianze campionarie\",\n    subtitle = \"Confronto: denominatore n vs. n-1\",\n    x = \"Varianza campionaria\",\n    y = \"Densità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  ) +\n  scale_color_manual(values = c(\"Con n\" = \"lightblue\", \"Con n-1\" = \"lightgreen\"))\n\n\n\n\n\n\n\nOsservazioni:\n\nLa curva corrispondente a “Con \\(n\\)” tende a sottostimare la varianza, mentre quella “Con \\(n-1\\)” si centra meglio attorno a \\(\\sigma^2 = 15^2 = 225\\).\n\nSe verifichiamo le medie delle due distribuzioni:\n\nmean(sample_vars_n)\n#&gt; [1] 180.7\nmean(sample_vars_n_minus_1)\n#&gt; [1] 225.8\n\ntroveremo che la prima è sensibilmente inferiore a 225, mentre la seconda si avvicina di più al valore vero.\n\n\n\nSia il massimo campionario sia la varianza campionaria dimostrano come non tutte le distribuzioni campionarie ereditino le stesse proprietà della media. Nel caso del massimo, la variabile risulta spostata verso valori elevati e non segue una forma gaussiana; nel caso della varianza, si deve porre attenzione alla formula usata, per evitare distorsioni sistematiche.\nIn sintesi:\n\n\nMassimo campionario: utile per l’analisi di fenomeni estremi (o massimi prestazionali), con una distribuzione tipicamente asimmetrica.\n\n\nVarianza campionaria: richiede la correzione di Bessel (denominatore \\(n-1\\)) per essere uno stimatore non distorto di \\(\\sigma^2\\).\n\nCapire le proprietà di queste (e altre) distribuzioni campionarie consente allo sperimentatore di valutare correttamente le incertezze nelle stime, di evitare errori di interpretazione e di utilizzare gli stimatori più appropriati in base al tipo di fenomeno studiato.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#errore-standard-incertezza-inferenziale-e-bias",
    "href": "chapters/probability/10_sampling_distr.html#errore-standard-incertezza-inferenziale-e-bias",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.9 Errore standard, incertezza inferenziale e bias",
    "text": "33.9 Errore standard, incertezza inferenziale e bias\n\n33.9.1 Errore standard e incertezza\nL’errore standard (SE) è la misura di quanto una data statistica (ad esempio la media) può variare da un campione all’altro per pura casualità di campionamento. In un contesto psicologico, può essere usato per mostrare graficamente l’affidabilità di una misura. Esporre i risultati di un test psicometrico riportando solo la media, senza un’idea dell’errore standard o di un intervallo di confidenza, rischia di dare un’illusione di precisione non giustificata.\n\n33.9.2 Bias: perché non basta un campione grandissimo\nAumentare la dimensione campionaria \\(n\\) riduce l’errore standard, ma non elimina possibili bias sistematici (si veda, ad esempio, la disussione fornita dal Andrew Gelman su questo tema). Ad esempio:\n\nSe i partecipanti più ansiosi evitano di partecipare allo studio (bias di selezione), la proporzione \\(\\bar{X}\\) sarà sistematicamente sottostimata.\nSe qualcuno falsifica le risposte per desiderabilità sociale (bias di risposta), la media misurata può allontanarsi dal valore vero in maniera non corretta da un semplice aumento del campione.\nSe lo strumento di misura (ad es. un questionario) è mal tarato o concettualmente scorretto, l’intero studio può soffrirne (misurazione errata).\n\nQuando è presente un bias, nessun aumento del numero di partecipanti potrà rimuoverlo: si otterranno stime molto “precise” (varianza piccola) ma sistematicamente lontane dal valore reale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/10_sampling_distr.html#riflessioni-conclusive",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.10 Riflessioni Conclusive",
    "text": "33.10 Riflessioni Conclusive\nQuesto percorso illustra come, in un contesto frequentista, sia essenziale distinguere fra:\n\n\nPopolazione e parametro (ad es. la vera proporzione di un sintomo psicologico, o la vera media di un punteggio): entità teoriche che non osserviamo direttamente.\n\nCampione e stima (il dato empirico raccolto su un campione, e il calcolo – ad esempio la media – derivato dal campione).\n\nLa distribuzione campionaria di una statistica, specialmente la media o la proporzione, rivela:\n\nChe la media campionaria è uno stimatore non distorto (il suo valore atteso coincide con quello della popolazione).\nChe la sua precisione (cioè \\(\\frac{1}{\\mathrm{Var}(\\bar{X})}\\)) aumenta con la dimensione del campione.\nChe il Teorema del Limite Centrale garantisce un’approssimazione normale per \\(\\bar{X}\\) se \\(n\\) è sufficientemente ampio, consentendo di costruire intervalli di confidenza e valutare probabilisticamente le stime.\nChe l’errore standard (SE) descrive la variabilità dovuta al campionamento, mentre i bias sistematici non vengono rimossi aumentando \\(n\\).\n\nIn sostanza, chi effettua ricerche in psicologia – come in qualunque altra disciplina – deve considerare sia l’incertezza intrinseca (errore casuale di campionamento) sia l’eventuale presenza di bias strutturali. Solo in questo modo si possono interpretare in modo appropriato i risultati delle analisi e valutare correttamente la credibilità delle conclusioni sui processi psicologici o sui fenomeni clinici d’interesse.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/10_sampling_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "33  Stime, stimatori e parametri",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#bibliografia",
    "href": "chapters/probability/10_sampling_distr.html#bibliografia",
    "title": "33  Stime, stimatori e parametri",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html",
    "href": "chapters/probability/11_joint_prob.html",
    "title": "34  Probabilità congiunta",
    "section": "",
    "text": "34.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo ci proponiamo di analizzare in dettaglio il concetto di probabilità congiunta, focalizzando l’attenzione sul caso di variabili aleatorie discrete. La probabilità congiunta rappresenta la misura della probabilità che due o più eventi si verifichino simultaneamente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#funzione-di-probabilità-congiunta",
    "href": "chapters/probability/11_joint_prob.html#funzione-di-probabilità-congiunta",
    "title": "34  Probabilità congiunta",
    "section": "\n34.2 Funzione di Probabilità Congiunta",
    "text": "34.2 Funzione di Probabilità Congiunta\nFinora ci siamo concentrati sulla probabilità associata a un singolo evento o, più precisamente, a un singolo valore assunto da una variabile aleatoria. Tuttavia, in molti contesti, siamo interessati a studiare la relazione tra due o più eventi o variabili aleatorie. La funzione di probabilità congiunta ci permette di estendere il concetto di probabilità al caso di più variabili aleatorie, descrivendo la probabilità che queste assumano specifici valori contemporaneamente.\nSpesso, un esperimento aleatorio è descritto attraverso più di una variabile aleatoria. Ecco alcuni esempi:\n\nAltezze di un gruppo di persone: Supponiamo di selezionare casualmente \\(n = 10\\) persone e di osservare le loro altezze. Siano \\(X_1, X_2, \\dots, X_n\\) le altezze individuali. In questo caso, siamo interessati a capire come le altezze dei singoli individui si relazionano tra loro.\nLancio ripetuto di una moneta: Consideriamo un esperimento in cui lanciamo una moneta più volte. Definiamo \\(X_i = 1\\) se l’\\(i\\)-esimo lancio risulta in “testa” e \\(X_i = 0\\) altrimenti. L’esperimento è quindi descritto da una sequenza di variabili aleatorie di Bernoulli \\(X_1, X_2, \\dots\\). Qui, potremmo voler studiare la probabilità che si verifichino determinate sequenze di risultati.\nPeso e altezza di una persona: Selezioniamo casualmente una persona da una grande popolazione e misuriamo il suo peso \\(X\\) e la sua altezza \\(Y\\). In questo caso, siamo interessati a capire come peso e altezza sono correlati, ad esempio, se persone più alte tendono a pesare di più.\n\nPer descrivere il comportamento delle variabili aleatorie in questi esperimenti, non è sufficiente specificare la funzione di densità di probabilità (PDF) o la funzione di massa di probabilità (PMF) delle singole variabili. È necessario anche considerare l’interazione tra le variabili aleatorie. Ad esempio:\n\nNel terzo esperimento (peso e altezza), se l’altezza \\(Y\\) è grande, è probabile che anche il peso \\(X\\) sia grande. Questo suggerisce una dipendenza tra le due variabili.\nNei primi due esperimenti, invece, è ragionevole assumere che le variabili aleatorie siano indipendenti: conoscere il valore di una variabile non fornisce informazioni aggiuntive sulle altre.\n\nPer catturare queste relazioni, abbiamo bisogno di specificare la distribuzione congiunta delle variabili aleatorie. La distribuzione congiunta descrive la probabilità che le variabili assumano specifici valori simultaneamente. Ad esempio:\n\nNel caso discreto, la funzione di massa di probabilità congiunta \\(p(x, y)\\) fornisce la probabilità che \\(X = x\\) e \\(Y = y\\) contemporaneamente.\nNel caso continuo, la funzione di densità di probabilità congiunta \\(f(x, y)\\) descrive la densità di probabilità associata ai valori \\(X = x\\) e \\(Y = y\\).\n\nConsideriamo un esempio psicologico: supponiamo di voler studiare la relazione tra il punteggio \\(X\\) ottenuto in un test cognitivo e il livello di ansia \\(Y\\) riportato da un gruppo di partecipanti. La distribuzione congiunta di \\(X\\) e \\(Y\\) ci permette di rispondere a domande come:\n\nQual è la probabilità che un partecipante con un alto livello di ansia ottenga un punteggio basso nel test cognitivo?\nEsiste una relazione tra ansia e prestazione cognitiva, e se sì, come possiamo quantificarla?\n\nIn questo contesto, la distribuzione congiunta ci aiuta a modellare la relazione tra due variabili psicologiche, fornendo una base per analisi più approfondite, come lo studio della correlazione o della dipendenza tra di esse.\nIn sintesi, la funzione di probabilità congiunta è uno strumento essenziale per analizzare la relazione tra due o più variabili aleatorie. Che si tratti di altezze e pesi, risultati di lanci di monete, o variabili psicologiche come ansia e prestazione cognitiva, la distribuzione congiunta ci permette di comprendere come queste variabili interagiscono e influenzano reciprocamente i loro valori.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#distribuzione-congiunta",
    "href": "chapters/probability/11_joint_prob.html#distribuzione-congiunta",
    "title": "34  Probabilità congiunta",
    "section": "\n34.3 Distribuzione Congiunta",
    "text": "34.3 Distribuzione Congiunta\n\nDefinizione 34.1 (Definizione: Distribuzione Congiunta) La distribuzione congiunta di due variabili aleatorie \\(X\\) e \\(Y\\) descrive la probabilità che \\(X\\) e \\(Y\\) assumano specifici valori simultaneamente. Nel caso discreto, è rappresentata dalla funzione di massa di probabilità congiunta \\(p(x, y)\\), mentre nel caso continuo dalla funzione di densità di probabilità congiunta \\(f(x, y)\\).\n\n\n34.3.1 Proprietà della Distribuzione Congiunta\nUna distribuzione di probabilità congiunta deve soddisfare le seguenti proprietà:\n\nNon negatività:\nPer ogni coppia di valori \\((x_i, y_j)\\), la probabilità congiunta è compresa tra 0 e 1: \\[\n0 \\leq P(x_i, y_j) \\leq 1.\n\\]\nNormalizzazione:\nLa somma delle probabilità congiunte su tutte le possibili coppie \\((x_i, y_j)\\) deve essere uguale a 1: \\[\n\\sum_{i} \\sum_{j} P(x_i, y_j) = 1.\n\\]\n\n34.3.2 Calcolo della Probabilità di Eventi Specifici\nData la distribuzione di probabilità congiunta, è possibile determinare la probabilità di eventi definiti in termini delle variabili aleatorie \\(X\\) e \\(Y\\). Ad esempio, per calcolare la probabilità che \\(X + Y \\leq 1\\), si sommano le probabilità di tutte le coppie \\((x, y)\\) che soddisfano questa condizione.\nIn conclusione, la distribuzione congiunta è uno strumento fondamentale per analizzare la relazione tra due o più variabili aleatorie. Attraverso di essa, possiamo calcolare probabilità di eventi complessi e comprendere come le variabili interagiscono tra loro.\n\nEsempio 34.1 Supponiamo di avere la seguente distribuzione congiunta discreta per \\(X\\) e \\(Y\\):\n\n\n\n\\(Y = 0\\)\n\\(Y = 1\\)\n\\(Y = 2\\)\n\n\n\n\\(X = 0\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{1}{8}\\)\n\n\n\\(X = 1\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{1}{8}\\)\n\n\n\\(X = 2\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{1}{8}\\)\n\\(0\\)\n\n\n\nPer calcolare \\(P(X + Y \\leq 1)\\), identifichiamo le coppie \\((x, y)\\) che soddisfano \\(x + y \\leq 1\\):\n\n\n\\((0, 0)\\),\n\n\\((0, 1)\\),\n\n\\((1, 0)\\).\n\nLa probabilità è quindi: \\[\nP(X + Y \\leq 1) = P(0, 0) + P(0, 1) + P(1, 0) = \\frac{1}{8} + \\frac{1}{8} + \\frac{1}{8} = \\frac{3}{8}.\n\\]\n\n\nEsempio 34.2 Per comprendere meglio il concetto di probabilità congiunta, immaginiamo di lanciare tre monete. Tutti i possibili risultati di questo esperimento (ad esempio, tre teste, due teste e una croce, ecc.) costituiscono quello che chiamiamo spazio campionario. In questo caso, lo spazio campionario \\(\\Omega\\) è dato da:\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\},\n\\]\ndove \\(T\\) indica “testa” e \\(C\\) indica “croce”. Assumendo che ogni lancio sia indipendente dagli altri, ogni risultato nello spazio campionario \\(\\Omega\\) ha la stessa probabilità di verificarsi, ovvero \\(1/8\\).\nDefiniamo ora le seguenti variabili casuali sullo spazio campionario \\(\\Omega\\):\n\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) rappresenta il numero totale di teste ottenute nei tre lanci.\n\n\\(Y \\in \\{0, 1\\}\\) indica se il primo lancio ha dato testa (\\(1\\)) oppure croce (\\(0\\)).\n\nLa tabella seguente mostra lo spazio campionario con i valori di \\(X\\) e \\(Y\\) associati a ciascun esito, insieme alla probabilità di ciascun evento \\(\\omega\\):\n\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\nOra possiamo determinare la probabilità congiunta per ogni coppia \\((X, Y)\\), che rappresenta la probabilità di ottenere un determinato numero di teste \\(X\\) e un determinato risultato per il primo lancio \\(Y\\). Ad esempio:\n\\[P(X=0, Y=0) = P(\\text{CCC}) = 1/8,\\]\ne così via per le altre coppie.\nLe probabilità congiunte per tutte le possibili combinazioni \\((X, Y)\\) sono calcolate come segue:\n\\[\n\\begin{aligned}\nP(X = 0, Y = 0) &= 1/8, \\\\\nP(X = 1, Y = 0) &= P(\\text{CCT}) + P(\\text{CTC}) = 1/4, \\\\\nP(X = 1, Y = 1) &= P(\\text{TCC}) = 1/8, \\\\\nP(X = 2, Y = 0) &= P(\\text{CTT}) = 1/8, \\\\\nP(X = 2, Y = 1) &= P(\\text{TTC}) + P(\\text{TCT}) = 1/4, \\\\\nP(X = 3, Y = 1) &= P(\\text{TTT}) = 1/8.\n\\end{aligned}\n\\]\nQueste probabilità costituiscono la distribuzione di probabilità congiunta delle variabili casuali \\(X\\) (numero di teste) e \\(Y\\) (testa al primo lancio). Questa distribuzione fornisce un quadro completo delle probabilità per tutte le combinazioni di risultati di queste due variabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#marginalizzazione",
    "href": "chapters/probability/11_joint_prob.html#marginalizzazione",
    "title": "34  Probabilità congiunta",
    "section": "\n34.4 Marginalizzazione",
    "text": "34.4 Marginalizzazione\nImmagina di condurre uno studio sul livello di stress tra studenti universitari, raccogliendo dati su variabili come l’anno di corso, il genere, il supporto sociale e il livello di stress. Se desideri comprendere come il livello di stress varia in funzione dell’anno di corso, indipendentemente dal genere e dal supporto sociale, puoi utilizzare la marginalizzazione.\nLa marginalizzazione consente di ottenere una distribuzione di probabilità focalizzata su una o più variabili di interesse, “eliminando” dal calcolo le variabili non rilevanti. Nel nostro esempio, per ottenere la distribuzione marginale del livello di stress rispetto all’anno di corso, occorre sommare (o integrare, nel caso di variabili continue) le probabilità associate a tutte le combinazioni di genere e supporto sociale, mantenendo fisso l’anno di corso. In questo modo, otteniamo una distribuzione che descrive come il livello di stress varia solo in relazione all’anno di corso.\nIl termine “marginalizzazione” deriva dalle tabelle di contingenza: quando rappresentiamo una distribuzione di probabilità congiunta in una tabella, le probabilità marginali—che descrivono la distribuzione di una variabile indipendentemente dalle altre—si trovano nei margini della tabella (ovvero nelle righe e colonne finali).\n\n34.4.1 Formalizzazione della Marginalizzazione\nData una distribuzione di probabilità congiunta \\(P(X, Y)\\) di due variabili casuali \\(X\\) e \\(Y\\), possiamo ottenere la distribuzione marginale di \\(X\\) sommando tutte le probabilità associate a \\(Y\\). Formalmente:\n\\[\nP(X = x) = \\sum_y P(X = x, Y = y),\n\\]\ndove \\(P(X = x, Y = y)\\) rappresenta la probabilità congiunta di \\(X\\) e \\(Y\\). La marginalizzazione garantisce inoltre che le distribuzioni siano normalizzate, cioè che le somme delle probabilità marginali per ciascuna variabile siano uguali a 1:\n\\[\n\\sum_x P(X = x) = 1 \\quad \\text{e} \\quad \\sum_y P(Y = y) = 1.\n\\]\nNel caso di variabili continue, questa operazione di somma viene sostituita dall’integrazione.\nPer chiarire, consideriamo il seguente esempio. Supponiamo di studiare l’efficacia di una terapia cognitivo-comportamentale per l’ansia, includendo variabili come l’età dei partecipanti e il livello iniziale di ansia. Se vogliamo valutare l’efficacia della terapia a prescindere dall’età e dal livello di ansia iniziale, marginalizziamo rispetto a queste due variabili, ottenendo così una distribuzione che riflette solo l’associazione tra terapia e riduzione dell’ansia.\nIn sintesi, la marginalizzazione:\n\npermette di estrarre distribuzioni di probabilità per variabili specifiche, “dimenticando” quelle non rilevanti;\nconsiste nel sommare o integrare le probabilità attraverso tutte le possibili combinazioni delle variabili non rilevanti, concentrandosi su quelle di interesse.\n\nIn conclusione, la marginalizzazione è uno strumento essenziale per l’analisi statistica, facilitando lo studio delle relazioni tra variabili complesse e aiutandoci a isolare gli effetti delle variabili di interesse in modo rigoroso.\n\nEsempio 34.3 Per fare un esempio, prendiamo come riferimento l’esperimento del lancio di tre monete equilibrate descritto precedentemente. Per calcolare le probabilità marginali di \\(X\\) e \\(Y\\), sommiamo le probabilità congiunte su una dimensione. La probabilità marginale di \\(X\\), \\(P_X\\), si ottiene sommando le probabilità lungo le colonne per ciascun valore fisso di \\(X\\); analogamente, la probabilità marginale di \\(Y\\), \\(P_Y\\), si calcola sommando le probabilità lungo le righe per ciascun valore fisso di \\(Y\\).\nLa tabella seguente mostra la distribuzione di probabilità congiunta \\(P(X, Y)\\) e le probabilità marginali \\(P(X)\\) e \\(P(Y)\\):\n\n\n\\(x \\setminus y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0\n\n\n\n\n\n34.4.2 Marginalizzazione per Variabili Casuali Continue\nNell’ambito della statistica bayesiana, il concetto di marginalizzazione gioca un ruolo cruciale. Un esempio di equazione che emerge da questo processo è:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) \\, d\\theta = \\int_{\\theta} p(y \\mid \\theta) p(\\theta) \\, d\\theta,\n\\]\ndove \\(y\\) e \\(\\theta\\) sono variabili casuali continue, con \\(y\\) che rappresenta i dati osservati e \\(\\theta\\) i parametri di un modello statistico. Questa equazione illustra come, in un contesto continuo, la marginalizzazione possa essere vista come l’estensione dell’approccio discreto a un continuum di valori per le variabili in esame.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#indipendenza-tra-variabili-casuali",
    "href": "chapters/probability/11_joint_prob.html#indipendenza-tra-variabili-casuali",
    "title": "34  Probabilità congiunta",
    "section": "\n34.5 Indipendenza tra Variabili Casuali",
    "text": "34.5 Indipendenza tra Variabili Casuali\nL’indipendenza tra variabili casuali è un concetto fondamentale in statistica e probabilità, parallelo all’idea di indipendenza tra eventi. Due variabili casuali si considerano indipendenti quando l’informazione su una non altera in alcun modo la distribuzione di probabilità dell’altra. Questa sezione offre una formalizzazione dell’indipendenza tra due variabili casuali discrete, basata sulla loro distribuzione di probabilità congiunta.\n\n34.5.1 Definizione di Indipendenza\nDue variabili casuali \\(X\\) e \\(Y\\), con una distribuzione congiunta, sono definite indipendenti se, e solo se, per ogni coppia di valori \\((x, y)\\) si verifica che:\n\\[\nP_{X, Y}(x, y) = P_X(x) \\cdot P_Y(y).\n\\]\nIn termini pratici, ciò significa che se \\(X\\) e \\(Y\\) sono variabili casuali discrete indipendenti, la loro distribuzione di probabilità congiunta è il prodotto delle rispettive distribuzioni di probabilità marginali. Se invece \\(P_{X, Y}(x, y) \\neq P_X(x) \\cdot P_Y(y)\\), le variabili non sono indipendenti e si dicono associate o dipendenti.\nQuesto concetto si applica anche alle variabili casuali continue, mantenendo la stessa logica: l’indipendenza si verifica quando la funzione di densità congiunta è il prodotto delle funzioni di densità marginali.\n\n34.5.2 Associazione tra Variabili Casuali\nQuando due variabili casuali non sono indipendenti, si descrivono come associate o dipendenti. In questo contesto, è utile introdurre il concetto di covarianza (e correlazione) come misura del grado di associazione lineare tra due variabili casuali. La covarianza e la correlazione quantificano in che modo la variazione di una variabile è associata alla variazione dell’altra, fornendo un indice della loro interdipendenza lineare.\nRiepilogando, l’indipendenza tra variabili casuali è un concetto chiave per comprendere le relazioni tra fenomeni aleatori. Riconoscere se due variabili sono indipendenti o associate è fondamentale per l’analisi statistica e per la modellazione di relazioni causali o di correlazione tra variabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#covarianza",
    "href": "chapters/probability/11_joint_prob.html#covarianza",
    "title": "34  Probabilità congiunta",
    "section": "\n34.6 Covarianza",
    "text": "34.6 Covarianza\nLa covarianza è un parametro statistico che quantifica il grado e la direzione della relazione lineare tra due variabili casuali, \\(X\\) e \\(Y\\). In termini semplici, misura come le variazioni di una variabile si accompagnano a quelle dell’altra. Per esempio, considerando l’altezza e il peso di giraffe, scopriremmo che queste due misure tendono ad aumentare insieme, evidenziando così una covarianza positiva. La covarianza è denotata come \\(Cov(X, Y) = \\sigma_{xy}\\).\n\n34.6.1 Definizione di Covarianza\n\nDefinizione 34.2 La covarianza tra due variabili casuali \\(X\\) e \\(Y\\) è definita come:\n\\[\nCov(X, Y) = \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right],\n\\]\ndove \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) rappresentano i valori attesi (o medie) di \\(X\\) ed \\(Y\\), rispettivamente.\n\nIn termini più espliciti, la covarianza può essere espressa come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y),\n\\]\ndove \\(\\mu_X\\) e \\(\\mu_Y\\) sono le medie di \\(X\\) ed \\(Y\\), e \\(f(x, y)\\) è la funzione di probabilità congiunta delle variabili.\nQuesta definizione mostra una stretta analogia con la varianza, che è la covarianza di una variabile con se stessa:\n\\[\n\\mathbb{V}(X) = Cov(X, X).\n\\]\nInoltre, la covarianza può essere calcolata attraverso la relazione:\n\\[\nCov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\]\n\n34.6.2 Dimostrazione\nLa formula alternativa per la covarianza si dimostra come segue:\n\\[\n\\begin{align}\nCov(X, Y) &= \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right]\\\\\n&= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\end{align}\n\\]\n\nEsempio 34.4 Consideriamo le variabili casuali \\(X\\) e \\(Y\\) con medie \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). La covarianza di \\(X\\) e \\(Y\\) si calcola come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y) = \\frac{1}{4}.\n\\]\nQuesto risultato si può ottenere anche dalla formula alternativa, calcolando prima \\(\\mathbb{E}(XY)\\):\n\\[\n\\mathbb{E}(XY) = 1.0.\n\\]\nAllora, la covarianza tra \\(X\\) e \\(Y\\) è:\n\\[\nCov(X, Y) = 1 - 1.5 \\cdot 0.5 = 0.25.\n\\]\n\n\nEsempio 34.5 Per calcolare la covarianza \\(Cov(X, Y)\\) in R, consideriamo l’esempio in cui \\(X\\) è il numero totale di teste che si ottiene dal lancio di tre monete equilibrate e \\(Y\\) è il risultato del primo lancio (testa = 1, croce = 0). Procediamo creando il prodotto cartesiano di tutti i possibili valori di \\(X\\) e \\(Y\\).\n\n# Creare il prodotto cartesiano di X (c3) e Y (c1)\nc3 &lt;- 0:3  # Numero totale di teste possibili\nc1 &lt;- 0:1  # Risultato del primo lancio (0 = croce, 1 = testa)\nsample &lt;- expand.grid(c1 = c1, c3 = c3)\nsample\n#&gt;   c1 c3\n#&gt; 1  0  0\n#&gt; 2  1  0\n#&gt; 3  0  1\n#&gt; 4  1  1\n#&gt; 5  0  2\n#&gt; 6  1  2\n#&gt; 7  0  3\n#&gt; 8  1  3\n\nIl primo numero di ogni coppia rappresenta il valore di \\(Y\\), mentre il secondo rappresenta il valore di \\(X\\). Tuttavia, queste coppie \\((X, Y)\\) non hanno tutte la stessa probabilità di verificarsi. La probabilità associata a ciascuna coppia è data dai seguenti valori: \\(1/8, 2/8, 1/8, 0, 0, 1/8, 2/8, 1/8\\). Questa è la distribuzione di massa di probabilità congiunta delle variabili casuali \\(X\\) e \\(Y\\). Applicando la formula per la covarianza:\n\\[\nCov(X, Y) = \\sum_{i=1}^n (X_i - E[X])(Y_i - E[Y]) P(X_i, Y_i)\n\\]\nCalcoliamo la covarianza in R:\n\n# Probabilità di ogni coppia (X, Y)\npmf &lt;- c(1 / 8, 2 / 8, 1 / 8, 0, 0, 1 / 8, 2 / 8, 1 / 8)\n\n# Calcolo della covarianza\nres &lt;- c()\nfor (i in 1:nrow(sample)) {\n  res &lt;- c(res, (sample$c1[i] - 0.5) * (sample$c3[i] - 1.5) * pmf[i])\n}\n\n# Somma dei prodotti ponderati\ncovariance &lt;- sum(res)\ncovariance\n#&gt; [1] -0.125\n\nLa covarianza tra \\(X\\) e \\(Y\\) è dunque uguale a \\(-0.125\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#correlazione",
    "href": "chapters/probability/11_joint_prob.html#correlazione",
    "title": "34  Probabilità congiunta",
    "section": "\n34.7 Correlazione",
    "text": "34.7 Correlazione\nMentre la covarianza fornisce un’indicazione della tendenza di due variabili casuali a variare insieme, essa è influenzata dalle unità di misura delle variabili, rendendo difficile valutare l’intensità della loro relazione lineare. Per ovviare a questo, si utilizza la correlazione, che normalizza la covarianza attraverso le deviazioni standard delle variabili, offrendo così una misura standardizzata dell’associazione lineare tra di esse.\n\nDefinizione 34.3 Il coefficiente di correlazione tra due variabili casuali \\(X\\) e \\(Y\\), denotato come \\(\\rho(X,Y)\\) o \\(\\rho_{X,Y}\\), è definito come:\n\\[\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{\\mathbb{V}(X)\\mathbb{V}(Y)}},\n\\]\ndove \\(\\mathbb{V}(X)\\) e \\(\\mathbb{V}(Y)\\) rappresentano le varianze di \\(X\\) e \\(Y\\), rispettivamente.\n\nIl coefficiente di correlazione \\(\\rho_{xy}\\) è un valore adimensionale, ovvero non dipende dalle unità di misura delle variabili, e varia nell’intervallo \\(-1 \\leq \\rho \\leq 1\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#proprietà",
    "href": "chapters/probability/11_joint_prob.html#proprietà",
    "title": "34  Probabilità congiunta",
    "section": "\n34.8 Proprietà",
    "text": "34.8 Proprietà\n\n\nCovarianza con una Costante: La covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) è sempre nulla: \\(Cov(c, X) = 0\\).\n\nSimmetria: La covarianza è simmetrica: \\(Cov(X,Y) = Cov(Y,X)\\).\n\nIntervallo di Correlazione: Il coefficiente di correlazione \\(\\rho\\) varia tra -1 e 1: \\(-1 \\leq \\rho(X,Y) \\leq 1\\).\n\nIndipendenza dalle Unità di Misura: La correlazione è indipendente dalle unità di misura: \\(\\rho(aX, bY) = \\rho(X,Y)\\) per ogni \\(a, b &gt; 0\\).\n\nRelazione Lineare Perfetta: Se \\(Y = a + bX\\) è una funzione lineare di \\(X\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\).\n\nCovarianza e Costanti: La covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, è \\(Cov(aX, bY) = ab \\, Cov(X,Y)\\).\n\nVarianza della Somma/Differenza: \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2Cov(X,Y)\\).\n\nCovarianza e Somma di Variabili: \\(Cov(X + Y, Z) = Cov(X,Z) + Cov(Y,Z)\\).\n\nVarianza di una Somma di Variabili Aleatorie: Per variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\(\\mathbb{V}(\\sum_{i=1}^n X_i) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i&lt;j} Cov(X_i, X_j)\\).\n\nCovarianza e Somme di Prodotti: \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j Cov(X_i, Y_j)\\).\n\nIndipendenza e Covarianza di Somme: Se \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_j X_j) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i)\\).\n\n\n34.8.1 Incorrelazione\nDue variabili casuali \\(X\\) ed \\(Y\\) si dicono incorrelate, o linearmente indipendenti, se la loro covarianza è nulla:\n\\[\nCov(X,Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)] = 0,\n\\]\nequivalente a dire che \\(\\rho_{XY} = 0\\) e \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nQuesta condizione indica una forma di indipendenza più debole rispetto all’indipendenza stocastica. Tuttavia, \\(Cov(X, Y) = 0\\) non implica necessariamente che \\(X\\) ed \\(Y\\) siano stocasticamente indipendenti.\n\nEsempio 34.6 Consideriamo una distribuzione di probabilità congiunta di due variabili aleatorie, \\(X\\) e \\(Y\\), definita come:\n\\[\nf_{XY}(x,y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}, \\\\\n0 & \\text{altrimenti.}\n\\end{array}\n\\right.\n\\]\nQuesto implica che le variabili aleatorie \\(X\\) e \\(Y\\) assumono valori specifici con probabilità uniforme solo per determinate coppie \\((x, y)\\) e zero in tutti gli altri casi.\nDistribuzioni Marginali\nLa distribuzione marginale di \\(X\\) si ottiene sommando le probabilità congiunte su tutti i possibili valori di \\(Y\\), e viceversa per \\(Y\\). Le distribuzioni marginali risultano essere:\n\n\nPer \\(X\\):\n\\[\nf_X(x) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } x=0, \\\\\n\\frac{1}{2} & \\text{per } x=1, \\\\\n\\frac{1}{4} & \\text{per } x=2.\n\\end{array}\n\\right.\n\\]\n\n\nPer \\(Y\\):\n\\[\nf_Y(y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } y=-1, \\\\\n\\frac{1}{2} & \\text{per } y=0, \\\\\n\\frac{1}{4} & \\text{per } y=1.\n\\end{array}\n\\right.\n\\]\n\n\nMedie e Varianze\nCalcoliamo ora le medie e le varianze di \\(X\\) e \\(Y\\):\n\n\nMedia di \\(X\\):\n\\[\n\\mathbb{E}(X) = 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{2} + 2 \\cdot \\frac{1}{4} = 1.\n\\]\n\n\nVarianza di \\(X\\):\n\\[\n\\mathbb{V}(X) = \\left(0^2 \\cdot \\frac{1}{4} + 1^2 \\cdot \\frac{1}{2} + 2^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(X)^2 = \\frac{3}{2} - 1 = \\frac{1}{2}.\n\\]\n\n\nMedia di \\(Y\\):\n\\[\n\\mathbb{E}(Y) = (-1) \\cdot \\frac{1}{4} + 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{4} = 0.\n\\]\n\n\nVarianza di \\(Y\\):\n\\[\n\\mathbb{V}(Y) = \\left((-1)^2 \\cdot \\frac{1}{4} + 0^2 \\cdot \\frac{1}{2} + 1^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(Y)^2 = \\frac{1}{2}.\n\\]\n\n\nCovarianza tra X e Y\nLa covarianza si calcola come:\n\\[\nCov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y),\n\\]\ndove \\(\\mathbb{E}(XY)\\) si trova sommando il prodotto delle coppie di valori \\((x, y)\\) per la loro probabilità congiunta:\n\\[\n\\mathbb{E}(XY) = 0.\n\\]\nDi conseguenza, la covarianza tra \\(X\\) e \\(Y\\) è zero:\n\\[\nCov(X,Y) = 0 - 1 \\cdot 0 = 0.\n\\]\nConclusioni\nSebbene \\(X\\) e \\(Y\\) siano incorrelate (covarianza nulla), ciò non implica la loro indipendenza. L’indipendenza richiede che la funzione di probabilità congiunta si possa esprimere come il prodotto delle funzioni di probabilità marginali per ogni \\(x\\) e \\(y\\), condizione che non si verifica in questo caso. Quindi, nonostante l’assenza di correlazione, \\(X\\) e \\(Y\\) non sono indipendenti, dimostrando che l’incorrelazione non garantisce l’indipendenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#variabili-continue",
    "href": "chapters/probability/11_joint_prob.html#variabili-continue",
    "title": "34  Probabilità congiunta",
    "section": "\n34.9 Variabili Continue",
    "text": "34.9 Variabili Continue\nPassiamo ora a considerare le distribuzioni di densità per variabili continue. Nella figura seguente, tratta da Martin (2024), è illustrata la relazione tra la probabilità congiunta \\(p(A, B)\\), le probabilità marginali \\(p(A)\\) e \\(p(B)\\), e le probabilità condizionali \\(p(A \\mid B)\\).\n\n\nDistribuzioni di densità (figura tratta da Martin (2024)).\n\n\n34.9.1 Probabilità Congiunta \\(p(A, B)\\)\n\nLa probabilità congiunta \\(p(A, B)\\) rappresenta la probabilità che le variabili \\(A\\) e \\(B\\) assumano determinati valori contemporaneamente. Nel caso di variabili continue, questa probabilità è data dall’integrazione della funzione di densità congiunta \\(f(A, B)\\) su una regione di interesse (ad esempio, un’area o un volume). Formalmente:\n\\[\nP(A \\in R_A, B \\in R_B) = \\iint_{R_A \\times R_B} f(A, B) \\, dA \\, dB,\n\\]\ndove \\(R_A\\) e \\(R_B\\) sono intervalli di valori per \\(A\\) e \\(B\\), rispettivamente.\n\n34.9.2 Probabilità Marginali \\(p(A)\\) e \\(p(B)\\)\n\nLe probabilità marginali \\(p(A)\\) e \\(p(B)\\) rappresentano la probabilità di osservare un particolare valore di \\(A\\) (o \\(B\\)) indipendentemente dal valore assunto dall’altra variabile. Nel caso continuo, si ottengono integrando la funzione di densità congiunta rispetto all’altra variabile:\n\\[\np(A) = \\int_{-\\infty}^{+\\infty} f(A, B) \\, dB,\n\\] \\[\np(B) = \\int_{-\\infty}^{+\\infty} f(A, B) \\, dA.\n\\]\nQueste distribuzioni marginali descrivono il comportamento individuale di ciascuna variabile, ignorando l’informazione sull’altra.\n\n34.9.3 Probabilità Condizionale \\(p(A \\mid B)\\)\n\nLa probabilità condizionale \\(p(A \\mid B)\\) esprime la probabilità che \\(A\\) assuma un certo valore, dato un valore specifico di \\(B\\). Nel contesto continuo, si calcola dividendo la funzione di densità congiunta per la densità marginale di \\(B\\):\n\\[\np(A \\mid B) = \\frac{f(A, B)}{p(B)}.\n\\]\nQuesta definizione estende il concetto di probabilità condizionale al caso continuo, mantenendo la stessa interpretazione fondamentale: la probabilità di \\(A\\) dato \\(B\\).\n\n34.9.4 Transizione da Variabili Discrete a Continue\nLa transizione dal trattamento delle variabili discrete a quello delle variabili continue richiede un cambiamento di strumenti matematici: le somme utilizzate nel caso discreto vengono sostituite da integrali nel caso continuo. Tuttavia, i concetti fondamentali di probabilità congiunta, marginale e condizionale rimangono invariati.\n\n34.9.5 Interpretazione Grafica\nNel caso continuo, la probabilità \\(P(X + Y \\leq 1)\\) corrisponde all’area sotto la curva della funzione di densità congiunta \\(f(x, y)\\) nella regione definita da \\(x + y \\leq 1\\). Questa area può essere calcolata tramite un integrale doppio:\n\\[\nP(X + Y \\leq 1) = \\iint_{x + y \\leq 1} f(x, y) \\, dx \\, dy.\n\\]\nQuesta rappresentazione grafica e matematica evidenzia come la probabilità sia legata all’area sotto la curva di densità, estendendo il concetto di probabilità a variabili continue.\nIn conclusione, le distribuzioni di densità per variabili continue permettono di analizzare la relazione tra due o più variabili in modo analogo al caso discreto, ma utilizzando strumenti matematici più avanzati come gli integrali. La probabilità congiunta, marginale e condizionale rimangono concetti chiave, applicabili sia nel contesto discreto che continuo, e forniscono una base solida per l’analisi statistica di fenomeni complessi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/11_joint_prob.html#riflessioni-conclusive",
    "title": "34  Probabilità congiunta",
    "section": "\n34.10 Riflessioni Conclusive",
    "text": "34.10 Riflessioni Conclusive\nIn molti contesti, ogni elemento di una popolazione può essere associato a più variabili casuali. Ad esempio, consideriamo l’insieme di tutti gli studenti iscritti a un’università. Se selezioniamo uno studente a caso e misuriamo la sua altezza e il suo peso, ogni individuo della popolazione è associato a due variabili casuali: l’altezza \\(X\\) e il peso \\(Y\\). Questo scenario illustra come, in situazioni reali, sia comune avere più variabili casuali associate a ciascun elemento di una popolazione.\nQuando si hanno due o più variabili casuali associate a ogni elemento di una popolazione, è possibile studiare la distribuzione congiunta di tali variabili. In questo capitolo, abbiamo esaminato:\n\nDistribuzione di Massa di Probabilità Congiunta: Abbiamo visto come rappresentare la probabilità congiunta \\(p(X, Y)\\) per due variabili casuali discrete, che descrive la probabilità che \\(X\\) e \\(Y\\) assumano specifici valori simultaneamente.\nDistribuzioni Marginali: Abbiamo mostrato come ottenere le distribuzioni marginali \\(p(X)\\) e \\(p(Y)\\) a partire dalla distribuzione congiunta, integrando (o sommando, nel caso discreto) rispetto all’altra variabile. Queste distribuzioni descrivono il comportamento individuale di ciascuna variabile, ignorando l’informazione sull’altra.\nIncorrelazione e Indipendenza: Abbiamo discusso i concetti di incorrelazione e indipendenza tra variabili casuali. Due variabili sono indipendenti se la loro distribuzione congiunta è il prodotto delle distribuzioni marginali: \\[\np(X, Y) = p(X) \\cdot p(Y).\n\\] L’indipendenza implica incorrelazione, ma non vale il viceversa: due variabili possono essere incorrelate senza essere indipendenti.\n\nLa distribuzione congiunta è uno strumento fondamentale per analizzare la relazione tra due o più variabili casuali. Essa permette di rispondere a domande come:\n\nQual è la probabilità che uno studente abbia un’altezza compresa tra 170 cm e 180 cm e un peso compreso tra 70 kg e 80 kg?\nEsiste una relazione tra altezza e peso, e se sì, come possiamo quantificarla?\n\nAttraverso la distribuzione congiunta, possiamo studiare non solo il comportamento individuale delle variabili, ma anche le loro interazioni e dipendenze.\nIl concetto di distribuzione congiunta può essere esteso a più di due variabili casuali, aprendo la strada all’analisi di fenomeni più complessi. Ad esempio, in uno studio psicologico, potremmo essere interessati a esaminare la relazione tra ansia, prestazione cognitiva e livello di stress, utilizzando una distribuzione congiunta a tre variabili.\nIn conclusione, lo studio delle distribuzioni congiunte fornisce una base solida per comprendere e modellare la relazione tra variabili casuali. Che si tratti di altezza e peso, ansia e prestazione, o altre coppie di variabili, la distribuzione congiunta ci permette di analizzare in modo rigoroso le interazioni tra di esse, aprendo la strada a previsioni e decisioni informate.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/11_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "34  Probabilità congiunta",
    "section": "\n34.11 Informazioni sull’Ambiente di Sviluppo",
    "text": "34.11 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.10.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        Rdpack_2.6.2      vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    pan_1.9          \n#&gt; [13] pacman_0.5.1      jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-2     \n#&gt; [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [21] mnormt_2.1.1      codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10      \n#&gt; [25] glmnet_4.1-8      nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64      \n#&gt; [29] reformulas_0.4.0  iterators_1.0.14  rpart_4.1.24      boot_1.3-31      \n#&gt; [33] mitml_0.4-5       foreach_1.5.2     nlme_3.1-167      tidyselect_1.2.1 \n#&gt; [37] digest_0.6.37     stringi_1.8.4     splines_4.4.2     rprojroot_2.0.4  \n#&gt; [41] fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1  cli_3.6.4        \n#&gt; [45] magrittr_2.0.3    survival_3.8-3    broom_1.0.7       withr_3.0.2      \n#&gt; [49] backports_1.5.0   timechange_0.3.0  rmarkdown_2.29    nnet_7.3-20      \n#&gt; [53] lme4_1.1-36       hms_1.1.3         evaluate_1.0.3    rbibutils_2.3    \n#&gt; [57] rlang_1.1.5       Rcpp_1.0.14       glue_1.8.0        minqa_1.2.8      \n#&gt; [61] rstudioapi_0.17.1 jsonlite_1.8.9    R6_2.6.1",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#bibliografia",
    "href": "chapters/probability/11_joint_prob.html#bibliografia",
    "title": "34  Probabilità congiunta",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.\n\n\nMartin, O. (2024). Bayesian analysis with python. Packt Publishing Ltd.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html",
    "href": "chapters/probability/12_discr_rv_distr.html",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "35.1 Introduzione\nÈ importante distinguere tra variabili casuali discrete e continue, perché le distribuzioni di probabilità associate sono molto diverse nei due casi.\nIn questo capitolo ci focalizzeremo sulle distribuzioni di probabilità discrete, strumenti fondamentali per modellare fenomeni aleatori che generano un numero finito o numerabile di possibili esiti. Queste distribuzioni risultano particolarmente efficaci per descrivere eventi che si verificano in contesti discreti, come il numero di successi in un esperimento, l’occorrenza di un evento, o la selezione casuale da un insieme di opzioni finite.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#introduzione",
    "href": "chapters/probability/12_discr_rv_distr.html#introduzione",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "35.1.1 Definizione di una Variabile Casuale Discreta\n\nDefinizione 35.1 Una variabile casuale \\(X\\) si dice avere una distribuzione discreta se assume valori in un insieme finito o numerabile di punti \\(\\{x_1, x_2, \\dots\\}\\), e per ciascun valore \\(x_i\\) nell’insieme, la probabilità \\(P(X = x_i) &gt; 0\\). Inoltre, la somma delle probabilità associate a tutti i possibili valori di \\(X\\) deve essere uguale a 1, ovvero:\n\\[\n\\sum_{i} P(X = x_i) = 1.\n\\]\nLa funzione di massa di probabilità (o probability mass function, PMF) di \\(X\\), denotata con \\(f(x)\\), è definita come:\n\\[\nf(x) = P(X = x),\n\\]\ndove \\(f(x) \\geq 0\\) per ogni \\(x\\) e \\(f(x) = 0\\) per tutti i valori \\(x\\) che non appartengono all’insieme dei valori possibili di \\(X\\).\n\n\n35.1.2 Caratteristiche delle distribuzioni discrete\nUna distribuzione discreta è caratterizzata da:\n\nun insieme finito o infinito numerabile di valori possibili per \\(X\\);\nuna probabilità positiva associata a ciascun valore possibile;\nla proprietà che la somma delle probabilità su tutti i valori possibili è pari a 1.\n\nLa funzione \\(f(x)\\) rappresenta quindi la probabilità che \\(X\\) assuma esattamente il valore \\(x\\). Per esempio, se \\(X\\) rappresenta il numero di teste ottenute lanciando una moneta tre volte, i possibili valori di \\(X\\) sono \\(\\{0, 1, 2, 3\\}\\), e la funzione \\(f(x)\\) specifica la probabilità di ciascuno di questi risultati.\nIn sintesi, una distribuzione discreta descrive fenomeni in cui le variabili casuali possono assumere solo valori isolati, e la funzione di massa di probabilità fornisce una descrizione completa della distribuzione di probabilità di \\(X\\).\n\n35.1.3 Panoramica delle Distribuzioni Discrete\nDi seguito, vengono presentate alcune delle principali distribuzioni discrete utilizzate in statistica e nella ricerca psicologica Ogni distribuzione è descritta in termini di caratteristiche fondamentali, applicazioni pratiche e importanza teorica.\n\n35.1.3.1 Distribuzione di Bernoulli\n\n\nDescrizione: La distribuzione di Bernoulli modella esperimenti con due possibili esiti, generalmente etichettati come “successo” (con probabilità \\(p\\)) e “fallimento” (con probabilità \\(1-p\\)).\n\nApplicazioni: Si applica a situazioni binarie, come il lancio di una moneta (testa/croce), la risposta a domande dicotomiche (sì/no), o l’esito di un evento che può verificarsi o meno.\n\nParametro:\n\n\n\\(p\\): probabilità di successo.\n\n\n\nImportanza: Costituisce la base per molte altre distribuzioni discrete, come la distribuzione binomiale e geometrica. È fondamentale per comprendere fenomeni con esiti dichotomici.\n\n35.1.3.2 Distribuzione Binomiale\n\n\nDescrizione: La distribuzione binomiale descrive il numero totale di successi in un numero fisso \\(n\\) di prove indipendenti, ciascuna governata da una distribuzione di Bernoulli con probabilità di successo \\(p\\).\n\nApplicazioni: Viene utilizzata per analizzare processi ripetuti con esiti binari, ad esempio:\n\nIl numero di voti favorevoli in un campione di opinione.\nIl numero di sintomi osservati in un gruppo di pazienti.\nIl conteggio di errori in un test di accuratezza.\n\n\n\nParametri:\n\n\n\\(n\\): numero di prove.\n\n\\(p\\): probabilità di successo in ogni prova.\n\n\n\nImportanza: Fornisce uno strumento essenziale per modellare fenomeni ripetuti in condizioni identiche, consentendo analisi probabilistiche avanzate e previsioni statistiche.\n\n35.1.3.3 Distribuzione di Poisson\n\n\nDescrizione: La distribuzione di Poisson modella il numero di eventi che si verificano in un intervallo fissato di tempo o spazio, quando tali eventi sono rari, indipendenti e accadono a un tasso medio costante \\(\\lambda\\).\n\nApplicazioni: Trova impiego in contesti dove gli eventi sono sporadici ma prevedibili, ad esempio:\n\nIl numero di episodi di ansia riportati in una settimana.\nIl numero di interazioni sociali spontanee di un bambino con disturbo dello spettro autistico durante una sessione di osservazione.\nLa frequenza di lapsus verbali durante una presentazione pubblica.\nIl numero di sogni vividi riportati durante una serie di notti consecutive in uno studio sul sonno.\n\n\n\nParametro:\n\n\n\\(\\lambda\\): tasso medio di eventi per unità di tempo o spazio.\n\n\n\nImportanza: È cruciale per analizzare fenomeni psicologici o comportamentali rari ma significativi. Aiuta a comprendere i meccanismi sottostanti e a modellare la variabilità osservata in contesti clinici, sperimentali o quotidiani.\n\n35.1.3.4 Distribuzione Uniforme Discreta\n\n\nDescrizione: La distribuzione uniforme discreta rappresenta situazioni in cui tutti gli eventi all’interno di un insieme finito hanno la stessa probabilità di verificarsi.\n\nApplicazioni: Si applica in contesti di scelta casuale equiprobabile, come:\n\nLa selezione casuale di uno stimolo da una lista di parole in un esperimento di memoria.\nL’assegnazione casuale di partecipanti a gruppi sperimentali in uno studio di psicologia sociale.\nLa scelta di un’immagine tra un insieme di stimoli visivi in una ricerca sull’attenzione.\nLa probabilità uniforme che un partecipante scelga una delle opzioni in un questionario a risposte multiple, in assenza di preferenze o conoscenze specifiche.\n\n\n\nParametri:\n\nIntervallo di supporto: l’insieme finito di valori possibili (ad esempio, \\(\\{1, 2, \\dots, k\\}\\)).\n\n\n\nImportanza: Funziona come modello di riferimento in situazioni di massima incertezza o mancanza di preferenze. È utile per definire un punto di partenza in analisi più complesse e per studiare comportamenti casuali.\n\nIn conclusione, le distribuzioni discrete sopra descritte rappresentano strumenti fondamentali per modellare una vasta gamma di fenomeni osservati in ambito scientifico, psicologico e applicativo. Ciascuna distribuzione offre una cornice teorica ben definita per interpretare e analizzare situazioni caratterizzate da variabili aleatorie discrete, fornendo così le basi per inferenze statistiche robuste e previsioni quantitative affidabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzioni-in-r",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzioni-in-r",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "\n35.2 Distribuzioni in R",
    "text": "35.2 Distribuzioni in R\nIn R, per ogni distribuzione sono disponibili quattro funzioni principali, i cui nomi iniziano con le lettere:\n\n\nd (density): per calcolare i valori teorici relativi alla distribuzione,\n\n\np (probability): per ottenere la probabilità cumulativa,\n\n\nq (quantile): per determinare i quantili,\n\n\nr (random): per generare campioni casuali.\n\nIl pacchetto di base stats include numerose funzioni dedicate alle principali distribuzioni statistiche, permettendo di calcolare valori teorici e simulare dati in modo semplice e flessibile. Per ulteriori dettagli sulle distribuzioni disponibili e sull’uso delle relative funzioni, è possibile consultare la documentazione con il comando ?Distributions.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-bernoulli-1",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-bernoulli-1",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "\n35.3 Distribuzione di Bernoulli",
    "text": "35.3 Distribuzione di Bernoulli\nIn statistica, un esperimento che ammette solo due esiti possibili è modellato attraverso quella che viene chiamata “prova Bernoulliana”. Un esempio tipico è il lancio di una moneta, che può dare come risultato testa o croce.\n\nDefinizione 35.2 Una variabile casuale \\(X\\) che assume valori in \\(\\{0, 1\\}\\) è detta variabile di Bernoulli. La sua distribuzione di probabilità è definita come:\n\\[\nP(X \\mid \\theta) =\n  \\begin{cases}\n    p     & \\text{se $X = 1$ (successo)}, \\\\\n    1 - p & \\text{se $X = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq p \\leq 1\\). Il parametro \\(p\\) rappresenta la probabilità del “successo” (\\(X = 1\\)), mentre \\(1 - p\\) è la probabilità dell’“insuccesso” (\\(X = 0\\)).\n\nLa distribuzione di Bernoulli descrive quindi un contesto in cui la probabilità di osservare l’esito 1 è \\(p\\) e quella di osservare l’esito 0 è \\(1 - p\\). Viene utilizzata per modellare situazioni binarie, come una risposta “sì” o “no”, oppure un “successo” o “insuccesso”.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{align}\n\\mathbb{E}(X) &= 0 \\cdot P(X=0) + 1 \\cdot P(X=1) = p, \\\\\n\\mathbb{V}(X) &= (0 - p)^2 \\cdot P(X=0) + (1 - p)^2 \\cdot P(X=1) = p(1-p).\n\\end{align}\n\\tag{35.1}\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\nEsaminiamo la dimostrazione algebrica del calcolo della varianza.\nEspandiamo il calcolo della somma, considerando i due possibili valori di \\(X\\) (0 e 1).\n\n\nPrimo termine (\\(X = 0\\)):\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = (0 - p)^2 \\cdot (1 - p).\n\\]\nSemplificando \\((0 - p)^2 = p^2\\), quindi:\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = p^2 \\cdot (1 - p).\n\\]\n\n\nSecondo termine (\\(X = 1\\)):\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - p)^2 \\cdot p.\n\\]\nSemplificando \\((1 - p)^2 = 1 - 2p + p^2\\), quindi:\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - 2p + p^2) \\cdot p = p - 2p^2 + p^3.\n\\]\n\n\nSomma dei termini\nOra sommiamo i due contributi:\n\\[\n\\mathbb{V}(X) = p^2 \\cdot (1 - p) + (p - 2p^2 + p^3).\n\\]\nEspandendo il primo termine:\n\\[\np^2 \\cdot (1 - p) = p^2 - p^3.\n\\]\nSomma completa:\n\\[\n\\mathbb{V}(X) = (p^2 - p^3) + (p - 2p^2 + p^3).\n\\]\n\n\nRaggruppiamo i termini\n\\[\n\\mathbb{V}(X) = p - p^2.\n\\]\nRisultato finale:\n\\[\n\\mathbb{V}(X) = p(1 - p).\n\\]\n\n\nIn sintesi, la varianza di una variabile aleatoria binaria \\(X\\), distribuita secondo Bernoulli con parametro \\(p\\), è data da \\(p(1-p)\\).\n\n\nTale risultato mostra come la varianza massima si ottenga per \\(p = 0.5\\), condizione che corrisponde alla massima incertezza intrinseca nel processo, ossia quando la probabilità di successo eguaglia quella di insuccesso.\n\n# Valori di p tra 0 e 1\np &lt;- seq(0, 1, length.out = 100)\nvariance &lt;- p * (1 - p)\ndata &lt;- data.frame(p = p, Variance = variance)\n\n# Creazione del grafico\nggplot(data, aes(x = p, y = Variance)) +\n  geom_line(color = \"blue\", linewidth = 1.2) +\n  labs(\n    x = expression(p),\n    y = \"Varianza\",\n    title = \"Varianza di una Variabile Bernoulliana in funzione di p\"\n  )\n\n\n\n\n\n\n\n\n35.3.1 Notazione\nPer indicare che la variabile casuale \\(X\\) segue una distribuzione Bernoulliana di parametro \\(p\\) Utilizziamo la notazione \\(X \\sim \\mathcal{Bern}(p)\\), o in maniera equivalente \\(\\mathcal{Bern}(X \\mid p)\\).\n\nEsempio 35.1 Nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilità di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilità assegna una probabilità di \\(\\frac{1}{2}\\) sia per \\(X = 0\\) che per \\(X = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(X = 0\\) e \\(1\\) per \\(X = 1\\).\nGeneriamo dei valori casuali dalla distribuzione di Bernoulli. Iniziamo con un singolo valore:\n\n# Probabilità di successo\np &lt;- 0.5\n\n# Genera un singolo valore\nbernoulli_sample &lt;- rbinom(n = 1, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt; [1] 1\n\n# Genera un campione di 10 valori\nbernoulli_sample &lt;- rbinom(n = 10, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt;  [1] 1 0 1 1 1 1 0 1 1 0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-binomiale-1",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-binomiale-1",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "\n35.4 Distribuzione Binomiale",
    "text": "35.4 Distribuzione Binomiale\nLa distribuzione binomiale è una distribuzione di probabilità discreta che modella il numero di successi \\(y\\) in un numero fissato \\(n\\) di prove di Bernoulli indipendenti e identiche, dove ciascuna prova ha solo due esiti possibili: “successo” (rappresentato da “1”) con probabilità \\(p\\) o “insuccesso” (rappresentato da “0”) con probabilità \\(1 - p\\). La notazione utilizzata è la seguente:\n\\[\nY \\sim \\mathcal{Binom}(n, p).\n\\]\n\nDefinizione 35.3 La distribuzione binomiale descrive la probabilità di osservare esattamente \\(y\\) successi in \\(n\\) prove di Bernoulli indipendenti:\n\\[\nP(Y = y) = \\binom{n}{y} p^{y} (1 - p)^{n - y} = \\frac{n!}{y!(n - y)!} p^{y} (1 - p)^{n - y},\n\\tag{35.2}\\]\ndove \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di modi possibili per ottenere \\(y\\) successi in \\(n\\) prove, e \\(p\\) è la probabilità di successo in ciascuna prova.\n\nLa distribuzione binomiale si presta bene a esempi classici come il lancio ripetuto di una moneta o l’estrazione di biglie da un’urna. Ad esempio, nel caso del lancio di una moneta, questa distribuzione descrive la probabilità di ottenere un determinato numero di “teste” in un certo numero di lanci, con ogni lancio che segue una distribuzione di Bernoulli con probabilità di successo \\(p\\).\nUna caratteristica interessante della distribuzione binomiale è la sua proprietà di riproducibilità: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono entrambe distribuzioni binomiali con lo stesso parametro \\(p\\), ma con un diverso numero di prove (\\(n_1\\) e \\(n_2\\)), la loro somma, \\(y = y_1 + y_2\\), sarà ancora distribuita binomialmente, con parametri \\(n_1 + n_2\\) e \\(p\\).\n\n35.4.1 Calcolo delle Probabilità\nPer chiarire il calcolo delle probabilità nella distribuzione binomiale, consideriamo una serie di prove di Bernoulli. Supponiamo di avere \\(n\\) prove, con \\(y\\) successi. La configurazione di questi risultati può essere rappresentata come:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ successi} \\overbrace{II\\dots I}^\\text{$n - y$ insuccessi}\n\\]\nLa probabilità di ottenere esattamente \\(y\\) successi in una sequenza specifica di prove è pari a:\n\\[\np^y \\cdot (1 - p)^{n - y},\n\\]\ndove \\(p^y\\) è la probabilità di ottenere \\(y\\) successi, e \\((1 - p)^{n - y}\\) è la probabilità di ottenere \\(n - y\\) insuccessi.\nTuttavia, siamo interessati alla probabilità complessiva di ottenere esattamente \\(y\\) successi in qualsiasi ordine. Il numero di modi in cui ciò può avvenire è dato dal coefficiente binomiale \\(\\binom{n}{y}\\), che rappresenta tutte le possibili disposizioni dei successi e degli insuccessi nelle \\(n\\) prove.\nQuindi, moltiplicando la probabilità di una singola sequenza per il numero di sequenze possibili, otteniamo la probabilità di osservare esattamente \\(y\\) successi:\n\\[\nP(Y = y) = \\binom{n}{y} p^y (1 - p)^{n - y}.\n\\]\nQuesto risultato corrisponde alla formula della distribuzione binomiale.\n\n35.4.2 Caso particolare \\(n = 1\\)\n\nOra consideriamo il caso particolare in cui \\(n = 1\\). Quando \\(n = 1\\), il coefficiente binomiale diventa:\n\\[\n\\binom{1}{k} = \\frac{1!}{k! (1-k)!}.\n\\]\nEspandiamo i fattoriali per i due possibili valori di \\(k\\), che può assumere solo 0 o 1 (poiché \\(k \\in \\{0, 1, \\dots, n\\}\\)).\nCaso 1: \\(k = 0\\)\n\\[\n\\binom{1}{0} = \\frac{1!}{0! (1-0)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(k = 0\\): \\[\nP(X = 0) = \\binom{1}{0} p^0 (1-p)^{1-0} = 1 \\cdot 1 \\cdot (1-p) = 1-p.\n\\]\nCaso 2: \\(k = 1\\)\n\\[\n\\binom{1}{1} = \\frac{1!}{1! (1-1)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(k = 1\\): \\[\nP(X = 1) = \\binom{1}{1} p^1 (1-p)^{1-1} = 1 \\cdot p \\cdot 1 = p.\n\\]\nIn conclusione, la PMF per la distribuzione binomiale con \\(n = 1\\) diventa:\n\\[\nP(X = k) =\n\\begin{cases}\n1-p, & \\text{se } k = 0, \\\\\np, & \\text{se } k = 1.\n\\end{cases}\n\\]\nQuesta è esattamente la PMF della distribuzione di Bernoulli con parametro \\(p\\):\n\\[\nP(X = x) = p^x (1-p)^{1-x}, \\quad x \\in \\{0, 1\\}.\n\\]\nPertanto, la distribuzione binomiale con \\(n = 1\\) è equivalente alla distribuzione di Bernoulli con parametro \\(p\\).\n\n35.4.3 Applicazioni Pratiche della Distribuzione Binomiale\nConsideriamo un esempio pratico per illustrare l’applicazione della distribuzione binomiale. Supponiamo di osservare 2 successi in 4 prove Bernoulliane, dove la probabilità di successo in ogni prova è \\(p = 0.2\\). La probabilità di ottenere questo risultato specifico è calcolata utilizzando l’eq. {eq}eq-binom-distr:\n\\[\nP(Y=2) = \\frac{4!}{2!(4-2)!} \\cdot 0.2^{2} \\cdot (1-0.2)^{4-2} = 0.1536.\n\\]\nQuesto calcolo può essere replicato in Python. Utilizzando il modulo math, possiamo calcolare direttamente:\n\n# Parametri\nn &lt;- 4\np &lt;- 0.2\ny &lt;- 2\n\n# Probabilità di ottenere esattamente y successi\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.1536\n\nIn alternativa, possiamo sfruttare la libreria SciPy per eseguire calcoli analoghi. SciPy offre una vasta gamma di funzioni per la gestione delle distribuzioni statistiche, tra cui la distribuzione binomiale.\n\n# Probabilità di ottenere esattamente y successi\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.1536\n\nUtilizzando dbinom(y, n, p), possiamo trovare le probabilità per ogni possibile valore \\(y\\) in una distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\):\n\n# Usando la funzione dbinom\nprob &lt;- dbinom(x = y, size = n, prob = p)\nprint(prob)\n#&gt; [1] 0.1536\n\nVisualizziamo la distribuzione di massa di probabilità:\n\ny &lt;- 0:n  # Numero di successi\nprobabilities &lt;- dbinom(y, size = n, prob = p)  # Probabilità associate\n\n# Preparare i dati in un data frame\ndf &lt;- data.frame(Successi = y, Probabilità = probabilities)\n\ndf |&gt; \n  ggplot(aes(x = Successi, y = Probabilità)) +\n    geom_segment(aes(xend = Successi, yend = 0), lwd = 1.2, color = \"blue\") +\n    geom_point(size = 3, color = \"blue\") +\n    labs(\n      x = \"Numero di Successi y\",\n      y = \"Probabilità\",\n      title = paste(\"Distribuzione Binomiale: n =\", n, \", p =\", p)\n  )\n\n\n\n\n\n\n\nUn campione casuale si ottiene con rbinom():\n\nset.seed(42)\nsamples &lt;- rbinom(n = 30, size = 5, prob = 0.5)\nprint(samples)\n#&gt;  [1] 4 4 2 4 3 3 3 1 3 3 2 3 4 2 2 4 5 1 2 3 4 1 5 4 1 3 2 4 2 4\n\nPer esplorare ulteriormente, consideriamo la distribuzione di probabilità di diverse distribuzioni binomiali per due valori di \\(n\\) e \\(\\theta\\). La seguente visualizzazione mostra come cambia la distribuzione al variare di \\(\\theta\\):\n\n# Parametri\nn &lt;- 20\np_values &lt;- seq(0.3, 0.9, by = 0.3) # Valori di probabilità\ny &lt;- 0:25 # Numero di successi\n\n# Creazione di un data frame per tutte le distribuzioni\ndf &lt;- data.frame()\n\nfor (p in p_values) {\n  binom_dist &lt;- dbinom(y, size = n, prob = p)\n  df &lt;- rbind(df, data.frame(y = y, Prob = binom_dist, p = factor(p)))\n}\n\n# Grafico con ggplot2\ndf |&gt; \n  ggplot(aes(x = y, y = Prob, color = p)) +\n    geom_point() +\n    geom_line() +\n    labs(\n      x = \"Numero di successi y\", \n      y = \"Probabilità\",\n      title = \"Distribuzione binomiale al variare di p\",\n      color = expression(theta)\n  )\n\n\n\n\n\n\n\nConsideriamo un altro esempio. Lanciando \\(5\\) volte una moneta onesta, qual è la probabilità che esca testa almeno due volte? Troviamo la soluzione usando stats.binom.pmf().\n\n# Calcolo della somma delle probabilità\nresult &lt;- dbinom(2, size = 5, prob = 0.5) +\n          dbinom(3, size = 5, prob = 0.5) +\n          dbinom(4, size = 5, prob = 0.5) +\n          dbinom(5, size = 5, prob = 0.5)\n\nprint(result)\n#&gt; [1] 0.8125\n\nOppure, in modo più compatto:\n\n# Valori di interesse\nresult &lt;- sum(dbinom(2:5, size = 5, prob = 0.5))\nprint(result)\n#&gt; [1] 0.8125\n\nRappresentiamo graficamente la funzione di ripartizione per una Binomiale di ordine \\(n\\) = 5 e \\(\\theta\\) = 0.5.\n\n# Parametri\nn &lt;- 5\np &lt;- 0.5\ny &lt;- 0:n\n\n# Calcolo della funzione di ripartizione cumulativa\ncdf_values &lt;- pbinom(y, size = n, prob = p)\n\n# Creazione del data frame per ggplot2\ndf &lt;- data.frame(y = y, cdf = cdf_values)\n\n# Grafico\ndf |&gt; \n  ggplot(aes(x = y, y = cdf)) +\n    geom_line() +\n    geom_point() +\n    geom_hline(yintercept = 1, color = \"black\", alpha = 0.7, linetype = \"dashed\") +\n    labs(\n      title = paste(\"Funzione di ripartizione binomiale: n =\", n, \", p =\", p),\n      x = \"y\",\n      y = \"Probabilità\"\n    )\n\n\n\n\n\n\n\nUn’altra funzione utile è quella che permette di trovare il numero di successi associato a una data probabilità cumulativa nella coda sinistra di una distribuzione binomiale. Questo si ottiene utilizzando la funzione qbinom, che rappresenta l’inversa della funzione di distribuzione cumulativa (CDF).\nAd esempio, consideriamo una distribuzione binomiale con \\(n = 5\\) prove e probabilità di successo \\(p = 0.5\\). Supponiamo di voler calcolare il numero minimo di successi per cui la probabilità cumulativa è almeno \\(1 - 0.8125 = 0.1875\\). Possiamo farlo nel seguente modo:\n\n# Probabilità target\ntarget_probability &lt;- 1 - 0.8125\n\n# Numero di successi corrispondente alla probabilità target\nresult &lt;- qbinom(target_probability, size = 5, prob = 0.5)\n\nprint(result)\n#&gt; [1] 1\n\nIn questo esempio, il valore restituito è \\(1\\), che indica che almeno 1 successo soddisfa la condizione di una probabilità cumulativa di \\(0.1875\\).\n\n35.4.4 Altro esempio\nConsideriamo ora una distribuzione binomiale con \\(n = 10\\) prove e probabilità di successo \\(p = 0.2\\). Per calcolare la probabilità cumulativa \\(P(Y \\leq 4)\\), ovvero la probabilità di ottenere al massimo 4 successi su 10 tentativi, possiamo utilizzare la funzione pbinom:\n\n# Calcolo della probabilità cumulativa\ntarget_probability &lt;- pbinom(4, size = 10, prob = 0.2)\nprint(target_probability)\n#&gt; [1] 0.9672\n\nIl risultato rappresenta la probabilità cumulativa associata a 4 o meno successi.\nSe invece vogliamo determinare il numero di successi corrispondente a questa probabilità cumulativa, possiamo utilizzare la funzione inversa qbinom:\n\n# Calcolo del numero di successi associato alla probabilità cumulativa\nresult &lt;- qbinom(target_probability, size = 10, prob = 0.2)\nprint(result)\n#&gt; [1] 4\n\nIn questo caso, il valore restituito rappresenta il numero massimo di successi \\(Y\\) per cui la probabilità cumulativa è uguale o inferiore a \\(target\\_probability\\). Questo è particolarmente utile per interpretare i risultati di una distribuzione binomiale in termini di successi associati a determinate probabilità cumulative.\n\n35.4.5 Valore atteso e deviazione standard\nLa media (numero atteso di successi in \\(n\\) prove) e la deviazione standard di una distribuzione binomiale si calcolano nel seguente modo:\n\\[\n\\begin{align}\n\\mu    &= np,  \\notag \\\\\n\\sigma &= \\sqrt{np(1-p)}.\n\\end{align}\n\\tag{35.3}\\]\nDimostrazione. Dato che \\(Y\\) rappresenta la somma di \\(n\\) prove di Bernoulli indipendenti \\(Y_i\\), possiamo scrivere:\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= \\mathbb{E}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{E}(Y_i) = np, \\\\\n\\mathbb{V}(Y) &= \\mathbb{V} \\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{V}(Y_i) = np(1-p).\n\\end{align}\n\\]\nPertanto, la deviazione standard è data da \\(\\sigma = \\sqrt{np(1-p)}\\).\nPer esempio, prendiamo in considerazione il caso di un esperimento in cui vengono lanciate quattro monete, ciascuna con una probabilità di ottenere testa (successo) pari a \\(p = 0.2\\). Calcoliamo il valore atteso e la varianza per questo esperimento.\nIl valore atteso, \\(\\mu\\), rappresenta il numero medio di teste che ci aspettiamo di ottenere in ciascun lancio. Per la distribuzione binomiale, questo è dato da \\(\\mu = n p\\), dove \\(n\\) è il numero di prove (lanci di monete). Nel nostro caso, con \\(n = 4\\) e \\(p = 0.2\\), abbiamo:\n\\[\n\\mu = n p = 4 \\times 0.2 = 0.8.\n\\]\nQuesto significa che, in media, ci aspettiamo di ottenere circa 0.8 teste per ogni serie di quattro lanci.\nPer quanto riguarda la varianza, che misura quanto i risultati individuali tendono a differire dalla media, nella distribuzione binomiale è calcolata come \\(n p (1-p)\\). Pertanto, per il nostro esperimento:\n\\[\n\\text{Varianza} = n p (1-p) = 4 \\times 0.2 \\times (1 - 0.2) = 0.64.\n\\]\nLa varianza di 0.64 suggerisce una certa dispersione intorno al valore medio di 0.8 teste.\nPer confermare queste aspettative teoriche, possiamo eseguire una simulazione. Creiamo una serie di esperimenti simulati in cui lanciamo quattro monete per un gran numero di volte, registrando il numero di teste ottenute in ogni serie. Calcoliamo poi la media e la varianza dei risultati ottenuti per vedere quanto si avvicinano ai valori teorici calcolati.\n\nset.seed(42)\n\n# Genera un campione di 1.000.000 di valori dalla distribuzione binomiale\nx &lt;- rbinom(n = 1000000, size = 4, prob = 0.2)\n\n\nmean(x)\n#&gt; [1] 0.8002\n\n\nvar(x)\n#&gt; [1] 0.639\n\n\n35.4.6 Funzioni R associate alle distribuzioni di probabilità\nLa seguente tabella riassume le funzioni di R utilizzate per manipolare le distribuzioni di probabilità, illustrando i casi della distribuzione Binomiale e della Normale.\n\n\n\n\n\n\n\nTipo\nEsempio: Binomiale (\\(y \\mid n, p\\))\nEsempio: Normale (\\(y \\mid \\mu, \\sigma\\))\n\n\n\nFunzione di verosimiglianza\ndbinom(y, size = n, prob = p)\ndnorm(y, mean = μ, sd = σ)\n\n\nProb \\(Y = y\\)\n\ndbinom(y, size = n, prob = p)\nNon definita (variabili continue hanno pdf, non pmf)\n\n\nProb \\(Y \\geq y, Y \\leq y, y_1 &lt; Y &lt; y_2\\)\n\n\npbinom(y, size = n, prob = p) o 1 - pbinom(y - 1, ...)\n\n\npnorm(y, mean = μ, sd = σ) o 1 - pnorm(y, ...)\n\n\n\nInversa della CDF\nqbinom(q, size = n, prob = p)\nqnorm(q, mean = μ, sd = σ)\n\n\nGenerazione di dati simulati\nrbinom(n, size = trials, prob = p)\nrnorm(n, mean = μ, sd = σ)\n\n\n\nIn seguito, useremo altre distribuzioni come Uniforme, Beta, ecc., ognuna delle quali ha un proprio insieme di funzioni disponibili in R. La sintassi segue uno schema generale comune:\n\n\nd*: Calcola la funzione di densità di probabilità (per distribuzioni continue) o di massa (per distribuzioni discrete). Esempi: dbinom, dnorm.\n\np*: Calcola la funzione di ripartizione cumulativa (CDF). Esempi: pbinom, pnorm.\n\nq*: Calcola l’inversa della funzione di ripartizione cumulativa (quantile function). Esempi: qbinom, qnorm.\n\nr*: Genera campioni casuali secondo una determinata distribuzione. Esempi: rbinom, rnorm.\n\n\nEsempio 35.2  \n\nCalcolare la probabilità di esattamente \\(y = 3\\) successi su \\(n = 5\\) prove con \\(p = 0.5\\):\n\n\ndbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.3125\n\n\nCalcolare la probabilità cumulativa \\(P(Y \\leq 3)\\):\n\n\npbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.8125\n\n\nCalcolare il valore minimo \\(y\\) tale che \\(P(Y \\leq y) \\geq 0.9\\):\n\n\nqbinom(0.9, size = 5, prob = 0.5)\n#&gt; [1] 4\n\n\nGenerare un campione di 100 numeri casuali da una distribuzione binomiale:\n\n\nrbinom(100, size = 5, prob = 0.5)\n#&gt;   [1] 2 2 4 1 3 2 3 2 2 2 3 3 3 3 1 4 1 1 0 2 2 2 4 1 2 3 3 1 5 2 3 3 0 3 2\n#&gt;  [36] 3 4 2 3 3 3 3 1 5 3 3 2 3 1 2 1 3 3 2 2 4 1 4 2 3 1 4 2 2 3 4 1 1 4 2\n#&gt;  [71] 3 2 3 3 3 1 4 4 3 3 4 3 3 3 2 2 3 3 2 4 4 3 2 2 0 3 1 3 1 2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "\n35.5 Distribuzione Discreta Uniforme",
    "text": "35.5 Distribuzione Discreta Uniforme\nLa distribuzione discreta uniforme è un tipo particolare di distribuzione di probabilità, dove ogni risultato in un insieme finito e discreto \\(S\\) ha la stessa probabilità \\(p\\) di verificarsi. Questa distribuzione è caratterizzata dalla sua semplicità e dalla sua proprietà fondamentale di equiprobabilità.\nConsideriamo un esempio pratico con una variabile casuale discreta \\(X\\), che può assumere valori nell’insieme \\(\\{1, 2, \\dots, N\\}\\). Un’istanza classica di questa distribuzione si verifica quando si sceglie casualmente un numero intero tra 1 e \\(N\\), inclusi. Se \\(X\\) rappresenta il numero selezionato, allora la somma delle probabilità di tutti i possibili valori di \\(X\\) deve totalizzare 1, come indicato dalla formula di normalizzazione:\n\\[\n\\sum_{i=1}^N P(X_i) = Np = 1.\n\\]\nDi conseguenza, la probabilità che \\(X\\) assuma un valore specifico \\(x\\) è uniformemente distribuita:\n\\[\nP(X = x) = \\frac{1}{N},\n\\]\nindicando che ogni evento ha la stessa probabilità di verificarsi.\nIl valore atteso, o la media, di \\(X\\) ci dà un’idea del risultato medio atteso e si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x=1}^N x \\cdot \\frac{1}{N} = \\frac{1}{N} \\cdot \\sum_{x=1}^N x.\n\\]\nA questo punto, dobbiamo calcolare la somma \\(\\sum_{x=1}^{N} x\\), che è la somma dei primi \\(N\\) numeri naturali. Questa somma è data dalla formula:\n\\[\n\\sum_{x=1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nSostituendo questa formula nel nostro calcolo del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nQuindi, abbiamo dimostrato che il valore atteso $ (X) $ per una variabile casuale \\(X\\) che assume valori interi uniformemente distribuiti da 1 a \\(N\\) è \\(\\frac{N + 1}{2}\\).\nPer determinare quanto i valori di \\(X\\) si disperdono attorno al valore medio, calcoliamo la varianza. Il primo passo è calcolare \\(\\mathbb{E}(X^2)\\), il valore atteso del quadrato di \\(X\\). Per una variabile casuale discreta uniforme, questo si ottiene moltiplicando ogni valore al quadrato per la sua probabilità (che è \\(1/N\\) per tutti i valori) e sommando i risultati:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\sum_{x=1}^N x^2\n\\]\nUsando l’identità per la somma dei quadrati dei primi \\(N\\) numeri naturali:\n\\[\n1^2 + 2^2 + \\dots + N^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\npossiamo sostituirla per trovare \\(\\mathbb{E}(X^2)\\):\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}\n\\]\nLa varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), si calcola usando la formula:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2\n\\]\nAbbiamo già stabilito che \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\) e \\(\\mathbb{E}(X^2) = \\frac{(N + 1)(2N + 1)}{6}\\). Sostituendo questi valori nella formula della varianza, otteniamo:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2\n\\]\nPer semplicare l’espressione della varianza, dobbiamo sottrarre il quadrato di \\(\\mathbb{E}(X)\\) da \\(\\mathbb{E}(X^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4} \\\\\n&= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1)(2(2N + 1) - 3(N + 1))}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}\n\\end{align*}\n\\]\nQuindi, la varianza \\(\\mathbb{V}(X)\\) di una variabile casuale uniforme discreta \\(X\\) che assume valori da 1 a \\(N\\) è \\(\\frac{(N + 1)(N - 1)}{12}\\), il che mostra come la dispersione dei valori attorno al loro valore medio dipenda dalla grandezza di \\(N\\). Questa formula fornisce la varianza di una variabile casuale in una distribuzione discreta uniforme, offrendo una misura quantitativa della dispersione dei valori attorno al loro valore medio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-poisson-1",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-poisson-1",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "\n35.6 Distribuzione di Poisson",
    "text": "35.6 Distribuzione di Poisson\nLa distribuzione di Poisson è utilizzata per modellare il numero di eventi che si verificano in un determinato intervallo di tempo o spazio, con eventi indipendenti e un tasso costante di occorrenza.\nLa funzione di massa di probabilità (PMF) è data da:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad y = 0, 1, 2, \\ldots\n\\]\ndove \\(\\lambda\\) rappresenta il tasso medio di eventi e \\(y\\) è il numero di eventi.\nLa distribuzione di Poisson può essere derivata come il limite di una distribuzione binomiale quando il numero di prove, \\(n\\), tende all’infinito e la probabilità di successo in ciascuna prova, \\(p\\), tende a zero, in modo tale che \\(np = \\lambda\\).\n\n\n\n\n\n\nDimostrazione\n\n\n\nPartiamo dalla funzione di probabilità binomiale:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} p^k (1 - p)^{n - k}.\n\\]\nImpostiamo \\(np = \\lambda\\), il che implica che \\(p = \\frac{\\lambda}{n}\\). Sostituendo \\(p\\) con \\(\\frac{\\lambda}{n}\\) nella formula binomiale, otteniamo:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} \\left(\\frac{\\lambda}{n}\\right)^k \\left(1 - \\frac{\\lambda}{n}\\right)^{n - k}.\n\\]\nOra, separiamo i termini per rendere più chiara la semplificazione. Possiamo riscrivere \\(\\left(\\frac{\\lambda}{n}\\right)^k\\) come \\(\\frac{\\lambda^k}{n^k}\\), e \\(\\left(1 - \\frac{\\lambda}{n}\\right)^{n - k}\\) come \\(\\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}\\). Quindi, l’espressione diventa:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} \\cdot \\frac{\\lambda^k}{n^k} \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}.\n\\]\nOra, separiamo ulteriormente i termini:\n\\[\np(k) = \\frac{\\lambda^k}{k!} \\cdot \\frac{n!}{(n - k)! n^k} \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}.\n\\]\nQuesto passaggio mostra come la funzione di probabilità binomiale, sotto le condizioni \\(np = \\lambda\\) e \\(n \\to \\infty\\), si trasformi gradualmente nella forma che conduce alla distribuzione di Poisson.\nQuando \\(n \\to \\infty\\):\n\\[\n\\frac{\\lambda}{n} \\to 0\n\\]\n\\[\n\\frac{n!}{(n - k)! n^k} \\to 1\n\\]\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n \\to e^{-\\lambda}\n\\]\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^{-k} \\to 1\n\\]\nSi ottiene quindi:\n\\[\np(k) \\to \\frac{\\lambda^k e^{-\\lambda}}{k!}\n\\]\nche è la funzione di Poisson.\n\n\n\n\n\n\n\n\nDimostrazione\n\n\n\nAnalizziamo il limite:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n \\to e^{-\\lambda} \\quad \\text{quando} \\quad n \\to \\infty.\n\\]\nUn limite fondamentale in analisi matematica è:\n\\[\n\\lim_{n \\to \\infty} \\left(1 + \\frac{a}{n}\\right)^n = e^a,\n\\]\ndove \\(e\\) è la base del logaritmo naturale (\\(e \\approx 2.71828\\)) e \\(a\\) è una costante. Questo limite è alla base della definizione della funzione esponenziale.\nNel nostro caso, abbiamo l’espressione:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n .\n\\]\nNotiamo che questa è molto simile al limite notevole, ma con un segno negativo. Possiamo riscriverla come:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n = \\left(1 + \\frac{-\\lambda}{n}\\right)^n.\n\\]\nApplicando il limite notevole con \\(a = -\\lambda\\), otteniamo:\n\\[\n\\lim_{n \\to \\infty} \\left(1 + \\frac{-\\lambda}{n}\\right)^n = e^{-\\lambda}.\n\\]\nQuindi, quando \\(n\\) diventa molto grande, l’espressione \\(\\left(1 - \\frac{\\lambda}{n}\\right)^n\\) si avvicina sempre di più a \\(e^{-\\lambda}\\).\n\n\n\n35.6.1 Proprietà principali\n\n\nMedia: \\(\\mathbb{E}[Y] = \\lambda\\)\n\n\nVarianza: \\(\\text{Var}(Y) = \\lambda\\)\n\n\nDi seguito, presentiamo esempi di calcolo e simulazione con R.\n\n35.6.2 Grafico della distribuzione di Poisson con \\(\\lambda = 2\\)\n\n\n# Parametro lambda\nlambda &lt;- 2\n\n# Valori di y (numero di eventi)\ny &lt;- 0:10\n\n# Calcolo delle probabilità\nprobabilities &lt;- dpois(y, lambda = lambda)\n\n# Creazione di un dataframe per ggplot\ndata &lt;- data.frame(\n  Numero_eventi = y,\n  Probabilita = probabilities\n)\n\n# Grafico della funzione di massa di probabilità con ggplot\nggplot(data, aes(x = Numero_eventi, y = Probabilita)) +\n  geom_col(fill = \"blue\") +  # Usa colonne verticali per rappresentare le probabilità\n  labs(\n    title = \"Distribuzione di Massa di Probabilità di Poisson\",\n    x = \"Numero di eventi (k)\",\n    y = \"Probabilità\"\n  ) \n\n\n\n\n\n\n\n\n35.6.3 Calcolo della probabilità per un numero specifico di eventi\nPer calcolare la probabilità di osservare esattamente 3 eventi con \\(\\lambda = 2\\):\n\nprob &lt;- dpois(3, lambda = 2)\nprint(prob)\n#&gt; [1] 0.1804\n\n\n35.6.4 Calcolo della probabilità cumulativa \\(P(Y \\leq 3)\\)\n\nPer calcolare \\(P(Y \\leq 3)\\), la probabilità cumulativa:\n\ncum_prob &lt;- ppois(3, lambda = 2)\nprint(cum_prob)\n#&gt; [1] 0.8571\n\n\n35.6.5 Trovare il quantile corrispondente a una probabilità data\nPer trovare il numero massimo di eventi per cui la probabilità cumulativa è al massimo \\(0.8125\\):\n\nquantile &lt;- qpois(0.8125, lambda = 2)\nprint(quantile)\n#&gt; [1] 3\n\n\n35.6.6 Generazione di numeri casuali\nPer generare un campione di 1.000.000 di osservazioni da una distribuzione di Poisson con \\(\\lambda = 2\\):\n\nset.seed(42)\nsample &lt;- rpois(1000000, lambda = 2)\n\n# Calcolo di media e varianza del campione\nmean_sample &lt;- mean(sample)\nvar_sample &lt;- var(sample)\n\nprint(mean_sample)\n#&gt; [1] 2\nprint(var_sample)\n#&gt; [1] 1.996\n\n\nEsempio 35.3 Consideriamo un ospedale con una media storica di 4.5 nascite al giorno. Qual è la probabilità che nascano esattamente 6 bambini in un giorno?\n\n# Calcolo della probabilità\nlambda &lt;- 4.5\nprob &lt;- dpois(6, lambda = lambda)\nprint(prob)\n#&gt; [1] 0.1281\n\nSimuliamo 365 giorni di nascite e confrontiamo la proporzione di giorni con esattamente 6 nascite:\n\nset.seed(42)\nn_days &lt;- 365\nsimulated_births &lt;- rpois(n_days, lambda = lambda)\n\n# Proporzione di giorni con esattamente 6 nascite\nproportion_six_births &lt;- mean(simulated_births == 6)\nprint(proportion_six_births)\n#&gt; [1] 0.1397\n\nIstogramma delle nascite simulate:\n\n# Creare un dataframe con i dati simulati\ndata &lt;- data.frame(Nascite = simulated_births)\n\n# Creare l'istogramma con ggplot\nggplot(data, aes(x = Nascite)) +\n  geom_histogram(\n    breaks = seq(-0.5, max(simulated_births) + 0.5, by = 1), \n    fill = \"blue\", \n    color = \"black\"\n  ) +\n  labs(\n    title = \"365 nascite simulate (Poisson)\",\n    x = \"Numero di nascite per giorno\",\n    y = \"Frequenza\"\n  )\n\n\n\n\n\n\n\nProbabilità di più di 6 nascite in un giorno. Per calcolare la probabilità teorica \\(P(Y &gt; 6)\\):\n\nprob_more_than_six &lt;- 1 - ppois(6, lambda = lambda)\nprint(prob_more_than_six)\n#&gt; [1] 0.1689\n\nProporzione simulata di più di 6 nascite:\n\nproportion_more_than_six &lt;- mean(simulated_births &gt; 6)\nprint(proportion_more_than_six)\n#&gt; [1] 0.1699\n\n\n\nEsempio 35.4 Questo esempio classico è tratto da von Bortkiewicz (1898). Furono registrate le morti causate da calci di cavalli all’interno di 10 squadroni della cavalleria prussiana, osservando i dati per un periodo di 20 anni, il che corrisponde a un totale di 200 “squadroni-anni” di dati.\nI dati e le probabilità ottenute da un modello di Poisson con parametro \\(\\lambda = 0.61\\) sono mostrati nella tabella seguente. La prima colonna della tabella indica il numero di decessi annui, che varia da 0 a 4. La seconda colonna elenca quante volte è stato osservato quel particolare numero di decessi. Per esempio, in 65 dei 200 squadroni-anni ci fu un solo decesso. Nella terza colonna, i numeri osservati vengono convertiti in frequenze relative dividendo ciascun valore per 200. La quarta colonna mostra le probabilità di Poisson calcolate con il parametro \\(\\lambda = 0.61\\). Il valore \\(\\lambda = 0.61\\) è stato scelto in modo da corrispondere al numero medio di decessi annui.\n\n\n\n\n\n\n\n\nNumero di decessi annui\nFrequenza osservata\nFrequenza relativa\nProbabilità di Poisson\n\n\n\n0\n109\n0.545\n0.543\n\n\n1\n65\n0.325\n0.331\n\n\n2\n22\n0.110\n0.101\n\n\n3\n3\n0.015\n0.021\n\n\n4\n1\n0.005\n0.003\n\n\n\nNote:\n\n\nFrequenza osservata: Indica quante volte un determinato numero di decessi è stato registrato nei 200 squadroni-anni.\n\nFrequenza relativa: È ottenuta dividendo la frequenza osservata per il totale dei dati (200).\n\nProbabilità di Poisson: Valori teorici calcolati usando il modello di Poisson con \\(\\lambda = 0.61\\), che rappresenta il tasso medio di decessi annui.\n\nQuesto esempio dimostra come il modello di Poisson possa essere utilizzato per descrivere fenomeni rari ma prevedibili, come le morti accidentali in questo caso.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "\n35.7 Distribuzione Beta-Binomiale",
    "text": "35.7 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilità nella probabilità di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilità per la distribuzione beta-binomiale è data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{35.4}\\]\ndove:\n\n\n\\(y\\) indica il numero di successi osservati.\n\n\\(N\\) rappresenta il numero totale di tentativi.\n\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilità nella probabilità di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, è definita tramite l’uso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL’importanza della distribuzione beta-binomiale deriva dalla sua capacità di modellare situazioni in cui la probabilità di successo non è fissa, ma segue una distribuzione di probabilità, specificatamente una distribuzione beta. Ciò la rende particolarmente adatta per applicazioni in cui le probabilità di successo cambiano in maniera incerta da un tentativo all’altro, come può avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilità di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione più realistica e flessibile per dati empirici che presentano variabilità nelle probabilità di successo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/12_discr_rv_distr.html#riflessioni-conclusive",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "\n35.8 Riflessioni Conclusive",
    "text": "35.8 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito alcune delle distribuzioni discrete più importanti, ognuna con caratteristiche uniche e campi di applicazione specifici. Abbiamo iniziato con la distribuzione di Bernoulli, che modella esperimenti con due soli esiti possibili, per poi passare alla distribuzione Binomiale, che generalizza la Bernoulli considerando un numero fisso di prove indipendenti. Successivamente, abbiamo esaminato la distribuzione di Poisson, utile per descrivere eventi rari in un intervallo di tempo o spazio, e la distribuzione Beta-Binomiale, un’estensione della Binomiale che incorpora la variabilità nella probabilità di successo, rendendola particolarmente adatta per modellare situazioni in cui tale probabilità non è fissa. Infine, abbiamo discusso la distribuzione Discreta Uniforme, che assegna la stessa probabilità a ciascun evento in un insieme finito e discreto.\nQueste distribuzioni rappresentano il fondamento dell’analisi statistica discreta e trovano applicazione in numerosi ambiti. In particolare, nel contesto dell’inferenza bayesiana, la comprensione della distribuzione Binomiale e della sua estensione Beta-Binomiale è essenziale. Queste distribuzioni, infatti, forniscono gli strumenti necessari per l’aggiornamento bayesiano, un processo chiave che permette di rivedere le nostre credenze iniziali alla luce di nuovi dati. Questo concetto sarà ulteriormente esplorato nei capitoli successivi, dove approfondiremo come le distribuzioni a priori e a posteriori interagiscono nel quadro bayesiano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#esercizi",
    "href": "chapters/probability/12_discr_rv_distr.html#esercizi",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "\n35.9 Esercizi",
    "text": "35.9 Esercizi\n\nEsercizio 35.1 Per ciascuna delle distribuzioni di massa di probabilità discusse, utilizzare R per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l’intervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media più una deviazione standard, calcolare la probabilità che la variabile aleatoria assuma un valore minore o uguale a questo valore.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/12_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#bibliografia",
    "href": "chapters/probability/12_discr_rv_distr.html#bibliografia",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html",
    "href": "chapters/probability/13_cont_rv_distr.html",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "",
    "text": "36.1 Introduzione\nProprio come per le variabili casuali discrete, anche per le variabili casuali continue è possibile rappresentare la variabilità di una popolazione attraverso un modello statistico. Tuttavia, mentre le distribuzioni discrete si applicano a fenomeni con un numero finito o numerabile di esiti, le variabili casuali continue richiedono l’uso di funzioni di densità di probabilità (pdf), che descrivono fenomeni in cui i valori possono assumere un continuum di possibilità. Queste funzioni ci permettono di modellare e analizzare situazioni in cui i risultati non sono discreti, ma possono variare in modo continuo.\nLa funzione di densità di probabilità \\(f(x)\\) associata a una variabile casuale continua \\(X\\) rappresenta la distribuzione della probabilità all’interno della popolazione. A differenza delle distribuzioni discrete, dove la probabilità è assegnata direttamente a singoli valori, la pdf non fornisce la probabilità di un singolo punto, ma descrive la probabilità che \\(X\\) assuma valori all’interno di un intervallo specifico. Questo approccio consente di costruire un modello matematico della popolazione, utile per fare previsioni e comprendere meglio i fenomeni aleatori continui.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#introduzione",
    "href": "chapters/probability/13_cont_rv_distr.html#introduzione",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "",
    "text": "36.1.1 Definizione di una Variabile Casuale Continua\n\nDefinizione 36.1 Una variabile casuale \\(X\\) è definita come avente una distribuzione continua se la sua funzione di distribuzione cumulativa \\(F(x)\\), che rappresenta la probabilità che \\(X\\) assuma un valore minore o uguale a \\(x\\), soddisfa le seguenti proprietà:\n\n\nEsiste una funzione \\(f(x)\\), chiamata funzione di densità di probabilità (pdf), tale che:\n\n\n\\(f(x) \\geq 0\\) per ogni \\(x \\in \\mathbb{R}\\);\nL’integrale di \\(f(x)\\) su tutto l’insieme dei numeri reali è uguale a 1: \\[\n\\int_{-\\infty}^{\\infty} f(x) \\, dx = 1.\n\\]\n\n\n\n\nPer qualsiasi intervallo \\((a, b]\\), con \\(a &lt; b\\), la probabilità che \\(X\\) cada in questo intervallo è data dall’area sotto la curva \\(f(x)\\) tra \\(a\\) e \\(b\\):\n\\[\nP(a &lt; X \\leq b) = F(b) - F(a) = \\int_{a}^{b} f(x) \\, dx.\n\\]\n\n\n\n\n36.1.2 Caratteristiche delle Distribuzioni Continue\nLa funzione \\(f(x)\\) descrive la “densità” di probabilità associata alla variabile casuale \\(X\\). A differenza delle distribuzioni discrete, in una distribuzione continua la probabilità che \\(X\\) assuma un valore specifico \\(x\\) è sempre nulla, ovvero \\(P(X = x) = 0\\). Questo perché, in un continuum di valori, la probabilità è concentrata su intervalli e non su singoli punti. Pertanto, la probabilità è definita solo per intervalli di valori, e l’area sotto la curva della pdf in un determinato intervallo rappresenta la probabilità che \\(X\\) cada in quell’intervallo.\nIn sintesi, le distribuzioni continue forniscono un potente strumento per modellare fenomeni aleatori in cui i risultati possono variare in modo continuo, permettendoci di calcolare probabilità per intervalli e di comprendere meglio la struttura sottostante dei dati.\nIniziamo ad esaminare la distribuzione continua uniforme.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#la-distribuzione-uniforme",
    "href": "chapters/probability/13_cont_rv_distr.html#la-distribuzione-uniforme",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "\n36.2 La Distribuzione Uniforme",
    "text": "36.2 La Distribuzione Uniforme\nLa distribuzione uniforme è una delle distribuzioni di probabilità più semplici e intuitive. Si utilizza quando ogni valore in un determinato intervallo ha la stessa probabilità di verificarsi. Un esempio comune è un esperimento in cui si fa ruotare uno spinner circolare e si registra l’angolo ottenuto: poiché ogni angolo ha la stessa probabilità, i valori sono distribuiti uniformemente.\n\n36.2.1 Simulazione della Distribuzione Uniforme\nPer comprendere meglio questa distribuzione, consideriamo una simulazione. Generiamo 20 valori casuali che rappresentano gli angoli ottenuti dallo spinner e li visualizziamo con un istogramma:\n\nset.seed(123)\nspinner_results &lt;- runif(20, min = 0, max = 360)\nprint(spinner_results)\n#&gt;  [1] 103.53 283.79 147.23 317.89 338.57  16.40 190.12 321.27 198.52 164.38\n#&gt; [11] 344.46 163.20 243.93 206.15  37.05 323.94  88.59  15.14 118.05 343.62\n\nggplot(data.frame(Valori = spinner_results), aes(x = Valori)) +\n  geom_histogram(binwidth = 10, fill = \"skyblue\", color = \"black\", alpha = 0.5) +\n  labs(x = \"Risultato dello spinner\", y = \"Frequenza relativa\",\n       title = \"Istogramma dei risultati (20 simulazioni)\")\n\n\n\n\n\n\n\nCon sole 20 osservazioni, l’istogramma potrebbe non apparire uniforme a causa della variabilità naturale nei piccoli campioni. Aumentiamo il numero di simulazioni a 100.000 per ottenere un’immagine più chiara:\n\nspinner_results_large &lt;- runif(100000, min = 0, max = 360)\n\nggplot(data.frame(Valori = spinner_results_large), aes(x = Valori)) +\n  geom_histogram(binwidth = 10, fill = \"skyblue\", color = \"black\", alpha = 0.5) +\n  labs(x = \"Risultato dello spinner\", y = \"Frequenza relativa\",\n       title = \"Istogramma dei risultati (100.000 simulazioni)\")\n\n\n\n\n\n\n\nCon 100,000 valori, l’istogramma appare visivamente uniforme, confermando la distribuzione uniforme dei dati nell’intervallo [0, 360].\n\n36.2.2 Funzione di Densità Uniforme\nLa distribuzione uniforme può essere descritta da una funzione di densità di probabilità (PDF). Per una distribuzione uniforme continua su un intervallo \\([a, b]\\), la densità è costante e definita come:\n\\[\nf(x) = \\frac{1}{b - a} \\quad \\text{per } x \\in [a, b].\n\\]\nNel caso dello spinner, con \\(a = 0\\) e \\(b = 360\\), la densità è:\n\\[\nf(x) = \\frac{1}{360}.\n\\]\nPossiamo visualizzare questa funzione in R:\n\nx &lt;- seq(0, 360, length.out = 100)\ndensity_uniform &lt;- dunif(x, min = 0, max = 360)\n\nggplot(data.frame(x = x, y = density_uniform), aes(x = x, y = y)) +\n  geom_line(linewidth = 1, color = \"blue\") +\n  labs(x = \"x\", y = \"p(x)\", title = \"Funzione di densità uniforme\")\n\n\n\n\n\n\n\n\n36.2.3 Calcolo della Probabilità in un Intervallo\nLa probabilità di ottenere un valore tra \\(150\\) e \\(250\\) in una distribuzione uniforme è data dall’area sotto la funzione di densità in quell’intervallo:\n\\[\nP(150 &lt; X &lt; 250) = (250 - 150) \\cdot \\frac{1}{360}.\n\\]\nIn R, possiamo calcolare questa probabilità manualmente:\n\nprob_intervallo &lt;- (250 - 150) * (1 / 360)\nprob_intervallo\n#&gt; [1] 0.2778\n\nOppure utilizzando la funzione cumulativa punif:\n\nprob_intervallo_cdf &lt;- \n  punif(250, min = 0, max = 360) - punif(150, min = 0, max = 360)\nprob_intervallo_cdf\n#&gt; [1] 0.2778\n\nLa probabilità è circa 0.2778. Visualizziamo questa area nell’intervallo [150, 250]:\n\nx &lt;- seq(0, 360, length.out = 1000)\nfx &lt;- dunif(x, min = 0, max = 360)\n\nggplot(data.frame(x = x, fx = fx), aes(x = x, y = fx)) +\n  geom_line(linewidth = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x = x, fx = fx), x &gt;= 150 & x &lt;= 250),\n            aes(x = x, y = fx), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"p(x)\", title = \"Probabilità per l'intervallo [150, 250]\")\n\n\n\n\n\n\n\n\n36.2.4 Proprietà della Distribuzione Uniforme\nPer una variabile casuale \\(X \\sim \\mathcal{U}(a, b)\\), le proprietà principali sono:\n\nValore atteso (media): \\[\nE(X) = \\frac{a + b}{2}.\n\\]\nVarianza: \\[\nV(X) = \\frac{(b - a)^2}{12}.\n\\]\n\nAd esempio, per \\(\\mathcal{U}(0, 360)\\):\n\nE_X &lt;- (0 + 360) / 2\nV_X &lt;- (360 - 0)^2 / 12\nE_X\n#&gt; [1] 180\nV_X\n#&gt; [1] 10800\n\n\n36.2.5 Funzioni in R per la Distribuzione Uniforme\nR offre diverse funzioni per manipolare la distribuzione uniforme:\n\n\nrunif: genera numeri casuali.\n\ndunif: calcola la densità per un valore specifico.\n\npunif: calcola la probabilità cumulativa fino a un valore.\n\nqunif: restituisce il quantile corrispondente a una probabilità specifica.\n\nEsempi pratici:\n\n# Densità per valori specifici\ndunif(c(0.5, 0.8, 1.2), min = 0, max = 1)\n#&gt; [1] 1 1 0\n\n# Probabilità cumulativa\npunif(c(0.5, 0.8), min = 0, max = 1)\n#&gt; [1] 0.5 0.8\n\n# Quantili\nqunif(c(0.5, 0.8), min = 0, max = 1)\n#&gt; [1] 0.5 0.8\n\n# Generazione di numeri casuali\nset.seed(123)\nrunif(5, min = 0, max = 1)\n#&gt; [1] 0.2876 0.7883 0.4090 0.8830 0.9405\n\nIn conclusione, la distribuzione uniforme fornisce una base fondamentale per comprendere i concetti di probabilità, densità e variabilità, ed è supportata da una gamma completa di strumenti in R per l’analisi e la simulazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-esponenziale",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-esponenziale",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "\n36.3 Distribuzione Esponenziale",
    "text": "36.3 Distribuzione Esponenziale\nLa distribuzione esponenziale è una distribuzione di probabilità continua ampiamente utilizzata per modellare il tempo di attesa fino al verificarsi di un evento. Questa distribuzione è caratterizzata dalla proprietà di assenza di memoria, che la rende unica.\n\n36.3.1 Proprietà di Assenza di Memoria\nL’assenza di memoria implica che la probabilità di un evento futuro è indipendente dal tempo già trascorso. Ad esempio, supponiamo che il tempo di rottura di un bicchiere da vino dopo il primo utilizzo segua una distribuzione esponenziale. Se un bicchiere non si è rotto dopo 3 anni, la probabilità che si rompa nel prossimo anno è uguale alla probabilità che un bicchiere nuovo si rompa nel primo anno di utilizzo.\n\n36.3.2 Funzione di densità\nLa funzione di densità di probabilità (PDF) per una variabile casuale esponenziale \\(X\\) è definita come:\n\\[\nf(x) = \\lambda e^{-\\lambda x}, \\quad \\lambda &gt; 0,\\, x \\geq 0,\n\\]\ndove \\(\\lambda\\) è il tasso di eventi per unità di tempo, pari all’inverso del tempo medio di attesa \\(\\mu\\):\n\\[\n\\lambda = \\frac{1}{\\mu}.\n\\]\nPertanto, possiamo esprimere la densità anche in funzione del tempo medio di attesa \\(\\mu\\):\n\\[\nf(x) = \\frac{1}{\\mu} e^{-x / \\mu}.\n\\]\n\n36.3.3 Proprietà principali\n\nMedia: \\[\nE(X) = \\frac{1}{\\lambda}.\n\\]\nVarianza: \\[\nV(X) = \\frac{1}{\\lambda^2}.\n\\]\nDeviazione standard: \\[\n\\sigma_X = \\frac{1}{\\lambda} = \\mu.\n\\]\n\n36.3.4 Esempio pratico\nSupponiamo che il tempo medio per la pubblicazione dei voti di un esame sia \\(\\mu = 4\\) giorni. La funzione di densità diventa:\n\\[\nf(x) = \\frac{1}{4} e^{-x / 4}.\n\\]\n\n36.3.5 Visualizzazione della distribuzione\nIn R, possiamo rappresentare la densità della distribuzione esponenziale con:\n\n# Parametri della distribuzione\nmu &lt;- 4\nlambda &lt;- 1 / mu\n\n# Generare valori per x\nx &lt;- seq(0, 20, by = 0.01)\n\n# Calcolare la densità\npdf &lt;- dexp(x, rate = lambda)\n\n# Grafico della densità\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(linewidth = 1, color = \"blue\") +\n  labs(\n    x = \"x\", y = \"f(x)\", \n    title = \"Funzione di densità della distribuzione esponenziale\"\n  )\n\n\n\n\n\n\n\n\n36.3.6 Calcolo delle probabilità\n\n36.3.6.1 Probabilità che \\(X \\leq 1.5\\)\n\nLa probabilità che il tempo di attesa sia minore o uguale a 1.5 giorni può essere calcolata utilizzando la funzione di ripartizione cumulativa (CDF):\n\\[\nP(X \\leq 1.5) = F(1.5) = 1 - e^{-\\lambda \\cdot 1.5}.\n\\]\nIn R:\n\npexp(1.5, rate = lambda)\n#&gt; [1] 0.3127\n\nVisualizziamo questa probabilità come l’area sotto la curva fino a \\(x = 1.5\\):\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(linewidth = 1, color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, pdf), x &lt;= 1.5), \n    aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5\n  ) +\n  labs(\n    x = \"x\", y = \"f(x)\", \n    title = \"Probabilità P(X &lt;= 1.5)\"\n  )\n\n\n\n\n\n\n\n\n36.3.6.2 Probabilità che \\(1 \\leq X \\leq 6\\)\n\nQuesta probabilità si calcola come differenza tra le funzioni di ripartizione:\n\\[\nP(1 \\leq X \\leq 6) = F(6) - F(1).\n\\]\nIn R:\n\npexp(6, rate = lambda) - pexp(1, rate = lambda)\n#&gt; [1] 0.5557\n\nVisualizziamo l’area corrispondente:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(linewidth = 1, color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, pdf), x &gt;= 1 & x &lt;= 6), \n    aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5\n  ) +\n  labs(\n    x = \"x\", y = \"f(x)\", \n    title = \"Probabilità P(1 &lt;= X &lt;= 6)\"\n  )\n\n\n\n\n\n\n\n\n36.3.6.3 Probabilità che \\(X \\geq 5.5\\)\n\nLa probabilità può essere calcolata come evento complementare:\n\\[\nP(X \\geq 5.5) = 1 - F(5.5).\n\\]\nIn R:\n\n1 - pexp(5.5, rate = lambda)\n#&gt; [1] 0.2528\n# Oppure\npexp(5.5, rate = lambda, lower.tail = FALSE)\n#&gt; [1] 0.2528\n\nVisualizziamo l’area sotto la curva per \\(x \\geq 5.5\\):\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(linewidth = 1, color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, pdf), x &gt;= 5.5), \n    aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5\n  ) +\n  labs(\n    x = \"x\", y = \"f(x)\", \n    title = \"Probabilità P(X &gt;= 5.5)\"\n  )\n\n\n\n\n\n\n\n\n36.3.7 Istogramma di valori simulati\nSimuliamo 1.000.000 di valori casuali da una distribuzione esponenziale con \\(\\lambda = 1/4\\) e costruiamo un istogramma confrontato con la densità teorica:\n\n# Simulazione di valori casuali\nset.seed(123)\nsamples &lt;- rexp(1000000, rate = lambda)\n\n# Istogramma con densità sovrapposta\nggplot(data.frame(samples), aes(x = samples)) +\n  geom_histogram(\n    aes(y = after_stat(density)), bins = 100, \n    fill = \"skyblue\", color = \"black\", alpha = 0.5\n  ) +\n  geom_line(\n    data = data.frame(x, pdf), aes(x = x, y = pdf), \n    color = \"red\", linewidth = 1\n  ) +\n  xlim(0, 20) +\n  labs(\n    x = \"Tempo di attesa\", y = \"Frequenza relativa\",\n    title = \"Istogramma dei valori simulati con densità teorica\"\n  )\n\n\n\n\n\n\n\nIn conclusione, la distribuzione esponenziale è uno strumento essenziale per modellare eventi che dipendono dal tempo di attesa. Grazie alla sua semplicità e alla proprietà di assenza di memoria, è particolarmente utile in molti contesti applicativi. Con le funzioni di R (dexp, pexp, qexp, rexp), è possibile analizzare e visualizzare facilmente i dati che seguono questa distribuzione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-normale",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-normale",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "\n36.4 Distribuzione Normale",
    "text": "36.4 Distribuzione Normale\nLa distribuzione normale, anche nota come distribuzione gaussiana, è una delle distribuzioni di probabilità più importanti in statistica. Deve il suo nome a Carl Friedrich Gauss, che ne scoprì l’utilità per modellare gli errori di misurazione. Adolphe Quetelet, uno dei padri delle scienze sociali quantitative, fu il primo a utilizzare questa distribuzione per studiare le misurazioni dell’uomo. Karl Pearson introdusse il termine “normale”, pur riconoscendo che ciò potesse erroneamente suggerire l’anormalità di altre distribuzioni.\n\n36.4.1 Una famiglia di distribuzioni\nLa distribuzione normale non è unica, ma rappresenta una famiglia di distribuzioni definite da due parametri:\n\n\n\\(\\mu\\) (media): il valore attorno al quale i dati sono simmetricamente distribuiti.\n\n\\(\\sigma\\) (deviazione standard): misura la dispersione dei dati attorno alla media.\n\nLa densità di probabilità per una variabile casuale continua \\(Y\\) che segue una distribuzione normale è data da:\n\\[\nf(y; \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y - \\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma &gt; 0\\).\nQuesta curva ha una caratteristica forma a campana, simmetrica rispetto alla media \\(\\mu\\). La media, la mediana e la moda coincidono.\n\n36.4.2 Origini storiche: dal binomiale alla normale\nLa connessione tra distribuzioni binomiali e normali fu notata da Abraham de Moivre nel 1733. Egli osservò che, aumentando il numero di prove di una distribuzione binomiale, la forma della distribuzione si avvicina a quella di una curva normale. Questo fenomeno può essere illustrato confrontando distribuzioni binomiali con pochi e molti eventi.\n\n36.4.3 Distribuzione binomiale con poche prove\nCon un numero di prove \\(n = 10\\) e una probabilità di successo \\(p = 0.9\\), la distribuzione binomiale è chiaramente asimmetrica:\n\n# Parametri\nn &lt;- 10\np &lt;- 0.9\n\n# Calcolo della distribuzione binomiale\nr_values &lt;- 0:n\ndist &lt;- dbinom(r_values, size = n, prob = p)\n\n# Grafico\nggplot(data.frame(Successi = r_values, Probabilità = dist), aes(x = Successi, y = Probabilità)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Distribuzione Binomiale: n = 10, p = 0.9\", \n    x = \"Numero di Successi\", y = \"Probabilità\"\n  )\n\n\n\n\n\n\n\n\n36.4.4 Distribuzione binomiale con molte prove\nAumentando il numero di prove a \\(n = 1000\\) con lo stesso \\(p\\), la distribuzione assume una forma più simmetrica, simile a quella della normale:\n\n# Parametri aggiornati\nn &lt;- 1000\n\n# Calcolo della distribuzione binomiale\nr_values &lt;- 850:950  # Intervallo per una migliore visualizzazione\ndist &lt;- dbinom(r_values, size = n, prob = p)\n\n# Grafico\nggplot(data.frame(Successi = r_values, Probabilità = dist), aes(x = Successi, y = Probabilità)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Distribuzione Binomiale: n = 1000, p = 0.9\", \n    x = \"Numero di Successi\", y = \"Probabilità\"\n  )\n\n\n\n\n\n\n\n\n36.4.5 La normale generata da simulazioni\nUn modo intuitivo per comprendere la distribuzione normale è attraverso la simulazione di passeggiate casuali. Immaginiamo che 1000 persone partano da una posizione iniziale e facciano 16 passi, ciascuno determinato da un lancio di moneta che stabilisce se avanzare o arretrare. Dopo 16 passi, la distribuzione delle loro posizioni segue una curva normale.\n\n# Parametri\nnumero_passi &lt;- 16\nripetizioni &lt;- 1000\n\n# Generazione di passeggiate casuali\nset.seed(123)\nx &lt;- matrix(0, nrow = numero_passi + 1, ncol = ripetizioni)\n\nfor (i in 1:ripetizioni) {\n  passi &lt;- runif(numero_passi, min = -1, max = 1)\n  x[-1, i] &lt;- cumsum(passi)\n}\n\n# Grafico delle passeggiate casuali\ndf &lt;- data.frame(\n  Passo = rep(0:numero_passi, times = ripetizioni), \n  Distanza = as.vector(x)\n)\n\nggplot(\n  df, \n  aes(\n    x = Passo, \n    y = Distanza, \n    group = rep(1:ripetizioni, each = numero_passi + 1))\n  ) +\n  geom_line(color = \"blue\", alpha = 0.05) +\n  labs(\n    title = \"Passeggiate Casuali\", \n    x = \"Numero di Passi\", y = \"Distanza dall'Origine\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#proprietà-della-distribuzione-normale",
    "href": "chapters/probability/13_cont_rv_distr.html#proprietà-della-distribuzione-normale",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "\n36.5 Proprietà della distribuzione normale",
    "text": "36.5 Proprietà della distribuzione normale\n\n36.5.1 Media e varianza\n\n\nMedia: \\(\\mathbb{E}(Y) = \\mu\\)\n\n\nVarianza: \\(\\mathbb{V}(Y) = \\sigma^2\\)\n\n\n36.5.2 Regola empirica\nNella normale, una proporzione nota dei dati cade entro 1, 2 o 3 deviazioni standard dalla media:\n\n\n68.3% tra \\([\\mu - \\sigma, \\mu + \\sigma]\\)\n\n\n95.6% tra \\([\\mu - 2\\sigma, \\mu + 2\\sigma]\\)\n\n\n99.7% tra \\([\\mu - 3\\sigma, \\mu + 3\\sigma]\\)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-normale-standard",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-normale-standard",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "\n36.6 Distribuzione normale standard",
    "text": "36.6 Distribuzione normale standard\nLa normale standard è un caso speciale della normale con \\(\\mu = 0\\) e \\(\\sigma = 1\\). Ogni normale può essere trasformata in una normale standard attraverso la formula:\n\\[\nZ = \\frac{Y - \\mu}{\\sigma}.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#funzioni-principali-in-r",
    "href": "chapters/probability/13_cont_rv_distr.html#funzioni-principali-in-r",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "\n36.7 Funzioni principali in R",
    "text": "36.7 Funzioni principali in R\nR offre funzioni integrate per la distribuzione normale:\n\n\ndnorm(): calcola la densità di probabilità.\n\n\npnorm(): calcola la funzione cumulativa (CDF).\n\n\nqnorm(): restituisce i quantili della distribuzione.\n\n\nrnorm(): genera valori casuali.\n\n\n36.7.1 Esempi\n\n\nDensità:\n\ndnorm(115, mean = 100, sd = 15)\n#&gt; [1] 0.01613\n\n\n\nProbabilità cumulativa:\n\npnorm(115, mean = 100, sd = 15)\n#&gt; [1] 0.8413\n\n\n\nQuantili:\n\nqnorm(0.975, mean = 100, sd = 15)\n#&gt; [1] 129.4\n\n\n\nValori casuali:\n\nset.seed(123)\nrnorm(10, mean = 100, sd = 15)\n#&gt;  [1]  91.59  96.55 123.38 101.06 101.94 125.73 106.91  81.02  89.70  93.32",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#visualizzazione",
    "href": "chapters/probability/13_cont_rv_distr.html#visualizzazione",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "\n36.8 Visualizzazione",
    "text": "36.8 Visualizzazione\nEsempio di confronto tra PDF, CDF e quantili:\n\n# Importare le librerie necessarie\nlibrary(gridExtra)\n\n# Definire i parametri\nmu &lt;- 100\nsigma &lt;- 15\n\n# Generare l'intervallo di valori per x\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 1000)\n\n# PDF\npdf_plot &lt;- ggplot(\n  data.frame(x = x, pdf = dnorm(x, mean = mu, sd = sigma)), \n  aes(x = x, y = pdf)\n  ) +\n  geom_line(color = \"blue\") +\n  labs(title = \"PDF\", x = \"Valori\", y = \"Densità\") \n\n# CDF\ncdf_plot &lt;- ggplot(\n  data.frame(x = x, cdf = pnorm(x, mean = mu, sd = sigma)), \n  aes(x = x, y = cdf)\n  ) +\n  geom_line(color = \"orange\") +\n  labs(title = \"CDF\", x = \"Valori\", y = \"Cumulativa\")\n\n# PPF\nquantiles &lt;- seq(0.01, 0.99, length.out = 100)\nppf_plot &lt;- ggplot(\n  data.frame(\n    Quantile = quantiles, \n    Valori = qnorm(quantiles, mean = mu, sd = sigma)\n  ), \n  aes(x = Quantile, y = Valori)\n  ) +\n  geom_line(color = \"green\") +\n  labs(title = \"PPF\", x = \"Quantile\", y = \"Valori\") \n\n# Mostrare i grafici\ngrid.arrange(pdf_plot, cdf_plot, ppf_plot, ncol = 3)\n\n\n\n\n\n\n\nLa distribuzione normale è alla base di numerosi metodi statistici ed è fondamentale per modellare dati reali e comprendere fenomeni naturali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "\n36.9 Distribuzione Chi-Quadrato",
    "text": "36.9 Distribuzione Chi-Quadrato\nLa distribuzione \\(\\chi^2\\) deriva dalla distribuzione normale e descrive la somma dei quadrati di \\(k\\) variabili casuali indipendenti e identicamente distribuite (i.i.d.) che seguono la distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Una variabile casuale \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libertà è definita come:\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]\ndove \\(Z_1, Z_2, \\dots, Z_k \\sim \\mathcal{N}(0, 1)\\). Il parametro \\(k\\), detto gradi di libertà (\\(\\nu\\)), determina la forma della distribuzione.\n\n36.9.1 Funzione di densità\nLa densità di probabilità della distribuzione \\(\\chi^2_{~\\nu}\\) è data da:\n\\[\nf(x) = C_{\\nu} x^{\\nu/2 - 1} \\exp(-x/2), \\quad \\text{per } x &gt; 0,\n\\]\ndove \\(C_{\\nu}\\) è una costante di normalizzazione.\n\n36.9.2 Simulazione della Distribuzione Chi-Quadrato\nUtilizziamo la definizione per simulare la distribuzione \\(\\chi^2\\) con 3 gradi di libertà.\n\n# Impostare il seed per la riproducibilità\nset.seed(1234)\n\n# Generare 1000 valori casuali per 3 variabili gaussiane standard\nn &lt;- 1000\nvar1 &lt;- rnorm(n, mean = 0, sd = 1)\nvar2 &lt;- rnorm(n, mean = 0, sd = 1)\nvar3 &lt;- rnorm(n, mean = 0, sd = 1)\n\n# Calcolare la somma dei quadrati\nchi_sq_values &lt;- var1^2 + var2^2 + var3^2\n\n# Creare un dataframe per il grafico\ndata &lt;- data.frame(chi_sq_values = chi_sq_values)\n\n# Istogramma e densità teorica\nggplot(data, aes(x = chi_sq_values)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7\n    ) +\n  stat_function(fun = dchisq, args = list(df = 3), color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione Chi-Quadrato (df = 3)\",\n    x = \"Valore\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nDescrizione:\n\nL’istogramma rappresenta i valori empirici simulati.\nLa curva rossa rappresenta la densità teorica della distribuzione \\(\\chi^2_{~3}\\).\n\n36.9.3 Media e Varianza Empiriche\nCalcoliamo la media e la varianza dei valori simulati:\n\n# Media empirica\nmean(chi_sq_values)\n#&gt; [1] 2.981\n\n# Varianza empirica\nvar(chi_sq_values)\n#&gt; [1] 5.968\n\nQuesti valori possono essere confrontati con le proprietà teoriche della distribuzione \\(\\chi^2\\):\n\n\nMedia: \\(\\nu = 3\\).\n\nVarianza: \\(2\\nu = 6\\).\n\n36.9.4 Grafico per Diversi Gradi di Libertà\nConfrontiamo le distribuzioni \\(\\chi^2\\) per diversi valori di \\(\\nu\\).\n\n# Intervallo di x\nx &lt;- seq(0, 40, by = 0.1)\n\n# Gradi di libertà\nnus &lt;- c(2, 4, 8, 16)\n\n# Creare un dataframe\ndata &lt;- do.call(rbind, lapply(nus, function(nu) {\n  data.frame(x = x, f_x = dchisq(x, df = nu), nu = as.factor(nu))\n}))\n\n# Grafico\nggplot(data, aes(x = x, y = f_x, color = nu)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzioni Chi-Quadrato per Diversi Valori di \\u03bd\",\n    x = \"x\",\n    y = \"f(x)\",\n    color = expression(nu)\n  ) \n\n\n\n\n\n\n\n\n36.9.5 Proprietà della Distribuzione Chi-Quadrato\n\n\nAsimmetria: La distribuzione \\(\\chi^2_{\\nu}\\) è asimmetrica, ma diventa più simmetrica al crescere di \\(\\nu\\).\n\nMedia: \\(\\mathbb{E}[\\chi^2_{\\nu}] = \\nu\\).\n\nVarianza: \\(\\mathbb{V}[\\chi^2_{\\nu}] = 2\\nu\\).\n\nConvergenza: Per \\(\\nu \\to \\infty\\), \\(\\chi^2_{\\nu} \\to \\mathcal{N}(\\nu, 2\\nu)\\).\n\nSomma: La somma di variabili \\(\\chi^2\\) indipendenti con gradi di libertà \\(\\nu_1, \\nu_2, \\dots, \\nu_k\\) segue una distribuzione \\(\\chi^2\\) con \\(\\nu = \\sum_{i=1}^k \\nu_i\\).\n\n36.9.6 Applicazioni\nLa distribuzione \\(\\chi^2\\) è utilizzata in molteplici ambiti statistici, tra cui:\n\n\nTest di indipendenza: Per verificare se due variabili categoriche sono indipendenti.\n\nTest di adattamento: Per confrontare una distribuzione empirica con una teorica.\n\nANOVA: Per valutare la variabilità nei dati.\n\nQuesta distribuzione è particolarmente importante in contesti di inferenza statistica e si trova alla base di numerosi test parametrici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "\n36.10 Distribuzione \\(t\\) di Student",
    "text": "36.10 Distribuzione \\(t\\) di Student\nLa distribuzione \\(t\\) di Student è una delle distribuzioni fondamentali della statistica inferenziale. Deriva dalle distribuzioni Normale e Chi-quadrato ed è particolarmente utile per analizzare campioni di piccole dimensioni o situazioni in cui la varianza della popolazione è sconosciuta.\n\n36.10.1 Definizione Formale\nSe:\n\n\n\\(Z \\sim \\mathcal{N}(0, 1)\\) (distribuzione Normale standard),\n\n\\(W \\sim \\chi^2_{\\nu}\\) (distribuzione Chi-quadrato con \\(\\nu\\) gradi di libertà),\n\ne \\(Z\\) e \\(W\\) sono indipendenti, allora la variabile casuale\n\\[\nT = \\frac{Z}{\\sqrt{\\frac{W}{\\nu}}}\n\\]\nsegue una distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libertà. Si indica come \\(T \\sim t_{\\nu}\\).\n\n36.10.2 Proprietà della Distribuzione \\(t\\) di Student\n\n\nForma della distribuzione:\n\nLa distribuzione \\(t\\) è simmetrica rispetto a zero, come la Normale standard (\\(\\mathcal{N}(0, 1)\\)).\nPresenta code più pesanti rispetto alla Normale, riflettendo una maggiore probabilità di osservare valori estremi.\n\n\n\nCode pesanti e gradi di libertà:\n\nLa pesantezza delle code diminuisce con l’aumentare dei gradi di libertà (\\(\\nu\\)).\nPer \\(\\nu \\to \\infty\\), la distribuzione \\(t\\) converge alla distribuzione Normale standard.\n\n\n\nMedia e varianza:\n\nLa media è \\(0\\) per \\(\\nu &gt; 1\\).\n\nLa varianza è:\n\\[\n\\text{Var}(T) = \\frac{\\nu}{\\nu - 2}, \\quad \\text{per } \\nu &gt; 2.\n\\]\nPer \\(\\nu \\leq 2\\), la varianza non è definita.\n\n\n\n\nApplicazioni principali:\n\n\nTest t di Student: Confronto delle medie di due gruppi o test per una singola media.\n\nIntervalli di confidenza: Stima dell’intervallo per la media quando la varianza è sconosciuta.\n\n\n\n36.10.3 Differenze tra la Distribuzione \\(t\\) e la Normale\n\n\n\n\n\n\n\nCaratteristica\nDistribuzione Normale\nDistribuzione \\(t\\) di Student\n\n\n\nForma\nSimmetrica, a campana\nSimmetrica, a campana\n\n\nCode\nSottili\nPesanti\n\n\nDipendenza dai gradi di libertà\nNo\nSì\n\n\nConvergenza\nNon varia\nCon \\(\\nu \\to \\infty\\), converge alla Normale\n\n\n\n36.10.4 Visualizzazione della Distribuzione \\(t\\)\n\nConfrontiamo graficamente la distribuzione \\(t\\) con diversi gradi di libertà e la distribuzione Normale standard:\n\n# Creazione dei dati\nx &lt;- seq(-4, 4, length.out = 1000)\ndf &lt;- c(1, 2, 5, 10)  # Gradi di libertà\n\n# Dataframe con curve di densità\ndata &lt;- data.frame(\n  x = rep(x, length(df) + 1),\n  density = c(\n    dnorm(x),\n    dt(x, df[1]),\n    dt(x, df[2]),\n    dt(x, df[3]),\n    dt(x, df[4])\n  ),\n  distribution = rep(c(\"Normale\", paste(\"t (df =\", df, \")\")), each = length(x))\n)\n\n# Plot\nggplot(data, aes(x = x, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzione Normale e distribuzioni $t$ di Student\",\n    x = \"Valore\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) \n\n\n\n\n\n\n\n\n36.10.5 Simulazione della Distribuzione \\(t\\)\n\nSimuliamo una distribuzione \\(t\\) con 10 gradi di libertà e confrontiamola con la densità teorica.\n\n# Impostare il seed per la riproducibilità\nset.seed(123)\n\n# Simulare 1000 valori da una distribuzione t\nn &lt;- 1000\ndf &lt;- 10  # Gradi di libertà\nt_values &lt;- rt(n, df = df)\n\n# Creare un dataframe per il grafico\ndata &lt;- data.frame(t_values = t_values)\n\n# Istogramma con densità teorica\nggplot(data, aes(x = t_values)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7\n  ) +\n  stat_function(fun = dt, args = list(df = df), color = \"red\", size = 1) +\n  labs(\n    title = paste(\"Distribuzione $t$ di Student (df =\", df, \")\"),\n    x = \"Valore\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n36.10.6 Proprietà Teoriche della Distribuzione \\(t\\)\n\n\nMedia: \\[\n\\mathbb{E}[T] = 0, \\quad \\text{per } \\nu &gt; 1.\n\\]\nVarianza: \\[\n\\mathbb{V}[T] = \\frac{\\nu}{\\nu - 2}, \\quad \\text{per } \\nu &gt; 2.\n\\]\n\nSimmetria:\n\nLa distribuzione è simmetrica rispetto a zero, come la Normale.\n\n\n\nCode:\n\nLe code sono più pesanti rispetto alla Normale, riflettendo una maggiore incertezza per piccoli campioni.\n\n\n\nIn conclusione, la distribuzione \\(t\\) di Student è uno strumento versatile nell’inferenza statistica, trovando applicazione in contesti sia frequentisti che bayesiani. È particolarmente utile in situazioni in cui la conoscenza della varianza è limitata o i campioni sono di dimensioni ridotte. Grazie alla sua forma simmetrica e alle code più pesanti rispetto alla distribuzione Normale, la distribuzione \\(t\\) può modellare meglio l’incertezza, includendo una maggiore probabilità per valori estremi.\nNel contesto bayesiano, la distribuzione \\(t\\) viene utilizzata come:\n\n\nPrior informativo robusto, per modellare parametri con valori plausibili lontani dalla media ma con una penalizzazione graduale per valori estremi.\n\nDistribuzione predittiva per sintetizzare l’incertezza derivante da campioni piccoli o con variabilità elevata.\n\nIn entrambi i paradigmi, la distribuzione \\(t\\) rappresenta una scelta robusta, capace di riflettere in modo flessibile la natura dei dati. Inoltre, per valori elevati dei gradi di libertà, la distribuzione \\(t\\) converge alla distribuzione Normale, un caso limite che ne estende ulteriormente l’utilità in vari contesti analitici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "chapters/probability/13_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "\n36.11 Funzione Beta di Eulero",
    "text": "36.11 Funzione Beta di Eulero\nLa funzione Beta di Eulero è una funzione matematica, non una densità di probabilità, ma è strettamente collegata alla distribuzione Beta, poiché appare nella sua definizione. Indicata comunemente con il simbolo \\(\\mathcal{B}(\\alpha, \\beta)\\), la funzione Beta può essere espressa in vari modi. Per i nostri scopi, utilizziamo la seguente definizione:\n\\[\n\\mathcal{B}(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\]\ndove \\(\\Gamma(x)\\) rappresenta la funzione Gamma, una generalizzazione del fattoriale definita per numeri reali positivi. Quando \\(x\\) è un numero intero, la funzione Gamma si riduce al fattoriale traslato:\n\\[\n\\Gamma(x) = (x-1)!.\n\\]\n\n36.11.1 Esempio di Calcolo\nSupponiamo di voler calcolare \\(\\mathcal{B}(3, 9)\\). Utilizzando la definizione, abbiamo:\n\\[\n\\mathcal{B}(3, 9) = \\frac{\\Gamma(3) \\cdot \\Gamma(9)}{\\Gamma(3 + 9)}.\n\\]\nIn R, possiamo calcolarla in tre modi diversi.\n\n36.11.1.1 Utilizzando la definizione con la funzione gamma():\n\nalpha &lt;- 3\nbeta &lt;- 9\n\nbeta_function &lt;- gamma(alpha) * gamma(beta) / gamma(alpha + beta)\nbeta_function\n#&gt; [1] 0.00202\n\n\n36.11.1.2 Utilizzando direttamente la funzione beta() di R:\n\nbeta(alpha, beta)\n#&gt; [1] 0.00202\n\n\n36.11.1.3 Calcolo manuale con fattoriali:\n\n(factorial(alpha - 1) * factorial(beta - 1)) / factorial(alpha + beta - 1)\n#&gt; [1] 0.00202\n\nTutti e tre i metodi restituiscono lo stesso risultato, confermando la correttezza della definizione.\n\n36.11.2 Rilevanza della Funzione Beta\nLa funzione Beta è centrale in probabilità e statistica, in particolare nella definizione della densità di probabilità Beta. Essa serve a normalizzare la densità, garantendo che l’area sotto la curva sia pari a \\(1\\). La connessione con la funzione Gamma ne amplia ulteriormente le applicazioni, rendendola uno strumento essenziale per descrivere relazioni fra distribuzioni e modelli.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-beta",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-beta",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "\n36.12 Distribuzione Beta",
    "text": "36.12 Distribuzione Beta\nLa distribuzione Beta, indicata come \\(\\mathcal{Beta}(\\alpha, \\beta)\\), è una distribuzione di probabilità continua definita sull’intervallo \\((0, 1)\\). È particolarmente utile per modellare proporzioni, probabilità o qualsiasi fenomeno limitato tra 0 e 1. La sua flessibilità la rende adatta a molte applicazioni, sia in ambito frequentista che bayesiano.\n\n36.12.1 Definizione Formale\nSe una variabile casuale \\(\\theta\\) segue una distribuzione Beta con parametri \\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\), indicata come \\(\\theta \\sim \\mathcal{Beta}(\\alpha, \\beta)\\), la sua funzione di densità è data da:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}, \\quad \\theta \\in (0, 1),\n\\]\ndove:\n\n\n\\(B(\\alpha, \\beta)\\) è la funzione Beta di Eulero, definita come:\n\n\\[\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)},\n\\]\n\n\n\\(\\Gamma(x)\\) è la funzione Gamma.\n\nUn’altra rappresentazione equivalente è:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}.\n\\]\n\n36.12.2 Ruolo dei Parametri \\(\\alpha\\) e \\(\\beta\\)\n\nI parametri \\(\\alpha\\) e \\(\\beta\\) determinano la forma della distribuzione:\n\n\n\\(\\alpha &gt; 1\\): favorisce valori di \\(\\theta\\) vicini a 1.\n\n\\(\\beta &gt; 1\\): favorisce valori di \\(\\theta\\) vicini a 0.\n\n\\(\\alpha = \\beta = 1\\): corrisponde alla distribuzione uniforme sull’intervallo \\([0, 1]\\).\n\n\\(\\alpha, \\beta &lt; 1\\): la distribuzione è bimodale, concentrandosi agli estremi (vicino a 0 e 1).\n\n36.12.3 Proprietà della Distribuzione Beta\n\nValore atteso: \\[\n\\mathbb{E}(\\theta) = \\frac{\\alpha}{\\alpha + \\beta}.\n\\]\nVarianza: \\[\n\\mathbb{V}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}.\n\\]\nModa (se \\(\\alpha, \\beta &gt; 1\\)): \\[\n\\text{Moda}(\\theta) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2}.\n\\]\n\nQueste proprietà evidenziano come \\(\\alpha\\) e \\(\\beta\\) possano essere interpretati come “successi” e “fallimenti” in una serie di prove, fornendo un collegamento intuitivo con la distribuzione binomiale.\n\n36.12.4 Relazione con la Distribuzione Binomiale\nLa distribuzione Beta può essere vista come una generalizzazione continua della distribuzione binomiale. In particolare, mentre la distribuzione binomiale modella il numero di successi in una serie di prove, la distribuzione Beta modella la probabilità di successo come una variabile casuale.\nNell’inferenza bayesiana, la distribuzione Beta è spesso utilizzata come prior coniugato per la distribuzione binomiale. Ad esempio:\n\nSe \\(\\theta \\sim \\mathcal{Beta}(\\alpha, \\beta)\\) è il prior,\nE osserviamo \\(x\\) successi in \\(n\\) prove, allora la distribuzione a posteriori è:\n\n\\[\n\\theta \\mid \\text{dati} \\sim \\mathcal{Beta}(\\alpha + x, \\beta + n - x).\n\\]\nQuesta proprietà consente un aggiornamento semplice delle credenze basato sui dati osservati.\n\n36.12.5 Visualizzazione della Distribuzione Beta\nDi seguito mostriamo come la forma della distribuzione Beta varia al variare dei parametri \\(\\alpha\\) e \\(\\beta\\):\n\n# Parametri\nx &lt;- seq(0, 1, length.out = 200)\nalphas &lt;- c(0.5, 5.0, 1.0, 2.0, 2.0)\nbetas &lt;- c(0.5, 1.0, 3.0, 2.0, 5.0)\n\n# Creare un dataframe\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dbeta(x, alphas[i], betas[i]),\n    label = paste0(\"α = \", alphas[i], \", β = \", betas[i])\n  )\n}))\n\n# Plot\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzioni Beta\"\n  ) +\n  theme(legend.title = element_blank(), legend.position = \"top\")\n\n\n\n\n\n\n\n\n36.12.6 Costante di Normalizzazione\nLa costante di normalizzazione della distribuzione Beta è il reciproco della funzione Beta di Eulero, \\(B(\\alpha, \\beta)\\). Questa garantisce che:\n\\[\n\\int_0^1 \\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) \\, d\\theta = 1.\n\\]\nAd esempio, calcoliamo \\(B(3, 9)\\) in R utilizzando tre approcci:\nUsando la funzione Gamma:\n\nalpha &lt;- 3\nbeta &lt;- 9\nbeta_function &lt;- gamma(alpha) * gamma(beta) / gamma(alpha + beta)\nbeta_function\n#&gt; [1] 0.00202\n\nUsando la funzione beta():\n\nbeta(alpha, beta)\n#&gt; [1] 0.00202\n\nCalcolo manuale:\n\nfactorial(alpha - 1) * factorial(beta - 1) / factorial(alpha + beta - 1)\n#&gt; [1] 0.00202\n\n\n36.12.7 Applicazioni della Distribuzione Beta\n\n\nModellazione di proporzioni:\n\nPercentuali di successo in esperimenti.\nPercentuali di risposte in sondaggi.\n\n\n\nInferenza Bayesiana:\n\nLa Beta è prior coniugato per modelli basati su prove di Bernoulli o distribuzioni binomiali.\n\n\n\nStime robuste:\n\nLa flessibilità della Beta permette di rappresentare credenze iniziali con diverse incertezze.\n\n\n\nIn conclusione, la distribuzione Beta è un potente strumento matematico e statistico. La sua flessibilità nel modellare proporzioni e probabilità, insieme alla semplicità di aggiornamento nell’inferenza bayesiana, la rende essenziale per molteplici applicazioni, dall’analisi dei dati al machine learning. La sua relazione con la funzione Beta di Eulero e con la distribuzione binomiale la collega a fondamenta matematiche solide e ampiamente utilizzate.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "\n36.13 Distribuzione di Cauchy",
    "text": "36.13 Distribuzione di Cauchy\nLa distribuzione di Cauchy è un caso speciale della distribuzione \\(t\\) di Student con un solo grado di libertà (\\(t_1\\)). Questa distribuzione è caratterizzata da code molto pesanti e da una media e varianza non definite, rendendola particolarmente utile in contesti dove valori estremi possono avere un’influenza importante.\n\n36.13.1 Funzione di Densità\nLa funzione di densità di probabilità della distribuzione di Cauchy è definita da due parametri:\n\n\n\\(\\alpha\\): posizione (location), che determina il centro della distribuzione.\n\n\\(\\beta &gt; 0\\): scala (scale), che controlla la larghezza della distribuzione.\n\nLa densità è data da:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{1}{\\pi \\beta \\left[1 + \\left( \\frac{x - \\alpha}{\\beta} \\right)^2\\right]} ,\n\\]\ndove:\n\n\n\\(x \\in \\mathbb{R}\\),\n\n\\(\\alpha \\in \\mathbb{R}\\),\n\n\\(\\beta &gt; 0\\).\n\nQuesta funzione descrive una distribuzione simmetrica attorno a \\(\\alpha\\), con code più pesanti rispetto alla distribuzione Normale.\n\n36.13.2 Proprietà della Distribuzione di Cauchy\n\n\nSimmetria: La distribuzione è simmetrica rispetto a \\(\\alpha\\).\n\nCode Pesanti: Le code sono significativamente più pesanti rispetto alla distribuzione Normale, con una decrescita più lenta (\\(\\propto x^{-2}\\)).\n\nMedia e Varianza: La distribuzione non ha una media né una varianza definita.\n\nRelazione con \\(t_1\\): La distribuzione di Cauchy è equivalente a una distribuzione \\(t\\) di Student con 1 grado di libertà.\n\nCaratteristiche Estreme: I valori estremi hanno una probabilità più alta rispetto ad altre distribuzioni comuni, rendendola utile per modellare fenomeni con outlier significativi.\n\n36.13.3 Visualizzazione della Distribuzione di Cauchy\nPer comprendere l’effetto dei parametri \\(\\alpha\\) e \\(\\beta\\) sulla forma della distribuzione, consideriamo alcuni esempi con:\n\n\n\\(\\alpha = 0.0, 0.0, 0.0, -2.0\\),\n\n\\(\\beta = 0.5, 1.0, 2.0, 1.0\\).\n\n\n# Definire i parametri\nx &lt;- seq(-5, 5, length.out = 500)\nalphas &lt;- c(0.0, 0.0, 0.0, -2.0)\nbetas &lt;- c(0.5, 1.0, 2.0, 1.0)\n\n# Creare un data frame per i risultati\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dcauchy(x, location = alphas[i], scale = betas[i]),\n    label = paste0(\"α = \", alphas[i], \", β = \", betas[i])\n  )\n}))\n\n# Grafico\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzioni di Cauchy con diversi parametri\"\n  ) +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n  )\n\n\n\n\n\n\n\n\n36.13.4 Applicazioni della Distribuzione di Cauchy\n\n\nInferenza Bayesiana:\n\nUtilizzata come prior robusto in modelli bayesiani, particolarmente quando si vuole attribuire una probabilità maggiore a valori estremi rispetto a una distribuzione Normale.\n\n\n\nModellazione di Fenomeni con Outlier:\n\nLa distribuzione di Cauchy è adatta per descrivere dati con valori estremi significativi che possono influenzare fortemente altre distribuzioni.\n\n\n\nAnalisi Teorica:\n\nEssendo una distribuzione con varianza non definita, viene spesso usata per dimostrare i limiti delle inferenze basate su media e varianza.\n\n\n\nIn conclusione, la distribuzione di Cauchy, con le sue proprietà uniche come code pesanti e l’assenza di media e varianza definite, è uno strumento fondamentale per modellare fenomeni in cui i valori estremi giocano un ruolo importante. La sua relazione con la distribuzione \\(t\\) di Student e la sua utilità nei modelli bayesiani ne ampliano ulteriormente le applicazioni in contesti statistici e probabilistici avanzati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-gamma",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-gamma",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "\n36.14 Distribuzione Gamma",
    "text": "36.14 Distribuzione Gamma\nLa distribuzione Gamma è una distribuzione di probabilità continua utilizzata principalmente per modellare variabili strettamente positive, come tassi, varianze, o tempi di attesa. È fondamentale nella statistica bayesiana come distribuzione a priori per parametri positivi e trova applicazione in ambiti come la modellazione di eventi rari o processi stocastici.\n\n36.14.1 Definizione Generale\nLa distribuzione Gamma è caratterizzata da due parametri principali:\n\n\nParametro di forma (\\(\\alpha\\)): determina la forma generale della distribuzione.\n\nParametro di scala (\\(\\theta\\)) o, alternativamente, il parametro di tasso (\\(\\beta = 1/\\theta\\)): regola la larghezza o la dispersione della distribuzione.\n\nLa funzione di densità di probabilità (PDF) è data da:\n\\[\nf(x \\mid \\alpha, \\theta) = \\frac{x^{\\alpha-1} e^{-x/\\theta}}{\\theta^\\alpha \\Gamma(\\alpha)}, \\quad x &gt; 0,\n\\]\ndove:\n\n\n\\(x\\) è la variabile casuale continua,\n\n\\(\\Gamma(\\alpha)\\) è la funzione Gamma di Eulero, definita come:\n\n\\[\n\\Gamma(\\alpha) = \\int_0^\\infty t^{\\alpha-1} e^{-t} dt.\n\\]\nSe utilizziamo il parametro di tasso \\(\\beta = 1/\\theta\\), la PDF può essere scritta come:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha x^{\\alpha-1} e^{-\\beta x}}{\\Gamma(\\alpha)}, \\quad x &gt; 0.\n\\]\n\n36.14.2 Relazioni con Altre Distribuzioni\n\n\nDistribuzione Esponenziale:\nLa distribuzione Gamma generalizza la distribuzione esponenziale. Quando \\(\\alpha = 1\\), la distribuzione Gamma coincide con una distribuzione esponenziale con parametro di tasso \\(\\beta\\).\n\\[\n\\text{Gamma}(1, \\beta) = \\text{Esponenziale}(\\beta).\n\\]\n\n\nTeorema del Limite Centrale:\nQuando il parametro di forma \\(\\alpha\\) è grande (\\(\\alpha \\to \\infty\\)), la distribuzione Gamma può essere approssimata da una distribuzione Normale con:\n\nMedia \\(\\mu = \\alpha \\cdot \\theta\\),\nVarianza \\(\\sigma^2 = \\alpha \\cdot \\theta^2\\).\n\n\n\nSomma di Variabili Esponenziali:\nLa distribuzione Gamma può essere vista come la somma di \\(\\alpha\\) variabili casuali indipendenti, ciascuna con una distribuzione esponenziale con lo stesso parametro di tasso \\(\\beta\\):\n\\[\n\\text{Gamma}(\\alpha, \\beta) = \\sum_{i=1}^\\alpha \\text{Esponenziale}(\\beta).\n\\]\n\n\n36.14.3 Proprietà della Distribuzione Gamma\n\nMedia: \\[\n\\mathbb{E}[X] = \\alpha \\cdot \\theta = \\frac{\\alpha}{\\beta}.\n\\]\nVarianza: \\[\n\\text{Var}(X) = \\alpha \\cdot \\theta^2 = \\frac{\\alpha}{\\beta^2}.\n\\]\nModa (per \\(\\alpha &gt; 1\\)): \\[\n\\text{Moda}(X) = (\\alpha - 1) \\cdot \\theta.\n\\]\n\n36.14.4 Parametri e Forma della Distribuzione\n\n\nParametro di Forma (\\(\\alpha\\)):\nControlla la distribuzione:\n\n\n\\(\\alpha &lt; 1\\): la distribuzione ha una coda lunga e si inclina verso valori bassi.\n\n\\(\\alpha = 1\\): la distribuzione è esponenziale.\n\n\\(\\alpha &gt; 1\\): la distribuzione ha una modalità (picco) in \\((\\alpha - 1) \\cdot \\theta\\).\n\n\n\nParametro di Scala (\\(\\theta\\)) o Tasso (\\(\\beta\\)):\n\nUn \\(\\theta\\) grande (\\(\\beta\\) piccolo) indica maggiore variabilità e una distribuzione più ampia.\nUn \\(\\theta\\) piccolo (\\(\\beta\\) grande) indica minore variabilità e una distribuzione più stretta.\n\n\n\n36.14.5 Visualizzazione della Distribuzione Gamma\nDi seguito, mostriamo un esempio per \\(\\alpha = 3\\) e \\(\\beta = 5/3\\), calcolando e rappresentando graficamente la distribuzione.\n\n36.14.5.1 Codice R\n\n\nCalcolo della Media e della Deviazione Standard:\n\n# Parametri\nalpha &lt;- 3\nbeta &lt;- 5 / 3\n\n# Calcolo\nmean &lt;- alpha / beta\nsigma &lt;- sqrt(alpha / beta^2)\n\ncat(\"Media:\", mean, \"\\n\")\n#&gt; Media: 1.8\ncat(\"Deviazione Standard:\", sigma, \"\\n\")\n#&gt; Deviazione Standard: 1.039\n\n\n\nGenerazione e Plot dei Dati:\n\n# Generazione di dati\nset.seed(123)\ndata &lt;- rgamma(100000, shape = alpha, rate = beta)\n\n# Data frame per ggplot\ndf &lt;- data.frame(values = data)\n\n# Plot\nggplot(df, aes(x = values)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"green\", alpha = 0.6) +\n  stat_function(fun = function(x) dgamma(x, shape = alpha, rate = beta),\n                color = \"red\", size = 1) +\n  labs(\n    x = \"Valore\",\n    y = \"Densità di probabilità\",\n    title = \"Distribuzione Gamma con α=3 e β=5/3\"\n  ) \n\n\n\n\n\n\n\n\n\n36.14.6 Applicazioni della Distribuzione Gamma\n\nModellazione del Tempo di Attesa:\nLa distribuzione Gamma è ideale per modellare tempi di attesa, ad esempio, il tempo necessario affinché si verifichino \\(n\\) eventi in un processo di Poisson.\n\nInferenza Bayesiana:\n\nUtilizzata come prior per parametri positivi, come tassi (\\(\\lambda\\)) o varianze (\\(\\sigma^2\\)).\nAd esempio, nella modellazione bayesiana dei processi di Poisson, una distribuzione Gamma è una scelta naturale per il prior su \\(\\lambda\\).\n\n\n\nBiologia:\n\nIn biologia, trova applicazione nella modellazione di tassi di mutazione o sopravvivenza.\n\n\n\nIn conclusione, la distribuzione Gamma è una distribuzione versatile, adatta per modellare una varietà di fenomeni strettamente positivi. Grazie alla sua flessibilità e alla relazione con altre distribuzioni, come l’esponenziale e la normale, rappresenta uno strumento essenziale sia nella statistica frequentista che in quella bayesiana. La parametrizzazione tramite \\(\\alpha\\) e \\(\\theta\\) consente un controllo preciso sulla forma e la dispersione, rendendola applicabile a molteplici ambiti, dalla scienza ai modelli finanziari.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/13_cont_rv_distr.html#riflessioni-conclusive",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "\n36.15 Riflessioni conclusive",
    "text": "36.15 Riflessioni conclusive\nLe distribuzioni di probabilità costituiscono il cuore dell’inferenza statistica, sia bayesiana che frequentista. In questo capitolo, abbiamo esplorato come R offre un insieme completo di strumenti per lavorare con diverse distribuzioni, permettendo di modellare e analizzare una vasta gamma di fenomeni.\n\n36.15.1 Principali Applicazioni\n\n\nInferenza Bayesiana:\nLe distribuzioni di probabilità, come la Beta, la Gamma e la Normale, sono essenziali per definire priors, calcolare posteriori e quantificare l’incertezza nei modelli bayesiani. Ad esempio:\n\nLa distribuzione Beta è ideale per modellare credenze a priori su proporzioni o probabilità.\nLa distribuzione Gamma è ampiamente usata per modellare parametri positivi come tassi o varianze.\n\n\nAnalisi Statistica e Modellazione:\nLe distribuzioni, come la (t) di Student, sono fondamentali per il confronto tra campioni, mentre la Normale è indispensabile per modellare fenomeni che seguono la legge del limite centrale.\nGenerazione e Simulazione di Dati:\nR permette di generare campioni casuali da distribuzioni comuni, utili per simulazioni, bootstrap e validazione di modelli.\n\n36.15.2 Funzionalità di R\nCon poche funzioni, R consente di:\n\n\nGenerare campioni casuali: con funzioni come rnorm, rgamma, rbeta, possiamo simulare dati da distribuzioni specifiche.\n\nCalcolare densità: ad esempio, con dnorm, dgamma, dbeta, possiamo visualizzare le funzioni di densità.\n\nCalcolare probabilità cumulate: con funzioni come pnorm, pbeta, possiamo determinare probabilità su intervalli specifici.\n\nDeterminare quantili: con funzioni come qnorm, qgamma, possiamo calcolare i punti corrispondenti a specifici livelli di probabilità.\n\n36.15.3 Versatilità delle Distribuzioni\nLe distribuzioni esplorate non solo descrivono fenomeni naturali, ma sono anche i “mattoncini” per costruire modelli statistici complessi. Le loro proprietà, come la media, la varianza, la simmetria o le code pesanti, consentono di adattare il modello al fenomeno studiato.\nIn conclusione, il linguaggio R, con la sua flessibilità e ricchezza di strumenti, permette di padroneggiare le distribuzioni di probabilità, non solo come oggetti matematici, ma anche come strumenti pratici per rispondere a domande complesse. La comprensione e l’uso delle distribuzioni presentate costituiscono le fondamenta per avanzare verso tecniche più sofisticate, come l’inferenza bayesiana avanzata o la modellazione gerarchica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/13_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#bibliografia",
    "href": "chapters/probability/13_cont_rv_distr.html#bibliografia",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html",
    "href": "chapters/probability/14_gauss.html",
    "title": "37  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "",
    "text": "37.1 Introduzione\nNell’analisi dei dati numerici, un aspetto cruciale da affrontare è l’imprecisione delle misurazioni, una caratteristica intrinseca dei dati reali. Anche in condizioni ottimali, le misure sono soggette a incertezze: i dati rappresentano sempre una stima approssimativa della realtà, accurata solo entro un certo margine (ad esempio, pochi punti percentuali). Inoltre, in molti contesti, come quelli demografici, commerciali o sociali, i dati possono essere arrotondati intenzionalmente o risultare imprecisi a causa di stime indirette, incompletezza delle informazioni o altri fattori.\nRiconoscere e gestire questa incertezza è una componente essenziale del processo analitico. Gli strumenti statistici forniscono un framework formale per descrivere e quantificare l’incertezza, consentendo di trarre inferenze robuste dai dati. Tra le distribuzioni di probabilità, la distribuzione normale (o gaussiana) occupa un posto centrale per la sua ubiquità e versatilità. Spesso rappresentata dalla caratteristica “curva a campana,” questa distribuzione è utilizzata per descrivere molte variabili naturali. Quando i dati approssimano una distribuzione normale, gran parte dei valori si concentra intorno alla media, con una diminuzione progressiva della probabilità di valori estremi.\nUna delle proprietà più utili della distribuzione normale è la possibilità di esprimere affermazioni quantitative rigorose. Ad esempio, si può calcolare la probabilità che un valore cada entro un determinato intervallo dalla media utilizzando parametri semplici come media (\\(\\mu\\)) e deviazione standard (\\(\\sigma\\)):\npnorm(1) - pnorm(-1)\n#&gt; [1] 0.6827\npnorm(3) - pnorm(-3)\n#&gt; [1] 0.9973\nQuesti calcoli costituiscono la base della “regola delle tre sigma,” una strategia utilizzata per identificare valori anomali (outlier), come discusso nel Capitolo 23. Tuttavia, tale regola può risultare fuorviante se i dati non seguono effettivamente una distribuzione normale.\nLa densità della distribuzione normale è definita dalla formula:\n\\[\np(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(\\mu\\) rappresenta la media e \\(\\sigma\\) la deviazione standard. Conoscere questi due parametri permette di calcolare proprietà fondamentali della distribuzione e di stimare probabilità associate a intervalli specifici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#introduzione",
    "href": "chapters/probability/14_gauss.html#introduzione",
    "title": "37  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "",
    "text": "Circa il 68.3% dei valori cade entro una deviazione standard dalla media:\n\n\n\nCirca il 99.7% cade entro tre deviazioni standard:\n\n\n\n\n\n\n\n37.1.1 Gaussianità e Inferenza Statistica\nLa distribuzione normale è particolarmente rilevante per molti metodi statistici, in particolare nell’approccio frequentista. Gran parte dei test di ipotesi e delle procedure inferenziali assume che i dati siano distribuiti normalmente, una condizione necessaria per derivare formalmente i risultati di molti test. Ad esempio, i test t di Student e l’ANOVA richiedono la normalità delle variabili o dei residui. Quando questa assunzione è soddisfatta, tali strumenti offrono inferenze precise e affidabili.\nTuttavia, se i dati non sono gaussiani, molti test perdono validità. Sebbene si siano proposti approcci che dimostrano la robustezza di alcuni test a deviazioni moderate dalla normalità (Shatz, 2024), tale robustezza non è garantita in tutte le situazioni. Inoltre, l’enfasi sui valori-p complica la questione, poiché violazioni dell’assunzione di normalità possono compromettere l’interpretazione di questi indicatori.\nUna strategia comune per affrontare la non-gaussianità è l’applicazione di trasformazioni dei dati, come la trasformazione logaritmica o quella della radice quadrata, per avvicinare i dati alla distribuzione normale (Osborne, 2002). Ad esempio, distribuzioni asimmetriche come quelle dei tempi di reazione possono essere rese più gaussiane attraverso trasformazioni adeguate, rendendo applicabili i test frequentisti standard. Tuttavia, l’uso delle trasformazioni ha un costo: la perdita di interpretabilità. Se i dati originali avevano un significato chiaro e intuitivo, la trasformazione può rendere i risultati più difficili da collegare al fenomeno studiato.\nIn questo capitolo, esploreremo come verificare se i dati seguono una distribuzione normale, discuteremo l’impatto di questa assunzione sui metodi frequentisti e valuteremo il ruolo delle trasformazioni. Il nostro obiettivo è fornire al data analyst una guida pratica per decidere come trattare i dati non gaussiani, considerando sia i vantaggi che i limiti di ciascun approccio.\n\n37.1.2 L’assunzione di Gaussianità: Quando è valida?\nSebbene la distribuzione normale sia spesso un buon modello per i dati numerici, non è sempre una rappresentazione adeguata. Questo può dipendere da caratteristiche intrinseche dei dati, come asimmetrie, code lunghe o la presenza di valori anomali. Valutare l’appropriatezza dell’assunzione di normalità è un passaggio critico in qualsiasi analisi statistica.\nPer diagnosticare la normalità, presenteremo tre strumenti grafici:\n\n\nIstogrammi, una visualizzazione semplice ma spesso limitata.\n\nGrafici di densità, che forniscono un confronto più fluido rispetto agli istogrammi.\n\nQQ-plot (Quantile-Quantile plot), uno strumento visivo particolarmente efficace per rilevare deviazioni dalla normalità.\n\nQuesti strumenti possono anche essere affiancati da test formali per consentire una diagnosi robusta e guidare le decisioni sul trattamento dei dati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#istogramma",
    "href": "chapters/probability/14_gauss.html#istogramma",
    "title": "37  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n37.2 Istogramma",
    "text": "37.2 Istogramma\nPer illustrare il concetto, utilizziamo un set di dati simulati che hanno proprietà simili a quelle dei tempi di reazione. Creeremo un istogramma e vi sovrapporremo la curva di densità normale calcolata in base ai dati.\n\n# Dati simulati di tempi di reazione\nset.seed(123)\nrt &lt;- c(rexp(100, rate = 0.2), 50, 60) # Aggiunti valori estremi\n\n# Calcolare la media e la deviazione standard per sovrapporre la densità normale\nmean_rt &lt;- mean(rt, na.rm = TRUE)\nsd_rt &lt;- sd(rt, na.rm = TRUE)\n\n# Creare l'istogramma e sovrapporre la densità normale\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30, color = \"black\"\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    size = 1\n  ) +\n  labs(\n    title = \"Istogramma dei Tempi di Reazione\\ne Densità Normale\",\n    x = \"Tempi di Reazione\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nL’istogramma mostra la distribuzione empirica dei dati, mentre la curva rossa rappresenta la densità normale con la stessa media e deviazione standard. Nel nostro caso, è evidente una discrepanza tra la distribuzione empirica e la densità normale, indicando che l’assunzione di normalità non è appropriata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#grafico-di-densità",
    "href": "chapters/probability/14_gauss.html#grafico-di-densità",
    "title": "37  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n37.3 Grafico di densità",
    "text": "37.3 Grafico di densità\nUn grafico di densità è una versione lisciata dell’istogramma che facilita il confronto con la distribuzione normale. Utilizzando il dataset precedente, possiamo creare un grafico di densità sovrapposto alla curva gaussiana.\n\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_density(alpha = 0.5) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    size = 1\n  ) +\n  labs(\n    title = \"Grafico di Densità del Peso dei Pulcini e\\nDensità Normale\",\n    x = \"Peso\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nAnche questa rappresentazione rende chiaro come l’assunzione di normalità non sia appropriata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#diagramma-quantile-quantile",
    "href": "chapters/probability/14_gauss.html#diagramma-quantile-quantile",
    "title": "37  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n37.4 Diagramma quantile-quantile",
    "text": "37.4 Diagramma quantile-quantile\nIl diagramma quantile-quantile (QQ-plot) è lo strumento più utile per analizzare visivamente la conformità di un dataset a una distribuzione teorica, in particolare alla distribuzione normale. Il QQ-plot è una tecnica essenziale per chi lavora con dati che si presume seguano una distribuzione specifica, e rappresenta un passaggio cruciale in molte analisi statistiche, soprattutto per verificare l’assunto di normalità.\nUn QQ-plot permette di:\n\n\nValutare graficamente la normalità dei dati: Se i punti nel diagramma seguono approssimativamente una linea retta, i dati possono essere considerati normalmente distribuiti. In caso contrario, il QQ-plot rivela deviazioni dalla normalità, come code pesanti o asimmetrie.\n\nConfrontare distribuzioni: Il QQ-plot non si limita solo alla distribuzione normale, ma può essere utilizzato per confrontare la distribuzione del campione con qualsiasi distribuzione teorica, facilitando l’analisi di dati con forme di distribuzione complesse.\n\nIdentificare outlier: Gli outlier nei dati saranno visibili come punti che si discostano significativamente dalla linea retta del QQ-plot.\n\nIl QQ-plot è costruito tracciando i quantili del campione contro i quantili teorici di una distribuzione di riferimento. L’interpretazione è piuttosto semplice:\n\nSe il campione segue la distribuzione teorica, i punti nel QQ-plot si allineano lungo una linea retta di pendenza 1 (e intercetta 0 nel caso di distribuzione normale standardizzata).\nLa deviazione dalla linea retta indica differenze nella distribuzione del campione rispetto alla distribuzione teorica:\n\n\nIntercetta diversa da 0: indica che la media del campione differisce dalla media della distribuzione teorica.\n\nPendenza diversa da 1: indica una differenza nella varianza tra il campione e la distribuzione teorica.\n\nCurve: indicano deviazioni sistematiche, come code pesanti o distribuzioni asimmetriche.\n\n\n\nNella discussione seguente, costruiremo e analizzeremo QQ-plot per tre casi tipici:\n\n\nCampione con stessa media e varianza della distribuzione teorica.\n\nCampione con media diversa ma stessa varianza.\n\nCampione con media e varianza diverse.\n\nSimuleremo i dati, li ordineremo, calcoleremo manualmente i quantili teorici e infine utilizzeremo librerie specializzate per replicare e confrontare i risultati. Questo approccio pratico ci permetterà di comprendere a fondo l’utilità e il funzionamento del QQ-plot.\n\n37.4.1 Comprendere e Costruire un QQ-Plot (Distribuzione Normale)\nUn QQ-plot (Quantile-Quantile plot) è uno strumento grafico utilizzato per confrontare la distribuzione di un campione con una distribuzione teorica, spesso la distribuzione normale. Il QQ-plot aiuta a visualizzare se un dataset segue una distribuzione specifica, tracciando i quantili del campione contro i quantili della distribuzione teorica.\n\n37.4.2 Passi per Costruire un QQ-Plot\n\n\nOrdinare i Dati: Disporre i dati del campione in ordine crescente.\n\nDeterminare i Quantili Teorici: Per una distribuzione normale, i quantili corrispondono all’inverso della funzione di distribuzione cumulativa (CDF) della distribuzione normale.\n\nConfrontare i Quantili: Tracciare i quantili del campione rispetto ai quantili della distribuzione teorica. Se il campione proviene dalla distribuzione teorica, i punti dovrebbero trovarsi approssimativamente su una linea retta.\n\n37.4.3 Caso 1: Campione con Stessa Media e Varianza della Distribuzione Normale\nSupponiamo che il campione provenga da una distribuzione normale \\(N(\\mu = 0, \\sigma^2 = 1)\\), esattamente come la distribuzione teorica.\n\n37.4.3.1 Simulazione dei Dati\nIniziamo simulando un piccolo dataset da \\(N(0, 1)\\):\n\n# Generiamo 20 punti dati da N(0, 1)\nset.seed(42)  # Per garantire la riproducibilità\ndati_campione &lt;- rnorm(20, mean = 0, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato &lt;- sort(dati_campione)\n\n# Calcoliamo i quantili teorici da N(0, 1)\nquantili_teorici &lt;- qnorm((seq(1, 20) - 0.5) / 20)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Stessa Media e Varianza\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti del QQ-plot dovrebbero allinearsi alla linea rossa, indicando che la distribuzione del campione corrisponde a quella teorica.\n\n37.4.4 Caso 2: Campione con Media Diversa (Intercetta ≠ 0)\nSimuliamo un campione da \\(N(2, 1)\\), con una media diversa ma la stessa varianza:\n\n# Generiamo 20 punti dati da N(2, 1)\ndati_campione_media_spostata &lt;- rnorm(20, mean = 2, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_media_spostata &lt;- sort(dati_campione_media_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_media_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media Diversa (Intercetta ≠ 0)\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti dovrebbero seguire una linea retta ma essere spostati verticalmente, indicando una media diversa (intercetta ≠ 0).\n\n37.4.5 Caso 3: Campione con Media e Varianza Diverse (Pendenza ≠ 1)\nSimuliamo un campione da \\(N(2, 2^2)\\), con una media e una varianza diverse:\n\n# Generiamo 20 punti dati da N(2, 2^2)\ndati_campione_varianza_spostata &lt;- rnorm(20, mean = 2, sd = 2)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_varianza_spostata &lt;- sort(dati_campione_varianza_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_varianza_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media e Varianza Diverse (Pendenza ≠ 1)\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti si discosteranno sia verticalmente (per la media diversa) sia rispetto alla pendenza della linea (per la varianza diversa).\n\n37.4.6 Calcolo Manuale del QQ-Plot\nPer ciascun caso sopra, i passaggi sono i seguenti:\n\n\nOrdinamento dei dati del campione: Questo fornisce i quantili del campione.\n\nCalcolo dei quantili teorici: Utilizzando la funzione inversa della CDF per la distribuzione normale.\n\nEsempio in R:\n\n# Calcolo manuale dei quantili teorici\nquantili_teorici_manuali &lt;- function(n) {\n  sapply(1:n, function(i) qnorm((i - 0.5) / n))\n}\n\nn &lt;- length(dati_campione)\nquantili_teorici_calcolati &lt;- quantili_teorici_manuali(n)\nquantili_teorici_calcolati\n#&gt;  [1] -1.95996 -1.43953 -1.15035 -0.93459 -0.75542 -0.59776 -0.45376 -0.31864\n#&gt;  [9] -0.18912 -0.06271  0.06271  0.18912  0.31864  0.45376  0.59776  0.75542\n#&gt; [17]  0.93459  1.15035  1.43953  1.95996\n\n\n37.4.7 Utilizzo di Funzioni Specializzate\nIn R, il pacchetto base offre la funzione qqnorm() per generare QQ-plot. Ad esempio:\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(dati_campione, main = \"QQ-Plot: Stessa Media e Varianza\")\nqqline(dati_campione, lwd = 2)  # Linea di riferimento\n\n\n\n\n\n\n\nPossiamo ripetere lo stesso per i campioni con media e varianza spostate.\n\nQuesto approccio fornisce un’analisi completa della corrispondenza tra distribuzioni teoriche e campioni simulati utilizzando QQ-plot.\nPer concludere, esaminiamo la distribuzione dei tempi di reazione simulati con il qq-plot.\n\nqqnorm(rt, main = \"Tempi di Reazione\")\n\n\n\n\n\n\n\nIl diagramma quantile-quantile rende molto chiaro che la distribuzione del peso dei pulcini non è gaussiana.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#valutare-la-normalità-test-statistici",
    "href": "chapters/probability/14_gauss.html#valutare-la-normalità-test-statistici",
    "title": "37  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n37.5 Valutare la Normalità: Test Statistici",
    "text": "37.5 Valutare la Normalità: Test Statistici\nSebbene esistano numerosi test statistici formali per valutare la conformità dei dati alla distribuzione normale, questi sono spesso troppo conservativi o sensibili a lievi deviazioni, e nella pratica sono frequentemente sostituiti da metodi visivi più flessibili ed efficaci.\nIn R sono disponibili diversi test per verificare la normalità dei dati. Di seguito presentiamo i più comuni, insieme a un esempio pratico basato sul dataset ChickWeight.\n\n37.5.1 Test di Shapiro-Wilk\nIl test di Shapiro-Wilk è uno dei test più utilizzati per verificare la normalità. Valuta l’ipotesi nulla che i dati seguano una distribuzione normale.\n\nshapiro_test &lt;- shapiro.test(rt)\nshapiro_test\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rt\n#&gt; W = 0.56, p-value = 5e-16\n\n\nIl p-value è inferiore a 0.05 → Rifiutiamo l’ipotesi nulla, i dati non sono normali.\nIl p-value è maggiore di 0.05 → Non rifiutiamo l’ipotesi nulla, i dati possono essere considerati normali.\n\n37.5.2 Test di Kolmogorov-Smirnov\nQuesto test confronta la distribuzione cumulativa dei dati con una distribuzione teorica, come la normale. Tuttavia, è meno sensibile rispetto al test di Shapiro-Wilk.\n\nks_test &lt;- ks.test(\n  rt, \n  \"pnorm\", \n  mean = mean(rt), \n  sd = sd(rt)\n)\nks_test\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  rt\n#&gt; D = 0.25, p-value = 5e-06\n#&gt; alternative hypothesis: two-sided\n\nIl test di Kolmogorov-Smirnov è più adatto per grandi dataset, ma è noto per essere eccessivamente conservativo.\n\n37.5.3 Limitazioni dei test statistici\nNonostante la loro precisione formale, i test statistici per la normalità notevoli limitazioni:\n\nEccessiva sensibilità ai grandi campioni: Quando il campione è ampio, anche lievi deviazioni dalla normalità, non rilevanti per l’analisi, possono portare a un risultato di non-normalità.\nMancanza di sensibilità nei piccoli campioni: Con campioni ridotti, i test possono mancare di potere statistico, portando a falsi negativi (ovvero, non rilevare deviazioni significative dalla normalità).\n\n\nset.seed(123)\nshapiro.test(rchisq(20, 4))\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rchisq(20, 4)\n#&gt; W = 0.94, p-value = 0.3\n\nIn questo esempio, vediamo come, con un campione di 20 osservazioni da una distribuzione \\(\\chi^2_4\\) si produca un falso negativo.\n\n\nDifficoltà interpretative: Un p-value elevato non implica che i dati siano esattamente normali; semplicemente, non c’è evidenza sufficiente per rifiutare l’ipotesi di normalità.\n\nI metodi visivi, sebbene meno formali, sono spesso più pratici ed efficaci per diagnosticare deviazioni dalla normalità.I metodi visivi sono preferibili sono preferibili perché\n\nforniscono una diagnosi immediata, che consente di identificare deviazioni rilevanti senza dipendere da un p-value.\nrivelano non solo se i dati non sono normali, ma anche come e dove differiscono dalla normalità (ad esempio, asimmetria o code pesanti).\noffrono indicazioni utili anche in presenza di grandi campioni, dove i test statistici possono risultare eccessivamente conservativi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalità",
    "href": "chapters/probability/14_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalità",
    "title": "37  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n37.6 Trasformazione dei dati: affrontare la non-normalità",
    "text": "37.6 Trasformazione dei dati: affrontare la non-normalità\nQuando i dati non rispettano l’assunzione di normalità, è possibile utilizzare diverse strategie per affrontare questa violazione. Una delle più comuni è l’uso di trasformazioni dei dati, che permettono di adattare la distribuzione dei dati a una forma più vicina a quella normale, mantenendo comunque la validità dell’analisi che richiede l’assunzione di normalità. Due approcci comuni sono Winsorizing e trimming.\n\n37.6.1 Winsorizing e Trimming\nQuesti metodi si concentrano sulla gestione degli outlier, ossia valori estremi che possono distorcere la distribuzione dei dati. Entrambi gli approcci presumono che la non-normalità sia dovuta a dati contaminanti e agiscono in modo differente:\n\n\nWinsorizing: Sostituisce i valori estremi con valori meno estremi, come i percentili limite della distribuzione.\n\nTrimming: Rimuove completamente i valori estremi dalla distribuzione.\n\nConsideriamo i seguenti dati di esempio:\n\ndati &lt;- c(\n  1.0, 2.2, 3.0, 3.1, 4.0, 4.0, 4.1, 5.3, 6.5, 8.3,\n  10.9, 20.4, 21.4, 34.\n)\n\n# Winsorizing al 20%\ndati_winsorized &lt;- winsorize(\n  dati,\n  method = \"percentile\", percentile = 20\n)\nprint(dati_winsorized)\n#&gt;  [1]  3.0  3.0  3.0  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9 20.4 20.4 20.4\n\n\n# Trimming al 20%\ndati_trimmed &lt;- dati[\n  dati &gt;= quantile(dati, 0.2) & dati &lt;= quantile(dati, 0.8)\n]\nprint(dati_trimmed)\n#&gt; [1]  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9\n\n\n\nDati Winsorized: I valori estremi (inferiori e superiori ai percentili 20° e 80°) sono sostituiti dai valori limite.\n\nDati Trimmed: I valori fuori dai percentili 20° e 80° sono completamente rimossi.\n\nQuesti metodi riducono l’impatto degli outlier, ma possono introdurre bias se i valori estremi sono effettivamente parte della popolazione target.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#trasformazioni-comuni",
    "href": "chapters/probability/14_gauss.html#trasformazioni-comuni",
    "title": "37  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n37.7 Trasformazioni comuni",
    "text": "37.7 Trasformazioni comuni\nQuando i dati non rispettano l’assunzione di normalità, è possibile applicare trasformazioni matematiche per modificarne la forma e migliorare l’adattamento a una distribuzione normale. Di seguito, presentiamo le trasformazioni più utilizzate.\nTrasformazione logaritmica.\nLa trasformazione logaritmica è particolarmente utile per variabili con asimmetria positiva (code lunghe a destra), come i tempi di reazione.\n\n# Trasformazione logaritmica\ndati_log &lt;- log(rt)\nplot(density(dati_log), main = \"Densità dei dati log-transformati\")\n\n\n\n\n\n\n\nTrasformazione radice quadrata.\nAdatta per variabili di conteggio o proporzioni con valori vicini a zero.\n\ndati_sqrt &lt;- sqrt(rt)\nplot(density(dati_sqrt), main = \"Densità dei dati trasformati con radice quadrata\")\n\n\n\n\n\n\n\nTrasformazione inversa.\nEfficace per dati con forte asimmetria positiva, ma può complicare l’interpretazione.\n\ndati_inv &lt;- 1 / rt\nplot(density(dati_inv), main = \"Densità dei dati trasformati inversamente\")\n\n\n\n\n\n\n\nTrasformazione Box-Cox.\nLa trasformazione Box-Cox è una tecnica parametrica che generalizza le precedenti. Utilizza il massimo della verosimiglianza per determinare la trasformazione ottimale per normalizzare i dati. La funzione di trasformazione dipende da un parametro \\(\\lambda\\):\n\\[\ny(\\lambda) =\n\\begin{cases}\n\\frac{y^\\lambda - 1}{\\lambda} & \\text{se } \\lambda \\neq 0, \\\\\n\\log(y) & \\text{se } \\lambda = 0.\n\\end{cases}\n\\]\n\nb &lt;- boxcox(lm(rt ~ 1))\n\n\n\n\n\n\n\n\n# Exact lambda\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n#&gt; [1] 0.1818\n\nTrasformiamo i dati utilizzando lambda.\n\nrt_boxcox &lt;- (rt^lambda - 1) / lambda\nrt_boxcox |&gt; head()\n#&gt; [1]  1.6450  1.1676  2.2609 -1.5681 -1.1334  0.4787\n\n\nplot(\n  density(rt_boxcox), \n  main = \"Densità dei dati trasformati con Box-Cox\"\n)\n\n\n\n\n\n\n\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(rt_boxcox, main = \"QQ-Plot\")\nqqline(rt_boxcox, lwd = 2) \n\n\n\n\n\n\n\n\n\n37.7.1 Pro e contro delle trasformazioni\nVantaggi:\nLe trasformazioni dei dati offrono molteplici benefici nell’analisi statistica. In primo luogo, possono migliorare l’aderenza alla normalità, un requisito fondamentale per l’applicazione di molti test statistici. Inoltre, contribuiscono a stabilizzare la varianza e a mitigare l’impatto dei valori estremi, riducendo il rischio che questi ultimi influenzino eccessivamente i risultati. Tali vantaggi migliorano la robustezza e l’accuratezza delle analisi.\nSvantaggi:\nNonostante i benefici, le trasformazioni presentano limitazioni rilevanti. La perdita di interpretabilità è uno degli aspetti più critici: i risultati su dati trasformati possono risultare meno intuitivi. Ad esempio, in un modello di regressione applicato a dati trasformati con il logaritmo, il coefficiente rappresenta un cambiamento percentuale anziché assoluto, rendendo l’interpretazione meno diretta per i non esperti.\nInoltre, l’applicazione di una trasformazione deve essere attentamente motivata in base alla natura dei dati e agli obiettivi dell’analisi. Una trasformazione inappropriata può introdurre distorsioni indesiderate, compromettendo la validità dei risultati e portando a conclusioni fuorvianti. Per questo motivo, è essenziale valutare attentamente i costi e i benefici della trasformazione nel contesto specifico della ricerca.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#riflessioni-conclusive",
    "href": "chapters/probability/14_gauss.html#riflessioni-conclusive",
    "title": "37  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n37.8 Riflessioni Conclusive",
    "text": "37.8 Riflessioni Conclusive\nLa verifica della normalità dei dati e l’eventuale utilizzo di trasformazioni matematiche costituiscono fasi fondamentali nell’analisi statistica. Sebbene i test formali (come Shapiro-Wilk o Kolmogorov-Smirnov) offrano una valutazione strutturata, essi possono risultare troppo sensibili, portando a rigettare l’assunto di normalità anche in presenza di lievi deviazioni non rilevanti dal punto di vista pratico. In questi casi, l’impiego di strumenti visivi—come istogrammi, grafici di densità o QQ-plot—si rivela spesso più informativo e flessibile, consentendo di individuare la natura e l’entità delle deviazioni.\nLe trasformazioni dei dati rappresentano una strategia utile per normalizzare la distribuzione, ma richiedono una scelta oculata. È essenziale verificare che la trasformazione adottata non comprometta il significato teorico della variabile in esame. Quando l’interpretabilità risulta compromessa, potrebbe essere preferibile ricorrere a metodi robusti o modelli alternativi (ad esempio, approcci bayesiani) che non presuppongono la normalità. In definitiva, la decisione finale dipenderà dal contesto di ricerca, dalla natura dei dati e dagli obiettivi analitici, privilegiando sempre un equilibrio tra rigore statistico e interpretabilità dei risultati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/14_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "37  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-64      datawizard_1.0.0 thematic_0.1.6   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.10.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt; [13] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 insight_1.0.2    \n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      glue_1.8.0       \n#&gt; [33] xfun_0.50         tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29   \n#&gt; [41] compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#bibliografia",
    "href": "chapters/probability/14_gauss.html#bibliografia",
    "title": "37  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nOsborne, J. (2002). Notes on the use of data transformations. Practical Assessment, Research, and Evaluation, 8(1).\n\n\nShatz, I. (2024). Assumption-checking rather than (just) testing: The importance of visualization and effect size in statistical diagnostics. Behavior Research Methods, 56(2), 826–845.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html",
    "href": "chapters/probability/15_likelihood.html",
    "title": "38  La verosimiglianza",
    "section": "",
    "text": "38.1 Introduzione\nI ricercatori utilizzano modelli con diverse strutture funzionali per descrivere e prevedere il comportamento dei dati. La scelta del modello più adatto si basa sul confronto tra le previsioni teoriche e i dati osservati: il modello che produce previsioni più vicine ai dati osservati viene considerato il migliore per rappresentare il fenomeno studiato. In questo processo, la funzione di verosimiglianza svolge un ruolo centrale, quantificando la probabilità che i dati osservati siano compatibili con un modello specifico e i suoi parametri.\nLa funzione di verosimiglianza rappresenta il meccanismo generativo dei dati, collegando i parametri del modello alle osservazioni empiriche. Tuttavia, essa non costituisce da sola un modello scientifico completo. Un modello scientifico include infatti altri elementi, come i priori (in un approccio bayesiano), che rappresentano le ipotesi iniziali sui parametri prima dell’osservazione dei dati, e la modellazione dell’errore di misurazione, che tiene conto delle imperfezioni nei dati raccolti.\nIn un approccio bayesiano, i priori si combinano con la verosimiglianza per generare la distribuzione a posteriori, che aggiorna le conoscenze sui parametri alla luce dei dati osservati. Questo passaggio è cruciale per il confronto tra modelli, poiché i priori possono influenzare significativamente le conclusioni.\nUn modello scientifico può anche includere la modellazione dell’errore di misurazione per spiegare le discrepanze tra i dati osservati e il processo reale. Questo aspetto è fondamentale per garantire che il modello sia in grado di catturare sia le osservazioni che le loro imprecisioni.\nIn sintesi, la funzione di verosimiglianza descrive come i dati potrebbero essere generati da un modello dato un insieme di parametri, ma un modello scientifico completo include ulteriori componenti, come i priori e la modellazione dell’errore, per rendere la rappresentazione del fenomeno più accurata. Questo capitolo si propone di approfondire il concetto di verosimiglianza e il suo ruolo nell’inferenza statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "href": "chapters/probability/15_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "title": "38  La verosimiglianza",
    "section": "\n38.2 Il Principio della Verosimiglianza e la sua Formalizzazione",
    "text": "38.2 Il Principio della Verosimiglianza e la sua Formalizzazione\nIl concetto di verosimiglianza è un concetto centrale della statistica, in quanto permette di quantificare l’informazione relativa ai parametri di un modello sulla base dei dati osservati. In altre parole, la verosimiglianza indica quanto siano “plausibili” diversi valori dei parametri per spiegare il fenomeno osservato.\n\nDefinizione 38.1 Sia \\(X\\) un vettore aleatorio con funzione di densità (o massa) di probabilità \\(f(\\cdot; \\theta)\\) (nel caso continuo o discreto, rispettivamente), dove \\(\\theta\\) è un vettore di parametri che appartiene allo spazio parametrico \\(\\Theta\\). Data un’osservazione \\(x\\) di \\(X\\), definiamo la funzione di verosimiglianza di \\(\\theta\\) come: \\[\nL(\\theta; x) = f(x; \\theta).\n\\] È fondamentale notare che, in questo contesto, \\(L\\) è una funzione di \\(\\theta\\) con \\(x\\) fissato, mentre \\(f\\) è considerata una funzione di \\(x\\) per un dato valore di \\(\\theta\\).\n\n\n38.2.1 Relazione tra Verosimiglianza e Funzione di Probabilità\nLa formula matematica che descrive la relazione tra dati e parametri è la stessa sia per la funzione di verosimiglianza che per la funzione di densità (o massa) di probabilità. Tuttavia, l’interpretazione di questa formula cambia a seconda del contesto in cui viene utilizzata.\n\nFunzione di densità (o massa) di probabilità:\nQuesta funzione rappresenta il meccanismo generativo dei dati. Fornisce la probabilità (o densità) di osservare un determinato insieme di dati, assumendo che i parametri del modello siano noti e fissi. In altre parole, descrive come i dati sono distribuiti in funzione dei parametri.\nFunzione di verosimiglianza:\nIn questo caso, i dati osservati sono considerati fissi, mentre i parametri \\(\\theta\\) variano. La funzione di verosimiglianza misura, per ogni possibile valore di \\(\\theta\\), quanto tale valore sia plausibile nel spiegare i dati osservati. In sintesi, essa quantifica la compatibilità dei parametri con i dati a disposizione.\n\nLa relazione tra le due funzioni può essere espressa formalmente come: \\[\nL(\\theta \\mid y) \\propto p(y \\mid \\theta),\n\\] dove:\n\n\n\\(L(\\theta \\mid y)\\) è la funzione di verosimiglianza, che rappresenta la plausibilità dei parametri \\(\\theta\\) dati i dati \\(y\\);\n\n\\(p(y \\mid \\theta)\\) è la funzione di densità (o massa) di probabilità, che indica la probabilità di osservare i dati \\(y\\) per un dato valore di \\(\\theta\\).\n\nIn breve, mentre la funzione di probabilità risponde alla domanda “quanto è probabile osservare questi dati, dati i parametri?”, la funzione di verosimiglianza si chiede “quanto sono plausibili questi parametri, dati i dati osservati?”. Questa distinzione è cruciale nell’inferenza statistica, poiché la verosimiglianza ci guida nella stima dei parametri più adatti a spiegare i dati osservati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#verosimiglianza-binomiale",
    "href": "chapters/probability/15_likelihood.html#verosimiglianza-binomiale",
    "title": "38  La verosimiglianza",
    "section": "\n38.3 Verosimiglianza Binomiale",
    "text": "38.3 Verosimiglianza Binomiale\nConsideriamo un esempio pratico: il lancio di una moneta. Supponiamo di osservare 23 teste su 30 lanci. La probabilità di osservare esattamente questo risultato, data una probabilità di successo \\(\\theta\\), può essere calcolata utilizzando la funzione di massa della distribuzione binomiale:\n\\[\nP(Y = y) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove:\n\n\n\\(n\\) è il numero totale di lanci,\n\n\\(y\\) è il numero di successi osservati,\n\n\\(\\theta\\) è la probabilità di successo per ogni lancio.\n\nLa funzione di verosimiglianza, invece, si concentra sull’identificazione dei valori di \\(\\theta\\) che meglio spiegano i dati osservati. Per la distribuzione binomiale, la funzione di verosimiglianza si scrive come:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^y (1 - \\theta)^{n - y}.\n\\]\nQui, il coefficiente binomiale \\(\\binom{n}{y}\\) può essere omesso perché non dipende da \\(\\theta\\) e quindi non influisce sulla stima del parametro.\n\n38.3.1 Verosimiglianza per il Lancio di una Moneta\nSupponiamo che:\n\n\n\\(n = 30\\) (numero di lanci),\n\n\\(y = 23\\) (numero di teste osservate).\n\nLa funzione di verosimiglianza diventa:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^{23} (1 - \\theta)^7.\n\\]\nQuesto ci permette di calcolare la verosimiglianza per diversi valori di \\(\\theta\\), determinando quale valore rende i dati osservati più plausibili. Ad esempio, possiamo simulare 100 valori equidistanti di \\(\\theta\\) nell’intervallo \\([0, 1]\\) e calcolare la funzione di verosimiglianza per ciascun valore.\nIn R, possiamo calcolare la funzione di verosimiglianza per \\(n = 30\\), \\(y = 23\\), e una griglia di valori di \\(\\theta\\) come segue:\n\n# Parametri\nn &lt;- 30\ny &lt;- 23\n\n# Definizione dei valori di theta\ntheta &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Visualizzazione della funzione di verosimiglianza\nggplot(\n  data.frame(theta, likelihood), \n  aes(x = theta, y = likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Verosimiglianza\",\n    x = \"Valore di θ\",\n    y = \"Verosimiglianza\"\n  ) \n\n\n\n\n\n\n\n\n38.3.2 Interpretazione della Verosimiglianza\n\n\nValore di \\(\\theta\\): La funzione di verosimiglianza indica quali valori di \\(\\theta\\) sono più plausibili dati i dati osservati.\n\nStima di Massima Verosimiglianza (MLE): Il valore di \\(\\theta\\) che massimizza la funzione di verosimiglianza è detto stima di massima verosimiglianza. Nel nostro esempio, possiamo individuare questo valore esplorando numericamente i punti di massimo della curva.\n\nIn pratica, per identificare numericamente il valore ottimale di \\(\\theta\\), si può utilizzare un approccio computazionale che identifica il massimo della verosimiglianza.\n\n# Calcolo delle probabilità binomiali\nl &lt;- dbinom(y, size = n, prob = theta)\n\n# Individuazione dell'indice massimo\nmax_index &lt;- which.max(l)\n\n# Recupero del valore corrispondente di theta\ntheta[max_index]\n#&gt; [1] 0.7677\n\nSpiegazione:\n\n\ndbinom(y, size = n, prob = theta) calcola la probabilità binomiale per ogni valore di theta.\n\nwhich.max(l) restituisce l’indice del valore massimo nella distribuzione di probabilità calcolata.\n\ntheta[max_index] seleziona il valore di theta corrispondente all’indice massimo.\n\nQuesto approccio illustra come la funzione di verosimiglianza aiuti a stimare parametri incogniti e a valutare la plausibilità relativa di diversi modelli statistici, basandosi esclusivamente sui dati osservati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#la-funzione-di-log-verosimiglianza",
    "href": "chapters/probability/15_likelihood.html#la-funzione-di-log-verosimiglianza",
    "title": "38  La verosimiglianza",
    "section": "\n38.4 La Funzione di Log-Verosimiglianza",
    "text": "38.4 La Funzione di Log-Verosimiglianza\nLa log-verosimiglianza è il logaritmo naturale della funzione di verosimiglianza:\n\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta \\mid y).\n\\]\nQuesta trasformazione è utile per semplificare i calcoli e migliorare la stabilità numerica, specialmente con dataset di grandi dimensioni.\nEsempio grafico per i valori di log-verosimiglianza:\n\n# Parametri\nn &lt;- 30\nr &lt;- 23\n\n# Genera la sequenza per theta\ntheta &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della log-verosimiglianza\nlog_likelihood &lt;- dbinom(r, size = n, prob = theta, log = TRUE)\n\n# Creazione del dataframe per ggplot\ndata &lt;- data.frame(theta = theta, log_likelihood = log_likelihood)\n\n# Creazione del grafico con ggplot2\nggplot(data, aes(x = theta, y = log_likelihood)) +\n  geom_line(color = \"blue\", linewidth = 1) +  # Linea del grafico\n  labs(\n    title = \"Funzione di log-verosimiglianza\",\n    x = \"Valore della variabile casuale theta [0, 1]\",\n    y = \"Log-verosimiglianza\"\n  ) \n\n\n\n\n\n\n\nIl massimo della log-verosimiglianza replica il risultato trovato in precedenza con la funzione di verosimiglianza.\n\n# Calcolo della log-verosimiglianza per ogni valore di theta\nlog_likelihood &lt;- dbinom(r, size = n, prob = theta, log = TRUE)\n\n# Trova l'indice del valore massimo\nmax_index &lt;- which.max(log_likelihood)\n\n# Valore di theta corrispondente al massimo\ntheta[max_index]\n#&gt; [1] 0.7677",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#verosimiglianza-congiunta",
    "href": "chapters/probability/15_likelihood.html#verosimiglianza-congiunta",
    "title": "38  La verosimiglianza",
    "section": "\n38.5 Verosimiglianza Congiunta",
    "text": "38.5 Verosimiglianza Congiunta\nNell’inferenza statistica basata sulla verosimiglianza, è comune incontrare situazioni in cui si dispone di più osservazioni indipendenti, tutte generate dallo stesso processo probabilistico. Ad esempio, raccogliamo un insieme di dati \\(Y = [y_1, y_2, \\ldots, y_n]\\), dove ciascun valore è osservato indipendentemente e segue la stessa distribuzione binomiale. Questo scenario, noto come condizione di indipendenza e identica distribuzione (IID), è frequente nelle applicazioni pratiche.\n\n38.5.1 Calcolo della Verosimiglianza Congiunta\nPer considerare congiuntamente tutte le osservazioni, calcoliamo la probabilità congiunta di osservare \\(y_1, y_2, \\ldots, y_n\\), data una comune probabilità di successo \\(\\theta\\). Grazie all’indipendenza delle osservazioni, questa probabilità si esprime come il prodotto delle probabilità individuali:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\theta) = \\prod_{i=1}^{n} p(y_i \\mid \\theta) = \\prod_{i=1}^{n} \\text{Binomiale}(y_i \\mid \\theta).\n\\]\nLa verosimiglianza congiunta è quindi:\n\\[\n\\mathcal{L}(\\theta \\mid Y) = \\prod_{i=1}^{n} \\mathcal{L}(\\theta \\mid y_i) = \\prod_{i=1}^{n} p(y_i \\mid \\theta).\n\\]\nQuesta funzione misura la plausibilità complessiva del parametro \\(\\theta\\) rispetto all’intero insieme di dati \\(Y\\). Il valore di \\(\\theta\\) che massimizza la verosimiglianza congiunta è noto come stimatore di massima verosimiglianza (MLE) e rappresenta il parametro che rende i dati osservati più plausibili.\n\n38.5.2 Log-Verosimiglianza Congiunta\nPoiché il prodotto delle probabilità può diventare numericamente instabile, lavoriamo spesso con la log-verosimiglianza, che trasforma il prodotto in una somma:\n\\[\n\\log \\mathcal{L}(\\theta \\mid Y) = \\sum_{i=1}^{n} \\log p(y_i \\mid \\theta).\n\\]\nIn un esempio pratico con dati raggruppati, consideriamo quattro gruppi di osservazioni binomiali indipendenti:\n\n\nGruppo 1: 30 prove con 23 successi\n\nGruppo 2: 28 prove con 20 successi\n\nGruppo 3: 40 prove con 29 successi\n\nGruppo 4: 36 prove con 29 successi\n\nLa log-verosimiglianza congiunta è:\n\\[\n\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right],\n\\]\ndove \\(n_i\\) e \\(y_i\\) rappresentano rispettivamente il numero di prove e di successi nel gruppo \\(i\\)-esimo.\n\n38.5.3 Implementazione in R\nPer calcolare la log-verosimiglianza congiunta, definiamo una funzione che accetta \\(\\theta\\) e i dati dei gruppi:\n\nlog_verosimiglianza_congiunta &lt;- function(theta, dati) {\n  # Evita valori problematici per log(0)\n  theta &lt;- pmax(pmin(theta, 1 - 1e-10), 1e-10)\n  \n  # Calcolo della log-verosimiglianza\n  log_likelihood &lt;- 0\n  for (gruppo in dati) {\n    n &lt;- gruppo[1]\n    y &lt;- gruppo[2]\n    log_likelihood &lt;- log_likelihood + y * log(theta) + (n - y) * log(1 - theta)\n  }\n  \n  return(-log_likelihood) # Negativo per ottimizzazione\n}\n\nI dati dei gruppi sono rappresentati come segue:\n\ndati_gruppi &lt;- list(c(30, 23), c(28, 20), c(40, 29), c(36, 29))\n\n\n38.5.4 Ottimizzazione per trovare \\(\\theta\\)\n\nUtilizziamo l’algoritmo di ottimizzazione optim per stimare il valore di \\(\\theta\\) che massimizza la log-verosimiglianza:\n\nresult &lt;- optim(\n  par = 0.5,                        # Valore iniziale\n  fn = log_verosimiglianza_congiunta, \n  dati = dati_gruppi,               # Dati\n  method = \"L-BFGS-B\",              # Metodo con vincoli\n  lower = 0,                        # Limite inferiore\n  upper = 1                         # Limite superiore\n)\n\n# Valore ottimale di theta\nresult$par\n#&gt; [1] 0.7537\n\n\n38.5.5 Visualizzazione della log-verosimiglianza\nCalcoliamo e tracciamo la log-verosimiglianza negativa per un intervallo di valori di \\(\\theta\\):\n\ntheta_values &lt;- seq(0.01, 0.99, length.out = 100)\n\nlog_likelihood_values &lt;- sapply(theta_values, function(theta) {\n  log_verosimiglianza_congiunta(theta, dati_gruppi)\n})\n\nggplot(\n  data.frame(theta = theta_values, log_likelihood = log_likelihood_values), \n  aes(x = theta, y = log_likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Log-verosimiglianza Congiunta\",\n    x = \"Theta\",\n    y = \"Log-verosimiglianza Negativa\"\n  ) \n\n\n\n\n\n\n\nIn conclusione, l’analisi della verosimiglianza congiunta consente di stimare con precisione il parametro \\(\\theta\\) considerando tutte le osservazioni contemporaneamente. La log-verosimiglianza, grazie alla sua stabilità numerica e alla semplicità di calcolo, è uno strumento potente per l’inferenza statistica. Utilizzando tecniche di ottimizzazione, possiamo identificare il valore di \\(\\theta\\) che meglio spiega i dati osservati, ottenendo stime affidabili anche in contesti complessi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#la-verosimiglianza-marginale",
    "href": "chapters/probability/15_likelihood.html#la-verosimiglianza-marginale",
    "title": "38  La verosimiglianza",
    "section": "\n38.6 La Verosimiglianza Marginale",
    "text": "38.6 La Verosimiglianza Marginale\nLa verosimiglianza marginale è un concetto fondamentale nell’inferenza bayesiana. Essa permette di calcolare la probabilità complessiva di osservare un determinato risultato, tenendo conto di tutte le possibili incertezze sui parametri del modello. Questo è particolarmente rilevante quando il parametro di interesse, \\(\\theta\\), non è considerato un valore fisso, ma è descritto da una distribuzione di probabilità.\nIn pratica, la verosimiglianza marginale valuta la compatibilità dei dati con il modello, integrando su tutti i possibili valori di \\(\\theta\\), ciascuno pesato dalla sua probabilità a priori.\n\n38.6.1 Caso con Parametri Discreti\nConsideriamo un esempio semplice in cui \\(\\theta\\) può assumere un insieme discreto di valori. Ad esempio, in una sequenza di prove binomiali con \\(k = 7\\) successi su \\(n = 10\\) prove, e con \\(\\theta \\in \\{0.1, 0.5, 0.9\\}\\), la verosimiglianza marginale è calcolata come:\n\\[\np(k = 7 \\mid n = 10) = \\sum_{\\theta \\in \\{0.1, 0.5, 0.9\\}} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta),\n\\]\ndove \\(p(\\theta)\\) rappresenta la probabilità a priori associata a ciascun valore discreto di \\(\\theta\\). In questo caso, la verosimiglianza marginale è la somma delle probabilità di osservare i dati, pesata dalla probabilità a priori di ciascun valore di \\(\\theta\\).\n\n38.6.2 Caso con Parametri Continui\nNella maggior parte delle applicazioni, \\(\\theta\\) varia continuamente all’interno di un intervallo, ad esempio \\([0, 1]\\) per un parametro binomiale. In tal caso, la verosimiglianza marginale è calcolata mediante un’integrazione:\n\\[\np(k = 7 \\mid n = 10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta) \\, d\\theta,\n\\]\ndove \\(p(\\theta)\\) è la densità a priori di \\(\\theta\\). Questa formula combina le probabilità condizionali dei dati dati \\(\\theta\\) con le probabilità a priori, integrando su tutti i possibili valori di \\(\\theta\\).\n\n38.6.3 Calcolo Numerico della Verosimiglianza Marginale\nPer calcolare la verosimiglianza marginale con \\(\\theta\\) continuo, possiamo utilizzare l’integrazione numerica. In R, il pacchetto stats offre strumenti utili come la funzione integrate. Ecco un esempio concreto:\n\n# Definizione della funzione di verosimiglianza\nlikelihood &lt;- function(theta) {\n  dbinom(x = 7, size = 10, prob = theta)\n}\n\n# Calcolo della verosimiglianza marginale con integrazione numerica\nmarginal_likelihood &lt;- integrate(likelihood, lower = 0, upper = 1)$value\n\n# Stampa del risultato\ncat(\"La verosimiglianza marginale è:\", marginal_likelihood, \"\\n\")\n#&gt; La verosimiglianza marginale è: 0.09091\n\n\n38.6.4 Interpretazione della Verosimiglianza Marginale\nLa verosimiglianza marginale rappresenta la capacità complessiva del modello di spiegare i dati, tenendo conto dell’incertezza sui parametri. Dal punto di vista geometrico, può essere interpretata come l’area sottesa alla funzione di verosimiglianza ponderata dalla distribuzione a priori di \\(\\theta\\).\nTuttavia, è importante chiarire che la verosimiglianza marginale non è una probabilità dei dati dato un valore specifico di \\(\\theta\\). Piuttosto, essa considera tutte le possibili incertezze sui parametri, fornendo una misura complessiva della compatibilità del modello con i dati.\n\n38.6.5 Ruolo nell’Inferenza Bayesiana\nLa verosimiglianza marginale assume un ruolo chiave nell’inferenza bayesiana come fattore di normalizzazione nella formula di Bayes:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) p(\\theta)}{p(D)},\n\\]\ndove \\(p(D)\\), ossia la verosimiglianza marginale, garantisce che la distribuzione posteriore \\(p(\\theta \\mid D)\\) sia una distribuzione di probabilità valida, con un’area totale pari a 1.\nIn conclusione, la verosimiglianza marginale è uno strumento fondamentale per valutare il modello nel suo complesso, integrando informazioni sui parametri e sulla loro incertezza. In particolare:\n\n\nPer parametri discreti, si calcola sommando le probabilità di ciascun valore di \\(\\theta\\), ponderate dalla loro probabilità a priori.\n\nPer parametri continui, si utilizza l’integrazione per ottenere una misura globale della compatibilità del modello con i dati.\n\nQuesta misura non solo consente di confrontare modelli diversi, ma garantisce anche la validità della distribuzione a posteriori nell’inferenza bayesiana. Grazie a strumenti computazionali, possiamo calcolare la verosimiglianza marginale anche in situazioni complesse, fornendo una base solida per analisi statistiche rigorose e flessibili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "href": "chapters/probability/15_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "title": "38  La verosimiglianza",
    "section": "\n38.7 Modello Gaussiano e Verosimiglianza",
    "text": "38.7 Modello Gaussiano e Verosimiglianza\nIn questa sezione analizziamo il caso di una distribuzione gaussiana per calcolare la funzione di verosimiglianza. Inizieremo con una singola osservazione e successivamente estenderemo l’analisi a un insieme di osservazioni indipendenti e identicamente distribuite (IID).\n\n38.7.1 Caso di una Singola Osservazione\nConsideriamo una singola osservazione \\(y\\), ad esempio il Quoziente Intellettivo (QI) di un individuo, che supponiamo seguire una distribuzione normale. La funzione di verosimiglianza per \\(y\\) esprime la plausibilità di diversi valori del parametro \\(\\mu\\) (media), dato il valore osservato, assumendo che la deviazione standard \\(\\sigma\\) sia nota.\n\n38.7.1.1 Definizione della Verosimiglianza\nLa funzione di densità di probabilità gaussiana è definita come:\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(y\\) è il valore osservato, \\(\\mu\\) è la media e \\(\\sigma\\) è la deviazione standard.\n\n38.7.1.2 Esempio con R\nSupponiamo di osservare un valore \\(y = 114\\) e di assumere che \\(\\sigma = 15\\). Esploriamo i valori di \\(\\mu\\) in un intervallo compreso tra 70 e 160 per determinare quale valore massimizza la verosimiglianza.\n\n# Parametri iniziali\ny_obs &lt;- 114\nsigma &lt;- 15\nmu_values &lt;- seq(70, 160, length.out = 1000)\n\n# Calcolo della funzione di verosimiglianza\nlikelihood &lt;- dnorm(y_obs, mean = mu_values, sd = sigma)\n\n# Visualizzazione della funzione di verosimiglianza\nlibrary(ggplot2)\nggplot(data.frame(mu = mu_values, likelihood = likelihood), aes(x = mu, y = likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Verosimiglianza per QI = 114\",\n    x = \"Valore di μ (media)\",\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\n\n38.7.1.3 Calcolo del Valore Ottimale\nPer determinare il valore di \\(\\mu\\) che massimizza la verosimiglianza, individuiamo il massimo della curva.\n\n# Identificazione del massimo\nmu_optimal &lt;- mu_values[which.max(likelihood)]\ncat(\"Il valore ottimale di μ è:\", mu_optimal, \"\\n\")\n#&gt; Il valore ottimale di μ è: 114\n\nIl valore di \\(\\mu\\) che massimizza la verosimiglianza è \\(\\mu = 114\\), coincidente con il valore osservato.\n\n38.7.2 Log-Verosimiglianza\nIn alternativa, possiamo lavorare con la log-verosimiglianza, una trasformazione utile per semplificare i calcoli numerici e migliorare la stabilità computazionale:\n\\[\n\\log L(\\mu \\mid y, \\sigma) = -\\frac{1}{2} \\log(2\\pi) - \\log(\\sigma) - \\frac{(y - \\mu)^2}{2\\sigma^2}.\n\\]\nQuesta funzione è equivalente alla funzione di verosimiglianza per determinare il valore di \\(\\mu\\) che meglio si adatta ai dati.\n\n38.7.2.1 Calcolo della Log-Verosimiglianza con R\n\n# Funzione di log-verosimiglianza negativa\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  0.5 * log(2 * pi) + log(sigma) + ((y - mu)^2) / (2 * sigma^2)\n}\n\n# Ottimizzazione per trovare il massimo della log-verosimiglianza\nresult &lt;- optim(\n  par = 100,  # Valore iniziale per μ\n  fn = negative_log_likelihood,\n  y = y_obs,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = 70,\n  upper = 160\n)\n\n# Risultato dell'ottimizzazione\nmu_max_loglik &lt;- result$par\ncat(\"Il valore ottimale di μ basato sulla log-verosimiglianza è:\", mu_max_loglik, \"\\n\")\n#&gt; Il valore ottimale di μ basato sulla log-verosimiglianza è: 114\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza è \\(\\mu\\) = 114, confermando che, in presenza di una singola osservazione, il valore ottimale coincide con l’osservazione stessa.\nIn conclusione, l’analisi della funzione di verosimiglianza nel caso gaussiano mostra che:\n\nLa funzione di verosimiglianza rappresenta la plausibilità dei parametri del modello dato il valore osservato.\nLa log-verosimiglianza è una trasformazione utile per calcoli più stabili e semplificati.\nNel caso di una singola osservazione e deviazione standard nota, il valore di \\(\\mu\\) che massimizza la verosimiglianza coincide con il valore osservato \\(y\\).\n\n38.7.3 Campione Indipendente di Osservazioni da una Distribuzione Normale\nConsideriamo un campione composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (IID), ognuna derivante da una distribuzione normale con media \\(\\mu\\) e deviazione standard \\(\\sigma\\). La distribuzione è rappresentata da:\n\\[\nX \\sim N(\\mu, \\sigma^2),\n\\]\ndove \\(y_i\\) indica ogni osservazione del campione.\nLa densità di probabilità congiunta per il campione è il prodotto delle densità delle singole osservazioni:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\mu, \\sigma) = \\prod_{i=1}^n p(y_i \\mid \\mu, \\sigma).\n\\]\nDi conseguenza, la funzione di verosimiglianza è:\n\\[\n\\mathcal{L}(\\mu, \\sigma \\mid y) = \\prod_{i=1}^n \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp \\left( -\\frac{(y_i - \\mu)^2}{2\\sigma^2} \\right).\n\\]\nPer semplificare i calcoli, si considera il logaritmo della funzione di verosimiglianza:\n\\[\n\\log \\mathcal{L}(\\mu, \\sigma \\mid y) = -\\frac{n}{2} \\log(2\\pi) - n \\log(\\sigma) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2.\n\\]\n\n38.7.3.1 Esempio Pratico\nSupponiamo di misurare i punteggi del BDI-II su un campione di 30 partecipanti. I dati sono i seguenti:\n\n# Dati osservati\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nAssumiamo che la deviazione standard \\(\\sigma\\) sia nota e pari alla deviazione standard campionaria (\\(\\sigma = 6.50\\)).\nDefiniamo una funzione per calcolare la log-verosimiglianza dato un valore di \\(\\mu\\):\n\nlog_likelihood &lt;- function(mu, y, sigma) {\n  n &lt;- length(y)\n  term1 &lt;- -n * log(sigma) - n * log(sqrt(2 * pi))\n  term2 &lt;- -sum((y - mu)^2) / (2 * sigma^2)\n  return(term1 + term2)\n}\n\nDefiniamo un intervallo per \\(\\mu\\), centrato sulla media campionaria:\n\n# Parametri\nsigma &lt;- 6.50\nmu_range &lt;- seq(mean(y) - 2 * sigma, mean(y) + 2 * sigma, length.out = 1000)\n\n# Calcolo della log-verosimiglianza per ogni valore di mu\nlog_lik_values &lt;- sapply(mu_range, log_likelihood, y = y, sigma = sigma)\n\nTracciamo la funzione di log-verosimiglianza per i diversi valori di \\(\\mu\\):\n\nggplot(\n  data.frame(mu = mu_range, log_likelihood = log_lik_values), \n  aes(x = mu, y = log_likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Log-Verosimiglianza\",\n    x = \"Valore di μ\",\n    y = \"Log-Verosimiglianza\"\n  ) +\n  geom_vline(xintercept = mean(y), linetype = \"dashed\", color = \"red\", alpha = 0.7) \n\n\n\n\n\n\n\nUtilizziamo l’ottimizzazione numerica per trovare il valore di \\(\\mu\\) che massimizza la log-verosimiglianza:\n\n# Definizione della funzione negativa per l'ottimizzazione\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  -log_likelihood(mu, y, sigma)\n}\n\n# Ottimizzazione\nresult &lt;- optim(\n  par = mean(y),  # Punto di partenza\n  fn = negative_log_likelihood,\n  y = y,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = min(mu_range),\n  upper = max(mu_range)\n)\n\n# Risultato\nmu_optimal &lt;- result$par\ncat(\"Il valore ottimale di μ è:\", mu_optimal, \"\\n\")\n#&gt; Il valore ottimale di μ è: 30.93\n\nInterpretazione dei risultati:\n\n\nStima di Massima Verosimiglianza (MLE): La media campionaria \\(\\bar{y}\\) rappresenta la stima di massima verosimiglianza (MLE) per \\(\\mu\\). Questo risultato è coerente con la proprietà della distribuzione normale.\n\nCurva della Log-Verosimiglianza: La curva mostra la “plausibilità relativa” dei diversi valori di \\(\\mu\\) alla luce dei dati osservati.\n\nOttimizzazione Numerica: Il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza è il valore che meglio spiega i dati osservati.\n\nIn conclusione, la log-verosimiglianza è uno strumento essenziale per stimare i parametri di una distribuzione normale:\n\nLa stima di massima verosimiglianza per \\(\\mu\\) coincide con la media campionaria.\nVisualizzare la log-verosimiglianza aiuta a comprendere la plausibilità dei parametri.\nL’ottimizzazione numerica fornisce una soluzione precisa ed efficiente per trovare il massimo della log-verosimiglianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#riflessioni-conclusive",
    "href": "chapters/probability/15_likelihood.html#riflessioni-conclusive",
    "title": "38  La verosimiglianza",
    "section": "\n38.8 Riflessioni Conclusive",
    "text": "38.8 Riflessioni Conclusive\nLa funzione di verosimiglianza rappresenta un ponte fondamentale tra i dati osservati e i parametri di un modello statistico, offrendo una misura della plausibilità dei dati rispetto a diversi valori possibili dei parametri. La sua costruzione richiede l’integrazione di tre elementi chiave: il modello statistico ipotizzato come generatore dei dati, lo spazio dei parametri associato al modello e le osservazioni empiriche disponibili.\nNell’ambito dell’inferenza statistica, la funzione di verosimiglianza svolge un ruolo centrale. Essa consente di valutare quanto bene diversi valori dei parametri siano in grado di spiegare i dati osservati, diventando così uno strumento essenziale per la stima dei parametri e la selezione del modello. La sua corretta applicazione è determinante per garantire analisi dati rigorose e interpretazioni affidabili dei risultati.\nIn sintesi, padroneggiare il concetto di verosimiglianza e saperlo applicare in modo appropriato sono competenze indispensabili per chi si occupa di ricerca empirica e analisi di dati complessi. La verosimiglianza non è solo uno strumento tecnico, ma un pilastro metodologico che supporta la comprensione e l’interpretazione dei fenomeni osservati attraverso modelli statistici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#esercizi",
    "href": "chapters/probability/15_likelihood.html#esercizi",
    "title": "38  La verosimiglianza",
    "section": "\n38.9 Esercizi",
    "text": "38.9 Esercizi\n\nEsercizio 38.1 Spiega ciascuno dei concetti seguenti con una frase:\n\nprobabilità.\nfunzione di massa di probabilità.\nfunzione di densità di probabilità.\ndistribuzione di probabilità.\ndistribuzione di probabilità discreta.\ndistribuzione di probabilità continua.\nfunzione di distribuzione cumulativa (cdf).\nverosimiglianza\n\n\n\n\n\n\n\n\nAll’esame ti verrà chiesto di:\n\nCalcolare la funzione di verosimiglianza binomiale e riportare il valore della funzione in corrispondenza di specifici valori \\(\\theta\\).\nCalcolare la funzione di verosimiglianza del modello gaussiano, per \\(\\sigma\\) noto, e riportare il valore della funzione in corrispondenza di specifici valori \\(\\mu\\).\nCalcolare la stima di massima verosimiglianza.\nRispondere a domande che implicano una adeguata comprensione del concetto di funzione di verosimiglianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/15_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "title": "38  La verosimiglianza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#bibliografia",
    "href": "chapters/probability/15_likelihood.html#bibliografia",
    "title": "38  La verosimiglianza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html",
    "href": "chapters/probability/16_simulation.html",
    "title": "39  Simulazioni",
    "section": "",
    "text": "39.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nLa simulazione permette di sfruttare la potenza di calcolo dei moderni computer per sostituire i calcoli analitici, talvolta complessi o impossibili da risolvere.\nIn questo capitolo, discuteremo alcuni esercizi di simulazione presentati da Schervish & DeGroot (2014) e da Gelman et al. (2021). Simulare variabili casuali è essenziale nelle statistiche applicate per diversi motivi:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#introduzione",
    "href": "chapters/probability/16_simulation.html#introduzione",
    "title": "39  Simulazioni",
    "section": "",
    "text": "Comprensione della variazione casuale: I modelli di probabilità imitano la variabilità del mondo reale. La simulazione aiuta a sviluppare intuizioni sulle oscillazioni casuali nel breve termine e sui loro effetti nel lungo termine.\nDistribuzione campionaria: Simulare dati consente di approssimare la distribuzione campionaria, trasferendo questa approssimazione alle stime e alle procedure statistiche.\nPrevisioni probabilistiche: I modelli di regressione producono previsioni probabilistiche. La simulazione è il metodo più generale per rappresentare l’incertezza nelle previsioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#calcolare-il-valore-medio-di-una-distribuzione",
    "href": "chapters/probability/16_simulation.html#calcolare-il-valore-medio-di-una-distribuzione",
    "title": "39  Simulazioni",
    "section": "\n39.2 Calcolare il valore medio di una distribuzione",
    "text": "39.2 Calcolare il valore medio di una distribuzione\nIl teorema dei grandi numeri ci garantisce che, osservando un grande campione di variabili casuali i.i.d. (indipendenti e identicamente distribuite) con media finita, la media campionaria sarà vicina alla media della distribuzione. Utilizzando un computer per generare un ampio campione di questo tipo, possiamo calcolare la media delle variabili casuali al posto di affrontare calcoli analitici.\nPer utilizzare la simulazione, occorre:\n\nIdentificare il tipo di variabili casuali necessarie.\nCapire come farle generare al computer.\nDeterminare il numero di osservazioni necessarie per avere fiducia nei risultati numerici.\n\nDi seguito, vedremo un esempio pratico che verifica il concetto di simulazione confrontando i risultati numerici con quelli analitici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#esempio-1-calcolo-della-media-di-una-distribuzione-uniforme",
    "href": "chapters/probability/16_simulation.html#esempio-1-calcolo-della-media-di-una-distribuzione-uniforme",
    "title": "39  Simulazioni",
    "section": "\n39.3 Esempio 1: Calcolo della media di una distribuzione uniforme",
    "text": "39.3 Esempio 1: Calcolo della media di una distribuzione uniforme\nLa distribuzione uniforme sull’intervallo \\([0, 1]\\) ha una media teorica pari a \\(0,5\\). Se generiamo \\(n\\) variabili casuali i.i.d. uniformi su \\([0, 1]\\), il teorema dei grandi numeri afferma che la media campionaria:\n\\[\n\\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nsarà vicina alla media teorica \\(0,5\\), soprattutto per campioni di grandi dimensioni.\nVediamo come questo concetto si applica attraverso una simulazione in R.\n\n# Impostiamo il numero di simulazioni\nset.seed(123) # Per riproducibilità\nsample_sizes &lt;- c(100, 1000, 10000, 100000) # Dimensioni del campione\nresults &lt;- data.frame(Sample_Size = sample_sizes, Sample_Mean = NA)\n\n# Calcoliamo la media campionaria per ciascun campione\nfor (i in seq_along(sample_sizes)) {\n  n &lt;- sample_sizes[i]\n  sample &lt;- runif(n, min = 0, max = 1) # Generazione delle variabili uniformi\n  results$Sample_Mean[i] &lt;- mean(sample) # Media campionaria\n}\n\n# Stampiamo i risultati\nprint(results)\n#&gt;   Sample_Size Sample_Mean\n#&gt; 1         100      0.4986\n#&gt; 2        1000      0.4953\n#&gt; 3       10000      0.4984\n#&gt; 4      100000      0.4995\n\n\n# Visualizzazione grafica delle medie campionarie\nggplot(results, aes(x = Sample_Size, y = Sample_Mean)) +\n  geom_point() +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  scale_x_log10() +\n  labs(\n    title = \"Convergenza della Media Campionaria alla Media Teorica\",\n    x = \"Dimensione del Campione (scala logaritmica)\",\n    y = \"Media Campionaria\"\n  ) \n\n\n\n\n\n\n\n\n\nGenerazione di variabili casuali: La funzione runif(n, min = 0, max = 1) genera \\(n\\) variabili uniformemente distribuite sull’intervallo \\([0, 1]\\).\n\nMedia campionaria: Per ogni dimensione del campione (\\(n\\)), calcoliamo la media con mean(sample).\n\nRisultati: Presentiamo i risultati in una tabella e li visualizziamo graficamente, mostrando la convergenza della media campionaria (\\(\\overline{X}\\)) verso il valore teorico \\(0,5\\).\n\nL’output mostrerà una tabella con le medie campionarie per diverse dimensioni del campione. Il grafico evidenzierà come la media campionaria si avvicini al valore teorico di \\(0,5\\) con l’aumentare della dimensione del campione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#esempio-2-probabilità-di-una-normale-standard",
    "href": "chapters/probability/16_simulation.html#esempio-2-probabilità-di-una-normale-standard",
    "title": "39  Simulazioni",
    "section": "\n39.4 Esempio 2: Probabilità di una Normale Standard",
    "text": "39.4 Esempio 2: Probabilità di una Normale Standard\nLa probabilità che una variabile casuale standard normale sia almeno \\(1.0\\) è nota e pari a \\(0.1587\\). Per verificare questa probabilità usando una simulazione, possiamo generare un grande numero di variabili casuali i.i.d. (indipendenti e identicamente distribuite) standard normali, ad esempio \\(X_1, \\ldots, X_n\\), e creare variabili casuali Bernoulli \\(Y_1, \\ldots, Y_n\\) definite come segue:\n\\[\nY_i =\n\\begin{cases}\n1 & \\text{se } X_i \\geq 1.0 \\\\\n0 & \\text{altrimenti.}\n\\end{cases}\n\\]\nIl teorema dei grandi numeri afferma che la proporzione:\n\\[\n\\overline{Y} = \\frac{1}{n} \\sum_{i=1}^n Y_i\n\\]\ndovrebbe essere vicina alla media teorica di \\(Y_i\\), ossia \\(\\text{Pr}(X_i \\geq 1.0) = 0.1587\\). In questo esempio, simuleremo campioni di diverse dimensioni \\(n\\) per calcolare la proporzione di \\(X_i \\geq 1.0\\) e confrontare i risultati con il valore teorico.\n\n# Impostiamo il seme per la riproducibilità\nset.seed(123)\n\n# Dimensioni dei campioni da analizzare\nsample_sizes &lt;- c(100, 1000, 10000, 100000)\n\n# Inizializziamo un data frame per salvare i risultati\nresults &lt;- data.frame(\n  Sample_Size = sample_sizes,\n  Proportion = NA\n)\n\n# Calcolo delle proporzioni per ciascun campione\nfor (i in seq_along(sample_sizes)) {\n  n &lt;- sample_sizes[i]\n  sample &lt;- rnorm(n)  # Generazione di variabili standard normali\n  Y &lt;- ifelse(sample &gt;= 1.0, 1, 0)  # Variabili Bernoulli\n  results$Proportion[i] &lt;- mean(Y)  # Proporzione di Y_i = 1\n}\n\n# Stampiamo i risultati\nprint(results)\n#&gt;   Sample_Size Proportion\n#&gt; 1         100     0.1700\n#&gt; 2        1000     0.1590\n#&gt; 3       10000     0.1571\n#&gt; 4      100000     0.1600\n\n\n# Grafico della proporzione rispetto alla dimensione del campione\nggplot(results, aes(x = Sample_Size, y = Proportion)) +\n  geom_point() +\n  geom_hline(yintercept = 0.1587, linetype = \"dashed\", color = \"red\") +\n  scale_x_log10() +\n  labs(\n    title = \"Convergenza della Proporzione Simulata alla Probabilità Teorica\",\n    x = \"Dimensione del Campione (scala logaritmica)\",\n    y = \"Proporzione di X ≥ 1.0\"\n  ) \n\n\n\n\n\n\n\n\n\nGenerazione di variabili normali standard: La funzione rnorm(n) genera \\(n\\) variabili casuali dalla distribuzione normale standard.\n\nCreazione delle variabili Bernoulli: Tramite ifelse(sample &gt;= 1.0, 1, 0) trasformiamo le variabili normali standard in variabili Bernoulli.\n\nCalcolo della proporzione: La proporzione di \\(Y_i = 1\\) è calcolata come la media delle variabili Bernoulli \\(Y\\).\n\nConfronto visivo: Il grafico mostra la convergenza della proporzione simulata al valore teorico (\\(0.1587\\)) con l’aumentare della dimensione del campione.\n\nIl codice dimostra che, con l’aumentare della dimensione del campione \\(n\\), la proporzione simulata di \\(X \\geq 1.0\\) converge verso la probabilità teorica \\(0.1587\\). Tuttavia, la variabilità delle simulazioni è evidente per campioni più piccoli, evidenziando l’importanza della dimensione campionaria nella stima accurata delle probabilità tramite simulazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#esempio-3-attesa-per-il-cambiamento-dellumore",
    "href": "chapters/probability/16_simulation.html#esempio-3-attesa-per-il-cambiamento-dellumore",
    "title": "39  Simulazioni",
    "section": "\n39.5 Esempio 3: Attesa per il Cambiamento dell’Umore",
    "text": "39.5 Esempio 3: Attesa per il Cambiamento dell’Umore\nImmaginiamo un esperimento psicologico in cui due partecipanti completano un compito che induce stress, al termine del quale misurano il loro livello di umore su una scala da 1 a 10. Entrambi devono raggiungere un punteggio di umore pari a 7 prima di fermarsi. Si vuole stimare, in media, quanto tempo uno dei due dovrà attendere affinché l’altro raggiunga il punteggio stabilito.\nSupponiamo che il cambiamento dell’umore per ciascun partecipante sia modellato come una variabile casuale gamma con parametri \\(k = 10\\) (numero di tentativi per raggiungere il livello) e \\(\\lambda = 0.3\\) (frequenza del cambiamento per minuto). Denotiamo il tempo necessario al partecipante A come \\(X\\) e al partecipante B come \\(Y\\). Vogliamo calcolare la media di \\(Z = |X - Y|\\), cioè la differenza assoluta nei tempi di completamento.\nAnziché affrontare calcoli analitici complessi, utilizzeremo una simulazione per stimare questa media.\n\n# Impostiamo il seme per la riproducibilità\nset.seed(123)\n\n# Parametri della distribuzione gamma\nk &lt;- 10  # Numero di eventi\nlambda &lt;- 0.3  # Frequenza degli eventi\n\n# Numero di simulazioni\nn_sim &lt;- 10000\n\n# Simuliamo i tempi di completamento per A e B\nX &lt;- rgamma(n_sim, shape = k, rate = lambda)\nY &lt;- rgamma(n_sim, shape = k, rate = lambda)\n\n# Calcoliamo la differenza assoluta\nZ &lt;- abs(X - Y)\n\n# Media della differenza assoluta\nmean_Z &lt;- mean(Z)\n\n# Stampa dei risultati\ncat(\"Media della differenza assoluta nei tempi di completamento:\", mean_Z, \"minuti\\n\")\n#&gt; Media della differenza assoluta nei tempi di completamento: 11.76 minuti\n\n\n# Istogramma della distribuzione di Z\nlibrary(ggplot2)\nggplot(data.frame(Z), aes(x = Z)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill = \"lightblue\") +\n  labs(\n    title = \"Distribuzione dei Tempi di Attesa (Z)\",\n    x = \"Tempo di attesa Z (minuti)\",\n    y = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\n\nGenerazione dei tempi gamma: Usiamo la funzione rgamma per generare \\(n = 10,000\\) tempi di completamento \\(X\\) e \\(Y\\), modellati come distribuzioni gamma con parametri \\(k = 10\\) e \\(\\lambda = 0.3\\).\n\nCalcolo della differenza assoluta: La differenza assoluta \\(Z = |X - Y|\\) rappresenta il tempo di attesa.\n\nStima della media: Utilizziamo la funzione mean per calcolare la media di \\(Z\\).\n\nIstogramma: Il grafico visualizza la distribuzione dei tempi di attesa \\(Z\\).\n\nSupponendo i parametri specificati, il codice produrrà una stima della media del tempo di attesa e un istogramma che mostra la distribuzione di \\(Z\\).\nQuesto esperimento simulato fornisce una stima del tempo medio di attesa tra due partecipanti in un contesto di regolazione emotiva. La variabilità nei tempi di completamento evidenzia come i processi individuali (ad esempio, il recupero emotivo) possano differire, un aspetto rilevante per la progettazione di interventi psicologici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#esempio-4-lunghe-sequenze-di-teste-in-un-lancio-di-monete",
    "href": "chapters/probability/16_simulation.html#esempio-4-lunghe-sequenze-di-teste-in-un-lancio-di-monete",
    "title": "39  Simulazioni",
    "section": "\n39.6 Esempio 4: Lunghe Sequenze di Teste in un Lancio di Monete",
    "text": "39.6 Esempio 4: Lunghe Sequenze di Teste in un Lancio di Monete\nHai sentito qualcuno dire di aver ottenuto 12 teste consecutive lanciando una moneta apparentemente equa. La probabilità di ottenere 12 teste consecutive in 12 lanci indipendenti è \\((0.5)^{12}\\), un numero molto piccolo. Tuttavia, scopri che questa sequenza di 12 teste è apparsa in una serie di 100 lanci, rendendo l’evento meno sorprendente. La domanda è: quanto aumenta la probabilità di ottenere una sequenza di 12 teste consecutive se si effettuano 100 lanci?\nUtilizzeremo una simulazione per stimare questa probabilità, modellando \\(X = 1\\) se nei 100 lanci appare una sequenza di almeno 12 teste consecutive, e \\(X = 0\\) altrimenti. Stimiamo la probabilità di una sequenza di 12 teste consecutive come la media delle osservazioni \\(X\\) in molte ripetizioni della simulazione.\n\n# Impostiamo il seme per la riproducibilità\nset.seed(123)\n\n# Parametri della simulazione\nn_sim &lt;- 10000  # Numero di simulazioni\nn_flips &lt;- 100  # Numero di lanci per simulazione\nsequence_length &lt;- 12  # Lunghezza della sequenza cercata\n\n# Funzione per verificare la presenza di una sequenza di almeno 'sequence_length' teste\ncheck_run &lt;- function(flips, sequence_length) {\n  # Trasformiamo i risultati in una stringa per contare sequenze consecutive\n  flip_string &lt;- paste(rbinom(flips, 1, 0.5), collapse = \"\")\n  return(any(grepl(paste(rep(1, sequence_length), collapse = \"\"), flip_string)))\n}\n\n# Eseguiamo la simulazione\nresults &lt;- replicate(n_sim, check_run(n_flips, sequence_length))\n\n# Calcoliamo la probabilità stimata\nestimated_probability &lt;- mean(results)\n\n# Stampiamo il risultato\ncat(\"Probabilità stimata di ottenere una sequenza di almeno\", sequence_length,\n    \"teste consecutive in\", n_flips, \"lanci:\", estimated_probability, \"\\n\")\n#&gt; Probabilità stimata di ottenere una sequenza di almeno 12 teste consecutive in 100 lanci: 0.0106\n\n\n# Distribuzione delle lunghezze massime delle sequenze\nlongest_runs &lt;- replicate(n_sim, {\n  flips &lt;- rbinom(n_flips, 1, 0.5)\n  max(rle(flips)$lengths[which(rle(flips)$values == 1)])\n})\n\n# Grafico della distribuzione delle sequenze più lunghe\nggplot(data.frame(Longest_Run = longest_runs), aes(x = Longest_Run)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill = \"lightblue\") +\n  labs(\n    title = \"Distribuzione delle Sequenze Più Lunghe di Teste in 100 Lanci\",\n    x = \"Lunghezza della sequenza più lunga\",\n    y = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\n\nGenerazione dei lanci di moneta: Ogni lancio è modellato come una variabile binaria con \\(\\text{Pr(Testa)} = 0.5\\), utilizzando rbinom.\n\nVerifica della sequenza: La funzione check_run cerca se una sequenza di lunghezza specificata appare nei lanci simulati. Questo è realizzato trasformando i risultati dei lanci in una stringa e utilizzando la funzione grepl per rilevare la sequenza.\n\nStima della probabilità: La proporzione di simulazioni in cui appare una sequenza di almeno 12 teste fornisce una stima della probabilità.\n\nDistribuzione delle sequenze più lunghe: Calcoliamo la lunghezza massima di una sequenza di teste per ogni simulazione e la visualizziamo con un istogramma.\n\nL’output fornisce:\n\nLa probabilità stimata di ottenere una sequenza di almeno 12 teste consecutive in 100 lanci.\nUn grafico che mostra la distribuzione delle sequenze più lunghe osservate nei 10,000 esperimenti.\n\nQuesto approccio può essere utilizzato per modellare eventi rari ma possibili in psicologia, come la comparsa di lunghe sequenze di comportamenti simili in compiti ripetuti (ad esempio, risposte corrette consecutive in un test di memoria). La simulazione offre una stima della probabilità di osservare tali eventi, fornendo informazioni utili per interpretare i risultati sperimentali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#esempio-probabilità-della-media-campionaria",
    "href": "chapters/probability/16_simulation.html#esempio-probabilità-della-media-campionaria",
    "title": "39  Simulazioni",
    "section": "\n39.7 Esempio: Probabilità della Media Campionaria",
    "text": "39.7 Esempio: Probabilità della Media Campionaria\nConsideriamo un campione casuale di 30 persone estratte dalla popolazione generale, in cui il QI segue una distribuzione normale \\(\\mathcal{N}(100, 15)\\). Vogliamo calcolare la probabilità che la media campionaria sia maggiore di 105.\nLa probabilità teorica è data dalla distribuzione normale della media campionaria:\n\\[\n\\text{Media campionaria: } \\mathcal{N}\\left(\\mu = 100, \\, \\sigma = \\frac{15}{\\sqrt{30}}\\right)\n\\]\nLa probabilità si calcola analiticamente come:\n\\[\nP\\left(\\bar{X} &gt; 105\\right) = 1 - \\Phi\\left(\\frac{105 - 100}{15 / \\sqrt{30}}\\right)\n\\]\nCalcoliamo questa probabilità teorica e stimiamola tramite simulazione.\n\n# Calcolo analitico della probabilità\nmu &lt;- 100        # Media della popolazione\nsigma &lt;- 15      # Deviazione standard della popolazione\nn &lt;- 30          # Dimensione del campione\nthreshold &lt;- 105 # Soglia per la media campionaria\n\n# Probabilità teorica\nprob_teorica &lt;- 1 - pnorm(threshold, mean = mu, sd = sigma / sqrt(n))\ncat(\"Probabilità teorica che la media campionaria sia maggiore di 105:\", prob_teorica, \"\\n\")\n#&gt; Probabilità teorica che la media campionaria sia maggiore di 105: 0.03394\n\n# Simulazione\nset.seed(123)  # Per riproducibilità\nn_sim &lt;- 100000 # Numero di simulazioni\n\n# Generazione dei campioni e calcolo delle medie campionarie\nsample_means &lt;- replicate(n_sim, mean(rnorm(n, mean = mu, sd = sigma)))\n\n# Probabilità stimata tramite simulazione\nprob_simulata &lt;- mean(sample_means &gt; threshold)\ncat(\"Probabilità stimata tramite simulazione:\", prob_simulata, \"\\n\")\n#&gt; Probabilità stimata tramite simulazione: 0.0339\n\n\n# Istogramma delle medie campionarie\nggplot(data.frame(Sample_Means = sample_means), aes(x = Sample_Means)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill = \"lightblue\") +\n  geom_vline(xintercept = threshold, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione delle Medie Campionarie\",\n    x = \"Media Campionaria\",\n    y = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\nLa funzione pnorm calcola la probabilità cumulativa della normale. Sottraendo tale valore da 1, otteniamo la probabilità di superare la soglia specificata.\nLa funzione rnorm genera \\(n\\) valori casuali da una distribuzione normale \\(\\mathcal{N}(100, 15)\\). Ripetiamo il processo 100,000 volte con replicate, calcolando la media campionaria ogni volta.\nLa proporzione di medie campionarie che superano 105 fornisce la stima simulata della probabilità.\n\nLa simulazione offre un metodo pratico per stimare probabilità anche in situazioni più complesse, dove il calcolo analitico potrebbe non essere semplice.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#esempio-5-simulazione-in-un-trial-clinico",
    "href": "chapters/probability/16_simulation.html#esempio-5-simulazione-in-un-trial-clinico",
    "title": "39  Simulazioni",
    "section": "\n39.8 Esempio 5: Simulazione in un Trial Clinico",
    "text": "39.8 Esempio 5: Simulazione in un Trial Clinico\nIn questo esempio, vogliamo analizzare i risultati di un trial clinico con quattro gruppi di trattamento (\\(i = 1, 2, 3, 4\\)), stimando la probabilità di successo (\\(P_i\\)) di ciascun trattamento. Il successo è definito come la probabilità che un paziente non abbia una ricaduta dopo il trattamento.\nL’analisi si basa su una distribuzione a posteriori di \\(P_i\\), calcolata combinando:\n\n\nLa verosimiglianza (likelihood): Derivata dai dati osservati \\(x_i\\) (successi) e \\(n_i\\) (pazienti totali per gruppo).\n\nLa distribuzione a priori: Una distribuzione Beta(\\(\\alpha_0, \\beta_0\\)) scelta per rappresentare le nostre convinzioni iniziali su \\(P_i\\).\n\n\n39.8.1 Derivazione della Distribuzione a Posteriori\n\nLikelihood (Verosimiglianza):\nLa probabilità di osservare \\(x_i\\) successi in \\(n_i\\) prove (pazienti) segue una distribuzione binomiale: \\[\nx_i \\sim \\text{Binomiale}(n_i, P_i)\n\\] La funzione di verosimiglianza per \\(P_i\\) è quindi: \\[\n\\mathcal{L}(P_i \\mid x_i, n_i) \\propto P_i^{x_i} (1 - P_i)^{n_i - x_i}\n\\]\nDistribuzione a priori:\nAssumiamo che \\(P_i\\) segua una distribuzione Beta(\\(\\alpha_0, \\beta_0\\)), con densità: \\[\n\\pi(P_i) \\propto P_i^{\\alpha_0 - 1} (1 - P_i)^{\\beta_0 - 1}\n\\]\nDistribuzione a posteriori:\nCombinando la verosimiglianza e la distribuzione a priori, otteniamo la distribuzione a posteriori (tramite il Teorema di Bayes): \\[\n\\pi(P_i \\mid x_i, n_i) \\propto \\mathcal{L}(P_i \\mid x_i, n_i) \\cdot \\pi(P_i)\n\\] Sostituendo le espressioni della likelihood e della prior: \\[\n\\pi(P_i \\mid x_i, n_i) \\propto P_i^{x_i + \\alpha_0 - 1} (1 - P_i)^{n_i - x_i + \\beta_0 - 1}\n\\] Questa è la densità di una distribuzione Beta con parametri aggiornati: \\[\nP_i \\sim \\text{Beta}(\\alpha_0 + x_i, \\beta_0 + n_i - x_i)\n\\]\n\n39.8.2 Simulazione con R\nIl nostro obiettivo è stimare:\n\n\n\\(\\Pr(P_i &gt; P_4)\\), dove \\(P_4\\) rappresenta il placebo.\nLa probabilità che un trattamento sia il più efficace (\\(P_i = \\max(P_1, P_2, P_3, P_4)\\)).\nLa probabilità che tutti i \\(P_i\\) siano vicini entro un intervallo \\(\\epsilon\\).\n\n\n# Parametri della distribuzione a priori\nalpha0 &lt;- 2  # Parametro a priori per i successi\nbeta0 &lt;- 2   # Parametro a priori per i fallimenti\n\n# Dati osservati\nn &lt;- c(50, 50, 50, 50)  # Numero totale di pazienti per ciascun gruppo\nx &lt;- c(35, 30, 25, 20)  # Numero di pazienti che non hanno avuto una ricaduta\n\n# Parametri posteriori\nposterior_alpha &lt;- alpha0 + x\nposterior_beta &lt;- beta0 + n - x\n\n# Numero di simulazioni\nn_sim &lt;- 10000\n\n# Simulazione delle distribuzioni posteriori\nset.seed(123)  # Per riproducibilità\nP &lt;- sapply(1:4, function(i) rbeta(n_sim, posterior_alpha[i], posterior_beta[i]))\n\n# 1. Probabilità che ciascun trattamento sia migliore del placebo\nprobs_better_than_placebo &lt;- colMeans(P[, 1:3] &gt; P[, 4])\nnames(probs_better_than_placebo) &lt;- paste0(\"P\", 1:3, \" &gt; P4\")\n# print(probs_better_than_placebo)\n\n# 2. Probabilità che un trattamento sia il migliore\nprobs_best &lt;- colMeans(apply(P, 1, function(row) row == max(row)))\nnames(probs_best) &lt;- paste0(\"P\", 1:4, \" è il migliore\")\n# print(probs_best)\n\n# 3. Probabilità che tutti i Pi siano entro epsilon\nepsilon &lt;- 0.1\nprobs_within_epsilon &lt;- mean(apply(P, 1, function(row) max(row) - min(row) &lt;= epsilon))\ncat(\"Probabilità che tutti i Pi siano entro epsilon =\", epsilon, \":\", probs_within_epsilon, \"\\n\")\n#&gt; Probabilità che tutti i Pi siano entro epsilon = 0.1 : 0.0047\n\n# Visualizzazione: Distribuzioni posteriori\nP_df &lt;- data.frame(\n  Simulazione = rep(1:n_sim, 4),\n  P = as.vector(P),\n  Gruppo = factor(rep(1:4, each = n_sim), labels = paste0(\"P\", 1:4))\n)\n\nggplot(P_df, aes(x = P, fill = Gruppo)) +\n  geom_density(alpha = 0.6) +\n  labs(\n    title = \"Distribuzioni Posteriori dei Pi\",\n    x = \"Probabilità Pi\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n39.8.3 Risultati e Interpretazione\n\n\nProbabilità \\(\\Pr(P_i &gt; P_4)\\): Indicano quanto è probabile che ogni trattamento superi il placebo.\n\nProbabilità che un trattamento sia il migliore: Mostrano quale trattamento è più efficace in termini probabilistici.\n\nProbabilità di vicinanza (\\(\\epsilon\\)): Forniscono informazioni sulla similarità tra le probabilità di successo dei trattamenti.\n\nQuesto approccio combina inferenza bayesiana e simulazione per rispondere a domande chiave in un trial clinico.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#esempio-6-quante-bambine-su-400-nascite",
    "href": "chapters/probability/16_simulation.html#esempio-6-quante-bambine-su-400-nascite",
    "title": "39  Simulazioni",
    "section": "\n39.9 Esempio 6: Quante bambine su 400 nascite?",
    "text": "39.9 Esempio 6: Quante bambine su 400 nascite?\nSupponiamo che la probabilità di nascita di una bambina sia \\(p\\) = 0.488. Se in un ospedale nascono 400 bambini in un anno, quante saranno bambine? Possiamo simulare questo processo usando una distribuzione binomiale, ripetendo la simulazione 10,000 volte.\n\n# Numero di simulazioni\nn_sims &lt;- 10000\n\n# Probabilità di nascita di una bambina\np_girl &lt;- 0.488\n\n# Simulazione del numero di bambine\nset.seed(123)\nn_girls &lt;- rbinom(n_sims, size = 400, prob = p_girl)\n\n# Visualizzazione dell'istogramma\nggplot(data.frame(n_girls), aes(x = n_girls)) +\n  geom_histogram(binwidth = 5, fill = \"blue\", color = \"black\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione del Numero di Bambine su 400 Nascite\",\n    x = \"Numero di Bambine\",\n    y = \"Frequenza\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#simulazione-di-probabilità-continue",
    "href": "chapters/probability/16_simulation.html#simulazione-di-probabilità-continue",
    "title": "39  Simulazioni",
    "section": "\n39.10 Simulazione di probabilità continue",
    "text": "39.10 Simulazione di probabilità continue\nGelman et al. (2021) dimostrano come sia possibile incorporare anche distribuzioni di probabilità continue nei tipi di simulazioni discusse nella sezione precedente. Forniscono il seguente esempio di un modello misto discreto/continuo: il 52% degli adulti negli Stati Uniti sono donne e il 48% sono uomini. L’altezza degli uomini segue approssimativamente una distribuzione normale con una media di 69.1 pollici e una deviazione standard di 2.9 pollici; per le donne, la media è 63.7 pollici e la deviazione standard è 2.7 pollici. Ecco il codice per generare l’altezza di un adulto scelto casualmente:\n\nsimulate_height &lt;- function(N) {\n  gender &lt;- rbinom(N, size = 1, prob = 0.48) # 1 = uomo, 0 = donna\n  height &lt;- ifelse(\n    gender == 1,\n    rnorm(N, mean = 69.1, sd = 2.9),\n    rnorm(N, mean = 63.7, sd = 2.7)\n  )\n  return(mean(height))\n}\n\nSupponiamo di selezionare 10 adulti a caso. Cosa possiamo dire della loro altezza media?\n\nset.seed(123)\nn_sims &lt;- 10000\navg_heights &lt;- replicate(n_sims, simulate_height(10))\n\n# Visualizzazione dell'istogramma\nggplot(data.frame(avg_heights), aes(x = avg_heights)) +\n  geom_histogram(binwidth = 0.2, fill = \"blue\", color = \"black\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione dell'Altezza Media di 10 Adulti\",\n    x = \"Altezza Media\",\n    y = \"Frequenza\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "href": "chapters/probability/16_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "title": "39  Simulazioni",
    "section": "\n39.11 Sommario di una simulazione con media e mediana",
    "text": "39.11 Sommario di una simulazione con media e mediana\nQuando le nostre distribuzioni sono costruite come simulazioni al computer, può essere conveniente riassumerle in qualche modo. Tipicamente, riassumiamo la posizione di una distribuzione con la sua media o mediana.\nLa variazione nella distribuzione è tipicamente riassunta dalla deviazione standard, ma spesso preferiamo usare la deviazione mediana assoluta. Se la mediana di un insieme di simulazioni \\(z_1, \\ldots, z_n\\) è \\(M\\), allora la deviazione mediana assoluta è:\n\\[ \\text{mad} = \\text{mediana}_{n} |z_i - M| \\]\nTuttavia, poiché siamo abituati a lavorare con le deviazioni standard, quando calcoliamo la deviazione mediana assoluta, la riscaliamo moltiplicandola per 1.483, il che riproduce la deviazione standard nel caso speciale della distribuzione normale:\n\\[ 1.483 * \\text{median}(|y - \\text{median}(z)|) \\]\nPreferiamo tipicamente i riassunti basati sulla mediana perché sono più stabili computazionalmente, e riscaliamo il riassunto basato sulla mediana della variazione come descritto sopra in modo da essere comparabile alla deviazione standard, che sappiamo già interpretare nella pratica statistica usuale.\nEcco come implementare quanto sopra in R per i dati relativi all’altezza media di 10 adulti.\n\n# Calcolo della media e mediana\nmean_avg_height &lt;- mean(avg_heights)\nmedian_avg_height &lt;- median(avg_heights)\n\n# Calcolo della deviazione standard\nsd_avg_height &lt;- sd(avg_heights)\n\n# Calcolo della MAD (Deviazione Mediana Assoluta)\nmad_avg_height &lt;- median(abs(avg_heights - median_avg_height)) * 1.483\n\n# Risultati\ncat(\"Mean:\", mean_avg_height, \"\\n\")\n#&gt; Mean: 66.3\ncat(\"Median:\", median_avg_height, \"\\n\")\n#&gt; Median: 66.28\ncat(\"Standard Deviation:\", sd_avg_height, \"\\n\")\n#&gt; Standard Deviation: 1.226\ncat(\"MAD (scaled):\", mad_avg_height, \"\\n\")\n#&gt; MAD (scaled): 1.235\n\n\n39.11.1 Intervalli di Incertezza\nPer rappresentare l’incertezza, possiamo calcolare intervalli centrali al 50% e al 95%.\n\n# Intervalli di incertezza\nlower_50 &lt;- quantile(avg_heights, 0.25)\nupper_50 &lt;- quantile(avg_heights, 0.75)\n\nlower_95 &lt;- quantile(avg_heights, 0.025)\nupper_95 &lt;- quantile(avg_heights, 0.975)\n\ncat(\"50% Interval:\", lower_50, \"-\", upper_50, \"\\n\")\n#&gt; 50% Interval: 65.46 - 67.13\ncat(\"95% Interval:\", lower_95, \"-\", upper_95, \"\\n\")\n#&gt; 95% Interval: 63.91 - 68.77\n\nEcco come interpretarli.\nIntervallo centrale al 50%.\n\nContiene i valori centrali che coprono il 50% della distribuzione. Questo intervallo si estende dal primo quartile (25° percentile) al terzo quartile (75° percentile).\nIndica la fascia di valori in cui si trovano i risultati “più comuni” o tipici. È una misura di variabilità concentrata nella parte centrale della distribuzione, meno sensibile a valori estremi.\n\nPer le altezze medie simulate di 10 adulti, un intervallo centrale al 50% che va da 65 a 67 pollici indica che metà delle medie osservate si trova in questo intervallo.\n\n\n\nIntervallo centrale al 95%.\n\nContiene il 95% della distribuzione simulata, lasciando solo il 2.5% dei valori al di sotto e il 2.5% al di sopra dell’intervallo. Questo intervallo si calcola tra il 2.5° percentile e il 97.5° percentile.\nIndica una fascia più ampia che cattura quasi tutti i valori plausibili, inclusi quelli meno probabili ma comunque possibili.\n\nPer le altezze medie simulate, un intervallo al 95% che va da 64 a 68 pollici significa che, in quasi tutte le simulazioni, l’altezza media si trova in questo intervallo, con poche eccezioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/16_simulation.html#commenti-e-considerazioni-finali",
    "title": "39  Simulazioni",
    "section": "\n39.12 Commenti e Considerazioni Finali",
    "text": "39.12 Commenti e Considerazioni Finali\nLo scopo della simulazione di dati fittizi non è fornire intuizioni sui dati o sul problema reale in esame, ma piuttosto valutare le proprietà dei metodi statistici utilizzati, partendo da un modello generativo ipotizzato. Le simulazioni sono cruciali nella pratica della ricerca. Molti autori suggeriscono che dovrebbero essere eseguite prima di raccogliere i dati di uno studio, per valutare, tra le altre cose, se la dimensione campionaria prevista fornisce un potere statistico sufficiente per rispondere alla domanda della ricerca (Gelman & Brown, 2024).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#esercizi",
    "href": "chapters/probability/16_simulation.html#esercizi",
    "title": "39  Simulazioni",
    "section": "\n39.13 Esercizi",
    "text": "39.13 Esercizi\n\nEsercizio 39.1 Immagina il caso di 220 studenti che devono sostenere tre prove in itinere in un corso. Il voto finale è la media dei voti ottenuti in queste tre prove. Le distribuzioni dei voti per le prove sono descritte come segue:\n\nPrima prova: I voti sono distribuiti secondo una gaussiana con media 24. Il 15% degli studenti ottiene un voto inferiore a 18.\nSeconda prova: I voti sono distribuiti secondo una gaussiana con media 25. Il 10% degli studenti ottiene un voto inferiore a 18.\nTerza prova: I voti sono distribuiti secondo una gaussiana con media 26. Solo il 5% degli studenti ottiene un voto inferiore a 18.\n\nDei 220 studenti iniziali:\n\nIl 10% non partecipa alla prima prova.\nUn ulteriore 5% non partecipa alla seconda prova.\n\nPer ottenere il voto finale, uno studente deve partecipare a tutte e tre le prove.\nUtilizzando una simulazione, trova la media finale dei voti e calcola l’intervallo di incertezza al 90% per la stima della media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/16_simulation.html#informazioni-sullambiente-di-sviluppo",
    "title": "39  Simulazioni",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_simulation.html#bibliografia",
    "href": "chapters/probability/16_simulation.html#bibliografia",
    "title": "39  Simulazioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nIn questa sezione della dispensa, esamineremo l’inferenza bayesiana applicata a modelli statistici in cui si stima un unico parametro scalare, ovvero quando l’estimando \\(\\theta\\) è unidimensionale.\nIn particolare, considereremo quattro modelli fondamentali e ampiamente utilizzati: il modello binomiale, il modello normale, il modello di Poisson e il modello esponenziale. Approfondiremo il processo di aggiornamento bayesiano analizzando due approcci principali per derivare la distribuzione a posteriori: l’approssimazione numerica tramite il metodo a griglia e l’impiego delle distribuzioni coniugate, in cui una specifica combinazione tra distribuzione a priori e verosimiglianza consente di ottenere la distribuzione a posteriori in forma analitica. Inoltre, esploreremo l’influenza della scelta della distribuzione a priori sulla distribuzione a posteriori e discuteremo le tecniche per sintetizzarla e interpretarla in modo efficace.\nUn aspetto cruciale dell’inferenza bayesiana, particolarmente rilevante nel contesto della crisi della replicabilità in psicologia, è la possibilità di formulare inferenze sulla distribuzione a posteriori dei parametri di interesse teorico senza dover ricorrere a decisioni binarie come “significativo” o “non significativo”. Questo approccio promuove una modalità di analisi più sfumata e rigorosa, con l’obiettivo di stabilire un nuovo standard per la presentazione e l’interpretazione dei risultati, favorendo affermazioni più ponderate nelle ricerche empiriche (Gelman et al., 1995; McElreath, 2020).",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html#bibliografia",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html",
    "href": "chapters/bayesian_inference/01_uncertainty.html",
    "title": "40  Abbracciare l’incertezza",
    "section": "",
    "text": "40.1 Introduzione\nL’espressione “abbracciare l’incertezza” è una delle più rappresentative nel contesto della statistica bayesiana. In questo capitolo, esploreremo il significato di questa affermazione, basandoci sulla trattazione introduttiva proposta nel primo capitolo di Understanding Uncertainty di Lindley (Lindley, 2013).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#lincertezza-nella-ricerca-psicologica",
    "href": "chapters/bayesian_inference/01_uncertainty.html#lincertezza-nella-ricerca-psicologica",
    "title": "40  Abbracciare l’incertezza",
    "section": "40.2 L’incertezza nella ricerca psicologica",
    "text": "40.2 L’incertezza nella ricerca psicologica\nL’incertezza è un elemento centrale non solo nella statistica, ma in tutte le discipline scientifiche, con un’importanza particolare in psicologia, dove si studiano fenomeni complessi e difficili da misurare. Nell’indagare processi cognitivi, emozioni e comportamenti, i ricercatori si trovano spesso ad affrontare dati intricati, ambigui e suscettibili di molteplici interpretazioni. Sebbene alcune affermazioni possano essere sostenute con elevata confidenza o confutate con certezza, la maggior parte delle ipotesi scientifiche si colloca in un’area grigia dominata dall’incertezza.\nL’obiettivo di questo corso è guidare gli studenti nella comprensione e nella gestione dell’incertezza nella ricerca psicologica, adottando l’approccio bayesiano all’analisi dei dati. Questo metodo, basato sulla quantificazione e sull’aggiornamento delle credenze alla luce di nuove evidenze, fornirà agli studenti gli strumenti per affrontare l’incertezza in modo rigoroso e sistematico, sia nella carriera accademica sia nella pratica clinica.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#la-natura-soggettiva-dellincertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#la-natura-soggettiva-dellincertezza",
    "title": "40  Abbracciare l’incertezza",
    "section": "40.3 La natura soggettiva dell’incertezza",
    "text": "40.3 La natura soggettiva dell’incertezza\nUn aspetto cruciale dell’incertezza, spesso trascurato, è la sua dimensione soggettiva. De Finetti (Finetti, 1970) ha sottolineato come l’incertezza sia, almeno in parte, una questione personale: ciò che è incerto per uno psicologo potrebbe non esserlo per un altro, in funzione delle loro esperienze, conoscenze pregresse e interpretazioni dei dati disponibili. Anche di fronte alla stessa questione, due ricercatori possono condividere un’incertezza comune, ma con gradi di intensità diversi.\nQuesta componente soggettiva è particolarmente rilevante in psicologia, dove le differenze individuali e culturali influenzano la percezione e l’interpretazione dei fenomeni. L’approccio bayesiano offre un potente strumento per affrontare questa soggettività, consentendo di quantificare le differenze tra credenze individuali e di aggiornarle in modo coerente sulla base di nuove evidenze oggettive.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#lonnipresenza-dellincertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#lonnipresenza-dellincertezza",
    "title": "40  Abbracciare l’incertezza",
    "section": "40.4 L’onnipresenza dell’incertezza",
    "text": "40.4 L’onnipresenza dell’incertezza\nL’incertezza permea ogni aspetto della ricerca psicologica. Ogni esperimento, misurazione o interpretazione dei dati comporta un margine di incertezza. Questa condizione è particolarmente evidente nello studio di fenomeni complessi come il comportamento umano o i processi mentali, dove innumerevoli variabili interagiscono, molte delle quali difficili da misurare o controllare con precisione.\nTuttavia, l’incertezza non deve essere vista come un ostacolo insormontabile. Al contrario, riconoscerla e quantificarla può favorire una comprensione più profonda e realistica dei fenomeni psicologici. Attraverso l’approccio bayesiano, diventa possibile integrare l’incertezza nel processo di indagine scientifica, trattandola non come un limite, ma come una risorsa (Koetke et al., 2024).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#superare-la-soppressione-dellincertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#superare-la-soppressione-dellincertezza",
    "title": "40  Abbracciare l’incertezza",
    "section": "40.5 Superare la soppressione dell’incertezza",
    "text": "40.5 Superare la soppressione dell’incertezza\nNonostante la sua onnipresenza, l’incertezza è spesso ignorata o minimizzata nella comunicazione scientifica. Questo può avvenire attraverso interpretazioni eccessivamente ottimistiche dei risultati, la presentazione di conclusioni come fatti certi, o una riluttanza a riconoscere i limiti degli studi condotti. Tale atteggiamento, sebbene comprensibile, può condurre a conclusioni errate e a una visione distorta della realtà.\nL’approccio bayesiano permette di affrontare l’incertezza in modo esplicito e costruttivo. Fornendo un quadro rigoroso per quantificarla, analizzarla e comunicarla chiaramente, migliora la trasparenza della ricerca e promuove conclusioni più oneste e accurate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#i-benefici-dellincertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#i-benefici-dellincertezza",
    "title": "40  Abbracciare l’incertezza",
    "section": "40.6 I benefici dell’incertezza",
    "text": "40.6 I benefici dell’incertezza\nContrariamente a quanto si possa pensare, l’incertezza offre numerosi vantaggi per la ricerca psicologica:\n\nStimola l’esplorazione scientifica: La consapevolezza dell’incertezza incoraggia i ricercatori a formulare nuove ipotesi e a migliorare i metodi di studio.\nPromuove l’onestà intellettuale: Accettare l’incertezza rende i ricercatori più cauti e aperti a prospettive alternative.\nMigliora la qualità delle analisi: Integrare l’incertezza porta a disegni sperimentali più robusti e interpretazioni più accurate.\nFacilita la collaborazione interdisciplinare: Riconoscere i limiti delle proprie conoscenze stimola la ricerca di input da altri esperti.\nRiflette la complessità dei fenomeni psicologici: L’incertezza è intrinseca ai processi mentali e riconoscerla consente di rappresentarli in modo più realistico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#tipi-di-incertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#tipi-di-incertezza",
    "title": "40  Abbracciare l’incertezza",
    "section": "40.7 Tipi di incertezza",
    "text": "40.7 Tipi di incertezza\nL’incertezza nella ricerca può essere classificata in tre categorie principali, in base alla sua origine: aleatoria, epistemica e ontologica (Gansch & Adee, 2020).\n\n40.7.1 Incertezza Aleatoria\nL’incertezza aleatoria è intrinseca alla natura casuale di un processo e non può essere eliminata per un dato modello probabilistico. Essa è considerata irreducibile e viene quantificata tramite distribuzioni probabilistiche. Ad esempio, nella misurazione della risposta di un individuo a uno stimolo, la variabilità intrinseca nel comportamento umano, dovuta a fattori imprevedibili, rappresenta un caso di incertezza aleatoria. Questo tipo di incertezza è una caratteristica fondamentale di molti fenomeni psicologici e biologici.\n\n\n40.7.2 Incertezza Epistemica\nL’incertezza epistemica deriva dalla conoscenza limitata o incompleta di un fenomeno. Essa rappresenta il “noto-ignoto”, cioè ciò che sappiamo di non sapere, ed è legata alle semplificazioni insite in ogni modello scientifico. Ad esempio, un modello psicologico che non consideri le influenze culturali o ambientali potrebbe risultare incompleto, introducendo incertezza epistemica. Diversamente dall’incertezza aleatoria, l’incertezza epistemica può essere ridotta attraverso il miglioramento dei modelli, l’inclusione di variabili rilevanti o la raccolta di ulteriori dati.\n\n\n40.7.3 Incertezza Ontologica\nL’incertezza ontologica riguarda l’“ignoto-ignoto”, ovvero aspetti di un sistema che non sono ancora stati identificati. In psicologia, questo potrebbe riferirsi a variabili o processi non ancora scoperti che influenzano un comportamento. Ad esempio, studiando i disturbi mentali, potrebbero emergere nuovi fattori di rischio precedentemente sconosciuti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#il-calcolo-dellincertezza-nellapproccio-bayesiano",
    "href": "chapters/bayesian_inference/01_uncertainty.html#il-calcolo-dellincertezza-nellapproccio-bayesiano",
    "title": "40  Abbracciare l’incertezza",
    "section": "40.8 Il calcolo dell’incertezza nell’approccio bayesiano",
    "text": "40.8 Il calcolo dell’incertezza nell’approccio bayesiano\nL’insegnamento si propone di fornire agli studenti strumenti per affrontare e quantificare l’incertezza attraverso l’approccio bayesiano (Gelman et al., 1995). Fondato sul teorema di Bayes, questo metodo rappresenta un quadro teorico rigoroso e sistematico per aggiornare le credenze alla luce di nuove evidenze, configurandosi come una componente centrale della metodologia scientifica.\nIl processo si basa su quattro passaggi essenziali. In primo luogo, si parte dalla quantificazione delle credenze iniziali, note come prior, che rappresentano le conoscenze pregresse o le ipotesi relative a un determinato fenomeno psicologico. Successivamente, si analizza la forza delle evidenze empiriche fornite dai dati raccolti, formalizzata nella likelihood. Queste due informazioni vengono combinate per generare le credenze aggiornate, chiamate posterior, che sintetizzano la conoscenza disponibile integrando i dati empirici e le ipotesi iniziali. Infine, le credenze aggiornate possono essere utilizzate per prendere decisioni più informate, pianificare ricerche future e orientare interventi.\n\n40.8.1 Il ruolo delle credenze e delle decisioni nella ricerca psicologica\nLe credenze rivestono un ruolo fondamentale nella ricerca psicologica, influenzando tutte le fasi del processo scientifico, dalla progettazione degli esperimenti all’interpretazione dei risultati, fino alla scelta di interventi clinici. L’approccio bayesiano si distingue per la sua capacità di esplicitare e formalizzare queste credenze, consentendo di aggiornare il loro contenuto in modo coerente e trasparente man mano che emergono nuove evidenze.\nQuesto metodo permette non solo di ottimizzare le decisioni basandosi su informazioni aggiornate, ma anche di comunicare chiaramente l’incertezza associata alle conclusioni, evidenziandone i limiti e garantendo maggiore trasparenza scientifica. Affrontare l’incertezza come una componente intrinseca della ricerca non solo migliora la qualità dell’analisi, ma consente anche di promuovere un approccio più realistico e rigoroso nello studio dei fenomeni psicologici.\nIn sintesi, l’approccio bayesiano offre un modello operativo per integrare l’incertezza nel processo decisionale, trattandola non come un ostacolo, ma come un elemento essenziale per una comprensione più sfumata e accurata della realtà.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/01_uncertainty.html#riflessioni-conclusive",
    "title": "40  Abbracciare l’incertezza",
    "section": "40.9 Riflessioni Conclusive",
    "text": "40.9 Riflessioni Conclusive\nQuesto insegnamento fornisce gli strumenti per applicare l’analisi bayesiana nell’ambito dei dati psicologici, insegnando a considerare l’incertezza come una parte integrante e preziosa del processo scientifico. Attraverso questo approccio, gli studenti potranno acquisire una comprensione più raffinata e strutturata dei fenomeni psicologici, integrando l’incertezza come elemento fondamentale per interpretare i dati e formulare inferenze rigorose.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#bibliografia",
    "href": "chapters/bayesian_inference/01_uncertainty.html#bibliografia",
    "title": "40  Abbracciare l’incertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFinetti, B. de. (1970). Teoria delle probabilità: sintesi introduttiva con appendice critica. Einaudi.\n\n\nGansch, R., & Adee, A. (2020). System theoretic view on uncertainties. 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE), 1345–1350.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nKoetke, J., Schumann, K., Bowes, S. M., & Vaupotič, N. (2024). The effect of seeing scientists as intellectually humble on trust in scientists and their research. Nature Human Behaviour, 1–14.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html",
    "href": "chapters/bayesian_inference/01_intro_bayes.html",
    "title": "41  La quantificazione dell’incertezza",
    "section": "",
    "text": "41.1 Introduzione\nL’approccio bayesiano non si limita all’applicazione del Teorema di Bayes, ma si distingue per una gestione esplicita dell’incertezza (si veda il Capitolo 40) e per l’uso delle distribuzioni di probabilità per rappresentare stime e soluzioni. Il processo di modellazione bayesiana, noto come workflow bayesiano (Baribault & Collins, 2023), comprende più fasi iterative: dalla costruzione del modello, all’applicazione del Teorema di Bayes, fino all’analisi critica dei risultati. Questo approccio permette un continuo affinamento delle stime, adattandole alle nuove evidenze.\nL’obiettivo dell’approccio bayesiano non è scoprire una “verità assoluta”, ma aggiornare razionalmente le credenze riguardo a un’ipotesi integrando nuove informazioni. In psicologia, dove le misurazioni sono soggette a incertezza e i fenomeni complessi, questa capacità è cruciale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#introduzione",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#introduzione",
    "title": "41  La quantificazione dell’incertezza",
    "section": "",
    "text": "“Quindi non avete una sola risposta alle vostre domande?”\n“Adson, se l’avessi insegnerei teologia a Parigi.”\n“A Parigi hanno sempre la risposta vera?”\n“Mai,” disse Guglielmo, “ma sono molto sicuri dei loro errori.”\n(Umberto Eco: Il Nome della Rosa)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-valore-dellincertezza",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-valore-dellincertezza",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.2 Il Valore dell’Incertezza",
    "text": "41.2 Il Valore dell’Incertezza\nIn psicologia e nelle scienze sociali, l’incertezza è una componente fondamentale: spesso lavoriamo con informazioni incomplete o imperfette e con variabili latenti che non possono essere osservate direttamente, come l’ansia, la motivazione o l’autostima. La probabilità offre un linguaggio matematico per rappresentare questa incertezza in modo rigoroso e sistematico.\nIn particolare, la probabilità consente di esprimere il grado di fiducia o di conoscenza che abbiamo riguardo a un evento o a un parametro. L’inferenza bayesiana integra la probabilità come strumento per gestire l’incertezza, rappresentandola sotto forma di distribuzioni probabilistiche che possono essere aggiornate man mano che emergono nuove informazioni (Jaynes, 2003).\nA differenza dei modelli deterministici, che assumono la possibilità di prevedere i risultati con certezza, i modelli probabilistici – e in particolare quelli bayesiani – abbracciano l’incertezza come parte integrante della comprensione dei fenomeni. Questo approccio si rivela particolarmente potente in psicologia, dove l’incertezza è intrinseca e i dati spesso offrono una visione parziale della realtà.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.3 Interpretazione Frequentista vs. Bayesiana dell’Incertezza",
    "text": "41.3 Interpretazione Frequentista vs. Bayesiana dell’Incertezza\n\n41.3.1 Interpretazione Frequentista\nL’approccio frequentista definisce la probabilità come la frequenza relativa con cui un evento si verifica nel lungo periodo, in un gran numero di prove simili. Per esempio, se si vuole stimare la probabilità che un individuo superi una certa soglia di ansia, si osserverebbe un ampio numero di individui simili e si calcolerebbe la proporzione di successi (\\(E\\)) rispetto al totale delle prove (\\(N\\)):\n\\[\n\\text{Pr}(E) = \\lim_{N \\to \\infty} \\frac{\\text{numero di volte in cui } E \\text{ si verifica}}{N}.\n\\]\nNel frequentismo, l’incertezza non è rappresentata direttamente, ma emerge dall’impossibilità pratica di osservare un numero infinito di eventi in condizioni identiche. Questo approccio presenta due limiti principali:\n\n\nOsservazioni infinite: Non è realistico osservare un evento infinite volte.\n\nDefinizione del gruppo di riferimento: È spesso difficile identificare con precisione le condizioni rilevanti che caratterizzano il fenomeno (la reference class).\n\nQuesti limiti rendono l’approccio frequentista meno applicabile in psicologia, dove le condizioni sperimentali sono spesso uniche e non ripetibili.\n\n41.3.2 Interpretazione Bayesiana\nL’approccio bayesiano interpreta la probabilità come una misura soggettiva del grado di fiducia in un evento, un’ipotesi o un parametro. La probabilità riflette quindi la nostra incertezza riguardo a un fenomeno, tenendo conto sia delle conoscenze precedenti (priori) sia delle nuove evidenze (dati). Questo legame diretto tra probabilità e incertezza consente di aggiornare le credenze man mano che emergono nuove informazioni.\nIl teorema di Bayes formalizza questo processo:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) \\cdot p(\\theta)}{p(D)},\n\\]\ndove:\n\n\n\\(p(\\theta \\mid D)\\): probabilità a posteriori di \\(\\theta\\), aggiornata in base ai dati \\(D\\),\n\n\\(p(\\theta)\\): probabilità a priori di \\(\\theta\\),\n\n\\(p(D \\mid \\theta)\\): verosimiglianza dei dati dato \\(\\theta\\),\n\n\\(p(D)\\): probabilità totale dei dati.\n\nL’approccio bayesiano rappresenta esplicitamente l’incertezza attraverso distribuzioni probabilistiche. Ogni stima incorpora la variabilità intrinseca dei dati e il grado di fiducia associato.\n\n\n\n\n\n\n\nCaratteristica\nFrequentismo\nBayesiano\n\n\n\nProbabilità\nFrequenza relativa nel lungo periodo\nGrado di credenza soggettiva\n\n\nIncertezza\nNon rappresentata esplicitamente\nModello centrale delle distribuzioni\n\n\nAggiornamento\nNon dinamico\nContinuo, basato sul Teorema di Bayes\n\n\nApplicabilità in Psicologia\nLimitata: richiede condizioni ripetibili\nFlessibile: integra dati e conoscenze\n\n\n\nIn conclusione, l’inferenza bayesiana offre un collegamento diretto tra incertezza e probabilità, rappresentando quest’ultima come una misura della conoscenza attuale su un fenomeno. Questa flessibilità rende l’approccio particolarmente potente per affrontare i problemi complessi della psicologia, dove variabili latenti e incertezza sono elementi centrali. Integrando dati empirici e conoscenze pregresse, l’inferenza bayesiana non solo migliora la precisione delle stime, ma fornisce anche un quadro intuitivo e rigoroso per la comprensione e la modellazione dell’incertezza.\n\nEsempio 41.1 Quando si misura l’ansia tramite questionari, l’incertezza può derivare da:\n\n\nSoggettività delle risposte: L’interpretazione delle domande varia tra individui.\n\nIncompletezza delle misure: Il questionario può non cogliere tutte le sfumature dell’ansia.\n\nRumore nei dati: Errori minori possono influenzare i risultati.\n\nL’inferenza bayesiana consente di rappresentare queste fonti di incertezza con una distribuzione a priori basata su studi precedenti. Man mano che si raccolgono nuovi dati, la distribuzione a posteriori fornisce stime aggiornate e più affidabili.\n\n\nEsempio 41.2 In uno studio sull’effetto del rinforzo negativo sulla motivazione, la “motivazione interna” è una variabile latente non osservabile direttamente. Possiamo inferirla attraverso:\n\n\nMisure indirette: Tempo speso sul compito, velocità di risposta.\n\nModelli bayesiani: Collegano queste variabili osservabili alla motivazione latente, rappresentando l’incertezza individuale e il contributo del rinforzo.\n\nAd esempio, se un modello bayesiano stima che un individuo ha l’80% di probabilità di rispondere positivamente al rinforzo negativo, questa probabilità può essere aggiornata con nuovi dati sperimentali, affinando la comprensione del fenomeno.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.4 Inferenza Bayesiana e Incertezza nelle Stime",
    "text": "41.4 Inferenza Bayesiana e Incertezza nelle Stime\nL’inferenza bayesiana utilizza le probabilità per aggiornare le credenze sui parametri di un modello basandosi sui dati osservati. Queste credenze sono rappresentate da distribuzioni di probabilità, e l’ampiezza di queste distribuzioni riflette l’incertezza associata alle stime. In psicologia, dove spesso si lavora con campioni limitati e misurazioni indirette di variabili latenti, questa gestione dell’incertezza è fondamentale per interpretare i risultati in modo robusto e realistico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-modello-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-modello-bayesiano",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.5 Il Modello Bayesiano",
    "text": "41.5 Il Modello Bayesiano\nUn modello statistico combina una distribuzione probabilistica con ipotesi sui parametri per descrivere un fenomeno osservato. Ad esempio, possiamo modellare il lancio di una moneta equa con un modello binomiale, in cui la probabilità \\(\\theta\\) è fissata a 0.5, oppure modellare l’altezza degli uomini italiani con un modello normale, in cui \\(\\mu\\) è 183 cm e \\(\\sigma\\) è 5 cm. In termini bayesiani, il modello statistico include tre componenti principali:\n\nDistribuzione a Priori (Prior): Rappresenta le credenze iniziali sui valori dei parametri del modello, informate da ricerche precedenti o da assunzioni neutre.\nVerosimiglianza (Likelihood): Descrive la probabilità di osservare i dati dati i parametri del modello, riflettendo il processo che genera i dati.\nDistribuzione a Posteriori (Posterior): È la distribuzione aggiornata dei parametri dopo aver osservato i dati, ottenuta combinando la prior e la verosimiglianza mediante il teorema di Bayes. La posterior rappresenta la conoscenza aggiornata dopo aver integrato le informazioni fornite dai dati.\n\nLa modellazione bayesiana descrive il processo generativo che ha prodotto i dati osservati, incorporando l’incertezza nei parametri e aggiornando continuamente le stime man mano che emergono nuovi dati. Questo approccio è particolarmente utile in contesti come la psicologia, dove i fenomeni complessi e le variabili latenti rendono necessario modellare l’incertezza in modo esplicito.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.6 Componenti Chiave della Modellazione Probabilistica",
    "text": "41.6 Componenti Chiave della Modellazione Probabilistica\n\nVariabili Aleatorie: Quantità incerte che assumono diversi valori secondo una distribuzione di probabilità. Ad esempio, il livello di depressione di un paziente può essere trattato come una variabile aleatoria.\nDistribuzioni di Probabilità: Descrivono come i valori di una variabile aleatoria sono distribuiti. Ad esempio, una distribuzione normale può essere utilizzata per modellare la variabilità dell’ansia in una popolazione.\nInferenza Bayesiana: Aggiorna la distribuzione di probabilità delle variabili di interesse sulla base dei nuovi dati, migliorando progressivamente le stime.\n\n\nEsempio 41.3 In uno studio clinico sulla depressione, possiamo utilizzare l’inferenza bayesiana per stimare il livello di depressione di un paziente partendo da una distribuzione a priori informata da studi precedenti. Ogni nuovo dato raccolto (come punteggi a questionari o osservazioni) permette di aggiornare questa stima, affinando progressivamente la comprensione del fenomeno.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.7 Il Potere dell’Aggiornamento Bayesiano",
    "text": "41.7 Il Potere dell’Aggiornamento Bayesiano\nIl vero punto di forza della modellazione bayesiana risiede nella sua capacità di aggiornare continuamente le credenze sui parametri del modello man mano che si raccolgono nuovi dati. Questo processo iterativo, basato sul teorema di Bayes, consente di integrare sia le credenze iniziali (a priori) sia le evidenze empiriche (verosimiglianza) per ottenere stime sempre più precise.\n\nEsempio 41.4 Un esempio intuitivo per spiegare l’aggiornamento bayesiano è quello proposto da McElreath (2020). Supponiamo di voler stimare la proporzione della superficie terrestre coperta d’acqua. L’esperimento consiste nel lanciare un globo terrestre in aria, afferrarlo e osservare se la superficie sotto il dito è acqua o terra. Dopo ogni osservazione, possiamo aggiornare le nostre credenze sulla proporzione d’acqua (p).\nIniziamo con una distribuzione a priori che assegna la stessa probabilità a tutti i valori possibili di \\(p\\) (proporzione d’acqua). Dopo il primo lancio, in cui osserviamo acqua (“W”), la probabilità che \\(p\\) sia zero diminuisce, mentre quella che \\(p\\) sia maggiore aumenta. Man mano che raccogliamo più dati, la distribuzione si aggiorna, riducendo l’incertezza e convergendo verso una stima più precisa di \\(p\\).\nCon l’aumento dei dati osservati, la distribuzione a posteriori si concentra sempre di più attorno ai valori di \\(p\\) che meglio spiegano i dati. Questo processo rappresenta il continuo affinamento delle stime bayesiane, che diventano più accurate man mano che le evidenze si accumulano.\nIn sintesi, l’aggiornamento bayesiano fornisce un quadro flessibile e sistematico per trattare l’incertezza e integrare nuove informazioni. È particolarmente utile nelle scienze psicologiche e sociali, dove la complessità e la variabilità dei fenomeni rendono difficile ottenere stime precise. Questo approccio consente di migliorare costantemente la comprensione dei fenomeni, adattando le credenze man mano che emergono nuovi dati.\n\n\n\n\n\n\n\n\nIl grafico precedente illustra un processo di aggiornamento bayesiano, in cui vengono progressivamente aggiornate le credenze sulla proporzione di superficie coperta d’acqua (\\(p\\)) del globo terrestre, man mano che vengono raccolti nuovi dati. Dopo ogni lancio, le probabilità sui possibili valori di \\(p\\) vengono aggiornate sulla base delle osservazioni, utilizzando il teorema di Bayes. Il processo è visualizzato attraverso una serie di grafici, organizzati in una griglia 3x3, con ogni pannello che rappresenta un’osservazione aggiuntiva.\nNota sui grafici.\n\n\nLinea Blu: La distribuzione a posteriori calcolata per il pannello corrente.\n\nLinea Grigia: La distribuzione a priori utilizzata, che è il posterior del pannello precedente.\n\nAggiornamento Bayesiano: Ogni volta che vengono osservati nuovi dati, la distribuzione a posteriori diventa il a priori per il passo successivo, consentendo di incorporare progressivamente l’informazione osservata.\n\n\n\n\n\n\n\n\nApprofondimento\n\n\n\n\n\nA una prima lettura, è sufficiente focalizzarsi sul significato dell’aggiornamento bayesiano e sulle conseguenze che questo produce rispetto alle nostre credenze su \\(p\\), man mano che vengono osservati nuovi dati. Per il momento, il meccanismo dettagliato attraverso cui l’aggiornamento bayesiano viene realizzato non è ancora stato esplicitato, e quindi gli studenti possono inizialmente tralasciare la spiegazione approfondita contenuta in questo riquadro.\nDopo aver letto il contenuto di Capitolo 46, sarà possibile tornare sull’esempio discusso qui e comprenderne appieno l’aggiornamento bayesiano, interpretandolo alla luce delle proprietà delle famiglie coniugate. Questo consentirà di cogliere non solo il significato generale dell’aggiornamento, ma anche i dettagli tecnici che lo rendono particolarmente efficiente in contesti come quello descritto.\nPrimo Pannello.\n\n\nOsservazione iniziale: Abbiamo il primo dato, un successo (“W”).\n\nA priori: La distribuzione a priori iniziale è una distribuzione Beta(1, 1). Questa rappresenta una conoscenza iniziale non informativa, ovvero l’ipotesi che qualsiasi proporzione di successi (\\(p\\)) sia ugualmente probabile.\n\nA posteriori: Con un successo su una prova: \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(1 + 1, 1 + 0) = \\mathcal{Beta}(2, 1).\n\\] La distribuzione risultante è concentrata verso i valori più alti di \\(p\\), riflettendo il successo osservato.\n\nSecondo Pannello.\n\n\nOsservazioni: Ora abbiamo due dati, “W” e “L”, quindi un successo su due prove.\n\nA priori: La distribuzione a priori per questo passo è il posterior del pannello precedente, ovvero \\(\\mathcal{Beta}(2, 1)\\).\n\nA posteriori: Con un successo (\\(W = 1\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(2 + 1, 1 + 1) = \\mathcal{Beta}(3, 2).\n\\] La nuova distribuzione riflette un aggiornamento che tiene conto sia del successo che dell’insuccesso.\n\nTerzo Pannello.\n\n\nOsservazioni: Ora abbiamo tre dati, “W”, “L”, “W”, quindi due successi su tre prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(3, 2)\\).\n\nA posteriori: Con due successi (\\(W = 2\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(3 + 1, 2 + 0) = \\mathcal{Beta}(4, 2).\n\\]\n\n\nQuarto Pannello.\n\n\nOsservazioni: Ora abbiamo quattro dati, “W”, “L”, “W”, “W”, quindi tre successi su quattro prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(4, 2)\\).\n\nA posteriori: Con tre successi (\\(W = 3\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(4 + 1, 2 + 0) = \\mathcal{Beta}(5, 2).\n\\]\n\n\nQuinto Pannello.\n\n\nOsservazioni: Ora abbiamo cinque dati, “W”, “L”, “W”, “W”, “L”, quindi tre successi su cinque prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(5, 2)\\).\n\nA posteriori: Con tre successi (\\(W = 3\\)) e due insuccessi (\\(L = 2\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(5 + 0, 2 + 1) = \\mathcal{Beta}(5, 3).\n\\]\n\n\nSesto Pannello.\n\n\nOsservazioni: Ora abbiamo sei dati, “W”, “L”, “W”, “W”, “L”, “W”, quindi quattro successi su sei prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(5, 3)\\).\n\nA posteriori: Con quattro successi (\\(W = 4\\)) e due insuccessi (\\(L = 2\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(5 + 1, 3 + 0) = \\mathcal{Beta}(6, 3).\n\\]\n\n\nSettimo Pannello.\n\n\nOsservazioni: Ora abbiamo sette dati, “W”, “L”, “W”, “W”, “L”, “W”, “L”, quindi quattro successi su sette prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(6, 3)\\).\n\nA posteriori: Con quattro successi (\\(W = 4\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(6 + 0, 3 + 1) = \\mathcal{Beta}(6, 4).\n\\]\n\n\nOttavo Pannello.\n\n\nOsservazioni: Ora abbiamo otto dati, “W”, “L”, “W”, “W”, “L”, “W”, “L”, “W”, quindi cinque successi su otto prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(6, 4)\\).\n\nA posteriori: Con cinque successi (\\(W = 5\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(6 + 1, 4 + 0) = \\mathcal{Beta}(7, 4).\n\\]\n\n\nNono Pannello.\n\n\nOsservazioni: Ora abbiamo nove dati, “W”, “L”, “W”, “W”, “L”, “W”, “L”, “W”, “W”, quindi sei successi su nove prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(7, 4)\\).\n\nA posteriori: Con sei successi (\\(W = 6\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(7 + 1, 4 + 0) = \\mathcal{Beta}(8, 4).\n\\]\n\n\n\n\n\nQuesto processo mostra come il modello bayesiano aggiorna continuamente le credenze man mano che i dati vengono osservati. Ogni nuovo pannello segue lo stesso schema: la distribuzione a priori (linea tratteggiata) viene aggiornata con la nuova osservazione (linea continua). Se viene osservata acqua (W), il picco della distribuzione si sposta a destra; se viene osservata terra (L), il picco si sposta a sinistra. In ogni caso, la curva diventa progressivamente più “appuntita”, indicando che l’incertezza sulla vera proporzione di acqua diminuisce con l’aumentare del numero di osservazioni.\nL’aspetto fondamentale dell’approccio bayesiano è che ogni distribuzione a posteriori aggiornata (linea continua) diventa la nuova distribuzione a priori per la successiva osservazione. Questo processo iterativo permette di apprendere progressivamente dai dati, integrando ogni nuova informazione per affinare la stima di \\(p\\). Alla fine, la distribuzione diventa sempre più concentrata intorno al valore più probabile di \\(p\\), man mano che raccogliamo più dati.\nIn conclusione, l’esempio illustra come l’aggiornamento bayesiano modifichi le nostre credenze sulla proporzione d’acqua (\\(p\\)) sulla superficie del globo, basandosi sulle osservazioni raccolte. Ogni curva rappresenta la sintesi delle conoscenze attuali, combinando le osservazioni precedenti con l’ultima evidenza raccolta. Il grafico dimostra visivamente come l’approccio bayesiano consenta di trattare l’incertezza e aggiornare le stime in modo coerente e progressivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.8 Il Processo Generatore dei Dati",
    "text": "41.8 Il Processo Generatore dei Dati\nL’esempio precedente mette in evidenza come, nel contesto dell’aggiornamento bayesiano, sia cruciale fare un’assunzione sul processo generatore dei dati, ovvero il meccanismo che collega i parametri sconosciuti ai dati osservati. Questo processo è formalizzato attraverso la funzione di verosimiglianza, che esprime la probabilità di osservare i dati disponibili per ogni valore possibile del parametro incognito.\nNel caso degli esperimenti bernoulliani, come il lancio del globo, ogni prova ha due possibili esiti: un successo (acqua) o un fallimento (terra). L’obiettivo è stimare la probabilità di successo, denotata con \\(\\theta\\). Il processo generatore dei dati per questo tipo di esperimento è ben rappresentato dalla distribuzione binomiale, che modella il numero di successi osservati su un certo numero di prove indipendenti, ciascuna con probabilità di successo pari a \\(\\theta\\):\n\\[\nP(W \\mid \\theta, n) = \\binom{n}{W} \\theta^W (1 - \\theta)^{n-W},\n\\]\ndove \\(\\binom{n}{W}\\) è il coefficiente binomiale che calcola il numero di combinazioni possibili di \\(W\\) successi in \\(n\\) prove.\nIn questo contesto, \\(\\theta\\) rappresenta la proporzione di superficie coperta d’acqua sul globo. L’assunzione fondamentale è che \\(\\theta\\) sia costante durante l’intero esperimento, garantendo che tutte le prove siano indipendenti e identicamente distribuite. Questo implica che ogni osservazione porta informazioni utili per aggiornare le nostre credenze su \\(\\theta\\), che si riflettono nella distribuzione a posteriori ad ogni passo.\nGrazie a questa struttura probabilistica, il processo di aggiornamento bayesiano ci consente di:\n\nIniziare con una distribuzione a priori che riflette le nostre conoscenze o ipotesi iniziali su \\(\\theta\\).\nUtilizzare la funzione di verosimiglianza per incorporare i dati osservati.\nCalcolare la distribuzione a posteriori, che sintetizza le nostre credenze aggiornate su \\(\\theta\\).\n\nQuesto processo iterativo consente di affinare progressivamente la stima del parametro \\(\\theta\\), integrando in modo rigoroso le informazioni provenienti dai dati.\n\n\n\n\n\nFigura 41.1: Gli stessi dati possono essere coerenti con diverse ipotesi riguardanti il processo che li ha generati(Figura tratta da Freiesleben & Molnar, 2024).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.9 Interpretazione della Distribuzione a Posteriori",
    "text": "41.9 Interpretazione della Distribuzione a Posteriori\nLa distribuzione a posteriori rappresenta l’aggiornamento delle nostre credenze su \\(\\theta\\) alla luce dei dati osservati. Questa distribuzione non solo sintetizza le informazioni provenienti dall’esperimento, ma ci permette anche di fare inferenze più robuste e quantitative su \\(\\theta\\).\nLa distribuzione a posteriori può essere interpretata utilizzando diverse statistiche riassuntive:\n\n\nModa: È il valore di \\(\\theta\\) con la massima densità di probabilità. Questo rappresenta la stima più plausibile di \\(\\theta\\) dato il modello e i dati osservati.\n\nMedia e Mediana: La media della distribuzione a posteriori fornisce una stima centrale ponderata da tutta la distribuzione, mentre la mediana individua il valore che divide la distribuzione in due metà uguali. Queste misure possono variare leggermente a seconda della simmetria o asimmetria della distribuzione.\n\nL’incertezza associata alla stima di \\(\\theta\\) è rappresentata dalla larghezza della distribuzione a posteriori:\n\nUna distribuzione stretta indica una bassa incertezza: la probabilità si concentra in un intervallo ristretto di valori, riflettendo una maggiore fiducia nella stima di \\(\\theta\\).\nUna distribuzione ampia suggerisce una maggiore incertezza: i dati osservati non sono sufficienti per restringere l’intervallo delle credenze su \\(\\theta\\).\n\nCon l’aumentare dei dati raccolti, la distribuzione a posteriori diventa progressivamente più concentrata attorno al valore più probabile di \\(\\theta\\), riducendo l’incertezza e migliorando la precisione delle inferenze.\n\nEsempio 41.5 Nel contesto dei lanci del globo, supponiamo che la distribuzione a posteriori abbia un picco vicino a \\(\\theta = 0.67\\). Questo significa che la stima più plausibile della proporzione di superficie coperta d’acqua sul globo è il 67%. Se la distribuzione è stretta, possiamo affermare con maggiore sicurezza che la vera proporzione è vicina a questo valore. Al contrario, una distribuzione più ampia rifletterebbe una maggiore incertezza, indicando che ulteriori osservazioni sono necessarie per affinare la stima.\n\nIn conclusione, la distribuzione a posteriori non solo fornisce una stima puntuale di \\(\\theta\\), ma cattura anche l’incertezza associata a questa stima. Attraverso il suo utilizzo, possiamo integrare rigorosamente i dati con le ipotesi iniziali e ottenere inferenze che riflettono sia le informazioni disponibili sia la variabilità residua.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.10 Influenza delle Distribuzioni a Priori",
    "text": "41.10 Influenza delle Distribuzioni a Priori\nIn questo esempio, abbiamo utilizzato una distribuzione a priori uniforme, che esprime una totale mancanza di conoscenza iniziale su \\(\\theta\\). Tuttavia, in contesti in cui abbiamo informazioni preesistenti, è possibile utilizzare distribuzioni a priori più informative. Ad esempio, se sappiamo da studi precedenti che circa il 70% della superficie terrestre è coperta d’acqua, possiamo utilizzare una distribuzione a priori che rifletta questa conoscenza. Questo tipo di distribuzione a priori informativa può rendere l’aggiornamento bayesiano più efficiente, portando a stime più precise con meno dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.11 Vantaggi dell’Aggiornamento Bayesiano",
    "text": "41.11 Vantaggi dell’Aggiornamento Bayesiano\nUno dei principali vantaggi dell’approccio bayesiano è che ogni nuova osservazione aggiorna automaticamente le credenze preesistenti, integrando le informazioni precedenti con i nuovi dati. Questo processo consente un apprendimento iterativo e progressivo, che diventa più efficiente man mano che si accumulano dati. Inoltre, la flessibilità nella scelta della distribuzione a priori consente al ricercatore di adattare l’inferenza bayesiana al contesto specifico, migliorando ulteriormente la precisione delle stime.\nIn sintesi, il processo generatore dei dati, modellato tramite la verosimiglianza, gioca un ruolo centrale nell’aggiornamento bayesiano. Nel caso del globo, abbiamo modellato il fenomeno utilizzando una distribuzione binomiale e, attraverso l’applicazione del Teorema di Bayes, abbiamo aggiornato progressivamente le nostre credenze sulla proporzione di acqua osservata. Il risultato è una stima sempre più precisa di \\(\\theta\\), con una distribuzione a posteriori che riflette sia le osservazioni passate sia le nuove evidenze, riducendo progressivamente l’incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#riflessioni-conclusive",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.12 Riflessioni Conclusive",
    "text": "41.12 Riflessioni Conclusive\nNegli ultimi anni, i metodi bayesiani stanno acquisendo sempre più importanza nel campo dell’inferenza statistica, anche in discipline come la psicologia. Questa diffusione è favorita dall’accesso a risorse educative e a testi fondamentali, come quelli di Albert & Hu (2019), Johnson et al. (2022), McElreath (2020) e Kruschke (2014), che hanno reso la modellizzazione bayesiana più accessibile, chiarendo i concetti centrali in modo pratico e comprensibile.\nL’approccio bayesiano si distingue dalla metodologia frequentista tradizionale per la sua capacità di trattare i parametri di interesse come quantità probabilistiche. Invece di considerare i parametri come valori fissi e sconosciuti (come avviene nel paradigma frequentista), il bayesianesimo assegna ai parametri una distribuzione a priori, che rappresenta le credenze iniziali del ricercatore. Man mano che nuovi dati vengono raccolti, queste credenze vengono aggiornate tramite il teorema di Bayes, portando a una distribuzione a posteriori che riflette sia le informazioni pregresse sia l’evidenza empirica. Questa distribuzione aggiornata consente di esprimere l’incertezza sui parametri in modo più completo e informato.\nUno dei principali vantaggi dell’approccio bayesiano è la sua capacità di combinare conoscenze pregresse con nuove osservazioni in modo fluido e sistematico. Ogni nuova informazione arricchisce e raffina le stime, rendendole più accurate e interpretabili nel contesto del problema specifico. Questo non solo migliora la precisione delle inferenze, ma permette anche una migliore comprensione dell’incertezza che circonda i parametri studiati.\nIn definitiva, l’inferenza bayesiana non è solo uno strumento analitico, ma un approccio dinamico che incoraggia un’interazione continua tra teoria ed evidenza. Offrendo una flessibilità unica e una gestione esplicita dell’incertezza, il bayesianesimo si rivela un metodo potente per supportare il processo decisionale in contesti complessi, rendendo le sue applicazioni particolarmente rilevanti in campi come la psicologia, dove l’incertezza è una componente inevitabile dell’analisi dei dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "41  La quantificazione dell’incertezza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#bibliografia",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#bibliografia",
    "title": "41  La quantificazione dell’incertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBaribault, B., & Collins, A. G. (2023). Troubleshooting Bayesian cognitive models. Psychological Methods.\n\n\nFreiesleben, T., & Molnar, C. (2024). Supervised Machine Learning for Science: How to stop worrying and love your black box. https://ml-science-book.com/\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nKruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_statistical_models.html",
    "href": "chapters/bayesian_inference/02_statistical_models.html",
    "title": "42  Modelli statistici",
    "section": "",
    "text": "42.1 Introduzione\nIl quadro concettuale per la modellizzazione e l’analisi statistica è illustrato nella figura seguente. Il punto di partenza è un problema reale (la realtà) e un corrispondente insieme di dati. Sulla base di questi dati, desideriamo trarre delle conclusioni riguardo al problema reale. Il secondo passo consiste nell’individuare un modello probabilistico per i dati. Questo modello incorpora ciò che sappiamo sulla realtà e su come i dati sono stati ottenuti. All’interno del modello, eseguiamo i nostri calcoli e le nostre analisi, che portano a conclusioni riguardanti il modello stesso. Infine, queste conclusioni sul modello vengono tradotte in conclusioni sulla realtà.\nLa statistica matematica utilizza la teoria della probabilità e altri rami della matematica per studiare i dati. In particolare, i dati sono considerati come realizzazioni di variabili casuali la cui distribuzione congiunta è specificata in anticipo, eventualmente con alcuni parametri sconosciuti. L’analisi matematica si concentra quindi esclusivamente sul modello e sui suoi parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_statistical_models.html#introduzione",
    "href": "chapters/bayesian_inference/02_statistical_models.html#introduzione",
    "title": "42  Modelli statistici",
    "section": "",
    "text": "Figura 42.1: Modellizzazione e analisi statistica (figura tratta da Chan & Kroese, 2025).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_statistical_models.html#campionamento-indipendente-da-una-distribuzione-fissa",
    "href": "chapters/bayesian_inference/02_statistical_models.html#campionamento-indipendente-da-una-distribuzione-fissa",
    "title": "42  Modelli statistici",
    "section": "\n42.2 Campionamento indipendente da una distribuzione fissa",
    "text": "42.2 Campionamento indipendente da una distribuzione fissa\nUno dei modelli statistici più semplici è quello in cui i dati\\(X_1, \\ldots, X_n\\)sono considerati indipendenti e identicamente distribuiti (iid). Per indicare che le variabili casuali formano un campione iid da una distribuzione di probabilità, si utilizza la notazione:\n\\[\nX_1, \\ldots, X_n \\stackrel{\\text{iid}}{\\sim} f \\quad \\text{oppure} \\quad X_1, \\ldots, X_n \\stackrel{\\text{iid}}{\\sim} \\text{Dist},\n\\]\ndove \\(f\\) rappresenta la funzione di densità di probabilità (pdf) della distribuzione, e “Dist” indica una generica distribuzione. Sia \\(f(x_1, \\ldots, x_n)\\) la pdf congiunta delle variabili \\(X_1, \\ldots, X_n\\). Allora, per la Regola del Prodotto, la pdf congiunta può essere espressa come il prodotto delle pdf marginali:\n\\[\nf(x_1, \\ldots, x_n) = f(x_1) \\cdot f(x_2) \\cdot \\ldots \\cdot f(x_n).\n\\]\nIn altre parole, poiché le variabili sono indipendenti e identicamente distribuite, la distribuzione congiunta è semplicemente il prodotto delle distribuzioni individuali di ciascuna variabile.\n\nEsempio 42.1 Ogni scenario descritto di seguito può essere modellato tramite un campione di variabili casuali indipendenti e identicamente distribuite (I.I.D.).\n\n\nLancio di un dado: Lanciamo un dado 100 volte e registriamo se al lancio i-esimo compare il numero 6 o meno. Definiamo \\(X_i = 1\\) se al lancio i-esimo esce un 6, e \\(X_i = 0\\) altrimenti, per \\(i = 1, \\dots, 100\\). Allora:\n\n\\[\n   X_1, \\dots, X_{100} \\sim \\text{Ber}(p) \\quad \\text{(indipendentemente e identicamente distribuite)},\n  \\]\ndove \\(p\\) è la probabilità di ottenere un 6 in un singolo lancio (nota o sconosciuta). Ad esempio, se il dado è equilibrato, \\(p = 1/6\\).\n\n\nMisurazione delle altezze: Selezioniamo casualmente 300 uomini tra i 40 e i 50 anni da una popolazione ampia e misuriamo le loro altezze. Sia \\(X_i\\)l’altezza dell’uomo i-esimo selezionato, per \\(i = 1, \\dots, 300\\). Allora:\n\n\\[\n   X_1, \\dots, X_{300} \\sim N(\\mu, \\sigma^2),\n  \\]\ndove \\(\\mu\\) e \\(\\sigma^2\\) sono rispettivamente la media e la varianza della distribuzione delle altezze, parametri sconosciuti.\n\n\nValutazione delle reazioni a stimoli emotivi: Un gruppo di 20 partecipanti viene sottoposto a uno studio in cui vengono mostrati diversi stimoli emotivi (ad esempio, immagini positive, negative o neutre). Per ciascun partecipante, viene registrato il numero di volte in cui si verifica una risposta fisiologica significativa (come un aumento del battito cardiaco) durante l’esposizione agli stimoli. Sia \\(X_i\\) il numero di risposte fisiologiche significative registrate per il partecipante i-esimo, per \\(i = 1, \\dots, 20\\). Allora:\n\n\\[\n   X_1, \\dots, X_{20} \\sim \\text{Poi}(\\mu),\n  \\]\ndove \\(\\mu &gt; 0\\) è il parametro di intensità della distribuzione di Poisson, che rappresenta la frequenza media di risposte fisiologiche significative per stimolo.\n\n\nSimulazione di test cognitivi: Un ricercatore sviluppa un modello computazionale per simulare le prestazioni cognitive di individui in un test di memoria. Il modello viene eseguito 10 volte con diverse configurazioni iniziali casuali (seed diversi), e per ogni esecuzione viene registrato il punteggio totale ottenuto nel test simulato. Sia \\(X_i\\) il punteggio totale ottenuto nella i-esima simulazione, per \\(i = 1, \\dots, 10\\). Allora:\n\n\\[\n   X_1, \\dots, X_{10} \\sim \\text{Dist},\n  \\]\ndove \\(\\text{Dist}\\) è una distribuzione sconosciuta che descrive la variabilità dei punteggi totali nei test cognitivi simulati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_statistical_models.html#campioni-multipli-indipendenti",
    "href": "chapters/bayesian_inference/02_statistical_models.html#campioni-multipli-indipendenti",
    "title": "42  Modelli statistici",
    "section": "\n42.3 Campioni Multipli Indipendenti",
    "text": "42.3 Campioni Multipli Indipendenti\nIl caso di un singolo campione I.I.D. (indipendente e identicamente distribuito), descritto nella Sezione 4.1, può essere facilmente generalizzato a più campioni I.I.D. I modelli più comuni coinvolgono variabili casuali di Bernoulli e normali.\n\nEsempio 42.2 Per valutare se esista una differenza tra i ragazzi e le ragazze riguardo alla propensione a rispondere “sì” a una domanda su un particolare tratto di personalità (ad esempio, “Ti consideri una persona empatica?”), selezioniamo casualmente 100 ragazzi e 100 ragazze e chiediamo loro di rispondere “sì” o “no” alla domanda. Questo scenario può essere modellato tramite due campioni indipendenti di variabili casuali di Bernoulli.\nSpecificamente, per\\(i = 1, \\dots, 100\\):\n\nSia \\(X_i = 1\\) se il ragazzo i-esimo risponde “sì” alla domanda, e \\(X_i = 0\\) altrimenti.\n\nSia \\(Y_i = 1\\) se la ragazza i-esima risponde “sì” alla domanda, e \\(Y_i = 0\\) altrimenti.\n\nIn questo modo, otteniamo il seguente modello:\n\\[\nX_1, \\dots, X_{100} \\sim \\text{Ber}(p_1) \\quad \\text{(I.I.D.)},\n\\]\n\\[\nY_1, \\dots, Y_{100} \\sim \\text{Ber}(p_2) \\quad \\text{(I.I.D.)},\n\\]\ndove \\(X_1, \\dots, X_{100}, Y_1, \\dots, Y_{100}\\) sono variabili indipendenti, e \\(p_1\\) e \\(p_2\\) sono parametri sconosciuti che rappresentano, rispettivamente, la probabilità che un ragazzo o una ragazza risponda “sì” alla domanda.\nL’obiettivo è stimare la differenza \\(p_1 - p_2\\) basandosi sui valori osservati di \\(X_1, \\dots, X_{100}\\) e \\(Y_1, \\dots, Y_{100}\\). Nota che è sufficiente registrare il numero totale di ragazzi e ragazze che rispondono “sì” in ciascun gruppo, ovvero:\n\\[\nX = \\sum_{i=1}^{100} X_i \\quad \\text{e} \\quad Y = \\sum_{i=1}^{100} Y_i.\n\\]\nQuesto porta al modello binomiale a due campioni:\n\\[\nX \\sim \\text{Bin}(100, p_1), \\quad Y \\sim \\text{Bin}(100, p_2),\n\\]\ndove \\(X\\) e \\(Y\\) sono indipendenti, e \\(p_1\\) e \\(p_2\\) sono sconosciuti.\n\n\nEsempio 42.3 Da una popolazione ampia, selezioniamo 200 uomini tra i 25 e i 30 anni e misuriamo le loro altezze. Per ogni persona, registreremo anche se la madre ha fumato durante la gravidanza o meno. Supponiamo che 60 madri abbiano fumato durante la gravidanza.\nSia:\n\n\n\\(X_1, \\dots, X_{60}\\) le altezze degli uomini le cui madri hanno fumato,\n\n\\(Y_1, \\dots, Y_{140}\\) le altezze degli uomini le cui madri non hanno fumato.\n\nUn possibile modello è quello normale a due campioni: \\[\nX_1, \\dots, X_{60} \\sim N(\\mu_1, \\sigma_1^2) \\quad \\text{(I.I.D.)},\n\\]\n\\[\nY_1, \\dots, Y_{140} \\sim N(\\mu_2, \\sigma_2^2) \\quad \\text{(I.I.D.)},\n\\]\ndove \\(X_1, \\dots, X_{60}, Y_1, \\dots, Y_{140}\\) sono variabili indipendenti, e i parametri \\(\\mu_1, \\mu_2, \\sigma_1^2, \\sigma_2^2\\) sono sconosciuti.\nTipicamente, si vorrebbe valutare la differenza \\(\\mu_1 - \\mu_2\\), ovvero se il fumo durante la gravidanza influisce sull’altezza media dei figli. Invece di dividere i dati in due gruppi (madri fumatrici e non fumatrici), sarebbe possibile suddividere ulteriormente il gruppo “madri fumatrici” in sottogruppi in base all’intensità del fumo, ad esempio: raramente, moderatamente e intensamente. In tal caso, i dati potrebbero essere modellati tramite quattro campioni indipendenti da una distribuzione normale. Tale modello dipenderebbe, in generale, da otto parametri sconosciuti: quattro medie (\\(\\mu_1, \\mu_2, \\mu_3, \\mu_4\\)) e quattro varianze (\\(\\sigma_1^2, \\sigma_2^2, \\sigma_3^2, \\sigma_4^2\\)).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_statistical_models.html#modelli-di-regressione-lineare",
    "href": "chapters/bayesian_inference/02_statistical_models.html#modelli-di-regressione-lineare",
    "title": "42  Modelli statistici",
    "section": "\n42.4 Modelli di Regressione Lineare",
    "text": "42.4 Modelli di Regressione Lineare\nL’analisi della regressione riguarda la ricerca di relazioni tra diverse variabili. In particolare, c’è una variabile di risposta (o dipendente) che si vuole “spiegare” tramite una o più variabili esplicative (o indipendenti). Le variabili esplicative vengono anche chiamate predittori, covariate o variabili indipendenti. Nell’ultimo caso, la variabile di risposta è detta variabile dipendente. La regressione viene generalmente vista come una relazione funzionale tra variabili continue.\n\n42.4.1 Regressione Lineare Semplice\nIl modello di regressione più basilare prevede una relazione lineare tra la variabile di risposta e una singola variabile esplicativa. Come nei dati sull’altezza forniti da Pearson, abbiamo misurazioni \\((x_1, y_1), \\dots, (x_n, y_n)\\) che giacciono approssimativamente su una retta. Si assume che queste misurazioni siano realizzazioni di coppie \\((x_1, Y_1), \\dots, (x_n, Y_n)\\), dove, per ogni variabile esplicativa deterministica \\(x_i\\), la variabile di risposta \\(Y_i\\) è una variabile casuale con:\n\\[\n\\mathbb{E}[Y_i] = \\beta_0 + \\beta_1 x_i, \\quad i = 1, \\dots, n,\n\\]\ndove \\(\\beta_0\\) e \\(\\beta_1\\) sono parametri sconosciuti. La retta sconosciuta:\n\\[\ny = \\beta_0 + \\beta_1 x\n\\]\nè detta retta di regressione. Per specificare completamente il modello, è necessario definire la distribuzione congiunta di \\(Y_1, \\dots, Y_n\\). Il modello di regressione lineare più comune è descritto di seguito. L’aggettivo “semplice” si riferisce al fatto che viene utilizzata una sola variabile esplicativa per spiegare la risposta.\n\n42.4.2 Regressione Lineare Multipla\nUn modello di regressione lineare che include più di una variabile esplicativa è detto modello di regressione lineare multipla. In un modello di regressione lineare multipla gaussiana, i dati di risposta \\(Y_1, \\dots, Y_n\\) dipendono da variabili esplicative multidimensionali \\(x_1, \\dots, x_n\\), con \\(x_i = [x_{i1}, \\dots, x_{id}]^T\\), attraverso la relazione lineare:\n\\[\nY_i = \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_d x_{id} + \\varepsilon_i, \\quad \\varepsilon_1, \\dots, \\varepsilon_n \\sim \\text{i.i.d. } N(0, \\sigma^2),\n\\]\ndove \\(\\varepsilon_i\\) rappresenta il termine di errore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_statistical_models.html#regressione-generale",
    "href": "chapters/bayesian_inference/02_statistical_models.html#regressione-generale",
    "title": "42  Modelli statistici",
    "section": "\n42.5 Regressione Generale",
    "text": "42.5 Regressione Generale\n\n42.5.1 Modelli di Regressione Non Lineari\nLa regressione generale si occupa di modellare la relazione tra una variabile risposta \\(Y\\) e una o più variabili esplicative \\(x\\). In molti casi, la relazione tra le variabili non è lineare, ma può essere descritta da funzioni più complesse. Un modello di regressione generale può essere espresso nella forma:\n\\[\nY_i = g(x_i; \\beta) + \\varepsilon_i, \\quad i = 1, \\dots, n,\n\\]\ndove:\n\n\n\\(g(x; \\beta)\\) è una funzione nota che descrive la relazione tra la variabile risposta \\(Y\\) e le variabili esplicative \\(x\\), dipendente dai parametri \\(\\beta\\).\n\n\\(\\varepsilon_i\\) rappresenta il termine di errore, solitamente assunto indipendente e identicamente distribuito (i.i.d.) con media nulla.\n\nSe la funzione \\(g(x; \\beta)\\) è lineare nei parametri \\(\\beta\\), il modello è detto modello di regressione lineare. Tuttavia, quando \\(g(x; \\beta)\\) è una funzione non lineare in \\(\\beta\\), il modello è definito come modello di regressione non lineare.\n\n42.5.1.0.1 Esempi di Modelli Non Lineari\nAlcuni esempi comuni di modelli di regressione non lineari includono:\n\nModello Esponenziale: \\[\ny = a e^{bx},\n\\] dove \\(a\\) e \\(b\\) sono parametri da stimare.\nModello di Legge di Potenza: \\[\ny = a x^b,\n\\] utile per descrivere fenomeni in cui la relazione tra \\(y\\) e \\(x\\) è proporzionale a una potenza di \\(x\\).\nModello Logistico: \\[\ny = \\frac{L}{1 + e^{-(a + bx)}},\n\\] spesso utilizzato per modellare crescita limitata o curve a “S”.\nModello di Weibull: \\[\ny = 1 - e^{-\\left(\\frac{x}{a}\\right)^b},\n\\] comunemente usato in analisi della sopravvivenza e affidabilità.\n\nIn questi modelli, la funzione \\(g(x; \\beta)\\) non è lineare nei parametri \\(\\beta\\), richiedendo metodi di stima specifici, come la minimizzazione della somma dei quadrati ponderati o l’uso di algoritmi iterativi.\n\n42.5.2 Modello Lineare Generalizzato (GLM)\nNel contesto dei modelli lineari standard, si assume che gli errori \\(\\varepsilon_i\\) siano distribuiti normalmente con media zero e varianza costante (\\(\\varepsilon_i \\sim N(0, \\sigma^2)\\)). Tuttavia, in molte applicazioni reali, questa ipotesi non è soddisfatta. Ad esempio:\n\nLe variabili risposta possono essere binarie (successo/fallimento), conteggiate (numeri interi non negativi), o positive e skewed.\nLa varianza degli errori può non essere costante (eteroschedasticità).\n\nPer affrontare queste situazioni, si utilizzano i modelli lineari generalizzati (GLM), che estendono i modelli lineari tradizionali rilassando l’ipotesi di normalità sugli errori e consentendo relazioni non lineari tra la media della variabile risposta e le variabili esplicative.\nUn GLM è definito da tre componenti principali:\n\nFunzione di Link: Una funzione \\(h(\\cdot)\\) che collega la media della variabile risposta \\(\\mu = \\mathbb{E}[Y]\\) alle variabili esplicative tramite un modello lineare: \\[\nh(\\mu) = \\mathbf{x}^T \\beta.\n\\] Ad esempio, nel caso del modello logistico, la funzione di link è il logit: \\[\nh(\\mu) = \\log\\left(\\frac{\\mu}{1 - \\mu}\\right).\n\\]\nDistribuzione della Variabile Risposta: Si assume che \\(Y\\) segua una distribuzione appartenente alla famiglia esponenziale, come Bernoulli, Poisson, Gamma, o Binomiale Negativa.\n\nRelazione di Varianza: La varianza di \\(Y\\) è funzione della sua media \\(\\mu\\), ad esempio:\n\nPer la distribuzione Poisson: \\(\\text{Var}(Y) = \\mu\\),\nPer la distribuzione Gamma: \\(\\text{Var}(Y) = \\phi \\mu^2\\).\n\n\n\n\n42.5.2.0.1 Esempi di GLM\n\nRegressione Logistica: Utilizzata quando la variabile risposta è binaria (\\(Y \\in \\{0, 1\\}\\)): \\[\n\\log\\left(\\frac{\\mu}{1 - \\mu}\\right) = \\mathbf{x}^T \\beta,\n\\] dove \\(\\mu = \\mathbb{P}(Y = 1)\\).\nRegressione di Poisson: Utilizzata per dati di conteggio (\\(Y \\in \\{0, 1, 2, \\dots\\}\\)): \\[\n\\log(\\mu) = \\mathbf{x}^T \\beta,\n\\] dove \\(\\mu = \\mathbb{E}[Y]\\).\nRegressione Gamma: Utilizzata per dati continui positivi e skewed: \\[\n\\log(\\mu) = \\mathbf{x}^T \\beta.\n\\]\n\n42.5.3 Confronto tra Modelli Non Lineari e GLM\n\n\n\n\n\n\n\nCaratteristica\nModelli Non Lineari\nGLM\n\n\n\nFunzione di Relazione\nNon lineare nei parametri\nLineare dopo trasformazione (funzione di link)\n\n\nDistribuzione degli Errori\nSolitamente normale\nFamiglia esponenziale\n\n\nStima\nMetodi iterativi (ad es., NLSS)\nMassima verosimiglianza\n\n\nApplicazioni\nCurve di crescita, leggi fisiche\nDati binari, conteggi, positivi\n\n\n\nIn sintesi, i modelli non lineari permettono di catturare relazioni complesse tra le variabili, mentre i GLM forniscono una struttura flessibile per gestire distribuzioni non gaussiane delle variabili risposta. Entrambi i tipi di modelli sono fondamentali per l’analisi statistica moderna.\n\n42.5.4 Modelli Psicologici\nI modelli di regressione descritti in precedenza rappresentano uno strumento essenziale per l’analisi statistica, in quanto permettono di identificare e quantificare le relazioni tra variabili. Tuttavia, questi modelli hanno un carattere prevalentemente descrittivo: si limitano a evidenziare associazioni tra i dati senza fornire spiegazioni sui meccanismi causali o sui processi psicologici che le generano. Per comprendere appieno i fenomeni psicologici, è necessario andare oltre l’analisi delle associazioni statistiche e adottare modelli che descrivano i processi cognitivi e comportamentali sottostanti.\nIn questo contesto, i modelli computazionali sviluppati nell’ambito della psichiatria computazionale e della psicologia cognitiva assumono un ruolo centrale (Hitchcock et al., 2022). A differenza dei modelli statistici tradizionali, i modelli computazionali cercano di simulare i processi mentali e decisionali, offrendo una rappresentazione dinamica e meccanicistica del comportamento umano. Due esempi particolarmente rilevanti sono:\n\nModello di Apprendimento Associativo:\nQuesto modello descrive come gli individui apprendono a associare stimoli e risposte attraverso meccanismi di condizionamento. Basato su principi derivati dalla psicologia comportamentale, il modello spiega come le esperienze passate influenzino le risposte future, modulando la forza delle associazioni tra stimoli e comportamenti. È ampiamente utilizzato per studiare fenomeni come l’apprendimento per tentativi ed errori, il condizionamento classico e operante, e la formazione di abitudini.\nModello Drift-Diffusion:\nQuesto modello rappresenta il processo decisionale come un’accumulazione progressiva di evidenza verso una soglia di decisione. Simula come le informazioni vengono integrate nel tempo, tenendo conto della velocità e dell’accuratezza delle scelte. Il modello è particolarmente utile per studiare situazioni in cui gli individui devono prendere decisioni in condizioni di incertezza, come nei compiti di discriminazione percettiva o nei test di attenzione e memoria.\n\nQuesti modelli computazionali non solo permettono di descrivere il comportamento osservato, ma offrono anche una finestra sui processi cognitivi e neurali che lo guidano. Attraverso la simulazione e la previsione del comportamento, è possibile formulare ipotesi verificabili sui meccanismi interni che regolano l’apprendimento, la decisione e altre funzioni cognitive.\nPer chi desidera approfondire questi temi, è disponibile una risorsa introduttiva sui modelli computazionali in psicologia al seguente sito. Questi strumenti rappresentano un ponte tra la teoria psicologica e l’analisi empirica, contribuendo a una comprensione più profonda e dinamica dei fenomeni mentali e comportamentali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_statistical_models.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/02_statistical_models.html#riflessioni-conclusive",
    "title": "42  Modelli statistici",
    "section": "\n42.6 Riflessioni Conclusive",
    "text": "42.6 Riflessioni Conclusive\nIn questo capitolo abbiamo esaminato i principi di base della modellizzazione statistica, partendo da problemi reali e introducendo strumenti probabilistici per l’analisi dei dati. Abbiamo presentato alcuni dei modelli più semplici, come il campionamento da una singola distribuzione, il campionamento da più distribuzioni e l’analisi di regressione, sia semplice che multipla. Questi approcci rappresentano il fondamento per utilizzare i dati al fine di trarre conclusioni su fenomeni psicologici, applicando metodi matematici e probabilistici in modo rigoroso.\nNel prosieguo del corso, ci concentreremo sui modelli introdotti in questo capitolo, approfondendone sia gli aspetti teorici che quelli pratici. Questo percorso ci consentirà di consolidare una comprensione solida dei principi statistici di base, che potrà essere estesa in futuro per affrontare contesti più articolati. Attraverso esempi applicativi e analisi dettagliate, svilupperemo le competenze necessarie per risolvere problemi concreti legati all’analisi dei dati psicologici, adottando un approccio metodico e strutturato.\nIn particolare, approfondiremo temi come il campionamento da una o più distribuzioni e i modelli di regressione, sia semplice che multipla, che costituiscono la base per tecniche statistiche più avanzate. Lo studio di questi argomenti ci fornirà gli strumenti per interpretare i dati, formulare ipotesi e trarre conclusioni, contribuendo così a una migliore comprensione dei fenomeni psicologici oggetto di indagine.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_statistical_models.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/02_statistical_models.html#informazioni-sullambiente-di-sviluppo",
    "title": "42  Modelli statistici",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_statistical_models.html#bibliografia",
    "href": "chapters/bayesian_inference/02_statistical_models.html#bibliografia",
    "title": "42  Modelli statistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.\n\n\nHitchcock, P. F., Fried, E. I., & Frank, M. J. (2022). Computational psychiatry needs time and context. Annual review of psychology, 73(1), 243–270.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_bayesian_inference.html",
    "href": "chapters/bayesian_inference/03_bayesian_inference.html",
    "title": "43  Inferenza bayesiana",
    "section": "",
    "text": "43.1 Introduzione\nRiprendiamo il quadro concettuale della modellizzazione e analisi statistica presentato nella Figura 42.1. L’inferenza statistica si concentra sulla parte centrale di questo schema, ovvero sul processo di trarre conclusioni sul modello a partire dai dati osservati. I due principali approcci all’inferenza statistica sono:\nNell’approccio bayesiano, l’inferenza statistica si basa sull’integrazione di informazioni a priori riguardo al vettore dei parametri \\(\\mathbf{\\theta}\\), spesso rappresentate da una densità di probabilità \\(f(\\mathbf{\\theta})\\), nota come distribuzione a priori. Questo permette di trattare \\(\\mathbf{\\theta}\\) come un vettore aleatorio ai fini computazionali. L’inferenza su \\(\\mathbf{\\theta}\\) viene condotta analizzando la densità di probabilità condizionata \\(f(\\mathbf{\\theta} \\mid \\mathbf{x})\\), nota come distribuzione a posteriori.\nIl teorema di Bayes fornisce il fondamento matematico per questa inferenza:\n\\[\nf(\\mathbf{\\theta} \\mid \\mathbf{x}) = \\frac{f(\\mathbf{x} \\mid \\mathbf{\\theta}) f(\\mathbf{\\theta})}{f(\\mathbf{x})},\n\\]\ndove:\nQuesto approccio fornisce un quadro rigoroso per aggiornare le nostre credenze alla luce di nuove evidenze, un aspetto fondamentale sia nel ragionamento scientifico che nelle decisioni quotidiane.\nNel resto di questo capitolo, esploreremo in dettaglio i principali elementi dell’approccio bayesiano all’inferenza statistica, partendo da un semplice esempio introduttivo. Approfondiremo il processo di aggiornamento bayesiano, un meccanismo formale che consente di combinare nuove osservazioni con conoscenze pregresse in modo coerente e sistematico.\nPer contrasto, nella statistica frequentista, il vettore dei dati \\(\\mathbf{x}\\) è interpretato come il risultato di un vettore aleatorio \\(\\mathbf{X}\\), descritto da un modello probabilistico. Solitamente, il modello è definito fino a un parametro (multidimensionale) \\(\\mathbf{\\theta}\\), espresso come \\(\\mathbf{X} \\sim f(\\cdot; \\mathbf{\\theta})\\). L’inferenza statistica si focalizza quindi sul modello stesso e, in particolare, sul parametro \\(\\mathbf{\\theta}\\). Ad esempio, sulla base dei dati, si potrebbe voler:\nUna differenza chiave tra i due approcci risiede proprio nell’uso di informazioni a priori: mentre la statistica bayesiana le incorpora esplicitamente attraverso la distribuzione a priori \\(f(\\mathbf{\\theta})\\), la statistica frequentista si basa esclusivamente sui dati osservati \\(\\mathbf{x}\\).\nL’inferenza frequentista sarà esaminata in una sezione successiva della dispensa, mentre questo capitolo si concentrerà sull’approccio bayesiano, evidenziandone la potenza e la flessibilità nel contesto della modellizzazione statistica. In particolare, vedremo come l’approccio bayesiano consenta di integrare informazioni diverse (ad esempio, dati storici o esperti) in modo naturale, fornendo risultati interpretabili sotto forma di distribuzioni di probabilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_bayesian_inference.html#introduzione",
    "href": "chapters/bayesian_inference/03_bayesian_inference.html#introduzione",
    "title": "43  Inferenza bayesiana",
    "section": "",
    "text": "statistica bayesiana;\n\nstatistica frequentista.\n\n\n\n\n\n\n\n\\(f(\\mathbf{x} \\mid \\mathbf{\\theta})\\) è la funzione di verosimiglianza, che descrive la probabilità (o densità) dei dati \\(\\mathbf{x}\\) dato il parametro \\(\\mathbf{\\theta}\\);\n\n\n\\(f(\\mathbf{\\theta})\\) è la distribuzione a priori, che codifica le nostre conoscenze o credenze iniziali su \\(\\mathbf{\\theta}\\);\n\n\n\\(f(\\mathbf{x})\\) è la marginal likelihood (o evidenza), che agisce come una costante di normalizzazione e dipende solo dai dati osservati \\(\\mathbf{x}\\).\n\n\n\n\n\n\nstimare il parametro, ad esempio calcolando un estimatore \\(\\hat{\\mathbf{\\theta}}\\);\n\n\neseguire test statistici sul parametro, valutando ipotesi specifiche riguardo a \\(\\mathbf{\\theta}\\).\n\n\n\n\n\n\n\n\n\nCaratteristica\nStatistica Bayesiana\nStatistica Frequentista\n\n\n\nInterpretazione del parametro\n\n\\(\\mathbf{\\theta}\\) è un vettore aleatorio\n\n\\(\\mathbf{\\theta}\\) è una quantità fissa\n\n\nUso delle informazioni a priori\n\nIncorporate esplicitamente\nNon utilizzate\n\n\nObiettivo principale\nAggiornare la distribuzione a posteriori\n\nStima e test sul parametro\n\n\nInferenza\nProbabilistica\nBasata sulla frequenza degli eventi\n\n\n\n\n\n43.1.1 L’Inferenza Bayesiana\nNella scienza, così come nella vita quotidiana, spesso ci troviamo a valutare ipotesi con diversi gradi di credibilità. Ad esempio, consideriamo la domanda su quale nazione vincerà il Campionato Mondiale di Calcio del 2026. Potremmo ritenere la Grecia un candidato molto improbabile, l’Inghilterra non del tutto implausibile, e l’Italia, la Francia o la Germania come favoriti. Questo esempio illustra che lo stato epistemico di un’ipotesi non è una questione di “vero o falso”, ma piuttosto di gradazione. È qui che entra in gioco l’approccio bayesiano: i bayesiani utilizzano il concetto di grado di credenza per descrivere gli atteggiamenti epistemici riguardo a proposizioni incerte, e rappresentano questi gradi di credenza attraverso una struttura matematica specifica: le funzioni di probabilità. Questi due presupposti modellistici sono gli elementi centrali dell’inferenza bayesiana. In sintesi, i bayesiani interpretano le probabilità come espressioni di incertezza soggettiva, un’interpretazione che risale a Thomas Bayes (1701–1761).\nLa funzione di probabilità non solo assegna gradi di credenza a singole proposizioni, ma anche a combinazioni logiche di proposizioni (ad esempio, congiunzioni, disgiunzioni e negazioni). Tuttavia, per semplicità, concentriamoci su una singola proposizione. Consideriamo un esempio tratto dalla psicologia cognitiva, in cui una teoria afferma che “l’esposizione a stimoli positivi migliora l’umore”. Questa proposizione può essere rappresentata come:\n\n\n\\(A\\): “L’esposizione a stimoli positivi migliora l’umore.”\n\nAttraverso l’inferenza bayesiana, possiamo assegnare un grado di credenza iniziale (a priori) a questa proposizione, basandoci su conoscenze pregresse o evidenze preliminari. Ad esempio, potremmo iniziare con una probabilità iniziale:\n\n\n\\(p(A) = 0.7\\): crediamo che l’esposizione a stimoli positivi migliori l’umore con una probabilità del 70%.\n\nSupponiamo ora di condurre un esperimento in cui i partecipanti esposti a stimoli positivi mostrano un significativo miglioramento dell’umore. Alla luce di questi nuovi dati, possiamo aggiornare la nostra credenza utilizzando il teorema di Bayes. Se i dati supportano fortemente la proposizione \\(A\\), la probabilità a posteriori \\(p(A \\mid \\text{dati})\\) potrebbe aumentare, ad esempio, a 0.9.\nQuesto processo di aggiornamento bayesiano ci permette di affinare le nostre credenze in modo dinamico, integrando nuove evidenze empiriche con le conoscenze pregresse. In questo modo, l’inferenza bayesiana non solo quantifica l’incertezza, ma fornisce anche un quadro chiaro e sistematico per valutare la validità di singole proposizioni all’interno di una teoria scientifica, sia in psicologia che in altre discipline.\n\n43.1.2 Argomenti a Favore della Probabilità come Misura di Credenza\nL’interpretazione della probabilità come misura quantitativa dei gradi di credenza soggettivi è sostenuta da tre principali linee di argomentazione, ciascuna delle quali fornisce una giustificazione teorica e pratica per l’adozione delle regole probabilistiche nella modellazione delle credenze. Tali argomenti provengono dai domini delle decisioni, della coerenza e dell’epistemologia.\n\n43.1.2.1 Argomenti della Scommessa Olandese (Dutch Book)\nGli argomenti della scommessa olandese costituiscono una dimostrazione formale del fatto che gradi di credenza non probabilistici portano a incoerenze logiche e vulnerabilità economiche. Se un individuo assegna gradi di credenza che violano gli assiomi della probabilità (ad esempio, la regola della somma per eventi mutuamente esclusivi), è possibile costruire un insieme di scommesse (un “Dutch Book”) che garantisce una perdita certa, indipendentemente dall’esito degli eventi (Ramsey, 1926; De Finetti, 1972).\nFormalmente, se \\(p(A)\\) rappresenta il grado di credenza di un evento \\(A\\) e non rispetta le leggi della probabilità (ad esempio, \\(p(A \\cup B) \\neq p(A) + p(B)\\) per eventi mutuamente esclusivi \\(A\\) e \\(B\\)), esiste una combinazione di scommesse che sfrutta questa incoerenza per generare una perdita sicura. La coerenza probabilistica protegge da tali situazioni di perdita certa, che sono considerate irrazionali.\n\n43.1.2.2 Argomenti Decisionistici\nGli argomenti basati sulla teoria della decisione razionale dimostrano che l’adozione di gradi di credenza probabilistici è una condizione necessaria per massimizzare l’utilità attesa, un principio cardine delle scelte razionali (Savage, 1954; von Neumann & Morgenstern, 1947). Secondo questa teoria, un agente razionale assegna probabilità agli eventi per rappresentare il proprio grado di fiducia e combina tali probabilità con una funzione di utilità che riflette le proprie preferenze, al fine di scegliere l’alternativa che offre il massimo beneficio atteso.\nQuando i gradi di credenza non rispettano le regole della probabilità, l’agente non è in grado di calcolare correttamente l’utilità attesa. Ciò può portare a incoerenze decisionali, come preferenze cicliche o scelte subottimali che contraddicono gli obiettivi dell’agente. Ad esempio,\n\nuna violazione della regola della somma (ad esempio, \\(p(A \\cup B) \\neq p(A) + p(B)\\) per eventi mutuamente esclusivi) può comportare l’assegnazione di risorse in modo inefficiente tra opzioni alternative;\nuna violazione della regola del prodotto (ad esempio, \\(p(A \\cap B) \\neq p(A) \\cdot p(B)\\) per eventi indipendenti) può indurre l’agente a sottostimare o sovrastimare i rischi associati a decisioni complesse.\n\nQueste incoerenze non solo compromettono la razionalità formale dell’agente, ma lo espongono a decisioni che possono portano a esiti non ottimali.\nIn sintesi, la coerenza probabilistica non è un semplice requisito tecnico, ma un presupposto indispensabile affinché un agente possa agire in modo razionale e allineare le proprie decisioni agli obiettivi di massimizzazione dell’utilità attesa.\n\n43.1.2.3 Argomenti Epistemici\nGli argomenti epistemici si concentrano sulla relazione tra i gradi di credenza e la verità, sostenendo che le credenze probabilistiche rappresentano il modo più razionale per minimizzare l’inaccuratezza epistemica rispetto alla realtà (Cox, 1946). L’inaccuratezza epistemica può essere definita come una misura della discrepanza tra il grado di credenza assegnato a una proposizione e il suo valore di verità oggettivo (ad esempio, 1 se la proposizione è vera, 0 se è falsa). In altre parole, l’inaccuratezza epistemica quantifica quanto una credenza si discosta dalla realtà.\nLa minimizzazione dell’inaccuratezza epistemica richiede l’adozione di credenze probabilistiche che rispettino i principi fondamentali della teoria della probabilità. Studi condotti da autori come Joyce (1998, 2009) e Pettigrew (2016) dimostrano che le funzioni di probabilità sono l’unica struttura matematica in grado di minimizzare l’inaccuratezza media rispetto a un’ampia gamma di possibili stati del mondo. In altre parole, le credenze probabilistiche non solo sono coerenti, ma sono anche ottimali nel ridurre l’errore epistemico.\nIn sintesi, anche se ciascun argomento, preso singolarmente, non è sufficiente a giustificare in modo definitivo l’approccio probabilistico, insieme formano un quadro robusto a favore dell’utilizzo della probabilità come misura di credenza razionale. Questi principi costituiscono il fondamento dell’inferenza bayesiana, che rappresenta un approccio potente per modellare il ragionamento e il processo decisionale scientifico.\n\n43.1.3 Il Paradigma dell’Inferenza Bayesiana\nL’inferenza bayesiana si basa sull’idea che la probabilità misuri il grado di certezza soggettiva riguardo a un’ipotesi o alla plausibilità di un valore per un parametro sconosciuto. Il cuore di questo approccio è l’aggiornamento continuo: le credenze iniziali (priori) vengono riviste alla luce di nuove informazioni provenienti dai dati, producendo credenze aggiornate (posteriori).\nPer comprendere meglio questo processo, è necessario introdurre due concetti chiave: il modello generativo dei dati e il parametro.\n\n43.1.3.1 Modello Generativo dei Dati\nUn modello generativo dei dati è una rappresentazione matematica che descrive come i dati osservati potrebbero essere generati da un processo sottostante. In altre parole, è un’astrazione che specifica le relazioni tra le variabili osservabili (i dati) e le variabili non osservabili (i parametri). Il modello generativo ci permette di simulare dati ipotetici e di fare previsioni su ciò che potremmo osservare in base a determinate ipotesi.\nAd esempio, nel contesto del lancio di una moneta, il modello generativo potrebbe essere basato sulla distribuzione binomiale, che descrive la probabilità di ottenere un certo numero di “teste” in un dato numero di lanci, assumendo una certa probabilità di successo (in questo caso, la probabilità di ottenere “testa”).\n\n43.1.3.2 Parametro\nUn parametro è una quantità sconosciuta che caratterizza il modello generativo. Nel caso del lancio della moneta, il parametro di interesse è la probabilità \\(\\theta\\) di ottenere “testa”. Questo parametro è ciò che vogliamo stimare o inferire attraverso l’osservazione dei dati. In generale, i parametri possono rappresentare diverse caratteristiche del processo generativo, come medie, varianze, coefficienti di regressione, ecc.\n\n43.1.3.3 Applicazione all’Esempio del Lancio della Moneta\nOra che abbiamo introdotto i concetti di modello generativo dei dati e parametro, possiamo applicarli all’esempio del lancio della moneta. Immaginiamo di lanciare una moneta 10 volte e osservare 8 teste (\\(y = 8\\)). Vogliamo stabilire se la moneta sia equilibrata (\\(\\theta = 0.5\\)) o meno.\nPer rispondere a questa domanda, definiamo un modello generativo dei dati utilizzando la distribuzione binomiale, che è caratterizzata dal parametro \\(\\theta\\), la probabilità di ottenere “testa”. La distribuzione binomiale descrive la probabilità di osservare un certo numero di successi (in questo caso, “teste”) in un numero fisso di prove indipendenti, assumendo un valore specifico per \\(\\theta\\).\nIn questo contesto, il parametro \\(\\theta\\) è l’oggetto della nostra inferenza. Vogliamo aggiornare la nostra credenza iniziale su \\(\\theta\\) (ad esempio, che la moneta sia equilibrata, quindi \\(\\theta = 0.5\\)) alla luce dei nuovi dati osservati (8 teste su 10 lanci). Questo aggiornamento avviene attraverso l’applicazione del teorema di Bayes, che combina la nostra credenza a priori, descritta da una distribuzione a priori e indicata come \\(p(\\theta)\\), con la verosimiglianza dei dati osservati per produrre una credenza a posteriori su \\(\\theta\\), descritta dalla distribuzione a posteriori e denotata come \\(p(\\theta \\mid \\text{dati})\\).\nLa distribuzione a priori, \\(p(\\theta)\\), riflette ciò che riteniamo plausibile prima di osservare i dati. Quando raccogliamo nuove informazioni, rivediamo le nostre credenze, ridistribuendo la credibilità su tutto il range di valori possibili del parametro. Questo processo di aggiornamento produce la distribuzione a posteriori, \\(p(\\theta \\mid \\text{dati})\\), che rappresenta la nostra credenza aggiornata (Gelman et al., 1995).\nUn aspetto filosofico e matematico distintivo dell’approccio bayesiano è la concezione del parametro d’interesse come una variabile casuale che può assumere valori differenti, anziché come un valore fisso (come avviene nel paradigma frequentista). Questa prospettiva permette di trattare il parametro come una distribuzione, fornendo una rappresentazione più flessibile delle incertezze (Kruschke, 2014). Ad esempio, se tracciassimo la distribuzione a posteriori, l’asse \\(x\\) rappresenterebbe l’intero intervallo di valori possibili per il parametro, mentre l’asse \\(y\\) indicherebbe la densità di probabilità associata a ciascun valore. Il valore “utilizzabile” più credibile è spesso quello che massimizza la distribuzione (moda), o la sua media o mediana.\n\n43.1.4 Approccio Classico: Massima Verosimiglianza\nNel contesto classico, uno dei metodi più utilizzati per stimare \\(\\theta\\) è la massima verosimiglianza, che stima \\(\\theta\\) come il rapporto tra successi e tentativi: \\(\\hat{\\theta} = y/N = 0.8\\). Sebbene semplice, questa stima puntuale non fornisce informazioni sull’incertezza di \\(\\theta\\) né sulla plausibilità di valori alternativi. In altre parole, non ci dice quanto sia plausibile che \\(\\theta\\) sia, ad esempio, 0.7 o 0.9, né quantifica l’incertezza associata alla stima.\n\n43.1.5 Approccio Bayesiano: Priori e Posteriori\nL’approccio bayesiano supera i limiti dell’approccio classico basato sulla massima verosimiglianza, offrendo un quadro più completo e flessibile per l’aggiornamento delle credenze. Questo risultato è reso possibile dal teorema di Bayes, che formalizza il processo di integrazione tra le informazioni iniziali (rappresentate dalla distribuzione a priori) e le nuove evidenze fornite dai dati osservati. Attraverso questo meccanismo, l’approccio bayesiano non solo fornisce stime puntuali, ma quantifica anche l’incertezza associata ai parametri, permettendo una valutazione più robusta e informata delle ipotesi. L’equazione fondamentale è:\n\\[\np(\\theta \\mid \\text{dati}) = \\frac{p(\\theta) \\cdot p(\\text{dati} \\mid \\theta)}{p(\\text{dati})},\n\\]\ndove:\n\n\n\\(p(\\theta)\\) è la distribuzione a priori, che rappresenta ciò che sappiamo del parametro prima di osservare i dati.\n\n\\(p(\\text{dati} \\mid \\theta)\\) è la verosimiglianza, che descrive la probabilità di osservare i dati dati i valori ipotizzati del parametro.\n\n\\(p(\\text{dati})\\) è la probabilità marginale dei dati, che funge da costante di normalizzazione per garantire che la distribuzione a posteriori sia una distribuzione di probabilità valida.\n\nLa distribuzione a posteriori \\(p(\\theta \\mid \\text{dati})\\) riflette la combinazione delle credenze iniziali con le informazioni derivanti dai dati osservati.\nEsempio: Moneta con \\(y = 8\\) e \\(N = 10\\). Supponiamo di adottare una distribuzione a priori uniforme su \\([0, 1]\\), che attribuisce la stessa plausibilità a tutti i valori di \\(p\\). Osservando \\(y = 8\\) teste su \\(N = 10\\) lanci, la verosimiglianza \\(p(y \\mid \\theta)\\) sarà determinata dal modello binomiale:\n\\[\np(y \\mid \\theta) = \\binom{N}{y} p^y (1-p)^{N-y}.\n\\]\nCombinando prior e verosimiglianza attraverso il teorema di Bayes otteniamo:\n\\[\np(\\theta \\mid y) \\propto p(y \\mid \\theta) \\cdot p(\\theta).\n\\]\nLa distribuzione a posteriori risultante ci consente di:\n\n\nCalcolare stime plausibili di \\(\\theta\\), come la mediana o la moda.\n\nQuantificare l’incertezza su \\(\\theta\\), ad esempio tramite varianza o intervalli di credibilità.\n\nQuesto processo fornisce un quadro completo che integra informazioni iniziali e nuove evidenze, superando i limiti delle stime puntuali della massima verosimiglianza. Ad esempio, se la distribuzione a posteriori è concentrata attorno a \\(\\theta = 0.8\\), possiamo concludere che è plausibile che la moneta sia sbilanciata a favore di “testa”. Tuttavia, l’intervallo di credibilità (ad esempio, \\([0.6, 0.95]\\)) ci fornisce anche una misura dell’incertezza associata a questa stima.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_bayesian_inference.html#unintroduzione-ai-priori",
    "href": "chapters/bayesian_inference/03_bayesian_inference.html#unintroduzione-ai-priori",
    "title": "43  Inferenza bayesiana",
    "section": "\n43.2 Un’introduzione ai Priori",
    "text": "43.2 Un’introduzione ai Priori\nCiò che distingue l’approccio bayesiano da quello basato sulla massima verosimiglianza è l’uso esplicito di credenze iniziali riguardo al fenomeno di interesse. Nel linguaggio bayesiano, queste credenze sono formalizzate come distribuzioni di probabilità, chiamate distribuzioni a priori. Le distribuzioni a priori rappresentano la nostra conoscenza o le nostre ipotesi su un parametro o un’ipotesi prima di osservare i dati. Esse forniscono un punto di partenza per l’inferenza, permettendo di incorporare informazioni pregresse nel processo di analisi.\nA seconda del grado di conoscenza o incertezza che abbiamo prima di raccogliere i dati, le distribuzioni a priori possono assumere forme diverse. Questa variabilità riflette il livello di fiducia o informazione iniziale e influenza in modo significativo il modo in cui le nuove evidenze vengono integrate nel processo di aggiornamento bayesiano. La scelta della distribuzione a priori è quindi un aspetto cruciale, poiché determina come le credenze iniziali interagiscono con i dati osservati per produrre la distribuzione a posteriori, ovvero la nostra credenza aggiornata.\n\n43.2.1 Priori Non Informativi\nCome suggerisce il nome, i priori non informativi (Flat Priors) sono generalmente privi di informazioni specifiche. Esistono diverse tipologie di distribuzioni a priori non informative, ma la loro distinzione dettagliata esula dallo scopo di questa trattazione. Sono spesso definiti flat priors perché la loro funzione di densità di probabilità appare come una linea orizzontale quando rappresentata graficamente. Questa distribuzione, classificata come uniforme, assegna la stessa probabilità a tutti i possibili valori del parametro, riflettendo così un’ignoranza totale riguardo al parametro (Gelman et al., 1995).\nIn generale, l’uso di priori non informativi è sconsigliato, a meno che non si abbia effettivamente nessuna conoscenza preliminare o convinzione riguardo ai valori probabili del parametro (Johnson et al., 2022; McElreath, 2020). Infatti, in alcuni casi, l’uso di un prior non informativo porta a una distribuzione a posteriori identica alla funzione di verosimiglianza, con stime dei parametri indistinguibili da quelle ottenute con l’approccio frequentista della massima verosimiglianza. Di conseguenza, l’adozione di un’inferenza bayesiana in tali contesti potrebbe essere non giustificata, poiché il concetto di priors è centrale nella statistica bayesiana.\n\n43.2.2 Priori Debolmente Informativi\nSpesso non abbiamo una conoscenza precisa del parametro d’interesse, ma solo un’idea generale o vincoli noti (ad esempio, l’associazione positiva tra ore di studio e punteggio in un test di matematica). In tali situazioni, possiamo utilizzare priori debolmente informativi (anche detti vaguely informative o default priors). Questi prior incorporano informazioni generali o vincoli sul parametro senza influenzare in modo eccessivo i risultati della posteriori.\nI priori debolmente informativi (Default Priors) rappresentano un compromesso tra l’integrazione di conoscenze pregresse e l’evitare bias significativi, permettendo ai dati di “dominare” i risultati (Gelman et al., 2021). Sono particolarmente utili quando le informazioni preliminari sono limitate o quando si desidera ridurre al minimo l’impatto di credenze iniziali forti.\n\n43.2.3 Priori Informativi\nDiversamente dai priori debolmente informativi o non informativi, i priori informativi trasmettono informazioni deliberate e specifiche sul parametro d’interesse. Questi priori si basano su conoscenze consolidate, risultati di studi precedenti o opinioni di esperti (Falconer et al., 2022) e hanno un’influenza maggiore sulla distribuzione a posteriori rispetto ai priori default o flat.\nI priori informativi sono particolarmente utili in presenza di campioni ridotti, poiché restringono lo spazio credibile del parametro e consentono intervalli di incertezza più stretti (Kruschke, 2014). Tuttavia, richiedono una definizione accurata, basata su evidenze solide.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_bayesian_inference.html#costante-di-normalizzazione-e-priori-coniugati",
    "href": "chapters/bayesian_inference/03_bayesian_inference.html#costante-di-normalizzazione-e-priori-coniugati",
    "title": "43  Inferenza bayesiana",
    "section": "\n43.3 Costante di Normalizzazione e Priori Coniugati",
    "text": "43.3 Costante di Normalizzazione e Priori Coniugati\nNell’equazione del teorema di Bayes:\n\\[\np(\\theta \\mid \\text{dati}) = \\frac{p(\\theta) \\cdot p(\\text{dati} \\mid \\theta)}{p(\\text{dati})},\n\\]\nla costante di normalizzazione, indicata come \\(p(\\text{dati})\\), rappresenta la probabilità complessiva di osservare i dati, indipendentemente dal valore specifico del parametro \\(\\theta\\). Questo termine garantisce che la distribuzione a posteriori sia una distribuzione di probabilità valida, cioè che la somma (o l’integrale) delle probabilità sia uguale a 1. In altre parole, la costante di normalizzazione “aggiusta” la distribuzione risultante affinché sia coerente con le regole della probabilità.\nCalcolare \\(p(\\text{dati})\\) può essere complesso, poiché richiede di considerare tutte le possibili combinazioni di dati e valori del parametro. Tuttavia, in molti casi pratici, non è necessario calcolarla esplicitamente, poiché la forma della distribuzione a posteriori può essere dedotta direttamente dal prodotto tra la distribuzione a priori e la verosimiglianza, a meno di una costante.\n\n43.3.1 Priori Coniugati\nI priori coniugati sono una scelta specifica di distribuzione a priori che, quando combinata con una determinata verosimiglianza, produce una distribuzione a posteriori della stessa famiglia. Questa proprietà semplifica notevolmente i calcoli, rendendo l’aggiornamento bayesiano più efficiente dal punto di vista computazionale.\nEsempio: Se la verosimiglianza è binomiale e la distribuzione a priori è una Beta, la distribuzione a posteriori sarà ancora una Beta. Questo caso è particolarmente utile, ad esempio, quando si studia la probabilità di successo in una serie di prove (come il lancio di una moneta).\nVantaggi dei Priori Coniugati:\n\n\nCalcolo diretto: La distribuzione a posteriori può essere determinata analiticamente senza metodi numerici complessi.\n\nEfficienza computazionale: Ideale per modelli semplici e ben definiti.\n\nLimitazioni:\n\nApplicabile solo a modelli specifici e semplici.\nNon adatto a situazioni con dati complessi o modelli ad alta dimensionalità.\n\n43.3.2 Metodi Approssimativi\nQuando i priori coniugati non sono applicabili o il modello è troppo complesso per soluzioni analitiche, si ricorre a metodi numerici approssimativi. Uno dei più utilizzati è il Markov-Chain Monte Carlo (MCMC), una tecnica di campionamento casuale che permette di stimare la distribuzione a posteriori anche in casi complessi.\nVantaggi dei Metodi Approssimativi:\n\n\nFlessibilità: Possono gestire modelli complessi e dati reali con molte variabili.\n\nPrecisione: Forniscono stime accurate della distribuzione a posteriori, anche in assenza di soluzioni analitiche.\n\nSvantaggi:\n\n\nCosto computazionale: Richiedono più tempo e risorse rispetto ai metodi analitici.\n\nComplessità implementativa: Possono richiedere una maggiore attenzione nella scelta dei parametri e nella validazione dei risultati.\n\nIn sintesi, la scelta tra approccio analitico e numerico dipende dalla complessità del problema e dalle risorse disponibili. Mentre i priori coniugati e i metodi analitici sono ideali per modelli semplici, i metodi numerici come l’MCMC offrono la flessibilità necessaria per affrontare problemi più complessi. In ogni caso, l’obiettivo è sempre lo stesso: aggiornare le nostre credenze in modo rigoroso e sistematico, integrando nuove evidenze con le conoscenze pregresse.\n\n43.3.3 Approfondimenti sull’MCMC e Altri Metodi Numerici\nQuando i modelli diventano troppo complessi per essere risolti analiticamente, l’approccio bayesiano si affida a metodi numerici per approssimare la distribuzione a posteriori. Uno dei metodi più potenti e diffusi è il Markov-Chain Monte Carlo (MCMC), che permette di campionare dalla distribuzione a posteriori anche in assenza di soluzioni esatte. Questo metodo è particolarmente utile quando i priori coniugati non sono applicabili o quando il modello coinvolge molte variabili e parametri.\n\n43.3.3.1 Cos’è l’MCMC?\nL’MCMC è una famiglia di algoritmi che generano una sequenza di campioni (una “catena”) dalla distribuzione a posteriori. Ogni campione rappresenta un possibile valore del parametro di interesse, e i campioni successivi dipendono dai precedenti, come i collegamenti di una catena. Con un numero sufficiente di iterazioni, questa catena converge alla distribuzione a posteriori, permettendo di stimarne forma, centro e variabilità.\nCome funziona l’MCMC? - Metropolis-Hastings: Questo algoritmo è adatto a distribuzioni generiche. Richiede la definizione di una “funzione proposta” che suggerisce nuovi valori per il parametro, che vengono poi accettati o rifiutati in base a una regola probabilistica. - Gibbs Sampling: Questo metodo è particolarmente efficace quando le distribuzioni condizionali dei parametri sono note, anche se la distribuzione congiunta è complessa. In pratica, si campiona iterativamente da ciascuna distribuzione condizionale, aggiornando un parametro alla volta.\nPratiche comuni in MCMC: - Warm-up (o burn-in): All’inizio dell’algoritmo, i campioni vengono scartati per permettere alla catena di stabilizzarsi e raggiungere la distribuzione target. Questa fase è cruciale per evitare che i campioni iniziali, spesso non rappresentativi, influenzino i risultati. - Thinning: Per ridurre l’autocorrelazione tra i campioni, si seleziona solo uno ogni n campioni (ad esempio, ogni 5° campione). Questo migliora l’efficienza e l’indipendenza dei campioni utilizzati per l’analisi.\n\n43.3.3.2 Altri Metodi Numerici\nOltre all’MCMC, esistono altri metodi numerici per approssimare la distribuzione a posteriori, ciascuno con i propri vantaggi e svantaggi:\n\n\nVariational Bayes: Questo approccio approssima la distribuzione a posteriori risolvendo un problema di ottimizzazione, minimizzando la divergenza di Kullback-Leibler tra una distribuzione proposta \\(q(z)\\) e la distribuzione reale \\(p(z \\mid x)\\). È più veloce dell’MCMC ma meno preciso, soprattutto per distribuzioni complesse.\n\nApprossimazione di Laplace: Questo metodo semplifica la distribuzione a posteriori approssimandola con una distribuzione normale centrata sul valore MAP (Maximum A Posteriori). È utile per modelli semplici ma meno accurato per distribuzioni non gaussiane.\n\nVantaggi e Svantaggi degli Approcci Numerici: - Vantaggi: - Applicabilità a modelli complessi e ad alta dimensionalità. - Flessibilità nell’incorporare informazioni a priori dettagliate. - Svantaggi: - Richiedono risorse computazionali elevate. - Necessitano di un tuning accurato degli algoritmi (ad esempio, scelte iniziali in MCMC).\n\n43.3.4 Linguaggi di Programmazione Probabilistica (PPL)\nPer semplificare l’implementazione dei metodi numerici, sono stati sviluppati linguaggi di programmazione probabilistica (PPL). Questi strumenti automatizzano il processo di inferenza bayesiana, permettendo ai ricercatori di concentrarsi sulla modellizzazione mentre il PPL gestisce l’inferenza sottostante.\n\n43.3.4.1 PPL più Diffusi\n\n\nStan: Un linguaggio efficiente e flessibile, ampiamente utilizzato in ambito accademico per la sua capacità di gestire modelli complessi.\n\nPyMC: Una libreria user-friendly per Python, ideale per chi preferisce un approccio più accessibile.\n\nTensorFlow Probability: Combina modellizzazione probabilistica e apprendimento automatico, offrendo strumenti avanzati per l’inferenza bayesiana.\n\nI PPL consentono di definire il modello probabilistico in modo intuitivo e delegare l’inferenza agli algoritmi numerici sottostanti, come MCMC o inferenza variazionale. Questo rende l’inferenza bayesiana più accessibile e applicabile a una vasta gamma di problemi, inclusi quelli in psicologia, biologia, economia e scienze sociali.\n\n43.3.5 Notazione nei Modelli Bayesiani\nNella formulazione dei modelli bayesiani, è comune utilizzare una notazione standard per descrivere le relazioni tra dati, parametri e distribuzioni. Ecco un esempio di come viene strutturata un’equazione bayesiana:\n\n\n\\(y\\): Dati osservati.\n\n\\(\\theta\\): Parametri sconosciuti.\n\n\\(x\\): Quantità note (ad esempio, predittori o variabili esplicative).\n\nEsempio di Modello: Supponiamo di voler modellare un insieme di dati \\(y\\) come provenienti da una distribuzione normale con media \\(\\mu\\) e deviazione standard \\(\\sigma\\). Le distribuzioni a priori per \\(\\mu\\) e \\(\\sigma\\) potrebbero essere specificate come segue:\n\\[\n\\begin{aligned}\ny & \\sim \\mathrm{normal}(\\mu, \\sigma), \\\\\n\\mu & \\sim \\mathrm{normal}(0, 10), \\\\\n\\sigma & \\sim \\mathrm{normal}^+(\\sigma \\mid 0, 1),\n\\end{aligned}\n\\]\ndove il simbolo \\(\\sim\\) indica “è distribuito come”. La stessa espressione può essere scritta in termini di probabilità:\n\\[\n\\begin{aligned}\np(y \\mid \\mu, \\sigma) & = \\mathrm{normal}(y \\mid \\mu, \\sigma), \\\\\np(\\mu) & = \\mathrm{normal}(\\mu \\mid 0, 10), \\\\\np(\\sigma) & = \\mathrm{normal}^+(\\sigma \\mid 0, 1).\n\\end{aligned}\n\\]\nQuesta notazione chiarisce come i dati e i parametri siano collegati attraverso distribuzioni di probabilità, fornendo un quadro completo per l’inferenza bayesiana.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_bayesian_inference.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/03_bayesian_inference.html#riflessioni-conclusive",
    "title": "43  Inferenza bayesiana",
    "section": "\n43.4 Riflessioni Conclusive",
    "text": "43.4 Riflessioni Conclusive\nL’inferenza bayesiana è un approccio potente e versatile per aggiornare le nostre credenze alla luce di nuove evidenze. La sua peculiarità risiede nella capacità di rispondere a una domanda fondamentale per la ricerca scientifica: qual è la probabilità dei parametri (o delle ipotesi) dati i dati osservati? Questo concetto, noto come probabilità inversa, è il cuore dell’approccio bayesiano e lo distingue dall’inferenza frequentista, che si concentra invece sulla probabilità dei dati condizionata ai parametri.\nIl teorema di Bayes formalizza questa intuizione, permettendoci di calcolare la distribuzione a posteriori \\(p(\\theta \\mid D)\\), che rappresenta la nostra credenza aggiornata sui parametri \\(\\theta\\) dopo aver osservato i dati \\(D\\):\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) \\cdot p(\\theta)}{p(D)}.\n\\]\nQuesta equazione mostra come, partendo da un modello generativo \\(p(D \\mid \\theta)\\) dei dati osservati e combinando questo con una distribuzione a priori \\(p(\\theta)\\), sia possibile inferire la distribuzione a posteriori \\(p(\\theta \\mid D)\\). Questo processo di aggiornamento consente di integrare in modo rigoroso e sistematico nuove evidenze con conoscenze pregresse.\nUna stima puntuale comunemente utilizzata nell’inferenza bayesiana è il Massimo A Posteriori (MAP), ovvero il valore di \\(\\theta\\) che massimizza la distribuzione a posteriori:\n\\[\n\\theta^* = \\arg \\max_\\theta p(\\theta \\mid D).\n\\]\nNel caso di un prior non informativo (una distribuzione a priori piatta), la stima MAP coincide con la stima di massima verosimiglianza (MLE), che massimizza la probabilità dei dati osservati. Tuttavia, in presenza di informazioni a priori rilevanti e ben specificate, la stima MAP combina i dati osservati con le credenze iniziali, fornendo una stima più robusta e informata.\nLa forza dell’approccio bayesiano risiede nella sua capacità di affrontare diverse sfide:\n\n\nIncertezza delle ipotesi: In contesti come la psicologia, la medicina o le scienze sociali, dove le ipotesi sono spesso incerte, l’inferenza bayesiana permette di valutarne la plausibilità.\n\nDati limitati o rumorosi: Quando i dati sono scarsi o affetti da rumore, l’approccio bayesiano garantisce stime più robuste integrando informazioni a priori.\n\nConfronto tra ipotesi complesse: L’approccio bayesiano consente di confrontare e valutare ipotesi multiple in modo rigoroso.\n\nIl teorema di Bayes offre un quadro formale per quantificare l’incertezza e aggiornare le credenze in modo dinamico. Questo è particolarmente utile in situazioni in cui:\n\nLe informazioni a priori sono cruciali per guidare l’inferenza.\nÈ necessario un compromesso tra conoscenze pregresse e nuove evidenze.\nI problemi analizzati sono complessi e richiedono strumenti avanzati.\n\nPer modelli semplici, i priori coniugati e i metodi analitici possono essere sufficienti. Tuttavia, per problemi più complessi, l’uso di strumenti numerici come l’MCMC (Markov Chain Monte Carlo) e i linguaggi di programmazione probabilistica (PPL) è indispensabile. Questi strumenti consentono di applicare l’approccio bayesiano a scenari realistici, superando le limitazioni computazionali e garantendo maggiore flessibilità.\nIn conclusione, l’inferenza bayesiana non è solo un metodo statistico, ma un paradigma che trasforma il modo di pensare alla scienza e alla conoscenza. Essa permette di formulare domande scientificamente rilevanti, di quantificare l’incertezza e di aggiornare le credenze in modo rigoroso. Attraverso il teorema di Bayes, possiamo passare dalla domanda “qual è la probabilità dei dati dati i parametri?” alla domanda più interessante: “qual è la probabilità dei parametri dati i dati?”\nQuesta inversione di prospettiva, unita agli strumenti computazionali moderni, rende l’approccio bayesiano uno strumento indispensabile per la ricerca scientifica contemporanea. In un’epoca caratterizzata da dati complessi e incertezze diffuse, il paradigma bayesiano si pone come una guida affidabile per comprendere meglio il mondo attraverso l’analisi rigorosa e l’aggiornamento continuo delle nostre credenze.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/03_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "title": "43  Inferenza bayesiana",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_bayesian_inference.html#bibliografia",
    "href": "chapters/bayesian_inference/03_bayesian_inference.html#bibliografia",
    "title": "43  Inferenza bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nFalconer, J. R., Frank, E., Polaschek, D. L., & Joshi, C. (2022). Methods for eliciting informative prior distributions: A critical review. Decision Analysis, 19(3), 189–204.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nKruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html",
    "href": "chapters/bayesian_inference/04_subj_prop.html",
    "title": "44  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "44.1 Introduzione\nL’inferenza bayesiana è un metodo di inferenza statistica che utilizza la probabilità per aggiornare le credenze sui parametri di un modello, sulla base di nuove evidenze o dati osservati. Essa fornisce un quadro concettuale per stimare variabili sconosciute, tenendo conto dell’incertezza. Attraverso un modello che descrive le dipendenze tra variabili aleatorie, la teoria della probabilità può essere impiegata per inferire tutte le quantità sconosciute. In questo approccio, tutte le incertezze, sia nelle osservazioni che nei parametri del modello, sono trattate come distribuzioni di probabilità.\nIn sintesi, l’inferenza bayesiana è il processo di deduzione delle proprietà di una distribuzione di probabilità a partire dai dati, utilizzando il teorema di Bayes. Questo processo incorpora l’idea che la probabilità rappresenti una misura della fiducia su una previsione o un risultato.\nQuesto capitolo ha lo scopo di esplorare in dettaglio il concetto di aggiornamento bayesiano, illustrandolo con un esempio concreto in un contesto semplificato. L’obiettivo è dimostrare come le credenze preesistenti sulla probabilità di un parametro \\(\\theta\\) possano essere aggiornate attraverso l’osservazione di nuovi dati.\nIl primo passo nell’inferenza bayesiana consiste nel rappresentare le credenze iniziali, formulate prima di raccogliere i dati, tramite una distribuzione a priori. La distribuzione a priori riflette le nostre conoscenze o ipotesi preesistenti su \\(\\theta\\) e può variare in base al contesto o alle informazioni pregresse disponibili.\nUna volta ottenuti nuovi dati, il passaggio successivo è l’aggiornamento delle credenze tramite la distribuzione a posteriori. Questo aggiornamento si ottiene moltiplicando la distribuzione a priori per la verosimiglianza dei dati osservati, il che riflette quanto i dati supportino un determinato valore di \\(\\theta\\). Il prodotto di questi due termini fornisce una misura delle credenze aggiornate, che viene successivamente normalizzata per garantire che il risultato sia una distribuzione di probabilità valida (ovvero, che l’area sotto la curva sia pari a 1).\nIl capitolo si concentra sul modello binomiale. Questo modello è utilizzato per stimare una proporzione sconosciuta basata su una serie di dati binari \\(y_1, \\ldots, y_n\\), ciascuno dei quali può assumere valore 0 o 1.\nInizieremo esplorando un esempio in cui la distribuzione a priori di \\(\\theta\\) è discreta, un caso in cui i valori possibili di \\(\\theta\\) sono limitati a un insieme finito di opzioni. Successivamente, discuteremo scenari in cui la distribuzione a priori è continua, ampliando il modello per affrontare casi più complessi e realistici. Questo approccio progressivo consente di acquisire una comprensione graduale dei concetti centrali dell’inferenza bayesiana e del loro utilizzo pratico nel contesto di problemi statistici reali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#introduzione",
    "href": "chapters/bayesian_inference/04_subj_prop.html#introduzione",
    "title": "44  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "L’unica cosa rilevante è l’incertezza – il grado della nostra conoscenza e ignoranza. Il fatto che gli eventi considerati siano in qualche modo determinati, o conosciuti da altre persone, non ha alcuna importanza (Bruno deFinetti).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/bayesian_inference/04_subj_prop.html#verosimiglianza-binomiale",
    "title": "44  Pensare ad una proporzione in termini soggettivi",
    "section": "\n44.2 Verosimiglianza Binomiale",
    "text": "44.2 Verosimiglianza Binomiale\nLa distribuzione binomiale offre un modello naturale per dati che derivano da una sequenza di \\(n\\) prove indipendenti e identicamente distribuite, dove ciascuna prova dà origine a uno dei due possibili esiti, convenzionalmente etichettati come ‘successo’ e ‘fallimento’. Grazie al fatto che le prove sono iid, i dati possono essere riassunti dal numero totale di successi nelle \\(n\\) prove, che denotiamo con \\(y\\). Il parametro \\(\\theta\\) rappresenta la proporzione di successi nella popolazione o, equivalentemente, la probabilità di successo in ciascuna prova. Il modello di campionamento binomiale è:\n\\[\np(y \\mid \\theta) = \\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y},\n\\]\ndove nella parte sinistra dell’equazione non si indica la dipendenza da \\(n\\) perché viene considerato parte del disegno sperimentale e fissato; tutte le probabilità discusse per questo problema sono considerate condizionate su \\(n\\), cioè assumono che il numero totale di prove sia fissato e noto.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "href": "chapters/bayesian_inference/04_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "title": "44  Pensare ad una proporzione in termini soggettivi",
    "section": "\n44.3 Applicazione Specifica del Modello Binomiale",
    "text": "44.3 Applicazione Specifica del Modello Binomiale\nIn questo capitolo, esaminiamo un’applicazione specifica del modello binomiale per valutare la prestazione di un partecipante in un classico esperimento di psicologia, noto come Go/No-Go task (Shiffrin & Schneider, 1977). In questo tipo di compito, ai partecipanti viene richiesto di rispondere a determinati stimoli (prove Go) e di trattenere la risposta ad altri stimoli (prove No-Go). Ad esempio, i partecipanti possono vedere una serie di lettere presentate su uno schermo e devono premere un pulsante quando vedono qualsiasi lettera tranne una specifica lettera bersaglio (ad esempio, la lettera “X”). In questo esperimento, ogni prova rappresenta un evento di tipo bernoulliano con due possibili esiti: o il partecipante risponde correttamente o commette un errore. I ricercatori analizzano la percentuale di risposte corrette e di inibizioni, concentrandosi in particolare sulla capacità del partecipante di controllare l’impulso di rispondere durante le prove No-Go.\nConsideriamo un piccolo numero di prove No-Go di un partecipante, dove i risultati sono: 1, 0, 1, 1, 1, 0, 1, 0, 1. Qui, il valore “1” indica che il partecipante è stato in grado di inibire la risposta, mentre “0” indica che non è riuscito a farlo. L’obiettivo dell’analisi è quantificare l’incertezza nella stima di \\(\\theta\\), che rappresenta la proporzione di risposte corrette nel compito No-Go, ovvero la capacità inibitoria del partecipante.\nConsideriamo questi dati come una sequenza di 9 prove bernoulliane indipendenti. Utilizzando il modello binomiale, stimiamo la probabilità \\(\\theta\\) che il partecipante riesca a controllare il proprio impulso di rispondere durante le prove No-Go e quantifichiamo l’incertezza associata a questa stima.\n\n44.3.1 Flusso di Lavoro Bayesiano\nMcElreath (2020) descrive il flusso di lavoro bayesiano nel modo seguente.\n\n\nDefinizione di un Modello Generativo per i Dati\nUn modello generativo rappresenta il processo attraverso cui i dati vengono prodotti. Per esempio, nel caso di un compito No-Go, ogni prova può essere considerata come un esperimento di tipo Bernoulli, che può produrre due possibili risultati:\n\n\nSuccesso: inibizione della risposta corretta (rappresentata da 1).\n\n\nErrore: mancata inibizione della risposta (rappresentata da 0).\n\nDenotiamo con \\(\\theta\\) la probabilità di inibire correttamente la risposta. Il modello generativo è quindi formalizzato come:\n\\[\nX_i \\sim \\text{Bernoulli}(\\theta),\n\\]\ndove \\(i = 1, 2, \\dots, 9\\) indica le prove eseguite, e \\(X_i\\) rappresenta l’esito di ciascuna prova.\n\n\nDefinizione di uno Stimatore per il Parametro di Interesse\nLo stimatore è uno strumento che ci permette di calcolare una stima del parametro di interesse (in questo caso \\(\\theta\\)) basandoci sui dati raccolti.\n\n\n\\(\\theta\\) rappresenta la probabilità di successo, ovvero di inibire correttamente la risposta.\n\nOltre a stimare \\(\\theta\\), è importante quantificare l’incertezza della stima utilizzando i dati a disposizione.\n\n\n\nSviluppo di un Metodo Statistico per la Stima di \\(\\theta\\)\nUtilizziamo un approccio bayesiano per stimare \\(\\theta\\). Questo approccio combina:\n\n\nUna distribuzione a priori: rappresenta le convinzioni iniziali su \\(\\theta\\). Scegliamo una distribuzione Beta \\(\\text{Beta}(1, 1)\\), che corrisponde a una distribuzione uniforme, per indicare che non abbiamo informazioni iniziali preferenziali.\n\n\nLa verosimiglianza: rappresenta quanto i dati osservati siano compatibili con diversi valori di \\(\\theta\\). Per 6 successi e 3 errori, la verosimiglianza è data da una distribuzione binomiale:\\[\nL(\\theta) = {9 \\choose 6} \\theta^{6} (1-\\theta)^{3}.\n\\]\n\n\nLa distribuzione a posteriori: si ottiene aggiornando la distribuzione a priori con i dati osservati, tramite il teorema di Bayes:\\[\n\\text{Posteriore} \\propto \\text{Verosimiglianza} \\times \\text{Priori}.\n\\]\n\n\n\n\nValidazione del Modello Tramite Simulazioni\nPrima di applicare il modello ai dati reali, verifichiamo che il modello sia realistico attraverso:\n\n\nSimulazioni predittive a priori: servono per controllare se il modello è in grado di generare dati plausibili.\n\n\nSimulazioni predittive a posteriori: valutano se il modello, una volta adattato ai dati osservati, può riprodurre risultati simili a quelli effettivamente ottenuti.\n\n\n\nAnalisi e Sintesi dei Risultati\nUna volta adattato il modello ai dati reali:\n\nUtilizziamo metodi computazionali come il Monte Carlo a catene di Markov (MCMC) per calcolare la distribuzione a posteriori.\n\nRiassumiamo i risultati tramite statistiche descrittive, come media, mediana e intervalli di credibilità, per fare inferenze su \\(\\theta\\).\n\n\n\nIn questo capitolo, mostreremo come calcolare numericamente la distribuzione a posteriori di \\(\\theta\\). Nei capitoli successivi esploreremo in dettaglio ogni fase del flusso di lavoro bayesiano descritto da McElreath (2020).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/04_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "title": "44  Pensare ad una proporzione in termini soggettivi",
    "section": "\n44.4 Metodo Basato su Griglia nell’Aggiornamento Bayesiano",
    "text": "44.4 Metodo Basato su Griglia nell’Aggiornamento Bayesiano\nDopo aver discusso l’aggiornamento bayesiano e come permette di raffinare le nostre convinzioni preesistenti alla luce di nuove evidenze, esploreremo ora una tecnica specifica per realizzare questo aggiornamento: il metodo basato su griglia.\nIl metodo basato su griglia è un approccio semplice e intuitivo per stimare la distribuzione a posteriori, particolarmente utile quando non sono disponibili soluzioni analitiche esatte o si desidera evitare l’uso di algoritmi computazionali complessi. La procedura si articola nei seguenti passi:\n\n\nSelezione di un intervallo per il parametro: Basandosi sulle convinzioni a priori, si definisce un intervallo ragionevole per il parametro di interesse.\n\nCreazione di una griglia di punti: Su questo intervallo, si distribuiscono una serie di punti, di solito equidistanti tra loro.\n\nCalcolo della posteriori per ogni punto: Per ogni punto della griglia, si moltiplica la verosimiglianza per il prior corrispondente.\n\nNormalizzazione dei risultati: Per garantire che la somma delle probabilità sia pari a 1, si normalizzano i valori ottenuti dividendo ciascun punto per l’area totale sottesa dalla curva della distribuzione a posteriori.\n\nAttraverso questo metodo, si ottiene una rappresentazione approssimativa ma illustrativa della distribuzione a posteriori. Questo approccio offre un modo accessibile per visualizzare e comprendere il processo di aggiornamento bayesiano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "href": "chapters/bayesian_inference/04_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "title": "44  Pensare ad una proporzione in termini soggettivi",
    "section": "\n44.5 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta",
    "text": "44.5 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta\n\n44.5.1 Distribuzione a priori\nQuando non disponiamo di informazioni specifiche preliminari su \\(\\theta\\), potremmo inizialmente assegnare un valore di 0.5, suggerendo una probabilità a priori uniforme tra le due alternative (la capacità di inibire la risposta e la mancanza di questa capacità in una prova del compito Go/No-Go). Tuttavia, questo valore non rappresenta adeguatamente l’intero spettro della nostra incertezza iniziale.\nPer riflettere meglio questa incertezza, utilizziamo una distribuzione a priori discreta, che assegna una probabilità distinta a ciascun valore plausibile di \\(\\theta\\). Questo approccio ci permette di quantificare le nostre convinzioni preliminari sulla distribuzione di questi valori.\nSupponiamo di considerare undici possibili valori per \\(\\theta\\), che variano da 0 a 1 con incrementi di 0.1. Possiamo attribuire a ciascun valore una probabilità a priori uguale, creando così una distribuzione uniforme, oppure scegliere una distribuzione non uniforme che meglio rifletta le nostre aspettative sui valori di \\(\\theta\\) più probabili.\nDopo aver osservato i dati — nel nostro caso, 6 successi in 9 prove — applichiamo il teorema di Bayes per trasformare la distribuzione a priori in una distribuzione a posteriori. Questo processo consiste nel combinare la probabilità a priori di \\(\\theta\\) con la verosimiglianza dei dati per produrre una probabilità a posteriori aggiornata per \\(\\theta\\).\n\n44.5.2 Distribuzione a Posteriori\nLa distribuzione a posteriori combina le informazioni a priori con i dati osservati, aggiornando le nostre credenze riguardo al parametro \\(\\theta\\). Vediamo passo passo come implementare il calcolo della distribuzione a posteriori e delle relative quantità in R, partendo dalla rappresentazione discreta di \\(\\theta\\).\n\n44.5.2.1 1. Definizione di \\(\\theta\\)\n\nIniziamo definendo un insieme discreto di valori per \\(\\theta\\).\n\ntheta &lt;- seq(0, 1, by = 0.1)\ntheta\n#&gt;  [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\n44.5.2.2 2. Distribuzione a Priori Uniforme\nSe non abbiamo motivi per preferire alcuni valori di \\(\\theta\\), assegniamo probabilità uguali a tutti i valori, \\(\\theta \\sim \\mathcal{Uniform}(0, 1)\\).\n\nunif_prior_not_norm &lt;- rep(1, length(theta))\nprint(unif_prior_not_norm)\n#&gt;  [1] 1 1 1 1 1 1 1 1 1 1 1\n\nStandardizziamo la distribuzione affinché le probabilità si sommino a 1.\n\nunif_prior &lt;- unif_prior_not_norm / length(theta)\nprint(unif_prior)\n#&gt;  [1] 0.09091 0.09091 0.09091 0.09091 0.09091 0.09091 0.09091 0.09091 0.09091\n#&gt; [10] 0.09091 0.09091\n\nVerifichiamo.\n\nsum(unif_prior) # Verifica che le probabilità sommino a 1\n#&gt; [1] 1\n\nVisualizziamo questa distribuzione a priori uniforme:\n\nggplot(data.frame(theta, unif_prior), aes(x = theta, y = unif_prior)) +\n  geom_segment(aes(xend = theta, yend = 0), linetype = \"solid\", linewidth = 1.2) +\n  labs(\n    title = \"Distribuzione a Priori (Uniforme)\",\n    x = expression(theta),\n    y = \"Probabilità\"\n  )\n\n\n\n\n\n\n\n\n44.5.2.3 3. Distribuzione a Priori Non Uniforme\nSe riteniamo più probabili i valori centrali di \\(\\theta\\), definiamo una distribuzione a priori discreta non uniforme:\n\ntheta &lt;- seq(0, 1, length.out = 11)\n\nnot_unif_prior &lt;-\n  c(0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05)\n\ndata.frame(theta, not_unif_prior) |&gt;\n  ggplot(\n    aes(x = theta, y = not_unif_prior)\n  ) +\n  geom_segment(\n    aes(xend = theta, yend = 0),\n    linetype = \"solid\", linewidth = 1.2\n  ) +\n  labs(\n    title = \"Distribuzione a Priori (Non Uniforme)\",\n    x = expression(theta),\n    y = \"Probabilità\"\n  )\n\n\n\n\n\n\n\n\nsum(not_unif_prior) # Verifica che le probabilità sommino a 1\n#&gt; [1] 1\n\n\n44.5.2.4 4. Calcolo della Verosimiglianza\nLa funzione di verosimiglianza per il modello binomiale, \\(y \\sim \\mathcal{Binomial}(n, \\theta)\\), è definita in R nel modo seguente:\n\nlikelihood &lt;- dbinom(6, size = 9, prob = theta)\n\nNormalizziamo.\n\nlikelihood &lt;- likelihood / sum(likelihood) \n\n\ndata.frame(theta, likelihood) |&gt;\n  ggplot(\n    aes(x = theta, y = likelihood)\n  ) +\n  geom_segment(\n    aes(xend = theta, yend = 0),\n    linetype = \"solid\", linewidth = 1.2\n  ) +\n  labs(\n    title = \"Funzione di Verosimiglianza\",\n    x = expression(theta),\n    y = expression(L(theta))\n  )\n\n\n\n\n\n\n\n\n44.5.2.5 5. Distribuzione a Posteriori\nLa distribuzione a posteriori, \\(Pr(\\theta \\mid y)\\), si calcola moltiplicando elemento per elemento la distribuzione a priori e la verosimiglianza, quindi dividendo per la probabilità marginale dei dati (normalizzazione).\n\npost_not_norm &lt;- (not_unif_prior * likelihood) \nprint(post_not_norm)\n#&gt;  [1] 0.00000000 0.00000306 0.00013754 0.00104951 0.01299717 0.02869228\n#&gt;  [7] 0.04386543 0.04666454 0.00880231 0.00223060 0.00000000\n\nNormalizziamo.\n\npost &lt;- post_not_norm / sum(post_not_norm)\nprint(post)\n#&gt;  [1] 0.00000000 0.00002118 0.00095219 0.00726597 0.08998163 0.19864159\n#&gt;  [7] 0.30368799 0.32306667 0.06093994 0.01544284 0.00000000\n\nVerifica che la distribuzione a posteriori sommi a 1.\n\nsum(post) \n#&gt; [1] 1\n\nVisualizziamo la distribuzione a posteriori.\n\ndata.frame(theta, post) |&gt;\n  ggplot(\n    aes(x = theta, y = post)\n  ) +\n  geom_segment(\n    aes(xend = theta, yend = 0),\n    linetype = \"solid\", linewidth = 1.2\n  ) +\n  labs(\n    title = \"Distribuzione a Posteriori\",\n    x = expression(theta),\n    y = expression(f(theta))\n  )\n\n\n\n\n\n\n\n\n44.5.2.6 6. Quantità a Posteriori\n\n\nMedia a Posteriori: Calcolata come il valore atteso di \\(\\theta\\) sotto la distribuzione a posteriori.\n\n\nposterior_mean &lt;- sum(theta * post)\nposterior_mean\n#&gt; [1] 0.6087\n\n\n\nVarianza a Posteriori: Calcolata come la varianza della distribuzione a posteriori.\n\n\nposterior_variance &lt;- sum((theta^2) * post) - posterior_mean^2\nposterior_variance\n#&gt; [1] 0.01338\n\n\n\nModa a Posteriori: Il valore di \\(\\theta\\) con la probabilità più alta.\n\n\nposterior_mode &lt;- theta[which.max(post)]\nposterior_mode\n#&gt; [1] 0.7\n\nIn sintesi, abbiamo calcolato la distribuzione a posteriori di \\(\\theta\\) utilizzando una distribuzione a priori discreta non uniforme e osservando 6 successi su 9 prove. Abbiamo derivato quantità statistiche come media, varianza e moda a posteriori. Questo processo dimostra come l’inferenza bayesiana aggiorni le credenze a priori in base ai dati osservati, offrendo una visione quantitativamente informata del parametro \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "href": "chapters/bayesian_inference/04_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "title": "44  Pensare ad una proporzione in termini soggettivi",
    "section": "\n44.6 Aggiornamento Bayesiano con una Distribuzione a Priori Continua",
    "text": "44.6 Aggiornamento Bayesiano con una Distribuzione a Priori Continua\nPassiamo ora all’aggiornamento bayesiano utilizzando una distribuzione a priori continua, in particolare la distribuzione Beta. Questo approccio è particolarmente utile poiché consente di rappresentare \\(\\theta\\) come una variabile continua definita nell’intervallo [0, 1].\n\n44.6.1 Definizione della Distribuzione Beta\nIniziamo con una distribuzione Beta simmetrica, Beta(2, 2), e calcoliamo la sua densità di probabilità su un intervallo continuo di valori \\(\\theta\\).\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 2\n\n# Valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000)\n\n# Densità di probabilità della distribuzione Beta\npdf &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione Beta\ndata.frame(theta, pdf) |&gt;\n  ggplot(\n    aes(x = theta, y = pdf)\n  ) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Densità di Probabilità Beta(2, 2)\",\n    x = expression(theta),\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n44.6.2 Distribuzione a Priori Non Simmetrica\nConsideriamo una distribuzione a priori non simmetrica, Beta(2, 5), per rappresentare credenze che privilegiano valori bassi di \\(\\theta\\).\n\n# Parametri della distribuzione Beta non simmetrica\nalpha &lt;- 2\nbeta &lt;- 5\n\n# Valori di theta e densità di probabilità\ntheta &lt;- seq(0, 1, length.out = 100) # Valori di theta\npdf &lt;- dbeta(theta, alpha, beta) # Densità di probabilità Beta(2, 5)\n\n# Creazione del grafico\ndata.frame(theta, pdf) |&gt;\n  ggplot(aes(x = theta, y = pdf)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Densità di Probabilità Beta(2, 5)\",\n    x = expression(theta),\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n44.6.3 Verosimiglianza\nConsideriamo un esperimento con 9 prove e 6 successi, modellato con una distribuzione binomiale. Calcoliamo la funzione di verosimiglianza normalizzata.\n\n# Parametri dell'esperimento\nn &lt;- 9\nk &lt;- 6\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- dbinom(k, size = n, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood) # Normalizzazione\n\n# Grafico della verosimiglianza\ndata.frame(theta, likelihood) |&gt;\n  ggplot(\n    aes(x = theta, y = likelihood)\n  ) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Verosimiglianza\",\n    x = expression(theta),\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n44.6.4 Distribuzione a Posteriori\nLa distribuzione a posteriori si ottiene moltiplicando la distribuzione a priori per la verosimiglianza e normalizzando il risultato.\n\n# Calcolo della distribuzione a priori Beta(2, 5)\nprior &lt;- dbeta(theta, shape1 = 2, shape2 = 5)\nprior &lt;- prior / sum(prior)\n\n# Calcolo della distribuzione a posteriori\nposterior &lt;- (prior * likelihood) / sum(prior * likelihood)\n\n\n# Uniamo tutti i dati in un dataframe per ggplot2\ndat &lt;- tibble(\n  theta,\n  prior,\n  likelihood,\n  posterior\n)\n\n# Preparazione dei dati per il plot\nlong_data &lt;- dat |&gt;\n  pivot_longer(\n    cols = c(prior, likelihood, posterior),\n    names_to = \"distribution\",\n    values_to = \"density\"\n  )\n\n# Grafico\nlong_data |&gt;\n  ggplot(aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Distribuzioni Bayesiane\",\n    x = expression(theta),\n    y = \"Densità\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n44.6.5 Quantità a Posteriori\nCalcoliamo alcune quantità riassuntive dalla distribuzione a posteriori.\n\nMedia a Posteriori\n\n\nposterior_mean &lt;- sum(theta * posterior)\nposterior_mean\n#&gt; [1] 0.5\n\n\nDeviazione Standard a Posteriori\n\n\nposterior_sd &lt;- sqrt(sum((theta^2) * posterior) - posterior_mean^2)\nposterior_sd\n#&gt; [1] 0.1213\n\n\nModa a Posteriori\n\n\nposterior_mode &lt;- theta[which.max(posterior)]\nposterior_mode\n#&gt; [1] 0.4949\n\n\n44.6.6 Campionamento dalla Distribuzione a Posteriori\nPossiamo generare campioni casuali dalla distribuzione a posteriori per effettuare inferenze.\n\n# Campionamento casuale basato sul posterior\nset.seed(123)\nsamples &lt;- sample(theta, size = 10000, prob = posterior, replace = TRUE)\n\n# Creazione dell'istogramma e della curva di densità\ndata_frame_samples &lt;- data.frame(samples)\n\n# Grafico con ggplot\ndata_frame_samples |&gt;\n  ggplot(aes(x = samples)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 20,\n    fill = \"gray\", color = \"black\"\n  ) +\n  geom_density(color = \"black\", size = 1.2) +\n  labs(\n    title = \"Distribuzione dei Campioni dalla Posteriori\",\n    x = expression(theta),\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n44.6.6.1 Intervalli di Credibilità\nCalcoliamo l’intervallo di credibilità al 94%.\n\ncredible_interval &lt;- quantile(samples, probs = c(0.03, 0.97))\ncredible_interval\n#&gt;     3%    97% \n#&gt; 0.2727 0.7273\n\nSe desideriamo calcolare l’intervallo di densità più alta (HPDI), possiamo utilizzare pacchetti aggiuntivi come HDInterval.\n\n# Calcolo HPDI (richiede il pacchetto HDInterval)\nhdi(samples, credMass = 0.94)\n#&gt;  lower  upper \n#&gt; 0.2828 0.7273 \n#&gt; attr(,\"credMass\")\n#&gt; [1] 0.94\n\nIn sintesi, questo approccio dimostra l’applicazione del metodo bayesiano con distribuzioni a priori continue, utilizzando sia formule analitiche che campionamento. I risultati mostrano come possiamo ottenere credenze aggiornate su \\(\\theta\\) e riassumerle con quantità come media, moda e intervalli di credibilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/04_subj_prop.html#metodo-basato-su-griglia",
    "title": "44  Pensare ad una proporzione in termini soggettivi",
    "section": "\n44.7 Metodo basato su griglia",
    "text": "44.7 Metodo basato su griglia\nIl metodo utilizzato in questo capitolo per generare la distribuzione a posteriori è noto come metodo basato su griglia. Questo metodo numerico esatto si basa sul calcolo della distribuzione a posteriori mediante una griglia di punti uniformemente spaziati. Nonostante la maggior parte dei parametri sia continua, l’approssimazione della distribuzione a posteriori può essere ottenuta considerando soltanto una griglia finita di valori dei parametri. Il metodo segue quattro fasi:\n\nFissare una griglia discreta di possibili valori dei parametri.\nValutare la distribuzione a priori e la funzione di verosimiglianza per ciascun valore della griglia.\nCalcolare l’approssimazione della densità a posteriori, ottenuta moltiplicando la distribuzione a priori per la funzione di verosimiglianza per ciascun valore della griglia e normalizzando i prodotti in modo che la loro somma sia uguale a 1.\nSelezionare \\(n\\) valori casuali dalla griglia per ottenere un campione casuale della densità a posteriori normalizzata.\n\nQuesto metodo può essere potenziato aumentando il numero di punti nella griglia, ma il limite principale risiede nel fatto che all’aumentare della dimensionalità dello spazio dei parametri, il numero di punti necessari per una stima accurata cresce in modo esponenziale, rendendo il metodo impraticabile per problemi complessi.\nIn sintesi, l’approccio basato sulla griglia è intuitivo e non richiede competenze di programmazione avanzate per l’implementazione. Inoltre, fornisce un risultato che può essere considerato, per tutti gli scopi pratici, come un campione casuale estratto dalla distribuzione di probabilità a posteriori condizionata ai dati. Tuttavia, questo metodo è limitato a causa della maledizione della dimensionalità1, il che significa che può essere applicato soltanto a modelli statistici semplici con non più di due parametri. Di conseguenza, in pratica, è spesso sostituito da altre tecniche più efficienti, poiché i modelli impiegati in psicologia richiedono frequentemente la stima di centinaia o anche migliaia di parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/04_subj_prop.html#riflessioni-conclusive",
    "title": "44  Pensare ad una proporzione in termini soggettivi",
    "section": "\n44.8 Riflessioni Conclusive",
    "text": "44.8 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato l’aggiornamento bayesiano utilizzando una distribuzione a priori discreta, accennando brevemente al caso delle distribuzioni a priori continue. Quando si affrontano scenari con distribuzioni a priori continue, l’elaborazione della distribuzione a posteriori generalmente richiede la risoluzione di un integrale che, nella maggior parte dei casi, non ammette una soluzione analitica. Tuttavia, ci sono eccezioni notevoli, come nell’inferenza relativa alle proporzioni, dove la distribuzione a priori è modellata come una distribuzione Beta e la funzione di verosimiglianza segue una distribuzione binomiale. In queste circostanze particolari, è possibile derivare analiticamente la distribuzione a posteriori. L’analisi dettagliata di questo caso sarà trattata nel capitolo successivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#esercizi",
    "href": "chapters/bayesian_inference/04_subj_prop.html#esercizi",
    "title": "44  Pensare ad una proporzione in termini soggettivi",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nIn uno studio sull’analisi delle pratiche di trasparenza e riproducibilità nella ricerca in psicologia, Hardwicke et al. (2022) hanno riportato che la condivisione dei materiali di ricerca è stata rilevata nel 14% dei casi (26 su 183 studi), con un intervallo di confidenza al 95% pari a [10%, 19%]. Questo suggerisce che la condivisione di materiali è rara.\nIspirandoti ai risultati di questo studio, costruisci una distribuzione a priori per la probabilità \\(\\theta\\) che uno studio condivida i materiali di ricerca. Per semplicità, discretizza \\(\\theta\\) in 10 livelli equispaziati: \\(0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95\\).\nAttribuisci le seguenti probabilità a priori ai 10 livelli, basandoti sull’informazione che la condivisione dei materiali è un evento raro ma non trascurabile: \\(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02\\).\nSupponiamo che siano stati osservati 20 studi su 100 che hanno condiviso i materiali di ricerca. Calcola la distribuzione a posteriori utilizzando il metodo basato su griglia. Calcola la media della distribuzione a posteriori e l’intervallo di credibilità al 89%.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n# Definizione dei possibili valori di theta (probabilità discreta)\ntheta &lt;- seq(0.05, 0.95, by = 0.10)\n\n# Definizione della distribuzione a priori\nprior &lt;- c(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02)\n\n# Normalizzazione della prior (se necessario, ma in questo caso già normalizzata)\nprior &lt;- prior / sum(prior)\n\n# Dati osservati\nsuccessi &lt;- 20  # studi che hanno condiviso materiali\nn &lt;- 100        # studi totali\n\n# Calcolo della verosimiglianza usando la distribuzione binomiale\nlikelihood &lt;- dbinom(successi, size = n, prob = theta)\n\n# Calcolo della distribuzione a posteriori (applicazione del teorema di Bayes)\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)  # Normalizzazione\n\n# Calcolo della media della distribuzione a posteriori\nposterior_mean &lt;- sum(theta * posterior)\n\n# Calcolo dell'intervallo di credibilità al 89%\ncdf &lt;- cumsum(posterior)  # Distribuzione cumulativa\nlower_bound &lt;- theta[which.min(abs(cdf - 0.055))]  # 5.5% quantile\nupper_bound &lt;- theta[which.min(abs(cdf - 0.945))]  # 94.5% quantile\n\n# Output dei risultati\nlist(\n  posterior_mean = posterior_mean,\n  credibility_interval_89 = c(lower_bound, upper_bound)\n)\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nL’obiettivo di questo esercizio è applicare il metodo basato su griglia per stimare la distribuzione a posteriori di una proporzione, utilizzando dati dalla Scala della Rete Sociale di Lubben (LSNS-6). Si assume che un punteggio LSNS-6 superiore a una soglia prefissata indichi isolamento sociale. Il compito è:\n\nScegliere una soglia per classificare i partecipanti in due gruppi (isolati vs. non isolati), garantendo che la proporzione osservata non sia inferiore a 0.1 o superiore a 0.9.\nCalcolare la distribuzione a posteriori della proporzione usando un’approssimazione discreta su una griglia di valori.\nDeterminare l’intervallo di credibilità all’89%.\nInterpretare i risultati.\n\nConsegna: caricare su Moodle il file .qmd compilato in pdf.\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nDati e Modellizzazione\nSi assume che i dati siano rappresentati da una variabile binaria \\(y\\), con \\(y = 1\\) per individui classificati come isolati e \\(y = 0\\) altrimenti. Supponiamo che su un campione di \\(n\\) individui, \\(s\\) siano isolati.\nDefiniamo il modello statistico:\n\\[ y_i \\sim \\text{Bernoulli}(\\theta) \\]\ncon:\n\n\n\\(y_i \\in \\{0,1\\}\\) per \\(i=1,\\dots,n\\),\n\n\\(\\theta\\) proporzione di individui isolati nella popolazione.\n\nLa distribuzione a priori su \\(\\theta\\) è scelta come \\(\\text{Beta}(2,2)\\), che rappresenta una conoscenza iniziale moderata e non estrema.\nMetodo basato su griglia\nIl metodo a griglia approssima la distribuzione a posteriori calcolando la probabilità per una serie di valori discreti di \\(\\theta\\).\n\n\nDefinire una griglia di valori per \\(\\theta\\):\ntheta &lt;- seq(0, 1, length.out = 100)\n\n\nCalcolare la distribuzione a priori:\nprior &lt;- dbeta(theta, 2, 2)\nprior &lt;- prior / sum(prior)  # Normalizzazione\n\n\nCalcolare la verosimiglianza:\nlikelihood &lt;- dbinom(s, size = n, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood)  # Normalizzazione\n\n\nCalcolare la distribuzione a posteriori:\nposterior &lt;- prior * likelihood\nposterior &lt;- posterior / sum(posterior)  # Normalizzazione\n\n\n** Calcolo dell’intervallo di credibilità all’89%**\nL’intervallo di credibilità è calcolato come l’intervallo che contiene il 89% della probabilità a posteriori.\nci_89 &lt;- quantile(sample(theta, size = 10000, prob = posterior, replace = TRUE), probs = c(0.055, 0.945))\nci_89\nInterpretazione dei risultati\n\n\nValore atteso e moda a posteriori:\nmean_theta &lt;- sum(theta * posterior)\nmode_theta &lt;- theta[which.max(posterior)]\n\nIl valore atteso fornisce una stima puntuale di \\(\\theta\\).\nLa moda indica il valore più probabile della proporzione di isolamento sociale.\n\n\n\nIntervallo di credibilità:\n\nL’89% della probabilità a posteriori cade tra i valori dell’intervallo di credibilità.\nSe l’intervallo è stretto, c’è maggiore certezza sulla proporzione stimata.\nSe l’intervallo è ampio, vi è maggiore incertezza sulla proporzione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/04_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "title": "44  Pensare ad una proporzione in termini soggettivi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HDInterval_0.2.4 thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.10.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#bibliografia",
    "href": "chapters/bayesian_inference/04_subj_prop.html#bibliografia",
    "title": "44  Pensare ad una proporzione in termini soggettivi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nHardwicke, T. E., Thibault, R. T., Kosie, J. E., Wallach, J. D., Kidwell, M. C., & Ioannidis, J. P. (2022). Estimating the prevalence of transparency and reproducibility-related research practices in psychology (2014–2017). Perspectives on Psychological Science, 17(1), 239–251.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nShiffrin, R. M., & Schneider, W. (1977). Controlled and automatic human information processing: II. Perceptual learning, automatic attending and a general theory. Psychological Review, 84(2), 127–190.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_subj_prop.html#footnotes",
    "href": "chapters/bayesian_inference/04_subj_prop.html#footnotes",
    "title": "44  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Per comprendere la maledizione della dimensionalità, possiamo considerare l’esempio di una griglia di 100 punti equispaziati. Nel caso di un solo parametro, sarebbe necessario calcolare solo 100 valori. Tuttavia, se abbiamo due parametri, il numero di valori da calcolare diventa \\(100^2\\). Se invece abbiamo 10 parametri, il numero di valori da calcolare sarebbe di \\(10^{10}\\). È evidente che la quantità di calcoli richiesta diventa troppo grande persino per un computer molto potente. Pertanto, per modelli che richiedono la stima di un numero significativo di parametri, è necessario utilizzare un approccio diverso.↩︎",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_grid_gauss.html",
    "href": "chapters/bayesian_inference/05_grid_gauss.html",
    "title": "45  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "",
    "text": "45.1 Introduzione\nIn questo capitolo, estenderemo la discussione precedente sul calcolo della distribuzione a posteriori utilizzando il metodo basato su griglia, applicandolo questa volta a un caso con verosimiglianza gaussiana. In particolare, ci concentreremo su come costruire un modello gaussiano per descrivere l’intelligenza.\nImmaginiamo di condurre uno studio sulla plusdotazione, considerando l’approccio psicometrico. Secondo questo approccio, una persona è considerata plusdotata se ha un QI (Quoziente Intellettivo) di 130 o superiore (Robinson, Zigler, & Gallagher, 2000). Anche se l’uso di un QI di 130 come soglia è il criterio più comune, non è universalmente accettato. L’intelligenza nei bambini plusdotati non è solo superiore rispetto a quella dei loro pari, ma è qualitativamente diversa (Lubart & Zenasni, 2010). I bambini plusdotati tendono a mostrare caratteristiche come un vocabolario ampio, un linguaggio molto sviluppato, processi di ragionamento avanzati, eccellente memoria, vasti interessi, forte curiosità, empatia, capacità di leadership, abilità visive elevate, impegno in situazioni sfidanti e un forte senso di giustizia (Song & Porath, 2005).\nNella simulazione che seguirà, assumeremo che i dati provengano da una distribuzione normale. Per semplicità, considereremo che la deviazione standard sia nota e pari a 5. Il parametro della media sarà l’oggetto della nostra inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_grid_gauss.html#dati",
    "href": "chapters/bayesian_inference/05_grid_gauss.html#dati",
    "title": "45  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n45.2 Dati",
    "text": "45.2 Dati\nSupponiamo di avere un campione di 10 osservazioni. I dati saranno generati casualmente da una distribuzione normale con media 130 e deviazione standard 5.\n\nset.seed(123) # Per la riproducibilità\nvera_media &lt;- 130 # Media vera\nsigma_conosciuta &lt;- 5 # Deviazione standard conosciuta\ndimensione_campione &lt;- 10 # Dimensione del campione\n\n# Generare un campione\ncampione &lt;- round(rnorm(n = dimensione_campione, mean = vera_media, sd = sigma_conosciuta))\ncampione\n#&gt;  [1] 127 129 138 130 131 139 132 124 127 128",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_grid_gauss.html#griglia",
    "href": "chapters/bayesian_inference/05_grid_gauss.html#griglia",
    "title": "45  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n45.3 Griglia",
    "text": "45.3 Griglia\nCreiamo ora una griglia di 100 valori compresi tra 110 e 150.\n\nmu_griglia &lt;- seq(110, 150, length.out = 100)\nmu_griglia\n#&gt;   [1] 110.0 110.4 110.8 111.2 111.6 112.0 112.4 112.8 113.2 113.6 114.0\n#&gt;  [12] 114.4 114.8 115.3 115.7 116.1 116.5 116.9 117.3 117.7 118.1 118.5\n#&gt;  [23] 118.9 119.3 119.7 120.1 120.5 120.9 121.3 121.7 122.1 122.5 122.9\n#&gt;  [34] 123.3 123.7 124.1 124.5 124.9 125.4 125.8 126.2 126.6 127.0 127.4\n#&gt;  [45] 127.8 128.2 128.6 129.0 129.4 129.8 130.2 130.6 131.0 131.4 131.8\n#&gt;  [56] 132.2 132.6 133.0 133.4 133.8 134.2 134.6 135.1 135.5 135.9 136.3\n#&gt;  [67] 136.7 137.1 137.5 137.9 138.3 138.7 139.1 139.5 139.9 140.3 140.7\n#&gt;  [78] 141.1 141.5 141.9 142.3 142.7 143.1 143.5 143.9 144.3 144.7 145.2\n#&gt;  [89] 145.6 146.0 146.4 146.8 147.2 147.6 148.0 148.4 148.8 149.2 149.6\n#&gt; [100] 150.0",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_grid_gauss.html#calcolo-della-verosimiglianza",
    "href": "chapters/bayesian_inference/05_grid_gauss.html#calcolo-della-verosimiglianza",
    "title": "45  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n45.4 Calcolo della Verosimiglianza",
    "text": "45.4 Calcolo della Verosimiglianza\nPer ogni valore della griglia, calcoliamo la verosimiglianza complessiva come prodotto delle densità di probabilità.\n\nlikelihood &lt;- sapply(mu_griglia, function(mu) {\n    prod(dnorm(campione, mean = mu, sd = sigma_conosciuta))\n})\nlikelihood\n#&gt;   [1] 5.288e-50 1.406e-48 3.502e-47 8.172e-46 1.786e-44 3.658e-43 7.016e-42\n#&gt;   [8] 1.261e-40 2.122e-39 3.347e-38 4.944e-37 6.842e-36 8.870e-35 1.077e-33\n#&gt;  [15] 1.226e-32 1.306e-31 1.304e-30 1.220e-29 1.069e-28 8.772e-28 6.745e-27\n#&gt;  [22] 4.858e-26 3.278e-25 2.072e-24 1.227e-23 6.807e-23 3.537e-22 1.722e-21\n#&gt;  [29] 7.852e-21 3.355e-20 1.343e-19 5.033e-19 1.768e-18 5.816e-18 1.792e-17\n#&gt;  [36] 5.175e-17 1.400e-16 3.547e-16 8.418e-16 1.872e-15 3.899e-15 7.608e-15\n#&gt;  [43] 1.391e-14 2.381e-14 3.820e-14 5.741e-14 8.082e-14 1.066e-13 1.317e-13\n#&gt;  [50] 1.524e-13 1.652e-13 1.678e-13 1.596e-13 1.423e-13 1.188e-13 9.293e-14\n#&gt;  [57] 6.809e-14 4.674e-14 3.005e-14 1.810e-14 1.022e-14 5.400e-15 2.674e-15\n#&gt;  [64] 1.240e-15 5.391e-16 2.195e-16 8.370e-17 2.990e-17 1.001e-17 3.138e-18\n#&gt;  [71] 9.215e-19 2.535e-19 6.535e-20 1.578e-20 3.569e-21 7.563e-22 1.501e-22\n#&gt;  [78] 2.791e-23 4.863e-24 7.935e-25 1.213e-25 1.737e-26 2.330e-27 2.929e-28\n#&gt;  [85] 3.448e-29 3.802e-30 3.929e-31 3.802e-32 3.447e-33 2.928e-34 2.330e-35\n#&gt;  [92] 1.736e-36 1.212e-37 7.931e-39 4.860e-40 2.790e-41 1.500e-42 7.557e-44\n#&gt;  [99] 3.566e-45 1.576e-46",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_grid_gauss.html#calcolo-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/05_grid_gauss.html#calcolo-della-distribuzione-a-posteriori",
    "title": "45  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n45.5 Calcolo della Distribuzione a Posteriori",
    "text": "45.5 Calcolo della Distribuzione a Posteriori\nImpostiamo una prior uniforme e calcoliamo la distribuzione a posteriori normalizzata.\n\nprior &lt;- rep(1, length(mu_griglia)) # Prior uniforme\nposterior_non_norm &lt;- likelihood * prior\nposterior &lt;- posterior_non_norm / sum(posterior_non_norm) # Normalizzazione\n\nVisualizzazione:\n\n# Creazione del dataframe per il plot\ndat &lt;- tibble(\n  mu_griglia = mu_griglia, # Ascissa\n  posterior = posterior    # Ordinata\n)\n\n# Grafico con ggplot2\ndat |&gt;\n  ggplot(aes(x = mu_griglia, y = posterior)) +\n  geom_line(size = 1.2) + \n  labs(\n    title = \"Distribuzione a Posteriori della Media\",\n    x = \"Media\",\n    y = \"Probabilità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5), # Centra il titolo\n    legend.position = \"none\" \n  )\n\n\n\n\n\n\n\n\n45.5.1 Aggiunta di una Prior Informativa\nUsiamo una prior gaussiana con media 140 e deviazione standard 3.\n\n# Calcolo prior, posterior non normalizzato e posterior\nprior &lt;- dnorm(mu_griglia, mean = 140, sd = 3)\nposterior_non_norm &lt;- likelihood * prior\nposterior &lt;- posterior_non_norm / sum(posterior_non_norm)\n\n# Creazione del dataframe per il grafico\ndat &lt;- tibble(\n  mu_griglia = mu_griglia,\n  prior = prior / sum(prior),  # Normalizzazione del prior\n  posterior = posterior        # Posterior già normalizzato\n)\n\n# Preparazione dei dati in formato lungo per ggplot2\nlong_data &lt;- dat |&gt;\n  pivot_longer(\n    cols = c(prior, posterior),\n    names_to = \"distribution\",\n    values_to = \"density\"\n  )\n\n# Grafico con ggplot2\nlong_data |&gt;\n  ggplot(aes(x = mu_griglia, y = density, color = distribution, linetype = distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Distribuzione a Posteriori e Prior della Media\",\n    x = \"Media\",\n    y = \"Densità\",\n    color = \"Distribuzione\",\n    linetype = \"Distribuzione\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"bottom\"\n  )",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_grid_gauss.html#campionamento-dalla-posterior",
    "href": "chapters/bayesian_inference/05_grid_gauss.html#campionamento-dalla-posterior",
    "title": "45  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n45.6 Campionamento dalla Posterior",
    "text": "45.6 Campionamento dalla Posterior\nGeneriamo un campione dalla distribuzione a posteriori.\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Sampling from the posterior distribution\nindice_campionato &lt;- sample(1:length(mu_griglia), size = 1000, replace = TRUE, prob = posterior)\nmedia_campionata &lt;- mu_griglia[indice_campionato]\n\n# Create a dataframe for ggplot2\nsample_df &lt;- tibble(media_campionata = media_campionata)\n\n# Histogram using ggplot2\nggplot(sample_df, aes(x = media_campionata)) +\n  geom_histogram(\n    bins = 20, \n    color = \"white\", \n    alpha = 0.8\n  ) +\n  labs(\n    title = \"Campionamento dalla Posterior\",\n    x = \"Media\",\n    y = \"Frequenza\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\n# Media e intervallo di credibilità\nmean(media_campionata)\n#&gt; [1] 132.6\nquantile(media_campionata, c(0.03, 0.97))\n#&gt;    3%   97% \n#&gt; 130.2 135.5",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_grid_gauss.html#calcolo-della-log-verosimiglianza",
    "href": "chapters/bayesian_inference/05_grid_gauss.html#calcolo-della-log-verosimiglianza",
    "title": "45  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n45.7 Calcolo della Log-Verosimiglianza",
    "text": "45.7 Calcolo della Log-Verosimiglianza\nUtilizziamo i logaritmi per migliorare la stabilità numerica.\n\n# Calcolo log-likelihood, log-prior e posterior\nlog_likelihood &lt;- sapply(mu_griglia, function(mu) {\n  sum(dnorm(campione, mean = mu, sd = sigma_conosciuta, log = TRUE))\n})\nlog_prior &lt;- dnorm(mu_griglia, mean = 140, sd = 3, log = TRUE)\nlog_posterior_non_norm &lt;- log_likelihood + log_prior\nlog_posterior &lt;- log_posterior_non_norm - max(log_posterior_non_norm) # Stabilizzazione numerica\nposterior &lt;- exp(log_posterior) / sum(exp(log_posterior))\n\n# Creazione del dataframe per il grafico\ndat &lt;- tibble(\n  mu_griglia = mu_griglia,\n  posterior = posterior\n)\n\n# Grafico con ggplot2\ndat |&gt;\n  ggplot(aes(x = mu_griglia, y = posterior)) +\n  geom_line(size = 1.2) + \n  labs(\n    title = \"Distribuzione a Posteriori con Log-Verosimiglianza\",\n    x = \"Media\",\n    y = \"Probabilità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5), # Centra il titolo\n    legend.position = \"none\"               # Rimuove la legenda per una linea singola\n  )",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_grid_gauss.html#estensione-alla-deviazione-standard-ignota",
    "href": "chapters/bayesian_inference/05_grid_gauss.html#estensione-alla-deviazione-standard-ignota",
    "title": "45  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n45.8 Estensione alla Deviazione Standard Ignota",
    "text": "45.8 Estensione alla Deviazione Standard Ignota\nPer una griglia bidimensionale di valori di \\(\\mu\\) e \\(\\sigma\\):\n\nmu_griglia &lt;- seq(110, 150, length.out = 100)\nsigma_griglia &lt;- seq(1, 10, length.out = 50)\n\n# Create combinations of mu and sigma using expand.grid\ngrid &lt;- expand.grid(mu = mu_griglia, sigma = sigma_griglia)\n\n# Compute the log-likelihood for each combination of mu and sigma\nlog_likelihood &lt;- apply(grid, 1, function(params) {\n    mu &lt;- params[\"mu\"]\n    sigma &lt;- params[\"sigma\"]\n    sum(dnorm(campione, mean = mu, sd = sigma, log = TRUE))\n})\n\n# Reshape log-likelihood into a matrix\nlog_likelihood_2d &lt;- matrix(log_likelihood, nrow = length(mu_griglia), ncol = length(sigma_griglia))\n\n# Compute priors for mu and sigma\nlog_prior_mu &lt;- dnorm(mu_griglia, mean = 140, sd = 5, log = TRUE)\nlog_prior_sigma &lt;- dnorm(sigma_griglia, mean = 5, sd = 2, log = TRUE)\n\n# Combine priors into a grid\nlog_prior_2d &lt;- outer(log_prior_mu, log_prior_sigma, \"+\")\n\n# Compute log-posterior\nlog_posterior_2d &lt;- log_likelihood_2d + log_prior_2d\nlog_posterior_2d &lt;- log_posterior_2d - max(log_posterior_2d) # Stabilize\nposterior_2d &lt;- exp(log_posterior_2d)\nposterior_2d &lt;- posterior_2d / sum(posterior_2d) # Normalize\n\n# Convert posterior_2d to a data frame for visualization\nposterior_df &lt;- reshape2::melt(posterior_2d)\nnames(posterior_df) &lt;- c(\"mu_idx\", \"sigma_idx\", \"posterior\")\nposterior_df$mu &lt;- mu_griglia[posterior_df$mu_idx]\nposterior_df$sigma &lt;- sigma_griglia[posterior_df$sigma_idx]\n\n# Plot the posterior distribution\nggplot(posterior_df, aes(x = mu, y = sigma, fill = posterior)) +\n  geom_tile() +\n  scale_fill_viridis_c(name = \"Posterior\") +\n  labs(\n    title = \"Distribuzione a Posteriori Bidimensionale\",\n    x = expression(mu), \n    y = expression(sigma)\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"right\"\n  )",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_grid_gauss.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/05_grid_gauss.html#riflessioni-conclusive",
    "title": "45  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n45.9 Riflessioni Conclusive",
    "text": "45.9 Riflessioni Conclusive\nQuando si passa alla stima simultanea di più parametri, come la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)), l’analisi diventa notevolmente più complessa. Questo perché occorre considerare un numero molto maggiore di combinazioni di parametri rispetto alla stima di un solo parametro, aumentando così il carico computazionale. Inoltre, la scelta delle priors per ciascun parametro richiede particolare attenzione, poiché queste influenzeranno in modo diretto le stime a posteriori.\nIn scenari dove lo spazio dei parametri è multidimensionale o quando l’esplorazione della griglia diventa impraticabile, l’uso di metodi avanzati come il campionamento di Markov Chain Monte Carlo (MCMC) diventa indispensabile. Questi metodi permettono di campionare in modo efficiente dalla distribuzione a posteriori, senza la necessità di esplorare esplicitamente ogni combinazione possibile di parametri, rendendo l’analisi più gestibile anche in contesti complessi.\nIn conclusione, l’estensione dell’approccio bayesiano a problemi con più parametri sconosciuti richiede un’attenzione ancora maggiore nella definizione dello spazio dei parametri, nella selezione delle priors appropriate e nel calcolo delle distribuzioni a posteriori. L’adozione di tecniche come l’MCMC può facilitare questo processo, permettendo di affrontare in modo efficiente problemi che altrimenti sarebbero proibitivi dal punto di vista computazionale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/05_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "45  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4   thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.10.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     plyr_1.8.9        rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    viridisLite_0.4.2 mnormt_2.1.1      cli_3.6.4        \n#&gt; [17] rlang_1.1.5       munsell_0.5.1     withr_3.0.2       tools_4.4.2      \n#&gt; [21] parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1     \n#&gt; [25] vctrs_0.6.5       R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4\n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      Rcpp_1.0.14      \n#&gt; [33] glue_1.8.0        xfun_0.50         tidyselect_1.2.1  rstudioapi_0.17.1\n#&gt; [37] farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167      labeling_0.4.3   \n#&gt; [41] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_grid_gauss.html#bibliografia",
    "href": "chapters/bayesian_inference/05_grid_gauss.html#bibliografia",
    "title": "45  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_1.html",
    "href": "chapters/bayesian_inference/06_conjugate_families_1.html",
    "title": "46  Distribuzioni coniugate (1)",
    "section": "",
    "text": "46.1 Introduzione\nIn questo capitolo, esploriamo il concetto di distribuzioni a priori coniugate e il loro ruolo nell’inferenza bayesiana. Utilizzando il modello beta-binomiale come esempio paradigmatico, dimostreremo come queste distribuzioni semplifichino l’analisi attraverso calcoli analitici diretti. L’uso di una distribuzione a priori coniugata non solo rende l’inferenza più agevole, ma fornisce anche una chiara visione del modo in cui le credenze a priori influenzano le conclusioni.\nPer favorire la comprensione, procederemo in tre fasi principali:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_1.html#introduzione",
    "href": "chapters/bayesian_inference/06_conjugate_families_1.html#introduzione",
    "title": "46  Distribuzioni coniugate (1)",
    "section": "",
    "text": "Introduzione del modello beta-binomiale.\nAnalisi della distribuzione Beta e del suo ruolo come distribuzione a priori.\nDescrizione del processo di aggiornamento bayesiano e dei vantaggi derivanti dall’uso di distribuzioni coniugate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_1.html#il-modello-beta-binomiale",
    "href": "chapters/bayesian_inference/06_conjugate_families_1.html#il-modello-beta-binomiale",
    "title": "46  Distribuzioni coniugate (1)",
    "section": "\n46.2 Il Modello Beta-Binomiale",
    "text": "46.2 Il Modello Beta-Binomiale\nIl modello beta-binomiale è un esempio classico per analizzare una proporzione \\(\\theta\\), ossia la probabilità di successo in una sequenza di prove binarie (ad esempio, successo/fallimento). Supponiamo di osservare \\(y\\) successi su \\(n\\) prove, dove ogni prova è indipendente e con la stessa probabilità di successo \\(\\theta\\), che appartiene all’intervallo \\([0,1]\\).\nLa funzione di verosimiglianza, basata sulla distribuzione binomiale, è espressa come:\n\\[\n\\mathcal{Binomial}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove \\(\\binom{n}{y}\\) è il coefficiente binomiale che conta il numero di modi in cui \\(y\\) successi possono verificarsi in \\(n\\) prove.\nPer modellare la nostra conoscenza preliminare su \\(\\theta\\), scegliamo una distribuzione a priori Beta, che rappresenta un’ampia gamma di credenze iniziali con parametri flessibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_1.html#la-distribuzione-beta",
    "href": "chapters/bayesian_inference/06_conjugate_families_1.html#la-distribuzione-beta",
    "title": "46  Distribuzioni coniugate (1)",
    "section": "\n46.3 La Distribuzione Beta",
    "text": "46.3 La Distribuzione Beta\nLa distribuzione Beta è definita come:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{con } \\theta \\in (0, 1),\n\\]\ndove:\n\n\\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\) sono i iperparametri, che determinano la forma della distribuzione.\n\n\\(B(\\alpha, \\beta)\\) è la funzione Beta di Eulero, calcolata come:\n\\[\n  B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)},\n  \\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, una generalizzazione del fattoriale.\n\n\nNel contesto bayesiano:\n\n\n\\(\\alpha -1\\) rappresenta il numero ipotetico di “successi” a priori.\n\n\\(\\beta -1\\) rappresenta il numero ipotetico di “fallimenti” a priori.\n\nAd esempio:\n\nUna distribuzione Beta(1, 1) è uniforme (0 successi a priori e 0 fallimenti), indicando totale incertezza iniziale (assenza di credenze informate).\nUna distribuzione Beta(10, 20) rappresenta una conoscenza a priori basata su 9 successi e 19 fallimenti ipotizzati, indicando una convinzione iniziale relativamente solida, poiché deriva da un totale di 28 osservazioni virtuali che riflettono le credenze precedenti.\n\nQuesta interpretazione consente di calibrare le credenze a priori in base all’evidenza disponibile o alla fiducia nella stima.\nLa distribuzione Beta è estremamente versatile:\n\n\nForma: Valori diversi di \\(\\alpha\\) e \\(\\beta\\) producono distribuzioni simmetriche, asimmetriche o uniformi.\n\nForza del prior: Valori elevati di \\(\\alpha\\) e \\(\\beta\\) riducono la varianza, riflettendo credenze più forti.\n\nQuesta flessibilità rende la distribuzione Beta una scelta ideale per rappresentare credenze iniziali su proporzioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_1.html#aggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/06_conjugate_families_1.html#aggiornamento-bayesiano",
    "title": "46  Distribuzioni coniugate (1)",
    "section": "\n46.4 Aggiornamento Bayesiano",
    "text": "46.4 Aggiornamento Bayesiano\nL’aggiornamento bayesiano combina le informazioni iniziali (priori) con i dati osservati (verosimiglianza) per produrre una nuova distribuzione delle credenze (posteriori). Nel caso del modello beta-binomiale, questo processo è particolarmente semplice grazie alla “coniugazione”: il prior Beta e la verosimiglianza Binomiale producono una distribuzione a posteriori che appartiene ancora alla famiglia Beta.\n\n46.4.1 Problema\nDato \\(y\\) successi su \\(n\\) prove, vogliamo aggiornare la nostra distribuzione a priori Beta con i dati osservati per ottenere una distribuzione a posteriori Beta. I parametri aggiornati della distribuzione a posteriori sono dati da:\n\\[\n\\alpha' = \\alpha + y, \\quad \\beta' = \\beta + n - y.\n\\]\nEsaminiamo passo per passo come si arriva a questo risultato.\n\n46.4.2 Passaggi dell’Aggiornamento Bayesiano\n\n46.4.2.1 1. Formula di Bayes\nLa regola di Bayes stabilisce che:\n\\[\np(\\theta \\mid y, n) \\propto p(\\theta) \\cdot \\mathcal{L}(\\theta),\n\\]\ndove:\n\n\n\\(p(\\theta)\\) è la distribuzione a priori,\n\n\\(\\mathcal{L}(\\theta)\\) è la verosimiglianza,\n\n\\(\\propto\\) indica “proporzionale a”.\n\nCi concentriamo solo sui termini che dipendono da \\(\\theta\\), il parametro di interesse che rappresenta la probabilità di successo.\n\n46.4.2.2 2. Espressione del Prior\nIl prior è una distribuzione Beta, definita come:\n\\[\np(\\theta) = \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1},\n\\]\ndove:\n\n\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri che riflettono le credenze iniziali:\n\n\n\\(\\alpha\\): successi attesi prima di osservare i dati,\n\n\\(\\beta\\): insuccessi attesi prima di osservare i dati.\n\n\n\n46.4.2.3 3. Espressione della Verosimiglianza\nLa verosimiglianza è data dalla distribuzione binomiale, che descrive la probabilità di osservare \\(y\\) successi su \\(n\\) prove:\n\\[\n\\mathcal{L}(\\theta) \\propto \\theta^y (1-\\theta)^{n-y}.\n\\]\nQui:\n\n\n\\(y\\) è il numero di successi osservati,\n\n\\(n\\) è il numero totale di prove,\n\n\\(\\theta\\) è la probabilità di successo.\n\n46.4.2.4 4. Moltiplicazione di Prior e Verosimiglianza\nCombinando il prior e la verosimiglianza otteniamo:\n\\[\np(\\theta \\mid y, n) \\propto \\underbrace{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}_{\\text{Prior}} \\cdot \\underbrace{\\theta^y (1-\\theta)^{n-y}}_{\\text{Verosimiglianza}}.\n\\]\n\n46.4.2.5 5. Raggruppamento dei Termini\nMoltiplicando i termini simili, raggruppiamo gli esponenti di \\(\\theta\\) e \\(1-\\theta\\):\n\\[\np(\\theta \\mid y, n) \\propto \\theta^{(\\alpha-1) + y} (1-\\theta)^{(\\beta-1) + (n-y)}.\n\\]\n\n46.4.2.6 6. Forma Finale\nSemplificando gli esponenti, otteniamo:\n\\[\np(\\theta \\mid y, n) \\propto \\theta^{\\alpha + y - 1} (1-\\theta)^{\\beta + n - y - 1}.\n\\]\nQuesta espressione ha la forma di una distribuzione Beta con parametri aggiornati:\n\\[\n\\alpha' = \\alpha + y, \\quad \\beta' = \\beta + n - y.\n\\]\n\n46.4.2.7 7. Normalizzazione\nPer ottenere una distribuzione di probabilità vera e propria, dobbiamo normalizzare dividendo per una costante di normalizzazione. La funzione Beta \\(B(\\alpha', \\beta')\\) è definita come:\n\\[\nB(\\alpha', \\beta') = \\int_0^1 \\theta^{\\alpha' - 1} (1-\\theta)^{\\beta' - 1} \\, d\\theta.\n\\]\nLa distribuzione a posteriori normalizzata è quindi:\n\\[\np(\\theta \\mid y, n) = \\frac{\\theta^{\\alpha' - 1} (1-\\theta)^{\\beta' - 1}}{B(\\alpha', \\beta')}.\n\\]\n\n46.4.3 Conclusione\nI parametri aggiornati della distribuzione a posteriori sono:\n\n\n\\(\\alpha' = \\alpha + y\\): aggiorna il parametro dei successi con il numero di successi osservati,\n\n\\(\\beta' = \\beta + n - y\\): aggiorna il parametro degli insuccessi con il numero di insuccessi osservati.\n\n46.4.4 Vantaggi del Modello Beta-Binomiale\n\n\nSemplicità analitica: La coniugatezza della distribuzione Beta-Binomiale semplifica i calcoli, rendendo immediato l’aggiornamento dei parametri.\n\nInterpretazione intuitiva: L’aggiornamento dei parametri \\(\\alpha\\) e \\(\\beta\\) mostra in modo trasparente come i dati influenzino le credenze.\n\nIn sintesi, il modello Beta-Binomiale è un esempio didattico fondamentale per comprendere l’inferenza bayesiana e rappresenta un punto di partenza ideale per approcci più avanzati.\n\nEsempio 46.1 Nel Capitolo 44 abbiamo utilizzato il metodo basato su griglia per determinare la distribuzione a posteriori nel caso di \\(y = 6\\) successi su \\(n = 9\\) prove (vedi anche McElreath, 2020 per una discussione dettagliata). Ora esploriamo un approccio alternativo, sfruttando le proprietà delle famiglie coniugate.\nLa verosimiglianza binomiale per questo esperimento è espressa dalla seguente funzione:\n\\[\n\\mathcal{L}(\\theta) \\propto \\theta^y (1-\\theta)^{n-y},\n\\]\ndove \\(y = 6\\) rappresenta il numero di successi e \\(n = 9\\) il numero totale di prove.\nScegliendo una distribuzione a priori Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 5\\), possiamo applicare il teorema di Bayes per calcolare i parametri aggiornati della distribuzione a posteriori. In base alla regola di aggiornamento per distribuzioni coniugate, otteniamo:\n\\[\n\\alpha' = \\alpha + y = 2 + 6 = 8.\n\\] \\[\n\\beta' = \\beta + n - y = 5 + 9 - 6 = 8.\n\\]\nLa distribuzione a posteriori risultante è quindi una distribuzione Beta con parametri \\(\\mathcal{Beta}(8, 8)\\).\nProcediamo ora a visualizzare le tre distribuzioni rilevanti:\n\n\nDistribuzione a priori: \\(\\mathcal{Beta}(2, 2)\\),\n\nVerosimiglianza binomiale: per \\(y = 6\\) e \\(n = 9\\),\n\nDistribuzione a posteriori: \\(\\text{Beta}(8, 5)\\).\n\nEcco il codice R per generare il grafico comparativo:\n\n# Definizione dei parametri\nalpha_prior &lt;- 2\nbeta_prior &lt;- 5\ny &lt;- 6\nn &lt;- 9\n\n# Parametri della distribuzione a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\n# Sequenza di valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle PDF\nprior_pdf &lt;- dbeta(theta, shape1 = alpha_prior, shape2 = beta_prior)\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Normalizzazione della verosimiglianza\nlikelihood_integral &lt;- sum(likelihood) * (theta[2] - theta[1])\nnormalized_likelihood &lt;- likelihood / likelihood_integral\n\nposterior_pdf &lt;- dbeta(theta, shape1 = alpha_post, shape2 = beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = rep(theta, 3),\n  densita = c(prior_pdf, normalized_likelihood, posterior_pdf),\n  distribuzione = rep(c(\"Prior\", \"Likelihood\", \"Posterior\"), each = length(theta))\n)\n\n# Creare il grafico \nggplot(df, aes(x = theta, y = densita, color = distribuzione)) +\n  geom_line(size = 1) +  # Aggiungere le linee per le distribuzioni\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Likelihood\" = \"green\", \"Posterior\" = \"red\")) +  # Assegnare i colori\n  labs(title = \"Distribuzioni Prior, Likelihood e Posterior\",\n       x = expression(theta),\n       y = \"Densità\",\n       color = \"Distribuzione\") +  # Aggiungere titoli e label\n  theme(legend.position = \"top\")  # Posizionare la legenda in alto\n\n\n\n\n\n\n\n\n\nCurva blu: Prior \\(\\mathcal{Beta}(2, 5)\\), che riflette le credenze iniziali prima dell’osservazione dei dati.\n\n\nCurva verde: Likelihood (normalizzata), rappresenta l’evidenza fornita dai dati osservati.\n\n\nCurva rossa: Posterior \\(\\mathcal{Beta}(8, 8)\\), risultato dell’aggiornamento bayesiano che combina prior e likelihood.\n\nNota sulla normalizzazione della verosimiglianza. La verosimiglianza binomiale non è una distribuzione di probabilità (il suo integrale non è pari a 1). Per rappresentarla visivamente accanto alla distribuzione a priori e a quella a posteriori, è necessario normalizzarla. Questo è fatto calcolando il suo integrale su \\(\\theta \\in [0, 1]\\) e dividendo la funzione per il risultato. La normalizzazione serve solo per la visualizzazione e non influisce sui calcoli analitici.\n\n\nEsempio 46.2 Esaminiamo ora un esempio discuso da Johnson et al. (2022). In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorità, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell’articolo, Milgram descrive lo studio come\n\nconsistente nell’ordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che è un complice addestrato dell’esperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un ‘esperimento di apprendimento’ apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l’esperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre più intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realtà era un attore addestrato) sulla loro capacità di memorizzare una serie di item. Se l’attore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all’attore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l’attore stesse solo fingendo di provare dolore dalla scossa.\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello “Pericolo: Scossa Grave”. Il problema richiede di costruire la distribuzione a posteriori della probabilità \\(\\theta\\) di infliggere una scossa a l livello “Pericolo: Scossa Grave”, ipotizzando che uno studio precedente aveva stabilito che \\(\\theta\\) segue una distribuzione Beta(1, 10).\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n# Impostazione dei parametri della distribuzione Beta\nalpha &lt;- 1\nbeta_val &lt;- 10\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, shape1 = alpha, shape2 = beta_val)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  x = x_values,\n  densita = beta_pdf\n)\n\n# Creare il grafico\nggplot(df, aes(x = x, y = densita)) +\n  geom_line(color = \"#b97c7c\", size = 1) +  # Aggiungere la linea per la densità\n  labs(title = \"Distribuzione Beta(1, 10)\",  # Aggiungere il titolo\n       x = \"x\",  # Label dell'asse x\n       y = \"Densità di probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  geom_vline(xintercept = 0, color = \"black\", linetype = \"dashed\", size = 0.5) +  # Linea verticale opzionale\n  geom_vline(xintercept = 1, color = \"black\", linetype = \"dashed\", size = 0.5) +  # Linea verticale opzionale\n  annotate(\"text\", x = 0.8, y = max(beta_pdf) * 0.9, label = \"Beta(1, 10)\", color = \"#b97c7c\", size = 5)  # Aggiungere una legenda\n\n\n\n\n\n\n\nLa distribuzione a posteriori segue una distribuzione Beta con parametri aggiornati:\n\ny &lt;- 26\nn &lt;- 40\n\nalpha_prior &lt;- 1\nbeta_prior &lt;- 10\n\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\nalpha_post\n#&gt; [1] 27\nbeta_post\n#&gt; [1] 24\n\nCreazione di un grafico per la distribuzione a posteriori:\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, alpha_post, beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = x_values,\n  densita = beta_pdf\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densità\n  labs(title = \"Distribuzione Beta(27, 24)\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Densità di probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  annotate(\"text\", x = 0.8, y = max(beta_pdf) * 0.9, label = \"Beta(27, 24)\", color = \"blue\", size = 5)  \n\n\n\n\n\n\n\nCalcolo della media a posteriori di \\(\\theta\\):\n\nalpha_post / (alpha_post + beta_post)\n#&gt; [1] 0.5294\n\nCalcolo della moda a posteriori:\n\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n#&gt; [1] 0.5306\n\nCalcolo della probabilità che \\(\\theta &gt; 0.6\\):\n\npbeta(0.6, alpha_post, beta_post, lower.tail = FALSE)\n#&gt; [1] 0.1562\n\nOvvero:\n\n1 - pbeta(0.6, alpha_post, beta_post)\n#&gt; [1] 0.1562\n\nEseguiamo il problema utilizzando il metodo basato su griglia. Definiamo la griglia di interesse:\n\ntheta &lt;- seq(0, 1, length.out = 100)\n\nCreiamo la distribuzione a priori:\n\nprior &lt;- dbeta(theta, alpha_prior, beta_prior)\n\n# Normalizzazione della densità per ottenere una somma pari a 1\nprior_normalized &lt;- prior / sum(prior)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = prior_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"blue\", size = 1) +  # Linee verticali per rappresentare le probabilità\n  labs(title = \"Distribuzione a priori\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nCreiamo la verosimiglianza:\n\nlk &lt;- dbinom(y, n, theta)\n\n# Normalizzazione della verosimiglianza per ottenere una somma pari a 1\nlk_normalized &lt;- lk / sum(lk)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = lk_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"red\", size = 1) +  # Linee verticali per rappresentare la verosimiglianza\n  labs(title = \"Verosimiglianza\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nCalcoliamo la distribuzione a posteriori:\n\npost &lt;- (prior * lk) / sum(prior * lk)\n\n# Normalizzazione della verosimiglianza per ottenere una somma pari a 1\nlk_normalized &lt;- lk / sum(lk)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = lk_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"green\", size = 1) +  # Linee verticali per rappresentare la verosimiglianza\n  labs(title = \"Distribuzione a posteriori\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nEstrazione di un campione dalla distribuzione a posteriori:\n\nsamples &lt;- sample(theta, size = 1e6, replace = TRUE, prob = post)\n\nTroviamo la media a posteriori:\n\nmean(samples)\n#&gt; [1] 0.5295\n\nCalcoliamo la probabilità che \\(\\theta &gt; 0.6\\):\n\nmean(samples &gt; 0.6)\n#&gt; [1] 0.1527\n\nQuesto codice mantiene la struttura logica del problema e produce risultati equivalenti utilizzando R.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "href": "chapters/bayesian_inference/06_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "title": "46  Distribuzioni coniugate (1)",
    "section": "\n46.5 Principali distribuzioni coniugate",
    "text": "46.5 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle più note coniugazioni tra modelli statistici e distribuzioni a priori:\n\nNel modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribuzione a priori è \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione a posteriori è \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nNel modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nNel modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nNel modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribuzione a priori è \\(\\text{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione a posteriori è \\(\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_1.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/06_conjugate_families_1.html#riflessioni-conclusive",
    "title": "46  Distribuzioni coniugate (1)",
    "section": "\n46.6 Riflessioni Conclusive",
    "text": "46.6 Riflessioni Conclusive\nIn conclusione, l’utilizzo di priori coniugati presenta vantaggi e svantaggi. Cominciamo con i vantaggi principali. Il principale vantaggio dell’adozione di distribuzioni a priori coniugate risiede nella loro capacità di rendere l’analisi della distribuzione a posteriori trattabile da un punto di vista analitico. Ad esempio, nel corso di questo capitolo abbiamo esaminato come sia possibile formulare la distribuzione a posteriori in seguito a un esperimento composto da una serie di prove di Bernoulli (con una verosimiglianza binomiale), utilizzando una distribuzione Beta sia per la prior che per il posteriore.\nTuttavia, è cruciale riconoscere che i modelli basati sul concetto di famiglie coniugate presentano delle limitazioni intrinseche. Le distribuzioni coniugate a priori sono disponibili solamente per distribuzioni di verosimiglianza di base e relativamente semplici. Per modelli complessi e più realistici, la ricerca di priori coniugati diventa spesso un compito estremamente arduo, limitando quindi la loro utilità. Inoltre, anche quando le distribuzioni a priori coniugate sono disponibili, un modello che ne fa uso potrebbe non essere sufficientemente flessibile per adattarsi alle nostre credenze iniziali. Ad esempio, un modello basato su una distribuzione normale è sempre unimodale e simmetrico rispetto alla media \\(\\mu\\). Tuttavia, se le nostre conoscenze iniziali non sono simmetriche o non seguono una distribuzione unimodale, la scelta di una distribuzione a priori normale potrebbe non risultare la più adeguata (Johnson et al., 2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_1.html#esercizi",
    "href": "chapters/bayesian_inference/06_conjugate_families_1.html#esercizi",
    "title": "46  Distribuzioni coniugate (1)",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nSi consideri lo studio “An excess of positive results: Comparing the standard psychology literature with registered reports” di Scheel et al. (2021). In questo lavoro, gli autori confrontano il tasso di risultati positivi \\(\\theta\\) ottenuti in studi psicologici pubblicati senza preregistrazione con quelli pubblicati con preregistrazione. Si utilizzi il tasso di successo riportato negli studi preregistrati per costruire una distribuzione a priori per il parametro \\(\\theta\\).\nSecondo i risultati degli studi preregistrati, gli autori riscontrano un tasso di successo del 43.66%, con un intervallo di confidenza al 95% [CI] = [31.91, 55.95]. Sulla base di questi dati, si costruisca una distribuzione beta come distribuzione a priori per \\(\\theta\\), seguendo il metodo illustrato da Johnson et al. (2022).\nSuccessivamente, utilizzando questa distribuzione beta come distribuzione a priori, si determini la distribuzione a posteriori utilizzando il metodo delle famiglie coniugate per due scenari distinti, basati su 152 studi osservati: (a) Un tasso di successo del 60% (b) Un tasso di successo del 96% (come riportato per gli studi non preregistrati da Scheel et al. (2021)).\nInfine, si commentino i risultati derivanti dall’analisi delle distribuzioni a posteriori ottenute per entrambi gli scenari.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\n\n# Funzione per trovare i parametri della distribuzione beta\nfind_beta_parameters &lt;- function(mean, lower, upper, conf_level = 0.95) {\n  # Funzione obiettivo da minimizzare\n  objective &lt;- function(alpha) {\n    beta &lt;- alpha * (1 - mean) / mean\n    predicted_ci &lt;- qbeta(c((1-conf_level)/2, 1-(1-conf_level)/2), alpha, beta)\n    error &lt;- (predicted_ci[1] - lower)^2 + (predicted_ci[2] - upper)^2\n    return(error)\n  }\n  \n  # Ottimizzazione per trovare alpha\n  result &lt;- optimize(objective, interval = c(0.1, 100))\n  alpha &lt;- result$minimum\n  beta &lt;- alpha * (1 - mean) / mean\n  \n  return(list(alpha = alpha, beta = beta))\n}\n\n# Parametri degli studi preregistrati\nmean_preregistered &lt;- 0.4366\nci_lower &lt;- 0.3191\nci_upper &lt;- 0.5595\n\n# Calcolo dei parametri della distribuzione beta a priori\nprior_params &lt;- find_beta_parameters(mean_preregistered, ci_lower, ci_upper)\nalpha_prior &lt;- prior_params$alpha\nbeta_prior &lt;- prior_params$beta\n\n# Dati osservati\nn &lt;- 152  # numero di studi\nsuccesses_60 &lt;- round(0.60 * n)  # scenario (a)\nsuccesses_96 &lt;- round(0.96 * n)  # scenario (b)\n\n# Calcolo delle distribuzioni a posteriori\nalpha_post_60 &lt;- alpha_prior + successes_60\nbeta_post_60 &lt;- beta_prior + (n - successes_60)\n\nalpha_post_96 &lt;- alpha_prior + successes_96\nbeta_post_96 &lt;- beta_prior + (n - successes_96)\n\n# Creazione del dataframe per il plotting\ntheta &lt;- seq(0, 1, length.out = 1000)\n\ndf &lt;- data.frame(\n  theta = rep(theta, 3),\n  density = c(\n    dbeta(theta, alpha_prior, beta_prior),\n    dbeta(theta, alpha_post_60, beta_post_60),\n    dbeta(theta, alpha_post_96, beta_post_96)\n  ),\n  distribution = rep(c(\"Priori\", \"Posteriori (60%)\", \"Posteriori (96%)\"), \n                    each = length(theta))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    x = expression(theta),\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n# Calcolo degli intervalli di credibilità al 95%\ncredible_intervals &lt;- data.frame(\n  Distribution = c(\"Priori\", \"Posteriori (60%)\", \"Posteriori (96%)\"),\n  Mean = c(\n    alpha_prior / (alpha_prior + beta_prior),\n    alpha_post_60 / (alpha_post_60 + beta_post_60),\n    alpha_post_96 / (alpha_post_96 + beta_post_96)\n  ),\n  Lower = c(\n    qbeta(0.025, alpha_prior, beta_prior),\n    qbeta(0.025, alpha_post_60, beta_post_60),\n    qbeta(0.025, alpha_post_96, beta_post_96)\n  ),\n  Upper = c(\n    qbeta(0.975, alpha_prior, beta_prior),\n    qbeta(0.975, alpha_post_60, beta_post_60),\n    qbeta(0.975, alpha_post_96, beta_post_96)\n  )\n)\n\n# Visualizzazione dei risultati\nprint(\"Parametri della distribuzione beta a priori:\")\nprint(paste(\"alpha =\", round(alpha_prior, 2)))\nprint(paste(\"beta =\", round(beta_prior, 2)))\n\nprint(\"\\nIntervalli di credibilità al 95%:\")\nprint(credible_intervals)\n\n# Visualizza il grafico\nprint(p)\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nTra i fattori che possono influenzare il rapporto tra i sessi alla nascita c’è la condizione materna di placenta previa, una condizione insolita della gravidanza in cui la placenta è impiantata in basso nell’utero, impedendo un normale parto vaginale del feto. Uno studio condotto in Germania ha esaminato il sesso dei neonati in casi di placenta previa e ha riscontrato che, su un totale di 980 nascite, 437 erano femmine.\nQuanta evidenza fornisce questo studio a supporto dell’ipotesi che la proporzione di nascite femminili nella popolazione di placenta previa sia inferiore a 0.485, che rappresenta la proporzione di nascite femminili nella popolazione generale? (Esercizio tratto da Gelman et al. (1995))\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Calcolo della proporzione osservata\np_hat &lt;- y/n\nprint(paste(\"Proporzione osservata di femmine:\", round(p_hat, 3)))\n\n# Test dell'ipotesi utilizzando il Bayes Factor\n# H0: p = 0.485 vs H1: p &lt; 0.485\n\n# Funzione per calcolare la verosimiglianza marginale sotto H1\nmarginal_likelihood_h1 &lt;- function(y, n, p_max = 0.485) {\n  # Integrazione numerica sulla distribuzione uniforme tra 0 e p_max\n  p_grid &lt;- seq(0, p_max, length.out = 1000)\n  likelihood &lt;- dbinom(y, n, p_grid)\n  prior &lt;- dunif(p_grid, 0, p_max)\n  mean(likelihood * prior) * p_max\n}\n\n# Verosimiglianza sotto H0\nlikelihood_h0 &lt;- dbinom(y, n, p0)\n\n# Verosimiglianza marginale sotto H1\nmarg_lik_h1 &lt;- marginal_likelihood_h1(y, n)\n\n# Calcolo del Bayes Factor\nbf10 &lt;- marg_lik_h1 / likelihood_h0\nprint(paste(\"Bayes Factor (H1 vs H0):\", round(bf10, 2)))\n\n# Visualizzazione delle distribuzioni a posteriori\np_grid &lt;- seq(0, 1, length.out = 1000)\nlikelihood &lt;- dbinom(y, n, p_grid)\nprior &lt;- dunif(p_grid, 0, 1)\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = p_grid,\n  Posterior = posterior / max(posterior)  # normalizzato per la visualizzazione\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = Posterior)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = p_hat, linetype = \"dashed\", color = \"blue\") +\n  labs(\n    title = \"Distribuzione a Posteriori della Proporzione di Nascite Femminili\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità a Posteriori (normalizzata)\"\n  ) +\n  annotate(\"text\", x = p0, y = 0.1, \n           label = \"Popolazione Generale\", \n           angle = 90, vjust = -0.5, color = \"red\") +\n  annotate(\"text\", x = p_hat, y = 0.1, \n           label = \"Proporzione Osservata\", \n           angle = 90, vjust = -0.5, color = \"blue\")\n\n# Calcolo dell'intervallo di credibilità al 95%\nsorted_p &lt;- sort(p_grid)\ncum_post &lt;- cumsum(posterior)\nlower &lt;- sorted_p[which(cum_post &gt; 0.025)[1]]\nupper &lt;- sorted_p[which(cum_post &gt; 0.975)[1]]\n\nprint(paste(\"Intervallo di credibilità al 95%: [\", \n            round(lower, 3), \",\", round(upper, 3), \"]\"))\n\n# Calcolo della probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- sum(posterior[p_grid &lt; p0])\nprint(paste(\"Probabilità a posteriori che p &lt; 0.485:\", \n            round(prob_less_than_p0, 3)))\n\n# Visualizza il grafico\nprint(p)\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nPer valutare la sensibilità della soluzione precedente alla scelta della distribuzione a priori, ripetere l’esercizio utilizzando come distribuzione a priori per la proporzione di nascite femminili una distribuzione Beta(48.5, 51.5). Questa distribuzione è centrata su 0.485 e concentra la maggior parte della sua massa nell’intervallo [0.385, 0.585]. Interpretare i risultati ottenuti.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Parametri della distribuzione beta a priori\nalpha_prior &lt;- 48.5\nbeta_prior &lt;- 51.5\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori Beta(48.5, 51.5)\", \"Posteriori\"), each = length(p_grid))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    subtitle = \"Proporzione di Nascite Femminili con Placenta Previa\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = p0, y = max(posterior_density)/2, \n           label = \"Popolazione Generale (0.485)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Calcolo statistiche rilevanti\n# Media a priori e posteriori\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\n# Intervalli di credibilità al 95%\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- pbeta(p0, alpha_post, beta_post)\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Dati osservati:\\n\")\ncat(sprintf(\"Numero totale di nascite: %d\\n\", n))\ncat(sprintf(\"Numero di femmine: %d\\n\", y))\ncat(sprintf(\"Proporzione osservata: %.3f\\n\\n\", y/n))\n\ncat(\"Analisi a priori:\\n\")\ncat(sprintf(\"Media a priori: %.3f\\n\", prior_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\\n\", \n            prior_ci[1], prior_ci[2]))\n\ncat(\"Analisi a posteriori:\\n\")\ncat(sprintf(\"Media a posteriori: %.3f\\n\", post_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\", \n            post_ci[1], post_ci[2]))\ncat(sprintf(\"Probabilità che p &lt; %.3f: %.3f\\n\", p0, prob_less_than_p0))\n\n# Visualizza il grafico\nprint(p)\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Parametri della distribuzione beta a priori\nalpha_prior &lt;- 48.5\nbeta_prior &lt;- 51.5\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori Beta(48.5, 51.5)\", \"Posteriori\"), each = length(p_grid))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    subtitle = \"Proporzione di Nascite Femminili con Placenta Previa\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = p0, y = max(posterior_density)/2, \n           label = \"Popolazione Generale (0.485)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Calcolo statistiche rilevanti\n# Media a priori e posteriori\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\n# Intervalli di credibilità al 95%\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- pbeta(p0, alpha_post, beta_post)\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Dati osservati:\\n\")\ncat(sprintf(\"Numero totale di nascite: %d\\n\", n))\ncat(sprintf(\"Numero di femmine: %d\\n\", y))\ncat(sprintf(\"Proporzione osservata: %.3f\\n\\n\", y/n))\n\ncat(\"Analisi a priori:\\n\")\ncat(sprintf(\"Media a priori: %.3f\\n\", prior_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\\n\", \n            prior_ci[1], prior_ci[2]))\n\ncat(\"Analisi a posteriori:\\n\")\ncat(sprintf(\"Media a posteriori: %.3f\\n\", post_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\", \n            post_ci[1], post_ci[2]))\ncat(sprintf(\"Probabilità che p &lt; %.3f: %.3f\\n\", p0, prob_less_than_p0))\n\n# Visualizza il grafico\nprint(p)\nI risultati mostrano che:\n\nLa proporzione osservata nel campione (0.446) è inferiore al valore di riferimento della popolazione generale (0.485)\nLa distribuzione a priori Beta(48.5, 51.5):\n\n\nHa media 0.485\nRiflette la nostra conoscenza iniziale sulla proporzione di nascite femminili\nFornisce un’incertezza ragionevole attorno al valore di riferimento\n\n\nLa distribuzione a posteriori:\n\n\nHa una media di circa 0.447\nL’intervallo di credibilità al 95% esclude il valore di riferimento 0.485\nIndica una probabilità elevata che la vera proporzione sia inferiore a 0.485\n\n\nQuesta analisi suggerisce che:\n\n\nEsiste un’associazione tra placenta previa e una minor proporzione di nascite femminili\nL’effetto è moderato ma statisticamente rilevante\nLa stima è abbastanza precisa grazie alla dimensione campionaria considerevole\n\n\n\n\n\n\n\n\n\n\nProblemi 4\n\n\n\n\n\nIn uno studio recente, Gori et al. (2024) hanno esaminato un campione di 202 adulti italiani e hanno riscontrato una prevalenza di mancini del 6.4%. Una meta-analisi di Papadatou-Pastou et al. (2020), condotta su un totale di 2,396,170 soggetti, riporta che la proporzione di mancini varia tra il 9.3% e il 18.1%, a seconda di come viene misurata la lateralità manuale. Inoltre, Papadatou-Pastou et al. (2020) mostrano che la prevalenza della lateralità manuale varia tra i paesi e nel tempo. Considerata questa incertezza, si determini la distribuzione a posteriori che combina i dati dello studio di Gori et al. (2024) con le informazioni pregresse fornite da Papadatou-Pastou et al. (2020). Le informazioni di Papadatou-Pastou et al. (2020) possono essere espresse in termini di una distribuzione Beta(8, 60).\n\n\n\n\n\n\n\n\n\nSoluzioni 4\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati dello studio di Gori et al. (2024)\nn &lt;- 202       # dimensione del campione\ny &lt;- round(0.064 * n)  # numero di mancini (6.4% del campione)\n\n# Parametri della distribuzione beta a priori (da Papadatou-Pastou et al., 2020)\nalpha_prior &lt;- 8\nbeta_prior &lt;- 60\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 0.3, length.out = 1000)  # limitato a 0.3 per migliore visualizzazione\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori (Papadatou-Pastou et al., 2020)\", \n                      \"Posteriori (con dati Gori et al., 2024)\"), \n                    each = length(p_grid))\n)\n\n# Calcolo statistiche rilevanti\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = 0.064, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della Prevalenza dei Mancini\",\n    subtitle = \"Confronto tra Distribuzione a Priori e a Posteriori\",\n    x = \"Proporzione di Mancini\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = 0.064, y = max(posterior_density)/2, \n           label = \"Valore osservato (6.4%)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Distribuzione a priori (Papadatou-Pastou et al., 2020):\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", prior_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\\n\", \n            prior_ci[1] * 100, prior_ci[2] * 100))\n\ncat(\"Dati osservati (Gori et al., 2024):\\n\")\ncat(sprintf(\"Campione: %d individui\\n\", n))\ncat(sprintf(\"Mancini osservati: %d (%.1f%%)\\n\\n\", y, y/n * 100))\n\ncat(\"Distribuzione a posteriori:\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", post_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\", \n            post_ci[1] * 100, post_ci[2] * 100))\n\n# Visualizza il grafico\nprint(p)\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati dello studio di Gori et al. (2024)\nn &lt;- 202       # dimensione del campione\ny &lt;- round(0.064 * n)  # numero di mancini (6.4% del campione)\n\n# Parametri della distribuzione beta a priori (da Papadatou-Pastou et al., 2020)\nalpha_prior &lt;- 8\nbeta_prior &lt;- 60\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 0.3, length.out = 1000)  # limitato a 0.3 per migliore visualizzazione\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori (Papadatou-Pastou et al., 2020)\", \n                      \"Posteriori (con dati Gori et al., 2024)\"), \n                    each = length(p_grid))\n)\n\n# Calcolo statistiche rilevanti\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = 0.064, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della Prevalenza dei Mancini\",\n    subtitle = \"Confronto tra Distribuzione a Priori e a Posteriori\",\n    x = \"Proporzione di Mancini\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = 0.064, y = max(posterior_density)/2, \n           label = \"Valore osservato (6.4%)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Distribuzione a priori (Papadatou-Pastou et al., 2020):\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", prior_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\\n\", \n            prior_ci[1] * 100, prior_ci[2] * 100))\n\ncat(\"Dati osservati (Gori et al., 2024):\\n\")\ncat(sprintf(\"Campione: %d individui\\n\", n))\ncat(sprintf(\"Mancini osservati: %d (%.1f%%)\\n\\n\", y, y/n * 100))\n\ncat(\"Distribuzione a posteriori:\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", post_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\", \n            post_ci[1] * 100, post_ci[2] * 100))\n\n# Visualizza il grafico\nprint(p)\nL’analisi bayesiana della prevalenza dei mancini combina le informazioni provenienti dalla meta-analisi di Papadatou-Pastou et al. (2020) con i dati più recenti di Gori et al. (2024). Di seguito sono riportati i principali risultati:\n\n\nDistribuzione a priori (basata su Papadatou-Pastou et al., 2020):\n\nModellata come una distribuzione Beta(8, 60).\n\nPresenta una media intorno all’11,8%.\n\nRiflette la variabilità osservata nella meta-analisi.\n\nL’intervallo di credibilità al 95% copre approssimativamente il range 9,3%-18,1%, come riportato nello studio.\n\n\n\nDati osservati (Gori et al., 2024):\n\n202 partecipanti italiani.\n\n13 mancini, corrispondenti al 6,4% del campione.\n\nQuesto valore è inferiore alla media stimata dalla meta-analisi globale.\n\n\n\nDistribuzione a posteriori:\n\nCombina le informazioni a priori con i nuovi dati osservati.\n\nLa media a posteriori si è spostata verso il basso rispetto alla distribuzione a priori.\n\nL’intervallo di credibilità si è ristretto, indicando una riduzione dell’incertezza.\n\nMaggiore peso è stato attribuito ai dati italiani rispetto alla meta-analisi globale.\n\n\n\nInterpretazione:\n\nLa stima finale suggerisce una prevalenza di mancini nella popolazione italiana inferiore alla media globale.\n\nQuesto risultato potrebbe riflettere specificità culturali o metodologiche dello studio italiano.\n\nL’incertezza nella stima finale è diminuita rispetto alla meta-analisi, ma rimane significativa.\n\nI risultati supportano l’ipotesi di una variabilità geografica nella prevalenza della mancinismo.\n\n\n\nLa distribuzione a posteriori fornisce una sintesi equilibrata tra le conoscenze globali precedenti e i dati specifici della popolazione italiana, suggerendo che potrebbero esistere peculiarità culturali o demografiche che influenzano la prevalenza del mancinismo in Italia.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/06_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "46  Distribuzioni coniugate (1)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.10.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        Rdpack_2.6.2      vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    pan_1.9          \n#&gt; [13] pacman_0.5.1      jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-2     \n#&gt; [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [21] mnormt_2.1.1      codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64       reformulas_0.4.0 \n#&gt; [29] iterators_1.0.14  rpart_4.1.24      boot_1.3-31       mitml_0.4-5      \n#&gt; [33] foreach_1.5.2     nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37    \n#&gt; [37] stringi_1.8.4     labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4  \n#&gt; [41] fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1  cli_3.6.4        \n#&gt; [45] magrittr_2.0.3    survival_3.8-3    broom_1.0.7       withr_3.0.2      \n#&gt; [49] backports_1.5.0   timechange_0.3.0  rmarkdown_2.29    nnet_7.3-20      \n#&gt; [53] lme4_1.1-36       hms_1.1.3         evaluate_1.0.3    rbibutils_2.3    \n#&gt; [57] rlang_1.1.5       Rcpp_1.0.14       glue_1.8.0        minqa_1.2.8      \n#&gt; [61] rstudioapi_0.17.1 jsonlite_1.8.9    R6_2.6.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_1.html#bibliografia",
    "href": "chapters/bayesian_inference/06_conjugate_families_1.html#bibliografia",
    "title": "46  Distribuzioni coniugate (1)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGori, B., Grippo, A., Focardi, M., & Lolli, F. (2024). The Italian version of Edinburgh Handedness Inventory: Translation, transcultural adaptation, and validation in healthy subjects. Laterality, 29(2), 151–168.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPapadatou-Pastou, M., Ntolka, E., Schmitz, J., Martin, M., Munafò, M. R., Ocklenburg, S., & Paracchini, S. (2020). Human handedness: A meta-analysis. Psychological bulletin, 146(6), 481–524.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_2.html",
    "href": "chapters/bayesian_inference/07_conjugate_families_2.html",
    "title": "47  Distribuzioni coniugate (2)",
    "section": "",
    "text": "47.1 Introduzione\nLa statistica bayesiana ci permette di aggiornare le nostre credenze iniziali o conoscenze a priori sulla distribuzione di un parametro (in questo caso, la media della popolazione) in base ai dati osservati. Questo processo di aggiornamento ci porta a ottenere una distribuzione a posteriori che riflette una nuova comprensione del parametro, integrata con le informazioni fornite dal campione.\nIl concetto fondamentale è che, attraverso l’aggiornamento bayesiano, l’incertezza sulla stima del parametro si riduce. Questo è dovuto al fatto che l’informazione aggiuntiva fornita dai dati osservati consente di “restringere” la distribuzione a posteriori rispetto alla distribuzione a priori, riducendo così la varianza (o deviazione standard) della distribuzione del parametro di interesse.\nIn questo capitolo, approfondiremo il tema delle famiglie coniugate (Capitolo 46), focalizzandoci sul modello normale-normale. Una caratteristica distintiva di questo modello è la sua capacità di auto-coniugazione rispetto a una funzione di verosimiglianza gaussiana. In termini più semplici, se la funzione di verosimiglianza segue una distribuzione gaussiana, l’adozione di una distribuzione a priori gaussiana per la media garantisce che anche la distribuzione a posteriori mantenga la sua forma gaussiana.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_2.html#perché-usare-la-distribuzione-normale",
    "href": "chapters/bayesian_inference/07_conjugate_families_2.html#perché-usare-la-distribuzione-normale",
    "title": "47  Distribuzioni coniugate (2)",
    "section": "\n47.2 Perché Usare la Distribuzione Normale?",
    "text": "47.2 Perché Usare la Distribuzione Normale?\nSpesso, quando la distribuzione a posteriori è nota per essere unimodale e simmetrica, possiamo modellarla efficacemente con una distribuzione normale, anche se sappiamo che la sua forma è solo approssimativamente normale. Nei casi in cui il ricercatore abbia un’idea approssimativa di dove sia centrato un parametro sconosciuto, la distribuzione normale fornisce un metodo utile per modellare questa stima, permettendo di descrivere il livello di incertezza tramite il termine di varianza della distribuzione normale. Questa convenienza può offrire buone approssimazioni alla densità a posteriori desiderata, con la consapevolezza che, con l’aumentare dei dati osservati, tali assunzioni perdono di importanza.\nCome dimostrato di seguito, il modello normale bayesiano possiede proprietà frequentiste desiderabili. Sebbene l’enfasi nell’analisi bayesiana non sia sulle stime puntuali, si può dimostrare che, con campioni sempre più grandi, la media della distribuzione a posteriori bayesiana si avvicina alla stima di massima verosimiglianza. Questa proprietà esiste perché la distribuzione a posteriori è un compromesso ponderato tra la distribuzione a priori specificata dall’utente, che in questo capitolo è normale, e la funzione di verosimiglianza derivata dai dati, anch’essa normale in questo capitolo. Con l’aumentare delle dimensioni del campione, la verosimiglianza diventa sempre più dominante in questa ponderazione.\nNel caso di una media normale, illustrato qui, la varianza della distribuzione di campionamento frequentista diminuisce con l’aumento della dimensione del campione. Nel contesto bayesiano, la riduzione della varianza media dalla funzione di verosimiglianza alla fine prevale anche su una varianza a priori deliberatamente grande. Pertanto, se si prevede che la dimensione del dataset sia grande, i ricercatori possono permettersi di essere liberali nella specificazione della varianza a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "href": "chapters/bayesian_inference/07_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "title": "47  Distribuzioni coniugate (2)",
    "section": "\n47.3 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota",
    "text": "47.3 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota\nConsideriamo un insieme di dati \\(y = [y_1, y_2, \\ldots, y_n]\\), composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) secondo una distribuzione normale \\(\\mathcal{N}(\\mu, \\sigma^2)\\). In questo scenario, il nostro obiettivo è stimare il valore del parametro \\(\\mu\\), che rappresenta la media della popolazione da cui provengono i dati.\n\n47.3.1 Distribuzione a Priori\nNell’approccio bayesiano, assumiamo una conoscenza iniziale sul parametro \\(\\mu\\) mediante una distribuzione a priori. In questo caso, utilizziamo una distribuzione normale coniugata, ovvero una distribuzione normale con media \\(\\mu_0\\) e varianza \\(\\sigma_0^2\\). Questa scelta riflette la nostra incertezza iniziale su \\(\\mu\\).\n\n47.3.2 Funzione di Verosimiglianza\nLa funzione di verosimiglianza, denotata da \\(p(y | \\mu, \\sigma)\\), rappresenta la probabilità di osservare i dati \\(y\\) dato il valore del parametro \\(\\mu\\) e la varianza nota \\(\\sigma^2\\). Per una distribuzione normale i.i.d., la funzione di verosimiglianza è data da:\n\\[\np(y | \\mu, \\sigma) = \\prod_{i=1}^n \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(y_i - \\mu)^2}{2\\sigma^2}\\right).\n\\]\n\n47.3.3 Teorema di Bayes e Distribuzione a Posteriori\nIl teorema di Bayes combina la distribuzione a priori con la funzione di verosimiglianza per ottenere la distribuzione a posteriori del parametro \\(\\mu\\), data l’evidenza osservata \\(y\\):\n\\[\np(\\mu | y) = \\frac{ p(y | \\mu) p(\\mu) }{ p(y) }.\n\\]\nPoiché la distribuzione a priori e la funzione di verosimiglianza sono entrambe distribuzioni normali, la distribuzione a posteriori risulterà anch’essa una distribuzione normale con media a posteriori \\(\\mu_p\\) e varianza a posteriori \\(\\sigma_p^2\\).\n\n47.3.4 Formula per la Media a Posteriori (\\(\\mu_p\\))\nLa media a posteriori \\(\\mu_p\\) rappresenta la stima aggiornata del parametro \\(\\mu\\) alla luce delle informazioni contenute nei dati osservati. La sua formula è:\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2} \\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}},\n\\]\ndove \\(\\bar{y}\\) rappresenta la media campionaria:\n\\[\n\\bar{y} = \\frac{\\sum_{i=1}^n y_i}{n}.\n\\]\nOsserviamo che \\(\\mu_p\\) è una combinazione ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\). Il peso di \\(\\bar{y}\\) aumenta con il numero di osservazioni \\(n\\), mentre il peso di \\(\\mu_0\\) diminuisce. Questo riflette il fatto che con più dati, la nostra fiducia nella media campionaria cresce, mentre l’incertezza a priori diminuisce.\n\n47.3.5 Formula per la Varianza a Posteriori (\\(\\sigma_p^2\\))\nLa varianza a posteriori \\(\\sigma_p^2\\) rappresenta l’incertezza residua sulla stima del parametro \\(\\mu\\) dopo aver incorporato le informazioni dai dati. La sua formula è:\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}.\n\\]\nRispetto alla varianza a priori \\(\\sigma_0^2\\), la varianza a posteriori \\(\\sigma_p^2\\) è sempre inferiore o uguale. In altre parole, l’incertezza sulla stima di \\(\\mu\\) si riduce con l’aumentare del numero di osservazioni. La varianza a posteriori rappresenta un bilanciamento tra l’incertezza a priori (\\(\\sigma_0^2\\)) e l’informazione derivata dai dati (\\(\\sigma^2/n\\)).\nIn sintesi, nel caso normale-normale con varianza nota, la distribuzione a posteriori risulta essere una distribuzione normale con una media e una varianza che riflettono un’integrazione bilanciata tra l’informazione a priori e quella ottenuta dai dati osservati. Questo approccio garantisce una stima aggiornata e affinata del parametro \\(\\mu\\) che migliora con l’aumento del numero di osservazioni.\n\nEsempio 47.1 I test standard di QI sono progettati per misurare l’intelligenza con una media di 100 e una deviazione standard di 15. Tuttavia, si dice anche che questi test presentino bias culturali che favoriscono alcuni gruppi rispetto ad altri. Un’ulteriore complicazione si verifica quando i punteggi di QI vengono aggregati a livello nazionale, poiché le caratteristiche interne ai paesi vengono mascherate. Questo esempio analizza i dati di QI raccolti a livello internazionale (Lynn e Vanhanen, 2001) per 80 paesi da fonti nazionali pubblicate e discussi da Gill (2015). L’idea chiave nella descrizione della distribuzione a posteriori è se le differenze tra le nazioni alterano la parametrizzazione prevista.\nI dati di Lynn e Vanhanen (2001) sono forniti di seguito:\n\n\n\n\n\n\n\n\n\n\n\n\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\n\n\n\nArgentina\n96\nAustralia\n98\nAustria\n102\nBarbados\n78\n\n\nBelgium\n100\nBrazil\n87\nBulgaria\n93\nCanada\n97\n\n\nChina\n100\nCongo (Br.)\n73\nCongo (Zr.)\n65\nCroatia\n90\n\n\nCuba\n85\nCzech Repub.\n97\nDenmark\n98\nEcuador\n80\n\n\nEgypt\n83\nEq. Guinea\n59\nEthiopia\n63\nFiji\n84\n\n\nFinland\n97\nFrance\n98\nGermany\n102\nGhana\n71\n\n\nGreece\n92\nGuatemala\n79\nGuinea\n66\nHong Kong\n107\n\n\nHungary\n99\nIndia\n81\nIndonesia\n89\nIran\n84\n\n\nIraq\n87\nIreland\n93\nIsrael\n94\nItaly\n102\n\n\nJamaica\n72\nJapan\n105\nKenya\n72\nKorea (S.)\n106\n\n\nLebanon\n86\nMalaysia\n92\nMarshall I.\n84\nMexico\n87\n\n\nMorocco\n85\nNepal\n78\nNetherlands\n102\nNew Zealand\n100\n\n\nNigeria\n67\nNorway\n98\nPeru\n90\nPhilippines\n86\n\n\nPoland\n99\nPortugal\n95\nPuerto Rico\n84\nQatar\n78\n\n\nRomania\n94\nRussia\n96\nSamoa\n87\nSierra Leone\n64\n\n\nSingapore\n103\nSlovakia\n96\nSlovenia\n95\nSouth Africa\n72\n\n\nSpain\n97\nSudan\n72\nSuriname\n89\nSweden\n101\n\n\nSwitzerland\n101\nTaiwan\n104\nTanzania\n72\nThailand\n91\n\n\nTonga\n87\nTurkey\n90\nUganda\n73\nU.K.\n100\n\n\nU.S.\n98\nUruguay\n96\nZambia\n77\nZimbabwe\n66\n\n\n\nImplementiamo le informazioni necessarie in Python.\n\n# Dati IQ delle 80 nazioni\niq &lt;- c(\n  96, 100, 100, 85, 83, 97, 92, 99, 87, 72, 86, 85, 67, 99, 94, 103, 97, 101, \n  87, 98, 87, 73, 97, 59, 98, 79, 81, 93, 105, 92, 78, 98, 95, 96, 72, 104, \n  90, 96, 98, 102, 78, 90, 63, 84, 84, 107, 86, 102, 106, 94, 102, 72, 101, \n  89, 72, 101, 91, 100, 100, 66, 107, 86, 78, 84, 78, 64, 72, 101, 91, 100, \n  67, 86\n)\n\n\n# Numero di osservazioni\nn &lt;- length(iq)\n\n# Media campionaria\ny_bar &lt;- mean(iq)\n\n# Deviazione standard nota\nsigma &lt;- 15\n\n# Parametri a priori\nmu_0 &lt;- 100\nsigma_0 &lt;- 15\n\nCalcoliamo la media a posteriori con la formula discussa in precedenza\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\ndove:\n\n\n\\(\\mu_0\\) è la media a priori\n\n\\(\\sigma_0\\) è la deviazione standard a priori\n\n\\(n\\) è il numero di osservazioni\n\n\\(\\sigma\\) è la deviazione standard delle osservazioni (nota)\n\n\\(\\bar{y}\\) è la media campionaria\n\n\nmu_p &lt;- ((1 / sigma_0^2) * mu_0 + (n / sigma^2) * y_bar) /\n  ((1 / sigma_0^2) + (n / sigma^2))\nprint(paste(\"Media a posteriori (mu_p):\", round(mu_p, 2)))\n#&gt; [1] \"Media a posteriori (mu_p): 89.36\"\n\nCalcoliamo la varianza a posteriori\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}}\n\\]\n\nsigma_p_sq &lt;- 1 / ((1 / sigma_0^2) + (n / sigma^2))\nsigma_p &lt;- sqrt(sigma_p_sq)\nprint(paste(\"Varianza a posteriori (sigma_p_sq):\", round(sigma_p_sq, 2)))\n#&gt; [1] \"Varianza a posteriori (sigma_p_sq): 3.08\"\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto mu_0 = 100 e sigma_0 = 15 per la distribuzione a priori.\n\n# Definizione dei valori sull'asse x\nx &lt;- seq(mu_p - 4 * sigma_p, mu_p + 4 * sigma_p, length.out = 1000)\n\n# Calcolo della densità di probabilità\npdf &lt;- dnorm(x, mean = mu_p, sd = sigma_p)\n\n# Creazione del grafico\nggplot(data.frame(x = x, pdf = pdf), aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\", linewidth = 1) +\n  geom_area(aes(fill = \"Posterior\"), alpha = 0.2) +\n  scale_fill_manual(values = c(\"blue\")) +\n  labs(\n    x = \"Media del Quoziente di Intelligenza\",\n    y = \"Densità di probabilità\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nL’analisi condotta mediante un modello bayesiano basato sulla distribuzione normale ha prodotto un risultato interessante: la media stimata della distribuzione a posteriori del QI si attesta a 89.36, un valore sensibilmente inferiore ai 100 punti previsti come media standard.\nTuttavia, per un’interpretazione completa di questo dato, è fondamentale adottare un approccio critico che consideri alcuni aspetti cruciali:\n\nLa media a posteriori è ottenuta aggregando i dati QI di 80 nazioni diverse. Questo processo può innescare un effetto di aggregazione, dove la media “smussata” risultante non rispecchia accuratamente la distribuzione del QI a livello individuale in ogni singola nazione. Di conseguenza, le differenze tra le nazioni in termini di QI medio e variabilità potrebbero essere mascherate da questa media aggregata.\nÈ importante sottolineare che la media a posteriori viene calcolata utilizzando dati non ponderati per ogni nazione. Ciò significa che nazioni con popolazioni più piccole, anche se con punteggi QI mediamente più alti o più bassi, hanno lo stesso impatto sulla media aggregata rispetto a nazioni con popolazioni più grandi. Questo aspetto potrebbe ulteriormente distorcere la rappresentazione della vera distribuzione globale del QI.\nLa deviazione osservata dalla media standard di 100 potrebbe non riflettere esclusivamente differenze nell’intelligenza media tra le nazioni, ma anche differenze nei contesti sanitari, sociologici e politici in cui i test sono stati somministrati. Fattori quali l’accesso all’istruzione, la qualità della nutrizione e l’esposizione a stimoli cognitivi possono influenzare i punteggi QI ottenuti e contribuire alla variabilità osservata tra le nazioni.\nInoltre, è fondamentale considerare la possibilità di un bias culturale intrinseco allo strumento stesso. I test del QI sono stati originariamente progettati per un contesto specifico (paese industrializzato di lingua inglese) e potrebbero non essere adatti o culturalmente sensibili a contesti differenti. Questo potrebbe portare a una sottostima dei punteggi QI in alcune nazioni e influenzare la media a posteriori aggregata.\n\nQuesti risultati evidenziano l’importanza di un’attenta considerazione dei fattori metodologici quando si interpretano dati di test del QI a livello trans-culturale. L’effetto di aggregazione, l’utilizzo di medie non ponderate, le differenze nei contesti e il potenziale bias culturale richiedono un’analisi più approfondita che consideri questi fattori e utilizzi metodi statistici più sofisticati per ottenere una comprensione più completa delle differenze nel QI tra le nazioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_2.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/07_conjugate_families_2.html#riflessioni-conclusive",
    "title": "47  Distribuzioni coniugate (2)",
    "section": "\n47.4 Riflessioni Conclusive",
    "text": "47.4 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito il meccanismo dell’aggiornamento bayesiano attraverso l’implementazione del modello normale-normale. Il processo inizia definendo una distribuzione a priori per \\(\\mu\\), specificata da una media \\(\\mu_0\\) e una varianza \\(\\sigma_0^2\\). Dopo l’acquisizione di nuovi dati, ipotizzando che seguano una distribuzione Normale con media campionaria \\(\\bar{y}\\) e varianza nota \\(\\sigma^2\\), implementiamo il teorema normale-normale per derivare la distribuzione a posteriori del parametro.\nLa media della distribuzione a posteriori, denotata come \\(\\mu_{\\text{post}}\\), si configura come una media ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\), dove il peso assegnato a ciascuna media è determinato dalle rispettive varianze \\(\\sigma_0^2\\) e \\(\\sigma^2\\) della distribuzione a priori e dei dati osservati. Analogamente, la varianza a posteriori \\(\\sigma_{\\text{post}}^2\\) è determinata utilizzando un’espressione che incorpora entrambe le varianze.\nIn sintesi, l’adozione del modello normale-normale in un contesto bayesiano facilita il calcolo delle distribuzioni a posteriori, grazie alla scelta di una distribuzione a priori Normale che mantiene la proprietà di coniugatezza, semplificando così l’intero processo analitico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/07_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "47  Distribuzioni coniugate (2)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.10.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        Rdpack_2.6.2      vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    pan_1.9          \n#&gt; [13] pacman_0.5.1      jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-2     \n#&gt; [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [21] mnormt_2.1.1      codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64       reformulas_0.4.0 \n#&gt; [29] iterators_1.0.14  rpart_4.1.24      boot_1.3-31       mitml_0.4-5      \n#&gt; [33] foreach_1.5.2     nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37    \n#&gt; [37] stringi_1.8.4     labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4  \n#&gt; [41] fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1  cli_3.6.4        \n#&gt; [45] magrittr_2.0.3    survival_3.8-3    broom_1.0.7       withr_3.0.2      \n#&gt; [49] backports_1.5.0   timechange_0.3.0  rmarkdown_2.29    nnet_7.3-20      \n#&gt; [53] lme4_1.1-36       hms_1.1.3         evaluate_1.0.3    rbibutils_2.3    \n#&gt; [57] rlang_1.1.5       Rcpp_1.0.14       glue_1.8.0        minqa_1.2.8      \n#&gt; [61] rstudioapi_0.17.1 jsonlite_1.8.9    R6_2.6.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_2.html#bibliografia",
    "href": "chapters/bayesian_inference/07_conjugate_families_2.html#bibliografia",
    "title": "47  Distribuzioni coniugate (2)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGill, J. (2015). Bayesian methods: A social and behavioral sciences approach (3rd Edition). Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_summary_posterior.html",
    "href": "chapters/bayesian_inference/08_summary_posterior.html",
    "title": "48  Sintesi a posteriori",
    "section": "",
    "text": "48.1 Introduzione\nIn questo capitolo, concentriamo la nostra attenzione sulla sintesi dell’informazione racchiusa nella distribuzione a posteriori, la quale rappresenta il nostro livello di incertezza riguardo al parametro o ai parametri incogniti oggetto dell’inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_summary_posterior.html#riepilogo-numerico",
    "href": "chapters/bayesian_inference/08_summary_posterior.html#riepilogo-numerico",
    "title": "48  Sintesi a posteriori",
    "section": "\n48.2 Riepilogo numerico",
    "text": "48.2 Riepilogo numerico\nLa distribuzione a posteriori contiene in sé tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico \\(p(\\theta \\mid y)\\).\nTuttavia, quando ci troviamo di fronte a vettori di parametri con più di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori:\n\nStima puntuale;\nIntervallo di credibilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_summary_posterior.html#stima-puntuale",
    "href": "chapters/bayesian_inference/08_summary_posterior.html#stima-puntuale",
    "title": "48  Sintesi a posteriori",
    "section": "\n48.3 Stima puntuale",
    "text": "48.3 Stima puntuale\nNel contesto dell’inferenza bayesiana, il processo di stima del valore più credibile del parametro \\(\\theta\\) tramite la distribuzione a posteriori si avvale di tre statistiche: la moda, la mediana e la media, la cui scelta è guidata dalla forma della distribuzione a posteriori. Queste statistiche sono utilizzate per ottenere una stima puntuale della tendenza centrale della distribuzione a posteriori, che a sua volta fornisce il “valore più credibile” del parametro. Questo valore rappresenta la stima a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sui dati osservati e sulle nostre credenze a priori.\n\n\nModa (Massimo a posteriori, MAP):\nLa moda rappresenta il valore più probabile di un parametro, ovvero quello che massimizza la distribuzione a posteriori. Questo valore è noto come “massimo a posteriori” (MAP). La stima MAP prende origine dalla stima di massima verosimiglianza (MLE), che cerca il valore di \\(\\theta\\), denotato come \\(\\hat{\\theta}_{ML}\\), che massimizza la funzione di verosimiglianza \\(L(\\theta \\mid y)\\):\n\n\n\\[\n\\hat{\\theta}_{ML} = \\arg \\max_\\theta L(\\theta \\mid y).\n\\]\nNell’inferenza bayesiana, \\(\\theta\\) è considerato una variabile casuale, e si specifica una distribuzione a priori su \\(\\theta\\) per riflettere l’incertezza sul suo valore. Integrando l’informazione a priori nella funzione di verosimiglianza, si ottiene la formula per la stima MAP:\n\\[\n\\hat{\\theta}_{MAP} = \\arg \\max_\\theta L(\\theta \\mid y)p(\\theta).\n\\]\nQuesta formula evidenzia che la stima MAP corrisponde al valore che massimizza la densità a posteriori di \\(\\theta\\) dati i dati osservati \\(y\\), ovvero il valore che rappresenta la moda della distribuzione a posteriori.\nSebbene il concetto di MAP sia intuitivo, presenta diversi problemi che ne limitano l’uso nella pratica.\nLa prima difficoltà è di tipo computazionale: con i metodi MCMC comunemente utilizzati per stimare le distribuzioni a posteriori, è molto difficile individuare con precisione la posizione esatta del MAP nello spazio delle distribuzioni posteriori.\nIl secondo problema è legato all’uso dell’inferenza bayesiana in modelli complessi e in situazioni non asintotiche. In questi casi, la verosimiglianza o la distribuzione a posteriori possono avere forme irregolari o non normali. Se la distribuzione a posteriori è molto asimmetrica, il MAP potrebbe non rappresentare adeguatamente dove si concentra la maggior parte della probabilità. Di conseguenza, il MAP non sempre fornisce un’idea accurata del comportamento complessivo della distribuzione a posteriori.\n\n\nMedia a posteriori:\n\nLa media a posteriori è il valore atteso del parametro \\(\\theta\\), calcolato sulla base della distribuzione a posteriori. In termini matematici, nel caso continuo, è espressa dalla formula:\n\\[\nE(\\theta \\mid y) = \\int_{-\\infty}^{\\infty} \\theta \\, p(\\theta \\mid y) \\, d\\theta.\n\\]\n\n\nMediana:\n\nLa mediana è il valore del parametro per cui il 50% della massa di probabilità a posteriori si distribuisce equamente a sinistra e a destra. È una misura robusta della tendenza centrale, particolarmente utile in presenza di distribuzioni asimmetriche o multimodali, dove la moda potrebbe non fornire una stima accurata del valore più probabile del parametro.\nPer valutare l’incertezza associata al parametro \\(\\theta\\), è utile calcolare la varianza a posteriori. Questa varianza è basata sulla tendenza centrale definita dalla media a posteriori, e la sua radice quadrata fornisce la deviazione standard a posteriori, che misura l’incertezza a posteriori relativa a \\(\\theta\\), espressa nelle stesse unità di misura dei dati. La formula per la varianza a posteriori è data da:\n\\[\nV(\\theta|y) = E[((\\theta - E[(\\theta|y)])^2 |y) = \\int_{-\\infty}^{\\infty} (\\theta - E[\\theta | y])^2 p(\\theta | y) d\\theta = E[\\theta^2 |y] - E[\\theta|y]^2.\n\\]\nIn sintesi, la media, la moda e la mediana a posteriori, insieme alla varianza a posteriori, forniscono una descrizione comprensiva del comportamento della distribuzione a posteriori di \\(\\theta\\), permettendoci di derivare stime puntuali e misurare l’incertezza associata a \\(\\theta\\) in modo informativo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_summary_posterior.html#intervallo-di-credibilità",
    "href": "chapters/bayesian_inference/08_summary_posterior.html#intervallo-di-credibilità",
    "title": "48  Sintesi a posteriori",
    "section": "\n48.4 Intervallo di credibilità",
    "text": "48.4 Intervallo di credibilità\nNell’inferenza bayesiana, l’intervallo di credibilità è uno strumento utilizzato per definire un intervallo che contiene una determinata percentuale della massa della distribuzione a posteriori del parametro \\(\\theta\\). Questo intervallo riflette l’incertezza associata alla stima del parametro: un intervallo più ampio suggerisce una maggiore incertezza. Lo scopo principale dell’intervallo di credibilità è fornire una misura quantitativa dell’incertezza riguardante \\(\\theta\\).\nA differenza degli intervalli di confidenza frequentisti, non esiste un unico intervallo di credibilità per un dato livello di confidenza \\((1 - \\alpha) \\cdot 100\\%\\). In effetti, è possibile costruire un numero infinito di tali intervalli. Per questo motivo, è necessario stabilire criteri aggiuntivi per selezionare l’intervallo di credibilità più appropriato. Tra le opzioni più comuni ci sono l’intervallo di credibilità simmetrico e l’intervallo di massima densità posteriore (HPD).\n\n\nIntervallo di Credibilità Simmetrico:\n\nQuesto tipo di intervallo è centrato rispetto al punto di stima puntuale. Se \\(\\hat{\\theta}\\) rappresenta la stima del parametro, l’intervallo simmetrico avrà la forma \\((\\hat{\\theta} - a, \\hat{\\theta} + a)\\), dove \\(a\\) è un valore positivo scelto in modo tale che la massa totale inclusa sia pari a \\((1 - \\alpha)\\). Più formalmente, un intervallo di credibilità simmetrico al livello \\(\\alpha\\) può essere espresso come:\n\\[\nI_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}],\n\\]\ndove \\(q_z\\) rappresenta il quantile \\(z\\) della distribuzione a posteriori. Ad esempio, un intervallo di credibilità simmetrico al 94% sarà:\n\\[\nI_{0.06} = [q_{0.03}, q_{0.97}],\n\\]\ndove il 3% della massa a posteriori si trova in ciascuna delle due code della distribuzione.\n\n\nIntervallo di Credibilità Più Stretto (Intervallo di Massima Densità Posteriore, HPD):\n\nL’intervallo di massima densità posteriore (HPD) è l’intervallo più stretto possibile che contiene il \\((1 - \\alpha) \\cdot 100\\%\\) della massa a posteriori. A differenza dell’intervallo simmetrico, l’HPD include tutti i valori di \\(\\theta\\) che hanno la maggiore densità a posteriori. Per costruirlo, si disegna una linea orizzontale sulla distribuzione a posteriori e si regola l’altezza della linea in modo che l’area sotto la curva corrisponda a \\((1 - \\alpha)\\). L’HPD risulta essere il più stretto tra tutti gli intervalli possibili per lo stesso livello di confidenza. Nel caso di una distribuzione a posteriori unimodale e simmetrica, l’HPD coincide con l’intervallo di credibilità simmetrico.\n\n48.4.1 Interpretazione\nIl calcolo degli intervalli di credibilità, in particolare dell’intervallo di massima densità posteriore (HPD), richiede spesso l’uso di software statistici avanzati. Questo perché determinare manualmente tali intervalli può essere complicato, soprattutto nei modelli bayesiani con distribuzioni posteriori complesse o quando sono necessarie simulazioni numeriche per stimare la distribuzione a posteriori.\nUn aspetto cruciale dell’inferenza bayesiana riguarda l’interpretazione dell’incertezza. Nel contesto frequentista, si considera il parametro, come ad esempio la media della popolazione \\(\\mu\\), come un valore fisso ma sconosciuto. L’inferenza frequentista si basa sull’immaginare un numero infinito di campioni ripetuti dalla popolazione. Per ogni campione, si può calcolare una media campionaria \\(\\bar{x}\\) e formare un intervallo di confidenza al \\(100(1-\\alpha)\\%\\). L’interpretazione corretta in termini frequentisti è che, nel lungo periodo, il \\(100(1-\\alpha)\\%\\) degli intervalli di confidenza costruiti con questo metodo conterrà il vero valore del parametro \\(\\mu\\). Tuttavia, per un singolo intervallo calcolato, la probabilità che contenga effettivamente \\(\\mu\\) è o 0 o 1, poiché \\(\\mu\\) è considerato un valore fisso.\nNel framework bayesiano, invece, il parametro è trattato come una variabile aleatoria con una distribuzione di probabilità. Campionando dalla distribuzione a posteriori dei parametri, possiamo ottenere quantili che ci permettono di calcolare direttamente la probabilità che un parametro rientri in un determinato intervallo. Ad esempio, un intervallo di credibilità al 95% indica che c’è una probabilità del 95% che il parametro sia contenuto all’interno di quell’intervallo, data l’evidenza osservata. Questa interpretazione differisce profondamente da quella frequentista e risulta più intuitiva, poiché riflette direttamente il grado di incertezza che abbiamo riguardo al parametro.\nIn sintesi, mentre l’intervallo di confidenza frequentista riguarda la ripetizione ipotetica del campionamento, l’intervallo di credibilità bayesiano fornisce una misura diretta dell’incertezza attuale sul valore di un parametro, basata sui dati osservati e sulle informazioni a priori. Questo approccio è spesso considerato più vicino al senso comune quando si tratta di interpretare la probabilità associata ai parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/bayesian_inference/08_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "48  Sintesi a posteriori",
    "section": "\n48.5 Verifica di ipotesi bayesiana",
    "text": "48.5 Verifica di ipotesi bayesiana\nL’inferenza bayesiana può essere applicata anche nel contesto della verifica di ipotesi, in un approccio noto come verifica di ipotesi bayesiana. In questo tipo di inferenza, l’obiettivo è valutare la plausibilità che un parametro \\(\\theta\\) assuma valori all’interno di un determinato intervallo. Ad esempio, possiamo voler sapere quanto è probabile che \\(\\theta\\) sia maggiore di 0.5 o che rientri in un intervallo specifico, come [0.5, 1.0].\nIn questo approccio, si calcola la probabilità a posteriori che \\(\\theta\\) si trovi all’interno dell’intervallo di interesse. Questa probabilità viene ottenuta integrando la distribuzione a posteriori su tale intervallo. Quindi, invece di rifiutare o accettare un’ipotesi come nel test di ipotesi frequentista, la verifica di ipotesi bayesiana fornisce una misura diretta della probabilità che un parametro rientri in un intervallo specifico, dato l’evidenza osservata e le informazioni a priori.\nIn altre parole, questo approccio consente di quantificare la nostra incertezza rispetto all’affermazione che \\(\\theta\\) rientri in un certo intervallo, fornendo una probabilità che rappresenta direttamente la plausibilità di quell’ipotesi.\n\nEsempio 48.1 Per illustrare l’approccio bayesiano, consideriamo i dati relativi ai punteggi del BDI-II (Beck Depression Inventory - Second Edition) di 30 soggetti clinici, come riportato nello studio condotto da Zetsche et al. (2019). Il BDI-II è uno strumento per valutare la gravità dei sintomi depressivi.\nI punteggi del BDI-II per i 30 soggetti sono:\n\n# Dati del BDI-II\nbdi &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\nbdi\n#&gt;  [1] 26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35\n#&gt; [25] 33 28 27 34 27 22\n\nUn punteggio BDI-II \\(\\geq 30\\) indica un livello grave di depressione. Nel nostro campione, 17 pazienti su 30 manifestano un livello grave:\n\n# Conteggio di depressione grave\nsum(bdi &gt;= 30)\n#&gt; [1] 17\n\nStima della distribuzione a posteriori.\nSupponiamo di voler stimare la probabilità \\(\\theta\\) di depressione grave nei pazienti clinici utilizzando una distribuzione a priori \\(Beta(8, 2)\\). I dati possono essere visti come una sequenza di prove Bernoulliane indipendenti, dove la presenza di depressione grave è un “successo”. La verosimiglianza è quindi binomiale con parametri \\(n = 30\\) e \\(y = 17\\).\nCon una distribuzione a priori \\(Beta(8, 2)\\), la distribuzione a posteriori di \\(\\theta\\) sarà:\n\\[\n\\text{Beta}(\\alpha = 8 + 17, \\beta = 2 + 30 - 17) = \\text{Beta}(25, 15).\n\\]\nTracciamo la distribuzione a posteriori.\n\n# Parametri della distribuzione Beta\nalpha &lt;- 25\nbeta &lt;- 15\n\n# Calcolo della densità per valori di theta\ntheta &lt;- seq(0, 1, length.out = 200)\nposterior_density &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione a posteriori\nggplot(data = data.frame(theta, posterior_density), aes(x = theta, y = posterior_density)) +\n  geom_line() +\n  labs(\n    title = \"Distribuzione a Posteriori Beta(25, 15)\",\n    x = expression(theta),\n    y = \"Densità di probabilità\"\n  ) \n\n\n\n\n\n\n\nStime puntuali.\n\n\nMedia a Posteriori\nLa media della distribuzione a posteriori è calcolata come:\n\n\\[\n\\mathbb{E}(\\theta | y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 15} = 0.625.\n\\]\nIn R:\n\n# Calcolo della media a posteriori\nposterior_mean &lt;- alpha / (alpha + beta)\nposterior_mean\n#&gt; [1] 0.625\n\n\n\nModa a Posteriori (MAP)\nLa moda della distribuzione a posteriori è:\n\n\\[\nMo(\\theta | y = 17) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2} = \\frac{25 - 1}{25 + 15 - 2} = 0.6316.\n\\]\nIn R:\n\n# Calcolo della moda a posteriori\nposterior_mode &lt;- (alpha - 1) / (alpha + beta - 2)\nposterior_mode\n#&gt; [1] 0.6316\n\n\n\nMediana a Posteriori\nLa mediana si ottiene utilizzando la funzione di distribuzione cumulativa inversa:\n\n\n# Calcolo della mediana a posteriori\nposterior_median &lt;- qbeta(0.5, alpha, beta)\nposterior_median\n#&gt; [1] 0.6271\n\nIntervallo di credibilità.\nL’intervallo di credibilità simmetrico al 94% è dato dai percentili 3% e 97%:\n\n# Intervallo di credibilità simmetrico al 94%\ncred_interval &lt;- qbeta(c(0.03, 0.97), alpha, beta)\ncred_interval\n#&gt; [1] 0.4781 0.7613\n\nPossiamo interpretare questo intervallo come segue: c’è una certezza soggettiva del 94% che \\(\\theta\\) sia compreso tra 0.478 e 0.761.\nVerifica di ipotesi bayesiana.\nInfine, calcoliamo la probabilità che \\(\\theta &gt; 0.5\\):\n\\[\nP(\\theta &gt; 0.5 | y = 17) = \\int_{0.5}^1 f(\\theta | y = 17) d\\theta.\n\\]\nIn R:\n\n# Probabilità P(theta &gt; 0.5)\nprob_theta_greater_0_5 &lt;- pbeta(0.5, alpha, beta, lower.tail = FALSE)\nprob_theta_greater_0_5\n#&gt; [1] 0.9459\n\nIn conclusione, utilizzando un approccio bayesiano, abbiamo stimato la distribuzione a posteriori di \\(\\theta\\), ottenuto stime puntuali e costruito intervalli di credibilità. Abbiamo inoltre calcolato la probabilità che \\(\\theta\\) superi una soglia specifica, mostrando la flessibilità e l’interpretabilità delle analisi bayesiane.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "href": "chapters/bayesian_inference/08_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "title": "48  Sintesi a posteriori",
    "section": "\n48.6 Sintesi della distribuzione a posteriori: questioni multivariate",
    "text": "48.6 Sintesi della distribuzione a posteriori: questioni multivariate\nQuando si affronta un’analisi bayesiana con più parametri, la complessità aumenta. Le principali difficoltà riguardano le interazioni tra i parametri e il modo in cui queste influenzano le distribuzioni marginali. Questi fattori possono complicare notevolmente la sintesi della distribuzione a posteriori e, se non considerati attentamente, possono portare a interpretazioni errate.\n\n48.6.1 Correlazioni nascoste e distribuzioni marginali\nUn problema comune nelle analisi con più parametri è rappresentato dalle correlazioni tra i parametri. Le distribuzioni marginali a posteriori, spesso riportate nei riassunti statistici, possono essere molto fuorvianti se considerate isolatamente. Quando i parametri sono fortemente correlati, le distribuzioni marginali possono apparire piatte o poco informative, inducendo a pensare che non ci sia molta informazione nella verosimiglianza.\nTuttavia, le correlazioni tra parametri possono restringere notevolmente lo spazio delle combinazioni plausibili, escludendo vaste aree dello spazio dei parametri. Questo significa che, nonostante le marginali possano sembrare non informative, l’analisi congiunta dei parametri può rivelare una struttura sottostante che riduce l’incertezza su specifiche combinazioni. Pertanto, è essenziale esaminare le correlazioni congiunte tra i parametri per ottenere una visione più completa dell’incertezza.\nCon un numero maggiore di parametri, anche i grafici di correlazione bidimensionali possono diventare limitati, poiché potrebbero esistere correlazioni di ordine superiore che non emergono in rappresentazioni a due dimensioni.\n\n48.6.2 Correlazioni non lineari\nUn’altra difficoltà significativa riguarda le correlazioni non lineari tra i parametri. Quando queste correlazioni sono presenti, il massimo delle distribuzioni marginali non coincide necessariamente con il massimo della distribuzione congiunta. Per esempio, se due parametri presentano una correlazione complessa, come una forma a “banana”, il massimo delle distribuzioni marginali potrebbe trovarsi in una posizione diversa rispetto al massimo globale della distribuzione congiunta.\nQuesto fenomeno rende più difficile sintetizzare correttamente la distribuzione a posteriori. In tali casi, la stima del massimo a posteriori (MAP) o altri riassunti, come gli intervalli di credibilità (CI) o gli intervalli di massima densità a posteriori (HPD), calcolati sulle marginali, potrebbero essere fuorvianti. Quando la distribuzione a posteriori è asimmetrica nello spazio multivariato, le distribuzioni marginali non catturano adeguatamente le relazioni tra i parametri. Questa è una fonte comune di confusione, poiché si tende a sottovalutare l’importanza della struttura multivariata nella distribuzione a posteriori.\n\n48.6.3 Strategie per affrontare queste sfide\n\n\nConfronto tra distribuzioni predittive:\n\nConfrontare la distribuzione predittiva a priori con quella a posteriori offre una visione più completa della riduzione dell’incertezza.\nQuesto approccio è particolarmente utile in presenza di parametri multipli e correlazioni complesse, poiché la distribuzione predittiva a posteriori incorpora le interazioni tra i parametri, fornendo una rappresentazione più accurata della plausibilità dei diversi valori parametrici.\n\n\n\nAnalisi congiunta:\n\nEsaminare le distribuzioni congiunte dei parametri, oltre alle distribuzioni marginali.\nUtilizzare grafici di dispersione bivariati o multivariati per visualizzare le relazioni tra i parametri.\nTecniche avanzate di visualizzazione, come i pair plots o le heatmap, possono essere utili per esplorare relazioni in spazi ad alta dimensionalità.\n\n\n\nMisure di dipendenza:\n\nUtilizzare misure di dipendenza non lineare, come la correlazione di Spearman o l’informazione mutua, che possono catturare relazioni complesse che le misure lineari tradizionali potrebbero non rilevare.\n\n\n\nAnalisi di sensibilità:\n\nCondurre un’analisi di sensibilità per valutare come i cambiamenti in un parametro influenzano gli altri parametri e le previsioni del modello. Questo permette di capire meglio le relazioni tra i parametri e il loro impatto sulle inferenze.\n\n\n\nTecniche di riduzione della dimensionalità:\n\nQuando ci sono molti parametri, l’uso di metodi come l’analisi delle componenti principali (PCA) può aiutare a identificare strutture latenti e ridurre la complessità del problema, facilitando l’interpretazione dei risultati.\n\n\n\nIn sintesi, l’analisi multivariata in un contesto bayesiano richiede particolare attenzione nella sintesi delle distribuzioni a posteriori. Le distribuzioni marginali possono fornire informazioni utili, ma spesso nascondono importanti correlazioni e strutture di dipendenza tra i parametri. Un’analisi completa dovrebbe combinare l’esame delle marginali con una valutazione attenta delle relazioni congiunte tra i parametri, utilizzando tecniche di visualizzazione e misure di dipendenza adeguate. Questo approccio integrato permette di comprendere più a fondo la distribuzione a posteriori e di trarre inferenze più robuste e accurate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_summary_posterior.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/08_summary_posterior.html#riflessioni-conclusive",
    "title": "48  Sintesi a posteriori",
    "section": "\n48.7 Riflessioni Conclusive",
    "text": "48.7 Riflessioni Conclusive\nIn conclusione, la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri sconosciuti. L’impiego delle statistiche descrittive e l’analisi degli intervalli di credibilità contribuiscono a tracciare un quadro completo della distribuzione a posteriori e delle nostre inferenze riguardo al parametro di interesse.\nLe stime puntuali, ottenute attraverso statistiche descrittive come media, mediana o moda a posteriori, offrono una singola valutazione numerica del parametro ignoto. Gli intervalli di credibilità forniscono un intervallo di valori all’interno del quale si ritiene, con un certo grado di probabilità soggettiva, che il parametro incognito possa rientrare. Questi intervalli quantificano l’incertezza associata al parametro e consentono di esprimere il livello di fiducia soggettiva riguardo ai possibili valori del parametro dopo l’analisi dei dati. Abbiamo inoltre esaminato il concetto di test di ipotesi bayesiano, il quale può essere condotto agevolmente calcolando l’area appropriata sotto la distribuzione a posteriori, in accordo con l’ipotesi in questione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/08_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "48  Sintesi a posteriori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.10.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        Rdpack_2.6.2      vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    pan_1.9          \n#&gt; [13] pacman_0.5.1      jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-2     \n#&gt; [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [21] mnormt_2.1.1      codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64       reformulas_0.4.0 \n#&gt; [29] iterators_1.0.14  rpart_4.1.24      boot_1.3-31       mitml_0.4-5      \n#&gt; [33] foreach_1.5.2     nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37    \n#&gt; [37] stringi_1.8.4     labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4  \n#&gt; [41] fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1  cli_3.6.4        \n#&gt; [45] magrittr_2.0.3    survival_3.8-3    broom_1.0.7       withr_3.0.2      \n#&gt; [49] backports_1.5.0   timechange_0.3.0  rmarkdown_2.29    nnet_7.3-20      \n#&gt; [53] lme4_1.1-36       hms_1.1.3         evaluate_1.0.3    rbibutils_2.3    \n#&gt; [57] rlang_1.1.5       Rcpp_1.0.14       glue_1.8.0        minqa_1.2.8      \n#&gt; [61] rstudioapi_0.17.1 jsonlite_1.8.9    R6_2.6.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_summary_posterior.html#bibliografia",
    "href": "chapters/bayesian_inference/08_summary_posterior.html#bibliografia",
    "title": "48  Sintesi a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "",
    "text": "49.1 Introduzione\nConsideriamo un semplice scenario medico: un paziente si presenta dal dottore con un mal di testa. Il medico, per formulare una diagnosi accurata, dovrà considerare diversi fattori. Possiamo immaginare due medici con approcci leggermente differenti:\nQuale dei due medici è in grado di fornire una diagnosi più precisa? La risposta risiede nel concetto di probabilità a priori (o semplicemente prior), ovvero le credenze che un individuo ha su un evento prima di osservare nuovi dati.\nNel contesto medico, la storia clinica del paziente rappresenta una preziosa fonte di informazioni a priori. Conoscere gli antecedenti sanitari di un individuo permette al medico di formulare ipotesi più plausibili sulla causa del mal di testa. In termini bayesiani, i priori agiscono come una sorta di “lente” attraverso cui vengono interpretati i nuovi dati (in questo caso, i risultati dei test).\nQuando prendiamo decisioni nella vita quotidiana, utilizziamo costantemente le nostre conoscenze pregresse per interpretare nuove informazioni. Ad esempio, se vediamo una persona che indossa un camice bianco in un ospedale, inferiamo che si tratti di un medico, basandoci sulla nostra esperienza e sulle associazioni mentali che abbiamo costruito nel tempo. Questo processo di inferenza è molto simile a quello che avviene nell’aggiornamento bayesiano.\nLa scelta dei priori ha un impatto fondamentale sulla qualità delle inferenze che possiamo trarre dai dati. Questo capitolo si focalizza sull’importanza e sulle implicazioni che derivano dalla scelta dei priori sul processo di aggiornamento bayesiano. Per illustrare questi concetti, esamineremo alcuni esempi discussi da Johnson et al. (2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html#introduzione",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html#introduzione",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "",
    "text": "Medico 1: Si basa principalmente sui risultati di test specifici, senza considerare una storia clinica pregressa del paziente.\n\nMedico 2: Oltre ai test, tiene conto della storia clinica del paziente, cercando di individuare eventuali fattori di rischio o condizioni preesistenti che potrebbero essere correlate al mal di testa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html#la-distribuzione-a-priori",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html#la-distribuzione-a-priori",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "\n49.2 La Distribuzione a Priori",
    "text": "49.2 La Distribuzione a Priori\nLa distribuzione a priori gioca un ruolo centrale nell’approccio bayesiano, poiché rappresenta le nostre conoscenze pregresse o le ipotesi sui parametri del modello prima di osservare i dati. Questo concetto è fondamentale perché permette di integrare le informazioni disponibili in precedenza con i dati osservati, fornendo così una stima più precisa e robusta dei parametri. Le distribuzioni a priori possono variare a seconda del grado di certezza che si attribuisce ai valori dei parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "\n49.3 Tipologie di Distribuzioni a Priori",
    "text": "49.3 Tipologie di Distribuzioni a Priori\nLa scelta della distribuzione a priori (nota come elicitazione della prior) è uno dei passaggi cruciali nell’analisi bayesiana ed è spesso vista come la fase più controversa, poiché è considerata “soggettiva”. Tuttavia, è importante sottolineare che la scelta della prior non è necessariamente soggettiva. A differenza dell’approccio frequentista, l’approccio bayesiano incoraggia la raccolta e l’integrazione di tutte le informazioni conosciute sul parametro in anticipo. Questo può essere fatto in modo oggettivo, basandosi su evidenze pregresse o raccomandazioni consolidate.\nEsistono tre principali categorie di distribuzioni a priori.\n\nDistribuzioni a Priori Non Informative. Le distribuzioni a priori non informative sono caratterizzate da una totale mancanza di conoscenza pregressa e assegnano la stessa credibilità a tutti i valori dei parametri. Un esempio comune di distribuzione a priori non informativa è la distribuzione uniforme, basata sul “Principio della Ragione Insufficiente” formulato da Laplace. Secondo questo principio, in assenza di evidenze rilevanti pregresse, tutte le possibili configurazioni dei parametri sono considerate equiprobabili.\n\nDistribuzioni a Priori Debolmente Informative. Le distribuzioni a priori debolmente informative consentendo di integrare una quantità limitata di informazioni pregresse nei modelli statistici. Queste distribuzioni sono progettate per riflettere le nostre assunzioni su quali possono essere i valori “ragionevoli” dei parametri del modello, tenendo conto delle incertezze presenti nell’analisi. L’uso di informazioni a priori debolmente informative può contribuire a migliorare la stabilità dell’analisi senza influenzare in modo significativo le conclusioni derivate da essa.\nLe distribuzioni a priori debolmente informative hanno la caratteristica di non “spostare” in modo significativo la distribuzione a posteriori in una direzione specifica. In altre parole, sono centrate su valori “neutri” dei parametri. Ad esempio, quando si trattano parametri che possono assumere valori positivi o negativi, la distribuzione a priori debolmente informativa potrebbe essere centrata sullo zero. Nel caso di parametri che rappresentano proporzioni, essa potrebbe essere centrata su 0.5.\nTuttavia, ciò che rende queste distribuzioni debolmente informative è la specifica definizione di un intervallo “plausibile” di valori dei parametri. Questo intervallo indica quali valori dei parametri sono considerati plausibili e quali sono invece considerati implausibili. Ad esempio, una distribuzione a priori debolmente informativa potrebbe suggerire che valori estremamente grandi o estremamente bassi dei parametri sono poco plausibili, concentrandosi su un intervallo più stretto di valori considerati ragionevoli.\nIn sintesi, le distribuzioni a priori debolmente informative sono utilizzate per incorporare informazioni pregresse limitate nei modelli bayesiani, contribuendo a stabilizzare le stime dei parametri senza influenzare in modo significativo le conclusioni derivate dai dati. Queste distribuzioni definiscono un intervallo plausibile di valori dei parametri, aiutando a guidare l’analisi verso soluzioni più verosimili senza imporre vincoli eccessivi sui risultati.\n\n\nDistribuzioni a Priori Informativa. Le conoscenze pregresse, acquisite attraverso ricerche precedenti, pareri esperti o una combinazione di entrambi, possono essere meticolosamente integrate nel processo di analisi mediante l’incorporazione nelle distribuzioni a priori. Queste distribuzioni sono comunemente conosciute come distribuzioni a priori informative. Esse rappresentano un mezzo per codificare in modo sistematico informazioni concrete e rilevanti che possono avere un notevole impatto sull’analisi statistica, fornendo una solida base di conoscenza su cui fondare l’inferenza bayesiana.\nLe distribuzioni a priori informative possono derivare da una vasta gamma di fonti, comprese ricerche pregresse, pareri di esperti nel campo e altre fonti affidabili. Questo approccio offre un metodo strutturato per integrare in modo coerente le conoscenze pregresse nel processo di analisi statistica. L’incorporazione di queste informazioni aggiuntive contribuisce notevolmente a migliorare la robustezza e l’accuratezza delle conclusioni derivate dai dati, fornendo una solida base empirica su cui basare le stime dei parametri del modello e le decisioni basate sull’analisi bayesiana.\nNell’ambito della ricerca psicologica, l’utilizzo di distribuzioni a priori informative è attualmente poco diffuso, tuttavia emergono segnali che all’interno della comunità statistica sta crescendo l’interesse per questa pratica, considerandola come un avanzamento promettente nel campo della data science.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "\n49.4 L’importanza della Prior in base ai Dati",
    "text": "49.4 L’importanza della Prior in base ai Dati\nUn aspetto cruciale da considerare è che l’influenza della prior diminuisce all’aumentare del numero di dati osservati. In altre parole, con un numero infinito di dati, la verosimiglianza diventa estremamente precisa (o “affilata”), rendendo la scelta della prior irrilevante, a patto che la prior non assegni probabilità zero a regioni dello spazio parametri dove la verosimiglianza è positiva.\nTuttavia, la prior assume un’importanza fondamentale quando si lavora con dataset di piccole dimensioni. In questi casi, la distribuzione a priori può avere un’influenza significativa sulle stime, poiché i dati da soli non sono sufficienti per ottenere stime precise.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "\n49.5 Effetti del Cambiamento di Scala dei Parametri",
    "text": "49.5 Effetti del Cambiamento di Scala dei Parametri\nUn altro aspetto da tenere a mente è che le priors possono cambiare quando si modificano le scale dei parametri. Se un parametro viene riscalato, ad esempio passando da metri a chilometri, anche la prior deve essere riscalata di conseguenza per mantenere la coerenza dell’inferenza.\n\n49.5.1 Scala e invariabilità della scelta delle distribuzioni a priori\nLa scelta delle distribuzioni a priori non informative non è sempre banale e non può sempre essere rappresentata da una prior piatta. Per capire questo concetto, è fondamentale comprendere il ruolo della scala. Vediamo un esempio per chiarire meglio questo aspetto.\nImmaginiamo di avere un dataset che contiene la media dei diametri di alcuni alberi, e vogliamo stimare la media di questi diametri utilizzando un metodo bayesiano. Prima di osservare i dati, dobbiamo specificare la nostra distribuzione a priori, poiché non vogliamo che i dati influenzino la nostra scelta. Supponiamo di scegliere una distribuzione a priori piatta tra 1 cm e 10 cm, per evitare di introdurre bias:\n\n# Creazione di un vettore da 1 a 5\nvalori &lt;- 1:5\n# Creazione di un vettore di 5 elementi, tutti uguali a 1/5\npesoPrior &lt;- rep(1/5, 5)\n# Mostra i risultati\npesoPrior\n#&gt; [1] 0.2 0.2 0.2 0.2 0.2\n\nIn questo caso, stiamo assegnando la stessa probabilità a ciascun diametro compreso tra 1 e 10 cm, senza dare più peso a un valore rispetto a un altro. Questa sembra una scelta ragionevole e “non informativa”, poiché non stiamo preferendo nessun diametro in particolare.\nOra, supponiamo di voler modificare leggermente la nostra analisi e di misurare la grandezza degli alberi in termini di area basale (cioè la sezione trasversale dell’albero alla base), che è proporzionale al quadrato del diametro (cioè \\(x^2\\)). Poiché abbiamo già specificato la nostra distribuzione a priori in termini di diametro, dovremmo trasformare questa distribuzione in modo coerente con la nuova scala (area basale).\nIl problema che emerge è il seguente: quando riscaliamo l’asse \\(x\\) per riflettere l’area basale (cioè, passiamo da cm a cm\\(^2\\)), i valori più grandi diventano più ampi (poiché l’area cresce con il quadrato del diametro), mentre i valori più piccoli diventano più stretti. Se vogliamo mantenere la stessa distribuzione a priori in termini di probabilità, dobbiamo modificare il peso di ciascun valore.\nDi conseguenza, una distribuzione a priori che inizialmente era piatta (uguale per tutti i valori di diametro) non rimane piatta dopo la trasformazione in area basale. I valori più grandi ora hanno un peso minore, mentre i valori più piccoli hanno un peso maggiore. Questo dimostra che una distribuzione a priori non può essere piatta per tutte le possibili trasformazioni dei parametri.\n\n49.5.2 Il concetto di invariabilità della scala\nUna delle chiavi per definire correttamente le distribuzioni a priori non informative è l’invariabilità rispetto alle trasformazioni dei parametri. Se possiamo scegliere liberamente come rappresentare i parametri (ad esempio, in termini di diametro o area basale), la nostra distribuzione a priori dovrebbe essere definita in modo che sia coerente indipendentemente dalla scala scelta.\n\n49.5.3 Attenzione alle trasformazioni dei parametri\nUn secondo messaggio importante riguarda la cautela nelle trasformazioni dei parametri nell’analisi bayesiana. Quando cambiamo i parametri del nostro modello, non stiamo semplicemente osservando un singolo valore, ma una distribuzione intera. La forma di questa distribuzione può cambiare notevolmente con la trasformazione dei parametri.\nAd esempio, se si sta conducendo uno studio psicologico e si vuole misurare un parametro legato alla gravità di un disturbo (ad esempio, la gravità della depressione su una scala numerica), e poi si decide di trasformare la scala in un’unità diversa (ad esempio, un punteggio quadratico per evidenziare differenze estreme), la distribuzione a priori che sembrava ragionevole prima della trasformazione potrebbe non esserlo più dopo. Questo significa che bisogna prestare attenzione a come si scelgono le priors e come queste si comportano sotto diverse rappresentazioni del problema.\nIn conclusione, la scelta delle distribuzioni a priori non può essere fatta superficialmente. Deve essere considerata con attenzione, tenendo conto delle possibili trasformazioni dei parametri e assicurandosi che le priors siano coerenti rispetto alla scala scelta. Questo rende evidente che le priors non informative non sono sempre piatte, e la loro scelta deve tenere conto della struttura del problema e delle variabili coinvolte.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "\n49.6 Scelte predefinite per le distribuzioni a priori non informative",
    "text": "49.6 Scelte predefinite per le distribuzioni a priori non informative\nUna delle domande più ricorrenti nell’inferenza bayesiana riguarda la scelta delle distribuzioni a priori non informative. La risposta, però, è piuttosto complessa: non esiste una soluzione generalmente accettata. Questo è particolarmente importante perché, mentre le priors informative possono essere basate su conoscenze pregresse, una prior non informativa deve essere scelta con cura per evitare di influenzare eccessivamente i risultati.\nUna delle proposte più famose, che soddisfa molte delle proprietà desiderabili, è la prior di Jeffreys, definita come:\n\\[\np(\\phi) \\propto \\sqrt{ \\det (F(\\phi)) },\n\\]\ndove \\(F(\\phi)\\) è la matrice di informazione di Fisher, che misura quanto la verosimiglianza cambia quando variano i parametri. La prior di Jeffreys ha due caratteristiche fondamentali:\n\n\nInvarianza rispetto alla riscalatura dei parametri: Ciò significa che se trasformiamo la scala del parametro, la prior si adatta automaticamente, rimanendo coerente con il problema.\n\nProporzionalità all’influenza dei parametri sulla verosimiglianza: Parametri che influenzano maggiormente la verosimiglianza hanno una prior più informativa.\n\nQuesti aspetti sembrano coprire molti dei criteri comunemente accettati per la scelta delle distribuzioni a priori non informative. Tuttavia, la prior di Jeffreys presenta alcuni problemi nei modelli multivariati e gerarchici, il che limita la sua applicabilità come soluzione universale.\n\n49.6.1 Scelte predefinite comuni per le priors non informative\nNonostante le difficoltà legate alla prior di Jeffreys, sono emerse alcune scelte predefinite comuni per le priors non informative, basate su intuizioni derivanti proprio da questa distribuzione. Di seguito sono elencate alcune di queste scelte:\n\n\nParametri di scala (es. coefficiente angolare o intercetta in una regressione):\n\nPer i parametri di scala, che influenzano l’output in modo lineare, si utilizzano comunemente priors piatte o quasi piatte. Queste possono essere distribuzioni uniformi con limiti fissati o, più comunemente, una distribuzione normale ampia.\nUn esempio di prior modificata è l’uso di una normalità centrata su un valore neutro, come 0, per ottenere l’analogo bayesiano della regressione Lasso o Ridge, che introduce una penalizzazione sui parametri (Park & Casella, 2008; Kyung et al., 2010).\n\nSe questa penalizzazione è lieve, si parla di priors debolmente regolarizzanti.\nSe è forte, si parla di priors di riduzione (shrinkage), che possono essere fisse o adattative:\n\n\nShrinkage fisso: la forza della riduzione (ad es. controllata dalla deviazione standard nella prior normale) rimane costante.\n\nShrinkage adattativo: la prior di riduzione si adatta tramite un iperparametro (hyperprior), il che consente al modello di decidere autonomamente la forza della riduzione.\n\n\n\n\n\n\n\nParametri di varianza (es. la deviazione standard in una regressione lineare):\n\nPer i parametri di varianza, si utilizzano spesso priors che decrescono all’aumentare del valore. Un esempio classico è la prior di Jeffrey’s, che per la varianza assume la forma \\(1/x\\), oppure la distribuzione inversa-gamma, molto comune per via della sua proprietà di coniugazione, che semplifica il calcolo bayesiano.\n\n\n\nIperparametri di varianza nei modelli gerarchici:\n\nNei modelli gerarchici, gli iperparametri di varianza vengono trattati con priors decrescenti come l’inversa-gamma o la distribuzione half-t (Gelman, 2006). Queste priors sono progettate per gestire la varianza tra gruppi in modo efficace.\n\n\n\nDistribuzioni binomiali:\n\nPer una distribuzione binomiale, la prior di Jeffreys corrisponde a una distribuzione Beta(1/2, 1/2), che è considerata una buona scelta predefinita non informativa. Questo tipo di prior assegna un peso equo alle possibili probabilità di successo, riflettendo una distribuzione equilibrata senza favorire un particolare risultato.\n\n\n\n49.6.2 Attenzione alle trasformazioni dei parametri\nUn aspetto importante da considerare nell’uso delle priors non informative è che la loro forma può cambiare significativamente in seguito a trasformazioni dei parametri. Per esempio, passando dalla scala lineare alla scala quadratica di un parametro, la prior può assumere una forma diversa e introdurre involontariamente un bias. Pertanto, è essenziale prestare attenzione a come i parametri sono scalati e trasformati nel modello.\n\n49.6.3 Analisi di sensibilità\nInfine, quando si è incerti sulla scelta della prior, un buon approccio consiste nel condurre un’analisi di sensibilità. Questa tecnica prevede di variare la prior e osservare come ciò influenzi i risultati. Se i risultati sono robusti rispetto a diverse scelte di prior, ciò suggerisce che la prior scelta non sta influenzando in modo eccessivo l’inferenza finale. Questo è particolarmente utile nei casi in cui si dispone di pochi dati, situazione in cui la prior può avere un impatto maggiore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html#priori-coniugate",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html#priori-coniugate",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "\n49.7 Priori coniugate",
    "text": "49.7 Priori coniugate\nUna distribuzione a priori è detta coniugata rispetto a una funzione di verosimiglianza se la distribuzione a posteriori risultante ha la stessa forma funzionale della distribuzione a priori. In altre parole, la distribuzione a priori e quella a posteriori appartengono alla stessa famiglia di distribuzioni. Questo è particolarmente utile perché, quando si usano priori coniugate, si ottiene una distribuzione a posteriori che può essere espressa in forma chiusa, rendendo possibile risolverla analiticamente.\nUn esempio tipico è quello delle funzioni di verosimiglianza appartenenti alla famiglia esponenziale, per le quali esiste sempre una distribuzione a priori coniugata. Questo è uno dei motivi per cui le distribuzioni della famiglia esponenziale sono così rilevanti: in modelli semplici, l’uso di una prior coniugata consente di ottenere una soluzione analitica per la distribuzione a posteriori, noto come modello coniugato-esponenziale.\nTradizionalmente, si preferiva specificare priori coniugate quando possibile, proprio per la semplicità analitica che garantivano. Tuttavia, l’importanza delle priors coniugate è diminuita con l’evoluzione dei metodi di campionamento. Oggi, la maggior parte dei campionatori moderni (come i metodi MCMC) non richiede più la coniugazione per funzionare in modo efficiente, e l’uso di priors non coniugate è diventato comune senza compromettere la qualità delle stime.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html#simulazioni",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html#simulazioni",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "\n49.8 Simulazioni",
    "text": "49.8 Simulazioni\nIn questa sezione, esploriamo come le distribuzioni a priori influenzano la distribuzione a posteriori attraverso una serie di simulazioni. La formula di Bayes, \\(p(\\theta \\mid y) \\propto p(\\theta) \\times p(y \\mid \\theta)\\), evidenzia come la distribuzione a posteriori sia il risultato della combinazione tra la distribuzione a priori e la funzione di verosimiglianza basata sui dati osservati. Se abbiamo le valutazioni puntuali della verosimiglianza e della distribuzione a priori, possiamo moltiplicarle punto per punto per ottenere la distribuzione a posteriori.\n\n49.8.1 Verosimiglianza Binomiale con Distribuzioni a Priori Arbitrari\nConsideriamo un caso in cui la verosimiglianza è binomiale, ma utilizziamo distribuzioni a priori non coniugate. Supponiamo che i dati consistano in 6 successi su 9 prove di tipo bernoulliano. Confronteremo l’effetto di tre distribuzioni a priori diverse sulla distribuzione a posteriori e analizzeremo come ciascuna influisce sull’inferenza finale.\n\n49.8.1.1 Creazione della Griglia e Calcolo della Verosimiglianza\nIniziamo definendo una griglia di valori per \\(\\theta\\) e calcolando la verosimiglianza a ciascun punto della griglia.\n\n# Dati\nsuccess &lt;- 6\ntosses &lt;- 9\n\n# Griglia di valori per theta\ngrid_points &lt;- 100\np_grid &lt;- seq(0, 1, length.out = grid_points)\n\n# Verosimiglianza binomiale\nlikelihood &lt;- dbinom(success, tosses, p_grid)\n\n\n49.8.1.2 Funzione per Calcolare e Visualizzare la Posteriori\nDefiniamo una funzione che calcola la distribuzione a posteriori in base alla verosimiglianza e al priore fornito. La funzione visualizza anche il priore, la verosimiglianza e la distribuzione a posteriori.\n\ncomputePosterior &lt;- function(likelihood, prior, p_grid) {\n  # Calcolo della distribuzione a posteriori non normalizzata\n  unstd_posterior &lt;- likelihood * prior\n  \n  # Normalizzazione\n  posterior &lt;- unstd_posterior / sum(unstd_posterior)\n  \n  # Creazione del dataframe per il plotting\n  data &lt;- tibble(\n    theta = p_grid,\n    Prior = prior,\n    Likelihood = likelihood,\n    Posterior = posterior\n  ) |&gt; \n    pivot_longer(cols = c(Prior, Likelihood, Posterior), \n                 names_to = \"distribution\", \n                 values_to = \"density\")\n  \n  # Grafico con ggplot2\n  p &lt;- ggplot(data, aes(x = theta, y = density, color = distribution)) +\n    geom_line(size = 1.2) +\n    scale_color_manual(\n      values = MetBrewer::met.brewer(\"Hiroshige\", 10)[1:3], \n      # Usa i primi 3 colori della palette\n      labels = c(\"Prior\", \"Likelihood\", \"Posterior\")\n    ) +\n    facet_wrap(~distribution, scales = \"free_y\", ncol = 3) +\n    labs(\n      title = \"Distribuzioni: Prior, Likelihood, e Posterior\",\n      x = expression(theta),\n      y = \"Densità\"\n    ) +\n    theme(\n      plot.title = element_text(hjust = 0.5),\n      legend.position = \"none\",\n      strip.text = element_text(size = 12, face = \"bold\")\n    )\n  \n  # Restituzione della distribuzione a posteriori\n  print(p)\n  return(posterior)\n}\n\n\n49.8.2 Priore Uniforme\nIl nostro primo priore è una distribuzione uniforme: \\(p(\\theta) = 1\\). Questo riflette una completa mancanza di informazioni a priori sulla probabilità di successo \\(\\theta\\).\n\n# Priore uniforme\nprior1 &lt;- rep(1, grid_points)\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior1 &lt;- computePosterior(likelihood, prior1, p_grid)\n\n\n\n\n\n\n\nCome previsto, la distribuzione a posteriori coincide con la verosimiglianza (a parte un fattore di scala), poiché non abbiamo aggiunto informazioni.\n\n49.8.3 Priore a Gradino\nIl secondo priore è una funzione a gradino che riflette la convinzione che \\(\\theta\\) sia almeno \\(0.5\\). Questo priore esprime la credenza che il successo (“testa”) sia più probabile, ma non specifica di quanto.\n\n# Priore a gradino\nprior2 &lt;- ifelse(p_grid &gt;= 0.5, 1, 0)\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior2 &lt;- computePosterior(likelihood, prior2, p_grid)\n\n\n\n\n\n\n\nLa distribuzione a posteriori risultante esclude completamente i valori di \\(\\theta\\) inferiori a 0.5, coerentemente con le ipotesi del priore.\n\n49.8.4 Priore Esponenziale\nIl terzo priore è una distribuzione centrata su 0.5, con un rapido decadimento esponenziale su entrambi i lati. Questo priore riflette la convinzione che \\(\\theta\\) sia vicina a 0.5.\n\n# Priore esponenziale\nprior3 &lt;- exp(-5 * abs(p_grid - 0.5))\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior3 &lt;- computePosterior(likelihood, prior3, p_grid)\n\n\n\n\n\n\n\nQuesto priore “attrare” la distribuzione a posteriori verso 0.5, a meno che i dati non forniscano evidenze contrarie molto forti.\n\n49.8.5 Analisi del Modello Beta-Binomiale\nConsideriamo ora il caso coniugato, in cui il priore è una distribuzione Beta e i dati seguono una distribuzione Binomiale.\nDefiniamo una funzione per visualizzare le distribuzioni del modello Beta-Binomiale: priore, verosimiglianza e posteriore.\n\nplot_beta_binomial &lt;- function(alpha, beta, y = NULL, n = NULL) {\n  # Griglia di valori per theta\n  theta &lt;- seq(0, 1, length.out = 100)\n  \n  # Priore\n  prior_density &lt;- dbeta(theta, alpha, beta)\n  \n  # Verosimiglianza e posterior\n  if (!is.null(y) && !is.null(n)) {\n    likelihood &lt;- dbinom(y, n, theta)\n    scaled_likelihood &lt;- likelihood / max(likelihood)\n    posterior_alpha &lt;- alpha + y\n    posterior_beta &lt;- beta + n - y\n    posterior_density &lt;- dbeta(theta, posterior_alpha, posterior_beta)\n  }\n  \n  # Creazione del dataframe\n  data &lt;- tibble(\n    theta = theta,\n    prior = prior_density,\n    likelihood = if (!is.null(y) && !is.null(n)) scaled_likelihood else NA,\n    posterior = if (!is.null(y) && !is.null(n)) posterior_density else NA\n  ) |&gt; \n    pivot_longer(cols = c(prior, likelihood, posterior), \n                 names_to = \"distribution\", \n                 values_to = \"density\")\n  \n  # Filtra i valori validi\n  data &lt;- data |&gt; filter(!is.na(density))\n  \n  # Grafico con ggplot2\n  ggplot(data, aes(x = theta, y = density, color = distribution)) +\n    geom_line(size = 1.2) +\n    scale_color_manual(\n      values = MetBrewer::met.brewer(\"Hiroshige\", 10)[c(1, 2, 3)], \n      # Usa la palette di MetBrewer\n      labels = c(\"Prior\", \"Likelihood (scaled)\", \"Posterior\")\n    ) +\n    labs(\n      title = \"Beta-Binomial Model\",\n      x = expression(theta),\n      y = \"Density\",\n      color = \"Distribution\"\n    ) +\n    theme(\n      plot.title = element_text(hjust = 0.5), # Centra il titolo\n      legend.position = \"bottom\",            # Posiziona la legenda in basso\n      legend.title = element_text(size = 12)\n    )\n}\n\n\n49.8.5.1 Priore Uniforme\n\nplot_beta_binomial(alpha = 1, beta = 1, y = 15, n = 20)\n\n\n\n\n\n\n\n\n49.8.5.2 Priore Informativo (Beta(2, 2))\n\nplot_beta_binomial(alpha = 2, beta = 2, y = 15, n = 20)\n\n\n\n\n\n\n\n\n49.8.5.3 Priore Fortemente Informativo (Beta(2, 5))\n\nplot_beta_binomial(alpha = 2, beta = 5, y = 15, n = 20)\n\n\n\n\n\n\n\nIn conclusione, abbiamo esplorato come i priori influenzano la distribuzione a posteriori in contesti binomiali, dimostrando che l’influenza del priore è maggiore nei campioni piccoli e diminuisce con campioni di grandi dimensioni. L’analisi bayesiana consente un’integrazione flessibile delle conoscenze pregresse con i dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "\n49.9 Connessione tra Intuizioni e Teoria",
    "text": "49.9 Connessione tra Intuizioni e Teoria\nL’equilibrio tra la distribuzione a priori e le evidenze provenienti dai dati, come dimostrato negli esempi precedenti, non solo rispecchia le nostre intuizioni, ma rappresenta anche una necessità matematica. Questo concetto diventa chiaro esaminando la formula del valore atteso della distribuzione a posteriori nel contesto del caso beta-binomiale, che può essere riscritta come segue:\n\\[\n\\begin{align}\n\\mathbb{E}_{\\text{post}} &[\\text{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\\n&= \\frac{a+b}{a+b+n} \\cdot \\frac{a}{a+b} + \\frac{n}{a+b+n} \\cdot \\frac{y}{n}.\n\\end{align}\n\\]\nL’equazione precedente rivela che il valore atteso a posteriori si ottiene come una media ponderata tra il valore atteso a priori \\(\\left( \\frac{\\alpha}{\\alpha+\\beta}\\right)\\) e la proporzione osservata dei successi \\(\\left(\\frac{y}{n}\\right)\\). I pesi sono dati da \\(\\left( \\frac{\\alpha+\\beta}{\\alpha+\\beta+n}\\right)\\) e \\(\\left( \\frac{n}{\\alpha+\\beta+n}\\right)\\). Pertanto, quando il numero di osservazioni \\(n\\) è significativo rispetto alla somma dei parametri \\(\\alpha + \\beta\\), la distribuzione a posteriori sarà principalmente influenzata dai dati osservati e in minor misura dalle credenze a priori. Al contrario, se \\(n\\) è piccolo rispetto a \\(\\alpha + \\beta\\), i dati avranno un peso inferiore rispetto alle credenze a priori.\nQueste considerazioni indicano come scegliere i parametri \\(\\alpha\\) e \\(\\beta\\): se desideriamo rappresentare una totale ignoranza sul fenomeno, una scelta coerente è \\(\\alpha = \\beta = 1\\) (attribuiamo uguale credibilità a ogni valore di \\(\\theta\\)). Se, invece, possediamo forti credenze a priori, possiamo selezionare \\(\\alpha\\) in modo da eguagliare il valore atteso a priori, mentre \\(\\alpha + \\beta\\) rifletterà l’importanza attribuita all’informazione a priori: maggiore è il valore di \\(\\alpha + \\beta\\), maggiore sarà il numero di dati necessari per influenzare significativamente la distribuzione a posteriori rispetto a quella a priori. In situazioni in cui \\(n\\) è considerevolmente grande, la distribuzione a posteriori avrà un impatto ridotto sulla distribuzione a priori, a meno che non si facciano scelte estreme per i parametri a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "\n49.10 Conflitto tra Prior e Verosimiglianza",
    "text": "49.10 Conflitto tra Prior e Verosimiglianza\nEsaminiamo ora un altro esempio proposto da McElreath:\n\nLesson: Don’t trust intuition, for even simple prior+likelihood scenarios defy it. Four examples below, each producing radically different posteriors. Can you guess what each does?\n\n\nNella figura successiva vediamo la risposta alla domanda precedente.\n\nMcElreath descrive le caratteristiche di quattro diversi modelli in cui si combinano distribuzioni normali (Gaussiane) e Student-t (con 2 gradi di libertà) per il prior e la likelihood. La distribuzione gaussiana ha code molto sottili, mentre quella di Student-t ha code più spesse.\n\n\nIn Alto a Sinistra: Prior Normale, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Normal(10,1)\n\nIn questo scenario classico di aggiornamento bayesiano, il posterior risulta essere un compromesso tra il prior e la likelihood. La distribuzione normale, con le sue code sottili, contribuisce a un aggiornamento più “prevedibile” e concentrato attorno al valore medio.\n\n\nIn Alto a Destra: Prior Student, Likelihood Student (df=2)\n\ny ~ Student(2,mu,1)\nmu ~ Student(2,10,1)\n\nIn questo caso, entrambe le distribuzioni hanno code più spesse. La presenza di “extra massa” nelle code significa che ciascuna distribuzione trova il modo dell’altra più plausibile, portando a una media che non rappresenta il miglior “compromesso”. Questo scenario risulta in una maggiore incertezza e un posterior meno definito.\n\n\nIn Basso a Sinistra: Prior Student, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Student(2,10,1)\n\nQui, la likelihood normale, con le sue code sottili, tende a dominare. Essa è molto scettica nei confronti del prior con code spesse, ma il prior di Student-t non è sorpreso dalla likelihood. Questo porta a un posterior che è più influenzato dalla likelihood normale.\n\n\nIn Basso a Destra: Prior Normale, Likelihood Student\n\ny ~ Student(2,mu,1)\nmu ~ Normal(10,1)\n\nIn questo ultimo scenario, è il prior normale a dominare. Il ragionamento è simile a quello del caso precedente, ma in senso inverso. Il prior normale, con le sue code sottili, impone una maggiore influenza sul posterior, rendendolo meno influenzato dalle code più spesse della likelihood di Student-t.\n\n\nIn sintesi, la combinazione di queste due distribuzioni in diversi modi porta a risultati di aggiornamento bayesiano molto differenti, a seconda di quale tra prior e likelihood abbia le code più spesse e quindi eserciti una maggiore influenza sul posterior.\nIn conclusione, questo esercizio mostra come, ad eccezione del caso gaussiano, i risultati non sono affatto intuitivi. Pertanto, in contesti come questi, affidarsi esclusivamente alle proprie intuizioni non è una scelta consigliabile. È invece fondamentale procedere con l’esecuzione dei calcoli.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html#riflessioni-conclusive",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "\n49.11 Riflessioni Conclusive",
    "text": "49.11 Riflessioni Conclusive\nLa scelta della distribuzione a priori è uno degli aspetti più cruciali nell’inferenza bayesiana. Da un lato, le priors non informative possono essere utilizzate per minimizzare l’influenza delle conoscenze pregresse, permettendo ai dati osservati di guidare l’inferenza. Dall’altro, le priors informative sono estremamente utili quando si dispone di informazioni affidabili sui parametri, consentendo una stima più precisa. È importante ricordare che, con un gran numero di dati, l’influenza della prior tende a ridursi, mentre nei contesti con pochi dati la scelta della prior può avere un impatto significativo.\nUn aspetto essenziale dell’approccio bayesiano, come evidenziato nell’esempio di Johnson (2022), è che il processo di aggiornamento bayesiano riflette il modo in cui le persone ragionano intuitivamente: di fronte a evidenze deboli, le credenze rimangono stabili, mentre nuove informazioni robuste portano a un aggiornamento significativo delle credenze. Questo meccanismo formalizza in modo quantitativo e rigoroso le intuizioni che utilizziamo quotidianamente. Al contrario, l’approccio frequentista ignora le conoscenze pregresse, il che può portare a cambiamenti nelle inferenze senza tener conto delle credenze già esistenti.\nTuttavia, come evidenziato dagli esempi di McElreath, la situazione può essere più complessa nei modelli non coniugati, dove l’intuizione può fallire nel prevedere correttamente la distribuzione a posteriori. Questo ci ricorda che il contesto e la struttura del modello giocano un ruolo determinante nell’inferenza bayesiana.\n\n49.11.1 Il Ruolo della Prior nella Regolarizzazione\nNel contesto bayesiano, le distribuzioni a priori debolmente informative fungono da meccanismo di regolarizzazione, limitando l’influenza delle osservazioni estreme e garantendo inferenze più stabili. Questo approccio è ormai ampiamente accettato nella comunità statistica, poiché permette di ottenere risultati più prudenti senza introdurre un forte bias.\n\n49.11.2 L’Importanza dei Prior Informativi\nNegli ultimi anni, l’uso di priori informativi ha guadagnato maggiore attenzione, soprattutto grazie all’integrazione delle conoscenze esperte nel processo inferenziale. Questa pratica, nota come elicitazione della conoscenza esperta, richiede un rigoroso approccio metodologico per evitare bias cognitivi e assicurare che le informazioni pregresse siano incorporate in modo accurato. Questo è particolarmente rilevante in campi come la psicologia, dove spesso la base teorica è incerta, e l’elicitazione esperta può contribuire a migliorare la solidità delle analisi bayesiane (O’Hagan, 2019).\n\n49.11.3 Conclusioni Finali\nIn conclusione, la scelta delle prior deve essere ponderata attentamente in base alla disponibilità di dati e al contesto dell’analisi. Sebbene l’uso di priors non informative possa sembrare una scelta “neutra”, è spesso sub-ottimale. Le priors debolmente informative rappresentano lo standard attuale, poiché favoriscono un’inferenza più robusta grazie alla loro capacità di regolarizzare l’influenza dei dati. Infine, l’uso di priori informativi, sviluppati attraverso protocolli rigorosi di elicitazione esperta, è una frontiera in crescita nell’analisi bayesiana, poiché consente di sfruttare al meglio le conoscenze pregresse per migliorare la qualità delle inferenze e ridurre l’incertezza.\nQuesto approccio, che bilancia conoscenza pregressa e nuovi dati, permette di sviluppare modelli bayesiani più solidi e informati, riflettendo accuratamente sia l’incertezza sia la competenza specifica del dominio di studio.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.10.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        Rdpack_2.6.2      vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    pan_1.9          \n#&gt; [13] pacman_0.5.1      jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-2     \n#&gt; [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [21] mnormt_2.1.1      codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64       reformulas_0.4.0 \n#&gt; [29] iterators_1.0.14  rpart_4.1.24      boot_1.3-31       mitml_0.4-5      \n#&gt; [33] foreach_1.5.2     nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37    \n#&gt; [37] stringi_1.8.4     labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4  \n#&gt; [41] fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1  cli_3.6.4        \n#&gt; [45] magrittr_2.0.3    survival_3.8-3    broom_1.0.7       withr_3.0.2      \n#&gt; [49] backports_1.5.0   timechange_0.3.0  rmarkdown_2.29    nnet_7.3-20      \n#&gt; [53] lme4_1.1-36       hms_1.1.3         evaluate_1.0.3    rbibutils_2.3    \n#&gt; [57] rlang_1.1.5       Rcpp_1.0.14       glue_1.8.0        minqa_1.2.8      \n#&gt; [61] rstudioapi_0.17.1 jsonlite_1.8.9    R6_2.6.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html#bibliografia",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html#bibliografia",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A. (2006). Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper). Bayesian Analysis, 1(3), 515–534. https://doi.org/10.1214/06-BA117A\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nO’Hagan, A. (2019). Expert knowledge elicitation: subjective but scientific. The American Statistician, 73(sup1), 69–81.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_poisson_model.html",
    "href": "chapters/bayesian_inference/10_gamma_poisson_model.html",
    "title": "50  Modello coniugato Gamma-Poisson",
    "section": "",
    "text": "50.1 Introduzione\nIn psicologia, le variabili di conteggio (\\(y\\)), che indicano il numero di occorrenze di un evento, trovano ampio impiego in diversi ambiti. Ad esempio, sono usate per quantificare la frequenza dei sintomi di un disturbo o per analizzare le frequenze delle parole negli studi di psicolinguistica. Queste variabili, assumendo valori discreti, richiedono modelli statistici specifici.\nQuesto capitolo si focalizza sulla stima del tasso medio di incidenza (\\(\\lambda_i\\)) di tali eventi, ovvero sul numero medio di occorrenze per unità di misura. Adotteremo un approccio bayesiano, utilizzando il modello di Poisson per descrivere la distribuzione di probabilità delle variabili di conteggio. In particolare, esploreremo la derivazione analitica della distribuzione a posteriori del parametro \\(\\lambda_i\\), considerando una distribuzione a priori Gamma. Successivamente, verificheremo la validità dei risultati analitici mediante simulazioni Monte Carlo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_poisson_model.html#distribuzione-di-poisson",
    "href": "chapters/bayesian_inference/10_gamma_poisson_model.html#distribuzione-di-poisson",
    "title": "50  Modello coniugato Gamma-Poisson",
    "section": "\n50.2 Distribuzione di Poisson",
    "text": "50.2 Distribuzione di Poisson\nLa distribuzione di Poisson è un modello probabilistico utilizzato per descrivere il numero di eventi che si verificano in un intervallo di tempo o spazio fisso, partendo dall’assunto che tali eventi si verifichino con una frequenza media costante e in modo indipendente rispetto al tempo trascorso dall’ultimo evento. Se un dato \\(y\\) segue una distribuzione di Poisson con parametro \\(\\lambda\\), allora la probabilità di osservare un singolo valore \\(y_i\\) è data da:\n\\[\nf(y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!},\n\\]\ndove \\(\\lambda &gt; 0\\) rappresenta la frequenza media di occorrenza degli eventi e \\(y_i\\) è il numero di eventi osservati. La distribuzione di Poisson ha la caratteristica che sia il valore atteso che la varianza di una variabile casuale \\(Y\\) che segue questa distribuzione sono pari a \\(\\lambda\\), cioè \\(E(Y) = \\lambda\\) e \\(\\text{Var}(Y) = \\lambda\\).\n\n50.2.1 Simulazione\nPer capire meglio come funziona la distribuzione di Poisson, immaginiamo un paziente con un disturbo ossessivo-compulsivo. Supponiamo che in media questo paziente ripeta un’azione compulsiva 2 volte ogni ora. In questo caso, il parametro della distribuzione di Poisson è λ = 2.\nLa probabilità di osservare esattamente \\(k\\) eventi in un’ora è calcolata dalla formula:\n\\[\nf(k | \\lambda) = \\frac{e^{-\\lambda} \\lambda^k}{k!}.\n\\]\nNel caso specifico con \\(\\lambda = 2\\), le probabilità per i primi valori di \\(k\\) sono:\n\nLa probabilità di osservare 0 eventi in un’ora è \\(\\frac{e^{-2} \\cdot 2^0}{0!} = e^{-2} \\approx 0{.}1353\\).\nLa probabilità di osservare 1 evento in un’ora è \\(\\frac{e^{-2} \\cdot 2^1}{1!} = 2e^{-2} \\approx 0{.}2707\\).\nLa probabilità di osservare 2 eventi in un’ora è \\(\\frac{e^{-2} \\cdot 2^2}{2!} = 2e^{-2} \\approx 0{.}2707\\).\nE così via per \\(k = 3\\), \\(k = 4\\), \\(\\dots\\)\n\n\nQuesto esempio illustra come la distribuzione di Poisson possa essere utilizzata per modellare il numero di eventi rari che si verificano in un intervallo temporale fisso, con una frequenza media nota.\nSvolgiamo ora i calcoli utilizzando la funzione dpois in R:\n\nlam_true &lt;- 2\n# Creazione di un vettore di valori da 0 a 9\nk_values &lt;- 0:9\n\n# Calcolo delle probabilità per ogni valore in k_values\nprobabilities &lt;- dpois(k_values, lambda = lam_true)\n\n# Stampa delle probabilità\nfor (i in seq_along(k_values)) {\n  cat(sprintf(\"Probabilità di %d eventi: %.4f\\n\", k_values[i], probabilities[i]))\n}\n#&gt; Probabilità di 0 eventi: 0.1353\n#&gt; Probabilità di 1 eventi: 0.2707\n#&gt; Probabilità di 2 eventi: 0.2707\n#&gt; Probabilità di 3 eventi: 0.1804\n#&gt; Probabilità di 4 eventi: 0.0902\n#&gt; Probabilità di 5 eventi: 0.0361\n#&gt; Probabilità di 6 eventi: 0.0120\n#&gt; Probabilità di 7 eventi: 0.0034\n#&gt; Probabilità di 8 eventi: 0.0009\n#&gt; Probabilità di 9 eventi: 0.0002\n\nIl seguente codice R genera il grafico della funzione di massa di probabilità (PMF) di una distribuzione di Poisson con parametro \\(\\lambda = 2\\):\n\n# Definiamo il parametro lambda\nlambd &lt;- 2\n\n# Generiamo i valori sull'asse x (numero di eventi)\nx &lt;- 0:9  # Possiamo aumentare o diminuire il range a seconda delle esigenze\n\n# Calcoliamo le probabilità corrispondenti utilizzando la funzione dpois\ny &lt;- dpois(x, lambda = lambd)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  numero_eventi = x,\n  probabilita = y\n)\n\n# Creare il grafico a barre con ggplot2\nggplot(df, aes(x = numero_eventi, y = probabilita)) +\n  geom_col(fill = \"lightblue\", width = 0.7) +  # Creazione delle barre\n  labs(title = \"Distribuzione di Poisson (λ = 2)\",  # Aggiungere il titolo\n       x = \"Numero di eventi\",  # Label dell'asse x\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_poisson_model.html#verosimiglianza-per-un-campione-di-osservazioni",
    "href": "chapters/bayesian_inference/10_gamma_poisson_model.html#verosimiglianza-per-un-campione-di-osservazioni",
    "title": "50  Modello coniugato Gamma-Poisson",
    "section": "\n50.3 Verosimiglianza per un Campione di Osservazioni",
    "text": "50.3 Verosimiglianza per un Campione di Osservazioni\nConsideriamo un campione di \\(n\\) osservazioni indipendenti e identicamente distribuite, \\(y_1, y_2, \\dots, y_n\\), tratto da una distribuzione di Poisson con parametro \\(\\lambda\\). La funzione di verosimiglianza \\(f(y \\mid \\lambda)\\) rappresenta la probabilità congiunta di osservare esattamente questi valori dato un particolare valore di \\(\\lambda\\).\nMatematicamente, la verosimiglianza si esprime come:\n\\[\nf(y \\mid \\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!}\n= \\frac{e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^{n} y_i!}.\n\\]\nQuesta funzione misura la compatibilità tra i dati osservati e un dato valore di \\(\\lambda\\). Valori di \\(\\lambda\\) che rendono più alta la verosimiglianza sono quelli che meglio spiegano i dati osservati.\nLa funzione di verosimiglianza descrive quanto sia plausibile un valore specifico di \\(\\lambda\\) dato il campione di dati osservati \\(y_1, y_2, \\dots, y_n\\). Per ogni possibile valore di \\(\\lambda\\), la funzione fornisce una misura della compatibilità tra il valore ipotizzato e i dati. In altre parole, essa risponde alla domanda: quanto bene questo valore di \\(\\lambda\\) spiega i dati osservati?\nPer semplificare i calcoli ed evitare problemi di overflow numerico, è comune utilizzare il logaritmo naturale della funzione di verosimiglianza, chiamato log-verosimiglianza. La log-verosimiglianza per il modello di Poisson si ottiene come:\n\\[\n\\log f(y \\mid \\lambda) = -n\\lambda + \\left(\\sum_{i=1}^n y_i \\right) \\log \\lambda - \\sum_{i=1}^n \\log(y_i!).\n\\]\nL’uso del logaritmo trasforma il prodotto nella somma, facilitando le analisi e la stima dei parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_poisson_model.html#distribuzione-gamma",
    "href": "chapters/bayesian_inference/10_gamma_poisson_model.html#distribuzione-gamma",
    "title": "50  Modello coniugato Gamma-Poisson",
    "section": "\n50.4 Distribuzione Gamma",
    "text": "50.4 Distribuzione Gamma\nLa distribuzione Gamma riveste un ruolo centrale nel modello coniugato Gamma-Poisson, poiché funge da distribuzione a priori per il parametro di tasso \\(\\lambda\\) della distribuzione di Poisson. La sua scelta è motivata dalla proprietà di coniugatezza, che consente di ottenere una distribuzione a posteriori appartenente alla stessa famiglia della prior, semplificando significativamente i calcoli inferenziali e aggiornando in modo diretto le credenze alla luce dei dati osservati.\nLa funzione di densità della distribuzione Gamma è definita come:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x},\n\\]\ndove:\n\n\n\\(\\alpha\\) (detto parametro di forma) determina la forma della distribuzione: valori più elevati di \\(\\alpha\\) tendono a rendere la distribuzione più simmetrica;\n\n\\(\\beta\\) (detto parametro di tasso o scala inversa) controlla la scala: valori più elevati di \\(\\beta\\) concentrano maggiormente la massa di probabilità vicino all’origine.\n\nAd esempio:\n\nUna distribuzione Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\) rappresenta un processo in cui eventi relativamente rari si verificano occasionalmente.\nUna distribuzione Gamma con \\(\\alpha = 10\\) e \\(\\beta = 1\\) descrive un processo più regolare, con eventi che si verificano con maggiore frequenza e prevedibilità.\n\n\n\n\n\n\n\nIn R, la parametrizzazione della distribuzione Gamma utilizza direttamente il parametro \\(\\beta\\) come tasso (\\(rate\\)), che è l’inverso del parametro di scala (\\(scale = 1 / \\beta\\)).\n\n\n\nPer calcolare la densità di probabilità in R, si utilizza:\ndgamma(x, shape = alpha, rate = beta)\n\n# Definizione dei parametri\nalpha &lt;- 2\nbeta &lt;- 3\n\n# Generazione dei valori di x\nx &lt;- seq(0, 3, length.out = 500)\n\n# Calcolo della densità di probabilità\npdf &lt;- dgamma(x, shape = alpha, rate = beta)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  x = x,\n  densita = pdf\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = x, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densità\n  labs(\n    title = expression(\"Distribuzione Gamma (\" ~ alpha == 2 ~ \",\" ~ beta == 3 ~ \")\"),  # Titolo con espressioni matematiche\n    x = \"x\",  # Label dell'asse x\n    y = \"Densità di probabilità\"  # Label dell'asse y\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nQuesto grafico mostra la densità di una distribuzione Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\), calcolata su un intervallo \\([0, 3]\\).\n\n50.4.1 Metodo Basato su Griglia\nSupponiamo di voler calcolare la distribuzione a posteriori del parametro \\(\\lambda\\) di un modello di Poisson, con una distribuzione a priori Gamma. Utilizziamo un approccio numerico basato sulla discretizzazione dello spazio dei parametri.\nConsideriamo i seguenti dati osservati:\n\n# Dati osservati\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\nAdotteremo questa distribuzione a priori:\n\n# Parametri della distribuzione a priori Gamma\nalpha_prior &lt;- 9\nbeta_prior &lt;- 2\n\n# Griglia dei valori di lambda\nlambda_grid &lt;- seq(0.01, 10, length.out = 1000)\n\n# Calcolo della densità della distribuzione a priori\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  lambda = lambda_grid,\n  densita = prior\n)\n\n# Calcolo delle linee verticali (media Gamma e media campionaria)\nmedia_gamma &lt;- alpha_prior / beta_prior\nmedia_campionaria &lt;- mean(y)\n\n# Creare il grafico \nggplot(df, aes(x = lambda, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densità\n  geom_vline(xintercept = media_gamma, color = \"red\", linetype = \"dashed\", size = 1) +  # Linea verticale per la media Gamma\n  geom_vline(xintercept = media_campionaria, color = \"green\", linetype = \"dashed\", size = 1) +  # Linea verticale per la media campionaria\n  annotate(\"text\", x = media_gamma + 0.5, y = max(prior) * 0.8, label = \"Media Gamma\", color = \"red\", size = 4) +  # Etichetta per la media Gamma\n  annotate(\"text\", x = media_campionaria + 0.5, y = max(prior) * 0.7, label = \"Media Campionaria\", color = \"green\", size = 4) +  # Etichetta per la media campionaria\n  labs(\n    title = \"Distribuzione Gamma a Priori\",\n    x = expression(lambda),  # Label dell'asse x usando espressioni matematiche\n    y = \"Densità di probabilità\"  # Label dell'asse y\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nCalcoliamo la verosimiglianza:\n\n# Inizializzazione della verosimiglianza\nlikelihood &lt;- rep(1, length(lambda_grid))\n\n# Calcolo iterativo della verosimiglianza\nfor (yi in y) {\n  likelihood &lt;- likelihood * dpois(yi, lambda = lambda_grid)\n}\n\nCalcoliamo la distribuzione a posteriori non normalizzata:\n\nposterior_unnormalized &lt;- likelihood * prior\n\nNormalizzazione della distribuzione a posteriori:\n\n# Fattore di normalizzazione\nnormalization_factor &lt;- sum(posterior_unnormalized * diff(lambda_grid)[1])\n\n# Distribuzione a posteriori normalizzata\nposterior &lt;- posterior_unnormalized / normalization_factor\n\nCreiamo un grafico delle distribuzioni a priori e a posteriori:\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  lambda = lambda_grid,\n  densita_posterior = posterior,\n  densita_prior = prior\n)\n\n# Convertire i dati in formato \"lungo\" per facilitare la visualizzazione con ggplot2\ndf_long &lt;- reshape2::melt(\n  df, id.vars = \"lambda\", \n  measure.vars = c(\"densita_posterior\", \"densita_prior\"),\n  variable.name = \"distribuzione\", value.name = \"densita\"\n)\n\n# Creare il grafico con ggplot2\nggplot(df_long, aes(x = lambda, y = densita, color = distribuzione)) +\n  geom_line(size = 1) +  # Aggiungere le linee per le distribuzioni\n  scale_color_manual(\n    values = c(\"densita_posterior\" = \"blue\", \"densita_prior\" = \"red\"),  # Assegnare i colori\n    labels = c(\"densita_posterior\" = \"Posteriori\", \"densita_prior\" = \"A Priori\")  # Etichette personalizzate\n  ) +\n  labs(\n    title = \"Distribuzione a Posteriori di Lambda\",\n    x = expression(lambda),  # Label dell'asse x usando espressioni matematiche\n    y = \"Densità di probabilità\",  # Label dell'asse y\n    color = \"Distribuzione\"  # Titolo della legenda\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nIn conclusione,\n\nla distribuzione a posteriori è spostata a sinistra rispetto a quella a priori, indicando che i dati suggeriscono un valore più basso per \\(\\lambda\\).\nla distribuzione a posteriori è più stretta rispetto a quella a priori, indicando una riduzione dell’incertezza.\n\nQuesto approccio numerico consente di esplorare come le osservazioni aggiornano la nostra credenza sul parametro \\(\\lambda\\), evidenziando la potenza del metodo bayesiano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "href": "chapters/bayesian_inference/10_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "title": "50  Modello coniugato Gamma-Poisson",
    "section": "\n50.5 Modello Coniugato Gamma-Poission",
    "text": "50.5 Modello Coniugato Gamma-Poission\nPer calcolare analiticamente la distribuzione a posteriori nel contesto di un modello gamma-Poisson possiamo seguire un processo diretto. Il modello Gamma-Poisson è coniugato, il che significa che la distribuzione a posteriori sarà ancora una distribuzione Gamma.\nSeguendo il teorema di Bayes, possiamo scrivere la distribuzione a posteriori come:\n\\(f(\\lambda \\mid y) \\propto f(y \\mid \\lambda) \\cdot f(\\lambda) ,\\)\ndove \\(f(\\lambda \\mid y)\\) è la distribuzione a posteriori, \\(f(y \\mid \\lambda)\\) è la verosimiglianza e \\(f(\\lambda)\\) è la distribuzione a priori.\nDefiniamo la verosimiglianza (distribuzione di Poisson):\n\\(f(y \\mid \\lambda) = \\prod_{i=1}^n \\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!} = \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!}.\\)\nDefiniamo la distribuzione a priori (distribuzione Gamma):\n\\(f(\\lambda) = \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nOra, moltiplichiamo la verosimiglianza per la distribuzione a priori:\n\\(f(\\lambda|y) \\propto \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!} \\cdot \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nSemplifichiamo, eliminando i termini costanti (che non dipendono da \\(\\lambda\\)):\n\\(f(\\lambda \\mid y) \\propto e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1}e^{-b\\lambda}.\\)\nRaggruppiamo i termini:\n\\(f(\\lambda|y) \\propto \\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1} \\cdot e^{-n\\lambda} \\cdot e^{-b\\lambda}.\\)\nSemplifichiamo ulteriormente:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{\\sum_{i=1}^n y_i + a - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nRiconosciamo che questa è la forma di una distribuzione Gamma con nuovi parametri:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{(\\sum_{i=1}^n y_i + a) - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nQuindi, la distribuzione a posteriori è una Gamma con parametri:\n\n\n\\(\\alpha_{post} = a + \\sum_{i=1}^n y_i\\),\n\n\\(\\beta_{post} = b + n\\),\n\ndove:\n\n\n\\(a\\) e \\(b\\) sono i parametri della distribuzione Gamma a priori,\n\n\\(\\sum_{i=1}^n y_i\\) è la somma di tutte le osservazioni,\n\n\\(n\\) è il numero di osservazioni.\n\nQuesta derivazione mostra come la distribuzione a posteriori mantiene la forma di una Gamma, ma con parametri aggiornati che incorporano l’informazione dai dati osservati.\nConsideriamo nuovamente l’esempio precedente. Utilizzando i parametri aggiornati, rappresentiamo graficamente la distribuzione a posteriori:\n\n# Parametri aggiornati della distribuzione a posteriori Gamma\nalpha_post &lt;- alpha_prior + sum(y)\nbeta_post &lt;- beta_prior + length(y)\n\n# Griglia dei valori di lambda\nlambda_grid &lt;- seq(0.01, 10, length.out = 1000)\n\n# Distribuzione a posteriori analitica\nposterior_analytic &lt;- dgamma(lambda_grid, shape = alpha_post, rate = beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  lambda = lambda_grid,\n  densita = posterior_analytic\n)\n\n# Calcolo della media a posteriori\nmedia_posterior &lt;- alpha_post / beta_post\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = lambda, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densità a posteriori\n  geom_vline(xintercept = media_posterior, color = \"red\", linetype = \"dashed\", size = 1) +  # Linea verticale per la media a posteriori\n  labs(\n    title = \"Distribuzione a Posteriori Analitica Gamma-Poisson\",\n    x = expression(lambda),  # Label dell'asse x usando espressioni matematiche\n    y = \"Densità di probabilità\"  # Label dell'asse y\n  ) +\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  annotate(\"text\", x = media_posterior + 0.5, y = max(posterior_analytic) * 0.8, \n           label = \"Media a Posteriori\", color = \"red\", size = 4) +  # Etichetta per la media a posteriori\n  scale_x_continuous(expand = expansion(mult = c(0, 0.1)))  # Aumentare lo spazio sull'asse x per migliorare la visualizzazione\n\n\n\n\n\n\n\nIl grafico mostra la distribuzione a posteriori analitica del parametro di tasso \\(\\lambda\\) di un modello di Poisson, ottenuta utilizzando una distribuzione a priori Gamma e aggiornando i parametri alla luce dei dati osservati. La distribuzione a posteriori è calcolata come una Gamma aggiornata con i parametri \\(\\alpha_{\\text{post}}\\) e \\(\\beta_{\\text{post}}\\), e rappresenta la nostra conoscenza aggiornata dopo aver visto i dati. I risultati analitici concordano con quelli ottenuti tramite simulazione.\nProcediamo ora con il calcolo della soluzione analitica per la media della distribuzione a posteriori del parametro \\(\\lambda\\):\n\n# Media della distribuzione a posteriori\nposterior_mean &lt;- alpha_post / beta_post\ncat(sprintf(\"Media a Posteriori = %.3f\\n\", posterior_mean))\n#&gt; Media a Posteriori = 2.200\n\n# Parametri della distribuzione a posteriori\ncat(sprintf(\"Shape (α) = %.1f\\n\", alpha_post))\n#&gt; Shape (α) = 22.0\ncat(sprintf(\"Rate (β) = %.1f\\n\", beta_post))\n#&gt; Rate (β) = 10.0\n\nPossiamo calcolare la probabilità di qualsiasi evento di interesse. Per esempio, ci possiamo chiedere quale sia la probabilità di osservare più di 3 compulsioni per ora:\n\n# Probabilità di osservare più di 3 eventi\nprob_y_greater_than_3 &lt;- 1 - pgamma(3, shape = alpha_post, rate = beta_post)\ncat(sprintf(\"Probabilità di osservare più di 3 eventi = %.3f\\n\", prob_y_greater_than_3))\n#&gt; Probabilità di osservare più di 3 eventi = 0.054",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/10_gamma_poisson_model.html#riflessioni-conclusive",
    "title": "50  Modello coniugato Gamma-Poisson",
    "section": "\n50.6 Riflessioni Conclusive",
    "text": "50.6 Riflessioni Conclusive\nIl modello Gamma-Poisson offre un framework robusto per l’inferenza bayesiana su dati di conteggio in psicologia. Partendo da una distribuzione a priori Gamma, che rappresenta la nostra conoscenza iniziale sul tasso medio, siamo in grado di aggiornare questa conoscenza alla luce dei dati osservati, ottenendo una distribuzione a posteriori che riflette in modo più preciso la realtà sottostante. Questo approccio permette di quantificare l’incertezza associata alle nostre stime e di prendere decisioni informate sulla base dei dati disponibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_poisson_model.html#esercizi",
    "href": "chapters/bayesian_inference/10_gamma_poisson_model.html#esercizi",
    "title": "50  Modello coniugato Gamma-Poisson",
    "section": "\n50.7 Esercizi",
    "text": "50.7 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo uno studio longitudinale su coppie, dove i partecipanti registrano quotidianamente la frequenza con cui nascondono il loro comportamento di fumo al partner. Basandoci sui dati di Scholz et al. (2021), assumiamo che il tasso medio di nascondere il fumo sia di 1.52 volte al giorno. Supponiamo di avere i seguenti dati giornalieri per un partecipante:\n\nGiorno 1: 2 volte.\nGiorno 2: 0 volte.\nGiorno 3: 1 volta.\nGiorno 4: 3 volte.\n\nUtilizzare un modello Gamma-Poisson per stimare la distribuzione a posteriori del tasso individuale di nascondere il fumo per un partecipante specifico, dato il suo insieme di osservazioni giornaliere.\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nVogliamo stimare quante volte al giorno una persona tende a nascondere il proprio fumo al partner. Abbiamo quattro giorni di dati su questa persona e, grazie a un precedente studio, sappiamo che in media le persone lo fanno circa 1.52 volte al giorno.\nMa i dati di una sola persona sono pochi, quindi useremo un approccio bayesiano per combinare:\n\n\nLe informazioni preesistenti (dal precedente studio),\n\nLe nuove osservazioni (quanti eventi sono stati registrati nei quattro giorni).\n\nCon un modello Gamma-Poisson, possiamo aggiornare la nostra stima e ottenere una distribuzione a posteriori, che ci dirà quali sono i valori più probabili per il tasso di nascondimento di questa persona.\n# Dati osservati: numero di volte che la persona ha nascosto il fumo ogni giorno\nosservazioni &lt;- c(2, 0, 1, 3)\n\n# Numero totale di giorni osservati\nn_giorni &lt;- length(osservazioni)\n\n# Numero totale di eventi (quante volte ha nascosto il fumo in totale)\neventi_totali &lt;- sum(osservazioni)\n\n# Informazione a priori dallo studio precedente\nmedia_priori &lt;- 1.52\nforma_priori &lt;- 3   # Parametro di forma scelto per un'incertezza moderata\ntasso_priori &lt;- forma_priori / media_priori  # Parametro di scala\n\n# Aggiornamento bayesiano: parametri della distribuzione a posteriori\nforma_post &lt;- forma_priori + eventi_totali\ntasso_post &lt;- tasso_priori + n_giorni\n\n# Creazione della griglia di valori possibili per il tasso giornaliero (lambda)\nlambda_valori &lt;- seq(0, 5, length.out = 100)\n\n# Calcolo delle densità per le distribuzioni a priori e a posteriori\ndensita_priori &lt;- dgamma(lambda_valori, shape = forma_priori, rate = tasso_priori)\ndensita_post &lt;- dgamma(lambda_valori, shape = forma_post, rate = tasso_post)\n\n# Creazione di un dataframe per il grafico\ndati_plot &lt;- data.frame(\n  lambda = rep(lambda_valori, 2),\n  densita = c(densita_priori, densita_post),\n  distribuzione = rep(c(\"Priori\", \"Posteriori\"), each = length(lambda_valori))\n)\n\n# Creazione del grafico per confrontare la distribuzione a priori e quella aggiornata (posteriori)\nggplot(dati_plot, aes(x = lambda, y = densita, color = distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Stima del tasso di nascondimento del fumo\",\n    x = \"Tasso giornaliero (λ)\",\n    y = \"Densità\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\nCosa fa questo codice\n\n\nCarica i dati: abbiamo registrato per 4 giorni quante volte questa persona ha nascosto il fumo.\n\nImposta una conoscenza iniziale (priori): basata sullo studio precedente.\n\nApplica il teorema di Bayes per aggiornare la stima con i nuovi dati.\n\nGenera il grafico: confronta la distribuzione prima e dopo l’aggiornamento con i dati osservati.\n\nInterpretazione del risultato\n\nLa curva rossa (priori) rappresenta la nostra stima iniziale, basata sullo studio precedente.\nLa curva blu (posteriori) è la nostra nuova stima dopo aver considerato i dati della persona.\nSe i dati raccolti sono molto diversi dal valore medio dello studio, la curva blu si sposterà rispetto alla rossa.\n\nQuesta analisi ci permette di stimare il comportamento specifico di una persona integrando dati generali e osservazioni individuali, in modo più informativo rispetto a una semplice media.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/10_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "50  Modello coniugato Gamma-Poisson",
    "section": "\n50.8 Informazioni sull’Ambiente di Sviluppo",
    "text": "50.8 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.10.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] digest_0.6.37     rpart_4.1.24      timechange_0.3.0  lifecycle_1.0.4  \n#&gt;  [9] survival_3.8-3    magrittr_2.0.3    compiler_4.4.2    rlang_1.1.5      \n#&gt; [13] tools_4.4.2       labeling_0.4.3    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [17] plyr_1.8.9        withr_3.0.2       nnet_7.3-20       grid_4.4.2       \n#&gt; [21] jomo_2.7-6        colorspace_2.1-1  iterators_1.0.14  MASS_7.3-64      \n#&gt; [25] cli_3.6.4         rmarkdown_2.29    reformulas_0.4.0  generics_0.1.3   \n#&gt; [29] rstudioapi_0.17.1 reshape2_1.4.4    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [33] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [37] glmnet_4.1-8      Matrix_1.7-2      jsonlite_1.8.9    hms_1.1.3        \n#&gt; [41] mitml_0.4-5       foreach_1.5.2     glue_1.8.0        nloptr_2.1.1     \n#&gt; [45] pan_1.9           codetools_0.2-20  stringi_1.8.4     shape_1.4.6.1    \n#&gt; [49] gtable_0.3.6      lme4_1.1-36       munsell_0.5.1     pillar_1.10.1    \n#&gt; [53] htmltools_0.5.8.1 R6_2.6.1          Rdpack_2.6.2      rprojroot_2.0.4  \n#&gt; [57] evaluate_1.0.3    lattice_0.22-6    rbibutils_2.3     backports_1.5.0  \n#&gt; [61] broom_1.0.7       Rcpp_1.0.14       nlme_3.1-167      xfun_0.50        \n#&gt; [65] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_poisson_model.html#bibliografia",
    "href": "chapters/bayesian_inference/10_gamma_poisson_model.html#bibliografia",
    "title": "50  Modello coniugato Gamma-Poisson",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nScholz, U., Stadler, G., Berli, C., Lüscher, J., & Knoll, N. (2021). How do people experience and respond to social control from their partner? Three daily diary studies. Frontiers in Psychology, 11, 613546.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_exponential_model.html",
    "href": "chapters/bayesian_inference/11_gamma_exponential_model.html",
    "title": "51  Modello gamma-esponenziale",
    "section": "",
    "text": "51.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNell’inferenza bayesiana, il modello coniugato Gamma-Esponenziale rappresenta un approccio analitico efficace per l’analisi di dati che seguono una distribuzione esponenziale. Questa distribuzione è comunemente utilizzata per modellare i tempi di attesa tra eventi in processi di Poisson, come ad esempio gli intervalli tra arrivi in un sistema a coda o la durata di eventi psicologici.\nConsideriamo, ad esempio, un esperimento in psicologia in cui si misurano i tempi di insorgenza di episodi di ansia in seguito a un evento stressante. In questo caso, si può ipotizzare che i tempi di insorgenza siano distribuiti esponenzialmente. Il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio con cui si verificano gli episodi di ansia.\nIl modello coniugato Gamma-Esponenziale consente di stimare il parametro \\(\\lambda\\) utilizzando i dati osservati. La distribuzione a priori Gamma viene utilizzata per rappresentare l’incertezza iniziale su \\(\\lambda\\), mentre la distribuzione esponenziale modella i dati osservati. Grazie a questa coniugazione, l’aggiornamento delle credenze sul parametro \\(\\lambda\\) avviene in modo semplice e analitico, permettendo di ottenere una stima bayesiana del tasso medio di occorrenza degli episodi di ansia, fornendo così una descrizione probabilistica accurata del fenomeno in esame.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_exponential_model.html#introduzione",
    "href": "chapters/bayesian_inference/11_gamma_exponential_model.html#introduzione",
    "title": "51  Modello gamma-esponenziale",
    "section": "",
    "text": "51.1.1 Il Modello Matematico\nCaso singolo. Supponiamo di osservare un singolo tempo di attesa \\(y_1\\) prima che si verifichi un evento, come un episodio di disagio psicologico. Assumiamo che questo tempo di attesa segua una distribuzione esponenziale con parametro \\(\\lambda\\). La funzione di densità di probabilità (pdf) della distribuzione esponenziale è data da:\n\\[\nf(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1},\n\\]\ndove:\n\n\n\\(y_1\\) rappresenta il tempo di attesa,\n\n\\(\\lambda\\) è il parametro della distribuzione, che rappresenta il tasso medio con cui gli eventi si verificano per unità di tempo.\n\nIn questa distribuzione, \\(\\lambda\\) è il tasso di occorrenza o tasso di decadimento, ed è l’inverso del tempo medio di attesa. Più precisamente:\n\nIl tempo medio di attesa è il valore medio del tempo che trascorre prima che l’evento si verifichi (ad esempio, quanto tempo ci si aspetta in media prima che arrivi un autobus).\nIl parametro \\(\\lambda\\) rappresenta la frequenza con cui l’evento si verifica per unità di tempo, e quindi \\(\\lambda = \\frac{1}{\\text{tempo medio}}\\).\n\nPertanto, nella funzione esponenziale \\(f(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1}\\), il parametro \\(\\lambda\\) è inversamente proporzionale al tempo medio di attesa: più grande è \\(\\lambda\\), più breve è il tempo medio di attesa tra gli eventi.\nQuesta funzione descrive la probabilità di osservare un tempo di attesa esattamente uguale a \\(y_1\\), dato un valore specifico di \\(\\lambda\\). Per la distribuzione esponenziale, la media è \\(\\frac{1}{\\lambda}\\) e la varianza è \\(\\frac{1}{\\lambda^2}\\), il che riflette l’influenza del tasso \\(\\lambda\\) sulla dispersione dei tempi di attesa.\nPer fare un esempio, supponiamo che il tempo medio di attesa sia 2 ore. In questo caso, il parametro \\(\\lambda\\) (l’inverso del tempo medio di attesa) è \\(\\frac{1}{2}\\).\n\n# Parametro lambda (l'inverso del tempo medio di attesa)\nlambda_value &lt;- 1 / 2\n\nDisegniamo la funzione di densità esponenziale per tempi di attesa compresi tra 0 e 10 ore.\n\n# Creazione dei valori di y1 su cui valutare la funzione\ny1_values &lt;- seq(0, 10, length.out = 500) # Intervallo da 0 a 10 ore\n\n# Definizione della funzione di densità esponenziale\nexponential_density &lt;- function(y1, lambda_value) {\n  lambda_value * exp(-lambda_value * y1)\n}\n\n# Calcolo dei valori di f(y1 | lambda)\nf_values &lt;- exponential_density(y1_values, lambda_value)\n\n# Creazione del grafico\nplot(\n  y1_values, f_values,\n  type = \"l\", lwd = 2,\n  main = expression(paste(\n    \"Funzione di Densità Esponenziale con \",\n    lambda, \" = 1/2\"\n  )),\n  xlab = \"Tempo di attesa (ore)\", ylab = \"Densità\"\n)\nlegend(\"topright\",\n  legend = expression(f(y[1] ~ \"|\" ~ lambda) == lambda ~ e^(-lambda * y[1])),\n  lty = 1, bty = \"n\"\n)\n\n\n\n\n\n\n\nQuesto codice crea un grafico della funzione di densità esponenziale per \\(\\lambda = 1/2\\) e tempi di attesa compresi tra 0 e 10 ore.\nIl caso di \\(n\\) osservazioni indipendenti. Consideriamo ora un campione di \\(n\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_n\\). L’indipendenza tra le osservazioni implica che il tempo di attesa osservato per un evento non influisce sulla probabilità di osservare altri tempi di attesa.\nPoiché le osservazioni sono indipendenti, la probabilità congiunta di osservare tutti i tempi di attesa nel campione è il prodotto delle probabilità individuali. Di conseguenza, la funzione di verosimiglianza per l’intero campione è data da:\n\\[\nf(y_1, y_2, \\dots, y_n \\mid \\lambda) = f(y_1 \\mid \\lambda) \\cdot f(y_2 \\mid \\lambda) \\cdot \\dots \\cdot f(y_n \\mid \\lambda).\n\\]\nSostituendo la funzione di densità della distribuzione esponenziale per ciascuna osservazione, otteniamo:\n\\[\nf(y \\mid \\lambda) = \\lambda e^{-\\lambda y_1} \\cdot \\lambda e^{-\\lambda y_2} \\cdot \\dots \\cdot \\lambda e^{-\\lambda y_n}.\n\\]\nRaccogliendo i termini comuni, possiamo riscrivere la funzione di verosimiglianza come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda (y_1 + y_2 + \\dots + y_n)}.\n\\]\nUtilizzando la notazione di sommatoria, possiamo esprimere la funzione di verosimiglianza in modo compatto come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} y_i}.\n\\]\nLa funzione di verosimiglianza \\(f(y \\mid \\lambda)\\) rappresenta la probabilità di osservare il campione \\(y_1, y_2, \\dots, y_n\\) dato un particolare valore del parametro \\(\\lambda\\). Un valore più alto della verosimiglianza indica una maggiore plausibilità del valore di \\(\\lambda\\), dato il campione osservato.\nSpesso è più conveniente lavorare con il logaritmo della funzione di verosimiglianza, poiché il logaritmo trasforma i prodotti in somme, semplificando i calcoli. Il logaritmo della funzione di verosimiglianza è:\n\\[\n\\log L(\\lambda \\mid y_1, y_2, \\dots, y_n) = n \\log \\lambda - \\lambda \\sum_{i=1}^{n} y_i.\n\\]\nQuesta forma semplificata della log-verosimiglianza è utile per stimare il parametro \\(\\lambda\\) tramite tecniche come la massimizzazione della verosimiglianza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "href": "chapters/bayesian_inference/11_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "title": "51  Modello gamma-esponenziale",
    "section": "\n51.2 Aggiornare le Nostre Credenze con l’Inferenza Bayesiana",
    "text": "51.2 Aggiornare le Nostre Credenze con l’Inferenza Bayesiana\nNell’approccio bayesiano, non consideriamo solo i dati, ma anche le nostre conoscenze a priori sul parametro \\(\\lambda\\). Assegniamo a \\(\\lambda\\) una distribuzione a priori, tipicamente una distribuzione Gamma. Combinando la verosimiglianza con la distribuzione a priori, otteniamo la distribuzione a posteriori di \\(\\lambda\\), che rappresenta la nostra conoscenza aggiornata alla luce dei dati. La proprietà della coniugazione assicura che la distribuzione a posteriori sia anch’essa una Gamma, facilitando i calcoli.\nPer fare un esempio concreto, simuleremo un campione di dati. Immaginiamo di raccogliere dati che rappresentano il tempo, misurato in ore, che intercorre tra episodi di ansia in individui con disturbi d’ansia. La distribuzione esponenziale può essere utilizzata per modellare questo tempo di attesa tra un episodio di ansia e il successivo. Ad esempio, possiamo ipotizzare che, una volta concluso un episodio, l’insorgenza del prossimo segua un processo stocastico con un tasso costante, indipendentemente dal tempo trascorso dall’episodio precedente. In questo contesto, il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio di occorrenza degli episodi di ansia, ossia quanti episodi ci si aspetta in media in una certa unità di tempo (ad esempio, in un giorno).\nSe \\(\\lambda\\) è elevato, ciò indica che gli episodi di ansia sono più frequenti, con tempi di attesa più brevi tra un episodio e l’altro.\n\n# Impostiamo il seed per rendere i risultati riproducibili\nset.seed(42)\n\n# Parametro medio (tempo medio di attesa in ore)\nmean_time &lt;- 3.0\nlambda_param &lt;- 1 / mean_time # Parametro lambda per la distribuzione esponenziale\n\n# Numero di osservazioni nel campione\nn &lt;- 15\n\n# Generazione del campione casuale\ny &lt;- round(rexp(n, rate = lambda_param))\ny\n#&gt;  [1] 1 2 1 0 1 4 1 1 4 2 4 7 0 0 4\n\nImmaginiamo che questi dati rappresentino il tempo di attesa in ore tra episodi di ansia in 15 individui con disturbi d’ansia. Il tempo di attesa medio è:\n\nmean_time_observed &lt;- mean(y)\nmean_time_observed\n#&gt; [1] 2.133\n\nIl tasso di occorrenza, \\(\\lambda\\), calcolato sulla base dei dati osservati è:\n\nlambda_estimated &lt;- 1 / mean_time_observed\nlambda_estimated\n#&gt; [1] 0.4688\n\nOra possiamo procedere a trovare la distribuzione a posteriori per il tasso di occorrenza \\(\\lambda\\).\n\n51.2.1 Passi per definire un prior debolmente informativo\nIl primo passo consiste nel definire una distribuzione a priori per \\(\\lambda\\), il tasso di occorrenza degli episodi di ansia in individui con disturbi d’ansia. Se disponiamo di poche informazioni a priori riguardo al valore di \\(\\lambda\\), possiamo adottare una distribuzione a priori debolmente informativa. Un prior debolmente informativo ha lo scopo di esercitare una minima influenza sull’inferenza, consentendo ai dati osservati di guidare principalmente la stima del parametro.\nLa distribuzione a priori coniugata per la distribuzione esponenziale è la distribuzione Gamma. Un prior debolmente informativo per \\(\\lambda\\) potrebbe essere impostato in modo tale da riflettere una conoscenza vaga, con una media che rappresenta un tempo di attesa ragionevole (basato su qualche informazione preliminare o ipotesi generale), ma con una varianza ampia, in modo da non vincolare eccessivamente l’inferenza.\nSupponiamo di voler impostare una distribuzione a priori per il tasso di occorrenza \\(\\lambda\\), in modo tale che il tempo medio di attesa sia 3.33 ore, con una deviazione standard ampia, ad esempio 5 ore. Poiché \\(\\lambda\\) rappresenta il tasso di occorrenza (ovvero l’inverso del tempo medio di attesa), dobbiamo applicare la distribuzione Gamma ai valori di \\(\\lambda\\), non direttamente ai tempi di attesa.\nI parametri della distribuzione Gamma, \\(\\alpha\\) (forma) e \\(\\beta\\) (tasso), sono dati da:\n\n\\(\\alpha_{\\text{prior}} = 0.45\\)\n\\(\\beta_{\\text{prior}} = 1.5\\)\n\nVerifichiamo che questi parametri corrispondano alla media e alla varianza desiderate.\n\n# Parametri della distribuzione Gamma\nalpha_prior &lt;- 0.45 # Forma\nbeta_prior &lt;- 1.5 # Tasso (inverso della scala)\n\n# Calcolo della media e della varianza della distribuzione Gamma per λ\nmean_lambda &lt;- alpha_prior / beta_prior\nvariance_lambda &lt;- alpha_prior / (beta_prior^2)\n\n# Calcolo della media del tempo di attesa (E[Y] = 1 / E[λ])\nmean_waiting_time &lt;- 1 / mean_lambda\n\n# Stampiamo la media e la varianza di λ e del tempo di attesa\ncat(\"Media di λ:\", mean_lambda, \"\\n\")\n#&gt; Media di λ: 0.3\ncat(\"Varianza di λ:\", variance_lambda, \"\\n\")\n#&gt; Varianza di λ: 0.2\ncat(\"Media del tempo di attesa:\", mean_waiting_time, \"ore\\n\")\n#&gt; Media del tempo di attesa: 3.333 ore\n\nLa media del tempo di attesa è 3.33 ore, come desiderato. La varianza del tempo di attesa richiede un calcolo più complesso e non è semplicemente l’inverso della varianza di \\(\\lambda\\).\n\n51.2.2 Visualizzazione della Distribuzione a Priori\nDisegniamo la funzione di densità della distribuzione Gamma per \\(\\lambda\\), utilizzando i parametri specificati.\n\n# Creazione dei valori x per il grafico\nx &lt;- seq(0, 2, length.out = 500)\n\n# Funzione di densità della distribuzione Gamma con i parametri dati\ngamma_pdf &lt;- dgamma(x, shape = alpha_prior, rate = beta_prior)\n\n# Creazione del grafico\nplot(x, gamma_pdf,\n  type = \"l\", lwd = 2,\n  main = bquote(\"Funzione di Densità Gamma con \" ~ alpha == .(alpha_prior) ~ \",\" ~ beta == .(beta_prior)),\n  xlab = expression(lambda),\n  ylab = \"Densità di probabilità\"\n)\nlegend(\n  \"topright\",\n  legend = \"Distribuzione a Priori\",\n  lty = 1,\n  lwd = 2,\n  bty = \"n\"\n)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_exponential_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/11_gamma_exponential_model.html#metodo-basato-su-griglia",
    "title": "51  Modello gamma-esponenziale",
    "section": "\n51.3 Metodo Basato su Griglia",
    "text": "51.3 Metodo Basato su Griglia\nPoniamoci l’obiettivo di utilizzare il metodo basato su griglia per derivare la distribuzione a posteriori del parametro \\(\\lambda\\) della distribuzione esponenziale. Iniziamo creando una griglia per \\(\\lambda\\) nell’intervallo [0.01, 2].\n\n# Evitiamo zero per evitare divisione per zero\nlambda_grid &lt;- seq(0.01, 2, length.out = 1000)\n\n\n51.3.1 Calcolo della Distribuzione a Priori\n\n# Calcolo della distribuzione a priori\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\n\n51.3.2 Calcolo della Verosimiglianza\nImmaginiamo di avere i seguenti dati, che rappresentano i tempi di attesa (in ore) tra episodi di ansia per 15 individui:\n\n# Impostiamo il seed per rendere i risultati riproducibili\nset.seed(42)\n\n# Parametro medio (tempo medio di attesa in ore)\nmean_time &lt;- 3.0\nlambda_param &lt;- 1 / mean_time # Parametro λ per la distribuzione esponenziale\n\n# Numero di osservazioni nel campione\nn &lt;- 15\n\n# Generazione del campione casuale\ny &lt;- round(rexp(n, rate = lambda_param))\ny\n#&gt;  [1] 1 2 1 0 1 4 1 1 4 2 4 7 0 0 4\n\nCalcoliamo la log-verosimiglianza per ciascun valore di \\(\\lambda\\) nella griglia:\n\n# Calcolo della log-verosimiglianza per ciascun valore di lambda\nlog_likelihood &lt;- sapply(\n  lambda_grid,\n  function(lam) sum(dexp(y, rate = lam, log = TRUE))\n)\n\n\n51.3.3 Calcolo della Distribuzione a Posteriori\nCalcoliamo la distribuzione a posteriori non normalizzata in logaritmo per evitare problemi di underflow numerico:\n\n# Calcolo del log-posteriori non normalizzato\nlog_posterior_unnormalized &lt;- log_likelihood + log(prior)\n\n# Normalizzazione per stabilità numerica\nlog_posterior_unnormalized &lt;- log_posterior_unnormalized - max(log_posterior_unnormalized)\n\n# Convertiamo in scala normale\nposterior_unnormalized &lt;- exp(log_posterior_unnormalized)\n\nNormalizziamo la distribuzione a posteriori:\n\n# Calcolo del passo nella griglia\ndelta_lambda &lt;- diff(lambda_grid)[1] # Assumendo che la griglia sia equispaziata\n\n# Normalizzazione della distribuzione a posteriori\nposterior &lt;-\n  posterior_unnormalized / sum(posterior_unnormalized * delta_lambda)\n\n\n51.3.4 Visualizzazione dei Risultati\n\n# Grafico della distribuzione a posteriori e a priori\nplot(lambda_grid, posterior,\n  type = \"l\",\n  lwd = 2,\n  xlab = expression(lambda),\n  ylab = \"Densità di probabilità\",\n  main = \"Distribuzione a Posteriori di λ\"\n)\nlines(lambda_grid, prior, lwd = 2, lty = 2)\nlegend(\"topright\",\n  legend = c(\"Posteriori\", \"Priori\"),\n  lty = c(1, 2), \n  lwd = 2, \n  bty = \"n\"\n)\n\n\n\n\n\n\n\nDal grafico, possiamo osservare come la distribuzione a posteriori di \\(\\lambda\\) sia aggiornata rispetto alla distribuzione a priori in base ai dati osservati. La distribuzione a posteriori riflette sia le informazioni a priori sia l’evidenza fornita dai dati, fornendo una stima aggiornata del tasso di occorrenza degli episodi di ansia.\n\n51.3.5 Calcolo della Media e Varianza Posteriori\nPossiamo calcolare la media e la varianza a posteriori di \\(\\lambda\\) utilizzando la distribuzione a posteriori calcolata sulla griglia.\n\n# Calcolo della media a posteriori di λ\nposterior_mean_lambda &lt;- sum(lambda_grid * posterior * delta_lambda)\n\n# Calcolo della varianza a posteriori di λ\nposterior_variance_lambda &lt;-\n  sum((lambda_grid - posterior_mean_lambda)^2 * posterior * delta_lambda)\n\n# Stampiamo i risultati\ncat(\"Media a posteriori di λ:\", posterior_mean_lambda, \"\\n\")\n#&gt; Media a posteriori di λ: 0.4612\ncat(\"Varianza a posteriori di λ:\", posterior_variance_lambda, \"\\n\")\n#&gt; Varianza a posteriori di λ: 0.01377\n\n\n51.3.6 Stima del Tempo di Attesa Medio a Posteriori\nUtilizzando la media a posteriori di \\(\\lambda\\), possiamo stimare il tempo di attesa medio a posteriori:\n\n# Stima del tempo di attesa medio a posteriori\nposterior_mean_waiting_time &lt;- 1 / posterior_mean_lambda\ncat(\"Tempo di attesa medio a posteriori:\", posterior_mean_waiting_time, \"ore\\n\")\n#&gt; Tempo di attesa medio a posteriori: 2.168 ore\n\nIn conclusione, attraverso il metodo basato su griglia, abbiamo derivato la distribuzione a posteriori del tasso di occorrenza \\(\\lambda\\), tenendo conto della nostra conoscenza a priori e dei dati osservati. Questo approccio ci permette di aggiornare le nostre credenze su \\(\\lambda\\) in modo coerente con l’evidenza empirica, fornendo stime più accurate e affidabili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "href": "chapters/bayesian_inference/11_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "title": "51  Modello gamma-esponenziale",
    "section": "\n51.4 Modello Coniugato Gamma-Esponenziale",
    "text": "51.4 Modello Coniugato Gamma-Esponenziale\nQuando utilizziamo una distribuzione \\(\\text{Gamma}(\\alpha, \\beta)\\) come distribuzione coniugata a priori, la distribuzione a posteriori risulta anch’essa essere una distribuzione Gamma, con parametri aggiornati \\(\\alpha + n\\) e \\(\\beta + \\sum_{i=1}^{n} x_{i}\\).\nIn altre parole, se il parametro \\(\\lambda\\) della distribuzione esponenziale segue una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\), allora, dopo aver osservato un campione di \\(n\\) osservazioni \\(x_1, x_2, \\dots, x_n\\), la distribuzione a posteriori di \\(\\lambda\\) sarà ancora una distribuzione Gamma, ma con i parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_{i}).\n\\]\nQuesto aggiornamento dei parametri è una conseguenza della proprietà coniugata della distribuzione Gamma rispetto alla distribuzione esponenziale.\n\n51.4.1 Dimostrazione del Modello Coniugato Gamma-Esponenziale\nPer dimostrare questo risultato, partiamo dal teorema di Bayes:\n\\[\nf(\\lambda \\mid x) \\propto f(x \\mid \\lambda) \\cdot f(\\lambda),\n\\]\ndove \\(f(\\lambda \\mid x)\\) è la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\), \\(f(x \\mid \\lambda)\\) è la verosimiglianza basata sul campione \\(x\\), e \\(f(\\lambda)\\) è la distribuzione a priori di \\(\\lambda\\).\nLa funzione di verosimiglianza per un campione di \\(n\\) osservazioni indipendenti \\(x_1, x_2, \\dots, x_n\\), che seguono una distribuzione esponenziale con parametro \\(\\lambda\\), è data da:\n\\[\nf(x \\mid \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i} = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i}.\n\\]\nSupponiamo che il parametro \\(\\lambda\\) segua una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\):\n\\[\nf(\\lambda) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nMoltiplicando la verosimiglianza per la distribuzione a priori, otteniamo la distribuzione a posteriori:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i} \\cdot \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nSemplificando, si ottiene:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^{n + \\alpha - 1} e^{-\\lambda \\left(\\beta + \\sum_{i=1}^{n} x_i\\right)}.\n\\]\nQuesta espressione corrisponde alla forma di una distribuzione Gamma con parametri aggiornati:\n\nparametro della forma (alpha): \\(\\alpha_{\\text{post}} = \\alpha + n\\);\nparametro della scala (beta): \\(\\beta_{\\text{post}} = \\beta + \\sum_{i=1}^{n} x_i\\).\n\nQuindi, la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\) segue una distribuzione Gamma con parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_i).\n\\]\nQuesta derivazione mostra come l’informazione contenuta nei dati osservati venga incorporata nei parametri della distribuzione a posteriori, mantenendo la forma della distribuzione a priori grazie alla proprietà coniugata.\n\n51.4.2 Calcolo dei Parametri Aggiornati\nPer il caso dell’esempio in discussione:\n\nIl numero di osservazioni nel campione \\(n\\) è 15;\nLa somma delle osservazioni nel campione è:\n\n\\[\n\\sum_{i=1}^{n} y_i =\n1 + 9 + 4 + 3 + 1 + 1 + 0 + 6 + 3 + 4 + 0 + 11 + 5 + 1 + 1 = 50.\n\\]\nLa distribuzione a posteriori per \\(\\lambda\\) segue una distribuzione Gamma aggiornata con i seguenti parametri:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + n,\n\\]\n\\[\n\\beta_{\\text{post}} = \\beta_{\\text{prior}} + \\sum_{i=1}^{n} y_i.\n\\]\nUsando i valori \\(\\alpha_{\\text{prior}} = 0.009\\) e \\(\\beta_{\\text{prior}} = 0.03\\), otteniamo:\n\\[\n\\alpha_{\\text{post}} = 0.009 + 15 = 15.009,\n\\]\n\\[\n\\beta_{\\text{post}} = 0.03 + 50 = 50.03.\n\\]\n\n# Dati iniziali\nalpha_prior &lt;- 0.009\nbeta_prior &lt;- 0.03\nn &lt;- 15\ny &lt;- c(1, 9, 4, 3, 1, 1, 0, 6, 3, 4, 0, 11, 5, 1, 1)\nsum_y &lt;- sum(y)\n\n# Parametri aggiornati\nalpha_post &lt;- alpha_prior + n\nbeta_post &lt;- beta_prior + sum_y\n\n# Stampa dei parametri aggiornati\ncat(sprintf(\"alpha_post = %.3f; beta_post = %.3f\\n\", alpha_post, beta_post))\n#&gt; alpha_post = 15.009; beta_post = 50.030\n\nGeneriamo il grafico della distribuzione a posteriori.\n\n# Griglia di valori di lambda per il grafico\nlambda_grid &lt;- seq(0, 2, length.out = 1000)\n\n# Calcolo della densità della distribuzione Gamma a posteriori\nposterior_pdf &lt;- dgamma(lambda_grid, shape = alpha_post, rate = beta_post)\n\n# Creazione del grafico\nplot(\n  lambda_grid, posterior_pdf,\n  type = \"l\", lwd = 2,\n  main = bquote(\n    \"Distribuzione Gamma a Posteriori con \" ~ alpha[post] ==\n      .(alpha_post) ~ \",\" ~ beta[post] == .(beta_post)\n  ),\n  xlab = expression(lambda), ylab = \"Densità di probabilità\"\n)\nlegend(\n  \"topright\",\n  legend = bquote(\n    Gamma(alpha[post] == .(alpha_post) ~ \",\" ~ beta[post] == .(beta_post))\n  ),\n  lty = 1,\n  lwd = 2,\n  bty = \"n\"\n)\n\n\n\n\n\n\n\n\n51.4.3 Calcolo della Media e della Varianza a Posteriori\nLa media e la varianza della distribuzione a posteriori sono calcolate come:\n\\[\n\\text{E}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}},\n\\]\n\\[\n\\text{Var}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}^2}.\n\\]\nIn R:\n\n# Calcolo della media e della varianza a posteriori\nposterior_mean &lt;- alpha_post / beta_post\nposterior_variance &lt;- alpha_post / (beta_post^2)\n\n# Stampa dei risultati\ncat(sprintf(\"Media a posteriori di λ: %.3f\\n\", posterior_mean))\n#&gt; Media a posteriori di λ: 0.300\ncat(sprintf(\"Varianza a posteriori di λ: %.6f\\n\", posterior_variance))\n#&gt; Varianza a posteriori di λ: 0.005996\n\nLa distribuzione a posteriori di \\(\\lambda\\) è aggiornata in base ai dati osservati e al prior. La media a posteriori rappresenta la stima del tasso di occorrenza degli episodi di ansia, mentre la varianza riflette l’incertezza nella stima.\n\n\nMedia a Posteriori: La media a posteriori di \\(\\lambda\\) è circa 0.3, indicando un tasso di occorrenza medio di 0.3 episodi per ora.\n\nVarianza a Posteriori: La varianza di 0.006 riflette una moderata incertezza nella stima di \\(\\lambda\\).\n\nQuesti risultati evidenziano come la distribuzione Gamma aggiornata combini informazioni a priori e dati osservati per ottenere stime robuste del tasso di occorrenza \\(\\lambda\\).\n\n51.4.4 Trasformazione della media e della varianza\nPer interpretare questi risultati in termini di tempi di attesa, dobbiamo trasformare i valori sulla scala inversa, cioè passare dal tasso \\(\\lambda\\) ai tempi di attesa \\(T = \\frac{1}{\\lambda}\\).\nLa media del tempo di attesa \\(T\\) è l’inverso della media del tasso di occorrenza \\(\\lambda\\). Pertanto, la media dei tempi di attesa sarà:\n\\[\n\\text{E}[T \\mid y] = \\frac{1}{\\text{E}[\\lambda \\mid y]} = \\frac{1}{0.3} \\approx 3.33 \\, \\text{ore}.\n\\]\nPer la varianza del tempo di attesa, dobbiamo applicare una trasformazione più complessa. La varianza del tempo di attesa \\(T\\) è legata alla varianza di \\(\\lambda\\) da:\n\\[\n\\text{Var}(T) = \\frac{\\text{Var}[\\lambda \\mid y]}{(\\text{E}[\\lambda \\mid y])^4}.\n\\]\nSostituendo i valori calcolati per la varianza e la media di \\(\\lambda\\), otteniamo:\n\\[\n\\text{Var}(T) \\approx \\frac{0.006}{(0.3)^4} \\approx 24.59 \\, \\text{ore}.\n\\]\nIn conclusione,\n\nla media del tempo di attesa a posteriori è di circa 3.33 ore;\nla varianza del tempo di attesa a posteriori è di circa 24.59 ore, che indica una certa dispersione dei tempi di attesa, con alcuni episodi che possono verificarsi molto più rapidamente o più lentamente rispetto alla media. Si noti che la distribuzione a posteriori è più concentrata rispetto al prior, poiché incorpora l’informazione aggiuntiva proveniente dai dati osservati.\n\nQuesta trasformazione ci permette di interpretare i risultati sulla scala dei tempi di attesa, che è più intuitiva per descrivere fenomeni psicologici come l’insorgenza di episodi di ansia.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_exponential_model.html#applicazioni",
    "href": "chapters/bayesian_inference/11_gamma_exponential_model.html#applicazioni",
    "title": "51  Modello gamma-esponenziale",
    "section": "\n51.5 Applicazioni",
    "text": "51.5 Applicazioni\nUna volta ottenuta la distribuzione a posteriori per λ, possiamo utilizzarla per rispondere a domande probabilistiche relative ai tempi di attesa tra episodi di ansia. Questo approccio ci consente di calcolare probabilità aggiornate alla luce dei dati osservati, rispecchiando meglio l’incertezza e le informazioni disponibili. Ad esempio, possiamo stimare la probabilità di osservare tempi di attesa compresi tra 2 e 5 ore.\nPer risolvere questo problema possiamo usare il metodo Monte Carlo:\n\nGeneriamo un gran numero di campioni dalla distribuzione Gamma a posteriori di \\(\\lambda\\), usando i parametri \\(\\alpha_{\\text{posteriori}}\\) e \\(\\beta_{\\text{posteriori}}\\).\nConvertiamo ciascun \\(\\lambda\\) campionato in un tempo di attesa \\(T = \\frac{1}{\\lambda}\\).\nCalcoliamo le probabilità richieste (ad esempio, \\(P(T &gt; 2)\\) e \\(P(T &lt; 5)\\)) semplicemente contando le proporzioni di campioni che soddisfano tali condizioni.\n\n\n51.5.1 Simulazione con Monte Carlo\nUtilizziamo i parametri posteriori della distribuzione Gamma per simulare campioni di \\(\\lambda\\) e calcolare la probabilità che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore.\n\n# Parametri posteriori per la distribuzione Gamma\nalpha_post &lt;- 15.009\nbeta_post &lt;- 50.03\n\n# Numero di campioni da generare\nn_samples &lt;- 100000\n\n# Simulazione di campioni dalla distribuzione Gamma per λ\nlambda_samples &lt;- rgamma(n_samples, shape = alpha_post, rate = beta_post)\n\n# Conversione dei campioni di λ in tempi di attesa T = 1/λ\nwaiting_time_samples &lt;- 1 / lambda_samples\n\n# Calcolo della probabilità che il tempo di attesa sia compreso tra 2 e 5 ore\nprob_between_2_and_5_mc &lt;-\n  mean(waiting_time_samples &gt;= 2 & waiting_time_samples &lt;= 5)\n\n# Stampa del risultato\ncat(sprintf(\"Probabilità che il tempo di attesa sia tra 2 e 5 ore: %.4f\\n\", prob_between_2_and_5_mc))\n#&gt; Probabilità che il tempo di attesa sia tra 2 e 5 ore: 0.9027\n\nLa probabilità che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore è di circa 0.9029, ovvero il 90.3%. Questa stima si basa su campioni simulati dalla distribuzione a posteriori di \\(\\lambda\\), trasformati nei corrispondenti tempi di attesa. L’approccio Monte Carlo è utile per calcolare probabilità che coinvolgono trasformazioni non lineari, come nel caso del tempo di attesa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_exponential_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/11_gamma_exponential_model.html#riflessioni-conclusive",
    "title": "51  Modello gamma-esponenziale",
    "section": "\n51.6 Riflessioni Conclusive",
    "text": "51.6 Riflessioni Conclusive\nIl modello esponenziale si rivela uno strumento utile e versatile nella ricerca psicologica, in particolare per la modellazione di fenomeni caratterizzati da tempi di attesa o durate di eventi. È applicabile in vari contesti, tra cui l’analisi dei tempi di reazione, lo studio degli intervalli tra episodi di ansia o depressione e, più in generale, in tutti quei processi psicologici che possono essere descritti come il tempo trascorso fino al verificarsi di un evento.\nUn aspetto particolarmente vantaggioso dell’uso di modelli basati sulla distribuzione esponenziale nell’inferenza bayesiana è la possibilità di utilizzare le famiglie coniugate. Nella famiglia coniugata Gamma-Esponenziale, la distribuzione a priori Gamma per il tasso \\(\\lambda\\) si aggiorna in modo analitico quando si osservano nuovi dati esponenziali. Questo rende i calcoli bayesiani particolarmente efficienti e semplici da implementare, poiché la distribuzione a posteriori rimane della stessa forma della distribuzione a priori (ossia, una Gamma). Tale proprietà coniugata consente di ottenere una stima aggiornata del tasso \\(\\lambda\\) e di fare inferenze accurate sui tempi di attesa futuri.\nLa combinazione tra la distribuzione esponenziale e il prior Gamma non solo semplifica l’inferenza, ma fornisce anche una struttura interpretativa chiara. Ad esempio, il parametro \\(\\lambda\\), che rappresenta il tasso di occorrenza di un fenomeno, viene aggiornato sulla base dell’evidenza osservata, consentendo una stima dinamica della frequenza con cui gli episodi si verificano. Questo approccio bayesiano offre un’interpretazione probabilistica naturale dei tempi di attesa futuri, rispecchiando l’incertezza presente nei dati.\nInoltre, grazie alla flessibilità del metodo Monte Carlo, è possibile simulare campioni dalla distribuzione a posteriori di \\(\\lambda\\) e ottenere stime precise per una vasta gamma di probabilità, come la probabilità che il tempo di attesa sia compreso tra intervalli specifici. Questo approccio simulativo permette di rispondere a domande specifiche relative ai processi psicologici, ad esempio la probabilità che un episodio di ansia duri più di un certo numero di ore.\nIn conclusione, il modello esponenziale, integrato in un framework bayesiano con famiglie coniugate, rappresenta un utile strumento per la ricerca psicologica. Offre un modo rigoroso per modellare e analizzare dati su tempi di attesa e durate, fornendo al contempo una base solida per l’inferenza e la previsione dei processi psicologici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/11_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "51  Modello gamma-esponenziale",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_post_pred_distr.html",
    "href": "chapters/bayesian_inference/12_post_pred_distr.html",
    "title": "52  Distribuzione predittiva a posteriori",
    "section": "",
    "text": "52.1 Introduzione\nNel contesto dell’inferenza bayesiana, uno degli obiettivi principali è non solo stimare i parametri di un modello (ad esempio, la probabilità \\(p\\) di successo in un esperimento binomiale) ma anche fare previsioni su dati futuri basandosi su ciò che abbiamo osservato. La distribuzione predittiva a posteriori risponde proprio a questa esigenza, combinando:\nIn termini semplici, la distribuzione predittiva a posteriori ci dice quali risultati futuri sono plausibili, dato ciò che sappiamo dai dati osservati e dal modello.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_post_pred_distr.html#introduzione",
    "href": "chapters/bayesian_inference/12_post_pred_distr.html#introduzione",
    "title": "52  Distribuzione predittiva a posteriori",
    "section": "",
    "text": "La nostra incertezza sui parametri descritta dalla distribuzione a posteriori.\nLa variabilità intrinseca del processo che genera i dati futuri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_post_pred_distr.html#definizione-formale",
    "href": "chapters/bayesian_inference/12_post_pred_distr.html#definizione-formale",
    "title": "52  Distribuzione predittiva a posteriori",
    "section": "\n52.2 Definizione Formale",
    "text": "52.2 Definizione Formale\nSupponiamo di avere un insieme di dati osservati \\(y = \\{y_1, y_2, \\ldots, y_n\\}\\), generati da un modello che dipende da un parametro sconosciuto \\(\\theta\\). Il parametro \\(\\theta\\) può rappresentare qualsiasi caratteristica del modello, come una probabilità di successo, una media, o un coefficiente in un modello di regressione. Inizialmente, la nostra conoscenza su \\(\\theta\\) è rappresentata dalla distribuzione a priori \\(p(\\theta)\\), che riflette ciò che sappiamo (o non sappiamo) su \\(\\theta\\) prima di osservare i dati.\nDopo aver osservato i dati \\(y\\), possiamo aggiornare la nostra conoscenza su \\(\\theta\\) utilizzando la formula di Bayes per calcolare la distribuzione a posteriori \\(p(\\theta \\mid y)\\):\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{p(y)},\n\\]\ndove:\n\n\\(p(\\theta \\mid y)\\): la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\theta\\) dopo aver osservato i dati.\n\\(p(y \\mid \\theta)\\): la verosimiglianza è la probabilità di osservare i dati dati i parametri del modello.\n\\(p(\\theta)\\): la distribuzione a priori rappresenta la conoscenza iniziale su \\(\\theta\\).\n\n\\(p(y)\\): l’evidenza è la probabilità totale dei dati osservati, calcolata come:\n\\[\np(y) = \\int p(y \\mid \\theta) p(\\theta) \\, d\\theta.\n\\]\n\n\n\n52.2.1 Previsione di Nuovi Dati\n\nQuando vogliamo prevedere un nuovo dato, indicato con \\(\\tilde{y}\\), la nostra attenzione si sposta sulla distribuzione predittiva a posteriori, \\(p(\\tilde{y} \\mid y)\\).\n\n52.2.1.1 Cosa rappresenta \\(\\tilde{y}\\)?\n\n\n\\(\\tilde{y}\\) rappresenta un dato futuro o non osservato. Ad esempio, se i dati \\(y\\) rappresentano il numero di successi osservati in una serie di lanci di una moneta, \\(\\tilde{y}\\) potrebbe rappresentare il numero di successi in una nuova serie di lanci.\nL’obiettivo è stimare \\(p(\\tilde{y} \\mid y)\\), cioè la probabilità del nuovo dato \\(\\tilde{y}\\) dato ciò che abbiamo osservato in \\(y\\).\n\n52.2.1.2 Cosa rappresenta \\(p(\\tilde{y} \\mid \\theta)\\)?\n\n\n\\(p(\\tilde{y} \\mid \\theta)\\) è la probabilità del nuovo dato \\(\\tilde{y}\\) dato un particolare valore del parametro \\(\\theta\\).\nAd esempio, in un modello binomiale, \\(p(\\tilde{y} \\mid \\theta)\\) corrisponde alla probabilità di ottenere \\(\\tilde{y}\\) successi su \\(n_{\\text{new}}\\) prove, data la probabilità di successo \\(\\theta\\).\n\n52.2.1.3 Combinazione di \\(p(\\tilde{y} \\mid \\theta)\\) con \\(p(\\theta \\mid y)\\)\n\nPoiché non conosciamo esattamente \\(\\theta\\), dobbiamo considerare tutte le possibili ipotesi su \\(\\theta\\), pesandole in base alla loro probabilità a posteriori \\(p(\\theta \\mid y)\\). Questo porta alla formula per la distribuzione predittiva a posteriori:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\, d\\theta.\n\\]\n\n52.2.1.4 Interpretazione\n\nLa distribuzione predittiva a posteriori, \\(p(\\tilde{y} \\mid y)\\), rappresenta la nostra miglior stima della probabilità del nuovo dato \\(\\tilde{y}\\), tenendo conto sia dei dati osservati \\(y\\) sia dell’incertezza su \\(\\theta\\).\n\n52.2.2 Caso Discreto\nSe il parametro \\(\\theta\\) assume un numero finito di valori, l’integrale si semplifica in una somma:\n\\[\np(\\tilde{y} \\mid y) = \\sum_{\\theta} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y).\n\\]\nQuesto approccio è utile nei modelli discreti o quando si approssimano i parametri con un numero finito di valori campionati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_post_pred_distr.html#il-caso-beta-binomiale",
    "href": "chapters/bayesian_inference/12_post_pred_distr.html#il-caso-beta-binomiale",
    "title": "52  Distribuzione predittiva a posteriori",
    "section": "\n52.3 Il Caso Beta-Binomiale",
    "text": "52.3 Il Caso Beta-Binomiale\nConsideriamo un classico esperimento binomiale: lanciare una moneta \\(n\\) volte e osservare il numero di successi \\(y\\) (ad esempio, il numero di “teste”). In un contesto bayesiano, il processo di analisi si articola in tre fasi:\n\n\nDistribuzione a Priori: Prima di osservare i dati, formuliamo una distribuzione a priori sulla probabilità \\(p\\) di successo, che riflette le nostre conoscenze iniziali (o la loro assenza). Una scelta comune è la distribuzione Beta(\\(\\alpha, \\beta\\)), perché è flessibile e ben definita per probabilità. Per esempio:\n\n\n\\(\\alpha\\) rappresenta il numero “fittizio” di successi osservati.\n\n\\(\\beta\\) rappresenta il numero “fittizio” di insuccessi osservati.\n\n\n\nDistribuzione a Posteriori: Dopo aver osservato \\(y\\) successi su \\(n\\) prove, aggiorniamo la distribuzione a priori combinandola con i dati osservati, ottenendo la distribuzione a posteriori di \\(p\\):\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + y, \\quad \\beta_{\\text{post}} = \\beta_{\\text{prior}} + (n - y).\n\\]\nQuesta distribuzione rappresenta ciò che sappiamo di \\(p\\) dopo aver osservato i dati.\n\n\nDistribuzione Predittiva a Posteriori: Per prevedere il numero di successi futuri \\(y_{\\text{new}}\\) in un nuovo esperimento con \\(n_{\\text{new}}\\) prove, combiniamo la distribuzione a posteriori di \\(p\\) con la variabilità intrinseca del processo binomiale. In pratica:\n\nCampioniamo \\(p\\) dalla distribuzione a posteriori (\\(p \\sim \\text{Beta}(\\alpha_{\\text{post}}, \\beta_{\\text{post}})\\)).\nUsiamo ciascun campione di \\(p\\) per simulare nuovi dati (\\(y_{\\text{new}} \\sim \\text{Binomiale}(n_{\\text{new}}, p)\\)).\n\n\n\nQuesto processo tiene conto sia dell’incertezza sui parametri (\\(p\\)) sia della variabilità intrinseca nei dati futuri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_post_pred_distr.html#simulazione-della-distribuzione-predittiva-a-posteriori",
    "href": "chapters/bayesian_inference/12_post_pred_distr.html#simulazione-della-distribuzione-predittiva-a-posteriori",
    "title": "52  Distribuzione predittiva a posteriori",
    "section": "\n52.4 Simulazione della Distribuzione Predittiva a Posteriori",
    "text": "52.4 Simulazione della Distribuzione Predittiva a Posteriori\n\n52.4.1 Impostazione dei Parametri\n\nSupponiamo di aver osservato \\(y = 70\\) successi su \\(n = 100\\) prove.\nUtilizziamo una distribuzione a priori Beta(\\(2, 2\\)), che rappresenta una conoscenza iniziale debolmente informativa, con una leggera preferenza per \\(p \\approx 0.5\\).\n\n52.4.2 Calcolo della Distribuzione a Posteriori\n\n\nAggiorniamo la distribuzione a priori con i dati osservati. I parametri aggiornati sono:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + y = 2 + 70 = 72, \\quad \\beta_{\\text{post}} = \\beta_{\\text{prior}} + (n - y) = 2 + 30 = 32.\n\\]\n\nLa distribuzione a posteriori è quindi \\(p \\sim \\text{Beta}(72, 32)\\), che descrive la probabilità aggiornata di successo basata sui dati.\n\n52.4.3 Simulazione dei Dati Futuri\n\nGeneriamo \\(n_{\\text{sim}} = 1000\\) campioni di \\(p\\) dalla distribuzione a posteriori Beta(72, 32).\n\nPer ogni campione di \\(p\\), simuliamo \\(y_{\\text{new}}\\), il numero di successi futuri su \\(n_{\\text{new}} = 10\\) prove, utilizzando la distribuzione binomiale:\n\\[\ny_{\\text{new}} \\sim \\text{Binomiale}(n_{\\text{new}} = 10, p).\n\\]\n\n\nInfine, convertiamo \\(y_{\\text{new}}\\) in proporzioni predette:\n\\[\n\\text{Proporzione predetta} = \\frac{y_{\\text{new}}}{n_{\\text{new}}}.\n\\]\n\n\n\n# Impostazione del seed per riproducibilità\nset.seed(123)\n\n# Parametri osservati\ny &lt;- 70\nn &lt;- 100\n\n# Parametri a priori\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\n\n# Calcolo dei parametri a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Simulazione della distribuzione a posteriori\np_samples &lt;- rbeta(1000, alpha_post, beta_post)\n\n# Simulazione di nuovi dati per n_new = 10\ny_preds &lt;- sapply(p_samples, function(p) {\n  rbinom(1, 10, p)\n})\n\n# Calcolo delle proporzioni predette\nprop_preds &lt;- y_preds / 10\n\n\n52.4.4 Risultati Attesi\n\n\nDistribuzione a Posteriori di \\(p\\):\n\nCentrata attorno a \\(0.7\\), con una varianza ridotta grazie alla dimensione del campione \\(n = 100\\).\n\n\n\nDistribuzione Predittiva per \\(n_{\\text{new}} = 10\\):\n\nVariabilità più ampia rispetto a \\(p\\), dovuta al numero ridotto di prove (\\(n_{\\text{new}} = 10\\)).\nRiflette sia l’incertezza su \\(p\\) sia la variabilità intrinseca dei dati futuri.\n\n\n\n\n# Visualizzazione\npar(mfrow = c(1, 2))\ncurve(dbeta(x, alpha_prior, beta_prior), from = 0, to = 1, \n      main = \"Distribuzione a Priori\", col = \"blue\", lwd = 2)\ncurve(dbeta(x, alpha_post, beta_post), from = 0, to = 1, \n      main = \"Distribuzione a Posteriori\", col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\nhist(prop_preds, breaks = 20, col = \"lightblue\", freq = FALSE,\n     main = \"Distribuzione Predittiva (n_new = 10)\",\n     xlab = \"Proporzione di Successi\")\nabline(v = y / n, col = \"blue\", lwd = 3, lty = 2)\n\n\n\n\n\n\n\n\n52.4.5 Spiegazione del Codice\nSimulazione di nuovi dati per \\(n_{\\text{new}} = 10\\):\ny_preds &lt;- sapply(p_samples, function(p) {\n  rbinom(1, 10, p)\n})\n\n\np_samples contiene \\(1000\\) valori di \\(p\\) simulati dalla distribuzione Beta(72, 32).\nPer ciascun \\(p\\), rbinom(1, 10, p) genera un valore di \\(y_{\\text{new}}\\), simulando il numero di successi futuri su \\(n_{\\text{new}} = 10\\) prove.\n\nRisultato: un vettore di 1000 valori di \\(y_{\\text{new}}\\), uno per ciascun campione di \\(p\\).\nCalcolo delle proporzioni predette:\nprop_preds &lt;- y_preds / 10\n\nDivide ciascun valore di \\(y_{\\text{new}}\\) per \\(n_{\\text{new}} = 10\\), ottenendo le proporzioni di successi predette.\n\nRisultato: un vettore di 1000 proporzioni predette (\\(y_{\\text{new}} / n_{\\text{new}}\\)).\n\n52.4.6 Interpretazione\n\nLa distribuzione a posteriori di \\(p\\), Beta(72, 32), è centrata attorno a \\(p \\approx 0.7\\), coerente con i dati osservati (\\(y / n = 0.7\\)).\nLe proporzioni predette mostrano la variabilità combinata dell’incertezza su \\(p\\) (dalla distribuzione a posteriori) e della variabilità binomiale per un campione futuro di 10 prove.\nL’istogramma delle proporzioni predette è più ampio rispetto alla distribuzione a posteriori di \\(p\\), riflettendo l’incertezza aggiuntiva derivante dal numero ridotto di prove (\\(n_{\\text{new}} = 10\\)).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_post_pred_distr.html#posterior-predictive-check-pp-check",
    "href": "chapters/bayesian_inference/12_post_pred_distr.html#posterior-predictive-check-pp-check",
    "title": "52  Distribuzione predittiva a posteriori",
    "section": "\n52.5 Posterior Predictive Check (PP-Check)",
    "text": "52.5 Posterior Predictive Check (PP-Check)\nLa distribuzione predittiva a posteriori ottenuta dalla simulazione (\\(n_{\\text{new}} = 10\\)) può essere utilizzata per effettuare un Posterior Predictive Check (PP-Check). Questo controllo confronta i dati osservati con i dati simulati dal modello per verificare se il modello è in grado di riprodurre caratteristiche rilevanti dei dati osservati.\nIn questa simulazione, il Posterior Predictive-Check suggerisce che il modello è ben specificato per i dati osservati (\\(y = 70\\), \\(n = 100\\)): la proporzione osservata (\\(0.7\\)) è vicina al centro della distribuzione predittiva. Questo significa che il modello può essere considerato valido per fare previsioni sui dati futuri, almeno nel contesto specificato.\n\n\n\n\n\n\nIl fatto che la distribuzione predittiva a posteriori rappresenti accuratamente la proporzione osservata può sembrare ovvio nel caso presente. Questo avviene perché stiamo lavorando con un modello semplice e ben specificato, utilizzato qui con l’intento di chiarire la logica del concetto di distribuzione predittiva a posteriori. Tuttavia, nei modelli più complessi, tipici delle indagini psicologiche, la corrispondenza tra i dati osservati e quelli predetti dal modello non può mai essere data per scontata. È essenziale verificarla attraverso la distribuzione predittiva a posteriori.\nSe i dati osservati non sono ben rappresentati dalla distribuzione predittiva a posteriori, ciò indica che il modello non è adeguato a spiegare i dati e necessita di revisione. Questo processo di verifica non solo garantisce la coerenza del modello con i dati disponibili, ma consente anche di identificare eventuali aree problematiche nella specificazione del modello, come prior inappropriati o assunzioni non realistiche. In definitiva, il confronto tra i dati osservati e quelli predetti è un passo fondamentale per la validazione di modelli complessi in contesti psicologici e scientifici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_post_pred_distr.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/12_post_pred_distr.html#riflessioni-conclusive",
    "title": "52  Distribuzione predittiva a posteriori",
    "section": "\n52.6 Riflessioni Conclusive",
    "text": "52.6 Riflessioni Conclusive\nLa distribuzione predittiva a posteriori è uno strumento centrale nell’inferenza bayesiana, poiché consente di fare previsioni sui dati futuri integrando l’incertezza sui parametri del modello con la variabilità intrinseca del processo generativo. Questa capacità va oltre la semplice stima dei parametri, permettendo di confrontare le previsioni del modello con i dati reali, un passaggio fondamentale per verificare la coerenza e l’utilità del modello stesso.\nNel flusso di lavoro bayesiano, la distribuzione predittiva a posteriori svolge un ruolo chiave nella valutazione del modello. Ad esempio, consente di effettuare controlli predittivi a posteriori per identificare discrepanze tra i dati osservati e quelli previsti. Tali controlli aiutano a diagnosticare problemi di specificazione del modello, a valutare l’adeguatezza delle scelte a priori e a guidare eventuali revisioni del modello.\nInoltre, il caso beta-binomiale utilizzato in questo capitolo rappresenta un esempio intuitivo e potente: evidenzia come l’incertezza sui parametri possa essere tradotta in previsioni probabilistiche robuste, senza la necessità di fare assunzioni rigide o non realistiche. Questo approccio non solo formalizza l’incertezza in modo rigoroso, ma permette anche di comunicare le previsioni in modo trasparente e interpretabile, caratteristiche essenziali in ambito decisionale e scientifico.\nIn sintesi, la distribuzione predittiva a posteriori è un elemento fondamentale della modellazione bayesiana, che lega l’inferenza paramatrica alla previsione empirica, contribuendo a rendere l’intero processo inferenziale più affidabile, interpretabile e applicabile a scenari complessi.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/12_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "52  Distribuzione predittiva a posteriori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_post_pred_distr.html#bibliografia",
    "href": "chapters/bayesian_inference/12_post_pred_distr.html#bibliografia",
    "title": "52  Distribuzione predittiva a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSchoot, R. van de, Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., et al. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1), 1.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/introduction_mcmc.html",
    "href": "chapters/mcmc/introduction_mcmc.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, ci concentreremo sulle procedure Monte Carlo a catena di Markov, con particolare attenzione all’algoritmo di Metropolis, che consente di approssimare la distribuzione a posteriori quando non è possibile ottenere una soluzione analitica. Esploreremo il concetto di predizione bayesiana, fondamentale per la costruzione della distribuzione predittiva a posteriori, e discuteremo anche la distribuzione predittiva a priori. Applicheremo l’inferenza bayesiana a diversi contesti, tra cui la stima di una proporzione, il confronto tra due proporzioni, la stima di una media da una distribuzione normale e il confronto tra due medie. Esamineremo inoltre il modello bayesiano di Poisson per l’analisi delle frequenze. Infine, introdurremo il modello gerarchico bayesiano, uno strumento potente per affrontare situazioni in cui le osservazioni sono strutturate su diversi livelli di incertezza.",
    "crumbs": [
      "MCMC",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html",
    "href": "chapters/mcmc/01_metropolis.html",
    "title": "53  L’algoritmo di Metropolis-Hastings",
    "section": "",
    "text": "53.1 Introduzione\nIn precedenza, abbiamo esplorato diversi esempi di inferenza bayesiana riguardanti la distribuzione a posteriori di un singolo parametro, come nel caso del modello bernoulliano. Abbiamo anche trattato metodi come l’approssimazione tramite griglia e l’utilizzo dei priori coniugati per ottenere o approssimare la distribuzione a posteriori. In questo capitolo, ci concentreremo sul metodo di simulazione Monte Carlo a Catena di Markov (MCMC).\nIl metodo MCMC è una tecnica computazionale utilizzata per approssimare distribuzioni di probabilità complesse, generando una sequenza di campioni (correlati) attraverso una catena di Markov, in cui ogni campione viene ottenuto tramite una transizione iterativa con probabilità attentamente progettate.\nIl metodo MCMC rappresenta l’approccio moderno per approssimare distribuzioni a posteriori complesse. L’idea di base è simile al concetto di considerare la distribuzione a posteriori come una popolazione da cui estraiamo campioni ripetutamente. Con un numero sufficientemente grande di campioni (ad esempio 1000), la distribuzione del campione si avvicina molto alla distribuzione della popolazione, consentendo stime affidabili dei parametri incogniti.\nUna differenza rispetto all’analogia precedente è che i campioni generati con MCMC sono correlati: se il primo campione ha un valore alto, anche il successivo ha maggiori probabilità di essere alto. Questo accade perché non abbiamo un modo diretto per estrarre campioni dalla distribuzione a posteriori, che spesso ha una forma molto complessa; utilizziamo invece algoritmi che ci permettono di arrivarci indirettamente. La correlazione tra i campioni non rappresenta un problema rilevante, ma rende necessario estrarre un numero maggiore di campioni per compensare questa correlazione e ottenere stime accurate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "href": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "title": "53  L’algoritmo di Metropolis-Hastings",
    "section": "\n53.2 Il denominatore bayesiano",
    "text": "53.2 Il denominatore bayesiano\nNell’approccio bayesiano, l’obiettivo principale è determinare la distribuzione a posteriori \\(p(\\theta \\mid y)\\) di un parametro \\(\\theta\\), utilizzando i dati osservati \\(y\\) e la distribuzione a priori \\(p(\\theta)\\). Questo si ottiene attraverso il teorema di Bayes:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int p(y \\mid \\theta) p(\\theta) d\\theta}.\n\\]\nIl denominatore \\(\\int p(y \\mid \\theta) p(\\theta) d\\theta\\) rappresenta la probabilità marginale di \\(y\\), chiamata evidenza. Tale integrale garantisce che \\(p(\\theta \\mid y)\\) sia una distribuzione di probabilità valida. Tuttavia, il calcolo di questo integrale è spesso complesso, soprattutto in modelli articolati o ad alta dimensionalità, rendendo difficile ottenere una rappresentazione esplicita della distribuzione a posteriori.\nUna possibile semplificazione analitica è l’uso di distribuzioni a priori coniugate, che offrono una soluzione esatta per la distribuzione a posteriori. Tuttavia, questo approccio è limitato a casi specifici e impone forti vincoli sulla scelta delle distribuzioni a priori e delle verosimiglianze.\nUn approccio più generale è ricorrere a soluzioni numeriche. In precedenza abbiamo discusso il metodo di campionamento a griglia. Tuttavia, i metodi di campionamento a griglia, sebbene efficaci per modelli con pochi parametri, diventano impraticabili man mano che il numero di parametri aumenta, poiché richiedono una copertura densa dell’intero spazio parametrico. Di conseguenza, per modelli più complessi e con più parametri, si rende necessario un metodo che possa esplorare lo spazio dei parametri in maniera più efficiente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-metodo-monte-carlo-e-le-sue-limitazioni",
    "href": "chapters/mcmc/01_metropolis.html#il-metodo-monte-carlo-e-le-sue-limitazioni",
    "title": "53  L’algoritmo di Metropolis-Hastings",
    "section": "\n53.3 Il metodo Monte Carlo e le sue limitazioni",
    "text": "53.3 Il metodo Monte Carlo e le sue limitazioni\nIl metodo Monte Carlo fornisce una soluzione a questo problema generando campioni casuali dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\). L’idea centrale è semplice: se possiamo generare un numero sufficiente di campioni casuali dalla distribuzione a posteriori, possiamo usare questi campioni per stimare le proprietà d’interesse, come la media o la varianza del parametro \\(\\theta\\). Questa procedura ci permette di evitare il calcolo diretto dell’integrale complicato nel denominatore del teorema di Bayes.\nPer esempio, se fossimo in grado di generare una serie di campioni \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\) dalla distribuzione a posteriori, potremmo approssimare il valore atteso di \\(\\theta\\) con la media campionaria:\n\\[\n\\mathbb{E}[\\theta] \\approx \\frac{1}{T} \\sum_{t=1}^T \\theta^{(t)}.\n\\]\nTuttavia, un problema nei metodi Monte Carlo tradizionali è che generare campioni indipendenti dalla distribuzione a posteriori non è semplice, soprattutto quando questa distribuzione ha una forma complessa, è multimodale o definita su spazi di alta dimensionalità. Le regioni di alta densità, che contribuiscono maggiormente al valore dell’integrale, possono essere difficili da individuare e campionare adeguatamente. Per ottenere una buona copertura dello spazio dei parametri, sarebbe necessario generare un numero enorme di campioni, rendendo il metodo Monte Carlo inefficiente e computazionalmente oneroso.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#perché-i-metodi-mcmc-sono-necessari",
    "href": "chapters/mcmc/01_metropolis.html#perché-i-metodi-mcmc-sono-necessari",
    "title": "53  L’algoritmo di Metropolis-Hastings",
    "section": "\n53.4 Perché i metodi MCMC sono necessari",
    "text": "53.4 Perché i metodi MCMC sono necessari\nÈ qui che entrano in gioco i Metodi Monte Carlo a Catena di Markov (MCMC). Questi metodi risolvono il problema generando campioni dipendenti dalla distribuzione a posteriori, sfruttando la struttura di una catena di Markov. A differenza dei campioni indipendenti utilizzati nei metodi Monte Carlo tradizionali, i metodi MCMC costruiscono una sequenza di campioni, in cui ciascun campione dipende dal precedente. Questa dipendenza permette di esplorare in modo più efficiente le regioni di alta densità della distribuzione a posteriori, riducendo il numero di campioni necessari per ottenere stime accurate.\nIn pratica, MCMC consente di evitare di campionare inutilmente da regioni di bassa densità, concentrandosi invece sulle aree più rilevanti della distribuzione. Questo approccio è particolarmente potente nei contesti ad alta dimensionalità o in presenza di distribuzioni multimodali, dove i metodi Monte Carlo tradizionali risulterebbero inefficaci o richiederebbero un numero sproporzionato di campioni.\nIn sintesi, i metodi Monte Carlo classici sono limitati quando si tratta di campionare da distribuzioni complesse e multidimensionali. I metodi MCMC, invece, offrono una soluzione efficiente e flessibile, permettendo di esplorare le distribuzioni a posteriori anche in contesti complessi, senza la necessità di campionare indipendentemente ogni punto. Nel prossimo paragrafo introdurremo i concetti fondamentali delle catene di Markov e vedremo come queste vengono utilizzate nei metodi MCMC per campionare efficacemente da distribuzioni a posteriori difficili da trattare analiticamente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "href": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "title": "53  L’algoritmo di Metropolis-Hastings",
    "section": "\n53.5 Le Catene di Markov",
    "text": "53.5 Le Catene di Markov\nLe catene di Markov, introdotte da Andrey Markov nel 1906, rappresentano un’estensione della legge dei grandi numeri per descrivere sequenze di variabili casuali non indipendenti. Nella statistica tradizionale, si lavora spesso con sequenze di variabili casuali indipendenti e identicamente distribuite (i.i.d.), come \\(X_0, X_1, \\ldots, X_n, \\ldots\\), dove ogni variabile è indipendente dalle altre e segue la stessa distribuzione. Tuttavia, nei modelli più realistici che descrivono fenomeni complessi, l’indipendenza tra variabili è un’assunzione troppo rigida e spesso irrealistica.\nLe catene di Markov superano questo limite introducendo una dipendenza locale, detta dipendenza a un passo, formalizzata nella cosiddetta proprietà di Markov. Secondo questa proprietà, il valore futuro di una variabile casuale \\(X_{n+1}\\) dipende unicamente dal valore attuale \\(X_n\\), ignorando tutta la storia precedente della catena. Questo permette di semplificare notevolmente i calcoli relativi alle probabilità condizionali. La proprietà di Markov è formalmente espressa come:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nIn altre parole, la previsione di un evento futuro dipende soltanto dallo stato attuale e non da tutti gli eventi precedenti, semplificando così il processo di modellazione. Questa caratteristica rende le catene di Markov particolarmente utili per descrivere sistemi dinamici in cui gli eventi successivi sono influenzati solo dallo stato immediatamente precedente.\n\n53.5.1 Catene di Markov e Metodi MCMC\nLe catene di Markov sono fondamentali nei metodi Monte Carlo a Catena di Markov (MCMC) perché forniscono un modo efficiente per generare sequenze di campioni che approssimano distribuzioni di probabilità complesse. Mentre i metodi Monte Carlo classici generano campioni indipendenti, i metodi MCMC costruiscono una sequenza di campioni dipendenti attraverso una catena di Markov, in cui ciascun campione è ottenuto in base al campione precedente. Questo approccio consente di concentrarsi sulle regioni di alta probabilità della distribuzione, migliorando l’efficienza del campionamento.\nPer esempio, consideriamo una distribuzione di probabilità \\(P(x_1, x_2, ..., x_n)\\) definita su un insieme di variabili \\(x_1, x_2, ..., x_n\\). Nei metodi MCMC, si genera una sequenza di configurazioni \\(\\{x(0)\\}, \\{x(1)\\}, \\{x(2)\\}, \\dots\\), tale che la frequenza con cui ogni configurazione \\(\\{x\\}\\) viene visitata è proporzionale alla sua probabilità \\(P(x)\\). In questo modo, le configurazioni più probabili vengono visitate più spesso, garantendo che l’algoritmo converga alla distribuzione di interesse.\n\n53.5.2 Condizioni fondamentali per le Catene di Markov\nAffinché un algoritmo MCMC funzioni correttamente e converga alla distribuzione desiderata, la catena di Markov deve soddisfare alcune condizioni fondamentali:\n\n\nProprietà di Markov: La prossima configurazione dipende solo dalla configurazione attuale, non dalla storia passata. Questo garantisce che l’evoluzione della catena sia “locale” e non influenzata dagli stati remoti.\n\nIrriducibilità: Ogni configurazione della catena può essere raggiunta da qualsiasi altra in un numero finito di passi. Ciò assicura che l’intero spazio dei parametri possa essere esplorato.\n\nAperiodicità: La catena non segue cicli fissi e non ritorna sistematicamente allo stesso stato dopo un certo numero di passi. Questo garantisce che la catena possa esplorare lo spazio dei parametri in modo casuale.\n\nCondizione di bilanciamento dettagliato: La probabilità di passare da uno stato a un altro deve essere bilanciata dalla probabilità di tornare allo stato iniziale, assicurando così che la distribuzione di equilibrio della catena sia proprio la distribuzione a posteriori desiderata.\n\n53.5.3 Algoritmi MCMC\nEsistono diversi algoritmi basati su MCMC, ognuno con caratteristiche specifiche:\n\nMetropolis-Hastings: Questo è uno degli algoritmi più noti. Si basa sulla generazione di una configurazione proposta che viene accettata o rifiutata in base a un criterio di probabilità. Se la configurazione proposta ha una probabilità più alta, viene accettata; se ha una probabilità più bassa, può essere accettata con una certa probabilità, che dipende dal rapporto tra le probabilità delle due configurazioni.\nGibbs Sampling: In questo algoritmo, le variabili vengono aggiornate una alla volta, campionando ogni variabile dalla sua distribuzione condizionale data la configurazione corrente delle altre variabili. È particolarmente utile quando le distribuzioni condizionali sono note o facili da campionare.\nHamiltonian Monte Carlo (HMC): Utilizza principi della meccanica hamiltoniana per esplorare lo spazio dei parametri in modo più efficiente, considerando non solo le probabilità, ma anche le “forze” che muovono i campioni attraverso lo spazio dei parametri. Questo approccio è particolarmente vantaggioso per modelli complessi e ad alta dimensionalità, poiché consente di generare campioni lontani dallo stato corrente senza ricorrere a piccoli passi.\n\nIn sintesi, le catene di Markov forniscono il fondamento teorico e pratico per i metodi MCMC, offrendo un modo efficiente per esplorare lo spazio dei parametri nei modelli complessi. Grazie alle proprietà specifiche delle catene di Markov, i metodi MCMC permettono di affrontare problemi di inferenza bayesiana che sarebbero intrattabili con approcci analitici o con i metodi Monte Carlo classici. Essendo flessibili e potenti, le catene di Markov continueranno a essere uno strumento fondamentale nella statistica e nella scienza dei dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "href": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "title": "53  L’algoritmo di Metropolis-Hastings",
    "section": "\n53.6 Estrazione di campioni dalla distribuzione a posteriori",
    "text": "53.6 Estrazione di campioni dalla distribuzione a posteriori\nIn questo capitolo presenteremo l’algoritmo di Metropolis, che è uno dei più semplici e potenti metodi MCMC. Sfruttando la struttura delle catene di Markov, esplora in modo efficiente lo spazio dei parametri, permettendo di ottenere campioni dalla distribuzione a posteriori anche in casi complessi, dove i metodi analitici falliscono. In sostanza, il MCMC genera un gran numero di valori per il parametro \\(\\theta\\) che, nel loro insieme, approssimano la distribuzione di interesse \\(p(\\theta \\mid y)\\). A questo fine, il capitolo è strutturato in varie sezioni che facilitano la comprensione progressiva del tema.\n\nInizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o “a posteriori,” sia già conosciuta o disponibile per l’analisi.\nIn seguito, passeremo a illustrare come l’algoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non è direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un’approssimazione efficace della distribuzione a posteriori.\n\nA titolo esemplificativo, utilizzeremo il dataset moma_sample.csv, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.\nIl nostro interesse è focalizzato sulla determinazione della probabilità che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilità sarà indicata come \\(\\pi\\).\nImportiamo i dati.\n\nmoma_sample &lt;- rio::import(here::here(\"data\", \"moma_sample.csv\"))\n\nEsaminiamo le prime cinque righe del DataFrame.\n\nmoma_sample |&gt; \n  head()\n#&gt;                artist  country birth death alive  genx gender count\n#&gt; 1        Ad Gerritsen    dutch  1940  2015 FALSE FALSE   male     1\n#&gt; 2 Kirstine Roepstorff   danish  1972    NA  TRUE  TRUE female     3\n#&gt; 3    Lisa Baumgardner american  1958  2015 FALSE FALSE female     2\n#&gt; 4         David Bates american  1952    NA  TRUE FALSE   male     1\n#&gt; 5          Simon Levy american  1946    NA  TRUE FALSE   male     1\n#&gt; 6      Pierre Mercure canadian  1927  1966 FALSE FALSE   male     8\n#&gt;   year_acquired_min year_acquired_max\n#&gt; 1              1981              1981\n#&gt; 2              2005              2005\n#&gt; 3              2016              2016\n#&gt; 4              2001              2001\n#&gt; 5              2012              2012\n#&gt; 6              2008              2008\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\n# Calcoliamo la distribuzione delle generazioni\nresult &lt;- table(moma_sample$genx)\nresult\n#&gt; \n#&gt; FALSE  TRUE \n#&gt;    86    14\n\nIl valore campionato \\(y = 14\\) riflette le caratteristiche del campione che è stato osservato. Tuttavia, poiché il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di \\(\\theta\\) (la probabilità di appartenere alla generazione X o a una generazione successiva) all’interno di questa popolazione.\nPossiamo interpretare i dati \\(y = 14\\) come l’esito di una variabile casuale Binomiale con parametri \\(N = 100\\) e \\(\\theta\\) sconosciuto.\nSupponiamo che le nostre credenze pregresse riguardo a \\(\\theta\\) possano essere modellate attraverso una distribuzione Beta(4, 6).\nSfruttando le proprietà delle distribuzioni coniugate, possiamo calcolare esattamente la distribuzione a posteriori:\n# Y ~ Binomiale(100, π)\n# θ ~ Beta(4, 6)\n# Posteriori: θ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) → Beta(18, 92)\nNella figura seguente, è rappresentata la distribuzione a posteriori del parametro \\(\\theta\\), insieme alla distribuzione a priori specificata.\n\n# Generiamo la sequenza dei valori per θ\nx &lt;- seq(0, 1, length.out = 1000)\n\n# Calcoliamo le densità della prior e della posterior\nprior_density &lt;- dbeta(x, 4, 6)\nposterior_density &lt;- dbeta(x, 18, 92)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  x = x,\n  prior = prior_density,\n  posterior = posterior_density\n)\n\n# Convertiamo i dati in formato \"lungo\" per facilitare la visualizzazione con ggplot2\ndf_long &lt;- reshape2::melt(df, id.vars = \"x\", \n                          measure.vars = c(\"prior\", \"posterior\"),\n                          variable.name = \"distribuzione\", value.name = \"densita\")\n\n# Creare il grafico con ggplot2\nggplot(df_long, aes(x = x, y = densita, fill = distribuzione)) +\n  geom_line(aes(color = distribuzione), size = 1) +  # Aggiungere le linee per le distribuzioni\n  geom_area(aes(fill = distribuzione), alpha = 0.5, position = \"identity\") +  # Aggiungere le aree sotto le curve\n  scale_fill_manual(\n    values = c(\"prior\" = adjustcolor(\"blue\", alpha.f = 0.5), \n               \"posterior\" = adjustcolor(\"red\", alpha.f = 0.5)),\n    labels = c(\"Prior: Beta(4, 6)\", \"Posterior: Beta(18, 92)\")\n  ) +\n  scale_color_manual(\n    values = c(\"prior\" = \"blue\", \"posterior\" = \"red\"),\n    labels = c(\"Prior: Beta(4, 6)\", \"Posterior: Beta(18, 92)\")\n  ) +\n  labs(\n    title = \"Densità a Priori e a Posteriori\",\n    x = \"Valore del Parametro\",\n    y = \"Densità\",\n    fill = NULL, color = NULL\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5),  # Centrare il titolo\n    legend.position = \"top\"  # Posizionare la legenda in alto\n  )\n\n\n\n\n\n\n\nIn questo grafico, la curva blu rappresenta la distribuzione a priori \\(\\text{Beta}(4, 6)\\), mentre la curva rossa mostra la distribuzione a posteriori \\(\\text{Beta}(18, 92)\\). La sovrapposizione delle aree evidenzia come l’evidenza fornita dai dati modifichi la conoscenza iniziale sul parametro \\(\\theta\\).\nSe vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto è\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n\\]\n\n53.6.1 Simulazione con distribuzione target nota\nUsiamo ora una simulazione numerica per stimare la media a posteriori di \\(\\theta\\). Conoscendo la forma della distribuzione a posteriori \\(Beta(18, 92)\\), possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un’approssimazione della media a posteriori.\nSe vogliamo ottenere un risultato approssimato con un numero limitato di campioni (ad esempio, 10), possiamo utilizzare la seguente simulazione:\n\n# Generiamo 10 campioni dalla distribuzione Beta(18, 92)\nset.seed(1)  # Per riproducibilità\ny &lt;- rbeta(10, shape1 = 18, shape2 = 92)\ny\n#&gt;  [1] 0.1396 0.1711 0.1319 0.1774 0.1325 0.1844 0.1963 0.1517 0.2418 0.1800\n\n\n# Calcoliamo la media dei campioni\nmean(y)\n#&gt; [1] 0.1707\n\nTuttavia, con soli 10 campioni, l’approssimazione potrebbe non essere molto accurata. Aumentando il numero di campioni, ad esempio a 10.000, possiamo ottenere una stima molto più precisa:\n\n# Generiamo 10.000 campioni e calcoliamo la media\nset.seed(123)  # Per riproducibilità\nmean(rbeta(10000, shape1 = 18, shape2 = 92))\n#&gt; [1] 0.1637\n\nQuando il numero di campioni dalla distribuzione a posteriori diventa molto grande, la media campionaria converge al valore atteso della distribuzione della popolazione. Questo principio non si applica solo alla media, ma anche ad altre statistiche descrittive come la moda e la varianza.\nÈ importante sottolineare che l’applicazione della simulazione di Monte Carlo è efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni Python per estrarre campioni casuali da tale distribuzione. Ciò è stato possibile nel caso della distribuzione a posteriori \\(Beta(18, 92)\\).\nTuttavia, questa situazione ideale non si verifica sempre nella pratica, poiché le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l’espressione\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}\n\\]\nrende impossibile calcolare analiticamente la distribuzione a posteriori di \\(\\theta\\), precludendo quindi l’utilizzo diretto di Python per generare campioni casuali.\nIn queste circostanze, però, è possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l’uso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l’algoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori senza richiedere la conoscenza della sua rappresentazione analitica. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.\n\n53.6.2 Algoritmo di Metropolis\nL’algoritmo di Metropolis appartiene alla famiglia dei metodi Monte Carlo basati su catene di Markov (MCMC), sfruttando le proprietà di queste catene per generare campioni da una distribuzione target. Il suo obiettivo principale è di esplorare lo spazio dei parametri in modo efficiente, producendo campioni che approssimano la distribuzione a posteriori di interesse.\n\n53.6.3 Principio di Funzionamento\nL’algoritmo inizia da un valore iniziale per i parametri e, in ogni iterazione, genera un nuovo campione tramite una distribuzione di proposta (solitamente una distribuzione normale centrata sul valore corrente). Successivamente, decide se accettare il nuovo campione in base al confronto tra le densità posteriori del nuovo campione e di quello precedente. Questa accettazione avviene in modo probabilistico, favorendo campioni con una densità più alta ma consentendo anche l’accettazione di campioni peggiori per evitare che la catena rimanga bloccata in minimi locali.\n\n53.6.4 Burn-in e Convergenza\nPoiché i primi campioni potrebbero non rappresentare bene la distribuzione target, si esclude spesso una porzione iniziale della catena (fase di burn-in). Con il progredire delle iterazioni, i campioni si distribuiscono in accordo con la distribuzione stazionaria desiderata, indipendentemente dallo stato iniziale scelto. Questo processo permette di esplorare lo spazio dei parametri in modo efficiente.\n\n53.6.5 Meccanismo di Accettazione e Rifiuto\nL’algoritmo di Metropolis bilancia due esigenze opposte:\n\n\nEsplorazione di nuove aree dello spazio dei parametri.\n\nSfruttamento delle informazioni già acquisite dai campioni precedenti.\n\nUtilizzando una regola probabilistica per accettare campioni peggiori (con minore densità a posteriori), l’algoritmo evita di restare intrappolato in minimi locali, esplorando così in modo più completo l’intera distribuzione.\n\n53.6.6 Passaggi Fondamentali dell’Algoritmo di Metropolis\n\n\nScelta di uno stato iniziale \\(\\theta_1\\) e impostazione del contatore \\(t = 1\\).\n\nQuesto è il punto di partenza della catena, dove \\(\\theta_1\\) rappresenta il primo campione.\n\n\n\nProposta di un nuovo campione \\(\\theta_p\\).\n\nUn nuovo valore \\(\\theta_p\\) viene generato da una distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\), solitamente una distribuzione normale centrata sul campione corrente \\(\\theta_t\\) con una deviazione standard \\(\\tau\\) che controlla l’ampiezza dei passi.\n\n\n\nVerifica dei vincoli del campione proposto.\n\nSe il nuovo campione deve rispettare dei vincoli (ad esempio, essere compreso tra 0 e 1 per probabilità), campioni non validi vengono automaticamente rifiutati.\n\n\n\nCalcolo del rapporto di accettazione \\(\\alpha\\).\n\nSi calcola \\(\\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)}\\), che rappresenta il rapporto tra le densità a posteriori del nuovo campione \\(\\theta_p\\) e del campione corrente \\(\\theta_t\\). Questo valore guida la decisione di accettazione.\n\n\n\nDecisione di accettazione.\n\nSe \\(\\alpha \\geq 1\\), il nuovo campione \\(\\theta_p\\) viene accettato incondizionatamente.\nSe \\(\\alpha &lt; 1\\), il campione \\(\\theta_p\\) viene accettato con probabilità \\(\\alpha\\). In caso di rifiuto, si mantiene il campione corrente \\(\\theta_t\\) per la prossima iterazione.\n\n\n\nRipetizione del processo.\n\nSi ripetono i passaggi dal 2 al 5 fino a ottenere il numero desiderato di campioni.\n\n\n\n53.6.7 Dettagli Aggiuntivi\n\nDistribuzione di proposta: La distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\) genera nuovi campioni attorno a \\(\\theta_t\\). Tipicamente si usa una normale \\(N(\\theta_t, \\tau)\\), dove \\(\\tau\\) controlla quanto il nuovo campione si discosta da quello corrente. Scegliere un \\(\\tau\\) troppo piccolo può rendere l’esplorazione lenta, mentre un \\(\\tau\\) troppo grande può far rifiutare troppi campioni, riducendo l’efficienza.\nRapporto di accettazione \\(\\alpha\\): Se il nuovo campione ha una densità a posteriori maggiore del campione corrente, viene sempre accettato. Se ha una densità inferiore, viene accettato con probabilità \\(\\alpha\\), il che consente di esplorare anche regioni meno probabili della distribuzione.\nAccettazione probabilistica: Accettare campioni peggiori occasionalmente aiuta l’algoritmo a evitare di bloccarsi in minimi locali. Questo è uno dei punti di forza dell’algoritmo di Metropolis, che garantisce una buona esplorazione dello spazio dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "href": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "title": "53  L’algoritmo di Metropolis-Hastings",
    "section": "\n53.7 Esempio di Implementazione",
    "text": "53.7 Esempio di Implementazione\nPer questa simulazione, adattiamo l’approccio proposto da Elizaveta Semenova, implementando l’algoritmo di Metropolis-Hastings in R. Cominciamo definendo alcune funzioni fondamentali.\nDefiniamo una funzione prior che calcola la densità della distribuzione Beta(4, 6) per un dato valore di \\(\\theta\\):\n\n# Definizione della distribuzione a priori (Beta(4, 6))\nprior &lt;- function(p) {\n  dbeta(p, shape1 = 4, shape2 = 6)\n}\n\nDefiniamo la funzione likelihood, che calcola la densità della verosimiglianza binomiale per 14 successi su 100 prove:\n\n# Definizione della funzione di verosimiglianza (Binomiale \n# con y = 14 su n = 100)\nlikelihood &lt;- function(p) {\n  y &lt;- 14\n  n &lt;- 100\n  dbinom(y, size = n, prob = p)\n}\n\nDefiniamo la funzione posterior, che calcola la densità della distribuzione a posteriori non normalizzata come prodotto tra la distribuzione a priori e la verosimiglianza:\n\n# Definizione della distribuzione a posteriori (non normalizzata)\nposterior &lt;- function(p) {\n  likelihood(p) * prior(p)\n}\n\nLa distribuzione proposta sarà una distribuzione normale centrata sullo stato corrente con una deviazione standard specificata:\n\n# Distribuzione proposta (normale centrata sullo stato corrente)\nproposal_distribution &lt;- function(current_state, proposal_sigma) {\n  rnorm(1, mean = current_state, sd = proposal_sigma)\n}\n\nDefiniamo infine la distribuzione target, che corrisponde alla distribuzione a posteriori:\n\n# Distribuzione target, equivalente alla distribuzione a posteriori\ntarget_distribution &lt;- function(p) {\n  posterior(p)\n}\n\nProcediamo ora con l’implementazione dell’algoritmo di Metropolis-Hastings, considerando i dati relativi agli artisti della Generazione X presenti al MoMA. La distribuzione a priori per \\(\\theta\\) è modellata come una Beta(4, 6).\n\n# Algoritmo di Metropolis-Hastings\nmetropolis_hastings &lt;- function(num_samples, initial_state, proposal_sigma) {\n  # Inizializza lo stato corrente e la lista dei campioni\n  samples &lt;- numeric(num_samples)\n  current_state &lt;- initial_state\n\n  for (i in seq_len(num_samples)) {\n    # Proponi un nuovo stato dalla distribuzione proposta\n    proposed_state &lt;- proposal_distribution(current_state, proposal_sigma)\n\n    # Verifica che il valore proposto sia tra 0 e 1\n    if (proposed_state &gt;= 0 && proposed_state &lt;= 1) {\n      # Calcola il rapporto di accettazione\n      acceptance_ratio &lt;- min(\n        1,\n        target_distribution(proposed_state) / target_distribution(current_state)\n      )\n\n      # Accetta o rifiuta lo stato proposto\n      if (runif(1) &lt; acceptance_ratio) {\n        current_state &lt;- proposed_state\n      }\n    }\n\n    # Registra lo stato corrente (accettato o rifiutato)\n    samples[i] &lt;- current_state\n  }\n\n  return(samples)\n}\n\n\n\n\n\n\n\nPunti Chiave dell’Algoritmo\n\n\n\n\n\nGenerazione dei nuovi stati: Ogni nuovo stato viene proposto campionando da una distribuzione normale centrata sullo stato corrente. Questo approccio consente un’esplorazione sistematica dello spazio dei parametri.\n\n\nControllo dei limiti: Gli stati proposti devono rientrare nell’intervallo [0, 1], poiché rappresentano probabilità. Questo assicura che i valori generati siano validi nel contesto dell’analisi.\n\n\nRapporto di accettazione: La decisione di accettare o rifiutare un nuovo stato è basata sul confronto tra la densità a posteriori del nuovo stato e quella dello stato corrente. Stati più probabili vengono sempre accettati, mentre quelli meno probabili sono accettati con una probabilità proporzionale.\n\n\nMemorizzazione degli stati: Ogni iterazione salva lo stato corrente, sia che il nuovo stato venga accettato sia che venga rifiutato, garantendo una catena continua di valori.\n\n\n\nQuesta implementazione fornisce una stima robusta della distribuzione a posteriori utilizzando una combinazione di una distribuzione a priori e dei dati osservati.\nLa distribuzione normale utilizzata per la proposta è simmetrica, soddisfacendo i requisiti dell’algoritmo di Metropolis. Questa simmetria garantisce che la probabilità di proporre uno stato \\(\\theta_p\\) partendo da \\(\\theta_t\\) sia uguale alla probabilità inversa, assicurando l’equilibrio dettagliato necessario per la corretta convergenza della catena Markoviana.\n\n53.7.1 Esecuzione dell’Algoritmo\n\n# Parametri dell'algoritmo\nnum_samples &lt;- 10000\ninitial_state &lt;- 0.5\nproposal_sigma &lt;- 0.1\n\n# Esecuzione del campionamento\nset.seed(123)  # Per riproducibilità\nsamples &lt;- metropolis_hastings(num_samples, initial_state, proposal_sigma)\n\n\n53.7.2 Analisi dei Risultati\nScartiamo i primi 5000 campioni per considerare solo quelli generati dopo il burn-in:\n\nburnin &lt;- floor(num_samples * 0.5)\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\nCalcoliamo la media e la deviazione standard dei campioni:\n\n# Media a posteriori\nmean(post_burnin_samples)\n#&gt; [1] 0.1631\n\n# Deviazione standard a posteriori\nsd(post_burnin_samples)\n#&gt; [1] 0.03535\n\nVisualizziamo l’evoluzione della catena per i primi 200 campioni e per quelli post-burn-in:\n\n# Trace plot dei primi 200 campioni\nplot(\n  samples[1:200], \n  type = \"l\", \n  main = \"Trace Plot (Primi 200 Campioni)\",\n  xlab = \"Iterazioni\", \n  ylab = expression(theta)\n)\n\n\n\n\n\n\n\n\n# Trace plot dopo il burn-in\nplot(\n  post_burnin_samples, \n  type = \"l\", \n  main = \"Trace Plot (Post Burn-in)\",\n  xlab = \"Iterazioni\", \n  ylab = expression(theta)\n)\n\n\n\n\n\n\n\nSovrapponiamo la distribuzione analitica \\(\\text{Beta}(18, 92)\\) all’istogramma dei campioni post-burn-in:\n\n# Istogramma e distribuzione analitica\nhist(\n  post_burnin_samples, \n  breaks = 20, \n  probability = TRUE, \n  col = \"lightblue\",\n  main = \"Istogramma e Distribuzione Posteriori\", \n  xlab = expression(theta)\n)\ncurve(\n  dbeta(x, 18, 92), \n  add = TRUE, \n  col = \"red\", \n  lwd = 2\n)\nlegend(\n  \"topright\", \n  legend = c(\"Istogramma MCMC\", \"Beta(18, 92)\"),\n  col = c(\"lightblue\", \"red\"), lwd = 2, fill = c(\"lightblue\", NA)\n)\n\n\n\n\n\n\n\nCalcoliamo l’intervallo di credibilità al 94%:\n\nquantile(post_burnin_samples, probs = c(0.03, 0.97))\n#&gt;     3%    97% \n#&gt; 0.1020 0.2347\n\nQuesta implementazione in R dimostra come utilizzare l’algoritmo di Metropolis per stimare una distribuzione a posteriori e analizzare i risultati in modo dettagliato e riproducibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "href": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "title": "53  L’algoritmo di Metropolis-Hastings",
    "section": "\n53.8 Catene di Markov e Convergenza",
    "text": "53.8 Catene di Markov e Convergenza\nNell’ambito delle simulazioni Monte Carlo, una catena rappresenta una sequenza di valori campionati dall’algoritmo durante le sue iterazioni. Ogni valore nella catena corrisponde a un possibile stato del sistema che stiamo modellando. In altre parole, una catena traccia il percorso che l’algoritmo segue nello spazio dei parametri, esplorando le diverse configurazioni possibili.\nPer verificare se l’algoritmo ha raggiunto la convergenza e se i campioni generati rappresentano effettivamente la distribuzione di interesse, è utile eseguire multiple catene. Ogni catena parte da un punto iniziale diverso nello spazio dei parametri.\nI vantaggi delle multiple catene:\n\n\nDiagnostica della convergenza: Confrontando le diverse catene, possiamo valutare se si stabilizzano verso la stessa distribuzione. Se le catene si mescolano bene, ovvero si intersecano frequentemente nel grafico dei valori campionati (trace plot), è un forte indicatore di convergenza.\n\nRobustezza: L’utilizzo di multiple catene rende l’analisi meno sensibile alla scelta del punto di partenza. Se una singola catena potesse rimanere “intrappolata” in una regione dello spazio dei parametri, multiple catene aumentano la probabilità di esplorare lo spazio in modo più completo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "title": "53  L’algoritmo di Metropolis-Hastings",
    "section": "\n53.9 Diagnostiche della soluzione MCMC",
    "text": "53.9 Diagnostiche della soluzione MCMC\n\n53.9.1 Stazionarietà e Convergenza\nUn aspetto cruciale nell’analisi delle catene di Markov MCMC è la convergenza alla distribuzione stazionaria. Intuitivamente, la catena converge quando i campioni generati rappresentano fedelmente la distribuzione di interesse, indipendentemente dal punto di partenza. Questo fenomeno è spesso indicato come “mixing”.\n\n53.9.1.1 Valutazione Visuale: Trace Plots e Grafici di Densità\n\n\nTrace Plots: Questi grafici visualizzano l’evoluzione dei parametri nel tempo. Una catena convergente mostra tracce stabili e senza trend evidenti. Tracce irregolari o con andamenti sistematici suggeriscono problemi di convergenza.\n\nGrafici di Densità: Confrontando i grafici di densità dei campioni con la distribuzione teorica, è possibile valutare visivamente se la catena sta esplorando adeguatamente lo spazio dei parametri. Una buona convergenza si manifesta con una sovrapposizione tra i due grafici.\n\nSegni di Convergenza:\n\n\nStabilità: I valori campionati oscillano attorno a un valore medio costante, senza trend marcati.\n\nOmogeneità: La variabilità dei campioni rimane relativamente uniforme nel tempo.\n\nAssenza di Periodicità: Non si osservano pattern ciclici o ripetitivi.\n\nIn sintesi, i trace plots e i grafici di densità offrono strumenti visivi rapidi per valutare la convergenza di una catena di Markov MCMC. Una convergenza soddisfacente è fondamentale per garantire la validità delle inferenze statistiche basate sui campioni generati.\n\n53.9.2 Autocorrelazione nelle catene di Markov MCMC\nA differenza dei generatori di numeri casuali indipendenti, gli algoritmi MCMC producono una sequenza di campioni correlati. Ogni valore campionato dipende da quello precedente, formando una catena di Markov. Questa interdipendenza è un aspetto fondamentale dell’MCMC.\nL’autocorrelazione quantifica il grado di dipendenza tra valori distanti di una certa quantità (detta lag) nella catena. Un’alta autocorrelazione a lag bassi indica una forte dipendenza tra campioni successivi. Al contrario, una rapida diminuzione dell’autocorrelazione al crescere del lag suggerisce che la catena “miscela” bene, ovvero esplora lo spazio dei parametri in modo efficiente.\n\n\nLag 1: Misura la correlazione tra valori consecutivi nella catena.\n\nLag 2: Misura la correlazione tra valori separati da un passo intermedio.\n\nLag k: Generalizza il concetto ai valori separati da k passi.\n\nUn correlogramma è un grafico che mostra l’autocorrelazione in funzione del lag. Un decadimento rapido dell’autocorrelazione verso zero indica una buona convergenza della catena.\nL’autocorrelazione di ordine \\(k\\) è data da \\(\\rho_k\\) e può essere stimata come:\n\\[\n\\begin{align}\n\\rho_k &= \\frac{Cov(\\theta_m, \\theta_{m+k})}{Var(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{align}\n\\tag{53.1}\\]\n\n53.9.3 Esempio di Simulazione di Dati Autocorrelati\nPer fare un esempio pratico, creiamo un vettore di dati autocorrelati:\n\n# Creiamo un vettore di dati\nx &lt;- c(22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51)\nx\n#&gt;  [1] 22 24 25 25 28 29 34 37 40 44 51 48 47 50 51\n\n\n53.9.3.1 Calcolo dell’Autocorrelazione\nL’autocorrelazione di ordine 1 è la correlazione tra ciascun elemento e il successivo nella sequenza. In R possiamo utilizzare la funzione acf() per calcolare l’autocorrelazione.\n\n# Calcolo dell'autocorrelazione\nacf_values &lt;- acf(x, plot = FALSE)\nacf_values\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;      0      1      2      3      4      5      6      7      8      9 \n#&gt;  1.000  0.832  0.656  0.491  0.279  0.031 -0.165 -0.304 -0.401 -0.458 \n#&gt;     10     11 \n#&gt; -0.450 -0.369\n\nNell’esempio, il vettore x rappresenta una serie temporale di 15 elementi. Il calcolo dell’autocorrelazione restituisce i seguenti valori per i primi ritardi (lag):\n\n\n0.8317: autocorrelazione di ordine 1 (lag = 1),\n\n0.6563: autocorrelazione di ordine 2 (lag = 2),\n\n0.4910: autocorrelazione di ordine 3 (lag = 3),\necc.\n\n53.9.3.2 Specifica del Numero di Ritardi (Lag)\nPossiamo limitare il numero di ritardi calcolati utilizzando l’argomento lag.max nella funzione acf():\n\n# Calcolo dell'autocorrelazione per i primi 4 lag\nacf(x, lag.max = 4, plot = FALSE)\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;     0     1     2     3     4 \n#&gt; 1.000 0.832 0.656 0.491 0.279\n\n\n53.9.3.3 Grafico della Funzione di Autocorrelazione (Correlogramma)\nIn R possiamo creare un correlogramma con la funzione acf():\n\n# Correlogramma per la serie temporale\nacf(x, main = \"Correlogramma della Serie Temporale\", lag.max = 9)\n\n\n\n\n\n\n\n\n53.9.4 Analisi della Catena di Markov\nApplichiamo lo stesso approccio alla catena di Markov ottenuta precedentemente, considerando i campioni post burn-in:\n\n# Definizione dei campioni post burn-in\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\n# Correlogramma per i campioni post burn-in\nacf(\n  post_burnin_samples, \n  main = \"Correlogramma della Catena Post Burn-in\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\nIn situazioni ideali, l’autocorrelazione diminuisce rapidamente, diventando insignificante per piccoli lag. Questo comportamento è un’indicazione del “mixing” efficace della catena, ossia della sua convergenza alla distribuzione stazionaria.\n\n53.9.5 Sottocampionamento (Thinning)\nPer ridurre l’autocorrelazione, possiamo applicare una strategia di sottocampionamento (thinning), memorizzando solo ogni \\(m\\)-esimo campione.\n\n# Sottocampionamento con un fattore di 5\nthin &lt;- 5\nsampsthin &lt;- \n  post_burnin_samples[seq(1, length(post_burnin_samples), by = thin)]\n\n# Correlogramma per i campioni sottocampionati\nacf(\n  sampsthin, \n  main = \"Correlogramma con Sottocampionamento (Thinning)\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\nIn conclusione, il correlogramma con thinning mostra che l’autocorrelazione diminuisce più rapidamente rispetto ai campioni originali, suggerendo che la strategia di sottocampionamento è efficace nel migliorare l’indipendenza tra i campioni successivi. Questo migliora la qualità delle inferenze basate sulla catena di Markov.\n\n53.9.5.1 Tasso di accettazione\nQuando si utilizza l’algoritmo Metropolis, è importante monitorare il tasso di accettazione e assicurarsi che sia nell’intervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegherà molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D’altra parte, se il tasso di accettazione è molto basso, la catena rimarrà bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l’algoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale è compreso tra il 40% e il 50%.\n\n53.9.6 Test Statistici per la Convergenza\nOltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.\n\n53.9.6.1 Test di Geweke\nIl test di Geweke è una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l’ultimo 50% dei campioni, dopo aver escluso un iniziale periodo di “burn-in” (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base è che, se la catena è in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze importanti tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.\n\n53.9.6.2 Geweke Z-score\nUna variante del test di Geweke è lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:\n\n\nAl di sotto di 2 (in valore assoluto) suggerisce che non ci sono differenze degne di nota tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.\n\nSuperiore a 2 (in valore assoluto) indica che esiste una differenza degna di nota tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in più esteso.\n\nEntrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. È importante notare che nessun test può garantire con certezza la convergenza, ma l’utilizzo congiunto di approcci grafici e test statistici può offrire una buona indicazione dello stato della catena.\n\n53.9.7 Dimensione del campione effettiva (ESS)\nLa correlazione tra campioni consecutivi in una catena MCMC riduce l’informazione effettiva contenuta in ogni iterazione. La dimensione del campione effettiva (ESS) quantifica questa perdita di informazione dovuta alla dipendenza tra i campioni, stimando il numero equivalente di campioni indipendenti. Un valore basso di ESS indica una forte correlazione tra i campioni e una convergenza più lenta della catena.\nL’ESS descrive l’efficacia del campionamento dipendente in termini di campioni indipendenti estratti dalla stessa distribuzione. Rappresenta un indicatore dell’efficienza del campionamento e dell’autocorrelazione della catena.\nLa formula per stimare la dimensione del campione effettiva (ESS) di una catena di Markov è:\n\\[\n\\text{ESS} = \\frac{N}{1 + 2 \\sum_{t=1}^{T} \\rho_t},\n\\]\ndove:\n\n\n\\(N\\) è il numero totale di campioni nella catena,\n\n\\(T\\) è il lag, ovvero il numero massimo di termini di autocorrelazione considerati,\n\n\\(\\rho_t\\) è l’autocorrelazione al lag \\(t\\), ossia la correlazione tra due campioni consecutivi separati da \\(t\\) iterazioni.\n\nIn pratica, \\(T\\) viene scelto in modo tale che \\(\\rho_T\\) sia sufficientemente piccolo, indicando che l’autocorrelazione è quasi svanita. La somma \\(\\sum_{t=1}^T \\rho_t\\) viene quindi troncata approssimativamente a \\(T\\), poiché i contributi delle autocorrelazioni successive diventano trascurabili.\n\n53.9.8 Calcolo della Statistica di Gelman-Rubin (\\(\\hat{R}\\))\nPer calcolare la statistica di Gelman-Rubin (spesso indicata come \\(\\hat{R}\\)), è necessario eseguire più catene e confrontare la variabilità all’interno di ciascuna catena con la variabilità tra le catene. Ecco i passaggi per calcolare \\(\\hat{R}\\):\n\nEsegui \\(m\\) catene di Markov di lunghezza \\(n\\), dove \\(m\\) è solitamente maggiore di 1.\nPer ciascun parametro scalare \\(\\theta\\), calcola la varianza all’interno delle catene (\\(W\\)) e la varianza tra le catene (\\(B\\)).\nCalcola la varianza combinata \\(\\hat{V}\\) come media ponderata delle varianze all’interno delle catene.\nCalcola il fattore di riduzione della scala potenziale \\(\\hat{R}\\) come la radice quadrata del rapporto tra la varianza combinata \\(\\hat{V}\\) e la varianza all’interno delle catene \\(W\\):\n\n\\[\n\\hat{R} = \\sqrt{\\frac{\\hat{V}}{W}}.\n\\]\n\nSe \\(\\hat{R}\\) è vicino a 1, ciò indica che le catene sono in convergenza.\n\nLa statistica di Gelman-Rubin \\(\\hat{R}\\) è una misura di convergenza per le catene di Markov. Essa quantifica il grado di accordo tra più catene, fornendo uno strumento diagnostico per valutare la convergenza nelle simulazioni MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "href": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "title": "53  L’algoritmo di Metropolis-Hastings",
    "section": "\n53.10 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche",
    "text": "53.10 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche\nIl campionamento MCMC offre notevoli vantaggi pratici rispetto alle soluzioni analitiche nella statistica bayesiana, in particolare quando si tratta di manipolare distribuzioni a posteriori. Sebbene l’impossibilità di calcolare analiticamente la distribuzione a posteriori sia spesso la motivazione principale per l’uso di MCMC, i benefici di questo approccio si estendono ben oltre questa necessità (Bürkner, 2024).\n\n53.10.1 Facilità di Manipolazione e Flessibilità\nIl vantaggio chiave del campionamento MCMC risiede nella semplicità con cui si possono manipolare i campioni ottenuti. Mentre le densità calcolate analiticamente possono richiedere trasformazioni matematiche complesse, i campioni MCMC possono essere facilmente trasformati con operazioni dirette. Questa flessibilità si manifesta in diversi aspetti:\n\n\nTrasformazioni di Variabili: Consideriamo un caso in cui siamo interessati alla varianza residua (\\(\\sigma^2\\)) in un modello, ma abbiamo campioni solo della deviazione standard residua (\\(\\sigma\\)). Con il campionamento MCMC, la trasformazione è immediata:\n\n\\[\n(\\sigma^{(s)})^2 = \\sigma^{2(s)},\n\\]\ndove \\(s\\) indica il singolo campione. Questa operazione si traduce semplicemente nell’elevare al quadrato ogni campione di \\(\\sigma\\), ottenendo direttamente campioni validi di \\(\\sigma^2\\). In contrasto, con una densità analitica di \\(\\sigma\\), la trasformazione richiederebbe l’applicazione dell’aggiustamento del Jacobiano, un processo matematicamente più complesso.\n\n\nCombinazione di Parametri: Il MCMC semplifica notevolmente la combinazione di parametri in modelli statistici. Per una quantità \\(\\theta\\) che dipende da parametri \\(\\beta_1\\) e \\(\\beta_2\\) attraverso una funzione \\(f\\), possiamo calcolare:\n\n\\[\n\\theta^{(s)} = f(\\beta_1^{(s)}, \\beta_2^{(s)}).\n\\]\nQuesta operazione si estende facilmente a combinazioni complesse e funzioni non lineari, contrastando nettamente con la complessità di derivare analiticamente la distribuzione di \\(\\theta\\).\nIn conclusione, il campionamento MCMC non è solo una necessità quando le soluzioni analitiche sono introvabili, ma offre vantaggi in termini di facilità di manipolazione, flessibilità computazionale e applicabilità pratica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "href": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "title": "53  L’algoritmo di Metropolis-Hastings",
    "section": "\n53.11 Caso Normale-Normale con Soluzione Analitica",
    "text": "53.11 Caso Normale-Normale con Soluzione Analitica\nConsideriamo un caso normale-normale per cui possiamo derivare una soluzione analitica. Supponiamo che il prior sia distribuito secondo \\(\\mathcal{N}(30, 5^2)\\).\nDefiniamo le funzioni per il prior, la verosimiglianza e il posterior non normalizzato.\n\n# Prior: Normal(30, 5^2)\nprior &lt;- function(mu) {\n  dnorm(mu, mean = 30, sd = 5)\n}\n\n# Likelihood: Normal(mu, sigma^2) con sigma calcolata dai dati\nlikelihood &lt;- function(mu, data) {\n  sigma &lt;- sd(data)  # Deviazione standard dei dati\n  prod(dnorm(data, mean = mu, sd = sigma))\n}\n\n# Posterior non normalizzato\nposterior &lt;- function(mu, data) {\n  likelihood(mu, data) * prior(mu)\n}\n\nImplementiamo l’algoritmo di Metropolis per il caso normale-normale:\n\n# Algoritmo di Metropolis\nmetropolis_for_normal &lt;- function(nsamp, xinit, data) {\n  samples &lt;- numeric(nsamp)\n  x_prev &lt;- xinit\n  \n  for (i in seq_len(nsamp)) {\n    x_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)  # Proposta\n    if (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n      x_prev &lt;- x_star\n    }\n    samples[i] &lt;- x_prev\n  }\n  \n  samples\n}\n\nUtilizziamo un campione di 30 valori BDI-II forniti da Zetsche et al. (2019):\n\n# Dati osservati\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, \n  28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nEsecuzione dell’algoritmo:\n\nsamples &lt;- metropolis_for_normal(100000, mean(y), y)\n\nNel caso normale-normale, il posterior può essere calcolato analiticamente come segue:\n\n# Parametri del prior\nmu_prior &lt;- 30\nstd_prior &lt;- 5\nvar_prior &lt;- std_prior^2\n\n# Calcolo dei parametri posterior\nn &lt;- length(y)\nsum_y &lt;- sum(y)\nvar_data &lt;- var(y)\n\nmu_post &lt;- (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post &lt;- 1 / (1 / var_prior + n / var_data)\nstd_post &lt;- sqrt(var_post)\n\nmu_post\n#&gt; [1] 30.88\nstd_post\n#&gt; [1] 1.173\n\nVisualizziamo i risultati con un istogramma dei campioni MCMC e la curva della distribuzione analitica:\n\n# Campioni post burn-in\nburnin &lt;- floor(length(samples) * 0.5)\npost_samples &lt;- samples[-seq_len(burnin)]\n\n# Dati per la curva analitica\nx &lt;- seq(mu_post - 4 * std_post, mu_post + 4 * std_post, length.out = 1000)\nanalytical_posterior &lt;- dnorm(x, mean = mu_post, sd = std_post)\n\n# Creazione del grafico\nggplot() +\n  geom_histogram(aes(x = post_samples, y = after_stat(density)), bins = 30, fill = \"blue\", alpha = 0.4) +\n  geom_line(aes(x = x, y = analytical_posterior), color = \"red\", size = 1) +\n  labs(title = \"Distribuzione Posterior: MCMC vs Analitico\",\n       x = expression(mu), y = \"Densità\") \n\n\n\n\n\n\n\nTroviamo le proprietà del Posterior derivato con MCMC:\n\nmean(samples)\n#&gt; [1] 30.91\n\n\nsd(samples)\n#&gt; [1] 1.177\n\nIn conclusione, questo esempio mostra come applicare l’algoritmo di Metropolis per stimare una distribuzione a posteriori e come confrontare i risultati del sampling con la soluzione analitica, confermando la coerenza tra le due tecniche.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "href": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "title": "53  L’algoritmo di Metropolis-Hastings",
    "section": "\n53.12 Riflessioni Conclusive",
    "text": "53.12 Riflessioni Conclusive\nIn molti casi, la distribuzione a posteriori dei parametri di un modello statistico non ha una forma analitica risolvibile. Per affrontare questa limitazione, si utilizzano metodi Monte Carlo basati su catene di Markov (MCMC). Questi algoritmi permettono di campionare efficacemente dalla distribuzione a posteriori, anche per modelli complessi, generando una sequenza di valori che approssima la distribuzione desiderata. L’algoritmo di Metropolis-Hastings (Hastings, 1970), un’estensione dell’algoritmo di Metropolis originale (Metropolis et al., 1953), è uno dei metodi MCMC più ampiamente utilizzati.\nIn sintesi, l’algoritmo segue questi passaggi principali:\n\n\nGenerazione del nuovo stato proposto: Si crea un nuovo stato vicino a quello corrente utilizzando una distribuzione di proposta.\n\nConfronto tra densità posteriori: Si confrontano le densità a posteriori del nuovo stato proposto e dello stato corrente.\n\nAccettazione probabilistica: Il nuovo stato viene sempre accettato se ha una densità posteriore maggiore, oppure accettato con una certa probabilità se ha una densità minore.\n\nBurn-in e tasso di accettazione: I primi campioni vengono scartati (fase di burn-in) per garantire che la catena abbia raggiunto la distribuzione stazionaria, e si monitora il tasso di accettazione per ottimizzare l’efficienza del campionamento.\n\nQuesto approccio consente di ottenere campioni che approssimano la distribuzione a posteriori, ma l’algoritmo di Metropolis può presentare limiti di efficienza, soprattutto per problemi ad alta dimensionalità o distribuzioni con geometrie complesse. Un aspetto cruciale è il tasso di accettazione, che rappresenta il rapporto tra il numero di proposte accettate e il numero totale di proposte. Un tasso troppo basso può indicare che la catena esplora lo spazio dei parametri in modo inefficiente, mentre un tasso troppo alto può segnalare che i passi effettuati sono troppo piccoli per consentire una buona esplorazione.\nRispetto alle varianti più moderne, l’algoritmo di Metropolis tende a essere meno efficiente. Metodi come il No-U-Turn Sampler (NUTS) e l’Hamiltonian Monte Carlo (HMC) offrono importanti miglioramenti, specialmente in spazi di parametri di grandi dimensioni. NUTS, ad esempio, viene utilizzato in strumenti avanzati come Stan e PyMC (Hoffman et al., 2014), permettendo un’esplorazione più rapida e accurata della distribuzione a posteriori.\nTra gli altri algoritmi MCMC degni di nota troviamo il campionatore di Gibbs (Geman & Geman, 1984) e l’Hamiltonian Monte Carlo (Duane et al., 1987). Questi metodi, insieme a Metropolis-Hastings, formano la base di numerose tecniche moderne per il campionamento da distribuzioni complesse. Per un approfondimento dettagliato sulle tecniche MCMC, si consiglia di consultare Hanada & Matsuura (2022).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "title": "53  L’algoritmo di Metropolis-Hastings",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.8.1   thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.10.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.50           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.5       lattice_0.22-6      \n#&gt;  [7] tzdb_0.4.0           vctrs_0.6.5          tools_4.4.2         \n#&gt; [10] ps_1.8.1             generics_0.1.3       parallel_4.4.2      \n#&gt; [13] pacman_0.5.1         R.oo_1.27.0          pkgconfig_2.0.3     \n#&gt; [16] data.table_1.16.4    checkmate_2.3.2      distributional_0.5.0\n#&gt; [19] lifecycle_1.0.4      compiler_4.4.2       farver_2.1.2        \n#&gt; [22] munsell_0.5.1        mnormt_2.1.1         htmltools_0.5.8.1   \n#&gt; [25] pillar_1.10.1        R.utils_2.12.3       abind_1.4-8         \n#&gt; [28] nlme_3.1-167         posterior_1.6.0.9000 tidyselect_1.2.1    \n#&gt; [31] digest_0.6.37        stringi_1.8.4        reshape2_1.4.4      \n#&gt; [34] labeling_0.4.3       rprojroot_2.0.4      fastmap_1.2.0       \n#&gt; [37] grid_4.4.2           colorspace_2.1-1     cli_3.6.4           \n#&gt; [40] magrittr_2.0.3       withr_3.0.2          backports_1.5.0     \n#&gt; [43] timechange_0.3.0     rmarkdown_2.29       R.methodsS3_1.8.2   \n#&gt; [46] hms_1.1.3            evaluate_1.0.3       rlang_1.1.5         \n#&gt; [49] Rcpp_1.0.14          glue_1.8.0           rstudioapi_0.17.1   \n#&gt; [52] jsonlite_1.8.9       plyr_1.8.9           R6_2.6.1",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#bibliografia",
    "href": "chapters/mcmc/01_metropolis.html#bibliografia",
    "title": "53  L’algoritmo di Metropolis-Hastings",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBürkner, P.-C. (2024). The brms Book: Applied Bayesian Regression Modelling Using R and Stan (Early Draft). https://paulbuerkner.com/software/brms-book\n\n\nDuane, S., Kennedy, A. D., Pendleton, B. J., & Roweth, D. (1987). Hybrid monte carlo. Physics letters B, 195(2), 216–222.\n\n\nGeman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on pattern analysis and machine intelligence, 6, 721–741.\n\n\nHanada, M., & Matsuura, S. (2022). MCMC from Scratch. Springer.\n\n\nHastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1), 97–109.\n\n\nHoffman, M. D., Gelman, A., et al. (2014). The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593–1623.\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21(6), 1087–1092.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html",
    "href": "chapters/mcmc/02_ppl.html",
    "title": "54  Linguaggi di programmazione probabilistici",
    "section": "",
    "text": "54.1 Cos’è la programmazione probabilistica\nLa programmazione probabilistica è un paradigma della programmazione informatica che consente di creare modelli e algoritmi capaci di gestire l’incertezza e la casualità. Combina i principi della teoria delle probabilità con la programmazione, permettendo di costruire sistemi in grado di ragionare su dati incerti e di prendere decisioni informate. Questo approccio consente di esprimere modelli complessi in modo naturale e intuitivo, facilitando il processo di inferenza bayesiana.\nLa programmazione probabilistica si colloca all’intersezione tra algoritmi di machine learning, statistica e linguaggi di programmazione. I suoi obiettivi principali sono semplificare il processo di inferenza e automatizzarlo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "href": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "title": "54  Linguaggi di programmazione probabilistici",
    "section": "54.2 Perché abbiamo bisogno della programmazione probabilistica?",
    "text": "54.2 Perché abbiamo bisogno della programmazione probabilistica?\nScrivere un proprio campionatore per l’inferenza bayesiana è un compito estremamente difficile. Richiede competenze matematiche avanzate e una profonda conoscenza degli algoritmi di campionamento (sia MCMC che approssimati). Inoltre, ci sono numerosi problemi potenziali legati alla stabilità numerica e ai costi computazionali. Questo significa che per riuscirci bisogna essere allo stesso tempo degli ottimi sviluppatori e degli esperti statistici.\nÈ però possibile delegare tutti questi compiti a un sistema che li automatizzi, permettendoci di concentrarci sulla risoluzione dei problemi scientifici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "href": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "title": "54  Linguaggi di programmazione probabilistici",
    "section": "54.3 Linguaggi di programmazione probabilistica (PPLs)",
    "text": "54.3 Linguaggi di programmazione probabilistica (PPLs)\nIn questa sezione esamineremo il panorama moderno dei linguaggi di programmazione probabilistica (PPLs) e, nella sezione successiva, esploreremo le funzionalità di uno di questi, Stan.\n\n54.3.1 Linguaggi di Programmazione Probabilistica (PPL)\nUn linguaggio di programmazione probabilistica (PPL) consente di formalizzare modelli bayesiani e di eseguire inferenze utilizzando algoritmi avanzati. L’utente deve semplicemente definire il modello, selezionare un campionatore e avviare il processo di inferenza.\nIn generale, le funzionalità fondamentali richieste a un PPL sono:\n\ngenerare valori casuali da distribuzioni probabilistiche;\ncondizionare variabili su dati osservati.\n\nI primi linguaggi di programmazione probabilistica, come BUGS e WinBUGS, hanno gettato le basi offrendo tre capacità essenziali:\n\nrandom: per definire variabili casuali.\nconstraint: per vincolare variabili ai dati osservati.\ninfer: per calcolare e restituire la distribuzione delle variabili di interesse.\n\nNel corso del tempo, l’elenco dei PPL disponibili si è notevolmente ampliato, comprendendo una vasta gamma di strumenti in continua evoluzione. Ecco alcuni esempi rappresentativi:\n\nBUGS, WinBUGS, JAGS\nStan\nPyMC3, PyMC4, PyMC\nNimble\nPyro, NumPyro\nEdward, TensorFlow Probability, Edward 2\nGen\nTuring\nStheno\nSOSS\nOmega\nInfer.NET",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "href": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "title": "54  Linguaggi di programmazione probabilistici",
    "section": "54.4 Come scegliere un PPL?",
    "text": "54.4 Come scegliere un PPL?\nDal punto di vista pratico, come si può decidere quale linguaggio di programmazione probabilistica utilizzare? Ecco alcuni fattori chiave da considerare:\n\nDocumentazione: La presenza di risorse ben strutturate, come guide, tutorial e documentazione ufficiale, è essenziale per facilitare l’apprendimento e migliorare la produttività. Un PPL con documentazione chiara e completa è sempre preferibile, specialmente per chi è alle prime armi.\nPerformance: Alcuni PPL sono ottimizzati per offrire prestazioni superiori, ad esempio mediante l’elaborazione parallela o l’uso di acceleratori hardware come le GPU. Valuta le prestazioni in relazione alla complessità e alla scala dei modelli che desideri costruire.\nFunzionalità: È importante verificare se il PPL offre un’ampia gamma di distribuzioni probabilistiche e campionatori, oltre a strumenti avanzati per personalizzare i modelli e implementare inferenze specifiche.\nSupporto della comunità: Una comunità attiva può fare la differenza quando incontri difficoltà. Forum, gruppi di discussione e risorse condivise dagli utenti (come esempi pratici o risposte a domande frequenti) sono fondamentali per risolvere problemi in modo rapido e imparare dalle esperienze di altri.\nIntegrazione: Considera quanto bene il PPL si integra con gli strumenti e i framework già in uso. Per esempio, se utilizzi librerie per la manipolazione dei dati, la visualizzazione o il machine learning, come pandas, ggplot o TensorFlow, verifica che il PPL scelto supporti queste interazioni senza complicazioni.\n\n\n54.4.1 API\nI linguaggi di programmazione probabilistica (PPL) permettono agli utenti di definire con precisione le caratteristiche dei priori, della verosimiglianza e dell’intero modello bayesiano. Inoltre, offrono strumenti per effettuare le necessarie trasformazioni sui dati, garantendo la flessibilità richiesta per affrontare una vasta gamma di problemi statistici. Tuttavia, anche se i PPL cercano di semplificare queste operazioni, l’utente deve comunque scrivere codice che rispetti i vincoli sintattici e logici specifici del linguaggio. Questo richiede non solo competenze di programmazione, ma anche una buona conoscenza dei principi statistici e bayesiani.\nPer venire incontro a utenti che desiderano utilizzare l’inferenza bayesiana senza doversi addentrare nella programmazione, sono state sviluppate interfacce di alto livello. Queste interfacce permettono di specificare modelli statistici comuni in modo intuitivo, utilizzando una sintassi semplificata. Sebbene offrano meno controllo sui dettagli tecnici del modello, garantiscono comunque la possibilità di personalizzare elementi cruciali, come i priori e la verosimiglianza, rendendo l’inferenza bayesiana accessibile anche a chi non ha competenze di programmazione.\n\n\n54.4.2 Principali Interfacce di Alto Livello\nTra le interfacce più popolari troviamo:\n\nbrms: utilizza Stan come motore sottostante per eseguire l’inferenza.\nBambi: si basa su PyMC per eseguire l’inferenza bayesiana.\n\nEntrambe queste librerie adottano una sintassi semplificata, nota come sintassi di Wilkinson (Wilkinson & Rogers, 1973). Questo approccio consente di specificare modelli in modo dichiarativo, usando una struttura simile a quella adottata da pacchetti R come lm (per modelli di regressione lineare) o lme4 (per modelli multilivello con lmer).\nAd esempio, in brms è possibile specificare un modello di regressione lineare con una sintassi simile a questa:\nfit &lt;- brm(y ~ x1 + x2, data = dataset)\nIn questo esempio y ~ x1 + x2 definisce la relazione tra la variabile dipendente (y) e le variabili indipendenti (x1 e x2).\n\n\n54.4.3 Vantaggi delle Interfacce di Alto Livello\n\nAccessibilità: Riduzione della complessità sintattica, rendendo l’inferenza bayesiana più accessibile a un pubblico più ampio, inclusi studenti e ricercatori con competenze di programmazione limitate.\nFlessibilità: Sebbene più semplici, le interfacce consentono di specificare prior distribuiti in modo personalizzato e di modificare molteplici aspetti del modello.\nEfficienza: Automatizzano molti passaggi tecnici, permettendo di concentrarsi sulla definizione del modello e sull’interpretazione dei risultati.\nCompatibilità: Integrazione con strumenti statistici familiari, come il framework di modelli lineari in R.\n\nIn questo corso, utilizzeremo principalmente brms per specificare e stimare modelli di regressione lineare e multilivello, sfruttandone la sintassi intuitiva e l’integrazione con R. Negli approfondimenti, invece, esploreremo come scrivere direttamente modelli in Stan, per comprendere meglio le basi dei PPL e avere maggiore controllo sui dettagli tecnici.\nQuesta combinazione ci permetterà di bilanciare semplicità e potenza, rendendo l’inferenza bayesiana sia accessibile che personalizzabile, a seconda delle esigenze specifiche del progetto o dell’analisi.\n\n\n54.4.4 Introduzione alla sintassi di Wilkinson\nLa sintassi di Wilkinson in R fornisce un modo semplice ed efficace per specificare modelli di regressione lineare, consentendo di descrivere relazioni tra una variabile dipendente (risposta) e una o più variabili indipendenti (predittori) utilizzando una notazione simbolica. Questa sintassi si allinea direttamente al modello matematico, rendendo immediata la corrispondenza tra i termini simbolici e il codice.\n\n54.4.4.1 Modello simbolico e modello Wilkinson\nSupponiamo di voler specificare un modello di regressione lineare multipla con la seguente formula:\n\\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i ,\n\\]\ndove:\n\n\\(y_i\\) è la variabile dipendente per l’osservazione \\(i\\),\n\\(\\alpha\\) è l’intercetta,\n\\(\\beta_1\\) e \\(\\beta_2\\) sono i coefficienti di regressione per i predittori \\(x_1\\) e \\(x_2\\),\n\\(\\varepsilon_i\\) rappresenta l’errore residuo, normalmente distribuito (\\(\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)).\n\nIn R, questo modello può essere specificato con la sintassi Wilkinson:\ny ~ x1 + x2\n\n\n54.4.4.2 Dettaglio dei componenti\n\nIntercetta implicita:\nLa sintassi R include automaticamente l’intercetta (\\(\\alpha\\)) quando si utilizza il simbolo +. Ad esempio:\ny ~ x1 + x2\nequivale al modello: \\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i\n\\]\nEsclusione dell’intercetta:\nSe si desidera escludere l’intercetta (\\(\\alpha\\)), si utilizza - 1 nella specifica:\ny ~ x1 + x2 - 1\nQuesto produce un modello senza intercetta: \\[\ny_i = \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i\n\\]\nInclusione esplicita dell’intercetta:\nAnche se è implicita, l’intercetta può essere specificata esplicitamente con 1 +:\ny ~ 1 + x1 + x2\nQuesto è equivalente al modello con intercetta implicita.\nInterazione tra predittori:\nLa sintassi Wilkinson consente anche di specificare interazioni. Ad esempio, un’interazione tra \\(x_1\\) e \\(x_2\\):\ny ~ x1 * x2\nEspande automaticamente il modello per includere: \\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 (x_{1i} \\cdot x_{2i}) + \\varepsilon_i\n\\]\n\n\n\n54.4.4.3 Esempio pratico\nSupponiamo di avere un dataset con una variabile dipendente y e due predittori x1 e x2. Ecco come specificare e adattare un modello di regressione lineare multipla in R:\n# Specifica del modello\nmodello &lt;- lm(y ~ x1 + x2, data = dataset)\n\n# Sommario del modello\nsummary(modello)\nQuesto codice:\n\nSpecifica un modello con intercetta e due predittori.\nAdatta il modello ai dati contenuti in dataset.\nCalcola i coefficienti (\\(\\alpha, \\beta_1, \\beta_2\\)), i valori di errore standard, i p-value (frequentisti) e altre statistiche di sintesi.\n\nIn sintesi, la sintassi di Wilkinson in R permette di esprimere modelli di regressione lineare in modo conciso e leggibile, rendendo il passaggio dal modello matematico al codice intuitivo e diretto.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "href": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "title": "54  Linguaggi di programmazione probabilistici",
    "section": "54.5 Riflessioni Conclusive",
    "text": "54.5 Riflessioni Conclusive\nI linguaggi di programmazione probabilistica (PPL) rappresentano strumenti potenti per la specificazione completa e flessibile di modelli bayesiani, consentendo agli utenti di definire ogni aspetto del modello, dai priori alla verosimiglianza, fino agli algoritmi di inferenza. Strumenti come Stan e PyMC permettono un controllo dettagliato sui modelli, rendendoli ideali per analisi avanzate e progetti personalizzati.\nTuttavia, questo livello di controllo richiede competenze di programmazione e una comprensione approfondita della statistica bayesiana. Per superare queste barriere e rendere l’inferenza bayesiana accessibile a un pubblico più ampio, sono state sviluppate interfacce di alto livello come brms (basata su Stan) e Bambi (basata su PyMC). Questi strumenti semplificano enormemente il processo, consentendo agli utenti di specificare modelli statistici complessi senza la necessità di scrivere codice dettagliato, grazie a una sintassi intuitiva come quella di Wilkinson.\nIn sintesi:\n\nI PPL offrono flessibilità massima e un controllo completo, ma richiedono esperienza nella programmazione.\nLe interfacce di alto livello rendono possibile l’inferenza bayesiana anche a chi preferisce evitare la programmazione, garantendo un compromesso tra semplicità e capacità di personalizzazione.\n\nLa scelta tra un PPL e un’interfaccia di alto livello dipende quindi dalle esigenze specifiche: chi necessita di modelli estremamente personalizzati e complessi opterà per un PPL come Stan o PyMC, mentre chi desidera facilità d’uso senza rinunciare alla potenza dell’inferenza bayesiana troverà in brms o Bambi strumenti ideali. In ogni caso, la crescente disponibilità di strumenti e risorse rende oggi l’inferenza bayesiana più accessibile che mai, anche per chi non ha un background tecnico avanzato.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#bibliografia",
    "href": "chapters/mcmc/02_ppl.html#bibliografia",
    "title": "54  Linguaggi di programmazione probabilistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392–399.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html",
    "href": "chapters/mcmc/07_bayesian_workflow.html",
    "title": "55  Flusso di lavoro bayesiano",
    "section": "",
    "text": "55.1 Introduzione\nL’applicazione dell’inferenza bayesiana nella risoluzione di problemi reali richiede un approccio strutturato e multidisciplinare, noto come workflow bayesiano. Questo processo iterativo e complesso va ben oltre la semplice applicazione della regola di Bayes, che pur costituendo il fondamento teorico dell’inferenza bayesiana, rappresenta solo il punto di partenza di un percorso analitico più articolato.\nIl workflow bayesiano include molteplici fasi interconnesse, tra cui:\nPer esempio, immaginiamo di voler valutare l’efficacia di un intervento psicologico. Il ricercatore deve affrontare diverse decisioni: quali variabili includere (covariate), come modellare i dati gerarchici (ad esempio, individui e gruppi), e quali distribuzioni utilizzare per rappresentare incertezze (priori). Queste decisioni, lungi dall’essere definitive, richiedono continui aggiustamenti basati sui risultati intermedi.\nUn ulteriore aspetto critico è la gestione di possibili problemi computazionali. Ad esempio, il campionamento MCMC (Markov Chain Monte Carlo) potrebbe non convergere correttamente, richiedendo modifiche al modello o all’approccio algoritmico. Inoltre, il workflow bayesiano non si limita alla stima dei parametri: include la valutazione della capacità del modello di fare previsioni attendibili e il confronto tra modelli alternativi.\nInfine, è fondamentale bilanciare la complessità del modello con la rilevanza pratica dei risultati. Modelli troppo semplici possono portare a conclusioni distorte, mentre modelli troppo complessi possono diventare difficili da interpretare. Il workflow bayesiano aiuta i ricercatori a navigare queste sfide, fornendo un quadro metodologico flessibile e iterativo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#introduzione",
    "href": "chapters/mcmc/07_bayesian_workflow.html#introduzione",
    "title": "55  Flusso di lavoro bayesiano",
    "section": "",
    "text": "Costruzione iterativa del modello: Definizione e revisione di modelli probabilistici che rappresentano i processi generativi dei dati.\nVerifica e validazione: Controllo della qualità delle stime e valutazione delle capacità predittive del modello.\nRisultati e interpretazione: Confronto tra modelli alternativi per trarre conclusioni solide.\nGestione di problemi computazionali: Identificazione e soluzione di eventuali difficoltà nell’adattamento del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#principi-del-workflow-bayesiano",
    "href": "chapters/mcmc/07_bayesian_workflow.html#principi-del-workflow-bayesiano",
    "title": "55  Flusso di lavoro bayesiano",
    "section": "55.2 Principi del workflow bayesiano",
    "text": "55.2 Principi del workflow bayesiano\nUn workflow è una sequenza strutturata di passi che definisce cosa costituisce una “buona pratica” in un determinato ambito. Nel contesto dell’inferenza bayesiana, il workflow si ispira a concetti come il Ciclo di Box e le più recenti estensioni proposte da studiosi come Gelman e Riha.\n\n55.2.1 Il Ciclo di Box\nGeorge Box, uno dei pionieri della statistica moderna, ha sviluppato negli anni ’60 un approccio ciclico alla modellizzazione statistica, noto come Ciclo di Box. Questo paradigma sottolinea che la modellizzazione non è un processo lineare, ma un ciclo continuo di miglioramento.\n\n\n\nFigura tratta da Blei (2014).\n\n\nIl Ciclo di Box si articola in una serie di fasi iterative:\n\nFormulazione del modello: Si costruisce un modello basato sulle conoscenze disponibili e sui dati osservati.\nInferenza: Si stimano i parametri del modello e si valutano le incertezze associate.\nValutazione del modello: Si verifica quanto il modello si adatta ai dati.\nRevisione del modello: Si corregge il modello in base alle discrepanze identificate.\n\nQuesto approccio iterativo è il cuore del workflow bayesiano. La capacità dell’inferenza bayesiana di aggiornare le credenze a priori alla luce di nuovi dati lo rende particolarmente adatto a essere integrato nel Ciclo di Box. Più recentemente, Gelman et al. (2020) hanno proposto una versione estesa del Ciclo di Box, fornendo una guida dettagliata per implementare un workflow bayesiano completo.\n\n\n\nFigura tratta da Gelman et al. (2020).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#costruzione-iterativa-del-modello",
    "href": "chapters/mcmc/07_bayesian_workflow.html#costruzione-iterativa-del-modello",
    "title": "55  Flusso di lavoro bayesiano",
    "section": "55.3 Costruzione iterativa del modello",
    "text": "55.3 Costruzione iterativa del modello\nIl processo di costruzione di un modello bayesiano può essere descritto attraverso i seguenti passaggi:\n\nComprensione del fenomeno e formulazione del problema: Il punto di partenza è definire chiaramente la domanda di ricerca. L’obiettivo non è semplicemente descrivere correlazioni tra variabili, ma comprendere i meccanismi generativi dei dati.\nFormulazione matematica: Si costruisce un modello probabilistico che rappresenti il processo generativo, spesso utilizzando linguaggi probabilistici (PPL) come Stan o PyMC.\nImplementazione: Il modello viene tradotto in codice utilizzando interfacce software come R, Python o Julia, che permettono di adattare modelli complessi ai dati.\nVerifiche predittive a priori: Si simulano dati basandosi sulle distribuzioni a priori per verificare che i parametri scelti siano ragionevoli.\nAdattamento del modello: Si utilizza un algoritmo di campionamento per stimare i parametri del modello dai dati osservati (ad esempio, cmdstanr o cmdstanpy).\nDiagnostiche di convergenza: Si verifica che le catene MCMC abbiano raggiunto la convergenza, utilizzando strumenti come il valore R-hat.\nVerifiche predittive a posteriori: Si generano dati simulati a partire dalla distribuzione a posteriori per confrontarli con i dati reali e valutare la bontà del modello.\nIterazione: Sulla base dei risultati, il modello viene raffinato e migliorato.\n\nQuesto processo iterativo consente di costruire modelli che siano sia robusti sia interpretabili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#analisi-multiverso",
    "href": "chapters/mcmc/07_bayesian_workflow.html#analisi-multiverso",
    "title": "55  Flusso di lavoro bayesiano",
    "section": "55.4 Analisi Multiverso",
    "text": "55.4 Analisi Multiverso\nL’analisi multiverso, introdotta recentemente (Riha et al., 2024), amplia il workflow bayesiano, permettendo di esplorare simultaneamente molteplici modelli alternativi. Ogni modello rappresenta una combinazione unica di scelte modellistiche (ad esempio, covariate, distribuzioni a priori, o assunzioni sul processo generativo).\nI vantaggi principali dell’analisi multiverso includono:\n\nTrasparenza: Documenta tutte le scelte di modellizzazione.\nEsplorazione completa: Riduce il rischio di trascurare ipotesi rilevanti.\nConfronto diretto: Permette di identificare i modelli più adatti basandosi su criteri come l’Expected Log-Predictive Density (ELPD).\nRobustezza: Esamina come le conclusioni cambiano tra diversi modelli.\nReplicabilità: Fornisce informazioni dettagliate per riprodurre l’analisi e i risultati.\n\nQuesto approccio incorpora anche verifiche computazionali e analisi di sensibilità. Le prime identificano i modelli che necessitano di ulteriori verifiche per garantire l’affidabilità dei risultati, mentre le seconde esaminano la robustezza delle conclusioni rispetto alle diverse scelte di modellazione e all’influenza delle priori sulle stime posteriori.\nTuttavia, la generazione di numerosi modelli può complicare la gestione e l’interpretazione dei risultati. Per affrontare questa sfida, Riha et al. (2024) propongono un metodo di “iterative filtering” che comprende:\n\nCreazione di un multiverso iniziale di modelli.\nValutazione delle capacità predittive attraverso controlli predittivi posteriori (PPC) e calcolo dell’expected log point-wise predictive density (elpd).\nVerifica della qualità computazionale, esaminando convergenza ed efficienza del campionamento MCMC.\nFiltraggio iterativo basato su criteri di qualità predefiniti.\nPossibilità di estendere il multiverso e ripetere il processo.\n\nQuesto approccio mantiene i vantaggi della multiverse analysis riducendo al contempo la complessità attraverso un filtraggio sistematico. Il risultato è un workflow bayesiano più robusto e informativo, che bilancia la necessità di considerare molteplici ipotesi modellistiche con l’esigenza pratica di focalizzarsi sui modelli più promettenti per il problema in esame.\nUno dei casi di studio esaminati da Riha et al. (2024) riguarda l’analisi del numero di crisi epilettiche in relazione a diverse variabili (covariate) e scelte di modellazione. I dati utilizzati provengono dallo studio di Leppik et al. (1987) e sono disponibili nel pacchetto R brms.\nSono stati confrontati 24 modelli statistici, ciascuno con una specifica formulazione matematica (illustrata nella Tabella seguente). La scelta dei modelli ha riguardato diverse combinazioni di covariate e di distribuzioni di probabilità per descrivere il fenomeno in esame.\n\n\n\nTabella 1 ricavata da Riha et al. (2024).\n\n\nPer valutare la capacità predittiva dei modelli, è stato utilizzato il criterio ELPD (Expected Log-Predictive Density). I risultati sono riportati nel grafico seguente.\n\n\n\nFigura 12 ricavata da Riha et al. (2024).\n\n\nCome si può osservare, i modelli presentano performance predittive differenti.\nOltre all’ELPD, sono stati condotti controlli predittivi posteriori (PPC) per valutare la plausibilità dei modelli rispetto ai dati osservati. I risultati dei PPC sono visualizzati nella figura seguente.\n\n\n\nFigura 13 ricavata da Riha et al. (2024).\n\n\nIl modello selezionato è quello che ha mostrato il miglior valore di ELPD, evidenziando una buona capacità predittiva. Inoltre, i controlli PPC hanno confermato la plausibilità del modello rispetto ai dati osservati. Infine, il modello selezionato non ha presentato problemi computazionali durante la stima dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#riflessioni-conclusive",
    "href": "chapters/mcmc/07_bayesian_workflow.html#riflessioni-conclusive",
    "title": "55  Flusso di lavoro bayesiano",
    "section": "55.5 Riflessioni Conclusive",
    "text": "55.5 Riflessioni Conclusive\nIl workflow bayesiano rappresenta una strategia strutturata e iterativa per affrontare l’analisi dei dati complessi. Attraverso strumenti come le verifiche predittive e l’analisi multiverso, consente di sviluppare modelli solidi e capaci di adattarsi a nuovi dati e conoscenze. La sua integrazione con linguaggi come Stan o PyMC ne facilita l’applicazione, rendendolo un approccio essenziale per la ricerca moderna.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#bibliografia",
    "href": "chapters/mcmc/07_bayesian_workflow.html#bibliografia",
    "title": "55  Flusso di lavoro bayesiano",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlei, D. M. (2014). Build, compute, critique, repeat: Data analysis with latent variable models. Annual Review of Statistics and Its Application, 1(1), 203–232.\n\n\nBulbulia, J. A. (2023). A workflow for causal inference in cross-cultural psychology. Religion, Brain & Behavior, 13(3), 291–306.\n\n\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., Kennedy, L., Gabry, J., Bürkner, P.-C., & Modrák, M. (2020). Bayesian workflow. arXiv preprint arXiv:2011.01808.\n\n\nLeppik, I., Dreifuss, F., Porter, R., Bowman, T., Santilli, N., Jacobs, M., Crosby, C., Cloyd, J., Stackman, J., Graves, N., et al. (1987). A controlled study of progabide in partial seizures: methodology and results. Neurology, 37(6), 963–963.\n\n\nRiha, A. E., Siccha, N., Oulasvirta, A., & Vehtari, A. (2024). Supporting Bayesian modelling workflows with iterative filtering for multiverse analysis. arXiv preprint arXiv:2404.01688.\n\n\nSteegen, S., Tuerlinckx, F., Gelman, A., & Vanpaemel, W. (2016). Increasing transparency through a multiverse analysis. Perspectives on Psychological Science, 11(5), 702–712.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/introduction_linear_models.html",
    "href": "chapters/linear_models/introduction_linear_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "Gli obiettivi di questo insegnamento riguardano i casi più semplici di inferenza statistica, cioè l’inferenza su una singola media, la differenza tra due medie, e l’analisi del modello di regressione lineare (bivariato e multiplo) con predittori sia quantitativi sia qualitativi.\nTradizionalmente, l’inferenza su una media o sulla differenza tra due medie viene affrontata tramite il test t di Student, in un’ottica frequentista. In una prospettiva più moderna, tuttavia, questi argomenti possono essere inquadrati nel framework generale del modello lineare. Di conseguenza, in questa sezione della dispensa presenteremo il modello lineare sia dal punto di vista bayesiano sia frequentista, mostrando come l’inferenza su una o due medie rappresenti in realtà un caso particolare di questo impianto metodologico.",
    "crumbs": [
      "Regressione",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html",
    "href": "chapters/linear_models/01_reglin_frequentist.html",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "56.1 Introduzione\nLa regressione è un metodo fondamentale che consente ai ricercatori di riassumere come le previsioni o i valori medi di una variabile risultato (dipendente) variano in funzione di un insieme di predittori (indipendenti). Grazie alla sua versatilità, la regressione è utilizzata in un’ampia gamma di contesti, dai modelli predittivi alla valutazione degli effetti causali.\nSecondo Gelman et al. (2021), i principali utilizzi della regressione includono:\nIn tutti questi contesti, è cruciale che il modello includa tutte le variabili rilevanti. Ad esempio, in uno studio sull’efficacia di una terapia per la depressione, fattori come età, condizioni di salute preesistenti e supporto sociale devono essere inclusi nel modello per evitare conclusioni fuorvianti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "Previsione: Modellare osservazioni esistenti o prevedere nuovi dati, sia continui che categoriali.\n\nAd esempio: prevedere punteggi futuri in un test, monitorare il benessere psicologico in uno studio longitudinale o classificare individui in base alla probabilità di successo in un compito cognitivo.\n\n\n\nEsplorazione delle associazioni: Quantificare il grado di relazione tra una o più variabili indipendenti e un risultato.\n\nAd esempio: studiare i tratti di personalità associati alla resilienza allo stress, analizzare la relazione tra stili di attaccamento infantile e capacità relazionali in età adulta, o valutare l’impatto di fattori socio-economici sullo sviluppo cognitivo nei bambini.\n\n\n\nEstrapolazione: Generalizzare i risultati osservati in un campione a una popolazione più ampia.\n\nAd esempio: stimare l’efficacia di una terapia testata su studenti universitari per la popolazione generale, oppure prevedere l’impatto di un intervento scolastico su un intero distretto partendo dai risultati osservati in alcune scuole.\n\n\n\nInferenza causale: Stimare gli effetti di un trattamento o intervento.\n\nAd esempio: valutare l’efficacia di un programma di mindfulness sui livelli di ansia, stimare l’impatto di una tecnica psicoterapeutica per il disturbo post-traumatico da stress o determinare l’effetto di un intervento educativo su una popolazione diversificata.\n\n\n\n\n\n56.1.1 Approccio frequentista\nI modelli lineari hanno una lunga storia nella statistica. Come riportato da Stigler (1986), il metodo dei minimi quadrati per adattare un modello di regressione lineare bivariata fu introdotto nel XVIII secolo per problemi di analisi dei dati in astronomia. Ad esempio, gli astronomi lo utilizzavano per determinare il moto della Luna o per modellare i movimenti non periodici di Giove e Saturno. In quel contesto, l’omogeneità dei dati raccolti direttamente dagli astronomi favorì l’adozione di questi metodi, in netto contrasto con le scienze sociali, dove la variabilità dei dati raccolti ritardava l’adozione della regressione.\n\n56.1.2 Il modello lineare bivariato\nNel contesto frequentista, il modello di regressione lineare bivariata consente di predire una variabile continua \\(y\\) sulla base di un singolo predittore continuo \\(x\\). La relazione tra le due variabili è espressa dall’equazione della retta di regressione:\n\\[\ny_i = a + b x_i + e_i, \\quad i = 1, \\dots, n,\n\\tag{56.1}\\]\ndove:\n\n\n\\(a\\) è l’intercetta (valore atteso di \\(y\\) quando \\(x = 0\\)),\n\n\\(b\\) è la pendenza della retta (coefficiente di regressione, che misura il cambiamento atteso in \\(y\\) per unità di incremento in \\(x\\)),\n\n\\(e_i\\) è l’errore residuo (la differenza tra il valore osservato di \\(y_i\\) e il valore predetto dal modello).\n\n\n56.1.2.1 Aspetti principali\n\nStima dei coefficienti\nI coefficienti \\(a\\) e \\(b\\) vengono stimati mediante il metodo dei minimi quadrati, che minimizza la somma dei quadrati degli errori residui (\\(\\sum e_i^2\\)).\n\nInterpretazione dei coefficienti\n\n\n\\(a\\): rappresenta il valore medio previsto di \\(y\\) quando \\(x = 0\\).\n\n\n\\(b\\): indica la variazione media prevista in \\(y\\) per ogni unità di variazione in \\(x\\).\n\n\n\nValutazione del modello\nLa bontà di adattamento del modello viene valutata attraverso:\n\nL’indice di determinazione (\\(R^2\\)), che misura la proporzione della varianza di \\(y\\) spiegata dal modello.\nL’analisi dei residui, che verifica la presenza di eventuali pattern non catturati dal modello.\n\n\n\nQuesto capitolo illustrerà come applicare e interpretare il modello di regressione bivariata, collegandolo successivamente al modello lineare multiplo e agli approcci più avanzati per l’inferenza causale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "href": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n56.2 La Predizione dell’Intelligenza",
    "text": "56.2 La Predizione dell’Intelligenza\nNella presente discussione, esamineremo i dati kidiq che consistono in una raccolta di dati provenienti da una survey su donne adulte americane e i loro figli, selezionati da un sotto-campione del National Longitudinal Survey of Youth (Gelman et al., 2021).\nNello specifico, ci concentreremo sulla relazione tra il punteggio di intelligenza del bambino (kid_score) e quello della madre (mom_iq). Ci proponiamo di valutare se e in quale misura l’intelligenza della madre possa prevedere l’intelligenza del bambino. Per fare ciò, inizieremo ad importare i dati nell’ambiente R.\n\n# Caricamento dei dati\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\n\n# Anteprima dei dati\nhead(kidiq)\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1 121.12        4      27\n#&gt; 2        98      1  89.36        4      25\n#&gt; 3        85      1 115.44        4      27\n#&gt; 4        83      1  99.45        3      25\n#&gt; 5       115      1  92.75        4      27\n#&gt; 6        98      0 107.90        1      18\n\nUn diagramma a dispersione per i dati di questo campione suggerisce la presenza di un’associazione positiva tra l’intelligenza del bambino (kid_score) e l’intelligenza della madre (mom_iq).\n\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.4) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Diagramma a dispersione\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#stima-del-modello-di-regressione-lineare",
    "href": "chapters/linear_models/01_reglin_frequentist.html#stima-del-modello-di-regressione-lineare",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n56.3 Stima del modello di regressione lineare",
    "text": "56.3 Stima del modello di regressione lineare\nCalcoliamo i coefficienti della retta di regressione utilizzando la funzione lm.\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n\n# Coefficienti stimati\ncoef(mod)\n#&gt; (Intercept)      mom_iq \n#&gt;       25.80        0.61\n\nCi sono però infinite rette che, in linea di principio, possono essere usate per “approssimare” la nube di punti nel diagramma a dispersione. È dunque necessario introdurre dei vincoli per selezionare una di queste possibili rette. Il vincolo che viene introdotto dal modello di regressione è quello di costringere la retta a passare per il punto \\((\\bar{x}, \\bar{y})\\).\n\n# Calcola le medie per mom_iq e kid_score\nmean_x &lt;- mean(kidiq$mom_iq, na.rm = TRUE)\nmean_y &lt;- mean(kidiq$kid_score, na.rm = TRUE)\n\n# Aggiungi il punto medio al grafico\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  annotate(\n    \"point\", x = mean_x, y = mean_y, color = \"red\", size = 5, \n    shape = 4, stroke = 3) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Retta di regressione\")\n\n\n\n\n\n\n\nUna retta di regressione che passa per il punto medio \\((\\bar{x}, \\bar{y})\\) (che rappresenta il centro di massa dei dati) è preferibile dal punto di vista statistico poiché minimizza la somma dei quadrati degli errori residui.\nIl campione è costituito da \\(n\\) coppie di osservazioni (\\(x, y\\)).\n\\[\n\\begin{array}{cc}\n\\hline\nx_1 & y_1 \\\\\nx_2 & y_2 \\\\\nx_3 & y_3 \\\\\n\\vdots & \\vdots \\\\\nx_n & y_n \\\\\n\\hline\n\\end{array}\n\\]\nPer ciascuna coppia di valori \\(x_i, y_i\\), il modello di regressione si aspetta che il valore \\(y_i\\) sia associato al corrispondente valore \\(x_i\\) come indicato dalla seguente equazione\n\\[\n\\begin{equation}\n\\mathbb{E}(y_i) = a + b x_i ,\n\\end{equation}\n\\tag{56.2}\\]\novvero:\n\\[\n\\begin{array}{ccc}\n\\hline\nx_i & y_i & \\mathbb{E}(y_i) = a + b x_i \\\\\n\\hline\nx_1 & y_1 & a + b x_1 \\\\\nx_2 & y_2 & a + b x_2 \\\\\nx_3 & y_3 & a + b x_3 \\\\\n\\vdots & \\vdots & \\vdots \\\\\nx_n & y_n & a + b x_n \\\\\n\\hline\n\\end{array}\n\\]\nI valori \\(y_i\\) corrispondono, nell’esempio che stiamo discutendo, alla variabile kid_score. I primi 10 valori della variabile \\(y\\) sono i seguenti:\n\nkidiq$kid_score[0:10]\n#&gt;  [1]  65  98  85  83 115  98  69 106 102  95\n\nPer fare riferimento a ciascuna osservazione usiamo l’indice \\(i\\). Quindi, ad esempio, \\(y_2\\) è uguale a\n\nkidiq$kid_score[2]\n#&gt; [1] 98\n\nIl modello di regressione lineare bivariata, rappresentato dall’equazione \\(y_i = a + b x_i + e_i\\), descrive la relazione tra le variabili \\(x\\) e \\(y\\), dove \\(y\\) è la variabile dipendente (nel nostro esempio, la variabile kid_score) e \\(x\\) è la variabile indipendente (nel nostro esempio, la variabile mom_iq).\nIl valore di \\(y\\) è la somma di due componenti:\n\nla componente deterministica, \\(\\hat{y}_i = a + b x_i\\), rappresenta la porzione della \\(y\\) che è prevedibile conoscendo il valore di \\(x\\);\nla componente aleatoria, \\(e_i\\), rappresenta la porzione della \\(y\\) che non è prevedibile dal modello.\n\nIl modello lineare cerca di trovare i coefficienti \\(a\\) e \\(b\\) che permettono di prevedere la componente deterministica di \\(y\\) conoscendo il valore di \\(x\\). Tuttavia, poiché la retta è solo un’approssimazione della relazione tra \\(x\\) e \\(y\\), la componente deterministica rappresenta solo una stima approssimata della vera relazione tra le due variabili.\nPer valutare l’accuratezza del modello di regressione lineare, è necessario calcolare il residuo\n\\[\ne_i = y_i - (a + b x_i) ,\n\\tag{56.3}\\]\novvero la differenza tra il valore osservato di \\(y\\) e il valore previsto dal modello, \\(\\hat{y}\\). La dimensione del residuo indica quanto la componente aleatoria contribuisce al valore osservato di \\(y\\).\nIl modello di regressione lineare ha tre obiettivi (Fox, 2015):\n\nil primo è quello di trovare i coefficienti \\(a\\) e \\(b\\) che permettono di prevedere la componente deterministica di \\(y\\) conoscendo il valore di \\(x\\);\nil secondo obiettivo è quello di valutare l’accuratezza della predizione fornita dal modello di regressione lineare;\ninfine, il terzo obiettivo è quello dell’inferenza, ovvero quello di capire quali relazioni esistono tra la relazione tra \\(x\\) e \\(y\\) osservata nel campione e la relazione tra le due variabili nella popolazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#stima-dei-coefficienti-di-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#stima-dei-coefficienti-di-regressione",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n56.4 Stima dei coefficienti di regressione",
    "text": "56.4 Stima dei coefficienti di regressione\nIn breve, stiamo cercando di descrivere una relazione tra due variabili, il QI della madre e il QI del bambino, utilizzando un modello di regressione lineare. L’equazione lineare che descrive la relazione tra le due variabili è della forma \\(\\hat{y}_i = a_i + bx_i\\), dove \\(\\hat{y}_i\\) rappresenta la previsione per il QI del bambino \\(i\\)-esimo, \\(a_i\\) e \\(b\\) sono i coefficienti di regressione che vogliamo trovare e \\(x_i\\) è il QI della madre del bambino \\(i\\)-esimo.\nPer trovare i coefficienti di regressione, dobbiamo introdurre dei vincoli per limitare lo spazio delle possibili soluzioni. Il primo vincolo è che la retta di regressione deve passare per il baricentro del grafico a dispersione. Il secondo vincolo è che vogliamo minimizzare la somma dei quadrati dei residui, ovvero la differenza tra il valore osservato e il valore previsto dal modello. I coefficienti di regressione che soddisfano questi vincoli si chiamano coefficienti dei minimi quadrati.\nIl problema di trovare i coefficienti di regressione \\(a\\) e \\(b\\) che minimizzano la somma dei quadrati dei residui ha una soluzione analitica. Questa soluzione si ottiene trovando il punto di minimo di una superficie tridimensionale che rappresenta la somma dei quadrati dei residui. Il punto di minimo è quello per cui il piano tangente alla superficie nelle due direzioni \\(a\\) e \\(b\\) è piatto, cioè le derivate parziali rispetto ad \\(a\\) e \\(b\\) sono uguali a zero. In pratica, ciò significa risolvere un sistema di equazioni lineari con due incognite \\(a\\) e \\(b\\), noto come equazioni normali.\nLa soluzione delle equazioni normali ci fornisce i coefficienti di regressione stimati, che minimizzano la somma dei quadrati dei residui. La formula per il coefficiente \\(a\\) è\n\\[\na = \\bar{y} - b \\bar{x} ,\n\\tag{56.4}\\]\nla formula per il coefficiente \\(b\\) è\n\\[\nb = \\frac{Cov(x, y)}{Var(x)},\n\\tag{56.5}\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) sono le medie delle variabili \\(x\\) e \\(y\\), \\(Cov(x,y)\\) è la covarianza tra \\(x\\) e \\(y\\) e \\(Var(x)\\) è la varianza di \\(x\\).\nQueste equazioni rappresentano la stima dei minimi quadrati dei coefficienti di regressione che ci permettono di trovare la retta che minimizza la somma dei quadrati dei residui.\n\n56.4.1 Calcolo manuale dei coefficienti di regressione\nCalcoliamo i coefficientii dei minimi quadrati con l’Equazione 56.4 e l’Equazione 56.5:\n\n# Calcolo manuale dei coefficienti\ncov_xy &lt;- cov(kidiq$kid_score, kidiq$mom_iq)  # Covarianza tra le due variabili\nvar_x &lt;- var(kidiq$mom_iq)  # Varianza della variabile indipendente\nb &lt;- cov_xy / var_x  # Pendenza (coefficiente b)\nb\n#&gt; [1] 0.61\n\n\n# Intercetta (coefficiente a)\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$mom_iq)\na\n#&gt; [1] 25.8\n\nI risultati replicano quelli ottenuti in precedenza con lm().\n\n56.4.2 Interpretazione\nIl coefficiente \\(a\\) indica l’intercetta della retta di regressione nel diagramma a dispersione. Questo valore rappresenta il punto in cui la retta di regressione interseca l’asse \\(y\\) del sistema di assi cartesiani. Tuttavia, in questo caso specifico, il valore di \\(a\\) non è di particolare interesse poiché corrisponde al valore della retta di regressione quando l’intelligenza della madre è pari a 0, il che non ha senso nella situazione reale. Successivamente, vedremo come è possibile trasformare i dati per fornire un’interpretazione utile del coefficiente \\(a\\).\nInvece, il coefficiente \\(b\\) indica la pendenza della retta di regressione, ovvero di quanto aumenta (se \\(b\\) è positivo) o diminuisce (se \\(b\\) è negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\). Nel caso specifico del QI delle madri e dei loro figli, il coefficiente \\(b\\) ci indica che un aumento di 1 punto del QI delle madri è associato, in media, a un aumento di 0.61 punti del QI dei loro figli.\nIn pratica, il modello di regressione lineare cerca di prevedere le medie dei punteggi del QI dei figli in base al QI delle madri. Ciò significa che non è in grado di prevedere esattamente il punteggio di ciascun bambino in funzione del QI della madre, ma solo una stima della media dei punteggi dei figli quando il QI delle madri aumenta o diminuisce di un punto.\nIl coefficiente \\(b\\) ci dice di quanto aumenta (o diminuisce) in media il QI dei figli per ogni unità di aumento (o diminuzione) del QI della madre. Nel nostro caso, se il QI della madre aumenta di un punto, il QI dei figli aumenta in media di 0.61 punti.\nÈ importante comprendere che il modello statistico di regressione lineare non è in grado di prevedere il valore preciso di ogni singolo bambino, ma solo una stima della media dei punteggi del QI dei figli quando il QI delle madri aumenta o diminuisce. Questa stima è basata su una distribuzione di valori possibili che si chiama distribuzione condizionata \\(p(y \\mid x_i)\\).\nUna rappresentazione grafica del valore predetto dal modello di regressione, \\(\\hat{y}_i = a + bx_i\\) è stato fornito in precedenza. Il diagramma presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). I valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#residui",
    "href": "chapters/linear_models/01_reglin_frequentist.html#residui",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n56.5 Residui",
    "text": "56.5 Residui\nIn precedenza abbiamo detto che il residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione, corrisponde alla distanza verticale tra il valore \\(y_i\\) osservato e il valore \\(\\hat{y}_i\\) predetto dal modello di regressione:\n\\[\ne_i = y_i - (a + b x_i).\n\\]\nPer fare un esempio numerico, consideriamo il punteggio osservato del QI del primo bambino.\n\nkidiq$kid_score[1]\n#&gt; [1] 65\n\nIl QI della madre è\n\nkidiq$mom_iq[1]\n#&gt; [1] 121.1\n\nPer questo bambino, il valore predetto dal modello di regressione è\n\na + b * kidiq$mom_iq[1]\n#&gt; [1] 99.68\n\nL’errore che compiamo per predire il QI del bambino utilizzando il modello di regressione (ovvero, il residuo) è\n\nkidiq$kid_score[1] - (a + b * kidiq$mom_iq[1])\n#&gt; [1] -34.68\n\nPer tutte le osservazioni abbiamo\n\nres &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\nÈ una proprietà del modello di regressione (calcolato con il metodo dei minimi quadrati) che la somma dei residui sia uguale a zero.\n\nsum(res)\n#&gt; [1] 1.444e-11\n\nQuesto significa che ogni valore osservato \\(y_i\\) viene scomposto dal modello di regressione in due componenti distinte. La componente deterministica \\(\\hat{y}_i\\), che è predicibile da \\(x_i\\), è data da \\(\\hat{y}_i = a + b x_i\\). Il residuo, invece, è dato da \\(e_i = y_i - \\hat{y}_i\\). La somma di queste due componenti, ovviamente, riproduce il valore osservato.\n\n# Creazione di un data frame con i valori calcolati\ndf &lt;- data.frame(\n  kid_score = kidiq$kid_score,\n  mom_iq = kidiq$mom_iq,\n  y_hat = a + b * kidiq$mom_iq,\n  e = kidiq$kid_score - (a + b * kidiq$mom_iq),\n  y_hat_plus_e = (a + b * kidiq$mom_iq) + (kidiq$kid_score - (a + b * kidiq$mom_iq))\n)\n\n# Visualizzazione dei primi 6 valori\nhead(df)\n#&gt;   kid_score mom_iq y_hat       e y_hat_plus_e\n#&gt; 1        65 121.12 99.68 -34.678           65\n#&gt; 2        98  89.36 80.31  17.692           98\n#&gt; 3        85 115.44 96.22 -11.217           85\n#&gt; 4        83  99.45 86.46  -3.462           83\n#&gt; 5       115  92.75 82.37  32.628          115\n#&gt; 6        98 107.90 91.62   6.383           98",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#trasformazione-dei-dati",
    "href": "chapters/linear_models/01_reglin_frequentist.html#trasformazione-dei-dati",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n56.6 Trasformazione dei dati",
    "text": "56.6 Trasformazione dei dati\nIn generale, per variabili a livello di scala ad intervalli, l’intercetta del modello di regressione lineare non ha un’interpretazione utile. Questo perché l’intercetta indica il valore atteso di \\(y\\) quando \\(x = 0\\), ma in caso di variabili a scala di intervalli, il valore “0” di \\(x\\) è arbitrario e non corrisponde ad un “assenza” della variabile \\(x\\). Ad esempio, un QI della madre pari a 0 non indica un’assenza di intelligenza, ma solo un valore arbitrario del test usato per misurare il QI. Quindi, sapere il valore medio del QI dei bambini quando il QI della madre è 0 non è di alcun interesse.\nPer fornire all’intercetta del modello di regressione un’interpretazione più utile, dobbiamo trasformare le osservazioni di \\(x\\). Per esempio, esprimiamo \\(x\\) come differenza dalla media. Chiamiamo questa nuova variabile \\(xd\\):\n\nkidiq$xd &lt;- kidiq$mom_iq - mean(kidiq$mom_iq)\n\nkidiq |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age       xd\n#&gt; 1        65      1 121.12        4      27  21.1175\n#&gt; 2        98      1  89.36        4      25 -10.6381\n#&gt; 3        85      1 115.44        4      27  15.4432\n#&gt; 4        83      1  99.45        3      25  -0.5504\n#&gt; 5       115      1  92.75        4      27  -7.2543\n#&gt; 6        98      0 107.90        1      18   7.9018\n\nSe ora usiamo le coppie di osservazioni \\((xd_i, y_i)\\), il diagramma a dispersione assume la forma seguente.\n\n# Aggiungiamo una nuova variabile centrata (scarti dalla media)\nkidiq &lt;- kidiq %&gt;%\n  mutate(xd = mom_iq - mean(mom_iq))\n\n# Calcolo della retta di regressione\nb &lt;- cov(kidiq$xd, kidiq$kid_score) / var(kidiq$xd)\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$xd)\n\n# Grafico con ggplot2\nggplot(kidiq, aes(x = xd, y = kid_score)) +\n  geom_point(alpha = 0.4) +  # Punti del grafico\n  geom_abline(intercept = a, slope = b, color = \"blue\") +  # Retta di regressione\n  labs(\n    x = \"QI della madre (scarti dalla media)\", \n    y = \"QI del bambino\"\n  ) +\n  ggtitle(\"Retta di regressione sui dati centrati\")\n\n\n\n\n\n\n\nIn pratica, abbiamo spostato tutti i punti del grafico lungo l’asse delle \\(x\\), in modo tale che la media dei valori di \\(x\\) sia uguale a 0. Questo non ha cambiato la forma dei punti nel grafico, ma ha solo spostato l’origine dell’asse \\(x\\). La pendenza della linea di regressione tra \\(x\\) e \\(y\\) rimane la stessa, sia per i dati originali che per quelli trasformati. L’unica cosa che cambia è il valore dell’intercetta della linea di regressione, che ora ha un’interpretazione più significativa.\n\nfm1 &lt;- lm(kid_score ~ xd, data = kidiq)\ncoef(fm1)\n#&gt; (Intercept)          xd \n#&gt;       86.80        0.61\n\nL’intercetta rappresenta il punto in cui la retta di regressione incontra l’asse \\(y\\) nel diagramma a dispersione. Nel caso dei dati trasformati, abbiamo spostato la nube di punti lungo l’asse \\(x\\) di una quantità pari a \\(x - \\bar{x}\\), ma le relazioni spaziali tra i punti rimangono invariate. Pertanto, la pendenza della retta di regressione non cambia rispetto ai dati non trasformati. Tuttavia, il valore dell’intercetta viene influenzato dalla trasformazione. In particolare, poiché \\(xd = 0\\) corrisponde a \\(x = \\bar{x}\\) nei dati grezzi, l’intercetta del modello di regressione lineare calcolata sui dati trasformati corrisponde al valore atteso di \\(y\\) quando \\(x\\) assume il valore medio sulla scala dei dati grezzi. In altre parole, l’intercetta del modello di regressione lineare sui dati trasformati rappresenta il valore atteso del QI dei bambini corrispondente al QI medio delle madri.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#il-metodo-dei-minimi-quadrati",
    "href": "chapters/linear_models/01_reglin_frequentist.html#il-metodo-dei-minimi-quadrati",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n56.7 Il metodo dei minimi quadrati",
    "text": "56.7 Il metodo dei minimi quadrati\nPer stimare i coefficienti \\(a\\) e \\(b\\), possiamo minimizzare la somma dei quadrati dei residui tra i valori osservati \\(y_i\\) e quelli previsti \\(a + b x_i\\).\nIniziamo con il creare una griglia per i valori di \\(b\\). Supponiamo che il valore di \\(a\\) sia noto (\\(a = 25.79978\\)). Usiamo R per creare una griglia di valori possibili per \\(b\\).\n\n# Griglia di valori per b\nb_grid &lt;- seq(0, 1, length.out = 1001)\na &lt;- 25.79978  # Intercetta nota\n\nDefiniamo ora una funzione che calcola la somma dei quadrati dei residui (\\(SSE\\)) per ciascun valore di \\(b\\).\n\n# Funzione per la somma dei quadrati dei residui\nsse &lt;- function(a, b, x, y) {\n  sum((y - (a + b * x))^2)\n}\n\nApplichiamo la funzione sse alla griglia di valori \\(b\\) per calcolare la somma dei quadrati dei residui per ogni valore di \\(b\\).\n\n# Calcolo di SSE per ciascun valore di b\nsse_vals &lt;- sapply(\n  b_grid, \n  function(b) sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n)\n\n\n\nsapply:\n\nÈ una funzione di R che applica una funzione ad ogni elemento di un vettore (o lista) e restituisce i risultati in un vettore.\nQui, applica la funzione sse a ciascun valore di \\(b\\) contenuto in b_grid.\n\n\n\nfunction(b):\n\nÈ una funzione anonima definita al volo per specificare come calcolare \\(SSE\\) per ciascun valore di \\(b\\).\nAll’interno, viene chiamata la funzione sse(a, b, x, y) con i seguenti parametri:\n\n\na: il valore dell’intercetta (fissato in precedenza o noto).\n\nb: il valore corrente nella griglia b_grid.\n\nx: la variabile indipendente del dataset (kidiq$mom_iq).\n\ny: la variabile dipendente del dataset (kidiq$kid_score).\n\n\n\n\nIl risultato è un vettore, sse_vals, che contiene i valori di \\(SSE\\) corrispondenti a ciascun valore di \\(b\\) in b_grid.\n\nTracciamo un grafico che mostra la somma dei quadrati dei residui (\\(SSE\\)) in funzione dei valori di \\(b\\), evidenziando il minimo.\n\n# Identificazione del valore di b che minimizza SSE\nb_min &lt;- b_grid[which.min(sse_vals)]\n\n# Creazione del dataframe per ggplot\ndat &lt;- data.frame(b_grid = b_grid, sse_vals = sse_vals)\n\n# Genera il grafico\nggplot(dat, aes(x = b_grid, y = sse_vals)) +\n  geom_line(color = \"blue\", linewidth = 1) +  \n  annotate(\n    \"point\", x = b_min, y = min(sse_vals),\n    color = \"red\", size = 3\n  ) +  # Punto minimo\n  labs(\n    x = expression(paste(\"Possibili valori di \", hat(beta))),\n    y = \"Somma dei quadrati dei residui (SSE)\",\n    title = \"Minimizzazione dei residui quadratici\"\n  ) +\n  annotate(\n    \"text\", x = b_min, y = min(sse_vals), \n    label = expression(hat(beta)), color = \"red\", vjust = -1, hjust = 0.5\n  )\n\n\n\n\n\n\n\nInfine, identifichiamo il valore di \\(b\\) che minimizza la somma dei quadrati dei residui.\n\nb_min\n#&gt; [1] 0.61\n\nCon questa simulazione, abbiamo stimato il coefficiente \\(b\\) minimizzando la somma dei quadrati dei residui.\nQuesto approccio può essere esteso per stimare simultaneamente entrambi i coefficienti (\\(a\\) e \\(b\\)) utilizzando metodi di ottimizzazione più avanzati, come optim in R.\n\noptim_result &lt;- optim(\n  par = c(a = 25, b = 0.5),  # Valori iniziali\n  fn = function(params) {\n    a &lt;- params[1]\n    b &lt;- params[2]\n    sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n  }\n)\n\n# Coefficienti stimati\noptim_result$par\n#&gt;       a       b \n#&gt; 25.7874  0.6101\n\nQuesta simulazione illustra come, tramite il metodo dei minimi quadrati, sia possibile stimare i parametri di un modello bivariato di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n56.8 L’errore standard della regressione",
    "text": "56.8 L’errore standard della regressione\nIl secondo obiettivo del modello di regressione lineare è quello di misurare quanto della variabilità di \\(y\\) possa essere spiegata dalla variabilità di \\(x\\) per ogni osservazione. L’indice di bontà di adattamento del modello viene fornito dalla deviazione standard dei residui, chiamata anche errore standard della stima (o errore standard della regressione), \\(s_e\\).\nPer calcolare \\(s_e\\), si sommano i quadrati dei residui \\(e_i\\) per ogni osservazione e si divide per \\(n-2\\), dove \\(n\\) rappresenta la numerosità del campione e \\(2\\) il numero di coefficienti stimati nel modello di regressione. Si prende poi la radice quadrata del risultato:\n\\[\n\\sqrt{\\frac{1}{n-2} \\sum_{i=1}^n \\big(y_i - (\\hat{a} + \\hat{b}x_i)\\big)^2},\n\\tag{56.6}\\]\nL’indice \\(s_e\\) possiede la stessa unità di misura di \\(y\\) ed è una stima della deviazione standard dei residui nella popolazione.\nIllustriamo il calcolo di \\(s_e\\) con i dati a disposizione. I residui \\(e\\) possono essere calcolati sottraendo ai valori osservati \\(y_i\\) i valori predetti dal modello \\(a + b x_i\\):\n\n# Calcolo dei residui\ne &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\n# Mostriamo i primi 10 residui\nhead(e, 10)\n#&gt;  [1] -34.678  17.692 -11.217  -3.462  32.628   6.383 -41.521   3.865  26.414\n#&gt; [10]  11.208\n\nCalcoliamo il valore medio assoluto dei residui per avere un’indicazione della deviazione media rispetto alla retta di regressione.\n\n# Media assoluta dei residui\nmean(abs(e))\n#&gt; [1] 14.47\n\nL’errore standard della stima \\(s_e\\) si calcola come la radice quadrata della somma dei quadrati dei residui divisa per \\(n-2\\):\n\n# Calcolo di s_e\nse &lt;- sqrt(sum(e^2) / (length(e) - 2))\nse\n#&gt; [1] 18.27\n\nNotiamo che il valore medio assoluto dei residui e l’errore standard \\(s_e\\) non sono identici, ma hanno lo stesso ordine di grandezza. \\(s_e\\) è una misura più rigorosa della deviazione standard dei residui.\nQuesta analisi dimostra come \\(s_e\\) consenta di valutare quanto le previsioni del modello si discostino (in media) dai dati osservati.\n\n56.8.1 Sottostima dell’Errore nel Modello di Regressione\nCome discusso da Gelman et al. (2021), l’errore standard della regressione tende a sottostimare la vera deviazione standard \\(\\sigma\\) dell’errore nel modello di regressione nella popolazione. Questa sottostima è dovuta al fenomeno del sovradimensionamento, dato che i parametri \\(a\\) e \\(b\\) sono stimati utilizzando gli stessi \\(n\\) punti dati su cui vengono calcolati i residui. In altre parole, i residui non sono del tutto indipendenti dal modello.\nUn approccio alternativo per valutare l’errore predittivo e mitigare il problema del sovradimensionamento è la validazione incrociata. In particolare, l’approccio leave-one-out (LOOCV) offre una soluzione semplice ed efficace. Questo metodo consiste nell’adattare il modello \\(n\\) volte, escludendo ogni volta un punto dati, adattando il modello ai rimanenti \\(n-1\\) punti, e utilizzando tale modello per predire l’osservazione esclusa.\n\n56.8.1.1 Procedura Leave-One-Out:\n\n\nPer \\(i = 1, \\ldots, n\\):\n\nAdatta il modello \\(y = a + bx + \\text{errore}\\) ai \\(n-1\\) punti dati \\((x, y)_j, j \\neq i\\). Denomina i coefficienti stimati come \\(\\hat{a}_{-i}\\) e \\(\\hat{b}_{-i}\\).\n\nCalcola il residuo validato incrociato:\n\\[\ne_{\\text{CV}} = y_i - (\\hat{a}_{-i} + \\hat{b}_{-i} x_i).\n\\]\n\nSalva il residuo al quadrato per il calcolo successivo.\n\n\n\nCalcola infine la stima di \\(\\sigma_{\\text{CV}}\\) come:\n\\[\n\\sigma_{\\text{CV}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n e_{\\text{CV}}^2}.\n\\]\n\n\n56.8.1.2 Applicazione Pratica:\nEcco un esempio applicato al modello che predice l’intelligenza del bambino (\\(\\texttt{kid\\_score}\\)) in funzione dell’intelligenza della madre (\\(\\texttt{mom\\_iq}\\)) utilizzando il dataset kidiq.\n\noptions(round = 5)\n\n# Array per salvare i residui validati incrociati\nresiduals_cv &lt;- numeric(nrow(kidiq))\n\n# Loop per la validazione incrociata leave-one-out\nfor (i in 1:nrow(kidiq)) {\n  # Dati di training escludendo l'i-esimo punto\n  train_data &lt;- kidiq[-i, ]\n  test_data &lt;- kidiq[i, ]\n  \n  # Addestramento del modello\n  model &lt;- lm(kid_score ~ mom_iq, data = train_data)\n  \n  # Predizione sull'i-esimo punto\n  y_pred &lt;- predict(model, newdata = test_data)\n  \n  # Calcolo del residuo validato incrociato\n  residual_cv &lt;- test_data$kid_score - y_pred\n  residuals_cv[i] &lt;- residual_cv^2\n}\n\n# Calcolo di sigma_cv\nsigma_cv &lt;- sqrt(mean(residuals_cv))\n\ncat(\"Stima di σ_CV:\", sigma_cv, \"\\n\")\n#&gt; Stima di σ_CV: 18.31\n\nCalcoliamo ora la stima tradizionale di \\(\\sigma\\) utilizzando il modello completo e confrontiamola con \\(\\sigma_{\\text{CV}}\\).\n\n# Modello completo\nfm2 &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Stima tradizionale dell'errore standard della regressione\nres &lt;- summary(fm2)\ncat(\"Errore standard della regressione (tradizionale):\", res$sigma, \"\\n\")\n#&gt; Errore standard della regressione (tradizionale): 18.27\n\nNel caso analizzato, i valori stimati di \\(\\sigma_{\\text{CV}}\\) e \\(\\hat{\\sigma}_e\\) tradizionale possono risultare molto simili. Tuttavia, in generale, la stima di \\(\\sigma_{\\text{CV}}\\) tende a essere leggermente superiore, in quanto riflette meglio l’errore predittivo su dati non utilizzati per adattare il modello. Questo rende \\(\\sigma_{\\text{CV}}\\) una misura più robusta e conservativa dell’incertezza del modello.\nIn conclusione, la validazione incrociata, e in particolare l’approccio LOOCV, rappresenta uno strumento importante per valutare le performance predittive di un modello di regressione e per ottenere stime più affidabili della deviazione standard dell’errore.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#indice-di-determinazione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#indice-di-determinazione",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n56.9 Indice di determinazione",
    "text": "56.9 Indice di determinazione\nUn importante risultato dell’analisi di regressione riguarda la scomposizione della varianza della variabile dipendente \\(y\\) in due componenti: la varianza spiegata dal modello e la varianza residua. Questa scomposizione è descritta mediante l’indice di determinazione \\(R^2\\), che fornisce una misura della bontà di adattamento del modello ai dati del campione.\nPer una generica osservazione \\(x_i, y_i\\), la deviazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) può essere espressa come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\):\n\\[\ny_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}).\n\\]\nLa varianza totale di \\(y\\) può quindi essere scritta come:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(e_i + (\\hat{y}_i - \\bar{y}))^2.\n\\]\nSviluppando il quadrato e sommando, si ottiene:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2.\n\\tag{56.7}\\]\nIl primo termine rappresenta la varianza residua, mentre il secondo termine rappresenta la varianza spiegata dal modello. Questa scomposizione della devianza va sotto il nome di teorema della scomposizione della devianza.\nL’indice di determinazione \\(R^2\\) è definito come il rapporto tra la varianza spiegata e la varianza totale:\n\\[\nR^2 = \\frac{\\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}.\n\\tag{56.8}\\]\nQuesto indice varia tra 0 e 1 e indica la frazione di varianza totale di \\(y\\) spiegata dal modello di regressione lineare. Un valore alto di \\(R^2\\) indica che il modello di regressione lineare si adatta bene ai dati, in quanto una grande parte della varianza di \\(y\\) è spiegata dalla variabile indipendente \\(x\\).\nPer l’esempio in discussione, possiamo calcolare la devianza totale, la devianza spiegata e l’indice di determinazione \\(R^2\\) come segue:\nLa devianza totale misura la variabilità complessiva dei punteggi osservati \\(y\\) rispetto alla loro media:\n\n# Devianza totale\ndev_t &lt;- sum((kidiq$kid_score - mean(kidiq$kid_score))^2)\ndev_t\n#&gt; [1] 180386\n\nLa devianza spiegata misura la variabilità che il modello è in grado di spiegare, considerando i valori predetti \\(a + b x\\):\n\n# Devianza spiegata\ndev_r &lt;- sum(((a + b * kidiq$mom_iq) - mean(kidiq$kid_score))^2)\ndev_r\n#&gt; [1] 36249\n\nL’indice \\(R^2\\) è il rapporto tra la devianza spiegata e la devianza totale, e indica la frazione della variabilità totale che è spiegata dal modello di regressione:\n\n# Indice di determinazione\nR2 &lt;- dev_r / dev_t\nround(R2, 3)\n#&gt; [1] 0.201\n\nPer verificare i calcoli, utilizziamo il modello di regressione lineare in R e leggiamo \\(R^2\\) direttamente dal sommario del modello:\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Sommario del modello per leggere R^2\nsummary(mod)$r.squared\n#&gt; [1] 0.201\n\nIl risultato mostra che circa il 20% della variabilità nei punteggi del QI dei bambini è spiegabile conoscendo il QI delle madri. Questo significa che il modello cattura una porzione rilevante della relazione, ma lascia anche spazio a fattori non inclusi nel modello che influenzano il QI dei bambini.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sul-modello-di-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sul-modello-di-regressione",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n56.10 Inferenza sul modello di regressione",
    "text": "56.10 Inferenza sul modello di regressione\nIl terzo obiettivo del modello di regressione è l’inferenza. Nell’approccio frequentista, l’inferenza viene effettuata calcolando la distribuzione campionaria dei parametri e gli intervalli di fiducia per i parametri. Ad esempio, se si vuole determinare se la pendenza della retta di regressione è maggiore di zero, si calcola l’intervallo di fiducia al 95% per il parametro \\(\\beta\\). Se l’intervallo non include lo zero e se il limite inferiore dell’intervallo è maggiore di zero, si conclude che c’è evidenza di un’associazione lineare positiva tra \\(x\\) e \\(y\\) con un grado di confidenza del 95%.1 Il prossimo capitolo spiegherà come effettuare l’inferenza sui coefficienti del modello di regressione lineare in un contesto bayesiano.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "href": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n56.11 Riflessioni Conclusive",
    "text": "56.11 Riflessioni Conclusive\nIl modello lineare bivariato è uno strumento fondamentale nell’analisi delle relazioni tra due variabili e rappresenta una pietra miliare dell’approccio frequentista. Questo capitolo ha mostrato come il modello consenta di quantificare il grado di associazione tra una variabile indipendente \\(x\\) e una variabile dipendente \\(y\\), utilizzando una relazione lineare.\nGrazie all’approccio frequentista, abbiamo imparato a stimare i coefficienti \\(a\\) (intercetta) e \\(b\\) (pendenza) attraverso il metodo dei minimi quadrati, che minimizza la somma dei quadrati dei residui per trovare la retta che meglio approssima i dati osservati. Inoltre, l’indice di determinazione (\\(R^2\\)) ci ha permesso di valutare la bontà di adattamento del modello e di quantificare quanta parte della variabilità di \\(y\\) è spiegata dalla variabile \\(x\\).\nIn pratica, il modello lineare bivariato consente di rispondere a domande fondamentali, come:\n\nSe il valore della variabile indipendente aumenta o diminuisce, come si comporta la variabile dipendente?\nQual è l’intensità e il segno della relazione tra le due variabili?\n\nLa semplicità del modello lo rendono uno strumento utile non solo per descrivere e analizzare relazioni tra variabili, ma anche per effettuare previsioni. Pur limitandosi a un singolo predittore, il modello lineare bivariato fornisce una base per comprendere relazioni più complesse, come quelle coinvolgenti più variabili indipendenti (regressione multivariata).\nL’approccio frequentista offre una metodologia consolidata per stimare i parametri e valutare il modello, fornendo inferenze utili per analisi pratiche e decisioni informate. Con una solida comprensione di questi concetti, si è pronti a esplorare modelli lineari più complessi e a estendere queste tecniche a scenari più articolati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/01_reglin_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] broom_1.0.7      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.10.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.50         htmlwidgets_1.6.4 lattice_0.22-6   \n#&gt;  [5] tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2       generics_0.1.3   \n#&gt;  [9] parallel_4.4.2    pacman_0.5.1      pkgconfig_2.0.3   R.oo_1.27.0      \n#&gt; [13] Matrix_1.7-2      lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      htmltools_0.5.8.1 pillar_1.10.1    \n#&gt; [21] R.utils_2.12.3    nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37    \n#&gt; [25] stringi_1.8.4     labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4  \n#&gt; [29] fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1  cli_3.6.4        \n#&gt; [33] magrittr_2.0.3    withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [37] rmarkdown_2.29    R.methodsS3_1.8.2 hms_1.1.3         evaluate_1.0.3   \n#&gt; [41] haven_2.5.4       mgcv_1.9-1        rlang_1.1.5       glue_1.8.0       \n#&gt; [45] rstudioapi_0.17.1 jsonlite_1.8.9    R6_2.6.1",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "href": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi (III rist. 2023, Vol. 11, p. 320). Laterza.\n\n\nFox, J. (2015). Applied regression analysis and generalized linear models. Sage publications.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nStigler, S. (1986). The History of Statistics. Belknap Harvard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "href": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "title": "56  La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "Per un approfondimento sull’approccio frequentista alla regressione, si veda, per esempio, Caudek & Luccio (2001).↩︎",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html",
    "href": "chapters/linear_models/02_regr_toward_mean.html",
    "title": "57  La regressione verso la media",
    "section": "",
    "text": "57.1 Introduzione\nIl concetto di regressione verso la media è stato introdotto da Francis Galton, un pioniere della statistica, mentre studiava la trasmissione ereditaria di tratti fisici, in particolare l’altezza. Galton osservò che, quando si confronta l’altezza dei padri con quella dei figli, i figli tendono ad essere più vicini alla media della popolazione rispetto ai loro padri. Questo fenomeno è noto come regressione verso la media.\nImmaginiamo di avere un padre che è più alto della media della popolazione. Ci aspettiamo che suo figlio sia anch’esso più alto della media, ma non tanto quanto il padre. In altre parole, l’altezza del figlio “regredisce” parzialmente verso la media della popolazione. Lo stesso principio si applica ai padri più bassi della media: i loro figli tenderanno ad essere più bassi della media, ma non tanto quanto i padri.\nPerché succede? Quando un padre è alto 75 pollici (mentre la media magari è 69.1), essere così alto potrebbe essere dovuto a molti fattori “eccezionali” combinati (genetici, ambientali, casuali). Il figlio, tuttavia, eredita solo una parte di quei fattori, e probabilmente avrà altri fattori (positivi o negativi) in modo casuale, cosicché la sua altezza si sposta verso la media della popolazione. Questo non vuol dire che il figlio sia basso: rimane comunque al di sopra della media, ma non raggiunge l’estremo del padre.\nIl cuore statistico del fenomeno si trova nella correlazione tra due variabili (in questo caso, altezza del padre e altezza del figlio). Se la correlazione fosse 1 (perfetta), un padre alto in modo eccezionale avrebbe sempre un figlio proporzionalmente alto, senza “riavvicinarsi” alla media. Se invece la correlazione è minore di 1, come succede quasi sempre nel mondo reale, la relazione padre-figlio non è perfetta e vi è una certa variabilità.\nGalton misurò in media una correlazione di circa 0.5 tra altezza paterna e altezza del figlio maschio. Questo valore implica che, se un padre si discosta di 2-3 deviazioni standard sopra la media, il figlio di solito ne recupererà una parte, ma non interamente.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#introduzione",
    "href": "chapters/linear_models/02_regr_toward_mean.html#introduzione",
    "title": "57  La regressione verso la media",
    "section": "",
    "text": "57.1.1 I Dati di Galton\nEsaminiamo il fenomeno della regressione verso la media usando i dati di Galton. Nel pacchetto HistData di R sono disponibili i dati originali raccolti da Galton, che includono informazioni sull’altezza di padri, madri, figli maschi e femmine. Per semplificare l’analisi, possiamo creare un dataset che include solo l’altezza del padre e l’altezza di un figlio maschio scelto casualmente da ogni famiglia:\n\nset.seed(1234)\n\ngalton_heights &lt;- GaltonFamilies |&gt;\n  filter(gender == \"male\") |&gt;\n  group_by(family) |&gt;\n  sample_n(1) |&gt;\n  ungroup() |&gt;\n  select(father, childHeight) |&gt;\n  rename(son = childHeight)\n\nQuesto dataset contiene due colonne: father (altezza del padre) e son (altezza del figlio maschio). Calcolando la media e la deviazione standard delle altezze dei padri e dei figli, otteniamo:\n\ngalton_heights |&gt; \n  summarize(\n    mean_father = mean(father), \n    sd_father   = sd(father),\n    mean_son    = mean(son), \n    sd_son      = sd(son)\n  )\n#&gt; # A tibble: 1 × 4\n#&gt;   mean_father sd_father mean_son sd_son\n#&gt;         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1        69.1      2.55     69.1   2.62\n\nI risultati mostrano che, in media, i padri e i figli hanno altezze simili, anche se le distribuzioni non sono identiche. Un grafico di dispersione (scatterplot) evidenzia una chiara tendenza: padri più alti tendono ad avere figli più alti:\n\ngalton_heights |&gt;\n  ggplot(aes(father, son)) +\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\n57.1.2 Il Coefficiente di Correlazione\nPer quantificare la relazione lineare tra l’altezza del padre e quella del figlio, utilizziamo il coefficiente di correlazione (indicato con \\(r\\) o \\(\\rho\\)). La formula del coefficiente di correlazione è:\n\\[\n\\rho = \\frac{1}{n}\\sum_{i=1}^n\n\\left(\\frac{x_i - \\mu_x}{\\sigma_x}\\right)\n\\left(\\frac{y_i - \\mu_y}{\\sigma_y}\\right).\n\\]\nIn R, possiamo calcolare la correlazione tra l’altezza del padre e quella del figlio con il seguente codice:\n\ngalton_heights |&gt; \n  summarize(r = cor(father, son)) |&gt; \n  pull(r)\n#&gt; [1] 0.4434\n\nNel nostro caso, la correlazione è circa 0.5. Questo valore positivo indica che padri più alti tendono ad avere figli più alti, ma la correlazione non è perfetta. Il coefficiente di correlazione varia tra -1 e 1, dove il valore assoluto misura la forza della relazione lineare.\n\n57.1.3 Stime Condizionate: Previsioni basate sull’Altezza del Padre\nUn modo per fare previsioni è chiedersi: “Se un padre è alto 72 pollici, quale sarà l’altezza media dei figli di tutti i padri di 72 pollici?” In termini statistici, questa è l’aspettativa condizionata \\(\\mathbb{E}(\\text{altezza figlio} \\mid \\text{altezza padre} = 72)\\).\n\nSe filtriamo i dati prendendo solo i padri di altezza 72 pollici, possiamo calcolare la media dell’altezza dei figli in quel sottogruppo.\nTuttavia, questo metodo può essere instabile se il numero di osservazioni nel sottogruppo è piccolo.\n\nAd esempio:\n\ngalton_heights |&gt; \n  filter(round(father) == 72) |&gt;\n  summarize(avg_son = mean(son))\n#&gt; # A tibble: 1 × 1\n#&gt;   avg_son\n#&gt;     &lt;dbl&gt;\n#&gt; 1    70.2\n\nQuesto ci dà la stima condizionata dell’altezza media del figlio di un padre di 72 pollici. Spesso, questa media è maggiore della media generale dei figli, ma meno di quanto il padre (72 pollici) sia sopra la media dei padri. Questo fenomeno è noto come regressione verso la media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#visualizzare-la-regressione-verso-la-media",
    "href": "chapters/linear_models/02_regr_toward_mean.html#visualizzare-la-regressione-verso-la-media",
    "title": "57  La regressione verso la media",
    "section": "\n57.2 Visualizzare la Regressione verso la Media",
    "text": "57.2 Visualizzare la Regressione verso la Media\nRipetiamo ora lo stesso procedimento per tutti i dati. Stratifichiamo i dati raggruppadoli in base a valori simili di altezza del padre. Calcoliamo poi in ogni gruppo la media dell’altezza del figlio:\n\ngalton_heights |&gt;\n  mutate(father_strata = factor(round(father))) |&gt;\n  group_by(father_strata) |&gt;\n  summarize(avg_son = mean(son)) |&gt;\n  ggplot(aes(x = father_strata, y = avg_son)) +\n  geom_point()\n\n\n\n\n\n\n\nNel grafico risultante, ogni punto rappresenta la media dei figli corrispondenti a un determinato “strato” di padri. Se tracciamo anche la retta di regressione, noteremo che i punti si dispongono in modo approssimativamente lineare: a padri più alti corrispondono figli più alti, ma in media meno alti di quanto ci si aspetterebbe se la correlazione fosse perfetta.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#la-retta-di-regressione",
    "href": "chapters/linear_models/02_regr_toward_mean.html#la-retta-di-regressione",
    "title": "57  La regressione verso la media",
    "section": "\n57.3 La Retta di Regressione",
    "text": "57.3 La Retta di Regressione\nPer capire perché, dal punto di vista statistico, si verifica la regressione verso la media, consideriamo il modello di regressione lineare semplice che prevede l’altezza del figlio \\(\\hat{Y}\\) in base all’altezza del padre \\(X\\):\n\\[\n\\hat{Y} = \\beta_0 + \\beta_1 X.\n\\]\n\nQuando standardizziamo i dati (cioè trasformiamo sia \\(X\\) sia \\(Y\\) in “punti z”, sottraendo la media e dividendo per la deviazione standard), la pendenza \\(\\beta_1\\) della retta di regressione diventa esattamente la correlazione \\(\\rho\\).\n\nSe \\(\\rho = 1\\), la pendenza sarebbe 1 e non ci sarebbe alcun “riavvicinamento” alla media: i valori alti di \\(X\\) corrisponderebbero a valori altrettanto alti di \\(Y\\).\n\nSe \\(\\rho &lt; 1\\), la pendenza risulta minore di 1 e ciò significa che, partendo da un valore molto alto (o molto basso) di \\(X\\), la nostra previsione di \\(Y\\) si colloca in una posizione parzialmente più vicina alla media di \\(Y\\) rispetto alla distanza del padre dalla media di \\(X\\). È proprio questo il fenomeno della regressione verso la media.\n\n\n57.3.1 Forma non standardizzata\nNella forma originale (non standardizzata), i coefficienti si calcolano con:\n\\[\n\\beta_1\n= \\rho \\,\\frac{\\sigma_Y}{\\sigma_X},\n\\quad\n\\beta_0\n= \\mu_Y\n- \\beta_1 \\,\\mu_X,\n\\]\ndove:\n\n\n\\(\\mu_X, \\mu_Y\\) sono le medie di \\(X\\) (altezza del padre) e \\(Y\\) (altezza del figlio);\n\n\\(\\sigma_X, \\sigma_Y\\) sono le rispettive deviazioni standard;\n\n\\(\\rho\\) è la correlazione tra \\(X\\) e \\(Y\\).\n\n57.3.2 Forma standardizzata\nNella forma standardizzata, le deviazioni standard di \\(X\\) e \\(Y\\) sono pari a 1 e i coefficienti di regressione diventano:\n\\[\n\\beta_1\n= \\rho,\n\\quad\n\\beta_0\n= 0,\n\\]\ndato che le medie di \\(X\\) e \\(Y\\) sono uguali a zero.\n\n57.3.3 Regressione Verso la Media\nNe segue dunque che, se la correlazione tra le variabili è minore di 1, si verificherà necessariamente il fenomeno della regressione verso la media.\nIn R, possiamo stimare la retta di regressione tramite la stima dei minimi quadrati:\n\nfit &lt;- lm(son ~ father, data = galton_heights)\nfit$coefficients\n#&gt; (Intercept)      father \n#&gt;     37.6324      0.4559\n\nLa funzione lm calcola gli stimatori \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) che minimizzano la somma dei quadrati degli scarti:\n\\[\n\\text{RSS} = \\sum_{i} \\left[y_i - (\\beta_0 + \\beta_1 x_i)\\right]^2.\n\\]\nPossiamo quindi tracciare la retta sullo scatterplot dei dati:\n\ngalton_heights |&gt;\n  ggplot(aes(father, son)) +\n  geom_point(alpha = 0.5) +\n  geom_abline(\n    slope = coef(fit)[2], \n    intercept = coef(fit)[1],\n    color = \"blue\"\n  )\n\n\n\n\n\n\n\nSe standardizziamo i dati, la pendenza della retta di regressione diventa uguale alla correlazione:\n\nfit_2 &lt;- lm(scale(son) ~ scale(father), data = galton_heights)\nfit_2$coefficients\n#&gt;   (Intercept) scale(father) \n#&gt;    -7.598e-15     4.434e-01\n\n\ngalton_heights |&gt;\n  ggplot(aes(scale(father), scale(son))) +\n  geom_point(alpha = 0.5) +\n  geom_abline(\n    slope = coef(fit_2)[2], \n    intercept = coef(fit_2)[1],\n    color = \"blue\"\n  )\n\n\n\n\n\n\n\nIl punto cruciale è ricordare che la pendenza \\(\\beta_1\\) è proporzionale alla correlazione \\(\\rho\\). Se la correlazione non è perfetta (\\(\\rho &lt; 1\\)), allora qualsiasi previsione basata su \\(X\\) (ad esempio, l’altezza del padre) risulterà meno estrema di quanto sia \\(X\\) stesso rispetto alla sua media. In altre parole, un padre altissimo (molto sopra la media) avrà, in media, un figlio sopra la media ma non altrettanto estremo, “regredendo” parzialmente verso il centro della distribuzione.\nIn sintesi: la correlazione imperfetta (\\(\\rho &lt; 1\\)) è la ragione principale per cui un valore estremo di \\(X\\) (ad esempio, un padre molto alto) porta a un valore \\(\\hat{Y}\\) che è sì superiore (o inferiore) alla media, ma meno estremo del padre. Questo “ritorno verso il centro” è ciò che chiamiamo regressione verso la media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#riflessioni-conclusive",
    "href": "chapters/linear_models/02_regr_toward_mean.html#riflessioni-conclusive",
    "title": "57  La regressione verso la media",
    "section": "\n57.4 Riflessioni Conclusive",
    "text": "57.4 Riflessioni Conclusive\n\n\nGalton scoprì il fenomeno della regressione verso la media studiando l’altezza di padri e figli: un padre più alto della media tenderà ad avere un figlio più alto della media, ma non tanto quanto ci si aspetterebbe se la correlazione fosse perfetta.\nQuesto concetto è generale e applicabile in molti contesti. Spesso, un apparente “calo” o “miglioramento” delle prestazioni è semplicemente un effetto statistico di regressione verso la media, non un effetto causale.\nLa retta di regressione minimizza la somma dei quadrati degli errori e la sua pendenza è legata alla correlazione \\(\\rho\\) e al rapporto tra le deviazioni standard \\(\\sigma_Y\\) e \\(\\sigma_X\\).\n\nIn sintesi, la regressione verso la media è un fenomeno statistico che spiega perché, in media, i valori estremi tendono a “ritornare” verso la media della popolazione. Questo concetto è fondamentale per interpretare correttamente i dati e evitare errori di interpretazione causati da correlazioni imperfette.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/02_regr_toward_mean.html#informazioni-sullambiente-di-sviluppo",
    "title": "57  La regressione verso la media",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HistData_0.9-1   thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.10.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#bibliografia",
    "href": "chapters/linear_models/02_regr_toward_mean.html#bibliografia",
    "title": "57  La regressione verso la media",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html",
    "href": "chapters/linear_models/03_reglin_bayes.html",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "58.1 Introduzione\nIn questa sezione della dispensa, esploreremo il modello di regressione lineare bivariata bayesiano, confrontandolo con l’approccio frequentista.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#introduzione",
    "href": "chapters/linear_models/03_reglin_bayes.html#introduzione",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "58.1.1 Modello di Regressione Bayesiano\nL’approccio bayesiano si distingue dai metodi dei minimi quadrati o della massima verosimiglianza, poiché combina le informazioni derivanti dai dati con conoscenze preesistenti, rappresentate da distribuzioni a priori. Questo processo produce distribuzioni a posteriori che aggiornano le credenze iniziali dopo l’osservazione dei dati, superando i limiti delle stime puntuali dei metodi classici.\nNel contesto di un modello lineare bayesiano, indichiamo con \\(y\\) la variabile di risposta, con \\(x\\) le variabili predittive, e con \\(i\\) l’indice delle osservazioni, da 1 al numero totale di dati.\n\n58.1.2 Verosimiglianza\nNel modello bayesiano bivariato, la relazione tra la variabile \\(y\\) e la variabile \\(x\\) è descritta dalla verosimiglianza:\n\\[\ny \\sim \\text{Normale}(\\alpha + \\beta x, \\sigma).\n\\]\nCiò implica che i valori osservati di \\(y\\) sono distribuiti attorno alla retta di regressione \\(\\alpha + \\beta x\\), con una deviazione standard \\(\\sigma\\). Ogni osservazione è quindi una combinazione lineare dell’intercetta \\(\\alpha\\), del coefficiente \\(\\beta\\) che moltiplica la variabile predittiva, e di un termine di errore distribuito normalmente.\n\n58.1.3 Distribuzioni a Priori\nPer definire il modello bayesiano, si specificano distribuzioni a priori per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). Sebbene siano possibili prior uniformi, che esprimono una totale assenza di conoscenza iniziale, è preferibile adottare prior debolmente informativi per garantire maggiore robustezza. Per esempio:\n\\[\n\\alpha \\sim \\mathcal{N}(0, 2.5), \\quad \\beta \\sim \\mathcal{N}(0, 2.5), \\quad \\sigma \\sim \\text{Cauchy}(0, 2.5).\n\\]\nQueste distribuzioni riflettono ipotesi iniziali ragionevoli senza introdurre eccessiva informazione a priori.\n\n58.1.4 Distribuzioni a Posteriori\nLe distribuzioni a posteriori sono ottenute combinando la verosimiglianza dei dati con le distribuzioni a priori tramite il teorema di Bayes. Esse rappresentano lo stato aggiornato delle conoscenze sui parametri, integrando l’informazione empirica con le ipotesi iniziali. L’approccio bayesiano non si limita a fornire stime puntuali, ma restituisce una descrizione completa dell’incertezza associata ai parametri sotto forma di distribuzioni probabilistiche.\nNel contesto di un modello di regressione bivariata, le distribuzioni a posteriori dei parametri \\(\\alpha\\) (intercetta), \\(\\beta\\) (coefficiente angolare), e \\(\\sigma\\) (deviazione standard residua) vengono stimate utilizzando algoritmi MCMC (Markov Chain Monte Carlo). Questi algoritmi consentono di campionare iterativamente dalle distribuzioni a posteriori, garantendo una stima accurata anche in modelli complessi.\nNella sezione successiva, esploreremo come utilizzare la funzione brm() del pacchetto brms per implementare un modello di regressione bayesiano e ottenere le stime a posteriori, analizzandone le proprietà e le implicazioni.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#adattare-una-retta-di-regressione-a-dati-simulati",
    "href": "chapters/linear_models/03_reglin_bayes.html#adattare-una-retta-di-regressione-a-dati-simulati",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "\n58.2 Adattare una Retta di Regressione a Dati Simulati",
    "text": "58.2 Adattare una Retta di Regressione a Dati Simulati\nDefiniamo i parametri e simuliamo i dati.\n\nset.seed(123)\n\n# Definizione delle variabili\nx &lt;- 1:100\nn &lt;- length(x)\na &lt;- 1.5\nb &lt;- 0.5\nsigma &lt;- 10\n\n# Generazione di y\ny &lt;- a + b * x + rnorm(n, 0, sigma)\n\n# Creazione del dataframe\nfake &lt;- tibble(x = x, y = y)\nhead(fake)\n#&gt; # A tibble: 6 × 2\n#&gt;       x      y\n#&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1     1 -3.60 \n#&gt; 2     2  0.198\n#&gt; 3     3 18.6  \n#&gt; 4     4  4.21 \n#&gt; 5     5  5.29 \n#&gt; 6     6 21.7\n\nIniziamo adattando ai dati un modello frequentista:\n\nfm1 &lt;- lm(y ~ x, data = fake)\n\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x, data = fake)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -24.536  -5.524  -0.346   6.485  20.949 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)   1.1360     1.8429    0.62     0.54\n#&gt; x             0.5251     0.0317   16.57   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 9.15 on 98 degrees of freedom\n#&gt; Multiple R-squared:  0.737,  Adjusted R-squared:  0.734 \n#&gt; F-statistic:  275 on 1 and 98 DF,  p-value: &lt;2e-16\n\nPer ottenere l’intervallo di confidenza (nel senso frequentista) della stima dei parametri usiamo:\n\nconfint(fm1, level = 0.95)\n#&gt;               2.5 % 97.5 %\n#&gt; (Intercept) -2.5212  4.793\n#&gt; x            0.4622  0.588\n\nAdattiamo ora ai dati un modello di regressione bayesiano utilizzando brms. Si noti che, anche in questo caso, usiamo la sintassi di Wilkinson y ~ x, come per lm(). Eseguiamo il campionamento:\n\nfm2 &lt;- brm(\n  y ~ x, \n  data = fake,\n  backend = \"cmdstanr\"\n)\n\nCome discusso nell’analisi dell’algoritmo di Metropolis, il primo passo è esaminare le tracce dei parametri per verificare la convergenza dell’algoritmo. La convergenza può essere considerata raggiunta se le catene (nel caso di brm, sono 4 per impostazione predefinita) risultano ben mescolate. Questo si manifesta in un trace plot che mostra una distribuzione uniforme e casuale dei campioni attorno a un valore centrale, senza pattern evidenti o tendenze sistematiche.\nLe tracce dei parametri si ottengono nel modo seguente:\n\nmcmc_trace(\n  fm2, \n  pars = c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nGli istogrammi delle distribuzioni a posteriori dei parametri si generano nel modo seguente:\n\nmcmc_hist(\n  fm2, \n  pars =c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nPer valutare l’autocorrelazione tra i campioni a posteriori del parametro beta, possiamo utilizzare il seguente comando:\n\nmcmc_acf(fm2, \"b_x\")\n\n\n\n\n\n\n\nL’autocorrelazione fornisce informazioni sulla dipendenza tra campioni successivi nella catena di Markov. È normale che i campioni successivi non siano completamente indipendenti, poiché le catene di Markov generano campioni correlati per costruzione. Tuttavia, se l’algoritmo ha raggiunto la convergenza, l’autocorrelazione dovrebbe diminuire rapidamente e diventare trascurabile dopo un numero relativamente piccolo di lag. Questo significa che, dopo un certo numero di passi, i campioni diventano progressivamente meno correlati tra loro, comportandosi in modo simile a campioni indipendenti estratti dalla distribuzione target.\nUn’elevata autocorrelazione su lag più lunghi potrebbe invece indicare problemi di mescolamento delle catene o una mancata convergenza, richiedendo ulteriori verifiche o aggiustamenti, come l’aumento del numero di iterazioni o una diversa parametrizzazione del modello.\nNel caso presente, notiamo una rapida diminuzione dell’autocorrelazione in funzione del numero di passi. Ciò è indicativo del fatto che la convergenza è stata raggiunta.\nUna sintesi numerica dei risultati si trova nel modo seguente:\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: y ~ x \n#&gt;    Data: fake (Number of observations: 100) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     1.11      1.85    -2.55     4.77 1.00     3976     2968\n#&gt; x             0.53      0.03     0.46     0.59 1.00     4028     3041\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     9.26      0.69     7.99    10.75 1.00     3753     3097\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nConfrontiamo le stime ottenute con i valori reali dei parametri simulati. L’intercetta è stata stimata attorno a 1.14, con un’incertezza al 95% che varia tra -2.4 e 4.8. Questo risultato rientra negli intervalli di credibilità previsti, confermando l’accuratezza del modello. Analogamente, per la pendenza \\(b\\), l’intervallo di credibilità al 95% include il valore reale simulato, dimostrando come le stime bayesiane riflettano accuratamente l’incertezza sui parametri.\nSe si utilizza la funzione conditional_effects() viene prodotto un grafico che rappresenta la relazione stimata tra il predittore \\(x\\) e la variabile di risposta \\(y\\).\n\nconditional_effects(fm2) |&gt;\n  plot(points = TRUE)\n\n\n\n\n\n\n\n\n\nLinea stimata (effetto medio):\n\nLa linea centrale del grafico rappresenta il valore medio previsto di\\(y\\) per ogni valore di\\(x\\), dato dalla relazione\\(y = \\alpha + \\beta x\\).\nQuesta linea è calcolata usando i valori medi a posteriori stimati per\\(\\alpha\\) e\\(\\beta\\).\n\n\n\nBande di incertezza (intervalli di credibilità):\n\nLe bande attorno alla linea rappresentano gli intervalli di credibilità (ad esempio, al 95%). Questi mostrano l’incertezza associata alle stime del modello per ogni valore di\\(x\\).\nPiù strette sono le bande, maggiore è la certezza del modello riguardo alla relazione stimata.\n\n\n\nDati osservati:\n\nI punti rappresentano i valori effettivi di\\(y\\) osservati nei dati. Questo consente di confrontare visivamente come i dati reali si allineano con le previsioni del modello.\n\n\n\nIl grafico consente\n\nuna verifica visiva della relazione stimata tra\\(y\\) e\\(x\\);\ndi identificazione di eventuali discrepanze tra i dati osservati e le previsioni del modello;\nuna rappresentazione dell’incertezza nelle stime.\n\nAd esempio, il grafico può mostrare se\\(x\\) ha un effetto credibile su\\(y\\) e con quale livello di incertezza. Se l’effetto di\\(x\\) è debole o nullo, la linea stimata sarà piatta (vicina a zero) e le bande di incertezza saranno ampie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "href": "chapters/linear_models/03_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "\n58.3 Simulazione di Livelli di Copertura",
    "text": "58.3 Simulazione di Livelli di Copertura\nVerifichiamo la copertura degli intervalli di credibilità al 95% attraverso simulazioni ripetute.\n\nset.seed(42)\n# Parametri veri\na_true &lt;- 0.2\nb_true &lt;- 0.3\nsigma_true &lt;- 0.5\n# Numero di simulazioni\nnum_simulations &lt;- 1000\n# Conteggio delle coperture\ncoverage_a &lt;- 0\ncoverage_b &lt;- 0\nfor (i in 1:num_simulations) {\n  # Generazione dei dati\n  x &lt;- 1:20\n  y &lt;- a_true + b_true * x + sigma_true * rnorm(length(x))\n  # Adattamento del modello\n  fit &lt;- lm(y ~ x)\n  ci &lt;- confint(fit) # Intervalli di confidenza\n  # Verifica delle coperture\n  if (ci[1,1] &lt;= a_true & ci[1, 2] &gt;= a_true) {\n    coverage_a &lt;- coverage_a + 1\n  }\n  if (ci[2,1] &lt;= b_true & ci[2, 2] &gt;= b_true) {\n    coverage_b &lt;- coverage_b + 1\n  }\n}\n\n\n# Risultati\ncat(\"Coverage for a:\", coverage_a / num_simulations, \"\\n\")\n#&gt; Coverage for a: 0.952\ncat(\"Coverage for b:\", coverage_b / num_simulations, \"\\n\")\n#&gt; Coverage for b: 0.955\n\nI risultati indicano che i livelli di copertura empirici ottenuti con l’approccio frequentista corrispondono strettamente ai livelli teorici attesi.\nPer proseguire, ripeteremo la simulazione adottando un approccio bayesiano. Useremo la funzione brm() del pacchetto brms al posto di lm().\n#| message: false\n#| warning: false\n#| output: false\n#| \n# Definizione dei parametri\nset.seed(23)\nn_fake &lt;- 1000\ncover_68 &lt;- rep(NA, n_fake)\ncover_95 &lt;- rep(NA, n_fake)\na &lt;- 0.2 # Intercetta vera\nb &lt;- 0.3 # Pendenza vera\nsigma &lt;- 0.5 # Deviazione standard vera\nx &lt;- 1:20 # Variabile indipendente\nn &lt;- length(x) # Numero di osservazioni\n\n# Ciclo per simulazioni\nfor (s in 1:n_fake) {\n  # Generazione dei dati\n  y &lt;- a + b * x + rnorm(n, 0, sigma)\n  fake &lt;- data.frame(x = x, y = y)\n\n  # Adattamento del modello con brms\n  fit &lt;- brm(\n    bf(y ~ 1 + x, center = FALSE),\n    data = fake,\n    family = gaussian(),\n    prior = c(\n      prior(normal(0, 2.5), class = \"b\", coef = \"Intercept\"), # Prior per alpha\n      prior(normal(0, 2.5), class = \"b\", coef = \"x\"), # Prior per beta\n      prior(cauchy(0, 2.5), class = \"sigma\") # Prior per sigma\n    ),\n    seed = 42,\n    iter = 2000, \n    chains = 2, \n    refresh = 0, # Suppress console output\n    backend = \"cmdstanr\"\n  )\n\n  # Estrazione dei coefficienti stimati e delle deviazioni standard\n  posterior_summary &lt;- summary(fit)$fixed\n  b_hat &lt;- posterior_summary[\"x\", \"Estimate\"]\n  b_se &lt;- posterior_summary[\"x\", \"Est.Error\"]\n\n  # Calcolo della copertura\n  cover_68[s] &lt;- abs(b - b_hat) &lt; b_se\n  cover_95[s] &lt;- abs(b - b_hat) &lt; 2 * b_se\n}\n# Summarize the coverage results\nmean_cover_68 &lt;- mean(cover_68, na.rm = TRUE)\nmean_cover_95 &lt;- mean(cover_95, na.rm = TRUE)\ncat(\"Coverage for 68% interval:\", mean_cover_68, \"\\n\")\ncat(\"Coverage for 95% interval:\", mean_cover_95, \"\\n\")\nQuesta seconda simulazione evidenzia che anche i livelli di copertura empirici ottenuti con l’approccio bayesiano si avvicinano ai valori teorici previsti.\nI risultati ottenuti confermano l’efficacia degli intervalli di confidenza e di credibilità stimati attraverso i modelli frequentisti e bayesiani.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#confronti-non-effetti",
    "href": "chapters/linear_models/03_reglin_bayes.html#confronti-non-effetti",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "\n58.4 Confronti, non Effetti",
    "text": "58.4 Confronti, non Effetti\nGelman et al. (2021) sottolineano che i coefficienti di regressione sono spesso denominati “effetti”, ma questa terminologia può trarre in inganno. Gli “effetti”, infatti, implicano una relazione causale. Tuttavia, ciò che un modello di regressione stima non è necessariamente un effetto causale, ma piuttosto un pattern osservazionale. In particolare, ciò che osserviamo è che la media della variabile dipendente nella sottopopolazione con \\(X = x + 1\\) è spesso maggiore o minore (a seconda del segno di \\(\\beta\\)) rispetto alla media della sottopopolazione con \\(X = x\\).\nLa regressione è uno strumento matematico utilizzato principalmente per fare previsioni. I coefficienti di regressione devono quindi essere interpretati come confronti medi. Solo in circostanze specifiche, quando la regressione descrive un processo causale ben definito, è possibile interpretarli come effetti. Tuttavia, questa interpretazione causale deve essere giustificata dal disegno dello studio e non può essere dedotta unicamente dall’uso del modello statistico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#riflessioni-conclusive",
    "href": "chapters/linear_models/03_reglin_bayes.html#riflessioni-conclusive",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "\n58.5 Riflessioni Conclusive",
    "text": "58.5 Riflessioni Conclusive\nIn questo capitolo abbiamo adottato un approccio bayesiano per stimare i parametri di un modello di regressione bivariato. È emerso che, quando i prior sono debolmente informativi, le stime bayesiane tendono a coincidere con quelle ottenute tramite l’approccio frequentista. Tuttavia, il valore dell’approccio bayesiano risiede non solo nella stima dei parametri, ma anche nella possibilità di incorporare conoscenze a priori e di rappresentare esplicitamente l’incertezza nelle stime.\nAl di là della scelta tra approccio frequentista e bayesiano, è cruciale riflettere sul ruolo dei modelli statistici nella ricerca scientifica, in particolare nel contesto psicologico. Come evidenziato da Alexander (2023), i modelli statistici non sono strumenti per rivelare una verità assoluta, ma mezzi per interpretare i dati e costruire significato a partire da essi. Essi non rappresentano la realtà in modo fedele, ma piuttosto funzionano come “lenti” attraverso le quali possiamo mettere a fuoco aspetti specifici del fenomeno studiato.\nI modelli statistici possono essere utilizzati principalmente per due scopi distinti ma complementari: inferenza e previsione.\n\nPrevisione: mira a descrivere le associazioni tra variabili, consentendo di formulare stime future basate sui dati disponibili. È un processo empirico, in cui la bontà del modello viene valutata sulla sua capacità di fare previsioni accurate.\nInferenza: si concentra sull’individuazione di relazioni causali tra variabili. Questo tipo di analisi richiede una progettazione rigorosa, come esperimenti controllati o disegni quasi-sperimentali, e una chiara giustificazione delle ipotesi del modello. La regressione, in particolare, può supportare inferenze causali solo se accompagnata da un contesto teorico robusto e da dati appropriati.\n\nÈ fondamentale ricordare che la regressione rappresenta una forma di media ponderata e, di conseguenza, i suoi risultati possono essere influenzati da bias intrinseci e dalle caratteristiche specifiche del dataset. Pertanto:\n\nLa qualità dei risultati dipende dalla qualità dei dati e dalla correttezza delle ipotesi del modello.\nÈ importante considerare potenziali fonti di bias, come la selezione dei dati, variabili confondenti non incluse nel modello, o ipotesi non verificate sulla linearità delle relazioni.\n\nIn conclusione, l’adozione di un modello statistico non è un fine in sé, ma uno strumento per esplorare, interpretare e comprendere il fenomeno di interesse. Sia che si utilizzi un approccio bayesiano o frequentista, il successo dell’analisi dipende dalla capacità di integrare i risultati quantitativi con una riflessione teorica critica e da un’attenzione costante alla validità delle ipotesi e delle conclusioni.\nPer un approfondimento sul modello bayesiano di regressione lineare, oltre al testo di Johnson et al. (2022), si consiglia Regression and Other Stories, un riferimento fondamentale che fornisce una trattazione chiara e approfondita del tema.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/03_reglin_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6         StanHeaders_2.32.10  brms_2.22.0         \n#&gt;  [4] Rcpp_1.0.14          posterior_1.6.0.9000 cmdstanr_0.8.1      \n#&gt;  [7] thematic_0.1.6       MetBrewer_0.2.0      ggokabeito_0.1.0    \n#&gt; [10] see_0.10.0           gridExtra_2.3        patchwork_1.3.0     \n#&gt; [13] bayesplot_1.11.1     psych_2.4.12         scales_1.3.0        \n#&gt; [16] markdown_1.13        knitr_1.49           lubridate_1.9.4     \n#&gt; [19] forcats_1.0.0        stringr_1.5.1        dplyr_1.1.4         \n#&gt; [22] purrr_1.0.4          readr_2.1.5          tidyr_1.3.1         \n#&gt; [25] tibble_3.2.1         ggplot2_3.5.1        tidyverse_2.0.0     \n#&gt; [28] rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      survival_3.8-3      \n#&gt; [13] processx_3.8.5       magrittr_2.0.3       compiler_4.4.2      \n#&gt; [16] rlang_1.1.5          tools_4.4.2          yaml_2.3.10         \n#&gt; [19] data.table_1.16.4    labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    curl_6.2.0           pkgbuild_1.4.6      \n#&gt; [25] mnormt_2.1.1         plyr_1.8.9           abind_1.4-8         \n#&gt; [28] multcomp_1.4-28      withr_3.0.2          stats4_4.4.2        \n#&gt; [31] grid_4.4.2           inline_0.3.21        xtable_1.8-4        \n#&gt; [34] colorspace_2.1-1     emmeans_1.10.7       MASS_7.3-64         \n#&gt; [37] cli_3.6.4            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [40] generics_0.1.3       RcppParallel_5.1.10  rstudioapi_0.17.1   \n#&gt; [43] reshape2_1.4.4       tzdb_0.4.0           splines_4.4.2       \n#&gt; [46] parallel_4.4.2       matrixStats_1.5.0    vctrs_0.6.5         \n#&gt; [49] V8_6.0.1             Matrix_1.7-2         sandwich_3.1-1      \n#&gt; [52] jsonlite_1.8.9       hms_1.1.3            glue_1.8.0          \n#&gt; [55] codetools_0.2-20     ps_1.8.1             distributional_0.5.0\n#&gt; [58] stringi_1.8.4        gtable_0.3.6         QuickJSR_1.5.1      \n#&gt; [61] munsell_0.5.1        pillar_1.10.1        htmltools_0.5.8.1   \n#&gt; [64] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [67] evaluate_1.0.3       lattice_0.22-6       backports_1.5.0     \n#&gt; [70] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-167        \n#&gt; [73] checkmate_2.3.2      xfun_0.50            zoo_1.8-12          \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#bibliografia",
    "href": "chapters/linear_models/03_reglin_bayes.html#bibliografia",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html",
    "href": "chapters/linear_models/04_synt_sugar.html",
    "title": "59  Zucchero sintattico",
    "section": "",
    "text": "59.1 Introduzione\nI modelli lineari sono così ampiamente utilizzati che sono stati sviluppati appositamente una sintassi, dei metodi e delle librerie per la regressione. Una di queste librerie è brms (Bayesian Regression Models using Stan), già introdotta nel Capitolo 58. brms è un pacchetto R progettato per adattare modelli gerarchici generalizzati lineari (di cui il modello lineare bivariato è un caso particolare), utilizzando una sintassi simile a quella presente nei pacchetti R, come lme4, nlme, rstanarm. brms si basa su Stan, ma offre un’API di livello superiore.\nIn questo capitolo esploreremo in maniera dettagliata come condurre un’analisi di regressione utilizzando brms invece di Stan.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#interfaccia-brms",
    "href": "chapters/linear_models/04_synt_sugar.html#interfaccia-brms",
    "title": "59  Zucchero sintattico",
    "section": "\n59.2 Interfaccia brms\n",
    "text": "59.2 Interfaccia brms\n\nPer fare un esempio, applicheremo il modello di regressione bivariato alla relazione tra altezza e peso. I dati contenuti nel file Howell_18.csv sono parte di un censimento parziale della popolazione !Kung San dell’area di Dobe, raccolti tramite interviste condotte da Nancy Howell alla fine degli anni ’60 (McElreath, 2020). I !Kung San sono una delle popolazioni di raccoglitori-cacciatori più conosciute del ventesimo secolo e sono stati oggetto di numerosi studi antropologici. In questa analisi, consideriamo un sottocampione di dati relativi alla popolazione adulta (di età superiore ai 18 anni).\nImportiamo i dati contenuti nel file Howell_18.csv.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\n\n\ndf |&gt; \n  head()\n#&gt;   height weight age male\n#&gt; 1  151.8  47.83  63    1\n#&gt; 2  139.7  36.49  63    0\n#&gt; 3  136.5  31.86  65    0\n#&gt; 4  156.8  53.04  41    1\n#&gt; 5  145.4  41.28  51    0\n#&gt; 6  163.8  62.99  35    1\n\nGeneriamo un diagramma a dispersione tra le variabili height (altezza) e weight (peso):\n\nggplot(df, aes(x = weight, y = height)) +\n  geom_point() +  \n  labs(x = \"Weight\", y = \"Height\") \n\n\n\n\n\n\n\nbrms si concentra sui modelli di regressione, e questa specializzazione permette di adottare una sintassi più semplice, conosciuta come sintassi di Wilkinson (Wilkinson & Rogers, 1973).\nAd esempio, il modello \\(y = \\alpha + \\beta x + \\varepsilon\\) si implementa come segue:\na_model = brm(y ∼ 1 + x, data = df)\nNella sintassi di Wilkinson, il simbolo tilde (∼) separa la variabile dipendente (a sinistra) dalle variabili indipendenti (a destra). In questo caso, stiamo specificando solo la media (\\(\\mu\\)) della \\(y\\).\nbrms assume di default che la distribuzione di verosimiglianza sia gaussiana, ma è possibile modificarla tramite l’argomento family.\nLa notazione 1 si riferisce all’intercetta. L’intercetta viene inclusa di default. Per cui il modello precedente si può anche scrivere, in maniera equivalente, come\na_model = brm(y ∼ x, data = df)\nSe desideriaamo escludere l’intercetta dal modello, possiamo farlo in questo modo\nno_intercept_model = brm(y ∼ 0 + x, data = df)\noppure in questo modo\nno_intercept_model = brm(y ∼ -1 + x, data = df)\nPer includere ulteriori variabili nel modello, possiamo procedere così:\nmodel_2 = brm(\"y ∼ x + z\", data)\nbrms consente anche di includere effetti a livello di gruppo (gerarchici). Ad esempio, se desideriamo un modello ad effetti misti nel quale abbiamo un effetto diverso di \\(x\\) in ciascun gruppo g, possiamo usare la seguente sintassi:\nmodel_h = brm(y ∼ x + z + (x | g), data = df)\nLa sintassi di Wilkinson non specifica le distribuzioni a priori, ma solo come le variabili dipendenti e indipendenti sono collegate. brms definirà automaticamente delle distribuzioni a priori debolmente informative per noi, rendendo superflua la loro definizione esplicita. Tuttavia, se preferiamo avere un maggiore controllo, possiamo specificarle manualmente, come vedremo in seguito.\n\n59.2.1 Centrare le Variabili\nPer interpretare più facilmente l’intercetta, centriamo la variabile weight rispetto alla media del campione:\n\ndf$weight_c = df$weight - mean(df$weight)\n\nOra, l’intercetta (\\(\\alpha\\)) rappresenterà l’altezza media quando il peso corrisponde alla media del campione.\nAdattiamo un modello lineare con la variabile weight centrata e esaminiamo i risultati:\n\nfit_1 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nLe tracce dei parametri si ottengono nel modo seguente:\n\nmcmc_trace(\n  fit_1, \n  pars = c(\"b_Intercept\", \"b_weight_c\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\n\nsummary(fit_1)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 + weight_c \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.59      0.27   154.06   155.11 1.00     3947     2871\n#&gt; weight_c      0.91      0.04     0.82     0.99 1.00     3945     2996\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     5.10      0.20     4.74     5.51 1.00     4902     3275\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nLa stima dell’intercetta \\(\\alpha\\) = 154.60 suggerisce che, per le persone con un peso corrispondente al valore medio del campione analizzato, l’altezza prevista è di 154.60 cm.\nPossiamo confrontare i risultati ottenuti da brm() con quelli prodotti dall’appriccio frequentista:\n\nfit_2 &lt;- lm(height ~ 1 + weight_c, data = df)\n\n\nsummary(fit_2)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = height ~ 1 + weight_c, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -19.746  -2.884   0.022   3.142  14.774 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  154.597      0.271   570.2   &lt;2e-16\n#&gt; weight_c       0.905      0.042    21.5   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 5.09 on 350 degrees of freedom\n#&gt; Multiple R-squared:  0.57,   Adjusted R-squared:  0.568 \n#&gt; F-statistic:  463 on 1 and 350 DF,  p-value: &lt;2e-16\n\nAnche in questo caso, l’uso di prior debolmente informativi fa in modo che i risultati dei due approcci siano praticamente equivalenti.\n\n59.2.2 Visualizzazione dei Risultati\nPer comprendere la relazione stimata, utilizziamo la funzione conditional_effects:\n\nconditional_effects(fit_1, effects = \"weight_c\")\n\n\n\n\n\n\n\nIl grafico generato mostra:\n\nMedia posteriore: La linea rappresenta la stima centrale dell’altezza per un dato peso.\nIntervallo di densità più alta (HDI): L’area evidenziata intorno alla linea mostra l’incertezza delle stime con un intervallo di probabilità del 95%.\n\nSe si desidera modificare la percentuale dell’intervallo di credibilità, è possibile farlo utilizzando l’argomento prob, per esempio:\n\nconditional_effects(fit_1, effects = \"weight_c\", prob = 0.89)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#distribuzione-a-posteriori-dei-parametri",
    "href": "chapters/linear_models/04_synt_sugar.html#distribuzione-a-posteriori-dei-parametri",
    "title": "59  Zucchero sintattico",
    "section": "\n59.3 Distribuzione a Posteriori dei Parametri",
    "text": "59.3 Distribuzione a Posteriori dei Parametri\nPer esaminare la distribuzione a posteriori dei parametri usiamo la funzione mcmc_plot():\n\nmcmc_plot(fit_1, type = \"dens\")\n\n\n\n\n\n\n\nEsaminiamo in maggiori dettagli il sommario numerico dei parametri stimati:\n\ndraws &lt;- posterior::as_draws(fit_1, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.269   0.00428  0.00391 \n#&gt; 2 b_weight_c    0.906 0.0423  0.000675 0.000681\n\nUtilizziamo la funzione as_draws() che trasforma un oggetto R in un formato compatibile con posterior. Gli argomenti variable = \"^b_\" e regex = TRUEconsentono di selezionare solo i parametri il cui nome inizia con b_: nel nostro caso saranno l’intercetta e la pendenza del modello di regressione lineare.\nSuccessivamente usiamo la funzione summarise_draws() con gli argomenti specificati per un sommario della distribuzione a posteriori dei parametri prescelti.\n\n59.3.1 Spiegazione di mcse_mean e mcse_sd\n\nI valori mcse_mean e mcse_sd sono le Monte Carlo Standard Errors (errori standard Monte Carlo) per la stima della media (mean) e della deviazione standard (sd), rispettivamente. Questi valori quantificano l’incertezza associata al processo di campionamento effettuato durante l’analisi bayesiana, in particolare quando si utilizzano algoritmi Monte Carlo come MCMC (Markov Chain Monte Carlo).\n\n59.3.1.1 mcse_mean\n\n\nRappresenta l’errore standard Monte Carlo per la stima della media.\nIndica quanto la media stimata (\\(\\text{mean}\\)) potrebbe variare a causa della finitezza dei campioni generati dall’algoritmo MCMC.\nUn valore di mcse_mean basso rispetto alla deviazione standard (\\(\\text{sd}\\)) suggerisce che il numero di campioni generati è sufficiente per ottenere una stima accurata della media.\n\n59.3.1.2 mcse_sd\n\n\nRappresenta l’errore standard Monte Carlo per la stima della deviazione standard.\nIndica quanto potrebbe variare la stima della deviazione standard (\\(\\text{sd}\\)) a causa del numero finito di campioni generati.\nAnche qui, un valore basso di mcse_sd rispetto alla sd suggerisce che l’incertezza introdotta dal campionamento è trascurabile.\n\n59.3.2 Come interpretarli?\n\n\nProporzione rispetto alla sd:\n\n\nmcse_mean e mcse_sd dovrebbero essere molto più piccoli rispetto ai rispettivi parametri (mean e sd), idealmente almeno un ordine di grandezza inferiore.\nAd esempio, per b_Intercept, mcse_mean = 0.0044 è molto più piccolo rispetto a sd = 0.2695, indicando che la stima della media è robusta.\n\n\n\nIndicazione della qualità del campionamento:\n\nValori alti di mcse_mean o mcse_sd rispetto alla sd potrebbero indicare che il numero di iterazioni MCMC non è sufficiente, che le catene non sono ben mescolate o che ci sono problemi di convergenza.\n\n\n\nIn sintesi, mcse_mean e mcse_sd sono utili per valutare l’affidabilità delle stime derivate dal campionamento Monte Carlo. Se questi valori sono bassi, possiamo essere confidenti che il numero di campioni è sufficiente per rappresentare accuratamente la distribuzione a posteriori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#specificare-i-priors",
    "href": "chapters/linear_models/04_synt_sugar.html#specificare-i-priors",
    "title": "59  Zucchero sintattico",
    "section": "\n59.4 Specificare i Priors",
    "text": "59.4 Specificare i Priors\nSe vogliamo personalizzare i priors, possiamo utilizzare la funzione get_prior per esplorare quelli predefiniti:\n\nget_prior(height ~ 1 + weight_c, data = df)\n#&gt;                     prior     class     coef group resp dpar nlpar lb ub\n#&gt;  student_t(3, 154.3, 8.5) Intercept                                     \n#&gt;                    (flat)         b                                     \n#&gt;                    (flat)         b weight_c                            \n#&gt;      student_t(3, 0, 8.5)     sigma                                 0   \n#&gt;        source\n#&gt;       default\n#&gt;       default\n#&gt;  (vectorized)\n#&gt;       default\n\n\n\nprior: descrive il prior predefinito assegnato a ciascun parametro del modello. Ad esempio:\n\n\nstudent_t(3, 154.3, 8.5): prior t di Student per l’intercetta con 3 gradi di libertà, una media di 154.3, e una scala di 8.5.\n\n(flat): prior piatto (non informativo) per i coefficienti delle variabili predittive, come \\(b\\) e \\(b_{weight_c}\\).\n\nstudent_t(3, 0, 8.5): prior t di Student per il parametro \\(\\sigma\\) (deviazione standard residua), centrato su 0 con una scala di 8.5.\n\n\n\nclass: identifica la classe di parametro a cui il prior si applica:\n\n\nIntercept: prior per l’intercetta (\\(\\alpha\\)).\n\nb: prior per i coefficienti delle variabili predittive (\\(\\beta\\)).\n\nsigma: prior per il parametro della deviazione standard residua (\\(\\sigma\\)).\n\n\n\ncoef: specifica a quale predittore si riferisce il prior, se applicabile. Ad esempio:\n\nVuoto per l’intercetta (poiché non dipende da un predittore specifico).\n\nweight_c per il coefficiente relativo al predittore weight_c.\n\n\n\nlb e ub: rappresentano rispettivamente i limiti inferiori (lower bound) e superiori (upper bound) per il prior, se specificati. Ad esempio:\n\nPer sigma, il limite inferiore è \\(0\\), dato che la deviazione standard non può essere negativa.\n\n\n\nsource: indica l’origine del prior. Se il prior è predefinito (default), il valore sarà default. Se un prior è specificato manualmente dall’utente, sarà indicato come tale.\n\nOra impostiamo priors espliciti e adattiamo un nuovo modello:\n\nprior_guassian &lt;-\n  prior(normal(160, 10), class = \"b\", coef = \"Intercept\") +\n  prior(normal(0, 5), class = \"b\", coef = \"weight_c\") +\n  prior(cauchy(0, 5), class = \"sigma\")\n\n\nfit_2 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nOtteniamo un sommario numerico dei parametri stimati:\n\ndraws &lt;- posterior::as_draws(fit_2, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.274   0.00445  0.00425 \n#&gt; 2 b_weight_c    0.906 0.0436  0.000661 0.000697\n\nI prior che abbiamo specificato non cambiano in maniera rilevante la soluzione a posteriori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#predizioni-predittive-a-posteriori",
    "href": "chapters/linear_models/04_synt_sugar.html#predizioni-predittive-a-posteriori",
    "title": "59  Zucchero sintattico",
    "section": "\n59.5 Predizioni Predittive a Posteriori",
    "text": "59.5 Predizioni Predittive a Posteriori\nUn aspetto fondamentale nella valutazione di un modello statistico, sia frequentista che bayesiano, è verificare quanto bene i dati osservati siano rappresentati dalle predizioni del modello. Tuttavia, l’approccio e l’interpretazione differiscono tra i due paradigmi.\n\n59.5.1 Confronto Frequentista\nNel caso frequentista, si confrontano i valori predetti dal modello, \\(\\hat{y} = \\hat{\\alpha} + \\hat{\\beta}x\\), con i dati osservati. Questo confronto si basa sull’analisi di: - La vicinanza della retta di regressione stimata ai dati osservati. - L’eventuale presenza di pattern nei dati che si discostano da un andamento lineare. - La variazione della dispersione dei valori di \\(y\\) rispetto a \\(x\\) (ad esempio, per verificare l’ipotesi di omoschedasticità).\n\n59.5.2 Approccio Bayesiano\nNell’approccio bayesiano, si eseguono le stesse verifiche di base, ma l’analisi si arricchisce attraverso l’uso delle Predizioni Predittive a Posteriori (Posterior Predictive Checks, PPCs). Questo metodo consente di confrontare i dati osservati con dati simulati dal modello, utilizzando l’incertezza stimata nelle distribuzioni a posteriori dei parametri.\n\n59.5.3 Costruzione delle Predizioni Predittive a Posteriori\nNel caso di un modello bivariato, il processo per generare un grafico delle Predizioni Predittive a Posteriori è il seguente:\n\nDati osservati: Si parte dall’istogramma lisciato dei dati osservati, che rappresenta la distribuzione empirica di \\(y\\).\n\nSimulazione di dati predetti:\n\nSi estrae un campione casuale di valori \\(\\alpha'\\), \\(\\beta'\\), e \\(\\sigma'\\) dalle distribuzioni a posteriori dei parametri (\\(\\alpha\\), \\(\\beta\\), e \\(\\sigma\\)).\nUsando questi valori, si calcolano dati simulati da una distribuzione normale: \\[\ny_{\\text{sim}} \\sim \\mathcal{N}(\\alpha' + \\beta'x, \\sigma')\n\\] dove \\(x\\) sono i valori predittori osservati.\n\n\nCreazione di istogrammi: Per ogni campione simulato, si costruisce un istogramma lisciato che rappresenta la distribuzione predetta dal modello.\nRipetizione: Il processo viene ripetuto più volte, generando molti istogrammi lisciati.\nConfronto: Tutti gli istogrammi predetti vengono sovrapposti all’istogramma dei dati osservati. Questo consente di confrontare visivamente la capacità del modello di rappresentare la distribuzione dei dati.\n\n59.5.4 Interpretazione\n\n\nBuona corrispondenza: Se gli istogrammi lisciati dei dati simulati si sovrappongono bene all’istogramma dei dati osservati, significa che il modello è in grado di rappresentare adeguatamente il campione corrente.\n\nDiscrepanze: Se vi sono discrepanze sistematiche (ad esempio, picchi o code mancanti nei dati predetti rispetto agli osservati), ciò indica che il modello potrebbe non essere adeguato o che vi sono aspetti dei dati non catturati dal modello.\n\nL’approccio delle Predizioni Predittive a Posteriori è particolarmente potente perché:\n\nIntegra l’incertezza nei parametri del modello.\nPermette di verificare non solo la bontà di adattamento complessiva, ma anche specifici aspetti delle distribuzioni predette.\nÈ visivo e intuitivo, facilitando l’identificazione di discrepanze tra modello e dati.\n\nIn conclusione, le Predizioni Predittive a Posteriori forniscono un modo robusto per valutare l’adeguatezza di un modello bayesiano rispetto ai dati osservati. Se il modello riproduce bene la distribuzione dei dati osservati, si può concludere che è adatto almeno per il campione corrente. In caso contrario, potrebbe essere necessario rivedere le specifiche del modello, come i priors o la struttura delle variabili.\nVerifichiamo dunque le predizioni del modello confrontandole con i dati osservati del campione corrente:\n\npp_check(fit_2)\n\n\n\n\n\n\n\nNel caso presente, vi è una buona corrispondenza tra i dati simulati dal modello e i dati osservati.\nIl grafico seguente analizza gli errori del modello rispetto alla retta di regressione stimata.\n\npp_check(fit_1, type = \"error_scatter_avg\")\n\n\n\n\n\n\n\nQuesto comando utilizza la funzione pp_check() per produrre un grafico che mostra i residui bayesiani, ovvero le differenze tra i dati osservati e quelli predetti dal modello. Nel tipo specifico di grafico scelto (\"error_scatter_avg\"), i residui sono rappresentati rispetto ai valori predetti, consentendo di valutare visivamente se sono distribuiti in modo uniforme.\nDal grafico, si osserva che i residui bayesiani appaiono distribuiti in modo omogeneo rispetto alla retta di regressione (che non è direttamente mostrata nel grafico). Questo suggerisce che:\n\nIl modello cattura correttamente la relazione tra la variabile predittiva e la variabile di risposta.\nNon ci sono pattern sistematici nei residui, come deviazioni non lineari o variazioni della dispersione (eteroschedasticità).\n\nSe fossero presenti pattern evidenti nei residui (ad esempio, una struttura curva o una variazione sistematica della dispersione), ciò indicherebbe che il modello potrebbe non essere adeguato, richiedendo una rivalutazione della sua struttura (ad esempio, aggiungendo termini non lineari o trasformando le variabili).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#regressione-robusta",
    "href": "chapters/linear_models/04_synt_sugar.html#regressione-robusta",
    "title": "59  Zucchero sintattico",
    "section": "\n59.6 Regressione Robusta",
    "text": "59.6 Regressione Robusta\nIn questa sezione introduciamo la regressione robusta. Lo scopo è quello di mostrare quanto sia facile modificare il modello definito da brm per specificare una diversa distribuzione degli errori. Questo non è possibile nel caso dell’approccio frequentista.\nI modelli robusti sono utili in presenza di outlier. Ad esempio, introduciamo un outlier nei dati:\n\ndf_outlier &lt;- df\ndf_outlier$height[1] &lt;- 200\ndf_outlier$weight_c[1] &lt;- -15\n\n\ndf_outlier |&gt; \n  ggplot(aes(x = weight_c, y = height)) +\n    geom_point() +  \n    labs(x = \"Weight\", y = \"Height\") \n\n\n\n\n\n\n\nNotiamo come la presenza di un solo outlier introduce una distorsione nei risultati:\n\nfit_3 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\n\ndraws &lt;- posterior::as_draws(fit_3, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.319   0.00488  0.00496 \n#&gt; 2 b_weight_c    0.846 0.0483  0.000810 0.000734\n\nAdattiamo ora un modello robusto utilizzando una distribuzione \\(t\\) di Student:\n\nfit_4 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  family = student(),\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nI risultati mostrano che il modello \\(t\\) è meno influenzato dagli outlier rispetto al modello gaussiano.\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.273   0.00447  0.00495 \n#&gt; 2 b_weight_c    0.920 0.0415  0.000652 0.000777\n\nIl parametro \\(\\nu\\) della \\(t\\) di Student viene stimato dal modello. Nel caso presente\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"nu\")\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 1 × 5\n#&gt;   variable  mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 nu        6.16  1.68    0.0294  0.0353\n\nCon un parametro \\(\\nu\\) = 6, la \\(t\\) di Student ha delle “code” molto maggiori di una gaussiana, e questo le consene di “assorbire” gli outliers in maniera maggiore che la gaussiana.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#indice-di-determinazione-bayesiano",
    "href": "chapters/linear_models/04_synt_sugar.html#indice-di-determinazione-bayesiano",
    "title": "59  Zucchero sintattico",
    "section": "\n59.7 Indice di Determinazione Bayesiano",
    "text": "59.7 Indice di Determinazione Bayesiano\nCon il pacchetto brms, possiamo calcolare il Bayes \\(R^2\\), che rappresenta l’equivalente bayesiano del classico indice di determinazione \\(R^2\\). Questo indice quantifica la proporzione di varianza spiegata dal modello, tenendo conto dell’incertezza intrinseca delle stime bayesiane.\nIl comando per calcolarlo è:\n\nbayes_R2(fit_4)\n#&gt;    Estimate Est.Error   Q2.5  Q97.5\n#&gt; R2   0.5001   0.02085 0.4567 0.5373\n\nIl comando restituisce un tibble (una tabella ordinata) con le seguenti informazioni:\n\n\nEstimate: La stima media del Bayes \\(R^2\\), cioè la proporzione di varianza spiegata dal modello, basata sulle distribuzioni a posteriori dei parametri.\n\nEst.Error: L’errore standard associato alla stima del \\(R^2\\).\n\nQ2.5 e Q97.5: I limiti inferiore e superiore dell’intervallo di credibilità al 95% per il Bayes \\(R^2\\). Questi valori indicano l’incertezza sul \\(R^2\\), riflettendo la distribuzione a posteriori.\n\nNel caso presente\n\n\nStima del \\(R^2\\): Il modello spiega in media circa il 50% della varianza osservata nella variabile dipendente.\n\nErrore Standard: L’incertezza sulla stima è relativamente bassa (±0.02).\n\nIntervallo di Credibilità: C’è un 95% di probabilità che il vero valore del \\(R^2\\) si trovi tra 0.457 e 0.537.\n\n\n59.7.1 Differenze rispetto al Frequentista \\(R^2\\)\n\n\n\nIncertezza: Il Bayes \\(R^2\\) include un’intera distribuzione a posteriori, permettendo di rappresentare l’incertezza attraverso l’intervallo di credibilità. Questo non è possibile con il \\(R^2\\) frequentista, che fornisce una stima puntuale.\n\nPriors: Il Bayes \\(R^2\\) è influenzato dai priors scelti per i parametri del modello, il che consente una maggiore flessibilità e incorpora conoscenze preesistenti.\n\nIn conclusione, il Bayes \\(R^2\\) è uno strumento potente per valutare l’adattamento di un modello bayesiano, permettendo di quantificare non solo la proporzione di varianza spiegata, ma anche l’incertezza associata alla stima.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#riflessioni-conclusive",
    "href": "chapters/linear_models/04_synt_sugar.html#riflessioni-conclusive",
    "title": "59  Zucchero sintattico",
    "section": "\n59.9 Riflessioni Conclusive",
    "text": "59.9 Riflessioni Conclusive\nQuesto capitolo ha mostrato come utilizzare brms per costruire e interpretare modelli lineari, evidenziando le sue capacità di gestione dei priors, diagnostica e modellizzazione robusta. Grazie alla sua semplicità e flessibilità, brms rappresenta un potente strumento per l’inferenza bayesiana.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/04_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "title": "59  Zucchero sintattico",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidybayes_3.0.7      rstan_2.32.6         StanHeaders_2.32.10 \n#&gt;  [4] cmdstanr_0.8.1       posterior_1.6.0.9000 brms_2.22.0         \n#&gt;  [7] Rcpp_1.0.14          thematic_0.1.6       MetBrewer_0.2.0     \n#&gt; [10] ggokabeito_0.1.0     see_0.10.0           gridExtra_2.3       \n#&gt; [13] patchwork_1.3.0      bayesplot_1.11.1     psych_2.4.12        \n#&gt; [16] scales_1.3.0         markdown_1.13        knitr_1.49          \n#&gt; [19] lubridate_1.9.4      forcats_1.0.0        stringr_1.5.1       \n#&gt; [22] dplyr_1.1.4          purrr_1.0.4          readr_2.1.5         \n#&gt; [25] tidyr_1.3.1          tibble_3.2.1         ggplot2_3.5.1       \n#&gt; [28] tidyverse_2.0.0      rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.5          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] matrixStats_1.5.0    compiler_4.4.2       loo_2.8.0           \n#&gt; [10] vctrs_0.6.5          reshape2_1.4.4       arrayhelpers_1.1-0  \n#&gt; [13] pkgconfig_2.0.3      fastmap_1.2.0        backports_1.5.0     \n#&gt; [16] labeling_0.4.3       utf8_1.2.4           rmarkdown_2.29      \n#&gt; [19] tzdb_0.4.0           ps_1.8.1             xfun_0.50           \n#&gt; [22] jsonlite_1.8.9       parallel_4.4.2       R6_2.6.1            \n#&gt; [25] stringi_1.8.4        estimability_1.5.1   zoo_1.8-12          \n#&gt; [28] pacman_0.5.1         R.utils_2.12.3       Matrix_1.7-2        \n#&gt; [31] splines_4.4.2        timechange_0.3.0     tidyselect_1.2.1    \n#&gt; [34] rstudioapi_0.17.1    abind_1.4-8          yaml_2.3.10         \n#&gt; [37] codetools_0.2-20     curl_6.2.0           processx_3.8.5      \n#&gt; [40] pkgbuild_1.4.6       lattice_0.22-6       plyr_1.8.9          \n#&gt; [43] withr_3.0.2          bridgesampling_1.1-2 coda_0.19-4.1       \n#&gt; [46] evaluate_1.0.3       survival_3.8-3       RcppParallel_5.1.10 \n#&gt; [49] ggdist_3.3.2         pillar_1.10.1        tensorA_0.36.2.1    \n#&gt; [52] checkmate_2.3.2      stats4_4.4.2         distributional_0.5.0\n#&gt; [55] generics_0.1.3       rprojroot_2.0.4      hms_1.1.3           \n#&gt; [58] rstantools_2.4.0     munsell_0.5.1        xtable_1.8-4        \n#&gt; [61] glue_1.8.0           emmeans_1.10.7       tools_4.4.2         \n#&gt; [64] data.table_1.16.4    mvtnorm_1.3-3        grid_4.4.2          \n#&gt; [67] QuickJSR_1.5.1       colorspace_2.1-1     nlme_3.1-167        \n#&gt; [70] cli_3.6.4            svUnit_1.0.6         Brobdingnag_1.2-9   \n#&gt; [73] V8_6.0.1             gtable_0.3.6         R.methodsS3_1.8.2   \n#&gt; [76] digest_0.6.37        TH.data_1.1-3        htmlwidgets_1.6.4   \n#&gt; [79] farver_2.1.2         htmltools_0.5.8.1    R.oo_1.27.0         \n#&gt; [82] lifecycle_1.0.4      MASS_7.3-64",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#bibliografia",
    "href": "chapters/linear_models/04_synt_sugar.html#bibliografia",
    "title": "59  Zucchero sintattico",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392–399.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html",
    "href": "chapters/linear_models/05_one_mean.html",
    "title": "60  Inferenza bayesiana su una media",
    "section": "",
    "text": "60.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#introduzione",
    "href": "chapters/linear_models/05_one_mean.html#introduzione",
    "title": "60  Inferenza bayesiana su una media",
    "section": "\n60.2 Introduzione",
    "text": "60.2 Introduzione\nL’obiettivo principale di questo capitolo è esaminare un contesto che abbiamo già preso in considerazione in precedenza: ci troviamo di fronte a un campione di dati misurati su una scala a intervalli o rapporti e desideriamo effettuare inferenze sulla media della popolazione da cui il campione è stato estratto. Tuttavia, anziché procedere con una derivazione analitica della distribuzione a posteriori della media della popolazione, in questo caso utilizzeremo brms.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#il-modello-normale",
    "href": "chapters/linear_models/05_one_mean.html#il-modello-normale",
    "title": "60  Inferenza bayesiana su una media",
    "section": "\n60.3 Il modello Normale",
    "text": "60.3 Il modello Normale\nI priori coniugati Normali di una Normale non richiedono l’approssimazione numerica ottenuta mediante metodi MCMC. In questo capitolo, tuttavia, ripetiamo l’esercizio descritto nel Capitolo 47 usando brms.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#un-esempio-concreto",
    "href": "chapters/linear_models/05_one_mean.html#un-esempio-concreto",
    "title": "60  Inferenza bayesiana su una media",
    "section": "\n60.4 Un esempio concreto",
    "text": "60.4 Un esempio concreto\nPer applicare il modello Normale, utilizzeremo i dati del censimento parziale dell’area di Dobe dei !Kung San, raccolti attraverso interviste condotte da Nancy Howell alla fine degli anni ’60. I !Kung San sono una suddivisione della popolazione San, che vive nel deserto del Kalahari, tra Namibia, Botswana e Angola, e mantengono un’economia basata su caccia e raccolta. Riprodurremo l’analisi descritta da McElreath (2020), esaminando unicamente i valori dell’altezza di individui di età superiore ai 18 anni.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\ndf |&gt; \n  head()\n#&gt;   height weight age male\n#&gt; 1  151.8  47.83  63    1\n#&gt; 2  139.7  36.49  63    0\n#&gt; 3  136.5  31.86  65    0\n#&gt; 4  156.8  53.04  41    1\n#&gt; 5  145.4  41.28  51    0\n#&gt; 6  163.8  62.99  35    1\n\nIl campione include 352 osservazioni:\n\nlength(df$height)\n#&gt; [1] 352\n\n\nggplot(df, aes(x = height)) +\n  geom_histogram(binwidth = 5, color = \"black\", fill = \"lightgray\") +\n  labs(title = \"Istogramma dell'Altezza\", x = \"Altezza (cm)\", y = \"Frequenza\") +\n  theme(\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\nCome indicato dall’istogramma, i dati sono approssimativamente distribuiti in maniera gaussiana:\n\ndf |&gt;\n  ggplot(aes(sample = height)) +\n  stat_qq() +\n  stat_qq_line(colour = \"red\") +\n  labs(\n    title = \"Normal Q-Q plot\",\n    x = \"Teorici (Z-score)\",\n    y = \"Valori osservati\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\nIn realtà, dal Q-Q plot si nota un piccolo scostamento sistematico. Quando la retta che approssima i punti empirici risulta più piatta rispetto alla diagonale teorica (che avrebbe pendenza 1 se i dati fossero perfettamente normali), la distribuzione empirica risulta meno dispersa di una Gaussiana di riferimento: i quantili empirici aumentano più lentamente di quelli teorici, indicando una varianza leggermente inferiore (o code meno ampie). Nel caso presente, tuttavia, questo scostamento è di modesta entità e si può comunque procedere all’adattamento di un modello gaussiano.\nLa media dei valori dell’altezza nel campione è:\n\nmean(df$height)\n#&gt; [1] 154.6\n\ncon una deviazione standard pari a:\n\nsd(df$height)\n#&gt; [1] 7.742",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#modello-frequentista-semplice",
    "href": "chapters/linear_models/05_one_mean.html#modello-frequentista-semplice",
    "title": "60  Inferenza bayesiana su una media",
    "section": "\n60.5 Modello frequentista semplice",
    "text": "60.5 Modello frequentista semplice\nIniziamo con un modello frequentista molto semplice, in cui ipotizziamo che ogni osservazione \\(y_i\\) sia generata dal modello:\n\\[\ny_i = \\alpha + \\varepsilon_i,\n\\]\ndove \\(\\varepsilon_i\\) è un errore aleatorio con media zero (ad esempio, \\(\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)) e \\(\\alpha\\) è la sola incognita (intercetta). Poiché non ci interessa includere altre variabili predittive, stiamo stimando semplicemente la media di \\(y\\).\nLa stima di \\(\\alpha\\) è basata sul principio di massima verosimiglianza, senza informazioni a priori. In R, con l’approccio frequentista, ci basta usare:\n\nfm1 &lt;- lm(\n  formula = height ~ 1, \n  data = df\n)\n\nQui, height ~ 1 indica che vogliamo un modello con sola intercetta (nessuna covariata). Analizziamo il risultato:\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = height ~ 1, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -18.072  -6.007  -0.292   6.058  24.473 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  154.597      0.413     375   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 7.74 on 351 degrees of freedom\n\n\n\nsummary(fm1) mostra la stima puntuale di \\(\\alpha\\) (che è la media campionaria di height) assieme ad altri indicatori (p-value, R-squared e così via, anche se in questo caso non ha senso parlare di R-squared con un solo parametro).\n\n\n60.5.1 Intervallo di confidenza al 95%\nPer ottenere l’intervallo di confidenza (nel senso frequentista) della stima di \\(\\alpha\\), usiamo:\n\nconfint(fm1, level = 0.95)\n#&gt;             2.5 % 97.5 %\n#&gt; (Intercept) 153.8  155.4\n\nQuesto produce l’intervallo di confidenza al 95% basato su procedure di inferenza classica (stima della varianza e dell’errore standard di \\(\\alpha\\)).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#modello-bayesiano-senza-specificare-priori-priori-uniformi",
    "href": "chapters/linear_models/05_one_mean.html#modello-bayesiano-senza-specificare-priori-priori-uniformi",
    "title": "60  Inferenza bayesiana su una media",
    "section": "\n60.6 Modello bayesiano senza specificare priori (priori uniformi)",
    "text": "60.6 Modello bayesiano senza specificare priori (priori uniformi)\nOra vogliamo replicare lo stesso modello usando un approccio bayesiano con il pacchetto brms. Se non specifichiamo esplicitamente la distribuzione a priori di \\(\\alpha\\), brms usa di default un priore piatto (o debolmente informativo), di fatto molto simile a non avere un’informazione a priori.\nIl codice è analogo:\n\nfm2 &lt;- brm(\n  formula = height ~ 1, \n  data = df,\n  backend = \"cmdstanr\"\n)\n\n\nAnche qui, il modello è \\(y_i = \\alpha + \\varepsilon_i\\), ma gestito in modo bayesiano.\n\nsummary(fm2) mostrerà la posterior mean (o mediana, a seconda dei parametri di configurazione) per \\(\\alpha\\), l’errore standard e l’intervallo di credibilità.\n\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.59      0.41   153.76   155.38 1.00     2729     2179\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.30     7.20     8.37 1.00     3096     2129\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n60.6.1 Intervallo di credibilità\nL’output di summary(fm2) presenta di default l’intervallo di credibilità al 95%. Questo valore può essere modificato con l’argomento prob =, ad esempio summary(fm2, prob = 0.90) per un 90% di credibilità.\nIn assenza di un priore informativo, la distribuzione a posteriori è sostanzialmente uguale a quella massima verosimiglianza (più un’eventuale correzione di normalizzazione), quindi i risultati numerici corrispondono molto da vicino a quelli ottenuti dal metodo frequentista. Piccole discrepanze sono dovute alle approssimazioni MCMC.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#differenze-di-interpretazione-degli-intervalli",
    "href": "chapters/linear_models/05_one_mean.html#differenze-di-interpretazione-degli-intervalli",
    "title": "60  Inferenza bayesiana su una media",
    "section": "\n60.7 Differenze di interpretazione degli intervalli",
    "text": "60.7 Differenze di interpretazione degli intervalli\n\n\nApproccio frequentista:\n\nL’intervallo di confidenza (ad esempio \\([153.78, 155.41]\\)) è un procedimento statistico che, se ripetuto molte volte su campioni diversi, “catturerà” il vero valore di \\(\\alpha\\) nel 95% dei casi. In altre parole, è un’affermazione sul metodo di costruzione dell’intervallo, non sull’incertezza del parametro in sé.\n\nNon è lecito dire “c’è il 95% di probabilità che \\(\\alpha\\) stia nell’intervallo \\([153.78, 155.41]\\)”. La probabilità si riferisce alla procedura di campionamento dei dati, non al parametro (che nel frequentismo è considerato fisso e ignoto).\n\n\n\nApproccio bayesiano:\n\nL’intervallo di credibilità \\([153.78, 155.41]\\) al 95% dice che, dati i dati osservati e la prior (qui praticamente uniforme), c’è il 95% di probabilità che \\(\\alpha\\) appartenga a quell’intervallo.\n\nQui la probabilità è assegnata direttamente al parametro \\(\\alpha\\), perché nella prospettiva bayesiana il parametro è visto come una variabile aleatoria che riflette la nostra incertezza prima dell’osservazione dei dati (prior) e dopo l’osservazione dei dati (posterior).\n\n\n\nIn sintesi:\n\n\nFrequentista: l’intervallo di fiducia è una proprietà della procedura di stima; il parametro è fisso, i dati sono casuali.\n\n\nBayesiano: l’intervallo di credibilità è una proprietà della distribuzione a posteriori; il parametro è casuale (nel senso che abbiamo incertezza su di esso), e i dati sono osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#riportare-i-risultati",
    "href": "chapters/linear_models/05_one_mean.html#riportare-i-risultati",
    "title": "60  Inferenza bayesiana su una media",
    "section": "\n60.8 Riportare i Risultati",
    "text": "60.8 Riportare i Risultati\nNel caso frequentista, il risultato può essere riportato nel modo seguente:\n\nL’analisi ha fornito una stima puntuale di α pari a 154.6, con un intervallo di confidenza al 95% compreso tra [153.8; 155.4].\n\nNel caso bayesiano:\n\nL’analisi bayesiana, condotta con una prior non informativa, ha restituito una stima a posteriori di α pari a 154.6, con un intervallo di credibilità al 95% [153.8; 155.4].",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#conclusioni-intermedie",
    "href": "chapters/linear_models/05_one_mean.html#conclusioni-intermedie",
    "title": "60  Inferenza bayesiana su una media",
    "section": "\n60.9 Conclusioni Intermedie",
    "text": "60.9 Conclusioni Intermedie\n\nCon lm() (modello lineare frequen­tista), otteniamo la stima di \\(\\alpha\\) con massima verosimiglianza e un intervallo di confidenza al 95%.\n\nCon brm() e un priore piatto (o molto debole), il risultato numerico è essenzialmente lo stesso, ma la filosofia interpretativa dell’intervallo \\([153.78, 155.41]\\) cambia.\n\nSe volessimo aggiungere informazioni a priori, potremmo specificare un priore su \\(\\alpha\\) in brm(), e otterremmo stime a posteriori diverse dalle frequentiste, soprattutto se i dati sono poco informativi.\n\nIn questo modo, abbiamo mostrato come lo stesso modello (una semplice stima di media) produca numeri quasi identici in ottica frequentista e bayesiana se il priore è non informativo, pur differendo profondamente nell’interpretazione degli intervalli risultanti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#modello-bayesiano-con-prior",
    "href": "chapters/linear_models/05_one_mean.html#modello-bayesiano-con-prior",
    "title": "60  Inferenza bayesiana su una media",
    "section": "\n60.10 Modello Bayesiano con Prior",
    "text": "60.10 Modello Bayesiano con Prior\nImpostiamo una distribuzione a priori \\(\\mathcal{N}(181, 30)\\) per il parametro \\(\\mu\\) e una distribuzione a priori \\(\\mathcal{N}(0, 20)\\) per il parametro \\(\\sigma\\). Seguendo McElreath (2020), ho impostato la distribuzione a priori per \\(\\mu\\) sul valore della mia altezza, per incorporare nel modello le mie conoscenze precedenti rispetto ai valori dell’altezza.\nPertanto, il modello Normale si definisce nel modo seguente:\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(181, 30) \\notag\\\\\n\\sigma &\\sim \\mathcal{N}(0, 20) \\notag\n\\end{align}\n\\]\nCon questa specifica del modello:\n\nLa variabile casuale \\(Y_i\\) segue una distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nIl parametro \\(\\mu\\) ha una distribuzione a priori normale con media 181 e deviazione standard 30.\nIl parametro \\(\\sigma\\) ha una distribuzione a priori normale con deviazione standard 20, troncata inferiormente a 0.\n\nPer \\(\\sigma\\), la normale troncata con deviazione standard pari a 20 permette una grande variabilità, garantendo valori positivi per la deviazione standard della distribuzione normale di \\(Y_i\\). I parametri \\(\\mu\\) e \\(\\sigma\\) sono sconosciuti e rappresentano l’oggetto dell’inferenza.\n\nfm3 &lt;- brm(\n  formula = height ~ 1,   # Modello con sola intercetta (mu)\n  data    = df,\n  family  = gaussian(),   # Distribuzione Normale\n  prior   = c(\n    prior(normal(181, 30), class = \"Intercept\"),  # Prior su mu\n    prior(normal(0, 20),   class = \"sigma\")       # Prior su sigma\n  ),\n  chains  = 4,\n  iter    = 2000,\n  seed    = 1234,\n  backend = \"cmdstanr\"\n)\n\n\nsummary(fm3)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.80   155.41 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.20     8.38 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nAnche usando questi prior debolmente informativi per \\(\\alpha\\) e \\(\\sigma\\), l’intervallo a posteriori per \\(\\alpha\\) coincide con quello frequentista.\nCalcoliamo ora l’intervallo di credibilità all’89%:\n\nsummary(fm3, prob = 0.89)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.94   155.27 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.32     8.25 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nIl risultato ottenuto replica i valori riportati da McElreath (2020) nella sua discussione dell’analisi di questi dati, anche se McElreath usa una procedura bayesiana diversa da quella presentata qui. McElreath (2020) giustifica la scelta dell’89% nel modo seguente:\n\nWhy 89%? It’s just the default. It displays a quite wide interval, so it shows a high-probability range of parameter values. If you want another interval, such as the conventional and mindless 95%, you can use precis(m4.1,prob=0.95). But I don’t recommend 95% intervals, because readers will have a hard time not viewing them as significance tests. 89 is also a prime number, so if someone asks you to justify it, you can stare at them meaningfully and incant, “Because it is prime.” That’s no worse justification than the conventional justification for 95%.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#funzioni-bayesplot",
    "href": "chapters/linear_models/05_one_mean.html#funzioni-bayesplot",
    "title": "60  Inferenza bayesiana su una media",
    "section": "\n60.11 Funzioni bayesplot\n",
    "text": "60.11 Funzioni bayesplot\n\nIl pacchetto bayesplot mette a disposizione un insieme di funzioni molto utili per visualizzare la distribuzione a posteriori di uno o più parametri e per verificare la bontà di adattamento del modello ai dati.\n\n60.11.1 Traceplot\nUn traceplot consente di verificare la convergenza delle catene MCMC e di controllare l’autocorrelazione dei campioni a posteriori. Nel seguente esempio, si mostrano le tracce (i valori campionati lungo le iterazioni) per i parametri “Intercept” e “sigma”:\n\nmcmc_trace(\n  fm3, \n  pars = c(\"Intercept\", \"sigma\"),\n  facet_args = list(nrow = 2)\n)\n\n\n\n\n\n\n\n\nL’asse orizzontale indica il numero di iterazione MCMC,\n\nL’asse verticale mostra il valore assunto dal parametro in quella iterazione,\n\nAvere catene che si mescolano bene e appaiono “stazionarie” (senza trend crescenti o calanti) è un buon segnale di convergenza.\n\n60.11.2 Distribuzione a posteriori di un singolo parametro\nSe vogliamo visualizzare la distribuzione a posteriori di un singolo parametro (ad esempio l’intercetta, qui chiamata “b_Intercept” nel modello brms), possiamo usare:\n\nmcmc_areas(fm3, regex_pars = \"b_Intercept\", prob = 0.89)\n\n\n\n\n\n\n\n\nViene mostrata la densità a posteriori, con un’area evidenziata corrispondente all’89% di credibilità (specificabile con prob = 0.89 o un altro valore).\n\nSe desideriamo un intervallo di credibilità al 95%, useremo prob = 0.95.\n\n60.11.3 Rappresentazione congiunta di due parametri\nPer studiare la relazione tra due parametri (ad esempio “Intercept” e “sigma”):\n\nmcmc_scatter(fm3, pars = c(\"Intercept\", \"sigma\"))\n\n\n\n\n\n\n\n\nSi ottiene un diagramma di dispersione dei campioni a posteriori sui due assi, uno per ciascun parametro, con eventuali isodensità che mostrano le aree più probabili nella distribuzione congiunta.\n\n60.11.4 Posterior Predictive Check\nLa funzione pp_check() è essenziale per valutare se il modello è in grado di riprodurre i dati osservati:\n\npp_check(fm3)\n\n\n\n\n\n\n\n\nQuesta funzione genera un confronto tra la distribuzione dei dati reali (rappresentati, ad esempio, con una linea nera su un istogramma) e la distribuzione di diversi dataset simulati dal modello, sfruttando la distribuzione a posteriori dei parametri (\\(\\alpha\\), \\(\\sigma\\), ecc.).\n\nPoiché il modello bayesiano è generativo, possiamo campionare nuovi dati “fittizi” a partire da ogni draw della posterior: in questo modo otteniamo molteplici dataset simulati, ognuno generato con un diverso valore di \\(\\alpha\\) e \\(\\sigma\\) estratto dalle distribuzioni posteriori.\n\nNel grafico prodotto da pp_check(), i dati osservati compaiono spesso come linea continua nera, mentre i dati simulati dal modello (ad esempio, 8 repliche di default) sono mostrati in colori più chiari o linee semitrasparenti. Se la distribuzione empirica si sovrappone bene a quelle generate, significa che il modello spiega adeguatamente i dati.\n\nNel nostro caso, notiamo che le distribuzioni simulate risultano molto simili a quella osservata, indicando che la stima di \\(\\alpha\\) e \\(\\sigma\\) cattura in modo soddisfacente la variabilità dei dati.\n\nSe invece avessimo osservato discrepanze sistematiche (ad esempio, dati reali con code più pesanti, oppure un picco in posizioni diverse rispetto alle distribuzioni simulate), ci saremmo insospettiti riguardo all’adeguatezza del modello. In situazioni del genere, conviene rivedere le assunzioni (e.g. normalità, varianza costante, eventuali covariate assenti, ecc.) prima di trarre conclusioni dai risultati a posteriori.\n\nIn sintesi, il pacchetto bayesplot fornisce strumenti fondamentali per:\n\n\nValutare la convergenza delle catene MCMC (traceplot, autocorrelation plots),\n\n\nEsplorare la distribuzione a posteriori dei parametri (mcmc_areas, mcmc_density, mcmc_scatter, …),\n\n\nVerificare la bontà del modello rispetto ai dati osservati mediante posterior predictive checks (pp_check).\n\nQueste analisi grafiche forniscono informazioni cruciali sia sulla qualità del campionamento (e dunque sulla stabilità delle stime) sia sull’adeguatezza delle ipotesi modellistiche adottate.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#lapproccio-tradizionale",
    "href": "chapters/linear_models/05_one_mean.html#lapproccio-tradizionale",
    "title": "60  Inferenza bayesiana su una media",
    "section": "\n60.12 L’approccio Tradizionale",
    "text": "60.12 L’approccio Tradizionale\nPrima dell’avvento dei metodi bayesiani e di altri approcci moderni, l’inferenza sulla media di una popolazione veniva spesso affrontata ricorrendo al test t di Student.\n\n60.12.1 La statistica T di Student\nIl test si basa sulla seguente statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}},\n\\]\ndove:\n\n\n\\(\\bar{X}\\) è la media campionaria di \\(n\\) osservazioni,\n\n\n\\(\\mu_0\\) è il valore ipotizzato dalla cosiddetta “ipotesi nulla” (solitamente \\(\\mu_0 = 0\\), ma può essere qualsiasi valore di riferimento),\n\n\n\\(s\\) è la deviazione standard campionaria corretta (ovvero stimatore di \\(\\sigma\\)),\n\n\n\\(n\\) è la dimensione del campione.\n\nQuando \\(\\sigma\\) (deviazione standard vera) è sconosciuta e sostituita da \\(s\\), la statistica \\(\\,T\\) segue (in teoria) una distribuzione t di Student con \\(n - 1\\) gradi di libertà:\n\\[\nT \\sim t_{(n-1)}.\n\\]\n\n60.12.2 Collegamento con la distribuzione Z\nSe \\(\\sigma\\) fosse nota, useremmo la statistica:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}},\n\\]\nla quale segue una distribuzione Normale Standard (\\(Z \\sim \\mathcal{N}(0,1)\\)). Quando invece \\(\\sigma\\) è sostituita da \\(s\\), la distribuzione di questa statistica diventa una t di Student (che, per \\(n\\) grande, si avvicina molto alla \\(\\mathcal{N}(0,1)\\)).\n\n60.12.3 Intervallo di confidenza\nCon il test t di Student, si ottiene anche il tradizionale intervallo di confidenza al 95% per \\(\\mu\\):\n\\[\n\\bar{X} \\pm t_{0.975,\\,n-1} \\cdot \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(t_{0.975,\\,n-1}\\) è il quantile al 97.5% della distribuzione t con \\(n-1\\) gradi di libertà (circa 2.0 se \\(n\\) è sufficientemente grande, mentre 1.96 è il valore per la distribuzione normale standard).\n\n60.12.3.1 Esempio in R\nNell’esempio riportato, se vogliamo costruire l’intervallo di confidenza al 95% manualmente, possiamo scrivere:\n\nmean(df$height) + c(-1, 1) * \n  qt(0.975, length(df$height) - 1) * \n  (sd(df$height) / sqrt(length(df$height)))\n#&gt; [1] 153.8 155.4\n\noppure usare direttamente la funzione:\n\nt.test(df$height, mu = 0)\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  df$height\n#&gt; t = 375, df = 351, p-value &lt;2e-16\n#&gt; alternative hypothesis: true mean is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  153.8 155.4\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt;     154.6\n\nche restituisce sia il valore della statistica T, sia l’intervallo di confidenza e il p-value del test t (ipotizzando, in questo esempio, \\(\\mu_0 = 0\\) come ipotesi nulla).\n\n60.12.4 Confronto con il modello di regressione a sola intercetta\nSi noti che i risultati (media stimata e intervallo di confidenza) coincidono con quanto si otterrebbe usando una regressione lineare con sola intercetta (come lm(height ~ 1, data=df)) e richiedendo l’intervallo di confidenza con confint(). Sia il test \\(t\\) di Student sia la regressione lineare semplice (senza covariate) condividono infatti le stesse assunzioni di base e forniscono risultati equivalenti per quanto riguarda l’inferenza sulla media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/05_one_mean.html#informazioni-sullambiente-di-sviluppo",
    "title": "60  Inferenza bayesiana su una media",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6         StanHeaders_2.32.10  brms_2.22.0         \n#&gt;  [4] Rcpp_1.0.14          bayestestR_0.15.2    posterior_1.6.0.9000\n#&gt;  [7] cmdstanr_0.8.1       thematic_0.1.6       MetBrewer_0.2.0     \n#&gt; [10] ggokabeito_0.1.0     see_0.10.0           gridExtra_2.3       \n#&gt; [13] patchwork_1.3.0      bayesplot_1.11.1     psych_2.4.12        \n#&gt; [16] scales_1.3.0         markdown_1.13        knitr_1.49          \n#&gt; [19] lubridate_1.9.4      forcats_1.0.0        stringr_1.5.1       \n#&gt; [22] dplyr_1.1.4          purrr_1.0.4          readr_2.1.5         \n#&gt; [25] tidyr_1.3.1          tibble_3.2.1         ggplot2_3.5.1       \n#&gt; [28] tidyverse_2.0.0      rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.5          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] ggridges_0.5.6       matrixStats_1.5.0    compiler_4.4.2      \n#&gt; [10] loo_2.8.0            vctrs_0.6.5          reshape2_1.4.4      \n#&gt; [13] pkgconfig_2.0.3      fastmap_1.2.0        backports_1.5.0     \n#&gt; [16] labeling_0.4.3       rmarkdown_2.29       tzdb_0.4.0          \n#&gt; [19] ps_1.8.1             xfun_0.50            jsonlite_1.8.9      \n#&gt; [22] parallel_4.4.2       R6_2.6.1             stringi_1.8.4       \n#&gt; [25] estimability_1.5.1   zoo_1.8-12           pacman_0.5.1        \n#&gt; [28] R.utils_2.12.3       Matrix_1.7-2         splines_4.4.2       \n#&gt; [31] timechange_0.3.0     tidyselect_1.2.1     rstudioapi_0.17.1   \n#&gt; [34] abind_1.4-8          yaml_2.3.10          codetools_0.2-20    \n#&gt; [37] curl_6.2.0           processx_3.8.5       pkgbuild_1.4.6      \n#&gt; [40] lattice_0.22-6       plyr_1.8.9           withr_3.0.2         \n#&gt; [43] bridgesampling_1.1-2 coda_0.19-4.1        evaluate_1.0.3      \n#&gt; [46] survival_3.8-3       RcppParallel_5.1.10  pillar_1.10.1       \n#&gt; [49] tensorA_0.36.2.1     checkmate_2.3.2      stats4_4.4.2        \n#&gt; [52] insight_1.0.2        distributional_0.5.0 generics_0.1.3      \n#&gt; [55] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [58] munsell_0.5.1        xtable_1.8-4         glue_1.8.0          \n#&gt; [61] emmeans_1.10.7       tools_4.4.2          data.table_1.16.4   \n#&gt; [64] mvtnorm_1.3-3        grid_4.4.2           QuickJSR_1.5.1      \n#&gt; [67] colorspace_2.1-1     nlme_3.1-167         cli_3.6.4           \n#&gt; [70] Brobdingnag_1.2-9    V8_6.0.1             gtable_0.3.6        \n#&gt; [73] R.methodsS3_1.8.2    digest_0.6.37        TH.data_1.1-3       \n#&gt; [76] htmlwidgets_1.6.4    farver_2.1.2         htmltools_0.5.8.1   \n#&gt; [79] R.oo_1.27.0          lifecycle_1.0.4      MASS_7.3-64",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#bibliografia",
    "href": "chapters/linear_models/05_one_mean.html#bibliografia",
    "title": "60  Inferenza bayesiana su una media",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html",
    "href": "chapters/linear_models/06_prediction_stan.html",
    "title": "61  Predizione e inferenza",
    "section": "",
    "text": "61.1 Introduzione\nGelman et al. (2021) osservano che l’inferenza bayesiana si sviluppa in tre passaggi fondamentali, che vanno oltre la stima classica. In primo luogo, i dati e il modello vengono combinati per formare una distribuzione a posteriori, che solitamente viene riassunta tramite le distribuzioni a posteriori dei parametri del modello. In secondo luogo, è possibile propagare l’incertezza presente in questa distribuzione, ottenendo previsioni basate su simulazioni per risultati non osservati o futuri, tenendo conto dell’incertezza nei parametri del modello. Infine, è possibile integrare ulteriori informazioni nel modello utilizzando una distribuzione a priori. Questo capitolo si concentra sui temi della previsione e dell’inferenza, con particolare attenzione all’incertezza della retta di regressione e alle distribuzioni predittive.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#predizione",
    "href": "chapters/linear_models/06_prediction_stan.html#predizione",
    "title": "61  Predizione e inferenza",
    "section": "\n61.2 Predizione",
    "text": "61.2 Predizione\nPer discutere i temi della predizione e dell’inferenza bayesiana nel contesto del modello bayesiano di regressione lineare bivariata, esamineremo nuovamente il set di dati relativo alla relazione tra Tense Arousal (TA1) e ansia di stato (state1).\n\ndf &lt;- rio::import(here::here(\"data\", \"affect.csv\")) |&gt; \n  dplyr::select(state1, TA1)\ndf |&gt; \n  head()\n#&gt;   state1 TA1\n#&gt; 1     41  11\n#&gt; 2     26   5\n#&gt; 3     31   8\n#&gt; 4     28   8\n#&gt; 5     47  12\n#&gt; 6     43  10",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#distribuzione-predittiva-a-priori",
    "href": "chapters/linear_models/06_prediction_stan.html#distribuzione-predittiva-a-priori",
    "title": "61  Predizione e inferenza",
    "section": "\n61.3 Distribuzione Predittiva a Priori",
    "text": "61.3 Distribuzione Predittiva a Priori\nConsideriamo il modello bayesiano di regressione lineare bivariata che include prior uniformi per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). Utilizzeremo il pacchetto brms per specificare e adattare il modello, concentrandoci in particolare sulla distribuzione predittiva a priori, ovvero sulle previsioni generate dal modello basandosi esclusivamente sulle distribuzioni a priori, senza considerare i dati osservati.\n\n61.3.1 Specificazione del modello con prior predittivi\nPer esaminare la distribuzione predittiva a priori, specifichiamo il modello impostando l’argomento sample_prior = \"only\". Questo ci permette di generare previsioni basate solo sui prior, ignorando i dati del campione.\n\n# Prior predictive check con sample_prior = \"only\"\nmodel_prior &lt;- brm(\n  formula = TA1 ~ state1, \n  data = df, \n  prior = c(\n    prior(uniform(-50, 50), class = \"Intercept\"),  # Prior per alpha\n    prior(uniform(-50, 50), class = \"b\"),          # Prior per beta\n    prior(uniform(0, 50), class = \"sigma\")         # Prior per sigma\n  ), \n  sample_prior = \"only\",  # Campiona solo dai prior\n  backend = \"cmdstanr\",\n  silent = 0\n)\n\n\n61.3.2 Visualizzazione della distribuzione predittiva a priori\nUtilizziamo la funzione pp_check per visualizzare la distribuzione predittiva a priori e confrontarla con i dati osservati. Questo passaggio è fondamentale per valutare se i prior scelti sono realistici e appropriati per il contesto del problema.\n\n# Visualizzazione del prior predictive check\npp_check(model_prior) + xlim(-100, 100)\n\n\n\n\n\n\n\n\n61.3.3 Interpretazione dei risultati\nDalla visualizzazione, notiamo che la distribuzione dei dati previsti dal modello, basata esclusivamente sui prior e sul modello generativo ipotizzato, è molto più ampia rispetto alla distribuzione dei dati effettivi. Questo suggerisce che i prior scelti sono troppo ampi e poco informativi. In altre parole, le previsioni generate dai prior coprono un intervallo di valori eccessivamente vasto, che non riflette adeguatamente la variabilità osservata nei dati reali.\n\n61.3.3.1 Implicazioni\n\n\nPrior troppo ampi: Quando i prior sono troppo ampi, il modello genera previsioni che possono essere irrealistiche o eccessivamente disperse. Questo può portare a una scarsa capacità del modello di adattarsi ai dati osservati una volta che questi vengono incorporati.\n\nPrior informativi: Per migliorare il modello, potrebbe essere necessario utilizzare prior più informativi, che riflettano meglio la conoscenza preesistente sul fenomeno in studio. Ad esempio, limitare l’intervallo dei prior per \\(\\alpha\\) e \\(\\beta\\) o scegliere distribuzioni a priori più realistiche per \\(\\sigma\\).\n\nIn sintesi, il prior predictive check è uno strumento essenziale per valutare l’adeguatezza delle distribuzioni a priori scelte. Attraverso questo controllo, possiamo identificare prior troppo ampi o inappropriati, che potrebbero compromettere la qualità delle inferenze bayesiane. Nel nostro caso, i risultati suggeriscono la necessità di rivedere i prior, adottando scelte più informative e coerenti con la realtà dei dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#modello-di-regressione-lineare-bayesiana",
    "href": "chapters/linear_models/06_prediction_stan.html#modello-di-regressione-lineare-bayesiana",
    "title": "61  Predizione e inferenza",
    "section": "\n61.4 Modello di Regressione Lineare Bayesiana",
    "text": "61.4 Modello di Regressione Lineare Bayesiana\nIn questa sezione, specifichiamo e adattiamo un modello di regressione lineare bivariata utilizzando prior uniformi per i parametri \\(\\alpha\\) (intercetta), \\(\\beta\\) (coefficiente angolare) e \\(\\sigma\\) (deviazione standard). L’obiettivo è ottenere la distribuzione a posteriori dei parametri del modello e confrontare i risultati con quelli ottenuti tramite il metodo di massima verosimiglianza.\n\n61.4.1 Specificazione del Modello con Prior Uniformi\nUtilizziamo il pacchetto brms per specificare il modello di regressione lineare. I prior scelti sono uniformi e coprono un intervallo ampio per ciascun parametro, riflettendo un approccio inizialmente non informativo.\n\n# Specificazione del modello con prior uniformi\nmodel &lt;- brm(\n  formula = TA1 ~ state1,  # Formula del modello\n  data = df,               # Dati\n  prior = c(\n    prior(uniform(-50, 50), class = \"Intercept\"),  # Prior per alpha\n    prior(uniform(-50, 50), class = \"b\"),          # Prior per beta\n    prior(uniform(0, 50), class = \"sigma\")         # Prior per sigma\n  ),\n  seed = 123,              # Seme per la riproducibilità\n  chains = 4,              # Numero di catene MCMC\n  iter = 4000,             # Numero totale di iterazioni (2000 warmup, 2000 sampling)\n  warmup = 2000,           # Iterazioni di warmup\n  backend = \"cmdstanr\",    # Backend per l'ottimizzazione\n  silent = 0               # Mostra messaggi di avviso\n)\n\n\n61.4.2 Esame delle Distribuzioni a Posteriori\nPer esaminare le distribuzioni a posteriori dei parametri, utilizziamo la funzione summary. Questo ci permette di ottenere stime puntuali, intervalli di credibilità e altre statistiche rilevanti.\n\nsummary(model)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: TA1 ~ state1 \n#&gt;    Data: df (Number of observations: 78) \n#&gt;   Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     1.57      1.28    -1.01     4.07 1.00     8973     5508\n#&gt; state1        0.27      0.03     0.21     0.33 1.00     8503     4886\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     2.72      0.23     2.31     3.20 1.00     8001     6020\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nUn aspetto cruciale è che la distribuzione a posteriori non fornisce solo informazioni sui singoli parametri, ma anche sulle loro interdipendenze. Queste relazioni sono riflesse nei campioni a posteriori, che possono essere ulteriormente analizzati e trasformati.\n\n61.4.3 Confronto con il Metodo di Massima Verosimiglianza\nPer confrontare i risultati bayesiani con quelli classici, stimiamo il modello di regressione lineare utilizzando il metodo di massima verosimiglianza.\n\nsummary(lm(TA1 ~ state1, data = df))\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = TA1 ~ state1, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -7.238 -1.754  0.159  1.973  6.302 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)   1.5555     1.2485    1.25     0.22\n#&gt; state1        0.2671     0.0292    9.14  7.3e-14\n#&gt; \n#&gt; Residual standard error: 2.67 on 76 degrees of freedom\n#&gt; Multiple R-squared:  0.523,  Adjusted R-squared:  0.517 \n#&gt; F-statistic: 83.5 on 1 and 76 DF,  p-value: 7.35e-14\n\nNel caso di prior uniformi, la soluzione bayesiana coincide con quella di massima verosimiglianza. Questo risultato è atteso, poiché prior non informativi portano a distribuzioni a posteriori dominate dai dati osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#predizione-a-posteriori",
    "href": "chapters/linear_models/06_prediction_stan.html#predizione-a-posteriori",
    "title": "61  Predizione e inferenza",
    "section": "\n61.5 Predizione a Posteriori",
    "text": "61.5 Predizione a Posteriori\nUna volta ottenuta la distribuzione a posteriori dei parametri, possiamo utilizzarla per fare previsioni. In particolare, siamo interessati a due scenari: 1. Predizione per un valore specifico del predittore. 2. Quantificazione dell’incertezza nelle previsioni per tutti i valori osservati del predittore.\n\n61.5.1 Predizione a Posteriori per un Valore Specifico\nPer ottenere la distribuzione a posteriori della predizione per un valore specifico del predittore (ad esempio, state1 = 30), utilizziamo la funzione posterior_predict.\n\n# Predizione a posteriori per ansia di stato pari a 30\nnew_data &lt;- data.frame(state1 = 30)\npost_pred &lt;- posterior_predict(model, newdata = new_data)\n\n# Esame della distribuzione a posteriori della predizione\nsummary(post_pred)\n#&gt;        V1       \n#&gt;  Min.   :-2.43  \n#&gt;  1st Qu.: 7.67  \n#&gt;  Median : 9.55  \n#&gt;  Mean   : 9.56  \n#&gt;  3rd Qu.:11.45  \n#&gt;  Max.   :19.11\n\nQuesto ci fornisce una distribuzione di valori predetti per TA1 quando state1 = 30, riflettendo l’incertezza associata ai parametri del modello.\n\n61.5.2 Quantificazione dell’Incertezza nelle Predizioni\nPer quantificare l’incertezza complessiva nelle previsioni del modello, calcoliamo la distribuzione a posteriori delle predizioni per tutti i valori osservati di \\(x\\). Questo ci permette di ottenere stime puntuali e intervalli di credibilità.\n\n# Predizione a posteriori per tutti i valori di x\npost_pred_all &lt;- posterior_predict(model)\n\n\n61.5.3 Visualizzazione dell’Incertezza delle Predizioni\nVisualizziamo l’incertezza delle predizioni utilizzando un grafico che mostra la linea di regressione media e gli intervalli di credibilità al 95%.\n\n# Creazione del data frame per ggplot\nplot_data &lt;- data.frame(\n  state1 = df$state1,\n  TA1 = df$TA1,\n  pred_mean = colMeans(post_pred_all),  # Media delle predizioni\n  pred_lower = apply(post_pred_all, 2, quantile, 0.025),  # Limite inferiore\n  pred_upper = apply(post_pred_all, 2, quantile, 0.975)   # Limite superiore\n)\n\n# Costruzione del grafico\nggplot(plot_data, aes(x = state1, y = TA1)) +\n  geom_point(color = \"blue\", size = 1) +  # Punti osservati\n  geom_line(aes(y = pred_mean), color = \"red\", size = 1, alpha = 0.8) +  # Linea di regressione\n  geom_ribbon(\n    aes(ymin = pred_lower, ymax = pred_upper), fill = \"gray\", alpha = 0.3) +  \n  # Intervalli di credibilità\n  labs(\n    title = \"Incertezza delle Predizioni del Modello\",\n    x = \"State Anxiety\",\n    y = \"Tense Arousal\"\n  )",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#interpretazione-dei-risultati-1",
    "href": "chapters/linear_models/06_prediction_stan.html#interpretazione-dei-risultati-1",
    "title": "61  Predizione e inferenza",
    "section": "\n61.6 Interpretazione dei Risultati",
    "text": "61.6 Interpretazione dei Risultati\n\n61.6.1 Significato della Predizione a Posteriori\nIl comando posterior_predict(model) genera una matrice in cui:\n\nOgni riga rappresenta un campione della distribuzione a posteriori.\nOgni colonna rappresenta una predizione per un valore specifico di \\(x\\).\n\nQuesta matrice ci permette di:\n\n\nVisualizzare l’incertezza: Gli intervalli di credibilità riflettono l’incertezza associata alle previsioni.\n\nValutare la bontà del modello: Confrontando le predizioni con i dati osservati, possiamo verificare se il modello è adeguato.\n\nFare previsioni robuste: Generiamo previsioni per nuovi dati, tenendo conto dell’incertezza nei parametri.\n\n61.6.2 Esempio di Interpretazione\nSupponiamo che per state1 = 30, la media delle predizioni a posteriori sia 50, con un intervallo di credibilità al 95% compreso tra 45 e 55. Questo significa che, dato il modello e i dati, c’è una probabilità del 95% che il valore vero di TA1 per state1 = 30 sia compreso tra 45 e 55. L’ampiezza dell’intervallo riflette l’incertezza associata alla predizione.\n\n61.6.3 Confronto con l’Approccio Classico\nNell’approccio classico (frequentista), le predizioni sono accompagnate da intervalli di confidenza, che riflettono solo l’incertezza nella stima dei parametri. Al contrario, l’approccio bayesiano include sia l’incertezza nei parametri sia la variabilità residua, fornendo una visione più completa dell’incertezza predittiva.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#distribuzione-predittiva-a-posteriori",
    "href": "chapters/linear_models/06_prediction_stan.html#distribuzione-predittiva-a-posteriori",
    "title": "61  Predizione e inferenza",
    "section": "\n61.7 Distribuzione Predittiva a Posteriori",
    "text": "61.7 Distribuzione Predittiva a Posteriori\nIl Posterior Predictive Check (PPC) è uno strumento fondamentale nella modellazione bayesiana, utilizzato per valutare la bontà di adattamento del modello ai dati osservati. Questo controllo consiste nel confrontare i dati predetti dal modello (basati sulla distribuzione a posteriori dei parametri) con i dati effettivamente osservati. Se il modello è adeguato, le previsioni generate dovrebbero essere coerenti con i dati reali.\n\n61.7.1 Esecuzione del Posterior Predictive Check\nPer eseguire un PPC, utilizziamo la funzione pp_check del pacchetto brms. Questa funzione genera un insieme di previsioni basate sulla distribuzione a posteriori e le confronta visivamente con i dati osservati.\n\npp_check(model, ndraws = 100)\n\n\n\n\n\n\n\n\n61.7.2 Interpretazione dei Risultati\nDall’output del PPC, notiamo che i dati predetti dal modello sono simili ai dati osservati nel campione. Questa corrispondenza suggerisce che il modello ipotizzato è in grado di riprodurre adeguatamente le caratteristiche principali dei dati. In altre parole, il modello sembra essere appropriato per descrivere la relazione tra le variabili analizzate.\n\n61.7.2.1 Cosa Significa “Simili”?\n\n\nCoerenza nella forma: La distribuzione dei dati predetti ha una forma simile a quella dei dati osservati, indicando che il modello cattura correttamente la struttura sottostante dei dati.\n\nVariabilità: La variabilità delle previsioni è in linea con quella dei dati osservati, suggerendo che il modello tiene conto adeguatamente dell’incertezza intrinseca nei dati.\n\nAssenza di discrepanze evidenti: Non ci sono differenze sistematiche tra le previsioni e i dati osservati, il che supporta l’ipotesi che il modello sia ben specificato.\n\n61.7.3 Importanza del PPC\nIl PPC è un passaggio cruciale perché:\n\n\nValuta l’adattamento del modello: Fornisce una verifica visiva e quantitativa della capacità del modello di riprodurre i dati osservati.\n\nIdentifica potenziali problemi: Se le previsioni non corrispondono ai dati osservati, ciò può indicare che il modello è mal specificato o che mancano componenti importanti.\n\nSupporta la validità del modello: Un buon adattamento tra previsioni e dati osservati aumenta la fiducia nelle inferenze e nelle previsioni del modello.\n\nIn sintesi, nel nostro caso, la somiglianza tra i dati predetti e quelli osservati è un’indicazione positiva che il modello di regressione lineare bivariata, con i prior uniformi specificati, è adeguato per descrivere la relazione tra state1 e TA1. Tuttavia, è sempre consigliabile eseguire ulteriori controlli e verifiche, come l’analisi dei residui o l’uso di metriche quantitative (ad esempio, il Bayesian R-squared), per confermare ulteriormente la bontà del modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#riflessioni-conclusive",
    "href": "chapters/linear_models/06_prediction_stan.html#riflessioni-conclusive",
    "title": "61  Predizione e inferenza",
    "section": "\n61.8 Riflessioni Conclusive",
    "text": "61.8 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito i temi della predizione bayesiana nel contesto del modello di regressione bivariato, evidenziando l’importanza delle verifiche predittive a priori e a posteriori per la valutazione e la validazione del modello.\nAbbiamo visto come il Prior Predictive Check sia essenziale per verificare che le distribuzioni a priori siano appropriate per il modello e i dati del campione. Questo passaggio consente di esaminare se le ipotesi iniziali sono coerenti con la conoscenza preesistente e con i risultati attesi. Un’adeguata verifica predittiva a priori aiuta a prevenire l’adozione di distribuzioni a priori che possano portare a previsioni irrealistiche o fuorvianti.\nSuccessivamente, abbiamo esaminato il Posterior Predictive Check come strumento per valutare la capacità del modello di adattarsi ai dati osservati. Dopo aver integrato le informazioni dei dati con le distribuzioni a priori, il posterior predictive check permette di confrontare le predizioni del modello con i dati effettivamente osservati. Se il modello è adeguato, le sue predizioni dovrebbero essere in linea con i dati reali.\nInoltre, abbiamo discusso l’incertezza della retta di regressione, mostrando come le distribuzioni a posteriori dei parametri possano essere utilizzate per quantificare l’incertezza nelle previsioni. Attraverso la visualizzazione degli intervalli di credibilità, abbiamo evidenziato come l’approccio bayesiano fornisca una misura più completa dell’incertezza rispetto ai metodi classici.\nIn conclusione, l’approccio bayesiano alla predizione e alla verifica dei modelli offre un framework robusto e flessibile per l’analisi statistica. I prior e posterior predictive checks non sono semplici passaggi tecnici, ma costituiscono una parte integrante del processo di modellizzazione, assicurando che il modello non solo sia ben adattato ai dati, ma anche che le sue assunzioni siano giustificate e realistiche. L’utilizzo di questi strumenti permette di costruire modelli che siano coerenti con la realtà che intendono rappresentare.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/06_prediction_stan.html#informazioni-sullambiente-di-sviluppo",
    "title": "61  Predizione e inferenza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6         StanHeaders_2.32.10  posterior_1.6.0.9000\n#&gt;  [4] brms_2.22.0          Rcpp_1.0.14          thematic_0.1.6      \n#&gt;  [7] MetBrewer_0.2.0      ggokabeito_0.1.0     see_0.10.0          \n#&gt; [10] gridExtra_2.3        patchwork_1.3.0      bayesplot_1.11.1    \n#&gt; [13] psych_2.4.12         scales_1.3.0         markdown_1.13       \n#&gt; [16] knitr_1.49           lubridate_1.9.4      forcats_1.0.0       \n#&gt; [19] stringr_1.5.1        dplyr_1.1.4          purrr_1.0.4         \n#&gt; [22] readr_2.1.5          tidyr_1.3.1          tibble_3.2.1        \n#&gt; [25] ggplot2_3.5.1        tidyverse_2.0.0      rio_1.2.3           \n#&gt; [28] here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         R.utils_2.12.3      \n#&gt;  [4] loo_2.8.0            fastmap_1.2.0        TH.data_1.1-3       \n#&gt;  [7] tensorA_0.36.2.1     pacman_0.5.1         digest_0.6.37       \n#&gt; [10] timechange_0.3.0     estimability_1.5.1   lifecycle_1.0.4     \n#&gt; [13] processx_3.8.5       survival_3.8-3       magrittr_2.0.3      \n#&gt; [16] compiler_4.4.2       rlang_1.1.5          tools_4.4.2         \n#&gt; [19] yaml_2.3.10          data.table_1.16.4    labeling_0.4.3      \n#&gt; [22] bridgesampling_1.1-2 htmlwidgets_1.6.4    curl_6.2.0          \n#&gt; [25] pkgbuild_1.4.6       mnormt_2.1.1         plyr_1.8.9          \n#&gt; [28] cmdstanr_0.8.1       abind_1.4-8          multcomp_1.4-28     \n#&gt; [31] withr_3.0.2          R.oo_1.27.0          stats4_4.4.2        \n#&gt; [34] grid_4.4.2           inline_0.3.21        xtable_1.8-4        \n#&gt; [37] colorspace_2.1-1     emmeans_1.10.7       MASS_7.3-64         \n#&gt; [40] cli_3.6.4            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [43] generics_0.1.3       RcppParallel_5.1.10  rstudioapi_0.17.1   \n#&gt; [46] reshape2_1.4.4       tzdb_0.4.0           splines_4.4.2       \n#&gt; [49] parallel_4.4.2       matrixStats_1.5.0    vctrs_0.6.5         \n#&gt; [52] V8_6.0.1             Matrix_1.7-2         sandwich_3.1-1      \n#&gt; [55] jsonlite_1.8.9       hms_1.1.3            glue_1.8.0          \n#&gt; [58] ps_1.8.1             codetools_0.2-20     distributional_0.5.0\n#&gt; [61] stringi_1.8.4        gtable_0.3.6         QuickJSR_1.5.1      \n#&gt; [64] munsell_0.5.1        pillar_1.10.1        htmltools_0.5.8.1   \n#&gt; [67] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [70] evaluate_1.0.3       lattice_0.22-6       R.methodsS3_1.8.2   \n#&gt; [73] backports_1.5.0      rstantools_2.4.0     coda_0.19-4.1       \n#&gt; [76] nlme_3.1-167         checkmate_2.3.2      xfun_0.50           \n#&gt; [79] zoo_1.8-12           pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#bibliografia",
    "href": "chapters/linear_models/06_prediction_stan.html#bibliografia",
    "title": "61  Predizione e inferenza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html",
    "href": "chapters/linear_models/07_two_means.html",
    "title": "62  Confronto tra le medie di due gruppi",
    "section": "",
    "text": "62.1 Introduzione\nSpesso, ci troviamo ad affrontare la necessità di confrontare due gruppi di dati. Potrebbe interessarci sapere se la media di un gruppo è maggiore o diversa rispetto a quella di un altro gruppo. Per effettuare tale confronto, è fondamentale utilizzare un modello statistico, poiché le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.\nIl metodo tradizionale per confrontare statisticamente due o più gruppi è quello di utilizzare un test di ipotesi statistico. Questo approccio prevede l’individuazione di un’ipotesi nulla, che solitamente afferma che non ci sono differenze tra i gruppi, e l’utilizzo di una statistica test per determinare se i dati osservati sono plausibili sotto questa ipotesi. L’ipotesi nulla viene rifiutata quando la statistica test calcolata supera una soglia predefinita.\nTuttavia, i test di ipotesi possono essere complessi e i risultati spesso soggetti a interpretazioni errate. La scelta delle specifiche del test statistico (ad esempio, quale test utilizzare, quale ipotesi nulla testare, quale livello di significatività adottare) è spesso arbitraria e basata su convenzioni piuttosto che sulla specificità del problema o delle decisioni da prendere (Johnson, 1999). Inoltre, i risultati forniti dai test sono spesso indiretti, incompleti e tendono a sovrastimare le evidenze contro l’ipotesi nulla (Goodman, 1999).\nUn approccio più informativo ed efficace per il confronto tra gruppi è quello basato sulla stima invece che sul test dell’ipotesi nulla, ed è guidato dalla probabilità bayesiana anziché dalla frequentista. In pratica, invece di testare se ci sono differenze tra i gruppi, si cerca di ottenere una stima di quanto siano effettivamente diversi. Questo approccio è intrinsecamente più informativo. Inoltre, viene inclusa una stima dell’incertezza associata a tale differenza, che tiene conto sia dell’incertezza dovuta alla nostra mancanza di conoscenza dei parametri del modello (incertezza epistemica) sia dell’incertezza causata dalla variabilità intrinseca del sistema (incertezza aleatoria).\nPer affrontare tale problema possiamo usare un modello di regressione. In questo caso, anziché calcolare direttamente la differenza tra le medie, si introduce una variabile indicatrice (o “dummy”) \\(D\\) nel modello di regressione, come segue:\n\\[\ny_i = \\alpha + \\gamma D_i + \\varepsilon_i.\n\\]\nLa variabile indicatrice \\(D\\) specifica l’appartenenza ai gruppi attraverso valori binari: 0 per il gruppo di riferimento e 1 per il gruppo di confronto, definita come:\n\\[\nD_i =\n\\begin{cases}\n0 & \\text{se l'osservazione } i \\text{ appartiene al gruppo 0,} \\\\\n1 & \\text{se l'osservazione } i \\text{ appartiene al gruppo 1.}\n\\end{cases}\n\\]\nEntrambi i metodi sono appropriati per studiare la differenza tra le medie di due gruppi indipendenti. Tuttavia, il modello di regressione offre maggiore flessibilità e possibilità di estensione. Questa metodologia consente di includere ulteriori variabili esplicative, migliorando la comprensione dei fattori che influenzano l’esito di interesse. Tale flessibilità diventa particolarmente utile per esplorare come altre variabili incidano sulla differenza tra le medie o per analizzare contemporaneamente più variabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "href": "chapters/linear_models/07_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "title": "62  Confronto tra le medie di due gruppi",
    "section": "\n62.2 Regressione bayesiana per due gruppi indipendenti",
    "text": "62.2 Regressione bayesiana per due gruppi indipendenti\nIn un approccio bayesiano, il modello di regressione può essere espresso come:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\gamma D_i.\n\\end{align*}\n\\]\nIn questo modello:\n\n\n\\(\\alpha\\) rappresenta l’intercetta, corrispondente alla media del gruppo con \\(D = 0\\) (gruppo di riferimento),\n\n\\(\\gamma\\) quantifica la differenza attesa tra le medie dei due gruppi,\n\n\\(\\sigma\\) rappresenta la deviazione standard associata agli errori casuali.\n\nPer il gruppo di riferimento (\\(D = 0\\)), il modello si riduce a:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha.\n\\end{align*}\n\\]\nIn questo caso, \\(\\alpha\\) rappresenta direttamente la media del gruppo 0.\nPer il gruppo di confronto (\\(D = 1\\)), il modello diventa:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\gamma.\n\\end{align*}\n\\]\nQui, \\(\\alpha + \\gamma\\) rappresenta la media del gruppo 1, mentre \\(\\gamma\\) riflette la differenza tra la media del gruppo 1 e quella del gruppo 0.\nDi conseguenza, l’analisi della differenza tra le medie dei due gruppi si traduce nell’inferenza sul parametro \\(\\gamma\\). In un contesto bayesiano, ciò comporta l’esame della distribuzione a posteriori di \\(\\gamma\\), che consente di effettuare confronti diretti e di valutare l’incertezza associata alla stima di tale differenza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#approccio-frequentista",
    "href": "chapters/linear_models/07_two_means.html#approccio-frequentista",
    "title": "62  Confronto tra le medie di due gruppi",
    "section": "\n62.3 Approccio Frequentista",
    "text": "62.3 Approccio Frequentista\nL’inferenza frequentista si basa sulla costruzione della distribuzione campionaria di una statistica di interesse. Nel caso presente, la statistica di interesse è la differenza tra le medie di due gruppi indipendenti. Supponiamo che i dati provengano da due popolazioni distribuite normalmente:\n\\[\nY_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1) \\quad \\text{e} \\quad Y_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2),\n\\]\ndove \\(\\mu_1\\) e \\(\\mu_2\\) sono le medie delle popolazioni, e \\(\\sigma_1\\) e \\(\\sigma_2\\) sono le deviazioni standard. Assumiamo inoltre che le varianze delle due popolazioni siano uguali, ovvero \\(\\sigma_1 = \\sigma_2 = \\sigma\\).\n\n62.3.1 Inferenza sulla differenza delle medie\nSiamo interessati a fare inferenza sulla differenza \\(\\mu_1 - \\mu_2\\). La statistica campionaria corrispondente è la differenza tra le medie campionarie:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2.\n\\]\nPer fare inferenza, dobbiamo determinare la distribuzione di \\(\\bar{Y}_1 - \\bar{Y}_2\\) nell’universo dei campioni.\n\n62.3.1.1 Valore atteso\nIl valore atteso della differenza tra le medie campionarie è:\n\\[\nE(\\bar{Y}_1 - \\bar{Y}_2) = E(\\bar{Y}_1) - E(\\bar{Y}_2) = \\mu_1 - \\mu_2.\n\\]\n\n62.3.1.2 Varianza\nLa varianza della differenza tra le medie campionarie dipende dall’indipendenza dei due campioni. Se \\(\\bar{Y}_1\\) e \\(\\bar{Y}_2\\) sono indipendenti, la covarianza tra di essi è zero, e la varianza è data da:\n\\[\n\\begin{align}\nV(\\bar{Y}_1 - \\bar{Y}_2) &= V(\\bar{Y}_1) + V(\\bar{Y}_2) - 2 \\text{Cov}(\\bar{Y}_1, \\bar{Y}_2) \\\\\n&= V(\\bar{Y}_1) + V(\\bar{Y}_2) \\quad \\text{(poiché $\\text{Cov}(\\bar{Y}_1, \\bar{Y}_2) = 0$)} \\\\\n&= \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2},\n\\end{align}\n\\]\ndove:\n\n\n\\(\\sigma_1^2\\) e \\(\\sigma_2^2\\) sono le varianze delle popolazioni da cui sono estratti i campioni,\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni \\(\\bar{Y}_1\\) e \\(\\bar{Y}_2\\).\n\nSe invece \\(\\bar{Y}_1\\) e \\(\\bar{Y}_2\\) non sono indipendenti, la covarianza \\(\\text{Cov}(\\bar{Y}_1, \\bar{Y}_2)\\) deve essere inclusa nel calcolo:\n\\[\nV(\\bar{Y}_1 - \\bar{Y}_2) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2} - 2 \\text{Cov}(\\bar{Y}_1, \\bar{Y}_2).\n\\]\nTuttavia, in generale, la covarianza non è nota, e l’inferenza frequentista si applica principalmente al caso in cui i due campioni sono indipendenti, ovvero \\(\\text{Cov}(\\bar{Y}_1, \\bar{Y}_2) = 0\\).\n\n62.3.2 Distribuzione della statistica\nPer due campioni indipendenti provenienti da popolazioni normali, la statistica \\(\\bar{Y}_1 - \\bar{Y}_2\\) segue una distribuzione normale:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2 \\sim \\mathcal{N}\\left(\\mu_1 - \\mu_2, \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}\\right).\n\\]\nNel caso in cui \\(\\sigma_1 = \\sigma_2 = \\sigma\\), è possibile stimare la varianza comune \\(\\sigma^2\\) utilizzando una varianza pooled:\n\\[\ns_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2},\n\\]\ndove \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie dei due gruppi, calcolate come:\n\\[\ns_1^2 = \\frac{1}{n_1 - 1} \\sum_{i=1}^{n_1} (y_{1,i} - \\bar{y}_1)^2 \\quad \\text{e} \\quad s_2^2 = \\frac{1}{n_2 - 1} \\sum_{i=1}^{n_2} (y_{2,i} - \\bar{y}_2)^2.\n\\]\nIn sintesi, per due campioni indipendenti provenienti da popolazioni normali con varianze uguali, la differenza delle medie campionarie \\(\\bar{Y}_1 - \\bar{Y}_2\\) segue una distribuzione normale con:\n\n\nValore atteso: \\(\\mu_1 - \\mu_2\\),\n\nVarianza: \\(\\frac{\\sigma^2}{n_1} + \\frac{\\sigma^2}{n_2}\\), stimabile tramite la varianza pooled \\(s_p^2\\).\n\nQuesto risultato è fondamentale per costruire test di ipotesi e intervalli di confidenza sulla differenza delle medie. Questi argomenti verranno approfonditi in seguito. Per ora, limitiamoci a costruire la distribuzione campionaria della statistica \\(\\bar{Y}_1 - \\bar{Y}_2\\) e a calcolare delle probabilità.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/07_two_means.html#un-esempio-illustrativo",
    "title": "62  Confronto tra le medie di due gruppi",
    "section": "\n62.4 Un esempio illustrativo",
    "text": "62.4 Un esempio illustrativo\nConsideriamo il dataset relativo al quoziente di intelligenza (QI) di un campione di bambini, distinguendo tra quelli le cui madri hanno completato la scuola superiore e quelli le cui madri non l’hanno completata. Vediamo come implementare l’analisi descritta sopra passo per passo.\n\n62.4.1 Esplorazione iniziale dei dati\nCarichiamo i dati e osserviamo una sintesi delle prime righe per capire la struttura del dataset:\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\nkidiq |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1 121.12        4      27\n#&gt; 2        98      1  89.36        4      25\n#&gt; 3        85      1 115.44        4      27\n#&gt; 4        83      1  99.45        3      25\n#&gt; 5       115      1  92.75        4      27\n#&gt; 6        98      0 107.90        1      18\n\nSuccessivamente, analizziamo la distribuzione dei bambini nei due gruppi, in base all’educazione delle madri:\n\nkidiq |&gt; \n  group_by(mom_hs) |&gt; \n  summarize(\n    avg = mean(kid_score),\n    std = sd(kid_score),\n    n = n()\n)\n#&gt; # A tibble: 2 × 4\n#&gt;   mom_hs   avg   std     n\n#&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1      0  77.5  22.6    93\n#&gt; 2      1  89.3  19.0   341\n\nI risultati mostrano che:\n\n\n93 bambini hanno madri che non hanno completato la scuola superiore.\n\n341 bambini hanno madri diplomate,\n\ncon le medie e deviazioni standard del QI riportate sopra.\nLa differenza tra le medie del QI dei due gruppi può essere calcolata direttamente come:\n\nmean(kidiq[kidiq$mom_hs == 1, ]$kid_score) - \n  mean(kidiq[kidiq$mom_hs == 0, ]$kid_score)\n#&gt; [1] 11.77\n\nQuesta analisi preliminare evidenzia la differenza media tra i gruppi.\nPer comprendere meglio la distribuzione dei dati, utilizziamo un violin plot, che mostra la densità stimata dei punteggi del QI nei due gruppi:\n\nggplot(kidiq, aes(x = as.factor(mom_hs), y = kid_score)) +\n  geom_violin(trim = FALSE) + \n  labs(\n    x = \"Livello di istruzione della madre\",\n    y = \"QI del bambino\",\n    title = \"Distribuzione dei punteggi QI in base all'istruzione materna\"\n  ) +\n  scale_x_discrete(labels = c(\"0\" = \"Non diplomata\", \"1\" = \"Diplomata\"))",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#parallelo-tra-approccio-frequentista-e-bayesiano-nel-confronto-tra-due-medie",
    "href": "chapters/linear_models/07_two_means.html#parallelo-tra-approccio-frequentista-e-bayesiano-nel-confronto-tra-due-medie",
    "title": "62  Confronto tra le medie di due gruppi",
    "section": "\n62.5 Parallelo tra approccio frequentista e bayesiano nel confronto tra due medie",
    "text": "62.5 Parallelo tra approccio frequentista e bayesiano nel confronto tra due medie\nIl confronto tra le medie di due gruppi indipendenti può essere affrontato sia con un approccio frequentista, basato sulla distribuzione campionaria, sia con un approccio bayesiano, basato sull’aggiornamento delle credenze a posteriori. Vediamo i due approcci in dettaglio.\n\n62.5.1 Approccio Frequentista\nL’inferenza frequentista si basa sulla distribuzione campionaria della differenza tra le medie dei due gruppi. Supponiamo che i dati provengano da due popolazioni distribuite normalmente:\n\\[\nY_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1) \\quad \\text{e} \\quad Y_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2),\n\\]\ndove \\(\\mu_1\\) e \\(\\mu_2\\) sono le medie delle popolazioni, e \\(\\sigma_1\\) e \\(\\sigma_2\\) sono le deviazioni standard.\nSiamo interessati alla differenza delle medie campionarie, \\(\\bar{Y}_1 - \\bar{Y}_2\\), che ha una distribuzione normale:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2 \\sim \\mathcal{N}\\left(\\mu_1 - \\mu_2, \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}\\right).\n\\]\nSe le varianze delle due popolazioni sono uguali (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)), possiamo stimare \\(\\sigma^2\\) tramite una varianza poolata:\n\\[\ns_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}.\n\\]\nCon questa stima, possiamo calcolare la probabilità che la differenza osservata tra le medie campionarie superi un certo valore, ad esempio 5 punti.\n\n62.5.1.1 Esempio pratico\nConsideriamo i dati:\n\n\nGruppo 1 (madri diplomate): \\(n_1 = 341\\), \\(\\bar{Y}_1 = 89.3\\), \\(s_1 = 19.0\\),\n\nGruppo 2 (madri non diplomate): \\(n_2 = 93\\), \\(\\bar{Y}_2 = 77.5\\), \\(s_2 = 22.6\\).\n\nCalcoliamo la probabilità che la differenza campionaria \\(\\bar{Y}_1 - \\bar{Y}_2\\) superi 5 punti:\n\n# Dati\nmean_1 &lt;- 89.3\nstd_1 &lt;- 19.0\nn_1 &lt;- 341\n\nmean_2 &lt;- 77.5\nstd_2 &lt;- 22.6\nn_2 &lt;- 93\n\n# Varianza poolata\npooled_variance &lt;- (((n_1 - 1) * std_1^2) + ((n_2 - 1) * std_2^2)) / (n_1 + n_2 - 2)\n\n# Deviazione standard della differenza\nstd_diff &lt;- sqrt(pooled_variance / n_1 + pooled_variance / n_2)\n\n# Probabilità\ndiff_threshold &lt;- 5\np_value &lt;- 1 - pnorm(diff_threshold, mean = 0, sd = std_diff)\np_value\n#&gt; [1] 0.01553\n\n\n62.5.2 Approccio Bayesiano\nL’approccio bayesiano utilizza un modello di regressione con una variabile indicatrice (dummy) per distinguere i due gruppi. La formula del modello è:\n\\[\nY = \\beta_0 + \\beta_1 \\cdot \\text{mom\\_hs} + \\epsilon,\n\\]\ndove:\n\n\n\\(\\beta_0\\) è la media del gruppo di riferimento (madri non diplomate),\n\n\\(\\beta_1\\) è la differenza tra le medie dei due gruppi,\n\n\\(\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)\\).\n\n\n62.5.2.1 Specifica del modello e stima\nUtilizziamo il pacchetto brms per stimare il modello, con distribuzioni a priori debolmente informative:\n\nfit_1 &lt;- brm(\n  kid_score ~ mom_hs, \n  data = kidiq, \n  backend = \"cmdstanr\",\n  silent = 0\n)\n\nDopo aver stimato il modello, possiamo esaminare la distribuzione a posteriori del coefficiente \\(\\beta_1\\), che rappresenta la differenza tra le medie.\n\n62.5.2.2 Probabilità e intervalli di credibilità\nCalcoliamo la probabilità che la differenza tra le medie sia maggiore di 5 punti:\n\n# Campioni posteriori del coefficiente mom_hs\nposterior_samples &lt;- as_draws_df(fit_1)\nmom_hs_coef &lt;- posterior_samples$b_mom_hs\n\n# Probabilità che la differenza sia maggiore di 5\nprob_greater_than_5 &lt;- mean(mom_hs_coef &gt; 5)\nprob_greater_than_5\n#&gt; [1] 0.9975\n\n\n62.5.3 Differenze tra i due approcci\nI risultati ottenuti con i due approcci possono differire perché calcolano la probabilità sotto assunzioni e modelli differenti. Vediamo nel dettaglio le differenze tra i due approcci per chiarire la discrepanza.\n\n62.5.3.1 Approccio frequentista\n\n\nIpotesi: La differenza tra le medie campionarie \\(\\bar{Y}_1 - \\bar{Y}_2\\) è distribuita secondo una normale centrata in \\(0\\) (sotto l’ipotesi nulla che \\(\\mu_1 = \\mu_2\\)).\n\nDistribuzione utilizzata: La distribuzione normale ha una deviazione standard basata sulla stima poolata della varianza campionaria.\n\nRisultato: La probabilità calcolata rappresenta quanto è improbabile osservare una differenza di almeno 5 punti sotto l’ipotesi nulla.\n\nQuesto approccio parte dall’ipotesi di uguali medie (\\(\\mu_1 = \\mu_2\\)) e misura l’evidenza contro questa ipotesi. In sostanza, stiamo testando un’ipotesi frequentista sulla differenza campionaria.\n\n62.5.3.2 Approccio bayesiano\n\n\nIpotesi: Modello lineare bayesiano che stima il valore del coefficiente \\(\\beta\\) associato a mom_hs, usando i dati osservati per costruire una distribuzione a posteriori.\n\nDistribuzione utilizzata: La distribuzione a posteriori del coefficiente \\(\\beta\\), che rappresenta la plausibilità dei valori di \\(\\beta\\) dati i dati osservati.\n\nRisultato: La probabilità calcolata è la proporzione di campioni posteriori in cui \\(\\beta &gt; 5\\).\n\nQuesto approccio riflette l’evidenza dei dati osservati rispetto al modello stimato, senza partire dall’ipotesi che \\(\\mu_1 = \\mu_2\\).\n\n62.5.3.3 Perché i risultati differiscono?\n\n\nAssunzioni di partenza:\n\nFrequentista: Parte dall’ipotesi nulla \\(\\mu_1 = \\mu_2\\) e calcola quanto è improbabile osservare una differenza di almeno 5 punti sotto questa ipotesi.\nBayesiano: Parte da una distribuzione a priori per i parametri del modello, aggiornata con i dati osservati per stimare la distribuzione a posteriori. Non assume \\(\\mu_1 = \\mu_2\\), ma stima direttamente la probabilità che la differenza sia maggiore di 5.\n\n\n\nDistribuzione di riferimento:\n\nNel metodo frequentista, la distribuzione normale è centrata su \\(0\\) con varianza stimata.\nNel metodo bayesiano, la distribuzione è centrata sulla stima massima a posteriori (MAP) del coefficiente \\(\\beta\\), che riflette il valore più plausibile dato i dati.\n\n\n\nEffetto dei dati osservati:\n\nNel metodo frequentista, il valore di \\(5\\) è confrontato con una distribuzione teorica basata sull’ipotesi nulla.\nNel metodo bayesiano, il valore di \\(5\\) è confrontato con una distribuzione basata sui dati osservati.\n\n\n\nQuale metodo usare?\nDipende dall’interpretazione desiderata: - se vogliamo testare quanto sono compatibili i dati con l’ipotesi \\(\\mu_1 = \\mu_2\\), il metodo frequentista è appropriato; - se vogliamo stimare direttamente la probabilità che la differenza sia maggiore di 5 punti, data la distribuzione a posteriori, il metodo bayesiano è più adatto.\nLa discrepanza tra i risultati riflette le diverse filosofie statistiche dei due approcci. Tuttavia, se partiamo dal presupposto che l’ipotesi nulla (\\(\\mu_1 = \\mu_2\\)) sia sicuramente falsa, come accade quasi sempre nel mondo reale (poiché una differenza, per quanto piccola, è inevitabile), l’approccio frequentista perde di utilità pratica. Testare cosa accadrebbe se la differenza fosse esattamente zero è una costruzione teorica che raramente offre informazioni utili per comprendere i dati osservati.\nL’approccio bayesiano, invece, permette di concentrarsi su una domanda più pertinente: qual è il grado di incertezza sulla differenza tra le medie delle due popolazioni? Questo approccio combina i dati osservati con informazioni a priori (esplicite o deboli) per costruire una distribuzione a posteriori che descrive la plausibilità dei possibili valori della differenza. In altre parole, ci consente di stimare direttamente quanto è probabile che la differenza tra le medie superi una soglia significativa (ad esempio, 5 punti), senza fare affidamento su ipotesi non realistiche come quella di una differenza esattamente nulla.\nIn sintesi, l’approccio bayesiano è più utile in questo contesto perché:\n\nNon si basa su un’ipotesi nulla idealizzata che sappiamo non essere vera.\nStima direttamente la nostra incertezza rispetto alla differenza tra le medie, fornendo una risposta concreta e interpretabile in termini di probabilità.\nPermette di integrare le evidenze dei dati con la conoscenza preesistente, per ottenere inferenze più realistiche e informate.\n\nPertanto, l’approccio bayesiano è particolarmente adatto quando l’obiettivo è comprendere e quantificare l’incertezza riguardo alla differenza tra gruppi, piuttosto che testare una condizione ipotetica che difficilmente riflette la realtà.\n\n62.5.4 Intervallo di credibilità\nSviluppiamo l’analisi bayesiana. Calcoliamo anche l’intervallo di credibilità per \\(\\beta_1\\):\n\nbayestestR::hdi(fit_1, parameters = \"mom_hs\", ci = 0.89)\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |       89% HDI\n#&gt; -------------------------\n#&gt; mom_hs    | [8.36, 15.66]\n\n\n62.5.5 Distribuzione Predittiva a Posteriori\nEffettuiamo un controllo grafico per confrontare i dati osservati con quelli predetti dal modello:\n\npp_check(fit_1)\n\n\n\n\n\n\n\n\n62.5.6 R² bayesiano\nInfine, calcoliamo il coefficiente di determinazione (Bayesiano \\(R^2\\)) per valutare la capacità del modello di spiegare la variabilità nei dati:\n\nbayes_R2(fit_1)\n#&gt;    Estimate Est.Error    Q2.5  Q97.5\n#&gt; R2  0.05766   0.02055 0.02176 0.1007\n\nQuesto esempio dimostra come l’analisi di regressione bayesiana consenta di replicare e approfondire i risultati ottenuti in precedenza. Il modello non solo stima la differenza tra i gruppi, ma offre anche un quadro completo dell’incertezza associata, evidenziando la flessibilità e la potenza di questo approccio.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#una-parametrizzazione-alternativa",
    "href": "chapters/linear_models/07_two_means.html#una-parametrizzazione-alternativa",
    "title": "62  Confronto tra le medie di due gruppi",
    "section": "\n62.6 Una Parametrizzazione Alternativa",
    "text": "62.6 Una Parametrizzazione Alternativa\nPoiché il posterior predictive check (pp-check) ha evidenziato una leggera discrepanza tra i valori osservati (\\(y\\)) e quelli predetti dal modello, consideriamo una parametrizzazione alternativa. Adottiamo un modello gaussiano esteso con un parametro aggiuntivo per modellare l’asimmetria nella distribuzione, utilizzando una famiglia di distribuzioni skew-normal.\nEcco come definiamo e stimiamo il nuovo modello:\n\nfit_2 &lt;- brm(\n  kid_score ~ mom_hs, \n  family = skew_normal(),\n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq\n)\n\n\n62.6.1 Verifica del modello\nDopo aver stimato il modello, eseguiamo nuovamente il pp-check per confrontare i dati osservati con quelli predetti:\n\npp_check(fit_2)\n\n\n\n\n\n\n\nI risultati mostrano un miglioramento nell’adattamento del modello, indicando che l’aggiunta del parametro per l’asimmetria ha contribuito a ridurre le discrepanze.\n\n62.6.2 Valutazione delle stime\nAnalizziamo le stime posteriori dei parametri per verificare eventuali variazioni rispetto al modello precedente:\n\ndraws &lt;- posterior::as_draws(fit_2, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable     mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept 79.2   1.99    0.0325  0.0290\n#&gt; 2 b_mom_hs     9.65  2.24    0.0361  0.0321\n\n\n62.6.3 Intervallo di credibilità\nCalcoliamo l’intervallo di credibilità a densità massima (HDI) per il parametro associato a mom_hs:\n\nbayestestR::hdi(fit_2, parameters = \"mom_hs\", ci = 0.89)\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |       89% HDI\n#&gt; -------------------------\n#&gt; mom_hs    | [6.10, 13.27]\n\n\n62.6.4 Valutazione della variabilità spiegata\nInfine, calcoliamo il coefficiente di determinazione Bayesiano (\\(R^2\\)) per quantificare la capacità del modello di spiegare la variabilità nei dati:\n\nbayes_R2(fit_2)\n#&gt;    Estimate Est.Error    Q2.5   Q97.5\n#&gt; R2  0.04003   0.01711 0.01137 0.07688\n\nIn conclusioni, il modello con distribuzione skew-normal offre un adattamento migliore rispetto al modello gaussiano standard, come evidenziato dal pp-check. Tuttavia, le stime posteriori dei parametri differiscono solo marginalmente rispetto al modello precedente. Questo suggerisce che, sebbene l’aggiunta dell’asimmetria migliori l’adattamento, l’effetto sulla stima della relazione tra kid_score e mom_hs è limitato.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#prior-predictive-checks",
    "href": "chapters/linear_models/07_two_means.html#prior-predictive-checks",
    "title": "62  Confronto tra le medie di due gruppi",
    "section": "\n62.7 Prior Predictive Checks",
    "text": "62.7 Prior Predictive Checks\nIl punto di partenza per valutare le prestazioni predittive dei priori consiste nell’effettuare controlli predittivi grafici sui priori. In brms, questi controlli possono essere eseguiti in modo quasi identico ai posterior predictive checks. Basta indicare a brms di ignorare i dati durante il campionamento, concentrandosi unicamente sui priori. Per fare ciò, è fondamentale che tutti i parametri abbiano priori propri e, idealmente, non eccessivamente ampi o poco plausibili.\nPartiamo specificando priori debolmente informativi per il nostro modello gaussiano applicato ai dati kidiq. Esaminiamo prima i priori predefiniti da brms:\n\nget_prior(kid_score ~ mom_hs, data = kidiq)\n#&gt;                   prior     class   coef group resp dpar nlpar lb ub\n#&gt;  student_t(3, 90, 19.3) Intercept                                   \n#&gt;                  (flat)         b                                   \n#&gt;                  (flat)         b mom_hs                            \n#&gt;   student_t(3, 0, 19.3)     sigma                               0   \n#&gt;        source\n#&gt;       default\n#&gt;       default\n#&gt;  (vectorized)\n#&gt;       default\n\n\n62.7.1 Specifica dei Priori\nModifichiamo i priori predefiniti per utilizzare prior debolmente informativi personalizzati:\n\nprior_gaussian &lt;- \n  prior(normal(90, 20), class = \"b\", coef = \"Intercept\") +\n  prior(normal(0, 15), class = \"b\", coef = \"mom_hs\") +\n  prior(cauchy(0, 20), class = \"sigma\")\n\n\n62.7.2 Aggiunta dei Priori al Modello\nAggiungiamo i priori definiti alla funzione brm:\n\nfit_3 &lt;- brm(\n  bf(kid_score ~ 1 + mom_hs, center = FALSE), \n  kid_score ~ mom_hs, \n  prior = prior_gaussian,\n  family = gaussian(),\n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq\n)\n\nLe stime a posteriori per i parametri \\(\\alpha\\) e \\(\\beta\\) corrispondono ai valori ottenuti in precedenza:\n\ndraws &lt;- posterior::as_draws(fit_3, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable     mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  78.0  2.05    0.0534  0.0414\n#&gt; 2 b_mom_hs     11.2  2.29    0.0593  0.0469\n\n\n62.7.3 Esame della Distribuzione Predittiva a Priori\nPer generare campioni unicamente dalla distribuzione dei priori, specifichiamo l’argomento sample_prior = \"only\":\n\nfit_4 &lt;- brm(\n  bf(kid_score ~ 1 + mom_hs, center = FALSE), \n  kid_score ~ mom_hs, \n  prior = prior_gaussian,\n  family = gaussian(),\n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq,\n  sample_prior = \"only\"\n)\n\nQuando analizziamo il sommario del modello, osserviamo che i valori stimati dai “posteriori” riflettono effettivamente i priori:\n\nsummary(fit_4)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: kid_score ~ 1 + mom_hs \n#&gt;          autocor ~ tructure(list(), class = \"formula\", .Environment = &lt;environment&gt;)\n#&gt;    Data: kidiq (Number of observations: 434) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept    89.89     20.01    50.65   128.40 1.00     3689     2858\n#&gt; mom_hs       -0.04     14.73   -27.63    28.42 1.00     3613     2922\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma   240.42   4297.30     0.66   578.48 1.00     3095     2039\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nPossiamo utilizzare pp_check per visualizzare i prior predictive checks:\n\npp_check(fit_4, ndraws = 100) + xlim(10, 180)\n\n\n\n\n\n\n\nLa distribuzione predittiva a priori risulta più ampia rispetto alla distribuzione dei dati osservati, ma rimane comunque dello stesso ordine di grandezza. Questo è esattamente ciò che ci aspettiamo: i priori dovrebbero essere abbastanza ampi da consentire flessibilità, ma non così eccessivi da risultare irrealistici. Sebbene questo controllo non garantisca con certezza che tutti i priori siano ragionevoli, è utile per identificare priori potenzialmente troppo ampi o poco informativi.\n\n62.7.4 Massima Verosimiglianza vs Approccio Bayesiano\nIl modello di regressione basato sulla massima verosimiglianza stima i parametri ottimizzando la funzione di verosimiglianza, che rappresenta la probabilità dei dati dati i parametri. Sebbene questo approccio sia robusto, si limita a fornire stime puntuali e intervalli di fiducia frequentisti, che non hanno un’interpretazione probabilistica diretta (ad esempio, non possiamo dire che c’è una probabilità del 95% che il vero parametro sia contenuto nell’intervallo).\nL’approccio bayesiano, al contrario:\n\n\nCostruisce una distribuzione a posteriori per il parametro di interesse (ad esempio, la differenza tra gruppi), combinando i dati osservati con informazioni a priori.\n\nPermette di calcolare probabilità dirette: ad esempio, la probabilità che la differenza sia maggiore di un certo valore (\\(P(\\beta_{mean\\_diff} &gt; 5)\\)).\n\nIntegra incertezze multiple: ogni fonte di incertezza viene propagata naturalmente nella distribuzione a posteriori, rendendo l’analisi più realistica.\n\n62.7.5 Test \\(t\\) di Student vs Bayesiano\nIl test \\(t\\) di Student si basa su un’ipotesi nulla rigida (\\(\\mu_1 = \\mu_2\\)), mentre l’approccio bayesiano permette di valutare la probabilità che la differenza sia significativa rispetto a un valore ipotetico (es. 5 o 10 punti). Questo consente un’analisi più flessibile e rilevante:\n\n\nNessun focus sull’ipotesi nulla: Invece di testare l’ipotesi nulla che sappiamo essere quasi certamente falsa, l’approccio bayesiano si concentra su ciò che i dati ci dicono direttamente riguardo alla differenza.\n\nInformazioni aggiuntive: Il test bayesiano, attraverso la distribuzione a posteriori, permette di visualizzare l’incertezza e valutare intervalli di credibilità attorno alla stima.\n\n62.7.6 Esempio con Prior Informativi\nUn ulteriore approfondimento dell’approccio bayesiano consiste nell’uso di prior informativi. Ad esempio, se studi precedenti indicano che le differenze tra i due gruppi tendono ad essere intorno a 10 punti, possiamo specificare un prior normale centrato su 10 con una deviazione standard moderata. Questo prior può influenzare i risultati quando i dati sono scarsi o poco informativi, ma con un campione ampio come in questo caso, i dati tendono a prevalere sui prior.\n\nfit_5 &lt;- brm(\n  kid_score ~ mom_hs,\n  data = kidiq,\n  prior = c(set_prior(\"normal(10, 5)\", class = \"b\", coef = \"mom_hs\")),\n  backend = \"cmdstanr\",\n  silent = 0\n)\n\n\nsummary(fit_5)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: kid_score ~ mom_hs \n#&gt;    Data: kidiq (Number of observations: 434) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept    77.81      1.92    74.07    81.58 1.00     4427     3120\n#&gt; mom_hs       11.43      2.12     7.37    15.60 1.00     4265     3078\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma    19.88      0.66    18.62    21.20 1.00     4270     3219\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nCon prior informativi, i risultati rifletteranno sia le evidenze dei dati sia il nostro stato di conoscenza precedente, arricchendo ulteriormente l’inferenza.\n\n62.7.7 Test di Ipotesi Bayesiano con hypothesis()\n\nIl comando hypothesis() in brms consente di verificare ipotesi specifiche direttamente sulla distribuzione a posteriori. Ad esempio:\n\nhypothesis(fit_1, \"mom_hs &gt; 5\")\n#&gt; Hypothesis Tests for class b:\n#&gt;         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n#&gt; 1 (mom_hs)-(5) &gt; 0     6.78      2.31     3.02    10.54        399\n#&gt;   Post.Prob Star\n#&gt; 1         1    *\n#&gt; ---\n#&gt; 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n#&gt; '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n#&gt; for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n#&gt; Posterior probabilities of point hypotheses assume equal prior probabilities.\n\nConfrontando questo approccio al test frequentista:\n\nIl test bayesiano non restituisce un \\(p\\)-value, ma una probabilità interpretabile, come “c’è una probabilità del 99.8% che la differenza tra i gruppi sia maggiore di 5 punti”.\nL’output include un intervallo di credibilità, che rappresenta un range di valori plausibili per il parametro con una certa probabilità (ad esempio, 89%).\n\n62.7.8 Integrazione Bayesiana nella Pratica\nL’approccio bayesiano si distingue per la sua flessibilità, soprattutto quando:\n\nL’ipotesi nulla è irrealistica o poco utile.\nSi desidera incorporare conoscenze precedenti in modo sistematico.\nSi vuole ottenere inferenze probabilistiche più dirette e intuitive, come la probabilità che un parametro superi una soglia rilevante.\n\nCon l’aumentare della complessità dei modelli o della necessità di rispondere a domande più sfumate, l’approccio bayesiano diventa lo strumento più adatto per catturare la reale incertezza e complessità dei dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#riflessioni-conclusive",
    "href": "chapters/linear_models/07_two_means.html#riflessioni-conclusive",
    "title": "62  Confronto tra le medie di due gruppi",
    "section": "\n62.8 Riflessioni Conclusive",
    "text": "62.8 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato le numerose funzionalità offerte da brms per la modellazione bayesiana, dimostrando come questo pacchetto consenta di implementare analisi sofisticate in modo intuitivo e flessibile. Dalla specifica dei modelli all’interpretazione probabilistica dei risultati, brms si è rivelato uno strumento particolarmente utile per tradurre domande di ricerca complesse in analisi statistiche rigorose.\nUn punto chiave emerso è l’importanza dell’approccio bayesiano nel superare i limiti delle inferenze frequentiste, permettendo di stimare direttamente l’incertezza sui parametri e di testare ipotesi rilevanti senza fare affidamento su ipotesi nulle spesso irrealistiche. Inoltre, abbiamo visto come la capacità di incorporare conoscenze pregresse attraverso i priori consenta di adattare i modelli al contesto specifico della ricerca, rendendo l’approccio bayesiano non solo potente, ma anche estremamente versatile.\nIn definitiva, brms non è soltanto un software per l’analisi statistica, ma uno strumento che favorisce un cambiamento nella mentalità analitica, promuovendo una visione più completa e realistica dell’incertezza e della probabilità. Questo capitolo dovrebbe servire come base per l’applicazione di modelli bayesiani in scenari reali, fornendo sia le competenze tecniche che una prospettiva critica sui vantaggi dell’approccio bayesiano nella ricerca quantitativa moderna.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/07_two_means.html#informazioni-sullambiente-di-sviluppo",
    "title": "62  Confronto tra le medie di due gruppi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6         StanHeaders_2.32.10  insight_1.0.2       \n#&gt;  [4] bayestestR_0.15.2    brms_2.22.0          Rcpp_1.0.14         \n#&gt;  [7] posterior_1.6.0.9000 cmdstanr_0.8.1       thematic_0.1.6      \n#&gt; [10] MetBrewer_0.2.0      ggokabeito_0.1.0     see_0.10.0          \n#&gt; [13] gridExtra_2.3        patchwork_1.3.0      bayesplot_1.11.1    \n#&gt; [16] psych_2.4.12         scales_1.3.0         markdown_1.13       \n#&gt; [19] knitr_1.49           lubridate_1.9.4      forcats_1.0.0       \n#&gt; [22] stringr_1.5.1        dplyr_1.1.4          purrr_1.0.4         \n#&gt; [25] readr_2.1.5          tidyr_1.3.1          tibble_3.2.1        \n#&gt; [28] ggplot2_3.5.1        tidyverse_2.0.0      rio_1.2.3           \n#&gt; [31] here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.5          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] matrixStats_1.5.0    compiler_4.4.2       loo_2.8.0           \n#&gt; [10] reshape2_1.4.4       vctrs_0.6.5          pkgconfig_2.0.3     \n#&gt; [13] fastmap_1.2.0        backports_1.5.0      labeling_0.4.3      \n#&gt; [16] utf8_1.2.4           rmarkdown_2.29       tzdb_0.4.0          \n#&gt; [19] haven_2.5.4          ps_1.8.1             xfun_0.50           \n#&gt; [22] jsonlite_1.8.9       parallel_4.4.2       R6_2.6.1            \n#&gt; [25] stringi_1.8.4        estimability_1.5.1   zoo_1.8-12          \n#&gt; [28] pacman_0.5.1         R.utils_2.12.3       Matrix_1.7-2        \n#&gt; [31] splines_4.4.2        timechange_0.3.0     tidyselect_1.2.1    \n#&gt; [34] rstudioapi_0.17.1    abind_1.4-8          yaml_2.3.10         \n#&gt; [37] codetools_0.2-20     curl_6.2.0           processx_3.8.5      \n#&gt; [40] pkgbuild_1.4.6       plyr_1.8.9           lattice_0.22-6      \n#&gt; [43] withr_3.0.2          bridgesampling_1.1-2 coda_0.19-4.1       \n#&gt; [46] evaluate_1.0.3       survival_3.8-3       RcppParallel_5.1.10 \n#&gt; [49] pillar_1.10.1        tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [52] stats4_4.4.2         distributional_0.5.0 generics_0.1.3      \n#&gt; [55] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [58] munsell_0.5.1        xtable_1.8-4         glue_1.8.0          \n#&gt; [61] emmeans_1.10.7       tools_4.4.2          data.table_1.16.4   \n#&gt; [64] mvtnorm_1.3-3        grid_4.4.2           QuickJSR_1.5.1      \n#&gt; [67] datawizard_1.0.0     colorspace_2.1-1     nlme_3.1-167        \n#&gt; [70] cli_3.6.4            Brobdingnag_1.2-9    V8_6.0.1            \n#&gt; [73] gtable_0.3.6         R.methodsS3_1.8.2    digest_0.6.37       \n#&gt; [76] TH.data_1.1-3        htmlwidgets_1.6.4    farver_2.1.2        \n#&gt; [79] htmltools_0.5.8.1    R.oo_1.27.0          lifecycle_1.0.4     \n#&gt; [82] MASS_7.3-64",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#bibliografia",
    "href": "chapters/linear_models/07_two_means.html#bibliografia",
    "title": "62  Confronto tra le medie di due gruppi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html",
    "href": "chapters/linear_models/08_sample_size.html",
    "title": "63  Disegno della ricerca e potere statistico",
    "section": "",
    "text": "63.1 Introduzione\nLa potenza statistica è definita come la probabilità, calcolata prima che uno studio venga condotto, che un determinato confronto raggiunga un livello predefinito di “significatività statistica” (tipicamente un p-value inferiore a 0,05), dato un effetto reale ipotizzato. Per calcolare la potenza, si parte da un’ipotesi sulla dimensione dell’effetto, si fanno assunzioni sulla variabilità dei dati e sulla dimensione del campione, e si utilizzano calcoli probabilistici per determinare la probabilità che il p-value sia inferiore alla soglia stabilita.\nLa visione convenzionale sconsiglia di condurre studi con bassa potenza, poiché hanno basse probabilità di “successo”. Tuttavia, in casi in cui i costi sono molto bassi rispetto ai potenziali benefici, un ricercatore potrebbe decidere di correre il rischio. Come vedremo, però, questa scelta può nascondere insidie significative.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#la-maledizione-del-vincitore-negli-studi-a-bassa-potenza",
    "href": "chapters/linear_models/08_sample_size.html#la-maledizione-del-vincitore-negli-studi-a-bassa-potenza",
    "title": "63  Disegno della ricerca e potere statistico",
    "section": "\n63.2 La maledizione del vincitore negli studi a bassa potenza",
    "text": "63.2 La maledizione del vincitore negli studi a bassa potenza\nIn uno studio con bassa potenza, il “successo” apparente di un risultato statisticamente significativo può essere ingannevole. Quando il segnale è debole e il rumore elevato, i risultati significativi tendono a essere erronei (esagerati o nel segno sbagliato), con scarse probabilità di replicabilità. Questi errori sono noti come errori di tipo M (esagerazione della dimensione dell’effetto) e di tipo S (errore nel segno dell’effetto). Di conseguenza, uno studio a bassa potenza rischia di generare informazioni fuorvianti, contribuendo alla crisi di replicazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#stimare-la-dimensione-del-campione",
    "href": "chapters/linear_models/08_sample_size.html#stimare-la-dimensione-del-campione",
    "title": "63  Disegno della ricerca e potere statistico",
    "section": "\n63.3 Stimare la dimensione del campione",
    "text": "63.3 Stimare la dimensione del campione\nPrima di raccogliere dati, è utile stimare la dimensione del campione necessaria per ottenere un certo livello di precisione o per garantire una potenza desiderata. Vediamo i calcoli dettagliati.\n\n63.3.1 Determinazione della dimensione del campione per un errore standard specifico\nSupponiamo di voler stimare un valore medio \\(\\theta\\) della popolazione utilizzando un campione casuale di dimensione \\(n\\). La stima \\(\\bar{y}\\), cioè la media campionaria, ha un errore standard dato da:\n\\[\n\\text{s.e.}(\\bar{y}) = \\frac{\\sigma}{\\sqrt{n}},\n\\]\ndove:\n\n\n\\(\\text{s.e.}(\\bar{y})\\) è l’errore standard della media campionaria,\n\n\\(\\sigma\\) è la deviazione standard della popolazione,\n\n\\(n\\) è la dimensione del campione.\n\nSe vogliamo ottenere un errore standard specifico, denotato con \\(\\text{s.e.}\\), impostiamo l’equazione:\n\\[\n\\text{s.e.} = \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nPer risolvere rispetto a \\(n\\), procediamo come segue:\n\nMoltiplichiamo entrambi i lati per \\(\\sqrt{n}\\) per eliminare il denominatore: \\[\n\\text{s.e.} \\cdot \\sqrt{n} = \\sigma.\n\\]\nDividiamo entrambi i lati per \\(\\text{s.e.}\\): \\[\n\\sqrt{n} = \\frac{\\sigma}{\\text{s.e.}}.\n\\]\nEleviamo al quadrato entrambi i lati per eliminare la radice: \\[\nn = \\left(\\frac{\\sigma}{\\text{s.e.}}\\right)^2.\n\\]\n\nQuesta formula ci dice che la dimensione del campione necessaria per ottenere un determinato errore standard è proporzionale al quadrato del rapporto tra la deviazione standard \\(\\sigma\\) e l’errore standard desiderato \\(\\text{s.e.}\\).\n\n63.3.2 Dimensione del campione per una potenza dell’80%\nSupponiamo ora di voler determinare la dimensione del campione necessaria per ottenere l’80% di potenza nel distinguere un valore \\(\\theta\\) dalla media ipotizzata \\(\\theta_0\\).\nL’errore standard della differenza \\(\\theta - \\theta_0\\) è dato da:\n\\[\n\\text{s.e.} = \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nPer ottenere l’80% di potenza, vogliamo che la differenza osservata \\(\\theta - \\theta_0\\) sia sufficientemente grande da essere rilevata con il livello di significatività prefissato (ad esempio, 5%).\n\n63.3.2.1 Passaggi algebrici per derivare la formula:\n\nPer una potenza dell’80%, la differenza \\(\\theta - \\theta_0\\) deve essere almeno 2,8 volte l’errore standard, dove il valore \\(2.8\\) è dato dalla somma dei quantili della distribuzione normale per il 95% di confidenza (\\(1.96\\)) e per l’80% di potenza (\\(0.84\\)): \\[\n\\theta - \\theta_0 = 2.8 \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nRisolviamo per \\(\\sqrt{n}\\): \\[\n\\sqrt{n} = \\frac{2.8 \\cdot \\sigma}{\\theta - \\theta_0}.\n\\]\nEleviamo al quadrato entrambi i lati: \\[\nn = \\left(\\frac{2.8 \\cdot \\sigma}{\\theta - \\theta_0}\\right)^2.\n\\]\n\nQuesta formula fornisce la dimensione del campione necessaria per ottenere l’80% di potenza, dove \\(2.8\\) rappresenta il valore soglia della distribuzione normale standard.\n\n63.3.2.2 Esempio pratico\nSe vogliamo distinguere \\(\\theta\\) da \\(\\theta_0\\) con \\(\\sigma = 10\\) e una differenza minima rilevabile di \\(\\theta - \\theta_0 = 5\\), possiamo calcolare \\(n\\) come segue:\n\\[\nn = \\left(\\frac{2.8 \\cdot 10}{5}\\right)^2 = \\left(5.6\\right)^2 = 31.36.\n\\]\nArrotondando, servono almeno 32 osservazioni.\n\n63.3.3 Correzione per campioni piccoli e distribuzione t\nPer studi con pochi gradi di libertà, l’incertezza sulla stima di \\(\\sigma\\) aumenta, e la distribuzione t di Student diventa più appropriata. In questi casi, il valore \\(2.8\\) deve essere sostituito con un valore più grande, dipendente dai gradi di libertà, per compensare l’incertezza aggiuntiva.\nAd esempio, per uno studio che confronta due gruppi di 6 pazienti ciascuno, i gradi di libertà sono 10. In R, la somma dei quantili della distribuzione t con 10 gradi di libertà per l’80% di potenza e il 95% di confidenza è \\(3.1\\), quindi \\(2.8\\) viene sostituito da \\(3.1\\) nei calcoli per la potenza dell’80%.\n\n# Gradi di libertà\ndf &lt;- 10\n\n# Calcola il quantile per l'80% di potenza (quindi 0.8) e il 95% di confidenza (quindi 0.975)\nt_value_80 &lt;- qt(0.8, df)\nt_value_95 &lt;- qt(0.975, df)\n\n# Somma dei due quantili\nt_total &lt;- t_value_80 + t_value_95\nt_total\n#&gt; [1] 3.107\n\nEseguendo questo codice in R, otteniamo il valore 3.107, che sostituisce il valore \\(2.8\\) nei calcoli per la potenza dell’80% quando si lavora con piccoli campioni e si utilizza la distribuzione t invece della normale standard.\n\n63.3.4 Nota\nQuesto esempio evidenzia come la distribuzione t tenga conto della maggiore variabilità introdotta dalla stima della deviazione standard in campioni di piccole dimensioni, aumentando leggermente il valore soglia richiesto per la potenza desiderata.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#confronto-di-medie",
    "href": "chapters/linear_models/08_sample_size.html#confronto-di-medie",
    "title": "63  Disegno della ricerca e potere statistico",
    "section": "\n63.4 Confronto di Medie",
    "text": "63.4 Confronto di Medie\nEsaminiamo ora il caso del confronto tra le medie di due gruppi indipendenti. Vogliamo determinare la dimensione del campione necessaria per rilevare una differenza significativa \\(\\Delta\\) tra le due medie con una potenza statistica dell’80%.\n\n63.4.1 Errore Standard della Differenza tra Due Medie\nL’errore standard della differenza tra le medie campionarie \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) è dato da:\n\\[\n\\text{s.e.}(\\bar{y}_1 - \\bar{y}_2) = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}},\n\\]\ndove:\n\n\n\\(\\sigma_1^2\\) e \\(\\sigma_2^2\\) sono le varianze delle popolazioni dei due gruppi,\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni nei due gruppi.\n\n\n63.4.1.1 Caso di Varianze e Dimensioni del Campione Uguali\nSe assumiamo che:\n\nle varianze sono uguali: \\(\\sigma_1 = \\sigma_2 = \\sigma\\),\nle dimensioni dei campioni sono uguali: \\(n_1 = n_2 = n\\),\n\nl’errore standard diventa:\n\n\nSostituiamo le varianze e le dimensioni dei campioni:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n}} = \\sqrt{\\frac{2\\sigma^2}{n}}.\n\\]\n\n\nSemplifichiamo l’espressione:\n\\[\n\\text{s.e.} = \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\n\n\n63.4.2 Dimensione del Campione per un Errore Standard Specifico\nSe desideriamo ottenere un errore standard specifico \\(\\text{s.e.}\\), possiamo determinare la dimensione del campione \\(n\\) seguendo questi passaggi:\n\n\nPartiamo dall’espressione dell’errore standard:\n\\[\n\\text{s.e.} = \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\n\n\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{\\sqrt{2}\\sigma}{\\text{s.e.}}.\n\\]\n\n\nEleviamo al quadrato entrambi i membri:\n\\[\nn = \\left( \\frac{\\sqrt{2}\\sigma}{\\text{s.e.}} \\right)^2 = \\frac{2\\sigma^2}{\\text{s.e.}^2}.\n\\]\n\n\n63.4.3 Dimensione del Campione per una Differenza \\(\\Delta\\) con l’80% di Potenza\nPer garantire una potenza dell’80% nel rilevare una differenza \\(\\Delta\\) tra le due medie, seguiamo questi passaggi:\n\n63.4.3.1 Determinazione del Valore Critico\nPer un test bilaterale al livello di significatività del 5%, i valori critici della distribuzione normale standard sono:\n\n\n\\(z_{\\alpha/2} = 1.96\\) (per il 95% di confidenza),\n\n\\(z_{\\text{potenza}} = 0.84\\) (per l’80% di potenza).\n\nLa somma totale è:\n\\[\nz_{\\text{totale}} = z_{\\alpha/2} + z_{\\text{potenza}} = 1.96 + 0.84 = 2.8.\n\\]\n\n63.4.3.2 Relazione tra \\(\\Delta\\) ed Errore Standard\nLa differenza minima rilevabile \\(\\Delta\\) è legata all’errore standard dalla relazione:\n\n\nImpostiamo l’equazione:\n\\[\n\\Delta = z_{\\text{totale}} \\times \\text{s.e.} = 2.8 \\times \\text{s.e.}.\n\\]\n\n\nSostituiamo l’espressione per \\(\\text{s.e.}\\):\n\\[\n\\Delta = 2.8 \\times \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\n\n\nCalcoliamo il coefficiente:\n\\[\n2.8 \\times \\sqrt{2} = 2.8 \\times 1.4142 \\approx 3.96.\n\\]\nQuindi:\n\\[\n\\Delta = 3.96 \\times \\frac{\\sigma}{\\sqrt{n}}.\n\\]\n\n\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{3.96 \\sigma}{\\Delta}.\n\\]\n\n\nEleviamo al quadrato entrambi i membri:\n\\[\nn = \\left( \\frac{3.96 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\n63.4.4 Formula Finale per la Dimensione del Campione\nLa dimensione del campione necessaria per ciascun gruppo è data da:\n\\[\nn = \\left( \\frac{3.96 \\sigma}{\\Delta} \\right)^2.\n\\]\nPer semplificare i calcoli, possiamo arrotondare \\(3.96\\) a \\(4\\):\n\\[\nn = \\left( \\frac{4 \\sigma}{\\Delta} \\right)^2.\n\\]\nNota Importante: Questa formula si applica quando:\n\n\nLe varianze delle popolazioni sono uguali (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)).\n\nLe dimensioni dei campioni nei due gruppi sono uguali (\\(n_1 = n_2 = n\\)).\n\nIl totale dei campioni è \\(N = 2n\\).\n\n63.4.5 Interpretazione della Formula\n\n\nSe la deviazione standard \\(\\sigma\\) è elevata: C’è maggiore variabilità nei dati, quindi è necessario un campione più grande per rilevare una differenza \\(\\Delta\\) con la stessa potenza.\n\nSe la differenza \\(\\Delta\\) è piccola: Serve un campione più grande per garantire che la differenza sia rilevabile con l’80% di potenza.\n\n63.4.6 Esempio Pratico\nSupponiamo di voler rilevare una differenza \\(\\Delta = 5\\) unità tra due gruppi, con una deviazione standard comune \\(\\sigma = 10\\) unità.\nCalcolo della dimensione del campione per ciascun gruppo:\n\n\nUtilizziamo la formula:\n\\[\nn = \\left( \\frac{4 \\times 10}{5} \\right)^2 = \\left( \\frac{40}{5} \\right)^2 = \\left( 8 \\right)^2 = 64.\n\\]\n\n\nRisultato:\n\n\n64 partecipanti per gruppo.\n\nTotale di 128 partecipanti.\n\n\n\n63.4.7 Caso con Campione Totale Fissato\nSe il campione totale è fissato a \\(n\\), con dimensioni dei gruppi \\(n_1 = n_2 = n/2\\), l’errore standard cambia leggermente.\n\n63.4.7.1 Calcolo dell’Errore Standard\n\n\nSostituiamo \\(n_1 = n_2 = n/2\\) nell’errore standard:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{\\sigma^2}{n/2} + \\frac{\\sigma^2}{n/2}} = \\sqrt{2 \\times \\frac{\\sigma^2}{n/2}}.\n\\]\n\n\nSemplifichiamo l’espressione:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{4\\sigma^2}{n}} = \\frac{2\\sigma}{\\sqrt{n}}.\n\\]\n\n\n63.4.7.2 Dimensione del Campione\n\n\nRelazione tra \\(\\Delta\\) ed errore standard:\n\\[\n\\Delta = 2.8 \\times \\text{s.e.} = 2.8 \\times \\frac{2\\sigma}{\\sqrt{n}} = \\frac{5.6 \\sigma}{\\sqrt{n}}.\n\\]\n\n\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{5.6 \\sigma}{\\Delta}.\n\\]\n\n\nEleviamo al quadrato:\n\\[\nn = \\left( \\frac{5.6 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\nIn questo scenario, la dimensione totale del campione è \\(n\\), con \\(n/2\\) partecipanti per ciascun gruppo.\n\n63.4.8 Scelta della Formula Adeguata\n\n\nSe \\(n\\) rappresenta la dimensione del campione per gruppo:\n\\[\nn = \\left( \\frac{4 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\nSe \\(n\\) rappresenta la dimensione totale del campione:\n\\[\nn = \\left( \\frac{5.6 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\nAssicurarsi di chiarire come si definisce \\(n\\) è fondamentale per applicare correttamente le formule.\n\n63.4.9 Sintesi\n\n\nVarianze e dimensioni uguali nei due gruppi semplificano i calcoli.\n\nLa dimensione del campione aumenta con l’aumentare della deviazione standard \\(\\sigma\\) e con la diminuzione della differenza \\(\\Delta\\) che si vuole rilevare.\n\nEssere chiari sulla definizione di \\(n\\) (per gruppo o totale) evita errori nei calcoli.\n\n\nEsempio 63.1 Se la differenza \\(\\Delta\\) che vogliamo rilevare è pari a metà della deviazione standard (\\(\\Delta = 0.5\\sigma\\)), allora la formula ci dirà quanti partecipanti sono necessari in ciascun gruppo per rilevare questa differenza con l’80% di potenza. Ad esempio, se \\(\\Delta = 0.5\\sigma\\), la dimensione totale del campione sarà:\n\\[\nn = \\left(\\frac{5.6 \\sigma}{0.5\\sigma}\\right)^2 = (11.2)^2 = 125.44 \\approx 126.\n\\]\nQuindi, servirebbero 63 partecipanti per gruppo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#riflessioni-conclusive",
    "href": "chapters/linear_models/08_sample_size.html#riflessioni-conclusive",
    "title": "63  Disegno della ricerca e potere statistico",
    "section": "\n63.5 Riflessioni Conclusive",
    "text": "63.5 Riflessioni Conclusive\nLa determinazione della dimensione del campione è un passaggio cruciale nella progettazione degli studi, poiché garantisce che le inferenze siano robuste e i risultati affidabili. Questo capitolo ha mostrato come le caratteristiche dei dati, come la deviazione standard e la differenza attesa tra i gruppi, influenzino direttamente la dimensione del campione necessaria per ottenere una potenza statistica adeguata. Inoltre, l’attenzione ai dettagli, come l’uso della distribuzione t per piccoli campioni, sottolinea l’importanza di considerare le fonti di variabilità e incertezza nei calcoli. Pianificare con rigore la dimensione del campione non solo aumenta la probabilità di rilevare effetti significativi, ma contribuisce anche a ridurre il rischio di risultati fuorvianti, migliorando così la qualità complessiva della ricerca scientifica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/08_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "63  Disegno della ricerca e potere statistico",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pointblank_0.12.2 haven_2.5.4       labelled_2.14.0   mice_3.17.0      \n#&gt;  [5] thematic_0.1.6    MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.10.0       \n#&gt;  [9] gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1  psych_2.4.12     \n#&gt; [13] scales_1.3.0      markdown_1.13     knitr_1.49        lubridate_1.9.4  \n#&gt; [17] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4      \n#&gt; [21] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n#&gt; [25] tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] digest_0.6.37     rpart_4.1.24      timechange_0.3.0  lifecycle_1.0.4  \n#&gt;  [9] survival_3.8-3    magrittr_2.0.3    compiler_4.4.2    rlang_1.1.5      \n#&gt; [13] tools_4.4.2       htmlwidgets_1.6.4 mnormt_2.1.1      withr_3.0.2      \n#&gt; [17] nnet_7.3-20       grid_4.4.2        jomo_2.7-6        colorspace_2.1-1 \n#&gt; [21] iterators_1.0.14  MASS_7.3-64       cli_3.6.4         rmarkdown_2.29   \n#&gt; [25] reformulas_0.4.0  generics_0.1.3    rstudioapi_0.17.1 tzdb_0.4.0       \n#&gt; [29] minqa_1.2.8       splines_4.4.2     parallel_4.4.2    vctrs_0.6.5      \n#&gt; [33] boot_1.3-31       glmnet_4.1-8      Matrix_1.7-2      jsonlite_1.8.9   \n#&gt; [37] hms_1.1.3         mitml_0.4-5       foreach_1.5.2     blastula_0.3.5   \n#&gt; [41] glue_1.8.0        nloptr_2.1.1      pan_1.9           codetools_0.2-20 \n#&gt; [45] stringi_1.8.4     shape_1.4.6.1     gtable_0.3.6      lme4_1.1-36      \n#&gt; [49] munsell_0.5.1     pillar_1.10.1     htmltools_0.5.8.1 R6_2.6.1         \n#&gt; [53] Rdpack_2.6.2      rprojroot_2.0.4   evaluate_1.0.3    lattice_0.22-6   \n#&gt; [57] rbibutils_2.3     backports_1.5.0   broom_1.0.7       Rcpp_1.0.14      \n#&gt; [61] nlme_3.1-167      xfun_0.50         pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#bibliografia",
    "href": "chapters/linear_models/08_sample_size.html#bibliografia",
    "title": "63  Disegno della ricerca e potere statistico",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html",
    "href": "chapters/linear_models/09_anova_1via.html",
    "title": "64  ANOVA ad una via",
    "section": "",
    "text": "64.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, emmeans)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#introduzione",
    "href": "chapters/linear_models/09_anova_1via.html#introduzione",
    "title": "64  ANOVA ad una via",
    "section": "\n64.2 Introduzione",
    "text": "64.2 Introduzione\nNel Capitolo 62 abbiamo visto come costruire regressori fittizi (dummy) per rappresentare l’effetto di variabili categoriche (fattori) a due livelli. Consideriamo ora il caso di un singolo fattore con più di due livelli. Per esempio, nel caso di una classificazione a tre categorie, possiamo adottare il modello\n\\[\nY_i = \\alpha + \\gamma_1 D_{i1} + \\gamma_2 D_{i2} + \\varepsilon_i,\n\\tag{64.1}\\]\nutilizzando la seguente codifica per i regressori dummy:\n\\[\n\\begin{array}{c|cc}\n\\text{Gruppo} & D_1 & D_2 \\\\\n\\hline\n1 & 1 & 0 \\\\\n2 & 0 & 1 \\\\\n3 & 0 & 0\n\\end{array}\n\\tag{64.2}\\]\nL’aspettativa della variabile di risposta in ciascun gruppo (cioè in ciascuna categoria o livello del fattore) corrisponde alla media di popolazione del gruppo, indicata con \\(\\mu_j\\) per il gruppo \\(j\\). Poiché l’errore \\(\\varepsilon\\) ha media zero, in base alle usuali ipotesi del modello lineare, prendendo l’aspettativa di entrambi i membri dell’equazione (8.1) si ottengono le relazioni seguenti tra le medie di gruppo e i parametri:\n\\[\n\\begin{aligned}\n\\text{Gruppo 1: } \\mu_1 &= \\alpha + \\gamma_1 \\cdot 1 + \\gamma_2 \\cdot 0 = \\alpha + \\gamma_1, \\\\\n\\text{Gruppo 2: } \\mu_2 &= \\alpha + \\gamma_1 \\cdot 0 + \\gamma_2 \\cdot 1 = \\alpha + \\gamma_2, \\\\\n\\text{Gruppo 3: } \\mu_3 &= \\alpha + \\gamma_1 \\cdot 0 + \\gamma_2 \\cdot 0 = \\alpha.\n\\end{aligned}\n\\tag{64.3}\\]\nQui troviamo tre parametri \\((\\alpha, \\gamma_1, \\gamma_2)\\) e tre medie di gruppo, per cui è possibile risolvere in modo univoco i parametri in termini delle medie di gruppo:\n\\[\n\\alpha = \\mu_3, \\quad \\gamma_1 = \\mu_1 - \\mu_3, \\quad \\gamma_2 = \\mu_2 - \\mu_3.\n\\tag{64.4}\\]\nNon sorprende che \\(\\alpha\\) rappresenti la media della categoria di riferimento (il Gruppo 3), mentre \\(\\gamma_1\\) e \\(\\gamma_2\\) descrivono quanto le altre due medie di gruppo si discostino dalla media della categoria di riferimento.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#simulazione",
    "href": "chapters/linear_models/09_anova_1via.html#simulazione",
    "title": "64  ANOVA ad una via",
    "section": "\n64.3 Simulazione",
    "text": "64.3 Simulazione\nPer esaminare un’applicazione pratica, simuliamo i dati di un fattore con 3 livelli:\n\n# Imposta un seme per riproducibilità (opzionale)\nset.seed(123)\n\n# Definiamo il numero di osservazioni per ogni gruppo\nn &lt;- 30\n\n# Definiamo le medie\nmean_control &lt;- 30\nmean_psico1  &lt;- 25\nmean_psico2  &lt;- 20\n\n# Definiamo la deviazione standard (ipotizziamo la stessa per tutti i gruppi)\nsd_value &lt;- 5\n\n# Generiamo i dati casuali da distribuzioni normali\ncontrollo     &lt;- rnorm(n, mean_control, sd_value)\npsicoterapia1 &lt;- rnorm(n, mean_psico1,  sd_value)\npsicoterapia2 &lt;- rnorm(n, mean_psico2,  sd_value)\n\n# Creiamo un data frame con due colonne:\n# - \"condizione\": indica il gruppo (controllo / psicoterapia1 / psicoterapia2)\n# - \"punteggio\":  contiene i dati numerici generati\ndf &lt;- data.frame(\n  condizione = rep(c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\"), each = n),\n  punteggio  = c(controllo, psicoterapia1, psicoterapia2)\n)\n\n\nhead(df)\n#&gt;   condizione punteggio\n#&gt; 1  controllo     27.20\n#&gt; 2  controllo     28.85\n#&gt; 3  controllo     37.79\n#&gt; 4  controllo     30.35\n#&gt; 5  controllo     30.65\n#&gt; 6  controllo     38.58\n\n\ntail(df)\n#&gt;       condizione punteggio\n#&gt; 85 psicoterapia2     18.90\n#&gt; 86 psicoterapia2     21.66\n#&gt; 87 psicoterapia2     25.48\n#&gt; 88 psicoterapia2     22.18\n#&gt; 89 psicoterapia2     18.37\n#&gt; 90 psicoterapia2     25.74\n\nEsaminiamo la distribuzione dei dati nei tre gruppi:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = condizione)) +\n  # Il violin plot\n  geom_violin(trim = FALSE) +\n  # Boxplot interno al violino\n  geom_boxplot(width = 0.2, outlier.shape = NA) +\n  labs(\n    title = \"Depressione in funzione del gruppo\",\n    x = \"Gruppo\",\n    y = \"Depressione\"\n  ) +\n  # Rimuovi la legenda \n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nCalcoliamo le medie dei gruppi:\n\ndf |&gt; \n  group_by(condizione) |&gt; \n  summarize(\n    avg = mean(punteggio),\n    std = sd(punteggio)\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   condizione      avg   std\n#&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 controllo      29.8  4.91\n#&gt; 2 psicoterapia1  25.9  4.18\n#&gt; 3 psicoterapia2  20.1  4.35\n\nNel caso presente, desideriamo creare due variabili dummy per codificare il fattore \\(`condizione`\\), assumendo come gruppo di riferimento (baseline) la categoria controllo. Ecco come procedere:\n\ndf$condizione &lt;- factor(df$condizione)\ndf$condizione &lt;- relevel(df$condizione, ref = \"controllo\")\ncontrasts(df$condizione)\n#&gt;               psicoterapia1 psicoterapia2\n#&gt; controllo                 0             0\n#&gt; psicoterapia1             1             0\n#&gt; psicoterapia2             0             1\n\nCon questa impostazione, il modello di regressione assume la forma:\n\\[\nY_i = \\beta_0 \\;+\\; \\beta_1 \\,(\\text{psicoterapia1}_i) \\;+\\; \\beta_2 \\,(\\text{psicoterapia2}_i) \\;+\\; \\varepsilon_i,\n\\]\ndove:\n\n\n\\(\\beta_0\\) (l’intercetta) rappresenta la media della condizione di controllo.\n\n\n\\(\\beta_1\\) indica la differenza tra la media del gruppo psicoterapia1 e la media del gruppo controllo.\n\n\n\\(\\beta_2\\) indica la differenza tra la media del gruppo psicoterapia2 e la media del gruppo controllo.\n\nLe variabili \\(\\text{psicoterapia1}_i\\) e \\(\\text{psicoterapia2}_i\\) sono i regressori dummy (0/1) che R crea per i due gruppi di psicoterapia, mentre \\(\\varepsilon_i\\) è il termine di errore.\nIn particolare, nei vari gruppi:\n\nGruppo di controllo: \\(\\text{psicoterapia1}_i = 0\\) e \\(\\text{psicoterapia2}_i = 0\\).\\[\nE[Y_{\\text{controllo}}] = \\beta_0.\n\\]\nGruppo psicoterapia1: \\(\\text{psicoterapia1}_i = 1\\) e \\(\\text{psicoterapia2}_i = 0\\).\\[\nE[Y_{\\text{psicoterapia1}}] = \\beta_0 + \\beta_1.\n\\]\nGruppo psicoterapia2: \\(\\text{psicoterapia1}_i = 0\\) e \\(\\text{psicoterapia2}_i = 1\\).\\[\nE[Y_{\\text{psicoterapia2}}] = \\beta_0 + \\beta_2.\n\\]\n\nIn altre parole, \\(\\beta_1\\) e \\(\\beta_2\\) misurano rispettivamente di quanto la media di psicoterapia1 e di psicoterapia2 si discostino dalla media del gruppo di riferimento (controllo).\n\n\n64.3.1 Stima del modello e interpretazione dei coefficienti\nPer verificare quanto detto, stimiamo il modello di regressione con l’approccio frequentista:\n\nfm1 &lt;- lm(punteggio ~ condizione, data = df)\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)               29.764      0.819   36.33  &lt; 2e-16\n#&gt; condizionepsicoterapia1   -3.873      1.159   -3.34   0.0012\n#&gt; condizionepsicoterapia2   -9.642      1.159   -8.32  1.1e-12\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n\nPossiamo anche calcolare le medie empiriche di ciascun gruppo:\n\nout &lt;- tapply(df$punteggio, df$condizione, mean)\nout\n#&gt;     controllo psicoterapia1 psicoterapia2 \n#&gt;         29.76         25.89         20.12\n\ne quindi le differenze rispetto al controllo:\n\nout[2] - out[1]  # Differenza psico1 - controllo\n#&gt; psicoterapia1 \n#&gt;        -3.873\nout[3] - out[1]  # Differenza psico2 - controllo\n#&gt; psicoterapia2 \n#&gt;        -9.642\n\nLe stime dei coefficienti ottenute da summary(fm1) coincideranno con queste differenze (a meno di arrotondamenti). In altre parole, l’inferenza (frequentista o bayesiana) sul coefficiente \\(\\beta_j\\) corrisponde all’inferenza su tale scostamento tra medie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#contrasti-personalizzati",
    "href": "chapters/linear_models/09_anova_1via.html#contrasti-personalizzati",
    "title": "64  ANOVA ad una via",
    "section": "\n64.4 Contrasti personalizzati",
    "text": "64.4 Contrasti personalizzati\nQuando abbiamo un fattore con tre livelli — ad esempio, controllo, psicoterapia1 e psicoterapia2 — esistono vari schemi di codifica per le variabili dummy. Scegliere lo schema di codifica adeguato significa decidere come interpretare i coefficienti del modello. Per esempio, se vogliamo rispondere alla domanda «la media congiunta delle due psicoterapie è minore (o maggiore) della media del controllo?», possiamo definire un contrasto lineare ad hoc che confronti il gruppo controllo con la media delle due psicoterapie.\n\n64.4.1 Possibili approcci\n\n\nCreare un contrasto lineare ad hoc che confronti \\(\\{\\text{psicoterapia1}, \\text{psicoterapia2}\\}\\) con controllo.\n\n\nRaggruppare i due livelli di psicoterapia in un nuovo fattore binario (controllo vs. psicoterapia) e condurre un test su questo fattore a due livelli (ma in questo modo si perderebbe la distinzione tra “psicoterapia1” e “psicoterapia2”).\n\nIl metodo più flessibile è definire direttamente contrasti personalizzati sul fattore a tre livelli. In tal modo, possiamo gestire contemporaneamente più confronti, ad esempio:\n\n\nContrasto 1: controllo vs. media (psicoterapia1, psicoterapia2)\n\n\nContrasto 2: psicoterapia1 vs. psicoterapia2\n\n\n\n64.4.2 Contrasti personalizzati in R\nObiettivo: definire due contrasti ortogonali per confrontare (1) il gruppo di controllo con la media delle due psicoterapie e (2) psicoterapia1 con psicoterapia2.\n\n64.4.3 Contrasto 1: Controllo vs. (psico1 + psico2)\n\n\nContrasto “grezzo” (non normalizzato):\n\\[\n  (-2,\\; +1,\\; +1)\n  \\quad \\text{con} \\quad -2 + 1 + 1 = 0.\n\\]\nSe usassimo questi pesi direttamente, il coefficiente stimato \\(\\beta_1\\) sarebbe proporzionale alla differenza tra la media del controllo e la media delle due psicoterapie. Tuttavia, il passo da controllo (\\(-2\\)) a ciascuna psicoterapia (\\(+1\\)) è di 3 unità, il che può rendere il coefficiente meno intuitivo da leggere.\n\nNormalizzazione\nPossiamo dividere ogni valore di \\((-2, +1, +1)\\) per la somma assoluta (o per la radice della somma dei quadrati, o per un altro fattore) al fine di ottenere contrasti più semplici.\nAd esempio, se dividiamo \\((-2, +1, +1)\\) per 3, otteniamo \\(\\bigl(-\\tfrac{2}{3}, +\\tfrac{1}{3}, +\\tfrac{1}{3}\\bigr)\\). In tal caso, passare da controllo a psicoterapia fa variare il contrasto di 1 (anziché di 3).\n\n64.4.4 Contrasto 2: psico1 vs. psico2\n\n\nContrasto “grezzo”:\n\\[\n   (\\,0,\\; +1,\\; -1\\,)\n   \\quad \\text{con} \\quad 0 + 1 + (-1) = 0.\n\\]\nQuesto pesi confrontano direttamente psicoterapia1 con psicoterapia2.\n\nNormalizzazione (opzionale)\nPossiamo anche qui dividere per la radice della somma dei quadrati \\(\\sqrt{(0^2 + 1^2 + (-1)^2)}= \\sqrt{2}\\), oppure lasciare i pesi così (poiché qui già passare da p1 a p2 equivale a 2 unità, e potrebbe essere chiaro abbastanza).\n\nNel codice seguente, si è scelto di riscalare (o “normalizzare”) i pesi in modo leggermente diverso, ottenendo numeri come 0.6667 e -0.3333. L’importante è che:\n\nLa somma dei pesi in ciascun contrasto rimanga 0.\n\nI due contrasti siano ortogonali (i prodotti incrociati dei pesi per ogni livello sommano a 0).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#codice-r-per-impostare-e-verificare-i-contrasti",
    "href": "chapters/linear_models/09_anova_1via.html#codice-r-per-impostare-e-verificare-i-contrasti",
    "title": "64  ANOVA ad una via",
    "section": "\n64.5 Codice R per impostare e verificare i Contrasti",
    "text": "64.5 Codice R per impostare e verificare i Contrasti\nDi seguito mostriamo un esempio concreto. Prima descriviamo la matrice di contrasti “grezza” e poi quella normalizzata usata nel codice.\n\n64.5.1 Matrice di contrasti “grezza”\n\n# Contrasto 1 (grezzo):  -2, +1, +1\n# Contrasto 2 (grezzo):   0, +1, -1\n\nmy_contrasts_raw &lt;- matrix(c(\n  -2,  0,  # controllo\n   1, +1,  # psicoterapia1\n   1, -1   # psicoterapia2\n), ncol = 2, byrow = TRUE)\n\ncolnames(my_contrasts_raw) &lt;- c(\"Ctrl_vs_PsicoMean\", \"P1_vs_P2\")\nrownames(my_contrasts_raw) &lt;- c(\"controllo\",\"psicoterapia1\",\"psicoterapia2\")\nmy_contrasts_raw\n#&gt;               Ctrl_vs_PsicoMean P1_vs_P2\n#&gt; controllo                    -2        0\n#&gt; psicoterapia1                 1        1\n#&gt; psicoterapia2                 1       -1\n\n\n64.5.2 Matrice di contrasti “normalizzata” (quella effettivamente nel codice)\nNel codice che segue, i pesi sono stati riscalati per avere differenze di “1” anziché “3” o “2” quando si passa da un gruppo all’altro. Puoi notare, per il primo contrasto, i valori \\((+0.6667, -0.3333, -0.3333)\\) invece di \\((+1, -0.5, -0.5)\\) o \\((-2, +1, +1)\\). Sono solo versioni multiplicativamente equivalenti.\n\nset.seed(123)\n\n# Esempio: definizione della matrice di contrasti\nmy_contrasts &lt;- matrix(c(\n  0.6667,  0,    # controllo  = +0.6667\n  -0.3333, 0.5,  # p1         = -0.3333\n  -0.3333, -0.5  # p2         = -0.3333\n), ncol = 2, byrow = TRUE)\n\ncolnames(my_contrasts) &lt;- c(\"Ctrl_vs_PsicoMean\", \"P1_vs_P2\")\nrownames(my_contrasts) &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\n\n# Verifica: ogni colonna deve sommare a 0\ncolSums(my_contrasts)  # dovrebbero essere circa (0, 0)\n#&gt; Ctrl_vs_PsicoMean          P1_vs_P2 \n#&gt;            0.0001            0.0000\n\n# Verifica: i due contrasti sono ortogonali?\nsum(my_contrasts[,1] * my_contrasts[,2])  # dovrebbe essere 0\n#&gt; [1] 0\n\n\n64.5.3 Applicazione al modello\n\n# 1) Convertiamo 'condizione' in fattore (se non già fattore)\ndf$condizione &lt;- factor(df$condizione)\n\n# 2) Assegnamo la matrice di contrasti al fattore\ncontrasts(df$condizione) &lt;- my_contrasts\n\n# 3) Stimiamo il modello di regressione lineare\nmod_custom &lt;- lm(punteggio ~ condizione, data = df)\n\n# 4) Esaminiamo il riepilogo\nsummary(mod_custom)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)                   25.259      0.473   53.40  &lt; 2e-16\n#&gt; condizioneCtrl_vs_PsicoMean    6.758      1.003    6.73  1.7e-09\n#&gt; condizioneP1_vs_P2             5.770      1.159    4.98  3.2e-06\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#interpretazione-dei-coefficienti",
    "href": "chapters/linear_models/09_anova_1via.html#interpretazione-dei-coefficienti",
    "title": "64  ANOVA ad una via",
    "section": "\n64.6 Interpretazione dei coefficienti",
    "text": "64.6 Interpretazione dei coefficienti\n\nIntercetta (\\(\\hat{\\alpha}\\))\nIn base allo schema di contrasti adottato, può non coincidere con la media effettiva di uno dei tre gruppi. Spesso rappresenta una qualche combinazione lineare delle medie di controllo, psicoterapia1 e psicoterapia2.\n\nPrimo coefficiente (“Ctrl_vs_PsicoMean”)\nConfronta la media del gruppo di controllo con la media (eventualmente pesata) delle due psicoterapie.\n\nSe è positivo, il controllo ha una media maggiore rispetto a quella (combinata) delle psicoterapie.\n\nSe è negativo, indica il contrario (psicoterapie &gt; controllo).\n\n\n\nSecondo coefficiente (“P1_vs_P2”)\nConfronta direttamente psicoterapia1 con psicoterapia2.\n\nSe è positivo, psicoterapia1 ha un punteggio maggiore (in media) di psicoterapia2.\n\nSe è negativo, psicoterapia2 supera psicoterapia1.\n\n\n\nPer controllare manualmente queste differenze, puoi calcolare:\n\n\n\\(\\text{controllo} - \\frac{\\text{psicoterapia1} + \\text{psicoterapia2}}{2}\\):\n\n\nout[1] - (out[2] + out[3]) / 2\n#&gt; controllo \n#&gt;     6.758\n\ndove out[i] è la media empirica del gruppo \\(i\\).\n\n\n\\(\\text{psicoterapia1} - \\text{psicoterapia2}\\):\n\n\nout[2] - out[3]\n#&gt; psicoterapia1 \n#&gt;          5.77\n\nIn sintesi,\n\nLa matrice grezza \\(\\begin{pmatrix} -2 & 0 \\\\ 1 & 1 \\\\ 1 & -1 \\end{pmatrix}\\) e la matrice normalizzata (con valori decimali) rappresentano lo stesso schema di contrasti, ma con differenti scale numeriche.\n\nL’aspetto essenziale è che ciascun contrasto sommi a 0 e che i due contrasti siano ortogonali (prodotto incrociato dei pesi = 0), garantendo interpretazioni indipendenti.\n\nNormalizzare i pesi modifica il valore numerico dei coefficienti, ma non la loro significatività statistica.\n\nScegliendo opportunamente la matrice dei contrasti, possiamo verificare se la media congiunta di psicoterapia1 e psicoterapia2 differisce da quella di controllo e, contemporaneamente, se psicoterapia1 differisce da psicoterapia2. L’eventuale normalizzazione dei pesi non incide sulle conclusioni del test, ma influenza la scala numerica dei coefficienti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#pacchetto-emmeans",
    "href": "chapters/linear_models/09_anova_1via.html#pacchetto-emmeans",
    "title": "64  ANOVA ad una via",
    "section": "\n64.7 Pacchetto emmeans\n",
    "text": "64.7 Pacchetto emmeans\n\nLe stesse analisi descritte sopra possono essere svolte utilizzando le funzioni del pacchetto emmeans. L’idea è:\n\nStimare un modello lineare (come prima).\n\nCalcolare le stime delle medie marginali (le “means” del fattore condizione) tramite emmeans().\n\nDefinire i contrasti di interesse con la funzione contrast().\n\nIn questo modo, è possibile ottenere stime delle medie di ciascun gruppo e confrontarle (ad esempio “controllo” vs. “media delle psicoterapie” o “psicoterapia1” vs. “psicoterapia2”), anche in forma di test statistici (p-value, intervalli di confidenza, ecc.).\n\n64.7.1 Preparazione del modello\nUsiamo ora un modello bayesiano, con prior non informativi o debolmente informativi:\n\nmod &lt;- brm(punteggio ~ condizione, data = df, backend = \"cmdstanr\")\n\n\nsummary(mod)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: punteggio ~ condizione \n#&gt;    Data: df (Number of observations: 90) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                             Estimate Est.Error l-95% CI u-95% CI Rhat\n#&gt; Intercept                      25.25      0.48    24.30    26.21 1.00\n#&gt; condizioneCtrl_vs_PsicoMean     6.77      1.02     4.79     8.77 1.00\n#&gt; condizioneP1_vs_P2              5.73      1.20     3.34     8.03 1.00\n#&gt;                             Bulk_ESS Tail_ESS\n#&gt; Intercept                       4391     3161\n#&gt; condizioneCtrl_vs_PsicoMean     4794     3220\n#&gt; condizioneP1_vs_P2              4632     2764\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     4.54      0.35     3.93     5.30 1.00     4090     2859\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n64.7.2 Calcolo delle medie marginali con emmeans\n\nCalcoliamo le stime delle medie (ls-means) per ciascun livello di ‘condizione’:\n\nem &lt;- emmeans(mod, specs = \"condizione\")\nem\n#&gt;  condizione    emmean lower.HPD upper.HPD\n#&gt;  controllo       29.8      28.3      31.5\n#&gt;  psicoterapia1   25.9      24.3      27.6\n#&gt;  psicoterapia2   20.1      18.4      21.8\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nQuesto oggetto em contiene le medie stimate (e i relativi errori standard) per i tre gruppi: “controllo”, “psicoterapia1” e “psicoterapia2”.\n\n64.7.3 Confronti (pairwise) tra i gruppi\nConfronti a coppie tra tutti i livelli di ‘condizione’ (psicoterapia1 vs controllo, ecc.):\n\npairs(em)\n#&gt;  contrast                      estimate lower.HPD upper.HPD\n#&gt;  controllo - psicoterapia1         3.91      1.62      6.21\n#&gt;  controllo - psicoterapia2         9.64      7.24     11.94\n#&gt;  psicoterapia1 - psicoterapia2     5.74      3.30      7.96\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\n\n64.7.4 Contrasti personalizzati\nReplichiamo i contrasti “ad hoc” (“controllo vs (psico1+psico2)” e “psicoterapia1 vs psicoterapia2”) utilizzati in precedenza:\n\n# Definiamo i contrasti desiderati\nmy_list &lt;- list(\n  \"Ctrl_vs_PsicoMean\" = \n    c(\"controllo\" = 1, \"psicoterapia1\" = -0.5, \"psicoterapia2\" = -0.5),\n  \"P1_vs_P2\"          = \n    c(\"controllo\" = 0,  \"psicoterapia1\" = 1,    \"psicoterapia2\" = -1)\n)\n\ncontrast(em, method = my_list)\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.76      4.78      8.74\n#&gt;  P1_vs_P2              5.74      3.30      7.96\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#altre-opzioni-utili-di-emmeans",
    "href": "chapters/linear_models/09_anova_1via.html#altre-opzioni-utili-di-emmeans",
    "title": "64  ANOVA ad una via",
    "section": "\n64.8 Altre opzioni utili di emmeans\n",
    "text": "64.8 Altre opzioni utili di emmeans\n\n\n\nCredibility intervals:\n\n\nconfint( contrast(em, method = my_list) )\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.76      4.78      8.74\n#&gt;  P1_vs_P2              5.74      3.30      7.96\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nper intervalli di confidenza dei contrasti specificati.\n\n\nTest corretti per confronti multipli:\n\n\ncontrast(em, method = my_list, adjust = \"bonferroni\")\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.76      4.78      8.74\n#&gt;  P1_vs_P2              5.74      3.30      7.96\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\no altre correzioni (ad es. \"holm\", \"sidak\", \"none\").\n\n\nVisualizzazione:\nIl pacchetto emmeans ha anche funzioni per la visualizzazione (plot(em), pwpp(), ecc.).\n\n\n\nplot(em)\n\n\n\n\n\n\n\nIn conclusione, usare emmeans semplifica notevolmente:\n\n\nIl calcolo delle medie stimate (o “ls-means”) di ciascun livello di un fattore in un modello lineare (o GLM, o mixed model, ecc.).\n\n\nLa definizione di contrasti personalizzati, senza dover ridefinire manualmente la matrice di contrasti nel modello (come si fa con contrasts(fattore) &lt;- ...).\n\n\nLa produzione di test e intervalli di confidenza per i confronti desiderati, integrando anche correzioni per confronti multipli se necessario.\n\nIn questo modo, è possibile ottenere esattamente gli stessi risultati che otterresti impostando manualmente i contrasti a livello di design matrix, ma con un approccio più flessibile e con meno passaggi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#riflessioni-conclusive",
    "href": "chapters/linear_models/09_anova_1via.html#riflessioni-conclusive",
    "title": "64  ANOVA ad una via",
    "section": "\n64.9 Riflessioni Conclusive",
    "text": "64.9 Riflessioni Conclusive\nL’ANOVA ad una via non è altro che l’applicazione del modello di regressione al caso di una variabile dipendente quantitativa e di un fattore con più di due livelli. L’aspetto più utile dell’ANOVA riguarda i contrasti, ovvero specifiche ipotesi sulla differenza tra le medie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/09_anova_1via.html#informazioni-sullambiente-di-sviluppo",
    "title": "64  ANOVA ad una via",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6         StanHeaders_2.32.10  emmeans_1.10.7      \n#&gt;  [4] brms_2.22.0          Rcpp_1.0.14          bayestestR_0.15.2   \n#&gt;  [7] posterior_1.6.0.9000 cmdstanr_0.8.1       thematic_0.1.6      \n#&gt; [10] MetBrewer_0.2.0      ggokabeito_0.1.0     see_0.10.0          \n#&gt; [13] gridExtra_2.3        patchwork_1.3.0      bayesplot_1.11.1    \n#&gt; [16] psych_2.4.12         scales_1.3.0         markdown_1.13       \n#&gt; [19] knitr_1.49           lubridate_1.9.4      forcats_1.0.0       \n#&gt; [22] stringr_1.5.1        dplyr_1.1.4          purrr_1.0.4         \n#&gt; [25] readr_2.1.5          tidyr_1.3.1          tibble_3.2.1        \n#&gt; [28] ggplot2_3.5.1        tidyverse_2.0.0      rio_1.2.3           \n#&gt; [31] here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      survival_3.8-3      \n#&gt; [13] processx_3.8.5       magrittr_2.0.3       compiler_4.4.2      \n#&gt; [16] rlang_1.1.5          tools_4.4.2          utf8_1.2.4          \n#&gt; [19] yaml_2.3.10          data.table_1.16.4    labeling_0.4.3      \n#&gt; [22] bridgesampling_1.1-2 htmlwidgets_1.6.4    curl_6.2.0          \n#&gt; [25] pkgbuild_1.4.6       mnormt_2.1.1         plyr_1.8.9          \n#&gt; [28] abind_1.4-8          multcomp_1.4-28      withr_3.0.2         \n#&gt; [31] stats4_4.4.2         grid_4.4.2           inline_0.3.21       \n#&gt; [34] xtable_1.8-4         colorspace_2.1-1     MASS_7.3-64         \n#&gt; [37] insight_1.0.2        cli_3.6.4            mvtnorm_1.3-3       \n#&gt; [40] rmarkdown_2.29       generics_0.1.3       RcppParallel_5.1.10 \n#&gt; [43] rstudioapi_0.17.1    reshape2_1.4.4       tzdb_0.4.0          \n#&gt; [46] splines_4.4.2        parallel_4.4.2       matrixStats_1.5.0   \n#&gt; [49] vctrs_0.6.5          V8_6.0.1             Matrix_1.7-2        \n#&gt; [52] sandwich_3.1-1       jsonlite_1.8.9       hms_1.1.3           \n#&gt; [55] glue_1.8.0           codetools_0.2-20     ps_1.8.1            \n#&gt; [58] distributional_0.5.0 stringi_1.8.4        gtable_0.3.6        \n#&gt; [61] QuickJSR_1.5.1       munsell_0.5.1        pillar_1.10.1       \n#&gt; [64] htmltools_0.5.8.1    Brobdingnag_1.2-9    R6_2.6.1            \n#&gt; [67] rprojroot_2.0.4      evaluate_1.0.3       lattice_0.22-6      \n#&gt; [70] backports_1.5.0      rstantools_2.4.0     coda_0.19-4.1       \n#&gt; [73] nlme_3.1-167         checkmate_2.3.2      xfun_0.50           \n#&gt; [76] zoo_1.8-12           pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#bibliografia",
    "href": "chapters/linear_models/09_anova_1via.html#bibliografia",
    "title": "64  ANOVA ad una via",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html",
    "href": "chapters/linear_models/10_anova_2vie.html",
    "title": "65  ANOVA ad due vie",
    "section": "",
    "text": "65.1 Introduzione\nL’ANOVA a due o più vie estende il caso dell’ANOVA ad una via alla presenza di molteplici criteri di classificazione. Qui ci concentreremo sull’ANOVA a due vie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#introduzione",
    "href": "chapters/linear_models/10_anova_2vie.html#introduzione",
    "title": "65  ANOVA ad due vie",
    "section": "",
    "text": "65.1.1 Pattern delle medie nella classificazione a due vie\nImmaginiamo di disporre delle medie di popolazione. La notazione per la classificazione a due vie è illustrata nella seguente tabella:\n\n\n\nC1\nC2\n…\nCc\nTotale colonna\n\n\n\nR1\nµ11\nµ12\n…\nµ1c\nµ1:\n\n\nR2\nµ21\nµ22\n…\nµ2c\nµ2:\n\n\n…\n…\n…\n…\n…\n…\n\n\nRr\nµr1\nµr2\n…\nµrc\nµr:\n\n\n————\n——-\n——-\n——\n——-\n—————-\n\n\nTotale riga\nµ:1\nµ:2\n…\nµ:c\nµ::\n\n\n\nQui, i fattori \\(R\\) e \\(C\\) (così denominati in riferimento alle righe e alle colonne della tabella delle medie) presentano rispettivamente \\(r\\) e \\(c\\) categorie. Indichiamo le categorie dei fattori come \\(R_j\\) e \\(C_k\\).\nAll’interno di ogni cella del disegno sperimentale—cioè per ciascuna combinazione di categorie \\(\\{R_j, C_k\\}\\) dei due fattori—si trova una media di popolazione \\(\\mu_{jk}\\) relativa alla variabile di risposta.\nPer descrivere le medie su righe, colonne e quella complessiva, utilizziamo la notazione a “punti”:\n\\[\n\\mu_{j:} \\;=\\; \\frac{\\sum_{k=1}^{c} \\mu_{jk}}{c}\n\\quad\\text{(media marginale sulla riga $j$)},\n\\]\n\\[\n\\mu_{:k} \\;=\\; \\frac{\\sum_{j=1}^{r} \\mu_{jk}}{r}\n\\quad\\text{(media marginale sulla colonna $k$)},\n\\]\n\\[\n\\mu_{::} \\;=\\; \\frac{\\sum_{j=1}^{r}\\sum_{k=1}^{c} \\mu_{jk}}{r\\,c}\n\\;=\\; \\frac{\\sum_{j=1}^{r} \\mu_{j:}}{r}\n\\;=\\; \\frac{\\sum_{k=1}^{c} \\mu_{:k}}{c}\n\\quad\\text{(media generale, o grand mean)}.\n\\]\n\n65.1.2 Effetti principali e interazione\nSe i fattori \\(R\\) e \\(C\\) non interagiscono nel determinare la variabile di risposta, allora l’effetto di uno di essi, a parità di categoria dell’altro, rimane costante. In termini pratici, la differenza fra le medie di cella \\(\\mu_{jk} - \\mu_{j'k}\\)—quando confrontiamo due categorie di \\(R\\), ad esempio \\(R_j\\) e \\(R_{j'}\\)—è la stessa per tutte le categorie di \\(C\\) (cioè per \\(k = 1, 2, \\dots, c\\)).\nDi conseguenza, la differenza fra le medie nelle righe è uguale alla differenza fra le corrispondenti medie marginali di riga:\n\\[\n\\mu_{jk} - \\mu_{j'k} \\;=\\; \\mu_{jk'} - \\mu_{j'k'} \\;=\\; \\mu_{j:} - \\mu_{j':}\n\\quad\\text{per ogni } j, j' \\text{ e } k, k'.\n\\]\nUn altro modo di vedere questa assenza di interazione è attraverso i profili di medie di cella, che in questo caso risultano “paralleli”. Se i profili sono paralleli, allora la differenza fra \\(\\mu_{j1}\\) e \\(\\mu_{j2}\\) (categorie \\(C_1\\) e \\(C_2\\)) resta costante fra le diverse righe \\(j = 1, 2\\), e coincide con la differenza fra le medie marginali di colonna, \\(\\mu_{:1} - \\mu_{:2}\\).\nL’interazione è un concetto simmetrico: se il fattore \\(R\\) interagisce con il fattore \\(C\\), vale anche il contrario. Quando non si verifica interazione, l’effetto principale (o main effect) di ogni fattore corrisponde semplicemente alla differenza fra le medie marginali di popolazione relative a quel fattore.\nLa figura seguente presentata diversi scenari possibili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#simulazione",
    "href": "chapters/linear_models/10_anova_2vie.html#simulazione",
    "title": "65  ANOVA ad due vie",
    "section": "\n65.2 Simulazione",
    "text": "65.2 Simulazione\nPer fare un esempio concreto, simuliamo dei dati seguendo lo schema utilizzato con l’ANOVA ad una via. In questo caso, aggiungiamo un secondo fattore: la gravità dei sintomi.\n\n# Imposta un seme per riproducibilità (opzionale)\nset.seed(123)\n\n# Definiamo il numero di osservazioni per ogni cella\nn &lt;- 30\n\n# Definiamo le categorie dei fattori\ngravita &lt;- c(\"molto_gravi\", \"poco_gravi\")\ncondizione &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\n\n# Definiamo la deviazione standard (ipotizziamo la stessa per tutte le celle)\nsd_value &lt;- 5\n\n# Definiamo le medie attese per ciascuna combinazione (gravita x condizione)\n# Esempio:\n# - Pazienti molto gravi:  (controllo=30, psico1=25, psico2=20)\n# - Pazienti poco gravi:   (controllo=25, psico1=20, psico2=15)\n\nmean_table &lt;- matrix(\n  c(30, 25, 20,  # molto_gravi\n    25, 20, 15), # poco_gravi\n  nrow = 2,      # 2 righe per \"molto_gravi\" e \"poco_gravi\"\n  ncol = 3,      # 3 colonne per \"controllo\", \"psicoterapia1\", \"psicoterapia2\"\n  byrow = TRUE\n)\n\n# Crea un data frame vuoto che riempiremo con i dati simulati\ndf &lt;- data.frame()\n\nfor (i in seq_along(gravita)) {\n  for (j in seq_along(condizione)) {\n    # Estraiamo la media corrispondente alla combinazione (i, j)\n    current_mean &lt;- mean_table[i, j]\n    \n    # Generiamo 'n' osservazioni normali con media = current_mean e sd = sd_value\n    simulated_data &lt;- rnorm(n, mean = current_mean, sd = sd_value)\n    \n    # Creiamo un data frame temporaneo per questa combinazione\n    temp_df &lt;- data.frame(\n      gravita    = gravita[i],\n      condizione = condizione[j],\n      punteggio  = simulated_data\n    )\n    \n    # Append al data frame finale\n    df &lt;- rbind(df, temp_df)\n  }\n}\n\nEsaminiamo le medie:\n\n# Esempio di sintesi statistica\naggregate(punteggio ~ gravita + condizione, data = df, mean)\n#&gt;       gravita    condizione punteggio\n#&gt; 1 molto_gravi     controllo     29.76\n#&gt; 2  poco_gravi     controllo     24.53\n#&gt; 3 molto_gravi psicoterapia1     25.89\n#&gt; 4  poco_gravi psicoterapia1     19.08\n#&gt; 5 molto_gravi psicoterapia2     20.12\n#&gt; 6  poco_gravi psicoterapia2     15.77\n\nRappresentiamo graficamente la distribuzione dei dati nelle varie condizioni:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = gravita)) +\n  geom_boxplot(position = position_dodge()) +\n  labs(title = \"Simulazione dati: Effetto gravità e condizione\",\n       x = \"Condizione sperimentale\",\n       y = \"Punteggio\")\n\n\n\n\n\n\n\nAddattiamo ai dati un modello bayesiano:\n\nmod &lt;- brm(\n  punteggio ~ gravita * condizione, \n  data = df,\n  backend = \"cmdstanr\"\n)\n\nEsaminiamo le stime del modello:\n\nconditional_effects(mod, \"condizione:gravita\")\n\n\n\n\n\n\n\nUn sommario delle stime a posteriori si ottiene nel modo seguente:\n\nsummary(mod)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: punteggio ~ gravita * condizione \n#&gt;    Data: df (Number of observations: 180) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                                           Estimate Est.Error l-95% CI\n#&gt; Intercept                                    29.75      0.86    28.03\n#&gt; gravitapoco_gravi                            -5.20      1.21    -7.61\n#&gt; condizionepsicoterapia1                      -3.86      1.23    -6.24\n#&gt; condizionepsicoterapia2                      -9.61      1.23   -12.05\n#&gt; gravitapoco_gravi:condizionepsicoterapia1    -1.61      1.72    -4.99\n#&gt; gravitapoco_gravi:condizionepsicoterapia2     0.83      1.72    -2.53\n#&gt;                                           u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept                                    31.45 1.00     2133     2829\n#&gt; gravitapoco_gravi                            -2.87 1.00     1866     2352\n#&gt; condizionepsicoterapia1                      -1.36 1.00     2240     2404\n#&gt; condizionepsicoterapia2                      -7.16 1.00     2274     2624\n#&gt; gravitapoco_gravi:condizionepsicoterapia1     1.85 1.00     1924     2338\n#&gt; gravitapoco_gravi:condizionepsicoterapia2     4.23 1.00     2071     2416\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     4.79      0.25     4.33     5.32 1.00     3481     2699\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nL’esame dell’output precedente mostra come sia difficile rispondere alle domende di interesse mediante l’esame dei singoli coefficienti. Per valutare gli effetti principali e la presenza di interazione si usa invece un metodo basato sul confronto tra modelli.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#confronto-tra-modelli",
    "href": "chapters/linear_models/10_anova_2vie.html#confronto-tra-modelli",
    "title": "65  ANOVA ad due vie",
    "section": "\n65.3 Confronto tra Modelli",
    "text": "65.3 Confronto tra Modelli\nIl test degli effetti principali e dell’interazione viene eseguito, nell’approccio frequentista, calcolando R^2 per i vari modelli per poi fare una differenza tra gli R^2 pesati per i gradi di libertà. Questa differenza si distribuisce come F e quindi disponiamo di una distribuzione campionaria nota per questa statistica. Il test si fa nel solito modo, ovvero ci si chiede se la differenza in R^2 osservata è sufficientemente piccola da potere essere attribuita al caso, sotto l’ipotesi che i due modelli sono equivalenti, oppure no.\nI test bayesiani si basano su una logica diversa, anche se ha alcuni punti in comune. Il confronto tra modelli si basa su una quantità chiamata LOO (Leave-One-Out cross-validation).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#cosè-loo-leave-one-out-cross-validation",
    "href": "chapters/linear_models/10_anova_2vie.html#cosè-loo-leave-one-out-cross-validation",
    "title": "65  ANOVA ad due vie",
    "section": "\n65.4 Cos’è LOO (Leave-One-Out cross-validation)?",
    "text": "65.4 Cos’è LOO (Leave-One-Out cross-validation)?\nLOO è un metodo per stimare quanto bene un modello predice nuovi dati. In particolare, misura quanto il modello è in grado di generalizzare oltre i dati usati per costruirlo.\n\nCome funziona:\nSi rimuove iterativamente una osservazione dal dataset, si stima il modello sui dati rimanenti e si valuta quanto bene il modello predice l’osservazione esclusa. Questo processo viene ripetuto per tutte le osservazioni.\nNel contesto Bayesiano:\nPoiché ricalcolare il modello per ogni possibile sottogruppo di dati sarebbe computazionalmente oneroso, si usa una stima approssimativa di LOO basata sul concetto di PSIS-LOO (Pareto Smoothed Importance Sampling). Questa stima è disponibile direttamente in brms tramite il comando loo().",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#indicatori-principali-nei-risultati-di-loo",
    "href": "chapters/linear_models/10_anova_2vie.html#indicatori-principali-nei-risultati-di-loo",
    "title": "65  ANOVA ad due vie",
    "section": "\n65.5 Indicatori principali nei risultati di LOO\n",
    "text": "65.5 Indicatori principali nei risultati di LOO\n\n\nelpd (expected log predictive density):\nÈ la somma logaritmica delle probabilità predittive del modello per ogni osservazione, calcolata dopo aver escluso quella stessa osservazione. Valori più alti indicano un modello che predice meglio.\nelpd_diff:\nDifferenza di elpd tra due modelli. Se \\(\\text{elpd}_{\\text{model1}} &gt; \\text{elpd}_{\\text{model2}}\\), il modello 1 è preferito.\nse_diff (standard error of difference):\nL’incertezza associata a elpd_diff. Se |elpd_diff| è molto piccolo rispetto a se_diff, la differenza tra i modelli non è considerata robusta.\n\n\nNel caso presente, confrontiamo due modelli:\n\n\nmod1: Modello completo (con interazione).\n\n\nmod: Modello senza interazione (solo effetti principali).\n\n\nmod1 &lt;- brm(\n  punteggio ~ gravita + condizione, \n  data = df,\n  backend = \"cmdstanr\"\n)\n\n\n65.5.1 Confronto LOO\n\n# Confronto via LOO\nloo_full &lt;- loo(mod)\nloo_noint  &lt;- loo(mod1)\nloo_compare(loo_full, loo_noint)\n#&gt;      elpd_diff se_diff\n#&gt; mod1  0.0       0.0   \n#&gt; mod  -0.7       1.5\n\n\nelpd_diff = -0.9: Il modello con interazione (mod) ha un elpd leggermente più basso rispetto al modello senza interazione (mod1). Questo significa che il modello senza interazione è leggermente preferibile in termini di capacità predittiva sui nuovi dati.\nse_diff = 1.5: L’incertezza associata alla differenza di elpd è molto più grande della differenza stessa (elpd_diff / se_diff). Questo implica che non c’è evidenza sufficiente per concludere che uno dei due modelli sia chiaramente migliore.\n\nIn conclusione,\n\nIl modello senza interazione (mod1) è leggermente preferibile in termini di LOO-IC, ma la differenza è trascurabile e non robusta, data l’elevata incertezza (se_diff = 1.5).\n\nInterpretazione pratica:\n\nNon ci sono prove sufficienti per preferire il modello con interazione (mod) rispetto al modello senza interazione (mod1).\nIn assenza di altre considerazioni teoriche che giustifichino l’inclusione dell’interazione, il modello più semplice (mod1, senza interazione) è probabilmente una scelta migliore.\n\n\n\nSi procede in un modo simile per i test degli effetti principali. In quel caso potremmo confrontrare un modello con gli effetti additivi dei due fattori con un modello con un unico fattore.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/10_anova_2vie.html#informazioni-sullambiente-di-sviluppo",
    "title": "65  ANOVA ad due vie",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6         StanHeaders_2.32.10  bridgesampling_1.1-2\n#&gt;  [4] loo_2.8.0            emmeans_1.10.7       brms_2.22.0         \n#&gt;  [7] Rcpp_1.0.14          bayestestR_0.15.2    posterior_1.6.0.9000\n#&gt; [10] cmdstanr_0.8.1       thematic_0.1.6       MetBrewer_0.2.0     \n#&gt; [13] ggokabeito_0.1.0     see_0.10.0           gridExtra_2.3       \n#&gt; [16] patchwork_1.3.0      bayesplot_1.11.1     psych_2.4.12        \n#&gt; [19] scales_1.3.0         markdown_1.13        knitr_1.49          \n#&gt; [22] lubridate_1.9.4      forcats_1.0.0        stringr_1.5.1       \n#&gt; [25] dplyr_1.1.4          purrr_1.0.4          readr_2.1.5         \n#&gt; [28] tidyr_1.3.1          tibble_3.2.1         ggplot2_3.5.1       \n#&gt; [31] tidyverse_2.0.0      rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         fastmap_1.2.0       \n#&gt;  [4] TH.data_1.1-3        tensorA_0.36.2.1     pacman_0.5.1        \n#&gt;  [7] digest_0.6.37        timechange_0.3.0     estimability_1.5.1  \n#&gt; [10] lifecycle_1.0.4      survival_3.8-3       processx_3.8.5      \n#&gt; [13] magrittr_2.0.3       compiler_4.4.2       rlang_1.1.5         \n#&gt; [16] tools_4.4.2          yaml_2.3.10          data.table_1.16.4   \n#&gt; [19] labeling_0.4.3       htmlwidgets_1.6.4    curl_6.2.0          \n#&gt; [22] pkgbuild_1.4.6       mnormt_2.1.1         plyr_1.8.9          \n#&gt; [25] abind_1.4-8          multcomp_1.4-28      withr_3.0.2         \n#&gt; [28] stats4_4.4.2         grid_4.4.2           inline_0.3.21       \n#&gt; [31] xtable_1.8-4         colorspace_2.1-1     MASS_7.3-64         \n#&gt; [34] insight_1.0.2        cli_3.6.4            mvtnorm_1.3-3       \n#&gt; [37] rmarkdown_2.29       generics_0.1.3       RcppParallel_5.1.10 \n#&gt; [40] rstudioapi_0.17.1    reshape2_1.4.4       tzdb_0.4.0          \n#&gt; [43] splines_4.4.2        parallel_4.4.2       matrixStats_1.5.0   \n#&gt; [46] vctrs_0.6.5          V8_6.0.1             Matrix_1.7-2        \n#&gt; [49] sandwich_3.1-1       jsonlite_1.8.9       hms_1.1.3           \n#&gt; [52] glue_1.8.0           codetools_0.2-20     ps_1.8.1            \n#&gt; [55] distributional_0.5.0 stringi_1.8.4        gtable_0.3.6        \n#&gt; [58] QuickJSR_1.5.1       munsell_0.5.1        pillar_1.10.1       \n#&gt; [61] htmltools_0.5.8.1    Brobdingnag_1.2-9    R6_2.6.1            \n#&gt; [64] rprojroot_2.0.4      evaluate_1.0.3       lattice_0.22-6      \n#&gt; [67] backports_1.5.0      rstantools_2.4.0     coda_0.19-4.1       \n#&gt; [70] nlme_3.1-167         checkmate_2.3.2      xfun_0.50           \n#&gt; [73] zoo_1.8-12           pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#bibliografia",
    "href": "chapters/linear_models/10_anova_2vie.html#bibliografia",
    "title": "65  ANOVA ad due vie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html",
    "href": "chapters/linear_models/11_one_proportion.html",
    "title": "66  Inferenza sulle proporzioni",
    "section": "",
    "text": "66.1 Introduzione\nIn questo capitolo esploreremo come affrontare il problema dell’inferenza su una proporzione o sul confronto tra due proporzioni utilizzando un approccio bayesiano. Per tale scopo, utilizzeremo il pacchetto brms in R. L’approccio bayesiano ci permette di ottenere una distribuzione completa della probabilità a posteriori del parametro di interesse, offrendo una visione più ricca e flessibile rispetto all’approccio frequentista tradizionale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#inferenza-su-una-proporzione",
    "href": "chapters/linear_models/11_one_proportion.html#inferenza-su-una-proporzione",
    "title": "66  Inferenza sulle proporzioni",
    "section": "\n66.2 Inferenza su Una Proporzione",
    "text": "66.2 Inferenza su Una Proporzione\n\n66.2.1 Contesto e Dati\nCome esempio per l’inferenza su una proporzione, utilizzeremo i dati dello studio di Brückner & Bearman (2005), discussi anche da Wagenmakers et al. (2010). Nell’articolo “After the promise: the STD consequences of adolescent virginity pledges”, Brückner & Bearman (2005) analizzano una serie di interviste condotte nell’ambito del National Longitudinal Study of Adolescent Health (Add Health). Lo studio si concentra sul comportamento sessuale di adolescenti, di età compresa tra 18 e 24 anni, che hanno fatto un “virginity pledge”, ovvero una promessa pubblica o scritta di rimanere vergini fino al matrimonio. Studi scientifici indicano che il comportamento sessuale di questi adolescenti non sia statisticamente diverso da quello di chi non ha fatto tale promessa, con l’unica eccezione che i “pledgers” hanno una minore probabilità di utilizzare il preservativo durante il primo rapporto sessuale.\nI dati rilevanti per la nostra analisi sono i seguenti:\n\nsu 777 adolescenti che hanno fatto il “virginity pledge”, 424 (54.6%) hanno dichiarato di aver usato il preservativo durante il primo rapporto sessuale;\nsu 9072 adolescenti che non hanno fatto la promessa, 5416 (59.7%) hanno dichiarato di aver usato il preservativo.\n\n66.2.2 Obiettivo dell’Analisi\nNella prima analisi, ci concentreremo sul campione di adolescenti che hanno fatto il “virginity pledge”. Ci chiediamo se sia credibile pensare che questi adolescenti tendano ad avere un rapporto protetto, nel loro primo rapporto sessuale, in una proporzione minore di quella che ci si potrebbe aspettare in caso di casualità (ovvero, una proporzione di 0.5).\n\n66.2.3 Analisi Frequentista\nIniziamo con un test frequentista per confrontare la proporzione osservata con il valore di riferimento 0.5.\n\nprop_test_freq_vol &lt;- prop.test(\n  x = 424,\n  n = 777,\n  p = 0.5\n)\n\ntidy(prop_test_freq_vol)\n#&gt; # A tibble: 1 × 8\n#&gt;   estimate statistic p.value parameter conf.low conf.high method            \n#&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;             \n#&gt; 1    0.546      6.31  0.0120         1    0.510     0.581 1-sample proporti…\n#&gt; # ℹ 1 more variable: alternative &lt;chr&gt;\n\nL’intervallo di confidenza frequentista non include il valore di riferimento 0.5, quindi, in base a questa analisi, possiamo concludere che la proporzione osservata (0.546) sia significativamente maggiore del valore atteso in caso di casualità (0.5).\n\n66.2.4 Approccio Bayesiano con brms\n\nSe utilizziamo dei prior non informativi, ci aspettiamo di giungere alla stessa conclusione anche con un approccio bayesiano. Tuttavia, l’approccio bayesiano ci permette di ottenere una distribuzione completa della probabilità a posteriori del parametro di interesse, offrendo una visione più ricca e flessibile rispetto all’approccio frequentista.\n\n66.2.4.1 Preparazione dei Dati\nIniziamo creando un data frame che sarà utilizzato con la funzione brm().\n\npledge_binomial_df &lt;- tibble(\n  n_yes = 424,\n  n_total = 777\n)\n\n# tiny data\npledge_binomial_df\n#&gt; # A tibble: 1 × 2\n#&gt;   n_yes n_total\n#&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1   424     777\n\n\n66.2.4.2 Definizione delle Opzioni del Campionatore\nImpostiamo alcune opzioni globali per il campionatore Stan.\n\n# Set some global Stan options\nCHAINS &lt;- 4\nITER &lt;- 2000\nWARMUP &lt;- 1000\nBAYES_SEED &lt;- 1234\n\n\n66.2.4.3 Modello Bayesiano\nUtilizziamo un modello di regressione con una funzione link binomiale. Questo significa che stimeremo la proporzione \\(p\\) con un modello di regressione beta-binomiale bayesiano utilizzando brms. Useremo un prior non informativo \\(\\mathcal{Beta}(1, 1)\\). Questo è un modello solo con intercetta, senza altre covariate, poiché siamo interessati solo alla proporzione sottostante, senza condizionarla su altre variabili.\nIl modello può essere rappresentato come segue:\n\\[\n\\begin{aligned}\ny_{\\text{condom\\_use}} &\\sim \\mathcal{Binomial}(n, \\pi) \\\\\n\\pi &= \\beta_0 \\\\\n\\beta_0 &\\sim \\mathcal{Beta}(1, 1)\n\\end{aligned}\n\\]\nEseguiamo l’analisi bayesiana.\n\nmodel_pledge_binomial &lt;- brm(\n  n_yes | trials(n_total) ~ 1,\n  data = pledge_binomial_df,\n  family = binomial(link = \"identity\"),\n  prior = c(prior(beta(1, 1), class = \"Intercept\", lb = 0, ub = 1)),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n#&gt; Running MCMC with 4 sequential chains...\n#&gt; \n#&gt; Chain 1 finished in 0.0 seconds.\n#&gt; Chain 2 finished in 0.0 seconds.\n#&gt; Chain 3 finished in 0.0 seconds.\n#&gt; Chain 4 finished in 0.0 seconds.\n#&gt; \n#&gt; All 4 chains finished successfully.\n#&gt; Mean chain execution time: 0.0 seconds.\n#&gt; Total execution time: 0.5 seconds.\n\n\n66.2.4.4 Risultati del Modello\nPoiché questo è un modello di regressione, si comporta come qualsiasi altro modello brms. Il coefficiente per l’intercetta rappresenta la proporzione stimata di adolescenti tra i 18 e i 24 anni che hanno usato il preservativo durante il primo rapporto sessuale nel campione.\n\nsummary(model_pledge_binomial)\n#&gt;  Family: binomial \n#&gt;   Links: mu = identity \n#&gt; Formula: n_yes | trials(n_total) ~ 1 \n#&gt;    Data: pledge_binomial_df (Number of observations: 1) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     0.55      0.02     0.51     0.58 1.00     1457     1756\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nSi noti come l’intervallo di credibilità al 95% riproduce l’intervallo frequentista calcolato in precedenza.\n\n66.2.5 Discussione e Confronto tra Approcci\nConfrontiamo ora i risultati ottenuti dai due approcci. L’analisi frequentista ha mostrato che la proporzione osservata (0.546) è significativamente maggiore del valore di riferimento 0.5. L’approccio bayesiano conferma questa conclusione, fornendo una distribuzione completa della probabilità a posteriori per la proporzione π. Uno dei vantaggi dell’approccio bayesiano è la possibilità di incorporare informazioni a priori, se disponibili, migliorando così la robustezza delle inferenze. Inoltre, l’intervallo di credibilità bayesiano fornisce una descrizione più completa della distribuzione dei parametri, consentendo una migliore interpretazione dei risultati.\n\n66.2.6 Modello Beta-Binomiale e Soluzione Analitica\nIn questo contesto, il problema può essere modellato utilizzando una distribuzione beta-binomiale, per la quale esiste una soluzione analitica per la distribuzione a posteriori. Il modello beta-binomiale è particolarmente adatto quando si lavora con dati binomiali (ad esempio, successi e fallimenti) e si desidera incorporare una distribuzione a priori coniugata per la proporzione \\(p\\).\n\n66.2.6.1 Contestualizzazione del Modello\nPer il gruppo “pledgers”, abbiamo \\(y_1\\) successi su \\(n_1\\) prove. Se assumiamo una distribuzione a priori Beta(\\(\\alpha\\), \\(\\beta\\)), la distribuzione a posteriori per la proporzione \\(p_1\\) sarà anch’essa una distribuzione Beta, data da:\n\\[\np_1 \\mid y_1, n_1 \\sim \\mathcal{Beta}(\\alpha + y_1, \\beta + n_1 - y_1)\n\\]\nNel nostro caso specifico, scegliamo una prior non informativa \\(\\mathcal{Beta}(1, 1)\\), che equivale a una distribuzione uniforme sull’intervallo [0, 1]. Questa scelta riflette l’assenza di informazioni pregresse sulla proporzione \\(p_1\\). Pertanto, la distribuzione a posteriori per il gruppo “pledgers” diventa:\n\\[\np_1 \\mid y_1, n_1 \\sim \\mathcal{Beta}(1 + 424, 1 + 777 - 424) = \\mathcal{Beta}(425, 354)\n\\]\n\n66.2.6.2 Calcolo dell’Intervallo di Credibilità\nUtilizziamo R per calcolare l’intervallo di credibilità al 95% basato sulla distribuzione a posteriori derivata analiticamente.\n\n# Parametri della distribuzione Beta\na_post &lt;- 425  # Parametro alpha\nb_post &lt;- 354  # Parametro beta\n\n# Calcolo dell'intervallo centrale al 95%\ncredibility_interval &lt;- qbeta(c(0.025, 0.975), shape1 = a_post, shape2 = b_post)\nprint(credibility_interval)\n#&gt; [1] 0.5105 0.5804\n\nIl risultato ottenuto dall’analisi bayesiana analitica replica quello ottenuto tramite il modello brm() implementato in precedenza. Questo confronto tra approcci ci permette di validare i risultati e dimostra la coerenza tra le tecniche frequentista, bayesiana numerica e bayesiana analitica.\n\n66.2.7 Discussione e Confronto tra Approcci\nL’utilizzo della distribuzione beta-binomiale e della soluzione analitica offre diversi vantaggi:\n\n\nSemplicità: La soluzione analitica è spesso più semplice da implementare rispetto ai metodi numerici, come quelli utilizzati in brms.\n\nVelocità: I calcoli sono generalmente più veloci poiché non richiedono iterazioni o campionamenti.\n\nInterpretazione: L’uso di distribuzioni coniugate facilita l’interpretazione dei risultati, fornendo direttamente la distribuzione a posteriori senza bisogno di complessi algoritmi di inferenza.\n\nTuttavia, l’approccio bayesiano numerico tramite brms presenta anche vantaggi significativi:\n\n\nFlessibilità: Può gestire modelli più complessi e includere covariate multiple.\n\nPriori informativi: Permette di incorporare facilmente informazioni a priori, se disponibili.\n\nEstensioni: Facilita l’estensione del modello a casi più complessi, come il confronto tra proporzioni di due gruppi.\n\n\n66.2.7.1 Analisi della Distribuzione a Posteriori\nEssendo un’analisi bayesiana, possiamo lavorare con l’intera distribuzione a posteriori e calcolare direttamente l’estimando, come la differenza tra la proporzione campionaria e la proporzione di riferimento (0.5).\n\npledge_draws &lt;- model_pledge_binomial |&gt; \n  spread_draws(b_Intercept) |&gt; \n  mutate(diff = b_Intercept - 0.5)\n\nVisualizziamo la distribuzione a posteriori della proporzione.\n\np1 &lt;- ggplot(pledge_draws, aes(x = b_Intercept, y = \"Age 18–24\")) + \n  stat_halfeye(fill = \"gray\") +\n  geom_vline(xintercept = 0.5) +\n  scale_x_continuous(labels = label_percent()) +\n  coord_cartesian(ylim = c(1.5, 1.5)) +\n  labs(x = \"Proportion used a condom at first sex\", y = NULL)\np1\n\n\n\n\n\n\n\nIl valore di riferimento (0.5) non è incluso nella distribuzione a posteriori, il che significa che la differenza tra la proporzione campionaria e la proporzione di riferimento non include lo zero, con un livello di credibilità del 95%. Possiamo quindi concludere, con un livello soggettivo di credibilità del 95%, che l’uso del preservativo durante il primo rapporto sessuale sia maggiore del caso, per gli adolescenti che hanno fatto il “virginity pledge”.\n\n66.2.8 La Regione di Equivalenza Pratica (ROPE)\nL’analisi precedente confronta la proporzione osservata con un singolo valore di riferimento (0.5). Un approccio alternativo è considerare un intervallo di valori attorno a 0.5 che possano essere considerati “praticamente equivalenti” al valore di riferimento. Questo intervallo è chiamato Regione di Equivalenza Pratica (ROPE).\nSecondo Kruschke & Liddell (2018), la ROPE può essere definita come un intervallo attorno al valore nullo (baseline) che corrisponde a un decimo della deviazione standard della distribuzione a posteriori del parametro di interesse. Nel nostro caso, il parametro di interesse è la proporzione \\(p\\), e il valore nullo è 0.5. Per calcolare la ROPE, estraiamo i campioni a posteriori dal modello.\n\nposterior_samples &lt;- as_draws_df(model_pledge_binomial)\n\nCalcoliamo la deviazione standard a posteriori di \\(p\\).\n\nposterior_std_dev &lt;- sd(posterior_samples$b_Intercept)\nposterior_std_dev\n#&gt; [1] 0.01809\n\nDefiniamo la ROPE come un intervallo attorno al valore di riferimento 0.5.\n\nbaseline &lt;- 0.5  # Valore nullo (baseline)\nrope_low &lt;- baseline - 0.1 * posterior_std_dev\nrope_high &lt;- baseline + 0.1 * posterior_std_dev\n\nCalcoliamo ora la probabilità che la proporzione \\(p\\) si trovi all’interno della ROPE.\n\nrope_probability &lt;-\n  mean(\n    posterior_samples$b_Intercept &gt;= rope_low &\n      posterior_samples$b_Intercept &lt;= rope_high\n  )\nrope_probability\n#&gt; [1] 0.00325\n\nVisualizziamo la distribuzione a posteriori di \\(p\\) insieme alla ROPE.\n\nggplot(posterior_samples, aes(x = b_Intercept)) +\n  geom_density(fill = \"gray\", alpha = 0.5) +\n  annotate(\n    geom = \"rect\", \n    xmin = rope_low, \n    xmax = rope_high, \n    ymin = 0, ymax = Inf, \n    fill = \"lightgray\", alpha = 0.2\n  ) +\n  geom_vline(xintercept = baseline, color = \"lightgray\") +\n  scale_x_continuous(labels = scales::percent) +\n  labs(x = \"Proportion used a condom at first sex\", y = \"Density\")\n\n\n\n\n\n\n\nIn conclusione, dato che solo lo 0.325% (meno dell’uno per cento) della distribuzione a posteriori di \\(p\\) si trova nella ROPE, possiamo concludere che ci sono evidenze credibili che la distribuzione a posteriori del parametro \\(p\\) (la proporzione di adolescenti, di età compresa tra 18 e 24 anni, che hanno fatto il “virginity pledge” e hanno usato il preservativo durante il primo rapporto sessuale) sia diversa dal valore di riferimento 0.5. Nel caso specifico, questa proporzione è più alta, indicando che la tendenza ad avere un rapporto protetto è maggiore rispetto al caso di casualità, per questa popolazione.\n\n66.2.8.1 Discussione sulla ROPE\nL’utilizzo della ROPE offre una prospettiva aggiuntiva e importante nell’interpretazione delle inferenze bayesiane. Invece di semplicemente determinare se un parametro è statisticamente significativo rispetto a un valore di riferimento, la ROPE permette di valutare se le differenze osservate siano praticamente rilevanti o significative in termini di impatto reale.\n\n\nSoglia di Rilevanza: L’impostazione di una ROPE consente di stabilire una soglia di rilevanza pratica. Se la maggior parte della distribuzione a posteriori cade al di fuori della ROPE, possiamo concludere che la differenza è non solo statistica ma anche pratica.\n\nInterpretazione Clinica: Nelle applicazioni pratiche, come in ambito medico o sociale, la ROPE aiuta a distinguere tra risultati statisticamente significativi ma clinicamente insignificanti e quelli che hanno un impatto rilevante.\n\nNel contesto dello studio sui “pledgers”, l’uso della ROPE fornisce una valutazione più completa della tendenza degli adolescenti a utilizzare il preservativo durante il primo rapporto sessuale, dimostrando che questa tendenza è non solo statisticamente diversa dal caso di casualità, ma anche significativa dal punto di vista pratico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#inferenza-sulla-differenza-tra-due-proporzioni",
    "href": "chapters/linear_models/11_one_proportion.html#inferenza-sulla-differenza-tra-due-proporzioni",
    "title": "66  Inferenza sulle proporzioni",
    "section": "\n66.3 Inferenza sulla Differenza tra Due Proporzioni",
    "text": "66.3 Inferenza sulla Differenza tra Due Proporzioni\nEstendiamo ora l’analisi precedente per confrontare le proporzioni di due gruppi, un compito per il quale non esiste una soluzione analitica semplice. Nello studio in esame, ci poniamo la domanda: Fino a che punto l’analisi statistica supporta l’ipotesi che i “pledgers” abbiano una minore probabilità rispetto ai “non-pledgers” di usare il preservativo durante il primo rapporto sessuale?\nPer testare questa ipotesi utilizzando brms, estendiamo il modello bayesiano includendo due gruppi: i pledgers (che hanno fatto il voto di astinenza) e i non-pledgers (che non lo hanno fatto). L’obiettivo è stimare la differenza tra le due proporzioni e valutare se questa sia credibilmente diversa da zero.\n\n66.3.1 Creazione del Dataset\nCostruiamo un tibble con i dati relativi ai due gruppi:\n\npledge_data &lt;- tibble(\n  group = c(\"pledgers\", \"nonpledgers\"),\n  n_yes = c(424, 5416),   # Numero di partecipanti che hanno usato il preservativo\n  n_total = c(777, 9072)  # Totale dei partecipanti per ciascun gruppo\n)\nprint(pledge_data)\n#&gt; # A tibble: 2 × 3\n#&gt;   group       n_yes n_total\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 pledgers      424     777\n#&gt; 2 nonpledgers  5416    9072\n\n\n66.3.2 Specifica del Modello Bayesiano\nUtilizziamo un modello binomiale con un predittore categorico per distinguere tra i due gruppi. Il modello può essere rappresentato come:\n\\[\np_i \\sim \\text{Binomiale}(n_i, \\theta_i)\n\\]\ndove \\(\\theta_i\\) è la proporzione di utilizzo del preservativo nel gruppo \\(i\\), e modelliamo la probabilità di successo come:\n\\[\n\\theta = \\beta_0 + \\beta_1 \\cdot \\text{group}\n\\]\ndove: - \\(\\beta_0\\) rappresenta la proporzione di non-pledgers che usano il preservativo. - \\(\\beta_1\\) rappresenta la differenza tra pledgers e non-pledgers (cioè la variazione della proporzione di utilizzo del preservativo associata all’appartenenza al gruppo dei pledgers).\nStimiamo il modello in brms utilizzando una distribuzione binomiale e un link identità:\n\nmodel_pledge_diff &lt;- brm(\n  n_yes | trials(n_total) ~ group,\n  data = pledge_data,\n  family = binomial(link = \"identity\"),\n  prior = c(\n    prior(beta(1, 1), class = \"Intercept\", lb = 0, ub = 1),  \n    # Prior per la proporzione nei non-pledgers\n    prior(normal(0, 1), class = \"b\")  # Prior per la differenza tra gruppi\n  ),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n#&gt; Running MCMC with 4 sequential chains...\n#&gt; \n#&gt; Chain 1 finished in 0.1 seconds.\n#&gt; Chain 2 finished in 0.0 seconds.\n#&gt; Chain 3 finished in 0.1 seconds.\n#&gt; Chain 4 finished in 0.0 seconds.\n#&gt; \n#&gt; All 4 chains finished successfully.\n#&gt; Mean chain execution time: 0.1 seconds.\n#&gt; Total execution time: 0.8 seconds.\n\n\n66.3.3 Analisi della Distribuzione A Posteriori\nEsaminiamo il sommario del modello per valutare la stima della differenza tra le proporzioni:\n\nsummary(model_pledge_diff)\n#&gt;  Family: binomial \n#&gt;   Links: mu = identity \n#&gt; Formula: n_yes | trials(n_total) ~ group \n#&gt;    Data: pledge_data (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept         0.60      0.01     0.59     0.61 1.00     4511     3068\n#&gt; grouppledgers    -0.05      0.02    -0.09    -0.01 1.01      889      793\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nPer interpretare meglio i risultati, estraiamo i campioni a posteriori per la differenza tra le due proporzioni:\n\npledge_diff_draws &lt;- model_pledge_diff |&gt; \n  spread_draws(b_Intercept, b_grouppledgers) |&gt; \n  mutate(\n    nonpledgers_prop = b_Intercept,  # Stima della proporzione nei non-pledgers\n    pledgers_prop = b_Intercept + b_grouppledgers,  # Stima della proporzione nei pledgers\n    diff = nonpledgers_prop - pledgers_prop  # Differenza tra le due proporzioni\n  )\n\nVisualizziamo la distribuzione a posteriori della differenza:\n\np3 &lt;- ggplot(pledge_diff_draws, aes(x = diff)) + \n  stat_halfeye(fill = \"gray\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  scale_x_continuous(labels = label_percent()) +\n  labs(x = \"Differenza nella proporzione di utilizzo del preservativo\", \n       y = \"Densità a posteriori\") \nprint(p3)\n\n\n\n\n\n\n\nCalcoliamo la probabilità che la differenza tra le proporzioni sia maggiore di zero:\n\ndiff_probability &lt;- mean(pledge_diff_draws$diff &gt; 0)\nprint(diff_probability)\n#&gt; [1] 0.997\n\n\n66.3.4 Interpretazione dei Risultati\nLa probabilità calcolata è 0.997; ciò significa che c’è una probabilità del 99.7% che la proporzione di non-pledgers che usano il preservativo sia maggiore rispetto a quella dei pledgers. Questo supporta con elevata credibilità l’ipotesi che i pledgers abbiano meno probabilità di utilizzare il preservativo durante il primo rapporto sessuale.\nPossiamo quindi concludere che la differenza tra le due proporzioni è credibilmente diversa da zero, con un’elevata probabilità a favore dell’ipotesi che i pledgers abbiano una minore propensione all’uso del preservativo rispetto ai non-pledgers. Questi risultati riproducono quelli riportati dalla letteratura precedente, come discusso da Brückner & Bearman (2005).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#riflessioni-conclusive",
    "href": "chapters/linear_models/11_one_proportion.html#riflessioni-conclusive",
    "title": "66  Inferenza sulle proporzioni",
    "section": "\n66.4 Riflessioni Conclusive",
    "text": "66.4 Riflessioni Conclusive\nL’inferenza su una proporzione tramite un approccio bayesiano offre una prospettiva più ricca e flessibile rispetto agli approcci frequentisti tradizionali. Utilizzando il pacchetto brms in R, abbiamo dimostrato come sia possibile modellare la proporzione di adolescenti che hanno usato il preservativo durante il primo rapporto sessuale, ottenendo risultati coerenti con quelli frequentisti. La capacità di ottenere una distribuzione completa della probabilità a posteriori consente non solo stime puntuali ma anche una comprensione approfondita dell’incertezza associata ai parametri stimati, rendendo l’approccio bayesiano uno strumento potente per l’analisi statistica avanzata.\nL’estensione dell’analisi alla differenza tra due proporzioni ha ulteriormente evidenziato i vantaggi dell’approccio bayesiano. Attraverso brms, abbiamo confrontato le proporzioni di utilizzo del preservativo tra i “pledgers” e i “non-pledgers”, ottenendo risultati coerenti e facilmente interpretabili. L’uso di distribuzioni a posteriori complete ci ha permesso di valutare in modo più dettagliato la plausibilità delle differenze osservate, offrendo una maggiore profondità di interpretazione rispetto agli intervalli di confidenza frequentisti.\n\n66.4.1 Vantaggi dell’Approccio Bayesiano\n\nDistribuzioni A Posteriori: L’approccio bayesiano fornisce una visione completa della distribuzione dei parametri stimati, permettendo di calcolare probabilità direttamente e quantificare l’incertezza in modo più intuitivo.\nFlessibilità Modellistica: brms consente di costruire modelli complessi, inclusi modelli gerarchici e multivariati, adattandosi alle specifiche esigenze dell’analisi senza perdere di generalità.\nPrior Informativi e Non Informativi: La possibilità di incorporare prior informativi o utilizzare prior non informativi permette di integrare conoscenze pregresse o lavorare in assenza di informazioni preliminari, aumentando la robustezza delle inferenze.\nIntegrazione con Stan: Sfruttando la potenza di Stan, brms offre algoritmi di campionamento efficienti e accurati per modelli complessi, garantendo risultati affidabili anche in situazioni di alta dimensionalità.\nVisualizzazione e Interpretazione: L’integrazione con pacchetti come tidyverse e ggplot2 facilita la visualizzazione e l’interpretazione dei risultati, rendendo più semplice comunicare le analisi bayesiane a un pubblico ampio e variegato.\n\n66.4.2 Applicazioni Pratiche\nI risultati ottenuti confermano che i “pledgers” hanno una minore propensione all’uso del preservativo rispetto ai “non-pledgers”, supportando con elevata credibilità l’ipotesi formulata. Questi risultati riproducono quelli riportati dalla letteratura precedente, rafforzando la validità dell’approccio bayesiano nelle applicazioni pratiche.\n\n66.4.3 Conclusione\nIn sintesi, l’approccio bayesiano, implementato attraverso il pacchetto brms, rappresenta uno strumento estremamente potente e flessibile per l’inferenza statistica. Offre una visione più dettagliata e comprensiva rispetto agli approcci frequentisti tradizionali, permettendo di ottenere risultati coerenti e facilmente interpretabili. La capacità di fornire una distribuzione completa della probabilità a posteriori rende l’approccio bayesiano ideale per affrontare problemi complessi e per sostenere decisioni basate su dati con maggiore fiducia e precisione.\nQuesto capitolo ha illustrato come l’inferenza bayesiana possa essere applicata efficacemente a problemi reali, fornendo una base solida per ulteriori sviluppi e applicazioni in ambiti diversi, dall’epidemiologia alla psicologia sociale, e oltre.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/11_one_proportion.html#informazioni-sullambiente-di-sviluppo",
    "title": "66  Inferenza sulle proporzioni",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6         StanHeaders_2.32.10  tidybayes_3.0.7     \n#&gt;  [4] broom_1.0.7          brms_2.22.0          Rcpp_1.0.14         \n#&gt;  [7] bayestestR_0.15.2    posterior_1.6.0.9000 cmdstanr_0.8.1      \n#&gt; [10] thematic_0.1.6       MetBrewer_0.2.0      ggokabeito_0.1.0    \n#&gt; [13] see_0.10.0           gridExtra_2.3        patchwork_1.3.0     \n#&gt; [16] bayesplot_1.11.1     psych_2.4.12         scales_1.3.0        \n#&gt; [19] markdown_1.13        knitr_1.49           lubridate_1.9.4     \n#&gt; [22] forcats_1.0.0        stringr_1.5.1        dplyr_1.1.4         \n#&gt; [25] purrr_1.0.4          readr_2.1.5          tidyr_1.3.1         \n#&gt; [28] tibble_3.2.1         ggplot2_3.5.1        tidyverse_2.0.0     \n#&gt; [31] rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.5          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] matrixStats_1.5.0    compiler_4.4.2       loo_2.8.0           \n#&gt; [10] vctrs_0.6.5          reshape2_1.4.4       pkgconfig_2.0.3     \n#&gt; [13] arrayhelpers_1.1-0   fastmap_1.2.0        backports_1.5.0     \n#&gt; [16] labeling_0.4.3       utf8_1.2.4           rmarkdown_2.29      \n#&gt; [19] tzdb_0.4.0           ps_1.8.1             xfun_0.50           \n#&gt; [22] jsonlite_1.8.9       parallel_4.4.2       R6_2.6.1            \n#&gt; [25] stringi_1.8.4        estimability_1.5.1   zoo_1.8-12          \n#&gt; [28] pacman_0.5.1         Matrix_1.7-2         splines_4.4.2       \n#&gt; [31] timechange_0.3.0     tidyselect_1.2.1     rstudioapi_0.17.1   \n#&gt; [34] abind_1.4-8          codetools_0.2-20     curl_6.2.0          \n#&gt; [37] processx_3.8.5       pkgbuild_1.4.6       plyr_1.8.9          \n#&gt; [40] lattice_0.22-6       withr_3.0.2          bridgesampling_1.1-2\n#&gt; [43] coda_0.19-4.1        evaluate_1.0.3       survival_3.8-3      \n#&gt; [46] RcppParallel_5.1.10  ggdist_3.3.2         pillar_1.10.1       \n#&gt; [49] tensorA_0.36.2.1     checkmate_2.3.2      stats4_4.4.2        \n#&gt; [52] insight_1.0.2        distributional_0.5.0 generics_0.1.3      \n#&gt; [55] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [58] munsell_0.5.1        xtable_1.8-4         glue_1.8.0          \n#&gt; [61] emmeans_1.10.7       tools_4.4.2          data.table_1.16.4   \n#&gt; [64] mvtnorm_1.3-3        grid_4.4.2           QuickJSR_1.5.1      \n#&gt; [67] colorspace_2.1-1     nlme_3.1-167         cli_3.6.4           \n#&gt; [70] svUnit_1.0.6         Brobdingnag_1.2-9    V8_6.0.1            \n#&gt; [73] gtable_0.3.6         digest_0.6.37        TH.data_1.1-3       \n#&gt; [76] htmlwidgets_1.6.4    farver_2.1.2         htmltools_0.5.8.1   \n#&gt; [79] lifecycle_1.0.4      MASS_7.3-64",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#bibliografia",
    "href": "chapters/linear_models/11_one_proportion.html#bibliografia",
    "title": "66  Inferenza sulle proporzioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBrückner, H., & Bearman, P. (2005). After the promise: The STD consequences of adolescent virginity pledges. Journal of Adolescent Health, 36(4), 271–278.\n\n\nKruschke, J. K., & Liddell, T. M. (2018). Bayesian data analysis for newcomers. Psychonomic Bulletin & Review, 25(1), 155–177.\n\n\nWagenmakers, E.-J., Lodewyckx, T., Kuriyal, H., & Grasman, R. (2010). Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method. Cognitive Psychology, 60(3), 158–189.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html",
    "href": "chapters/linear_models/12_two_proportions.html",
    "title": "67  Confronto tra due proporzioni indipendenti",
    "section": "",
    "text": "67.1 Introduzione\nSpesso, ci troviamo ad affrontare la necessità di confrontare due gruppi di dati. Mentre nel capitolo precedente abbiamo considerato il contronto tra le medie di due gruppi indipendenti, nel caso presente ci concentreremo sul confronto tra le proporzioni di due gruppi indipendenti. Per esempio, potrebbe interessarci sapere se la proporzione di un gruppo è maggiore o diversa rispetto a quella di un altro gruppo. Come in precedenza, per effettuare tale confronto, è fondamentale utilizzare un modello statistico, poiché le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#confronto-tra-le-proporzioni-di-due-gruppi-indipendenti",
    "href": "chapters/linear_models/12_two_proportions.html#confronto-tra-le-proporzioni-di-due-gruppi-indipendenti",
    "title": "67  Confronto tra due proporzioni indipendenti",
    "section": "\n67.2 Confronto tra le proporzioni di due gruppi indipendenti",
    "text": "67.2 Confronto tra le proporzioni di due gruppi indipendenti\nAnche nel caso delle proporzioni, il metodo tradizionale per confrontare statisticamente due o più gruppi consiste nell’utilizzare un test di ipotesi. Questo approccio prevede la definizione di un’ipotesi nulla, che tipicamente afferma l’assenza di differenze tra i gruppi, e l’uso di una statistica test per valutare se i dati osservati sono compatibili con tale ipotesi. Se la statistica test supera una soglia prestabilita, l’ipotesi nulla viene rifiutata, suggerendo che esiste una differenza significativa tra i gruppi.\nTuttavia, i test di ipotesi presentano alcune criticità. Innanzitutto, possono risultare complessi da applicare e interpretare, e i loro risultati sono spesso soggetti a errori di valutazione. La scelta delle specifiche del test statistico—quale test utilizzare, quale ipotesi nulla formulare, quale livello di significatività adottare—è spesso basata su convenzioni piuttosto che sulle peculiarità del problema analizzato o sulle decisioni da prendere (Johnson, 1999). Inoltre, i risultati dei test di ipotesi sono spesso indiretti e incompleti, e tendono a sovrastimare le evidenze contro l’ipotesi nulla (Goodman, 1999).\nUn approccio alternativo e più informativo è quello basato sulla stima anziché sul test dell’ipotesi nulla, fondato sulla probabilità bayesiana piuttosto che su quella frequentista. In questo caso, l’obiettivo non è semplicemente verificare se esiste una differenza tra i gruppi, ma stimare quanto siano effettivamente diversi. Questo metodo è intrinsecamente più informativo, poiché fornisce una stima diretta della differenza tra i gruppi, accompagnata da una misura dell’incertezza associata. Tale incertezza riflette sia la nostra limitata conoscenza dei parametri del modello (incertezza epistemica) sia la variabilità intrinseca del sistema (incertezza aleatoria).\nIn sintesi, mentre i test di ipotesi si concentrano sul rigetto o meno di un’ipotesi nulla, l’approccio basato sulla stima offre una visione più completa e utile, permettendo di quantificare direttamente la differenza tra i gruppi e di valutare l’incertezza associata a tale stima. Questo rende l’analisi più adatta a supportare decisioni informate e basate sui dati.\nPer affrontare tale problema possiamo usare un modello di regressione. In questo caso, anziché calcolare direttamente la differenza tra le proporzioni, si introduce una variabile indicatrice (o “dummy”) \\(D\\) nel modello di regressione, come segue:\n\\[\ny_i \\sim \\text{Bernoulli}(p_i), \\\\\n\\text{logit}(p_i) = \\alpha + \\gamma D_i.\n\\]\nLa variabile indicatrice \\(D\\) specifica l’appartenenza ai gruppi attraverso valori binari: 0 per il gruppo di riferimento e 1 per il gruppo di confronto, definita come:\n\\[\nD_i =\n\\begin{cases}\n0 & \\text{se l'osservazione } i \\text{ appartiene al gruppo 0,} \\\\\n1 & \\text{se l'osservazione } i \\text{ appartiene al gruppo 1.}\n\\end{cases}\n\\]\nEntrambi i metodi sono appropriati per studiare la differenza tra le proporzioni di due gruppi indipendenti. Tuttavia, il modello di regressione offre maggiore flessibilità e possibilità di estensione. Questa metodologia consente di includere ulteriori variabili esplicative, migliorando la comprensione dei fattori che influenzano l’esito di interesse. Tale flessibilità diventa particolarmente utile per esplorare come altre variabili incidano sulla differenza tra le proporzioni o per analizzare contemporaneamente più variabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "href": "chapters/linear_models/12_two_proportions.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "title": "67  Confronto tra due proporzioni indipendenti",
    "section": "\n67.3 Regressione bayesiana per due gruppi indipendenti",
    "text": "67.3 Regressione bayesiana per due gruppi indipendenti\nIn un approccio bayesiano, possiamo utilizzare un modello di regressione per confrontare le proporzioni di due gruppi indipendenti. Tuttavia, poiché stiamo lavorando con dati binari (ad esempio, successo/fallimento, sì/no), la distribuzione di riferimento non è più la normale (gaussiana), come nel caso delle medie, ma la distribuzione di Bernoulli. Questo significa che ogni osservazione \\(y_i\\) può assumere solo due valori: 0 (fallimento) o 1 (successo), e la probabilità di successo è indicata con \\(p_i\\).\nIl modello di regressione può essere espresso come:\n\\[\n\\begin{align*}\ny_i & \\sim \\text{Bernoulli}(p_i), \\\\\n\\text{logit}(p_i) & = \\alpha + \\gamma D_i.\n\\end{align*}\n\\]\n\n67.3.1 Cosa significa “logit”?\nIl logit è una trasformazione matematica che ci permette di lavorare con probabilità (che sono limitate tra 0 e 1) nel contesto di un modello lineare. In particolare, il logit di una probabilità \\(p_i\\) è definito come:\n\\[\n\\text{logit}(p_i) = \\log\\left(\\frac{p_i}{1 - p_i}\\right).\n\\]\nQuesta trasformazione ha due vantaggi principali:\n\nTrasforma l’intervallo [0, 1] in \\((-\\infty, +\\infty)\\): mentre una probabilità \\(p_i\\) è confinata tra 0 e 1, il logit può assumere qualsiasi valore reale. Questo è fondamentale perché i modelli lineari (come quello che stiamo usando) funzionano meglio quando la variabile dipendente non ha limiti.\nInterpretazione come “log-odds”: il termine \\(\\frac{p_i}{1 - p_i}\\) è chiamato odds (rapporto tra la probabilità di successo e quella di fallimento). Prendendo il logaritmo, otteniamo il log-odds, che è più facile da gestire in un modello lineare.\n\n67.3.2 Componenti del modello\nNel modello di regressione:\n\n\n\\(y_i \\sim \\text{Bernoulli}(p_i)\\): indica che ogni osservazione \\(y_i\\) segue una distribuzione di Bernoulli con probabilità di successo \\(p_i\\).\n\n\\(\\text{logit}(p_i) = \\alpha + \\gamma D_i\\): è l’equazione lineare che collega la probabilità di successo \\(p_i\\) alla variabile indicatrice \\(D_i\\), che rappresenta l’appartenenza al gruppo.\n\n\n67.3.2.1 Parametri del modello\n\n\\(\\alpha\\): rappresenta l’intercetta, ovvero il logit della probabilità di successo per il gruppo di riferimento (\\(D = 0\\)). Per ottenere la probabilità \\(p\\) corrispondente, possiamo applicare la funzione inversa del logit, chiamata funzione logistica: \\[\np = \\frac{e^\\alpha}{1 + e^\\alpha}.\n\\]\n\\(\\gamma\\): rappresenta la differenza nel logit delle probabilità tra il gruppo di confronto (\\(D = 1\\)) e il gruppo di riferimento (\\(D = 0\\)). In altre parole, \\(\\gamma\\) quantifica quanto il logit della probabilità di successo del gruppo 1 si discosta da quello del gruppo 0.\n\n67.3.3 Interpretazione per i due gruppi\n\nGruppo di riferimento (\\(D = 0\\)): \\[\n\\text{logit}(p_i) = \\alpha.\n\\] Qui, \\(\\alpha\\) rappresenta direttamente il logit della probabilità di successo per il gruppo 0.\nGruppo di confronto (\\(D = 1\\)): \\[\n\\text{logit}(p_i) = \\alpha + \\gamma.\n\\] In questo caso, \\(\\alpha + \\gamma\\) rappresenta il logit della probabilità di successo per il gruppo 1. La differenza tra i due gruppi è quindi catturata dal parametro \\(\\gamma\\).\n\n67.3.4 Inferenza bayesiana\nIn un contesto bayesiano, l’obiettivo è stimare la distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\gamma\\), che ci fornisce informazioni sulla probabilità di successo nei due gruppi e sulla differenza tra di essi. In particolare, ci interessa la distribuzione a posteriori di \\(\\gamma\\), che ci permette di valutare quanto sia plausibile che ci sia una differenza degna di nota tra i due gruppi e di quantificare l’incertezza associata a questa stima.\n\n67.3.5 Perché usare il logit?\nLa scelta di modellare il logit della probabilità, anziché la probabilità stessa, è dettata dalla necessità di adattare un modello lineare a dati binari. Mentre una probabilità è limitata tra 0 e 1, il logit può assumere qualsiasi valore reale, rendendolo compatibile con la struttura del modello lineare. Senza questa trasformazione, non potremmo utilizzare un modello lineare per analizzare dati binari, poiché le previsioni del modello potrebbero cadere al di fuori dell’intervallo [0, 1], il che non avrebbe senso per una probabilità.\nIn sintesi, il logit ci permette di “aprire” l’intervallo [0, 1] e di utilizzare un modello lineare per analizzare dati binari, mantenendo al contempo un’interpretazione chiara e intuitiva dei risultati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#approccio-frequentista",
    "href": "chapters/linear_models/12_two_proportions.html#approccio-frequentista",
    "title": "67  Confronto tra due proporzioni indipendenti",
    "section": "\n67.4 Approccio Frequentista",
    "text": "67.4 Approccio Frequentista\nL’inferenza frequentista si basa sulla costruzione della distribuzione campionaria di una statistica di interesse. Nel caso presente, la statistica di interesse è la differenza tra le proporzioni di due gruppi indipendenti. Supponiamo che i dati provengano da due popolazioni distribuite come Bernoulli:\n\\[\nY_1 \\sim \\text{Bernoulli}(p_1) \\quad \\text{e} \\quad Y_2 \\sim \\text{Bernoulli}(p_2),\n\\]\ndove \\(p_1\\) e \\(p_2\\) sono le proporzioni delle popolazioni.\n\n67.4.1 Inferenza sulla differenza delle proporzioni\nSiamo interessati a fare inferenza sulla differenza \\(p_1 - p_2\\). La statistica campionaria corrispondente è la differenza tra le proporzioni campionarie:\n\\[\n\\hat{p}_1 - \\hat{p}_2.\n\\]\nPer fare inferenza, dobbiamo determinare la distribuzione di \\(\\hat{p}_1 - \\hat{p}_2\\) nell’universo dei campioni.\n\n67.4.1.1 Valore atteso\nIl valore atteso della differenza tra le proporzioni campionarie è:\n\\[\nE(\\hat{p}_1 - \\hat{p}_2) = E(\\hat{p}_1) - E(\\hat{p}_2) = p_1 - p_2.\n\\]\n\n67.4.1.2 Varianza\nLa varianza della differenza tra le proporzioni campionarie dipende dall’indipendenza dei due campioni. Se \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) sono indipendenti, la covarianza tra di essi è zero, e la varianza è data da:\n\\[\n\\begin{align}\nV(\\hat{p}_1 - \\hat{p}_2) &= V(\\hat{p}_1) + V(\\hat{p}_2) - 2 \\text{Cov}(\\hat{p}_1, \\hat{p}_2) \\\\\n&= V(\\hat{p}_1) + V(\\hat{p}_2) \\quad \\text{(poiché $\\text{Cov}(\\hat{p}_1, \\hat{p}_2) = 0$)} \\\\\n&= \\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2},\n\\end{align}\n\\]\ndove:\n\n\n\\(p_1\\) e \\(p_2\\) sono le proporzioni delle popolazioni da cui sono estratti i campioni,\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\).\n\n67.4.2 Distribuzione della statistica\nPer due campioni indipendenti provenienti da popolazioni Bernoulli, la statistica \\(\\hat{p}_1 - \\hat{p}_2\\) segue una distribuzione normale approssimata:\n\\[\n\\hat{p}_1 - \\hat{p}_2 \\sim \\mathcal{N}\\left(p_1 - p_2, \\sqrt{\\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2}}\\right).\n\\]\nQuesto risultato è fondamentale per costruire test di ipotesi e intervalli di confidenza sulla differenza delle proporzioni. Questi argomenti verranno approfonditi in seguito. Per ora, limitiamoci a costruire la distribuzione campionaria della statistica \\(\\hat{p}_1 - \\hat{p}_2\\) e a calcolare delle probabilità.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo",
    "title": "67  Confronto tra due proporzioni indipendenti",
    "section": "\n67.5 Un esempio illustrativo",
    "text": "67.5 Un esempio illustrativo\nConsideriamo i dati di un recente studio di Banerjee et al. (2025) sui bambini provenienti da contesti socioeconomici svantaggiati. Lo studio si è concentrato sulle competenze matematiche di bambini che lavorano nei mercati di Kolkata e Delhi, in India, confrontandole con quelle di bambini che frequentano la scuola ma non hanno esperienza di lavoro. L’obiettivo era capire se le abilità matematiche apprese in contesti reali, come il mercato, possano trasferirsi in ambito scolastico e viceversa.\nI risultati principali dello studio sono i seguenti.\n\nBambini che lavorano nei mercati (n = 1.436): Quasi tutti questi bambini dimostravano di saper eseguire calcoli aritmetici complessi nel contesto lavorativo. Erano abili nel risolvere problemi matematici legati a situazioni concrete, come quelle che incontrano quotidianamente al mercato. Tuttavia, quando gli stessi problemi venivano presentati in formato astratto, tipico dei libri di scuola, le loro performance peggioravano notevolmente. Questo suggerisce che le loro abilità matematiche sono fortemente legate al contesto pratico in cui le hanno apprese.\nBambini che frequentano la scuola (n = 471): Al contrario, i bambini senza esperienza di lavoro nei mercati mostravano una buona capacità di risolvere problemi matematici semplici e astratti, ma solo l’1% di loro riusciva a risolvere correttamente un problema applicato al contesto del mercato, che invece era risolto da più di un terzo dei bambini lavoratori. Inoltre, i bambini scolarizzati utilizzavano metodi di calcolo scritto inefficienti, faticavano a combinare diverse operazioni e impiegavano troppo tempo per arrivare a una soluzione, rendendo le loro abilità poco utili in situazioni reali o in matematica avanzata.\n\nLo studio evidenzia un contrasto netto tra le abilità matematiche dei due gruppi:\n\ni bambini lavoratori eccellono in problemi concreti ma faticano con quelli astratti;\ni bambini scolari sono più abili con problemi astratti ma mostrano difficoltà nel trasferire queste competenze in contesti pratici.\n\nQuesto risultato è chiaro nei dati dello studio 3, illustrato dalla Figura 4 dell’articolo.\n\n\n\n\n\nFigura 67.1: Confronto tra bambini lavoratori e non lavoratori in problemi astratti orali e problemi matematici di mercato (studio 3). A sinistra, confronto delle prestazioni dei bambini lavoratori e non lavoratori sui medesimi problemi astratti di sottrazione e divisione. Al centro, confronto delle prestazioni dei bambini lavoratori e non lavoratori sul problema matematico di mercato dopo un solo tentativo. A destra, confronto delle prestazioni dei bambini lavoratori e non lavoratori sul problema matematico di mercato dopo aver ricevuto un suggerimento per suddividere il problema e utilizzare strategie di arrotondamento. I problemi astratti orali e i problemi matematici di mercato non erano stati resi equivalenti per livello di difficoltà. Le barre di errore mostrano gli intervalli di confidenza al 95% attorno alla media (media \\(\\pm\\) 1.96 \\(\\times\\) errore standard della media). I valori-p sono stati calcolati utilizzando test \\(t\\) di Student bilaterali senza correzioni per confronti multipli (figura tratta da Banerjee et al. (2025)).\n\n\nQuesti dati offrono un caso pratico per applicare modelli statistici che confrontano le proporzioni di successo tra due gruppi indipendenti. Nel caso presente, siamo interessati a stimare la differenza nella probabilità di risolvere correttamente un problema matematico tra i bambini lavoratori e quelli scolari. Utilizzando un approccio bayesiano, come descritto in precedenza, possiamo non solo quantificare questa differenza, ma anche valutare l’incertezza associata alla stima, fornendo così una base solida per interpretare i risultati e trarre conclusioni.\nCi focalizzeremo sui pannelli di sinistra e centrale della figura per analizzare i risultati.\nPer quanto riguarda i problemi astratti, le prestazioni sono state le seguenti:\n\nI bambini lavoratori hanno ottenuto 670 successi su 1488 prove, corrispondenti a una proporzione di successo \\(p = 0.45\\).\nI bambini scolarizzati hanno raggiunto 320 successi su 542 prove, con una proporzione di successo \\(p = 0.59\\).\n\nInvece, per i problemi matematici di mercato, i risultati sono stati:\n\nI bambini lavoratori hanno registrato 134 successi su 373 prove, con una proporzione di successo \\(p = 0.36\\).\nI bambini scolarizzati hanno ottenuto solo 3 successi su 271 prove, equivalente a una proporzione di successo \\(p = 0.01\\).\n\nQuesta distribuzione evidenzia notevoli differenze nelle prestazioni tra i due gruppi nei diversi tipi di problemi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#parallelo-tra-approccio-frequentista-e-bayesiano",
    "href": "chapters/linear_models/12_two_proportions.html#parallelo-tra-approccio-frequentista-e-bayesiano",
    "title": "67  Confronto tra due proporzioni indipendenti",
    "section": "\n67.6 Parallelo tra approccio frequentista e bayesiano",
    "text": "67.6 Parallelo tra approccio frequentista e bayesiano\nIl confronto tra le proporzioni di due gruppi indipendenti può essere affrontato sia con un approccio frequentista, basato sulla distribuzione campionaria, sia con un approccio bayesiano, basato sull’aggiornamento delle credenze a posteriori. Vediamo i due approcci in dettaglio.\n\n67.6.1 Approccio Frequentista\nL’inferenza frequentista per il confronto tra due proporzioni si basa sulla distribuzione campionaria della differenza tra le proporzioni dei due gruppi. Supponiamo che i dati provengano da due campioni indipendenti di dimensioni \\(n_1\\) e \\(n_2\\), con proporzioni di successo \\(p_1\\) e \\(p_2\\), rispettivamente.\nLa differenza tra le proporzioni campionarie, \\(\\hat{p}_1 - \\hat{p}_2\\), segue una distribuzione approssimativamente normale, soprattutto quando le dimensioni dei campioni sono sufficientemente grandi (in genere, quando \\(n_1 p_1\\), \\(n_1 (1 - p_1)\\), \\(n_2 p_2\\) e \\(n_2 (1 - p_2)\\) sono tutti maggiori di 5). Questa approssimazione è basata sul Teorema del Limite Centrale, che garantisce che la distribuzione della differenza tra le proporzioni campionarie tende a una distribuzione normale al crescere della dimensione del campione.\n\n67.6.1.1 Distribuzione della differenza tra proporzioni\nLa differenza \\(\\hat{p}_1 - \\hat{p}_2\\) ha una distribuzione normale con:\n\nValore atteso: \\[\nE(\\hat{p}_1 - \\hat{p}_2) = p_1 - p_2.\n\\] Questo significa che, in media, la differenza osservata tra le proporzioni campionarie riflette la differenza vera tra le proporzioni delle popolazioni.\nVarianza: \\[\nV(\\hat{p}_1 - \\hat{p}_2) = \\frac{p_1 (1 - p_1)}{n_1} + \\frac{p_2 (1 - p_2)}{n_2}.\n\\] La varianza della differenza dipende dalle proporzioni delle popolazioni e dalle dimensioni dei campioni. Maggiore è la dimensione del campione, minore è la varianza e quindi più precisa è la stima della differenza.\n\n67.6.1.2 Stima della varianza\nPoiché le proporzioni delle popolazioni \\(p_1\\) e \\(p_2\\) sono generalmente sconosciute, utilizziamo le proporzioni campionarie \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) per stimare la varianza:\n\\[\nV(\\hat{p}_1 - \\hat{p}_2) \\approx \\frac{\\hat{p}_1 (1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2 (1 - \\hat{p}_2)}{n_2}.\n\\]\n\n67.6.1.3 Intervallo di confidenza\nUn intervallo di confidenza per la differenza tra le proporzioni \\(p_1 - p_2\\) può essere costruito utilizzando la distribuzione normale approssimata. L’intervallo di confidenza al 95% è dato da:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z \\cdot \\sqrt{\\frac{\\hat{p}_1 (1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2 (1 - \\hat{p}_2)}{n_2}},\n\\]\ndove \\(z\\) è il valore critico della distribuzione normale standard (ad esempio, 1.96 per un intervallo di confidenza al 95%).\n\n67.6.1.4 Test di ipotesi\nPer testare l’ipotesi nulla \\(H_0: p_1 = p_2\\) (cioè che non c’è differenza tra le proporzioni dei due gruppi), possiamo utilizzare una statistica test basata sulla differenza standardizzata tra le proporzioni campionarie:\n\\[\nZ = \\frac{\\hat{p}_1 - \\hat{p}_2}{\\sqrt{\\hat{p} (1 - \\hat{p}) \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)}},\n\\]\ndove \\(\\hat{p}\\) è la proporzione pooled, calcolata come:\n\\[\n\\hat{p} = \\frac{n_1 \\hat{p}_1 + n_2 \\hat{p}_2}{n_1 + n_2}.\n\\]\nLa statistica \\(Z\\) segue una distribuzione normale standard sotto l’ipotesi nulla. Se il valore assoluto di \\(Z\\) supera il valore critico (ad esempio, 1.96 per un livello di significatività del 5%), rifiutiamo l’ipotesi nulla e concludiamo che c’è una differenza significativa tra le proporzioni dei due gruppi.\n\n67.6.2 Vantaggi e limiti dell’approccio frequentista\n\n\nVantaggi:\n\nÈ un metodo ben consolidato e ampiamente utilizzato.\nFornisce risultati chiari e immediati, come intervalli di confidenza e p-value.\nÈ relativamente semplice da applicare, soprattutto con software statistici.\n\n\n\nLimiti:\n\nL’approssimazione normale funziona bene solo con campioni sufficientemente grandi. Per campioni piccoli o proporzioni vicine a 0 o 1, potrebbero essere necessari metodi alternativi.\nL’interpretazione dei p-value può essere fuorviante, soprattutto se non si considera l’effetto della dimensione del campione.\nNon fornisce una stima diretta della probabilità che l’ipotesi nulla sia vera, ma solo una misura di quanto i dati siano compatibili con essa.\n\n\n\nIn sintesi, l’approccio frequentista offre un metodo robusto e intuitivo per confrontare due proporzioni, ma richiede attenzione alle condizioni di applicabilità e alla corretta interpretazione dei risultati.\n\n67.6.3 Esempio Pratico\nPer applicare l’approccio frequentista ai dati forniti, possiamo utilizzare un test di proporzioni per confrontare le proporzioni di successo tra i bambini lavoratori e i bambini scolarizzati, sia per i problemi astratti che per i problemi matematici di mercato. L’approccio frequentista si basa sull’uso di dati osservati per fare inferenze statistiche, e in questo caso, utilizzeremo un test z per proporzioni.\n\n67.6.4 1. Confronto per i problemi astratti\n\nIpotesi:\n\n\n\\(H_0\\): Non c’è differenza tra le proporzioni di successo dei bambini lavoratori e dei bambini scolarizzati (\\(p_{\\text{lavoratori}} = p_{\\text{scolarizzati}}\\)).\n\n\\(H_1\\): C’è una differenza tra le proporzioni di successo (\\(p_{\\text{lavoratori}} \\neq p_{\\text{scolarizzati}}\\)).\n\nDati:\n\nBambini lavoratori: 670 successi su 1488 prove, \\(p_{\\text{lavoratori}} = 0.45\\).\nBambini scolarizzati: 320 successi su 542 prove, \\(p_{\\text{scolarizzati}} = 0.59\\).\n\nCalcolo della statistica z:\nLa statistica z per il confronto di due proporzioni è data da:\n\\[\nz = \\frac{p_1 - p_2}{\\sqrt{p(1 - p) \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)}}\n\\]\ndove \\(p\\) è la proporzione complessiva di successi:\n\\[\np = \\frac{X_1 + X_2}{n_1 + n_2} = \\frac{670 + 320}{1488 + 542} = \\frac{990}{2030} \\approx 0.487\n\\]\nOra calcoliamo la statistica z:\n\\[\nz = \\frac{0.45 - 0.59}{\\sqrt{0.487 \\times (1 - 0.487) \\times \\left( \\frac{1}{1488} + \\frac{1}{542} \\right)}}\n\\]\n\\[\nz = \\frac{-0.14}{\\sqrt{0.487 \\times 0.513 \\times \\left( \\frac{1}{1488} + \\frac{1}{542} \\right)}}\n\\]\n\\[\nz = \\frac{-0.14}{\\sqrt{0.487 \\times 0.513 \\times (0.000672 + 0.001845)}}\n\\]\n\\[\nz = \\frac{-0.14}{\\sqrt{0.487 \\times 0.513 \\times 0.002517}}\n\\]\n\\[\nz = \\frac{-0.14}{\\sqrt{0.000629}}\n\\]\n\\[\nz = \\frac{-0.14}{0.0251} \\approx -5.58\n\\]\nConclusione: Il valore di z è -5.58, che corrisponde a un p-value molto piccolo (inferiore a 0.0001). Pertanto, rifiutiamo l’ipotesi nulla \\(H_0\\) e concludiamo che c’è una differenza statisticamente significativa tra le proporzioni di successo dei bambini lavoratori e dei bambini scolarizzati nei problemi astratti.\n\n67.6.5 2. Confronto per i problemi matematici di mercato\n\nIpotesi:\n\n\n\\(H_0\\): Non c’è differenza tra le proporzioni di successo dei bambini lavoratori e dei bambini scolarizzati (\\(p_{\\text{lavoratori}} = p_{\\text{scolarizzati}}\\)).\n\n\\(H_1\\): C’è una differenza tra le proporzioni di successo (\\(p_{\\text{lavoratori}} \\neq p_{\\text{scolarizzati}}\\)).\n\nDati:\n\nBambini lavoratori: 134 successi su 373 prove, \\(p_{\\text{lavoratori}} = 0.36\\).\nBambini scolarizzati: 3 successi su 271 prove, \\(p_{\\text{scolarizzati}} = 0.01\\).\n\nCalcolo della statistica z:\nLa proporzione complessiva di successi è:\n\\[\np = \\frac{134 + 3}{373 + 271} = \\frac{137}{644} \\approx 0.213\n\\]\nOra calcoliamo la statistica z:\n\\[\nz = \\frac{0.36 - 0.01}{\\sqrt{0.213 \\times (1 - 0.213) \\times \\left( \\frac{1}{373} + \\frac{1}{271} \\right)}}\n\\]\n\\[\nz = \\frac{0.35}{\\sqrt{0.213 \\times 0.787 \\times \\left( \\frac{1}{373} + \\frac{1}{271} \\right)}}\n\\]\n\\[\nz = \\frac{0.35}{\\sqrt{0.213 \\times 0.787 \\times (0.002681 + 0.00369)}}\n\\]\n\\[\nz = \\frac{0.35}{\\sqrt{0.213 \\times 0.787 \\times 0.006371}}\n\\]\n\\[\nz = \\frac{0.35}{\\sqrt{0.001067}}\n\\]\n\\[\nz = \\frac{0.35}{0.0327} \\approx 10.70\n\\]\nConclusione: Il valore di z è 10.70, che corrisponde a un p-value molto piccolo (inferiore a 0.0001). Pertanto, rifiutiamo l’ipotesi nulla \\(H_0\\) e concludiamo che c’è una differenza statisticamente significativa tra le proporzioni di successo dei bambini lavoratori e dei bambini scolarizzati nei problemi matematici di mercato.\n\n67.6.6 Riassunto:\n\n\nProblemi astratti: C’è una differenza significativa tra le proporzioni di successo dei bambini lavoratori e dei bambini scolarizzati (z = -5.58, p &lt; 0.0001).\n\nProblemi matematici di mercato: C’è una differenza significativa tra le proporzioni di successo dei bambini lavoratori e dei bambini scolarizzati (z = 10.70, p &lt; 0.0001).\n\nIn entrambi i casi, i bambini scolarizzati hanno una proporzione di successo significativamente diversa rispetto ai bambini lavoratori.\n\n67.6.7 Svolgimento con R\nDi seguito mostriamo due modalità per replicare i calcoli in R: (1) passo passo usando le formule manuali, (2) usando la funzione prop.test() di R. Verranno illustrate entrambe le analisi: quella per i problemi astratti e quella per i problemi matematici di mercato.\n\n67.6.7.1 Problemi astratti\nDati\n\nBambini lavoratori (gruppo 1): 670 successi su 1488 prove.\nBambini scolarizzati (gruppo 2): 320 successi su 542 prove.\n\n\n# Dati\nX1 &lt;- 670\nn1 &lt;- 1488\nX2 &lt;- 320\nn2 &lt;- 542\n\n# Proporzioni campionarie\np1 &lt;- X1 / n1\np2 &lt;- X2 / n2\n\n# Proporzione pooled (combinata)\np_pool &lt;- (X1 + X2) / (n1 + n2)\n\n# Differenza fra le proporzioni\ndiff_p &lt;- p1 - p2\n\n# Calcolo della varianza della differenza (usando la formula per due proporzioni)\nvar_diff &lt;- p_pool * (1 - p_pool) * (1/n1 + 1/n2)\n\n# Deviazione standard della differenza\nsd_diff &lt;- sqrt(var_diff)\n\n# Statistica z\nz_value &lt;- diff_p / sd_diff\n\n# p-value (test a due code)\np_value &lt;- 2 * pnorm(abs(z_value), lower.tail = FALSE)\n\n# Visualizzazione risultati\nz_value\n#&gt; [1] -5.588\np_value\n#&gt; [1] 2.295e-08\n\nSpiegazione passaggi chiave:\n\nCalcoliamo le proporzioni empiriche: \\(p_1 = X_1 / n_1\\), \\(p_2 = X_2 / n_2\\).\nCalcoliamo la proporzione “pooled”: \\(p_{\\mathrm{pool}} = \\frac{X_1 + X_2}{n_1 + n_2}\\).\nCalcoliamo la differenza delle proporzioni: \\(\\Delta p = p_1 - p_2\\).\nCalcoliamo la varianza (approssimata) della differenza, usando \\(p_{\\mathrm{pool}}\\) per lo stimatore comune.\nOtteniamo la statistica \\(z\\) come \\(\\frac{\\Delta p}{\\text{deviazione standard}}\\).\nIl p-value (a due code) si ottiene come \\(2 \\times P(Z &gt; |z|)\\), con pnorm che fornisce la distribuzione cumulativa della normale.\n\n67.6.7.2 Analisi con funzione prop.test()\n\nPer ottenere direttamente il test di confronto di due proporzioni, possiamo usare la funzione prop.test di R. Attenzione che, di default, prop.test effettua una correzione per la continuità (Yates), che in questo contesto di solito disattiviamo per confrontare i risultati con i calcoli manuali (impostando correct = FALSE).\n\n# Confronto due proporzioni senza correzione per la continuità\ntest_astratti &lt;- prop.test(\n  x = c(X1, X2),\n  n = c(n1, n2),\n  alternative = \"two.sided\",\n  correct = FALSE\n)\n\ntest_astratti\n#&gt; \n#&gt;  2-sample test for equality of proportions without continuity\n#&gt;  correction\n#&gt; \n#&gt; data:  c(X1, X2) out of c(n1, n2)\n#&gt; X-squared = 31, df = 1, p-value = 2e-08\n#&gt; alternative hypothesis: two.sided\n#&gt; 95 percent confidence interval:\n#&gt;  -0.18864 -0.09163\n#&gt; sample estimates:\n#&gt; prop 1 prop 2 \n#&gt; 0.4503 0.5904\n\nIl risultato fornirà:\n\nStatistica di test (approx. z).\np-value.\nStima delle due proporzioni e dell’intervallo di confidenza della loro differenza.\n\n67.6.7.3 Problemi matematici di mercato\n\n# Dati\nX1_m &lt;- 134\nn1_m &lt;- 373\nX2_m &lt;- 3\nn2_m &lt;- 271\n\n# Proporzioni campionarie\np1_m &lt;- X1_m / n1_m\np2_m &lt;- X2_m / n2_m\n\n# Proporzione pooled\np_pool_m &lt;- (X1_m + X2_m) / (n1_m + n2_m)\n\n# Differenza di proporzioni\ndiff_p_m &lt;- p1_m - p2_m\n\n# Varianza della differenza (usando la proporzione pooled)\nvar_diff_m &lt;- p_pool_m * (1 - p_pool_m) * (1/n1_m + 1/n2_m)\n\n# Deviazione standard\nsd_diff_m &lt;- sqrt(var_diff_m)\n\n# Statistica z\nz_value_m &lt;- diff_p_m / sd_diff_m\n\n# p-value (test a due code)\np_value_m &lt;- 2 * pnorm(abs(z_value_m), lower.tail = FALSE)\n\n# Visualizzazione risultati\nz_value_m\n#&gt; [1] 10.66\np_value_m\n#&gt; [1] 1.581e-26\n\nAnalogamente a quanto fatto per i problemi astratti:\n\n# Confronto due proporzioni\ntest_mercato &lt;- prop.test(\n  x = c(X1_m, X2_m),\n  n = c(n1_m, n2_m),\n  alternative = \"two.sided\",\n  correct = FALSE\n)\n\ntest_mercato\n#&gt; \n#&gt;  2-sample test for equality of proportions without continuity\n#&gt;  correction\n#&gt; \n#&gt; data:  c(X1_m, X2_m) out of c(n1_m, n2_m)\n#&gt; X-squared = 114, df = 1, p-value &lt;2e-16\n#&gt; alternative hypothesis: two.sided\n#&gt; 95 percent confidence interval:\n#&gt;  0.2979 0.3984\n#&gt; sample estimates:\n#&gt;  prop 1  prop 2 \n#&gt; 0.35925 0.01107\n\n\n67.6.7.3.1 Interpretazione dei risultati\n\n\nProblemi astratti\n\nStatistica z (calcolo manuale): circa -5.58\n\np-value: molto piccolo (&lt;&lt; 0.001)\n\nConclusione: rifiutiamo \\(H_0\\) e concludiamo che le proporzioni di successo dei bambini lavoratori e scolarizzati sono significativamente diverse.\n\n\n\nProblemi matematici di mercato\n\nStatistica z (calcolo manuale): circa 10.70\n\np-value: estremamente piccolo (&lt;&lt; 0.001)\n\nConclusione: rifiutiamo \\(H_0\\) e concludiamo che anche in questo caso le proporzioni di successo dei due gruppi sono significativamente diverse.\n\n\n\nNota: I valori di z in prop.test() potrebbero risultare leggermente diversi a causa di eventuali arrotondamenti o correzioni implementate nella funzione. Assicurandoci di disattivare la correzione per la continuità (correct = FALSE), dovremmo comunque ottenere risultati molto simili a quelli dei calcoli manuali.\n\n67.6.8 Approccio Bayesiano\nL’approccio bayesiano utilizza un modello di regressione con una variabile indicatrice (dummy) per distinguere i due gruppi.\nConsideriamo i problemi astratti. Utilizziamo il pacchetto brms per stimare il modello, con distribuzioni a priori debolmente informative:\n\nX1 &lt;- 670\nn1 &lt;- 1488\nX2 &lt;- 320\nn2 &lt;- 542\n\ndat_a &lt;- data.frame(\n  count = c(X1, X2),\n  tot = c(n1, n2),\n  group = c(\"working\", \"non-working\")\n)\ndat_a\n\n\nfit_a &lt;- brm(count | trials(tot) ~ group, data = dat_a, family = binomial())\n\n\nsummary(fit_a)\n#&gt;  Family: binomial \n#&gt;   Links: mu = logit \n#&gt; Formula: count | trials(tot) ~ group \n#&gt;    Data: dat_a (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept        0.37      0.09     0.19     0.54 1.00     1561     2015\n#&gt; groupworking    -0.57      0.10    -0.77    -0.36 1.00     1873     1865\n#&gt; \n#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n# Extract posterior draws of the Intercept and groupworking coefficients\npost &lt;- posterior_samples(fit_a) \n# or posterior_draws(fit_a) in newer versions\n\n# Probability for reference group = logistic(Intercept)\npost$p_ref &lt;- plogis(post$b_Intercept)\n\n# Probability for working group = logistic(Intercept + groupworking)\npost$p_work &lt;- plogis(post$b_Intercept + post$b_groupworking)\n\n# Now summarize\nsummary_ref  &lt;- quantile(post$p_ref,  probs = c(0.025, 0.5, 0.975))\nsummary_work &lt;- quantile(post$p_work, probs = c(0.025, 0.5, 0.975))\n\nsummary_ref\n#&gt;   2.5%    50%  97.5% \n#&gt; 0.5471 0.5907 0.6321\nsummary_work\n#&gt;   2.5%    50%  97.5% \n#&gt; 0.4243 0.4504 0.4762\n\n\n# 1. Extract samples\npost &lt;- as_draws_df(fit_a) \n\n# 2. Summaries on logit \n# b_groupworking\nb_groupworking_CI &lt;- quantile(post$b_groupworking, probs = c(0.025, 0.5, 0.975))\nprint(\"b_groupworking (log-odds) [2.5%, 50%, 97.5%]:\")\n#&gt; [1] \"b_groupworking (log-odds) [2.5%, 50%, 97.5%]:\"\nb_groupworking_CI\n#&gt;    2.5%     50%   97.5% \n#&gt; -0.7707 -0.5670 -0.3612\n\n# 3. Summaries on OR\npost$OR_groupworking &lt;- exp(post$b_groupworking)\nOR_groupworking_CI &lt;- quantile(post$OR_groupworking, probs = c(0.025, 0.5, 0.975))\nprint(\"Odds Ratio for 'working' vs. reference [2.5%, 50%, 97.5%]:\")\n#&gt; [1] \"Odds Ratio for 'working' vs. reference [2.5%, 50%, 97.5%]:\"\nOR_groupworking_CI\n#&gt;   2.5%    50%  97.5% \n#&gt; 0.4627 0.5672 0.6968\n\n# 4. Summaries on prob. scale\n\n# Probability reference group\npost$p_ref  &lt;- plogis(post$b_Intercept)\n\n# Probability working group\npost$p_work &lt;- plogis(post$b_Intercept + post$b_groupworking)\n\n# Difference on probability scale\npost$diff_p_work_ref &lt;- post$p_work - post$p_ref\n\nsummary_ref  &lt;- quantile(post$p_ref,  probs = c(0.025, 0.5, 0.975))\nsummary_work &lt;- quantile(post$p_work, probs = c(0.025, 0.5, 0.975))\ndiff_p_CI    &lt;- quantile(post$diff_p_work_ref, probs = c(0.025, 0.5, 0.975))\n\n\ncat(\"\\nReference group probability [2.5%, 50%, 97.5%]:\\n\")\n#&gt; \n#&gt; Reference group probability [2.5%, 50%, 97.5%]:\nprint(summary_ref)\n#&gt;   2.5%    50%  97.5% \n#&gt; 0.5471 0.5907 0.6321\n\n\ncat(\"\\nWorking group probability [2.5%, 50%, 97.5%]:\\n\")\n#&gt; \n#&gt; Working group probability [2.5%, 50%, 97.5%]:\nprint(summary_work)\n#&gt;   2.5%    50%  97.5% \n#&gt; 0.4243 0.4504 0.4762\n\n\ncat(\"\\nDifference in probability (Working - Reference) [2.5%, 50%, 97.5%]:\\n\")\n#&gt; \n#&gt; Difference in probability (Working - Reference) [2.5%, 50%, 97.5%]:\nprint(diff_p_CI)\n#&gt;     2.5%      50%    97.5% \n#&gt; -0.18948 -0.14056 -0.08989\n\nSi noti come, usando prior debolmente informativi, i risultati ottenuti con i due approcci (frequentista e bayesiano) sono praticamente equivalenti.\nCome abbiamo osservato nel caso del confronto tra medie, l’approccio bayesiano è più utile perché:\n\nNon si basa su un’ipotesi nulla idealizzata che sappiamo non essere vera.\nStima direttamente la nostra incertezza rispetto alla differenza tra le proporzioni, fornendo una risposta concreta e interpretabile in termini di probabilità.\nPermette di integrare le evidenze dei dati con la conoscenza preesistente, per ottenere inferenze più realistiche e informate.\n\n67.6.9 Intervallo di credibilità\nPer ottenere l’intervallo di credibilità (Highest Density Interval, HDI) sulla scala delle probabilità (e non su quella logit), è necessario trasformare manualmente i draw a livello di probabilità e poi calcolare l’HDI su quei valori trasformati. In altre parole:\n\n\nEstraiamo i draw posteriori di b_Intercept e b_groupworking.\n\n\nTrasformiamo i valori con la funzione logit-inversa (\\(\\operatorname{logistic}(x) = 1/(1+e^{-x})\\)) per ottenere le probabilità.\n\n\nSe ci concentriamo sul solo effetto sulla scala della probabilità (e.g. differenza fra i due gruppi), calcoliamo la differenza tra la probabilità del gruppo “working” e quella del gruppo “reference” per ciascun draw.\n\n\nApplichiamo hdi() su queste grandezze trasformate.\n\nDi seguito è fornito il codice R con il workflow completo.\n\nEstrazione draw posteriori.\n\n\npost &lt;- as_draws_df(fit_a)\n\n\n\nCalcolo delle probabilità per ciascun draw. La variabile ‘group’ abbia due livelli:\n\n“working” (effetto =&gt; b_groupworking)\n“non-working” (riferimento =&gt; b_Intercept)\n\n\n\n\npost &lt;- post %&gt;%\n  dplyr::mutate(\n    p_ref      = plogis(b_Intercept),                       # probabilità (referenza)\n    p_working  = plogis(b_Intercept + b_groupworking),      # prob. gruppo working\n    diff_working_ref = p_working - p_ref                    # differenza\n  )\n\n\nCalcolo dell’HDI sull’effetto (o sulle probabilità).\n\n\nHDI per la probabilità del gruppo “working”.\n\n\n\nhdi_working_prob &lt;- hdi(post$p_working, ci = 0.95)\nhdi_working_prob\n#&gt; 95% HDI: [0.42, 0.48]\n\n\nHDI per la probabilità del gruppo “non-working” (riferimento).\n\n\nhdi_ref_prob &lt;- hdi(post$p_ref, ci = 0.95)\nhdi_ref_prob\n#&gt; 95% HDI: [0.55, 0.64]\n\n\nHDI della differenza fra le due probabilità.\n\n\nhdi_diff &lt;- hdi(post$diff_working_ref, ci = 0.89)\nhdi_diff\n#&gt; 89% HDI: [-0.18, -0.10]\n\nInterpretazione\n\n\nhdi_working_prob fornisce l’HDI al 95% (o al livello che specifichi) della probabilità di “successo” del gruppo “working”.\n\n\nhdi_ref_prob fa lo stesso per il gruppo di riferimento.\n\n\nhdi_diff restituisce l’HDI della differenza in probabilità tra “working” e “reference” (\\(p_{\\text{working}} - p_{\\text{reference}}\\)).\n\nIn questo modo ottieniamo l’intervallo di credibilità (HDI) sulla scala delle probabilità.\n\n67.6.10 Distribuzione Predittiva a Posteriori\nEffettuiamo un controllo grafico per confrontare i dati osservati con quelli predetti dal modello:\n\npp_check(fit_a)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#riflessioni-conclusive",
    "href": "chapters/linear_models/12_two_proportions.html#riflessioni-conclusive",
    "title": "67  Confronto tra due proporzioni indipendenti",
    "section": "\n67.7 Riflessioni Conclusive",
    "text": "67.7 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato il confronto tra due proporzioni (per esempio, la proporzione di successi in due gruppi indipendenti) adottando sia l’approccio frequentista sia quello bayesiano. L’obiettivo principale era valutare se la proporzione di successi in un gruppo differisse da quella osservata nell’altro gruppo, e con quale grado di incertezza.\n\n67.7.1 Approccio Frequentista\n\n\nStatistica di test e p-value: Nella procedura classica frequentista (test per due proporzioni), si calcola una statistica di test (ad esempio, un test z) e il relativo p-value, ossia la probabilità di osservare un risultato così estremo (o più) assumendo che le due proporzioni reali siano uguali (ipotesi nulla).\n\n\nIntervallo di confidenza: È possibile costruire un intervallo di confidenza (IC) per la differenza tra le due proporzioni. L’interpretazione frequentista di tale IC, però, si basa su un’ipotetica ripetizione di campionamenti ed è focalizzata sull’eventuale rifiuto o meno dell’ipotesi che la differenza sia zero.\n\n\nLimiti interpretativi: L’approccio frequentista si fonda sul concetto di ipotesi nulla “nessuna differenza” e non fornisce una probabilità diretta di quanto la differenza vera sia maggiore o minore di un certo valore, limitandosi a indicare se i dati sono inusuali qualora la differenza fosse zero.\n\n67.7.2 Approccio Bayesiano\n\n\nDistribuzione a posteriori: Grazie alla regola di Bayes, combiniamo informazioni a priori (sul probabile valore delle proporzioni) con i dati osservati, per ottenere una distribuzione a posteriori della differenza tra le due proporzioni. Questa distribuzione descrive i valori plausibili della differenza, insieme alle relative credibilità (probabilità).\n\n\nCredible Interval o Highest Density Interval (HDI): Al posto di un intervallo di confidenza, l’approccio bayesiano fornisce un intervallo di credibilità. Ad esempio, un 95% HDI indica i valori della differenza tra le proporzioni che cumulativamente contengono il 95% della probabilità a posteriori. È un costrutto immediatamente interpretabile: “Abbiamo una probabilità del 95% che la differenza vera cada all’interno di questo intervallo”.\n\n\nFlessibilità e interpretazione diretta: L’approccio bayesiano permette di rispondere in modo più naturale a domande come: “Qual è la probabilità che la differenza fra le due proporzioni sia maggiore di 0?” oppure “Qual è la probabilità che la proporzione di un gruppo superi quella dell’altro di almeno una certa soglia rilevante?”.\n\n67.7.3 Confronto tra i due approcci\n\n\nInterpretazione dei risultati: Il p-value frequentista ci dice quanto il dato sia “improbabile” sotto l’ipotesi di uguaglianza delle proporzioni; il Bayesianesimo risponde direttamente a quanto è plausibile ogni possibile valore di differenza.\n\n\nCentralità dell’ipotesi nulla: Nel frequentismo, l’ipotesi nulla (differenza = 0) è centrale. Nel modello bayesiano, è invece possibile assegnare direttamente probabilità alla differenza e alla sua distanza da zero, evitando un focus eccessivo sull’uguaglianza perfetta delle due proporzioni.\n\n\nRuolo dei priors: L’uso di priors (non informativi o informativi) può influire sulle stime bayesiane quando i dati sono scarsi, rendendo evidente la necessità di scelte trasparenti e ben motivate. Tuttavia, con campioni ampi, l’influenza dei priors tende a ridursi e la stima a posteriori è dominata dai dati.\n\n\nCompletezza dell’inferenza: L’approccio bayesiano consente di integrare nuove informazioni e di aggiornare la distribuzione a posteriori man mano che arrivano dati aggiuntivi. Al contrario, l’approccio frequentista non fornisce un meccanismo diretto di “aggiornamento” delle stime alla luce di nuovi dati.\n\n67.7.4 Conclusioni Finali\n\n\nApproccio frequentista: Si tratta di una metodologia consolidata e standard nella ricerca; fornisce risultati in termini di p-value e IC, ma l’interpretazione del p-value e dell’IC resta legata a procedure di campionamento ipotetico.\n\n\nApproccio bayesiano: Offre una maniera più intuitiva di quantificare l’incertezza, assegnando probabilità dirette ai possibili valori di differenza fra le due proporzioni. Consente di formulare domande più specifiche (es. la probabilità che la differenza superi un valore definito) e di integrare in modo naturale informazioni a priori.\n\n\nScelta o integrazione: Nella pratica della ricerca, l’approccio frequentista rimane diffuso. Tuttavia, l’inferenza bayesiana fornisce un quadro interpretativo più ricco e flessibile. Utilizzare entrambi i metodi, quando appropriato, può potenziare l’analisi e la comprensione dei dati, permettendo di trarre conclusioni più robuste e trasparenti.\n\nNel complesso, il confronto fra due proporzioni mostra chiaramente che la differenza tra l’ottica frequentista e quella bayesiana non è solo tecnica, ma anche concettuale: si tratta di due modi diversi di gestire l’incertezza e le ipotesi in gioco. Conoscere entrambi i paradigmi e i relativi vantaggi può aiutare a scegliere l’approccio più adeguato alle finalità dello studio e alle domande di ricerca poste.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/12_two_proportions.html#informazioni-sullambiente-di-sviluppo",
    "title": "67  Confronto tra due proporzioni indipendenti",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.0.2        bayestestR_0.15.2    posterior_1.6.0.9000\n#&gt;  [4] cmdstanr_0.8.1       brms_2.22.0          Rcpp_1.0.14         \n#&gt;  [7] thematic_0.1.6       MetBrewer_0.2.0      ggokabeito_0.1.0    \n#&gt; [10] see_0.10.0           gridExtra_2.3        patchwork_1.3.0     \n#&gt; [13] bayesplot_1.11.1     psych_2.4.12         scales_1.3.0        \n#&gt; [16] markdown_1.13        knitr_1.49           lubridate_1.9.4     \n#&gt; [19] forcats_1.0.0        stringr_1.5.1        dplyr_1.1.4         \n#&gt; [22] purrr_1.0.4          readr_2.1.5          tidyr_1.3.1         \n#&gt; [25] tibble_3.2.1         ggplot2_3.5.1        tidyverse_2.0.0     \n#&gt; [28] rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      StanHeaders_2.32.10 \n#&gt; [13] processx_3.8.5       survival_3.8-3       magrittr_2.0.3      \n#&gt; [16] compiler_4.4.2       rlang_1.1.5          tools_4.4.2         \n#&gt; [19] yaml_2.3.10          labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    curl_6.2.0           pkgbuild_1.4.6      \n#&gt; [25] mnormt_2.1.1         plyr_1.8.9           abind_1.4-8         \n#&gt; [28] multcomp_1.4-28      withr_3.0.2          stats4_4.4.2        \n#&gt; [31] grid_4.4.2           inline_0.3.21        xtable_1.8-4        \n#&gt; [34] colorspace_2.1-1     emmeans_1.10.7       MASS_7.3-64         \n#&gt; [37] cli_3.6.4            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [40] generics_0.1.3       RcppParallel_5.1.10  rstudioapi_0.17.1   \n#&gt; [43] reshape2_1.4.4       tzdb_0.4.0           rstan_2.32.6        \n#&gt; [46] splines_4.4.2        parallel_4.4.2       matrixStats_1.5.0   \n#&gt; [49] vctrs_0.6.5          V8_6.0.1             Matrix_1.7-2        \n#&gt; [52] sandwich_3.1-1       jsonlite_1.8.9       callr_3.7.6         \n#&gt; [55] hms_1.1.3            glue_1.8.0           ps_1.8.1            \n#&gt; [58] codetools_0.2-20     distributional_0.5.0 stringi_1.8.4       \n#&gt; [61] gtable_0.3.6         QuickJSR_1.5.1       munsell_0.5.1       \n#&gt; [64] pillar_1.10.1        htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [67] R6_2.6.1             rprojroot_2.0.4      evaluate_1.0.3      \n#&gt; [70] lattice_0.22-6       backports_1.5.0      rstantools_2.4.0    \n#&gt; [73] coda_0.19-4.1        nlme_3.1-167         checkmate_2.3.2     \n#&gt; [76] xfun_0.50            zoo_1.8-12           pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#bibliografia",
    "href": "chapters/linear_models/12_two_proportions.html#bibliografia",
    "title": "67  Confronto tra due proporzioni indipendenti",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBanerjee, A. V., Bhattacharjee, S., Chattopadhyay, R., Duflo, E., Ganimian, A. J., Rajah, K., & Spelke, E. S. (2025). Children’s arithmetic skills do not transfer between applied and academic mathematics. Nature, 1–9.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "Differenze fondamentali tra i due approcci\nNell’inferenza statistica, due approcci principali si distinguono per il modo in cui interpretano la probabilità e integrano le informazioni: la statistica frequentista e la statistica bayesiana. Entrambi i metodi consentono di trarre conclusioni sulla popolazione di interesse, stimare quantità sconosciute, fare previsioni e testare ipotesi. Tuttavia, differiscono profondamente nella loro filosofia e nelle modalità operative, specialmente riguardo al ruolo delle conoscenze pregresse e all’interpretazione dell’incertezza.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#differenze-fondamentali-tra-i-due-approcci",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#differenze-fondamentali-tra-i-due-approcci",
    "title": "Introduzione",
    "section": "",
    "text": "La statistica bayesiana\nLa statistica bayesiana interpreta la probabilità come una misura di convinzione o grado di certezza riguardo a un evento. Questo approccio consente di incorporare conoscenze pregresse (definite prior) e di aggiornarle alla luce di nuove evidenze attraverso il teorema di Bayes. In questo contesto, il valore vero di un parametro della popolazione è trattato come una variabile casuale, la cui distribuzione di probabilità viene costantemente aggiornata man mano che nuovi dati vengono raccolti. Il risultato è una distribuzione a posteriori, che rappresenta una descrizione completa dell’incertezza associata al parametro e può essere utilizzata per fare previsioni probabilistiche.\n\n\nLa statistica frequentista\nAl contrario, la statistica frequentista interpreta la probabilità come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio presuppone che il vero valore di un parametro della popolazione sia fisso ma sconosciuto e debba essere stimato esclusivamente dai dati osservati. Le inferenze si basano su tecniche statistiche come la stima puntuale, gli intervalli di confidenza e i test di ipotesi, senza incorporare esplicitamente conoscenze pregresse.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#il-problema-dellinduzione-di-hume",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#il-problema-dellinduzione-di-hume",
    "title": "Introduzione",
    "section": "Il problema dell’induzione di Hume",
    "text": "Il problema dell’induzione di Hume\nUno dei modi per comprendere la differenza tra i due approcci è fare riferimento al problema dell’induzione, formulato da David Hume nel 1739 nel suo A Treatise of Human Nature (Hacking, 2006). Hume solleva una questione fondamentale: come possiamo giustificare le inferenze che traiamo dalle osservazioni passate per fare previsioni future? Egli sostiene che nessuna quantità di esperienze passate può fornire una garanzia logica che il futuro si comporterà nello stesso modo. Questo scetticismo mette in discussione la validità delle generalizzazioni statistiche e induce a riflettere su come valutiamo la probabilità degli eventi futuri.\n\nL’approccio frequentista si basa sull’idea che la probabilità di un evento possa essere definita come la frequenza relativa di quell’evento in un numero infinito di prove. Tuttavia, questo approccio presuppone implicitamente che il mondo segua regolarità statistiche costanti, un’assunzione che Hume mette in discussione.\nL’approccio bayesiano, invece, incorpora esplicitamente l’incertezza e l’aggiornamento delle conoscenze attraverso l’utilizzo di probabilità soggettive. In questo quadro, le nostre credenze vengono continuamente aggiornate alla luce di nuove evidenze, senza richiedere l’assunzione di una regolarità assoluta del mondo. Questo rende l’approccio bayesiano particolarmente adatto a gestire situazioni in cui le condizioni future possono cambiare o non essere perfettamente prevedibili.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#un-esempio-pratico-il-lancio-di-una-moneta",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#un-esempio-pratico-il-lancio-di-una-moneta",
    "title": "Introduzione",
    "section": "Un esempio pratico: il lancio di una moneta",
    "text": "Un esempio pratico: il lancio di una moneta\nConsideriamo il caso classico del lancio di una moneta per illustrare le differenze tra i due approcci:\n\nFrequentista: Un frequentista definirebbe la probabilità di ottenere testa come la proporzione di teste in un numero infinito di lanci. La probabilità è vista come una proprietà intrinseca della moneta, indipendente dalle nostre credenze.\nBayesiano: Un bayesianista, invece, partirebbe con una distribuzione di probabilità iniziale (prior) sulla propensione della moneta a cadere su testa, basata su conoscenze pregresse o ipotesi iniziali. Man mano che osserva i risultati dei lanci, aggiornerebbe questa distribuzione utilizzando la likelihood (la probabilità dei dati osservati dato il parametro), producendo una nuova distribuzione di probabilità (posterior). Questo processo riflette un aggiornamento razionale delle credenze alla luce delle nuove evidenze.\n\nL’approccio bayesiano, quindi, riflette più fedelmente lo spirito del pensiero di Hume: accetta l’incertezza intrinseca del futuro e cerca di gestirla attraverso un processo di aggiornamento razionale delle credenze.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#obiettivo-di-questa-sezione",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#obiettivo-di-questa-sezione",
    "title": "Introduzione",
    "section": "Obiettivo di questa sezione",
    "text": "Obiettivo di questa sezione\nIn questa sezione della dispensa esamineremo i metodi frequentisti della stima puntuale, degli intervalli di confidenza e del test di ipotesi. Questi strumenti rappresentano il cuore dell’inferenza statistica tradizionale e forniscono un quadro solido per analizzare i dati e trarre conclusioni in assenza di informazioni pregresse. Tuttavia, è importante tenere presente che, come evidenziato dal problema di Hume, ogni approccio ha i suoi limiti e le sue presupposizioni, e la scelta tra frequentista e bayesiano dipende spesso dal contesto e dagli obiettivi dell’analisi.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#bibliografia",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#bibliografia",
    "title": "Introduzione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html",
    "title": "69  Introduzione all’inferenza frequentista",
    "section": "",
    "text": "69.1 Introduzione\nCi sono due approcci principali per l’inferenza statistica: la statistica frequentista e la statistica bayesiana. Questi metodi consentono di fare conclusioni sulla popolazione di interesse attraverso l’analisi dei dati. Entrambi gli approcci sono usati per stimare quantità sconosciute, fare previsioni e testare ipotesi, ma differiscono nella loro interpretazione della probabilità e in come integrano le conoscenze precedenti ed evidenze.\nNella statistica frequentista, la probabilità viene interpretata come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull’idea che il vero valore di un parametro della popolazione sia fisso, ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute a partire dai dati osservati, mediante l’utilizzo di tecniche come la stima puntuale, gli intervalli di confidenza e il test di ipotesi, e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nD’altra parte, la statistica bayesiana interpreta la probabilità come una misura di convinzione o grado di certezza riguardo a un evento (Jaynes, 2003). Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell’analisi statistica attraverso l’uso del teorema di Bayes. In questo contesto, il vero valore di un parametro della popolazione è trattato come una variabile casuale e viene continuamente aggiornato man mano che vengono raccolti nuovi dati. Ciò porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, che può essere utilizzata per fare previsioni probabilistiche e quantificare l’incertezza associata.\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell’inferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle proprietà probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste proprietà sono utili per costruire gli intervalli di fiducia e i test di ipotesi che costituiscono gli strumenti principali dell’inferenza statistica frequentista.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "title": "69  Introduzione all’inferenza frequentista",
    "section": "\n69.2 I Frequentisti sono Razzisti?",
    "text": "69.2 I Frequentisti sono Razzisti?\nNel Capitolo 29, abbiamo esaminato le origini storiche e il contesto culturale che ha contribuito all’interpretazione applicativa del teorema di Bayes fornita da Richard Price. Queste origini sono legate alle idee alla base della rivoluzione americana, rappresentando quello che potremmo definire il “lato luminoso” del liberalismo moderno.\nLe origini culturali dell’approccio frequentista, invece, sono diametralmente opposte e strettamente connesse a quella che potremmo chiamare la “parte oscura” della modernità. Si potrebbe dire che l’avversione per la soggettività abbia guidato l’ascesa del frequentismo.\nFrancis Galton (1822-1911) fu un uomo straordinario sotto molti aspetti. Cugino di Charles Darwin e medico qualificato, ereditò una fortuna che gli permise di dedicarsi liberamente ai suoi interessi. Esplorò l’Africa, ricevendo una medaglia dalla Royal Geographical Society, e diede un importante contributo alla meteorologia, notando per primo il fenomeno degli “anticicloni”. Tuttavia, il suo contributo più significativo riguardò l’uso della statistica nello studio degli esseri umani, in particolare nell’analisi della trasmissione ereditaria del talento.\nGalton trascorse gran parte della sua carriera all’University College di Londra, dove fece numerose scoperte. Tra queste, un importante contributo riguardava la distribuzione normale. Fu anche il primo a spiegare il concetto che oggi conosciamo come “regressione verso la media”, da lui chiamato “regressione verso la mediocrità”.\nIl suo interesse per l’ereditarietà del talento portò Francis Galton a scrivere il libro Hereditary Genius, in cui analizzava come individui brillanti tendessero a concentrarsi in specifiche famiglie. Fu lui a coniare l’espressione “nature and nurture” per riferirsi ai due fattori fondamentali che influenzano lo sviluppo umano: l’ereditarietà (ciò che oggi chiamiamo genetica) e l’ambiente.\nTuttavia, Galton non si limitò a osservare e documentare la distribuzione dell’intelligenza. Il suo obiettivo era ambizioso e controverso: creare una scienza per il “miglioramento della specie umana”, che egli chiamò “eugenetica”. Promuoveva l’idea di incoraggiare la riproduzione tra le famiglie considerate di maggior successo e, al contrario, di scoraggiarla tra quelle ritenute meno fortunate.\nVa però sottolineato che Galton abbracciava idee profondamente razziste. In una lettera pubblicata sul Times di Londra, descrisse gli africani come “inferiori” e li definì “selvaggi pigri e chiacchieroni”. Gli arabi, secondo lui, erano “poco più che consumatori della produzione altrui”. Proponeva inoltre di consegnare l’Africa orientale ai cinesi, che giudicava “inclini alla menzogna e alla servilità” ma anche, a suo dire, “naturalmente industriosi e amanti dell’ordine”. Per Galton, gli anglosassoni rappresentavano la razza migliore esistente, sebbene ritenesse che gli antichi ateniesi fossero stati il vertice dell’umanità.\nIl lavoro di Galton ispirò una generazione successiva di statistici, in particolare Karl Pearson (1857-1936) e Ronald Fisher (1890-1962). Come Galton, Fisher e Pearson erano brillanti, ma condividevano anche le sue idee razziste, considerate inaccettabili sia per gli standard attuali che per quelli del loro tempo.\nKarl Pearson, poliedrico studioso e innovatore, divenne professore di matematica applicata all’UCL nel 1885, seguendo le orme di Francis Galton. Dopo la morte di quest’ultimo, ereditò la cattedra di eugenetica, istituita e finanziata da Galton stesso. Pearson fondò la rivista di statistica Biometrika e diede un contributo fondamentale alla disciplina, sviluppando il test del chi quadrato e coniando il termine “deviazione standard”.\nRonald Fisher, più giovane, succedette a Pearson come professore di eugenetica presso l’UCL. Considerato un gigante della teoria statistica, Fisher contribuì in modo decisivo allo sviluppo della disciplina, inventando o perfezionando strumenti fondamentali come l’analisi della varianza (ANOVA), il concetto di “significatività statistica” e il metodo della massima verosimiglianza (MLE).\nTutti questi ricercatori cercarono di allontanare la statistica dall’approccio soggettivo di Laplace e Bayes. Come Galton, sia Pearson che Fisher erano convinti sostenitori dell’eugenetica.\nÈ interessante riflettere su quanto le idee di Galton, Pearson e Fisher sull’eugenetica possano aver influenzato le loro visioni scientifiche. Secondo alcuni studiosi, la storia della statistica e quella dell’eugenetica sono strettamente intrecciate. Fisher, e in misura minore Pearson, rigettavano il bayesianesimo perché desideravano conferire un fondamento apparentemente “oggettivo” alle loro idee eugenetiche. Se fosse stata la scienza a “dimostrare” che alcune razze erano inferiori ad altre, o che la riproduzione tra i poveri dovesse essere scoraggiata, queste teorie sarebbero state presentate come indiscutibili. Il bayesianesimo, con la sua componente intrinseca di soggettività, rappresentava una minaccia a questa pretesa di oggettività.\nQuanto dovremmo tenere in considerazione le implicazioni storiche ed etiche quando valutiamo la statistica frequentista? Chivers (2024) risponde così: è indubbio che parte dell’ideologia razziale nazista possa essere collegata alle idee di Galton senza particolari difficoltà. Tuttavia, per quanto questa riflessione sia cruciale dal punto di vista storico ed etico, essa non è direttamente pertinente nell’analisi strettamente statistica. La domanda centrale rimane: “Quale approccio metodologico è corretto?” o, ancora meglio, “Quale approccio si dimostra più utile?”. Interrogarsi su “Quale approccio ha avuto i sostenitori più discutibili?” rischia di allontanarsi dal cuore del dibattito statistico.\nPur riconoscendo il merito di questa risposta nel mantenere l’attenzione sulla metodologia, ritengo che sia intrinsecamente insufficiente. Consideriamo un esempio ipotetico: supponiamo che in una “torre d’avorio” – che rappresenti la statistica, l’accademia o la scienza in senso lato – la teoria A risulti più efficace della teoria B. Tuttavia, al di fuori di questo contesto isolato, la teoria A genera conseguenze etiche inaccettabili, mentre la teoria B no. Dovremmo davvero scegliere la teoria A semplicemente perché funziona meglio in un sistema chiuso e teorico? La mia risposta è un netto e inequivocabile no.\nLe cosiddette “torri d’avorio” sono costrutti ideologici che non trovano riscontro nella realtà. Non esiste una rigida separazione tra ciò che accade “all’interno” e “all’esterno”: scienza ed etica non sono domini isolati, ma sfere che si intrecciano costantemente. Valutare una teoria esclusivamente sulla base della sua efficacia in un contesto ristretto equivale a ignorarne le implicazioni più ampie, spesso con conseguenze potenzialmente dannose.\nNel caso specifico del frequentismo, è evidente – come mostrerò in seguito – che questo approccio non solo presenta implicazioni etiche discutibili, ma è anche intrinsecamente debole dal punto di vista metodologico. La sua presunta superiorità all’interno di un ambito limitato è un’illusione che non resiste a un’analisi critica più ampia. Non possiamo, né dobbiamo, separare l’efficacia teorica dalle conseguenze pratiche ed etiche.\nIl frequentismo fallisce su entrambi i fronti: morale e scientifico. Sostenere tale approccio significa perpetuare un paradigma insostenibile, incapace di rispondere alle esigenze della scienza moderna e della responsabilità sociale. Pertanto, la sua difesa non può essere giustificata in alcun contesto.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "title": "69  Introduzione all’inferenza frequentista",
    "section": "\n69.3 Stime, stimatori e parametri",
    "text": "69.3 Stime, stimatori e parametri\nSpostiamo ora il discorso da un piano culturale ad un piano strettamente statistico. Consideriamo il concetto di stima statistica.\nQuando si analizzano i dati, solitamente si è interessati a una quantità a livello di popolazione; tuttavia, di solito si ha accesso solo a un campione di osservazioni. La quantità sconosciuta di nostro interesse viene chiamata parametro. La statistica che calcoliamo utilizzando i dati del campione viene chiamata stima, e la formula che la produce viene chiamata stimatore. Formalmente, uno stimatore è una funzione dei dati osservati utilizzata per produrre una stima di un parametro.\nIn altre parole, quando analizziamo un campione di dati, vogliamo inferire alcune proprietà della popolazione di cui il campione è rappresentativo. Il parametro rappresenta la misura di tali proprietà, ma spesso non è possibile calcolarlo direttamente sulla popolazione. Pertanto, lo stimiamo utilizzando le osservazioni del campione. La stima è quindi l’approssimazione del valore del parametro che otteniamo dal nostro campione, mentre lo stimatore è la formula matematica utilizzata per calcolare questa stima.\nTuttavia, le stime non sono necessariamente identiche ai parametri di nostro interesse. Le stime presentano una certa incertezza dovuta alla variabilità del campionamento. In questo capitolo esamineremo come l’approccio frequentista quantifica l’incertezza nelle nostre stime, in modo da poter trarre conclusioni sul parametro.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "title": "69  Introduzione all’inferenza frequentista",
    "section": "\n69.4 Distribuzione campionaria",
    "text": "69.4 Distribuzione campionaria\nIn questo capitolo esploreremo come la media di un campione casuale può essere utilizzata per stimare la media \\(\\mu\\) di una popolazione. Per valutare l’incertezza di questa stima, ci avvaliamo del concetto di distribuzione campionaria, un’importante idea dell’approccio frequentista.\nPer introdurre il concetto, utilizzeremo una popolazione finita di piccole dimensioni, pur sapendo che le proprietà illustrate valgono anche per popolazioni di dimensioni maggiori.\n\n69.4.1 Esempio introduttivo\nConsideriamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nL’istogramma sottostante rappresenta la distribuzione di frequenza della popolazione:\n\nhist(\n  x, breaks = 5, \n  freq = FALSE, \n  main = \"Distribuzione della popolazione\", \n  xlab = \"Valori\"\n)\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione:\n\nmean(x)  # Media\n#&gt; [1] 4.25\nvar(x)   # Varianza\n#&gt; [1] 2.417\n\n\n69.4.2 Campionamento\nSupponiamo ora di estrarre tutti i possibili campioni di dimensione \\(n = 2\\) dalla popolazione. Per generare queste combinazioni:\n\nsamples &lt;- expand.grid(x, x)\nsamples\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nOgni riga rappresenta un campione possibile. Calcoliamo il numero totale di campioni:\n\nnrow(samples)\n#&gt; [1] 16\n\nOra calcoliamo la media di ciascun campione, ottenendo la distribuzione campionaria delle medie per \\(n = 2\\):\n\nsample_means &lt;- rowMeans(samples)\nsample_means\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\n\n69.4.3 Visualizzazione della distribuzione campionaria\nPossiamo rappresentare graficamente questa distribuzione:\n\nhist(\n  sample_means, \n  breaks = 5, \n  freq = FALSE, \n  main = \"Distribuzione campionaria delle medie (n = 2)\", \n  xlab = \"Media campionaria\"\n)\n\n\n\n\n\n\n\n\n69.4.4 Verifiche teoriche\n\n69.4.4.1 Media della distribuzione campionaria\nLa media della distribuzione campionaria deve essere uguale alla media della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nmean(sample_means)  # Media della distribuzione campionaria\n#&gt; [1] 4.25\n\n\n69.4.4.2 Varianza della distribuzione campionaria\nLa varianza della distribuzione campionaria deve essere pari alla varianza della popolazione divisa per \\(n\\):\n\n# Evito la divisione per (n - 1)\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)\n}\n\n\nvariance(x) / 2  # Varianza teorica\n#&gt; [1] 0.9062\nvariance(sample_means)  # Varianza empirica\n#&gt; [1] 0.9062\n\n\n69.4.5 Esempio di campione osservato\nConsideriamo un singolo campione, ad esempio \\(\\{5, 5.5\\}\\):\n\nobserved_sample &lt;- c(5, 5.5)\nobserved_sample\n#&gt; [1] 5.0 5.5\n\nTroviamo la sua media e deviazione standard:\n\nmean(observed_sample)  # Media del campione\n#&gt; [1] 5.25\nsqrt(variance(observed_sample))    # Deviazione standard del campione\n#&gt; [1] 0.25\n\nConfrontiamo questi valori con quelli della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nsqrt(variance(x))     # Deviazione standard della popolazione\n#&gt; [1] 1.346\n\nIn conclusione, dalla simulazione emergono due risultati fondamentali:\n\n\nLa media della distribuzione campionaria coincide con la media della popolazione. Questo significa che, se si considera la media \\(\\bar{X}_n\\) di campioni casuali di ampiezza \\(n\\), il valore atteso di \\(\\bar{X}_n\\) è uguale alla media della popolazione \\(\\mu\\). Formalmente:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\mathbb{E}(S_n) = \\frac{1}{n} n \\mu = \\mu,\n\\] dove \\(\\mathbb{E}(\\cdot)\\) rappresenta il valore atteso e \\(S_n\\) la somma delle osservazioni nel campione.\n\n\nLa varianza della distribuzione campionaria è inferiore alla varianza della popolazione. In particolare, la varianza delle medie campionarie è data dalla varianza della popolazione divisa per l’ampiezza del campione, ovvero:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\n\n\n\n\n\n\n\n\nIl secondo risultato sopra può essere dimostrato come segue.\nSia \\(X_1, X_2, \\dots, X_n\\) un campione casuale di \\(n\\) osservazioni indipendenti estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). La media campionaria è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nPer definizione, la varianza di \\(\\bar{X}\\) è:\n\\[\n\\mathbb{V}(\\bar{X}) = \\mathbb{V}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right).\n\\]\nPoiché una costante moltiplicata da una variabile aleatoria può essere “estratta” dalla varianza, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right).\n\\]\nOra dobbiamo calcolare \\(\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right)\\). Le variabili \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, quindi la varianza della somma è la somma delle varianze:\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\mathbb{V}(X_i).\n\\]\nPoiché tutte le variabili \\(X_i\\) hanno la stessa varianza \\(\\sigma^2\\):\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = n \\sigma^2.\n\\]\nSostituendo nella formula precedente, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\cdot n \\sigma^2 = \\frac{\\sigma^2}{n}.\n\\]\nIn generale, dunque, per un campione di ampiezza \\(n\\), vale la relazione \\(\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\\).\n\n\n\n\n69.4.6 Proprietà della distribuzione campionaria\nInfine, osserviamo una proprietà fondamentale della distribuzione campionaria:\n\nSe la popolazione segue una distribuzione normale, allora anche la distribuzione delle medie campionarie seguirà una distribuzione normale, indipendentemente dall’ampiezza del campione.\nSe invece la popolazione non segue una distribuzione normale, il teorema del limite centrale garantisce che, all’aumentare della dimensione del campione \\(n\\), la distribuzione campionaria delle medie tenderà a una distribuzione normale.\n\nQueste proprietà sono centrali in molti metodi statistici, poiché consentono di fare inferenza sulla popolazione utilizzando campioni.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "title": "69  Introduzione all’inferenza frequentista",
    "section": "\n69.5 Teorema del Limite Centrale",
    "text": "69.5 Teorema del Limite Centrale\nEsaminiamo ora più in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Laplace dimostrò il TLC, che afferma che la somma di una sequenza di variabili casuali indipendenti tende a distribuirsi secondo una distribuzione Normale. Inoltre, il TLC stabilisce i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.\n\nTeorema 69.1 Si supponga che \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\) sia una sequenza di v.a. i.i.d. (variabili aleatorie identicamente distribuite e indipendenti) con \\(\\mathbb{E}(Y_i) = \\mu\\) e \\(SD(Y_i) = \\sigma\\). Si definisca una nuova variabile casuale come:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nCon \\(n \\rightarrow \\infty\\), \\(Z\\) tenderà a seguire una distribuzione Normale con lo stesso valore atteso di \\(Y_i\\) e una deviazione standard ridotta di un fattore pari a \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nIl TLC può essere generalizzato a variabili casuali che non sono identicamente distribuite, a condizione che siano indipendenti e abbiano aspettative e varianze finite. Molti fenomeni naturali, come l’altezza degli adulti, sono il risultato di una combinazione di effetti additivi relativamente piccoli. Questi effetti, indipendentemente dalla loro distribuzione individuale, tendono a portare alla normalità della distribuzione risultante. Questa è la ragione per cui la distribuzione normale fornisce una buona approssimazione per la distribuzione di molti fenomeni naturali.\n\n69.5.1 Illustrazione del TLC\nPer dimostrare il Teorema del Limite Centrale, consideriamo una popolazione iniziale con una distribuzione fortemente asimmetrica: una distribuzione Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 1\\). Estraiamo 50.000 campioni casuali di ampiezza \\(n\\) da questa popolazione e costruiamo la distribuzione campionaria delle medie.\nDefiniamo una funzione per simulare e visualizzare la distribuzione campionaria per diversi valori di \\(n\\):\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 1\n\n# Funzione per simulare e visualizzare la distribuzione campionaria\nplot_samples &lt;- function(n) {\n  # Media e deviazione standard della distribuzione Beta\n  mu &lt;- alpha / (alpha + beta)\n  sigma &lt;- sqrt(alpha * beta / ((alpha + beta)^2 * (alpha + beta + 1)))\n  \n  # Generazione di 50.000 campioni casuali di dimensione n\n  sample_means &lt;- replicate(50000, mean(rbeta(n, alpha, beta)))\n  \n  # Dati per la distribuzione normale teorica\n  x &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\n  y &lt;- dnorm(x, mean = mu, sd = sigma / sqrt(n))\n  \n  # Creazione del grafico\n  hist(\n    sample_means, \n    breaks = 50, \n    probability = TRUE, \n    main = paste(\"Ampiezza campionaria =\", n), \n    xlab = \"Media campionaria\", \n    ylab = \"Densità\"\n  )\n  lines(x, y, col = \"black\", lwd = 2)\n}\n\n\n69.5.2 Visualizzazione per diverse dimensioni campionarie\n\nAmpiezza campionaria \\(n = 1\\)\n\nSe \\(n = 1\\), la distribuzione campionaria delle medie coincide con la popolazione di partenza.\n\nplot_samples(1)\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 2\\)\n\nPer \\(n = 2\\), la distribuzione delle medie dei campioni inizia ad avvicinarsi alla normalità.\n\nplot_samples(2)\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 4\\)\n\nPer \\(n = 4\\), l’approssimazione alla distribuzione normale migliora.\n\nplot_samples(4)\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 30\\)\n\nPer \\(n = 30\\), la distribuzione campionaria delle medie è ben approssimata dalla normale.\n\nplot_samples(30)\n\n\n\n\n\n\n\nIn conclusione, il Teorema del Limite Centrale (TLC) afferma che, indipendentemente dalla forma della distribuzione della popolazione:\n\nPer campioni di dimensione sufficiente, la distribuzione campionaria delle medie \\(\\bar{X}\\) tende a una distribuzione normale.\n\nLa media \\(\\mu\\) e la deviazione standard \\(\\sigma\\) della popolazione determinano la distribuzione delle medie campionarie come segue:\n\\[\n\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma / \\sqrt{n}),\n\\]\ndove \\(n\\) è l’ampiezza del campione.\n\n\nQuesta proprietà ha implicazioni fondamentali:\n\nLa normalità emergente giustifica l’uso della distribuzione normale anche quando i dati non sono inizialmente normali.\nIl TLC fornisce una formula esplicita per calcolare l’errore standard \\(\\sigma / \\sqrt{n}\\), che quantifica la precisione della media campionaria come stima della media della popolazione.\n\n69.5.3 Applicazioni in psicologia\nMolti fenomeni psicologici che misuriamo (ad esempio, il QI come media di molte abilità cognitive) derivano dalla media di più variabili, e quindi seguono la distribuzione normale grazie al TLC. Questo spiega perché la distribuzione normale appare così frequentemente nei dati sperimentali di psicologia e in molte altre discipline scientifiche.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "69  Introduzione all’inferenza frequentista",
    "section": "\n69.6 Distribuzioni campionarie di altre statistiche",
    "text": "69.6 Distribuzioni campionarie di altre statistiche\nAbbiamo già analizzato la distribuzione campionaria della media dei campioni. Tuttavia, è possibile costruire distribuzioni campionarie per altre statistiche campionarie. Ad esempio, consideriamo la distribuzione campionaria del valore massimo e della varianza.\n\n69.6.1 Distribuzione campionaria del valore massimo\nSupponiamo di avere una popolazione normalmente distribuita con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Generiamo 10.000 campioni casuali di ampiezza \\(n = 5\\) e calcoliamo il valore massimo per ogni campione.\n\n69.6.1.1 Simulazione e visualizzazione\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\n\n# Simulazione: calcolo del valore massimo per ciascun campione\nn_samples &lt;- 10000\nsample_maxes &lt;- replicate(\n  n_samples, \n  max(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria del valore massimo\nhist(\n  sample_maxes, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria del valore massimo\",\n  xlab = \"Valore massimo\", \n  ylab = \"Densità\"\n)\n\n# Sovrapposizione della distribuzione normale della popolazione\ncurve(dnorm(x, mean = mu, sd = sigma), add = TRUE, col = \"black\", lwd = 2)\n\n\n\n\n\n\n\nOsserviamo che il valore atteso della distribuzione campionaria del massimo è maggiore della media della popolazione \\(\\mu\\).\n\n69.6.2 Distribuzione campionaria della varianza\nUn’altra statistica interessante è la varianza campionaria. La formula della varianza campionaria, basata sulla statistica descrittiva, è:\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nCalcoliamo la distribuzione campionaria della varianza per campioni di ampiezza \\(n = 5\\).\n\n69.6.2.1 Simulazione e visualizzazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza per ciascun campione\nsample_vars &lt;- replicate(\n  n_samples, \n  variance(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria della varianza\nhist(\n  sample_vars, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria della varianza\",\n  xlab = \"Varianza\", ylab = \"Densità\"\n)\n\n\n\n\n\n\n\n\n# Media empirica della varianza campionaria\nmean(sample_vars)\n#&gt; [1] 180.7\n\nSappiamo che la varianza della popolazione è \\(\\sigma^2 = 15^2 = 225\\). Tuttavia, il valore medio empirico delle varianze campionarie calcolate con \\(S^2\\) risulta minore di 225. Questo avviene perché lo stimatore \\(S^2\\) è distorto.\n\n69.6.3 Correzione della distorsione\nPer eliminare la distorsione, utilizziamo il seguente stimatore della varianza della popolazione:\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n-1}.\n\\]\n\n69.6.3.1 Verifica con simulazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza con la correzione\nsample_vars_unbiased &lt;- replicate(\n  n_samples, \n  var(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria della varianza corretta\nhist(\n  sample_vars_unbiased, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria della varianza (corretta)\",\n  xlab = \"Varianza\", \n  ylab = \"Densità\"\n)\n\n\n\n\n\n\n\n\n# Media empirica della varianza corretta\nmean(sample_vars_unbiased)\n#&gt; [1] 225.8\n\nCon questo stimatore, la media della distribuzione campionaria coincide con la varianza reale della popolazione \\(\\sigma^2 = 225\\).\nIn conclusione:\n\nLa distribuzione campionaria del massimo mostra che il valore massimo dei campioni è, in media, maggiore della media della popolazione.\nLa varianza campionaria non corretta (\\(S^2\\)) è uno stimatore distorto, poiché il suo valore atteso non coincide con la varianza della popolazione.\nLo stimatore corretto \\(s^2\\), che utilizza il divisore \\(n - 1\\), elimina la distorsione e fornisce una stima non distorta della varianza della popolazione.\n\nIn generale, uno stimatore è considerato non distorto quando il valore atteso delle sue stime coincide con il valore reale del parametro. Nel caso della media campionaria e della varianza corretta, entrambi gli stimatori sono non distorti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "title": "69  Introduzione all’inferenza frequentista",
    "section": "\n69.7 Riflessioni Conclusive",
    "text": "69.7 Riflessioni Conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell’inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.\n\n\n\n\n\n\n\nSimbolo\nNome\nÈ qualcosa che conosciamo?\n\n\n\n\\(s\\)\nDeviazione standard del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nSì, ma non è uguale a \\(\\sigma\\)\n\n\n\n\\(s^2\\)\nVarianza del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nSì, ma non è uguale a \\(\\sigma^2\\)\n\n\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione è la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione è:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#esercizi-sulla-distribuzione-campionaria-della-media",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#esercizi-sulla-distribuzione-campionaria-della-media",
    "title": "69  Introduzione all’inferenza frequentista",
    "section": "\n69.8 Esercizi sulla Distribuzione Campionaria della Media",
    "text": "69.8 Esercizi sulla Distribuzione Campionaria della Media\nLa distribuzione campionaria della media descrive come le medie dei campioni casuali estratti da una popolazione variano.\n\n69.8.1 Proprietà della Distribuzione Campionaria della Media\n\nMedia: La media della distribuzione campionaria coincide con la media della popolazione:\nVarianza: La varianza della distribuzione campionaria è pari alla varianza della popolazione divisa per la dimensione del campione:\nForma:\n\n\nSe la popolazione segue una distribuzione normale, anche la distribuzione campionaria della media sarà normale.\nSe la popolazione non è normale, il Teorema del Limite Centrale garantisce che la distribuzione campionaria della media sarà approssimativamente normale per campioni di dimensioni sufficientemente grandi (\\(n \\geq 30\\)).\n\nDefiniamo una popolazione e calcoliamo i parametri:\n\n# Popolazione\nx &lt;- c(2, 4.5, 5, 5.5)\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nvar(x)   # Varianza della popolazione\n#&gt; [1] 2.417\n\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) e calcolare la media di ciascun campione:\n\n# Tutti i campioni di ampiezza 2\nsamples &lt;- expand.grid(x, x)\nsample_means &lt;- rowMeans(samples)\n\n# Visualizzare la distribuzione campionaria\ndf &lt;- data.frame(sample_means = sample_means)\n\nggplot(df, aes(x = sample_means)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 5, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria delle medie\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCalcoliamo la probabilità che, all’interno della distribuzione campionaria, la media del campione sia minore di 3. Troviamo il valore esatto nella simulazione. Approssimiamo il valore esatto con il valore atteso se il campione fosse sufficientemente grande da poter assumere una distribuzione campionaria normale:\n\n# Probabilità esatta dalla distribuzione campionaria\nexact_probability &lt;- mean(sample_means &lt; 3)\nexact_probability\n#&gt; [1] 0.0625\n\n# Approssimazione tramite distribuzione normale\nmu &lt;- mean(x)  # Media della popolazione\nsigma &lt;- sqrt(var(x) / 2)  # Deviazione standard della distribuzione campionaria\napprox_probability &lt;- pnorm(3, mean = mu, sd = sigma)\napprox_probability\n#&gt; [1] 0.1277\n\nRipetiamo ora l’esempio, mantenendo la stessa struttura della simulazione, ma considerando una popolazione più grande tale per cui si possa estrarre un campione di ampiezza 15:\n\n# Nuova popolazione\nset.seed(123)\nx_large &lt;- rnorm(1000, mean = 10, sd = 3)  # Popolazione più grande\nmean(x_large)  # Media della popolazione\n#&gt; [1] 10.05\nvar(x_large)   # Varianza della popolazione\n#&gt; [1] 8.851\n\n# Estrazione di campioni di ampiezza 15\nsamples_large &lt;- replicate(10000, mean(sample(x_large, size = 15)))\n\n# Creazione del data frame per ggplot2\ndf_large &lt;- data.frame(sample_means = samples_large)\n\n# Visualizzazione con ggplot2\nggplot(df_large, aes(x = sample_means)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria delle medie (n = 15)\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n# Probabilità esatta dalla simulazione\nexact_probability_large &lt;- mean(samples_large &lt; 9)\nexact_probability_large\n#&gt; [1] 0.0834\n\n\n# Approssimazione tramite distribuzione normale\nmu_large &lt;- mean(x_large)\nsigma_large &lt;- sqrt(var(x_large) / 15)\napprox_probability_large &lt;- pnorm(9, mean = mu_large, sd = sigma_large)\napprox_probability_large\n#&gt; [1] 0.08616",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#esercizio-distribuzione-campionaria-della-differenza-tra-due-medie-indipendenti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#esercizio-distribuzione-campionaria-della-differenza-tra-due-medie-indipendenti",
    "title": "69  Introduzione all’inferenza frequentista",
    "section": "\n69.9 Esercizio: Distribuzione Campionaria della Differenza tra Due Medie Indipendenti",
    "text": "69.9 Esercizio: Distribuzione Campionaria della Differenza tra Due Medie Indipendenti\nLa distribuzione campionaria della differenza tra due medie descrive la variabilità delle differenze delle medie di campioni estratti da due popolazioni indipendenti.\n\n69.9.1 Esercizio 1: Simulazione con Popolazioni di Piccola Dimensione\nSupponiamo di avere due popolazioni finite definite come segue:\n\nPopolazione 1: \\(x_1 = \\{2, 4.5, 5, 6\\}\\)\n\nPopolazione 2: \\(x_2 = \\{3, 3.5, 4, 7\\}\\)\n\n\n\nCalcola le medie e le varianze delle due popolazioni:\n\n\n# Popolazione 1\nx1 &lt;- c(2, 4.5, 5, 6)\nmean(x1)  # Media di x1\n#&gt; [1] 4.375\nvar(x1)   # Varianza di x1\n#&gt; [1] 2.896\n\n\n# Popolazione 2\nx2 &lt;- c(3, 3.5, 4, 7)\nmean(x2)  # Media di x2\n#&gt; [1] 4.375\nvar(x2)   # Varianza di x2\n#&gt; [1] 3.229\n\n\nEstrai tutti i possibili campioni di ampiezza \\(n = 2\\) da entrambe le popolazioni:\n\n\n# Tutti i campioni di ampiezza 2\nsamples1 &lt;- expand.grid(x1, x1)\nsamples2 &lt;- expand.grid(x2, x2)\n\n# Medie campionarie\nsample_means1 &lt;- rowMeans(samples1)\nsample_means2 &lt;- rowMeans(samples2)\n\n\nCalcola la differenza tra le medie campionarie di ciascuna combinazione di campioni:\n\n\n# Differenze tra le medie campionarie\nsample_diff &lt;- as.vector(outer(sample_means1, sample_means2, \"-\"))\n\n\nVisualizza la distribuzione campionaria della differenza tra le medie:\n\n\n# Istogramma della differenza tra medie campionarie\n\n# Creazione del data frame per ggplot2\ndf_diff &lt;- data.frame(sample_diff = sample_diff)\n\n# Visualizzazione con ggplot2\nggplot(df_diff, aes(x = sample_diff)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 10, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra medie\",\n    x = \"Differenza campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\nCalcola la probabilità che la differenza campionaria sia maggiore di 1:\n\n\n# Probabilità esatta dalla distribuzione campionaria\nexact_probability &lt;- mean(sample_diff &gt; 1)\nexact_probability\n#&gt; [1] 0.2656\n\n\n69.9.2 Esercizio 2: Simulazione con Popolazioni di Grande Dimensione\nOra considera due popolazioni più grandi con distribuzioni normali:\n\nPopolazione 1: \\(X_1 \\sim N(10, 4^2)\\)\n\nPopolazione 2: \\(X_2 \\sim N(8, 3^2)\\)\n\n\n\nGenera due popolazioni casuali:\n\n\nset.seed(123)\npop1 &lt;- rnorm(10000, mean = 10, sd = 4)\npop2 &lt;- rnorm(10000, mean = 8, sd = 3)\n\n\nEstrai 10.000 campioni casuali di ampiezza \\(n_1 = 15\\) e \\(n_2 = 20\\) rispettivamente:\n\n\n# Estrazione di campioni e calcolo delle medie\nsample_means1 &lt;- replicate(10000, mean(sample(pop1, size = 15)))\nsample_means2 &lt;- replicate(10000, mean(sample(pop2, size = 20)))\n\n\nCalcola la differenza tra le medie campionarie:\n\n\n# Differenze tra medie campionarie\nsample_diff_large &lt;- sample_means1 - sample_means2\n\n\nVisualizza la distribuzione campionaria della differenza tra le medie:\n\n\n# Istogramma della distribuzione campionaria\n\n# Creazione del data frame per ggplot2\ndf_diff_large &lt;- data.frame(sample_diff = sample_diff_large)\n\n# Visualizzazione con ggplot2\nggplot(df_diff_large, aes(x = sample_diff)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra medie (n1 = 15, n2 = 20)\",\n    x = \"Differenza campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n\nCalcola la probabilità che la differenza campionaria sia maggiore di 2 utilizzando:\n\nla simulazione;\nl’approssimazione normale.\n\n\n\n\n# Probabilità esatta\nexact_probability_large &lt;- mean(sample_diff_large &gt; 2)\nexact_probability_large\n#&gt; [1] 0.505\n\n\n# Approssimazione normale\nmu_diff &lt;- 10 - 8  # Differenza tra le medie delle popolazioni\nsigma_diff &lt;- sqrt(4^2 / 15 + 3^2 / 20)  # Deviazione standard della differenza\napprox_probability_large &lt;- 1 - pnorm(2, mean = mu_diff, sd = sigma_diff)\napprox_probability_large\n#&gt; [1] 0.5\n\nDomande di Discussione.\n\nCome cambia la forma della distribuzione campionaria al variare delle dimensioni campionarie \\(n_1\\) e \\(n_2\\)?\nLa probabilità calcolata tramite simulazione coincide con quella calcolata tramite approssimazione normale? Perché?\nCosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali?",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#esercizio-distribuzione-campionaria-di-una-proporzione",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#esercizio-distribuzione-campionaria-di-una-proporzione",
    "title": "69  Introduzione all’inferenza frequentista",
    "section": "\n69.10 Esercizio: Distribuzione Campionaria di una Proporzione",
    "text": "69.10 Esercizio: Distribuzione Campionaria di una Proporzione\nLa distribuzione campionaria di una proporzione descrive come la proporzione campionaria (\\(\\hat{p}\\)) varia tra campioni di una popolazione. Per campioni grandi, il Teorema del Limite Centrale garantisce che la distribuzione campionaria di \\(\\hat{p}\\) può essere approssimata con una distribuzione normale.\n\n\nSupponiamo una popolazione infinita in cui la probabilità di successo (\\(p\\)) è \\(p = 0.6\\). Scegli una dimensione campionaria \\(n = 100\\).\nSimula 10.000 campioni casuali di ampiezza \\(n\\) e calcola le proporzioni campionarie (\\(\\hat{p}\\)).\nConfronta l’istogramma delle proporzioni campionarie con la distribuzione normale teorica approssimativa.\n\n\n# Parametri della popolazione\np &lt;- 0.6  # Probabilità di successo nella popolazione\nn &lt;- 100  # Dimensione del campione\n\n# Simulazione di 10.000 campioni\nset.seed(123)\nsample_props &lt;- replicate(10000, mean(rbinom(n, size = 1, prob = p)))\n\n# Creazione di un data frame per ggplot2\ndf_props &lt;- data.frame(sample_props = sample_props)\n\n# Parametri della distribuzione normale teorica\nmean_theoretical &lt;- p\nsd_theoretical &lt;- sqrt(p * (1 - p) / n)\n\n# Visualizzazione con ggplot2\nggplot(df_props, aes(x = sample_props)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 40, fill = \"blue\", alpha = 0.6) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_theoretical, sd = sd_theoretical),\n    color = \"red\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione campionaria di una proporzione (n = 100)\",\n    x = \"Proporzione campionaria (\\u0302p)\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n\nPopolazione e parametri:\n\nLa popolazione è definita da \\(p = 0.6\\).\nLa deviazione standard teorica della distribuzione campionaria è calcolata come \\(\\text{SD}(\\hat{p}) = \\sqrt{\\frac{p(1-p)}{n}}\\).\n\n\n\nSimulazione:\n\nPer ogni campione, i successi (\\(0\\) o \\(1\\)) sono generati con rbinom, e la proporzione campionaria \\(\\hat{p}\\) è calcolata come media.\n\n\n\nGrafico:\n\nL’istogramma delle proporzioni campionarie è sovrapposto alla curva normale teorica (\\(N(p, \\text{SD}(\\hat{p}))\\)).\n\n\n\nDomande di Discussione.\n\nLa distribuzione campionaria di \\(\\hat{p}\\) sembra approssimarsi a una distribuzione normale? Perché?\nCosa accadrebbe se \\(n\\) fosse più piccolo (es. \\(n = 30\\))?\nSe \\(p\\) fosse più vicino a \\(0\\) o \\(1\\), l’approssimazione normale sarebbe ancora valida? Spiega.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#esercizio-distribuzione-campionaria-della-differenza-tra-due-proporzioni",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#esercizio-distribuzione-campionaria-della-differenza-tra-due-proporzioni",
    "title": "69  Introduzione all’inferenza frequentista",
    "section": "\n69.11 Esercizio: Distribuzione Campionaria della Differenza tra Due Proporzioni",
    "text": "69.11 Esercizio: Distribuzione Campionaria della Differenza tra Due Proporzioni\nLa distribuzione campionaria della differenza tra due proporzioni (\\(\\hat{p}_1 - \\hat{p}_2\\)) descrive come la differenza tra le proporzioni campionarie varia tra due campioni indipendenti estratti da due popolazioni.\nPer campioni grandi, il Teorema del Limite Centrale garantisce che \\(\\hat{p}_1 - \\hat{p}_2\\) segue approssimativamente una distribuzione normale con media e varianza calcolate dalle proporzioni della popolazione.\nObiettivo:\n\nSimulare due popolazioni con proporzioni \\(p_1\\) e \\(p_2\\).\nEstrarre campioni indipendenti da ciascuna popolazione.\nCalcolare la distribuzione campionaria di \\(\\hat{p}_1 - \\hat{p}_2\\).\nCalcolare la probabilità che la differenza campionaria sia maggiore di un valore specifico (es. \\(0.1\\)).\n\nParametri del Problema:\n\nPopolazione 1: \\(p_1 = 0.6\\)\n\nPopolazione 2: \\(p_2 = 0.4\\)\n\nDimensione campionaria: \\(n_1 = n_2 = 150\\)\n\nValore specifico: \\(0.1\\)\n\n\n\n# Parametri delle due popolazioni\np1 &lt;- 0.6  # Proporzione di successi nella Popolazione 1\np2 &lt;- 0.4  # Proporzione di successi nella Popolazione 2\nn1 &lt;- 150  # Dimensione campionaria per la Popolazione 1\nn2 &lt;- 150  # Dimensione campionaria per la Popolazione 2\n\n# Simulazione di 10.000 campioni indipendenti\nset.seed(123)\nsample_p1 &lt;- replicate(10000, mean(rbinom(n1, size = 1, prob = p1)))\nsample_p2 &lt;- replicate(10000, mean(rbinom(n2, size = 1, prob = p2)))\n\n# Calcolo della differenza tra proporzioni campionarie\nsample_diff &lt;- sample_p1 - sample_p2\n\n# Parametri teorici della distribuzione normale approssimata\nmean_diff &lt;- p1 - p2\nsd_diff &lt;- sqrt((p1 * (1 - p1) / n1) + (p2 * (1 - p2) / n2))\n\n# Creazione del data frame per ggplot2\ndf_diff &lt;- data.frame(sample_diff = sample_diff)\n\n# Visualizzazione con ggplot2\nggplot(df_diff, aes(x = sample_diff)) +\n  geom_histogram(\n    aes(y = after_stat(density)), bins = 40, fill = \"blue\", alpha = 0.6\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_diff, sd = sd_diff),\n    color = \"red\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra proporzioni\",\n    x = \"Differenza campionaria (p1 - p2)\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n# Calcolo della probabilità che la differenza sia maggiore di 0.1\nexact_probability &lt;- mean(sample_diff &gt; 0.1)\nexact_probability\n#&gt; [1] 0.9599\n\n\n# Approssimazione tramite distribuzione normale\napprox_probability &lt;- 1 - pnorm(0.1, mean = mean_diff, sd = sd_diff)\napprox_probability\n#&gt; [1] 0.9615\n\n\n\nParametri delle popolazioni:\n\nDue popolazioni con proporzioni \\(p_1 = 0.6\\) e \\(p_2 = 0.4\\).\nDimensioni campionarie \\(n_1 = n_2 = 150\\).\n\n\n\nSimulazione:\n\nPer ogni campione, i successi (\\(0\\) o \\(1\\)) sono generati con rbinom.\nCalcoliamo le proporzioni campionarie e la differenza tra di esse.\n\n\n\nDistribuzione teorica:\n\nMedia teorica: \\(p_1 - p_2\\).\nDeviazione standard teorica: \\(\\sqrt{\\frac{p_1 (1-p_1)}{n_1} + \\frac{p_2 (1-p_2)}{n_2}}\\).\n\n\n\nVisualizzazione:\n\nUn istogramma di \\(\\hat{p}_1 - \\hat{p}_2\\) sovrapposto alla curva della distribuzione normale teorica.\n\n\n\nCalcolo della probabilità:\n\nProbabilità esatta dalla simulazione: proporzione di \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\nProbabilità approssimata dalla distribuzione normale.\n\n\n\nDomande di Discussione.\n\nL’approssimazione normale è valida in questo caso? Perché?\nCome cambierebbe la distribuzione campionaria se \\(n_1\\) o \\(n_2\\) fossero più piccoli?\nCome influenzerebbe la probabilità calcolata un valore \\(p_1\\) o \\(p_2\\) più vicino a \\(0\\) o \\(1\\)?",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "69  Introduzione all’inferenza frequentista",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "title": "69  Introduzione all’inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html",
    "href": "chapters/frequentist_inference/02_conf_interv.html",
    "title": "70  Intervalli di fiducia",
    "section": "",
    "text": "70.1 Introduzione\nGli intervalli di confidenza sono uno strumento fondamentale nell’inferenza statistica frequentista. Essi consentono di stimare un parametro sconosciuto di una popolazione, come la media \\(\\mu\\), tenendo conto dell’incertezza derivante dal fatto che la stima si basa su un campione. Questo materiale didattico si propone di spiegare in modo dettagliato e chiaro la costruzione di un intervallo di confidenza per la media di una popolazione, sia nel caso di varianza nota sia in quello di varianza incognita.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "href": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "title": "70  Intervalli di fiducia",
    "section": "\n70.2 Inferenza Statistica Frequentista e Media Campionaria",
    "text": "70.2 Inferenza Statistica Frequentista e Media Campionaria\nQuando estraiamo un campione casuale semplice \\(X_1, X_2, \\dots, X_n\\) da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria \\(\\bar{X}\\) è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nLa media campionaria \\(\\bar{X}\\) è una variabile casuale perché dipende dai valori osservati nel campione, che sono essi stessi casuali. Le proprietà della media campionaria sono le seguenti:\n\n\nMedia della distribuzione campionaria: \\(E[\\bar{X}] = \\mu\\). La media campionaria è uno stimatore non distorto della media della popolazione.\n\nVarianza della distribuzione campionaria: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\). Questo significa che la precisione di \\(\\bar{X}\\) come stima di \\(\\mu\\) aumenta con il numero di osservazioni \\(n\\).\n\nQueste proprietà sono fondamentali per calcolare un intervallo di confidenza, poiché ci permettono di descrivere la distribuzione di \\(\\bar{X}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "title": "70  Intervalli di fiducia",
    "section": "\n70.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota",
    "text": "70.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota\nSupponiamo che la popolazione sia distribuita normalmente con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e che \\(\\sigma^2\\) sia nota. La distribuzione della media campionaria \\(\\bar{X}\\) è anch’essa normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right).\n\\]\nPasso 1: Standardizzazione della Media Campionaria.\nPer lavorare con una distribuzione normale standard (media 0 e varianza 1), standardizziamo \\(\\bar{X}\\) utilizzando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQui, \\(\\sigma / \\sqrt{n}\\) è la deviazione standard della distribuzione campionaria di \\(\\bar{X}\\).\nDopo questa trasformazione, la variabile \\(Z\\) segue una distribuzione normale standard:\n\\[\nZ \\sim \\mathcal{N}(0, 1).\n\\]\nPasso 2: Determinazione del Livello di Confidenza.\nScegliamo un livello di confidenza \\(\\gamma\\), ad esempio \\(\\gamma = 0.95\\). Per una distribuzione normale standard, troviamo il valore critico \\(z\\) tale che la probabilità tra \\(-z\\) e \\(+z\\) sia pari al livello di confidenza:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nPer un livello di confidenza del 95%, \\(z \\approx 1.96\\).\nPasso 3: Formulazione dell’Intervallo di Confidenza.\nPartiamo dalla probabilità per \\(Z\\):\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nSostituiamo la definizione di \\(Z\\):\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\nMoltiplichiamo tutti i membri per \\(\\sigma / \\sqrt{n}\\) per rimuovere il denominatore:\n\\[\nP\\left(-z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\) a tutti i membri per isolare \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nPasso 4: Limiti dell’Intervallo di Confidenza.\nDefiniamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\\[\n\\hat{a} = \\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nL’intervallo di confidenza per \\(\\mu\\) è quindi:\n\\[\n(\\hat{a}, \\hat{b}) = \\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "title": "70  Intervalli di fiducia",
    "section": "\n70.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita",
    "text": "70.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita\nNella maggior parte dei casi pratici, la varianza \\(\\sigma^2\\) non è nota. In questi casi, stimiamo \\(\\sigma\\) con la deviazione standard campionaria \\(s\\) e utilizziamo la distribuzione t di Student, che tiene conto dell’incertezza aggiuntiva.\nPasso 1: Distribuzione t di Student.\nLa statistica che seguiamo è:\n\\[\nT = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}},\n\\]\ndove \\(T\\) segue una distribuzione t con \\(n-1\\) gradi di libertà.\nPasso 2: Costruzione dell’Intervallo di Confidenza.\nAnalogamente al caso precedente, costruiamo l’intervallo partendo da:\n\\[\nP(-t^\\ast \\leq T \\leq t^\\ast) = \\gamma,\n\\]\ndove \\(t^\\ast\\) è il valore critico della distribuzione t per il livello di confidenza \\(\\gamma\\) e \\(n-1\\) gradi di libertà.\nSostituendo \\(T\\):\n\\[\nP\\left(-t^\\ast \\leq \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}} \\leq t^\\ast\\right) = \\gamma.\n\\]\nMoltiplichiamo per \\(s / \\sqrt{n}\\):\n\\[\nP\\left(-t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nPasso 3: Limiti dell’Intervallo.\nI limiti dell’intervallo sono:\n\\[\n\\hat{a} = \\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}.\n\\]\nIn conclusione, gli intervalli di confidenza forniscono un modo per quantificare l’incertezza nelle stime di parametri sconosciuti. La loro costruzione dipende dalla distribuzione campionaria dello stimatore e dall’informazione disponibile sulla varianza.\n\n70.4.1 Applicabilità e Limitazioni\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e è valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non è normalmente distribuita e la dimensione del campione è ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell’intervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "href": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "title": "70  Intervalli di fiducia",
    "section": "\n70.5 Livello di Copertura",
    "text": "70.5 Livello di Copertura\nPer interpretare correttamente gli intervalli di fiducia è fondamentale considerare il concetto di “livello di copertura”. Questo livello indica la frequenza con cui l’intervallo di fiducia include il valore reale del parametro della popolazione, in una serie di esperimenti ripetuti.\nEsempio di Livello di Copertura:\n\nSe il livello di copertura è del 95%, significa che, nel lungo periodo, il 95% degli intervalli di fiducia costruiti conterrà il valore vero del parametro.\nImportante: Questo non implica che ci sia una probabilità del 95% che il valore vero del parametro cada in un particolare intervallo di fiducia. Infatti, il parametro della popolazione è un valore fisso e non soggetto a probabilità; piuttosto, l’incertezza risiede nell’intervallo di fiducia stesso.\n\nCome Funziona la Copertura:\n\nNel contesto frequentista, la “probabilità” si riferisce alla frequenza a lungo termine di un certo evento in un gran numero di ripetizioni dell’esperimento.\nNel caso degli intervalli di fiducia, l’“esperimento” è l’estrazione di un campione dalla popolazione, e l’“evento” è la generazione di un intervallo di fiducia che contiene il valore vero del parametro.\nIl livello di copertura, generalmente indicato come \\(1-\\alpha\\), rappresenta la probabilità a lungo termine che intervalli di fiducia costruiti con questa metodologia includano il vero valore del parametro.\n\n\n70.5.1 Simulazione\n\nPer illustrare questo concetto, eseguiamo una simulazione con la popolazione degli adulti maschi italiani, assunta come normalmente distribuita con media 175 cm e varianza 49 cm².\nEseguiamo 1000 ripetizioni di un esperimento, estraendo ogni volta un campione di 30 individui.\nPer ciascun campione, calcoliamo l’intervallo di fiducia al 95% usando la formula:\n\n\\[\n\\bar{X} \\pm t \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) è la media campionaria, \\(s\\) è la deviazione standard campionaria e \\(t\\) è il valore critico della distribuzione t-Student per \\(n-1\\) gradi di libertà al livello di significatività \\(\\alpha/2 = 0.025\\). - Registriamo i limiti di ciascun intervallo e controlliamo quanti di essi includono effettivamente il vero valore medio della popolazione.\nAttraverso questa simulazione, possiamo visualizzare concretamente il concetto di livello di copertura e la sua importanza nella statistica frequentista.\nIn questa simulazione, genereremo 1000 campioni casuali di dimensione \\(n = 30\\) da una distribuzione normale con media \\(\\mu = 175\\) e deviazione standard \\(\\sigma = 7\\). Successivamente, calcoleremo gli intervalli di confidenza al 95% per ciascun campione e valuteremo il livello di copertura.\n\nset.seed(123)  # Per riproducibilità\n\n# Parametri della distribuzione\nmu &lt;- 175\nsigma &lt;- 7\nn &lt;- 30\nn_samples &lt;- 1000\n\n# Generazione dei campioni\nsamples &lt;- replicate(n_samples, rnorm(n, mean = mu, sd = sigma))\ndim(samples)  # Verifica dimensioni: 30 righe per 1000 colonne\n#&gt; [1]   30 1000\n\nIl primo campione di ampiezza \\(n = 30\\) che abbiamo ottenuto è il seguente:\n\nsamples[, 1]  # Primo campione\n#&gt;  [1] 171.1 173.4 185.9 175.5 175.9 187.0 178.2 166.1 170.2 171.9 183.6 177.5\n#&gt; [13] 177.8 175.8 171.1 187.5 178.5 161.2 179.9 171.7 167.5 173.5 167.8 169.9\n#&gt; [25] 170.6 163.2 180.9 176.1 167.0 183.8\n\nStampiamo le medie dei primi dieci campioni:\n\nsample_means &lt;- colMeans(samples)  # Medie di tutti i campioni\nsample_means[1:10]  # Prime dieci medie\n#&gt;  [1] 174.7 176.2 175.2 174.3 173.7 176.1 175.1 174.4 175.4 177.4\n\nTroviamo il valore critico della distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libertà e livello di confidenza del 95% (\\(\\alpha = 0.05\\)):\n\nalpha &lt;- 0.05\nt_critical &lt;- qt(1 - alpha / 2, df = n - 1)  # Valore critico\nt_critical\n#&gt; [1] 2.045\n\nUtilizzando il valore critico \\(t\\), calcoliamo 1000 intervalli di confidenza per la media della popolazione:\n\n# Calcolo della deviazione standard campionaria\nsample_sds &lt;- apply(samples, 2, sd)\n\n# Ampiezza degli intervalli\ninterval_width &lt;- t_critical * sample_sds / sqrt(n)\n\n# Limiti degli intervalli di confidenza\nCI_low &lt;- sample_means - interval_width\nCI_high &lt;- sample_means + interval_width\n\nTroviamo il livello di copertura, ovvero la proporzione di intervalli di confidenza che contengono il vero valore della media della popolazione \\(\\mu\\):\n\ncoverage &lt;- mean(CI_low &lt; mu & mu &lt; CI_high)  # Proporzione di copertura\ncoverage\n#&gt; [1] 0.956\n\nIn conclusione, ripetendo la simulazione per 1000 campioni, abbiamo ottenuto un livello di copertura molto vicino al valore nominale di \\(1 - \\alpha = 0.95\\). Questo risultato dimostra che, con un campione di dimensione \\(n = 30\\), gli intervalli di confidenza al 95% calcolati utilizzando la distribuzione \\(t\\) di Student forniscono stime accurate della media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "href": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "title": "70  Intervalli di fiducia",
    "section": "\n70.6 Il Concetto di Livello di Confidenza",
    "text": "70.6 Il Concetto di Livello di Confidenza\nGli intervalli di confidenza sono range di valori che, con una certa sicurezza statistica, si ritiene includano il parametro di interesse.\nSecondo l’approccio frequentista, l’intervallo di confidenza si deve considerare come una metodologia:\n\nSe ripetiamo l’esperimento (estrarre un campione e calcolare l’intervallo di confidenza) molte volte, il metodo produce un intervallo che coprirà il valore vero del parametro nel 95% dei casi, assumendo un livello di confidenza del 95%.\n\n\n70.6.1 Un Malinteso Comune nell’Interpretazione degli Intervalli di Confidenza\nÈ inesatto affermare che un determinato intervallo di confidenza contenga il valore vero di un parametro con una probabilità del 95%. Questo è un errore diffuso, persino tra i ricercatori, che spesso interpretano l’intervallo di confidenza come indicativo della probabilità che il parametro (ad esempio, la media della popolazione \\(\\mu\\)) si trovi effettivamente all’interno di un dato intervallo (es. \\([\\hat{a}, \\hat{b}]\\)).\nLa descrizione corretta è la seguente:\n\n“La metodologia impiegata per calcolare l’intervallo \\([\\hat{a}, \\hat{b}]\\) ha il 95% di probabilità di generare un intervallo che include il vero valore del parametro”.\nCiò significa che l’intervallo di confidenza non esprime una probabilità circa la posizione precisa del parametro, ma riflette la probabilità che la procedura adottata per determinarlo generi un intervallo che lo includa.\n\nIn conclusione, l’intervallo di confidenza ci fornisce una garanzia statistica riguardo alla affidabilità del metodo usato per la sua stima, piuttosto che sulla esatta ubicazione del parametro in questione.\n\n70.6.2 Fraintendimenti Comuni sugli Intervalli di Confidenza\nNel loro lavoro, Hoekstra et al. (2014) evidenziano come, nonostante l’ampio riconoscimento dei limiti dei test di ipotesi nulle, gli intervalli di confidenza siano spesso consigliati per l’inferenza statistica. Anche l’American Psychological Association (APA) suggerisce che gli intervalli di confidenza siano “in generale, la migliore strategia di reportistica”. Tuttavia, Hoekstra et al. (2014) sottolineano che queste raccomandazioni non considerano la difficoltà nel fornire una corretta interpretazione degli intervalli di confidenza.\nPer indagare l’interpretazione degli intervalli di confidenza, Hoekstra et al. (2014) hanno condotto uno studio con due domande principali:\n\nQuanto frequentemente intervalli di confidenza sono mal interpretati da studenti e ricercatori?\nL’esperienza nella ricerca riduce le interpretazioni errate degli intervalli di confidenza?\n\nPrima di presentare lo studio, Hoekstra et al. (2014) ricordano qual è l’interpretazione corretta degli intervalli di confidenza.\n\nA CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (e.g., Berger & Wolpert, 1988). As is the case with \\(p\\)-values, CIs do not allow one to make probability statements about parameters or hypotheses.\n\nNel loro studio, Hoekstra et al. (2014) hanno presentato un questionario a 596 partecipanti, tra cui studenti universitari e ricercatori, con le seguenti affermazioni riguardanti l’interpretazione degli intervalli di confidenza.\n\nProfessor Bumbledorf conducts an experiment, analyzes the data, and reports: “The 95% confidence interval for the mean ranges from 0.1 to 0.4.” Please mark each of the statements below as ‘true’ or ‘false’.\n\n\n\nThe probability that the true mean is greater than 0 is at least 95%.\nThe probability that the true mean equals 0 is smaller than 5%.\nThe “null hypothesis” that the true mean equals 0 is likely to be incorrect.\nThere is a 95% probability that the true mean lies between 0.1 and 0.4.\nWe can be 95% confident that the true mean lies between 0.1 and 0.4.\nIf we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.\n\n\nSorprendentemente, anche se tutte le sei affermazioni nel questionario sono errate, molti partecipanti hanno concordato con esse. I risultati mostrano che, in media, i partecipanti hanno concordato con circa 3.5 affermazioni errate su 6. Non è stata rilevata una differenza di rilievo nell’interpretazione degli intervalli di confidenza tra studenti e ricercatori, suggerendo che l’esperienza nella ricerca non migliora la comprensione di questo concetto.\nI risultati indicano che molte persone interpretano erroneamente gli intervalli di confidenza, e che anche l’esperienza nella ricerca non garantisce una migliore comprensione. Questo solleva dubbi sull’efficacia degli intervalli di confidenza frequentisti e suggerisce che gli “intervalli di credibilità” bayesiani possano rappresentare un’alternativa più vantaggiosa. Quest’ultimi tendono ad essere più intuitivi e di più facile interpretazione corretta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "href": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "title": "70  Intervalli di fiducia",
    "section": "\n70.7 Confronto tra Intervalli Frequentisti e Bayesiani",
    "text": "70.7 Confronto tra Intervalli Frequentisti e Bayesiani\nConcludiamo questo capitolo esaminando le differenze tra l’intervallo di confidenza frequentista e l’intervallo di credibilità bayesiano, utilizzando lo stesso set di dati per entrambi i calcoli.\n\n70.7.1 Intervallo di confidenza frequentista\nImmaginiamo di avere un gruppo di 20 osservazioni relative alla performance in un test cognitivo. Il nostro obiettivo è stimare la media della popolazione da cui queste osservazioni sono tratte. Supponiamo che i dati provengano da una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della popolazione\nsample_size &lt;- 20\nmu &lt;- 50\nsigma &lt;- 10\n\n# Simulazione del campione\nsample_data &lt;- rnorm(sample_size, mean = mu, sd = sigma)\nprint(sample_data)\n#&gt;  [1] 44.40 47.70 65.59 50.71 51.29 67.15 54.61 37.35 43.13 45.54 62.24 53.60\n#&gt; [13] 54.01 51.11 44.44 67.87 54.98 30.33 57.01 45.27\n\nVisualizziamo la distribuzione dei dati:\n\ntibble(Valori = sample_data) |&gt;\n  ggplot(aes(x = Valori)) +\n  geom_histogram(aes(y = after_stat(density)),\n    bins = 30, # Puoi regolare il numero di bin\n    fill = \"skyblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione dei dati campionari\",\n    x = \"Valori\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nLa media campionaria (\\(\\hat{\\mu}\\)) viene calcolata come:\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nIn R:\n\nsample_mean &lt;- mean(sample_data)\nsample_mean\n#&gt; [1] 51.42\n\nLa deviazione standard campionaria (\\(s\\)) si calcola come:\n\\[\ns = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n\\]\nIn R:\n\nvariance &lt;- function(x) {\n  sum((x - mean(x))^2) / length(x)\n}\n\nsample_sd &lt;- sqrt(variance(sample_data))  # Deviazione standard campionaria\nsample_sd\n#&gt; [1] 9.48\n\nL’errore standard della media (\\(SE\\)) è:\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\]\nIn R:\n\nstandard_error &lt;- sample_sd / sqrt(sample_size)\nstandard_error\n#&gt; [1] 2.12\n\nUn intervallo di confidenza è definito come:\n\\[\n\\bar{X} \\pm t_{\\text{critico}} \\cdot SE\n\\]\ndove \\(t_{\\text{critico}}\\) è il valore critico della distribuzione \\(t\\) di Student per un livello di confidenza del 95% (\\(\\alpha = 0.05\\)) e \\(n-1\\) gradi di libertà. In R:\n\nalpha &lt;- 0.05\ndf &lt;- sample_size - 1\nt_critical &lt;- qt(1 - alpha / 2, df)\nt_critical\n#&gt; [1] 2.093\n\nCalcoliamo il margine di errore:\n\nmargin_of_error &lt;- t_critical * standard_error\nmargin_of_error\n#&gt; [1] 4.437\n\nCalcoliamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\nconfidence_interval &lt;- \n  c(sample_mean - margin_of_error, sample_mean + margin_of_error)\nconfidence_interval\n#&gt; [1] 46.98 55.85\n\nPossiamo interpretare questo risultato dicendo che la procedura utilizzata per calcolare l’intervallo include il valore vero della media della popolazione nel 95% dei casi.\nCreiamo un grafico per mostrare la distribuzione dei dati, la media campionaria e l’intervallo di confidenza:\n\ntibble(Valori = sample_data) |&gt;\n  ggplot(aes(x = Valori)) +\n  geom_histogram(aes(y = ..density..),\n    bins = 30, # Puoi regolare il numero di bin\n    fill = \"skyblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n\n  # Linea per la media campionaria\n  geom_vline(aes(xintercept = sample_mean),\n    color = \"blue\",\n    linetype = \"dashed\",\n    linewidth = 1.2\n  ) +\n\n  # Linee per l'intervallo di confidenza\n  geom_vline(aes(xintercept = confidence_interval[1]),\n    color = \"darkgreen\",\n    linewidth = 1.2\n  ) +\n  geom_vline(aes(xintercept = confidence_interval[2]),\n    color = \"darkgreen\",\n    linewidth = 1.2\n  ) +\n\n  # Titoli e assi\n  labs(\n    title = \"Intervallo di Confidenza per la Media\",\n    x = \"Valori\",\n    y = \"Densità\"\n  ) +\n\n  # Legenda personalizzata\n  annotate(\"text\",\n    x = sample_mean, y = 0.02, label = \"Media campionaria\",\n    color = \"blue\", angle = 90, vjust = -0.5\n  ) +\n  annotate(\"text\",\n    x = confidence_interval[1], y = 0.02, label = \"IC Inferiore\",\n    color = \"darkgreen\", angle = 90, vjust = -0.5\n  ) +\n  annotate(\"text\",\n    x = confidence_interval[2], y = 0.02, label = \"IC Superiore\",\n    color = \"darkgreen\", angle = 90, vjust = -0.5\n  )\n\n\n\n\n\n\n\n\n70.7.1.1 Confronto tra gli Approcci Frequentista e Bayesiano\nIntervallo di Credibilità Bayesiano:\n\nRappresenta il grado di credenza (posteriori) che il parametro \\(\\mu\\) si trovi all’interno dell’intervallo calcolato.\nDipende sia dai dati osservati sia dalle distribuzioni a priori utilizzate nel modello, che possono influenzare il risultato in base alla loro specificità o vaghezza.\n\nIntervallo di Confidenza Frequentista:\n\nNon esprime la probabilità che il parametro \\(\\mu\\) appartenga a un determinato intervallo.\nSi riferisce invece alla procedura di costruzione dell’intervallo: se il campionamento fosse ripetuto infinite volte, il 95% degli intervalli costruiti conterrebbe il vero valore di \\(\\mu\\).\n\nIn sintesi:\n\nL’intervallo di credibilità bayesiano fornisce una stima probabilistica diretta e interpretabile della posizione di \\(\\mu\\), basata su dati osservati e informazioni a priori.\nL’intervallo di confidenza frequentista, invece, valuta la affidabilità della procedura nel lungo termine, senza fare affermazioni dirette sulla probabilità che il parametro rientri nell’intervallo specifico.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "title": "70  Intervalli di fiducia",
    "section": "\n70.8 Riflessioni Conclusive",
    "text": "70.8 Riflessioni Conclusive\nCome sottolineato da Hoekstra et al. (2014), è comune riscontrare fraintendimenti riguardo agli intervalli di fiducia. Il “livello di confidenza del 95%” è da interpretarsi come la probabilità a lungo termine che, in una serie di intervalli di fiducia calcolati, il 95% di essi includa il vero valore del parametro sconosciuto. Tuttavia, per un singolo intervallo di fiducia, non è possibile dichiarare con sicurezza che questo contenga effettivamente il parametro di interesse. In altre parole, la certezza sulla presenza del parametro sconosciuto all’interno di un dato intervallo di fiducia non è garantita per ogni singolo caso analizzato.\nÈ inoltre inesatto presumere che esista un legame diretto tra la varianza e la media di un campione, ipotizzando che un intervallo di fiducia più ristretto implichi maggiore precisione. Nella prospettiva frequentista, la “precisione” è strettamente legata al livello di copertura a lungo termine assicurato dal metodo usato per creare gli intervalli di fiducia. Questo concetto non si applica al singolo intervallo di fiducia osservato. Dunque, un intervallo di fiducia che si presenta estremamente ristretto potrebbe in realtà essere significativamente lontano dal valore vero del parametro non noto.\nÈ importante sottolineare che l’approccio frequentista offre un metodo per calcolare gli intervalli di confidenza per una vasta gamma di statistiche. Questo include, ad esempio, la stima dell’intervallo di confidenza per la differenza tra due medie, per una proporzione o per la differenza tra due proporzioni. Ecco le formule per calcolare gli intervalli di confidenza per i casi menzionati:\nIntervallo di confidenza per la differenza tra due medie.\nSe abbiamo due campioni indipendenti di dimensione \\(n_1\\) e \\(n_2\\), con medie \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) e deviazioni standard \\(s_1\\) e \\(s_2\\), l’intervallo di confidenza per la differenza tra le medie è calcolato come:\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}},\n\\]\ndove \\(t_{\\alpha/2}\\) è il valore critico della distribuzione t di Student con \\(\\alpha/2\\) di probabilità di coda e gradi di libertà \\(df = n_1 + n_2 - 2\\).\nIntervallo di confidenza per una proporzione.\nPer stimare l’intervallo di confidenza per una proporzione \\(p\\) in un campione binomiale di dimensione \\(n\\), la formula è:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}},\n\\]\ndove \\(\\hat{p}\\) è la proporzione campionaria e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.\nIntervallo di confidenza per la differenza tra due proporzioni.\nPer stimare l’intervallo di confidenza per la differenza tra due proporzioni \\(p_1\\) e \\(p_2\\) in due campioni binomiali di dimensioni \\(n_1\\) e \\(n_2\\), la formula è:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}},\n\\]\ndove \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) sono le proporzioni campionarie e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "title": "70  Intervalli di fiducia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bayestestR_0.15.2    posterior_1.6.0.9000 cmdstanr_0.8.1      \n#&gt;  [4] thematic_0.1.6       MetBrewer_0.2.0      ggokabeito_0.1.0    \n#&gt;  [7] see_0.10.0           gridExtra_2.3        patchwork_1.3.0     \n#&gt; [10] bayesplot_1.11.1     psych_2.4.12         scales_1.3.0        \n#&gt; [13] markdown_1.13        knitr_1.49           lubridate_1.9.4     \n#&gt; [16] forcats_1.0.0        stringr_1.5.1        dplyr_1.1.4         \n#&gt; [19] purrr_1.0.4          readr_2.1.5          tidyr_1.3.1         \n#&gt; [22] tibble_3.2.1         ggplot2_3.5.1        tidyverse_2.0.0     \n#&gt; [25] rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.50           \n#&gt;  [4] htmlwidgets_1.6.4    insight_1.0.2        processx_3.8.5      \n#&gt;  [7] lattice_0.22-6       tzdb_0.4.0           vctrs_0.6.5         \n#&gt; [10] tools_4.4.2          ps_1.8.1             generics_0.1.3      \n#&gt; [13] parallel_4.4.2       pacman_0.5.1         pkgconfig_2.0.3     \n#&gt; [16] checkmate_2.3.2      distributional_0.5.0 lifecycle_1.0.4     \n#&gt; [19] compiler_4.4.2       farver_2.1.2         munsell_0.5.1       \n#&gt; [22] mnormt_2.1.1         htmltools_0.5.8.1    pillar_1.10.1       \n#&gt; [25] abind_1.4-8          nlme_3.1-167         tidyselect_1.2.1    \n#&gt; [28] digest_0.6.37        stringi_1.8.4        labeling_0.4.3      \n#&gt; [31] rprojroot_2.0.4      fastmap_1.2.0        grid_4.4.2          \n#&gt; [34] colorspace_2.1-1     cli_3.6.4            magrittr_2.0.3      \n#&gt; [37] withr_3.0.2          backports_1.5.0      timechange_0.3.0    \n#&gt; [40] rmarkdown_2.29       hms_1.1.3            evaluate_1.0.3      \n#&gt; [43] rlang_1.1.5          glue_1.8.0           rstudioapi_0.17.1   \n#&gt; [46] jsonlite_1.8.9       R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "href": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "title": "70  Intervalli di fiducia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21(5), 1157–1164.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html",
    "href": "chapters/frequentist_inference/03_sample_size.html",
    "title": "70  La grandezza del campione",
    "section": "",
    "text": "70.1 Introduzione\nLa scelta della dimensione del campione è fondamentale per garantire che i risultati di uno studio siano affidabili, bilanciando precisione e costi. In questo capitolo, esamineremo come calcolare la dimensione minima del campione necessaria per stimare la media di una popolazione con un margine di errore prefissato e un determinato livello di confidenza. Utilizzeremo un esempio tratto dalla psicologia per illustrare il processo e fornire implementazioni pratiche in R.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "title": "70  La grandezza del campione",
    "section": "\n70.2 La Logica Dietro la Scelta della Dimensione Campionaria",
    "text": "70.2 La Logica Dietro la Scelta della Dimensione Campionaria\nIn psicologia, è comune stimare la media di una variabile (ad esempio, il punteggio medio di una scala psicometrica). I vantaggi di utilizzare campioni più grandi includono:\n\n\nStime più precise: Con un campione più grande, la varianza dell’estimatore diminuisce, rendendo le stime più accurate.\n\nMaggiore fiducia nei risultati: Un campione più grande riduce il margine di errore, aumentando la certezza dei risultati.\n\nTuttavia, i campioni più grandi richiedono risorse maggiori in termini di tempo e denaro. Pertanto, il problema si riduce spesso a trovare il campione più piccolo che garantisca la precisione desiderata.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria",
    "title": "70  La grandezza del campione",
    "section": "\n70.3 Calcolo della Dimensione Campionaria",
    "text": "70.3 Calcolo della Dimensione Campionaria\nPer campioni sufficientemente grandi, la media campionaria \\(\\bar{X}\\) segue una distribuzione normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n\\]\ndove:\n\n\n\\(n\\) è la dimensione del campione,\n\n\\(\\mu\\) è la vera media della popolazione,\n\n\\(\\sigma^2\\) è la varianza della popolazione.\n\nIl nostro obiettivo è trovare la dimensione campionaria \\(n\\) tale che:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) \\geq 0.95,\n\\]\ndove:\n\n\n\\(\\bar{X}\\) è la media campionaria,\n\n\\(\\mu\\) è la media della popolazione,\n\n\\(E\\) è il margine di errore massimo accettabile.\n\nSappiamo che, per il teorema centrale del limite, la media campionaria \\(\\bar{X}\\) può essere standardizzata come segue:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQuesta quantità \\(Z\\) segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\).\nQuindi, possiamo riscrivere la probabilità richiesta come:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) = P\\left(|Z| &lt; z_{0.025}\\right),\n\\]\ndove \\(z_{0.025} = 1.96\\) è il quantile superiore della distribuzione normale standard corrispondente a un livello di confidenza del \\(95\\%\\).\nDalla definizione della variabile standardizzata \\(Z\\), possiamo ricavare la relazione per il margine di errore:\n\\[\n|\\bar{X} - \\mu| &lt; E \\implies Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\implies \\left|\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\\right| &lt; \\frac{E}{\\sigma / \\sqrt{n}}.\n\\]\nSostituendo la condizione \\(|Z| &lt; z_{0.025}\\), otteniamo:\n\\[\n\\frac{E}{\\sigma / \\sqrt{n}} = z_{0.025}.\n\\]\nRisolvendo per \\(\\sqrt{n}\\), moltiplichiamo entrambi i membri per \\(\\sigma / \\sqrt{n}\\):\n\\[\nE = z_{0.025} \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nIsoliamo \\(\\sqrt{n}\\) dividendo entrambi i membri per \\(z_{0.025} \\cdot \\sigma\\):\n\\[\n\\sqrt{n} = \\frac{z_{0.025} \\cdot \\sigma}{E}.\n\\]\nInfine, eleviamo entrambi i membri al quadrato per ottenere \\(n\\):\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]\nIn conclusione, la dimensione campionaria minima \\(n\\) necessaria per soddisfare il margine di errore \\(E\\) e il livello di confidenza richiesto è:\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "href": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "title": "70  La grandezza del campione",
    "section": "\n70.4 Stima della Media del Punteggio di Autostima",
    "text": "70.4 Stima della Media del Punteggio di Autostima\nConsideriamo un esempio pratico: vogliamo stimare la media del punteggio di autostima in una popolazione di giovani adulti, utilizzando la Rosenberg Self-Esteem Scale (RSES), che assegna un punteggio compreso tra 0 e 30.\nDettagli del Problema:\n\nDeviazione standard del punteggio: \\(\\sigma = 6\\) (stimata da studi precedenti).\nMargine di errore massimo accettabile: \\(E = 2\\).\nLivello di confidenza: \\(95\\%\\).\n\nImplementiamo in R la formula derivata in precedenza.\n\n# Parametri del problema\nsigma &lt;- 6     # Deviazione standard del punteggio RSES\nE &lt;- 2         # Margine di errore desiderato\nz_alpha &lt;- qnorm(0.975)  # Quantile superiore della distribuzione normale (95% confidenza)\n\n# Calcolo della dimensione campionaria\nn &lt;- (z_alpha * sigma / E)^2\nn &lt;- ceiling(n)  # Arrotondamento all'intero successivo\nn\n#&gt; [1] 35\n\nIn conclusione, la dimensione campionaria minima necessaria per stimare la media del punteggio di autostima con un margine di errore massimo di 2 punti e un livello di confidenza del 95% è \\(n = 35\\).\n\n70.4.1 Approfondimenti\n\n\nPrecisione e Livello di Confidenza Aumentando \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\nQuesto restringe l’intervallo di confidenza e migliora la precisione.\n\nCosto e Praticità Un campione più grande comporta costi più elevati. È importante trovare il giusto compromesso tra precisione e fattibilità.\nAdattamento ad Altri Livelli di Confidenza Per altri livelli di confidenza, basta modificare il quantile \\(z_{\\alpha/2}\\). Ad esempio, per un livello di confidenza del 99%, \\(z_{0.005} \\approx\\) 2.576.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "title": "70  La grandezza del campione",
    "section": "\n70.5 Riflessioni Conclusive",
    "text": "70.5 Riflessioni Conclusive\nDefinire la dimensione del campione rappresenta un passaggio cruciale nella progettazione di qualsiasi studio psicologico. Un approccio matematico rigoroso, fondato su analisi di potenza statistica e stime di effetti attesi, consente di ottimizzare il bilanciamento tra precisione dei risultati e limitazioni pratiche, come tempi, costi e disponibilità dei partecipanti. Questo equilibrio è fondamentale per garantire che i dati raccolti siano sufficientemente robusti da supportare conclusioni valide, senza tuttavia sprecare risorse in campioni eccessivamente ampi. Una corretta determinazione del campione contribuisce inoltre a ridurre il rischio di errori di tipo I e II, rafforzando l’integrità scientifica della ricerca.\nNel confronto tra paradigmi statistici, l’approccio frequentista si distingue per la sua enfasi sul controllo degli errori e sulla replicabilità attraverso il calcolo del valore p e della potenza statistica. Questo metodo richiede una rigorosa pianificazione preliminare, con la determinazione a priori della dimensione del campione basata su stime dell’effetto atteso e soglie prefissate di significatività e potenza. Tale rigidità metodologica, sebbene garantisca standardizzazione e controllo degli errori di Tipo I, può presentare notevoli limitazioni. In particolare, non permette modifiche alla dimensione del campione durante lo studio senza compromettere la validità statistica e può portare al problema dello “optional stopping”, dove il controllo ripetuto dei risultati aumenta il rischio di falsi positivi.\nL’approccio bayesiano, d’altra parte, offre una prospettiva complementare, ponendo l’accento sulla stima e sull’aggiornamento delle credenze in base ai dati osservati. Nel contesto bayesiano, la dimensione del campione non è solo uno strumento per garantire la significatività statistica, ma diventa un mezzo per affinare la precisione delle stime a posteriori. Questo approccio si caratterizza per una maggiore flessibilità, permettendo il monitoraggio continuo dell’evidenza attraverso i fattori di Bayes e l’aggiornamento sequenziale delle stime di probabilità. L’uso di distribuzioni a priori consente di incorporare conoscenze pregresse, portando a distribuzioni a posteriori che quantificano l’incertezza in modo più intuitivo e direttamente interpretabile.\nLa scelta di quando interrompere la raccolta dati rappresenta un esempio emblematico delle differenze tra i due approcci. Mentre il metodo frequentista richiede una dimensione campionaria fissa determinata a priori, l’approccio bayesiano permette una maggiore flessibilità, consentendo di interrompere la raccolta quando si raggiunge un livello desiderato di precisione nelle stime posteriori. Tuttavia, questa flessibilità comporta anche sfide specifiche, come la necessità di specificare distribuzioni a priori appropriate e una maggiore complessità computazionale.\nUna soluzione pragmatica potrebbe essere l’integrazione dei punti di forza di entrambi gli approcci. Si potrebbe utilizzare l’analisi della potenza frequentista per stabilire una dimensione minima del campione, implementando poi un monitoraggio bayesiano per valutare quando l’evidenza raccolta è sufficiente. Questo approccio integrato dovrebbe essere guidato da regole decisionali stabilite a priori e supportato da analisi di sensitività per valutare la robustezza delle conclusioni.\nIn sintesi, la scelta della dimensione del campione e la decisione su quando concludere la raccolta dati non dovrebbero essere viste solo come problemi tecnici, ma come opportunità per riflettere sulle priorità della ricerca, sul contesto teorico e sulle metodologie più adatte. La combinazione dei punti di forza degli approcci frequentista e bayesiano può portare a una ricerca più robusta, flessibile e informativa, contribuendo a un progresso scientifico più solido e sfaccettato. Tale scelta metodologica deve considerare gli obiettivi specifici dello studio, le risorse disponibili, i requisiti delle riviste scientifiche e la natura delle ipotesi da testare, bilanciando le esigenze di precisione con quelle di praticabilità. Pertanto, investire tempo nella pianificazione di questo aspetto non è solo una scelta metodologica, ma un imperativo etico per chiunque si impegni nella produzione di conoscenza psicologica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#riflessioni",
    "href": "chapters/frequentist_inference/03_sample_size.html#riflessioni",
    "title": "70  La grandezza del campione",
    "section": "\n70.6 Riflessioni",
    "text": "70.6 Riflessioni",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "70  La grandezza del campione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-167      rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#bibliografia",
    "href": "chapters/frequentist_inference/03_sample_size.html#bibliografia",
    "title": "70  La grandezza del campione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGiner-Sorolla, R., Montoya, A. K., Reifman, A., Carpenter, T., Lewis Jr, N. A., Aberson, C. L., Bostyn, D. H., Conrique, B. G., Ng, B. W., Schoemann, A. M., et al. (2024). Power to detect what? Considerations for planning and evaluating sample size. Personality and Social Psychology Review, 28(3), 276–301.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html",
    "title": "\n71  Significatività statistica\n",
    "section": "",
    "text": "71.1 Introduzione\nIl test di ipotesi è un metodo fondamentale della ricerca scientifica, utilizzato per fare inferenze sui parametri della popolazione a partire dai dati campionari. Nel contesto della psicologia, questo approccio viene frequentemente impiegato per valutare l’efficacia di interventi psicologici, confrontare teorie o approcci, analizzare l’influenza di variabili psicologiche su comportamenti e processi cognitivi, e approfondire i meccanismi alla base di fenomeni complessi come apprendimento, memoria ed emozioni.\nIn questo capitolo ci focalizzeremo sul test di ipotesi frequentista, un metodo largamente utilizzato ma non privo di limiti. È importante sottolineare che la comunità statistica sconsiglia di affidarsi esclusivamente a questo approccio come criterio decisionale per valutare la validità di un risultato sperimentale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#test-del-chi-quadrato",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#test-del-chi-quadrato",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.2 Test del Chi-Quadrato",
    "text": "71.2 Test del Chi-Quadrato\nPer introdurre il concetto di test di ipotesi nel contesto frequentista, iniziamo presentando uno dei test più semplici e utilizzati: il test del Chi-Quadrato. Questo test è particolarmente utile per valutare l’ipotesi di indipendenza tra due variabili categoriali organizzate in una tabella di contingenza (per ulteriori dettagli sulla struttura delle tabelle di contingenza, si veda il Capitolo 15).\nUna tabella di contingenza è una rappresentazione tabellare che mostra la distribuzione congiunta di due variabili categoriali. Ogni cella della tabella contiene la frequenza osservata delle combinazioni delle categorie delle due variabili. Inoltre, la tabella include i totali marginali, che rappresentano le somme delle frequenze per ciascuna riga e ciascuna colonna.\nIl test del Chi-Quadrato si pone una domanda fondamentale: “Come apparirebbe la tabella di contingenza se le due variabili fossero indipendenti?”. In altre parole, il test verifica se esiste una relazione significativa tra le due variabili o se, al contrario, le variabili sono indipendenti l’una dall’altra.\nCome già visto in precedenza analizzando la distribuzione di probabilità congiunta, si ha indipendenza quando le probabilità congiunte sono uguali al prodotto delle probabilità marginali. Partendo dalle proporzioni marginali, possiamo quindi calcolare i valori teorici attesi in ciascuna cella della tabella di contingenza, assumendo che le due variabili siano indipendenti.\nVa sottolineato che l’indipendenza è una proprietà della popolazione, non del campione. Pertanto, nei dati campionari, ci aspettiamo che i valori osservati nelle celle della tabella differiscano leggermente dai valori teorici attesi, anche se nella popolazione le variabili sono realmente indipendenti. La discrepanza complessiva tra i valori osservati e quelli attesi, calcolati sotto l’ipotesi di indipendenza, può essere misurata utilizzando una statistica chiamata Chi-Quadrato (\\(\\chi^2\\)).\nLa formula della statistica Chi-Quadrato è:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i} ,\n\\]\ndove:\n\n\n\\(O_i\\) rappresenta i valori osservati nelle celle della tabella,\n\n\n\\(E_i\\) rappresenta i valori attesi nelle celle, calcolati sotto l’ipotesi di indipendenza,\n\nLa somma (\\(\\sum\\)) viene effettuata su tutte le celle della tabella.\n\n\n71.2.1 Interpretazione della Statistica Chi-Quadrato\nLa statistica Chi-Quadrato misura la discrepanza complessiva tra i valori osservati e quelli attesi. Se non ci fosse differenza tra i valori congiunti osservati e quelli teorici, la statistica Chi-Quadrato sarebbe pari a zero. All’aumentare della discrepanza tra valori osservati e attesi, il valore della statistica Chi-Quadrato aumenta.\nPer valutare l’importanza della discrepanza osservata, utilizziamo la distribuzione campionaria della statistica Chi-Quadrato. Questa distribuzione descrive la probabilità di ottenere valori della statistica Chi-Quadrato sotto l’ipotesi nulla (indipendenza tra le variabili). La forma della distribuzione dipende dai gradi di libertà (\\(\\nu\\)), che si calcolano come:\n\\[\n\\nu = (n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1) ,\n\\]\ndove \\(n_{\\text{righe}}\\) e \\(n_{\\text{colonne}}\\) rappresentano rispettivamente il numero di righe e colonne della tabella di contingenza.\n\n71.2.2 Valutazione dell’Ipotesi di Indipendenza\nLa probabilità associata a una data discrepanza (\\(\\chi^2\\)) tra valori osservati e attesi, assumendo che l’ipotesi nulla sia vera, corrisponde all’area sotto la coda destra della distribuzione Chi-Quadrato, nell’intervallo [\\(C\\), \\(+\\infty\\)]. Questa probabilità è indicata come \\(p\\)-value.\nSe il \\(p\\)-value è molto piccolo (tipicamente inferiore a una soglia predefinita, come 0.05), possiamo rifiutare l’ipotesi nulla e concludere che è improbabile che le due variabili siano indipendenti nella popolazione.\n\n71.2.3 Riepilogo dei Passaggi del Test Chi-Quadrato\n\n\nCalcolo dei Valori Attesi: Per ogni cella, calcola \\(E_i\\) utilizzando la formula:\n\\[\nE_i = \\frac{\\text{Totale della Riga} \\times \\text{Totale della Colonna}}{\\text{Totale Complessivo}}\n\\]\n\n\nCalcolo della Statistica Chi-Quadrato: Usa la formula:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n\\]\n\nDeterminazione dei Gradi di Libertà: Calcola \\(\\nu\\) come \\((n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1)\\).\nConfronto con la Distribuzione Chi-Quadrato: Determina il \\(p\\)-value associato al valore di \\(\\chi^2\\) calcolato e valuta l’ipotesi nulla.\n\nIn conclusione, il Test Chi-Quadrato rappresenta uno strumento per verificare l’indipendenza tra due variabili categoriali. Grazie alla sua semplicità di applicazione e interpretazione, costituisce un metodo di analisi largamente utilizzato in ambito psicologico, sociale e statistico. Tuttavia, è importante prestare attenzione ai presupposti del test, come la sufficienza dei dati in ogni cella, per garantire risultati affidabili e interpretabili.\n\n# Creare la tabella di contingenza\nobserved &lt;- matrix(c(44, 0, 119, \n                              55, 68, 0, \n                              47, 0, 0),\n                            nrow = 3, byrow = TRUE)\n\n# Aggiungere i nomi di righe e colonne\nrownames(observed) &lt;- c(\"Biscoe\", \"Dream\", \"Torgersen\")\ncolnames(observed) &lt;- c(\"Adelie\", \"Chinstrap\", \"Gentoo\")\n\n# Visualizzare la tabella\nprint(observed)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe        44         0    119\n#&gt; Dream         55        68      0\n#&gt; Torgersen     47         0      0\n\n\nchi_square_result &lt;- chisq.test(observed)\nchi_square_result\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed\n#&gt; X-squared = 285, df = 4, p-value &lt;2e-16\n\nSvolgiamo i calcoli “a mano” usando R. Per calcolare la statistica del test del Chi-Quadrato “a mano” in R, segui questi passaggi:\nCalcoliamo i totali per righe e colonne e il totale complessivo.\n\n# Totali marginali\nrow_totals &lt;- rowSums(observed)\ncol_totals &lt;- colSums(observed)\ngrand_total &lt;- sum(observed)\n\n# Visualizzare i totali\nprint(\"Totali marginali per righe:\")\n#&gt; [1] \"Totali marginali per righe:\"\nprint(row_totals)\n#&gt;    Biscoe     Dream Torgersen \n#&gt;       163       123        47\nprint(\"Totali marginali per colonne:\")\n#&gt; [1] \"Totali marginali per colonne:\"\nprint(col_totals)\n#&gt;    Adelie Chinstrap    Gentoo \n#&gt;       146        68       119\nprint(paste(\"Totale complessivo:\", grand_total))\n#&gt; [1] \"Totale complessivo: 333\"\n\nI valori attesi si calcolano come:\n\\[\nE_{ij} = \\frac{\\text{Totale riga} \\times \\text{Totale colonna}}{\\text{Totale complessivo}} .\n\\]\n\n# Calcolo dei valori attesi\nexpected &lt;- outer(row_totals, col_totals) / grand_total\n\n# Visualizzare i valori attesi\nprint(\"Valori attesi:\")\n#&gt; [1] \"Valori attesi:\"\nprint(expected)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe     71.47    33.285  58.25\n#&gt; Dream      53.93    25.117  43.95\n#&gt; Torgersen  20.61     9.598  16.80\n\nLa statistica Chi-Quadrato si calcola con:\n\\[\n\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}} .\n\\]\n\n# Calcolo della statistica Chi-Quadrato\nchi_square_stat &lt;- sum((observed - expected)^2 / expected)\n\n# Visualizzare il risultato\nprint(paste(\"Statistica Chi-Quadrato:\", chi_square_stat))\n#&gt; [1] \"Statistica Chi-Quadrato: 284.590012688092\"\n\nI gradi di libertà si calcolano come:\n\\[\ndof = (\\text{n. righe} - 1) \\times (\\text{n. colonne} - 1) .\n\\]\n\n# Calcolo dei gradi di libertà\ndof &lt;- (nrow(observed) - 1) * (ncol(observed) - 1)\n\n# Visualizzare i gradi di libertà\nprint(paste(\"Gradi di libertà:\", dof))\n#&gt; [1] \"Gradi di libertà: 4\"\n\nConfrontiamo la statistica Chi-Quadrato con la distribuzione teorica per ottenere il p-value.\n\n# Calcolo del p-value\np_value &lt;- pchisq(chi_square_stat, df = dof, lower.tail = FALSE)\n\n# Visualizzare il p-value\nprint(paste(\"p-value:\", p_value))\n#&gt; [1] \"p-value: 2.28189154098739e-60\"\n\nInterpretazione:\nIl valore-\\(p\\) risulta molto piccolo, indicando che, se le variabili Isola e Specie fossero realmente indipendenti, sarebbe estremamente improbabile osservare una distribuzione delle specie di pinguini sulle tre isole così diversa da quella teoricamente attesa. In altre parole, il valore-\\(p\\) rappresenta la probabilità di ottenere, per puro caso, una discrepanza tra i valori osservati e quelli attesi pari o superiore a quella riscontrata nei dati.\nPoiché il valore-\\(p\\) è estremamente basso, possiamo concludere che l’ipotesi di indipendenza tra le variabili Isola e Specie non è plausibile. Questo indica che la distribuzione delle specie di pinguini varia in relazione all’isola, ovvero che conoscendo l’isola è possibile prevedere la distribuzione delle specie. In altre parole, le variabili Isola e Specie sono associate.\n\n71.2.4 Significatività Statistica: Un Concetto da Riconsiderare\nCome discusso nell’esempio precedente, un risultato è considerato “statisticamente significativo” se la probabilità che sia dovuto al caso è bassa, il che suggerisce che il risultato sia stabile o reale. Al contrario, risultati “non significativi” vengono spesso etichettati come privi di valore e ignorati. Questa semplificazione, però, può portare a gravi fraintendimenti. Ad esempio:\n\n\nDipendenza dal campione: La significatività statistica è fortemente influenzata dalla dimensione del campione; risultati apparentemente “significativi” possono emergere anche da effetti molto piccoli in campioni ampi.\n\nRisultati non significativi: Un risultato non significativo non implica che l’effetto sia nullo o irrilevante.\n\nScelte soggettive: Livelli di confidenza e test statistici differenti possono influenzare l’esito dell’analisi, portando a interpretazioni arbitrarie.\n\n71.2.5 Limiti e Applicazioni del Metodo Frequentista\nIl problema più grave dell’approccio frequentista è che esso non sempre mantiene la “promessa” di fornire una base oggettiva per la decisione statistica. Infatti, il ricorso esclusivo alla significatività statistica conduce a risultati opposti a quelli desiderati, aumentando il rischio di pubblicare risultati non replicabili o di trascurare evidenze importanti si veda il 76.\nIn alternativa, è più utile considerare il risultato osservato nel contesto scientifico più ampio, integrandolo con altre analisi. Questo approccio critico e completo consente di superare i limiti della significatività statistica e di interpretare i risultati con maggiore rigore.\n\n71.2.6 Un Caso Specifico: La Media del Campione\nTorniamo ora a esaminare il test di ipotesi all’interno del quadro frequentista, focalizzandoci sul caso di una variabile continua, diversamente dal contesto qualitativo trattato nel test del Chi-Quadrato. Per approfondire la comprensione della significatività statistica, analizzeremo in dettaglio l’utilizzo della media campionaria come stimatore della media della popolazione. Questa riflessione ci consentirà di esplorare sia i limiti che le applicazioni pratiche di tale strumento all’interno della statistica inferenziale frequentista. Attraverso questo esempio, potremo mettere in luce aspetti teorici e operativi dei test di ipotesi, nonché fornire indicazioni su come migliorare l’interpretazione dei risultati, con particolare riferimento al campo della ricerca psicologica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.3 Il Test di Ipotesi",
    "text": "71.3 Il Test di Ipotesi\nIl test di ipotesi è un metodo statistico utilizzato per valutare se i dati sono coerenti con l’ipotesi nulla (\\(H_0\\)). L’ipotesi nulla solitamente afferma che non vi è alcun effetto o differenza significativa, mentre l’ipotesi alternativa (\\(H_1\\)) rappresenta l’affermazione che si desidera testare. I dati del campione vengono analizzati per determinare se forniscono prove sufficienti per rifiutare l’ipotesi nulla. Un passaggio cruciale consiste nel calcolare il value-p.\n\n71.3.1 La procedura di Test di Ipotesi\nEsaminiamo in dettaglio le varie fasi della procedura del test di ipotesi di stampo frequentista.\nPasso 1: Formulare l’ipotesi nulla (\\(H_0\\)) e l’ipotesi alternativa (\\(H_1\\)) basandosi sulla domanda di ricerca.\nPasso 2: Stabilire un livello di significatività, α (solitamente 0.05).\nPasso 3: Selezionare il Test Statistico appropriato, verificare eventuali assunzioni e calcolare il test statistico.\nPasso 4: Decidere se il risultato è “statisticamente significativo” secondo (a) la regione di rifiuto o (b) il valore-p.\n\nL’approccio della regione di rifiuto. Basandosi sulla distribuzione campionaria nota del test statistico, la regione di rifiuto è un insieme di valori per il test statistico per i quali l’ipotesi nulla viene rifiutata. Se il valore osservato del test statistico rientra nella regione di rifiuto, allora si rifiuta l’ipotesi nulla.\nL’approccio del valore-p. Il valore-p è la probabilità di ottenere i risultati osservati, o risultati ancora più estremi, se l’ipotesi nulla è vera.\n\nConfrontiamo il valore-p calcolato con il livello di significatività α:\n\nSe il valore-p &lt; α, si rifiuta l’ipotesi nulla (\\(H_0\\)).\nSe il valore-p ≥ α, non si rifiuta l’ipotesi nulla (\\(H_0\\)).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.4 Il Test di Ipotesi nel Contesto Frequentista",
    "text": "71.4 Il Test di Ipotesi nel Contesto Frequentista\nSi noti che i metodi bayesiani e frequentisti non sono semplicemente due approcci diversi per rispondere alla stessa domanda, ma formulano domande fondamentalmente diverse. Pertanto, per comprendere il test di ipotesi frequentista, è essenziale chiarire cosa si intende per valore-p.\nL’American Statistical Association (ASA) definisce il valore-p come:\n\nthe probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value (Wasserstein e Lazar 2016).\n\nQuesta definizione può risultare difficile da comprendere perché contiene concetti complessi come “probabilità” e “modello statistico specificato”. Per capire meglio cosa rappresenta un valore-p, è necessario esaminare attentamente entrambi questi concetti. Questo ci porterà anche a una comprensione più profonda di altri concetti fondamentali per l’inferenza frequentista e ci aiuterà a distinguere tra inferenza frequentista e inferenza bayesiana.\nUna distinzione fondamentale tra l’approccio frequentista e quello bayesiano riguarda l’interpretazione della probabilità: il primo si basa sulla frequenza relativa degli eventi nel lungo periodo, mentre il secondo si basa sulla “certezza soggettiva” o sul grado di fiducia che un individuo attribuisce a un evento specifico.\nChiarito che la probabilità assume significati diversi nei contesti frequentista e bayesiano, possiamo chiederci quale nozione di probabilità sia implicita nella definizione del valore-p fornita dall’ASA. La visione comune suggerisce che si riferisca alle frequenze relative. Ma frequenze relative di cosa e ripetizioni di cosa?\nPossiamo riformulare la definizione dell’ASA in questo modo:\n\nIl valore-p si riferisce alla frequenza relativa di ottenere un riassunto statistico dei dati grande quanto o più grande del valore osservato in ripetizioni ipotetiche di un esperimento descritto da un modello statistico specificato.\n\nQuindi, l’approccio frequentista può essere descritto come un metodo per stimare il valore di un parametro attraverso esperimenti ipotetici, confrontando i nostri dati con i risultati di tali esperimenti per giudicare se i nostri dati sono sorprendenti o meno.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#applicazione-alla-media-campionaria",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#applicazione-alla-media-campionaria",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.5 Applicazione alla Media Campionaria",
    "text": "71.5 Applicazione alla Media Campionaria\nIn questo capitolo ci concentreremo sull’applicazione del processo di test di ipotesi frequentista alla media campionaria. Vedremo come la media di un campione possa essere impiegata per trarre inferenze sulla media di una popolazione, analizzandone limiti e possibili utilizzi nell’ambito dell’inferenza statistica frequentista.\nI test su uno o due campioni (one-sample e two-sample tests) hanno rappresentato le prime fondamenta dell’analisi statistica dei dati. Al giorno d’oggi, tuttavia, i nostri disegni sperimentali tendono a essere più complessi di quanto questi semplici test possano gestire. Nonostante ciò, tali test – in particolare il celebre t-test di Student – costituiscono ancora un’ottima porta d’ingresso alla modellazione statistica, poiché i principi su cui si basano sono relativamente intuitivi e consentono di familiarizzare con il processo di verifica dell’ipotesi.\nPer comprendere meglio i valori-p e la verifica del test di ipotesi, può essere molto utile ricorrere a simulazioni. Attraverso queste ultime è possibile ricreare condizioni sperimentali ipotetiche e osservare la variabilità dei risultati, fornendo così una prospettiva più chiara sulle implicazioni della statistica frequentista.\n\n71.5.1 La Distribuzione della Media Campionaria\nQuando consideriamo la media campionaria come stima della media di una popolazione, assumiamo che questa popolazione segua una distribuzione normale. Vogliamo quindi esplorare la distribuzione della media campionaria (\\(\\bar{X}\\)), che descrive la variazione di \\(\\bar{X}\\) attraverso infiniti campioni di dimensione \\(n\\). Abbiamo già dimostrato che, se la popolazione è normalmente distribuita, anche la distribuzione campionaria di \\(\\bar{X}\\) seguirà una distribuzione normale, con media \\(\\mu\\) (la media della popolazione) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\) (dove \\(\\sigma\\) è la deviazione standard della popolazione e \\(n\\) è la dimensione del campione).\n\n71.5.2 Test di Ipotesi sulla Media Campionaria\nSupponendo di conoscere \\(\\sigma\\) ma non \\(\\mu\\), utilizziamo i test di ipotesi per indagare quanto la media campionaria osservata si discosti da un valore ipotetico \\(\\mu_0\\), specificato dall’ipotesi nulla. Questo processo ci permette di valutare la plausibilità di \\(\\mu_0\\) come vera media della popolazione.\n\n71.5.3 Calcolo della Statistica del Test\nPer valutare quanto la media campionaria osservata si discosti dall’ipotesi nulla che propone \\(\\mu = \\mu_0\\), standardizziamo \\(\\bar{X}\\) usando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\nQuesta trasformazione produce una variabile \\(Z\\) che segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Valori estremi di \\(Z\\) (sia molto grandi che molto piccoli) suggeriscono che la media campionaria osservata è incompatibile con \\(\\mu_0\\), portando al rigetto dell’ipotesi nulla.\n\n71.5.3.1 Simulazione\nPer illustrare quanto espresso sopra attraverso una simulazione, consideriamo un esempio numerico. Supponiamo che \\(\\mu_0 = 100\\), \\(\\sigma = 15\\) e \\(n = 30\\). Vogliamo calcolare il valore-p per l’evento \\(\\bar{X} &gt; 105\\).\nLa simulazione può essere eseguita come segue:\n\n# To make the simulation reproducible\nset.seed(123)\n\nmu_0 &lt;- 100\nsigma &lt;- 15\nn &lt;- 30\nn_sim &lt;- 10000  # Number of simulations\n\n# Generate n_sim sample means from a N(mu_0, sigma/sqrt(n))\nsample_means &lt;- rnorm(n_sim, mean = mu_0, sd = sigma / sqrt(n))\n\n# Calculate the p-value as the proportion of sample means &gt; 105\np_value &lt;- mean(sample_means &gt; 105)\n\n# Print the p-value\nprint(p_value)\n#&gt; [1] 0.0339\n\nQuesto script simula la distribuzione campionaria di \\(\\bar{X}\\) sotto l’ipotesi nulla che \\(\\mu = \\mu_0\\) e calcola il valore-p per l’evento \\(\\bar{X} &gt; 105\\). Il valore-p indica la probabilità di osservare un valore di \\(\\bar{X}\\) così estremo (o più estremo) se l’ipotesi nulla fosse vera.\nIl risultato della simulazione può essere confrontato con il calcolo teorico del valore-p usando la distribuzione normale standard. Il valore \\(Z\\) per \\(\\bar{X} = 120\\) è calcolato come:\n\\[\nZ = \\frac{105 - 100}{15/\\sqrt{30}}\n\\]\nPossiamo usare la funzione stats.norm.sf() per trovare l’area sotto la curva normale standard a destra di questo valore \\(Z\\), che corrisponde al valore-p teorico.\n\n# Calculate the Z-score\nZ &lt;- (105 - 100) / (15 / sqrt(30))\nprint(Z)\n#&gt; [1] 1.826\n\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- pnorm(Z, lower.tail = FALSE)\n\nprint(upper_tail_prob)\n#&gt; [1] 0.03394\n\nOppure, in maniera equivalente\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- 1 - pnorm(105, mean = 100, sd = 15 / sqrt(30))\nprint(upper_tail_prob)\n#&gt; [1] 0.03394\n\nIl calcolo teorico mostra che il valore \\(Z\\) per una media campionaria di 105 è 1.82. Questo valore indica una deviazione sostanziale dalla media ipotizzata sotto l’ipotesi nulla (\\(\\mu_0 = 100\\)). Tale deviazione può essere quantificata dalla “sorpresa” indicata dal valore-p, dove valori-p piccoli rappresentano una maggiore sorpresa. Il valore-p ottenuto, pari a 0.0339, indica un elevato grado di sorpresa: come mostrato dalla simulazione, un valore di 105 o superiore si verifica solo nel 3.4% dei casi se l’esperimento viene ripetuto numerose volte sotto l’ipotesi nulla. Questo suggerisce che un risultato del genere è altamente improbabile se l’ipotesi nulla fosse vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#applicazioni-pratiche",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#applicazioni-pratiche",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.6 Applicazioni pratiche",
    "text": "71.6 Applicazioni pratiche\nNella precedente discussione, abbiamo supposto \\(\\sigma\\) nota. Tuttavia, poiché di solito non conosciamo il valore di \\(\\sigma\\) nella pratica, dobbiamo stimarlo utilizzando la deviazione standard campionaria \\(s\\). Pertanto, al posto di \\(\\sigma\\), possiamo utilizzare \\(s\\), ottenendo così la statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{\\frac{s}{\\sqrt{n}}}.\n\\]\nSi può dimostrare che la statistica \\(T\\) segue una distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà se il campione casuale è stato estratto da una popolazione normale.\nA questo punto, possiamo applicare la stessa logica descritta in precedenza e possiamom basarci sulla statistica \\(T\\) per testare un’ipotesi sulla media della popolazione. Utilizzando il valore critico appropriato dalla distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà e un livello di significatività predefinito, possiamo determinare se i dati osservati supportano o respingono l’ipotesi nulla sulla media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-statistiche",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-statistiche",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.7 Ipotesi statistiche",
    "text": "71.7 Ipotesi statistiche\nEsaminiamo in maggior dettaglio la procedura di test di ipotesi statistiche nel contesto frequentista. Definiamo innanzitutto l’ipotesi statistica come una dichiarazione riguardante la distribuzione di probabilità di una variabile casuale. Tale ipotesi può riguardare la forma funzionale della distribuzione o i parametri che la caratterizzano.\nIn particolare, l’ipotesi che riguarda i parametri di una o più popolazioni viene denominata ipotesi nulla e viene rappresentata come \\(H_0\\). Per un parametro sconosciuto \\(\\theta\\), l’ipotesi nulla viene formulata come:\n\\[\nH_0: \\theta \\in \\Theta_0 \\subset \\Theta,\n\\]\ndove \\(\\Theta_0\\) è un sottoinsieme del dominio \\(\\Theta\\), che rappresenta tutti i possibili valori del parametro \\(\\theta\\) coerenti con il modello statistico adottato. L’ipotesi nulla può essere semplice se \\(\\Theta_0\\) contiene un unico elemento, oppure composta se contiene più di un elemento.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.8 I passi di un test di ipotesi",
    "text": "71.8 I passi di un test di ipotesi\nPer prendere una decisione tra accettare o respingere l’ipotesi nulla, i frequentisti utilizzano un test statistico. Un test statistico frequentista ci permette di valutare se i dati osservati forniscono prove sufficienti per respingere o accettare un’ipotesi riguardante una proprietà di una popolazione di interesse e si può descrivere nel modo seguente.\nIniziamo formulando l’ipotesi nulla \\(H_0\\), che rappresenta un’affermazione specifica sulla popolazione. L’ipotesi alternativa \\(H_1\\) viene formulata come l’evento complementare rispetto all’evento specificato dall’ipotesi nulla. Successivamente, definiamo una statistica campionaria \\(\\mathcal{G}_n(X_1, \\dots, X_n)\\) che viene calcolata a partire dai dati campionari e che ha una distribuzione nota quando l’ipotesi nulla è vera.\nSuccessivamente, suddividiamo l’insieme di tutte le possibili realizzazioni della statistica \\(\\mathcal{G}_n\\) in due insiemi disgiunti: la “regione di accettazione” \\(\\mathcal{A}\\) e la sua regione complementare, la “regione di rifiuto” \\(\\mathcal{R}\\). La regione di accettazione rappresenta l’insieme dei valori che la statistica può assumere sotto l’ipotesi nulla, mentre la regione di rifiuto rappresenta l’insieme dei valori che la statistica può assumere se l’ipotesi nulla è falsa.\nInfine, selezioniamo un livello di significatività \\(\\alpha\\), che rappresenta la massima probabilità di respingere erroneamente l’ipotesi nulla quando questa è vera. Se l’osservazione della statistica \\(\\mathcal{G}_n\\) rientra nella regione di accettazione, allora l’ipotesi nulla non viene respinta; altrimenti, viene respinta a favore dell’ipotesi alternativa.\nIn sintesi, il test statistico ci consente di stabilire se i dati osservati forniscono sufficienti evidenze per rifiutare l’ipotesi nulla a favore dell’ipotesi alternativa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-alternativa",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-alternativa",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.9 Ipotesi alternativa",
    "text": "71.9 Ipotesi alternativa\nDurante un test di ipotesi, dopo aver definito l’ipotesi nulla \\(H_0\\), possono essere considerate diverse ipotesi alternative \\(H_1\\). Le ipotesi alternative più comuni si suddividono in tre tipi:\n\n\n\\(H_1: \\theta \\neq \\theta_0\\),\n\n\\(H_1: \\theta &gt; \\theta_0\\),\n\n\\(H_1: \\theta &lt; \\theta_0\\).\n\nQueste corrispondono rispettivamente a un test bidirezionale, un test unilaterale superiore (o destro) e un test unilaterale inferiore (o sinistro).\nLa scelta dell’ipotesi alternativa determina la definizione della regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla \\(H_0\\). La regione di rifiuto rappresenta i valori estremi della distribuzione, nella direzione dell’ipotesi alternativa \\(H_1\\). Nel caso di un test unilaterale inferiore, \\(\\mathcal{R}\\) si trova nella coda sinistra della distribuzione, nell’intervallo [\\(-\\infty\\), \\(\\theta_0\\)]. Nel caso di un test unilaterale superiore, \\(\\mathcal{R}\\) si trova nella coda destra della distribuzione, nell’intervallo [\\(\\theta_0\\), \\(\\infty\\)].\nI valori critici sono i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bidirezionale. Il risultato di un test viene considerato statisticamente significativo se il valore della statistica del test si trova nella regione di rifiuto \\(\\mathcal{R}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#valore-p",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#valore-p",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.10 Valore-p",
    "text": "71.10 Valore-p\nIl valore-p è definito come la probabilità che la statistica del test assuma un valore uguale o più estremo di quello osservato, considerando la distribuzione campionaria costruita assumendo come vera l’ipotesi nulla. La significatività statistica viene convenzionalmente definita come un valore-p inferiore a 0.05, indicando che l’evidenza osservata è improbabile da ottenere se l’ipotesi nulla è vera. Se il risultato osservato non raggiunge la significatività statistica, significa che la stima non è statisticamente significativa e che il valore osservato può essere spiegato da una semplice variazione casuale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#un-esempio-motivante",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#un-esempio-motivante",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.11 Un esempio motivante",
    "text": "71.11 Un esempio motivante\nPer esplorare il concetto di significatività statistica, possiamo prendere in considerazione uno studio svolto da Mehr et al. (2016) sul ruolo della musica nella trasmissione di messaggi sociali ai bambini. La musica è una forma d’arte presente in molte attività quotidiane e può trasmettere informazioni relative alla cultura e all’appartenenza sociale. Gli autori dello studio hanno voluto indagare se i bambini di soli 5 mesi avessero una preferenza per individui sconosciuti che cantavano loro una canzone familiare rispetto ad altri individui sconosciuti che cantavano una canzone simile, ma con una diversa melodia.\nDalle analisi condotte da Mehr et al. (2016) è emerso che la preferenza dei bambini si manifestava solo quando la canzone veniva cantata dai loro genitori durante la fase di familiarizzazione, ma non quando la stessa canzone veniva cantata da un estraneo. Secondo gli autori, questo dimostra che il significato sociale è un elemento chiave nella preferenza dei bambini, oltre alla familiarità con la canzone.\n\n71.11.1 Domanda della ricerca e ipotesi statistiche\nLa ricerca condotta da Mehr et al. (2016) si è concentrata sullo studio dell’influenza della musica sui messaggi sociali trasmessi ai bambini molto piccoli. Tuttavia, come molte altre ipotesi psicologiche, l’ipotesi principale non può essere valutata direttamente in termini quantitativi. Pertanto, i ricercatori devono formulare ipotesi statistiche, che, sebbene non coincidano con l’ipotesi della ricerca, possono essere esaminate in termini probabilistici.\nPer chiarire questo punto, consideriamo l’esperimento condotto sui bambini da Mehr et al. (2016). Dopo la fase di familiarizzazione con la canzone di prova, i bambini partecipanti sono stati sottoposti a un test in laboratorio, durante il quale sono stati mostrati due video. Nel primo video, un estraneo cantava la canzone di prova, mentre nel secondo video, un altro individuo cantava una canzone simile ma non familiare ai bambini. I ricercatori hanno misurato il tempo in cui i bambini fissavano ciascun video. Nel primo esperimento, la variabile dipendente era la media delle proporzioni di tempo che i bambini fissavano il video “familiare” rispetto al tempo di fissazione totale. Poiché l’ipotesi principale non può essere valutata direttamente, i ricercatori hanno formulato ipotesi statistiche che possono essere esaminate in termini probabilistici.\nPoiché nei tipici esperimenti psicologici, come nel caso della ricerca di Mehr et al. (2016), l’ipotesi della ricerca non può essere valutata direttamente, è necessario stabilire una connessione tra l’ipotesi della ricerca e l’ipotesi statistica. Nel caso specifico, ci sono tre possibili scenari da considerare:\n\nNel caso in cui i bambini non mostrino alcuna preferenza tra i due tipi di video-registrazione, la media delle proporzioni di tempo di fissazione per la popolazione sarà uguale a \\(\\mu = 0.5\\), in quanto i tempi di fissazione saranno uguali in media per le due video-registrazioni.\nSe invece gli autori della ricerca hanno ragione, i bambini mostreranno una preferenza per il video con la canzone familiare rispetto a quello con la canzone non familiare. In questo caso, l’ipotesi statistica sarà \\(\\mu &gt; 0.5\\), dove \\(\\mu = 0.5\\) rappresenta il livello di probabilità casuale.\nInfine, una terza possibilità è che i bambini siano maggiormente attratti da una melodia non familiare, contrariamente a quanto suggerito dagli autori della ricerca. In tal caso, l’ipotesi statistica diventa \\(\\mu &lt; 0.5\\).\n\nLe tre ipotesi precedenti sono esempi di ipotesi statistiche, che sono delle affermazioni riguardanti i valori di un parametro di un modello statistico. Nel caso dell’esperimento di Mehr et al. (2016), il modello statistico riguarda la distribuzione delle proporzioni dei tempi di fissazione di una popolazione virtuale di infiniti bambini di sei mesi di età. Ogni bambino avrà una proporzione di tempi di fissazione diversa dagli altri bambini. Il modello statistico descritto dai ricercatori rappresenta la distribuzione dei possibili valori della proporzione del tempo di fissazione nei confronti del video “familiare”. I dati raccolti dagli sperimentatori corrispondono alla media della proporzione del tempo di fissazione del video “familiare” e possono essere messi in relazione con il modello statistico.\n\n71.11.2 Domanda della ricerca e ipotesi statistiche\nLa distinzione tra l’ipotesi della ricerca e l’ipotesi statistica è cruciale durante il test delle ipotesi. L’ipotesi della ricerca riguarda l’affermazione che si intende testare sulla natura dei fenomeni psicologici, mentre l’ipotesi statistica riguarda il modello generativo dei dati, ovvero le proprietà della popolazione. Nel caso dell’esperimento condotto da Mehr e colleghi, l’ipotesi della ricerca afferma che la preferenza sociale dei bambini è influenzata dalla musica e, in particolare, dalla familiarità con i materiali musicali. L’ipotesi statistica, invece, sostiene che la media della proporzione del tempo di fissazione dei bambini sul video “familiare” sia maggiore di 0.5.\nI test di ipotesi vengono applicati alle ipotesi statistiche, non alle ipotesi della ricerca. Ciò significa che se l’esperimento non viene condotto nella maniera appropriata, il collegamento tra l’ipotesi statistica e la domanda della ricerca può essere spezzato. Ad esempio, se l’attore che canta la melodia familiare assomiglia ad uno dei genitori del bambino, mentre l’altro attore ha un aspetto molto diverso, allora potrebbe essere facile trovare evidenze a supporto dell’ipotesi statistica secondo cui la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” è maggiore di 0.5, ma ciò non avrebbe nulla a che fare con la domanda della ricerca.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.12 Ipotesi nulla e ipotesi alternativa",
    "text": "71.12 Ipotesi nulla e ipotesi alternativa\nFino a qui il ragionamento è stato semplice: il ricercatore ha un’ipotesi a proposito dei fenomeni psicologici e a tale ipotesi di ricerca corrisponde un’ipotesi statistica che riguarda il meccanismo generativo dei dati. Se il fenomeno psicologico possiede le proprietà suggerite dall’ipotesi della ricerca, allora il ricercatore può aspettarsi che i dati osservati abbiano alcune specifiche caratteristiche. A questo punto, però, il ragionamento diventa contro-intuitivo perché non è possibile verificare direttamente l’ipotesi statistica che corrisponde alla domanda della ricerca.\n\n71.12.1 Apagogia\nIn linea di principio, non è mai possibile dimostrare direttamente la verità di una proposizione. Tuttavia, possiamo dimostrare la sua verità in modo indiretto, ovvero provando la falsità della sua proposizione complementare.\nL’esempio classico è il seguente. Consideriamo la seguente proposizione: “Tutti i cigni sono bianchi” (questo è l’esempio ornitologico preferito da Popper). L’osservazione di un numero qualsiasi di cigni bianchi non è sufficiente a dimostrare la verità di questa proposizione – infatti, ci potrebbe essere da qualche parte un cigno non bianco che non abbiamo osservato (e infatti c’è). D’altra parte, invece, l’osservazione di un solo cigno che non sia bianco (ovvero, per esempio, l’osservazione di un cigno nero proveniente dall’Australia) può falsificare la proposizione considerata. Questa è la logica del falsificazionismo di Popper.\nQuesto modo di pensare è stato trasferito nella procedura di test di ipotesi di stampo frequentista. Dato che non possiamo dimostrare vera l’ipotesi statistica associata alla domanda della ricerca, seguiamo il percorso opposto. Ovvero, ci poniamo l’obiettivo di dimostrare falso l’evento complementare a quello specificato dall’ipotesi statistica associata alla domanda della ricerca. L’ipotesi statistica che vorremmo falsificare si chiama “ipotesi nulla” e viene denotata con \\(H_0\\). Nel caso dell’esempio che stiamo discutendo, l’ipotesi nulla è: \\(\\mu \\leq 0.5\\). Si noti che l’ipotesi nulla include tutte le possibili ipotesi statistiche che si possono formulare (ovvero, \\(\\mu = 0.5\\) e \\(\\mu &lt; 0.5\\)), ad eccezione di quella che è associata all’ipotesi della ricerca (ovvero, \\(\\mu &gt; 0.5\\)). Questo definisce, nel caso presente, un test unilaterale.\nIn pratica, ciò che stiamo facendo è dividere tutti i possibili valori di \\(\\mu\\) in due gruppi: quei valori che sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi alternativa, denotata con \\(H_1\\)) e quei valori che non sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi nulla).\nAvendo detto questo, la cosa importante da riconoscere è che l’obiettivo di un test di ipotesi frequentista non è quello di dimostrare che l’ipotesi alternativa è (probabilmente) vera; l’obiettivo è mostrare che l’ipotesi nulla è (probabilmente) falsa. La maggior parte delle persone ritiene che questo modo di ragionare sia piuttosto strano.\n\n71.12.2 La similitudine del processo penale\nUn test di ipotesi è spesso comparato ad un processo penale, dove l’ipotesi nulla rappresenta l’imputato, il ricercatore il pubblico ministero, e il test statistico il giudice. Così come in un processo penale, anche in un test di ipotesi c’è una presunzione di innocenza, dove l’ipotesi nulla viene considerata vera a meno che il ricercatore non dimostri, con evidenza al di là di ogni ragionevole dubbio, che è falsa. Il ricercatore progetta l’esperimento in modo da massimizzare la possibilità che i dati producano una condanna dell’ipotesi nulla. Il test statistico, rappresentato dal giudice in questa metafora, stabilisce le regole che devono essere seguite per giungere al verdetto e tali regole sono pensate per proteggere l’ipotesi nulla. In particolare, sono studiate per garantire che la probabilità di una condanna sia bassa se l’ipotesi nulla è effettivamente vera. È importante sottolineare che l’ipotesi nulla deve essere protetta, poiché il ricercatore sta cercando di dimostrare che essa è falsa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#due-tipi-di-errori",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#due-tipi-di-errori",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.13 Due tipi di errori",
    "text": "71.13 Due tipi di errori\nPrima di entrare nei dettagli su come viene costruito un test statistico è utile capire la logica su cui esso è basato. In precedenza abbiamo paragonato il test di ipotesi nulla ad un processo penale, ma ora dobbiamo essere più espliciti. Idealmente, vorremmo costruire il nostro test in modo da non commettere errori. Sfortunatamente, però, questo non è possibile: a volte il ricercatore è sfortunato e finisce per prendere la decisione sbagliata, anche se adotta un processo decisionale razionale. Ad esempio, può succedere che una moneta venga lanciata 10 volte di fila e produca testa tutte le 10 volte. Ciò sembra fornire una prova molto forte del fatto che la moneta è sbilanciata, ma c’è una possibilità su 1024 che ciò accada anche se la moneta è equilibrata. In altre parole, nella vita reale dobbiamo sempre accettare la possibilità che le nostre scelte siano sbagliate, anche quando sembrano ragionevoli. Di conseguenza, l’obiettivo dei test delle ipotesi statistiche non è quello di eliminare completamente gli errori (questo è impossibile), ma di ridurre gli errori al minimo.\nA questo punto, dobbiamo precisare meglio cosa intendiamo per “errori”. Iniziamo con il rendere esplicito quello che è ovvio: l’ipotesi nulla può essere vera o falsa, e il nostro test ci può condurre a rifiutare l’ipotesi nulla o a non rifiutarla. La decisione di rigettare o non rigettare l’ipotesi nulla ci espone dunque al rischio di commettere uno di due tipi di errore, come indicato nella figura seguente. L’errore di I tipo, denotato con \\(\\alpha\\), è quello che commettiamo se rigettiamo l’ipotesi nulla quando essa è vera; l’errore di II tipo, denotato con \\(\\beta\\), è quello che commettiamo se accettiamo l’ipotesi nulla mentre invece è vera l’ipotesi alternativa.\n\n\n71.13.1 Errore di I tipo: la protezione dei diritti dell’imputato\nIn precedenza abbiamo paragonato il test statistico ad un processo penale. Infatti, un processo penale richiede che si stabilisca la colpevolezza dell’imputato “oltre ogni ragionevole dubbio”. Le regole del processo penale sono state progettate per garantire che non ci sia (quasi) nessuna possibilità di condannare ingiustamente un imputato innocente: il processo penale è progettato (almeno in teoria) per proteggere i diritti dell’imputato. Detto in altri termini, il processo penale non mette sullo stesso piano i due tipi di errore che si possono commettere: punire un innocente o assolvere un colpevole. L’errore che consiste nel punire un innocente viene considerato assai più grave di quello che porta ad assolvere un colpevole.\nUn test statistico fa praticamente la stessa cosa: i test di ipotesi statistiche sono costruiti in modo tale da controllare la probabilità di un errore di I tipo, con l’obiettivo di mantenerla al di sotto di una certa soglia prefissata. Questa probabilità, denotata con \\(\\alpha\\), viene chiamata “livello di significatività del test”. Usando parole diverse, possiamo dire che un test di ipotesi ha un livello di significatività \\(\\alpha\\) se il tasso di errore di I tipo non è più grande di \\(\\alpha\\). Per convenzione, i ricercatori fanno uso di tre diversi livelli \\(\\alpha\\): 0.05, 0.01 e 0.001.\n\n71.13.2 Errore di II tipo: l’asimmetria del giudizio\nChe dire del tasso di errore di II tipo? In realtà, vorremmo tenere anche quello sotto controllo e denotiamo la probabilità di un errore di II tipo con \\(\\beta\\). Il livello d’errore \\(\\beta\\) viene raramente discusso ed è molto più comune fare riferimento alla potenza del test, che è la probabilità dell’evento complementare, ovvero la probabilità con cui rifiutiamo l’ipotesi nulla quando è realmente falsa, ovvero \\(1-\\beta\\). Un test viene detto “potente” quando è caratterizzato da un piccolo valore \\(\\beta\\) pur mantenendo il livello \\(\\alpha\\) sotto una piccola soglia di probabilità prefissata.\nSi noti l’asimmetria qui rivelata: i test di ipotesi sono progettati per garantire che il livello \\(\\alpha\\) sia mantenuto sotto la soglia prefissata, ma non esiste alcuna corrispondente garanzia a proposito di \\(\\beta\\). Sicuramente è preferibile che il tasso di errore di II tipo sia piccolo, e in generale i ricercatori cercano di progettare i loro esperimenti in maniera tale da avere una ragionevole potenza del test (\\(1 - \\beta\\)) – questo si ottiene utilizzando un campione sufficientemente grande – ma nella logica della costruzione del test di ipotesi questo aspetto è secondario rispetto alla necessità di controllare il tasso di errore di I tipo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.14 Come si costruisce un test di ipotesi?",
    "text": "71.14 Come si costruisce un test di ipotesi?\nRitorniamo all’esempio relativo allo studio di Mehr et al. (2016). In questo caso, sulla base all’ipotesi della ricerca, l’ipotesi nulla può essere formulata come \\(H_0: \\mu \\leq 0.5\\). Esaminando un campione di 32 bambini di età media pari a 5.6 mesi, Mehr et al. (2016) hanno scoperto che, in media, i bambini dirigevano lo sguardo verso il video “familiare” nel 56% del tempo totale di fissazione. Dunque, la media campionaria è \\(\\bar{X} = 0.56\\) Questo è il valore campionario rilevante per il test dell’ipotesi nulla.\nIngenuamente, potremmo pensare che, per decidere se \\(H_0\\) sia falsa o meno, sia sufficiente confrontare la proporzione calcolata nel campione con il valore \\(\\pi\\) specificato dall’ipotesi nulla. Nel caso presente, l’ipotesi nulla non specifica un unico valore \\(\\mu\\) ma bensì un intervallo di valori: \\([0, 0.5]\\). I dati campionari specificano un valore \\(\\bar{X} = 0.56\\), ovvero un valore che non è incluso nell’intervallo specificato da \\(H_0\\). Questo è incoraggiante. Se invece avessimo osservato \\(\\bar{X} = 0.41\\), per esempio, allora non ci sarebbe stato nient’altro da dire: se i dati osservati sono compatibili con \\(H_0\\) non c’è bisogno di eseguire alcun test statistico – abbiamo già trovato la risposta alla domanda della ricerca.\n\n71.14.1 La variabilità campionaria\nNel caso dell’esperimento di Mehr et al. (2016) che stiamo discutendo, \\(\\bar{X}\\) non cade nell’intervallo specificato da \\(H_0\\). Sulla base del valore osservato \\(\\bar{X} = 0.56\\) possiamo dunque concludere che \\(H_0\\) è falsa? Non così presto. Non è sufficiente trovare una differenza \\(\\bar{X} - \\mu\\) nella direzione giusta (cioè positiva, nel nostro caso). È anche necessario tenere in considerazione il fenomeno della variabilità campionaria.\nInfatti, la media \\(\\bar{X}\\) osservata in ogni singolo campione di ampiezza \\(n=32\\) è una variabile aleatoria: in ciascun possibile campione di ampiezza 32 i bambini si comportano in maniera diversa e, di conseguenza, \\(\\bar{X}\\) assumerà un valore diverso da campione a campione. Le statistiche campionarie – nel nostro caso la media \\(\\bar{X}\\) – sono di necessità diverse dai parametri. Ciò a cui noi siamo interessati è la media della popolazione, ovvero \\(\\mu\\), ma sfortunatamente conosciamo solo una sua realizzazione campionaria, ovvero \\(\\bar{X}\\).\nRisulta dunque chiaro che la nostra decisione rispetto ad \\(H_0\\) non può essere unicamente basata sulla differenza tra \\(\\bar{X} - \\mu\\). Infatti, è ragionevole pensare che, indipendentemente dal fatto che l’ipotesi nulla sia vera o meno, in alcuni campioni la differenza \\(\\bar{X} - \\mu\\) sarà positive mentre in altri campioni sarà negativa. Dobbiamo dunque trovare una procedura che riduca la possibilità di rifiutare \\(H_0\\) per effetto del caso soltanto. Possiamo (e dobbiamo) fare di meglio che considerare unicamente la differenza \\(\\bar{X} - \\mu\\).\n\n71.14.2 Le distribuzioni delle statistiche test\nIl metodo seguito dall’approccio frequentista per affrontare questo problema è quello di costruire la distribuzione della statistica test \\(\\mathcal{G}_n\\), rilevante per il test di \\(H_0\\), assumendo come vera l’ipotesi nulla. Questo è il concetto più contro-intuitivo di tutta la procedura di test di ipotesi dell’approccio frequentista. Esaminiamolo più in dettaglio.\nLo scopo della procedura di test statistici dell’approccio frequentista non è quello di verificare l’ipotesi alternativa: questo non è logicamente possibile. Invece, come suggerito dalla similitudine del processo penale all’ipotesi nulla, l’approccio frequentista si pone l’obiettivo di determinare se ci siano indizi sufficienti per “condannare” l’ipotesi nulla, ovvero, per rigettarla. In questa reductio ad absurdum, la “presunzione di innocenza” di \\(H_0\\) corrisponde all’idea che dobbiamo assumere come vera l’ipotesi nulla fino a prova contraria.\nNell’esempio che stiamo discutendo, assumere come vera l’ipotesi nulla significa assumere che il parametro \\(\\mu\\) (la media della popolazione) sia uguale a 0.5. Sulla base di questa assunzione, per i dati dell’esempio presente, è possibile costruire la distribuzione delle medie dei campioni di ampiezza 32. Standardizzando poi la media del campione, è possibile stabilire quanto sia “distante” dal valore atteso della distribuzione campionaria costruita assumento come vera \\(H_0\\).\nLa standardizzazione di \\(\\bar{X}\\) si effettua mediante il rapporto\n\\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}},\n\\]\ndove \\(\\bar{X}\\) è la media del campione (nel nostro caso, 0.56), \\(s\\) è la deviazione standard del campione (gli autori riportano \\(s\\) = 0.179) e \\(n\\) è l’ampiezza del campione (ovvero, \\(n\\) = 32). Per il caso presente otteniamo:\n\nT &lt;- (0.56 - 0.50) / (0.179 / sqrt(32))\nprint(T)\n#&gt; [1] 1.896\n\n\n71.14.3 Regioni di rifiuto e regioni di non rifiuto\nConoscendo la distribuzione dei valori della statistica test (distribuzione determinata assumendo come vera \\(H_0\\)) diventa poi possibile dividere l’insieme dei valori possibili di \\(\\mathcal{G}_n\\) (il nome che abbiamo assegnato ad una generica statistica test) in due regioni: i valori che ci portano a rigettare \\(H_0\\) (regione di rifiuto) e quelli che non ci consentono di rigettare \\(H_0\\) (regione di non rifiuto).\nPer decidere quanto deve essere grande la regione di rifiuto di \\(H_0\\) è sufficiente collocare nella regione di rifiuto i valori estremi della statistica test \\(\\mathcal{G}_n\\), ovvero quelli che sarebbe molto improbabile osservare se \\(H_0\\) fosse vera.\n\n71.14.4 Quando rifiutare l’ipotesi nulla\nSupponiamo che la figura seguente rappresenti la distribuzione campionaria della statistica test \\(\\mathcal{G}_n\\).\n\nSe i dati producono la statistica test \\(\\mathcal{G}_n^1\\), non possiamo rifiutare l’ipotesi nulla \\(H_0\\). Se invece i dati producono \\(\\mathcal{G}_n^2\\) allora possiamo rifiutare l’ipotesi nulla in favore dell’ipotesi alternativa. Ci sono varie cose da notare.\n\nLa regione di rifiuto è costituita da valori lontani dal centro della distribuzione campionaria della statistica test, la quale è stata costruita assumendo come vera \\(H_0\\).\nLa regione di rifiuto è situata nelle code della distribuzione. Vedremo in seguito anche degli esempi di regioni di rifiuto unilaterali.\nIn questa discussione, l’ipotesi alternativa non è menzionata. Rifiutiamo o non rifiutiamo \\(H_0\\) basandoci unicamente sulla distribuzione campionaria \\(f(\\mathcal{G}_n \\mid H_0)\\), cioè sulla probabilità della statistica test condizionata all’ipotesi nulla \\(H_0\\). L’ipotesi alternativa \\(H_1\\) viene presa in considerazione quando si sceglie dove posizionare la regione di rifiuto di \\(H_0\\), ma formalmente non gioca alcun ruolo nel rigettare o meno \\(H_0\\).\n\n71.14.5 Specificazione delle regioni di rifiuto\nL’ipotesi alternativa \\(H_1\\) può assumere forme diverse e ciò conduce a specificazioni diverse della regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\). La regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla corrisponde ai valori collocati agli estremi della distribuzione secondo la direzione dell’ipotesi alternativa \\(H_1\\).\n\nSe l’ipotesi alternativa è \\(H_1: \\theta \\neq \\theta_0\\) (dove \\(\\theta\\) è un generico parametro e \\(\\theta_0\\) è uno specifico valore del parametro), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute negli intervalli \\([-\\infty, \\theta_0]\\) e \\([\\theta_0, +\\infty]\\).\nSe l’ipotesi alternativa è \\(H_1: \\theta &lt; \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([-\\infty, \\theta_0]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di sinistra della distribuzione.\nSe l’ipotesi alternativa è \\(H_1: \\theta &gt; \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([\\theta_0, \\infty]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di destra della distribuzione.\n\nSi chiamano valori critici i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bilaterale. In un test bidirezionale, i valori critici lasciano in ciascuna delle due code della distribuzione della statistica test una probabilità pari a \\(\\alpha/2\\); in un test unidirezionale lasciano una probabilità pari ad \\(\\alpha\\) in una sola coda. Il risultato di un test si dice statisticamente significativo quando il valore della statistica test ricade nella regione di rifiuto \\(\\mathcal{R}\\).\n\n71.14.6 La decisione statistica\nIl processo di decisione statistica viene descritto da von Mises (1964) nel modo seguente:\n\nControllare (checking) o saggiare (testing) ha la forma seguente: se il “risultato osservato” ha una ‘piccola’ probabilità subordinatamente all’ipotesi assunta, respingiamo l’ipotesi. (p. 441)\n\nOvviamente l’ipotesi a cui von Mises fa riferimento è l’ipotesi nulla.\nIn pratica, possiamo decidere se rigettare o meno l’ipotesi nulla in due modi: determinando se la statistica test \\(\\mathcal{G}_n\\) cade o meno nella regione di rifiuto (come abbiamo descritto sopra) o confrontando il valore-\\(p\\) con \\(\\alpha\\) – i due metodi sono equivalenti.\nIl valore-p rappresenta la probabilità di osservare un valore della statistica test \\(\\mathcal{G}_n\\) pari a quello effettivamente osservato, o maggiore, quanto l’ipotesi nulla è vera. Se il valore-\\(p\\) è minore del livello di significatività \\(\\alpha\\), allora la statistica test cade nella regione di rifiuto di \\(H_0\\) e ciò conduce al rifiuto dell’ipotesi nulla. Tali concetti sono riassunti nella tabella seguente.\n\nPer l’esempio in discussione, la statistica \\(T\\) calcolata sopra si distribuisce come \\(t\\) di Student con \\(\\nu = 31\\) gradi di libertà. Il valore-p corrisponde dunque all’area sottesa ad una \\(t_{31}\\) nell’intervallo \\([1.896, +\\infty]\\) (test unidirezionale destro), ovvero\n\n# Calculate the upper tail probability for the t-distribution\np &lt;- 1 - pt(T, df = 31)\nprint(p)\n#&gt; [1] 0.03365\n\nDato che il valore-p è minore di \\(\\alpha = 0.05\\), Mehr et al. (2016) rifiutano \\(H_0\\) (cioè che la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” sia 0.5, o minore) e concludono che i bambini mostrano una preferenza per il video familiare.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#potenza-del-test",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#potenza-del-test",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.15 Potenza del test",
    "text": "71.15 Potenza del test\nRitorniamo ora al concetto di potenza del test. Il livello di significatività e la potenza del test vengono usati per quantificare la qualità dell’inferenza statistica. Idealmente, la procedura di test di ipotesi non dovrebbe giungere alla conclusione sbagliata. Ovvero, non dovrebbe respingere \\(H_0\\) quando essa è vera e dovrebbe respingere \\(H_0\\) in favore dell’alternativa quando \\(H_1\\) è vera. Ma questi sono solo due dei quattro esiti che, in principio, sono possibili, e corrispondono alle probabilità indicate di seguito.\n\nPossiamo pensare a \\(H_0\\) come all’ipotesi che descrive l’evento “nulla di interessante sta succedendo” – ad esempio, “la moneta è bilanciata”, “il trattamento non è migliore del placebo”, ecc. – e pensare ad \\(H_1\\) come al caso contrario, ovvero: “sta accadendo qualcosa di interessante”. Quindi la potenza del test, ovvero la probabilità \\(1 - \\beta\\) di rigettare \\(H_0\\) quando essa è falsa, corrisponde alla probabilità di rilevare qualcosa di interessante, quando qualcosa di interessante è effettivamente successo, mentre il livello di significatività corrisponde alla probabilità di affermare che qualcosa di interessante si è verificato, quando in realtà non è successo nulla di interessante.\nIl calcolo della potenza di un test è spesso difficile, perché richiede la conoscenza della distribuzione campionaria di \\(\\mathcal{G}_n\\) quando è vera l’ipotesi alternativa \\(H_1\\). Tipicamente possiamo aumentare la potenza di un test aumentando la numerosità del campione in maniera tale da diminuire la varianza delle distribuzioni della statistica test condizionate a \\(H_0\\) e ad \\(H_1\\). In un disegno sperimentale è importante determinare in anticipo il numero di prove o dei soggetti necessari per raggiungere la potenza desiderata.\n\n71.15.1 Neyman e Fisher\nLa procedura di test di ipotesi statistiche descritta sopra combina due approcci teorici diversi, proposti da Sir Ronald Fisher e Jerzy Neyman. La storia di questi due approcci non è lineare, poiché Fisher e Neyman hanno modificato le loro opinioni nel tempo, senza mai fornire una “verità definitiva” su come interpretare il loro lavoro.\nIn sintesi, Fisher considerava che il ricercatore avesse un’unica ipotesi (quella nulla) e che lo scopo fosse verificare se i dati fossero coerenti o meno con essa. In questo senso, il valore-\\(p\\) rappresenta la probabilità di osservare, sotto l’ipotesi nulla, il risultato ottenuto o uno ancora più estremo. Se il valore-\\(p\\) è piccolo, Fisher rifiutava l’ipotesi nulla. Tuttavia, poiché non venivano formulate altre ipotesi, non c’era modo di “accettare l’alternativa”.\nAl contrario, Neyman adottava un approccio più formale rispetto a Fisher e pensava che lo scopo della verifica delle ipotesi fosse quello di prendere decisioni. Secondo Neyman, il problema era decidere se accettare l’ipotesi nulla o l’alternativa e il test serviva a stabilire quale supporto venisse fornito alle due alternative. Per questo motivo, era fondamentale specificare in modo preciso l’ipotesi alternativa. Nel suo approccio, il valore-\\(p\\) non misurava la probabilità del risultato del test o di uno più estremo sotto l’ipotesi nulla, ma forniva una descrizione astratta dei “possibili test” che portavano all’accettazione dell’ipotesi nulla o dell’alternativa.\nAttualmente ci troviamo in una situazione strana e ambigua, dove sono presenti elementi di entrambi gli approcci. La procedura di verifica di ipotesi statistiche distingue tra un’ipotesi nulla e un’ipotesi alternativa, seguendo la visione di Neyman, ma definisce il valore-\\(p\\) in termini di dati estremi, come avrebbe fatto Fisher, in confronto con un livello \\(\\alpha\\) stabilito da Neyman. Alcuni test statistici specificano in modo chiaro l’ipotesi alternativa, mentre altri sono più vaghi in merito, adottando l’approccio di Fisher. Inoltre, c’è disaccordo tra i ricercatori riguardo alla possibilità di “accettare l’alternativa”, a seconda che si segua Neyman o Fisher. Questa confusione costituisce il “peccato originale” della procedura di verifica di ipotesi statistiche. Tuttavia, ci sono motivi più specifici per cui questo approccio, noto come significatività statistica, viene criticato da molti ricercatori come una delle cause principali della crisi della replicabilità dei risultati della ricerca in psicologia e in altri campi. Nel capitolo ?sec-errors-s-m esploreremo queste ragioni in dettaglio.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.16 La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni",
    "text": "71.16 La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni\nConcludiamo l’analisi della procedura dei test di ipotesi statistici esaminando l’evento che ha ispirato Ronald A. Fisher a sviluppare la sua teoria dell’inferenza statistica, focalizzata sul test dell’ipotesi nulla. Questo episodio è descritto dettagliatamente da Etz et al. (2018). L’aneddoto riguarda un tè che Fisher aveva offerto alla sua collega, la Dott.ssa Muriel Bristol. Durante la preparazione della bevanda, la Dr.ssa Bristol contestò il metodo adottato da Fisher, asserendo che il tè avrebbe avuto un gusto migliore se il latte fosse stato versato prima dell’acqua bollente. Per verificare l’affermazione della Dr.ssa Bristol, Fisher ideò un esperimento di discriminazione sensoriale. Nei test condotti, la Dr.ssa Bristol fu in grado di individuare correttamente il processo di preparazione del tè in cinque occasioni su sei.\nQuesto risultato pose Fisher di fronte a un interrogativo: la sua collega stava semplicemente facendo una supposizione fortunata, oppure era effettivamente in grado di discernere tra le due diverse modalità di preparazione? Per risolvere questa questione, Fisher elaborò la sua metodologia per il test dell’ipotesi nulla. Utilizzò un valore-\\(p\\) calcolato sulla base della probabilità dell’evento osservato, nonché di qualsiasi altro evento più estremo che potrebbe verificarsi sotto l’ipotesi nulla.\nTuttavia, è stato fatto notare che l’approccio di Fisher al test dell’ipotesi nulla può essere insufficiente e portare a conclusioni errate (Etz et al., 2018). Una delle questioni fondamentali riguarda la definizione di un evento “più estremo” rispetto a quello osservato.\nSupponiamo che lo scopo dell’esperimento casuale sia di determinare l’accuratezza delle riposte della Dr.ssa Bristol in esattamente sei tentativi (e non di più). In tale caso, con 5 risposte corrette, il valore-\\(p\\) è pari a 0.109, che non è statisticamente significativo. In questo scenario, secondo la logica di Fisher, non si dovrebbe respingere l’ipotesi nulla che la Dr. Bristol stesse semplicemente indovinando.\nSupponiamo ora che lo scopo dell’esperimento casuale sia di continuare a servire tè fino a quando la Dr.ssa Bristol non abbia raggiunto cinque risposte corrette (un risultato che, per coincidenza, si è verificato dopo sei tentativi). Se analizziamo i dati in questo secondo scenario, il valore-\\(p\\) diventa pari a 0.031, che è statisticamente significativo. In quest’ultimo caso, l’ipotesi nulla verrebbe respinta.\nQuello che emerge è che, nonostante i dati osservati nei due scenari siano identici, giungiamo a conclusioni opposte come conseguenza delle diverse modalità di campionamento impiegate. Questa variabilità è problematica poiché il valore-\\(p\\), e quindi la nostra valutazione delle capacità discriminative della Dr.ssa Bristol, dipendono non solo dai dati effettivamente raccolti, ma anche dal disegno sperimentale adottato. Questa constatazione mette in discussione la robustezza del test dell’ipotesi nulla come strumento fondamentale per l’inferenza scientifica.\nPer illustrare il problema, svolgiamo i calcoli utilizzando le distribuzioni statistiche richieste per i due tipi di campionamento: la distribuzione binomiale e la distribuzione geometrica negativa.\n\n71.16.1 Distribuzione Binomiale\nLa distribuzione binomiale è la distribuzione da utilizzare quando il numero di tentativi è prefissato e conosciuto a priori. Nel contesto dell’esempio del tè, assumiamo che siano state servite esattamente sei tazze. La formula per determinare la probabilità di registrare esattamente \\(k\\) successi in \\(n\\) tentativi è la seguente:\n\\[\nP(X = k) = \\binom{n}{k} \\times p^k \\times (1-p)^{(n-k)}\n\\]\nQui, \\(\\binom{n}{k}\\) rappresenta il coefficiente binomiale, \\(p\\) è la probabilità di un singolo successo (ossia di indovinare correttamente la preparazione del tè), e \\((1-p)\\) è la probabilità di un singolo fallimento.\nPer calcolare il valore-\\(p\\) in questo specifico contesto, dobbiamo sommare le probabilità di ottenere un risultato di 5 o più estremo su un totale di 6 tentativi.\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success\n\n# Calculate the p-value for the binomial distribution\np_value_binomial &lt;- 1 - pbinom(n_success - 1, size = n_binomial, prob = p)\n\np_value_binomial\n#&gt; [1] 0.1094\n\n\n71.16.2 Distribuzione Geometrica Negativa\nNel contesto dell’esperimento del tè, quando il test continua fino al raggiungimento di un numero prefissato di successi (nel nostro caso, cinque identificazioni corrette), la distribuzione di riferimento appropriata è la distribuzione geometrica negativa.\nLa distribuzione geometrica negativa modella il numero di fallimenti \\(k\\) che si verificano prima di ottenere un numero prefissato \\(r\\) di successi in una sequenza di prove indipendenti di Bernoulli, dove ogni prova ha probabilità di successo \\(p\\).\nLa probabilità di osservare esattamente \\(k\\) fallimenti prima di ottenere \\(r\\) successi è data da:\n\\[\nP(X = k) = \\binom{k+r-1}{k} p^r (1-p)^k,\n\\]\ndove:\n\n\n\\(k\\) è il numero di fallimenti,\n\n\\(r\\) è il numero di successi desiderato,\n\n\\(p\\) è la probabilità di successo in ogni prova,\n\n\\(\\binom{k+r-1}{k}\\) è il coefficiente binomiale che rappresenta il numero di modi possibili in cui \\(k\\) fallimenti e \\(r\\) successi possono essere ordinati.\n\nNel nostro caso specifico:\n\n\n\\(r = 5\\) (successi desiderati),\n\n\\(p = 0.5\\) (probabilità di indovinare correttamente sotto l’ipotesi nulla),\n\n\\(k\\) varia da 0 a 1 (possibili fallimenti prima del quinto successo).\n\nIl valore-p si calcola sommando le probabilità per tutti i casi “più estremi” di quello osservato:\n\\[\n\\text{valore-p} = \\sum_{k=0}^{1} \\binom{k+5-1}{k} (0.5)^5 (0.5)^k.\n\\]\nImplementazione:\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success (guessing the tea cup)\n\n# Calculate the p-value for the negative binomial distribution\np_value_geom_corrected &lt;- 0\nfor (k in 0:(n_binomial - n_success - 1)) {  # Number of failures before the 5th success\n  p_value_geom_corrected &lt;- p_value_geom_corrected + \n    choose(k + n_success - 1, k) * ((1 - p)^k) * (p^n_success)\n}\n\np_value_geom_corrected\n#&gt; [1] 0.03125\n\nIn conclusione,\n\nper la distribuzione binomiale, il p-value è \\(0.109\\), che non è statisticamente significativo (dato che è maggiore di 0.05); quindi, secondo Fisher, in questo caso non dovremmo rigettare l’ipotesi nulla che Dr. Bristol stia indovinando.\nper la distribuzione geometrica negativa, il p-value è \\(0.031\\), che è statisticamente significativo (dato che è minore di 0.05); in questo caso, dovremmo rigettare l’ipotesi nulla, suggerendo che Dr. Bristol non sta semplicemente indovinando.\n\nLa presente discussione mostra che, in base alla procedura del test dell’ipotesi nulla, la stessa sequenza di eventi (5 successi su 6 tentativi) può portare a conclusioni opposte a seconda delle ipotesi sul processo di campionamento. Questo paradosso è uno dei motivi (per ulteriori critiche, si veda Wasserstein & Lazar (2016); Benjamin et al. (2018)) per cui l’inferenza bayesiana è diventata più popolare negli ultimi anni come quadro alternativo per il test delle ipotesi e la stima dei parametri.\n\n71.16.3 Approccio Bayesiano\nNel loro lavoro, Etz et al. (2018) propongono un’alternativa bayesiana per risolvere il problema esaminato da Fisher. Questa soluzione bayesiana evita le contraddizioni che emergono quando si cercano di definire “risultati più estremi” che non sono stati osservati. L’approccio bayesiano si focalizza esclusivamente sui dati effettivamente raccolti e utilizza queste osservazioni per aggiornare le probabilità iniziali (o “a priori”) associate a diverse ipotesi. Il processo si basa sulla regola di Bayes e si sviluppa in tre fasi principali:\n\nStabilire Probabilità a Priori: Iniziamo assegnando una distribuzione di probabilità a priori a tutti i possibili tassi di successo che la Dr. Bristol potrebbe avere. Questo include una probabilità specifica per l’ipotesi nulla, che suggerisce che la Dr. Bristol stia semplicemente indovinando (con un tasso di successo del 50%).\nAggiornare le Probabilità con Dati Osservati: Utilizziamo i dati raccolti nell’esperimento per aggiornare le nostre probabilità a priori. Questo aggiornamento è fatto utilizzando la regola di Bayes.\nCalcolare il Fattore di Bayes: Questa metrica ci dice quanto i dati osservati influenzano le probabilità delle diverse ipotesi. Un Fattore di Bayes molto maggiore di 1 indicherebbe un forte supporto per l’ipotesi alternativa rispetto all’ipotesi nulla.\n\nNel caso specifico, il Fattore di Bayes calcolato è risultato essere circa 147.33, un valore notevolmente alto. Questo suggerisce che i dati osservati sono molto più compatibili con l’ipotesi che la Dr.ssa Bristol possa effettivamente distinguere tra le diverse preparazioni del tè, piuttosto che con l’ipotesi che stia indovinando.\nEtz et al. (2018) concludono che l’approccio bayesiano offre un quadro più robusto e coerente per il test delle ipotesi. A differenza del metodo frequentista, esso non dipende dalla definizione di “risultati più estremi” non osservati e si concentra invece esclusivamente sui dati effettivamente raccolti. Questa focalizzazione, in generale, rende l’approccio bayesiano una soluzione più solida per valutare le ipotesi scientifiche. Per una rivisitazione bayesiana dell’esperimento “The Lady Tasting Tea”, si veda anche la discussione di Doorn et al. (2020).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#malintesi-sul-valore-p",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#malintesi-sul-valore-p",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.17 Malintesi sul valore-p",
    "text": "71.17 Malintesi sul valore-p\nSono diffusi molti malintesi sul valore-p. Ne esaminiamo qui quelli più comuni.\nMalinteso 1: Un valore p non significativo significa che l’ipotesi nulla è vera.\nIl malinteso che un valore p non significativo (p &gt; 0.05) implichi l’assenza di effetto o la verità dell’ipotesi nulla è diffuso e porta a conclusioni errate. La chiave per evitare questo errore sta nel comprendere che i valori p riflettono la probabilità dei dati osservati sotto l’ipotesi nulla, e non la probabilità dell’ipotesi stessa. Un valore p elevato non dimostra che l’ipotesi nulla sia vera, ma indica semplicemente che i dati osservati non sono sufficientemente insoliti da rifiutare l’ipotesi nulla con un livello di confidenza predefinito.\nRisultati non significativi possono verificarsi anche quando esiste un effetto reale, ma i dati non sono abbastanza estremi da superare la soglia di significatività statistica.\nInvece di concludere affrettatamente l’assenza di effetto da un valore p non significativo, dovremmo riconoscere l’ambiguità e considerare altre possibilità. Dichiarazioni come “non c’era differenza” dovrebbero essere riformulate in termini di assenza di differenza statisticamente significativa, lasciando aperta la questione dell’esistenza di un effetto reale.\nL’approccio bayesiano offre una prospettiva diversa che può essere particolarmente utile per interpretare risultati non significativi. A differenza dei valori p, che si limitano a valutare la probabilità dei dati sotto l’ipotesi nulla, l’inferenza bayesiana permette di calcolare direttamente la probabilità delle ipotesi date i dati.\nL’approccio bayesiano, quindi, non si limita a rifiutare o non rifiutare l’ipotesi nulla, ma quantifica la forza dell’evidenza a favore di un’ipotesi rispetto all’altra, fornendo una conclusione più informativa rispetto al semplice “non posso rifiutare l’ipotesi nulla”.\nMalintesto 2: Un valore p significativo significa che l’ipotesi nulla è falsa.\nCome spiegato in precedenza, il valore-p quantifica la “sorpresa” suscitata dai dati, alla luce dell’ipotesi nulla. Non ci dice niente sull’ipotesi che abbiamo assunto per quantificare la “sorpresa”.\nMalinteso 3: Un valore p significativo significa che è stato scoperto un effetto importante.\nLa distinzione tra “significatività statistica” e “rilevanza pratica” è fondamentale: mentre la prima indica semplicemente che un risultato è improbabile sotto l’ipotesi nulla, la seconda valuta l’effetto nel contesto di applicazioni reali e le sue implicazioni.\nUn effetto statisticamente significativo non garantisce che l’effetto abbia un impatto pratico notevole o utile.\nInoltre, al di là della significatività pratica, l’abitudine di molti psicologi di escludere i predittori che non risultano “statisticamente significativi” è un grossolano errore: la significatività statistica non può essere usata come un metodo per la selezione di variabili in un modello statistico.\nUn p &lt; 0.05 indica che, se l’ipotesi nulla è vera, abbiamo osservato dati che dovrebbero essere considerati sorprendenti. Tuttavia, solo perché i dati sono sorprendenti, non significa che dobbiamo preoccuparcene. È principalmente l’etichetta verbale “significativo” che causa confusione qui: in un contesto frequentista, un effetto “significativo” è un effetto “sorprendente” alla luce di \\(H_0\\), non è necessariamente un effetto “importante”.\nMalinteso 4: Se avete osservato un risultato significativo, la probabilità che abbiate commesso un errore di Tipo 1 (un falso positivo) è del 5%.\nIl malinteso che la presenza di un risultato significativo (per esempio, p &lt; 0.05) indichi una probabilità del 5% di aver commesso un errore di Tipo 1 (falso positivo) riflette una comprensione errata della statistica frequentista. La probabilità del 5% si riferisce al tasso di errore di Tipo 1, che è la proporzione di volte che potremmo aspettarci di rifiutare erroneamente l’ipotesi nulla se questa fosse vera, su molteplici ripetizioni dell’esperimento sotto le stesse condizioni. In altre parole, se potessimo ripetere lo stesso studio infinite volte, osserveremmo risultati falsamente positivi nel 5% di questi studi, assumendo che l’ipotesi nulla sia effettivamente vera in ogni caso.\nTuttavia, una volta che abbiamo raccolto i dati e ottenuto un risultato significativo in un unico studio, non possiamo dire che “la probabilità che questo particolare risultato sia un errore di Tipo 1 è del 5%”. In realtà, in quel momento specifico, l’evento (commettere un errore di Tipo 1) è già accaduto o non è accaduto; la probabilità associata a quel singolo risultato non è più applicabile nel modo in cui potremmo aspettarci intuitivamente. Il risultato è, per così dire, una realtà fissa: o abbiamo rilevato un effetto che in realtà non esiste (errore di Tipo 1), oppure abbiamo correttamente identificato un effetto reale. Senza ulteriori esperimenti o dati, non possiamo determinare con certezza in quale di queste categorie cade il nostro risultato.\nIn breve, il tasso del 5% di errore di Tipo 1 non si applica retroattivamente a un singolo risultato ottenuto, ma piuttosto descrive il comportamento a lungo termine di un test statistico sotto ripetute campionature. Questa distinzione è cruciale per una corretta interpretazione dei risultati degli esperimenti e sottolinea l’importanza di non sovrastimare la certezza di un singolo risultato statistico significativo.\nMalinteso 5: Uno meno il valore p è la probabilità che l’effetto si replichi quando ripetuto.\nIl concetto che 1 meno il valore p rappresenti la probabilità di replicazione di un effetto è un malinteso diffuso. In realtà, la probabilità di replicazione di un effetto non può essere direttamente calcolata dal valore p di un singolo studio a causa della complessità dei fattori coinvolti, tra cui la vera differenza media tra i gruppi. La potenza statistica di un test, che dipende dalla dimensione dell’effetto, dalla dimensione del campione e dal livello di significatività α, fornisce una stima della probabilità di rilevare un effetto significativo se questo effetto esiste davvero. Tuttavia, osservare un effetto significativo in un unico studio (ad esempio, p = 0.03) non significa che vi sia una probabilità del 97% che tale effetto si replichi in studi futuri. La possibilità di replicare un risultato dipende dalla presenza di un vero effetto e dalla potenza statistica del test originale.\nIn sintesi, la replicabilità di un effetto è influenzata da molti fattori e non può essere inferita semplicemente dal valore p di un singolo risultato. La comprensione e l’interpretazione corrette della replicabilità richiedono un’analisi dettagliata della potenza statistica e della dimensione dell’effetto, oltre che della consistenza dei risultati attraverso studi multipli.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#riflessioni-conclusive",
    "title": "\n71  Significatività statistica\n",
    "section": "\n71.18 Riflessioni Conclusive",
    "text": "71.18 Riflessioni Conclusive\nIl presente capitolo ha messo in evidenza le numerose limitazioni e i potenziali pericoli dell’approccio frequentista al test dell’ipotesi nulla, portando alla luce una serie di paradossi e malintesi che minano la sua validità come strumento primario per l’inferenza scientifica. In particolare, abbiamo visto come il valore-p, spesso utilizzato come metro di giudizio assoluto per decidere se un risultato è significativo o meno, possa condurre a conclusioni fuorvianti, dipendendo non solo dai dati osservati ma anche dal contesto sperimentale e dalle scelte soggettive del ricercatore. Questo approccio, che si basa su una logica binaria di “accettare” o “rifiutare” l’ipotesi nulla, sembra incapace di cogliere la complessità delle relazioni causali e degli effetti reali presenti nei fenomeni psicologici e sociali. Più profondamente, emerge con chiarezza che il metodo frequentista, lungi dall’essere un sistema oggettivo per la decisione statistica, è invece intriso di convenzioni arbitrarie (come il livello di significatività α = 0.05) e di una visione riduzionistica della probabilità, concepita come frequenza relativa di eventi ripetibili nel tempo piuttosto che come misura della nostra incertezza riguardo a un evento specifico.\nTuttavia, al di là delle critiche tecniche, il problema più grave risiede nella tendenza a considerare il test dell’ipotesi nulla come uno strumento definitivo per valutare la veridicità di ipotesi scientifiche, anziché come un semplice punto di partenza per ulteriori indagini. La cultura prevalente nella comunità scientifica, che premia i risultati “statisticamente significativi”, ha contribuito a creare un ambiente in cui gli studi replicabili sono rari e dove molti risultati pubblicati sono fragili e difficilmente generalizzabili. È qui che l’approccio bayesiano entra in gioco, offrendo una soluzione coerente e robusta che supera molte delle carenze del frequentismo. Al contrario del metodo frequentista, che si concentra su ipotesi nulle arbitrariamente definite e sulle distribuzioni campionarie di statistiche teoriche, il bayesianesimo ci permette di incorporare informazioni pregresse (prior) e di aggiornare queste conoscenze in base ai dati osservati, fornendo una stima diretta della probabilità delle ipotesi di interesse. Questo approccio, che mette al centro la nozione di evidenza, permette di quantificare la forza delle prove a favore di diverse ipotesi, evitando così le dicotomie rigide tra “significativo” e “non significativo” e promuovendo una visione più sfumata e matematicamente fondata dell’inferenza statistica.\nIn conclusione, il test dell’ipotesi nulla frequentista, pur essendo ampiamente utilizzato, rappresenta uno degli aspetti più controversi e problematici dell’approccio tradizionale. La sua rigidità metodologica e la dipendenza da concetti come il valore p e la significatività statistica lo rendono non solo impreciso, ma anche inadeguato a cogliere la complessità dei fenomeni che la ricerca psicologica si propone di esplorare. Abbandonare questo paradigma non è solo una questione di precisione tecnica, ma di superare una mentalità riduzionista che limita la nostra capacità di interpretare i dati in modo sfumato e contestuale.\nL’adozione di metodologie bayesiane, al contrario, offre un quadro più dinamico e flessibile, in cui le ipotesi non sono semplicemente accettate o rifiutate, ma valutate in termini probabilistici. Questo approccio incoraggia un confronto diretto tra modelli e ipotesi contrapposte, permettendo di aggiornare le nostre credenze alla luce dei nuovi dati. Non si tratta solo di un miglioramento tecnico nelle inferenze scientifiche, ma di un invito a ripensare il modo in cui concepiamo la conoscenza e il processo di scoperta. La prospettiva bayesiana, infatti, enfatizza l’incertezza come parte intrinseca della ricerca, trasformandola in uno strumento per affinare le nostre comprensioni piuttosto che un ostacolo da superare.\nIn un contesto psicologico intrinsecamente complesso e caratterizzato da incertezza, l’approccio bayesiano rappresenta un’opportunità per adottare un’epistemologia più flessibile e razionale. La sua forza risiede nella capacità di adattarsi alla natura multifattoriale dei fenomeni psicologici, integrando in modo coerente e trasparente sia le conoscenze pregresse sia le nuove evidenze. In questo senso, l’adozione del paradigma bayesiano non è soltanto un avanzamento metodologico, ma anche un passo verso una scienza più consapevole, critica e adatta alle sfide della psicologia contemporanea.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n71  Significatività statistica\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.10.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        Rdpack_2.6.2      vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    pan_1.9          \n#&gt; [13] pacman_0.5.1      jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-2     \n#&gt; [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [21] mnormt_2.1.1      codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64       reformulas_0.4.0 \n#&gt; [29] iterators_1.0.14  rpart_4.1.24      boot_1.3-31       mitml_0.4-5      \n#&gt; [33] foreach_1.5.2     nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37    \n#&gt; [37] stringi_1.8.4     splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0    \n#&gt; [41] grid_4.4.2        colorspace_2.1-1  cli_3.6.4         magrittr_2.0.3   \n#&gt; [45] survival_3.8-3    broom_1.0.7       withr_3.0.2       backports_1.5.0  \n#&gt; [49] timechange_0.3.0  rmarkdown_2.29    nnet_7.3-20       lme4_1.1-36      \n#&gt; [53] hms_1.1.3         evaluate_1.0.3    rbibutils_2.3     rlang_1.1.5      \n#&gt; [57] Rcpp_1.0.14       glue_1.8.0        minqa_1.2.8       rstudioapi_0.17.1\n#&gt; [61] jsonlite_1.8.9    R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#bibliografia",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#bibliografia",
    "title": "\n71  Significatività statistica\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., et al. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6–10.\n\n\nDoorn, J. van, Matzke, D., & Wagenmakers, E.-J. (2020). An in-class demonstration of Bayesian inference. Psychology Learning & Teaching, 19(1), 36–45.\n\n\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic bulletin & review, 25(1), 219–234.\n\n\nMehr, S. A., Song, L. A., & Spelke, E. S. (2016). For 5-month-old infants, melodies are social. Psychological Science, 27(4), 486–501.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html",
    "title": "\n72  Test t di Student per campioni indipendenti\n",
    "section": "",
    "text": "72.1 Introduzione\nQuesto capitolo è dedicato al test t di Student per campioni indipendenti, uno dei test statistici più utilizzati nella pratica frequentista. Il test t di Student è un metodo che permette di confrontare le medie di due gruppi diversi (o “campioni”) e determinare se la differenza osservata tra le medie sia statisticamente significativa o se possa essere attribuita a semplice casualità.\nIl test è particolarmente utile quando si ha accesso solo a piccoli campioni provenienti da popolazioni sconosciute, ma è importante comprendere bene i suoi principi fondamentali e limiti prima di applicarlo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "title": "\n72  Test t di Student per campioni indipendenti\n",
    "section": "\n72.2 Applicazioni del Test t di Student",
    "text": "72.2 Applicazioni del Test t di Student\nIl test t di Student per campioni indipendenti serve per rispondere alla domanda: “Le medie di due gruppi sono significativamente diverse?” Per esempio, potremmo voler sapere se ci sono differenze significative nel peso medio tra uomini e donne.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#assunzioni-principali",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#assunzioni-principali",
    "title": "\n72  Test t di Student per campioni indipendenti\n",
    "section": "\n72.3 Assunzioni Principali",
    "text": "72.3 Assunzioni Principali\nPrima di procedere con il test, è essenziale assicurarsi che siano valide le seguenti ipotesi:\n\n\nIndipendenza: Le osservazioni nei due campioni devono essere indipendenti.\n\nNormalità: I dati nei due campioni provengono da popolazioni distribuite normalmente.\n\nUguaglianza delle Varianze (Omoschedasticità): Le varianze delle due popolazioni da cui provengono i campioni sono uguali.\n\nSe queste condizioni non sono soddisfatte, potrebbe essere necessario considerare alternative come il test di Welch, che non richiede l’uguaglianza delle varianze.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#passaggi-del-test-t-di-student",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#passaggi-del-test-t-di-student",
    "title": "\n72  Test t di Student per campioni indipendenti\n",
    "section": "\n72.4 Passaggi del Test t di Student",
    "text": "72.4 Passaggi del Test t di Student\nEcco una panoramica dei passaggi chiave:\n\n\nCalcolare la Differenza tra le Medie: Si calcola la differenza tra le medie dei due campioni.\n\\[\n\\bar{x}_1 - \\bar{x}_2\n\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) sono le medie dei due campioni.\n\n\nStimare la Deviazione Standard Combinata: Se assumiamo che le varianze siano uguali (omoschedasticità), possiamo usare una stima combinata della deviazione standard, chiamata deviazione standard pooled \\(s_p\\):\n\\[\ns_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\n\\]\ndove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni, e \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie.\n\n\nCalcolare la Statistica t: La statistica t viene calcolata usando la formula seguente:\n\\[\nt = \\frac{(\\bar{x}_1 - \\bar{x}_2)}{s_p \\sqrt{\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}\n\\]\n\n\nDeterminare i Gradi di Libertà: I gradi di libertà (\\(df\\)) sono calcolati come:\n\\[\ndf = n_1 + n_2 - 2\n\\]\n\nCalcolare il Valore-p: Infine, si confronta la statistica t con la distribuzione t di Student per ottenere il valore-p. Questo valore indica la probabilità di osservare una differenza così estrema tra le medie dei campioni, dato che l’ipotesi nulla è vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#dimostrazione",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#dimostrazione",
    "title": "\n72  Test t di Student per campioni indipendenti\n",
    "section": "\n72.5 Dimostrazione",
    "text": "72.5 Dimostrazione\nPer dimostrare come calcolare la varianza della differenza tra due medie campionarie, consideriamo due campioni casuali indipendenti \\(X_1, X_2, \\dots, X_n\\) e \\(Y_1, Y_2, \\dots, Y_m\\), estratti dalla stessa popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo \\(\\bar{X}\\) e \\(\\bar{Y}\\) come le medie campionarie di questi due campioni, rispettivamente.\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono date da:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i ,\n\\] \\[\n\\bar{Y} = \\frac{1}{m} \\sum_{j=1}^m Y_j .\n\\]\nEntrambe le medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono stimatori non distorti della media della popolazione \\(\\mu\\). Le loro varianze sono:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n} ,\n\\] \\[\n\\text{Var}(\\bar{Y}) = \\frac{\\sigma^2}{m} .\n\\]\nSiamo interessati a calcolare la varianza della differenza \\(\\bar{X} - \\bar{Y}\\). Utilizzando le proprietà della varianza per combinazioni lineari di variabili aleatorie indipendenti, otteniamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\text{Var}(\\bar{X}) + \\text{Var}(\\bar{Y}) ,\n\\]\ndato che i termini incrociati si annullano per l’indipendenza di \\(\\bar{X}\\) e \\(\\bar{Y}\\). Sostituendo le varianze di \\(\\bar{X}\\) e \\(\\bar{Y}\\), abbiamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{m} ,\n\\] \\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\sigma^2 \\left(\\frac{1}{n} + \\frac{1}{m}\\right) .\n\\]\nQuindi, la varianza della differenza tra le due medie campionarie è una combinazione delle varianze delle singole medie, ponderate in base alle dimensioni dei campioni corrispondenti.\nPer giungere alla formula del test \\(t\\) di Student per due campioni indipendenti, dobbiamo considerare l’incertezza aggiuntiva derivante dal fatto che non conosciamo \\(\\sigma\\). Il modo migliore per stimare \\(\\sigma\\) è utilizzare le due deviazioni standard dei campioni, ponderate per i rispettivi gradi di libertà, come indicato nella formula della deviazione standard pooled:\n\\[\ns_p = \\sqrt{\\frac{(n - 1)s^2_x + (m - 1)s^2_y}{n + m - 2}},\n\\]\ndove \\(s_x\\) e \\(s_y\\) sono le deviazioni standard dei due campioni, e \\(n\\) e \\(m\\) sono le numerosità dei due campioni.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#esempio-pratico",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#esempio-pratico",
    "title": "\n72  Test t di Student per campioni indipendenti\n",
    "section": "\n72.6 Esempio Pratico",
    "text": "72.6 Esempio Pratico\nSupponiamo di avere due campioni:\n\n\nDonne: Pesi = [38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5]\n\nUomini: Pesi = [67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4]\n\nCreiamo un DataFrame in R e calcoliamo la statistica t:\n\nwomen_weight &lt;- c(38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5)\nmen_weight &lt;- c(67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4)\n\nweight &lt;- c(women_weight, men_weight)\nis_female &lt;- rep(c(1, 0), each = 9)  # 1 = Femmina, 0 = Maschio\n\ndf &lt;- data.frame(is_female = is_female, weight = weight)\n\nPer calcolare manualmente la statistica t:\n\n# Estraiamo i pesi per ogni gruppo\nweight_f &lt;- df$weight[df$is_female == 1]\nweight_m &lt;- df$weight[df$is_female == 0]\n\n# Calcolo della deviazione standard pooled\ns_pool_num &lt;- ((length(weight_f) - 1) * var(weight_f)) + ((length(weight_m) - 1) * var(weight_m))\ns_pool_denom &lt;- length(weight_f) + length(weight_m) - 2\ns_pool &lt;- sqrt(s_pool_num / s_pool_denom)\n\n# Calcolo della statistica t\nt_num &lt;- mean(weight_f) - mean(weight_m)\nt_denom &lt;- s_pool * sqrt(1 / length(weight_f) + 1 / length(weight_m))\nT &lt;- t_num / t_denom\nT\n#&gt; [1] -2.784\n\n\n# Gradi di libertà\ndf_degrees &lt;- length(weight_f) + length(weight_m) - 2\ndf_degrees\n#&gt; [1] 16\n\n\n# Calcolo del valore-p\np_value &lt;- 2 * pt(abs(T), df = df_degrees, lower.tail = FALSE)\nprint(p_value)\n#&gt; [1] 0.01327\n\nIn alternativa, possiamo usare la funzione t.test di R:\n\nres &lt;- t.test(weight_f, weight_m, var.equal = TRUE)\nprint(res, digits = 7)\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  weight_f and weight_m\n#&gt; t = -2.7842, df = 16, p-value = 0.01327\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -29.748019  -4.029759\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;  52.10000  68.98889\n\n\n72.6.1 Interpretazione dei Risultati\nIl test t di Student ha generato un valore-p inferiore a 0.05, indicando che la differenza osservata tra i pesi medi delle donne e degli uomini è statisticamente significativa. Questo significa che, con un livello di confidenza del 95%, possiamo rifiutare l’ipotesi nulla secondo cui le medie dei due gruppi sono uguali.\nÈ importante ricordare che un basso valore-p suggerisce che la differenza osservata non è dovuta al caso. Tuttavia, ciò non prova automaticamente una relazione causale; piuttosto, apre la strada ad ulteriori indagini sulle cause della differenza.\n\n72.6.2 Riportare i Risultati\nQuando si riportano i risultati di un test t, è fondamentale adottare pratiche che favoriscano una comprensione approfondita e accurata dei dati. Di seguito viene presentato un confronto tra due versioni dei risultati: una da evitare, che si basa su un’interpretazione tradizionale della significatività statistica, e una versione migliorata che enfatizza l’intervallo di confidenza e l’ampiezza dell’effetto.\n\n72.6.2.1 Versione da Evitare\nLa seguente formulazione segue un approccio tradizionale incentrato sulla “significatività statistica,” che è oggi ritenuto inadeguato per una comunicazione efficace dei risultati:\n\nAbbiamo condotto un test t di Student per confrontare le medie dei due gruppi. I risultati mostrano una differenza significativa tra i pesi medi delle donne e degli uomini (t(16) = -2.78, p-value = 0.01). L’intervallo di confidenza al 95% per la differenza delle medie è [-29.75, -4.03]. L’ampiezza dell’effetto, misurata con Cohen’s d, è 1.31, indicando un effetto grande. La potenza statistica del test è stata stimata al 74.4%.\n\nIn questa versione, il focus è eccessivamente concentrato sul valore-p, che può portare a interpretazioni riduttive e distorte dei risultati.\n\n72.6.2.2 Versione Migliorata\nEcco invece una versione migliore che mantiene un approccio frequentista, ma sposta l’enfasi sull’intervallo di confidenza e sull’ampiezza dell’effetto, offrendo una descrizione più completa e informativa:\n\nÈ stato condotto un test t di Student per confrontare le medie dei due gruppi. La differenza tra i pesi medi delle donne e degli uomini è stata stimata in -16.89 kg (intervallo di confidenza al 95%: [-29.75, -4.03]), suggerendo che il peso medio degli uomini sia maggiore rispetto a quello delle donne nel campione analizzato. Questo intervallo indica che, con una fiducia del 95%, la differenza reale tra i pesi medi potrebbe variare tra circa -29.75 kg e -4.03 kg.\nL’ampiezza dell’effetto, misurata con Cohen’s d = 1.31, indica una differenza considerevole, equivalente a oltre una deviazione standard. Questo valore suggerisce che la differenza osservata non solo è statisticamente rilevante, ma anche sostanziale dal punto di vista pratico.\nInoltre, la potenza del test, considerando la dimensione dell’effetto osservata, è pari al 74.4%, suggerendo che il test ha una buona capacità di rilevare differenze di questa entità nel campione analizzato. Ciò significa che, se una differenza di tale magnitudine fosse presente nella popolazione, esisterebbe una probabilità superiore al 70% di rilevarla correttamente.\n\nQuesta modalità di reporting fornisce una descrizione più dettagliata ed esplicativa dei risultati, evitando interpretazioni basate esclusivamente sul valore-p e concentrandosi invece sulla grandezza e sull’incertezza della stima. Tale approccio consente una valutazione più equilibrata e informata dei dati, promuovendo una comprensione più approfondita delle implicazioni pratiche e scientifiche dei risultati ottenuti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#riflessioni-conclusive",
    "title": "\n72  Test t di Student per campioni indipendenti\n",
    "section": "\n72.7 Riflessioni Conclusive",
    "text": "72.7 Riflessioni Conclusive\nIl test t di Student è uno strumento statistico ampiamente utilizzato per l’inferenza su una media o per confrontare le medie di due gruppi. È talmente importante che alcuni lo hanno definito il metodo statistico più importante nella scienza. Tuttavia, come osserva Andrew Gelman, questa affermazione non va accettata acriticamente. Benché il test t sia semplice ed efficace in molti contesti, presenta notevoli limitazioni che ne riducono l’affidabilità e l’applicabilità quando si affrontano problemi complessi o si desidera una comprensione più approfondita dei dati (Kruschke, 2013).\n\n72.7.1 Limiti del Test t di Student\nUno dei principali limiti del test t risiede nell’assunzione che i dati seguano una distribuzione normale (gaussiana). Questa assunzione è spesso violata in pratica, specialmente con campioni piccoli o quando i dati presentano asimmetrie o code pesanti. Inoltre, nel caso di campioni indipendenti, il test richiede l’omogeneità delle varianze, un’altra assunzione frequentemente infondata. Quando queste condizioni non sono soddisfatte, il test può fornire risultati distorti, necessitando di correzioni come quella di Welch per gestire differenze di varianza.\nUn ulteriore limite del test t è legato alla sua dipendenza dalla soglia di significatività \\(\\alpha\\), solitamente fissata a 0.05. Questa scelta è arbitraria e può influenzare criticamente le conclusioni. Il test valuta esclusivamente la compatibilità dei dati con l’ipotesi nulla (\\(H_0\\)) e fornisce solo un p-value, senza offrire informazioni dirette sulla plausibilità dell’ipotesi alternativa (\\(H_1\\)). Ciò significa che un p-value basso non garantisce che \\(H_1\\) sia vera o che i dati supportino tale ipotesi.\n\n72.7.2 L’Approccio Bayesiano: Una Soluzione Più Potente\nIn contrasto con il paradigma frequentista, l’approccio bayesiano offre un quadro statistico più flessibile e informativo. Attraverso il teorema di Bayes, è possibile calcolare direttamente la probabilità di un’ipotesi dato l’insieme dei dati osservati. Questo permette di quantificare la forza dell’evidenza a favore di un’ipotesi rispetto alle altre, superando le limitazioni intrinseche del test t.\n\n72.7.2.1 Vantaggi dell’Approccio Bayesiano\n\nNon richiede assunzioni rigide: A differenza del test t, che si basa su ipotesi restrittive come la normalità e l’omoschedasticità, l’inferenza bayesiana è in grado di gestire modelli più generali e robusti, adattandosi ai dati reali senza doverli forzare in strutture artificiali.\nIncorporazione delle informazioni pregresse: L’approccio bayesiano permette di integrare conoscenze pregresse attraverso distribuzioni a priori, migliorando la qualità delle stime e consentendo analisi più realistiche. Questo è particolarmente utile in situazioni dove i dati disponibili sono scarsi o rumorosi.\nInferenze più informative: Al posto di semplici decisioni binarie (“rifiuto” o “non rifiuto” di \\(H_0\\)), il bayesianismo fornisce distribuzioni a posteriori complete, che descrivono l’incertezza sui parametri di interesse. Questo consente inferenze più dettagliate e interpretabili.\nGestione della complessità: L’approccio bayesiano gestisce in modo naturale modelli complessi e gerarchici, rendendolo ideale per analisi avanzate. Ad esempio, Kruschke (2013) dimostra come tecniche bayesiane possano superare le limitazioni del test t anche in presenza di violazioni delle assunzioni classiche, producendo risultati più stabili e affidabili.\n\n72.7.2.2 Implementazione Pratica\nSebbene l’approccio bayesiano richieda una maggiore attenzione nella scelta delle distribuzioni a priori e nella specificazione del modello, l’avvento di software moderni come Stan, PyMC3 e JAGS ha reso l’implementazione di modelli bayesiani sempre più accessibile. Oggi, anche ricercatori con competenze statistiche moderate possono applicare metodi bayesiani per affrontare problemi complessi con maggiore precisione e coerenza.\n\n72.7.3 Conclusioni\nIl test t di Student rimane un valido strumento per analisi rapide e semplici, ma le sue limitazioni diventano evidenti quando si lavora con dati complessi o si cerca una comprensione più profonda delle relazioni sottostanti. L’approccio bayesiano rappresenta un’evoluzione concettuale e metodologica rispetto all’inferenza frequentista tradizionale, offrendo numerosi vantaggi: inferenze più ricche, integrazione di informazioni pregresse, gestione delle violazioni delle assunzioni e produzione di stime più robuste. Per questi motivi, il paradigma bayesiano è sempre più considerato come la scelta preferibile per chi desidera un’analisi statistica solida, flessibile e informativa.\nIn ultima analisi, mentre il test t resta un punto di partenza utile, l’adozione dell’approccio bayesiano permette di avanzare verso una comprensione più completa e accurata dei dati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n72  Test t di Student per campioni indipendenti\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.10.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        Rdpack_2.6.2      vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    pan_1.9          \n#&gt; [13] pacman_0.5.1      jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-2     \n#&gt; [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [21] mnormt_2.1.1      codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64       reformulas_0.4.0 \n#&gt; [29] iterators_1.0.14  rpart_4.1.24      boot_1.3-31       mitml_0.4-5      \n#&gt; [33] foreach_1.5.2     nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37    \n#&gt; [37] stringi_1.8.4     splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0    \n#&gt; [41] grid_4.4.2        colorspace_2.1-1  cli_3.6.4         magrittr_2.0.3   \n#&gt; [45] survival_3.8-3    broom_1.0.7       withr_3.0.2       backports_1.5.0  \n#&gt; [49] timechange_0.3.0  rmarkdown_2.29    nnet_7.3-20       lme4_1.1-36      \n#&gt; [53] hms_1.1.3         evaluate_1.0.3    rbibutils_2.3     rlang_1.1.5      \n#&gt; [57] Rcpp_1.0.14       glue_1.8.0        minqa_1.2.8       rstudioapi_0.17.1\n#&gt; [61] jsonlite_1.8.9    R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#bibliografia",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#bibliografia",
    "title": "\n72  Test t di Student per campioni indipendenti\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nIn psicologia, nelle scienze sociali e in altre discipline è in corso una Riforma Metodologica, scaturita da una profonda crisi che ha colpito la scienza contemporanea: la crisi di replicazione dei risultati delle ricerche. Un esempio emblematico è rappresentato dal sito Retraction Watch, che monitora le ritrattazioni di studi scientifici. Questa crisi mina la credibilità della ricerca scientifica e ha spinto a una revisione radicale delle metodologie alla base delle scienze psicologiche e di altre discipline affini (Korbmacher et al., 2023). Le cause della crisi di replicazione sono molteplici: frodi, pratiche di ricerca scorrette e incentivi distorti offerti dal sistema accademico. Una delle cause più rilevanti per un corso sull’analisi dei dati psicologici è l’uso delle tecniche inferenziali di stampo frequentista, che ha contribuito alla proliferazione di pubblicazioni contenenti falsi positivi.\nUn articolo di Altmejd et al. (2019) identifica alcuni fattori semplici ma altamente predittivi della replicabilità degli studi: il campione era di dimensioni adeguate? I ricercatori hanno ottenuto un risultato appena sotto la soglia di significatività di p = 0.05? (Spesso un articolo può rivendicare un risultato “significativo” se questa soglia viene raggiunta, e molti utilizzano vari trucchi statistici per superare tale limite.) Lo studio ha rilevato un effetto sull’intera popolazione studiata o ha individuato un “effetto di interazione” (ad esempio, un effetto presente solo in un segmento più piccolo della popolazione), che è molto meno probabile che si riproduca?\nÈ emerso inoltre che prevedere la replicazione di uno studio è sorprendentemente semplice. Non è necessario un approfondimento della metodologia statistica né un esame rigoroso dei dati, né tantomeno una scrupolosa analisi delle teorie più esoteriche per individuare errori sottili: questi articoli presentano problemi evidenti, a livello superficiale. Uno studio pubblicato su Nature ha coinvolto scienziati in una scommessa su quali studi di scienze sociali sarebbero stati replicati. Camerer et al. (2018) ha scoperto che le previsioni degli scienziati in questo mercato delle scommesse erano estremamente accurate nel determinare quali articoli avrebbero avuto successo nella replicazione.\nUlteriori ricerche hanno dimostrato che non è nemmeno necessario consultare esperti del settore per indovinare quali studi resisteranno a un esame rigoroso. Uno studio di Hoogeveen et al. (2020) ha coinvolto partecipanti senza un background professionale nelle scienze sociali, chiedendo loro di leggere articoli di psicologia e prevedere se questi si sarebbero replicati. “I non-esperti senza una formazione professionale nelle scienze sociali sono in grado di prevedere la replicabilità degli studi con una precisione superiore al caso,” conclude lo studio, “basandosi esclusivamente su semplici descrizioni verbali degli studi.”\nSebbene i non esperti non siano stati altrettanto precisi nelle loro previsioni rispetto agli scienziati nello studio pubblicato su Nature, il fatto che siano comunque riusciti a individuare molte replicazioni fallite suggerisce che molti di questi studi presentano difetti evidenti, riconoscibili anche da chi non è un addetto ai lavori.\nLa pubblicazione di un articolo peer-reviewed non rappresenta l’ultimo passo del processo scientifico. Dopo la pubblicazione, altri studi potrebbero citare l’articolo originale, diffondendo eventuali errori o fraintendimenti. Uno studio di Yang et al. (2020) mostra che non esiste alcuna correlazione tra la replicabilità di uno studio e la sua frequenza di citazione. “Gli studi falliti si diffondono nella letteratura scientifica con la stessa rapidità degli studi replicabili,” affermano Yang et al. (2020). Questo solleva una domanda: se gli scienziati sono abbastanza bravi nel prevedere se uno studio si replicherà, perché sono altrettanto inclini a citare studi non replicabili quanto quelli validi?\nQueste considerazioni suggeriscono che la crisi di replicazione non richiede solo una revisione metodologica, ma è il sintomo di un sistema scientifico che necessita di un ripensamento più ampio. Le riviste scientifiche non sono sufficientemente responsabili per la pubblicazione di articoli discutibili, e il sistema accademico promuove incentivi distorti. In alcuni casi, la cultura accademica sembra addirittura incentivare la produzione di ricerche di bassa qualità. La pressione a pubblicare un elevato numero di articoli favorisce chi riesce a farlo rapidamente, spesso ricorrendo a “scorciatoie”. Di conseguenza, si è creato un sistema in cui gli incentivi continuano a promuovere la cattiva ricerca, nonostante si comprenda sempre meglio cosa costituisca una ricerca di qualità.\nIn questa sezione della dispensa, ci concentreremo su uno dei problemi che stanno alla base della crisi della riproducibilità dei risultati della ricerca, ovvero i limiti dell’inferenza frequentista (Baker, 2016). Analizzeremo gli errori di tipo S e di tipo M, concetti introdotti da Gelman & Carlin (2014), che hanno contribuito a migliorare la comprensione dei limiti della statistica frequentista. Inoltre, discuteremo alcuni possibili metodi per affrontare la crisi e le implicazioni che derivano dall’integrità della ricerca.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Altmejd, A., Dreber, A., Forsell, E., Huber, J., Imai, T., Johannesson, M., Kirchler, M., Nave, G., & Camerer, C. (2019). Predicting the replicability of social science lab experiments. PloS one, 14(12), e0225826.\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nCamerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., et al. (2018). Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015. Nature human behaviour, 2(9), 637–644.\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nHoogeveen, S., Sarafoglou, A., & Wagenmakers, E.-J. (2020). Laypeople can predict which social-science studies will be replicated successfully. Advances in Methods and Practices in Psychological Science, 3(3), 267–285.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nYang, Y., Youyou, W., & Uzzi, B. (2020). Estimating the deep replicability of scientific findings using human and artificial intelligence. Proceedings of the National Academy of Sciences, 117(20), 10762–10768.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html",
    "href": "chapters/replication_crisis/01_crisis.html",
    "title": "73  La crisi della replicazione",
    "section": "",
    "text": "73.1 Introduzione\nIl presente capitolo introduce la crisi di replicazione che affligge la ricerca psicologica, analizzandone le cause precipue e ponendo in rilievo il ruolo che l’approccio statistico frequentista ha avuto nel concorrere a tale problematica. Il contenuto di questo capitolo costituisce una sintesi rielaborata del testo A student’s guide to open science: Using the replication crisis to reform psychology (Pennington, 2023).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cosa-dovrebbe-essere-la-scienza",
    "href": "chapters/replication_crisis/01_crisis.html#cosa-dovrebbe-essere-la-scienza",
    "title": "73  La crisi della replicazione",
    "section": "\n73.2 Cosa dovrebbe essere la scienza",
    "text": "73.2 Cosa dovrebbe essere la scienza\nPennington (2023) avvia la sua discussione sulla crisi di replicazione delineando le caratteristiche di uno scenario “ideale” cui la prassi scientifica dovrebbe aspirare. Affinché la psicologia possa essere considerata una disciplina scientifica a pieno titolo, è imprescindibile l’adesione ai principi di replicabilità e riproducibilità. In altri termini, qualora un effetto sia reale e robusto, qualsiasi ricercatore, a parità di procedure e con un’adeguata dimensione campionaria, dovrebbe essere in grado di rilevarlo. Ulteriori attributi auspicabili della ricerca scientifica sono i seguenti:\n\n\nCredibile: La scienza dovrebbe essere credibile, non incredibile. Gli scienziati dovrebbero essere disposti a sottoporre le loro affermazioni e scoperte a un esame equo e rigoroso.\n\n\nAffidabile: I risultati scientifici dovrebbero essere riportati in modo accurato. Il pubblico dovrebbe poterli considerare attendibili e usarli per prendere decisioni informate.\n\n\nTrasparente: La scienza dovrebbe essere assolutamente chiara. I metodi e i risultati scientifici dovrebbero essere descritti in dettaglio, permettendo repliche indipendenti, valutazioni e l’accumulo di conoscenze.\n\n\nAccessibile: La scienza dovrebbe essere accessibile a tutti. Sia i ricercatori sia il pubblico generale dovrebbero poter accedere, leggere e valutare facilmente i risultati scientifici.\n\n\nInclusiva: La scienza dovrebbe essere diversificata e inclusiva. Gli scienziati appartenenti a gruppi sottorappresentati dovrebbero avere pari opportunità di partecipazione e accesso.\n\n\nCollaborativa: La scienza dovrebbe massimizzare l’uso delle risorse disponibili, incoraggiando la cooperazione tra ricercatori piuttosto che la competizione, per produrre lavori di alta qualità.\n\n\nAutocorrettiva: La scienza dovrebbe basarsi su prove accurate nel perseguimento della conoscenza. Gli errori riscontrati negli articoli dovrebbero essere corretti e spiegati, rendendo questa pratica normale nel processo scientifico.\n\nA questo punto, Pennington (2023) propone una riflessione retorica: “Immaginate di chiudere gli occhi e visualizzare uno scienziato stereotipato. Quale immagine vi si presenta? Quali azioni compie? Quali sono i suoi comportamenti?”.\nL’autore offre la propria visualizzazione: “Io vedo un uomo bianco, di mezza età, all’interno di un laboratorio contrassegnato da un grande cartello con la scritta ‘DIVIETO DI ACCESSO!’. I suoi risultati rappresentano un tesoro personale, gelosamente custodito, precluso a qualsiasi osservatore esterno. Egli teme che qualcuno possa appropriarsi delle sue brillanti intuizioni, replicare il suo lavoro o tentare di riprodurne i risultati. Si tratta della sua scienza, non di una scienza condivisa.”\nTale rappresentazione incarna una scienza priva di trasparenza, accessibilità e spirito collaborativo.\nNella psicologia contemporanea è in corso un ampio dibattito su quali cambiamenti siano necessari per superare le criticità emerse negli ultimi anni e promuovere una scienza più rigorosa e affidabile. Nonostante la scienza si fondi su principi chiave, come replicabilità e riproducibilità, la prassi scientifica non è sempre stata coerente con questi ideali. Questa discrepanza ha portato a ciò che molti definiscono una crisi nella psicologia moderna.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "href": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "title": "73  La crisi della replicazione",
    "section": "\n73.3 La Crisi della Replicazione in Psicologia",
    "text": "73.3 La Crisi della Replicazione in Psicologia\nNegli ultimi decenni, la psicologia si è trovata al centro di una crisi che ha messo in discussione molte delle sue basi epistemologiche e metodologiche: la crisi della replicazione. Questo fenomeno indica l’incapacità di replicare con successo un’ampia parte degli studi pubblicati, con implicazioni rilevanti per la cultura accademica e il modo di concepire la ricerca scientifica (Parsons et al., 2022).\nPer fallimento della replicazione si intende il caso in cui uno studio, ripetuto da altri ricercatori seguendo le stesse procedure e utilizzando campioni simili, non riesce a ottenere risultati comparabili a quelli originali. Questo ha portato alla luce problemi sistemici legati alla metodologia di ricerca, all’interpretazione dei dati e alle dinamiche del sistema accademico. La crisi della replicazione ha dunque evidenziato la necessità di un cambiamento strutturale nella pratica scientifica, sottolineando l’urgenza di un approccio più trasparente, rigoroso e collaborativo.\nNelle sezioni seguenti vengono presentati gli eventi chiave di quella che possiamo chiamare la storia della crisi della replicazione.\n\n73.3.1 2005: “Perché la maggior parte dei risultati pubblicati è falsa” (Ioannidis)\nUn primo momento cruciale è stato l’articolo di “Why Most Published Research Findings Are False” (Ioannidis, 2005) che ha evidenziato come molti risultati scientifici fossero in realtà falsi positivi. Ioannidis attribuì questo fenomeno a campioni di piccole dimensioni, un’eccessiva enfasi sui valori-p per indicare significatività, flessibilità nei metodi di analisi e la competizione per produrre risultati “innovativi”. Questo articolo ha messo in luce problemi che trascendono la psicologia, ma che in seguito sarebbero emersi come centrali anche per questa disciplina.\n\n73.3.2 2011: Lo Studio di Daryl Bem, “Feeling the Future”\nUno degli eventi più controversi è stato lo studio di Daryl Bem “Feeling the Future” (Bem, 2011), che suggeriva l’esistenza della precognizione, ovvero la capacità di “sentire” eventi futuri. Attraverso nove esperimenti, Bem pubblicò risultati statisticamente significativi che sembravano sfidare le leggi della causalità.\nLo studio di Bem si inseriva nella tradizione degli esperimenti di “priming”, una tecnica ampiamente utilizzata in psicologia sociale dagli anni ’70. Gli esperimenti di priming tipicamente coinvolgevano studenti universitari, remunerati con modeste somme o crediti accademici. I partecipanti venivano esposti a determinati concetti per poi osservare come questi influenzassero il loro comportamento successivo. Un celebre esempio è lo studio di John Bargh del 1996, che dimostrò come l’esposizione a parole associate all’età avanzata inducesse i soggetti a camminare più lentamente (Bargh et al., 1996). Un altro studio del 2006 rivelò che il priming con concetti legati al denaro rendeva le persone meno propense ad aiutare gli altri. Questi studi sembravano dimostrare una straordinaria malleabilità della mente umana, suggerendo che il nostro comportamento potesse essere inconsciamente manipolato da sottili segnali ambientali (Leys, 2024). Tuttavia, lo studio di Bem introdusse un elemento nuovo in questo paradigma sperimentale.\nTra i vari esperimenti condotti da Bem, uno in particolare si distingueva. I soggetti venivano esposti a una parola con connotazione positiva o negativa e successivamente dovevano valutare rapidamente la piacevolezza di alcune immagini. Fin qui, nulla di insolito. La svolta radicale consisteva nel fatto che in metà delle prove, il priming avveniva dopo che i soggetti avevano già visto e valutato l’immagine (Bem, 2011).\nSorprendentemente, i risultati mostravano che il priming funzionava anche in queste condizioni: i partecipanti erano più veloci a giudicare piacevoli le immagini quando successivamente venivano esposti a una parola positiva. Questo effetto risultava statisticamente significativo, con un p-value di 0.01, sufficiente secondo gli standard correnti per rifiutare l’ipotesi nulla.\nBem interpretò questi risultati come prova della chiaroveggenza, una conclusione che suscitò notevoli controversie e ridicolizzò la psicologia. Gli altri otto esperimenti dello studio, tutti basati su classici paradigmi della psicologia sociale con l’ordine temporale invertito, mostrarono risultati altrettanto statisticamente significativi.\nQuesti risultati ponevano la comunità scientifica di fronte a un dilemma: accettare l’esistenza di fenomeni paranormali o mettere in discussione le pratiche statistiche e metodologiche consolidate nella disciplina. Bem stesso continua a sostenere la validità dei suoi risultati come prova dell’esistenza di capacità precognitive.\nSebbene pubblicato su una rivista prestigiosa, lo studio sollevò enormi dubbi metodologici. Le repliche successive non riuscirono a confermare i risultati di Bem, mostrando come pratiche discutibili, quali il p-hacking (modifiche al metodo di analisi per ottenere risultati significativi), potessero produrre falsi positivi apparentemente robusti.\n\n73.3.3 2011: Il Caso di Frode di Diederik Stapel\nNello stesso anno, Diederik Stapel, una figura di spicco della psicologia sociale, fu accusato di aver falsificato dati in decine di studi pubblicati. Tra i suoi esperimenti più famosi vi era quello secondo cui ambienti disordinati aumenterebbero il razzismo. Un altro studio suggeriva che mangiare carne rendeva le persone più antisociali. Tuttavia, si scoprì che per quegli studi, e molti altri, non aveva mai condotto gli esperimenti né raccolto i dati. Li aveva semplicemente inventati. A volte le frodi accadono. Stapel fu scoperto (alla fine), licenziato e decine dei suoi articoli furono ritirati. Questo scandalo scosse profondamente la comunità accademica e divenne un simbolo della crisi.\n\n73.3.4 2011: La Meta-ricerca e le Pratiche di Ricerca Discutibili (QRPs)\nLa meta-ricerca è un campo di studio che si concentra sul modo in cui viene condotta la ricerca scientifica. Comprende temi come i metodi, la trasparenza nella comunicazione, la riproducibilità, la valutazione e i sistemi di incentivi che regolano la scienza (Ioannidis et al., 2015). Questo ambito è emerso con urgenza dopo una serie di casi controversi e di frodi conclamate, come gli studi di Daryl Bem e Diederik Stapel, che hanno evidenziato falle nei processi di ricerca. I ricercatori hanno così iniziato ad analizzare pratiche note come Questionable Research Practices (QRPs, Pratiche di Ricerca Discutibili), che sfruttano aree grigie nelle norme scientifiche per raccogliere e analizzare i dati.\nSimmons et al. (2011) hanno dimostrato come la flessibilità nella raccolta, analisi e comunicazione dei dati permetta ai ricercatori di far apparire “significativo” praticamente qualsiasi risultato. Tra le pratiche discusse, spiccano:\n\n\nOptional stopping: Interrompere la raccolta dei dati non appena si raggiunge la significatività statistica, invece di seguire un piano prestabilito.\n\n\nP-hacking: Condurre molteplici test non pianificati, selezionando variabili o analisi solo quando producono un valore p inferiore a 0.05.\n\n\nHARKing (Hypothesizing After Results are Known): Modificare le ipotesi a posteriori per adattarle ai risultati ottenuti, presentandole come ipotesi iniziali.\n\nQueste pratiche non solo compromettono l’integrità scientifica, ma rendono estremamente facile produrre falsi positivi. Per dimostrarlo, Simmons e colleghi hanno condotto simulazioni al computer e due esperimenti, rivelando quanto fosse “troppo facile” raccogliere prove a sostegno di ipotesi false.\nLa portata di queste pratiche è sorprendente. Simmons et al. hanno scoperto che:\n\nUsare una sola QRP può quasi raddoppiare il tasso di falsi positivi, portandolo dal 5% al 10%.\n\nCombinare più QRPs può far salire questa percentuale oltre il 60%.\n\nPer sottolineare il problema, i ricercatori hanno dimostrato, in modo volutamente ironico, che ascoltare la canzone dei Beatles “When I’m Sixty-Four” potrebbe far apparire le persone più giovani di quanto fossero prima di ascoltarla. Questa dimostrazione satirica evidenziava che inseguire la significatività statistica senza un rigore metodologico può produrre risultati assurdi.\nJohn et al. (2012) hanno condotto un’indagine su larga scala, intervistando 2000 ricercatori per comprendere la diffusione delle QRPs. Con un approccio innovativo, hanno chiesto ai partecipanti non solo di riferire le proprie pratiche, ma anche quelle dei colleghi. I risultati sono stati sconvolgenti:\n\nOltre il 60% degli intervistati ha ammesso di non aver riportato tutte le variabili dipendenti misurate.\n\nPiù del 50% ha interrotto la raccolta dati non appena ottenuti risultati significativi (optional stopping).\n\nPiù del 40% ha selezionato e riportato solo esperimenti “riusciti”.\n\nSorprendentemente, i ricercatori tendevano a dichiarare che i colleghi adottavano queste pratiche più frequentemente di loro stessi. Molti giustificavano queste pratiche come “norme accademiche” del tempo.\nLa meta-ricerca ha giocato un ruolo cruciale nell’aprire gli occhi della comunità scientifica sui pericoli di queste decisioni apparentemente “banali”. In un contesto in cui le QRPs erano ampiamente accettate, la meta-ricerca ha evidenziato come queste pratiche possano seriamente danneggiare il progresso scientifico. Grazie al movimento dell’Open Science, si stanno introducendo norme che migliorano la credibilità della ricerca, spostando l’enfasi dalla produzione di risultati “significativi” alla conduzione di studi rigorosi e trasparenti.\n\n73.3.5 2012: La Crisi di Fiducia della Psicologia\nSiamo nel 2012, un anno segnato da una serie di eventi che spingono Harold Pashler ed Eric-Jan Wagenmakers a dichiarare che la psicologia sta affrontando una “crisi di fiducia”. In un numero speciale della rivista Perspectives on Psychological Science (PoPs), i due autori raccolgono una molteplicità di prospettive sulla nascente crisi della replicazione, cercando di individuarne le cause e le implicazioni.\nLe reazioni alla crisi sono variegate e, in alcuni casi, contrastanti. Alcuni studiosi sostengono che le affermazioni di una crisi siano premature (Stroebe e Strack, 2014) e che i problemi di replicazione non siano un fenomeno nuovo (Spellman, 2015). Altri, invece, sottolineano come incentivare e valorizzare gli studi di replicazione rappresenti un metodo efficace e diretto per migliorare la qualità della scienza psicologica (Koole e Lakens, 2012).\nIl numero speciale evidenzia anche iniziative in corso per affrontare il problema. Tra queste, l’Open Science Collaboration (OSC), un progetto di larga scala avviato nel 2012, si propone di verificare empiricamente se la psicologia sia effettivamente alle prese con una crisi della replicazione. L’obiettivo del progetto è ambizioso: replicare numerosi studi pubblicati per valutare la robustezza dei risultati originari. Sebbene i risultati di questa iniziativa non fossero ancora disponibili al momento della pubblicazione del numero speciale, il progetto rappresentava già una pietra miliare per la disciplina.\nNonostante le preoccupazioni, il numero speciale si chiude con una nota positiva, destinata a risuonare nella comunità scientifica. I casi di frode, le pratiche di ricerca discutibili (QRPs) e i fallimenti nei tentativi di replicazione, sebbene dannosi, hanno aperto la strada a una riflessione critica. Questo processo ha permesso alla psicologia di affrontare i propri limiti, correggere errori, superare i bias e costruire una letteratura più affidabile e trasparente.\nQuesto periodo storico segna un punto di svolta: la crisi di fiducia ha messo in discussione le fondamenta della disciplina, ma ha anche creato l’opportunità per un rinnovamento scientifico, stimolando pratiche più rigorose e una maggiore attenzione alla replicabilità e alla trasparenza.\n\n73.3.6 2014: Il Progetto “Many Labs”\nNel 2014 fu pubblicato il primo tentativo su larga scala di replicare risultati psicologici: il progetto “Many Labs”. Questo imponente sforzo collaborativo, guidato da Klein et al. (2014), testò la replicabilità di 13 risultati classici della psicologia, coinvolgendo 6344 partecipanti in 12 paesi. Gli studi selezionati rispettavano tre criteri principali: erano relativamente brevi, avevano un design semplice e potevano essere facilmente condotti online.\nTra i fenomeni esaminati figurava la fallacia del costo irrecuperabile (sunk cost fallacy), secondo cui le persone tendono a proseguire un’attività quando vi hanno già investito tempo, sforzi o denaro. Un esempio classico: se hai acquistato un biglietto per vedere la tua squadra di calcio preferita e, il giorno della partita, inizia a piovere a dirotto, sarai più propenso a partecipare perché hai già speso i soldi per il biglietto (Oppenheimer e Monin, 2009).\nAltri studi replicati includevano:\n\nL’influenza del framing dei guadagni e delle perdite sul rischio (Tversky e Kahneman, 1981).\n\nLe differenze di genere negli atteggiamenti impliciti verso la matematica e le arti (Nosek et al., 2002).\n\nI risultati sembravano promettenti: il 77% degli studi replicò con successo i risultati originali (10 su 13). Tuttavia, non tutti gli studi fornirono lo stesso livello di evidenza. Ad esempio:\n\nUno studio sull’efficacia del contatto sociale immaginato nel ridurre i pregiudizi (Husnu e Crisp, 2010) mostrò supporto limitato, con solo 4 campioni su 36 che evidenziarono un effetto significativo.\n\nDue studi di priming non furono replicati. Nel primo, i ricercatori non trovarono che l’esposizione alla bandiera americana aumentasse il conservatorismo (Carter et al., 2011). Nel secondo, il priming con concetti legati al denaro non portò a un incremento delle credenze o dei comportamenti capitalistici (Caruso et al., 2013).\n\nSebbene i risultati fossero accolti come una vittoria per la replicabilità, alcuni ricercatori sottolinearono limiti nel progetto Many Labs 1. Gli stessi autori riconobbero che molti degli studi selezionati erano già noti per essere altamente replicabili. Secondo alcuni critici, il principale contributo di questo progetto era dimostrare che almeno dieci effetti psicologici erano replicabili, ma non forniva una panoramica più ampia sulla replicabilità complessiva nella psicologia (Yarkoni, 2013).\nQuesto progetto rappresentò comunque un passo fondamentale per affrontare la crisi della replicazione, sottolineando l’importanza della collaborazione scientifica e del rigore metodologico.\n\n73.3.7 2015: Il Progetto di Riproducibilità della Open Science Collaboration\nNel 2015, la Open Science Collaboration (OSC) pubblicò i risultati del Reproducibility Project: Psychology, dimostrando che la buona scienza richiede tempo e rigore. Superando i limiti del progetto Many Labs 1, un team composto da oltre 270 ricercatori internazionali si impegnò a replicare 100 studi scelti casualmente da riviste di punta nel campo della psicologia.\nPer garantire risultati solidi e inattaccabili, il team adottò una metodologia rigorosa:\n- Consultazione con gli autori originali: gli autori degli studi originali furono coinvolti per confermare il design sperimentale e ridurre al minimo eventuali discrepanze.\n- Aumento delle dimensioni campionarie: i campioni furono ampliati per garantire una potenza statistica sufficiente.\n- Registrazione preventiva dei metodi: i piani di analisi e raccolta dati furono registrati in anticipo per prevenire bias da parte dei ricercatori.\nGli studi selezionati per la replicazione includevano domande di ricerca come:\n\nLa convinzione che il comportamento umano sia predeterminato incoraggia il tradimento?\n\nI bambini seguono automaticamente lo sguardo per trovare oggetti nascosti?\n\nÈ possibile osservare un “effetto after-motion” da fotografie fisse che rappresentano movimento?\n\nI risultati del progetto fecero scalpore e conquistarono i titoli dei giornali a livello globale. Solo il 36% degli studi replicò con successo, ottenendo un valore-p inferiore a 0.05. La psicologia sociale si rivelò particolarmente problematica, con un tasso di replicazione del 25%, rispetto al 50% degli studi di psicologia cognitiva.\nPer contestualizzare questi numeri, se gli effetti originali fossero stati realmente validi, il tasso minimo di replicazione atteso sarebbe stato dell’89% (Field et al., 2019). Anche tra gli studi replicati, le dimensioni degli effetti risultarono dimezzate rispetto a quelle riportate negli studi originali.\nQuesti risultati provocarono una forte reazione nella comunità scientifica. Ci si chiedeva: era la fine della psicologia? La disciplina avrebbe mai recuperato credibilità? Sebbene i dati fossero allarmanti, aprirono un dibattito più ampio. Come sottolineato da Kuhn (1962) e Redish et al. (2018), fallimenti nella replicazione possono segnare l’inizio di una rivoluzione scientifica, stimolando un ripensamento dei metodi, delle ipotesi e delle pratiche di ricerca.\nIl Reproducibility Project: Psychology non solo mise in luce le fragilità della disciplina, ma divenne un punto di partenza per migliorare la trasparenza, la collaborazione e la robustezza nella ricerca psicologica.\n\n73.3.7.1 Studi Successivi\nQuesti risultati sono stati ulteriormente corroborati da numerosi studi successivi, tra cui una ricerca più recente basata su tecniche di machine learning, che ha esaminato studi di psicologia pubblicati in sei importanti riviste nell’arco di vent’anni. Questa ricerca suggerisce che poco più della metà di questi articoli di psicologia non supererebbe i test di replicazione (Youyou et al., 2023). Discipline come la psicologia sociale sono state oggetto di particolare preoccupazione, con un tasso di replicazione del solo 25% riportato dal Progetto di Riproducibilità (Collaboration, 2015). Questo dato è in linea con il lavoro di Youyou et al. (2023), che ha mostrato come la replicabilità degli articoli di psicologia vari considerevolmente per sottocampo, con la psicologia sociale che mostra un tasso di replicazione stimato del 37%, un risultato leggermente più incoraggiante rispetto a quanto riportato in precedenza, ma ancora tra i più bassi dei sottocampi esaminati. Altri settori come la psicologia dello sviluppo, cognitiva e clinica hanno mostrato tassi di replicazione stimati rispettivamente del 36%, 42% e 44%, mentre aree come la psicologia delle organizzazioni e della personalità hanno mostrato tassi leggermente più incoraggianti (50% e 55%, rispettivamente). Complessivamente, le evidenze suggeriscono che le preoccupazioni diffuse sulla robustezza e replicabilità dei risultati della ricerca psicologica siano fondate. Sebbene il problema non sia limitato esclusivamente alla psicologia, le questioni rilevate in questo campo hanno ricevuto notevole attenzione a causa dell’apparente portata del fenomeno.\nQuesti risultati confermavano in modo drammatico le previsioni formulate anni prima da John Ioannidis e Dennis Lindley. Le loro avvertenze riguardo alla possibilità che una larga parte, se non la maggioranza, dei risultati scientifici pubblicati potesse essere falsa, si rivelavano ora profetiche.\nIl Progetto di Riproducibilità di Nosek ha segnato un punto di svolta nel dibattito sulla crisi della replicazione in psicologia e, più in generale, nelle scienze sociali e biomediche. Ha evidenziato non solo la fragilità di molti risultati ritenuti consolidati, ma anche la necessità di un riesame critico delle pratiche di ricerca e pubblicazione scientifica. Questo ripensamento delle metodologie scientifiche è ancora in atto.\n\n73.3.8 2015: 1500 Scienziati Sollevano il Velo sulla Riproducibilità\nI risultati del progetto dell’Open Science Collaboration (2015) colpirono il mondo della psicologia come un fulmine a ciel sereno. Molti risultati psicologici, considerati affidabili, crollarono improvvisamente, generando un’ondata di discussioni nei dipartimenti universitari: quale sarebbe stato il prossimo “effetto” a fallire? Tuttavia, nonostante la psicologia fosse diventata l’emblema delle repliche fallite, presto si comprese che non era un problema esclusivo della disciplina.\nNel 2016, Baker condusse un’indagine su 1500 scienziati provenienti da diverse discipline, tra cui chimica, medicina, fisica e ingegneria, per esplorare le preoccupazioni riguardo alla replicazione e alla riproducibilità. I risultati furono sorprendenti: circa il 90% dei partecipanti concordò sull’esistenza di una crisi di riproducibilità, definita come significativa dal 52% e lieve dal 38%.\nUn dato particolarmente allarmante emerse dall’indagine:\n\nIn media, il 40% degli scienziati aveva riscontrato difficoltà nel riprodurre i propri esperimenti.\n\nQuesta percentuale saliva a oltre il 60% quando si tentava di riprodurre gli esperimenti di altri ricercatori.\n\nTra le discipline, la chimica risultò la più problematica, con oltre l’85% dei ricercatori che riportavano fallimenti nel riprodurre i risultati altrui.\nL’articolo di Baker riportava anche esperienze personali che riflettevano il senso di smarrimento generato da questa crisi. Il professor Marcus Munafò, per esempio, descrisse così il suo percorso:\n\n“Ho cercato di replicare ciò che dalla letteratura sembrava semplice, ma non ci sono riuscito. Ho avuto una crisi di fiducia, e poi ho scoperto che questa esperienza non era affatto rara.” (Baker, 2016, p. 452)\n\nL’indagine di Baker non si limitò a evidenziare il problema, ma esplorò anche le possibili cause della crisi, come pratiche metodologiche inadeguate e pressioni accademiche, offrendo al contempo suggerimenti per interventi correttivi.\nL’indagine segnò un momento cruciale: la crisi della riproducibilità, inizialmente confinata a discussioni accademiche, raggiunse una visibilità globale. Non era più solo un problema della psicologia, ma un fenomeno che colpiva l’intero mondo scientifico, portando con sé la necessità di una trasformazione radicale delle pratiche di ricerca.\nQuesto evento contribuì a consolidare il riconoscimento della crisi della riproducibilità come una sfida centrale per tutta la scienza, spingendo verso un cambiamento culturale che mettesse al centro trasparenza, rigore e collaborazione.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "href": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "title": "73  La crisi della replicazione",
    "section": "\n73.4 La Cultura della Frode nel Sistema Accademico",
    "text": "73.4 La Cultura della Frode nel Sistema Accademico\nIn alcuni casi, la crisi della replicazione si intreccia con episodi di frode scientifica, rivelando un lato oscuro della ricerca accademica. Uno degli aspetti più preoccupanti è che il sistema accademico, con i suoi meccanismi di incentivo basati su pubblicazioni frequenti e finanziamenti competitivi, può indirettamente favorire comportamenti disonesti. Questo sistema, orientato al publish or perish (pubblica o scompari), crea pressioni che talvolta spingono i ricercatori a compromettere l’integrità scientifica per raggiungere i propri obiettivi di carriera.\n\n73.4.1 Il Caso Brian Wansink\nUn caso emblematico è quello di Brian Wansink, ex ricercatore di spicco alla Cornell University, che ricevette cospicui finanziamenti federali durante l’amministrazione Obama. I suoi studi sul comportamento alimentare, come quello sugli uomini che mangiano di più in presenza di donne o sull’effetto dei nomi “attraenti” dati alle verdure sul consumo da parte dei bambini, attirarono grande attenzione mediatica ma si rivelarono in seguito non replicabili. Le conseguenze per Wansink furono severe: diciotto suoi articoli furono ritirati, sette ricevettero “espressioni di preoccupazione”, e quindici furono corretti. Nel 2019, Wansink si dimise dalla Cornell University dopo essere stato giudicato colpevole di cattiva condotta scientifica.\n\n73.4.2 Il Caso Sylvain Lesné\nUn altro esempio rilevante riguarda Sylvain Lesné e i suoi coautori che, nel 2006, pubblicarono su Nature un importante articolo sul morbo di Alzheimer. Questo lavoro era fondamentale per lo sviluppo dell’ipotesi amiloide, un meccanismo proposto per spiegare come la malattia affligge le sue vittime. La ricerca sulla malattia di Alzheimer, che colpisce oltre 50 milioni di persone nel mondo, ha ricevuto oltre un miliardo di dollari in finanziamenti governativi fino al 2022, incoraggiata da studi come quello di Lesné.\nNel 2022, il neuroscienziato Matthew Schrag scoprì immagini manipolate in questo e in molti altri articoli di Lesné, inclusi quelli che sostenevano l’ipotesi amiloide. Le immagini erano state manualmente modificate e accorpate per mostrare falsamente supporto alle ipotesi degli articoli. Queste frodi passarono inosservate attraverso i processi di peer review formali di Nature e di altre sei riviste accademiche, venendo infine scoperte solo tramite canali non ufficiali.\nLe conseguenze di queste scoperte furono lente e frammentarie. Gli altri coautori dell’articolo del 2006 alla fine accettarono di ritirarlo, ma non Lesné stesso. La lentezza della risposta a queste evidenze di frode, e il fatto che Lesné continui a essere finanziato dal National Institutes of Health e impiegato presso l’Università del Minnesota, dimostra un fallimento sistemico nell’affrontare la cattiva condotta scientifica.\n\n73.4.3 Altri Casi di Rilievo\nNel mondo accademico, diversi altri recenti scandali hanno messo in luce il problema della frode scientifica e le sue conseguenze spesso limitate per i responsabili. Ecco alcuni casi emblematici:\n\nMarc Tessier-Lavigne, ex presidente della Stanford University: Nel 2023, fu costretto a dimettersi dopo la rivelazione di dati falsificati in sue ricerche precedenti presso Genentech. Nonostante lo scandalo, Tessier-Lavigne ha subito conseguenze minime, diventando successivamente CEO di una nuova azienda di ricerca farmacologica. Lo scandalo fu portato alla luce grazie all’indagine condotta da Theo Baker, uno studente diciassettenne di Stanford.\n\nDan Ariely e Francesca Gino: Questi due rinomati psicologi, noti per le loro ricerche sulla disonestà e il comportamento non etico, sono stati coinvolti in uno scandalo di frode scientifica.\n\nDan Ariely, nel 2021, fu implicato nella fabbricazione di dati in un articolo del 2012 sulla disonestà.\nFrancesca Gino, docente presso la Harvard Business School, è stata accusata di aver presentato lavori contenenti risultati falsificati. Il sito del Dipartimento ora riporta che è in “administrative leave”.\n\n\n\nL’inefficacia delle istituzioni accademiche nel gestire la frode scientifica sembra riflettere un problema culturale di carattere sistemico. Gli incentivi attuali favoriscono la pubblicazione di risultati positivi e innovativi, spesso a scapito dell’integrità scientifica. Gli studiosi che resistono a queste pressioni rischiano di essere emarginati, mentre chi adotta pratiche discutibili per ottenere risultati desiderati viene premiato con finanziamenti, promozioni e prestigio accademico.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "title": "73  La crisi della replicazione",
    "section": "\n73.5 Cosa Significa “Fallimento della Replicazione”?",
    "text": "73.5 Cosa Significa “Fallimento della Replicazione”?\nIl fallimento della replicazione non coincide necessariamente con l’idea che il fenomeno studiato sia inesistente. Al contrario, le cause di un esito negativo in un tentativo di replicazione possono essere molteplici e spesso difficili da individuare con precisione. Comprendere queste ragioni è fondamentale per identificare le criticità metodologiche, migliorare il rigore scientifico e favorire il progresso della conoscenza. Al di là dei casi evidenti di frode, i fallimenti della replicazione rappresentano un’opportunità per riflettere sulla qualità delle pratiche di ricerca.\n\n73.5.1 Possibili Cause di Fallimento nella Replicazione\n\nFalsi positivi nello studio originale\nUn fallimento può indicare che lo studio originale abbia rilevato un effetto inesistente per puro caso. Questo rischio è particolarmente elevato in studi con campioni di piccole dimensioni e bassa potenza statistica, dove gli effetti riportati risultano spesso sovrastimati o instabili.\n\nFalsi negativi nella replica\nIl fallimento può derivare da un falso negativo, ovvero la mancata rilevazione di un effetto realmente esistente. Le cause principali includono:\n\nDifferenze metodologiche o di popolazione tra studio originale e replica.\n\nConfondenti metodologici o una potenza statistica insufficiente.\n\nPresenza di variabili moderatrici che influenzano l’intensità dell’effetto in determinati contesti.\n\n\n\n73.5.2 La Scienza tra Incertezza e Riproducibilità\nLa scienza raramente offre certezze assolute. Come evidenziato dall’Open Science Collaboration, un singolo studio, sia esso originale o di replica, non è sufficiente a fornire una risposta definitiva. Solo replicazioni multiple e sistematiche possono distinguere effetti reali da errori casuali, offrendo una visione più affidabile di un fenomeno. Questo approccio richiede tempo e risorse, ma rappresenta il cuore del metodo scientifico.\n\n73.5.3 Psicologia e Altri Campi\nSebbene la crisi della replicazione sia stata ampiamente discussa in psicologia, problemi simili affliggono molte altre discipline scientifiche. Studi di replicazione hanno evidenziato risultati preoccupanti: in oncologia, meno della metà degli studi replicati ha prodotto risultati coerenti, con tassi di riproducibilità estremamente bassi in alcuni casi; nelle neuroscienze, i tentativi di replicare correlazioni cervello-comportamento hanno mostrato un altissimo tasso di insuccesso. Anche in discipline come l’economia e la filosofia sperimentale, pur registrando tassi di replicazione relativamente più elevati, permangono dubbi sulla selezione degli studi replicati e sulla rappresentatività dei risultati (Pennington, 2023).\nQuesti dati dimostrano che la problematica della replicazione non è esclusiva della psicologia, ma comune a diverse aree del sapere. Tuttavia, sollevano anche un interrogativo critico: è corretto parlare di “crisi” o si tratta piuttosto di una fase di trasformazione necessaria per migliorare il rigore e la trasparenza nella ricerca scientifica?",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "title": "73  La crisi della replicazione",
    "section": "\n73.6 Dibattito sulla Natura della Crisi",
    "text": "73.6 Dibattito sulla Natura della Crisi\nIl tema della crisi della replicazione ha suscitato un dibattito acceso e opinioni contrastanti all’interno della comunità scientifica:\n\nApproccio alle repliche: Alcuni ricercatori ritengono che le repliche esatte siano poco significative, preferendo le repliche concettuali che possano approfondire la comprensione di un fenomeno. Altri, invece, sostengono che solo repliche rigorose ed esatte siano in grado di verificare la robustezza di un effetto, garantendo maggiore affidabilità.\nInterpretazione dei dati dell’Open Science Collaboration (OSC): Il tasso di successo delle repliche riportato dall’OSC, pari al 36%, ha alimentato ulteriori discussioni. Alcuni attribuiscono questo risultato a differenze metodologiche tra studi originali e tentativi di replica, come campioni diversi o contesti modificati. Tuttavia, ricerche successive hanno smentito queste ipotesi, indicando che tali variazioni non spiegano interamente i bassi tassi di replicazione.\n\nInvece di considerare i fallimenti di replicazione come una crisi, molti studiosi li interpretano come un’opportunità per rafforzare la scienza. La replicazione, infatti, rappresenta un elemento fondamentale del metodo scientifico: permette di identificare i limiti di un fenomeno e di migliorare la comprensione delle condizioni in cui si manifesta. Ogni fallimento diventa, così, uno stimolo per il progresso.\nQuesta visione ha dato origine a un movimento noto come “rivoluzione della credibilità”, che punta a migliorare la qualità della ricerca attraverso trasparenza, autocorrezione e valorizzazione delle repliche. Progetti come il Loss of Confidence dimostrano che riconoscere i limiti e le incertezze degli studi precedenti non rappresenta una debolezza, ma un segno di integrità scientifica.\nIl passaggio dalla percezione di crisi a una rivoluzione della credibilità rappresenta un profondo cambiamento culturale nella comunità accademica. La scienza non è un processo statico, ma un percorso dinamico che evolve grazie al confronto critico e alla riflessione. In questa prospettiva, ogni fallimento nella replicazione non è un punto d’arrivo, ma un trampolino di lancio verso una conoscenza più affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "title": "73  La crisi della replicazione",
    "section": "\n73.7 Cause della Crisi",
    "text": "73.7 Cause della Crisi\n\n73.7.1 Incentivi Accademici e la Dominanza della Quantità sulla Qualità\nPer comprendere a fondo le problematiche che affliggono il mondo della ricerca, è essenziale considerare il contesto lavorativo in cui operano i ricercatori. Sebbene spesso vengano idealizzati come figure obiettive e razionali, è fondamentale ricordare che sono anche esseri umani, soggetti a pressioni professionali, responsabilità economiche e ambizioni di carriera. Il loro lavoro è costantemente sottoposto a valutazione: oltre a gestire attività didattiche e amministrative, devono pubblicare articoli su riviste di prestigio e assicurarsi finanziamenti per sostenere i loro gruppi di ricerca. Questo sistema premia la quantità a discapito della qualità, favorendo una mentalità di “pubblica o perisci”.\nLa pressione a pubblicare incessantemente è una delle principali cause dei problemi che alimentano la crisi di replicazione nella scienza. La cultura del “publish or perish” spinge i ricercatori a produrre rapidamente risultati rilevanti, spesso a scapito della rigorosità metodologica e della riproducibilità (Gopalakrishna et al., 2022; Grimes et al., 2018).\nQuesta situazione genera un paradosso: ciò che favorisce la carriera individuale di uno scienziato non sempre coincide con gli interessi del progresso scientifico. Le motivazioni intrinseche di contribuire alla conoscenza vengono spesso offuscate da motivazioni estrinseche legate a indicatori di produttività accademica. Non sorprende, quindi, che oltre il 60% dei ricercatori individui questa pressione come una delle principali cause dei problemi legati alla replicazione e alla riproducibilità.\n\n73.7.2 Bias Cognitivi e Distorsioni nella Ricerca\nI bias cognitivi rappresentano un ulteriore ostacolo alla qualità della ricerca. Tra i principali si trovano:\n\n\nBias di conferma: la tendenza a cercare o interpretare informazioni che confermano le proprie ipotesi iniziali, trascurando dati contrari.\n\nApofenia: il riconoscimento di schemi in dati casuali, spesso combinato con una preferenza per risultati positivi.\n\nBias retrospettivo: la convinzione che un evento fosse prevedibile solo dopo che si è verificato, portando i ricercatori a presentare risultati in modo fuorviante.\n\nQuesti bias favoriscono la ricerca di risultati positivi a scapito di quelli nulli o contrari, contribuendo a creare un problema più grande: il bias di pubblicazione.\n\n73.7.3 Bias di Pubblicazione e il Problema dei “File Drawer”\nIl sistema di pubblicazione accademica incentiva risultati innovativi e positivi, spesso trascurando studi con risultati nulli o repliche. Questo bias, noto come file drawer problem, descrive la tendenza a relegare nei “cassetti” studi non statisticamente significativi, rendendoli inaccessibili e distorcendo la letteratura scientifica.\nIn psicologia, l’impatto di questo fenomeno è particolarmente grave. Studi hanno rilevato che oltre il 90% degli articoli in psicologia riporta risultati positivi, una percentuale notevolmente più alta rispetto ad altre discipline. Questo non solo crea una rappresentazione distorta della realtà, ma amplifica il rischio di undead theories, teorie prive di solide basi empiriche che continuano a dominare il dibattito scientifico.\n\n73.7.4 Pratiche di Ricerca Dubbiamente Etiche\nLa pressione a pubblicare ha portato all’emergere di comportamenti noti come Questionable Research Practices (QRPs). Tra questi:\n\n\nP-hacking: manipolazione dei dati o analisi fino a ottenere un p-value significativo (&lt; 0.05).\n\nHARKing (Hypothesizing After Results are Known): modificare l’ipotesi iniziale per adattarla ai risultati ottenuti.\n\nStopping opzionale: interrompere la raccolta dei dati quando si raggiunge un p-value desiderato.\n\nQueste pratiche, pur non essendo sempre considerate frodi, distorcono i risultati e compromettono la replicabilità degli studi, creando teorie difficili da falsificare.\n\n73.7.5 La Centralità dei Valori-p e la Crisi della Significatività Statistica\nIl valore-p, elemento centrale della metodologia scientifica basata sull’ipotesi nulla (Null Hypothesis Significance Testing), è diventato una “valuta” per la pubblicazione. Tuttavia, affidarsi esclusivamente ai valori-p presenta gravi limiti:\n\n\nParadosso di Lindley: con campioni di grandi dimensioni, valori-p vicini a 0.05 possono supportare l’ipotesi nulla invece di confutarla.\n\nDistorsioni da QRPs: l’utilizzo di pratiche discutibili può produrre falsi positivi statisticamente significativi.\n\nBenché alcuni studiosi abbiano proposto l’abbassamento della soglia di significatività statistica a 0.005 o l’integrazione dei valori-p con stime degli effetti e intervalli di confidenza, il punto centrale continua ad essere il fatto che l’enfasi dovrebbe spostarsi dai risultati statistici alla qualità metodologica degli studi.\nPer affrontare questi problemi, è necessario un cambiamento culturale e strutturale. La trasparenza, l’autocorrezione e l’adozione di pratiche come la preregistrazione degli studi possono aiutare a ridurre l’impatto dei bias e delle QRPs. Inoltre, incentivare repliche rigorose e promuovere un sistema di pubblicazione che premi la qualità rispetto alla quantità sono passi fondamentali per migliorare la credibilità della scienza.\n\n73.7.6 Campioni Troppo Piccoli\nUno dei fattori chiave che contribuiscono alla crisi della replicazione in psicologia è l’uso di campioni di dimensioni ridotte. Questo approccio ha permesso ai ricercatori di massimizzare la quantità di pubblicazioni a scapito della qualità e dell’affidabilità degli effetti rilevati. Higginson e Munafò (2016) sottolineano come questo fenomeno rappresenti una “selezione naturale della cattiva scienza”, dove incentivi strutturali premiano metodologie di ricerca poco rigorose.\nContrariamente a quanto si potrebbe pensare, ottenere un effetto significativo con un campione piccolo non garantisce che lo stesso effetto rimanga significativo con un campione più grande. Questo problema è strettamente legato alla potenza statistica, che rappresenta la probabilità, nel lungo periodo, di rifiutare correttamente l’ipotesi nulla quando l’ipotesi alternativa è vera. Una potenza statistica bassa comporta un’elevata probabilità di errori di Tipo II (falsi negativi) e, allo stesso tempo, riduce la probabilità che un risultato significativo rifletta un effetto reale.\nIn psicologia, la potenza statistica viene solitamente fissata a un minimo dell’80%, il che significa che, nel lungo termine, uno studio dovrebbe avere l’80% di possibilità di rilevare un effetto reale. Tuttavia, molti studi più datati raramente menzionano la potenza statistica, nonostante il concetto sia noto dagli anni ’30. Questo ha contribuito a generare una letteratura scientifica con effetti sovrastimati o poco affidabili.\nIn un approccio frequentista, per calcolare la potenza di uno studio, è necessario conoscere almeno due dei seguenti tre parametri: dimensione dell’effetto atteso, criterio di significatività e dimensione del campione pianificata. Per esempio, un ricercatore che si aspetta di trovare un effetto “medio” (Cohen’s d = 0.50) con un criterio di significatività di p &lt; .05 può determinare la dimensione del campione necessaria per garantire una potenza sufficiente. Tuttavia, molti studi psicologici hanno ignorato questo tipo di pianificazione, basandosi su campioni troppo piccoli per rilevare effetti affidabili.\nL’uso di campioni piccoli, combinato con pratiche discutibili di ricerca (Questionable Research Practices, QRPs) e bias di pubblicazione, ha portato a una letteratura scientifica piena di effetti inflazionati. Ad esempio, meta-analisi iniziali sul concetto di esaurimento dell’ego (ego depletion) stimavano un effetto medio (d = 0.62). Tuttavia, repliche successive hanno trovato effetti molto più piccoli, spesso inferiori a d = 0.10. Allo stesso modo, il progetto dell’Open Science Collaboration (2015) ha evidenziato che le dimensioni degli effetti nelle repliche erano, in media, dimezzate rispetto agli studi originali.\nCampioni di piccole dimensioni non solo riducono la probabilità di rilevare effetti reali, ma compromettono anche la credibilità dei risultati significativi. Una bassa potenza statistica mina l’obiettivo fondamentale della ricerca scientifica, limitando la capacità di trarre conclusioni solide e contribuendo alla crisi della replicazione. Per migliorare la qualità della scienza, è essenziale adottare pratiche di ricerca più rigorose, pianificando adeguatamente la dimensione del campione e garantendo una potenza statistica sufficiente.\n\n73.7.7 La Misurazione: Un Problema Sottovalutato\nOltre alle dimensioni campionarie inadeguate, la psicologia potrebbe soffrire di problemi legati alla misurazione. Per rispondere a domande scientifiche, i ricercatori devono definire e misurare con precisione il costrutto oggetto di indagine. Ad esempio, per investigare se una mentalità di crescita possa migliorare l’intelligenza, un ricercatore deve prima definire e poi misurare sia la mentalità che l’intelligenza. Tuttavia, la misurazione è un processo complesso e impegnativo.\nL’intelligenza è un costrutto latente, il che significa che, a differenza dell’altezza di una persona, non può essere osservata o misurata direttamente. Gli psicologi inferiscono l’intelligenza stimando il quoziente intellettivo (QI) di un individuo, basandosi sulle risposte a numerose domande di un test di intelligenza, adattate all’età del partecipante. Ma come possiamo sapere se il QI rappresenta un buon indicatore dell’intelligenza? È necessario valutare la validità di costrutto, definita come la capacità di una misura di comportarsi in modo coerente con le ipotesi teoriche (Cronbach e Meehl, 1955; Fink, 2010). Alcuni ricercatori hanno sostenuto che una spiegazione spesso trascurata della crisi della replicazione risieda nella scarsa validità di costrutto delle nostre misure (Lilienfeld e Strother, 2020; Loken e Gelman, 2017).\nPer evidenziare il problema della misurazione in psicologia, Flake e colleghi hanno condotto una revisione di articoli pubblicati in una rivista prestigiosa. La loro analisi ha mostrato che molte scale di misurazione utilizzate non avevano una chiara fonte dichiarata, mentre altre erano state sviluppate senza una documentazione adeguata. Inoltre, una parte significativa delle scale citate era stata modificata rispetto alla versione originale, rendendo sconosciute le loro proprietà psicometriche.\nGli autori hanno anche rilevato l’uso di Pratiche di Misurazione Discutibili (Questionable Measurement Practices, QMPs), che includono la mancata divulgazione di informazioni sulla validità delle misure quando questa non risulta soddisfacente. Questi problemi suggeriscono che molti costrutti psicologici non siano adeguatamente validati, un fattore che potrebbe contribuire alle difficoltà di replicazione degli studi.\nAltri ricercatori hanno argomentato che problemi di validità interna ed esterna possano contribuire alla crisi della replicazione (Fabrigar et al., 2020). La validità interna si riferisce a come uno studio stabilisce una relazione di causa-effetto tra le variabili indipendenti e dipendenti (Cook e Campbell, 1979). Fabrigar et al. suggeriscono che un tentativo di replicazione possa fallire se:\n\nLo studio originale ha sofferto di minacce alla validità che hanno causato un effetto spurio (alta validità interna nella replica).\nI ricercatori introducono elementi assenti nello studio originale (bassa validità interna nella replica).\n\nLa validità esterna riguarda la possibilità di generalizzare i risultati di uno studio ad altri contesti o popolazioni. Questo può influenzare le repliche se, ad esempio, la replica viene condotta su una popolazione diversa o se i materiali dello studio sono tradotti da un’altra lingua, causando incomprensioni nei partecipanti.\nPer sintetizzare questi problemi, Flake e Fried (2020) li definiscono “measurement schmeasurement”, espressione che descrive la mancanza di attenzione verso la validità delle misure nella scienza psicologica. Se le misure utilizzate in uno studio non sono valide, ne consegue che anche i risultati e le conclusioni tratte non possono essere considerati affidabili. Quando tali studi vengono replicati, potrebbero essere destinati al fallimento ancor prima di iniziare.\n\n73.7.8 La Novità a Scapito della Replicazione: Una Distorsione nella Ricerca\nL’enfasi eccessiva sui risultati innovativi e il valore attribuito alle scoperte significative stanno incentivando pratiche di ricerca distorte, favorendo la sovrarappresentazione di risultati positivi e una mancanza di rigore metodologico (Ferguson & Heene, 2012; Ware & Munafò, 2015).\nLa psicologia sperimentale, nata nel 1879 con il primo laboratorio fondato da Wilhelm Wundt, si trova oggi a fronteggiare una crisi di replicazione nonostante oltre un secolo di progresso scientifico. Una delle principali cause è la scarsa attenzione dedicata agli studi di replicazione, storicamente poco valorizzati e raramente premiati nelle scienze sociali.\nLa cultura accademica attuale privilegia la novità e i risultati positivi, relegando i risultati nulli e gli studi di replicazione a un ruolo marginale. Questo fenomeno riflette ciò che Antonakis (2017) definisce significosis – un’ossessione per i risultati significativi – e neofilia – un’eccessiva enfasi sulla novità. Già Sterling (1959) aveva messo in guardia contro il rischio che i ricercatori testassero ripetutamente un’ipotesi fino a ottenere, per puro caso, un risultato significativo, senza verificarlo attraverso replicazioni. In assenza di queste verifiche, interi ambiti di studio possono essere costruiti su un numero allarmante di affermazioni non supportate da dati solidi.\nQuesto squilibrio si riflette non solo nella letteratura scientifica, ma anche nei progetti di ricerca condotti dagli studenti. Le tesi di laurea in psicologia, spesso realizzate in autonomia, senza finanziamenti e con tempistiche ridotte, soffrono degli stessi problemi della ricerca accademica: campioni di piccole dimensioni, studi sottopotenziati e un’elevata probabilità di falsi positivi. Se pubblicati selettivamente, questi progetti rischiano di premiare la fortuna più della qualità scientifica.\nIniziative come il Collaborative Replications and Education Project (CREP) rappresentano un passo verso un cambiamento culturale. CREP incoraggia gli studenti a condurre studi di replicazione come parte del loro percorso formativo, promuovendo una scienza più collaborativa, rigorosa e orientata alla verifica dei risultati, contrastando così la prevalenza della novità fine a se stessa.\n\n73.7.9 La scienza non si autocorregge come dovrebbe\nUn principio cardine della scienza è l’autocorrezione, ma nella pratica accademica moderna, questo processo sembra spesso ostacolato da incentivi e preoccupazioni reputazionali. I ricercatori, pressati dalle scadenze per nuovi progetti o richieste di finanziamento, raramente dedicano il tempo necessario a rivedere e correggere i propri lavori passati. Questo mancato impegno rappresenta una delle spiegazioni della crisi di replicazione.\nUn esempio significativo è il Registered Replication Report dello studio di Srull e Wyer (1979), replicato da McCarthy et al. (2018). Lo studio originale aveva mostrato che il priming con stimoli aggressivi portava i partecipanti a interpretare un comportamento ambiguo come più ostile. Tuttavia, il tentativo di replicazione ha rilevato un effetto trascurabile. Una possibile spiegazione è che alcune statistiche dello studio originale fossero riportate in modo errato, un errore che, nonostante tutto, non è mai stato corretto. Similmente, altri casi documentano gravi discrepanze nei dati riportati in letteratura, come dimostrato da van der Zee et al. (2017) nel loro riesame di articoli del Cornell Food Lab, che ha rivelato oltre 150 incongruenze.\nLa microbiologa Elizabeth Bik ha inoltre evidenziato che la manipolazione di immagini scientifiche è diventata una forma emergente di cattiva condotta, volta a rendere i risultati più impressionanti o a mascherare dati problematici. Sebbene alcuni casi di manipolazione portino a ritrazioni o correzioni, il lavoro di revisione è spesso svolto da altri ricercatori come attività volontaria, suggerendo che la scienza sia più “eterocorrettiva” che autocorrettiva.\nNonostante le difficoltà, il processo di autocorrezione è fondamentale per il progresso scientifico. Vazire (2020) sostiene che il disagio provocato dalla revisione critica sia salutare e necessiti di una maggiore umiltà intellettuale da parte dei ricercatori. Questo include il riconoscimento pubblico delle limitazioni dei propri studi e, quando necessario, la pubblicazione di correzioni o dichiarazioni di perdita di fiducia nei risultati originali.\n\n73.7.10 La Scienza Chiusa come Ostacolo alla Replicazione\nUno degli ostacoli principali alla replicazione è la mancanza di trasparenza e dettaglio negli studi precedenti. In un sistema di “scienza chiusa,” in cui dati e metodi sono trattati come segreti industriali, ricreare esperimenti e verificare analisi diventa un’impresa ardua, se non impossibile. Questa opacità interessa molti aspetti della ricerca, dai materiali utilizzati ai dati raccolti, fino alle scelte analitiche effettuate durante lo studio.\nPratiche come la reportistica selettiva e la flessibilità non dichiarata nei metodi e nei dati compromettono l’integrità della scienza. La riluttanza a condividere dati e materiali, insieme al bias di pubblicazione che favorisce i risultati significativi rispetto a quelli nulli, amplifica ulteriormente il problema (Bruton et al., 2020; Nosek et al., 2012).\nUn esempio concreto riguarda le decisioni prese durante l’analisi dei dati, come la gestione dei valori anomali o le correzioni per analisi multiple. Queste scelte possono avere un impatto notevole sui risultati, ma se non vengono documentate in modo trasparente, altri ricercatori non saranno in grado di replicare gli stessi risultati. Questo problema è noto come il giardino dei sentieri che si biforcano (garden of forking paths), dove una serie di decisioni non esplicitate porta a risultati divergenti e difficili da verificare (Gelman & Loken, 2013).\n\n\n\n\n\n\nLo psicologo Paul Meehl condusse uno studio su un campione di cinquantasettamila studenti delle scuole superiori del Minnesota, indagando su variabili quali religione, abitudini nel tempo libero, ordine di nascita, numero di fratelli, piani post-diploma e numerosi altri aspetti (Meehl, 2012). Complessivamente, le diverse risposte dei partecipanti potevano essere combinate in 990 modi distinti, permettendo analisi del tipo: “Gli studenti appassionati di cucina hanno una maggiore probabilità di essere figli unici?” o “Gli studenti provenienti da famiglie battiste sono più inclini a partecipare a club politici scolastici?”. Meehl evidenziò che, analizzando i dati, il 92% di queste possibili combinazioni risultava in correlazioni statisticamente significative. Queste differenze, sebbene reali, presumibilmente derivano da cause multifattoriali e complesse.\nAndrew Gelman ha denominato questo fenomeno Il Giardino dei Sentieri che si Biforcano [Garden of Forking Paths; Gelman & Loken (2013)], riferendosi ai molteplici gradi di libertà a disposizione del ricercatore nell’analisi dei dati. Come nell’esempio di Meehl, è possibile esaminare le differenze intergruppo (se questo è l’oggetto di interesse) da molteplici prospettive. Con un campione sufficientemente ampio, alcune di queste differenze risulteranno “statisticamente significative”. Ciò indica che, in quello specifico campione, quel particolare aspetto dei dati è rilevante. Tuttavia, questa differenza “statisticamente significativa” non sarà necessariamente generalizzabile ad un altro campione, il quale presenterà le proprie idiosincrasie.\nIn altri termini, come sottolineato da Gelman & Loken (2013), l’approccio basato sul test dell’ipotesi nulla si limita a “descrivere il rumore”. Da un punto di vista teorico, simili esercizi statistici risultano privi di valore euristico e non contribuiscono in nessun modo all’avanzamento delle conoscenze sul fenomeno oggetto di studio.\nIn un’ottica di inferenza statistica, questo problema è riconducibile al concetto di “p-hacking” o “data dredging”, dove l’esplorazione esaustiva di molteplici ipotesi statistiche su un singolo set di dati può portare a falsi positivi e a una sovrastima della significatività statistica.\n\n\n\nLa soluzione è chiara: promuovere una cultura di apertura, rendendo dati e metodi accessibili. Nonostante i progressi tecnologici che facilitano la condivisione, questa pratica rimane poco diffusa. Sebbene esistano ragioni valide per non condividere i dati, come la tutela dell’anonimato dei partecipanti, tali motivazioni dovrebbero essere dichiarate in modo esplicito e rigoroso.\nQuesti ostacoli sottolineano l’urgenza di una trasformazione culturale all’interno della comunità scientifica, che favorisca trasparenza e collaborazione. Affrontare queste limitazioni strutturali è essenziale per superare la crisi di replicazione, permettendo alla scienza di avanzare in modo più affidabile e autoregolarsi nel tempo.\n\n73.7.11 La Probabilità Inversa\nOltre a questi fattori, alcuni studiosi sostengono che la radice della crisi della replicazione sia ancora più profonda e risieda nell’approccio statistico stesso, ampiamente adottato dalla comunità scientifica (Chivers, 2024; Gelman & Loken, 2014; Loken & Gelman, 2017). Questo punto di vista suggerisce che le difficoltà nella replicazione dei risultati non siano solo il prodotto di comportamenti individuali discutibili, ma derivino in larga parte da un’interpretazione e un’applicazione problematica dei metodi statistici.\nPer comprendere meglio questa questione, dobbiamo tornare alle basi della statistica inferenziale. L’approccio frequentista, dominante nella ricerca scientifica, si basa sulle probabilità di campionamento. Questo metodo, che risale a Jakob Bernoulli nel XVIII secolo, calcola la probabilità di osservare certi dati assumendo che una determinata ipotesi sia vera. Il famoso “p-value” è un esempio di questa logica: esso indica la probabilità di ottenere risultati estremi quanto o più estremi di quelli osservati, supponendo che l’ipotesi nulla sia vera.\nTuttavia, questo approccio ha un limite fondamentale: non ci dice direttamente quanto è probabile che la nostra ipotesi sia vera alla luce dei dati raccolti. In altre parole, non fornisce una “probabilità inferenziale”, cioè la probabilità che l’ipotesi sia corretta in base ai risultati ottenuti. Qui entra in gioco l’approccio bayesiano. Il teorema di Bayes offre un metodo per calcolare proprio questa probabilità inferenziale. L’approccio bayesiano tiene conto non solo dei dati osservati, ma anche delle conoscenze pregresse (le “prior”) relative all’ipotesi in esame.\nLa differenza tra questi due approcci è cruciale. Mentre il p-value ci dice quanto sono improbabili i nostri dati se l’ipotesi nulla è vera, l’approccio bayesiano ci fornisce la probabilità che la nostra ipotesi sia vera alla luce dei dati raccolti e delle conoscenze precedenti.\n\n73.7.12 Implicazioni per la Pratica Scientifica\nQuesta distinzione ha implicazioni profonde per la pratica scientifica. L’uso esclusivo dell’approccio frequentista può portare a sovrastimare la forza delle evidenze a favore di un’ipotesi, specialmente quando si lavora con campioni piccoli o si conducono molti test statistici, come spesso accade in psicologia.\nAlcune soluzioni proposte per affrontare la crisi della replicazione includono:\n\nAbbassare la soglia di significatività statistica, rendendo più difficile dichiarare un risultato “significativo”.\nRichiedere la preregistrazione delle ipotesi per prevenire l’HARKing (Hypothesizing After Results are Known).\nFar sì che le riviste accettino gli articoli basandosi sui metodi piuttosto che sui risultati, per evitare il bias verso la pubblicazione di risultati solo “positivi” o “nuovi”.\n\nTuttavia, queste soluzioni, pur utili, non affrontano il problema fondamentale dell’interpretazione delle evidenze statistiche. L’adozione di un approccio bayesiano offre una soluzione più radicale, fornendo un quadro più completo e realistico della forza delle evidenze a favore o contro un’ipotesi scientifica.\n\n73.7.12.1 Guardare i Dati\nConsideriamo una simulazione, ispirata da Lakens (2015), che illustra come una pratica apparentemente innocua – osservare i risultati man mano che vengono raccolti nell’approccio frequentista – possa avere conseguenze significative sulle conclusioni di uno studio. In particolare, questa pratica può influire sulla probabilità di ottenere un risultato statisticamente significativo.\nNella simulazione seguente, due campioni casuali vengono estratti dalla stessa popolazione normale di partenza. Di conseguenza, l’“ipotesi nulla” è vera: non c’è differenza tra le medie delle popolazioni. Tuttavia, a causa della variabilità campionaria, il p-valore risulta fortemente influenzato da ogni singola osservazione aggiunta al campione.\n\nsimulate_t_tests &lt;- function(seed, max_sample_size, mu = 0, sigma = 1) {\n  set.seed(seed)\n\n  # Intervallo di grandezza campionaria\n  sample_sizes &lt;- seq(2, max_sample_size, by = 2)\n  p_values &lt;- numeric(length(sample_sizes))\n\n  # Genera due campioni grandi iniziali da una distribuzione normale\n  full_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n  full_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n  # Simulazione\n  for (i in seq_along(sample_sizes)) {\n    n &lt;- sample_sizes[i]\n\n    # Estrai sottoinsiemi incrementali dai campioni completi\n    sample1 &lt;- full_sample1[1:n]\n    sample2 &lt;- full_sample2[1:n]\n\n    # Esegui il t-test per il confronto delle medie di due gruppi indipendenti\n    t_test &lt;- t.test(sample1, sample2, var.equal = TRUE)\n    p_values[i] &lt;- t_test$p.value\n  }\n\n  # Crea il grafico del p-valore in funzione della grandezza campionaria\n  plot(\n    sample_sizes, p_values, type = \"l\", col = \"#b97c7c\",\n    xlab = \"Grandezza Campionaria\", ylab = \"P-valore\",\n    main = \"P-valore in funzione della grandezza campionaria\"\n  )\n  abline(h = 0.05, col = \"#8f2727\", lty = 2, lwd = 1.5)\n  legend(\"topright\", legend = \"Significatività a 0.05\", col = \"#8f2727\", lty = 2, cex = 0.8)\n}\n\nNelle due simulazioni seguenti, osserviamo come il p-valore cambi progressivamente aumentando la dimensione dei campioni casuali da \\(n = 2\\) a \\(n = 300\\). È evidente come il p-valore vari drasticamente con l’aggiunta di nuove osservazioni ai campioni. Inoltre, in alcune configurazioni, il p-valore può scendere al di sotto della soglia critica di 0.05 per puro caso. Se un ricercatore interrompesse la raccolta dei dati in quel momento, otterrebbe un risultato “statisticamente significativo”, pur avendo campioni estratti dalla stessa popolazione.\n\nsimulate_t_tests(seed = 1234, max_sample_size = 300, mu = 0, sigma = 2)\nsimulate_t_tests(seed = 2, max_sample_size = 300, mu = 0, sigma = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuesta simulazione mette in evidenza una limitazione fondamentale dell’approccio frequentista: ogni test statistico considera esclusivamente i dati del campione corrente, ignorando le conoscenze accumulate in precedenza. Questo rende il processo decisionale estremamente volatile, poiché, teoricamente, ad ogni nuovo studio si “dimentica” tutta l’informazione derivante dagli studi precedenti.\n\n73.7.12.2 Analisi Bayesiana\nL’approccio bayesiano offre una soluzione elegante a questo problema. Nel framework bayesiano, la distribuzione a posteriori (cioè, la nostra convinzione aggiornata dopo aver osservato i dati) bilancia sempre l’informazione a priori (ciò che sapevamo prima dell’esperimento) con la verosimiglianza (ciò che i dati ci dicono). Questo equilibrio è particolarmente prezioso quando i dati sono deboli o contengono molto rumore, come nel caso dei dati della simulazione che stiamo discutendo. In tali situazioni, l’informazione a priori assume un ruolo più rilevante, impedendo conclusioni affrettate basate su dati poco informativi.\nPer illustrare questa differenza, consideriamo l’analisi bayesiana dei dati simulati in precedenza. Se questi dati vengono analizzati con l’approccio frequentista, forniscono un risultato “statisticamente significativo”, suggerendo una differenza tra i due gruppi.\nTuttavia, analizzando gli stessi dati con un approccio bayesiano, otteniamo un intervallo di credibilità al 95% compreso tra -0.52 e 1.12. Poiché questo intervallo include lo zero, possiamo affermare, con un livello di certezza soggettiva del 95%, che non c’è una differenza sostanziale tra le medie delle due popolazioni da cui sono stati estratti i campioni.\nQuesta discrepanza nei risultati evidenzia un punto cruciale: l’approccio bayesiano è più resistente ai falsi positivi in presenza di dati rumorosi o campioni piccoli. Invece di forzare una decisione binaria (significativo/non significativo) basata su una soglia arbitraria, l’analisi bayesiana fornisce una rappresentazione più sfumata e realistica dell’incertezza associata alle nostre conclusioni.\nInoltre, l’approccio bayesiano offre il vantaggio di essere cumulativo: ogni nuovo studio non parte da zero, ma incorpora naturalmente le conoscenze precedenti attraverso la distribuzione a priori.\n\n# Imposta il seme per la riproducibilità\nset.seed(12)\n\n# Parametri della distribuzione normale\nmu &lt;- 0\nsigma &lt;- 2\nmax_sample_size &lt;- 50\n\n# Genera due campioni indipendenti\nfull_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\nfull_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n\n# Prepara i dati per Stan\nstan_data &lt;- list(\n  N1 = length(full_sample1),\n  N2 = length(full_sample2),\n  y1 = full_sample1,\n  y2 = full_sample2\n)\n\n# Visualizza i dati preparati\nprint(stan_data)\n#&gt; $N1\n#&gt; [1] 50\n#&gt; \n#&gt; $N2\n#&gt; [1] 50\n#&gt; \n#&gt; $y1\n#&gt;  [1] -2.9611  3.1543 -1.9135 -1.8400 -3.9953 -0.5446 -0.6307 -1.2565 -0.2129\n#&gt; [10]  0.8560 -1.5554 -2.5878 -1.5591  0.0239 -0.3048 -1.4069  2.3778  0.6810\n#&gt; [19]  1.0139 -0.5866  0.4473  4.0144  2.0240 -0.6049 -2.0505 -0.5348 -0.3982\n#&gt; [28]  0.2622  0.2916  0.7241  1.3480  4.1441 -1.0821 -2.1410 -0.7449 -0.9703\n#&gt; [37]  0.5496 -0.9590  1.5962 -2.0089  0.2100 -2.3120  1.1563 -3.1913 -0.6170\n#&gt; [46]  0.8989 -1.9541  0.3800  1.4629 -0.9852\n#&gt; \n#&gt; $y2\n#&gt;  [1] -0.085370 -0.225341  0.913654  4.040670 -2.101780  1.469304  1.078499\n#&gt;  [8] -2.628546 -0.500077  0.628409  0.813093  1.988841  1.711537  0.394258\n#&gt; [15]  1.668650  1.693580  3.908211 -4.298520  1.942241  2.290123 -1.050801\n#&gt; [22]  0.500640 -0.858813 -0.365039 -0.206621 -1.267676 -2.542108 -0.767901\n#&gt; [29]  1.033512 -0.355937  0.008516 -2.548119 -0.404221  2.328932 -0.046759\n#&gt; [36]  1.794313 -0.353449  2.227418 -1.083778 -1.926797  0.752897 -1.969348\n#&gt; [43]  1.795119  0.258525  2.067406 -0.684579  0.904563 -1.389476 -0.478027\n#&gt; [50] -2.014598\n\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"two_means_diff.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\nmod$code() # Stampa il codice del modello\n#&gt;  [1] \"data {\"                                                                \n#&gt;  [2] \"  int&lt;lower=0&gt; N1; // Numero di osservazioni nel gruppo 1\"             \n#&gt;  [3] \"  int&lt;lower=0&gt; N2; // Numero di osservazioni nel gruppo 2\"             \n#&gt;  [4] \"  vector[N1] y1; // Dati del gruppo 1\"                                 \n#&gt;  [5] \"  vector[N2] y2; // Dati del gruppo 2\"                                 \n#&gt;  [6] \"}\"                                                                     \n#&gt;  [7] \"parameters {\"                                                          \n#&gt;  [8] \"  real mu1; // Media del gruppo 1\"                                     \n#&gt;  [9] \"  real delta; // Differenza tra le medie\"                              \n#&gt; [10] \"  real&lt;lower=0&gt; sigma; // Deviazione standard comune\"                  \n#&gt; [11] \"  real&lt;lower=0&gt; nu; // Gradi di libertà per la distribuzione t\"        \n#&gt; [12] \"}\"                                                                     \n#&gt; [13] \"transformed parameters {\"                                              \n#&gt; [14] \"  real mu2; // Media del gruppo 2\"                                     \n#&gt; [15] \"  mu2 = mu1 + delta;\"                                                  \n#&gt; [16] \"}\"                                                                     \n#&gt; [17] \"model {\"                                                               \n#&gt; [18] \"  // Priori\"                                                           \n#&gt; [19] \"  mu1 ~ normal(0, 5);\"                                                 \n#&gt; [20] \"  delta ~ normal(0, 2); // Priore su delta\"                            \n#&gt; [21] \"  sigma ~ cauchy(0, 5);\"                                               \n#&gt; [22] \"  nu ~ gamma(2, 0.1); // Priore sulla t-student\"                       \n#&gt; [23] \"  \"                                                                    \n#&gt; [24] \"  // Verosimiglianza\"                                                  \n#&gt; [25] \"  y1 ~ student_t(nu, mu1, sigma);\"                                     \n#&gt; [26] \"  y2 ~ student_t(nu, mu2, sigma);\"                                     \n#&gt; [27] \"}\"                                                                     \n#&gt; [28] \"generated quantities {\"                                                \n#&gt; [29] \"  real diff; // Differenza tra le medie (alias di delta per chiarezza)\"\n#&gt; [30] \"  diff = delta;\"                                                       \n#&gt; [31] \"}\"\n\nEsegui il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  show_messages = FALSE\n)\n\nRiassumi i risultati per mu1, mu2 e delta:\n\nfit_summary &lt;- fit$summary(variables = c(\"mu1\", \"mu2\", \"delta\"))\nprint(fit_summary)\n#&gt; # A tibble: 3 × 10\n#&gt;   variable   mean median    sd   mad      q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu1      -0.313 -0.312 0.241 0.238 -0.707  0.0818  1.00    5378.    5491.\n#&gt; 2 mu2       0.164  0.166 0.246 0.248 -0.235  0.568   1.00    9428.    6234.\n#&gt; 3 delta     0.477  0.474 0.341 0.344 -0.0887 1.04    1.00    5155.    5260.\n\nEstrai i campioni di delta:\n\ndelta_samples &lt;- fit$draws(variables = \"delta\", format = \"matrix\")[, 1]\n\nDisegna la distribuzione a posteriori di delta:\n\ndelta_df &lt;- data.frame(delta = delta_samples)\n\nggplot(delta_df, aes(x = delta)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"#b97c7c\", alpha = 0.75) +\n  geom_vline(\n    xintercept = mean(delta_samples),\n    linetype = \"dashed\",\n    linewidth = 1.2,\n    label = paste(\"Mean:\", round(mean(delta_samples), 2))\n  ) +\n  labs(\n    x = \"delta\",\n    y = \"Density\",\n    title = \"Posterior distribution of delta\"\n  ) \n\n\n\n\n\n\n\nPuoi calcolare l’intervallo di credibilità usando per un intervallo al 95%:\n\nquantile(delta_samples, probs = c(0.025, 0.975))\n#&gt;    2.5%   97.5% \n#&gt; -0.1872  1.1553\n\n\n73.7.12.3 Garbage In, Garbage Out\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l’ipotesi nulla o non la si rifiuta. Ciò implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, è inevitabile trovare qualche effetto, anche se di minima entità.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell’effetto e di fornire una distribuzione di probabilità. Una distribuzione di probabilità è una rappresentazione grafica delle diverse possibilità che potrebbero verificarsi. In questo contesto, si tratta della “probabilità inversa”, ovvero della plausibilità dell’ipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed è il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l’aggiornamento bayesiano. Il parametro \\(\\delta\\) è la nostra ipotesi sulla differenza tra le due medie, e l’inferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL’approccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell’ipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di “significatività statistica”, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l’approccio frequentista sia spesso considerato “ingenuo” da molti ricercatori, adottare l’approccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione degli incentivi accademici che favoriscono la pubblicazione di un elevato numero di articoli, indipendentemente dalla loro qualità. Un principio fondamentale della ricerca è “Garbage in, garbage out”. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualità delle misurazioni è insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, può trasformare la spazzatura in oro.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#esercizi",
    "href": "chapters/replication_crisis/01_crisis.html#esercizi",
    "title": "73  La crisi della replicazione",
    "section": "\n73.8 Esercizi",
    "text": "73.8 Esercizi\n\nEsercizio 73.1 Esistono numerosi esempi di ricerche che non riescono a essere replicate (posso citare anche uno studio di replicazione che ho condotto io stesso: Caudek et al. (2017)). Un recente caso emblematico è rappresentato dallo studio di Karataş & Cutright (2023) e dal successivo tentativo di replicazione condotto da Moore et al. (2024). Analizzando le quattro principali argomentazioni sollevate da Gelman & Brown (2024) per criticare lo studio di Aungle & Langer (2023), si offra un’interpretazione del perché lo studio di Karataş & Cutright (2023) non sia stato replicato con successo.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "title": "73  La crisi della replicazione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] posterior_1.6.0.9000 cmdstanr_0.8.1       thematic_0.1.6      \n#&gt;  [4] MetBrewer_0.2.0      ggokabeito_0.1.0     see_0.10.0          \n#&gt;  [7] gridExtra_2.3        patchwork_1.3.0      bayesplot_1.11.1    \n#&gt; [10] psych_2.4.12         scales_1.3.0         markdown_1.13       \n#&gt; [13] knitr_1.49           lubridate_1.9.4      forcats_1.0.0       \n#&gt; [16] stringr_1.5.1        dplyr_1.1.4          purrr_1.0.4         \n#&gt; [19] readr_2.1.5          tidyr_1.3.1          tibble_3.2.1        \n#&gt; [22] ggplot2_3.5.1        tidyverse_2.0.0      rio_1.2.3           \n#&gt; [25] here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.50           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.5       lattice_0.22-6      \n#&gt;  [7] tzdb_0.4.0           vctrs_0.6.5          tools_4.4.2         \n#&gt; [10] ps_1.8.1             generics_0.1.3       parallel_4.4.2      \n#&gt; [13] pacman_0.5.1         pkgconfig_2.0.3      data.table_1.16.4   \n#&gt; [16] checkmate_2.3.2      distributional_0.5.0 lifecycle_1.0.4     \n#&gt; [19] compiler_4.4.2       farver_2.1.2         munsell_0.5.1       \n#&gt; [22] mnormt_2.1.1         htmltools_0.5.8.1    yaml_2.3.10         \n#&gt; [25] pillar_1.10.1        abind_1.4-8          nlme_3.1-167        \n#&gt; [28] tidyselect_1.2.1     digest_0.6.37        stringi_1.8.4       \n#&gt; [31] labeling_0.4.3       rprojroot_2.0.4      fastmap_1.2.0       \n#&gt; [34] grid_4.4.2           colorspace_2.1-1     cli_3.6.4           \n#&gt; [37] magrittr_2.0.3       utf8_1.2.4           withr_3.0.2         \n#&gt; [40] backports_1.5.0      timechange_0.3.0     rmarkdown_2.29      \n#&gt; [43] matrixStats_1.5.0    hms_1.1.3            evaluate_1.0.3      \n#&gt; [46] rlang_1.1.5          glue_1.8.0           rstudioapi_0.17.1   \n#&gt; [49] jsonlite_1.8.9       R6_2.6.1",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "title": "73  La crisi della replicazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230–244.\n\n\nBem, D. J. (2011). Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect. Journal of Personality and Social Psychology, 100(3), 407–425.\n\n\nBruton, S. V., Medlin, M., Brown, M., & Sacco, D. F. (2020). Personal motivations and systemic incentives: Scientists on questionable research practices. Science and Engineering Ethics, 26(3), 1531–1547.\n\n\nCaudek, C., Lorenzino, M., & Liperoti, R. (2017). Delta plots do not reveal response inhibition in lying. Consciousness and Cognition, 55, 232–244.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nFerguson, C. J., & Heene, M. (2012). A vast graveyard of undead theories: Publication bias and psychological science’s aversion to the null. Perspectives on Psychological Science, 7(6), 555–561.\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nGopalakrishna, G., Ter Riet, G., Vink, G., Stoop, I., Wicherts, J. M., & Bouter, L. M. (2022). Prevalence of questionable research practices, research misconduct and their potential explanatory factors: A survey among academic researchers in The Netherlands. PloS one, 17(2), e0263023.\n\n\nGrimes, D. R., Bauch, C. T., & Ioannidis, J. P. (2018). Modelling science trustworthiness under publish or perish pressure. Royal Society open science, 5(1), 171511.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKarataş, M., & Cutright, K. M. (2023). Thinking about God increases acceptance of artificial intelligence in decision-making. Proceedings of the National Academy of Sciences, 120(33), e2218961120.\n\n\nLakens, D. (2015). On the challenges of drawing conclusions from p-values just below 0.05. PeerJ, 3, e1142.\n\n\nLeys, R. (2024). Anatomy of a Train Wreck: The Rise and Fall of Priming Research. University of Chicago Press.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMeehl, P. E. (2012). Why summaries of research on psychological theories are often uninterpretable. In Improving inquiry in social science (pp. 13–59). Routledge.\n\n\nMoore, D. A., Schroeder, J., Bailey, E. R., Gershon, R., Moore, J. E., & Simmons, J. P. (2024). Does thinking about God increase acceptance of artificial intelligence in decision-making? Proceedings of the National Academy of Sciences, 121(31), e2402315121.\n\n\nNosek, B. A., Spies, J. R., & Motyl, M. (2012). Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science, 7(6), 615–631.\n\n\nPennington, C. (2023). A student’s guide to open science: Using the replication crisis to reform psychology. McGraw-Hill Education (UK).\n\n\nWare, J. J., & Munafò, M. R. (2015). Significance chasing in research practice: causes, consequences and possible solutions. Addiction, 110(1), 4–8.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html",
    "title": "74  Limiti dell’inferenza frequentista",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nIn questa sezione della dispensa, abbiamo approfondito il metodo “tradizionale” per il test di significatività dell’ipotesi nulla (NHST). Comprendere la logica sottostante all’approccio NHST è fondamentale, poiché esso ha rappresentato il principale strumento della statistica inferenziale sin dalla sua introduzione all’inizio del XX secolo, e la maggior parte dei ricercatori continua a basarsi su questa procedura per l’analisi dei dati. Tuttavia, negli ultimi anni, l’NHST è stato oggetto di crescenti critiche, con molti studiosi che sostengono che questo approccio possa generare più problemi di quanti ne risolva. Per questo motivo, è cruciale esaminare le critiche avanzate dalla comunità scientifica nei confronti della procedura inferenziale NHST. In questa sezione, analizzeremo alcuni dei principali dubbi e limiti emersi riguardo a tale metodologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "74  Limiti dell’inferenza frequentista",
    "section": "74.1 L’uso del valore-\\(p\\) nel mondo della ricerca",
    "text": "74.1 L’uso del valore-\\(p\\) nel mondo della ricerca\nNel suo articolo “Statistical Errors” (2014), Nuzzo mette in luce i limiti dell’approccio NHST nella pratica scientifica Nuzzo (2014). Sebbene il valore-\\(p\\) sia stato introdotto da Ronald Fisher negli anni ’20, egli non lo concepì mai come un test formale. Fisher lo considerava piuttosto uno strumento informale per valutare se l’evidenza empirica fosse “significativa” in senso colloquiale, ovvero meritevole di ulteriore attenzione. Nella pratica, Fisher suggeriva di assumere un’ipotesi nulla e di calcolare la probabilità di osservare un risultato altrettanto estremo o più estremo di quello ottenuto, presupponendo che il risultato fosse interamente dovuto alla variabilità campionaria. Tuttavia, per Fisher, il valore-\\(p\\) non era una conclusione definitiva, ma uno strumento da integrare in un processo decisionale più ampio, che tenesse conto sia delle evidenze empiriche sia delle conoscenze pregresse del ricercatore. In altre parole, il valore-\\(p\\) era parte di un ragionamento scientifico, non il punto finale di tale ragionamento.\nVerso la fine degli anni ’20, Jerzy Neyman e Egon Pearson, rivali di Fisher, formalizzarono le procedure di decisione statistica con l’obiettivo di renderle più rigorose e oggettive. Introdussero concetti come il potere statistico e il tasso di falsi positivi, ma si distanziarono dall’uso del valore-\\(p\\) proposto da Fisher. Le divergenze tra Fisher, Neyman e Pearson diedero vita a un acceso dibattito: Neyman definì il lavoro di Fisher “matematicamente peggiore dell’inutilità”, mentre Fisher bollò l’approccio di Neyman come “infantile” e “dannoso per la libertà intellettuale dell’Occidente”.\nNel frattempo, altri autori iniziarono a scrivere manuali di statistica per guidare i ricercatori. Tuttavia, molti di questi autori non erano statistici e avevano una comprensione superficiale delle differenze tra i vari approcci. Il risultato fu un sistema ibrido che combinava il valore-\\(p\\) di Fisher con il framework rigoroso di Neyman e Pearson. Fu in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne arbitrariamente definita come “statisticamente significativa”.\nStoricamente, tuttavia, il valore-\\(p\\) proposto da Fisher aveva un significato molto diverso rispetto a quello che gli viene attribuito oggi. Come abbiamo visto, per Fisher era uno strumento informale, da utilizzare all’interno di un processo decisionale più ampio e non come un criterio meccanico per stabilire la verità scientifica. L’uso del valore-\\(p\\) nel sistema ibrido adottato dai manuali di statistica è quindi privo di una solida giustificazione teorica.\nNel 2016, l’American Statistical Association (ASA) ha espresso forti preoccupazioni riguardo all’uso inappropriato del valore-\\(p\\) nella pratica scientifica contemporanea Wasserstein & Lazar (2016):\n\n\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\nL’articolo prosegue sottolineando che:\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical “bright-line” rules (such as “\\(p &lt; 0.05\\)”) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‘true’ on one side of the divide and ‘false’ on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‘yes-no’ decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of “statistical significance” (generally interpreted as ) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "title": "74  Limiti dell’inferenza frequentista",
    "section": "74.2 \\(P\\)-hacking",
    "text": "74.2 \\(P\\)-hacking\nLa pratica del \\(P\\)-hacking rappresenta una delle principali criticità associate all’uso del valore-\\(p\\) ed è conosciuta anche con termini come data-dredging, snooping, fishing, significance-chasing o double-dipping. Secondo Uri Simonsohn, professore all’Università della Pennsylvania, il \\(P\\)-hacking consiste nel manipolare i dati o le analisi fino a ottenere un risultato statisticamente significativo, tipicamente con un valore-\\(p\\) inferiore a 0.05. Ad esempio, si potrebbe dire: “Quel risultato sembra frutto di \\(P\\)-hacking; gli autori hanno escluso una condizione per far scendere il valore-\\(p\\) sotto la soglia di 0.05” oppure “Lei è un \\(P\\)-hacker, controlla continuamente i dati durante la raccolta per trovare un risultato significativo”.\nQuesta pratica trasforma uno studio esplorativo, che dovrebbe essere interpretato con estrema cautela, in uno studio confermativo (apparentemente robusto), i cui risultati, tuttavia, hanno una probabilità molto bassa di essere replicati in ricerche successive. Secondo le simulazioni condotte da Simonsohn, piccole modifiche nelle scelte analitiche possono aumentare il tasso di falsi positivi fino al 60% in un singolo studio.\nIl \\(P\\)-hacking è particolarmente diffuso negli studi che cercano di dimostrare effetti di piccola entità utilizzando dati molto rumorosi. Un’analisi della letteratura psicologica ha rivelato che i valori-\\(p\\) riportati tendono a concentrarsi appena al di sotto della soglia di 0.05, un fenomeno che può essere interpretato come un segnale di \\(P\\)-hacking: i ricercatori eseguono molteplici test statistici fino a trovarne uno che raggiunge la “significatività statistica” e poi riportano solo quello. Come evidenziato in figura, questa pratica non è limitata alla psicologia, ma è ampiamente diffusa in tutti i campi della ricerca scientifica, contribuendo a minare l’affidabilità dei risultati pubblicati.\n\n\n\nDistribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "title": "74  Limiti dell’inferenza frequentista",
    "section": "74.3 Critiche al valore-\\(p\\)",
    "text": "74.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) è stato spesso paragonato a creature fastidiose e persistenti come le zanzare, oppure ai “vestiti nuovi dell’imperatore”, metafora che rappresenta la tendenza a ignorare problemi evidenti preferendo fingere che tutto vada bene. È stato anche definito un intellectual rake sterile, un termine che sottolinea la sua incapacità di produrre risultati utili. Non manca nemmeno l’ironia sul fatto che la procedura di statistical hypothesis inference testing venga chiamata così principalmente per l’acronimo che genera.\nIl valore-\\(p\\) promuove un modo di pensare distorto, spostando l’attenzione dal cuore della ricerca, ovvero la forza della manipolazione sperimentale, verso la dimostrazione di un’ipotesi nulla che si sa già essere falsa. Ad esempio, uno studio condotto su oltre 19,000 individui ha mostrato che le coppie che si incontrano online hanno una probabilità inferiore di divorziare (\\(p &lt; 0.002\\)) e riportano una maggiore soddisfazione nella vita matrimoniale (\\(p &lt; 0.001\\)) rispetto a quelle che si sono conosciute offline. Sebbene questi risultati possano sembrare interessanti, senza considerare la dimensione dell’effetto – come la riduzione del tasso di divorzio dal 7.67% al 5.96% o l’aumento dell’indice di soddisfazione matrimoniale da 5.48 a 5.64 su una scala a sette punti – il loro impatto pratico rischia di essere sopravvalutato. In generale, la domanda chiave non dovrebbe essere “c’è un effetto?”, ma piuttosto “quanto è grande l’effetto?”. Questo approccio permette di valutare meglio l’effettiva rilevanza dei risultati, andando oltre la semplice significatività statistica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "title": "74  Limiti dell’inferenza frequentista",
    "section": "74.4 L’effetto sperimentale è esattamente nullo?",
    "text": "74.4 L’effetto sperimentale è esattamente nullo?\nUna delle critiche più ricorrenti alla logica del test di verifica delle ipotesi statistiche riguarda l’assunzione irrealistica che l’effetto della manipolazione sperimentale sia esattamente nullo. Ad esempio, la fisica ci dimostra che persino lo spostamento di un grammo di massa in una stella distante anni luce dalla Terra può influenzare, seppur minimamente, il movimento delle molecole di un gas sul nostro pianeta (Borel, 1914). Questo esempio suggerisce che ogni manipolazione sperimentale, per quanto piccola, produca in qualche modo un effetto. Pertanto, come sottolinea Andrew Gelman, il problema non è tanto dimostrare che l’ipotesi nulla sia falsa – ovvero che la manipolazione sperimentale non abbia alcun effetto – quanto piuttosto valutare se la dimensione dell’effetto sia sufficientemente grande da avere un impatto pratico e se tale effetto sia riproducibile.\nIn questo contesto, la logica del test dell’ipotesi nulla risulta particolarmente problematica, specialmente quando si lavora con campioni piccoli ed effetti di modesta entità, come accade spesso negli studi psicologici. Questo approccio può portare a una sovrastima della dimensione dell’effetto e a una visione binaria dei risultati (vero/falso), distogliendo l’attenzione dalla stima accurata e non distorta della dimensione effettiva dell’effetto. In altre parole, la ricerca dovrebbe concentrarsi meno sul rifiutare un’ipotesi nulla spesso irrealistica e più sulla comprensione e quantificazione dell’impatto reale delle variabili studiate.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "title": "74  Limiti dell’inferenza frequentista",
    "section": "74.5 Attenti al valore-\\(p\\)!",
    "text": "74.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema. Supponiamo di eseguire un \\(t\\)-test per due campioni indipendenti per verificare l’ipotesi nulla che le medie delle due popolazioni siano uguali. Fissiamo un livello di significatività \\(\\alpha = 0.05\\) e otteniamo un valore-\\(p\\) pari a \\(0.04\\). La domanda è: qual è la probabilità che i due campioni provengano da distribuzioni con la stessa media?\nLe opzioni sono:\n(a) \\(19/20\\); (b) \\(1/19\\); (c) \\(1/20\\); (d) \\(95/100\\); (e) sconosciuta.\nLa risposta corretta è: (e) sconosciuta. Questo perché la statistica frequentista calcola le probabilità dei dati condizionatamente alle ipotesi (assunte come vere), ma non permette di determinare la probabilità di un’ipotesi. In altre parole, il valore-\\(p\\) non fornisce informazioni sulla probabilità che l’ipotesi nulla sia vera o falsa; indica solo la probabilità di osservare i dati (o risultati più estremi) assumendo che l’ipotesi nulla sia vera.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "title": "74  Limiti dell’inferenza frequentista",
    "section": "74.6 La crisi della riprodicibilità dei risultati della ricerca",
    "text": "74.6 La crisi della riprodicibilità dei risultati della ricerca\nNegli ultimi anni, la mancanza di replicabilità dei risultati della ricerca – inclusa quella psicologica – è emersa come un tema di grande rilevanza nel dibattito scientifico. In questo contesto, è stato evidenziato che alcuni aspetti del metodo scientifico, in particolare l’uso del valore-\\(p\\) e la pratica del test di significatività dell’ipotesi nulla (NHST, Null Hypothesis Significance Testing), potrebbero contribuire a quella che è stata definita una “crisi della ricerca scientifica”. Un’analisi approfondita di questo problema è stata proposta da Gelman (2016), il quale sostiene che la NHST sia intrinsecamente problematica. Questo approccio, infatti, spinge i ricercatori a cercare di rigettare un’ipotesi “fantoccio” (straw-man), spesso già falsa a priori o di scarso interesse scientifico, a favore di un’ipotesi alternativa che il ricercatore preferisce. In generale, è più ragionevole affermare che la differenza tra due condizioni sia molto piccola piuttosto che esattamente uguale a zero, ma la NHST non è progettata per cogliere questa sfumatura.\nNei libri di statistica, la NHST viene spesso presentata come una sorta di “alchimia” che trasforma la casualità in una falsa certezza, utilizzando termini come “confidenza” e “significatività” (Gelman, 2016). Il processo di raccolta dei dati, analisi e inferenza statistica viene sintetizzato in una conclusione espressa in termini di valore-\\(p\\) e intervalli di confidenza che escludono lo zero. Tuttavia, questo può creare l’impressione errata che il ricercatore abbia una comprensione completa del fenomeno studiato. Il problema principale della NHST è che spesso produce risultati “statisticamente significativi” in contesti in cui le caratteristiche del fenomeno non giustificano le conclusioni tratte. Questo può portare a una bassa replicabilità dei risultati, contribuendo alla crisi di fiducia nella ricerca.\nLa comunità statistica ha sottolineato come la non replicabilità sia particolarmente evidente quando i ricercatori, utilizzando la NHST, traggono conclusioni errate basate su piccoli campioni ed effetti di dimensioni ridotte. Queste condizioni, insieme ad altre, rendono l’applicazione della NHST estremamente problematica. Purtroppo, queste situazioni descrivono molte delle ricerche recenti in psicologia, un campo in cui gli effetti sono spesso modesti e i campioni limitati.\nLa statistica è stata definita come un metodo per prendere decisioni razionali in condizioni di incertezza. Gli statistici raccomandano ai ricercatori non solo di padroneggiare le tecniche statistiche, ma anche di imparare a convivere con l’incertezza, nonostante la crescente sofisticazione degli strumenti disponibili. Conviverci significa evitare di pensare che ottenere un valore-\\(p\\) “statisticamente significativo” equivalga a risolvere un problema scientifico. Ma allora, come possiamo avere fiducia in ciò che apprendiamo dai dati? Una possibile strategia è la replicazione e la convalida esterna dei risultati, sebbene nella ricerca psicologica e nelle scienze sociali questo sia spesso difficile da realizzare a causa degli elevati costi e delle complessità pratiche. Il problema di quali strumenti metodologici e metodi statistici siano più adatti per indagare i fenomeni psicologici, senza cadere in errori di interpretazione, rimane quindi una questione aperta e di cruciale importanza.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "title": "74  Limiti dell’inferenza frequentista",
    "section": "74.7 Commenti e considerazioni finali",
    "text": "74.7 Commenti e considerazioni finali\nNon possiamo concludere senza affrontare la controversia che circonda il concetto di valore-\\(p\\). Nonostante sia ancora ampiamente utilizzato e spesso interpretato in modo errato, il valore-\\(p\\) conferisce solo una parvenza di legittimità a risultati dubbi, incoraggia cattive pratiche di ricerca e favorisce la produzione di falsi positivi. Inoltre, il suo significato è spesso frainteso, persino dagli esperti: quando chiamati a definire il valore-\\(p\\), molti forniscono risposte imprecise o sbagliate. Ciò che i ricercatori desiderano sapere è se i risultati di uno studio siano corretti o meno, ma il valore-\\(p\\) non fornisce questa informazione. Non dice nulla sulla dimensione dell’effetto, sulla forza dell’evidenza o sulla probabilità che il risultato sia frutto del caso. Allora, qual è il suo vero significato? Stuart Buck lo spiega in modo efficace:\n\nImmaginate di avere una moneta che sospettate sia truccata a favore della testa (l’ipotesi nulla è che la moneta sia equa). La lanciate 100 volte e ottenete più teste che croci. Il valore-\\(p\\) non vi dirà se la moneta è equa, ma vi indicherà la probabilità di ottenere almeno lo stesso numero di teste osservato se la moneta fosse equa. Questo è tutto – niente di più.\n\nIn sintesi, il valore-\\(p\\) risponde a una domanda molto specifica che, tuttavia, non ha alcuna rilevanza diretta per la validità scientifica dei risultati di una ricerca. In un’epoca in cui la crisi della riproducibilità dei risultati è sempre più evidente (Baker, 2016), il test dell’ipotesi nulla e gli intervalli di confidenza frequentisti sono stati identificati come una delle principali cause del problema. Questo ha spinto molti ricercatori a cercare alternative metodologiche più robuste e informative, in grado di superare i limiti intrinseci del valore-\\(p\\) e di promuovere una scienza più affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "title": "74  Limiti dell’inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nBorel, E. (1914). Introduction Géométrique. G. Villars, New York.\n\n\nGelman, A. (2016). Commentary on «Crisis in Science? Or Crisis in Statistics! Mixed Messages in Statistics with Impact on Science». Journal of Statistical Research, 48-50(1), 11–12.\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nNuzzo, R. (2014). Statistical Errors. Nature, 506(7487), 150–152.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html",
    "href": "chapters/replication_crisis/03_effect_size.html",
    "title": "75  La grandezza dell’effetto",
    "section": "",
    "text": "75.1 Introduzione\nLa dimensione dell’effetto (effect size) è un concetto chiave nella metodologia della ricerca, utilizzato per quantificare la forza della relazione statistica tra due variabili. Questa misura standardizzata descrive l’entità di un effetto, come quello di un intervento o di un trattamento, fornendo una valutazione quantitativa dell’importanza di un fenomeno osservato.\nÈ essenziale distinguere tra dimensione dell’effetto e significatività statistica. Un risultato può essere “statisticamente significativo” anche se l’effetto è di piccole dimensioni, e viceversa. La conoscenza di uno di questi aspetti non fornisce automaticamente informazioni sull’altro, evidenziando la necessità di considerare entrambi nell’analisi dei dati.\nL’importanza della dimensione dell’effetto è ampiamente riconosciuta nel mondo della ricerca scientifica. Il manuale dell’American Psychological Association (APA) del 2010 ne sottolinea la rilevanza, raccomandando di includere questa misura negli studi pubblicati. Di conseguenza, la maggior parte degli articoli nelle riviste associate all’APA riporta la dimensione dell’effetto, solitamente indicata tra parentesi accanto al valore-\\(p\\).\nNonostante la sua importanza e la prassi di riportarla, la psicologia scientifica spesso mostra una carenza nella corretta valutazione e interpretazione delle dimensioni dell’effetto. Molti ricercatori si limitano a comunicare questi valori senza analizzarli in profondità, portando a conclusioni che possono risultare superficiali, poco informative, fuorvianti o addirittura errate. Questa tendenza riflette una sottovalutazione sistematica e una diffusa incomprensione del concetto di dimensione dell’effetto, persino tra i professionisti della ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "href": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "title": "75  La grandezza dell’effetto",
    "section": "75.2 Misurazione dell’Effetto: Approcci e Applicazioni",
    "text": "75.2 Misurazione dell’Effetto: Approcci e Applicazioni\nTra le metriche più utilizzate per quantificare l’effetto di un trattamento o di una differenza tra gruppi troviamo il \\(d\\) di Cohen e l’\\(r\\) di Pearson. Il \\(d\\) di Cohen è particolarmente utile per descrivere le differenze tra le medie di due gruppi sperimentali, esprimendo tale differenza in termini di deviazione standard aggregata.\nLa differenza standardizzata tra le medie di due gruppi può essere calcolata con la seguente formula (equazione 5.1, Glass et al., 1981):\n\\[\nd_p = \\frac{M_1 - M_2}{S_p},\n\\]\ndove:\n\n\\(M_1\\) e \\(M_2\\) sono le medie dei due gruppi,\n\\(S_p\\) è la deviazione standard combinata.\n\nUn valore positivo di \\(d_p\\) indica che la media del gruppo 1 è maggiore di quella del gruppo 2. La deviazione standard combinata \\(S_p\\) è calcolata come la radice quadrata della varianza media ponderata per i gradi di libertà (\\(df = n-1\\)) dei due gruppi (pp. 108, Glass et al., 1981):\n\\[\nS_p = \\sqrt{\\frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}},\n\\]\ndove:\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei due gruppi,\n\\(S_1^2\\) e \\(S_2^2\\) sono le varianze (quadrato della deviazione standard) dei due gruppi.\n\nIl \\(d_p\\) di Cohen è strettamente correlato alla statistica \\(t\\) di un test \\(t\\) per campioni indipendenti. Infatti, è possibile calcolare \\(d_p\\) a partire dalla statistica \\(t\\) utilizzando la seguente formula (equazione 5.3, Glass et al., 1981):\n\\[\nd = t \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}.\n\\]\nL’errore standard di \\(d_p\\) è dato da:\n\\[\nSE_{d_p} = \\sqrt{\\frac{n_1 + n_2}{n_1 n_2} + \\frac{d_p^2}{2(n_1 + n_2)}}.\n\\]\nD’altra parte, la statistica \\(r\\) di Pearson misura il grado di correlazione lineare tra due variabili, indicando quanto una variabile possa predire l’altra. È interessante notare che queste due misure, \\(d\\) e \\(r\\), possono essere convertite l’una nell’altra attraverso la relazione:\n\\[\nd = \\frac{2r}{\\sqrt{1-r^2}}.\n\\]\nQuesta conversione permette di passare da una misura di differenza tra medie a una misura di correlazione, offrendo una maggiore flessibilità nell’interpretazione dei risultati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#interpretazione-della-dimensione-delleffetto",
    "href": "chapters/replication_crisis/03_effect_size.html#interpretazione-della-dimensione-delleffetto",
    "title": "75  La grandezza dell’effetto",
    "section": "75.3 Interpretazione della Dimensione dell’Effetto",
    "text": "75.3 Interpretazione della Dimensione dell’Effetto\nL’interpretazione della dimensione dell’effetto è un aspetto cruciale nell’analisi statistica, ma spesso viene affrontata in modi che possono risultare privi di significato o addirittura fuorvianti. Di seguito, esploriamo due approcci comuni e le loro criticità.\n\n75.3.1 Gli Standard di Cohen\nUno dei metodi più diffusi per interpretare la dimensione dell’effetto si basa sugli standard proposti da Jacob Cohen (1977, 1988). Cohen ha suggerito delle soglie arbitrarie per classificare l’effetto:\n\nr = 0.10 → effetto piccolo,\nr = 0.30 → effetto medio,\nr = 0.50 → effetto grande.\n\nTuttavia, come sottolineato da Funder (2019), queste soglie sono spesso utilizzate in modo acritico, senza considerare il contesto specifico. Lo stesso Cohen ha espresso rammarico per aver introdotto queste categorie, precisando che dovrebbero essere adottate solo in assenza di criteri più solidi.\nLe etichette “piccolo”, “medio” e “grande” sono prive di significato se non vengono contestualizzate. Per un’interpretazione corretta, è essenziale porsi due domande fondamentali:\n\nRispetto a cosa? Cosa rappresenta un effetto piccolo, medio o grande nel contesto specifico dello studio?\nA quale scopo? Qual è l’impatto pratico o teorico dell’effetto osservato?\n\nSenza rispondere a queste domande, l’uso degli standard di Cohen rischia di essere poco informativo o addirittura ingannevole.\n\n\n75.3.2 Elevare al Quadrato la Correlazione\nUn altro approccio comune, ma altrettanto problematico, consiste nell’elevare al quadrato il coefficiente di correlazione \\(r\\) per ottenere \\(r^2\\), interpretato come la “proporzione di varianza spiegata”. Ad esempio, una correlazione \\(r = 0.30\\) corrisponde a \\(r^2 = 0.09\\), spesso descritto come “solo il 9% della varianza spiegata”.\nTuttavia, come evidenziato da Funder & Ozer (2019), questa pratica è criticabile per due motivi principali:\n\nMancanza di interpretabilità: Mentre \\(r\\) rappresenta la pendenza di una regressione standardizzata, \\(r^2\\) è molto meno intuitivo, poiché riflette solo la proporzione di varianza condivisa tra due variabili.\nPotenziale fuorviante: Elevare al quadrato \\(r\\) può distorcere la percezione dell’effetto. Ad esempio, una correlazione \\(r = 0.30\\) (effetto medio secondo Cohen) diventa \\(r^2 = 0.09\\), che sembra trascurabile, ma in realtà potrebbe avere un impatto significativo nel contesto applicativo.\n\nUn esempio chiaro è fornito da Darlington (1990). Consideriamo un gioco in cui si lanciano due monete: un nickel (5¢) e un dime (10¢). Se esce testa, si vincono rispettivamente 5¢ o 10¢. Le correlazioni tra il valore delle monete e il pagamento sono:\n\nNickel: \\(r = 0.4472\\) (\\(r^2 = 0.20\\)),\nDime: \\(r = 0.8944\\) (\\(r^2 = 0.80\\)).\n\nSe interpretassimo \\(r^2\\) in modo letterale, potremmo erroneamente concludere che il dime “conta quattro volte più” del nickel. Tuttavia, le correlazioni originali mostrano che \\(0.8944\\) è esattamente il doppio di \\(0.4472\\), offrendo un confronto più accurato e informativo.\nIn sintesi, l’interpretazione della dimensione dell’effetto richiede cautela e contestualizzazione. Gli standard di Cohen, sebbene ampiamente utilizzati, sono arbitrari e possono essere fuorvianti se applicati in modo acritico. Allo stesso modo, elevare al quadrato la correlazione \\(r\\) per ottenere \\(r^2\\) rischia di distorcere la percezione dell’effetto, rendendolo meno interpretabile e potenzialmente fuorviante. Per un’analisi robusta, è essenziale considerare il contesto e l’impatto pratico dell’effetto osservato, evitando di affidarsi esclusivamente a metriche standardizzate o trasformazioni matematiche poco informative.\n\n\n75.3.3 Alternative migliori\nÈ cruciale interpretare le dimensioni degli effetti in modo che ne arricchisca il significato. Funder & Ozer (2019) propongono due strategie principali: l’adozione di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\nUtilizzare criteri di riferimento significa confrontare l’entità di un risultato con quella di risultati ben noti e ampiamente compresi. Simile al modo in cui giudichiamo l’altezza di una persona basandoci su confronti con altri, i ricercatori possono ottenere una percezione accurata dell’importanza di un risultato confrontandolo con la dimensione di effetti noti, sia quelli tipici del campo di studio sia quelli emersi da ricerche passate.\nUn approccio al benchmarking può includere l’analisi di risultati considerati “classici” nel campo di interesse o la considerazione di dimensioni dell’effetto per risultati che hanno ottenuto un solido consenso nella comunità psicologica.\nIn un’ottica più ampia, alcuni ricercatori hanno proposto benchmark per la dimensione dell’effetto calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha esaminato 708 correlazioni ottenute meta-analiticamente, rivelando che la dimensione media dell’effetto \\(r\\) era di .19.\nLa conoscenza comune o i risultati di ricerche non psicologiche possono offrire benchmark per valutare la forza di una relazione tra variabili. Un esempio è l’efficacia degli antistaminici contro il comune raffreddore, che corrisponde a un \\(r\\) di .11, mentre l’effetto degli anti-infiammatori non steroidei (come l’ibuprofene) sul dolore è di \\(r = .14\\).\n\nTali confronti illustrano come l’interpretazione delle dimensioni dell’effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili, sia dentro che fuori il campo della psicologia. Questo metodo consente di inserire i risultati di nuove ricerche in un contesto più vasto, favorendo una valutazione più consapevole della loro rilevanza relativa.\n\n\n75.3.4 Alternative Migliori per Interpretare la Dimensione dell’Effetto\nPer arricchire il significato delle dimensioni dell’effetto, è essenziale adottare approcci che vadano oltre le metriche standardizzate e si basino su criteri di riferimento concreti e contestualizzati. Funder & Ozer (2019) propone due strategie principali: l’uso di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\n75.3.4.1 1. Utilizzare Criteri di Riferimento (Benchmark)\nUn modo efficace per interpretare la dimensione dell’effetto è confrontarla con risultati ben noti e ampiamente compresi, sia all’interno del campo di studio che in contesti più generali. Questo approccio è simile a come giudichiamo l’altezza di una persona confrontandola con quella di altre persone.\n\nConfronto con Risultati Classici: I ricercatori possono ottenere una percezione più accurata dell’importanza di un risultato confrontandolo con dimensioni dell’effetto di studi considerati “classici” nel proprio campo. Ad esempio, in psicologia, è possibile fare riferimento a risultati che hanno ottenuto un solido consenso nella comunità scientifica.\nMedie da Meta-Analisi: Alcuni ricercatori hanno proposto benchmark calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha analizzato 708 correlazioni ottenute meta-analiticamente, rilevando che la dimensione media dell’effetto \\(r\\) era di 0.19. Questo valore può servire come punto di riferimento per valutare l’entità di nuovi risultati.\nEsempi Trasversali: Anche conoscenze comuni o risultati di ricerche non psicologiche possono offrire benchmark utili. Ad esempio:\n\nL’efficacia degli antistaminici contro il comune raffreddore corrisponde a un \\(r = 0.11\\).\nL’effetto degli anti-infiammatori non steroidei (come l’ibuprofene) sul dolore è pari a \\(r = 0.14\\).\n\n\nQuesti confronti mostrano come l’interpretazione della dimensione dell’effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili.\n\n\n75.3.4.2 2. Valutare le Implicazioni Pratiche\nOltre ai benchmark, è fondamentale considerare le implicazioni pratiche dei risultati. Un effetto statisticamente piccolo può avere un impatto significativo se applicato a un contesto reale. Ad esempio:\n\nUn \\(r = 0.10\\) potrebbe sembrare trascurabile, ma se tradotto in un intervento su larga scala (ad esempio, un programma educativo o una politica sanitaria), potrebbe portare a benefici tangibili per un gran numero di persone.\n\nIn conclusione, l’interpretazione della dimensione dell’effetto può essere notevolmente migliorata attraverso l’uso di benchmark e la valutazione delle implicazioni pratiche. Confrontare i risultati con studi classici, medie di meta-analisi o esempi tratti da altri campi consente di inserire i nuovi risultati in un contesto più ampio e significativo. Questo approccio non solo arricchisce l’interpretazione, ma favorisce anche una valutazione più consapevole della rilevanza e dell’impatto delle scoperte scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/03_effect_size.html#riflessioni-conclusive",
    "title": "75  La grandezza dell’effetto",
    "section": "75.4 Riflessioni Conclusive",
    "text": "75.4 Riflessioni Conclusive\nLa sovrastima della grandezza degli effetti in psicologia rappresenta un problema diffuso e significativo. Un principio spesso enfatizzato nella psicologia sociale e nell’economia comportamentale, specialmente nei media e nei corsi di business, è che piccoli interventi, o “nudge” (spinte gentili), possano produrre effetti sorprendentemente ampi sul comportamento. Questa idea ha portato a numerose affermazioni sensazionalistiche, come l’ipotesi che le elezioni possano essere influenzate dall’esito di partite di football o che stimoli subliminali, come una faccina sorridente, possano generare cambiamenti drastici negli atteggiamenti verso temi complessi come l’immigrazione.\nAlla base di queste affermazioni c’è un modello di mondo che non si limita al concetto di “effetto farfalla” (dove piccoli cambiamenti possono avere conseguenze imprevedibili e amplificate), ma suggerisce che piccoli interventi possano produrre effetti grandi e prevedibili. Questo approccio, talvolta definito “modello a pulsante” delle scienze sociali, presuppone che, facendo X, si possa aspettarsi di osservare Y in modo sistematico. Tuttavia, questa visione presenta diverse criticità:\n\n75.4.1 Problemi del Modello “a Pulsante”\n\nSovrastima degli effetti: Molti studi riportano effetti esagerati per interventi minimi, che spesso non vengono replicati in ricerche successive. Questo solleva dubbi sulla validità e sull’affidabilità di tali risultati.\nMancanza di considerazione delle interazioni: Se esistessero davvero molti effetti grandi e prevedibili, questi interferirebbero tra loro, rendendo difficile osservare risultati coerenti nei dati reali. La complessità del comportamento umano raramente si presta a relazioni lineari e isolate.\nInstabilità del sistema: Un sistema sociale caratterizzato da molti effetti grandi e prevedibili sarebbe intrinsecamente instabile e difficile da studiare, contraddicendo l’osservazione che le società tendono a mostrare una certa stabilità nel tempo.\nGeneralizzazione eccessiva: Spesso i risultati ottenuti in contesti di laboratorio altamente controllati vengono estesi a situazioni reali molto più complesse, senza considerare le differenze contestuali.\nBias di pubblicazione: Gli studi che riportano effetti grandi e statisticamente significativi hanno maggiori probabilità di essere pubblicati, creando una rappresentazione distorta della realtà e alimentando un ciclo di sovrastima.\n\n\n\n75.4.2 Verso un Approccio più Cauto e Sfumato\nNonostante queste criticità, è importante riconoscere che la psicologia ha identificato molti fenomeni robusti, specialmente in aree come la psicologia clinica e la psicologia della percezione. Tuttavia, è fondamentale adottare un approccio più cauto e riflessivo nell’interpretazione e nella comunicazione dei risultati della ricerca.\nLa consapevolezza di questi problemi ha portato a una serie di miglioramenti metodologici, tra cui:\n\nEnfasi sulla replicabilità: Maggiore attenzione alla riproducibilità degli studi per garantire che i risultati siano affidabili.\nUso di campioni più ampi: Studi condotti su campioni più grandi e diversificati per aumentare la validità esterna.\nMetodi statistici più robusti: Adozione di tecniche statistiche avanzate per ridurre il rischio di falsi positivi.\nApproccio critico e riflessivo: La comunità scientifica sta diventando sempre più consapevole della necessità di evitare semplificazioni eccessive e di riconoscere la complessità dei fenomeni psicologici.\n\nIn sintesi, mentre la psicologia offre intuizioni preziose sul comportamento umano, è essenziale mantenere un sano scetticismo verso affermazioni di effetti grandi e facilmente ottenibili. La realtà è spesso più complessa e sfumata di quanto suggerito da titoli sensazionalistici o da singoli studi. Un approccio equilibrato, che combina rigore metodologico, contestualizzazione e umiltà scientifica, è fondamentale per avanzare nella comprensione dei fenomeni psicologici e per evitare di cadere in trappole interpretative che possono distorcere la nostra visione del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "href": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "title": "75  La grandezza dell’effetto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFunder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: Sense and nonsense. Advances in Methods and Practices in Psychological Science, 2(2), 156–168.\n\n\nGlass, G. V., McGaw, B., & Smith, M. L. (1981). Meta-analysis in Social Research. Sage Publications.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html",
    "href": "chapters/replication_crisis/04_s_m_errors.html",
    "title": "76  Errori di segno e errori di grandezza",
    "section": "",
    "text": "76.1 Introduzione\nIn questo capitolo analizzeremo la relazione tra la crisi della replicabilità e le procedure decisionali statistiche proprie dell’approccio frequentista. In particolare, approfondiremo gli errori di tipo M (magnitude) e di tipo S (sign), discussi da Loken & Gelman (2017), e il loro impatto sulla validità dei risultati scientifici.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "href": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "title": "76  Errori di segno e errori di grandezza",
    "section": "\n76.2 Il Filtro della Significatività Statistica",
    "text": "76.2 Il Filtro della Significatività Statistica\nNel ?sec-crisis abbiamo esplorato come la pratica scientifica contemporanea sia spesso compromessa da casi di frode, principalmente a causa delle significative implicazioni economiche legate alla pubblicazione su riviste scientifiche di alto prestigio. Questo fenomeno è spesso sottovalutato, poiché le riviste tendono a essere riluttanti nel riconoscere la necessità di correzioni o ritrattazioni degli articoli già pubblicati.\nLa frode scientifica rappresenta una minaccia evidente alla riproducibilità dei risultati, un pilastro fondamentale del metodo scientifico. Tuttavia, le difficoltà nel replicare i risultati pubblicati non sono attribuibili esclusivamente a frodi o a “pratiche di ricerca disoneste” (Nelson et al., 2018). Un problema intrinseco risiede nel metodo statistico ampiamente adottato dai ricercatori: l’approccio del test di ipotesi nulla e della significatività statistica di stampo fisheriano. Secondo questo metodo, i risultati che non raggiungono la soglia di “significatività statistica” vengono scartati, mentre quelli che la superano sono considerati credibili, basandosi esclusivamente su questo criterio (Wagenmakers et al., 2008).\nTuttavia, l’idea che la significatività statistica sia un filtro affidabile per distinguere i risultati di ricerca “validi” da quelli “non validi” è fondamentalmente errata. Numerose evidenze dimostrano i limiti di questo approccio. Per approfondire questa problematica, esamineremo lo studio di Loken & Gelman (2017), che mette in luce la relazione tra la crisi della replicabilità e le procedure decisionali statistiche dell’approccio frequentista.\nUno dei principali problemi evidenziati da Loken & Gelman (2017) è che, in contesti di ricerca complessi, la significatività statistica fornisce prove molto deboli riguardo al segno (sign) o all’entità (magnitude) degli effetti sottostanti. In altre parole, il raggiungimento della significatività statistica non garantisce né la rilevanza né la consistenza dei risultati ottenuti. Questo solleva seri dubbi sull’affidabilità di tale criterio come unico strumento per valutare la validità delle scoperte scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "href": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "title": "76  Errori di segno e errori di grandezza",
    "section": "\n76.3 Errori di tipo M e S\n",
    "text": "76.3 Errori di tipo M e S\n\nPer illustrare le implicazioni del processo decisionale basato sulla significatività statistica, Loken & Gelman (2017) hanno condotto una simulazione. In questa simulazione, hanno considerato uno scenario di ricerca ipotetico in cui era presente un effetto reale, sebbene molto debole, difficilmente rilevabile senza un ampio volume di dati. Utilizzando l’approccio frequentista, hanno cercato di identificare questo effetto valutando la significatività statistica.\nI risultati della simulazione hanno mostrato che, anche in presenza di un effetto reale (seppur debole), l’approccio frequentista riusciva a rilevare un effetto statisticamente significativo solo in una piccola percentuale dei casi. Inoltre, quando un effetto significativo veniva individuato, la stima della sua grandezza risultava altamente imprecisa e instabile.\nIn sintesi, la significatività statistica fornisce un’indicazione generica sulla presenza o assenza di un effetto, ma non offre informazioni affidabili sulla sua entità o replicabilità. Questo problema è particolarmente rilevante in campi come la psicologia e le scienze sociali, dove gli studi spesso si basano su campioni di dimensioni ridotte e gli effetti osservati tendono a essere modesti. In tali contesti, l’approccio frequentista rischia di produrre prove deboli e instabili, compromettendo la replicabilità e l’affidabilità dei risultati.\n\n76.3.1 Simulazione semplificata\nRiproduciamo qui, in forma semplificata, la simulazione condotta da Loken & Gelman (2017). Iniziamo importando le librerie necessarie.\nConsideriamo due campioni casuali indipendenti di dimensioni \\(n_1 = 20\\) e \\(n_2 = 25\\), estratti rispettivamente dalle distribuzioni normali \\(\\mathcal{N}(102, 10)\\) e \\(\\mathcal{N}(100, 10)\\). La dimensione effettiva dell’effetto (\\(d\\)) per la differenza tra le medie dei due campioni è calcolata utilizzando la formula:\n\\[\nd = \\frac{\\bar{y}_1 - \\bar{y}_2}{s_p},\n\\]\ndove \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) rappresentano le medie campionarie dei due gruppi, e \\(s_p\\) è la deviazione standard combinata, definita come:\n\\[\ns_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}.\n\\]\nIn questo caso specifico, la dimensione effettiva dell’effetto risulta molto piccola, indicando che la differenza osservata tra le medie dei due gruppi non ha una rilevanza pratica significativa. Ciò suggerisce che la distinzione tra i due gruppi, seppur statisticamente rilevabile, non ha un impatto sostanziale in contesti reali.\n\n# Parametri\nmu_1 &lt;- 102  # Media del primo gruppo\nmu_2 &lt;- 100  # Media del secondo gruppo\nsigma &lt;- 10  # Deviazione standard comune\nn1 &lt;- 20     # Numero di osservazioni nel primo gruppo\nn2 &lt;- 25     # Numero di osservazioni nel secondo gruppo\n\n# Calcolo della differenza media\nmean_difference &lt;- abs(mu_1 - mu_2)\n\n# Calcolo della deviazione standard pooled\npooled_sd &lt;- sqrt(((n1 - 1) * sigma^2 + (n2 - 1) * sigma^2) / (n1 + n2 - 2))\n\n# Calcolo di Cohen's d\ncohen_d &lt;- mean_difference / pooled_sd\n\n# Output del risultato\ncat(\"Dimensione dell'effetto (Cohen's d):\", cohen_d, \"\\n\")\n#&gt; Dimensione dell'effetto (Cohen's d): 0.2\n\nEsaminiamo ora le conclusioni che emergerebbero applicando l’approccio frequentista e la sua procedura di decisione statistica in questo contesto. Supponiamo di condurre una simulazione in cui vengono estratti due campioni: il primo composto da 20 osservazioni provenienti dalla prima popolazione e il secondo da 25 osservazioni provenienti dalla seconda popolazione. Successivamente, applichiamo il test \\(t\\) di Student per confrontare le medie dei due gruppi.\nNell’ambito dell’approccio frequentista, il valore-\\(p\\) ottenuto dal test determina la decisione statistica. Se il valore-\\(p\\) è superiore a 0.05, i risultati vengono considerati non significativi e, di conseguenza, scartati. Al contrario, se il valore-\\(p\\) è inferiore a 0.05, il risultato è ritenuto “pubblicabile” e si conclude che esiste una differenza statisticamente significativa tra i due gruppi.\nPer valutare in modo approfondito le conclusioni derivate da questa procedura, è necessario ripetere l’intero processo per un numero elevato di iterazioni, ad esempio 50.000 volte. Ciò significa che, in ciascuna iterazione, vengono estratti nuovi campioni, viene calcolato il test \\(t\\) di Student e viene determinato il corrispondente valore-\\(p\\). Ripetendo questo processo su larga scala, è possibile ottenere una distribuzione completa dei risultati, che consente di analizzare la frequenza con cui si ottengono risultati significativi e la stabilità delle stime prodotte dall’approccio frequentista in questo contesto.\n\n# Parametri\nn_samples &lt;- 50000\nmu_1 &lt;- 102\nmu_2 &lt;- 100\nsigma &lt;- 10\nn1 &lt;- 20\nn2 &lt;- 25\n\n# Inizializzazione del risultato\nres &lt;- c()\n\n# Simulazioni\nset.seed(123)  # Per la riproducibilità\nfor (i in 1:n_samples) {\n  # Generazione dei campioni casuali\n  y1 &lt;- rnorm(n1, mean = mu_1, sd = sigma)\n  y2 &lt;- rnorm(n2, mean = mu_2, sd = sigma)\n  \n  # Calcolo della dimensione dell'effetto\n  y1bar &lt;- mean(y1)\n  y2bar &lt;- mean(y2)\n  v1 &lt;- var(y1)\n  v2 &lt;- var(y2)\n  s &lt;- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2) / (n1 + n2 - 2))\n  efsize &lt;- (y1bar - y2bar) / s\n  \n  # Calcolo del valore p\n  t_test &lt;- t.test(y1, y2, var.equal = TRUE)\n  \n  # Salvataggio della dimensione dell'effetto solo per risultati \"statisticamente significativi\"\n  if (t_test$p.value &lt; 0.05) {\n    res &lt;- c(res, efsize)\n  }\n}\n\n\nres_df &lt;- data.frame(effect_size = res)\n\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 20, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(\n    xintercept = 0.2, color = \"red\", linetype = \"dashed\", \n    size = 1.2, label = \"True Effect Size\") +\n  labs(\n    x = \"Effect Size\",\n    y = \"Frequency\",\n    title = \"Histogram of Effect Sizes for\\n'Statistically Significant' Results\"\n  ) \n\n\n\n\n\n\n\nCome evidenziato da Loken & Gelman (2017), l’applicazione dell’approccio frequentista nella procedura di decisione statistica può condurre a due tipi di errori rilevanti. Il primo, noto come errore di magnitude (grandezza), si manifesta quando i risultati pubblicati tendono a sovrastimare la reale entità dell’effetto. Nella simulazione condotta, nonostante la vera grandezza dell’effetto fosse modesta (0.2), la media della grandezza dell’effetto per i risultati classificati come “statisticamente significativi” era circa 0.8, suggerendo un effetto di entità “ampia”. Questo indica una distorsione sistematica verso stime esagerate.\nIl secondo errore, chiamato errore di segno, si verifica quando, a causa della variabilità campionaria, la direzione dell’effetto viene stimata in modo errato. In tali casi, il ricercatore potrebbe erroneamente concludere che \\(\\mu_2 &gt; \\mu_1\\), quando in realtà non è così. È importante sottolineare che, anche in queste situazioni, la grandezza assoluta dell’effetto risulta sovrastimata.\nUn aspetto degno di nota è che queste conclusioni rimarrebbero valide anche se si considerasse l’intervallo di confidenza per la differenza tra le medie. In sintesi, l’approccio frequentista introduce un errore sistematico nella stima della grandezza dell’effetto, che rappresenta la quantità più rilevante per il ricercatore. In alcuni casi, può persino portare a errori nella determinazione della direzione dell’effetto, compromettendo ulteriormente l’affidabilità delle conclusioni scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "title": "76  Errori di segno e errori di grandezza",
    "section": "\n76.4 Riflessioni Conclusive",
    "text": "76.4 Riflessioni Conclusive\nIn conclusione, l’approccio frequentista non rappresenta un metodo affidabile per valutare i risultati della ricerca e determinarne l’attendibilità o la necessità di scartarli (Gelman & Carlin, 2014; Loken & Gelman, 2017). Questa mancanza di affidabilità è dovuta all’introduzione di errori sistematici nella stima della grandezza degli effetti, che in alcuni casi possono persino portare a errori nella direzione dell’effetto stesso. Alla luce di queste criticità, non sembrano esserci motivi validi per continuare a fare affidamento su questo approccio.\nAl contrario, l’adozione dell’approccio bayesiano sembra offrire una soluzione più precisa e affidabile per l’analisi dei dati di ricerca. Questo metodo valuta la probabilità delle ipotesi alla luce dei dati osservati, evitando gli errori intrinseci dell’approccio frequentista e fornendo una base più solida per prendere decisioni informate sulla validità dei risultati. In questo modo, l’approccio bayesiano si presenta come un’alternativa più robusta e scientificamente rigorosa.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "href": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "title": "76  Errori di segno e errori di grandezza",
    "section": "\n76.5 Esercizi",
    "text": "76.5 Esercizi\n\nEsercizio 76.1 Esegui una simulazione con 10.000 ripetizioni (nrep = 10000) in cui vengono estratti due campioni casuali dalla stessa popolazione normale con media 0 e deviazione standard 10. Per ogni simulazione, esegui un t-test per confrontare le medie di due gruppi indipendenti.\n\nProporzione di risultati statisticamente significativi: Calcola la proporzione di risultati in cui si ottiene un risultato statisticamente significativo (p &lt; 0.05) in questa condizione in cui i campioni provengono dalla stessa popolazione, e quindi non c’è una differenza reale tra i gruppi. Questo ti darà un’idea della frequenza dei falsi positivi.\nGrandezza dell’effetto media: Calcola la grandezza dell’effetto (d di Cohen) media, considerando solo quei test in cui si è ottenuta una differenza statisticamente significativa. Questo valore ti mostrerà quanto grande appare l’effetto quando il risultato è significativo, nonostante la realtà sia priva di un effetto reale.\nRipetizione della simulazione con diverse grandezze campionarie: Ripeti la simulazione usando due diverse dimensioni campionarie: 20 osservazioni per gruppo e 200 osservazioni per gruppo. Confronta i risultati per capire come la dimensione del campione influenzi la proporzione di falsi positivi e la grandezza dell’effetto media.\nInterpretazione dei risultati: Interpreta i risultati alla luce del concetto del “filtro della significatività statistica”. Questo concetto suggerisce che tra tutti gli studi effettuati, tendono ad essere pubblicati e riportati solo quelli che ottengono risultati statisticamente significativi. Di conseguenza, i risultati significativi pubblicati possono sovrastimare la vera grandezza dell’effetto o indicare erroneamente che un effetto esiste quando in realtà non c’è. Questa simulazione dovrebbe mostrare come, anche in assenza di una differenza reale tra gruppi, si possano ottenere risultati apparentemente significativi con una certa frequenza, soprattutto quando la dimensione campionaria è piccola.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "title": "76  Errori di segno e errori di grandezza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "href": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "title": "76  Errori di segno e errori di grandezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNelson, L. D., Simmons, J., & Simonsohn, U. (2018). Psychology’s renaissance. Annual review of psychology, 69(1), 511–534.\n\n\nWagenmakers, E.-J., Lee, M., Lodewyckx, T., & Iverson, G. J. (2008). Bayesian versus frequentist inference. Bayesian evaluation of informative hypotheses, 181–207.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html",
    "href": "chapters/replication_crisis/05_p_values.html",
    "title": "\n77  La fragilità del p-valore\n",
    "section": "",
    "text": "77.1 Introduzione\nIl codice presentato è ispirato da un post sul blog di Andrew Gelman. L’obiettivo è esplorare la fragilità dei p-valori e la loro variabilità in diverse condizioni sperimentali.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#simulazione",
    "href": "chapters/replication_crisis/05_p_values.html#simulazione",
    "title": "\n77  La fragilità del p-valore\n",
    "section": "\n77.2 Simulazione",
    "text": "77.2 Simulazione\nQuesta simulazione mira a dimostrare quanto i p-valori possano essere instabili e variare significativamente da campione a campione, anche quando i dati provengono da una distribuzione con parametri molto simili. Questo evidenzia come il p-valore, comunemente utilizzato per valutare la significatività statistica di un effetto, possa essere fortemente influenzato dalla variabilità campionaria, specialmente in campioni di piccole dimensioni o con effetti deboli. Gelman & Stern (2006) esprimono questo concetto affermando che:\n\nla differenza tra “significativo” e “non significativo” non è di per sé statisticamente significativa.\n\n\n77.2.1 Logica della Simulazione\n\n\nObiettivo:\n\nDimostrare la variabilità dei p-valori calcolati su diversi campioni estratti da una popolazione con una media molto vicina a zero.\nMostrare come, nonostante l’effetto reale sia piccolo, i p-valori possano variare notevolmente a seconda della variabilità e delle dimensioni del campione.\n\n\n\nSetup della Simulazione:\n\nGeneriamo \\(J = 10\\) campioni indipendenti, ciascuno con un numero ridotto di osservazioni (\\(n = 10\\)), per massimizzare la variabilità dei risultati.\nOgni campione è generato da una distribuzione normale con una media vera di \\(\\mu = 0.05\\) e una deviazione standard di \\(\\sigma = 0.1\\). Questi parametri sono scelti per rendere la media dei campioni vicina a zero, mantenendo una certa variabilità.\n\n\n\nCalcolo della media campionaria:\n\nPer ciascun campione, calcoliamo la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nLa media del campione (\\(\\hat{\\mu}\\)) è utilizzata come stima del parametro.\n\n\n\nCalcolo del p-valore:\n\nApplichiamo un t-test per ciascun campione per verificare l’ipotesi nulla (\\(H_0\\)) che la media del campione sia zero.\n\nIl p-valore viene calcolato utilizzando la formula classica del t-test:\n\\[\nt = \\frac{\\hat{\\mu}}{\\frac{\\hat{\\sigma}}{\\sqrt{n}}}\n\\]\ndove:\n\n\n\\(\\hat{\\mu}\\) è la media del campione,\n\n\\(\\hat{\\sigma}\\) è la deviazione standard del campione,\n\n\\(n\\) è il numero di osservazioni per campione.\n\n\n\nSuccessivamente, il p-valore è calcolato come:\n\\[\n\\text{p-value} = 2 \\times (1 - \\text{CDF}(|t|))\n\\]\ndove \\(\\text{CDF}\\) è la funzione cumulativa della distribuzione t con \\(n-1\\) gradi di libertà.\n\n\n\n\n77.2.2 Descrizione della Sintassi\nIl codice R è strutturato come segue:\n\n\nGenerazione dei campioni:\n\nCreiamo una lista di campioni (10 campioni in totale), ciascuno con 10 osservazioni, utilizzando la distribuzione normale con media 0.05 e deviazione standard 0.1.\n\n\n\nCalcolo delle medie e dei p-valori:\n\nIteriamo su ciascun campione per calcolare la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nCalcoliamo il valore statistico \\(t\\) e il corrispondente p-valore utilizzando la distribuzione t.\n\n\n\nStampa dei risultati:\n\nI p-valori vengono arrotondati e stampati per osservare la loro variabilità.\n\n\n\n\n# Imposta il seme per riproducibilità\nset.seed(1234)\n\n# Parametri della simulazione\nJ &lt;- 10              # Numero di campioni indipendenti\nn &lt;- 10              # Numero di osservazioni per campione\ntrue_mean &lt;- 0.05    # Media vera della popolazione\ntrue_sd &lt;- 0.1       # Deviazione standard della popolazione\n\n# Genera i campioni casuali\nsamples &lt;- replicate(J, rnorm(n, mean = true_mean, sd = true_sd), simplify = FALSE)\n\n# Calcola statistiche campionarie e p-valori\nresults &lt;- lapply(samples, function(sample) {\n  sample_mean &lt;- mean(sample)                         # Media campionaria\n  sample_sd &lt;- sd(sample)                             # Deviazione standard campionaria\n  t_statistic &lt;- sample_mean / (sample_sd / sqrt(n))  # Statistica t\n  p_value &lt;- 2 * (1 - pt(abs(t_statistic), df = n - 1))  # p-valore bilaterale\n  list(mean = sample_mean, sd = sample_sd, t = t_statistic, p_value = p_value)\n})\n\n# Converti i risultati in un data frame per facilitarne la visualizzazione\nresults_df &lt;- do.call(rbind, lapply(results, as.data.frame))\nrownames(results_df) &lt;- paste(\"C\", 1:J)\n\n# Visualizza i risultati\nprint(results_df)\n#&gt;          mean      sd       t  p_value\n#&gt; C 1   0.01168 0.09958  0.3711 0.719183\n#&gt; C 2   0.03818 0.10673  1.1313 0.287183\n#&gt; C 3   0.01121 0.06660  0.5320 0.607576\n#&gt; C 4  -0.02662 0.08942 -0.9413 0.371116\n#&gt; C 5  -0.01098 0.07872 -0.4411 0.669552\n#&gt; C 6   0.02211 0.11860  0.5896 0.569941\n#&gt; C 7   0.11166 0.11442  3.0860 0.013013\n#&gt; C 8   0.04577 0.09237  1.5670 0.151566\n#&gt; C 9   0.03415 0.07349  1.4695 0.175755\n#&gt; C 10  0.10607 0.09840  3.4089 0.007763\n\n\nggplot(results_df, aes(x = rownames(results_df), y = p_value)) +\n  geom_point(size = 3, color = \"blue\") +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Variabilità dei p-valori nei campioni\",\n    x = \"Campioni\",\n    y = \"p-valore\"\n  ) \n\n\n\n\n\n\n\n\n77.2.3 Interpretazione dei Risultati\nImmaginiamo che questo sia un esperimento reale. Alcuni campioni potrebbero mostrare risultati compatibili con il puro rumore, altri fornire deboli indicazioni contro l’ipotesi nulla, mentre altri ancora potrebbero sembrare altamente significativi dal punto di vista statistico. Tuttavia, la differenza tra “significativo” e “non significativo” non è di per sé statisticamente significativa. Ad esempio, una differenza tra un p-valore di 0.336 e uno di 0.003 potrebbe sembrare rilevante, ma non lo è.\nQuesto scenario estremo riflette una situazione in cui non c’è una reale variazione sottostante. Se si utilizzasse un modello multilivello, probabilmente emergerebbe l’assenza di una variazione effettiva significativa.\n\n77.2.4 Punti Chiave\n\nIl p-valore descrive solo l’ipotesi nulla: È una misura relativa all’assenza di effetto, ma non ha necessariamente un significato diretto rispetto a un effetto reale, anche se piccolo.\nIl p-valore è altamente variabile: Essendo una trasformazione non lineare dello z-score, il p-valore può comportarsi in modi non intuitivi, soprattutto con campioni piccoli.\nLe simulazioni sono istruttive: Anche esperimenti semplici come questo possono essere estremamente utili per comprendere le limitazioni e l’interpretazione dei risultati.\n\n77.2.5 Un Avvertimento Importante\nAnche le inferenze bayesiane sono soggette a variabilità. Qualsiasi sintesi dei dati porta con sé un certo grado di incertezza. Il problema non risiede nei p-valori in sé, ma nel loro utilizzo scorretto. Interpretare un p-valore come una dichiarazione forte sulla realtà, invece di considerarlo un riassunto rumoroso di un esperimento specifico, è un errore comune.\nAllo stesso modo, fraintendimenti e sovrainterpretazioni possono verificarsi anche con approcci bayesiani. Ad esempio, l’adattamento di un modello con prior non informativi e l’interpretazione della probabilità posteriore di un parametro (ad esempio, maggiore di zero) sulla base di una soglia arbitraria può portare a conclusioni altrettanto problematiche. Questi risultati ci ricordano l’importanza di una sana cautela nell’interpretazione statistica, indipendentemente dal metodo utilizzato.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "title": "\n77  La fragilità del p-valore\n",
    "section": "\n77.3 Riflessioni Conclusive",
    "text": "77.3 Riflessioni Conclusive\nLa simulazione mostra che, nonostante le medie dei campioni siano generate con una distribuzione simile, i p-valori possono variare drasticamente. Questo effetto è amplificato dalla scelta di campioni piccoli e di una media vera molto vicina all’ipotesi nulla (zero). Dimostra quanto il p-valore possa essere influenzato da piccole variazioni nei dati e perché non sia sempre un indicatore affidabile per valutare l’efficacia o la presenza di un effetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n77  La fragilità del p-valore\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "href": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "title": "\n77  La fragilità del p-valore\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Stern, H. (2006). The difference between «significant» and «not significant» is not itself statistically significant. The American Statistician, 60(4), 328–331.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html",
    "href": "chapters/replication_crisis/06_changes.html",
    "title": "78  Riforma",
    "section": "",
    "text": "78.1 Introduzione\nLa crisi della riproducibilità ha stimolato un profondo dibattito sullo stato della ricerca nelle scienze comportamentali, cognitive e sociali. La scoperta che molti studi pubblicati non sono replicabili ha minato la fiducia nella ricerca scientifica, evidenziando carenze metodologiche e strutturali nel sistema accademico. In risposta a questa crisi, sono state avanzate diverse proposte di riforma per migliorare la qualità e l’affidabilità della ricerca scientifica.\nSecondo Korbmacher et al. (2023), sono necessarie riforme strutturali, cambiamenti procedurali e trasformazioni nella comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "href": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "title": "78  Riforma",
    "section": "78.2 Riforme Strutturali",
    "text": "78.2 Riforme Strutturali\n\n78.2.1 Integrazione della Riproducibilità nei Curriculum Educativi\nUna proposta chiave per affrontare la crisi della riproducibilità è l’integrazione delle pratiche di riproducibilità nei curriculum delle scienze psicologiche e affini. Attualmente, molti programmi di formazione non enfatizzano sufficientemente l’importanza della replicabilità e della trasparenza nella ricerca. Includere questi temi nei corsi di metodologia della ricerca può sensibilizzare le nuove generazioni di ricercatori sull’adozione di pratiche più rigorose e trasparenti. Alcuni programmi universitari hanno già iniziato a incorporare repliche di studi famosi nel percorso formativo, offrendo agli studenti l’opportunità di comprendere meglio i limiti e le potenzialità del processo scientifico.\n\n\n78.2.2 Incentivi per la Scienza Aperta\nUn altro aspetto cruciale è la riforma dei sistemi di incentivazione accademica. Tradizionalmente, il sistema accademico ha privilegiato la quantità di pubblicazioni e la novità dei risultati, piuttosto che la loro qualità e replicabilità. Per promuovere pratiche di scienza aperta, come la preregistrazione degli studi e la condivisione aperta dei dati, si propone l’introduzione di riconoscimenti ufficiali, come badge di “open science” o crediti accademici per la pubblicazione di rapporti registrati. Questi cambiamenti potrebbero favorire una maggiore adozione di pratiche che promuovono la trasparenza e rafforzano la fiducia nella ricerca scientifica.\nA tal proposito, uno studio di Scheel et al. (2021) ha confrontato i risultati di rapporti registrati pubblicati (N = 71) con un campione casuale di studi ipotetico-deduttivi della letteratura standard (N = 152) in psicologia. Analizzando la prima ipotesi di ciascun articolo, è emerso che il 96% dei risultati nei rapporti standard erano positivi, contro solo il 44% nei rapporti registrati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "title": "78  Riforma",
    "section": "78.3 Cambiamenti Procedurali",
    "text": "78.3 Cambiamenti Procedurali\n\n78.3.1 Mercati di Previsione per la Credibilità della Ricerca\nI mercati di previsione sono stati proposti come strumento innovativo per valutare la credibilità della ricerca. In questi mercati, esperti e non esperti scommettono sulla probabilità che i risultati di determinati studi siano replicabili. Questo approccio ha dimostrato un’elevata accuratezza nella classificazione della replicabilità degli studi, offrendo un metodo alternativo e complementare alla replicazione diretta. I mercati di previsione potrebbero essere particolarmente utili in contesti in cui la raccolta dati è costosa o difficile, fornendo una prima indicazione sulla solidità dei risultati di ricerca.\n\n\n78.3.2 Strumenti di Valutazione Statistica\nUn’altra proposta riguarda l’adozione di nuovi strumenti di valutazione statistica per identificare e correggere il bias di pubblicazione e migliorare la potenza degli studi. Strumenti come la curva-p e la curva-z sono stati sviluppati per analizzare la distribuzione dei valori p e identificare eventuali distorsioni nei risultati pubblicati. Inoltre, alcuni studiosi hanno suggerito di abbassare il livello di significatività statistica standard da 0,05 a 0,005 per ridurre il tasso di falsi positivi e aumentare la robustezza dei risultati. Queste proposte rappresentano passi importanti verso una maggiore precisione nelle analisi statistiche.\n\n\n78.3.3 Analisi Multiverso\nL’analisi multiverso è un’altra proposta innovativa che mira a gestire la molteplicità di scelte analitiche possibili in un singolo studio. Questa tecnica prevede l’esecuzione di molteplici analisi su uno stesso dataset, variando i parametri e le scelte metodologiche, per testare la stabilità dei risultati. L’adozione di questo approccio permette di evidenziare quanto i risultati siano sensibili alle scelte analitiche, contribuendo a una maggiore trasparenza e affidabilità nelle conclusioni tratte dagli studi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "title": "78  Riforma",
    "section": "78.4 Cambiamenti nella Comunità",
    "text": "78.4 Cambiamenti nella Comunità\n\n78.4.1 Big Team Science\nIl concetto di “Big Team Science” rappresenta un cambiamento significativo nella modalità di condurre ricerca. Questo approccio prevede la collaborazione su larga scala tra scienziati di diversi paesi e discipline, con l’obiettivo di replicare studi, raccogliere grandi campioni e condividere risorse. Questo modello di lavoro collettivo non solo aumenta l’efficienza della ricerca, ma promuove anche una maggiore diversità nei campioni e nei team di ricerca. Tuttavia, esistono anche criticità, come la possibilità di perpetuare disuguaglianze tra ricercatori di paesi sviluppati e in via di sviluppo, e la difficoltà nel riconoscere adeguatamente i contributi individuali all’interno di grandi consorzi.\n\n\n78.4.2 Collaborazioni Avversariali\nLe collaborazioni avversariali rappresentano un altro approccio interessante per migliorare la qualità della ricerca. In queste collaborazioni, ricercatori con visioni teoriche contrastanti lavorano insieme per progettare e condurre studi che testino le loro ipotesi in modo rigoroso. Questo tipo di collaborazione può ridurre i bias personali e promuovere un confronto costruttivo, portando a conclusioni più solide e condivise all’interno della comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "href": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "title": "78  Riforma",
    "section": "78.5 Crisi della Generalizzabilità",
    "text": "78.5 Crisi della Generalizzabilità\nYarkoni (2022) affronta la questione critica della scarsa validità delle inferenze quantitative presenti nella letteratura psicologica pubblicata, proponendo tre strategie principali per migliorare la qualità della ricerca in psicologia.\n\n78.5.1 Do Something Else\nIl primo suggerimento è di considerare l’abbandono della ricerca psicologica quantitativa quando risulta troppo difficile estrarre conclusioni significative e generalizzabili da effetti complessi e variabili. L’autore critica la tendenza a concludere ogni contributo di ricerca con una nota positiva, indipendentemente dalle evidenze raccolte. In alcuni casi, potrebbe essere più saggio riconoscere i limiti della ricerca e scegliere percorsi di carriera alternativi, specialmente per i ricercatori alle prime armi.\n\n\n78.5.2 Abbracciare l’Analisi Qualitativa\nLa seconda opzione proposta è continuare a fare ricerca psicologica, ma abbandonando in gran parte i metodi statistici inferenziali a favore di metodi qualitativi. L’autore sostiene che gran parte della scienza quantitativa in psicologia sia in realtà un’analisi qualitativa mascherata. In molti casi, l’analisi qualitativa potrebbe fornire risposte più profonde e significative rispetto a un approccio quantitativo superficiale.\n\n\n78.5.3 Adottare Standard Migliori\nLa terza strategia consiste nel migliorare gli standard della ricerca quantitativa in psicologia per renderla più rigorosa e affidabile. L’autore propone diverse pratiche, tra cui:\n\nInferenze più conservative: Evitare generalizzazioni ampie basate su dati limitati.\nRicerca descrittiva: Prendere più seriamente la ricerca descrittiva, che si concentra sulla caratterizzazione delle relazioni tra variabili.\nModelli statistici più espansivi: Utilizzare modelli che considerino una più ampia gamma di variabili e fattori.\nProgettare con la variazione in mente: Abbracciare la variabilità naturale delle condizioni sperimentali.\nStime della varianza: Porre maggiore enfasi sull’analisi delle componenti della varianza.\nPredizioni più rischiose: Formulare predizioni teoriche che comportino un alto grado di rischio.\nUtilità predittiva pratica: Concentrarsi sull’utilità pratica delle predizioni piuttosto che su considerazioni puramente teoriche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "href": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "title": "78  Riforma",
    "section": "78.6 Sviluppare Teorie Formali",
    "text": "78.6 Sviluppare Teorie Formali\nOltre alle carenze metodologiche o statistiche, è stato spesso sottolineato che la crisi di replicabilità trova le sue radici nella mancanza di un quadro teorico cumulativo. Senza un quadro teorico generale che generi ipotesi in diversi ambiti, i programmi empirici si sviluppano a partire da intuizioni personali e teorie popolari influenzate culturalmente. Fornendo strumenti per formulare previsioni chiare, anche attraverso l’uso di modelli formali, i quadri teorici stabiliscono aspettative che permettono di determinare se un nuovo risultato conferma le ricerche esistenti, integrandosi con esse, oppure se è inaspettato e, pertanto, richiede ulteriori verifiche e approfondimenti (Muthukrishna & Henrich, 2019).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "title": "78  Riforma",
    "section": "78.7 Riflessioni Conclusive",
    "text": "78.7 Riflessioni Conclusive\nL’ampio utilizzo dei test statistici frequentisti in psicologia risulta spesso fuorviante, poiché attribuisce un’apparenza di rigore scientifico a inferenze che, in realtà, sono principalmente qualitative. Si rende quindi necessaria una profonda riforma delle pratiche di ricerca, volta a promuovere una maggiore trasparenza e precisione, oltre a incoraggiare la disponibilità a mettere in discussione e abbandonare approcci metodologici che non superano una rigorosa analisi critica (Yarkoni, 2022).\nLa crisi di replicabilità ha spinto verso una serie di riforme con il potenziale di trasformare positivamente la ricerca psicologica. Tra queste iniziative vi sono la promozione della scienza aperta, l’adozione di standard metodologici più rigorosi e una maggiore attenzione a pratiche di ricerca che privilegiano la qualità e la replicabilità dei risultati rispetto alla loro quantità e novità. Sebbene questi cambiamenti possano sembrare meno spettacolari rispetto ai metodi attualmente utilizzati, essi rappresentano un percorso fondamentale per garantire la credibilità e la sostenibilità a lungo termine della disciplina.\nAffinché queste riforme abbiano un impatto duraturo, è essenziale un cambiamento strutturale a tutti i livelli della comunità scientifica:\n\nI ricercatori devono impegnarsi ad adottare pratiche più rigorose e trasparenti, privilegiando la solidità metodologica e la replicabilità dei loro studi.\nGli enti finanziatori devono incentivare la qualità e la replicabilità degli studi, piuttosto che premiare esclusivamente la produzione di risultati innovativi o appariscenti.\nLe istituzioni accademiche devono rivedere i criteri di valutazione del merito scientifico, dando maggior peso all’impatto a lungo termine delle ricerche e alla loro solidità metodologica.\nLe riviste scientifiche devono assicurarsi che i risultati pubblicati siano realmente robusti e generalizzabili, anziché limitarsi a privilegiare i risultati nuovi o sorprendenti.\n\nQuesti cambiamenti, sebbene complessi e talvolta impopolari, sono fondamentali per ristabilire la fiducia nel processo scientifico e per garantire che la ricerca psicologica continui a offrire contributi utili e affidabili nella comprensione della mente umana e del comportamento.\nIn conclusione, la sfida posta dalla crisi di replicabilità offre un’opportunità unica per ridefinire e rafforzare le fondamenta metodologiche della ricerca psicologica. Abbracciando questi cambiamenti, la psicologia può emergere come una disciplina più robusta, trasparente e affidabile, capace di fornire intuizioni utili e durature sul funzionamento della mente e del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#bibliografia",
    "href": "chapters/replication_crisis/06_changes.html#bibliografia",
    "title": "78  Riforma",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMuthukrishna, M., & Henrich, J. (2019). A problem in theory. Nature Human Behaviour, 3(3), 221–229.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html",
    "href": "chapters/replication_crisis/07_piranha.html",
    "title": "79  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "",
    "text": "79.1 Introduzione\nUn recente articolo di Tosh et al. (2025) affronta una questione centrale per la psicologia e la crisi della replicabilità: il cosiddetto “problema del piranha”. Questo argomento riguarda la convinzione, diffusa in molti studi psicologici, che piccoli interventi (o “nudges”), apparentemente insignificanti, possano generare effetti notevoli sul comportamento. L’articolo dimostra formalmente, con il supporto del teorema di Van der Corput (Tao, 2014), che se tali effetti fossero davvero così grandi e consistenti, allora sarebbe possibile manipolare il comportamento umano in modi empiricamente irrealistici.\nIn altre parole, la letteratura psicologica spesso riporta effetti di dimensioni tali che richiederebbero assunzioni incompatibili con le evidenze empiriche. Questi risultati suggeriscono che le affermazioni di grandi effetti indipendenti sono più probabilmente attribuibili a problemi metodologici, come bassa potenza statistica o “gradi di libertà del ricercatore” (Simmons et al., 2011).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "href": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "title": "79  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "79.2 Il problema del piranha",
    "text": "79.2 Il problema del piranha\nTosh et al. (2025) evidenziano che, in un sistema complesso, se molte variabili esplicative hanno un forte impatto su una singola variabile di esito, queste devono inevitabilmente mostrare interazioni o correlazioni rilevanti tra loro.\n\n79.2.1 Punti chiave del problema\n\nEffetti ampi e interazioni: Il “problema del piranha” sottolinea che è improbabile che molte variabili esplicative abbiano effetti ampi e indipendenti su una singola variabile di esito all’interno di un sistema stabile. Questo principio si basa sulla disuguaglianza di Van der Corput, che dimostra come l’aumento del numero di variabili con grandi effetti richieda una considerazione delle loro interazioni. Tali interazioni generano una rete complessa di influenze, rendendo difficile isolare l’impatto di un singolo fattore. Gli effetti osservati in un dato studio potrebbero non essere generalizzabili, poiché dipendono dai livelli di altre variabili presenti nello stesso contesto.\nAnalogia con i piranha: L’analogia del piranha descrive un sistema sovraffollato di variabili esplicative con grandi effetti, che interagiscono tra loro fino a ridurre la stabilità complessiva. Proprio come i piranha in un acquario competono tra loro fino a ridurre il loro numero, un sistema con molte variabili di forte impatto tende a generare interazioni che limitano la prevedibilità e la stabilità del sistema. In altre parole, gli effetti individuali vengono alterati, ridotti o cancellati attraverso la competizione tra variabili.\n\n\n\n79.2.2 Rilevanza per la crisi di replicabilità\nIl problema del piranha offre una prospettiva cruciale per comprendere le cause della crisi di replicabilità nella psicologia e nelle scienze sociali. Secondo Tosh et al. (2025), questa crisi non è attribuibile soltanto a problemi metodologici come la bassa potenza statistica, ma riflette un limite intrinseco dell’idea stessa che numerosi grandi effetti indipendenti possano coesistere in un sistema complesso.\nI teoremi discussi nell’articolo dimostrano che un sistema stabile non può contenere numerosi effetti forti e indipendenti senza generare predizioni empiricamente insostenibili. Ciò implica che la ricerca di molteplici “grandi effetti” rischia di essere basata su assunzioni irrealistiche riguardo alla natura delle interazioni tra variabili.\nIl problema del piranha è particolarmente rilevante per la psicologia, dove spesso si cercano numerose cause indipendenti per spiegare fenomeni complessi. Tosh et al. (2025) mettono in discussione non tanto i singoli effetti riportati, quanto l’assunzione di base secondo cui il comportamento umano e le interazioni sociali sarebbero influenzati da un gran numero di effetti indipendenti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "href": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "title": "79  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "79.3 Il priming nella psicologia sociale",
    "text": "79.3 Il priming nella psicologia sociale\nUno degli esempi analizzati da Tosh et al. (2025) riguarda la ricerca sul priming sociale, una linea di indagine ampiamente discussa e criticata nella psicologia sociale (si veda anche Leys, 2024). Gli autori utilizzano uno studio classico per illustrare le loro argomentazioni: un esperimento del 1996 condotto da Bargh et al. (1996), in cui i partecipanti riorganizzavano frasi contenenti parole associate alla vecchiaia (ad esempio, “Florida” o “solo”). I risultati riportavano che questi partecipanti camminavano più lentamente rispetto a un gruppo di controllo, con una riduzione del 13% nella velocità di camminata (Bargh et al., 1996).\nL’idea che una manipolazione così semplice possa produrre un effetto tanto marcato è stata successivamente oggetto di numerose critiche. I tentativi di replicare lo studio non hanno avuto successo, e il lavoro di Bargh et al. (1996) è ora considerato un esempio emblematico di risultati impossibili da replicare. Questo studio rappresenta solo uno dei molti casi in cui sono stati riportati effetti sorprendentemente grandi per manipolazioni apparentemente insignificanti.\nTosh et al. (2025) sostengono che, se davvero piccoli interventi (nudges) producono effetti così rilevanti, emergerebbe inevitabilmente il problema delle interazioni con numerosi altri fattori già noti per influire sul comportamento umano. La letteratura psicologica include infatti studi che attribuiscono grandi effetti a fattori come ormoni, immagini subliminali, notizie di partite di calcio o attacchi di squali, incontri casuali con sconosciuti, stato socioeconomico dei genitori, condizioni meteorologiche, l’ultima cifra dell’età, il genere del nome di un uragano, e molti altri. Secondo gli autori, se tutti questi fattori influenzassero realmente un singolo esito, le loro interazioni diventerebbero incredibilmente complesse e imprevedibili, rendendo impossibile individuare effetti stabili e replicabili.\nPer illustrare l’assurdità di alcuni di questi risultati, Tosh et al. (2025) propongono un esempio ipotetico. Supponiamo che 100 nudges producano ciascuno un effetto del 13% sulla velocità di camminata, come riportato da Bargh et al. (1996). Se questi effetti fossero indipendenti, l’effetto combinato sarebbe enorme: la velocità di camminata potrebbe facilmente raddoppiare, dimezzarsi o variare ancora di più. Tuttavia, tali variazioni sono empiricamente irrealistiche. In altre parole, le assunzioni su cui si basano molte di queste ricerche porterebbero a predizioni che non trovano riscontro nei dati osservabili.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/07_piranha.html#riflessioni-conclusive",
    "title": "79  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "79.4 Riflessioni Conclusive",
    "text": "79.4 Riflessioni Conclusive\nIl “problema del piranha” evidenzia i limiti intrinseci nell’assumere che numerosi effetti indipendenti e di grande entità possano coesistere all’interno di un sistema complesso. In realtà, tali effetti devono necessariamente interagire tra loro o essere correlati, rendendo improbabile la loro indipendenza. Questa dinamica crea instabilità nel sistema e porta a variazioni degli effetti nel tempo o tra popolazioni, compromettendo la possibilità di generalizzarne i risultati.\nTosh et al. (2025) suggeriscono che molti risultati pubblicati, che riportano effetti improbabilmente grandi, siano attribuibili non tanto a reali fenomeni psicologici, quanto a problemi metodologici, come bassa potenza statistica e i “gradi di libertà del ricercatore” (Simmons et al., 2011). La proliferazione di questi risultati contribuisce alla crisi di replicabilità, poiché i presunti effetti si rivelano spesso instabili o non replicabili.\nLa consapevolezza dei limiti imposti dal problema del piranha invita la ricerca psicologica a focalizzarsi maggiormente sulla robustezza metodologica, sull’identificazione di effetti plausibili e sulla considerazione delle interazioni tra variabili. Piuttosto che cercare di identificare molteplici grandi effetti, è essenziale riconoscere che un sistema complesso, per essere stabile e prevedibile, richiede un approccio che consideri l’interdipendenza delle variabili e la struttura complessiva del sistema. Questo approccio può contribuire a migliorare la validità e la replicabilità della ricerca nelle scienze sociali.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "href": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "title": "79  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230–244.\n\n\nLeys, R. (2024). Anatomy of a Train Wreck: The Rise and Fall of Priming Research. University of Chicago Press.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nTosh, C., Greengard, P., Goodrich, B., Gelman, A., Vehtari, A., & Hsu, D. (2025). The Piranha Problem: Large Effects Swimming in a Small Pond. Notices of the American Mathematical Society.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html",
    "href": "chapters/replication_crisis/08_integrity.html",
    "title": "80  Integrità della ricerca",
    "section": "",
    "text": "80.1 Introduzione\nL’integrità della ricerca si fonda su principi e standard professionali volti a garantire l’affidabilità e la qualità degli studi scientifici. Essa si distingue dall’etica della ricerca, che invece si concentra sui principi morali. Elementi chiave per l’integrità includono la condivisione dei dati, il consenso informato e la trasparenza nelle pratiche di ricerca. I codici di condotta svolgono un ruolo cruciale nel guidare i comportamenti etici sia dei ricercatori che delle istituzioni. Tra le principali sfide da affrontare vi sono le pratiche di ricerca discutibili, la fabbricazione e falsificazione dei dati, il plagio e la gestione dei conflitti di interesse. Promuovere una cultura della ricerca basata su onestà, trasparenza e rispetto dei principi etici è essenziale per preservare l’integrità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "href": "chapters/replication_crisis/08_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "title": "80  Integrità della ricerca",
    "section": "80.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca",
    "text": "80.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca\nNel contesto della ricerca, aderire a principi di condotta responsabile è fondamentale. Questi principi, spesso definiti come buone pratiche di ricerca, stabiliscono standard professionali che mirano a ottimizzare la qualità e l’affidabilità degli studi. Sebbene i concetti di base su cosa costituisca una buona pratica di ricerca rimangano stabili nel tempo, la loro applicazione pratica si evolve in risposta a cambiamenti sociali, politici e tecnologici. Un esempio significativo di questa evoluzione è l’enfasi crescente sulla condivisione dei dati di ricerca, resa possibile dall’uso di repository online gratuiti. Ciò ha portato a un’aspettativa diffusa di trasparenza e accessibilità dei dati. Allo stesso modo, la condivisione del codice utilizzato per analizzare i dati è diventata una pratica sempre più incoraggiata.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#differenziazione-tra-integrità-ed-etica-della-ricerca",
    "href": "chapters/replication_crisis/08_integrity.html#differenziazione-tra-integrità-ed-etica-della-ricerca",
    "title": "80  Integrità della ricerca",
    "section": "80.3 Differenziazione tra Integrità ed Etica della Ricerca",
    "text": "80.3 Differenziazione tra Integrità ed Etica della Ricerca\nL’integrità della ricerca si basa su standard professionali, mentre l’etica della ricerca si fonda su principi morali come l’autonomia, la beneficenza, la non-maleficenza e la giustizia. Questi principi etici si traducono in pratiche specifiche, quali il consenso informato e la garanzia di verità e riservatezza nei confronti dei partecipanti. I ricercatori hanno l’obbligo di evitare studi che possano causare danni o risultare eccessivamente onerosi per i soggetti coinvolti.\nI codici di condotta per l’integrità della ricerca presentano alcune variazioni tra le diverse fonti. Ad esempio, il Codice di condotta europeo per l’integrità della ricerca sottolinea l’importanza di principi come onestà, trasparenza, accuratezza, responsabilità, affidabilità, rispetto e indipendenza. Questi principi si traducono in comportamenti specifici attesi sia dai ricercatori che dalle istituzioni, come la condivisione dei dati nel rispetto delle normative sulla protezione dei dati, tra cui il GDPR europeo.\nUn esempio pratico di come gli standard si siano evoluti è rappresentato dalla condivisione dei dati di ricerca. In passato, questa pratica era limitata dalla mancanza di infrastrutture adeguate. Oggi, grazie ai repository online e alla pressione esercitata da riviste scientifiche e finanziatori, la condivisione dei dati è diventata una pratica standard, riflettendo un cambiamento verso una maggiore apertura e trasparenza.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "href": "chapters/replication_crisis/08_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "title": "80  Integrità della ricerca",
    "section": "80.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta",
    "text": "80.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta\nNonostante l’esistenza di codici di condotta, i ricercatori, specialmente quelli all’inizio della carriera, possono subire pressioni da parte dei supervisori per adottare comportamenti che deviano dagli standard stabiliti. Questo è spesso dovuto alla competitività nel campo scientifico e al sistema di valutazione basato sul numero di pubblicazioni. Tali dinamiche possono portare a pratiche di ricerca discutibili (PRD), come la pubblicazione selettiva dei risultati o l’uso di analisi dei dati flessibili per ottenere risultati statisticamente significativi.\nPer preservare l’integrità della ricerca, è essenziale creare un ambiente di lavoro che promuova apertura, inclusività e discussione franca delle pressioni e delle sfide etiche. Ciò richiede non solo l’adesione ai codici di condotta esistenti, ma anche un impegno attivo delle istituzioni nel promuovere la formazione etica e l’integrità tra i ricercatori. Solo attraverso un approccio di questo tipo la comunità scientifica può aspirare a una ricerca di alta qualità, sia eticamente responsabile che metodologicamente solida.\nUn esempio emblematico delle tensioni nel mondo accademico è il gioco da tavolo Publish or Perish, recentemente promosso dalla prestigiosa rivista Nature. La descrizione del gioco è provocatoria:\n\n“Falsificare dati, screditare altri scienziati, pubblicare una montagna di articoli che ricevono una torre di citazioni: i cinici potrebbero descrivere questi come passi necessari per raggiungere il successo accademico.”\n\nQuesta iniziativa solleva interrogativi sullo stato attuale della ricerca scientifica. Il mondo accademico sembra offrire incentivi distorti, mentre il sistema economico delle riviste scientifiche presenta una componente di monetizzazione che spesso entra in conflitto con gli obiettivi fondamentali della ricerca. Questo contesto favorisce l’accettazione di pratiche disoneste, funzionali al mantenimento dello status quo.\nIn questo scenario complesso, emergono voci di dissenso che auspicano una riforma del sistema scientifico (McElreath, 2020; Smaldino & McElreath, 2016). È necessaria una riflessione profonda su come bilanciare la produttività accademica con l’etica e la qualità della ricerca, nonché sul ruolo delle riviste scientifiche nel plasmare il panorama della ricerca contemporanea.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#bibliografia",
    "href": "chapters/replication_crisis/08_integrity.html#bibliografia",
    "title": "80  Integrità della ricerca",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society open science, 3(9), 160384.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html",
    "href": "chapters/epiloque/epiloque.html",
    "title": "Considerazioni Conclusive",
    "section": "",
    "text": "Limiti dell’Inferenza Frequentista\nL’inferenza bayesiana rappresenta un approccio rigoroso e trasparente per integrare conoscenze pregresse e dati empirici nell’analisi psicologica. A differenza dei metodi frequentisti, l’approccio bayesiano consente di quantificare l’incertezza e di costruire modelli che riflettono le nostre aspettative iniziali. Questa flessibilità è particolarmente preziosa in psicologia, dove teorie e ipotesi svolgono un ruolo centrale nel guidare la ricerca. L’inferenza bayesiana rende esplicite le nostre assunzioni a priori e ci permette di valutare come i dati influenzano la nostra comprensione dei fenomeni psicologici.\nIn questo corso, abbiamo esaminato i limiti dell’inferenza frequentista, specialmente quando utilizzata come “filtro” per distinguere risultati scientifici rilevanti da quelli trascurabili. L’eccessiva dipendenza dai valori-p è stata ampiamente criticata per la sua associazione con inferenze inadeguate. Gli effetti possono essere sovrastimati, talvolta anche nella direzione sbagliata, quando la stima è vincolata alla significatività statistica in presenza di dati altamente variabili (Loken & Gelman, 2017).\nNonostante le critiche di lunga data e i dibattiti sul loro uso improprio (Gardner e Altman, 1986; Cohen, 1994; Anderson et al., 2000; Fidler et al., 2004; Finch et al., 2004), i valori-p persistono come indicatore di significatività. Questa tenacia riflette forse la necessità dei ricercatori di avere strumenti intuitivi, sebbene semplificati, per interpretare i dati. Tuttavia, l’uso rigido di soglie arbitrarie (ad esempio, 0.05, 0.01, 0.001) ha trasformato il raggiungimento della significatività in un obiettivo fine a se stesso, piuttosto che in uno strumento per comprendere i fenomeni sottostanti (Cohen, 1994; Kirk, 1996). Inoltre, i valori-p possono solo rifiutare l’ipotesi nulla, ma non confermarla, poiché un risultato non significativo non implica l’assenza di effetti o differenze (Wagenmakers, 2007; Amrhein et al., 2019).\nL’uso improprio dei valori-p, noto come “p-hacking” (Simmons et al., 2011), ha favorito pratiche scientifiche discutibili, contribuendo alla crisi di riproducibilità nella psicologia (Chambers et al., 2014; Szucs e Ioannidis, 2016).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "href": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "title": "Considerazioni Conclusive",
    "section": "La Crisi della Replicabilità",
    "text": "La Crisi della Replicabilità\nLa crisi della replicabilità rappresenta una delle principali sfide che affliggono la ricerca scientifica contemporanea, con effetti particolarmente rilevanti nel campo della psicologia. Quando i risultati di uno studio non possono essere riprodotti in condizioni simili, si mette in discussione non solo la validità delle teorie su cui si basano interventi clinici e politiche pubbliche, ma anche la fiducia generale nella scienza. Questo problema va oltre l’ambito accademico, influenzando direttamente l’efficacia delle applicazioni pratiche delle ricerche.\n\nLe Cause Sottostanti\nUno dei fattori principali della crisi è legato all’uso di metodologie di ricerca e analisi dei dati insufficientemente rigorose, che spesso portano a falsi positivi. Sebbene siano stati fatti appelli per migliorare le pratiche scientifiche, tali problemi persistono, indicando che il fenomeno non è semplicemente frutto di errori o mancanza di comprensione. Secondo Smaldino e McElreath (2016), la causa radicale risiede nei sistemi di incentivi distorti che favoriscono la quantità piuttosto che la qualità della ricerca. In questo contesto, la pressione a pubblicare risultati significativi diventa prioritaria rispetto alla rigorosità metodologica, alimentando un circolo vizioso in cui la “scienza scadente” si perpetua.\nPratiche comuni, come il p-hacking (manipolazione statistica per ottenere risultati significativi) o la selezione selettiva dei dati, vengono adottate inconsciamente o intenzionalmente per massimizzare le probabilità di pubblicazione. Questo meccanismo, descritto come una forma di “selezione naturale della scienza scadente”, premia approcci che facilitano la produzione di risultati spettacolari, ma non necessariamente veritieri.\n\n\nVerso una Soluzione: Cambiare la Cultura Scientifica\nPer superare questa crisi, è fondamentale operare un cambiamento culturale all’interno della comunità scientifica. Non basta correggere gli errori metodologici; occorre modificare radicalmente gli incentivi per premiare la qualità, la trasparenza e la replicabilità della ricerca. Alcune strategie chiave includono:\n\nPromozione di Pratiche Rigorose:\n\nAdottare protocolli trasparenti, preregistrare gli studi prima del loro avvio e condividere apertamente dati e materiali.\nImplementare procedure di peer review più severe e incoraggiare la revisione post-pubblicazione.\n\nValorizzazione della Replicazione:\n\nDare maggiore riconoscimento agli studi che replicano risultati precedenti, anziché privilegiare esclusivamente nuove scoperte.\nCreare riviste specializzate che si concentriano sulla verifica e sulla riproducibilità degli studi.\n\nRiforma dei Criteri di Valutazione:\n\nSpostare l’attenzione dalla quantità delle pubblicazioni alla loro qualità e impatto scientifico.\nIncorporare metriche alternative, come l’impatto sociale e la contribuzione alla conoscenza consolidata.\n\n\n\n\nNuovi Approcci Metodologici\nAlcune proposte innovative mirano a migliorare la qualità delle analisi statistiche e ridurre la propensione a falsi positivi. Un esempio è l’adozione dell’inferenza bayesiana, che offre vantaggi significativi rispetto ai metodi tradizionali:\n\nMaggiore flessibilità nell’analisi di dati rumorosi o campioni piccoli.\nMinore propensione agli errori di tipo I.\nPossibilità di incorporare conoscenze pregresse nel processo decisionale.\n\nTuttavia, l’inferenza bayesiana da sola non può risolvere completamente il problema. È necessario affrontare anche le cause strutturali, come il sistema accademico che premia la produttività quantitativa piuttosto che la qualità.\nUn’altra prospettiva promettente è quella avanzata da Richard McElreath, che suggerisce di passare da un approccio descrittivo a uno che descrive formalmente i meccanismi generativi dei dati. Questo significa formulare ipotesi esplicite sui processi sottostanti e testarle attraverso confronti quantitativi tra modelli. Tecniche come la validazione incrociata bayesiana Leave-One-Out (LOO) permettono di valutare la robustezza dei modelli e la loro capacità di generalizzare a nuovi contesti.\nInoltre, la “rivoluzione causale” cerca di identificare relazioni causali in contesti naturali, superando i limiti degli esperimenti controllati tradizionali. Questo approccio richiede ai ricercatori di formulare ipotesi causali esplicite e confrontare modelli alternativi, migliorando così la comprensione dei fenomeni studiati.\n\n\nImplicazioni Sociali e Educative\nLa crisi della replicabilità ha implicazioni concrete al di là del mondo accademico. Interventi clinici, politiche pubbliche e decisioni basate su ricerche non replicabili rischiano di essere inefficaci o dannose. Pertanto, garantire la replicabilità e l’affidabilità delle scoperte scientifiche è essenziale non solo per preservare l’integrità accademica, ma anche per assumersi responsabilità sociali.\nUna revisione dei metodi didattici e dei programmi accademici è altrettanto cruciale. Gli studenti devono essere formati per comprendere e applicare inferenze basate su dati empirici. Studiosi come Mine Dogucu hanno sottolineato l’importanza di integrare approcci bayesiani e causalità nei corsi di formazione, e la presente dispensa si inserisce in questo sforzo (Dogucu & Çetinkaya-Rundel, 2021; Dogucu & Hu, 2022; Johnson et al., 2022; Rosenberg et al., 2022).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#conclusioni",
    "href": "chapters/epiloque/epiloque.html#conclusioni",
    "title": "Considerazioni Conclusive",
    "section": "Conclusioni",
    "text": "Conclusioni\nAffrontare e superare la crisi della replicabilità rappresenta una sfida fondamentale per la comunità scientifica, richiedendo un impegno collettivo per riformare profondamente la cultura della ricerca. Modificare gli incentivi che favoriscono quantità piuttosto che qualità, promuovere pratiche metodologiche rigorose e valorizzare la replicazione sono passi essenziali per costruire una scienza più affidabile. Solo attraverso un approccio multidimensionale sarà possibile ripristinare la fiducia nella psicologia scientifica e garantire che le sue applicazioni pratiche siano fondate su basi solide e verificabili.\nIn questo contesto, l’inferenza bayesiana emerge come uno strumento di grande valore per l’analisi dei dati psicologici. Offrendo metodi avanzati per gestire l’incertezza, integrare conoscenze pregresse e adattarsi a modelli complessi, essa si dimostra particolarmente utile per esplorare i fenomeni legati alla mente umana e al comportamento. La sua capacità di fornire previsioni robuste e di aggiornare le ipotesi in base a nuovi dati la rende un approccio ideale per affrontare le sfide poste dalla natura intrinsecamente dinamica del campo psicologico.\nTuttavia, è importante sottolineare che l’adozione di metodi bayesiani non costituisce da sola una soluzione completa alla crisi della replicabilità. Per migliorare realmente la qualità della ricerca, è necessario integrare queste tecniche con pratiche metodologiche rigorose. Tra queste, spiccano la formalizzazione di modelli generativi, che consentono di descrivere esplicitamente i processi sottostanti ai dati osservati, e il confronto tra modelli alternativi, fondamentale per valutare l’adeguatezza delle teorie proposte. Inoltre, l’adozione di una prospettiva causale esplicita è cruciale per identificare correttamente le relazioni di causa-effetto, superando i limiti degli studi correlazionali o degli esperimenti tradizionali.\nIn conclusione, solo un approccio integrato, che combini l’inferenza bayesiana con pratiche metodologiche avanzate e una riflessione critica sui sistemi di incentivi accademici, permetterà di progredire verso una scienza psicologica più affidabile e riproducibile. Questo sforzo collettivo non solo migliorerà la qualità delle ricerche, ma contribuirà anche a fornire una comprensione più profonda e accurata del comportamento umano, consolidando così la posizione della psicologia come disciplina scientifica solida e credibile.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#bibliografia",
    "href": "chapters/epiloque/epiloque.html#bibliografia",
    "title": "Considerazioni Conclusive",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDogucu, M., & Çetinkaya-Rundel, M. (2021). Web scraping in the statistics and data science curriculum: Challenges and opportunities. Journal of Statistics and Data Science Education, 29(sup1), S112–S122.\n\n\nDogucu, M., & Hu, J. (2022). The current state of undergraduate Bayesian education and recommendations for the future. The American Statistician, 76(4), 405–413.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nRosenberg, J. M., Kubsch, M., Wagenmakers, E.-J., & Dogucu, M. (2022). Making sense of uncertainty in the science classroom: A Bayesian approach. Science & Education, 31(5), 1239–1262.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html",
    "href": "chapters/appendix/a02_shell.html",
    "title": "Appendice A — La Shell",
    "section": "",
    "text": "A.1 Che cos’è una Shell?\nUna shell è un programma che riceve comandi dall’utente tramite tastiera (o da file) e li passa al sistema operativo per l’esecuzione. Può essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html#che-cosè-una-shell",
    "href": "chapters/appendix/a02_shell.html#che-cosè-una-shell",
    "title": "Appendice A — La Shell",
    "section": "",
    "text": "A.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\nA.1.2 Windows vs macOS/Linux\n\nWindows 10: È possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l’ambiente preferito è solitamente PowerShell.\nmacOS/Linux: Zsh è la shell predefinita in entrambi i sistemi. È consigliabile sfruttare l’applicazione warp per un’esperienza utente moderna e ottimizzata.\n\n\n\nA.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\nA.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\nA.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless / more: Visualizza il contenuto dei file con possibilità di navigazione.\ncat: Mostra l’intero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\nA.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l’utilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilità nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma più potente perché può rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\nA.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\nA.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilità di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l’intero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\nÈ cruciale familiarizzarsi con l’utilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L’impiego dei percorsi relativi rende il processo di navigazione più intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l’utilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: È importante evitare l’inserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, \\), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l’uso del trattino (-) può causare problemi; quindi è consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilità con alcuni sistemi operativi o applicazioni, rendendo più complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, è consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, è possibile ottimizzare notevolmente l’organizzazione e la gestione dei propri file, migliorando l’efficienza del lavoro e riducendo il rischio di errori.\n\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti (es., Robbins, 2016). La familiarità con la shell è fondamentale nella data science.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html#bibliografia",
    "href": "chapters/appendix/a02_shell.html#bibliografia",
    "title": "Appendice A — La Shell",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nRobbins, A. (2016). Bash Pocket Reference: Help for Power Users and Sys Admins. O’Reilly Media, Inc.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a10_math_symbols.html",
    "href": "chapters/appendix/a10_math_symbols.html",
    "title": "Appendice B — Simbologia di base",
    "section": "",
    "text": "Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire “per ogni.”\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) è un elemento dell’insieme \\(A\\).\nL’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\).\nL’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge “tale che.”\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge “proporzionale a.”\nIl simbolo \\(\\approx\\) si legge “circa.”\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.”\nIl simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.”\nIl simbolo \\(\\#\\) indica la cardinalità di un insieme.\nIl simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore più alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html",
    "href": "chapters/appendix/a11_numbers.html",
    "title": "Appendice C — Numeri e intervalli",
    "section": "",
    "text": "C.1 Numeri binari\nI numeri binari rappresentano il sistema numerico più elementare utilizzato in informatica, poiché sono composti unicamente da due simboli: 0 e 1. Questa caratteristica li rende particolarmente adatti alla rappresentazione di situazioni dicotomiche (vero/falso, presente/assente) e consente ai computer di operare rapidamente ed efficacemente sui dati.\nUn esempio semplice d’impiego dei valori logici binari si ottiene quando raccogliamo risposte a una domanda chiusa. Immaginiamo, ad esempio, di porre la domanda “Ti piacciono i mirtilli?” a 10 studenti. Se le risposte vengono memorizzate in R come valori logici (TRUE per “Sì” e FALSE per “No”), potremmo avere:\nopinion &lt;- c(TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE)\nopinion\n\n [1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE\nIn questo caso, TRUE e FALSE corrispondono a 1 e 0 rispettivamente quando utilizzati in operazioni numeriche. Lo stesso avviene in Python, dove True è interpretato come 1 e False come 0. Questa rappresentazione binaria permette di ottenere facilmente statistiche sintetiche. Per esempio, per calcolare la proporzione di risposte positive rispetto al totale, è sufficiente sommare i valori (contando così il numero di TRUE) e dividere per la lunghezza del vettore:\nsum(opinion) / length(opinion)\n\n[1] 0.7\nQuesto fornisce immediatamente la percentuale di studenti che hanno risposto “Sì” alla domanda.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-interi",
    "href": "chapters/appendix/a11_numbers.html#numeri-interi",
    "title": "Appendice C — Numeri e intervalli",
    "section": "\nC.2 Numeri interi",
    "text": "C.2 Numeri interi\nI numeri interi sono caratterizzati dall’assenza di componenti decimali. Essi includono sia i numeri naturali (1, 2, 3, …), tradizionalmente utilizzati per il conteggio, sia i loro opposti negativi. L’insieme dei numeri naturali è indicato con \\(\\mathbb{N}\\), mentre l’insieme dei numeri interi (che include i numeri naturali, i loro negativi e lo zero) si denota con \\(\\mathbb{Z}\\):\n\\[\n\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\pm 3, \\dots\\}\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "title": "Appendice C — Numeri e intervalli",
    "section": "\nC.3 Numeri razionali",
    "text": "C.3 Numeri razionali\nI numeri razionali sono quei numeri che possono essere espressi come il rapporto tra due numeri interi, con il denominatore diverso da zero. Essi formano l’insieme:\n\\[\n\\mathbb{Q} = \\left\\{\\frac{m}{n} \\mid m,n \\in \\mathbb{Z}, n \\neq 0\\right\\}.\n\\]\nPoiché ogni numero naturale è anche un intero, e ogni intero può essere rappresentato come razionale (ad esempio \\(5 = \\frac{5}{1}\\)), si ha una catena d’inclusioni tra i diversi insiemi di numeri:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}.\n\\]\nSe si desidera considerare solo i numeri razionali non negativi, si utilizza la notazione:\n\\[\n\\mathbb{Q}^+ = \\{q \\in \\mathbb{Q} \\mid q \\geq 0\\}.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "title": "Appendice C — Numeri e intervalli",
    "section": "\nC.4 Numeri irrazionali",
    "text": "C.4 Numeri irrazionali\nNon tutti i numeri possono essere espressi come rapporto di due interi. I numeri che non hanno questa proprietà sono detti irrazionali. Essi non possono essere scritti in forma frazionaria e la loro espansione decimale è infinita e non periodica. Esempi tipici di numeri irrazionali sono:\n\n\\(\\sqrt{2}\\)\n\\(\\sqrt{3}\\)\n\\(\\pi = 3.141592...\\)",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-reali",
    "href": "chapters/appendix/a11_numbers.html#numeri-reali",
    "title": "Appendice C — Numeri e intervalli",
    "section": "\nC.5 Numeri reali",
    "text": "C.5 Numeri reali\nI numeri razionali non coprono tutti i possibili punti sulla retta reale. Per rappresentare ogni possibile misura, grandezza o punto su una linea continua, si considerano i numeri reali, denotati con \\(\\mathbb{R}\\). L’insieme dei numeri reali comprende sia i razionali sia gli irrazionali:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q} \\subseteq \\mathbb{R}.\n\\]\nIn statistica, la precisione con cui si esprime una misura è spesso legata al numero di cifre decimali utilizzate, sfruttando così appieno la “continuità” offerta dai numeri reali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "href": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "title": "Appendice C — Numeri e intervalli",
    "section": "\nC.6 Intervalli Numerici",
    "text": "C.6 Intervalli Numerici\nDefinizione: Un intervallo numerico è un sottoinsieme connesso della retta reale. Intuitivamente, rappresenta tutti i numeri reali compresi tra due estremi, che possono o meno essere inclusi nell’intervallo stesso.\nClassificazione degli intervalli: Gli intervalli vengono classificati in base all’inclusione o meno degli estremi:\n\n\nIntervallo chiuso: Include entrambi gli estremi. Si indica con \\([a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x \\leq b\\).\n\nIntervallo aperto: Non include alcun estremo. Si indica con \\((a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x &lt; b\\).\n\nIntervalli semiaperti:\n\n\nChiuso a sinistra e aperto a destra: Include l’estremo sinistro ma non quello destro. Si indica con \\([a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x &lt; b\\).\n\nAperto a sinistra e chiuso a destra: Include l’estremo destro ma non quello sinistro. Si indica con \\((a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x \\leq b\\).\n\n\n\nTabella riassuntiva:\n\n\nIntervallo\nNotazione\nCondizione\n\n\n\nChiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\nAperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nChiuso a sinistra, aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\nAperto a sinistra, chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)\n\n\n\nOsservazioni: * La scelta della notazione con parentesi quadre o tonde indica rispettivamente l’inclusione o l’esclusione degli estremi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "Appendice E — Sommatorie",
    "section": "",
    "text": "E.1 Manipolazione di somme\nLe somme sono uno strumento fondamentale in molti contesti matematici e statistici, e per gestirle in modo efficace è essenziale disporre di una notazione chiara e precisa. Consideriamo, ad esempio, la somma dei primi \\(n\\) numeri interi, che può essere espressa come \\(1 + 2 + \\dots + (n-1) + n\\), dove i puntini di sospensione (\\(\\dots\\)) indicano che la sequenza deve essere completata seguendo il pattern definito dai termini precedenti e successivi. Tuttavia, una notazione come \\(1 + 7 + \\dots + 73.6\\) risulterebbe ambigua senza ulteriori specifiche. In generale, ci troveremo di fronte a somme della forma\n\\[\nx_1 + x_2 + \\dots + x_n,\n\\]\ndove \\(x_n\\) rappresenta un numero definito altrove. Sebbene questa notazione con i puntini di sospensione sia utile in alcuni contesti, può risultare poco chiara in altri. Per questo motivo, si preferisce utilizzare la notazione di sommatoria:\n\\[\n\\sum_{i=1}^n x_i,\n\\]\nche si legge “sommatoria per \\(i\\) che va da \\(1\\) a \\(n\\) di \\(x_i\\)”. Il simbolo \\(\\sum\\) (la lettera sigma maiuscola dell’alfabeto greco) rappresenta l’operazione di somma, \\(x_i\\) è il generico addendo, mentre \\(1\\) e \\(n\\) sono gli estremi della sommatoria, che definiscono l’intervallo di variazione dell’indice \\(i\\). Solitamente, l’estremo inferiore è \\(1\\), ma potrebbe essere qualsiasi altro numero \\(m &lt; n\\). Pertanto, possiamo scrivere:\n\\[\n\\sum_{i=1}^n x_i = x_1 + x_2 + \\dots + x_n.\n\\]\nAd esempio, se i valori di \\(x\\) sono \\(\\{3, 11, 4, 7\\}\\), avremo:\n\\[\n\\sum_{i=1}^4 x_i = 3 + 11 + 4 + 7 = 25,\n\\]\ndove \\(x_1 = 3\\), \\(x_2 = 11\\), e così via. La quantità \\(x_i\\) è detta argomento della sommatoria, mentre la variabile \\(i\\), che assume valori interi successivi, è chiamata indice della sommatoria.\nLa notazione di sommatoria può anche essere espressa nella forma:\n\\[\n\\sum_{P(i)} x_i,\n\\]\ndove \\(P(i)\\) è una proposizione logica riguardante \\(i\\) che può essere vera o falsa. Quando è evidente che si vogliono sommare tutte le \\(n\\) osservazioni, la notazione può essere semplificata in \\(\\sum_{i} x_i\\) o addirittura \\(\\sum x_i\\). L’indice \\(i\\) può essere sostituito da altre lettere, come \\(k, j, l, \\dots\\), a seconda del contesto.\nPer semplificare i calcoli che coinvolgono le sommatorie, è utile conoscere alcune proprietà fondamentali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "Appendice E — Sommatorie",
    "section": "",
    "text": "E.1.1 Proprietà 1 (Somma di una costante)\nLa sommatoria di \\(n\\) valori tutti uguali a una costante \\(a\\) è pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a}_{n \\text{ volte}} = n a.\n\\]\n\n\nE.1.2 Proprietà 2 (Proprietà distributiva)\nSe l’argomento della sommatoria contiene una costante, è possibile fattorizzarla. Ad esempio:\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n = a (x_1 + x_2 + \\dots + x_n) = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\nE.1.3 Proprietà 3 (Proprietà associativa)\nSe l’argomento della sommatoria è una somma, possiamo separare i termini:\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_2) + \\dots + (a + x_n) = n a + \\sum_{i=1}^{n} x_i.\n\\]\nIn generale, possiamo scrivere:\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\nE.1.4 Proprietà 4 (Operazioni algebriche)\nSe è necessario eseguire un’operazione algebrica (come l’elevamento a potenza o il logaritmo) sull’argomento della sommatoria, questa operazione deve essere eseguita prima della somma. Ad esempio:\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left( \\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\nE.1.5 Proprietà 5 (Prodotto di termini)\nNel caso di un prodotto tra termini, il prodotto deve essere eseguito prima della somma:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n.\n\\]\nInfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "Appendice E — Sommatorie",
    "section": "E.2 Doppia sommatoria",
    "text": "E.2 Doppia sommatoria\nIn alcuni contesti, si incontrano espressioni con una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{m} x_{ij}.\n\\]\nQuesta notazione implica che, per ogni valore dell’indice esterno \\(i\\) (da \\(1\\) a \\(n\\)), si deve sviluppare la sommatoria interna per \\(j\\) (da \\(1\\) a \\(m\\)). Ad esempio:\n\\[\n\\sum_{i=1}^{3} \\sum_{j=4}^{6} x_{ij} = (x_{1,4} + x_{1,5} + x_{1,6}) + (x_{2,4} + x_{2,5} + x_{2,6}) + (x_{3,4} + x_{3,5} + x_{3,6}).\n\\]\nUn caso particolare interessante è la doppia sommatoria del prodotto di due variabili:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j.\n\\]\nIn questo caso, poiché \\(x_i\\) non dipende dall’indice \\(j\\), possiamo estrarre \\(x_i\\) dalla sommatoria interna:\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo, la sommatoria interna \\(\\sum_{j=1}^{n} y_j\\) non dipende da \\(i\\), quindi può essere estratta dalla sommatoria esterna:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j = \\left( \\sum_{i=1}^{n} x_i \\right) \\left( \\sum_{j=1}^{n} y_j \\right).\n\\]\n\nE.2.1 Esempio pratico\nConsideriamo i vettori \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\). Calcoliamo la doppia sommatoria:\n\\[\n\\begin{align}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1 y_1 + x_1 y_2 + x_1 y_3 + x_2 y_1 + x_2 y_2 + x_2 y_3 + x_3 y_1 + x_3 y_2 + x_3 y_3 \\\\\n&= 2 \\times (1 + 4 + 9) + 3 \\times (1 + 4 + 9) + 1 \\times (1 + 4 + 9) \\\\\n&= 2 \\times 14 + 3 \\times 14 + 1 \\times 14 = 84.\n\\end{align}\n\\]\nD’altra parte, il prodotto delle due sommatorie è:\n\\[\n\\left( \\sum_{i=1}^3 x_i \\right) \\left( \\sum_{j=1}^3 y_j \\right) = (2 + 3 + 1) \\times (1 + 4 + 9) = 6 \\times 14 = 84.\n\\]\nI due risultati coincidono, confermando la validità della proprietà.\nPer ulteriori approfondimenti, si consiglia la consultazione del testo Concrete Mathematics: A Foundation for Computer Science (Graham et al., 1994).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "href": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "title": "Appendice E — Sommatorie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGraham, R. L., Knuth, D. E., & Patashnik, O. (1994). Concrete Mathematics: A Foundation for Computer Science (2nd ed.). Addison-Wesley.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html",
    "href": "chapters/appendix/a13_sets.html",
    "title": "Appendice E — Insiemi",
    "section": "",
    "text": "E.1 Diagrammi di Eulero-Venn\nUn insieme (o collezione, classe, gruppo, …) è stato definito da Georg Cantor nel modo seguente:\nMentre non è rilevante la natura degli oggetti che costituiscono l’insieme, ciò che importa è distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilità: il dato oggetto è un elemento dell’insieme considerato oppure non è elemento dell’insieme considerato. Due insiemi \\(A\\) e \\(B\\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \\(A=B\\). Due insiemi \\(A\\) e \\(B\\) si dicono diversi se non contengono gli stessi elementi: \\(A \\neq B\\). Ad esempio, i seguenti insiemi sono uguali:\n\\[\n\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\n\\]\nGli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \\(A\\) si indica con\n\\[\nA = \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con } n &gt; 0.\n\\]\nLa scrittura \\(a \\in A\\) dice che \\(a\\) è un elemento di \\(A\\). Per dire che \\(b\\) non è un elemento di \\(A\\) si scrive \\(b \\notin A.\\)\nPer quegli insiemi i cui elementi soddisfano una certa proprietà che li caratterizza, tale proprietà può essere usata per descrivere più sinteticamente l’insieme:\n\\[\nA = \\{x ~\\vert~ \\text{proprietà posseduta da } x\\},\n\\]\nche si legge come “\\(A\\) è l’insieme degli elementi \\(x\\) per cui è vera la proprietà indicata.” Per esempio, per indicare l’insieme \\(A\\) delle coppie di numeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si può scrivere:\n\\[\nA = \\{(x,y) ~\\vert~ y = x^2 + 1\\}.\n\\]\nDati due insiemi \\(A\\) e \\(B\\), diremo che \\(A\\) è un sottoinsieme di \\(B\\) se e solo se tutti gli elementi di \\(A\\) sono anche elementi di \\(B\\):\n\\[\nA \\subseteq B \\iff (\\forall x \\in A \\Rightarrow x \\in B).\n\\]\nSe esiste almeno un elemento di \\(B\\) che non appartiene ad \\(A\\) allora diremo che \\(A\\) è un sottoinsieme proprio di \\(B\\):\n\\[\nA \\subset B \\iff (A \\subseteq B, \\exists~ x \\in B ~\\vert~ x \\notin A).\n\\]\nUn altro insieme, detto insieme delle parti, o insieme potenza, che si associa all’insieme \\(A\\) è l’insieme di tutti i sottoinsiemi di \\(A\\), inclusi l’insieme vuoto e \\(A\\) stesso. Per esempio, per l’insieme \\(A = \\{a, b, c\\}\\), l’insieme delle parti è:\n\\[\n\\mathcal{P}(A) = \\{\n\\emptyset, \\{a\\}, \\{b\\}, \\{c\\},\n\\{a, b\\}, \\{a, c\\}, \\{c, b\\},\n\\{a, b, c\\}\n\\}.\n\\]\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le proprietà delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19° secolo John Venn, anche se rappresentazioni simili erano già state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le proprietà degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all’interno di essi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "Appendice E — Insiemi",
    "section": "\nE.2 Appartenenza ad un insieme",
    "text": "E.2 Appartenenza ad un insieme\nUsiamo ora R\n\nSet1 &lt;- c(1, 2)\nprint(Set1)\n\n[1] 1 2\n\nprint(class(Set1))\n\n[1] \"numeric\"\n\n\n\nmy_list &lt;- c(1, 2, 3, 4)\nmy_set_from_list &lt;- unique(my_list)\nprint(my_set_from_list)\n\n[1] 1 2 3 4\n\n\nL’appartenenza ad un insieme si verifica con %in%.\n\nmy_set &lt;- c(1, 3, 5)\nprint(\"Ecco il mio insieme:\")\n\n[1] \"Ecco il mio insieme:\"\n\nprint(my_set)\n\n[1] 1 3 5\n\nprint(\"1 appartiene all'insieme:\")\n\n[1] \"1 appartiene all'insieme:\"\n\nprint(1 %in% my_set)\n\n[1] TRUE\n\nprint(\"2 non appartiene all'insieme:\")\n\n[1] \"2 non appartiene all'insieme:\"\n\nprint(2 %in% my_set)\n\n[1] FALSE\n\nprint(\"4 NON appartiene all'insieme:\")\n\n[1] \"4 NON appartiene all'insieme:\"\n\nprint(!(4 %in% my_set))\n\n[1] TRUE",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "title": "Appendice E — Insiemi",
    "section": "\nE.3 Relazioni tra insiemi",
    "text": "E.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l’insieme universo e l’insieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv &lt;- 0:10\nSuper &lt;- Univ[Univ %% 2 == 0]\nDisj &lt;- Univ[Univ %% 2 == 1]\nSub &lt;- c(4, 6)\nNull &lt;- Univ[Univ &gt; 10]\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\")\n\n[1] \"Insieme Universo (tutti gli interi positivi fino a 10):\"\n\nprint(Univ)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nprint(\"Tutti gli interi positivi pari fino a 10:\")\n\n[1] \"Tutti gli interi positivi pari fino a 10:\"\n\nprint(Super)\n\n[1]  0  2  4  6  8 10\n\nprint(\"Tutti gli interi positivi dispari fino a 10:\")\n\n[1] \"Tutti gli interi positivi dispari fino a 10:\"\n\nprint(Disj)\n\n[1] 1 3 5 7 9\n\nprint(\"Insieme di due elementi, 4 e 6:\")\n\n[1] \"Insieme di due elementi, 4 e 6:\"\n\nprint(Sub)\n\n[1] 4 6\n\nprint(\"Un insieme vuoto:\")\n\n[1] \"Un insieme vuoto:\"\n\nprint(Null)\n\ninteger(0)\n\n\n\nprint('È \"Super\" un sovrainsieme di \"Sub\"?')\n\n[1] \"È \\\"Super\\\" un sovrainsieme di \\\"Sub\\\"?\"\n\nprint(all(Sub %in% Super))\n\n[1] TRUE\n\nprint('È \"Super\" un sottoinsieme di \"Univ\"?')\n\n[1] \"È \\\"Super\\\" un sottoinsieme di \\\"Univ\\\"?\"\n\nprint(all(Super %in% Univ))\n\n[1] TRUE\n\nprint('È \"Sub\" un sovrainsieme di \"Super\"?')\n\n[1] \"È \\\"Sub\\\" un sovrainsieme di \\\"Super\\\"?\"\n\nprint(all(Super %in% Sub))\n\n[1] FALSE\n\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?')\n\n[1] \"Sono \\\"Super\\\" e \\\"Disj\\\" insiemi disgiunti?\"\n\nprint(length(intersect(Super, Disj)) == 0)\n\n[1] TRUE",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "title": "Appendice E — Insiemi",
    "section": "\nE.4 Operazioni tra insiemi",
    "text": "E.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l’insieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l’insieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cioè\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l’insieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l’insieme differenza \\(A \\setminus B\\) è detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare è data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione all’interno del cerchio di sinistra e \\(R\\) è la regione all’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura.\n\n\nDiagrammi di Venn\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\nLeggi di DeMorgan\n\nVediamo ora come si eseguono le operazioni tra insiemi con R.\nIntersezione.\n\nS1 &lt;- seq(1, 10, by = 3)\nS2 &lt;- 1:6\nS_intersection &lt;- intersect(S1, S2)\nprint(\"Intersezione di S1 e S2:\")\n\n[1] \"Intersezione di S1 e S2:\"\n\nprint(S_intersection)\n\n[1] 1 4\n\n\nUnione. Si noti che il connettivo logico | corrisponde all’unione.\n\nS_union &lt;- union(S1, S2)\nprint(\"Unione di S1 e S2:\")\n\n[1] \"Unione di S1 e S2:\"\n\nprint(S_union)\n\n[1]  1  4  7 10  2  3  5  6\n\n\nInsieme complementare.\n\nS &lt;- seq(0, 20, by = 2)\nS_complement &lt;- setdiff(0:20, S)\nprint(\"S è l'insieme dei numeri interi pari tra 0 e 20:\")\n\n[1] \"S è l'insieme dei numeri interi pari tra 0 e 20:\"\n\nprint(S)\n\n [1]  0  2  4  6  8 10 12 14 16 18 20\n\nprint(\"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\")\n\n[1] \"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\"\n\nprint(S_complement)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\n\nprint(\"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\")\n\n[1] \"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\"\n\nprint(setequal(union(S, S_complement), 0:20))\n\n[1] TRUE\n\n\nDifferenza tra insiemi.\n\nS1 &lt;- seq(0, 30, by = 3)\nS2 &lt;- seq(0, 30, by = 5)\nprint(\"Differenza tra S2 e S1:\")\n\n[1] \"Differenza tra S2 e S1:\"\n\nprint(setdiff(S2, S1))\n\n[1]  5 10 20 25\n\nprint(\"Differenza tra S1 e S2:\")\n\n[1] \"Differenza tra S1 e S2:\"\n\nprint(setdiff(S1, S2))\n\n[1]  3  6  9 12 18 21 24 27\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Δ, è un’operazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all’unione tra i due insiemi meno la loro intersezione.\n\nsym_diff &lt;- union(setdiff(S1, S2), setdiff(S2, S1))\nprint(\"Differenza simmetrica:\")\n\n[1] \"Differenza simmetrica:\"\n\nprint(sym_diff)\n\n [1]  3  6  9 12 18 21 24 27  5 10 20 25",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Appendice E — Insiemi",
    "section": "\nE.5 Coppie ordinate e prodotto cartesiano",
    "text": "E.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) è l’insieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata) e \\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPiù in generale, un prodotto cartesiano di \\(n\\) insiemi può essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento è una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non è dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento è possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all’n-esimo. Il prodotto cartesiano prende il nome da René Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA &lt;- c(\"a\", \"b\", \"c\")\nS &lt;- 1:3\ncartesian_product &lt;- expand.grid(A, S)\nprint(\"Prodotto cartesiano di A e S:\")\n\n[1] \"Prodotto cartesiano di A e S:\"\n\nprint(cartesian_product)\n\n  Var1 Var2\n1    a    1\n2    b    1\n3    c    1\n4    a    2\n5    b    2\n6    c    2\n7    a    3\n8    b    3\n9    c    3\n\n\nSi definisce cardinalità (o potenza) di un insieme finito il numero degli elementi dell’insieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalità dell'insieme prodotto cartesiano è:\")\n\n[1] \"La cardinalità dell'insieme prodotto cartesiano è:\"\n\nprint(nrow(cartesian_product))\n\n[1] 9\n\n\nPotenza del prodotto cartesiano\n\nA &lt;- c(\"Head\", \"Tail\")\np2 &lt;- expand.grid(A, A)\nprint(\"Il quadrato dell'insieme A è un insieme che contiene:\")\n\n[1] \"Il quadrato dell'insieme A è un insieme che contiene:\"\n\nprint(nrow(p2))\n\n[1] 4\n\nprint(p2)\n\n  Var1 Var2\n1 Head Head\n2 Tail Head\n3 Head Tail\n4 Tail Tail\n\n\n\np3 &lt;- expand.grid(A, A, A)\nprint(\"L'insieme A elevato alla terza potenza è costituito da:\")\n\n[1] \"L'insieme A elevato alla terza potenza è costituito da:\"\n\nprint(nrow(p3))\n\n[1] 8\n\nprint(p3)\n\n  Var1 Var2 Var3\n1 Head Head Head\n2 Tail Head Head\n3 Head Tail Head\n4 Tail Tail Head\n5 Head Head Tail\n6 Tail Head Tail\n7 Head Tail Tail\n8 Tail Tail Tail",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html",
    "href": "chapters/appendix/a14_combinatorics.html",
    "title": "86  Calcolo combinatorio",
    "section": "",
    "text": "86.1 Principio della somma\nIl calcolo combinatorio si occupa di determinare il numero di modi in cui è possibile combinare, ordinare o disporre elementi di uno o più insiemi, seguendo regole predefinite. Molti problemi di probabilità richiedono l’applicazione di tecniche combinatorie per calcolare le probabilità di eventi complessi. In questo capitolo, esploreremo le nozioni fondamentali del calcolo combinatorio, mettendo in relazione i suoi concetti con i vari metodi di campionamento dall’urna. Descriveremo i principi della somma e del prodotto, che costituiscono le basi del calcolo combinatorio e trovano applicazione in problemi più complessi, come permutazioni, disposizioni e combinazioni.\nIl principio della somma si applica quando un insieme può essere suddiviso in sottoinsiemi disgiunti (cioè senza sovrapposizioni). In questo caso, il numero totale di elementi è dato dalla somma degli elementi dei sottoinsiemi:\n\\[\nn_{\\text{tot}} = n_1 + n_2 + \\dots + n_k .\n\\]",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "title": "86  Calcolo combinatorio",
    "section": "",
    "text": "Esempio 86.1 Un distributore contiene tre diversi scomparti di caramelle:\n\nScomparto A: 10 caramelle alla menta,\nScomparto B: 8 caramelle alla frutta,\nScomparto C: 12 caramelle al cioccolato.\n\nQuante caramelle diverse ci sono in totale nel distributore?\nSecondo il principio della somma, il totale è dato dalla somma delle caramelle nei tre scomparti:\n\\[\nn_{\\text{tot}} = n_A + n_B + n_C .\n\\]\nCalcolo in R:\n\nA &lt;- 10\nB &lt;- 8\nC &lt;- 12\n\ntotale_caramelle &lt;- A + B + C\ntotale_caramelle\n#&gt; [1] 30\n\nRisultato: Nel distributore ci sono 30 caramelle in totale.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "href": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "title": "86  Calcolo combinatorio",
    "section": "\n86.2 Principio del prodotto",
    "text": "86.2 Principio del prodotto\nIl principio del prodotto si applica quando un’operazione può essere suddivisa in più fasi indipendenti, ciascuna con un numero di possibilità specifico. Il numero totale di combinazioni è dato dal prodotto delle possibilità offerte da ciascuna fase:\n\\[\nn_{\\text{tot}} = n_1 \\cdot n_2 \\cdot \\dots \\cdot n_k .\n\\]\n\nEsempio 86.2 Poniamo di avere quattro urne:\n\nUrna A: 5 palline,\n\nUrna B: 6 palline,\n\nUrna C: 3 palline,\n\nUrna D: 2 palline.\n\nVogliamo formare insiemi di due palline, ciascuna estratta da urne differenti.\nSecondo il principio del prodotto, per ogni coppia di urne, il numero di combinazioni è dato dal prodotto delle palline nelle due urne. Successivamente, usiamo il principio della somma per sommare tutte le possibilità.\n\\[\nn_{\\text{tot}} = AB + AC + AD + BC + BD + CD\n\\]\nCalcolo in R:\n\nAB &lt;- 5 * 6\nAC &lt;- 5 * 3\nAD &lt;- 5 * 2\nBC &lt;- 6 * 3\nBD &lt;- 6 * 2\nCD &lt;- 3 * 2\n\ntotale_insiemi &lt;- AB + AC + AD + BC + BD + CD\ntotale_insiemi\n#&gt; [1] 91\n\nRisultato: Si possono formare 91 insiemi di due palline, ciascuna estratta da urne differenti.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "href": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "title": "86  Calcolo combinatorio",
    "section": "\n86.3 Il modello dell’urna e i metodi di campionamento",
    "text": "86.3 Il modello dell’urna e i metodi di campionamento\nI problemi combinatori spesso si riducono a modelli di estrazione di palline da urne, con quattro principali varianti:\n\n\nCon ripetizione e ordine: ogni estrazione rimette la pallina nell’urna (campionamento Bernoulliano).\n\nSenza ripetizione e con ordine: ogni estrazione rimuove la pallina.\n\nCon ripetizione e senza ordine: si considerano le combinazioni, ignorando l’ordine.\n\nSenza ripetizione e senza ordine: si contano le combinazioni senza rimettere la pallina.\n\n\nEsempio 86.3  \n\nurna &lt;- c(\"a\", \"b\", \"c\")\n\n# Con ripetizione e ordine\ncampionamento1 &lt;- expand.grid(urna, urna) |&gt;\n    rename(Elemento1 = Var1, Elemento2 = Var2)\n\n# Senza ripetizione e con ordine\ncampionamento2 &lt;- permutations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Con ripetizione e senza ordine\ncampionamento3 &lt;- combinations(\n    n = length(urna), r = 2, v = urna, repeats.allowed = TRUE\n) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Senza ripetizione e senza ordine\ncampionamento4 &lt;- combinations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Risultati\nlist(\n    `Con ripetizione e ordine` = campionamento1,\n    `Senza ripetizione e con ordine` = campionamento2,\n    `Con ripetizione e senza ordine` = campionamento3,\n    `Senza ripetizione e senza ordine` = campionamento4\n)\n#&gt; $`Con ripetizione e ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         b         a\n#&gt; 3         c         a\n#&gt; 4         a         b\n#&gt; 5         b         b\n#&gt; 6         c         b\n#&gt; 7         a         c\n#&gt; 8         b         c\n#&gt; 9         c         c\n#&gt; \n#&gt; $`Senza ripetizione e con ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         a\n#&gt; 4         b         c\n#&gt; 5         c         a\n#&gt; 6         c         b\n#&gt; \n#&gt; $`Con ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         a         b\n#&gt; 3         a         c\n#&gt; 4         b         b\n#&gt; 5         b         c\n#&gt; 6         c         c\n#&gt; \n#&gt; $`Senza ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         c",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#permutazioni-semplici",
    "href": "chapters/appendix/a14_combinatorics.html#permutazioni-semplici",
    "title": "86  Calcolo combinatorio",
    "section": "\n86.4 Permutazioni Semplici",
    "text": "86.4 Permutazioni Semplici\nLe permutazioni rappresentano tutte le disposizioni possibili di un insieme di \\(n\\) elementi distinti, considerando l’ordine. Il numero totale di permutazioni è dato dalla formula:\n\\[\nP_n = n!\n\\]\ndove \\(n!\\) (n fattoriale) indica il prodotto di tutti i numeri interi da 1 a \\(n\\):\n\\[\nn! = n \\cdot (n-1) \\cdot (n-2) \\cdot \\dots \\cdot 1 .\n\\]\n\nEsempio 86.4 Calcoliamo tutte le permutazioni possibili per un insieme di tre elementi distinti \\(\\{a, b, c\\}\\). Il numero di permutazioni atteso è:\n\\[\nP_3 = 3! = 3 \\cdot 2 \\cdot 1 = 6 .\n\\]\nImplementazione in R:\n\n# Insieme di partenza\nA &lt;- c(\"a\", \"b\", \"c\")\n\n# Calcolo delle permutazioni\nperm &lt;- permutations(n = length(A), r = length(A), v = A)\n\n# Visualizzazione delle permutazioni\nprint(perm)\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,] \"a\"  \"b\"  \"c\" \n#&gt; [2,] \"a\"  \"c\"  \"b\" \n#&gt; [3,] \"b\"  \"a\"  \"c\" \n#&gt; [4,] \"b\"  \"c\"  \"a\" \n#&gt; [5,] \"c\"  \"a\"  \"b\" \n#&gt; [6,] \"c\"  \"b\"  \"a\"\n\n# Verifica del numero di permutazioni\nnrow(perm)\n#&gt; [1] 6\n\nLe permutazioni dell’insieme sono:\n\\[\n  \\begin{aligned}\n  &\\{a, b, c\\}, \\{a, c, b\\}, \\{b, a, c\\}, \\{b, c, a\\}, \\{c, a, b\\}, \\{c, b, a\\} .\n  \\end{aligned}\n  \\]\nIl numero totale è \\(P_3 = 6\\).\n\n\n86.4.1 Caratteristiche delle Permutazioni\nLe permutazioni rappresentano un caso di campionamento senza ripetizione con ordine:\n\n\nSenza ripetizione: Ogni elemento può essere utilizzato una sola volta.\n\nCon ordine: La disposizione degli elementi è importante.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#disposizioni-semplici",
    "href": "chapters/appendix/a14_combinatorics.html#disposizioni-semplici",
    "title": "86  Calcolo combinatorio",
    "section": "\n86.5 Disposizioni Semplici",
    "text": "86.5 Disposizioni Semplici\nLe disposizioni semplici sono sequenze ordinate di \\(k\\) elementi scelti da un insieme di \\(n\\) elementi distinti. Il numero totale di disposizioni si calcola con la formula:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!}\n\\]\ndove:\n\n\n\\(n!\\) (fattoriale di \\(n\\)) è il prodotto dei numeri interi da 1 a \\(n\\),\n\n\\((n-k)!\\) rappresenta il fattoriale della differenza tra il numero totale di elementi e quelli scelti.\n\n\nEsempio 86.5 Consideriamo l’insieme\\(\\{a, b, c\\}\\) (\\(n = 3\\)) e calcoliamo tutte le disposizioni possibili di 2 elementi (\\(k = 2\\)).\nIl numero di disposizioni atteso è:\n\\[\nD_{3,2} = \\frac{3!}{(3-2)!} = \\frac{3 \\cdot 2 \\cdot 1}{1} = 6 .\n\\]\nImplementazione in R:\n\n# Insieme di partenza\nA &lt;- c(\"a\", \"b\", \"c\")\n\n# Calcolo delle disposizioni di 2 elementi\ndisp &lt;- permutations(n = length(A), r = 2, v = A)\n\n# Visualizzazione delle disposizioni\nprint(disp)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"a\" \n#&gt; [4,] \"b\"  \"c\" \n#&gt; [5,] \"c\"  \"a\" \n#&gt; [6,] \"c\"  \"b\"\n\n# Verifica del numero di disposizioni\nnrow(disp)\n#&gt; [1] 6\n\n\nLe disposizioni di 2 elementi sono: \\[\n\\{a, b\\}, \\{a, c\\}, \\{b, a\\}, \\{b, c\\}, \\{c, a\\}, \\{c, b\\} .\n\\]\n\nIl numero totale è \\(D_{3,2} = 6\\).\n\n\n\n86.5.1 Caratteristiche delle Disposizioni Semplici\nLe disposizioni semplici rappresentano un caso di campionamento senza ripetizione e con ordine:\n\n\nSenza ripetizione: Ogni elemento può essere utilizzato una sola volta.\n\nCon ordine: La disposizione degli elementi selezionati è importante.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#combinazioni-semplici",
    "href": "chapters/appendix/a14_combinatorics.html#combinazioni-semplici",
    "title": "86  Calcolo combinatorio",
    "section": "\n86.6 Combinazioni Semplici",
    "text": "86.6 Combinazioni Semplici\nLe combinazioni semplici rappresentano i modi di selezionare \\(k\\) elementi da un insieme di \\(n\\) elementi senza considerare l’ordine. Il numero totale di combinazioni si calcola con la formula:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n\\]\ndove:\n\n\n\\(n!\\) è il fattoriale di \\(n\\),\n\n\\(k!\\) è il fattoriale di \\(k\\),\n\n\\((n-k)!\\) è il fattoriale della differenza tra il numero totale di elementi e quelli scelti.\n\n\nEsempio 86.6 Consideriamo l’insieme \\(\\{a, b, c\\}\\) (\\(n = 3\\)) e calcoliamo tutte le combinazioni possibili di 2 elementi (\\(k = 2\\)).\nIl numero di combinazioni atteso è:\n\\[\nC_{3,2} = \\binom{3}{2} = \\frac{3!}{2! \\cdot (3-2)!} = \\frac{3 \\cdot 2 \\cdot 1}{2 \\cdot 1 \\cdot 1} = 3 .\n\\]\nImplementazione in R:\n\n# Insieme di partenza\nA &lt;- c(\"a\", \"b\", \"c\")\n\n# Calcolo delle combinazioni di 2 elementi\ncomb &lt;- combinations(n = length(A), r = 2, v = A)\n\n# Visualizzazione delle combinazioni\nprint(comb)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"c\"\n\n# Verifica del numero di combinazioni\nnrow(comb)\n#&gt; [1] 3\n\n\nLe combinazioni di 2 elementi sono: \\[\n\\{a, b\\}, \\{a, c\\}, \\{b, c\\} .\n\\]\n\nIl numero totale è \\(C_{3,2} = 3\\).\n\n\n\n86.6.1 Caratteristiche delle Combinazioni Semplici\nLe combinazioni semplici rappresentano un caso di campionamento senza ripetizione e senza ordine:\n\n\nSenza ripetizione: Ogni elemento può essere selezionato una sola volta.\n\nSenza ordine: L’ordine degli elementi selezionati non ha importanza (\\(\\{a, b\\}\\) è uguale a \\(\\{b, a\\}\\)).\n\nQuesto capitolo ha illustrato i legami tra i metodi del calcolo combinatorio e le diverse modalità di campionamento, mostrando come implementare questi concetti in R.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html",
    "href": "chapters/appendix/a15_calculus.html",
    "title": "87  Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "87.1 Integrali\nIn questo capitolo, traduciamo e adattiamo il capitolo Per liberarvi dai terrori preliminari tratto da Calculus made easy.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#integrali",
    "href": "chapters/appendix/a15_calculus.html#integrali",
    "title": "87  Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "Il terrore preliminare, che spesso impedisce agli studenti di avvicinarsi all’analisi matematica, può essere superato comprendendo il significato intuitivo dei due simboli principali utilizzati in questo campo.\nQuesti simboli, che possono sembrare intimidatori, sono in realtà molto semplici:\n\n\\(d\\): Questo simbolo significa semplicemente “un po’ di”. Ad esempio, \\(\\operatorname{d}\\!x\\) indica un piccolo incremento di \\(x\\), mentre \\(\\operatorname{d}\\!u\\) rappresenta un piccolo incremento di \\(u\\). I matematici preferiscono dire “un elemento di” invece di “un po’ di”, ma il concetto è lo stesso. Questi piccoli incrementi possono essere considerati infinitamente piccoli.\n\\(\\int\\): Questo simbolo è una S allungata e rappresenta “la somma di”. Quindi, \\(\\int \\operatorname{d}\\!x\\) significa la somma di tutti i piccoli incrementi di \\(x\\), mentre \\(\\int \\operatorname{d}\\!t\\) indica la somma di tutti i piccoli incrementi di \\(t\\). I matematici chiamano questo simbolo “integrale”. Se consideri \\(x\\) come composto da tanti piccoli pezzi \\(\\operatorname{d}\\!x\\), sommandoli tutti otterrai l’intero valore di \\(x\\). La parola “integrale” significa semplicemente “il tutto”. Ad esempio, se pensi a un’ora come composta da 3600 secondi, la somma di tutti questi secondi ti darà un’ora. Quando vedi un’espressione che inizia con \\(\\int\\), significa che devi sommare tutti i piccoli pezzi indicati dai simboli che seguono.\n\nEcco, il terrore è svanito!\n\n\n\n\n87.1.1 Verifica con Simulazioni in R\nPer calcolare e visualizzare l’integrale di una funzione di densità, possiamo utilizzare il linguaggio di programmazione R. Consideriamo come esempio la funzione di densità gaussiana, definita dalla seguente formula:\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}.\n\\]\nIn R, possiamo definire questa funzione come segue:\n\ngaussian &lt;- function(x, mu, sigma) {\n  1 / (sigma * sqrt(2 * pi)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\nDefiniamo i parametri e generiamo i valori per il calcolo della funzione di densità su un intervallo:\n\nmu &lt;- 0      # Media\nsigma &lt;- 1   # Deviazione standard\na &lt;- -10     # Limite inferiore\nb &lt;- 10      # Limite superiore\nn &lt;- 10000   # Numero di punti\n\nx_range &lt;- seq(a, b, length.out = n)  # Valori x\nfx &lt;- gaussian(x_range, mu, sigma)   # Ordinata della funzione\n\nVisualizziamo la funzione utilizzando il pacchetto ggplot2:\n\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(data.frame(x = x_range, fx = fx), aes(x, fx)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di densità gaussiana\", \n    x = \"x\", \n    y = \"f(x)\"\n  )\n\n\n\n\n\n\n\nCreiamo una funzione per approssimare l’integrale sommando i prodotti \\(\\Delta x \\cdot f(x)\\):\n\nintegral_approximation &lt;- function(f, a, b, n) {\n  delta &lt;- (b - a) / n\n  sum(delta * f)\n}\n\n# Calcolo dell'integrale approssimato\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9999\n\n\nConfrontiamo il risultato con il calcolo fornito dalla funzione integrate di R:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n1 with absolute error &lt; 7.4e-05\n\n\nCalcoliamo l’area sotto la curva in intervalli di interesse. Ad esempio, per \\([-1.96, 1.96]\\), che corrisponde al 95% dell’area nella distribuzione normale standard:\n\na &lt;- -1.96\nb &lt;- 1.96\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9499321\n\n\nConfrontiamo con il risultato fornito da integrate():\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.9500042 with absolute error &lt; 1e-11\n\n\nVerifichiamo l’area sotto la curva per \\([-1, 1]\\), che rappresenta circa il 68% dell’area totale:\n\na &lt;- -1.0\nb &lt;- 1.0\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.6826696\n\n\nConfronto:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.6826895 with absolute error &lt; 7.6e-15\n\n\nIn sintesi, questo approccio dimostra come calcolare l’integrale di una funzione di densità in un intervallo utilizzando sia un metodo approssimativo basato sulla somma dei rettangoli sia il metodo numerico integrato. In entrambi i casi, l’obiettivo è calcolare l’area sotto la curva, che corrisponde all’integrale della funzione di densità.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#potenze",
    "href": "chapters/appendix/a15_calculus.html#potenze",
    "title": "87  Per liberarvi dai terrori preliminari",
    "section": "\n87.2 Potenze",
    "text": "87.2 Potenze\nLe potenze sono un’operazione matematica che rappresenta un prodotto ripetuto. Si indicano generalmente come:\n\\[\na^n,\n\\]\ndove:\n\n\n\\(a\\) è la base,\n\n\\(n\\) è l’esponente.\n\nLa potenza rappresenta il prodotto della base \\(a\\) ripetuto \\(n\\) volte.\n\n87.2.1 Definizione di potenza\n\\[\na^n = \\underbrace{a \\cdot a \\cdot \\dots \\cdot a}_{n \\text{ fattori}} \\quad \\text{con } n \\in \\mathbb{N}.\n\\]\nAd esempio:\n\n\n\\(2^3 = 2 \\cdot 2 \\cdot 2 = 8\\),\n\n\\(3^4 = 3 \\cdot 3 \\cdot 3 \\cdot 3 = 81\\).\n\n\n87.2.2 Proprietà delle potenze\n\n\nMoltiplicazione di potenze con la stessa base:\n\\[\na^m \\cdot a^n = a^{m+n}\n\\]\nEsempio: \\(2^3 \\cdot 2^2 = 2^{3+2} = 2^5 = 32\\).\n\n\nDivisione di potenze con la stessa base:\n\\[\n\\frac{a^m}{a^n} = a^{m-n}, \\quad \\text{con } m \\geq n.\n\\]\nEsempio: \\(\\frac{5^4}{5^2} = 5^{4-2} = 5^2 = 25\\).\n\n\nPotenze di potenze:\n\\[\n(a^m)^n = a^{m \\cdot n}.\n\\]\nEsempio: \\((3^2)^3 = 3^{2 \\cdot 3} = 3^6 = 729\\).\n\n\nProdotto di potenze con basi diverse ma lo stesso esponente:\n\\[\na^n \\cdot b^n = (a \\cdot b)^n.\n\\]\nEsempio: \\(2^3 \\cdot 3^3 = (2 \\cdot 3)^3 = 6^3 = 216\\).\n\n\nDivisione di potenze con basi diverse ma lo stesso esponente:\n\\[\n\\frac{a^n}{b^n} = \\left(\\frac{a}{b}\\right)^n.\n\\]\nEsempio: \\(\\frac{4^2}{2^2} = \\left(\\frac{4}{2}\\right)^2 = 2^2 = 4\\).\n\n\nEsponente zero:\n\\[\na^0 = 1, \\quad \\text{con } a \\neq 0.\n\\]\nEsempio: \\(5^0 = 1\\).\n\n\nEsponente negativo:\n\\[\na^{-n} = \\frac{1}{a^n}.\n\\]\nEsempio: \\(2^{-3} = \\frac{1}{2^3} = \\frac{1}{8}\\).\n\n\nRadice come potenza frazionaria:\n\\[\na^{\\frac{1}{n}} = \\sqrt[n]{a}, \\quad a^{\\frac{m}{n}} = \\sqrt[n]{a^m}.\n\\]\nEsempio: \\(8^{\\frac{1}{3}} = \\sqrt[3]{8} = 2\\).\n\n\n\n87.2.3 Esempi pratici\n\n\nCalcolo semplice:\n\\[\n4^3 = 4 \\cdot 4 \\cdot 4 = 64.\n\\]\n\n\nUtilizzo delle proprietà:\n\\[\n3^5 \\cdot 3^2 = 3^{5+2} = 3^7 = 2187.\n\\]\n\n\nDivisione:\n\\[\n\\frac{6^4}{6^2} = 6^{4-2} = 6^2 = 36.\n\\]\n\n\nEsponente negativo:\n\\[\n10^{-2} = \\frac{1}{10^2} = \\frac{1}{100} = 0.01.\n\\]\n\n\nRadice come potenza:\n\\[\n16^{\\frac{1}{2}} = \\sqrt{16} = 4.\n\\]\n\n\n\n87.2.4 Nota sui numeri razionali e reali\n\nLe potenze con esponenti interi sono definite per ogni base.\nLe potenze con esponenti frazionari o reali richiedono che la base sia positiva per evitare ambiguità.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#logaritmi",
    "href": "chapters/appendix/a15_calculus.html#logaritmi",
    "title": "87  Per liberarvi dai terrori preliminari",
    "section": "\n87.3 Logaritmi",
    "text": "87.3 Logaritmi\nIl logaritmo è una funzione matematica che risponde alla domanda: “quante volte devo moltiplicare un certo numero (chiamato”base”) per ottenere un altro numero?” Matematicamente, questo è espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perché \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano più grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo è utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio:\n\n\\(\\log(1) = 0\\)\n\\(\\log(0.1) = -1\\)\n\\(\\log(0.01) = -2\\)\n\\(\\log(0.001) = -3\\)\n\nCome si può vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle proprietà più utili dei logaritmi è che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta proprietà è estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilità potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn’altra proprietà utile dei logaritmi è che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa proprietà è molto utilizzata in matematica, specialmente in situazioni in cui è necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare più agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli più gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html",
    "href": "chapters/appendix/a50_lin_fun.html",
    "title": "Appendice H — La funzione lineare",
    "section": "",
    "text": "H.1 Concetto di Funzione\nNello studio dei fenomeni naturali e nella risoluzione di problemi tecnici e matematici, è spesso necessario considerare la variazione di una grandezza come dipendente dalla variazione di un’altra. Ad esempio, nello studio del moto, il percorso compiuto da un oggetto può essere visto come una grandezza variabile in funzione del tempo: il cammino percorso è, dunque, una funzione del tempo.\nQuesta considerazione ci conduce alla seguente definizione:\nSe a ogni valore della variabile \\(x\\) (all’interno di un certo intervallo) corrisponde un valore ben definito di un’altra variabile \\(y\\), allora si dice che \\(y\\) è una funzione di \\(x\\). In notazione funzionale si scrive:\n\\[\ny = f(x) \\quad \\text{o anche} \\quad y = \\varphi(x).\n\\]\nLa variabile \\(x\\) è detta variabile indipendente o argomento della funzione. La relazione che lega \\(x\\) a \\(y\\) si chiama relazione funzionale. La lettera \\(f\\) nella notazione \\(y = f(x)\\) indica che per ottenere il valore di \\(y\\) a partire da \\(x\\) è necessario applicare una certa “regola” o “operazione”. In modo analogo, si possono utilizzare anche altre notazioni come \\(u = \\varphi(x)\\).\nLa notazione \\(y = C\\), dove \\(C\\) è una costante, indica una funzione il cui valore rimane invariato per qualunque valore di \\(x\\).\nL’insieme dei valori di \\(x\\) per cui la funzione \\(y = f(x)\\) è definita si chiama dominio di definizione della funzione.\nSe per valori crescenti della variabile indipendente \\(x\\) anche il valore della funzione \\(y = f(x)\\) aumenta, allora la funzione si dice crescente. Analogamente, se a valori crescenti di \\(x\\) corrispondono valori decrescenti della funzione \\(y = f(x)\\), la funzione si dice decrescente.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html#la-retta",
    "href": "chapters/appendix/a50_lin_fun.html#la-retta",
    "title": "Appendice H — La funzione lineare",
    "section": "H.2 La Retta",
    "text": "H.2 La Retta\nLa funzione lineare è definita come:\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono costanti. Il grafico di tale funzione è una retta. Qui, \\(b\\) è detto coefficiente angolare, mentre \\(a\\) è l’intercetta con l’asse delle \\(y\\). In altri termini, la retta interseca l’asse \\(y\\) nel punto \\((0, a)\\).\nPer comprendere il ruolo di \\(a\\) e \\(b\\), consideriamo prima il caso particolare:\n\\[\ny = b x.\n\\]\nQuesta espressione rappresenta una proporzionalità diretta tra \\(x\\) e \\(y\\): al crescere di \\(x\\), \\(y\\) varia in proporzione. Nel caso generale:\n\\[\ny = a + b x,\n\\]\nil termine \\(a\\) “trasla” verticalmente il grafico, aggiungendo una costante a ogni valore \\(b x\\).\nIl segno del coefficiente \\(b\\) determina il comportamento della funzione lineare:\n\nSe \\(b &gt; 0\\), il valore di \\(y\\) aumenta all’aumentare di \\(x\\).\n\nSe \\(b &lt; 0\\), il valore di \\(y\\) diminuisce all’aumentare di \\(x\\).\n\nSe \\(b = 0\\), il grafico è una retta orizzontale e \\(y\\) rimane costante.\n\nPossiamo dare un’interpretazione geometrica ancora più intuitiva se consideriamo variazioni (incrementi) di \\(x\\). Preso un punto \\(x_0\\) e aggiungendo un piccolo incremento \\(\\varepsilon\\), definiamo:\n\\[\n\\Delta x = (x_0 + \\varepsilon) - x_0 = \\varepsilon,\n\\] \\[\n\\Delta y = f(x_0 + \\varepsilon) - f(x_0).\n\\]\nIl coefficiente angolare \\(b\\) può essere interpretato come il rapporto tra la variazione di \\(y\\) e la variazione di \\(x\\):\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0}.\n\\]\nQuesto rapporto è costante e non dipende dalla scelta di \\(x_0\\) o di \\(\\varepsilon\\). In particolare, se scegliamo \\(\\Delta x = 1\\), il coefficiente angolare \\(b\\) rappresenta semplicemente di quanto varia \\(y\\) quando \\(x\\) aumenta di un’unità.\n\n\n\n\n\n\n\nFigura H.1: La funzione lineare \\(y = a + bx\\).\n\n\n\nCome mostrato in figura, il coefficiente \\(b\\) indica la pendenza della retta, ossia quanto “ripida” è la sua inclinazione rispetto all’asse orizzontale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a71_install_cmdstan.html",
    "href": "chapters/appendix/a71_install_cmdstan.html",
    "title": "Appendice I — Come installare CmdStan",
    "section": "",
    "text": "I.1 Windows\nSu macOS e Linux, questa configurazione dovrebbe essere già pronta di default.\nSu Windows è necessario installare RTools e configurare PATH:\nProblemi comuni:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Come installare CmdStan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a71_install_cmdstan.html#windows",
    "href": "chapters/appendix/a71_install_cmdstan.html#windows",
    "title": "Appendice I — Come installare CmdStan",
    "section": "",
    "text": "Installazione di RTools:\n\nVai su https://cran.r-project.org/bin/windows/Rtools/\nScarica la versione di RTools compatibile con la tua versione di R (Generalmente, RTools 4.3 per R 4.3.x, RTools 4.2 per R 4.2.x, etc.)\nEsegui l’installer scaricato\nIMPORTANTE: Durante l’installazione, seleziona la casella “Add rtools to system PATH”\n\nVerifica dell’installazione e configurazione del PATH:\n\nApri PowerShell o Command Prompt\nVerifica se RTools è nel PATH digitando:\n\ngcc --version\nSe vedi la versione di gcc, RTools è nel PATH.\nSe RTools non è nel PATH, devi aggiungerlo manualmente:\n\nCerca “Impostazioni di Sistema” in Windows\nClicca su “Impostazioni di sistema avanzate”\nClicca su “Variabili d’ambiente”\nNella sezione “Variabili di sistema”, trova “Path”\nClicca “Modifica”\nClicca “Nuovo” e aggiungi questi percorsi (sostituisci X.X con la tua versione di RTools):\nC:\\rtools4X\\mingw64\\bin\nC:\\rtools4X\\usr\\bin\n\nVerifica finale:\n\nChiudi e riapri il terminale\nProva questi comandi:\n\ngcc --version\nmake --version\nSe entrambi i comandi mostrano le versioni, l’installazione è completa.\nTest in R:\n\nApri R o RStudio\nEsegui:\n\nSys.which(\"make\")\nDovrebbe mostrare il percorso di make.\n\n\n\nSe i comandi non vengono riconosciuti dopo aver aggiunto il PATH, prova a riavviare il computer.\nSe usi RStudio, potrebbe essere necessario riavviarlo dopo aver modificato il PATH.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Come installare CmdStan</span>"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Psicometria",
    "section": "License",
    "text": "License\n\nThis work is licensed under a Creative Commons Attribution 4.0 International License. This means you are free to share and adapt the work for any purpose, including commercial use, provided you give appropriate credit, link to the license, and indicate any changes made.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Psicometria",
    "section": "Citation",
    "text": "Citation\nTo cite this work, please use the following format:\nCaudek, C. (2025). Dispensa di Psicometria per l’AA 2024-2025. Università degli Studi di Firenze.\nBibTeX citation:\n@misc{caudek2025psicometria,\n  author = {Caudek, Corrado},\n  title = {Dispensa di Psicometria per l'AA 2024-2025},\n  year = {2025},\n  howpublished = {Università degli Studi di Firenze},\n  url = {https://ccaudek.github.io/psicometria-r/}\n}",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#esercizi",
    "href": "chapters/bayesian_inference/01_uncertainty.html#esercizi",
    "title": "40  Abbracciare l’incertezza",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nChe cosa significa “abbracciare l’incertezza” nel contesto della statistica bayesiana e perché è particolarmente rilevante nella ricerca psicologica?\nQuali sono le tre principali categorie di incertezza nella ricerca psicologica e come si differenziano tra loro?\nIn che modo l’approccio bayesiano consente di affrontare l’incertezza in modo sistematico e rigoroso?\nQual è il ruolo della soggettività nell’incertezza secondo l’approccio bayesiano, e perché questo è particolarmente rilevante in psicologia?\nQuali sono alcuni dei principali vantaggi dell’incertezza nella ricerca psicologica e come può essere utilizzata per migliorare la qualità della scienza? Consegna: Rispondi con parole tue e carica il file .qmd, convertito in PDF su Moodle.\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nAbbracciare l’incertezza nella statistica bayesiana significa riconoscerla come una parte inevitabile della ricerca e trattarla in modo esplicito e formale, anziché ignorarla o minimizzarla. Nella ricerca psicologica, l’incertezza è centrale perché si studiano fenomeni complessi e difficili da misurare, come emozioni e processi cognitivi. L’approccio bayesiano consente di quantificare e aggiornare l’incertezza in modo sistematico, offrendo un metodo più realistico per interpretare i dati e formulare inferenze.\nLe tre principali categorie di incertezza sono:\n\nIncertezza aleatoria: è intrinseca alla natura casuale di un fenomeno e non può essere eliminata (es. variabilità nelle risposte di un individuo a uno stesso stimolo).\n\nIncertezza epistemica: deriva da una conoscenza incompleta del fenomeno studiato e può essere ridotta con migliori modelli e raccolta di dati (es. omissione di variabili importanti in un modello psicologico).\n\nIncertezza ontologica: si riferisce a variabili o aspetti del sistema ancora sconosciuti (es. fattori di rischio per disturbi mentali non ancora identificati).\n\nL’approccio bayesiano affronta l’incertezza attraverso quattro fasi fondamentali: (1) definizione delle credenze iniziali (prior), (2) valutazione delle nuove evidenze (likelihood), (3) aggiornamento delle credenze (posterior), e (4) utilizzo delle credenze aggiornate per prendere decisioni più informate. Questo processo consente di integrare sistematicamente nuove informazioni e di migliorare continuamente la comprensione di un fenomeno.\nSecondo De Finetti, l’incertezza ha una componente soggettiva, poiché le credenze degli individui influenzano il modo in cui interpretano i dati. Due ricercatori con esperienze diverse possono avere livelli di incertezza differenti riguardo allo stesso fenomeno. In psicologia, questa soggettività è particolarmente rilevante perché le percezioni e le interpretazioni dei fenomeni sono spesso influenzate da differenze individuali e culturali. L’approccio bayesiano permette di quantificare e aggiornare queste credenze in modo formale e trasparente.\nL’incertezza offre diversi vantaggi nella ricerca psicologica:\n\nStimola l’esplorazione scientifica, incoraggiando nuove ipotesi e metodi.\n\nPromuove l’onestà intellettuale, rendendo i ricercatori più cauti e aperti a spiegazioni alternative.\n\nMigliora la qualità delle analisi, portando a modelli più robusti e interpretazioni più accurate.\n\nFacilita la collaborazione interdisciplinare, spingendo a integrare competenze diverse.\nRiflette meglio la complessità della psicologia, permettendo una rappresentazione più realistica dei fenomeni studiati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_statistical_models.html#esercizi",
    "href": "chapters/bayesian_inference/02_statistical_models.html#esercizi",
    "title": "42  Modelli statistici",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQual è il processo concettuale alla base della modellizzazione e dell’analisi statistica?\nCosa significa che un campione è indipendente e identicamente distribuito (iid) e perché questa assunzione è importante nei modelli statistici?\nCome si differenziano i modelli di campionamento da una singola distribuzione rispetto ai modelli di campioni multipli indipendenti?\nQual è la differenza tra regressione lineare semplice e regressione lineare multipla?\nIn che modo i modelli computazionali, come il modello di apprendimento associativo e il modello drift-diffusion, si differenziano dai modelli statistici tradizionali?\n\nConsegna: Rispondi con parole tue e carica il file .qmd, convertito in PDF su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nIl processo concettuale della modellizzazione e analisi statistica inizia con un problema reale e i dati raccolti su tale problema. Si costruisce quindi un modello probabilistico che rappresenta le conoscenze disponibili e il modo in cui i dati sono stati ottenuti. L’analisi viene condotta all’interno del modello, producendo conclusioni sui suoi parametri. Infine, i risultati vengono tradotti in inferenze sulla realtà, con lo scopo di migliorare la comprensione del fenomeno studiato.\nUn campione è detto indipendente e identicamente distribuito (iid) se le osservazioni sono indipendenti tra loro e seguono la stessa distribuzione di probabilità. Questa assunzione è fondamentale perché semplifica le analisi statistiche e permette di applicare risultati teorici importanti, come la legge dei grandi numeri e il teorema del limite centrale.\nNei modelli di campionamento da una singola distribuzione, si assume che tutte le osservazioni provengano da una stessa popolazione e seguano la stessa distribuzione. Nei modelli di campioni multipli indipendenti, invece, si confrontano più gruppi distinti, ciascuno con la propria distribuzione, per studiare differenze tra le popolazioni. Un esempio è il confronto tra altezze di individui con madri fumatrici e non fumatrici.\nLa regressione lineare semplice analizza la relazione tra una variabile dipendente e una sola variabile indipendente attraverso una relazione lineare. La regressione lineare multipla, invece, estende questo concetto a più variabili indipendenti, permettendo di modellare fenomeni più complessi e controllare l’effetto di più fattori simultaneamente.\nI modelli computazionali, come il modello di apprendimento associativo e il modello drift-diffusion, differiscono dai modelli statistici tradizionali perché mirano a simulare i processi mentali e decisionali sottostanti il comportamento umano. I modelli statistici descrivono principalmente relazioni tra variabili nei dati osservati, mentre i modelli computazionali cercano di rappresentare dinamicamente i meccanismi cognitivi e comportamentali che generano tali dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_bayesian_inference.html#esercizi",
    "href": "chapters/bayesian_inference/03_bayesian_inference.html#esercizi",
    "title": "43  Inferenza bayesiana",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQual è la differenza principale tra l’approccio bayesiano e l’approccio frequentista all’inferenza statistica?\nCosa rappresenta la distribuzione a priori in inferenza bayesiana e quale ruolo svolge nel processo inferenziale?\nCome si calcola la distribuzione a posteriori in inferenza bayesiana e quali sono i suoi elementi principali?\nQual è il significato della funzione di verosimiglianza nel teorema di Bayes?\nCome viene interpretata la probabilità nell’approccio bayesiano rispetto a quello frequentista?\nQuali sono i vantaggi principali dell’inferenza bayesiana rispetto all’inferenza frequentista?\nCos’è una distribuzione a priori coniugata e quali vantaggi offre nel calcolo della distribuzione a posteriori?\nQuali sono i principali metodi numerici utilizzati per approssimare la distribuzione a posteriori quando i calcoli analitici non sono possibili?\nCosa sono i modelli generativi dei dati e quale ruolo svolgono nell’inferenza bayesiana?\nQuali sono le tre principali giustificazioni teoriche per l’uso delle probabilità come misura di credenza nell’inferenza bayesiana?\n\nConsegna: Rispondi con parole tue e carica il file .qmd, convertito in PDF su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nLa differenza principale tra l’approccio bayesiano e quello frequentista riguarda l’interpretazione del parametro \\(\\theta\\). Nell’approccio bayesiano, il parametro è considerato una variabile aleatoria con una distribuzione a priori, mentre nell’approccio frequentista il parametro è una quantità fissa e sconosciuta. Inoltre, l’inferenza bayesiana aggiorna le credenze attraverso il teorema di Bayes, mentre l’inferenza frequentista basa le proprie conclusioni solo sui dati osservati.\nLa distribuzione a priori rappresenta le credenze iniziali riguardo al parametro \\(\\theta\\) prima di osservare i dati. Essa consente di integrare informazioni pregresse o conoscenze esterne nel processo inferenziale, influenzando la distribuzione a posteriori e permettendo di aggiornare le credenze alla luce di nuove evidenze.\n\nLa distribuzione a posteriori si calcola applicando il teorema di Bayes:\n\\[\nf(\\theta \\mid x) = \\frac{f(x \\mid \\theta) f(\\theta)}{f(x)}\n\\]\nI suoi elementi principali sono:\n\nLa funzione di verosimiglianza \\(f(x \\mid \\theta)\\), che esprime la probabilità di osservare i dati dato un valore del parametro.\n\nLa distribuzione a priori \\(f(\\theta)\\), che rappresenta le credenze iniziali sul parametro.\n\nLa costante di normalizzazione \\(f(x)\\), che garantisce che la distribuzione a posteriori sia una distribuzione di probabilità valida.\n\n\nLa funzione di verosimiglianza, \\(f(x \\mid \\theta)\\), rappresenta la probabilità di osservare i dati dati i valori del parametro \\(\\theta\\). Essa è fondamentale nel teorema di Bayes perché determina quanto bene un certo valore di \\(\\theta\\) spiega i dati osservati, contribuendo alla determinazione della distribuzione a posteriori.\nNell’approccio bayesiano, la probabilità è interpretata come un grado di credenza soggettivo su un evento o un parametro incerto. Nell’approccio frequentista, invece, la probabilità è definita come il limite della frequenza relativa di un evento dopo un numero infinito di ripetizioni. Questo porta a differenze metodologiche nel modo in cui vengono effettuate le inferenze.\n\nI principali vantaggi dell’inferenza bayesiana sono:\n\n\nIntegrazione di informazioni pregresse: Permette di combinare dati osservati con conoscenze precedenti.\n\n\nQuantificazione dell’incertezza: Fornisce una distribuzione completa dei parametri, anziché un singolo valore stimato.\n\n\nFlessibilità: Può essere applicata a modelli complessi e a problemi con pochi dati.\n\n\nInterpretazione intuitiva: Le probabilità risultanti rappresentano direttamente il grado di credenza sui parametri.\n\n\nUna distribuzione a priori coniugata è una scelta specifica di distribuzione a priori che, quando combinata con una verosimiglianza di una certa famiglia, produce una distribuzione a posteriori della stessa famiglia. Ad esempio, una distribuzione Beta come prior per un parametro binomiale produce una distribuzione Beta come a posteriori. Questo semplifica enormemente i calcoli, poiché la distribuzione a posteriori può essere determinata in modo analitico senza necessità di metodi numerici complessi.\n\nQuando non è possibile calcolare la distribuzione a posteriori in modo analitico, si utilizzano metodi numerici come:\n\n\nMarkov Chain Monte Carlo (MCMC): Un insieme di algoritmi di campionamento (ad esempio, Metropolis-Hastings e Gibbs Sampling) che permette di stimare la distribuzione a posteriori generando campioni iterativi.\n\n\nInferenza Variazionale: Un metodo di approssimazione che ottimizza una distribuzione più semplice per avvicinarsi alla distribuzione a posteriori.\n\n\nApprossimazione di Laplace: Un’approssimazione basata sulla normalizzazione locale intorno al massimo a posteriori (MAP).\n\n\nUn modello generativo dei dati è una rappresentazione matematica del processo che ha generato i dati osservati. Esso definisce la relazione tra il parametro sconosciuto \\(\\theta\\) e i dati \\(\\mathbf{x}\\) attraverso una distribuzione di probabilità. Nell’inferenza bayesiana, il modello generativo aiuta a formulare la funzione di verosimiglianza e a inferire i parametri che meglio spiegano i dati.\nLe tre principali giustificazioni per l’uso delle probabilità come misura di credenza nell’inferenza bayesiana sono:\n\n\n\nArgomento della scommessa olandese (Dutch Book): Se i gradi di credenza non rispettano le regole della probabilità, si possono costruire scommesse che garantiscono una perdita certa, dimostrando che è irrazionale non seguire le leggi della probabilità.\n\n\nArgomento decisionistico: Per massimizzare l’utilità attesa nelle scelte razionali, i gradi di credenza devono seguire le regole della probabilità. Se non lo fanno, si possono prendere decisioni incoerenti o subottimali.\n\n\nArgomento epistemico: Le funzioni di probabilità minimizzano l’errore epistemico rispetto alla verità oggettiva, rendendole la struttura più razionale per rappresentare le credenze in condizioni di incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_grid_gauss.html#esercizi",
    "href": "chapters/bayesian_inference/05_grid_gauss.html#esercizi",
    "title": "45  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQuali sono i vantaggi dell’uso del metodo della griglia per il calcolo della distribuzione a posteriori? Quali sono le principali limitazioni di questo approccio?\nQual è il ruolo della funzione di verosimiglianza nell’inferenza bayesiana e come si combina con la distribuzione a priori per ottenere la distribuzione a posteriori?\nIn che modo l’uso di una distribuzione a priori informativa può influenzare l’inferenza bayesiana rispetto a una a priori uniforme? Fai riferimento a un esempio pratico.\nPerché in alcuni casi è preferibile lavorare con la log-verosimiglianza anziché con la verosimiglianza stessa? Spiega i vantaggi di questa trasformazione.\nQual è il significato del campionamento dalla distribuzione a posteriori e perché è utile in un’analisi bayesiana? Quali sono alcuni metodi alternativi per ottenere campioni dalla posterior quando il metodo della griglia non è praticabile?\nUtilizzando i dati della Satisfaction With Life Scale (SWLS) raccolti dagli studenti, costruisci un modello bayesiano per stimare la media della soddisfazione di vita. Segui questi passaggi:\n\n\n\nCarica i dati della SWLS e visualizza la distribuzione delle risposte.\n\n\nDefinisci una griglia di valori possibili per la media della soddisfazione di vita (ad esempio, da 1 a 7 se il punteggio della SWLS è su una scala Likert 1-7).\n\n\nAssumi che la deviazione standard sia nota (puoi stimarla dai dati o usare un valore ragionevole, come 1).\n\n\nCalcola la funzione di verosimiglianza per ogni valore della griglia assumendo una distribuzione normale.\n\n\nImposta una distribuzione a priori (uniforme o gaussiana centrata su un valore atteso, ad esempio 4).\n\n\nCalcola la distribuzione a posteriori e normalizzala.\n\n\nVisualizza la distribuzione a posteriori della media della soddisfazione di vita.\n\n\nEstrai campioni dalla distribuzione a posteriori e calcola un intervallo di credibilità al 94%.\n\nEsegui il codice in R e commenta i risultati ottenuti.\nConsegna: carica il file .qmd con le risposte, convertito in PDF, su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nIl metodo della griglia ha il vantaggio di essere intuitivo e facilmente implementabile, poiché calcola direttamente la distribuzione a posteriori valutando la funzione di verosimiglianza e il prior su una griglia di valori possibili per il parametro di interesse. Questo approccio permette una visualizzazione chiara della distribuzione a posteriori e facilita il confronto tra diversi prior.\nTuttavia, presenta alcune limitazioni:\n\n\nScalabilità: Diventa impraticabile quando il numero di parametri cresce, poiché il numero di combinazioni nella griglia aumenta esponenzialmente.\n\n\nRisoluzione: La precisione dell’inferenza dipende dalla densità della griglia, e una griglia troppo fine può essere computazionalmente costosa.\n\n\nDifficoltà per modelli complessi: Non è adatto per modelli con parametri ad alta dimensionalità o con distribuzioni a posteriori complesse.\n\n\n\nLa funzione di verosimiglianza rappresenta la probabilità di osservare i dati dati i valori del parametro di interesse. Nell’inferenza bayesiana, questa informazione viene combinata con la distribuzione a priori attraverso il teorema di Bayes, che permette di aggiornare la conoscenza pregressa con le nuove osservazioni.\nMatematicamente, la distribuzione a posteriori è data da:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) p(\\theta)}{p(D)}\n\\]\ndove:\n\n\n\\(p(D \\mid \\theta)\\) è la verosimiglianza, che misura quanto bene il parametro \\(\\theta\\) spiega i dati \\(D\\).\n\n\n\\(p(\\theta)\\) è il prior, che rappresenta la conoscenza iniziale sul parametro.\n\n\n\\(p(D)\\) è la costante di normalizzazione.\n\nL’aggiornamento bayesiano consente di affinare le stime dei parametri alla luce di nuove evidenze in modo sistematico e coerente.\n\n\nL’uso di un prior informativo consente di incorporare conoscenze pregresse nella stima dei parametri, riducendo l’incertezza quando i dati sono scarsi. Tuttavia, se il prior è troppo forte rispetto ai dati, potrebbe dominare la distribuzione a posteriori e introdurre un bias nelle stime.\nEsempio pratico: Supponiamo di voler stimare il QI medio di una popolazione sulla base di un piccolo campione. Se usiamo un prior informativo centrato su 140 con una deviazione standard di 3, la distribuzione a posteriori sarà fortemente influenzata da questa assunzione. Se invece utilizziamo un prior uniforme, i dati avranno un impatto maggiore sulla stima a posteriori.\nIn generale, i prior informativi sono utili quando abbiamo conoscenze affidabili da incorporare, mentre i prior non informativi sono preferibili quando vogliamo lasciare che i dati guidino l’inferenza.\n\n\nLavorare con la log-verosimiglianza presenta diversi vantaggi:\n\n\nStabilità numerica: La moltiplicazione di molte probabilità può portare a valori molto piccoli che causano underflow numerico. Usare il logaritmo trasforma i prodotti in somme, evitando questi problemi.\n\n\nEfficienza computazionale: Le somme sono più efficienti da calcolare rispetto ai prodotti, specialmente per modelli con molti dati.\n\n\nInterpretabilità: La log-verosimiglianza fornisce una misura più chiara della bontà di adattamento del modello, poiché la somma dei log-likelihood è direttamente proporzionale alla probabilità complessiva dei dati dato il parametro.\n\nPer questi motivi, la log-verosimiglianza è ampiamente usata in applicazioni statistiche e machine learning.\n\n\nIl campionamento dalla distribuzione a posteriori permette di ottenere stime dei parametri e di quantificare l’incertezza in modo efficace. Poiché la posterior rappresenta la nostra credenza aggiornata sul parametro dopo aver osservato i dati, il campionamento consente di generare simulazioni di possibili valori di \\(\\theta\\).\nUtilità del campionamento:\n\nPermette di calcolare intervalli di credibilità.\n\nConsente di effettuare inferenze basate sulla distribuzione completa, anziché su un singolo valore puntuale.\n\nÈ utile per simulare previsioni e testare ipotesi.\n\nMetodi alternativi per il campionamento dalla posterior:\n\n\nMetropolis-Hastings (MCMC): Un algoritmo di Markov Chain Monte Carlo che permette di esplorare distribuzioni complesse.\n\n\nGibbs Sampling: Un metodo MCMC particolarmente utile per modelli con più parametri condizionali noti.\n\n\nHamiltonian Monte Carlo (HMC): Utilizza gradienti per esplorare lo spazio dei parametri in modo efficiente, come implementato in Stan.\n\nQuando il metodo della griglia non è praticabile, questi metodi consentono di stimare la posterior in modo efficiente anche per modelli complessi e ad alta dimensionalità.\n\nEcco un codice in R che segue i passaggi richiesti.\n\n# Caricamento librerie necessarie\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tibble)\n\n# Dati SWLS\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n\n# Usando la deviazione standard campionaria\nsigma_conosciuta &lt;- sd(swls_data$soddisfazione)  \nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\n\ncat(\"Deviazione standard campionaria:\", sigma_conosciuta, \"\\n\")\ncat(\"Media campionaria:\", mean_x, \"\\n\")\n\n# Definizione della griglia più fine e centrata intorno alla media campionaria\nmu_griglia &lt;- seq(mean_x - 3*sigma_conosciuta/sqrt(n), \n                 mean_x + 3*sigma_conosciuta/sqrt(n), \n                 length.out = 1000)\n\n# Calcolo della verosimiglianza\nlog_likelihood &lt;- numeric(length(mu_griglia))\nfor (i in seq_along(mu_griglia)) {\n  # Utilizzo della log-likelihood per evitare problemi numerici\n  log_likelihood[i] &lt;- sum(dnorm(swls_data$soddisfazione, \n                                mean = mu_griglia[i], \n                                sd = sigma_conosciuta, \n                                log = TRUE))\n}\n\n# Prior uniforme (in scala logaritmica)\nlog_prior &lt;- rep(0, length(mu_griglia))\n\n# Calcolo della posteriori\nlog_posterior &lt;- log_likelihood + log_prior\nposterior &lt;- exp(log_posterior - max(log_posterior))\nposterior &lt;- posterior / sum(posterior)\n\n# Campionamento e calcolo statistiche\nsamples_grid &lt;- sample(mu_griglia, size = 10000, replace = TRUE, prob = posterior)\nmean_post_grid &lt;- mean(samples_grid)\nsd_post_grid &lt;- sd(samples_grid)\nci_grid &lt;- quantile(samples_grid, c(0.03, 0.97))\n\nresults &lt;- tibble(\n  `Media Posteriori` = c(mean_post_grid),\n  `Dev. Std. Posteriori` = c(sd_post_grid)\n)\n\n# Visualizzazione risultati\nprint(results)\n\n# Plot della distribuzione a posteriori per entrambi i metodi\nggplot() +\n  geom_line(data = data.frame(mu = mu_griglia, density = posterior),\n            aes(x = mu, y = density, color = \"Griglia\")) +\n  labs(title = \"Distribuzione a Posteriori\",\n       x = \"Media\", y = \"Densità\")\n  \n# Stampa intervallo di credibilità al 94%\ncat(\"\\nIntervallo di credibilità al 94% (metodo griglia):\\n\")\nprint(ci_grid)\nConclusione:\nIl modello bayesiano ci fornisce una stima della media della soddisfazione di vita con un intervallo di credibilità, quantificando l’incertezza in modo rigoroso.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_2.html#esercizi",
    "href": "chapters/bayesian_inference/07_conjugate_families_2.html#esercizi",
    "title": "47  Distribuzioni coniugate (2)",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nRiprendi i dati della SWLS che sono stati utilizzati nell’esercizio del Capitolo 45. Trova la media e la deviazione standard della distribuzione a posteriori usando il metodo delle distribuzioni coniugate. Confronta i risultati con quelli ottenuti con il metodo basato su griglia.\nConsegna: Carica il file .qmd, convertito in PDF, su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nPer risolvere questo esercizio con il metodo delle distribuzioni coniugate, assumiamo che i dati provengano da una distribuzione normale con deviazione standard nota e media da stimare. Nel caso di una verosimiglianza gaussiana con prior gaussiano, la distribuzione a posteriori sarà ancora una distribuzione normale. Questo approccio è analitico e ci permette di ottenere la media e la deviazione standard della distribuzione a posteriori senza dover ricorrere a metodi numerici come la discretizzazione della griglia.\nPassaggi per il calcolo della distribuzione a posteriori\n\n\nDefiniamo i dati osservati:\n\nLa media campionaria: \\(\\bar{x}\\)\n\nLa deviazione standard nota dei dati: \\(\\sigma\\)\n\nIl numero di osservazioni: \\(n\\)\n\n\n\n\nScegliamo un prior gaussiano molto diffuso:\n\nMedia a priori: \\(\\mu_0\\)\n\nDeviazione standard a priori molto grande: \\(\\sigma_0\\)\n\n\n\n\nCalcoliamo la media e la varianza della distribuzione a posteriori:\n\n\nLa media a posteriori è:\n\\[\n\\mu_{\\text{post}} = \\frac{\\sigma^2_0 \\bar{x} + \\sigma^2 n \\mu_0}{\\sigma^2_0 + \\sigma^2 n}\n\\]\n\n\nLa varianza a posteriori è:\n\\[\n\\sigma^2_{\\text{post}} = \\frac{\\sigma^2_0 \\sigma^2}{\\sigma^2_0 + \\sigma^2 n}\n\\]\n\n\n\n\nImplementazione in R\n# Caricamento librerie necessarie\nlibrary(dplyr)\nlibrary(tibble)\n\n# Dati SWLS\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n\n# Parametri comuni per entrambi i metodi\nsigma_conosciuta &lt;- sd(swls_data$soddisfazione)  # Usando la deviazione standard campionaria\nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\n\ncat(\"Deviazione standard campionaria:\", sigma_conosciuta, \"\\n\")\ncat(\"Media campionaria:\", mean_x, \"\\n\")\n\n# ---- Metodo 1: Griglia ----\n# Definizione della griglia più fine e centrata intorno alla media campionaria\nmu_griglia &lt;- seq(mean_x - 3*sigma_conosciuta/sqrt(n), \n                 mean_x + 3*sigma_conosciuta/sqrt(n), \n                 length.out = 1000)\n\n# Calcolo della verosimiglianza\nlog_likelihood &lt;- numeric(length(mu_griglia))\nfor (i in seq_along(mu_griglia)) {\n  # Utilizzo della log-likelihood per evitare problemi numerici\n  log_likelihood[i] &lt;- sum(dnorm(swls_data$soddisfazione, \n                                mean = mu_griglia[i], \n                                sd = sigma_conosciuta, \n                                log = TRUE))\n}\n\n# Prior uniforme (in scala logaritmica)\nlog_prior &lt;- rep(0, length(mu_griglia))\n\n# Calcolo della posteriori\nlog_posterior &lt;- log_likelihood + log_prior\nposterior &lt;- exp(log_posterior - max(log_posterior))\nposterior &lt;- posterior / sum(posterior)\n\n# Campionamento e calcolo statistiche\nsamples_grid &lt;- sample(mu_griglia, size = 10000, replace = TRUE, prob = posterior)\nmean_post_grid &lt;- mean(samples_grid)\nsd_post_grid &lt;- sd(samples_grid)\nci_grid &lt;- quantile(samples_grid, c(0.03, 0.97))\n\n# ---- Metodo 2: Soluzione analitica ----\n# Prior poco informativo ma non improprio\nmu_prior &lt;- mean_x\nsigma_prior &lt;- 10\n\n# Calcolo posteriori\nmu_post_analytic &lt;- (sigma_prior^2 * mean_x + sigma_conosciuta^2 * mu_prior/n) / \n                    (sigma_prior^2 + sigma_conosciuta^2/n)\nsigma_post_analytic &lt;- sqrt((sigma_prior^2 * sigma_conosciuta^2/n) / \n                           (sigma_prior^2 + sigma_conosciuta^2/n))\n\n# Confronto risultati\nresults &lt;- tibble(\n  Metodo = c(\"Griglia\", \"Analitico\"),\n  `Media Posteriori` = c(mean_post_grid, mu_post_analytic),\n  `Dev. Std. Posteriori` = c(sd_post_grid, sigma_post_analytic)\n)\nresults\nInterpretazione dei risultati\n\nLa media a posteriori rappresenta la miglior stima aggiornata della media della popolazione dopo aver osservato i dati.\nLa deviazione standard a posteriori ci dice quanto è incerta la nostra stima della media dopo aver integrato i dati e il prior.\n\nSiccome abbiamo scelto un prior molto diffuso (\\(\\sigma_0 = 10\\)), il risultato ottenuto è molto vicino a quello ottenuto con il metodo della griglia, dove il prior uniforme aveva un impatto minimo sulla distribuzione a posteriori.\nQuesta implementazione analitica permette di ottenere il risultato in modo efficiente senza necessità di metodi numerici approssimati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_summary_posterior.html#esercizi",
    "href": "chapters/bayesian_inference/08_summary_posterior.html#esercizi",
    "title": "48  Sintesi a posteriori",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?\n\nSpiega le differenze tra moda (MAP), media a posteriori e mediana.\nIn quali contesti è preferibile utilizzare una di queste statistiche rispetto alle altre?\n\n2. Qual è la differenza tra un intervallo di credibilità bayesiano e un intervallo di confidenza frequentista?\n\nSpiega le differenze concettuali tra i due approcci.\nQuale dei due è più intuitivo in termini di incertezza sui parametri?\n\n3. Cos’è un intervallo di massima densità posteriore (HPD) e in cosa si differenzia dall’intervallo di credibilità simmetrico?\n\nSpiega il concetto di HPD e perché è più informativo in alcuni casi.\nIn quali situazioni l’HPD è preferibile rispetto all’intervallo di credibilità simmetrico?\n\n4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?\n\nPerché il MAP può essere meno affidabile rispetto ad altre statistiche?\nQuali problemi si possono incontrare nei modelli bayesiani complessi?\n\n5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di più parametri incogniti?\n\nQuali sono le principali difficoltà nell’interpretare la distribuzione congiunta di più parametri?\nCome si possono visualizzare e sintetizzare distribuzioni posteriori multivariate?\n\n📌 Domande applicative in R\nPer queste domande, usa il dataset basato sulla Satisfaction with Life Scale (SWLS), supponendo che i dati seguano una distribuzione normale.\n1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa. - Usa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n2. Costruisci un intervallo di credibilità simmetrico al 94% per la media SWLS.\n\nUsa la distribuzione normale a posteriori per calcolare l’intervallo.\n\n3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densità.\n\nGenera un campione dalla distribuzione a posteriori e rappresentalo con ggplot2.\n\n4. Confronta l’intervallo di credibilità simmetrico con l’intervallo di massima densità posteriore (HPD).\n\nUsa la funzione hdi() del pacchetto bayestestR per calcolare l’HPD.\n\n5. Calcola la probabilità a posteriori che la media SWLS sia minore di 23.\n\nUsa la distribuzione a posteriori per calcolare questa probabilità.\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?\nLe tre principali statistiche usate per ottenere una stima puntuale del parametro \\(\\theta\\) nella distribuzione a posteriori sono:\n\n\nModa (Massimo a Posteriori, MAP)\n\nÈ il valore di \\(\\theta\\) che massimizza la distribuzione a posteriori \\(p(\\theta \\mid y)\\).\n\nSe la distribuzione è unimodale e simmetrica, il MAP coincide con la media a posteriori.\n\nIl MAP è spesso simile alla stima di massima verosimiglianza (MLE) quando il prior è uniforme.\n\n\n\nMedia a Posteriori\n\nÈ il valore atteso della distribuzione a posteriori:\\[\nE(\\theta \\mid y) = \\int \\theta \\, p(\\theta \\mid y) \\, d\\theta\n\\]\n\nÈ la stima più utile quando si vuole minimizzare l’errore quadratico medio (MSE).\n\nRisente dell’eventuale asimmetria della distribuzione, spostandosi verso le code.\n\n\n\nMediana a Posteriori\n\nÈ il valore che divide la distribuzione a posteriori in due parti uguali:\\[\nP(\\theta \\leq \\theta_{\\text{mediana}} \\mid y) = 0.5\n\\]\n\nÈ più robusta agli outlier rispetto alla media ed è utile quando la distribuzione è fortemente asimmetrica.\n\n\n\n💡 Quando usarle? - Se la distribuzione è simmetrica, tutte e tre le statistiche coincidono. - Se la distribuzione è asimmetrica, la mediana è più robusta, la media può essere influenzata dalle code e il MAP è utile se si vuole un valore più probabile.\n2. Qual è la differenza tra un intervallo di credibilità bayesiano e un intervallo di confidenza frequentista?\n\n\n\n\n\n\n\nCaratteristica\nIntervallo di Credibilità (Bayesiano)\nIntervallo di Confidenza (Frequentista)\n\n\n\nSignificato\nEsprime la probabilità che il parametro sia nell’intervallo, dati i dati osservati.\nÈ una proprietà di un metodo di campionamento: se si ripetesse l’esperimento infinite volte, il \\((1 - \\alpha)100\\%\\) degli intervalli conterrebbe il vero valore del parametro.\n\n\nApproccio\nAssume che il parametro sia una variabile casuale con una distribuzione di probabilità.\nAssume che il parametro sia fisso e sconosciuto, mentre i dati sono casuali.\n\n\nInterpretazione\n“C’è il 95% di probabilità che il parametro sia tra questi valori.”\n“Se ripetessimo l’esperimento molte volte, il 95% degli intervalli conterrebbe il vero parametro.”\n\n\n\n💡 Differenza fondamentale:\n\nL’intervallo di credibilità è probabilistico e più intuitivo: si può direttamente dire che il parametro ha il 95% di probabilità di trovarsi nell’intervallo.\n\nL’intervallo di confidenza è basato sulla ripetizione ipotetica dell’esperimento e non può essere interpretato in termini probabilistici sul singolo intervallo.\n\n3. Cos’è un intervallo di massima densità posteriore (HPD) e in cosa si differenzia dall’intervallo di credibilità simmetrico?\nL’intervallo di massima densità posteriore (HPD) è l’intervallo più stretto che contiene una percentuale fissata (es. 94%) della distribuzione a posteriori. Si distingue dall’intervallo di credibilità simmetrico perché:\n\n\n\n\n\n\n\nCaratteristica\nIntervallo HPD\nIntervallo di Credibilità Simmetrico\n\n\n\nDefinizione\nContiene il \\((1 - \\alpha)100\\%\\) della probabilità a posteriori, minimizzando la lunghezza dell’intervallo.\nÈ centrato attorno alla mediana e copre una frazione fissa della distribuzione.\n\n\nForma\nPuò essere asimmetrico e discontinuo se la distribuzione è multimodale.\nÈ sempre simmetrico.\n\n\nVantaggio\nÈ più informativo se la distribuzione è asimmetrica o multimodale.\nÈ più facile da calcolare, specialmente per distribuzioni unimodali.\n\n\n\n💡 Quando usarli?\n\nSe la distribuzione è simmetrica, entrambi gli intervalli danno risultati simili.\n\nSe la distribuzione è asimmetrica o multimodale, l’HPD è più informativo.\n\n4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?\nSebbene il MAP sia un concetto intuitivo (il valore più probabile della distribuzione a posteriori), presenta alcune limitazioni:\n\n\nDifficoltà computazionale con MCMC\n\nCon metodi di campionamento come Markov Chain Monte Carlo (MCMC), trovare il massimo della distribuzione a posteriori è difficile perché la funzione viene stimata in modo discreto.\nSpesso si preferisce stimare media o mediana, più facili da calcolare con MCMC.\n\n\n\nSensibilità ai dati e al prior\n\nIl MAP dipende fortemente dal prior scelto.\nSe il prior è informativo, il MAP può spostarsi troppo rispetto ai dati.\n\n\n\nProblemi con distribuzioni multimodali\n\nSe la distribuzione a posteriori ha più di un massimo (moda), il MAP potrebbe non essere una buona rappresentazione della distribuzione.\n\n\n\n💡 Quando evitarlo?\n- Se la distribuzione a posteriori è asimmetrica o multimodale. - Se si usa un metodo MCMC, dove la media o la mediana sono più semplici da stimare.\n5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di più parametri incogniti?\nQuando l’inferenza bayesiana coinvolge più parametri (es. \\(\\mu\\) e \\(\\sigma\\)), l’analisi diventa più complessa per diversi motivi:\n\n\nInterazioni tra parametri\n\nI parametri spesso non sono indipendenti: la distribuzione a posteriori congiunta può mostrare correlazioni che non emergono dalle distribuzioni marginali.\n\n\n\nDifficoltà di visualizzazione\n\nPer un parametro si usa un istogramma o una funzione di densità.\nPer due parametri si usa un contour plot o un grafico 3D.\nCon più di due parametri, si ricorre a pair plots o matrici di correlazione.\n\n\n\nStimare margine e congiunta\n\nLa distribuzione marginale di un parametro si ottiene integrando la distribuzione congiunta rispetto agli altri parametri: \\[\np(\\theta_1) = \\int p(\\theta_1, \\theta_2) d\\theta_2\n\\]\n\nSe i parametri sono fortemente correlati, le marginali possono nascondere informazioni importanti.\n\n\n\nRischio di correlazioni non lineari\n\nLe correlazioni non lineari tra i parametri possono portare a distribuzioni con forme complesse (es. a banana), rendendo difficile la sintesi con MAP o media.\n\n\n\n💡 Strategie per affrontare il problema:\n- Visualizzare le correlazioni tra i parametri con scatter plot o heatmap.\n- Usare tecniche di riduzione della dimensionalità come PCA (Analisi delle Componenti Principali).\n- Utilizzare il MCMC per campionare direttamente dalla distribuzione congiunta.\nEsercizio in R con i dati SWLS\nNell’esercizio, usa i dati della SWLS che sono stati raccolti. Qui useremo i dati seguenti:\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa.\n\nUsa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n\nlibrary(tibble)\n\n# Dati\nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\nsigma &lt;- 1  # Deviazione standard nota\n\n# Prior diffuso\nmu_prior &lt;- 4.5    \nsigma_prior &lt;- 10  \n\n# Media a posteriori\nmu_post &lt;- (sigma_prior^2 * mean_x + sigma^2 * n * mu_prior) / (sigma_prior^2 + sigma^2 * n)\n\n# Deviazione standard a posteriori\nsigma_post &lt;- sqrt((sigma_prior^2 * sigma^2) / (sigma_prior^2 + sigma^2 * n))\n\n# Moda (MAP)\nposterior_mode &lt;- mu_post  # Per una distribuzione normale, MAP coincide con la media\n\n# Mediana (simile alla media in una distribuzione normale)\nposterior_median &lt;- mu_post\n\ntibble(\"Media a Posteriori\" = mu_post,\n       \"Moda (MAP)\" = posterior_mode,\n       \"Mediana\" = posterior_median)\n2. Costruisci un intervallo di credibilità simmetrico al 94% per la media SWLS.\n\nUsa la distribuzione normale a posteriori per calcolare l’intervallo.\n\ncred_interval &lt;- qnorm(c(0.03, 0.97), mean = mu_post, sd = sigma_post)\ncred_interval\n3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densità.\n\nGenera un campione dalla distribuzione a posteriori e rappresentalo con ggplot2.\n\nlibrary(ggplot2)\n\n# Campionamento dalla distribuzione a posteriori\nset.seed(123)\nsamples &lt;- rnorm(1000, mean = mu_post, sd = sigma_post)\n\n# Creazione del dataframe\nsamples_df &lt;- tibble(media_campionata = samples)\n\n# Grafico della distribuzione a posteriori\nggplot(samples_df, aes(x = media_campionata)) +\n  geom_density(fill = \"blue\", alpha = 0.5) +\n  labs(title = \"Distribuzione a Posteriori della Media SWLS\",\n       x = \"Media\", y = \"Densità\")\n4. Confronta l’intervallo di credibilità simmetrico con l’intervallo di massima densità posteriore (HPD).\n\nUsa la funzione hdi() del pacchetto bayestestR per calcolare l’HPD.\n\nlibrary(bayestestR)\n\n# Calcolo intervallo HPD al 94%\nhpd_interval &lt;- hdi(samples, ci = 0.94)\nhpd_interval\n5. Calcola la probabilità a posteriori che la media SWLS sia minore di 23 – per fare un esempio, qui caloleremo per i dati simulati la probabilità a posteriori per la media SWLS maggiore di 4.7.\n\nUsa la distribuzione a posteriori per calcolare questa probabilità.\n\nprob_greater_4_7 &lt;- 1 - pnorm(4.7, mean = mu_post, sd = sigma_post)\nprob_greater_4_7",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html",
    "href": "chapters/appendix/a01_shell.html",
    "title": "Appendice A — La Shell",
    "section": "",
    "text": "A.1 Che cos’è una Shell?\nUna shell è un programma che riceve comandi dall’utente tramite tastiera (o da file) e li passa al sistema operativo per l’esecuzione. Può essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html#che-cosè-una-shell",
    "href": "chapters/appendix/a01_shell.html#che-cosè-una-shell",
    "title": "Appendice A — La Shell",
    "section": "",
    "text": "A.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\nA.1.2 Windows vs macOS/Linux\n\nWindows 10: È possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l’ambiente preferito è solitamente PowerShell.\nmacOS/Linux: Zsh è la shell predefinita in entrambi i sistemi. È consigliabile sfruttare l’applicazione warp per un’esperienza utente moderna e ottimizzata.\n\n\n\nA.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\nA.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\nA.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless / more: Visualizza il contenuto dei file con possibilità di navigazione.\ncat: Mostra l’intero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\nA.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l’utilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilità nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma più potente perché può rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\nA.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\nA.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilità di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l’intero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\nÈ cruciale familiarizzarsi con l’utilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L’impiego dei percorsi relativi rende il processo di navigazione più intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l’utilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: È importante evitare l’inserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, \\), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l’uso del trattino (-) può causare problemi; quindi è consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilità con alcuni sistemi operativi o applicazioni, rendendo più complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, è consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, è possibile ottimizzare notevolmente l’organizzazione e la gestione dei propri file, migliorando l’efficienza del lavoro e riducendo il rischio di errori.\n\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti (es., Robbins, 2016). La familiarità con la shell è fondamentale nella data science.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html#bibliografia",
    "href": "chapters/appendix/a01_shell.html#bibliografia",
    "title": "Appendice A — La Shell",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nRobbins, A. (2016). Bash Pocket Reference: Help for Power Users and Sys Admins. O’Reilly Media, Inc.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_math_symbols.html",
    "href": "chapters/appendix/a02_math_symbols.html",
    "title": "Appendice B — Simbologia di base",
    "section": "",
    "text": "Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire “per ogni.”\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) è un elemento dell’insieme \\(A\\).\nL’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\).\nL’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge “tale che.”\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge “proporzionale a.”\nIl simbolo \\(\\approx\\) si legge “circa.”\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.”\nIl simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.”\nIl simbolo \\(\\#\\) indica la cardinalità di un insieme.\nIl simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore più alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html",
    "href": "chapters/appendix/a03_latex.html",
    "title": "Appendice C — Equazioni Matematiche in LaTeX",
    "section": "",
    "text": "C.1 LaTeX\nLaTeX è un potente strumento di composizione tipografica, ampiamente utilizzato per la produzione di documenti scientifici e tecnici. Una delle sue caratteristiche più apprezzate è la capacità di gestire equazioni matematiche in modo elegante e preciso. In questo articolo, esploreremo come scrivere equazioni matematiche in LaTeX, coprendo i modi matematici, le operazioni di base, l’allineamento delle equazioni e molto altro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#modelli-matematici-in-latex",
    "href": "chapters/appendix/a03_latex.html#modelli-matematici-in-latex",
    "title": "Appendice C — Equazioni Matematiche in LaTeX",
    "section": "C.2 Modelli Matematici in LaTeX",
    "text": "C.2 Modelli Matematici in LaTeX\nPer scrivere equazioni matematiche in LaTeX, esistono due modalità principali: la modalità inline e la modalità display.\n\nModalità Inline: Utilizzata per inserire equazioni all’interno del testo. Le espressioni matematiche sono racchiuse tra simboli di dollaro ($), ad esempio $E=mc^2$ produce \\(E=mc^2\\).\nModalità Display: Utilizzata per equazioni che devono essere evidenziate e centrate su una nuova linea. Le espressioni possono essere racchiuse tra $$ e $$, o all’interno di ambienti come \\begin{equation} e \\end{equation}.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#scrivere-costrutti-matematici-di-base",
    "href": "chapters/appendix/a03_latex.html#scrivere-costrutti-matematici-di-base",
    "title": "Appendice C — Equazioni Matematiche in LaTeX",
    "section": "C.3 Scrivere Costrutti Matematici di Base",
    "text": "C.3 Scrivere Costrutti Matematici di Base\n\nC.3.1 Operazioni Aritmetiche\nLe operazioni aritmetiche possono essere scritte direttamente all’interno del testo utilizzando il simbolo del dollaro. Ad esempio:\n\nAddizione: $a + b$ produce \\(a + b\\).\nMoltiplicazione: $a \\cdot b$ o $a \\times b$ produce \\(a \\cdot b\\) o \\(a \\times b\\).\nDivisione: $a / b$ o $a \\div b$ produce \\(a / b\\) o \\(a \\div b\\).\n\n\n\nC.3.2 Frazioni e Coefficienti Binomiali\nLe frazioni si scrivono utilizzando il comando \\frac{num}{den}. Ad esempio, $\\frac{a}{b}$ produce \\(\\frac{a}{b}\\).\nPer i coefficienti binomiali, si utilizza il comando \\binom{n}{k}. Ad esempio, $\\binom{n}{k}$ produce \\(\\binom{n}{k}\\).\n\n\nC.3.3 Pedici e Apici\nI pedici si ottengono con _, mentre gli apici con ^. Ad esempio:\n\n$a_{1}$ produce \\(a_{1}\\).\n$a^{2}$ produce \\(a^{2}\\).\n\n\n\nC.3.4 Integrali e Radici\nPer gli integrali, i limiti di integrazione si scrivono come pedici e apici. Ad esempio:\n\n$\\int_{a}^{b} f(x) \\, dx$ produce \\(\\int_{a}^{b} f(x) \\, dx\\).\n\nLe radici si ottengono con il comando \\sqrt{}. Ad esempio, $\\sqrt{a + b}$ produce \\(\\sqrt{a + b}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#allineamento-delle-equazioni",
    "href": "chapters/appendix/a03_latex.html#allineamento-delle-equazioni",
    "title": "Appendice C — Equazioni Matematiche in LaTeX",
    "section": "C.4 Allineamento delle Equazioni",
    "text": "C.4 Allineamento delle Equazioni\nPer allineare più equazioni, si utilizza l’ambiente align. Ad esempio:\n\\begin{align*}\na + b &= c \\\\\nd + e &= f\n\\end{align*}\nQuesto allinea le equazioni al segno di uguale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#parentesi-e-operatori",
    "href": "chapters/appendix/a03_latex.html#parentesi-e-operatori",
    "title": "Appendice C — Equazioni Matematiche in LaTeX",
    "section": "C.5 Parentesi e Operatori",
    "text": "C.5 Parentesi e Operatori\nLe parentesi possono essere ridimensionate utilizzando i comandi \\left( e \\right). Ad esempio:\n$$ \n\\left( \\frac{a}{b} \\right) \n$$\nGli operatori come seno, coseno e logaritmi si scrivono con comandi specifici come \\sin, \\cos, e \\log.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#conclusione",
    "href": "chapters/appendix/a03_latex.html#conclusione",
    "title": "Appendice C — Equazioni Matematiche in LaTeX",
    "section": "C.6 Conclusione",
    "text": "C.6 Conclusione\nLaTeX offre una vasta gamma di strumenti per la scrittura di equazioni matematiche, rendendolo uno strumento indispensabile per chiunque lavori con documenti scientifici. Con un po’ di pratica, è possibile padroneggiare queste tecniche e produrre documenti di alta qualità con facilità.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_balance_prior_post.html#esercizi",
    "href": "chapters/bayesian_inference/09_balance_prior_post.html#esercizi",
    "title": "49  L’influenza della distribuzione a priori",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nL’obiettivo di questo esercizio è comprendere come la distribuzione a priori influenzi la distribuzione a posteriori a seconda della grandezza del campione. Utilizzeremo dati raccolti della Satisfaction With Life Scale (SWLS), categorizzandoli in base a una soglia e analizzando la proporzione di risposte che superano tale soglia con un approccio bayesiano.\nFase 1: Raccolta e categorizzazione dei dati\n\nOgni studente utilizza i valori della scala SWLS che sono stati raccolti dal suo gruppo TPV.\nSi sceglie una soglia arbitraria (ad esempio, un punteggio superiore a 20 indica “elevata soddisfazione”).\n\nSi calcola la proporzione di persone con punteggi superiori alla soglia:\n\\[\n\\hat{p} = \\frac{k}{n}\n\\]\ndove \\(k\\) è il numero di persone con SWLS sopra la soglia e \\(n\\) è la dimensione del campione (circa 15).\n\n\nFase 2: Inferenza Bayesiana con un Prior Mediamente Informativo\n\n\nSi assume una distribuzione Beta come prior per la proporzione di persone con SWLS sopra la soglia:\n\\[\np \\sim \\text{Beta}(a, b)\n\\]\ndove \\(a = 2\\) e \\(b = 2\\), un prior mediamente informativo (distribuzione simmetrica centrata su 0.5).\n\n\nSi calcola la distribuzione a posteriori utilizzando la coniugazione della Beta con la distribuzione binomiale:\n\\[\np \\mid D \\sim \\text{Beta}(a + k, b + n - k)\n\\]\n\n\nSi calcolano:\n\n\nStima puntuale della proporzione (valore atteso della Beta a posteriori):\n\\[\nE[p \\mid D] = \\frac{a + k}{a + b + n}\n\\]\n\nIntervallo di credibilità (CI al 95%), utilizzando i quantili della distribuzione Beta a posteriori.\n\n\n\nFase 3: Analisi con un Campione Più Grande\n\nSi ripete lo stesso esercizio, ma immaginando che la stessa proporzione \\(\\hat{p}\\) provenga da un campione di n = 1000.\n\nSi calcola la nuova distribuzione a posteriori:\n\\[\np \\mid D \\sim \\text{Beta}(a + k', b + n' - k')\n\\] con \\(k' = \\hat{p} \\times 1000\\).\n\nSi ricalcolano stima puntuale e intervallo di credibilità.\n\nFase 4: Confronto e Interpretazione\n\n\nSi confrontano le due distribuzioni a posteriori:\n\nCome cambia la varianza della distribuzione a posteriori?\nCome cambia l’influenza del prior?\nQual è la differenza nella precisione della stima puntuale e dell’intervallo di credibilità?\n\n\nSi discute come, all’aumentare del campione, l’influenza della distribuzione a priori diminuisce, facendo emergere il ruolo della likelihood.\n\nConsegna: caricare su Moodle il file .qmd compilato in pdf.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html",
    "href": "chapters/linear_models/13_poisson_model.html",
    "title": "\n68  Modello di Poisson\n",
    "section": "",
    "text": "68.1 Introduzione\nNel precedente Capitolo 50 abbiamo visto come si ottiene la distribuzione a posteriori per i parametri di una Poisson con prior Gamma. Qui, costruiremo lo stesso tipo di analisi in R tramite brms.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#domanda-della-ricerca",
    "href": "chapters/linear_models/13_poisson_model.html#domanda-della-ricerca",
    "title": "\n68  Modello di Poisson\n",
    "section": "\n68.2 Domanda della ricerca",
    "text": "68.2 Domanda della ricerca\nCome spiegato qui, i dati che esamineremo sono raccolti dal Washington Post con lo scopo di registrare ogni sparatoria mortale negli Stati Uniti ad opera di agenti di polizia, a partire dal 1° gennaio 2015. Il Washington Post ha adottato un approccio sistematico e accurato nella raccolta di queste informazioni, fornendo dati che possono essere utili per valutare i problemi legati alla violenza delle forze di polizia negli Stati Uniti.\nLo scopo della presente analisi dei dati è determinare il tasso di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno, e fornire una stima dell’incertezza associata a questo valore.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#importazione-e-pre-processing-dei-dati",
    "href": "chapters/linear_models/13_poisson_model.html#importazione-e-pre-processing-dei-dati",
    "title": "\n68  Modello di Poisson\n",
    "section": "\n68.3 Importazione e pre-processing dei dati",
    "text": "68.3 Importazione e pre-processing dei dati\nScarichiamo i dati direttamente da GitHub:\n\nurl &lt;- \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nfps_dat &lt;- read.csv(url, stringsAsFactors = FALSE)\nhead(fps_dat)\n#&gt;   id       date threat_type flee_status armed_with          city\n#&gt; 1  3 2015-01-02       point         not        gun       Shelton\n#&gt; 2  4 2015-01-02       point         not        gun         Aloha\n#&gt; 3  5 2015-01-03        move         not    unarmed       Wichita\n#&gt; 4  8 2015-01-04       point         not    replica San Francisco\n#&gt; 5  9 2015-01-04       point         not      other         Evans\n#&gt; 6 11 2015-01-04      attack         not        gun       Guthrie\n#&gt;          county state latitude longitude location_precision\n#&gt; 1         Mason    WA    47.25   -123.12      not_available\n#&gt; 2    Washington    OR    45.49   -122.89      not_available\n#&gt; 3      Sedgwick    KS    37.69    -97.28      not_available\n#&gt; 4 San Francisco    CA    37.76   -122.42      not_available\n#&gt; 5          Weld    CO    40.38   -104.69      not_available\n#&gt; 6         Logan    OK    35.88    -97.42      not_available\n#&gt;                 name age gender race   race_source\n#&gt; 1         Tim Elliot  53   male    A not_available\n#&gt; 2   Lewis Lee Lembke  47   male    W not_available\n#&gt; 3 John Paul Quintero  23   male    H not_available\n#&gt; 4    Matthew Hoffman  32   male    W not_available\n#&gt; 5  Michael Rodriguez  39   male    H not_available\n#&gt; 6  Kenneth Joe Brown  18   male    W not_available\n#&gt;   was_mental_illness_related body_camera agency_ids\n#&gt; 1                       True       False         73\n#&gt; 2                      False       False         70\n#&gt; 3                      False       False        238\n#&gt; 4                       True       False        196\n#&gt; 5                      False       False        473\n#&gt; 6                      False       False        101\n\nConvertiamo la colonna delle date e creiamo la variabile “year”:\n\nfps_dat$date &lt;- as.Date(fps_dat$date)  # conversione in oggetto Date\nfps_dat$year &lt;- as.numeric(format(fps_dat$date, \"%Y\"))\n\nRimuoviamo eventuali osservazioni del 2025 (dato che è incompleto):\n\nfps &lt;- subset(fps_dat, year != 2025)\ntable(fps$year)\n#&gt; \n#&gt; 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 \n#&gt;  995  959  984  992  993 1021 1050 1097 1164 1173\n\nCreiamo poi un data frame con i conteggi per anno:\n\nyear_counts &lt;- table(fps$year)\ndf &lt;- data.frame(\n  year   = as.numeric(names(year_counts)),\n  events = as.vector(year_counts)\n)\ndf\n#&gt;    year events\n#&gt; 1  2015    995\n#&gt; 2  2016    959\n#&gt; 3  2017    984\n#&gt; 4  2018    992\n#&gt; 5  2019    993\n#&gt; 6  2020   1021\n#&gt; 7  2021   1050\n#&gt; 8  2022   1097\n#&gt; 9  2023   1164\n#&gt; 10 2024   1173\n\nQui, df$events indica quante sparatorie fatali sono state registrate in ogni anno compreso tra il 2015 e il 2023 (estremi inclusi).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#modello-di-poisson",
    "href": "chapters/linear_models/13_poisson_model.html#modello-di-poisson",
    "title": "\n68  Modello di Poisson\n",
    "section": "\n68.4 Modello di Poisson",
    "text": "68.4 Modello di Poisson\nVogliamo stimare il parametro \\(\\lambda\\) della Poisson (tasso di sparatorie all’anno). Se denotiamo con \\(Y\\) il numero di sparatorie in un anno, l’assunto è:\n\\[\nY \\sim \\text{Poisson}(\\lambda).\n\\]",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#distribuzione-a-priori",
    "href": "chapters/linear_models/13_poisson_model.html#distribuzione-a-priori",
    "title": "\n68  Modello di Poisson\n",
    "section": "\n68.5 Distribuzione a priori",
    "text": "68.5 Distribuzione a priori\n\n68.5.1 Motivazione\nScegliamo una distribuzione a priori su \\(\\lambda\\). In teoria, potremmo adottare una Gamma(\\(\\alpha, \\beta\\)) “esplicita”. Tuttavia, brms richiede di specificare i prior nella forma più consueta per i modelli GLM in Stan, ovvero sul log della media di Poisson (in quanto, per difetto, la famiglia Poisson usa il link log).\nSe desiderassimo imporre esattamente una prior Gamma su \\(\\lambda\\), potremmo dover ricorrere a definizioni custom in Stan. Di solito, però, si sceglie una normal sul log(\\(\\lambda\\)) che approssimi bene la forma desiderata (la log-normal è un’approssimazione comune di una generica gamma).\n\n68.5.2 Esempio di prior per \\(\\lambda\\)\n\nIpotizziamo una media a priori di 600 e una deviazione standard di 200. Se vogliamo approssimare questa gamma con una log-normal, basta trovare media e dev. std. (sul log-scale) corrispondenti. Faremo una stima spannometrica direttamente:\n\nmedia del log(\\(\\lambda\\)) \\(\\approx \\log(600)\\approx 6.4\\).\ndev. std. \\(\\approx 0.3\\) (che dà un intervallo ragionevole intorno a 600 \\(\\pm\\) qualche centinaio).\n\nCosì scriviamo:\n\nprior_approx &lt;- c(\n  prior(normal(6.4, 0.3), class = \"Intercept\")  # normal su log(lambda)\n)\n\nIn tal modo, stiamo dicendo a brms che il log della media di Poisson (cioè l’Intercept del modello) segue pressappoco \\(\\mathcal{N}(6.4, 0.3^2)\\). Questo corrisponde a una distribuzione su \\(\\lambda\\) (\\(\\exp(\\log(\\)\\())\\)) i cui valori plausibili si aggirano intorno a 600.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#stima-del-tasso-annuo",
    "href": "chapters/linear_models/13_poisson_model.html#stima-del-tasso-annuo",
    "title": "\n68  Modello di Poisson\n",
    "section": "\n68.6 Stima del tasso annuo",
    "text": "68.6 Stima del tasso annuo\n\n68.6.1 Costruzione del modello in brms\nCreiamo un modello di Poisson semplicissimo: un unico intercept (cioè ipotizziamo che in tutti gli anni il tasso sia costante). Chiaramente questa è un’approssimazione: si potrebbe estendere per anno, trend, ecc. Ma qui mostriamo solo la logica gamma-Poisson di base.\n\n# df ha due colonne: year, events\n# Poiché brms si aspetta le \"osservazioni\" riga per riga,\n# creeremo un data frame in cui ogni riga rappresenta un anno\n# e la colonna events è il numero di sparatorie di quell'anno.\n\nm0 &lt;- brm(\n  formula = events ~ 1, # solo intercetta\n  family  = poisson(link = \"log\"),\n  data    = df,\n  prior   = prior_approx,\n  iter    = 3000, # numero di iterazioni (warmup+sampling)\n  warmup  = 1000,\n  chains  = 4,\n  seed    = 123\n)\n\nTerminato l’addestramento del modello, esaminiamo un sommario dei parametri:\n\nsummary(m0)\n#&gt;  Family: poisson \n#&gt;   Links: mu = log \n#&gt; Formula: events ~ 1 \n#&gt;    Data: df (Number of observations: 10) \n#&gt;   Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     6.95      0.01     6.93     6.97 1.00     2879     3532\n#&gt; \n#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nUscita tipica (semplificata):\n\n\nb_Intercept: stima dell’intercetta sullo scale log.\n\nEst.Error: errore standard a posteriori.\n\nl-95% CI e u-95% CI: limiti dell’intervallo di credibilità (IC) al 95% predefinito.\n\nPer ottenere il tasso \\(\\lambda\\) a posteriori possiamo ricorrere a:\n\n# Ottieni i campioni posteriori usando as_draws\nposterior_draws_m0 &lt;- as_draws(m0)\n\n# Estrai i campioni dell'intercetta (b_Intercept)\nb_Intercept_draws &lt;- posterior_draws_m0 %&gt;% \n  tidybayes::spread_draws(b_Intercept)\n\n# Converti i campioni in lambda (exp(b_Intercept))\nlambda_draws &lt;- exp(b_Intercept_draws$b_Intercept)\n\n# Calcola i quantili\nquantile(lambda_draws, probs = c(0.03, 0.5, 0.97))\n#&gt;   3%  50%  97% \n#&gt; 1022 1042 1061\n\nSe vogliamo un IC al 94% (invece del 95%), basta:\n\nquantile(lambda_draws, probs = c(0.03, 0.5, 0.97)) \n#&gt;   3%  50%  97% \n#&gt; 1022 1042 1061\n\no più elegantemente:\n\ntidybayes::median_qi(lambda_draws, .width = 0.94)\n#&gt;      y ymin ymax .width .point .interval\n#&gt; 1 1042 1022 1061   0.94 median        qi\n\nQuesto ci darà una stima mediana a posteriori di \\(\\lambda\\) e l’intervallo di credibilità al 94%.\n\n68.6.2 Visualizzazione\nPossiamo infine tracciare la densità a posteriori del parametro \\(\\lambda\\):\n\ntibble(lambda = lambda_draws) %&gt;%\n  ggplot(aes(x = lambda)) +\n  stat_halfeye(fill = \"skyblue\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione a posteriori di λ (tasso Poisson annuo)\",\n    x = \"λ\",\n    y = \"Densità a posteriori\"\n  )\n\n\n\n\n\n\n\nIn sostanza, otteniamo (come nel caso Stan/Python) una stima del tasso \\(\\lambda\\) e un intervallo di incertezza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#derivazione-analitica-breve-richiamo",
    "href": "chapters/linear_models/13_poisson_model.html#derivazione-analitica-breve-richiamo",
    "title": "\n68  Modello di Poisson\n",
    "section": "\n68.7 Derivazione analitica (breve richiamo)",
    "text": "68.7 Derivazione analitica (breve richiamo)\nQuando la verosimiglianza è di tipo Poisson e si usa un prior Gamma(\\(\\alpha_0\\), \\(\\beta_0\\)), la posterior di \\(\\lambda\\) rimane gamma, con parametri aggiornati:\n\n\\(\\alpha_{\\text{post}} = \\alpha_0 + \\sum y_i\\)\n\n\\(\\beta_{\\text{post}}  = \\beta_0 + n\\),\n\ndove \\(n\\) è il numero di osservazioni (in questo caso, anni) e \\(y_i\\) sono i conteggi. brms di default usa la scala log per le stime e calcola la posterior via MCMC. La soluzione chiusa rimane utile come conferma analitica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#vittime-non-armate",
    "href": "chapters/linear_models/13_poisson_model.html#vittime-non-armate",
    "title": "\n68  Modello di Poisson\n",
    "section": "\n68.8 Vittime non armate",
    "text": "68.8 Vittime non armate\nRiprendiamo ora l’argomento di (Ross et al., 2021) sul differente tasso di sparatorie fatali tra persone di razza caucasica (bianche) e non-caucasica, limitandoci ai casi in cui la vittima risulti disarmata.\n\n68.8.1 Pre-processing dei dati\nFiltriamo i casi “unarmed”:\n\nfps_unarmed &lt;- subset(fps, armed_with == \"unarmed\")\n\nSepariamo in due gruppi:\n\nwhite_df    &lt;- subset(fps_unarmed, race == \"W\")\nnon_white_df &lt;- subset(fps_unarmed, race != \"W\")\n\nVerifichiamo:\n\nhead(white_df)\n#&gt;      id       date threat_type flee_status armed_with        city\n#&gt; 9    16 2015-01-06    accident         not    unarmed  Burlington\n#&gt; 73  342 2015-01-29        move        foot    unarmed  Stillwater\n#&gt; 77  114 2015-02-02        flee        foot    unarmed Hummelstown\n#&gt; 120 159 2015-02-17        flee        foot    unarmed Springfield\n#&gt; 137 371 2015-02-23        move         not    unarmed       Omaha\n#&gt; 141 180 2015-02-26      threat         not    unarmed Terre Haute\n#&gt;         county state latitude longitude location_precision\n#&gt; 9   Des Moines    IA    40.81    -91.12      not_available\n#&gt; 73       Payne    OK    36.12    -97.05      not_available\n#&gt; 77     Dauphin    PA    40.27    -76.71      not_available\n#&gt; 120     Greene    MO    37.23    -93.32      not_available\n#&gt; 137    Douglas    NE    41.24    -95.93      not_available\n#&gt; 141       Vigo    IN    39.46    -87.38      not_available\n#&gt;                       name age gender race   race_source\n#&gt; 9            Autumn Steele  34 female    W not_available\n#&gt; 73            Ralph Willis  42   male    W not_available\n#&gt; 77           David Kassick  59   male    W not_available\n#&gt; 120        Michael Ireland  31   male    W not_available\n#&gt; 137           Daniel Elrod  39   male    W not_available\n#&gt; 141 Alexander Phillip Long  31   male    W not_available\n#&gt;     was_mental_illness_related body_camera agency_ids year\n#&gt; 9                        False        True        287 2015\n#&gt; 73                       False       False        164 2015\n#&gt; 77                       False       False        303 2015\n#&gt; 120                      False       False        350 2015\n#&gt; 137                      False       False        158 2015\n#&gt; 141                      False       False   377;3612 2015\n\n\nhead(non_white_df)\n#&gt;      id       date threat_type flee_status armed_with        city   county\n#&gt; 3     5 2015-01-03        move         not    unarmed     Wichita Sedgwick\n#&gt; 18   36 2015-01-08      attack         not    unarmed      Strong    Union\n#&gt; 63  352 2015-01-26        flee         car    unarmed      Tahoka     Lynn\n#&gt; 84  116 2015-02-04      attack         not    unarmed Tallahassee     Leon\n#&gt; 87  125 2015-02-04    accident         not    unarmed       Tempe Maricopa\n#&gt; 101 138 2015-02-10        flee        foot    unarmed       Pasco Franklin\n#&gt;     state latitude longitude location_precision                    name age\n#&gt; 3      KS    37.69    -97.28      not_available      John Paul Quintero  23\n#&gt; 18     AR    33.11    -92.36      not_available     Artago Damon Howard  36\n#&gt; 63     TX    33.17   -101.67      not_available      Joshua Omar Garcia  24\n#&gt; 84     FL    30.47    -84.33      not_available             Jeremy Lett  28\n#&gt; 87     AZ    33.38   -111.98      not_available       Joaquin Hernandez  28\n#&gt; 101    WA    46.23   -119.10      not_available Antonio Zambrano-Montes  35\n#&gt;     gender race   race_source was_mental_illness_related body_camera\n#&gt; 3     male    H not_available                      False       False\n#&gt; 18    male    B not_available                      False       False\n#&gt; 63    male    H not_available                      False       False\n#&gt; 84    male    B not_available                      False       False\n#&gt; 87    male    H not_available                      False       False\n#&gt; 101   male    H not_available                       True       False\n#&gt;           agency_ids year\n#&gt; 3                238 2015\n#&gt; 18               249 2015\n#&gt; 63               179 2015\n#&gt; 84               311 2015\n#&gt; 87  247;195;2267;319 2015\n#&gt; 101              331 2015\n\nOra costruiamo i conteggi anno per anno nei due gruppi:\n\ncount_white &lt;- table(white_df$year)\nevents_by_year_white &lt;- data.frame(\n  year = as.numeric(names(count_white)),\n  event_count = as.vector(count_white)\n)\n\ncount_non_white &lt;- table(non_white_df$year)\nevents_by_year_non_white &lt;- data.frame(\n  year = as.numeric(names(count_non_white)),\n  event_count = as.vector(count_non_white)\n)\n\n\nevents_by_year_white\n#&gt;    year event_count\n#&gt; 1  2015          31\n#&gt; 2  2016          29\n#&gt; 3  2017          29\n#&gt; 4  2018          26\n#&gt; 5  2019          26\n#&gt; 6  2020          27\n#&gt; 7  2021           7\n#&gt; 8  2022          23\n#&gt; 9  2023          18\n#&gt; 10 2024           6\n\n\nevents_by_year_non_white\n#&gt;    year event_count\n#&gt; 1  2015          63\n#&gt; 2  2016          35\n#&gt; 3  2017          40\n#&gt; 4  2018          33\n#&gt; 5  2019          28\n#&gt; 6  2020          34\n#&gt; 7  2021          26\n#&gt; 8  2022          28\n#&gt; 9  2023          33\n#&gt; 10 2024          22\n\n\n68.8.2 Una prior plausibile\nDalle medie dei due campioni, immaginiamo di mettere una prior lognormale su \\(\\lambda\\) attorno a 30 (dev. std. \\(\\approx 10\\)). Approfittiamo di un’ulteriore approssimazione:\n\n# prior ~ lognormal(meanlog = 3.4, sdlog = 0.3) ~ circa media 30, sd ~10\nprior_unarmed &lt;- c(\n  prior(normal(3.4, 0.3), class = \"Intercept\")\n)\n\n\n68.8.3 Stima separata per i due gruppi\n\n68.8.3.1 Gruppo caucasico (white)\n\nm_white &lt;- brm(\n  formula = event_count ~ 1,\n  family  = poisson(link = \"log\"),\n  data    = events_by_year_white,\n  prior   = prior_unarmed,\n  iter    = 3000, warmup = 1000, seed = 123\n)\n\n\nsummary(m_white)\n#&gt;  Family: poisson \n#&gt;   Links: mu = log \n#&gt; Formula: event_count ~ 1 \n#&gt;    Data: events_by_year_white (Number of observations: 10) \n#&gt;   Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     3.11      0.07     2.98     3.24 1.00     2896     4026\n#&gt; \n#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nOtteniamo la posterior su \\(\\lambda_{\\text{white}}\\):\n\n# Ottieni i campioni posteriori usando as_draws\nposterior_draws_m_white &lt;- as_draws(m_white)\n\n# Estrai i campioni dell'intercetta (b_Intercept)\nb_Intercept_draws &lt;- posterior_draws_m_white %&gt;% \n  tidybayes::spread_draws(b_Intercept)\n\n# Converti i campioni in lambda (exp(b_Intercept))\nlambda_draws &lt;- exp(b_Intercept_draws$b_Intercept)\n\nmedian_qi(lambda_draws, .width = 0.94)\n#&gt;       y  ymin  ymax .width .point .interval\n#&gt; 1 22.45 19.76 25.33   0.94 median        qi\n\n\n68.8.3.2 Gruppo non-caucasico\n\nm_non_white &lt;- brm(\n  formula = event_count ~ 1,\n  family  = poisson(link = \"log\"),\n  data    = events_by_year_non_white,\n  prior   = prior_unarmed,\n  iter    = 3000, warmup = 1000, seed = 123\n)\n\n\nsummary(m_non_white)\n#&gt;  Family: poisson \n#&gt;   Links: mu = log \n#&gt; Formula: event_count ~ 1 \n#&gt;    Data: events_by_year_non_white (Number of observations: 10) \n#&gt;   Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     3.53      0.05     3.42     3.63 1.00     3028     3565\n#&gt; \n#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nEstraiamo la posterior e calcoliamo l’intervallo di credibilità:\n\n# Ottieni i campioni posteriori usando as_draws\nposterior_draws_m_non_white &lt;- as_draws(m_non_white)\n\n# Estrai i campioni dell'intercetta (b_Intercept)\nb_Intercept_draws &lt;- posterior_draws_m_non_white %&gt;% \n  tidybayes::spread_draws(b_Intercept)\n\n# Converti i campioni in lambda (exp(b_Intercept))\nlambda_draws &lt;- exp(b_Intercept_draws$b_Intercept)\n\nmedian_qi(lambda_draws, .width = 0.94)\n#&gt;       y  ymin  ymax .width .point .interval\n#&gt; 1 34.01 30.62 37.48   0.94 median        qi\n\nIl confronto tra i due intervalli di credibilità, come già visto in precedenza, indica che il tasso di vittime disarmate (per anno) sia più elevato tra i non-caucasici rispetto ai caucasici.\n\n68.8.4 Modello congiunto (due gruppi in un unico fit)\nPossiamo anche costruire un unico modello che stimi congiuntamente i due tassi e la loro differenza. Per far ciò, costruiamo un data frame in cui ogni riga è un anno-gruppo:\n\nevents_white    &lt;- events_by_year_white %&gt;%\n  mutate(group = \"White\")\n\nevents_nonwhite &lt;- events_by_year_non_white %&gt;%\n  mutate(group = \"NonWhite\")\n\ndf_groups &lt;- bind_rows(events_white, events_nonwhite) %&gt;%\n  arrange(year, group)\n\ndf_groups\n#&gt;    year event_count    group\n#&gt; 1  2015          63 NonWhite\n#&gt; 2  2015          31    White\n#&gt; 3  2016          35 NonWhite\n#&gt; 4  2016          29    White\n#&gt; 5  2017          40 NonWhite\n#&gt; 6  2017          29    White\n#&gt; 7  2018          33 NonWhite\n#&gt; 8  2018          26    White\n#&gt; 9  2019          28 NonWhite\n#&gt; 10 2019          26    White\n#&gt; 11 2020          34 NonWhite\n#&gt; 12 2020          27    White\n#&gt; 13 2021          26 NonWhite\n#&gt; 14 2021           7    White\n#&gt; 15 2022          28 NonWhite\n#&gt; 16 2022          23    White\n#&gt; 17 2023          33 NonWhite\n#&gt; 18 2023          18    White\n#&gt; 19 2024          22 NonWhite\n#&gt; 20 2024           6    White\n\nOra adattiamo un modello con un effetto fittizio per ogni gruppo (senza intercetta globale, se vogliamo stime distinte e dirette sul link log):\n\n# Il simbolo 0 + group rimuove l’intercetta e stima un parametro di log-tasso\n# per il gruppo White e un altro per NonWhite.\n\nm_groups &lt;- brm(\n  formula = event_count ~ 0 + group,  # 2 coefficienti: groupWhite, groupNonWhite\n  family  = poisson(link = \"log\"),\n  data    = df_groups,\n  prior   = c(\n    prior(normal(3.4, 0.3), class=\"b\", coef=\"groupWhite\"),\n    prior(normal(3.4, 0.3), class=\"b\", coef=\"groupNonWhite\")\n  ),\n  iter = 3000, warmup = 1000, chains = 4, seed=123\n)\n\nsummary(m_groups)\n\nNell’output avremo:\n\n\nb_groupWhite: stima log(\\(\\lambda_{\\text{white}}\\))\n\nb_groupNonWhite: stima log(\\(\\lambda_{\\text{nonwhite}}\\))\n\n\n68.8.4.1 Calcolo della differenza delle frequenze attese\nSe vogliamo la differenza sulla scala naturale (cioè \\(\\lambda_{\\text{nonwhite}} - \\lambda_{\\text{white}}\\)), basta estrarre i campioni e poi calcolare:\n\npost_mg &lt;- posterior_samples(m_groups)\nlambda_white_mg    &lt;- exp(post_mg$b_groupWhite)\nlambda_nonwhite_mg &lt;- exp(post_mg$b_groupNonWhite)\ndiff_lambda &lt;- lambda_nonwhite_mg - lambda_white_mg\n\nmedian_qi(diff_lambda, .width = 0.94)\n#&gt;       y  ymin  ymax .width .point .interval\n#&gt; 1 11.54 7.126 15.99   0.94 median        qi\n\nSe questo IC al 94% sta tutto sopra lo zero, possiamo concludere che \\(\\lambda_{\\text{nonwhite}} &gt; \\lambda_{\\text{white}}\\) con alta credibilità.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/linear_models/13_poisson_model.html#riflessioni-conclusive",
    "title": "\n68  Modello di Poisson\n",
    "section": "\n68.9 Riflessioni Conclusive",
    "text": "68.9 Riflessioni Conclusive\nSulla base dei risultati ottenuti dal modello di Poisson, possiamo trarre le seguenti conclusioni:\n\nIl tasso stimato di incidenza delle vittime disarmate uccise dalla polizia negli Stati Uniti è più alto per il gruppo non caucasico rispetto al gruppo caucasico. La differenza media stimata tra i due tassi di incidenza è di 11.508, con una deviazione standard di 2.586. Questo significa che, in media, il tasso per il gruppo non caucasico è di circa 11.5 punti superiore rispetto al tasso per il gruppo caucasico.\nL’intervallo di credibilità al 94% per questa differenza va da 6.792 a 16.443, indicando che è molto probabile che la vera differenza tra i tassi di incidenza dei due gruppi si trovi all’interno di questo intervallo. Questo intervallo di credibilità non include lo zero, il che fornisce ulteriore evidenza che il tasso di incidenza per il gruppo non caucasico è effettivamente più alto rispetto al gruppo caucasico.\n\nInoltre, i tassi di incidenza stimati per ciascun gruppo sono i seguenti:\n\nGruppo non caucasico: tasso medio di 35.577 con un intervallo di credibilità al 94% tra 31.978 e 39.260.\nGruppo caucasico: tasso medio di 24.069 con un intervallo di credibilità al 94% tra 21.098 e 27.285.\n\nQuesti risultati indicano chiaramente che il gruppo non caucasico ha un tasso di incidenza più alto di vittime disarmate uccise dalla polizia rispetto al gruppo caucasico. L’intervallo di credibilità per ciascun tasso fornisce una stima robusta e credibile della variabilità di questi tassi.\nIn sintesi, il modello di Poisson fornisce una forte evidenza che esiste una differenza robusta tra i tassi di incidenza dei due gruppi, con il gruppo non caucasico che presenta un tasso più elevato di vittime disarmate uccise dalla polizia rispetto al gruppo caucasico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#esercizi",
    "href": "chapters/linear_models/13_poisson_model.html#esercizi",
    "title": "\n68  Modello di Poisson\n",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nNella finale olimpica di calcio 2024, la Spagna ha sconfitto la Francia per 5 a 3. Supponiamo di voler calcolare la probabilità di superiorità della Spagna rispetto alla Francia utilizzando un modello coniugato Gamma-Poisson (o l’approssimazione brms con prior lognormale).\n\nConsidera che il numero di gol segnati da una squadra segua una Poisson con parametro \\(\\lambda\\).\n\nSpecifica un prior su \\(\\lambda\\) per entrambe le squadre, ad esempio \\(\\alpha=1\\) e \\(\\beta=1\\) nella parametrizzazione Gamma classica (oppure una Normal(0,1.4) sull’intercetta, in modo da avere una media a posteriori analoga).\n\nAggiorna la distribuzione a posteriori conoscendo i gol segnati (5 per la Spagna e 3 per la Francia in una singola partita).\n\nCalcola la probabilità che \\(\\lambda_{\\text{Spagna}} &gt; \\lambda_{\\text{Francia}}\\).\n\n(Ispirato a “The World Cup Problem”, (Downey, 2021).)\nSuggerimento: puoi risolvere il problema in modo analitico (Gamma-Poisson con un solo conteggio) oppure puoi usare brms costruendo un dataframe:\ndf_soccer &lt;- data.frame(\n  team = c(\"Spain\", \"France\"),\n  goals = c(5, 3)\n)\n\nModello: goals ~ 0 + team, family=poisson().\nPrior su b_teamSpain e b_teamFrance.\nInfine, estrai i draws e calcola la probabilità \\(\\Pr(\\exp(b_{\\text{Spain}}) &gt; \\exp(b_{\\text{France}}))\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/13_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n68  Modello di Poisson\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidybayes_3.0.7  brms_2.22.0      Rcpp_1.0.14      HDInterval_0.2.4\n#&gt;  [5] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.10.0      \n#&gt;  [9] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt; [13] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [17] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [21] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [25] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.5          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] matrixStats_1.5.0    compiler_4.4.2       loo_2.8.0           \n#&gt; [10] callr_3.7.6          vctrs_0.6.5          reshape2_1.4.4      \n#&gt; [13] pkgconfig_2.0.3      arrayhelpers_1.1-0   fastmap_1.2.0       \n#&gt; [16] backports_1.5.0      labeling_0.4.3       rmarkdown_2.29      \n#&gt; [19] tzdb_0.4.0           ps_1.8.1             xfun_0.50           \n#&gt; [22] jsonlite_1.8.9       parallel_4.4.2       R6_2.6.1            \n#&gt; [25] stringi_1.8.4        StanHeaders_2.32.10  estimability_1.5.1  \n#&gt; [28] rstan_2.32.6         zoo_1.8-12           pacman_0.5.1        \n#&gt; [31] Matrix_1.7-2         splines_4.4.2        timechange_0.3.0    \n#&gt; [34] tidyselect_1.2.1     rstudioapi_0.17.1    abind_1.4-8         \n#&gt; [37] yaml_2.3.10          codetools_0.2-20     curl_6.2.0          \n#&gt; [40] processx_3.8.5       pkgbuild_1.4.6       lattice_0.22-6      \n#&gt; [43] plyr_1.8.9           withr_3.0.2          bridgesampling_1.1-2\n#&gt; [46] posterior_1.6.0.9000 coda_0.19-4.1        evaluate_1.0.3      \n#&gt; [49] survival_3.8-3       RcppParallel_5.1.10  ggdist_3.3.2        \n#&gt; [52] pillar_1.10.1        tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [55] stats4_4.4.2         distributional_0.5.0 generics_0.1.3      \n#&gt; [58] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [61] munsell_0.5.1        xtable_1.8-4         glue_1.8.0          \n#&gt; [64] emmeans_1.10.7       tools_4.4.2          mvtnorm_1.3-3       \n#&gt; [67] grid_4.4.2           QuickJSR_1.5.1       colorspace_2.1-1    \n#&gt; [70] nlme_3.1-167         cli_3.6.4            svUnit_1.0.6        \n#&gt; [73] Brobdingnag_1.2-9    V8_6.0.1             gtable_0.3.6        \n#&gt; [76] digest_0.6.37        TH.data_1.1-3        htmlwidgets_1.6.4   \n#&gt; [79] farver_2.1.2         htmltools_0.5.8.1    lifecycle_1.0.4     \n#&gt; [82] MASS_7.3-64",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#bibliografia",
    "href": "chapters/linear_models/13_poisson_model.html#bibliografia",
    "title": "\n68  Modello di Poisson\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDowney, A. B. (2021). Think Bayes. \" O’Reilly Media, Inc.\".\n\n\nRoss, C. T., Winterhalder, B., & McElreath, R. (2021). Racial disparities in police use of deadly force against unarmed individuals persist after appropriately benchmarking shooting data on violent crime rates. Social Psychological and Personality Science, 12(3), 323–332.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#approfondimento-sulla-manipolazione-della-distribuzione-a-posteriori-con-brms",
    "href": "chapters/linear_models/04_synt_sugar.html#approfondimento-sulla-manipolazione-della-distribuzione-a-posteriori-con-brms",
    "title": "59  Zucchero sintattico",
    "section": "\n59.8 Approfondimento sulla manipolazione della distribuzione a posteriori con brms\n",
    "text": "59.8 Approfondimento sulla manipolazione della distribuzione a posteriori con brms\n\nDi seguito illustriamo come accedere e manipolare i campioni generati dal modello bayesiano in brms. Supponiamo di aver costruito un modello lineare semplice, dove vogliamo predire la variabile height in funzione di weight_c:\nfit_1 &lt;- brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\nUna volta che il modello è stato fit, possiamo estrarre le draws (ossia i campioni) della distribuzione a posteriori tramite la funzione as_draws():\n\nposterior_1 &lt;- as_draws(fit_1)\n\n\n59.8.1 Struttura dei campioni a posteriori\nL’oggetto posterior_1 ottenuto è di tipo draws (una struttura definita dal pacchetto posterior), che internamente può essere rappresentato come una lista o un array in cui sono memorizzati i campioni MCMC:\n\nstr(posterior_1)\n#&gt; List of 4\n#&gt;  $ 1:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 155 155 154 155 154 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.886 0.84 0.91 0.888 0.98 ...\n#&gt;   ..$ sigma      : num [1:1000] 5.36 5.21 5.07 4.97 5.36 ...\n#&gt;   ..$ lprior     : num [1:1000] -2.7 -2.68 -2.67 -2.66 -2.7 ...\n#&gt;   ..$ lp__       : num [1:1000] -1077 -1074 -1073 -1072 -1075 ...\n#&gt;  $ 2:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 154 155 155 154 155 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.967 0.924 0.865 0.929 0.891 ...\n#&gt;   ..$ sigma      : num [1:1000] 5.25 5.25 4.88 4.94 4.99 ...\n#&gt;   ..$ lprior     : num [1:1000] -2.69 -2.69 -2.66 -2.66 -2.67 ...\n#&gt;   ..$ lp__       : num [1:1000] -1074 -1073 -1073 -1073 -1072 ...\n#&gt;  $ 3:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 155 155 154 155 155 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.953 0.955 0.809 0.933 0.939 ...\n#&gt;   ..$ sigma      : num [1:1000] 4.97 4.94 5.12 5.3 5.7 ...\n#&gt;   ..$ lprior     : num [1:1000] -2.66 -2.66 -2.68 -2.69 -2.73 ...\n#&gt;   ..$ lp__       : num [1:1000] -1073 -1073 -1075 -1075 -1077 ...\n#&gt;  $ 4:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 155 155 154 154 154 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.905 0.899 0.878 0.913 0.938 ...\n#&gt;   ..$ sigma      : num [1:1000] 5.24 4.98 4.79 5.11 5.09 ...\n#&gt;   ..$ lprior     : num [1:1000] -2.69 -2.66 -2.65 -2.68 -2.67 ...\n#&gt;   ..$ lp__       : num [1:1000] -1072 -1072 -1074 -1072 -1073 ...\n#&gt;  - attr(*, \"class\")= chr [1:3] \"draws_list\" \"draws\" \"list\"\n\nQuesta ispezione ti permette di vedere che l’oggetto contiene le catene e i parametri campionati.\n\n59.8.2 Estrazione di un parametro specifico\nPossiamo estrarre i nomi dei parametri del modello dall’oggetto creato da brm() nel modo seguente:\n\nvariables(fit_1)\n#&gt; [1] \"b_Intercept\" \"b_weight_c\"  \"sigma\"       \"lprior\"      \"lp__\"\n\nNel nostro esempio, siamo interessati al coefficiente di regressione associato a weight_c, che in brms è etichettato come b_weight_c. Per semplificare la manipolazione e l’analisi, possiamo servirci di tidybayes, un pacchetto che fornisce funzioni utili per trasformare i campioni in formati “tidy”.\n\nlibrary(tidybayes)\n\nb_slope_draws &lt;- posterior_1 |&gt; \n  spread_draws(b_weight_c)\n\nLa funzione spread_draws() estrae e “srotola” le draw dei parametri in un tibble, che risulta più comodo da esplorare:\n\nhead(b_slope_draws)\n#&gt; # A tibble: 6 × 4\n#&gt;   .chain .iteration .draw b_weight_c\n#&gt;    &lt;int&gt;      &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n#&gt; 1      1          1     1      0.886\n#&gt; 2      1          2     2      0.840\n#&gt; 3      1          3     3      0.910\n#&gt; 4      1          4     4      0.888\n#&gt; 5      1          5     5      0.980\n#&gt; 6      1          6     6      0.884\n\nIn questo modo, ogni riga corrisponde a un singolo campione della catena MCMC, per quel parametro.\n\n59.8.3 Calcolo di statistiche riassuntive\nUna volta estratti i campioni del parametro di interesse (qui b_weight_c), possiamo calcolare facilmente statistiche come quantili e medie:\n\nquantile(b_slope_draws$b_weight_c, probs = c(0.03, 0.50, 0.97))\n#&gt;     3%    50%    97% \n#&gt; 0.8263 0.9060 0.9845\n\n\nmean(b_slope_draws$b_weight_c)\n#&gt; [1] 0.9056\n\n\nI quantili a 0.03, 0.50 e 0.97 forniscono, rispettivamente, un limite inferiore al 94% (0.03–0.97), la mediana a posteriori (0.50) e un limite superiore.\n\nLa funzione mean() restituisce la media a posteriori del coefficiente, un’altra statistica utile per la stima puntuale.\n\n59.8.4 Visualizzazione della distribuzione a posteriori\nPer comprendere meglio la forma della distribuzione a posteriori, è buona prassi tracciarne la densità. Con tidyverse e tidybayes, possiamo creare un grafico elegante in poche righe:\n\ntibble(beta = b_slope_draws$b_weight_c) %&gt;%\n  ggplot(aes(x = beta)) +\n  stat_halfeye(fill = \"skyblue\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione a posteriori di β (b_weight_c)\",\n    x = \"Valore di β\",\n    y = \"Densità a posteriori\"\n  )\n\n\n\n\n\n\n\n\n\nstat_halfeye() mostra la densità stimata dei campioni, evidenziando in modo intuitivo i valori più probabili.\n\nIl colore e l’alpha permettono di personalizzare l’aspetto del grafico.\n\nIn sintesi, utilizzando l’oggetto restituito da brm() e la funzione as_draws(), possiamo estrarre i campioni della distribuzione a posteriori e analizzare:\n\n\nstatistiche di sintesi, come media, mediana e quantili;\n\ndistribuzioni di densità, per una visualizzazione più immediata della variabilità e della forma della distribuzione a posteriori di un parametro.\n\nLa combinazione di posterior, tidybayes e tidyverse rende l’intero flusso di lavoro — dall’estrazione dei campioni fino alla creazione di grafici e statistiche — semplice e molto flessibile.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_post_pred_distr.html#esercizi",
    "href": "chapters/bayesian_inference/12_post_pred_distr.html#esercizi",
    "title": "52  Distribuzione predittiva a posteriori",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nConsideriamo i dati della SWLS somministrata a un campione di studenti, ottenendo per ciascuno uno score complessivo. Per semplicità, vogliamo “dichiarare positivo” lo studente se il punteggio SWLS supera una determinata soglia (ad esempio, 20 su 35). In questo modo otteniamo una variabile dicotomica (0/1), che useremo come “successo” in un modello binomiale.\n\n\nDati e conteggio dei successi\n\nCarica il dataset con le risposte SWLS.\n\nCostruisci la variabile binaria (ad esempio SWLS_dich) che vale 1 se lo score ≥ 20, e 0 altrimenti.\n\nCalcola il numero di successi (numero di persone che superano la soglia) e il numero totale di osservazioni (N).\n\n\n\nModello beta-binomiale (approccio manuale via simulazione)\n\n\nSpecifica una distribuzione Beta(a, b) come prior per la probabilità di successo \\(p\\). Scegli una coppia \\((a, b)\\) relativamente poco informativa, ad esempio (2,2) o (1,1).\n\nOsservando \\(y\\) successi su \\(n\\) soggetti, aggiorna i parametri a posteriori: \\[\n  a_{\\text{post}} = a + y,\n  \\quad\n  b_{\\text{post}} = b + (n - y).\n\\]\n\nSimula un gran numero di campioni di \\(p\\) dalla distribuzione Beta\\(\\bigl(a_{\\text{post}},\\, b_{\\text{post}}\\bigr)\\).\n\nPer ciascun campione di \\(p\\), genera un valore \\(\\tilde{y}\\) da una Binomiale\\(\\bigl(n_{\\text{new}}, p\\bigr)\\), dove \\(n_{\\text{new}}\\) è la dimensione di un ipotetico nuovo campione (che puoi scegliere, ad esempio, uguale a \\(n\\) oppure un valore diverso). Otterrai così una posterior predictive distribution per \\(\\tilde{y}\\).\n\nInfine, calcola statistiche descrittive (media, varianza, intervalli) e/o disegna un istogramma di \\(\\tilde{y}\\) o della proporzione \\(\\tilde{y}/n_{\\text{new}}\\).\n\n\n\nReplicare con brms\n\n\nUsa il pacchetto brms per costruire un modello binomiale. Per esempio:\nlibrary(brms)\n\n# Crea un data frame con la variabile dicotomica\ndf_binom &lt;- data.frame(\n  successes = y,    # conteggio dei successi\n  failures  = n - y\n)\n\n# Modello binomiale con prior Beta(a,b) approssimato tramite logit\nfit_brms &lt;- brm(\n  bf(successes | trials(n) ~ 1), \n  data = df_binom,\n  family = binomial(link = \"logit\"),\n  prior = c(\n    prior(beta(2, 2), class = \"Intercept\", dpar = \"mu\") \n    # NOTA: la specifica di una \"beta(2,2)\" diretta sull'intercetta\n    # è un'approssimazione, tipicamente serve passare a una scala logit.\n    # In brms, di solito si usa prior su scale normali dell'intercetta.\n  ),\n  seed = 123\n)\n(Le specifiche del prior potrebbero richiedere una formulazione differente se vuoi rispettare esattamente la corrispondenza con Beta(a,b). In ogni caso, l’idea è mostrare come definire un prior e costruire un modello binomiale con brms.)\n\n\nVerifica la convergenza e poi estrai la posterior predictive distribution con le funzioni di brms:\npp_check(fit_brms, nsamples = 100)\nQuesto ti mostrerà come i dati predetti dal modello (in termini di binomiale) si confrontano con i dati osservati.\n\n\n\n\nConfronto e interpretazione\n\nMetti a confronto i risultati della simulazione “manuale” (Beta-Binomial) e quelli ottenuti con brms. Noterai che le distribuzioni predittive dovrebbero essere coerenti, se hai impostato un prior per brms simile a quello del modello Beta-Binomiale.\n\nDiscuti brevemente se la distribuzione predittiva a posteriori acquisita è plausibile rispetto ai dati osservati. Ad esempio, la probabilità di osservare \\(\\tilde{y}\\) simile a \\(y\\) dovrebbe essere relativamente alta se il modello è appropriato.\n\nSe vuoi, puoi cambiare \\(n_{\\text{new}}\\) (es. previsione su 200 soggetti futuri) per vedere come la variabilità della previsione si “ridimensiona” o cresce a seconda della taglia del campione.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nCostruzione del dataset\n\n\nSe la SWLS varia tra 5 e 35, e la soglia è 20, puoi fare:\ndf$SWLS_dich &lt;- ifelse(df$SWLS_score &gt;= 20, 1, 0)\ny &lt;- sum(df$SWLS_dich)\nn &lt;- nrow(df)\n\n\n\n\nApproccio Beta-Binomial manuale\n\nPrior: \\((a, b) = (2, 2)\\)\nPosterior: \\((a_{\\text{post}}, b_{\\text{post}}) = (2 + y,\\, 2 + n - y)\\).\n\nGenerazione dei campioni:\nN_sim &lt;- 2000\np_post &lt;- rbeta(N_sim, a_post, b_post)\ny_pred &lt;- rbinom(N_sim, size = n_new, prob = p_post)\n\n# Se preferisci la proporzione futura:\nprop_pred &lt;- y_pred / n_new\n\n\nStatistiche:\nmean_p &lt;- mean(p_post) # media a posteriori di p\nquantile_p &lt;- quantile(p_post, c(0.025, 0.975))  \n\nmean_prop_pred &lt;- mean(prop_pred)\nquantile_prop_pred &lt;- quantile(prop_pred, c(0.025, 0.975))\n\n\nGrafici (istogramma e densità):\nhist(prop_pred, freq=FALSE, col='lightblue',\n     main='Posterior Predictive Distribution: prop. di successi')\n\n\n\n\nModello con brms\n\nUsa la sintassi di una binomiale con offset o con trials(n).\n\nSpecifica un prior che approssimi Beta(2,2) sullo scale logit, ad esempio:\n# Beta(2,2) ha media ~ 0.5, varianza relativamente ampia.\n# Approssimandola su scala logit ~ normal(0, 2.2) \n# (valore indicativo: la normal(0, 2) su logit copre un intervallo ampio).\n\nprior_approx &lt;- prior(normal(0, 2), class = \"Intercept\")\n\nEsegui pp_check(fit_brms) e interpreta.\n\n\n\nInterpretazione\n\nSe la soglia scelta per la SWLS cattura un “buon livello di soddisfazione”, potresti aspettarti una certa % di successi.\n\nSe i dati futuri simulati sono coerenti con i dati reali — ad esempio, la media di \\(\\tilde{y}\\) è vicina a \\(y\\) — allora il modello sembra descrivere bene la realtà. Altrimenti, potresti rivedere la soglia o la specifica del prior.\n\n\n\nL’elemento chiave è che la distribuzione predittiva a posteriori (posterior predictive distribution) non si limita a considerare un solo valore di \\(p\\), bensì campiona molteplici valori plausibili (dalla posterior), e per ciascuno simula un potenziale outcome. Così facendo, si riflette pienamente l’incertezza residua sul parametro e l’aleatorietà del processo binomiale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#pianificazione",
    "href": "chapters/eda/01_project_structure.html#pianificazione",
    "title": "13  Le fasi del progetto di analisi dei dati",
    "section": "\n13.2 Pianificazione",
    "text": "13.2 Pianificazione\nQuando ci si appresta ad affrontare un progetto complesso, è raro che i programmatori esperti inizino a scrivere codice senza una pianificazione adeguata (Gillespie & Lovelace, 2016). Al contrario, dedicano tempo a definire con cura i passaggi necessari per portare a termine il compito nel modo più efficiente possibile. Come sottolinea Berkun (2005), “una preparazione intelligente minimizza il lavoro”. Sebbene i motori di ricerca possano essere utili per identificare strategie appropriate, approcci basati su tentativi ed errori – come scrivere codice in modo casuale e cercare soluzioni ai messaggi di errore che ne derivano – risultano generalmente inefficienti e dispendiosi in termini di tempo.\nIl pensiero strategico nelle fasi iniziali di un progetto è cruciale. Le decisioni prese in questo momento possono avere ripercussioni a cascata sull’intero ciclo di vita del progetto. Scelte sbagliate o affrettate possono generare problemi difficili da correggere, con conseguenze negative sull’efficacia, la sostenibilità e la qualità del lavoro. Nel contesto dello sviluppo software, questo fenomeno è stato definito “debito tecnico” (Kruchten et al., 2012), ovvero “codice non del tutto corretto che rimandiamo di sistemare”. Accumulare debito tecnico significa aumentare la probabilità di dover intervenire costantemente in futuro, con un impatto significativo su costi, tempi e qualità del risultato finale.\nPer minimizzare il debito tecnico, il punto di partenza ideale è spesso rappresentato da strumenti semplici, come carta e penna, uniti a una mente aperta e creativa. Abbozzare idee e definire con precisione gli obiettivi, senza farsi imbrigliare dai vincoli di una specifica tecnologia, è un esercizio estremamente utile prima di iniziare a scrivere codice. In questa fase, la definizione della “visione” del progetto è un processo che richiede creatività e riflessione, indipendenti dai limiti del software scelto per l’implementazione. Una volta chiariti gli obiettivi, i requisiti e le sfide, diventa più agevole selezionare tecnologie e strumenti adeguati, valutando aspetti quali scalabilità, manutenibilità e compatibilità con le esigenze future.\nSolo una pianificazione oculata può ridurre il rischio di errori e assicurare che il progetto sia sostenibile nel lungo termine, prevenendo l’accumulo di debiti tecnici e aumentando l’efficienza complessiva del lavoro.\n\n13.2.1 Cinque suggerimenti per un workflow efficiente\nGillespie & Lovelace (2016) presentano cinque suggerimenti per un workflow efficiente:\n\n\nInizia senza scrivere codice, ma con una mente chiara e possibilmente carta e penna. Questo ti aiuterà a mantenere gli obiettivi al centro dell’attenzione, senza farti distrarre dalla tecnologia.\n\n\nFai un piano. Le dimensioni e la natura del piano dipenderanno dal progetto, ma definire tempistiche, risorse e suddividere il lavoro in “blocchi” ti renderà più efficace quando inizierai.\n\n\nSeleziona i pacchetti che utilizzerai per implementare il piano in anticipo. Minuti spesi nella ricerca e selezione delle opzioni disponibili potrebbero farti risparmiare ore in futuro.\n\n\nDocumenta il tuo lavoro in ogni fase. Il lavoro può essere efficace solo se comunicato chiaramente, e il codice può essere compreso in modo efficiente solo se commentato.\n\n\nRendi l’intero workflow il più riproducibile possibile. Strumenti come Quarto possono aiutarti in questa fase di documentazione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#stima-e-inferenza-statistica-dal-campione-alla-popolazione",
    "href": "chapters/key_notions/02_key_notions.html#stima-e-inferenza-statistica-dal-campione-alla-popolazione",
    "title": "1  Concetti chiave",
    "section": "1.5 Stima e Inferenza Statistica: Dal Campione alla Popolazione",
    "text": "1.5 Stima e Inferenza Statistica: Dal Campione alla Popolazione\nLa stima e l’inferenza statistica costituiscono i pilastri della metodologia quantitativa, poiché permettono di estendere le conclusioni tratte da un campione – una porzione limitata di individui osservati – all’intera popolazione di interesse. L’uso dei campioni risulta indispensabile a causa dei vincoli di tempo, costi e risorse, che spesso rendono impossibile lo studio dell’intera popolazione.\nTuttavia, il ricorso al campione introduce inevitabilmente un’incertezza intrinseca: le statistiche campionarie (come media o varianza del campione) sono stime dei parametri della popolazione e di norma non coincidono esattamente con i valori “veri” della popolazione. Tale discrepanza è nota come errore di campionamento, la cui entità dipende, tra l’altro, dalla dimensione del campione e dalla strategia di campionamento adottata.\nLa teoria degli stimatori e gli strumenti di inferenza statistica (ad esempio, intervalli di confidenza in un approccio frequentista o intervalli di credibilità in un approccio bayesiano) consentono di quantificare e gestire quest’incertezza, fornendo un quadro che permette di trarre conclusioni rigorose sulla popolazione partendo dai dati raccolti.\n\n1.5.1 Stima: Inferire le Caratteristiche della Popolazione\nLa stima è il processo con cui si utilizzano i dati di un campione per dedurre le proprietà della popolazione, come la media o la varianza. Ogni campione rappresenta solo una frazione della popolazione e può produrre stime diverse, fenomeno definito variabilità campionaria. Questa variabilità è la principale fonte di incertezza nelle inferenze: se un singolo campione non è sufficientemente numeroso o rappresentativo, la stima potrebbe allontanarsi dai valori reali della popolazione.\n\n1.5.1.1 Fattori che Influenzano l’Accuratezza\nTre fattori fondamentali influiscono sull’accuratezza di una stima:\n\nDimensione del campione\nUn campione più grande tende a ridurre la variabilità campionaria, aumentando la precisione delle stime.\nRappresentatività\nUn campione ben progettato e rappresentativo rispecchia le caratteristiche essenziali della popolazione. Al contrario, un campione distorto (ad esempio, selezionato per convenienza) può condurre a stime fuorvianti.\nVariabilità della popolazione\nSe la popolazione è estremamente eterogenea, sono necessari campioni più ampi per produrre stime affidabili.\n\n\n\n1.5.1.2 Gli Stimatori: Proprietà Fondamentali\nGli stimatori sono formule matematiche o procedure statistiche usate per calcolare le stime. La loro qualità si valuta principalmente in base a:\n\nConsistenza\nUno stimatore è consistente se, all’aumentare della dimensione del campione, la stima tende a convergere verso il valore reale del parametro.\nNon distorsione (unbiasedness)\nUno stimatore è non distorto se il suo valore atteso corrisponde al parametro della popolazione. In altri termini, in media, lo stimatore coincide con il valore reale.\nEfficienza\nTra stimatori non distorti, è più efficiente quello con varianza minore, poiché fornisce stime più stabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#inferenza-statistica",
    "href": "chapters/key_notions/02_key_notions.html#inferenza-statistica",
    "title": "1  Concetti chiave",
    "section": "1.6 Inferenza Statistica",
    "text": "1.6 Inferenza Statistica\nL’inferenza statistica si basa sulle stime campionarie per trarre conclusioni sull’intera popolazione. In particolare, risponde a tre grandi interrogativi:\n\nStima dei parametri della popolazione\nOttenere valori plausibili per parametri quali media, varianza e proporzioni, quantificando contestualmente l’incertezza (ad esempio, costruendo intervalli di confidenza o di credibilità).\nValutazione di ipotesi (hypothesis testing)\nConfrontare ipotesi rivali, come l’esistenza di differenze tra gruppi o di relazioni tra variabili. Attraverso il confronto tra ipotesi e dati, si determina quale ipotesi è meglio supportata.\nPrevisione\nUtilizzare i dati esistenti per anticipare risultati futuri, tenendo conto delle fonti di incertezza legate sia alla variabilità intrinseca dei dati sia ai parametri non perfettamente noti.\n\nSia l’approccio frequentista sia quello bayesiano affrontano questi problemi in modo rigoroso, ma differiscono nel modo di concettualizzare l’incertezza e di incorporare l’informazione nei modelli.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#esercizi",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#esercizi",
    "title": "69  Introduzione all’inferenza frequentista",
    "section": "\n69.8 Esercizi",
    "text": "69.8 Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nParte 1: Popolazione di Piccole Dimensioni Si consideri una popolazione con i seguenti valori:\n\\[\nx = \\{2, 4.5, 5, 5.5\\}\n\\]\n\nCalcolare la media e la varianza della popolazione.\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) con ripetizione e calcolare la media di ciascun campione.\nRappresentare graficamente la distribuzione campionaria delle medie.\nCalcolare la probabilità che la media campionaria sia inferiore a 3:\n\nEsattamente, utilizzando la distribuzione campionaria.\nApprossimativamente, assumendo una distribuzione normale se il campione fosse sufficientemente grande.\n\n\n\nParte 2: Popolazione di Grandi Dimensioni\nSi consideri ora una popolazione più grande, generata da una distribuzione normale con media \\(\\mu = 10\\) e deviazione standard \\(\\sigma = 3\\).\n\nGenerare una popolazione di 1000 osservazioni.\nCalcolare la media e la varianza della popolazione.\nEstrarre 10.000 campioni casuali di ampiezza \\(n = 15\\) e calcolare la media campionaria per ciascun campione.\nRappresentare graficamente la distribuzione campionaria delle medie.\nCalcolare la probabilità che la media campionaria sia inferiore a 9:\n\nEsattamente, utilizzando la distribuzione campionaria.\nApprossimativamente, utilizzando la distribuzione normale.\n\n\n\nObiettivo: Verificare sperimentalmente le proprietà della distribuzione campionaria della media e confrontare i risultati con le previsioni teoriche fornite dal Teorema del Limite Centrale.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nProprietà della Distribuzione Campionaria della Media\n\nMedia: La media della distribuzione campionaria coincide con la media della popolazione:\nVarianza: La varianza della distribuzione campionaria è pari alla varianza della popolazione divisa per la dimensione del campione:\nForma:\n\n\nSe la popolazione segue una distribuzione normale, anche la distribuzione campionaria della media sarà normale.\nSe la popolazione non è normale, il Teorema del Limite Centrale garantisce che la distribuzione campionaria della media sarà approssimativamente normale per campioni di dimensioni sufficientemente grandi (\\(n \\geq 30\\)).\n\nDefiniamo una popolazione e calcoliamo i parametri:\n\n# Popolazione\nx &lt;- c(2, 4.5, 5, 5.5)\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nvar(x)   # Varianza della popolazione\n#&gt; [1] 2.417\n\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) e calcolare la media di ciascun campione:\n\n# Tutti i campioni di ampiezza 2\nsamples &lt;- expand.grid(x, x)\nsample_means &lt;- rowMeans(samples)\n\n# Visualizzare la distribuzione campionaria\ndf &lt;- data.frame(sample_means = sample_means)\n\nggplot(df, aes(x = sample_means)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 5, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria delle medie\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCalcoliamo la probabilità che, all’interno della distribuzione campionaria, la media del campione sia minore di 3. Troviamo il valore esatto nella simulazione. Approssimiamo il valore esatto con il valore atteso se il campione fosse sufficientemente grande da poter assumere una distribuzione campionaria normale:\n\n# Probabilità esatta dalla distribuzione campionaria\nexact_probability &lt;- mean(sample_means &lt; 3)\nexact_probability\n#&gt; [1] 0.0625\n\n# Approssimazione tramite distribuzione normale\nmu &lt;- mean(x)  # Media della popolazione\nsigma &lt;- sqrt(var(x) / 2)  # Deviazione standard della distribuzione campionaria\napprox_probability &lt;- pnorm(3, mean = mu, sd = sigma)\napprox_probability\n#&gt; [1] 0.1277\n\nRipetiamo ora l’esempio, mantenendo la stessa struttura della simulazione, ma considerando una popolazione più grande tale per cui si possa estrarre un campione di ampiezza 15:\n\n# Nuova popolazione\nset.seed(123)\nx_large &lt;- rnorm(1000, mean = 10, sd = 3)  # Popolazione più grande\nmean(x_large)  # Media della popolazione\n#&gt; [1] 10.05\nvar(x_large)   # Varianza della popolazione\n#&gt; [1] 8.851\n\n# Estrazione di campioni di ampiezza 15\nsamples_large &lt;- replicate(10000, mean(sample(x_large, size = 15)))\n\n# Creazione del data frame per ggplot2\ndf_large &lt;- data.frame(sample_means = samples_large)\n\n# Visualizzazione con ggplot2\nggplot(df_large, aes(x = sample_means)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria delle medie (n = 15)\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n# Probabilità esatta dalla simulazione\nexact_probability_large &lt;- mean(samples_large &lt; 9)\nexact_probability_large\n#&gt; [1] 0.0834\n\n\n# Approssimazione tramite distribuzione normale\nmu_large &lt;- mean(x_large)\nsigma_large &lt;- sqrt(var(x_large) / 15)\napprox_probability_large &lt;- pnorm(9, mean = mu_large, sd = sigma_large)\napprox_probability_large\n#&gt; [1] 0.08616\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nDistribuzione Campionaria della Differenza tra Medie\nL’obiettivo di questo esercizio è esplorare le proprietà della distribuzione campionaria della differenza tra medie campionarie, analizzando sia il caso di popolazioni finite di piccole dimensioni sia il caso di popolazioni più grandi, con distribuzioni normali.\nEsercizio 1: Simulazione con Popolazioni di Piccole Dimensioni\nConsideriamo due popolazioni finite composte da un numero limitato di elementi:\n\n\nPopolazione 1: \\(x_1 = \\{2, 4.5, 5, 6\\}\\)\n\n\nPopolazione 2: \\(x_2 = \\{3, 3.5, 4, 7\\}\\)\n\n\n\n69.8.0.1 Compiti:\n\n\n\nCalcolo dei parametri delle popolazioni:\n\nDeterminare la media e la varianza di entrambe le popolazioni.\n\n\n\nEstrazione di campioni:\n\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) con ripetizione da entrambe le popolazioni.\nCalcolare la media campionaria di ciascun campione.\n\n\n\nDistribuzione campionaria della differenza tra le medie:\n\nCalcolare la differenza tra le medie di tutti i possibili campioni ottenuti dalle due popolazioni.\nRappresentare graficamente la distribuzione della differenza tra le medie.\n\n\n\nProbabilità della differenza tra le medie:\n\nCalcolare la probabilità che la differenza tra le medie campionarie sia maggiore di 1.\n\n\n\nEsercizio 2: Simulazione con Popolazioni di Grande Dimensione\nConsideriamo ora due popolazioni più grandi, distribuite normalmente:\n\n\nPopolazione 1: \\(X_1 \\sim N(10, 4^2)\\) (media = 10, deviazione standard = 4)\n\nPopolazione 2: \\(X_2 \\sim N(8, 3^2)\\) (media = 8, deviazione standard = 3)\n\nCompiti:\n\n\nGenerazione delle popolazioni:\n\nCreare due popolazioni casuali di 10.000 osservazioni ciascuna, distribuite normalmente.\n\n\n\nEstrazione di campioni:\n\nEstrarre 10.000 campioni casuali di ampiezza \\(n_1 = 15\\) dalla prima popolazione e \\(n_2 = 20\\) dalla seconda popolazione.\nCalcolare la media di ciascun campione.\n\n\n\nDistribuzione campionaria della differenza tra le medie:\n\nCalcolare la differenza tra le medie campionarie ottenute dalle due popolazioni.\nRappresentare graficamente la distribuzione della differenza tra le medie.\n\n\n\nProbabilità della differenza tra le medie:\n\nCalcolare la probabilità che la differenza tra le medie campionarie sia maggiore di 2 in due modi:\n\n\nMetodo empirico: utilizzando la distribuzione ottenuta nella simulazione.\n\nMetodo teorico: approssimando la distribuzione con una normale e calcolando la probabilità con la formula teorica della varianza della differenza tra le medie.\n\n\n\n\n\nDomande di Discussione\n\nCome cambia la forma della distribuzione campionaria al variare delle dimensioni dei campioni \\(n_1\\) e \\(n_2\\)?\nLa probabilità stimata tramite simulazione coincide con quella calcolata utilizzando l’approssimazione normale? Perché?\nCosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali? Quale sarebbe il ruolo del Teorema del Limite Centrale?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 1: Simulazione con Popolazioni di Piccola Dimensione\nSupponiamo di avere due popolazioni finite definite come segue:\n\nPopolazione 1: \\(x_1 = \\{2, 4.5, 5, 6\\}\\)\n\nPopolazione 2: \\(x_2 = \\{3, 3.5, 4, 7\\}\\)\n\n\n\nCalcola le medie e le varianze delle due popolazioni:\n\n\n# Popolazione 1\nx1 &lt;- c(2, 4.5, 5, 6)\nmean(x1)  # Media di x1\n#&gt; [1] 4.375\nvar(x1)   # Varianza di x1\n#&gt; [1] 2.896\n\n\n# Popolazione 2\nx2 &lt;- c(3, 3.5, 4, 7)\nmean(x2)  # Media di x2\n#&gt; [1] 4.375\nvar(x2)   # Varianza di x2\n#&gt; [1] 3.229\n\n\nEstrai tutti i possibili campioni di ampiezza \\(n = 2\\) da entrambe le popolazioni:\n\n\n# Tutti i campioni di ampiezza 2\nsamples1 &lt;- expand.grid(x1, x1)\nsamples2 &lt;- expand.grid(x2, x2)\n\n# Medie campionarie\nsample_means1 &lt;- rowMeans(samples1)\nsample_means2 &lt;- rowMeans(samples2)\n\n\nCalcola la differenza tra le medie campionarie di ciascuna combinazione di campioni:\n\n\n# Differenze tra le medie campionarie\nsample_diff &lt;- as.vector(outer(sample_means1, sample_means2, \"-\"))\n\n\nVisualizza la distribuzione campionaria della differenza tra le medie:\n\n\n# Istogramma della differenza tra medie campionarie\n\n# Creazione del data frame per ggplot2\ndf_diff &lt;- data.frame(sample_diff = sample_diff)\n\n# Visualizzazione con ggplot2\nggplot(df_diff, aes(x = sample_diff)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 10, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra medie\",\n    x = \"Differenza campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\nCalcola la probabilità che la differenza campionaria sia maggiore di 1:\n\n\n# Probabilità esatta dalla distribuzione campionaria\nexact_probability &lt;- mean(sample_diff &gt; 1)\nexact_probability\n#&gt; [1] 0.2656\n\nEsercizio 2: Simulazione con Popolazioni di Grande Dimensione\nOra considera due popolazioni più grandi con distribuzioni normali:\n\nPopolazione 1: \\(X_1 \\sim N(10, 4^2)\\)\n\nPopolazione 2: \\(X_2 \\sim N(8, 3^2)\\)\n\n\n\nGenera due popolazioni casuali:\n\n\nset.seed(123)\npop1 &lt;- rnorm(10000, mean = 10, sd = 4)\npop2 &lt;- rnorm(10000, mean = 8, sd = 3)\n\n\nEstrai 10.000 campioni casuali di ampiezza \\(n_1 = 15\\) e \\(n_2 = 20\\) rispettivamente:\n\n\n# Estrazione di campioni e calcolo delle medie\nsample_means1 &lt;- replicate(10000, mean(sample(pop1, size = 15)))\nsample_means2 &lt;- replicate(10000, mean(sample(pop2, size = 20)))\n\n\nCalcola la differenza tra le medie campionarie:\n\n\n# Differenze tra medie campionarie\nsample_diff_large &lt;- sample_means1 - sample_means2\n\n\nVisualizza la distribuzione campionaria della differenza tra le medie:\n\n\n# Istogramma della distribuzione campionaria\n\n# Creazione del data frame per ggplot2\ndf_diff_large &lt;- data.frame(sample_diff = sample_diff_large)\n\n# Visualizzazione con ggplot2\nggplot(df_diff_large, aes(x = sample_diff)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra medie (n1 = 15, n2 = 20)\",\n    x = \"Differenza campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n\nCalcola la probabilità che la differenza campionaria sia maggiore di 2 utilizzando:\n\nla simulazione;\nl’approssimazione normale.\n\n\n\n\n# Probabilità esatta\nexact_probability_large &lt;- mean(sample_diff_large &gt; 2)\nexact_probability_large\n#&gt; [1] 0.505\n\n\n# Approssimazione normale\nmu_diff &lt;- 10 - 8  # Differenza tra le medie delle popolazioni\nsigma_diff &lt;- sqrt(4^2 / 15 + 3^2 / 20)  # Deviazione standard della differenza\napprox_probability_large &lt;- 1 - pnorm(2, mean = mu_diff, sd = sigma_diff)\napprox_probability_large\n#&gt; [1] 0.5\n\nDomande di Discussione.\n\nCome cambia la forma della distribuzione campionaria al variare delle dimensioni campionarie \\(n_1\\) e \\(n_2\\)?\nLa probabilità calcolata tramite simulazione coincide con quella calcolata tramite approssimazione normale? Perché?\nCosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali?\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nProblema: Distribuzione Campionaria di una Proporzione\nL’obiettivo di questo esercizio è esplorare la distribuzione campionaria di una proporzione campionaria \\(\\hat{p}\\) e verificare l’applicabilità dell’approssimazione normale per grandi dimensioni campionarie, come previsto dal Teorema del Limite Centrale.\nSituazione\nSupponiamo di avere una popolazione infinita in cui ciascun individuo può appartenere a una di due categorie: “successo” (codificato come 1) o “insuccesso” (codificato come 0). La probabilità di successo nella popolazione è data da \\(p = 0.6\\).\nCompiti\n\n\nDefinizione della popolazione e dei parametri:\n\nLa popolazione ha una proporzione di successi pari a \\(p = 0.6\\).\nLa deviazione standard teorica della distribuzione campionaria della proporzione è calcolata come:\\[\n\\text{SD}(\\hat{p}) = \\sqrt{\\frac{p(1 - p)}{n}}\n\\]\n\nSi fissi una dimensione campionaria pari a \\(n = 100\\).\n\n\n\nSimulazione di campioni:\n\nGenerare 10.000 campioni casuali di ampiezza \\(n = 100\\).\nPer ogni campione, calcolare la proporzione campionaria \\(\\hat{p}\\), cioè la frazione di successi nel campione.\n\n\n\nDistribuzione campionaria delle proporzioni:\n\nRappresentare graficamente la distribuzione delle proporzioni campionarie con un istogramma.\nSovrapporre la distribuzione normale teorica \\(N(p, \\text{SD}(\\hat{p}))\\) per confrontare l’andamento empirico con quello teorico.\n\n\n\nAnalisi della distribuzione:\n\nValutare se la distribuzione campionaria ottenuta rispetta l’approssimazione normale.\nRiflettere su come la dimensione del campione e il valore di \\(p\\) influenzano questa approssimazione.\n\n\n\nDomande di Discussione\n\nLa distribuzione campionaria delle proporzioni \\(\\hat{p}\\) sembra approssimarsi a una distribuzione normale? Perché?\nCosa accadrebbe se la dimensione del campione fosse più piccola, ad esempio \\(n = 30\\)?\nSe la probabilità di successo \\(p\\) fosse molto vicina a 0 o 1, l’approssimazione normale sarebbe ancora valida? Perché?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nLa distribuzione campionaria di una proporzione descrive come la proporzione campionaria (\\(\\hat{p}\\)) varia tra campioni di una popolazione. Per campioni grandi, il Teorema del Limite Centrale garantisce che la distribuzione campionaria di \\(\\hat{p}\\) può essere approssimata con una distribuzione normale.\n\n\nSupponiamo una popolazione infinita in cui la probabilità di successo (\\(p\\)) è \\(p = 0.6\\). Scegli una dimensione campionaria \\(n = 100\\).\nSimula 10.000 campioni casuali di ampiezza \\(n\\) e calcola le proporzioni campionarie (\\(\\hat{p}\\)).\nConfronta l’istogramma delle proporzioni campionarie con la distribuzione normale teorica approssimativa.\n\n\n# Parametri della popolazione\np &lt;- 0.6  # Probabilità di successo nella popolazione\nn &lt;- 100  # Dimensione del campione\n\n# Simulazione di 10.000 campioni\nset.seed(123)\nsample_props &lt;- replicate(10000, mean(rbinom(n, size = 1, prob = p)))\n\n# Creazione di un data frame per ggplot2\ndf_props &lt;- data.frame(sample_props = sample_props)\n\n# Parametri della distribuzione normale teorica\nmean_theoretical &lt;- p\nsd_theoretical &lt;- sqrt(p * (1 - p) / n)\n\n# Visualizzazione con ggplot2\nggplot(df_props, aes(x = sample_props)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 40, fill = \"blue\", alpha = 0.6) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_theoretical, sd = sd_theoretical),\n    color = \"red\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione campionaria di una proporzione (n = 100)\",\n    x = \"Proporzione campionaria (\\u0302p)\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n\nPopolazione e parametri:\n\nLa popolazione è definita da \\(p = 0.6\\).\nLa deviazione standard teorica della distribuzione campionaria è calcolata come \\(\\text{SD}(\\hat{p}) = \\sqrt{\\frac{p(1-p)}{n}}\\).\n\n\n\nSimulazione:\n\nPer ogni campione, i successi (\\(0\\) o \\(1\\)) sono generati con rbinom, e la proporzione campionaria \\(\\hat{p}\\) è calcolata come media.\n\n\n\nGrafico:\n\nL’istogramma delle proporzioni campionarie è sovrapposto alla curva normale teorica (\\(N(p, \\text{SD}(\\hat{p}))\\)).\n\n\n\nDomande di Discussione.\n\nLa distribuzione campionaria di \\(\\hat{p}\\) sembra approssimarsi a una distribuzione normale? Perché?\nCosa accadrebbe se \\(n\\) fosse più piccolo (es. \\(n = 30\\))?\nSe \\(p\\) fosse più vicino a \\(0\\) o \\(1\\), l’approssimazione normale sarebbe ancora valida? Spiega.\n\n\n\n\n\n\n\n\n\n\nProblemi 4\n\n\n\n\n\nProblema: Distribuzione Campionaria della Differenza tra Due Proporzioni\nL’obiettivo di questo esercizio è esplorare la distribuzione campionaria della differenza tra due proporzioni campionarie, \\(\\hat{p}_1 - \\hat{p}_2\\), ottenute da due campioni indipendenti estratti da popolazioni diverse. Per campioni sufficientemente grandi, il Teorema del Limite Centrale garantisce che la distribuzione di \\(\\hat{p}_1 - \\hat{p}_2\\) può essere approssimata con una distribuzione normale.\nSituazione\nAbbiamo due popolazioni con proporzioni di successo diverse:\n\n\nPopolazione 1 ha una proporzione di successo \\(p_1 = 0.6\\).\n\nPopolazione 2 ha una proporzione di successo \\(p_2 = 0.4\\).\n\nVogliamo studiare il comportamento della distribuzione campionaria della differenza tra le proporzioni campionarie quando preleviamo campioni indipendenti da ciascuna popolazione.\nCompiti\n\n\nDefinizione delle popolazioni e dei parametri:\n\nLa proporzione di successi nelle due popolazioni è \\(p_1 = 0.6\\) e \\(p_2 = 0.4\\).\nEntrambi i campioni hanno dimensione \\(n_1 = n_2 = 150\\).\nLa deviazione standard teorica della distribuzione campionaria della differenza tra proporzioni è calcolata come: \\[\n\\text{SD}(\\hat{p}_1 - \\hat{p}_2) = \\sqrt{\\frac{p_1 (1-p_1)}{n_1} + \\frac{p_2 (1-p_2)}{n_2}}\n\\]\n\n\n\n\nSimulazione di campioni:\n\nGenerare 10.000 campioni indipendenti di ampiezza \\(n_1 = 150\\) dalla prima popolazione e \\(n_2 = 150\\) dalla seconda popolazione.\nCalcolare la proporzione campionaria \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) per ciascun campione.\nCalcolare la differenza tra le proporzioni campionarie.\n\n\n\nDistribuzione campionaria della differenza tra le proporzioni:\n\nRappresentare graficamente la distribuzione di \\(\\hat{p}_1 - \\hat{p}_2\\) con un istogramma.\nSovrapporre la distribuzione normale teorica \\(N(p_1 - p_2, \\text{SD}(\\hat{p}_1 - \\hat{p}_2))\\) per confrontare l’andamento empirico con quello teorico.\n\n\n\nCalcolo della probabilità che la differenza tra proporzioni sia maggiore di un valore specifico:\n\n\nMetodo empirico: calcolare la proporzione di campioni in cui \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\n\nMetodo teorico: utilizzare la distribuzione normale approssimata per stimare la probabilità che \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\n\n\n\nDomande di Discussione\n\nL’approssimazione normale è valida in questo caso? Perché?\nCome cambierebbe la distribuzione campionaria se la dimensione del campione \\(n_1\\) o \\(n_2\\) fosse più piccola?\nSe i valori di \\(p_1\\) o \\(p_2\\) fossero più vicini a 0 o 1, come cambierebbe la probabilità calcolata e l’accuratezza dell’approssimazione normale?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 4\n\n\n\n\n\nLa distribuzione campionaria della differenza tra due proporzioni (\\(\\hat{p}_1 - \\hat{p}_2\\)) descrive come la differenza tra le proporzioni campionarie varia tra due campioni indipendenti estratti da due popolazioni.\nPer campioni grandi, il Teorema del Limite Centrale garantisce che \\(\\hat{p}_1 - \\hat{p}_2\\) segue approssimativamente una distribuzione normale con media e varianza calcolate dalle proporzioni della popolazione.\nObiettivo:\n\nSimulare due popolazioni con proporzioni \\(p_1\\) e \\(p_2\\).\nEstrarre campioni indipendenti da ciascuna popolazione.\nCalcolare la distribuzione campionaria di \\(\\hat{p}_1 - \\hat{p}_2\\).\nCalcolare la probabilità che la differenza campionaria sia maggiore di un valore specifico (es. \\(0.1\\)).\n\nParametri del Problema:\n\nPopolazione 1: \\(p_1 = 0.6\\)\n\nPopolazione 2: \\(p_2 = 0.4\\)\n\nDimensione campionaria: \\(n_1 = n_2 = 150\\)\n\nValore specifico: \\(0.1\\)\n\n\n\n# Parametri delle due popolazioni\np1 &lt;- 0.6  # Proporzione di successi nella Popolazione 1\np2 &lt;- 0.4  # Proporzione di successi nella Popolazione 2\nn1 &lt;- 150  # Dimensione campionaria per la Popolazione 1\nn2 &lt;- 150  # Dimensione campionaria per la Popolazione 2\n\n# Simulazione di 10.000 campioni indipendenti\nset.seed(123)\nsample_p1 &lt;- replicate(10000, mean(rbinom(n1, size = 1, prob = p1)))\nsample_p2 &lt;- replicate(10000, mean(rbinom(n2, size = 1, prob = p2)))\n\n# Calcolo della differenza tra proporzioni campionarie\nsample_diff &lt;- sample_p1 - sample_p2\n\n# Parametri teorici della distribuzione normale approssimata\nmean_diff &lt;- p1 - p2\nsd_diff &lt;- sqrt((p1 * (1 - p1) / n1) + (p2 * (1 - p2) / n2))\n\n# Creazione del data frame per ggplot2\ndf_diff &lt;- data.frame(sample_diff = sample_diff)\n\n# Visualizzazione con ggplot2\nggplot(df_diff, aes(x = sample_diff)) +\n  geom_histogram(\n    aes(y = after_stat(density)), bins = 40, fill = \"blue\", alpha = 0.6\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_diff, sd = sd_diff),\n    color = \"red\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra proporzioni\",\n    x = \"Differenza campionaria (p1 - p2)\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n# Calcolo della probabilità che la differenza sia maggiore di 0.1\nexact_probability &lt;- mean(sample_diff &gt; 0.1)\nexact_probability\n#&gt; [1] 0.9599\n\n\n# Approssimazione tramite distribuzione normale\napprox_probability &lt;- 1 - pnorm(0.1, mean = mean_diff, sd = sd_diff)\napprox_probability\n#&gt; [1] 0.9615\n\n\n\nParametri delle popolazioni:\n\nDue popolazioni con proporzioni \\(p_1 = 0.6\\) e \\(p_2 = 0.4\\).\nDimensioni campionarie \\(n_1 = n_2 = 150\\).\n\n\n\nSimulazione:\n\nPer ogni campione, i successi (\\(0\\) o \\(1\\)) sono generati con rbinom.\nCalcoliamo le proporzioni campionarie e la differenza tra di esse.\n\n\n\nDistribuzione teorica:\n\nMedia teorica: \\(p_1 - p_2\\).\nDeviazione standard teorica: \\(\\sqrt{\\frac{p_1 (1-p_1)}{n_1} + \\frac{p_2 (1-p_2)}{n_2}}\\).\n\n\n\nVisualizzazione:\n\nUn istogramma di \\(\\hat{p}_1 - \\hat{p}_2\\) sovrapposto alla curva della distribuzione normale teorica.\n\n\n\nCalcolo della probabilità:\n\nProbabilità esatta dalla simulazione: proporzione di \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\nProbabilità approssimata dalla distribuzione normale.\n\n\n\nDomande di Discussione.\n\nL’approssimazione normale è valida in questo caso? Perché?\nCome cambierebbe la distribuzione campionaria se \\(n_1\\) o \\(n_2\\) fossero più piccoli?\nCome influenzerebbe la probabilità calcolata un valore \\(p_1\\) o \\(p_2\\) più vicino a \\(0\\) o \\(1\\)?",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#esercizi",
    "href": "chapters/frequentist_inference/02_conf_interv.html#esercizi",
    "title": "70  Intervalli di fiducia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nChe cos’è un intervallo di confidenza dal punto di vista frequentista?\nChe cosa significa la copertura al 95% di un intervallo di confidenza?\nPerché non è corretto dire che “c’è il 95% di probabilità che il valore vero di \\(\\mu\\) cada in questo intervallo di confidenza”?\nIn cosa consiste la differenza tra un intervallo di confidenza costruito con la distribuzione normale standard \\(Z\\) e uno costruito con la distribuzione \\(t\\) di Student?\nPerché, nel caso di varianza incognita, si usa la deviazione standard campionaria \\(s\\) al posto di \\(\\sigma\\)?\nCome influenza la dimensione del campione \\(n\\) l’ampiezza dell’intervallo di confidenza?\nPerché gli intervalli di confidenza frequentisti si basano su un concetto di “ripetizione dell’esperimento” nel lungo periodo?\nQuali sono due fraintendimenti comuni sugli intervalli di confidenza?\nCome si interpreta correttamente un intervallo di confidenza al 95%?\nQual è la differenza essenziale tra un intervallo di confidenza frequentista e un intervallo di credibilità bayesiano?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nChe cos’è un intervallo di confidenza dal punto di vista frequentista?\n\nRisposta\nUn intervallo di confidenza (IC) è un range di valori costruito attorno a una stima campionaria (ad esempio, la media campionaria) che, secondo il metodo frequentista adottato, conterrà il valore vero del parametro in una certa proporzione di casi (ad esempio il 95%) se si ripetesse l’esperimento (ossia il campionamento) un numero molto grande di volte. Non esprime dunque la “probabilità” che il parametro sia dentro l’intervallo in un singolo caso, ma una frequenza di successo nel lungo periodo.\n\nChe cosa significa la copertura al 95% di un intervallo di confidenza?\n\nRisposta\nIl livello di copertura (ad esempio, 95%) indica che, in una serie ipotetica di infiniti campioni indipendenti e nel calcolo ripetuto di infiniti intervalli di confidenza secondo la stessa procedura, il 95% di tali intervalli conterrà il valore vero del parametro. È una proprietà della procedura di costruzione degli intervalli, non di un singolo intervallo già calcolato.\n\nPerché non è corretto dire che “c’è il 95% di probabilità che il valore vero di \\(\\mu\\) cada in questo intervallo di confidenza”?\n\nRisposta\nNella prospettiva frequentista, il parametro \\(\\mu\\) è considerato un valore fisso (non una variabile casuale). L’incertezza risiede nel campione e nella procedura di costruzione dell’intervallo, non nel parametro. Di conseguenza, non si può associare una probabilità alla posizione di \\(\\mu\\) all’interno di un singolo intervallo: l’intervallo o contiene \\(\\mu\\) oppure no, senza mezze misure probabilistiche.\n\nIn cosa consiste la differenza tra un intervallo di confidenza costruito con la distribuzione normale standard \\(Z\\) e uno costruito con la distribuzione \\(t\\) di Student?\n\nRisposta\n- Distribuzione \\(Z\\): si utilizza quando la varianza della popolazione \\(\\sigma^2\\) è nota (o si approssima molto bene) e la popolazione è normalmente distribuita, o quando il campione è molto grande (per applicare il teorema del limite centrale).\n- Distribuzione \\(t\\): si impiega quando la varianza \\(\\sigma^2\\) non è nota e bisogna stimarla con la deviazione standard campionaria \\(s\\). La distribuzione \\(t\\) “corregge” per l’incertezza aggiuntiva dovuta alla stima di \\(\\sigma\\) e diventa progressivamente simile alla normale standard quando il numero di gradi di libertà (cioè la dimensione del campione meno uno) è elevato.\n\nPerché, nel caso di varianza incognita, si usa la deviazione standard campionaria \\(s\\) al posto di \\(\\sigma\\)?\n\nRisposta\nQuando \\(\\sigma\\) non è nota, la si sostituisce con la stima campionaria \\(s\\). Poiché \\(s\\) è anch’essa una variabile casuale (cioè dipende dai dati osservati), introduce un’ulteriore fonte di incertezza. Questo giustifica l’uso della distribuzione \\(t\\) di Student anziché della normale standard, poiché \\(t\\) ingloba tale incertezza aggiuntiva.\n\nCome influenza la dimensione del campione \\(n\\) l’ampiezza dell’intervallo di confidenza?\n\nRisposta\nAumentando \\(n\\), l’errore standard della media (cioè \\(\\frac{\\sigma}{\\sqrt{n}}\\) oppure \\(\\frac{s}{\\sqrt{n}}\\)) diminuisce. Di conseguenza, l’intervallo di confidenza si restringe (a parità di livello di confidenza). In altre parole, con più dati a disposizione la stima della media è più “precisa” nel senso frequentista, e ciò si riflette in un IC più stretto.\n\nPerché gli intervalli di confidenza frequentisti si basano su un concetto di “ripetizione dell’esperimento” nel lungo periodo?\n\nRisposta\nLa filosofia frequentista definisce la probabilità come una frequenza relativa di un evento dopo molteplici repliche dell’esperimento. Per gli intervalli di confidenza, ciò implica che la probabilità di copertura (ad esempio 95%) è intesa come la frequenza con cui, ripetendo infinite volte il campionamento e la costruzione di IC allo stesso modo, l’intervallo calcolato conterrà il vero parametro. Non riguarda invece la probabilità del parametro di trovarsi in un intervallo specifico.\n\nQuali sono due fraintendimenti comuni sugli intervalli di confidenza?\n\nRisposta\n1. Credere che l’IC fornisca una probabilità diretta di contenere il parametro (es. “c’è il 95% di probabilità che \\(\\mu\\) sia qui dentro”) – in realtà, nel frequentismo \\(\\mu\\) è fisso e l’IC varia.\n2. Pensare che l’intervallo di confidenza sia significativo per la singola stima più che per la procedura – in realtà, il 95% di copertura si riferisce alla ripetizione dell’esperimento, non a un singolo intervallo.\n\nCome si interpreta correttamente un intervallo di confidenza al 95%?\n\nRisposta\n“Se ripetiamo più volte l’esperimento, ossia estraiamo molti campioni indipendenti dalla popolazione e costruiamo ogni volta un intervallo di confidenza con la stessa procedura, allora il 95% di quegli intervalli conterrà il valore vero della media \\(\\mu\\).” È dunque una garanzia circa l’efficacia della metodologia nel lungo periodo.\n\nQual è la differenza essenziale tra un intervallo di confidenza frequentista e un intervallo di credibilità bayesiano?\n\nRisposta\n- Intervallo di confidenza frequentista: descrive la performance a lungo termine di una procedura; non permette di affermare “la probabilità che \\(\\mu\\) sia nell’intervallo è il 95%”.\n- Intervallo di credibilità bayesiano: esprime direttamente una credenza probabilistica a posteriori sul parametro (ad esempio, “c’è il 95% di probabilità che \\(\\mu\\) sia in questo intervallo”), perché il parametro è trattato come variabile casuale, con una distribuzione a priori che si aggiorna con i dati osservati.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nDi seguito trovi 10 esercizi incentrati sulla costruzione di intervalli di confidenza. I primi 5 richiedono di svolgere i calcoli “a mano” (carta e penna o calcolatrice), gli ultimi 5 prevedono l’utilizzo di R.\nEsercizi da Risolvere “a Mano”\n\nIntervallo di Confidenza per la Media (Varianza Nota)\n\nUna ricercatrice vuole stimare la media di un punteggio di reattività emotiva (scala 0–100) in giovani adulti. Dai dati precedenti, si sa che la varianza vera (della popolazione) è \\(\\sigma^2 = 16\\). Si raccoglie un campione di \\(n=25\\) partecipanti e la media campionaria risulta \\(\\bar{X} = 45\\).\n1. Calcola l’intervallo di confidenza al 95% per la media della popolazione (\\(\\mu\\)).\n2. Fornisci un’interpretazione corretta (frequentista) del risultato.\n\nIntervallo di Confidenza per la Media (Varianza Incognita, 99%)\n\nIn un’indagine sulla soddisfazione lavorativa (scala da 1 a 7), vengono coinvolti \\(n=10\\) psicologi clinici. I dati raccolti forniscono:\n- Media campionaria \\(\\bar{X} = 5{,}6\\)\n- Deviazione standard campionaria \\(s=0{,}8\\)\nLa popolazione è considerata approssimativamente normale ma la varianza è ignota. Calcola l’IC al 99% per la vera media di soddisfazione \\(\\mu\\).\n\nIntervallo di Confidenza per la Differenza tra Due Medie (Varianze Incognite Uguali)\n\nUn team di psicologi del lavoro vuole confrontare i livelli di stress (scala 0–50) tra due gruppi di dipendenti di un’azienda (Campione 1: reparto A, Campione 2: reparto B). I dati sono:\n\nReparto A (\\(n_1=12\\)):\\(\\bar{X}_1 = 22\\), \\(s_1 = 4\\)\nReparto B (\\(n_2=10\\)):\\(\\bar{X}_2 = 19\\), \\(s_2 = 3{,}5\\)\n\nAssumi che le due popolazioni siano normali con varianze ignote ma uguali e calcola l’intervallo di confidenza al 95% per \\(\\mu_A - \\mu_B\\). (Usa quindi la formula con la varianza pooled.)\n\nIntervallo di Confidenza per una Proporzione\n\nUno studio pilota su un programma di training per la gestione dell’ansia vede 120 persone iscriversi. Alla fine del programma, 48 di loro riportano di aver diminuito la frequenza di attacchi di panico in modo “significativo”.\n1. Stima la proporzione campionaria \\(\\hat{p}\\).\n2. Calcola l’IC al 95% per la vera proporzione \\(p\\) di persone che trarrebbe beneficio “significativo” dal programma.\n\nIntervallo di Confidenza per la Differenza tra Due Proporzioni\n\nIn un esperimento, due gruppi di partecipanti ricevono diversi percorsi di psicoterapia per ridurre l’insonnia:\n\n\nGruppo 1 (\\(n_1=50\\)): 35 persone riportano un netto miglioramento del sonno.\n\n\nGruppo 2 (\\(n_2=40\\)): 20 persone riportano un netto miglioramento del sonno.\n\nSi vuole stimare la differenza \\((p_1 - p_2)\\) nelle proporzioni di successo dei due trattamenti. Calcola l’IC al 95%.\nEsercizi da Risolvere con R\nNei prossimi esercizi, utilizza R per effettuare i calcoli. I dati sono già contestualizzati in ambito psicologico.\n\nIntervallo di Confidenza per la Media (Varianza Incognita)\n\nHai misurato i tempi di reazione (in millisecondi) a uno stimolo di pericolo in un gruppo di 15 partecipanti. I dati (approssimati) sono:\nreaction_times &lt;- c(220, 250, 210, 240, 260, 270, 225, 255, 235, 245, 210, 270, 265, 220, 230)\n\nUtilizza R per calcolare la media e la deviazione standard campionaria.\n\nCostruisci (tramite t.test(reaction_times)) l’intervallo di confidenza al 95% per il tempo di reazione medio della popolazione.\n\n\nIntervallo di Confidenza per la Differenza tra Due Medie (Varianze Incognite)\n\nDue gruppi di studenti hanno svolto un test di memoria verbale dopo aver seguito differenti strategie di studio:\ngroupA &lt;- c(15, 12, 18, 10, 14, 16, 19, 11)\ngroupB &lt;- c(10, 9, 14, 11, 8, 12, 13, 15)\n\nCalcola in R le medie campionarie dei due gruppi.\n\nUtilizza t.test(groupA, groupB, var.equal = FALSE) per ottenere l’IC al 95% della differenza \\(\\mu_A - \\mu_B\\).\n\nRiporta i risultati numerici.\n\n\nIntervallo di Confidenza per una Proporzione (Studio su Fobia Specifica)\n\nIn un piccolo studio, hai i dati (binari: 1 = “attacco d’ansia”, 0 = “nessun attacco”) raccolti da 20 persone esposte a uno stimolo fobico:\nattacks &lt;- c(1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,0,0,1,0,1)\n\nCalcola in R la proporzione campionaria di attacchi d’ansia.\n\nUtilizza prop.test() per costruire l’IC al 95% per la proporzione vera di attacchi d’ansia in questa specifica situazione.\n\n\nIntervallo di Confidenza per la Differenza tra Due Proporzioni (Test A/B di un Training Psicologico)\n\nDue versioni di un training psicologico anti-stress (A e B) sono state testate su studenti universitari, registrando (binario: 1/0) se al termine del corso mostrano ridotti livelli di stress:\nversionA &lt;- c(1,1,0,1,1,0,1,0,1,1,0,1)\nversionB &lt;- c(0,0,1,1,1,0,1,0,0,1,0,0)\n\nCalcola in R \\(\\hat{p}_A\\) e \\(\\hat{p}_B\\).\n\nUsa prop.test(x = ..., n = ...) per l’IC al 95% di \\((p_A - p_B)\\).\n\nRiporta i risultati.\n\n\nSimulazione di Copertura per l’IC sulla Media (Contesto Psicologico)\n\nScrivi (o completa) uno script in R che simuli 1000 campioni di punteggi di ansia (scala 0–80) estratti da una distribuzione approssimata come Normale, con media vera \\(\\mu=40\\) e \\(\\sigma=10\\). Per ogni campione di ampiezza \\(n=25\\):\n\nCalcola la media campionaria e la deviazione standard.\n\nCostruisci l’IC al 95% (usando la distribuzione t).\n\nVerifica quante volte l’intervallo contiene il vero valore \\(\\mu = 40\\).\n\nStima la proporzione di copertura e commenta se è prossima a 0,95.\n\nEsempio di traccia:\nset.seed(123)\nn_sims &lt;- 1000\nn &lt;- 25\nmu &lt;- 40\nsigma &lt;- 10\n\ncount_included &lt;- 0\n\nfor(i in 1:n_sims){\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  # calcola media, sd, IC, verifica se 40 è dentro l’IC\n}\n\ncoverage &lt;- count_included / n_sims\ncoverage\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nSoluzioni Esercizi “a Mano”\nSoluzione 1\n\nDati: \\(\\sigma^2=16 \\implies \\sigma=4\\); \\(n=25\\); \\(\\bar{X}=45\\); livello di confidenza 95% (\\(\\alpha=0{,}05\\)).\n\nErrore standard:\\[\n\\text{SE} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{4}{5} = 0{,}8.\n\\]\n\nValore critico \\(z_{\\alpha/2}\\approx 1{,}96\\).\n\nMargine di errore:\\[\nE = z_{\\alpha/2} \\times \\text{SE} \\approx 1{,}96 \\times 0{,}8 = 1{,}57.\n\\]\n\nIC 95%:\\[\n45 \\pm 1{,}57 \\quad \\Rightarrow \\quad (43{,}43;\\, 46{,}57).\n\\]\n\n\nSoluzione 2\n\nDati: \\(n=10\\), \\(\\bar{X}=5{,}6\\), \\(s=0{,}8\\), confidenza 99% (\\(\\alpha=0{,}01\\)).\n\nGradi di libertà \\(df = 9\\). Il valore di \\(t_{\\alpha/2, df=9}\\) (per \\(\\alpha/2=0{,}005\\)) è approssimativamente 3,25 (dipende dalla tabella).\n\nErrore standard:\\[\n\\text{SE} = \\frac{s}{\\sqrt{n}} = \\frac{0{,}8}{\\sqrt{10}} \\approx \\frac{0{,}8}{3{,}162} \\approx 0{,}253.\n\\]\n\nMargine di errore:\\[\nE = 3{,}25 \\times 0{,}253 \\approx 0{,}82.\n\\]\n\nIC al 99%:\\[\n5{,}6 \\pm 0{,}82 \\quad \\Rightarrow \\quad (4{,}78;\\, 6{,}42).\n\\]\n\n\nSoluzione 3\n\nDati:\n\nCampione 1 (A): \\(n_1=12\\), \\(\\bar{X}_1=22\\), \\(s_1=4\\).\n\nCampione 2 (B): \\(n_2=10\\), \\(\\bar{X}_2=19\\), \\(s_2=3{,}5\\).\n\nIC 95% \\(\\Rightarrow \\alpha=0{,}05\\).\n\nSi assume varianza uguale (\\(\\sigma_A^2 = \\sigma_B^2\\)) \\(\\Rightarrow\\) varianza pooled.\n\n\n\n\nVarianza campionaria: \\(s_1^2=16\\), \\(s_2^2=12{,}25\\).\n\nVarianza pooled:\\[\ns_p^2\n= \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}\n= \\frac{(11 \\times 16) + (9 \\times 12{,}25)}{12 + 10 - 2}.\n\\] \\[\n= \\frac{176 + 110{,}25}{20}\n= \\frac{286{,}25}{20}\n= 14{,}3125.\n\\] \\[\ns_p = \\sqrt{14{,}3125} \\approx 3{,}785.\n\\]\n\nErrore standard della differenza:\\[\n\\text{SE}(\\bar{X}_1 - \\bar{X}_2)\n= \\sqrt{\\,s_p^2\\!\\left(\\tfrac{1}{n_1} + \\tfrac{1}{n_2}\\right)}\n= \\sqrt{\\,14{,}3125 \\times \\left(\\tfrac{1}{12} + \\tfrac{1}{10}\\right)}.\n\\] \\[\n\\tfrac{1}{12} + \\tfrac{1}{10} = 0{,}0833 + 0{,}1 = 0{,}1833.\n\\] \\[\n14{,}3125 \\times 0{,}1833 \\approx 2{,}624\n\\quad \\Rightarrow \\quad \\sqrt{2{,}624} \\approx 1{,}62.\n\\]\n\nDifferenza campionaria: \\(\\bar{X}_1 - \\bar{X}_2 = 3\\).\n\nValore critico \\(t_{\\alpha/2}\\) con \\(df = n_1 + n_2 - 2 = 20\\): circa 2,086.\n\nMargine di errore: \\(E \\approx 2{,}086 \\times 1{,}62 \\approx 3{,}38\\).\n\nIC 95%:\\[\n3 \\pm 3{,}38 \\quad \\Rightarrow \\quad (-0{,}38;\\, 6{,}38).\n\\] (Approssimando: i valori variano un po’ in base agli arrotondamenti.)\n\n\nSoluzione 4\n\nDati: \\(n=120\\), successo \\(x=48\\).\n\n\n\\(\\hat{p} = \\frac{48}{120}=0{,}4\\).\n\nErrore standard (approssimazione normale):\\[\n\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} = \\sqrt{\\frac{0{,}4 \\times 0{,}6}{120}} = \\sqrt{\\frac{0{,}24}{120}} = \\sqrt{0{,}002} \\approx 0{,}0447.\n\\]\n\nCon \\(\\alpha=0{,}05\\), \\(z_{\\alpha/2} \\approx 1{,}96\\).\n\nMargine di errore:\\[\nE = 1{,}96 \\times 0{,}0447 \\approx 0{,}0876.\n\\]\n\nIC 95%:\\[\n0{,}4 \\pm 0{,}0876 \\quad \\Rightarrow \\quad (0{,}3124;\\, 0{,}4876).\n\\]\n\n\nSoluzione 5\n\nDati:\n\nGruppo 1 (\\(n_1=50\\)): 35 successi \\(\\Rightarrow \\hat{p}_1=35/50=0{,}70\\).\n\nGruppo 2 (\\(n_2=40\\)): 20 successi \\(\\Rightarrow \\hat{p}_2=20/40=0{,}50\\).\n\n\n\nDifferenza: \\(\\hat{p}_1 - \\hat{p}_2=0{,}20\\).\n\nErrore standard:\\[\n\\sqrt{\\frac{0{,}70 \\cdot 0{,}30}{50} + \\frac{0{,}50 \\cdot 0{,}50}{40}}\n= \\sqrt{\\frac{0{,}21}{50} + \\frac{0{,}25}{40}}\n= \\sqrt{0{,}0042 + 0{,}00625}\n= \\sqrt{0{,}01045} \\approx 0{,}1022.\n\\]\n\nMargine di errore (al 95%, \\(z_{\\alpha/2}=1{,}96\\)):\\[\n1{,}96 \\times 0{,}1022 \\approx 0{,}200.\n\\]\n\nIC 95%:\\[\n0{,}20 \\pm 0{,}20 \\quad \\Rightarrow \\quad (0{,}00;\\, 0{,}40).\n\\] *(Può capitare un limite inferiore esattamente 0, se si arrotonda.)\n\nSoluzioni Esercizi con R\n(I risultati possono variare leggermente a seconda della versione di R e di eventuali correzioni di continuità nelle funzioni di test.)\nSoluzione 6\nreaction_times &lt;- c(220, 250, 210, 240, 260, 270, 225, 255, 235, 245, 210, 270, 265, 220, 230)\n\nmean(reaction_times)         # media\nsd(reaction_times)           # deviazione standard\nt.test(reaction_times)       # t.test con conf.level = 0.95 di default\n\nEsempio di risultato:\n\nMedia campionaria \\(\\bar{X}\\approx 240\\) (dipende dai dati esatti)\n\n\nt.test() riporta un IC 95% (ad es.): \\((230, 250)\\) [numeri a titolo di esempio].\n\n\n\nSoluzione 7\ngroupA &lt;- c(15, 12, 18, 10, 14, 16, 19, 11)\ngroupB &lt;- c(10, 9, 14, 11, 8, 12, 13, 15)\n\nmean(groupA)  # ~ 14.375\nmean(groupB)  # ~ 11.50\nt.test(groupA, groupB, var.equal = FALSE)\n\n\nEsempio di output (fittizio):\nWelch Two Sample t-test\ndata:  groupA and groupB\nt = 2.35, df = 13.7, p-value = 0.033\n95 percent confidence interval:\n  0.47  5.77\nsample estimates:\n  mean of x  mean of y \n      14.375     11.500\nQuindi l’IC 95% per \\(\\mu_A - \\mu_B\\) potrebbe essere circa \\((0{,}47;\\, 5{,}77)\\).\n\n\nSoluzione 8\nattacks &lt;- c(1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,0,0,1,0,1)\n\nsum(attacks)        # conta quanti \"1\"\nlength(attacks)     # 20\n\nprop.test(sum(attacks), length(attacks), conf.level = 0.95)\n\nSe, ad esempio, vi fossero 12 “1” su 20, \\(\\hat{p}=0{,}60\\).\n\nL’intervallo di confidenza al 95% (a seconda della continuity correction) potrebbe essere indicativamente \\((0{,}36;\\, 0{,}80)\\).\n\nSoluzione 9\nversionA &lt;- c(1,1,0,1,1,0,1,0,1,1,0,1)\nversionB &lt;- c(0,0,1,1,1,0,1,0,0,1,0,0)\n\nsumA &lt;- sum(versionA)\nsumB &lt;- sum(versionB)\nnA   &lt;- length(versionA)\nnB   &lt;- length(versionB)\n\nprop.test(c(sumA,sumB), c(nA,nB), conf.level = 0.95)\n\nEsempio:\n\n\nsum(versionA) = 8 successi su 12 (\\(\\hat{p}_A=0{,}666...\\))\n\n\nsum(versionB) = 5 successi su 12 (\\(\\hat{p}_B=0{,}416...\\))\n\nL’IC per \\(\\hat{p}_A - \\hat{p}_B\\) potrebbe essere, ad esempio, \\((-0{,}05;\\, 0{,}61)\\).\n\n\n\n(I numeri esatti variano a seconda dell’eventuale correzione di continuità.)\nSoluzione 10\nUn possibile script:\nset.seed(123)\nn_sims &lt;- 1000\nn &lt;- 25\nmu &lt;- 40\nsigma &lt;- 10\n\ncount_included &lt;- 0\n\nfor(i in 1:n_sims){\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  xbar &lt;- mean(sample_data)\n  s &lt;- sd(sample_data)\n  \n  # t critico\n  t_crit &lt;- qt(0.975, df = n - 1)\n  \n  # IC\n  se &lt;- s / sqrt(n)\n  E &lt;- t_crit * se\n  lower &lt;- xbar - E\n  upper &lt;- xbar + E\n  \n  if(mu &gt;= lower & mu &lt;= upper){\n    count_included &lt;- count_included + 1\n  }\n}\n\ncoverage &lt;- count_included / n_sims\ncoverage\n\n\nEsempio di risultato:\n&gt; coverage\n[1] 0.948\nOvvero ~94,8% degli IC contengono il vero valore \\(\\mu=40\\), in linea con il 95% atteso (piccole differenze dovute al caso).\n\n\nCommento Conclusivo\nIn ogni caso, ricorda sempre che l’interpretazione frequentista di un intervallo di confidenza si basa sulla “copertura a lungo termine” del metodo di costruzione dell’IC, non sulla probabilità che il vero parametro cada nell’intervallo specifico appena calcolato.\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 – Calcolo e interpretazione dell’IC frequentista per la media\n\n\nCalcola la media campionaria \\(\\bar{X}\\) e la deviazione standard campionaria \\(s\\).\n\nAssumendo che il punteggio SWLS nella popolazione di riferimento (ad esempio, “giovani adulti universitari”) sia approssimativamente normale ma con varianza sconosciuta, costruisci l’intervallo di confidenza al 95% per la media \\(\\mu\\) utilizzando la distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libertà (dove \\(n=10\\)).\n\n\nInterpreta questo intervallo di confidenza in ottica frequentista. Metti in evidenza la distinzione fra l’“interpretazione corretta” (copertura sul lungo periodo) e l’“interpretazione scorretta” (credere che ci sia il 95% di probabilità che \\(\\mu\\) stia nell’intervallo calcolato).\n\nSpunti di riflessione sui limiti:\n- Con un campione molto piccolo, l’intervallo di confidenza potrebbe essere molto ampio.\n- Se la popolazione non fosse davvero normale, la validità dell’IC con distribuzione \\(t\\) potrebbe essere compromessa.\n- In ottica frequentista, il singolo intervallo o contiene il vero valore di \\(\\mu\\) o non lo contiene: la “probabilità 95%” si riferisce alla procedura di costruzione, non a questo singolo intervallo specifico.\nEsercizio 2 – Sensibilità dell’IC a diversi livelli di confidenza\n\nUtilizzando gli stessi 10 dati, calcola:\n\nl’intervallo di confidenza all’80%\n\nl’intervallo di confidenza al 99%\n\n\n\nConfronta l’ampiezza dei tre intervalli (80%, 95%, 99%).\n\nCommenta dal punto di vista dell’interpretazione frequentista: perché l’IC al 99% è più ampio di quello al 95%, e quest’ultimo è più ampio di quello all’80%?\n\nSpunti di riflessione sui limiti:\n- Aumentare il livello di confidenza fa sì che l’IC si allarghi, spesso di molto se \\(n\\) è piccolo.\n- Un IC più ampio rassicura sulla “copertura” nel lungo periodo, ma è meno informativo per il singolo studio.\nEsercizio 3 – Utilizzo di software per il calcolo (ad esempio, R o altro)\n\n\nInserisci i dati in un software (come R). Puoi farlo in R con:\nswls_data &lt;- c(28, 22, 26, 18, 30, 24, 27, 17, 21, 25)\n\n\nCalcola la media e la deviazione standard in R, poi utilizza la funzione t.test():\nt.test(swls_data, conf.level = 0.95)\n\nRiporta l’intervallo di confidenza ottenuto e confrontalo con quello calcolato a mano.\nCommenta eventuali differenze (minime) dovute agli arrotondamenti o a correzioni interne di R.\nRibadisci la corretta interpretazione frequentista: se si ripetesse lo stesso studio molte volte (stessa dimensione campionaria, stesso contesto di popolazione, stessa procedura di calcolo), il 95% di questi IC conterrebbe il valore vero di \\(\\mu\\).\n\nEsercizio 4 – Confronto pratico e riflessioni critiche\n\nImmagina di avere un’ipotesi: “La media SWLS nella popolazione dei giovani adulti universitari è pari a 24” (un’ipotesi plausibile se la scala totale va da 5 a 35).\n\nOsserva l’IC al 95% che hai calcolato: contiene il valore 24?\n\nSe l’IC contiene 24, puoi dire che il valore “24” è “molto probabile”? (No, attenzione! Vedi interpretazione corretta vs. errata.)\n\nSe l’IC non contiene 24, puoi concludere che la media reale è “sicuramente” diversa da 24? (No, perché hai solo un campione piccolo e il concetto di significatività vs. copertura può essere fuorviante.)\n\nSpunti di riflessione sui limiti:\n- Il “livello di fiducia” dell’IC non è una “probabilità” che \\(\\mu\\) sia all’interno di un singolo intervallo: è una proprietà della procedura sul lungo periodo.\n- Con pochi dati, le assunzioni (come la normalità) e la variabilità casuale giocano un ruolo enorme: l’intervallo può risultare poco stabile e molto sensibile a pochi valori estremi.\n- L’IC non dice “quanto è plausibile 24” (questo sarebbe più vicino a un approccio bayesiano, che definisce un intervallo di credibilità). L’IC frequentista dice soltanto che, ripetendo molte volte la stessa procedura, nel 95% dei casi il vero \\(\\mu\\) cadrà entro l’intervallo calcolato in ciascuna ripetizione.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nSupponiamo siano stati raccolti i dati seguenti (sostituisci con i dati effettivi):\n28, 22, 26, 18, 30, 24, 27, 17, 21, 25\nEsercizio 1\n\nCalcolo di media e deviazione standard campionaria\n\nIndichiamo i punteggi come \\(X_1, X_2, \\dots, X_{10}\\). La media campionaria è:\n\\[\n\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i.\n\\]\nFacendo la somma \\(28 + 22 + 26 + 18 + 30 + 24 + 27 + 17 + 21 + 25 = 238\\).\nQuindi, con \\(n=10\\), otteniamo:\n\\[\n\\bar{X} = \\frac{238}{10} = 23.8.\n\\]\nPer la deviazione standard campionaria \\(s\\), si utilizza:\n\\[\ns = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n \\bigl(X_i - \\bar{X}\\bigr)^2}.\n\\]\nCalcolando (o usando un foglio di calcolo / software), si ricava approssimativamente:\n\\[\ns \\approx 4.26.\n\\]\n\nCostruzione dell’Intervallo di Confidenza al 95%\n\nPoiché la varianza è sconosciuta e il campione è piccolo, usiamo la distribuzione \\(t\\) di Student con \\(n-1 = 9\\) gradi di libertà.\n- Livello di confidenza: \\(95\\%\\).\n- \\(\\alpha = 0,05\\), quindi \\(\\alpha/2 = 0,025\\).\n- Il valore critico \\(t_{\\alpha/2,df=9}\\) è circa 2,262 (da tavole o software).\n\nErrore standard\n\n\\[\n\\text{SE} = \\frac{s}{\\sqrt{n}} = \\frac{4.26}{\\sqrt{10}} \\approx 4.26 / 3.162 \\approx 1.35.\n\\]\n\nMargine di errore\n\n\\[\nE = t_{\\alpha/2} \\times \\text{SE} \\approx 2.262 \\times 1.35 \\approx 3.05.\n\\]\n\nIntervallo di confidenza\n\n\\[\n\\bar{X} \\pm E \\quad \\Rightarrow \\quad 23.8 \\pm 3.05\n\\quad \\Rightarrow \\quad (20.75;\\, 26.85).\n\\]\n\nInterpretazione frequentista corretta\n\n\n\nInterpretazione corretta: se ripetessimo lo stesso tipo di studio molte volte (stessa procedura di campionamento, stesse dimensioni, stesso metodo di calcolo dell’IC), il 95% di questi intervalli conterrà il vero valore della media della popolazione (\\(\\mu\\)).\n\n\nInterpretazione scorretta (da evitare): “C’è il 95% di probabilità che la vera media sia qui dentro”. Nel frequentismo, \\(\\mu\\) è considerato un valore fisso e non aleatorio. L’incertezza riguarda l’intervallo, non il parametro.\n\nLimite: con poche osservazioni (n=10), l’intervallo può risultare piuttosto ampio. Inoltre, l’assunzione di normalità della popolazione di partenza potrebbe non essere pienamente soddisfatta.\nEsercizio 2\n\nCalcolo di due nuovi IC: 80% e 99%\n\nUtilizziamo gli stessi \\(\\bar{X} = 23.8\\), \\(s = 4.26\\), \\(n=10\\). Cambia solo il valore critico \\(t\\).\n\n\nIC all’80% (\\(\\alpha=0,20\\), \\(\\alpha/2 = 0,10\\)):\n\n\n\\(t_{0,10,df=9} \\approx 1.383\\)\n\n\n\\(\\text{SE} \\approx 1.35\\) (come prima)\n\nMargine di errore \\(E = 1.383 \\times 1.35 \\approx 1.87\\)\n\nIC 80%: \\((23.8 \\pm 1.87)\\) \\(\\Rightarrow\\) \\((21.93;\\, 25.67)\\).\n\n\n\nIC al 99% (\\(\\alpha=0,01\\), \\(\\alpha/2 = 0,005\\)):\n\n\n\\(t_{0,005,df=9} \\approx 3.25\\)\n\n\n\\(\\text{SE} \\approx 1.35\\)\n\nMargine di errore \\(E = 3.25 \\times 1.35 \\approx 4.39\\)\n\nIC 99%: \\((23.8 \\pm 4.39)\\) \\(\\Rightarrow\\) \\((19.41;\\, 28.19)\\).\n\n\n\n\nConfronto delle ampiezze\n\n\n\n80%: \\((21.93;\\, 25.67)\\) (più stretto)\n\n\n95%: \\((20.75;\\, 26.85)\\) (intermedio)\n\n\n99%: \\((19.41;\\, 28.19)\\) (più largo)\n\nAumentando il livello di confidenza, l’intervallo si espande. Per “coprire” il valore vero nel 99% delle volte, occorre un intervallo più ampio.\nEsercizio 3\n\nCalcolo in R\n\nSe in R inseriamo i dati:\nswls_data &lt;- c(28, 22, 26, 18, 30, 24, 27, 17, 21, 25)\n\nmean(swls_data)  # ~ 23.8\nsd(swls_data)    # ~ 4.26\nt.test(swls_data, conf.level = 0.95)\n\nConfronto con il calcolo “a mano”\n\nLa funzione t.test() (di default) eseguirà un One Sample t-test con confidenza 95%. Restituisce:\n\nUn IC molto simile a \\((20.75;\\, 26.85)\\), con possibili piccole differenze di arrotondamento.\n\n\nRibadire l’interpretazione\n\n\nIl risultato di t.test() potrebbe riportare:95 percent confidence interval: (20.72, 26.88)\n(o valori simili).\n\nAnche qui vale la regola: non è una probabilità che \\(\\mu\\) sia dentro, bensì una proprietà della procedura (lungo periodo).\n\nEsercizio 4\n\n\nIpotesi: “La media SWLS reale nella popolazione è 24”.\n\n\nVerifica se 24 è dentro l’IC al 95%. Dall’IC \\((20.75;\\, 26.85)\\), notiamo che 24 rientra in questo intervallo.\n\nSignifica che è “probabile” 24?\n\nAttenzione: l’IC frequentista non fornisce una probabilità su questo specifico valore. Dire che “24 è dentro l’intervallo” non equivale a dire “la probabilità che \\(\\mu\\) = 24 è 95%”.\n\n\n\nSe 24 fosse stato fuori dall’intervallo, non potremmo comunque affermare con certezza che \\(\\mu\\neq 24\\). Ricordiamo sempre che, con un campione così piccolo, l’incertezza è alta e l’IC si basa su assunzioni (normalità e stima corretta).\n\nLimiti dell’interpretazione\n\nCon campioni ridotti, basta poco (un outlier o una leggera deviazione dalla normalità) per alterare significativamente l’intervallo.\n\nIl livello di confidenza (ad es. 95%) è una proprietà della procedura: in una serie di infiniti studi simili, il 95% di quegli intervalli conterrebbe \\(\\mu\\). Non significa che, dato questo singolo intervallo, ci sia una “probabilità 95%” di includere il parametro.\n\nRiepilogo Finale\n\n\nValori Numerici:\n\nMedia \\(\\bar{X} = 23.8\\); dev. standard \\(s \\approx 4.26\\).\n\nIC 95% (a mano) \\(\\approx (20.75;\\, 26.85)\\).\n\nIC 80% \\(\\approx (21.93;\\, 25.67)\\); IC 99% \\(\\approx (19.41;\\, 28.19)\\).\n\n\n\n\nInterpretazione Frequentista:\n&gt; Nel lungo periodo, il 95% (o 99%, 80%, ecc.) degli intervalli calcolati con la stessa procedura conterrà il vero valore di \\(\\mu\\).\n\n\nLimiti (campioni piccoli, ipotesi di normalità, differenza tra “copertura ripetuta” e “probabilità che \\(\\mu\\) sia in un singolo IC”).\n\nIn questo modo, gli studenti vedono sia la parte di calcolo (formule, tabelle/valori critici, software) sia gli aspetti interpretativi (come evitare i fraintendimenti più comuni sul significato dell’IC frequentista).\nConclusioni generali\n\nCon un campione così piccolo (n=10), l’intervallo di confidenza può essere largo e sensibile a qualsiasi deviazione dall’assunzione di normalità.\n\nL’interpretazione frequentista si focalizza sulla “procedura” e sul “lungo periodo” (ripetizione dell’esperimento), non sulla probabilità che \\(\\mu\\) sia dentro questo intervallo specifico.\n\nÈ facile incorrere in fraintendimenti (“c’è il 95% di probabilità che la vera media sia qui dentro?”), occorre ribadire che la probabilità secondo il frequentismo riguarda il campionamento e la costruzione dell’intervallo, non la posizione fissa del parametro.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#soluzione-esercizio-1",
    "href": "chapters/frequentist_inference/02_conf_interv.html#soluzione-esercizio-1",
    "title": "70  Intervalli di fiducia",
    "section": "\n70.9 Soluzione Esercizio 1",
    "text": "70.9 Soluzione Esercizio 1\n\n70.9.1 1. Calcolo di media e deviazione standard campionaria\nIndichiamo i punteggi come \\(X_1, X_2, \\dots, X_{10}\\). La media campionaria è:\n\\[\n\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i.\n\\]\nFacendo la somma \\(28 + 22 + 26 + 18 + 30 + 24 + 27 + 17 + 21 + 25 = 238\\).\nQuindi, con \\(n=10\\), otteniamo:\n\\[\n\\bar{X} = \\frac{238}{10} = 23.8.\n\\]\nPer la deviazione standard campionaria \\(s\\), si utilizza:\n\\[\ns = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n \\bigl(X_i - \\bar{X}\\bigr)^2}.\n\\]\nCalcolando (o usando un foglio di calcolo / software), si ricava approssimativamente:\n\\[\ns \\approx 4.26.\n\\]\n\n70.9.2 2. Costruzione dell’Intervallo di Confidenza al 95%\nPoiché la varianza è sconosciuta e il campione è piccolo, usiamo la distribuzione \\(t\\) di Student con \\(n-1 = 9\\) gradi di libertà.\n- Livello di confidenza: \\(95\\%\\).\n- \\(\\alpha = 0,05\\), quindi \\(\\alpha/2 = 0,025\\).\n- Il valore critico \\(t_{\\alpha/2,df=9}\\) è circa 2,262 (da tavole o software).\n\n70.9.2.1 a) Errore standard\n\\[\n\\text{SE} = \\frac{s}{\\sqrt{n}} = \\frac{4.26}{\\sqrt{10}} \\approx 4.26 / 3.162 \\approx 1.35.\n\\]\n\n70.9.2.2 b) Margine di errore\n\\[\nE = t_{\\alpha/2} \\times \\text{SE} \\approx 2.262 \\times 1.35 \\approx 3.05.\n\\]\n\n70.9.2.3 c) Intervallo di confidenza\n\\[\n\\bar{X} \\pm E \\quad \\Rightarrow \\quad 23.8 \\pm 3.05\n\\quad \\Rightarrow \\quad (20.75;\\, 26.85).\n\\]\n\n70.9.3 3. Interpretazione frequentista corretta\n\n\nInterpretazione corretta: se ripetessimo lo stesso tipo di studio molte volte (stessa procedura di campionamento, stesse dimensioni, stesso metodo di calcolo dell’IC), il 95% di questi intervalli conterrà il vero valore della media della popolazione (\\(\\mu\\)).\n\n\nInterpretazione scorretta (da evitare): “C’è il 95% di probabilità che la vera media sia qui dentro”. Nel frequentismo, \\(\\mu\\) è considerato un valore fisso e non aleatorio. L’incertezza riguarda l’intervallo, non il parametro.\n\nLimite: con poche osservazioni (n=10), l’intervallo può risultare piuttosto ampio. Inoltre, l’assunzione di normalità della popolazione di partenza potrebbe non essere pienamente soddisfatta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#soluzione-esercizio-2",
    "href": "chapters/frequentist_inference/02_conf_interv.html#soluzione-esercizio-2",
    "title": "70  Intervalli di fiducia",
    "section": "\n70.10 Soluzione Esercizio 2",
    "text": "70.10 Soluzione Esercizio 2\n\n70.10.1 a) Calcolo di due nuovi IC: 80% e 99%\nUtilizziamo gli stessi \\(\\bar{X} = 23.8\\), \\(s = 4.26\\), \\(n=10\\). Cambia solo il valore critico \\(t\\).\n\n\nIC all’80% (\\(\\alpha=0,20\\), \\(\\alpha/2 = 0,10\\)):\n\n\n\\(t_{0,10,df=9} \\approx 1.383\\)\n\n\n\\(\\text{SE} \\approx 1.35\\) (come prima)\n\nMargine di errore \\(E = 1.383 \\times 1.35 \\approx 1.87\\)\n\nIC 80%: \\((23.8 \\pm 1.87)\\) \\(\\Rightarrow\\) \\((21.93;\\, 25.67)\\).\n\n\n\nIC al 99% (\\(\\alpha=0,01\\), \\(\\alpha/2 = 0,005\\)):\n\n\n\\(t_{0,005,df=9} \\approx 3.25\\)\n\n\n\\(\\text{SE} \\approx 1.35\\)\n\nMargine di errore \\(E = 3.25 \\times 1.35 \\approx 4.39\\)\n\nIC 99%: \\((23.8 \\pm 4.39)\\) \\(\\Rightarrow\\) \\((19.41;\\, 28.19)\\).\n\n\n\n70.10.2 b) Confronto delle ampiezze\n\n\n80%: \\((21.93;\\, 25.67)\\) (più stretto)\n\n\n95%: \\((20.75;\\, 26.85)\\) (intermedio)\n\n\n99%: \\((19.41;\\, 28.19)\\) (più largo)\n\nAumentando il livello di confidenza, l’intervallo si espande. Per “coprire” il valore vero nel 99% delle volte, occorre un intervallo più ampio.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#soluzione-esercizio-3",
    "href": "chapters/frequentist_inference/02_conf_interv.html#soluzione-esercizio-3",
    "title": "70  Intervalli di fiducia",
    "section": "\n70.11 Soluzione Esercizio 3",
    "text": "70.11 Soluzione Esercizio 3\n\n70.11.1 1. Calcolo in R\nSe in R inseriamo i dati:\nswls_data &lt;- c(28, 22, 26, 18, 30, 24, 27, 17, 21, 25)\n\nmean(swls_data)  # ~ 23.8\nsd(swls_data)    # ~ 4.26\nt.test(swls_data, conf.level = 0.95)\n\n70.11.2 2. Confronto con il calcolo “a mano”\nLa funzione t.test() (di default) eseguirà un One Sample t-test con confidenza 95%. Restituisce: - Un IC molto simile a \\((20.75;\\, 26.85)\\), con possibili piccole differenze di arrotondamento.\n\n70.11.3 3. Ribadire l’interpretazione\n\nIl risultato di t.test() potrebbe riportare:95 percent confidence interval: (20.72, 26.88)\n(o valori simili).\n\nAnche qui vale la regola: non è una probabilità che \\(\\mu\\) sia dentro, bensì una proprietà della procedura (lungo periodo).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#soluzione-esercizio-4",
    "href": "chapters/frequentist_inference/02_conf_interv.html#soluzione-esercizio-4",
    "title": "70  Intervalli di fiducia",
    "section": "\n70.12 Soluzione Esercizio 4",
    "text": "70.12 Soluzione Esercizio 4\n\n\nIpotesi: “La media SWLS reale nella popolazione è 24”.\n\n\nVerifica se 24 è dentro l’IC al 95%. Dall’IC \\((20.75;\\, 26.85)\\), notiamo che 24 rientra in questo intervallo.\n\nSignifica che è “probabile” 24?\n\nAttenzione: l’IC frequentista non fornisce una probabilità su questo specifico valore. Dire che “24 è dentro l’intervallo” non equivale a dire “la probabilità che \\(\\mu\\) = 24 è 95%”.\n\n\n\nSe 24 fosse stato fuori dall’intervallo, non potremmo comunque affermare con certezza che \\(\\mu\\neq 24\\). Ricordiamo sempre che, con un campione così piccolo, l’incertezza è alta e l’IC si basa su assunzioni (normalità e stima corretta).\n\n\n70.12.1 Limiti dell’interpretazione\n\nCon campioni ridotti, basta poco (un outlier o una leggera deviazione dalla normalità) per alterare significativamente l’intervallo.\n\nIl livello di confidenza (ad es. 95%) è una proprietà della procedura: in una serie di infiniti studi simili, il 95% di quegli intervalli conterrebbe \\(\\mu\\). Non significa che, dato questo singolo intervallo, ci sia una “probabilità 95%” di includere il parametro.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  }
]