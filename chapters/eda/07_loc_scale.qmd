# Indicatori di tendenza centrale e variabilità {#sec-central-tendency-variability}

::: callout-important
## In questo capitolo imparerai a

- calcolare e interpretare i principali indici di tendenza centrale e di variabilità.
:::

::: callout-tip
## Prerequisiti

- Leggere "Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals" [@speelman2024most].
- Studiare l'@sec-apx-sums.
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(tidyr, viridis, vcd)
```
:::

## Introduzione

La visualizzazione grafica dei dati rappresenta il pilastro fondamentale di ogni analisi quantitativa. Grazie alle rappresentazioni grafiche adeguate, è possibile individuare importanti caratteristiche di una distribuzione, quali la simmetria o l'asimmetria, nonché la presenza di una o più mode. Successivamente, al fine di descrivere sinteticamente le principali caratteristiche dei dati, si rende necessario l'utilizzo di specifici indici numerici. In questo capitolo, verranno presentati i principali indicatori della statistica descrittiva.

## Indici di Tendenza Centrale

Gli indici di tendenza centrale sono misure statistiche che cercano di rappresentare un valore tipico o centrale all'interno di un insieme di dati. Sono utilizzati per ottenere una comprensione immediata della distribuzione dei dati senza dover analizzare l'intero insieme. Gli indici di tendenza centrale sono fondamentali nell'analisi statistica, in quanto forniscono una sintesi semplice e comprensibile delle caratteristiche principali di un insieme di dati. I principali indici di tendenza centrale sono: 

1. **Media**: La media è la somma di tutti i valori divisa per il numero totale di valori. È spesso utilizzata come misura generale di tendenza centrale, ma è sensibile agli estremi (valori molto alti o molto bassi).
2. **Mediana**: La mediana è il valore che divide l'insieme di dati in due parti uguali. A differenza della media, non è influenzata da valori estremi ed è quindi più robusta in presenza di outlier.
3. **Moda**: La moda è il valore che appare più frequentemente in un insieme di dati. In alcuni casi, può non essere presente o esserci più di una moda.

La scelta dell'indice di tendenza centrale appropriato dipende dalla natura dei dati e dall'obiettivo dell'analisi. Ad esempio, la mediana potrebbe essere preferita alla media se l'insieme di dati contiene valori anomali che potrebbero distorcere la rappresentazione centrale. La conoscenza e l'applicazione corretta di questi indici possono fornire una preziosa intuizione sulle caratteristiche centrali di una distribuzione di dati.

## Moda

La **moda** ($\text{Mo}$) rappresenta il valore della variabile che **compare con maggiore frequenza** in una distribuzione. In altre parole, è il valore più **ricorrente** nei dati.  
- Nelle **distribuzioni unimodali**, esiste una sola moda, che coincide con il valore centrale della distribuzione più frequente.  
- Tuttavia, in alcune distribuzioni, possono emergere **più di una moda**, rendendole **multimodali**. In questi casi, la moda perde il suo significato di indicatore unico di tendenza centrale, poiché la presenza di più valori con frequenze elevate rende difficile individuare un singolo punto di riferimento.  

## Mediana

La **mediana** ($\tilde{x}$) corrisponde al valore che divide il campione in due metà: il 50% dei dati è inferiore o uguale alla mediana e il restante 50% è superiore o uguale. A differenza della media, la mediana è meno influenzata dai valori estremi, rendendola una misura particolarmente robusta in presenza di dati asimmetrici o outlier.

## Media

La media aritmetica di un insieme di valori rappresenta il punto centrale o il baricentro della distribuzione dei dati. È calcolata come la somma di tutti i valori divisa per il numero totale di valori, ed è espressa dalla formula:

$$
\bar{x}=\frac{1}{n}\sum_{i=1}^n x_i,
$$ {#eq-mean}

dove $x_i$ rappresenta i valori nell'insieme, $n$ è il numero totale di valori, e $\sum$ indica la sommatoria.

### Calcolo della Media con `R`

Per calcolare la media di un piccolo numero di valori in R, possiamo utilizzare la somma di questi valori e dividerla per il numero totale di elementi. Consideriamo ad esempio i valori 12, 44, 21, 62, 24:

```{r}
(12 + 44 + 21 + 62 + 24) / 5
```

ovvero

```{r}
x <- c(12, 44, 21, 62, 24)
mean(x)
```

### Proprietà della Media

Una proprietà fondamentale della media è che la somma degli scarti di ciascun valore dalla media è zero:

$$
\sum_{i=1}^n (x_i - \bar{x}) = 0.\notag
$$ {#eq-diffmeansumzero}

Infatti,

$$
\begin{aligned}
\sum_{i=1}^n (x_i - \bar{x}) &= \sum_i x_i - \sum_i \bar{x}\notag\\
&= \sum_i x_i - n \bar{x}\notag\\
&= \sum_i x_i - \sum_i x_i = 0.\notag
\end{aligned}
$$

Questa proprietà implica che i dati sono equamente distribuiti intorno alla media.

In R abbiamo:

```{r}
sum(x - mean(x))
```

::: {.callout-tip title="Nota" collapse="true"}
Quando in un terminale viene visualizzato un numero come `-7.105e-15` in notazione scientifica, esso corrisponde a $-7.105 \cdot 10^{-15}$, che è effettivamente zero nel contesto dei calcoli numerici.  

Questa approssimazione è una conseguenza diretta della **precisione finita** dei calcolatori. I sistemi digitali, infatti, rappresentano i numeri reali attraverso una codifica in **virgola mobile** (*floating point*), che comporta inevitabili errori di arrotondamento. La ragione risiede nell'impossibilità di memorizzare numeri reali con precisione assoluta.  

Lo standard **IEEE 754 a doppia precisione** (64 bit), ampiamente utilizzato, suddivide la memoria in tre componenti:  

- 1 bit per il segno (positivo/negativo),  
- 11 bit per l'esponente (intervallo di scala),  
- 52 bit per la mantissa (o significando), che definisce le cifre significative.

Grazie a questa struttura, è possibile rappresentare numeri con una precisione di circa **15-17 cifre decimali**. Tuttavia, qualsiasi valore non esprimibile in formato binario entro questi limiti subisce un troncamento o un arrotondamento, generando piccole discrepanze rispetto al risultato teorico.
:::

### La media come Centro di Gravità dell'Istogramma

La media aritmetica può essere interpretata come il centro di gravità o il punto di equilibrio della distribuzione dei dati. In termini fisici, il centro di gravità è il punto in cui la massa di un sistema è equilibrata o concentrata.

In termini statistici, possiamo considerare la media come il punto in cui la distribuzione dei dati è in equilibrio. Ogni valore dell'insieme di dati può essere visto come un punto materiale con una massa proporzionale al suo valore. Se immaginiamo questi punti disposti su una linea, con valori più grandi a destra e più piccoli a sinistra, la media corrisponderà esattamente al punto in cui la distribuzione sarebbe in equilibrio.

### Principio dei Minimi Quadrati

Il **metodo dei minimi quadrati** afferma che la posizione della media minimizza la somma dei quadrati delle distanze dai dati. Matematicamente, ciò significa che la somma dei quadrati degli scarti tra ciascun valore osservato e la media è minima. Questo principio è alla base dell'analisi statistica della regressione e conferma il ruolo della media come **centro di gravità** della distribuzione dei dati.

#### Simulazione

Utilizziamo una simulazione per verificare questo principio, calcolando la somma dei quadrati degli scarti per diversi valori e visualizzando il risultato con **ggplot2**.

```{r}
# Definizione dell'intervallo di valori da testare
nrep <- 10000
M <- seq(20, 40, length.out = nrep)
res <- rep(NA, nrep)

# Calcolo della somma dei quadrati degli scarti per ciascun valore di M
for (i in 1:nrep) {
  res[i] = sum((x - M[i])^2)
}

# Identificazione del valore minimo
min_index <- which.min(res)
min_M <- M[min_index]

# Creazione del dataframe per ggplot
df <- data.frame(M, res)

df |> 
  ggplot(aes(x = M, y = res)) +
  geom_line(color = "blue") +
  geom_vline(xintercept = min_M, linetype = "dashed", color = "red") +
  labs(
    title = "Minimizzazione della somma dei quadrati",
    x = "Valore di M",
    y = "Somma dei quadrati degli scarti"
  ) 
```

Stampiamo il minimo:

```{r}
min_M
```

Confronto con la media:

```{r}
mean(x)
```

Osserviamo che il valore di `M` che minimizza la somma dei quadrati degli scarti coincide con la media dei dati, confermando il principio dei minimi quadrati.

### Le Proporzioni Sono Medie

Se una collezione consiste solo di uni e zeri, allora la somma della collezione è il numero di uni in essa, e la media della collezione è la proporzione di uni.

```{r}
zero_one <- c(1, 1, 1, 0)
result <- mean(zero_one)
result
```

È possibile sostituire 1 con il valore booleano True e 0 con False:

```{r}
mean(c(TRUE, TRUE, TRUE, FALSE))
```

### Limiti della Media Aritmetica

La media aritmetica, tuttavia, ha alcune limitazioni: non sempre è l'indice più adeguato per descrivere accuratamente la tendenza centrale della distribuzione, specialmente quando si verificano asimmetrie o valori anomali (outlier). In queste situazioni, è più indicato utilizzare la mediana o la media spuntata (come spiegheremo successivamente).

## Come Descrivere la Tendenza Centrale in Distribuzioni Asimmetriche  

Il diverso significato degli indici di tendenza centrale – moda, media e mediana – diventa evidente quando si analizzano **distribuzioni asimmetriche**. Per illustrare questo concetto, utilizzeremo i dati del Progetto Natsal, contenuti nel file `sexual-partners.csv`.

Negli anni '80, con la crescente preoccupazione per l'AIDS, le autorità sanitarie del Regno Unito si resero conto della mancanza di dati affidabili sui comportamenti sessuali della popolazione. In particolare, vi erano dubbi sulla frequenza con cui le persone cambiavano partner, sul numero di partner simultanei e sulle pratiche sessuali adottate. Questa conoscenza era essenziale per prevedere la diffusione delle malattie sessualmente trasmissibili nella società e per pianificare adeguatamente i servizi sanitari. Tuttavia, si faceva ancora riferimento ai dati raccolti da Alfred Kinsey negli Stati Uniti negli anni '40, che non tenevano conto della rappresentatività del campione.

A partire dalla fine degli anni '80, vennero dunque avviati nel Regno Unito e negli Stati Uniti ampi e rigorosi studi sui comportamenti sessuali, nonostante una forte opposizione in alcuni ambienti. Nel Regno Unito, il governo guidato da Margaret Thatcher ritirò il proprio sostegno a un'importante indagine sui comportamenti sessuali all'ultimo momento. Fortunatamente, i ricercatori riuscirono a ottenere finanziamenti da enti benefici, dando vita al *National Sexual Attitudes and Lifestyles Survey* (Natsal). Da allora, questa indagine viene condotta ogni dieci anni, a partire dal 1990. La terza rilevazione, denominata Natsal-3, è stata effettuata intorno al 2010.

Poniamoci il problema di descrivere la tendenza centrale per i dati contenuti nel file `sexual-partners.csv`, separatamente per maschi e femmine. Il dataset fornisce la distribuzione del **numero totale dichiarato di partner sessuali di sesso opposto** nella vita per uomini e donne di età compresa tra 35 e 44 anni. I dati provengono dal sondaggio Natsal-3 e corrispondono a un totale di 796 uomini e 1193 donne.

Procediamo all'importazione dei dati per iniziare l'analisi. 

```{r}
df <- rio::import(here::here("data", "sexual-partners.csv"))
```

Esaminiamo alcune righe prese a caso dal data frame `df`:

```{r}
df[sample(1:nrow(df), size = 10, replace = FALSE), ]
```

La colonna `Gender` riporta il genere del rispondente e la colonna `NumPartners` il numero di partner sessuali di sesso opposto dichiarati.

Esaminiamo la numerosità di ciascun gruppo.

```{r}
df |> 
  group_by(Gender) |> 
  summarize(count = n())
```

Poniamoci innnanzitutto il problema di visualizzare i dati con un istogramma, separatamente per maschi e femmine. Per ragioni di spazio ci limiteremo ad un numero massimo di partner sessuali di 50 (ma in questo campione il numero massimo arriva a 501 per gli uomini e 550 per le donne):

```{r}
df |> 
  group_by(Gender) |> 
  summarize(maximum = max(NumPartners))
```

Iniziamo calcolando la percentuale di intervistati per ciascun valore possibile della variabile "numero di partner sessuali", compreso tra 0 e 50. Il calcolo verrà svolto in due passaggi:

- Conteggio delle frequenze assolute:
Per ogni valore della variabile "numero di partner sessuali" e per ciascun gruppo di genere (uomini e donne), contiamo quante volte quel valore compare nei dati.

- Calcolo delle percentuali relative:
Per ciascun gruppo di genere, dividiamo il conteggio di ogni valore per il totale delle osservazioni nel gruppo e moltiplichiamo per 100 per ottenere la percentuale.

```{r}
# Filtra i dati troncando il numero di partner a 50
df_truncated <- df[df$NumPartners <= 50, ]

# Calcola il conteggio per ciascun genere e numero di partner
counts_data <- df_truncated %>%
  group_by(Gender, NumPartners) %>%  # Raggruppa per genere e numero di partner
  summarise(Count = n(), .groups = "drop")  # Conta le occorrenze

# Aggiunge la percentuale relativa per ciascun genere
percentage_data <- counts_data %>%
  group_by(Gender) %>%  # Raggruppa nuovamente per genere
  mutate(Percentage = Count / sum(Count) * 100)  # Calcola la percentuale

head(percentage_data)
```

Possiamo ora creare gli istogrammi per maschi e femmine:

```{r}
# Crea l'istogramma separato per maschi e femmine
gender_labels <- c("Man" = "Uomini 35-44", "Woman" = "Donne 35-44")

# Trova il massimo valore di Percentage per impostare lo stesso limite
y_max <- max(percentage_data$Percentage)

# Grafico con limiti dell'asse y uguali nei due pannelli
percentage_data |>
  ggplot(aes(NumPartners, Percentage, fill = Gender)) +
  geom_col(position = "dodge", color = "black") +
  facet_wrap(~Gender, labeller = labeller(Gender = gender_labels)) +
  scale_y_continuous(limits = c(0, y_max)) +  # Imposta i limiti dell'asse y
  labs(
    x = "Numero di partner sessuali di sesso opposto dichiarati nella vita",
    y = "Percentuale"
  ) +
  theme(legend.position = "none")
```

::: {.callout-tip title="Nota" collapse="true"}
Senza distinguere per genere, è possibile ottenere l'istogramma con il seguente codice:

```{r}
df_truncated |>
  ggplot(
    aes(
      x = NumPartners,
      y = after_stat(density)
    )
  ) +
  geom_histogram(binwidth = 2, fill = "lightblue", color = "black", alpha = 0.7) +
  labs(
    title = "Distribuzione del Numero di Partner Sessuali",
    x = "Numero di Partner",
    y = "Densità"
  )
```

Si noti l'uso di `y = after_stat(density)` all'interno di `aes()`, che consente di normalizzare l'istogramma affinché l'area totale sia pari a 1. In questo modo, l'istogramma rappresenta una densità di probabilità anziché una semplice frequenza assoluta.
:::

Notiamo che la distribuzione è altamente asimmetrica positiva. Come possiamo descrivere la tendenza centrale di questi dati?

Calcoliamo gli indici di tendenza centrale all'interno dei due gruppi. Per la moda utilizziamo una funzione personalizzata:

```{r}
# Funzione personalizzata per calcolare la moda
get_mode <- function(x) {
  # Calcola la tabella di frequenza e restituisce il valore con frequenza massima
  tbl <- table(x)
  as.numeric(names(tbl)[which.max(tbl)])
}

# Calcolo delle statistiche per Gender
df |> 
  group_by(Gender) |> 
  summarise(
    mean_sex_partner = mean(NumPartners, na.rm = TRUE),
    median_sex_partner = median(NumPartners, na.rm = TRUE),
    mode_sex_partner = get_mode(NumPartners)  # Usa la funzione personalizzata per la moda
  )
```

::: {.callout-tip title="Nota" collapse="true"}
Per trovare la moda, anziché definire una funzione personalizzata come `get_mode()` è anche possibile usare **dplyr**:

```{r}
df |> 
  group_by(Gender) |> 
  summarise(
    mean_sex_partner = mean(NumPartners, na.rm = TRUE),
    median_sex_partner = median(NumPartners, na.rm = TRUE),
    mode_sex_partner = as.numeric(names(which.max(table(NumPartners))))
  )
```

Questa soluzione evita la definizione esplicita di una funzione `get_mode()`, ma il principio è lo stesso.
:::

È evidente che, quando la distribuzione dei dati è altamente asimmetrica, come nel caso attuale, gli indici di tendenza centrale – media, mediana e moda – possono fornire risultati molto diversi, rendendo difficile individuare una misura rappresentativa della tendenza centrale.

- La **media** risulta più elevata rispetto alla mediana e alla moda. Questo è tipico di una distribuzione asimmetrica positiva, caratterizzata da una lunga coda destra: pochi individui con valori estremamente alti influenzano la media, spostandola verso destra.  
- La **mediana**, invece, rappresenta il valore centrale della distribuzione e risulta meno influenzata dai valori estremi. Per questo motivo, è spesso più vicina alla "realtà" dei dati, offrendo una stima più robusta della tendenza centrale per la maggior parte degli individui.  
- La **moda**, infine, corrisponde al valore più frequente nella distribuzione (in questo caso, 1 partner). Tuttavia, in presenza di un'elevata dispersione dei dati, la moda può risultare poco rappresentativa della distribuzione complessiva.

In conclusione, quando la distribuzione è fortemente asimmetrica, la **mediana** è generalmente l'indice di tendenza centrale più appropriato. Essendo insensibile ai valori estremi, fornisce una rappresentazione più robusta della "posizione centrale" dei dati. Tuttavia, è utile integrare la mediana con la media e la moda per offrire un quadro più completo della distribuzione.

Per una descrizione efficace della tendenza centrale in distribuzioni asimmetriche, si consiglia dunque di seguire questa procedura:  

1. utilizzare la mediana come misura principale della tendenza centrale;  
2. riportare media e moda come complemento per confrontare i risultati e interpretare eventuali differenze.  

È comunque fondamentale **visualizzare la distribuzione** dei dati attraverso grafici appropriati, come istogrammi o boxplot. Questi strumenti consentono di evidenziare chiaramente l'asimmetria, identificare valori estremi e comprendere meglio la struttura dei dati.  

Inoltre, per arricchire i sommari numerici, è importante associare indici di dispersione che tratteremo in seguito. 

### Media Spuntata

La *media spuntata*, indicata come $\bar{x}_t$ o *trimmed mean*, è un metodo di calcolo della media che prevede l'eliminazione di una determinata percentuale di dati estremi prima di effettuare la media aritmetica. Solitamente, viene eliminato il 10% dei dati, ovvero il 5% all'inizio e alla fine della distribuzione. Per ottenere la media spuntata, i dati vengono ordinati in modo crescente, $x_1 \leq x_2 \leq x_3 \leq \dots \leq x_n$, e quindi viene eliminato il primo 5% e l'ultimo 5% dei dati nella sequenza ordinata. Infine, la media spuntata è calcolata come la media aritmetica dei dati rimanenti. Questo approccio è utile quando ci sono valori anomali o quando la distribuzione è asimmetrica e la media aritmetica non rappresenta adeguatamente la tendenza centrale dei dati.

::: {#exm-}
A titolo di esempio, procediamo al calcolo della media spuntata dei valori `NumPartners` per i due gruppi definiti dalla variabile `Gender`, escludendo il 10% dei valori più estremi.

```{r}
glimpse(df)
```

Uomini:

```{r}
sex_partners_men <- df[df$Gender == "Man", "NumPartners"]
mean(sex_partners_men, trim = 0.10, na.rm = TRUE)
```

Donne:

```{r}
sex_partners_women <- df[df$Gender == "Woman", "NumPartners"]
mean(sex_partners_women, trim = 0.10, na.rm = TRUE)
```
:::

### Quando Usare Media, Media Spuntata, Moda e Mediana  

La scelta della misura di tendenza centrale più appropriata dipende dal tipo di dati, dalla distribuzione e dalla presenza di valori anomali o asimmetrie. 

#### Moda  

La **moda** è il valore che compare con maggiore frequenza nei dati ed è l'unica misura di tendenza centrale utilizzabile per dati a livello nominale (categorie senza ordine) o ordinale (categorie ordinate ma senza distanza definita). Tuttavia:  
- In una distribuzione unimodale, la moda può rappresentare un indicatore significativo della tendenza centrale.  
- In distribuzioni multimodali (con più valori ricorrenti), la moda diventa meno interpretabile, poiché l'esistenza di più "picchi" rende difficile individuare un singolo valore rappresentativo.  
- Nei dati continui, la moda può non essere definita o risultare meno informativa, soprattutto in presenza di valori unici.

#### Media 

La **media aritmetica** è una misura efficace di tendenza centrale se la distribuzione è simmetrica e priva di valori anomali. In tali condizioni, la media rappresenta il "baricentro" della distribuzione, equilibrando i valori a sinistra e a destra. Tuttavia: 

- In distribuzioni asimmetriche o con outlier, la media è fortemente influenzata dai valori estremi e tende a spostarsi nella direzione della coda più lunga (asimmetria positiva o negativa).  
- In questi casi, la media potrebbe non essere rappresentativa della tendenza centrale reale.

#### Media Spuntata 

La **media spuntata** è una versione modificata della media, calcolata dopo aver rimosso una certa percentuale di valori estremi (generalmente il 5% o il 10%) sia dalla coda inferiore che da quella superiore della distribuzione. Questa misura è particolarmente utile quando:  
- La distribuzione è asimmetrica o contiene outlier, ma si desidera comunque una stima della tendenza centrale che consideri gran parte dei dati.  
- La media spuntata è meno sensibile ai valori anomali rispetto alla media tradizionale, pur mantenendo il vantaggio di considerare un'ampia porzione dei dati.

#### Mediana

La **mediana** è il valore centrale che divide il campione in due metà: il 50% dei dati è inferiore e il restante 50% è superiore. È una misura robusta della tendenza centrale, particolarmente adatta quando:  
- La distribuzione è asimmetrica o contiene valori anomali. Poiché si basa sulla posizione dei dati e non sulle loro dimensioni, la mediana non è influenzata da valori estremi.  
- Nei dati **ordinali**, la mediana è spesso più appropriata della media, poiché non richiede una scala numerica con distanze precise.  

#### Quale Misura Scegliere?  

1. **Distribuzioni Simmetriche**:  
   La **media** è la scelta più appropriata, poiché riflette bene la tendenza centrale.  

2. **Distribuzioni Asimmetriche** o con **Outlier**:  
   La **mediana** è preferibile perché è robusta e meno influenzata dai valori estremi. In alternativa, si può utilizzare la **media spuntata** per ottenere un compromesso tra media e mediana.

3. **Dati Categoriali**:  
   La **moda** è l’unica misura applicabile, ma è interpretabile solo in distribuzioni unimodali.  

4. **Distribuzioni Multimodali**:  
   In questo caso, è importante visualizzare i dati (ad esempio con un istogramma) e descrivere ciascun "picco" separatamente, poiché nessuna delle misure tradizionali (media, mediana, moda) sarà sufficiente da sola per rappresentare la tendenza centrale.  

In conclusione  

- La **media** è ideale per distribuzioni simmetriche senza valori estremi.  
- La **mediana** è più robusta e appropriata in caso di asimmetria o outlier.  
- La **media spuntata** rappresenta una soluzione intermedia utile nei casi con pochi valori anomali.  
- La **moda** è rilevante solo per dati nominali o ordinale, ma perde significato in distribuzioni multimodali.

## Quantili e Misure di Dispersione

Accanto alle misure di tendenza centrale (media, mediana, moda), i **quantili** descrivono la posizione relativa di un'osservazione all'interno di una distribuzione. Mentre le misure di tendenza centrale identificano un "valore tipico", i quantili rispondono alla domanda: *Qual è il valore al di sotto del quale si trova una certa proporzione dei dati?*

### Definizione Formale

Il **quantile non interpolato** di ordine $p$ ($0 < p < 1$) è il valore $q_p = x_{(k)}$, dove:

- $x_{(k)}$ è il $k$-esimo elemento nei dati ordinati in modo crescente.
- $k = \lceil p \cdot n \rceil$, con $n =$ numero totale di osservazioni e $\lceil \cdot \rceil$ la funzione arrotondamento all'intero superiore.

#### Esempio di Calcolo

Dati ordinati: $\{15, 20, 23, 25, 28, 30, 35, 40, 45, 50\}$.  
Calcolo del 30° percentile ($p = 0.3$):

1. $k = \lceil 0.3 \cdot 10 \rceil = 3$.
2. Il quantile corrisponde al terzo valore: $q_{0.3} = 23$.


### Tipologie di Quantili

#### Quantili Interpolati

Quando $p \cdot n$ non è un intero, si utilizza un **quantile interpolato**, calcolato con interpolazione lineare tra due valori consecutivi. Questo metodo è standard in software statistici (es. R, Python).

#### Percentili

Caso particolare di quantili, dividono i dati in **100 parti uguali**:

- **25° percentile (primo quartile $Q_1$)**: 25% dei dati è inferiore a questo valore.
- **50° percentile (mediana)**: Divide la distribuzione in due metà uguali.
- **75° percentile (terzo quartile $Q_3$)**: 75% dei dati è inferiore a questo valore.

## Importanza dei Quantili nell'Analisi dei Dati

I quantili permettono di:

1. **Esplorare la variabilità**: Identificare range, asimmetrie e code della distribuzione.
2. **Confrontare gruppi**: Analizzare differenze nella dispersione tra sottopopolazioni.
3. **Rilevare valori anomali**: Utilizzando regole come $\text{valore anomalo} > Q_3 + 1.5 \cdot \text{IQR}$.

::: {#exm-}
Consideriamo ora la variabile `NumPartners` per due gruppi definiti dalla variabile `Gender` ("Man" e "Woman"). Calcoleremo i quantili di ordine 0.1 e 0.9 per ciascun gruppo:

- Il quantile di ordine 0.1 rappresenta il valore al di sotto del quale si trova il 10% dei dati.  
- Il quantile di ordine 0.9 rappresenta il valore al di sotto del quale si trova il 90% dei dati.  

Calcolo per il Gruppo "Man":

```{r}
# Quantili di ordine 0.1 e 0.9 per i maschi
quantile(df[df$Gender == "Man", "NumPartners"], probs = c(0.1, 0.9))
```

- 10° percentile (0.1): $1.0$ → Il 10% degli uomini ha dichiarato al massimo 1 partner sessuale.  
- 90° percentile (0.9): $34.5$ → Il 10% degli uomini con i valori più alti ha dichiarato più di 34 partner sessuali.  

Calcolo per il Gruppo "Woman":

```{r}
# Quantili di ordine 0.1 e 0.9 per le femmine
quantile(df[df$Gender == "Woman", "NumPartners"], probs = c(0.1, 0.9))
```

- 10° percentile (0.1): $1.0$ → Anche per le donne, il 10% dei valori più bassi corrisponde a 1 partner sessuale.  
- 90° percentile (0.9): $18.0$ → Il 10% delle donne con i valori più alti ha dichiarato più di 18 partner sessuali.  

I quantili calcolati forniscono una descrizione chiara della dispersione e della variabilità dei dati nei due gruppi:  

- Il fatto che il 10° percentile sia identico per entrambi i gruppi suggerisce che una porzione simile di intervistati dichiara un numero molto basso di partner sessuali.  
- La differenza nel 90° percentile tra uomini e donne è significativa:  
   - Per gli uomini, il valore è più alto ($34.5$), indicando una maggiore presenza di valori estremi nella coda superiore della distribuzione.  
   - Per le donne, il valore ($18.0$) è inferiore, suggerendo una minore dispersione nella parte alta della distribuzione.  

Questa differenza evidenzia una asimmetria positiva più pronunciata nel gruppo degli uomini, dove pochi individui con valori elevati "tirano" la coda della distribuzione verso destra.  
:::

## La Media come Rappresentazione della Psicologia Umana: Un'Arma a Doppio Taglio?

La media è uno degli strumenti statistici più semplici e intuitivi che i ricercatori utilizzano per sintetizzare i dati. È un indice di tendenza centrale familiare e intuitivo: se chiediamo a un gruppo di persone la loro età e calcoliamo la media, otteniamo un valore che sintetizza in un'unica cifra l'informazione disponibile. Ma cosa significa, in realtà, "riassumere" i dati con la media? E soprattutto, questa operazione ha senso quando si studiano i processi psicologici e il comportamento umano?

In molte discipline scientifiche, il concetto di media è utile perché descrive fenomeni che tendono a essere stabili e uniformi. Per esempio, se misuriamo l’altezza di un gruppo di persone, possiamo aspettarci che la distribuzione sia approssimativamente normale e che la media offra una stima ragionevole di un valore tipico. Tuttavia, la mente umana e i processi psicologici non funzionano come il sistema cardiovascolare o i muscoli. Ogni persona ha esperienze uniche che plasmano le sue risposte, i suoi pensieri e le sue emozioni. 

Un problema centrale, sollevato da @speelman2013mean, riguarda l'implicita assunzione che ci sia un *vero valore* sottostante ai processi psicologici che possiamo stimare attraverso la media, come se il comportamento umano fosse determinato da meccanismi identici in ogni individuo, con le differenze attribuibili solo a "rumore" sperimentale. Questo approccio, tipico della psicologia sperimentale tradizionale, assume che testare un gruppo di persone e mediare i loro risultati ci permetta di rivelare la struttura comune della mente umana. Ma questa assunzione è davvero giustificata?

### La Fallacia Ergodica e l’Illusione dell’Universalità {#sec-eda-ergodic-fallacy}

Un errore metodologico frequente nella psicologia è la cosiddetta *fallacia ergodica*, ovvero l’errata convinzione che le caratteristiche medie di un gruppo possano essere automaticamente applicate ai singoli individui che lo compongono [@speelman2024most]. Questo equivoco nasce dall’idea che la media descriva un valore "tipico" valido per tutti, senza considerare le differenze individuali o le variazioni nel tempo.

Immaginiamo di studiare la felicità di un gruppo di persone nel corso di una settimana e di calcolare la media dei loro punteggi di benessere giornalieri. Se lunedì una persona ha un punteggio di 2 (molto infelice), mercoledì 5 (moderatamente felice) e sabato 8 (molto felice), il suo punteggio medio sarà 5. Tuttavia, questo valore intermedio non rappresenta in alcun modo la realtà soggettiva vissuta da quella persona nei singoli giorni. Lo stesso problema si pone quando si usano le medie per descrivere abilità cognitive, tratti di personalità o stati emotivi: la media può nascondere fluttuazioni e differenze individuali fondamentali per comprendere la psicologia umana.

Il rischio, come sottolineato da @molden2006finding, è che il nostro desiderio di trovare *universalità* nei processi cognitivi ci porti a enfatizzare somiglianze tra le persone, ignorando le variazioni individuali che possono essere altrettanto, se non più, informative. Per esempio, due studenti con lo stesso punteggio medio in un test di memoria potrebbero aver ottenuto quel risultato in modi completamente diversi: uno potrebbe aver avuto prestazioni costantemente nella media, mentre l’altro potrebbe aver avuto picchi di eccellenza alternati a difficoltà estreme.

### La Media: Uno Strumento da Usare con Cautela

Questi problemi non significano che la media sia inutile in psicologia. È un indicatore potente e spesso informativo, ma deve essere interpretato con cautela. In particolare, non può essere usata per fare inferenze sui singoli individui senza considerare altre misure, come la *varianza* e la *deviazione standard*, che ci dicono quanto i dati siano dispersi intorno alla media.

In psicologia, comprendere la variabilità è tanto importante quanto individuare una tendenza centrale. Se vogliamo davvero capire il comportamento umano, dobbiamo chiederci non solo *qual è il valore medio?* ma anche *quanto variano i dati?* e *cosa ci dice questa variabilità sulle differenze individuali?* Nella prossima sezione, esamineremo questi concetti e vedremo come la varianza e la deviazione standard ci aiutano a catturare le differenze che la media, da sola, non può rivelare.

## La Variabilità nei Dati Psicologici  

Nei fenomeni psicologici e comportamentali, **la variabilità è una caratteristica intrinseca**. Ad esempio, se misuriamo il livello di stress percepito da una persona più volte nella stessa giornata, è raro osservare lo stesso valore anche utilizzando strumenti identici. Allo stesso modo, un questionario standardizzato sull’autostima somministrato a un gruppo di studenti universitari restituirà punteggi differenti per ciascun partecipante. Anche registrando i tempi di reazione in un compito cognitivo, noteremo fluttuazioni sia tra individui diversi sia nelle prestazioni dello stesso individuo in prove ripetute.  

Questa **dispersione sistematica** non è un “rumore” da ignorare, ma un elemento informativo cruciale. L’analisi statistica in psicologia ha infatti uno scopo duplice: da un lato, quantificare la variabilità; dall’altro, identificarne le origini. Differenze individuali, contesto ambientale, errori di misurazione o interazioni tra fattori sono solo alcune delle possibili fonti che contribuiscono alla variazione osservata.  

In questa sezione esploreremo:  

1. **La scomposizione della variabilità** in componenti spiegate (attribuibili a fattori noti, come un intervento sperimentale) e non spiegate (legate a elementi casuali o non controllati).  
2. **Strumenti per descriverla**, sia attraverso rappresentazioni grafiche (boxplot, istogrammi) sia mediante indici numerici (differenza interquartile, varianza, deviazione standard).  

Comprendere la variabilità non è un esercizio tecnico, ma un passo fondamentale per interpretare fenomeni complessi come le differenze di personalità, le oscillazioni emotive o l’efficacia di una terapia. Ogni modello psicologico, infatti, deve fare i conti con questa dimensione dinamica e multideterminata dei dati.  

## Misure di Dispersione Basate sui Quantili

Per descrivere la variabilità dei dati, uno dei metodi più semplici consiste nell'utilizzo di indici basati sui quantili. Questi indici forniscono informazioni sulla dispersione dei valori senza fare assunzioni sulla forma della distribuzione.

### Intervallo di Variazione

L’intervallo di variazione è la differenza tra il valore massimo e il valore minimo dei dati:  

$$
\text{Intervallo} = \max(X) - \min(X)
$$

**Vantaggi**:  

- Facile da calcolare e interpretare.  
- Offre un'indicazione immediata dell'ampiezza della distribuzione.  

**Limitazioni**:  

- Considera solo due valori estremi della distribuzione, ignorando tutti gli altri dati.  
- È fortemente influenzato dalla presenza di valori anomali (outlier), risultando poco rappresentativo della variabilità generale.  

**Esempio**:  
Supponiamo di misurare i punteggi di autostima in un campione di adolescenti e di ottenere:  
$$
\max(X) = 35, \quad \min(X) = 12 .
$$

L’intervallo di variazione sarà:  

$$
35 - 12 = 23 .
$$

Questo valore indica che i punteggi variano su un intervallo di 23 punti.

### Differenza Interquartile (Interquartile Range, IQR)

La **differenza interquartile (IQR)** misura la dispersione del **50% centrale** della distribuzione, escludendo i valori più estremi:  

$$
\text{IQR} = Q_3 - Q_1 .
$$

dove:  

- $Q_1$ è il primo quartile (25° percentile), ovvero il valore sotto il quale si trova il 25% dei dati;  
- $Q_3$ è il terzo quartile (75° percentile), ovvero il valore sotto il quale si trova il 75% dei dati.  

**Vantaggi**:  

- **Robusto rispetto ai valori anomali**, poiché considera solo la parte centrale della distribuzione.  
- Utile per identificare **asimmetrie** e la presenza di outlier.  

**Limitazioni**:  

- Non tiene conto della dispersione complessiva dei dati, ma solo di quella nella fascia centrale.  
- Può essere meno informativo in distribuzioni fortemente asimmetriche o con più picchi.  

**Esempio**:  
Se analizziamo il livello di ansia in un gruppo di studenti e troviamo:  

$$
Q_1 = 25, \quad Q_3 = 40 .
$$

allora la differenza interquartile sarà: 

$$
IQR = 40 - 25 = 15 .
$$
Ciò significa che il 50% centrale dei punteggi di ansia si distribuisce in un intervallo di 15 unità.


### Considerazioni Finali 

L’**intervallo di variazione** e la **differenza interquartile** sono due strumenti utili per descrivere la dispersione di una distribuzione, ma presentano anche delle limitazioni. L’intervallo di variazione è molto sensibile ai valori estremi, mentre la differenza interquartile, pur essendo più robusta, considera solo una parte della distribuzione.  

Per ottenere una misura della dispersione più completa, che tenga conto di tutti i dati senza essere eccessivamente influenzata dagli outlier, si ricorre spesso a **misure basate sulla deviazione dai valori medi**, come la **varianza** e la **deviazione standard**. Queste ultime saranno oggetto della prossima sezione.

## La Varianza

La **varianza** è una delle misure di dispersione più utilizzate in statistica perché tiene conto di **tutte** le osservazioni e descrive quanto i valori si discostano dalla loro media. Formalmente, se abbiamo $n$ osservazioni $x_1, x_2, \dots, x_n$ e indichiamo con $\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i$ la loro media, la varianza (in versione **descrittiva**) si calcola così:

$$
S^2 = \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2.
$$ {#eq-var-descr}

In altre parole, per trovare la varianza:

1. Calcoliamo la media di tutti i valori ($\bar{x}$).
2. Sottraiamo la media a ciascun valore, ottenendo così lo **scarto** $(x_i - \bar{x})$.
3. Eleviamo ogni scarto al quadrato, per rendere positivi i valori ed enfatizzare gli scostamenti più grandi.
4. Infine, facciamo la **media** di questi quadrati.

Maggiore è la varianza, maggiore è la variabilità (o dispersione) dei dati rispetto alla media. Al contrario, una varianza prossima allo zero indica che le osservazioni sono molto vicine tra loro e quasi coincidenti con la media.

> **Nota su popolazione e campione:** spesso, nell’analisi di dati campionari, la varianza viene calcolata usando $\frac{1}{n-1}$ al denominatore al posto di $\frac{1}{n}$. In questo modo otteniamo una stima corretta (non distorta) della varianza della popolazione. Nel contesto della formula sopra riportata, invece, stiamo calcolando la varianza **descrittiva** (o **popolazione completa**).


### Esempio pratico

Immaginiamo di aver misurato il numero di **ore di studio** giornaliere di un piccolo gruppo di partecipanti a un esperimento di psicologia. I dati raccolti sono:

$$
x = \{3,\, 1,\, 4,\, 2\}.
$$

Passo 1: Calcolo della media

$$
\bar{x} = \frac{3 + 1 + 4 + 2}{4} = \frac{10}{4} = 2.5.
$$

Passo 2: Scarti dalla media

- Per il primo valore ($x_1 = 3$): $3 - 2.5 = 0.5$
- Per il secondo valore ($x_2 = 1$): $1 - 2.5 = -1.5$
- Per il terzo valore ($x_3 = 4$): $4 - 2.5 = 1.5$
- Per il quarto valore ($x_4 = 2$): $2 - 2.5 = -0.5$

Passo 3: Quadrati degli scarti

- $(0.5)^2 = 0.25$
- $(-1.5)^2 = 2.25$
- $(1.5)^2 = 2.25$
- $(-0.5)^2 = 0.25$

Passo 4: Calcolo della varianza

Facciamo la media di questi valori:

$$
S^2 = \frac{0.25 + 2.25 + 2.25 + 0.25}{4} = \frac{5}{4} = 1.25.
$$

Dunque la varianza è 1.25.

### Interpretazione

Una varianza pari a 1.25 indica che le ore di studio giornaliere si discostano, in media, di **1.25** unità quadrate dalla media di 2.5 ore. Per comprendere meglio l’ordine di grandezza di questa dispersione, solitamente si fa riferimento alla **deviazione standard**, che è la radice quadrata della varianza. In questo caso, $\sqrt{1.25} \approx 1.12$ ore.

- Se la varianza (o la deviazione standard) fosse stata molto più grande, avremmo dedotto che gli studenti del campione presentano abitudini di studio molto diverse.
- Al contrario, se la varianza fosse prossima a 0, significherebbe che quasi tutti studiano un numero di ore molto simile a 2.5.

### Calcolo in R

Se volessimo effettuare lo stesso calcolo in R, potremmo fare così:

```{r}
# Dati
x <- c(3, 1, 4, 2)

# Calcolo manuale della media
media_x <- mean(x)

# Calcolo manuale della varianza secondo la formula descrittiva
varianza_descr <- mean((x - media_x)^2)
varianza_descr
# [1] 1.25

# Calcolo della varianza con la funzione var() di R
# (Attenzione: per default var() usa n-1 al denominatore)
varianza_campionaria <- var(x)
varianza_campionaria
# [1] 1.666667
```

Osserviamo che `var(x)` dà un valore di circa 1.67 perché R, di default, calcola la **varianza campionaria** (con $n-1$ al denominatore). Se vogliamo la **varianza descrittiva** (come nella formula con $n$ al denominatore), usiamo la nostra `varianza_descr`.

**In sintesi**, la varianza fornisce un modo per quantificare quanto siano diverse tra loro le osservazioni. Nel caso dell’esempio sulle ore di studio, abbiamo visto che i valori, pur non essendo tutti identici, non mostrano una dispersione eccessiva (la varianza è 1.25). Se i comportamenti di studio fossero estremamente diversificati (per esempio, se qualcuno studiasse 0 ore al giorno e qualcun altro 10), la varianza sarebbe molto più elevata, indicando una marcata eterogeneità nel campione.

## Stima della Varianza della Popolazione

Si noti il denominatore della formula della varianza. Nell'@eq-var-descr, ho utilizzato $n$ come denominatore (l'ampiezza campionaria, ovvero il numero di osservazioni nel campione). In questo modo, otteniamo la varianza come *statistica descrittiva* del campione. Tuttavia, è possibile utilizzare $n-1$ come denominatore alternativo:

$$
\begin{equation}
s^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2 .
\end{equation}
$$ {#eq-var-stimatore}

In questo secondo caso, otteniamo la varianza come *stimatore* della varianza della popolazione. Si può dimostrare che l'@eq-var-stimatore fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre l'@eq-var-descr fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: $S^2$ rappresenta la varianza come statistica descrittiva, mentre $s^2$ rappresenta la varianza come stimatore.

### Simulazione

Per illustrare questo punto, svolgiamo una simulazione. Consideriamo la distribuzione dei punteggi del quoziente di intelligenza (QI). I valori del QI seguono una particolare distribuzione chiamata *distribuzione normale* (v. @sec-eda-intro-gauss), con media 100 e deviazione standard 15. La forma di questa distribuzione è illustrata nella figura seguente.

```{r}
# Define parameters
x <- seq(100 - 4 * 15, 100 + 4 * 15, by = 0.001)
mu <- 100
sigma <- 15

# Compute the PDF
pdf <- dnorm(x, mean = mu, sd = sigma)

# Plot using ggplot2
data <- tibble(x = x, pdf = pdf)
ggplot(data, aes(x = x, y = pdf)) +
  geom_line() +
  labs(
    x = "QI", 
    y = "Densità", 
    title = "Distribuzione del QI nella popolazione"
  ) 
```

Supponiamo di estrarre un campione casuale di 4 osservazioni dalla popolazione del quoziente di intelligenza -- in altre parole, supponiamo di misurare il quoziente di intelligenza di 4 persone prese a caso dalla popolazione.

```{r}
set.seed(123) 
x <- rnorm(4, mean = 100, sd = 15)
print(x)
```

Calcoliamo la varianza usando $n$ al denominatore. Si noti che la vera varianza del quoziente di intelligenza è $15^2$ = 225.

```{r}
var(x)
```

Consideriamo ora 10 campioni casuali del QI, ciascuno di ampiezza 4.

```{r}
mu <- 100
sigma <- 15
size <- 4
niter <- 10
random_samples <- list()

set.seed(123) 

for (i in 1:niter) {
  one_sample <- rnorm(size, mean = mu, sd = sigma)
  random_samples[[i]] <- one_sample
}
```

Il primo campione è

```{r}
random_samples[1]
```

Il decimo campione è

```{r}
random_samples[10]
```

Stampiamo i valori di tutti i 10 campioni.

```{r}
rs <- do.call(rbind, random_samples)
rs
```

Per ciascun campione (ovvero, per ciascuna riga della matrice
precedente), calcoliamo la varianza usando la formula con $n$ al denominatore.
Otteniamo così 10 stime della varianza della popolazione del QI.

```{r}
x_var <- apply(rs, 1, var)  # Applica la funzione var su ciascuna riga
print(x_var)
```

Notiamo due cose: 

- le stime sono molto diverse tra loro; questo fenomeno è noto con il nome di *variabilità campionaria*;
- in media le stime sono troppo piccole.

Per aumentare la sicurezza riguardo al secondo punto menzionato in precedenza, ripeteremo la simulazione utilizzando un numero di iterazioni maggiore.

```{r}
mu <- 100
sigma <- 15
size <- 4
niter <- 10000
random_samples <- list()

set.seed(123) # Replace 123 with your desired seed for reproducibility

for (i in 1:niter) {
  one_sample <- rnorm(size, mean = mu, sd = sigma)
  random_samples[[i]] <- one_sample
}

rs <- do.call(rbind, random_samples)
x_var <- apply(rs, 1, var) * (size - 1) / size  # Adjust for population variance (ddof = 0)
```

Esaminiamo la distribuzione dei valori ottenuti.

```{r}
# Create a data frame for plotting
data <- data.frame(x_var = x_var)

# Plot the histogram using ggplot2
ggplot(data, aes(x = x_var)) +
  geom_histogram(fill = "lightblue", bins = 30, color = "black") +
  scale_x_continuous(limits = c(0, 1500)) +
  scale_y_continuous(limits = c(0, 2250)) +
  labs(
    x = "Varianza", 
    y = "Frequenza", 
    title = "Varianza del QI in campioni di n = 4"
  )
```

La stima più verosimile della varianza del QI è dato dalla media di
questa distribuzione. 

```{r}
mean(x_var)
```

Si noti che il nostro spospetto è stato confermato: il valore medio della stima della varianza ottenuta con l'@eq-var-descr è troppo piccolo rispetto al valore corretto di $15^2 = 225$. 

Ripetiamo ora la simulazione usando la formula della varianza con $n-1$ al denominatore.

```{r}
set.seed(123) 

mu <- 100
sigma <- 15
size <- 4
niter <- 10000
random_samples <- list()

for (i in 1:niter) {
  one_sample <- rnorm(size, mean = mu, sd = sigma)
  random_samples[[i]] <- one_sample
}

rs <- do.call(rbind, random_samples)
x_var <- apply(rs, 1, var)  # ddof = 1 is default for var in R
```

Esaminiamo la distribuzione dei valori ottenuti.

```{r}
# Create a data frame for plotting
data <- data.frame(x_var = x_var)

# Plot the histogram using ggplot2
ggplot(data, aes(x = x_var)) +
  geom_histogram(fill = "lightblue", bins = 30, color = "black") +
  scale_x_continuous(limits = c(0, 1500)) +
  scale_y_continuous(limits = c(0, 2250)) +
  labs(
    x = "Varianza Corretta", 
    y = "Frequenza", 
    title = "Varianza corretta del QI in campioni di n = 4"
  )
```

Nel secondo caso, se utilizziamo $n-1$ come denominatore per calcolare la stima della varianza, il valore atteso di questa stima è molto vicino al valore corretto di 225. Se il numero di campioni fosse infinito, i due valori sarebbero identici.

```{r}
mean(x_var)
```

In conclusione, le due formule della varianza hanno scopi diversi. 

- La formula della varianza con $n$ al denominatore viene utilizzata come statistica descrittiva per descrivere la variabilità di un particolare campione di osservazioni.
- D'altro canto, la formula della varianza con $n-1$ al denominatore viene utilizzata come stimatore per ottenere la migliore stima della varianza della popolazione da cui quel campione è stato estratto.

## Deviazione Standard

Per interpretare la varianza in modo più intuitivo, si può calcolare la deviazione standard (o scarto quadratico medio o scarto tipo) prendendo la radice quadrata della varianza. La deviazione standard è espressa nell'unità di misura originaria dei dati, a differenza della varianza che è espressa nel quadrato dell'unità di misura dei dati. La deviazione standard fornisce una misura della dispersione dei dati attorno alla media, rendendo più facile la comprensione della variabilità dei dati.

La deviazione standard (o scarto quadratico medio, o scarto tipo) è definita come:

$$
s^2 = \sqrt{(n-1)^{-1} \sum_{i=1}^n (x_i - \bar{x})^2}.
$$ {#eq-sd-stimatore}

Quando tutte le osservazioni sono uguali, $s = 0$, altrimenti $s > 0$.

::: {.callout-note}
Il termine *standard deviation* è stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca $\sigma$ che lo rappresenta. Il termine italiano "deviazione standard" ne è la traduzione più utilizzata nel linguaggio comune; il termine dell’[Ente Nazionale Italiano di Unificazione](https://it.wikipedia.org/wiki/Ente_nazionale_italiano_di_unificazione) è tuttavia “scarto tipo”, definito come la radice quadrata positiva della varianza.
:::

La deviazione standard $s$ dovrebbe essere utilizzata solo quando la media è una misura appropriata per descrivere il centro della distribuzione, ad esempio nel caso di distribuzioni simmetriche. Tuttavia, è importante tener conto che, come la media $\bar{x}$, anche la deviazione standard è fortemente influenzata dalla presenza di dati anomali, ovvero pochi valori che si discostano notevolmente dalla media rispetto agli altri dati della distribuzione. In presenza di dati anomali, la deviazione standard può risultare ingannevole e non rappresentare accuratamente la variabilità complessiva della distribuzione. Pertanto, è fondamentale considerare attentamente il contesto e le caratteristiche dei dati prima di utilizzare la deviazione standard come misura di dispersione. In alcune situazioni, potrebbe essere più appropriato ricorrere a misure di dispersione robuste o ad altre statistiche descrittive per caratterizzare la variabilità dei dati in modo più accurato e affidabile.

### Interpretazione

La deviazione standard misura la dispersione dei dati rispetto alla media aritmetica. In termini semplici, indica quanto, in media, ciascun valore osservato si discosta dalla media del campione. Anche se è simile allo scarto semplice medio campionario (la media dei valori assoluti degli scarti rispetto alla media), la deviazione standard utilizza lo scarto quadratico medio e produce un valore leggermente diverso.

::: {#exm-}
Per verificare l'interpretazione della deviazione standard, utilizziamo i punteggi relativi alle ore di studio di un piccolo numero di studenti.

```{r}
x <- c(3, 1, 4, 2)

std_x <- sqrt(var(x) * 3 / 4)
std_x
```

La deviazione standard calcolata è 1.12. Questo valore ci dice che, in media, ciascun punteggio si discosta di circa 1.12 ore dalla media aritmetica delle ore di studio di questo gruppo di studenti.

- Valore più alto: indica maggiore dispersione dei dati intorno alla media.
- Valore più basso: i dati sono più concentrati vicino alla media.

Se calcoliamo anche lo scarto semplice medio campionario per confronto, otteniamo:

```{r}
mean(abs(x - mean(x)))
```

I due valori (deviazione standard e scarto semplice medio) sono simili ma non identici, a causa delle diverse definizioni matematiche.
:::

## Varianza Spiegata e Non Spiegata

La varianza, come abbiamo visto, misura quanto i dati si disperdono attorno alla media. Un concetto fondamentale nei **modelli statistici lineari** è la distinzione tra **varianza spiegata** e **varianza non spiegata**, che ci permette di valutare quanto bene un modello teorico riesca a chiarire la variabilità osservata nei dati.

### Decomposizione della Varianza

Quando osserviamo un fenomeno (ad esempio i risultati di un test), troviamo inevitabilmente differenze tra individui. Queste differenze possono essere suddivise in due componenti principali:

- **varianza spiegata**: la parte di variabilità che può essere attribuita a fattori identificati e misurabili;
- **varianza non spiegata**: la parte rimanente di variabilità che non è chiarita dai fattori considerati.

Formalmente, questa decomposizione può essere espressa come:

$$
\sum_{i=1}^{n}(Y_i - \bar{Y})^2 = \sum_{i=1}^{n}(\hat{Y}_i - \bar{Y})^2 + \sum_{i=1}^{n}(Y_i - \hat{Y}_i)^2 ,
$$

dove:

- $Y_i$ sono i dati osservati,
- $\bar{Y}$ è la media dei dati osservati,
- $\hat{Y}_i$ sono i valori attesi (previsti) dal modello teorico.

Intuitivamente:

- la **varianza totale** (lato sinistro della formula) rappresenta la dispersione complessiva dei dati attorno alla loro media;
- la **varianza spiegata** (primo termine a destra) indica quanto bene i valori previsti dal modello descrivono il comportamento dei dati;
- la **varianza non spiegata** (secondo termine a destra) riflette ciò che il modello non riesce a prevedere.

### Simulazione in R

Supponiamo di analizzare i punteggi di un esame universitario di "Psicometria" ottenuti da 200 studenti. La nostra teoria indica che i punteggi dipendano da:

1. Ore settimanali dedicate allo studio;
2. Presenza o assenza di "paura della matematica" (*math anxiety*) [@barroso2021meta].

Nello specifico, ipotizziamo:

- una relazione positiva tra ore di studio e punteggio ottenuto;
- una riduzione del 30% del punteggio per chi presenta paura della matematica rispetto agli altri studenti, a parità di ore di studio.

Ecco la simulazione in R:

```{r}
set.seed(123)

# Simuliamo i dati per 200 studenti
n <- 200
ore_studio <- runif(n, min = 2, max = 15) |> round()
paura_mat <- rbinom(n, 1, prob = 0.3)

k <- 2  # Ogni ora di studio corrisponde a circa 2 punti

# Calcoliamo i punteggi attesi, limitati a 30 punti massimo
punteggio_atteso <- ore_studio * k * ifelse(paura_mat == 1, 0.7, 1) |> round()
punteggio_atteso <- ifelse(punteggio_atteso > 30, 30, punteggio_atteso)

# Generiamo punteggi reali aggiungendo casualità (tra 0 e 30 punti)
punteggio_reale <- (punteggio_atteso + rnorm(n, mean = 0, sd = 3)) |> round()
punteggio_reale <- pmin(pmax(punteggio_reale, 0), 30)

# Creiamo il dataset finale
data <- data.frame(ore_studio, paura_mat, punteggio_atteso, punteggio_reale)
head(data)
```

Calcoliamo ora la decomposizione della varianza usando le formule indicate:

```{r}
# Media dei punteggi reali
media_reale <- mean(data$punteggio_reale)

# Calcolo delle componenti della varianza
varianza_totale <- mean((data$punteggio_reale - media_reale)^2)
varianza_spiegata <- mean((data$punteggio_atteso - media_reale)^2)
varianza_non_spiegata <- mean((data$punteggio_reale - data$punteggio_atteso)^2)

# Risultati
c(varianza_totale, varianza_spiegata, varianza_non_spiegata)
```

### Interpretazione dei Risultati

- **Varianza totale** indica quanto in generale i punteggi differiscono tra loro.
- **Varianza spiegata** rappresenta quanto della variabilità totale può essere attribuita ai fattori teorici (ore di studio e paura della matematica).
- **Varianza non spiegata** evidenzia la variabilità residua che il modello non riesce a cogliere.

La proporzione di varianza spiegata è data dal rapporto:

```{r}
prop_spiegata <- varianza_spiegata / varianza_totale
prop_spiegata
```

Questa proporzione è sempre compresa tra 0 e 1:

- valori vicini a 1 indicano che il modello è efficace nel descrivere i dati;
- valori vicini a 0 suggeriscono che il modello non cattura adeguatamente la realtà osservata.

Questa decomposizione della varianza è uno strumento cruciale per valutare l'efficacia delle teorie e dei modelli statistici. Approfondiremo ulteriormente questi aspetti nel capitolo dedicato ai **modelli di regressione** (v.  @sec-linear-models-biv-model-frequentist).

## Deviazione Mediana Assoluta

La **deviazione mediana assoluta** (MAD) è una misura robusta di dispersione basata sulla mediana. È definita come la mediana dei valori assoluti delle deviazioni dei dati rispetto alla mediana:

$$
\text{MAD} = \text{median} \left( |X_i - \text{median}(X)| \right) 
$$ {#eq-mad-def}

La MAD è particolarmente utile per analizzare dati contenenti outlier o distribuzioni asimmetriche, poiché è meno influenzata dai valori estremi rispetto alla deviazione standard.

### Relazione tra MAD e Deviazione Standard in una Distribuzione Normale

Quando i dati seguono una distribuzione normale (gaussiana), esiste una relazione approssimativa tra MAD e deviazione standard. La MAD può essere convertita in una stima della deviazione standard moltiplicandola per una costante di 1.4826:

$$ 
\sigma \approx k \times \text{MAD},
$$

dove:

- $\sigma$ è la deviazione standard,
- MAD è la Mediana della Deviazione Assoluta,
- $k$ è una costante che, per una distribuzione normale, è tipicamente presa come circa 1.4826.

Questa costante deriva dalla proprietà della distribuzione normale, in cui circa il 50% dei valori si trova entro 0.6745 deviazioni standard dalla media.

La formula completa per convertire la MAD in una stima della deviazione standard in una distribuzione normale è:

$$ 
\sigma \approx 1.4826 \times \text{MAD} 
$$

Questa relazione è utile per stimare la deviazione standard in modo più robusto, specialmente quando si sospetta la presenza di outlier o si ha a che fare con campioni piccoli. Di conseguenza, molti software restituiscono il valore MAD moltiplicato per questa costante per fornire un'indicazione più intuitiva della variabilità dei dati. Tuttavia, è importante notare che questa relazione si mantiene accurata solo per le distribuzioni che sono effettivamente normali. In presenza di distribuzioni fortemente asimmetriche o con elevati outlier, la deviazione standard e la MAD possono fornire indicazioni molto diverse sulla variabilità dei dati.

::: {#exm-}
Per verificare questo principio, usiamo un campione di dati simulati dalla distribuzione del QI:

```{r}
qi <- rnorm(200, 100, 15)
1.4826 * median(abs(qi - median(qi)), na.rm = TRUE)
```

Otteniamo un valore che è simile alla deviazione standard calcolata con:

```{r}
sqrt(
  var(qi) * (length(qi) - 1) / length(qi)
)
```

Ciò conferma la relazione tra MAD e deviazione standard in distribuzioni gaussiane.

Se invece usiamo dei dati non normali, l'approssimazione non è buona:

```{r}
set.seed(123) 
y <- rchisq(200, 1)
1.4826 * median(abs(y - median(y)))
```

```{r}
sqrt(
  var(y) * (length(y) - 1) / length(y)
)
```
:::

### Quando Usare Deviazione Standard e MAD

- **Deviazione standard:**
È la misura più appropriata per dati normalmente distribuiti e situazioni in cui l'obiettivo è descrivere la dispersione dei dati rispetto alla media. Tuttavia, è sensibile ai valori anomali (outlier).

- **Deviazione mediana assoluta:**
È ideale quando i dati sono non normali, asimmetrici o contengono outlier. La MAD è più robusta poiché utilizza la mediana anziché la media e non è influenzata da valori estremi.

## Indici di Variabilità Relativi

A volte può essere necessario confrontare la variabilità di grandezze incommensurabili, ovvero di caratteri misurati con differenti unità di misura. In queste situazioni, le misure di variabilità descritte in precedenza diventano inadeguate poiché dipendono dall'unità di misura utilizzata. Per superare questo problema, si ricorre a specifici numeri adimensionali chiamati *indici relativi di variabilità*.

Il più importante di questi indici è il *coefficiente di variazione* ($C_v$), definito come il rapporto tra la deviazione standard ($\sigma$) e la media dei dati ($\bar{x}$):

$$
C_v = \frac{\sigma}{\bar{x}}.
$$ {#eq-cv-def}

Il coefficiente di variazione è un numero puro e permette di confrontare la variabilità di distribuzioni con unità di misura diverse.

Un altro indice relativo di variabilità è la *differenza interquartile rapportata* a uno dei tre quartili (primo quartile, terzo quartile o mediana). Questo indice è definito come:

$$
\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \qquad \frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \qquad \frac{x_{0.75} - x_{0.25}}{x_{0.50}}.
$$

Questi indici relativi di variabilità forniscono una misura adimensionale della dispersione dei dati, rendendo possibile il confronto tra grandezze con diverse unità di misura e facilitando l'analisi delle differenze di variabilità tra i dati.


## Riflessioni Conclusive

Le statistiche descrittive forniscono strumenti essenziali per sintetizzare e comprendere i dati raccolti in psicologia e nelle scienze sociali. Le misure di tendenza centrale, come la media, la mediana e la moda, ci permettono di individuare un valore tipico o rappresentativo di una distribuzione, facilitando la sintesi e l'interpretazione generale dei dati raccolti. Parallelamente, gli indici di dispersione, come la deviazione standard, la varianza e l'intervallo interquartile, offrono informazioni cruciali sulla variabilità, mostrandoci quanto i singoli dati siano vicini o distanti da questa tendenza centrale.

Tuttavia, è fondamentale riflettere attentamente sulle implicazioni teoriche e metodologiche che accompagnano l'uso di queste misure. In particolare, è importante considerare il rischio della **fallacia ergodica**, ovvero l'errata convinzione che i risultati ottenuti da medie e statistiche aggregate possano automaticamente applicarsi ai singoli individui. Nella pratica psicologica, infatti, ogni persona è caratterizzata da una notevole variabilità intra- e inter-individuale, che spesso non può essere adeguatamente rappresentata da semplici indicatori aggregati.

Le statistiche descrittive rappresentano quindi un primo e fondamentale passo nella comprensione dei dati psicologici, ma devono essere integrate da analisi più approfondite e attente alle differenze individuali. L'uso critico e consapevole di questi strumenti statistici ci consente di evitare generalizzazioni eccessive, fornendo una visione più accurata e realistica dei fenomeni psicologici e comportamentali che studiamo.


## Esercizi {.unnumbered}

::: {.callout-important title="Problemi" collapse="true"}

**Parte 1: Domande Teoriche**

1. **Definizione e comprensione dei concetti**

   - Spiega la differenza tra media, mediana e moda.
   - In quali situazioni la mediana fornisce una misura della tendenza centrale migliore rispetto alla media?
   - Perché la media è sensibile ai valori estremi?
   - Quali sono i vantaggi della deviazione mediana assoluta (MAD) rispetto alla deviazione standard?
   
2. **Interpretazione della variabilità**

   - Spiega il concetto di varianza e la sua interpretazione.
   - Qual è la differenza tra varianza e deviazione standard?
   - Descrivi in quali casi l'utilizzo del coefficiente di variazione è più appropriato rispetto alla deviazione standard.
   - Quali sono i limiti della moda come indice di tendenza centrale?
   
**Parte 2: Calcoli Manuali**

3. **Calcolo della media, mediana e moda**

   - Considera i seguenti punteggi totali della SWLS che sono stati raccolti in un campione di studenti. Calcola manualmente:
   
     - La media
     - La mediana
     - La moda
     - Il range

4. **Calcolo della varianza e della deviazione standard**

   - Usando gli stessi dati dell'esercizio precedente, calcola:
     - La varianza
     - La deviazione standard
     - La deviazione mediana assoluta (MAD)
   
**Parte 3: Esercizi con R**

5. **Analisi descrittiva con R**

   - Carica il dataset `swls_scores.csv` contenente i punteggi SWLS degli studenti.
   - Calcola media, mediana e moda utilizzando R.
   - Calcola la varianza e la deviazione standard utilizzando le funzioni appropriate in R.
   
   **Codice suggerito:**
   
   ```r
   library(tidyverse)
   library(rio)
   
   # Caricamento del dataset
   df <- import("swls_scores.csv")
   
   # Calcolo delle statistiche descrittive
   mean(df$swls_total)
   median(df$swls_total)
   
   # Moda (funzione personalizzata)
   get_mode <- function(x) {
     tbl <- table(x)
     as.numeric(names(tbl)[which.max(tbl)])
   }
   get_mode(df$swls_total)
   
   # Varianza e deviazione standard
   var(df$swls_total)
   sd(df$swls_total)
   
   # Deviazione mediana assoluta
   mad(df$swls_total)
   ```
   
6. **Visualizzazione della distribuzione dei dati**

   - Crea un istogramma dei punteggi totali della SWLS.
   - Aggiungi una linea verticale che rappresenti la media e una che rappresenti la mediana.
   
   **Codice suggerito:**
   
   ```r
   ggplot(df, aes(x = swls_total)) +
     geom_histogram(binwidth = 2, fill = "blue", alpha = 0.5, color = "black") +
     geom_vline(aes(xintercept = mean(swls_total)), color = "red", linetype = "dashed", size = 1) +
     geom_vline(aes(xintercept = median(swls_total)), color = "green", linetype = "dotted", size = 1) +
     labs(title = "Distribuzione dei punteggi SWLS", x = "Punteggio SWLS", y = "Frequenza")
   ```
   
**Parte 4: Domande di Comprensione**

7. **Analisi concettuale**

   - Perché la media aritmetica può essere considerata il "baricentro" della distribuzione dei dati?
   - Se aggiungiamo un valore estremo al dataset, quale delle misure di tendenza centrale subirà il maggior impatto?
   - In quali situazioni la varianza campionaria è preferibile rispetto alla varianza della popolazione?
   - Qual è la relazione tra la deviazione standard e la varianza?
   - Fornisci un'interpretazione intuitiva della deviazione standard.
   - Discuti le differenze e le somiglianze tra la deviazione standard e MAD. Usa queste informazioni per ridescrivere in maniera intuitiva il significato di deviazione standard.
:::

::: {.callout-tip title="Soluzioni" collapse="true"}
Poniamo che i valori SWLS siano [ 18, 22, 26, 19, 24, 30, 26, 22, 18, 28, 21 ].

1. **Media:**
   $$ \bar{x} = \frac{18 + 22 + 26 + 19 + 24 + 30 + 26 + 22 + 18 + 28 + 21}{11} = 23.36 $$
   
2. **Mediana:**
   Ordinando i dati: [ 18, 18, 19, 21, 22, 22, 24, 26, 26, 28, 30 ]
   La mediana è il valore centrale: $22$
   
3. **Moda:**
   Il valore più frequente è **22** (appare due volte).
   
4. **Varianza:**
   $$ s^2 = \frac{\sum (x_i - \bar{x})^2}{n-1} = 13.96 $$
   
5. **Deviazione Standard:**
   $$ s = \sqrt{13.96} = 3.73 $$
   
6. **MAD:**
   $$ \text{MAD} = \text{mediana}(|X_i - \text{mediana}(X)|) = 4 $$
   
**Soluzioni con R**

I risultati eseguendo il codice R:

   - **Media:** 23.36
   - **Mediana:** 22
   - **Moda:** 22
   - **Varianza:** 13.96
   - **Deviazione standard:** 3.73
   - **MAD:** 4

**Soluzioni alle Domande di Comprensione**

1. La media è il baricentro poiché minimizza la somma degli scarti quadrati.
2. La media è più influenzata dai valori estremi rispetto alla mediana.
3. La varianza campionaria corregge la sottostima della varianza popolazionale.
4. La deviazione standard è la radice quadrata della varianza, consentendo un'interpretazione del risultato sulla scala dei dati grezzi.
5. La deviazione standard è simile, ma non identica, al valore medio degli scarti assoluti tra ciascun valore della distribuzione e la media. In altre parole, rappresenta la "distanza tipica" media tra le osservazioni e il valore medio della distribuzione.
6. La deviazione standard e il MAD (Median Absolute Deviation, o scarto medio assoluto) sono entrambi misure di variabilità che descrivono quanto i valori in un insieme di dati si discostino dal centro della distribuzione. Tuttavia, presentano alcune importanti differenze e somiglianze.

  **Somiglianze**
  
  - Entrambe le misure quantificano la dispersione dei dati attorno a un punto centrale.
  - Sia la deviazione standard che il MAD utilizzano lo scarto (la differenza tra ciascun valore e un punto centrale) per calcolare la variabilità.
  
  **Differenze**
  
  - **Punto centrale usato:** La deviazione standard si basa sulla media aritmetica, mentre il MAD si basa sulla mediana.
  - **Trattamento degli scarti:** Nella deviazione standard, gli scarti vengono elevati al quadrato prima di essere mediati, quindi la radice quadrata viene applicata al risultato finale. Questo processo penalizza maggiormente gli scarti più grandi, rendendo la deviazione standard più sensibile agli outlier. Il MAD, invece, considera semplicemente il valore assoluto degli scarti, rendendolo meno influenzato dagli estremi.
  - **Sensibilità agli outlier:** Poiché la deviazione standard dipende dai quadrati degli scarti, è più sensibile alle osservazioni estreme (outlier). Il MAD, essendo basato sulla mediana, è una misura più robusta e resiste meglio alla presenza di valori anomali.
  
  **Ridescrizione Intuitiva della Deviazione Standard**
  
  - La deviazione standard può essere vista come una misura della "dispersione tipica" dei dati attorno alla media, ma con un'enfasi particolare sugli scarti più grandi. Immagina di prendere ogni valore del dataset, calcolarne la distanza dalla media, amplificare queste distanze attraverso il quadrato, poi trovare una sorta di "distanza media" ponderata. Questo processo dà maggiore peso agli scarti più grandi, fornendo così una visione della variabilità che tiene conto sia delle fluttuazioni ordinarie sia di eventuali valori estremi. In sintesi, mentre il MAD offre una visione più resistente e diretta della variabilità centrata sulla mediana, la deviazione standard fornisce una misura più dettagliata e sensibile alla forma complessiva della distribuzione, inclusi i suoi possibili outliers. 
:::

## Informazioni sull'Ambiente di Sviluppo {.unnumbered}

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}


