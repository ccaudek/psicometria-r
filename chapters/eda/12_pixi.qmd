# Flusso di lavoro riproducibile üî∏ {#sec-r-workflow}


::: callout-note
## In questo capitolo imparerai a

- organizzazione un progetto di analisi dei dati
- conoscere le funzionalit√† di `targets` e di Pixi
:::

::: callout-tip
## Prerequisiti

- Leggere "1,500 scientists lift the lid on reproducibility" [@baker20161].
:::

::: callout-important
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(readr)
```
:::


## Introduzione

In questo capitolo esploreremo gli strumenti essenziali per garantire che il flusso di lavoro di un progetto di analisi dei dati in R sia pienamente riproducibile.

## Analisi e Flussi di Lavoro Riproducibili

La possibilit√† di confermare ripetutamente i risultati scientifici attraverso la replica √® un principio fondamentale della scienza. Questo concetto si basa sull'idea che una verit√† scientifica debba resistere a ulteriori indagini da parte di altri osservatori. In ambito scientifico, √® utile distinguere due aspetti legati alla replica: **replicabilit√†** e **riproducibilit√†**.

- **Replicabilit√†**: si riferisce alla capacit√† di ottenere risultati simili con dati diversi, ma seguendo lo stesso protocollo sperimentale.
- **Riproducibilit√†**: indica la capacit√† di ottenere gli stessi risultati utilizzando gli stessi dati e lo stesso metodo di analisi, sia dalla stessa persona che da altri.

### Riproducibilit√† dei Dati

La replicazione di esperimenti fisici pu√≤ presentare difficolt√† pratiche significative. Tuttavia, anche riprodurre semplicemente un‚Äôanalisi dei dati, che sembra un compito pi√π semplice, √® spesso problematico per molteplici ragioni. Tradizionalmente, i ricercatori annotavano scrupolosamente i dettagli sperimentali nei loro taccuini di laboratorio, consentendo di replicare l‚Äôesperimento. Oggi, strumenti software moderni permettono di applicare lo stesso principio alla riproduzione dei dati: tutto il necessario per rifare l‚Äôanalisi deve essere documentato in modo chiaro e centralizzato.

Questi strumenti non solo facilitano la ripetizione dell‚Äôanalisi, ma permettono anche di migliorarla e applicarla facilmente a nuovi dati. Tuttavia, per essere riproducibile, l‚Äôanalisi deve essere scritta in modo appropriato, utilizzando ambienti di programmazione statistica come R o Python, che permettono l‚Äôautomazione del processo. Al contrario, software come i fogli di calcolo non sono adatti a garantire riproducibilit√†, perch√© legano i comandi a celle specifiche, rendendo l‚Äôadattamento a nuovi dati complesso e soggetto a errori.

## La Crisi della Replicazione e la Riproducibilit√†

La crisi della replicazione evidenzia un problema crescente nella scienza moderna: molti studi pubblicati, anche sottoposti a peer review, non sono replicabili. Studi come quello di @ioannidis2005most e @baker20161 denunciano che molte ricerche sperimentali e statistiche non resistono alla verifica di altri ricercatori. Questo significa che, nonostante l'apparente validit√† dei risultati, spesso non √® possibile raggiungere le stesse conclusioni ripetendo lo studio.

Tra le cause di questa crisi figurano problematiche complesse come la molteplicit√† e i percorsi analitici alternativi (il cosiddetto *garden of forking paths*). Tuttavia, indipendentemente da queste difficolt√†, un‚Äôanalisi riproducibile √® un requisito minimo per garantire la validit√† dei risultati.

::: {.callout-note}

Un problema che compromette la solidit√† delle conclusioni di molti studi √® stato definito da [Andrew Gelman](https://statmodeling.stat.columbia.edu/), della Columbia University, come il [garden of forking paths](https://en.wikipedia.org/wiki/Forking_paths_problem) (giardino dei sentieri che si biforcano). La maggior parte delle analisi richiede una serie di decisioni su come codificare i dati, identificare i fattori rilevanti e formulare (e successivamente rivedere) i modelli prima di arrivare alle analisi finali. Questo processo implica spesso l'esame dei dati per costruire una rappresentazione parsimoniosa. Ad esempio, un predittore continuo potrebbe essere suddiviso arbitrariamente in gruppi per valutare la relazione con l'esito, oppure alcune variabili potrebbero essere incluse o escluse da un modello di regressione durante una fase esplorativa.

Questo approccio tende a favorire risultati dei test di ipotesi che sono distorti verso il rigetto dell'ipotesi nulla, poich√© le decisioni prese durante il processo possono privilegiare segnali pi√π forti (o p-value pi√π piccoli) rispetto ad altre alternative. Nella maggior parte dei problemi di data science, questo rappresenta una sfida importante che solleva dubbi sulla riproducibilit√† dei risultati.

:::

## Elementi chiave per un workflow riproducibile

Un flusso di lavoro riproducibile si compone di tre elementi fondamentali:

1. **Ambienti di programmazione statistica scriptabili**: software come R o Python consentono di automatizzare le analisi e ridurre gli errori manuali.
2. **Analisi riproducibili**: basate sull‚Äôapproccio della *literate programming*, dove codice e documentazione sono integrati per garantire trasparenza e comprensione.
3. **Controllo di versione**: sistemi come Git e piattaforme come GitHub permettono di monitorare e documentare i cambiamenti, favorendo la collaborazione e la tracciabilit√†.

Integrare questi componenti nella pratica quotidiana non solo migliora la qualit√† delle analisi, ma contribuisce a rafforzare la fiducia nella scienza.

## Gestione del Workflow

L‚Äôutilizzo di R per scrivere script che documentano le analisi dei dati √® un importante passo avanti verso la riproducibilit√†, ma non garantisce automaticamente che il progetto possa essere replicato con successo da altri ricercatori. A conferma di ci√≤, uno studio condotto da @obels2020analysis ha analizzato la condivisione di dati e codice per articoli pubblicati come *Registered Reports* nella letteratura psicologica tra il 2014 e il 2018. Tentando di riprodurre i risultati principali di ciascun articolo, hanno osservato quanto segue:

> "Abbiamo esaminato dati e script condivisi per i Registered Reports pubblicati nella letteratura psicologica dal 2014 al 2018 e tentato di riprodurre computazionalmente i risultati principali di ciascun articolo. Dei 62 articoli che soddisfacevano i nostri criteri di inclusione, 41 mettevano a disposizione i dati e 37 gli script di analisi. Dati e codice erano condivisi per 36 articoli. Siamo riusciti a eseguire gli script per 31 analisi e a riprodurre i risultati principali di 21 articoli. Sebbene la percentuale di articoli con dati e codice condivisi (58%) e quella degli articoli riproducibili computazionalmente (58%) siano relativamente alte rispetto ad altri studi, c'√® un evidente margine di miglioramento."

Questi risultati evidenziano come, anche con dati e codice disponibili, la riproducibilit√† non sia garantita. Gli script possono essere incompleti o l'ambiente di sviluppo originale potrebbe non essere replicabile da altri ricercatori.

### Strumenti per la Gestione del Workflow

Per migliorare la riproducibilit√†, esistono diversi strumenti per la gestione del workflow, che permettono di strutturare i progetti in modo chiaro e ripetibile:

- **Make**: uno strumento storico per sistemi Unix, noto per la sua portabilit√† e la presenza predefinita su molti sistemi.
- **Snakemake**: popolare in biologia, offre flessibilit√† nella gestione di workflow complessi.
- **targets**: specifico per R, consente una gestione semplice ed efficace di workflow riproducibili in progetti di analisi dati.
- **Pixi**: un workflow manager innovativo basato sull'ecosistema **Conda**.

Questi strumenti aiutano a coordinare i diversi passaggi di un'analisi, mantenendo traccia dei file e garantendo che ogni fase del processo sia ripetibile.

#### Limiti degli Strumenti di Workflow Management

L‚Äôadozione di strumenti per la gestione del workflow richiede un certo investimento iniziale. Oltre a scrivere gli script per l‚Äôanalisi dei dati, √® necessario sviluppare ulteriori script per definire il workflow, riorganizzando il progetto per garantire riproducibilit√†. Questo processo pu√≤ rendere pi√π complesso il debug e le modifiche successive, motivo per cui alcuni ricercatori possono trovare impegnativo integrare tali strumenti.

## Funzioni e Astrazione

Il pacchetto **`targets`** √® uno strumento per R che semplifica la gestione dei workflow riproducibili. La sua utilit√† emerge soprattutto nei progetti complessi, dove il codice pu√≤ diventare lungo e difficile da gestire. 

### Gestione di codice lungo e complesso

Nel contesto di analisi dati, il codice pu√≤ includere diverse sezioni che svolgono compiti specifici e spesso ripetuti, come l'importazione dei dati, la pulizia, l'analisi e la generazione di report. Man mano che il progetto cresce, tenere traccia delle diverse parti del codice e farle funzionare in sequenza pu√≤ diventare complicato.

Un codice ben scritto deve essere chiaro e comunicare il suo scopo in modo efficace. La trasparenza aumenta la possibilit√† che il codice sia compreso, sia dagli altri ricercatori sia da te stesso in futuro.

Un modo efficace per affrontare la complessit√† √® suddividere il codice in **funzioni**, utilizzando il concetto di **astrazione** per ridurre la complessit√† e migliorare la leggibilit√†.

### Funzioni: Gestire la Complessit√†

Una **funzione** √® un blocco di codice che realizza un compito specifico. Le funzioni permettono di evitare ripetizioni, rendendo il codice pi√π compatto e leggibile. In R esistono molte funzioni integrate, come `mean()` per calcolare la media aritmetica, ma, come abbiamo visto in precedenza, √® possibile scrivere funzioni personalizzate per compiti specifici.

Le funzioni devono essere il pi√π generali possibile per favorirne il riutilizzo in diversi progetti.

### Il Concetto di Astrazione

**L‚Äôastrazione** consiste nel suddividere il codice complesso in compiti pi√π piccoli e specifici, delegando i dettagli a funzioni. Questo approccio semplifica la struttura del codice principale (main script), rendendolo pi√π leggibile e autoesplicativo [@filazzola2022call].

Nel main script, le funzioni sono richiamate in sequenza, mentre i dettagli sono "nascosti" nei file che contengono le definizioni delle funzioni. Ad esempio:

#### Main Script:

```r
library(tidyverse)
library(here)

source("R/functions.R")

# Importa e pulisci i dati
raw_data <- read_csv(here("data/raw_data.csv"))
cleaned_data <- clean_data(raw_data)

# Modello
my_model <- fit_model(data = cleaned_data, response = "Value", predictor = "Gradient")
summary(my_model)

# Grafico
my_plot <- make_plot(cleaned_data)
```

#### Script delle Funzioni:

```r
clean_data <- function(data){
  data |> 
    filter(!is.na(Value)) |> 
    mutate(Gradient = recode(Gradient, "C" = "Control", "B" = "Treatment")) |> 
    filter(Taxon == "SpeciesA")
}

fit_model <- function(data, response, predictor){
  lm(as.formula(paste(response, "~", predictor)), data = data)
}

make_plot <- function(data){
  ggplot(data, aes(x = Gradient, y = Value)) +
    geom_boxplot()
}
```

Questa separazione migliora la leggibilit√†, la modularit√† e la riutilizzabilit√† del codice.

## Introduzione a `targets`

`targets` √® uno strumento per la gestione di pipeline in R, progettato per coordinare i diversi passaggi di un‚Äôanalisi dati. Permette di automatizzare e ottimizzare il workflow, gestire le dipendenze tra i vari step, e tenere traccia degli oggetti obsoleti che necessitano di essere aggiornati. Una delle sue caratteristiche chiave √® la capacit√† di evitare inutili ripetizioni, riducendo i tempi di esecuzione.

In una pipeline di `targets`, ogni passaggio rappresenta un "target", che pu√≤ essere un oggetto R come un dataset, un modello o una figura. Ogni target √® generato da una funzione e la pipeline viene orchestrata da uno script principale chiamato `_targets.R`, che tiene traccia delle dipendenze tra i target e ne garantisce l‚Äôesecuzione nell‚Äôordine corretto.

Questa struttura √® coerente con il concetto di **astrazione**: suddividere il codice complesso in compiti pi√π semplici e ben definiti.

### Quando utilizzare `targets`?

- **Codice complesso o con lunghi tempi di esecuzione**: Quando il codice richiede molto tempo per essere elaborato, `targets` evita di rieseguire le parti gi√† aggiornate e supporta l'elaborazione in parallelo, ottimizzando i tempi di calcolo.  
- **Workflow con dipendenze tra i passaggi**: Se il flusso di lavoro include step interconnessi, `targets` semplifica la gestione delle dipendenze, garantendo che ogni step sia eseguito nell'ordine corretto.  
- **Riproducibilit√† dell‚Äôanalisi**: Automatizza il controllo dell‚Äôallineamento tra codice, dati e risultati, assicurando che il workflow sia sempre coerente e riproducibile.  

In breve, `targets` consente di creare pipeline di analisi dati riproducibili e scalabili, migliorando l‚Äôefficienza e la gestione del workflow in R. Per un approfondimento pratico, √® possibile consultare il tutorial disponibile nella pagina web [The {targets} R package user manual](https://books.ropensci.org/targets/walkthrough.html).

## Pixi

Oltre a `targets`, vale la pena citare **Pixi**, un moderno workflow manager progettato per semplificare la gestione dei flussi di lavoro nei progetti di analisi dati. Pixi si distingue per la sua semplicit√† d‚Äôuso e la capacit√† di affrontare le sfide legate alla riproducibilit√† e all‚Äôorganizzazione di progetti complessi.

Pixi √® un gestore di pacchetti rapido e versatile, basato sull'ecosistema **Conda**, che facilita la creazione e la gestione di ambienti di sviluppo su piattaforme come Windows, macOS e Linux. Supporta un‚Äôampia gamma di linguaggi di programmazione, tra cui **Python**, **R**, **C/C++**, **Rust** e **Ruby**, offrendo una grande flessibilit√† per progetti interdisciplinari. Una delle sue caratteristiche principali √® la possibilit√† di creare ambienti riproducibili senza la complessit√† aggiuntiva di strumenti come Docker, riducendo cos√¨ i tempi e gli sforzi necessari per configurare e mantenere il progetto.

Con Pixi, una configurazione iniziale ben organizzata permette di concentrare le energie sull'analisi dei dati e sulla produzione di risultati, garantendo al contempo un workflow riproducibile e ben strutturato. Questo lo rende uno strumento ideale per migliorare l'efficienza e l‚Äôaffidabilit√† dei progetti di analisi dati.

### Installazione di Pixi

Per utilizzare Pixi, √® necessario avere installati **R**, **RStudio** e Pixi stesso. L'installazione di Pixi √® semplice seguendo le [indicazioni ufficiali](https://github.com/prefix-dev/pixi). Per installare Pixi, √® sufficiente eseguire il seguente comando nel terminale:

```bash
curl -fsSL https://pixi.sh/install.sh | bash
```

### Struttura del Progetto

Immaginiamo che il progetto segua questa struttura organizzativa:

```
data-analysis-project/
‚îÇ
‚îú‚îÄ‚îÄ pixi.toml               # File di configurazione Pixi
‚îú‚îÄ‚îÄ pixi.lock               # Lockfile per le dipendenze
‚îÇ
‚îú‚îÄ‚îÄ data/                   # Directory per i dati
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Dati grezzi
‚îÇ   ‚îî‚îÄ‚îÄ processed/          # Dati processati
‚îÇ
‚îú‚îÄ‚îÄ src/                    # Codice sorgente in R
‚îÇ   ‚îú‚îÄ‚îÄ data_cleaning.R     # Script per pulizia dei dati
‚îÇ   ‚îú‚îÄ‚îÄ analysis.R          # Script per analisi
‚îÇ   ‚îî‚îÄ‚îÄ visualization.R     # Script per visualizzazioni
‚îÇ
‚îú‚îÄ‚îÄ reports/                # Report e output
‚îÇ   ‚îú‚îÄ‚îÄ figures/            # Figure generate
‚îÇ   ‚îî‚îÄ‚îÄ report.Rmd          # Report in R Markdown
‚îÇ
‚îî‚îÄ‚îÄ README.md               # Documentazione del progetto
```

---

### Configurazione di Pixi

Per configurare Pixi, si crea un file `pixi.toml` nella directory principale del progetto:

```toml
[project]
name = "r-data-analysis"
description = "Progetto di analisi dati con R"
authors = ["Tuo Nome <tua.email@example.com>"]
channels = ["conda-forge"]
platforms = ["osx-64", "linux-64","win-64"]

[dependencies]
r-base = ">=4.3,<5"
r-tidyverse = "*"
r-rio= "*"
r-knitr = "*"
r-rmarkdown = "*"
r-here = "*"

[tasks]
clean = "rm -rf reports/figures/* data/processed/*"
data-prep = "Rscript src/data_cleaning.R"
analysis = "Rscript src/analysis.R"
report = "Rscript -e 'rmarkdown::render(\"reports/report.Rmd\")'"
all = { depends-on = ["clean", "data-prep", "analysis", "report"] }
```


### Script di Pulizia Dati (`src/data_cleaning.R`)

Uno script per pulire e organizzare i dati grezzi:

```r
library(readr)
library(dplyr)

# Caricamento dati grezzi
raw_data <- read_csv("data/raw/dati_esempio.csv")

# Pulizia e trasformazione dei dati
cleaned_data <- raw_data %>%
  filter(!is.na(valore)) %>%
  mutate(categoria = factor(categoria)) %>%
  group_by(categoria) %>%
  summarise(media = mean(valore, na.rm = TRUE))

# Salvataggio dei dati processati
write_csv(cleaned_data, "data/processed/dati_puliti.csv")
```


### Script di Analisi (`src/analysis.R`)

Uno script per eseguire analisi statistiche e creare visualizzazioni:

```r
library(readr)
library(dplyr)
library(ggplot2)

# Caricamento dei dati processati
dati <- read_csv("data/processed/dati_puliti.csv")

# Analisi statistica
risultati_analisi <- dati %>%
  group_by(categoria) %>%
  summarise(
    media = mean(media),
    deviazione_standard = sd(media)
  )

# Salvataggio dei risultati
write_csv(risultati_analisi, "reports/risultati_analisi.csv")

# Creazione di un grafico
grafico <- ggplot(dati, aes(x = categoria, y = media)) +
  geom_bar(stat = "identity") +
  ggtitle("Media per Categoria")

# Salvataggio del grafico
ggsave("reports/figures/media_categoria.png", plot = grafico)
```

### Creazione di un Report (`reports/report.Rmd`)

Un report generato con R Markdown per presentare i risultati dell'analisi:

````
---
title: "Report di Analisi dei Dati"
output: html_document
---

## Risultati dell'Analisi

```
library(readr)
library(knitr)
risultati <- read_csv("reports/risultati_analisi.csv")
kable(risultati)
```

## Grafico delle Medie per Categoria

![Media per Categoria](figures/media_categoria.png)
````

### Esecuzione del Workflow con Pixi

Una volta installato Pixi, puoi inizializzare un nuovo progetto con:

```bash
# Inizializzazione del progetto
pixi init
```

Per installare le dipendenze specificate in `in pixi.toml`, esegui:

```bash
# Installazione delle dipendenze specificate in pixi.toml
pixi install
```

Questo comando crea un file `pixi.lock` che elenca tutte le dipendenze del progetto, garantendo che l'ambiente possa essere ricreato in modo identico su diverse macchine.

Per eseguire le attivit√† definite, utilizza:

```bash
pixi run data-prep
pixi run analysis
pixi run report
```

Oppure, per eseguire tutte le attivit√† in sequenza:

```bash
pixi run all
```

Il codice utilizzato in questo tutorial √® disponibile nel [repository GitHub dedicato](https://github.com/ccaudek/pixi-tutorial).

## Riflessioni Conclusive

Strumenti di workflow management come `targets` e Pixi offrono soluzioni efficaci per semplificare e ottimizzare la gestione dei progetti di analisi dati in R. Automatizzando i flussi di lavoro, questi strumenti garantiscono riproducibilit√†, coerenza e organizzazione, riducendo la possibilit√† di errori. Una configurazione iniziale ben strutturata consente di focalizzarsi sull‚Äôanalisi e sull‚Äôinterpretazione dei dati, massimizzando l‚Äôefficienza e migliorando la qualit√† complessiva del processo.


## Informazioni sull'Ambiente di Sviluppo {.unnumbered}

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

