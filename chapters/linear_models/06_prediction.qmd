# Predizione e inferenza {#sec-linear-models-prediction}

::: callout-note
## In questo capitolo imparerai a

- 
:::

::: callout-tip
## Prerequisiti

- Leggere *Regression and Other Stories* [@gelman2021regression].
  - Prestare particolare attenzione al capitolo 9, "Prediction and Bayesian inference", che offrono una guida dettagliata ai temi della predizione e dell'inferenza nel modello bayesiano di regressione lineare bivariata.
:::

::: callout-important
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(cmdstanr, posterior)
```
:::

## Introduzione

@gelman2021regression osservano che l'inferenza bayesiana si sviluppa in tre passaggi fondamentali, che vanno oltre la stima classica. In primo luogo, i dati e il modello vengono combinati per formare una distribuzione a posteriori, che solitamente viene riassunta tramite le distribuzioni a posteriori dei parametri del modello. In secondo luogo, è possibile propagare l'incertezza presente in questa distribuzione, ottenendo previsioni basate su simulazioni per risultati non osservati o futuri, tenendo conto dell'incertezza nei parametri del modello. Infine, è possibile integrare ulteriori informazioni nel modello utilizzando una distribuzione a priori. Questo capitolo si concentra sui temi della previsione e dell'inferenza.

## Predizione

Per discutere i temi della predizione e dell'inferenza bayesiana nel contesto del modello bayesiano di regressione lineare bivariata, esamineremo nuovamente il set di esaminati nel @sec-bivariate-bayesian-regression e relativi alla relazione tra Tense Arousal e ansia di stato.

```{r}
df <- rio::import(here::here("data", "affect.csv")) |> 
  dplyr::select(state1, TA1)
df |> 
  head()
```

Consideriamo il modello bayesiano di regressione lineare bivariata che include prior uniformi per i parametri $\alpha$, $\beta$ e $\sigma$ che abbiamo discusso nel @sec-bivariate-bayesian-regression. Compiliamo il modello.


```{r}
model <- cmdstan_model(here::here("stan", "arousal_model_prior_raw.stan"))
```

Il modello ha questa forma:

```{r}
model$print()
```

Sistemiamo i dati in un dizionario come richiesto dal modello Stan.

```{r}
stan_data = list(
  N = length(df$TA1),
  x = df$state1,
  y = df$TA1
)
```

Eseguiamo il campionamento MCMC.

```{r}
#| message: false
#| 
fit1 <- model$sample(
  data = stan_data,
  seed = 123,
  iter_warmup = 2000,
  iter_sampling = 2000,
  show_message = FALSE
)
```

Esaminiamo le distribuzioni a posteriori dei parametri:

```{r}
fit1$summary(variables = c("alpha", "beta", "sigma"))
```

Il punto importante qui è che la distribuzione a posteriori non fornisce solo informazioni sui singoli parametri, ma anche sulle loro interdipendenze. Queste relazioni sono riflesse nei campioni a posteriori, che possono essere trasformati in vari modi. Ad esempio, possiamo calcolare la predizione a posteriori del modello lineare per il valore atteso di Tense Arousal quando l'ansia di stato è pari a 30 usando il seguente comando nel blocco `generated quantities`:

`pred = alpha + beta * 30;`

Modifichiamo il modello Stan che include la specifica di distribuzioni debolmente informative sui  parametri $\alpha$, $\beta$ e $\sigma$ per aggiungere questo comando nel blocco `generated quantities` e compiliamo il modello.

```{r}
model2 <- cmdstan_model(here::here("stan", "arousal_model2.stan"))
```

Il modello ha questa forma:

```{r}
model2$print()
```

In questo modello Stan aggiornato, il blocco `generated quantities` calcola la predizione a posteriori `pred` per una variabile predittore con valore 30. Questa modifica permette di ottenere la distribuzione a posteriori della predizione per un valore specifico del predittore.

Eseguiamo il campionamento.

```{r}
#| message: false
#| 
fit2 <- model2$sample(
  data = stan_data,
  seed = 123,
  iter_warmup = 2000,
  iter_sampling = 2000,
  show_message = FALSE
)
```

Esaminiamo la stima a posteriori del valore atteso di Tense Arousal quando l'ansia di stato è pari a 30. Questa analisi fornirà sia una stima puntuale di Tense Arousal che una misura dell'incertezza associata, rappresentata dall'intervallo di credibilità al livello di confidenza scelto.

```{r}
fit2$summary(variables = "pred")
```

## Quantificazione dell'incertezza

Per quantificare l'incertezza complessiva nelle predizioni del modello, possiamo calcolare la distribuzione a posteriori delle predizioni per tutti i valori di $x$ del campione. Questo ci permette di ottenere sia le stime puntuali delle predizioni sia una misura dell'incertezza associata.

Per fare ciò, modifichiamo il blocco `generated quantities` nel seguente modo:

```
generated quantities {
  vector[N] y_rep; // Predizioni a posteriori per ciascun valore di x
  
  for (n in 1:N) {
    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);
  }
}
```

Esaminiamo le modifiche:

1. **Dichiarazione del vettore `y_rep`**:

   - `vector[N] y_rep;`: Dichiara un vettore `y_rep` di lunghezza `N` per contenere le predizioni a posteriori per ciascun valore di `x`.

2. **Ciclo `for` per generare le predizioni**:

   - `for (n in 1:N)`: Itera su tutte le osservazioni.
   - `y_rep[n] = normal_rng(alpha + beta * x[n], sigma);`: Per ogni valore di `x[n]`, genera una predizione dalla distribuzione normale con media `alpha + beta * x[n]` e deviazione standard `sigma`. La funzione `normal_rng` genera numeri casuali dalla distribuzione normale specificata, rappresentando l'incertezza nelle predizioni.

Questo approccio consente di ottenere la distribuzione a posteriori delle predizioni, fornendo una visione completa dell'incertezza associata. Dalla distribuzione a posteriori di `y_rep`, possiamo calcolare sia la stima puntuale (come la media o la mediana delle predizioni) sia gli intervalli di credibilità (come l'intervallo al 95%) per ogni valore di `x`. Questo offre una misura dell'incertezza delle predizioni, riflettendo la variabilità e l'affidabilità del modello.

Modifichiamo il modello imponendo distribuzioni a priori debolmente informative sui parametri:

- Per $\alpha$ e $\beta$, utilizziamo una distribuzione Normale centrata su 0 con una deviazione standard di 2.
- Per $\sigma$, utilizziamo una distribuzione di Cauchy centrata su 0 con una scala di 2.


```{r}
model3 <- cmdstan_model(here::here("stan", "arousal_model3.stan"))
```

Il modello ha questa forma:

```{r}
model3$print()
```

Eseguiamo il campionamento.

```{r}
#| message: false
#| 
fit3 <- model3$sample(
  data = stan_data,
  seed = 123,
  iter_warmup = 2000,
  iter_sampling = 2000,
  show_message = FALSE
)
```

Esaminiamo la distribuzione a posteriori dei parametri.

```{r}
fit3$summary(variables = c("alpha", "beta", "sigma"))
```

### Manipolare le Stime a Posteriori dei Parametri

Costruiamo un grafico che rappresenta i valori osservati e la linea di regressione stimata tramite un modello bayesiano. Al grafico aggiungeremo diverse linee di regressione, ognuna basata su valori campionati casualmente dalla distribuzione a posteriori dei parametri $\alpha$ e $\beta$.

#### Recuperare le Stime a Posteriori

Con cmdstanr, i risultati del campionamento sono accessibili come oggetti `draws_matrix`, `draws_array`, o `draws_df`. Per estrarre le distribuzioni a posteriori di specifici parametri, possiamo usare il metodo `draws()` o `as_draws_df()`. Ad esempio, per estrarre i campioni di $\alpha$ e $\beta$ dall'oggetto `fit3`, utilizziamo:

```{r}
# Estrazione dei campioni a posteriori
alpha_samples <- as_draws_df(fit3)$alpha
beta_samples <- as_draws_df(fit3)$beta
```

Stampiamo i primi 20 valori di `alpha_samples` per verificare:

```{r}
head(alpha_samples, 20)
```

#### Calcolare le Stime Puntuali

Possiamo calcolare la media a posteriori dei parametri per stimare la retta di regressione media:

```{r}
mean_alpha <- mean(alpha_samples)
mean_beta <- mean(beta_samples)

cat("Mean alpha:", mean_alpha, "\nMean beta:", mean_beta)
```

#### Grafico della Regressione con Incertezza

Sovrapponiamo una retta di regressione media e linee basate sui campioni a posteriori:

```{r}
# Dati osservati
x <- df$state1
y <- df$TA1

# Creazione del data frame per ggplot
plot_data <- data.frame(x = x, y = y)

# Costruzione del grafico
ggplot(plot_data, aes(x = x, y = y)) +
  geom_point(color = "blue", size = 1) +
  # Linee di regressione basate sui campioni
  geom_abline(aes(intercept = mean_alpha, slope = mean_beta),
              color = "red", size = 1, alpha = 0.8) +
  lapply(1:300, function(i) {
    geom_abline(aes(intercept = alpha_samples[i], slope = beta_samples[i]),
                color = "gray", alpha = 0.1)
  }) +
  labs(
    title = "Regressione con Incertezza Posteriori",
    x = "State Anxiety",
    y = "Tense Arousal"
  ) 
```

---

#### Incertezza delle Predizioni con $\texttt{y\_rep}$

Un approccio alternativo consiste nel rappresentare l'incertezza delle predizioni usando $\texttt{y\_rep}$, la distribuzione a posteriori delle osservazioni simulate:

```{r}
# Estrazione dei campioni posteriori di y_rep
y_rep_samples <- as_draws_df(fit3)
y_rep_matrix <- y_rep_samples[, grep("y_rep", colnames(y_rep_samples))]

# Compute posterior mean and intervals
y_rep_mean <- colMeans(y_rep_matrix)
y_rep_lower <- apply(y_rep_matrix, 2, quantile, 0.025)
y_rep_upper <- apply(y_rep_matrix, 2, quantile, 0.975)

# Create plot_data with y_rep summaries
plot_data <- data.frame(
  x = df$state1,
  y = df$TA1,
  y_rep_mean = y_rep_mean,
  y_rep_lower = y_rep_lower,
  y_rep_upper = y_rep_upper
)

ggplot(plot_data, aes(x = x, y = y)) +
  geom_point(color = "blue", size = 1) +
  geom_line(aes(y = y_rep_mean), color = "red", size = 1, alpha = 0.8) +
  geom_ribbon(aes(ymin = y_rep_lower, ymax = y_rep_upper),
              fill = "gray", alpha = 0.3) +
  labs(
    title = "Incertezza delle Predizioni del Modello",
    x = "State Anxiety",
    y = "Tense Arousal"
  ) 
```

---

#### Confronto tra Approcci

1. **Distribuzioni a Posteriori di $\alpha$ e $\beta$**: 
   - Visualizza l'incertezza nei parametri del modello ($\alpha$ e $\beta$).
   - Le linee di regressione rappresentano variazioni nella pendenza e intercetta dovute all'incertezza dei parametri.

2. **Distribuzione a Posteriori di $\texttt{y\_rep}$**:
   - Include sia l'incertezza dei parametri sia la variabilità residua ($\sigma$).
   - Fornisce una descrizione più completa dell'incertezza predittiva.

Entrambi gli approcci sono utili per esplorare diverse sfaccettature dell'incertezza nel modello bayesiano.

Nel primo approccio, calcoliamo l'incertezza delle predizioni utilizzando le distribuzioni a posteriori di `alpha` e `beta`. Questo metodo consiste nel generare predizioni lineari per ciascun campione a posteriori di `alpha` e `beta`, tracciando quindi le linee di regressione risultanti. Questo ci permette di vedere come varia la linea di regressione in base alle incertezze nei parametri `alpha` e `beta`. Questo metodo visualizza come l'incertezza nei parametri del modello si traduce in incertezza nelle predizioni.

Nel secondo approccio, descriviamo l'incertezza delle predizioni utilizzando direttamente la distribuzione a posteriori di `y_rep`. In questo caso, generiamo predizioni per ciascun valore osservato di `x` nel modello Stan, tenendo conto delle distribuzioni a posteriori dei parametri del modello. Questo metodo visualizza direttamente l'incertezza nelle predizioni, tenendo conto delle variazioni nei dati osservati e delle distribuzioni a posteriori dei parametri.

Le due descrizioni dell'incertezza delle predizioni del modello sono diverse perché riflettono aspetti differenti della distribuzione a posteriori:

1. **Distribuzione a posteriori di `alpha` e `beta`**: Questo approccio considera solo l'incertezza nei parametri del modello (`alpha` e `beta`). Le linee di regressione tracciate variano in base a questi parametri, ma non tengono conto dell'incertezza residua (`sigma`).

2. **Distribuzione a posteriori di `y_rep`**: Questo approccio include non solo l'incertezza nei parametri `alpha` e `beta`, ma anche l'incertezza residua (`sigma`). La distribuzione di `y_rep` riflette la variabilità totale nel modello, inclusa la variabilità nei dati osservati. Pertanto, l'incertezza nelle predizioni è maggiore perché tiene conto di tutte le fonti di variabilità.


## Posterior-predictive check

Il Posterior Predictive Check (PPC) è un passaggio cruciale nella modellazione bayesiana, che ci permette di valutare quanto bene il modello si adatta ai dati osservati, tenendo conto delle informazioni aggiornate dai dati stessi. L'idea alla base del PPC è confrontare le predizioni del modello, basate sulla distribuzione a posteriori dei parametri, con i dati reali, per vedere se il modello riesce a catturare correttamente le caratteristiche dei dati osservati.

1. Dopo aver adattato il modello ai dati, otteniamo campioni dai parametri a posteriori ($\alpha$, $\beta$, $\sigma$). Questi campioni riflettono le nostre credenze aggiornate sui parametri, basate sia sulle distribuzioni a priori che sui dati osservati.

2. Utilizzando i campioni della distribuzione a posteriori, simuliamo nuovi dati predetti ($y_{rep}$). Questi dati simulati rappresentano le previsioni del modello, date le nostre stime a posteriori dei parametri.

3. Confrontiamo le osservazioni simulate ($y_{rep}$) con i dati osservati reali ($y$). Il PPC plot ci permette di vedere se il modello, con i parametri aggiornati, è in grado di riprodurre correttamente i dati osservati.

Per creare il PPC plot, usiamo ArviZ. Creiamo un oggetto `InferenceData` che contiene sia le predizioni a posteriori che i dati osservati, organizzati nel formato richiesto da ArviZ.

```{r}
# Estrai i campioni y_rep
y_rep <- fit3$draws("y_rep", format = "matrix")

# Crea il plot di controllo posteriore predittivo
ppc_plot <- ppc_dens_overlay(stan_data$y, y_rep[1:100, ])
print(ppc_plot)
```

Il Posterior Predictive Check è uno strumento potente per verificare la validità del modello dopo l'analisi, assicurando che le predizioni del modello siano realistiche e che riflettano accuratamente le osservazioni effettive.

## Riflessioni Conclusive

In questo capitolo, abbiamo approfondito i temi della predizione bayesiana nel contesto del modello di regressione bivariato, evidenziando l'importanza delle verifiche predittive a priori e a posteriori per la valutazione e la validazione del modello.

Abbiamo visto come il *Prior Predictive Check* sia essenziale per verificare che le distribuzioni a priori siano appropriate per il modello e i dati del campione. Questo passaggio consente di esaminare se le ipotesi iniziali sono coerenti con la conoscenza preesistente e con i risultati attesi. Un'adeguata verifica predittiva a priori aiuta a prevenire l'adozione di distribuzioni a priori che possano portare a previsioni irrealistiche o fuorvianti. Se le predizioni basate sulle distribuzioni a priori risultano incompatibili con ciò che ci si aspetta dai dati, è un segnale che le distribuzioni a priori devono essere riviste.

Successivamente, abbiamo esaminato il *Posterior Predictive Check* come strumento per valutare la capacità del modello di adattarsi ai dati osservati. Dopo aver integrato le informazioni dei dati con le distribuzioni a priori, il posterior predictive check permette di confrontare le predizioni del modello con i dati effettivamente osservati. Se il modello è adeguato, le sue predizioni dovrebbero essere in linea con i dati reali. Tuttavia, se emerge una discrepanza sostanziale tra le predizioni e i dati osservati, questo è un chiaro segnale che il modello potrebbe non essere appropriato per il fenomeno in esame e potrebbe richiedere una revisione. Tale revisione può comportare la modifica delle assunzioni di base, l'inclusione di nuovi predittori, o l'adozione di un modello completamente diverso.

In conclusione, l'approccio bayesiano alla predizione e alla verifica dei modelli offre un framework robusto e flessibile per l'analisi statistica. I prior e posterior predictive checks non sono semplici passaggi tecnici, ma costituiscono una parte integrante del processo di modellizzazione, assicurando che il modello non solo sia ben adattato ai dati, ma anche che le sue assunzioni siano giustificate e realistiche. L'utilizzo di questi strumenti permette di costruire modelli che siano  coerenti con la realtà che intendono rappresentare.

## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

