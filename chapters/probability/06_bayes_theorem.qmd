# Il teorema di Bayes {#sec-prob-bayes-theorem}

::: callout-important
## In questo capitolo imparerai a

- capire in profondità il teorema di Bayes e la sua importanza;
- utilizzare il teorema di Bayes per analizzare e interpretare i test diagnostici, tenendo in considerazione la prevalenza della malattia in questione;
- affrontare e risolvere problemi di probabilità discreta che necessitano dell'applicazione del teorema di Bayes.
:::

::: callout-tip
## Prerequisiti

- Leggere *Everything is Predictable: How Bayesian Statistics Explain Our World* [@chivers2024everything]. Questo libro offre una descrizione chiara e accessibile dell'impatto che il teorema di Bayes ha avuto sulla vita moderna.
- Leggere [Bayesian Models of Cognition](https://oecs.mit.edu/pub/lwxmte1p/release/2) di Thomas L. Griffiths, una voce della [Open Encyclopedia of Cognitive Science](https://oecs.mit.edu).
- Leggere il capitolo *Conditional Probability* [@schervish2014probability].
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()
```
:::

> "It is, without exaggeration, perhaps the most important single equation in history."  
> — **Tom Chivers (2024)**

## Introduzione

Il teorema di Bayes offre una soluzione ottimale ai problemi induttivi, che spaziano dall'identificazione della struttura tridimensionale del mondo basata su dati sensoriali limitati [@ma2023bayesian; @domini20033; @caudek2024fenomeni], all'inferenza dei pensieri altrui a partire dal loro comportamento [@baker2011bayesian]. Questa regola si rivela particolarmente utile in situazioni in cui i dati osservati sono insufficienti per distinguere in modo definitivo tra diverse ipotesi.

Nonostante ciò, tutte le previsioni basate su questo metodo mantengono un certo grado di incertezza. Anche se l'universo fosse completamente deterministico, la nostra conoscenza di esso rimarrebbe imperfetta: non possiamo conoscere la posizione e lo stato di ogni singola particella che lo compone. Le informazioni a nostra disposizione sono inevitabilmente parziali e imprecise, ottenute attraverso i nostri sensi limitati.

La vita reale non è paragonabile a una partita di scacchi, un gioco con informazioni perfette che può essere "risolto" in linea di principio. Assomiglia piuttosto al poker, dove le decisioni vengono prese utilizzando le informazioni limitate a disposizione dei giocatori [@chivers2024everything]. Questo capitolo si concentra sull'equazione che ci permette di fare proprio questo: il teorema di Bayes. Esso descrive come modifichiamo le nostre convinzioni riguardo a un'ipotesi in una situazione in cui i dati disponibili non consentono una decisione certa.

Questo processo è noto come inferenza induttiva, che ci permette di trarre conclusioni generali da dati specifici e limitati. Il teorema di Bayes fornisce quindi un framework matematico per aggiornare le nostre credenze alla luce di nuove evidenze, permettendoci di prendere decisioni informate in un mondo caratterizzato dall'incertezza.

## Una Rivoluzione nel Pensiero Probabilistico

Nel cuore del XVIII secolo, un ecclesiastico presbiteriano di nome Thomas Bayes pose le fondamenta per una delle più importanti rivoluzioni nel campo della statistica e del calcolo delle probabilità. Il suo contributo, noto oggi come **teorema di Bayes**, non solo trasformò radicalmente l’interpretazione della probabilità, ma continua a influenzare profondamente la scienza moderna, la tecnologia e persino l’intelligenza artificiale [@chivers2024everything].

Nato in una famiglia benestante, Thomas Bayes ricevette un’educazione raffinata, studiando teologia a Edimburgo per prepararsi alla vita da ecclesiastico. Come sottolinea il biografo David Bellhouse, Bayes "non incarnava l’archetipo dell’accademico moderno. Era piuttosto un erudito, un libero pensatore: perseguiva il sapere per il proprio piacere personale, non per seguire un rigido programma di ricerca."

Bayes pubblicò due opere principali durante la sua vita:

- **Un trattato teologico**, *Divine Benevolence: Or, an Attempt to Prove that the Principal End of the Divine Providence and Government is the Happiness of His Creatures* (1731), in cui argomentò una teodicea basata sull’ottimizzazione del benessere universale attraverso le leggi naturali [@bellhouse2004].
- ***Un’apologia del calcolo newtoniano**, *An Introduction to the Doctrine of Fluxions* (1736), difesa metodologica contro le critiche di George Berkeley ai fondamenti degli infinitesimi, allora ritenuti logicamente inconsistenti [@jesseph1993berkeley].

Tuttavia, fu il suo lavoro postumo, *An Essay towards Solving a Problem in the Doctrine of Chances* (1763), pubblicato nelle *Philosophical Transactions of the Royal Society*, a cambiare per sempre il corso della teoria della probabilità. Questo lavoro formalizzò per la prima volta un metodo per aggiornare probabilisticamente ipotesi alla luce di dati empirici, ponendo le basi per l’inferenza bayesiana [@stigler1990history].

Come evidenziato dallo storico David Bellhouse, l’interesse di Bayes per la matematica era emblematico del ruolo culturale della scienza tra le élite colte nel XVIII secolo: "Per i ricchi del tempo, impegnarsi in discipline scientifiche era un segno di status, analogo all’odierna passione per attività come gli sport esclusivi" [@bellhouse2004]. 

Il contributo rivoluzionario dell’approccio bayesiano non risiede tanto nella sua formulazione matematica quanto nella sua **portata epistemologica**. Come sottolinea David Spiegelhalter, statistico di fama internazionale e già presidente della *Royal Statistical Society*, per Bayes «la probabilità incarna l’espressione quantificabile della nostra ignoranza sul mondo». Questa definizione sovverte radicalmente la visione classica – legata a frequenze osservative e ripetibilità – trasformando la probabilità da proprietà oggettiva degli eventi a **strumento soggettivo di conoscenza**.  

Nel paradigma bayesiano, assegnare una probabilità diventa un atto intrinsecamente *contestuale*: non riflette dinamiche "esterne", ma sintetizza il grado di fiducia razionale di un osservatore, inevitabilmente filtrato dal suo bagaglio di conoscenze, esperienze e persino pregiudizi. Il teorema di Bayes formalizza questo processo dialettico, strutturando l’inferenza come **revisione critica delle credenze** alla luce di nuovi dati. La probabilità si trasforma così in una misura dinamica, continuamente aggiornabile, che modella statistiche e convinzioni in un unico atto cognitivo [@spiegelhalter2019art].

Per illustrare questo concetto, Bayes utilizzò l'esempio di un esperimento mentale che coinvolge sei palline lanciate casualmente su un tavolo da biliardo. 

> Supponiamo che una pallina bianca venga lanciata a caso sul tavolo, la sua posizione lungo il tavolo sia segnata con una linea, e poi la pallina bianca venga rimossa. Successivamente, un certo numero di palline rosse viene lanciato casualmente sul tavolo, e ti viene comunicato solo quante di esse si trovano a sinistra e quante a destra della linea. Dove pensi che possa trovarsi la linea, e quale dovrebbe essere la probabilità che la prossima pallina rossa cada alla sua sinistra?

La soluzione proposta da Bayes utilizza non solo i dati osservati (il numero di palline rosse a sinistra e a destra della linea), ma anche le convinzioni iniziali (il "prior").

**Richard Price (1723-1791)**, altro ecclesiastico nonconformista, fu determinante per la diffusione dell’opera di Thomas Bayes. Ben più noto dell’amico, Price godeva di una solida reputazione nei circoli intellettuali del tempo. Intratteneva rapporti con numerosi Padri Fondatori della Rivoluzione Americana, tra cui **Benjamin Franklin**, **Thomas Jefferson** e **John Adams** – futuro secondo presidente degli Stati Uniti –, ai cui ideali rivoluzionari aderì con fervore. Nel 1776, pubblicò un opuscolo di grande impatto, *Observations on the Nature of Civil Liberty, the Principles of Government, and the Justice and Policy of the War with America*, divenuto manifesto del sostegno britannico all’indipendenza americana. La sua rete di contatti includeva anche filosofi del calibro di **David Hume** e **Adam Smith**, con cui discuteva di etica ed economia.

Il contributo più rilevante di Price in ambito scientifico fu però la valorizzazione del lavoro di Bayes. Dopo la morte di quest’ultimo, nel 1761 sottopose il saggio inedito al fisico **John Canton** e ne curò la pubblicazione nelle *Philosophical Transactions* della Royal Society, avvenuta due anni più tardi. Il ritardo non fu casuale: Price non si limitò a una semplice revisione di refusi o punteggiatura. Rivisitò profondamente l’opera, aggiungendovi una seconda metà interamente dedicata alle applicazioni pratiche del teorema. Mentre Bayes si era concentrato sulla dimensione teorica – come del resto in tutti i suoi scritti, privi di qualsiasi riferimento a casi concreti –, Price ampliò il testo con esempi probabilistici, trasformandolo in uno strumento utilizzabile in pratica. Non a caso, lo storico della statistica **Stephen Stigler** lo definisce *«il primo bayesiano della storia»*.

Sebbene l'opera di Bayes rimase pressoché ignorata per oltre mezzo secolo - oscurata dal contributo pionieristico di **Pierre-Simon Laplace**, che nel 1774 formulò indipendentemente principi analoghi per poi sistematizzarli nella monumentale *Théorie analytique des probabilités* (1812) - il teorema bayesiano rappresenta oggi il fondamento epistemologico della statistica moderna. Questo strumento matematico, che formalizza il processo di aggiornamento delle credenze probabilistiche alla luce di nuove evidenze, incarna una visione dinamica della conoscenza dove ogni dato modifica iterativamente lo spazio delle ipotesi possibili.

Nell'era digitale, la rivoluzione bayesiana ha permeato ogni ambito scientifico: dalla genomica alle scienze cognitive, dalla fisica delle particelle all'econometria. Il suo impatto risulta particolarmente importante nell'intelligenza artificiale, dove costituisce l'architettura logica di sistemi di apprendimento automatico. Modelli linguistici avanzati come ChatGPT e Claude implementano versioni sofisticate di inferenza bayesiana per ottimizzare previsioni, generare testi coerenti e adattarsi contestualmente agli input dell'utente.

La parabola storica di questo teorema - nato dalle speculazioni teologiche di un pastore presbiteriano settecentesco - illustra il potere trasformativo delle idee matematiche. Come sottolinea Tom Chivers in *Everything Is Predictable: How Bayesian Statistics Explain Our World*, la statistica bayesiana è diventata una "grammatica universale" per decifrare la realtà, permettendoci non solo di interpretare fenomeni complessi ma di prevederne l'evoluzione in condizioni d'incertezza [@chivers2024everything]. 

## La Regola di Bayes

L'inferenza bayesiana si basa su un principio fondamentale della teoria delle probabilità: la **regola di Bayes**. Questa formula consente di aggiornare le credenze alla luce di nuove evidenze, combinando informazioni a priori con dati osservati.

Per comprenderla, consideriamo due variabili casuali, $A$ e $B$. La **regola della catena** ci permette di esprimere la loro probabilità congiunta come il prodotto tra una probabilità condizionata e una probabilità marginale:

$$
P(A, B) = P(A \mid B) P(B).
$$ {#eq-chain-1}

Poiché la probabilità congiunta è simmetrica, possiamo anche scriverla invertendo l’ordine delle variabili:

$$
P(A, B) = P(B \mid A) P(A).
$$ {#eq-chain-2}

Eguagliando le due espressioni e riorganizzando i termini, otteniamo la **regola di Bayes**:

$$
P(B \mid A) = \frac{P(A \mid B) P(B)}{P(A)}.
$$ {#eq-bayes-rule-1}

Questa formula permette di calcolare la probabilità condizionata di $B$ dato $A$ utilizzando la probabilità inversa $P(A \mid B)$, la probabilità a priori $P(B)$ e la probabilità marginale $P(A)$. 

Nel contesto dell'inferenza bayesiana:

- **$P(B)$** rappresenta la nostra conoscenza iniziale (**prior**),
- **$P(A \mid B)$** è la **verosimiglianza**, ovvero la probabilità di osservare i dati supponendo che l'ipotesi sia vera,
- **$P(B \mid A)$** è la probabilità aggiornata (**posterior**), che incorpora l'evidenza fornita dai dati.

## Applicazioni della Regola di Bayes

La **regola di Bayes** è fondamentale per l'inferenza probabilistica, permettendo di aggiornare le credenze alla luce di nuove informazioni. Supponiamo di voler determinare quale processo ha generato un insieme di dati osservati, denotato con $D$. Indichiamo con $H$ un'ipotesi su tale processo e con $H'$ un insieme di ipotesi alternative.

L'agente esprime il proprio grado di credenza in $H$ attraverso la **probabilità a priori** $P(H)$, che riflette il livello di fiducia nell'ipotesi prima di osservare i dati. Dopo aver raccolto nuovi dati $D$, questa credenza viene aggiornata calcolando la **probabilità a posteriori** $P(H \mid D)$, ovvero la probabilità dell'ipotesi dopo aver considerato l’evidenza.

La regola di Bayes fornisce il modo formale per eseguire questo aggiornamento:

$$
P(H \mid D) = \frac{P(D \mid H) P(H)}{P(D)}.
$$ {#eq-bayes-rule-2}

Dove:

- **$P(D \mid H)$** è la **verosimiglianza**, ovvero la probabilità di osservare i dati $D$ supponendo che l'ipotesi $H$ sia vera. Indica quanto l'ipotesi spiega i dati osservati.
- **$P(H)$** è la **probabilità a priori**, ovvero la conoscenza preesistente su $H$ prima dell'osservazione dei dati.
- **$P(D)$** è la **probabilità marginale** dei dati, ottenuta sommando (o integrando) le probabilità congiunte su tutte le ipotesi possibili:

  $$
  P(D) = \sum_{H'} P(D \mid H') P(H').
  $$

Questa quantità, detta **evidenza** o **fattore di normalizzazione**, garantisce che la somma delle probabilità a posteriori su tutte le ipotesi sia pari a 1.

### La Marginalizzazione

Il calcolo della probabilità marginale $P(D)$ è fondamentale per normalizzare la distribuzione a posteriori. Questo avviene considerando tutte le ipotesi possibili. 

Nel caso discreto, la probabilità marginale si ottiene sommando su tutte le possibili ipotesi:

$$
P(D) = \sum_{H' \in H} P(D \mid H') P(H').
$$

Sostituendo questa espressione nella regola di Bayes, otteniamo la formula esplicita della distribuzione a posteriori:

$$
P(H \mid D) = \frac{P(D \mid H) P(H)}{\sum_{H' \in H} P(D \mid H') P(H')}.
$$ {#eq-marginal-prob}

Nel caso continuo, la somma viene sostituita da un **integrale**:

$$
P(H \mid D) = \frac{P(D \mid H) P(H)}{\int P(D \mid H') P(H') \, dH'}.
$$ {#eq-bayes-rule-cont}

L'evidenza $P(D)$ può essere computazionalmente onerosa da calcolare, specialmente in spazi ad alta dimensionalità. Per questo motivo, si utilizzano tecniche di approssimazione come il **campionamento Monte Carlo** o i **metodi variazionali**.

### Componenti Chiave della Formula di Bayes

La regola di Bayes si basa su tre elementi essenziali:

1. **Probabilità a priori $P(H)$**: la credenza iniziale sull'ipotesi $H$ prima di osservare i dati.
2. **Verosimiglianza $P(D \mid H)$**: la probabilità dei dati osservati, dato che $H$ sia vera. Misura quanto l'ipotesi è compatibile con l'evidenza.
3. **Probabilità a posteriori $P(H \mid D)$**: la credenza aggiornata in $H$ dopo aver osservato i dati.

L'aggiornamento delle credenze attraverso la **regola di Bayes** è un processo iterativo: ogni volta che vengono raccolti nuovi dati, la distribuzione a posteriori diventa la nuova distribuzione a priori per il successivo aggiornamento. Questo meccanismo consente di adattare continuamente le proprie credenze alla luce di nuove informazioni, rendendo l'approccio bayesiano estremamente utile per modellare il ragionamento umano in condizioni di incertezza.

### Applicazioni in Psicologia

Negli ultimi anni, i **modelli bayesiani** hanno acquisito un ruolo centrale nello studio della cognizione umana e animale, fornendo una struttura formale per comprendere come il cervello costruisca rappresentazioni del mondo e prenda decisioni sulla base di dati incerti. Come discusso da @griffiths2024bayesian, questi modelli sono stati applicati a una vasta gamma di processi cognitivi, tra cui:

- **Apprendimento e generalizzazione**: i modelli bayesiani descrivono come gli individui apprendano nuove categorie e concetti sulla base di dati limitati e rumorosi (Tenenbaum, Griffiths, & Kemp, 2006).
- **Percezione e interpretazione sensoriale**: la percezione visiva e il riconoscimento di oggetti possono essere spiegati come un'inferenza bayesiana sulla base di segnali sensoriali ambigui (Yuille & Kersten, 2006).
- **Controllo motorio**: il sistema motorio umano sembra ottimizzare i movimenti attraverso una combinazione di modelli interni e aggiornamenti bayesiani (Kording & Wolpert, 2006).
- **Memoria e recupero delle informazioni**: i processi mnemonici, come il richiamo della memoria semantica, possono essere modellati come inferenze bayesiane basate su conoscenze pregresse (Steyvers, Griffiths, & Dennis, 2006).
- **Acquisizione del linguaggio**: l'apprendimento del linguaggio nei bambini può essere descritto attraverso processi probabilistici che permettono di inferire le strutture grammaticali sulla base di dati linguistici limitati (Chater & Manning, 2006; Xu & Tenenbaum, in press).
- **Apprendimento causale**: la capacità di inferire relazioni causali dagli eventi osservati è coerente con un modello bayesiano, in cui la mente valuta la probabilità di una relazione causale sulla base dell'evidenza disponibile (Griffiths & Tenenbaum, 2005, 2007).
- **Ragionamento e decisione**: il ragionamento simbolico e il processo decisionale possono essere formalizzati come un aggiornamento bayesiano delle credenze sulla base di nuove informazioni (Oaksford & Chater, 2001).
- **Cognizione sociale**: le inferenze sulle intenzioni e credenze altrui possono essere modellate attraverso processi bayesiani, permettendo di spiegare come le persone comprendano il comportamento altrui (Baker, Tenenbaum, & Saxe, 2007).

### L’Inferenza Bayesiana nella Cognizione Umana

Un tema centrale che emerge da questi programmi di ricerca è la seguente domanda: **come fa la mente umana ad andare oltre i dati dell'esperienza?** In altre parole, come riesce il cervello a costruire modelli complessi del mondo a partire da informazioni limitate e spesso ambigue?

L’approccio bayesiano propone che il cervello utilizzi un processo di **inferenza probabilistica** per aggiornare continuamente le proprie credenze, combinando informazioni pregresse con nuove osservazioni per affinare le proprie rappresentazioni mentali. Questo meccanismo consente di spiegare molte delle capacità cognitive umane, dall’apprendimento rapido di nuove categorie alla capacità di adattarsi a un ambiente mutevole, fino alla formulazione di inferenze sociali e alla presa di decisioni in condizioni di incertezza.

L’adozione dei modelli bayesiani nella psicologia cognitiva ha portato a una nuova comprensione della mente come **sistema predittivo**, in grado di formulare ipotesi probabilistiche sugli eventi futuri e di correggerle dinamicamente sulla base dell’esperienza. Questo approccio ha profonde implicazioni per lo studio del comportamento umano e per lo sviluppo di nuove tecniche di modellizzazione nei campi della psicologia, delle neuroscienze e dell’intelligenza artificiale.


## Test medici

Il modo più comune per introdurre il teorema di Bayes è attraverso i test medici.

::: {#exm-}
Prendiamo come esempio il caso della mammografia e la diagnosi del cancro al seno che abbiamo già discusso nel @sec-prob-conditional-prob. Supponiamo di avere un test di mammografia con una sensibilità del 90% e una specificità del 90%. Questo significa che:

- In presenza di cancro al seno, la probabilità che il test lo rilevi correttamente è del 90%.
- In assenza di cancro al seno, la probabilità che il test confermi correttamente l'assenza della malattia è del 90%.

In altri termini, il test ha un tasso di falsi negativi del 10% e un tasso di falsi positivi anch'esso del 10%.

Definiamo due ipotesi:

- $M^+$: presenza della malattia;
- $M^-$: assenza della malattia.

L'evidenza è rappresentata dal risultato positivo di un test di mammografia, che indichiamo con $T^+$.

Come in precedenza, assumiamo che la prevalenza del cancro al seno nella popolazione sia dell'1% (0.01). Applicando il teorema di Bayes, possiamo calcolare la probabilità di avere il cancro al seno dato un risultato positivo al test, come segue:

$$
P(M^+ \mid T^+) = \frac{P(T^+ \mid M^+) \cdot P(M^+)}{P(T^+ \mid M^+) \cdot P(M^+) + P(T^+ \mid M^-) \cdot P(M^-)},
$$

dove:

- $P(M^+ \mid T^+)$ è la probabilità di avere il cancro ($M^+$) dato un risultato positivo al test ($T^+$).
- $P(T^+ \mid M^+)$ rappresenta la sensibilità del test, ovvero la probabilità che il test risulti positivo in presenza effettiva del cancro. In questo caso, è pari a 0.90.
- $P(M^+)$ è la probabilità a priori che una persona abbia il cancro, ovvero la prevalenza della malattia nella popolazione.
- $P(T^+ \mid M^-)$ indica la probabilità di un falso positivo, cioè la probabilità che il test risulti positivo in assenza di cancro. Con una specificità del 90%, questa probabilità si calcola come:

  $$
  P(T^+ \mid M^-) = 1 - \text{Specificità} = 1 - 0.90 = 0.10
  $$

  Questo significa che c'è una probabilità del 10% che il test diagnostichi erroneamente la presenza del cancro in una persona sana.

- $P(M^-)$ è la probabilità a priori che una persona non sia affetta da cancro prima di effettuare il test.

Questa formulazione del teorema di Bayes ci permette di calcolare la probabilità effettiva di avere il cancro al seno, dato un risultato positivo al test di mammografia, tenendo conto sia della sensibilità e specificità del test, sia della prevalenza della malattia nella popolazione.

Inserendo nella formula i del problema, otteniamo:

$$
\begin{align}
P(M^+ \mid T^+) &= \frac{0.9 \cdot 0.01}{0.9 \cdot 0.01 + 0.1 \cdot 0.99} \notag\\
&= \frac{9}{108} \notag\\
&\approx 0.083.\notag
\end{align}
$$

I calcoli effettuati evidenziano come, in presenza di una mammografia positiva ottenuta con un test avente sensibilità e specificità pari al 90%, la probabilità di effettiva positività al tumore al seno si attesta intorno all'8.3%. Tale risultato conferma quanto precedentemente ottenuto nel @sec-prob-conditional-prob, attraverso un metodo di calcolo alternativo.
:::

### Il Valore Predittivo di un Test di Laboratorio

Per semplicità, possiamo riscrivere il teorema di Bayes in due modi distinti per calcolare ciò che viene chiamato valore predittivo del test positivo e valore predittivo del test negativo.

La comprensione di tre elementi è fondamentale per questo calcolo: la prevalenza della malattia, la sensibilità e la specificità del test.

- **Prevalenza:** Si riferisce alla percentuale di individui in una popolazione affetti da una certa malattia in un determinato momento. Viene espressa come percentuale o frazione della popolazione. Per esempio, una prevalenza dello 0,5% indica che su mille persone, cinque sono affette dalla malattia.

- **Sensibilità:** Indica la capacità del test di identificare correttamente la malattia negli individui malati. Viene calcolata come la frazione di veri positivi (individui malati correttamente identificati) sul totale degli individui malati. La formula della sensibilità ($Sens$) è la seguente:

    $$ \text{Sensibilità} = \frac{TP}{TP + FN}, $$

    dove $TP$ rappresenta i veri positivi e $FN$ i falsi negativi. Pertanto, la sensibilità misura la probabilità che il test risulti positivo se la malattia è effettivamente presente.

- **Specificità:** Misura la capacità del test di riconoscere gli individui sani, producendo un risultato negativo per chi non è affetto dalla malattia. Si calcola come la frazione di veri negativi (individui sani correttamente identificati) sul totale degli individui sani. La specificità ($Spec$) si definisce come:

    $$ \text{Specificità} = \frac{TN}{TN + FP}, $$

    dove $TN$ sono i veri negativi e $FP$ i falsi positivi. Così, la specificità rappresenta la probabilità che il test risulti negativo in assenza della malattia.

Questa tabella riassume la terminologia:

|       | $T^+$                                              | $T^-$                                              | Totale              |
| :---: | :------------------------------------------------: | :------------------------------------------------: | :------------------:|
| $M^+$ | $P(T^+ \cap M^+)$ <br> (Sensibilità)               | $P(T^- \cap M^+)$ <br> (1 - Sensibilità)           | $P(M^+)$            |
| $M^-$ | $P(T^+ \cap M^-)$ <br> (1 - Specificità)           | $P(T^- \cap M^-)$ <br> (Specificità)               | $P(M^-)$            |
| Totale| $P(T^+)$                                           | $P(T^-)$                                           | 1                   |

dove $T^+$ e $T^-$ indicano rispettivamente un risultato positivo o negativo del test, mentre $M^+$ e $M^-$ la presenza o assenza effettiva della malattia. In questa tabella, i totali marginali rappresentano:

- **Totale per $M^+$ e $M^-$** (ultima colonna): La probabilità totale di avere la malattia ($P(M^+)$) e la probabilità totale di non avere la malattia ($P(M^-)$), rispettivamente. Questi valori sono calcolati sommando le probabilità all'interno di ciascuna riga.
- **Totale per $T^+$ e $T^-$** (ultima riga): La probabilità totale di un risultato positivo al test ($P(T^+)$) e la probabilità totale di un risultato negativo al test ($P(T^-)$), rispettivamente. Questi valori sono calcolati sommando le probabilità all'interno di ciascuna colonna.
- **Totale generale** (angolo in basso a destra): La somma di tutte le probabilità, che per definizione è 1, rappresentando l'intera popolazione o il set di casi considerati.

Mediante il teorema di Bayes, possiamo usare queste informazioni per stimare la probabilità post-test di avere o non avere la malattia basandoci sul risultato del test.

Il **valore predittivo positivo** (VPP) del test, cioè la probabilità post-test che un individuo sia malato dato un risultato positivo del test, è calcolato come:

$$
P(M^+ \mid T^+) = \frac{P(T^+ \mid M^+) \cdot P(M^+)}{P(T^+ \mid M^+) \cdot P(M^+) + P(T^+ \mid M^-) \cdot P(M^-)}.
$$

ovvero,

$$ VPP = \frac{(\text{Sensibilità} \times \text{Prevalenza})}{(\text{Sensibilità} \times \text{Prevalenza}) + (1 - \text{Specificità}) \times (1 - \text{Prevalenza})} $$

Analogamente, il **valore predittivo negativo** (VPN), che è la probabilità che un individuo non sia malato dato un risultato negativo del test, si calcola come:

$$
P(M^- \mid T^-) = \frac{P(T^- \mid M^-) \cdot (1 - P(M^+))}{P(T^- \mid M^-) \cdot (1 - P(M^+)) + P(T^- \mid M^+) \cdot P(M^+)}.
$$

ovvero,

$$ NPV = \frac{\text{Specificità} \cdot (1 - \text{Prevalenza})}{\text{Specificità} \cdot (1 - \text{Prevalenza}) + (1 - \text{Sensibilità}) \cdot \text{Prevalenza}}. $$

::: {#exm-}

Implementiamo le formule del valore predittivo positivo e del valore predittivo negativo del test in R e usiamo gli stessi dati dell'esercizio precedente.

```{r}
positive_predictive_value_of_diagnostic_test <- function(sens, spec, prev) {
  (sens * prev) / (sens * prev + (1 - spec) * (1 - prev))
}

negative_predictive_value_of_diagnostic_test <- function(sens, spec, prev) {
  (spec * (1 - prev)) / (spec * (1 - prev) + (1 - sens) * prev)
}
```

Inseriamo i dati del problema.

```{r}
sens = 0.9  # sensibilità
spec = 0.9  # specificità
prev = 0.01  # prevalenza
```

Il valore predittivo del test positivo è:

```{r}
res_pos <- positive_predictive_value_of_diagnostic_test(sens, spec, prev)
cat(sprintf("P(M+ | T+) = %.3f\n", res_pos))
```

Il valore predittivo del test negativo è:

```{r}
res_neg <- negative_predictive_value_of_diagnostic_test(sens, spec, prev)
cat(sprintf("P(M- | T-) = %.3f\n", res_neg))
```
:::

::: {#exm-3a}

La simulazione seguente ha lo scopo di aiutare a visualizzare il teorema di Bayes, utilizzando come esempio gli stessi dati della mammografia che abbiamo analizzato in precedenza.

```{r}
# Parametri
sensitivity <- 0.90  # Sensibilità del test (P(T+ | M+))
specificity <- 0.90  # Specificità del test (P(T- | M-))
prev_cancer <- 0.01  # Prevalenza (P(M+))

# Simulazione per una popolazione di 100.000 persone
N_mammography <- 100000

# Generazione del campione casuale
set.seed(123)
outcome_mammography <- sample(
  c("Cancer", "Healthy"), 
  N_mammography, 
  replace = TRUE, 
  prob = c(prev_cancer, 1 - prev_cancer)
)

# Conteggio delle persone con e senza cancro
N_C <- sum(outcome_mammography == "Cancer")
N_H <- sum(outcome_mammography == "Healthy")

# Simulazione dei risultati del test
test_mammography <- character(N_mammography)
test_mammography[outcome_mammography == "Cancer"] <- sample(
  c("+", "-"), 
  N_C, 
  replace = TRUE, 
  prob = c(sensitivity, 1 - sensitivity)
)
test_mammography[outcome_mammography == "Healthy"] <- sample(
  c("-", "+"), 
  N_H, 
  replace = TRUE, 
  prob = c(specificity, 1 - specificity)
)

# Creazione di un data frame per memorizzare i risultati
df_mammography <- tibble(
  outcome = outcome_mammography,
  test = test_mammography
)

# Creazione di una tabella di contingenza
contingency_table_mammography <- df_mammography %>%
  count(outcome, test) %>%
  pivot_wider(names_from = test, values_from = n, values_fill = 0)

contingency_table_mammography
```

```{r}
# Calcolo delle probabilità basate sulla tabella di contingenza

# Veri positivi (cancro e risultato positivo al test)
true_positives <- contingency_table_mammography %>%
  filter(outcome == "Cancer") %>%
  pull(`+`)

# Falsi positivi (sani e risultato positivo al test)
false_positives <- contingency_table_mammography %>%
  filter(outcome == "Healthy") %>%
  pull(`+`)

# Frequenza totale dei risultati positivi
total_positives <- true_positives + false_positives

# Applicazione del teorema di Bayes sui dati simulati
P_M_given_T <- true_positives / total_positives
P_M_given_T
```

Utilizzando i dati della simulazione, la probabilità che una persona abbia il cancro al seno dato un risultato positivo al test è molto vicina al valore teorico calcolato in precedenza (circa 8.3%). Se eseguissimo la simulazione nuovamente, il valore ottenuto potrebbe variare leggermente a causa della casualità intrinseca nel campionamento. Tuttavia, ripetendo la simulazione molte volte, i risultati tenderanno a convergere verso il valore teorico, grazie alla legge dei grandi numeri. Questo conferma che il modello teorico è coerente con i risultati simulati.

:::

:::{#exm-hiv}

Poniamoci il problema di capire quanto sia affidabile un test per l'HIV. Per fare questo, utilizzeremo le seguenti informazioni [@petersen2024principles]:

- **Tasso di base dell'HIV (P(HIV))**: 0.3% (0.003). Questa è la probabilità che una persona nella popolazione generale abbia l'HIV.
- **Sensibilità del test (P(Test+ \mid HIV))**: 95% (0.95). Questa è la probabilità che il test risulti positivo se la persona ha effettivamente l'HIV.
- **Specificità del test (P(Test- \mid ¬HIV))**: 99.28% (0.9928). Questa è la probabilità che il test risulti negativo se la persona non ha l'HIV.

**Calcolo della probabilità di HIV dato un test positivo.**

Per calcolare la probabilità di avere l'HIV dato un test positivo (P(HIV \mid Test+)), utilizziamo il teorema di Bayes:

$$
P(HIV \mid Test+) = \frac{P(Test+ \mid HIV) \times P(HIV)}{P(Test+)}.
$$

Abbiamo bisogno di calcolare il denominatore, ovvero la probabilità complessiva di ottenere un test positivo (P(Test+)). Questo valore include sia i veri positivi che i falsi positivi:

$$
P(Test+) = P(Test+ \mid HIV) \times P(HIV) + P(Test+ \mid \neg HIV) \times P(\neg HIV),
$$

dove:

- $P(Test+ \mid \neg HIV) = 1 - P(Test- \mid \neg HIV) = 1 - 0.9928 = 0.0072$ (tasso di falsi positivi),
- $P(\neg HIV) = 1 - P(HIV) = 1 - 0.003 = 0.997$.

Calcoliamo $P(Test+)$:

$$
P(Test+) = (0.95 \times 0.003) + (0.0072 \times 0.997) \approx 0.010027.
$$

Ora possiamo calcolare $P(HIV \mid Test+)$:

$$
P(HIV \mid Test+) = \frac{0.95 \times 0.003}{0.010027} \approx 0.2844 \text{ o 28.44\%}.
$$

Quindi, se il test risulta positivo, la probabilità di avere l'HIV è circa il 28.44%.

**Calcolo della probabilità di un secondo test positivo.**

Dopo un primo test positivo, la probabilità di avere l'HIV è aumentata al 28.44%. Ora calcoleremo la probabilità che un secondo test risulti positivo e la conseguente probabilità di avere l'HIV dopo due test positivi consecutivi.

Per calcolare $P(\text{Secondo Test+})$, consideriamo due scenari:

1. La persona ha effettivamente l'HIV:
   - Probabilità: $P(HIV \mid Test+) = 0.2844$.
   - Probabilità di un test positivo: $P(\text{Test+} \mid HIV) = 0.95$ (sensibilità del test).

2. La persona non ha l'HIV:
   - Probabilità: $P(\neg HIV \mid Test+) = 1 - P(HIV \mid Test+) = 0.7156$.
   - Probabilità di un test positivo: $P(\text{Test+} \mid \neg HIV) = 0.0072$ (tasso di falsi positivi).

Utilizziamo la formula della probabilità totale:

$$
\begin{aligned}
P(\text{Secondo Test+}) &= P(\text{Test+} \mid HIV) \times P(HIV \mid Test+) + \\
&\quad P(\text{Test+} \mid \neg HIV) \times P(\neg HIV \mid Test+).
\end{aligned}
$$

Sostituendo i valori:

$$
P(\text{Secondo Test+}) = (0.95 \times 0.2844) + (0.0072 \times 0.7156) \approx 0.2753.
$$

Applichiamo nuovamente il teorema di Bayes per calcolare la probabilità di avere l'HIV dopo un secondo test positivo:

$$
P(HIV \mid \text{Secondo Test+}) = \frac{P(\text{Secondo Test+} \mid HIV) \times P(HIV \mid Test+)}{P(\text{Secondo Test+})}.
$$

Sostituendo i valori:

$$
P(HIV \mid \text{Secondo Test+}) = \frac{0.95 \times 0.2844}{0.2753} \approx 0.981.
$$

Dopo un secondo test positivo, la probabilità di avere l'HIV aumenta significativamente, passando dal 28.44% al 98.1%. Questo aumento drastico dimostra l'importanza di:

1. Considerare il tasso di base (prevalenza) nella popolazione.
2. Aggiornare progressivamente le probabilità con nuove evidenze.
3. Interpretare i risultati di test diagnostici multipli in modo bayesiano.

L'analisi evidenzia come l'accumulo di evidenze attraverso test ripetuti, in linea con i principi del teorema di Bayes, possa portare a una stima molto più accurata della probabilità di avere una condizione medica, riducendo significativamente l'incertezza iniziale.

:::

::: {#exm-}

Consideriamo ora un altro esempio relativo ai test medici e analizziamo i risultati del test antigenico rapido per il virus SARS-CoV-2 alla luce del teorema di Bayes. Questo test può essere eseguito mediante tampone nasale, tampone naso-orofaringeo o campione di saliva. L'Istituto Superiore di Sanità, nel documento pubblicato il 5 novembre 2020, sottolinea che, fino a quel momento, i dati disponibili sui vari test erano quelli forniti dai produttori: la sensibilità varia tra il 70% e l'86%, mentre la specificità si attesta tra il 95% e il 97%.

Prendiamo un esempio specifico: nella settimana tra il 17 e il 23 marzo 2023, in Italia, il numero di individui positivi al virus è stato stimato essere di 138.599 (fonte: Il Sole 24 Ore). Questo dato corrisponde a una prevalenza di circa lo 0,2% su una popolazione totale di circa 59 milioni di persone.

```{r}
 prev = 138599 / 59000000
 prev
```

L'obiettivo è determinare la probabilità di essere effettivamente affetti da Covid-19, dato un risultato positivo al test antigenico rapido, ossia $P(M^+ \mid T^+)$. Per raggiungere questo scopo, useremo la formula relativa al valore predittivo positivo del test.

```{r}
# Calcolo della sensibilità e specificità medie
sens <- (0.7 + 0.86) / 2  # sensibilità
spec <- (0.95 + 0.97) / 2 # specificità

# Calcolo del valore predittivo positivo
res_pos <- positive_predictive_value_of_diagnostic_test(sens, spec, prev)
cat(sprintf("P(M+ | T+) = %.3f\n", res_pos))
```

Pertanto, se il risultato del tampone è positivo, la probabilità di essere effettivamente affetti da Covid-19 è solo del 4.4%.

Se la prevalenza fosse 100 volte superiore (cioè, pari al 23.5%), la probabilità di avere il Covid-19, dato un risultato positivo del tampone, aumenterebbe notevolmente e sarebbe pari a circa l'86%.

```{r}
# Calcolo della prevalenza aumentata di 100 volte
prev <- 138599 / 59000000 * 100

# Calcolo del valore predittivo positivo
res_pos <- positive_predictive_value_of_diagnostic_test(sens, spec, prev)
cat(sprintf("P(M+ | T+) = %.3f\n", res_pos))
```

Se il risultato del test fosse negativo, considerando la prevalenza stimata del Covid-19 nella settimana dal 17 al 23 marzo 2023, la probabilità di non essere infetto sarebbe del 99.9%.

```{r}
# Calcolo della sensibilità, specificità e prevalenza
sens <- (0.7 + 0.86) / 2  # sensibilità
spec <- (0.95 + 0.97) / 2  # specificità
prev <- 138599 / 59000000  # prevalenza

# Calcolo del valore predittivo negativo
res_neg <- negative_predictive_value_of_diagnostic_test(sens, spec, prev)
cat(sprintf("P(M- | T-) = %.3f\n", res_neg))
```

Tuttavia, un'esito del genere non dovrebbe sorprenderci, considerando che la prevalenza della malattia è molto bassa; in altre parole, il risultato negativo conferma una situazione già presunta prima di sottoporsi al test. Il vero ostacolo, specialmente nel caso di malattie rare come il Covid-19 in quel periodo specifico, non risiede tanto nell'asserire l'assenza della malattia quanto piuttosto nel confermarne la presenza.

:::

::: {#exm-}

Consideriamo le persone in attesa di un figlio. Il teorema di Bayes gioca un ruolo cruciale nell'interpretazione dei test prenatali non invasivi (NIPT), un esame del sangue materno usato per rilevare anomalie cromosomiche fetali. Sebbene il NIPT sia spesso pubblicizzato con un'accuratezza del 99%, la sua affidabilità varia significativamente a seconda della condizione testata e della popolazione esaminata.

Parametri chiave del NIPT:

1. Sensibilità:

   - Sindrome di Down: 99%
   - Sindrome di Edwards: 97%
   - Sindrome di Patau: 91%

2. Specificità: circa 99.9% per tutte le condizioni citate

3. Prevalenza nelle nascite:

   - Sindrome di Down: 1 su 700 (0.14%)
   - Sindrome di Edwards: 1 su 5,000 (0.02%)
   - Sindrome di Patau: 1 su 10,000 (0.01%)

Nonostante l'alta sensibilità e specificità, il VPP può essere sorprendentemente basso, soprattutto nella popolazione generale. Questo implica che molti risultati positivi potrebbero essere falsi positivi, in particolare per le condizioni più rare.

Per calcolare il VPP, utilizziamo il teorema di Bayes:

$$ VPP = \frac{(\text{Sensibilità} \times \text{Prevalenza})}{(\text{Sensibilità} \times \text{Prevalenza}) + (1 - \text{Specificità}) \times (1 - \text{Prevalenza})} $$

Applicando questa formula alla popolazione generale:

- Sindrome di Down:
  $$ VPP = \frac{(0.99 \times 0.0014)}{(0.99 \times 0.0014) + (1 - 0.999) \times (1 - 0.0014)} \approx 58\% $$

- Sindrome di Edwards:
  $$ VPP = \frac{(0.97 \times 0.0002)}{(0.97 \times 0.0002) + (1 - 0.999) \times (1 - 0.0002)} \approx 16.2\% $$

- Sindrome di Patau:
  $$ VPP = \frac{(0.91 \times 0.0001)}{(0.91 \times 0.0001) + (1 - 0.999) \times (1 - 0.0001)} \approx 8.3\% $$

Questi calcoli rivelano VPP molto bassi, specialmente per condizioni molto rare come la sindrome di Patau. Anche in questo caso, dunque, il teorema di Bayes ci mostra che la probabilità che un risultato positivo sia effettivamente corretto dipende non solo dall'accuratezza del test, ma anche dalla prevalenza della condizione nella popolazione testata. Per questo motivo, il NIPT risulta più affidabile nelle categorie ad alto rischio.

In conclusione, mentre il NIPT è uno strumento prezioso per lo screening prenatale, è fondamentale interpretare i risultati con cautela, considerando il contesto specifico di ogni paziente e la prevalenza della condizione nella popolazione di riferimento.

:::

## La Fallacia del Procuratore

Il teorema di Bayes non è rilevante solo in ambito medico; è altrettanto cruciale nel contesto legale, dove un errore logico noto come **fallacia del procuratore** può avere conseguenze significative. Questa fallacia si verifica quando si confonde la probabilità di un risultato dato un evento con la probabilità dell'evento dato il risultato. In ambito giudiziario, ciò accade spesso quando si scambia la probabilità di ottenere una corrispondenza del DNA se una persona è innocente con la probabilità che una persona sia innocente dato che il test del DNA ha prodotto una corrispondenza.

::: {#exm-}

Supponiamo che un test del DNA venga utilizzato per identificare un sospetto in una popolazione di 65 milioni di persone. Consideriamo i seguenti parametri:

- **Sensibilità**: $P(T^+ \mid C) = 99\%$, ovvero la probabilità che il test identifichi correttamente il colpevole.
- **Specificità**: $P(T^- \mid I) = 99.99997\%$, ovvero la probabilità che il test identifichi correttamente un innocente.
- **Prevalenza**: $P(C) = \frac{1}{65.000.000}$, ovvero la probabilità a priori che una persona qualsiasi sia il colpevole.

Un campione di DNA è stato trovato sulla scena del crimine e confrontato con quello di una persona nel database. Determiniamo la probabilità che questa persona sia effettivamente il colpevole, dato che il test è positivo ($T^+$).

Passo 1: Calcolo della Probabilità del Test Positivo $P(T^+)$.

La probabilità di ottenere un test positivo ($T^+$) è data dalla somma delle probabilità di un risultato positivo per un colpevole e per un innocente:

$$
P(T^+) = P(T^+ \mid C) \cdot P(C) + P(T^+ \mid I) \cdot P(I),
$$

dove $P(I) = 1 - P(C)$ è la probabilità che una persona sia innocente e $P(T^+ \mid I) = 1 - \text{Specificità}$.

Sostituiamo i valori noti:

$$
P(T^+) = 0.99 \cdot \frac{1}{65.000.000} + (1 - 0.9999997) \cdot \frac{64.999.999}{65.000.000}.
$$

Eseguiamo i calcoli:

$$
P(T^+) \approx 0.99 \cdot 1.5385 \times 10^{-8} + 0.0000003 \cdot 0.9999999,
$$

$$
P(T^+) \approx 1.5231 \times 10^{-8} + 2.9999997 \times 10^{-7},
$$

$$
P(T^+) \approx 3.1523 \times 10^{-7}.
$$


Passo 2: Probabilità Condizionale che il Sospetto sia Colpevole Dato un Test Positivo. 

Utilizzando il teorema di Bayes, la probabilità a posteriori che il sospetto sia colpevole, dato un test positivo, è:

$$
P(C \mid T^+) = \frac{P(T^+ \mid C) \cdot P(C)}{P(T^+)}.
$$

Sostituiamo i valori calcolati:

$$
P(C \mid T^+) = \frac{0.99 \cdot \frac{1}{65.000.000}}{3.1523 \times 10^{-7}},
$$

$$
P(C \mid T^+) = \frac{0.99 \cdot 1.5385 \times 10^{-8}}{3.1523 \times 10^{-7}},
$$

$$
P(C \mid T^+) \approx 0.0483.
$$

La probabilità che il sospetto sia effettivamente il colpevole, dato che il test del DNA è positivo, è quindi circa **4.83%**, nonostante la specificità estremamente elevata del test.

Questo risultato dimostra quanto sia importante considerare la bassa prevalenza del colpevole nella popolazione. Affermare, ad esempio, che "c'è solo una probabilità su 3 milioni che il sospetto sia innocente" confonde la specificità del test ($P(T^- \mid I)$) con la probabilità condizionale di colpevolezza ($P(C \mid T^+)$).

In realtà, la probabilità che il sospetto sia colpevole dato un test positivo è molto più bassa, a causa della prevalenza estremamente ridotta. Questo errore logico può portare a gravi ingiustizie, poiché non si considera che i falsi positivi diventano statisticamente più rilevanti quando il numero di innocenti testati è molto alto.

Per chiarire, confondere $P(T^+ \mid I)$ con $P(I \mid T^+)$ è analogo a confondere "Quanto è probabile che il DNA di una persona corrisponda al campione, se è innocente?" con "Quanto è probabile che una persona sia innocente, dato che il suo DNA corrisponde al campione?".

In conclusione, la fallacia del procuratore mette in evidenza l'importanza di interpretare correttamente i risultati dei test probabilistici in contesti legali. L'uso del teorema di Bayes è essenziale per evitare errori logici e per garantire che le decisioni siano basate su una comprensione accurata delle probabilità condizionali.
:::

## Probabilità Inversa

Gli esempi precedenti evidenziano la differenza tra due domande fondamentali. La prima è: "Qual è la probabilità di osservare un determinato risultato, supponendo che una certa ipotesi sia vera?" La seconda, invece, è: "Qual è la probabilità che un'ipotesi sia vera, dato il risultato osservato?"

Un esempio che risponde alla prima domanda potrebbe essere questo: supponiamo che la probabilità di ottenere testa nel lancio di una moneta sia 0.5 (ipotesi). Qual è la probabilità di ottenere 0 teste in cinque lanci?

Per la seconda domanda, un esempio potrebbe essere: supponiamo di aver ottenuto 0 teste in 5 lanci di una moneta (evidenza). Qual è la probabilità che la moneta sia effettivamente bilanciata, alla luce di questa osservazione?

Per molto tempo, lo studio della probabilità si è concentrato principalmente sulla prima domanda. Tuttavia, nel XVIII secolo, il reverendo Thomas Bayes iniziò a riflettere sulla seconda domanda, dando origine a quello che oggi chiamiamo probabilità inversa.

Questo approccio ha generato numerose controversie nella storia della statistica, in gran parte perché influenza molti ambiti. Ad esempio, possiamo chiederci: quanto è probabile che un'ipotesi scientifica sia vera, dato il risultato di un esperimento? Per stimare questa probabilità — un compito che molti scienziati ritengono essenziale per la statistica moderna — è necessario fare uso del teorema di Bayes e delle probabilità a priori.

::: {.callout-tip title="Il problema di Monty Hall" collapse="true"}
Abbiamo già discusso in precedenza il problema di Monty Hall. Vediamo ora come possa essere risolto utilizzando il Teorema di Bayes. 

Ci sono tre porte:

- dietro una porta c'è un'automobile (il premio);
- dietro le altre due porte ci sono delle capre.

Il giocatore sceglie una porta (ad esempio, la porta 1). Successivamente, il conduttore (che sa cosa c'è dietro ogni porta) apre una delle due porte rimanenti, rivelando una capra (ad esempio, apre la porta 3). A questo punto, il giocatore può decidere se mantenere la scelta iniziale o cambiare porta.

Vogliamo calcolare la probabilità che l'automobile sia dietro la porta 2, sapendo che il conduttore ha aperto la porta 3.

Definizione degli eventi.

- A1, A2, A3: l'automobile si trova dietro la porta 1, 2 o 3, rispettivamente.
- P3: il conduttore apre la porta 3, rivelando una capra.

Vogliamo calcolare la probabilità condizionata $P(A2 \mid P3)$, ovvero la probabilità che l'automobile sia dietro la porta 2, sapendo che il conduttore ha aperto la porta 3. La formula di Bayes è:

$$
P(A2 \mid P3) = \frac{P(P3 \mid A2) \cdot P(A2)}{P(P3)}
$$

1. **$P(A2)$**: probabilità iniziale che l'automobile sia dietro la porta 2.
   - Poiché ci sono tre porte e solo un'automobile, $P(A2) = \frac{1}{3}$.

2. **$P(P3 \mid A2)$**: probabilità che il conduttore apra la porta 3, sapendo che l'automobile è dietro la porta 2.
   - Se l'automobile è dietro la porta 2, il conduttore deve aprire la porta 3 (non può aprire la porta 1, scelta dal giocatore, né la porta 2, dove c'è l'automobile). Quindi, $P(P3 \mid A2) = 1$.

3. **$P(P3)$**: probabilità che il conduttore apra la porta 3.
   - Il conduttore può aprire la porta 3 in due casi:
     - Se l'automobile è dietro la porta 2 (con probabilità $\frac{1}{3}$).
     - Se l'automobile è dietro la porta 1 (con probabilità $\frac{1}{3}$), e il conduttore sceglie casualmente tra la porta 2 e la porta 3 (con probabilità $\frac{1}{2}$).
   - Quindi:
     $$
     \begin{align}
     P(P3) &= P(P3 \mid A2) \cdot P(A2) + P(P3 \mid A1) \cdot P(A1) \notag\\
     &= 1 \cdot \frac{1}{3} + \frac{1}{2} \cdot \frac{1}{3} = \frac{1}{3} + \frac{1}{6} = \frac{1}{2}.\notag
     \end{align}
     $$

Sostituendo i valori calcolati:

$$
P(A2 \mid P3) = \frac{1 \cdot \frac{1}{3}}{\frac{1}{2}} = \frac{\frac{1}{3}}{\frac{1}{2}} = \frac{2}{3}.
$$

In conclusione, la probabilità che l'automobile sia dietro la porta 2, sapendo che il conduttore ha aperto la porta 3, è $\frac{2}{3}$ (circa 66.7%). Questo significa che cambiando porta, il giocatore ha una probabilità di vincita del 66.7%, mentre mantenendo la scelta iniziale la probabilità è solo del 33.3%.

Questo esempio mostra come il Teorema di Bayes permetta di aggiornare le probabilità in base a nuove informazioni. Nel contesto del problema di Monty Hall, cambiare porta raddoppia le possibilità di vincere l'automobile.
:::

## Riflessioni Conclusive

In questo capitolo abbiamo esplorato vari esempi, principalmente nel campo medico e forense, per illustrare come il teorema di Bayes permetta di combinare le informazioni derivate dalle osservazioni con le conoscenze precedenti (priori), aggiornando così il nostro grado di convinzione rispetto a un'ipotesi. Il teorema di Bayes fornisce un meccanismo razionale, noto come "aggiornamento bayesiano", che ci consente di ricalibrare le nostre convinzioni iniziali alla luce di nuove evidenze.

Una lezione fondamentale che il teorema di Bayes ci insegna, sia nella ricerca scientifica che nella vita quotidiana, è che spesso non ci interessa tanto conoscere la probabilità che qualcosa accada assumendo vera un'ipotesi, quanto piuttosto la probabilità che un'ipotesi sia vera, dato che abbiamo osservato una certa evidenza. In altre parole, la forza del teorema di Bayes sta nella sua capacità di affrontare direttamente il problema inverso, cioè come dedurre la verità di un'ipotesi a partire dalle osservazioni.

Il framework bayesiano per l'inferenza probabilistica offre un approccio generale per comprendere come i problemi di induzione possano essere risolti in linea di principio e, forse, anche come possano essere affrontati dalla mente umana.

In questo capitolo ci siamo concentrati sull'applicazione del teorema di Bayes utilizzando probabilità puntuali. Tuttavia, il teorema esprime pienamente il suo potenziale quando sia l'evidenza che i gradi di certezza a priori delle ipotesi sono rappresentati attraverso distribuzioni di probabilità continue. Questo sarà l'argomento centrale nella prossima sezione della dispensa, dove approfondiremo il flusso di lavoro bayesiano e l'uso di distribuzioni continue nell'aggiornamento bayesiano.

## Informazioni sull'Ambiente di Sviluppo {.unnumbered}

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}


