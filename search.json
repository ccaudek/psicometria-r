[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psicometria",
    "section": "",
    "text": "Benvenuti\nBenvenuti nel sito web dell’insegnamento di Psicometria, parte del Corso di Laurea in Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#descrizione",
    "href": "index.html#descrizione",
    "title": "Psicometria",
    "section": "Descrizione",
    "text": "Descrizione\nL’insegnamento offre una formazione teorico-pratica nell’ambito dell’inferenza statistica, con un focus particolare sulle applicazioni in campo psicologico. Attraverso esercitazioni pratiche in Python e R, gli studenti acquisiranno competenze nell’analisi di dati e nell’uso di modelli statistici avanzati.\n\nAnno Accademico: 2024-2025\nCodice Insegnamento: B000286\nOrario e Luogo: Lunedì e Martedì (8:30-10:30), Giovedì (11:30-13:30), Plesso didattico La Torretta.\n\n\n\n\n\n\n\nNota\n\n\n\nQuesto sito web è la fonte ufficiale per il programma dell’insegnamento B000286 - Psicometria e le modalità d’esame.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#struttura-dellinsegnamento",
    "href": "index.html#struttura-dellinsegnamento",
    "title": "Psicometria",
    "section": "Struttura dell’Insegnamento",
    "text": "Struttura dell’Insegnamento\nL’insegnamento è articolato in diverse sezioni, ognuna delle quali si concentra su un argomento chiave per fornire una comprensione approfondita delle metodologie e degli strumenti necessari per l’analisi statistica e la gestione dei dati.\n\nFondamenti di Statistica: Introduzione ai concetti statistici di base, con un focus su misure descrittive, distribuzioni e visualizzazione dei dati.\nTeoria della Probabilità: Principi fondamentali della probabilità, inclusi eventi, distribuzioni di probabilità e applicazioni pratiche.\nInferenza Frequentista: Approfondimento sull’inferenza statistica basata sulla frequenza, con applicazioni per test di ipotesi e stime puntuali e intervallari.\nInferenza Bayesiana: Introduzione e applicazioni avanzate dell’inferenza bayesiana, con un confronto con l’approccio frequentista.\nProgrammazione in R: Esercitazioni pratiche sull’utilizzo di R per l’analisi dei dati, con particolare attenzione a script replicabili e workflow efficienti.\nGestione di un Progetto di Data Analysis: Approccio strutturato per interpretare, documentare e comunicare i risultati di un’analisi, con attenzione alla riproducibilità.\nComunicazione dei Risultati: Tecniche per rappresentare in modo efficace i risultati statistici, inclusa la creazione di report, visualizzazioni e presentazioni.\n\nQuesta struttura mira a combinare teoria e pratica, offrendo agli studenti gli strumenti necessari per affrontare le sfide dell’analisi statistica in contesti reali.\nConsulta il syllabus completo per ulteriori dettagli.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#materiale-didattico",
    "href": "index.html#materiale-didattico",
    "title": "Psicometria",
    "section": "Materiale Didattico",
    "text": "Materiale Didattico\nIl presente sito web ospita la dispensa ufficiale del corso, contenente tutte le note e i materiali relativi alle lezioni. Per quanto riguarda le esercitazioni pratiche e gli esempi applicativi, è possibile accedere al sito dedicato, disponibile al seguente indirizzo: Psicometria Esercizi. Entrambi i materiali sono forniti gratuitamente agli studenti, senza necessità di ulteriori acquisti.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "prefazione.html",
    "href": "prefazione.html",
    "title": "Prefazione",
    "section": "",
    "text": "Bibliografia\nCome possiamo migliorare l’analisi dei dati psicologici per renderla più affidabile e robusta? È possibile affrontare questa sfida semplicemente applicando una serie di algoritmi o procedure standard? L’analisi dei dati in psicologia può davvero essere ridotta a un insieme di “ricette” preconfezionate (McElreath, 2020)?\nQueste domande ci portano a riflettere sulla natura stessa dell’analisi dei dati psicologici. A differenza di ciò che suggerisce l’approccio frequentista del test dell’ipotesi nulla, l’analisi dei dati non è una disciplina che si esaurisce con l’applicazione meccanica di metodi predefiniti. Anzi, considerare l’analisi dei dati come un insieme di procedure automatiche contribuisce a uno dei problemi più gravi della psicologia contemporanea: la crisi della replicabilità dei risultati (Korbmacher et al., 2023).\nMa perché la replicabilità è così cruciale? Se i risultati delle ricerche psicologiche non sono replicabili, significa che la nostra comprensione dei fenomeni psicologici è superficiale e inaffidabile. Questo non è solo un problema teorico o accademico; ha implicazioni dirette sulle applicazioni pratiche della psicologia. Se le basi scientifiche sono incerte, anche le strategie di intervento psicologico rischiano di essere inefficaci o addirittura dannose (Funder et al., 2014; Ioannidis, 2019; Shrout & Rodgers, 2018; Tackett et al., 2019).\nPerché le pratiche di analisi dei dati derivanti dal frequentismo potrebbero contribuire a questa crisi? In che modo gli incentivi accademici influenzano la qualità della ricerca psicologica? E, soprattutto, quali alternative abbiamo per migliorare l’affidabilità e la validità delle nostre conclusioni?\nL’analisi bayesiana emerge come una delle proposte per superare i limiti dell’approccio frequentista (Gelman et al., 1995). Tuttavia, è sufficiente abbandonare l’inferenza frequentista per risolvere i problemi della psicologia? Come possiamo integrare metodi robusti e flessibili, come quelli bayesiani, con una comprensione più approfondita e trasparente dei fenomeni psicologici?\nIn questo corso, esploreremo queste domande, cercando di identificare le “buone pratiche” dell’analisi dei dati psicologici. Discuteremo i limiti delle metodologie attuali, esamineremo le cause sottostanti della crisi della replicabilità e valuteremo come l’adozione di metodi avanzati, come l’inferenza bayesiana e la modellazione causale, possa offrire soluzioni efficaci (Oberauer & Lewandowsky, 2019; Wagenmakers et al., 2018; Yarkoni, 2022). Il nostro obiettivo è fornire una visione critica e costruttiva, che non solo identifichi le sfide della ricerca psicologica, ma proponga anche percorsi concreti per migliorare la qualità e l’affidabilità della scienza psicologica.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "prefazione.html#bibliografia",
    "href": "prefazione.html#bibliografia",
    "title": "Prefazione",
    "section": "",
    "text": "Funder, D. C., Levine, J. M., Mackie, D. M., Morf, C. C., Sansone, C., Vazire, S., & West, S. G. (2014). Improving the dependability of research in personality and social psychology: Recommendations for research and educational practice. Personality and Social Psychology Review, 18(1), 3–12.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nIoannidis, J. P. (2019). What have we (not) learnt from millions of scientific papers with P values? The American Statistician, 73(sup1), 20–25.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nShrout, P. E., & Rodgers, J. L. (2018). Psychology, science, and knowledge construction: Broadening perspectives from the replication crisis. Annual Review of Psychology, 69(1), 487–510.\n\n\nTackett, J. L., Brandes, C. M., King, K. M., & Markon, K. E. (2019). Psychology’s replication crisis and clinical psychological science. Annual Review of Clinical Psychology, 15(1), 579–604.\n\n\nWagenmakers, E.-J., Marsman, M., Jamil, T., Ly, A., Verhagen, J., Love, J., Selker, R., Gronau, Q. F., Šmı́ra, M., Epskamp, S., et al. (2018). Bayesian inference for psychology. Part I: Theoretical advantages and practical ramifications. Psychonomic Bulletin & Review, 25, 35–57.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "programmazione2024.html",
    "href": "programmazione2024.html",
    "title": "1  Calendario delle lezioni",
    "section": "",
    "text": "1.1 Calendario delle relazioni in itinere\nIl calendario didattico prevede 32 incontri, con un esame parziale a metà corso e gli ultimi tre incontri riservati a un secondo esame parziale e alle presentazioni degli studenti.\nPausa di Pasqua\nLe relazioni di avanzamento del progetto di gruppo dovranno essere consegnate entro le scadenze stabilite. Ogni gruppo dovrà presentare un unico elaborato.\nOgni relazione rappresenta una tappa del progetto di gruppo, che culminerà nella presentazione finale durante gli ultimi incontri del corso.",
    "crumbs": [
      "Programmazione",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Calendario delle lezioni</span>"
    ]
  },
  {
    "objectID": "programmazione2024.html#calendario-delle-relazioni-in-itinere",
    "href": "programmazione2024.html#calendario-delle-relazioni-in-itinere",
    "title": "1  Calendario delle lezioni",
    "section": "",
    "text": "Data di Scadenza\nContenuto della Relazione\n\n\n\n\n18 marzo\nRelazione 1: Importazione dei dati, data wrangling, data tidying, dizionario dei dati, statistiche descrittive\n\n\n25 marzo\nRelazione 2: Priori coniugati e metodo basato su griglia\n\n\n31 marzo\nRelazione 3: Metodi Monte Carlo e algoritmi MCMC\n\n\n7 aprile\nRelazione 4: Regressione lineare\n\n\n8 maggio\nRelazione 5: Confronto di modelli\n\n\n18 maggio\nRelazione 6: Analisi frequentista; limiti dell’approccio frequentista",
    "crumbs": [
      "Programmazione",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Calendario delle lezioni</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/introduction_key_notions.html",
    "href": "chapters/key_notions/introduction_key_notions.html",
    "title": "Introduzione",
    "section": "",
    "text": "La data science è un campo che si sviluppa all’intersezione tra la statistica e l’informatica. La statistica fornisce una serie di metodologie per analizzare i dati e ottenere informazioni significative, mentre l’informatica si occupa dello sviluppo di software e strumenti per implementare tali metodologie. In questa sezione della dispensa, approfondiremo alcuni concetti fondamentali della statistica e della misurazione psicologica. Considereremo anche in termini generali quali sono gli obiettivi e i limiti dell’analisi dei dati psicologici.",
    "crumbs": [
      "Fondamenti",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html",
    "href": "chapters/key_notions/00_uncertainty.html",
    "title": "2  Abbracciare l’incertezza",
    "section": "",
    "text": "2.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nL’espressione “abbracciare l’incertezza” è tra le più emblematiche nel panorama della statistica bayesiana. In questo capitolo, approfondiremo il significato di questa affermazione, seguendo la trattazione introduttiva proposta nel primo capitolo di Understanding Uncertainty di Lindley (Lindley, 2013).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#lincertezza-nella-ricerca-psicologica",
    "href": "chapters/key_notions/00_uncertainty.html#lincertezza-nella-ricerca-psicologica",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.2 L’incertezza nella ricerca psicologica",
    "text": "2.2 L’incertezza nella ricerca psicologica\nL’incertezza rappresenta un elemento cruciale non solo nella statistica, ma in tutte le discipline scientifiche, con particolare rilievo per la psicologia, che affronta fenomeni complessi e difficili da misurare. Nell’indagare processi cognitivi, emozioni e comportamenti, i ricercatori si confrontano con dati complessi, spesso ambigui e suscettibili di interpretazioni molteplici. Sebbene alcune affermazioni possano essere sostenute con elevata confidenza o confutate con certezza, la maggior parte delle ipotesi scientifiche si colloca in una zona grigia dominata dall’incertezza.\nL’obiettivo di questo insegnamento è guidare gli studenti nella comprensione e nella gestione dell’incertezza nella ricerca psicologica, adottando l’approccio bayesiano all’analisi dei dati. Questo metodo, basato sulla quantificazione e sull’aggiornamento delle credenze alla luce di nuove evidenze, fornirà agli studenti gli strumenti per affrontare l’incertezza in modo rigoroso e sistematico, sia nella carriera accademica sia nella pratica clinica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#la-natura-soggettiva-dellincertezza",
    "href": "chapters/key_notions/00_uncertainty.html#la-natura-soggettiva-dellincertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.3 La natura soggettiva dell’incertezza",
    "text": "2.3 La natura soggettiva dell’incertezza\nUn elemento cruciale dell’incertezza, spesso trascurato, è la sua dimensione soggettiva. De Finetti (Finetti, 1970) ha evidenziato come l’incertezza sia, almeno in parte, una questione personale: ciò che è incerto per uno psicologo può non esserlo per un altro, in funzione delle loro esperienze, conoscenze pregresse e interpretazioni dei dati disponibili. Anche di fronte a una stessa questione, due ricercatori possono condividere un’incertezza comune, ma con gradi di intensità diversi.\nQuesta componente soggettiva è particolarmente significativa in psicologia, dove le differenze individuali e culturali influenzano la percezione e l’interpretazione dei fenomeni. L’approccio bayesiano offre un potente strumento per affrontare questa soggettività, consentendo di quantificare le differenze tra credenze individuali e di aggiornarle in modo coerente sulla base di nuove evidenze oggettive.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#lonnipresenza-dellincertezza",
    "href": "chapters/key_notions/00_uncertainty.html#lonnipresenza-dellincertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.4 L’onnipresenza dell’incertezza",
    "text": "2.4 L’onnipresenza dell’incertezza\nL’incertezza pervade ogni aspetto della ricerca psicologica. Ogni esperimento, misurazione o interpretazione dei dati comporta un margine di incertezza. Questa condizione è particolarmente evidente nello studio di fenomeni complessi come il comportamento umano o i processi mentali, dove innumerevoli variabili interagiscono, molte delle quali difficili da misurare o controllare con precisione.\nTuttavia, l’incertezza non deve essere vista come un ostacolo insormontabile. Al contrario, riconoscerla e quantificarla può favorire una comprensione più profonda e realistica dei fenomeni psicologici. Attraverso l’approccio bayesiano, diventa possibile integrare l’incertezza nel processo di indagine scientifica, trattandola non come un limite, ma come una risorsa.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#superare-la-soppressione-dellincertezza",
    "href": "chapters/key_notions/00_uncertainty.html#superare-la-soppressione-dellincertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.5 Superare la soppressione dell’incertezza",
    "text": "2.5 Superare la soppressione dell’incertezza\nNonostante la sua onnipresenza, l’incertezza è spesso ignorata o minimizzata nella comunicazione scientifica. Questo può avvenire attraverso interpretazioni eccessivamente ottimistiche dei risultati, la presentazione di conclusioni come fatti certi, o una riluttanza a riconoscere i limiti degli studi condotti. Tale atteggiamento, sebbene comprensibile, può condurre a conclusioni errate e a una visione distorta della realtà.\nL’approccio bayesiano permette di affrontare l’incertezza in modo esplicito e costruttivo. Fornendo un quadro rigoroso per quantificarla, analizzarla e comunicarla chiaramente, migliora la trasparenza della ricerca e promuove conclusioni più oneste e accurate.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#i-benefici-dellincertezza",
    "href": "chapters/key_notions/00_uncertainty.html#i-benefici-dellincertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.6 I benefici dell’incertezza",
    "text": "2.6 I benefici dell’incertezza\nContrariamente a quanto si possa pensare, l’incertezza offre numerosi vantaggi per la ricerca psicologica:\n\nStimola l’esplorazione scientifica: La consapevolezza dell’incertezza incoraggia i ricercatori a formulare nuove ipotesi e a migliorare i metodi di studio.\nPromuove l’onestà intellettuale: Accettare l’incertezza rende i ricercatori più cauti e aperti a prospettive alternative.\nMigliora la qualità delle analisi: Integrare l’incertezza porta a disegni sperimentali più robusti e interpretazioni più accurate.\nFacilita la collaborazione interdisciplinare: Riconoscere i limiti delle proprie conoscenze stimola la ricerca di input da altri esperti.\nRiflette la complessità dei fenomeni psicologici: L’incertezza è intrinseca ai processi mentali e riconoscerla consente di rappresentarli in modo più realistico.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#tipi-di-incertezza",
    "href": "chapters/key_notions/00_uncertainty.html#tipi-di-incertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.7 Tipi di incertezza",
    "text": "2.7 Tipi di incertezza\nL’incertezza nella ricerca può essere classificata in tre categorie principali, in base alla sua origine: aleatoria, epistemica e ontologica (Gansch & Adee, 2020).\n\n2.7.1 Incertezza Aleatoria\nL’incertezza aleatoria è intrinseca alla natura casuale di un processo e non può essere eliminata per un dato modello probabilistico. Essa è considerata irreducibile e viene quantificata tramite distribuzioni probabilistiche. Ad esempio, nella misurazione della risposta di un individuo a uno stimolo, la variabilità intrinseca nel comportamento umano, dovuta a fattori imprevedibili, rappresenta un caso di incertezza aleatoria. Questo tipo di incertezza è una caratteristica fondamentale di molti fenomeni psicologici e biologici.\n\n\n2.7.2 Incertezza Epistemica\nL’incertezza epistemica deriva dalla conoscenza limitata o incompleta di un fenomeno. Essa rappresenta il “noto-ignoto”, cioè ciò che sappiamo di non sapere, ed è legata alle semplificazioni insite in ogni modello scientifico. Ad esempio, un modello psicologico che non consideri le influenze culturali o ambientali potrebbe risultare incompleto, introducendo incertezza epistemica. Diversamente dall’incertezza aleatoria, l’incertezza epistemica può essere ridotta attraverso il miglioramento dei modelli, l’inclusione di variabili rilevanti o la raccolta di ulteriori dati.\n\n\n2.7.3 Incertezza Ontologica\nL’incertezza ontologica riguarda l’“ignoto-ignoto”, ovvero aspetti di un sistema che non sono ancora stati identificati. In psicologia, questo potrebbe riferirsi a variabili o processi non ancora scoperti che influenzano un comportamento. Ad esempio, studiando i disturbi mentali, potrebbero emergere nuovi fattori di rischio precedentemente sconosciuti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#il-calcolo-dellincertezza-nellapproccio-bayesiano",
    "href": "chapters/key_notions/00_uncertainty.html#il-calcolo-dellincertezza-nellapproccio-bayesiano",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.8 Il calcolo dell’incertezza nell’approccio bayesiano",
    "text": "2.8 Il calcolo dell’incertezza nell’approccio bayesiano\nL’insegnamento si propone di fornire agli studenti strumenti per affrontare e quantificare l’incertezza attraverso l’approccio bayesiano (Gelman et al., 1995). Fondato sul teorema di Bayes, questo metodo rappresenta un quadro teorico rigoroso e sistematico per aggiornare le credenze alla luce di nuove evidenze, configurandosi come una componente centrale della metodologia scientifica.\nIl processo si basa su quattro passaggi essenziali. In primo luogo, si parte dalla quantificazione delle credenze iniziali, note come prior, che rappresentano le conoscenze pregresse o le ipotesi relative a un determinato fenomeno psicologico. Successivamente, si analizza la forza delle evidenze empiriche fornite dai dati raccolti, formalizzata nella likelihood. Queste due informazioni vengono combinate per generare le credenze aggiornate, chiamate posterior, che sintetizzano la conoscenza disponibile integrando i dati empirici e le ipotesi iniziali. Infine, le credenze aggiornate possono essere utilizzate per prendere decisioni più informate, pianificare ricerche future e orientare interventi.\n\n2.8.1 Il ruolo delle credenze e delle decisioni nella ricerca psicologica\nLe credenze rivestono un ruolo fondamentale nella ricerca psicologica, influenzando tutte le fasi del processo scientifico, dalla progettazione degli esperimenti all’interpretazione dei risultati, fino alla scelta di interventi clinici. L’approccio bayesiano si distingue per la sua capacità di esplicitare e formalizzare queste credenze, consentendo di aggiornare il loro contenuto in modo coerente e trasparente man mano che emergono nuove evidenze.\nQuesto metodo permette non solo di ottimizzare le decisioni basandosi su informazioni aggiornate, ma anche di comunicare chiaramente l’incertezza associata alle conclusioni, evidenziandone i limiti e garantendo maggiore trasparenza scientifica. Affrontare l’incertezza come una componente intrinseca della ricerca non solo migliora la qualità dell’analisi, ma consente anche di promuovere un approccio più realistico e rigoroso nello studio dei fenomeni psicologici.\nIn sintesi, l’approccio bayesiano offre un modello operativo per integrare l’incertezza nel processo decisionale, trattandola non come un ostacolo, ma come un elemento essenziale per una comprensione più sfumata e accurata della realtà.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#riflessioni-conclusive",
    "href": "chapters/key_notions/00_uncertainty.html#riflessioni-conclusive",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.9 Riflessioni Conclusive",
    "text": "2.9 Riflessioni Conclusive\nQuesto insegnamento fornisce gli strumenti per applicare l’analisi bayesiana nell’ambito dei dati psicologici, insegnando a considerare l’incertezza come una parte integrante e preziosa del processo scientifico. Attraverso questo approccio, gli studenti potranno acquisire una comprensione più raffinata e strutturata dei fenomeni psicologici, integrando l’incertezza come elemento fondamentale per interpretare i dati e formulare inferenze rigorose.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#bibliografia",
    "href": "chapters/key_notions/00_uncertainty.html#bibliografia",
    "title": "2  Abbracciare l’incertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFinetti, B. de. (1970). Teoria delle probabilità: sintesi introduttiva con appendice critica. Einaudi.\n\n\nGansch, R., & Adee, A. (2020). System theoretic view on uncertainties. 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE), 1345–1350.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html",
    "href": "chapters/key_notions/01_key_notions.html",
    "title": "3  Concetti chiave",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nQuesto capitolo introduce il contesto e i principi base dell’analisi dei dati, con un focus su come le tecniche statistiche, combinate con una solida teoria dei fenomeni, siano strumentali all’avanzamento delle conoscenze scientifiche.\nL’analisi dei dati consente di sintetizzare grandi quantità di informazioni e di verificare le previsioni avanzate dalle teorie. Tuttavia, senza una teoria che dia significato ai dati, le osservazioni rimangono mere descrizioni prive di un contesto esplicativo. È attraverso l’integrazione tra dati e teoria che si raggiunge una comprensione profonda dei fenomeni e si favorisce l’avanzamento scientifico.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#introduzione",
    "href": "chapters/key_notions/01_key_notions.html#introduzione",
    "title": "3  Concetti chiave",
    "section": "",
    "text": "Most of the fundamental ideas of science are essentially simple, and may, as a rule, be expressed in a language comprehensible to everyone.\n(Einstein A and Infeld L, 1938)\n\n\n\n\n\n\n\n\nStatistica\n\n\n\nIl termine “statistica” può assumere diversi significati, a seconda del contesto in cui viene utilizzato.\n\nNel primo senso, la statistica è una scienza e una disciplina che si occupa dello studio e dell’applicazione di metodi e tecniche per la raccolta, l’organizzazione, l’analisi, l’interpretazione e la presentazione di dati.\nNel secondo senso, il termine “statistica” si riferisce a una singola misura o un valore numerico che è stato calcolato a partire da un campione di dati. Questo tipo di statistica rappresenta una caratteristica specifica del campione. Esempi comuni di statistiche in questo senso includono la media campionaria, la deviazione standard campionaria o il coefficiente di correlazione campionario.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#la-spiegazione-scientifica",
    "href": "chapters/key_notions/01_key_notions.html#la-spiegazione-scientifica",
    "title": "3  Concetti chiave",
    "section": "3.1 La Spiegazione Scientifica",
    "text": "3.1 La Spiegazione Scientifica\nLa scienza non si limita a descrivere o prevedere i fenomeni; essa mira a spiegare il perché degli eventi, fornendo una comprensione delle cause e dei meccanismi che governano il mondo. La spiegazione scientifica è quindi uno strumento essenziale per costruire teorie che non solo descrivono e prevedono, ma anche chiariscono le dinamiche causali e le connessioni tra fenomeni, aiutando così a sviluppare un controllo informato sugli stessi.\nSe prendiamo l’esempio del successo accademico in psicologia dell’educazione, possiamo osservare che i dati rivelano una forte associazione tra il livello di istruzione dei genitori e il successo scolastico dei figli. Tuttavia, una semplice previsione basata su questa associazione – “provenendo da una famiglia con basso livello d’istruzione, è improbabile che tu ottenga un titolo universitario” – non risponde alle domande fondamentali per migliorare il sistema educativo: perché esiste questa disparità? Quali interventi potrebbero ridurre questa disuguaglianza?\nPer andare oltre la previsione, la scienza deve individuare i fattori causali che contribuiscono al fenomeno, esplorare il modo in cui agire su questi fattori potrebbe alterare l’outcome, e stimare le incertezze e le dinamiche temporali di questi effetti. Ad esempio, per ridurre la disuguaglianza educativa, è necessario comprendere se e come aumentare il sostegno finanziario agli studenti possa realmente facilitare il percorso scolastico di chi proviene da contesti meno favoriti, e prevedere gli effetti di lungo termine di tali politiche. Questo approccio permette non solo di prevedere ma anche di controllare e migliorare i fenomeni studiati.\n\n3.1.1 Elementi Fondamentali della Spiegazione Scientifica\nLa filosofia della scienza ha individuato tre elementi chiave di una spiegazione scientifica:\n\nExplanandum: il fenomeno da spiegare. Ad esempio, “si è verificata una crisi petrolifera nel 1973.”\nExplanans: un insieme di affermazioni che spiegano il fenomeno. Per esempio, “gli stati membri dell’OAPEC hanno imposto un embargo sul petrolio in risposta al sostegno degli Stati Uniti a Israele nella guerra del Kippur.”\nLegame esplicativo: i principi o le leggi che descrivono il meccanismo sottostante, ossia il modo in cui l’explanans causa l’explanandum. Nel caso dell’embargo, il legame potrebbe essere: “gli stati dell’OAPEC usarono il petrolio come strumento politico per influenzare la politica estera degli Stati Uniti.”\n\nI modelli scientifici incorporano questi elementi, rappresentando una metodologia per ottenere spiegazioni scientifiche. Essi includono il fenomeno da spiegare, i fattori causali rilevanti e i meccanismi che collegano i fattori all’esito. A differenza dei modelli puramente descrittivi o predittivi, i modelli scientifici in psicologia sono progettati per rispondere a domande causali, facilitando la comprensione e il controllo dei fenomeni.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#modelli-psicologici",
    "href": "chapters/key_notions/01_key_notions.html#modelli-psicologici",
    "title": "3  Concetti chiave",
    "section": "3.2 Modelli Psicologici",
    "text": "3.2 Modelli Psicologici\nUn modello è una rappresentazione matematica semplificata di un fenomeno reale. È composto da un insieme di equazioni e ipotesi che definiscono la struttura probabilistica e le relazioni tra le variabili, cercando di cogliere gli aspetti essenziali del fenomeno senza includerne ogni dettaglio. Esistono spesso diversi modelli applicabili a uno stesso problema, e il compito della scienza dei dati è identificare quello che meglio si adatta ai dati, soddisfacendo criteri di validità e accuratezza.\nI modelli psicologici sono strumenti concettuali per descrivere, spiegare e prevedere il comportamento umano e i processi mentali. Un buon modello psicologico dovrebbe avere alcune caratteristiche fondamentali:\n\nCoerenza descrittiva: Il modello deve rappresentare in modo logico e coerente il fenomeno studiato, catturando gli aspetti chiave del processo psicologico e organizzando le osservazioni in una struttura comprensibile.\nCapacità predittiva: Un modello efficace deve essere in grado di fare previsioni accurate sui futuri sviluppi del fenomeno. Questa capacità non solo ne aumenta l’utilità, ma permette anche di testarne la validità.\nSupporto empirico: Le ipotesi e le previsioni del modello devono essere confermate da dati raccolti attraverso ricerche sistematiche e rigorose.\nFalsificabilità: Un modello scientifico deve poter essere testato e, se necessario, confutato con l’osservazione e l’esperimento. Questo principio assicura che il modello rimanga aperto alla revisione e al miglioramento in base a nuove evidenze.\nParsimonia: Il modello dovrebbe spiegare il fenomeno nel modo più semplice possibile, evitando complessità inutili.\nGeneralizzabilità: Deve essere applicabile a una vasta gamma di situazioni e contesti, non limitandosi a casi specifici o condizioni sperimentali particolari.\nUtilità pratica: Un modello efficace dovrebbe fornire spunti utili per interventi, terapie o applicazioni nel mondo reale.\n\nLa modellazione in psicologia affronta sfide uniche dovute alla natura soggettiva e variabile dell’esperienza umana. I ricercatori devono bilanciare la precisione scientifica con la flessibilità necessaria per cogliere la complessità dei fenomeni psicologici, considerando al contempo i limiti etici della sperimentazione e le potenziali implicazioni sociali dei loro modelli.\nL’analisi dei dati, attraverso tecniche statistiche, è il mezzo per valutare un modello psicologico. Oltre a stabilire se il modello riesce a spiegare i dati osservati, l’analisi verifica la capacità del modello di fare previsioni su dati non ancora raccolti. In questo modo, la modellazione non solo consente di comprendere i fenomeni psicologici ma permette anche di prevedere e, in certi casi, influenzare il comportamento e i processi mentali.\n\n3.2.1 Rappresentare i Fenomeni per Ragionare e Comunicare\nLa spiegazione scientifica, oltre a chiarire i meccanismi causali, serve anche a fornire un linguaggio per ragionare sui fenomeni e per condividere la conoscenza. In psicologia, la costruzione di modelli scientifici permette di rappresentare i fenomeni attraverso variabili, funzioni e parametri, fornendo un vocabolario per descrivere componenti, dipendenze e proprietà dei fenomeni. Un modello semplice e chiaro consente di emulare il comportamento del fenomeno senza necessità di simulazioni complesse, facilitando la comunicazione e l’intuizione.\nUn aspetto importante della spiegazione scientifica è la possibilità di utilizzare i modelli per stimolare l’intuizione e generare nuove domande. La comprensione dei fenomeni attraverso una rappresentazione scientifica accessibile permette di formulare ipotesi, collegare concetti, e trasferire conoscenze da un campo all’altro.\nIn sintesi, la spiegazione scientifica va oltre la mera previsione: mira a fornire una comprensione completa dei fenomeni, basata su nessi causali e su un linguaggio formale per ragionare e comunicare. I modelli scientifici non solo predicono eventi, ma spiegano come e perché questi eventi si verificano, offrendo una struttura con cui intervenire e influenzare i fenomeni stessi.\nNell’analisi dei dati bayesiana, questa attenzione alle cause e agli effetti trova un’applicazione naturale. La possibilità di aggiornare le proprie credenze alla luce di nuove informazioni consente di costruire modelli che non si limitano alla descrizione o alla previsione, ma che forniscono spiegazioni coerenti e profonde dei fenomeni, aiutando a sviluppare teorie sempre più raffinate e applicabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#ruolo-dellanalisi-dei-dati",
    "href": "chapters/key_notions/01_key_notions.html#ruolo-dellanalisi-dei-dati",
    "title": "3  Concetti chiave",
    "section": "3.3 Ruolo dell’Analisi dei Dati",
    "text": "3.3 Ruolo dell’Analisi dei Dati\nL’analisi dei dati riveste un ruolo centrale nelle scienze, specialmente in psicologia, per due ragioni principali:\n\nRiassumere grandi quantità di informazioni: consente di sintetizzare dati complessi in statistiche descrittive, grafici e altre rappresentazioni che rendono i dati accessibili e comprensibili. Questo processo evidenzia tendenze generali, variazioni e anomalie, facilitando l’identificazione di schemi comportamentali e differenze tra gruppi.\nVerificare le predizioni di un modello scientifico: permette di confrontare le aspettative teoriche con i dati osservati, valutando la validità delle ipotesi sottostanti. Questa verifica contribuisce direttamente all’avanzamento della conoscenza scientifica, sostenendo, modificando o confutando una teoria.\n\nSebbene l’analisi dei dati possa portare alla scoperta di correlazioni o schemi interessanti, questi risultati, senza una teoria, offrono solo una comprensione limitata. Per esempio, rilevare che due variabili psicologiche sono correlate non fornisce informazioni sulla natura di questa relazione o sul motivo per cui esiste. Per interpretare e attribuire un significato a queste osservazioni, è necessario un quadro teorico che le contestualizzi e proponga meccanismi causali o esplicativi.\n\n3.3.1 Carattere Multidisciplinare dell’Analisi dei Dati\nL’analisi dei dati si situa all’intersezione di tre discipline principali: statistica, teoria della probabilità e informatica. Ciascuna contribuisce con strumenti e approcci specifici essenziali per comprendere i dati, estrarre conoscenza e generare nuove ipotesi scientifiche.\n\nStatistica: offre tecniche per raccogliere, analizzare e interpretare i dati, fornendo strumenti descrittivi e inferenziali utili per trarre conclusioni e prendere decisioni.\nTeoria della probabilità: fornisce la base matematica della statistica, consentendo di modellare e quantificare l’incertezza e di comprendere i fenomeni aleatori che caratterizzano molte osservazioni in psicologia.\nInformatica: supporta l’analisi attraverso strumenti per la gestione, l’elaborazione e la visualizzazione di grandi quantità di dati. La programmazione consente di sviluppare modelli avanzati e gestire dataset complessi.\n\nQuesta natura multidisciplinare riflette la complessità dell’analisi dei dati e la necessità di integrare diverse competenze per affrontare le sfide scientifiche contemporanee.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "href": "chapters/key_notions/01_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "title": "3  Concetti chiave",
    "section": "3.4 Concetti Chiave nell’Analisi dei Dati",
    "text": "3.4 Concetti Chiave nell’Analisi dei Dati\nPer condurre un’analisi dei dati efficace, è fondamentale comprendere alcuni concetti chiave.\n\n3.4.1 Popolazioni e Campioni\nIn ogni analisi dei dati, è fondamentale identificare la popolazione di interesse, l’insieme completo di entità o individui che rappresentano il fenomeno studiato. In psicologia, ad esempio, si può voler studiare il benessere in una popolazione generale o in una sotto-popolazione specifica, come gli individui che hanno subito un evento stressante.\nPer ottenere informazioni dettagliate su una popolazione, si utilizzano campioni: sottoinsiemi rappresentativi dai quali si possono fare inferenze sull’intera popolazione. La rappresentatività del campione è cruciale, poiché un campione non rappresentativo può portare a conclusioni errate e limitare la generalizzabilità dei risultati.\n\n\n3.4.2 Bias nella Raccolta Dati\nI bias nella raccolta e interpretazione dei dati possono influenzare profondamente i risultati di uno studio. Capire chi ha raccolto i dati, come e con quali finalità, è fondamentale per garantire una corretta interpretazione. I dati non sono mai neutri e le intenzioni che ne guidano la raccolta spesso ne influenzano l’interpretazione (Murray & Carr, 2024; Nobles, 2000)\n\n\n\nTabella creata da Ellie Murray.\n\n\n\n\n3.4.3 Variabili e Costanti\nNell’analisi statistica, le variabili rappresentano le caratteristiche osservate che possono assumere diversi valori (numerici o categorici). Al contrario, le costanti sono valori che rimangono fissi in un dato contesto. Si distinguono poi le variabili indipendenti (o predittive), che influenzano le variabili dipendenti, e le variabili dipendenti, che rappresentano gli esiti di interesse.\n\n\n3.4.4 Effetti\nIn statistica, un effetto misura il cambiamento osservato nelle variabili dipendenti in relazione alle variabili indipendenti. Ad esempio, l’efficacia di una terapia può essere valutata misurando la differenza nei sintomi prima e dopo il trattamento (Huntington-Klein, 2021).\n\n\n3.4.5 Stima e Inferenza\n\n3.4.5.1 Stima\nLa stima statistica consente di ottenere informazioni su una popolazione a partire da un campione. Si utilizzano statistiche campionarie (come la media campionaria) per stimare i parametri della popolazione (come la media vera della popolazione).\nGli stimatori devono possedere proprietà come:\n\nconsistenza: la stima converge al vero valore del parametro all’aumentare della dimensione del campione;\nnon distorsione: il valore atteso dello stimatore è uguale al vero valore del parametro;\nefficienza: lo stimatore ha la minor varianza possibile.\n\nL’accuratezza della stima dipende da vari fattori, tra cui la dimensione e la rappresentatività del campione, la variabilità nella popolazione e il metodo di campionamento utilizzato.\n\n\n\n3.4.6 Inferenza Statistica\nDopo aver ottenuto le stime, l’inferenza statistica permette di trarre conclusioni più generali sulla popolazione. Essa consente di valutare ipotesi specifiche o rispondere a domande di ricerca basate sui dati raccolti.\nAd esempio, se abbiamo stimato la media del rendimento accademico in un campione di studenti, l’inferenza statistica ci consente di quantificare l’incertezza riguardo alla differenza di rendimento tra maschi e femmine all’interno della popolazione più ampia. In questo modo, l’inferenza statistica ci fornisce gli strumenti per fare previsioni e trarre conclusioni su fenomeni che riguardano l’intera popolazione.\nEsistono due approcci principali.\nL’inferenza bayesiana:\n\nSi basa sul teorema di Bayes;\nUtilizza probabilità a priori, che riflettono conoscenze o credenze iniziali su un fenomeno;\nAggiorna queste probabilità con nuovi dati per ottenere probabilità a posteriori;\nFornisce una interpretazione delle probabilità come gradi di credenza soggettivi.\n\nL’approccio frequentista:\n\nSi fonda sulla frequenza relativa di eventi osservati in esperimenti ripetuti;\nUtilizza strumenti come il test di ipotesi nulla e gli intervalli di confidenza per trarre conclusioni;\nNon fa uso di probabilità a priori, concentrandosi esclusivamente sui dati osservati.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "href": "chapters/key_notions/01_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "title": "3  Concetti chiave",
    "section": "3.5 Le Sfide dell’Inferenza Statistica in Psicologia",
    "text": "3.5 Le Sfide dell’Inferenza Statistica in Psicologia\nSecondo Gelman et al. (2020), l’inferenza statistica in psicologia affronta tre sfide principali:\n\nGeneralizzare dai campioni alla popolazione: Questa sfida è strettamente legata al problema del campionamento di comodo, spesso usato in psicologia, ma presente in quasi tutte le applicazioni dell’inferenza statistica. La difficoltà risiede nel trarre conclusioni affidabili su una popolazione più ampia partendo da un campione limitato e, a volte, non rappresentativo.\nGeneralizzare dal gruppo trattato al gruppo di controllo: Questa sfida riguarda l’inferenza causale, un aspetto centrale per determinare l’efficacia dei trattamenti psicologici. L’obiettivo è stabilire se i risultati osservati nel gruppo trattato possano essere applicati al gruppo di controllo o ad altre popolazioni, permettendo una valutazione valida dell’effetto del trattamento.\nGeneralizzare dalle misurazioni osservate ai costrutti sottostanti: In psicologia, i dati raccolti non corrispondono mai perfettamente ai costrutti teorici di interesse. La sfida è inferire questi costrutti latenti dai dati osservati, che rappresentano spesso solo un’approssimazione imperfetta.\n\nQueste sfide evidenziano la complessità dell’inferenza in psicologia e la necessità di metodologie robuste per affrontarle.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#riflessioni-conclusive",
    "href": "chapters/key_notions/01_key_notions.html#riflessioni-conclusive",
    "title": "3  Concetti chiave",
    "section": "3.6 Riflessioni Conclusive",
    "text": "3.6 Riflessioni Conclusive\nIn psicologia, le teorie forniscono ipotesi testabili che spiegano il “come” e il “perché” di determinati fenomeni mentali e comportamentali. Una teoria robusta permette di formulare previsioni chiare e specifiche, che possono essere verificate empiricamente attraverso l’analisi dei dati. Ad esempio, una teoria sull’ansia potrebbe prevedere che, in un compito di esposizione graduale a stimoli ansiogeni, il livello di ansia diminuisca progressivamente. Senza una teoria che spieghi perché questo dovrebbe accadere, tale osservazione rimane solo un dato descrittivo, privo di valore esplicativo o predittivo.\nL’analisi dei dati diventa davvero potente quando è integrata a una teoria. Senza teoria, i dati possono descrivere fenomeni ma non spiegare i meccanismi sottostanti. La teoria fornisce il contesto interpretativo, orientando la raccolta e l’analisi dei dati, e permettendo una comprensione profonda dei fenomeni psicologici.\nUn esempio è l’uso della data science per analizzare l’efficacia di un trattamento psicoterapeutico. I dati possono mostrarci una diminuzione dei sintomi in seguito alla terapia, ma è solo la teoria alla base del trattamento che fornisce un quadro interpretativo per questo miglioramento, proponendo i meccanismi per cui il trattamento riduce i sintomi. La teoria orienta quindi l’analisi e permette di interpretare i dati in un contesto scientifico.\nSviluppare una teoria in psicologia è complesso a causa della notevole variabilità umana. Un buon modello psicologico deve prevedere con precisione i comportamenti osservabili e rappresentare i processi mentali latenti. Queste previsioni devono essere testabili e falsificabili (Eronen & Bringmann, 2021).\nLa relazione tra teoria e analisi dei dati è dinamica e iterativa. I modelli e le teorie si evolvono grazie alla verifica empirica. Se i dati non supportano le previsioni di una teoria, essa viene modificata o sostituita, favorendo l’avanzamento scientifico.\nIn conclusione, la teoria e l’analisi dei dati sono complementari e interdipendenti. L’analisi dei dati offre gli strumenti per testare e affinare le teorie psicologiche, mentre la teoria dà significato e contesto ai dati, rendendo possibile una comprensione profonda e utile dei fenomeni psicologici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#bibliografia",
    "href": "chapters/key_notions/01_key_notions.html#bibliografia",
    "title": "3  Concetti chiave",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nEronen, M. I., & Bringmann, L. F. (2021). The theory crisis in psychology: How to move forward. Perspectives on Psychological Science, 16(4), 779–788.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories. Cambridge University Press.\n\n\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMurray, E. J., & Carr, K. C. (2024). Measuring Racial Sentiment Using Social Media Is Harder Than It Seems. Epidemiology, 35(1), 60–63.\n\n\nNobles, M. (2000). Shades of citizenship: Race and the census in modern politics. Stanford University Press.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html",
    "href": "chapters/key_notions/02_measurement.html",
    "title": "4  La misurazione in psicologia",
    "section": "",
    "text": "4.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nLa scienza si avvale di modelli per interpretare i dati, ma opera sempre con teorie incomplete e misurazioni soggette a errori. Di conseguenza, è fondamentale riconoscere le incertezze quando si cerca di estrarre informazioni dalle misurazioni utilizzando i nostri modelli. Nessuna misurazione, spiegazione o previsione è perfettamente accurata e precisa, e non possiamo mai conoscere con esattezza l’entità dei loro errori.\nQuesta incertezza viene catturata in tre equazioni fondamentali. La prima è l’Equazione di Misurazione, che riconosce l’errore osservativo: \\(y = z + \\varepsilon_y\\), dove \\(y\\) rappresenta il valore misurato, \\(z\\) il valore reale e \\(\\varepsilon_y\\) l’errore di misurazione. La seconda è l’Equazione di Modellazione, che esprime la presenza di un diverso tipo di errore: \\(z = f(x, \\theta) + \\varepsilon_\\text{model}\\), dove \\(f\\) è il modello, \\(x\\) sono le condizioni ambientali per cui eseguiamo il modello, \\(\\theta\\) sono i valori dei parametri del modello e \\(\\varepsilon_\\text{model}\\) rappresenta l’errore del modello, che sorge perché \\(f\\), \\(x\\) e \\(\\theta\\) saranno tutti in qualche misura imprecisi.\nCombinando queste due equazioni, otteniamo l’Equazione della Scienza: \\(y = f(x, \\theta) + \\varepsilon_\\text{model} + \\varepsilon_y\\). La scienza è il tentativo di spiegare le osservazioni \\(y\\) utilizzando un modello \\(f\\), cercando di minimizzare l’errore di misurazione \\(\\varepsilon_y\\) e l’errore del modello \\(\\varepsilon_\\text{model}\\), in modo che il modello possa essere utilizzato per fare previsioni sul mondo reale (\\(z\\)). L’approccio bayesiano alla scienza riconosce e quantifica le incertezze su tutti e sei gli elementi dell’Equazione della Scienza: \\(y\\), \\(f\\), \\(x\\), \\(\\theta\\), \\(\\varepsilon_\\text{model}\\) e \\(\\varepsilon_y\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#la-teoria-della-misurazione",
    "href": "chapters/key_notions/02_measurement.html#la-teoria-della-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.2 La teoria della Misurazione",
    "text": "4.2 La teoria della Misurazione\nLa teoria della misurazione, oggetto di questo capitolo, si concentra sull’errore di misurazione e sull’equazione fondamentale \\(y = z + \\varepsilon_y\\). Questa equazione può essere esaminata da tre prospettive distinte. La prima concerne l’affidabilità della misura, rappresentata dal termine \\(\\varepsilon_y\\). La psicometria, branca dedicata alla teoria della misurazione psicologica, si occupa di quantificare l’affidabilità delle misure psicologiche attraverso metodi come la Teoria Classica dei Test e la Teoria di Risposta all’Item.\nLa seconda prospettiva riguarda la validità delle misure psicologiche, ovvero quanto adeguatamente la misura \\(y\\) rappresenti il costrutto \\(z\\). Questo aspetto, più complesso dell’affidabilità, non può essere risolto meramente con metodi statistici, ma richiede una profonda comprensione delle teorie psicologiche e della loro capacità di descrivere e prevedere i fenomeni psicologici.\nLa terza prospettiva si concentra sulle procedure di assegnazione dei valori a \\(y\\), esplorando quali metodi (questionari, interviste, esperimenti) siano più appropriati e come valutarne l’adeguatezza.\n\n4.2.1 Costrutti Psicologici\nLa teoria della misurazione sottolinea l’importanza di distinguere tra la procedura di misurazione e il costrutto che si intende misurare. Ad esempio, mentre la temperatura è un costrutto, il termometro è lo strumento di misurazione. Analogamente, l’abilità matematica è un costrutto, mentre un test di matematica è la procedura per misurarla.\nNelle scienze psicologiche e sociali, la misurazione presenta sfide uniche rispetto alle scienze fisiche, poiché i costrutti in esame sono spesso astratti e non direttamente osservabili. Ciò richiede una particolare attenzione alla validità e all’affidabilità degli strumenti di misurazione, nonché una costante riflessione sulle limitazioni e le potenziali fonti di errore.\nIl capitolo introduce concetti fondamentali relativi alla misurazione quantitativa delle caratteristiche psicologiche, con un focus sulla teoria delle scale di misura di Stevens (1946). Questa teoria fornisce un quadro concettuale per comprendere i diversi tipi di scale di misurazione e le operazioni matematiche appropriate per ciascuna. Inoltre, vengono esplorate alcune procedure di scaling psicologico, ovvero l’assegnazione di numeri all’intensità di fenomeni psicologici.\n\n\n4.2.2 Scaling Psicologico\nLo scaling psicologico si occupa della trasformazione dei dati empirici raccolti durante uno studio psicologico in misure o punteggi che rappresentino accuratamente le caratteristiche psicologiche oggetto di indagine.\nScaling di Guttman. Uno dei metodi di scaling più noti è lo «Scaling di Guttman», che viene utilizzato per rappresentare relazioni ordinate tra gli elementi di una scala. Ad esempio, in un questionario sui sintomi dell’ansia, le domande possono essere disposte in ordine di intensità crescente dei sintomi. Secondo il modello di Guttman, se un partecipante risponde “sì” a una domanda che riflette un sintomo più intenso, ci si aspetta che abbia risposto “sì” anche a tutte le domande precedenti, che rappresentano sintomi di intensità minore. Questo approccio consente di costruire una scala che riflette in modo sistematico e coerente la gravità dei sintomi.\nScaling Thurstoniano. Lo «Scaling Thurstoniano» è un metodo utilizzato per misurare preferenze o giudizi soggettivi. Ad esempio, per valutare la preferenza tra diversi tipi di cibi, i partecipanti confrontano due cibi alla volta ed esprimono una preferenza. Le risposte vengono poi utilizzate per assegnare punteggi che riflettono la preferenza media per ciascun cibo.\nQuestionari Likert. I questionari Likert richiedono ai partecipanti di esprimere il loro grado di accordo con una serie di affermazioni su una scala a più livelli, che va da «fortemente in disaccordo» a «fortemente d’accordo». I punteggi ottenuti vengono sommati per rappresentare la posizione complessiva dell’individuo rispetto all’oggetto di studio.\n\n\n4.2.3 Metodi di Valutazione delle Scale Psicologiche\nPer valutare le proprietà delle scale psicologiche, vengono utilizzati vari metodi. Ad esempio, l’affidabilità delle misure può essere analizzata utilizzando il coefficiente alpha di Cronbach o il coefficiente Omega di McDonald, entrambi utilizzati per misurare la coerenza interna delle risposte ai diversi item di un questionario. Inoltre, la validità delle scale può essere esaminata confrontando i risultati ottenuti con misure simili o attraverso analisi statistiche che verificano se la scala cattura accuratamente il costrutto psicologico che si intende misurare. La validità di costrutto è particolarmente cruciale, poiché riguarda la capacità della scala di misurare effettivamente il concetto psicologico che si intende esplorare.\n\n\n4.2.4 Prospettive Moderne\nNegli ultimi anni, il dibattito sulla misurazione psicologica si è arricchito di nuove prospettive, grazie all’avvento di tecnologie avanzate e all’integrazione di approcci interdisciplinari. Ecco alcune delle tendenze più rilevanti.\nTeoria della Risposta agli Item. La Teoria della Risposta agli Item (IRT) ha guadagnato popolarità per la sua capacità di fornire stime più precise delle abilità latenti rispetto ai modelli classici. La IRT considera la probabilità che un individuo risponda correttamente a un item in funzione della sua abilità e delle caratteristiche dell’item stesso, offrendo una visione più dettagliata delle proprietà psicometriche degli strumenti di misurazione.\nApprocci Bayesiani. Gli approcci bayesiani stanno rivoluzionando il campo della psicometria, permettendo di incorporare informazioni a priori nelle stime e di aggiornare le credenze sulla base di nuovi dati. Questi metodi sono particolarmente utili per affrontare la complessità e l’incertezza inerenti alla misurazione psicologica.\nAnalisi di Rete. L’analisi di rete è un’altra metodologia emergente che vede i costrutti psicologici non come variabili latenti indipendenti, ma come reti di sintomi interconnessi. Questo approccio può offrire nuove intuizioni sulla struttura delle psicopatologie e sulla dinamica dei sintomi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#le-scale-di-misurazione",
    "href": "chapters/key_notions/02_measurement.html#le-scale-di-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.3 Le scale di misurazione",
    "text": "4.3 Le scale di misurazione\nLe scale di misurazione sono strumenti fondamentali per assegnare numeri ai dati osservati, rappresentando le proprietà psicologiche. La teoria delle scale di Stevens Stevens (1946) identifica quattro tipi di scale di misurazione: nominali, ordinali, a intervalli e di rapporti. Ognuna di queste scale consente di effettuare operazioni aritmetiche diverse, poiché ciascuna di esse è in grado di “catturare” solo alcune delle proprietà dei fenomeni psicologici che si intende misurare.\n\n\n\nScale di misurazione.\n\n\n\n4.3.1 Scala nominale\nILa scala nominale è il livello di misurazione più semplice e corrisponde ad una tassonomia o classificazione delle categorie che utilizziamo per descrivere i fenomeni psicologici. I simboli o numeri che costituiscono questa scala rappresentano i nomi delle categorie e non hanno alcun valore numerico intrinseco. Con la scala nominale possiamo solo distinguere se una caratteristica psicologica è uguale o diversa da un’altra.\nI dati raccolti con la scala nominale sono suddivisi in categorie qualitative e mutuamente esclusive, in cui ogni dato appartiene ad una sola categoria. In questa scala, esiste solo la relazione di equivalenza tra le misure delle unità di studio: gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti.\nL’unica operazione algebrica consentita dalla scala nominale è quella di contare le unità di studio che appartengono ad ogni categoria e il numero totale di categorie. Di conseguenza, la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nDalla scala nominale è possibile costruire altre scale nominali equivalenti alla prima, trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle categorie, ma lasciando inalterata la suddivisione delle unità di studio nelle medesime classi di equivalenza. In altre parole, cambiando i nomi delle categorie di una variabile misurata su scala nominale, si ottiene una nuova variabile esattamente equivalente alla prima.\n\n\n4.3.2 Scala ordinale\nLa scala ordinale mantiene la caratteristica della scala nominale di classificare ogni unità di misura all’interno di una singola categoria, ma introduce la relazione di ordinamento tra le categorie. In quanto basata su una relazione di ordine, una scala ordinale descrive solo il rango di ordine tra le categorie e non fornisce informazioni sulla distanza tra di esse. Non ci dice, ad esempio, se la distanza tra le categorie \\(a\\) e \\(b\\) è uguale, maggiore o minore della distanza tra le categorie \\(b\\) e \\(c\\).\nUn esempio classico di scala ordinale è quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed è scalfito da quello di livello superiore.\n\n\n\nLa scala di durezza dei minerali di Mohs. Un oggetto è considerato più duro di X se graffia X. Sono incluse anche misure di durezza relativa utilizzando uno sclerometro, da cui emerge la non linearità della scala di Mohs (Burchard, 2004).\n\n\n\n\n4.3.3 Scala ad intervalli\nLa scala ad intervalli di misurazione include le proprietà della scala nominale e della scala ordinale e permette di misurare le distanze tra le coppie di unità statistiche in termini di un intervallo costante, chiamato “unità di misura”, a cui viene attribuito il valore “1”. L’origine della scala, ovvero il punto zero, è scelta arbitrariamente e non indica l’assenza della proprietà che si sta misurando. Ciò significa che la scala ad intervalli consente anche valori negativi e lo zero non viene attribuito all’unità statistica in cui la proprietà risulta assente.\nLa scala ad intervalli equivalenti consente l’esecuzione di operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non possibili con le scale di misura nominale o ordinale. Tuttavia, il limite della scala ad intervalli è che non consente di calcolare il rapporto tra coppie di misure. È possibile affermare la differenza tra \\(a\\) e \\(b\\) come la metà della differenza tra \\(c\\) e \\(d\\) o che le due differenze sono uguali, ma non è possibile affermare che \\(a\\) abbia una proprietà misurata in quantità doppia rispetto a \\(b\\). In altre parole, non è possibile stabilire rapporti diretti tra le misure ottenute. Solo le differenze tra le modalità permettono tutte le operazioni aritmetiche, come la somma, l’elevazione a potenza o la divisione, che sono alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l’unità di misura è arbitraria e può essere cambiata attraverso una dilatazione, ovvero la moltiplicazione di tutti i valori della scala per una costante positiva. Inoltre, la traslazione, ovvero l’aggiunta di una costante a tutti i valori della scala, è ammessa poiché non altera le differenze tra i valori della scala. La scala rimane invariata rispetto a traslazioni e dilatazioni e dunque le uniche trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b &gt; 0.\n\\]\nInfatti, l’uguaglianza dei rapporti fra gli intervalli rimane invariata a seguito di una trasformazione lineare.\nEsempio di scala ad intervalli è la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è possibile stabilire se due modalità sono uguali o diverse: 30\\(^\\circ\\)C \\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale è possibile mettere due modalità in una relazione d’ordine: 30\\(^\\circ\\)C \\(&gt;\\) 20\\(^\\circ\\)C. In aggiunta ai casi precedenti, però, è possibile definire una unità di misura per cui è possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c’è una differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. I valori di temperatura, oltre a poter essere ordinati secondo l’intensità del fenomeno, godono della proprietà che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di 80\\(^\\circ\\)C non è il doppio di una di 40\\(^\\circ\\)C. Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, 20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa che la relazione “il doppio di” che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla proprietà misurata (cioè la temperatura). La decisione di che scala usare (Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realtà empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\nÈ facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n\n4.3.4 Scala di rapporti\nNella scala a rapporti equivalenti, lo zero non è arbitrario e rappresenta l’elemento che ha intensità nulla rispetto alla proprietà misurata. Per costruire questa scala, si associa il numero 0 all’elemento con intensità nulla e si sceglie un’unità di misura \\(u\\). Ad ogni elemento si assegna un numero \\(a\\) definito come \\(a=d/u\\), dove \\(d\\) rappresenta la distanza dall’origine. In questo modo, i numeri assegnati riflettono le differenze e i rapporti tra le intensità della proprietà misurata.\nIn questa scala, è possibile effettuare operazioni aritmetiche non solo sulle differenze tra i valori della scala, ma anche sui valori stessi della scala. L’unica scelta arbitraria è l’unità di misura, ma lo zero deve sempre rappresentare l’intensità nulla della proprietà considerata.\nLe trasformazioni ammissibili in questa scala sono chiamate trasformazioni di similarità e sono del tipo \\(y' = by\\), dove \\(b&gt;0\\). In questa scala, i rapporti tra i valori rimangono invariati dopo le trasformazioni. In altre parole, se rapportiamo due valori originali e due valori trasformati, il rapporto rimane lo stesso: \\(\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "href": "chapters/key_notions/02_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.4 Gerarchia dei livelli delle scale di misurazione",
    "text": "4.4 Gerarchia dei livelli delle scale di misurazione\nSecondo Stevens (1946), esiste una gerarchia dei livelli delle scale di misurazione, denominati “livelli di scala”. Questi livelli sono organizzati in modo gerarchico, in cui la scala nominale rappresenta il livello più basso della misurazione, mentre la scala a rapporti equivalenti rappresenta il livello più alto.\n\nLa scala nominale è il livello più elementare, in cui le categorie o le etichette vengono assegnate agli oggetti o agli individui senza alcuna valutazione di grandezza o ordine.\nAl livello successivo si trova la scala ordinale, in cui le categorie sono ordinate in base a una qualche qualità o caratteristica. Qui, è possibile stabilire un ordine di preferenza o gerarchia tra le categorie, ma non è possibile quantificare la differenza tra di esse in modo preciso.\nLa scala intervallo rappresenta un livello successivo, in cui le categorie sono ordinate e la differenza tra di esse è quantificabile in modo preciso. In questa scala, è possibile effettuare operazioni matematiche come l’addizione e la sottrazione tra i valori, ma non è possibile stabilire un vero e proprio punto zero significativo.\nInfine, la scala a rapporti equivalenti rappresenta il livello più alto. In questa scala, le categorie sono ordinate, la differenza tra di esse è quantificabile in modo preciso e esiste un punto zero assoluto che rappresenta l’assenza totale della grandezza misurata. Questo livello di scala permette di effettuare tutte le operazioni matematiche, compresa la moltiplicazione e la divisione.\n\nPassando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente.\n\n\n\nRelazioni tra i livelli di misurazione.\n\n\nPer ciò che riguarda le trasformazioni ammissibili, più il livello di scala è basso, più le funzioni sono generali (sono minori cioè i vincoli per passare da una rappresentazione numerica ad un’altra equivalente). Salendo la gerarchia, la natura delle funzioni di trasformazione si fa più restrittiva.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#variabili-discrete-o-continue",
    "href": "chapters/key_notions/02_measurement.html#variabili-discrete-o-continue",
    "title": "4  La misurazione in psicologia",
    "section": "4.5 Variabili discrete o continue",
    "text": "4.5 Variabili discrete o continue\nLe variabili possono essere classificate come variabili a livello di intervalli o di rapporti e possono essere sia discrete che continue.\n\nLe variabili discrete assumono valori specifici ma non possono assumere valori intermedi. Una volta che l’elenco dei valori accettabili è stato definito, non vi sono casi che si trovano tra questi valori. In genere, le variabili discrete assumono valori interi, come il numero di eventi, il numero di persone o il numero di oggetti.\nD’altra parte, le variabili continue possono assumere qualsiasi valore all’interno di un intervallo specificato. Teoricamente, ciò significa che è possibile utilizzare frazioni e decimali per ottenere qualsiasi grado di precisione.\n\n\n\n\nVariabili discrete e continue.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#comprendere-gli-errori-nella-misurazione",
    "href": "chapters/key_notions/02_measurement.html#comprendere-gli-errori-nella-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.6 Comprendere gli errori nella misurazione",
    "text": "4.6 Comprendere gli errori nella misurazione\nGli errori di misurazione possono essere casuali o sistematici. Gli errori casuali sono fluttuazioni aleatorie, mentre gli errori sistematici sono costanti e derivano da problemi nel metodo di misurazione o negli strumenti.\n\n4.6.1 Precisione e Accuratezza\nLa precisione indica la coerenza tra misurazioni ripetute, mentre l’accuratezza si riferisce alla vicinanza del valore misurato al valore reale. Entrambi i concetti sono cruciali per l’assessment psicometrico.\nUtilizzando l’analogia del tiro al bersaglio, si può avere una serie di colpi vicini tra loro ma lontani dal centro (precisione senza accuratezza) oppure colpi distribuiti in modo sparso ma in media vicini al centro (accuratezza senza precisione).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#assessment-psicometrico",
    "href": "chapters/key_notions/02_measurement.html#assessment-psicometrico",
    "title": "4  La misurazione in psicologia",
    "section": "4.7 Assessment psicometrico",
    "text": "4.7 Assessment psicometrico\nL’assessment psicometrico valuta la qualità delle misurazioni psicologiche, considerando la validità e l’affidabilità.\n\n4.7.1 Validità nella Misurazione Psicologica\nLa validità è una proprietà psicometrica fondamentale dei test psicologici. Secondo gli Standards for Educational and Psychological Testing (2014), la validità si riferisce al grado in cui evidenza e teoria supportano le interpretazioni dei punteggi dei test per gli usi proposti. Questo concetto evidenzia che la validità riguarda sia il significato dei punteggi sia il loro utilizzo, rendendola “la considerazione più fondamentale nello sviluppo e nella valutazione dei test”.\n\n\n4.7.2 Evoluzione del Concetto di Validità\nTradizionalmente, la validità era suddivisa in tre categorie:\n\nValidità di Contenuto: Si riferisce alla corrispondenza tra il contenuto degli item di un test e il dominio dell’attributo psicologico che il test intende misurare. È importante che gli item siano pertinenti e rappresentativi dell’attributo misurato.\nValidità di Criterio: Valuta il grado di concordanza tra i risultati ottenuti tramite lo strumento di misurazione e i risultati ottenuti da altri strumenti che misurano lo stesso costrutto o da un criterio esterno. Include validità concorrente e predittiva.\nValidità di Costrutto: Riguarda il grado in cui un test misura effettivamente il costrutto che si intende misurare. Si suddivide in validità convergente (accordo con strumenti che misurano lo stesso costrutto) e validità divergente (capacità di discriminare tra costrutti diversi).\n\nLa moderna teoria della validità non adotta più questa visione tripartita. Gli Standards del 2014 descrivono la validità come un concetto unitario, dove diverse forme di evidenza concorrono a supportare l’interpretazione dei punteggi del test per il loro utilizzo previsto.\n\n\n4.7.3 Tipologie di Prove di Validità\nGli Standards del 2014 identificano cinque categorie principali di prove di validità:\n\nProve Basate sul Contenuto del Test: Valutano quanto il contenuto del test rappresenti adeguatamente il dominio del costrutto da misurare.\nProve Basate sui Processi di Risposta: Analizzano se i processi cognitivi e comportamentali degli esaminandi riflettono il costrutto valutato.\nProve Basate sulla Struttura Interna: Esaminano la coerenza tra gli elementi del test e la struttura teorica del costrutto. L’analisi fattoriale è uno strumento chiave in questo contesto.\nProve Basate sulle Relazioni con Altre Variabili: Studiano la correlazione tra i punteggi del test e altre variabili teoricamente correlate, utilizzando metodi come la validità convergente e divergente.\nProve Basate sulle Conseguenze del Test: Considerano le implicazioni e gli effetti dell’uso del test, sia intenzionali che non intenzionali.\n\n\n\n4.7.4 Minacce alla Validità\nLa validità può essere compromessa quando un test non misura integralmente il costrutto di interesse (sotto-rappresentazione del costrutto) o quando include varianza estranea al costrutto. Inoltre, fattori esterni come l’ansia o la bassa motivazione degli esaminandi, e deviazioni nelle procedure di amministrazione e valutazione, possono influenzare negativamente la validità delle interpretazioni dei risultati.\n\n\n4.7.5 Integrazione delle Prove di Validità\nLa validità di un test si costruisce attraverso l’integrazione di diverse linee di evidenza. Ogni interpretazione o uso di un test deve essere validato specificamente, richiedendo una valutazione continua e accurata delle prove disponibili. Questo processo implica la costruzione di un argomento di validità che consideri attentamente la qualità tecnica del test e l’adeguatezza delle sue interpretazioni per gli scopi previsti.\nIn conclusione, la validità è un concetto complesso e integrato che richiede un’analisi continua e multidimensionale delle evidenze. La moderna teoria della validità enfatizza l’importanza di considerare diverse forme di evidenza per supportare le interpretazioni dei punteggi dei test, garantendo che siano utilizzati in modo appropriato e significativo. Gli sviluppatori e gli utilizzatori di test devono impegnarsi a valutare costantemente la validità per assicurare misurazioni psicologiche accurate e affidabili.\n\n\n4.7.6 Affidabilità\nL’affidabilità concerne la consistenza e stabilità delle misurazioni, verificata attraverso metodi come l’affidabilità test-retest, inter-rater, intra-rater e l’affidabilità interna.\n\nAffidabilità Test-Retest: Questa forma di affidabilità verifica la consistenza delle misurazioni nel tempo. Se un individuo viene testato in due momenti diversi, i risultati dovrebbero essere simili, assumendo che non ci siano stati cambiamenti significativi nel costrutto misurato.\nAffidabilità Inter-rater: In questo caso, l’affidabilità è determinata dalla concordanza tra le valutazioni di diversi esaminatori. Ad esempio, se più psicologi dovessero valutare un individuo utilizzando lo stesso strumento, le loro valutazioni dovrebbero essere simili.\nAffidabilità Intra-rater: Questa misura dell’affidabilità si riferisce alla consistenza delle valutazioni dello stesso esaminatore in momenti diversi.\nAffidabilità Interna: Si riferisce alla coerenza delle risposte all’interno dello stesso test. Ad esempio, se un test misura un costrutto come l’ansia, gli item che misurano l’ansia dovrebbero correlare positivamente l’uno con l’altro. Un modo comune per valutare l’affidabilità interna è utilizzare il coefficiente \\(\\omega\\) di McDonald.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#commenti-e-considerazioni-finali",
    "href": "chapters/key_notions/02_measurement.html#commenti-e-considerazioni-finali",
    "title": "4  La misurazione in psicologia",
    "section": "4.8 Commenti e considerazioni finali",
    "text": "4.8 Commenti e considerazioni finali\nLa teoria della misurazione è fondamentale nella ricerca empirica per valutare l’attendibilità e la validità delle misurazioni. È cruciale valutare l’errore nella misurazione per garantire la precisione e l’accuratezza delle misure. L’assessment psicometrico si occupa di valutare la qualità delle misurazioni psicologiche, considerando l’affidabilità e la validità per garantire misure accurate dei costrutti teorici. Le moderne tecnologie e metodologie stanno continuamente arricchendo questo campo, offrendo strumenti sempre più raffinati per la comprensione delle caratteristiche psicologiche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#bibliografia",
    "href": "chapters/key_notions/02_measurement.html#bibliografia",
    "title": "4  La misurazione in psicologia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLilienfeld, S. O., & Strother, A. N. (2020). Psychological measurement and the replication crisis: Four sacred cows. Canadian Psychology/Psychologie Canadienne, 61(4), 281–288.\n\n\nMaul, A., Irribarra, D. T., & Wilson, M. (2016). On the philosophical foundations of psychological measurement. Measurement, 79, 311–320.\n\n\nStevens, S. S. (1946). On the theory of scales of measurement. Science, 103(2684), 677–680.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html",
    "href": "chapters/key_notions/03_data_analysis.html",
    "title": "5  L’analisi dei dati psicologici",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e competenze chiave\nNel panorama contemporaneo delle scienze sociali e della psicologia, gli ultimi due decenni hanno visto l’emergere di una profonda trasformazione metodologica ed epistemologica. Questo movimento, caratterizzato da concetti chiave quali “Credibility Revolution” (Angrist & Pischke, 2010), “Causal Revolution” (Pearl & Mackenzie, 2018) e “Replication Crisis” (Collaboration, 2015), ha determinato un cambiamento paradigmatico nelle pratiche delle scienze sociali e, in particolare, della psicologia (Korbmacher et al., 2023). Questa transizione verso quella che Munger (2023) definisce “Science versione 2” è stata motivata dalle lacune metodologiche precedenti e ha catalizzato l’adozione di approcci più rigorosi e replicabili.\nLa genesi di questa Riforma è radicata nella constatazione di problematiche metodologiche pervasive, tra cui la proliferazione di falsi positivi (Simmons et al., 2011), l’abuso dei “gradi di libertà dei ricercatori” (Gelman & Loken, 2013), e l’inadeguatezza delle pratiche statistiche tradizionali (Gelman & Loken, 2014). Fenomeni come il p-hacking, l’uso di campioni sottodimensionati (Button et al., 2013), e la mancanza di trasparenza nei metodi di ricerca hanno contribuito a minare la credibilità delle scoperte psicologiche (Ioannidis, 2005; Meehl, 1967), portando alla cosiddetta “Replication Crisis” (Baker, 2016; Bishop, 2019) – si veda il ?sec-crisis.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano",
    "href": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano",
    "title": "5  L’analisi dei dati psicologici",
    "section": "5.1 L’Approccio Bayesiano",
    "text": "5.1 L’Approccio Bayesiano\nIn risposta a queste sfide, l’approccio bayesiano è emerso come un paradigma statistico fondamentale nella “Credibility Revolution”. Contrariamente all’inferenza frequentista basata sul Test dell’Ipotesi Nulla, la statistica bayesiana offre un framework più flessibile e intuitivo per l’analisi dei dati e l’inferenza causale. Il principio cardine dell’approccio bayesiano, l’aggiornamento delle distribuzioni di probabilità a priori (priors) alla luce di nuove evidenze, si allinea perfettamente con l’obiettivo di una scienza cumulativa e auto-correttiva.\nL’adozione di metodi bayesiani in psicologia comporta diversi vantaggi significativi:\n\nQuantificazione dell’incertezza: L’inferenza bayesiana fornisce distribuzioni di probabilità posteriori complete per i parametri di interesse, offrendo una rappresentazione più ricca e sfumata dell’incertezza rispetto agli intervalli di confidenza frequentisti.\nIncorporazione di conoscenze pregresse: Le priors bayesiane consentono l’integrazione formale di conoscenze precedenti nel processo inferenziale, promuovendo un approccio cumulativo alla ricerca.\nRobustezza alle pratiche di ricerca discutibili: I metodi bayesiani sono meno suscettibili a pratiche come il p-hacking, poiché l’inferenza si basa sull’intera distribuzione posteriore piuttosto che su soglie arbitrarie di significatività.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano-nella-ricerca",
    "href": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano-nella-ricerca",
    "title": "5  L’analisi dei dati psicologici",
    "section": "5.2 L’approccio bayesiano nella ricerca",
    "text": "5.2 L’approccio bayesiano nella ricerca\nL’impiego delle statistiche bayesiane nella ricerca psicologica presenta notevoli vantaggi rispetto ad altri metodi statistici tradizionali, come il test di significatività dell’ipotesi nulla. Un punto di forza importante risiede nella sua indipendenza dalla teoria dei grandi campioni, rendendolo particolarmente adatto per gli studi psicologici che spesso si basano su campioni di dimensioni ridotte (Larson et al., 2023).\nLa ricerca psicologica è frequentemente caratterizzata da campioni limitati, dovuti a diversi fattori quali la bassa prevalenza di determinate condizioni, le difficoltà nel reclutamento dei partecipanti e le complessità nelle procedure di valutazione. Questi campioni di piccole dimensioni sono intrinsecamente soggetti a una maggiore eterogeneità, che si manifesta nella variabilità del fenotipo comportamentale delle condizioni psicologiche esaminate e nella discrepanza tra le stime degli effetti in diversi studi. Tale eterogeneità può condurre a stime degli effetti distorte e scarsamente riproducibili.\nL’approccio bayesiano offre una soluzione efficace a queste problematiche. In primo luogo, consente di valutare l’adeguatezza della dimensione del campione attraverso un’analisi della sensibilità dei risultati rispetto alla specificazione delle distribuzioni a priori. In secondo luogo, permette di ottenere risultati precisi anche con campioni ridotti, a condizione che le conoscenze a priori siano accurate e ben definite.\nUn ulteriore vantaggio dell’approccio bayesiano è la sua capacità di ottimizzare l’uso dei campioni di partecipanti, favorendo un’inclusione equa delle popolazioni diversificate. Questo è particolarmente rilevante per gruppi spesso sottorappresentati, come le minoranze etniche. Le statistiche bayesiane aiutano a superare questa sfida evitando di esercitare una pressione eccessiva su questi gruppi per aumentarne la partecipazione, permettendo così una ricerca più equa e rappresentativa.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#modellazione-formale",
    "href": "chapters/key_notions/03_data_analysis.html#modellazione-formale",
    "title": "5  L’analisi dei dati psicologici",
    "section": "5.3 Modellazione Formale",
    "text": "5.3 Modellazione Formale\nLa “Credibility Revolution” ha catalizzato l’integrazione della Data Science nelle pratiche di ricerca psicologica. L’adozione di pipeline di analisi dei dati riproducibili, l’uso di controllo di versione, e la condivisione di dati e codice sono diventati standard de facto nella comunità scientifica. Questi strumenti non solo migliorano la trasparenza e la replicabilità della ricerca, ma facilitano anche la collaborazione e l’accumulo di conoscenze nel campo.\nParallelamente, si è osservato un rinnovato interesse per la modellazione formale in psicologia, che consente non solo la verifica ma anche lo sviluppo di modelli dei meccanismi sottostanti ai fenomeni psicologici (Oberauer & Lewandowsky, 2019; Van Dongen et al., 2024). Questo approccio supera la mera descrizione delle associazioni tra variabili, che era tipica della pratica dominante dell’ANOVA nel contesto pre-riforma.\nLa modellazione bayesiana si presta particolarmente bene a questo approccio, offrendo un framework unificato per la specificazione di modelli formali, l’incorporazione di incertezza parametrica, e la valutazione dell’evidenza empirica. Attraverso tecniche come il confronto tra modelli bayesiano e l’analisi di sensibilità, i ricercatori possono valutare rigorosamente la plausibilità relativa di diverse teorie psicologiche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#riflessioni-epistemologiche",
    "href": "chapters/key_notions/03_data_analysis.html#riflessioni-epistemologiche",
    "title": "5  L’analisi dei dati psicologici",
    "section": "5.4 Riflessioni Epistemologiche",
    "text": "5.4 Riflessioni Epistemologiche\nL’adozione di metodi bayesiani e della Data Science in psicologia deve essere accompagnata da una profonda riflessione epistemologica. Come sottolineato da George Box\n\ntutti i modelli sono sbagliati, ma alcuni sono utili.\n\nQuesta massima risuona particolarmente nel contesto della ricerca psicologica, dove i fenomeni di interesse sono spesso complessi e multifattoriali.\nL’approccio bayesiano, con la sua enfasi sull’aggiornamento iterativo delle credenze alla luce di nuove evidenze, si allinea naturalmente con una visione della scienza come processo di apprendimento continuo piuttosto che come ricerca di verità assolute. Questa prospettiva riconosce i limiti intrinseci dei nostri modelli e delle nostre teorie, pur valorizzandone l’utilità euristica e predittiva (si veda la discussione nella ?sec-poetic-validity).\nIn particolare, McElreath (2020) sottolinea l’importanza di riconoscere la dualità tra il “mondo del modello” e il mondo reale più ampio che cerchiamo di comprendere. Questa consapevolezza è cruciale per evitare la reificazione dei nostri modelli statistici e per mantenere una prospettiva critica sulle nostre inferenze.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#conclusione",
    "href": "chapters/key_notions/03_data_analysis.html#conclusione",
    "title": "5  L’analisi dei dati psicologici",
    "section": "5.5 Conclusione",
    "text": "5.5 Conclusione\nL’integrazione dell’approccio bayesiano e della data science nella ricerca psicologica rappresenta una risposta promettente alle sfide poste dalla “Replication Crisis”. Offrendo un framework coerente per la modellazione formale, l’inferenza statistica e l’incorporazione di conoscenze pregresse, questi approcci promettono di elevare il rigore e la credibilità della ricerca psicologica. Tuttavia, è fondamentale che l’adozione di questi metodi sia accompagnata da una adeguata consapevolezza metodologica ed epistemologica – si veda, ad esempio, il ?sec-causal-inference-regr.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#bibliografia",
    "href": "chapters/key_notions/03_data_analysis.html#bibliografia",
    "title": "5  L’analisi dei dati psicologici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAngrist, J. D., & Pischke, J.-S. (2010). The credibility revolution in empirical economics: How better research design is taking the con out of econometrics. Journal of economic perspectives, 24(2), 3–30.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBishop, D. (2019). The psychology of experimental psychologists: Overcoming cognitive constraints to improve research.\n\n\nButton, K. S., Ioannidis, J. P., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S., & Munafò, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365–376.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nLabatut, B. (2021). Quando abbiamo smesso di capire il mondo. Adelphi Edizioni spa.\n\n\nLarson, C., Kaplan, D., Girolamo, T., Kover, S. T., & Eigsti, I.-M. (2023). A Bayesian statistics tutorial for clinical research: Prior distributions and meaningful results for small clinical samples. Journal of Clinical Psychology, 79(11), 2602–2624.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMeehl, P. E. (1967). Theory-testing in psychology and physics: A methodological paradox. Philosophy of science, 34(2), 103–115.\n\n\nMunger, K. (2023). Temporal validity as meta-science. Research & Politics, 10(3), 20531680231187271.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nPearl, J., & Mackenzie, D. (2018). The book of why: the new science of cause and effect. Basic books.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nVan Dongen, N., Bork, R. van, Finnemann, A., Haslbeck, J., Maas, H. L. van der, Robinaugh, D. J., Ron, J. de, Sprenger, J., & Borsboom, D. (2024). Productive explanation: A framework for evaluating explanations in psychological science. Psychological Review.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html",
    "href": "chapters/R/introduction_r_lang.html",
    "title": "Introduzione",
    "section": "",
    "text": "R è uno dei linguaggi di programmazione più utilizzati per l’analisi dei dati, apprezzato per la sua flessibilità, potenza e il supporto offerto da una vasta comunità di utenti e sviluppatori. Nato come progetto open-source agli inizi degli anni ’90, R è stato concepito specificamente per rispondere alle esigenze di analisi statistica e visualizzazione grafica, diventando rapidamente uno strumento essenziale nel panorama accademico e scientifico.\nR si distingue per la sua capacità di gestire, manipolare e analizzare grandi quantità di dati. Il linguaggio offre un ecosistema ricchissimo di funzionalità che spaziano dalla modellazione lineare e non lineare all’analisi delle serie temporali, includendo tecniche avanzate di classificazione e clustering. Tale versatilità copre praticamente ogni possibile esigenza di analisi statistica, e grazie a una libreria pressoché infinita di pacchetti disponibili, gli utenti possono estendere ulteriormente le capacità del linguaggio per soddisfare necessità specifiche e settoriali.\nUno degli aspetti più apprezzati di R è la sua capacità di creare grafici e visualizzazioni di alta qualità. Con strumenti come quelli offerti dai pacchetti ggplot2 e plotly, R permette di realizzare rappresentazioni grafiche personalizzate e immediatamente pronte per la pubblicazione, come istogrammi, scatterplot e visualizzazioni interattive. Questi strumenti grafici ricoprono un ruolo cruciale nella comunicazione scientifica, rendendo i dati complessi più comprensibili e accessibili.\nIn psicologia e nelle scienze sociali, R è particolarmente utile grazie alle sue capacità avanzate di analisi statistica e visualizzazione. Permette di affrontare analisi sofisticate, come modelli di regressione, analisi fattoriale, e metodi per dati longitudinali, rendendolo uno strumento indispensabile per chi si occupa di ricerca. La sua flessibilità lo rende inoltre ideale per adattarsi a dataset eterogenei e complessi, spesso caratteristici di queste discipline.\nImparare R non significa solo acquisire competenze tecniche, ma anche aprire le porte a nuove possibilità di analisi e ricerca. Grazie al suo continuo sviluppo e alla natura open-source, R è in costante evoluzione, garantendo strumenti sempre aggiornati per affrontare le sfide più attuali nel campo della scienza dei dati.\nIn questo percorso introduttivo, esploreremo le basi del linguaggio R, muovendoci dalla gestione basilare dei dati fino alla creazione di grafici complessi e alla realizzazione di analisi statistiche articolate.",
    "crumbs": [
      "R",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html",
    "href": "chapters/R/01_r_syntax.html",
    "title": "6  Introduzione a R e RStudio",
    "section": "",
    "text": "6.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNegli ultimi anni, la crisi della replicabilità ha messo in luce problemi significativi nella scienza: molte analisi non possono essere riprodotte, minando la fiducia nei risultati pubblicati (Nosek et al., 2022). Per affrontare questa sfida, è fondamentale adottare strumenti che promuovano trasparenza, riproducibilità e rigore metodologico. R si distingue come uno strumento ideale per soddisfare queste esigenze, grazie a tre punti di forza principali:\nA differenza di software con interfacce grafiche (GUI), che spesso introducono errori nascosti e rendono difficile documentare il flusso di lavoro, R favorisce un approccio basato su codice esplicito. Questo approccio:\nUtilizzare R non significa solo apprendere uno strumento tecnico, ma adottare un approccio scientifico moderno e replicabile. Lavorare in R risponde alle richieste di una ricerca affidabile e contribuisce a contrastare la crisi della replicabilità, favorendo analisi trasparenti, rigorose e comunicabili.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#introduzione",
    "href": "chapters/R/01_r_syntax.html#introduzione",
    "title": "6  Introduzione a R e RStudio",
    "section": "",
    "text": "Scripting e documentazione trasparente. Ogni analisi in R viene realizzata attraverso script che documentano in modo esplicito tutti i passaggi. Questo approccio offre numerosi vantaggi:\n\nGli script possono essere salvati, condivisi e rivisti, garantendo che ogni aspetto del processo analitico sia accessibile e riproducibile.\nLa possibilità di eseguire gli stessi script con nuovi dati consente di verificare i risultati originali o applicare l’analisi in contesti differenti.\n\nFlessibilità e personalizzazione. R fornisce un ambiente altamente flessibile, che permette di:\n\nAdattare i flussi di lavoro a problemi specifici o a nuovi set di dati.\nSfruttare una vasta libreria di pacchetti che coprono metodi statistici avanzati, visualizzazione dei dati e machine learning.\nSviluppare funzioni personalizzate per rispondere a esigenze analitiche uniche.\n\nIntegrazione con strumenti di reporting. R si integra perfettamente con strumenti come R Markdown e Quarto, che consentono di combinare analisi, codice e risultati in un unico documento dinamico. Questo approccio offre:\n\nLa possibilità di creare report automatici, aggiornabili semplicemente modificando i dati sottostanti.\nUn formato unificato che include testo descrittivo, codice e output (grafici, tabelle, statistiche), facilitando la comunicazione scientifica.\n\n\n\n\nElimina ambiguità, poiché ogni operazione è descritta chiaramente nello script.\nIncrementa la verificabilità, consentendo a terzi di esaminare ogni passaggio dell’analisi.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#installare-r-e-rstudio",
    "href": "chapters/R/01_r_syntax.html#installare-r-e-rstudio",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.2 Installare R e RStudio",
    "text": "6.2 Installare R e RStudio\n\nScarica e installa R\nVai al sito ufficiale di CRAN (https://cran.r-project.org/), scegli la versione per il tuo sistema operativo (Windows, Mac o Linux) e segui le istruzioni di installazione.\nScarica e installa RStudio\nDopo aver installato R, scarica RStudio dal sito ufficiale (https://posit.co/download/rstudio-desktop/). Scegli la versione gratuita “RStudio Desktop” e segui le istruzioni per il tuo sistema operativo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#panoramica-sullinterfaccia-di-rstudio",
    "href": "chapters/R/01_r_syntax.html#panoramica-sullinterfaccia-di-rstudio",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.3 Panoramica sull’interfaccia di RStudio",
    "text": "6.3 Panoramica sull’interfaccia di RStudio\nRStudio rende l’uso di R più intuitivo grazie alla sua interfaccia divisa in quattro pannelli principali:\n\nPannello degli script: Qui puoi scrivere e modificare i tuoi script, cioè sequenze di comandi salvabili per analisi ripetibili e organizzate.\nConsole: Esegue i comandi scritti direttamente o lanciati dagli script, mostrando risultati, messaggi e errori.\nPannello dell’ambiente: Mostra i dataset, le variabili e gli oggetti caricati nella sessione di lavoro, permettendoti di gestire facilmente i dati.\nPannello grafici/aiuto/file: Visualizza grafici, fornisce accesso alla documentazione di R e consente di navigare tra file e cartelle sul tuo sistema.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#creare-un-nuovo-progetto-in-rstudio",
    "href": "chapters/R/01_r_syntax.html#creare-un-nuovo-progetto-in-rstudio",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.4 Creare un Nuovo Progetto in RStudio",
    "text": "6.4 Creare un Nuovo Progetto in RStudio\nAvviare un nuovo progetto\nDal menu di RStudio, seleziona File &gt; New Project… per creare un nuovo progetto. I progetti in RStudio sono uno strumento efficace per organizzare il lavoro relativo a una specifica analisi o domanda di ricerca. All’interno di un progetto puoi raccogliere script, file di dati e output, mantenendo tutto ben strutturato.\nScegliere la posizione del progetto\nPuoi creare una nuova directory dedicata al progetto oppure associare il progetto a una directory esistente. Organizzare i progetti in cartelle dedicate aiuta a mantenere i file in ordine e a utilizzare percorsi relativi, rendendo il tuo lavoro più facile da condividere con collaboratori e più portabile tra diversi sistemi.\nQuesta organizzazione è particolarmente utile per evitare confusione e assicurarsi che tutti i file necessari siano facilmente accessibili e collegati al progetto corretto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#concetti-di-base-nella-programmazione-in-r",
    "href": "chapters/R/01_r_syntax.html#concetti-di-base-nella-programmazione-in-r",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.5 Concetti di Base nella Programmazione in R",
    "text": "6.5 Concetti di Base nella Programmazione in R\nIniziare a usare R, soprattutto per chi si avvicina per la prima volta a questo linguaggio nel contesto della psicologia, significa comprendere i concetti fondamentali che ne costituiscono la base. Questo capitolo introduce i principi essenziali della programmazione in R, tra cui:\n\nLa comprensione della sintassi di R.\nLa familiarizzazione con i principali tipi di dati e strutture.\nL’acquisizione delle operazioni di base.\n\nQuesti concetti sono fondamentali per manipolare efficacemente i dati e condurre analisi statistiche, rappresentando il punto di partenza per sfruttare al meglio le potenzialità di R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#oggetti-in-r",
    "href": "chapters/R/01_r_syntax.html#oggetti-in-r",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.6 Oggetti in R",
    "text": "6.6 Oggetti in R\nIn R, tutto è un oggetto: dai numeri o stringhe di testo semplici, fino a strutture più complesse come grafici, riassunti di analisi statistiche o script che eseguono compiti specifici. Creare e assegnare valori agli oggetti è fondamentale per lavorare in R.\n\n6.6.1 Creare oggetti\nPer creare un oggetto, basta assegnargli un nome e un valore usando l’operatore di assegnazione &lt;-:\n\nmy_obj &lt;- 48\n\nIn questo esempio, abbiamo creato un oggetto chiamato my_obj e gli abbiamo assegnato il valore 48. Anche l’operatore = può essere usato, ma è considerato una cattiva pratica.\nPer visualizzare il valore di un oggetto, basta scriverne il nome:\n\nmy_obj\n#&gt; [1] 48\n\nGli oggetti creati vengono memorizzati nell’ambiente di lavoro. In RStudio, puoi visualizzarli nella scheda Environment e ottenere dettagli come tipo, lunghezza e valore.\nÈ possibile assegnare a un oggetto anche una stringa di testo, racchiudendola tra virgolette:\n\nmy_obj2 &lt;- \"R è fantastico\"\nmy_obj2\n#&gt; [1] \"R è fantastico\"\n\nSe dimentichi le virgolette, R mostrerà un errore.\nPer modificare il valore di un oggetto esistente, basta riassegnarlo:\n\nmy_obj2 &lt;- 1024\n\nOra il tipo di my_obj2 è cambiato da carattere a numerico. È anche possibile usare oggetti per crearne di nuovi:\n\nmy_obj3 &lt;- my_obj + my_obj2\nmy_obj3\n#&gt; [1] 1072\n\nSe provi a sommare oggetti di tipo diverso, R restituirà un errore:\nchar_obj &lt;- \"ciao\"\nchar_obj2 &lt;- \"mondo\"\nchar_obj3 &lt;- char_obj + char_obj2\n#&gt; Error in char_obj + char_obj2 : non-numeric argument to binary operator\nQuando incontri errori come questo, chiedi a AI la spiegazione del messaggio, per esempio: “non-numeric argument to binary operator error + r”. Un errore comune è anche:\nmy_obj &lt;- 48\nmy_obj4 &lt;- my_obj + no_obj\n#&gt; Error: object 'no_obj' not found\nR segnala che no_obj non è stato definito e, di conseguenza, l’oggetto my_obj4 non è stato creato.\n\n\n6.6.2 Nomi degli oggetti\nDare un nome agli oggetti può sembrare banale, ma è importante scegliere nomi brevi e informativi. Usa un formato coerente, come:\n\nSnake case: output_summary\nDot case: output.summary\nCamel case: outputSummary\n\nEvita di iniziare i nomi con numeri (es. 2my_variable) o caratteri speciali (&, ^, /, ecc.). Inoltre, non usare parole riservate (es. TRUE, NA) o nomi di funzioni già esistenti (es. data).\nEsempio da evitare:\ndata &lt;- read.table(\"mydatafile\", header = TRUE) # `data` è già una funzione!",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#commenti",
    "href": "chapters/R/01_r_syntax.html#commenti",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.7 Commenti",
    "text": "6.7 Commenti\nI commenti nel linguaggio di programmazione (in questo caso R) sono parti del codice che il linguaggio stesso ignora completamente, ovvero non vengono eseguite. La loro funzione principale è aiutare il programmatore a chiarire cosa fanno le diverse parti del codice, rendendolo più comprensibile sia a sé stessi sia ad altri. In R, come si può osservare nell’esempio sopra, i commenti iniziano con il simbolo #. Tutto ciò che segue il simbolo # sulla stessa riga viene ignorato durante l’esecuzione del codice.\nÈ una buona pratica commentare frequentemente il codice, soprattutto nei punti in cui le decisioni prese non risultano immediatamente evidenti. I commenti dovrebbero spiegare perché si sta facendo qualcosa, piuttosto che come viene fatto: il “come” è già descritto dal codice stesso.\nAd esempio, invece di scrivere un commento come:\n# Assegno 42 alla variabile x\nx &lt;- 42\nè più utile spiegare il contesto o la motivazione:\n# Valore iniziale scelto per semplificare i calcoli successivi\nx &lt;- 42\nQuesto approccio aiuta chiunque legga il codice (incluso il futuro te stesso!) a comprendere le intenzioni alla base delle scelte fatte, riducendo il tempo necessario per interpretarlo o modificarlo. Un codice ben commentato è quindi non solo più comprensibile, ma anche più facile da mantenere e riutilizzare.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#usare-le-funzioni-in-r",
    "href": "chapters/R/01_r_syntax.html#usare-le-funzioni-in-r",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.8 Usare le funzioni in R",
    "text": "6.8 Usare le funzioni in R\nFino ad ora abbiamo creato oggetti semplici assegnando loro direttamente un valore. Con l’aumento dell’esperienza in R, potresti voler creare oggetti più complessi. Per aiutarti, R offre numerose funzioni già disponibili nella sua installazione di base, e altre possono essere aggiunte installando pacchetti. Una funzione è un insieme di istruzioni che eseguono un compito specifico. Inoltre, è possibile creare funzioni personalizzate.\n\n6.8.1 La funzione c() per creare vettori\nLa prima funzione utile da imparare è c(), che serve a concatenare valori in un vettore. Ad esempio:\n\nmy_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\n\nQuesto codice crea un oggetto chiamato my_vec che contiene una sequenza di numeri. Alcuni concetti fondamentali sulle funzioni in R:\n\nNome e parentesi: Le funzioni in R sono sempre seguite da parentesi tonde ().\nArgomenti: Gli elementi passati alla funzione (tra le parentesi) ne personalizzano il comportamento e sono separati da virgole.\n\nPer vedere il contenuto del vettore:\n\nmy_vec\n#&gt; [1] 2 3 1 6 4 3 3 7\n\n\n\n6.8.2 Funzioni per analizzare vettori\nPuoi utilizzare altre funzioni per calcolare statistiche sul vettore:\n\nmean(my_vec)    # Media\n#&gt; [1] 3.625\n\n\nvar(my_vec)     # Varianza\n#&gt; [1] 3.982143\n\n\nsd(my_vec)      # Deviazione standard\n#&gt; [1] 1.995531\n\n\nlength(my_vec)  # Numero di elementi\n#&gt; [1] 8\n\nPuoi anche salvare i risultati in nuovi oggetti per riutilizzarli:\n\nvec_mean &lt;- mean(my_vec)\nvec_mean\n#&gt; [1] 3.625\n\n\n\n6.8.3 Creare sequenze regolari\nPer creare sequenze di numeri in passi regolari, puoi usare i seguenti comandi.\nSimbolo : per sequenze semplici:\n\nmy_seq &lt;- 1:10\nmy_seq\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\nFunzione seq() per maggiore controllo:\n\nmy_seq2 &lt;- seq(from = 1, to = 5, by = 0.5)\nmy_seq2\n#&gt; [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0\n\n\n\n6.8.4 Ripetere valori\nPuoi ripetere valori o sequenze con la funzione rep().\nRipetere un valore:\n\nmy_seq3 &lt;- rep(2, times = 10)\nmy_seq3\n#&gt;  [1] 2 2 2 2 2 2 2 2 2 2\n\nRipetere una sequenza:\n\nmy_seq5 &lt;- rep(1:5, times = 3)\n\nRipetere ogni elemento di una sequenza:\n\nmy_seq6 &lt;- rep(1:5, each = 3)\nmy_seq6\n#&gt;  [1] 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5\n\n\n\n6.8.5 Annidare funzioni\nÈ possibile combinare funzioni per creare comandi più complessi, come nell’esempio:\n\nmy_seq7 &lt;- rep(c(3, 1, 10, 7), each = 3)\nmy_seq7\n#&gt;  [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\nPer maggiore leggibilità, puoi separare i passaggi:\n\nin_vec &lt;- c(3, 1, 10, 7)\nmy_seq7 &lt;- rep(in_vec, each = 3)\nmy_seq7\n#&gt;  [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\nQuesta pratica facilita la comprensione del codice e lo rende più chiaro.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#lavorare-con-i-vettori-in-r",
    "href": "chapters/R/01_r_syntax.html#lavorare-con-i-vettori-in-r",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.9 Lavorare con i vettori in R",
    "text": "6.9 Lavorare con i vettori in R\nIn R, i vettori sono uno degli elementi fondamentali per manipolare, riassumere e ordinare i dati. Qui trovi una panoramica su come estrarre, sostituire, ordinare, lavorare con dati mancanti e sfruttare la vettorizzazione dei vettori.\n\n6.9.1 Estrarre elementi da un vettore\nPuoi estrarre uno o più elementi da un vettore usando le parentesi quadre [ ].\nPer posizione: Specifica la posizione degli elementi.\n\nmy_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\nmy_vec[3]  # Terzo elemento\n#&gt; [1] 1\n\n\nmy_vec[c(1, 5, 6)]  # Elementi 1°, 5° e 6°\n#&gt; [1] 2 4 3\n\n\nmy_vec[3:8]  # Da 3° a 8°\n#&gt; [1] 1 6 4 3 3 7\n\nCon condizioni logiche: Usa espressioni logiche per selezionare elementi.\n\nmy_vec[my_vec &gt; 4]  # Elementi &gt; 4\n#&gt; [1] 6 7\n\n\nmy_vec[my_vec &lt;= 4]  # Elementi ≤ 4\n#&gt; [1] 2 3 1 4 3 3\n\n\nmy_vec[my_vec != 4]  # Elementi diversi da 4\n#&gt; [1] 2 3 1 6 3 3 7\n\nOperatori logici: Combina condizioni con & (AND) e | (OR).\n\nmy_vec[my_vec &gt; 2 & my_vec &lt; 6]  # Tra 2 e 6\n#&gt; [1] 3 4 3 3\n\n\n\n6.9.2 Sostituire elementi in un vettore\nPuoi modificare i valori di un vettore usando [ ] e l’operatore &lt;-.\nUn singolo elemento:\n\nmy_vec[4] &lt;- 500  # Cambia il 4° elemento\nmy_vec\n#&gt; [1]   2   3   1 500   4   3   3   7\n\nPiù elementi:\n\nmy_vec[c(6, 7)] &lt;- 100  # Cambia il 6° e 7° elemento\nmy_vec\n#&gt; [1]   2   3   1 500   4 100 100   7\n\nCon condizioni logiche:\n\nmy_vec[my_vec &lt;= 4] &lt;- 1000  # Cambia valori ≤ 4\nmy_vec\n#&gt; [1] 1000 1000 1000  500 1000  100  100    7\n\n\n\n6.9.3 Ordinare un vettore\nDal più piccolo al più grande:\n\nvec_sort &lt;- sort(my_vec)\nvec_sort\n#&gt; [1]    7  100  100  500 1000 1000 1000 1000\n\nDal più grande al più piccolo:\n\nvec_sort2 &lt;- sort(my_vec, decreasing = TRUE)\nvec_sort2\n#&gt; [1] 1000 1000 1000 1000  500  100  100    7\n\nOrdinare un vettore in base a un altro:\n\nheight &lt;- c(180, 155, 160, 167, 181)\np.names &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\", \"Karen\", \"Amy\")\nheight_ord &lt;- order(height)\nnames_ord &lt;- p.names[height_ord]\nnames_ord\n#&gt; [1] \"Charlotte\" \"Helen\"     \"Karen\"     \"Joanna\"    \"Amy\"\n\n\n\n6.9.4 Operazioni vettoriali (vettorizzazione)\nLe funzioni in R sono vettorizzate, cioè operano automaticamente su tutti gli elementi di un vettore senza bisogno di un ciclo.\nOperazioni aritmetiche:\n\nmy_vec2 &lt;- c(3, 5, 7, 1, 9, 20)\nmy_vec2 * 5  # Moltiplica ogni elemento per 5\n#&gt; [1]  15  25  35   5  45 100\n\nOperazioni tra vettori:\n\nmy_vec3 &lt;- c(17, 15, 13, 19, 11, 0)\nmy_vec2 + my_vec3  # Somma due vettori\n#&gt; [1] 20 20 20 20 20 20\n\nRiciclo (recycling): Attenzione quando i vettori hanno lunghezze diverse.\n\nmy_vec4 &lt;- c(1, 2)\nmy_vec2 + my_vec4  # R ricicla gli elementi del vettore più corto\n#&gt; [1]  4  7  8  3 10 22\n\n\n\n6.9.5 Gestire dati mancanti (NA)\nR rappresenta i dati mancanti con NA. La gestione dei dati mancanti dipende dalla funzione utilizzata.\nCalcolo con dati mancanti:\n\ntemp &lt;- c(7.2, NA, 7.1, 6.9, 6.5, 5.8, 5.8, 5.5, NA, 5.5)\nmean(temp)  # Restituisce NA\n#&gt; [1] NA\n\n\nmean(temp, na.rm = TRUE)  # Ignora i valori mancanti\n#&gt; [1] 6.2875\n\nNota: na.rm = TRUE è un argomento comune per ignorare i NA, ma non tutte le funzioni lo supportano. Consulta la documentazione della funzione per verificare come gestisce i dati mancanti.\nIn conclusione, manipolare vettori è un’abilità essenziale in R. Dalla selezione e modifica degli elementi all’ordinamento e gestione di dati mancanti, queste tecniche sono alla base dell’analisi dei dati in R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#i-dati-in-r",
    "href": "chapters/R/01_r_syntax.html#i-dati-in-r",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.10 I dati in R",
    "text": "6.10 I dati in R\nIn R, i dati possono essere rappresentati in diversi tipi e strutture. Comprendere come gestirli è fondamentale per manipolare, analizzare e riassumere i dataset più complessi.\n\n6.10.1 Tipi di dati in R\nR supporta diversi tipi di dati:\n\nNumeric: Numeri decimali (es. 2.5).\nInteger: Numeri interi (es. 3).\nLogical: Valori booleani (TRUE o FALSE) e NA per dati mancanti.\nCharacter: Stringhe di testo (es. \"hello\").\nFactor: Variabili categoriche (es. livelli come \"low\", \"medium\", \"high\").\n\nPuoi verificare il tipo di un oggetto con class() e controllare se appartiene a un tipo specifico con funzioni come is.numeric(). È anche possibile convertire un tipo in un altro con funzioni come as.character().\n\n\n6.10.2 Strutture di dati in R\nVettori: Contengono dati dello stesso tipo (es. numeri, stringhe o logici).\n\nmy_vec &lt;- c(1, 2, 3)\nmy_vec\n#&gt; [1] 1 2 3\n\nMatrici e array: Strutture bidimensionali (matrici) o multidimensionali (array) con dati dello stesso tipo.\nCreare una matrice:\n\nmy_mat &lt;- matrix(1:12, nrow = 3, byrow = TRUE)\nmy_mat\n#&gt;      [,1] [,2] [,3] [,4]\n#&gt; [1,]    1    2    3    4\n#&gt; [2,]    5    6    7    8\n#&gt; [3,]    9   10   11   12\n\nOperazioni utili:\n\nTrasposizione: t(my_mat)\nDiagonale: diag(my_mat)\nMoltiplicazione matriciale: mat1 %*% mat2\n\nListe: Possono contenere elementi di tipi diversi, inclusi vettori, matrici o altre liste.\n\nmy_list &lt;- list(\n  numbers = c(1, 2), \n  text = \"hello\", \n  mat = matrix(1:4, nrow = 2)\n)\nmy_list$numbers  # Accedi agli elementi con il nome\n#&gt; [1] 1 2\n\nData frame: Strutture bidimensionali che possono contenere colonne di tipi diversi. Ideale per dataset strutturati.\nCreare un data frame:\n\nheight &lt;- c(180, 155, 160)\nweight &lt;- c(65, 50, 52)\nnames &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\")\n\ndataf &lt;- data.frame(height = height, weight = weight, names = names)\nstr(dataf)  # Mostra la struttura del data frame\n#&gt; 'data.frame':    3 obs. of  3 variables:\n#&gt;  $ height: num  180 155 160\n#&gt;  $ weight: num  65 50 52\n#&gt;  $ names : chr  \"Joanna\" \"Charlotte\" \"Helen\"\n\nPer convertire le stringhe in fattori durante la creazione:\n\ndataf &lt;- data.frame(\n  height = height, \n  weight = weight, \n  names = names, \n  stringsAsFactors = TRUE\n)\n\ndataf\n#&gt;   height weight     names\n#&gt; 1    180     65    Joanna\n#&gt; 2    155     50 Charlotte\n#&gt; 3    160     52     Helen\n\n\n\n6.10.3 Operazioni utili sui data frame\n\nVerificare dimensioni: dim(dataf)\nVisualizzare struttura: str(dataf)\nAccedere a colonne: dataf$height",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#operazioni-di-base-in-r",
    "href": "chapters/R/01_r_syntax.html#operazioni-di-base-in-r",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.11 Operazioni di Base in R",
    "text": "6.11 Operazioni di Base in R\n\n6.11.1 Operazioni Aritmetiche\nR supporta le classiche operazioni aritmetiche come somma (+), sottrazione (-), moltiplicazione (*), divisione (/) ed esponenziazione (^).\n\n# Somma\n3 + 2\n#&gt; [1] 5\n# Moltiplicazione\n3 * 2\n#&gt; [1] 6\n\n\n\n6.11.2 Operazioni Logiche\nLe operazioni logiche in R includono:\n\n&: “and” logico\n\n|: “or” logico\n\n!: “not” logico\n\n&gt;: maggiore di\n\n&lt;: minore di\n\n==: uguale a\n\n!=: diverso da\n\nEsempi:\n\n# Maggiore di\n3 &gt; 2\n#&gt; [1] TRUE\n# Uguale a\n3 == 2\n#&gt; [1] FALSE",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#estrazione-di-sottoinsiemi-di-oggetti-in-r",
    "href": "chapters/R/01_r_syntax.html#estrazione-di-sottoinsiemi-di-oggetti-in-r",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.12 Estrazione di Sottoinsiemi di Oggetti in R",
    "text": "6.12 Estrazione di Sottoinsiemi di Oggetti in R\nIn R esistono tre operatori principali per estrarre sottoinsiemi di oggetti:\n\nOperatore [ ]\nQuesto operatore restituisce sempre un oggetto della stessa classe dell’originale. È utile per selezionare più elementi da un oggetto. È importante chiudere l’estrazione con ].\nOperatore [[ ]]\nQuesto operatore viene utilizzato per estrarre elementi da liste o data frame. A differenza di [ ], permette di estrarre un solo elemento alla volta e la classe dell’oggetto restituito non sarà necessariamente una lista o un data frame. L’estrazione va chiusa con ]].\nOperatore $\nCome visto in precedenza, questo operatore serve per estrarre elementi da una lista o un data frame utilizzando il loro nome letterale. Il comportamento semantico è simile a quello di [[ ]].\n\n\n6.12.1 Esempi Pratici\nSelezione di colonne in un data frame:\n\niris[, 1:3] |&gt; head()\n#&gt;   Sepal.Length Sepal.Width Petal.Length\n#&gt; 1          5.1         3.5          1.4\n#&gt; 2          4.9         3.0          1.4\n#&gt; 3          4.7         3.2          1.3\n#&gt; 4          4.6         3.1          1.5\n#&gt; 5          5.0         3.6          1.4\n#&gt; 6          5.4         3.9          1.7\n\nRestituisce le prime tre colonne del dataset iris.\nSelezione di colonne specifiche per nome:\n\niris[, c('Sepal.Length', 'Petal.Length')] |&gt; \n  head()  # Nomi delle colonne\n#&gt;   Sepal.Length Petal.Length\n#&gt; 1          5.1          1.4\n#&gt; 2          4.9          1.4\n#&gt; 3          4.7          1.3\n#&gt; 4          4.6          1.5\n#&gt; 5          5.0          1.4\n#&gt; 6          5.4          1.7\n\nSelezione di una singola colonna:\n\niris[, 'Petal.Length'] |&gt; head()\n#&gt; [1] 1.4 1.4 1.3 1.5 1.4 1.7\n\nSelezione di righe specifiche:\n\niris[c(1, 3), ]\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\n\nRestituisce le righe 1 e 3.\nFiltraggio logico di righe:\n\niris[iris$Species == 'versicolor', ] |&gt; head()\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; 51          7.0         3.2          4.7         1.4 versicolor\n#&gt; 52          6.4         3.2          4.5         1.5 versicolor\n#&gt; 53          6.9         3.1          4.9         1.5 versicolor\n#&gt; 54          5.5         2.3          4.0         1.3 versicolor\n#&gt; 55          6.5         2.8          4.6         1.5 versicolor\n#&gt; 56          5.7         2.8          4.5         1.3 versicolor\n\nRestituisce le righe con Species uguale a “versicolor”. Numero di righe e colonne del sottoinsieme:\n\ndim(iris[iris$Species == 'versicolor', ])\n#&gt; [1] 50  5\n\n\n\n6.12.2 Filtraggio Avanzato con Operatori Logici\nGli operatori logici & (AND), | (OR) e ! (NOT) permettono un filtraggio più sofisticato.\nEsempio: Filtrare le osservazioni di specie “versicolor” con lunghezza del sepalo non superiore a 5.0:\n\niris[(iris$Species == 'versicolor') & (iris$Sepal.Length &lt;= 5.0), ]\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; 58          4.9         2.4          3.3           1 versicolor\n#&gt; 61          5.0         2.0          3.5           1 versicolor\n#&gt; 94          5.0         2.3          3.3           1 versicolor\n\nNumero di osservazioni trovate:\n\ndim(iris[(iris$Species == 'versicolor') & (iris$Sepal.Length &lt;= 5.0), ])\n#&gt; [1] 3 5",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#riflessioni-conclusive",
    "href": "chapters/R/01_r_syntax.html#riflessioni-conclusive",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.13 Riflessioni Conclusive",
    "text": "6.13 Riflessioni Conclusive\nR non è soltanto un linguaggio di programmazione per la statistica, ma rappresenta una filosofia che si fonda su tre principi chiave: apertura, collaborazione e avanzamento della conoscenza scientifica.\nPer chi si avvicina a R, sia nel campo della comunicazione sia in altri ambiti, cogliere questa filosofia è essenziale per apprezzarne appieno il valore. R promuove non solo competenze tecniche, ma anche un impegno verso pratiche di ricerca trasparente e riproducibile, che costituiscono un pilastro fondamentale per una scienza rigorosa e affidabile.\n\n6.13.1 La Filosofia di R\nOpen Source\nR è un software open source, liberamente accessibile a tutti. Questo significa che chiunque può visualizzarne, modificarne e distribuirne il codice sorgente, promuovendo un ambiente trasparente e collaborativo. Essendo gratuito, R garantisce accessibilità a ricercatori di tutto il mondo, indipendentemente dal budget o dal supporto istituzionale. Inoltre, grazie alla sua natura aperta, R beneficia del contributo collettivo di una comunità globale eterogenea.\nContributi della Comunità\nLa comunità di R è uno dei suoi punti di forza principali. Statistici, ricercatori e data scientist di diverse discipline arricchiscono continuamente R sviluppando pacchetti: raccolte di funzioni, dati e codice che ampliano le sue funzionalità. Questa collaborazione ha portato alla creazione di migliaia di pacchetti che coprono tecniche statistiche, metodi grafici e strumenti per la manipolazione dei dati, rendendo R uno strumento sempre più versatile e adatto a un’ampia gamma di esigenze di ricerca.\n\n\n6.13.2 La Ricerca Riproducibile e il Ruolo di R\nLa ricerca riproducibile consiste nel condurre studi in modo tale che altri possano replicarne i risultati utilizzando gli stessi dati e seguendo la stessa metodologia. Questo approccio è cruciale per la validazione delle scoperte scientifiche, permettendo la verifica dei risultati e la costruzione di nuove conoscenze su basi solide.\nR facilita la ricerca riproducibile grazie a:\n\nUn ecosistema completo di pacchetti per l’analisi dei dati e la generazione di report dinamici.\n\nStrumenti come R Markdown e Quarto, che permettono di integrare testo descrittivo e codice R in un unico documento. Questa integrazione consente di documentare ogni fase del processo di ricerca—dalla pulizia dei dati all’analisi e alla presentazione dei risultati—garantendo trasparenza e replicabilità.\n\nIn conclusione, comprendere la filosofia open source di R e il suo ruolo nella promozione della ricerca riproducibile fornisce un quadro chiaro del motivo per cui R è diventato uno strumento essenziale per ricercatori e statistici di diverse discipline. Per chi opera in psicologia, sfruttare le potenzialità di R significa produrre risultati di ricerca più trasparenti, replicabili e credibili, contribuendo alla robustezza e affidabilità della conoscenza scientifica nel settore.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/01_r_syntax.html#informazioni-sullambiente-di-sviluppo",
    "title": "6  Introduzione a R e RStudio",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.0       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1 \n#&gt; [37] cli_3.6.3         magrittr_2.0.3    utf8_1.2.4        broom_1.0.7      \n#&gt; [41] withr_3.0.2       backports_1.5.0   promises_1.3.1    timechange_0.3.0 \n#&gt; [45] rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3         shiny_1.9.1      \n#&gt; [49] evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [53] xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#bibliografia",
    "href": "chapters/R/01_r_syntax.html#bibliografia",
    "title": "6  Introduzione a R e RStudio",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nNosek, B. A., Hardwicke, T. E., Moshontz, H., Allard, A., Corker, K. S., Dreber, A., Fidler, F., Hilgard, J., Kline Struhl, M., Nuijten, M. B., et al. (2022). Replicability, robustness, and reproducibility in psychological science. Annual Review of Psychology, 73(1), 719–748.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html",
    "href": "chapters/R/02_r_programming.html",
    "title": "7  Programmazione in R",
    "section": "",
    "text": "7.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nIn questo capitolo esploreremo tre strumenti fondamentali per la scrittura di codice in R: le funzioni, le istruzioni condizionali e i cicli. Questi elementi costituiscono la base per sviluppare script flessibili, efficienti e riutilizzabili, essenziali per ogni programmatore o analista che utilizza R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#funzioni",
    "href": "chapters/R/02_r_programming.html#funzioni",
    "title": "7  Programmazione in R",
    "section": "7.2 Funzioni",
    "text": "7.2 Funzioni\nR mette a disposizione una vasta gamma di funzioni integrate per l’analisi statistica, la manipolazione dei dati e la visualizzazione grafica.\nEsempi di funzioni comuni:\n\n# Sommare numeri\nsum(1, 2, 3)\n#&gt; [1] 6\n\n\n# Creare un grafico\nplot(1:10, 1:10)\n\n\n\n\n\n\n\n\nIn sintesi, una funzione è un blocco di codice progettato per eseguire un’operazione specifica. Puoi immaginarla come una “macchina”: fornisci un input, la funzione elabora i dati e restituisce un output.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#creare-funzioni-personalizzate",
    "href": "chapters/R/02_r_programming.html#creare-funzioni-personalizzate",
    "title": "7  Programmazione in R",
    "section": "7.3 Creare Funzioni Personalizzate",
    "text": "7.3 Creare Funzioni Personalizzate\nLa creazione di funzioni personalizzate in R rappresenta uno strumento fondamentale per migliorare il processo di programmazione, in particolare quando si tratta di operazioni ripetitive. Le funzioni consentono di rendere il codice più leggibile, efficiente e facile da riutilizzare, contribuendo a una gestione più organizzata e chiara delle operazioni da svolgere.\nUtilizzare funzioni personalizzate porta diversi vantaggi.\n\nIn primo luogo, permette di assegnare un nome descrittivo al blocco di codice che rappresenta l’operazione. Questo rende più intuitivo comprendere cosa fa la funzione, anche a distanza di tempo o per chiunque non abbia scritto originariamente il codice.\nIn secondo luogo, le funzioni facilitano la manutenzione: eventuali modifiche possono essere apportate in un unico punto, evitando di dover aggiornare manualmente tutte le occorrenze del codice e riducendo così il rischio di errori.\nUn ulteriore vantaggio consiste nella prevenzione degli errori tipici del copia-e-incolla, un approccio che può introdurre inconsistenze o dimenticanze nei programmi più complessi.\nInfine, le funzioni personalizzate favoriscono il riutilizzo del codice, rendendolo applicabile in più progetti o contesti senza la necessità di riscriverlo ogni volta.\n\nÈ importante sapere quando è opportuno scrivere una funzione. Una buona regola pratica è questa: se hai copiato e incollato lo stesso blocco di codice più di due volte, probabilmente è il momento di considerare la creazione di una funzione. Questo approccio permette di semplificare il lavoro e di costruire codice più pulito, scalabile e professionale. Creare una funzione non è solo un esercizio di programmazione, ma una scelta strategica per gestire il lavoro in modo più efficace e sostenibile nel lungo periodo.\n\n7.3.1 Sintassi di una Funzione\nLa struttura di una funzione in R è la seguente:\nnome_funzione &lt;- function(argomenti) {\n  # Corpo della funzione\n  codice\n  risultato\n}\n\nnome_funzione: Nome descrittivo della funzione.\n\nargomenti: I parametri che la funzione utilizza.\n\ncodice: Le operazioni che la funzione esegue.\n\nrisultato: Il valore restituito dalla funzione (se non specificato, R restituisce l’ultimo valore calcolato).\n\n\nEsempio 7.1 Supponiamo di voler creare una funzione che sommi due numeri:\n\nsomma_due &lt;- function(a, b) {\n    a + b\n}\n\nPer utilizzarla:\n\nsomma_due(5, 3)\n#&gt; [1] 8\n\n\nQuesto approccio permette di scrivere codice più organizzato, comprensibile e facile da gestire.\n\n\n7.3.2 Tre Tipi di Funzioni\nSeguendo Wickham et al. (2023), esaminiamo tre tipi di funzioni:\n\nFunzioni per vettori: accettano uno o più vettori come input e restituiscono un vettore.\nFunzioni per data frame: accettano un data frame e restituiscono un altro data frame.\nFunzioni per grafici: accettano un data frame e restituiscono un grafico.\n\n\n7.3.2.1 Funzioni per Vettori\nSupponiamo di voler riscalare i valori di diverse colonne di un data frame tra 0 e 1. Scriviamo la funzione rescale01. La funzione seguente riscalerà un vettore tra 0 e 1:\n\nrescale01 &lt;- function(x) {\n    rng &lt;- range(x, na.rm = TRUE)\n    (x - rng[1]) / (rng[2] - rng[1])\n}\n\n\nEsempio 7.2  \n\ndf &lt;- tibble(\n    x = c(3, 2, 6, 3, 1),\n    y = c(2, 3, 3, 2, 5),\n    grp = c(\"a\", \"a\", \"b\", \"b\", \"a\")\n)\n\ndf |&gt;\n    mutate(across(where(is.numeric), rescale01))\n#&gt; # A tibble: 5 × 3\n#&gt;       x     y grp  \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1   0.4 0     a    \n#&gt; 2   0.2 0.333 a    \n#&gt; 3   1   0.333 b    \n#&gt; 4   0.4 0     b    \n#&gt; 5   0   1     a\n\n\n\n\n7.3.2.2 Funzioni per Data Frame\nPoniamoci il problema di creare una funzione per riassumere variabili. Un esempio di funzione che calcola statistiche di base:\n\nsummary_stats &lt;- function(data, var) {\n    data |&gt; summarize(\n        min = min({{ var }}, na.rm = TRUE),\n        mean = mean({{ var }}, na.rm = TRUE),\n        max = max({{ var }}, na.rm = TRUE),\n        .groups = \"drop\"\n    )\n}\n\n\nEsempio 7.3  \n\nsummary_stats(df, x)\n#&gt; # A tibble: 1 × 3\n#&gt;     min  mean   max\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     3     6\n\nSi noti la selezione dinamica con {} (embracing). Se devi passare nomi di variabili come argomenti, usa { }:\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n    df |&gt;\n        group_by({{ group_var }}) |&gt;\n        summarize(mean = mean({{ mean_var }}, na.rm = TRUE))\n}\n\n\ngrouped_mean(df, grp, y)\n#&gt; # A tibble: 2 × 2\n#&gt;   grp    mean\n#&gt;   &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 a      3.33\n#&gt; 2 b      2.5\n\n\n\n\n7.3.2.3 Funzioni per Grafici\nCreare un istogramma personalizzato.\n\nmy_histogram &lt;- function(df, var, binwidth = NULL) {\n    df |&gt;\n        ggplot(aes(x = {{ var }})) +\n        geom_histogram(binwidth = binwidth)\n}\n\n\nEsempio 7.4  \n\ndiamonds |&gt;\n    my_histogram(carat, 0.1)\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.3 Stile e Nomenclatura\nÈ consigliato di usare nomi di funzioni chiari e descrittivi, preferibilmente verbi (es. compute_mean()). Inoltre, è importante mantenere una struttura leggibile, con spazi coerenti e indentazione.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#istruzioni-condizionali-in-r",
    "href": "chapters/R/02_r_programming.html#istruzioni-condizionali-in-r",
    "title": "7  Programmazione in R",
    "section": "7.4 Istruzioni Condizionali in R",
    "text": "7.4 Istruzioni Condizionali in R\nLe istruzioni condizionali permettono di introdurre logica nel tuo codice. Ad esempio, l’operazione x * y si limita a moltiplicare i valori di x e y, senza alcuna logica aggiunta. Con le istruzioni condizionali, puoi dire al programma di eseguire diverse operazioni a seconda che una condizione sia vera (TRUE) o falsa (FALSE).\nL’istruzione condizionale più comune in R è if. Può essere letta come: “Se la condizione è vera, esegui un’azione”. Con else, si estende la logica: “Se la condizione è vera, fai qualcosa; altrimenti fai qualcos’altro”.\nLa struttura generale è questa:\nif (condizione) {\n  # Codice eseguito se la condizione è TRUE\n} else {\n  # Codice eseguito se la condizione è FALSE\n}\nImmagina questa situazione:\n\nUn programmatore riceve la richiesta: “Vai al negozio e compra una confezione di latte, e se hanno le uova, prendi sei confezioni di latte”.\nIl programmatore torna con sei confezioni di latte.\nIl partner chiede: “Perché hai comprato sei confezioni di latte?”\nRisposta: “Perché c’erano le uova”.\n\nIl problema qui sta nell’interpretazione condizionale: se ci sono uova (condizione vera), si doveva prendere una confezione di latte e anche sei uova.\nIn R, questo può essere scritto così:\n\neggs &lt;- TRUE # Indica se il negozio ha le uova\n\nif (eggs == TRUE) {\n    n_milk &lt;- 6 # Prendi 6 confezioni di latte\n} else {\n    n_milk &lt;- 1 # Prendi 1 confezione di latte\n}\n\nn_milk\n#&gt; [1] 6\n\nQuesto codice però ha lo stesso errore della barzelletta: il focus è sul latte, non sulle uova.\n\n7.4.1 Uso di ifelse()\nUn’alternativa più compatta a if e else è la funzione ifelse(), utile soprattutto per vettori. Ad esempio:\n\neggs &lt;- TRUE\nn_milk &lt;- ifelse(eggs == TRUE, yes = 6, no = 1)\n\nn_milk\n#&gt; [1] 6\n\nLa logica è: “Se ci sono uova, assegna 6 a n_milk; altrimenti assegna 1”. Questo approccio è utile per evitare codice ripetitivo.\n\n\n7.4.2 Creare una funzione con istruzioni condizionali\nLe istruzioni condizionali possono essere racchiuse in una funzione per rendere il codice più flessibile e riutilizzabile. Ecco come trasformare l’esempio sopra in una funzione:\n\nmilk &lt;- function(eggs) {\n    if (eggs == TRUE) {\n        6\n    } else {\n        1\n    }\n}\n\nmilk(eggs = TRUE)\n#&gt; [1] 6\n\nOra possiamo chiamare la funzione con eggs = TRUE o eggs = FALSE per determinare quante confezioni di latte prendere.\nIn conclusione, le istruzioni condizionali come if, else e ifelse() sono strumenti fondamentali per introdurre logica e controllo nel tuo codice. Puoi usarle per prendere decisioni, gestire errori e rendere il tuo codice più flessibile ed efficiente. Creare funzioni che incorporano queste istruzioni è un passo fondamentale per scrivere codice ordinato e riutilizzabile.\n\n\n7.4.3 Combinare operatori logici in R\nFinora abbiamo creato funzioni abbastanza semplici e mirate. Ora proviamo a realizzare una funzione leggermente più complessa. Immaginiamo di voler determinare se una persona ha avuto una buona giornata basandoci su due criteri:\n\nLivello di stress: basso (TRUE) o alto (FALSE).\nLivello di supporto sociale percepito: alto (TRUE) o basso (FALSE).\n\nVogliamo creare una funzione che prenda questi due fattori e restituisca un messaggio che descrive come potrebbe essere stata la giornata della persona.\nEcco come possiamo costruire la funzione:\n\ngood_day &lt;- function(low_stress, high_support) {\n    if (low_stress == TRUE && high_support == TRUE) {\n        \"Giornata fantastica! Ti senti calmo e supportato.\"\n    } else if (low_stress == FALSE && high_support == TRUE) {\n        \"Il supporto sociale ti aiuta a gestire lo stress elevato.\"\n    } else if (low_stress == TRUE && high_support == FALSE) {\n        \"Nonostante lo stress sia basso, la mancanza di supporto sociale pesa.\"\n    } else if (low_stress == FALSE && high_support == FALSE) {\n        \"Giornata difficile: stress elevato e poco supporto sociale.\"\n    }\n}\n\nEsempi di utilizzo\nCaso 1: Stress basso e supporto sociale alto\n\ngood_day(low_stress = TRUE, high_support = TRUE)\n#&gt; [1] \"Giornata fantastica! Ti senti calmo e supportato.\"\n\nCaso 2: Stress elevato e supporto sociale alto.\n\ngood_day(FALSE, TRUE)\n#&gt; [1] \"Il supporto sociale ti aiuta a gestire lo stress elevato.\"\n\nCaso 3: Stress basso e supporto sociale basso.\n\ngood_day(TRUE, FALSE)\n#&gt; [1] \"Nonostante lo stress sia basso, la mancanza di supporto sociale pesa.\"\n\nCaso 4: Stress elevato e supporto sociale basso.\n\ngood_day(FALSE, FALSE)\n#&gt; [1] \"Giornata difficile: stress elevato e poco supporto sociale.\"\n\nLa funzione considera tutte le combinazioni di stress e supporto sociale:\n\nStress basso e supporto alto: giornata ideale.\nStress elevato e supporto alto: il supporto aiuta a mitigare lo stress.\nStress basso e supporto basso: la mancanza di supporto rovina una situazione potenzialmente buona.\nStress elevato e supporto basso: la situazione peggiore.\n\nNell’esempio abbiamo usato i seguenti operatori logici:\n\n&& (AND logico): Entrambe le condizioni devono essere vere.\n== (uguale a): Verifica se una variabile è vera o falsa.\n\nAd esempio, questa condizione:\nif (low_stress == TRUE && high_support == TRUE)\nverifica se il livello di stress è basso e il supporto sociale è alto.\nIn conclusione, questa funzione dimostra come combinare condizioni logiche complesse utilizzando operatori logici come && (AND) e || (OR). Grazie a questi strumenti, possiamo gestire facilmente logiche più articolate, mantenendo il codice leggibile e funzionale.\n\n\n7.4.4 Gli operatori logici in R\nGli operatori logici sono essenziali per definire le condizioni nelle istruzioni if. Ecco una tabella riassuntiva con i principali operatori:\n\n\n\n\n\n\n\n\n\nOperatore\nDescrizione tecnica\nSignificato\nEsempio\n\n\n\n\n&&\nAND logico\nEntrambe le condizioni devono essere vere\nif(cond1 == test && cond2 == test)\n\n\n||\nOR logico\nAlmeno una condizione deve essere vera\nif(cond1 == test || cond2 == test)\n\n\n&lt;\nMinore di\nX è minore di Y\nif(X &lt; Y)\n\n\n&gt;\nMaggiore di\nX è maggiore di Y\nif(X &gt; Y)\n\n\n&lt;=\nMinore o uguale a\nX è minore o uguale a Y\nif(X &lt;= Y)\n\n\n&gt;=\nMaggiore o uguale a\nX è maggiore o uguale a Y\nif(X &gt;= Y)\n\n\n==\nUguale a\nX è uguale a Y\nif(X == Y)\n\n\n!=\nDiverso da\nX è diverso da Y\nif(X != Y)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#cicli-in-r",
    "href": "chapters/R/02_r_programming.html#cicli-in-r",
    "title": "7  Programmazione in R",
    "section": "7.5 Cicli in R",
    "text": "7.5 Cicli in R\nR è particolarmente efficace nell’eseguire attività ripetitive. Quando dobbiamo ripetere un’operazione più volte, possiamo utilizzare un ciclo. I cicli eseguono un insieme di istruzioni per un numero specifico di volte o fino a quando una determinata condizione non è soddisfatta.\nIn R esistono tre tipi principali di cicli:\n\nCiclo for: ripete un’operazione per un numero definito di iterazioni.\nCiclo while: continua a eseguire le istruzioni fino a quando una condizione logica è soddisfatta.\nCiclo repeat: itera indefinitamente fino a quando non viene esplicitamente interrotto con un’istruzione break.\n\nI cicli sono strumenti essenziali in tutti i linguaggi di programmazione, ma in R il loro utilizzo dovrebbe essere valutato attentamente, poiché spesso esistono alternative più efficienti come le funzioni della famiglia apply.\n\n7.5.1 Il ciclo for\nIl ciclo for è il più utilizzato per eseguire un’operazione un numero definito di volte. Ecco un esempio base:\n\nfor (i in 1:5) {\n    print(i)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nCome funziona?\n\nL’indice i prende il primo valore della sequenza 1:5 (cioè 1).\nIl corpo del ciclo, ovvero il codice tra { }, viene eseguito.\nAl termine di ogni iterazione, i assume il valore successivo nella sequenza, e il processo si ripete fino all’ultimo valore (5 in questo caso).\n\nAggiungere logica nel corpo del ciclo\nPossiamo aggiungere operazioni all’interno del ciclo, come ad esempio sommare 1 a ogni valore:\n\nfor (i in 1:5) {\n    print(i + 1)\n}\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n#&gt; [1] 6\n\n\n\n7.5.2 Il ciclo while\nIl ciclo while continua a eseguire le istruzioni fino a quando una condizione logica è soddisfatta. Ecco un esempio:\n\ni &lt;- 0\nwhile (i &lt;= 4) {\n    i &lt;- i + 1\n    print(i)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nCome funziona?\n\nLa condizione logica (i &lt;= 4) viene verificata prima di ogni iterazione.\nSe la condizione è vera, il ciclo esegue il codice tra { }.\nQuando la condizione diventa falsa (i &gt; 4), il ciclo si interrompe.\n\n\n\n7.5.3 Ciclo repeat\nIl ciclo repeat esegue il codice indefinitamente, a meno che non venga interrotto con un’istruzione break:\n\ni &lt;- 0\nrepeat {\n    i &lt;- i + 1\n    print(i)\n    if (i &gt;= 5) {\n        break\n    }\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nQuando usarlo?\nIl ciclo repeat è raro e viene utilizzato solo in situazioni molto particolari. Nella maggior parte dei casi, for o while sono più adatti.\n\n\n7.5.4 Evitare i cicli: la famiglia di funzioni apply\nI cicli in R sono relativamente lenti, specialmente con dataset di grandi dimensioni. Quando possibile, è preferibile usare funzioni della famiglia apply per ottenere lo stesso risultato in modo più efficiente e con meno rischi di errore.\n\n7.5.4.1 La funzione lapply()\nlapply() esegue una funzione su ciascun elemento di una lista o vettore e restituisce una lista con i risultati.\nEsempio:\n\nlapply(0:4, function(a) {\n    a + 1\n})\n#&gt; [[1]]\n#&gt; [1] 1\n#&gt; \n#&gt; [[2]]\n#&gt; [1] 2\n#&gt; \n#&gt; [[3]]\n#&gt; [1] 3\n#&gt; \n#&gt; [[4]]\n#&gt; [1] 4\n#&gt; \n#&gt; [[5]]\n#&gt; [1] 5\n\n\n\n7.5.4.2 La funzione sapply()\nlapply() restituisce una lista, ma se vuoi un vettore come output, usa sapply():\n\nsapply(0:4, function(a) {\n    a + 1\n})\n#&gt; [1] 1 2 3 4 5\n\n\n\n\n7.5.5 Quando usare i cicli?\nI cicli sono utili quando:\n\nDevi simulare modelli complessi (es. modelli ricorsivi).\nHai bisogno di operazioni che dipendono dai risultati delle iterazioni precedenti.\n\nIn tutti gli altri casi, considera alternative come apply(), lapply() o funzioni simili per un codice più efficiente e meno soggetto a errori.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#riflessioni-conclusive",
    "href": "chapters/R/02_r_programming.html#riflessioni-conclusive",
    "title": "7  Programmazione in R",
    "section": "7.6 Riflessioni Conclusive",
    "text": "7.6 Riflessioni Conclusive\nScrivere funzioni è un passaggio essenziale per migliorare la leggibilità, l’efficienza e la riutilizzabilità del codice. Funzioni ben progettate semplificano le modifiche, riducono errori e rendono il lavoro più chiaro, sia per te stesso che per i collaboratori futuri. Se trovi che stai copiando e incollando codice più volte, è il momento di pensare a creare una funzione.\nLe istruzioni condizionali, come if, else e ifelse(), sono fondamentali per introdurre logica e controllo nel codice. Permettono di gestire scenari diversi e prendere decisioni dinamiche, migliorando la flessibilità e l’efficienza dei tuoi script. Combinando queste istruzioni con operatori logici come && e ||, puoi affrontare situazioni complesse con un codice chiaro e leggibile.\nI cicli sono potenti strumenti per eseguire operazioni ripetitive, ma in R il loro utilizzo dovrebbe essere limitato ai casi in cui non esistono alternative più efficienti. Le funzioni apply() e simili rappresentano spesso un’opzione migliore per manipolare dati in modo più rapido e leggibile.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/02_r_programming.html#informazioni-sullambiente-di-sviluppo",
    "title": "7  Programmazione in R",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.0       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] labeling_0.4.3    rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [37] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    utf8_1.2.4       \n#&gt; [41] broom_1.0.7       withr_3.0.2       backports_1.5.0   promises_1.3.1   \n#&gt; [45] timechange_0.3.0  rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3        \n#&gt; [49] shiny_1.9.1       evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4      \n#&gt; [53] Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9   \n#&gt; [57] R6_2.5.1",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#bibliografia",
    "href": "chapters/R/02_r_programming.html#bibliografia",
    "title": "7  Programmazione in R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_packages.html",
    "href": "chapters/R/03_r_packages.html",
    "title": "8  Pacchetti in R",
    "section": "",
    "text": "8.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nI pacchetti R sono estensioni del linguaggio di programmazione statistica R. Questi pacchetti forniscono una raccolta di risorse che possono essere utilizzate per ampliare le funzionalità di base di R. Ogni pacchetto generalmente include:\nI pacchetti R sono distribuiti e installati attraverso repository centralizzati, il più noto dei quali è CRAN (Comprehensive R Archive Network). CRAN garantisce la qualità e l’affidabilità dei pacchetti, sottoponendoli a controlli rigorosi prima della pubblicazione.\nLa vasta disponibilità di pacchetti è una delle ragioni principali della popolarità di R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_packages.html#introduzione",
    "href": "chapters/R/03_r_packages.html#introduzione",
    "title": "8  Pacchetti in R",
    "section": "",
    "text": "Codice: funzioni e script scritti in R (e talvolta in altri linguaggi come C++ o Fortran) che implementano specifiche analisi o strumenti.\nDati: dataset di esempio o utili per testare e dimostrare le funzionalità del pacchetto.\nDocumentazione: file descrittivi che spiegano come utilizzare il pacchetto, spesso in formato manuale o vignette (tutorial pratici).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_packages.html#installare-i-pacchetti-r",
    "href": "chapters/R/03_r_packages.html#installare-i-pacchetti-r",
    "title": "8  Pacchetti in R",
    "section": "8.2 Installare i Pacchetti R",
    "text": "8.2 Installare i Pacchetti R\nQuando installi R, vengono installati automaticamente alcuni pacchetti base. Tuttavia, hai la possibilità di aggiungere ulteriori pacchetti che trovi utili per i tuoi scopi. Questi pacchetti sono memorizzati sui server di R (mirror), e l’installazione di un nuovo pacchetto richiede una connessione internet al mirror CRAN che hai scelto durante l’installazione di R.\nPer installare un pacchetto, utilizza il comando:\ninstall.packages(\"&lt;nome_pacchetto&gt;\")\nSostituisci &lt;nome_pacchetto&gt; con il nome del pacchetto che desideri installare. Ad esempio, se vuoi installare il pacchetto rio (utile per importare i dati in R), puoi digitare:\ninstall.packages(\"rio\")   # Non dimenticare le virgolette!",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_packages.html#caricamento-di-un-pacchetto",
    "href": "chapters/R/03_r_packages.html#caricamento-di-un-pacchetto",
    "title": "8  Pacchetti in R",
    "section": "8.3 Caricamento di un pacchetto",
    "text": "8.3 Caricamento di un pacchetto\nOgni volta che avvii una nuova sessione di R, se desideri utilizzare un pacchetto, devi caricarlo manualmente. Questo si fa con il comando library(). Ad esempio, dopo aver installato rio, per utilizzarlo digita:\nlibrary(rio)   # Nota: le virgolette non sono necessarie, ma puoi usarle se preferisci.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_packages.html#utilizzo-delle-funzioni-di-un-pacchetto-senza-caricarlo",
    "href": "chapters/R/03_r_packages.html#utilizzo-delle-funzioni-di-un-pacchetto-senza-caricarlo",
    "title": "8  Pacchetti in R",
    "section": "8.4 Utilizzo delle funzioni di un pacchetto senza caricarlo",
    "text": "8.4 Utilizzo delle funzioni di un pacchetto senza caricarlo\nSe hai bisogno di utilizzare una funzione specifica di un pacchetto, ma sai che la userai solo una volta, puoi evitare di caricare l’intero pacchetto con library(). Ad esempio, invece di scrivere:\nlibrary(nome_pacchetto)\nfunzione(x = 2, sd = 3)\npuoi accedere direttamente alla funzione usando l’operatore :::\nnome_pacchetto::funzione(x = 2, sd = 3)\nQuesto approccio è utile per funzioni che usi raramente o una sola volta. Personalmente, utilizzo :: anche quando ho già caricato il pacchetto, per ricordare a “me del futuro” da quale pacchetto proviene una determinata funzione. Questo può rendere il codice più leggibile e comprensibile nel tempo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_quarto.html",
    "href": "chapters/R/04_quarto.html",
    "title": "9  Quarto",
    "section": "",
    "text": "9.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nQuarto si inserisce nella tradizione del literate programming, un approccio introdotto da Donald Knuth negli anni ’80. Il literate programming nasce con l’idea di combinare codice e testo descrittivo in un unico documento, rendendo il programma non solo eseguibile ma anche leggibile e comprensibile agli esseri umani. Questo approccio mira a superare la separazione tra codice e documentazione, permettendo di spiegare non solo come un programma funziona, ma anche perché è stato scritto in un certo modo.\nQuesta filosofia è particolarmente rilevante nella scienza dei dati e nell’analisi statistica, dove la riproducibilità e la trasparenza sono fondamentali. In questo contesto, strumenti come Quarto giocano un ruolo chiave, permettendo di integrare codice, risultati e narrazione in un unico documento. Con Quarto, è possibile produrre report, articoli, presentazioni e altri output in diversi formati (HTML, PDF, Word, ecc.), combinando testi interpretativi, risultati numerici e grafici.\nQuarto si distingue per la sua flessibilità e per il supporto a diversi linguaggi di programmazione, tra cui R, Python e Julia. Questo strumento può essere utilizzato in tre modi principali:\nPur non essendo un pacchetto R, Quarto è uno strumento CLI (Command Line Interface). Tuttavia, grazie a RStudio, l’installazione e l’utilizzo di Quarto sono gestiti automaticamente, rendendolo accessibile anche a chi ha meno familiarità con il terminale.\nQuarto rappresenta quindi una naturale evoluzione del concetto di literate programming, combinando praticità e rigore scientifico in un unico ambiente di lavoro.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_quarto.html#introduzione",
    "href": "chapters/R/04_quarto.html#introduzione",
    "title": "9  Quarto",
    "section": "",
    "text": "Presentare conclusioni: condividere i risultati senza esporre il codice sottostante.\nDocumentare il processo analitico: includere sia il codice che i risultati per garantire trasparenza e riproducibilità.\nAnnotare l’analisi: integrare interpretazioni e decisioni prese durante il lavoro analitico.\n\n\n\n\n9.1.1 Creare un documento Quarto\nUn file Quarto ha estensione .qmd e segue questa struttura:\n\nQuesto file include:\n\nUn’intestazione YAML (metadati del documento).\nBlocchi di codice delimitati da ```.\nTesto scritto in Markdown con formattazioni semplici come titoli (# Titolo), corsivi (*testo*), ecc.\n\n\n\n9.1.2 Editor visivo e sorgente\n\nEditor visivo: simile a Google Docs, offre un’interfaccia WYSIWYM (What You See Is What You Mean). Consente di inserire facilmente immagini, tabelle, citazioni e altro.\nEditor sorgente: consente un controllo diretto sul Markdown, utile per debug e personalizzazioni avanzate.\n\n\n\n9.1.3 Blocchi di codice\nI blocchi di codice (chiamati “chunks”) eseguono codice e visualizzano i risultati. Ogni chunk è delimitato da ``` e può includere opzioni specifiche:\n#| label: esempio\n#| echo: false\n1 + 1\nLe opzioni più comuni includono:\n\necho: false (nasconde il codice nel report),\neval: false (non esegue il codice),\nmessage: false e warning: false (nasconde messaggi o avvisi).\n\n\n\n9.1.4 Figure\nLe figure possono essere generate tramite codice (es. ggplot()) o inserite come file esterni. Le opzioni più comuni per il controllo delle dimensioni sono:\n\nfig-width e fig-height (dimensioni della figura in pollici),\nout-width (percentuale di larghezza del documento),\nfig-asp (rapporto d’aspetto, es. 0.618 per il rapporto aureo).\n\nEsempio:\n#| fig-width: 6\nggplot(data, aes(x, y)) + geom_point()\n\n\n9.1.5 Tabelle\nLe tabelle possono essere stampate direttamente o personalizzate con funzioni come knitr::kable() o pacchetti come gt:\n\nknitr::kable(head(mtcars))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\n\n9.1.6 Caching\nPer velocizzare i documenti con calcoli complessi, Quarto supporta la memorizzazione dei risultati:\n\ncache: true salva i risultati di un chunk, evitando di ricalcolarli se il codice non cambia.\ndependson specifica dipendenze tra chunk.\n\n\n\n9.1.7 Citazioni e bibliografie in Quarto\nQuarto supporta la generazione automatica di citazioni e bibliografie in formati personalizzati, come lo stile APA. Per includere riferimenti, è necessario creare un file .bib (ad esempio, references.bib) che contenga le citazioni in formato BibTeX. Puoi ottenere queste citazioni direttamente da Google Scholar o altri database accademici. Ecco un esempio:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect: Evidence from a visual search task},\n  author={Ceccarini, Francesco and Colpizzi, Ilaria and Caudek, Corrado},\n  journal={Psychonomic Bulletin \\& Review},\n  pages={1--10},\n  year={2024},\n  publisher={Springer}\n}\n\n9.1.7.1 Configurazione del file YAML\nNel file .qmd, aggiungi le seguenti righe all’intestazione YAML per collegare il file references.bib e configurare lo stile bibliografico:\nbibliography: references.bib\nbiblio-style: apalike\ncsl: apa.csl\n\nbibliography: specifica il percorso del file .bib (in questo esempio si assume che si trovi nella stessa cartella del file Quarto).\nbiblio-style: imposta lo stile delle citazioni (ad esempio, apalike per uno stile simile all’APA).\ncsl: permette di utilizzare uno stile di citazione personalizzato (es., apa.csl), che puoi scaricare facilmente da siti come Zotero Style Repository.\n\n\n\n9.1.7.2 Citazioni inline\nNel testo del documento .qmd, le citazioni vengono inserite utilizzando il formato @ seguito dal nome identificativo della citazione nel file .bib. Ad esempio:\n... come messo in evidenza da @ceccarini2024age, si può osservare che...\nQuarto genera automaticamente la bibliografia includendo tutti i riferimenti citati nel documento. La bibliografia apparirà alla fine del file renderizzato (ad esempio, HTML o PDF).\nIl presente documento è un file .qmd. Quindi il testo precedente sarà reso nel modo seguente:\n… come messo in evidenza da Ceccarini et al. (2024), si può osservare che…\nSi noti la citazione completa alla fine di questa pagina web.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_quarto.html#riflessioni-conclusive",
    "href": "chapters/R/04_quarto.html#riflessioni-conclusive",
    "title": "9  Quarto",
    "section": "9.2 Riflessioni Conclusive",
    "text": "9.2 Riflessioni Conclusive\nQuarto è uno strumento potente per la creazione di documenti riproducibili e ben strutturati, integrando codice, risultati e testo descrittivo in un unico file. Questa introduzione dovrebbe essere sufficiente per iniziare a lavorare con Quarto, ma c’è ancora molto da imparare. Il modo migliore per rimanere aggiornati è consultare il sito ufficiale di Quarto: https://quarto.org.\nUn argomento importante che non abbiamo trattato qui riguarda i dettagli di come comunicare in modo accurato le proprie idee agli altri. Per migliorare le proprie capacità di scrittura, Wickham et al. (2023) consigliano due libri: Style: Lessons in Clarity and Grace di Joseph M. Williams & Joseph Bizup, e The Sense of Structure: Writing from the Reader’s Perspective di George Gopen. Una serie di brevi articoli sulla scrittura sono offerti da George Gopen e sono disponibili su https://www.georgegopen.com/litigation-articles.html.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_quarto.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/04_quarto.html#informazioni-sullambiente-di-sviluppo",
    "title": "9  Quarto",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.0       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1 \n#&gt; [37] cli_3.6.3         magrittr_2.0.3    utf8_1.2.4        broom_1.0.7      \n#&gt; [41] withr_3.0.2       backports_1.5.0   promises_1.3.1    timechange_0.3.0 \n#&gt; [45] rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3         shiny_1.9.1      \n#&gt; [49] evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [53] xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_quarto.html#bibliografia",
    "href": "chapters/R/04_quarto.html#bibliografia",
    "title": "9  Quarto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCeccarini, F., Colpizzi, I., & Caudek, C. (2024). Age-dependent changes in the anger superiority effect: Evidence from a visual search task. Psychonomic Bulletin & Review, 1–10.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html",
    "href": "chapters/eda/introduction_eda.html",
    "title": "Introduzione",
    "section": "",
    "text": "Dopo aver acquisito un dataset, è fondamentale comprendere a fondo le caratteristiche dei dati in esso contenuti. Sebbene le statistiche descrittive e altre misure numeriche siano spesso efficaci per ottenere una visione d’insieme, talvolta è un’immagine a valere più di mille parole.\nIn questa sezione della dispensa, esploreremo alcuni concetti chiave della statistica descrittiva. Oltre a fornire definizioni teoriche, presenteremo istruzioni pratiche in Python per condurre analisi statistiche su dati reali. Il capitolo si concluderà con una riflessione critica sui limiti di un approccio epistemologico basato esclusivamente sull’analisi delle associazioni tra variabili, evidenziando l’importanza di indagare le cause sottostanti ai fenomeni osservati.",
    "crumbs": [
      "EDA",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html",
    "href": "chapters/eda/01_project_structure.html",
    "title": "10  Le fasi del progetto di analisi dei dati",
    "section": "",
    "text": "10.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nUna gestione accurata ed efficace dei dati è fondamentale, soprattutto in discipline come la psicologia, dove l’analisi di dataset complessi è una componente centrale della ricerca. Assicurare che i dati siano raccolti con precisione, organizzati in modo chiaro e facilmente accessibili per analisi e verifiche è essenziale per preservare l’integrità del lavoro scientifico e promuovere la sua riproducibilità. Una gestione rigorosa dei dati garantisce qualità e affidabilità durante tutte le fasi del progetto, dalla raccolta alla documentazione dei processi di elaborazione e delle eventuali modifiche apportate.\nDati ben organizzati e documentati non solo semplificano e rendono più efficiente il processo di analisi, ma riducono anche il rischio di errori, migliorando l’utilizzabilità e l’interpretazione delle informazioni. Questo aspetto è particolarmente rilevante quando si lavora con dataset provenienti da fonti eterogenee o con strutture complesse. Inoltre, la trasparenza e la completezza nella gestione dei dati rappresentano una condizione imprescindibile per garantire la riproducibilità della ricerca, pilastro fondamentale della scienza.\nLa possibilità per altri ricercatori di replicare i risultati utilizzando gli stessi dati e metodi rafforza la credibilità delle conclusioni e contribuisce a costruire un progresso scientifico condiviso e solido. Una gestione dei dati responsabile, dunque, non è solo una buona pratica, ma una necessità per la produzione di conoscenze affidabili e sostenibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#panoramica-delle-capacità-di-gestione-dei-dati-in-r",
    "href": "chapters/eda/01_project_structure.html#panoramica-delle-capacità-di-gestione-dei-dati-in-r",
    "title": "10  Le fasi del progetto di analisi dei dati",
    "section": "10.2 Panoramica delle Capacità di Gestione dei Dati in R",
    "text": "10.2 Panoramica delle Capacità di Gestione dei Dati in R\nR è uno strumento potente e versatile, progettato per supportare ogni fase del ciclo di vita dei dati, dalla raccolta alla documentazione, rendendolo indispensabile per chiunque lavori con dati complessi.\n\nImportazione ed esportazione dei dati: Con pacchetti come readr e rio, R facilita l’importazione di dati da diverse fonti, tra cui file CSV, database e API web, e consente l’esportazione in formati adatti a diversi utilizzi.\nPulizia e preparazione dei dati: Pacchetti come dplyr, tidyr e stringr offrono strumenti intuitivi e potenti per manipolare, trasformare e preparare i dati in modo efficiente, rendendoli pronti per l’analisi.\nEsplorazione e sintesi: R, attraverso pacchetti come dplyr e ggplot2, permette di calcolare statistiche descrittive, individuare pattern significativi e visualizzare distribuzioni e relazioni in modo chiaro e informativo.\nDocumentazione dinamica: Grazie a strumenti come R Markdown e Quarto, è possibile creare documenti interattivi che integrano codice, analisi, testo esplicativo e risultati, promuovendo la riproducibilità e la trasparenza del lavoro.\nControllo delle versioni: L’integrazione di Git in RStudio offre un sistema di gestione delle versioni che consente di monitorare modifiche, collaborare con altri e garantire la tracciabilità del processo analitico.\n\nQueste funzionalità rendono R uno strumento essenziale per gestire i dati in modo organizzato, trasparente e ottimale, facilitando analisi rigorose e riproducibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#configurare-lambiente-r-per-la-gestione-dei-dati",
    "href": "chapters/eda/01_project_structure.html#configurare-lambiente-r-per-la-gestione-dei-dati",
    "title": "10  Le fasi del progetto di analisi dei dati",
    "section": "10.3 Configurare l’Ambiente R per la Gestione dei Dati",
    "text": "10.3 Configurare l’Ambiente R per la Gestione dei Dati\nPer sfruttare al meglio le potenzialità di R, è essenziale configurare correttamente RStudio e integrare i pacchetti fondamentali per la gestione dei dati. Una configurazione adeguata favorisce la riproducibilità e l’organizzazione del lavoro.\n\n10.3.1 Workspace e Cronologia\nAccedi a Tools &gt; Global Options &gt; General e modifica le seguenti impostazioni:\n\nDisabilita l’opzione Restore .RData into workspace at startup.\n\nImposta Save workspace to .RData on exit su Never.\n\nQueste configurazioni incoraggiano una gestione basata sugli script, rendendo il lavoro più trasparente e riducendo conflitti tra sessioni diverse. Ogni analisi sarà così chiaramente documentata nello script, evitando dipendenze da file temporanei o precedenti sessioni.\n\n\n10.3.2 Pacchetti Essenziali\nR è composto da un modulo base che fornisce le funzionalità fondamentali del linguaggio, ma la sua potenza deriva dall’enorme ecosistema di pacchetti aggiuntivi. Questi pacchetti possono essere caricati secondo necessità. Per questo corso, utilizzeremo regolarmente i seguenti pacchetti:\n\nhere: per una gestione ordinata dei percorsi relativi, evitando problemi legati ai percorsi assoluti.\n\ntidyverse: una raccolta di pacchetti per manipolazione, analisi e visualizzazione dei dati, che include dplyr, tidyr, ggplot2 e altri strumenti indispensabili.\n\nAssicurati di installarli e caricarli all’inizio di ogni script con i comandi:\n\n# install.packages(c(\"here\", \"tidyverse\")) # è solo necessario installarli una volta\nlibrary(here)\nlibrary(tidyverse)\n\n\n\n10.3.3 Gestione dei Progetti\nI progetti in RStudio rappresentano uno strumento chiave per mantenere il lavoro organizzato. Utilizzare i progetti consente di lavorare in ambienti separati, dove ogni progetto ha la propria directory dedicata.\nPer creare un nuovo progetto:\n1. Vai su File &gt; New Project.\n2. Seleziona una directory specifica per il progetto.\n3. Salva tutti i file correlati (script, dati, risultati) all’interno della directory del progetto.\nQuesto approccio facilita la navigazione e previene errori derivanti dall’uso di file non correlati. Ogni progetto diventa così un’unità autonoma, ideale per mantenere ordine e coerenza nel lavoro.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#il-ciclo-di-vita-di-un-progetto-di-data-science",
    "href": "chapters/eda/01_project_structure.html#il-ciclo-di-vita-di-un-progetto-di-data-science",
    "title": "10  Le fasi del progetto di analisi dei dati",
    "section": "10.4 Il Ciclo di Vita di un Progetto di Data Science",
    "text": "10.4 Il Ciclo di Vita di un Progetto di Data Science\nSecondo Yu & Barter (2024), i progetti di analisi dei dati seguono solitamente queste fasi:\n\nFormulazione del problema e raccolta dei dati: Definizione delle domande di ricerca e acquisizione dei dataset.\nPulizia, preprocessing e analisi esplorativa: Preparazione dei dati per l’analisi attraverso trasformazioni e sintesi.\nAnalisi predittiva e/o inferenziale: (Opzionale) Modelli statistici o predittivi per rispondere alle domande di ricerca.\nValutazione dei risultati: Interpretazione e verifica delle conclusioni tratte.\nComunicazione dei risultati: Presentazione dei risultati in forma visiva e narrativa.\n\nNon tutti i progetti includono la fase 3, ma quasi tutti attraversano le altre fasi, rendendo essenziale un approccio organizzato e ben strutturato.\n\n10.4.1 Fase 1: Formulazione del Problema e Raccolta dei Dati\nLa formulazione di una domanda di ricerca chiara e precisa è il primo passo per qualsiasi progetto di data science. È fondamentale che la domanda sia costruita in modo tale da poter essere risolta tramite l’analisi dei dati disponibili. Spesso, la domanda iniziale può risultare troppo vaga o irrealizzabile, rendendo necessario un processo di revisione per adattarla alle informazioni a disposizione. Questo approccio assicura che i dati raccolti o utilizzati siano adeguati per rispondere efficacemente al problema di ricerca.\nLa raccolta dei dati rappresenta una fase altrettanto cruciale del processo. In alcuni casi, i progetti sfruttano dati esistenti provenienti da repository pubblici, database interni o esperimenti passati; in altri, è necessaria una nuova raccolta di dati. Per evitare problematiche future, è essenziale pianificare con attenzione le analisi statistiche da effettuare prima di raccogliere i dati. In assenza di questa pianificazione, si rischia di ottenere dataset inadatti, privi di informazioni cruciali o non conformi alle assunzioni richieste dai modelli statistici previsti.\nUn altro aspetto chiave della raccolta dei dati è comprendere appieno i processi e le metodologie utilizzate per acquisirli. È fondamentale analizzare e documentare le tecniche impiegate, le procedure seguite e i potenziali bias che potrebbero influenzare i risultati. Questa consapevolezza contribuisce a garantire che le misure ottenute siano affidabili e che eventuali limitazioni siano considerate durante l’analisi.\n\n\n10.4.2 Fase 2: Pulizia dei Dati e Analisi Esplorativa\n\n10.4.2.1 Importare i Dati in R\nIn ogni dataset, i dati sono generalmente organizzati in una matrice in cui ogni colonna rappresenta una variabile e ogni riga un’osservazione. Le variabili possono essere suddivise in diverse categorie: quantitative (continue o discrete), qualitative (nominali o ordinali), temporali (date e orari) e testuali (strutturate o non strutturate). La dimensionalità del dataset, cioè il numero di variabili, può influenzare notevolmente la complessità dell’analisi, soprattutto quando si lavora con dati ad alta dimensionalità (tipicamente oltre 100 variabili).\nPer lavorare con questi dati in R, il primo passo è importare i file in un oggetto chiamato data frame, una struttura tabellare che organizza i dati in modo pronto per l’elaborazione e la visualizzazione. Il pacchetto rio semplifica notevolmente questo processo con la funzione import(), che consente di caricare dati da diversi formati (ad esempio, .csv, .xlsx, .json) senza dover ricordare funzioni specifiche per ogni tipo di file.\nQuando si utilizza un progetto in RStudio, è buona pratica organizzare i file in una struttura chiara con sotto-cartelle dedicate, come una per i dati grezzi e una per quelli processati. Utilizzare percorsi relativi, resi semplici dal pacchetto here, permette di mantenere i progetti portabili e ben organizzati. Ad esempio, per importare un file nome_file.csv contenuto nella cartella data/raw, si può usare il comando:\nlibrary(here)\nlibrary(rio)\n\ndati &lt;- import(here(\"data\", \"raw\", \"nome_file.csv\"))\nAnalogamente, l’esportazione dei dati elaborati può essere effettuata con rio::export(), specificando il percorso relativo in cui salvare il file:\nexport(my_data, here(\"data\", \"processed\", \"nome_file.csv\"))\nQueste pratiche non solo assicurano che i file siano salvati nella posizione corretta, ma promuovono anche un workflow organizzato, rendendo più facile condividere e replicare i progetti. Inoltre, strumenti come here e rio migliorano l’efficienza, semplificando il lavoro con dataset complessi e formati diversi.\nIn conclusione, una gestione accurata dei dati è il fondamento di un’analisi robusta e riproducibile. Pianificare attentamente la raccolta dei dati, organizzarli in modo strutturato e utilizzare strumenti adeguati per l’importazione e l’esportazione sono passaggi indispensabili per garantire il successo del progetto.\n\n\n10.4.2.2 Pulizia dei Dati\nDopo aver definito la domanda della ricerca e avere raccolto i dati rilevanti, è il momento di pulire i dati. Un dataset pulito è ordinato, formattato in modo appropriato e ha voci non ambigue. La fase iniziale di pulizia dei dati consiste nell’identificare problemi con i dati (come formattazioni anomale e valori non validi) e modificarli in modo che i valori siano validi e formattati in modo comprensibile sia per il computer che per noi. La pulizia dei dati è una fase estremamente importante di un progetto di data science perché non solo aiuta a garantire che i dati siano interpretati correttamente dal computer, ma aiuta anche a sviluppare una comprensione dettagliata delle informazioni contenute nei dati e delle loro limitazioni.\nL’obiettivo della pulizia dei dati è creare una versione dei dati che rifletta nella maniera più fedele possibile la realtà e che sia interpretata correttamente dal computer. Per garantire che il computer utilizzi fedelmente le informazioni contenute nei dati, è necessario modificare i dati (scrivendo codice, non modificando il file dati grezzo stesso) in modo che siano in linea con ciò che il computer “si aspetta”. Tuttavia, il processo di pulizia dei dati è necessariamente soggettivo e comporta fare assunzioni sulle quantità reali sottostanti misurate e decisioni su quali modifiche siano le più sensate.\n\n\n10.4.2.3 Preprocessing\nIl preprocessing si riferisce al processo di modifica dei dati puliti per soddisfare i requisiti di un algoritmo specifico che si desidera applicare. Ad esempio, se si utilizza un algoritmo che richiede che le variabili siano sulla stessa scala, potrebbe essere necessario trasformarle, oppure, se si utilizza un algoritmo che non consente valori mancanti, potrebbe essere necessario imputarli o rimuoverli. Durante il preprocessing, potrebbe essere utile anche definire nuove caratteristiche/variabili utilizzando le informazioni esistenti nei dati, se si ritiene che queste possano essere utili per l’analisi.\nCome per la pulizia dei dati, non esiste un unico modo corretto per pre-elaborare un dataset, e la procedura finale comporta tipicamente una serie di decisioni che dovrebbero essere documentate nel codice e nei file di documentazione.\n\n\n10.4.2.4 Analisi Esplorativa dei Dati\nDopo l’acquisizione dei dati, si procede con un’Analisi Esplorativa dei Dati (EDA - Exploratory Data Analysis). Questa fase iniziale mira a far familiarizzare il ricercatore con il dataset e a scoprire pattern nascosti. Si realizza attraverso:\n\nLa costruzione di tabelle di frequenza e contingenza.\nIl calcolo di statistiche descrittive (come indici di posizione, dispersione e forma della distribuzione).\nLa creazione di rappresentazioni grafiche preliminari.\n\nL’EDA permette di generare ipotesi sui dati e di guidare le successive analisi statistiche.\n\n\n\n10.4.3 Fase 3: Analisi Predittiva e Inferenziale\nMolte domande nella data science si presentano come problemi di inferenza e/o previsione, in cui l’obiettivo principale è utilizzare dati osservati, passati o presenti, per descrivere le caratteristiche di una popolazione più ampia o per fare previsioni su dati futuri non ancora disponibili. Questo tipo di analisi è spesso orientato a supportare decisioni nel mondo reale.\n\n\n10.4.4 Fase 4: Valutazione dei Risultati\nIn questa fase, i risultati ottenuti vengono analizzati alla luce della domanda di ricerca iniziale. Si procede a una valutazione sia quantitativa, attraverso l’applicazione di tecniche statistiche appropriate, sia qualitativa, attraverso un’attenta riflessione critica.\n\n\n10.4.5 Fase 5: Comunicazione dei Risultati\nL’ultima fase di un progetto di analisi dei dati consiste nel condividere i risultati con un pubblico più ampio, il che richiede la preparazione di materiali comunicativi chiari e concisi. L’obiettivo è trasformare i risultati dell’analisi in informazioni utili per supportare il processo decisionale. Questo può includere la stesura di un articolo scientifico, la creazione di un report per un team di lavoro, o la preparazione di una presentazione con diapositive.\nLa comunicazione deve essere adattata al pubblico di riferimento. Non si deve dare per scontato che il pubblico abbia familiarità con il progetto: è fondamentale spiegare l’analisi e le visualizzazioni in modo chiaro e dettagliato. Anche se per il ricercatore il messaggio principale di una figura o diapositiva può sembrare ovvio, è sempre una buona pratica guidare il pubblico nella sua interpretazione, evitando l’uso di gergo tecnico complesso.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "href": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "title": "10  Le fasi del progetto di analisi dei dati",
    "section": "10.5 Organizzazione del Progetto",
    "text": "10.5 Organizzazione del Progetto\nUn requisito fondamentale per un progetto di analisi dei dati è organizzare in modo efficiente i file sul proprio computer. Questo include i file dei dati, il codice e la documentazione del progetto. Tutti questi elementi dovrebbero essere raccolti all’interno di una singola cartella dedicata al progetto.\n\n10.5.1 Home Directory\nIn RStudio, è possibile creare un file chiamato nome_del_progetto.Rproj, che consente di configurare automaticamente la home directory del progetto, ovvero la cartella principale da cui R avvia il lavoro relativo al progetto. Per utilizzare questa funzionalità, è sufficiente aprire RStudio cliccando direttamente sul file nome_del_progetto.Rproj.\nLa home directory rappresenta il punto di riferimento principale per tutte le operazioni del progetto, come il caricamento di file, il salvataggio degli output e la gestione delle risorse.\nGrazie a questa configurazione, è possibile utilizzare percorsi relativi per accedere ai file all’interno del progetto. I percorsi relativi si basano sempre sulla cartella principale del progetto, il che rende il codice più portabile e adattabile. In pratica, chiunque scarichi il tuo progetto sarà in grado di eseguirlo senza dover modificare manualmente i percorsi dei file. Questo approccio migliora la condivisione e garantisce una maggiore riproducibilità del tuo lavoro.\n\n\n10.5.2 Struttura di un Progetto\nYu & Barter (2024) propone il seguente template per la struttura di un progetto:\n\nLe due cartelle principali sono:\n\ndata/: contiene il dataset grezzo (ad esempio, data.csv) e una sottocartella con documentazione relativa ai dati, come metadati e codebook.\ndslc_documentation/: raccoglie i file di documentazione e codice necessari per le varie fasi del progetto. Questi possono essere file .qmd (per Quarto, in R) o .ipynb (per Jupyter Notebook, in Python), utilizzati per condurre ed esplorare le analisi. I file sono prefissati da un numero per mantenerli in ordine cronologico. All’interno di questa cartella, è presente una sottocartella functions/, che contiene script .R (per R) o .py (per Python) con funzioni utili per le diverse analisi.\n\nUn file README.md descrive la struttura del progetto e riassume il contenuto di ogni file.\nUn’organizzazione come quella proposta da Yu & Barter (2024) offre un notevole vantaggio: permette di specificare i percorsi dei file in modo relativo, utilizzando come radice la cartella del progetto. Questo rende il progetto facilmente trasferibile e condivisibile tra diversi utenti o computer.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "href": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "title": "10  Le fasi del progetto di analisi dei dati",
    "section": "10.6 Riflessioni Conclusive",
    "text": "10.6 Riflessioni Conclusive\nLa forza e la bellezza del codice risiedono nella sua riusabilità: una volta scritto, può essere applicato infinite volte per ottenere risultati coerenti. Se configurato correttamente, lo stesso codice applicato agli stessi dati produrrà sempre gli stessi risultati. Questo principio, noto come riproducibilità computazionale, è fondamentale per garantire la trasparenza e l’affidabilità del lavoro scientifico.\nLa riproducibilità offre numerosi vantaggi:\n\nMonitorare le modifiche del progetto\nLa possibilità di riprodurre il lavoro semplifica il monitoraggio delle evoluzioni e dei cambiamenti nel progetto. Questo consente di comprendere come il progetto si è sviluppato nel tempo, facilitando il confronto tra diverse versioni o approcci.\nRiprodurre il proprio lavoro\nIl primo beneficiario della riproducibilità sei tu stesso. Essere in grado di replicare i propri risultati è essenziale, soprattutto se in futuro sarà necessario rivedere o approfondire il lavoro. La riproducibilità garantisce che le analisi possano essere riprese con facilità e senza ambiguità.\nCostruire su basi solide\nAltri ricercatori possono utilizzare il tuo lavoro come punto di partenza, espandendolo o applicandolo a nuovi contesti. La condivisione di codice riproducibile non solo favorisce la collaborazione, ma contribuisce a creare un corpo di conoscenze più robusto e condiviso.\n\nTuttavia, rendere il codice riproducibile non è sempre semplice. Richiede attenzione nella documentazione, un’organizzazione chiara del progetto e strumenti adeguati per garantire che l’ambiente di lavoro sia stabile e replicabile. In questo capitolo, abbiamo esplorato alcune strategie e tecniche per raggiungere questi obiettivi.\n\n\n\n\n\n\nNota\n\n\n\nUn problema cruciale nella psicologia contemporanea è la crisi di replicabilità, che evidenzia come molti risultati di ricerca non siano replicabili (Collaboration, 2015). La riproducibilità computazionale, pur avendo un obiettivo più ristretto, si concentra sulla possibilità di ottenere gli stessi risultati applicando lo stesso codice agli stessi dati. Questo approccio, sebbene non risolva interamente la crisi, rappresenta un passo fondamentale verso una scienza più trasparente e rigorosa.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "title": "10  Le fasi del progetto di analisi dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats4    stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mokken_3.1.2         poLCA_1.6.0.1        scatterplot3d_0.3-44\n#&gt;  [4] mirt_1.43            lattice_0.22-6       MASS_7.3-61         \n#&gt;  [7] viridis_0.6.5        viridisLite_0.4.2    ggpubr_0.6.0        \n#&gt; [10] ggExtra_0.10.1       gridExtra_2.3        patchwork_1.3.0     \n#&gt; [13] bayesplot_1.11.1     psych_2.4.6.26       scales_1.3.0        \n#&gt; [16] markdown_1.13        knitr_1.49           lubridate_1.9.3     \n#&gt; [19] forcats_1.0.0        stringr_1.5.1        dplyr_1.1.4         \n#&gt; [22] purrr_1.0.2          readr_2.1.5          tidyr_1.3.1         \n#&gt; [25] tibble_3.2.1         ggplot2_3.5.1        tidyverse_2.0.0     \n#&gt; [28] rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         pbapply_1.7-2        testthat_3.2.1.1    \n#&gt;  [4] permute_0.9-7        rlang_1.1.4          magrittr_2.0.3      \n#&gt;  [7] compiler_4.4.2       mgcv_1.9-1           vctrs_0.6.5         \n#&gt; [10] pkgconfig_2.0.3      fastmap_1.2.0        backports_1.5.0     \n#&gt; [13] utf8_1.2.4           promises_1.3.1       rmarkdown_2.29      \n#&gt; [16] sessioninfo_1.2.2    tzdb_0.4.0           xfun_0.49           \n#&gt; [19] jsonlite_1.8.9       later_1.4.0          Deriv_4.1.6         \n#&gt; [22] broom_1.0.7          parallel_4.4.2       cluster_2.1.6       \n#&gt; [25] R6_2.5.1             stringi_1.8.4        parallelly_1.39.0   \n#&gt; [28] car_3.1-3            brio_1.1.5           Rcpp_1.0.13-1       \n#&gt; [31] future.apply_1.11.3  snow_0.4-4           audio_0.1-11        \n#&gt; [34] pacman_0.5.1         R.utils_2.12.3       httpuv_1.6.15       \n#&gt; [37] Matrix_1.7-1         splines_4.4.2        timechange_0.3.0    \n#&gt; [40] tidyselect_1.2.1     abind_1.4-8          yaml_2.3.10         \n#&gt; [43] vegan_2.6-8          codetools_0.2-20     miniUI_0.1.1.1      \n#&gt; [46] dcurver_0.9.2        curl_6.0.1           listenv_0.9.1       \n#&gt; [49] shiny_1.9.1          withr_3.0.2          evaluate_1.0.1      \n#&gt; [52] future_1.34.0        pillar_1.9.0         carData_3.0-5       \n#&gt; [55] generics_0.1.3       rprojroot_2.0.4      hms_1.1.3           \n#&gt; [58] munsell_0.5.1        globals_0.16.3       xtable_1.8-4        \n#&gt; [61] glue_1.8.0           RPushbullet_0.3.4    tools_4.4.2         \n#&gt; [64] beepr_2.0            SimDesign_2.17.1     ggsignif_0.6.4      \n#&gt; [67] grid_4.4.2           colorspace_2.1-1     nlme_3.1-166        \n#&gt; [70] Formula_1.2-5        cli_3.6.3            fansi_1.0.6         \n#&gt; [73] gtable_0.3.6         R.methodsS3_1.8.2    rstatix_0.7.2       \n#&gt; [76] digest_0.6.37        progressr_0.15.1     GPArotation_2024.3-1\n#&gt; [79] htmlwidgets_1.6.4    farver_2.1.2         htmltools_0.5.8.1   \n#&gt; [82] R.oo_1.27.0          lifecycle_1.0.4      mime_0.12",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#bibliografia",
    "href": "chapters/eda/01_project_structure.html#bibliografia",
    "title": "10  Le fasi del progetto di analisi dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html",
    "href": "chapters/eda/02_data_cleaning.html",
    "title": "11  Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "11.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNonostante la fase più interessante di un progetto di analisi dei dati sia quella in cui si riesce a rispondere alla domanda che ha dato avvio all’indagine, gran parte del tempo di un analista è in realtà dedicata a una fase preliminare: la pulizia e il preprocessing dei dati, operazioni che vengono svolte ancor prima dell’analisi esplorativa.\nIn questo capitolo, esamineremo un caso concreto di data cleaning e preprocessing, seguendo il tutorial di Crystal Lewis. Il problema viene presentato come segue:\nCrystal Lewis elenca i seguenti passaggi da seguire nel processo di data cleaning:\nSebbene l’ordine di questi passaggi sia flessibile e possa essere adattato alle esigenze specifiche, c’è un passaggio che non dovrebbe mai essere saltato: il primo, ovvero la revisione dei dati. Senza una revisione preliminare, l’analista rischia di sprecare ore a pulire i dati per poi scoprire che mancano dei partecipanti, che i dati non sono organizzati come previsto o, peggio ancora, che sta lavorando con i dati sbagliati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#introduzione",
    "href": "chapters/eda/02_data_cleaning.html#introduzione",
    "title": "11  Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "I am managing data for a longitudinal randomized controlled trial (RCT) study. For this RCT, schools are randomized to either a treatment or control group. Students who are in a treatment school receive a program to boost their math self-efficacy. Data is collected on all students in two waves (wave 1 is in the fall of a school year, and wave 2 is collected in the spring). At this point in time, we have collected wave 1 of our student survey on a paper form and we set up a data entry database for staff to enter the information into. Data has been double-entered, checked for entry errors, and has been exported in a csv format (“w1_mathproj_stu_svy_raw.csv”) to a folder (called “data”) where it is waiting to be cleaned.\n\n\n\nRevisione dei dati.\nRegolazione del numero di casi.\nDe-identificazione dei dati.\nEliminazione delle colonne irrilevanti.\nDivisione delle colonne, se necessario.\nRidenominazione delle variabili.\nTrasformazione/normalizzazione delle variabili.\nStandardizzazione delle variabili.\nAggiornamento dei tipi di variabili, se necessario.\nRicodifica delle variabili.\nCreazione di eventuali variabili necessarie.\nGestione dei valori mancanti, se necessario.\nAggiunta di metadati, se necessario.\nValidazione dei dati.\nFusione e/o unione dei dati, se necessario.\nTrasformazione dei dati, se necessario.\nSalvataggio dei dati puliti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#tutorial",
    "href": "chapters/eda/02_data_cleaning.html#tutorial",
    "title": "11  Flusso di lavoro per la pulizia dei dati",
    "section": "11.2 Tutorial",
    "text": "11.2 Tutorial\nEsamineremo questi passaggi seguendo il tutorial di Crystal Lewis.\nImportare i Dati\nI dati grezzi non dovrebbero mai essere modificati direttamente. È consigliabile organizzare i dati in una struttura di cartelle all’interno di una directory chiamata data, che contiene due sottocartelle: raw e processed. I dati originali, non ancora elaborati, devono essere conservati nella cartella raw e mantenuti inalterati. I dati ripuliti e preprocessati, invece, devono essere salvati nella cartella processed.\nPer fare un esempio, importiamo i dati dal file w1_mathproj_stu_svy_raw.csv e iniziamo il processo di pulizia. È importante notare che tutte le istruzioni sono formulate in modo relativo alla home directory del progetto. Prima di tutto, definiamo il percorso della home directory del progetto.\n\nEsaminare i Dati\n\nProcediamo con l’importazione dei dati.\n\nsvy = rio::import(here::here(\"data\", \"w1_mathproj_stu_svy_raw.csv\"))\nglimpse(svy)\n#&gt; Rows: 6\n#&gt; Columns: 7\n#&gt; $ stu_id      &lt;int&gt; 1347, 1368, 1377, 1387, 1347, 1399\n#&gt; $ svy_date    &lt;IDate&gt; 2023-02-13, 2023-02-13, 2023-02-13, 2023-02-13, 2023-02…\n#&gt; $ grade_level &lt;int&gt; 9, 10, 9, 11, 9, 12\n#&gt; $ math1       &lt;int&gt; 2, 3, 4, 3, 2, 4\n#&gt; $ math2       &lt;chr&gt; \"1\", \"2\", \"\\n4\", \"3\", \"2\", \"1\"\n#&gt; $ math3       &lt;int&gt; 3, 2, 4, NA, 4, 3\n#&gt; $ math4       &lt;int&gt; 3, 2, 4, NA, 2, 1\n\nÈ utile esaminare visivamente le prime o le ultime righe del data frame per verificare che i dati siano stati importati correttamente.\n\nsvy |&gt; \n  head()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n\nsvy |&gt; \n  tail()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n\nModificare i casi secondo necessità\n\nIl secondo passo è quello in cui vengono fatte delle semplici ma necessarie modifiche al data frame. Crystal Lewis descrive così questo passo per i dati in esame:\n\nVerificare la presenza di duplicati - Il record 1347 è duplicato.\nRimuovere i duplicati.\nOrdinare per svy_date in ordine crescente.\nEsaminare i dati dopo aver rimosso i duplicati.\n\n\n# Trova i duplicati basati su 'stu_id'\nduplicates &lt;- svy[duplicated(svy$stu_id) | duplicated(svy$stu_id, fromLast = TRUE), ]\n\n# Ordina per 'svy_date' in ordine crescente e rimuovi i duplicati mantenendo il primo\nsvy &lt;- svy[order(svy$svy_date), ]\nsvy &lt;- svy[!duplicated(svy$stu_id), ]\n\n# Mostra il DataFrame finale\nprint(svy)\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n\nsvy |&gt; \n  dim()\n#&gt; [1] 5 7\n\n\nDe-identificazione dei Dati\n\n\n# Rimuovi la colonna 'svy_date'\nsvy &lt;- svy |&gt;\n  dplyr::select(-svy_date)\n\n# Mostra i nomi delle colonne rimaste\nnames(svy)\n#&gt; [1] \"stu_id\"      \"grade_level\" \"math1\"       \"math2\"       \"math3\"      \n#&gt; [6] \"math4\"\n\n\nRimuovere le Colonne non Necessarie\n\nNel caso presente, la rimozione di colonne non è necessaria. Tuttavia, in molti progetti di analisi dei dati, soprattutto quando i dati vengono raccolti utilizzando software di terze parti o strumenti specifici per esperimenti psicologici, è comune trovarsi con colonne che non sono pertinenti allo studio in corso.\nQueste colonne possono includere dati come identificatori interni, timestamp generati automaticamente, informazioni di debug, o variabili che non sono rilevanti per l’analisi che si intende condurre. Quando tali colonne sono irrilevanti per la ricerca, possono essere rimosse per semplificare il dataset e ridurre il rischio di confusione o errori durante l’analisi. Rimuovere le colonne non necessarie non solo rende il dataset più gestibile, ma aiuta anche a focalizzare l’analisi sulle variabili che realmente importano per rispondere alle domande di ricerca.\n\nDividere le Colonne Secondo Necessità\n\nNel caso presente, questa operazione non è necessaria. Tuttavia, se si lavora con un dataset che include una colonna chiamata “NomeCompleto”, contenente sia il nome che il cognome di uno studente, è buona pratica separare questa colonna in due colonne distinte, “Nome” e “Cognome”. Questa suddivisione facilita l’analisi e la manipolazione dei dati, rendendoli più organizzati e accessibili.\n\nRinominare le Colonne\n\nÈ importante assegnare nomi chiari alle colonne del dataset. Utilizzare nomi di variabili comprensibili aiuta a rendere l’analisi dei dati più intuitiva e a ridurre il rischio di errori interpretativi.\nEsempi di buone pratiche:\n\nEvita nomi di colonne come “x” o acronimi incomprensibili. Questi possono creare confusione durante l’analisi, specialmente se il dataset viene condiviso con altri ricercatori o se viene ripreso dopo un lungo periodo di tempo.\nInvece, cerca di utilizzare nomi di variabili che descrivano chiaramente il contenuto della colonna. Ad esempio, invece di “x1” o “VAR123”, un nome come “ansia_base” o “liv_autoefficacia” è molto più comprensibile e immediato.\nPer i nomi composti, utilizza un separatore come il trattino basso _. Ad esempio, se stai lavorando con dati relativi a un test psicologico, potresti avere colonne chiamate “test_ansia_pre” e “test_ansia_post” per indicare i risultati del test di ansia prima e dopo un intervento.\n\nEsempi di nomi di colonne ben scelti:\n\nNome generico: TS, AE\n\nNome migliore: tempo_studio, auto_efficacia\n\nNome generico: S1, S2\n\nNome migliore: stress_situazione1, stress_situazione2\n\nNome generico: Q1, Q2\n\nNome migliore: qualità_sonno_sett1, qualità_sonno_sett2\n\n\n\nTrasformare le Variabili\n\nNel caso presente non si applica, ma è un passo importante in molte analisi dei dati.\nEsempi di trasformazione delle variabili:\n\nLogaritmo di una variabile: Immaginiamo di avere una variabile che misura i tempi di reazione dei partecipanti a un esperimento. Se i tempi di reazione hanno una distribuzione fortemente asimmetrica (con alcuni valori molto elevati), potrebbe essere utile applicare una trasformazione logaritmica per rendere la distribuzione più simmetrica e migliorare l’interpretabilità dei risultati.\nCodifica delle variabili categoriche: Se è presente una variabile categorica come il “tipo di intervento” con valori come “cognitivo”, “comportamentale” e “farmacologico”, potrebbe essere necessario trasformare questa variabile in variabili dummy (ad esempio, intervento_cognitivo, intervento_comportamentale, intervento_farmacologico), dove ogni variabile assume il valore 0 o 1 a seconda della presenza o meno di quel tipo di intervento. Questo è utile quando si utilizzano tecniche di regressione.\n\n\nStandardizzare / Normalizzare le Variabili\n\nNel caso presente non si applica, ma è un passo importante in molte analisi dei dati.\nEsempi di standardizzazione delle variabili:\n\nStandardizzazione dei punteggi: Supponiamo di avere una variabile che misura il livello di ansia su una scala da 0 a 100. Se desideriamo confrontare i livelli di ansia tra diversi gruppi o includere questa variabile in un modello di regressione, potrebbe essere utile standardizzare i punteggi (cioè, sottrarre la media e dividere per la deviazione standard) per ottenere una variabile con media 0 e deviazione standard 1. Questo processo rende i punteggi comparabili e facilita l’interpretazione dei coefficienti in un modello di regressione.\nNormalizzazione delle variabili: Se hai dati su diverse variabili come “ore di sonno”, “livello di stress” e “auto-efficacia”, e queste variabili hanno scale molto diverse, potrebbe essere utile normalizzarle (ad esempio, ridimensionarle tutte su una scala da 0 a 1) per garantire che abbiano lo stesso peso in un’analisi multivariata.\n\nTrasformare e standardizzare le variabili sono passaggi cruciali in molte analisi psicologiche, specialmente quando si confrontano dati provenienti da diverse fonti o gruppi. Questi processi aiutano a garantire che le variabili siano trattate in modo appropriato e che i risultati dell’analisi siano validi e interpretabili.\n\nAggiornare i Tipi delle Variabili\n\nNel caso presente non è necessario. Supponiamo invece di avere una colonna in un dataset psicologico che contiene punteggi di un questionario, ma i dati sono stati importati come stringhe (testo) invece che come numeri. Per eseguire calcoli statistici, sarà necessario convertire questa colonna da stringa a numerico.\nIn R, si potrebbe usare il seguente codice:\n\n# Supponiamo di avere un data frame chiamato 'df' con una colonna 'punteggio' importata come carattere\ndf$punteggio &lt;- as.numeric(df$punteggio)\n\n# Ora la colonna 'punteggio' è stata convertita in un tipo numerico ed è possibile eseguire calcoli su di essa\n\nIn questo esempio, la funzione as.numeric() viene utilizzata per convertire la colonna punteggio in un formato numerico, permettendo di eseguire analisi quantitative sui dati.\nUn altro caso molto comune si verifica quando si importano dati da file Excel. Spesso capita che, all’interno di una cella di una colonna che dovrebbe contenere solo valori numerici, venga inserito erroneamente uno o più caratteri alfanumerici. Di conseguenza, l’intera colonna viene interpretata come di tipo alfanumerico, anche se i valori dovrebbero essere numerici. In questi casi, è fondamentale individuare la cella problematica, correggere il valore errato, e poi riconvertire l’intera colonna da alfanumerica a numerica.\n\nRicodificare le Variabili\n\nAnche se in questo caso non è necessario, la ricodifica delle variabili è una pratica molto comune nelle analisi dei dati psicologici.\nPer esempio, consideriamo una variabile categoriale con modalità descritte da stringhe poco comprensibili, che vengono ricodificate con nomi più chiari e comprensibili.\nSupponiamo di avere un DataFrame chiamato df con una colonna tipo_intervento che contiene le modalità \"CT\", \"BT\", e \"MT\" per rappresentare rispettivamente “Terapia Cognitiva”, “Terapia Comportamentale” e “Terapia Mista”. Queste abbreviazioni potrebbero non essere immediatamente chiare a chiunque analizzi i dati, quindi decidiamo di ricodificarle con nomi più espliciti. Ecco come farlo in R:\n\n# Supponiamo di avere un tibble chiamato 'df' con una colonna 'tipo_intervento'\ndf &lt;- tibble(tipo_intervento = c(\"CT\", \"BT\", \"MT\", \"CT\", \"BT\"))\n\n# Ricodifica delle modalità della variabile 'tipo_intervento' in nomi più comprensibili\ndf &lt;- df %&gt;%\n  mutate(tipo_intervento_ricodificato = dplyr::recode(\n    tipo_intervento,\n    \"CT\" = \"Terapia Cognitiva\",\n    \"BT\" = \"Terapia Comportamentale\",\n    \"MT\" = \"Terapia Mista\"\n  ))\n\n# Mostra il tibble con la nuova colonna ricodificata\nprint(df)\n\n\nAggiungere Nuove Variabili nel Data Frame\n\nNel caso presente non è richiesto, ma aggiungere nuove variabili a un DataFrame è un’operazione comune durante l’analisi dei dati. Un esempio è il calcolo dell’indice di massa corporea (BMI).\nSupponiamo di avere un DataFrame chiamato df che contiene le colonne peso_kg (peso in chilogrammi) e altezza_m (altezza in metri) per ciascun partecipante a uno studio psicologico. Per arricchire il dataset, possiamo calcolare il BMI per ogni partecipante e aggiungerlo come una nuova variabile.\nIl BMI si calcola con la formula:\n\\[ \\text{BMI} = \\frac{\\text{peso in kg}}{\\text{altezza in metri}^2} .\\]\nEcco come aggiungere la nuova colonna.\n\n# Supponiamo di avere un tibble chiamato 'df' con le colonne 'peso_kg' e 'altezza_m'\ndf &lt;- tibble(\n  peso_kg = c(70, 85, 60, 95),\n  altezza_m = c(1.75, 1.80, 1.65, 1.90)\n)\n\n# Calcola il BMI e aggiungilo come una nuova colonna 'BMI'\ndf &lt;- df %&gt;%\n  mutate(BMI = peso_kg / (altezza_m^2))\n\n# Mostra il tibble con la nuova variabile aggiunta\nprint(df)\n#&gt; # A tibble: 4 × 3\n#&gt;   peso_kg altezza_m   BMI\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1      70      1.75  22.9\n#&gt; 2      85      1.8   26.2\n#&gt; 3      60      1.65  22.0\n#&gt; 4      95      1.9   26.3\n\n\nAffrontare il Problema dei Dati Mancanti\n\nL’imputazione è una tecnica utilizzata per gestire i dati mancanti in un dataset, un problema comune in molte analisi. Lasciare i valori mancanti nel DataFrame può compromettere la qualità dell’analisi, poiché molti algoritmi statistici non sono in grado di gestire direttamente i dati incompleti, portando a risultati distorti o poco affidabili.\nI valori mancanti possono causare diversi problemi:\n\nBias dei risultati: I dati mancanti possono introdurre un bias nelle stime se i valori mancanti non sono distribuiti in modo casuale.\nRiduzione della potenza statistica: Quando si eliminano le righe con dati mancanti (rimozione listwise), si riduce la dimensione del campione, diminuendo la potenza dell’analisi.\nImpossibilità di utilizzare alcuni algoritmi: Molti algoritmi di statistica richiedono che tutti i valori siano presenti per eseguire correttamente i calcoli.\n\nEsistono vari approcci per affrontare i dati mancanti:\n\nImputazione Semplice:\n\nMedia/Mediana: Un metodo comune e semplice è sostituire i valori mancanti con la media o la mediana della colonna. Questo metodo è facile da implementare, ma può ridurre la variabilità dei dati e portare a una sottostima della varianza.\nMode (moda): Per le variabili categoriche, è possibile sostituire i valori mancanti con la moda (il valore più frequente). Tuttavia, questo può portare a una distorsione se la distribuzione dei dati è molto eterogenea.\n\nImputazione Multipla:\n\nRegressione Iterativa: L’imputazione multipla, come implementata con algoritmi come IterativeImputer, è una procedura più sofisticata che predice i valori mancanti in modo iterativo utilizzando un modello basato sulle altre variabili del dataset. Questa tecnica tiene conto delle relazioni tra le variabili, migliorando l’accuratezza delle imputazioni rispetto ai metodi semplici.\nL’imputazione multipla conserva la variabilità nei dati e riduce il bias, fornendo stime più accurate rispetto ai metodi di imputazione semplice.\n\n\nL’imputazione dei dati mancanti è essenziale per garantire che l’analisi statistica sia accurata e robusta. Sebbene i metodi semplici come la sostituzione con la media possano essere utili in alcuni casi, l’imputazione multipla offre un approccio più completo e sofisticato, particolarmente utile quando si desidera preservare le relazioni tra le variabili e mantenere l’integrità statistica del dataset. Questo argomento verrà ulteriormente discusso nel ?sec-missing-data.\nApplichiamo la procedura dell’imputazione multipla al caso presente.\n\n# Supponiamo di avere un data frame chiamato 'd'\nd &lt;- svy %&gt;% as_tibble()\n\n# Mantieni l'indice originale \noriginal_index &lt;- rownames(d)\n\n# Converti solo le colonne numeriche relative ai punteggi in numerico per l'imputazione\nnumeric_columns &lt;- c(\"math1\", \"math2\", \"math3\", \"math4\")\nd &lt;- d %&gt;%\n  mutate(across(all_of(numeric_columns), as.numeric))\n\n# Applica mice per l'imputazione multipla\nimputed &lt;- mice(d[numeric_columns], m = 1, maxit = 10, method = \"norm.predict\", seed = 0)\n#&gt; \n#&gt;  iter imp variable\n#&gt;   1   1  math3  math4\n#&gt;   2   1  math3  math4\n#&gt;   3   1  math3  math4\n#&gt;   4   1  math3  math4\n#&gt;   5   1  math3  math4\n#&gt;   6   1  math3  math4\n#&gt;   7   1  math3  math4\n#&gt;   8   1  math3  math4\n#&gt;   9   1  math3  math4\n#&gt;   10   1  math3  math4\n#&gt; Warning: Number of logged events: 2\n\n# Estrai il dataset imputato\ndf_imputed &lt;- complete(imputed)\n\n# Arrotonda i valori imputati ai numeri interi più vicini\ndf_imputed &lt;- df_imputed %&gt;%\n  mutate(across(everything(), round))\n\n# Inserisci i valori imputati e arrotondati nel data frame originale\nd[numeric_columns] &lt;- df_imputed\n\n# Mostra il data frame dopo l'imputazione e l'arrotondamento\ncat(\"\\nDataFrame dopo l'imputazione e l'arrotondamento:\\n\")\n#&gt; \n#&gt; DataFrame dopo l'imputazione e l'arrotondamento:\nprint(d)\n#&gt; # A tibble: 5 × 6\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt;    &lt;int&gt;       &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     2     3\n#&gt; 5   1399          12     4     1     3     1\n\nPer eseguire l’imputazione multipla in R, utilizziamo il pacchetto mice, uno strumento avanzato per gestire i valori mancanti nei dati. Questo approccio si basa su metodi di regressione iterativa, in cui ogni valore mancante viene stimato utilizzando un modello predittivo che considera tutte le altre variabili presenti nel dataset.\n\nSelezione delle colonne numeriche per l’imputazione:\n\nAbbiamo identificato le colonne numeriche che richiedono l’imputazione (math1, math2, math3, math4).\n\nImputazione Multipla con mice:\n\nIl pacchetto mice utilizza un processo iterativo per stimare i valori mancanti. Ogni variabile con valori mancanti viene modellata a turno come una funzione delle altre variabili, utilizzando metodi specifici (ad esempio, regressione lineare o modelli bayesiani).\nL’imputazione iterativa procede in cicli successivi. Durante ogni ciclo, i valori mancanti di una variabile vengono stimati utilizzando le imputazioni correnti delle altre variabili.\nParametro maxit=10: Il processo iterativo viene ripetuto fino a un massimo di 10 volte, o fino al raggiungimento della convergenza (stabilità dei valori imputati).\n\nApplicazione e Arrotondamento:\n\nDopo l’imputazione, i valori stimati vengono reinseriti nel dataset. Per le variabili numeriche che rappresentano conteggi o valori discreti, i valori imputati sono stati arrotondati al numero intero più vicino.\n\nRisultato:\n\nIl dataset risultante non contiene più valori mancanti nelle colonne numeriche specificate (math1, math2, math3, math4), poiché questi sono stati imputati utilizzando le relazioni con le altre variabili del dataset.\n\n\nIn sintesi, l’imputazione multipla con mice è una tecnica potente per gestire i valori mancanti senza eliminare intere righe o colonne. Questo approccio preserva le relazioni tra variabili, garantendo che l’inferenza statistica rimanga accurata e valida. Nel nostro caso, abbiamo utilizzato un modello predittivo iterativo per stimare i valori mancanti basandoci sulle informazioni fornite dalle altre variabili. Questo metodo aumenta la qualità dei dati e consente analisi più robuste e affidabili.\n\nAggiungere i Metadati\n\nI metadati sono informazioni che descrivono i dati stessi, come etichette di variabili, etichette di valori, informazioni sull’origine dei dati, unità di misura e altro ancora. Questi metadati sono essenziali per comprendere, documentare e condividere correttamente un dataset.\nIn R, i metadati sono gestiti in modo molto dettagliato e strutturato attraverso pacchetti come haven, labelled, e Hmisc. Questi pacchetti consentono di associare etichette ai dati, come etichette di variabili e di valori, e persino di gestire i valori mancanti con etichette specifiche.\n\nEtichette di variabili: Si possono aggiungere direttamente alle colonne di un DataFrame usando funzioni come labelled::set_variable_labels().\nEtichette di valori: Possono essere aggiunte a variabili categoriali utilizzando labelled::labelled().\nValori mancanti: In R, è possibile etichettare specifici valori come mancanti usando labelled::na_values&lt;-.\n\nQuesti strumenti rendono molto facile documentare un dataset all’interno del processo di analisi, assicurando che tutte le informazioni critiche sui dati siano facilmente accessibili e ben documentate.\n\n# Creazione del dataset\nsvy &lt;- tibble(\n  stu_id = c(1347, 1368, 1377, 1387, 1399),\n  grade_level = c(9, 10, 9, 11, 12),\n  math1 = c(2, 3, 4, 3, 4),\n  math2 = c(1, 2, 4, 3, 1),\n  math3 = c(3.0, 2.0, 4.0, NA, 3.0),\n  math4 = c(3.0, 2.0, 4.0, NA, 1.0),\n  int = c(1, 0, 1, 0, 1)\n)\n\n# Definizione delle etichette di valore per le variabili math1:math4\nvalue_labels_math &lt;- set_names(\n  as.numeric(names(c(\n    `1` = \"strongly disagree\",\n    `2` = \"disagree\",\n    `3` = \"agree\",\n    `4` = \"strongly agree\"\n  ))),\n  c(\"strongly disagree\", \"disagree\", \"agree\", \"strongly agree\")\n)\n\n# Aggiunta delle etichette di valore alle colonne math1:math4\nsvy &lt;- svy %&gt;%\n  mutate(across(starts_with(\"math\"), ~ labelled(., labels = value_labels_math)))\n\n# Verifica delle etichette\nval_labels(svy$math1)\n#&gt; strongly disagree          disagree             agree    strongly agree \n#&gt;                 1                 2                 3                 4\n\n\nValidazione dei Dati\n\nLa validazione dei dati è un passaggio fondamentale per garantire che il dataset soddisfi i criteri previsti e sia pronto per le analisi successive. Questo processo include il controllo della coerenza e della correttezza dei dati in base a specifiche regole definite dal dizionario dei dati. Alcune verifiche comuni includono:\n\nUnicità delle righe: Assicurarsi che ogni riga sia unica, verificando l’assenza di ID duplicati.\nValidità degli ID: Controllare che gli ID rientrino in un intervallo previsto (es. numerico).\nValori accettabili nelle variabili categoriali: Verificare che variabili come grade_level, int e le colonne math contengano esclusivamente valori appartenenti a un set di valori validi.\n\nIl pacchetto pointblank fornisce strumenti flessibili e intuitivi per eseguire verifiche di validazione e generare report dettagliati. Questo pacchetto consente di:\n\nDefinire le regole di validazione: Specificare controlli come unicità, intervalli di valori e appartenenza a insiemi predefiniti.\nEseguire i controlli: Applicare le regole di validazione su un dataset per identificare eventuali discrepanze.\nGenerare report interattivi: Creare un riepilogo chiaro e visivo dei controlli, evidenziando eventuali errori o anomalie.\n\nCon pointblank, è possibile integrare la validazione dei dati come parte di un workflow strutturato, garantendo la qualità dei dati in modo sistematico e ripetibile.\n\ncreate_agent(svy) %&gt;%\n  rows_distinct(columns = vars(stu_id)) %&gt;%\n  col_vals_between(columns = c(stu_id), \n                   left = 1300, right = 1400, na_pass = TRUE) %&gt;%\n  col_vals_in_set(columns = c(grade_level), \n                  set = c(9, 10, 11, 12, NA)) %&gt;%\n  col_vals_in_set(columns = c(int),\n                  set = c(0, 1, NA)) %&gt;%\n  col_vals_in_set(columns = c(math1:math4),\n                  set = c(1, 2, 3, 4, NA)) %&gt;%\n  interrogate()\n\n\n\n\n\n\n\nPointblank Validation\n\n\n\n\n[2024-12-03|02:49:48]\n\n\ntibble svy\n\n\n\n\n\n\nSTEP\nCOLUMNS\nVALUES\nTBL\nEVAL\nUNITS\nPASS\nFAIL\nW\nS\nN\nEXT\n\n\n\n\n\n\n1\n\n\n\n\nrows_distinct\n\n         \n\n\n rows_distinct()\n\n\n▮stu_id\n\n—\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n\n2\n\n\n\n\ncol_vals_between\n\n     \n\n\n col_vals_between()\n\n\n▮stu_id\n\n\n[1,300, 1,400]\n\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n\n3\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n col_vals_in_set()\n\n\n▮grade_level\n\n\n9, 10, 11, 12, NA\n\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n\n4\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n col_vals_in_set()\n\n\n▮int\n\n\n0, 1, NA\n\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n\n5\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n col_vals_in_set()\n\n\n▮math1\n\n\n1, 2, 3, 4, NA\n\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n\n6\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n col_vals_in_set()\n\n\n▮math2\n\n\n1, 2, 3, 4, NA\n\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n\n7\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n col_vals_in_set()\n\n\n▮math3\n\n\n1, 2, 3, 4, NA\n\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n\n8\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n col_vals_in_set()\n\n\n▮math4\n\n\n1, 2, 3, 4, NA\n\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n2024-12-03 02:49:48 CET &lt; 1 s 2024-12-03 02:49:48 CET\n\n\n\n\n\n\n\n\nIl dataset ripulito soddisfa tutte le aspettative delineate da Crystal Lewis.\n\nCompleto: Tutti i dati raccolti sono stati inseriti e/o recuperati. Non dovrebbero esserci dati estranei che non appartengono al dataset (come duplicati o partecipanti non autorizzati).\nValido: Le variabili rispettano i vincoli definiti nel tuo dizionario dei dati. Ricorda che il dizionario dei dati specifica i nomi delle variabili, i tipi, i range, le categorie e altre informazioni attese.\nAccurato: Sebbene non sia sempre possibile determinare l’accuratezza dei valori durante il processo di pulizia dei dati (ovvero, se un valore è realmente corretto o meno), in alcuni casi è possibile valutarla sulla base della conoscenza pregressa riguardante quel partecipante o caso specifico.\nCoerente: I valori sono allineati tra le varie fonti. Ad esempio, la data di nascita raccolta attraverso un sondaggio studentesco dovrebbe avere un formato corrispondere alla data di nascita raccolta dal distretto scolastico.\nUniforme: I dati sono standardizzati attraverso i moduli e nel tempo. Ad esempio, lo stato di partecipazione ai programmi di pranzo gratuito o a prezzo ridotto è sempre fornito come una variabile numerica con la stessa rappresentazione, oppure il nome della scuola è sempre scritto in modo coerente in tutto il dataset.\nDe-identificato: Tutte le informazioni personali identificabili (PII) sono state rimosse dal dataset per proteggere la riservatezza dei partecipanti (se richiesto dal comitato etico/consenso informato).\nInterpretabile: I dati hanno nomi di variabili leggibili sia da umani che dal computer, e sono presenti etichette di variabili e valori laddove necessario per facilitare l’interpretazione.\nAnalizzabile: Il dataset è in un formato rettangolare (righe e colonne), leggibile dal computer e conforme alle regole di base della struttura dei dati.\n\nUna volta completati i 14 passaggi precedenti, è possibile esportare questo dataset ripulito nella cartella processed per le successive analisi statistiche.\n\nUnire e/o aggiungere dati se necessario\n\nIn questo passaggio, è possibile unire o aggiungere colonne o righe presenti in file diversi. È importante eseguire nuovamente i controlli di validazione dopo l’unione/aggiunta di nuovi dati.\n\nTrasformare i dati se necessario\n\nEsistono vari motivi per cui potrebbe essere utile memorizzare i dati in formato long o wide. In questo passaggio, è possibile ristrutturare i dati secondo le esigenze.\n\nSalvare il dataset pulito finale\n\nL’ultimo passaggio del processo di pulizia consiste nell’esportare o salvare il dataset pulito. Come accennato in precedenza, può essere utile esportare/salvare il dataset in più di un formato di file (ad esempio, un file .csv e un file .parquet).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "href": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "title": "11  Flusso di lavoro per la pulizia dei dati",
    "section": "11.3 Organizzazione dei file e informazioni aggiuntive",
    "text": "11.3 Organizzazione dei file e informazioni aggiuntive\nInfine, è essenziale includere una documentazione adeguata per garantire che le informazioni siano interpretate correttamente, sia da altri utenti che da te stesso, se dovessi tornare a lavorare su questo progetto in futuro. La documentazione minima da fornire dovrebbe includere:\n\nDocumentazione a livello di progetto: Questa sezione fornisce informazioni contestuali sul perché e come i dati sono stati raccolti. È utile per chiunque voglia comprendere lo scopo e la metodologia del progetto.\nMetadati a livello di progetto: Se condividi i dati in un repository pubblico o privato, è importante includere metadati a livello di progetto. Questi metadati forniscono informazioni dettagliate che facilitano la ricerca, la comprensione e la consultabilità dei dati. I metadati a livello di progetto possono includere descrizioni generali del progetto, parole chiave, e riferimenti bibliografici.\nDizionario dei dati: Un documento che descrive tutte le variabili presenti nel dataset, inclusi i loro nomi, tipi, range di valori, categorie e qualsiasi altra informazione rilevante. Questo strumento è fondamentale per chiunque voglia comprendere o analizzare i dati.\nREADME: Un file che fornisce una panoramica rapida dei file inclusi nel progetto, spiegando cosa contengono e come sono interconnessi. Il README è spesso il primo documento consultato e serve a orientare l’utente tra i vari file e risorse del progetto. Questa documentazione non solo aiuta a mantenere il progetto organizzato, ma è anche cruciale per facilitare la collaborazione e l’archiviazione a lungo termine.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "href": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "title": "11  Flusso di lavoro per la pulizia dei dati",
    "section": "11.4 Dizionario dei Dati",
    "text": "11.4 Dizionario dei Dati\nApprofondiamo qui il problema della creazione del Dizionario dei dati.\nUn dizionario dei dati è un documento che descrive le caratteristiche di ciascuna variabile in un dataset. Include informazioni come il nome della variabile, il tipo di dato, il range di valori, le categorie (per le variabili categoriche), e altre informazioni rilevanti. Questo strumento è essenziale per comprendere e analizzare correttamente il dataset.\nSi presti particolare attenzione alle guide di stile per la denominazione delle variabili e la codifica dei valori delle risposte.\nEcco come tradurre i passi per creare un dizionario dei dati in R, utilizzando il pacchetto tibble per creare il dizionario e writexl o readr per esportarlo in formato .xlsx o .csv.\n\n11.4.1 Passi per Creare un Dizionario dei Dati\n\nIdentificare le variabili: Elencare tutte le variabili presenti nel dataset.\nDescrivere ogni variabile: Per ciascuna variabile, definire il tipo (ad esempio, integer, numeric, character), il range di valori accettabili o le categorie, e fornire una descrizione chiara.\nSalvare il dizionario dei dati: Il dizionario può essere salvato in un file .csv o .xlsx per una facile consultazione.\n\n\n\n11.4.2 Esempio in R\nCreeremo un dizionario dei dati per un dataset di esempio e lo salveremo sia in formato CSV che Excel.\n\nlibrary(tibble)\nlibrary(readr)\nlibrary(writexl)\n\n# Creazione del Dizionario dei Dati\ndata_dict &lt;- tibble(\n  `Variable Name` = c(\n    \"stu_id\",\n    \"svy_date\",\n    \"grade_level\",\n    \"math1\",\n    \"math2\",\n    \"math3\",\n    \"math4\"\n  ),\n  `Type` = c(\n    \"integer\",\n    \"datetime\",\n    \"integer\",\n    \"integer\",\n    \"integer\",\n    \"numeric\",\n    \"numeric\"\n  ),\n  `Description` = c(\n    \"Student ID\",\n    \"Survey Date\",\n    \"Grade Level\",\n    \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\"\n  ),\n  `Range/Values` = c(\n    \"1347-1399\",\n    \"2023-02-13 to 2023-02-14\",\n    \"9-12\",\n    \"1-4\",\n    \"1-4\",\n    \"1.0-4.0 (NA allowed)\",\n    \"1.0-4.0 (NA allowed)\"\n  )\n)\n\n# Visualizza il Dizionario dei Dati\nprint(data_dict)\n\n# Salva il Dizionario dei Dati in un file CSV\nwrite_csv(data_dict, \"data_dictionary.csv\")\n\n# Salva il Dizionario dei Dati in un file Excel\nwrite_xlsx(data_dict, \"data_dictionary.xlsx\")\n\nOutput Atteso: file CSV (data_dictionary.csv).\n\n\n\n\n\n\n\n\n\nVariable Name\nType\nDescription\nRange/Values\n\n\n\n\nstu_id\ninteger\nStudent ID\n1347-1399\n\n\nsvy_date\ndatetime\nSurvey Date\n2023-02-13 to 2023-02-14\n\n\ngrade_level\ninteger\nGrade Level\n9-12\n\n\nmath1\ninteger\nMath Response 1 (1: Strongly Disagree, 4: Strongly Agree)\n1-4\n\n\nmath2\ninteger\nMath Response 2 (1: Strongly Disagree, 4: Strongly Agree)\n1-4\n\n\nmath3\nnumeric\nMath Response 3 (1: Strongly Disagree, 4: Strongly Agree)\n1.0-4.0 (NA allowed)\n\n\nmath4\nnumeric\nMath Response 4 (1: Strongly Disagree, 4: Strongly Agree)\n1.0-4.0 (NA allowed)\n\n\n\n\nDocumentazione: Il dizionario dei dati offre una descrizione chiara e standardizzata, utile per analisi successive e per la condivisione del dataset.\nSalvataggio multiplo: I formati .csv e .xlsx garantiscono la massima compatibilità con altri software e sistemi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#guide-di-stile",
    "href": "chapters/eda/02_data_cleaning.html#guide-di-stile",
    "title": "11  Flusso di lavoro per la pulizia dei dati",
    "section": "11.5 Guide di Stile",
    "text": "11.5 Guide di Stile\nLe guide di stile possono essere applicate a diversi aspetti di un progetto di analisi dei dati, non soltanto al dizionario dei dati. Un’ottima introduzione alle regole di stile per un progetto di analisi dei dati è fornita in questo capitolo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "href": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "title": "11  Flusso di lavoro per la pulizia dei dati",
    "section": "11.6 Riflessioni Conclusive",
    "text": "11.6 Riflessioni Conclusive\nNel processo di analisi dei dati, la fase di pulizia e pre-elaborazione è cruciale per garantire la qualità e l’integrità dei risultati finali. Sebbene questa fase possa sembrare meno interessante rispetto all’analisi vera e propria, essa costituisce la base su cui si costruiscono tutte le successive elaborazioni e interpretazioni. Attraverso una serie di passaggi strutturati, come quelli illustrati in questo capitolo, è possibile trasformare dati grezzi e disordinati in un dataset pulito, coerente e pronto per l’analisi. La cura nella gestione dei dati, dalla rimozione di duplicati alla creazione di un dizionario dei dati, è fondamentale per ottenere risultati affidabili e riproducibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "title": "11  Flusso di lavoro per la pulizia dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pointblank_0.12.2 haven_2.5.4       labelled_2.13.0   mice_3.16.0      \n#&gt;  [5] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [9] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt; [13] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [17] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [21] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [25] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1      rlang_1.1.4       magrittr_2.0.3    compiler_4.4.2   \n#&gt;  [5] vctrs_0.6.5       pkgconfig_2.0.3   shape_1.4.6.1     fastmap_1.2.0    \n#&gt;  [9] backports_1.5.0   utf8_1.2.4        promises_1.3.1    blastula_0.3.5   \n#&gt; [13] rmarkdown_2.29    tzdb_0.4.0        nloptr_2.1.1      xfun_0.49        \n#&gt; [17] glmnet_4.1-8      jomo_2.7-6        jsonlite_1.8.9    later_1.4.0      \n#&gt; [21] pan_1.9           broom_1.0.7       parallel_4.4.2    R6_2.5.1         \n#&gt; [25] stringi_1.8.4     car_3.1-3         boot_1.3-31       rpart_4.1.23     \n#&gt; [29] Rcpp_1.0.13-1     iterators_1.0.14  base64enc_0.1-3   pacman_0.5.1     \n#&gt; [33] R.utils_2.12.3    httpuv_1.6.15     Matrix_1.7-1      splines_4.4.2    \n#&gt; [37] nnet_7.3-19       timechange_0.3.0  tidyselect_1.2.1  abind_1.4-8      \n#&gt; [41] yaml_2.3.10       codetools_0.2-20  miniUI_0.1.1.1    lattice_0.22-6   \n#&gt; [45] shiny_1.9.1       withr_3.0.2       evaluate_1.0.1    survival_3.7-0   \n#&gt; [49] xml2_1.3.6        pillar_1.9.0      carData_3.0-5     foreach_1.5.2    \n#&gt; [53] generics_0.1.3    rprojroot_2.0.4   hms_1.1.3         commonmark_1.9.2 \n#&gt; [57] munsell_0.5.1     minqa_1.2.8       xtable_1.8-4      glue_1.8.0       \n#&gt; [61] tools_4.4.2       data.table_1.16.2 lme4_1.1-35.5     ggsignif_0.6.4   \n#&gt; [65] grid_4.4.2        colorspace_2.1-1  nlme_3.1-166      Formula_1.2-5    \n#&gt; [69] cli_3.6.3         fansi_1.0.6       gt_0.11.1         gtable_0.3.6     \n#&gt; [73] R.methodsS3_1.8.2 rstatix_0.7.2     sass_0.4.9.9000   digest_0.6.37    \n#&gt; [77] htmlwidgets_1.6.4 farver_2.1.2      R.oo_1.27.0       htmltools_0.5.8.1\n#&gt; [81] lifecycle_1.0.4   mitml_0.4-5       mime_0.12",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#bibliografia",
    "href": "chapters/eda/02_data_cleaning.html#bibliografia",
    "title": "11  Flusso di lavoro per la pulizia dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBuchanan, E. M., Crain, S. E., Cunningham, A. L., Johnson, H. R., Stash, H., Papadatou-Pastou, M., Isager, P. M., Carlsson, R., & Aczel, B. (2021). Getting started creating data dictionaries: How to create a shareable data set. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920928007.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html",
    "href": "chapters/eda/03_dplyr.html",
    "title": "12  Data wrangling",
    "section": "",
    "text": "12.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nL’obiettivo di questo capitolo è fornire un’introduzione alle funzioni principali del linguaggio R per le operazioni di data wrangling, cioè per il preprocessing e la pulizia dei dati. In R, queste operazioni sono strettamente legate al concetto di “data tidying”, che si riferisce all’organizzazione sistematica dei dati per facilitare l’analisi.\nPer comprendere meglio il concetto di “data tidying”, possiamo rifarci a una citazione tratta dal testo di riferimento R for Data Science (2e):\nL’essenza del “data tidying” è organizzare i dati in un formato che sia facile da gestire e analizzare. Anche se gli stessi dati possono essere rappresentati in vari modi, non tutte le rappresentazioni sono ugualmente efficienti o facili da usare. Un dataset “tidy” segue tre principi fondamentali che lo rendono particolarmente pratico:\nI pacchetti R come dplyr, ggplot2 e gli altri pacchetti del tidyverse sono progettati specificamente per lavorare con dati in formato “tidy”, permettendo agli utenti di eseguire operazioni di manipolazione e visualizzazione in modo più intuitivo ed efficiente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#introduzione",
    "href": "chapters/eda/03_dplyr.html#introduzione",
    "title": "12  Data wrangling",
    "section": "",
    "text": "“Happy families are all alike; every unhappy family is unhappy in its own way.”\n— Leo Tolstoy\n\n\n“Tidy datasets are all alike, but every messy dataset is messy in its own way.”\n— Hadley Wickham\n\n\n\nOgni variabile è una colonna: ogni colonna nel dataset rappresenta una singola variabile.\nOgni osservazione è una riga: ogni riga nel dataset rappresenta un’unica osservazione.\nOgni valore è una cella: ogni cella del dataset contiene un singolo valore.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#pipe",
    "href": "chapters/eda/03_dplyr.html#pipe",
    "title": "12  Data wrangling",
    "section": "12.2 Pipe",
    "text": "12.2 Pipe\nSia il pacchetto tidyr che il pacchetto dplyr utilizzano l’operatore pipe, che in R può essere rappresentato da due notazioni principali: |&gt; (introdotto nativamente in R a partire dalla versione 4.1.0) e %&gt;% (introdotto dal pacchetto magrittr, ampiamente utilizzato in tidyverse). Entrambi gli operatori permettono di concatenare in modo efficiente una serie di operazioni, ma presentano alcune differenze che meritano attenzione.\n\n12.2.1 Cosa Fa la Pipe?\nLa pipe è uno strumento potente che permette di collegare in modo diretto l’output di una funzione come input della funzione successiva. Questo approccio:\n\nRiduce la necessità di creare variabili intermedie.\nMigliora la leggibilità del codice.\nRende il flusso delle operazioni più chiaro e lineare.\n\nOgni funzione applicata con la pipe riceve automaticamente l’output della funzione precedente come suo primo argomento. Ciò consente di scrivere sequenze di operazioni in un formato compatto e intuitivo.\nEcco un esempio pratico:\n\n# Utilizzo della pipe per trasformare un dataset\nlibrary(dplyr)\n\ndf &lt;- data.frame(\n  id = 1:5,\n  value = c(10, 20, 30, 40, 50)\n)\n\n# Filtra i dati, seleziona colonne e calcola nuovi valori\ndf_clean &lt;- df |&gt;\n  dplyr::filter(value &gt; 20) |&gt;\n  dplyr::select(id, value) |&gt;\n  mutate(squared_value = value^2)\n\nIn questa sequenza, il dataset originale df viene filtrato, le colonne desiderate vengono selezionate e viene aggiunta una nuova colonna con il valore al quadrato.\n\nhead(df_clean)\n#&gt;   id value squared_value\n#&gt; 1  3    30           900\n#&gt; 2  4    40          1600\n#&gt; 3  5    50          2500\n\nIn sintesi, la pipe è uno strumento fondamentale per scrivere codice R moderno e leggibile, indipendentemente dal fatto che si utilizzi |&gt; o %&gt;%.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#verbi",
    "href": "chapters/eda/03_dplyr.html#verbi",
    "title": "12  Data wrangling",
    "section": "12.3 Verbi",
    "text": "12.3 Verbi\nLe funzioni principali (“verbi) di dplyr sono le seguenti:\n\n\n\n\n\n\n\nVerbo dplyr\nDescrizione\n\n\n\n\nselect()\nSeleziona colonne\n\n\nfilter()\nFiltra righe\n\n\narrange()\nRiordina o organizza le righe\n\n\nmutate()\nCrea nuove colonne\n\n\nsummarise()\nRiassume i valori\n\n\ngroup_by()\nConsente di eseguire operazioni di gruppo\n\n\n\nI verbi di dplyr sono suddivisi in quattro gruppi, in base all’elemento su cui operano: righe, colonne, gruppi o tabelle.\nInoltre, le diverse funzioni bind_ e _joins permettono di combinare più tibbles (ovvero, data frame) in uno solo.\nPer introdurre il processo di “data tidying”, in questo tutorial utilizzeremo il dataset msleep.\n\ndata(msleep)\ndim(msleep)\n#&gt; [1] 83 11\n\nEsaminiamo i dati:\n\nglimpse(msleep)\n#&gt; Rows: 83\n#&gt; Columns: 11\n#&gt; $ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater s…\n#&gt; $ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", \"…\n#&gt; $ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"c…\n#&gt; $ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", \"…\n#&gt; $ conservation &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"d…\n#&gt; $ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.0…\n#&gt; $ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0.…\n#&gt; $ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.1333333, 0.6666667, 0.7666667, 0.3833333…\n#&gt; $ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.0…\n#&gt; $ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.07000…\n#&gt; $ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, 0…\n\nLe colonne, nell’ordine, corrispondono a quanto segue:\n\n\n\nNome colonna\nDescrizione\n\n\n\n\nname\nNome comune\n\n\ngenus\nRango tassonomico\n\n\nvore\nCarnivoro, onnivoro o erbivoro?\n\n\norder\nRango tassonomico\n\n\nconservation\nStato di conservazione del mammifero\n\n\nsleep_total\nQuantità totale di sonno, in ore\n\n\nsleep_rem\nSonno REM, in ore\n\n\nsleep_cycle\nDurata del ciclo di sonno, in ore\n\n\nawake\nQuantità di tempo trascorso sveglio, in ore\n\n\nbrainwt\nPeso del cervello, in chilogrammi\n\n\nbodywt\nPeso corporeo, in chilogrammi",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#righe",
    "href": "chapters/eda/03_dplyr.html#righe",
    "title": "12  Data wrangling",
    "section": "12.4 Righe",
    "text": "12.4 Righe\nI verbi più importanti che operano sulle righe di un dataset sono filter(), che seleziona le righe da includere senza modificarne l’ordine, e arrange(), che cambia l’ordine delle righe senza alterare la selezione delle righe presenti.\n\nmsleep |&gt;\n    dplyr::filter(sleep_total &lt; 4) |&gt;\n    arrange(sleep_total)\n#&gt; # A tibble: 9 × 11\n#&gt;   name            genus         vore  order          conservation sleep_total\n#&gt;   &lt;chr&gt;           &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 Giraffe         Giraffa       herbi Artiodactyla   cd                   1.9\n#&gt; 2 Pilot whale     Globicephalus carni Cetacea        cd                   2.7\n#&gt; 3 Horse           Equus         herbi Perissodactyla domesticated         2.9\n#&gt; 4 Roe deer        Capreolus     herbi Artiodactyla   lc                   3  \n#&gt; 5 Donkey          Equus         herbi Perissodactyla domesticated         3.1\n#&gt; 6 African elepha… Loxodonta     herbi Proboscidea    vu                   3.3\n#&gt; # ℹ 3 more rows\n#&gt; # ℹ 5 more variables: sleep_rem &lt;dbl&gt;, sleep_cycle &lt;dbl&gt;, awake &lt;dbl&gt;, …\n\nPossiamo usare filter() speficicano più di una condizione logica.\n\nmsleep |&gt;\n    dplyr::filter((sleep_total &lt; 4 & bodywt &gt; 100) | brainwt &gt; 1) |&gt;\n    arrange(sleep_total)\n#&gt; # A tibble: 7 × 11\n#&gt;   name            genus         vore  order          conservation sleep_total\n#&gt;   &lt;chr&gt;           &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 Giraffe         Giraffa       herbi Artiodactyla   cd                   1.9\n#&gt; 2 Pilot whale     Globicephalus carni Cetacea        cd                   2.7\n#&gt; 3 Horse           Equus         herbi Perissodactyla domesticated         2.9\n#&gt; 4 Donkey          Equus         herbi Perissodactyla domesticated         3.1\n#&gt; 5 African elepha… Loxodonta     herbi Proboscidea    vu                   3.3\n#&gt; 6 Asian elephant  Elephas       herbi Proboscidea    en                   3.9\n#&gt; # ℹ 1 more row\n#&gt; # ℹ 5 more variables: sleep_rem &lt;dbl&gt;, sleep_cycle &lt;dbl&gt;, awake &lt;dbl&gt;, …",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#colonne",
    "href": "chapters/eda/03_dplyr.html#colonne",
    "title": "12  Data wrangling",
    "section": "12.5 Colonne",
    "text": "12.5 Colonne\nEsistono quattro verbi principali che modificano le colonne di un dataset senza cambiare le righe:\n\nrelocate() cambia la posizione delle colonne;\nrename() modifica i nomi delle colonne;\nselect() seleziona le colonne da includere o escludere;\nmutate() crea nuove colonne a partire da quelle esistenti.\n\n\nmsleep2 &lt;- msleep |&gt;\n    mutate(\n        rem_prop = sleep_rem / sleep_total * 100\n    ) |&gt;\n    dplyr::select(name, vore, rem_prop, sleep_total) |&gt;\n    arrange(desc(rem_prop))\n\nglimpse(msleep2)\n#&gt; Rows: 83\n#&gt; Columns: 4\n#&gt; $ name        &lt;chr&gt; \"European hedgehog\", \"Thick-tailed opposum\", \"Giant arm…\n#&gt; $ vore        &lt;chr&gt; \"omni\", \"carni\", \"insecti\", \"omni\", \"carni\", \"omni\", \"o…\n#&gt; $ rem_prop    &lt;dbl&gt; 34.65347, 34.02062, 33.70166, 29.21348, 28.71287, 27.22…\n#&gt; $ sleep_total &lt;dbl&gt; 10.1, 19.4, 18.1, 8.9, 10.1, 18.0, 9.1, 10.3, 12.5, 8.4…\n\nIn questo esempio, utilizziamo mutate() per creare una nuova colonna rem_prop che rappresenta la percentuale di sonno REM sul totale del sonno. Successivamente, select() viene utilizzato per scegliere solo alcune colonne del dataset, e infine desc(rem_prop) ordina i valori di rem_prop in ordine decrescente, dal valore maggiore a quello minore.\nPer cambiare il nome di una colonna possiamo usare rename(). Inoltre, possiamo cambiare l’ordine delle variabili con relocate().\n\nmsleep2 |&gt;\n    rename(rem_perc = rem_prop) |&gt;\n    relocate(rem_perc, .before = name)\n#&gt; # A tibble: 83 × 4\n#&gt;   rem_perc name                   vore    sleep_total\n#&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;         &lt;dbl&gt;\n#&gt; 1     34.7 European hedgehog      omni           10.1\n#&gt; 2     34.0 Thick-tailed opposum   carni          19.4\n#&gt; 3     33.7 Giant armadillo        insecti        18.1\n#&gt; 4     29.2 Tree shrew             omni            8.9\n#&gt; 5     28.7 Dog                    carni          10.1\n#&gt; 6     27.2 North American Opossum omni           18  \n#&gt; # ℹ 77 more rows",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#gruppi",
    "href": "chapters/eda/03_dplyr.html#gruppi",
    "title": "12  Data wrangling",
    "section": "12.6 Gruppi",
    "text": "12.6 Gruppi\nIl verbo group_by() viene utilizzato per suddividere un dataset in gruppi, in base a una o più variabili, che siano rilevanti per l’analisi. Questo permette di eseguire operazioni di sintesi su ciascun gruppo separatamente, ottenendo informazioni aggregate.\nAd esempio, nel codice seguente:\n\nmsleep |&gt;\n    group_by(order) |&gt;\n    summarise(\n        avg_sleep = mean(sleep_total),\n        min_sleep = min(sleep_total),\n        max_sleep = max(sleep_total),\n        total = n()\n    ) |&gt;\n    arrange(desc(avg_sleep))\n#&gt; # A tibble: 19 × 5\n#&gt;   order           avg_sleep min_sleep max_sleep total\n#&gt;   &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Chiroptera           19.8      19.7      19.9     2\n#&gt; 2 Didelphimorphia      18.7      18        19.4     2\n#&gt; 3 Cingulata            17.8      17.4      18.1     2\n#&gt; 4 Afrosoricida         15.6      15.6      15.6     1\n#&gt; 5 Pilosa               14.4      14.4      14.4     1\n#&gt; 6 Rodentia             12.5       7        16.6    22\n#&gt; # ℹ 13 more rows\n\n\ngroup_by(order) suddivide il dataset msleep in gruppi, ciascuno corrispondente a un valore distinto della variabile order.\nSuccessivamente, summarise() calcola diverse statistiche per ogni gruppo:\n\navg_sleep è la media del totale del sonno (sleep_total) all’interno di ciascun gruppo.\nmin_sleep è il valore minimo di sleep_total in ogni gruppo.\nmax_sleep è il valore massimo di sleep_total in ogni gruppo.\ntotal è il numero di osservazioni (o righe) per ciascun gruppo, calcolato con la funzione n().\n\nInfine, arrange(desc(avg_sleep)) ordina i risultati in ordine decrescente in base alla media del sonno totale (avg_sleep), mostrando prima i gruppi con la media di sonno più alta.\n\nQuesto tipo di approccio è utile quando si vuole analizzare come cambiano le caratteristiche dei dati a seconda dei gruppi specifici, fornendo una visione più dettagliata e significativa.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#dati-mancanti",
    "href": "chapters/eda/03_dplyr.html#dati-mancanti",
    "title": "12  Data wrangling",
    "section": "12.7 Dati mancanti",
    "text": "12.7 Dati mancanti\nNel dataset ci sono celle che contengono valori mancanti, indicati come NA. Questi rappresentano misurazioni per le quali i dati non sono stati registrati.\nPer ottenere una panoramica dei dati, inclusi i valori mancanti, possiamo utilizzare il comando:\n\nsummary(msleep)\n#&gt;      name              genus               vore              order          \n#&gt;  Length:83          Length:83          Length:83          Length:83         \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;  conservation        sleep_total      sleep_rem      sleep_cycle    \n#&gt;  Length:83          Min.   : 1.90   Min.   :0.100   Min.   :0.1167  \n#&gt;  Class :character   1st Qu.: 7.85   1st Qu.:0.900   1st Qu.:0.1833  \n#&gt;  Mode  :character   Median :10.10   Median :1.500   Median :0.3333  \n#&gt;                     Mean   :10.43   Mean   :1.875   Mean   :0.4396  \n#&gt;                     3rd Qu.:13.75   3rd Qu.:2.400   3rd Qu.:0.5792  \n#&gt;                     Max.   :19.90   Max.   :6.600   Max.   :1.5000  \n#&gt;                                     NA's   :22      NA's   :51      \n#&gt;      awake          brainwt            bodywt        \n#&gt;  Min.   : 4.10   Min.   :0.00014   Min.   :   0.005  \n#&gt;  1st Qu.:10.25   1st Qu.:0.00290   1st Qu.:   0.174  \n#&gt;  Median :13.90   Median :0.01240   Median :   1.670  \n#&gt;  Mean   :13.57   Mean   :0.28158   Mean   : 166.136  \n#&gt;  3rd Qu.:16.15   3rd Qu.:0.12550   3rd Qu.:  41.750  \n#&gt;  Max.   :22.10   Max.   :5.71200   Max.   :6654.000  \n#&gt;                  NA's   :27\n\nPer visualizzare il pattern di dati mancanti, ovvero come la mancanza di una variabile possa influenzare la mancanza di altre, si può usare:\n\nmd.pattern(msleep, rotate.names = TRUE)\n#&gt;    name genus order sleep_total awake bodywt vore sleep_rem brainwt\n#&gt; 20    1     1     1           1     1      1    1         1       1\n#&gt; 9     1     1     1           1     1      1    1         1       1\n#&gt; 9     1     1     1           1     1      1    1         1       1\n#&gt; 5     1     1     1           1     1      1    1         1       1\n#&gt; 1     1     1     1           1     1      1    1         1       0\n#&gt; 10    1     1     1           1     1      1    1         1       0\n#&gt; 1     1     1     1           1     1      1    1         1       0\n#&gt; 1     1     1     1           1     1      1    1         1       0\n#&gt; 5     1     1     1           1     1      1    1         0       1\n#&gt; 3     1     1     1           1     1      1    1         0       1\n#&gt; 7     1     1     1           1     1      1    1         0       0\n#&gt; 5     1     1     1           1     1      1    1         0       0\n#&gt; 2     1     1     1           1     1      1    0         1       1\n#&gt; 1     1     1     1           1     1      1    0         1       1\n#&gt; 2     1     1     1           1     1      1    0         1       1\n#&gt; 2     1     1     1           1     1      1    0         0       0\n#&gt;       0     0     0           0     0      0    7        22      27\n#&gt;    conservation sleep_cycle    \n#&gt; 20            1           1   0\n#&gt; 9             1           0   1\n#&gt; 9             0           1   1\n#&gt; 5             0           0   2\n#&gt; 1             1           1   1\n#&gt; 10            1           0   2\n#&gt; 1             0           1   2\n#&gt; 1             0           0   3\n#&gt; 5             1           0   2\n#&gt; 3             0           0   3\n#&gt; 7             1           0   3\n#&gt; 5             0           0   4\n#&gt; 2             1           0   2\n#&gt; 1             0           1   2\n#&gt; 2             0           0   3\n#&gt; 2             0           0   5\n#&gt;              29          51 136\n\n\n\n\n\n\n\n\nIl modo più semplice per gestire i valori mancanti è l’analisi dei casi completi (complete case analysis), che esclude dall’analisi le osservazioni con valori mancanti e utilizza solo quelle con tutte le variabili registrate. Questo approccio può essere implementato come segue:\n\nmsleep_comp &lt;- msleep |&gt;\n    drop_na()\ndim(msleep_comp)\n#&gt; [1] 20 11\n\nTuttavia, per il dataset in questione, questa strategia non è adeguata, poiché si passa da 83 osservazioni iniziali a solo 20 righe dopo aver eliminato i dati mancanti.\nUn approccio più utile è l’utilizzo di metodi di imputazione (imputation methods). Uno di questi è l’imputazione semplice (single imputation, SI), dove il valore mancante viene sostituito dalla media della variabile corrispondente. Questo tipo di imputazione può essere eseguito come segue:\n\nimp &lt;- mice(msleep, method = \"mean\", m = 1, maxit = 1, print = FALSE)\n#&gt; Warning: Number of logged events: 6\ncomplete(imp) |&gt;\n    summary()\n#&gt;      name              genus               vore              order          \n#&gt;  Length:83          Length:83          Length:83          Length:83         \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;  conservation        sleep_total      sleep_rem      sleep_cycle    \n#&gt;  Length:83          Min.   : 1.90   Min.   :0.100   Min.   :0.1167  \n#&gt;  Class :character   1st Qu.: 7.85   1st Qu.:1.150   1st Qu.:0.4167  \n#&gt;  Mode  :character   Median :10.10   Median :1.875   Median :0.4396  \n#&gt;                     Mean   :10.43   Mean   :1.875   Mean   :0.4396  \n#&gt;                     3rd Qu.:13.75   3rd Qu.:2.200   3rd Qu.:0.4396  \n#&gt;                     Max.   :19.90   Max.   :6.600   Max.   :1.5000  \n#&gt;      awake          brainwt            bodywt        \n#&gt;  Min.   : 4.10   Min.   :0.00014   Min.   :   0.005  \n#&gt;  1st Qu.:10.25   1st Qu.:0.00635   1st Qu.:   0.174  \n#&gt;  Median :13.90   Median :0.11500   Median :   1.670  \n#&gt;  Mean   :13.57   Mean   :0.28158   Mean   : 166.136  \n#&gt;  3rd Qu.:16.15   3rd Qu.:0.28158   3rd Qu.:  41.750  \n#&gt;  Max.   :22.10   Max.   :5.71200   Max.   :6654.000\n\nTuttavia, uno dei problemi dell’imputazione media è che tende a ridurre la varianza e a rendere le stime dell’errore standard meno accurate, generando bias verso il basso.\nUn metodo più sofisticato è l’imputazione multipla (multiple imputation, MI). Questa tecnica genera più imputazioni, creando diversi dataset completi. Per ciascuno di questi dataset, è possibile effettuare l’analisi desiderata e, al termine, combinare i risultati ottenuti dai vari dataset imputati per ottenere un risultato finale più robusto. Un esempio di questa tecnica utilizza il metodo di predictive mean matching (metodo = “pmm”), che sfrutta i valori vicini nei dati come imputazioni:\n\nimp2 &lt;- mice(msleep, method = \"pmm\", m = 1, maxit = 100, print = FALSE)\n#&gt; Warning: Number of logged events: 6\ncomplete(imp2) |&gt;\n    summary()\n#&gt;      name              genus               vore              order          \n#&gt;  Length:83          Length:83          Length:83          Length:83         \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;  conservation        sleep_total      sleep_rem      sleep_cycle    \n#&gt;  Length:83          Min.   : 1.90   Min.   :0.100   Min.   :0.1167  \n#&gt;  Class :character   1st Qu.: 7.85   1st Qu.:0.900   1st Qu.:0.1833  \n#&gt;  Mode  :character   Median :10.10   Median :1.500   Median :0.3333  \n#&gt;                     Mean   :10.43   Mean   :1.843   Mean   :0.4502  \n#&gt;                     3rd Qu.:13.75   3rd Qu.:2.400   3rd Qu.:0.6667  \n#&gt;                     Max.   :19.90   Max.   :6.600   Max.   :1.5000  \n#&gt;      awake          brainwt            bodywt        \n#&gt;  Min.   : 4.10   Min.   :0.00014   Min.   :   0.005  \n#&gt;  1st Qu.:10.25   1st Qu.:0.00260   1st Qu.:   0.174  \n#&gt;  Median :13.90   Median :0.01210   Median :   1.670  \n#&gt;  Mean   :13.57   Mean   :0.23634   Mean   : 166.136  \n#&gt;  3rd Qu.:16.15   3rd Qu.:0.13600   3rd Qu.:  41.750  \n#&gt;  Max.   :22.10   Max.   :5.71200   Max.   :6654.000\n\nL’imputazione multipla, grazie alla sua capacità di considerare la variabilità tra le diverse imputazioni, fornisce stime più accurate rispetto all’imputazione media semplice, riducendo il rischio di bias e fornendo risultati più affidabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#considerazioni-conclusive",
    "href": "chapters/eda/03_dplyr.html#considerazioni-conclusive",
    "title": "12  Data wrangling",
    "section": "12.8 Considerazioni Conclusive",
    "text": "12.8 Considerazioni Conclusive\nIl data wrangling è una delle fasi più importanti in qualsiasi pipeline di analisi dei dati. In questo capitolo abbiamo introdotto l’uso del pacchetto tidyverse di R per la manipolazione dei dati e il suo utilizzo in scenari di base. Tuttavia, il tidyverse è un ecosistema ampio e qui abbiamo trattato solo gli elementi fondamentali. Per approfondire, si consiglia di consultare ulteriori risorse come quelle disponibili sul sito web del tidyverse e il libro R for Data Science (2e), di cui esiste anche una traduzione italiana.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/03_dplyr.html#informazioni-sullambiente-di-sviluppo",
    "title": "12  Data wrangling",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] missForest_1.5    mice_3.16.0       MASS_7.3-61       viridis_0.6.5    \n#&gt;  [5] viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3    \n#&gt;  [9] patchwork_1.3.0   bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0     \n#&gt; [13] markdown_1.13     knitr_1.49        lubridate_1.9.3   forcats_1.0.0    \n#&gt; [17] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n#&gt; [21] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#&gt; [25] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         rlang_1.1.4          magrittr_2.0.3      \n#&gt;  [4] compiler_4.4.2       vctrs_0.6.5          pkgconfig_2.0.3     \n#&gt;  [7] shape_1.4.6.1        fastmap_1.2.0        backports_1.5.0     \n#&gt; [10] utf8_1.2.4           promises_1.3.1       rmarkdown_2.29      \n#&gt; [13] tzdb_0.4.0           nloptr_2.1.1         itertools_0.1-3     \n#&gt; [16] xfun_0.49            glmnet_4.1-8         jomo_2.7-6          \n#&gt; [19] randomForest_4.7-1.2 jsonlite_1.8.9       later_1.4.0         \n#&gt; [22] pan_1.9              broom_1.0.7          parallel_4.4.2      \n#&gt; [25] R6_2.5.1             stringi_1.8.4        car_3.1-3           \n#&gt; [28] boot_1.3-31          rpart_4.1.23         Rcpp_1.0.13-1       \n#&gt; [31] iterators_1.0.14     pacman_0.5.1         httpuv_1.6.15       \n#&gt; [34] Matrix_1.7-1         splines_4.4.2        nnet_7.3-19         \n#&gt; [37] timechange_0.3.0     tidyselect_1.2.1     abind_1.4-8         \n#&gt; [40] yaml_2.3.10          codetools_0.2-20     miniUI_0.1.1.1      \n#&gt; [43] doRNG_1.8.6          lattice_0.22-6       shiny_1.9.1         \n#&gt; [46] withr_3.0.2          evaluate_1.0.1       survival_3.7-0      \n#&gt; [49] pillar_1.9.0         carData_3.0-5        rngtools_1.5.2      \n#&gt; [52] foreach_1.5.2        generics_0.1.3       rprojroot_2.0.4     \n#&gt; [55] hms_1.1.3            munsell_0.5.1        minqa_1.2.8         \n#&gt; [58] xtable_1.8-4         glue_1.8.0           tools_4.4.2         \n#&gt; [61] lme4_1.1-35.5        ggsignif_0.6.4       grid_4.4.2          \n#&gt; [64] colorspace_2.1-1     nlme_3.1-166         Formula_1.2-5       \n#&gt; [67] cli_3.6.3            fansi_1.0.6          gtable_0.3.6        \n#&gt; [70] rstatix_0.7.2        digest_0.6.37        htmlwidgets_1.6.4   \n#&gt; [73] farver_2.1.2         htmltools_0.5.8.1    lifecycle_1.0.4     \n#&gt; [76] mitml_0.4-5          mime_0.12",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html",
    "href": "chapters/eda/04_exploring_qualitative_data.html",
    "title": "13  Esplorare i dati qualitativi",
    "section": "",
    "text": "13.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nIn questo capitolo ci concentreremo sull’analisi dei dati qualitativi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "href": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "title": "13  Esplorare i dati qualitativi",
    "section": "13.2 Il dataset penguins",
    "text": "13.2 Il dataset penguins\nPer fornire esempi pratici, in questo capitolo utilizzeremo il dataset palmerpenguins, messo a disposizione da Allison Horst. I dati sono stati raccolti e resi disponibili da Dr. Kristen Gorman e dalla Palmer Station, parte del programma di ricerca ecologica a lungo termine Long Term Ecological Research Network. Il dataset contiene informazioni su 344 pinguini, appartenenti a 3 diverse specie, raccolte su 3 isole dell’arcipelago di Palmer, in Antartide. Per semplicità, i dati sono organizzati nel file penguins.csv.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "href": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "title": "13  Esplorare i dati qualitativi",
    "section": "13.3 Importare i Dati",
    "text": "13.3 Importare i Dati\nPossiamo caricare i dati grezzi dal file penguins.csv in un DataFrame con il seguente comando:\n\nd &lt;- rio::import(here::here(\"data\", \"penguins.csv\"))\n\nEsaminiamo i dati.\n\nglimpse(d)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;chr&gt; \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\",…\n#&gt; $ island            &lt;chr&gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen…\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.…\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.…\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, …\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 347…\n#&gt; $ sex               &lt;chr&gt; \"male\", \"female\", \"female\", NA, \"female\", \"male\",…\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2…\n\n\nd |&gt; \n  head()\n#&gt;   species    island bill_length_mm bill_depth_mm flipper_length_mm\n#&gt; 1  Adelie Torgersen           39.1          18.7               181\n#&gt; 2  Adelie Torgersen           39.5          17.4               186\n#&gt; 3  Adelie Torgersen           40.3          18.0               195\n#&gt; 4  Adelie Torgersen             NA            NA                NA\n#&gt; 5  Adelie Torgersen           36.7          19.3               193\n#&gt; 6  Adelie Torgersen           39.3          20.6               190\n#&gt;   body_mass_g    sex year\n#&gt; 1        3750   male 2007\n#&gt; 2        3800 female 2007\n#&gt; 3        3250 female 2007\n#&gt; 4          NA   &lt;NA&gt; 2007\n#&gt; 5        3450 female 2007\n#&gt; 6        3650   male 2007\n\nPer semplicità, rimuoviamo le righe con valori mancanti con la seguente istruzione:\n\ndf &lt;- d |&gt;\n  drop_na()\n\n\ndf |&gt; \n  summary()\n#&gt;    species             island          bill_length_mm  bill_depth_mm  \n#&gt;  Length:333         Length:333         Min.   :32.10   Min.   :13.10  \n#&gt;  Class :character   Class :character   1st Qu.:39.50   1st Qu.:15.60  \n#&gt;  Mode  :character   Mode  :character   Median :44.50   Median :17.30  \n#&gt;                                        Mean   :43.99   Mean   :17.16  \n#&gt;                                        3rd Qu.:48.60   3rd Qu.:18.70  \n#&gt;                                        Max.   :59.60   Max.   :21.50  \n#&gt;  flipper_length_mm  body_mass_g       sex                 year     \n#&gt;  Min.   :172       Min.   :2700   Length:333         Min.   :2007  \n#&gt;  1st Qu.:190       1st Qu.:3550   Class :character   1st Qu.:2007  \n#&gt;  Median :197       Median :4050   Mode  :character   Median :2008  \n#&gt;  Mean   :201       Mean   :4207                      Mean   :2008  \n#&gt;  3rd Qu.:213       3rd Qu.:4775                      3rd Qu.:2009  \n#&gt;  Max.   :231       Max.   :6300                      Max.   :2009",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "href": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "title": "13  Esplorare i dati qualitativi",
    "section": "13.4 Tabelle di Contingenza",
    "text": "13.4 Tabelle di Contingenza\nUna tabella di contingenza è uno strumento utilizzato per riassumere i dati di due variabili categoriali, ovvero variabili qualitative che assumono valori all’interno di un insieme finito di categorie. In una tabella di contingenza, ogni cella mostra quante volte si è verificata una combinazione specifica di categorie per le due variabili considerate.\nPer esempio, se prendiamo in esame due variabili categoriali come “island” e “species” all’interno di un DataFrame df, ciascuna delle quali rappresenta rispettivamente l’isola di provenienza e la specie dei pinguini, possiamo costruire una tabella che mostra quante volte ciascuna combinazione di “island” e “species” appare nel nostro campione. In altre parole, la tabella di contingenza ci permette di vedere quante osservazioni ci sono per ogni combinazione di categorie tra queste due variabili.\n\ntable(df$island, df$species)\n#&gt;            \n#&gt;             Adelie Chinstrap Gentoo\n#&gt;   Biscoe        44         0    119\n#&gt;   Dream         55        68      0\n#&gt;   Torgersen     47         0      0\n\nQuesta tabella di contingenza mostra la distribuzione di tre specie di pinguini (Adelie, Chinstrap, Gentoo) rispetto a tre isole (Biscoe, Dream, Torgersen). Ogni cella rappresenta il numero di pinguini di una determinata specie presenti su ciascuna isola. Ecco un’interpretazione dettagliata:\n\nIsola Biscoe: Qui troviamo 44 pinguini della specie Adelie e 119 pinguini della specie Gentoo, mentre non sono presenti pinguini Chinstrap.\nIsola Dream: Questa isola ospita 55 pinguini Adelie e 68 pinguini Chinstrap, ma nessun pinguino della specie Gentoo.\nIsola Torgersen: Su quest’isola sono presenti solo 47 pinguini della specie Adelie, e nessun pinguino delle specie Chinstrap o Gentoo.\n\nPossiamo dunque commentare dicendo:\n\nLa specie Adelie è distribuita su tutte e tre le isole, con numeri notevoli sia su Biscoe (44), Dream (55), che Torgersen (47).\nLa specie Chinstrap si trova solo sull’isola Dream (68 esemplari) e non è presente sulle altre due isole.\nLa specie Gentoo si trova esclusivamente sull’isola Biscoe (119 esemplari), non essendo presente su Dream e Torgersen.\n\nQuesto suggerisce una distribuzione geografica specifica delle diverse specie di pinguini, con alcune specie limitate a determinate isole e altre distribuite più ampiamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "href": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "title": "13  Esplorare i dati qualitativi",
    "section": "13.5 Grafico a barre",
    "text": "13.5 Grafico a barre\n\n13.5.1 Grafico a Barre con una Singola Variabile\nUn grafico a barre è uno strumento comunemente utilizzato per rappresentare visivamente una singola variabile categoriale. Questo tipo di grafico mostra le diverse categorie su uno degli assi (solitamente l’asse orizzontale) e utilizza barre di altezza proporzionale per rappresentare la frequenza o il conteggio di ciascuna categoria sull’altro asse (solitamente l’asse verticale).\nAd esempio, in un dataset che contiene informazioni su diverse specie di pinguini, un grafico a barre potrebbe mostrare il numero di pinguini per ciascuna specie. Le specie vengono visualizzate come etichette lungo l’asse delle ascisse, mentre l’altezza delle barre rappresenta il numero di pinguini osservati per ciascuna specie.\nIl grafico a barre consente di confrontare le dimensioni delle categorie in modo semplice e intuitivo.\nPer i dati in esame, creiamo un grafico a barre che rappresenta il numero totale di pinguini per isola.\n\nggplot(df, aes(x = island)) +\n  geom_bar(alpha = 0.5) +\n  ggtitle(\"Numero totale di pinguini per isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\")\n\n\n\n\n\n\n\n\nUn secondo grafico a barre mostra il numero totale di pinguini per specie.\n\nggplot(df, aes(x = species)) +\n  geom_bar(alpha = 0.5) +\n  ggtitle(\"Numero totale di pinguini per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\")\n\n\n\n\n\n\n\n\n\n\n13.5.2 Grafico a Barre con Due Variabili\nÈ possibile visualizzare contemporaneamente le distribuzioni di due variabili categoriali utilizzando un grafico a barre. Questo tipo di grafico è particolarmente utile per esaminare la relazione tra due variabili categoriali.\nIn un grafico a barre con due variabili, una delle variabili viene rappresentata sull’asse orizzontale come categoria principale, mentre la seconda variabile è distinta tramite colori diversi o barre impilate. In questo modo, possiamo confrontare facilmente le frequenze o le proporzioni delle categorie della prima variabile, osservando allo stesso tempo come sono distribuite le categorie della seconda variabile all’interno di ciascuna categoria principale.\nAd esempio, visualizziamo il numero di pinguini per specie e isola. A qusto fine possiamo creare un grafico a barre dove le isole sono rappresentate sull’asse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle specie su ciascuna isola. Questo approccio consente di esplorare come le due variabili categoriali (specie e isola) interagiscono visivamente.\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"stack\") +\n  ggtitle(\"Numero di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Specie\")\n\n\n\n\n\n\n\n\nIn alternativa, è possibile creare un grafico a barre dove le specie sono rappresentate sull’asse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle isole per ciascuna specie.\n\nggplot(df, aes(x = species, fill = island)) +\n  geom_bar(position = \"stack\") +\n  ggtitle(\"Numero di pinguini per isola e specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Isola\")\n\n\n\n\n\n\n\n\nIn alternativa all’uso delle frequenze assolute, possiamo rappresentare i dati utilizzando le frequenze relative. Questo approccio permette di confrontare meglio le categorie indipendentemente dal numero totale di osservazioni. Nella figura seguente, ad esempio, viene mostrata la proporzione di pinguini di ciascuna specie per ogni isola, evidenziando la distribuzione relativa delle specie su ogni isola, anziché il conteggio assoluto. Questa rappresentazione aiuta a visualizzare le differenze nella composizione delle specie, anche se il numero complessivo di pinguini varia tra le isole.\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\") +\n  ggtitle(\"Proporzione di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Proporzione\") +\n  labs(fill = \"Specie\")",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "href": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "title": "13  Esplorare i dati qualitativi",
    "section": "13.6 Mosaic plots",
    "text": "13.6 Mosaic plots\nIl Mosaic plot è una tecnica di visualizzazione particolarmente adatta per rappresentare tabelle di contingenza. Questo tipo di grafico somiglia a un grafico a barre impilate standard, ma con un vantaggio importante: oltre a visualizzare la suddivisione interna delle categorie, permette di vedere anche le dimensioni relative dei gruppi della variabile principale.\nIn altre parole, il Mosaic plot non solo mostra come si distribuiscono le categorie di una variabile secondaria all’interno di ogni gruppo della variabile principale, ma fornisce anche un’idea visiva della grandezza complessiva dei gruppi. Questo lo rende uno strumento utile per analizzare e interpretare le relazioni tra due variabili categoriali, evidenziando sia la proporzione all’interno di ciascun gruppo, sia la grandezza relativa tra i gruppi stessi.\n\nmosaic(~ species + island, data = df, main = \"Mosaic Plot of Species and Island\")",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "href": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "title": "13  Esplorare i dati qualitativi",
    "section": "13.7 Proporzioni di Riga e Colonna",
    "text": "13.7 Proporzioni di Riga e Colonna\nNelle sezioni precedenti abbiamo esaminato la visualizzazione di due variabili categoriali utilizzando grafici a barre e Mosaic plot. Tuttavia, non abbiamo ancora discusso come vengono calcolate le proporzioni mostrate in questi grafici. In questa sezione ci concentreremo sulla suddivisione frazionaria di una variabile rispetto a un’altra, esplorando come possiamo modificare la nostra tabella di contingenza per ottenere una visione più dettagliata delle proporzioni.\nQuesto ci permetterà di comprendere meglio le relazioni tra le due variabili, visualizzando non solo i conteggi assoluti, ma anche le proporzioni relative per riga o per colonna. Le proporzioni di riga mostrano la distribuzione di una variabile all’interno delle categorie di un’altra, mentre le proporzioni di colonna evidenziano la distribuzione inversa.\nCalcoliamo le proporzioni di specie per isola.\n\n# Calcola le proporzioni di riga\nrow_proportions &lt;- df |&gt; \n  count(island, species) |&gt; \n  group_by(island) |&gt; \n  mutate(proportion = n / sum(n)) |&gt; \n  pivot_wider(names_from = species, values_from = proportion, values_fill = 0)\n\n# Aggiungi una colonna \"Totale\" che rappresenta il totale di ciascuna riga\nrow_proportions_with_total &lt;- row_proportions |&gt; \n  mutate(Totale = rowSums(across(where(is.numeric))))\n\n# Mostra la tabella con proporzioni di riga e il totale\nprint(row_proportions_with_total)\n#&gt; # A tibble: 5 × 6\n#&gt; # Groups:   island [3]\n#&gt;   island        n Adelie Gentoo Chinstrap Totale\n#&gt;   &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 Biscoe       44  0.270  0         0       44.3\n#&gt; 2 Biscoe      119  0      0.730     0      120. \n#&gt; 3 Dream        55  0.447  0         0       55.4\n#&gt; 4 Dream        68  0      0         0.553   68.6\n#&gt; 5 Torgersen    47  1      0         0       48\n\nCalcoliamo nuovamente le proporzioni, ma questa volta in funzione delle colonne (per isola).\n\n# Calcola la tabella di contingenza\ncontingency_table &lt;- xtabs(~ island + species, data = df)\n\n# Calcola le proporzioni di colonna\ncolumn_proportions &lt;- prop.table(contingency_table, margin = 2)\n\n# Aggiungi una riga \"Totale\" con la somma di ciascuna colonna\ncolumn_proportions_with_total &lt;- rbind(\n  column_proportions, Totale = colSums(column_proportions)\n)\n\n# Mostra la tabella con proporzioni di colonna e il totale\nprint(column_proportions_with_total)\n#&gt;              Adelie Chinstrap Gentoo\n#&gt; Biscoe    0.3013699         0      1\n#&gt; Dream     0.3767123         1      0\n#&gt; Torgersen 0.3219178         0      0\n#&gt; Totale    1.0000000         1      1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "href": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "title": "13  Esplorare i dati qualitativi",
    "section": "13.8 Confronto tra Gruppi",
    "text": "13.8 Confronto tra Gruppi\nAlcune delle analisi più interessanti emergono confrontando i dati numerici tra diversi gruppi. In questa sezione approfondiremo alcune delle tecniche che abbiamo già esplorato per visualizzare i dati numerici di più gruppi su uno stesso grafico e introdurremo nuovi metodi per confrontare i dati numerici tra gruppi. Queste tecniche ci permetteranno di osservare meglio le differenze e le somiglianze tra gruppi, mettendo in evidenza tendenze, variazioni e altre caratteristiche rilevanti.\nQui consideriamo due variabili qualitative. Creiamo un grafico a barre per confrontare la distribuzione del genere per specie.\n\nggplot(df, aes(x = species, fill = sex)) +\n  geom_bar(position = \"dodge\") +\n  ggtitle(\"Distribuzione del genere per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Conteggio\")\n\n\n\n\n\n\n\n\nSpesso, i confronti più interessanti riguardano come una variabile numerica varia in base a una o più categorie. Questo tipo di analisi ci aiuta a capire differenze tra gruppi e a individuare modelli o tendenze.\nNel grafico seguente, confrontiamo la distribuzione del peso corporeo (body_mass_g) in base alla specie e al genere. Le aree colorate rappresentano come si distribuisce il peso per maschi e femmine all’interno di ciascuna specie. Le linee più strette al centro delle aree colorate aggiungono ulteriori dettagli, mostrando i valori più comuni e come si concentrano i dati per ciascun gruppo.\n\nggplot(df, aes(x = species, y = body_mass_g, fill = sex)) +\n  geom_violin(position = position_dodge(width = 0.9), alpha = 0.5) +\n  geom_boxplot(position = position_dodge(width = 0.9), width = 0.2, alpha = 0.8) +\n  ggtitle(\"Distribuzione della massa corporea\\nin base alla specie e al genere\") +\n  xlab(\"Specie\") +\n  ylab(\"Massa corporea (g)\") +\n  labs(fill = \"Genere\")\n\n\n\n\n\n\n\n\n\nAree colorate (grafico a violino):\n\nRappresentano l’intera distribuzione dei pesi per ogni gruppo (specie e genere). Più l’area è larga in un punto, maggiore è il numero di pinguini con quel peso.\n\nLinee strette al centro (boxplot):\n\nForniscono un riassunto visivo dei dati, mostrando dove i pesi si concentrano maggiormente e quanto variano all’interno di ciascun gruppo.\n\nCosa possiamo osservare:\n\nPossiamo vedere facilmente se i maschi e le femmine di una stessa specie tendono ad avere pesi simili o differenti, e se c’è una certa sovrapposizione tra i due gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "13  Esplorare i dati qualitativi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] vcd_1.4-13        MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] R.oo_1.27.0       pkgconfig_2.0.3   data.table_1.16.2 lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] carData_3.0-5     httpuv_1.6.15     htmltools_0.5.8.1 yaml_2.3.10      \n#&gt; [25] Formula_1.2-5     car_3.1-3         pillar_1.9.0      later_1.4.0      \n#&gt; [29] R.utils_2.12.3    abind_1.4-8       nlme_3.1-166      mime_0.12        \n#&gt; [33] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     labeling_0.4.3   \n#&gt; [37] rprojroot_2.0.4   fastmap_1.2.0     colorspace_2.1-1  cli_3.6.3        \n#&gt; [41] magrittr_2.0.3    utf8_1.2.4        broom_1.0.7       withr_3.0.2      \n#&gt; [45] backports_1.5.0   promises_1.3.1    timechange_0.3.0  rmarkdown_2.29   \n#&gt; [49] ggsignif_0.6.4    R.methodsS3_1.8.2 zoo_1.8-12        hms_1.1.3        \n#&gt; [53] shiny_1.9.1       evaluate_1.0.1    lmtest_0.9-40     miniUI_0.1.1.1   \n#&gt; [57] rlang_1.1.4       Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0       \n#&gt; [61] jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html",
    "href": "chapters/eda/05_exploring_numeric_data.html",
    "title": "14  Esplorare i dati numerici",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nIn questo capitolo ci concentreremo sull’analisi dei dati numerici. In particolare, esamineremo le distribuzioni di frequenza e i quantili, insieme alle tecniche di visualizzazione più comuni, come l’istogramma, l’istogramma smussato e il box-plot. Tratteremo sia gli aspetti computazionali che quelli interpretativi di queste misure, fornendo strumenti utili non solo per una comprensione personale, ma anche per la comunicazione efficace dei risultati, in particolare con chi utilizza questi dati per prendere decisioni pratiche nel mondo reale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "href": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "title": "14  Esplorare i dati numerici",
    "section": "14.1 I dati sulle aspettative negative nella depressione",
    "text": "14.1 I dati sulle aspettative negative nella depressione\nSupponimo di essere interessati alla distribuzione di una singola variabili quantitativa. Per fare un esempio, consideriamo i dati sulle aspettative negative come meccanismo chiave nel mantenimento della depressione (Zetsche et al., 2019). Importiamo i dati:\n\ndf = rio::import(here::here(\"data\", \"data.mood.csv\"))\n\nPer questo esercizio, ci concentreremo sulle colonne esm_id (il codice del soggetto), group (il gruppo) e bdi (il valore BDI-II).\n\ndf &lt;- df |&gt; \n  dplyr::select(\"esm_id\", \"group\", \"bdi\")\ndf |&gt; \n  head()\n#&gt;   esm_id group bdi\n#&gt; 1     10   mdd  25\n#&gt; 2     10   mdd  25\n#&gt; 3     10   mdd  25\n#&gt; 4     10   mdd  25\n#&gt; 5     10   mdd  25\n#&gt; 6     10   mdd  25\n\nSe elenchiamo le modalità presenti in group utilizzando il metodo unique(), scopriamo che corrispondono a mdd (pazienti) e ctl (controlli sani).\n\ndf$group |&gt; \n  unique()\n#&gt; [1] \"mdd\" \"ctl\"\n\nRimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:\n\ndf &lt;- df[!duplicated(df), ]\n\nVerifichiamo di avere ottenuto il risultato desiderato.\n\ndim(df)\n#&gt; [1] 67  3\n\n\nhead(df)\n#&gt;    esm_id group bdi\n#&gt; 1      10   mdd  25\n#&gt; 15      9   mdd  30\n#&gt; 30      6   mdd  26\n#&gt; 46      7   mdd  35\n#&gt; 65     12   mdd  44\n#&gt; 83     16   mdd  30\n\nSi noti che il nuovo DataFrame (con 67 righe) conserva il “nome” delle righe (ovvero, l’indice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga è 15. Questo non ha nessuna conseguenza perché non useremo l’indice di riga nelle analisi seguenti.\nEliminiamo eventuali valori mancanti:\n\ndf &lt;- df[!is.na(df$bdi), ]\n\nOtteniamo così il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):\n\ndim(df)\n#&gt; [1] 66  3\n\nStampiamo i valori BDI-II presentandoli ordinati dal più piccolo al più grande:\n\ndf$bdi |&gt; \n  sort()\n#&gt;  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1\n#&gt; [25]  1  2  2  2  2  3  3  3  5  7  9 12 19 22 22 24 25 25 26 26 26 27 27 28\n#&gt; [49] 28 30 30 30 31 31 33 33 34 35 35 35 36 39 41 43 43 44\n\nNel linguaggio statistico, un’osservazione rappresenta l’informazione raccolta da un singolo individuo o entità che partecipa allo studio. Nel caso del dataset utilizzato da Zetsche et al. (2019), l’unità di osservazione è costituita dai partecipanti allo studio. Ogni riga del DataFrame, denominato df, corrisponde quindi a un individuo distinto incluso nell’analisi.\nLe variabili, invece, riflettono le diverse caratteristiche degli individui o delle entità considerate. Per i dati in esame, questo concetto si esprime così:\n\nOgni colonna di df rappresenta una variabile che descrive una specifica proprietà comune ai partecipanti.\nLe variabili sono identificate da etichette nelle colonne, come esa_id (l’identificativo del soggetto), mdd (il gruppo di appartenenza), e bdi (il punteggio del test BDI-II).\n\nIn termini simbolisi, per indicare una singola osservazione della variabile generica \\(X\\), si utilizza la notazione \\(X_i\\), dove \\(i\\) rappresenta l’indice dell’osservazione. Questo implica che abbiamo un valore diverso di \\(X\\) per ogni differente \\(i\\). Nel caso presente, con 67 osservazioni, \\(i\\) varia da 1 a 67. Così, per rappresentare la seconda osservazione (quella con \\(i=2\\)), useremo la notazione \\(X_2\\).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "href": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "title": "14  Esplorare i dati numerici",
    "section": "14.2 Distribuzioni di frequenza",
    "text": "14.2 Distribuzioni di frequenza\nCome osservato nell’output della sezione precedente, i dati grezzi non forniscono un’interpretazione immediata. Per rendere i dati più comprensibili e sintetici, è utile costruire una distribuzione di frequenza.\nUna distribuzione di frequenza mostra quante volte i valori di una variabile si verificano all’interno di intervalli specifici. Nel caso dei punteggi BDI-II, possiamo raggruppare i punteggi in quattro classi:\n\n0–13: depressione minima\n14–19: depressione lieve-moderata\n20–28: depressione moderata-severa\n29–63: depressione severa\n\nOgni classe, denotata come \\(\\Delta_i\\), rappresenta un intervallo di valori, definito come \\([a_i, b_i)\\) (aperto a destra) o \\((a_i, b_i]\\) (aperto a sinistra), dove \\(a_i\\) e \\(b_i\\) sono rispettivamente il limite inferiore e superiore della classe. A ciascuna classe si associa un’ampiezza, data da \\(b_i - a_i\\), e un valore centrale, indicato con \\(\\bar{x}_i\\). Poiché ogni osservazione \\(x_i\\) appartiene a una sola classe \\(\\Delta_i\\), possiamo calcolare le seguenti quantità:\n\nFrequenza assoluta \\(n_i\\): il numero di osservazioni che rientrano nella classe \\(\\Delta_i\\).\n\nProprietà: \\(n_1 + n_2 + \\dots + n_m = n\\), dove \\(n\\) è il numero totale di osservazioni.\n\nFrequenza relativa \\(f_i\\): la proporzione di osservazioni in ciascuna classe, calcolata come \\(f_i = n_i/n\\).\n\nProprietà: \\(f_1 + f_2 + \\dots + f_m = 1\\).\n\nFrequenza cumulata \\(N_i\\): il numero totale di osservazioni che rientrano nelle classi fino alla \\(i\\)-esima inclusa, calcolata come \\(N_i = \\sum_{j=1}^i n_j\\).\nFrequenza cumulata relativa \\(F_i\\): la somma delle frequenze relative fino alla \\(i\\)-esima classe, data da \\(F_i = \\frac{N_i}{n} = \\sum_{j=1}^i f_j\\).\n\nQueste misure permettono di riassumere in modo efficace la distribuzione dei punteggi e facilitano l’interpretazione delle caratteristiche del campione.\n\n14.2.1 Frequenze Assolute e Relative\nPer ottenere la distribuzione di frequenza assoluta e relativa dei valori BDI-II nel dataset di zetsche_2019future, è necessario aggiungere al DataFrame df una colonna contenente una variabile categoriale che classifichi ciascuna osservazione in una delle quattro classi che descrivono la gravità della depressione. Questo risultato si ottiene utilizzando la funzione cut().\nNella funzione cut():\n\nIl primo argomento, x, è un vettore unidimensionale (ad esempio, un vettore di tipo numeric o una colonna di un DataFrame) che contiene i dati da classificare.\nIl secondo argomento, breaks, definisce gli intervalli delle classi, specificandone i limiti inferiori e superiori.\nL’argomento include.lowest = TRUE garantisce che il limite inferiore dell’intervallo più basso sia incluso nella classificazione. Nel nostro caso, questo è particolarmente utile per assicurare che i valori uguali al limite inferiore siano assegnati correttamente.\n\nDi seguito, il codice per aggiungere la variabile categoriale al DataFrame:\n\n# Creare una variabile categoriale per classi di depressione\ndf &lt;- df %&gt;% \n  mutate(\n    bdi_class = cut(\n      bdi, \n      breaks = c(0, 13.5, 19.5, 28.5, 63),\n      include.lowest = TRUE\n    )\n  )\n\nQuesto codice suddivide i valori della variabile bdi in quattro intervalli corrispondenti ai livelli di gravità della depressione:\n\n0–13: depressione minima\n14–19: depressione lieve-moderata\n20–28: depressione moderata-severa\n29–63: depressione severa\n\nOgni osservazione verrà assegnata al corrispondente intervallo, creando così una nuova colonna bdi_class nel DataFrame df.\n\n14.2.1.1 Frequenze assolute\n\ntable(df$bdi_class)\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;          36           1          12          17\n\n\n\n14.2.1.2 Frequenze relative\n\nprop.table(table(df$bdi_class))\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;  0.54545455  0.01515152  0.18181818  0.25757576\n\n\n\n\n14.2.2 Distribuzioni congiunte\nLe variabili possono anche essere analizzate insieme tramite le distribuzioni congiunte di frequenze. Queste distribuzioni rappresentano l’insieme delle frequenze assolute o relative ad ogni possibile combinazione di valori delle variabili. Ad esempio, se l’insieme di variabili \\(V\\) è composto da due variabili, \\(X\\) e \\(Y\\), ciascuna delle quali può assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per \\(V\\) potrebbe essere espressa come \\(f(X = 1, Y = 1) = 0.2\\), \\(f(X = 1, Y = 2) = 0.1\\), \\(f(X = 2, Y = 1) = 0.5\\), e \\(f(X = 2, Y = 2) = 0.2\\). Come nel caso delle distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare a 1.\nPer i dati dell’esempio precedente, la funzione prop.table() può essere utilizzata anche per produrre questo tipo di tabella: basta indicare le serie corrispondenti alle variabili considerate come valori degli argomenti bdi_class e group.\n\nprop.table(table(df$bdi_class, df$group))\n#&gt;              \n#&gt;                      ctl        mdd\n#&gt;   [0,13.5]    0.54545455 0.00000000\n#&gt;   (13.5,19.5] 0.00000000 0.01515152\n#&gt;   (19.5,28.5] 0.00000000 0.18181818\n#&gt;   (28.5,63]   0.00000000 0.25757576",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "href": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "title": "14  Esplorare i dati numerici",
    "section": "14.3 Istogramma",
    "text": "14.3 Istogramma\nUn istogramma rappresenta graficamente una distribuzione di frequenze. Un istogramma mostra sulle ascisse i limiti delle classi \\(\\Delta_i\\) e sulle ordinate la densità della frequenza relativa della variabile \\(X\\) nella classe \\(\\Delta_i\\). La densità della frequenza relativa è misurata dalla funzione costante a tratti \\(\\varphi_n(x)= \\frac{f_i}{b_i-a_i}\\), dove \\(f_i\\) è la frequenza relativa della classe \\(\\Delta_i\\) e \\(b_i - a_i\\) rappresenta l’ampiezza della classe. In questo modo, l’area del rettangolo associato alla classe \\(\\Delta_i\\) sull’istogramma sarà proporzionale alla frequenza relativa \\(f_i\\). È importante notare che l’area totale dell’istogramma delle frequenze relative è uguale a 1.0, poiché rappresenta la somma delle aree dei singoli rettangoli.\nPer fare un esempio, costruiamo un istogramma per i valori BDI-II di Zetsche et al. (2019). Con i quattro intervalli individuati dai cut-off del BDI-II creo una prima versione dell’istogramma – si notino le frequenze assolute sull’asse delle ordinate.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    breaks = c(0, 13.5, 19.5, 28.5, 63),\n    aes(y = ..density..),\n    fill = \"blue\", \n    alpha = 0.5\n  ) +\n  labs(title = \"Istogramma delle frequenze relative\", x = \"BDI-II\", y = \"Densità\")\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nAnche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un’ampiezza uguale.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    aes(y = ..density..),\n    fill = \"blue\", \n    alpha = 0.5\n  ) +\n  labs(title = \"Istogramma delle frequenze relative\", x = \"BDI-II\", y = \"Densità\")\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "href": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "title": "14  Esplorare i dati numerici",
    "section": "14.4 Kernel density plot",
    "text": "14.4 Kernel density plot\nConfrontando le due figure precedenti, emerge chiaramente una limitazione dell’istogramma: la sua forma dipende dall’arbitrarietà con cui vengono scelti il numero e l’ampiezza delle classi, rendendo difficile interpretare correttamente la distribuzione dei dati.\nPer superare questa difficoltà, possiamo utilizzare una tecnica alternativa chiamata stima della densità kernel (KDE) – si veda l’?sec-kde. Mentre l’istogramma utilizza barre per rappresentare i dati, la KDE crea un profilo smussato che fornisce una visione più continua e meno dipendente dall’arbitrarietà delle classi.\nImmaginiamo un istogramma con classi di ampiezza molto piccola, tanto da avere una curva continua invece di barre discrete. Questo è ciò che fa la KDE: smussa il profilo dell’istogramma per ottenere una rappresentazione continua dei dati. Invece di utilizzare barre, la KDE posiziona una piccola curva (detta kernel) su ogni osservazione nel dataset. Queste curve possono essere gaussiane (a forma di campana) o di altro tipo. Ogni kernel ha un’altezza e una larghezza determinate da parametri di smussamento (o bandwidth), che controllano quanto deve essere larga e alta la curva. Tutte le curve kernel vengono sommate per creare una singola curva complessiva. Questa curva rappresenta la densità dei dati, mostrando come i dati sono distribuiti lungo il range dei valori.\nLa curva risultante dal KDE mostra la proporzione di casi per ciascun intervallo di valori. L’area sotto la curva in un determinato intervallo rappresenta la proporzione di casi della distribuzione che ricadono in quell’intervallo. Per esempio, se un intervallo ha un’area maggiore sotto la curva rispetto ad altri, significa che in quell’intervallo c’è una maggiore concentrazione di dati.\nLa curva di densità ottenuta tramite KDE fornisce dunque un’idea chiara di come i dati sono distribuiti senza dipendere dall’arbitrarietà della scelta delle classi dell’istogramma.\nCrediamo un kernel density plot per ciascuno dei due gruppi di valori BDI-II riportati da {cite:t}zetsche_2019future.\n\nggplot(df, aes(x = bdi, fill = group)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Curva di densità KDE\", x = \"BDI-II\", y = \"Densità\")",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "href": "chapters/eda/05_exploring_numeric_data.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "title": "14  Esplorare i dati numerici",
    "section": "14.5 Consigli per Creare Visualizzazioni di Dati Efficaci",
    "text": "14.5 Consigli per Creare Visualizzazioni di Dati Efficaci\nEcco alcuni suggerimenti per creare visualizzazioni di dati esplicative, efficaci e di qualità adatta alle presentazioni:\n\nMessaggio chiaro: Assicurati che il grafico trasmetta un messaggio chiaro e immediato (ad esempio, “Il livello di benessere psicologico dei partecipanti aumenta nel tempo”).\nUso del colore:\n\nUtilizza i colori in modo ponderato e con moderazione.\nNon eccedere nell’uso dei colori solo perché è possibile farlo.\nLimita l’uso a non più di cinque o sei colori in una singola figura.\nVerifica che le scelte cromatiche non distorcano le conclusioni della figura.\nEvita l’uso contemporaneo di rosso e verde nello stesso grafico, poiché queste tonalità sono difficili da distinguere per le persone daltoniche.\n\nGuidare l’attenzione:\n\nUtilizza dimensioni, colori e testo per guidare l’attenzione del pubblico.\nEvidenzia elementi particolari del grafico per enfatizzare punti chiave.\n\nGestione del sovraccarico visivo:\n\nUtilizza la trasparenza per ridurre il “sovrapplotting” (che si verifica quando ci sono molti elementi sovrapposti nel grafico, come punti o linee, rendendo difficile individuare i pattern).\nQuesta tecnica è particolarmente utile quando si visualizza una grande quantità di dati.\nSe il dataset è molto ampio e l’aggiunta di trasparenza non è sufficiente, considera la visualizzazione di un sottocampione dei dati (un campione casuale di punti dati, scelto senza sostituzione). Questa tecnica è nota come sottocampionamento.\n\nElementi testuali:\n\nI titoli, le etichette degli assi e il testo delle legende devono essere chiari e facilmente comprensibili.\nGli elementi della legenda dovrebbero essere ordinati in modo logico e coerente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "href": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "title": "14  Esplorare i dati numerici",
    "section": "14.6 Forma di una Distribuzione",
    "text": "14.6 Forma di una Distribuzione\nIn statistica, la forma di una distribuzione descrive come i dati sono distribuiti intorno ai valori centrali. Si distingue tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali e multimodali. Un’illustrazione grafica è fornita nella figura seguente. Nel pannello 1, la distribuzione è unimodale con asimmetria negativa; nel pannello 2, la distribuzione è unimodale con asimmetria positiva; nel pannello 3, la distribuzione è simmetrica e unimodale; nel pannello 4, la distribuzione è bimodale.\n\n\n\nDistribuzioni\n\n\nIl grafico della densità di kernel (Kernel Density Plot) dei valori BDI-II nel campione di Zetsche et al. (2019) è bimodale. Questo indica che le osservazioni della distribuzione si raggruppano in due cluster distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l’altro gruppo tende ad avere valori BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "href": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "title": "14  Esplorare i dati numerici",
    "section": "14.7 Indici di posizione",
    "text": "14.7 Indici di posizione\n\n14.7.1 Quantili\nLa distribuzione dei valori BDI-II di Zetsche et al. (2019) può essere sintetizzata attraverso l’uso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, \\(q_1\\), divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, \\(q_2\\), corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.\nInoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.\nPer calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di \\(np\\), dove \\(n\\) è la dimensione del campione e \\(p\\) è l’ordine del quantile. Se \\(np\\) non è un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\). Se \\(np\\) è un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(k\\) e \\(k+1\\), dove \\(k\\) è la parte intera di \\(np\\).\nGli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che è molto popolare e può essere utilizzata in alternativa ad un istogramma.\nAd esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di Zetsche et al. (2019), si determina il valore di \\(np = 9 \\cdot 0.5 = 4.5\\), che non è un intero. Pertanto, il valore del secondo quartile è pari al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\), ovvero \\(q_2 = x_{4 + 1} = 27\\). Per calcolare il quantile di ordine \\(2/3\\), si determina il valore di \\(np = 9 \\cdot 2/3 = 6\\), che è un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(6\\) e \\(7\\), ovvero \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\nUsiamo numpy per trovare la soluzione dell’esercizio precedente.\n\nx = c(19, 26, 27, 28, 28, 33, 33, 41, 43)\nquantile(x, 2 / 3)\n#&gt; 66.66667% \n#&gt;        33",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "href": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "title": "14  Esplorare i dati numerici",
    "section": "14.8 Mostrare i dati",
    "text": "14.8 Mostrare i dati\n\n14.8.1 Diagramma a scatola\nIl box plot è uno strumento grafico che visualizza la dispersione di una distribuzione. Per creare un box plot, si disegna un rettangolo (la “scatola”) di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile (\\(q_{0.75}\\)) e il primo quartile (\\(q_{0.25}\\)). La mediana (\\(q_{0.5}\\)) è rappresentata da una linea all’interno del rettangolo.\nAi lati della scatola, vengono tracciati due segmenti di retta, detti “baffi”, che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore è il valore più basso tra le osservazioni che è maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore è il valore più alto tra le osservazioni che è minore o uguale al terzo quartile più 1.5 volte la distanza interquartile.\nSe ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati “valori anomali” e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.\n\nUtilizziamo un box-plot per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo.\n\nggplot(df, aes(x = group, y = bdi)) +\n  geom_boxplot() +\n  labs(title = \"Box plot per gruppo\", x = \"Gruppo\", y = \"BDI-II\")\n\n\n\n\n\n\n\n\nUn risultato migliore si ottiene utilizzando un grafico a violino (violin plot) e includendo anche i dati grezzi.\n\n\n14.8.2 Grafico a Violino\nI grafici a violino combinano le caratteristiche dei box plot e dei grafici di densità di kernel (KDE plot) per offrire una rappresentazione più dettagliata dei dati. A questi grafici vengono sovrapposti i dati grezzi, fornendo una visione completa della distribuzione e delle caratteristiche dei dati.\n\nggplot(df, aes(x = group, y = bdi)) +\n  geom_violin(fill = \"lightgray\", color = \"black\") +\n  geom_jitter(width = 0.2, color = \"red\", alpha = 0.6) +\n  labs(\n    title = \"Violin plot con overlay dei punti grezzi\",\n    x = \"Gruppo\", \n    y = \"BDI-II\"\n  )",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#commenti-e-considerazioni-finali",
    "href": "chapters/eda/05_exploring_numeric_data.html#commenti-e-considerazioni-finali",
    "title": "14  Esplorare i dati numerici",
    "section": "14.9 Commenti e considerazioni finali",
    "text": "14.9 Commenti e considerazioni finali\nAbbiamo esplorato diverse tecniche per sintetizzare e visualizzare i dati, includendo distribuzioni di frequenze, istogrammi e grafici di densità. Questi strumenti sono essenziali per comprendere meglio i dati e presentare risultati in modo chiaro e informativo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "14  Esplorare i dati numerici",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] R.oo_1.27.0       pkgconfig_2.0.3   data.table_1.16.2 lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] carData_3.0-5     httpuv_1.6.15     htmltools_0.5.8.1 yaml_2.3.10      \n#&gt; [25] Formula_1.2-5     car_3.1-3         pillar_1.9.0      later_1.4.0      \n#&gt; [29] R.utils_2.12.3    abind_1.4-8       nlme_3.1-166      mime_0.12        \n#&gt; [33] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     labeling_0.4.3   \n#&gt; [37] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1 \n#&gt; [41] cli_3.6.3         magrittr_2.0.3    utf8_1.2.4        broom_1.0.7      \n#&gt; [45] withr_3.0.2       backports_1.5.0   promises_1.3.1    timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    ggsignif_0.6.4    R.methodsS3_1.8.2 hms_1.1.3        \n#&gt; [53] shiny_1.9.1       evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4      \n#&gt; [57] Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9   \n#&gt; [61] R6_2.5.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#bibliografia",
    "href": "chapters/eda/05_exploring_numeric_data.html#bibliografia",
    "title": "14  Esplorare i dati numerici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html",
    "href": "chapters/eda/06_data_visualization.html",
    "title": "15  Principi della visualizzazione dei dati",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e competenze chiave\nIn questo capitolo verranno introdotti i principi fondamentali della visualizzazione dei dati, accompagnati da una descrizione concisa. Per un approfondimento su ciascun principio, si rimanda al capitolo Data Visualization del libro Introduction to Data Science.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "href": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "title": "15  Principi della visualizzazione dei dati",
    "section": "15.1 Codificare i dati attraverso segnali visivi",
    "text": "15.1 Codificare i dati attraverso segnali visivi\nIniziamo con una panoramica dei principali segnali visivi utilizzati per codificare i dati: posizione, lunghezza, angoli, area, luminosità e tonalità del colore. Tra questi, posizione e lunghezza sono i segnali visivi più efficaci e intuitivi, poiché il cervello umano è particolarmente abile nel riconoscere variazioni spaziali. Questo rende la posizione e la lunghezza strumenti potenti per la rappresentazione quantitativa. In altre parole, le persone riescono a confrontare con maggiore precisione altezze e lunghezze (come le barre in un barplot) rispetto ad angoli o aree (come in un grafico a torta).\nAngoli e aree, sebbene comunemente usati, sono segnali visivi meno efficaci. Grafici come i pie chart, che si basano su angoli e aree per rappresentare quantità, risultano spesso meno precisi e più difficili da interpretare, specialmente quando le differenze sono piccole. Anche l’uso dell’area, ad esempio nei bubble plot, può distorcere la percezione delle differenze tra i dati, a meno che non venga gestita correttamente. Anche se l’area di una bolla può essere proporzionale al valore rappresentato, la percezione umana tende a sovrastimare le differenze tra aree più grandi.\nLuminosità e tonalità del colore sono utili per rappresentare variabili qualitative o categoriali, ma possono risultare difficili da interpretare quando si tratta di confrontare quantità precise. Tuttavia, il colore gioca un ruolo cruciale nelle visualizzazioni multidimensionali, come le heatmap, dove è necessario rappresentare più di due variabili contemporaneamente. È importante, però, usare il colore con attenzione, soprattutto per garantire l’accessibilità a persone con problemi di daltonismo.\nLe tabelle sono utili quando si ha una quantità limitata di dati e si richiede una precisione numerica rigorosa. Tuttavia, per set di dati più grandi o per evidenziare tendenze e differenze, i grafici (come i barplot) sono generalmente più efficaci. Le tabelle non offrono lo stesso impatto visivo immediato e rendono più difficile l’individuazione di pattern complessi.\n\n15.1.1 Ulteriori considerazioni sulla scelta della visualizzazione\nLa scelta della visualizzazione più appropriata dipende sia dalla natura dei dati che dallo scopo della comunicazione. Per esempio:\n\nBarplot o dot plot sono ideali per confrontare valori quantitativi tra categorie.\nIstogrammi, boxplot e raincloud plots sono più adatti per descrivere la distribuzione di dati continui e fare confronti tra categorie.\nGrafici di dispersione (scatter plot) sono eccellenti per esplorare relazioni tra due variabili continue.\n\nLa chiarezza e la leggibilità sono principi fondamentali nella creazione di visualizzazioni efficaci. L’aggiunta di elementi visivi eccessivi, come decorazioni superflue o troppi colori, può distrarre dal messaggio principale. Un buon grafico deve essere semplice, ma allo stesso tempo completo, includendo solo gli elementi visivi necessari per trasmettere il messaggio desiderato.\nIn conclusione, scegliere i segnali visivi adeguati e il tipo di grafico più appropriato non solo migliora l’accuratezza della comunicazione, ma rende le informazioni più accessibili e comprensibili per il pubblico.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#quando-includere-lo-zero",
    "href": "chapters/eda/06_data_visualization.html#quando-includere-lo-zero",
    "title": "15  Principi della visualizzazione dei dati",
    "section": "15.2 Quando includere lo zero",
    "text": "15.2 Quando includere lo zero\nQuando si usa la lunghezza come segnale visivo, come nei barplot, è essenziale che l’asse parta da zero. Non farlo può essere fuorviante e far sembrare le differenze più grandi di quanto non siano in realtà. Questo errore viene spesso sfruttato nei media per esagerare differenze apparentemente significative.\nTuttavia, quando si usa la posizione (ad esempio in un grafico a dispersione), non è sempre necessario includere lo zero, soprattutto se l’interesse principale è il confronto tra gruppi rispetto alla variabilità interna.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-le-distorsioni",
    "href": "chapters/eda/06_data_visualization.html#evitare-le-distorsioni",
    "title": "15  Principi della visualizzazione dei dati",
    "section": "15.3 Evitare le distorsioni",
    "text": "15.3 Evitare le distorsioni\nUna distorsione comune si verifica quando le differenze tra quantità sono rappresentate utilizzando aree, come nei bubble plot, dove il raggio dei cerchi è proporzionale al dato. Il problema è che, poiché l’area di un cerchio è proporzionale al quadrato del raggio, le differenze sembrano molto più ampie di quanto siano realmente. Per evitare queste distorsioni, è meglio utilizzare la posizione o la lunghezza, come in un grafico a barre, per confrontare direttamente le quantità.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#ordinare-le-categorie",
    "href": "chapters/eda/06_data_visualization.html#ordinare-le-categorie",
    "title": "15  Principi della visualizzazione dei dati",
    "section": "15.4 Ordinare le categorie",
    "text": "15.4 Ordinare le categorie\nQuando si visualizzano categorie, come nei barplot o nei boxplot, è opportuno ordinarle in base al valore della variabile di interesse, anziché in ordine alfabetico. Questo aiuta a evidenziare pattern significativi e facilita il confronto tra categorie.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-i-dynamite-plots",
    "href": "chapters/eda/06_data_visualization.html#evitare-i-dynamite-plots",
    "title": "15  Principi della visualizzazione dei dati",
    "section": "15.5 Evitare i Dynamite Plots",
    "text": "15.5 Evitare i Dynamite Plots\nI dynamite plots, che mostrano la media e l’errore standard (o la deviazione standard), sono spesso utilizzati in psicologia ma sono fuorvianti. Questi grafici tendono a esagerare le differenze e possono indurre false interpretazioni. È preferibile mostrare tutti i dati, ad esempio tramite un dot plot, che fornisce un’immagine più chiara della distribuzione dei dati (Butler, 2022).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#facilitare-i-confronti",
    "href": "chapters/eda/06_data_visualization.html#facilitare-i-confronti",
    "title": "15  Principi della visualizzazione dei dati",
    "section": "15.6 Facilitare i confronti",
    "text": "15.6 Facilitare i confronti\nQuando si confrontano due distribuzioni, come in un istogramma, è fondamentale mantenere gli stessi assi per entrambi i grafici. Se le distribuzioni sono presentate su assi con scale diverse, il confronto diventa difficile e potrebbe portare a conclusioni errate. Allineare i grafici verticalmente o orizzontalmente consente di percepire più facilmente le differenze tra i gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#trasformazioni-logaritmiche",
    "href": "chapters/eda/06_data_visualization.html#trasformazioni-logaritmiche",
    "title": "15  Principi della visualizzazione dei dati",
    "section": "15.7 Trasformazioni logaritmiche",
    "text": "15.7 Trasformazioni logaritmiche\nLe trasformazioni logaritmiche sono utili quando si lavora con dati distribuiti su più ordini di grandezza o quando le variazioni tra le quantità sono moltiplicative (West, 2022). L’uso della scala logaritmica in un grafico a barre o a dispersione può ridurre le distorsioni visive e migliorare l’interpretazione dei dati. Questo approccio è particolarmente utile quando alcuni valori estremi potrebbero dominare il grafico, nascondendo dettagli rilevanti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#codificare-una-terza-variabile",
    "href": "chapters/eda/06_data_visualization.html#codificare-una-terza-variabile",
    "title": "15  Principi della visualizzazione dei dati",
    "section": "15.8 Codificare una terza variabile",
    "text": "15.8 Codificare una terza variabile\nPer rappresentare tre variabili, è possibile utilizzare un grafico di dispersione con variabili codificate attraverso dimensioni aggiuntive come il colore, la dimensione o la forma dei punti. Ad esempio, in un grafico che confronta aspettativa di vita e reddito, la dimensione dei punti potrebbe rappresentare la popolazione e il colore la regione geografica. Quando si utilizza il colore per rappresentare una variabile, è importante scegliere palette cromatiche accessibili anche per chi è affetto da daltonismo, evitando combinazioni problematiche come rosso-verde.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-pseudo-tre-dimensioni",
    "href": "chapters/eda/06_data_visualization.html#evitare-pseudo-tre-dimensioni",
    "title": "15  Principi della visualizzazione dei dati",
    "section": "15.9 Evitare pseudo-tre dimensioni",
    "text": "15.9 Evitare pseudo-tre dimensioni\nGrafici tridimensionali, come barre o pie chart 3D, spesso aggiungono confusione senza fornire informazioni aggiuntive significative. Sebbene visivamente accattivanti, questi grafici distorcono la percezione e rendono difficile l’interpretazione accurata dei dati. È preferibile mantenere le visualizzazioni bidimensionali, a meno che la terza dimensione non rappresenti effettivamente una variabile aggiuntiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#scegliere-il-numero-giusto-di-cifre-significative",
    "href": "chapters/eda/06_data_visualization.html#scegliere-il-numero-giusto-di-cifre-significative",
    "title": "15  Principi della visualizzazione dei dati",
    "section": "15.10 Scegliere il numero giusto di cifre significative",
    "text": "15.10 Scegliere il numero giusto di cifre significative\nÈ importante evitare l’uso di troppe cifre decimali nelle tabelle e nei grafici. Spesso, una o due cifre significative sono sufficienti per rappresentare accuratamente i dati, mentre l’aggiunta di cifre inutili può confondere il lettore e dare un falso senso di precisione. Limitiamoci a mostrare solo le cifre necessarie per trasmettere il messaggio in modo chiaro.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#conoscere-il-pubblico",
    "href": "chapters/eda/06_data_visualization.html#conoscere-il-pubblico",
    "title": "15  Principi della visualizzazione dei dati",
    "section": "15.11 Conoscere il pubblico",
    "text": "15.11 Conoscere il pubblico\nInfine, è fondamentale adattare la visualizzazione dei dati al pubblico di riferimento. Grafici progettati per l’analisi esplorativa interna possono contenere dettagli tecnici complessi, ma quando si comunica a un pubblico più ampio o non specializzato, è necessario semplificare. Ad esempio, utilizzare una scala logaritmica può essere utile per un pubblico esperto, ma confondere un pubblico generale. In questi casi, mantenere la scala lineare e spiegare chiaramente i dati aiuta a evitare malintesi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#riflessioni-conclusive",
    "href": "chapters/eda/06_data_visualization.html#riflessioni-conclusive",
    "title": "15  Principi della visualizzazione dei dati",
    "section": "15.12 Riflessioni Conclusive",
    "text": "15.12 Riflessioni Conclusive\nI principi di visualizzazione dei dati trattati in questo capitolo sono strumenti fondamentali per garantire chiarezza e accuratezza nella rappresentazione delle informazioni. Scelte appropriate di grafici, segnali visivi e trasformazioni facilitano la comprensione, riducendo la possibilità di distorsioni o interpretazioni errate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#bibliografia",
    "href": "chapters/eda/06_data_visualization.html#bibliografia",
    "title": "15  Principi della visualizzazione dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nButler, R. C. (2022). Popularity leads to bad habits: Alternatives to «the statistics» routine of significance,«alphabet soup» and dynamite plots. In Annals of Applied Biology (Fasc. 2; Vol. 180, pp. 182–195). Wiley Online Library.\n\n\nHealy, K. (2018). Data visualization: a practical introduction. Princeton University Press.\n\n\nWest, R. M. (2022). Best practice in statistics: The use of log transformation. Annals of Clinical Biochemistry, 59(3), 162–165.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".\n\n\nWilke, C. O. (2019). Fundamentals of data visualization: a primer on making informative and compelling figures. O’Reilly Media.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html",
    "href": "chapters/eda/07_loc_scale.html",
    "title": "16  Indicatori di tendenza centrale e variabilità",
    "section": "",
    "text": "16.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nLa visualizzazione grafica dei dati rappresenta il pilastro fondamentale di ogni analisi quantitativa. Grazie alle rappresentazioni grafiche adeguate, è possibile individuare importanti caratteristiche di una distribuzione, quali la simmetria o l’asimmetria, nonché la presenza di una o più mode. Successivamente, al fine di descrivere sinteticamente le principali caratteristiche dei dati, si rende necessario l’utilizzo di specifici indici numerici. In questo capitolo, verranno presentati i principali indicatori della statistica descrittiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "href": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "title": "16  Indicatori di tendenza centrale e variabilità",
    "section": "16.2 Indici di tendenza centrale",
    "text": "16.2 Indici di tendenza centrale\nGli indici di tendenza centrale sono misure statistiche che cercano di rappresentare un valore tipico o centrale all’interno di un insieme di dati. Sono utilizzati per ottenere una comprensione immediata della distribuzione dei dati senza dover analizzare l’intero insieme. Gli indici di tendenza centrale sono fondamentali nell’analisi statistica, in quanto forniscono una sintesi semplice e comprensibile delle caratteristiche principali di un insieme di dati. I principali indici di tendenza centrale sono:\n\nMedia: La media è la somma di tutti i valori divisa per il numero totale di valori. È spesso utilizzata come misura generale di tendenza centrale, ma è sensibile agli estremi (valori molto alti o molto bassi).\nMediana: La mediana è il valore che divide l’insieme di dati in due parti uguali. A differenza della media, non è influenzata da valori estremi ed è quindi più robusta in presenza di outlier.\nModa: La moda è il valore che appare più frequentemente in un insieme di dati. In alcuni casi, può non essere presente o esserci più di una moda.\n\nLa scelta dell’indice di tendenza centrale appropriato dipende dalla natura dei dati e dall’obiettivo dell’analisi. Ad esempio, la mediana potrebbe essere preferita alla media se l’insieme di dati contiene valori anomali che potrebbero distorcere la rappresentazione centrale. La conoscenza e l’applicazione corretta di questi indici possono fornire una preziosa intuizione sulle caratteristiche centrali di una distribuzione di dati.\n\n16.2.1 Media\nLa media aritmetica di un insieme di valori rappresenta il punto centrale o il baricentro della distribuzione dei dati. È calcolata come la somma di tutti i valori divisa per il numero totale di valori, ed è espressa dalla formula:\n\\[\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i,\n\\tag{16.1}\\]\ndove \\(x_i\\) rappresenta i valori nell’insieme, \\(n\\) è il numero totale di valori, e \\(\\sum\\) indica la sommatoria.\n\n16.2.1.1 Proprietà della media\nUna proprietà fondamentale della media è che la somma degli scarti di ciascun valore dalla media è zero:\n\\[\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\tag{16.2}\\]\nInfatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]\nQuesta proprietà implica che i dati sono equamente distribuiti intorno alla media.\n\n\n16.2.1.2 La media come centro di gravità dell’istogramma\nLa media aritmetica può essere interpretata come il centro di gravità o il punto di equilibrio della distribuzione dei dati. In termini fisici, il centro di gravità è il punto in cui la massa di un sistema è equilibrata o concentrata.\nIn termini statistici, possiamo considerare la media come il punto in cui la distribuzione dei dati è in equilibrio. Ogni valore dell’insieme di dati può essere visto come un punto materiale con una massa proporzionale al suo valore. Se immaginiamo questi punti disposti su una linea, con valori più grandi a destra e più piccoli a sinistra, la media corrisponderà esattamente al punto in cui la distribuzione sarebbe in equilibrio.\n\n\n16.2.1.3 Principio dei minimi quadrati\nLa posizione della media minimizza la somma delle distanze quadrate dai dati, un principio noto come “metodo dei minimi quadrati”. Matematicamente, questo si traduce nel fatto che la somma dei quadrati degli scarti tra ciascun valore e la media è minima. Questo principio è alla base dell’analisi statistica dei modelli di regressione e conferma l’interpretazione della media come centro di gravità dell’istogramma.\n\n\n16.2.1.4 Calcolo della media con R\nPer calcolare la media di un piccolo numero di valori in Python, possiamo utilizzare la somma di questi valori e dividerla per il numero totale di elementi. Consideriamo ad esempio i valori 12, 44, 21, 62, 24:\n\n(12 + 44 + 21 + 62 + 24) / 5\n#&gt; [1] 32.6\n\novvero\n\nx &lt;- c(12, 44, 21, 62, 24)\nmean(x)\n#&gt; [1] 32.6\n\n\n\n16.2.1.5 Le proporzioni sono medie\nSe una collezione consiste solo di uni e zeri, allora la somma della collezione è il numero di uni in essa, e la media della collezione è la proporzione di uni.\n\nzero_one &lt;- c(1, 1, 1, 0)\nresult &lt;- mean(zero_one)\nresult\n#&gt; [1] 0.75\n\nÈ possibile sostituire 1 con il valore booleano True e 0 con False:\n\nmean(c(TRUE, TRUE, TRUE, FALSE))\n#&gt; [1] 0.75\n\n\n\n16.2.1.6 Limiti della media aritmetica\nLa media aritmetica, tuttavia, ha alcune limitazioni: non sempre è l’indice più adeguato per descrivere accuratamente la tendenza centrale della distribuzione, specialmente quando si verificano asimmetrie o valori anomali (outlier). In queste situazioni, è più indicato utilizzare la mediana o la media spuntata (come spiegheremo successivamente).\n\n\n16.2.1.7 Medie per gruppi\nMolto spesso però i nostri dati sono contenuti in file e inserire i dati manualmente non è fattibile. Per fare un esempio, considereremo i dati del Progetto STAR, contenuti nel file STAR.csv, che rappresentano un’importante indagine sulle prestazioni degli studenti in relazione alla dimensione delle classi. Negli anni ’80, i legislatori del Tennessee considerarono la possibilità di ridurre le dimensioni delle classi per migliorare il rendimento degli studenti. Al fine di prendere decisioni informate, commissionarono lo studio multimilionario “Progetto Student-Teacher Achievement Ratio” (Project STAR). Lo studio coinvolgeva bambini della scuola materna assegnati casualmente a classi piccole, con 13-17 studenti, o classi di dimensioni regolari, con 22-25 studenti, fino alla fine della terza elementare. I ricercatori hanno seguito il progresso degli studenti nel tempo, concentrandosi su variabili di risultato, come i punteggi dei test standardizzati di lettura (reading) e matematica (math) alla terza elementare, oltre ai tassi di diploma di scuola superiore (graduated, con valore 1 per sì e 0 per no).\nPoniamoci il problema di calcolare la media dei punteggi math calcolata separatamente per i due gruppi di studenti: coloro che hanno completato la scuola superiore e coloro che non l’hanno completata.\nProcediamo all’importazione dei dati per iniziare l’analisi.\n\ndf &lt;- rio::import(here::here(\"data\", \"STAR.csv\"))\ndf |&gt; \n  head()\n#&gt;   classtype reading math graduated\n#&gt; 1     small     578  610         1\n#&gt; 2   regular     612  612         1\n#&gt; 3   regular     583  606         1\n#&gt; 4     small     661  648         1\n#&gt; 5     small     614  636         1\n#&gt; 6   regular     610  603         0\n\nEsaminiamo la numerosità di ciascun gruppo.\n\ndf |&gt; \n  group_by(graduated) |&gt; \n  summarize(count = n())\n#&gt; # A tibble: 2 × 2\n#&gt;   graduated count\n#&gt;       &lt;int&gt; &lt;int&gt;\n#&gt; 1         0   166\n#&gt; 2         1  1108\n\nOra procediamo al calcolo delle medie dei punteggi math all’interno dei due gruppi. Per rendere la risposta più concisa, useremo la funzione round() per stampare solo 2 valori decimali.\n\ndf |&gt; \n  group_by(graduated) |&gt; \n  summarise(\n    mean_math = round(mean(math, na.rm = TRUE), 2)\n  )\n#&gt; # A tibble: 2 × 2\n#&gt;   graduated mean_math\n#&gt;       &lt;int&gt;     &lt;dbl&gt;\n#&gt; 1         0      607.\n#&gt; 2         1      635.\n\n\n\n\n16.2.2 Media spuntata\nLa media spuntata, indicata come \\(\\bar{x}_t\\) o trimmed mean, è un metodo di calcolo della media che prevede l’eliminazione di una determinata percentuale di dati estremi prima di effettuare la media aritmetica. Solitamente, viene eliminato il 10% dei dati, ovvero il 5% all’inizio e alla fine della distribuzione. Per ottenere la media spuntata, i dati vengono ordinati in modo crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), e quindi viene eliminato il primo 5% e l’ultimo 5% dei dati nella sequenza ordinata. Infine, la media spuntata è calcolata come la media aritmetica dei dati rimanenti. Questo approccio è utile quando ci sono valori anomali o quando la distribuzione è asimmetrica e la media aritmetica non rappresenta adeguatamente la tendenza centrale dei dati.\nA titolo di esempio, procediamo al calcolo della media spuntata dei valori math per i due gruppi definiti dalla variabile graduated, escludendo il 10% dei valori più estremi.\n\nglimpse(df)\n#&gt; Rows: 1,274\n#&gt; Columns: 4\n#&gt; $ classtype &lt;chr&gt; \"small\", \"regular\", \"regular\", \"small\", \"small\", \"regular…\n#&gt; $ reading   &lt;int&gt; 578, 612, 583, 661, 614, 610, 595, 665, 616, 624, 593, 59…\n#&gt; $ math      &lt;int&gt; 610, 612, 606, 648, 636, 603, 610, 631, 636, 626, 601, 56…\n#&gt; $ graduated &lt;int&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, …\n\n\nnot_graduated &lt;- df[df$graduated == 0, \"math\"]\nmean(not_graduated, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 605.6493\n\n\nnot_graduated &lt;- df[df$graduated == 1, \"math\"]\nmean(not_graduated, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 634.4403\n\n\n\n16.2.3 Quantili\nIl quantile non interpolato di ordine \\(p\\) \\((0 &lt; p &lt; 1)\\) rappresenta il valore che divide la distribuzione dei dati in modo tale che una frazione \\(p\\) dei dati si trovi al di sotto di esso.\nLa formula per calcolare il quantile non interpolato è la seguente:\n\\[\n    q_p = x_{(k)},\n\\]\ndove \\(x_{(k)}\\) è l’elemento \\(k\\)-esimo nell’insieme di dati ordinato in modo crescente, e \\(k\\) è calcolato come:\n\\[\nk = \\lceil p \\cdot n \\rceil,\n\\]\ndove \\(n\\) è il numero totale di dati nel campione, e \\(\\lceil \\cdot \\rceil\\) rappresenta la funzione di arrotondamento all’intero successivo. In questa definizione, il quantile non interpolato corrisponde al valore effettivo nell’insieme di dati, senza effettuare alcuna interpolazione tra i valori circostanti.\nAd esempio, consideriamo il seguente insieme di dati: \\(\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}\\). Supponiamo di voler calcolare il quantile non interpolato di ordine \\(p = 0.3\\) (cioè il 30° percentile).\nOrdiniamo i dati in modo crescente: \\(\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}.\\) Calcoliamo \\(k\\) utilizzando la formula \\(k = \\lceil p \\cdot n \\rceil\\), dove \\(n\\) è il numero totale di dati nel campione. Nel nostro caso, \\(n = 10\\) e \\(p = 0.3\\):\n\\[\nk = \\lceil 0.3 \\cdot 10 \\rceil = \\lceil 3 \\rceil = 3.\n\\]\nIl quantile non interpolato corrisponde al valore \\(x_{(k)}\\), ovvero l’elemento \\(k\\)-esimo nell’insieme ordinato: \\(q_{0.3} = x_{(3)} = 23.\\)\nOltre al quantile non interpolato, esiste anche il concetto di quantile interpolato. A differenza del quantile non interpolato, il quantile interpolato può essere calcolato anche per percentili che non corrispondono esattamente a valori presenti nell’insieme di dati. Per ottenere il valore del quantile interpolato, viene utilizzato un procedimento di interpolazione lineare tra i valori adiacenti. In genere, il calcolo del quantile interpolato viene eseguito mediante l’uso di software dedicati.\nOra, procediamo al calcolo dei quantili di ordine 0.10 e 0.90 per i valori math all’interno dei due gruppi. I quantili sono dei valori che dividono la distribuzione dei dati in parti specifiche. Ad esempio, il quantile di ordine 0.10 corrisponde al valore al di sotto del quale si trova il 10% dei dati, mentre il quantile di ordine 0.90 rappresenta il valore al di sotto del quale si trova il 90% dei dati.\nCalcoliamo i quantili di ordine 0.1 e 0.9 della distribuzione dei punteggi math nei due gruppi definiti dalla variabile graduated.\n\n# Quantili di ordine 0.1 e 0.9 per il gruppo di studenti che hanno completato \n# la scuola superiore\nquantile(df[df$graduated == 1, \"math\"], probs = c(0.1, 0.9))\n#&gt; 10% 90% \n#&gt; 588 684\n\n\n# Quantili di ordine 0.1 e 0.9 per il gruppo di studenti che non hanno \n# completato la scuola superiore\nquantile(df[df$graduated == 0, \"math\"], probs = c(0.1, 0.9))\n#&gt;   10%   90% \n#&gt; 564.5 651.0\n\n\n\n16.2.4 Moda e mediana\nIn precedenza abbiamo già incontrato altri due popolari indici di tendenza centrale: la moda (Mo), che rappresenta il valore centrale della classe con la frequenza massima (in alcune distribuzioni può esserci più di una moda, rendendola multimodale e facendo perdere a questo indice il suo significato di indicatore di tendenza centrale); e la mediana (\\(\\tilde{x}\\)), che rappresenta il valore corrispondente al quantile di ordine 0.5 della distribuzione.\n\n\n16.2.5 Quando usare media, moda, mediana\nLa moda può essere utilizzata per dati a livello nominale o ordinale ed è l’unica tra le tre statistiche che può essere calcolata in questi casi.\nLa media, d’altra parte, è una buona misura di tendenza centrale solo se la distribuzione dei dati è simmetrica, ossia se i valori sono distribuiti uniformemente a sinistra e a destra della media. Tuttavia, se ci sono valori anomali o se la distribuzione è asimmetrica, la media può essere influenzata in modo significativo e, pertanto, potrebbe non essere la scelta migliore come misura di tendenza centrale.\nIn queste situazioni, la mediana può fornire una misura migliore di tendenza centrale rispetto alla media poiché è meno influenzata dai valori anomali e si basa esclusivamente sul valore centrale dell’insieme di dati. Di conseguenza, la scelta tra media e mediana dipende dal tipo di distribuzione dei dati e dagli obiettivi dell’analisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-dispersione",
    "href": "chapters/eda/07_loc_scale.html#indici-di-dispersione",
    "title": "16  Indicatori di tendenza centrale e variabilità",
    "section": "16.3 Indici di dispersione",
    "text": "16.3 Indici di dispersione\nLe misure di posizione descritte in precedenza, come le medie e gli indici di posizione, offrono una sintesi dei dati mettendo in evidenza la tendenza centrale delle osservazioni. Tuttavia, trascurano un aspetto importante della distribuzione dei dati: la variabilità dei valori numerici della variabile statistica. Pertanto, è essenziale completare la descrizione della distribuzione di una variabile statistica utilizzando anche indicatori che valutino la dispersione delle unità statistiche. In questo modo, otterremo una visione più completa e approfondita delle caratteristiche del campione analizzato.\n\n16.3.1 Indici basati sull’ordinamento dei dati\nPer valutare la variabilità dei dati, è possibile utilizzare indici basati sull’ordinamento dei dati. L’indice più semplice è l’intervallo di variazione, che corrisponde alla differenza tra il valore massimo e il valore minimo di una distribuzione di dati. Tuttavia, questo indice ha il limite di essere calcolato basandosi solo su due valori della distribuzione, e non tiene conto di tutte le informazioni disponibili. Inoltre, l’intervallo di variazione può essere fortemente influenzato dalla presenza di valori anomali.\nUn altro indice basato sull’ordinamento dei dati è la differenza interquartile, già incontrata in precedenza. Anche se questo indice utilizza più informazioni rispetto all’intervallo di variazione, presenta comunque il limite di essere calcolato basandosi solo su due valori della distribuzione, ossia il primo quartile \\(Q_1\\) e il terzo quartile \\(Q_3\\).\nPer valutare la variabilità in modo più completo, è necessario utilizzare altri indici di variabilità che tengano conto di tutti i dati disponibili. In questo modo, si otterrà una valutazione più accurata della dispersione dei valori nella distribuzione e si potranno individuare eventuali pattern o tendenze nascoste.\n\n\n16.3.2 Varianza\nDate le limitazioni delle statistiche descritte in precedenza, è più comune utilizzare una misura di variabilità che tenga conto della dispersione dei dati rispetto a un indice di tendenza centrale. La varianza è la misura di variabilità più utilizzata per valutare la variabilità di una variabile statistica. Essa è definita come la media dei quadrati degli scarti \\(x_i - \\bar{x}\\) tra ogni valore e la media della distribuzione, come segue:\n\\[\n\\begin{equation}\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2.\n\\end{equation}\n\\tag{16.3}\\]\nLa varianza è una misura di dispersione più completa rispetto a quelle descritte in precedenza. Tuttavia, è appropriata solo nel caso di distribuzioni simmetriche ed è fortemente influenzata dai valori anomali, come altre misure di dispersione. Inoltre, la varianza è espressa in un’unità di misura che è il quadrato dell’unità di misura dei dati originali, pertanto, potrebbe non essere facilmente interpretata in modo intuitivo.\nCalcoliamo la varianza dei valori math per i dati del progetto STAR. Applicando l’equazione della varianza, otteniamo:\n\nsum((df$math - mean(df$math))^2) / length(df$math)\n#&gt; [1] 1507.233\n\nPiù semplicemente, possiamo usare la funzione var():\n\nvar(df$math) * (length(df$math) -1) / length(df$math)\n#&gt; [1] 1507.233\n\n\n16.3.2.1 Stima della varianza della popolazione\nSi noti il denominatore della formula della varianza. Nell’Equazione 16.3, ho utilizzato \\(n\\) come denominatore (l’ampiezza campionaria, ovvero il numero di osservazioni nel campione). In questo modo, otteniamo la varianza come statistica descrittiva del campione. Tuttavia, è possibile utilizzare \\(n-1\\) come denominatore alternativo:\n\\[\n\\begin{equation}\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2\n\\end{equation}\n\\tag{16.4}\\]\nIn questo secondo caso, otteniamo la varianza come stimatore della varianza della popolazione. Si può dimostrare che l’Equazione 16.4 fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre l’Equazione 16.3 fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: \\(S^2\\) rappresenta la varianza come statistica descrittiva, mentre \\(s^2\\) rappresenta la varianza come stimatore.\nPer illustrare questo punto, svolgiamo una simulazione. Consideriamo la distribuzione dei punteggi del quoziente di intelligenza (QI). I valori del QI seguono una particolare distribuzione chiamata distribuzione normale, con media 100 e deviazione standard 15. La forma di questa distribuzione è illustrata nella figura seguente.\n\n# Define parameters\nx &lt;- seq(100 - 4 * 15, 100 + 4 * 15, by = 0.001)\nmu &lt;- 100\nsigma &lt;- 15\n\n# Compute the PDF\npdf &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Plot using ggplot2\ndata &lt;- data.frame(x = x, pdf = pdf)\nggplot(data, aes(x = x, y = pdf)) +\n  geom_line() +\n  labs(x = \"x\", y = \"f(x)\") \n\n\n\n\n\n\n\n\nSupponiamo di estrarre un campione casuale di 4 osservazioni dalla popolazione del quoziente di intelligenza – in altre parole, supponiamo di misurare il quoziente di intelligenza di 4 persone prese a caso dalla popolazione.\n\nset.seed(123) \nx &lt;- rnorm(4, mean = 100, sd = 15)\nprint(x)\n#&gt; [1]  91.59287  96.54734 123.38062 101.05763\n\nCalcoliamo la varianza usando \\(n\\) al denominatore. Si noti che la vera varianza del quoziente di intelligenza è \\(15^2\\) = 225.\n\nvar(x)\n#&gt; [1] 196.9395\n\nConsideriamo ora 10 campioni casuali del QI, ciascuno di ampiezza 4.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10\nrandom_samples &lt;- list()\n\nset.seed(123) \n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nIl primo campione è\n\nrandom_samples[1]\n#&gt; [[1]]\n#&gt; [1]  91.59287  96.54734 123.38062 101.05763\n\nIl decimo campione è\n\nrandom_samples[10]\n#&gt; [[1]]\n#&gt; [1] 108.30876  99.07132  95.41056  94.29293\n\nStampiamo i valori di tutti i 10 campioni.\n\nrs &lt;- do.call(rbind, random_samples)\nrs\n#&gt;            [,1]      [,2]      [,3]      [,4]\n#&gt;  [1,]  91.59287  96.54734 123.38062 101.05763\n#&gt;  [2,] 101.93932 125.72597 106.91374  81.02408\n#&gt;  [3,]  89.69721  93.31507 118.36123 105.39721\n#&gt;  [4,] 106.01157 101.66024  91.66238 126.80370\n#&gt;  [5,] 107.46776  70.50074 110.52034  92.90813\n#&gt;  [6,]  83.98264  96.73038  84.60993  89.06663\n#&gt;  [7,]  90.62441  74.69960 112.56681 102.30060\n#&gt;  [8,]  82.92795 118.80722 106.39696  95.57393\n#&gt;  [9,] 113.42688 113.17200 112.32372 110.32960\n#&gt; [10,] 108.30876  99.07132  95.41056  94.29293\n\nPer ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando la formula con \\(n\\) al denominatore. Otteniamo così 10 stime della varianza della popolazione del QI.\n\nx_var &lt;- apply(rs, 1, var)  # Applica la funzione var su ciascuna riga\nprint(x_var)\n#&gt;  [1] 196.939534 337.535917 168.546563 218.684024 333.475844  34.520447\n#&gt;  [7] 264.378073 234.081410   1.970867  40.468397\n\nNotiamo due cose:\n\nle stime sono molto diverse tra loro; questo fenomeno è noto con il nome di variabilità campionaria;\nin media le stime sono troppo piccole.\n\nPer aumentare la sicurezza riguardo al secondo punto menzionato in precedenza, ripeteremo la simulazione utilizzando un numero di iterazioni maggiore.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nset.seed(123) # Replace 123 with your desired seed for reproducibility\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var) * (size - 1) / size  # Adjust for population variance (ddof = 0)\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\n# Create a data frame for plotting\ndata &lt;- data.frame(x_var = x_var)\n\n# Plot the histogram using ggplot2\nggplot(data, aes(x = x_var)) +\n  geom_histogram(bins = 10, alpha = 0.5, fill = \"blue\") +\n  labs(x = \"Varianza\", y = \"Frequenza\", title = \"Varianza del QI in campioni di n = 4\")\n\n\n\n\n\n\n\n\nLa stima più verosimile della varianza del QI è dato dalla media di questa distribuzione.\n\nmean(x_var)\n#&gt; [1] 168.9337\n\nSi noti che il nostro spospetto è stato confermato: il valore medio della stima della varianza ottenuta con l’Equazione 16.3 è troppo piccolo rispetto al valore corretto di \\(15^2 = 225\\).\nRipetiamo ora la simulazione usando la formula della varianza con \\(n-1\\) al denominatore.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nset.seed(123) # Replace 123 with your desired seed for reproducibility\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var)  # ddof = 1 is default for var in R\n\nmean(x_var)\n#&gt; [1] 225.2449\n\nNel secondo caso, se utilizziamo \\(n-1\\) come denominatore per calcolare la stima della varianza, il valore atteso di questa stima è molto vicino al valore corretto di 225. Se il numero di campioni fosse infinito, i due valori sarebbero identici.\nIn conclusione, le due formule della varianza hanno scopi diversi. La formula della varianza con \\(n\\) al denominatore viene utilizzata come statistica descrittiva per descrivere la variabilità di un particolare campione di osservazioni. D’altro canto, la formula della varianza con \\(n-1\\) al denominatore viene utilizzata come stimatore per ottenere la migliore stima della varianza della popolazione da cui quel campione è stato estratto.\n\n\n\n16.3.3 Deviazione standard\nPer interpretare la varianza in modo più intuitivo, si può calcolare la deviazione standard (o scarto quadratico medio o scarto tipo) prendendo la radice quadrata della varianza. La deviazione standard è espressa nell’unità di misura originaria dei dati, a differenza della varianza che è espressa nel quadrato dell’unità di misura dei dati. La deviazione standard fornisce una misura della dispersione dei dati attorno alla media, rendendo più facile la comprensione della variabilità dei dati.\nLa deviazione standard (o scarto quadratico medio, o scarto tipo) è definita come:\n\\[\ns^2 = \\sqrt{(n-1)^{-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}.\n\\tag{16.5}\\]\nQuando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s &gt; 0\\).\n\n\n\n\n\n\nNota\n\n\n\nIl termine standard deviation è stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca \\(\\sigma\\) che lo rappresenta. Il termine italiano “deviazione standard” ne è la traduzione più utilizzata nel linguaggio comune; il termine dell’Ente Nazionale Italiano di Unificazione è tuttavia “scarto tipo”, definito come la radice quadrata positiva della varianza.\n\n\nLa deviazione standard \\(s\\) dovrebbe essere utilizzata solo quando la media è una misura appropriata per descrivere il centro della distribuzione, ad esempio nel caso di distribuzioni simmetriche. Tuttavia, è importante tener conto che, come la media \\(\\bar{x}\\), anche la deviazione standard è fortemente influenzata dalla presenza di dati anomali, ovvero pochi valori che si discostano notevolmente dalla media rispetto agli altri dati della distribuzione. In presenza di dati anomali, la deviazione standard può risultare ingannevole e non rappresentare accuratamente la variabilità complessiva della distribuzione. Pertanto, è fondamentale considerare attentamente il contesto e le caratteristiche dei dati prima di utilizzare la deviazione standard come misura di dispersione. In alcune situazioni, potrebbe essere più appropriato ricorrere a misure di dispersione robuste o ad altre statistiche descrittive per caratterizzare la variabilità dei dati in modo più accurato e affidabile.\nPer fare un esempio, calcoliamo la deviazione standard per i valori math del campione di dati del progetto STAR. Applicando l’Equazione 16.5, per tutto il campione abbiamo\n\nsd(df$math)\n#&gt; [1] 38.83834\n\nPer ciascun gruppo, abbiamo:\n\ndf |&gt; \n  group_by(graduated) |&gt; \n  summarise(std_math = sd(math, na.rm = TRUE)) \n#&gt; # A tibble: 2 × 2\n#&gt;   graduated std_math\n#&gt;       &lt;int&gt;    &lt;dbl&gt;\n#&gt; 1         0     34.1\n#&gt; 2         1     38.1\n\n\n16.3.3.1 Interpretazione\nLa deviazione standard può essere interpretata in modo semplice: essa rappresenta la dispersione dei dati rispetto alla media aritmetica. È simile allo scarto semplice medio campionario, cioè alla media aritmetica dei valori assoluti degli scarti tra ciascuna osservazione e la media, anche se non è identica. La deviazione standard ci fornisce un’indicazione di quanto, in media, le singole osservazioni si discostino dal centro della distribuzione.\nPer verificare l’interpretazione della deviazione standard, utilizziamo i valori math del campione di dati del progetto STAR.\n\nsd(df$math)\n#&gt; [1] 38.83834\n\nLa deviazione standard calcolata per questi dati è \\(\\approx 38.8\\). Questo valore ci indica che, in media, ogni osservazione si discosta di circa 38.8 punti dalla media aritmetica dei punteggi math. Maggiore è il valore della deviazione standard, maggiore è la dispersione dei dati attorno alla media, mentre un valore più piccolo indica che i dati sono più concentrati vicino alla media. La deviazione standard ci offre quindi una misura quantitativa della variabilità dei dati nella distribuzione.\nPer questi dati, lo scarto semplice medio campionario è\n\nmean(abs(df$math - mean(df$math, na.rm = TRUE)), na.rm = TRUE)\n#&gt; [1] 30.96827\n\nSi noti che i due valori sono simili, ma non identici.\n\n\n\n16.3.4 Deviazione mediana assoluta\nUna misura robusta della dispersione statistica di un campione è la deviazione mediana assoluta (Median Absolute Deviation, MAD) definita come la mediana del valore assoluto delle deviazioni dei dati dalla mediana. Matematicamente, la formula per calcolare la MAD è:\n\\[\n\\text{MAD} = \\text{median} \\left( |X_i - \\text{median}(X)| \\right)\n\\tag{16.6}\\]\nLa deviazione mediana assoluta è particolarmente utile quando si affrontano distribuzioni con presenza di dati anomali o asimmetrie, poiché è meno influenzata da questi valori estremi rispetto alla deviazione standard.\nQuando i dati seguono una distribuzione gaussiana (normale), esiste una relazione specifica tra MAD e la deviazione standard (si veda il Capitolo {ref}cont-rv-distr-notebook). In una distribuzione normale, la MAD è proporzionale alla deviazione standard. La costante di proporzionalità dipende dalla forma esatta della distribuzione normale, ma in generale, la relazione è data da:\n\\[\n\\sigma \\approx k \\times \\text{MAD},\n\\]\ndove:\n\n\\(\\sigma\\) è la deviazione standard.\nMAD è la Mediana della Deviazione Assoluta.\n\\(k\\) è una costante che, per una distribuzione normale, è tipicamente presa come circa 1.4826.\n\nQuesta costante di 1.4826 è derivata dal fatto che, in una distribuzione normale, circa il 50% dei valori si trova entro 0.6745 deviazioni standard dalla media. Quindi, per convertire la MAD (basata sulla mediana) nella deviazione standard (basata sulla media), si usa il reciproco di 0.6745, che è approssimativamente 1.4826.\nLa formula completa per convertire la MAD in una stima della deviazione standard in una distribuzione normale è:\n\\[\n\\sigma \\approx 1.4826 \\times \\text{MAD}\n\\]\nQuesta relazione è utile per stimare la deviazione standard in modo più robusto, specialmente quando si sospetta la presenza di outlier o si ha a che fare con campioni piccoli. Di conseguenza, molti software restituiscono il valore MAD moltiplicato per questa costante per fornire un’indicazione più intuitiva della variabilità dei dati. Tuttavia, è importante notare che questa relazione si mantiene accurata solo per le distribuzioni che sono effettivamente normali. In presenza di distribuzioni fortemente asimmetriche o con elevati outlier, la deviazione standard e la MAD possono fornire indicazioni molto diverse sulla variabilità dei dati.\nPer verificare questo principio, calcoliamo la deviazione mediana assoluta dei valori math del campione di dati del progetto STAR.\n\n1.4826 * median(abs(df$math - median(df$math, na.rm = TRUE)), na.rm = TRUE)\n#&gt; [1] 41.5128\n\nIn questo caso, la MAD per i punteggi di matematica è simile alla deviazione standard.\n\nsd(df$math)\n#&gt; [1] 38.83834\n\nInfatti, la distribuzione dei punteggi math è approssimativamente gaussiana.\n\nggplot(df, aes(x = math)) +\n  geom_histogram(bins = 10, alpha = 0.5, fill = \"blue\") +\n  labs(x = \"math\", y = \"Frequenza\", title = \"Distribuzione dei Punteggi di Matematica\")\n\n\n\n\n\n\n\n\nVerifichiamo nuovamente il principio usando un campione di dati estratto da una popolazione normale. Usiamo, ad esempio, la distribuzione \\(\\mathcal{N}(100, 15)\\):\n\nset.seed(123) \nx &lt;- rnorm(10000, mean = 100, sd = 15)\n1.4826 * median(abs(x - median(x)))\n#&gt; [1] 14.92317\n\n\n\n16.3.5 Quando usare la deviazione standard e MAD\nLa deviazione standard e la MAD sono entrambe misure di dispersione che forniscono informazioni su quanto i dati in un insieme si discostano dalla tendenza centrale. Tuttavia, ci sono alcune differenze tra le due misure e situazioni in cui può essere più appropriato utilizzare una rispetto all’altra.\n\nDeviazione standard: Questa misura è particolarmente utile per descrivere la dispersione dei dati in una distribuzione normale. La deviazione standard è una scelta appropriata se si vuole sapere quanto i dati sono distribuiti intorno alla media, o se si vuole confrontare la dispersione di due o più set di dati. Tuttavia, la deviazione standard è fortemente influenzata dalla presenza di dati anomali, e questo può rappresentare una limitazione in casi in cui sono presenti valori estremi nell’insieme di dati.\nDeviazione mediana assoluta (MAD): La MAD è meno sensibile ai valori anomali rispetto alla deviazione standard, il che la rende una scelta migliore quando ci sono valori anomali nell’insieme di dati. Inoltre, la MAD può essere una buona scelta quando si lavora con dati non normalmente distribuiti, poiché non assume una distribuzione specifica dei dati. La MAD è calcolata utilizzando la mediana e i valori assoluti delle deviazioni dei dati dalla mediana, il che la rende una misura robusta di dispersione.\n\nIn sintesi, se si sta lavorando con dati normalmente distribuiti, la deviazione standard è la misura di dispersione più appropriata. Se si lavora con dati non normalmente distribuiti o si hanno valori anomali nell’insieme di dati, la MAD può essere una scelta migliore. In ogni caso, la scelta tra le due misure dipende dal tipo di dati che si sta analizzando e dall’obiettivo dell’analisi.\n\n\n16.3.6 Indici di variabilità relativi\nA volte può essere necessario confrontare la variabilità di grandezze incommensurabili, ovvero di caratteri misurati con differenti unità di misura. In queste situazioni, le misure di variabilità descritte in precedenza diventano inadeguate poiché dipendono dall’unità di misura utilizzata. Per superare questo problema, si ricorre a specifici numeri adimensionali chiamati indici relativi di variabilità.\nIl più importante di questi indici è il coefficiente di variazione (\\(C_v\\)), definito come il rapporto tra la deviazione standard (\\(\\sigma\\)) e la media dei dati (\\(\\bar{x}\\)):\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}.\n\\tag{16.7}\\]\nIl coefficiente di variazione è un numero puro e permette di confrontare la variabilità di distribuzioni con unità di misura diverse.\nUn altro indice relativo di variabilità è la differenza interquartile rapportata a uno dei tre quartili (primo quartile, terzo quartile o mediana). Questo indice è definito come:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]\nQuesti indici relativi di variabilità forniscono una misura adimensionale della dispersione dei dati, rendendo possibile il confronto tra grandezze con diverse unità di misura e facilitando l’analisi delle differenze di variabilità tra i dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-fallacia-ergodica",
    "href": "chapters/eda/07_loc_scale.html#la-fallacia-ergodica",
    "title": "16  Indicatori di tendenza centrale e variabilità",
    "section": "16.4 La fallacia ergodica",
    "text": "16.4 La fallacia ergodica\nSebbene il concetto di “media” possa sembrare chiaro, ciò non implica che il suo utilizzo non presenti delle problematiche nell’ambito della pratica psicologica. Un aspetto su cui vale la pena soffermarsi è ciò che viene definito “fallacia ergodica”.\nIl concetto di “fallacia ergodica” (Speelman et al., 2024) si riferisce all’errore compiuto dai ricercatori quando assumono che le caratteristiche medie di un gruppo di individui possano essere applicate a ciascun individuo all’interno di quel gruppo, senza considerare le differenze individuali o le variazioni nel tempo. Questa fallacia emerge dalla pratica comune nella ricerca psicologica di raccogliere dati aggregati da gruppi di persone per stimare parametri della popolazione, al fine di confrontare comportamenti in condizioni diverse o esplorare associazioni tra diverse misurazioni della stessa persona.\nIl problema di questo approccio è che l’uso dei risultati basati sul gruppo per caratterizzare le caratteristiche degli individui o per estrapolare a persone simili a quelle del gruppo è ingiustificato, poiché le medie di gruppo possono fornire informazioni solo sui risultati collettivi, come la performance media del gruppo, e non consentono di fare affermazioni accurate sugli individui che compongono quel gruppo. La fallacia ergodica si basa sull’assunzione che per utilizzare legittimamente una statistica aggregata (ad esempio, la media) derivata da un gruppo per descrivere un individuo di quel gruppo, due condizioni devono essere soddisfatte: gli individui devono essere così simili da essere praticamente interscambiabili, e le caratteristiche degli individui devono essere temporalmente stabili.\nTuttavia, i fenomeni e i processi psicologici di interesse per i ricercatori sono per natura non uniformi tra gli individui e variabili nel tempo, sia all’interno degli individui che tra di loro. Di conseguenza, i risultati ottenuti dalla media di misure di comportamenti, cognizioni o stati emotivi di più individui non descrivono accuratamente nessuno di quegli individui in un dato momento, né possono tenere conto dei cambiamenti in quelle variabili per un individuo nel tempo.\nSpeelman et al. (2024) osservano che la stragrande maggioranza degli articoli che hanno analizzato include conclusioni nelle sezioni degli Abstract e/o delle Discussioni che implicano che i risultati trovati con dati aggregati di gruppo si applichino anche agli individui in quei gruppi e/o si applichino agli individui nella popolazione. Questa pratica riflette la fallacia ergodica, che consiste nell’assumere che i campioni siano sistemi ergodici quando non lo sono.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "href": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "title": "16  Indicatori di tendenza centrale e variabilità",
    "section": "16.5 Riflessioni Conclusive",
    "text": "16.5 Riflessioni Conclusive\nLe statistiche descrittive ci permettono di ottenere indicatori sintetici che riassumono i dati di una popolazione o di un campione estratto da essa. Questi indicatori includono misure di tendenza centrale, come la media, la mediana e la moda, che ci forniscono informazioni sulla posizione centrale dei dati rispetto alla distribuzione. Inoltre, ci sono gli indici di dispersione, come la deviazione standard e la varianza, che ci indicano quanto i dati si disperdono attorno alla tendenza centrale. Questi indici ci aiutano a comprendere quanto i valori si discostano dalla media, e quindi ci forniscono un’idea della variabilità dei dati. In conclusione, le statistiche descrittive ci offrono un quadro sintetico delle caratteristiche principali dei dati, consentendoci di comprendere meglio la loro distribuzione e variabilità.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "title": "16  Indicatori di tendenza centrale e variabilità",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] vcd_1.4-13        MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] R.oo_1.27.0       pkgconfig_2.0.3   data.table_1.16.2 lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] carData_3.0-5     httpuv_1.6.15     htmltools_0.5.8.1 yaml_2.3.10      \n#&gt; [25] Formula_1.2-5     car_3.1-3         pillar_1.9.0      later_1.4.0      \n#&gt; [29] R.utils_2.12.3    abind_1.4-8       nlme_3.1-166      mime_0.12        \n#&gt; [33] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     labeling_0.4.3   \n#&gt; [37] rprojroot_2.0.4   fastmap_1.2.0     colorspace_2.1-1  cli_3.6.3        \n#&gt; [41] magrittr_2.0.3    utf8_1.2.4        broom_1.0.7       withr_3.0.2      \n#&gt; [45] backports_1.5.0   promises_1.3.1    timechange_0.3.0  rmarkdown_2.29   \n#&gt; [49] ggsignif_0.6.4    R.methodsS3_1.8.2 zoo_1.8-12        hms_1.1.3        \n#&gt; [53] shiny_1.9.1       evaluate_1.0.1    lmtest_0.9-40     miniUI_0.1.1.1   \n#&gt; [57] rlang_1.1.4       Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0       \n#&gt; [61] jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#bibliografia",
    "href": "chapters/eda/07_loc_scale.html#bibliografia",
    "title": "16  Indicatori di tendenza centrale e variabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSpeelman, C. P., Parker, L., Rapley, B. J., & McGann, M. (2024). Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals. Collabra: Psychology, 10(1).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html",
    "href": "chapters/eda/08_correlation.html",
    "title": "17  Relazioni tra variabili",
    "section": "",
    "text": "17.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNonostante sia un’operazione di base, l’analisi delle associazioni tra variabili rappresenta uno degli aspetti più controversi nell’ambito dell’analisi dei dati psicologici. Sebbene possa sembrare un passaggio naturale dopo l’analisi univariata, questo processo solleva numerose questioni metodologiche e concettuali.\nTradizionalmente, in psicologia, l’analisi delle associazioni tra variabili è stata considerata come l’obiettivo finale del processo di ricerca. Questa visione si basa sull’idea che la descrizione delle relazioni tra variabili fornisca una spiegazione esaustiva dei fenomeni psicologici. Tale approccio trova le sue radici storiche nel pensiero di Karl Pearson (1911), il quale sosteneva che la spiegazione scientifica si esaurisse una volta delineate le associazioni tra le variabili osservate:\nSebbene sia indubbio che rispondere alla seconda domanda posta da Pearson sia relativamente semplice, è altresì evidente che la nostra comprensione di un fenomeno non può dipendere unicamente dalle informazioni fornite dalle correlazioni.\nIn contrasto con questa visione tradizionale, la “Causal Revolution” propone un paradigma radicalmente diverso secondo il quale le associazioni tra variabili sono considerate come epifenomeni, mentre l’obiettivo principale della ricerca è l’identificazione e la comprensione delle relazioni causali: per comprendere veramente i fenomeni psicologici è essenziale indagare le cause sottostanti, andando oltre la mera descrizione delle associazioni.\nLa discussione dei metodi utilizzati per individuare le relazioni causali sarà trattata successivamente. In questo capitolo, ci concentreremo sui concetti statistici fondamentali necessari per descrivere le associazioni lineari tra variabili. È importante sottolineare che, sebbene esistano indici statistici per quantificare associazioni non lineari, la maggior parte degli psicologi si limita all’utilizzo di indici lineari.\nNel linguaggio comune, termini come “dipendenza”, “associazione” e “correlazione” vengono spesso usati in modo intercambiabile. Tuttavia, da un punto di vista tecnico, è importante distinguere questi concetti:\nÈ cruciale comprendere che non tutte le associazioni sono correlazioni e, soprattutto, che la correlazione non implica necessariamente causalità. Questa distinzione è fondamentale per interpretare correttamente i dati e evitare conclusioni errate sulle relazioni tra variabili.\nIn questo capitolo, esamineremo due misure statistiche fondamentali per valutare la relazione lineare tra due variabili: la covarianza e la correlazione. Questi indici ci permettono di descrivere il grado e la direzione dell’associazione lineare tra variabili, quantificando come queste variano congiuntamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#introduzione",
    "href": "chapters/eda/08_correlation.html#introduzione",
    "title": "17  Relazioni tra variabili",
    "section": "",
    "text": "Quanto spesso, quando è stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‘qual è la sua causa?’. Questa è una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, può essere più facile rispondere alla domanda: ‘in che misura altri fenomeni sono associati con esso?’. Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze.\n\n\n\n\n\n\nAssociazione: questo termine indica una relazione generale tra variabili, dove la conoscenza del valore di una variabile fornisce informazioni su un’altra.\nCorrelazione: descrive una relazione specifica e quantificabile, indicando se due variabili tendono a variare insieme in modo sistematico. Ad esempio, in una correlazione positiva, se \\(X &gt; \\mu_X\\), è probabile che anche \\(Y &gt; \\mu_Y\\). La correlazione specifica il segno e l’intensità di una relazione lineare.\nDipendenza: indica una relazione causale tra le variabili, dove la variazione della variabile causale porta probabilisticamente alla variazione della variabile dipendente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#i-dati-grezzi",
    "href": "chapters/eda/08_correlation.html#i-dati-grezzi",
    "title": "17  Relazioni tra variabili",
    "section": "17.2 I dati grezzi",
    "text": "17.2 I dati grezzi\nPer illustrare la correlazione e la covarianza, analizzeremo i dati raccolti da Zetsche et al. (2019) in uno studio che indaga le aspettative negative come meccanismo chiave nel mantenimento e nella reiterazione della depressione. Nello specifico, i ricercatori si sono proposti di determinare se gli individui depressi sviluppano aspettative accurate riguardo al loro umore futuro o se tali aspettative sono distortamente negative.\nUno dei loro studi ha coinvolto un campione di 30 soggetti con almeno un episodio depressivo maggiore, confrontati con un gruppo di controllo composto da 37 individui sani. La misurazione del livello di depressione è stata effettuata tramite il Beck Depression Inventory (BDI-II).\nIl BDI-II è uno strumento di autovalutazione utilizzato per valutare la gravità della depressione in adulti e adolescenti. Il test è stato sviluppato per identificare e misurare l’intensità dei sintomi depressivi sperimentati nelle ultime due settimane. I 21 item del test sono valutati su una scala a 4 punti, dove 0 rappresenta il grado più basso e 3 il grado più elevato di sintomatologia depressiva.\nNell’esercizio successivo, ci proponiamo di analizzare i punteggi di depressione BDI-II nel campione di dati fornito da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#definizione-delle-relazioni-tra-variabili",
    "href": "chapters/eda/08_correlation.html#definizione-delle-relazioni-tra-variabili",
    "title": "17  Relazioni tra variabili",
    "section": "17.3 Definizione delle relazioni tra variabili",
    "text": "17.3 Definizione delle relazioni tra variabili\nNel contesto delle indagini statistiche, spesso non ci limitiamo a esaminare la distribuzione di una singola variabile. Invece, il nostro interesse si concentra sulla relazione che emerge nei dati tra due o più variabili. Ma cosa significa esattamente quando diciamo che due variabili hanno una relazione?\nPer comprendere ciò, prendiamo ad esempio l’altezza e l’età tra un gruppo di bambini. In generale, è possibile notare che all’aumentare dell’età di un bambino, aumenta anche la sua altezza. Pertanto, conoscere l’età di un bambino, ad esempio tredici anni, e l’età di un altro, sei anni, ci fornisce un’indicazione su quale dei due bambini sia più alto.\nNel linguaggio statistico, definiamo questa relazione tra altezza e età come positiva, il che significa che all’aumentare dei valori di una delle variabili (in questo caso, l’età), ci aspettiamo di vedere valori più elevati anche nell’altra variabile (l’altezza). Tuttavia, esistono anche relazioni negative, in cui l’aumento di una variabile è associato a un diminuzione dell’altra (ad esempio, più età è correlata a meno pianto).\nNon si tratta solo di relazioni positive o negative; ci sono anche situazioni in cui le variabili non hanno alcuna relazione tra loro, definendo così una relazione nulla. Inoltre, le relazioni possono variare nel tempo, passando da positive a negative o da fortemente positive a appena positiva. In alcuni casi, una delle variabili può essere categorica, rendendo difficile parlare di “maggioranza” o “minoranza” ma piuttosto di “differente” (ad esempio, i bambini più grandi potrebbero semplicemente avere diverse preferenze rispetto ai bambini più piccoli, senza necessariamente essere “migliori” o “peggiori”).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#sec-scatter-plot",
    "href": "chapters/eda/08_correlation.html#sec-scatter-plot",
    "title": "17  Relazioni tra variabili",
    "section": "17.4 Grafico a dispersione",
    "text": "17.4 Grafico a dispersione\nIl metodo più diretto per visualizzare la relazione tra due variabili continue è tramite un grafico a dispersione, comunemente noto come “scatterplot”. Questo tipo di diagramma rappresenta le coppie di dati ottenute da due variabili, posizionandole sull’asse delle ascisse (orizzontale) e delle ordinate (verticale).\nPer rendere l’idea più chiara, consideriamo i dati dello studio condotto da Zetsche et al. (2019), in cui i ricercatori hanno utilizzato due scale psicometriche, il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D), per misurare il livello di depressione nei partecipanti. Il BDI-II è uno strumento di autovalutazione che valuta la presenza e l’intensità dei sintomi depressivi in pazienti adulti e adolescenti con diagnosi psichiatrica, mentre la CES-D è una scala di autovalutazione progettata per misurare i sintomi depressivi sperimentati nella settimana precedente nella popolazione generale, in particolare negli adolescenti e nei giovani adulti. Poiché entrambe le scale misurano lo stesso costrutto, ovvero la depressione, ci aspettiamo una relazione tra i punteggi ottenuti dal BDI-II e dalla CES-D. Un diagramma a dispersione ci consente di esaminare questa relazione in modo visuale e intuitivo.\n\n# Leggi i dati dal file CSV\ndf = rio::import(here::here(\"data\", \"data.mood.csv\"))\n\n# Seleziona le colonne di interesse\ndf &lt;- df |&gt; \n  dplyr::select(\"esm_id\", \"group\", \"bdi\", \"cesd_sum\")\n\n# Rimuovi le righe duplicate\ndf &lt;- df[!duplicated(df), ]\n\n# Rimuovi le righe con valori mancanti nella colonna \"bdi\"\ndf &lt;- df[!is.na(df$bdi), ]\n\nPosizionando i valori del BDI-II sull’asse delle ascisse e quelli del CES-D sull’asse delle ordinate, ogni punto sul grafico rappresenta un individuo, di cui conosciamo il livello di depressione misurato dalle due scale. È evidente che i valori delle scale BDI-II e CES-D non possono coincidere per due motivi principali: (1) la presenza di errori di misurazione e (2) l’utilizzo di unità di misura arbitrarie per le due variabili. L’errore di misurazione è una componente inevitabile che influisce in parte su qualsiasi misurazione, ed è particolarmente rilevante in psicologia, dove la precisione degli strumenti di misurazione è generalmente inferiore rispetto ad altre discipline, come la fisica. Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere identici è che l’unità di misura della depressione è una questione arbitraria e non standardizzata. Tuttavia, nonostante le differenze dovute agli errori di misurazione e all’uso di unità di misura diverse, ci aspettiamo che, se le due scale misurano lo stesso costrutto (la depressione), i valori prodotti dalle due scale dovrebbero essere associati linearmente tra di loro. Per comprendere meglio il concetto di “associazione lineare”, è possibile esaminare i dati attraverso l’utilizzo di un diagramma a dispersione.\n\n\n\n\n\n\n\n\n\nOsservando il grafico a dispersione, è evidente che i dati mostrano una tendenza a distribuirsi in modo approssimativamente lineare. In termini statistici, ciò suggerisce una relazione di associazione lineare tra i punteggi CES-D e BDI-II.\nTuttavia, è importante notare che la relazione lineare tra le due variabili è lontana dall’essere perfetta. In una relazione lineare perfetta, tutti i punti nel grafico sarebbero allineati in modo preciso lungo una retta. Nella realtà, la dispersione dei punti dal comportamento lineare ideale è evidente.\nDi conseguenza, sorge la necessità di quantificare numericamente la forza e la direzione della relazione lineare tra le due variabili e di misurare quanto i punti si discostino da una relazione lineare ideale. Esistono vari indici statistici a disposizione per raggiungere questo obiettivo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#covarianza",
    "href": "chapters/eda/08_correlation.html#covarianza",
    "title": "17  Relazioni tra variabili",
    "section": "17.5 Covarianza",
    "text": "17.5 Covarianza\nIniziamo a considerare il più importante di tali indici, chiamato covarianza. In realtà la definizione di questo indice non ci sorprenderà più di tanto in quanto, in una forma solo apparentemente diversa, l’abbiamo già incontrata in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) è definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\]\nLa varianza viene talvolta descritta come la “covarianza di una variabile con sé stessa”. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, ci chiediamo come due variabili \\(X\\) e \\(Y\\) “variano insieme” (co-variano). È facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{17.1}\\]\nL’Equazione 17.1 ci fornisce la definizione della covarianza.\n\n17.5.1 Interpretazione\nPer capire il significato dell’Equazione 17.1, supponiamo di dividere il grafico riportato nella Sezione 17.4 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avrà un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza avrà segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avrà un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza avrà segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l’associazione lineare si dice positiva se la covarianza è positiva, negativa se la covarianza è negativa.\nEsercizio. Implemento l’Equazione 17.1 in R.\n\ncov_value &lt;- function(x, y) {\n  mean_x &lt;- sum(x) / length(x)\n  mean_y &lt;- sum(y) / length(y)\n  \n  sub_x &lt;- x - mean_x\n  sub_y &lt;- y - mean_y\n  \n  sum_value &lt;- sum(sub_y * sub_x)\n  denom &lt;- length(x)\n  \n  cov &lt;- sum_value / denom\n  return(cov)\n}\n\nPer i dati mostrati nel diagramma, la covarianza tra BDI-II e CESD è 207.4\n\nx = df$bdi\ny = df$cesd_sum\n\ncov_value(x, y)\n#&gt; [1] 207.4265\n\nOppure, in maniera più semplice:\n\nmean((x - mean(x)) * (y - mean(y)))\n#&gt; [1] 207.4265\n\nLo stesso risultato si ottiene con la funzione cov:\n\ncov(x, y) * (length(x) - 1) / length(x)\n#&gt; [1] 207.4265\n\nLa funzione cov(x, y) calcola la covarianza tra due array, x e y utilizzando \\(n-1\\) al denominatore.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione",
    "href": "chapters/eda/08_correlation.html#correlazione",
    "title": "17  Relazioni tra variabili",
    "section": "17.6 Correlazione",
    "text": "17.6 Correlazione\nLa direzione della relazione tra le variabili è indicata dal segno della covarianza, ma il valore assoluto di questo indice non fornisce informazioni utili poiché dipende dall’unità di misura delle variabili. Ad esempio, considerando l’altezza e il peso delle persone, la covarianza sarà più grande se l’altezza è misurata in millimetri e il peso in grammi, rispetto al caso in cui l’altezza è in metri e il peso in chilogrammi. Pertanto, per descrivere la forza e la direzione della relazione lineare tra due variabili in modo adimensionale, si utilizza l’indice di correlazione.\nLa correlazione è ottenuta standardizzando la covarianza tramite la divisione delle deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr = \\frac{S_{XY}}{S_X S_Y}.\n\\tag{17.2}\\]\nLa quantità che si ottiene dall’Equazione 17.2 viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l’uno dall’altro, l’hanno introdotta).\nIn maniera equivalente, per una lista di coppie di valori \\((x_1, y_1), \\dots, (x_n, y_n)\\), il coefficiente di correlazione è definito come la media del prodotto dei valori standardizzati:\n\\[\nr = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{\\sigma_x} \\right) \\left( \\frac{y_i - \\bar{y}}{\\sigma_y} \\right),\n\\tag{17.3}\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) rappresentano, rispettivamente, le medie dei valori \\(x\\) e \\(y\\), e \\(\\sigma_x\\) e \\(\\sigma_y\\) sono le rispettive deviazioni standard.\nNell’Equazione 17.3, i valori \\(x_i\\) e \\(y_i\\) vengono prima standardizzati sottraendo la media e dividendo per la deviazione standard, e poi si calcola la media del prodotto di questi valori standardizzati.\n\n17.6.1 Proprietà\nIl coefficiente di correlazione ha le seguenti proprietà:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\nè un numero puro, cioè non dipende dall’unità di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\n\n\n17.6.2 Interpretazione\nAll’indice di correlazione possiamo assegnare la seguente interpretazione:\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensità diversa;\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\nEsercizio. Per i dati riportati nel diagramma della sezione {ref}sec-zetsche-scatter, la covarianza è 207.4. Il segno positivo della covarianza ci dice che tra le due variabili c’è un’associazione lineare positiva. Per capire quale sia l’intensità della relazione lineare calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore è prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva.\nTroviamo la correlazione con la funzione corrcoef():\n\ncor(x, y)\n#&gt; [1] 0.904062\n\nReplichiamo il risultato implementando l’eq. {eq}eq-cor-def:\n\ns_xy &lt;- mean((x - mean(x)) * (y - mean(y)))\ns_x &lt;- sqrt(mean((x - mean(x))^2))  # Deviazione standard popolazione\ns_y &lt;- sqrt(mean((y - mean(y))^2))  # Deviazione standard popolazione\nr_xy &lt;- s_xy / (s_x * s_y)\nprint(r_xy)\n#&gt; [1] 0.904062\n\nUn altro modo ancora per trovare la correlazione tra i punteggi BDI-II e CESD è quello di applicare l’Equazione 17.3:\n\nz_x &lt;- (x - mean(x)) / sqrt(mean((x - mean(x))^2))  # Standardizzazione con deviazione standard popolazione\nz_y &lt;- (y - mean(y)) / sqrt(mean((y - mean(y))^2))  # Standardizzazione con deviazione standard popolazione\nmean(z_x * z_y)\n#&gt; [1] 0.904062\n\nEsempio. Un uso interessante delle correlazioni viene fatto in un recente articolo di Guilbeault et al. (2024). Il concetto di “gender bias” si riferisce alla tendenza sistematica di favorire un sesso rispetto all’altro, spesso a scapito delle donne. Lo studio di Guilbeault et al. (2024) analizza come le immagini online influenzino la diffusione su vasta scala di questo preconcetto di genere.\nAttraverso un vasto insieme di immagini e testi raccolti online, gli autori dimostrano che sia le misurazioni basate sulle immagini che quelle basate sui testi catturano la frequenza con cui varie categorie sociali sono associate a rappresentazioni di genere, valutate su una scala da -1 (femminile) a 1 (maschile), con 0 che indica una neutralità di genere. Questo consente di quantificare il preconcetto di genere come una forma di bias statistico lungo tre dimensioni: la tendenza delle categorie sociali ad associarsi a un genere specifico nelle immagini e nei testi, la rappresentazione relativa delle donne rispetto agli uomini in tutte le categorie sociali nelle immagini e nei testi, e il confronto tra le associazioni di genere nei dati delle immagini e dei testi con la distribuzione empirica delle donne e degli uomini nella società. Il lavoro di Guilbeault et al. (2024) evidenzia che il preconcetto di genere è molto più evidente nelle immagini rispetto ai testi, come mostrato nella {numref}gender-bias-1-fig C.\nSi noti che, nel grafico della {numref}gender-bias-1-fig C, ogni punto può essere interpretato come una misura di correlazione. La misura utilizzata da Guilbeault et al. (2024) riflette il grado di associazione tra le categorie sociali e le rappresentazioni di genere presenti nelle immagini e nei testi analizzati. Quando la misura è vicina a +1, indica una forte associazione positiva tra una categoria sociale specifica e una rappresentazione di genere maschile, mentre un valore vicino a -1 indica una forte associazione negativa con una rappresentazione di genere femminile. Un valore di 0, invece, suggerisce che non vi è alcuna associazione tra la categoria sociale considerata e un genere specifico, indicando una sorta di neutralità di genere. In sostanza, questa misura di frequenza può essere interpretata come una correlazione che riflette la tendenza delle categorie sociali a essere rappresentate in un modo o nell’altro nelle immagini e nei testi analizzati, rispetto ai concetti di genere femminile e maschile.\n\n\n\nIl preconcetto di genere è più prevalente nelle immagini online (da Google Immagini) e nei testi online (da Google News). A. La correlazione tra le associazioni di genere nelle immagini da Google Immagini e nei testi da Google News per tutte le categorie sociali (n = 2.986), organizzate per decili. B. La forza dell’associazione di genere in queste immagini e testi online per tutte le categorie (n = 2.986), suddivisa in base al fatto che queste categorie siano inclinate verso il femminile o il maschile. C. Le associazioni di genere per un campione di occupazioni secondo queste immagini e testi online; questo campione è stato selezionato manualmente per evidenziare i tipi di categorie sociali e preconcetti di genere esaminati. (Figura tratta da Guilbeault et al. (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "href": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "title": "17  Relazioni tra variabili",
    "section": "17.7 Correlazione di Spearman",
    "text": "17.7 Correlazione di Spearman\nUn’alternativa per valutare la relazione lineare tra due variabili è il coefficiente di correlazione di Spearman, che si basa esclusivamente sull’ordine dei dati e non sugli specifici valori. Questo indice di associazione è particolarmente adatto quando gli psicologi sono in grado di misurare solo le relazioni di ordine tra diverse modalità di risposta dei soggetti, ma non l’intensità della risposta stessa. Tali variabili psicologiche che presentano questa caratteristica sono definite come “ordinali”.\n\n\n\n\n\n\nNota\n\n\n\nÈ importante ricordare che, nel caso di una variabile ordinale, non è possibile utilizzare le statistiche descrittive convenzionali come la media e la varianza per sintetizzare le osservazioni. Tuttavia, è possibile riassumere le osservazioni attraverso una distribuzione di frequenze delle diverse modalità di risposta. Come abbiamo appena visto, la direzione e l’intensità dell’associazione tra due variabili ordinali possono essere descritte utilizzando il coefficiente di correlazione di Spearman.\n\n\nPer fornire un esempio, consideriamo due variabili di scala ordinale e calcoliamo la correlazione di Spearman tra di esse.\n\ncor.test(c(1, 2, 3, 4, 5), c(5, 6, 7, 8, 7), method = \"spearman\")\n#&gt; Warning in cor.test.default(c(1, 2, 3, 4, 5), c(5, 6, 7, 8, 7), method =\n#&gt; \"spearman\"): Impossibile calcolare p-value esatti in presenza di ties\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  c(1, 2, 3, 4, 5) and c(5, 6, 7, 8, 7)\n#&gt; S = 3.5843, p-value = 0.08859\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt;       rho \n#&gt; 0.8207827",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione-nulla",
    "href": "chapters/eda/08_correlation.html#correlazione-nulla",
    "title": "17  Relazioni tra variabili",
    "section": "17.8 Correlazione nulla",
    "text": "17.8 Correlazione nulla\nUn aspetto finale da sottolineare riguardo alla correlazione è che essa descrive la direzione e l’intensità della relazione lineare tra due variabili. Tuttavia, la correlazione non cattura relazioni non lineari tra le variabili, anche se possono essere molto forti. È fondamentale comprendere che una correlazione pari a zero non implica l’assenza di una relazione tra le due variabili, ma indica solamente l’assenza di una relazione lineare tra di esse.\nLa figura seguente fornisce tredici esempi di correlazione nulla in presenza di una chiara relazione (non lineare) tra due variabili. In questi tredici insiemi di dati i coefficienti di correlazione di Pearson sono sempre uguali a 0. Ma questo non significa che non vi sia alcuna relazione tra le variabili.\n\ndatasaurus_data &lt;- read.csv(\"../../data/datasaurus.csv\")\n\ndatasaurus_summary &lt;- datasaurus_data %&gt;%\n  group_by(dataset) %&gt;%\n  summarise(\n    x_count = n(),\n    x_mean = mean(x, na.rm = TRUE),\n    x_std = sd(x, na.rm = TRUE),\n    y_count = n(),\n    y_mean = mean(y, na.rm = TRUE),\n    y_std = sd(y, na.rm = TRUE)\n  )\n\nprint(datasaurus_summary)\n#&gt; # A tibble: 13 × 7\n#&gt;   dataset  x_count x_mean x_std y_count y_mean y_std\n#&gt;   &lt;chr&gt;      &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 away         142   54.3  16.8     142   47.8  26.9\n#&gt; 2 bullseye     142   54.3  16.8     142   47.8  26.9\n#&gt; 3 circle       142   54.3  16.8     142   47.8  26.9\n#&gt; 4 dino         142   54.3  16.8     142   47.8  26.9\n#&gt; 5 dots         142   54.3  16.8     142   47.8  26.9\n#&gt; 6 h_lines      142   54.3  16.8     142   47.8  26.9\n#&gt; # ℹ 7 more rows\n\n\ndatasaurus_data |&gt; \n  ggplot(aes(x = x, y = y)) +\n  geom_point(alpha = 0.7) +\n  facet_wrap(~ dataset, nrow = 4, ncol = 4) +\n  labs(x = NULL, y = NULL)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#due-paradossi-comuni",
    "href": "chapters/eda/08_correlation.html#due-paradossi-comuni",
    "title": "17  Relazioni tra variabili",
    "section": "17.9 Due Paradossi Comuni",
    "text": "17.9 Due Paradossi Comuni\nEsistono due situazioni comuni in cui le associazioni tra variabili possono ingannarci, e che vale la pena esaminare esplicitamente: il paradosso di Simpson e il paradosso di Berkson.\n\n17.9.1 Paradosso di Simpson\nIl paradosso di Simpson si verifica quando stimiamo una relazione per sottoinsiemi dei nostri dati, ma otteniamo una relazione diversa considerando l’intero dataset (Simpson 1951). È un caso particolare della fallacia ecologica, che si verifica quando cerchiamo di fare affermazioni sugli individui basandoci sui loro gruppi. Ad esempio, potrebbe esserci una relazione positiva tra i voti universitari e la performance alla scuola di specializzazione in due dipartimenti considerati individualmente. Tuttavia, se i voti universitari tendono a essere più alti in un dipartimento rispetto all’altro, mentre la performance alla scuola di specializzazione tende a essere opposta, potremmo trovare una relazione negativa tra i voti universitari e la performance alla scuola di specializzazione.\n\n\n17.9.2 Paradosso di Berkson\nIl paradosso di Berkson si verifica quando stimiamo una relazione basandoci sul dataset che abbiamo, ma a causa della selezione del dataset, la relazione risulta diversa in un dataset più generale (Berkson 1946). Ad esempio, se abbiamo un dataset di ciclisti professionisti, potremmo non trovare una relazione tra il loro VO2 max e la possibilità di vincere una gara di ciclismo (Coyle et al. 1988; Podlogar, Leo, and Spragg 2022). Tuttavia, se avessimo un dataset della popolazione generale, potremmo trovare una relazione tra queste due variabili. Il dataset professionale è così selezionato che la relazione scompare; non si può diventare ciclisti professionisti senza avere un VO2 max adeguato, ma tra i ciclisti professionisti, tutti hanno un VO2 max sufficiente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#considerazioni-conclusive",
    "href": "chapters/eda/08_correlation.html#considerazioni-conclusive",
    "title": "17  Relazioni tra variabili",
    "section": "17.10 Considerazioni conclusive",
    "text": "17.10 Considerazioni conclusive\nIn questo capitolo, abbiamo approfondito i concetti di correlazione e covarianza, strumenti chiave per quantificare le relazioni tra variabili nei fenomeni psicologici. L’aspetto cruciale non risiede tanto nel saper calcolare queste misure, quanto nel comprendere le informazioni che esse offrono. È fondamentale ricordare che le associazioni osservate non indicano necessariamente i meccanismi causali sottostanti.\nLe relazioni tra variabili possono presentarsi in diversi scenari:\n\nCausalità diretta: Quando una variabile \\(X\\) influisce direttamente su una variabile \\(Y\\), l’associazione tra le due sarà evidente. In un contesto ideale, con un effetto causale lineare e isolato, la correlazione rifletterebbe esattamente la forza e la direzione dell’effetto causale. Tuttavia, questo scenario è teorico e raramente applicabile ai fenomeni psicologici complessi.\nInfluenza di altre variabili: Nella realtà, anche quando esiste una relazione causale diretta tra \\(X\\) e \\(Y\\), l’intervento di altre variabili può modificare l’associazione osservata. Come vedremo nel prossimo capitolo, la struttura delle relazioni causali può portare a correlazioni positive, nulle o persino negative, pur in presenza di un effetto causale positivo.\nAssociazioni spurie: È possibile riscontrare associazioni tra variabili che non sono causate da una relazione diretta tra di esse. Questo fenomeno evidenzia l’importanza di non confondere correlazione e causalità, e di essere cauti nelle interpretazioni.\n\nQuesti scenari mettono in luce un principio fondamentale: l’osservazione di un’associazione tra due variabili non è sufficiente per inferire una relazione causale. Le associazioni, considerate isolatamente, forniscono informazioni limitate sul fenomeno in esame.\nTuttavia, in alcuni contesti, le associazioni possono rivelarsi utili:\n\nquando vengono misurate molteplici variabili e si utilizzano tecniche psicometriche come l’analisi fattoriale o lo scaling psicologico;\nquando si ha una chiara comprensione dei meccanismi causali che regolano il dominio di studio, permettendo di controllare le variabili confondenti tramite l’uso di metodi statistici avanzati.\n\nNel capitolo successivo, ci concentreremo su queste tematiche, esplorando strumenti e metodologie che ci consentiranno di andare oltre la semplice osservazione delle associazioni, per avvicinarci a una comprensione più profonda e causale dei fenomeni psicologici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "title": "17  Relazioni tra variabili",
    "section": "17.11 Informazioni sull’Ambiente di Sviluppo",
    "text": "17.11 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pointblank_0.12.2 haven_2.5.4       labelled_2.13.0   mice_3.16.0      \n#&gt;  [5] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [9] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt; [13] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [17] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [21] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [25] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1      rlang_1.1.4       magrittr_2.0.3    compiler_4.4.2   \n#&gt;  [5] vctrs_0.6.5       pkgconfig_2.0.3   shape_1.4.6.1     fastmap_1.2.0    \n#&gt;  [9] backports_1.5.0   labeling_0.4.3    utf8_1.2.4        promises_1.3.1   \n#&gt; [13] blastula_0.3.5    rmarkdown_2.29    tzdb_0.4.0        nloptr_2.1.1     \n#&gt; [17] xfun_0.49         glmnet_4.1-8      jomo_2.7-6        jsonlite_1.8.9   \n#&gt; [21] later_1.4.0       pan_1.9           broom_1.0.7       parallel_4.4.2   \n#&gt; [25] R6_2.5.1          stringi_1.8.4     car_3.1-3         boot_1.3-31      \n#&gt; [29] rpart_4.1.23      Rcpp_1.0.13-1     iterators_1.0.14  pacman_0.5.1     \n#&gt; [33] R.utils_2.12.3    httpuv_1.6.15     Matrix_1.7-1      splines_4.4.2    \n#&gt; [37] nnet_7.3-19       timechange_0.3.0  tidyselect_1.2.1  abind_1.4-8      \n#&gt; [41] yaml_2.3.10       codetools_0.2-20  miniUI_0.1.1.1    lattice_0.22-6   \n#&gt; [45] shiny_1.9.1       withr_3.0.2       evaluate_1.0.1    survival_3.7-0   \n#&gt; [49] pillar_1.9.0      carData_3.0-5     foreach_1.5.2     generics_0.1.3   \n#&gt; [53] rprojroot_2.0.4   hms_1.1.3         munsell_0.5.1     minqa_1.2.8      \n#&gt; [57] xtable_1.8-4      glue_1.8.0        tools_4.4.2       data.table_1.16.2\n#&gt; [61] lme4_1.1-35.5     ggsignif_0.6.4    grid_4.4.2        colorspace_2.1-1 \n#&gt; [65] nlme_3.1-166      Formula_1.2-5     cli_3.6.3         fansi_1.0.6      \n#&gt; [69] gtable_0.3.6      R.methodsS3_1.8.2 rstatix_0.7.2     digest_0.6.37    \n#&gt; [73] htmlwidgets_1.6.4 farver_2.1.2      R.oo_1.27.0       htmltools_0.5.8.1\n#&gt; [77] lifecycle_1.0.4   mitml_0.4-5       mime_0.12",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#bibliografia",
    "href": "chapters/eda/08_correlation.html#bibliografia",
    "title": "17  Relazioni tra variabili",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHamaker, E. (2024). The curious case of the cross-sectional correlation. Multivariate Behavioral Research, 59(6), 1111–1122.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html",
    "href": "chapters/eda/09_causality.html",
    "title": "18  Causalità dai dati osservazionali",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e competenze chiave\nLa pura osservazione dei dati può rivelare correlazioni e pattern nei dati, ma senza un’indagine sulle cause che stanno alla base di tali correlazioni, le conclusioni tratte possono essere fuorvianti o incomplete.\nRichard McElreath, nel suo libro “Statistical Rethinking” (McElreath, 2020), utilizza l’analogia dei Golem - creature potenti ma prive di saggezza - per descrivere un approccio metodologico che è stato a lungo predominante in psicologia. Questo approccio si basa esclusivamente sull’analisi delle associazioni statistiche tra variabili, trascurando considerazioni più profonde sulla causalità.\nIl metodo in questione si concentra principalmente sul test delle ipotesi nulle, senza stabilire una chiara connessione tra le domande di ricerca riguardanti relazioni causali e i test statistici impiegati. Questa disconnessione è evidente nella figura successiva, tratta da un manuale di analisi dati di impostazione frequentista, che illustra la procedura raccomandata dai sostenitori di questo approccio per descrivere le associazioni tra variabili.\nÈ importante notare come tale procedura non fornisca strumenti utili per identificare le effettive cause sottostanti ai fenomeni osservati. Questa limitazione metodologica è stata identificata come uno dei fattori principali che hanno contribuito alla crisi di replicabilità nella ricerca psicologica, come approfondito nel ?sec-crisis. L’approccio descritto, pur essendo potente nell’individuare correlazioni, manca della “saggezza” necessaria per distinguere tra semplici associazioni e vere relazioni causali, analogamente ai Golem della metafora di McElreath.\nUn problema evidenziato da McElreath (2020) è che processi causali completamente distinti possono generare la stessa distribuzione di risultati osservati. Pertanto, un approccio focalizzato esclusivamente sull’analisi delle associazioni mediante il test dell’ipotesi nulla non è in grado di distinguere tra questi diversi scenari, come spiegato nel ?sec-causal-inference-regr.\nL’approccio frequentista, che si limita a descrivere le associazioni tra le variabili, ha una scarsa capacità di rilevare le caratteristiche cruciali dei fenomeni studiati e tende a produrre un alto tasso di falsi positivi (Zwet et al., 2023). È invece necessario utilizzare una metodologia che non si limiti a confutare ipotesi nulle, ma sia in grado di sviluppare modelli causali che rispondano direttamente alle domande di ricerca. In questo capitolo, ci concentreremo sull’introduzione dei concetti fondamentali dell’analisi causale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#introduzione",
    "href": "chapters/eda/09_causality.html#introduzione",
    "title": "18  Causalità dai dati osservazionali",
    "section": "",
    "text": "Esempio di albero decisionale per la selezione di una procedura statistica appropriata. Iniziando dall’alto, l’utente risponde a una serie di domande riguardanti la misurazione e l’intento, arrivando infine al nome di una procedura. Sono possibili molti alberi decisionali simili. (Figura tratta da McElreath (2020)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#cosè-la-causalità",
    "href": "chapters/eda/09_causality.html#cosè-la-causalità",
    "title": "18  Causalità dai dati osservazionali",
    "section": "18.1 Cos’è la causalità?",
    "text": "18.1 Cos’è la causalità?\nHardt & Recht (2022) introducono il concetto di causalità distinguendo tra osservazione e azione. Ciò che vediamo nell’osservazione passiva è il modo in cui le persone seguono i loro comportamenti abituali, le loro inclinazioni naturali, proiettando lo stato del mondo su un insieme di caratteristiche che abbiamo scelto di evidenziare. Tuttavia, le domande più importanti spesso non riguardano semplici osservazioni.\n\nNon ci basta sapere che le persone che praticano regolarmente attività fisica soffrono meno d’ansia; vogliamo capire se l’attività fisica riduce effettivamente i livelli d’ansia.\nNon ci accontentiamo di osservare che chi segue una terapia cognitivo-comportamentale (CBT) presenta meno sintomi depressivi; desideriamo verificare se la CBT riduce realmente questi sintomi.\nNon ci limitiamo a constatare che l’uso frequente dei social media è associato a un calo del benessere mentale; vogliamo determinare se l’uso intensivo dei social media causa effettivamente una diminuzione del benessere mentale.\n\nAlla base, il ragionamento causale è un quadro concettuale per affrontare domande sugli effetti di azioni o interventi ipotetici. Una volta compreso quale sia l’effetto di un’azione, possiamo invertire la domanda e chiederci quale azione plausibile abbia causato un determinato evento.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#effetto-causale",
    "href": "chapters/eda/09_causality.html#effetto-causale",
    "title": "18  Causalità dai dati osservazionali",
    "section": "18.2 Effetto Causale",
    "text": "18.2 Effetto Causale\nSebbene non esista una definizione univoca di causalità, possiamo concettualizzarla in modo pratico: diciamo che X causa Y se, intervenendo e modificando il valore di X (il trattamento), la distribuzione di Y cambia di conseguenza. Questa definizione sottolinea l’importanza cruciale dell’azione o dell’intervento nel determinare una relazione causale.\nQuando X è una variabile binaria, rappresentante la presenza o l’assenza del trattamento, la conseguenza dell’intervento su X è denominata effetto medio del trattamento. Questo ci indica quanto il trattamento (azione X = 1) aumenta l’aspettativa di Y rispetto all’assenza di trattamento (azione X = 0).\nÈ importante notare che gli effetti causali sono quantità relative alla popolazione. Si riferiscono a effetti mediati sull’intera popolazione in esame. Tuttavia, spesso l’effetto del trattamento può variare significativamente da un individuo all’altro o tra gruppi di individui. In questi casi, parliamo di effetti di trattamento eterogenei.\nPer chiarire questo concetto, consideriamo un esempio concreto: supponiamo che la terapia cognitivo-comportamentale (CBT) riduca l’ansia. Se un gruppo di persone ansiose non riceve alcun trattamento, i loro livelli d’ansia rimarranno presumibilmente invariati. Se invece interveniamo introducendo la CBT (modificando così il valore di X), i livelli d’ansia nel gruppo tenderanno a diminuire (cambiando quindi il valore di Y). Questo esempio illustra la distinzione tra semplice correlazione, basata sull’osservazione passiva, e causalità, che implica un’azione o un intervento.\nLa definizione di causalità può essere applicata anche per collegare variabili apparentemente distanti. Ad esempio, l’autoefficacia potrebbe non avere un effetto causale diretto sulle prestazioni accademiche. Tuttavia, se aumentiamo l’autoefficacia attraverso interventi mirati, è probabile che osserviamo un miglioramento nell’impegno allo studio. Questo aumento dell’impegno, a sua volta, tende a migliorare le prestazioni accademiche. Di conseguenza, possiamo affermare che l’autoefficacia influisce indirettamente sulle prestazioni accademiche attraverso una catena causale.\nÈ importante precisare che affermiamo l’esistenza di una relazione causale tra X e Y anche quando modificare X non porta necessariamente a un cambiamento immediato o deterministico in Y, ma altera la probabilità che Y si verifichi in un certo modo, modificando quindi la distribuzione di Y. Questa prospettiva probabilistica della causalità è particolarmente rilevante in campi come la psicologia, dove le relazioni tra variabili sono spesso complesse e influenzate da molteplici fattori.\n\n18.2.1 I Limiti dell’Osservazione\nPer comprendere i limiti dell’osservazione passiva, e quindi la necessità di comprendere le relazioni causali sottostanti, Hardt & Recht (2022) si riferiscono all’esempio storico delle ammissioni ai corsi di laurea dell’Università della California, Berkeley, nel 1973. In quell’anno, 12,763 candidati furono considerati per l’ammissione in uno dei 101 dipartimenti o major interdipartimentali. Di questi, 4,321 erano donne e 8,442 erano uomini. I dati mostrano che circa il 35% delle donne fu ammesso, rispetto al 44% degli uomini. Test di significatività statistica indicano che questa differenza non è attribuibile al caso, suggerendo una disparità nei tassi di ammissione tra i generi.\nUna tendenza simile si osserva quando si analizzano le decisioni aggregate di ammissione nei sei maggiori dipartimenti. Il tasso di ammissione complessivo per gli uomini era di circa il 44%, mentre per le donne era solo il 30%, un’altra differenza significativa. Tuttavia, poiché i dipartimenti hanno autonomia nelle loro decisioni di ammissione, è utile esaminare il possibile bias di genere a livello di singolo dipartimento.\nUomini\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n825\n62\n\n\nB\n520\n60\n\n\nC\n325\n37\n\n\nD\n417\n33\n\n\nE\n191\n28\n\n\nF\n373\n6\n\n\n\nDonne\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n108\n82\n\n\nB\n25\n68\n\n\nC\n593\n34\n\n\nD\n375\n35\n\n\nE\n393\n24\n\n\nF\n341\n7\n\n\n\nDall’osservazione di questi dati, emerge che quattro dei sei maggiori dipartimenti mostrano un tasso di ammissione più elevato per le donne, mentre due mostrano un tasso più elevato per gli uomini. Tuttavia, questi due dipartimenti non possono giustificare la sostanziale differenza nei tassi di ammissione osservata nei dati aggregati. Questo suggerisce che la tendenza generale di un tasso di ammissione più alto per gli uomini sembra invertita quando i dati sono disaggregati per dipartimento.\nQuesto fenomeno è noto come paradosso di Simpson, un paradosso statistico in cui una tendenza che appare in sottopopolazioni si inverte o scompare quando i dati vengono aggregati. Nel contesto attuale, il paradosso di Simpson si manifesta nel fatto che, mentre i dati aggregati sembrano indicare una discriminazione di genere contro le donne, l’analisi dei dati disaggregati per dipartimento rivela che in alcuni casi le donne sono favorite in termini di ammissioni.\nLa domanda fondamentale è se questi dati indicano effettivamente un problema di discriminazione di genere o se, come suggerito dallo studio originale, il bias di genere nelle ammissioni fosse principalmente dovuto al fatto che “le donne sono indirizzate dalla loro socializzazione e istruzione verso campi di studio generalmente più affollati, meno produttivi in termini di completamento dei diplomi, meno finanziati e che spesso offrono prospettive professionali peggiori.” In altre parole, il problema risiederebbe in differenze sistemiche e strutturali tra i campi di studio scelti dalle donne e quelli scelti dagli uomini.\nIl paradosso di Simpson crea disagio proprio perché l’intuizione suggerisce che una tendenza valida per tutte le sottopopolazioni dovrebbe esserlo anche a livello aggregato. Tuttavia, questo paradosso evidenzia un errore comune nell’interpretazione delle probabilità condizionate: confondere l’osservazione passiva con l’analisi causale. I dati che abbiamo rappresentano solo un’istantanea del comportamento normale di uomini e donne che si candidavano per l’ammissione a UC Berkeley nel 1973.\nNon possiamo trarre conclusioni definitive da questi dati. Possiamo solo riconoscere che l’analisi iniziale solleva ulteriori domande, come ad esempio la necessità di progettare nuovi studi per raccogliere dati più completi, che potrebbero portare a conclusioni più definitive. In alternativa, potremmo discutere su quale scenario sia più verosimile in base alle nostre convinzioni e alle notre ipotesi sul mondo.\nL’inferenza causale può essere utile in entrambi i casi. Da un lato, può guidare la progettazione di nuovi studi, aiutandoci a scegliere quali variabili includere, quali escludere e quali mantenere costanti. Dall’altro, i modelli causali possono fungere da meccanismo per incorporare le conoscenze scientifiche del dominio e passare da ipotesi plausibili a conclusioni plausibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#variabili-confondenti",
    "href": "chapters/eda/09_causality.html#variabili-confondenti",
    "title": "18  Causalità dai dati osservazionali",
    "section": "18.3 Variabili confondenti",
    "text": "18.3 Variabili confondenti\nSebbene gli esperimenti controllati offrano un elevato grado di certezza nell’identificazione di queste relazioni, molte domande di ricerca non possono essere affrontate sperimentalmente a causa di limitazioni etiche o pratiche. In questi casi, i ricercatori ricorrono a disegni osservazionali, che offrono maggiore flessibilità e applicabilità. Tuttavia, l’uso di dati osservazionali comporta una sfida significativa: la difficoltà di trarre conclusioni causali affidabili.\nAl centro di questa complessità si trovano le variabili confondenti. Possiamo dire che una variabile confondente è presente quando l’associazione osservata tra due variabili X e Y non riflette accuratamente la vera relazione causale tra di esse. In altre parole, la variabile confondente influenza sia X che Y, creando l’apparenza di una relazione diretta tra le due che potrebbe essere fuorviante o inesatta.\nNegli studi osservazionali, se le variabili confondenti non vengono misurate e controllate adeguatamente, possono distorcere le stime degli effetti causali, introducendo bias nei risultati e impedendo di riflettere il vero valore dell’effetto. In pratica, la presenza di variabili confondenti può portare a conclusioni errate quando si confrontano semplicemente i risultati osservati in diversi gruppi. Ciò che si osserva nei dati potrebbe non corrispondere a ciò che accadrebbe se si potesse manipolare direttamente la variabile di interesse in un esperimento controllato.\nUn approccio apparentemente semplice per affrontare questo problema potrebbe essere quello di controllare statisticamente tutte le variabili confondenti. In questo metodo, si stima l’effetto di X su Y separatamente in ogni segmento della popolazione definito da una condizione Z = z per ogni possibile valore di z. Successivamente, si calcola la media di questi effetti stimati nelle sottopopolazioni, ponderandoli per la probabilità di Z = z nella popolazione. Tuttavia, questo metodo presenta due difficoltà fondamentali: richiede la conoscenza di tutte le possibili variabili confondenti e la capacità di misurare ciascuna di esse, cosa che spesso non è praticabile.\nIl controllo delle variabili confondenti è cruciale per stabilire relazioni causali, poiché permette di isolare gli effetti delle variabili indipendenti da quelli delle variabili confondenti che potrebbero influenzare le variabili dipendenti. Esistono due principali metodologie di controllo:\n\nIl controllo sperimentale, implementato attraverso il disegno sperimentale e basato principalmente sulla randomizzazione.\nIl controllo statistico, applicato durante l’analisi dei dati, con l’obiettivo di neutralizzare o quantificare l’influenza delle variabili estranee.\n\nA causa di queste difficoltà, l’inferenza causale basata su dati osservazionali è spesso considerata problematica, dando origine al famoso detto “la correlazione non implica causalità”. Tuttavia, è importante notare che in alcune circostanze, è possibile fare inferenze causali anche a partire da dati osservazionali.\nL’obiettivo dell’analisi causale moderna è proprio quello di fornire gli strumenti concettuali e metodologici per affrontare queste sfide. Attraverso l’uso di tecniche avanzate come i modelli causali strutturali, i grafi aciclici diretti (DAG) e i metodi di identificazione degli effetti causali, i ricercatori possono spesso superare le limitazioni dei dati osservazionali e trarre conclusioni causali più robuste.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "href": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "title": "18  Causalità dai dati osservazionali",
    "section": "18.4 Modelli Causali Strutturali",
    "text": "18.4 Modelli Causali Strutturali\nI modelli causali sono strumenti essenziali per l’analisi dei dati osservazionali, poiché consentono di rappresentare il processo sottostante a un fenomeno e di prevedere gli effetti di un intervento. Questi modelli non solo permettono di anticipare le conseguenze di una causa, ma offrono anche la possibilità di esplorare scenari controfattuali, immaginando esiti alternativi che si sarebbero potuti verificare in presenza di decisioni diverse.\nUn modello causale strutturale (Structural Causal Model, SCM) è un approccio che rappresenta le relazioni causali tra variabili. Esso si basa su una serie di assegnazioni che, partendo da variabili di rumore indipendenti (note anche come variabili esogene), generano una distribuzione di probabilità congiunta.\nLe variabili di rumore indipendenti svolgono un ruolo cruciale negli SCM. Esse rappresentano fonti di incertezza o variabilità all’interno del sistema e non sono influenzate da altre variabili del modello. Queste variabili sono mutuamente indipendenti, il che significa che il loro valore non fornisce informazioni sul valore delle altre.\nLa costruzione di un SCM segue una sequenza specifica: si parte dalle variabili di rumore indipendenti, si applicano una serie di assegnazioni che descrivono gli effetti causali delle variabili esogene su altre variabili, e si genera progressivamente un insieme di variabili casuali che dà origine a una distribuzione congiunta.\nIl principale vantaggio di un SCM risiede nella sua duplice natura: da un lato, fornisce una distribuzione di probabilità congiunta delle variabili, e dall’altro, descrive il processo generativo che porta alla formazione di tale distribuzione, partendo dalle variabili di rumore elementari.\nQuesta struttura consente non solo di modellare le relazioni probabilistiche tra le variabili, ma anche di rappresentare in modo esplicito i meccanismi causali che le governano.\nI SCM possono essere rappresentati graficamente attraverso Grafi Aciclici Direzionati (Directed Acyclic Graphs, DAG). Questi DAG visualizzano le relazioni causali tra le variabili all’interno di un SCM, facilitando l’identificazione delle variabili confondenti e il loro impatto sull’analisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "href": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "title": "18  Causalità dai dati osservazionali",
    "section": "18.5 Bias da Variabile Omessa",
    "text": "18.5 Bias da Variabile Omessa\nPossiamo introdurre i DAG facendo riferiento al bias da variabile omessa (Omitted Variable Bias, o OVB; Wilms et al. (2021)). Come discusso da Byrnes & Dee (2024), l’omissione dall’analisi statistica di variabili confondenti note ma non misurate, o sconosciute e non misurate, può portare a stime errate della magnitudine degli effetti, errori nel segno delle stime (stimatori distorti), correlazioni spurie, e al mascheramento delle vere relazioni causali.\nUn illustrazione di questa situazione è fornita nella Figura 18.1. La figura mostra tre DAG che illustrano diversi scenari in cui le variabili non osservate non influenzano i risultati del modello o potrebbero creare problemi a causa della confusione. Una variabile di risposta di interesse (Y) è causata sia da una variabile misurata (X) che da una variabile non misurata (U). Nel pannello di sinistra, la variabile non osservata (U) non è una variabile confondente. Nel pannello centrale, la variabile non osservata (U) è una variabile confondente e causa il bias da variabile omessa. Nel pannello di destra la variabile non osservata (U) causa il bias da variabile omessa in maniera indiretta.\n\n\n\n\n\n\nFigura 18.1: Nel pannello di sinistra, X e U sono non correlate, quindi la mancata inclusione di U in un modello statistico aumenterebbe l’errore standard della stima (riducendo la precisione del modello) ma non porterebbe a bias nella stima dell’effetto di X su Y. Tuttavia, se U influenza anche X come nel pannello centrale, o se U e X sono influenzati da un fattore comune Z come nel pannello di destra, allora omettere U da un modello statistico causa il bias da variabile omessa nella stima dell’effetto di X su Y. I casi illustrati dal pannello centrale e dal pannello di destra sono esempi di sistemi in cui le cause comuni di confusione (U e Z rispettivamente) devono essere controllate per effettuare inferenze causali non distorte (la figura è ispirata da Byrnes & Dee (2024)).\n\n\n\nAffrontare i problemi creati dalle variabili confondenti non misurate rappresenta una sfida primaria nell’inferenza causale dai dati osservazionali. A differenza dell’errore di misurazione nelle variabili predittive, che produce un bias costante verso lo zero e può essere corretto o modellato (McElreath, 2020; Schennach, 2016), con l’OVB non possiamo conoscere la grandezza o la direzione del bias senza conoscere tutte le possibili variabili confondenti e le loro relazioni nel sistema.\nNonostante queste sfide, non è necessario abbandonare l’uso dei dati osservazionali per l’inferenza causale in psicologia. È invece necessario ricorrere all’adozione delle tecniche dei SCM per potere comunque svolgere l’inferenza causale.\nÈ evidente che questo approccio porterà a conclusioni inevitabilmente parziali, destinate ad essere perfezionate da studi successivi. Tuttavia, tale metodologia offre il vantaggio di esplicitare il “modello generativo dei dati”, ovvero la struttura causale sottostante ai fenomeni psicologici oggetto di studio.\nI progressi nella ricerca empirica conducono a una maggiore comprensione e, di conseguenza, a modifiche nelle ipotesi sui meccanismi causali. Questo processo rappresenta un’evoluzione della conoscenza scientifica. Tale sviluppo è reso possibile proprio perché le ipotesi causali sono formulate in termini di modelli formali, che descrivono in modo preciso i meccanismi ipotizzati.\nAl contrario, limitarsi alla mera descrizione delle associazioni tra variabili non consente questo tipo di avanzamento conoscitivo. La formulazione di modelli causali espliciti permette infatti di testare, raffinare e, se necessario, rivedere le ipotesi sui meccanismi sottostanti ai fenomeni osservati, portando a una comprensione più profonda e dinamica dei processi psicologici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "href": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "title": "18  Causalità dai dati osservazionali",
    "section": "18.6 Grafi Aciclici Diretti",
    "text": "18.6 Grafi Aciclici Diretti\nI DAG sono uno strumento fondamentale per l’inferenza causale, offrendo una rappresentazione visiva delle relazioni causali ipotizzate tra variabili. Questi grafi sono definiti “diretti” perché le variabili, rappresentate da nodi, sono collegate da frecce orientate anziché da semplici linee. Sono inoltre chiamati “aciclici” poiché non è possibile tornare a un nodo di partenza seguendo il percorso delle frecce.\nIn un DAG, una freccia che va da X a Y indica un’influenza probabilistica di X su Y. La terminologia delle relazioni all’interno del grafo è importante: il nodo di origine di una freccia è chiamato “genitore”, mentre il nodo di destinazione è detto “figlio”. Quando è possibile raggiungere un nodo B partendo da un nodo A seguendo una successione di frecce, A è definito “antenato” di B, e B è considerato “discendente” di A.\nI DAG consentono di distinguere chiaramente tra cause dirette e indirette. Una causa diretta è rappresentata da un nodo genitore, mentre una causa indiretta può essere qualsiasi antenato di un nodo nel grafo causale. Questa struttura permette di differenziare efficacemente causa ed effetto basandosi sulla posizione relativa dei nodi all’interno del grafo, ovvero se un nodo è antenato o discendente di un altro.\nQuesti grafi sono particolarmente utili per identificare variabili confondenti, basandosi sulla teoria sviluppata da Judea Pearl (Pearl, 2009). È cruciale rappresentare in un DAG tutte le possibili relazioni causali, poiché l’assenza di una freccia tra due nodi implica la certezza dell’assenza di una relazione causale diretta tra le variabili corrispondenti.\nNella teoria dei DAG, due concetti fondamentali sono la d-separazione e il criterio del back-door.\n\nLa d-separazione\nLa d-separazione ci aiuta a determinare quando due variabili in un grafo causale sono indipendenti condizionatamente a un insieme di altre variabili. Questo concetto è cruciale per comprendere come l’informazione o l’influenza si propaga tra le variabili in un modello causale.\nIn termini più semplici, la d-separazione ci permette di identificare se esiste un “blocco” nel flusso di informazioni tra due variabili, dato un certo insieme di altre variabili (che chiameremo Λ). Quando due variabili sono d-separate da Λ, significa che non c’è flusso di informazioni tra di loro, condizionatamente a Λ.\nPer comprendere meglio la d-separazione, consideriamo tre situazioni principali che possono verificarsi in un DAG:\n\nCatena (X → Z → Y): In questo caso, Z è un mediatore tra X e Y. Se Z appartiene all’insieme Λ (cioè, se controlliamo o condizioniamo su Z), blocchiamo il flusso di informazioni da X a Y attraverso questo percorso. Per esempio, se X è “esercizio fisico”, Z è “pressione sanguigna” e Y è “rischio di malattie cardiache”, controllando per la pressione sanguigna (Z) blocchiamo il percorso attraverso il quale l’esercizio fisico influenza il rischio di malattie cardiache.\nFork (X ← Z → Y): Qui, Z è una causa comune sia di X che di Y. Se Z appartiene a Λ, blocchiamo la correlazione spuria tra X e Y che deriva dalla loro causa comune. Per esempio, se Z è “status socioeconomico”, X è “livello di istruzione” e Y è “stato di salute”, controllando per lo status socioeconomico (Z) eliminiamo la correlazione apparente tra istruzione e salute che potrebbe derivare dal fatto che entrambe sono influenzate dallo status socioeconomico.\nCollider (X → Z ← Y): In questa situazione, Z è un effetto comune di X e Y. Sorprendentemente, se né Z né i suoi discendenti appartengono a Λ, il percorso è già bloccato. Controllare per Z (o i suoi discendenti) in realtà aprirebbe un percorso tra X e Y, creando una correlazione spuria. Per esempio, se X è “intelligenza”, Y è “bellezza” e Z è “successo in una carriera di attore”, controllare per il successo nella carriera di attore (Z) creerebbe una correlazione apparente tra intelligenza e bellezza, anche se queste potrebbero essere indipendenti nella popolazione generale.\n\nIn sintesi, la d-separazione ci permette di determinare, dato un certo insieme di variabili Λ, se due variabili X e Y sono indipendenti condizionatamente a Λ. Questo ci aiuta a identificare quali variabili dobbiamo controllare (e quali non dobbiamo controllare) per ottenere stime causali non distorte, facilitando così l’inferenza causale corretta. La d-separazione è quindi uno strumento potente che ci permette di leggere le indipendenze condizionali direttamente dal grafo, senza dover fare calcoli probabilistici complessi.\n\n\nIl criterio del back-door\nIl criterio del back-door consente di identificare un insieme di variabili che, se controllate adeguatamente, permettono di stimare gli effetti causali in modo non distorto. L’obiettivo principale di questo criterio è eliminare l’influenza di percorsi non causali tra la variabile di esposizione (causa potenziale) e l’outcome (effetto), mantenendo aperto solo il percorso causale diretto di interesse.\nIn questo contesto, due variabili sono considerate “confuse” se esiste tra di esse un percorso di tipo back-door. Un back-door path da X a Y è definito come qualsiasi percorso che inizia da X con una freccia entrante in X. Per esempio, consideriamo il seguente percorso:\nX ← A → B ← C → Y\nIn questo caso, il percorso rappresenta un flusso di informazioni da X a Y che non è causale, ma potrebbe creare l’apparenza di una relazione causale.\nPer “deconfondere” una coppia di variabili, è necessario selezionare un insieme di variabili (chiamato back-door set) che “blocchi” tutti i back-door paths tra i due nodi di interesse. Il blocco di questi percorsi avviene in modi diversi a seconda della struttura del percorso:\n\nUn back-door path che coinvolge una catena di variabili (ad esempio, A → B → C) può essere bloccato controllando per la variabile intermedia (in questo caso, B).\nUn percorso che coinvolge un “collider” (una variabile che riceve frecce da entrambe le direzioni, come in A → B ← C) è naturalmente bloccato e non permette il flusso di informazioni.\n\nÈ importante notare che bisogna prestare attenzione a non aprire involontariamente un flusso di informazioni attraverso un collider. Questo può accadere se si condiziona l’analisi sul collider stesso o su un suo discendente, il che potrebbe erroneamente aprire il percorso e introdurre bias nell’analisi.\n\nPunti chiave:\n\nIl criterio del back-door aiuta a identificare il set minimale di variabili da controllare.\nNon tutte le variabili associate sia all’esposizione che all’outcome devono essere controllate; solo quelle che creano percorsi back-door.\nIn alcuni casi, potrebbe non essere necessario controllare alcuna variabile (se non ci sono percorsi back-door aperti).\nIn altri casi, potrebbe essere impossibile bloccare tutti i percorsi back-door con le variabili disponibili, indicando che l’effetto causale non può essere identificato con i dati a disposizione.\n\nUtilizzando il criterio del back-door in combinazione con i DAG, i ricercatori possono fare scelte più informate su quali variabili includere nelle loro analisi, migliorando così la validità delle loro inferenze causali.\n\n\n\n18.6.1 Applicazioni\nConsideriamo nuovamente la struttura causale illustrata nella Figura 18.1, pannello centrale. Dopo aver costruito un DAG come descritto nella sezione precedente, è possibile identificare le potenziali fonti di bias da variabili omesse, inclusi i confondenti non misurati (ad esempio, U). Non controllare per le variabili confondenti apre una “back-door” permettendo alla variazione confondente di influenzare la relazione tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl, 2009). In altre parole, omettere una variabile confondente come U nella Figura 18.1 (pannello centrale) in un’analisi statistica significa che questa viene incorporata nel termine di errore del modello statistico, insieme alle fonti di errore casuali. La Figura 18.2 illustra le conseguenze di un confondente U che ha un effetto positivo su X ma un effetto negativo su Y. Se adattiamo un modello come mostrato nella Figura 18.2 bi, l’effetto stimato di X su Y è positivo quando si controlla per U. Tuttavia, se non si controlla per U, come mostrato nella Figura 18.2 bii, U viene incorporato nel termine di errore, inducendo una correlazione tra l’errore e X, come illustrato nella Figura 18.2 biii, portando a una stima errata. Pertanto, il termine di errore del modello e X risultano correlati, il che viola un’assunzione fondamentale dei modelli lineari (ovvero, il teorema di Gauss-Markov; Abdallah et al., 2015; Antonakis et al., 2010). Questo produce una stima errata, evidenziata in blu.\n\n\n\n\n\n\nFigura 18.2: Una visualizzazione del bias da variabile omessa e delle conseguenze per l’inferenza causale. (A) mostra un DAG di un sistema in cui X ha un effetto positivo su Y, e una variabile confondente U ha un effetto positivo su Y ma un effetto negativo su X. Le variabili non osservate (cioè non misurate) sono rappresentate in ellissi, come la variabile U e il termine di errore e nel pannello B. (B) illustra diverse stime del DAG in (A) utilizzando un’analisi del percorso. Vedi Box 1 per una breve spiegazione delle principali differenze tra DAG e diagrammi dei percorsi. Presumiamo che U non sia misurata. In (Bi), presumiamo di poter misurare e controllare U, rappresentata dalla freccia a doppia testa tra U e X, che rappresenta la correlazione tra le due variabili considerata dal modello. La variabile non misurata e è la fonte residua di variazione che si presume non sia correlata con nessun predittore. La freccia rossa rappresenta il percorso stimato. Al contrario, (Bii) e (Biii) rappresentano la realtà, dove non abbiamo una misurazione di U e non la controlliamo nel modello dei percorsi. Il ricercatore pensa di adattare il modello in (Bii) ma in realtà sta adattando il modello in (Biii), dove il termine di errore non è solo e, ma la somma di e e la variazione dovuta alla variabile omessa U. A causa di ciò, c’è un percorso diretto dal termine di errore del modello a X (e quindi X è endogeno). (C) mostra le relazioni stimate risultanti dai modelli in (Bi) rispetto a (Bii). Le linee rappresentano la relazione stimata tra X e Y dai rispettivi modelli. La linea rossa è la vera relazione causale, stimata da (Bi), mentre la linea blu contiene il bias da variabile omessa, poiché non si tiene conto della variabile confondente U, come stimato dal modello in Bii/Biii (Figura tratta da Byrnes & Dee (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#commenti-e-considerazioni-finali",
    "href": "chapters/eda/09_causality.html#commenti-e-considerazioni-finali",
    "title": "18  Causalità dai dati osservazionali",
    "section": "18.7 Commenti e Considerazioni Finali",
    "text": "18.7 Commenti e Considerazioni Finali\nI diagrammi causali sono uno dei primi strumenti per identificare il bias da variabili omesse (Pearl, 1995; Pearl et al., 2016). I diagrammi causali, sotto forma di DAG, visualizzano la nostra comprensione delle relazioni causali e delle variabili confondenti all’interno di un sistema. In questo modo, i DAG chiariscono in modo trasparente le assunzioni dietro le affermazioni causali derivate dai dati e mostrano le potenziali fonti di bias derivanti da variabili confondenti.\nÈ fondamentale che i DAG includano tutte le cause comuni di un predittore e della risposta di interesse, comprendendo tutte le variabili confondenti misurate e non misurate. Questo significa che l’inferenza causale è possibile solo quando il ricercatore dispone di adeguate conoscenze del dominio.\nDopo aver costruito un DAG, è possibile determinare le potenziali fonti di bias da variabili omesse, incluse quelle derivanti da variabili confondenti non misurate (es., U nella figura fig-byrnes-dee-1, pannello centrale). Non controllare le variabili confondenti apre una “back-door” per la variazione confondente, permettendo a quest’ultima di fluire tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl, 2009).\nPertanto, un diagramma causale è un primo passo fondamentale per identificare potenziali bias da variabili omesse. I DAG giustificano anche la scelta delle variabili di controllo, rendendo trasparenti le assunzioni che un ricercatore fa su come funziona il sistema oggetto di studio.\nÈ importante notare che i DAG possono essere incorretti o non includere variabili confondenti sconosciute. Infatti, un DAG rappresenta solo la comprensione attuale e le assunzioni del ricercatore riguardo alle relazioni causali all’interno di un sistema.\nUn sommario ironico di questi concetti è fornito nella vignetta di xkcd.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bibliografia",
    "href": "chapters/eda/09_causality.html#bibliografia",
    "title": "18  Causalità dai dati osservazionali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nByrnes, J. E., & Dee, L. E. (2024). Causal inference with observational data and unobserved confounding variables. bioRxiv, 2024–2002.\n\n\nHardt, M., & Recht, B. (2022). Patterns, Predictions, and Actions: Foundations of Machine Learning. Princeton University Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPearl, J. (1995). Causal diagrams for empirical research. Biometrika, 82(4), 669–688.\n\n\nPearl, J. (2009). Causality. Cambridge University Press.\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal inference in statistics: A primer. John Wiley & Sons.\n\n\nRiederer, E. (2021). Causal design patterns for data analysts. https://emilyriederer.netlify.app/post/causal-design-patterns/\n\n\nSchennach, S. M. (2016). Recent advances in the measurement error literature. Annual Review of Economics, 8(1), 341–377.\n\n\nWilms, R., Mäthner, E., Winnen, L., & Lanwehr, R. (2021). Omitted variable bias: A threat to estimating causal relationships. Methods in Psychology, 5, 100075.\n\n\nZwet, E. van, Gelman, A., Greenland, S., Imbens, G., Schwab, S., & Goodman, S. N. (2023). A New Look at P Values for Randomized Clinical Trials. NEJM Evidence, 3(1), EVIDoa2300003.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html",
    "href": "chapters/eda/10_estimand.html",
    "title": "19  Estimandi teorici e estimandi empirici",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e competenze chiave\nIn questo capitolo abbiamo esplorato diverse tecniche di analisi esplorativa dei dati, utili per sintetizzare grandi quantità di informazioni e visualizzare le distribuzioni delle variabili e le relazioni tra esse. Abbiamo presunto che le variabili siano state misurate correttamente per rispondere a una specifica domanda teorica. Tuttavia, invece di considerare questo legame tra estimandi empirici e teorici come scontato, è importante riflettere criticamente su tale relazione. A tal fine, esamineremo l’articolo di Lundberg et al. (2021), intitolato “What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory”. Il punto centrale dell’articolo è l’importanza di definire con chiarezza l’estimando chiave in qualsiasi studio quantitativo, affinché questo possa rispondere in modo preciso alla domanda di ricerca.\nL’estimando è la quantità che uno studio intende stimare, fungendo da collegamento tra teoria ed evidenza statistica. Gli autori propongono un approccio metodologico articolato in tre fasi principali:\nQuesto approccio chiarisce come le evidenze empiriche possano rispondere alle domande teoriche alla base della ricerca. In sintesi, Lundberg et al. (2021) esortano i ricercatori a definire con precisione l’estimando teorico, indipendentemente dal modello statistico utilizzato, per rendere esplicito il collegamento tra teoria ed evidenza empirica.\nIn altre parole, gli autori sottolineano che non è sufficiente affermare che lo scopo di uno studio è verificare se un coefficiente di regressione sia “significativamente diverso da zero”, poiché in questo caso l’estimando è definito solo in relazione al modello statistico. Al contrario, è necessario distinguere tra estimando teorico (l’obiettivo concettuale della ricerca, ad esempio l’apprendimento associativo) ed estimando empirico (la misura osservabile). Ad esempio, l’estimando empirico potrebbe essere rappresentato dal tasso di apprendimento \\(\\alpha\\) o dalla temperatura inversa \\(\\beta\\), parametri del modello Rescorla-Wagner applicato ai dati di un compito di Probabilistic Reversal Learning (PRL). Questi parametri spiegano l’apprendimento associativo in termini di predisposizione del soggetto a modificare il valore attribuito agli stimoli o la sua strategia di scelta (esplorazione vs sfruttamento) — si veda la sezione ?sec-rescorla-wagner.\nÈ cruciale riconoscere che gli estimandi empirici possono essere calcolati in modi diversi. Il modello Rescorla-Wagner è solo uno dei tanti modelli per rappresentare l’apprendimento associativo, e i parametri possono essere stimati attraverso vari metodi. Inoltre, i dati su cui si basano queste analisi possono essere raccolti in esperimenti progettati in modi differenti o applicati a popolazioni diverse. Pertanto, l’estimando empirico, ossia il valore numerico che rappresenta la capacità di apprendimento associativo, può variare a seconda del modello, delle tecniche di stima e del design sperimentale utilizzati.\nIn definitiva, Lundberg et al. (2021) sottolineano che i ricercatori devono definire la loro domanda di ricerca in termini di un estimando teorico che sia indipendente dal metodo di analisi dei dati. Successivamente, devono giustificare la scelta di uno specifico estimando empirico, spiegando perché, dati i dati disponibili, hanno optato per una particolare strategia di stima piuttosto che per altre, visto che molteplici opzioni sono generalmente disponibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#introduzione",
    "href": "chapters/eda/10_estimand.html#introduzione",
    "title": "19  Estimandi teorici e estimandi empirici",
    "section": "",
    "text": "Definire un estimando teorico, collegandolo chiaramente alla teoria che guida la ricerca.\nCollegare l’estimando teorico a un estimando empirico, ossia una misura ottenuta dai dati osservabili che fornisca informazioni sull’estimando teorico, considerando una serie di assunzioni di identificazione.\nApprendere dai dati, scegliendo strategie di stima appropriate per ottenere l’estimando empirico in modo rigoroso.\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nIn italiano, la traduzione comunemente usata di “estimand” nella letteratura scientifica è estimando. Questo termine viene utilizzato per riferirsi alla quantità o al parametro che si desidera stimare in un’analisi statistica.\nStimatore, invece, è la traduzione di “estimator” e si riferisce alla regola o alla funzione utilizzata per calcolare una stima basata sui dati osservati. Quindi, “estimando” e “stimatore” sono termini distinti: l’“estimando” è l’oggetto dell’inferenza statistica, mentre lo “stimatore” è il metodo o la formula usata per ottenere l’inferenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#limiti-dellapproccio-attuale",
    "href": "chapters/eda/10_estimand.html#limiti-dellapproccio-attuale",
    "title": "19  Estimandi teorici e estimandi empirici",
    "section": "19.1 Limiti dell’Approccio Attuale",
    "text": "19.1 Limiti dell’Approccio Attuale\nLundberg et al. (2021) osservano che spesso i ricercatori sociali omettono il passaggio cruciale della definizione dell’estimando, concentrandosi direttamente sui dati e sulle procedure statistiche. Questo approccio può causare una mancanza di chiarezza riguardo a ciò che si intende effettivamente stimare, limitando anche l’uso di modelli statistici alternativi che potrebbero essere più adatti a rispondere alla domanda di ricerca. Sebbene Lundberg et al. (2021) facciano riferimento alla letteratura sociologica, questi stessi argomenti sono applicabili anche alla psicologia.\nIl problema del collegamento tra estimandi teorici ed empirici (si veda la figura seguente) può essere illustrato con un esempio in psicologia riguardante l’intelligenza. La distinzione tra estimandi teorici ed empirici è cruciale: gli estimandi teorici possono includere quantità non osservabili, come i costrutti latenti, ad esempio l’intelligenza come concetto astratto. Gli estimandi empirici, invece, riguardano esclusivamente dati osservabili, come i punteggi ottenuti in un test di intelligenza.\nNel caso dell’intelligenza, la scelta dell’estimando teorico richiede un’argomentazione sostanziale riguardo alla teoria dell’intelligenza adottata e agli obiettivi della ricerca. Ad esempio, se si vuole studiare l’intelligenza generale (fattore g), bisogna chiarire come questo costrutto viene teoricamente definito e perché è rilevante per lo studio.\nD’altra parte, la scelta dell’estimando empirico richiede un’argomentazione concettuale su come i dati osservabili, come i risultati dei test di intelligenza, possano rappresentare il costrutto latente di interesse. È necessario spiegare quali dati vengono utilizzati per inferire il costrutto teorico e quali assunzioni si fanno riguardo al rapporto tra le misure osservate e il costrutto latente.\nInfine, la scelta delle strategie di stima, come l’uso di modelli di equazioni strutturali per stimare l’intelligenza generale da diversi test, è una decisione separata, che può essere in parte guidata dai dati disponibili e dalle caratteristiche della misurazione. Separare chiaramente questi passaggi aiuta i ricercatori a fare scelte informate e fondate, consente ai lettori di valutare in modo critico le affermazioni fatte e permette alla comunità scientifica di costruire su basi solide per futuri sviluppi della ricerca.\n\n\n\nTre Scelte Critiche nelle Argomentazioni delle Scienze Sociali Quantitative. La prima scelta riguarda gli estimandi teorici, che definiscono gli obiettivi dell’inferenza. È necessario un argomento che colleghi gli estimandi teorici alla teoria più ampia. La seconda scelta riguarda gli estimandi empirici, che collegano questi obiettivi ai dati osservabili. Questo collegamento richiede delle assunzioni sostanziali, che possono essere formalizzate attraverso grafici aciclici diretti. La terza scelta riguarda le strategie di stima, che determinano come verranno effettivamente utilizzati i dati. La selezione delle strategie di stima si basa sui dati disponibili (figura tratta da Lundberg et al. (2021)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#definizione-dellestimando-teorico",
    "href": "chapters/eda/10_estimand.html#definizione-dellestimando-teorico",
    "title": "19  Estimandi teorici e estimandi empirici",
    "section": "19.2 Definizione dell’Estimando Teorico",
    "text": "19.2 Definizione dell’Estimando Teorico\nLa definizione dell’estimando teorico è cruciale per determinare la natura dello studio perché specifica chiaramente quale tipo di relazione tra le variabili stiamo cercando di indagare. In altre parole, l’estimando teorico indica se lo studio mira a descrivere, prevedere o stabilire una relazione causale. Vediamo come questo funziona in pratica con esempi legati all’intelligenza e all’allenamento cognitivo.\n\n19.2.1 1. Estimando Teorico in uno Studio Descrittivo\nUno studio descrittivo ha come obiettivo semplicemente quello di caratterizzare o descrivere una certa realtà o fenomeno senza inferire relazioni di causa-effetto. In questo caso, l’estimando teorico potrebbe essere una misura che riassume una caratteristica della popolazione.\nEsempio: Qual è il punteggio medio di intelligenza tra le persone che hanno partecipato a un programma di allenamento cognitivo rispetto a quelle che non l’hanno fatto?\nEstimando Teorico: La differenza media nei punteggi di intelligenza tra i due gruppi. Questo tipo di estimando descrive la distribuzione dei punteggi di intelligenza nei gruppi, ma non implica che l’allenamento abbia causato le differenze osservate.\n\n\n19.2.2 2. Estimando Teorico in uno Studio Predittivo\nUno studio predittivo si concentra sulla capacità di prevedere un risultato basato su dati osservabili. Qui, l’estimando teorico riguarda la capacità del modello di predire correttamente i risultati futuri, ma senza implicazioni causali.\nEsempio: In che misura la partecipazione a un programma di allenamento cognitivo può prevedere il punteggio di intelligenza futuro di una persona?\nEstimando Teorico: La previsione del punteggio di intelligenza basata sulla partecipazione all’allenamento cognitivo. Questo estimando si basa su modelli statistici che utilizzano variabili osservabili per fare previsioni, ma non determinano la causalità tra allenamento e punteggi di intelligenza.\n\n\n19.2.3 3. Estimando Teorico in uno Studio Causale\nUno studio causale cerca di stabilire un nesso diretto di causa-effetto tra variabili. L’estimando teorico in questo caso riguarda l’effetto diretto di una variabile indipendente su una variabile dipendente, tenendo conto di altre variabili confondenti.\nEsempio: L’allenamento cognitivo causa un aumento nei punteggi di intelligenza?\nEstimando Teorico: La differenza media nei punteggi di intelligenza che si attribuisce direttamente all’effetto dell’allenamento cognitivo, controllando per tutte le altre variabili confondenti. Questo estimando implica l’uso di un disegno di ricerca che isola l’effetto dell’allenamento, come un esperimento con assegnazione casuale.\n\n\n19.2.4 Come l’Estimando Teorico Chiarisce la Natura dello Studio\nDefinire l’estimando teorico in modo preciso aiuta a chiarire la natura dello studio perché specifica esattamente quale relazione tra le variabili viene studiata:\n\nStudi Descrittivi: L’estimando teorico è una semplice descrizione di dati, come una media o una differenza, senza inferire causalità.\nStudi Predittivi: L’estimando teorico si concentra sulla capacità di un modello di fare previsioni basate sui dati, senza implicazioni causali.\nStudi Causali: L’estimando teorico cerca di determinare l’effetto diretto di una variabile su un’altra, richiedendo un disegno di studio che possa controllare variabili confondenti per isolare la causalità.\n\nIn sintesi, l’estimando teorico orienta il ricercatore nel definire chiaramente se lo scopo dello studio è descrittivo, predittivo o causale, e guida il disegno dello studio e l’analisi dei dati di conseguenza.\n\n\n19.2.5 Importanza dei DAG nel Contesto degli Estimandi Teorici\nNella figura 2 dell’articolo di Lundberg et al. (2021), i Grafici Aciclici Diretti (DAG) vengono utilizzati per illustrare le relazioni causali tra variabili all’interno di uno studio. I DAG sono strumenti visivi che aiutano i ricercatori a rappresentare e comprendere le assunzioni causali sottostanti ai loro studi, fornendo una chiara rappresentazione grafica di come le variabili si influenzano a vicenda. Questo è particolarmente importante quando si definiscono estimandi teorici, perché i DAG consentono di identificare chiaramente le variabili confondenti e di stabilire le relazioni di causalità.\nI DAG possono contribuire alla definizione degli estimandi teorici in molti modi.\n\nChiarificazione delle Relazioni Causali: I DAG aiutano a chiarire quali variabili sono considerate come cause potenziali e quali come effetti. Questo è fondamentale per definire l’estimando teorico, soprattutto in uno studio causale, dove è importante distinguere tra correlazione e causalità. Ad esempio, se si studia l’effetto dell’allenamento cognitivo sull’intelligenza, un DAG può mostrare come l’allenamento influisce direttamente sull’intelligenza, identificando al contempo variabili confondenti come il background educativo o la motivazione.\nIdentificazione delle Variabili Confondenti: Uno dei principali vantaggi dell’utilizzo dei DAG è la loro capacità di identificare le variabili confondenti che possono influenzare entrambe le variabili di interesse. Nel contesto degli estimandi teorici, riconoscere e controllare queste variabili confondenti è cruciale per stabilire una relazione causale valida. Ad esempio, un DAG potrebbe rivelare che la motivazione personale influisce sia sulla partecipazione all’allenamento cognitivo che sui punteggi di intelligenza, indicando che questa variabile deve essere controllata per ottenere un estimando causale corretto.\nGuida nella Costruzione del Disegno di Ricerca: I DAG sono strumenti utili nella pianificazione del disegno di ricerca perché aiutano a determinare quali variabili devono essere misurate e controllate. Definendo chiaramente le relazioni tra le variabili, i ricercatori possono progettare esperimenti o studi osservazionali che minimizzano i bias e migliorano la validità interna dello studio. Ad esempio, un DAG può suggerire la necessità di randomizzare l’assegnazione all’allenamento cognitivo per garantire che l’effetto osservato sui punteggi di intelligenza sia realmente causato dall’allenamento e non da un’altra variabile.\nSupporto nella Selezione delle Strategie di Stima: Una volta definite le relazioni tra le variabili attraverso un DAG, i ricercatori possono scegliere strategie di stima appropriate per gli estimandi teorici ed empirici. Per esempio, se un DAG indica che non ci sono percorsi diretti tra alcune variabili, si possono utilizzare metodi statistici che presuppongono l’indipendenza condizionale, come la regressione lineare o i modelli di equazioni strutturali.\n\nIn sintesi, nel contesto della definizione degli estimandi teorici, i DAG sono strumenti essenziali che consentono ai ricercatori di visualizzare e comprendere le relazioni causali e le variabili confondenti all’interno di uno studio. Essi facilitano la costruzione di disegni di ricerca solidi, la selezione di strategie di stima appropriate e la comunicazione chiara delle assunzioni causali sottostanti. Utilizzando i DAG, i ricercatori possono garantire che gli estimandi teorici siano ben definiti e che le inferenze tratte dai dati siano valide e affidabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#collegamento-tra-estimando-teorico-ed-empirico",
    "href": "chapters/eda/10_estimand.html#collegamento-tra-estimando-teorico-ed-empirico",
    "title": "19  Estimandi teorici e estimandi empirici",
    "section": "19.3 Collegamento tra Estimando Teorico ed Empirico",
    "text": "19.3 Collegamento tra Estimando Teorico ed Empirico\nLundberg et al. (2021) sottolineano l’importanza di collegare chiaramente l’estimando teorico all’estimando empirico, utilizzando assunzioni sostanziali e metodi appropriati per garantire che le conclusioni tratte dai dati siano valide.\nEstimando Empirico: L’estimando empirico è la quantità che viene effettivamente calcolata dai dati osservati. Mentre l’estimando teorico rappresenta l’obiettivo concettuale dello studio (come l’effetto dell’allenamento cognitivo sull’intelligenza), l’estimando empirico è ciò che viene effettivamente misurato nel contesto dei dati disponibili.\nPer tradurre un estimando teorico in uno empirico, è essenziale formulare assunzioni che rendano possibile l’inferenza causale. Queste assunzioni possono essere formalizzate attraverso l’uso dei Grafici Aciclici Diretti (DAG) per garantire che le variabili confondenti siano adeguatamente controllate. L’identificazione corretta assicura che le conclusioni derivate dai dati osservati siano valide rispetto all’effetto causale che si sta cercando di stimare.\nConsideriamo uno studio psicologico sull’effetto dell’allenamento cognitivo sui punteggi di intelligenza:\n\nEstimando Teorico: Il nostro obiettivo teorico potrebbe essere stimare l’effetto causale dell’allenamento cognitivo sull’aumento del punteggio di intelligenza in una popolazione adulta. L’estimando teorico qui sarebbe la differenza media nei punteggi di intelligenza tra gli individui che hanno partecipato all’allenamento e quelli che non lo hanno fatto, supponendo che l’unica differenza tra i gruppi sia l’allenamento stesso.\nEstimando Empirico: Per passare all’estimando empirico, dobbiamo considerare cosa possiamo effettivamente misurare. Supponiamo di avere dati da un campione di adulti, alcuni dei quali hanno partecipato all’allenamento cognitivo e altri no. L’estimando empirico potrebbe essere la differenza osservata nei punteggi di intelligenza tra questi due gruppi nel campione disponibile.\nAssunzioni per l’Identificazione:\n\nAssunzione di Nessuna Confusione (No Confounding): Dobbiamo assumere che non vi siano variabili non misurate che influenzano sia la partecipazione all’allenamento che i punteggi di intelligenza. Per esempio, la motivazione personale potrebbe influenzare sia la decisione di partecipare all’allenamento che il punteggio di intelligenza. Se questa variabile non è controllata, l’estimando empirico potrebbe sovrastimare o sottostimare l’effetto dell’allenamento.\nAssunzione di Non-Interferenza (Stable Unit Treatment Value Assumption, SUTVA): Dobbiamo assumere che la partecipazione di un individuo all’allenamento non influisca sui punteggi di intelligenza di altri individui. Questa assunzione potrebbe essere violata, ad esempio, se i partecipanti condividono tecniche apprese con amici che non hanno partecipato.\n\nUtilizzo dei DAG per la Chiarificazione:\n\nUn DAG può aiutare a visualizzare queste assunzioni mostrando le relazioni tra le variabili. In un DAG ben costruito, l’allenamento cognitivo influenzerebbe direttamente il punteggio di intelligenza, mentre altre variabili come l’educazione o la motivazione sarebbero rappresentate come confondenti da controllare. Se il DAG indica che ci sono variabili confondenti che non possiamo osservare o misurare, dovremo usare metodi statistici specifici, come i modelli di equazioni strutturali o l’uso di variabili strumentali, per isolare l’effetto dell’allenamento cognitivo.\n\n\nIn sintesi, collegare correttamente l’estimando teorico a uno empirico è un passo cruciale per garantire la validità delle inferenze causali in uno studio. Utilizzando l’esempio relativo all’effetto dell’allenamento cognitivo sull’intelligenza, possiamo vedere come le assunzioni sostanziali e gli strumenti come i DAG siano essenziali per identificare correttamente le relazioni causali e assicurare che i risultati siano interpretabili in modo affidabile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#dedurre-lestimando-empirico-dai-dati-osservati",
    "href": "chapters/eda/10_estimand.html#dedurre-lestimando-empirico-dai-dati-osservati",
    "title": "19  Estimandi teorici e estimandi empirici",
    "section": "19.4 Dedurre l’Estimando Empirico dai Dati Osservati",
    "text": "19.4 Dedurre l’Estimando Empirico dai Dati Osservati\nDopo aver chiaramente definito l’estimando teorico e stabilito il collegamento con l’estimando empirico attraverso l’identificazione, il passo successivo è utilizzare tecniche statistiche per ottenere stime valide dai dati raccolti.\nRiprendiamo l’esempio psicologico sull’effetto dell’allenamento cognitivo sui punteggi di intelligenza per illustrare come l’approccio bayesiano può essere utilizzato per stimare l’estimando empirico:\n\nDefinizione dell’Estimando Empirico:\n\nL’estimando empirico in questo contesto è la differenza media nei punteggi di intelligenza tra il gruppo di individui che ha partecipato all’allenamento cognitivo e il gruppo che non ha partecipato.\n\nStrategie di Stima Appropriate:\n\nRegressione Lineare: Se ipotizziamo che i punteggi di intelligenza dipendano linearmente dalla partecipazione all’allenamento cognitivo e da altre variabili confondenti controllate, potremmo utilizzare una regressione lineare per stimare l’effetto dell’allenamento. In questa regressione, la partecipazione all’allenamento sarebbe una variabile indipendente, e i punteggi di intelligenza la variabile dipendente.\nMatching: Se i dati disponibili includono molte variabili confondenti misurate, potremmo utilizzare una tecnica di matching per creare coppie di individui simili (matchati) tra i gruppi di trattamento e controllo, basati su queste variabili. Questo metodo aiuta a bilanciare le differenze tra i gruppi che potrebbero influenzare i risultati, cercando di rendere le stime dell’effetto più affidabili.\nPropensity Score Matching: Invece di confrontare direttamente individui basandosi su caratteristiche osservabili, possiamo calcolare un punteggio di propensione per ciascun individuo, che rappresenta la probabilità di partecipare all’allenamento in base alle covariate osservate. Gli individui con punteggi di propensione simili vengono quindi confrontati, aiutando a controllare per le variabili confondenti.\nModelli di Equazioni Strutturali (SEM): Se ci sono molteplici relazioni tra variabili latenti e osservate, un modello di equazioni strutturali può essere utilizzato per stimare simultaneamente questi effetti complessi e isolare l’effetto diretto dell’allenamento cognitivo sui punteggi di intelligenza.\nRandomizzazione: In un disegno sperimentale ideale, l’assegnazione casuale dell’allenamento cognitivo elimina l’influenza delle variabili confondenti, permettendo una stima non distorta dell’effetto causale. Se i dati derivano da un esperimento randomizzato, potremmo semplicemente confrontare le medie dei due gruppi.\n\nInterpreting the Results:\n\nStime Non Distorte: Utilizzando la strategia di stima appropriata, possiamo ottenere una stima non distorta dell’effetto dell’allenamento cognitivo sui punteggi di intelligenza. Ad esempio, se utilizziamo una regressione lineare e controlliamo correttamente per tutte le variabili confondenti, l’effetto stimato rappresenterà l’effetto causale dell’allenamento.\n\n\nLa fase di stima è cruciale per trasformare i dati osservati in stime valide dell’estimando empirico. Nel contesto psicologico dell’allenamento cognitivo e dell’intelligenza, la scelta della strategia di stima appropriata dipende dalle assunzioni fatte sulla causalità e dalla natura dei dati disponibili. Utilizzando tecniche come la regressione, il matching, o i modelli di equazioni strutturali, i ricercatori possono ottenere stime precise e affidabili, garantendo che le conclusioni tratte siano valide e scientificamente robuste.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#implicazioni-per-la-ricerca",
    "href": "chapters/eda/10_estimand.html#implicazioni-per-la-ricerca",
    "title": "19  Estimandi teorici e estimandi empirici",
    "section": "19.5 Implicazioni per la Ricerca",
    "text": "19.5 Implicazioni per la Ricerca\nLundberg et al. (2021) sottolineano l’importanza di una chiara comunicazione e dell’uso del framework presentato per migliorare la pratica della ricerca quantitativa.\n\n19.5.1 Importanza della Trasparenza e della Chiarezza nella Ricerca\nGli autori sottolineano che per garantire la validità e la replicabilità dei risultati di ricerca, è fondamentale che i ricercatori siano trasparenti e chiari su tutte le fasi del loro lavoro. Questo significa esplicitare le assunzioni fatte, il modo in cui l’estimando teorico è stato tradotto in un estimando empirico, e come i dati sono stati analizzati.\nPer esempio, in uno studio sull’effetto di una terapia cognitivo-comportamentale (CBT) sui livelli di ansia, è essenziale che i ricercatori definiscano chiaramente l’estimando teorico, ad esempio, “l’effetto medio della CBT sulla riduzione dell’ansia nella popolazione target di adulti con disturbo d’ansia generalizzato”. Devono poi descrivere come questo estimando è stato misurato empiricamente, ad esempio, utilizzando questionari standardizzati per l’ansia prima e dopo l’intervento. Infine, devono spiegare le assunzioni fatte e le tecniche utilizzate per l’analisi dei dati, come un modello bayesiano per gestire la variabilità individuale nella risposta alla terapia.\n\n\n19.5.2 Benefici dell’Utilizzo di Estimandi Chiaramente Definiti\nL’articolo discute come l’uso di estimandi chiaramente definiti può migliorare la comprensione dei risultati e facilitare il confronto tra studi diversi. Quando i ricercatori definiscono in modo preciso ciò che stanno stimando, diventa più facile per altri replicare lo studio, confrontare risultati e costruire un corpus di conoscenza cumulativo.\nPer esempio, consideriamo due studi sull’efficacia di diversi tipi di training di memoria per migliorare le funzioni cognitive negli anziani. Se entrambi gli studi definiscono chiaramente il loro estimando teorico (ad esempio, “l’effetto del training di memoria verbale sul punteggio del test di memoria a lungo termine”) e empirico (ad esempio, “la differenza media nei punteggi del test di memoria tra il gruppo che ha ricevuto il training e un gruppo di controllo”), sarà più semplice confrontare i risultati e capire quale tipo di training è più efficace.\n\n\n19.5.3 Adattabilità e Flessibilità del Framework\nIl framework proposto dagli autori è adattabile a diversi contesti di ricerca, permettendo ai ricercatori di applicare questi principi in una varietà di studi quantitativi, indipendentemente dal dominio specifico.\nPer esempio, in uno studio che esplora l’effetto della privazione del sonno sulla capacità di attenzione nei bambini, il framework potrebbe essere utilizzato per definire l’estimando teorico come “l’effetto della privazione di 8 ore di sonno sulla capacità di mantenere l’attenzione in attività ripetitive”, e l’estimando empirico potrebbe essere “la differenza media nei punteggi di attenzione tra bambini che hanno dormito 8 ore e quelli che non hanno dormito”. Questo approccio garantisce che le conclusioni siano fondate su basi metodologiche solide e che altri ricercatori possano replicare lo studio per verificare i risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#conclusioni-e-implicazioni-per-la-ricerca-futura",
    "href": "chapters/eda/10_estimand.html#conclusioni-e-implicazioni-per-la-ricerca-futura",
    "title": "19  Estimandi teorici e estimandi empirici",
    "section": "19.6 Conclusioni e Implicazioni per la Ricerca Futura",
    "text": "19.6 Conclusioni e Implicazioni per la Ricerca Futura\nL’adozione del framework proposto da Lundberg et al. (2021) per la definizione degli estimandi teorici ed empirici, la chiara identificazione delle assunzioni e l’utilizzo di metodi di stima appropriati può migliorare la qualità e l’affidabilità della ricerca quantitativa nelle scienze sociali. Questo approccio promuove una pratica di ricerca più rigorosa e trasparente.\nSe la comunità psicologica integrasse questo framework, studi sugli interventi psicologici, come quelli sulla terapia cognitivo-comportamentale (CBT) discusso nell’esempio sopra, potrebbero diventare più comparabili e replicabili. Ciò migliorerebbe la nostra comprensione dell’efficacia e dei limiti di tali interventi. Ad esempio, definendo chiaramente cosa si intende per “efficacia” della CBT (come la riduzione del punteggio su una scala di ansia standardizzata) e utilizzando metodi bayesiani per incorporare dati preesistenti e nuove osservazioni, è possibile ottenere stime più robuste e interpretabili. Queste stime rifletterebbero meglio l’efficacia reale della terapia nella pratica clinica.\nLe proposte di Lundberg et al. (2021) sono in linea con le raccomandazioni di altri studiosi. Andrew Gelman, ad esempio, sottolinea spesso l’importanza di definire con precisione cosa si sta cercando di stimare in un’analisi statistica. Gelman sostiene che una definizione vaga o mal definita dell’estimando teorico può portare a interpretazioni errate e conclusioni fuorvianti. La chiara definizione dell’estimando teorico, come evidenziato nell’articolo di Lundberg et al., è cruciale per determinare se uno studio è descrittivo, predittivo o causale, e per comprendere la natura dell’inferenza da trarre dai dati (Gelman & Imbens, 2013).\nSia McElreath (2020), nel suo testo “Statistical Rethinking,” sia Andrew Gelman, enfatizzano l’importanza dell’utilizzo dei Grafici Aciclici Diretti (DAG) per rappresentare visivamente le assunzioni causali e le relazioni tra variabili in un modello statistico. Questo tipo di approccio aiuta i ricercatori a identificare variabili confondenti e a chiarire le relazioni causali, migliorando così la validità delle inferenze.\nGelman discute anche frequentemente l’importanza della trasparenza nella comunicazione dei risultati di ricerca, un principio centrale anche nell’articolo di Lundberg et al. Egli insiste sul fatto che i ricercatori dovrebbero essere espliciti riguardo alle assunzioni fatte, ai metodi utilizzati e alle limitazioni dei loro studi (Gelman et al., 1995).\nIn sintesi, sia Lundberg et al. che altri ricercatori evidenziano l’importanza di una chiara definizione degli estimandi, dell’uso dei DAG per rappresentare le assunzioni causali e della scelta di strategie di stima appropriate. L’approccio bayesiano, in particolare, offre un metodo potente e flessibile per gestire l’incertezza e aggiornare le inferenze alla luce di nuove evidenze. Adottando queste pratiche, i ricercatori nelle scienze sociali e nella psicologia possono migliorare la validità, la replicabilità e la trasparenza delle loro ricerche, contribuendo a una conoscenza scientifica più solida e affidabile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#riflessioni-conclusive",
    "href": "chapters/eda/10_estimand.html#riflessioni-conclusive",
    "title": "19  Estimandi teorici e estimandi empirici",
    "section": "19.7 Riflessioni Conclusive",
    "text": "19.7 Riflessioni Conclusive\nIn questo capitolo abbiamo esaminato l’importanza della definizione dell’estimando in uno studio quantitativo, come evidenziato nell’articolo di Lundberg et al. (2021). Il concetto centrale è la distinzione tra estimando teorico ed estimando empirico e il loro collegamento, che facilita l’interpretazione dei risultati e rende l’inferenza statistica più rigorosa.\nL’articolo propone un framework strutturato in tre fasi principali:\n\nDefinire un estimando teorico collegato alla teoria sottostante.\nTradurre questo estimando in un estimando empirico, basato su dati osservabili e assunzioni di identificazione.\nScegliere le strategie di stima adeguate per ottenere stime affidabili.\n\nL’adozione di questo approccio consente di migliorare la chiarezza e la trasparenza nella ricerca, rendendo più facili il confronto tra studi diversi e la replicabilità dei risultati. La corretta definizione dell’estimando guida l’intero processo di ricerca, dalla progettazione dello studio alla scelta delle tecniche di stima e all’interpretazione dei risultati, garantendo che la teoria e le evidenze empiriche siano strettamente collegate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#bibliografia",
    "href": "chapters/eda/10_estimand.html#bibliografia",
    "title": "19  Estimandi teorici e estimandi empirici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGelman, A., & Imbens, G. (2013). Why ask why? Forward causal inference and reverse causal questions. National Bureau of Economic Research.\n\n\nLundberg, I., Johnson, R., & Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532–565.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_pixi.html",
    "href": "chapters/eda/11_pixi.html",
    "title": "20  Flusso di lavoro riproducibile",
    "section": "",
    "text": "20.1 Introduzione\nPrerequisiti\nPrima di iniziare, assicurati di avere:\nConcetti e competenze chiave\nPreparazione del Notebook\nIn questo capitolo esploreremo gli strumenti essenziali per garantire che il flusso di lavoro di un progetto di analisi dei dati in R sia pienamente riproducibile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_pixi.html#analisi-e-flussi-di-lavoro-riproducibili",
    "href": "chapters/eda/11_pixi.html#analisi-e-flussi-di-lavoro-riproducibili",
    "title": "20  Flusso di lavoro riproducibile",
    "section": "20.2 Analisi e flussi di lavoro riproducibili",
    "text": "20.2 Analisi e flussi di lavoro riproducibili\nLa possibilità di confermare ripetutamente i risultati scientifici attraverso la replica è un principio fondamentale della scienza. Questo concetto si basa sull’idea che una verità scientifica debba resistere a ulteriori indagini da parte di altri osservatori. In ambito scientifico, è utile distinguere due aspetti legati alla replica: replicabilità e riproducibilità.\n\nReplicabilità: si riferisce alla capacità di ottenere risultati simili con dati diversi, ma seguendo lo stesso protocollo sperimentale.\nRiproducibilità: indica la capacità di ottenere gli stessi risultati utilizzando gli stessi dati e lo stesso metodo di analisi, sia dalla stessa persona che da altri.\n\n\n20.2.1 Riproducibilità dei dati: una sfida spesso sottovalutata\nLa replicazione di esperimenti fisici può presentare difficoltà pratiche significative. Tuttavia, anche riprodurre semplicemente un’analisi dei dati, che sembra un compito più semplice, è spesso problematico per molteplici ragioni. Tradizionalmente, i ricercatori annotavano scrupolosamente i dettagli sperimentali nei loro taccuini di laboratorio, consentendo di replicare l’esperimento. Oggi, strumenti software moderni permettono di applicare lo stesso principio alla riproduzione dei dati: tutto il necessario per rifare l’analisi deve essere documentato in modo chiaro e centralizzato.\nQuesti strumenti non solo facilitano la ripetizione dell’analisi, ma permettono anche di migliorarla e applicarla facilmente a nuovi dati. Tuttavia, per essere riproducibile, l’analisi deve essere scritta in modo appropriato, utilizzando ambienti di programmazione statistica come R o Python, che permettono l’automazione del processo. Al contrario, software come i fogli di calcolo non sono adatti a garantire riproducibilità, perché legano i comandi a celle specifiche, rendendo l’adattamento a nuovi dati complesso e soggetto a errori.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_pixi.html#la-crisi-della-replicazione-e-la-riproducibilità",
    "href": "chapters/eda/11_pixi.html#la-crisi-della-replicazione-e-la-riproducibilità",
    "title": "20  Flusso di lavoro riproducibile",
    "section": "20.3 La crisi della replicazione e la riproducibilità",
    "text": "20.3 La crisi della replicazione e la riproducibilità\nLa crisi della replicazione evidenzia un problema crescente nella scienza moderna: molti studi pubblicati, anche sottoposti a peer review, non sono replicabili. Studi come quello di Ioannidis (2005) e Baker (2016) denunciano che molte ricerche sperimentali e statistiche non resistono alla verifica di altri ricercatori. Questo significa che, nonostante l’apparente validità dei risultati, spesso non è possibile raggiungere le stesse conclusioni ripetendo lo studio.\nTra le cause di questa crisi figurano problematiche complesse come la molteplicità e i percorsi analitici alternativi (il cosiddetto garden of forking paths). Tuttavia, indipendentemente da queste difficoltà, un’analisi riproducibile è un requisito minimo per garantire la validità dei risultati.\n\n\n\n\n\n\nNota\n\n\n\nUn problema che compromette la solidità delle conclusioni di molti studi è stato definito da Andrew Gelman, della Columbia University, come il garden of forking paths (giardino dei sentieri che si biforcano). La maggior parte delle analisi richiede una serie di decisioni su come codificare i dati, identificare i fattori rilevanti e formulare (e successivamente rivedere) i modelli prima di arrivare alle analisi finali. Questo processo implica spesso l’esame dei dati per costruire una rappresentazione parsimoniosa. Ad esempio, un predittore continuo potrebbe essere suddiviso arbitrariamente in gruppi per valutare la relazione con l’esito, oppure alcune variabili potrebbero essere incluse o escluse da un modello di regressione durante una fase esplorativa.\nQuesto approccio tende a favorire risultati dei test di ipotesi che sono distorti verso il rigetto dell’ipotesi nulla, poiché le decisioni prese durante il processo possono privilegiare segnali più forti (o p-value più piccoli) rispetto ad altre alternative. Nella maggior parte dei problemi di data science, questo rappresenta una sfida importante che solleva dubbi sulla riproducibilità dei risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_pixi.html#elementi-chiave-per-un-workflow-riproducibile",
    "href": "chapters/eda/11_pixi.html#elementi-chiave-per-un-workflow-riproducibile",
    "title": "20  Flusso di lavoro riproducibile",
    "section": "20.4 Elementi chiave per un workflow riproducibile",
    "text": "20.4 Elementi chiave per un workflow riproducibile\nUn flusso di lavoro riproducibile si compone di tre elementi fondamentali:\n\nAmbienti di programmazione statistica scriptabili: software come R o Python consentono di automatizzare le analisi e ridurre gli errori manuali.\nAnalisi riproducibili: basate sull’approccio della literate programming, dove codice e documentazione sono integrati per garantire trasparenza e comprensione.\nControllo di versione: sistemi come Git e piattaforme come GitHub permettono di monitorare e documentare i cambiamenti, favorendo la collaborazione e la tracciabilità.\n\nIntegrare questi componenti nella pratica quotidiana non solo migliora la qualità delle analisi, ma contribuisce a rafforzare la fiducia nella scienza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_pixi.html#gestione-del-workflow",
    "href": "chapters/eda/11_pixi.html#gestione-del-workflow",
    "title": "20  Flusso di lavoro riproducibile",
    "section": "20.5 Gestione del Workflow",
    "text": "20.5 Gestione del Workflow\nAnche se l’uso di R per scrivere script che documentano le analisi dei dati rappresenta un importante passo verso la riproducibilità, questo non garantisce che il progetto possa essere riprodotto con successo da altri ricercatori. Ad esempio, Obels et al. (2020) hanno esaminato la condivisione di dati e codice per gli articoli pubblicati come Registered Reports nella letteratura psicologica tra il 2014 e il 2018, tentando di riprodurre indipendentemente i risultati principali. Riportano:\n\n“Abbiamo esaminato dati e script condivisi per i Registered Reports pubblicati nella letteratura psicologica dal 2014 al 2018 e tentato di riprodurre computazionalmente i risultati principali di ciascun articolo. Dei 62 articoli che soddisfacevano i nostri criteri di inclusione, 41 mettevano a disposizione i dati e 37 gli script di analisi. Dati e codice erano condivisi per 36 articoli. Siamo riusciti a eseguire gli script per 31 analisi e a riprodurre i risultati principali di 21 articoli. Sebbene la percentuale di articoli con dati e codice condivisi (36 su 62, ovvero il 58%) e quella degli articoli per cui i risultati principali potevano essere riprodotti computazionalmente (21 su 36, ovvero il 58%) siano relativamente alte rispetto a quelle riscontrate in altri studi, c’è un evidente margine di miglioramento.”\n\nQuesti risultati evidenziano che, anche quando dati e codice sono disponibili, la riproducibilità non è garantita. Gli script possono essere incompleti, o l’ambiente di sviluppo originariamente utilizzato dagli autori può non essere replicabile da altri ricercatori.\n\n20.5.1 Strumenti per la Gestione del Workflow\nPer affrontare queste problematiche, sono stati sviluppati numerosi strumenti di gestione del workflow. Tra i più noti ricordiamo:\n\nMake: uno strumento storico progettato per sistemi Unix, altamente portabile e preinstallato su tutti i sistemi Unix e derivati.\nSnakemake: molto popolare in biologia, offre grande flessibilità per gestire flussi di lavoro complessi.\ntargets: uno strumento specificamente progettato per R, che semplifica la gestione dei workflow riproducibili nei progetti di analisi dati.\n\n\n\n20.5.2 Limiti degli Strumenti di Workflow Management\nNonostante i vantaggi, l’adozione di questi strumenti comporta un certo aggravio per il ricercatore. Oltre a dover scrivere gli script per l’analisi dei dati, è necessario creare ulteriori script che definiscano il workflow e garantiscano la riproducibilità. Questo può richiedere una riorganizzazione significativa del modo in cui gli script sono strutturati, rendendo talvolta più complesso il debug e le successive modifiche. Per questi motivi, l’uso di strumenti di workflow management può risultare impegnativo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_pixi.html#un-workflow-manager-semplice-e-innovativo",
    "href": "chapters/eda/11_pixi.html#un-workflow-manager-semplice-e-innovativo",
    "title": "20  Flusso di lavoro riproducibile",
    "section": "20.6 Un Workflow Manager Semplice e Innovativo",
    "text": "20.6 Un Workflow Manager Semplice e Innovativo\nIn questo capitolo verrà introdotto Pixi, un workflow manager di ultima generazione progettato per semplificare la gestione dei flussi di lavoro nei progetti di analisi dati. Pixi si distingue per la sua intuitività e per la capacità di affrontare molte delle difficoltà tipiche legate alla riproducibilità e all’organizzazione di progetti complessi. Questo strumento è particolarmente adatto a ricercatori e data scientist che desiderano automatizzare e strutturare efficacemente il proprio lavoro senza aggiungere complessità inutili.\nPixi è un gestore di pacchetti veloce e versatile, basato sull’ecosistema Conda, che semplifica la creazione di ambienti di sviluppo su diverse piattaforme, tra cui Windows, macOS e Linux. Supporta una vasta gamma di linguaggi di programmazione, tra cui Python, R, C/C++, Rust e Ruby, rendendolo uno strumento estremamente flessibile. Inoltre, Pixi consente di creare ambienti riproducibili senza dover ricorrere a strumenti più complessi come Docker, riducendo così il tempo e lo sforzo necessari per configurare il progetto.\nCon una configurazione iniziale ben strutturata, Pixi permette di concentrarsi sull’analisi dei dati e sulla generazione di risultati, garantendo al tempo stesso la piena riproducibilità del workflow.\n\n20.6.1 Installazione di Pixi\nPer utilizzare Pixi, è necessario avere installati R, RStudio e Pixi stesso. L’installazione di Pixi è semplice seguendo le indicazioni ufficiali. Per installare Pixi, è sufficiente eseguire il seguente comando nel terminale:\ncurl -fsSL https://pixi.sh/install.sh | bash\n\n\n20.6.2 Struttura del Progetto\nImmaginiamo che il progetto segua questa struttura organizzativa:\ndata-analysis-project/\n│\n├── pixi.toml               # File di configurazione Pixi\n├── pixi.lock               # Lockfile per le dipendenze\n│\n├── data/                   # Directory per i dati\n│   ├── raw/                # Dati grezzi\n│   └── processed/          # Dati processati\n│\n├── src/                    # Codice sorgente in R\n│   ├── data_cleaning.R     # Script per pulizia dei dati\n│   ├── analysis.R          # Script per analisi\n│   └── visualization.R     # Script per visualizzazioni\n│\n├── reports/                # Report e output\n│   ├── figures/            # Figure generate\n│   └── report.Rmd          # Report in R Markdown\n│\n└── README.md               # Documentazione del progetto\n\n\n\n20.6.3 Configurazione di Pixi\nPer configurare Pixi, si crea un file pixi.toml nella directory principale del progetto:\n[project]\nname = \"r-data-analysis\"\ndescription = \"Progetto di analisi dati con R\"\nauthors = [\"Tuo Nome &lt;tua.email@example.com&gt;\"]\nchannels = [\"conda-forge\"]\nplatforms = [\"osx-64\", \"linux-64\",\"win-64\"]\n\n[dependencies]\nr-base = \"&gt;=4.3,&lt;5\"\nr-tidyverse = \"*\"\nr-rio= \"*\"\nr-knitr = \"*\"\nr-rmarkdown = \"*\"\nr-here = \"*\"\n\n[tasks]\nclean = \"rm -rf reports/figures/* data/processed/*\"\ndata-prep = \"Rscript src/data_cleaning.R\"\nanalysis = \"Rscript src/analysis.R\"\nreport = \"Rscript -e 'rmarkdown::render(\\\"reports/report.Rmd\\\")'\"\nall = { depends-on = [\"clean\", \"data-prep\", \"analysis\", \"report\"] }\n\n\n20.6.4 Script di Pulizia Dati (src/data_cleaning.R)\nUno script per pulire e organizzare i dati grezzi:\nlibrary(readr)\nlibrary(dplyr)\n\n# Caricamento dati grezzi\nraw_data &lt;- read_csv(\"data/raw/dati_esempio.csv\")\n\n# Pulizia e trasformazione dei dati\ncleaned_data &lt;- raw_data %&gt;%\n  filter(!is.na(valore)) %&gt;%\n  mutate(categoria = factor(categoria)) %&gt;%\n  group_by(categoria) %&gt;%\n  summarise(media = mean(valore, na.rm = TRUE))\n\n# Salvataggio dei dati processati\nwrite_csv(cleaned_data, \"data/processed/dati_puliti.csv\")\n\n\n20.6.5 Script di Analisi (src/analysis.R)\nUno script per eseguire analisi statistiche e creare visualizzazioni:\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Caricamento dei dati processati\ndati &lt;- read_csv(\"data/processed/dati_puliti.csv\")\n\n# Analisi statistica\nrisultati_analisi &lt;- dati %&gt;%\n  group_by(categoria) %&gt;%\n  summarise(\n    media = mean(media),\n    deviazione_standard = sd(media)\n  )\n\n# Salvataggio dei risultati\nwrite_csv(risultati_analisi, \"reports/risultati_analisi.csv\")\n\n# Creazione di un grafico\ngrafico &lt;- ggplot(dati, aes(x = categoria, y = media)) +\n  geom_bar(stat = \"identity\") +\n  ggtitle(\"Media per Categoria\")\n\n# Salvataggio del grafico\nggsave(\"reports/figures/media_categoria.png\", plot = grafico)\n\n\n20.6.6 Creazione di un Report (reports/report.Rmd)\nUn report generato con R Markdown per presentare i risultati dell’analisi:\n---\ntitle: \"Report di Analisi dei Dati\"\noutput: html_document\n---\n\n## Risultati dell'Analisi\n\n```\nlibrary(readr)\nlibrary(knitr)\nrisultati &lt;- read_csv(\"reports/risultati_analisi.csv\")\nkable(risultati)\n```\n\n## Grafico delle Medie per Categoria\n\n![Media per Categoria](figures/media_categoria.png)\n\n\n20.6.7 Esecuzione del Workflow con Pixi\nUna volta installato Pixi, puoi inizializzare un nuovo progetto con:\n# Inizializzazione del progetto\npixi init\nPer installare le dipendenze specificate in in pixi.toml, esegui:\n# Installazione delle dipendenze specificate in pixi.toml\npixi install\nQuesto comando crea un file pixi.lock che elenca tutte le dipendenze del progetto, garantendo che l’ambiente possa essere ricreato in modo identico su diverse macchine.\nPer eseguire le attività definite, utilizza:\npixi run data-prep\npixi run analysis\npixi run report\nOppure, per eseguire tutte le attività in sequenza:\npixi run all\nIl codice utilizzato in questo tutorial è disponibile nel repository GitHub dedicato.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_pixi.html#riflessioni-conclusive",
    "href": "chapters/eda/11_pixi.html#riflessioni-conclusive",
    "title": "20  Flusso di lavoro riproducibile",
    "section": "20.7 Riflessioni Conclusive",
    "text": "20.7 Riflessioni Conclusive\nPixi semplifica la gestione dei progetti di analisi dati in R, automatizzando il workflow e garantendo riproducibilità e coerenza. Non è necessario modificare gli script esistenti; possono essere utilizzati direttamente da Pixi. Con una configurazione iniziale ben strutturata, consente di concentrarsi sull’analisi dei dati e sulla generazione di risultati, minimizzando gli errori e massimizzando l’efficienza del processo. Pixi elenca automaticamente tutte le dipendenze utilizzate nel progetto nel file pixi.lock, assicurando che l’ambiente sia pienamente riproducibile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_pixi.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/11_pixi.html#informazioni-sullambiente-di-sviluppo",
    "title": "20  Flusso di lavoro riproducibile",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.0       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1 \n#&gt; [37] cli_3.6.3         magrittr_2.0.3    utf8_1.2.4        broom_1.0.7      \n#&gt; [41] withr_3.0.2       backports_1.5.0   promises_1.3.1    timechange_0.3.0 \n#&gt; [45] rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3         shiny_1.9.1      \n#&gt; [49] evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [53] xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_pixi.html#bibliografia",
    "href": "chapters/eda/11_pixi.html#bibliografia",
    "title": "20  Flusso di lavoro riproducibile",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A. (2020). Analysis of open data and computational reproducibility in registered reports in psychology. Advances in Methods and Practices in Psychological Science, 3(2), 229–237.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/probability/introduction_probability.html",
    "href": "chapters/probability/introduction_probability.html",
    "title": "Introduzione",
    "section": "",
    "text": "Questa sezione della dispensa introduce la teoria della probabilità, una componente essenziale per la ricerca scientifica. Nell’ambito della scienza, l’inferenza induttiva è di fondamentale importanza, e la probabilità svolge un ruolo cruciale in questo processo. Sebbene non possiamo ottenere una certezza assoluta riguardo alla veridicità di un’ipotesi o teoria, possiamo assegnare loro un grado di certezza probabilistica. L’approccio bayesiano utilizza la probabilità per quantificare il grado di fiducia che possiamo attribuire a una determinata proposizione.\nL’inferenza statistica bayesiana mira a quantificare la fiducia nell’ipotesi \\(H\\) dopo aver osservato un dato di evidenza \\(O\\). Per affrontare adeguatamente l’inferenza statistica bayesiana, è quindi essenziale avere una solida comprensione della teoria delle probabilità, almeno nei suoi concetti fondamentali.\nIn questa sezione esamineremo le definizioni di probabilità, la probabilità condizionale e il teorema di Bayes. Approfondiremo inoltre le proprietà delle variabili casuali e le principali distribuzioni di massa e densità di probabilità. Concluderemo presentando la funzione di verosimiglianza, un concetto fondamentale sia nell’inferenza bayesiana sia nell’inferenza frequentista.",
    "crumbs": [
      "Probabilità",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html",
    "href": "chapters/probability/01_intro_prob.html",
    "title": "21  Interpretazione della probabilità",
    "section": "",
    "text": "21.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNel corso di questo capitolo, esploreremo varie concezioni della probabilità, tra cui la visione classica, frequentista e bayesiana. Inoltre, introdurremo la simulazione con Python per una migliore comprensione della legge dei grandi numeri, un concetto fondamentale nell’ambito della probabilità. Iniziamo introducendo il concetto di causalità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#introduzione",
    "href": "chapters/probability/01_intro_prob.html#introduzione",
    "title": "21  Interpretazione della probabilità",
    "section": "",
    "text": "“La probabilità è il concetto più importante nella scienza moderna, soprattutto considerando che nessuno ha la minima idea di cosa significhi davvero.” (Attribuito a Bertrand Russell, 1929)\n\n\n\n21.1.1 Il Concetto di Casualità e la Teoria della Probabilità\nLa casualità emerge ogni volta che ci troviamo in una situazione caratterizzata da incertezza, in cui non possiamo prevedere con certezza l’esito di un evento. Questo concetto è fondamentale in molteplici contesti, dai giochi d’azzardo alla ricerca scientifica, e rappresenta un modello che ci aiuta a gestire l’imprevedibilità intrinseca in molti fenomeni. La casualità è il nostro modo di comprendere ciò che è incerto, permettendoci di trattare e quantificare eventi che, pur non potendo essere previsti singolarmente, seguono comunque schemi riconoscibili.\n\n\n21.1.2 L’Urna come Modello di Casualità\nUn modo semplice ma efficace per rappresentare la casualità è il classico modello dell’urna. Immaginiamo un’urna contenente numerose palline identiche, ciascuna numerata consecutivamente. Supponiamo che ogni pallina abbia la stessa probabilità di essere estratta. Definiremo quindi l’estrazione come “casuale”, perché ogni pallina ha uguali possibilità di essere selezionata. In questo contesto, non possiamo anticipare quale pallina verrà estratta, ma sappiamo che ognuna ha la stessa probabilità di esserlo.\nQuesto modello apparentemente semplice, basato sull’equivalenza delle probabilità, rappresenta in realtà l’essenza della casualità. Ci consente di estendere questo concetto per spiegare situazioni molto più complesse, dove possiamo applicare il principio della casualità a fenomeni ben oltre l’estrazione di palline, come il comportamento umano o i risultati di un esperimento scientifico.\n\n\n21.1.3 Applicazioni del Concetto di Casualità\nLa casualità trova applicazione in diversi ambiti, e il modello dell’urna offre una base di comprensione per i seguenti contesti:\n\nGiochi d’azzardo: Per garantire un ambiente “equo” per i giocatori, si cerca di fare in modo che ogni numero o risultato abbia la stessa probabilità di verificarsi. La casualità è qui fondamentale per assicurare che nessun risultato sia predeterminato.\nIndagini statistiche: Nei sondaggi o nelle ricerche demografiche, il campionamento casuale consente di ottenere un campione rappresentativo di una popolazione più ampia, riducendo il rischio di bias di selezione e offrendo inferenze generalizzabili.\nSperimentazione scientifica: La randomizzazione è utilizzata per distribuire casualmente i partecipanti tra i diversi gruppi sperimentali, permettendo così di controllare variabili confondenti e assicurare che le differenze osservate siano imputabili all’intervento e non ad altri fattori.\nCrittografia: Molti sistemi di sicurezza informatica si basano sulla generazione di numeri casuali per creare chiavi crittografiche robuste, che risultino difficili da prevedere e quindi da decifrare.\nSimulazioni: In vari campi scientifici, come la fisica o la psicologia, i modelli basati sulla casualità permettono di simulare sistemi complessi e di fare previsioni sugli esiti possibili.\n\n\n\n21.1.4 Dalla Casualità alla Teoria della Probabilità\nIl concetto di casualità rappresenta il fondamento della teoria della probabilità, che fornisce gli strumenti matematici per quantificare e analizzare rigorosamente l’incertezza. La teoria della probabilità, infatti, consente di trasformare la nostra intuizione della casualità in un modello matematico, attraverso il quale possiamo fare previsioni, calcolare rischi e prendere decisioni in condizioni di incertezza.\nIn particolare, la teoria della probabilità ci permette di:\n\nQuantificare l’incertezza: Assegnando un valore numerico a ciascun esito possibile, possiamo esprimere in modo preciso quanto riteniamo probabile ciascun risultato.\nCombinare informazioni: Attraverso regole matematiche come la somma e il prodotto delle probabilità, possiamo calcolare la probabilità di eventi complessi derivati da eventi più semplici.\nAggiornare le credenze: Quando emergono nuove informazioni, la teoria della probabilità (soprattutto in ambito bayesiano) ci fornisce metodi per aggiornare le nostre stime di probabilità in modo coerente e razionale.\nPrendere decisioni informate: La probabilità ci aiuta a valutare rischi e benefici attesi in situazioni incerte, orientando le nostre scelte in maniera ottimale.\n\n\n\n21.1.5 L’Importanza della Quantificazione dell’Incertezza\nQuantificare l’incertezza attraverso la teoria della probabilità è cruciale in molti campi:\n\nRicerca scientifica: La probabilità permette di valutare la solidità dell’evidenza raccolta a supporto di un’ipotesi.\nPsicologia: In ambito clinico e sperimentale, la probabilità aiuta a valutare l’efficacia dei trattamenti e a prendere decisioni informate su interventi terapeutici.\nEconomia e finanza: La teoria della probabilità è fondamentale per la gestione del rischio e la valutazione di investimenti.\nPrevisioni meteorologiche: Permette di comunicare l’incertezza legata alle previsioni, dando una stima del margine di errore.\n\nIn sintesi, il concetto di casualità e la teoria della probabilità costituiscono strumenti potenti per navigare un mondo intrinsecamente incerto. Forniscono un linguaggio preciso per descrivere l’incertezza e un quadro rigoroso per ragionare su di essa. Comprendere questi concetti è essenziale non solo per matematici o statistici, ma per chiunque desideri prendere decisioni razionali in condizioni di incertezza, che si tratti di ricercatori, psicologi o cittadini comuni.\nNei capitoli seguenti, esploreremo in dettaglio come questi concetti si applicano all’analisi dei dati, con un focus particolare sull’approccio bayesiano. Questo metodo offre un modo naturale e intuitivo di ragionare sull’incertezza, aggiornando progressivamente le conoscenze alla luce di nuove evidenze.\n\n\n21.1.6 Storia e Definizioni della Probabilità\nLa probabilità è un concetto cardine nella matematica e nelle scienze, utilizzato per misurare l’incertezza e studiare fenomeni aleatori. Nel corso del tempo, la sua definizione si è evoluta, passando da intuizioni di tipo qualitativo a formulazioni formali e rigorose.\nLa probabilità nasce dal bisogno di distinguere gli eventi deterministici, il cui esito è prevedibile, da quelli casuali, caratterizzati dall’imprevedibilità. Un evento deterministico, almeno in teoria, produce sempre lo stesso risultato nelle stesse condizioni, mentre un evento casuale ha esiti che non possiamo prevedere con certezza. Questa distinzione ha portato alla necessità di quantificare l’incertezza associata agli eventi casuali, utilizzando il concetto di probabilità.\n\n\n21.1.7 Fonti dell’Incertezza\nL’incertezza nei fenomeni casuali può derivare da due fonti principali:\n\nIncertezza epistemica: Questa forma di incertezza è legata alla nostra conoscenza limitata. Ad esempio, in un esperimento scientifico complesso, la nostra impossibilità di controllare tutte le variabili può introdurre incertezza nei risultati.\nIncertezza ontologica: Si riferisce alla casualità intrinseca di alcuni fenomeni, come in fisica quantistica, dove l’indeterminazione sembra essere una caratteristica fondamentale della realtà stessa. Un esempio intuitivo è il lancio di un dado: indipendentemente da quanto conosciamo le condizioni, non possiamo prevedere con assoluta precisione il risultato.\n\nIl fisico danese Niels Bohr ha offerto un’interpretazione illuminante su questo tema: la fisica, secondo Bohr, non mira a rivelare una verità assoluta sulla natura, ma a capire cosa possiamo dire su di essa. Questa visione riconosce che l’incertezza – sia epistemica che ontologica – riflette i limiti del nostro linguaggio e delle nostre conoscenze. Questo approccio si allinea bene con l’interpretazione soggettiva della probabilità, secondo la quale la probabilità rappresenta il grado di fiducia che un individuo ha riguardo al verificarsi di un evento, basata sulle informazioni di cui dispone.\n\n\n21.1.8 Assiomatizzazione della Probabilità\nNel 1933, il matematico Andrey Kolmogorov fornì una definizione formale della probabilità, introducendo un sistema assiomatico che costituì la base della moderna teoria della probabilità. Questa formulazione ha trasformato la probabilità in una disciplina matematica rigorosa, offrendo uno strumento essenziale per quantificare l’incertezza in contesti scientifici. Da semplice metodo per analizzare i giochi d’azzardo nel XVII secolo, la probabilità è diventata una pietra miliare del ragionamento scientifico, fornendo un linguaggio universale per descrivere e analizzare l’incertezza in numerosi campi del sapere.\n\n\n21.1.9 Interpretazioni Frequentiste e Bayesiane\nLe due principali interpretazioni della probabilità sono:\n\nInterpretazione frequentista: In questo approccio, la probabilità di un evento è definita come il limite della frequenza relativa con cui l’evento si verifica in una lunga serie di esperimenti identici. Questa visione oggettiva considera la probabilità come una proprietà intrinseca del fenomeno, indipendente dalle informazioni dell’osservatore.\nInterpretazione bayesiana: Al contrario, la probabilità è vista come una credenza soggettiva sul verificarsi di un evento. In questa visione, la probabilità rappresenta il grado di fiducia di un osservatore, dipendente dalle informazioni disponibili e dal contesto. L’approccio bayesiano permette quindi di aggiornare le stime probabilistiche man mano che nuove evidenze vengono acquisite, rendendo la probabilità una misura flessibile della conoscenza.\n\n\n\n21.1.10 La Storia della Probabilità\nLa probabilità moderna nacque da una domanda posta da Antoine Gombaud (Chevalier de Méré) a Blaise Pascal nel XVII secolo su come dividere equamente le puntate di un gioco d’azzardo interrotto.\n\n21.1.10.1 Il Problema dei Punti\nIl problema può essere riassunto come segue:\n\nImmaginiamo due persone, A e B, che partecipano a un gioco in cui il primo che vince sei round consecutivi ottiene un premio. Dopo sei round, A ha vinto cinque round e B uno. Poiché il gioco si interrompe prima di assegnare il premio, come dovrebbero dividere il premio in modo equo?\n\nQuesta domanda diede origine a una corrispondenza tra Pascal e Fermat, che svilupparono una soluzione matematica basata sulle probabilità di vittoria per ciascun giocatore. Se, per esempio, A aveva una probabilità del 97% di vincere, mentre B una del 3%, sembrava equo assegnare il 97% del premio ad A. La loro corrispondenza ispirò l’opera di Christian Huygens, “De Ratiociniis in Ludo Aleae” (1657), che rimase un riferimento in probabilità per mezzo secolo.\n\n\n21.1.10.2 Sviluppi Successivi\nNel 1713, Jacob Bernoulli pubblicò postumo “L’Arte della Congettura”, introducendo la legge dei grandi numeri e ponendo le basi per l’applicazione della probabilità al di fuori dei giochi d’azzardo, ad esempio nello studio della mortalità e della giustizia penale.\n\n\n\n21.1.11 Interpretazione Classica\nLa definizione classica di probabilità fu proposta da Pierre-Simon Laplace (1749-1827), che basò il concetto sul calcolo combinatorio. Secondo Laplace, la probabilità di un evento è data dal rapporto tra i casi favorevoli e il numero totale di casi possibili, assumendo che tutti siano equiprobabili. Ad esempio, la probabilità di ottenere un “3” lanciando un dado è \\(\\frac{1}{6}\\), poiché solo uno dei sei risultati è favorevole. Tuttavia, questa definizione è limitata, poiché si basa sull’assunzione che ogni evento sia equiprobabile, il che non è sempre vero. Inoltre, è parzialmente circolare, poiché presuppone una conoscenza implicita del concetto di probabilità.\n\n\n21.1.12 Interpretazione Frequentista\nL’approccio frequentista, nato dalla necessità di evitare le limitazioni dell’interpretazione classica, definisce la probabilità come il limite della frequenza relativa con cui un evento si verifica in una serie infinita di prove. Per esempio, la probabilità di ottenere “testa” in un lancio di moneta può essere stimata come la frequenza relativa di “testa” sul totale dei lanci, quando il numero di lanci tende all’infinito. Questa definizione è utile, ma impraticabile in molte situazioni, poiché richiede un numero infinito di ripetizioni e assume che gli eventi futuri siano identici a quelli passati.\n\ncoin_flips &lt;- function(n, run_label) {\n  # Genera un vettore di 0 e 1 dove 1 rappresenta \"testa\" e 0 \"croce\"\n  # usando una distribuzione binomiale.\n  heads &lt;- rbinom(n, 1, 0.5)\n  \n  # Calcola la proporzione cumulativa di teste.\n  flips &lt;- seq(1, n)\n  proportion_heads &lt;- cumsum(heads) / flips\n  \n  # Crea un data frame per un facile accesso e visualizzazione dei dati.\n  df &lt;- data.frame(flips = flips, proportion_heads = proportion_heads, run = run_label)\n  \n  return(df)\n}\n\nn &lt;- 1000\n\ndf &lt;- do.call(rbind, lapply(1:4, function(i) coin_flips(n, paste0(\"run\", i))))\n\nggplot(df, aes(x = flips, y = proportion_heads, color = run)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n21.1.13 La Legge dei Grandi Numeri\nLa simulazione precedente fornisce un esempio della Legge dei grandi numeri. La Legge dei Grandi Numeri afferma che, man mano che il numero di esperimenti casuali ripetuti aumenta, la stima della probabilità di un evento \\(P(Y=y)\\) diventa sempre più accurata.\nIl teorema sostiene che, con l’aumento del numero di ripetizioni di un esperimento casuale, la media dei risultati osservati tende a convergere al valore atteso teorico della variabile casuale. In altre parole, la media empirica dei risultati osservati si avvicina sempre di più al valore medio teorico.\nQuesta legge è cruciale perché garantisce che, con un numero sufficientemente grande di prove, la stima empirica della probabilità di un evento si avvicina al valore reale. Questo rende le stime probabilistiche più precise e affidabili.\nDal punto di vista pratico, la Legge dei Grandi Numeri consente di utilizzare modelli probabilistici per interpretare fenomeni reali. Anche se le osservazioni singole possono variare in modo casuale, la media delle osservazioni su un ampio numero di ripetizioni rifletterà fedelmente le probabilità teoriche.\nFormalmente, data una serie di variabili casuali indipendenti \\(X_1, X_2, \\ldots, X_n\\), ciascuna con media \\(\\mu\\), la Legge dei Grandi Numeri è espressa come:\n\\[\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{X_1 + X_2 + \\ldots + X_n}{n} - \\mu\\right| &lt; \\epsilon\\right) = 1,\n\\]\ndove \\(\\epsilon\\) è un valore positivo arbitrariamente piccolo e \\(P(\\cdot)\\) indica la probabilità. Questo significa che, con un numero molto grande di ripetizioni, la media campionaria osservata sarà vicina alla media teorica attesa, permettendo inferenze affidabili sulla probabilità degli eventi.\nIn sintesi, la Legge dei Grandi Numeri assicura che, aumentando il numero di prove, le stime empiriche delle probabilità diventano sempre più precise, allineandosi con i valori teorici attesi.\n\n21.1.13.1 Problema del caso singolo\nNell’ambito dell’approccio frequentista alla probabilità, basato sulla concezione delle frequenze relative di eventi osservati su lunghe serie di ripetizioni, emerge un limite concettuale nel trattare la probabilità di eventi singolari e non ripetibili. Secondo questa prospettiva, infatti, non risulta rigorosamente appropriato discutere di probabilità relative a eventi unici e non replicabili nel tempo. Esempi emblematici di tali eventi includono la possibilità che Alcaraz vinca contro Djokovic nella finale di Wimbledon del 2023 o che si verifichi pioggia a Firenze il giorno di Ferragosto del 2024. Questi scenari, essendo unici e circoscritti a un preciso momento storico, sfuggono alla logica frequentista che richiede, per definizione, la possibilità di osservazione ripetuta degli eventi per valutarne la probabilità. Nonostante ciò, nel linguaggio comune non specialistico, è comune l’uso del termine “probabilità” per riferirsi anche a tali eventi specifici e non ripetibili, evidenziando così una discrepanza tra l’uso tecnico e quello colloquiale del concetto di probabilità.\n\n\n\n21.1.14 Collegamento tra probabilità e statistica\nDurante gli anni ’20 del Novecento, Ronald A. Fisher propose un nuovo framework teorico per l’inferenza statistica, basato sulla concettualizzazione della frequenza. Fisher introdusse concetti chiave come la massima verosimiglianza, i test di significatività, i metodi di campionamento, l’analisi della varianza e il disegno sperimentale.\nNegli anni ’30, Jerzy Neyman ed Egon Pearson fecero ulteriori progressi nel campo con lo sviluppo di una teoria della decisione statistica, basata sul principio della verosimiglianza e sull’interpretazione frequentista della probabilità. Definirono due tipologie di errori decisionali e utilizzarono il test di significatività di Fisher, interpretando i valori-\\(p\\) come indicatori dei tassi di errore a lungo termine.\n\n\n21.1.15 La riscoperta dei metodi Monte Carlo Markov chain\nFisher assunse una prospettiva critica nei confronti della “probabilità inversa” (ossia, i metodi bayesiani), nonostante questa fosse stata la metodologia predominante per l’inferenza statistica per quasi un secolo e mezzo. Il suo approccio frequentista ebbe un profondo impatto sullo sviluppo della statistica sia teorica che sperimentale, contribuendo a un decremento nell’utilizzo dell’inferenza basata sul metodo della probabilità inversa, originariamente proposto da Laplace.\nNel 1939, il libro di Harold Jeffreys intitolato “Theory of Probability” rappresentò una delle prime esposizioni moderne dei metodi bayesiani. Tuttavia, la rinascita del framework bayesiano fu rinviata fino alla scoperta dei metodi Monte Carlo Markov chain alla fine degli anni ’80. Questi metodi hanno reso fattibile il calcolo di risultati precedentemente non ottenibili, consentendo un rinnovato interesse e sviluppo nei metodi bayesiani. Per una storia dell’approccio bayesiano, si veda Bayesian Methods: General Background oppure Philosophy of Statistics.\n\n\n21.1.16 Interpretazione soggettivista\nUna visione alternativa della probabilità la considera come una credenza soggettiva. Finetti (1970) ha proposto un’interpretazione in cui la probabilità non è vista come una caratteristica oggettiva degli eventi, ma piuttosto come una misura della credenza soggettiva, suggerendo di trattare \\(p(·)\\) come una probabilità soggettiva. È interessante notare che de Finetti era un soggettivista radicale. Infatti, la frase di apertura del suo trattato in due volumi sulla probabilità afferma che “La probabilità non esiste”, intendendo che la probabilità non ha uno status oggettivo, ma rappresenta piuttosto la quantificazione della nostra esperienza di incertezza. Riteneva che l’idea di una probabilità esterna all’individuo, con uno status oggettivo, fosse pura superstizione, paragonabile al credere in “Etere cosmico, Spazio e Tempo assoluti, …, o Fate e Streghe…”. Secondo de Finetti, “… esistono solo probabilità soggettive - cioè, il grado di credenza nell’occorrenza di un evento attribuito da una determinata persona in un dato momento con un dato insieme di informazioni.”\nCome sottolineato da Press (2009), la prima menzione della probabilità come grado di credenza soggettiva fu fatta da Ramsey (1926), ed è questa nozione di probabilità come credenza soggettiva che ha portato a una notevole resistenza alle idee bayesiane. Una trattazione dettagliata degli assiomi della probabilità soggettiva si trova in Fishburn (1986).\nLa denominazione “soggettivo” legata alla probabilità potrebbe risultare infelice, poiché potrebbe suggerire un ragionamento vago o non scientifico. Lindley (2013) condivide queste riserve, proponendo l’alternativa “probabilità personale” rispetto a “probabilità soggettiva”. Analogamente, Howson & Urbach (2006) preferiscono utilizzare l’espressione “probabilità epistemica”, che riflette il grado di incertezza di un individuo di fronte al problema trattato. In sostanza, la probabilità epistemica si riferisce all’incertezza personale riguardo a variabili sconosciute. Questa terminologia viene adottata anche nel testo di Kaplan (2023), fornendo un linguaggio più neutro per discutere di questi concetti.\nVa inoltre notato che l’interpretazione soggettiva si adatta bene a eventi singoli, permettendo di esprimere una convinzione su eventi specifici, come la probabilità di pioggia in un dato giorno o l’esito di una competizione sportiva.\n\n\n\n\n\n\nNota\n\n\n\nPer chi desidera approfondire, il primo capitolo del testo Bernoulli’s Fallacy (Clayton, 2021) offre un’introduzione molto leggibile alle tematiche della definizione della probabilità nella storia della scienza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/01_intro_prob.html#commenti-e-considerazioni-finali",
    "title": "21  Interpretazione della probabilità",
    "section": "21.2 Commenti e Considerazioni Finali",
    "text": "21.2 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo esplorato il significato filosofico della nozione di probabilità e introdotto la simulazione come metodo per approssimare le probabilità empiriche quando non è possibile ottenere soluzioni analitiche.\nNel prossimo capitolo, esamineremo la probabilità dal punto di vista matematico.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "21  Interpretazione della probabilità",
    "section": "21.3 Informazioni sull’Ambiente di Sviluppo",
    "text": "21.3 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.0       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] labeling_0.4.3    rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [37] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    utf8_1.2.4       \n#&gt; [41] broom_1.0.7       withr_3.0.2       backports_1.5.0   promises_1.3.1   \n#&gt; [45] timechange_0.3.0  rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3        \n#&gt; [49] shiny_1.9.1       evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4      \n#&gt; [53] Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9   \n#&gt; [57] R6_2.5.1",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#bibliografia",
    "href": "chapters/probability/01_intro_prob.html#bibliografia",
    "title": "21  Interpretazione della probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nClayton, A. (2021). Bernoulli’s Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press.\n\n\nFinetti, B. de. (1970). Teoria delle probabilità (pp. VIII, 350–769). G. Einaudi.\n\n\nFishburn, P. C. (1986). The axioms of subjective probability. Statistical Science, 1(3), 335–345.\n\n\nHowson, C., & Urbach, P. (2006). Scientific reasoning: the Bayesian approach. Open Court Publishing.\n\n\nKaplan, D. (2023). Bayesian statistics for the social sciences. Guilford Publications.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.\n\n\nPress, S. J. (2009). Subjective and objective Bayesian statistics: Principles, models, and applications. John Wiley & Sons.\n\n\nRamsey, F. P. (1926). Truth and probability. In Readings in Formal Epistemology: Sourcebook (pp. 21–45). Springer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html",
    "href": "chapters/probability/02_prob_spaces.html",
    "title": "22  Misura di Probabilità",
    "section": "",
    "text": "22.1 Introduzione alle Probabilità: Origine e Definizione\nPrerequisiti\nConcetti e Competenze Chiave\nDa dove derivano matematicamente i numeri che chiamiamo “probabilità”? Per rispondere, in questo capitolo faremo riferimento alla trattazione di Michael Betancourt. Questo capitolo offre una versione semplificata del suo lavoro, mantenendo la notazione e le figure originali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#insiemi-finiti",
    "href": "chapters/probability/02_prob_spaces.html#insiemi-finiti",
    "title": "22  Misura di Probabilità",
    "section": "22.2 Insiemi Finiti",
    "text": "22.2 Insiemi Finiti\nPer semplificare, Betancourt introduce i fondamenti della teoria della probabilità utilizzando uno spazio campionario composto da un numero finito di elementi.\nUn insieme finito è costituito da un numero finito di elementi distinti,\n\\[\nX = \\{x_1, ..., x_N\\}.\n\\]\nQui, l’indice numerico serve a distinguere gli \\(N\\) elementi individuali, senza implicare necessariamente un ordine particolare tra di essi. Per evitare qualsiasi presunzione di ordine, Betancourt utilizza il seguente insieme arbitrario di cinque elementi quale esempio:\n\\[\nX = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}.\n\\]\n\n\n\n\n\n\nFigura 22.1: Un insieme finito contiene un numero finito di elementi. Questo particolare insieme ne contiene cinque.\n\n\n\nNelle applicazioni pratiche della teoria della probabilità, gli elementi astratti \\(x_{n}\\) rappresentano oggetti concreti. Tuttavia, in questo capitolo, ci si concentrerà esclusivamente sui concetti matematici, evitando qualsiasi interpretazione particolare. Quando l’insieme \\(X\\) rappresenta tutti gli oggetti di interesse in una data applicazione, viene denominato spazio campionario. Una volta definito lo spazio campionario, possiamo organizzare e manipolare i suoi elementi in vari modi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#sottoinsiemi",
    "title": "22  Misura di Probabilità",
    "section": "22.3 Sottoinsiemi",
    "text": "22.3 Sottoinsiemi\nUn sottoinsieme di \\(X\\) è qualsiasi collezione di elementi in \\(X\\). Per evitare ambiguità, Betancourt usa le lettere romane minuscole \\(x\\) per indicare un elemento variabile nello spazio campionario \\(X\\) e le lettere minuscole sans serif \\(\\mathsf{x}\\) per indicare un sottoinsieme variabile.\nAd esempio, \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) è un sottoinsieme di \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\). Importante notare che nel concetto di sottoinsieme non esiste la nozione di molteplicità, solo di appartenenza: un sottoinsieme può includere un elemento \\(x_{n}\\) ma non può includerlo più volte.\n\n\n\n\n\n\nFigura 22.2: Un sottoinsieme \\(\\mathsf{x} \\subset X\\) è qualsiasi collezione di elementi dallo spazio campionario \\(X\\). Qui \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) contiene solo tre dei cinque elementi in $X = {, , , , }.\n\n\n\nSe \\(\\mathsf{x}\\) è un sottoinsieme dello spazio campionario \\(X\\) allora scriviamo \\(\\mathsf{x} \\subset X\\). Quando \\(\\mathsf{x}\\) contiene tutti gli elementi di \\(X\\), ovvero \\(\\mathsf{x} = X\\), allora scriviamo \\(\\mathsf{x} \\subseteq X\\).\nIndipendentemente da quanti elementi un insieme finito \\(X\\) contiene, possiamo sempre costruire tre tipi speciali di sottoinsiemi. L’insieme vuoto \\(\\emptyset = \\{\\}\\) non contiene alcun elemento. D’altra parte, l’intero insieme stesso può essere considerato un sottoinsieme contenente tutti gli elementi. Un sottoinsieme contenente un singolo elemento è denotato \\(\\{ x_{n} \\}\\) ed è chiamato insieme atomico.\nCi sono\n\\[\n{N \\choose n} = \\frac{ N! }{ n! (N - n)!}\n\\]\nmodi per selezionare \\(n\\) elementi da un insieme finito di \\(N\\) elementi totali, e quindi \\({N \\choose n}\\) sottoinsiemi totali di dimensione \\(n\\). Ad esempio, esiste un solo sottoinsieme che non contiene alcun elemento,\n\\[\n{N \\choose 0} = \\frac{ N! }{ 0! (N - 0)!} = \\frac{ N! }{ N! } = 1,\n\\]\ned è l’insieme vuoto. Allo stesso modo, esiste un solo sottoinsieme che contiene tutti gli elementi,\n\\[\n{N \\choose N} = \\frac{ N! }{ N! (N - N)!} = \\frac{ N! }{ N! } = 1,\n\\]\ned è l’insieme completo stesso. D’altra parte, ci sono\n\\[\n{N \\choose 1} = \\frac{ N! }{ 1! (N - 1)!} = N\n\\]\ninsiemi atomici distinti che contengono un solo elemento, uno per ciascun elemento in \\(X\\).\nContando tutti i sottoinsiemi di tutte le dimensioni possibili si ottiene\n\\[\n\\sum_{n = 0}^{N} {N \\choose n} = 2^{N}\n\\]\nsottoinsiemi possibili che possiamo costruire da un insieme finito con \\(N\\) elementi.\nLa collezione di tutti i sottoinsiemi è essa stessa un insieme finito con \\(2^{N}\\) elementi. Chiamiamo questo insieme insieme potenza di \\(X\\) e lo denotiamo \\(2^{X}\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "title": "22  Misura di Probabilità",
    "section": "22.4 Operazioni sui Sottoinsiemi",
    "text": "22.4 Operazioni sui Sottoinsiemi\nPossiamo sempre costruire sottoinsiemi elemento per elemento, ma possiamo anche costruirli manipolando sottoinsiemi esistenti.\nAd esempio, dato un sottoinsieme \\(\\mathsf{x} \\subset X\\) possiamo costruire il suo complemento raccogliendo tutti gli elementi in \\(X\\) che non sono già in \\(\\mathsf{x}\\). L’insieme atomico \\(\\mathsf{x} = \\{ \\diamondsuit \\}\\) contiene l’unico elemento \\(\\diamondsuit\\) e il suo complemento contiene i rimanenti elementi \\[\n\\mathsf{x}^{c} = \\{ \\Box, \\clubsuit, \\heartsuit, \\spadesuit \\}.\n\\] Per costruzione, il complemento dell’insieme vuoto è l’intero insieme, \\(\\emptyset^{c} = X\\), e il complemento dell’insieme completo è l’insieme vuoto, \\(X^{c} = \\emptyset\\).\n\n\n\n\n\n\nFigura 22.3: Il complemento di un sottoinsieme \\(\\mathsf{x}\\) è il sottoinsieme \\(\\mathsf{x}^{c}\\) costituito da tutti gli elementi nello spazio campionario che non sono in \\(\\mathsf{x}\\).\n\n\n\nAd esempio, applicando l’operatore di complemento al sottoinsieme \\(\\mathsf{x} = \\{ \\clubsuit, \\spadesuit \\}\\) otteniamo \\[\n\\mathsf{x}^{c}\n= \\{ \\clubsuit, \\spadesuit \\}^{c}\n= \\{ \\Box, \\diamondsuit, \\heartsuit \\}.\n\\]\nPossiamo anche costruire sottoinsiemi da più di un sottoinsieme. Consideriamo, ad esempio, due sottoinsiemi \\(\\mathsf{x}_1 = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_2 = \\{ \\Box, \\spadesuit \\}\\). La collezione di tutti gli elementi che sono contenuti in uno qualsiasi dei due sottoinsiemi è essa stessa un sottoinsieme, \\[\n\\{ \\Box, \\heartsuit, \\spadesuit \\} \\subset X,\n\\] così come la collezione di tutti gli elementi che sono contenuti in entrambi i sottoinsiemi, \\[\n\\{ \\Box \\} \\subset X.\n\\] Questi sottoinsiemi derivati sono chiamati rispettivamente unione, \\[\n\\mathsf{x}_1 \\cup \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box, \\heartsuit, \\spadesuit \\},\n\\] e intersezione, \\[\n\\mathsf{x}_1 \\cap \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cap \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box \\}.\n\\]\n\n\n\n\n\n\nFigura 22.4: Possiamo manipolare due sottoinsiemi in vari modi per ottenere un nuovo sottoinsieme.\n\n\n\n\n\n\n\n\n\nFigura 22.5: L’unione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cup \\mathsf{x}_2\\), è un sottoinsieme contenente tutti gli elementi di entrambi i sottoinsiemi in input. D’altra parte, l’intersezione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cap \\mathsf{x}_2\\), è un sottoinsieme contenente solo gli elementi che compaiono in entrambi i sottoinsiemi in input.\n\n\n\nDue sottoinsiemi sono disgiunti se non condividono alcun elemento; in questo caso la loro intersezione è l’insieme vuoto, \\[\n\\mathsf{x}_{1} \\cap \\mathsf{x}_{2} = \\emptyset.\n\\] L’unione e l’intersezione di un sottoinsieme con se stesso restituiscono quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\mathsf{x} = \\mathsf{x} \\cap \\mathsf{x} = \\mathsf{x}.\n\\] Poiché l’insieme vuoto non contiene alcun elemento, la sua unione con qualsiasi sottoinsieme restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\emptyset = \\emptyset \\cup \\mathsf{x} = \\mathsf{x},\n\\] e la sua intersezione con qualsiasi sottoinsieme restituisce l’insieme vuoto, \\[\n\\mathsf{x} \\cap \\emptyset = \\emptyset \\cap \\mathsf{x} = \\emptyset.\n\\] Allo stesso modo, l’unione di un sottoinsieme con l’insieme completo restituisce l’insieme completo, \\[\n\\mathsf{x} \\cup X = X \\cup \\mathsf{x} = X,\n\\] e l’intersezione di un sottoinsieme con l’insieme completo restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cap X = X \\cap \\mathsf{x} = \\mathsf{x}.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sugli-elementi",
    "href": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sugli-elementi",
    "title": "22  Misura di Probabilità",
    "section": "22.5 Misura e Probabilità sugli Elementi",
    "text": "22.5 Misura e Probabilità sugli Elementi\nDa un punto di vista matematico, la teoria della misura riguarda l’allocazione coerente di una qualche quantità astratta attraverso lo spazio campionario. Consideriamo un serbatoio (il termine standard in questo contesto sarebbe “misura totale” o “massa totale”) di una qualche quantità positiva, continua e conservata, \\(M \\in [0, \\infty]\\). Poiché \\(M\\) è conservato, qualsiasi quantità \\(m_{n}\\) che viene allocata all’elemento \\(x_{n} \\in X\\) deve essere detratta dal serbatoio, lasciando meno da allocare agli altri elementi.\nUn caso particolare si verifica quando il contenuto totale del serbatoio \\(M\\) è infinito. In questo scenario, possiamo allocare una quantità infinita dal serbatoio pur avendo ancora una quantità infinita rimanente. Allo stesso tempo, allocare una quantità infinita può esaurire completamente il serbatoio o lasciare qualsiasi quantità finita residua. L’infinito è un concetto matematicamente complesso da trattare.\n\n\n\n\n\n\nFigura 22.6: La teoria della misura riguarda l’allocazione di una qualche quantità continua e positiva \\(M\\) sugli elementi individuali dello spazio campionario.\n\n\n\nUn’allocazione esaustiva di \\(M\\) su tutto lo spazio campionario assicura che il serbatoio sia completamente svuotato. In altre parole, l’intero valore di \\(M\\) deve essere distribuito tra gli elementi \\(x_{n} \\in X\\).\nPer illustrare questo concetto, consideriamo il nostro spazio campionario dimostrativo \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit \\}\\). Il processo di allocazione può essere descritto come segue:\n\nAllocchiamo \\(m_\\Box\\) a \\(\\Box\\), lasciando \\(M - m_\\Box\\) nel serbatoio.\nAssegniamo \\(m_\\clubsuit\\) a \\(\\clubsuit\\), riducendo ulteriormente il contenuto del serbatoio a \\(M - m_\\Box - m_\\clubsuit\\).\nContinuiamo questo processo per \\(\\diamondsuit\\) e \\(\\heartsuit\\).\nInfine, per svuotare completamente il serbatoio, dobbiamo allocare tutto ciò che rimane a \\(\\spadesuit\\).\n\nMatematicamente, l’ammontare finale allocato a \\(\\spadesuit\\) sarà:\n\\[\nM - m_{\\Box} - m_{\\clubsuit} - m_{\\diamondsuit} - m_{\\heartsuit}.\n\\]\nQuesta allocazione finale assicura che la somma di tutte le quantità distribuite sia esattamente uguale a \\(M\\), svuotando così completamente il serbatoio.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n \n\n\n\n\nFigura 22.7: Poiché la quantità totale \\(M\\) è conservata, ogni allocazione \\(m_{n}\\) a un elemento \\(x_{n} \\in X\\) riduce la quantità disponibile per l’allocazione agli altri elementi. Un’allocazione esaustiva non lascia nulla nel serbatoio iniziale dopo che ciascun elemento ha ricevuto la sua allocazione.\n\n\n\nUna misura è qualsiasi allocazione coerente della quantità \\(M\\) agli elementi di uno spazio campionario. Matematicamente, qualsiasi misura su un insieme finito può essere caratterizzata da \\(N\\) numeri \\[\n\\mu = \\{ m_{1}, \\ldots, m_{N} \\}\n\\] che soddisfano \\[\n0 \\le m_{n}\n\\] e \\[\n\\sum_{n = 1}^{N} m_{n} = M.\n\\] Ad esempio, qualsiasi misura sui cinque elementi dell’insieme \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\) è specificata da cinque numeri positivi \\(\\{ m_\\Box, m_\\clubsuit, m_\\diamondsuit, m_\\heartsuit, m_\\spadesuit \\}\\) che soddisfano \\[\nm_\\Box + m_\\clubsuit + m_\\diamondsuit + m_\\heartsuit + m_\\spadesuit = M.\n\\]\n\n\n\n\n\n\nFigura 22.8: Una misura \\(\\mu\\) su un insieme finito \\(X\\) è qualsiasi allocazione coerente di \\(M\\) agli elementi $x_{n} X. Ogni misura può essere caratterizzata da \\(N\\) numeri \\(m_{n}\\) che sommano a \\(M\\), o equivalentemente una funzione che mappa ogni elemento \\(x_{n}\\) alla sua misura allocata \\(m_{n}\\).\n\n\n\nPiù grande è \\(m_{n}\\), più di \\(M\\) viene allocato all’elemento \\(x_{n}\\). Seguendo questa terminologia, chiameremo anche \\(M\\) come la misura totale e \\(m_{n}\\) come la misura allocata a \\(x_{n}\\).\nIn questa discussione, ci occuperemo solo di misure finite, dove la misura totale \\(M\\) è un numero positivo e finito (\\(0 \\leq M \\leq \\infty\\)). Non tratteremo il caso di misure infinite (\\(M = \\infty\\)), poiché richiede considerazioni più complesse che vanno oltre lo scopo di questa trattazione.\nUna misura \\(\\mu\\) su uno spazio campionario \\(X\\) può essere vista come una funzione che assegna un valore numerico non negativo (la misura) a ogni elemento dello spazio:\n\\[\n\\begin{alignat*}{6}\n\\mu :\\; & X & &\\rightarrow& \\; & [0, \\infty] &\n\\\\\n& x_{n} & &\\mapsto& & m_{n} = \\mu(x_{n}) &,\n\\end{alignat*}\n\\] dove:\n\n\\(X\\) è lo spazio campionario,\n\\(x_n\\) è un elemento di \\(X\\),\n\\(m_n\\) è la misura assegnata a \\(x_n\\).\n\nQuesto approccio funzionale ci permette di considerare ogni elemento dello spazio campionario separatamente, valutando \\(\\mu(x_{n})\\) per ciascun \\(x_{n}\\), invece di dover gestire tutte le allocazioni contemporaneamente.\nÈ importante notare che esistono molti modi diversi per distribuire una misura totale \\(M\\) tra gli elementi di un insieme finito. L’insieme di tutte le possibili misure su \\(X\\) si indica con \\(\\mathcal{M}(X)\\).\nAll’interno di questa collezione ci sono alcuni esempi notevoli. Ad esempio, una misura singolare alloca la misura totale \\(M\\) a un singolo elemento, lasciando il resto con niente. D’altra parte, una misura uniforme alloca la stessa misura \\(M / N\\) a ciascun elemento. Su insiemi finiti ci sono \\(N\\) misure singolari distinte, una per ciascun elemento distinto, e una misura uniforme unica.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigura 22.9: Una misura singolare (a) alloca la misura totale a un singolo elemento, mentre la misura uniforme (b) distribuisce la misura totale uniformemente a ciascun elemento.\n\n\n\nLe misure finite sono una categoria particolarmente importante nel campo della teoria della misura. Una misura si definisce finita quando la sua misura totale \\(M\\) è un numero positivo e limitato, ovvero \\(0 &lt; M &lt; \\infty\\).\nL’importanza delle misure finite risiede nella possibilità di esprimere le allocazioni in termini relativi anziché assoluti. Questo significa che possiamo rappresentare la misura di ciascun elemento come una frazione o una percentuale della misura totale, invece di usare il valore assoluto. Invece di considerare la misura assoluta allocata a ciascun elemento \\(m_{n}\\), possiamo considerare la proporzione della misura totale allocata a ciascun elemento \\[\np_{n} = m_{n} / M.\n\\] Per costruzione, le proporzioni sono confinate all’intervallo unitario \\([0, 1]\\). Come per qualsiasi quantità che assume valori in \\([0, 1]\\), possiamo rappresentare le proporzioni altrettanto bene con decimali, ad esempio \\(p_{n} = 0.2\\), e percentuali, \\(p_{n} = 20\\%\\).\nQuesto approccio relativo offre diversi vantaggi: permette di confrontare facilmente l’importanza relativa di diversi elementi, facilita la comprensione della distribuzione della misura sull’intero spazio campionario e consente di normalizzare misure diverse, rendendo più semplice il confronto tra sistemi diversi. In sintesi, le misure finite ci permettono di passare da una visione “assoluta” a una “relativa” della distribuzione della misura, offrendo una prospettiva più intuitiva e utile per l’analisi.\n\n\n\n\n\n\nFigura 22.10: Ogni misura finita può essere caratterizzata da un’allocazione proporzionale.\n\n\n\nIn altre parole, una misura proporzionale definisce la funzione \\[\n\\begin{alignat*}{6}\n\\pi :\\; & X & &\\rightarrow& \\; & [0, 1] &\n\\\\\n& x_{n} & &\\mapsto& & p_{n} = \\pi(x_{n}) &\n\\end{alignat*}\n\\] con \\[\n0 \\le p_{n} \\le 1\n\\] e \\[\n\\sum_{n = 1}^{N} p_{n} = 1.\n\\] Una collezione di variabili \\(\\{ p_{1}, \\ldots, p_{N} \\}\\) che soddisfano queste proprietà è chiamata simplex.\n\n\n\n\n\n\nFigura 22.11: Un’allocazione proporzionale è anche conosciuta come distribuzione di probabilità.\n\n\n\nPiù importante, una misura proporzionale \\(\\pi\\) è anche conosciuta come distribuzione di probabilità, e le allocazioni proporzionali \\(p_{n}\\) sono chiamate probabilità. Sebbene il termine “probabilità” sia spesso carico di significati interpretativi e filosofici, la sua struttura matematica è piuttosto semplice: su un insieme finito, una probabilità rappresenta semplicemente la proporzione di una quantità finita assegnata a ciascun elemento individuale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sui-sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sui-sottoinsiemi",
    "title": "22  Misura di Probabilità",
    "section": "22.6 Misura e Probabilità sui Sottoinsiemi",
    "text": "22.6 Misura e Probabilità sui Sottoinsiemi\nSugli insiemi finiti, qualsiasi allocazione, sia assoluta che proporzionale, agli elementi individuali \\(x \\in X\\) determina anche un’allocazione per i sottoinsiemi \\(\\mathsf{x} \\in 2^{X}\\). La misura assegnata a un sottoinsieme è semplicemente la somma delle misure assegnate agli elementi che lo compongono. Ad esempio, la misura assegnata al sottoinsieme \\(\\mathsf{x} = \\{ \\Box, \\clubsuit, \\heartsuit \\}\\) è \\(m_{\\Box} + m_{\\clubsuit} + m_{\\heartsuit}\\).\n\n\n\n\n\n\nFigura 22.12: Su un insieme finito, un’allocazione sugli elementi individuali definisce anche un’allocazione su qualsiasi sottoinsieme.\n\n\n\nPer costruzione, qualsiasi misura sui sottoinsiemi e distribuzione di probabilità soddisfano una serie di proprietà utili. Ad esempio, per qualsiasi misura \\[\n\\mu( \\emptyset ) = 0\n\\] e \\[\n\\mu( X ) = \\sum_{n = 1}^{N} \\mu(x_{n}) = M,\n\\] mentre per qualsiasi distribuzione di probabilità abbiamo \\(\\pi( \\emptyset ) = 0\\) e \\(\\pi( X ) = 1\\).\nLe allocazioni sui sottoinsiemi si combinano in modo naturale con le operazioni sui sottoinsiemi. Consideriamo, ad esempio, i due sottoinsiemi disgiunti \\(\\mathsf{x}_{1} = \\{ \\Box, \\diamondsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\clubsuit, \\spadesuit \\}\\). Poiché i due sottoinsiemi sono disgiunti, la loro unione include semplicemente tutti i loro elementi:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2}\n=\n\\{ \\Box, \\diamondsuit \\} \\cup \\{ \\clubsuit, \\spadesuit \\}\n=\n\\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\},\n\\]\ne la misura di questa unione è solo la somma delle misure dei due sottoinsiemi:\n\\[\n\\begin{align*}\n\\mu ( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} )\n&=\n\\mu ( \\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\} )\n\\\\\n&=\nm_{\\Box} + m_{\\clubsuit} + m_{\\diamondsuit} + m_{\\spadesuit}\n\\\\\n&=\n( m_{\\Box} + m_{\\diamondsuit} ) + ( m_{\\clubsuit} + m_{\\spadesuit} )\n\\\\\n&=\n\\mu( \\mathsf{x}_{1} ) + \\mu( \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nPiù in generale, per qualsiasi collezione di sottoinsiemi\n\\[\n\\mathsf{x}_{1}, \\ldots, \\mathsf{x}_{K}\n\\]\nche sono reciprocamente disgiunti,\n\\[\n\\mathsf{x}_{k} \\cap \\mathsf{x}_{k'} = \\emptyset \\quad \\text{per} \\quad k \\ne k',\n\\]\nabbiamo\n\\[\n\\mu ( \\cup_{k = 1}^{K} \\mathsf{x}_{k} )\n=\n\\sum_{k = 1}^{K} \\mu ( \\mathsf{x}_{k} ).\n\\]\nIn altre parole, se possiamo scomporre un sottoinsieme in una collezione di sottoinsiemi più piccoli e disgiunti, possiamo anche scomporre la misura allocata a quel sottoinsieme iniziale nelle misure allocate ai sottoinsiemi componenti. Questa proprietà di coerenza è chiamata additività.\nUn sottoinsieme \\(\\mathsf{x}\\) e il suo complemento \\(\\mathsf{x}^{c}\\) sono sempre disgiunti, ovvero \\(\\mathsf{x} \\cap \\mathsf{x}^{c} = \\emptyset\\). Allo stesso tempo, la loro unione copre l’intero insieme: \\(\\mathsf{x} \\cup \\mathsf{x}^{c} = X\\). Di conseguenza, l’additività implica che:\n\\[\n\\begin{align*}\nM &= \\mu (X) \\\\\n  &= \\mu ( \\mathsf{x} \\cup \\mathsf{x}^{c} ) \\\\\n  &= \\mu ( \\mathsf{x} ) + \\mu ( \\mathsf{x}^{c} ),\n\\end{align*}\n\\]\nda cui segue che:\n\\[\n\\mu ( \\mathsf{x}^{c} ) = M - \\mu ( \\mathsf{x} ).\n\\]\nIn altre parole, la misura assegnata al complemento di un sottoinsieme è la misura totale meno la misura assegnata a quel sottoinsieme. Per le distribuzioni di probabilità, questo concetto è ancora più evidente:\n\\[\n\\pi ( \\mathsf{x}^{c} ) = 1 - \\pi ( \\mathsf{x} ).\n\\]\nQuando due sottoinsiemi si sovrappongono, dobbiamo considerare che la somma delle loro misure \\(\\mu (\\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} )\\) conta due volte la misura degli elementi condivisi tra di essi. Ad esempio, se \\(\\mathsf{x}_{1} = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\Box, \\spadesuit \\}\\), allora l’unione include l’elemento sovrapposto \\(\\Box\\) solo una volta:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2} = \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\} = \\{ \\Box, \\heartsuit, \\spadesuit \\}.\n\\]\nDi conseguenza:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) &= \\mu( \\{ \\Box, \\heartsuit, \\spadesuit \\} ) \\\\\n&= m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit}.\n\\end{align*}\n\\]\nSommando le misure allocate ai due sottoinsiemi individualmente, tuttavia, otteniamo:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) &= (m_{\\Box} + m_{\\heartsuit} ) + ( m_{\\Box} + m_{\\spadesuit} ) \\\\\n&= m_{\\Box} + m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit} \\\\\n&= m_{\\Box} + \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nL’elemento che viene contato due volte è esattamente l’unico elemento nell’intersezione dei due sottoinsiemi:\n\\[\nm_{\\Box} = \\mu( \\{ \\Box \\} ) = \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nIn altre parole, possiamo scrivere:\n\\[\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) = \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) + \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nQuesta relazione vale per qualsiasi due sottoinsiemi, indipendentemente dalla loro sovrapposizione.\n\n\n\n\n\n\nFigura 22.13: Quando due sottoinsiemi si sovrappongono, la misura allocata a ciascuno conta doppio la misura allocata a qualsiasi elemento sovrapposto, qui \\(\\Box\\), ma la misura allocata alla loro unione no. Questo risulta in una relazione importante tra le misure allocate ai due sottoinsiemi, la misura allocata alla loro unione e la misura allocata alla loro intersezione.\n\n\n\nQueste proprietà dei sottoinsiemi ci permettono di costruire una misura in molti modi diversi, ciascuno dei quali può essere utile in circostanze diverse. Questa flessibilità è molto comoda quando si applica la teoria della misura e la teoria della probabilità nella pratica.\nAd esempio, possiamo specificare una misura in due modi principali:\n\nAllocazione globale: possiamo assegnare le misure a tutti gli elementi individuali contemporaneamente. Questo metodo considera l’intero insieme fin dall’inizio e assegna una misura a ciascun elemento.\n\n\n\n\n\n\n\nFigura 22.14: Le misure possono essere costruite specificando le allocazioni degli elementi individuali tutte insieme.\n\n\n\n\nAllocazione locale: possiamo assegnare la misura a ciascun elemento uno alla volta. Questo metodo permette di concentrarsi su un elemento alla volta, aggiungendo gradualmente le misure agli altri elementi.\n\n\n\n\n\n\n\nFigura 22.15: Allo stesso tempo, le misure possono essere costruite specificando le allocazioni degli elementi individuali uno alla volta.\n\n\n\nInoltre, non è sempre necessario partire dalle allocazioni individuali. Un altro metodo consiste nel:\n\nAllocazione iterativa: possiamo iniziare allocando la misura totale a sottoinsiemi disgiunti e poi affinare iterativamente questa allocazione suddividendo i sottoinsiemi in parti sempre più piccole fino a raggiungere gli elementi individuali.\n\n\n\n\n\n\n\nFigura 22.16: Le misure possono anche essere costruite allocando la misura totale a sottoinsiemi disgiunti e poi raffinando iterativamente tale allocazione a sottoinsiemi sempre più piccoli.\n\n\n\nQuesta flessibilità nelle modalità di costruzione delle misure è particolarmente utile perché permette di adattare l’approccio alle specifiche necessità del problema in questione. Ad esempio, nella pratica, potremmo trovare più semplice allocare inizialmente misure a grandi gruppi di elementi e poi suddividere questi gruppi, oppure potremmo voler assegnare le misure a ciascun elemento uno per uno a seconda delle esigenze del contesto.\nInfine, la definizione di misura sui sottoinsiemi \\(\\mu : 2^{X} \\rightarrow [0, \\infty]\\) è cruciale per estendere la teoria della misura oltre gli insiemi finiti. Questa estensione è necessaria per definire misure in modo coerente su insiemi matematicamente più complessi, come la retta reale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#riflessioni-conclusive",
    "href": "chapters/probability/02_prob_spaces.html#riflessioni-conclusive",
    "title": "22  Misura di Probabilità",
    "section": "22.7 Riflessioni Conclusive",
    "text": "22.7 Riflessioni Conclusive\nIl significato applicativo delle nozioni di misura e distribuzione di probabilità è centrale per comprendere come utilizzare questi concetti nella pratica, in particolare nella statistica bayesiana. Il punto cruciale è capire cosa rappresenta \\(M\\), la “misura totale”. Nelle applicazioni bayesiane, \\(M\\) rappresenta la nostra certezza complessiva.\nQuando si lavora con distribuzioni di probabilità, stiamo effettivamente allocando questa certezza complessiva tra diversi eventi possibili. Una distribuzione (di massa) di probabilità è quindi l’allocazione relativa della nostra certezza tra un insieme di eventi disgiunti. Ogni probabilità individuale, \\(p_n\\), rappresenta la proporzione della nostra certezza totale che assegniamo a un particolare evento.\nNella teoria bayesiana, la “misura totale” \\(M\\) è interpretata come la somma totale delle probabilità, che è sempre uguale a 1. Questo riflette il fatto che la somma delle nostre certezze relative per tutti gli eventi possibili deve essere completa: siamo completamente certi che uno degli eventi nel nostro spazio campionario si verificherà.\nQuando creiamo una distribuzione di probabilità, stiamo dividendo questa certezza totale tra i vari eventi possibili nel nostro spazio campionario. Ad esempio, se stiamo analizzando un problema con cinque possibili esiti distinti, dobbiamo allocare l’intera certezza (pari a 1) tra questi esiti. Ogni valore di probabilità \\(p_n\\) rappresenta la frazione della nostra certezza totale che attribuiamo a un particolare esito.\nLe nozioni di misura e distribuzione di probabilità trovano numerose applicazioni pratiche. Ad esempio:\n\nInferenza bayesiana: Utilizziamo distribuzioni di probabilità per rappresentare le nostre incertezze sui parametri di interesse. Dopo aver osservato i dati, aggiorniamo queste distribuzioni tramite il teorema di Bayes.\nModellizzazione probabilistica: Costruiamo modelli che descrivono il comportamento di sistemi complessi assegnando probabilità agli eventi possibili. Questo ci permette di fare previsioni e prendere decisioni informate basate sulle probabilità assegnate.\n\nIn conclusione, le nozioni di misura e distribuzione di probabilità sono strumenti potenti per allocare e manipolare la nostra certezza tra diversi eventi possibili. Comprendere questi concetti è fondamentale per comprendere le applicazioni della teoria della probabilità e della statistica bayesiana. La “misura totale” \\(M\\) rappresenta la nostra certezza complessiva, e le distribuzioni di probabilità ci permettono di distribuire questa certezza in modo coerente e informato tra gli eventi possibili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html",
    "href": "chapters/probability/03_prob_on_general_spaces.html",
    "title": "23  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "",
    "text": "23.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNel Capitolo 22 abbiamo introdotto la teoria della misura e della probabilità su insiemi con un numero finito di elementi. Tuttavia, molti degli spazi matematici che incontriamo nelle applicazioni pratiche, come gli interi e la retta reale, non hanno un numero finito di elementi, ma piuttosto un numero numerabile infinito o addirittura non numerabile infinito di elementi. Sfortunatamente, estendere la teoria della misura e della probabilità a spazi più generali come questi non è sempre semplice.\nSenza entrare nei dettagli, è stato dimostrato che la forma più generale della teoria della misura e della probabilità applicabile a qualsiasi spazio matematico è chiamata \\(\\sigma\\)-algebra. In questo capitolo, forniremo un’introduzione intuitiva ai vincoli delle \\(\\sigma\\)-algebre ed esamineremo alcune notevoli applicazioni. In particolare, introdurremo i concetti di variabile casuale, funzioni di massa di probabilità e funzioni di ripartizione.\nQuesti concetti sono fondamentali per comprendere come la probabilità e la misura possono essere utilizzate in contesti più complessi, permettendo di estendere le nostre analisi a insiemi infiniti e spazi continui, che sono comuni nelle applicazioni psicologiche.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#sigma-algebra",
    "href": "chapters/probability/03_prob_on_general_spaces.html#sigma-algebra",
    "title": "23  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "23.2 \\(\\sigma\\)-Algebra",
    "text": "23.2 \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra è una struttura matematica che permette di definire in modo coerente quali sottoinsiemi di un insieme sono “misurabili”.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "href": "chapters/probability/03_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "title": "23  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "23.3 Definizione di \\(\\sigma\\)-Algebra",
    "text": "23.3 Definizione di \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra è una collezione di sottoinsiemi di uno spazio \\(X\\) che soddisfa le seguenti proprietà:\n\nChiusura rispetto al complemento: Se un sottoinsieme \\(A\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche il suo complemento \\(A^c\\) appartiene a \\(\\mathcal{F}\\). Questo significa che se \\(\\mathcal{F}\\) contiene un certo sottoinsieme, deve contenere anche tutti gli elementi che non sono in quel sottoinsieme.\nChiusura rispetto alle unioni numerabili: Se una sequenza numerabile di sottoinsiemi \\(A_1, A_2, A_3, \\ldots\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche l’unione di tutti questi sottoinsiemi appartiene a \\(\\mathcal{F}\\). Questo implica che se \\(\\mathcal{F}\\) contiene una serie di sottoinsiemi, deve contenere anche il loro insieme unito.\nInclusione dello spazio campionario: Lo spazio campionario \\(X\\) stesso deve appartenere alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\). In altre parole, l’intero insieme \\(X\\) è considerato un sottoinsieme misurabile.\n\nLa chiusura in questo contesto significa che la collezione \\(\\mathcal{F}\\) è stabile rispetto a determinate operazioni insiemistiche. In particolare, se si applicano le operazioni di complemento o di unione numerabile a elementi della \\(\\sigma\\)-algebra, i risultati di queste operazioni rimarranno all’interno della stessa \\(\\sigma\\)-algebra. Questo garantisce che la \\(\\sigma\\)-algebra non “perda” elementi a causa di queste operazioni, mantenendo così la coerenza e la completezza della collezione di sottoinsiemi.\n\n23.3.1 Spazio Misurabile\nUn insieme dotato di una \\(\\sigma\\)-algebra, \\((X, \\mathcal{X})\\), è detto spazio misurabile. Gli elementi di una \\(\\sigma\\)-algebra sono noti come sottoinsiemi misurabili, mentre i sottoinsiemi non appartenenti alla \\(\\sigma\\)-algebra sono detti non misurabili. La distinzione tra sottoinsiemi misurabili e non misurabili è cruciale per evitare comportamenti anomali e controintuitivi nella teoria della misura e della probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#gli-assiomi-di-kolmogorov",
    "href": "chapters/probability/03_prob_on_general_spaces.html#gli-assiomi-di-kolmogorov",
    "title": "23  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "23.4 Gli Assiomi di Kolmogorov",
    "text": "23.4 Gli Assiomi di Kolmogorov\nI tre assiomi di Kolmogorov definiscono le proprietà fondamentali di una misura di probabilità e richiedono l’esistenza di una \\(\\sigma\\)-algebra.\n\nNon negatività: Per qualsiasi evento \\(A\\) nello spazio campionario \\(\\Omega\\), la probabilità di \\(A\\) è non negativa. \\[\nP(A) \\geq 0.\n\\]\nNormalizzazione: La probabilità dell’intero spazio campionario \\(\\Omega\\) è 1. \\[\nP(\\Omega) = 1.\n\\]\nAdditività numerabile: Per qualsiasi sequenza numerabile di eventi mutuamente esclusivi \\(A_1, A_2, A_3, \\ldots\\), la probabilità della loro unione è la somma delle loro probabilità. \\[\nP\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\sum_{i=1}^{\\infty} P(A_i).\n\\]\n\n\n23.4.1 Connessione tra gli Assiomi di Kolmogorov e le \\(\\sigma\\)-Algebre\nGli assiomi di Kolmogorov sono definiti rispetto a una misura di probabilità \\(P\\) su uno spazio campionario \\(\\Omega\\) e implicano l’esistenza di una \\(\\sigma\\)-algebra \\(\\mathcal{F}\\). La \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) è la collezione di eventi (sottoinsiemi di \\(\\Omega\\)) per i quali la misura di probabilità \\(P\\) è definita.\n\nNon negatività garantisce che \\(P\\) assegni un valore non negativo a ogni evento nella \\(\\sigma\\)-algebra.\nNormalizzazione garantisce che \\(P(\\Omega) = 1\\), assicurando che \\(\\Omega\\) sia un elemento della \\(\\sigma\\)-algebra.\nAdditività numerabile garantisce che la \\(\\sigma\\)-algebra sia chiusa rispetto alle unioni numerabili di insiemi disgiunti.\n\nIn sintesi, gli assiomi di Kolmogorov richiedono una \\(\\sigma\\)-algebra come struttura all’interno della quale queste proprietà valgono. La \\(\\sigma\\)-algebra è quindi la collezione di eventi per i quali la misura di probabilità è ben definita e coerente con gli assiomi di Kolmogorov.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#probabilità",
    "href": "chapters/probability/03_prob_on_general_spaces.html#probabilità",
    "title": "23  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "23.5 Probabilità",
    "text": "23.5 Probabilità\nUna volta definiti gli assiomi di Kolmogorov, è possibile introdurre la definizione di probabilità.\nLa probabilità di un evento è una misura numerica che indica la possibilità che tale evento si verifichi, in accordo con gli assiomi di Kolmogorov.\n\nSe \\(P(A) = 0\\), l’evento \\(A\\) è impossibile.\nSe \\(P(A) = 1\\), l’evento \\(A\\) è certo.\n\nPer denotare la probabilità che un evento \\(A\\) non si verifichi, si usa la notazione \\(P(A^c)\\), dove: \\[\nP(A^c) = 1 - P(A).\n\\]\n\n23.5.1 Proprietà Derivate dagli Assiomi di Kolmogorov\nAlcune proprietà importanti derivate dagli assiomi includono:\n\n\\(P(\\varnothing) = 0\\),\nSe \\(A \\subset B\\), allora \\(P(A) \\leq P(B)\\),\n\\(0 \\leq P(A) \\leq 1\\),\n\\(P(A^c) = 1 - P(A)\\),\nSe \\(A \\cap B = \\varnothing\\), allora \\(P(A \\cup B) = P(A) + P(B)\\).\n\n\n\n23.5.2 Regole di Addizione per Eventi\nPer eventi non mutuamente esclusivi, la probabilità della loro unione è data da: \\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n\\]\nUtilizzando il terzo assioma della probabilità, si ottiene: \\[\nP(A \\cup B) = P(A \\cap B^c) + P(B \\cap A^c) + P(A \\cap B).\n\\]\nQuando \\(A\\) e \\(B\\) sono mutuamente esclusivi, \\(P(A \\cap B) = 0\\), e quindi: \\[\nP(A \\cup B) = P(A) + P(B).\n\\]\nLa legge della probabilità totale permette di scrivere: \\[\nP(A) = P(A \\cap B) + P(A \\cap B^c),\n\\] e analogamente per \\(B\\): \\[\nP(B) = P(B \\cap A) + P(B \\cap A^c).\n\\]\nIn conclusione, gli assiomi di Kolmogorov forniscono la base per definire la probabilità su una \\(\\sigma\\)-algebra, garantendo che le proprietà fondamentali della probabilità siano rispettate e che la probabilità sia ben definita per una collezione coerente di sottoinsiemi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#probabilità-e-calcolo-combinatorio",
    "href": "chapters/probability/03_prob_on_general_spaces.html#probabilità-e-calcolo-combinatorio",
    "title": "23  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "23.6 Probabilità e Calcolo Combinatorio",
    "text": "23.6 Probabilità e Calcolo Combinatorio\nI problemi scolastici più comuni sulle probabilità richiedono l’uso del calcolo combinatorio. La struttura generale di questi problemi è sempre la stessa: dobbiamo contare il numero di modi in cui un evento compatibile con l’evento di “successo” definito dal problema si realizza e poi trovare la proporzione di tali eventi rispetto a tutti gli eventi possibili (inclusi quelli di “insuccesso”) che possono verificarsi nello spazio campionario. Questi problemi presentano due difficoltà principali:\n\nTrasformare la descrizione verbale del problema in una formulazione matematica chiara, suddividendo gli eventi possibili nello spazio campionario in base alle condizioni di successo e insuccesso definite dal problema.\nContare il numero di successi e il numero totale di eventi.\n\nPer risolvere questi problemi, dobbiamo utilizzare tecniche del calcolo combinatorio, come le permutazioni e le combinazioni, che ci permettono di contare in modo preciso il numero di possibilità.\nConsideriamo un esempio semplice e intuitivo per chiarire il concetto. Supponiamo di avere una scatola con 10 palline numerate da 1 a 10. Vogliamo calcolare la probabilità di estrarre una pallina con un numero pari.\n\nDefinizione degli eventi: In questo caso, l’evento di “successo” è l’estrazione di una pallina con un numero pari.\n\nEventi di successo: {2, 4, 6, 8, 10}\nEventi totali: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n\nConteggio delle possibilità:\n\nNumero di eventi di successo: 5\nNumero totale di eventi: 10\n\nCalcolo della probabilità: \\[\nP(\\text{numero pari}) = \\frac{\\text{numero di eventi di successo}}{\\text{numero totale di eventi}} = \\frac{5}{10} = 0.5.\n\\]\n\nPer problemi più complessi, come il calcolo della probabilità di ottenere una determinata combinazione di carte da un mazzo o di formare un particolare gruppo di persone da una popolazione più grande, utilizziamo strumenti del calcolo combinatorio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#il-problema-dei-fratelli-bernoulli",
    "href": "chapters/probability/03_prob_on_general_spaces.html#il-problema-dei-fratelli-bernoulli",
    "title": "23  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "23.7 Il Problema dei Fratelli Bernoulli",
    "text": "23.7 Il Problema dei Fratelli Bernoulli\nLa soluzione dei problemi di probabilità non è sempre semplice e nella storia della matematica ci sono molti esempi di celebri matematici che hanno commesso errori. Uno di questi aneddoti riguarda Jakob Bernoulli, uno dei pionieri della teoria della probabilità.\nJakob Bernoulli si interessò al calcolo delle probabilità mentre cercava di formalizzare le leggi del caso nel suo libro “Ars Conjectandi”, pubblicato postumo nel 1713. Uno dei problemi che affrontò riguardava il calcolo della probabilità di ottenere almeno una testa in 8 lanci di una moneta equa. Nonostante il suo approccio iniziale fosse corretto, Bernoulli commise un errore nel calcolo combinatorio durante il processo.\nPer risolvere il problema di calcolare la probabilità di ottenere almeno una testa in 8 lanci, bisogna considerare la probabilità complementare, ovvero la probabilità di non ottenere alcuna testa (ottenere solo croci) in 8 lanci, e poi sottrarla da 1:\n\nCalcolo della probabilità complementare: La probabilità di ottenere solo croci in un singolo lancio è \\(\\frac{1}{2}\\). La probabilità di ottenere solo croci in 8 lanci consecutivi è: \\[\n\\left(\\frac{1}{2}\\right)^8 = \\frac{1}{256}.\n\\]\nCalcolo della probabilità di ottenere almeno una testa: \\[\nP(\\text{almeno una testa}) = 1 - P(\\text{nessuna testa}) = 1 - \\frac{1}{256} = \\frac{255}{256}.\n\\]\n\nJakob Bernoulli commise un errore nel calcolo combinatorio che lo portò a una soluzione errata. Egli sottostimò la probabilità di ottenere almeno una testa, probabilmente a causa di un errore nel conteggio delle possibili combinazioni di successi e insuccessi.\nQuesto errore fu successivamente corretto da altri matematici, tra cui suo nipote Daniel Bernoulli, che dimostrarono il metodo corretto per risolvere tali problemi utilizzando il calcolo combinatorio in modo appropriato.\nLa storia del calcolo combinatorio e della probabilità è ricca di aneddoti, come quello di Jakob Bernoulli, che mettono in luce quanto i problemi di probabilità possano essere estremamente controintuitivi, persino per i grandi matematici. Oggi, grazie al lavoro e alle correzioni apportate dai matematici del passato, siamo in grado di risolvere molti di questi problemi con maggiore facilità. La teoria della probabilità, come molte altre discipline scientifiche, è il risultato di un lungo processo di sviluppo e comprensione, che ha richiesto tempo e sforzi considerevoli.\nUna delle sfide della probabilità è che spesso i problemi non si prestano a soluzioni immediate o intuitive. Tuttavia, esistono due approcci fondamentali per affrontarli. Il primo consiste nell’applicare i teoremi della teoria della probabilità, un metodo che, come abbiamo visto, può risultare controintuitivo. Il secondo approccio è quello della simulazione Monte Carlo, che consente di ottenere una soluzione approssimata, ma molto vicina al valore reale, seguendo una procedura più intuitiva. Il nome di questo metodo deriva dal famoso Casinò di Monte Carlo a Monaco, ma possiamo semplicemente riferirci ad esso come metodo di simulazione.\nLa simulazione Monte Carlo è una classe generale di metodi stocastici, in contrasto con i metodi deterministici, utilizzati per risolvere approssimativamente problemi analitici attraverso la generazione casuale delle quantità di interesse. Tra i metodi comunemente utilizzati troviamo il campionamento con reinserimento, in cui la stessa unità può essere selezionata più volte, e il campionamento senza reinserimento, in cui ogni unità può essere selezionata una sola volta. Questi strumenti offrono un potente mezzo per affrontare problemi complessi in modo pratico e accessibile.\n\nEsempio 23.1 Consideriamo il seguente esercizio che presenta un “classico” problema di calcolo delle probabilità.\n“Un’urna contiene 10 palline rosse, 10 palline blu e 20 palline verdi. Se si estraggono 5 palline a caso senza reinserimento, qual è la probabilità che venga selezionata almeno una pallina di ciascun colore?”\nLa soluzione al problema consiste nel contare il numero di modi in cui possono verificarsi gli eventi incompatibili con la condizione richiesta, dividere per il numero totale di modi in cui 5 palline possono essere estratte da un’urna con 40 palline, e sottrarre tale risultato da 1.\nIniziamo dal denominatore (“in quanti modi possono essere estratte 5 palline da un’urna che ne contiene 40”). La soluzione è data dal coefficiente binomiale: \\(\\binom{40}{5}\\).\nDobbiamo poi enumerare tutti i casi incompatibili con la condizione espressa dal problema; al numeratore avremo quindi: (modi di ottenere nessuna pallina rossa) + (modi di ottenere nessuna pallina blu) + (modi di ottenere nessuna pallina verde) - (modi di ottenere nessuna pallina rossa o blu) - (modi di ottenere nessuna pallina rossa o verde) - (modi di ottenere nessuna pallina blu o verde).\nLa soluzione è dunque:\n\\[\nP(\\text{almeno una rossa, blu e verde}) = \\frac{\n\\binom{30}{5} + \\binom{30}{5} + \\binom{20}{5} - \\binom{20}{5} - \\binom{10}{5} - \\binom{10}{5}\n}{\\binom{40}{5}}.\n\\]\nSvolgiamo i calcoli usando Python.\n\n# Funzione per calcolare il coefficiente binomiale\nchoose &lt;- function(n, k) {\n  factorial(n) / (factorial(k) * factorial(n - k))\n}\n\n# Calcoli\nno_red &lt;- choose(30, 5)\nno_blue &lt;- choose(30, 5)\nno_green &lt;- choose(20, 5)\n\n# Modi per estrarre 5 palline senza ottenere due colori specifici\nno_red_blue &lt;- choose(20, 5)\nno_red_green &lt;- choose(10, 5)\nno_blue_green &lt;- choose(10, 5)\n\n# Modi totali per estrarre 5 palline in generale\ntotal_ways &lt;- choose(40, 5)\n\n# Probabilità di estrarre almeno 1 pallina di ciascun colore\nprob_real &lt;- 1 - (no_red + no_blue + no_green - no_red_blue - no_red_green - no_blue_green) / total_ways\nprob_real\n#&gt; [1] 0.5676223\n\nLo stesso risultato si ottiene con una simulazione.\n\nset.seed(12345)\n\n# Creare un'urna con le palline\nurn &lt;- c(rep(\"red\", 10), rep(\"blue\", 10), rep(\"green\", 20))\n\n# Numero di simulazioni\nsimulations &lt;- 100000\n\ncount &lt;- 0\nfor (i in 1:simulations) {\n  # Estrarre 5 palline dall'urna\n  draw &lt;- sample(urn, 5, replace = FALSE)\n  \n  # Verificare se c'è almeno una pallina di ogni colore (red, blue, green)\n  if (\"red\" %in% draw && \"blue\" %in% draw && \"green\" %in% draw) {\n    count &lt;- count + 1\n  }\n}\n\n# Calcolare la probabilità simulata\nprob_simulated &lt;- count / simulations\nprob_simulated\n#&gt; [1] 0.56813\n\n\nIl metodo di simulazione consente di risolvere problemi che implicano il calcolo delle probabilità relative a vari eventi generati dal lancio dei dadi.\n\nEsempio 23.2 Nel caso del lancio di un dado, è facile calcolare la probabilità di ottenere un 1 o un 5. Questa probabilità è \\(\\frac{2}{6}\\). Tuttavia, quando lanciamo due dadi, la situazione si complica perché ci interessa ottenere almeno un 1 o un 5, e c’è la possibilità di ottenere entrambi. Invece di calcolare direttamente questa probabilità, possiamo considerare la probabilità di non ottenere né un 1 né un 5 e sottrarla da 1. Con 2 dadi, la probabilità di non ottenere né un 1 né un 5 è \\(\\frac{4}{6}\\) o \\(\\frac{2}{3}\\) per ogni dado. Per calcolare la probabilità congiunta, possiamo moltiplicare la probabilità per ciascun dado: \\(1 - (\\frac{2}{3} \\times \\frac{2}{3}) = 0.555\\). Questo significa che c’è il 55% di probabilità di ottenere almeno un 1 o un 5 quando si lanciano 2 dadi.\nInvece di calcolare matematicamente la probabilità di ottenere almeno un 1 o un 5, possiamo utilizzare il metodo Monte Carlo, simulando un grande numero di lanci di dadi e ottenendo la risposta attraverso un approccio di forza bruta. Ecco il procedimento generale:\n\nLancia 2 dadi per 100.000 volte (o per il numero di volte che preferisci).\nConta quante volte appare almeno un 1 o un 5 in ciascun lancio.\nDividi questo conteggio per 100.000. Questa sarà la probabilità.\n\n\nset.seed(12345) # Imposta il seme per la riproducibilità\n\n# Numero di simulazioni\nsimulations &lt;- 100000\nsuccess_count &lt;- 0\n\n# Simulazione dei lanci\nfor (i in 1:simulations) {\n  # Lancia due dadi\n  dice_rolls &lt;- sample(1:6, 2, replace = TRUE)\n  \n  # Verifica se c'è almeno un 1 o un 5\n  if (1 %in% dice_rolls || 5 %in% dice_rolls) {\n    success_count &lt;- success_count + 1\n  }\n}\n\n# Calcola la probabilità simulata\nprobability &lt;- success_count / simulations\ncat(sprintf(\"La probabilità di ottenere almeno un 1 o un 5 è: %.3f\\n\", probability))\n#&gt; La probabilità di ottenere almeno un 1 o un 5 è: 0.557\n\n\nUsiamo un ciclo for per simulare i lanci. In ogni iterazione, generiamo due numeri casuali tra 1 e 6, che rappresentano i risultati dei due dadi.\nControlliamo se in ciascun lancio appare almeno un 1 o un 5. Se è così, incrementiamo il contatore success_count.\nAlla fine, la probabilità viene calcolata dividendo success_count per il numero totale di simulazioni, e poi stampiamo il risultato.\n\nQuesto approccio, basato sulla simulazione, permette di ottenere un’ottima approssimazione della probabilità in modo intuitivo, senza dover ricorrere a calcoli matematici complessi.\nÈ facile cambiare la simulazione per consdierare il caso di un numero maggiore di dadi. Per esempio, per il caso del lancio di tre dadi, basta modificare il codice in modo che vengano lanciati tre dadi invece di due. Questo si ottiene cambiando range(2) in range(3) nel ciclo che genera i lanci dei dadi. Questa modifica consente di calcolare la probabilità di ottenere almeno un 1 o un 5 con tre dadi, utilizzando lo stesso approccio basato sulla simulazione.\nQuesto approccio basato sulla simulazione è anche al centro della statistica bayesiana moderna. Poiché il calcolo degli integrali complessi necessari per determinare le distribuzioni posteriori è estremamente difficile, possiamo impiegare processi di Markov Chain Monte Carlo (MCMC) per esplorare lo spazio plausibile della distribuzione posteriore, fino a raggiungere una convergenza su un valore stabile.\n\n\nEsempio 23.3 Il problema dei compleanni, generalmente attribuito a Richard von Mises, è un noto esempio controintuitivo di calcolo delle probabilità che utilizza il calcolo combinatorio, in particolare le permutazioni. Il problema chiede quanti individui sono necessari affinché la probabilità che almeno due persone abbiano lo stesso compleanno superi il 50%, assumendo che ogni giorno dell’anno sia ugualmente probabile come compleanno. Sorprendentemente, la risposta è solo 23 persone, molto meno di quanto la maggior parte delle persone immagina.\nPer risolvere il problema dei compleanni utilizzando le permutazioni, consideriamo la seguente relazione:\n\\[\n\\begin{align*}\nP(\\text{almeno due persone hanno lo stesso compleanno}) &= \\\\\n1 - P(\\text{nessuno ha lo stesso compleanno}).\n\\end{align*}\n\\]\nQuesta uguaglianza è valida perché l’evento “nessuno ha lo stesso compleanno” è il complemento dell’evento “almeno due persone hanno lo stesso compleanno”. Pertanto, dobbiamo calcolare la probabilità che nessuno abbia lo stesso compleanno.\nSia \\(k\\) il numero di persone. Per calcolare la probabilità che nessuno abbia lo stesso compleanno, dobbiamo contare il numero di modi in cui \\(k\\) persone possono avere compleanni diversi. Poiché ogni compleanno è ugualmente probabile, possiamo usare le permutazioni per contare il numero di modi in cui \\(k\\) compleanni unici possono essere disposti su 365 giorni:\n\\[\n365P_k = \\frac{365!}{(365 - k)!}.\n\\]\nDividiamo questo numero per il numero totale di elementi nello spazio campionario, che è il numero totale di modi in cui \\(k\\) compleanni possono essere disposti su 365 giorni:\n\\[\n365^k.\n\\]\nQuindi, la probabilità che nessuno abbia lo stesso compleanno è:\n\\[\nP(\\text{nessuno ha lo stesso compleanno}) = \\frac{365P_k}{365^k} = \\frac{365!}{365^k (365 - k)!}.\n\\]\nUsando questa formula, la probabilità che almeno due persone abbiano lo stesso compleanno è:\n\\[\nP(\\text{almeno due persone hanno lo stesso compleanno}) = 1 - \\frac{365!}{365^k (365 - k)!}.\n\\]\nIn sintesi, calcolando questa probabilità, si scopre che bastano solo 23 persone affinché la probabilità che almeno due di loro abbiano lo stesso compleanno superi il 50%, un risultato sorprendente rispetto all’intuizione comune.\n\n# Funzione per calcolare la probabilità\nbirthday &lt;- function(k) {\n  logdenom &lt;- k * log(365) + lgamma(365 - k + 1) # log denominatore\n  lognumer &lt;- lgamma(366) # log numeratore\n  pr &lt;- 1 - exp(lognumer - logdenom) # trasformazione inversa\n  return(pr)\n}\n\n# Calcola la probabilità per k persone\nk &lt;- 1:50\nbday &lt;- sapply(k, birthday)\n\n# Plot dei risultati\nggplot(data.frame(k = k, bday = bday), aes(x = k, y = bday)) +\n  geom_line(marker = \"o\", alpha = 0.5) +\n  geom_point(alpha = 0.5) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"gray\") +\n  labs(\n    x = \"Numero di persone\",\n    y = \"Probabilità che almeno due persone\\nabbiano lo stesso compleanno\",\n    title = \"Probabilità del Problema dei Compleanni\"\n  ) +\n  xlim(0, 50) +\n  ylim(0, 1)\n#&gt; Warning in geom_line(marker = \"o\", alpha = 0.5): Ignoring unknown\n#&gt; parameters: `marker`\n\n# Probabilità per 20-25 persone\nbday[20:25]\n#&gt; [1] 0.4114384 0.4436883 0.4756953 0.5072972 0.5383443 0.5686997\n\n\n\n\n\n\n\n\nOsserviamo che quando il numero di persone è 23, la probabilità che almeno due persone abbiano lo stesso compleanno supera 0.5. Quando il numero di persone è più di 50, questa probabilità è quasi 1.\n\n\nEsempio 23.4 In precedenza, abbiamo derivato la soluzione analitica esatta per il problema dei compleanni, ma possiamo ottenere una soluzione approssimata in modo più intuitivo utilizzando il metodo della simulazione Monte Carlo.\nPer affrontare il problema dei compleanni, campioniamo \\(k\\) compleanni, che potrebbero non essere unici, tra i 365 giorni dell’anno e verifichiamo se i \\(k\\) compleanni campionati sono tutti diversi. Utilizziamo il campionamento con reinserimento, poiché ogni giorno dei 365 ha la stessa probabilità di essere scelto, indipendentemente dai giorni estratti in precedenza. In altre parole, il fatto che una persona sia nata in un determinato giorno dell’anno non esclude che qualcun altro possa essere nato nello stesso giorno.\nDopo aver ripetuto questa procedura di campionamento molte volte, calcoliamo la frazione di simulazioni in cui almeno due compleanni coincidono. Questa frazione serve come stima della probabilità cercata. Questa procedura di simulazione è intuitiva perché riproduce il processo di generazione dei dati descritto nel problema dei compleanni.\nPer implementare il campionamento con o senza reinserimento in Python, utilizziamo la funzione numpy.random.choice. Nel caso del campionamento con reinserimento, impostiamo l’argomento replace su True. Il campionamento senza reinserimento significa che, una volta campionato un elemento, questo non sarà disponibile per estrazioni successive.\n\nset.seed(12345) # Imposta il seme per la riproducibilità\n\nk &lt;- 23  # Numero di persone\nsims &lt;- 1000  # Numero di simulazioni\nevent &lt;- 0  # Contatore eventi\n\n# Simulazioni per stimare la probabilità\nfor (i in 1:sims) {\n  days &lt;- sample(1:365, k, replace = TRUE)\n  unique_days &lt;- unique(days)\n  if (length(unique_days) &lt; k) {\n    event &lt;- event + 1\n  }\n}\n\n# Frazione di prove in cui almeno due compleanni sono uguali\nanswer &lt;- event / sims\ncat(sprintf(\"Stima della probabilità: %.6f\\n\", answer))\n#&gt; Stima della probabilità: 0.526000\n\n# Aumentare il numero di simulazioni a un milione per maggiore accuratezza\nsims_large &lt;- 1000000\nevent_large &lt;- 0\n\nfor (i in 1:sims_large) {\n  days &lt;- sample(1:365, k, replace = TRUE)\n  unique_days &lt;- unique(days)\n  if (length(unique_days) &lt; k) {\n    event_large &lt;- event_large + 1\n  }\n}\n\nanswer_large &lt;- event_large / sims_large\ncat(sprintf(\"Stima con un milione di simulazioni: %.6f\\n\", answer_large))\n#&gt; Stima con un milione di simulazioni: 0.506565\n\nNel codice sopra, abbiamo impostato il numero di simulazioni a un milione. Osserviamo che quando il numero di persone è 23, la probabilità che almeno due persone abbiano lo stesso compleanno è superiore a 0.5. Quando il numero di persone supera 50, questa probabilità è vicina a 1.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#le-assunzioni-nella-soluzione-dei-problemi",
    "href": "chapters/probability/03_prob_on_general_spaces.html#le-assunzioni-nella-soluzione-dei-problemi",
    "title": "23  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "23.8 Le Assunzioni nella Soluzione dei Problemi",
    "text": "23.8 Le Assunzioni nella Soluzione dei Problemi\nNella realtà, i compleanni non seguono una distribuzione uniforme. Una soluzione migliore al problema dei compleanni sarebbe quella di estrarre i compleanni dalla distribuzione effettiva piuttosto che da una distribuzione uniforme in cui ogni giorno ha la stessa probabilità. Non esiste un metodo matematico standard per calcolare questa probabilità; l’unico modo per farlo è attraverso la simulazione.\nNegli Stati Uniti, il CDC e la Social Security Administration monitorano il numero di nascite giornaliere. Nel 2016, FiveThirtyEight ha pubblicato un articolo sulle frequenze giornaliere di nascita e ha reso disponibili i dati in un file CSV su GitHub. Utilizzando il codice fornito da Andrew Heiss, possiamo caricare quei dati e calcolare le probabilità giornaliere dei compleanni negli Stati Uniti.\n\n# Leggi i dati\nbirths_1994_1999 &lt;- read_csv(\n  \"https://raw.githubusercontent.com/fivethirtyeight/data/master/births/US_births_1994-2003_CDC_NCHS.csv\"\n) %&gt;%\n  filter(year &lt; 2000)\n#&gt; Rows: 3652 Columns: 5\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (5): year, month, date_of_month, day_of_week, births\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbirths_2000_2014 &lt;- read_csv(\n  \"https://raw.githubusercontent.com/fivethirtyeight/data/master/births/US_births_2000-2014_SSA.csv\"\n)\n#&gt; Rows: 5479 Columns: 5\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (5): year, month, date_of_month, day_of_week, births\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Unisci i dataset\nbirths_combined &lt;- bind_rows(births_1994_1999, births_2000_2014)\n\n# Crea la colonna 'full_date' con un anno fittizio 2024 per mantenere la corretta relazione giorno/mese\nbirths_combined &lt;- births_combined %&gt;%\n  mutate(\n    full_date = make_date(2024, month, date_of_month),\n    day_of_year = yday(full_date),\n    month_categorical = month.name[month]\n  )\n\n# Calcola la media delle nascite per ciascun giorno del mese per ogni mese\navg_births_month_day &lt;- births_combined %&gt;%\n  group_by(month_categorical, date_of_month) %&gt;%\n  summarise(avg_births = mean(births, na.rm = TRUE)) %&gt;%\n  ungroup()\n#&gt; `summarise()` has grouped output by 'month_categorical'. You can override\n#&gt; using the `.groups` argument.\n\n# Correggi l'ordine dei mesi per l'asse Y\navg_births_month_day &lt;- avg_births_month_day %&gt;%\n  mutate(month_categorical = factor(month_categorical, levels = month.name))\n\n# Crea una matrice per la heatmap\navg_births_pivot &lt;- dcast(\n  avg_births_month_day,\n  month_categorical ~ date_of_month,\n  value.var = \"avg_births\"\n)\n\nggplot(avg_births_month_day, aes(x = date_of_month, y = month_categorical, fill = avg_births)) +\n  geom_tile() +\n  scale_fill_distiller(palette = \"Spectral\", name = \"Average births\") +\n  labs(\n    title = \"Average births per day\",\n    subtitle = \"1994–2014\",\n    x = \"\",\n    y = \"\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.y = element_text(angle = 0, hjust = 1))\n\n\n\n\n\n\n\n\nSi noti che i dati rivelano alcuni pattern evidenti:\n\nNessuno sembra voler avere figli durante le festività di Natale o Capodanno. Il giorno di Natale, la vigilia di Natale e il giorno di Capodanno presentano il numero medio di nascite più basso.\nAnche la vigilia di Capodanno, Halloween, il 4 luglio, il 1° aprile e l’intera settimana del Ringraziamento mostrano medie particolarmente basse.\nIl 13 di ogni mese registra leggermente meno nascite rispetto alla media—la colonna relativa al giorno 13 è particolarmente evidente in questo contesto.\nI giorni con il numero medio di nascite più alto si trovano a metà settembre, dal 9 al 20, ad eccezione dell’11 settembre.\n\nImmagino che in Italia i pattern siano, almeno in parte, diversi.\nNon è l’obiettivo qui riformulare la soluzione del problema dei compleanni utilizzando la distribuzione effettiva delle nascite piuttosto che quella uniforme, ma piuttosto sottolineare che le procedure di risoluzione dei problemi si basano su assunzioni—nel caso del problema dei compleanni, l’assunzione che la distribuzione dei compleanni sia uniforme, quando in realtà non lo è. Le soluzioni che otteniamo nei problemi probabilistici descrivono le regolarità osservabili nel mondo empirico tanto meglio quanto più sono ragionevoli le assunzioni formulate.\nIn tutti i modelli probabilistici (e quindi, in tutti i modelli scientifici, dato che esistono solo modelli probabilistici) è fondamentale prestare particolare attenzione alla plausibilità delle assunzioni su cui tali modelli si basano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/03_prob_on_general_spaces.html#commenti-e-considerazioni-finali",
    "title": "23  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "23.9 Commenti e considerazioni finali",
    "text": "23.9 Commenti e considerazioni finali\nLa teoria delle probabilità è un pilastro fondamentale della statistica, con applicazioni pratiche in numerosi campi, tra cui la psicologia. Comprendere le probabilità ci consente di prendere decisioni informate in situazioni di incertezza e di formulare previsioni affidabili. Una solida conoscenza delle basi della probabilità ci permette di affrontare una vasta gamma di problemi e di fare scelte ponderate basate sulla probabilità dei vari esiti possibili. Tuttavia, è importante ricordare che i modelli probabilistici sono solo approssimazioni della realtà e possono essere influenzati da semplificazioni o dalle limitazioni dei dati disponibili. Pertanto, è fondamentale interpretare i risultati con cautela e avere piena consapevolezza delle assunzioni che sottendono le analisi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#esercizi",
    "href": "chapters/probability/03_prob_on_general_spaces.html#esercizi",
    "title": "23  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "23.10 Esercizi",
    "text": "23.10 Esercizi\n\nEsercizio 23.1 Supponiamo di dover formare una commissione di 5 psicologi su un gruppo di 20 persone (10 psicologi clinici e 10 psicologi del lavoro). Qual è la probabilità che almeno 2 psicologi clinici siano nella commissione? Risolvi il problema usando una simulazione Monte Carlo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/03_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "title": "23  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4    MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6       xfun_0.49          htmlwidgets_1.6.4 \n#&gt;  [4] rstatix_0.7.2      lattice_0.22-6     tzdb_0.4.0        \n#&gt;  [7] vctrs_0.6.5        tools_4.4.2        generics_0.1.3    \n#&gt; [10] curl_6.0.1         parallel_4.4.2     fansi_1.0.6       \n#&gt; [13] pacman_0.5.1       pkgconfig_2.0.3    RColorBrewer_1.1-3\n#&gt; [16] lifecycle_1.0.4    compiler_4.4.2     farver_2.1.2      \n#&gt; [19] munsell_0.5.1      mnormt_2.1.1       carData_3.0-5     \n#&gt; [22] httpuv_1.6.15      htmltools_0.5.8.1  yaml_2.3.10       \n#&gt; [25] Formula_1.2-5      crayon_1.5.3       car_3.1-3         \n#&gt; [28] pillar_1.9.0       later_1.4.0        abind_1.4-8       \n#&gt; [31] nlme_3.1-166       mime_0.12          tidyselect_1.2.1  \n#&gt; [34] digest_0.6.37      stringi_1.8.4      labeling_0.4.3    \n#&gt; [37] rprojroot_2.0.4    fastmap_1.2.0      grid_4.4.2        \n#&gt; [40] colorspace_2.1-1   cli_3.6.3          magrittr_2.0.3    \n#&gt; [43] utf8_1.2.4         broom_1.0.7        withr_3.0.2       \n#&gt; [46] backports_1.5.0    promises_1.3.1     bit64_4.5.2       \n#&gt; [49] timechange_0.3.0   rmarkdown_2.29     bit_4.5.0         \n#&gt; [52] ggsignif_0.6.4     hms_1.1.3          shiny_1.9.1       \n#&gt; [55] evaluate_1.0.1     miniUI_0.1.1.1     rlang_1.1.4       \n#&gt; [58] Rcpp_1.0.13-1      xtable_1.8-4       glue_1.8.0        \n#&gt; [61] vroom_1.6.5        jsonlite_1.8.9     plyr_1.8.9        \n#&gt; [64] R6_2.5.1",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html",
    "href": "chapters/probability/04_conditional_prob.html",
    "title": "24  Probabilità condizionata",
    "section": "",
    "text": "24.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nIn questo capitolo esploreremo alcuni concetti chiave per una comprensione approfondita dell’aggiornamento bayesiano:\nQuesti concetti sono fondamentali per navigare nel processo di inferenza bayesiana e per comprendere come le probabilità si aggiornano in risposta a nuove informazioni. Inoltre, esamineremo i principali teoremi legati alla probabilità condizionata.\nPreparazione del Notebook\nLa probabilità è un linguaggio che ci consente di esprimere il nostro grado di credenza o incertezza riguardo all’occorrenza di eventi futuri. Questo concetto è strettamente legato all’idea di probabilità condizionata, che è fondamentale nella teoria della probabilità.\nLa probabilità condizionata si riferisce al calcolo della probabilità di un evento, tenendo conto che un altro evento si è già verificato. Questo concetto è cruciale perché riflette come aggiorniamo le nostre credenze alla luce di nuove evidenze o informazioni. Per esempio, immaginiamo di voler stimare la probabilità di pioggia per domani. La nostra stima iniziale cambia se oggi osserviamo un cielo nuvoloso. Il fatto che oggi sia nuvoloso “condiziona” la nostra valutazione della probabilità di pioggia per domani.\nQuesto processo di aggiornamento delle nostre credenze in base a nuove osservazioni è continuo. Una nuova evidenza coerente con una credenza esistente potrebbe rafforzarla, mentre un’osservazione inaspettata potrebbe metterla in discussione. La probabilità condizionata non è solo un concetto teorico, ma ha applicazioni pratiche sia nella vita quotidiana che in ambito scientifico. In realtà, si potrebbe argomentare che tutte le probabilità sono in qualche modo condizionate da un certo contesto o da informazioni preesistenti, anche se non sempre lo specifichiamo esplicitamente.\nIn sintesi, la probabilità condizionata ci fornisce un framework per comprendere e quantificare come le nostre credenze dovrebbero evolversi man mano che acquisiamo nuove informazioni, rendendo il concetto di probabilità uno strumento dinamico e potente per gestire l’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "title": "24  Probabilità condizionata",
    "section": "24.2 Indipendenza Stocastica",
    "text": "24.2 Indipendenza Stocastica\nNel contesto della probabilità condizionata, il concetto di indipendenza gioca un ruolo fondamentale. Questa caratteristica permette di semplificare notevolmente il calcolo delle probabilità in molti problemi, evidenziando come la conoscenza di un evento non fornisca alcuna informazione aggiuntiva sull’altro.\n\n24.2.1 Indipendenza di Due Eventi\nDue eventi \\(A\\) e \\(B\\) sono detti indipendenti se il verificarsi di uno non influenza la probabilità di verificarsi dell’altro. Formalmente, questa condizione è espressa come:\n\\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B),\\]\ndove \\(\\mathbb{P}(A \\cap B)\\) rappresenta la probabilità che entrambi gli eventi \\(A\\) e \\(B\\) si verifichino simultaneamente.\nSe questa condizione è soddisfatta, scriviamo \\(A \\text{ ⫫ } B\\), il che significa “A è indipendente da B”.\n\n\n24.2.2 Indipendenza di un Insieme di Eventi\nL’indipendenza stocastica è un concetto fondamentale nell’applicazione della probabilità in campo statistico. Un insieme di eventi \\(\\{ A_i : i \\in I \\}\\) è detto indipendente se per ogni sottoinsieme finito \\(J\\) di \\(I\\), la probabilità dell’intersezione degli eventi nel sottoinsieme \\(J\\) è uguale al prodotto delle loro singole probabilità. Formalmente:\n\\[\\mathbb{P} \\left( \\cap_{i \\in J} A_i \\right) = \\prod_{i \\in J} \\mathbb{P}(A_i).\\]\nQuesto significa che ogni combinazione finita di eventi nell’insieme è indipendente.\nL’indipendenza può essere assunta o derivata a seconda del contesto. In alcuni modelli o situazioni, assumiamo che certi eventi siano indipendenti perché questa assunzione semplifica i calcoli o riflette una conoscenza previa. In altri casi, l’indipendenza può essere derivata dai dati o da altre proprietà del modello.\n\n\n24.2.3 Eventi Disgiunti e Indipendenza\nEventi disgiunti (o mutuamente esclusivi) sono quelli che non possono verificarsi simultaneamente, cioè \\(\\mathbb{P}(A \\cap B) = 0\\). Se due eventi disgiunti hanno una probabilità positiva di verificarsi, allora non possono essere indipendenti. Questo perché per eventi disgiunti con \\(\\mathbb{P}(A) &gt; 0\\) e \\(\\mathbb{P}(B) &gt; 0\\), l’equazione di indipendenza \\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B)\\) non può essere soddisfatta, dato che \\(\\mathbb{P}(A \\cap B) = 0\\) e \\(\\mathbb{P}(A) \\mathbb{P}(B) &gt; 0\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#sec-v",
    "href": "chapters/probability/04_conditional_prob.html#sec-v",
    "title": "24  Probabilità condizionata",
    "section": "24.3 Probabilità condizionata su altri eventi",
    "text": "24.3 Probabilità condizionata su altri eventi\nLa probabilità di un evento è intrinsecamente condizionata dal nostro stato di informazione. In presenza di un determinato insieme di informazioni, attribuiamo a un evento una probabilità specifica di occorrenza. Tuttavia, qualora il nostro stato informativo subisca una modifica, anche la probabilità associata all’evento verrà corrispondentemente aggiornata.\nIn realtà, tutte le probabilità possono essere intese come probabilità condizionate, anche quando la variabile o l’evento condizionante non è esplicitamente specificato. Ciò implica che le probabilità sono sempre contestualizzate e dipendono dal set informativo disponibile in un dato scenario.\nQuesto quadro concettuale ci induce a considerare le probabilità come una ‘misura di plausibilità’ che riflette la nostra conoscenza corrente del sistema o del fenomeno sotto indagine. A seguito dell’acquisizione di nuove informazioni o di cambiamenti nel contesto, la nostra misura di plausibilità, e quindi la probabilità attribuita agli eventi, può essere rivista.\n\nTeorema 24.1 Siano \\(A\\) e \\(B\\) due eventi definiti su uno spazio campionario \\(S\\). Supponendo che l’evento \\(B\\) si verifichi, la probabilità condizionata di \\(A\\) dato \\(B\\) è data da\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{per}\\, P(B) &gt; 0,\n\\tag{24.1}\\]\ndove \\(P(A \\cap B)\\) rappresenta la probabilità congiunta dei due eventi, ovvero la probabilità che entrambi si verifichino.\n\nNell’Equazione 24.1, \\(P(A \\cap B)\\) è la probabilità congiunta che entrambi gli eventi si verifichino, mentre \\(P(B)\\) è la probabilità marginale dell’evento \\(B\\). Riorganizzando i termini, otteniamo la regola della moltiplicazione:\n\\[\nP(A \\cap B) = P(A \\mid B)P(B) = P(B \\mid A)P(A).\n\\]\nUtilizzando questa regola, possiamo derivare una forma alternativa della legge della probabilità totale:\n\\[\nP(A) = P(A \\mid B)P(B) + P(A \\mid B^c)P(B^c).\n\\]\nDove \\(B^c\\) rappresenta il complemento dell’evento \\(B\\).\nÈ importante notare che \\(P(A \\mid B)\\) non è definita se \\(P(B) = 0\\).\nLa probabilità condizionata può essere interpretata come una ricalibrazione dello spazio campionario da \\(S\\) a \\(B\\). Per spazi campionari discreti, la probabilità condizionata è espressa come\n\\[\nP(A \\mid B) = \\frac{| A \\cap B |}{| B |}.\n\\]\n\nEsempio 24.1 Lanciamo due dadi equilibrati e vogliamo calcolare la probabilità che la somma dei punteggi ottenuti sia minore di 8.\nInizialmente, quando non abbiamo ulteriori informazioni, possiamo calcolare la probabilità in modo tradizionale. Ci sono 21 risultati possibili con somma minore di 8. Poiché ci sono 36 possibili combinazioni di lancio dei due dadi, la probabilità di ottenere una somma minore di 8 è 21/36, che equivale a circa 0.58.\nSupponiamo ora di sapere che la somma del lancio di due dadi ha prodotto un risultato dispari. In questo caso, ci sono solo 18 possibili combinazioni di lancio dei due dadi (dato che abbiamo escluso i risultati pari). Tra essi, vi sono 12 risultati che soddisfano la condizione per cui la somma è minore di 8. Quindi, la probabilità di ottenere una somma minore di 8 cambia da circa 0.58 a 12/18, ovvero 0.67 quando consideriamo l’informazione aggiuntiva del risultato dispari.\nSvolgiamo il problema in Python.\n\nr &lt;- 1:6\nsample &lt;- expand.grid(i = r, j = r)\nsample\n#&gt;    i j\n#&gt; 1  1 1\n#&gt; 2  2 1\n#&gt; 3  3 1\n#&gt; 4  4 1\n#&gt; 5  5 1\n#&gt; 6  6 1\n#&gt; 7  1 2\n#&gt; 8  2 2\n#&gt; 9  3 2\n#&gt; 10 4 2\n#&gt; 11 5 2\n#&gt; 12 6 2\n#&gt; 13 1 3\n#&gt; 14 2 3\n#&gt; 15 3 3\n#&gt; 16 4 3\n#&gt; 17 5 3\n#&gt; 18 6 3\n#&gt; 19 1 4\n#&gt; 20 2 4\n#&gt; 21 3 4\n#&gt; 22 4 4\n#&gt; 23 5 4\n#&gt; 24 6 4\n#&gt; 25 1 5\n#&gt; 26 2 5\n#&gt; 27 3 5\n#&gt; 28 4 5\n#&gt; 29 5 5\n#&gt; 30 6 5\n#&gt; 31 1 6\n#&gt; 32 2 6\n#&gt; 33 3 6\n#&gt; 34 4 6\n#&gt; 35 5 6\n#&gt; 36 6 6\n\n\nevent &lt;- subset(sample, i + j &lt; 8)\ncat(nrow(event), \"/\", nrow(sample), \"\\n\")\n#&gt; 21 / 36\n\n\nsample_odd &lt;- subset(sample, (i + j) %% 2 != 0)\nsample_odd\n#&gt;    i j\n#&gt; 2  2 1\n#&gt; 4  4 1\n#&gt; 6  6 1\n#&gt; 7  1 2\n#&gt; 9  3 2\n#&gt; 11 5 2\n#&gt; 14 2 3\n#&gt; 16 4 3\n#&gt; 18 6 3\n#&gt; 19 1 4\n#&gt; 21 3 4\n#&gt; 23 5 4\n#&gt; 26 2 5\n#&gt; 28 4 5\n#&gt; 30 6 5\n#&gt; 31 1 6\n#&gt; 33 3 6\n#&gt; 35 5 6\n\n\nevent &lt;- subset(sample_odd, i + j &lt; 8)\ncat(nrow(event), \"/\", nrow(sample_odd), \"\\n\")\n#&gt; 12 / 18\n\nSe applichiamo l’Equazione 24.1, abbiamo: \\(P(A \\cap B)\\) = 12/36, \\(P(B)\\) = 18/36 e\n\\[\nP(A \\mid B) = \\frac{12}{18}.\n\\]\nQuesto esempio illustra come la probabilità di un evento possa variare in base alle informazioni aggiuntive di cui disponiamo. Nel secondo caso, avendo l’informazione che la somma è dispari, la probabilità di ottenere una somma minore di 8 aumenta notevolmente rispetto al caso iniziale in cui non avevamo questa informazione.\n\n\nEsempio 24.2 Consideriamo uno screening per la diagnosi precoce del tumore mammario utilizzando un test con determinate caratteristiche:\n\nSensibilità del test: 90%. Questo significa che il test classifica correttamente come positivo il 90% delle donne colpite dal cancro al seno.\nSpecificità del test: 90%. Ciò indica che il test classifica correttamente come negativo il 90% delle donne che non hanno il cancro al seno.\nPrevalenza del cancro al seno nella popolazione sottoposta allo screening: 1% (0.01). Questo è il 1% delle donne che ha effettivamente il cancro al seno, mentre il restante 99% (0.99) non ne è affetto.\n\nOra cerchiamo di rispondere alle seguenti domande:\n\nQual è la probabilità che una donna scelta a caso ottenga una mammografia positiva? Poiché il 1% delle donne ha il cancro al seno, la probabilità di ottenere una mammografia positiva (test positivo) è pari alla sensibilità del test, ovvero 0.90 (cioè 90%).\nSe la mammografia è positiva, qual è la probabilità che vi sia effettivamente un tumore al seno?\n\nPer risolvere questo problema, consideriamo un campione di 1000 donne sottoposte al test di screening per il tumore al seno. Di queste 1000 donne:\n\n10 donne (1% del campione) hanno effettivamente il cancro al seno. Per queste 10 donne con il cancro, il test darà un risultato positivo (vera positività) in 9 casi (90%).\nPer le restanti 990 donne (99% del campione) che non hanno il cancro al seno, il test darà un risultato positivo (falsa positività) in 99 casi (10%).\n\nQuesta situazione può essere rappresentata graficamente nel seguente modo:\n\n\n\n\n\n\nFigura 24.1: Esiti della mammografia per 1000 donne.\n\n\n\nCombinando i due risultati precedenti, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non lo hanno, per un totale di 108 risultati positivi su 1000. Pertanto, la probabilità di ottenere un risultato positivo al test è \\(\\frac{108}{1000}\\) = 0.108.\nTuttavia, tra le 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno effettivamente il cancro al seno. Quindi, la probabilità di avere il cancro al seno, dato un risultato positivo al test, è pari a \\(\\frac{9}{108}\\) = 0.083, corrispondente all’8.3%.\nIn questo esempio, la probabilità dell’evento “ottenere un risultato positivo al test” è una probabilità non condizionata, poiché calcoliamo semplicemente la proporzione di risultati positivi nel campione totale. D’altra parte, la probabilità dell’evento “avere il cancro al seno, dato che il test ha prodotto un risultato positivo” è una probabilità condizionata, poiché calcoliamo la proporzione delle donne con il cancro al seno tra quelle che hanno ottenuto un risultato positivo al test.\nQuesto esempio illustra come la conoscenza di ulteriori informazioni (il risultato positivo al test) può influenzare la probabilità di un evento (avere il cancro al seno), mostrando chiaramente la differenza tra probabilità condizionate e non condizionate.\n\n\nEsempio 24.3 Il problema di Monty Hall è diventato famoso grazie alla rubrica tenuta da Marilyn vos Savant nella rivista Parade, che rispose alla seguente lettera, pubblicata il 9 settembre 1990:\n\n“Supponiamo che tu sia in un quiz televisivo, e ti venga data la scelta tra tre porte. Dietro una delle porte c’è un’auto, dietro le altre due ci sono delle capre. Tu scegli una porta, diciamo la numero 1, e il conduttore, che sa cosa c’è dietro ogni porta, apre un’altra porta, diciamo la numero 3, che contiene una capra. Il conduttore ti chiede quindi se vuoi cambiare la tua scelta e passare alla porta numero 2. È vantaggioso cambiare la scelta?” Craig. F. Whitaker, Columbia, MD\n\nLa situazione descritta nella lettera è simile a quella che i concorrenti affrontavano nel quiz televisivo degli anni ’70 Let’s Make a Deal, condotto da Monty Hall e Carol Merrill. Marilyn rispose che il concorrente dovrebbe cambiare la scelta, poiché se l’auto è dietro una delle due porte non scelte (il che è due volte più probabile rispetto alla porta inizialmente scelta), il concorrente vince cambiando porta. Tuttavia, la sua risposta suscitò una reazione a catena, con molte lettere, persino da parte di matematici, che affermavano che avesse torto. Questo episodio diede origine al problema di Monty Hall e innescò migliaia di ore di dibattiti.\nQuesto incidente sottolinea un aspetto fondamentale della probabilità: spesso, l’intuizione porta a conclusioni completamente errate. Fino a quando non si affinano le capacità nel trattare problemi di probabilità, un approccio rigoroso e sistematico è utile per evitare errori.\nChiarire il Problema\nLa lettera originale di Craig Whitaker è un po’ vaga, quindi dobbiamo fare delle ipotesi per poter modellare formalmente il gioco. Supponiamo che:\n\nL’auto sia nascosta in modo casuale ed equiprobabile dietro una delle tre porte.\nIl giocatore scelga una delle tre porte in modo casuale, indipendentemente dalla posizione dell’auto.\nDopo che il giocatore ha scelto una porta, il conduttore apre un’altra porta, che contiene una capra, e offre al giocatore la possibilità di mantenere la scelta o cambiarla.\nSe il conduttore ha la possibilità di scegliere quale porta aprire (ossia, se ci sono due capre disponibili), sceglie casualmente quale porta aprire.\n\nCon queste assunzioni, possiamo affrontare la domanda: “Qual è la probabilità che un giocatore che cambia porta vinca l’auto?”\nIl Metodo in Quattro Passi\nOgni problema di probabilità riguarda un esperimento o un processo casuale. In questi casi, il problema può essere suddiviso in quattro fasi distinte.\nPasso 1: Trovare lo Spazio Campionario\nIl primo passo è identificare tutti i possibili esiti dell’esperimento. Nel problema di Monty Hall, ci sono tre quantità determinate casualmente:\n\nLa porta che nasconde l’auto.\nLa porta scelta inizialmente dal giocatore.\nLa porta che il conduttore apre per rivelare una capra.\n\nUn diagramma ad albero può aiutarci a visualizzare il problema, dato che il numero di esiti non è troppo grande e la struttura è semplice. Il primo evento casuale è la posizione dell’auto, che rappresentiamo con tre rami in un albero. Ogni ramo corrisponde a una delle porte. La seconda quantità casuale è la porta scelta dal giocatore, rappresentata nel secondo livello dell’albero, e la terza quantità casuale è la porta che il conduttore apre, mostrata nel terzo livello.\nEcco un esempio di diagramma ad albero in Python che rappresenta questa situazione:\n\n\n\n\n\n\nFigura 24.2: Il diagramma ad albero per il Problema di Monty Hall mostra le probabilità associate a ogni possibile esito. I pesi sugli archi rappresentano la probabilità di seguire quel particolare percorso, dato che ci troviamo nel nodo padre. Ad esempio, se l’auto si trova dietro la porta A, la probabilità che il giocatore scelga inizialmente la porta B è pari a 1/3. La colonna più a destra del diagramma mostra la probabilità di ciascun esito finale. Ogni probabilità di esito è calcolata moltiplicando le probabilità lungo il percorso che parte dalla radice (auto dietro una certa porta) e termina alla foglia (esito finale) (Figura tratta da Lehman, Leighton e Meyer, 2018).\n\n\n\nNel diagramma ad albero, i rami rappresentano le possibili combinazioni delle porte, e le foglie rappresentano gli esiti dell’esperimento. Ogni foglia dell’albero rappresenta un esito dello spazio campionario, che nel nostro caso è composto da 12 esiti. Per esempio, (Car A, Pick B, Reveal C).\nPasso 2: Definire gli Eventi di Interesse\nL’evento di interesse è “il giocatore vince cambiando porta”. Questo significa che, se la porta scelta dal giocatore inizialmente non contiene l’auto, e il giocatore decide di cambiare porta, allora vincerà. Gli esiti favorevoli sono quelli in cui la porta inizialmente scelta dal giocatore non nasconde l’auto, e cambiando porta il giocatore sceglie correttamente la porta che nasconde l’auto.\nGli esiti che soddisfano questa condizione sono:\n\n(Car A, Pick B, Reveal C)\n(Car A, Pick C, Reveal B)\n(Car B, Pick A, Reveal C)\n(Car B, Pick C, Reveal A)\n(Car C, Pick A, Reveal B)\n(Car C, Pick B, Reveal A)\n\nQuesti esiti sono 6 in totale.\nPasso 3: Calcolare le Probabilità degli Esiti\nOgni esito ha una certa probabilità di verificarsi. Il modo per determinare la probabilità di ciascun esito è moltiplicare le probabilità lungo il percorso nell’albero.\nEsempio di calcolo per l’esito (Car A, Pick B, Reveal C):\n\nLa probabilità che l’auto sia dietro la porta A è \\(\\frac{1}{3}\\).\nLa probabilità che il giocatore scelga la porta B è \\(\\frac{1}{3}\\).\nLa probabilità che il conduttore apra la porta C (che contiene una capra) è \\(1\\) (poiché il conduttore deve aprire una porta con una capra, e la porta C è l’unica possibile).\n\nLa probabilità totale per questo esito è:\n\\[\nP(\\text{Car A, Pick B, Reveal C}) = \\frac{1}{3} \\times \\frac{1}{3} \\times 1 = \\frac{1}{9}.\n\\]\nProcedendo in modo simile per tutti gli altri esiti, otteniamo le probabilità per tutti i 12 esiti.\nPasso 4: Calcolare le Probabilità degli Eventi\nLa probabilità di vincere cambiando porta è data dalla somma delle probabilità degli esiti favorevoli elencati sopra.\n\\[\n\\begin{aligned}\nP&(\\text{vincere cambiando porta}) = \\notag \\\\\n&\\quad P(\\text{Car A, Pick B, Reveal C}) + P(\\text{Car A, Pick C, Reveal B}) + \\notag\\\\  \n&\\quad P(\\text{Car B, Pick A, Reveal C}) + \\dots \\notag\n\\end{aligned}\n\\]\n\\[\n= \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} = \\frac{6}{9} = \\frac{2}{3}.\n\\]\nLa probabilità di vincere mantenendo la scelta originale è semplicemente il complemento:\n\\[\nP(\\text{vincere mantenendo la scelta}) = 1 - P(\\text{vincere cambiando porta}) = 1 - \\frac{2}{3} = \\frac{1}{3}.\n\\]\nLa conclusione è che il giocatore ha una probabilità di vincere pari a \\(\\frac{2}{3}\\) se cambia porta, contro una probabilità di \\(\\frac{1}{3}\\) se mantiene la sua scelta iniziale. Cambiare porta è quindi la strategia vincente. Questo risultato controintuitivo è il motivo per cui il problema di Monty Hall ha causato tanta confusione inizialmente.\nIl problema di Monty Hall è un classico esempio di probabilità condizionata perché la probabilità di vincere l’auto dipende da informazioni aggiuntive ottenute durante il gioco, cioè la porta che il conduttore apre. Inizialmente, la probabilità di trovare l’auto dietro la porta scelta dal giocatore è \\(\\frac{1}{3}\\), mentre la probabilità che l’auto sia dietro una delle altre due porte è \\(\\frac{2}{3}\\).\nQuando il conduttore apre una porta mostrando una capra, fornisce nuove informazioni che cambiano le probabilità. Questa nuova informazione condiziona la probabilità che l’auto sia dietro la porta non scelta dal giocatore, facendo sì che la probabilità di vincere cambiando porta diventi \\(\\frac{2}{3}\\). Quindi, il problema di Monty Hall è un esempio di probabilità condizionata perché l’aggiornamento delle probabilità dipende da un evento intermedio (la scelta della porta aperta dal conduttore).\n\n\nEsempio 24.4 Per confermare il risultato inaspettato del Problema di Monty Hall, è possibile eseguire una simulazione. In questa simulazione, consideriamo due scenari: uno in cui il concorrente mantiene la sua scelta iniziale e un altro in cui cambia la sua scelta dopo che Monty Hall ha svelato una capra. Ripetendo questa simulazione migliaia di volte, possiamo confrontare i risultati empirici e confermare come effettivamente il cambiamento di scelta aumenti le probabilità del concorrente di vincere l’automobile.\nDi seguito è riportato lo script di una simulazione progettata per illustrare il paradosso di Monty Hall.\n\nset.seed(123)  # For reproducibility\n\nporte &lt;- c(\"capra1\", \"capra2\", \"macchina\")  # Define the game\ncounter &lt;- 0\ncontatore_cambio &lt;- 0\nn &lt;- 10000\nporta_vincente &lt;- \"macchina\"\n\nfor (i in 1:n) {\n  scelta_casuale &lt;- sample(porte, 1)\n  porte_rimaste &lt;- porte[porte != scelta_casuale]\n  porta_rivelata &lt;- sample(porte_rimaste[porte_rimaste != porta_vincente], 1)\n  porta_alternativa &lt;- porte[porte != scelta_casuale & porte != porta_rivelata]\n  \n  if (\"macchina\" %in% porta_alternativa) {\n    contatore_cambio &lt;- contatore_cambio + 1\n  }\n  \n  if (scelta_casuale == \"macchina\") {\n    counter &lt;- counter + 1\n  }\n}\n\ncat(counter / n, \"\\n\")  # Proportion of wins without changing the door\n#&gt; 0.3342\ncat(contatore_cambio / n, \"\\n\")  # Proportion of wins by changing the door\n#&gt; 0.6658\n\nLa simulazione mostra che, effettivamente, la probabilità di vincere la macchina aumenta quando il concorrente sceglie di cambiare porta.\n\n\n24.3.1 Il paradosso di Simpson\nNel campo della probabilità condizionata, uno dei fenomeni più interessanti e, nel contempo, più controintuitivi, è rappresentato dal paradosso di Simpson. Il paradosso di Simpson è un fenomeno statistico in cui una tendenza che appare in diversi gruppi separati di dati scompare o si inverte quando i dati vengono combinati. Questo paradosso mette in luce l’importanza di considerare le variabili confondenti e di analizzare i dati con attenzione per evitare conclusioni errate.\n\nEsempio 24.5 Due psicoterapeuti, Rossi e Bianchi, praticano due tipi di terapie: terapia per disturbi d’ansia e coaching per migliorare le prestazioni lavorative. Ogni terapia può avere un esito positivo o negativo.\nI rispettivi bilanci dei due terapeuti sono riportati nelle seguenti tabelle.\nRossi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d’ansia\n70\n20\n\n\nCoaching lavorativo\n10\n0\n\n\nTotale\n80\n20\n\n\n\nBianchi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d’ansia\n2\n8\n\n\nCoaching lavorativo\n81\n9\n\n\nTotale\n83\n17\n\n\n\nRossi ha un tasso di successo superiore a Bianchi nella terapia per i disturbi d’ansia: 70 su 90 rispetto a 2 su 10. Anche nel coaching lavorativo, Rossi ha un tasso di successo superiore: 10 su 10 rispetto a 81 su 90. Tuttavia, se aggregiamo i dati dei due tipi di terapia per confrontare i tassi di successo globali, Rossi è efficace in 80 su 100 terapie, mentre Bianchi in 83 su 100: il tasso di successo globale di Bianchi risulta superiore!\nQuesto fenomeno è un esempio del paradosso di Simpson, dove una tendenza osservata in diversi gruppi si inverte quando i gruppi sono combinati.\nPer essere più precisi, possiamo calcolare i tassi di successo per ciascun terapeuta e per ciascun tipo di terapia, oltre al tasso di successo globale.\n\nRossi\n\nTasso di successo in terapia per disturbi d’ansia: \\(\\frac{70}{70+20} = \\frac{70}{90} \\approx 0.778\\)\nTasso di successo in coaching lavorativo: \\(\\frac{10}{10+0} = \\frac{10}{10} = 1\\)\nTasso di successo globale: \\(\\frac{70+10}{70+20+10+0} = \\frac{80}{100} = 0.8\\)\n\nBianchi\n\nTasso di successo in terapia per disturbi d’ansia: \\(\\frac{2}{2+8} = \\frac{2}{10} = 0.2\\)\nTasso di successo in coaching lavorativo: \\(\\frac{81}{81+9} = \\frac{81}{90} \\approx 0.9\\)\nTasso di successo globale: \\(\\frac{2+81}{2+8+81+9} = \\frac{83}{100} = 0.83\\)\n\n\nQuello che sta succedendo è che Rossi, presumibilmente a causa della sua reputazione come terapeuta più esperto, sta effettuando un numero maggiore di terapie per disturbi d’ansia, che sono intrinsecamente più complesse e con una probabilità di successo variabile rispetto al coaching lavorativo. Il suo tasso di successo globale è inferiore non a causa di una minore abilità in un particolare tipo di terapia, ma perché una frazione maggiore delle sue terapie riguarda casi più complessi.\nL’aggregazione dei dati tra diversi tipi di terapia presenta un quadro fuorviante delle abilità dei terapeuti perché perdiamo l’informazione su quale terapeuta tende a effettuare quale tipo di terapia. Quando sospettiamo la presenza di variabili di confondimento, come ad esempio il tipo di terapia in questo contesto, è fondamentale analizzare i dati in modo disaggregato per comprendere con precisione la dinamica in atto.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#teorema-della-probabilità-composta",
    "href": "chapters/probability/04_conditional_prob.html#teorema-della-probabilità-composta",
    "title": "24  Probabilità condizionata",
    "section": "24.4 Teorema della probabilità composta",
    "text": "24.4 Teorema della probabilità composta\nÈ possibile scrivere l’Equazione 24.1 nella forma:\n\\[\nP(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A).\n\\tag{24.2}\\]\nQuesto secondo modo di scrivere l’Equazione 24.1 è chiamato teorema della probabilità composta (o regola moltiplicativa, o regola della catena). La legge della probabilità composta ci dice che la probabilità che si verifichino contemporaneamente due eventi \\(A\\) e \\(B\\) è pari alla probabilità di uno dei due eventi moltiplicata per la probabilità dell’altro evento condizionata al verificarsi del primo.\nL’l’Equazione 24.2 si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente:\n\\[\nP\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left(  A_k  \\ \\Biggl\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right).\n\\tag{24.3}\\]\nPer esempio, nel caso di quattro eventi abbiamo\n\\[\n\\begin{split}\nP(&A_1 \\cap A_2 \\cap A_3 \\cap A_4) =  \\\\\n& P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot  P(A_3 \\mid A_1 \\cap A_2) \\cdot P(A_4 \\mid A_1 \\cap A_2 \\cap A_{3}).\\notag\n\\end{split}\n\\]\n\nEsempio 24.6 Per fare un esempio, consideriamo il problema seguente. Da un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento: “esce una pallina bianca alla \\(i\\)-esima estrazione” e con \\(N_i\\) l’estrazione di una pallina nera. L’evento: “escono due palline bianche nelle prime due estrazioni” è rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l’Equazione 24.2, la sua probabilità vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche, per l’Equazione 24.3, vale\n\\[\n\\begin{aligned}\nP(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\\n&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\\n&= \\frac{1}{6}.\n\\end{aligned}\n\\]\nLa probabilità dell’estrazione di tre palline nere è invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\\n&= \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#il-teorema-della-probabilità-totale",
    "href": "chapters/probability/04_conditional_prob.html#il-teorema-della-probabilità-totale",
    "title": "24  Probabilità condizionata",
    "section": "24.5 Il teorema della probabilità totale",
    "text": "24.5 Il teorema della probabilità totale\nIl teorema della probabilità totale (detto anche teorema delle partizioni) afferma che se abbiamo una partizione di uno spazio campionario \\(\\Omega\\) in \\(n\\) eventi mutualmente esclusivi e tali che la loro unione formi \\(\\Omega\\), allora la probabilità di un qualsiasi evento in \\(\\Omega\\) può essere calcolata sommando la probabilità dell’evento su ciascun sottoinsieme della partizione, pesata in base alla probabilità del sottoinsieme.\nIn altre parole, se \\(H_1, H_2, \\dots, H_n\\) sono eventi mutualmente esclusivi e tali che \\(\\bigcup_{i=1}^n H_i = \\Omega\\), allora per ogni evento \\(E \\subseteq \\Omega\\), la probabilità di \\(E\\) è data dalla formula:\n\\[\nP(E) = \\sum_{i=1}^n P(E \\mid H_i)P(H_i),\n\\tag{24.4}\\]\ndove \\(P(E \\mid H_i)\\) rappresenta la probabilità condizionata di \\(E\\) dato che si è verificato l’evento \\(H_i\\), e \\(P(H_i)\\) è la probabilità dell’evento \\(H_i\\).\nIl teorema della probabilità totale riveste un ruolo fondamentale in quanto fornisce il denominatore nel teorema di Bayes, svolgendo la funzione di costante di normalizzazione. Questa costante di normalizzazione è di vitale importanza per assicurare che la distribuzione a posteriori sia una distribuzione di probabilità valida. Per ulteriori dettagli e approfondimenti, è possibile fare riferimento al ?sec-subj-prop.\nNell’ambito della probabilità discreta, questo teorema viene usato quando abbiamo una partizione dello spazio campionario e vogliamo calcolare la probabilità di un evento, sfruttando le probabilità dei singoli eventi della partizione. Il caso più semplice è quello di una partizione dello spazio campione in due sottoinsiemi: \\(P(E) = P(E \\cap H_1) + P(E \\cap H_2)\\).\n\n\n\n\n\n\nFigura 24.3: Partizione dello spazio campionario per il teorema di Bayes.\n\n\n\nIn tali circostanza abbiamo che\n\\[\nP(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2).\n\\]\nL’Equazione 24.4 è utile per calcolare \\(P(E)\\), se \\(P(E \\mid H_i)\\) e \\(P(H_i)\\) sono facili da trovare.\n\nEsempio 24.7 Abbiamo tre urne, ciascuna delle quali contiene 100 palline:\n\nUrna 1: 75 palline rosse e 25 palline blu,\nUrna 2: 60 palline rosse e 40 palline blu,\nUrna 3: 45 palline rosse e 55 palline blu.\n\nUna pallina viene estratta a caso da un’urna anch’essa scelta a caso. Qual è la probabilità che la pallina estratta sia di colore rosso?\nSia \\(R\\) l’evento “la pallina estratta è rossa” e sia \\(U_i\\) l’evento che corrisponde alla scelta dell’\\(i\\)-esima urna. Sappiamo che\n\\[\nP(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n\\]\nGli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campione in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilità totale, la probabilità di estrarre una pallina rossa è dunque\n\\[\n\\begin{split}\nP(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n&=0.60.\n\\end{split}\n\\]\n\n\n24.5.1 Indipendenza e probabilità condizionata\nL’indipendenza tra due eventi \\(A\\) e \\(B\\) può essere espressa in modo intuitivo utilizzando la probabilità condizionata. Se \\(A\\) e \\(B\\) sono indipendenti, il verificarsi di uno degli eventi non influisce sulla probabilità del verificarsi dell’altro. In altre parole, la probabilità che \\(A\\) accada non cambia se sappiamo che \\(B\\) è avvenuto, e viceversa.\nPossiamo esprimere questa idea con le seguenti equazioni:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = P(B).\n\\]\nQuindi, due eventi \\(A\\) e \\(B\\) sono indipendenti se soddisfano le condizioni:\n\\[\nP(A \\mid B) = P(A),\n\\]\n\\[\nP(B \\mid A) = P(B).\n\\]\nQuesto significa che la probabilità di \\(A\\) rimane invariata indipendentemente dal fatto che \\(B\\) sia accaduto o meno, e lo stesso vale per \\(B\\).\n\n24.5.1.1 Indipendenza di Tre Eventi\nTre eventi \\(A\\), \\(B\\) e \\(C\\) sono indipendenti se soddisfano le seguenti condizioni:\n\\[\n\\begin{align}\nP(A \\cap B) &= P(A) P(B), \\\\\nP(A \\cap C) &= P(A) P(C), \\\\\nP(B \\cap C) &= P(B) P(C), \\\\\nP(A \\cap B \\cap C) &= P(A) P(B) P(C).\n\\end{align}\n\\]\nLe prime tre condizioni verificano l’indipendenza a due a due, ovvero l’indipendenza di ciascuna coppia di eventi. Tuttavia, per essere completamente indipendenti, deve essere soddisfatta anche l’ultima condizione, che riguarda l’intersezione di tutti e tre gli eventi. Solo se tutte queste condizioni sono soddisfatte possiamo dire che \\(A\\), \\(B\\) e \\(C\\) sono completamente indipendenti.\nIn sintesi, l’indipendenza tra eventi implica che la conoscenza del verificarsi di uno non fornisce alcuna informazione sulla probabilità del verificarsi degli altri.\n\nEsempio 24.8 Consideriamo un esempio utilizzando un mazzo di 52 carte. Ogni seme contiene 13 carte e ci sono 4 regine in totale. Definiamo i seguenti eventi:\n\nEvento A: pescare una carta di picche,\nEvento B: pescare una regina.\n\nProbabilità con un mazzo completo\nIn un mazzo completo, la probabilità di pescare una carta di picche (\\(P(A)\\)) è \\(\\frac{13}{52} = \\frac{1}{4}\\), poiché ci sono 13 picche su 52 carte totali. La probabilità di pescare una regina (\\(P(B)\\)) è \\(\\frac{4}{52} = \\frac{1}{13}\\), poiché ci sono 4 regine su 52 carte.\nOra consideriamo la probabilità congiunta di pescare la regina di picche (\\(P(AB)\\)). Poiché esiste solo una regina di picche nel mazzo, la probabilità di pescare questa specifica carta è \\(\\frac{1}{52}\\).\nSecondo la definizione di indipendenza, se gli eventi \\(A\\) e \\(B\\) sono indipendenti, allora:\n\\[ P(AB) = P(A)P(B) \\]\nCalcoliamo \\(P(A)P(B)\\):\n\\[ P(A)P(B) = \\left( \\frac{1}{4} \\right) \\left( \\frac{1}{13} \\right) = \\frac{1}{52} \\]\nPoiché \\(P(AB) = \\frac{1}{52}\\) è uguale a \\(P(A)P(B)\\), possiamo affermare che gli eventi \\(A\\) e \\(B\\) sono indipendenti con un mazzo completo di 52 carte.\nProbabilità dopo la rimozione di una carta\nConsideriamo ora un mazzo con una carta in meno, ad esempio il due di quadri, riducendo il numero totale di carte a 51. Ricalcoliamo le probabilità con questo mazzo ridotto:\nLa probabilità di pescare la regina di picche (\\(P(AB)\\)) è ora \\(\\frac{1}{51}\\), poiché ci sono 51 carte nel mazzo.\nRicalcoliamo anche \\(P(A)\\) e \\(P(B)\\):\n\n\\(P(A)\\) diventa \\(\\frac{13}{51}\\), poiché ci sono ancora 13 picche, ma su 51 carte.\n\\(P(B)\\) diventa \\(\\frac{4}{51}\\), poiché ci sono ancora 4 regine, ma su 51 carte.\n\nOra calcoliamo il prodotto \\(P(A)P(B)\\) con queste nuove probabilità:\n\\[ P(A)P(B) = \\left( \\frac{13}{51} \\right) \\left( \\frac{4}{51} \\right) = \\frac{52}{2601} \\]\nConfrontiamo \\(P(AB)\\) e \\(P(A)P(B)\\):\n\\[ \\frac{1}{51} \\neq \\frac{52}{2601} \\]\nPoiché \\(\\frac{1}{51} \\neq \\frac{52}{2601}\\), gli eventi \\(A\\) e \\(B\\) non sono più indipendenti dopo la rimozione del due di quadri.\nQuesto esempio mostra come l’indipendenza tra due eventi dipenda dal contesto. Con un mazzo completo, i due eventi sono indipendenti. Tuttavia, rimuovendo una carta dal mazzo, le probabilità cambiano e gli eventi non sono più indipendenti. Questo evidenzia l’importanza di considerare la composizione e le condizioni iniziali quando si analizzano probabilità e indipendenza. Modifiche nella composizione del mazzo possono alterare le probabilità, influenzando le relazioni di indipendenza tra eventi specifici.\nIn generale, l’indipendenza tra due eventi significa che la probabilità di uno non è influenzata dal verificarsi dell’altro. Questo concetto è cruciale per analisi probabilistiche e modelli statistici più complessi.\n\n\nEsempio 24.9 Nel lancio di due dadi non truccati, si considerino gli eventi: \\(A\\) = “esce un 1 o un 2 nel primo lancio” e \\(B\\) = “il punteggio totale è 8”. Gli eventi \\(A\\) e \\(B\\) sono indipendenti?\nCalcoliamo \\(P(A)\\):\n\nr &lt;- 1:6\nsample &lt;- expand.grid(i = r, j = r)\nA &lt;- subset(sample, i == 1 | i == 2)\nprint(A)\n#&gt;    i j\n#&gt; 1  1 1\n#&gt; 2  2 1\n#&gt; 7  1 2\n#&gt; 8  2 2\n#&gt; 13 1 3\n#&gt; 14 2 3\n#&gt; 19 1 4\n#&gt; 20 2 4\n#&gt; 25 1 5\n#&gt; 26 2 5\n#&gt; 31 1 6\n#&gt; 32 2 6\ncat(nrow(A), \"/\", nrow(sample), \"\\n\")\n#&gt; 12 / 36\n\nCalcoliamo \\(P(B)\\):\n\nB &lt;- subset(sample, i + j == 8)\nprint(B)\n#&gt;    i j\n#&gt; 12 6 2\n#&gt; 17 5 3\n#&gt; 22 4 4\n#&gt; 27 3 5\n#&gt; 32 2 6\ncat(nrow(B), \"/\", nrow(sample), \"\\n\")\n#&gt; 5 / 36\n\nCalcoliamo \\(P(A \\cap B)\\):\n\nI &lt;- subset(sample, (i == 1 | i == 2) & (i + j == 8))\nprint(I)\n#&gt;    i j\n#&gt; 32 2 6\ncat(nrow(I), \"/\", nrow(sample), \"\\n\")\n#&gt; 1 / 36\n\nGli eventi \\(A\\) e \\(B\\) non sono statisticamente indipendenti dato che \\(P(A \\cap B) \\neq P(A)P(B)\\):\n\n12/36 * 5/36 == 1/36\n#&gt; [1] FALSE",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/04_conditional_prob.html#riflessioni-conclusive",
    "title": "24  Probabilità condizionata",
    "section": "24.6 Riflessioni Conclusive",
    "text": "24.6 Riflessioni Conclusive\nLa probabilità condizionata riveste un ruolo fondamentale in statistica, poiché consente di definire con precisione il concetto di indipendenza statistica. Uno degli aspetti cruciali dell’analisi statistica è la valutazione dell’associazione tra due variabili. In questo capitolo, ci siamo focalizzati sul concetto di indipendenza, che indica l’assenza di relazione tra le variabili. Tuttavia, in futuro esploreremo come effettuare inferenze sulla correlazione tra variabili, ovvero come determinare se esiste una relazione statistica credibile tra di esse.\nIl concetto di probabilità condizionata ci permette di enunciare due regole fondamentali della probabilità:\n\nLa regola della congiunzione (regola del “e” o del prodotto):\n\\[\nP(A \\cap B\\,|\\,C) = P(A\\,|\\,C) \\times P(B\\,|\\,A, C) = P(B\\,|\\,C) \\times P(A\\,|\\,B, C).\n\\]\nLa regola della disgiunzione (regola del “o” o della somma):\n\\[\nP(A \\cup B\\,|\\,C) = P(A\\,|\\,C) + P(B\\,|\\,C) - P(A \\cap B\\,|\\,C).\n\\]\n\nUn’altra importante regola della probabilità è la legge della probabilità totale, che gioca un ruolo cruciale nel teorema di Bayes.\nNel contesto dell’inferenza bayesiana, il condizionamento è uno strumento essenziale. Questo approccio statistico utilizza il condizionamento per rivedere e aggiornare le credenze o incertezze riguardo a determinate ipotesi, basandosi sull’introduzione di nuove informazioni.\nIn sintesi, la probabilità condizionata non solo è fondamentale per comprendere l’indipendenza statistica, ma anche per applicare metodi inferenziali avanzati come l’inferenza bayesiana. Questa forma di inferenza ci permette di aggiornare continuamente le nostre conoscenze e credenze alla luce di nuove informazioni, rendendo il processo decisionale statistico dinamico e adattabile.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/04_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "24  Probabilità condizionata",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html",
    "href": "chapters/probability/05_random_var.html",
    "title": "25  Variabili casuali",
    "section": "",
    "text": "25.1 Introduzione\nPrerequisiti\nPrima di procedere con il presente capitolo, è essenziale leggere l’?sec-calculus.\nConcetti e competenze chiave\nPreparazione del Notebook\nFinora, ci siamo concentrati sulle probabilità degli eventi. Ad esempio, abbiamo calcolato la probabilità di vincere il gioco di Monty Hall o di avere una rara condizione medica dato che il test è risultato positivo. Ma, in molti casi, vorremmo sapere di più. Ad esempio, quanti concorrenti devono giocare al gioco di Monty Hall fino a quando uno di loro finalmente vince? Quanto durerà questa condizione? Quanto perderò giocando d’azzardo con un dado sbilanciato tutta la notte? Per rispondere a queste domande, dobbiamo lavorare con le variabili casuali. In questo capitolo, introduciamo le variabili casuali e le loro proprietà.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#definizione",
    "href": "chapters/probability/05_random_var.html#definizione",
    "title": "25  Variabili casuali",
    "section": "25.2 Definizione",
    "text": "25.2 Definizione\nLe variabili casuali sono risultati numerici derivanti da processi aleatori. Esse ci consentono di trasformare risultati qualitativi (ad esempio \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\)) in valori numerici, semplificando così l’analisi matematica.\nFormalmente, una variabile casuale è definita come una funzione che associa ogni elemento di uno spazio campionario \\(S\\) a un valore in un sottoinsieme dei numeri reali \\(\\mathbb{R}\\). Questa definizione consente di esprimere numericamente gli esiti di un fenomeno aleatorio, associando un valore specifico a ciascun possibile risultato dell’esperimento.\n\nEsempio 25.1 Un esempio è la variabile casuale \\(X\\), che rappresenta il risultato del lancio di un dado. Se definiamo \\(X = 1\\) per indicare che il risultato del lancio è un numero dispari (1, 3 o 5) e \\(X = 0\\) per indicare che il risultato è un numero pari (2, 4 o 6), abbiamo trasformato un’osservazione fisica (il lancio del dado) in un valore numerico che rappresenta una determinata categoria di eventi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#tipologie-di-variabili-casuali",
    "href": "chapters/probability/05_random_var.html#tipologie-di-variabili-casuali",
    "title": "25  Variabili casuali",
    "section": "25.3 Tipologie di Variabili Casuali",
    "text": "25.3 Tipologie di Variabili Casuali\nLe variabili casuali possono essere suddivise in due categorie principali: discrete e continue. Una variabile casuale discreta assume valori all’interno di un insieme finito o al massimo numerabile, il che significa che i suoi possibili esiti possono essere contati, anche se l’insieme è infinito. Al contrario, una variabile casuale continua può assumere un’infinità di valori all’interno di un intervallo, essendo in grado di coprire ogni punto di quell’intervallo senza interruzioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#convenzioni-notazionali",
    "href": "chapters/probability/05_random_var.html#convenzioni-notazionali",
    "title": "25  Variabili casuali",
    "section": "25.4 Convenzioni Notazionali",
    "text": "25.4 Convenzioni Notazionali\nNella teoria della probabilità, è usuale adottare una specifica convenzione di notazione per le variabili casuali e i loro esiti. Comunemente, si utilizzano le lettere maiuscole, come \\(X\\), per indicare una variabile casuale, ovvero un concetto che rappresenta una serie di possibili esiti di un fenomeno aleatorio. D’altro canto, la corrispondente lettera minuscola, \\(x\\) nel nostro esempio, è impiegata per denotare una specifica realizzazione o un esito particolare che la variabile casuale può assumere. Questa distinzione aiuta a chiarire se si sta parlando della variabile casuale nel suo insieme (\\(X\\)) o di un suo specifico valore (\\(x\\)).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#variabili-casuali-multiple",
    "href": "chapters/probability/05_random_var.html#variabili-casuali-multiple",
    "title": "25  Variabili casuali",
    "section": "25.5 Variabili casuali multiple",
    "text": "25.5 Variabili casuali multiple\nNella teoria della probabilità, le variabili casuali spesso interagiscono o si combinano tra loro. Consideriamo l’esempio di tre lanci di una moneta bilanciata, rappresentati da variabili casuali indipendenti \\(X_1\\), \\(X_2\\), e \\(X_3\\). Per ogni lancio:\n\n\\(P(X_n = 1)\\) (testa) = 0.5,\n\\(P(X_n = 0)\\) (croce) = 0.5,\n\ndove \\(n = 1, 2, 3\\).\nCombinando queste variabili, possiamo creare nuove variabili casuali. Ad esempio, definiamo \\(Z\\) come la somma dei risultati:\n\\[\nZ = X_1 + X_2 + X_3.\n\\]\n\\(Z\\) è una variabile casuale discreta che rappresenta il numero totale di teste ottenute nei tre lanci. I suoi possibili valori sono 0, 1, 2, e 3.\nQuesto esempio illustra come variabili casuali indipendenti possano essere combinate per creare nuove variabili casuali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#sec-fun-mass-prob",
    "href": "chapters/probability/05_random_var.html#sec-fun-mass-prob",
    "title": "25  Variabili casuali",
    "section": "25.6 Distribuzione di Probabilità",
    "text": "25.6 Distribuzione di Probabilità\nLa distribuzione di probabilità è un concetto fondamentale nella teoria della probabilità, che descrive come le probabilità si distribuiscono tra i possibili esiti di una variabile casuale. La sua rappresentazione varia a seconda che si tratti di variabili casuali discrete o continue.\n\n25.6.1 Variabili Casuali Discrete\nPer le variabili casuali discrete, che assumono valori specifici e contabili, la distribuzione di probabilità è rappresentata dalla funzione di massa di probabilità, indicata come \\(P(\\cdot)\\).\n\n25.6.1.1 Funzione di Massa di Probabilità\nLa funzione di massa di probabilità assegna una probabilità precisa a ciascun possibile esito della variabile casuale discreta. Ad esempio, per il lancio di un dado equilibrato:\n\\(P(Y = 1) = \\frac{1}{6}\\).\nQuesto significa che la probabilità di ottenere “1” in un singolo lancio è 1/6.\n\n\n25.6.1.2 Istogrammi per Variabili Discrete\nGli istogrammi sono strumenti visivi efficaci per rappresentare la distribuzione di probabilità delle variabili casuali discrete. Per queste variabili, possiamo impostare ciascun bin dell’istogramma in modo che copra un singolo valore della variabile casuale. L’altezza di ogni bin corrisponde alla probabilità di quel valore specifico.\nGli istogrammi ci permettono di identificare rapidamente caratteristiche importanti della distribuzione, come:\n\nunimodalità: concentrazione attorno a un singolo punto;\nmultimodalità: concentrazione attorno a più punti;\nsimmetria o asimmetria della distribuzione;\ndispersione dei valori.\n\n\n\n\n25.6.2 Variabili Casuali Continue\nPer le variabili casuali continue, che possono assumere un’infinità di valori in un intervallo, si utilizza la funzione di densità di probabilità, indicata come \\(p(\\cdot)\\).\n\n25.6.2.1 Funzione di Densità di Probabilità\nLa funzione di densità di probabilità non assegna probabilità a singoli valori (che sarebbe zero per una variabile continua), ma determina la probabilità che la variabile si trovi all’interno di un intervallo specifico.\n\n\n25.6.2.2 Istogrammi per Variabili Continue\nAnche per le variabili continue possiamo usare istogrammi, ma in questo caso i bin devono sempre coprire intervalli di valori. Riducendo progressivamente la larghezza dei bin, il profilo dell’istogramma tende a coincidere con la funzione di densità di probabilità della variabile casuale.\n\n\n\n25.6.3 Supporto della Variabile Casuale\nIl supporto di una variabile casuale è l’insieme di tutti i valori che la variabile può effettivamente assumere. Ad esempio:\n\nper un dado a sei facce: {1, 2, 3, 4, 5, 6};\nper una distribuzione gaussiana: l’intero insieme dei numeri reali.\n\n\n\n25.6.4 Assegnazione di Probabilità\n\nPer variabili discrete: si specifica la probabilità di ogni possibile valore.\nPer variabili continue: si utilizza la densità di probabilità per calcolare la probabilità di intervalli di valori.\n\nLa distribuzione di probabilità, sia per variabili discrete che continue, fornisce una descrizione completa del comportamento probabilistico della variabile casuale, permettendo analisi e previsioni accurate in vari campi di applicazione.\n\nEsempio 25.2 Consideriamo l’esperimento casuale costituito dal lancio di due dadi equilibrati. Definiamo la variabile casuale \\(X\\) come la somma dei punti ottenuti dai due dadi.\nLo spazio campionario \\(S\\) è l’insieme di tutte le possibili coppie ordinate \\((a,b)\\), dove \\(a\\) e \\(b\\) rappresentano i risultati del primo e del secondo dado rispettivamente:\n\\[\nS = {(1,1), (1,2), ..., (1,6), (2,1), (2,2), ..., (2,6), ..., (6,1), (6,2), ..., (6,6)}.\n\\]\nIn totale, ci sono 6 × 6 = 36 possibili esiti.\nLa variabile casuale \\(X\\) è definita come la somma dei punti dei due dadi. Quindi:\n\\[\nX = a + b, \\quad \\text{dove } (a,b) \\in S.\n\\]\n\\(X\\) può assumere valori interi da 2 (1+1) a 12 (6+6).\nLa distribuzione della variabile casuale \\(X\\) è una funzione che associa a ogni possibile valore di \\(X\\) la sua probabilità. In questo caso, poiché \\(X\\) è discreta, usiamo una funzione di massa di probabilità.\nPer calcolare la probabilità di ogni valore di \\(X\\), contiamo il numero di casi favorevoli e lo dividiamo per il numero totale di casi possibili (36).\n\n\n\n\n\n\n\n\n\nX\nCasi favorevoli\nNumero di casi\nProbabilità P(X = x)\n\n\n\n\n2\n(1,1)\n1\n1/36\n\n\n3\n(1,2), (2,1)\n2\n2/36 = 1/18\n\n\n4\n(1,3), (2,2), (3,1)\n3\n3/36 = 1/12\n\n\n5\n(1,4), (2,3), (3,2), (4,1)\n4\n4/36 = 1/9\n\n\n6\n(1,5), (2,4), (3,3), (4,2), (5,1)\n5\n5/36\n\n\n7\n(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\n6\n6/36 = 1/6\n\n\n8\n(2,6), (3,5), (4,4), (5,3), (6,2)\n5\n5/36\n\n\n9\n(3,6), (4,5), (5,4), (6,3)\n4\n4/36 = 1/9\n\n\n10\n(4,6), (5,5), (6,4)\n3\n3/36 = 1/12\n\n\n11\n(5,6), (6,5)\n2\n2/36 = 1/18\n\n\n12\n(6,6)\n1\n1/36\n\n\n\nQuesta tabella rappresenta la distribuzione completa della variabile casuale \\(X\\).\nIn conclusione, la distribuzione di una variabile casuale discreta, come nell’esempio della somma dei punti di due dadi, fornisce una descrizione completa delle proprietà probabilistiche della variabile. Essa associa a ogni possibile valore della variabile la sua probabilità di verificarsi.\nIn questo caso, la distribuzione ci dice, per esempio, che la probabilità di ottenere una somma di 7 è 1/6, la più alta tra tutti i possibili risultati. Questo è dovuto al fatto che ci sono più combinazioni che producono una somma di 7 rispetto a qualsiasi altro risultato.\nLa distribuzione ci permette di rispondere a domande come:\n\nQual è la probabilità di ottenere una somma pari? (Sommando le probabilità di 2, 4, 6, 8, 10, 12).\nQual è la probabilità di ottenere una somma maggiore o uguale a 10? (Sommando le probabilità di 10, 11, 12).\n\nLa distribuzione di massa di probabilità della variabile casuale \\(X\\) può essere rappresentata visivamente utilizzando un istogramma. Un istogramma permette di vedere immediatamente la probabilità associata a ciascun valore di \\(X\\), rendendo chiaro quali risultati sono più probabili e quali lo sono meno.\nLe istruzioni Python necessarie per generare questo istogramma sono fornite di seguito.\n\n\n# Valori possibili della variabile casuale X\nvalori_X &lt;- c(2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)\n\n# Probabilità associate a ciascun valore di X\nprobabilita_X &lt;- c(\n  1 / 36,\n  2 / 36,\n  3 / 36,\n  4 / 36,\n  5 / 36,\n  6 / 36,\n  5 / 36,\n  4 / 36,\n  3 / 36,\n  2 / 36,\n  1 / 36\n)\n\n# Creazione dell'istogramma\nbarplot(\n  probabilita_X,\n  names.arg = valori_X,\n  col = rgb(0, 0, 1, alpha = 0.5),\n  border = \"black\",\n  xlab = \"Valore della variabile casuale X\",\n  ylab = \"Probabilità P(X = x)\",\n  main = \"Distribuzione di Massa di Probabilità della Variabile Casuale X\"\n)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#funzione-di-distribuzione-cumulativa-cdf",
    "href": "chapters/probability/05_random_var.html#funzione-di-distribuzione-cumulativa-cdf",
    "title": "25  Variabili casuali",
    "section": "25.7 Funzione di Distribuzione Cumulativa (CDF)",
    "text": "25.7 Funzione di Distribuzione Cumulativa (CDF)\nLa Funzione di Distribuzione Cumulativa (CDF) è uno strumento fondamentale nella teoria della probabilità per descrivere la distribuzione di una variabile casuale.\n\n25.7.1 Definizione\nPer una variabile casuale \\(X\\), la funzione di distribuzione cumulativa \\(F(x)\\) è definita come:\n\\[\nF(x) = P(X \\leq x),\n\\]\ndove:\n\n\\(X\\) è la variabile casuale.\n\\(P(X \\leq x)\\) rappresenta la probabilità che \\(X\\) assuma un valore minore o uguale a \\(x\\).\n\nIn altre parole, \\(F(x)\\) quantifica la probabilità cumulativa dall’estremo inferiore dello spazio di probabilità fino al punto \\(x\\).\n\n\n25.7.2 Proprietà della CDF\n\nMonotonia non decrescente:\n\nPer \\(x_1 &lt; x_2\\), \\(F(x_1) \\leq F(x_2)\\).\nLa CDF non diminuisce mai quando ci si sposta da sinistra a destra lungo l’asse \\(x\\).\n\nNormalizzazione:\n\n\\(\\lim_{{x \\to -\\infty}} F(x) = 0 \\quad \\text{e} \\quad \\lim_{{x \\to +\\infty}} F(x) = 1\\).\nLa CDF parte da 0 quando \\(x\\) tende a \\(-\\infty\\) e raggiunge 1 quando \\(x\\) tende a \\(+\\infty\\).\n\nContinuità a destra:\n\n\\(F(x) = \\lim_{{y \\to x^+}} F(y)\\).\nLa CDF è continua da destra, il che significa che non presenta salti improvvisi quando ci si avvicina a un punto da destra.\n\n\n\n\n25.7.3 CDF per Variabili Casuali Discrete\nPer una variabile casuale discreta \\(X\\), la CDF (anche chiamata funzione di ripartizione cumulativa) è definita come:\n\\[\nF(x) = P(X \\leq x) = \\sum_{x_i \\leq x} P(X = x_i),\n\\]\ndove la somma è calcolata su tutti i valori \\(x_i\\) minori o uguali a \\(x\\).\n\n\n25.7.4 Importanza e Applicazioni\n\nLa CDF offre una rappresentazione visiva di come le probabilità si accumulano lungo l’intero intervallo dei possibili valori della variabile casuale.\nLa CDF permette di calcolare facilmente la probabilità che \\(X\\) cada in un intervallo specifico:\n\n\\[\nP(a &lt; X \\leq b) = F(b) - F(a).\n\\]\n\nLa CDF è utilizzata in vari metodi di generazione di variabili casuali, come il metodo della trasformazione inversa.\nLe CDF facilitano il confronto tra diverse distribuzioni di probabilità, consentendo di valutare differenze nelle loro caratteristiche cumulative.\n\nIn conclusione, la CDF è uno strumento versatile e potente che fornisce una descrizione completa della distribuzione di probabilità di una variabile casuale, sia essa discreta o continua.\n\nEsempio 25.3 Nel caso del lancio di due dadi, con la variabile casuale \\(Z\\) definita come la somma dei loro valori, la funzione di distribuzione cumulativa \\(F(z)\\) può essere illustrata come segue:\n\n\n\n\\(z\\)\n\\(P(Z = z)\\)\n\\(F(z)\\)\n\n\n\n\n2\n\\(\\frac{1}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n3\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\n\n4\n\\(\\frac{3}{36}\\)\n\\(\\frac{6}{36}\\)\n\n\n5\n\\(\\frac{4}{36}\\)\n\\(\\frac{10}{36}\\)\n\n\n6\n\\(\\frac{5}{36}\\)\n\\(\\frac{15}{36}\\)\n\n\n7\n\\(\\frac{6}{36}\\)\n\\(\\frac{21}{36}\\)\n\n\n8\n\\(\\frac{5}{36}\\)\n\\(\\frac{26}{36}\\)\n\n\n9\n\\(\\frac{4}{36}\\)\n\\(\\frac{30}{36}\\)\n\n\n10\n\\(\\frac{3}{36}\\)\n\\(\\frac{33}{36}\\)\n\n\n11\n\\(\\frac{2}{36}\\)\n\\(\\frac{35}{36}\\)\n\n\n12\n\\(\\frac{1}{36}\\)\n\\(\\frac{36}{36}\\)\n\n\n\nIn questa tabella:\n\n\\(P(Z = z)\\) rappresenta la probabilità che la somma dei due dadi sia esattamente \\(z\\).\n\\(F(z)\\) è la funzione di distribuzione cumulativa, che fornisce la probabilità che la somma \\(Z\\) sia minore o uguale a \\(z\\).\n\nQuesta tabella mostra come le probabilità cumulative si accumulano per la variabile casuale \\(Z\\), evidenziando la distribuzione delle somme possibili quando si lanciano due dadi. Ad esempio, \\(F(7) = \\frac{21}{36}\\) indica che la probabilità che la somma sia 7 o inferiore è \\(\\frac{21}{36}\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#trovare-la-distribuzione-di-probabilità-attraverso-una-simulazione",
    "href": "chapters/probability/05_random_var.html#trovare-la-distribuzione-di-probabilità-attraverso-una-simulazione",
    "title": "25  Variabili casuali",
    "section": "25.8 Trovare la Distribuzione di Probabilità attraverso una Simulazione",
    "text": "25.8 Trovare la Distribuzione di Probabilità attraverso una Simulazione\nLa distribuzione di probabilità teorica per il lancio di due dadi può essere calcolata analiticamente, ma un’alternativa altrettanto valida è ottenere una stima empirica tramite simulazione. Questo approccio consiste nel ripetere l’esperimento casuale un numero elevato di volte e analizzare le frequenze relative dei risultati ottenuti. Aumentando il numero di simulazioni, la distribuzione empirica tende a convergere verso quella teorica.\nDi seguito vedremo come implementare una simulazione in R per calcolare la distribuzione empirica di probabilità dei risultati ottenuti sommando i punteggi di due dadi.\n\nEsempio 25.4 Iniziamo definendo una funzione che simula il lancio di un dado a sei facce, restituendo un valore casuale tra 1 e 6.\n\n# Funzione per simulare il lancio di un dado\nroll_die &lt;- function() {\n  sample(1:6, size = 1)\n}\n\nPossiamo ora definire una funzione che calcola la somma dei valori di due dadi lanciati simultaneamente. La funzione accetta come argomento il numero di ripetizioni da effettuare e restituisce un vettore contenente i risultati.\n\n# Funzione per simulare il lancio di due dadi per n volte\nroll_two_dice &lt;- function(n) {\n  map_dbl(1:n, ~ roll_die() + roll_die())\n}\n\nUtilizziamo la funzione appena definita per simulare 100.000 lanci di due dadi. Memorizziamo i risultati in un oggetto res e visualizziamo i primi 20 valori.\n\n# Numero di simulazioni\nnrolls &lt;- 100000\n\n# Simula i risultati del lancio di due dadi\nres &lt;- roll_two_dice(nrolls)\n\n# Visualizza i primi 20 risultati\ncat(res[1:20], \"\\n\")\n#&gt; 6 2 6 4 5 6 10 4 4 4 9 10 6 7 3 8 9 6 10 7\n\nUtilizzando il tidyverse, possiamo creare un DataFrame contenente i risultati della simulazione e calcolare la distribuzione empirica delle probabilità. Per fare ciò, calcoliamo le frequenze assolute dei risultati, le normalizziamo dividendo per il numero totale di simulazioni e assicuriamo che siano rappresentati tutti i possibili valori (da 2 a 12).\n\n# Converti i risultati in un DataFrame (tibble)\ndf &lt;- tibble(y = res)\n\n# Calcola la distribuzione empirica delle probabilità\nempirical_probs &lt;- df %&gt;%\n  count(y) %&gt;%                             # Calcola le frequenze assolute\n  complete(y = 2:12, fill = list(n = 0)) %&gt;% # Assicura che tutti i valori siano inclusi\n  mutate(prob = n / nrolls)                # Calcola le probabilità relative\n\n# Visualizza la distribuzione empirica\nempirical_probs %&gt;%\n  dplyr::select(y, prob)\n#&gt; # A tibble: 11 × 2\n#&gt;       y   prob\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1     2 0.0282\n#&gt; 2     3 0.0566\n#&gt; 3     4 0.0849\n#&gt; 4     5 0.111 \n#&gt; 5     6 0.139 \n#&gt; 6     7 0.165 \n#&gt; # ℹ 5 more rows\n\nIl risultato finale è una tabella che mostra i valori possibili (da 2 a 12) e la loro probabilità empirica stimata. Questa distribuzione empirica dovrebbe essere molto simile alla distribuzione teorica, specialmente considerando un numero elevato di simulazioni.\nQuesto approccio dimostra come sia possibile utilizzare la simulazione per approssimare distribuzioni di probabilità, una tecnica particolarmente utile quando la soluzione analitica non è immediatamente disponibile.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/05_random_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "25  Variabili casuali",
    "section": "25.9 Informazioni sull’Ambiente di Sviluppo",
    "text": "25.9 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html",
    "href": "chapters/probability/06_expval_var.html",
    "title": "26  Proprietà delle variabili casuali",
    "section": "",
    "text": "26.1 Introduzione\nPrerequisiti\nPrima di affrontare il presente capitolo, è essenziale leggere la sezione ?sec-calculus.\nConcetti e Competenze Chiave\nPreparazione del Notebook\nSintetizzare la distribuzione di una variabile casuale attraverso indicatori caratteristici è spesso molto utile. Questi indicatori consentono di cogliere le principali proprietà della distribuzione, come la posizione centrale (ovvero il “baricentro”) e la variabilità (ossia la dispersione attorno al centro). In questo modo, è possibile ottenere una descrizione sintetica e significativa della distribuzione di probabilità della variabile casuale.\nIn questo capitolo, introdurremo i concetti fondamentali di valore atteso e varianza di una variabile casuale, che sono strumenti essenziali per comprendere e riassumere le proprietà di una distribuzione probabilistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#valore-atteso",
    "href": "chapters/probability/06_expval_var.html#valore-atteso",
    "title": "26  Proprietà delle variabili casuali",
    "section": "26.2 Valore Atteso",
    "text": "26.2 Valore Atteso\nQuando vogliamo comprendere il comportamento tipico di una variabile casuale, ci interessa spesso determinare il suo “valore tipico”. Tuttavia, questa nozione può essere interpretata in diversi modi:\n\nMedia: La somma dei valori divisa per il numero dei valori.\nMediana: Il valore centrale della distribuzione, quando i dati sono ordinati in senso crescente o decrescente.\nModa: Il valore che si verifica con maggiore frequenza.\n\nAd esempio, per il set di valori \\(\\{3, 1, 4, 1, 5\\}\\), la media è \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana è 3, e la moda è 1. Tuttavia, quando ci occupiamo di variabili casuali, anziché di semplici sequenze di numeri, diventa necessario chiarire cosa intendiamo per “valore tipico” in questo contesto. Questo ci porta alla definizione formale del valore atteso.\n\nDefinizione 26.1 Sia \\(X\\) una variabile casuale discreta che assume i valori \\(x_1, \\dots, x_n\\) con probabilità \\(P(X = x_i) = p(x_i)\\). Il valore atteso di \\(X\\), denotato con \\(\\mathbb{E}(X)\\), è definito come:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n x_i \\cdot p(x_i).\n\\]\n\nIn altre parole, il valore atteso (noto anche come speranza matematica o aspettazione) di una variabile casuale è la somma di tutti i valori che la variabile può assumere, ciascuno ponderato dalla probabilità con cui esso si verifica.\n\nEsempio 26.1 Calcoliamo il valore atteso della variabile casuale \\(X\\) corrispondente al lancio di una moneta equilibrata, dove testa corrisponde a \\(X = 1\\) e croce corrisponde a \\(X = 0\\):\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{2} x_i \\cdot P(x_i) = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = 0.5.\n\\]\n\n\nEsempio 26.2 Calcoliamo il valore atteso della variabile casuale \\(X\\) che rappresenta la somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\nCome abbiamo visto nel ?sec-prob-intro-random-var, \\(X\\) può assumere i valori [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] con una distribuzione di massa di probabilità pari a [1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36]. Applicando la formula del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{11} x_i \\cdot P(x_i) = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + \\dots + 12 \\cdot \\frac{1}{36} = 7.0.\n\\]\n\n\nEsempio 26.3 Vediamo ora come eseguire i calcoli del valore atteso utilizzando R. Per prima cosa, definiamo i valori della variabile casuale:\n\nx &lt;- 2:12\nx\n#&gt;  [1]  2  3  4  5  6  7  8  9 10 11 12\n\nSuccessivamente, calcoliamo la distribuzione di massa della variabile casuale.\n\n# Definire il range dei valori dei dadi\nr &lt;- 1:6\nsample &lt;- expand.grid(i = r, j = r)  # Tutte le combinazioni dei valori dei due dadi\n\n# Calcolare la distribuzione di probabilità\npx &lt;- numeric()\n\nfor (sum_value in 2:12) {\n  event &lt;- subset(sample, i + j == sum_value)  # Filtra le combinazioni che sommano a 'sum_value'\n  px &lt;- c(px, nrow(event) / nrow(sample))  # Calcola la probabilità\n}\n\npx\n#&gt;  [1] 0.02777778 0.05555556 0.08333333 0.11111111 0.13888889 0.16666667\n#&gt;  [7] 0.13888889 0.11111111 0.08333333 0.05555556 0.02777778\n\nOra, possiamo calcolare il valore atteso di \\(X\\) utilizzando la formula del valore atteso per variabili casuali discrete:\n\nex &lt;- sum(x * px)\nround(ex, 3)\n#&gt; [1] 7\n\nIn alternativa, possiamo utilizzare un approccio più diretto utilizzando le funzioni per la definizione di distribuzioni discrete in R. In questo caso, definiamo manualmente la distribuzione:\n\nx &lt;- 2:12\npx &lt;- c(1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36)\n\n# Calcoliamo il valore atteso direttamente:\nx_ev &lt;- sum(x * px)\nround(x_ev, 3)\n#&gt; [1] 7\n\nQuesti metodi dimostrano come sia possibile calcolare il valore atteso di una variabile casuale sia attraverso un approccio diretto, sia utilizzando R.\n\n\n26.2.1 Interpretazione\nIl valore atteso di una variabile casuale corrisponde alla media aritmetica di un ampio numero di realizzazioni indipendenti della variabile stessa.\nPer chiarire questo concetto, consideriamo nuovamente l’esempio del lancio di due dadi bilanciati a sei facce, dove la variabile casuale \\(X\\) rappresenta la “somma dei due dadi”. Per interpretare il valore atteso, possiamo simulare un grande numero di realizzazioni indipendenti di \\(X\\) utilizzando la funzione np.random.choice() della libreria NumPy. Questa funzione permette di generare campioni casuali basati sui valori della variabile casuale, sul numero di ripetizioni indipendenti (qui 1.000.000) e sulla distribuzione di massa di probabilità associata:\n\nset.seed(123)  # Per rendere i risultati riproducibili\nx_samples &lt;- sample(x, size = 1e6, replace = TRUE, prob = px)\n\nL’istruzione sample(x, size = 1e6, replace = TRUE, prob = px)) utilizza R per generare un array di 1.000.000 di elementi (specificato dal parametro size), selezionati casualmente dall’array x secondo le probabilità specificate nell’array px.\nQuando il numero di realizzazioni indipendenti è sufficientemente grande, la media aritmetica dei campioni generati si avvicina al valore atteso della variabile casuale:\n\nmean(x_samples) |&gt;\n  round(3)\n#&gt; [1] 6.998\n\nQuesto risultato conferma che, con un numero elevato di simulazioni, la media aritmetica dei valori ottenuti fornisce una buona approssimazione del valore atteso teorico di \\(X\\).\n\n\n26.2.2 Proprietà del Valore Atteso\nUna delle proprietà più importanti del valore atteso è la sua linearità: il valore atteso della somma di due variabili casuali è uguale alla somma dei loro rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{26.1}\\]\nQuesta proprietà, espressa dalla formula sopra, è intuitiva quando \\(X\\) e \\(Y\\) sono variabili casuali indipendenti, ma è valida anche nel caso in cui \\(X\\) e \\(Y\\) siano correlate.\nInoltre, se moltiplichiamo una variabile casuale per una costante \\(c\\), il valore atteso del prodotto è uguale alla costante moltiplicata per il valore atteso della variabile casuale:\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{26.2}\\]\nQuesta proprietà ci dice che una costante può essere “estratta” dall’operatore di valore atteso, e si applica a qualunque numero di variabili casuali.\nUn’altra proprietà significativa riguarda il prodotto di variabili casuali indipendenti. Se \\(X\\) e \\(Y\\) sono indipendenti, allora il valore atteso del loro prodotto è uguale al prodotto dei loro valori attesi:\n\\[\n\\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{26.3}\\]\nInfine, consideriamo la media aritmetica \\(\\bar{X} = \\frac{X_1 + \\ldots + X_n}{n}\\) di \\(n\\) variabili casuali indipendenti con la stessa distribuzione e con valore atteso \\(\\mu\\). Il valore atteso della media aritmetica è:\n\\[\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\left(\\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n)\\right) = \\frac{1}{n} \\cdot n \\cdot \\mathbb{E}(X) = \\mu.\n\\]\nQuesto risultato conferma che la media aritmetica di un campione di variabili casuali indipendenti ha lo stesso valore atteso della distribuzione originaria, rendendo il valore atteso uno strumento cruciale per l’analisi statistica e probabilistica.\n\nEsempio 26.4 Consideriamo il seguente esperimento casuale. Sia \\(Y\\) il numero che si ottiene dal lancio di un dado equilibrato a sei facce e \\(Y\\) il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di \\(X+Y\\).\nPer risolvere il problema iniziamo a costruire lo spazio campione dell’esperimento casuale.\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avrà la stessa probabilità di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) è dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nSi ottiene lo stesso risultato usando l’Equazione 26.1:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\n\n\nEsempio 26.5 Svolgiamo ora l’esercizio in R\n\ncoin &lt;- 0:1  # Valori della moneta: testa (0) e croce (1)\ndie &lt;- 1:6   # Valori del dado: da 1 a 6\n\n# Creazione del campione come combinazione di valori (moneta, dado)\nsample &lt;- expand.grid(coin = coin, die = die)\nprint(sample)\n#&gt;    coin die\n#&gt; 1     0   1\n#&gt; 2     1   1\n#&gt; 3     0   2\n#&gt; 4     1   2\n#&gt; 5     0   3\n#&gt; 6     1   3\n#&gt; 7     0   4\n#&gt; 8     1   4\n#&gt; 9     0   5\n#&gt; 10    1   5\n#&gt; 11    0   6\n#&gt; 12    1   6\n\n\npx &lt;- numeric()  # Vettore per memorizzare le probabilità\n\nfor (i in 1:7) {\n  # Filtrare le combinazioni in cui la somma è uguale a 'i'\n  event &lt;- subset(sample, coin + die == i)\n  # Calcolare la probabilità\n  prob &lt;- nrow(event) / nrow(sample)\n  px &lt;- c(px, prob)\n  \n  # Stampare la probabilità\n  cat(sprintf(\"P(X + Y = %d) = %d / %d\\n\", i, nrow(event), nrow(sample)))\n}\n#&gt; P(X + Y = 1) = 1 / 12\n#&gt; P(X + Y = 2) = 2 / 12\n#&gt; P(X + Y = 3) = 2 / 12\n#&gt; P(X + Y = 4) = 2 / 12\n#&gt; P(X + Y = 5) = 2 / 12\n#&gt; P(X + Y = 6) = 2 / 12\n#&gt; P(X + Y = 7) = 1 / 12\n\n\nx &lt;- 1:7  # Valori della variabile casuale (somma di moneta e dado)\nexpected_value &lt;- sum(x * px)\nexpected_value\n#&gt; [1] 4\n\n\n\nEsempio 26.6 Consideriamo le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso di \\(Z = X \\cdot Y\\).\nLa distribuzione di probabilità congiunta \\(P(X, Y)\\) è fornita nella tabella seguente.\n\n\n\n\\(x /\\ y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l’Equazione 26.3. Infatti, il valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) è\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerciò\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\n\n\n\n26.2.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(X\\), il valore atteso è definito come:\n\\[\n\\mathbb{E}(X) = \\int_{-\\infty}^{+\\infty} x \\cdot p(x) \\, \\mathrm{d}x.\n\\]\nAnche in questo contesto, il valore atteso rappresenta una media ponderata dei valori di \\(x\\), dove ogni possibile valore di \\(x\\) è ponderato in base alla densità di probabilità \\(p(x)\\).\nL’integrale può essere interpretato analogamente a una somma continua, in cui \\(x\\) rappresenta la posizione delle barre infinitamente strette di un istogramma, e \\(p(x)\\) rappresenta l’altezza di tali barre. La notazione \\(\\int_{-\\infty}^{+\\infty}\\) indica che si sta sommando il contributo di ogni valore possibile di \\(x\\) lungo l’intero asse reale.\nQuesta interpretazione rende chiaro come l’integrale calcoli una somma ponderata che si estende su tutti i possibili valori di \\(x\\), fornendo una misura centrale della distribuzione della variabile casuale continua. Per ulteriori dettagli sulla notazione dell’integrale, si veda l’?sec-calculus.\n\n26.2.3.1 Moda\nUn’altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda di \\(Y\\) individua il valore \\(y\\) più plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densità \\(p(y)\\):\n\\[\nMo(Y) = \\text{argmax}_y p(y).\n\\tag{26.4}\\]\n\n\n\n\n\n\nNota\n\n\n\nLa notazione \\(\\text{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#varianza",
    "href": "chapters/probability/06_expval_var.html#varianza",
    "title": "26  Proprietà delle variabili casuali",
    "section": "26.3 Varianza",
    "text": "26.3 Varianza\nDopo il valore atteso, la seconda proprietà più importante di una variabile casuale è la varianza.\n\nDefinizione 26.2 Se \\(X\\) è una variabile casuale discreta con distribuzione \\(p(x)\\), la varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), è definita come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\tag{26.5}\\]\n\nIn altre parole, la varianza misura la deviazione media quadratica dei valori della variabile rispetto alla sua media. Se denotiamo il valore atteso di \\(X\\) con \\(\\mu = \\mathbb{E}(X)\\), la varianza \\(\\mathbb{V}(X)\\) diventa il valore atteso di \\((X - \\mu)^2\\).\n\n26.3.1 Interpretazione della Varianza\nLa varianza rappresenta una misura della “dispersione” dei valori di \\(X\\) intorno al suo valore atteso. Quando calcoliamo la varianza, stiamo effettivamente misurando quanto i valori di \\(X\\) tendono a differire dalla media \\(\\mu\\).\nPer capire meglio, consideriamo la variabile casuale \\(X - \\mathbb{E}(X)\\), detta scarto o deviazione dalla media. Questa variabile rappresenta le “distanze” tra i valori di \\(X\\) e il valore atteso \\(\\mathbb{E}(X)\\). Tuttavia, poiché lo scarto può essere positivo o negativo, la media dello scarto è sempre zero, il che lo rende inadatto a quantificare la dispersione.\nPer risolvere questo problema, eleviamo al quadrato gli scarti, ottenendo \\((X - \\mathbb{E}(X))^2\\), che rende tutte le deviazioni positive. La varianza è quindi la media di questi scarti al quadrato, fornendo una misura efficace della dispersione complessiva dei valori di \\(X\\) rispetto alla sua media.\nQuesto concetto è fondamentale per comprendere la variabilità di una distribuzione e per applicare strumenti statistici che richiedono una conoscenza approfondita della distribuzione dei dati.\n\nEsempio 26.7 Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\nLa variabile casuale \\(S\\) ha la seguente distribuzione di probabilità:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n\\]\n\n\nEsempio 26.8 Svolgiamo l’esercizio in R\n\n# Definire i valori di x e le loro probabilità px\nx &lt;- 2:12\npx &lt;- c(\n  1 / 36, 2 / 36, 3 / 36, 4 / 36, 5 / 36, 6 / 36,\n  5 / 36, 4 / 36, 3 / 36, 2 / 36, 1 / 36\n)\n\n# Calcolare il valore atteso\nex &lt;- sum(x * px)\nex\n#&gt; [1] 7\n\nApplichiamo l’Equazione 26.5:\n\n# Calcolo della varianza utilizzando la definizione\nvariance &lt;- sum((x - ex)^2 * px)\nvariance\n#&gt; [1] 5.833333\n\nUsiamo la funzione var() di rv_discrete:\n\n# Calcolo della varianza con pesi\nvariance_check &lt;- weighted.mean((x - ex)^2, w = px)\nvariance_check\n#&gt; [1] 5.833333\n\n\n\n\n26.3.2 Formula Alternativa per la Varianza\nEsiste un metodo più semplice e diretto per calcolare la varianza di una variabile casuale \\(X\\):\n\\[\n\\begin{align}\n\\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big] &= \\mathbb{E}\\big(X^2 - 2Y\\mathbb{E}(X) + \\mathbb{E}(X)^2\\big) \\notag\\\\\n&= \\mathbb{E}(X^2) - 2\\mathbb{E}(Y)\\mathbb{E}(X) + \\mathbb{E}(X)^2,\n\\end{align}\n\\]\ndove \\(\\mathbb{E}(X)\\) è una costante. Semplificando ulteriormente, otteniamo:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(X)\\big)^2.\n\\tag{26.6}\\]\nIn altre parole, la varianza è data dalla differenza tra la media dei quadrati dei valori di \\(X\\) e il quadrato della media di \\(X\\).\nQuesta formula è utile perché permette di calcolare la varianza senza dover prima determinare lo scarto quadratico medio per ciascun valore di \\(X\\). Invece, si può calcolare direttamente la media dei quadrati e sottrarre il quadrato della media, il che spesso semplifica i calcoli e riduce il rischio di errori.\n\nEsempio 26.9 Consideriamo la variabile casuale \\(X\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\nIl valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(X) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(X^2\\) è\n\\[\n\\mathbb{E}(X^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\n\n\nEsempio 26.10 Svolgiamo l’esercizio in R:\n\n# Definire i valori di x e le probabilità px\nx &lt;- c(0, 1)\npx &lt;- c(0.2, 0.8)\n\n# Calcolare il risultato\nresult &lt;- sum(x^2 * px) - (sum(x * px))^2\nresult\n#&gt; [1] 0.16\n\n\n\n\n26.3.3 Proprietà\nSegno della varianza. La varianza di una variabile aleatoria non è mai negativa, ed è zero solamente quando la variabile assume un solo valore.\nInvarianza per traslazione. La varianza è invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n\\[\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n\\]\nDimostrazione. Iniziamo a scrivere\n\\[\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n\\]\nQuindi\n\\[\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n\\]\nEsaminiamo una dimostrazione numerica.\n\n# Definire i valori di x\nx &lt;- c(2, 1, 4, 7)\n\n# Calcolare y\ny &lt;- 100 + 2 * x\n\n# Verificare la relazione tra le varianze\nresult &lt;- var(y) == 2^2 * var(x)\nresult\n#&gt; [1] TRUE\n\nVarianza della somma di due variabili indipendenti. La varianza della somma di due variabili indipendenti o anche solo incorrelate è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione. Se \\(\\mathbb{E}(X) = \\mathbb{E}(Y) = 0\\), allora \\(\\mathbb{E}(X+Y) = 0\\) e\n\\[\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).\\]\nSiccome le variabili sono indipendenti risulta \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0\\).\nVarianza della differenza di due variabili indipendenti. La varianza della differenza di due variabili indipendenti è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione.\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nVarianza della somma di due variabili non indipendenti. Se \\(X\\) e \\(Y\\) non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n\\]\ndove \\(Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nUna dimostrazione numerica di questo principio è fornita sotto.\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolare la varianza di x + y con ddof = 0\nvar_x_y &lt;- mean((x + y - mean(x + y))^2)\nvar_x_y\n#&gt; [1] 35.25\n\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolo della varianza combinata\nresult &lt;- mean((x - mean(x))^2) + \n          mean((y - mean(y))^2) + \n          2 * cov(x, y) * (length(x) - 1) / length(x)\nresult\n#&gt; [1] 35.25\n\nVarianza della media di variabili indipendenti. La media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione, ha varianza\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n\\]\nIl principio precedente è illustrato dalla seguente simulazione.\n\n# Creare la popolazione\nset.seed(123)  # Per riproducibilità\npopulation &lt;- rnorm(10000, mean = 50, sd = 10)\n\n# Definire dimensione del campione e numero di campioni\nsample_size &lt;- 30\nnum_samples &lt;- 100000\n\n# Creare un vettore per memorizzare le medie campionarie\nsample_means &lt;- numeric(num_samples)\n\n# Generare i campioni e calcolare le medie\nfor (i in 1:num_samples) {\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  sample_means[i] &lt;- mean(sample)\n}\n\n# Calcolare la varianza delle medie campionarie\nsampling_dist_mean_var &lt;- var(sample_means) * ((num_samples - 1) / num_samples)  # ddof = 0\nsampling_dist_mean_var\n#&gt; [1] 3.330581\n\nIl valore teorico della varianza della distribuzione campionaria della media è\n\n10^2 / 30\n#&gt; [1] 3.333333\n\n\n\n26.3.4 Variabili casuali continue\nPer una variabile casuale continua \\(X\\), la varianza è definita come:\n\\[\n\\mathbb{V}(X) = \\int_{-\\infty}^{+\\infty} \\large[x - \\mathbb{E}(X)\\large]^2 p(x) \\,\\operatorname {d}\\!x.\n\\tag{26.7}\\]\nAnalogamente al caso discreto, la varianza di una variabile casuale continua \\(X\\) una misura della dispersione, ovvero la “distanza” media quadratica attesa dei valori \\(x\\) rispetto alla loro media \\(\\mathbb{E}(X)\\). In altre parole, la varianza quantifica quanto i valori della variabile casuale si discostano tipicamente dal loro valore medio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#deviazione-standard",
    "href": "chapters/probability/06_expval_var.html#deviazione-standard",
    "title": "26  Proprietà delle variabili casuali",
    "section": "26.4 Deviazione Standard",
    "text": "26.4 Deviazione Standard\nQuando si lavora con le varianze, i valori sono elevati al quadrato, il che può rendere i numeri significativamente più grandi (o più piccoli) rispetto ai dati originali. Per riportare questi valori all’unità di misura della scala originale, si prende la radice quadrata della varianza. Il risultato ottenuto è chiamato deviazione standard ed è comunemente indicato con la lettera greca \\(\\sigma\\).\n\nDefinizione 26.3 La deviazione standard, o scarto quadratico medio, è definita come la radice quadrata della varianza:\n\\[\n\\sigma_X = \\sqrt{\\mathbb{V}(X)}.\n\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale fornisce una misura della dispersione, ossia la “distanza” tipica o prevista dei valori \\(x\\) rispetto alla loro media.\n\nEsempio 26.11 Per i dadi equilibrati dell’esempio precedente, la deviazione standard della variabile casuale \\(S\\) è pari a \\(\\sqrt{5.833} = 2.415\\). Questo valore indica quanto i risultati della somma dei due dadi tendono a variare attorno alla loro media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#standardizzazione",
    "href": "chapters/probability/06_expval_var.html#standardizzazione",
    "title": "26  Proprietà delle variabili casuali",
    "section": "26.5 Standardizzazione",
    "text": "26.5 Standardizzazione\n\nDefinizione 26.4 Data una variabile casuale \\(X\\), si dice variabile standardizzata di \\(X\\) l’espressione\n\\[\nZ = \\frac{X - \\mathbb{E}(X)}{\\sigma_X}.\n\\tag{26.8}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#il-teorema-di-chebyshev",
    "href": "chapters/probability/06_expval_var.html#il-teorema-di-chebyshev",
    "title": "26  Proprietà delle variabili casuali",
    "section": "26.6 Il Teorema di Chebyshev",
    "text": "26.6 Il Teorema di Chebyshev\nIl Teorema di Chebyshev ci permette di stimare la probabilità che una variabile aleatoria si discosti dal suo valore atteso (media) di una certa quantità. In altre parole, ci fornisce un limite superiore alla probabilità che una variabile aleatoria assuma valori “estremi”.\nIl teorema di Chebyshev afferma che, per qualsiasi variabile aleatoria X con media E(X) e varianza Var(X), e per qualsiasi numero reale k &gt; 0, si ha:\n\\[\nP(|X - E(X)| ≥ kσ) ≤ 1/k^2,\n\\]\ndove:\n\nP(|X - E(X)| ≥ kσ) è la probabilità che lo scarto assoluto tra X e la sua media sia maggiore o uguale a k volte la deviazione standard (σ).\nσ è la radice quadrata della varianza, ovvero la deviazione standard.\n\nCosa ci dice questo teorema?\n\nLimite superiore: Il teorema ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di più di k deviazioni standard.\nQualsiasi distribuzione: La bellezza di questo teorema è che vale per qualsiasi distribuzione di probabilità, a patto che la media e la varianza esistano.\nUtilizzo: Il teorema di Chebyshev è molto utile quando non conosciamo la distribuzione esatta di una variabile aleatoria, ma conosciamo la sua media e la sua varianza.\n\nIn sintesi, il teorema di Chebyshev ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di una certa quantità, in base alla sua varianza. Il teorema di Chebyshev ci permette quindi di fare inferenze sulla distribuzione di una variabile aleatoria anche quando abbiamo informazioni limitate.\n\nEsempio 26.12 Supponiamo di avere una variabile aleatoria X con media 100 e varianza 25. Vogliamo stimare la probabilità che X assuma valori al di fuori dell’intervallo [90, 110]. In questo caso, k = 2 (poiché 10 è uguale a 2 volte la deviazione standard, che è 5). Applicando il teorema di Chebyshev, otteniamo:\nP(|X - 100| ≥ 10) ≤ 1/2^2 = 0.25\nQuindi, possiamo affermare con certezza che al massimo il 25% dei valori di X saranno al di fuori dell’intervallo [90, 110].",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#momenti-di-variabili-casuali",
    "href": "chapters/probability/06_expval_var.html#momenti-di-variabili-casuali",
    "title": "26  Proprietà delle variabili casuali",
    "section": "26.7 Momenti di variabili casuali",
    "text": "26.7 Momenti di variabili casuali\n\nDefinizione 26.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densità \\(p(x)\\), la quantità\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{26.9}\\]\nSe \\(X\\) è una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i),\n\\tag{26.10}\\]\ndove:\n\n\\(E(X^q)\\) rappresenta il valore atteso di \\(X\\) elevato alla \\(q\\)-esima potenza.\n\\(x_i\\) sono i possibili valori della variabile discreta.\n\\(P(x_i)\\) è la probabilità associata a ciascun valore discreto.\n\n\nI momenti sono parametri statistici che forniscono informazioni importanti sulle caratteristiche di una variabile casuale. Tra questi, i più noti e utilizzati sono:\n\nIl momento del primo ordine (\\(q\\) = 1): corrisponde al valore atteso (o media) della variabile casuale \\(X\\).\nIl momento del secondo ordine (\\(q\\) = 2): quando calcolato rispetto alla media, corrisponde alla varianza.\n\nPer i momenti di ordine superiore al primo, è comune calcolarli rispetto al valore medio di \\(X\\). Questo si ottiene applicando una traslazione: \\(x_0 = x − \\mathbb{E}(X)\\), dove \\(x_0\\) rappresenta lo scarto dalla media. In particolare, il momento centrale del secondo ordine, calcolato con questa traslazione, corrisponde alla definizione di varianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#alcuni-esempi-in-r",
    "href": "chapters/probability/06_expval_var.html#alcuni-esempi-in-r",
    "title": "26  Proprietà delle variabili casuali",
    "section": "26.8 Alcuni esempi in R",
    "text": "26.8 Alcuni esempi in R\nIn R, possiamo calcolare il valore atteso e la varianza di variabili casuali discrete utilizzando vettori di valori e probabilità.\nConsideriamo una variabile casuale \\(X\\) che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilità: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\nx &lt;- 0:6\nprint(x)\n#&gt; [1] 0 1 2 3 4 5 6\n\nIl vettore px conterrà le probabilità associate ai valori x:\n\npx &lt;- c(0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)\nprint(px)\n#&gt; [1] 0.1 0.2 0.3 0.1 0.1 0.0 0.2\n\nControlliamo che la somma sia 1:\n\nsum(px)\n#&gt; [1] 1\n\nCalcoliamo il valore atteso di \\(X\\) implementando la formula del valore atteso utilizzando i vettori x e px:\n\nx_ev &lt;- sum(x * px)\nx_ev\n#&gt; [1] 2.7\n\nCalcoliamo la varianza di \\(X\\) usando i vettori x e px:\n\nx_var &lt;- sum((x - x_ev)^2 * px)\nx_var\n#&gt; [1] 3.81\n\nCalcoliamo la deviazione standard di \\(X\\) prendendo la radice quadrata della varianza:\n\nx_sd &lt;- sqrt(x_var)\nx_sd\n#&gt; [1] 1.951922\n\nPer rappresentare graficamente la distribuzione di massa, possiamo usare ggplot2:\n\ndf &lt;- data.frame(x = x, pmf = px)\nggplot(df, aes(x = x, y = pmf)) +\n  geom_point(color = \"#832F2B\", size = 3) +\n  geom_segment(aes(xend = x, yend = 0), linewidth = 1) +\n  labs(title = \"Distribuzione di massa di probabilità\", \n       x = \"Valori\", y = \"Probabilità\")\n\n\n\n\n\n\n\n\nQuesto codice calcola il valore atteso, la varianza e la deviazione standard di una variabile casuale discreta e rappresenta graficamente la distribuzione di massa, tutto in R.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#riflessioni-conclusive",
    "href": "chapters/probability/06_expval_var.html#riflessioni-conclusive",
    "title": "26  Proprietà delle variabili casuali",
    "section": "26.9 Riflessioni Conclusive",
    "text": "26.9 Riflessioni Conclusive\nIn conclusione, i concetti di valore atteso e varianza sono fondamentali per comprendere il comportamento delle variabili casuali. Il valore atteso fornisce una misura centrale, rappresentando il “valore tipico” che ci si aspetta di osservare, mentre la varianza quantifica la dispersione dei valori attorno a questa media, offrendo una visione più completa della distribuzione. Questi strumenti sono essenziali per l’analisi e la modellizzazione statistica, fornendo le basi per valutare e interpretare la variabilità nei fenomeni aleatori.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/06_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "26  Proprietà delle variabili casuali",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.0       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html",
    "href": "chapters/probability/07_bayes_theorem.html",
    "title": "27  Il teorema di Bayes",
    "section": "",
    "text": "27.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nIl teorema di Bayes offre una soluzione ottimale ai problemi induttivi, che spaziano dall’identificazione della struttura tridimensionale del mondo basata su dati sensoriali limitati, all’inferenza dei pensieri altrui a partire dal loro comportamento. Questa regola si rivela particolarmente utile in situazioni in cui i dati osservati sono insufficienti per distinguere in modo definitivo tra diverse ipotesi.\nNonostante ciò, tutte le previsioni basate su questo metodo mantengono un certo grado di incertezza. Anche se l’universo fosse completamente deterministico, la nostra conoscenza di esso rimarrebbe imperfetta: non possiamo conoscere la posizione e lo stato di ogni singola particella che lo compone. Le informazioni a nostra disposizione sono inevitabilmente parziali e imprecise, ottenute attraverso i nostri sensi limitati.\nLa vita reale non è paragonabile a una partita di scacchi, un gioco con informazioni perfette che può essere “risolto” in linea di principio. Assomiglia piuttosto al poker, dove le decisioni vengono prese utilizzando le informazioni limitate a disposizione dei giocatori. Questo capitolo si concentra sull’equazione che ci permette di fare proprio questo: il teorema di Bayes. Esso descrive come modifichiamo le nostre convinzioni riguardo a un’ipotesi in una situazione in cui i dati disponibili non consentono una decisione certa.\nQuesto processo è noto come inferenza induttiva, che ci permette di trarre conclusioni generali da dati specifici e limitati. Il teorema di Bayes fornisce quindi un framework matematico per aggiornare le nostre credenze alla luce di nuove evidenze, permettendoci di prendere decisioni informate in un mondo caratterizzato dall’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#la-regola-di-bayes",
    "href": "chapters/probability/07_bayes_theorem.html#la-regola-di-bayes",
    "title": "27  Il teorema di Bayes",
    "section": "28.1 La Regola di Bayes",
    "text": "28.1 La Regola di Bayes\nL’inferenza bayesiana si basa su una formula fondamentale nota come regola di Bayes. Sebbene possa sembrare un semplice risultato della teoria delle probabilità, la sua applicazione ha implicazioni profonde in molti campi, inclusa la scienza cognitiva e l’apprendimento automatico. Supponiamo di avere due variabili casuali, \\(A\\) e \\(B\\). Un principio della probabilità, chiamato regola della catena, ci consente di esprimere la probabilità congiunta di queste due variabili \\(P(a, b)\\) come il prodotto della probabilità condizionale di \\(A\\) dato \\(B\\), e la probabilità marginale di \\(B\\). In termini formali:\n\\[\nP(a, b) = P(a \\mid b) P(b).\n\\tag{28.1}\\]\nNon vi è nulla di speciale nel trattare \\(A\\) prima di \\(B\\); possiamo infatti anche scrivere:\n\\[\nP(a, b) = P(b \\mid a) P(a).\n\\tag{28.2}\\]\nDalle due equazioni precedenti, possiamo derivare la regola di Bayes riorganizzando i termini:\n\\[\nP(b \\mid a) = \\frac{P(a \\mid b) P(b)}{P(a)}.\n\\tag{28.3}\\]\nQuesta espressione, nota come regola di Bayes, ci permette di calcolare la probabilità condizionale di \\(b\\) dato \\(a\\), usando la probabilità condizionale opposta \\(P(a \\mid b)\\), la probabilità a priori \\(P(b)\\), e la probabilità marginale \\(P(a)\\).\n\n28.1.1 Applicazioni della Regola di Bayes\nLa forza della regola di Bayes si manifesta pienamente quando la applichiamo a un contesto di inferenza. Supponiamo di avere un agente che tenta di inferire quale processo ha generato alcuni dati \\(d\\). Lasciamo che \\(h\\) rappresenti un’ipotesi su tale processo. L’agente usa le probabilità per rappresentare il grado di credenza in \\(h\\) e in altre ipotesi alternative \\(h'\\), e indichiamo con \\(P(h)\\) la probabilità a priori dell’ipotesi \\(h\\), ovvero la credenza che l’agente attribuisce a \\(h\\) prima di osservare i dati.\nA questo punto, l’agente vuole aggiornare questa credenza alla luce dei nuovi dati \\(d\\), ottenendo la probabilità a posteriori \\(P(h \\mid d)\\). Usando la regola di Bayes, possiamo calcolare questa probabilità nel seguente modo:\n\\[\nP(h \\mid d) = \\frac{P(d \\mid h) P(h)}{P(d)}.\n\\tag{28.4}\\]\nQui, \\(P(d \\mid h)\\) rappresenta la verosimiglianza, ovvero la probabilità di osservare i dati \\(d\\) supponendo che l’ipotesi \\(h\\) sia vera. La verosimiglianza gioca un ruolo cruciale nell’aggiornamento delle nostre credenze: essa “ri-pesa” ogni ipotesi in base alla sua capacità di predire i dati osservati.\n\n\n28.1.2 La Marginalizzazione\nLa teoria delle probabilità ci permette anche di calcolare la probabilità marginale associata a una singola variabile sommando o integrando su altre variabili in una distribuzione congiunta. Ad esempio, la probabilità marginale di \\(b\\) è data da:\n\\[\nP(b) = \\sum_a P(a, b).\n\\]\nQuesto processo è chiamato marginalizzazione. Utilizzando questo principio, possiamo riscrivere la regola di Bayes in un formato che include esplicitamente la somma su tutte le ipotesi alternative \\(h' \\in H\\) considerate dall’agente:\n\\[\nP(h \\mid d) = \\frac{P(d \\mid h) P(h)}{\\sum_{h' \\in H} P(d \\mid h') P(h')}.\n\\tag{28.5}\\]\nIn questo caso, \\(H\\) rappresenta l’insieme di tutte le ipotesi possibili, a volte chiamato spazio delle ipotesi, e la somma al denominatore assicura che le probabilità a posteriori siano normalizzate, cioè che la loro somma sia pari a uno.\n\n\n\n\n\n\n\n\n\n\n\n28.1.3 Estensione al Caso Continuo\nQuando le ipotesi non sono discrete ma fanno parte di un continuum, la formula di Bayes assume una forma integrale:\n\\[\nP(h_i \\mid d) = \\frac{P(d \\mid h_i) \\cdot P(h_i)}{\\int P(d \\mid H) \\cdot P(H) \\, dH}.\n\\tag{28.6}\\]\nIn questo caso, l’integrale nel denominatore somma tutte le ipotesi possibili, ponderandole per le loro probabilità a priori e verosimiglianze. Questo permette di aggiornare le credenze anche per ipotesi continue.\n\n\n28.1.4 Componenti Chiave della Formula di Bayes\nLa formula di Bayes si basa su tre elementi principali:\n\nProbabilità a Priori \\(P(h_i)\\): Questa rappresenta la credenza iniziale sull’ipotesi \\(h_i\\), prima di osservare i dati. È una stima preliminare basata su informazioni preesistenti.\nVerosimiglianza \\(P(d \\mid h_i)\\): Indica la probabilità di osservare i dati \\(d\\), dato che l’ipotesi \\(h_i\\) sia vera. Questa componente quantifica quanto l’ipotesi predice correttamente i dati osservati.\nProbabilità a Posteriori \\(P(h_i \\mid d)\\): Questa è la credenza aggiornata in \\(h_i\\), dopo aver considerato l’evidenza \\(d\\). È il prodotto della probabilità a priori e della verosimiglianza, normalizzato in modo che tutte le ipotesi abbiano probabilità totale pari a uno.\n\nIn conclusione, la regola di Bayes fornisce un quadro potente per aggiornare le credenze in modo coerente e sistematico man mano che si accumulano nuove informazioni, permettendo di affinare le nostre decisioni e previsioni.\nGrazie alla regola di Bayes, possiamo aggiornare costantemente le nostre credenze man mano che nuove informazioni diventano disponibili. Questo processo dinamico di aggiornamento ci permette di affinare le nostre convinzioni e le nostre previsioni, rendendo il modello bayesiano particolarmente utile nelle situazioni in cui le informazioni sono incomplete o incerte. Questo approccio non solo ci consente di prendere decisioni più informate, ma ci permette anche di sviluppare modelli più accurati della realtà basati sulle evidenze.\n\n\n28.1.5 Applicazioni dei modelli bayesiani\nCome discusso da Griffiths et al. (2024), negli ultimi anni, i modelli bayesiani hanno acquisito un’importanza crescente in vari campi delle scienze cognitive. Questi modelli sono stati applicati allo studio dell’apprendimento animale (Courville, Daw, & Touretzky, 2006), dell’apprendimento induttivo umano e della generalizzazione (Tenenbaum, Griffiths, & Kemp, 2006), della percezione visiva (Yuille & Kersten, 2006), del controllo motorio (Kording & Wolpert, 2006), della memoria semantica (Steyvers, Griffiths, & Dennis, 2006), dell’acquisizione e del processamento del linguaggio (Chater & Manning, 2006; Xu & Tenenbaum, in press), del ragionamento simbolico (Oaksford & Chater, 2001), dell’apprendimento causale (Steyvers, Tenenbaum, Wagenmakers, & Blum, 2003; Griffiths & Tenenbaum, 2005, 2007a), e della cognizione sociale (Baker, Tenenbaum, & Saxe, 2007), tra molti altri argomenti.\nDietro questi diversi programmi di ricerca emerge una domanda centrale: come fa la mente umana ad andare oltre i dati dell’esperienza? In altre parole, come riesce la mente a costruire modelli complessi e astratti del mondo, partendo solo da dati sparsi e rumorosi, osservati attraverso i nostri sensi? La risposta proposta dall’approccio bayesiano è che la mente umana utilizza un processo di inferenza probabilistica per aggiornare le proprie credenze sulla base delle nuove evidenze, creando così modelli del mondo sempre più accurati e raffinati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#alcuni-esempi",
    "href": "chapters/probability/07_bayes_theorem.html#alcuni-esempi",
    "title": "27  Il teorema di Bayes",
    "section": "28.2 Alcuni esempi",
    "text": "28.2 Alcuni esempi\n\nEsempio 28.1 Il modo più comune per spiegare il teorema di Bayes è attraverso i test medici. Prendiamo come esempio il caso della mammografia e la diagnosi del cancro al seno che abbiamo già discusso in precedenza.\nSupponiamo di avere un test di mammografia con una sensibilità del 90% e una specificità del 90%. Questo significa che:\n\nIn presenza di cancro al seno, la probabilità che il test lo rilevi correttamente è del 90%.\nIn assenza di cancro al seno, la probabilità che il test confermi correttamente l’assenza della malattia è del 90%.\n\nIn altri termini, il test ha un tasso di falsi negativi del 10% e un tasso di falsi positivi anch’esso del 10%.\nDefiniamo due ipotesi:\n\n\\(M^+\\): presenza della malattia\n\\(M^-\\): assenza della malattia\n\nL’evidenza è rappresentata dal risultato positivo di un test di mammografia, che indichiamo con \\(T^+\\).\nApplicando il teorema di Bayes, possiamo calcolare la probabilità di avere il cancro al seno dato un risultato positivo al test, come segue:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)},\n\\]\ndove:\n\n\\(P(M^+ \\mid T^+)\\) è la probabilità di avere il cancro (\\(M^+\\)) dato un risultato positivo al test (\\(T^+\\)).\n\\(P(T^+ \\mid M^+)\\) rappresenta la sensibilità del test, ovvero la probabilità che il test risulti positivo in presenza effettiva del cancro. In questo caso, è pari a 0.90.\n\\(P(M^+)\\) è la probabilità a priori che una persona abbia il cancro, ovvero la prevalenza della malattia nella popolazione.\n\\(P(T^+ \\mid M^-)\\) indica la probabilità di un falso positivo, cioè la probabilità che il test risulti positivo in assenza di cancro. Con una specificità del 90%, questa probabilità si calcola come:\n\\[\nP(T^+ \\mid M^-) = 1 - \\text{Specificità} = 1 - 0.90 = 0.10\n\\]\nQuesto significa che c’è una probabilità del 10% che il test diagnostichi erroneamente la presenza del cancro in una persona sana.\n\\(P(M^-)\\) è la probabilità a priori che una persona non sia affetta da cancro prima di effettuare il test.\n\nQuesta formulazione del teorema di Bayes ci permette di calcolare la probabilità effettiva di avere il cancro al seno, dato un risultato positivo al test di mammografia, tenendo conto sia della sensibilità e specificità del test, sia della prevalenza della malattia nella popolazione.\nInserendo nella formula i del problema, otteniamo:\n\\[\n\\begin{align}\nP(M^+ \\mid T^+) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n&= \\frac{9}{108} \\notag\\\\\n&\\approx 0.083.\\notag\n\\end{align}\n\\]\nI calcoli effettuati evidenziano come, in presenza di una mammografia positiva ottenuta con un test avente sensibilità e specificità pari al 90%, la probabilità di effettiva positività al tumore al seno si attesta intorno all’8.3%. Tale risultato conferma quanto precedentemente ottenuto nel ?sec-cond-prob, attraverso un metodo di calcolo alternativo.\n\n\n28.2.1 Il Valore Predittivo di un Test di Laboratorio\nPer semplicità, possiamo riscrivere il teorema di Bayes in due modi distinti per calcolare ciò che viene chiamato valore predittivo del test positivo e valore predittivo del test negativo.\nLa comprensione di tre elementi è fondamentale per questo calcolo: la prevalenza della malattia, la sensibilità e la specificità del test.\n\nPrevalenza: Si riferisce alla percentuale di individui in una popolazione affetti da una certa malattia in un determinato momento. Viene espressa come percentuale o frazione della popolazione. Per esempio, una prevalenza dello 0,5% indica che su mille persone, cinque sono affette dalla malattia.\nSensibilità: Indica la capacità del test di identificare correttamente la malattia negli individui malati. Viene calcolata come la frazione di veri positivi (individui malati correttamente identificati) sul totale degli individui malati. La formula della sensibilità (\\(Sens\\)) è la seguente:\n\\[ \\text{Sensibilità} = \\frac{TP}{TP + FN}, \\]\ndove \\(TP\\) rappresenta i veri positivi e \\(FN\\) i falsi negativi. Pertanto, la sensibilità misura la probabilità che il test risulti positivo se la malattia è effettivamente presente.\nSpecificità: Misura la capacità del test di riconoscere gli individui sani, producendo un risultato negativo per chi non è affetto dalla malattia. Si calcola come la frazione di veri negativi (individui sani correttamente identificati) sul totale degli individui sani. La specificità (\\(Spec\\)) si definisce come:\n\\[ \\text{Specificità} = \\frac{TN}{TN + FP}, \\]\ndove \\(TN\\) sono i veri negativi e \\(FP\\) i falsi positivi. Così, la specificità rappresenta la probabilità che il test risulti negativo in assenza della malattia.\n\nQuesta tabella riassume la terminologia:\n\n\n\n\n\n\n\n\n\n\n\\(T^+\\)\n\\(T^-\\)\nTotale\n\n\n\n\n\\(M^+\\)\n\\(P(T^+ \\cap M^+)\\)  (Sensibilità)\n\\(P(T^- \\cap M^+)\\)  (1 - Sensibilità)\n\\(P(M^+)\\)\n\n\n\\(M^-\\)\n\\(P(T^+ \\cap M^-)\\)  (1 - Specificità)\n\\(P(T^- \\cap M^-)\\)  (Specificità)\n\\(P(M^-)\\)\n\n\nTotale\n\\(P(T^+)\\)\n\\(P(T^-)\\)\n1\n\n\n\ndove \\(T^+\\) e \\(T^-\\) indicano rispettivamente un risultato positivo o negativo del test, mentre \\(M^+\\) e \\(M^-\\) la presenza o assenza effettiva della malattia. In questa tabella, i totali marginali rappresentano:\n\nTotale per \\(M^+\\) e \\(M^-\\) (ultima colonna): La probabilità totale di avere la malattia (\\(P(M^+)\\)) e la probabilità totale di non avere la malattia (\\(P(M^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilità all’interno di ciascuna riga.\nTotale per \\(T^+\\) e \\(T^-\\) (ultima riga): La probabilità totale di un risultato positivo al test (\\(P(T^+)\\)) e la probabilità totale di un risultato negativo al test (\\(P(T^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilità all’interno di ciascuna colonna.\nTotale generale (angolo in basso a destra): La somma di tutte le probabilità, che per definizione è 1, rappresentando l’intera popolazione o il set di casi considerati.\n\nMediante il teorema di Bayes, possiamo usare queste informazioni per stimare la probabilità post-test di avere o non avere la malattia basandoci sul risultato del test.\nIl valore predittivo positivo (VPP) del test, cioè la probabilità post-test che un individuo sia malato dato un risultato positivo del test, è calcolato come:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)}.\n\\]\novvero,\n\\[ VPP = \\frac{(\\text{Sensibilità} \\times \\text{Prevalenza})}{(\\text{Sensibilità} \\times \\text{Prevalenza}) + (1 - \\text{Specificità}) \\times (1 - \\text{Prevalenza})} \\]\nAnalogamente, il valore predittivo negativo (VPN), che è la probabilità che un individuo non sia malato dato un risultato negativo del test, si calcola come:\n\\[\nP(M^- \\mid T^-) = \\frac{P(T^- \\mid M^-) \\cdot (1 - P(M^+))}{P(T^- \\mid M^-) \\cdot (1 - P(M^+)) + P(T^- \\mid M^+) \\cdot P(M^+)}.\n\\]\novvero,\n\\[ NPV = \\frac{\\text{Specificità} \\cdot (1 - \\text{Prevalenza})}{\\text{Specificità} \\cdot (1 - \\text{Prevalenza}) + (1 - \\text{Sensibilità}) \\cdot \\text{Prevalenza}}. \\]\n\nEsempio 28.2 Implementiamo le formule del valore predittivo positivo e del valore predittivo negativo del test in Python e usiamo gli stessi dati dell’esercizio precedente.\n\npositive_predictive_value_of_diagnostic_test &lt;- function(sens, spec, prev) {\n  (sens * prev) / (sens * prev + (1 - spec) * (1 - prev))\n}\n\nnegative_predictive_value_of_diagnostic_test &lt;- function(sens, spec, prev) {\n  (spec * (1 - prev)) / (spec * (1 - prev) + (1 - sens) * prev)\n}\n\nInseriamo i dati del problema.\n\nsens = 0.9  # sensibilità\nspec = 0.9  # specificità\nprev = 0.01  # prevalenza\n\nIl valore predittivo del test positivo è:\n\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.083\n\nIl valore predittivo del test negativo è:\n\nres_neg &lt;- negative_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M- | T-) = %.3f\\n\", res_neg))\n#&gt; P(M- | T-) = 0.999\n\n\n\nEsempio 28.3 La simulazione seguente ha lo scopo di aiutare a visualizzare il teorema di Bayes, utilizzando come esempio gli stessi dati della mammografia che abbiamo analizzato in precedenza.\n\n# Parametri\nsensitivity &lt;- 0.90  # Sensibilità del test (P(T+ | M+))\nspecificity &lt;- 0.90  # Specificità del test (P(T- | M-))\nprev_cancer &lt;- 0.01  # Prevalenza (P(M+))\n\n# Simulazione per una popolazione di 100.000 persone\nN_mammography &lt;- 100000\n\n# Generazione del campione casuale\nset.seed(123)\noutcome_mammography &lt;- sample(\n  c(\"Cancer\", \"Healthy\"), \n  N_mammography, \n  replace = TRUE, \n  prob = c(prev_cancer, 1 - prev_cancer)\n)\n\n# Conteggio delle persone con e senza cancro\nN_C &lt;- sum(outcome_mammography == \"Cancer\")\nN_H &lt;- sum(outcome_mammography == \"Healthy\")\n\n# Simulazione dei risultati del test\ntest_mammography &lt;- character(N_mammography)\ntest_mammography[outcome_mammography == \"Cancer\"] &lt;- sample(\n  c(\"+\", \"-\"), \n  N_C, \n  replace = TRUE, \n  prob = c(sensitivity, 1 - sensitivity)\n)\ntest_mammography[outcome_mammography == \"Healthy\"] &lt;- sample(\n  c(\"-\", \"+\"), \n  N_H, \n  replace = TRUE, \n  prob = c(specificity, 1 - specificity)\n)\n\n# Creazione di un data frame per memorizzare i risultati\ndf_mammography &lt;- tibble(\n  outcome = outcome_mammography,\n  test = test_mammography\n)\n\n# Creazione di una tabella di contingenza\ncontingency_table_mammography &lt;- df_mammography %&gt;%\n  count(outcome, test) %&gt;%\n  pivot_wider(names_from = test, values_from = n, values_fill = 0)\n\ncontingency_table_mammography\n#&gt; # A tibble: 2 × 3\n#&gt;   outcome   `+`   `-`\n#&gt;   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1 Cancer    911   114\n#&gt; 2 Healthy  9897 89078\n\n\n# Calcolo delle probabilità basate sulla tabella di contingenza\n\n# Veri positivi (cancro e risultato positivo al test)\ntrue_positives &lt;- contingency_table_mammography %&gt;%\n  filter(outcome == \"Cancer\") %&gt;%\n  pull(`+`)\n\n# Falsi positivi (sani e risultato positivo al test)\nfalse_positives &lt;- contingency_table_mammography %&gt;%\n  filter(outcome == \"Healthy\") %&gt;%\n  pull(`+`)\n\n# Frequenza totale dei risultati positivi\ntotal_positives &lt;- true_positives + false_positives\n\n# Applicazione del teorema di Bayes sui dati simulati\nP_M_given_T &lt;- true_positives / total_positives\nP_M_given_T\n#&gt; [1] 0.08428942\n\nUtilizzando i dati della simulazione, la probabilità che una persona abbia il cancro al seno dato un risultato positivo al test è molto vicina al valore teorico calcolato in precedenza (circa 8.3%). Se eseguissimo la simulazione nuovamente, il valore ottenuto potrebbe variare leggermente a causa della casualità intrinseca nel campionamento. Tuttavia, ripetendo la simulazione molte volte, i risultati tenderanno a convergere verso il valore teorico, grazie alla legge dei grandi numeri. Questo conferma che il modello teorico è coerente con i risultati simulati.\n\n\nEsempio 28.4 Poniamoci il problema di capire quanto sia affidabile un test per l’HIV. Per fare questo, utilizzeremo le seguenti informazioni (Petersen, 2024):\n\nTasso di base dell’HIV (P(HIV)): 0.3% (0.003). Questa è la probabilità che una persona nella popolazione generale abbia l’HIV.\nSensibilità del test (P(Test+ HIV)): 95% (0.95). Questa è la probabilità che il test risulti positivo se la persona ha effettivamente l’HIV.\nSpecificità del test (P(Test- ¬HIV)): 99.28% (0.9928). Questa è la probabilità che il test risulti negativo se la persona non ha l’HIV.\n\nCalcolo della probabilità di HIV dato un test positivo.\nPer calcolare la probabilità di avere l’HIV dato un test positivo (P(HIV Test+)), utilizziamo il teorema di Bayes:\n\\[\nP(HIV \\mid Test+) = \\frac{P(Test+ \\mid HIV) \\times P(HIV)}{P(Test+)}.\n\\]\nAbbiamo bisogno di calcolare il denominatore, ovvero la probabilità complessiva di ottenere un test positivo (P(Test+)). Questo valore include sia i veri positivi che i falsi positivi:\n\\[\nP(Test+) = P(Test+ \\mid HIV) \\times P(HIV) + P(Test+ \\mid \\neg HIV) \\times P(\\neg HIV),\n\\]\ndove:\n\n\\(P(Test+ \\mid \\neg HIV) = 1 - P(Test- \\mid \\neg HIV) = 1 - 0.9928 = 0.0072\\) (tasso di falsi positivi),\n\\(P(\\neg HIV) = 1 - P(HIV) = 1 - 0.003 = 0.997\\).\n\nCalcoliamo \\(P(Test+)\\):\n\\[\nP(Test+) = (0.95 \\times 0.003) + (0.0072 \\times 0.997) \\approx 0.010027.\n\\]\nOra possiamo calcolare \\(P(HIV \\mid Test+)\\):\n\\[\nP(HIV \\mid Test+) = \\frac{0.95 \\times 0.003}{0.010027} \\approx 0.2844 \\text{ o 28.44\\%}.\n\\]\nQuindi, se il test risulta positivo, la probabilità di avere l’HIV è circa il 28.44%.\nCalcolo della probabilità di un secondo test positivo.\nDopo un primo test positivo, la probabilità di avere l’HIV è aumentata al 28.44%. Ora calcoleremo la probabilità che un secondo test risulti positivo e la conseguente probabilità di avere l’HIV dopo due test positivi consecutivi.\nPer calcolare \\(P(\\text{Secondo Test+})\\), consideriamo due scenari:\n\nLa persona ha effettivamente l’HIV:\n\nProbabilità: \\(P(HIV \\mid Test+) = 0.2844\\).\nProbabilità di un test positivo: \\(P(\\text{Test+} \\mid HIV) = 0.95\\) (sensibilità del test).\n\nLa persona non ha l’HIV:\n\nProbabilità: \\(P(\\neg HIV \\mid Test+) = 1 - P(HIV \\mid Test+) = 0.7156\\).\nProbabilità di un test positivo: \\(P(\\text{Test+} \\mid \\neg HIV) = 0.0072\\) (tasso di falsi positivi).\n\n\nUtilizziamo la formula della probabilità totale:\n\\[\n\\begin{aligned}\nP(\\text{Secondo Test+}) &= P(\\text{Test+} \\mid HIV) \\times P(HIV \\mid Test+) + \\\\\n&\\quad P(\\text{Test+} \\mid \\neg HIV) \\times P(\\neg HIV \\mid Test+).\n\\end{aligned}\n\\]\nSostituendo i valori:\n\\[\nP(\\text{Secondo Test+}) = (0.95 \\times 0.2844) + (0.0072 \\times 0.7156) \\approx 0.2753.\n\\]\nApplichiamo nuovamente il teorema di Bayes per calcolare la probabilità di avere l’HIV dopo un secondo test positivo:\n\\[\nP(HIV \\mid \\text{Secondo Test+}) = \\frac{P(\\text{Secondo Test+} \\mid HIV) \\times P(HIV \\mid Test+)}{P(\\text{Secondo Test+})}.\n\\]\nSostituendo i valori:\n\\[\nP(HIV \\mid \\text{Secondo Test+}) = \\frac{0.95 \\times 0.2844}{0.2753} \\approx 0.981.\n\\]\nDopo un secondo test positivo, la probabilità di avere l’HIV aumenta significativamente, passando dal 28.44% al 98.1%. Questo aumento drastico dimostra l’importanza di:\n\nConsiderare il tasso di base (prevalenza) nella popolazione.\nAggiornare progressivamente le probabilità con nuove evidenze.\nInterpretare i risultati di test diagnostici multipli in modo bayesiano.\n\nL’analisi evidenzia come l’accumulo di evidenze attraverso test ripetuti, in linea con i principi del teorema di Bayes, possa portare a una stima molto più accurata della probabilità di avere una condizione medica, riducendo significativamente l’incertezza iniziale.\n\n\nEsempio 28.5 Consideriamo ora un altro esempio relativo ai test medici e analizziamo i risultati del test antigenico rapido per il virus SARS-CoV-2 alla luce del teorema di Bayes. Questo test può essere eseguito mediante tampone nasale, tampone naso-orofaringeo o campione di saliva. L’Istituto Superiore di Sanità, nel documento pubblicato il 5 novembre 2020, sottolinea che, fino a quel momento, i dati disponibili sui vari test erano quelli forniti dai produttori: la sensibilità varia tra il 70% e l’86%, mentre la specificità si attesta tra il 95% e il 97%.\nPrendiamo un esempio specifico: nella settimana tra il 17 e il 23 marzo 2023, in Italia, il numero di individui positivi al virus è stato stimato essere di 138.599 (fonte: Il Sole 24 Ore). Questo dato corrisponde a una prevalenza di circa lo 0,2% su una popolazione totale di circa 59 milioni di persone.\n\n prev = 138599 / 59000000\n prev\n#&gt; [1] 0.002349136\n\nL’obiettivo è determinare la probabilità di essere effettivamente affetti da Covid-19, dato un risultato positivo al test antigenico rapido, ossia \\(P(M^+ \\mid T^+)\\). Per raggiungere questo scopo, useremo la formula relativa al valore predittivo positivo del test.\n\n# Calcolo della sensibilità e specificità medie\nsens &lt;- (0.7 + 0.86) / 2  # sensibilità\nspec &lt;- (0.95 + 0.97) / 2 # specificità\n\n# Calcolo del valore predittivo positivo\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.044\n\nPertanto, se il risultato del tampone è positivo, la probabilità di essere effettivamente affetti da Covid-19 è solo del 4.4%.\nSe la prevalenza fosse 100 volte superiore (cioè, pari al 23.5%), la probabilità di avere il Covid-19, dato un risultato positivo del tampone, aumenterebbe notevolmente e sarebbe pari a circa l’86%.\n\n# Calcolo della prevalenza aumentata di 100 volte\nprev &lt;- 138599 / 59000000 * 100\n\n# Calcolo del valore predittivo positivo\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.857\n\nSe il risultato del test fosse negativo, considerando la prevalenza stimata del Covid-19 nella settimana dal 17 al 23 marzo 2023, la probabilità di non essere infetto sarebbe del 99.9%.\n\n# Calcolo della sensibilità, specificità e prevalenza\nsens &lt;- (0.7 + 0.86) / 2  # sensibilità\nspec &lt;- (0.95 + 0.97) / 2  # specificità\nprev &lt;- 138599 / 59000000  # prevalenza\n\n# Calcolo del valore predittivo negativo\nres_neg &lt;- negative_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M- | T-) = %.3f\\n\", res_neg))\n#&gt; P(M- | T-) = 0.999\n\nTuttavia, un’esito del genere non dovrebbe sorprenderci, considerando che la prevalenza della malattia è molto bassa; in altre parole, il risultato negativo conferma una situazione già presunta prima di sottoporsi al test. Il vero ostacolo, specialmente nel caso di malattie rare come il Covid-19 in quel periodo specifico, non risiede tanto nell’asserire l’assenza della malattia quanto piuttosto nel confermarne la presenza.\n\n\nEsempio 28.6 Consideriamo le persone in attesa di un figlio. Il teorema di Bayes gioca un ruolo cruciale nell’interpretazione dei test prenatali non invasivi (NIPT), un esame del sangue materno usato per rilevare anomalie cromosomiche fetali. Sebbene il NIPT sia spesso pubblicizzato con un’accuratezza del 99%, la sua affidabilità varia significativamente a seconda della condizione testata e della popolazione esaminata.\nParametri chiave del NIPT:\n\nSensibilità:\n\nSindrome di Down: 99%\nSindrome di Edwards: 97%\nSindrome di Patau: 91%\n\nSpecificità: circa 99.9% per tutte le condizioni citate\nPrevalenza nelle nascite:\n\nSindrome di Down: 1 su 700 (0.14%)\nSindrome di Edwards: 1 su 5,000 (0.02%)\nSindrome di Patau: 1 su 10,000 (0.01%)\n\n\nNonostante l’alta sensibilità e specificità, il VPP può essere sorprendentemente basso, soprattutto nella popolazione generale. Questo implica che molti risultati positivi potrebbero essere falsi positivi, in particolare per le condizioni più rare.\nPer calcolare il VPP, utilizziamo il teorema di Bayes:\n\\[ VPP = \\frac{(\\text{Sensibilità} \\times \\text{Prevalenza})}{(\\text{Sensibilità} \\times \\text{Prevalenza}) + (1 - \\text{Specificità}) \\times (1 - \\text{Prevalenza})} \\]\nApplicando questa formula alla popolazione generale:\n\nSindrome di Down: \\[ VPP = \\frac{(0.99 \\times 0.0014)}{(0.99 \\times 0.0014) + (1 - 0.999) \\times (1 - 0.0014)} \\approx 58\\% \\]\nSindrome di Edwards: \\[ VPP = \\frac{(0.97 \\times 0.0002)}{(0.97 \\times 0.0002) + (1 - 0.999) \\times (1 - 0.0002)} \\approx 16.2\\% \\]\nSindrome di Patau: \\[ VPP = \\frac{(0.91 \\times 0.0001)}{(0.91 \\times 0.0001) + (1 - 0.999) \\times (1 - 0.0001)} \\approx 8.3\\% \\]\n\nQuesti calcoli rivelano VPP molto bassi, specialmente per condizioni molto rare come la sindrome di Patau. Anche in questo caso, dunque, il teorema di Bayes ci mostra che la probabilità che un risultato positivo sia effettivamente corretto dipende non solo dall’accuratezza del test, ma anche dalla prevalenza della condizione nella popolazione testata. Per questo motivo, il NIPT risulta più affidabile nelle categorie ad alto rischio.\nIn conclusione, mentre il NIPT è uno strumento prezioso per lo screening prenatale, è fondamentale interpretare i risultati con cautela, considerando il contesto specifico di ogni paziente e la prevalenza della condizione nella popolazione di riferimento.\n\n\nEsempio 28.7 Il teorema di Bayes non è rilevante solo in medicina. In ambito legale è presente un fenomeno noto come la Fallacia del Procuratore. La “fallacia del procuratore” è un errore logico che si verifica quando si confonde la probabilità di un evento dato un certo risultato con la probabilità di quel risultato dato l’evento. In ambito legale, si tratta spesso di confondere la probabilità di ottenere un risultato di un test (ad esempio, una corrispondenza del DNA) se una persona è innocente, con la probabilità che una persona sia innocente dato che il test ha mostrato una corrispondenza.\nSupponiamo di avere i seguenti parametri per un test del DNA:\n\nSensibilità: 99% (probabilità di identificare correttamente il colpevole).\nSpecificità: 99.99997% (probabilità di identificare correttamente un innocente).\nPrevalenza: 1 su 65 milioni (probabilità a priori che una persona qualsiasi sia il colpevole, data una popolazione di 65 milioni).\n\nImmaginiamo che ci sia stato un crimine e che un campione di DNA sia stato trovato sulla scena del crimine. Il campione è confrontato con il DNA di una persona nel database.\nSvolgiamo i calcoli:\n\nProbabilità a Priori (Prevalenza):\n\nLa prevalenza \\(P(C)\\) che una persona casuale sia il colpevole è \\(\\frac{1}{65.000.000}\\).\n\nSensibilità e Specificità:\n\nSensibilità \\(P(T+|C) = 0.99\\).\nSpecificità \\(P(T-|I) = 0.9999997\\).\n\nProbabilità del Test Positivo:\n\nProbabilità di ottenere un test positivo \\(P(T+)\\) è la somma della probabilità di ottenere un positivo dai veri colpevoli e dai falsi positivi:\n\n\n\\[ P(T+) = P(T+|C) \\cdot P(C) + P(T+|I) \\cdot P(I), \\]\n\ndove \\(P(T+|I)\\) è \\(1 - \\text{Specificità}\\) e \\(P(I)\\) è la probabilità di essere innocente (\\(1 - P(C)\\)).\n\n\\[ P(T+) = 0.99 \\cdot \\frac{1}{65.000.000} + (1 - 0.9999997) \\cdot \\frac{64.999.999}{65.000.000} \\]\n\\[ P(T+) \\approx 0.99 \\cdot 1.5385 \\times 10^{-8} + 0.0000003 \\cdot 0.9999999 \\]\n\\[ P(T+) \\approx 1.5231 \\times 10^{-8} + 2.9999997 \\times 10^{-7} \\]\n\\[ P(T+) \\approx 3.1523 \\times 10^{-7} \\]\n\nProbabilità Condizionale che il Sospetto sia Colpevole Dato un Test Positivo:\n\nUtilizzando il teorema di Bayes:\n\n\n\\[ P(C|T+) = \\frac{P(T+|C) \\cdot P(C)}{P(T+)} \\]\n\\[ P(C|T+) = \\frac{0.99 \\cdot \\frac{1}{65.000.000}}{3.1523 \\times 10^{-7}} \\]\n\\[ P(C|T+) = \\frac{0.99 \\times 1.5385 \\times 10^{-8}}{3.1523 \\times 10^{-7}} \\]\n\\[ P(C|T+) \\approx 0.0483 \\]\nQuindi, la probabilità che il sospetto sia effettivamente il colpevole, dato che il test del DNA è positivo, è circa 4.83%, nonostante l’alta specificità del test.\nIn sintesi, quando si afferma che c’è solo una probabilità su 3 milioni che il sospetto sia innocente (ovvero la specificità), si commette la fallacia del procuratore. In realtà, la probabilità che il sospetto sia colpevole, data una corrispondenza del DNA, è molto inferiore, come dimostrato nell’esempio numerico (circa 4.83%).\nQuesta fallacia può portare a errori giudiziari perché non si considera la bassa prevalenza del colpevole nella popolazione generale e si confonde la specificità del test con la probabilità condizionale di colpevolezza. In altre parole, non si riconosce che le due domande ‘Quanto è probabile che il DNA di una persona corrisponda al campione, se è innocente?’ e ‘Quanto è probabile che qualcuno sia innocente, dato che il suo DNA corrisponde al campione?’ non sono equivalenti. È come confondere ‘Quanto è probabile che un determinato essere umano sia il papa?’ con ‘Quanto è probabile che il papa sia un essere umano?’.\n\n\nEsempio 28.8 Due dadi equi vengono lanciati e ti viene detto che la somma dei loro punteggi è 9. Qual è la distribuzione a posteriori dei punteggi di ciascun dado? (Questo esempio è tratto da Taylan Cemgil ed è discusso da Barber (2012)).\nIndichiamo il punteggio del dado \\(a\\) con \\(s_a\\), dove \\(\\text{dom}(s_a) = \\{1,2,3,4,5,6\\}\\), e in modo simile per \\(s_b\\). Le tre variabili coinvolte sono quindi \\(s_a\\), \\(s_b\\) e la somma totale, \\(t = s_a + s_b\\). Un modello per queste tre variabili assume la forma:\n\\[\np(t, s_a, s_b) = p(t | s_a, s_b) p(s_a, s_b),\n\\]\ndove:\n\nLikelihood: \\(p(t | s_a, s_b)\\) rappresenta la probabilità che la somma dei dadi sia \\(t\\) dato \\(s_a\\) e \\(s_b\\).\nPrior: \\(p(s_a, s_b)\\) è la probabilità congiunta dei punteggi \\(s_a\\) e \\(s_b\\) senza conoscere la somma \\(t\\).\n\nAssumiamo che i dadi siano equi e indipendenti, quindi la probabilità congiunta \\(p(s_a, s_b)\\) è il prodotto delle distribuzioni uniformi di \\(s_a\\) e \\(s_b\\):\n\\[\np(s_a, s_b) = p(s_a) p(s_b) = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36}.\n\\]\nIl termine di likelihood è dato da:\n\\[\np(t | s_a, s_b) = I[t = s_a + s_b],\n\\]\ndove \\(I[A]\\) è la funzione indicatrice che vale 1 se la condizione \\(A\\) è vera e 0 altrimenti.\nAbbiamo che \\(p(t = 9 | s_a, s_b)\\) è 1 se la somma di \\(s_a\\) e \\(s_b\\) è 9, altrimenti è 0. Quindi la likelihood è data dalla seguente tabella:\n\n\n\n\\(s_b\\) \\\n1\n2\n3\n4\n5\n6\n\n\n\n\n\\(s_a\\)\n\n\n\n\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n0\n1\n\n\n4\n0\n0\n0\n0\n1\n0\n\n\n5\n0\n0\n0\n1\n0\n0\n\n\n6\n0\n0\n1\n0\n0\n0\n\n\n\nLe combinazioni possibili sono quindi \\((3,6), (4,5), (5,4), (6,3)\\).\nLa distribuzione a posteriori dei punteggi dei dadi, data la somma \\(t = 9\\), si calcola con:\n\\[\np(s_a, s_b | t = 9) = \\frac{p(t = 9 | s_a, s_b) p(s_a) p(s_b)}{p(t = 9)}.\n\\]\nIl denominatore \\(p(t = 9)\\) è la somma dei termini non nulli del numeratore:\n\\[\np(t = 9) = \\sum_{s_a, s_b} p(t = 9 | s_a, s_b) p(s_a) p(s_b) = 4 \\times \\frac{1}{36} = \\frac{1}{9}.\n\\]\nQuindi, la distribuzione a posteriori è:\n\n\n\n\\(s_b\\) \\\n1\n2\n3\n4\n5\n6\n\n\n\n\n\\(s_a\\)\n\n\n\n\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n0\n1/4\n\n\n4\n0\n0\n0\n0\n1/4\n0\n\n\n5\n0\n0\n0\n1/4\n0\n0\n\n\n6\n0\n0\n1/4\n0\n0\n0\n\n\n\nIn questo caso, le uniche combinazioni con probabilità non nulla sono quelle in cui la somma è 9, e ciascuna di queste ha probabilità \\(1/4\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#probabilità-inversa",
    "href": "chapters/probability/07_bayes_theorem.html#probabilità-inversa",
    "title": "27  Il teorema di Bayes",
    "section": "28.3 Probabilità Inversa",
    "text": "28.3 Probabilità Inversa\nGli esempi precedenti evidenziano la differenza tra due domande fondamentali. La prima è: “Qual è la probabilità di osservare un determinato risultato, supponendo che una certa ipotesi sia vera?” La seconda, invece, è: “Qual è la probabilità che un’ipotesi sia vera, dato il risultato osservato?”\nUn esempio che risponde alla prima domanda potrebbe essere questo: supponiamo che la probabilità di ottenere testa nel lancio di una moneta sia 0,5 (ipotesi). Qual è la probabilità di ottenere 0 teste in cinque lanci?\nPer la seconda domanda, un esempio potrebbe essere: supponiamo di aver ottenuto 0 teste in 5 lanci di una moneta (evidenza). Qual è la probabilità che la moneta sia effettivamente bilanciata, alla luce di questa osservazione?\nPer molto tempo, lo studio della probabilità si è concentrato principalmente sulla prima domanda. Tuttavia, nel XVIII secolo, il reverendo Thomas Bayes iniziò a riflettere sulla seconda domanda, dando origine a quello che oggi chiamiamo probabilità inversa.\nQuesto approccio ha generato numerose controversie nella storia della statistica, in gran parte perché influenza molti ambiti. Ad esempio, possiamo chiederci: quanto è probabile che un’ipotesi scientifica sia vera, dato il risultato di un esperimento? Per stimare questa probabilità — un compito che molti scienziati ritengono essenziale per la statistica moderna — è necessario fare uso del teorema di Bayes e delle probabilità a priori.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#riflessioni-conclusive",
    "href": "chapters/probability/07_bayes_theorem.html#riflessioni-conclusive",
    "title": "27  Il teorema di Bayes",
    "section": "28.4 Riflessioni Conclusive",
    "text": "28.4 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato vari esempi, principalmente nel campo medico e forense, per illustrare come il teorema di Bayes permetta di combinare le informazioni derivate dalle osservazioni con le conoscenze precedenti (priori), aggiornando così il nostro grado di convinzione rispetto a un’ipotesi. Il teorema di Bayes fornisce un meccanismo razionale, noto come “aggiornamento bayesiano”, che ci consente di ricalibrare le nostre convinzioni iniziali alla luce di nuove evidenze.\nUna lezione fondamentale che il teorema di Bayes ci insegna, sia nella ricerca scientifica che nella vita quotidiana, è che spesso non ci interessa tanto conoscere la probabilità che qualcosa accada assumendo vera un’ipotesi, quanto piuttosto la probabilità che un’ipotesi sia vera, dato che abbiamo osservato una certa evidenza. In altre parole, la forza del teorema di Bayes sta nella sua capacità di affrontare direttamente il problema inverso, cioè come dedurre la verità di un’ipotesi a partire dalle osservazioni.\nIl framework bayesiano per l’inferenza probabilistica offre un approccio generale per comprendere come i problemi di induzione possano essere risolti in linea di principio e, forse, anche come possano essere affrontati dalla mente umana.\nIn questo capitolo ci siamo concentrati sull’applicazione del teorema di Bayes utilizzando probabilità puntuali. Tuttavia, il teorema esprime pienamente il suo potenziale quando sia l’evidenza che i gradi di certezza a priori delle ipotesi sono rappresentati attraverso distribuzioni di probabilità continue. Questo sarà l’argomento centrale nel ?sec-bayes-workflow, dove approfondiremo il flusso di lavoro bayesiano e l’uso di distribuzioni continue nell’aggiornamento bayesiano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/07_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "title": "27  Il teorema di Bayes",
    "section": "28.5 Informazioni sull’Ambiente di Sviluppo",
    "text": "28.5 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] latex2exp_0.9.6   mice_3.16.0       MASS_7.3-61       viridis_0.6.5    \n#&gt;  [5] viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3    \n#&gt;  [9] patchwork_1.3.0   bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0     \n#&gt; [13] markdown_1.13     knitr_1.49        lubridate_1.9.3   forcats_1.0.0    \n#&gt; [17] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n#&gt; [21] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#&gt; [25] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.0       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#bibliografia",
    "href": "chapters/probability/07_bayes_theorem.html#bibliografia",
    "title": "27  Il teorema di Bayes",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBarber, D. (2012). Bayesian reasoning and machine learning. Cambridge University Press.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nGriffiths, T. L., Chater, N., & Tenenbaum, J. B. (2024). Bayesian models of cognition: reverse engineering the mind. MIT Press.\n\n\nPetersen, I. T. (2024). Principles of psychological assessment: With applied examples in R. CRC Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html",
    "href": "chapters/probability/08_sampling_distr.html",
    "title": "28  Stime, stimatori e parametri",
    "section": "",
    "text": "28.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell’inferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle proprietà probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste proprietà verranno utilizzate per costruire gli strumenti fondamentali dell’inferenza frequentista: gli intervalli di fiducia e i test di ipotesi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#popolazione-e-campioni",
    "href": "chapters/probability/08_sampling_distr.html#popolazione-e-campioni",
    "title": "28  Stime, stimatori e parametri",
    "section": "28.2 Popolazione e campioni",
    "text": "28.2 Popolazione e campioni\nNell’analisi dei dati, l’obiettivo spesso è comprendere una quantità specifica a livello di popolazione, ma in genere abbiamo accesso solo a un campione di osservazioni. La quantità sconosciuta che vogliamo determinare viene chiamata parametro. Quando usiamo i dati del campione per calcolare una misura di questo parametro, la misura ottenuta è chiamata stima, e la formula che utilizziamo per ottenerla è conosciuta come stimatore. In termini formali, uno stimatore è una funzione dei dati osservati, utilizzata per fornire un’approssimazione del parametro di interesse.\nIn pratica, quando analizziamo un campione di dati, il nostro obiettivo è inferire determinate proprietà della popolazione intera dalla quale il campione è stato tratto. Il parametro è l’indicatore numerico di queste proprietà, ma poiché spesso non possiamo calcolarlo direttamente sulla popolazione, ricorriamo alle osservazioni del campione per stimarlo. La stima, quindi, rappresenta il valore approssimato del parametro ottenuto dal campione, mentre lo stimatore è la regola o la formula matematica che usiamo per arrivare a questa approssimazione.\nÈ importante riconoscere che le stime possono non corrispondere esattamente ai parametri che vogliamo comprendere. In altre parole, le stime sono solo approssimazioni del parametro a causa della natura aleatoria del campionamento.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#la-relazione-tra-stime-e-parametri",
    "href": "chapters/probability/08_sampling_distr.html#la-relazione-tra-stime-e-parametri",
    "title": "28  Stime, stimatori e parametri",
    "section": "28.3 La relazione tra stime e parametri",
    "text": "28.3 La relazione tra stime e parametri\nIn questo capitolo, ci concentreremo sulla relazione tra le stime ottenute dai campioni e i parametri reali della popolazione, esplorando in particolare la connessione tra la media di un campione e la media della popolazione, denotata con \\(\\mu\\). Il nostro obiettivo è capire e caratterizzare l’incertezza che deriva dalla natura aleatoria delle stime, e per farlo, adotteremo l’approccio frequentista, facendo uso di un importante strumento statistico chiamato distribuzione campionaria.\n\n28.3.1 Distribuzione campionaria\nPer illustrare il concetto di distribuzione campionaria, possiamo iniziare considerando un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, è fondamentale notare che le proprietà e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\nLa distribuzione campionaria ci dà una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all’intera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di \\(\\mu\\). Tuttavia, un altro campione fornirà una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell’incertezza legata al processo di stima.\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nL’istogramma seguente descrive la distribuzione di frequenza della popolazione.\n\nggplot(data.frame(x = x), aes(x)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = ..density..)\n  )\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nStampiamo gli intervalli utilizzati per l’istogramma.\n\n# Calcolo degli intervalli e delle frequenze per l'istogramma\nhist_data &lt;- hist(x, breaks = 5, plot = FALSE)\n\n# Stampa degli intervalli e delle frequenze relative\ncat(\"Intervalli utilizzati per l'istogramma:\", hist_data$breaks, \"\\n\")\n#&gt; Intervalli utilizzati per l'istogramma: 2 2.5 3 3.5 4 4.5 5 5.5\ncat(\"Frequenze relative utilizzate per l'istogramma:\", hist_data$density, \"\\n\")\n#&gt; Frequenze relative utilizzate per l'istogramma: 0.5 0 0 0 0.5 0.5 0.5\n\n# Calcolo delle frequenze assolute\nhist_data_abs &lt;- hist(x, breaks = 5, plot = FALSE)\n\n# Stampa delle frequenze assolute\ncat(\"Frequenze assolute utilizzate per l'istogramma:\", hist_data_abs$counts, \"\\n\")\n#&gt; Frequenze assolute utilizzate per l'istogramma: 1 0 0 0 1 1 1\n\nCalcoliamo la media e la varianza della popolazione.\n\n# Calcolo della media e della varianza della popolazione\nmean_x &lt;- mean(x)\nvar_x &lt;- var(x) * ((length(x) - 1) / length(x)) # Varianza popolazione\nc(mean_x, var_x)\n#&gt; [1] 4.2500 1.8125\n\nSupponiamo ora di voler considerare l’estrazione di tutti i possibili campioni di dimensione (n = 2) da una popolazione rappresentata dal vettore x. Per fare ciò, possiamo fare uso della funzione expand.grid in R, che permette di generare tutte le combinazioni possibili di valori con ripetizione.\nUtilizzando expand.grid, otteniamo un data.frame in cui ogni riga rappresenta una coppia di valori possibili. La struttura risultante contiene tutte le combinazioni in cui ogni valore nel vettore x può essere abbinato a se stesso o a un altro valore nel vettore. Convertendo il risultato in una matrice, otteniamo una rappresentazione simile a un array NumPy, con 16 righe e 2 colonne, che rappresenta tutte le possibili coppie formate dai valori del vettore x.\nQuesto approccio è coerente con un concetto matematico fondamentale: se stiamo scegliendo 2 elementi da un insieme di 4, e ogni elemento può essere scelto più di una volta (ossia con ripetizione), il numero totale di possibili combinazioni sarà (4^2 = 16). Questo si spiega dal fatto che ci sono 4 scelte per il primo elemento e 4 scelte per il secondo elemento, risultando in un totale di (4 = 16) possibili coppie.\n\n# Creare tutte le combinazioni possibili di valori\nsamples &lt;- expand.grid(x, x)\nsamples &lt;- as.matrix(samples)  # Convertire in matrice\nprint(samples)\n#&gt;       Var1 Var2\n#&gt;  [1,]  2.0  2.0\n#&gt;  [2,]  4.5  2.0\n#&gt;  [3,]  5.0  2.0\n#&gt;  [4,]  5.5  2.0\n#&gt;  [5,]  2.0  4.5\n#&gt;  [6,]  4.5  4.5\n#&gt;  [7,]  5.0  4.5\n#&gt;  [8,]  5.5  4.5\n#&gt;  [9,]  2.0  5.0\n#&gt; [10,]  4.5  5.0\n#&gt; [11,]  5.0  5.0\n#&gt; [12,]  5.5  5.0\n#&gt; [13,]  2.0  5.5\n#&gt; [14,]  4.5  5.5\n#&gt; [15,]  5.0  5.5\n#&gt; [16,]  5.5  5.5\n\nLa matrice samples è bidimensionale, dove ogni riga rappresenta una coppia di valori. Per calcolare la media di ogni campione di ampiezza (n = 2), possiamo utilizzare la funzione rowMeans, che calcola la media per ogni riga di una matrice. In questo modo, otteniamo un vettore contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la distribuzione campionaria delle medie dei campioni di ampiezza (n = 2) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media di ciascun campione\nmeans &lt;- rowMeans(samples)\nprint(means)\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\nLa funzione rowMeans(samples) calcola la media per ogni riga della matrice samples. Una rappresentazione grafica della distribuzione campionaria dei campioni di ampiezza (n = 2) che possono essere estratti dalla popolazione x è fornita qui sotto.\n\n# Istogramma delle medie campionarie\nggplot(data.frame(means), aes(x = means)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = ..density..)\n)\n\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\n# Creare un data frame con i campioni e le loro medie\ndf &lt;- data.frame(\n  Samples = apply(samples, 1, paste, collapse = \", \"),\n  x_bar = rowMeans(samples)\n)\nprint(df)\n#&gt;     Samples x_bar\n#&gt; 1      2, 2  2.00\n#&gt; 2    4.5, 2  3.25\n#&gt; 3      5, 2  3.50\n#&gt; 4    5.5, 2  3.75\n#&gt; 5    2, 4.5  3.25\n#&gt; 6  4.5, 4.5  4.50\n#&gt; 7    5, 4.5  4.75\n#&gt; 8  5.5, 4.5  5.00\n#&gt; 9      2, 5  3.50\n#&gt; 10   4.5, 5  4.75\n#&gt; 11     5, 5  5.00\n#&gt; 12   5.5, 5  5.25\n#&gt; 13   2, 5.5  3.75\n#&gt; 14 4.5, 5.5  5.00\n#&gt; 15   5, 5.5  5.25\n#&gt; 16 5.5, 5.5  5.50\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza (n = 2) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media delle medie campionarie\nmean_of_means &lt;- mean(means)\nprint(mean_of_means)\n#&gt; [1] 4.25\n\n\n\n28.3.2 Valore atteso della media campionaria\nSupponiamo che $ X_1, X_2, , X_n $ siano variabili aleatorie iid con valore atteso $ $ e varianza $ ^2 $. Vogliamo trovare il valore atteso della media campionaria:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nEcco la dimostrazione:\n\\[\n\\begin{align*}\n\\mathbb{E}(\\bar{X}) & = \\mathbb{E}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\mathbb{E}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}(X_i) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mu \\\\\n& = \\frac{1}{n} \\cdot n \\cdot \\mu \\\\\n& = \\mu\n\\end{align*}\n\\]\nQuindi, il valore atteso della media campionaria di $ n $ variabili iid è uguale al valore atteso di ciascuna variabile singola, che in questo caso è $ $.\nVerifichiamo che ciò sia vero nel nostro caso specifico.\n\nmean(x)\n#&gt; [1] 4.25\nmean(means)\n#&gt; [1] 4.25\n\n\n\n28.3.3 Varianza della media campionaria\nDato che le variabili \\(X_1, X_2, \\ldots, X_n\\) sono indipendenti ed identicamente distribuite (iid) con valore atteso \\(\\mu\\) e varianza \\(\\sigma^2\\), possiamo calcolare la varianza della media campionaria \\(\\bar{X}\\) come segue:\n\\[\n\\begin{align*}\n\\text{Var}(\\bar{X}) & = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(X_i) \\quad \\text{(dato che le $X_i$ sono indipendenti, i termini incrociati si annullano)} \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 \\\\\n& = \\frac{1}{n^2} \\cdot n \\cdot \\sigma^2 \\\\\n& = \\frac{\\sigma^2}{n}\n\\end{align*}\n\\]\nQuindi, la varianza della media campionaria di \\(n\\) variabili iid è uguale alla varianza di ciascuna variabile singola divisa per \\(n\\), che in questo caso è \\(\\sigma^2/n\\).\nPer l’esempio in discussione, il valore della varianza delle medie dei campioni è dunque pari a\n\nvar(x) * ((length(x) - 1)/ length(x)) / 2\n#&gt; [1] 0.90625\n\nLo stesso risultato si ottiene facendo la media delle 16 medie che abbiamo trovato in precedenza.\n\nvar(means) * ((length(means) - 1)/ length(means))\n#&gt; [1] 0.90625\n\nConsideriamo ora un particolare campione. Per esempio\n\nobserved_sample = c(5, 5.5)\nprint(observed_sample)\n#&gt; [1] 5.0 5.5\n\nTroviamo la media del campione:\n\nsample_mean = mean(observed_sample)\nprint(sample_mean)\n#&gt; [1] 5.25\n\nLa media del campione è diversa dalla media della popolazione (\\(\\mu\\) = 4.25).\nTroviamo la deviazione standard del campione:\n\nsample_sd = sqrt(var(observed_sample)/2)\nprint(sample_sd)\n#&gt; [1] 0.25\n\nLa deviazione standard del campione è diversa dalla deviazione standard della popolazione:\n\nsqrt(var(x) * (length(x) - 1)/length(x))\n#&gt; [1] 1.346291\n\nIn conclusione, possiamo sottolineare due risultati centrali che emergono dall’analisi delle medie campionarie:\n\nMedia delle medie campionarie e media della popolazione: La media della distribuzione delle medie campionarie è identica alla media della popolazione. In termini matematici, questo significa che il valore atteso della media dei campioni (con ripetizione) da una popolazione (finita o infinita) con media $ $ è:\n\n\\[\n   \\mathbb{E}(\\bar{X}_n) = \\mu.\n\\]\n\nVarianza delle medie campionarie e varianza della popolazione: La varianza della distribuzione delle medie campionarie è inferiore alla varianza della popolazione e, precisamente, è pari alla varianza della popolazione divisa per la dimensione del campione:\n\n\\[\n   \\mathbb{V}(\\bar{X}_n) = \\frac{\\sigma^2}{n}.\n\\]\nQuesti risultati, che abbiamo verificato empiricamente attraverso la simulazione, ci offrono una comprensione profonda del comportamento delle medie campionarie.\nInoltre, è importante notare che il comportamento della distribuzione delle medie campionarie dipende dalla forma della distribuzione della popolazione stessa:\n\nSe la popolazione segue una distribuzione normale, allora la distribuzione delle medie dei campioni sarà anch’essa normale.\nSe la popolazione non segue una distribuzione normale, il teorema del limite centrale entra in gioco, assicurando che, man mano che le dimensioni del campione aumentano, la distribuzione delle medie dei campioni converga a una distribuzione normale.\n\nQuesti principi sono fondamentali in statistica e forniscono la base per molte tecniche di inferenza e modellazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "href": "chapters/probability/08_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "title": "28  Stime, stimatori e parametri",
    "section": "28.4 Errore standard e rappresentazione dell’incertezza inferenziale",
    "text": "28.4 Errore standard e rappresentazione dell’incertezza inferenziale\nNella statistica inferenziale, l’errore standard è una misura frequentemente utilizzata per rappresentare l’incertezza legata a un parametro stimato, conosciuta anche come incertezza inferenziale. L’errore standard quantifica quanto possa variare la stima di una statistica da un campione all’altro; un errore standard minore indica una stima più precisa, mentre uno maggiore implica maggiore incertezza. Spesso, le rappresentazioni grafiche includono gli errori standard nella forma di “media più o meno uno (o due) errori standard.” Questa espressione fornisce una gamma di valori entro cui è plausibile che ricada il valore vero del parametro della popolazione.\nL’uso dell’errore standard nei grafici non è soltanto una convenzione; esso è uno strumento per quantificare e visualizzare l’incertezza inferenziale. Contribuisce alla comprensione dell’affidabilità delle stime ottenute dai dati campionari, permettendo di valutare quanto le stime possano variare se si prendesse un altro campione dalla stessa popolazione. Tuttavia, è importante notare che questo utilizzo dell’errore standard può essere problematico (Ward & Mann, 2022).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#legge-dei-grandi-numeri",
    "href": "chapters/probability/08_sampling_distr.html#legge-dei-grandi-numeri",
    "title": "28  Stime, stimatori e parametri",
    "section": "28.5 Legge dei Grandi Numeri",
    "text": "28.5 Legge dei Grandi Numeri\nLa Legge dei Grandi Numeri (LLN) è un principio fondamentale della teoria delle probabilità che stabilisce come, incrementando il numero \\(n\\) di osservazioni, la media campionaria \\(\\bar{X}_n\\) tenda asintoticamente alla media teorica \\(\\mu\\). La LLN si articola in due varianti: la versione “forte” e quella “debole”, le quali differiscono per il tipo di convergenza verso la media attesa.\n\n28.5.1 Versione Forte della Legge dei Grandi Numeri (SLLN)\nLa SLLN afferma che la media campionaria $ {X}_n $ converge quasi certamente alla media teorica \\(\\mu\\), ovvero la convergenza avviene con probabilità 1. Questo implica che, per quasi ogni possibile sequenza di eventi nell’insieme campionario \\(S\\), \\(\\bar{X}_n(s)\\) tende a \\(\\mu\\), ad eccezione di un insieme di eventi \\(B_0\\) la cui probabilità è zero. In termini tecnici, si dice che \\(\\bar{X}_n\\) converge a \\(\\mu\\) “quasi certamente”.\n\n\n28.5.2 Versione Debole della Legge dei Grandi Numeri (WLLN)\nLa WLLN afferma che, per ogni \\(\\epsilon &gt; 0\\), la probabilità che la media campionaria \\(\\bar{X}_n\\) si discosti da \\(\\mu\\) di una quantità maggiore di \\(\\epsilon\\) tende a zero all’aumentare di \\(n\\). Questo fenomeno è definito come convergenza in probabilità verso la media teorica \\(\\mu\\).\n\n\n28.5.3 Implicazioni e Applicazioni\nLa Legge dei Grandi Numeri riveste un ruolo cruciale nel campo delle simulazioni, della statistica e, più in generale, nelle discipline scientifiche. La generazione di dati attraverso numerose repliche indipendenti di un esperimento, sia in ambito simulativo che empirico, implica l’utilizzo della media campionaria come stima affidabile della media teorica della variabile di interesse. In pratica, la LLN fornisce una base teorica per l’affidabilità delle stime medie ottenute da grandi campioni di dati, sottolineando come, a fronte di un numero elevato di osservazioni, le fluttuazioni casuali tendano ad annullarsi, convergendo verso un valore stabile e prevedibile.\n\nEsempio 28.1 Siano \\(X_1, X_2, \\ldots\\) variabili aleatorie indipendenti e identicamente distribuite secondo una distribuzione di Bernoulli con parametro \\(1/2\\). Interpretando gli \\(X_j\\) come indicatori di “Testa” in una sequenza di lanci di una moneta equa, \\(\\bar{X}_n\\) rappresenta la proporzione di “Testa” dopo \\(n\\) lanci. La Legge Forte dei Grandi Numeri (SLLN) afferma che, con probabilità 1, la sequenza di variabili aleatorie \\(\\bar{X}_1, \\bar{X}_2, \\bar{X}_3, \\ldots\\) convergerà a \\(1/2\\) quando si cristallizza in una sequenza di numeri reali. Matematicamente parlando, esistono scenari improbabili come una sequenza infinita di “Testa” (HHHHHH…) o sequenze irregolari come HHTHHTHHTHHT…, ma queste hanno una probabilità collettiva di zero di verificarsi. La Legge Debole dei Grandi Numeri (WLLN) stabilisce che, per ogni \\(\\epsilon &gt; 0\\), la probabilità che \\(\\bar{X}_n\\) sia distante più di \\(\\epsilon\\) da \\(1/2\\) può essere resa arbitrariamente piccola aumentando \\(n\\).\nCome illustrazione, abbiamo simulato sei sequenze di lanci di una moneta equa e, per ciascuna sequenza, abbiamo calcolato \\(\\bar{X}_n\\) in funzione di \\(n\\). Ovviamente, nella realtà non possiamo effettuare un numero infinito di lanci, quindi ci siamo fermati dopo 300 lanci. Il grafico seguente mostra \\(\\bar{X}_n\\) in funzione di $ n $ per ciascuna delle sei sequenze. All’inizio, notiamo una certa variazione nella proporzione cumulativa di “Testa”. Tuttavia, con l’aumentare del numero di lanci, la varianza $ ({X}_n) $ diminuisce progressivamente e \\(\\bar{X}_n\\) tende a \\(1/2\\).\n\n# Numero di sequenze\nnum_sequences &lt;- 6\n# Numero di lanci\nnum_tosses &lt;- 300\n\n# Creare un data frame per contenere i risultati\nresults &lt;- data.frame(Toss = numeric(), Proportion = numeric(), Sequence = character())\n\n# Loop attraverso ciascuna sequenza\nfor (i in 1:num_sequences) {\n  # Generare una sequenza di lanci di moneta equa (Testa=1, Croce=0)\n  coin_tosses &lt;- sample(c(0, 1), num_tosses, replace = TRUE)\n  \n  # Calcolare la proporzione cumulativa di Teste\n  running_proportion &lt;- cumsum(coin_tosses) / seq_along(coin_tosses)\n  \n  # Aggiungere i risultati al data frame\n  results &lt;- rbind(\n    results,\n    data.frame(\n      Toss = seq_along(coin_tosses),\n      Proportion = running_proportion,\n      Sequence = paste(\"Sequence\", i)\n    )\n  )\n}\n\n# Creare il grafico con ggplot2\nggplot(results, aes(x = Toss, y = Proportion, color = Sequence)) +\n  geom_line() +\n  geom_hline(yintercept = 0.5, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Number of Tosses\",\n    y = \"Running Proportion of Heads\",\n    title = \"Running Proportion of Heads in Six Sequences of Fair Coin Tosses\",\n    color = \"Sequence\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#teorema-del-limite-centrale",
    "href": "chapters/probability/08_sampling_distr.html#teorema-del-limite-centrale",
    "title": "28  Stime, stimatori e parametri",
    "section": "28.6 Teorema del Limite Centrale",
    "text": "28.6 Teorema del Limite Centrale\nIl teorema del limite centrale è un risultato fondamentale in statistica che è stato dimostrato per la prima volta da Laplace nel 1812. Esso fornisce una spiegazione matematica per il motivo per cui la distribuzione normale appare così frequentemente nei fenomeni naturali. Ecco la formulazione essenziale.\nSupponiamo di avere una sequenza di variabili aleatorie indipendenti ed identicamente distribuite (i.i.d.), \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\), ciascuna con valore atteso \\(\\mathbb{E}(Y_i) = \\mu\\) e deviazione standard \\(SD(Y_i) = \\sigma\\). Definiamo una nuova variabile casuale come la media aritmetica di queste variabili:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nAllora, quando \\(n\\) tende all’infinito, la distribuzione di \\(Z\\) convergerà a una distribuzione normale con media \\(\\mu\\) e deviazione standard ridotta di un fattore \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]\n\n28.6.1 Significato e generalizzazione\nIl TLC non si applica solo alle variabili casuali con la stessa distribuzione, ma può essere esteso a variabili casuali indipendenti con aspettative e varianze finite. La potenza del teorema sta nella sua capacità di descrivere fenomeni che sono il risultato di molteplici effetti additivi indipendenti. Anche se questi effetti possono avere distribuzioni diverse, la loro somma tende a una distribuzione normale.\nAd esempio, l’altezza degli esseri umani adulti può essere vista come la somma di molti fattori genetici e ambientali indipendenti. Indipendentemente dalla distribuzione individuale di questi fattori, la loro combinazione tende a formare una distribuzione normale. Questa universalità rende la distribuzione normale una buona approssimazione per molti fenomeni naturali.\n\nEsempio 28.2 Per visualizzare il TLC in azione, si può condurre una simulazione. Immaginiamo una popolazione distribuita in maniera uniforme. Estraiamo 300 campioni di dimensione \\(n\\) = 30 da questa popolazione e osserviamo come la distribuzione campionaria di tali medie converga a una distribuzione normale. Questa simulazione fornirà un’illustrazione concreta dell’efficacia del TLC nell’approssimare distribuzioni reali.\n\n# Set the random seed for reproducibility\nset.seed(42)\n\n# Generate a non-normally distributed population\npopulation &lt;- runif(5000, min = 0, max = 1)\n\n# Create a histogram of the population\npar(mfrow = c(1, 2))  # Set up a 1x2 grid for plotting\n\n# Plot the histogram of the population\nhist(population, breaks = 30, prob = TRUE, main = \"Population Distribution\",\n     xlab = \"Value\", col = \"lightblue\")\n\n# Step 2 and 3: Draw random samples and calculate sample means\nsample_size &lt;- 30\nnum_samples &lt;- 300\n\n# Empty vector to store sample means\nsample_means &lt;- c()\n\nfor (i in 1:num_samples) {\n  # Take a random sample\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  \n  # Calculate the mean of the sample\n  sample_means[i] &lt;- mean(sample)\n}\n\n# For sample\nx_bar &lt;- mean(sample_means)\nstd &lt;- sd(sample_means)\n\nprint('Sample Mean and Variance')\n#&gt; [1] \"Sample Mean and Variance\"\nprint(x_bar)\n#&gt; [1] 0.5010222\nprint(std**2)\n#&gt; [1] 0.002745131\n\n# For Population\nmu &lt;- mean(population)\nsigma &lt;- sd(population)\n\nprint('Population Mean and Variance')\n#&gt; [1] \"Population Mean and Variance\"\nprint(mu)\n#&gt; [1] 0.5031668\nprint((sigma**2)/sample_size)\n#&gt; [1] 0.002823829\n\n# Plot the histogram of sample means\nhist(sample_means, breaks = 30, prob = TRUE, main = \"Distribution of Sample Means\",\n     xlab = \"Sample Mean\", col = \"lightgreen\")\n\n# Overlay density curves\ncurve(dnorm(x, mean = x_bar, sd = std), col = \"black\", lwd = 2, add = TRUE)\n\n# Add labels and legends\nlegend(\"topright\", legend = c(\"Distribution Curve\"),\n       col = c(\"black\"), lwd = 2)\n\n# Reset the plot layout\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\n\n\nIn conclusione, il teorema del limite centrale (TLC) stabilisce che, a meno che non si stia lavorando con campioni estremamente piccoli, è possibile approssimare con buona precisione la distribuzione campionaria della media dei campioni utilizzando la distribuzione Normale. Questo vale indipendentemente dalla forma specifica della distribuzione della popolazione da cui sono tratti i campioni. In altre parole, quando si lavora con campioni di dimensioni sufficienti, il TLC offre una formula concreta per descrivere la forma della distribuzione campionaria della media dei campioni. Ciò avviene anche se non si hanno informazioni dettagliate sulla popolazione, come la media \\(\\mu\\) e la deviazione standard \\(\\sigma\\), ed è espresso dalla relazione \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/probability/08_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "28  Stime, stimatori e parametri",
    "section": "28.7 Distribuzioni campionarie di altre statistiche",
    "text": "28.7 Distribuzioni campionarie di altre statistiche\nIn precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente è possibile costruire la distribuzione campionaria di altre statistiche campionarie. Ad esempio, la figura seguente mostra l’approssimazione empirica della distribuzione campionaria del valore massimo del campione. È chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sarà maggiore della media della popolazione.\n\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e trovare il massimo punteggio per ciascun esperimento\nset.seed(123)  # Per riproducibilità\nsample_maxes &lt;- replicate(10000, max(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione dei massimi campionari insieme alla distribuzione della popolazione\n\n# Creare il data frame per il grafico\ndata &lt;- data.frame(SampleMaxes = sample_maxes)\ndensity_data &lt;- data.frame(x = x, y = y)\n\nggplot(data, aes(x = SampleMaxes)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  geom_line(data = density_data, aes(x = x, y = y), size = 1) +\n  labs(\n    title = \"Distribuzione dei massimi campionari\",\n    x = \"Massimo campionario\",\n    y = \"Densità\"\n  ) \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nLa distribuzione campionaria della varianza dei campioni è particolarmente interessante. Usiamo la formula della statistica descrittiva, ovvero\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nUna volta compresa la procedura, possiamo creare un grafico che rappresenta l’approssimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza. Sapendo che la varianza della popolazione è uguale a \\(15^2\\), abbiamo utilizzato la simulazione per stimare la varianza della popolazione. Tuttavia, il risultato ottenuto è stato interessante: in media, l’utilizzo della formula precedente ha portato a una stima della varianza della popolazione troppo piccola. Gli statistici chiamano questa discrepanza distorsione, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.\n\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(0, 30, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e calcolare la varianza per ciascun esperimento\nset.seed(123)  # Per riproducibilità\nsample_vars &lt;- replicate(10000, var(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione delle varianze campionarie\n\ndata &lt;- data.frame(SampleVars = sample_vars)\n\nggplot(data, aes(x = SampleVars)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione delle varianze campionarie\",\n    x = \"Varianza campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n\n# Calcolare la media delle varianze campionarie\nmean(sample_vars)\n#&gt; [1] 225.8211\n\nAbbiamo già visto come questo problema trova una semplice soluzione nel momento in cui usiamo \\(n-1\\) al denominatore.\n\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(0, 30, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e calcolare la varianza corretta per ciascun esperimento\nset.seed(123)  # Per riproducibilità\nsample_vars &lt;- replicate(10000, var(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione delle varianze campionarie\ndata &lt;- data.frame(SampleVars = sample_vars)\n\nggplot(data, aes(x = SampleVars)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione delle varianze campionarie\",\n    x = \"Varianza campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n\n# Calcolare la media delle varianze campionarie\nmean(sample_vars)\n#&gt; [1] 225.8211\n\nLa differenza tra la stima di un parametro e il valore vero del parametro è chiamata errore della stima. Uno stimatore si dice non distorto (unbiased) se la media delle sue stime su molteplici campioni ipotetici è uguale al valore del parametro che si vuole stimare. In altre parole, l’errore medio di stima è zero.\nIn questo capitolo abbiamo visto che \\(\\frac{\\sum_{i=1}^n{X_i}}{n}\\) è uno stimatore non distorto di \\(\\mu\\) e che \\(\\frac{\\sum_{i=1}^n{(^2)}}{n-1}\\) è uno stimatore non distorto di \\(\\sigma^2\\). Questo significa che tali stimatori hanno una distribuzione campionaria centrata sul vero valore del parametro.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/08_sampling_distr.html#riflessioni-conclusive",
    "title": "28  Stime, stimatori e parametri",
    "section": "28.8 Riflessioni Conclusive",
    "text": "28.8 Riflessioni Conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell’inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\nÈ qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nSì, ma non è uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nSì, ma non è uguale a \\(\\sigma^2\\)\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione è la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione è:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/08_sampling_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "28  Stime, stimatori e parametri",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.0       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#bibliografia",
    "href": "chapters/probability/08_sampling_distr.html#bibliografia",
    "title": "28  Stime, stimatori e parametri",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nWard, A., & Mann, T. (2022). Control yourself: Broad implications of narrowed attention. Perspectives on Psychological Science, 17(6), 1692–1703.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html",
    "href": "chapters/probability/09_joint_prob.html",
    "title": "29  Probabilità congiunta",
    "section": "",
    "text": "29.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo ci proponiamo di analizzare in dettaglio il concetto di probabilità congiunta, focalizzando l’attenzione sul caso di variabili aleatorie discrete. La probabilità congiunta rappresenta la misura della probabilità che due o più eventi si verifichino simultaneamente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#funzione-di-probabilità-congiunta",
    "href": "chapters/probability/09_joint_prob.html#funzione-di-probabilità-congiunta",
    "title": "29  Probabilità congiunta",
    "section": "29.2 Funzione di Probabilità Congiunta",
    "text": "29.2 Funzione di Probabilità Congiunta\nFinora abbiamo analizzato la probabilità associata a un singolo evento, o più precisamente, a un singolo valore assunto da una variabile aleatoria. Tuttavia, spesso siamo interessati a studiare la relazione tra due o più eventi. La funzione di probabilità congiunta ci permette di estendere il concetto di probabilità al caso di più variabili aleatorie, descrivendo la probabilità che queste assumano specifici valori contemporaneamente.\n\n29.2.1 Esempio: Lancio di Tre Monete Equilibrate\nPer comprendere meglio il concetto di probabilità congiunta, immaginiamo di lanciare tre monete. Tutti i possibili risultati di questo esperimento (ad esempio, tre teste, due teste e una croce, ecc.) costituiscono quello che chiamiamo spazio campionario. In questo caso, lo spazio campionario \\(\\Omega\\) è dato da:\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\},\n\\]\ndove \\(T\\) indica “testa” e \\(C\\) indica “croce”. Assumendo che ogni lancio sia indipendente dagli altri, ogni risultato nello spazio campionario \\(\\Omega\\) ha la stessa probabilità di verificarsi, ovvero \\(1/8\\).\nDefiniamo ora le seguenti variabili casuali sullo spazio campionario \\(\\Omega\\):\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) rappresenta il numero totale di teste ottenute nei tre lanci.\n\\(Y \\in \\{0, 1\\}\\) indica se il primo lancio ha dato testa (\\(1\\)) oppure croce (\\(0\\)).\n\nLa tabella seguente mostra lo spazio campionario con i valori di \\(X\\) e \\(Y\\) associati a ciascun esito, insieme alla probabilità di ciascun evento \\(\\omega\\):\n\n\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\nOra possiamo determinare la probabilità congiunta per ogni coppia \\((X, Y)\\), che rappresenta la probabilità di ottenere un determinato numero di teste \\(X\\) e un determinato risultato per il primo lancio \\(Y\\). Ad esempio:\n\\[P(X=0, Y=0) = P(\\text{CCC}) = 1/8,\\]\ne così via per le altre coppie.\nLe probabilità congiunte per tutte le possibili combinazioni \\((X, Y)\\) sono calcolate come segue:\n\\[\n\\begin{aligned}\nP(X = 0, Y = 0) &= 1/8, \\\\\nP(X = 1, Y = 0) &= P(\\text{CCT}) + P(\\text{CTC}) = 1/4, \\\\\nP(X = 1, Y = 1) &= P(\\text{TCC}) = 1/8, \\\\\nP(X = 2, Y = 0) &= P(\\text{CTT}) = 1/8, \\\\\nP(X = 2, Y = 1) &= P(\\text{TTC}) + P(\\text{TCT}) = 1/4, \\\\\nP(X = 3, Y = 1) &= P(\\text{TTT}) = 1/8.\n\\end{aligned}\n\\]\nQueste probabilità costituiscono la distribuzione di probabilità congiunta delle variabili casuali \\(X\\) (numero di teste) e \\(Y\\) (testa al primo lancio). Questa distribuzione fornisce un quadro completo delle probabilità per tutte le combinazioni di risultati di queste due variabili.\n\n\n29.2.2 Definizione: Funzione di Probabilità Congiunta\nLa funzione di probabilità congiunta di due variabili casuali \\(X\\) e \\(Y\\) associa a ogni coppia \\((x, y)\\) una probabilità \\(P(X = x, Y = y)\\).\n\n\n29.2.3 Proprietà\nUna distribuzione di probabilità congiunta deve soddisfare:\n\n\\(0 \\leq P(x_i, y_j) \\leq 1\\) per ogni coppia \\((x_i, y_j)\\),\n\\(\\sum_{i} \\sum_{j} P(x_i, y_j) = 1\\), ovvero la somma delle probabilità su tutte le coppie deve essere 1.\n\n\n\n29.2.4 Calcolo della Probabilità di Eventi Specifici\nData la distribuzione di probabilità congiunta, possiamo determinare la probabilità di eventi definiti in termini delle variabili aleatorie \\(X\\) e \\(Y\\). Ad esempio, per trovare la probabilità che \\(X + Y \\leq 1\\), sommiamo le probabilità di tutte le coppie \\((x, y)\\) che soddisfano questa condizione, ottenendo \\(P(X+Y \\leq 1) = 3/8\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#marginalizzazione",
    "href": "chapters/probability/09_joint_prob.html#marginalizzazione",
    "title": "29  Probabilità congiunta",
    "section": "29.3 Marginalizzazione",
    "text": "29.3 Marginalizzazione\nImmagina di condurre uno studio sul livello di stress tra studenti universitari, raccogliendo dati su variabili come l’anno di corso, il genere, il supporto sociale e il livello di stress. Se desideri comprendere come il livello di stress varia in funzione dell’anno di corso, indipendentemente dal genere e dal supporto sociale, puoi utilizzare la marginalizzazione.\nLa marginalizzazione consente di ottenere una distribuzione di probabilità focalizzata su una o più variabili di interesse, “eliminando” dal calcolo le variabili non rilevanti. Nel nostro esempio, per ottenere la distribuzione marginale del livello di stress rispetto all’anno di corso, occorre sommare (o integrare, nel caso di variabili continue) le probabilità associate a tutte le combinazioni di genere e supporto sociale, mantenendo fisso l’anno di corso. In questo modo, otteniamo una distribuzione che descrive come il livello di stress varia solo in relazione all’anno di corso.\nIl termine “marginalizzazione” deriva dalle tabelle di contingenza: quando rappresentiamo una distribuzione di probabilità congiunta in una tabella, le probabilità marginali—che descrivono la distribuzione di una variabile indipendentemente dalle altre—si trovano nei margini della tabella (ovvero nelle righe e colonne finali).\n\n29.3.1 Formalizzazione della Marginalizzazione\nData una distribuzione di probabilità congiunta \\(P(X, Y)\\) di due variabili casuali \\(X\\) e \\(Y\\), possiamo ottenere la distribuzione marginale di \\(X\\) sommando tutte le probabilità associate a \\(Y\\). Formalmente:\n\\[\nP(X = x) = \\sum_y P(X = x, Y = y),\n\\]\ndove \\(P(X = x, Y = y)\\) rappresenta la probabilità congiunta di \\(X\\) e \\(Y\\). La marginalizzazione garantisce inoltre che le distribuzioni siano normalizzate, cioè che le somme delle probabilità marginali per ciascuna variabile siano uguali a 1:\n\\[\n\\sum_x P(X = x) = 1 \\quad \\text{e} \\quad \\sum_y P(Y = y) = 1.\n\\]\nNel caso di variabili continue, questa operazione di somma viene sostituita dall’integrazione.\nPer chiarire, consideriamo il seguente esempio. Supponiamo di studiare l’efficacia di una terapia cognitivo-comportamentale per l’ansia, includendo variabili come l’età dei partecipanti e il livello iniziale di ansia. Se vogliamo valutare l’efficacia della terapia a prescindere dall’età e dal livello di ansia iniziale, marginalizziamo rispetto a queste due variabili, ottenendo così una distribuzione che riflette solo l’associazione tra terapia e riduzione dell’ansia.\nIn sintesi, la marginalizzazione:\n\npermette di estrarre distribuzioni di probabilità per variabili specifiche, “dimenticando” quelle non rilevanti;\nconsiste nel sommare o integrare le probabilità attraverso tutte le possibili combinazioni delle variabili non rilevanti, concentrandosi su quelle di interesse.\n\nIn conclusione, la marginalizzazione è uno strumento essenziale per l’analisi statistica, facilitando lo studio delle relazioni tra variabili complesse e aiutandoci a isolare gli effetti delle variabili di interesse in modo rigoroso.\n\nEsempio 29.1 Per fare un esempio, prendiamo come riferimento l’esperimento del lancio di tre monete equilibrate descritto precedentemente. Per calcolare le probabilità marginali di \\(X\\) e \\(Y\\), sommiamo le probabilità congiunte su una dimensione. La probabilità marginale di \\(X\\), \\(P_X\\), si ottiene sommando le probabilità lungo le colonne per ciascun valore fisso di \\(X\\); analogamente, la probabilità marginale di \\(Y\\), \\(P_Y\\), si calcola sommando le probabilità lungo le righe per ciascun valore fisso di \\(Y\\).\nLa tabella seguente mostra la distribuzione di probabilità congiunta \\(P(X, Y)\\) e le probabilità marginali \\(P(X)\\) e \\(P(Y)\\):\n\n\n\n\\(x \\setminus y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0\n\n\n\n\n\n\n29.3.2 Marginalizzazione per Variabili Casuali Continue\nNell’ambito della statistica bayesiana, il concetto di marginalizzazione gioca un ruolo cruciale. Un esempio di equazione che emerge da questo processo è:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) \\, d\\theta = \\int_{\\theta} p(y \\mid \\theta) p(\\theta) \\, d\\theta,\n\\]\ndove \\(y\\) e \\(\\theta\\) sono variabili casuali continue, con \\(y\\) che rappresenta i dati osservati e \\(\\theta\\) i parametri di un modello statistico. Questa equazione illustra come, in un contesto continuo, la marginalizzazione possa essere vista come l’estensione dell’approccio discreto a un continuum di valori per le variabili in esame.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#indipendenza-tra-variabili-casuali",
    "href": "chapters/probability/09_joint_prob.html#indipendenza-tra-variabili-casuali",
    "title": "29  Probabilità congiunta",
    "section": "29.4 Indipendenza tra Variabili Casuali",
    "text": "29.4 Indipendenza tra Variabili Casuali\nL’indipendenza tra variabili casuali è un concetto fondamentale in statistica e probabilità, parallelo all’idea di indipendenza tra eventi. Due variabili casuali si considerano indipendenti quando l’informazione su una non altera in alcun modo la distribuzione di probabilità dell’altra. Questa sezione offre una formalizzazione dell’indipendenza tra due variabili casuali discrete, basata sulla loro distribuzione di probabilità congiunta.\n\n29.4.1 Definizione di Indipendenza\nDue variabili casuali \\(X\\) e \\(Y\\), con una distribuzione congiunta, sono definite indipendenti se, e solo se, per ogni coppia di valori \\((x, y)\\) si verifica che:\n\\[\nP_{X, Y}(x, y) = P_X(x) \\cdot P_Y(y).\n\\]\nIn termini pratici, ciò significa che se \\(X\\) e \\(Y\\) sono variabili casuali discrete indipendenti, la loro distribuzione di probabilità congiunta è il prodotto delle rispettive distribuzioni di probabilità marginali. Se invece \\(P_{X, Y}(x, y) \\neq P_X(x) \\cdot P_Y(y)\\), le variabili non sono indipendenti e si dicono associate o dipendenti.\nQuesto concetto si applica anche alle variabili casuali continue, mantenendo la stessa logica: l’indipendenza si verifica quando la funzione di densità congiunta è il prodotto delle funzioni di densità marginali.\n\n\n29.4.2 Associazione tra Variabili Casuali\nQuando due variabili casuali non sono indipendenti, si descrivono come associate o dipendenti. In questo contesto, è utile introdurre il concetto di covarianza (e correlazione) come misura del grado di associazione lineare tra due variabili casuali. La covarianza e la correlazione quantificano in che modo la variazione di una variabile è associata alla variazione dell’altra, fornendo un indice della loro interdipendenza lineare.\nRiepilogando, l’indipendenza tra variabili casuali è un concetto chiave per comprendere le relazioni tra fenomeni aleatori. Riconoscere se due variabili sono indipendenti o associate è fondamentale per l’analisi statistica e per la modellazione di relazioni causali o di correlazione tra variabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#covarianza",
    "href": "chapters/probability/09_joint_prob.html#covarianza",
    "title": "29  Probabilità congiunta",
    "section": "29.5 Covarianza",
    "text": "29.5 Covarianza\nLa covarianza è un parametro statistico che quantifica il grado e la direzione della relazione lineare tra due variabili casuali, \\(X\\) e \\(Y\\). In termini semplici, misura come le variazioni di una variabile si accompagnano a quelle dell’altra. Per esempio, considerando l’altezza e il peso di giraffe, scopriremmo che queste due misure tendono ad aumentare insieme, evidenziando così una covarianza positiva. La covarianza è denotata come \\(Cov(X, Y) = \\sigma_{xy}\\).\n\n29.5.1 Definizione di Covarianza\nLa covarianza tra due variabili casuali \\(X\\) e \\(Y\\) è definita come:\n\\[\nCov(X, Y) = \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right],\n\\]\ndove \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) rappresentano i valori attesi (o medie) di \\(X\\) ed \\(Y\\), rispettivamente.\nIn termini più espliciti, la covarianza può essere espressa come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y),\n\\]\ndove \\(\\mu_X\\) e \\(\\mu_Y\\) sono le medie di \\(X\\) ed \\(Y\\), e \\(f(x, y)\\) è la funzione di probabilità congiunta delle variabili.\nQuesta definizione mostra una stretta analogia con la varianza, che è la covarianza di una variabile con se stessa:\n\\[\n\\mathbb{V}(X) = Cov(X, X).\n\\]\nInoltre, la covarianza può essere calcolata attraverso la relazione:\n\\[\nCov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\]\n\n\n29.5.2 Dimostrazione\nLa formula alternativa per la covarianza si dimostra come segue:\n\\[\n\\begin{align}\nCov(X, Y) &= \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right]\\\\\n&= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\end{align}\n\\]\n\n\n29.5.3 Esempio di Calcolo della Covarianza\nConsideriamo le variabili casuali \\(X\\) e \\(Y\\) con medie \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). La covarianza di \\(X\\) e \\(Y\\) si calcola come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y) = \\frac{1}{4}.\n\\]\nQuesto risultato si può ottenere anche dalla formula alternativa, calcolando prima \\(\\mathbb{E}(XY)\\):\n\\[\n\\mathbb{E}(XY) = 1.0.\n\\]\nAllora, la covarianza tra \\(X\\) e \\(Y\\) è:\n\\[\nCov(X, Y) = 1 - 1.5 \\cdot 0.5 = 0.25.\n\\]\n\nEsempio 29.2 Per calcolare la covarianza \\(Cov(X, Y)\\) in R, consideriamo l’esempio in cui \\(X\\) è il numero totale di teste che si ottiene dal lancio di tre monete equilibrate e \\(Y\\) è il risultato del primo lancio (testa = 1, croce = 0). Procediamo creando il prodotto cartesiano di tutti i possibili valori di \\(X\\) e \\(Y\\).\n\n# Creare il prodotto cartesiano di X (c3) e Y (c1)\nc3 &lt;- 0:3  # Numero totale di teste possibili\nc1 &lt;- 0:1  # Risultato del primo lancio (0 = croce, 1 = testa)\nsample &lt;- expand.grid(c1 = c1, c3 = c3)\nsample\n#&gt;   c1 c3\n#&gt; 1  0  0\n#&gt; 2  1  0\n#&gt; 3  0  1\n#&gt; 4  1  1\n#&gt; 5  0  2\n#&gt; 6  1  2\n#&gt; 7  0  3\n#&gt; 8  1  3\n\nIl primo numero di ogni coppia rappresenta il valore di \\(Y\\), mentre il secondo rappresenta il valore di \\(X\\). Tuttavia, queste coppie \\((X, Y)\\) non hanno tutte la stessa probabilità di verificarsi. La probabilità associata a ciascuna coppia è data dai seguenti valori: \\(1/8, 2/8, 1/8, 0, 0, 1/8, 2/8, 1/8\\). Questa è la distribuzione di massa di probabilità congiunta delle variabili casuali \\(X\\) e \\(Y\\). Applicando la formula per la covarianza:\n[ Cov(X, Y) = _{i=1}^n (X_i - E[X])(Y_i - E[Y]) P(X_i, Y_i) ]\nCalcoliamo la covarianza in R:\n\n# Probabilità di ogni coppia (X, Y)\npmf &lt;- c(1 / 8, 2 / 8, 1 / 8, 0, 0, 1 / 8, 2 / 8, 1 / 8)\n\n# Calcolo della covarianza\nres &lt;- c()\nfor (i in 1:nrow(sample)) {\n  res &lt;- c(res, (sample$c1[i] - 0.5) * (sample$c3[i] - 1.5) * pmf[i])\n}\n\n# Somma dei prodotti ponderati\ncovariance &lt;- sum(res)\ncovariance\n#&gt; [1] -0.125\n\nLa covarianza tra \\(X\\) e \\(Y\\) è dunque uguale a \\(-0.125\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#correlazione",
    "href": "chapters/probability/09_joint_prob.html#correlazione",
    "title": "29  Probabilità congiunta",
    "section": "29.6 Correlazione",
    "text": "29.6 Correlazione\nMentre la covarianza fornisce un’indicazione della tendenza di due variabili casuali a variare insieme, essa è influenzata dalle unità di misura delle variabili, rendendo difficile valutare l’intensità della loro relazione lineare. Per ovviare a questo, si utilizza la correlazione, che normalizza la covarianza attraverso le deviazioni standard delle variabili, offrendo così una misura standardizzata dell’associazione lineare tra di esse.\n\nDefinizione 29.1 Il coefficiente di correlazione tra due variabili casuali \\(X\\) e \\(Y\\), denotato come \\(\\rho(X,Y)\\) o \\(\\rho_{X,Y}\\), è definito come:\n\\[\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{\\mathbb{V}(X)\\mathbb{V}(Y)}},\n\\]\ndove \\(\\mathbb{V}(X)\\) e \\(\\mathbb{V}(Y)\\) rappresentano le varianze di \\(X\\) e \\(Y\\), rispettivamente.\n\nIl coefficiente di correlazione \\(\\rho_{xy}\\) è un valore adimensionale, ovvero non dipende dalle unità di misura delle variabili, e varia nell’intervallo \\(-1 \\leq \\rho \\leq 1\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#proprietà-1",
    "href": "chapters/probability/09_joint_prob.html#proprietà-1",
    "title": "29  Probabilità congiunta",
    "section": "29.7 Proprietà",
    "text": "29.7 Proprietà\n\nCovarianza con una Costante: La covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) è sempre nulla: \\(Cov(c, X) = 0\\).\nSimmetria: La covarianza è simmetrica: \\(Cov(X,Y) = Cov(Y,X)\\).\nIntervallo di Correlazione: Il coefficiente di correlazione \\(\\rho\\) varia tra -1 e 1: \\(-1 \\leq \\rho(X,Y) \\leq 1\\).\nIndipendenza dalle Unità di Misura: La correlazione è indipendente dalle unità di misura: \\(\\rho(aX, bY) = \\rho(X,Y)\\) per ogni \\(a, b &gt; 0\\).\nRelazione Lineare Perfetta: Se \\(Y = a + bX\\) è una funzione lineare di \\(X\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\).\nCovarianza e Costanti: La covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, è \\(Cov(aX, bY) = ab \\, Cov(X,Y)\\).\nVarianza della Somma/Differenza: \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2Cov(X,Y)\\).\nCovarianza e Somma di Variabili: \\(Cov(X + Y, Z) = Cov(X,Z) + Cov(Y,Z)\\).\nVarianza di una Somma di Variabili Aleatorie: Per variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\(\\mathbb{V}(\\sum_{i=1}^n X_i) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i&lt;j} Cov(X_i, X_j)\\).\nCovarianza e Somme di Prodotti: \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j Cov(X_i, Y_j)\\).\nIndipendenza e Covarianza di Somme: Se \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_j X_j) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i)\\).\n\n\n29.7.1 Incorrelazione\nDue variabili casuali \\(X\\) ed \\(Y\\) si dicono incorrelate, o linearmente indipendenti, se la loro covarianza è nulla:\n\\[\nCov(X,Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)] = 0,\n\\]\nequivalente a dire che \\(\\rho_{XY} = 0\\) e \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nQuesta condizione indica una forma di indipendenza più debole rispetto all’indipendenza stocastica. Tuttavia, \\(Cov(X, Y) = 0\\) non implica necessariamente che \\(X\\) ed \\(Y\\) siano stocasticamente indipendenti.\n\nEsempio 29.3 Consideriamo una distribuzione di probabilità congiunta di due variabili aleatorie, \\(X\\) e \\(Y\\), definita come:\n\\[\nf_{XY}(x,y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}, \\\\\n0 & \\text{altrimenti.}\n\\end{array}\n\\right.\n\\]\nQuesto implica che le variabili aleatorie \\(X\\) e \\(Y\\) assumono valori specifici con probabilità uniforme solo per determinate coppie \\((x, y)\\) e zero in tutti gli altri casi.\nDistribuzioni Marginali\nLa distribuzione marginale di \\(X\\) si ottiene sommando le probabilità congiunte su tutti i possibili valori di \\(Y\\), e viceversa per \\(Y\\). Le distribuzioni marginali risultano essere:\n\nPer \\(X\\):\n\\[\nf_X(x) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } x=0, \\\\\n\\frac{1}{2} & \\text{per } x=1, \\\\\n\\frac{1}{4} & \\text{per } x=2.\n\\end{array}\n\\right.\n\\]\nPer \\(Y\\):\n\\[\nf_Y(y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } y=-1, \\\\\n\\frac{1}{2} & \\text{per } y=0, \\\\\n\\frac{1}{4} & \\text{per } y=1.\n\\end{array}\n\\right.\n\\]\n\nMedie e Varianze\nCalcoliamo ora le medie e le varianze di \\(X\\) e \\(Y\\):\n\nMedia di \\(X\\):\n\\[\n\\mathbb{E}(X) = 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{2} + 2 \\cdot \\frac{1}{4} = 1.\n\\]\nVarianza di \\(X\\):\n\\[\n\\mathbb{V}(X) = \\left(0^2 \\cdot \\frac{1}{4} + 1^2 \\cdot \\frac{1}{2} + 2^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(X)^2 = \\frac{3}{2} - 1 = \\frac{1}{2}.\n\\]\nMedia di \\(Y\\):\n\\[\n\\mathbb{E}(Y) = (-1) \\cdot \\frac{1}{4} + 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{4} = 0.\n\\]\nVarianza di \\(Y\\):\n\\[\n\\mathbb{V}(Y) = \\left((-1)^2 \\cdot \\frac{1}{4} + 0^2 \\cdot \\frac{1}{2} + 1^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(Y)^2 = \\frac{1}{2}.\n\\]\n\nCovarianza tra X e Y\nLa covarianza si calcola come:\n\\[\nCov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y),\n\\]\ndove \\(\\mathbb{E}(XY)\\) si trova sommando il prodotto delle coppie di valori \\((x, y)\\) per la loro probabilità congiunta:\n\\[\n\\mathbb{E}(XY) = 0.\n\\]\nDi conseguenza, la covarianza tra \\(X\\) e \\(Y\\) è zero:\n\\[\nCov(X,Y) = 0 - 1 \\cdot 0 = 0.\n\\]\nConclusioni\nSebbene \\(X\\) e \\(Y\\) siano incorrelate (covarianza nulla), ciò non implica la loro indipendenza. L’indipendenza richiede che la funzione di probabilità congiunta si possa esprimere come il prodotto delle funzioni di probabilità marginali per ogni \\(x\\) e \\(y\\), condizione che non si verifica in questo caso. Quindi, nonostante l’assenza di correlazione, \\(X\\) e \\(Y\\) non sono indipendenti, dimostrando che l’incorrelazione non garantisce l’indipendenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#variabili-continue",
    "href": "chapters/probability/09_joint_prob.html#variabili-continue",
    "title": "29  Probabilità congiunta",
    "section": "29.8 Variabili continue",
    "text": "29.8 Variabili continue\nConsideriamo ora le distribuzioni di densità. Nella figura successiva, tratta da Martin (2024), vediamo una rappresentazione della relazione tra la probabilità congiunta \\(p(A,B)\\), le probabilità marginali \\(p(A)\\) e \\(p(B)\\), e le probabilità condizionali \\(p(A \\mid B)\\).\n\n\n\nDistribuzioni di densità (figura tratta da Martin (2024)).\n\n\n\nProbabilità congiunta \\(p(A,B)\\): rappresenta la probabilità che A e B assumano certi valori contemporaneamente. Per le variabili continue, questa è data dall’integrazione della funzione di densità congiunta su un’area o volume di interesse.\nProbabilità marginale \\(p(A)\\) e \\(p(B)\\): è la probabilità di osservare un particolare valore di A (o B) indipendentemente dal valore di B (o A). Si ottiene integrando la funzione di densità congiunta sull’intero intervallo di valori dell’altra variabile.\nProbabilità condizionale \\(p(A \\mid B)\\): esprime la probabilità di A dato B. Si calcola dividendo la probabilità congiunta per la probabilità marginale di B, applicando la definizione di probabilità condizionale anche nel contesto continuo.\n\nLa transizione dal trattamento delle variabili discrete a quello delle variabili continue richiede un cambiamento di strumenti matematici da somme ad integrali, ma i concetti fondamentali di probabilità congiunta, marginale e condizionale rimangono applicabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/09_joint_prob.html#riflessioni-conclusive",
    "title": "29  Probabilità congiunta",
    "section": "29.9 Riflessioni Conclusive",
    "text": "29.9 Riflessioni Conclusive\nIn alcune situazioni, ogni singolo elemento di una popolazione può essere associato a diverse variabili casuali. Ad esempio, consideriamo l’elenco di tutti gli studenti iscritti a un’università e immaginiamo di selezionare uno studente a caso per misurare la sua altezza e il suo peso. In questo caso, ogni individuo della popolazione è associato a due variabili casuali, l’altezza e il peso. Quando si hanno due o più variabili casuali associate ad ogni elemento di una popolazione, è possibile studiare la distribuzione congiunta di tali variabili casuali. In questo capitolo abbiamo esaminato come rappresentare la distribuzione di massa di probabilità congiunta di due variabili casuali discrete e come ottenere le distribuzioni marginali delle due variabili. Inoltre, abbiamo discusso i concetti di incorrelazione e indipendenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/09_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "29  Probabilità congiunta",
    "section": "29.10 Informazioni sull’Ambiente di Sviluppo",
    "text": "29.10 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#bibliografia",
    "href": "chapters/probability/09_joint_prob.html#bibliografia",
    "title": "29  Probabilità congiunta",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMartin, O. (2024). Bayesian analysis with python. Packt Publishing Ltd.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html",
    "href": "chapters/probability/10_density_func.html",
    "title": "30  La funzione di densità di probabilità",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn precedenza abbiamo trattato solo variabili casuali discrete, ossia variabili che assumono solo valori interi. Tuttavia, se vogliamo rappresentare grandezze come lunghezze, volumi, distanze o qualsiasi altra proprietà continua del mondo fisico o psicologico, è necessario generalizzare l’approccio utilizzato finora.\nLe variabili casuali continue assumono valori reali, e l’insieme dei numeri reali è non numerabile in quanto è più grande dell’insieme degli interi.1 Le leggi della probabilità valgono sia per le variabili casuali discrete che per quelle continue. Tuttavia, la nozione di funzione di massa di probabilità deve essere sostituita dal suo equivalente continuo, la funzione di densità di probabilità. In questo capitolo, il nostro obiettivo è chiarire il significato di questa nozione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "href": "chapters/probability/10_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "title": "30  La funzione di densità di probabilità",
    "section": "30.1 Spinner e variabili casuali continue uniformi",
    "text": "30.1 Spinner e variabili casuali continue uniformi\nConsideriamo l’esperimento casuale in cui facciamo ruotare ad alta velocità uno spinner simmetrico imperniato su un goniometro e osserviamo la posizione in cui si ferma, identificata dall’angolo acuto con segno tra il suo asse e l’asse orizzontale del goniometro. Denotiamo con \\(\\Theta\\) la variabile casuale corrispondente alla “pendenza dello spinner”. In questo contesto, l’assunzione che lo spinner sia simmetrico implica che, in ogni prova, la rotazione produce un angolo qualunque da 0 a 360 gradi con la stessa probabilità. In altre parole, un valore \\(\\Theta\\) compreso tra 0 e 36 gradi ha la stessa probabilità di essere osservato di un valore \\(\\Theta\\) compreso tra 200 e 236 gradi. Inoltre, dal momento che 36 gradi corrisponde a un decimo del percorso intorno al cerchio, la probabilità di ottenere un qualsiasi intervallo di 36 gradi sarà sempre uguale al 10%. Più precisamente, si ha \\(P(0 \\leq \\Theta \\leq 36) = \\frac{1}{10}\\) e \\(P(200 \\leq \\Theta \\leq 236) = \\frac{1}{10}\\).\nÈ importante sottolineare che le probabilità sopra menzionate non si riferiscono al fatto che la variabile casuale \\(\\Theta\\) assuma un valore specifico, ma piuttosto all’evento di osservare \\(\\Theta\\) in un intervallo di valori. In generale, la probabilità che la pendenza \\(\\Theta\\) cada in un intervallo specificato è data dalla frazione del cerchio rappresentata dall’intervallo, cioè \\(P(\\theta_1 \\leq \\Theta \\leq \\theta_2) = \\frac{\\theta_2 - \\theta_1}{360}\\), per ogni intervallo \\([\\theta_1, \\theta_2]\\) tale che \\(0 \\leq \\theta_1 \\leq \\theta_2 \\leq 360\\).\nNel caso di una variabile casuale continua, come l’angolo dello spinner, dunque, è facile capire come assegnare una probabilità all’evento in cui la variabile casuale assuma un valore compreso in un intervallo.\n\n30.1.1 Distribuzione uniforme\nL’esempio dello spinner rappresenta il “meccanismo generatore dei dati” della variabile casuale continua più semplice, ovvero la distribuzione continua uniforme. In teoria della probabilità, la distribuzione continua uniforme è una distribuzione di probabilità continua che assegna la stessa probabilità a tutti i punti appartenenti ad un intervallo [a, b] contenuto in un certo insieme.\nLa distribuzione uniforme continua definita sull’intervallo \\({\\displaystyle S=[a,b]\\subset \\mathbb {R}}\\) viene denotata con \\({\\displaystyle {\\mathcal {U}}(a,b)={\\mathcal {U}}([a,b])}\\). La sua densità di probabilità è\n\\[\nf(x) = \\frac{1}{b-a}, \\quad a \\leq x \\leq b\n\\]\ne 0 altrimenti. La distribuzione uniforme continua è caratterizzata dalla sua proprietà di equidistribuzione: tutti gli intervalli di pari lunghezza all’interno dell’intervallo [a, b] hanno la stessa probabilità. In altre parole, se \\({\\displaystyle [c,d]}\\) è un sottointervallo di \\({\\displaystyle [a,b]}\\), allora la probabilità che una variabile casuale continua con distribuzione uniforme in \\({\\displaystyle [a,b]}\\) cada in \\({\\displaystyle [c,d]}\\) è \\({\\displaystyle (d-c)/(b-a)}\\).\nSvolgiamo un esercizio con R in cui, per continuare il nostro esempio dello spinner, consideriamo una \\(\\mathcal {U}(0, 360)\\).\n\n# Definire i parametri della distribuzione uniforme\na &lt;- 0\nb &lt;- 360\nsize &lt;- 101\nx &lt;- seq(a, b, length.out = size)\ny &lt;- dunif(x, min = a, max = b)\n\ndata &lt;- data.frame(X = x, Density = y)\n\nggplot(data, aes(x = X, y = Density)) +\n  geom_line() +\n  labs(\n    x = \"X\",\n    y = \"Densità\",\n    title = \"Distribuzione Uniforme\"\n  ) \n\n\n\n\n\n\n\n\nGeneriamo 100,000 valori casuali di una v.c. \\(\\Theta \\sim \\mathcal {U}(0, 360)\\).\n\n# Generare dati da una distribuzione uniforme tra 0 e 360\ndata &lt;- runif(100000, min = 0, max = 360)\n\nL’istogramma delle 100,000 realizzazioni di \\(\\Theta\\) è il seguente.\n\ndf &lt;- data.frame(Theta = data)\n\nggplot(df, aes(x = Theta)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    fill = \"blue\",\n    alpha = 0.5\n  ) +\n  labs(\n    x = expression(Theta ~ U(0, 360)),\n    y = \"Densità\",\n    title = \"Distribuzione uniforme\"\n  )\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nÈ chiaro che, all’aumentare del numero delle realizzazioni \\(\\Theta\\), il profilo dell’istogramma tenderà a diventare una linea retta. Ciò significa che la funzione di densità di una variabile casuale uniforme continua è una costante: \\(f(\\Theta) = c\\).\nDalla figura precedente vediamo che l’area sottesa alla funzione di densità è \\((b - a)\\cdot c\\). Dato che tale area deve essere unitaria, ovvero, \\((b - a) \\cdot c = 1\\), possiamo trovare \\(c\\) dividendo entrambi i termini per \\(b - a\\),\n\\[\nc  = \\frac{\\displaystyle{1}}{\\displaystyle b - a}.\n\\]\nOvvero, se \\(\\Theta \\sim \\mathcal{U}(a, b)\\), allora\n\\[\np_{\\Theta}(\\theta) = \\mathcal{U}(\\theta \\mid a, b),\n\\]\nladdove\n\\[\n\\mathcal{U}(\\theta \\mid a, b) = \\frac{1}{b - a}.\n\\]\nIn conclusione, la densità di una variabile casuale uniforme continua non dipende da \\(\\theta\\) – è costante e identica per ogni possibile valore \\(\\theta\\).\nIl valore atteso di \\(X \\sim \\mathcal {U}(a,b)\\) è dato da\n\\[\n\\mathbb{E} = \\frac{b - a}{2}.\n\\]\nNel caso della presente simulazione otteniamo\n\nmean(df$Theta)\n#&gt; [1] 180.2548\n\nSvolgiamo un altro semplice esercizio. Consideriamo una variabile casuale uniforme \\(X\\) definita sull’intervallo [0, 100]. Poniamoci il problema di trovare la probabilità \\(P(20 &lt; X &lt; 60)\\).\nPer trovare la soluzione è sufficiente calcolare l’area di un rettangolo di base \\(60 - 20 = 40\\) e di altezza 1/100. La probabilità cercata è dunque \\(P(20 &lt; X &lt; 60) = 40 \\cdot 0.01 = 0.4\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#il-paradosso-delle-variabili-casuali-continue",
    "href": "chapters/probability/10_density_func.html#il-paradosso-delle-variabili-casuali-continue",
    "title": "30  La funzione di densità di probabilità",
    "section": "30.2 Il paradosso delle variabili casuali continue",
    "text": "30.2 Il paradosso delle variabili casuali continue\nConsideriamo ora la probabilità che la variabile casuale continua assuma un valore specifico, come ad esempio una pendenza dello spinner esattamente uguale a 36 gradi. Sorprendentemente, la risposta è zero:\n\\[\nP(\\Theta = 36) = 0.\n\\]\nCiò è dovuto al fatto che se la probabilità di un valore specifico fosse maggiore di zero, allora ogni altro possibile valore dovrebbe avere la stessa probabilità, poiché abbiamo assunto che tutti i valori \\(\\Theta\\) sono egualmente probabili. Ma se sommiamo tutte queste probabilità, il totale sarebbe maggiore di uno, il che è impossibile.\nNel caso delle variabili casuali continue, dobbiamo quindi rinunciare all’idea che ogni singolo valore della variabile casuale possa avere una massa di probabilità maggiore di zero. Invece, una massa di probabilità viene assegnata alla realizzazione della variabile casuale in un intervallo di valori. Questo è ciò che differenzia le variabili casuali continue dalle variabili casuali discrete, dove ogni singolo valore ha una probabilità di massa non nulla. In sintesi, le variabili casuali continue non hanno una massa di probabilità, ma una densità di probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#dagli-istogrammi-alle-densità",
    "href": "chapters/probability/10_density_func.html#dagli-istogrammi-alle-densità",
    "title": "30  La funzione di densità di probabilità",
    "section": "30.3 Dagli istogrammi alle densità",
    "text": "30.3 Dagli istogrammi alle densità\nLe considerazioni precedenti ci fanno comprendere che, a differenza delle variabili casuali discrete, non esiste l’equivalente di una funzione di massa di probabilità per le variabili casuali continue. Invece, esiste una funzione di densità di probabilità che può essere definita in termini di una simulazione. Considerando un numero enorme di casi e facendo tendere l’ampiezza \\(\\Delta\\) di ciascuna classe a 0, il profilo dell’istogramma delle frequenze delle classi di ampiezza \\(\\Delta\\) tende a diventare una curva continua. Tale curva continua \\(f(x)\\) è detta funzione di densità di probabilità.\nIn un istogramma, l’area di ogni barra è proporzionale alla frequenza relativa delle osservazioni nell’intervallo considerato. Dato che tutti gli intervalli hanno la stessa ampiezza, l’altezza di ogni barra sarà proporzionale alla frequenza relativa delle osservazioni nell’intervallo. Nella simulazione, possiamo pensare all’area di ciascuna barra dell’istogramma come alla stima della probabilità che la variabile casuale assuma un valore nell’intervallo considerato. Con l’aumentare del numero di osservazioni \\(M\\), le probabilità stimate si avvicinano sempre di più ai valori effettivi della probabilità. Inoltre, all’aumentare del numero degli intervalli (quando l’ampiezza \\(\\Delta\\) dell’intervallo tende a 0), il profilo dell’istogramma tende a diventare una curva continua. Tale curva continua è appunto la funzione di densità di probabilità della variabile casuale.\nIn precedenza, nella statistica descrittiva, abbiamo già incontrato una rappresentazione che ha lo stesso significato della funzione di densità, ovvero il kernel density plot. La stima della densità del kernel (KDE), infatti, è un metodo non parametrico utilizzato per stimare la funzione di densità di probabilità di una variabile casuale.\nPer fare un esempio, generiamo 50 valori dalla distribuzione del quoziente di intelligenza. Stampiamo i primi 5 valori.\n\n# Definire i parametri della distribuzione normale\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 50\n\n# Generare i dati\nset.seed(123)  # Per riproducibilità\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Mostrare i primi 5 valori\nhead(x, 5)\n#&gt; [1]  91.59287  96.54734 123.38062 101.05763 101.93932\n\nCreiamo ora un istogramma a cui sovrapponiamo la funzione di densità Normale con parametri corrispondenti alla media e deviazione standard del campione. Con poche osservazioni, non c’è una buona corrispondenza tra l’istogramma e la curva continua che abbiamo chiamato “funzione di densità”.\n\n# Calcolare la media e la deviazione standard dei dati\nmu &lt;- mean(x)\nstd &lt;- sd(x)\n\n# Creare un grafico dell'istogramma e della curva di densità\n\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = std)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 25,\n    fill = \"blue\",\n    alpha = 0.6\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    title = sprintf(\"Media e deviazione standard: %.2f e %.2f\", mu, std),\n    x = \"Valori\",\n    y = \"Densità\"\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nOra aumentiamo il numero di osservazioni. In questo caso consideriamo 20,000 valori del QI. Generiamo dunque una figura simile alla precedente, solo considerando un campione di dati più grande.\n\n# Generare dati normali\nsize &lt;- 10000\nset.seed(123)  # Per riproducibilità\nx &lt;- rnorm(size, mean = mu, sd = std)\n\n# Calcolare la media e la deviazione standard dei dati\nmu &lt;- mean(x)\nstd &lt;- sd(x)\n\n# Creare il grafico dell'istogramma e della curva di densità\n\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = std)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 50,\n    fill = \"blue\",\n    alpha = 0.6\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    title = sprintf(\"Media e deviazione standard: %.2f e %.2f\", mu, std),\n    x = \"Valori\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\nOra vediamo che c’è una corrispondenza molto buona tra il profilo dell’istogramma e la curva continua. Questo ci consente la seguente interpretazione: la funzione di densità è una curva che approssima il profilo di un istogramma, quando consideriamo un grande numero di osservazioni. In altre parole, una funzione di densità non è altro che un (profilo di un) istogramma nel caso di un numero infinito di osservazioni e intervalli di ampiezza \\(\\Delta\\) infinitamente piccoli.\nIn un istogramma, l’area di ciascuna barra è proporzionale alla frequenza relativa delle osservazioni in quel’intervallo. Perché tutti gli intervalli hanno la stessa ampiezza, anche l’altezza di ciascuna barra sarà proporzionale alla frequenza relativa delle osservazioni in quel’intervallo.\nNella simulazione, possiamo pensare all’area di ciascuna barra dell’istogramma come alla stima della probabilità che la variabile casuale assuma un valore compreso nell’intervallo considerato. All’aumentare del numero \\(M\\) di osservazioni, le probabilità stimate si avvicinano sempre di più ai veri valori della probabilità. All’aumentare del numero degli intervalli (quando l’ampiezza \\(\\Delta\\) dell’intervallo \\(\\rightarrow\\) 0), il profilo dell’istogramma tende a diventare una curva continua. Tale curva continua è la funzione di densità di probabilità della variabile casuale.\nNella statistica descrittiva abbiamo già incontrato una rappresentazione che ha lo stesso significato della funzione di densità, ovvero il kernel density plot. La stima della densità del kernel (KDE), infatti, è un metodo non parametrico per stimare la funzione di densità di probabilità di una variabile casuale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#interpretazioni-bayesiana-e-frequentista-della-funzione-di-densità-di-probabilità-pdf",
    "href": "chapters/probability/10_density_func.html#interpretazioni-bayesiana-e-frequentista-della-funzione-di-densità-di-probabilità-pdf",
    "title": "30  La funzione di densità di probabilità",
    "section": "30.4 Interpretazioni Bayesiana e Frequentista della Funzione di Densità di Probabilità (PDF)",
    "text": "30.4 Interpretazioni Bayesiana e Frequentista della Funzione di Densità di Probabilità (PDF)\nAbbiamo introdotto la funzione di densità di probabilità come limite del profilo di un istogramma, una descrizione intuitiva e utile per comprendere il concetto di densità. Questa interpretazione corrisponde, tuttavia, alla visione frequentista della densità di probabilità. Nella statistica Bayesiana, l’interpretazione è diversa e merita una spiegazione separata.\nNell’approccio Bayesiano, un parametro è considerato una “variabile casuale” che segue una distribuzione di valori, anziché un valore fisso. La Figura 30.1, vedi 30.1 illustra le diverse interpretazioni di una PDF per una quantità reale \\(x\\). Queste interpretazioni valgono sia che \\(x\\) rappresenti un parametro incognito sia che si tratti di un dato osservato.\nNel pannello di sinistra, vediamo l’interpretazione frequentista di \\(p(x)\\): la PDF rappresenta una collezione ipotetica di ripetizioni di esperimenti, in cui \\(x\\) può assumere diversi valori. La PDF corrisponde quindi a un istogramma limite di questi valori, distribuiti secondo \\(p(x)\\).\nIl pannello di destra, invece, raffigura l’interpretazione Bayesiana, in cui la PDF rappresenta l’incertezza sul valore di \\(x\\) per un singolo caso specifico. In questo caso, la probabilità si distribuisce lungo i possibili valori che \\(x\\) potrebbe assumere, visualizzata dalla sfumatura lungo l’asse \\(x\\).\nIn altre parole, nell’interpretazione frequentista, è il valore di \\(x\\) a essere distribuito in \\(p(x)\\) (attraverso ripetizioni dell’esperimento), mentre nell’interpretazione Bayesiana è la probabilità stessa a distribuirsi sui possibili valori di \\(x\\) nel caso analizzato. Una PDF Bayesiana può essere vista come analoga a una densità di materia \\(\\rho(x)\\) in meccanica classica: è la probabilità che si distribuisce lungo i possibili valori, e non i valori stessi di \\(x\\).\n\n\n\n\n\n\nFigura 30.1: Interpretazioni frequentista e bayesiana di una PDF (curva blu) per una quantità reale \\(x\\). A sinistra: interpretazione frequentista come istogramma limite dei valori di \\(x\\) nelle ripetizioni; i valori di \\(x\\) sono distribuiti secondo la PDF. A destra: interpretazione bayesiana, con \\(x\\) che assume un valore fisso ma incerto per il caso specifico (rappresentato dal punto sull’asse \\(x\\)), con la probabilità distribuita sui valori possibili (raffigurata con una sfumatura lungo l’asse \\(x\\)). (Figura tratta da Loredo & Wolpert, 2024)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#funzione-di-densità-di-probabilità",
    "href": "chapters/probability/10_density_func.html#funzione-di-densità-di-probabilità",
    "title": "30  La funzione di densità di probabilità",
    "section": "30.5 Funzione di densità di probabilità",
    "text": "30.5 Funzione di densità di probabilità\nDa un punto di vista matematico, l’intuizione precedente si può esprimere nel modo seguente.\nPer descrivere le probabilità che possono essere associate ad una variabile casuale continua \\(X\\) è necessario definire una funzione \\(p(X)\\) che deve soddisfare le seguenti due proprietà:\n\n\\(p(x) \\geq 0, \\forall x\\), ovvero, l’ordinata della funzione di densità è 0 o positiva;\n\\(\\int_{-\\infty}^{\\infty} p(x) \\,\\operatorname {d}\\!x = 1\\), ovvero, l’area sottesa dalla \\(p(x)\\) è unitaria2;\n\\(p(a &lt; x &lt; b) = \\int_a^b p(x) \\,\\operatorname {d}\\!x\\), se \\(a \\leq b\\), ovvero, l’area sottesa dalla \\(p(y)\\) tra due punti \\(a\\) e \\(b\\) corrisponde alla probabilità che la v.c. \\(x\\) assuma un valore compresto tra questi due estremi.\n\nInterpretazione. È possibile che \\(p(x) &gt; 1\\), quindi una densità di probabilità non può essere interpretata come una probabilità. Piuttosto, la densità \\(p(x)\\) può essere utilizzata per confrontare la credibilità relativa che può essere assegnata a diversi valori \\(x\\). Considerata una variabile casuale \\(X\\) di cui è disponibile un insieme di realizzazioni, possiamo dire che, se consideriamo due valori \\(x_k\\) e \\(x_l\\) con \\(p(x_k) &gt; p(x_l)\\), allora possiamo concludere che è più credibile, in termini relativi, osservare realizzazioni \\(X\\) nell’intorno di \\(x_k\\) piuttosto che nell’intorno di \\(x_l\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "chapters/probability/10_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "30  La funzione di densità di probabilità",
    "section": "30.6 La funzione di ripartizione per una variabile casuale continua",
    "text": "30.6 La funzione di ripartizione per una variabile casuale continua\nPer le variabili casuali continue, la funzione di ripartizione (ovvero, la distribuzione cumulativa) è definita esattamente come nel caso delle variabili casuali discrete:\n\\[\nF_{\\Theta}(\\theta) = P(\\Theta \\leq \\theta).\n\\]\nCioè, è la probabilità che la variabile casuale \\(\\Theta\\) assuma un valore minore di o uguale a \\(\\theta\\).\nCome nel caso discreto, la funzione di ripartizione di una v.c. continua può essere utilizzata per calcolare la probabilità che la v.c. assuma valori in un certo intervallo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#riflessioni-conclusive",
    "href": "chapters/probability/10_density_func.html#riflessioni-conclusive",
    "title": "30  La funzione di densità di probabilità",
    "section": "30.7 Riflessioni Conclusive",
    "text": "30.7 Riflessioni Conclusive\nLa funzione di densità di probabilità (PDF) è uno strumento fondamentale per descrivere distribuzioni di variabili continue. Un principio essenziale alla base di questa funzione è che la probabilità che una variabile aleatoria continua assuma un valore esatto è pari a zero. Matematicamente, ciò deriva dal fatto che l’area sotto la curva di densità in un punto singolo è sempre zero.\nQuesta concezione implica due conseguenze importanti:\n\nLa probabilità può essere calcolata solo per intervalli di valori, non per punti specifici.\nEventi con probabilità zero non sono necessariamente impossibili.\n\nDa questa seconda implicazione emerge un apparente paradosso: come possiamo conciliare il fatto che eventi osservabili (ad esempio, colpire il centro esatto di un bersaglio) abbiano probabilità zero?\nQuesto paradosso solleva due domande cruciali:\n\nÈ possibile confrontare le “possibilità” di eventi diversi che hanno tutti probabilità zero?\nCome può l’unione di infiniti eventi con probabilità zero (ogni punto specifico di un intervallo) dare origine a un evento certo (scegliere un punto qualsiasi nell’intervallo)?\n\nIl “paradosso della probabilità zero” richiama alla mente il famoso paradosso di Zenone sulla freccia: se in ogni istante la freccia è ferma, come può essa muoversi? In entrambi i casi, siamo posti di fronte a una sfida concettuale: come può una somma di “nulla” (eventi con probabilità zero) dare origine a “qualcosa” (un evento con probabilità certa)?\nUna soluzione moderna a questo enigma è emersa negli anni ’60 con il lavoro di Abraham Robinson sugli infinitesimi. Gli infinitesimi sono numeri infinitamente piccoli ma non nulli, che esistono tra zero e qualsiasi numero positivo reale. Questa teoria consente di assegnare probabilità infinitesimali a eventi che, nella teoria classica, avrebbero probabilità zero.\nApplicando questa idea al nostro paradosso, possiamo concludere che:\n\nLa probabilità di colpire un punto specifico non è zero, ma infinitesimale.\nLa probabilità di colpire uno tra due punti specifici è maggiore di quella di colpire un singolo punto, anche se la differenza è infinitesimale.\n\nQuesto approccio risolve il paradosso permettendo di distinguere tra eventi che nella teoria classica erano tutti assegnati a probabilità zero. Inoltre, spiega come l’unione di molti eventi con probabilità infinitesimale possa portare a un evento con probabilità uno.\nL’introduzione degli infinitesimi non è solo un artificio matematico, ma rappresenta un ritorno alle idee originarie di Newton e Leibniz, fornendo una base rigorosa per trattare l’infinitamente piccolo in matematica. Questa teoria offre un nuovo modo di concepire concetti come l’infinito e la continuità, con applicazioni che si estendono ben oltre la teoria della probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/10_density_func.html#informazioni-sullambiente-di-sviluppo",
    "title": "30  La funzione di densità di probabilità",
    "section": "30.8 Informazioni sull’Ambiente di Sviluppo",
    "text": "30.8 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.0       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#bibliografia",
    "href": "chapters/probability/10_density_func.html#bibliografia",
    "title": "30  La funzione di densità di probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLoredo, T. J., & Wolpert, R. L. (2024). Bayesian inference: more than Bayes’s theorem. Frontiers in Astronomy and Space Sciences, 11, 1326926.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#footnotes",
    "href": "chapters/probability/10_density_func.html#footnotes",
    "title": "30  La funzione di densità di probabilità",
    "section": "",
    "text": "Georg Cantor dimostrò che era impossibile mappare uno a uno i reali negli interi, dimostrando così che l’insieme dei reali è non numerabile.↩︎\nPer quel che riguarda la notazione dell’integrale, ovvero \\(\\int_x \\,\\operatorname {d}\\!x\\), rimando alla discussione di S.P. Thompson: https://calculusmadeeasy.org/1.html↩︎",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html",
    "href": "chapters/probability/11_discr_rv_distr.html",
    "title": "31  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "31.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nLa previsione è un processo che ci permette di formulare ipotesi su eventi incerti, sfruttando le regolarità osservate nei processi naturali, sociali e psicologici. Uno degli obiettivi principali della data science è proprio quello di prevedere fenomeni di cui non abbiamo ancora certezza, inclusi, ma non limitati a, eventi futuri.\nLa capacità di fare previsioni senza considerare ogni possibile risultato dipende dalla conoscenza della popolazione di riferimento. Gli esseri umani organizzano e rappresentano questa conoscenza in vari modi. In questo capitolo, esploreremo le implicazioni di un approccio specifico alla rappresentazione delle popolazioni: le distribuzioni di probabilità.\nSupponiamo di avere una distribuzione di probabilità \\(p(x)\\) associata a una variabile casuale \\(X\\). Consideriamo che questa distribuzione rappresenti la variabilità osservata all’interno di una popolazione. Se selezionassimo un’istanza in modo uniforme e casuale dalla popolazione, quale valore della variabile \\(X\\) dovremmo aspettarci? Ci aspettiamo che un campione estratto casualmente dalla popolazione segua la distribuzione \\(p(x)\\). In altre parole, questa distribuzione è ciò che definiamo un modello statistico, o più semplicemente, un modello della popolazione. Il termine “modello” sottolinea che la distribuzione non è la popolazione stessa, ma una rappresentazione astratta che utilizziamo per fare previsioni.\nIn particolare, ci concentreremo sulle distribuzioni di probabilità discrete, essenziali per comprendere i fenomeni aleatori che presentano un numero finito o numerabile di esiti. Queste distribuzioni sono cruciali nella modellazione e nell’analisi di eventi che si verificano in contesti discreti, fornendo le basi per una comprensione più profonda delle dinamiche probabilistiche che governano tali fenomeni.\nOgni distribuzione di probabilità è caratterizzata da uno o più parametri, che consentono di controllare specifici aspetti della distribuzione stessa. Esploreremo diverse distribuzioni discrete, ciascuna con le sue caratteristiche e applicazioni:\nIn sintesi, attraverso lo studio di queste distribuzioni, acquisiremo gli strumenti necessari per analizzare e prevedere una vasta gamma di situazioni reali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#introduzione",
    "href": "chapters/probability/11_discr_rv_distr.html#introduzione",
    "title": "31  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "Distribuzione di Bernoulli\n\nRappresenta esperimenti con due possibili esiti: “successo” o “insuccesso”\nCostituisce il nucleo dei processi Bernoulliani\nParametro chiave: probabilità di successo in ciascuna prova\n\nDistribuzione Binomiale\n\nDescrive il numero totale di successi in un numero fisso di prove Bernoulliane\nNasce dalla somma di prove Bernoulliane indipendenti\nParametri: probabilità di successo in ciascuna prova e numero totale di prove\n\nDistribuzione di Poisson\n\nModella eventi rari o che si verificano su intervalli di tempo o spazio variabili\nAdatta quando il numero di prove è una variabile casuale\nParametro: tasso medio di successo per unità di tempo o spazio\n\nDistribuzione Beta-Binomiale\n\nUtilizzata quando la probabilità di successo in una serie di prove Bernoulliane non è costante\nOffre una rappresentazione più flessibile rispetto alla distribuzione binomiale\nParametri: derivati dalla distribuzione Beta sottostante\n\nDistribuzione Uniforme Discreta\n\nOgni evento all’interno di un determinato intervallo finito ha la stessa probabilità\nUtile quando non ci sono motivi per privilegiare un risultato rispetto a un altro\nNon dipende da parametri una volta stabilito il supporto della distribuzione",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-bernoulli",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-bernoulli",
    "title": "31  Distribuzioni di v.c. discrete",
    "section": "31.2 Distribuzione di Bernoulli",
    "text": "31.2 Distribuzione di Bernoulli\nIn statistica, un esperimento che ammette solo due esiti possibili è modellato attraverso quella che viene chiamata “prova Bernoulliana”. Un esempio tipico è il lancio di una moneta, che può dare come risultato testa o croce.\n\nDefinizione 31.1 Una variabile casuale \\(X\\) che assume valori in \\(\\{0, 1\\}\\) è detta variabile di Bernoulli. La sua distribuzione di probabilità è definita come:\n\\[\nP(X \\mid \\theta) =\n  \\begin{cases}\n    p     & \\text{se $X = 1$ (successo)}, \\\\\n    1 - p & \\text{se $X = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq p \\leq 1\\). Il parametro \\(p\\) rappresenta la probabilità del “successo” (\\(X = 1\\)), mentre \\(1 - p\\) è la probabilità dell’“insuccesso” (\\(X = 0\\)).\n\nLa distribuzione di Bernoulli descrive quindi un contesto in cui la probabilità di osservare l’esito 1 è \\(p\\) e quella di osservare l’esito 0 è \\(1 - p\\). Viene utilizzata per modellare situazioni binarie, come una risposta “sì” o “no”, oppure un “successo” o “insuccesso”.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{align}\n\\mathbb{E}(X) &= 0 \\cdot P(X=0) + 1 \\cdot P(X=1) = p, \\\\\n\\mathbb{V}(X) &= (0 - p)^2 \\cdot P(X=0) + (1 - p)^2 \\cdot P(X=1) = p(1-p).\n\\end{align}\n\\tag{31.1}\\]\nEsplicitando ulteriormente la formula della varianza con \\(P(YX=0) = 1 - p\\) e \\(P(X=1) = p\\), abbiamo:\n\\[ \\mathbb{V}(X) = (0 - p)^2 \\cdot (1 - p) + (1 - p)^2 \\cdot p \\]\nCalcoliamo ora le singole parti dell’espressione: 1. \\((0 - p)^2 = p^2\\) 2. \\((1 - p)^2 = 1 - 2p + p^2\\)\nSostituendo queste espressioni nell’equazione della varianza, otteniamo:\n\\[ \\mathbb{V}(X) = p^2 \\cdot (1 - p) + (1 - 2p + p^2) \\cdot p \\]\n\\[ \\mathbb{V}(X) = p^2 - p^3 + p - 2p^2 + p^3 \\]\nSemplificando:\n\\[ \\mathbb{V}(X) = p - p^2 \\]\n\\[ \\mathbb{V}(X) = p(1-p). \\]\nIn sintesi, la varianza di una variabile aleatoria binaria \\(X\\), distribuita secondo Bernoulli con parametro \\(p\\), è data da \\(p(1-p)\\). Tale risultato mostra come la varianza massima si ottenga per \\(p = 0.5\\), condizione che corrisponde alla massima incertezza intrinseca nel processo, ossia quando la probabilità di successo eguaglia quella di insuccesso.\n\n# Valori di p tra 0 e 1\np &lt;- seq(0, 1, length.out = 100)\n\n# Varianza della distribuzione di Bernoulli è p * (1 - p)\nvariance &lt;- p * (1 - p)\n\n# Grafico\nplot(p, variance, type = \"l\", col = \"blue\", lwd = 2, \n     xlab = expression(p), ylab = \"Varianza\", \n     main = \"Varianza di una Variabile Bernoulliana in funzione di p\")\n\n\n\n\n\n\n\n\nPer indicare che la variabile casuale \\(X\\) segue una distribuzione Bernoulliana di parametro \\(p\\) Utilizziamo la notazione \\(X \\sim \\mathcal{Bern}(p)\\), o in maniera equivalente \\(\\mathcal{Bern}(X \\mid p)\\).\nAd esempio, nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilità di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilità assegna una probabilità di \\(\\frac{1}{2}\\) sia per \\(X = 0\\) che per \\(X = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(X = 0\\) e \\(1\\) per \\(X = 1\\).\nGeneriamo dei valori casuali dalla distribuzione di Bernoulli. Iniziamo con un singolo valore:\n\n# Probabilità di successo\np &lt;- 0.5\n\n# Genera un singolo valore\nbernoulli_sample &lt;- rbinom(n = 1, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt; [1] 1\n\n# Genera un campione di 10 valori\nbernoulli_sample &lt;- rbinom(n = 10, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt;  [1] 1 0 1 1 1 1 0 1 1 0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-binomiale",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-binomiale",
    "title": "31  Distribuzioni di v.c. discrete",
    "section": "31.3 Distribuzione Binomiale",
    "text": "31.3 Distribuzione Binomiale\nLa distribuzione binomiale è una distribuzione di probabilità discreta che modella il numero di successi \\(y\\) in un numero fissato \\(n\\) di prove di Bernoulli indipendenti e identiche, dove ciascuna prova ha solo due esiti possibili: “successo” (rappresentato da “1”) con probabilità \\(p\\) o “insuccesso” (rappresentato da “0”) con probabilità \\(1 - p\\). La notazione utilizzata è la seguente:\n\\[\nY \\sim \\mathcal{Binom}(n, p).\n\\]\n\nDefinizione 31.2 La distribuzione binomiale descrive la probabilità di osservare esattamente \\(y\\) successi in \\(n\\) prove di Bernoulli indipendenti:\n\\[\nP(Y = y) = \\binom{n}{y} p^{y} (1 - p)^{n - y} = \\frac{n!}{y!(n - y)!} p^{y} (1 - p)^{n - y},\n\\tag{31.2}\\]\ndove \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di modi possibili per ottenere \\(y\\) successi in \\(n\\) prove, e \\(p\\) è la probabilità di successo in ciascuna prova.\n\nLa distribuzione binomiale si presta bene a esempi classici come il lancio ripetuto di una moneta o l’estrazione di biglie da un’urna. Ad esempio, nel caso del lancio di una moneta, questa distribuzione descrive la probabilità di ottenere un determinato numero di “teste” in un certo numero di lanci, con ogni lancio che segue una distribuzione di Bernoulli con probabilità di successo \\(p\\).\nUna caratteristica interessante della distribuzione binomiale è la sua proprietà di riproducibilità: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono entrambe distribuzioni binomiali con lo stesso parametro \\(p\\), ma con un diverso numero di prove (\\(n_1\\) e \\(n_2\\)), la loro somma, \\(y = y_1 + y_2\\), sarà ancora distribuita binomialmente, con parametri \\(n_1 + n_2\\) e \\(p\\).\n\n31.3.1 Calcolo delle Probabilità\nPer chiarire il calcolo delle probabilità nella distribuzione binomiale, consideriamo una serie di prove di Bernoulli. Supponiamo di avere \\(n\\) prove, con \\(y\\) successi. La configurazione di questi risultati può essere rappresentata come:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ successi} \\overbrace{II\\dots I}^\\text{$n - y$ insuccessi}\n\\]\nLa probabilità di ottenere esattamente \\(y\\) successi in una sequenza specifica di prove è pari a:\n\\[\np^y \\cdot (1 - p)^{n - y},\n\\]\ndove \\(p^y\\) è la probabilità di ottenere \\(y\\) successi, e \\((1 - p)^{n - y}\\) è la probabilità di ottenere \\(n - y\\) insuccessi.\nTuttavia, siamo interessati alla probabilità complessiva di ottenere esattamente \\(y\\) successi in qualsiasi ordine. Il numero di modi in cui ciò può avvenire è dato dal coefficiente binomiale \\(\\binom{n}{y}\\), che rappresenta tutte le possibili disposizioni dei successi e degli insuccessi nelle \\(n\\) prove.\nQuindi, moltiplicando la probabilità di una singola sequenza per il numero di sequenze possibili, otteniamo la probabilità di osservare esattamente \\(y\\) successi:\n\\[\nP(Y = y) = \\binom{n}{y} p^y (1 - p)^{n - y}.\n\\]\nQuesto risultato corrisponde alla formula della distribuzione binomiale.\n\n\n31.3.2 Applicazioni Pratiche della Distribuzione Binomiale\nConsideriamo un esempio pratico per illustrare l’applicazione della distribuzione binomiale. Supponiamo di osservare 2 successi in 4 prove Bernoulliane, dove la probabilità di successo in ogni prova è \\(p = 0.2\\). La probabilità di ottenere questo risultato specifico è calcolata utilizzando l’eq. {eq}eq-binom-distr:\n\\[\nP(Y=2) = \\frac{4!}{2!(4-2)!} \\cdot 0.2^{2} \\cdot (1-0.2)^{4-2} = 0.1536.\n\\]\nQuesto calcolo può essere replicato in Python. Utilizzando il modulo math, possiamo calcolare direttamente:\n\n# Parametri\nn &lt;- 4\np &lt;- 0.2\ny &lt;- 2\n\n# Probabilità di ottenere esattamente y successi\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.1536\n\nIn alternativa, possiamo sfruttare la libreria SciPy per eseguire calcoli analoghi. SciPy offre una vasta gamma di funzioni per la gestione delle distribuzioni statistiche, tra cui la distribuzione binomiale.\n\n# Probabilità di ottenere esattamente y successi\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.1536\n\nUtilizzando dbinom(y, n, p), possiamo trovare le probabilità per ogni possibile valore \\(y\\) in una distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\):\n\n# Usando la funzione dbinom\nprob &lt;- dbinom(x = y, size = n, prob = p)\nprint(prob)\n#&gt; [1] 0.1536\n\nVisualizziamo la distribuzione di massa di probabilità:\n\ny &lt;- 0:n  # Numero di successi\nprobabilities &lt;- dbinom(y, size = n, prob = p)  # Probabilità associate\n\n# Preparare i dati in un data frame\ndf &lt;- data.frame(Successi = y, Probabilità = probabilities)\n\ndf |&gt; \n  ggplot(aes(x = Successi, y = Probabilità)) +\n    geom_segment(aes(xend = Successi, yend = 0), lwd = 1.2, color = \"blue\") +\n    geom_point(size = 3, color = \"blue\") +\n    labs(\n      x = \"Numero di Successi y\",\n      y = \"Probabilità\",\n      title = paste(\"Distribuzione Binomiale: n =\", n, \", p =\", p)\n  )\n\n\n\n\n\n\n\n\nUn campione casuale si ottiene con rbinom():\n\nset.seed(42)\nsamples &lt;- rbinom(n = 30, size = 5, prob = 0.5)\nprint(samples)\n#&gt;  [1] 4 4 2 4 3 3 3 1 3 3 2 3 4 2 2 4 5 1 2 3 4 1 5 4 1 3 2 4 2 4\n\nPer esplorare ulteriormente, consideriamo la distribuzione di probabilità di diverse distribuzioni binomiali per due valori di \\(n\\) e \\(\\theta\\). La seguente visualizzazione mostra come cambia la distribuzione al variare di \\(\\theta\\):\n\n# Parametri\nn &lt;- 20\np_values &lt;- seq(0.3, 0.9, by = 0.3) # Valori di probabilità\ny &lt;- 0:25 # Numero di successi\n\n# Creazione di un data frame per tutte le distribuzioni\ndf &lt;- data.frame()\n\nfor (p in p_values) {\n  binom_dist &lt;- dbinom(y, size = n, prob = p)\n  df &lt;- rbind(df, data.frame(y = y, Prob = binom_dist, p = factor(p)))\n}\n\n# Grafico con ggplot2\ndf |&gt; \n  ggplot(aes(x = y, y = Prob, color = p)) +\n    geom_point() +\n    geom_line() +\n    labs(\n      x = \"Numero di successi y\", \n      y = \"Probabilità\",\n      title = \"Distribuzione binomiale al variare di p\",\n      color = expression(theta)\n  )\n\n\n\n\n\n\n\n\nConsideriamo un altro esempio. Lanciando \\(5\\) volte una moneta onesta, qual è la probabilità che esca testa almeno due volte? Troviamo la soluzione usando stats.binom.pmf().\n\n# Calcolo della somma delle probabilità\nresult &lt;- dbinom(2, size = 5, prob = 0.5) +\n          dbinom(3, size = 5, prob = 0.5) +\n          dbinom(4, size = 5, prob = 0.5) +\n          dbinom(5, size = 5, prob = 0.5)\n\nprint(result)\n#&gt; [1] 0.8125\n\nOppure, in modo più compatto:\n\n# Valori di interesse\nresult &lt;- sum(dbinom(2:5, size = 5, prob = 0.5))\nprint(result)\n#&gt; [1] 0.8125\n\nRappresentiamo graficamente la funzione di ripartizione per una Binomiale di ordine \\(n\\) = 5 e \\(\\theta\\) = 0.5.\n\n# Parametri\nn &lt;- 5\np &lt;- 0.5\ny &lt;- 0:n\n\n# Calcolo della funzione di ripartizione cumulativa\ncdf_values &lt;- pbinom(y, size = n, prob = p)\n\n# Creazione del data frame per ggplot2\ndf &lt;- data.frame(y = y, cdf = cdf_values)\n\n# Grafico\ndf |&gt; \n  ggplot(aes(x = y, y = cdf)) +\n    geom_line() +\n    geom_point() +\n    geom_hline(yintercept = 1, color = \"black\", alpha = 0.7, linetype = \"dashed\") +\n    labs(\n      title = paste(\"Funzione di ripartizione binomiale: n =\", n, \", p =\", p),\n      x = \"y\",\n      y = \"Probabilità\"\n    )\n\n\n\n\n\n\n\n\nUn’altra funzione utile è quella che permette di trovare il numero di successi associato a una data probabilità cumulativa nella coda sinistra di una distribuzione binomiale. Questo si ottiene utilizzando la funzione qbinom, che rappresenta l’inversa della funzione di distribuzione cumulativa (CDF).\nAd esempio, consideriamo una distribuzione binomiale con \\(n = 5\\) prove e probabilità di successo \\(p = 0.5\\). Supponiamo di voler calcolare il numero minimo di successi per cui la probabilità cumulativa è almeno \\(1 - 0.8125 = 0.1875\\). Possiamo farlo nel seguente modo:\n\n# Probabilità target\ntarget_probability &lt;- 1 - 0.8125\n\n# Numero di successi corrispondente alla probabilità target\nresult &lt;- qbinom(target_probability, size = 5, prob = 0.5)\n\nprint(result)\n#&gt; [1] 1\n\nIn questo esempio, il valore restituito è \\(1\\), che indica che almeno 1 successo soddisfa la condizione di una probabilità cumulativa di \\(0.1875\\).\n\n\n31.3.3 Altro esempio\nConsideriamo ora una distribuzione binomiale con \\(n = 10\\) prove e probabilità di successo \\(p = 0.2\\). Per calcolare la probabilità cumulativa \\(P(Y \\leq 4)\\), ovvero la probabilità di ottenere al massimo 4 successi su 10 tentativi, possiamo utilizzare la funzione pbinom:\n\n# Calcolo della probabilità cumulativa\ntarget_probability &lt;- pbinom(4, size = 10, prob = 0.2)\nprint(target_probability)\n#&gt; [1] 0.9672065\n\nIl risultato rappresenta la probabilità cumulativa associata a 4 o meno successi.\nSe invece vogliamo determinare il numero di successi corrispondente a questa probabilità cumulativa, possiamo utilizzare la funzione inversa qbinom:\n\n# Calcolo del numero di successi associato alla probabilità cumulativa\nresult &lt;- qbinom(target_probability, size = 10, prob = 0.2)\nprint(result)\n#&gt; [1] 4\n\nIn questo caso, il valore restituito rappresenta il numero massimo di successi \\(Y\\) per cui la probabilità cumulativa è uguale o inferiore a \\(target\\_probability\\). Questo è particolarmente utile per interpretare i risultati di una distribuzione binomiale in termini di successi associati a determinate probabilità cumulative.\n\n\n31.3.4 Valore atteso e deviazione standard\nLa media (numero atteso di successi in \\(n\\) prove) e la deviazione standard di una distribuzione binomiale si calcolano nel seguente modo:\n\\[\n\\begin{align}\n\\mu    &= np,  \\notag \\\\\n\\sigma &= \\sqrt{np(1-p)}.\n\\end{align}\n\\tag{31.3}\\]\nDimostrazione. Dato che \\(Y\\) rappresenta la somma di \\(n\\) prove di Bernoulli indipendenti \\(Y_i\\), possiamo scrivere:\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= \\mathbb{E}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{E}(Y_i) = np, \\\\\n\\mathbb{V}(Y) &= \\mathbb{V} \\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{V}(Y_i) = np(1-p).\n\\end{align}\n\\]\nPertanto, la deviazione standard è data da \\(\\sigma = \\sqrt{np(1-p)}\\).\nPer esempio, prendiamo in considerazione il caso di un esperimento in cui vengono lanciate quattro monete, ciascuna con una probabilità di ottenere testa (successo) pari a \\(p = 0.2\\). Calcoliamo il valore atteso e la varianza per questo esperimento.\nIl valore atteso, \\(\\mu\\), rappresenta il numero medio di teste che ci aspettiamo di ottenere in ciascun lancio. Per la distribuzione binomiale, questo è dato da \\(\\mu = n p\\), dove \\(n\\) è il numero di prove (lanci di monete). Nel nostro caso, con \\(n = 4\\) e \\(p = 0.2\\), abbiamo:\n\\[\n\\mu = n p = 4 \\times 0.2 = 0.8.\n\\]\nQuesto significa che, in media, ci aspettiamo di ottenere circa 0.8 teste per ogni serie di quattro lanci.\nPer quanto riguarda la varianza, che misura quanto i risultati individuali tendono a differire dalla media, nella distribuzione binomiale è calcolata come \\(n p (1-p)\\). Pertanto, per il nostro esperimento:\n\\[\n\\text{Varianza} = n p (1-p) = 4 \\times 0.2 \\times (1 - 0.2) = 0.64.\n\\]\nLa varianza di 0.64 suggerisce una certa dispersione intorno al valore medio di 0.8 teste.\nPer confermare queste aspettative teoriche, possiamo eseguire una simulazione. Creiamo una serie di esperimenti simulati in cui lanciamo quattro monete per un gran numero di volte, registrando il numero di teste ottenute in ogni serie. Calcoliamo poi la media e la varianza dei risultati ottenuti per vedere quanto si avvicinano ai valori teorici calcolati.\n\nset.seed(42)\n\n# Genera un campione di 1.000.000 di valori dalla distribuzione binomiale\nx &lt;- rbinom(n = 1000000, size = 4, prob = 0.2)\n\n\nmean(x)\n#&gt; [1] 0.800212\n\n\nvar(x)\n#&gt; [1] 0.6389574\n\n\n\n31.3.5 Funzioni R associate alle distribuzioni di probabilità\nLa seguente tabella riassume le funzioni di R utilizzate per manipolare le distribuzioni di probabilità, illustrando i casi della distribuzione Binomiale e della Normale.\n\n\n\n\n\n\n\n\nTipo\nEsempio: Binomiale (\\(y \\mid n, p\\))\nEsempio: Normale (\\(y \\mid \\mu, \\sigma\\))\n\n\n\n\nFunzione di verosimiglianza\ndbinom(y, size = n, prob = p)\ndnorm(y, mean = μ, sd = σ)\n\n\nProb \\(Y = y\\)\ndbinom(y, size = n, prob = p)\nNon definita (variabili continue hanno pdf, non pmf)\n\n\nProb \\(Y \\geq y, Y \\leq y, y_1 &lt; Y &lt; y_2\\)\npbinom(y, size = n, prob = p) o 1 - pbinom(y - 1, ...)\npnorm(y, mean = μ, sd = σ) o 1 - pnorm(y, ...)\n\n\nInversa della CDF\nqbinom(q, size = n, prob = p)\nqnorm(q, mean = μ, sd = σ)\n\n\nGenerazione di dati simulati\nrbinom(n, size = trials, prob = p)\nrnorm(n, mean = μ, sd = σ)\n\n\n\nIn seguito, useremo altre distribuzioni come Uniforme, Beta, ecc., ognuna delle quali ha un proprio insieme di funzioni disponibili in R. La sintassi segue uno schema generale comune:\n\nd*: Calcola la funzione di densità di probabilità (per distribuzioni continue) o di massa (per distribuzioni discrete). Esempi: dbinom, dnorm.\np*: Calcola la funzione di ripartizione cumulativa (CDF). Esempi: pbinom, pnorm.\nq*: Calcola l’inversa della funzione di ripartizione cumulativa (quantile function). Esempi: qbinom, qnorm.\nr*: Genera campioni casuali secondo una determinata distribuzione. Esempi: rbinom, rnorm.\n\n\nEsercizio 31.1  \n\nCalcolare la probabilità di esattamente \\(y = 3\\) successi su \\(n = 5\\) prove con \\(p = 0.5\\):\n\n\ndbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.3125\n\n\nCalcolare la probabilità cumulativa \\(P(Y \\leq 3)\\):\n\n\npbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.8125\n\n\nCalcolare il valore minimo \\(y\\) tale che \\(P(Y \\leq y) \\geq 0.9\\):\n\n\nqbinom(0.9, size = 5, prob = 0.5)\n#&gt; [1] 4\n\n\nGenerare un campione di 100 numeri casuali da una distribuzione binomiale:\n\n\nrbinom(100, size = 5, prob = 0.5)\n#&gt;   [1] 2 2 4 1 3 2 3 2 2 2 3 3 3 3 1 4 1 1 0 2 2 2 4 1 2 3 3 1 5 2 3 3 0 3 2 3\n#&gt;  [37] 4 2 3 3 3 3 1 5 3 3 2 3 1 2 1 3 3 2 2 4 1 4 2 3 1 4 2 2 3 4 1 1 4 2 3 2\n#&gt;  [73] 3 3 3 1 4 4 3 3 4 3 3 3 2 2 3 3 2 4 4 3 2 2 0 3 1 3 1 2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "title": "31  Distribuzioni di v.c. discrete",
    "section": "31.4 Distribuzione Discreta Uniforme",
    "text": "31.4 Distribuzione Discreta Uniforme\nLa distribuzione discreta uniforme è un tipo particolare di distribuzione di probabilità, dove ogni risultato in un insieme finito e discreto \\(S\\) ha la stessa probabilità \\(p\\) di verificarsi. Questa distribuzione è caratterizzata dalla sua semplicità e dalla sua proprietà fondamentale di equiprobabilità.\nConsideriamo un esempio pratico con una variabile casuale discreta \\(X\\), che può assumere valori nell’insieme \\(\\{1, 2, \\dots, N\\}\\). Un’istanza classica di questa distribuzione si verifica quando si sceglie casualmente un numero intero tra 1 e \\(N\\), inclusi. Se \\(X\\) rappresenta il numero selezionato, allora la somma delle probabilità di tutti i possibili valori di \\(X\\) deve totalizzare 1, come indicato dalla formula di normalizzazione:\n\\[\n\\sum_{i=1}^N P(X_i) = Np = 1.\n\\]\nDi conseguenza, la probabilità che \\(X\\) assuma un valore specifico \\(x\\) è uniformemente distribuita:\n\\[\nP(X = x) = \\frac{1}{N},\n\\]\nindicando che ogni evento ha la stessa probabilità di verificarsi.\nIl valore atteso, o la media, di \\(X\\) ci dà un’idea del risultato medio atteso e si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x=1}^N x \\cdot \\frac{1}{N} = \\frac{1}{N} \\cdot \\sum_{x=1}^N x.\n\\]\nA questo punto, dobbiamo calcolare la somma \\(\\sum_{x=1}^{N} x\\), che è la somma dei primi \\(N\\) numeri naturali. Questa somma è data dalla formula:\n\\[\n\\sum_{x=1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nSostituendo questa formula nel nostro calcolo del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nQuindi, abbiamo dimostrato che il valore atteso $ (X) $ per una variabile casuale \\(X\\) che assume valori interi uniformemente distribuiti da 1 a \\(N\\) è \\(\\frac{N + 1}{2}\\).\nPer determinare quanto i valori di \\(X\\) si disperdono attorno al valore medio, calcoliamo la varianza. Il primo passo è calcolare \\(\\mathbb{E}(X^2)\\), il valore atteso del quadrato di \\(X\\). Per una variabile casuale discreta uniforme, questo si ottiene moltiplicando ogni valore al quadrato per la sua probabilità (che è \\(1/N\\) per tutti i valori) e sommando i risultati:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\sum_{x=1}^N x^2\n\\]\nUsando l’identità per la somma dei quadrati dei primi \\(N\\) numeri naturali:\n\\[\n1^2 + 2^2 + \\dots + N^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\npossiamo sostituirla per trovare \\(\\mathbb{E}(X^2)\\):\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}\n\\]\nLa varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), si calcola usando la formula:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2\n\\]\nAbbiamo già stabilito che \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\) e \\(\\mathbb{E}(X^2) = \\frac{(N + 1)(2N + 1)}{6}\\). Sostituendo questi valori nella formula della varianza, otteniamo:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2\n\\]\nPer semplicare l’espressione della varianza, dobbiamo sottrarre il quadrato di \\(\\mathbb{E}(X)\\) da \\(\\mathbb{E}(X^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4} \\\\\n&= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1)(2(2N + 1) - 3(N + 1))}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}\n\\end{align*}\n\\]\nQuindi, la varianza \\(\\mathbb{V}(X)\\) di una variabile casuale uniforme discreta \\(X\\) che assume valori da 1 a \\(N\\) è \\(\\frac{(N + 1)(N - 1)}{12}\\), il che mostra come la dispersione dei valori attorno al loro valore medio dipenda dalla grandezza di \\(N\\). Questa formula fornisce la varianza di una variabile casuale in una distribuzione discreta uniforme, offrendo una misura quantitativa della dispersione dei valori attorno al loro valore medio.\n\n31.4.1 Distribuzione di Poisson\nLa distribuzione di Poisson è utilizzata per modellare il numero di eventi che si verificano in un determinato intervallo di tempo o spazio, con eventi indipendenti e un tasso costante di occorrenza.\nLa funzione di massa di probabilità (PMF) è data da:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad y = 0, 1, 2, \\ldots\n\\]\ndove \\(\\lambda\\) rappresenta il tasso medio di eventi e \\(y\\) è il numero di eventi.\n\n31.4.1.1 Proprietà principali\n\nMedia: \\(\\mathbb{E}[Y] = \\lambda\\)\nVarianza: \\(\\text{Var}(Y) = \\lambda\\)\n\nDi seguito, presentiamo esempi di calcolo e simulazione con R.\n\n\n31.4.1.2 Grafico della distribuzione di Poisson con \\(\\lambda = 2\\)\n\n# Parametro lambda\nlambda &lt;- 2\n\n# Valori di y (numero di eventi)\ny &lt;- 0:10\n\n# Calcolo delle probabilità\nprobabilities &lt;- dpois(y, lambda = lambda)\n\n# Grafico della funzione di massa di probabilità\nbarplot(probabilities, names.arg = y, col = \"blue\", \n        xlab = \"Numero di eventi (k)\", ylab = \"Probabilità\", \n        main = \"Distribuzione di Massa di Probabilità di Poisson\")\n\n\n\n\n\n\n\n\n\n\n31.4.1.3 Calcolo della probabilità per un numero specifico di eventi\nPer calcolare la probabilità di osservare esattamente 3 eventi con \\(\\lambda = 2\\):\n\nprob &lt;- dpois(3, lambda = 2)\nprint(prob)\n#&gt; [1] 0.180447\n\n\n\n31.4.1.4 Calcolo della probabilità cumulativa \\(P(Y \\leq 3)\\)\nPer calcolare \\(P(Y \\leq 3)\\), la probabilità cumulativa:\n\ncum_prob &lt;- ppois(3, lambda = 2)\nprint(cum_prob)\n#&gt; [1] 0.8571235\n\n\n\n31.4.1.5 Trovare il quantile corrispondente a una probabilità data\nPer trovare il numero massimo di eventi per cui la probabilità cumulativa è al massimo \\(0.8125\\):\n\nquantile &lt;- qpois(0.8125, lambda = 2)\nprint(quantile)\n#&gt; [1] 3\n\n\n\n31.4.1.6 Generazione di numeri casuali\nPer generare un campione di 1.000.000 di osservazioni da una distribuzione di Poisson con \\(\\lambda = 2\\):\n\nset.seed(42)\nsample &lt;- rpois(1000000, lambda = 2)\n\n# Calcolo di media e varianza del campione\nmean_sample &lt;- mean(sample)\nvar_sample &lt;- var(sample)\n\nprint(mean_sample)\n#&gt; [1] 1.999915\nprint(var_sample)\n#&gt; [1] 1.996043\n\n\nEsercizio 31.2 Consideriamo un ospedale con una media storica di 4,5 nascite al giorno. Qual è la probabilità che nascano esattamente 6 bambini in un giorno?\n\n# Calcolo della probabilità\nlambda &lt;- 4.5\nprob &lt;- dpois(6, lambda = lambda)\nprint(prob)\n#&gt; [1] 0.1281201\n\nSimuliamo 365 giorni di nascite e confrontiamo la proporzione di giorni con esattamente 6 nascite:\n\nset.seed(42)\nn_days &lt;- 365\nsimulated_births &lt;- rpois(n_days, lambda = lambda)\n\n# Proporzione di giorni con esattamente 6 nascite\nproportion_six_births &lt;- mean(simulated_births == 6)\nprint(proportion_six_births)\n#&gt; [1] 0.139726\n\nIstogramma delle nascite simulate:\n\nhist(simulated_births, breaks = seq(-0.5, max(simulated_births) + 0.5, by = 1), \n     col = \"blue\", xlab = \"Numero di nascite per giorno\", \n     ylab = \"Frequenza\", main = \"365 nascite simulate (Poisson)\")\n\n\n\n\n\n\n\n\nProbabilità di più di 6 nascite in un giorno. Per calcolare la probabilità teorica \\(P(Y &gt; 6)\\):\n\nprob_more_than_six &lt;- 1 - ppois(6, lambda = lambda)\nprint(prob_more_than_six)\n#&gt; [1] 0.1689494\n\nProporzione simulata di più di 6 nascite:\n\nproportion_more_than_six &lt;- mean(simulated_births &gt; 6)\nprint(proportion_more_than_six)\n#&gt; [1] 0.169863",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "31  Distribuzioni di v.c. discrete",
    "section": "31.5 Distribuzione Beta-Binomiale",
    "text": "31.5 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilità nella probabilità di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilità per la distribuzione beta-binomiale è data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{31.4}\\]\ndove:\n\n\\(y\\) indica il numero di successi osservati.\n\\(N\\) rappresenta il numero totale di tentativi.\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilità nella probabilità di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, è definita tramite l’uso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL’importanza della distribuzione beta-binomiale deriva dalla sua capacità di modellare situazioni in cui la probabilità di successo non è fissa, ma segue una distribuzione di probabilità, specificatamente una distribuzione beta. Ciò la rende particolarmente adatta per applicazioni in cui le probabilità di successo cambiano in maniera incerta da un tentativo all’altro, come può avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilità di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione più realistica e flessibile per dati empirici che presentano variabilità nelle probabilità di successo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-categorica",
    "href": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-categorica",
    "title": "31  Distribuzioni di v.c. discrete",
    "section": "31.6 La Distribuzione Categorica",
    "text": "31.6 La Distribuzione Categorica\nLa distribuzione categorica è una distribuzione di probabilità discreta utilizzata per modellare eventi con più esiti distinti e non ordinati. È una generalizzazione della distribuzione Bernoulliana, che si limita a due esiti (successo e fallimento), ed è utile in situazioni in cui un evento può produrre uno tra molti esiti, ciascuno con una probabilità associata.\n\n31.6.1 Definizione e Funzione di Massa di Probabilità\nLa distribuzione categorica può essere caratterizzata dalla sua funzione di massa di probabilità (PMF):\n\\[\np(X = x) = \\mathcal{Categorical}(X \\mid p) = \\prod_{k=1}^K p_k^{I_{x=k}},\n\\]\ndove:\n\n\\(K\\) è il numero di esiti possibili,\n\\(p_k\\) è la probabilità associata al \\(k\\)-esimo esito,\n\\(I_{x=k}\\) è una funzione indicatrice che vale 1 se \\(x = k\\) e 0 altrimenti.\n\nLe probabilità \\(p_k\\) formano un vettore:\n\\[\np =\n\\begin{pmatrix}\np_1\\\\\np_2\\\\\n\\dots \\\\\np_K\n\\end{pmatrix},\n\\]\nche soddisfa la condizione:\n\\[\n\\sum_{k=1}^K p_k = 1.\n\\]\nIn altre parole, la somma delle probabilità di tutti i possibili esiti è pari a 1, come richiesto da qualsiasi distribuzione di probabilità.\n\n\n31.6.2 Proprietà Principali\n\nEsiti Multipli: La distribuzione categorica è adatta per modellare eventi con più di due esiti distinti. Un esempio classico è il lancio di un dado a sei facce, dove ciascun esito ha una probabilità di \\(\\frac{1}{6}\\) nel caso di un dado equo.\nGeneralizzazione della Distribuzione Bernoulliana: La distribuzione categorica è una generalizzazione della distribuzione Bernoulliana. In particolare, la distribuzione Bernoulliana rappresenta un caso speciale della distribuzione categorica con due sole categorie (\\(K = 2\\)), come il risultato di un lancio di una moneta (testa o croce).\nProbabilità in Forma di Simplex: Le probabilità degli esiti nella distribuzione categorica sono rappresentate da un vettore simplex. Un simplex è un vettore di probabilità non negative che sommano a 1, rispettando la condizione fondamentale delle distribuzioni di probabilità.\n\n\n\n31.6.3 Utilizzo della Distribuzione Categorica in Stan\nIn Stan, la distribuzione categorica è impiegata per modellare la probabilità di un singolo esito tra diversi possibili risultati. Questo è particolarmente utile in contesti come le catene di Markov, dove ogni stato può evolvere verso uno tra molti altri stati con una certa probabilità.\nAd esempio, supponiamo di avere una matrice di transizione \\(P\\) che descrive le probabilità di passaggio tra stati in una catena di Markov. Ogni riga della matrice \\(P\\) rappresenta una distribuzione categorica, in cui le voci corrispondono alle probabilità di transizione dallo stato corrente agli stati successivi. La distribuzione categorical può essere utilizzata per modellare la probabilità di osservare una specifica transizione.\nConsideriamo un esempio pratico: se uno studente si trova nello stato \\(A\\) al tempo \\(t\\), e le probabilità di transizione agli stati \\(A\\), \\(B\\) e \\(C\\) sono rispettivamente \\(0.7\\), \\(0.2\\) e \\(0.1\\), possiamo modellare la probabilità che l’evento successivo sia una transizione verso uno di questi stati usando la distribuzione categorica:\n\\[\nX \\sim \\text{categorical}(0.7, 0.2, 0.1)\n\\]\nQui, la variabile aleatoria \\(X\\) segue una distribuzione categorical con le probabilità assegnate ai tre possibili esiti (stati \\(A\\), \\(B\\), e \\(C\\)). Questo consente di simulare il prossimo stato in base alle probabilità specificate.\n\n31.6.3.1 Applicazione nelle Catene di Markov\nLa distribuzione categorical è particolarmente efficace nei modelli di catene di Markov, dove descrive le transizioni tra stati in un sistema dinamico. Ogni transizione tra stati è trattata come un evento discreto con più esiti possibili, ciascuno con la propria probabilità. Questo approccio è utile per modellare sistemi con molteplici stati e transizioni complesse, garantendo flessibilità e precisione nella simulazione delle dinamiche del sistema.\nIn sintesi, la distribuzione categorica in Stan permette di modellare eventi con molteplici esiti in modo semplice ed efficace, rendendola uno strumento prezioso per descrivere fenomeni dinamici, come le catene di Markov o qualsiasi altro processo con transizioni probabilistiche tra stati.\nDi seguito, esaminiamo come simulare una distribuzione categorica utilizzando numpy e come creare un istogramma per visualizzare la distribuzione di massa:\n\n# Definire le probabilità della distribuzione categorica\nprobabilities &lt;- c(0.6, 0.3, 0.1)  # Le probabilità per ciascun esito\n\n# Definire le categorie\ncategories &lt;- c(\"A\", \"B\", \"C\")\n\n# Numero di campioni da generare\nn_samples &lt;- 1000\n\n# Simulare la distribuzione categorica\nset.seed(123)  # Per riproducibilità\nsamples &lt;- sample(categories, size = n_samples, replace = TRUE, prob = probabilities)\n\nggplot(data.frame(samples = samples), aes(x = samples)) +\n  geom_bar(fill = \"skyblue\", color = \"black\") +\n  scale_x_discrete(labels = categories) +\n  labs(\n    x = \"Categorie\", \n    y = \"Frequenza\", \n    title = \"Istogramma della Distribuzione Categorica Simulata\"\n) \n\n\n\n\n\n\n\n\nConcludiamo chiarendo la relazione tra la distribuzione categorica e quella multinomiale.\nLa distribuzione categorica descrive l’esito di una singola prova con \\(K\\) categorie, ciascuna con una probabilità associata. È una generalizzazione della distribuzione Bernoulliana, che prevede solo due esiti (successo o fallimento).\n\nEsercizio 31.3 Lanciare un dado a sei facce una volta. Ciascuna faccia ha una probabilità di \\(\\frac{1}{6}\\).\nLa distribuzione multinomiale estende la distribuzione binomiale a più categorie e descrive il numero di esiti su un insieme di prove indipendenti che seguono una distribuzione categorica.\n\n\nEsercizio 31.4 Lanciare un dado dieci volte e contare quante volte appare ciascuna faccia.\nLa distribuzione categorica è un caso particolare della multinomiale quando si effettua una sola prova (\\(n = 1\\)). Nella distribuzione categorica otteniamo un singolo esito, mentre nella multinomiale otteniamo un conteggio di esiti su più prove.\n\n\n\n\n31.6.4 Implementazioni in R\n\nsample: Permette di campionare da una distribuzione categorica, restituendo uno o più esiti in base alle probabilità specificate. Ad esempio:\nsample(categories, size = n, replace = TRUE, prob = probabilities)\nDove categories è un vettore di esiti, n è il numero di campioni, e probabilities definisce le probabilità associate a ciascun esito.\nrmultinom: Funzione per la distribuzione multinomiale. Può essere utilizzata per simulare una distribuzione categorica impostando il numero di prove ( n = 1 ). Ad esempio:\nrmultinom(1, size = 1, prob = probabilities)\nQui, probabilities specifica le probabilità per ciascun esito. Restituisce il numero di successi per ciascuna categoria in una matrice.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-geometrica",
    "href": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-geometrica",
    "title": "31  Distribuzioni di v.c. discrete",
    "section": "31.7 La Distribuzione Geometrica",
    "text": "31.7 La Distribuzione Geometrica\nLa distribuzione geometrica è una distribuzione discreta che modella il numero di tentativi necessari per ottenere il primo successo in una sequenza di prove Bernoulliane indipendenti. Ogni prova ha due possibili esiti: successo (con probabilità \\(p\\)) o fallimento (con probabilità \\(1 - p\\)).\nIn termini pratici, la distribuzione geometrica può essere utilizzata per rispondere alla domanda: “Quante prove falliscono prima di ottenere il primo successo?”.\n\n31.7.1 Funzione di Massa di Probabilità\nLa funzione di massa di probabilità (PMF) della distribuzione geometrica è definita come:\n\\[\nP(X = k) = (1 - p)^{k-1} \\cdot p\n\\]\ndove:\n\n\\(X\\) è il numero di tentativi fino al primo successo (incluso il tentativo in cui si ottiene il successo).\n\\(p\\) è la probabilità di successo in ogni prova.\n\\(k\\) è il numero di prove necessarie per ottenere il primo successo (un numero intero positivo, \\(k \\geq 1\\)).\n\n\n\n31.7.2 Proprietà della Distribuzione Geometrica\n\nValore Atteso (Media): La media del numero di prove fino al primo successo è data da:\n\n\\[\n\\mathbb{E}[X] = \\frac{1}{p}.\n\\]\nQuesto significa che, in media, ci si aspetta di avere \\(\\frac{1}{p}\\) prove prima di ottenere un successo.\n\nVarianza: La varianza della distribuzione geometrica è:\n\n\\[\n\\text{Var}(X) = \\frac{1 - p}{p^2}.\n\\]\n\nMemoria Assente: La distribuzione geometrica ha una proprietà interessante chiamata “assenza di memoria”. Ciò significa che, dato che non si è verificato alcun successo fino a un certo punto, la probabilità di successo nelle prove future è indipendente dal passato e rimane sempre \\(p\\).\n\n\n\n31.7.3 Applicazione nel Modello\nAd esempio, supponiamo di voler modellare quanti giorni passano prima che un animale venga adottato in un rifugio. Se la probabilità giornaliera di essere adottato è \\(p\\), la distribuzione geometrica può dirci quanto tempo ci aspettiamo prima che l’adozione avvenga. Se, ad esempio, \\(p = 0.2\\), significa che c’è il 20% di probabilità di adozione ogni giorno, e possiamo modellare il numero di giorni fino all’adozione usando una distribuzione geometrica.\nNel nostro modello di adozione, stiamo utilizzando la distribuzione geometrica per modellare i giorni fino all’adozione. La probabilità \\(p\\) rappresenta la probabilità giornaliera che un animale venga adottato, e la distribuzione geometrica ci permette di modellare il numero di giorni fino a quando avviene il successo (adozione).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/11_discr_rv_distr.html#riflessioni-conclusive",
    "title": "31  Distribuzioni di v.c. discrete",
    "section": "31.8 Riflessioni Conclusive",
    "text": "31.8 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato diverse distribuzioni discrete fondamentali, ciascuna con le sue specifiche applicazioni e peculiarità. Abbiamo iniziato con la distribuzione Bernoulliana, che modella esperimenti con due possibili esiti, come il lancio di una moneta. Abbiamo poi approfondito la distribuzione Binomiale, una generalizzazione della Bernoulliana, che si focalizza sul conteggio del numero di successi in un dato numero di prove indipendenti.\nAbbiamo anche esaminato la distribuzione Beta-Binomiale, che estende ulteriormente il modello Binomiale incorporando la variabilità nella probabilità di successo, e la distribuzione di Poisson, utilizzata per modellare il numero di eventi che si verificano in un intervallo di tempo o spazio, quando questi eventi sono rari e indipendenti.\nInfine, abbiamo discusso la distribuzione Discreta Uniforme, che attribuisce la stessa probabilità a ogni evento in un insieme finito e discreto. Questa distribuzione è particolarmente utile quando non abbiamo ragioni per assegnare probabilità diverse ai diversi esiti.\nQueste distribuzioni formano il cuore dell’analisi statistica discreta e trovano applicazione in un’ampia gamma di settori. In particolare, nel contesto dell’analisi bayesiana, la comprensione della distribuzione Binomiale e Beta-Binomiale è cruciale, poiché queste distribuzioni forniscono le basi per l’aggiornamento bayesiano, un concetto chiave che sarà esplorato nei capitoli successivi.\nPer coloro interessati a tecniche più avanzate, la generazione di valori casuali a partire da queste distribuzioni è trattata nell’appendice {ref}rng-appendix. Questa sezione fornisce strumenti e approfondimenti utili per l’applicazione pratica di questi modelli probabilistici.\nIn conclusione, le distribuzioni discrete forniscono strumenti essenziali e versatili per modellare e analizzare fenomeni caratterizzati da eventi distinti e quantificabili. La comprensione approfondita di queste distribuzioni è cruciale per chiunque desideri esplorare il vasto campo della probabilità e della statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#esercizi",
    "href": "chapters/probability/11_discr_rv_distr.html#esercizi",
    "title": "31  Distribuzioni di v.c. discrete",
    "section": "31.9 Esercizi",
    "text": "31.9 Esercizi\n\nEsercizio 31.5 Per ciascuna delle distribuzioni di massa di probabilità discusse, utilizza Python per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l’intervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media più una deviazione standard, calcolare la probabilità che la variabile aleatoria assuma un valore minore o uguale a questo valore.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/11_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "31  Distribuzioni di v.c. discrete",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.0       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html",
    "href": "chapters/probability/12_cont_rv_distr.html",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "",
    "text": "32.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nAnalogamente a quanto avviene per le variabili casuali discrete, anche per le variabili casuali continue possiamo rappresentare la variabilità all’interno di una popolazione attraverso un modello statistico, ma in questo caso utilizziamo le densità di probabilità – si veda il ?sec-density-function. Mentre le distribuzioni di probabilità discrete si applicano a fenomeni con un numero finito o numerabile di esiti, le densità di probabilità sono fondamentali per descrivere variabili che possono assumere un continuum di valori.\nLa funzione di densità di probabilità \\(f(x)\\) associata a una variabile casuale continua \\(X\\) rappresenta la distribuzione della probabilità all’interno della popolazione. Questa funzione non fornisce la probabilità esatta di un singolo valore, ma piuttosto la probabilità di osservare valori di \\(X\\) all’interno di un intervallo specifico. Così come per le distribuzioni discrete, anche le densità di probabilità costituiscono un modello della popolazione, una rappresentazione matematica che ci consente di fare previsioni e di comprendere meglio i fenomeni aleatori continui.\nIniziamo con la distribuzione continua uniforme.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#introduzione",
    "href": "chapters/probability/12_cont_rv_distr.html#introduzione",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "",
    "text": "32.1.1 Distribuzione Uniforme\nLa distribuzione uniforme è una delle più semplici funzioni di densità di probabilità. Consideriamo di nuovo l’esperimento dello spinner introdotto in precedenza. Simuliamo 20 valori che potrebbero essere ottenuti facendo ruotare lo spinner e li rappresentiamo con un istogramma.\n\n32.1.1.1 Simulazione di 20 valori\n\n# Simulazione di 20 valori\nset.seed(123)\nspinner_results &lt;- runif(20, min = 0, max = 360)\nprint(spinner_results)\n#&gt;  [1] 103.52791 283.78985 147.23169 317.88627 338.56822  16.40034 190.11798\n#&gt;  [8] 321.27086 198.51661 164.38130 344.46000 163.20030 243.92543 206.14802\n#&gt; [15]  37.05289 323.93699  88.59158  15.14143 118.05146 343.62131\n\nggplot(data.frame(Valori = spinner_results), aes(x = Valori)) +\n  geom_histogram(binwidth = 10, fill = \"skyblue\", color = \"black\", alpha = 0.5) +\n  labs(x = \"Risultato dello spinner\", y = \"Frequenza relativa\",\n       title = \"Istogramma dei risultati (20 simulazioni)\") \n\n\n\n\n\n\n\n\nNonostante possiamo pensare che ogni risultato tra 0 e 360 sia ugualmente probabile, l’istogramma non lo suggerisce chiaramente con solo 20 osservazioni. Simuliamo ora 100.000 ripetizioni.\n\n\n32.1.1.2 Simulazione di 100.000 valori\n\n# Simulazione di 100.000 valori\nspinner_results_large &lt;- runif(100000, min = 0, max = 360)\n\n# Istogramma\nggplot(data.frame(Valori = spinner_results_large), aes(x = Valori)) +\n  geom_histogram(binwidth = 10, fill = \"skyblue\", color = \"black\", alpha = 0.5) +\n  labs(x = \"Risultato dello spinner\", y = \"Frequenza relativa\",\n       title = \"Istogramma dei risultati (100.000 simulazioni)\") \n\n\n\n\n\n\n\n\nIn questo caso, anche se ci sono variazioni nelle altezze delle barre (bin di ampiezza pari a 10), la forma generale dell’istogramma appare piuttosto uniforme su tutto l’intervallo \\([0, 360]\\). Con un numero enorme di risultati, l’istogramma si avvicinerebbe alla funzione di densità uniforme mostrata di seguito.\n\n\n32.1.1.3 Funzione di densità uniforme\n\n# Curva della funzione di densità uniforme\nx &lt;- seq(0, 360, length.out = 100)\ndensity_uniform &lt;- dunif(x, min = 0, max = 360)\n\nggplot(data.frame(x = x, y = density_uniform), aes(x = x, y = y)) +\n  geom_line(size = 1, color = \"blue\") +\n  labs(x = \"x\", y = \"p(x)\", title = \"Funzione di densità uniforme\") \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nQuando la variabile casuale \\(X\\) è continua, come nel caso dello spinner, la probabilità è rappresentata da una curva, la funzione di densità di probabilità. Poiché lo spinner copre l’intervallo \\([0, 360]\\), la probabilità che \\(X\\) sia compreso in questo intervallo è pari a 1. La densità costante è quindi:\n\n1 / 360\n#&gt; [1] 0.002777778\n\n\n\n32.1.1.4 Probabilità in un intervallo specifico\nLa probabilità di ottenere un valore tra 150 e 250, \\(P(150 &lt; X &lt; 250)\\), è data dall’area sottesa alla curva in quell’intervallo. L’altezza della curva è \\(1/360\\), mentre la base è \\(250 - 150 = 100\\). Quindi:\n\n100 * (1 / 360)\n#&gt; [1] 0.2777778\n\nPer calcolare la probabilità, si possono utilizzare le funzioni di distribuzione cumulative:\n\npunif(250, min = 0, max = 360) - punif(150, min = 0, max = 360)\n#&gt; [1] 0.2777778\n\n\n\n32.1.1.5 Visualizzazione dell’intervallo di probabilità\n\n# Visualizzazione della probabilità nell'intervallo [150, 250]\nx &lt;- seq(0, 360, length.out = 1000)\nfx &lt;- dunif(x, min = 0, max = 360)\n\nggplot(data.frame(x = x, fx = fx), aes(x = x, y = fx)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x = x, fx = fx), x &gt;= 150 & x &lt;= 250),\n            aes(x = x, y = fx), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"p(x)\", title = \"Probabilità per l'intervallo [150, 250]\")\n\n\n\n\n\n\n\n\nIn maniera più formale possiamo dire che la distribuzione continua uniforme è una distribuzione di probabilità continua che assegna lo stesso grado di fiducia a tutti i possibili valori di una variabile definita in un certo intervallo \\(S=[a,b]\\subset {\\mathbb  {R}}\\). La distribuzione continua uniforme viene indicata con \\({\\mathcal  {U}}(a,b)={\\mathcal  {U}}([a,b])\\). Come intervallo \\([a,b]\\) viene spesso preso l’intervallo unitario \\(I=[0,1]\\).\nLa densità di probabilità di una variabile casuale continua uniforme \\({\\mathcal  {U}}(a,b)\\) è\n\\[\nf(x)={\\frac  {1}{b-a}} \\quad \\text{su}\\; [a, b].\n\\]\nIl suo valore attesto è\n\\[\n\\displaystyle E(X)={\\frac {1}{2}}(b+a).\n\\]\nLa sua varianza è\n\\[\nV(X)={\\frac {1}{12}}(b-a)^{2}.\n\\]\nIn R, è possibile manipolare la distribuzione uniforme utilizzando le funzioni della famiglia runif, dunif, punif e qunif. Di default, queste funzioni lavorano con la distribuzione uniforme standard \\(\\mathcal{U}(0,1)\\).\n\n\n\n32.1.2 Funzione di densità di probabilità (PDF)\nLa funzione dunif() calcola l’ordinata della funzione di densità per i valori di input specificati. Per esempio, esaminiamo la densità di \\(\\mathcal{U}(0,1)\\) per i valori 0.5, 0.8 e 1.2. Ci aspettiamo di ottenere 1 per i primi due valori e 0 per 1.2, che è fuori dall’intervallo \\([0, 1]\\).\n\ndunif(c(0.5, 0.8, 1.2), min = 0, max = 1)\n#&gt; [1] 1 1 0\n\n\n\n32.1.3 Funzione di ripartizione (CDF)\nLa funzione punif() restituisce il valore della funzione di ripartizione. Per esempio, per \\(\\mathcal{U}(0,1)\\) nei punti 0.5 e 0.8:\n\npunif(c(0.5, 0.8), min = 0, max = 1)\n#&gt; [1] 0.5 0.8\n\n\n\n32.1.4 Calcolo della probabilità in un intervallo\nUtilizzando la funzione di ripartizione, possiamo calcolare la probabilità che la variabile casuale continua assuma un valore in un intervallo specificato. Per esempio, per \\(\\mathcal{U}(0,1)\\) troviamo \\(P(0.5 &lt; X &lt; 0.8)\\):\n\npunif(0.8, min = 0, max = 1) - punif(0.5, min = 0, max = 1)\n#&gt; [1] 0.3\n\n\n\n32.1.5 Calcolo dei quantili\nLa funzione qunif() restituisce i quantili della distribuzione uniforme, ovvero il valore della variabile casuale \\(X\\) in corrispondenza del valore della funzione di ripartizione fornito in input. Per esempio, troviamo i quantili di ordine 0.5 e 0.8 di \\(\\mathcal{U}(0,1)\\):\n\nqunif(c(0.5, 0.8), min = 0, max = 1)\n#&gt; [1] 0.5 0.8\n\n\n\n32.1.6 Simulazione di valori casuali\nLa funzione runif() consente di generare numeri casuali dalla distribuzione uniforme. Per esempio, simuliamo 5 valori casuali da \\(\\mathcal{U}(0,1)\\):\n\nset.seed(123)  # Per la riproducibilità\nrunif(5, min = 0, max = 1)\n#&gt; [1] 0.2875775 0.7883051 0.4089769 0.8830174 0.9404673\n\n\n\n32.1.7 Valore atteso\nPer verificare il valore atteso di 100,000 realizzazioni di \\(\\mathcal{U}(0,1)\\):\n\nmean(runif(100000, min = 0, max = 1))\n#&gt; [1] 0.4992833\n\n\n\n32.1.8 Varianza\nPer calcolare la varianza di 100,000 realizzazioni di \\(\\mathcal{U}(0,1)\\):\n\nvar(runif(100000, min = 0, max = 1))\n#&gt; [1] 0.08342307\n\nConfrontiamo il valore teorico della varianza per \\(\\mathcal{U}(0,1)\\), che è \\(1/12\\):\n\n1 / 12\n#&gt; [1] 0.08333333\n\nIn conclusione, le funzioni della famiglia runif, dunif, punif e qunif in R consentono di manipolare e analizzare la distribuzione uniforme.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "32.2 Distribuzione esponenziale",
    "text": "32.2 Distribuzione esponenziale\nUn’altra distribuzione di densità molto semplice è la distribuzione esponenziale. La distribuzione esponenziale viene spesso utilizzata per modellare il tempo trascorso prima che un evento si verifichi (tempo di attesa).\nLa distribuzione esponenziale è l’unica distribuzione di probabilità continua che possiede la proprietà di assenza di memoria. Ad esempio, ipotizziamo che il tempo necessario affinché un bicchiere da vino si rompa dopo il primo utilizzo segua una distribuzione esponenziale. Supponiamo inoltre che ci sia un bicchiere da vino che non si è rotto dopo 3 anni dal primo utilizzo. L’assenza di memoria significa che la probabilità che questo bicchiere da vino non si rompa nel prossimo anno è la stessa della probabilità che un altro bicchiere da vino nuovo non si rompa nel primo anno di utilizzo.\nChiamiamo \\(X\\) il tempo di attesa. Sia \\(\\mu = \\mathbb{E}(X)\\) il tempo di attesa medio. La funzione di densità esponenziale è\n\\[\nf(x) = \\lambda {\\rm e}^{-\\lambda x}, \\quad \\text{con} \\; \\lambda = 1/\\mu,\\, \\lambda &gt; 0,\\, x &gt; 0,\n\\tag{32.1}\\]\novvero\n\\[\nf(x) = \\frac{1}{\\mu} {\\rm e}^{-x/\\mu}.\n\\]\nLa media di una distribuzione esponenziale è\n\\[\nE(X) = \\frac{1}{\\lambda}.\n\\]\nLa varianza di una distribuzione esponenziale è\n\\[\nV(X) = \\mu = \\frac{1}{\\lambda^2}.\n\\]\nLa deviazione standard è dunque uguale alla media:\n\\[\n\\sigma_X = \\frac{1}{\\lambda} = \\mu.\n\\]\nAd esempio, il tempo di attesa della pubblicazione del voto di un esame scritto segue una distribuzione esponenziale. Supponiamo che, in questo Corso di Laurea, il tempo di attesa medio per conoscere il risultato di un esame scritto sia di 4 giorni. La funzione esponenziale diventa\n\\[\nf(x) = \\frac{1}{4} \\exp^{-x/4}.\n\\]\n\n32.2.1 Grafico della funzione di densità esponenziale\nLa densità esponenziale è definita da \\(f(x) = \\lambda e^{-\\lambda x}\\). In R, possiamo disegnarla con:\n\n# Parametri della distribuzione\nmu &lt;- 4  # Media\nlambda &lt;- 1 / mu  # Tasso (1 / media)\nstdev &lt;- 1 / lambda  # Deviazione standard\n\n# Generare valori per x\nx &lt;- seq(0, 20, by = 0.01)\n\n# Calcolare la densità\npdf &lt;- dexp(x, rate = lambda)\n\n# Grafico della densità\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  labs(x = \"x\", y = \"f(x)\", title = \"Funzione di densità della distribuzione esponenziale\") \n\n\n\n\n\n\n\n\n\n\n32.2.2 Probabilità che \\(X \\leq 1.5\\)\nLa probabilità \\(P(X \\leq 1.5)\\) è calcolata con la funzione di ripartizione pexp():\n\n# Probabilità che X &lt;= 1.5\npexp(1.5, rate = lambda)\n#&gt; [1] 0.3127107\n\nVisualizzazione dell’area sottesa:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x, pdf), x &lt;= 1.5), aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"f(x)\", title = \"Probabilità P(X &lt;= 1.5)\") \n\n\n\n\n\n\n\n\n\n\n32.2.3 Probabilità che \\(1 \\leq X \\leq 6\\)\nLa probabilità \\(P(1 \\leq X \\leq 6)\\) si calcola come differenza di funzioni di ripartizione:\n\n# Probabilità che 1 &lt;= X &lt;= 6\npexp(6, rate = lambda) - pexp(1, rate = lambda)\n#&gt; [1] 0.5556706\n\nVisualizzazione dell’area sottesa:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x, pdf), x &gt;= 1 & x &lt;= 6), aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"f(x)\", title = \"Probabilità P(1 &lt;= X &lt;= 6)\")\n\n\n\n\n\n\n\n\n\n\n32.2.4 Probabilità che \\(X \\geq 5.5\\)\nLa probabilità \\(P(X \\geq 5.5)\\) si ottiene con l’evento complementare \\(1 - P(X \\leq 5.5)\\) oppure con 1 - pexp():\n\n# Complemento\n1 - pexp(5.5, rate = lambda)\n#&gt; [1] 0.2528396\n\n# Alternativa con funzione di sopravvivenza\npexp(5.5, rate = lambda, lower.tail = FALSE)\n#&gt; [1] 0.2528396\n\nVisualizzazione dell’area sottesa:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x, pdf), x &gt;= 5.5), aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"f(x)\", title = \"Probabilità P(X &gt;= 5.5)\") \n\n\n\n\n\n\n\n\n\n\n32.2.5 Istogramma di valori simulati\nSimuliamo 1.000.000 di valori casuali da una distribuzione esponenziale con parametro \\(\\lambda = 1/4\\), quindi costruiamo l’istogramma sovrapponendo la densità teorica.\n\n# Simulazione di valori casuali\nset.seed(123)\nsamples &lt;- rexp(1000000, rate = lambda)\n\n# Istogramma con densità sovrapposta\nggplot(data.frame(samples), aes(x = samples)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 100, fill = \"skyblue\", color = \"black\", alpha = 0.5) +\n  geom_line(data = data.frame(x, pdf), aes(x = x, y = pdf), color = \"red\", size = 1) +\n  xlim(0, 20) +\n  labs(x = \"Tempo di attesa\", y = \"Frequenza relativa\",\n       title = \"Istogramma dei valori simulati con densità teorica\")\n#&gt; Warning: Removed 6631 rows containing non-finite outside the scale range\n#&gt; (`stat_bin()`).\n#&gt; Warning: Removed 2 rows containing missing values or values outside the scale range\n#&gt; (`geom_bar()`).\n\n\n\n\n\n\n\n\nQuesti esempi replicano tutte le funzionalità dell’implementazione Python utilizzando R e producono grafici chiari e ben definiti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-gaussiana",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-gaussiana",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "32.3 Distribuzione Gaussiana",
    "text": "32.3 Distribuzione Gaussiana\nLa più importante distribuzione di densità è la Gaussiana. Non c’è un’unica distribuzione gaussiana (o Normale): la distribuzione gaussiana è una famiglia di distribuzioni. Tali distribuzioni sono dette “gaussiane” in onore di Carl Friedrich Gauss (uno dei più grandi matematici della storia il quale, tra le altre cose, scoprì l’utilità di tale funzione di densità per descrivere gli errori di misurazione). Adolphe Quetelet, il padre delle scienze sociali quantitative, fu il primo ad applicare tale funzione di densità alle misurazioni dell’uomo. Karl Pearson usò per primo il termine “distribuzione normale” anche se ammise che questa espressione “ha lo svantaggio di indurre le persone a credere che le altre distribuzioni, in un senso o nell’altro, non siano normali.”\n\n32.3.1 Limite delle distribuzioni binomiali\nIniziamo con un un breve excursus storico. Nel 1733, Abraham de Moivre notò che, aumentando il numero di prove di una distribuzione binomiale, la distribuzione risultante diventava quasi simmetrica e a forma campanulare. Per esempio, con 10 prove e una probabilità di successo di 0.9, la distribuzione è chiaramente asimmetrica.\n\n# Parametri\nn &lt;- 10\np &lt;- 0.9\n\n# Calcolare la distribuzione binomiale\nr_values &lt;- 0:n\ndist &lt;- dbinom(r_values, size = n, prob = p)\n\n# Grafico\nggplot(data.frame(Successi = r_values, Probabilità = dist), aes(x = Successi, y = Probabilità)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Distribuzione Binomiale: n = 10, p = 0.9\", x = \"Numero di Successi\", y = \"Probabilità\") \n\n\n\n\n\n\n\n\nQuando il numero di prove N viene aumentato di un fattore di 100 a N = 1000, mantenendo costante la probabilità di successo del 90%, si osserva che la distribuzione assume una forma campanulare quasi simmetrica. Questa osservazione porta a una scoperta di de Moivre: quando N diventa grande, la funzione gaussiana, nonostante rappresenti la densità di variabili casuali continue, offre una buona approssimazione alla funzione di massa di probabilità binomiale.\n\n# Parametri aggiornati\nn &lt;- 1000\n\n# Calcolare la distribuzione\nr_values &lt;- 850:950  # Intervallo per una migliore visualizzazione\ndist &lt;- dbinom(r_values, size = n, prob = p)\n\n# Grafico\nggplot(data.frame(Successi = r_values, Probabilità = dist), aes(x = Successi, y = Probabilità)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Distribuzione Binomiale: n = 1000, p = 0.9\", \n    x = \"Numero di Successi\", \n    y = \"Probabilità\"\n  ) \n\n\n\n\n\n\n\n\nLa distribuzione Normale fu scoperta da Gauss nel 1809. Il Paragrafo successivo illustra come si possa giungere alla Normale mediante una simulazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "href": "chapters/probability/12_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "32.4 La Normale prodotta con una simulazione",
    "text": "32.4 La Normale prodotta con una simulazione\nIl libro “Rethinking Statistics” di McElreath (2020) spiega come sia possibile ottenere la distribuzione normale attraverso una simulazione. Immaginiamo di avere duemila persone che si trovano allineate su una linea di partenza. Quando viene dato il segnale di partenza, ogni persona lancia una moneta e compie un passo avanti o indietro a seconda del risultato del lancio. La lunghezza di ogni passo può variare da 0 a 1 metro. Ogni persona lancia la moneta 16 volte e quindi compie 16 passi.\nI risultati ottenuti da una serie di passeggiate casuali si traducono in varie distanze dall’origine, che è il punto da cui si parte, contrassegnato come zero, dopo un numero specificato di passi. Queste distanze sono rappresentate numericamente. Al termine di queste passeggiate, non è possibile determinare la posizione esatta di ogni individuo, ma è possibile descrivere accuratamente le caratteristiche della distribuzione delle 1000 distanze dall’origine.\nAd esempio, è possibile prevedere con precisione la frazione di individui che si sono mossi verso in avanti o indietro, o la proporzione di persone che si troveranno a una distanza specifica dal punto di partenza, come a 1.5 metri dall’origine. Queste previsioni sono fattibili perché la distribuzione delle distanze segue una distribuzione Normale.\nIl codice presentato di seguito genera passeggiate casuali utilizzando un generatore di numeri casuali e ne traccia i percorsi risultanti. Il codice inizia inizializzando un oggetto generatore di numeri casuali con la funzione np.random.default_rng() della libreria numpy. Questo generatore sarà usato per produrre numeri casuali uniformemente distribuiti tra -1 e 1, simulando così il lancio di una moneta.\nLa variabile steps specifica il numero di passi per ogni passeggiata casuale, mentre repetitions indica il numero di passeggiate da generare. La variabile show_steps è un elenco di numeri di passi in cui il codice traccerà linee verticali sul grafico.\nSuccessivamente, il codice crea un array bidimensionale di NumPy chiamato x con righe pari a steps + 1 e colonne pari a repetitions. La prima colonna di questo array è riempita di zeri, e le colonne rimanenti sono riempite con la somma cumulativa dei passi, ottenuti da numeri casuali uniformemente distribuiti generati dal generatore di numeri casuali. Questo array verrà utilizzato per memorizzare le posizioni della passeggiata casuale ad ogni passo.\nIl codice poi prepara una figura per tracciare tutte le passeggiate casuali. Il codice traccia anche la prima passeggiata casuale in nero.\n\n# Parametri\nnumero_passi &lt;- 16\nripetizioni &lt;- 1000\npunti_da_evidenziare &lt;- c(4, 8, 16)\n\n# Generare passeggiate casuali\nset.seed(123)\nx &lt;- matrix(0, nrow = numero_passi + 1, ncol = ripetizioni)\n\nfor (i in 1:ripetizioni) {\n  passi &lt;- runif(numero_passi, min = -1, max = 1)\n  x[-1, i] &lt;- cumsum(passi)\n}\n\n# Grafico delle passeggiate casuali\ndf &lt;- data.frame(\n  Passo = rep(0:numero_passi, times = ripetizioni), \n  Distanza = as.vector(x)\n)\n\n# Grafico delle passeggiate casuali\nggplot(\n  df, \n  aes(\n    x = Passo, \n    y = Distanza, \n    group = rep(1:ripetizioni, each = numero_passi + 1))\n  ) +\n  geom_line(color = \"blue\", alpha = 0.05) +\n  geom_line(\n    data = data.frame(Passo = 0:numero_passi, Distanza = x[, 1], group = 1), \n    aes(x = Passo, y = Distanza, group = group), color = \"black\") +\n  geom_vline(\n    xintercept = punti_da_evidenziare, \n    linetype = \"dashed\", \n    color = \"black\", \n    alpha = 0.5) +\n  labs(\n    title = \"Passeggiate Casuali\", \n    x = \"Numero di Passi\", \n    y = \"Distanza dall'Origine\"\n  ) \n\n\n\n\n\n\n\n\nIl grafico riportato qui sotto visualizza la distribuzione dei passi a partire dalla linea mediana dopo 4, 8 e 16 lanci di moneta/passi. Quello che si nota è che, man mano che procediamo nel numero di passi, le densità iniziano a somigliare alla curva a campana associata alle distribuzioni Gaussiane.\n\ndensities &lt;- lapply(punti_da_evidenziare, function(step) {\n  data.frame(Posizione = x[step + 1, ], Passo = step)\n})\n\ndensities &lt;- bind_rows(densities)\n\nggplot(densities, aes(x = Posizione, fill = as.factor(Passo))) +\n  geom_density(alpha = 0.6) +\n  facet_wrap(~ Passo, scales = \"free\") +\n  labs(\n    title = \"Densità delle Posizioni\",\n    x = \"Posizione\",\n    y = \"Densità\",\n    fill = \"Passo\"  # Etichetta per la legenda\n  ) +\n  theme(\n    legend.position = \"bottom\"  # Sposta la legenda in basso\n  )\n\n\n\n\n\n\n\n\nLa chiarezza dell’informazione presentata nei grafici precedenti può essere migliorata utilizzando un KDE plot.\n\n# Generare i dati\nposizioni &lt;- apply(matrix(runif(numero_passi * ripetizioni, min = -1, max = 1), nrow = numero_passi), 2, sum)\n\n# Calcolare media e deviazione standard\nmedia &lt;- mean(posizioni)\ndev_std &lt;- sd(posizioni)\n\n# Generare la curva normale\nvalori &lt;- seq(min(posizioni), max(posizioni), length.out = 1000)\ndensità_normale &lt;- dnorm(valori, mean = media, sd = dev_std)\n\n# Grafico\nggplot(data.frame(Posizione = posizioni), aes(x = Posizione)) +\n  geom_density(fill = \"skyblue\", alpha = 0.5) +\n  geom_line(data = data.frame(Posizione = valori, Densità = densità_normale), aes(x = Posizione, y = Densità), color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Confronto tra Passeggiate Casuali e Normale\", x = \"Posizione\", y = \"Densità\") \n\n\n\n\n\n\n\n\nQuesta simulazione in luce un principio fondamentale della teoria delle probabilità: ogni processo che coinvolge la somma di una sequenza di valori casuali, tutti estratti dalla stessa distribuzione, inevitabilmente tende verso una distribuzione normale, comunemente conosciuta come curva gaussiana. Questa tendenza si verifica indipendentemente dalla configurazione iniziale della distribuzione di partenza, che può essere uniforme, come nell’esempio menzionato, o di qualsiasi altro tipo. La forma specifica della distribuzione iniziale influisce sulla velocità con cui si verifica questa convergenza verso il comportamento gaussiano, con variazioni significative nella velocità di convergenza: alcuni processi possono manifestare una convergenza lenta, mentre altri possono convergere estremamente rapidamente. Un esempio emblematico di questo fenomeno è rappresentato dal dispositivo conosciuto come Galton box, il quale offre una rappresentazione visiva e fisica di come la somma di valori casuali generi una distribuzione normale.\nUn modo per razionalizzare la distribuzione Gaussiana è quello di pensare alle medie. Qualunque sia il valore medio della distribuzione di origine, ogni campione da essa può essere considerato una fluttuazione rispetto a quel valore medio. Tuttavia, quando sommiamo queste fluttuazioni insieme, esse si annullano a vicenda. E, facendo ciò, queste fluttuazioni convergono eventualmente alla media delle osservazioni collettive. Non importa quale sia la forma della distribuzione sottostante. A seconda della forma, le somme cumulative convergeranno inevitabilmente sulla media, alcune distribuzioni più lentamente di altre.\nDal punto di vista formale, possiamo definire una variabile casuale continua \\(Y\\) come avente una distribuzione normale se la sua densità di probabilità è distribuita secondo la seguente equazione\n\\[\nf(y; \\mu, \\sigma) = {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y -  \\mu)^2}{2 \\sigma^2} \\right\\},\n\\tag{32.2}\\]\ndove \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma &gt; 0\\) sono i parametri della distribuzione.\nLa densità normale è unimodale e simmetrica con una caratteristica forma a campana e con il punto di massima densità in corrispondenza di \\(\\mu\\).\nIl significato dei parametri \\(\\mu\\) e \\(\\sigma\\) che appaiono nell’eq. {eq}eq-normal-formula viene chiarito dalla dimostrazione che\n\\[\n\\mathbb{E}(Y) = \\mu, \\qquad \\mathbb{V}(Y) = \\sigma^2.\n\\]\nLa rappresentazione grafica di quattro densità Normali con medie -1, -0.5, 0, 1 e con deviazioni standard 0.25, 0.5, 1 e 2 è fornita nella figura seguente.\n\n# Definire l'intervallo di x\nx &lt;- seq(-5, 6, by = 0.001)\n\n# Parametri della distribuzione normale\nmus &lt;- c(-1.0, -0.5, 0.0, 1.0)\nsigmas &lt;- c(0.25, 0.5, 1, 2)\n\n# Creare un data frame per tutte le combinazioni di mu e sigma\ndata &lt;- do.call(rbind, lapply(1:length(mus), function(i) {\n  data.frame(\n    x = x,\n    f_x = dnorm(x, mean = mus[i], sd = sigmas[i]),\n    mu = mus[i],\n    sigma = sigmas[i]\n  )\n}))\n\n# Grafico\nggplot(data, aes(x = x, y = f_x, color = factor(mu), linetype = factor(sigma))) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    color = expression(mu),\n    linetype = expression(sigma),\n    title = \"Distribuzioni Normali con Diversi Parametri\"\n  ) +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\n32.4.1 Concentrazione\nÈ istruttivo osservare il grado di concentrazione della distribuzione Normale attorno alla media:\n\\[\n\\begin{align}\nP(\\mu - \\sigma &lt; Y &lt; \\mu + \\sigma) &= P (-1 &lt; Z &lt; 1) \\simeq 0.683, \\notag\\\\\nP(\\mu - 2\\sigma &lt; Y &lt; \\mu + 2\\sigma) &= P (-2 &lt; Z &lt; 2) \\simeq 0.956, \\notag\\\\\nP(\\mu - 3\\sigma &lt; Y &lt; \\mu + 3\\sigma) &= P (-3 &lt; Z &lt; 3) \\simeq 0.997. \\notag\n\\end{align}\n\\]\nSi noti come un dato la cui distanza dalla media è superiore a 3 volte la deviazione standard presenti un carattere di eccezionalità perché meno del 0.3% dei dati della distribuzione Normale presentano questa caratteristica.\nPer indicare la distribuzione Normale si usa la notazione \\(\\mathcal{N}(\\mu, \\sigma)\\).\n\n\n32.4.2 Funzione di ripartizione\nIl valore della funzione di ripartizione di \\(Y\\) nel punto \\(y\\) è l’area sottesa alla curva di densità \\(f(y)\\) nella semiretta \\((-\\infty, y]\\). Non esiste alcuna funzione elementare per la funzione di ripartizione\n\\[\nF(y) = \\int_{-\\infty}^y {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y - \\mu)^2}{2\\sigma^2} \\right\\} dy,\n\\] (eq-gaussian-rip-formula)\npertanto le probabilità \\(P(Y &lt; y)\\) vengono calcolate mediante integrazione numerica approssimata. I valori della funzione di ripartizione di una variabile casuale Normale sono dunque forniti da un software.\nEcco l’equivalente in R utilizzando le funzioni per la distribuzione normale e il pacchetto ggplot2 per i grafici.\n\n\n32.4.3 Generazione di Valori Casuali\nIn R, la funzione rnorm() genera valori casuali dalla distribuzione normale. Ad esempio, per ottenere un singolo valore casuale dalla \\(\\mathcal{N}(100, 15)\\):\n\n# Generare un singolo valore casuale\nset.seed(123)  # Per la riproducibilità\nrnorm(1, mean = 100, sd = 15)\n#&gt; [1] 91.59287\n\nPer estrarre 10 valori casuali dalla stessa distribuzione:\n\n# Generare 10 valori casuali\nset.seed(123)\nqi &lt;- rnorm(10, mean = 100, sd = 15)\nprint(qi)\n#&gt;  [1]  91.59287  96.54734 123.38062 101.05763 101.93932 125.72597 106.91374\n#&gt;  [8]  81.02408  89.69721  93.31507\n\n\n\n32.4.4 Funzione di Ripartizione (CDF)\nPer calcolare la probabilità che un’osservazione casuale abbia un valore minore o uguale a 115, utilizziamo pnorm():\n\n# Probabilità che X &lt;= 115\npnorm(115, mean = 100, sd = 15)\n#&gt; [1] 0.8413447\n\n\n\n32.4.5 Visualizzazione dell’Area Sottesa alla Funzione di Densità\nPossiamo visualizzare l’area sottesa utilizzando ggplot2:\n\n# Parametri\nmu &lt;- 100\nsigma &lt;- 15\n\n# Intervallo di x\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 1000)\n\n# Densità\nfx &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Grafico\nggplot(data.frame(x, fx), aes(x = x, y = fx)) +\n  geom_line(color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, fx), x &lt;= 115), \n    aes(x = x, y = fx), fill = \"gray\", alpha = 0.5\n  ) +\n  labs(title = \"Funzione di Densità Normale\", x = \"x\", y = \"f(x)\") \n\n\n\n\n\n\n\n\n\n\n32.4.6 Calcolo dell’Integrale con integrate\nPossiamo calcolare l’area sotto la curva manualmente utilizzando la funzione integrate:\n\n# Definizione della funzione gaussiana\ngaussian &lt;- function(x, mu, sigma) {\n  (1 / (sqrt(2 * pi) * sigma)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\n# Calcolo dell'area\nresult &lt;- integrate(gaussian, lower = -Inf, upper = 115, mu = 100, sigma = 15)\nprint(paste(\"Il risultato è\", result$value, \"con errore\", result$abs.error))\n#&gt; [1] \"Il risultato è 0.84134474610298 con errore 3.76616994661114e-06\"\n\n\n\n32.4.7 Proporzione di Valori Maggiori di 130\nCalcoliamo \\(P(X &gt; 130)\\) utilizzando il complementare della funzione di ripartizione:\n\n# Probabilità che X &gt; 130\n1 - pnorm(130, mean = 100, sd = 15)\n#&gt; [1] 0.02275013\n\nPossiamo anche utilizzare la funzione di sopravvivenza 1 - pnorm():\n\n# Funzione di sopravvivenza\npnorm(130, mean = 100, sd = 15, lower.tail = FALSE)\n#&gt; [1] 0.02275013\n\nVisualizzazione:\n\nggplot(data.frame(x, fx), aes(x = x, y = fx)) +\n  geom_line(color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, fx), x &gt;= 130), \n    aes(x = x, y = fx), fill = \"gray\", alpha = 0.5\n  ) +\n  labs(title = \"Area Sottesa per X &gt;= 130\", x = \"x\", y = \"f(x)\") \n\n\n\n\n\n\n\n\n\n\n32.4.8 Funzione di Quantile (PPF)\nLa funzione qnorm() restituisce il quantile della distribuzione normale. Ad esempio:\n\n# Quantile corrispondente al 97.725%\nqnorm(1 - 0.022750131948179195, mean = 100, sd = 15)\n#&gt; [1] 130\n\nIn conclusione, le funzioni rnorm, dnorm, pnorm, e qnorm in R forniscono gli strumenti necessari per manipolare la distribuzione normale.\n\n\n32.4.9 Distribuzione Normale standard\nLa distribuzione Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = 1\\) viene detta distribuzione Normale standard. La famiglia Normale è l’insieme avente come elementi tutte le distribuzioni Normali con parametri \\(\\mu\\) e \\(\\sigma\\) diversi. Tutte le distribuzioni Normali si ottengono dalla Normale standard mediante una trasformazione lineare: se \\(Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y)\\) allora\n\\[\nX = a + b Y \\sim \\mathcal{N}(\\mu_X = a+b \\mu_Y, \\sigma_X = \\left|b\\right|\\sigma_Y).\n\\]\nL’area sottesa alla curva di densità di \\(\\mathcal{N}(\\mu, \\sigma)\\) nella semiretta \\((-\\infty, y]\\) è uguale all’area sottesa alla densità Normale standard nella semiretta \\((-\\infty, z]\\), in cui \\(z = (y -\\mu_Y )/\\sigma_Y\\) è il punteggio standard di \\(Y\\). Per la simmetria della distribuzione, l’area sottesa nella semiretta \\([1, \\infty)\\) è uguale all’area sottesa nella semiretta \\((-\\infty, 1]\\) e quest’ultima coincide con \\(F(-1)\\). Analogamente, l’area sottesa nell’intervallo \\([y_a, y_b]\\), con \\(y_a &lt; y_b\\), è pari a \\(F(z_b) - F(z_a)\\), dove \\(z_a\\) e \\(z_b\\) sono i punteggi standard di \\(y_a\\) e \\(y_b\\).\nSi ha anche il problema inverso rispetto a quello del calcolo delle aree: dato un numero \\(0 \\leq p \\leq 1\\), il problema è quello di determinare un numero \\(z \\in \\mathbb{R}\\) tale che \\(P(Z &lt; z) = p\\). Il valore \\(z\\) cercato è detto quantile di ordine \\(p\\) della Normale standard e può essere trovato mediante un software.\nSupponiamo che l’altezza degli individui adulti segua la distribuzione Normale di media \\(\\mu = 1.7\\) m e deviazione standard \\(\\sigma = 0.1\\) m. Vogliamo sapere la proporzione di individui adulti con un’altezza compresa tra \\(1.7\\) e \\(1.8\\) m.\nIl problema ci chiede di trovare l’area sottesa alla distribuzione \\(\\mathcal{N}(\\mu = 1.7, \\sigma = 0.1)\\) nell’intervallo \\([1.7, 1.8]\\):\n\n# Parametri della distribuzione\nmu &lt;- 1.7\nsigma &lt;- 0.1\n\n# Calcolare la probabilità cumulativa\nprob &lt;- pnorm(1.8, mean = mu, sd = sigma) - pnorm(1.7, mean = mu, sd = sigma)\nprint(prob)\n#&gt; [1] 0.3413447\n\n\n# Generare dati\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 1000)\nfx &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Creare il grafico\nggplot(data.frame(x, fx), aes(x = x, y = fx)) +\n  geom_line(color = \"blue\") +\n  geom_area(data = subset(data.frame(x, fx), x &gt;= 1.7 & x &lt;= 1.8), \n            aes(x = x, y = fx), fill = \"gray\", alpha = 0.5) +\n  labs(title = \"Funzione di Densità Normale\", \n       x = \"Altezza (m)\", \n       y = \"Densità\")\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo standardizzare i valori che delimitano l’intervallo considerato e utilizzare la funzione di ripartizione della normale standardizzata. I limiti inferiore e superiore dell’intervallo sono\n\\[\nz_{\\text{inf}} = \\frac{1.7 - 1.7}{0.1} = 0, \\quad z_{\\text{sup}} = \\frac{1.8 - 1.7}{0.1} = 1.0,\n\\]\nquindi otteniamo\n\n# Standardizzazione\nz_inf &lt;- (1.7 - mu) / sigma\nz_sup &lt;- (1.8 - mu) / sigma\n\n# Calcolo con la normale standardizzata\nprob_standard &lt;- pnorm(z_sup, mean = 0, sd = 1) - pnorm(z_inf, mean = 0, sd = 1)\nprint(prob_standard)\n#&gt; [1] 0.3413447\n\nIl modo più semplice per risolvere questo problema resta comunque quello di rendersi conto che la probabilità richiesta non è altro che la metà dell’area sottesa dalle distribuzioni Normali nell’intervallo \\([\\mu - \\sigma, \\mu + \\sigma]\\), ovvero \\(0.683/2\\).\nConsideriamo ora la visualizzazione della PDF, la CDF e l’inverso della CDF della distribuzione normale.\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\n\n# Generare intervalli di valori\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 1000)\nprobabilities &lt;- seq(0.01, 0.99, length.out = 100)\n\n# Calcolo delle funzioni\npdf &lt;- dnorm(x, mean = mu, sd = sigma)\ncdf &lt;- pnorm(x, mean = mu, sd = sigma)\nppf &lt;- qnorm(probabilities, mean = mu, sd = sigma)\n\n# Creare i grafici con ggplot2\nlibrary(gridExtra)\n\n# Grafico della PDF\npdf_plot &lt;- ggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"PDF\", x = \"Valori\", y = \"Probabilità\")\n\n# Grafico della CDF\ncdf_plot &lt;- ggplot(data.frame(x, cdf), aes(x = x, y = cdf)) +\n  geom_line(color = \"orange\") +\n  labs(title = \"CDF\", x = \"Valori\", y = \"Cumulativa\")\n\n# Grafico dell'inversa della CDF\nppf_plot &lt;- ggplot(data.frame(Probabilità = probabilities, Valori = ppf), aes(x = Probabilità, y = Valori)) +\n  geom_line(color = \"green\") +\n  labs(title = \"Inverse CDF\", x = \"Probabilità\", y = \"Valori\") \n\n# Mostrare i grafici\ngrid.arrange(pdf_plot, cdf_plot, ppf_plot, ncol = 3)\n\n\n\n\n\n\n\n\nDovrebbe essere chiaro dalla figura che queste sono tre diverse modalità di osservare la stessa informazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "32.5 Distribuzione Chi-quadrato",
    "text": "32.5 Distribuzione Chi-quadrato\nDalla Normale deriva la distribuzione \\(\\chi^2\\). La distribuzione \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libertà descrive la variabile casuale\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]\ndove \\(Z_1, Z_2, \\dots, Z_k\\) sono variabili casuali i.i.d. che seguono la distribuzione Normale standard \\(\\mathcal{N}(0, 1)\\). La variabile casuale chi-quadrato dipende dal parametro intero positivo \\(\\nu = k\\) che ne identifica il numero di gradi di libertà. La densità di probabilità di \\(\\chi^2_{~\\nu}\\) è\n\\[\nf(x) = C_{\\nu} x^{\\nu/2-1} \\exp (-x/2), \\qquad \\text{se } x &gt; 0,\n\\]\ndove \\(C_{\\nu}\\) è una costante positiva.\n\n32.5.1 Grafico delle Distribuzioni Chi-Quadrato per Vari Valori di \\(\\nu\\)\nIn R, utilizziamo dchisq() per calcolare la funzione di densità della distribuzione chi-quadrato e ggplot2 per creare il grafico.\n\n# Intervallo di x\nx &lt;- seq(0, 40, by = 0.1)\n\n# Valori di gradi di libertà\nnus &lt;- c(2, 4, 8, 16)\n\n# Creazione del data frame per il grafico\ndata &lt;- do.call(rbind, lapply(nus, function(nu) {\n  data.frame(x = x, f_x = dchisq(x, df = nu), nu = as.factor(nu))\n}))\n\n# Grafico\nggplot(data, aes(x = x, y = f_x, color = nu)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzioni Chi-Quadrato per Diversi Valori di \\u03bd\",\n    x = \"x\",\n    y = \"f(x)\",\n    color = expression(nu)\n  ) \n\n\n\n\n\n\n\n\n\n\n32.5.2 Proprietà della Distribuzione Chi-Quadrato\n\nAsimmetria: La distribuzione \\(\\chi^2_{\\nu}\\) è asimmetrica.\nMedia: Il valore atteso di una variabile \\(\\chi^2_{\\nu}\\) è uguale a \\(\\nu\\).\nVarianza: La varianza è pari a \\(2\\nu\\).\nConvergenza: Per \\(k \\to \\infty\\), \\(\\chi^2_{\\nu} \\to \\mathcal{N}(\\nu, 2\\nu)\\).\nSomma di variabili: La somma di variabili \\(\\chi^2_{\\nu}\\) indipendenti con gradi di libertà diversi segue una distribuzione \\(\\chi^2_{m}\\), dove \\(m\\) è la somma dei gradi di libertà.\n\n\n\n32.5.3 Esempio con \\(\\chi^2_5\\)\n\n32.5.3.1 Densità della Distribuzione \\(\\chi^2_5\\)\n\n# Parametri\ndf &lt;- 5\nx &lt;- seq(0, 20, length.out = 200)\n\n# Calcolare la densità\npdf &lt;- dchisq(x, df = df)\n\n# Grafico\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\", size = 1) +\n  labs(\n    title = \"Distribuzione Chi-Quadrato (\\u03bd=5)\",\n    x = \"x\",\n    y = \"PDF\"\n  ) \n\n\n\n\n\n\n\n\n\n\n32.5.3.2 Generazione di Valori Casuali\nIn R, utilizziamo rchisq() per generare valori casuali dalla distribuzione chi-quadrato.\n\n# Generare 1.000.000 di valori casuali\nset.seed(123)  # Per riproducibilità\nx_samples &lt;- rchisq(1000000, df = df)\n\n# Mostrare i primi 20 valori\nhead(x_samples, 20)\n#&gt;  [1]  2.5718020  8.0747086  0.6485141  4.3740386 10.3216603  5.4098898\n#&gt;  [7]  1.2220565  0.6062728  8.2114143  5.0824402  5.2138617  4.3191833\n#&gt; [13]  2.5823235  8.5003495  6.6757373  3.8440466  2.7745098  3.4127394\n#&gt; [19]  1.6243638  3.7620351\n\n\n\n32.5.3.3 Calcolo della Media\nLa media teorica della distribuzione chi-quadrato è uguale a \\(\\nu\\). Verifichiamo empiricamente:\n\n# Calcolare la media\nmean(x_samples)\n#&gt; [1] 4.997691\n\n\n32.5.3.3.1 Calcolo della Varianza\nLa varianza teorica della distribuzione chi-quadrato è \\(2\\nu\\). Verifichiamo empiricamente:\n\n# Calcolare la varianza\nvar(x_samples)\n#&gt; [1] 9.990927\n\nIn conclusione,\n\nla distribuzione chi-quadrato è asimmetrica e converge alla distribuzione normale per valori elevati di \\(\\nu\\),\nla media e la varianza empiriche dei valori generati sono vicine ai valori teorici, verificando le proprietà della distribuzione.\n\nEcco la riscrittura del testo e del codice in R:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "32.6 Distribuzione \\(t\\) di Student",
    "text": "32.6 Distribuzione \\(t\\) di Student\nDalle distribuzioni Normale e Chi-quadrato deriva un’altra distribuzione molto nota, la \\(t\\) di Student. Se \\(Z \\sim \\mathcal{N}(0, 1)\\) e \\(W \\sim \\chi^2_{\\nu}\\) sono due variabili casuali indipendenti, allora il rapporto\n\\[\nT = \\frac{Z}{\\Big( \\frac{W}{\\nu}\\Big)^{\\frac{1}{2}}}\n\\]\ndefinisce la distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libertà. Si usa scrivere \\(T \\sim t_{\\nu}\\). L’andamento della distribuzione \\(t\\) di Student è simile a quello della distribuzione Normale, ma ha una dispersione maggiore (ha le code più pesanti di una Normale, ovvero ha una varianza maggiore di 1).\nLa seguente mostra alcune distribuzioni \\(t\\) di Student variando il parametro \\(\\nu\\).\n\nx &lt;- seq(-5, 5, by = 0.1)\nnus &lt;- c(1, 2, 5, 30)\n\ndf &lt;- data.frame(\n  x = rep(x, length(nus) + 1),\n  density = c(\n    sapply(nus, function(nu) dt(x, df = nu)), dnorm(x, mean = 0, sd = 1)\n  ),\n  distribution = factor(\n    rep(c(paste0(\"t (ν = \", nus, \")\"), \"N(μ = 0, σ = 1)\"), each = length(x))\n  )\n)\n\nggplot(df, aes(x = x, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\", \n    y = \"f(x)\", \n    title = \"Distribuzione t di Student e Normale\"\n  ) +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\n32.6.1 Proprietà\nLa variabile casuale \\(t\\) di Student soddisfa le seguenti proprietà:\n\nPer \\(\\nu \\rightarrow \\infty\\), \\(t_{\\nu}\\) tende alla normale standard \\(\\mathcal{N}(0, 1)\\).\nLa densità della \\(t_{\\nu}\\) è una funzione simmetrica con valore atteso nullo.\nPer \\(\\nu &gt; 2\\), la varianza della \\(t_{\\nu}\\) vale \\(\\nu / (\\nu - 2)\\); pertanto è sempre maggiore di 1 e tende a 1 per \\(\\nu \\rightarrow \\infty\\).\n\nCalcoliamo il valore della funzione di ripartizione di ordine 0.025 nel caso di una \\(t_{30}\\):\n\nqt(0.025, df = 30)\n#&gt; [1] -2.042272\n\nAumentiamo i gradi di libertà (\\(\\nu\\) = 1000):\n\nqt(0.025, df = 1000)\n#&gt; [1] -1.962339\n\nQuesto valore è quasi identico a quello della Normale standardizzata:\n\nqnorm(0.025, mean = 0, sd = 1)\n#&gt; [1] -1.959964\n\nLa ragione per cui il quantile della distribuzione \\(t\\) con \\(\\nu = 30\\) è maggiore (in valore assoluto) del quantile omotetico della distribuzione Normale Standard è che la distribuzione \\(t\\) ha una varianza maggiore rispetto alla distribuzione Normale Standard.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "chapters/probability/12_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "32.7 Funzione Beta di Eulero",
    "text": "32.7 Funzione Beta di Eulero\nLa funzione Beta di Eulero è una funzione matematica, non una densità di probabilità. La menzioniamo qui perché viene utilizzata nella densità di probabilità Beta. La funzione Beta di Eulero, comunemente indicata con il simbolo \\(B(\\alpha, \\beta)\\), si può scrivere in molti modi diversi; per i nostri scopi la presentiamo così:\n\\[\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, ovvero il fattoriale discendente, cioè\n\\[\n(x-1)(x-2)\\ldots (x-n+1)\\notag\\,.\n\\]\nPer esempio, posti \\(\\alpha = 3\\) e \\(\\beta = 9\\), la funzione Beta di Eulero assume il valore:\n\nalpha &lt;- 3\nbeta &lt;- 9\n\nbeta_function &lt;- gamma(alpha) * gamma(beta) / gamma(alpha + beta)\nbeta_function\n#&gt; [1] 0.002020202\n\nLo stesso risultato si ottiene usando direttamente la funzione beta in R:\n\nbeta(alpha, beta)\n#&gt; [1] 0.002020202\n\nOppure calcolandolo manualmente:\n\n(factorial(alpha - 1) * factorial(beta - 1)) / factorial(alpha + beta - 1)\n#&gt; [1] 0.002020202",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-beta",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-beta",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "32.8 Distribuzione Beta",
    "text": "32.8 Distribuzione Beta\nLa distribuzione di probabilità Beta, denotata comunemente come \\(Beta(\\alpha, \\beta)\\), è utilizzata per modellare fenomeni che sono espressi in percentuali o proporzioni. Un aspetto cruciale di questa distribuzione è la sua definizione esclusiva nell’intervallo \\((0, 1)\\). In pratica, ciò significa che essa considera valori compresi strettamente tra 0 e 1, escludendo sia lo 0 che l’1 come estremi.\n\n32.8.1 Definizione Formale\nConsideriamo una variabile casuale \\(\\theta\\), la quale può assumere qualunque valore nell’intervallo aperto \\((0, 1)\\). Se diciamo che \\(\\theta\\) segue una distribuzione Beta con parametri \\(\\alpha\\) e \\(\\beta\\) (indicato come \\(\\theta \\sim \\text{Beta}(\\alpha, \\beta)\\)), intendiamo che la sua funzione di densità è descritta dalla seguente formula:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} =  \\frac{\\Gamma(\\alpha+ \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} \\quad \\text{per } \\theta \\in (0, 1)\\,,\n\\]\ndove \\(B(\\alpha, \\beta)\\) è la funzione beta di Eulero, definita come \\(\\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\).\n\n\n32.8.2 I Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) giocano un ruolo cruciale nella distribuzione Beta, influenzando direttamente la sua forma e il suo comportamento. È essenziale che entrambi questi parametri siano positivi.\n\n\n32.8.3 Intuizione e Collegamento con la Distribuzione Binomiale\nLa distribuzione Beta può essere meglio compresa quando la si osserva in relazione con la distribuzione binomiale. Mentre la distribuzione binomiale modella il numero di successi in una serie di prove, la distribuzione Beta si focalizza sulla probabilità di successo in queste prove.\nNel contesto della distribuzione binomiale, la probabilità di successo è un parametro fisso; nella distribuzione Beta, questa probabilità diventa una variabile aleatoria.\n\n\n32.8.4 Interpretazione dei Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) possono essere interpretati come rappresentanti il numero di successi e insuccessi, rispettivamente. Questa interpretazione è analoga ai termini \\(n\\) e \\(n-x\\) nella distribuzione binomiale.\nLa scelta di \\(\\alpha\\) e \\(\\beta\\) dipende dall’aspettativa iniziale della probabilità di successo: - Se si presume un’alta probabilità di successo (ad esempio, 90%), si potrebbe scegliere \\(\\alpha = 90\\) e \\(\\beta = 10\\). - Al contrario, per una bassa aspettativa di successo, si potrebbe impostare \\(\\alpha = 10\\) e \\(\\beta = 90\\).\nUn aumento di \\(\\alpha\\) (successi) sposta la distribuzione verso destra, mentre un aumento di \\(\\beta\\) (insuccessi) la sposta verso sinistra. Inoltre, se sia \\(\\alpha\\) sia \\(\\beta\\) aumentano, la distribuzione diventa più stretta, indicando una maggiore certezza.\nQuesta interpretazione consente di utilizzare la distribuzione Beta per esprimere le nostre credenze a priori riguardo a una sequenza di prove di Bernoulli, dove il rapporto tra successi e tentativi totali è dato da:\n\\[\n\\frac{\\text{Numero di successi}}{\\text{Numero di successi} + \\text{Numero di insuccessi}} = \\frac{\\alpha}{\\alpha + \\beta}\\notag\\,.\n\\]\nAl variare di \\(\\alpha\\) e \\(\\beta\\) si ottengono molte distribuzioni di forma diversa; un’illustrazione è fornita dalla seguente GIF animata.\nLa figura seguente mostra la distribuzione \\(Beta(x \\mid \\alpha, \\beta)\\) per \\(\\alpha\\) = 0.5, 5.0, 1.0, 2.0, 2.0 e \\(\\beta\\) = 5, 1.0, 3.0, 2.0, 5.0.\n\n# Define the parameters\nx &lt;- seq(0, 1, length.out = 200)\nalphas &lt;- c(0.5, 5.0, 1.0, 2.0, 2.0)\nbetas &lt;- c(0.5, 1.0, 3.0, 2.0, 5.0)\n\n# Create a data frame for plotting\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dbeta(x, alphas[i], betas[i]),\n    label = paste0(\"α = \", alphas[i], \", β = \", betas[i])\n  )\n}))\n\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzioni Beta\"\n  ) +\n  ylim(0, 4.5) +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n  )\n#&gt; Warning: Removed 6 rows containing missing values or values outside the scale range\n#&gt; (`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n32.8.5 Costante di normalizzazione\nLa relazione \\(\\frac{1}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\) definisce il reciproco della funzione Beta di Eulero, \\(B(\\alpha, \\beta)\\), come una costante di normalizzazione. Qui, \\(\\Gamma(\\cdot)\\) denota la funzione Gamma di Eulero. Questa costante di normalizzazione garantisce che\n\\[\n\\int_0^1 \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} d\\theta = 1\\,,\n\\]\nper \\(\\alpha, \\beta &gt; 0\\). Questa integrazione conferma che \\(\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}\\), quando moltiplicata per la costante di normalizzazione, forma una densità di probabilità che si estende sull’intervallo \\([0,1]\\), con l’area sottesa dalla curva (l’integrale) uguale a 1.\nAd esempio, con \\(\\alpha = 3\\) e \\(\\beta = 9\\), possiamo calcolare il risultato integrando la funzione \\((p^{\\alpha - 1} \\cdot (1 - p)^{\\beta - 1})\\) su \\([0, 1]\\), usando la funzione integrate in R:\n\n# Definizione della funzione da integrare\nintegrand &lt;- function(p, a, b) {\n  p^(a - 1) * (1 - p)^(b - 1)\n}\n\n# Parametri\na &lt;- 3\nb &lt;- 9\n\n# Calcolo dell'integrale\nresult &lt;- integrate(integrand, lower = 0, upper = 1, a = a, b = b)\nresult$value  # Valore dell'integrale\n#&gt; [1] 0.002020202\n\nOtteniamo lo stesso risultato calcolando esplicitamente la funzione Beta di Eulero:\n\n# Calcolo usando la funzione Gamma\nresult_gamma &lt;- gamma(a) * gamma(b) / gamma(a + b)\nresult_gamma\n#&gt; [1] 0.002020202\n\nOppure utilizzando la funzione beta già disponibile in R:\n\n# Calcolo con la funzione beta\nresult_beta &lt;- beta(a, b)\nresult_beta\n#&gt; [1] 0.002020202\n\nQuesti approcci mostrano che i diversi metodi producono lo stesso valore per la funzione Beta di Eulero.\n\n\n32.8.6 Proprietà\nIl valore atteso, la moda e la varianza di una densità di probabilità Beta sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(\\theta) = \\frac{\\alpha}{\\alpha+\\beta}\\,,\n\\] (eq-beta-mean)\n\\[\nMo(\\theta) = \\frac{\\alpha-1}{\\alpha+\\beta-2}\\,,\n\\] (eq-beta-mode)\n\\[\n\\mathbb{V}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\\,.\n\\] (eq-beta-var)\nUsando le formule precedenti, possiamo definire una funzione beta_mean_mode_variance() in R per calcolare la media, la moda e la varianza di una distribuzione di probabilità Beta:\n\n# Funzione per calcolare media, moda e varianza della distribuzione Beta\nbeta_mean_mode_variance &lt;- function(alpha, beta) {\n  mean &lt;- alpha / (alpha + beta)\n  mode &lt;- ifelse(alpha &gt; 1 & beta &gt; 1, (alpha - 1) / (alpha + beta - 2), NA) # Moda definita solo per alpha, beta &gt; 1\n  variance &lt;- (alpha * beta) / ((alpha + beta)^2 * (alpha + beta + 1))\n  list(mean = mean, mode = mode, variance = variance)\n}\n\n# Esempio di utilizzo\nalpha &lt;- 7\nbeta &lt;- 3\nresult &lt;- beta_mean_mode_variance(alpha, beta)\n\n# Stampa dei risultati\ncat(sprintf(\"Mean: %.2f, Mode: %.2f, Variance: %.4f\\n\", result$mean, result$mode, result$variance))\n#&gt; Mean: 0.70, Mode: 0.75, Variance: 0.0191\n\n\n\n32.8.7 Risultati\nLa funzione calcola: - Media: \\(\\mu = \\frac{\\alpha}{\\alpha + \\beta}\\), - Moda: \\(\\frac{\\alpha - 1}{\\alpha + \\beta - 2}\\) (definita solo per \\(\\alpha &gt; 1\\) e \\(\\beta &gt; 1\\)), - Varianza: \\(\\frac{\\alpha \\cdot \\beta}{(\\alpha + \\beta)^2 \\cdot (\\alpha + \\beta + 1)}\\).\nSe \\(\\alpha\\) o \\(\\beta\\) sono inferiori o uguali a 1, la moda non è definita.\n\n\n32.8.8 Distribuzione a priori coniugata\nLa distribuzione Beta rappresenta una prior coniugata ottimale per una gamma di distribuzioni legate a eventi di successo e fallimento, quali le distribuzioni Bernoulli, Binomiale, Binomiale Negativa e Geometrica, nell’ambito dell’inferenza Bayesiana. Questa caratteristica di prior coniugata rende il calcolo della distribuzione a posteriori particolarmente efficiente, poiché permette di bypassare onerose computazioni numeriche tipicamente associate all’inferenza Bayesiana.\nPrendiamo, ad esempio, il caso in cui la distribuzione Beta, espressa come Beta(α, β), venga adottata come prior nel contesto di una distribuzione Binomiale. Questa scelta metodologica ci assicura che la distribuzione a posteriori manterrà la forma funzionale della distribuzione Beta. Ciò significa che, una volta raccolti i dati, l’aggiornamento a posteriori può essere eseguito semplicemente aggiungendo il numero di successi osservati (x) e il numero di fallimenti (n-x) ai parametri α e β del prior, rispettivamente. In tal modo, si ottiene una distribuzione a posteriori Beta con parametri aggiornati (α+x, β+n-x), senza la necessità di compiere la moltiplicazione tra la funzione di verosimiglianza e il prior.\n\n\n\n\n\n\nAvviso\n\n\n\nÈ importante prestare attenzione all’uso del termine “Beta” in questo contesto, poiché assume significati differenti a seconda del riferimento: - La distribuzione Beta, che descrive una distribuzione di probabilità continua. - La funzione Beta, una funzione matematica speciale. - Il parametro β, che insieme ad α, definisce i parametri specifici della distribuzione Beta.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "32.9 Distribuzione di Cauchy",
    "text": "32.9 Distribuzione di Cauchy\nLa distribuzione di Cauchy è un caso speciale della distribuzione di \\(t\\) di Student con 1 grado di libertà. È definita da una densità di probabilità che corrisponde alla seguente funzione, dipendente da due parametri \\(\\alpha\\) e \\(\\beta\\),\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{1}{\\pi \\beta \\left[1 + \\left( \\frac{x - \\alpha}{\\beta} \\right)^2\\right]}.\n\\tag{32.3}\\]\nIl grafico mostra alcune distribuzioni di Cauchy con \\(\\alpha\\) = 0., 0., 0., -2.0 e \\(\\beta\\) = .5, 1., 2., 1.0.\n\n# Definire i parametri\nx &lt;- seq(-5, 5, length.out = 500)\nalphas &lt;- c(0.0, 0.0, 0.0, -2.0)\nbetas &lt;- c(0.5, 1.0, 2.0, 1.0)\n\n# Creare un data frame per i risultati\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dcauchy(x, location = alphas[i], scale = betas[i]),\n    label = paste0(\"α = \", alphas[i], \", β = \", betas[i])\n  )\n}))\n\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzioni di Cauchy con diversi parametri\"\n  ) +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-gamma",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-gamma",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "32.10 Distribuzione Gamma",
    "text": "32.10 Distribuzione Gamma\nLa distribuzione Gamma è ampiamente utilizzata nella statistica bayesiana come distribuzione a priori per parametri che sono strettamente positivi, come tassi o varianze. È particolarmente utile nella modellazione di variabili che rappresentano tempi di attesa o qualsiasi altra quantità che può assumere solo valori positivi. La densità di probabilità Gamma gioca un ruolo fondamentale nella modellazione del tempo di attesa per l’occorrenza di un certo numero di eventi indipendenti e rari, rendendola adatta per processi di Poisson generalizzati.\nLa distribuzione Gamma può essere vista come una generalizzazione della distribuzione esponenziale. Più precisamente, la distribuzione esponenziale è un caso speciale della distribuzione Gamma. Se sommiamo \\(n\\) variabili casuali indipendenti, ciascuna delle quali segue una distribuzione esponenziale con parametro \\(\\lambda\\), il risultato segue una distribuzione Gamma con parametri \\(n\\) (numero di variabili sommate) e \\(\\lambda\\) (tasso esponenziale). Questo si formalizza come:\n\\[\n\\text{Gamma}(n, \\lambda) = \\sum_{i=1}^n \\text{Esponenziale}(\\lambda).\n\\]\nIn particolare, la distribuzione Gamma con parametro di forma 1, ovvero \\(\\text{Gamma}(1, \\lambda)\\), corrisponde esattamente a una distribuzione esponenziale con parametro \\(\\lambda\\), cioè:\n\\[\n\\text{Gamma}(1, \\lambda) = \\text{Esponenziale}(\\lambda).\n\\]\nLa distribuzione Gamma è anche legata alla distribuzione normale in alcuni contesti. Sebbene non vi sia una relazione diretta e semplice tra una distribuzione Gamma e una normale, un caso specifico è quando il parametro di forma \\(n\\) è molto grande (cioè \\(n \\to \\infty\\)). In questo caso, la distribuzione Gamma può essere approssimata da una distribuzione normale tramite il teorema del limite centrale. Più precisamente, quando \\(n\\) è grande, una Gamma di parametri \\(n\\) e \\(\\lambda\\) converge approssimativamente a una normale con media \\(n/\\lambda\\) e varianza \\(n/\\lambda^2\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#parametrizzazione",
    "href": "chapters/probability/12_cont_rv_distr.html#parametrizzazione",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "32.11 Parametrizzazione",
    "text": "32.11 Parametrizzazione\nLa distribuzione Gamma è caratterizzata da due parametri principali: \\(\\alpha\\) e \\(\\beta\\), noti rispettivamente come parametro di forma e parametro di tasso (o, alternativamente, si può usare \\(\\theta = \\frac{1}{\\beta}\\), il parametro di scala).\n\n32.11.1 Parametro di forma (\\(\\alpha\\))\nIl parametro di forma, \\(\\alpha\\), determina la forma generale della curva della distribuzione:\n\nSe \\(\\alpha = 1\\), la distribuzione Gamma si riduce a una distribuzione esponenziale, con la funzione di densità \\(f(x) = \\beta e^{-\\beta x}\\).\nSe \\(\\alpha &gt; 1\\), la distribuzione presenta un picco (modalità) attorno a \\((\\alpha - 1) \\cdot \\theta\\), indicando una distribuzione più concentrata attorno a un valore medio.\nSe \\(\\alpha &lt; 1\\), la distribuzione è inclinata verso destra, con una coda lunga che si estende verso valori più bassi, mostrando una maggiore probabilità di valori piccoli di \\(x\\).\n\nIl parametro \\(\\alpha\\) può essere interpretato come il numero di “eventi” che ci si aspetta si verifichino prima di raggiungere un certo tempo di attesa, in contesti di modelli di Poisson generalizzati. Ad esempio, se la distribuzione Gamma modella il tempo di attesa per l’arrivo di un certo numero di eventi, \\(\\alpha\\) indica il numero di eventi attesi.\nMan mano che \\(\\alpha\\) aumenta, la distribuzione si sposta verso destra e diventa più simmetrica. Per valori alti di \\(\\alpha\\), la distribuzione Gamma si avvicina a una distribuzione normale.\n\n\n32.11.2 Parametro di scala (\\(\\theta\\)) o tasso (\\(\\beta\\))\nIl parametro \\(\\theta\\) (o, alternativamente, \\(\\beta\\)) controlla la scala temporale o la larghezza della distribuzione:\n\nIl parametro di scala \\(\\theta\\) è inversamente proporzionale al parametro di tasso \\(\\beta\\). Un valore più grande di \\(\\theta\\) (o un valore più piccolo di \\(\\beta\\)) produce una curva più piatta, indicando una maggiore variabilità (dispersione) nel tempo di attesa.\nUn valore più piccolo di \\(\\theta\\) (o più grande di \\(\\beta\\)) rende la curva più appuntita, indicando una minore variabilità.\n\nNel contesto del tempo di attesa, \\(\\theta\\) agisce come un fattore di scala: un valore grande di \\(\\theta\\) indica un periodo di tempo più lungo tra gli eventi, mentre un valore piccolo di \\(\\theta\\) indica un periodo di tempo più breve.\n\n\n32.11.3 Formula della funzione di densità di probabilità\nLa funzione di densità di probabilità (PDF) della distribuzione Gamma è data da:\n\\[\nf(x \\mid \\alpha, \\theta) = \\frac{x^{\\alpha-1} e^{-\\frac{x}{\\theta}}}{\\theta^\\alpha \\Gamma(\\alpha)},\n\\]\ndove:\n\n\\(x\\) è la variabile casuale continua, con \\(x &gt; 0\\),\n\\(\\alpha\\) è il parametro di forma,\n\\(\\theta\\) è il parametro di scala (alternativamente si può usare \\(\\beta = \\frac{1}{\\theta}\\), il parametro di tasso),\n\\(\\Gamma(\\alpha)\\) è la funzione Gamma di Eulero, che generalizza il fattoriale per numeri reali e complessi. Per numeri interi \\(n\\), si ha \\(\\Gamma(n) = (n-1)!\\), ma per argomenti generali \\(\\alpha\\), la funzione Gamma è definita come:\n\n\\[\n\\Gamma(\\alpha) = \\int_0^\\infty x^{\\alpha-1} e^{-x} dx.\n\\]\n\n\n32.11.4 Media e varianza della distribuzione Gamma\nLe espressioni per la media e la varianza della distribuzione Gamma in funzione di \\(\\alpha\\) e \\(\\theta\\) (o \\(\\beta\\)) sono:\n\nMedia (\\(\\mu\\)):\n\n\\[\n\\mu = \\alpha \\cdot \\theta = \\frac{\\alpha}{\\beta}.\n\\]\n\nVarianza (\\(\\sigma^2\\)): \\[\n\\sigma^2 = \\alpha \\cdot \\theta^2 = \\frac{\\alpha}{\\beta^2}.\n\\]\n\nIn sintesi, il parametro di forma \\(\\alpha\\) controlla la forma generale della distribuzione, mentre il parametro di scala \\(\\theta\\) (o tasso \\(\\beta\\)) regola la dispersione o variabilità. Questa parametrizzazione è largamente utilizzata, in particolare nella statistica bayesiana, dove la distribuzione Gamma può servire da distribuzione a priori per parametri positivi, come varianze o tassi di processi stocastici.\nPer esempio, qui è riportata la distribuzione Gamma di parametri \\(\\alpha\\) = 3 e \\(\\beta\\) = 5/3.\n\n\n32.11.5 Calcolo della Media e della Deviazione Standard per la Distribuzione Gamma\nLa distribuzione Gamma è definita dai parametri \\(\\alpha\\) (shape) e \\(\\beta\\) (rate). La media e la deviazione standard della distribuzione possono essere calcolate come segue:\n\nMedia: \\(\\mu = \\frac{\\alpha}{\\beta}\\)\nDeviazione Standard: \\(\\sigma = \\sqrt{\\frac{\\alpha}{\\beta^2}}\\)\n\n\n32.11.5.1 Calcolo in R\n\n# Parametri della distribuzione Gamma\nalpha &lt;- 3\nbeta &lt;- 5 / 3\n\n# Calcolo della media\nmean &lt;- alpha / beta\ncat(\"Mean:\", mean, \"\\n\")\n#&gt; Mean: 1.8\n\n# Calcolo della deviazione standard\nsigma &lt;- sqrt(alpha / beta^2)\ncat(\"Standard Deviation:\", sigma, \"\\n\")\n#&gt; Standard Deviation: 1.03923\n\n\n\n\n32.11.6 Generazione di Dati dalla Distribuzione Gamma e Visualizzazione\n\n32.11.6.1 Generazione di dati\nIn R, possiamo utilizzare la funzione rgamma() per generare dati da una distribuzione Gamma specificando i parametri shape (\\(\\alpha\\)) e rate (\\(\\beta\\)).\n\n\n32.11.6.2 Plot della Distribuzione\n\n# Generazione di dati\nset.seed(123)  # Per riproducibilità\ndata &lt;- rgamma(100000, shape = alpha, rate = beta)\n\n# Creazione di un data frame per ggplot\ndf &lt;- data.frame(values = data)\n\n# Istogramma dei dati generati\nggplot(df, aes(x = values)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"green\", alpha = 0.6) +\n  stat_function(fun = function(x) dgamma(x, shape = alpha, rate = beta),\n                color = \"red\", size = 1, linetype = \"solid\") +\n  labs(\n    x = \"Valore\",\n    y = \"Densità di probabilità\",\n    title = \"Distribuzione Gamma con α=3 e β=5/3\"\n  ) \n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nSpiegazione del Codice.\n\nCalcolo della media e della deviazione standard:\n\nLa media è calcolata come il rapporto tra i parametri \\(\\alpha\\) e \\(\\beta\\).\nLa deviazione standard è la radice quadrata del rapporto tra \\(\\alpha\\) e \\(\\beta^2\\).\n\nGenerazione dei dati:\n\nrgamma(n, shape, rate) genera \\(n\\) osservazioni dalla distribuzione Gamma specificata.\n\nVisualizzazione:\n\nL’istogramma rappresenta i dati generati.\nLa funzione dgamma(x, shape, rate) calcola la densità teorica, che viene tracciata sopra l’istogramma per confrontare i dati simulati con la distribuzione teorica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale-1",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale-1",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "32.12 Distribuzione Esponenziale",
    "text": "32.12 Distribuzione Esponenziale\nLa distribuzione esponenziale è una distribuzione di probabilità continua che descrive la “durata di vita” di un fenomeno che non invecchia (ossia la distribuzione esponenziale è priva di memoria).\nLa distribuzione esponenziale (o di Laplace) può anche essere ricavata come la distribuzione di probabilità di una variabile aleatoria definita come somma dei quadrati di due variabili aleatorie normali standardizzate (ossia con valore atteso zero e varianza unitaria); dunque è riconducibile a un caso particolare di distribuzione del chi-quadro, essendo, quest’ultima, la distribuzione di probabilità della variabile aleatoria costruita come la somma dei quadrati di \\(n\\) variabili aleatorie indipendenti normali e standardizzate.\nLa distribuzione esponenziale con parametro \\({\\displaystyle \\lambda &gt;0}\\), ha funzione di densità di probabilità:\n\\[\n{\\displaystyle f(x;\\lambda )={\\begin{cases}\\lambda e^{-\\lambda x}&x&gt;0,\\\\0&x\\leq 0.\\end{cases}}}.\n\\]\nUna variabile aleatoria con distribuzione esponenziale di parametro \\({\\displaystyle \\lambda }\\) ha\n\nvalore atteso \\({\\displaystyle E[X]=1/\\lambda }\\),\nvarianza \\({\\displaystyle {\\text{Var}}(X)=1/\\lambda ^{2}}.\\)\n\nPer fare un esempio, consideriamo il punteggio totale della scala psicologica di Kessler (K6), una misura standardizzata utilizzata dal NHIS per lo screening del disagio psicologico. La K6 include sei item relativi alla sintomatologia depressiva e ansiosa e valuta il disagio psicologico aspecifico degli ultimi 30 giorni. Gli item sono valutati su una scala Likert a 5 punti, che va da “mai” (=0) a “sempre” (=4). I punteggi totali variano da 0 a 24. Secondo Tomitaka et al. (2019), il punteggio totale della K6 segue una distribuzione esponenziale, con punteggi di cut-off per disagio psicologico moderato e grave corrispondenti a punteggi di 5 e 13, rispettivamente. Dallo studio emerge che il punteggio medio del totale della K6 nella popolazione americana è di 2.5. La corrispondente distribuzione esponenziale è rappresentata di seguito.\n\n# Parametri della distribuzione Esponenziale\nmean &lt;- 2.5\nlambda &lt;- 1 / mean  # Lambda è l'inverso della media\n\n# Creazione del vettore x\nx &lt;- seq(0.001, 22, length.out = 100)\n\n# Calcolo della densità\npdf &lt;- dexp(x, rate = lambda)\n\n# Creazione del data frame per ggplot\ndf &lt;- data.frame(x = x, pdf = pdf)\n\n# Tracciamento del grafico\nlibrary(ggplot2)\nggplot(df, aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\", size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzione Esponenziale\"\n  ) +\n  annotate(\"text\", x = 10, y = max(pdf)/2, label = paste0(\"λ = \", round(lambda, 2)), size = 5, color = \"blue\")",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#riflessioni-conclusive-in-r",
    "href": "chapters/probability/12_cont_rv_distr.html#riflessioni-conclusive-in-r",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "32.13 Riflessioni Conclusive in R",
    "text": "32.13 Riflessioni Conclusive in R\nLa statistica bayesiana utilizza le distribuzioni di probabilità per la stima dei parametri e dell’incertezza. Possiamo considerare le distribuzioni di probabilità come “mattoncini” con cui costruire modelli statistici, dai più semplici ai più complessi. R offre strumenti per generare campioni casuali e calcolare densità, probabilità cumulate, e quantili per molte distribuzioni di probabilità.\n\n32.13.1 Generazione di Campioni\nIn R, possiamo generare campioni da diverse distribuzioni utilizzando le funzioni rnorm, runif, rt, rbeta, e rgamma. Ad esempio:\nDistribuzione Normale:\nset.seed(42)  # Per garantire la riproducibilità\nmedia &lt;- 0\ndeviazione_standard &lt;- 1\ncampione_normale &lt;- rnorm(100, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\na &lt;- 0\nb &lt;- 10\ncampione_uniforme &lt;- runif(100, min = a, max = b)\nDistribuzione t di Student:\ngradi_libertà &lt;- 10\ncampione_t &lt;- rt(100, df = gradi_libertà)\nDistribuzione Beta:\nalpha &lt;- 2\nbeta_param &lt;- 5\ncampione_beta &lt;- rbeta(100, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nforma &lt;- 2\nscala &lt;- 1\ncampione_gamma &lt;- rgamma(100, shape = forma, rate = 1 / scala)\n\n\n32.13.1.1 Calcolo della Densità\nPossiamo calcolare la densità utilizzando le funzioni dnorm, dunif, dt, dbeta, e dgamma. Ad esempio:\nDistribuzione Normale:\nx &lt;- seq(media - 4 * deviazione_standard, media + 4 * deviazione_standard, length.out = 100)\npdf_normale &lt;- dnorm(x, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\nx &lt;- seq(a, b, length.out = 100)\npdf_uniforme &lt;- dunif(x, min = a, max = b)\nDistribuzione t di Student:\nx &lt;- seq(-5, 5, length.out = 100)\npdf_t &lt;- dt(x, df = gradi_libertà)\nDistribuzione Beta:\nx &lt;- seq(0, 1, length.out = 100)\npdf_beta &lt;- dbeta(x, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nx &lt;- seq(0, 10, length.out = 100)\npdf_gamma &lt;- dgamma(x, shape = forma, rate = 1 / scala)\n\n\n\n32.13.1.2 Calcolo dei Quantili\nI quantili si calcolano con le funzioni qnorm, qunif, qt, qbeta, e qgamma. Ad esempio:\nDistribuzione Normale:\nprobabilità &lt;- 0.5\nquantile_normale &lt;- qnorm(probabilità, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\nquantile_uniforme &lt;- qunif(probabilità, min = a, max = b)\nDistribuzione t di Student:\nquantile_t &lt;- qt(probabilità, df = gradi_libertà)\nDistribuzione Beta:\nquantile_beta &lt;- qbeta(probabilità, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nquantile_gamma &lt;- qgamma(probabilità, shape = forma, rate = 1 / scala)\n\n\n\n32.13.1.3 Calcolo delle Probabilità Cumulate\nLe probabilità cumulate si calcolano con le funzioni pnorm, punif, pt, pbeta, e pgamma. Ad esempio:\nDistribuzione Normale:\nquantile &lt;- 0\nprobabilità_normale &lt;- pnorm(quantile, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\nprobabilità_uniforme &lt;- punif(quantile, min = a, max = b)\nDistribuzione t di Student:\nprobabilità_t &lt;- pt(quantile, df = gradi_libertà)\nDistribuzione Beta:\nprobabilità_beta &lt;- pbeta(quantile, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nprobabilità_gamma &lt;- pgamma(quantile, shape = forma, rate = 1 / scala)\n\nCon questi strumenti, R consente di generare, visualizzare e analizzare campioni da una vasta gamma di distribuzioni di probabilità, fornendo un potente supporto all’inferenza bayesiana e alla modellazione statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#esercizi",
    "href": "chapters/probability/12_cont_rv_distr.html#esercizi",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "32.14 Esercizi",
    "text": "32.14 Esercizi\n\nEsercizio 32.1 Per ciascuna delle distribuzioni di massa di probabilità discusse, utilizza R per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l’intervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media più una deviazione standard, calcolare la probabilità che la variabile aleatoria assuma un valore minore o uguale a questo valore.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/12_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.0       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#bibliografia",
    "href": "chapters/probability/12_cont_rv_distr.html#bibliografia",
    "title": "32  Distribuzioni di v.c. continue",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nTomitaka, S., Kawasaki, Y., Ide, K., Akutagawa, M., Ono, Y., & Furukawa, T. A. (2019). Distribution of psychological distress is stable in recent decades and follows an exponential pattern in the US population. Scientific reports, 9(1), 11982.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_qq_plot.html",
    "href": "chapters/probability/13_qq_plot.html",
    "title": "33  Diagramma quantile-quantile",
    "section": "",
    "text": "33.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nL’obiettivo di questo breve capitolo è spiegare il diagramma quantile-quantile (QQ-plot) e illustrarne l’utilità come strumento per analizzare visivamente la conformità di un dataset a una distribuzione teorica, in particolare alla distribuzione normale. Il QQ-plot è una tecnica essenziale per chi lavora con dati che si presume seguano una distribuzione specifica, e rappresenta un passaggio cruciale in molte analisi statistiche, soprattutto per verificare l’assunto di normalità.\nNelle analisi statistiche, si parte spesso dall’assunzione che i dati seguano una distribuzione specifica, come la distribuzione normale. Tuttavia, questa ipotesi deve essere verificata. Un QQ-plot permette di:\nIl QQ-plot è costruito tracciando i quantili del campione contro i quantili teorici di una distribuzione di riferimento. L’interpretazione è piuttosto semplice:\nIl QQ-plot è particolarmente utile nelle seguenti situazioni:\nNel capitolo che segue, costruiremo e analizzeremo QQ-plot per tre casi tipici:\nSimuleremo i dati, li ordineremo, calcoleremo manualmente i quantili teorici e infine utilizzeremo librerie specializzate per replicare e confrontare i risultati. Questo approccio pratico ci permetterà di comprendere a fondo l’utilità e il funzionamento del QQ-plot.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Diagramma quantile-quantile</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_qq_plot.html#introduzione",
    "href": "chapters/probability/13_qq_plot.html#introduzione",
    "title": "33  Diagramma quantile-quantile",
    "section": "",
    "text": "Valutare graficamente la normalità dei dati: Se i punti nel diagramma seguono approssimativamente una linea retta, i dati possono essere considerati normalmente distribuiti. In caso contrario, il QQ-plot rivela deviazioni dalla normalità, come code pesanti o asimmetrie.\nIdentificare outlier: Gli outlier nei dati saranno visibili come punti che si discostano significativamente dalla linea retta del QQ-plot.\nConfrontare distribuzioni: Il QQ-plot non si limita solo alla distribuzione normale, ma può essere utilizzato per confrontare la distribuzione del campione con qualsiasi distribuzione teorica, facilitando l’analisi di dati con forme di distribuzione complesse.\n\n\n\nSe il campione segue la distribuzione teorica, i punti nel QQ-plot si allineano lungo una linea retta di pendenza 1 (e intercetta 0 nel caso di distribuzione normale standardizzata).\nLa deviazione dalla linea retta indica differenze nella distribuzione del campione rispetto alla distribuzione teorica:\n\nIntercetta diversa da 0: indica che la media del campione differisce dalla media della distribuzione teorica.\nPendenza diversa da 1: indica una differenza nella varianza tra il campione e la distribuzione teorica.\nCurve: indicano deviazioni sistematiche, come code pesanti o distribuzioni asimmetriche.\n\n\n\n\nPre-analisi statistica: Prima di applicare tecniche come la regressione lineare, dove l’assunzione di normalità è cruciale, un QQ-plot permette di diagnosticare la normalità dei residui.\nVerifica della bontà del fit: Quando si utilizza un modello per stimare la distribuzione di un dataset, il QQ-plot permette di confrontare visivamente quanto il modello si adatti bene ai dati osservati.\nIdentificazione di dati anomali: Un QQ-plot può evidenziare valori atipici, che potrebbero influenzare negativamente i risultati dell’analisi, permettendo di valutare la necessità di una trasformazione dei dati o di un trattamento degli outlier.\n\n\n\nCampione con stessa media e varianza della distribuzione teorica.\nCampione con media diversa ma stessa varianza.\nCampione con media e varianza diverse.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Diagramma quantile-quantile</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_qq_plot.html#comprendere-e-costruire-un-qq-plot-distribuzione-normale",
    "href": "chapters/probability/13_qq_plot.html#comprendere-e-costruire-un-qq-plot-distribuzione-normale",
    "title": "33  Diagramma quantile-quantile",
    "section": "33.2 Comprendere e Costruire un QQ-Plot (Distribuzione Normale)",
    "text": "33.2 Comprendere e Costruire un QQ-Plot (Distribuzione Normale)\nUn QQ-plot (Quantile-Quantile plot) è uno strumento grafico utilizzato per confrontare la distribuzione di un campione con una distribuzione teorica, spesso la distribuzione normale. Il QQ-plot aiuta a visualizzare se un dataset segue una distribuzione specifica, tracciando i quantili del campione contro i quantili della distribuzione teorica.\n\n33.2.1 Passi per Costruire un QQ-Plot\n\nOrdinare i Dati: Disporre i dati del campione in ordine crescente.\nDeterminare i Quantili Teorici: Per una distribuzione normale, i quantili corrispondono all’inverso della funzione di distribuzione cumulativa (CDF) della distribuzione normale.\nConfrontare i Quantili: Tracciare i quantili del campione rispetto ai quantili della distribuzione teorica. Se il campione proviene dalla distribuzione teorica, i punti dovrebbero trovarsi approssimativamente su una linea retta.\n\n\n\n33.2.2 Caso 1: Campione con Stessa Media e Varianza della Distribuzione Normale\nSupponiamo che il campione provenga da una distribuzione normale \\(N(\\mu = 0, \\sigma^2 = 1)\\), esattamente come la distribuzione teorica.\n\n33.2.2.1 Simulazione dei Dati\nIniziamo simulando un piccolo dataset da \\(N(0, 1)\\):\n\n# Generiamo 20 punti dati da N(0, 1)\nset.seed(42)  # Per garantire la riproducibilità\ndati_campione &lt;- rnorm(20, mean = 0, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato &lt;- sort(dati_campione)\n\n# Calcoliamo i quantili teorici da N(0, 1)\nquantili_teorici &lt;- qnorm((seq(1, 20) - 0.5) / 20)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Stessa Media e Varianza\", pch = 16)\nabline(0, 1, col = \"red\", lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\n\nIn questo caso, i punti del QQ-plot dovrebbero allinearsi alla linea rossa, indicando che la distribuzione del campione corrisponde a quella teorica.\n\n\n\n\n33.2.3 Caso 2: Campione con Media Diversa (Intercetta ≠ 0)\nSimuliamo un campione da \\(N(2, 1)\\), con una media diversa ma la stessa varianza:\n\n# Generiamo 20 punti dati da N(2, 1)\ndati_campione_media_spostata &lt;- rnorm(20, mean = 2, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_media_spostata &lt;- sort(dati_campione_media_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_media_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media Diversa (Intercetta ≠ 0)\", pch = 16)\nabline(0, 1, col = \"red\", lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\n\nIn questo caso, i punti dovrebbero seguire una linea retta ma essere spostati verticalmente, indicando una media diversa (intercetta ≠ 0).\n\n\n\n33.2.4 Caso 3: Campione con Media e Varianza Diverse (Pendenza ≠ 1)\nSimuliamo un campione da \\(N(2, 2^2)\\), con una media e una varianza diverse:\n\n# Generiamo 20 punti dati da N(2, 2^2)\ndati_campione_varianza_spostata &lt;- rnorm(20, mean = 2, sd = 2)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_varianza_spostata &lt;- sort(dati_campione_varianza_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_varianza_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media e Varianza Diverse (Pendenza ≠ 1)\", pch = 16)\nabline(0, 1, col = \"red\", lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\n\nIn questo caso, i punti si discosteranno sia verticalmente (per la media diversa) sia rispetto alla pendenza della linea (per la varianza diversa).\n\n\n\n33.2.5 Calcolo Manuale del QQ-Plot\nPer ciascun caso sopra, i passaggi sono i seguenti:\n\nOrdinamento dei dati del campione: Questo fornisce i quantili del campione.\nCalcolo dei quantili teorici: Utilizzando la funzione inversa della CDF per la distribuzione normale.\n\nEsempio in R:\n\n# Calcolo manuale dei quantili teorici\nquantili_teorici_manuali &lt;- function(n) {\n  sapply(1:n, function(i) qnorm((i - 0.5) / n))\n}\n\nn &lt;- length(dati_campione)\nquantili_teorici_calcolati &lt;- quantili_teorici_manuali(n)\nquantili_teorici_calcolati\n#&gt;  [1] -1.95996398 -1.43953147 -1.15034938 -0.93458929 -0.75541503 -0.59776013\n#&gt;  [7] -0.45376219 -0.31863936 -0.18911843 -0.06270678  0.06270678  0.18911843\n#&gt; [13]  0.31863936  0.45376219  0.59776013  0.75541503  0.93458929  1.15034938\n#&gt; [19]  1.43953147  1.95996398\n\n\n\n\n33.2.6 Utilizzo di Funzioni Specializzate\nIn R, il pacchetto base offre la funzione qqnorm() per generare QQ-plot. Ad esempio:\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(dati_campione, main = \"QQ-Plot: Stessa Media e Varianza\")\nqqline(dati_campione, col = \"red\", lwd = 2)  # Linea di riferimento\n\n\n\n\n\n\n\n\nPossiamo ripetere lo stesso per i campioni con media e varianza spostate.\n\nQuesto approccio fornisce un’analisi completa della corrispondenza tra distribuzioni teoriche e campioni simulati utilizzando QQ-plot.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Diagramma quantile-quantile</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_qq_plot.html#conclusione",
    "href": "chapters/probability/13_qq_plot.html#conclusione",
    "title": "33  Diagramma quantile-quantile",
    "section": "33.3 Conclusione",
    "text": "33.3 Conclusione\nQuesto tutorial mostra come costruire manualmente un QQ-plot e interpretarlo in diversi casi che coinvolgono variazioni nella media e nella varianza del campione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Diagramma quantile-quantile</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_qq_plot.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/13_qq_plot.html#informazioni-sullambiente-di-sviluppo",
    "title": "33  Diagramma quantile-quantile",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Diagramma quantile-quantile</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html",
    "href": "chapters/probability/14_likelihood.html",
    "title": "34  La verosimiglianza",
    "section": "",
    "text": "34.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nI ricercatori utilizzano modelli con diverse strutture funzionali per descrivere e prevedere il comportamento dei dati. La scelta del modello più adatto si basa sul confronto tra le previsioni teoriche e i dati osservati: il modello che produce previsioni più vicine ai dati osservati viene considerato il migliore per rappresentare il fenomeno studiato. In questo processo, la funzione di verosimiglianza svolge un ruolo centrale, quantificando la probabilità che i dati osservati siano compatibili con un modello specifico e i suoi parametri.\nLa funzione di verosimiglianza rappresenta il meccanismo generativo dei dati, collegando i parametri del modello alle osservazioni empiriche. Tuttavia, essa non costituisce da sola un modello scientifico completo. Un modello scientifico include infatti altri elementi, come i priori (in un approccio bayesiano), che rappresentano le ipotesi iniziali sui parametri prima dell’osservazione dei dati, e la modellazione dell’errore di misurazione, che tiene conto delle imperfezioni nei dati raccolti.\nIn un approccio bayesiano, i priori si combinano con la verosimiglianza per generare la distribuzione a posteriori, che aggiorna le conoscenze sui parametri alla luce dei dati osservati. Questo passaggio è cruciale per il confronto tra modelli, poiché i priori possono influenzare significativamente le conclusioni.\nUn modello scientifico può anche includere la modellazione dell’errore di misurazione per spiegare le discrepanze tra i dati osservati e il processo reale. Questo aspetto è fondamentale per garantire che il modello sia in grado di catturare sia le osservazioni che le loro imprecisioni.\nIn sintesi, la funzione di verosimiglianza descrive come i dati potrebbero essere generati da un modello dato un insieme di parametri, ma un modello scientifico completo include ulteriori componenti, come i priori e la modellazione dell’errore, per rendere la rappresentazione del fenomeno più accurata. Questo capitolo si propone di approfondire il concetto di verosimiglianza e il suo ruolo nell’inferenza statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "href": "chapters/probability/14_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "title": "34  La verosimiglianza",
    "section": "34.2 Il Principio della Verosimiglianza e la sua Formalizzazione",
    "text": "34.2 Il Principio della Verosimiglianza e la sua Formalizzazione\nLa funzione di verosimiglianza è strettamente collegata alla funzione di densità (o massa) di probabilità, ma i due concetti hanno interpretazioni distinte:\n\nLa funzione di densità di probabilità descrive la probabilità di osservare un determinato insieme di dati, assumendo che i parametri siano noti e fissi.\nLa funzione di verosimiglianza considera i dati osservati come fissi e varia i parametri, valutando quanto ciascun valore dei parametri spieghi i dati.\n\nLa relazione tra queste due funzioni può essere formalizzata come segue:\n\\[\nL(\\theta \\mid y) \\propto p(y \\mid \\theta),\n\\]\ndove \\(L(\\theta \\mid y)\\) è la verosimiglianza dei parametri \\(\\theta\\) dati i dati \\(y\\), e \\(p(y \\mid \\theta)\\) rappresenta la probabilità di osservare i dati \\(y\\) dato un certo \\(\\theta\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#verosimiglianza-binomiale",
    "href": "chapters/probability/14_likelihood.html#verosimiglianza-binomiale",
    "title": "34  La verosimiglianza",
    "section": "34.3 Verosimiglianza Binomiale",
    "text": "34.3 Verosimiglianza Binomiale\nConsideriamo un esempio pratico: il lancio di una moneta. Supponiamo di osservare 23 teste su 30 lanci. La probabilità di osservare esattamente questo risultato, data una probabilità di successo \\(\\theta\\), può essere calcolata utilizzando la funzione di massa della distribuzione binomiale:\n\\[\nP(Y = y) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove:\n\n\\(n\\) è il numero totale di lanci,\n\\(y\\) è il numero di successi osservati,\n\\(\\theta\\) è la probabilità di successo per ogni lancio.\n\nLa funzione di verosimiglianza, invece, si concentra sull’identificazione dei valori di \\(\\theta\\) che meglio spiegano i dati osservati. Per la distribuzione binomiale, la funzione di verosimiglianza si scrive come:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^y (1 - \\theta)^{n - y}.\n\\]\nQui, il coefficiente binomiale \\(\\binom{n}{y}\\) può essere omesso perché non dipende da \\(\\theta\\) e quindi non influisce sulla stima del parametro.\n\n34.3.1 Verosimiglianza per il Lancio di una Moneta\nSupponiamo che:\n\n\\(n = 30\\) (numero di lanci),\n\\(y = 23\\) (numero di teste osservate).\n\nLa funzione di verosimiglianza diventa:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^{23} (1 - \\theta)^7.\n\\]\nQuesto ci permette di calcolare la verosimiglianza per diversi valori di \\(\\theta\\), determinando quale valore rende i dati osservati più plausibili. Ad esempio, possiamo simulare 100 valori equidistanti di \\(\\theta\\) nell’intervallo ([0, 1]) e calcolare la funzione di verosimiglianza per ciascun valore.\nIn R, possiamo calcolare la funzione di verosimiglianza per \\(n = 30\\), \\(y = 23\\), e una griglia di valori di \\(\\theta\\) come segue:\n\n# Parametri\nn &lt;- 30\ny &lt;- 23\n\n# Definizione dei valori di theta\ntheta &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Visualizzazione della funzione di verosimiglianza\nggplot(\n  data.frame(theta, likelihood), \n  aes(x = theta, y = likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Verosimiglianza\",\n    x = \"Valore di θ\",\n    y = \"Verosimiglianza\"\n  ) \n\n\n\n\n\n\n\n\n\n\n34.3.2 Interpretazione della Verosimiglianza\n\nValore di \\(\\theta\\): La funzione di verosimiglianza indica quali valori di \\(\\theta\\) sono più plausibili dati i dati osservati.\nStima di Massima Verosimiglianza (MLE): Il valore di \\(\\theta\\) che massimizza la funzione di verosimiglianza è detto stima di massima verosimiglianza. Nel nostro esempio, possiamo individuare questo valore esplorando numericamente i punti di massimo della curva.\n\nIn pratica, per identificare numericamente il valore ottimale di \\(\\theta\\), si può utilizzare un approccio computazionale che identifica il massimo della verosimiglianza.\n\n# Calcolo delle probabilità binomiali\nl &lt;- dbinom(y, size = n, prob = theta)\n\n# Individuazione dell'indice massimo\nmax_index &lt;- which.max(l)\n\n# Recupero del valore corrispondente di theta\ntheta[max_index]\n#&gt; [1] 0.7676768\n\nSpiegazione:\n\ndbinom(y, size = n, prob = theta) calcola la probabilità binomiale per ogni valore di theta.\nwhich.max(l) restituisce l’indice del valore massimo nella distribuzione di probabilità calcolata.\ntheta[max_index] seleziona il valore di theta corrispondente all’indice massimo.\n\nQuesto approccio illustra come la funzione di verosimiglianza aiuti a stimare parametri incogniti e a valutare la plausibilità relativa di diversi modelli statistici, basandosi esclusivamente sui dati osservati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#la-funzione-di-log-verosimiglianza",
    "href": "chapters/probability/14_likelihood.html#la-funzione-di-log-verosimiglianza",
    "title": "34  La verosimiglianza",
    "section": "34.4 La Funzione di Log-Verosimiglianza",
    "text": "34.4 La Funzione di Log-Verosimiglianza\nLa log-verosimiglianza è il logaritmo naturale della funzione di verosimiglianza:\n\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta \\mid y).\n\\]\nQuesta trasformazione è utile per semplificare i calcoli e migliorare la stabilità numerica, specialmente con dataset di grandi dimensioni.\nEsempio grafico per i valori di log-verosimiglianza:\n\n# Parametri\nn &lt;- 30\nr &lt;- 23\n\n# Genera la sequenza per theta\ntheta &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della log-verosimiglianza\nlog_likelihood &lt;- dbinom(r, size = n, prob = theta, log = TRUE)\n\n# Creazione del grafico\nplot(\n  theta, log_likelihood, type = \"l\",\n  main = \"Funzione di log-verosimiglianza\",\n  xlab = \"Valore della variabile casuale theta [0, 1]\",\n  ylab = \"Log-verosimiglianza\"\n)\n\n\n\n\n\n\n\n\nIl massimo della log-verosimiglianza replica il risultato trovato in precedenza con la funzione di verosimiglianza.\n\n# Calcolo della log-verosimiglianza per ogni valore di theta\nlog_likelihood &lt;- dbinom(r, size = n, prob = theta, log = TRUE)\n\n# Trova l'indice del valore massimo\nmax_index &lt;- which.max(log_likelihood)\n\n# Valore di theta corrispondente al massimo\ntheta[max_index]\n#&gt; [1] 0.7676768",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#verosimiglianza-congiunta",
    "href": "chapters/probability/14_likelihood.html#verosimiglianza-congiunta",
    "title": "34  La verosimiglianza",
    "section": "34.5 Verosimiglianza Congiunta",
    "text": "34.5 Verosimiglianza Congiunta\nNell’inferenza statistica basata sulla verosimiglianza, è comune incontrare situazioni in cui si dispone di più osservazioni indipendenti, tutte generate dallo stesso processo probabilistico. Ad esempio, raccogliamo un insieme di dati $ Y = [y_1, y_2, , y_n] $, dove ciascun valore è osservato indipendentemente e segue la stessa distribuzione binomiale. Questo scenario, noto come condizione di indipendenza e identica distribuzione (IID), è frequente nelle applicazioni pratiche.\n\n34.5.1 Calcolo della Verosimiglianza Congiunta\nPer considerare congiuntamente tutte le osservazioni, calcoliamo la probabilità congiunta di osservare $ y_1, y_2, , y_n $, data una comune probabilità di successo \\(\\theta\\). Grazie all’indipendenza delle osservazioni, questa probabilità si esprime come il prodotto delle probabilità individuali:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\theta) = \\prod_{i=1}^{n} p(y_i \\mid \\theta) = \\prod_{i=1}^{n} \\text{Binomiale}(y_i \\mid \\theta).\n\\]\nLa verosimiglianza congiunta è quindi:\n\\[\n\\mathcal{L}(\\theta \\mid Y) = \\prod_{i=1}^{n} \\mathcal{L}(\\theta \\mid y_i) = \\prod_{i=1}^{n} p(y_i \\mid \\theta).\n\\]\nQuesta funzione misura la plausibilità complessiva del parametro \\(\\theta\\) rispetto all’intero insieme di dati \\(Y\\). Il valore di \\(\\theta\\) che massimizza la verosimiglianza congiunta è noto come stimatore di massima verosimiglianza (MLE) e rappresenta il parametro che rende i dati osservati più plausibili.\n\n\n34.5.2 Log-Verosimiglianza Congiunta\nPoiché il prodotto delle probabilità può diventare numericamente instabile, lavoriamo spesso con la log-verosimiglianza, che trasforma il prodotto in una somma:\n\\[\n\\log \\mathcal{L}(\\theta \\mid Y) = \\sum_{i=1}^{n} \\log p(y_i \\mid \\theta).\n\\]\nIn un esempio pratico con dati raggruppati, consideriamo quattro gruppi di osservazioni binomiali indipendenti:\n\nGruppo 1: 30 prove con 23 successi\nGruppo 2: 28 prove con 20 successi\nGruppo 3: 40 prove con 29 successi\nGruppo 4: 36 prove con 29 successi\n\nLa log-verosimiglianza congiunta è:\n\\[\n\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right],\n\\]\ndove $ n_i $ e $ y_i $ rappresentano rispettivamente il numero di prove e di successi nel gruppo \\(i\\)-esimo.\n\n\n34.5.3 Implementazione in R\nPer calcolare la log-verosimiglianza congiunta, definiamo una funzione che accetta \\(\\theta\\) e i dati dei gruppi:\n\nlog_verosimiglianza_congiunta &lt;- function(theta, dati) {\n  # Evita valori problematici per log(0)\n  theta &lt;- pmax(pmin(theta, 1 - 1e-10), 1e-10)\n  \n  # Calcolo della log-verosimiglianza\n  log_likelihood &lt;- 0\n  for (gruppo in dati) {\n    n &lt;- gruppo[1]\n    y &lt;- gruppo[2]\n    log_likelihood &lt;- log_likelihood + y * log(theta) + (n - y) * log(1 - theta)\n  }\n  \n  return(-log_likelihood) # Negativo per ottimizzazione\n}\n\nI dati dei gruppi sono rappresentati come segue:\n\ndati_gruppi &lt;- list(c(30, 23), c(28, 20), c(40, 29), c(36, 29))\n\n\n\n34.5.4 Ottimizzazione per trovare \\(\\theta\\)\nUtilizziamo l’algoritmo di ottimizzazione optim per stimare il valore di \\(\\theta\\) che massimizza la log-verosimiglianza:\n\nresult &lt;- optim(\n  par = 0.5,                        # Valore iniziale\n  fn = log_verosimiglianza_congiunta, \n  dati = dati_gruppi,               # Dati\n  method = \"L-BFGS-B\",              # Metodo con vincoli\n  lower = 0,                        # Limite inferiore\n  upper = 1                         # Limite superiore\n)\n\n# Valore ottimale di theta\nresult$par\n#&gt; [1] 0.7537314\n\n\n\n34.5.5 Visualizzazione della log-verosimiglianza\nCalcoliamo e tracciamo la log-verosimiglianza negativa per un intervallo di valori di \\(\\theta\\):\n\ntheta_values &lt;- seq(0.01, 0.99, length.out = 100)\n\nlog_likelihood_values &lt;- sapply(theta_values, function(theta) {\n  log_verosimiglianza_congiunta(theta, dati_gruppi)\n})\n\nggplot(\n  data.frame(theta = theta_values, log_likelihood = log_likelihood_values), \n  aes(x = theta, y = log_likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Log-verosimiglianza Congiunta\",\n    x = \"Theta\",\n    y = \"Log-verosimiglianza Negativa\"\n  ) \n\n\n\n\n\n\n\n\nIn conclusione, l’analisi della verosimiglianza congiunta consente di stimare con precisione il parametro \\(\\theta\\) considerando tutte le osservazioni contemporaneamente. La log-verosimiglianza, grazie alla sua stabilità numerica e alla semplicità di calcolo, è uno strumento potente per l’inferenza statistica. Utilizzando tecniche di ottimizzazione, possiamo identificare il valore di \\(\\theta\\) che meglio spiega i dati osservati, ottenendo stime affidabili anche in contesti complessi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#la-verosimiglianza-marginale",
    "href": "chapters/probability/14_likelihood.html#la-verosimiglianza-marginale",
    "title": "34  La verosimiglianza",
    "section": "34.6 La Verosimiglianza Marginale",
    "text": "34.6 La Verosimiglianza Marginale\nLa verosimiglianza marginale è un concetto fondamentale nell’inferenza bayesiana. Essa permette di calcolare la probabilità complessiva di osservare un determinato risultato, tenendo conto di tutte le possibili incertezze sui parametri del modello. Questo è particolarmente rilevante quando il parametro di interesse, \\(\\theta\\), non è considerato un valore fisso, ma è descritto da una distribuzione di probabilità.\nIn pratica, la verosimiglianza marginale valuta la compatibilità dei dati con il modello, integrando su tutti i possibili valori di \\(\\theta\\), ciascuno pesato dalla sua probabilità a priori.\n\n34.6.1 Caso con Parametri Discreti\nConsideriamo un esempio semplice in cui \\(\\theta\\) può assumere un insieme discreto di valori. Ad esempio, in una sequenza di prove binomiali con \\(k = 7\\) successi su \\(n = 10\\) prove, e con \\(\\theta \\in \\{0.1, 0.5, 0.9\\}\\), la verosimiglianza marginale è calcolata come:\n\\[\np(k = 7 \\mid n = 10) = \\sum_{\\theta \\in \\{0.1, 0.5, 0.9\\}} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta),\n\\]\ndove \\(p(\\theta)\\) rappresenta la probabilità a priori associata a ciascun valore discreto di \\(\\theta\\). In questo caso, la verosimiglianza marginale è la somma delle probabilità di osservare i dati, pesata dalla probabilità a priori di ciascun valore di \\(\\theta\\).\n\n\n34.6.2 Caso con Parametri Continui\nNella maggior parte delle applicazioni, \\(\\theta\\) varia continuamente all’interno di un intervallo, ad esempio \\([0, 1]\\) per un parametro binomiale. In tal caso, la verosimiglianza marginale è calcolata mediante un’integrazione:\n\\[\np(k = 7 \\mid n = 10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta) \\, d\\theta,\n\\]\ndove \\(p(\\theta)\\) è la densità a priori di \\(\\theta\\). Questa formula combina le probabilità condizionali dei dati dati \\(\\theta\\) con le probabilità a priori, integrando su tutti i possibili valori di \\(\\theta\\).\n\n\n34.6.3 Calcolo Numerico della Verosimiglianza Marginale\nPer calcolare la verosimiglianza marginale con \\(\\theta\\) continuo, possiamo utilizzare l’integrazione numerica. In R, il pacchetto stats offre strumenti utili come la funzione integrate. Ecco un esempio concreto:\n\n# Definizione della funzione di verosimiglianza\nlikelihood &lt;- function(theta) {\n  dbinom(x = 7, size = 10, prob = theta)\n}\n\n# Calcolo della verosimiglianza marginale con integrazione numerica\nmarginal_likelihood &lt;- integrate(likelihood, lower = 0, upper = 1)$value\n\n# Stampa del risultato\ncat(\"La verosimiglianza marginale è:\", marginal_likelihood, \"\\n\")\n#&gt; La verosimiglianza marginale è: 0.09090909\n\n\n\n34.6.4 Interpretazione della Verosimiglianza Marginale\nLa verosimiglianza marginale rappresenta la capacità complessiva del modello di spiegare i dati, tenendo conto dell’incertezza sui parametri. Dal punto di vista geometrico, può essere interpretata come l’area sottesa alla funzione di verosimiglianza ponderata dalla distribuzione a priori di \\(\\theta\\).\nTuttavia, è importante chiarire che la verosimiglianza marginale non è una probabilità dei dati dato un valore specifico di \\(\\theta\\). Piuttosto, essa considera tutte le possibili incertezze sui parametri, fornendo una misura complessiva della compatibilità del modello con i dati.\n\n\n34.6.5 Ruolo nell’Inferenza Bayesiana\nLa verosimiglianza marginale assume un ruolo chiave nell’inferenza bayesiana come fattore di normalizzazione nella formula di Bayes:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) p(\\theta)}{p(D)},\n\\]\ndove \\(p(D)\\), ossia la verosimiglianza marginale, garantisce che la distribuzione posteriore \\(p(\\theta \\mid D)\\) sia una distribuzione di probabilità valida, con un’area totale pari a 1.\nIn conclusione, la verosimiglianza marginale è uno strumento fondamentale per valutare il modello nel suo complesso, integrando informazioni sui parametri e sulla loro incertezza. In particolare:\n\nPer parametri discreti, si calcola sommando le probabilità di ciascun valore di \\(\\theta\\), ponderate dalla loro probabilità a priori.\nPer parametri continui, si utilizza l’integrazione per ottenere una misura globale della compatibilità del modello con i dati.\n\nQuesta misura non solo consente di confrontare modelli diversi, ma garantisce anche la validità della distribuzione a posteriori nell’inferenza bayesiana. Grazie a strumenti computazionali, possiamo calcolare la verosimiglianza marginale anche in situazioni complesse, fornendo una base solida per analisi statistiche rigorose e flessibili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "href": "chapters/probability/14_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "title": "34  La verosimiglianza",
    "section": "34.7 Modello Gaussiano e Verosimiglianza",
    "text": "34.7 Modello Gaussiano e Verosimiglianza\nIn questa sezione analizziamo il caso di una distribuzione gaussiana per calcolare la funzione di verosimiglianza. Inizieremo con una singola osservazione e successivamente estenderemo l’analisi a un insieme di osservazioni indipendenti e identicamente distribuite (IID).\n\n34.7.1 Caso di una Singola Osservazione\nConsideriamo una singola osservazione $ y $, ad esempio il Quoziente Intellettivo (QI) di un individuo, che supponiamo seguire una distribuzione normale. La funzione di verosimiglianza per $ y $ esprime la plausibilità di diversi valori del parametro \\(\\mu\\) (media), dato il valore osservato, assumendo che la deviazione standard \\(\\sigma\\) sia nota.\n\n34.7.1.1 Definizione della Verosimiglianza\nLa funzione di densità di probabilità gaussiana è definita come:\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(y\\) è il valore osservato, \\(\\mu\\) è la media e \\(\\sigma\\) è la deviazione standard.\n\n\n34.7.1.2 Esempio con R\nSupponiamo di osservare un valore $ y = 114 $ e di assumere che \\(\\sigma = 15\\). Esploriamo i valori di \\(\\mu\\) in un intervallo compreso tra 70 e 160 per determinare quale valore massimizza la verosimiglianza.\n\n# Parametri iniziali\ny_obs &lt;- 114\nsigma &lt;- 15\nmu_values &lt;- seq(70, 160, length.out = 1000)\n\n# Calcolo della funzione di verosimiglianza\nlikelihood &lt;- dnorm(y_obs, mean = mu_values, sd = sigma)\n\n# Visualizzazione della funzione di verosimiglianza\nlibrary(ggplot2)\nggplot(data.frame(mu = mu_values, likelihood = likelihood), aes(x = mu, y = likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Verosimiglianza per QI = 114\",\n    x = \"Valore di μ (media)\",\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\n\n\n\n34.7.1.3 Calcolo del Valore Ottimale\nPer determinare il valore di \\(\\mu\\) che massimizza la verosimiglianza, individuiamo il massimo della curva.\n\n# Identificazione del massimo\nmu_optimal &lt;- mu_values[which.max(likelihood)]\ncat(\"Il valore ottimale di μ è:\", mu_optimal, \"\\n\")\n#&gt; Il valore ottimale di μ è: 113.964\n\nIl valore di \\(\\mu\\) che massimizza la verosimiglianza è $ = 114 $, coincidente con il valore osservato.\n\n\n\n34.7.2 Log-Verosimiglianza\nIn alternativa, possiamo lavorare con la log-verosimiglianza, una trasformazione utile per semplificare i calcoli numerici e migliorare la stabilità computazionale:\n\\[\n\\log L(\\mu \\mid y, \\sigma) = -\\frac{1}{2} \\log(2\\pi) - \\log(\\sigma) - \\frac{(y - \\mu)^2}{2\\sigma^2}.\n\\]\nQuesta funzione è equivalente alla funzione di verosimiglianza per determinare il valore di \\(\\mu\\) che meglio si adatta ai dati.\n\n34.7.2.1 Calcolo della Log-Verosimiglianza con R\n\n# Funzione di log-verosimiglianza negativa\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  0.5 * log(2 * pi) + log(sigma) + ((y - mu)^2) / (2 * sigma^2)\n}\n\n# Ottimizzazione per trovare il massimo della log-verosimiglianza\nresult &lt;- optim(\n  par = 100,  # Valore iniziale per μ\n  fn = negative_log_likelihood,\n  y = y_obs,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = 70,\n  upper = 160\n)\n\n# Risultato dell'ottimizzazione\nmu_max_loglik &lt;- result$par\ncat(\"Il valore ottimale di μ basato sulla log-verosimiglianza è:\", mu_max_loglik, \"\\n\")\n#&gt; Il valore ottimale di μ basato sulla log-verosimiglianza è: 114\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza è $ = 114 $, confermando che, in presenza di una singola osservazione, il valore ottimale coincide con l’osservazione stessa.\nIn conclusione, l’analisi della funzione di verosimiglianza nel caso gaussiano mostra che:\n\nLa funzione di verosimiglianza rappresenta la plausibilità dei parametri del modello dato il valore osservato.\nLa log-verosimiglianza è una trasformazione utile per calcoli più stabili e semplificati.\nNel caso di una singola osservazione e deviazione standard nota, il valore di \\(\\mu\\) che massimizza la verosimiglianza coincide con il valore osservato \\(y\\).\n\n\n\n\n34.7.3 Campione Indipendente di Osservazioni da una Distribuzione Normale\nConsideriamo un campione composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (IID), ognuna derivante da una distribuzione normale con media \\(\\mu\\) e deviazione standard \\(\\sigma\\). La distribuzione è rappresentata da:\n\\[\nX \\sim N(\\mu, \\sigma^2),\n\\]\ndove \\(y_i\\) indica ogni osservazione del campione.\nLa densità di probabilità congiunta per il campione è il prodotto delle densità delle singole osservazioni:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\mu, \\sigma) = \\prod_{i=1}^n p(y_i \\mid \\mu, \\sigma).\n\\]\nDi conseguenza, la funzione di verosimiglianza è:\n\\[\n\\mathcal{L}(\\mu, \\sigma \\mid y) = \\prod_{i=1}^n \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp \\left( -\\frac{(y_i - \\mu)^2}{2\\sigma^2} \\right).\n\\]\nPer semplificare i calcoli, si considera il logaritmo della funzione di verosimiglianza:\n\\[\n\\log \\mathcal{L}(\\mu, \\sigma \\mid y) = -\\frac{n}{2} \\log(2\\pi) - n \\log(\\sigma) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2.\n\\]\n\n34.7.3.1 Esempio Pratico\nSupponiamo di misurare i punteggi del BDI-II su un campione di 30 partecipanti. I dati sono i seguenti:\n\n# Dati osservati\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nAssumiamo che la deviazione standard \\(\\sigma\\) sia nota e pari alla deviazione standard campionaria (\\(\\sigma = 6.50\\)).\nDefiniamo una funzione per calcolare la log-verosimiglianza dato un valore di \\(\\mu\\):\n\nlog_likelihood &lt;- function(mu, y, sigma) {\n  n &lt;- length(y)\n  term1 &lt;- -n * log(sigma) - n * log(sqrt(2 * pi))\n  term2 &lt;- -sum((y - mu)^2) / (2 * sigma^2)\n  return(term1 + term2)\n}\n\nDefiniamo un intervallo per \\(\\mu\\), centrato sulla media campionaria:\n\n# Parametri\nsigma &lt;- 6.50\nmu_range &lt;- seq(mean(y) - 2 * sigma, mean(y) + 2 * sigma, length.out = 1000)\n\n# Calcolo della log-verosimiglianza per ogni valore di mu\nlog_lik_values &lt;- sapply(mu_range, log_likelihood, y = y, sigma = sigma)\n\nTracciamo la funzione di log-verosimiglianza per i diversi valori di \\(\\mu\\):\n\nggplot(\n  data.frame(mu = mu_range, log_likelihood = log_lik_values), \n  aes(x = mu, y = log_likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Log-Verosimiglianza\",\n    x = \"Valore di μ\",\n    y = \"Log-Verosimiglianza\"\n  ) +\n  geom_vline(xintercept = mean(y), linetype = \"dashed\", color = \"red\", alpha = 0.7) \n\n\n\n\n\n\n\n\nUtilizziamo l’ottimizzazione numerica per trovare il valore di \\(\\mu\\) che massimizza la log-verosimiglianza:\n\n# Definizione della funzione negativa per l'ottimizzazione\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  -log_likelihood(mu, y, sigma)\n}\n\n# Ottimizzazione\nresult &lt;- optim(\n  par = mean(y),  # Punto di partenza\n  fn = negative_log_likelihood,\n  y = y,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = min(mu_range),\n  upper = max(mu_range)\n)\n\n# Risultato\nmu_optimal &lt;- result$par\ncat(\"Il valore ottimale di μ è:\", mu_optimal, \"\\n\")\n#&gt; Il valore ottimale di μ è: 30.93333\n\nInterpretazione dei risultati:\n\nStima di Massima Verosimiglianza (MLE): La media campionaria \\(\\bar{y}\\) rappresenta la stima di massima verosimiglianza (MLE) per \\(\\mu\\). Questo risultato è coerente con la proprietà della distribuzione normale.\nCurva della Log-Verosimiglianza: La curva mostra la “plausibilità relativa” dei diversi valori di \\(\\mu\\) alla luce dei dati osservati.\nOttimizzazione Numerica: Il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza è il valore che meglio spiega i dati osservati.\n\nIn conclusione, la log-verosimiglianza è uno strumento essenziale per stimare i parametri di una distribuzione normale:\n\nLa stima di massima verosimiglianza per \\(\\mu\\) coincide con la media campionaria.\nVisualizzare la log-verosimiglianza aiuta a comprendere la plausibilità dei parametri.\nL’ottimizzazione numerica fornisce una soluzione precisa ed efficiente per trovare il massimo della log-verosimiglianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#riflessioni-conclusive",
    "href": "chapters/probability/14_likelihood.html#riflessioni-conclusive",
    "title": "34  La verosimiglianza",
    "section": "34.8 Riflessioni Conclusive",
    "text": "34.8 Riflessioni Conclusive\nLa funzione di verosimiglianza rappresenta un elemento cruciale che collega i dati osservati ai parametri di un modello statistico. Essa fornisce una misura della plausibilità dei dati in relazione a diversi valori possibili dei parametri del modello. La strutturazione di una funzione di verosimiglianza richiede la considerazione di tre componenti fondamentali: il modello statistico che si presume abbia generato i dati, l’insieme di valori possibili per i parametri di tale modello e le osservazioni empiriche che effettivamente abbiamo a disposizione.\nLa funzione di verosimiglianza è centrale nella pratica dell’inferenza statistica. Essa ci permette di quantificare quanto bene differenti set di parametri potrebbero aver generato i dati osservati. Questo è fondamentale sia per la selezione del modello che per la stima dei parametri, e pertanto è indispensabile per un’analisi dati rigorosa e per un’interpretazione accurata dei risultati.\nUn’applicazione pratica e illustrativa dei principi esposti in questo capitolo è fornita nella sezione sul modello Rescorla-Wagner, che è un esempio di come la teoria della verosimiglianza possa essere applicata per affrontare questioni empiriche in psicologia.\nIn sintesi, la comprensione e l’applicazione appropriata della funzione di verosimiglianza sono passaggi essenziali nel processo di analisi dati. Essa costituisce uno strumento indispensabile per chi è impegnato nella ricerca empirica e nell’interpretazione di dati complessi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#esercizi",
    "href": "chapters/probability/14_likelihood.html#esercizi",
    "title": "34  La verosimiglianza",
    "section": "34.9 Esercizi",
    "text": "34.9 Esercizi\n\nEsercizio 34.1 Spiega ciascuno dei concetti seguenti con una frase:\n\nprobabilità.\nfunzione di massa di probabilità.\nfunzione di densità di probabilità.\ndistribuzione di probabilità.\ndistribuzione di probabilità discreta.\ndistribuzione di probabilità continua.\nfunzione di distribuzione cumulativa (cdf).\nverosimiglianza\n\n\n\n\n\n\n\n\nAvviso\n\n\n\nAll’esame ti verrà chiesto di:\n\nCalcolare la funzione di verosimiglianza binomiale e riportare il valore della funzione in corrispondenza di specifici valori \\(\\theta\\).\nCalcolare la funzione di verosimiglianza del modello gaussiano, per \\(\\sigma\\) noto, e riportare il valore della funzione in corrispondenza di specifici valori \\(\\mu\\).\nCalcolare la stima di massima verosimiglianza.\nRispondere a domande che implicano una adeguata comprensione del concetto di funzione di verosimiglianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/14_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "title": "34  La verosimiglianza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pointblank_0.12.2 haven_2.5.4       labelled_2.13.0   mice_3.16.0      \n#&gt;  [5] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [9] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt; [13] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [17] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [21] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [25] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1      rlang_1.1.4       magrittr_2.0.3    compiler_4.4.2   \n#&gt;  [5] vctrs_0.6.5       pkgconfig_2.0.3   shape_1.4.6.1     fastmap_1.2.0    \n#&gt;  [9] backports_1.5.0   labeling_0.4.3    utf8_1.2.4        promises_1.3.1   \n#&gt; [13] blastula_0.3.5    rmarkdown_2.29    tzdb_0.4.0        nloptr_2.1.1     \n#&gt; [17] xfun_0.49         glmnet_4.1-8      jomo_2.7-6        jsonlite_1.8.9   \n#&gt; [21] later_1.4.0       pan_1.9           broom_1.0.7       parallel_4.4.2   \n#&gt; [25] R6_2.5.1          stringi_1.8.4     car_3.1-3         boot_1.3-31      \n#&gt; [29] rpart_4.1.23      Rcpp_1.0.13-1     iterators_1.0.14  pacman_0.5.1     \n#&gt; [33] httpuv_1.6.15     Matrix_1.7-1      splines_4.4.2     nnet_7.3-19      \n#&gt; [37] timechange_0.3.0  tidyselect_1.2.1  abind_1.4-8       yaml_2.3.10      \n#&gt; [41] codetools_0.2-20  miniUI_0.1.1.1    lattice_0.22-6    shiny_1.9.1      \n#&gt; [45] withr_3.0.2       evaluate_1.0.1    survival_3.7-0    pillar_1.9.0     \n#&gt; [49] carData_3.0-5     foreach_1.5.2     generics_0.1.3    rprojroot_2.0.4  \n#&gt; [53] hms_1.1.3         munsell_0.5.1     minqa_1.2.8       xtable_1.8-4     \n#&gt; [57] glue_1.8.0        tools_4.4.2       lme4_1.1-35.5     ggsignif_0.6.4   \n#&gt; [61] grid_4.4.2        colorspace_2.1-1  nlme_3.1-166      Formula_1.2-5    \n#&gt; [65] cli_3.6.3         fansi_1.0.6       gtable_0.3.6      rstatix_0.7.2    \n#&gt; [69] digest_0.6.37     htmlwidgets_1.6.4 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [73] lifecycle_1.0.4   mitml_0.4-5       mime_0.12",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html",
    "href": "chapters/probability/15_simulation.html",
    "title": "35  Simulazioni",
    "section": "",
    "text": "35.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo, discuteremo alcuni esercizi di simulazione presentati da Gelman et al. (2021) nel quinto capitolo del loro libro. Gli autori sottolineano che simulare variabili casuali è essenziale nelle statistiche applicate per diversi motivi:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#introduzione",
    "href": "chapters/probability/15_simulation.html#introduzione",
    "title": "35  Simulazioni",
    "section": "",
    "text": "Comprensione della variazione casuale: I modelli di probabilità imitano la variabilità del mondo reale. La simulazione aiuta a sviluppare intuizioni sulle oscillazioni casuali nel breve termine e sui loro effetti nel lungo termine.\nDistribuzione campionaria: Simulare dati consente di approssimare la distribuzione campionaria, trasferendo questa approssimazione alle stime e alle procedure statistiche.\nPrevisioni probabilistiche: I modelli di regressione producono previsioni probabilistiche. La simulazione è il metodo più generale per rappresentare l’incertezza nelle previsioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#esempio-1-quante-bambine-su-400-nascite",
    "href": "chapters/probability/15_simulation.html#esempio-1-quante-bambine-su-400-nascite",
    "title": "35  Simulazioni",
    "section": "35.2 Esempio 1: Quante bambine su 400 nascite?",
    "text": "35.2 Esempio 1: Quante bambine su 400 nascite?\nSupponiamo che la probabilità di nascita di una bambina sia \\(p\\) = 0.488. Se in un ospedale nascono 400 bambini in un anno, quante saranno bambine? Possiamo simulare questo processo usando una distribuzione binomiale, ripetendo la simulazione 10,000 volte.\n\n# Numero di simulazioni\nn_sims &lt;- 10000\n\n# Probabilità di nascita di una bambina\np_girl &lt;- 0.488\n\n# Simulazione del numero di bambine\nset.seed(123)\nn_girls &lt;- rbinom(n_sims, size = 400, prob = p_girl)\n\n# Visualizzazione dell'istogramma\nggplot(data.frame(n_girls), aes(x = n_girls)) +\n  geom_histogram(binwidth = 5, fill = \"blue\", color = \"black\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione del Numero di Bambine su 400 Nascite\",\n    x = \"Numero di Bambine\",\n    y = \"Frequenza\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#simulazione-di-probabilità-continue",
    "href": "chapters/probability/15_simulation.html#simulazione-di-probabilità-continue",
    "title": "35  Simulazioni",
    "section": "35.3 Simulazione di probabilità continue",
    "text": "35.3 Simulazione di probabilità continue\nGelman et al. (2021) dimostrano come sia possibile incorporare anche distribuzioni di probabilità continue nei tipi di simulazioni discusse nella sezione precedente. Forniscono il seguente esempio di un modello misto discreto/continuo: il 52% degli adulti negli Stati Uniti sono donne e il 48% sono uomini. L’altezza degli uomini segue approssimativamente una distribuzione normale con una media di 69.1 pollici e una deviazione standard di 2.9 pollici; per le donne, la media è 63.7 pollici e la deviazione standard è 2.7 pollici. Ecco il codice per generare l’altezza di un adulto scelto casualmente:\n\nsimulate_height &lt;- function(N) {\n  gender &lt;- rbinom(N, size = 1, prob = 0.48) # 1 = uomo, 0 = donna\n  height &lt;- ifelse(\n    gender == 1,\n    rnorm(N, mean = 69.1, sd = 2.9),\n    rnorm(N, mean = 63.7, sd = 2.7)\n  )\n  return(mean(height))\n}\n\nSupponiamo di selezionare 10 adulti a caso. Cosa possiamo dire della loro altezza media?\n\nset.seed(123)\nn_sims &lt;- 10000\navg_heights &lt;- replicate(n_sims, simulate_height(10))\n\n# Visualizzazione dell'istogramma\nggplot(data.frame(avg_heights), aes(x = avg_heights)) +\n  geom_histogram(binwidth = 0.2, fill = \"blue\", color = \"black\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione dell'Altezza Media di 10 Adulti\",\n    x = \"Altezza Media\",\n    y = \"Frequenza\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "href": "chapters/probability/15_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "title": "35  Simulazioni",
    "section": "35.4 Sommario di una simulazione con media e mediana",
    "text": "35.4 Sommario di una simulazione con media e mediana\nQuando le nostre distribuzioni sono costruite come simulazioni al computer, può essere conveniente riassumerle in qualche modo. Tipicamente, riassumiamo la posizione di una distribuzione con la sua media o mediana.\nLa variazione nella distribuzione è tipicamente riassunta dalla deviazione standard, ma spesso preferiamo usare la deviazione mediana assoluta. Se la mediana di un insieme di simulazioni \\(z_1, \\ldots, z_n\\) è \\(M\\), allora la deviazione mediana assoluta è:\n\\[ \\text{mad} = \\text{mediana}_{n} |z_i - M| \\]\nTuttavia, poiché siamo abituati a lavorare con le deviazioni standard, quando calcoliamo la deviazione mediana assoluta, la riscaliamo moltiplicandola per 1.483, il che riproduce la deviazione standard nel caso speciale della distribuzione normale:\n\\[ 1.483 * \\text{median}(|y - \\text{median}(z)|) \\]\nPreferiamo tipicamente i riassunti basati sulla mediana perché sono più stabili computazionalmente, e riscaliamo il riassunto basato sulla mediana della variazione come descritto sopra in modo da essere comparabile alla deviazione standard, che sappiamo già interpretare nella pratica statistica usuale.\nEcco come implementare quanto sopra in R per i dati relativi all’altezza media di 10 adulti.\n\n# Calcolo della media e mediana\nmean_avg_height &lt;- mean(avg_heights)\nmedian_avg_height &lt;- median(avg_heights)\n\n# Calcolo della deviazione standard\nsd_avg_height &lt;- sd(avg_heights)\n\n# Calcolo della MAD (Deviazione Mediana Assoluta)\nmad_avg_height &lt;- median(abs(avg_heights - median_avg_height)) * 1.483\n\n# Risultati\ncat(\"Mean:\", mean_avg_height, \"\\n\")\n#&gt; Mean: 66.3001\ncat(\"Median:\", median_avg_height, \"\\n\")\n#&gt; Median: 66.28163\ncat(\"Standard Deviation:\", sd_avg_height, \"\\n\")\n#&gt; Standard Deviation: 1.226406\ncat(\"MAD (scaled):\", mad_avg_height, \"\\n\")\n#&gt; MAD (scaled): 1.234851\n\n\n35.4.1 Intervalli di Incertezza\nPer rappresentare l’incertezza, possiamo calcolare intervalli centrali al 50% e al 95%.\n\n# Intervalli di incertezza\nlower_50 &lt;- quantile(avg_heights, 0.25)\nupper_50 &lt;- quantile(avg_heights, 0.75)\n\nlower_95 &lt;- quantile(avg_heights, 0.025)\nupper_95 &lt;- quantile(avg_heights, 0.975)\n\ncat(\"50% Interval:\", lower_50, \"-\", upper_50, \"\\n\")\n#&gt; 50% Interval: 65.46187 - 67.128\ncat(\"95% Interval:\", lower_95, \"-\", upper_95, \"\\n\")\n#&gt; 95% Interval: 63.91146 - 68.7695\n\nEcco come interpretarli.\nIntervallo centrale al 50%.\n\nContiene i valori centrali che coprono il 50% della distribuzione. Questo intervallo si estende dal primo quartile (25° percentile) al terzo quartile (75° percentile).\nIndica la fascia di valori in cui si trovano i risultati “più comuni” o tipici. È una misura di variabilità concentrata nella parte centrale della distribuzione, meno sensibile a valori estremi.\n\nPer le altezze medie simulate di 10 adulti, un intervallo centrale al 50% che va da 65 a 67 pollici indica che metà delle medie osservate si trova in questo intervallo.\n\n\nIntervallo centrale al 95%.\n\nContiene il 95% della distribuzione simulata, lasciando solo il 2.5% dei valori al di sotto e il 2.5% al di sopra dell’intervallo. Questo intervallo si calcola tra il 2.5° percentile e il 97.5° percentile.\nIndica una fascia più ampia che cattura quasi tutti i valori plausibili, inclusi quelli meno probabili ma comunque possibili.\n\nPer le altezze medie simulate, un intervallo al 95% che va da 64 a 68 pollici significa che, in quasi tutte le simulazioni, l’altezza media si trova in questo intervallo, con poche eccezioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/15_simulation.html#commenti-e-considerazioni-finali",
    "title": "35  Simulazioni",
    "section": "35.5 Commenti e Considerazioni Finali",
    "text": "35.5 Commenti e Considerazioni Finali\nLo scopo della simulazione di dati fittizi non è fornire intuizioni sui dati o sul problema reale in esame, ma piuttosto valutare le proprietà dei metodi statistici utilizzati, partendo da un modello generativo ipotizzato. Le simulazioni sono cruciali nella pratica della ricerca. Molti autori suggeriscono che dovrebbero essere eseguite prima di raccogliere i dati di uno studio, per valutare, tra le altre cose, se la dimensione campionaria prevista fornisce un potere statistico sufficiente per rispondere alla domanda della ricerca (Gelman & Brown, 2024).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#esercizi",
    "href": "chapters/probability/15_simulation.html#esercizi",
    "title": "35  Simulazioni",
    "section": "35.6 Esercizi",
    "text": "35.6 Esercizi\n\nEsercizio 35.1 Immagina il caso di 220 studenti che devono sostenere tre prove in itinere in un corso. Il voto finale è la media dei voti ottenuti in queste tre prove. Le distribuzioni dei voti per le prove sono descritte come segue:\n\nPrima prova: I voti sono distribuiti secondo una gaussiana con media 24. Il 15% degli studenti ottiene un voto inferiore a 18.\nSeconda prova: I voti sono distribuiti secondo una gaussiana con media 25. Il 10% degli studenti ottiene un voto inferiore a 18.\nTerza prova: I voti sono distribuiti secondo una gaussiana con media 26. Solo il 5% degli studenti ottiene un voto inferiore a 18.\n\nDei 220 studenti iniziali:\n\nIl 10% non partecipa alla prima prova.\nUn ulteriore 5% non partecipa alla seconda prova.\n\nPer ottenere il voto finale, uno studente deve partecipare a tutte e tre le prove.\nUtilizzando una simulazione, trova la media finale dei voti e calcola l’intervallo di incertezza al 90% per la stima della media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/15_simulation.html#informazioni-sullambiente-di-sviluppo",
    "title": "35  Simulazioni",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.0       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] labeling_0.4.3    rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [37] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    utf8_1.2.4       \n#&gt; [41] broom_1.0.7       withr_3.0.2       backports_1.5.0   promises_1.3.1   \n#&gt; [45] timechange_0.3.0  rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3        \n#&gt; [49] shiny_1.9.1       evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4      \n#&gt; [53] Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9   \n#&gt; [57] R6_2.5.1",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#bibliografia",
    "href": "chapters/probability/15_simulation.html#bibliografia",
    "title": "35  Simulazioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, esamineremo l’inferenza bayesiana applicata a modelli statistici in cui si stima un unico parametro scalare, cioè quando l’estimando \\(\\theta\\) è unidimensionale. In questo capitolo, consideriamo quattro modelli unidimensionali fondamentali e ampiamente utilizzati: il modello binomiale, il modello normale, il modello di Poisson e il modello esponenziale. Approfondiremo il processo di aggiornamento bayesiano, analizzando due metodi principali per derivare la distribuzione a posteriori: l’approssimazione numerica attraverso il metodo basato su griglia e l’utilizzo delle distribuzioni coniugate, in cui una specifica combinazione di distribuzione a priori e verosimiglianza consente una derivazione analitica della distribuzione a posteriori. Inoltre, considereremo l’influenza della scelta della distribuzione a priori sulla distribuzione a posteriori e discuteremo le tecniche utili per sintetizzare e interpretare quest’ultima in modo efficace.",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html",
    "href": "chapters/bayesian_inference/01_intro_bayes.html",
    "title": "36  La quantificazione dell’incertezza",
    "section": "",
    "text": "36.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nL’approccio bayesiano alla statistica non si limita all’applicazione del Teorema di Bayes, ma si caratterizza per una gestione rigorosa dell’incertezza e per la rappresentazione delle soluzioni attraverso distribuzioni di probabilità. Il processo di modellazione bayesiana, noto come workflow bayesiano (Baribault & Collins, 2023), si articola in più fasi: dalla costruzione del modello, all’applicazione del Teorema di Bayes, fino all’analisi critica dei risultati. Questo ciclo iterativo permette un apprendimento continuo, migliorando progressivamente le stime e adattandole alle nuove evidenze che emergono.\nL’obiettivo dell’approccio bayesiano non è quello di raggiungere una verità assoluta, ma di aggiornare razionalmente le credenze su una determinata ipotesi, integrando progressivamente nuove informazioni. Questo approccio è particolarmente utile in psicologia, dove i fenomeni analizzati sono complessi e le misurazioni soggette a molte fonti di incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#introduzione",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#introduzione",
    "title": "36  La quantificazione dell’incertezza",
    "section": "",
    "text": "“Quindi non avete una sola risposta alle vostre domande?”\n“Adson, se l’avessi insegnerei teologia a Parigi.”\n“A Parigi hanno sempre la risposta vera?”\n“Mai,” disse Guglielmo, “ma sono molto sicuri dei loro errori.”\n(Umberto Eco: Il Nome della Rosa)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-valore-dellincertezza",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-valore-dellincertezza",
    "title": "36  La quantificazione dell’incertezza",
    "section": "36.2 Il Valore dell’Incertezza",
    "text": "36.2 Il Valore dell’Incertezza\nIn psicologia e in altre scienze sociali, l’informazione è spesso incompleta, e le variabili di interesse sono latenti o difficili da osservare direttamente. L’inferenza bayesiana offre un quadro metodologico per rappresentare e affrontare questa incertezza, permettendo di modellare ciò che non si conosce come una variabile aleatoria che può essere aggiornata man mano che si acquisiscono nuovi dati (Jaynes, 2003).\nDiversamente dai modelli deterministici, che assumono la possibilità di prevedere i risultati con certezza date tutte le informazioni, i modelli bayesiani accolgono e gestiscono l’incertezza, caratteristica fondamentale in psicologia. Molti fenomeni psicologici coinvolgono variabili latenti – come l’ansia, la motivazione o l’autostima – che non possono essere osservate direttamente. L’approccio bayesiano consente di rappresentare tali variabili in modo flessibile, integrando evidenze precedenti con i dati attuali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "title": "36  La quantificazione dell’incertezza",
    "section": "36.3 Interpretazione Frequentista vs. Bayesiana dell’Incertezza",
    "text": "36.3 Interpretazione Frequentista vs. Bayesiana dell’Incertezza\n\nInterpretazione Frequentista: Immaginiamo di misurare la frequenza di un evento psicologico, come un livello di ansia oltre una certa soglia, in un grande campione di individui simili. Secondo i frequentisti, si potrebbe interpretare l’incertezza come la frequenza relativa dell’evento in situazioni simili nel lungo periodo. Tuttavia, questa interpretazione presenta due problemi principali: non è possibile osservare un evento infinite volte in condizioni identiche, e il “gruppo di riferimento” (o reference class) – cioè, le condizioni simili rilevanti – può essere difficile da definire precisamente.\nInterpretazione Bayesiana: Un’interpretazione bayesiana dell’incertezza riguarda invece il grado di credenza soggettiva. Supponiamo che uno psicologo creda con il 10% di fiducia che un individuo avrà un punteggio d’ansia superiore a una certa soglia. Questo grado di fiducia può essere aggiornato man mano che si raccolgono nuove informazioni, utilizzando il Teorema di Bayes per calcolare probabilità a posteriori. A differenza dell’approccio frequentista, l’incertezza bayesiana descrive una credenza soggettiva che può essere costantemente aggiornata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#esempi-psicologici-dellinferenza-bayesiana",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#esempi-psicologici-dellinferenza-bayesiana",
    "title": "36  La quantificazione dell’incertezza",
    "section": "36.4 Esempi Psicologici dell’Inferenza Bayesiana",
    "text": "36.4 Esempi Psicologici dell’Inferenza Bayesiana\nEsempio 1: Misurare l’Ansia con Questionari\nQuando si misura l’ansia tramite un questionario, la stima è soggetta a incertezza per vari motivi: 1. Risposte Soggettive: L’interpretazione delle domande può variare tra individui e può essere influenzata dallo stato d’animo. 2. Misurazioni Incomplete: Un questionario può non cogliere tutte le sfumature dell’ansia. 3. Rumore nei Dati: Errori minori, come distrazioni durante la compilazione, possono influire sulla precisione dei risultati.\nCon l’approccio bayesiano, è possibile combinare credenze a priori basate su ricerche precedenti con i dati raccolti per ottenere una stima aggiornata. Ad esempio, se si dispone di una distribuzione di probabilità iniziale sull’ansia, questa distribuzione può essere aggiornata man mano che si raccolgono più dati, permettendo una stima più accurata del livello di ansia effettivo.\nEsempio 2: Effetto del Rinforzo Negativo sulla Motivazione\nConsideriamo uno studio sull’effetto del rinforzo negativo sulla motivazione in un compito. La “motivazione interna” è una variabile latente, non osservabile direttamente. Possiamo inferirla, però, tramite misure indirette, come il tempo trascorso sul compito o la velocità di risposta. Un modello bayesiano consente di collegare queste variabili osservabili alla motivazione latente, rappresentando l’incertezza sia nella variabilità individuale sia nell’effetto del rinforzo negativo. Man mano che vengono raccolti nuovi dati, il modello bayesiano aggiorna le stime di motivazione e permette di esprimere in modo rigoroso la probabilità che un cambiamento osservato sia effettivamente dovuto al rinforzo negativo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "title": "36  La quantificazione dell’incertezza",
    "section": "36.5 Inferenza Bayesiana e Incertezza nelle Stime",
    "text": "36.5 Inferenza Bayesiana e Incertezza nelle Stime\nL’inferenza bayesiana utilizza le probabilità per aggiornare le credenze sui parametri di un modello basandosi sui dati osservati. Queste credenze sono rappresentate da distribuzioni di probabilità, e l’ampiezza di queste distribuzioni riflette l’incertezza associata alle stime. In psicologia, dove spesso si lavora con campioni limitati e misurazioni indirette di variabili latenti, questa gestione dell’incertezza è fondamentale per interpretare i risultati in modo robusto e realistico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-modello-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-modello-bayesiano",
    "title": "36  La quantificazione dell’incertezza",
    "section": "36.6 Il Modello Bayesiano",
    "text": "36.6 Il Modello Bayesiano\nUn modello statistico combina una distribuzione probabilistica con ipotesi sui parametri per descrivere un fenomeno osservato. Ad esempio, possiamo modellare il lancio di una moneta equa con un modello binomiale, in cui la probabilità \\(\\theta\\) è fissata a 0.5, oppure modellare l’altezza degli uomini italiani con un modello normale, in cui \\(\\mu\\) è 183 cm e \\(\\sigma\\) è 5 cm. In termini bayesiani, il modello statistico include tre componenti principali:\n\nDistribuzione a Priori (Prior): Rappresenta le credenze iniziali sui valori dei parametri del modello, informate da ricerche precedenti o da assunzioni neutre.\nVerosimiglianza (Likelihood): Descrive la probabilità di osservare i dati dati i parametri del modello, riflettendo il processo che genera i dati.\nDistribuzione a Posteriori (Posterior): È la distribuzione aggiornata dei parametri dopo aver osservato i dati, ottenuta combinando la prior e la verosimiglianza mediante il teorema di Bayes. La posterior rappresenta la conoscenza aggiornata dopo aver integrato le informazioni fornite dai dati.\n\nLa modellazione bayesiana descrive il processo generativo che ha prodotto i dati osservati, incorporando l’incertezza nei parametri e aggiornando continuamente le stime man mano che emergono nuovi dati. Questo approccio è particolarmente utile in contesti come la psicologia, dove i fenomeni complessi e le variabili latenti rendono necessario modellare l’incertezza in modo esplicito.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "title": "36  La quantificazione dell’incertezza",
    "section": "36.7 Componenti Chiave della Modellazione Probabilistica",
    "text": "36.7 Componenti Chiave della Modellazione Probabilistica\n\nVariabili Aleatorie: Quantità incerte che assumono diversi valori secondo una distribuzione di probabilità. Ad esempio, il livello di depressione di un paziente può essere trattato come una variabile aleatoria.\nDistribuzioni di Probabilità: Descrivono come i valori di una variabile aleatoria sono distribuiti. Ad esempio, una distribuzione normale può essere utilizzata per modellare la variabilità dell’ansia in una popolazione.\nInferenza Bayesiana: Aggiorna la distribuzione di probabilità delle variabili di interesse sulla base dei nuovi dati, migliorando progressivamente le stime.\n\nEsempio: Inferenza sul Livello di Depressione\nIn uno studio clinico sulla depressione, possiamo utilizzare l’inferenza bayesiana per stimare il livello di depressione di un paziente partendo da una distribuzione a priori informata da studi precedenti. Ogni nuovo dato raccolto (come punteggi a questionari o osservazioni) permette di aggiornare questa stima, affinando progressivamente la comprensione del fenomeno.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "title": "36  La quantificazione dell’incertezza",
    "section": "36.8 Il Potere dell’Aggiornamento Bayesiano",
    "text": "36.8 Il Potere dell’Aggiornamento Bayesiano\nIl vero punto di forza della modellazione bayesiana risiede nella sua capacità di aggiornare continuamente le credenze sui parametri del modello man mano che si raccolgono nuovi dati. Questo processo iterativo, basato sul teorema di Bayes, consente di integrare sia le credenze iniziali (a priori) sia le evidenze empiriche (verosimiglianza) per ottenere stime sempre più precise.\nEsempio Intuitivo: Il Globo Terrestre\nUn esempio intuitivo per spiegare l’aggiornamento bayesiano è quello proposto da McElreath (2020). Supponiamo di voler stimare la proporzione della superficie terrestre coperta d’acqua. L’esperimento consiste nel lanciare un globo terrestre in aria, afferrarlo e osservare se la superficie sotto il dito è acqua o terra. Dopo ogni osservazione, possiamo aggiornare le nostre credenze sulla proporzione d’acqua (p).\nIniziamo con una distribuzione a priori che assegna la stessa probabilità a tutti i valori possibili di \\(p\\) (proporzione d’acqua). Dopo il primo lancio, in cui osserviamo acqua (“W”), la probabilità che \\(p\\) sia zero diminuisce, mentre quella che \\(p\\) sia maggiore aumenta. Man mano che raccogliamo più dati, la distribuzione si aggiorna, riducendo l’incertezza e convergendo verso una stima più precisa di \\(p\\).\nCon l’aumento dei dati osservati, la distribuzione a posteriori si concentra sempre di più attorno ai valori di \\(p\\) che meglio spiegano i dati. Questo processo rappresenta il continuo affinamento delle stime bayesiane, che diventano più accurate man mano che le evidenze si accumulano.\nIn sintesi, l’aggiornamento bayesiano fornisce un quadro flessibile e sistematico per trattare l’incertezza e integrare nuove informazioni. È particolarmente utile nelle scienze psicologiche e sociali, dove la complessità e la variabilità dei fenomeni rendono difficile ottenere stime precise. Questo approccio consente di migliorare costantemente la comprensione dei fenomeni, adattando le credenze man mano che emergono nuovi dati.\n\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIl grafico precedente illustra un processo di aggiornamento bayesiano, in cui vengono progressivamente aggiornate le credenze sulla proporzione di superficie coperta d’acqua (\\(p\\)) del globo terrestre, man mano che vengono raccolti nuovi dati.\nL’esperimento prevede il lancio di un globo terrestre per osservare se la superficie sotto il dito è acqua (“W”) o terra (“L”). Dopo ogni lancio, le probabilità sui possibili valori di \\(p\\) vengono aggiornate sulla base delle osservazioni, utilizzando il teorema di Bayes. Il processo è visualizzato attraverso una serie di grafici, organizzati in una griglia 3x3, con ogni pannello che rappresenta un’osservazione aggiuntiva.\n\nLinee tratteggiate: Ogni curva tratteggiata in un pannello rappresenta la distribuzione di probabilità a posteriori (posterior) derivata dal pannello precedente. In altre parole, questa è la distribuzione che incorpora tutte le osservazioni fino a quel momento.\nLinee continue: Ogni curva continua rappresenta la nuova distribuzione a posteriori, aggiornata dopo aver aggiunto una nuova osservazione. Questa curva combina la distribuzione a priori (che coincide con la curva tratteggiata dal pannello precedente) e la nuova evidenza.\n\n\nPrimo Pannello (Osservazione: W)\n\nLa prima osservazione è “acqua” (W). La distribuzione a priori è uniforme, poiché non ci sono informazioni iniziali. Dopo aver osservato acqua, la distribuzione a posteriori si aggiorna: la probabilità che \\(p = 0\\) (nessuna acqua) è ora zero, e la curva si sposta verso destra, indicando che è più probabile che \\(p\\) sia maggiore di 0.\n\nSecondo Pannello (Osservazione: L)\n\nLa seconda osservazione è “terra” (L). La curva si sposta leggermente verso sinistra, poiché è ora meno probabile che \\(p\\) sia molto alto (vicino a 1). La probabilità che \\(p\\) sia 0.5 diventa massima, in quanto abbiamo osservato una volta acqua e una volta terra.\n\nTerzo Pannello (Osservazione: W)\n\nIl terzo lancio produce di nuovo acqua. La curva si sposta nuovamente verso destra, con un picco vicino a \\(p = 0.75\\), riflettendo che abbiamo osservato acqua due volte su tre. La distribuzione si aggiorna in base alla nuova evidenza.\n\nPannelli Successivi\n\nOgni nuovo pannello segue lo stesso schema: la distribuzione a priori (linea tratteggiata) viene aggiornata con la nuova osservazione (linea continua). Se viene osservata acqua (W), il picco della distribuzione si sposta a destra; se viene osservata terra (L), il picco si sposta a sinistra. In ogni caso, la curva diventa progressivamente più “appuntita”, indicando che l’incertezza sulla vera proporzione di acqua diminuisce con l’aumentare del numero di osservazioni.\n\n\nL’aspetto fondamentale dell’approccio bayesiano è che ogni distribuzione a posteriori aggiornata (linea continua) diventa la nuova distribuzione a priori per la successiva osservazione. Questo processo iterativo permette di apprendere progressivamente dai dati, integrando ogni nuova informazione per affinare la stima di \\(p\\). Alla fine, la distribuzione diventa sempre più concentrata intorno al valore più probabile di \\(p\\), man mano che raccogliamo più dati.\nIn conclusione, l’esempio illustra come l’aggiornamento bayesiano modifichi le nostre credenze sulla proporzione d’acqua (\\(p\\)) sulla superficie del globo, basandosi sulle osservazioni raccolte. Ogni curva rappresenta la sintesi delle conoscenze attuali, combinando le osservazioni precedenti con l’ultima evidenza raccolta. Il grafico dimostra visivamente come l’approccio bayesiano consenta di trattare l’incertezza e aggiornare le stime in modo coerente e progressivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "title": "36  La quantificazione dell’incertezza",
    "section": "36.9 Il Processo Generatore dei Dati",
    "text": "36.9 Il Processo Generatore dei Dati\nNel contesto dell’aggiornamento bayesiano, è fondamentale fare un’assunzione su quale modello statistico descriva il processo generatore dei dati, ossia il meccanismo che collega i parametri sconosciuti ai dati osservati. Questo modello è rappresentato dalla funzione di verosimiglianza, che descrive la probabilità di osservare i dati per ogni possibile valore del parametro incognito. Ad esempio, nel caso di esperimenti bernoulliani come quello dei lanci del globo, ogni prova può risultare in un successo (acqua) o in un fallimento (terra), e l’obiettivo è stimare la probabilità di successo, \\(\\theta\\).\nIl processo generatore dei dati per questo tipo di esperimento è ben descritto da una distribuzione binomiale, che modella il numero di successi osservati in una serie di prove indipendenti, ciascuna caratterizzata dalla stessa probabilità \\(\\theta\\). In questo contesto, \\(\\theta\\) rappresenta la proporzione di superficie coperta d’acqua sul globo, e l’assunzione chiave è che essa rimanga costante durante l’intero esperimento.\n\n\n\n\n\n\nFigura 36.1: Gli stessi dati possono essere coerenti con diverse ipotesi riguardanti il processo che li ha generati(Figura tratta da Freiesleben & Molnar, 2024).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#aggiornamento-bayesiano-e-processo-generatore",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#aggiornamento-bayesiano-e-processo-generatore",
    "title": "36  La quantificazione dell’incertezza",
    "section": "36.10 Aggiornamento Bayesiano e Processo Generatore",
    "text": "36.10 Aggiornamento Bayesiano e Processo Generatore\nL’aggiornamento bayesiano permette di modificare le nostre credenze riguardo al valore del parametro \\(\\theta\\) man mano che osserviamo nuovi dati. Il punto di partenza è una distribuzione a priori su \\(\\theta\\), che può riflettere la nostra ignoranza (ad esempio, una distribuzione uniforme, che assegna uguale probabilità a tutti i valori di \\(\\theta\\) tra 0 e 1) o conoscenze preesistenti. Nel nostro esempio con il globo, possiamo iniziare con una distribuzione a priori uniforme, che indica che ogni proporzione di acqua è inizialmente considerata ugualmente probabile.\nMan mano che raccogliamo dati (ad esempio, 6 successi su 9 lanci), applichiamo il Teorema di Bayes per combinare la distribuzione a priori con la verosimiglianza dei dati osservati, ottenendo una distribuzione a posteriori che rappresenta le nostre credenze aggiornate su \\(\\theta\\). La distribuzione a posteriori riflette le informazioni aggiunte dai dati e fornisce una stima aggiornata e più precisa di \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "title": "36  La quantificazione dell’incertezza",
    "section": "36.11 Interpretazione della Distribuzione a Posteriori",
    "text": "36.11 Interpretazione della Distribuzione a Posteriori\nLa distribuzione a posteriori ci permette di fare inferenze più solide su \\(\\theta\\). In particolare, possiamo calcolare:\n\nModa: Il valore di \\(\\theta\\) con la massima probabilità, che indica la stima più plausibile.\nMedia o Mediana: Altre misure riassuntive della distribuzione a posteriori, che possono fornire ulteriori informazioni sull’intervallo di valori probabili per \\(\\theta\\).\n\nL’incertezza sulla stima è rappresentata dall’ampiezza della distribuzione a posteriori. Se la distribuzione è stretta, significa che l’incertezza è bassa, mentre una distribuzione più ampia indica una maggiore incertezza. Con l’aumento dei dati osservati, la distribuzione tende a concentrarsi intorno a un intervallo ristretto, riducendo l’incertezza e migliorando la precisione della stima.\nNel caso del globo, ad esempio, se osserviamo che la distribuzione a posteriori ha un picco vicino a \\(\\theta = 0.67\\), possiamo concludere che la probabilità più plausibile per la proporzione di acqua sul globo è circa 67%. Inoltre, se la distribuzione a posteriori è stretta, possiamo essere più sicuri di questa stima, mentre se è più ampia, la nostra incertezza sarà maggiore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "title": "36  La quantificazione dell’incertezza",
    "section": "36.12 Influenza delle Distribuzioni a Priori",
    "text": "36.12 Influenza delle Distribuzioni a Priori\nIn questo esempio, abbiamo utilizzato una distribuzione a priori uniforme, che esprime una totale mancanza di conoscenza iniziale su \\(\\theta\\). Tuttavia, in contesti in cui abbiamo informazioni preesistenti, è possibile utilizzare distribuzioni a priori più informative. Ad esempio, se sappiamo da studi precedenti che circa il 70% della superficie terrestre è coperta d’acqua, possiamo utilizzare una distribuzione a priori che rifletta questa conoscenza. Questo tipo di distribuzione a priori informativa può rendere l’aggiornamento bayesiano più efficiente, portando a stime più precise con meno dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "title": "36  La quantificazione dell’incertezza",
    "section": "36.13 Vantaggi dell’Aggiornamento Bayesiano",
    "text": "36.13 Vantaggi dell’Aggiornamento Bayesiano\nUno dei principali vantaggi dell’approccio bayesiano è che ogni nuova osservazione aggiorna automaticamente le credenze preesistenti, integrando le informazioni precedenti con i nuovi dati. Questo processo consente un apprendimento iterativo e progressivo, che diventa più efficiente man mano che si accumulano dati. Inoltre, la flessibilità nella scelta della distribuzione a priori consente al ricercatore di adattare l’inferenza bayesiana al contesto specifico, migliorando ulteriormente la precisione delle stime.\nIn sintesi, il processo generatore dei dati, modellato tramite la verosimiglianza, gioca un ruolo centrale nell’aggiornamento bayesiano. Nel caso del globo, abbiamo modellato il fenomeno utilizzando una distribuzione binomiale e, attraverso l’applicazione del Teorema di Bayes, abbiamo aggiornato progressivamente le nostre credenze sulla proporzione di acqua osservata. Il risultato è una stima sempre più precisa di \\(\\theta\\), con una distribuzione a posteriori che riflette sia le osservazioni passate sia le nuove evidenze, riducendo progressivamente l’incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#riflessioni-conclusive",
    "title": "36  La quantificazione dell’incertezza",
    "section": "36.14 Riflessioni Conclusive",
    "text": "36.14 Riflessioni Conclusive\nNegli ultimi anni, i metodi bayesiani stanno acquisendo sempre più importanza nel campo dell’inferenza statistica, anche in discipline come la psicologia. Questa diffusione è favorita dall’accesso a risorse educative e a testi fondamentali, come quelli di Albert & Hu (2019), Johnson et al. (2022), McElreath (2020) e Kruschke (2014), che hanno reso la modellizzazione bayesiana più accessibile, chiarendo i concetti centrali in modo pratico e comprensibile.\nL’approccio bayesiano si distingue dalla metodologia frequentista tradizionale per la sua capacità di trattare i parametri di interesse come quantità probabilistiche. Invece di considerare i parametri come valori fissi e sconosciuti (come avviene nel paradigma frequentista), il bayesianesimo assegna ai parametri una distribuzione a priori, che rappresenta le credenze iniziali del ricercatore. Man mano che nuovi dati vengono raccolti, queste credenze vengono aggiornate tramite il teorema di Bayes, portando a una distribuzione a posteriori che riflette sia le informazioni pregresse sia l’evidenza empirica. Questa distribuzione aggiornata consente di esprimere l’incertezza sui parametri in modo più completo e informato.\nUno dei principali vantaggi dell’approccio bayesiano è la sua capacità di combinare conoscenze pregresse con nuove osservazioni in modo fluido e sistematico. Ogni nuova informazione arricchisce e raffina le stime, rendendole più accurate e interpretabili nel contesto del problema specifico. Questo non solo migliora la precisione delle inferenze, ma permette anche una migliore comprensione dell’incertezza che circonda i parametri studiati.\nIn definitiva, l’inferenza bayesiana non è solo uno strumento analitico, ma un approccio dinamico che incoraggia un’interazione continua tra teoria ed evidenza. Offrendo una flessibilità unica e una gestione esplicita dell’incertezza, il bayesianesimo si rivela un metodo potente per supportare il processo decisionale in contesti complessi, rendendo le sue applicazioni particolarmente rilevanti in campi come la psicologia, dove l’incertezza è una componente inevitabile dell’analisi dei dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "36  La quantificazione dell’incertezza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#bibliografia",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#bibliografia",
    "title": "36  La quantificazione dell’incertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBaribault, B., & Collins, A. G. (2023). Troubleshooting Bayesian cognitive models. Psychological Methods.\n\n\nFreiesleben, T., & Molnar, C. (2024). Supervised Machine Learning for Science: How to stop worrying and love your black box. https://ml-science-book.com/\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nKruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html",
    "title": "37  Inferenza bayesiana",
    "section": "",
    "text": "37.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nQuesto capitolo approfondisce i concetti introdotti nel capitolo precedente, presentando l’aggiornamento bayesiano in modo più formale e dettagliato.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#paradigma-bayesiano",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#paradigma-bayesiano",
    "title": "37  Inferenza bayesiana",
    "section": "37.2 Paradigma Bayesiano",
    "text": "37.2 Paradigma Bayesiano\nL’approccio bayesiano alla statistica si fonda sull’idea di rappresentare la conoscenza a priori sui parametri che governano un fenomeno attraverso distribuzioni di probabilità. Queste distribuzioni a priori riflettono le credenze iniziali del ricercatore riguardo ai parametri, prima di osservare i dati. Quando nuovi dati vengono raccolti, l’informazione fornita da tali dati viene integrata nel modello tramite la funzione di verosimiglianza, che rappresenta la probabilità di osservare quei dati dati i parametri ipotizzati.\nAttraverso l’applicazione del Teorema di Bayes, le credenze a priori vengono aggiornate combinando la distribuzione a priori con la verosimiglianza dei dati. Questo processo produce la distribuzione a posteriori, che rappresenta una nuova e più informata stima dei parametri, tenendo conto sia delle credenze iniziali sia dei dati osservati.\nL’approccio bayesiano richiede un cambiamento di prospettiva rispetto ai metodi classici di stima dei parametri. Non ci si limita più a trovare un singolo valore “ottimale” per i parametri del modello. Invece, l’obiettivo è determinare l’intera distribuzione a posteriori dei parametri, che descrive in modo completo lo stato di conoscenza attuale. Solo questa distribuzione fornisce una rappresentazione adeguata dell’incertezza associata ai parametri, permettendo di quantificare non solo quali valori sono più probabili, ma anche l’ampiezza dell’incertezza su tali stime.\n\n37.2.1 Vantaggi dell’Approccio Bayesiano\nUn aspetto distintivo dell’inferenza bayesiana è la sua capacità di gestire l’incertezza in modo esplicito. Invece di limitarsi a una singola stima puntuale, l’approccio bayesiano considera l’intero spettro di valori possibili per i parametri e le loro rispettive probabilità. Questo consente una rappresentazione più ricca delle informazioni disponibili e una valutazione più robusta delle ipotesi.\nInoltre, l’approccio bayesiano è altamente flessibile, permettendo di incorporare informazioni precedenti sotto forma di distribuzioni a priori. In contesti in cui si dispone di conoscenze pregresse, come dati di studi precedenti o teorie consolidate, questa caratteristica offre un vantaggio notevole rispetto agli approcci frequentisti, che non integrano facilmente tali informazioni.\nIn conclusione, il paradigma bayesiano offre una visione più ampia e completa dell’incertezza e della variabilità dei parametri rispetto ai metodi tradizionali, rappresentando un quadro teorico e pratico fondamentale per l’inferenza statistica e la modellazione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#densità-di-probabilità",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#densità-di-probabilità",
    "title": "37  Inferenza bayesiana",
    "section": "37.3 Densità di Probabilità",
    "text": "37.3 Densità di Probabilità\nNei capitoli precedenti abbiamo esaminato alcuni esempi di funzioni di densità di probabilità (PDF). Ma quali sono le caratteristiche generali di una PDF?\nSe \\(X\\) è una variabile casuale con una funzione di densità di probabilità \\(p(x)\\), la probabilità che \\(X\\) assuma un valore nell’intervallo \\((a, b)\\) può essere calcolata come:\n\\[\np(X \\in (a,b)) = \\int_a^b p(x)dx.\n\\]\nPer variabili discrete, l’integrazione si trasforma in una somma.\n\n37.3.1 Le Regole di Somma e Prodotto\nDate due variabili casuali continue \\(x\\) e \\(y\\), le regole di somma e prodotto per le densità di probabilità si esprimono come:\n\\[\n\\begin{align*}\np(y) = \\int p(x,y)dx \\quad &\\text{- regola della somma},\\\\\np(x,y) = p(y|x) p(x) = p(x|y) p(y) \\quad &\\text{- regola del prodotto}.\n\\end{align*}\n\\]\nLa probabilità \\(p(y)\\) è chiamata probabilità marginale.\nLa regola del prodotto specifica che la distribuzione congiunta di due variabili può essere espressa come il prodotto di una distribuzione condizionata \\(p(y \\mid x)\\) e una distribuzione marginale \\(p(x)\\), o viceversa.\n\n\n37.3.2 La Distribuzione Marginale\nLa distribuzione marginale si riferisce alla distribuzione di probabilità di una variabile quando si tiene conto di tutte le possibili variazioni dell’altra variabile in una distribuzione congiunta. In altre parole, essa descrive la probabilità di una variabile indipendentemente dall’altra.\nConsideriamo due variabili correlate, \\(x\\) e \\(y\\). Possiamo esprimere la relazione tra di esse con la regola del prodotto:\n\\[\np(x, y) = p(y \\mid x)p(x),\n\\]\ndove \\(p(y \\mid x)\\) è la probabilità di \\(y\\) dato un certo valore di \\(x\\), e \\(p(x)\\) è la distribuzione di probabilità di \\(x\\).\nPer ottenere la distribuzione marginale di \\(y\\), dobbiamo sommare o integrare \\(p(y \\mid x)\\) su tutti i possibili valori di \\(x\\):\n\\[\np(y) = \\int p(y \\mid x)p(x)dx.\n\\]\nIn questo modo, la distribuzione marginale di \\(y\\) rappresenta la probabilità di \\(y\\), tenendo conto di tutte le possibili variazioni di \\(x\\).\n\n\n37.3.3 Il Teorema di Bayes\nDalla regola di prodotto, e sfruttando la proprietà di simmetria \\(p(x \\mid y)p(y) = p(y \\mid x)p(x)\\), deriviamo immediatamente la regola di Bayes:\n\\[\np(y \\mid x) = \\frac{p(x \\mid y)p(y)}{p(x)} = \\frac{p(x \\mid y)p(y)}{\\int p(x \\mid y)p(y)dy}.\n\\]\nQuesta formula è l’elemento chiave nell’inferenza bayesiana, poiché definisce la densità a posteriori di \\(y\\), \\(p(y \\mid x)\\), dopo aver incorporato l’informazione \\(x\\) attraverso il modello di probabilità condizionata \\(p(x \\mid y)\\). La probabilità marginale di \\(x\\), \\(p(x)\\), funge da costante di normalizzazione, garantendo che \\(p(y \\mid x)\\) sia una corretta funzione di densità di probabilità.\n\n\n37.3.4 Modellizzazione e Inferenza Bayesiana\nLa modellizzazione bayesiana consiste nel descrivere matematicamente tutti i dati osservabili \\(y\\) e i parametri non osservabili, detti anche parametri “latenti” \\(\\theta\\), definendo la distribuzione congiunta di dati e parametri \\(p(y, \\theta)\\).\nSi costruiscono modelli probabilistici per le quantità osservate condizionate ai parametri \\(p(y \\mid \\theta)\\) e per le quantità non osservate, rappresentate dalla distribuzione a priori \\(p(\\theta)\\), che rappresenta le nostre conoscenze precedenti sui parametri. Questi due elementi vengono combinati, seguendo la regola del prodotto, per formare una distribuzione congiunta:\n\\[\np(y, \\theta) = p(y \\mid \\theta)p(\\theta).\n\\]\n\n\n37.3.5 Il Modello Osservazionale\nLa funzione\n\\[\np(y \\mid \\theta)\n\\]\nè un modello probabilistico dei dati osservati che mette in relazione \\(y\\) con i parametri sconosciuti \\(\\theta\\) che vogliamo stimare. Questo modello rappresenta l’evidenza fornita dai dati e costituisce la principale fonte di informazione. In questo contesto, viene chiamato funzione di verosimiglianza (likelihood). È importante notare che la funzione di verosimiglianza nel contesto bayesiano non è diversa da quella utilizzata nell’approccio frequentista: in entrambi i casi collega i dati osservati ai parametri sconosciuti.\n\n\n37.3.6 La Distribuzione a Priori\nLa distribuzione\n\\[\np(\\theta)\n\\]\nrappresenta la distribuzione a priori dei parametri, che codifica le conoscenze preesistenti sui parametri stessi. Questa distribuzione a priori può essere informativa o non informativa, a seconda della quantità di informazioni affidabili che si possiedono sui parametri. Uno degli aspetti principali che differenziano l’approccio bayesiano da quello frequentista è l’uso delle distribuzioni di probabilità per i parametri sconosciuti. Queste distribuzioni vengono poi combinate con la funzione di verosimiglianza per ottenere una distribuzione a posteriori, che incorpora sia le informazioni precedenti che le evidenze fornite dai nuovi dati.\n\n\n37.3.7 Inferenza sui Parametri\nOttenere la distribuzione a posteriori dei parametri sconosciuti è l’elemento centrale dell’approccio bayesiano. Riformulando la regola di Bayes in termini di \\(y\\) e \\(\\theta\\), otteniamo una formula che ci mostra come calcolare la distribuzione a posteriori:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)} = \\frac{p(y \\mid \\theta)p(\\theta)}{\\int p(y \\mid \\theta)p(\\theta) d\\theta}.\n\\]\nIl denominatore della regola di Bayes,\n\\[\np(y) = \\int p(y \\mid \\theta)p(\\theta) d \\theta,\n\\]\nè chiamato verosimiglianza marginale, poiché integra la verosimiglianza rispetto all’informazione a priori sui parametri. Questa quantità è anche nota come evidenza del modello e serve a normalizzare la distribuzione a posteriori, rendendola una vera distribuzione di probabilità. L’inferenza finale sarà un compromesso tra l’evidenza fornita dai dati e l’informazione a priori disponibile.\n\n\n37.3.8 Inferenza bayesiana in sintesi: verosimiglianza, prior, posteriore\nPer riassumere, ecco tutti i componenti fondamentali dell’inferenza bayesiana.\nIl teorema di Bayes, espresso in termini di dati \\(y\\) e parametri del modello \\(\\theta\\), è\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)},\n\\]\ndove:\n\nIl denominatore \\(p(y)\\) è la costante di normalizzazione o evidenza.\n\\(p(\\theta)\\) rappresenta il prior, ovvero le credenze iniziali sui parametri.\n\\(p(y \\mid \\theta)\\) è la verosimiglianza, che collega i dati osservati ai parametri del modello.\n\\(p(\\theta \\mid y)\\) è la distribuzione a posteriori, che rappresenta le credenze aggiornate sui parametri dopo aver osservato i dati.\n\nLa distribuzione a posteriori riassume il nostro stato di credenza sui possibili valori di \\(\\theta\\), aggiornato sulla base delle evidenze fornite dai dati.\nSi noti che \\(p(y)\\) non dipende dai parametri \\(\\theta\\). Pertanto, in molte situazioni pratiche, è sufficiente calcolare la distribuzione a posteriori fino a una costante. Per questo motivo, spesso la regola di Bayes viene riassunta come:\n\\[p(\\theta \\mid y) \\propto p(y \\mid \\theta)p(\\theta).\\]\nIn questa forma, si ignora il denominatore poiché è una costante (indipendente da \\(\\theta\\)).\n\n\n37.3.9 Il Ruolo dei Priors\nUna delle caratteristiche distintive dell’approccio bayesiano è l’incorporazione delle conoscenze a priori riguardo ai parametri del modello. Dichiarare questi priors ci obbliga a esplicitare tutte le assunzioni che facciamo sulla struttura del modello e sui suoi parametri. Allo stesso tempo, i priors sono spesso oggetto di critica nell’inferenza bayesiana a causa della soggettività che possono introdurre.\nTuttavia, l’inferenza bayesiana offre alcuni vantaggi meno evidenti a prima vista, tra cui:\n\nla capacità di lavorare efficacemente con piccoli set di dati,\nla capacità di eseguire la regolarizzazione del modello.\n\nQuesti aspetti rendono l’approccio bayesiano particolarmente utile in situazioni in cui i dati sono scarsi o le assunzioni esplicite sul modello possono contribuire a migliorare le previsioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#inferenza-predittiva",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#inferenza-predittiva",
    "title": "37  Inferenza bayesiana",
    "section": "37.4 Inferenza Predittiva",
    "text": "37.4 Inferenza Predittiva\nLa distribuzione a posteriori dei parametri può essere utilizzata per modellare l’incertezza nelle previsioni \\(\\tilde{y}\\) relative a nuove osservazioni. La distribuzione predittiva a posteriori di \\(\\tilde{y}\\) si ottiene marginalizzando la distribuzione congiunta delle previsioni \\(\\tilde{y}\\) e dei parametri \\(\\theta\\) rispetto ai parametri del modello:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y}, \\theta \\mid y)d \\theta = \\int p(\\tilde{y} \\mid \\theta, y)p(\\theta|y)d\\theta.\n\\]\nIn questo modo, la distribuzione predittiva può essere vista come una media delle previsioni del modello \\(p(\\tilde{y} \\mid \\theta, y)\\) ponderata sulla distribuzione a posteriori dei parametri del modello \\(p(\\theta \\mid y)\\). Questo consente di incorporare l’incertezza sui parametri nel processo di previsione, rendendo le stime più robuste.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#come-possiamo-eseguire-linferenza-bayesiana",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#come-possiamo-eseguire-linferenza-bayesiana",
    "title": "37  Inferenza bayesiana",
    "section": "37.5 Come possiamo eseguire l’inferenza bayesiana?",
    "text": "37.5 Come possiamo eseguire l’inferenza bayesiana?\nEsistono due approcci principali per determinare la distribuzione posteriore:\n\nApproccio Analitico (o Coniugato): Questo metodo è applicabile quando la distribuzione a priori scelta e la funzione di verosimiglianza appartengono alla stessa famiglia di distribuzioni, definite coniugate. In questi casi, la distribuzione posteriore può essere calcolata analiticamente, ovvero attraverso formule matematiche esatte. L’approccio coniugato è computazionalmente efficiente ma presenta una limitazione significativa: è applicabile solo in situazioni in cui si può assumere una coniugazione tra la distribuzione a priori e la verosimiglianza. Di conseguenza, trova un impiego limitato nelle analisi di dati reali, dove spesso le assunzioni di coniugazione risultano troppo restrittive.\nApproccio Numerico: Quando non è possibile ottenere una forma analitica chiusa per la distribuzione posteriore, a causa della complessità del modello o della mancanza di coniugazione tra la distribuzione a priori e la verosimiglianza, si ricorre a metodi numerici. Questi algoritmi consentono di ottenere una stima approssimata, ma spesso accurata, della distribuzione posteriore.\n\n\n37.5.1 Metodi Numerici\nLe catene di Markov Monte Carlo (MCMC) sono una classe di algoritmi ampiamente utilizzati in questo contesto. Essi costruiscono una catena di Markov che converge alla distribuzione posteriore desiderata. Tra i metodi MCMC più comuni troviamo:\n\nMetropolis-Hastings: Un algoritmo generale che consente di campionare da una vasta gamma di distribuzioni posteriori.\nGibbs Sampling: Un caso particolare di Metropolis-Hastings, particolarmente efficiente quando la distribuzione congiunta è difficile da campionare direttamente, ma le distribuzioni condizionali sono note.\n\nOltre alle MCMC, esistono altre tecniche numeriche:\n\nVariational Bayes: Questo approccio consiste nel trovare la distribuzione \\(q(z)\\) che meglio approssima la distribuzione posteriore \\(p(z \\mid x)\\), secondo un criterio di divergenza (ad esempio, la divergenza di Kullback-Leibler). L’obiettivo è trasformare il problema di inferenza esatta in un problema di ottimizzazione. Variational Bayes offre spesso una soluzione più veloce rispetto alle MCMC, ma l’approssimazione può essere meno accurata in alcuni casi.\nLaplace approximation: Questa tecnica consiste nell’approssimare la distribuzione posteriore con una distribuzione normale centrata sul massimo a posteriori (MAP) e con matrice di covarianza pari all’inverso della matrice di Hessiano negativa calcolata nel MAP. L’approssimazione di Laplace è computazionalmente efficiente, ma è valida solo localmente attorno al MAP e può portare a stime inaccurate della varianza posteriore.\n\nVantaggi:\n\nVersatilità: L’approccio numerico è applicabile a una vasta gamma di modelli e distribuzioni.\nFlessibilità: Consente di incorporare facilmente informazioni a priori complesse.\n\nSvantaggi:\n\nCosto computazionale: Può richiedere un tempo di calcolo considerevole, soprattutto per modelli complessi o grandi dataset.\nTuning: La scelta dei parametri degli algoritmi MCMC (ad esempio, la proposta iniziale) può influenzare la convergenza e l’efficienza del campionamento.\n\nIn sintesi, l’approccio numerico offre una soluzione generale e flessibile per l’inferenza bayesiana, ma richiede una maggiore attenzione alla scelta degli algoritmi e alla valutazione della convergenza delle catene.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#programmazione-probabilistica",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#programmazione-probabilistica",
    "title": "37  Inferenza bayesiana",
    "section": "37.6 Programmazione Probabilistica",
    "text": "37.6 Programmazione Probabilistica\nI linguaggi di programmazione probabilistica (PPL) rappresentano un’importante innovazione nella modellazione bayesiana, facilitando l’uso di tecniche di approssimazione numerica per stimare le distribuzioni posteriori. Grazie ai PPL, la modellizzazione probabilistica diventa più accessibile, riducendo le barriere tecniche e computazionali. Questi strumenti consentono di definire modelli in modo dichiarativo, descrivendo le relazioni tra le variabili in termini probabilistici senza doversi occupare dei dettagli algoritmici sottostanti. In altre parole, i PPL permettono ai ricercatori di concentrarsi sull’espressione del modello, lasciando ai linguaggi il compito di gestire l’implementazione computazionale.\nTra i PPL più utilizzati troviamo:\n\nStan: Uno dei linguaggi più popolari, noto per la sua efficienza e flessibilità.\nPyMC: Molto utilizzato nell’ecosistema Python, offre un’interfaccia user-friendly per la modellazione bayesiana.\nTensorFlow: Un framework che combina un approccio probabilistico con le reti neurali.\n\n\n37.6.1 Vantaggi della Programmazione Probabilistica in Psicologia\nLa programmazione probabilistica offre numerosi vantaggi per la ricerca psicologica, in particolare per l’analisi di processi complessi come l’apprendimento, le emozioni e il comportamento. Alcuni dei principali vantaggi includono:\n\nFlessibilità: I PPL, come Stan, Pyro, Numpyro, PyMC e Turing.jl, offrono un quadro flessibile per la definizione e la personalizzazione dei modelli probabilistici. In psicologia, questa flessibilità è cruciale, poiché i modelli devono adattarsi a una vasta gamma di processi mentali e comportamentali che variano tra individui e contesti.\nQuantificazione dell’Incertezza: La programmazione probabilistica permette di rappresentare esplicitamente e quantificare l’incertezza, un aspetto fondamentale in psicologia, dove molte variabili di interesse, come stati emotivi o atteggiamenti, sono latenti e soggette a incertezza. Incorporare questa incertezza nei modelli consente di ottenere stime più realistiche e affidabili.\nValidazione del Modello: I PPL facilitano la validazione dei modelli psicologici, consentendo ai ricercatori di confrontare le previsioni dei modelli con i dati osservati. Tecniche come i posterior predictive checks permettono di valutare la qualità e l’affidabilità del modello, contribuendo a una maggiore solidità delle conclusioni.\nModellazione Gerarchica: Molti studi psicologici raccolgono dati a più livelli (ad esempio, misurazioni ripetute per individuo, sessioni sperimentali, contesti diversi). I PPL semplificano la costruzione e l’analisi di modelli gerarchici, catturando la variabilità sia intra- che inter-individuale.\nSelezione e Confronto dei Modelli: In psicologia è spesso necessario confrontare modelli con strutture diverse o ipotesi alternative. I PPL permettono di confrontare le capacità predittive dei modelli in modo sistematico e rigoroso, supportando la scelta del modello più adatto basandosi sull’accuratezza predittiva e non solo sulla complessità.\nComunicazione Trasparente: La programmazione probabilistica favorisce la trasparenza nella modellizzazione. I ricercatori possono specificare chiaramente le assunzioni del modello, i prior e le funzioni di verosimiglianza, rendendo più facile la comunicazione e la collaborazione con altri esperti.\nLibrerie Estensibili: I PPL offrono librerie estese e strumenti avanzati per lo sviluppo di modelli, l’inferenza e la visualizzazione. Questo riduce il carico computazionale e di implementazione, rendendo più agevole l’analisi di dati complessi tipici della psicologia sperimentale e clinica.\n\n\n\n37.6.2 Come Funzionano i PPL?\nI linguaggi di programmazione probabilistica richiedono semplicemente la descrizione del modello probabilistico. Successivamente, utilizzano algoritmi di inferenza, come le catene di Markov Monte Carlo (MCMC) o l’inferenza variazionale, per stimare la distribuzione posteriore delle variabili di interesse. Ciò consente ai ricercatori di ottenere stime delle variabili sconosciute e di valutare l’incertezza associata.\nIn conclusione, i linguaggi di programmazione probabilistica hanno trasformato il modo in cui affrontiamo l’inferenza bayesiana, rendendola più accessibile e potente. Grazie alla loro semplicità d’uso e alla potenza computazionale, i PPL hanno reso l’inferenza bayesiana uno strumento sempre più diffuso in molte discipline, inclusa la psicologia. Questo approccio facilita la modellazione di fenomeni complessi e l’analisi rigorosa di dati, offrendo un metodo efficace per rispondere a domande di ricerca psicologica in modo trasparente e accurato.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#notazione",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#notazione",
    "title": "37  Inferenza bayesiana",
    "section": "37.7 Notazione",
    "text": "37.7 Notazione\nIn seguito, utilizzeremo \\(y\\) per rappresentare i dati osservati e \\(\\theta\\) per indicare i parametri sconosciuti di un modello statistico. Entrambi, \\(y\\) e \\(\\theta\\), saranno trattati come variabili casuali. Utilizzeremo \\(x\\) per denotare le quantità note, come i predittori di un modello lineare.\nÈ comune scrivere modelli statistici utilizzando la seguente notazione:\n\\[\n\\begin{aligned}\ny & \\sim \\mathrm{normal}(\\mu, \\sigma) \\\\\n\\mu & \\sim \\mathrm{normal}(0, 10) \\\\\n\\sigma & \\sim \\mathrm{normal}^+(\\sigma \\mid  0, 1),\n\\end{aligned}\n\\]\ndove il simbolo \\(\\sim\\) è chiamato tilde (\\sim in LaTeX).\nIn generale, possiamo leggere \\(\\sim\\) come “è distribuito come”, e questa notazione è usata come una scorciatoia per definire distribuzioni. L’esempio sopra può essere scritto anche come:\n\\[\n\\begin{aligned}\n   p(y \\mid \\mu, \\sigma) & = \\mathrm{normal}(y \\mid  \\mu, \\sigma)\\\\\n   p(\\mu) & = \\mathrm{normal}(\\mu \\mid 0, 10)\\\\\n   p(\\sigma) & = \\mathrm{normal}^+(\\sigma \\mid  0, 1).\n\\end{aligned}\n\\]",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#addendum-la-verosimiglianza-marginale",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#addendum-la-verosimiglianza-marginale",
    "title": "37  Inferenza bayesiana",
    "section": "37.8 Addendum: La Verosimiglianza Marginale",
    "text": "37.8 Addendum: La Verosimiglianza Marginale\nNella discussione precedente, abbiamo introdotto la verosimiglianza marginale \\(p(y)\\) come una costante di normalizzazione. Ma perché è così importante normalizzare la distribuzione posteriore? La verosimiglianza marginale rappresenta la probabilità dei dati osservati, integrata su tutti i possibili valori del parametro \\(\\theta\\). In altre parole, esprime la probabilità di osservare i dati senza fare riferimento a un particolare valore del parametro.\nPer comprendere intuitivamente, immagina di voler stimare la temperatura media di una stanza. Usando un termometro, ottieni una misurazione, ma sei consapevole che variabili come la posizione del termometro o l’ora del giorno potrebbero influenzare la lettura. La verosimiglianza marginale è equivalente a considerare la probabilità di ottenere una certa misurazione, prendendo in considerazione tutte queste possibili variabili.\nSenza la normalizzazione, la somma delle probabilità assegnate ai diversi valori del parametro non sarebbe uguale a 1, il che significherebbe che non avremmo una distribuzione di probabilità valida. Questo renderebbe difficile interpretare correttamente i risultati. La verosimiglianza marginale agisce come una costante di normalizzazione, garantendo che l’area sotto la curva della distribuzione posteriore sia esattamente pari a 1, come richiesto da una distribuzione di probabilità.\nLa verosimiglianza marginale si calcola integrando (o sommando, nel caso di parametri discreti) la funzione di verosimiglianza rispetto a tutti i possibili valori del parametro, pesando ciascun valore con la sua probabilità a priori.\nConsideriamo un esempio con una variabile casuale binomiale \\(Y\\), la cui funzione di massa di probabilità (PMF) \\(p(Y)\\) dipende dal parametro \\(\\theta\\). Supponiamo che \\(\\theta\\) possa assumere uno tra tre valori specifici: 0.1, 0.5 o 0.9, ciascuno con una probabilità a priori di \\(\\frac{1}{3}\\).\nSe i dati indicano \\(n = 10\\) prove e \\(k = 7\\) successi, la funzione di verosimiglianza è data da:\n\\[\np(k = 7, n = 10 \\mid \\theta) = \\binom{10}{7} \\theta^7 (1 - \\theta)^3.\n\\]\nPer calcolare la verosimiglianza marginale \\(p(k = 7, n = 10)\\), marginalizziamo su \\(\\theta\\), valutando la verosimiglianza per ciascun valore di \\(\\theta\\), moltiplicando per la probabilità a priori di ciascun \\(\\theta\\), e sommando i risultati:\n\\[\np(k = 7, n = 10) = \\sum_{i=1}^{3} p(k = 7, n = 10 \\mid \\theta_i) \\cdot p(\\theta_i).\n\\]\nSostituendo i valori di \\(\\theta\\) e le probabilità corrispondenti:\n\\[\np(k = 7, n = 10) = \\frac{1}{3} \\binom{10}{7} 0.1^7 (1 - 0.1)^3 + \\frac{1}{3} \\binom{10}{7} 0.5^7 (1 - 0.5)^3 + \\frac{1}{3} \\binom{10}{7} 0.9^7 (1 - 0.9)^3.\n\\]\nQuesto calcolo dimostra come la marginalizzazione su \\(\\theta\\) incorpori tutte le sue possibili variazioni, ottenendo una stima complessiva che tiene conto dell’incertezza su \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#implementazione-in-r",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#implementazione-in-r",
    "title": "37  Inferenza bayesiana",
    "section": "37.9 Implementazione in R",
    "text": "37.9 Implementazione in R\nPer calcolare la verosimiglianza marginale in R, possiamo distinguere tra il caso discreto (in cui \\(\\theta\\) assume valori specifici) e il caso continuo (in cui \\(\\theta\\) è trattato come una variabile continua su un intervallo). Per il caso discreto, sommiamo direttamente i contributi della funzione di verosimiglianza pesati dalla probabilità a priori. Per il caso continuo, utilizziamo l’integrazione numerica.\n\n37.9.1 Caso discreto\nNel caso in cui \\(\\theta\\) assuma valori discreti, possiamo implementare il calcolo della verosimiglianza marginale sommando i prodotti della verosimiglianza \\(p(k \\mid \\theta)\\) e della probabilità a priori \\(p(\\theta)\\):\n\n# Funzione di verosimiglianza per il caso binomiale\nlikelihood_binomial &lt;- function(theta, k, n) {\n  return(choose(n, k) * (theta^k) * ((1 - theta)^(n - k)))\n}\n\n# Valori di theta e probabilità a priori\ntheta_values &lt;- c(0.1, 0.5, 0.9)\nprior &lt;- rep(1 / length(theta_values), length(theta_values)) # Prior uniforme\nk &lt;- 7\nn &lt;- 10\n\n# Calcolo della verosimiglianza marginale discreta\nmarginal_likelihood_discrete &lt;- sum(prior * sapply(theta_values, likelihood_binomial, k = k, n = n))\n\ncat(sprintf(\"Likelihood Marginale (discreta): %.4f\\n\", marginal_likelihood_discrete))\n#&gt; Likelihood Marginale (discreta): 0.0582\n\nIl risultato rappresenta la verosimiglianza marginale calcolata sommando i contributi discreti.\n\n\n37.9.2 Caso continuo\nNel caso in cui \\(\\theta\\) sia una variabile continua definita su \\([0, 1]\\), utilizziamo l’integrazione numerica per calcolare la verosimiglianza marginale. L’approccio assume una distribuzione a priori uniforme su \\([0, 1]\\) (se non diversamente specificato):\n\n# Funzione per il calcolo della verosimiglianza marginale continua\nlikelihood_binomial_continuous &lt;- function(theta, k, n) {\n  # La verosimiglianza è 0 per valori di theta fuori dall'intervallo [0, 1]\n  theta[theta &lt; 0 | theta &gt; 1] &lt;- 0\n  return(choose(n, k) * (theta^k) * ((1 - theta)^(n - k)))\n}\n\n# Parametri\nk &lt;- 7\nn &lt;- 10\n\n# Calcolo dell'integrale numerico\nmarginal_likelihood_continuous &lt;- \n  integrate(\n    function(theta) likelihood_binomial_continuous(theta, k, n), \n    lower = 0, \n    upper = 1\n  )$value\n\ncat(\n  sprintf(\n    \"Likelihood Marginale (continua): %.4f\\n\", \n    marginal_likelihood_continuous)\n)\n#&gt; Likelihood Marginale (continua): 0.0909\n\nQui l’integrazione numerica restituisce la verosimiglianza marginale considerando \\(\\theta\\) come una variabile continua.\n\n\n37.9.3 Caso continuo con prior Beta\nPer utilizzare una distribuzione a priori diversa (ad esempio, una distribuzione Beta), è necessario moltiplicare la funzione di verosimiglianza per la densità della distribuzione a priori:\n\n# Funzione prior Beta\nprior_beta &lt;- function(theta, alpha, beta) {\n  return(dbeta(theta, alpha, beta))\n}\n\n# Funzione combinata di verosimiglianza e prior\nlikelihood_with_beta_prior &lt;- function(theta, k, n, alpha_prior, beta_prior) {\n  # La verosimiglianza è 0 per valori di theta fuori dall'intervallo [0, 1]\n  valid_theta &lt;- (theta &gt;= 0 & theta &lt;= 1)\n  likelihood &lt;- ifelse(valid_theta, choose(n, k) * (theta^k) * ((1 - theta)^(n - k)), 0)\n  prior &lt;- ifelse(valid_theta, prior_beta(theta, alpha_prior, beta_prior), 0)\n  return(likelihood * prior)\n}\n\n# Parametri\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\nk &lt;- 7\nn &lt;- 10\n\n# Calcolo dell'integrale numerico con prior Beta\nmarginal_likelihood_continuous_beta &lt;- integrate(\n  function(theta) likelihood_with_beta_prior(theta, k, n, alpha_prior, beta_prior),\n  lower = 0, upper = 1\n)$value\n\ncat(sprintf(\"Likelihood Marginale con prior Beta: %.4f\\n\", marginal_likelihood_continuous_beta))\n#&gt; Likelihood Marginale con prior Beta: 0.1119\n\nIn questo caso, la distribuzione a priori Beta(2,2) dà maggiore peso ai valori centrali di \\(\\theta\\), riflettendo una conoscenza a priori che privilegia valori intermedi. Il calcolo combina la verosimiglianza e il prior per fornire una verosimiglianza marginale ponderata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#riflessioni-conclusive",
    "title": "37  Inferenza bayesiana",
    "section": "37.10 Riflessioni Conclusive",
    "text": "37.10 Riflessioni Conclusive\nAl cuore della ricerca scientifica c’è una domanda del tipo: “dimmi qualcosa sulla variabile \\(\\theta\\) dato che ho osservato i dati \\(D\\) e ho una certa conoscenza del meccanismo sottostante che genera i dati”. La regola di Bayes fornisce la seguente risposta:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid\\theta) p(\\theta)}{p(D)} = \\frac{p(D \\mid \\theta) p(\\theta)}{\\int_\\theta p(D \\mid\\theta) p(\\theta) d\\theta}.\n\\]\nQuesta equazione mostra come, partendo da un modello generativo \\(p(D \\mid\\theta)\\) dei dati osservati e abbinato a una credenza a priori \\(p(\\theta)\\) su quali valori della variabile \\(\\theta\\) siano plausibili, possiamo inferire la distribuzione a posteriori \\(p(\\theta \\mid D)\\) della variabile alla luce dei dati osservati.\nLa stima MAP (Massimo A Posteriori), che corrisponde al valore di \\(\\theta\\) che massimizza la distribuzione a posteriori, rappresenta una stima puntuale del parametro:\n\\[\n\\theta^* = \\arg \\max_\\theta p(\\theta \\mid D).\n\\]\nNel caso di un prior non informativo (piatto), la stima MAP coincide con la stima di massima verosimiglianza, ovvero il valore di \\(\\theta\\) che massimizza la probabilità che il modello generi i dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "title": "37  Inferenza bayesiana",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#bibliografia",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#bibliografia",
    "title": "37  Inferenza bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html",
    "href": "chapters/bayesian_inference/03_subj_prop.html",
    "title": "38  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nLeggere il settimo capitolo del libro di Albert & Hu (2019).\nConcetti e Competenze Chiave\nPreparazione del Notebook\nL’inferenza bayesiana è un metodo di inferenza statistica che utilizza la probabilità per aggiornare le credenze sui parametri di un modello, sulla base di nuove evidenze o dati osservati. Essa fornisce un quadro concettuale per stimare variabili sconosciute, tenendo conto dell’incertezza. Attraverso un modello che descrive le dipendenze tra variabili aleatorie, la teoria della probabilità può essere impiegata per inferire tutte le quantità sconosciute. In questo approccio, tutte le incertezze, sia nelle osservazioni che nei parametri del modello, sono trattate come distribuzioni di probabilità.\nIn sintesi, l’inferenza bayesiana è il processo di deduzione delle proprietà di una distribuzione di probabilità a partire dai dati, utilizzando il teorema di Bayes. Questo processo incorpora l’idea che la probabilità rappresenti una misura della fiducia su una previsione o un risultato.\nQuesto capitolo ha lo scopo di esplorare in dettaglio il concetto di aggiornamento bayesiano, illustrandolo con un esempio concreto in un contesto semplificato. L’obiettivo è dimostrare come le credenze preesistenti sulla probabilità di un parametro \\(\\theta\\) possano essere aggiornate attraverso l’osservazione di nuovi dati.\nIl primo passo nell’inferenza bayesiana consiste nel rappresentare le credenze iniziali, formulate prima di raccogliere i dati, tramite una distribuzione a priori. La distribuzione a priori riflette le nostre conoscenze o ipotesi preesistenti su \\(\\theta\\) e può variare in base al contesto o alle informazioni pregresse disponibili.\nUna volta ottenuti nuovi dati, il passaggio successivo è l’aggiornamento delle credenze tramite la distribuzione a posteriori. Questo aggiornamento si ottiene moltiplicando la distribuzione a priori per la verosimiglianza dei dati osservati, il che riflette quanto i dati supportino un determinato valore di \\(\\theta\\). Il prodotto di questi due termini fornisce una misura delle credenze aggiornate, che viene successivamente normalizzata per garantire che il risultato sia una distribuzione di probabilità valida (ovvero, che l’area sotto la curva sia pari a 1).\nIl capitolo si concentra sul modello binomiale. Questo modello è utilizzato per stimare una proporzione sconosciuta basata su una serie di dati binari \\(y_1, \\ldots, y_n\\), ciascuno dei quali può assumere valore 0 o 1.\nInizieremo esplorando un esempio in cui la distribuzione a priori di \\(\\theta\\) è discreta, un caso in cui i valori possibili di \\(\\theta\\) sono limitati a un insieme finito di opzioni. Successivamente, discuteremo scenari in cui la distribuzione a priori è continua, ampliando il modello per affrontare casi più complessi e realistici. Questo approccio progressivo consente di acquisire una comprensione graduale dei concetti centrali dell’inferenza bayesiana e del loro utilizzo pratico nel contesto di problemi statistici reali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#introduzione",
    "href": "chapters/bayesian_inference/03_subj_prop.html#introduzione",
    "title": "38  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "L’unica cosa rilevante è l’incertezza – il grado della nostra conoscenza e ignoranza. Il fatto che gli eventi considerati siano in qualche modo determinati, o conosciuti da altre persone, non ha alcuna importanza.\n(Bruno deFinetti)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/bayesian_inference/03_subj_prop.html#verosimiglianza-binomiale",
    "title": "38  Pensare ad una proporzione in termini soggettivi",
    "section": "38.1 Verosimiglianza Binomiale",
    "text": "38.1 Verosimiglianza Binomiale\nLa distribuzione binomiale offre un modello naturale per dati che derivano da una sequenza di \\(n\\) prove indipendenti e identicamente distribuite, dove ciascuna prova dà origine a uno dei due possibili esiti, convenzionalmente etichettati come ‘successo’ e ‘fallimento’. Grazie al fatto che le prove sono iid, i dati possono essere riassunti dal numero totale di successi nelle \\(n\\) prove, che denotiamo con \\(y\\). Il parametro \\(\\theta\\) rappresenta la proporzione di successi nella popolazione o, equivalentemente, la probabilità di successo in ciascuna prova. Il modello di campionamento binomiale è:\n\\[\np(y \\mid \\theta) = \\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y},\n\\]\ndove nella parte sinistra dell’equazione non si indica la dipendenza da \\(n\\) perché viene considerato parte del disegno sperimentale e fissato; tutte le probabilità discusse per questo problema sono considerate condizionate su \\(n\\), cioè assumono che il numero totale di prove sia fissato e noto.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "href": "chapters/bayesian_inference/03_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "title": "38  Pensare ad una proporzione in termini soggettivi",
    "section": "38.2 Applicazione Specifica del Modello Binomiale",
    "text": "38.2 Applicazione Specifica del Modello Binomiale\nIn questo capitolo, esaminiamo un’applicazione specifica del modello binomiale per valutare la prestazione di un partecipante in un classico esperimento di psicologia, noto come Go/No-Go task (Shiffrin & Schneider, 1977). In questo tipo di compito, ai partecipanti viene richiesto di rispondere a determinati stimoli (prove Go) e di trattenere la risposta ad altri stimoli (prove No-Go). Ad esempio, i partecipanti possono vedere una serie di lettere presentate su uno schermo e devono premere un pulsante quando vedono qualsiasi lettera tranne una specifica lettera bersaglio (ad esempio, la lettera “X”). In questo esperimento, ogni prova rappresenta un evento di tipo bernoulliano con due possibili esiti: o il partecipante risponde correttamente o commette un errore. I ricercatori analizzano la percentuale di risposte corrette e di inibizioni, concentrandosi in particolare sulla capacità del partecipante di controllare l’impulso di rispondere durante le prove No-Go.\nConsideriamo un piccolo numero di prove No-Go di un partecipante, dove i risultati sono: 1, 0, 1, 1, 1, 0, 1, 0, 1. Qui, il valore “1” indica che il partecipante è stato in grado di inibire la risposta, mentre “0” indica che non è riuscito a farlo. L’obiettivo dell’analisi è quantificare l’incertezza nella stima di \\(\\theta\\), che rappresenta la proporzione di risposte corrette nel compito No-Go, ovvero la capacità inibitoria del partecipante.\nConsideriamo questi dati come una sequenza di 9 prove bernoulliane indipendenti. Utilizzando il modello binomiale, stimiamo la probabilità \\(\\theta\\) che il partecipante riesca a controllare il proprio impulso di rispondere durante le prove No-Go e quantifichiamo l’incertezza associata a questa stima.\n\n38.2.1 Processo di Lavoro\nMcElreath (2020) descrive il flusso lavoro bayesiano nel modo seguente.\n\nDefinire un Modello Generativo per i Dati: Un modello generativo descrive il processo attraverso il quale i dati vengono prodotti. Nel contesto del compito No-Go, consideriamo ogni prova come un processo di Bernoulli con due possibili esiti: una prestazione corretta, ovvero l’inibizione della risposta (rappresentata da 1), oppure una prestazione errata, ovvero la mancata inibizione della risposta (rappresentata da 0). Definiamo \\(\\theta\\) come la probabilità di ottenere una prestazione corretta nel compito No-Go. Il modello generativo per questi dati può essere formalizzato come:\n\\[\nX_i \\sim \\text{Bernoulli}(\\theta),\n\\]\ndove \\(i = 1, 2, \\dots, 9\\) e \\(X_i\\) assume il valore 1 in caso di prestazione corretta e 0 in caso di prestazione errata nel compito No-Go.\nDefinire uno Stimatore per il Parametro di Interesse: Uno stimatore è una regola o una formula che utilizza i dati campionari per fornire una stima del parametro di interesse. Nel nostro caso, lo stimatore di interesse è la probabilità \\(\\theta\\) di inibire correttamente la risposta durante le prove No-Go. L’obiettivo è non solo calcolare questa probabilità, ma anche quantificare l’incertezza associata alla stima di \\(\\theta\\), basandoci sui dati raccolti.\nSviluppare un Metodo Statistico per la Stima del Parametro di Interesse: Per stimare \\(\\theta\\), utilizziamo l’approccio bayesiano. In statistica bayesiana, si parte da una distribuzione a priori che rappresenta le nostre convinzioni iniziali su \\(\\theta\\), e poi si aggiorna questa distribuzione alla luce dei dati osservati per ottenere una distribuzione a posteriori. Nel contesto di un modello Bernoulli/Binomiale, una scelta comune per la distribuzione a priori è la distribuzione Beta. In questo caso, iniziamo con una distribuzione a priori non informativa, \\(\\text{Beta}(1, 1)\\), che corrisponde a una distribuzione uniforme su \\(\\theta\\).\nLa verosimiglianza dei nostri dati (6 “successi”, 3 “insuccessi”) è data dalla distribuzione binomiale:\n\\[\nL(p) = {9 \\choose 6} \\theta^{6} (1-\\theta)^{3}.\n\\]\nUtilizziamo il teorema di Bayes per combinare priori e verosimiglianza e ottenere la distribuzione a posteriori:\n\\[\n\\text{Posteriore} \\propto \\text{Verosimiglianza} \\times \\text{Priori}\n\\]\nValidazione del Modello tramite Simulazioni:\nPrima di analizzare i dati reali, eseguiamo una simulazione predittiva a priori per verificare se il modello è in grado di generare dati plausibili. Successivamente, dopo aver adattato il modello ai dati osservati, conduciamo una simulazione predittiva a posteriori per valutare la capacità del modello di riprodurre dati simili a quelli effettivamente osservati.\nAnalisi e Sintesi dei Risultati:\nInfine, analizziamo i dati reali calcolando la distribuzione a posteriori, tipicamente tramite metodi computazionali come il Monte Carlo a catene di Markov (MCMC). Riassumiamo questa distribuzione per fare inferenze su \\(\\theta\\), utilizzando statistiche descrittive come la media, la mediana e gli intervalli di credibilità.\n\nNel corso di questo capitolo, illustreremo come generare numericamente la distribuzione a posteriori, mentre nei capitoli successivi approfondiremo ulteriormente le varie fasi del flusso di lavoro proposto da McElreath (2020).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "title": "38  Pensare ad una proporzione in termini soggettivi",
    "section": "38.3 Metodo Basato su Griglia nell’Aggiornamento Bayesiano",
    "text": "38.3 Metodo Basato su Griglia nell’Aggiornamento Bayesiano\nDopo aver discusso l’aggiornamento bayesiano e come permette di raffinare le nostre convinzioni preesistenti alla luce di nuove evidenze, esploreremo ora una tecnica specifica per realizzare questo aggiornamento: il metodo basato su griglia.\nIl metodo basato su griglia è un approccio semplice e intuitivo per stimare la distribuzione a posteriori, particolarmente utile quando non sono disponibili soluzioni analitiche esatte o si desidera evitare l’uso di algoritmi computazionali complessi. La procedura si articola nei seguenti passi:\n\nSelezione di un intervallo per il parametro: Basandosi sulle convinzioni a priori, si definisce un intervallo ragionevole per il parametro di interesse.\nCreazione di una griglia di punti: Su questo intervallo, si distribuiscono una serie di punti, di solito equidistanti tra loro.\nCalcolo della posteriori per ogni punto: Per ogni punto della griglia, si moltiplica la verosimiglianza per il prior corrispondente.\nNormalizzazione dei risultati: Per garantire che la somma delle probabilità sia pari a 1, si normalizzano i valori ottenuti dividendo ciascun punto per l’area totale sottesa dalla curva della distribuzione a posteriori.\n\nAttraverso questo metodo, si ottiene una rappresentazione approssimativa ma illustrativa della distribuzione a posteriori. Questo approccio offre un modo accessibile per visualizzare e comprendere il processo di aggiornamento bayesiano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "href": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "title": "38  Pensare ad una proporzione in termini soggettivi",
    "section": "38.4 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta",
    "text": "38.4 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta\n\n38.4.1 Distribuzione a priori\nQuando non disponiamo di informazioni specifiche preliminari su \\(\\theta\\), potremmo inizialmente assegnare un valore di 0.5, suggerendo una probabilità a priori uniforme tra le due alternative (la capacità di inibire la risposta e la mancanza di questa capacità in una prova del compito Go/No-Go). Tuttavia, questo valore non rappresenta adeguatamente l’intero spettro della nostra incertezza iniziale.\nPer riflettere meglio questa incertezza, utilizziamo una distribuzione a priori discreta, che assegna una probabilità distinta a ciascun valore plausibile di \\(\\theta\\). Questo approccio ci permette di quantificare le nostre convinzioni preliminari sulla distribuzione di questi valori.\nSupponiamo di considerare undici possibili valori per \\(\\theta\\), che variano da 0 a 1 con incrementi di 0.1. Possiamo attribuire a ciascun valore una probabilità a priori uguale, creando così una distribuzione uniforme, oppure scegliere una distribuzione non uniforme che meglio rifletta le nostre aspettative sui valori di \\(\\theta\\) più probabili.\nDopo aver osservato i dati — nel nostro caso, 6 successi in 9 prove — applichiamo il teorema di Bayes per trasformare la distribuzione a priori in una distribuzione a posteriori. Questo processo consiste nel combinare la probabilità a priori di \\(\\theta\\) con la verosimiglianza dei dati per produrre una probabilità a posteriori aggiornata per \\(\\theta\\).\n\n\n38.4.2 Distribuzione a Posteriori in R\nLa distribuzione a posteriori combina le informazioni a priori con i dati osservati, aggiornando le nostre credenze riguardo al parametro \\(\\theta\\). Vediamo passo passo come implementare il calcolo della distribuzione a posteriori e delle relative quantità in R, partendo dalla rappresentazione discreta di \\(\\theta\\).\n\n38.4.2.1 1. Definizione di \\(\\theta\\)\nIniziamo definendo un insieme discreto di valori per \\(\\theta\\).\n\ntheta &lt;- seq(0, 1, by = 0.1)\ntheta\n#&gt;  [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\n\n38.4.2.2 2. Distribuzione a Priori Uniforme\nSe non abbiamo motivi per preferire alcuni valori di \\(\\theta\\), assegniamo probabilità uguali a tutti i valori. Standardizziamo la distribuzione affinché le probabilità si sommino a 1.\n\nunif_prior &lt;- rep(1 / length(theta), length(theta))\nprint(unif_prior)\n#&gt;  [1] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n#&gt;  [7] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n\n\nsum(unif_prior) # Verifica che le probabilità sommino a 1\n#&gt; [1] 1\n\nVisualizziamo questa distribuzione a priori uniforme:\n\nplot(\n  theta, \n  unif_prior, \n  type = \"h\", \n  lwd = 2, \n  main = \"Distribuzione a Priori (Uniforme)\",\n  xlab = expression(theta), \n  ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\n\n\n\n38.4.2.3 3. Distribuzione a Priori Non Uniforme\nSe riteniamo più probabili i valori centrali di \\(\\theta\\), definiamo una distribuzione a priori discreta non uniforme:\n\nnot_unif_prior &lt;- \n  c(0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05)\nplot(\n  theta, \n  not_unif_prior, \n  type = \"h\", \n  lwd = 2, \n  main = \"Distribuzione a Priori (Non Uniforme)\",\n  xlab = expression(theta), \n  ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\n\n\n\n38.4.2.4 4. Calcolo della Verosimiglianza\nLa funzione di verosimiglianza per il modello binomiale è definita come segue:\n\nlikelihood &lt;- dbinom(6, size = 9, prob = theta)\n\n\nlikelihood &lt;- likelihood / sum(likelihood) # Normalizzazione\n\n\nplot(\n  theta, \n  likelihood, \n  type = \"h\",\n  lwd = 2, \n  main = \"Funzione di Verosimiglianza\",\n  xlab = expression(theta), \n  ylab = expression(L(theta))\n)\n\n\n\n\n\n\n\n\n\n\n38.4.2.5 5. Distribuzione a Posteriori\nLa distribuzione a posteriori si calcola moltiplicando elemento per elemento la distribuzione a priori e la verosimiglianza, quindi dividendo per la probabilità marginale dei dati (normalizzazione).\n\npost &lt;- (not_unif_prior * likelihood) / sum(not_unif_prior * likelihood)\nprint(post)\n#&gt;  [1] 0.000000e+00 2.118359e-05 9.521865e-04 7.265973e-03 8.998163e-02\n#&gt;  [6] 1.986416e-01 3.036880e-01 3.230667e-01 6.093994e-02 1.544284e-02\n#&gt; [11] 0.000000e+00\n\n\nsum(post) # Verifica che sommi a 1\n#&gt; [1] 1\n\nVisualizziamo la distribuzione a posteriori:\n\nplot(\n  theta, \n  post, \n  type = \"h\", \n  lwd = 2, \n  main = \"Distribuzione a Posteriori\",\n  xlab = expression(theta), \n  ylab = expression(f(theta))\n)\n\n\n\n\n\n\n\n\n\n\n38.4.2.6 6. Quantità a Posteriori\n\nMedia a Posteriori: Calcolata come il valore atteso di \\(\\theta\\) sotto la distribuzione a posteriori.\n\n\nposterior_mean &lt;- sum(theta * post)\nposterior_mean\n#&gt; [1] 0.6086958\n\n\nVarianza a Posteriori: Calcolata come la varianza della distribuzione a posteriori.\n\n\nposterior_variance &lt;- sum((theta^2) * post) - posterior_mean^2\nposterior_variance\n#&gt; [1] 0.01337977\n\n\nModa a Posteriori: Il valore di \\(\\theta\\) con la probabilità più alta.\n\n\nposterior_mode &lt;- theta[which.max(post)]\nposterior_mode\n#&gt; [1] 0.7\n\nIn sintesi, abbiamo calcolato la distribuzione a posteriori di \\(\\theta\\) utilizzando una distribuzione a priori discreta non uniforme e osservando 6 successi su 9 prove. Abbiamo derivato quantità statistiche come media, varianza e moda a posteriori. Questo processo dimostra come l’inferenza bayesiana aggiorni le credenze a priori in base ai dati osservati, offrendo una visione quantitativamente informata del parametro \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua-in-r",
    "href": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua-in-r",
    "title": "38  Pensare ad una proporzione in termini soggettivi",
    "section": "38.5 Aggiornamento Bayesiano con una Distribuzione a Priori Continua in R",
    "text": "38.5 Aggiornamento Bayesiano con una Distribuzione a Priori Continua in R\nPassiamo ora all’aggiornamento bayesiano utilizzando una distribuzione a priori continua, in particolare la distribuzione Beta. Questo approccio è particolarmente utile poiché consente di rappresentare \\(\\theta\\) come una variabile continua definita nell’intervallo [0, 1].\n\n38.5.1 Definizione della Distribuzione Beta\nIniziamo con una distribuzione Beta simmetrica, Beta(2, 2), e calcoliamo la sua densità di probabilità su un intervallo continuo di valori \\(\\theta\\).\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 2\n\n# Valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000)\n\n# Densità di probabilità della distribuzione Beta\npdf &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione Beta\nplot(theta, pdf, type = \"l\", col = \"blue\", lwd = 2,\n     main = \"Funzione di Densità di Probabilità Beta(2, 2)\",\n     xlab = expression(theta), ylab = \"Densità\")\n\n\n\n\n\n\n\n\n\n\n38.5.2 Distribuzione a Priori Non Simmetrica\nConsideriamo una distribuzione a priori non simmetrica, Beta(2, 5), per rappresentare credenze che privilegiano valori bassi di \\(\\theta\\).\n\n# Parametri della distribuzione Beta non simmetrica\nalpha &lt;- 2\nbeta &lt;- 5\n\n# Densità di probabilità\npdf &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione Beta(2, 5)\nplot(theta, pdf, type = \"l\", col = \"red\", lwd = 2,\n     main = \"Funzione di Densità di Probabilità Beta(2, 5)\",\n     xlab = expression(theta), ylab = \"Densità\")\n\n\n\n\n\n\n\n\n\n\n38.5.3 Verosimiglianza\nConsideriamo un esperimento con 9 prove e 6 successi, modellato con una distribuzione binomiale. Calcoliamo la funzione di verosimiglianza normalizzata.\n\n# Parametri dell'esperimento\nn &lt;- 9\nk &lt;- 6\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- dbinom(k, size = n, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood) # Normalizzazione\n\n# Grafico della verosimiglianza\nplot(theta, likelihood, type = \"l\", col = \"green\", lwd = 2,\n     main = \"Funzione di Verosimiglianza\",\n     xlab = expression(theta), ylab = \"Densità\")\n\n\n\n\n\n\n\n\n\n\n38.5.4 Distribuzione a Posteriori\nLa distribuzione a posteriori si ottiene moltiplicando la distribuzione a priori per la verosimiglianza e normalizzando il risultato.\n\n# Calcolo della distribuzione a priori Beta(2, 5)\nprior &lt;- dbeta(theta, shape1 = 2, shape2 = 5)\nprior &lt;- prior / sum(prior)\n\n# Calcolo della distribuzione a posteriori\nposterior &lt;- (prior * likelihood) / sum(prior * likelihood)\n\n\n# Grafico delle distribuzioni\nplot(theta, prior, type = \"l\", col = \"red\", lwd = 2, ylim = c(0, max(posterior)),\n     main = \"Distribuzioni Bayesiane\",\n     xlab = expression(theta), ylab = \"Densità\")\nlines(theta, likelihood, col = \"green\", lwd = 2)\nlines(theta, posterior, col = \"purple\", lwd = 2)\nlegend(\"topright\", legend = c(\"Prior\", \"Likelihood\", \"Posterior\"),\n       col = c(\"red\", \"green\", \"purple\"), lwd = 2)\n\n\n\n\n\n\n\n\n\n\n38.5.5 Quantità a Posteriori\nCalcoliamo alcune quantità riassuntive dalla distribuzione a posteriori.\n\nMedia a Posteriori\n\n\nposterior_mean &lt;- sum(theta * posterior)\nposterior_mean\n#&gt; [1] 0.5\n\n\nDeviazione Standard a Posteriori\n\n\nposterior_sd &lt;- sqrt(sum((theta^2) * posterior) - posterior_mean^2)\nposterior_sd\n#&gt; [1] 0.1212678\n\n\nModa a Posteriori\n\n\nposterior_mode &lt;- theta[which.max(posterior)]\nposterior_mode\n#&gt; [1] 0.5005005\n\n\n\n38.5.6 Campionamento dalla Distribuzione a Posteriori\nPossiamo generare campioni casuali dalla distribuzione a posteriori per effettuare inferenze.\n\n# Campionamento casuale\nset.seed(123)\nsamples &lt;- sample(theta, size = 10000, prob = posterior, replace = TRUE)\n\n# Grafico dei campioni\nhist(samples, breaks = 50, col = \"purple\", probability = TRUE,\n     main = \"Distribuzione dei Campioni dalla Posteriori\",\n     xlab = expression(theta))\nlines(density(samples), col = \"blue\", lwd = 2)\n\n\n\n\n\n\n\n\n\n38.5.6.1 Intervalli di Credibilità\nCalcoliamo l’intervallo di credibilità al 94%.\n\ncredible_interval &lt;- quantile(samples, probs = c(0.03, 0.97))\ncredible_interval\n#&gt;        3%       97% \n#&gt; 0.2742442 0.7277277\n\nSe desideriamo calcolare l’intervallo di densità più alta (HPDI), possiamo utilizzare pacchetti aggiuntivi come HDInterval.\n\n# Calcolo HPDI (richiede il pacchetto HDInterval)\nhdi(samples, credMass = 0.94)\n#&gt;     lower     upper \n#&gt; 0.2712713 0.7237237 \n#&gt; attr(,\"credMass\")\n#&gt; [1] 0.94\n\nIn sintesi, questo approccio dimostra l’applicazione del metodo bayesiano con distribuzioni a priori continue, utilizzando sia formule analitiche che campionamento. I risultati mostrano come possiamo ottenere credenze aggiornate su \\(\\theta\\) e riassumerle con quantità come media, moda e intervalli di credibilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia",
    "title": "38  Pensare ad una proporzione in termini soggettivi",
    "section": "38.6 Metodo basato su griglia",
    "text": "38.6 Metodo basato su griglia\nIl metodo utilizzato in questo capitolo per generare la distribuzione a posteriori è noto come metodo basato su griglia. Questo metodo numerico esatto si basa sul calcolo della distribuzione a posteriori mediante una griglia di punti uniformemente spaziati. Nonostante la maggior parte dei parametri sia continua, l’approssimazione della distribuzione a posteriori può essere ottenuta considerando soltanto una griglia finita di valori dei parametri. Il metodo segue quattro fasi:\n\nFissare una griglia discreta di possibili valori dei parametri.\nValutare la distribuzione a priori e la funzione di verosimiglianza per ciascun valore della griglia.\nCalcolare l’approssimazione della densità a posteriori, ottenuta moltiplicando la distribuzione a priori per la funzione di verosimiglianza per ciascun valore della griglia e normalizzando i prodotti in modo che la loro somma sia uguale a 1.\nSelezionare \\(n\\) valori casuali dalla griglia per ottenere un campione casuale della densità a posteriori normalizzata.\n\nQuesto metodo può essere potenziato aumentando il numero di punti nella griglia, ma il limite principale risiede nel fatto che all’aumentare della dimensionalità dello spazio dei parametri, il numero di punti necessari per una stima accurata cresce in modo esponenziale, rendendo il metodo impraticabile per problemi complessi.\nIn sintesi, l’approccio basato sulla griglia è intuitivo e non richiede competenze di programmazione avanzate per l’implementazione. Inoltre, fornisce un risultato che può essere considerato, per tutti gli scopi pratici, come un campione casuale estratto dalla distribuzione di probabilità a posteriori condizionata ai dati. Tuttavia, questo metodo è limitato a causa della maledizione della dimensionalità1, il che significa che può essere applicato soltanto a modelli statistici semplici con non più di due parametri. Di conseguenza, in pratica, è spesso sostituito da altre tecniche più efficienti, poiché i modelli impiegati in psicologia richiedono frequentemente la stima di centinaia o anche migliaia di parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/03_subj_prop.html#riflessioni-conclusive",
    "title": "38  Pensare ad una proporzione in termini soggettivi",
    "section": "38.7 Riflessioni Conclusive",
    "text": "38.7 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato l’aggiornamento bayesiano utilizzando una distribuzione a priori discreta, accennando brevemente al caso delle distribuzioni a priori continue. Quando si affrontano scenari con distribuzioni a priori continue, l’elaborazione della distribuzione a posteriori generalmente richiede la risoluzione di un integrale che, nella maggior parte dei casi, non ammette una soluzione analitica. Tuttavia, ci sono eccezioni notevoli, come nell’inferenza relativa alle proporzioni, dove la distribuzione a priori è modellata come una distribuzione Beta e la funzione di verosimiglianza segue una distribuzione binomiale. In queste circostanze particolari, è possibile derivare analiticamente la distribuzione a posteriori. L’analisi dettagliata di questo caso sarà trattata nel capitolo successivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#esercizi",
    "href": "chapters/bayesian_inference/03_subj_prop.html#esercizi",
    "title": "38  Pensare ad una proporzione in termini soggettivi",
    "section": "38.8 Esercizi",
    "text": "38.8 Esercizi\n\nEsercizio 38.1 Viene chieso di calcolare la distribuzione a posteriori della probabilità che uno studio condivida i materiali di ricerca utilizzando il metodo basato su griglia. Si utilizzeranno dati reali per motivare e costruire una distribuzione a priori discretizzata.\nIn uno studio sull’analisi delle pratiche di trasparenza e riproducibilità nella ricerca in psicologia, Hardwicke et al. (2022) hanno riportato che la condivisione dei materiali di ricerca è stata rilevata nel 14% dei casi (26 su 183 studi), con un intervallo di confidenza al 95% pari a [10%, 19%]. Questo suggerisce che la condivisione di materiali è rara.\nIspirandoti ai risultati di questo studio, costruisci una distribuzione a priori per la probabilità \\(\\theta\\) che uno studio condivida i materiali di ricerca. Per semplicità, discretizza \\(\\theta\\) in 10 livelli equispaziati: \\(0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95\\).\nAttribuisci le seguenti probabilità a priori ai 10 livelli, basandoti sull’informazione che la condivisione dei materiali è un evento raro ma non trascurabile: \\(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02\\).\nSupponiamo che siano stati osservati 20 studi su 100 che hanno condiviso i materiali di ricerca. Calcola la distribuzione a posteriori utilizzando il metodo basato su griglia. Calcola la media della distribuzione a posteriori e l’intervallo di credibilità al 89%.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/03_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "title": "38  Pensare ad una proporzione in termini soggettivi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HDInterval_0.2.4  mice_3.16.0       MASS_7.3-61       viridis_0.6.5    \n#&gt;  [5] viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3    \n#&gt;  [9] patchwork_1.3.0   bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0     \n#&gt; [13] markdown_1.13     knitr_1.49        lubridate_1.9.3   forcats_1.0.0    \n#&gt; [17] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n#&gt; [21] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#&gt; [25] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#bibliografia",
    "href": "chapters/bayesian_inference/03_subj_prop.html#bibliografia",
    "title": "38  Pensare ad una proporzione in termini soggettivi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nHardwicke, T. E., Thibault, R. T., Kosie, J. E., Wallach, J. D., Kidwell, M. C., & Ioannidis, J. P. (2022). Estimating the prevalence of transparency and reproducibility-related research practices in psychology (2014–2017). Perspectives on Psychological Science, 17(1), 239–251.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nShiffrin, R. M., & Schneider, W. (1977). Controlled and automatic human information processing: II. Perceptual learning, automatic attending and a general theory. Psychological Review, 84(2), 127–190.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#footnotes",
    "href": "chapters/bayesian_inference/03_subj_prop.html#footnotes",
    "title": "38  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Per comprendere la maledizione della dimensionalità, possiamo considerare l’esempio di una griglia di 100 punti equispaziati. Nel caso di un solo parametro, sarebbe necessario calcolare solo 100 valori. Tuttavia, se abbiamo due parametri, il numero di valori da calcolare diventa \\(100^2\\). Se invece abbiamo 10 parametri, il numero di valori da calcolare sarebbe di \\(10^{10}\\). È evidente che la quantità di calcoli richiesta diventa troppo grande persino per un computer molto potente. Pertanto, per modelli che richiedono la stima di un numero significativo di parametri, è necessario utilizzare un approccio diverso.↩︎",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html",
    "href": "chapters/bayesian_inference/04_grid_gauss.html",
    "title": "39  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "",
    "text": "39.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo, estenderemo la discussione precedente sul calcolo della distribuzione a posteriori utilizzando il metodo basato su griglia, applicandolo questa volta a un caso con verosimiglianza gaussiana. In particolare, ci concentreremo su come costruire un modello gaussiano per descrivere l’intelligenza.\nImmaginiamo di condurre uno studio sulla plusdotazione, considerando l’approccio psicometrico. Secondo questo approccio, una persona è considerata plusdotata se ha un QI (Quoziente Intellettivo) di 130 o superiore (Robinson, Zigler, & Gallagher, 2000). Anche se l’uso di un QI di 130 come soglia è il criterio più comune, non è universalmente accettato. L’intelligenza nei bambini plusdotati non è solo superiore rispetto a quella dei loro pari, ma è qualitativamente diversa (Lubart & Zenasni, 2010). I bambini plusdotati tendono a mostrare caratteristiche come un vocabolario ampio, un linguaggio molto sviluppato, processi di ragionamento avanzati, eccellente memoria, vasti interessi, forte curiosità, empatia, capacità di leadership, abilità visive elevate, impegno in situazioni sfidanti e un forte senso di giustizia (Song & Porath, 2005).\nNella simulazione che seguirà, assumeremo che i dati provengano da una distribuzione normale. Per semplicità, considereremo che la deviazione standard sia nota e pari a 5. Il parametro della media sarà l’oggetto della nostra inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#dati",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#dati",
    "title": "39  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "39.2 Dati",
    "text": "39.2 Dati\nSupponiamo di avere un campione di 10 osservazioni. I dati saranno generati casualmente da una distribuzione normale con media 130 e deviazione standard 5.\n\nset.seed(123) # Per la riproducibilità\nvera_media &lt;- 130 # Media vera\nsigma_conosciuta &lt;- 5 # Deviazione standard conosciuta\ndimensione_campione &lt;- 10 # Dimensione del campione\n\n# Generare un campione\ncampione &lt;- round(rnorm(n = dimensione_campione, mean = vera_media, sd = sigma_conosciuta))\ncampione\n#&gt;  [1] 127 129 138 130 131 139 132 124 127 128",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#griglia",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#griglia",
    "title": "39  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "39.3 Griglia",
    "text": "39.3 Griglia\nCreiamo ora una griglia di 100 valori compresi tra 110 e 150.\n\nmu_griglia &lt;- seq(110, 150, length.out = 100)\nmu_griglia\n#&gt;   [1] 110.0000 110.4040 110.8081 111.2121 111.6162 112.0202 112.4242 112.8283\n#&gt;   [9] 113.2323 113.6364 114.0404 114.4444 114.8485 115.2525 115.6566 116.0606\n#&gt;  [17] 116.4646 116.8687 117.2727 117.6768 118.0808 118.4848 118.8889 119.2929\n#&gt;  [25] 119.6970 120.1010 120.5051 120.9091 121.3131 121.7172 122.1212 122.5253\n#&gt;  [33] 122.9293 123.3333 123.7374 124.1414 124.5455 124.9495 125.3535 125.7576\n#&gt;  [41] 126.1616 126.5657 126.9697 127.3737 127.7778 128.1818 128.5859 128.9899\n#&gt;  [49] 129.3939 129.7980 130.2020 130.6061 131.0101 131.4141 131.8182 132.2222\n#&gt;  [57] 132.6263 133.0303 133.4343 133.8384 134.2424 134.6465 135.0505 135.4545\n#&gt;  [65] 135.8586 136.2626 136.6667 137.0707 137.4747 137.8788 138.2828 138.6869\n#&gt;  [73] 139.0909 139.4949 139.8990 140.3030 140.7071 141.1111 141.5152 141.9192\n#&gt;  [81] 142.3232 142.7273 143.1313 143.5354 143.9394 144.3434 144.7475 145.1515\n#&gt;  [89] 145.5556 145.9596 146.3636 146.7677 147.1717 147.5758 147.9798 148.3838\n#&gt;  [97] 148.7879 149.1919 149.5960 150.0000",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-verosimiglianza",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-verosimiglianza",
    "title": "39  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "39.4 Calcolo della Verosimiglianza",
    "text": "39.4 Calcolo della Verosimiglianza\nPer ogni valore della griglia, calcoliamo la verosimiglianza complessiva come prodotto delle densità di probabilità.\n\nlikelihood &lt;- sapply(mu_griglia, function(mu) {\n    prod(dnorm(campione, mean = mu, sd = sigma_conosciuta))\n})\nlikelihood\n#&gt;   [1] 5.288265e-50 1.406074e-48 3.502225e-47 8.171857e-46 1.786234e-44\n#&gt;   [6] 3.657602e-43 7.016097e-42 1.260769e-40 2.122346e-39 3.346861e-38\n#&gt;  [11] 4.944244e-37 6.842315e-36 8.870476e-35 1.077288e-33 1.225624e-32\n#&gt;  [16] 1.306242e-31 1.304159e-30 1.219772e-29 1.068728e-28 8.771964e-28\n#&gt;  [21] 6.744771e-27 4.858233e-26 3.278161e-25 2.072159e-24 1.227034e-23\n#&gt;  [26] 6.806612e-23 3.537091e-22 1.721877e-21 7.852337e-21 3.354568e-20\n#&gt;  [31] 1.342502e-19 5.033084e-19 1.767641e-18 5.815606e-18 1.792407e-17\n#&gt;  [36] 5.175103e-17 1.399724e-16 3.546552e-16 8.418043e-16 1.871789e-15\n#&gt;  [41] 3.898910e-15 7.608000e-15 1.390716e-14 2.381483e-14 3.820297e-14\n#&gt;  [46] 5.741000e-14 8.082000e-14 1.065837e-13 1.316752e-13 1.523904e-13\n#&gt;  [51] 1.652160e-13 1.677982e-13 1.596480e-13 1.422920e-13 1.188059e-13\n#&gt;  [56] 9.292587e-14 6.808884e-14 4.673649e-14 3.005225e-14 1.810251e-14\n#&gt;  [61] 1.021507e-14 5.399888e-15 2.674046e-15 1.240492e-15 5.390880e-16\n#&gt;  [66] 2.194655e-16 8.369771e-17 2.990211e-17 1.000762e-17 3.137622e-18\n#&gt;  [71] 9.215336e-19 2.535494e-19 6.535139e-20 1.577930e-20 3.569124e-21\n#&gt;  [76] 7.562690e-22 1.501176e-22 2.791438e-23 4.862561e-24 7.934926e-25\n#&gt;  [81] 1.213002e-25 1.737085e-26 2.330351e-27 2.928616e-28 3.447817e-29\n#&gt;  [86] 3.802480e-30 3.928533e-31 3.802198e-32 3.447306e-33 2.927964e-34\n#&gt;  [91] 2.329659e-35 1.736441e-36 1.212462e-37 7.930807e-39 4.859676e-40\n#&gt;  [96] 2.789575e-41 1.500063e-42 7.556522e-44 3.565949e-45 1.576410e-46",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-distribuzione-a-posteriori",
    "title": "39  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "39.5 Calcolo della Distribuzione a Posteriori",
    "text": "39.5 Calcolo della Distribuzione a Posteriori\nImpostiamo una prior uniforme e calcoliamo la distribuzione a posteriori normalizzata.\n\nprior &lt;- rep(1, length(mu_griglia)) # Prior uniforme\nposterior_non_norm &lt;- likelihood * prior\nposterior &lt;- posterior_non_norm / sum(posterior_non_norm) # Normalizzazione\n\nVisualizzazione:\n\nplot(mu_griglia, posterior,\n    type = \"l\", main = \"Distribuzione a Posteriori della Media\",\n    xlab = \"Media\", ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\n\n\n39.5.1 Aggiunta di una Prior Informativa\nUsiamo una prior gaussiana con media 140 e deviazione standard 3.\n\nprior &lt;- dnorm(mu_griglia, mean = 140, sd = 3)\n\nposterior_non_norm &lt;- likelihood * prior\nposterior &lt;- posterior_non_norm / sum(posterior_non_norm)\n\n# Grafico\nplot(mu_griglia, posterior,\n    type = \"l\", col = \"blue\", lwd = 2,\n    main = \"Distribuzione a Posteriori e Prior della Media\",\n    xlab = \"Media\", ylab = \"Densità\"\n)\nlines(mu_griglia, prior / sum(prior), col = \"red\", lty = 2)\nlegend(\"topright\", legend = c(\"Posterior\", \"Prior\"), col = c(\"blue\", \"red\"), lty = c(1, 2))",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#campionamento-dalla-posterior",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#campionamento-dalla-posterior",
    "title": "39  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "39.6 Campionamento dalla Posterior",
    "text": "39.6 Campionamento dalla Posterior\nGeneriamo un campione dalla distribuzione a posteriori.\n\nset.seed(123)\nindice_campionato &lt;- sample(1:length(mu_griglia), size = 1000, replace = TRUE, prob = posterior)\nmedia_campionata &lt;- mu_griglia[indice_campionato]\n\n# Istogramma dei campioni\nhist(media_campionata,\n    main = \"Campionamento dalla Posterior\", xlab = \"Media\",\n    breaks = 20, col = \"lightblue\", border = \"white\"\n)\n\n# Media e intervallo di credibilità\nmean(media_campionata)\n#&gt; [1] 132.5737\nquantile(media_campionata, c(0.03, 0.97))\n#&gt;       3%      97% \n#&gt; 130.2020 135.4545",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-log-verosimiglianza",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-log-verosimiglianza",
    "title": "39  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "39.7 Calcolo della Log-Verosimiglianza",
    "text": "39.7 Calcolo della Log-Verosimiglianza\nUtilizziamo i logaritmi per migliorare la stabilità numerica.\n\nlog_likelihood &lt;- sapply(mu_griglia, function(mu) {\n    sum(dnorm(campione, mean = mu, sd = sigma_conosciuta, log = TRUE))\n})\n\nlog_prior &lt;- dnorm(mu_griglia, mean = 140, sd = 3, log = TRUE)\n\nlog_posterior_non_norm &lt;- log_likelihood + log_prior\nlog_posterior &lt;- log_posterior_non_norm - max(log_posterior_non_norm) # Stabilizzazione\nposterior &lt;- exp(log_posterior) / sum(exp(log_posterior))\n\n# Grafico\nplot(mu_griglia, posterior,\n    type = \"l\", col = \"darkgreen\", lwd = 2,\n    main = \"Distribuzione a Posteriori con Log-Verosimiglianza\",\n    xlab = \"Media\", ylab = \"Probabilità\"\n)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#estensione-alla-deviazione-standard-ignota",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#estensione-alla-deviazione-standard-ignota",
    "title": "39  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "39.8 Estensione alla Deviazione Standard Ignota",
    "text": "39.8 Estensione alla Deviazione Standard Ignota\nPer una griglia bidimensionale di valori di \\(\\mu\\) e \\(\\sigma\\):\n\n# Define the grid for mu and sigma\nmu_griglia &lt;- seq(110, 150, length.out = 100)\nsigma_griglia &lt;- seq(1, 10, length.out = 50)\n\n# Create combinations of mu and sigma using expand.grid\ngrid &lt;- expand.grid(mu = mu_griglia, sigma = sigma_griglia)\n\n# Compute the log-likelihood for each combination of mu and sigma\nlog_likelihood &lt;- apply(grid, 1, function(params) {\n    mu &lt;- params[1]\n    sigma &lt;- params[2]\n    sum(dnorm(campione, mean = mu, sd = sigma, log = TRUE))\n})\n\n# Reshape log-likelihood into a matrix\nlog_likelihood_2d &lt;- matrix(log_likelihood, nrow = length(mu_griglia), ncol = length(sigma_griglia))\n\n# Compute priors for mu and sigma\nlog_prior_mu &lt;- dnorm(mu_griglia, mean = 140, sd = 5, log = TRUE)\nlog_prior_sigma &lt;- dnorm(sigma_griglia, mean = 5, sd = 2, log = TRUE)\n\n# Combine priors into a grid\nlog_prior_2d &lt;- outer(log_prior_mu, log_prior_sigma, \"+\")\n\n# Compute log-posterior\nlog_posterior_2d &lt;- log_likelihood_2d + log_prior_2d\nlog_posterior_2d &lt;- log_posterior_2d - max(log_posterior_2d) # Stabilize\nposterior_2d &lt;- exp(log_posterior_2d)\nposterior_2d &lt;- posterior_2d / sum(posterior_2d) # Normalize\n\n# Convert posterior_2d to a data frame for visualization\nlibrary(reshape2)\nposterior_df &lt;- melt(posterior_2d)\nnames(posterior_df) &lt;- c(\"mu_idx\", \"sigma_idx\", \"posterior\")\nposterior_df$mu &lt;- mu_griglia[posterior_df$mu_idx]\nposterior_df$sigma &lt;- sigma_griglia[posterior_df$sigma_idx]\n\n# Plot the posterior distribution\nlibrary(ggplot2)\nggplot(posterior_df, aes(x = mu, y = sigma, fill = posterior)) +\n    geom_tile() +\n    scale_fill_viridis_c() +\n    labs(\n        title = \"Distribuzione a Posteriori Bidimensionale\",\n        x = \"Media ($\\\\mu$)\", y = \"Deviazione Standard ($\\\\sigma$)\"\n    )",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#riflessioni-conclusive",
    "title": "39  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "39.9 Riflessioni Conclusive",
    "text": "39.9 Riflessioni Conclusive\nQuando si passa alla stima simultanea di più parametri, come la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)), l’analisi diventa notevolmente più complessa. Questo perché occorre considerare un numero molto maggiore di combinazioni di parametri rispetto alla stima di un solo parametro, aumentando così il carico computazionale. Inoltre, la scelta delle priors per ciascun parametro richiede particolare attenzione, poiché queste influenzeranno in modo diretto le stime a posteriori.\nIn scenari dove lo spazio dei parametri è multidimensionale o quando l’esplorazione della griglia diventa impraticabile, l’uso di metodi avanzati come il campionamento di Markov Chain Monte Carlo (MCMC) diventa indispensabile. Questi metodi permettono di campionare in modo efficiente dalla distribuzione a posteriori, senza la necessità di esplorare esplicitamente ogni combinazione possibile di parametri, rendendo l’analisi più gestibile anche in contesti complessi.\nIn conclusione, l’estensione dell’approccio bayesiano a problemi con più parametri sconosciuti richiede un’attenzione ancora maggiore nella definizione dello spazio dei parametri, nella selezione delle priors appropriate e nel calcolo delle distribuzioni a posteriori. L’adozione di tecniche come l’MCMC può facilitare questo processo, permettendo di affrontare in modo efficiente problemi che altrimenti sarebbero proibitivi dal punto di vista computazionale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "39  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4    MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.0       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] labeling_0.4.3    rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [37] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    utf8_1.2.4       \n#&gt; [41] broom_1.0.7       withr_3.0.2       backports_1.5.0   promises_1.3.1   \n#&gt; [45] timechange_0.3.0  rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3        \n#&gt; [49] shiny_1.9.1       evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4      \n#&gt; [53] Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9   \n#&gt; [57] plyr_1.8.9        R6_2.5.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html",
    "title": "40  Distribuzioni coniugate (1)",
    "section": "",
    "text": "40.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nIn questo capitolo, esploriamo il concetto di distribuzioni a priori coniugate e il loro ruolo nell’inferenza bayesiana. Utilizzando il modello beta-binomiale come esempio paradigmatico, dimostreremo come queste distribuzioni semplifichino l’analisi attraverso calcoli analitici diretti. L’uso di una distribuzione a priori coniugata non solo rende l’inferenza più agevole, ma fornisce anche una chiara visione del modo in cui le credenze a priori influenzano le conclusioni.\nPer favorire la comprensione, procederemo in tre fasi principali:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#introduzione",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#introduzione",
    "title": "40  Distribuzioni coniugate (1)",
    "section": "",
    "text": "Introduzione del modello beta-binomiale.\nAnalisi della distribuzione Beta e del suo ruolo come distribuzione a priori.\nDescrizione del processo di aggiornamento bayesiano e dei vantaggi derivanti dall’uso di distribuzioni coniugate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#il-modello-beta-binomiale",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#il-modello-beta-binomiale",
    "title": "40  Distribuzioni coniugate (1)",
    "section": "40.2 Il Modello Beta-Binomiale",
    "text": "40.2 Il Modello Beta-Binomiale\nIl modello beta-binomiale è un esempio classico per analizzare una proporzione \\(\\theta\\), ossia la probabilità di successo in una sequenza di prove binarie (ad esempio, successo/fallimento). Supponiamo di osservare \\(y\\) successi su \\(n\\) prove, dove ogni prova è indipendente e con la stessa probabilità di successo \\(\\theta\\), che appartiene all’intervallo \\([0,1]\\).\nLa funzione di verosimiglianza, basata sulla distribuzione binomiale, è espressa come:\n\\[\n\\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove \\(\\binom{n}{y}\\) è il coefficiente binomiale che conta il numero di modi in cui \\(y\\) successi possono verificarsi in \\(n\\) prove.\nPer modellare la nostra conoscenza preliminare su \\(\\theta\\), scegliamo una distribuzione a priori Beta, che rappresenta un’ampia gamma di credenze iniziali con parametri flessibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#la-distribuzione-beta-un-prior-flessibile",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#la-distribuzione-beta-un-prior-flessibile",
    "title": "40  Distribuzioni coniugate (1)",
    "section": "40.3 La Distribuzione Beta: Un Prior Flessibile",
    "text": "40.3 La Distribuzione Beta: Un Prior Flessibile\nLa distribuzione Beta è definita come:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{con } \\theta \\in (0, 1),\n\\]\ndove:\n\n\\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\) sono i iperparametri, che determinano la forma della distribuzione.\n\\(B(\\alpha, \\beta)\\) è la funzione Beta di Eulero, calcolata come:\n\\[\n  B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)},\n  \\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, una generalizzazione del fattoriale.\n\n\n40.3.1 Interpretazione Intuitiva di \\(\\alpha\\) e \\(\\beta\\)\nNel contesto bayesiano:\n\n\\(\\alpha -1\\) rappresenta il numero ipotetico di “successi” a priori.\n\\(\\beta -1\\) rappresenta il numero ipotetico di “fallimenti” a priori.\n\nAd esempio:\n\nUna distribuzione Beta(1, 1) è uniforme (0 successi a priori e 0 fallimenti), indicando totale incertezza iniziale (assenza di credenze informate).\nUna distribuzione Beta(10, 20) rappresenta una conoscenza a priori basata su 9 successi e 19 fallimenti ipotizzati, indicando una convinzione iniziale relativamente solida, poiché deriva da un totale di 28 osservazioni virtuali che riflettono le credenze precedenti.\n\nQuesta interpretazione consente di calibrare le credenze a priori in base all’evidenza disponibile o alla fiducia nella stima.\n\n\n40.3.2 Flessibilità della Distribuzione Beta\nLa distribuzione Beta è estremamente versatile:\n\nForma: Valori diversi di \\(\\alpha\\) e \\(\\beta\\) producono distribuzioni simmetriche, asimmetriche o uniformi.\nForza del prior: Valori elevati di \\(\\alpha\\) e \\(\\beta\\) riducono la varianza, riflettendo credenze più forti.\n\nQuesta flessibilità rende la distribuzione Beta una scelta ideale per rappresentare credenze iniziali su proporzioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#aggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#aggiornamento-bayesiano",
    "title": "40  Distribuzioni coniugate (1)",
    "section": "40.4 Aggiornamento Bayesiano",
    "text": "40.4 Aggiornamento Bayesiano\nL’aggiornamento bayesiano combina le informazioni iniziali (priori) con i dati osservati (verosimiglianza) per produrre una nuova distribuzione delle credenze (posteriori). Nel caso del modello beta-binomiale, questo processo è particolarmente semplice grazie alla “coniugazione”: il prior Beta e la verosimiglianza Binomiale producono una distribuzione a posteriori che appartiene ancora alla famiglia Beta.\n\n40.4.1 Problema\nSe osserviamo \\(y\\) successi su \\(n\\) prove, vogliamo aggiornare il nostro prior Beta con i dati osservati per ottenere una distribuzione a posteriori Beta. I parametri aggiornati della distribuzione a posteriori sono:\n\\[\n\\alpha' = \\alpha + y, \\quad \\beta' = \\beta + n - y.\n\\]\nVediamo in dettaglio come si arriva a questo risultato.\n\n\n40.4.2 Passaggi dell’Aggiornamento Bayesiano\n1. Formula di Bayes\nLa regola di Bayes afferma che:\n\\[\n\\text{Posterior} \\propto \\text{Prior} \\times \\text{Verosimiglianza},\n\\]\ndove \\(\\propto\\) indica “proporzionale a”. Qui ci concentriamo sui termini che dipendono dal parametro di interesse, \\(\\theta\\), la probabilità di successo.\n2. Espressione del Prior\nIl prior è una distribuzione Beta, definita come:\n\\[\n\\text{Prior} = \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1},\n\\]\ndove:\n\n\\(\\theta\\) rappresenta la probabilità di successo,\n\\(\\alpha\\) e \\(\\beta\\) sono parametri che descrivono le nostre convinzioni iniziali:\n\n\\(\\alpha\\): il numero di successi attesi prima di osservare i dati,\n\\(\\beta\\): il numero di insuccessi attesi prima di osservare i dati.\n\n\n3. Espressione della Verosimiglianza\nLa verosimiglianza è data dalla distribuzione Binomiale, che rappresenta la probabilità di osservare \\(y\\) successi su \\(n\\) prove:\n\\[\n\\text{Verosimiglianza} = \\theta^y (1-\\theta)^{n-y},\n\\]\ndove:\n\n\\(y\\) è il numero di successi osservati,\n\\(n\\) è il numero totale di prove,\n\\(\\theta\\) è la probabilità di successo (il parametro che stiamo aggiornando).\n\n4. Moltiplicazione di Prior e Verosimiglianza\nCombinando prior e verosimiglianza, otteniamo:\n\\[\n\\text{Posterior} \\propto \\underbrace{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}_{\\text{Prior}} \\times \\underbrace{\\theta^y (1-\\theta)^{n-y}}_{\\text{Verosimiglianza}}.\n\\]\n5. Raggruppamento dei termini\nMoltiplicando i termini simili, raggruppiamo gli esponenti di \\(\\theta\\) e \\(1-\\theta\\):\n\\[\n\\text{Posterior} \\propto \\theta^{(\\alpha-1) + y} (1-\\theta)^{(\\beta-1) + (n-y)}.\n\\]\n6. Forma finale\nSemplificando gli esponenti:\n\\[\n\\text{Posterior} \\propto \\theta^{\\alpha + y - 1} (1-\\theta)^{\\beta + n - y - 1}.\n\\]\nQuesta è la forma di una distribuzione Beta con nuovi parametri:\n\\[\n\\alpha' = \\alpha + y, \\quad \\beta' = \\beta + n - y.\n\\]\n7. Normalizzazione\nPer trasformare questa espressione in una distribuzione di probabilità vera e propria, dobbiamo dividere per una costante di normalizzazione. La funzione Beta, \\(B(\\alpha', \\beta')\\), normalizza la distribuzione:\n\\[\np(\\theta | y, n) = \\frac{\\theta^{\\alpha' - 1} (1-\\theta)^{\\beta' - 1}}{B(\\alpha', \\beta')},\n\\]\ndove \\(B(\\alpha', \\beta')\\) è definita come:\n\\[\nB(\\alpha', \\beta') = \\int_0^1 \\theta^{\\alpha' - 1} (1-\\theta)^{\\beta' - 1} \\, d\\theta.\n\\]\nTuttavia, non dobbiamo calcolarla esplicitamente poiché sappiamo già che il risultato è una distribuzione Beta.\n8. Parametri aggiornati\nIn conclusione, i parametri aggiornati sono:\n\nNuovo \\(\\alpha'\\): \\(\\alpha + y\\), che somma al vecchio \\(\\alpha\\) il numero di successi osservati (\\(y\\)).\nNuovo \\(\\beta'\\): \\(\\beta + n - y\\), che somma al vecchio \\(\\beta\\) il numero di insuccessi osservati (\\(n-y\\)).\n\n\n\n40.4.3 Vantaggi del Modello Beta-Binomiale\nIl modello beta-binomiale presenta diversi vantaggi:\n\nSemplicità analitica: La distribuzione a posteriori appartiene alla stessa famiglia della distribuzione a priori, evitando calcoli complessi.\nInterpretazione trasparente: L’aggiornamento dei parametri \\(\\alpha\\) e \\(\\beta\\) mostra chiaramente come i dati influenzino le credenze.\n\nNonostante la semplicità, le distribuzioni a priori coniugate non sempre rappresentano credenze realistiche. Tecniche moderne come il campionamento Monte Carlo consentono di usare distribuzioni a priori più complesse, ma il modello beta-binomiale rimane un esempio didattico fondamentale per comprendere l’inferenza bayesiana.\nIn conclusione, il modello beta-binomiale illustra chiaramente come le distribuzioni a priori coniugate possano semplificare l’inferenza bayesiana e fornire una comprensione intuitiva dell’interazione tra prior e dati. Questo modello rappresenta un punto di partenza ideale per approfondire l’approccio bayesiano e prepararsi a concetti più avanzati.\n\nEsempio 40.1 In un esempio ispirato da McElreath (2020) nel suo libro “Statistical Rethinking”, consideriamo un esperimento dove otteniamo 6 successi (indicati come “acqua”) su un totale di 9 prove (immaginate come lanci di un mappamondo). La verosimiglianza binomiale per questo esperimento è data da:\n\\[\n\\theta^y (1-\\theta)^{n-y},\n\\]\ndove \\(y = 6\\) è il numero di successi e \\(n = 9\\) è il numero totale di prove.\nSe scegliamo una distribuzione a priori Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 2\\), possiamo utilizzare l’aggiornamento bayesiano per calcolare i parametri della distribuzione a posteriori, dato l’esito delle nostre prove. L’applicazione del teorema di Bayes porta a una distribuzione a posteriori Beta con i parametri aggiornati \\(\\alpha' = \\alpha + y = 8\\) e \\(\\beta' = \\beta + n - y = 5\\).\nOra, vediamo come visualizzare le tre distribuzioni di interesse: la distribuzione a priori Beta(\\(2, 2\\)), la verosimiglianza binomiale per \\(y=6\\) e \\(n=9\\), e la distribuzione a posteriori Beta(\\(8, 5\\)).\n\n# Definizione dei parametri\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\ny &lt;- 6\nn &lt;- 9\n\n# Parametri della distribuzione a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\n# Creiamo una sequenza di valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000) # Maggiore risoluzione\n\n# Calcoliamo le PDF\nprior_pdf &lt;- dbeta(theta, shape1 = alpha_prior, shape2 = beta_prior)\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Normalizziamo la verosimiglianza usando il metodo trapezoidale\nlikelihood_integral &lt;- sum(likelihood) * (theta[2] - theta[1]) # Approssimazione numerica dell'integrale\nnormalized_likelihood &lt;- likelihood / likelihood_integral\n\nposterior_pdf &lt;- dbeta(theta, shape1 = alpha_post, shape2 = beta_post)\n\n# Disegniamo le distribuzioni\nplot(theta, prior_pdf,\n    type = \"l\", col = \"blue\", lwd = 2,\n    ylim = c(0, max(c(prior_pdf, normalized_likelihood, posterior_pdf))),\n    xlab = expression(theta), ylab = \"Densità\",\n    main = \"Distribuzioni Prior, Likelihood e Posterior\"\n)\nlines(theta, normalized_likelihood, col = \"green\", lwd = 2, lty = 2)\nlines(theta, posterior_pdf, col = \"red\", lwd = 2)\nlegend(\"topleft\",\n    legend = c(\n        sprintf(\"Prior Beta(%d, %d)\", alpha_prior, beta_prior),\n        \"Likelihood (normalizzata)\",\n        sprintf(\"Posterior Beta(%d, %d)\", alpha_post, beta_post)\n    ),\n    col = c(\"blue\", \"green\", \"red\"),\n    lty = c(1, 2, 1), lwd = 2\n)\n\n\n\n\n\n\n\n\nIn questo codice, la funzione trapezoid viene usata per calcolare l’integrale della funzione di verosimiglianza non normalizzata su θ, fornendo il fattore di normalizzazione. Dividendo la funzione di verosimiglianza per questo fattore, otteniamo una funzione di verosimiglianza normalizzata, il cui integrale su [0, 1] è uguale a 1. La normalizzazione della verosimiglianza è eseguita solo a scopo di visualizzazione, per facilitare il confronto tra le curve.\n\n\nEsempio 40.2 Esaminiamo ora un esempio discuso da Johnson et al. (2022). In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorità, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell’articolo, Milgram descrive lo studio come\n\nconsistente nell’ordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che è un complice addestrato dell’esperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un ‘esperimento di apprendimento’ apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l’esperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre più intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realtà era un attore addestrato) sulla loro capacità di memorizzare una serie di item. Se l’attore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all’attore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l’attore stesse solo fingendo di provare dolore dalla scossa.\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello “Pericolo: Scossa Grave”. Il problema richiede di costruire la distribuzione a posteriori della probabilità \\(\\theta\\) di infliggere una scossa a l livello “Pericolo: Scossa Grave”, ipotizzando che uno studio precedente aveva stabilito che \\(\\theta\\) segue una distribuzione Beta(1, 10).\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n# Impostazione dei parametri della distribuzione Beta\nalpha &lt;- 1\nbeta_val &lt;- 10\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, shape1 = alpha, shape2 = beta_val)\n\n# Plot della densità di probabilità\ncolor_fill &lt;- \"#b97c7c\"\nplot(x_values, beta_pdf,\n    type = \"l\", col = color_fill, lwd = 2,\n    main = \"Distribuzione Beta(1, 10)\",\n    xlab = \"x\", ylab = \"Densità di probabilità\"\n)\nlegend(\"topright\", legend = \"Beta(1, 10)\", col = color_fill, lwd = 2)\n\n\n\n\n\n\n\n\nLa distribuzione a posteriori segue una distribuzione Beta con parametri aggiornati:\n\ny &lt;- 26\nn &lt;- 40\n\nalpha_prior &lt;- 1\nbeta_prior &lt;- 10\n\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\nalpha_post\n#&gt; [1] 27\nbeta_post\n#&gt; [1] 24\n\nCreazione di un grafico per la distribuzione a posteriori:\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, alpha_post, beta_post)\n\n# Plot della densità di probabilità\nplot(x_values, beta_pdf,\n    type = \"l\", col = \"blue\", lwd = 2,\n    main = \"Distribuzione Beta(27, 24)\", xlab = expression(theta), ylab = \"Densità di probabilità\"\n)\nlegend(\"topright\", legend = \"Beta(27, 24)\", col = \"blue\", lwd = 2)\n\n\n\n\n\n\n\n\nCalcolo della media a posteriori di \\(\\theta\\):\n\nalpha_post / (alpha_post + beta_post)\n#&gt; [1] 0.5294118\n\nCalcolo della moda a posteriori:\n\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n#&gt; [1] 0.5306122\n\nCalcolo della probabilità che \\(\\theta &gt; 0.6\\):\n\npbeta(0.6, alpha_post, beta_post, lower.tail = FALSE)\n#&gt; [1] 0.1561683\n\nOvvero:\n\n1 - pbeta(0.6, alpha_post, beta_post)\n#&gt; [1] 0.1561683\n\nEseguiamo il problema utilizzando il metodo basato su griglia. Definiamo la griglia di interesse:\n\ntheta &lt;- seq(0, 1, length.out = 100)\n\nCreiamo la distribuzione a priori:\n\nprior &lt;- dbeta(theta, alpha_prior, beta_prior)\n\nplot(theta, prior / sum(prior),\n    type = \"h\", col = \"blue\", lwd = 2,\n    main = \"Distribuzione a priori\", xlab = expression(theta), ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\n\nCreiamo la verosimiglianza:\n\nlk &lt;- dbinom(y, n, theta)\n\nplot(theta, lk / sum(lk),\n    type = \"h\", col = \"red\", lwd = 2,\n    main = \"Verosimiglianza\", xlab = expression(theta), ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\n\nCalcoliamo la distribuzione a posteriori:\n\npost &lt;- (prior * lk) / sum(prior * lk)\n\nplot(theta, post,\n    type = \"h\", col = \"green\", lwd = 2,\n    main = \"Distribuzione a posteriori\", xlab = expression(theta), ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\n\nEstrazione di un campione dalla distribuzione a posteriori:\n\nsamples &lt;- sample(theta, size = 1e6, replace = TRUE, prob = post)\n\nTroviamo la media a posteriori:\n\nmean(samples)\n#&gt; [1] 0.5294755\n\nCalcoliamo la probabilità che \\(\\theta &gt; 0.6\\):\n\nmean(samples &gt; 0.6)\n#&gt; [1] 0.152728\n\nQuesto codice mantiene la struttura logica del problema e produce risultati equivalenti utilizzando R.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "title": "40  Distribuzioni coniugate (1)",
    "section": "40.5 Principali distribuzioni coniugate",
    "text": "40.5 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle più note coniugazioni tra modelli statistici e distribuzioni a priori:\n\nNel modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribuzione a priori è \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione a posteriori è \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nNel modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nNel modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nNel modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribuzione a priori è \\(\\text{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione a posteriori è \\(\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#riflessioni-conclusive",
    "title": "40  Distribuzioni coniugate (1)",
    "section": "40.6 Riflessioni Conclusive",
    "text": "40.6 Riflessioni Conclusive\nIn conclusione, l’utilizzo di priori coniugati presenta vantaggi e svantaggi. Cominciamo con i vantaggi principali. Il principale vantaggio dell’adozione di distribuzioni a priori coniugate risiede nella loro capacità di rendere l’analisi della distribuzione a posteriori trattabile da un punto di vista analitico. Ad esempio, nel corso di questo capitolo abbiamo esaminato come sia possibile formulare la distribuzione a posteriori in seguito a un esperimento composto da una serie di prove di Bernoulli (con una verosimiglianza binomiale), utilizzando una distribuzione Beta sia per la prior che per il posteriore.\nTuttavia, è cruciale riconoscere che i modelli basati sul concetto di famiglie coniugate presentano delle limitazioni intrinseche. Le distribuzioni coniugate a priori sono disponibili solamente per distribuzioni di verosimiglianza di base e relativamente semplici. Per modelli complessi e più realistici, la ricerca di priori coniugati diventa spesso un compito estremamente arduo, limitando quindi la loro utilità. Inoltre, anche quando le distribuzioni a priori coniugate sono disponibili, un modello che ne fa uso potrebbe non essere sufficientemente flessibile per adattarsi alle nostre credenze iniziali. Ad esempio, un modello basato su una distribuzione normale è sempre unimodale e simmetrico rispetto alla media \\(\\mu\\). Tuttavia, se le nostre conoscenze iniziali non sono simmetriche o non seguono una distribuzione unimodale, la scelta di una distribuzione a priori normale potrebbe non risultare la più adeguata (Johnson et al., 2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#esercizi",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#esercizi",
    "title": "40  Distribuzioni coniugate (1)",
    "section": "40.7 Esercizi",
    "text": "40.7 Esercizi\n\nEsercizio 40.1 Si consideri lo studio “An excess of positive results: Comparing the standard psychology literature with registered reports” di Scheel et al. (2021). In questo lavoro, gli autori confrontano il tasso di risultati positivi \\(\\theta\\) ottenuti in studi psicologici pubblicati senza preregistrazione con quelli pubblicati con preregistrazione. Si utilizzi il tasso di successo riportato negli studi preregistrati per costruire una distribuzione a priori per il parametro \\(\\theta\\).\nSecondo i risultati degli studi preregistrati, gli autori riscontrano un tasso di successo del 43.66%, con un intervallo di confidenza al 95% [CI] = [31.91, 55.95]. Sulla base di questi dati, si costruisca una distribuzione beta come distribuzione a priori per \\(\\theta\\), seguendo il metodo illustrato da Johnson et al. (2022).\nSuccessivamente, utilizzando questa distribuzione beta come distribuzione a priori, si determini la distribuzione a posteriori utilizzando il metodo delle famiglie coniugate per due scenari distinti, basati su 152 studi osservati: (a) Un tasso di successo del 60% (b) Un tasso di successo del 96% (come riportato per gli studi non preregistrati da Scheel et al. (2021)).\nInfine, si commentino i risultati derivanti dall’analisi delle distribuzioni a posteriori ottenute per entrambi gli scenari.\n\n\nEsercizio 40.2 Tra i fattori che possono influenzare il rapporto tra i sessi alla nascita c’è la condizione materna di placenta previa, una condizione insolita della gravidanza in cui la placenta è impiantata in basso nell’utero, impedendo un normale parto vaginale del feto. Uno studio condotto in Germania ha esaminato il sesso dei neonati in casi di placenta previa e ha riscontrato che, su un totale di 980 nascite, 437 erano femmine.\nQuanta evidenza fornisce questo studio a supporto dell’ipotesi che la proporzione di nascite femminili nella popolazione di placenta previa sia inferiore a 0.485, che rappresenta la proporzione di nascite femminili nella popolazione generale? (Esercizio tratto da Gelman et al. (1995))\n\n\nEsercizio 40.3 Per valutare la sensibilità della soluzione precedente alla scelta della distribuzione a priori, ripetere l’esercizio utilizzando come distribuzione a priori per la proporzione di nascite femminili una distribuzione Beta(48.5, 51.5). Questa distribuzione è centrata su 0.485 e concentra la maggior parte della sua massa nell’intervallo [0.385, 0.585]. Interpretare i risultati ottenuti.\n\n\nEsercizio 40.4 In uno studio recente, Gori et al. (2024) hanno esaminato un campione di 202 adulti italiani e hanno riscontrato una prevalenza di mancini del 6.4%. Una meta-analisi di Papadatou-Pastou et al. (2020), condotta su un totale di 2,396,170 soggetti, riporta che la proporzione di mancini varia tra il 9.3% e il 18.1%, a seconda di come viene misurata la lateralità manuale. Inoltre, Papadatou-Pastou et al. (2020) mostrano che la prevalenza della lateralità manuale varia tra i paesi e nel tempo. Considerata questa incertezza, si determini la distribuzione a posteriori che combina i dati dello studio di Gori et al. (2024) con le informazioni pregresse fornite da Papadatou-Pastou et al. (2020). Le informazioni di Papadatou-Pastou et al. (2020) possono essere espresse in termini di una distribuzione Beta(8, 60).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "40  Distribuzioni coniugate (1)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#bibliografia",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#bibliografia",
    "title": "40  Distribuzioni coniugate (1)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGori, B., Grippo, A., Focardi, M., & Lolli, F. (2024). The Italian version of Edinburgh Handedness Inventory: Translation, transcultural adaptation, and validation in healthy subjects. Laterality, 29(2), 151–168.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPapadatou-Pastou, M., Ntolka, E., Schmitz, J., Martin, M., Munafò, M. R., Ocklenburg, S., & Paracchini, S. (2020). Human handedness: A meta-analysis. Psychological bulletin, 146(6), 481–524.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html",
    "title": "41  Distribuzioni coniugate (2)",
    "section": "",
    "text": "41.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nLa statistica bayesiana ci permette di aggiornare le nostre credenze iniziali o conoscenze a priori sulla distribuzione di un parametro (in questo caso, la media della popolazione) in base ai dati osservati. Questo processo di aggiornamento ci porta a ottenere una distribuzione a posteriori che riflette una nuova comprensione del parametro, integrata con le informazioni fornite dal campione.\nIl concetto fondamentale è che, attraverso l’aggiornamento bayesiano, l’incertezza sulla stima del parametro si riduce. Questo è dovuto al fatto che l’informazione aggiuntiva fornita dai dati osservati consente di “restringere” la distribuzione a posteriori rispetto alla distribuzione a priori, riducendo così la varianza (o deviazione standard) della distribuzione del parametro di interesse.\nIn questo capitolo, approfondiremo il tema delle famiglie coniugate (Capitolo 40), focalizzandoci sul modello normale-normale. Una caratteristica distintiva di questo modello è la sua capacità di auto-coniugazione rispetto a una funzione di verosimiglianza gaussiana. In termini più semplici, se la funzione di verosimiglianza segue una distribuzione gaussiana, l’adozione di una distribuzione a priori gaussiana per la media garantisce che anche la distribuzione a posteriori mantenga la sua forma gaussiana.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#perché-usare-la-distribuzione-normale",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#perché-usare-la-distribuzione-normale",
    "title": "41  Distribuzioni coniugate (2)",
    "section": "41.2 Perché Usare la Distribuzione Normale?",
    "text": "41.2 Perché Usare la Distribuzione Normale?\nSpesso, quando la distribuzione a posteriori è nota per essere unimodale e simmetrica, possiamo modellarla efficacemente con una distribuzione normale, anche se sappiamo che la sua forma è solo approssimativamente normale. Nei casi in cui il ricercatore abbia un’idea approssimativa di dove sia centrato un parametro sconosciuto, la distribuzione normale fornisce un metodo utile per modellare questa stima, permettendo di descrivere il livello di incertezza tramite il termine di varianza della distribuzione normale. Questa convenienza può offrire buone approssimazioni alla densità a posteriori desiderata, con la consapevolezza che, con l’aumentare dei dati osservati, tali assunzioni perdono di importanza.\nCome dimostrato di seguito, il modello normale bayesiano possiede proprietà frequentiste desiderabili. Sebbene l’enfasi nell’analisi bayesiana non sia sulle stime puntuali, si può dimostrare che, con campioni sempre più grandi, la media della distribuzione a posteriori bayesiana si avvicina alla stima di massima verosimiglianza. Questa proprietà esiste perché la distribuzione a posteriori è un compromesso ponderato tra la distribuzione a priori specificata dall’utente, che in questo capitolo è normale, e la funzione di verosimiglianza derivata dai dati, anch’essa normale in questo capitolo. Con l’aumentare delle dimensioni del campione, la verosimiglianza diventa sempre più dominante in questa ponderazione.\nNel caso di una media normale, illustrato qui, la varianza della distribuzione di campionamento frequentista diminuisce con l’aumento della dimensione del campione. Nel contesto bayesiano, la riduzione della varianza media dalla funzione di verosimiglianza alla fine prevale anche su una varianza a priori deliberatamente grande. Pertanto, se si prevede che la dimensione del dataset sia grande, i ricercatori possono permettersi di essere liberali nella specificazione della varianza a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "title": "41  Distribuzioni coniugate (2)",
    "section": "41.3 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota",
    "text": "41.3 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota\nConsideriamo un insieme di dati \\(y = [y_1, y_2, \\ldots, y_n]\\), composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) secondo una distribuzione normale \\(\\mathcal{N}(\\mu, \\sigma^2)\\). In questo scenario, il nostro obiettivo è stimare il valore del parametro \\(\\mu\\), che rappresenta la media della popolazione da cui provengono i dati.\n\n41.3.1 Distribuzione a Priori\nNell’approccio bayesiano, assumiamo una conoscenza iniziale sul parametro \\(\\mu\\) mediante una distribuzione a priori. In questo caso, utilizziamo una distribuzione normale coniugata, ovvero una distribuzione normale con media \\(\\mu_0\\) e varianza \\(\\sigma_0^2\\). Questa scelta riflette la nostra incertezza iniziale su \\(\\mu\\).\n\n\n41.3.2 Funzione di Verosimiglianza\nLa funzione di verosimiglianza, denotata da \\(p(y | \\mu, \\sigma)\\), rappresenta la probabilità di osservare i dati \\(y\\) dato il valore del parametro \\(\\mu\\) e la varianza nota \\(\\sigma^2\\). Per una distribuzione normale i.i.d., la funzione di verosimiglianza è data da:\n\\[\np(y | \\mu, \\sigma) = \\prod_{i=1}^n \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(y_i - \\mu)^2}{2\\sigma^2}\\right).\n\\]\n\n\n41.3.3 Teorema di Bayes e Distribuzione a Posteriori\nIl teorema di Bayes combina la distribuzione a priori con la funzione di verosimiglianza per ottenere la distribuzione a posteriori del parametro \\(\\mu\\), data l’evidenza osservata \\(y\\):\n\\[\np(\\mu | y) = \\frac{ p(y | \\mu) p(\\mu) }{ p(y) }.\n\\]\nPoiché la distribuzione a priori e la funzione di verosimiglianza sono entrambe distribuzioni normali, la distribuzione a posteriori risulterà anch’essa una distribuzione normale con media a posteriori \\(\\mu_p\\) e varianza a posteriori \\(\\sigma_p^2\\).\n\n\n41.3.4 Formula per la Media a Posteriori (\\(\\mu_p\\))\nLa media a posteriori \\(\\mu_p\\) rappresenta la stima aggiornata del parametro \\(\\mu\\) alla luce delle informazioni contenute nei dati osservati. La sua formula è:\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2} \\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}},\n\\]\ndove \\(\\bar{y}\\) rappresenta la media campionaria:\n\\[\n\\bar{y} = \\frac{\\sum_{i=1}^n y_i}{n}.\n\\]\nOsserviamo che \\(\\mu_p\\) è una combinazione ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\). Il peso di \\(\\bar{y}\\) aumenta con il numero di osservazioni \\(n\\), mentre il peso di \\(\\mu_0\\) diminuisce. Questo riflette il fatto che con più dati, la nostra fiducia nella media campionaria cresce, mentre l’incertezza a priori diminuisce.\n\n\n41.3.5 Formula per la Varianza a Posteriori (\\(\\sigma_p^2\\))\nLa varianza a posteriori \\(\\sigma_p^2\\) rappresenta l’incertezza residua sulla stima del parametro \\(\\mu\\) dopo aver incorporato le informazioni dai dati. La sua formula è:\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}.\n\\]\nRispetto alla varianza a priori \\(\\sigma_0^2\\), la varianza a posteriori \\(\\sigma_p^2\\) è sempre inferiore o uguale. In altre parole, l’incertezza sulla stima di \\(\\mu\\) si riduce con l’aumentare del numero di osservazioni. La varianza a posteriori rappresenta un bilanciamento tra l’incertezza a priori (\\(\\sigma_0^2\\)) e l’informazione derivata dai dati (\\(\\sigma^2/n\\)).\nIn sintesi, nel caso normale-normale con varianza nota, la distribuzione a posteriori risulta essere una distribuzione normale con una media e una varianza che riflettono un’integrazione bilanciata tra l’informazione a priori e quella ottenuta dai dati osservati. Questo approccio garantisce una stima aggiornata e affinata del parametro \\(\\mu\\) che migliora con l’aumento del numero di osservazioni.\n\nEsempio 41.1 I test standard di QI sono progettati per misurare l’intelligenza con una media di 100 e una deviazione standard di 15. Tuttavia, si dice anche che questi test presentino bias culturali che favoriscono alcuni gruppi rispetto ad altri. Un’ulteriore complicazione si verifica quando i punteggi di QI vengono aggregati a livello nazionale, poiché le caratteristiche interne ai paesi vengono mascherate. Questo esempio analizza i dati di QI raccolti a livello internazionale (Lynn e Vanhanen, 2001) per 80 paesi da fonti nazionali pubblicate e discussi da Gill (2015). L’idea chiave nella descrizione della distribuzione a posteriori è se le differenze tra le nazioni alterano la parametrizzazione prevista.\nI dati di Lynn e Vanhanen (2001) sono forniti di seguito:\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\n\n\n\n\nArgentina\n96\nAustralia\n98\nAustria\n102\nBarbados\n78\n\n\nBelgium\n100\nBrazil\n87\nBulgaria\n93\nCanada\n97\n\n\nChina\n100\nCongo (Br.)\n73\nCongo (Zr.)\n65\nCroatia\n90\n\n\nCuba\n85\nCzech Repub.\n97\nDenmark\n98\nEcuador\n80\n\n\nEgypt\n83\nEq. Guinea\n59\nEthiopia\n63\nFiji\n84\n\n\nFinland\n97\nFrance\n98\nGermany\n102\nGhana\n71\n\n\nGreece\n92\nGuatemala\n79\nGuinea\n66\nHong Kong\n107\n\n\nHungary\n99\nIndia\n81\nIndonesia\n89\nIran\n84\n\n\nIraq\n87\nIreland\n93\nIsrael\n94\nItaly\n102\n\n\nJamaica\n72\nJapan\n105\nKenya\n72\nKorea (S.)\n106\n\n\nLebanon\n86\nMalaysia\n92\nMarshall I.\n84\nMexico\n87\n\n\nMorocco\n85\nNepal\n78\nNetherlands\n102\nNew Zealand\n100\n\n\nNigeria\n67\nNorway\n98\nPeru\n90\nPhilippines\n86\n\n\nPoland\n99\nPortugal\n95\nPuerto Rico\n84\nQatar\n78\n\n\nRomania\n94\nRussia\n96\nSamoa\n87\nSierra Leone\n64\n\n\nSingapore\n103\nSlovakia\n96\nSlovenia\n95\nSouth Africa\n72\n\n\nSpain\n97\nSudan\n72\nSuriname\n89\nSweden\n101\n\n\nSwitzerland\n101\nTaiwan\n104\nTanzania\n72\nThailand\n91\n\n\nTonga\n87\nTurkey\n90\nUganda\n73\nU.K.\n100\n\n\nU.S.\n98\nUruguay\n96\nZambia\n77\nZimbabwe\n66\n\n\n\nImplementiamo le informazioni necessarie in Python.\n\n# Dati IQ delle 80 nazioni\niq &lt;- c(\n  96, 100, 100, 85, 83, 97, 92, 99, 87, 72, 86, 85, 67, 99, 94, 103, 97, 101, 87, 98,\n  87, 73, 97, 59, 98, 79, 81, 93, 105, 92, 78, 98, 95, 96, 72, 104, 90, 96, 98, 102,\n  78, 90, 63, 84, 84, 107, 86, 102, 106, 94, 102, 72, 101, 89, 72, 101, 91, 100, 100,\n  66, 107, 86, 78, 84, 78, 64, 72, 101, 91, 100, 67, 86\n)\n\n\n# Numero di osservazioni\nn &lt;- length(iq)\n\n# Media campionaria\ny_bar &lt;- mean(iq)\n\n# Deviazione standard nota\nsigma &lt;- 15\n\n# Parametri a priori\nmu_0 &lt;- 100\nsigma_0 &lt;- 15\n\nCalcoliamo la media a posteriori con la formula discussa in precedenza\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\ndove:\n\n\\(\\mu_0\\) è la media a priori\n\\(\\sigma_0\\) è la deviazione standard a priori\n\\(n\\) è il numero di osservazioni\n\\(\\sigma\\) è la deviazione standard delle osservazioni (nota)\n\\(\\bar{y}\\) è la media campionaria\n\n\nmu_p &lt;- ((1 / sigma_0^2) * mu_0 + (n / sigma^2) * y_bar) /\n  ((1 / sigma_0^2) + (n / sigma^2))\nprint(paste(\"Media a posteriori (mu_p):\", round(mu_p, 2)))\n#&gt; [1] \"Media a posteriori (mu_p): 89.36\"\n\nCalcoliamo la varianza a posteriori\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}}\n\\]\n\nsigma_p_sq &lt;- 1 / ((1 / sigma_0^2) + (n / sigma^2))\nsigma_p &lt;- sqrt(sigma_p_sq)\nprint(paste(\"Varianza a posteriori (sigma_p_sq):\", round(sigma_p_sq, 2)))\n#&gt; [1] \"Varianza a posteriori (sigma_p_sq): 3.08\"\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto mu_0 = 100 e sigma_0 = 15 per la distribuzione a priori.\n\n# Definizione dei valori sull'asse x\nx &lt;- seq(mu_p - 4 * sigma_p, mu_p + 4 * sigma_p, length.out = 1000)\n\n# Calcolo della densità di probabilità\npdf &lt;- dnorm(x, mean = mu_p, sd = sigma_p)\n\n# Creazione del grafico\nggplot(data.frame(x = x, pdf = pdf), aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\", size = 1) +\n  geom_area(aes(fill = \"Posterior\"), alpha = 0.2) +\n  scale_fill_manual(values = c(\"blue\")) +\n  labs(\n    title = \"Distribuzione a Posteriori\",\n    x = \"Media del Quoziente di Intelligenza\",\n    y = \"Densità di probabilità\"\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nL’analisi condotta mediante un modello bayesiano basato sulla distribuzione normale ha prodotto un risultato interessante: la media stimata della distribuzione a posteriori del QI si attesta a 89.36, un valore sensibilmente inferiore ai 100 punti previsti come media standard.\nTuttavia, per un’interpretazione completa di questo dato, è fondamentale adottare un approccio critico che consideri alcuni aspetti cruciali:\n\nLa media a posteriori è ottenuta aggregando i dati QI di 80 nazioni diverse. Questo processo può innescare un effetto di aggregazione, dove la media “smussata” risultante non rispecchia accuratamente la distribuzione del QI a livello individuale in ogni singola nazione. Di conseguenza, le differenze tra le nazioni in termini di QI medio e variabilità potrebbero essere mascherate da questa media aggregata.\nÈ importante sottolineare che la media a posteriori viene calcolata utilizzando dati non ponderati per ogni nazione. Ciò significa che nazioni con popolazioni più piccole, anche se con punteggi QI mediamente più alti o più bassi, hanno lo stesso impatto sulla media aggregata rispetto a nazioni con popolazioni più grandi. Questo aspetto potrebbe ulteriormente distorcere la rappresentazione della vera distribuzione globale del QI.\nLa deviazione osservata dalla media standard di 100 potrebbe non riflettere esclusivamente differenze nell’intelligenza media tra le nazioni, ma anche differenze nei contesti sanitari, sociologici e politici in cui i test sono stati somministrati. Fattori quali l’accesso all’istruzione, la qualità della nutrizione e l’esposizione a stimoli cognitivi possono influenzare i punteggi QI ottenuti e contribuire alla variabilità osservata tra le nazioni.\nInoltre, è fondamentale considerare la possibilità di un bias culturale intrinseco allo strumento stesso. I test del QI sono stati originariamente progettati per un contesto specifico (paese industrializzato di lingua inglese) e potrebbero non essere adatti o culturalmente sensibili a contesti differenti. Questo potrebbe portare a una sottostima dei punteggi QI in alcune nazioni e influenzare la media a posteriori aggregata.\n\nQuesti risultati evidenziano l’importanza di un’attenta considerazione dei fattori metodologici quando si interpretano dati di test del QI a livello trans-culturale. L’effetto di aggregazione, l’utilizzo di medie non ponderate, le differenze nei contesti e il potenziale bias culturale richiedono un’analisi più approfondita che consideri questi fattori e utilizzi metodi statistici più sofisticati per ottenere una comprensione più completa delle differenze nel QI tra le nazioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#riflessioni-conclusive",
    "title": "41  Distribuzioni coniugate (2)",
    "section": "41.4 Riflessioni Conclusive",
    "text": "41.4 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito il meccanismo dell’aggiornamento bayesiano attraverso l’implementazione del modello normale-normale. Il processo inizia definendo una distribuzione a priori per \\(\\mu\\), specificata da una media \\(\\mu_0\\) e una varianza \\(\\sigma_0^2\\). Dopo l’acquisizione di nuovi dati, ipotizzando che seguano una distribuzione Normale con media campionaria \\(\\bar{y}\\) e varianza nota \\(\\sigma^2\\), implementiamo il teorema normale-normale per derivare la distribuzione a posteriori del parametro.\nLa media della distribuzione a posteriori, denotata come \\(\\mu_{\\text{post}}\\), si configura come una media ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\), dove il peso assegnato a ciascuna media è determinato dalle rispettive varianze \\(\\sigma_0^2\\) e \\(\\sigma^2\\) della distribuzione a priori e dei dati osservati. Analogamente, la varianza a posteriori \\(\\sigma_{\\text{post}}^2\\) è determinata utilizzando un’espressione che incorpora entrambe le varianze.\nIn sintesi, l’adozione del modello normale-normale in un contesto bayesiano facilita il calcolo delle distribuzioni a posteriori, grazie alla scelta di una distribuzione a priori Normale che mantiene la proprietà di coniugatezza, semplificando così l’intero processo analitico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "41  Distribuzioni coniugate (2)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.0       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#bibliografia",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#bibliografia",
    "title": "41  Distribuzioni coniugate (2)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGill, J. (2015). Bayesian methods: A social and behavioral sciences approach (3rd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/introduction_mcmc.html",
    "href": "chapters/mcmc/introduction_mcmc.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, ci concentreremo sulle procedure Monte Carlo a catena di Markov, con particolare attenzione all’algoritmo di Metropolis, che consente di approssimare la distribuzione a posteriori quando non è possibile ottenere una soluzione analitica. Esploreremo il concetto di predizione bayesiana, fondamentale per la costruzione della distribuzione predittiva a posteriori, e discuteremo anche la distribuzione predittiva a priori. Applicheremo l’inferenza bayesiana a diversi contesti, tra cui la stima di una proporzione, il confronto tra due proporzioni, la stima di una media da una distribuzione normale e il confronto tra due medie. Esamineremo inoltre il modello bayesiano di Poisson per l’analisi delle frequenze. Infine, introdurremo il modello gerarchico bayesiano, uno strumento potente per affrontare situazioni in cui le osservazioni sono strutturate su diversi livelli di incertezza.",
    "crumbs": [
      "MCMC",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html",
    "href": "chapters/mcmc/04_stan_summary_posterior.html",
    "title": "42  Metodi di sintesi della distribuzione a posteriori",
    "section": "",
    "text": "42.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nL’obiettivo di questo capitolo è illustrare come sintetizzare una distribuzione a posteriori ottenuta attraverso il campionamento MCMC (Markov Chain Monte Carlo). Questa tecnica è fondamentale nell’inferenza bayesiana moderna, permettendo di comprendere e interpretare i parametri di interesse in modo probabilistico.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#introduzione",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#introduzione",
    "title": "42  Metodi di sintesi della distribuzione a posteriori",
    "section": "",
    "text": "42.1.1 Cos’è la Distribuzione a Posteriori?\nLa distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri di interesse. Essa combina l’informazione iniziale (distribuzione a priori) con le evidenze empiriche (dati osservati) attraverso il modello statistico. È un concetto chiave che distingue l’approccio bayesiano dall’inferenza classica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "title": "42  Metodi di sintesi della distribuzione a posteriori",
    "section": "42.2 Sintesi della Distribuzione a Posteriori",
    "text": "42.2 Sintesi della Distribuzione a Posteriori\nIl risultato di un’analisi bayesiana è una distribuzione a posteriori, contenente tutte le informazioni sui parametri dati un modello e un insieme di dati. Pertanto, riassumere la distribuzione a posteriori significa sintetizzare le conseguenze logiche del modello e dei dati analizzati. È prassi comune riportare, per ciascun parametro, una misura di posizione centrale (come la media, la moda o la mediana) per fornire un’idea della localizzazione della distribuzione, accompagnata da una misura di dispersione, quale la deviazione standard, per quantificare l’incertezza delle stime. La deviazione standard è adeguata per distribuzioni simili alla normale, ma può risultare fuorviante per distribuzioni di altra natura, come quelle asimmetriche.\nPer riassumere la dispersione di una distribuzione a posteriori, si utilizza spesso l’Intervallo di Densità Più Alta (HDI, Highest-Density Interval). L’HDI è l’intervallo più breve che contiene una data porzione della densità di probabilità. Ad esempio, se diciamo che l’HDI al 95% per un’analisi è [2, 5], intendiamo che, secondo i nostri dati e modello, il parametro in questione si trova tra 2 e 5 con una probabilità di 0.95. Non vi è nulla di particolare nella scelta del 95%, del 50% o di qualsiasi altro valore; siamo liberi di scegliere, ad esempio, l’intervallo HDI all’89% o al 94% secondo le nostre preferenze. Idealmente, le giustificazioni per queste scelte dovrebbero dipendere dal contesto e non essere automatiche, ma è accettabile stabilire un valore comune come il 95%.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#campionamento-con-stan",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#campionamento-con-stan",
    "title": "42  Metodi di sintesi della distribuzione a posteriori",
    "section": "42.3 Campionamento con Stan",
    "text": "42.3 Campionamento con Stan\nA scopo illustrativo, immaginiamo di aver condotto un’analisi campionando casualmente 100 opere dal Museum of Modern Art (MoMA) e di aver riscontrato che 14 sono di artisti della Generazione X. Utilizzeremo un modello Beta-Binomiale per affrontare questo problema. Il parametro θ rappresenterà la proporzione di artisti della Generazione X. Adotteremo una distribuzione a priori Beta(4, 6), che riflette un’aspettativa iniziale basata su conoscenze pregresse. I dati osservati (14 opere su 100) verranno utilizzati per aggiornare questa distribuzione iniziale.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#implementazione-in-stan",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#implementazione-in-stan",
    "title": "42  Metodi di sintesi della distribuzione a posteriori",
    "section": "42.4 Implementazione in Stan",
    "text": "42.4 Implementazione in Stan\nIl seguente codice Stan definisce il nostro modello probabilistico:\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"moma.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N;           // Numero totale di prove\n#&gt;   int&lt;lower=0&gt; y;           // Numero di successi osservati\n#&gt;   real&lt;lower=0&gt; alpha_prior; // Parametro alpha della distribuzione Beta a priori\n#&gt;   real&lt;lower=0&gt; beta_prior;  // Parametro beta della distribuzione Beta a priori\n#&gt; }\n#&gt; \n#&gt; parameters {\n#&gt;   real&lt;lower=0, upper=1&gt; theta; // Probabilità di successo\n#&gt; }\n#&gt; \n#&gt; model {\n#&gt;   // Distribuzione a priori Beta\n#&gt;   theta ~ beta(alpha_prior, beta_prior);\n#&gt;   \n#&gt;   // Likelihood binomiale\n#&gt;   y ~ binomial(N, theta);\n#&gt; }\n#&gt; \n#&gt; generated quantities {\n#&gt;   real log_lik; // Log-verosimiglianza\n#&gt;   log_lik = binomial_lpmf(y | N, theta);\n#&gt; }\n\nProcediamo con l’implementazione pratica del modello per stimare la proporzione di artisti della Generazione X (θ) al MoMA.\nDefiniamo i dati osservati e i parametri della distribuzione a priori:\n\nN &lt;- 100\ny &lt;- 14\n\nstan_data &lt;- list(\n  N = N,\n  y = y,\n  alpha_prior = 4,\n  beta_prior = 6\n)\n\nEseguiamo il campionamento utilizzando il modello compilato in precedenza:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000, \n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nPer evitare di dover ripetere il campionamento (che può essere computazionalmente costoso), possiamo salvare l’oggetto fit su disco utilizzando la funzione qsave() del pacchetto qs. Questo garantisce un caricamento rapido e senza perdita di dati.\n\n# Save the object to a file.\nqs::qsave(x = fit, file = \"fit_moma.qs\")\n\nSe in seguito vogliamo analizzare i risultati senza dover ripetere il campionamento, possiamo leggere l’oggetto salvato direttamente nel nostro ambiente R:\n\n# Read the object.\nfit2 &lt;- qs::qread(\"fit_moma.qs\")\n\nL’oggetto fit2 è identico a fit e contiene tutte le informazioni relative al modello, ai parametri, ai campioni e ai metadati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "title": "42  Metodi di sintesi della distribuzione a posteriori",
    "section": "42.5 Analisi della distribuzione a posteriori",
    "text": "42.5 Analisi della distribuzione a posteriori\nLa distribuzione a posteriori rappresenta la nostra conoscenza aggiornata riguardo al valore del parametro \\(\\theta\\) dopo aver osservato i dati. Combina le nostre credenze a priori riguardo al parametro (la distribuzione a priori) con le nuove evidenze fornite dai dati osservati (la funzione di verosimiglianza) per ottenere una nuova distribuzione che riflette la nostra comprensione aggiornata del parametro, ovvero la distribuzione a posteriori.\nLa distribuzione a posteriori ci dice quanto sia probabile ogni possibile valore del parametro alla luce dei dati osservati. Un picco stretto indica che i dati sono molto informativi rispetto al parametro, portando a una maggiore certezza nella sua stima. Un picco largo, invece, indica maggiore incertezza.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#esaminare-i-valori-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#esaminare-i-valori-della-distribuzione-a-posteriori",
    "title": "42  Metodi di sintesi della distribuzione a posteriori",
    "section": "42.6 Esaminare i Valori della Distribuzione a Posteriori",
    "text": "42.6 Esaminare i Valori della Distribuzione a Posteriori\nDopo aver eseguito il campionamento con Stan, possiamo esaminare i valori della distribuzione a posteriori accedendo ai campioni generati.\n\n42.6.1 Estrarre i Campioni in un Oggetto draws_array\nIl metodo fit$draws() restituisce i campioni in un oggetto tridimensionale del tipo draws_array, che fa parte del pacchetto posterior.\n\n# Estrazione dei campioni posteriori in formato array (default)\ndraws_arr &lt;- fit2$draws()  \nstr(draws_arr)  # Struttura dell'oggetto\n#&gt;  'draws_array' num [1:2000, 1:4, 1:3] -50 -49.7 -49 -49.1 -51.4 ...\n#&gt;  - attr(*, \"dimnames\")=List of 3\n#&gt;   ..$ iteration: chr [1:2000] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;   ..$ chain    : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n#&gt;   ..$ variable : chr [1:3] \"lp__\" \"theta\" \"log_lik\"\n\nL’output sarà un array 3D con le dimensioni iterazioni × catene × variabili, ovvero il formato standard per i campioni MCMC.\nPer verificare le dimensioni dell’array:\n\ndim(draws_arr)\n#&gt; [1] 2000    4    3\n\nAd esempio, se l’output di dim(draws_arr) restituisce (2000, 4, 3), le dimensioni si riferiscono a:\n\n2000: Numero di iterazioni di campionamento per ciascuna catena, specificato dall’argomento iter_sampling = 2000 durante il campionamento.\n4: Numero di catene eseguite in parallelo, specificato da chains = 4.\n3: Numero di parametri o quantità campionate, inclusi:\n\nParametri definiti nel blocco parameters del modello Stan.\nQuantità trasformate (transformed parameters).\nQuantità generate (generated quantities).\n\n\n\n\n42.6.2 Interpretazione della Struttura\nL’array 3D permette di accedere ai campioni in modo organizzato:\n\nPrima dimensione: Iterazioni per ciascuna catena (es. draws_arr[1,,] restituisce i valori della prima iterazione di tutte le catene).\nSeconda dimensione: Catene (es. draws_arr[,1,] restituisce tutti i campioni della prima catena).\nTerza dimensione: Variabili campionate (es. draws_arr[,,1] restituisce i valori della prima variabile in tutte le iterazioni e catene).\n\n\n\n42.6.3 Accesso ai Parametri\nPer accedere ai campioni di un parametro specifico, possiamo utilizzare il nome del parametro con il metodo fit$draws(format = \"matrix\") o fit$draws(format = \"df\").\n\n# Estrazione dei campioni in formato data frame\ndraws_df &lt;- fit2$draws(format = \"df\")\n\n# Visualizza i primi campioni della variabile \"theta\"\nhead(draws_df$theta)\n#&gt; [1] 0.1187770 0.1252060 0.1680210 0.1477010 0.0971118 0.0866890\n\n\n\n42.6.4 Sintesi dei Campioni\nPer riassumere i campioni della distribuzione a posteriori:\n\n# Riassunto della distribuzione a posteriori\nfit2$summary()\n#&gt; # A tibble: 3 × 10\n#&gt;   variable    mean  median     sd    mad      q5     q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -49.5   -49.2   0.697  0.292  -50.9   -49.0    1.00    3699.\n#&gt; 2 theta      0.164   0.162 0.0345 0.0339   0.112   0.225  1.00    2813.\n#&gt; 3 log_lik   -2.78   -2.46  0.827  0.397   -4.48   -2.17   1.00    3803.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n\n42.6.5 Vantaggi del Formato draws_array\nIl formato draws_array è particolarmente utile per:\n\nAnalisi avanzate: Permette di accedere direttamente a specifiche iterazioni, catene e parametri.\nVisualizzazioni: È compatibile con funzioni di plotting del pacchetto bayesplot.\nControlli diagnostici: Facilita l’analisi della convergenza e della miscelazione delle catene.\n\nCon questa struttura, possiamo esplorare in dettaglio la distribuzione a posteriori generata dal modello Stan.\n\nfit2$metadata()$model_params\n#&gt; [1] \"lp__\"    \"theta\"   \"log_lik\"\n\nRecuperiamo i campioni posteriori per theta:\n\n# draws x variables data frame\ndraws_df &lt;- fit2$draws(format = \"df\")\nhead(draws_df)\n#&gt; # A draws_df: 6 iterations, 1 chains, and 3 variables\n#&gt;   lp__ theta log_lik\n#&gt; 1  -50 0.119    -2.4\n#&gt; 2  -50 0.125    -2.3\n#&gt; 3  -49 0.168    -2.5\n#&gt; 4  -49 0.148    -2.2\n#&gt; 5  -51 0.097    -3.1\n#&gt; 6  -52 0.087    -3.7\n#&gt; # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\ndraws_df$theta |&gt;\n  head()\n#&gt; [1] 0.1187770 0.1252060 0.1680210 0.1477010 0.0971118 0.0866890\n\n\nlength(draws_df$theta)\n#&gt; [1] 8000\n\nGeneriamo un istogramma della distribuzione a posteriori di theta:\n\ndraws_df |&gt;\n  ggplot(aes(theta)) +\n  geom_histogram()\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nIn alternativa, possiamo passare l’oggetto fit$draws(\"theta\") alla funzione mcmc_hist() di bayesplot:\n\nmcmc_hist(fit2$draws(\"theta\"))\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nOppure possiamo usare la funzione mcmc_dens_overlay():\n\nmcmc_dens_overlay(fit2$draws(\"theta\"))\n\n\n\n\n\n\n\n\nLa traccia del campionamento si ottiene nel modo seguente:\n\nmcmc_trace(fit2$draws(\"theta\"))\n\n\n\n\n\n\n\n\nConfrontiamo la distribuzione a posteriori con la distribuzione a priori di \\(\\theta\\).\n\n# Parameters of the Beta distribution\nalpha &lt;- 4\nbeta_param &lt;- 6\n\n# Create a data frame for the prior Beta distribution\nx &lt;- seq(0, 1, length.out = 1000)\nprior_pdf &lt;- dbeta(x, alpha, beta_param)\nprior_df &lt;- data.frame(theta = x, density = prior_pdf, distribution = \"Prior\")\n\n# Extract posterior draws of theta and calculate density\nposterior_theta &lt;- as.vector(fit2$draws(\"theta\")) # Assuming `fit2$draws(\"theta\")` works\nposterior_density &lt;- density(posterior_theta)\nposterior_df &lt;- data.frame(\n  theta = posterior_density$x,\n  density = posterior_density$y,\n  distribution = \"Posterior\"\n)\n\n# Combine the prior and posterior data\ncombined_df &lt;- bind_rows(prior_df, posterior_df)\n\n# Plot using ggplot2\nggplot(combined_df, aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Density\",\n    title = \"Prior and Posterior Distributions\"\n  ) +\n  scale_color_manual(\n    values = c(\"Prior\" = \"black\", \"Posterior\" = \"red\"),\n    name = \"Distribution\"\n  ) +\n  theme(\n    legend.position = \"top\",\n    plot.title = element_text(hjust = 0.5)\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nNel caso presente, la distribuzione a posteriori differisce in maniera importante dalla distribuzione a priori. Ciò indica che i dati hanno avuto un forte impatto sulle nostre credenze riguardo al valore del parametro.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#intervallo-di-credibilità",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#intervallo-di-credibilità",
    "title": "42  Metodi di sintesi della distribuzione a posteriori",
    "section": "42.7 Intervallo di Credibilità",
    "text": "42.7 Intervallo di Credibilità\nGli intervalli di credibilità sono uno strumento fondamentale nell’inferenza bayesiana per riassumere l’incertezza sui parametri stimati. Esistono due metodi principali per calcolare gli intervalli di credibilità:\n\nHighest Density Interval (HDI): definisce l’intervallo più stretto che contiene la probabilità specificata, includendo le aree di maggiore densità della distribuzione a posteriori.\nEqual-tailed Interval (ETI): lascia una probabilità uguale (ad esempio, il 2,5% per un intervallo al 95%) in entrambe le code della distribuzione.\n\nQuesti metodi producono risultati identici in caso di distribuzioni simmetriche ma differiscono per distribuzioni asimmetriche. Di seguito vediamo come interpretare e calcolare questi intervalli.\nDistribuzione Simmetrica\nCon una distribuzione a posteriori simmetrica, come quella normale, gli intervalli HDI ed ETI coincidono.\nEsempio di calcolo:\n\n# Genera una distribuzione normale\nposterior &lt;- distribution_normal(1000)\n\n# Calcola HDI ed ETI\nci_hdi &lt;- ci(posterior, method = \"HDI\")\nci_eti &lt;- ci(posterior, method = \"ETI\")\n\n# Visualizza la distribuzione con i limiti degli intervalli\nout &lt;- estimate_density(posterior, extend = TRUE)\nggplot(out, aes(x = x, y = y)) +\n  geom_area(fill = \"orange\") +\n  # HDI in blu\n  geom_vline(xintercept = ci_hdi$CI_low, color = \"royalblue\", linewidth = 3) +\n  geom_vline(xintercept = ci_hdi$CI_high, color = \"royalblue\", linewidth = 3) +\n  # ETI in rosso\n  geom_vline(xintercept = ci_eti$CI_low, color = \"red\", linewidth = 1) +\n  geom_vline(xintercept = ci_eti$CI_high, color = \"red\", linewidth = 1)\n\n\n\n\n\n\n\n\nDistribuzione Asimmetrica\nQuando la distribuzione a posteriori è asimmetrica, come una distribuzione beta, l’HDI è generalmente più stretto rispetto all’ETI poiché privilegia le regioni di maggiore densità.\nEsempio di calcolo:\n\n# Genera una distribuzione beta\nposterior &lt;- distribution_beta(1000, 6, 2)\n\n# Calcola HDI ed ETI\nci_hdi &lt;- ci(posterior, method = \"HDI\")\nci_eti &lt;- ci(posterior, method = \"ETI\")\n\n# Visualizza la distribuzione con i limiti degli intervalli\nout &lt;- estimate_density(posterior, extend = TRUE)\nggplot(out, aes(x = x, y = y)) +\n  geom_area(fill = \"orange\") +\n  # HDI in blu\n  geom_vline(xintercept = ci_hdi$CI_low, color = \"royalblue\", linewidth = 3) +\n  geom_vline(xintercept = ci_hdi$CI_high, color = \"royalblue\", linewidth = 3) +\n  # ETI in rosso\n  geom_vline(xintercept = ci_eti$CI_low, color = \"red\", linewidth = 1) +\n  geom_vline(xintercept = ci_eti$CI_high, color = \"red\", linewidth = 1)\n\n\n\n\n\n\n\n\n\n42.7.1 Interpretazione dell’Intervallo di Credibilità\nL’intervallo di credibilità bayesiano offre una chiara interpretazione probabilistica: dato il modello e i dati, c’è una probabilità specificata (ad esempio, il 94%) che il parametro si trovi all’interno dell’intervallo calcolato.\n\n\n42.7.2 Calcolo degli intervalli in R\n\nHDI:\n\n\nbayestestR::ci(fit2$draws(\"theta\"), method = \"HDI\")\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |      95% HDI\n#&gt; ------------------------\n#&gt; theta     | [0.10, 0.23]\n\n\nETI:\n\n\nbayestestR::ci(fit2$draws(\"theta\"), method = \"ETI\")\n#&gt; Equal-Tailed Interval\n#&gt; \n#&gt; Parameter |      95% ETI\n#&gt; ------------------------\n#&gt; theta     | [0.10, 0.24]\n\n\n\n42.7.3 Visualizzazione grafica\nUtilizzando il pacchetto bayesplot possiamo rappresentare la distribuzione a posteriori con l’HDI:\n\nmcmc_areas(fit2$draws(\"theta\"), \n           prob = 0.94) +  # Specifica il livello dell'HDI\n  ggtitle(\"Distribuzione a Posteriori di Theta con HDI al 94%\") +\n  xlab(expression(theta)) +\n  ylab(\"Densità\")\n\n\n\n\n\n\n\n\n\n\n42.7.4 Confronto con gli Intervalli di Confidenza Frequentisti\nGli intervalli di credibilità bayesiani si distinguono nettamente dagli intervalli di confidenza frequentisti. Mentre gli intervalli frequentisti si basano su una prospettiva a lungo termine (ovvero, il 95% degli intervalli costruiti su infiniti campioni includerebbe il vero valore), gli intervalli bayesiani:\n\nHanno una chiara interpretazione probabilistica: dato il modello e i dati, indicano direttamente la probabilità che il parametro sia nell’intervallo.\nIncorporano credenze a priori, combinate con l’evidenza fornita dai dati.\n\n\n\n42.7.5 Scelta del Livello dell’Intervallo (89% vs 95%)\nUna discussione comune nell’inferenza bayesiana riguarda il livello predefinito degli intervalli. Sebbene il 95% sia un valore convenzionale mutuato dal frequentismo, alcune evidenze suggeriscono che livelli più bassi (ad esempio, 89%) possano essere più stabili per le distribuzioni a posteriori, specialmente con un numero limitato di campioni posteriori (Kruschke, 2014).\n\nVantaggi del 95%:\n\nRelazione intuitiva con la deviazione standard.\nMaggiore probabilità di includere 0, rendendo le analisi più conservative.\n\nVantaggi dell’89%:\n\nMaggiore stabilità con campioni posteriori limitati.\nEvita l’arbitrarietà del valore 95% (McElreath, 2018).\n\n\nIn conclusione, la scelta tra HDI e ETI, così come il livello dell’intervallo, dipende dagli obiettivi e dal contesto dell’analisi. Gli intervalli di credibilità offrono un approccio flessibile e intuitivo per sintetizzare l’incertezza, adattandosi alle esigenze di analisi sia esplorative che confermative.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#test-di-ipotesi-bayesiane",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#test-di-ipotesi-bayesiane",
    "title": "42  Metodi di sintesi della distribuzione a posteriori",
    "section": "42.8 Test di Ipotesi Bayesiane",
    "text": "42.8 Test di Ipotesi Bayesiane\nIn alcune situazioni, descrivere semplicemente la distribuzione a posteriori potrebbe non essere sufficiente. Potremmo dover prendere decisioni pratiche basate sulle inferenze, traducendo stime continue in scelte binarie. Ad esempio, possiamo voler determinare se una terapia è efficace, se un intervento ha avuto successo, o se una proporzione supera una soglia di rilevanza pratica.\nSupponiamo di voler verificare se, nel Museum of Modern Art (MoMA), gli artisti della generazione X (nati tra il 1965 e il 1980) rappresentano meno del 10% del corpus esposto. Analizzando un campione casuale di 100 opere e utilizzando un prior basato su convinzioni pregresse, stimiamo la distribuzione a posteriori della proporzione di artisti, \\(\\theta\\). L’intervallo di credibilità (Credible Interval, CI) al 94% risulta compreso tra 0.104 e 0.235.\nLa nostra ipotesi iniziale è che la proporzione di artisti della generazione X sia inferiore al 10%, cioè \\(\\theta &lt; 0.1\\). Tuttavia, il fatto che l’intero intervallo di credibilità al 94% si trovi sopra la soglia del 10% contraddice questa ipotesi. Per quantificare ulteriormente la compatibilità dei dati con questa ipotesi, calcoliamo la probabilità a posteriori che \\(\\theta &lt; 0.1\\).\n\nfit2$summary(\"theta\", pr_lt_01 = ~ mean(. &lt;= 0.1))\n#&gt; # A tibble: 1 × 2\n#&gt;   variable pr_lt_01\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;\n#&gt; 1 theta      0.0213\n\nLa probabilità a posteriori che \\(\\theta &lt; 0.1\\)** è molto bassa, ovvero \\(P(\\theta &lt; 0.1) = 0.0213\\), fornendo ulteriori evidenze contro l’ipotesi che gli artisti della generazione X rappresentino meno del 10% del corpus esposto.\nIn sintesi, sulla base dei dati e del modello, l’ipotesi che gli artisti della generazione X rappresentino meno del 10% non è supportata. Al contrario, i dati indicano, con un livello di certezza soggettiva del 94%, che la proporzione di artisti appartenenti a questa generazione è molto probabilmente superiore al 10%.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#riflessioni-conclusive",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#riflessioni-conclusive",
    "title": "42  Metodi di sintesi della distribuzione a posteriori",
    "section": "42.9 Riflessioni conclusive",
    "text": "42.9 Riflessioni conclusive\nLa crescente popolarità dei metodi bayesiani in psicologia e nelle scienze sociali è stata fortemente influenzata dalla (ri)scoperta di algoritmi numerici capaci di stimare le distribuzioni a posteriori dei parametri del modello a partire dai dati osservati. Prima di questi sviluppi, ottenere misure riassuntive delle distribuzioni a posteriori, soprattutto per modelli complessi con molti parametri, era praticamente impossibile.\nQuesto capitolo fornisce un’introduzione a cmdstanr, che permette di compilare ed eseguire modelli probabilistici espressi in linguaggio Stan. Grazie a questa tecnologia, è possibile generare una stima della distribuzione a posteriori attraverso il campionamento Markov Chain Monte Carlo (MCMC), rivoluzionando la capacità di effettuare inferenze bayesiane e rendendo l’analisi di modelli complessi più accessibile e gestibile.\nInoltre, nel capitolo sono state presentate diverse strategie per la trasformazione della distribuzione a posteriori e sono state esplorate modalità per ottenere intervalli di credibilità. Successivamente, è stata discussa l’analisi delle ipotesi a posteriori, che consente di confrontare due ipotesi contrapposte riguardanti il parametro \\(\\theta\\).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "42  Metodi di sintesi della distribuzione a posteriori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0           insight_1.0.0       bayestestR_0.15.0  \n#&gt;  [4] rstanarm_2.32.1     Rcpp_1.0.13-1       qs_0.27.2          \n#&gt;  [7] posterior_1.6.0     cmdstanr_0.8.1.9000 MASS_7.3-61        \n#&gt; [10] viridis_0.6.5       viridisLite_0.4.2   ggpubr_0.6.0       \n#&gt; [13] ggExtra_0.10.1      gridExtra_2.3       patchwork_1.3.0    \n#&gt; [16] bayesplot_1.11.1    psych_2.4.6.26      scales_1.3.0       \n#&gt; [19] markdown_1.13       knitr_1.49          lubridate_1.9.3    \n#&gt; [22] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [25] purrr_1.0.2         readr_2.1.5         tidyr_1.3.1        \n#&gt; [28] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [31] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;   [1] tensorA_0.36.2.1     jsonlite_1.8.9       datawizard_0.13.0   \n#&gt;   [4] magrittr_2.0.3       nloptr_2.1.1         farver_2.1.2        \n#&gt;   [7] rmarkdown_2.29       vctrs_0.6.5          minqa_1.2.8         \n#&gt;  [10] base64enc_0.1-3      rstatix_0.7.2        htmltools_0.5.8.1   \n#&gt;  [13] distributional_0.5.0 curl_6.0.1           broom_1.0.7         \n#&gt;  [16] Formula_1.2-5        StanHeaders_2.32.10  htmlwidgets_1.6.4   \n#&gt;  [19] plyr_1.8.9           zoo_1.8-12           igraph_2.1.1        \n#&gt;  [22] mime_0.12            lifecycle_1.0.4      pkgconfig_2.0.3     \n#&gt;  [25] colourpicker_1.3.0   Matrix_1.7-1         R6_2.5.1            \n#&gt;  [28] fastmap_1.2.0        shiny_1.9.1          digest_0.6.37       \n#&gt;  [31] colorspace_2.1-1     ps_1.8.1             rprojroot_2.0.4     \n#&gt;  [34] crosstalk_1.2.1      labeling_0.4.3       fansi_1.0.6         \n#&gt;  [37] timechange_0.3.0     abind_1.4-8          compiler_4.4.2      \n#&gt;  [40] withr_3.0.2          backports_1.5.0      inline_0.3.20       \n#&gt;  [43] shinystan_2.6.0      carData_3.0-5        QuickJSR_1.4.0      \n#&gt;  [46] pkgbuild_1.4.5       ggsignif_0.6.4       gtools_3.9.5        \n#&gt;  [49] loo_2.8.0            tools_4.4.2          httpuv_1.6.15       \n#&gt;  [52] threejs_0.3.3        glue_1.8.0           nlme_3.1-166        \n#&gt;  [55] promises_1.3.1       grid_4.4.2           checkmate_2.3.2     \n#&gt;  [58] reshape2_1.4.4       generics_0.1.3       gtable_0.3.6        \n#&gt;  [61] tzdb_0.4.0           data.table_1.16.2    RApiSerialize_0.1.4 \n#&gt;  [64] hms_1.1.3            stringfish_0.16.0    car_3.1-3           \n#&gt;  [67] utf8_1.2.4           pillar_1.9.0         later_1.4.0         \n#&gt;  [70] splines_4.4.2        lattice_0.22-6       survival_3.7-0      \n#&gt;  [73] tidyselect_1.2.1     miniUI_0.1.1.1       V8_6.0.0            \n#&gt;  [76] stats4_4.4.2         xfun_0.49            matrixStats_1.4.1   \n#&gt;  [79] DT_0.33              rstan_2.32.6         stringi_1.8.4       \n#&gt;  [82] yaml_2.3.10          pacman_0.5.1         boot_1.3-31         \n#&gt;  [85] evaluate_1.0.1       codetools_0.2-20     cli_3.6.3           \n#&gt;  [88] RcppParallel_5.1.9   shinythemes_1.2.0    xtable_1.8-4        \n#&gt;  [91] processx_3.8.4       munsell_0.5.1        parallel_4.4.2      \n#&gt;  [94] rstantools_2.4.0     dygraphs_1.1.1.6     lme4_1.1-35.5       \n#&gt;  [97] ggridges_0.5.6       xts_0.14.1           rlang_1.1.4         \n#&gt; [100] mnormt_2.1.1         shinyjs_2.1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html",
    "href": "chapters/mcmc/08_stan_odds_ratio.html",
    "title": "43  Analisi bayesiana dell’odds-ratio",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo, esploreremo l’applicazione degli strumenti statistici descritti nei capitoli precedenti all’analisi bayesiana di due proporzioni. Inizieremo definendo i concetti di odds, odds ratio e logit. Successivamente, mostreremo come effettuare l’analisi bayesiana per il confronto tra due proporzioni.\nUn rapporto di odds (OR) è una misura di associazione tra un’esposizione (o un certo gruppo o una certa conditione) e un risultato. L’OR rappresenta gli odds che si verifichi un risultato dato un’esposizione particolare, confrontate con gli odds del risultato che si verifica in assenza di tale esposizione.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#odds",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#odds",
    "title": "43  Analisi bayesiana dell’odds-ratio",
    "section": "43.1 Odds",
    "text": "43.1 Odds\nIl termine “odds” rappresenta il rapporto tra la probabilità che un evento si verifichi e la probabilità che l’evento opposto si verifichi. Matematicamente, l’odds può essere calcolato come:\n\\[\n\\text{odds} = \\frac{\\pi}{1-\\pi},\n\\]\ndove \\(\\pi\\) rappresenta la probabilità dell’evento di interesse.\nMentre una probabilità \\(\\pi\\) è sempre compresa tra 0 e 1, gli odds possono variare da 0 a infinito. Per comprendere meglio gli odds lungo questo spettro, consideriamo tre diversi scenari in cui \\(\\pi\\) rappresenta la probabilità di un evento.\nSe la probabilità di un evento è \\(\\pi = \\frac{2}{3}\\), allora la probabilità che l’evento non si verifichi è \\(1 - \\pi = \\frac{1}{3}\\) e gli odds del verificarsi dell’evento sono:\n\\[\n\\text{odds} = \\frac{2/3}{1-2/3} = 2.\n\\]\nQuesto significa che la probabilità che l’evento si verifichi è il doppio della probabilità che non si verifichi.\nSe, invece, la probabilità dell’evento è \\(\\pi = \\frac{1}{3}\\), allora gli odds che l’evento si verifichi sono la metà rispetto agli odds che non si verifichi:\n\\[\n\\text{odds} = \\frac{1/3}{1-1/3} = \\frac{1}{2}.\n\\]\nInfine, se la probabilità dell’evento è \\(\\pi = \\frac{1}{2}\\), allora gli odds dell’evento sono pari a 1:\n\\[\n\\text{odds} = \\frac{1/2}{1-1/2} = 1.\n\\]\n\n43.1.1 Interpretazione\nGli odds possono essere interpretati nel modo seguente. Consideriamo un evento di interesse con probabilità \\(\\pi \\in [0, 1]\\) e gli odds corrispondenti \\(\\frac{\\pi}{1-\\pi} \\in [0, \\infty)\\). Confrontando gli odds con il valore 1, possiamo ottenere una prospettiva sull’incertezza dell’evento:\n\nGli odds di un evento sono inferiori a 1 se e solo se le probabilità dell’evento sono inferiori al 50-50, cioè \\(\\pi &lt; 0.5\\).\nGli odds di un evento sono uguali a 1 se e solo se le probabilità dell’evento sono del 50-50, cioè \\(\\pi = 0.5\\).\nGli odds di un evento sono superiori a 1 se e solo se le probabilità dell’evento sono superiori al 50-50, cioè \\(\\pi &gt; 0.5\\).\n\nUno dei motivi per preferire l’uso dell’odds rispetto alla probabilità, nonostante quest’ultima sia un concetto più intuitivo, risiede nel fatto che quando le probabilità si avvicinano ai valori estremi (cioè 0 o 1), è più facile rilevare e apprezzare le differenze tra gli odds piuttosto che le differenze tra le probabilità.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#odds-ratio",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#odds-ratio",
    "title": "43  Analisi bayesiana dell’odds-ratio",
    "section": "43.2 Odds Ratio",
    "text": "43.2 Odds Ratio\nQuando abbiamo una variabile di interesse espressa come proporzione, possiamo confrontare i gruppi utilizzando l’odds ratio. L’odds ratio rappresenta il rapporto tra gli odds di un evento in un gruppo e gli odds dello stesso evento in un secondo gruppo:\n\\[\nOR = \\frac{odds_1}{odds_2} = \\frac{p_1/(1-p_1)}{p_2/(1-p_2)}.\n\\]\nInterpretazione:\n\nOR = 1: l’appartenenza al gruppo non influenza il risultato;\nOR &gt; 1: l’appartenenza al gruppo specificato al numeratore dell’OR aumenta la probabilità dell’evento rispetto al gruppo specificato al denominatore;\nOR &lt; 1: l’appartenenza al gruppo specificato al numeratore dell’OR riduce la probabilità dell’evento rispetto al gruppo specificato al denominatore.\n\nL’odds ratio è particolarmente utile quando vogliamo confrontare due gruppi e vedere come l’appartenenza a uno di essi influenza la probabilità di un certo evento. Ad esempio, consideriamo uno studio psicologico in cui stiamo valutando l’efficacia di una terapia comportamentale per ridurre l’ansia. Possiamo suddividere i partecipanti allo studio in due gruppi: quelli che sono stati sottoposti al trattamento (gruppo di trattamento) e quelli che non sono stati sottoposti al trattamento (gruppo di controllo).\nCalcolando l’odds ratio tra il gruppo di trattamento e il gruppo di controllo, possiamo capire se la terapia ha aumentato o ridotto la probabilità di riduzione dell’ansia. Se l’odds ratio è maggiore di 1, significa che la terapia ha aumentato le probabilità di riduzione dell’ansia; se è inferiore a 1, significa che il trattamento ha ridotto le probabilità di riduzione dell’ansia. L’odds ratio ci fornisce quindi una misura dell’effetto della terapia rispetto al controllo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#logaritmo-dellodds-ratio",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#logaritmo-dellodds-ratio",
    "title": "43  Analisi bayesiana dell’odds-ratio",
    "section": "43.3 Logaritmo dell’Odds Ratio",
    "text": "43.3 Logaritmo dell’Odds Ratio\nIl logaritmo dell’odds ratio è una trasformazione matematica molto utilizzata nell’analisi statistica, specialmente nella regressione logistica. Essa permette di rendere l’odds ratio interpretabile su una scala lineare, semplificando l’analisi e l’interpretazione dei risultati.\nLa formula per calcolare il logaritmo dell’odds ratio è la seguente:\n\\[\n\\text{logit}(OR) = \\log(OR) = \\log\\left(\\frac{odds_1}{odds_2}\\right).\n\\]\nIn altre parole, il logaritmo dell’odds ratio è il logaritmo naturale del rapporto tra gli odds di un evento nel primo gruppo e gli odds dello stesso evento nel secondo gruppo.\n\n43.3.1 Interpretazione\nL’interpretazione del logaritmo dell’odds ratio è più intuitiva rispetto all’odds ratio stesso. Una variazione di una unità nel logaritmo dell’odds ratio corrisponde a un cambiamento costante nell’odds ratio stesso.\nSe il logaritmo dell’odds ratio è positivo, significa che l’odds dell’evento nel primo gruppo è maggiore rispetto al secondo gruppo. Più il valore del logaritmo dell’odds ratio si avvicina a zero, più l’odds dell’evento nei due gruppi si avvicina a essere simile.\nSe, invece, il logaritmo dell’odds ratio è negativo, l’odds dell’evento nel primo gruppo è inferiore rispetto al secondo gruppo. Un valore di logaritmo dell’odds ratio vicino a zero indica che l’odds dell’evento è simile nei due gruppi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#analisi-bayesiana-delle-proporzioni",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#analisi-bayesiana-delle-proporzioni",
    "title": "43  Analisi bayesiana dell’odds-ratio",
    "section": "43.4 Analisi bayesiana delle proporzioni",
    "text": "43.4 Analisi bayesiana delle proporzioni\nUna volta compresi i concetti di odds, odds ratio e logit, possiamo procedere all’analisi bayesiana delle proporzioni. Questo approccio consente di confrontare le proporzioni di due gruppi, ottenendo stime delle probabilità a posteriori e degli intervalli di credibilità.\nL’analisi bayesiana si basa sull’applicazione del teorema di Bayes per aggiornare le conoscenze a priori con l’evidenza fornita dai dati osservati. Questo permette di ottenere una distribuzione a posteriori delle quantità di interesse, come l’odds ratio.\nIn questo capitolo, analizzeremo un set di dati fittizio ispirato a un classico esperimento di etologia descritto da Hoffmann et al. (2022). Von Frisch (1914) ha voluto verificare se le api possiedono la visione dei colori confrontando il comportamento di due gruppi di api. L’esperimento si compone di una fase di addestramento e di una fase di test.\nNella fase di addestramento, le api del gruppo sperimentale vengono esposte a un disco blu e a un disco verde. Solo il disco blu è ricoperto di una soluzione zuccherina, molto appetita dalle api. Il gruppo di controllo, invece, non riceve alcun addestramento.\nNella fase di test, la soluzione zuccherina viene rimossa dal disco blu e si osserva il comportamento di entrambi i gruppi. Se le api del gruppo sperimentale hanno appreso che solo il disco blu contiene la soluzione zuccherina e sono in grado di distinguere tra il blu e il verde, dovrebbero preferire esplorare il disco blu piuttosto che quello verde durante la fase di test.\nIl ricercatore osserva che in 130 casi su 200, le api del gruppo sperimentale continuano ad avvicinarsi al disco blu dopo la rimozione della soluzione zuccherina. Le api del gruppo di controllo, che non sono state addestrate, si avvicinano al disco blu 100 volte su 200.\nPer confrontare il comportamento delle api nelle due condizioni, useremo l’odds ratio, così da confrontare le probabilità dell’evento critico (scelta del disco blu) tra i due gruppi.\nCalcoliamo la proporzione delle api che scelgono il disco blu nella condizione sperimentale:\n\\[\np_e = \\frac{130}{200} = 0.65\n\\]\nCalcoliamo gli odds nella condizione sperimentale:\n\\[\n\\text{odds}_e = \\frac{p_e}{1 - p_e} \\approx 1.86\n\\]\nQuesto ci indica che, nel gruppo sperimentale, ci sono circa 1.86 “successi” (ossia la scelta del disco blu) per ogni “insuccesso” (scelta del disco verde).\nProcediamo calcolando gli odds nella condizione di controllo:\n\\[\np_c = \\frac{100}{200} = 0.5\n\\]\n\\[\n\\text{odds}_c = \\frac{p_c}{1 - p_c} = 1.0\n\\]\nQuesto ci indica che, nel gruppo di controllo, il numero di “successi” e “insuccessi” è uguale.\nInfine, confrontiamo gli odds tra la condizione sperimentale e la condizione di controllo per calcolare l’odds ratio (OR):\n\\[\n\\text{OR} = \\frac{\\text{odds}_e}{\\text{odds}_c} = 1.86\n\\]\nGli odds di scelta del disco blu aumentano di circa 1.86 volte nel gruppo sperimentale rispetto al gruppo di controllo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#analisi-bayesiana-dellodds-ratio",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#analisi-bayesiana-dellodds-ratio",
    "title": "43  Analisi bayesiana dell’odds-ratio",
    "section": "43.5 Analisi Bayesiana dell’Odds Ratio",
    "text": "43.5 Analisi Bayesiana dell’Odds Ratio\nNella nostra analisi, ci focalizziamo sull’Odds Ratio (OR) per valutare la differenza nel comportamento di scelta delle api nelle due condizioni dell’esperimento discusso. L’OR fornisce una stima puntuale della differenza basata sul nostro campione specifico. Tuttavia, per realizzare un’inferenza statistica robusta, è essenziale considerare l’incertezza nelle nostre stime, caratterizzata attraverso la distribuzione a posteriori.\nL’analisi bayesiana si basa sull’applicazione del teorema di Bayes per aggiornare le nostre conoscenze a priori con l’evidenza fornita dai dati osservati. Questo ci permette di ottenere una distribuzione a posteriori delle quantità di interesse, come l’odds ratio.\nPer affrontare questa questione, adottiamo un approccio bayesiano, costruendo la distribuzione a posteriori dell’OR. A partire da questa distribuzione, determiniamo un intervallo di credibilità del 90%, che rappresenta l’intervallo entro il quale, con il 90% di confidenza, possiamo aspettarci che ricada il vero valore dell’OR della popolazione.\nSe questo intervallo non include il valore 1, disponiamo di una solida evidenza (con un livello di credibilità del 90%) che la differenza tra le due condizioni esaminate corrisponde a una differenza reale nella popolazione, il che suggerisce che non si tratta di un artefatto generato dalla nostra incertezza. In altre parole, possiamo affermare con ragionevole certezza che le api dispongono di una visione cromatica.\nD’altro canto, se l’intervallo di credibilità includesse il valore 1, ciò indicherebbe che la differenza osservata nel nostro campione potrebbe non riflettere una differenza significativa nella popolazione generale, suggerendo che potrebbe essere una peculiarità del nostro campione specifico.\nL’analisi bayesiana e il calcolo dell’intervallo di credibilità verranno condotti utilizzando cmdstanpy, che ci permette di implementare modelli bayesiani in modo efficiente e rigoroso. Utilizzeremo una distribuzione a priori debolmente informativa per l’OR, in modo da non influenzare eccessivamente i risultati con assunzioni preliminari.\nUna volta ottenuta la distribuzione a posteriori dell’OR, possiamo calcolare il nostro intervallo di credibilità del 90%. Questo intervallo fornirà una rappresentazione della nostra incertezza riguardo il vero valore dell’OR nella popolazione. Se il nostro intervallo di credibilità esclude il valore 1, possiamo concludere che esiste una differenza significativa tra i due gruppi, confermando che le api possono distinguere i colori e preferire il disco blu.\nIn sintesi, l’approccio bayesiano non solo ci permette di stimare l’OR, ma anche di quantificare la nostra incertezza e fare inferenze più solide e informative sulla capacità delle api di distinguere tra colori.\n\n43.5.1 Likelihood\nLa likelihood del modello descrive la probabilità di osservare i dati dati i parametri del modello. Nel nostro caso, abbiamo due gruppi con eventi binomiali.\nPer il gruppo 1:\n\\[\ny_1 \\sim \\text{Binomiale}(N_1, \\theta_1).\n\\]\nPer il gruppo 2:\n\\[\ny_2 \\sim \\text{Binomiale}(N_2, \\theta_2).\n\\]\n\n\n43.5.2 Priors\nI priors del modello descrivono le nostre convinzioni iniziali sui parametri prima di osservare i dati. Nel nostro caso, i parametri \\(\\theta_1\\) e \\(\\theta_2\\) seguono una distribuzione Beta(2, 2).\nPer \\(\\theta_1\\):\n\\[\n\\theta_1 \\sim \\text{Beta}(2, 2).\n\\]\nPer \\(\\theta_2\\):\n\\[\n\\theta_2 \\sim \\text{Beta}(2, 2).\n\\]\nCompiliamo e stampiamo il modello Stan.\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"odds-ratio.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; //  Comparison of two groups with Binomial\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N1; // number of experiments in group 1\n#&gt;   int&lt;lower=0&gt; y1; // number of events in group 1\n#&gt;   int&lt;lower=0&gt; N2; // number of experiments in group 2\n#&gt;   int&lt;lower=0&gt; y2; // number of events in group 2\n#&gt; }\n#&gt; parameters {\n#&gt;   real&lt;lower=0, upper=1&gt; theta1; // probability of event in group 1\n#&gt;   real&lt;lower=0, upper=1&gt; theta2; // probability of event in group 2\n#&gt; }\n#&gt; model {\n#&gt;   // model block creates the log density to be sampled\n#&gt;   theta1 ~ beta(2, 2); // prior\n#&gt;   theta2 ~ beta(2, 2); // prior\n#&gt;   y1 ~ binomial(N1, theta1); // observation model / likelihood\n#&gt;   y2 ~ binomial(N2, theta2); // observation model / likelihood\n#&gt; }\n#&gt; generated quantities {\n#&gt;   real oddsratio = (theta1 / (1 - theta1)) / (theta2 / (1 - theta2));\n#&gt; }\n\nNel blocco generated quantities, calcoliamo l’odds ratio:\n\\[\n\\text{oddsratio} = \\frac{\\theta_1 / (1 - \\theta_1)}{\\theta_2 / (1 - \\theta_2)}.\n\\]\nQuesto rapporto delle odds ci dà una misura della forza dell’associazione tra l’evento e i gruppi.\nIn sintesi, il modello bayesiano utilizza i dati osservati per aggiornare le nostre convinzioni iniziali sui parametri \\(\\theta_1\\) e \\(\\theta_2\\), fornendo una distribuzione a posteriori che riflette sia le informazioni a priori sia le evidenze empiriche.\nCreiamo un dizionario che contiene i dati.\n\nn1 &lt;- 200\ny1 &lt;- 130\nn2 &lt;- 200\ny2 &lt;- 100\n\nstan_data &lt;- list(\n  N1 = n1,\n  y1 = y1,\n  N2 = n2,\n  y2 = y2\n)\n\nEseguiamo il campionamento.\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 5000, \n  iter_warmup = 2000,\n  adapt_delta = 0.99,\n  show_messages = FALSE\n)\n\nEstraiamo la distribuzione a posteriori dell’odds ratio e generiamo un istogramma.\n\n# Extract posterior draws for 'oddsratio'\nor_draws &lt;- fit$draws(variables = \"oddsratio\", format = \"array\")\n\n\n# Create a histogram of the posterior distribution\nmcmc_hist(\n  or_draws,\n  binwidth = NULL, # Automatically choose binwidth\n  freq = FALSE     # Plot density instead of frequencies\n) +\n  ggtitle(\"Istogramma della distribuzione a posteriori di OR\") +\n  xlab(\"Valori\") +\n  ylab(\"Frequenza\")\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nLa distribuzione posteriore del rapporto degli odds è il modo più semplice e accurato per descrivere la differenza tra i due gruppi. Nel caso presente, notiamo che vi è un’elevata probabilità che la differenza tra i due gruppi sia affidabile e relativamente grande.\nUn sommario della distribuzione a posteriori dell’odds ratio si ottine nel modo seguente.\n\nfit$summary()\n#&gt; # A tibble: 4 × 10\n#&gt;   variable      mean   median     sd    mad       q5      q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__      -275.    -275.    0.976  0.710  -277.    -274.     1.00    7085.\n#&gt; 2 theta1       0.647    0.648 0.0334 0.0341    0.592    0.701  1.00   10382.\n#&gt; 3 theta2       0.500    0.500 0.0345 0.0349    0.443    0.556  1.00   10901.\n#&gt; 4 oddsratio    1.88     1.84  0.385  0.374     1.32     2.57   1.00   10385.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\nPossiamo determinare la probabilità che il rapporto di probabilità (odds ratio) superi 1. Per farlo, è sufficiente analizzare gli 8000 campioni della distribuzione posteriore dell’odds ratio\n\ndim(or_draws)\n#&gt; [1] 5000    4    1\n\ne calcolare la proporzione di questi che presenta un valore maggiore di 1:\n\n# Summarize the proportion of posterior draws for 'oddsratio' greater than 1.0\nfit$summary(\"oddsratio\", pr_gt_one = ~ mean(. &gt; 1.0))\n#&gt; # A tibble: 1 × 2\n#&gt;   variable  pr_gt_one\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;\n#&gt; 1 oddsratio     0.999",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#diagnostica-delle-catene-markoviane",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#diagnostica-delle-catene-markoviane",
    "title": "43  Analisi bayesiana dell’odds-ratio",
    "section": "43.6 Diagnostica delle catene markoviane",
    "text": "43.6 Diagnostica delle catene markoviane\nPrima di esaminare i risultati, eseguiamo la diagnostica delle catene markoviane.\n\n43.6.1 Mixing\nIl trace plot precedente dimostra un buon mixing. Questo è evidenza che il campionamento MCMC ha raggiunto uno stato stazionario.\n\nmcmc_trace(or_draws) +\n  ggtitle(\"Trace Plot for 'oddsratio'\")\n\n\n\n\n\n\n\n\n\n\n43.6.2 Numerosità campionaria effettiva\nQuando si utilizzano metodi di campionamento MCMC, è ragionevole chiedersi se un particolare campione estratto dalla distribuzione a posteriori sia sufficientemente grande per calcolare con sicurezza le quantità di interesse, come una media o un HDI. Questo non è qualcosa che possiamo rispondere direttamente guardando solo il numero di punti della catena MCMC, e il motivo è che i campioni ottenuti dai metodi MCMC hanno un certo grado di autocorrelazione, quindi la quantità effettiva di informazioni contenute in quel campione sarà inferiore a quella che otterremmo da un campione iid della stessa dimensione. Possiamo pensare alla dimensione del campione effettivo (ESS) come a un stimatore che tiene conto dell’autocorrelazione e fornisce il numero di estrazioni che avremmo se il nostro campione fosse effettivamente iid.\nPer le catene buone, solitamente, il valore della dimensione del campione effettivo sarà inferiore al numero di campioni. Ma l’ESS può essere in realtà più grande del numero di campioni estratti. Quando si utilizza il campionatore NUTS, valori di ESS maggiori del numero totale di campioni possono verificarsi per parametri le cui distribuzioni posteriori sono vicine alla Gaussiana e che sono quasi indipendenti da altri parametri nel modello.\nNell’output di PyCM si considera ESS_BULK. Un euristica è che deve essere almeno uguale a 400. Nel caso presente questo si verifica, quindi il valore ESS_BULK non fornisce alcuna evidenza di cattivo mixing.\n\n\n43.6.3 R hat\nIn condizioni molto generali, i metodi di Markov chain Monte Carlo hanno garanzie teoriche che otterranno la risposta corretta indipendentemente dal punto di partenza. Sfortunatamente, tali garanzie sono valide solo per campioni infiniti. Quindi, nella pratica, abbiamo bisogno di modi per stimare la convergenza per campioni finiti. Un’idea diffusa è quella di generare più di una catena, partendo da punti molto diversi e quindi controllare le catene risultanti per vedere se sembrano simili tra loro. Questa nozione intuitiva può essere formalizzata in un indicatore numerico noto come R-hat. Esistono molte versioni di questo stimatore, poiché è stato perfezionato nel corso degli anni. In origine il R-hat veniva interpretato come la sovrastima della varianza dovuta al campionamento MCMC finito. Ciò significa che se si continua a campionare all’infinito si dovrebbe ottenere una riduzione della varianza della stima di un fattore R-hat. E quindi il nome “fattore di riduzione potenziale della scala” (potential scale reduction factor), con il valore target di 1 che significa che aumentare il numero di campioni non ridurrà ulteriormente la varianza della stima. Tuttavia, nella pratica è meglio pensarlo solo come uno strumento diagnostico senza cercare di sovra-interpretarlo.\nL’R-hat per il parametro theta viene calcolato come la deviazione standard di tutti i campioni di theta, ovvero includendo tutte le catene insieme, diviso per la radice quadratica media delle deviazioni standard separate all’interno della catena. Il calcolo effettivo è un po’ più complesso ma l’idea generale è questa. Idealmente dovremmo ottenere un valore di 1, poiché la varianza tra le catene dovrebbe essere la stessa della varianza all’interno della catena. Da un punto di vista pratico, valori di R-hat inferiori a 1.1 sono considerati sicuri.\nNel caso presente questo si verifica. Possiamo ottenere R hat nel modo seguente:\n\n# Extract the summary including R-hat\nsummary &lt;- fit$summary()\n\n# Extract R-hat values\nrhat_values &lt;- summary$rhat\n\n# Print R-hat values\nprint(rhat_values)\n#&gt; [1] 1.000647 1.000385 1.000449 1.000297\n\nIl valore di \\(\\hat{R}\\), al massimo, raggiunge il valore di 1.001. Essendo il valore molto simile a 1 nel caso presente, possiamo dire che non ci sono evidenza di assenza di convergenza.\n\n\n43.6.4 Errore standard di Monte Carlo\nQuando si utilizzano metodi MCMC introduciamo un ulteriore livello di incertezza poiché stiamo approssimando la posteriore con un numero finito di campioni. Possiamo stimare la quantità di errore introdotta utilizzando l’errore standard di Monte Carlo (MCSE). L’MCSE tiene conto del fatto che i campioni non sono veramente indipendenti l’uno dall’altro e sono in realtà calcolati dall’ESS. Mentre i valori di ESS e R-hat sono indipendenti dalla scala dei parametri, la statistica MCSE non lo è. Se vogliamo riportare il valore di un parametro stimato al secondo decimale, dobbiamo essere sicuri che MCSE sia al di sotto del secondo decimale altrimenti, finiremo, erroneamente, per riportare una precisione superiore a quella che abbiamo realmente. Dovremmo controllare MCSE solo una volta che siamo sicuri che ESS sia abbastanza alto e R-hat sia abbastanza basso; altrimenti, MCSE non è utile.\nNel nostro caso il MCSE è sufficientemente piccolo.\n\n# Extract posterior draws\ndraws &lt;- fit$draws()\n\n# Summarize the draws, including MCSE\nsummary &lt;- summarize_draws(draws, \"mean\", \"mcse_mean\")\n\n# Print the summary including MCSE\nprint(summary)\n#&gt; # A tibble: 4 × 3\n#&gt;   variable      mean mcse_mean\n#&gt;   &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 lp__      -275.     0.0120  \n#&gt; 2 theta1       0.647  0.000328\n#&gt; 3 theta2       0.500  0.000331\n#&gt; 4 oddsratio    1.88   0.00381\n\nL’errore standard di Monte Carlo ci informa della precisione della stima ottenuta usando il metodo MCMC. Non possiamo riportare una precisione dei risultati maggiore di quella indicata dalla MCSE. Pertanto, per il caso presente relativo all’Odds Ratio (OR), possiamo affermare che la precisione massima raggiungibile è limitata a due decimali.\n\n\n43.6.5 Autocorrelazione\nL’autocorrelazione riduce la quantità effettiva di informazioni contenute in un campione e quindi è qualcosa che vogliamo mantenere al minimo. Possiamo ispezionare direttamente l’autocorrelazione con az.plot_autocorr.\n\n# Extract posterior draws for 'oddsratio'\noddsratio_draws &lt;- fit$draws(variables = \"oddsratio\", format = \"matrix\")\n\n# Create an autocorrelation plot\nmcmc_acf(oddsratio_draws) +\n  ggtitle(\"Autocorrelation Plot for 'oddsratio'\")\n\n\n\n\n\n\n\n\n\n\n43.6.6 Rank Plots\nI grafici dei ranghi sono un altro strumento diagnostico visivo che possiamo utilizzare per confrontare il comportamento del campionamento sia all’interno che tra le catene. I grafici dei ranghi, in parole semplici, sono istogrammi dei campioni della distribuzione a posteriori espressi in termini di ranghi. Nei grafici dei ranghi, i ranghi sono calcolati combinando prima tutte le catene ma poi rappresentando i risultati separatamente per ogni catena. Se tutte le catene stimano la stessa distribuzione, ci aspettiamo che i ranghi abbiano una distribuzione uniforme. Inoltre, se i grafici dei ranghi di tutte le catene sembrano simili, ciò indica un buon mix delle catene.\nPossiamo ottenere i grafici dei ranghi con az.plot_rank.\n\nmcmc_rank_hist(oddsratio_draws) +\n  ggtitle(\"Rank Histogram for 'oddsratio'\")\n\n\n\n\n\n\n\n\nPossiamo vedere nella figura che i ranghi sono molto simili ad una distribuzione uniforme e che tutte le catene sono simili tra loro senza alcuno scostamento distintivo.\n\n\n43.6.7 Divergenza\nPer diagnosticare il funzionamento di un campionatore, abbiamo finora analizzato i campioni generati. Un altro approccio fondamentale consiste nel monitorare i meccanismi interni del metodo di campionamento. Una delle diagnosi più importanti in questo contesto è rappresentata dal concetto di divergenza, particolarmente rilevante nei metodi Hamiltonian Monte Carlo (HMC). Le divergenze (o transizioni divergenti) sono un segnale sensibile che indica potenziali problemi nella geometria del modello o nel campionamento. Queste diagnosi sono complementari agli altri controlli descritti in precedenza.\n\n43.6.7.1 Che cosa sono le transizioni divergenti?\nLe transizioni divergenti si verificano quando il metodo HMC non riesce a esplorare efficacemente la distribuzione a posteriori. Ciò accade, ad esempio, in presenza di geometrie complesse come regioni strette e allungate della distribuzione, dove il campionatore fatica a seguire il gradiente. Le transizioni divergenti sono quindi un’indicazione che il modello potrebbe necessitare di una riformulazione o di parametri di campionamento più adeguati (come un maggiore adapt_delta).\nCmdStan consente di rilevare queste transizioni e riporta il numero di divergenze per ciascuna catena durante il campionamento. Un risultato ottimale è zero divergenze, poiché ciò indica che il campionatore ha esplorato la distribuzione senza difficoltà.\n\n\n43.6.7.2 Diagnosi delle divergenze\nPer eseguire questa diagnosi, possiamo utilizzare il metodo fit$diagnostic_summary(), che restituisce un riepilogo dei principali indicatori diagnostici. Vediamo i valori restituiti nel caso specifico:\n\nfit$diagnostic_summary()\n#&gt; $num_divergent\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $num_max_treedepth\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $ebfmi\n#&gt; [1] 1.035259 1.051684 1.005021 1.068711\n\nI valori diagnostici restituiti sono i seguenti:\n\n$num_divergent:\n\nQuesto valore indica il numero di transizioni divergenti per ciascuna catena.\nCaso corrente: Tutte le catene riportano 0 transizioni divergenti. Ciò significa che il campionatore è stato in grado di esplorare la distribuzione a posteriori senza difficoltà, suggerendo che il modello è ben specificato e che non ci sono problemi nella geometria della distribuzione.\n\n$num_max_treedepth:\n\nQuesto valore rappresenta il numero di volte in cui una catena ha raggiunto la massima profondità dell’albero durante il campionamento NUTS (No-U-Turn Sampler).\nRaggiungere frequentemente la profondità massima potrebbe indicare inefficienza nel campionamento.\nCaso corrente: Nessuna catena ha raggiunto la massima profondità, il che significa che il campionatore è stato efficiente e non sono necessarie modifiche al parametro max_treedepth.\n\n$ebfmi (Energy Bayesian Fraction of Missing Information):\n\nL’E-BFMI misura l’efficienza del campionamento in relazione all’energia Hamiltoniana. Valori inferiori a 0.3 indicano problemi di esplorazione della distribuzione a posteriori.\nCaso corrente: Tutte le catene presentano valori di E-BFMI superiori a 1, indicando un’ottima esplorazione della distribuzione e l’assenza di problemi nella geometria del modello.\n\n\nIn sintesi, i risultati diagnostici indicano che il campionamento MCMC è stato eseguito correttamente e senza problemi:\n\n0 transizioni divergenti: Il modello è ben specificato e la distribuzione a posteriori è stata esplorata in modo efficace.\n0 superamenti della profondità dell’albero: Il campionatore è stato efficiente.\nE-BFMI &gt; 1: L’energia Hamiltoniana è stata esplorata in modo ottimale, senza segni di inefficienza.\n\nQuesti risultati ci consentono di procedere con fiducia nell’analisi dei risultati, poiché non vi sono evidenze di problematiche legate al campionamento o alla geometria del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#interpretazione-dei-risultati",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#interpretazione-dei-risultati",
    "title": "43  Analisi bayesiana dell’odds-ratio",
    "section": "43.7 Interpretazione dei Risultati",
    "text": "43.7 Interpretazione dei Risultati\nI risultati della diagnosi delle catene Markoviane non evidenziano problematiche relative alla convergenza dell’algoritmo né discrepanze nel modello statistico adottato, permettendoci di procedere con l’analisi dei risultati ottenuti.\nL’analisi ha determinato un valore a posteriori per l’OR di 1.88, accompagnato da un intervallo di credibilità del 94% compreso tra 1.20 e 2.60. Poiché questo intervallo non include il valore 1, possiamo affermare, con un grado di certezza del 94%, che il comportamento delle api differisce nelle due condizioni sperimentali. Questo fornisce evidenza a supporto dell’ipotesi che le api dispongano di una visione cromatica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#riflessioni-conclusive",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#riflessioni-conclusive",
    "title": "43  Analisi bayesiana dell’odds-ratio",
    "section": "43.8 Riflessioni Conclusive",
    "text": "43.8 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato come applicare un approccio bayesiano per analizzare e interpretare l’odds ratio tra due proporzioni. Attraverso l’uso del modello statistico, siamo stati in grado di stimare la distribuzione a posteriori dell’odds ratio e di calcolare l’intervallo di credibilità.\nI risultati ottenuti, supportati da un controllo diagnostico delle catene Markoviane, indicano che la differenza osservata tra i due gruppi è credibile e supportata dai dati. L’odds ratio stimato e il relativo intervallo di credibilità escludono il valore 1, suggerendo una differenza coerente tra i gruppi analizzati. L’approccio bayesiano si è dimostrato efficace, non solo per stimare i parametri di interesse, ma anche per quantificare l’incertezza associata a tali stime.\nIn sintesi, l’analisi bayesiana dell’odds ratio ha permesso di rispondere alla domanda di ricerca, confermando che le api mostrano comportamenti coerenti con una capacità di distinzione cromatica. L’approccio presentato in questo capitolo può essere esteso ad altre applicazioni, offrendo una struttura versatile per il confronto tra proporzioni in diversi contesti sperimentali.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#informazioni-sullambiente-di-sviluppo",
    "title": "43  Analisi bayesiana dell’odds-ratio",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] posterior_1.6.0     cmdstanr_0.8.1.9000 MASS_7.3-61        \n#&gt;  [4] viridis_0.6.5       viridisLite_0.4.2   ggpubr_0.6.0       \n#&gt;  [7] ggExtra_0.10.1      gridExtra_2.3       patchwork_1.3.0    \n#&gt; [10] bayesplot_1.11.1    psych_2.4.6.26      scales_1.3.0       \n#&gt; [13] markdown_1.13       knitr_1.49          lubridate_1.9.3    \n#&gt; [16] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [19] purrr_1.0.2         readr_2.1.5         tidyr_1.3.1        \n#&gt; [22] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [25] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         fastmap_1.2.0       \n#&gt;  [4] tensorA_0.36.2.1     pacman_0.5.1         promises_1.3.1      \n#&gt;  [7] digest_0.6.37        timechange_0.3.0     mime_0.12           \n#&gt; [10] lifecycle_1.0.4      processx_3.8.4       magrittr_2.0.3      \n#&gt; [13] compiler_4.4.2       rlang_1.1.4          tools_4.4.2         \n#&gt; [16] utf8_1.2.4           yaml_2.3.10          data.table_1.16.2   \n#&gt; [19] ggsignif_0.6.4       labeling_0.4.3       htmlwidgets_1.6.4   \n#&gt; [22] mnormt_2.1.1         plyr_1.8.9           abind_1.4-8         \n#&gt; [25] miniUI_0.1.1.1       withr_3.0.2          grid_4.4.2          \n#&gt; [28] fansi_1.0.6          xtable_1.8-4         colorspace_2.1-1    \n#&gt; [31] cli_3.6.3            rmarkdown_2.29       generics_0.1.3      \n#&gt; [34] reshape2_1.4.4       tzdb_0.4.0           parallel_4.4.2      \n#&gt; [37] matrixStats_1.4.1    vctrs_0.6.5          jsonlite_1.8.9      \n#&gt; [40] carData_3.0-5        car_3.1-3            hms_1.1.3           \n#&gt; [43] rstatix_0.7.2        Formula_1.2-5        glue_1.8.0          \n#&gt; [46] ps_1.8.1             distributional_0.5.0 stringi_1.8.4       \n#&gt; [49] gtable_0.3.6         later_1.4.0          munsell_0.5.1       \n#&gt; [52] pillar_1.9.0         htmltools_0.5.8.1    R6_2.5.1            \n#&gt; [55] rprojroot_2.0.4      evaluate_1.0.1       shiny_1.9.1         \n#&gt; [58] lattice_0.22-6       backports_1.5.0      broom_1.0.7         \n#&gt; [61] httpuv_1.6.15        Rcpp_1.0.13-1        nlme_3.1-166        \n#&gt; [64] checkmate_2.3.2      xfun_0.49            pkgconfig_2.0.3",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#bibliografia",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#bibliografia",
    "title": "43  Analisi bayesiana dell’odds-ratio",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoffmann, T., Hofman, A., & Wagenmakers, E.-J. (2022). Bayesian tests of two proportions: A tutorial with R and JASP. Methodology, 18(4), 239–277.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html",
    "href": "chapters/mcmc/18_cmdstanr_intro.html",
    "title": "44  Introduzione a CmdStanR",
    "section": "",
    "text": "44.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nRiprendiamo l’analisi dei dati fittizi di un compito Go/No-go, in cui sono state registrate 6 risposte corrette su 9 prove, già discussa in precedenza. In questa sezione, utilizzeremo il pacchetto cmdstanr in R, invece di cmdstanpy in Python, per eseguire l’analisi. L’obiettivo di questo capitolo è mostrare come utilizzare CmdStan attraverso il linguaggio R, offrendo un’alternativa all’uso di Python.\nIn R, i dati vengono salvati in una lista, che equivale a un dizionario in Python.\ndata_list &lt;- list(\n    \"N\" = 9,\n    \"y\" = 6\n)\nSuccessivamente, specifichiamo il percorso del file contenente lo script Stan. È importante notare che lo script Stan rimane identico indipendentemente dall’interfaccia utilizzata, sia essa R o Python.\nfile &lt;- file.path(here::here(\"stan\", \"go_nogo_model.stan\"))\nfile\n\n[1] \"/Users/corradocaudek/_repositories/psicometria-r/stan/go_nogo_model.stan\"",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#compilazione-del-modello",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#compilazione-del-modello",
    "title": "44  Introduzione a CmdStanR",
    "section": "44.2 Compilazione del modello",
    "text": "44.2 Compilazione del modello\nPer compilare il modello, utilizziamo la funzione cmdstan_model(), che crea un nuovo oggetto CmdStanModel a partire da un file contenente un programma Stan.\n\nmod &lt;- cmdstan_model(file)\n\nDopo aver compilato il modello, possiamo stamparne le informazioni.\n\nmod$print()\n\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=0&gt; y;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; p;\n}\nmodel {\n  y ~ binomial(N, p); // Likelihood\n  p ~ beta(1, 1); // Prior\n}\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; p_gt_chance = p &gt; 0.5;\n}",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#esecuzione-dellalgoritmo-mcmc",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#esecuzione-dellalgoritmo-mcmc",
    "title": "44  Introduzione a CmdStanR",
    "section": "44.3 Esecuzione dell’algoritmo MCMC",
    "text": "44.3 Esecuzione dell’algoritmo MCMC\nIl metodo $sample() sugli oggetti CmdStanModel esegue l’algoritmo MCMC predefinito di Stan. L’argomento data accetta una lista di oggetti R con nomi specificati.\n\nfit &lt;- mod$sample(\n    data = data_list,\n    seed = 123,\n    chains = 4,\n    parallel_chains = 4\n)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#statistiche-riassuntive-del-posterior",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#statistiche-riassuntive-del-posterior",
    "title": "44  Introduzione a CmdStanR",
    "section": "44.4 Statistiche riassuntive del posterior",
    "text": "44.4 Statistiche riassuntive del posterior\nIl metodo $summary() chiama la funzione summarise_draws() dal pacchetto posterior. Il primo argomento specifica le variabili da riassumere, e gli argomenti successivi sono passati a posterior::summarise_draws() per specificare quali statistiche calcolare, l’uso di più core, ecc.\n\nfit$summary(variables = c(\"p\"))\n\n# A tibble: 1 × 10\n  variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 p        0.636  0.647 0.141 0.148 0.389 0.854  1.00    1372.    1351.\n\n\nÈ possibile utilizzare una formula per riassumere funzioni arbitrarie, come ad esempio la probabilità che \\(p\\) sia minore o uguale a 0.5.\n\nfit$summary(\"p\", pr_lt_half = ~ mean(. &lt;= 0.5))\n\n# A tibble: 1 × 2\n  variable pr_lt_half\n  &lt;chr&gt;         &lt;dbl&gt;\n1 p             0.176",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#estrazione-dei-campioni-posteriori",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#estrazione-dei-campioni-posteriori",
    "title": "44  Introduzione a CmdStanR",
    "section": "44.5 Estrazione dei campioni posteriori",
    "text": "44.5 Estrazione dei campioni posteriori\n\n44.5.1 Estrazione dei campioni\nIl metodo $draws() può essere utilizzato per estrarre i campioni posteriori in formati supportati dal pacchetto posterior. Qui dimostriamo i formati draws_array e draws_df.\n\n# default is a 3-D draws_array object from the posterior package\n# iterations x chains x variables\ndraws_arr &lt;- fit$draws() # or format=\"array\"\nstr(draws_arr)\n\n 'draws_array' num [1:1000, 1:4, 1:3] -7.21 -8.34 -9.16 -7.22 -7.21 ...\n - attr(*, \"dimnames\")=List of 3\n  ..$ iteration: chr [1:1000] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ chain    : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n  ..$ variable : chr [1:3] \"lp__\" \"p\" \"p_gt_chance\"\n\n\nOppure, possiamo usare as_draws_df() per creare un data frame:\n\ndraws &lt;- as_draws_df(fit)\nhead(draws)\n\n# A draws_df: 6 iterations, 1 chains, and 3 variables\n  lp__    p p_gt_chance\n1 -7.2 0.63           1\n2 -8.3 0.41           0\n3 -9.2 0.34           0\n4 -7.2 0.66           1\n5 -7.2 0.63           1\n6 -7.2 0.64           1\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nLo stesso risultato si ottiene nel modo seguente:\n\ndraws_df &lt;- as_draws_df(draws_arr)\nhead(draws_df)\n\n# A draws_df: 6 iterations, 1 chains, and 3 variables\n  lp__    p p_gt_chance\n1 -7.2 0.63           1\n2 -8.3 0.41           0\n3 -9.2 0.34           0\n4 -7.2 0.66           1\n5 -7.2 0.63           1\n6 -7.2 0.64           1\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nUna volta creato un data frame, possiamo facilmente calcolare le statistiche descrittive. Per esempio:\n\ndraws_df$p |&gt;\n    mean()\n\n[1] 0.6364032\n\n\nIn questo modo possiamo calcolare la probabilità che, ad esempio, \\(p\\) sia compreso tra 0.5 e 0.75:\n\ndraws_df |&gt;\n    summarise(\n        p_between_0.5_and_0.75 = mean(p &gt; 0.5 & p &lt; 0.75)\n    )\n\n# A tibble: 1 × 1\n  p_between_0.5_and_0.75\n                   &lt;dbl&gt;\n1                  0.595\n\n\n\npartion_vector &lt;- c(\"italic(p)&lt;0.5\", \"{0.5&lt;italic(p)}&lt;0.75\", \"lower~80*'%'\", \"middle~80*'%'\")\n\ndraws_df |&gt;\n    mutate(\n        `italic(p)&lt;0.5` = p &lt; 0.5,\n        `{0.5&lt;italic(p)}&lt;0.75` = p &gt; 0.5 & p &lt; 0.75,\n        `lower~80*'%'` = p &lt; quantile(p, probs = 0.8),\n        `middle~80*'%'` = p &gt; quantile(p, probs = 0.1) & p &lt; quantile(p, probs = 0.9)\n    ) |&gt;\n    pivot_longer(cols = `italic(p)&lt;0.5`:`middle~80*'%'`) |&gt;\n    mutate(name = factor(name, levels = partion_vector)) |&gt;\n    ggplot(aes(x = p, fill = value)) +\n    geom_histogram(boundary = 0, binwidth = 0.01) +\n    scale_x_continuous(expression(proportion ~ water ~ (italic(p))), limits = 0:1) +\n    scale_y_continuous(NULL, breaks = NULL) +\n    scale_fill_viridis_d(end = 0.6, breaks = NULL) +\n    facet_wrap(~name, labeller = label_parsed)\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n\n\n\n\n\n\n\n\n\n44.5.2 Visualizzazione dei campioni\nVisualizzare le distribuzioni posteriori è semplice: basta passare l’oggetto restituito dal metodo $draws() direttamente alle funzioni di plotting del pacchetto bayesplot.\n\nmcmc_hist(fit$draws(\"p\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#diagnostica-del-campionatore",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#diagnostica-del-campionatore",
    "title": "44  Introduzione a CmdStanR",
    "section": "44.6 Diagnostica del campionatore",
    "text": "44.6 Diagnostica del campionatore\nIl metodo $sampler_diagnostics() estrae i valori dei parametri del campionatore (come treedepth__, divergent__, ecc.) in formati supportati dal pacchetto posterior.\n\nstr(fit$sampler_diagnostics(format = \"df\"))\n\ndraws_df [4,000 × 9] (S3: draws_df/draws/tbl_df/tbl/data.frame)\n $ treedepth__  : num [1:4000] 2 1 1 2 1 2 2 1 1 2 ...\n $ divergent__  : num [1:4000] 0 0 0 0 0 0 0 0 0 0 ...\n $ energy__     : num [1:4000] 7.21 8.57 9.3 9.06 7.23 ...\n $ accept_stat__: num [1:4000] 1 0.762 0.816 1 0.999 ...\n $ stepsize__   : num [1:4000] 0.937 0.937 0.937 0.937 0.937 ...\n $ n_leapfrog__ : num [1:4000] 3 3 1 3 3 3 3 1 1 3 ...\n $ .chain       : int [1:4000] 1 1 1 1 1 1 1 1 1 1 ...\n $ .iteration   : int [1:4000] 1 2 3 4 5 6 7 8 9 10 ...\n $ .draw        : int [1:4000] 1 2 3 4 5 6 7 8 9 10 ...\n\n\n\nfit$diagnostic_summary()\n\n$num_divergent\n[1] 0 0 0 0\n\n$num_max_treedepth\n[1] 0 0 0 0\n\n$ebfmi\n[1] 1.1950436 0.9774677 1.2009506 0.9659775\n\n\nQuesto processo consente di esaminare in dettaglio le prestazioni del campionatore e di verificare eventuali problemi o inefficienze durante l’esecuzione del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#informazioni-sullambiente-di-sviluppo",
    "title": "44  Introduzione a CmdStanR",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n\nR version 4.4.2 (2024-10-31)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] C/UTF-8/C/C/C/C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] here_1.0.1          bayesplot_1.11.1    posterior_1.6.0    \n [4] cmdstanr_0.8.1.9000 lubridate_1.9.3     forcats_1.0.0      \n [7] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        \n[10] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n[13] ggplot2_3.5.1       tidyverse_2.0.0    \n\nloaded via a namespace (and not attached):\n [1] tensorA_0.36.2.1     utf8_1.2.4           generics_0.1.3      \n [4] stringi_1.8.4        hms_1.1.3            digest_0.6.37       \n [7] magrittr_2.0.3       evaluate_1.0.1       grid_4.4.2          \n[10] timechange_0.3.0     fastmap_1.2.0        plyr_1.8.9          \n[13] rprojroot_2.0.4      jsonlite_1.8.9       processx_3.8.4      \n[16] backports_1.5.0      ps_1.8.1             fansi_1.0.6         \n[19] viridisLite_0.4.2    scales_1.3.0         abind_1.4-8         \n[22] cli_3.6.3            rlang_1.1.4          munsell_0.5.1       \n[25] withr_3.0.2          yaml_2.3.10          tools_4.4.2         \n[28] reshape2_1.4.4       tzdb_0.4.0           checkmate_2.3.2     \n[31] colorspace_2.1-1     vctrs_0.6.5          R6_2.5.1            \n[34] matrixStats_1.4.1    lifecycle_1.0.4      htmlwidgets_1.6.4   \n[37] pkgconfig_2.0.3      pillar_1.9.0         gtable_0.3.6        \n[40] Rcpp_1.0.13-1        data.table_1.16.2    glue_1.8.0          \n[43] xfun_0.49            tidyselect_1.2.1     knitr_1.49          \n[46] farver_2.1.2         htmltools_0.5.8.1    labeling_0.4.3      \n[49] rmarkdown_2.29       compiler_4.4.2       distributional_0.5.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/introduction_linear_models.html",
    "href": "chapters/linear_models/introduction_linear_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nIn questa sezione esploreremo un approccio all’analisi dei dati basato sull’uso della regressione lineare, esaminandolo dalla prospettiva dell’inferenza bayesiana. La regressione è un metodo che consente ai ricercatori di riassumere come le previsioni o i valori medi di un risultato variano tra individui definiti da un insieme di predittori.\nCome indicato da Gelman et al. (2020), alcuni degli usi più importanti della regressione sono:\nIn tutti questi scenari, è cruciale che il modello di regressione includa tutte le variabili rilevanti. Ad esempio, in uno studio sull’efficacia di una terapia per la depressione negli anziani, è essenziale includere fattori come l’età, le condizioni di salute preesistenti e il supporto sociale. Omettere questi predittori potrebbe portare a stime inaccurate e conclusioni fuorvianti sull’effettiva efficacia del trattamento in questa popolazione specifica.",
    "crumbs": [
      "Regressione",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/linear_models/introduction_linear_models.html#bibliografia",
    "href": "chapters/linear_models/introduction_linear_models.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Gelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/causal_inference/01_rct.html",
    "href": "chapters/causal_inference/01_rct.html",
    "title": "45  Trial controllati randomizzati",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nNel campo della psicologia, come in molte altre discipline scientifiche, la ricerca della causalità è fondamentale per comprendere i fenomeni umani e sviluppare interventi efficaci. Mentre la filosofia ha dibattuto per secoli sulla natura della causalità, la ricerca moderna ha fornito strumenti pratici per affrontare questa questione complessa. Tra questi, i trial controllati randomizzati (RCT) emergono come un metodo particolarmente potente e affidabile.\nGli RCT rappresentano un ponte tra la complessità teorica della causalità e la sua applicazione pratica nella ricerca. Questo approccio, pionieristicamente sviluppato da studiosi come Neyman (1923) e Rubin (1974), permette ai ricercatori di stabilire relazioni causali con un alto grado di confidenza, grazie all’uso attento della randomizzazione e dell’analisi statistica.\nQuesto capitolo, che segue la trattazione presentata nel testo Causal Inference: A Statistical Learning Approach di Stefan Wager, offre una panoramica sintetica delle stime statistiche e dell’inferenza nei trial controllati randomizzati. Quando disponibili, le prove derivate dagli RCT sono spesso considerate il “gold standard” delle evidenze statistiche; pertanto, i metodi per studiare gli RCT costituiscono la base degli strumenti statistici per l’inferenza causale. Inoltre, molti dei disegni di studio osservazionali ampiamente utilizzati, anche in psicologia, si ispirano agli RCT. Di conseguenza, questo capitolo funge anche da punto di partenza per le discussioni successive sulle stime e sull’inferenza negli studi osservazionali.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Trial controllati randomizzati</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/01_rct.html#concetti-fondamentali-negli-rct",
    "href": "chapters/causal_inference/01_rct.html#concetti-fondamentali-negli-rct",
    "title": "45  Trial controllati randomizzati",
    "section": "45.1 Concetti Fondamentali negli RCT",
    "text": "45.1 Concetti Fondamentali negli RCT\n\n45.1.1 Effetti del Trattamento\nNel contesto degli RCT in psicologia, il “trattamento” potrebbe essere un intervento terapeutico, un programma educativo, o qualsiasi altra variabile manipolata dai ricercatori. L’obiettivo principale è determinare l’effetto di questo trattamento su una o più variabili di risultato.\n\n\n45.1.2 Effetti medi del trattamento (ATE e SATE)\nQuando si vuole studiare l’effetto di un trattamento, una delle sfide principali è quella di capire come cambierebbe l’outcome se a una persona venisse somministrato un trattamento diverso da quello effettivamente ricevuto. Questo concetto è formalizzato nell’effetto causale individuale, che è la differenza tra il risultato osservabile se una persona riceve il trattamento (\\(Y_i(1)\\)) e il risultato se non lo riceve (\\(Y_i(0)\\)). Questa differenza si esprime come:\n\\[\n\\theta_i = Y_i(1) - Y_i(0).\n\\]\nTuttavia, poiché per ogni individuo possiamo osservare solo uno di questi due risultati (non possiamo sapere cosa sarebbe successo se avessero ricevuto un trattamento diverso), non possiamo mai conoscere direttamente l’effetto individuale.\nPer superare questo problema, si ricorre alla media degli effetti del trattamento su un gruppo di persone, ovvero all’effetto medio del trattamento. Questo può essere definito in due modi:\n\nEffetto Medio Campionario del Trattamento (SATE - Sample Average Treatment Effect), che è la media degli effetti del trattamento nel campione:\n\n\\[\n\\hat{\\theta} = \\frac{1}{n} \\sum_{i=1}^{n} (Y_i(1) - Y_i(0)).\n\\]\n\nEffetto Medio del Trattamento nella Popolazione (ATE - Average Treatment Effect), che è la media dell’effetto del trattamento in un’intera popolazione da cui è tratto il campione:\n\n\\[\n\\tau = \\mathbb{E}_P[Y_i(1) - Y_i(0)].\n\\]\nQueste definizioni permettono di stimare l’effetto medio del trattamento anche senza osservare gli effetti individuali per ogni persona.\n\n\n45.1.3 Stima tramite differenza delle medie\nUn metodo comune per stimare l’ATE in un trial randomizzato è usare la differenza tra le medie degli outcome tra il gruppo trattato e il gruppo di controllo. Questo metodo funziona in modo molto intuitivo: calcoliamo la media dei risultati per il gruppo che ha ricevuto il trattamento e la media per il gruppo che non l’ha ricevuto, quindi sottraiamo queste due medie:\n\\[\n\\hat{\\tau}_{DM} = \\frac{1}{n_1} \\sum_{i: W_i = 1} Y_i - \\frac{1}{n_0} \\sum_{i: W_i = 0} Y_i,\n\\]\ndove \\(n_1\\) è il numero di individui che hanno ricevuto il trattamento (gruppo trattato) e \\(n_0\\) è il numero di individui che non lo hanno ricevuto (gruppo di controllo).\nQuesto stimatore è non distorto se il trattamento è stato assegnato in modo casuale. Ciò significa che, in media, la stima dell’ATE fornita dalla differenza delle medie sarà corretta.\n\n\n45.1.4 Teorema del limite centrale e intervalli di confidenza\nPer dare una misura dell’incertezza della stima dell’ATE in termini frequentisti, possiamo applicare il teorema del limite centrale (TLC). Questo teorema afferma che, se il campione è sufficientemente grande e i partecipanti sono selezionati in modo indipendente da una popolazione, la distribuzione della stima dell’ATE tende a seguire una distribuzione normale, con media pari all’ATE vero e una certa varianza:\n\\[\n\\sqrt{n} (\\hat{\\tau}_{DM} - \\tau) \\sim N(0, V_{DM}),\n\\]\ndove \\(V_{DM}\\) rappresenta la varianza asintotica della differenza tra le medie. Questo ci permette di costruire un intervallo di confidenza per l’ATE:\n\\[\n\\hat{\\tau}_{DM} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{V}_{DM}}{n}}.\n\\]\nQui, \\(z_{\\alpha/2}\\) è il valore critico dalla distribuzione normale standard (ad esempio, per un livello di confidenza del 95%, \\(z_{0.025} = 1.96\\)). L’intervallo di confidenza fornisce una stima dell’ATE insieme a una misura della sua incertezza. Se l’intervallo è stretto, abbiamo una maggiore fiducia nella stima; se è largo, la stima è più incerta.\n\n\n45.1.5 Aggiustamenti per regressione\nGli aggiustamenti per regressione permettono di migliorare la precisione della stima dell’ATE includendo informazioni aggiuntive, come covariate pre-trattamento, nel modello. L’idea di base è che, oltre al trattamento, altre variabili (covariate) potrebbero influenzare l’outcome. Quindi, includere queste covariate può aiutarci a spiegare meglio le differenze negli outcome e a ridurre la varianza della stima dell’ATE.\nVediamo passo per passo come funziona:\n\n45.1.5.1 Modello di regressione con covariate\nSi usa una regressione lineare che modella l’outcome \\(Y_i\\) in funzione del trattamento \\(W_i\\) e delle covariate \\(X_i\\):\n\\[\nY_i = \\alpha + W_i \\tau + X_i \\beta + W_i X_i \\gamma + \\epsilon_i,\n\\]\n\n\\(Y_i\\): l’outcome dell’individuo \\(i\\).\n\\(W_i\\): il trattamento (1 se l’individuo è trattato, 0 se non lo è).\n\\(X_i\\): le covariate pre-trattamento (es. età, genere).\n\\(\\alpha\\): l’intercetta, cioè il valore dell’outcome medio quando \\(W_i = 0\\) e \\(X_i = 0\\).\n\\(\\tau\\): il parametro che rappresenta l’effetto medio del trattamento (ATE), che vogliamo stimare.\n\\(\\beta\\): il vettore di parametri associati alle covariate, che misura quanto le covariate influenzano l’outcome.\n\\(\\gamma\\): il vettore di parametri di interazione tra trattamento e covariate (cioè quanto l’effetto del trattamento varia in funzione delle covariate).\n\\(\\epsilon_i\\): l’errore, che rappresenta le variazioni non spiegate dal modello.\n\n\n\n45.1.5.2 Aggiustamento per covariate\nLa regressione permette di aggiustare gli outcome per le covariate \\(X_i\\), separando l’effetto delle covariate dall’effetto del trattamento. Questo è utile perché riduce la “rumorosità” dei dati e rende più facile identificare l’effetto del trattamento \\(\\tau\\).\n\n\n45.1.5.3 Stima dell’ATE\nUna volta stimati i coefficienti del modello tramite una regressione (solitamente con il metodo dei minimi quadrati), possiamo calcolare la stima dell’ATE.\nIl trucco è che possiamo usare i risultati della regressione per predire quale sarebbe stato l’outcome di ciascun individuo sotto entrambi i livelli del trattamento (\\(W_i = 1\\) e \\(W_i = 0\\)):\n\nPer stimare l’outcome atteso se tutti gli individui fossero trattati (\\(W_i = 1\\)):\n\\[\n\\hat{Y}_i(1) = \\hat{\\alpha}(1) + X_i \\hat{\\beta}(1).\n\\]\nPer stimare l’outcome atteso se nessun individuo fosse trattato (\\(W_i = 0\\)):\n\\[\n\\hat{Y}_i(0) = \\hat{\\alpha}(0) + X_i \\hat{\\beta}(0).\n\\]\n\ndove:\n\n\\(\\hat{\\alpha}(1)\\) e \\(\\hat{\\alpha}(0)\\) sono gli intercept stimati per i trattati e non trattati.\n\\(\\hat{\\beta}(1)\\) e \\(\\hat{\\beta}(0)\\) sono i coefficienti stimati per le covariate nei due gruppi.\n\nL’effetto medio del trattamento (ATE) si ottiene quindi come la differenza media tra questi due outcome previsti:\n\\[\n\\hat{\\tau}_{IREG} = \\frac{1}{n} \\sum_{i=1}^{n} \\left[ \\hat{Y}_i(1) - \\hat{Y}_i(0) \\right].\n\\]\nIn pratica, l’algoritmo di regressione ti permette di stimare quale sarebbe stato l’outcome atteso per ciascun individuo se fossero stati trattati o meno, tenendo conto delle loro caratteristiche (covariate). La differenza media tra questi due scenari fornisce una stima più precisa dell’ATE.\n\n\n45.1.5.4 Vantaggio dell’aggiustamento\nL’uso delle covariate nel modello aiuta a ridurre la varianza della stima dell’ATE, poiché le covariate possono spiegare parte della variabilità negli outcome. Ciò significa che, rispetto al semplice confronto delle medie tra trattati e non trattati, l’aggiustamento per covariate porta a una stima più precisa, soprattutto quando le covariate hanno una forte influenza sugli outcome.\nIn conclusione, l’aggiustamento per regressione permette di stimare l’ATE in modo più efficiente, migliorando la precisione senza introdurre distorsioni, anche quando la relazione tra le covariate e gli outcome non è perfettamente lineare.\n\n\n\n45.1.6 Confronto tra stimatori\nIl metodo della differenza delle medie è semplice da implementare, ma non ottimale in termini di efficienza statistica, poiché non sfrutta completamente le informazioni disponibili. Al contrario, l’aggiustamento per regressione migliora l’efficienza statistica riducendo la varianza della stima, senza introdurre distorsioni. In particolare, lo stimatore con regressione può essere sempre uguale o migliore (in termini di varianza) rispetto alla differenza delle medie, e questa riduzione della varianza diventa più significativa quando le covariate hanno una forte influenza sugli outcome.\nIn sintesi, l’uso della regressione per aggiustare i risultati è vantaggioso perché permette di utilizzare tutte le informazioni disponibili (inclusi i dati pre-trattamento), migliorando la precisione delle stime senza compromettere la validità delle inferenze.\nQuesti concetti sono fondamentali per comprendere come condurre inferenze causali in modo robusto, specialmente nei contesti sperimentali come i trial randomizzati.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Trial controllati randomizzati</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/01_rct.html#simulazione",
    "href": "chapters/causal_inference/01_rct.html#simulazione",
    "title": "45  Trial controllati randomizzati",
    "section": "45.2 Simulazione",
    "text": "45.2 Simulazione\nIn questo esempio, supponiamo di avere:\n\nUna variabile di trattamento (0 o 1),\nDue covariate (\\(X_1\\), \\(X_2\\)) che influenzano l’outcome,\nUn effetto causale del trattamento.\n\nUseremo una regressione per stimare l’ATE aggiustando per le covariate.\n\n# Imposta il seme per la riproducibilità\nnp.random.seed(42)\n\n# Numero di osservazioni\nn = 500\n\n# Generiamo due covariate indipendenti\nX1 = np.random.normal(50, 10, size=n)  # Covariata 1\nX2 = np.random.normal(30, 5, size=n)  # Covariata 2\n\n# Variabile di trattamento casuale (0 o 1)\ntreatment = np.random.binomial(1, 0.5, size=n)\n\n# Effetti veri delle covariate sugli outcome\nbeta_X1 = 2.0\nbeta_X2 = -1.5\n\n# Effetto del trattamento sull'outcome\ntreatment_effect = 5.0\n\n# Generiamo l'outcome vero includendo il trattamento e le covariate\n# Outcome simulato: Y = 5*T + 2*X1 - 1.5*X2 + errore\noutcome = (\n    treatment_effect * treatment\n    + beta_X1 * X1\n    + beta_X2 * X2\n    + np.random.normal(0, 5, size=n)\n)\n\n# Creiamo un DataFrame per contenere i dati\ndata = pd.DataFrame({\"Treatment\": treatment, \"X1\": X1, \"X2\": X2, \"Outcome\": outcome})\n\n# Mostra un'anteprima dei dati\nprint(data.head())\n\n   Treatment         X1         X2    Outcome\n0          0  54.967142  34.630888  56.161344\n1          0  48.617357  39.547083  38.837491\n2          1  56.476885  23.007162  76.707396\n3          1  65.230299  32.814846  81.380258\n4          0  47.658466  26.746787  61.198821\n\n\n\n45.2.1 Stima dell’ATE senza aggiustamento (Differenza tra le medie)\nLa differenza tra le medie può essere calcolata confrontando l’outcome medio per il gruppo trattato e il gruppo non trattato.\n\n# Calcolo della differenza tra le medie\nmean_treated = data[data[\"Treatment\"] == 1][\"Outcome\"].mean()\nmean_control = data[data[\"Treatment\"] == 0][\"Outcome\"].mean()\n\nate_naive = mean_treated - mean_control\nprint(f\"ATE senza aggiustamento (differenza tra le medie): {ate_naive:.2f}\")\n\nATE senza aggiustamento (differenza tra le medie): 9.59\n\n\n\n\n45.2.2 Aggiustamento per regressione\nOra eseguiamo una regressione lineare che include il trattamento e le covariate. Utilizziamo pingouin o statsmodels per eseguire la regressione e stimare l’ATE.\n\n# Aggiunta di un'intercetta al modello\nX = sm.add_constant(data[[\"Treatment\", \"X1\", \"X2\"]])\n\n# Eseguiamo la regressione con statsmodels\nmodel = sm.OLS(data[\"Outcome\"], X).fit()\n\n# Mostriamo i risultati della regressione\nprint(model.summary())\n\n# Estrarre il coefficiente del trattamento, che rappresenta l'ATE aggiustato\nate_adjusted = model.params[\"Treatment\"]\nprint(f\"\\nATE con aggiustamento per le covariate: {ate_adjusted:.2f}\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                Outcome   R-squared:                       0.952\nModel:                            OLS   Adj. R-squared:                  0.951\nMethod:                 Least Squares   F-statistic:                     3261.\nDate:                Sat, 21 Sep 2024   Prob (F-statistic):               0.00\nTime:                        08:18:33   Log-Likelihood:                -1501.2\nNo. Observations:                 500   AIC:                             3010.\nDf Residuals:                     496   BIC:                             3027.\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -0.0830      1.843     -0.045      0.964      -3.704       3.538\nTreatment      5.9935      0.439     13.648      0.000       5.131       6.856\nX1             1.9780      0.022     88.112      0.000       1.934       2.022\nX2            -1.4672      0.045    -32.658      0.000      -1.555      -1.379\n==============================================================================\nOmnibus:                        0.174   Durbin-Watson:                   1.952\nProb(Omnibus):                  0.917   Jarque-Bera (JB):                0.263\nSkew:                          -0.033   Prob(JB):                        0.877\nKurtosis:                       2.910   Cond. No.                         498.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nATE con aggiustamento per le covariate: 5.99\n\n\n\n\n45.2.3 Interpretazione dei risultati\n\nATE senza aggiustamento (Differenza tra le medie): Questa stima riflette l’effetto medio del trattamento senza tener conto delle covariate.\nATE con aggiustamento per covariate: Questa stima corregge per le differenze nelle covariate \\(X_1\\) e \\(X_2\\) tra i gruppi trattati e non trattati, fornendo una stima più precisa dell’effetto causale del trattamento (nella popolazione, l’ATE simulato era pari a 5).\n\nQuesto esempio mostra come possiamo simulare una popolazione con covariate che influenzano l’outcome e come utilizzare una regressione per aggiustare queste covariate quando stimiamo l’effetto del trattamento (ATE).",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Trial controllati randomizzati</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/01_rct.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/causal_inference/01_rct.html#informazioni-sullambiente-di-sviluppo",
    "title": "45  Trial controllati randomizzati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Jul 17 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nscipy     : 1.14.0\nseaborn   : 0.13.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nNeyman, J. (1923). Sur les applications de la théorie des probabilités aux experiences agricoles: Essai des principes. Roczniki Nauk Rolniczych, 10(1), 1–51.\n\n\nRubin, D. B. (1974). Estimating causal effects of treatments in randomized and nonrandomized studies. Journal of educational Psychology, 66(5), 688–701.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Trial controllati randomizzati</span>"
    ]
  },
  {
    "objectID": "chapters/glm/introduction_glm.html",
    "href": "chapters/glm/introduction_glm.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione esploreremo i modelli statistici che vanno oltre la regressione lineare, ossia quelli che fanno ipotesi distributive non gaussiane per la componente stocastica del modello, considerano una relazione non lineare tra il valore atteso della variabile di risposta e i predittori, e indeboliscono l’assunzione di indipendenza tra le osservazioni.",
    "crumbs": [
      "GLM",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/entropy/introduction_entropy.html",
    "href": "chapters/entropy/introduction_entropy.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, esploreremo il tema cruciale della validazione di un modello statistico e del confronto tra modelli. Vedremo come sia necessario trovare un equilibrio tra due dimensioni: la capacità del modello di predire accuratamente i dati osservati nel campione e la sua capacità di generalizzarsi a campioni diversi.",
    "crumbs": [
      "Entropia",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/introduction_dynamic_models.html",
    "href": "chapters/dynamic_models/introduction_dynamic_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nPrerequisiti\nUno degli sviluppi più significativi nella psicologia contemporanea è l’uso di teorie formali per formulare ipotesi sui meccanismi che sottendono i fenomeni psicologici. I modelli matematici sono strumenti essenziali per concettualizzare la cognizione umana e prevedere i comportamenti osservabili. Questi modelli cercano di fornire una formalizzazione matematica dei processi cognitivi, mappando i costrutti cognitivi latenti sui parametri del modello e descrivendo come questi producono i dati osservati.\nLa maggior parte dei modelli cognitivi tradizionali tratta i dati umani come osservazioni indipendenti e identicamente distribuite (IID). Questa assunzione implica che tali modelli spesso trascurano le variazioni temporali dei costrutti cognitivi latenti. Tuttavia, questi costrutti sono intrinsecamente dinamici, indipendentemente dalla scala temporale considerata. Negli esperimenti psicologici, le capacità cognitive sono influenzate non solo dalle richieste esterne del compito, ma anche dai processi mentali interni e dagli stati cerebrali che cambiano nel tempo. Le fluttuazioni sistematiche e non sistematiche che ne derivano possono avere diverse spiegazioni, come la fatica, la pratica, la divagazione mentale o fattori motivazionali. Come evidenziato da Schumacher et al. (2023), i meccanismi cognitivi dovrebbero essere trattati come sistemi dinamici complessi, e i modelli cognitivi dovrebbero tenere conto delle dinamiche dei loro componenti per comprendere appieno e catturare la ricca struttura dei dati empirici umani.\nLa teoria dei sistemi dinamici (Dynamic Systems Theory, DST) fornisce un quadro concettuale per comprendere i fenomeni psicologici come processi complessi, non lineari e spesso auto-organizzanti che si evolvono nel tempo. In psicologia, la DST sottolinea come il comportamento e la cognizione emergano dalle interazioni di molteplici componenti sia all’interno di un individuo sia tra l’individuo e il suo ambiente. Di seguito, presenteremo alcuni esempi di fenomeni psicologici che possono essere compresi attraverso la lente dei sistemi dinamici.\nApprendimento per rinforzo. L’apprendimento per rinforzo è un processo attraverso cui gli individui apprendono a modificare il proprio comportamento in base alle conseguenze che ne derivano. In termini di sistemi dinamici, l’apprendimento per rinforzo può essere visto come un processo adattativo in cui le decisioni di un individuo vengono continuamente aggiornate e migliorate attraverso l’interazione con l’ambiente. In questo contesto, le ricompense (o rinforzi positivi) e le punizioni (o rinforzi negativi) giocano un ruolo cruciale nel modellare il comportamento futuro, creando un ciclo di feedback che rafforza o indebolisce determinate azioni. Ad esempio, un comportamento che porta a una ricompensa tende a essere ripetuto, mentre un comportamento che porta a una punizione tende a essere evitato. Questo meccanismo di apprendimento, che può essere descritto matematicamente attraverso modelli probabilistici, permette di predire come un individuo possa modificare il proprio comportamento in situazioni diverse, sulla base delle esperienze passate e delle aspettative future. I modelli di apprendimento per rinforzo, come il modello di Rescorla-Wagner, sono stati ampiamente utilizzati in psicologia per spiegare non solo comportamenti semplici come il condizionamento classico e operante, ma anche fenomeni più complessi come la dipendenza, i disturbi d’ansia e i disturbi dell’umore. In questi casi, le aspettative disadattive e i bias cognitivi possono essere visti come il risultato di un apprendimento per rinforzo anomalo, in cui le associazioni tra stimoli e conseguenze sono distorte o esagerate. Studi recenti in psichiatria computazionale utilizzano questi modelli per sviluppare interventi terapeutici più efficaci, mirati a ristrutturare le associazioni disfunzionali e promuovere schemi di apprendimento più adattivi.\nRegolazione delle emozioni. La regolazione delle emozioni implica l’interazione dinamica di processi fisiologici, cognitivi e comportamentali. Ad esempio, il modo in cui una persona regola le proprie emozioni in risposta a un evento stressante può essere influenzato da diversi fattori, come esperienze precedenti, contesto attuale, stati fisiologici (come frequenza cardiaca o livelli ormonali) e valutazioni cognitive. Nel tempo, questi componenti possono interagire in modo non lineare, creando circuiti di retroazione. Ad esempio, una persona potrebbe inizialmente cercare di sopprimere le proprie emozioni, il che potrebbe portare a un aumento dell’eccitazione fisiologica, intensificando così l’emozione che stava cercando di regolare.\nAttaccamento e relazioni sociali. Anche gli stili di attaccamento e le relazioni sociali sono sistemi dinamici. La teoria dell’attaccamento descrive come le prime relazioni con i caregiver influenzino le dinamiche interpersonali per tutta la vita. Queste relazioni possono essere viste come sistemi in cui i comportamenti, le emozioni e le cognizioni di una persona influenzano continuamente e sono influenzati da quelli degli altri. Ad esempio, in una relazione genitore-figlio, il comportamento del bambino può influenzare le risposte del genitore, che a loro volta modellano il comportamento e gli stati emotivi futuri del bambino, creando un ciclo di retroazione che evolve nel tempo.\nSviluppo cognitivo. Lo sviluppo cognitivo, soprattutto nei bambini, viene spesso modellato come un sistema dinamico. La teoria dello sviluppo cognitivo di Jean Piaget, sebbene non esplicitamente in termini di DST, può essere reinterpretata in questo modo. Ad esempio, il processo di raggiungimento dell’equilibrio cognitivo comporta interazioni continue tra le strutture di conoscenza esistenti del bambino (schemi) e le nuove esperienze. Questo processo è dinamico perché il sistema cognitivo del bambino si adatta e si riorganizza costantemente in risposta a nuove informazioni, il che può portare a cambiamenti qualitativi nel pensiero.\nControllo motorio e coordinazione. Lo sviluppo e il controllo delle azioni motorie, come camminare o afferrare, sono esempi classici di sistemi dinamici. Il controllo motorio coinvolge il coordinamento di numerosi muscoli, circuiti di retroazione sensoriale e aggiustamenti basati sull’ambiente. L’approccio dei sistemi dinamici allo sviluppo motorio enfatizza come i comportamenti motori emergano dall’auto-organizzazione di molteplici sistemi interagenti, come componenti neurali, muscolari e percettivi. Imparare a camminare, ad esempio, non è solo un’accumulazione lineare di forza ed equilibrio, ma comporta cambiamenti non lineari nel coordinamento muscolare, nell’integrazione sensoriale e nei processi di retroazione.\nDecision making e problem solving. Il processo decisionale e la risoluzione dei problemi coinvolgono l’integrazione di molteplici fattori cognitivi ed emotivi che cambiano nel tempo. La natura dinamica di questi processi è evidente in come le decisioni iniziali possano portare a cambiamenti negli obiettivi, nel comportamento di ricerca delle informazioni e negli stati emotivi, che a loro volta influenzano le decisioni successive. Ad esempio, quando si prende una decisione in condizioni di incertezza, i livelli di fiducia di una persona, le reazioni emotive e le interpretazioni di nuove informazioni possono interagire dinamicamente, creando un modello fluttuante di comportamento decisionale.\nSalute mentale e psicopatologia. La salute mentale e la psicopatologia possono essere comprese anche da una prospettiva di sistemi dinamici. I disturbi come la depressione o l’ansia non sono visti come entità statiche, ma come schemi dinamici di cognizione, emozione e comportamento che evolvono nel tempo. Ad esempio, i sintomi depressivi possono creare un ciclo di retroazione in cui i pensieri negativi portano a una ridotta attività, che a sua volta porta a pensieri ed emozioni ancora più negativi, perpetuando il ciclo. Comprendere la psicopatologia come un sistema dinamico aiuta a sviluppare interventi che mirano a questi cicli di retroazione e promuovono schemi più adattivi.\nSviluppo del linguaggio. Lo sviluppo del linguaggio è un altro ambito in cui la teoria dei sistemi dinamici è applicabile. L’acquisizione del linguaggio nei bambini implica l’interazione di molteplici fattori, come la conoscenza fonologica, sintattica e semantica, nonché l’interazione sociale e le esperienze percettive. Lo sviluppo del linguaggio non è un’accumulazione lineare di vocabolario e regole grammaticali; piuttosto, emerge dall’interazione dinamica di questi fattori mentre i bambini interagiscono con il loro ambiente e i caregiver, portando a cambiamenti qualitativi nelle capacità linguistiche nel tempo.\nDinamiche di gruppo e influenza sociale. Il comportamento di gruppo e l’influenza sociale sono fenomeni che possono essere modellati come sistemi dinamici. Nei gruppi sociali, i comportamenti e gli atteggiamenti individuali possono influenzare gli altri, portando a cambiamenti nelle norme e nelle dinamiche di gruppo. Questi cambiamenti possono quindi influenzare di nuovo i comportamenti individuali, creando un ciclo di retroazione. Ad esempio, in un contesto di gruppo, l’emergere di un leader o la diffusione di una particolare opinione può portare a cambiamenti nel comportamento del gruppo che sono dinamici e talvolta imprevedibili.\nAutoregolazione e funzioni esecutive. L’autoregolazione e le funzioni esecutive coinvolgono la capacità di controllare l’attenzione, le emozioni e i comportamenti per raggiungere obiettivi a lungo termine. Questi processi sono dinamici perché implicano il monitoraggio continuo e l’aggiustamento delle azioni sulla base del feedback dall’ambiente. Ad esempio, rimanere concentrati su un compito implica regolare dinamicamente l’attenzione in risposta alle distrazioni, il che richiede l’integrazione di molteplici processi cognitivi come la memoria di lavoro, l’inibizione e la pianificazione.\nApprendimento e memoria. L’apprendimento e la memoria sono anche processi intrinsecamente dinamici. La codifica, l’immagazzinamento e il recupero dei ricordi coinvolgono l’interazione di molteplici sistemi neurali e cognitivi che cambiano nel tempo. Ad esempio, il processo di consolidamento della memoria, in cui i ricordi a breve termine vengono stabilizzati in ricordi a lungo termine, è dinamico e può essere influenzato da vari fattori come il sonno, lo stato emotivo e le esperienze successive.\nIn questa sezione della dispensa, forniremo un’introduzione ai modelli dinamici, con particolare attenzione ai modelli di apprendimento per rinforzo. Questi modelli sono utilizzati in psicologia per spiegare i bias cognitivi in varie patologie, tra cui la depressione, i disturbi alimentari e il disturbo ossessivo-compulsivo. Questo campo di studio all’avanguardia, noto come psichiatria computazionale, non si limita agli esempi citati ma esplora una vasta gamma di applicazioni. In particolare, introdurremo uno dei modelli più famosi in questo contesto: il modello di apprendimento associativo di Rescorla-Wagner. Questo modello descrive come gli organismi apprendano a prevedere eventi attraverso l’associazione tra stimoli, fornendo una spiegazione quantitativa di come si sviluppano e si modificano le aspettative basate sull’esperienza. In psicologia, il modello di Rescorla-Wagner è utilizzato per comprendere come gli individui apprendano dalle conseguenze delle loro azioni e come questo apprendimento possa essere influenzato da fattori cognitivi e affettivi, contribuendo così alla nostra comprensione dei meccanismi alla base di diverse condizioni psicopatologiche.",
    "crumbs": [
      "Dinamiche",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/introduction_dynamic_models.html#bibliografia",
    "href": "chapters/dynamic_models/introduction_dynamic_models.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Hayes, S. C., Hofmann, S. G., Stanton, C. E., Carpenter, J. K., Sanford, B. T., Curtiss, J. E., & Ciarrochi, J. (2019). The role of the individual in the coming era of process-based therapy. Behaviour Research and Therapy, 117, 40–53.\n\n\nSchumacher, L., Bürkner, P.-C., Voss, A., Köthe, U., & Radev, S. T. (2023). Neural superstatistics for Bayesian estimation of dynamic cognitive models. Scientific Reports, 13(1), 13778.",
    "crumbs": [
      "Dinamiche",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "I Modelli Computazionali della Cognizione\nComprendere la cognizione umana è stato uno dei principali obiettivi della ricerca psicologica per oltre un secolo. Gli approcci matematici allo studio della cognizione risalgono già al XIX secolo, quando ricercatori come Ernst Heinrich Weber svilupparono modelli matematici per descrivere fenomeni percettivi, come l’effetto della “differenza appena percepibile”, che descrive il modo in cui gli esseri umani percepiscono le differenze tra gli oggetti (Raymond & Rutherford, 2012). Tuttavia, fu solo con l’avvento dell’informatica teorica e dei computer digitali nel XX secolo che la psicologia computazionale emerse come un campo a sé stante. La nascita del computer digitale permise agli psicologi cognitivi di sviluppare formalismi matematici e modelli computazionali che descrivevano la cognizione come un fenomeno di elaborazione delle informazioni, in modo simile a come operano i computer digitali. Ricercatori come George Miller, Allen Newell, Herbert Simon e Frank Rosenblatt applicarono metodi computazionali allo studio della percezione, del linguaggio e della risoluzione dei problemi, gettando le basi per questo campo emergente (Boden, 2008). La psicologia computazionale ha offerto un approccio alternativo allo studio della mente, basato su algoritmi e simulazioni al computer, anziché su correlazioni e sperimentazioni in laboratorio, i paradigmi predominanti all’epoca, come osservato dal presidente dell’American Psychological Association, Lee Cronbach (Cronbach, 1957).\nNel primo quarto del XXI secolo, il campo dei modelli computazionali della cognizione sta vivendo una crescita rapida in un mondo dove nazioni e giganti tecnologici competono per scoprire i segreti dell’intelligenza umana e artificiale. In questa introduzione, offro una panoramica storica degli approcci computazionali in scienza cognitiva, evidenziando l’importanza e la prospettiva unica di questi metodi nello studio del pensiero e del comportamento umano. Adotterò una prospettiva storica, concentrandomi su una narrazione ad alto livello dell’evoluzione del campo, piuttosto che su numerosi esempi individuali di modelli computazionali (Boden, 2008).",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#la-scienza-cognitiva-computazionale",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#la-scienza-cognitiva-computazionale",
    "title": "Introduzione",
    "section": "La Scienza Cognitiva Computazionale",
    "text": "La Scienza Cognitiva Computazionale\nNonostante l’importanza dei modelli computazionali, la scienza cognitiva computazionale ha impiegato molto tempo a consolidarsi tra i paradigmi principali nello studio della mente e del comportamento. Durante la prima metà del XX secolo, lo studio della mente era visto con sospetto da molti, data la nostra incapacità di accedere direttamente ai suoi contenuti (Skinner, 1965; Watson, 1913). Concetti come “coscienza” o “memoria” sono entità che i ricercatori possono misurare solo indirettamente osservando il comportamento delle persone, ma non esiste un modo per “toccare” o “vedere” un frammento di memoria nella mente di qualcuno. Questi sono eventi privati, esperienze soggettive, entità inaccessibili di costituzione eterea. Sebbene all’epoca fossimo in grado di osservare e misurare i pattern di attività elettrica nel cervello, trovare una corrispondenza diretta tra tali pattern e un particolare frammento di memoria era quanto mai ambiguo.\nL’invenzione del computer digitale è stata quindi rivoluzionaria per gli psicologi cognitivi, poiché ha fornito un esempio fisico di qualcosa che poteva fare molte delle cose che fa la mente umana: aritmetica, logica, memorizzazione di informazioni, e altro ancora. Dopo tutto, è possibile costruire, toccare e vedere un computer digitale. Si sa esattamente dove un’informazione viene elaborata e memorizzata. È difficile osservare un computer digitale in azione e non notare la somiglianza con i meccanismi interni della mente umana.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#oltre-le-reti-neurali",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#oltre-le-reti-neurali",
    "title": "Introduzione",
    "section": "Oltre le Reti Neurali",
    "text": "Oltre le Reti Neurali\nSebbene le reti neurali abbiano avuto un ruolo di primo piano nello sviluppo della scienza cognitiva computazionale, i modelli computazionali della cognizione non si limitano a queste. In realtà, esistono diversi approcci modellistici, ciascuno con le proprie specificità e aree di applicazione. I modelli simbolici, ad esempio, descrivono la cognizione umana come il risultato della manipolazione di simboli, basandosi su logica formale e linguistica. I modelli probabilistici, invece, utilizzano la teoria delle probabilità per descrivere il ragionamento umano in condizioni di incertezza.\nNel corso degli anni, questi approcci si sono evoluti e spesso integrati tra loro, portando allo sviluppo di modelli ibridi che combinano elementi simbolici, connessionisti e probabilistici. La psichiatria computazionale, in particolare, ha tratto vantaggio da questo approccio integrato, utilizzando modelli che possono adattarsi a diverse scale di analisi, dai circuiti neuronali ai comportamenti osservabili, per fornire una visione più completa dei disturbi mentali.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#la-psichiatria-computazionale",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#la-psichiatria-computazionale",
    "title": "Introduzione",
    "section": "La Psichiatria Computazionale",
    "text": "La Psichiatria Computazionale\nLa psichiatria computazional è un campo emergente utilizza modelli matematici e computazionali per comprendere i meccanismi mentali e comportamentali che stanno alla base dei disturbi mentali. L’approccio computazionale in psichiatria cerca di modellare in modo preciso le alterazioni nei processi cognitivi e decisionali che possono caratterizzare patologie come la schizofrenia, la depressione e i disturbi d’ansia.\nUn esempio emblematico di questo approccio è il lavoro di Michael Frank, che ha sviluppato modelli computazionali per comprendere i processi di apprendimento e decisione nei disturbi mentali. Frank ha esplorato come i modelli computazionali possano essere utilizzati per comprendere il funzionamento dei circuiti neuronali associati al rinforzo e alla punizione, e come alterazioni in questi circuiti possano contribuire a diverse manifestazioni psicopatologiche (Hitchcock et al., 2022). Ad esempio, i suoi studi sui meccanismi di rinforzo e sulla modulazione dopaminergica hanno fornito nuove prospettive sul funzionamento della malattia di Parkinson e sui disturbi compulsivi, mettendo in luce come alterazioni nei circuiti di rinforzo possano influenzare le decisioni e i comportamenti.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#conclusioni",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#conclusioni",
    "title": "Introduzione",
    "section": "Conclusioni",
    "text": "Conclusioni\nI modelli computazionali della cognizione hanno una lunga tradizione, iniziata nella prima metà del XX secolo come un intreccio di teoria computazionale e psicologia cognitiva. Nel tempo, sono emersi quattro principali approcci all’interno di questa prospettiva: modelli basati su simboli, modelli basati su connessionismi, modelli ibridi e modelli basati su probabilità. L’approccio computazionale ha contribuito a migliorare e ampliare la nostra comprensione della cognizione e del comportamento umano. Le recenti avanzate nella disponibilità di risorse computazionali e di dati, insieme all’interesse pubblico e privato nello sviluppo di tecnologie di intelligenza artificiale, forniscono un contesto fertile per la crescita e il consolidamento della prospettiva computazionale nelle scienze cognitive e nella psichiatria.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#bibliografia",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#bibliografia",
    "title": "Introduzione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBoden, M. A. (2008). An evaluation of computational modeling in cognitive science.\n\n\nCronbach, L. J. (1957). The two disciplines of scientific psychology. American psychologist, 12(11), 671–684.\n\n\nHitchcock, P. F., Fried, E. I., & Frank, M. J. (2022). Computational psychiatry needs time and context. Annual review of psychology, 73(1), 243–270.\n\n\nSkinner, B. F. (1965). Science and human behavior. Simon; Schuster.\n\n\nWatson, J. B. (1913). Psychology as the behaviorist views it. Psychological review, 20(2), 158.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "Nell’inferenza statistica esistono due approcci principali: la statistica frequentista e la statistica bayesiana. Entrambi i metodi permettono di trarre conclusioni sulla popolazione di interesse analizzando i dati, stimare quantità sconosciute, fare previsioni e testare ipotesi. Tuttavia, differiscono nell’interpretazione della probabilità e nell’integrazione di conoscenze precedenti ed evidenze.\nLa statistica bayesiana interpreta la probabilità come una misura di convinzione o grado di certezza riguardo a un evento. Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell’analisi statistica utilizzando il teorema di Bayes. In questo contesto, il valore vero di un parametro della popolazione è trattato come una variabile casuale, che viene costantemente aggiornata man mano che nuovi dati vengono raccolti. Ciò porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, utilizzabile per fare previsioni probabilistiche e quantificare l’incertezza associata.\nD’altra parte, la statistica frequentista interpreta la probabilità come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull’idea che il vero valore di un parametro della popolazione sia fisso ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute dai dati osservati utilizzando varie tecniche statistiche e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nIn questa sezione della dispensa esamineremo i metodi frequentisti della stima puntuale, degli intervalli di confidenza e del test di ipotesi.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html",
    "title": "46  Introduzione all’inferenza frequentista",
    "section": "",
    "text": "46.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nCi sono due approcci principali per l’inferenza statistica: la statistica frequentista e la statistica bayesiana. Questi metodi consentono di fare conclusioni sulla popolazione di interesse attraverso l’analisi dei dati. Entrambi gli approcci sono usati per stimare quantità sconosciute, fare previsioni e testare ipotesi, ma differiscono nella loro interpretazione della probabilità e in come integrano le conoscenze precedenti ed evidenze.\nNella statistica frequentista, la probabilità viene interpretata come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull’idea che il vero valore di un parametro della popolazione sia fisso, ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute a partire dai dati osservati, mediante l’utilizzo di tecniche come la stima puntuale, gli intervalli di confidenza e il test di ipotesi, e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nD’altra parte, la statistica bayesiana interpreta la probabilità come una misura di convinzione o grado di certezza riguardo a un evento (Jaynes, 2003). Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell’analisi statistica attraverso l’uso del teorema di Bayes. In questo contesto, il vero valore di un parametro della popolazione è trattato come una variabile casuale e viene continuamente aggiornato man mano che vengono raccolti nuovi dati. Ciò porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, che può essere utilizzata per fare previsioni probabilistiche e quantificare l’incertezza associata.\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell’inferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle proprietà probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste proprietà sono utili per costruire gli intervalli di fiducia e i test di ipotesi che costituiscono gli strumenti principali dell’inferenza statistica frequentista.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "title": "46  Introduzione all’inferenza frequentista",
    "section": "46.2 I Frequentisti sono Razzisti?",
    "text": "46.2 I Frequentisti sono Razzisti?\nNel ?sec-bayes_theorem, abbiamo esaminato le origini storiche e il contesto culturale che ha contribuito all’interpretazione applicativa del teorema di Bayes fornita da Richard Price. Queste origini sono legate alle idee alla base della rivoluzione americana, rappresentando quello che potremmo definire il “lato luminoso” del liberalismo moderno.\nLe origini culturali dell’approccio frequentista, invece, sono diametralmente opposte e strettamente connesse a quella che potremmo chiamare la “parte oscura” della modernità. Si potrebbe dire che l’avversione per la soggettività abbia guidato l’ascesa del frequentismo.\nFrancis Galton (1822-1911) fu un uomo straordinario sotto molti aspetti. Cugino di Charles Darwin e medico qualificato, ereditò una fortuna che gli permise di dedicarsi liberamente ai suoi interessi. Esplorò l’Africa, ricevendo una medaglia dalla Royal Geographical Society, e diede un importante contributo alla meteorologia, notando per primo il fenomeno degli “anticicloni”. Tuttavia, il suo contributo più significativo riguardò l’uso della statistica nello studio degli esseri umani, in particolare nell’analisi della trasmissione ereditaria del talento.\nGalton trascorse gran parte della sua carriera all’University College di Londra, dove fece numerose scoperte. Tra queste, un importante contributo riguardava la distribuzione normale. Fu anche il primo a spiegare il concetto che oggi conosciamo come “regressione verso la media”, da lui chiamato “regressione verso la mediocrità”.\nIl suo interesse per l’ereditarietà del talento portò Francis Galton a scrivere il libro Hereditary Genius, in cui analizzava come individui brillanti tendessero a concentrarsi in specifiche famiglie. Fu lui a coniare l’espressione “nature and nurture” per riferirsi ai due fattori fondamentali che influenzano lo sviluppo umano: l’ereditarietà (ciò che oggi chiamiamo genetica) e l’ambiente.\nTuttavia, Galton non si limitò a osservare e documentare la distribuzione dell’intelligenza. Il suo obiettivo era ambizioso e controverso: creare una scienza per il “miglioramento della specie umana”, che egli chiamò “eugenetica”. Promuoveva l’idea di incoraggiare la riproduzione tra le famiglie considerate di maggior successo e, al contrario, di scoraggiarla tra quelle ritenute meno fortunate.\nVa però sottolineato che Galton abbracciava idee profondamente razziste. In una lettera pubblicata sul Times di Londra, descrisse gli africani come “inferiori” e li definì “selvaggi pigri e chiacchieroni”. Gli arabi, secondo lui, erano “poco più che consumatori della produzione altrui”. Proponeva inoltre di consegnare l’Africa orientale ai cinesi, che giudicava “inclini alla menzogna e alla servilità” ma anche, a suo dire, “naturalmente industriosi e amanti dell’ordine”. Per Galton, gli anglosassoni rappresentavano la razza migliore esistente, sebbene ritenesse che gli antichi ateniesi fossero stati il vertice dell’umanità.\nIl lavoro di Galton ispirò una generazione successiva di statistici, in particolare Karl Pearson (1857-1936) e Ronald Fisher (1890-1962). Come Galton, Fisher e Pearson erano brillanti, ma condividevano anche le sue idee razziste, considerate inaccettabili sia per gli standard attuali che per quelli del loro tempo.\nKarl Pearson, poliedrico studioso e innovatore, divenne professore di matematica applicata all’UCL nel 1885, seguendo le orme di Francis Galton. Dopo la morte di quest’ultimo, ereditò la cattedra di eugenetica, istituita e finanziata da Galton stesso. Pearson fondò la rivista di statistica Biometrika e diede un contributo fondamentale alla disciplina, sviluppando il test del chi quadrato e coniando il termine “deviazione standard”.\nRonald Fisher, più giovane, succedette a Pearson come professore di eugenetica presso l’UCL. Considerato un gigante della teoria statistica, Fisher contribuì in modo decisivo allo sviluppo della disciplina, inventando o perfezionando strumenti fondamentali come l’analisi della varianza (ANOVA), il concetto di “significatività statistica” e il metodo della massima verosimiglianza (MLE).\nTutti questi ricercatori cercarono di allontanare la statistica dall’approccio soggettivo di Laplace e Bayes. Come Galton, sia Pearson che Fisher erano convinti sostenitori dell’eugenetica.\nÈ interessante riflettere su quanto le idee di Galton, Pearson e Fisher sull’eugenetica possano aver influenzato le loro visioni scientifiche. Secondo alcuni studiosi, la storia della statistica e quella dell’eugenetica sono strettamente intrecciate. Fisher, e in misura minore Pearson, rigettavano il bayesianesimo perché desideravano conferire un fondamento apparentemente “oggettivo” alle loro idee eugenetiche. Se fosse stata la scienza a “dimostrare” che alcune razze erano inferiori ad altre, o che la riproduzione tra i poveri dovesse essere scoraggiata, queste teorie sarebbero state presentate come indiscutibili. Il bayesianesimo, con la sua componente intrinseca di soggettività, rappresentava una minaccia a questa pretesa di oggettività.\nQuanto dovremmo considerare le implicazioni storiche ed etiche quando valutiamo la statistica frequentista? Chivers (2024) risponde così: è indubbio che una parte dell’ideologia razziale nazista possa essere ricondotta a Galton senza troppe difficoltà. Tuttavia, questa riflessione, per quanto cruciale dal punto di vista storico ed etico, non è direttamente rilevante in ambito strettamente statistico. La domanda fondamentale rimane: “Quale approccio è corretto?” o, meglio ancora, “Quale approccio è più utile?”, anziché chiedersi “Quale approccio ha avuto i sostenitori più discutibili?”.\nPur riconoscendo il valore di questa risposta in termini di focalizzazione sulla metodologia, ritengo che sia intrinsecamente inadeguata. Consideriamo uno scenario ipotetico: supponiamo che in una “torre d’avorio” – che sia la statistica, l’accademia o la scienza in generale – la teoria A risulti più efficace della teoria B. Tuttavia, al di fuori di questo contesto isolato, la teoria A comporta conseguenze etiche inaccettabili, mentre la teoria B no. Dovremmo davvero accettare A semplicemente perché funziona meglio in un sistema chiuso e teorico? La mia risposta è un categorico no.\nLe cosiddette “torri d’avorio” sono costruzioni ideologiche che non rispecchiano la realtà. Non esiste una netta separazione tra “dentro” e “fuori”: scienza ed etica non operano in compartimenti stagni, ma interagiscono costantemente. L’idea di giudicare una teoria esclusivamente sulla base della sua efficacia all’interno di un contesto limitato ignora le sue implicazioni più ampie e potenzialmente dannose.\nNel caso specifico del frequentismo, è evidente – come dimostreremo in seguito – che questo approccio non solo presenta implicazioni etiche problematiche, ma è anche intrinsecamente fallace dal punto di vista metodologico. La sua supposta efficacia in un ambito ristretto è un’illusione che non regge a un’analisi critica più ampia. Non possiamo, né dobbiamo, separare l’efficacia teorica dalle conseguenze pratiche ed etiche. Il frequentismo fallisce su entrambi i fronti: morale e scientifico. Difenderlo, quindi, risulta insostenibile in ogni contesto.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "title": "46  Introduzione all’inferenza frequentista",
    "section": "46.3 Stime, stimatori e parametri",
    "text": "46.3 Stime, stimatori e parametri\nSpostiamo ora il discorso da un piano culturale ad un piano strettamente statistico. Consideriamo il concetto di stima statistica.\nQuando si analizzano i dati, solitamente si è interessati a una quantità a livello di popolazione; tuttavia, di solito si ha accesso solo a un campione di osservazioni. La quantità sconosciuta di nostro interesse viene chiamata parametro. La statistica che calcoliamo utilizzando i dati del campione viene chiamata stima, e la formula che la produce viene chiamata stimatore. Formalmente, uno stimatore è una funzione dei dati osservati utilizzata per produrre una stima di un parametro.\nIn altre parole, quando analizziamo un campione di dati, vogliamo inferire alcune proprietà della popolazione di cui il campione è rappresentativo. Il parametro rappresenta la misura di tali proprietà, ma spesso non è possibile calcolarlo direttamente sulla popolazione. Pertanto, lo stimiamo utilizzando le osservazioni del campione. La stima è quindi l’approssimazione del valore del parametro che otteniamo dal nostro campione, mentre lo stimatore è la formula matematica utilizzata per calcolare questa stima.\nTuttavia, le stime non sono necessariamente identiche ai parametri di nostro interesse. Le stime presentano una certa incertezza dovuta alla variabilità del campionamento. In questo capitolo esamineremo come l’approccio frequentista quantifica l’incertezza nelle nostre stime, in modo da poter trarre conclusioni sul parametro.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "title": "46  Introduzione all’inferenza frequentista",
    "section": "46.4 Distribuzione campionaria",
    "text": "46.4 Distribuzione campionaria\nIn questo capitolo esploreremo come la media di un campione casuale può essere utilizzata per stimare la media \\(\\mu\\) di una popolazione. Per valutare l’incertezza di questa stima, ci avvaliamo del concetto di distribuzione campionaria, un’importante idea dell’approccio frequentista.\nPer introdurre il concetto, utilizzeremo una popolazione finita di piccole dimensioni, pur sapendo che le proprietà illustrate valgono anche per popolazioni di dimensioni maggiori.\n\n46.4.1 Esempio introduttivo\nConsideriamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nL’istogramma sottostante rappresenta la distribuzione di frequenza della popolazione:\n\nhist(\n  x, breaks = 5, \n  freq = FALSE, \n  main = \"Distribuzione della popolazione\", \n  xlab = \"Valori\"\n)\n\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione:\n\nmean(x)  # Media\n#&gt; [1] 4.25\nvar(x)   # Varianza\n#&gt; [1] 2.416667\n\n\n\n46.4.2 Campionamento\nSupponiamo ora di estrarre tutti i possibili campioni di dimensione \\(n = 2\\) dalla popolazione. Per generare queste combinazioni:\n\nsamples &lt;- expand.grid(x, x)\nsamples\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nOgni riga rappresenta un campione possibile. Calcoliamo il numero totale di campioni:\n\nnrow(samples)\n#&gt; [1] 16\n\nOra calcoliamo la media di ciascun campione, ottenendo la distribuzione campionaria delle medie per \\(n = 2\\):\n\nsample_means &lt;- rowMeans(samples)\nsample_means\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\n\n\n46.4.3 Visualizzazione della distribuzione campionaria\nPossiamo rappresentare graficamente questa distribuzione:\n\nhist(\n  sample_means, \n  breaks = 5, \n  freq = FALSE, \n  main = \"Distribuzione campionaria delle medie (n = 2)\", \n  xlab = \"Media campionaria\"\n)\n\n\n\n\n\n\n\n\n\n\n46.4.4 Verifiche teoriche\n\n46.4.4.1 Media della distribuzione campionaria\nLa media della distribuzione campionaria deve essere uguale alla media della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nmean(sample_means)  # Media della distribuzione campionaria\n#&gt; [1] 4.25\n\n\n\n46.4.4.2 Varianza della distribuzione campionaria\nLa varianza della distribuzione campionaria deve essere pari alla varianza della popolazione divisa per \\(n\\):\n\n# Evito la divisione per (n - 1)\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)\n}\n\n\nvariance(x) / 2  # Varianza teorica\n#&gt; [1] 0.90625\nvariance(sample_means)  # Varianza empirica\n#&gt; [1] 0.90625\n\n\n\n\n46.4.5 Esempio di campione osservato\nConsideriamo un singolo campione, ad esempio \\(\\{5, 5.5\\}\\):\n\nobserved_sample &lt;- c(5, 5.5)\nobserved_sample\n#&gt; [1] 5.0 5.5\n\nTroviamo la sua media e deviazione standard:\n\nmean(observed_sample)  # Media del campione\n#&gt; [1] 5.25\nsqrt(variance(observed_sample))    # Deviazione standard del campione\n#&gt; [1] 0.25\n\nConfrontiamo questi valori con quelli della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nsqrt(variance(x))     # Deviazione standard della popolazione\n#&gt; [1] 1.346291\n\nIn conclusione, dalla simulazione emergono due risultati fondamentali:\n\nLa media della distribuzione campionaria coincide con la media della popolazione. Questo significa che, se si considera la media \\(\\bar{X}_n\\) di campioni casuali di ampiezza \\(n\\), il valore atteso di \\(\\bar{X}_n\\) è uguale alla media della popolazione \\(\\mu\\). Formalmente:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\mathbb{E}(S_n) = \\frac{1}{n} n \\mu = \\mu,\n\\] dove \\(\\mathbb{E}(\\cdot)\\) rappresenta il valore atteso e \\(S_n\\) la somma delle osservazioni nel campione.\nLa varianza della distribuzione campionaria è inferiore alla varianza della popolazione. In particolare, la varianza delle medie campionarie è data dalla varianza della popolazione divisa per l’ampiezza del campione, ovvero:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\n\n\n\n\n\n\n\nNota\n\n\n\nIl secondo risultato sopra può essere dimostrato come segue.\nSia \\(X_1, X_2, \\dots, X_n\\) un campione casuale di \\(n\\) osservazioni indipendenti estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). La media campionaria è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nPer definizione, la varianza di \\(\\bar{X}\\) è:\n\\[\n\\mathbb{V}(\\bar{X}) = \\mathbb{V}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right).\n\\]\nPoiché una costante moltiplicata da una variabile aleatoria può essere “estratta” dalla varianza, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right).\n\\]\nOra dobbiamo calcolare \\(\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right)\\). Le variabili \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, quindi la varianza della somma è la somma delle varianze:\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\mathbb{V}(X_i).\n\\]\nPoiché tutte le variabili \\(X_i\\) hanno la stessa varianza \\(\\sigma^2\\):\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = n \\sigma^2.\n\\]\nSostituendo nella formula precedente, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\cdot n \\sigma^2 = \\frac{\\sigma^2}{n}.\n\\]\nIn generale, dunque, per un campione di ampiezza \\(n\\), vale la relazione \\(\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\\).\n\n\n\n\n46.4.6 Proprietà della distribuzione campionaria\nInfine, osserviamo una proprietà fondamentale della distribuzione campionaria:\n\nSe la popolazione segue una distribuzione normale, allora anche la distribuzione delle medie campionarie seguirà una distribuzione normale, indipendentemente dall’ampiezza del campione.\nSe invece la popolazione non segue una distribuzione normale, il teorema del limite centrale garantisce che, all’aumentare della dimensione del campione \\(n\\), la distribuzione campionaria delle medie tenderà a una distribuzione normale.\n\nQueste proprietà sono centrali in molti metodi statistici, poiché consentono di fare inferenza sulla popolazione utilizzando campioni.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "title": "46  Introduzione all’inferenza frequentista",
    "section": "46.5 Teorema del Limite Centrale",
    "text": "46.5 Teorema del Limite Centrale\nEsaminiamo ora più in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Laplace dimostrò il TLC, che afferma che la somma di una sequenza di variabili casuali indipendenti tende a distribuirsi secondo una distribuzione Normale. Inoltre, il TLC stabilisce i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.\n\nTeorema 46.1 Si supponga che \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\) sia una sequenza di v.a. i.i.d. (variabili aleatorie identicamente distribuite e indipendenti) con \\(\\mathbb{E}(Y_i) = \\mu\\) e \\(SD(Y_i) = \\sigma\\). Si definisca una nuova variabile casuale come:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nCon \\(n \\rightarrow \\infty\\), \\(Z\\) tenderà a seguire una distribuzione Normale con lo stesso valore atteso di \\(Y_i\\) e una deviazione standard ridotta di un fattore pari a \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nIl TLC può essere generalizzato a variabili casuali che non sono identicamente distribuite, a condizione che siano indipendenti e abbiano aspettative e varianze finite. Molti fenomeni naturali, come l’altezza degli adulti, sono il risultato di una combinazione di effetti additivi relativamente piccoli. Questi effetti, indipendentemente dalla loro distribuzione individuale, tendono a portare alla normalità della distribuzione risultante. Questa è la ragione per cui la distribuzione normale fornisce una buona approssimazione per la distribuzione di molti fenomeni naturali.\n\n46.5.1 Illustrazione del TLC\nPer dimostrare il Teorema del Limite Centrale, consideriamo una popolazione iniziale con una distribuzione fortemente asimmetrica: una distribuzione Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 1\\). Estraiamo 50.000 campioni casuali di ampiezza \\(n\\) da questa popolazione e costruiamo la distribuzione campionaria delle medie.\nDefiniamo una funzione per simulare e visualizzare la distribuzione campionaria per diversi valori di \\(n\\):\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 1\n\n# Funzione per simulare e visualizzare la distribuzione campionaria\nplot_samples &lt;- function(n) {\n  # Media e deviazione standard della distribuzione Beta\n  mu &lt;- alpha / (alpha + beta)\n  sigma &lt;- sqrt(alpha * beta / ((alpha + beta)^2 * (alpha + beta + 1)))\n  \n  # Generazione di 50.000 campioni casuali di dimensione n\n  sample_means &lt;- replicate(50000, mean(rbeta(n, alpha, beta)))\n  \n  # Dati per la distribuzione normale teorica\n  x &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\n  y &lt;- dnorm(x, mean = mu, sd = sigma / sqrt(n))\n  \n  # Creazione del grafico\n  hist(\n    sample_means, \n    breaks = 50, \n    probability = TRUE, \n    main = paste(\"Ampiezza campionaria =\", n), \n    xlab = \"Media campionaria\", \n    ylab = \"Densità\"\n  )\n  lines(x, y, col = \"black\", lwd = 2)\n}\n\n\n\n46.5.2 Visualizzazione per diverse dimensioni campionarie\n\nAmpiezza campionaria \\(n = 1\\)\n\nSe \\(n = 1\\), la distribuzione campionaria delle medie coincide con la popolazione di partenza.\n\nplot_samples(1)\n\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 2\\)\n\nPer \\(n = 2\\), la distribuzione delle medie dei campioni inizia ad avvicinarsi alla normalità.\n\nplot_samples(2)\n\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 4\\)\n\nPer \\(n = 4\\), l’approssimazione alla distribuzione normale migliora.\n\nplot_samples(4)\n\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 30\\)\n\nPer \\(n = 30\\), la distribuzione campionaria delle medie è ben approssimata dalla normale.\n\nplot_samples(30)\n\n\n\n\n\n\n\n\nIn conclusione, il Teorema del Limite Centrale (TLC) afferma che, indipendentemente dalla forma della distribuzione della popolazione:\n\nPer campioni di dimensione sufficiente, la distribuzione campionaria delle medie \\(\\bar{X}\\) tende a una distribuzione normale.\nLa media \\(\\mu\\) e la deviazione standard \\(\\sigma\\) della popolazione determinano la distribuzione delle medie campionarie come segue:\n\\[\n\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma / \\sqrt{n}),\n\\]\ndove \\(n\\) è l’ampiezza del campione.\n\nQuesta proprietà ha implicazioni fondamentali:\n\nLa normalità emergente giustifica l’uso della distribuzione normale anche quando i dati non sono inizialmente normali.\nIl TLC fornisce una formula esplicita per calcolare l’errore standard \\(\\sigma / \\sqrt{n}\\), che quantifica la precisione della media campionaria come stima della media della popolazione.\n\n\n\n46.5.3 Applicazioni in psicologia\nMolti fenomeni psicologici che misuriamo (ad esempio, il QI come media di molte abilità cognitive) derivano dalla media di più variabili, e quindi seguono la distribuzione normale grazie al TLC. Questo spiega perché la distribuzione normale appare così frequentemente nei dati sperimentali di psicologia e in molte altre discipline scientifiche.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "46  Introduzione all’inferenza frequentista",
    "section": "46.6 Distribuzioni campionarie di altre statistiche",
    "text": "46.6 Distribuzioni campionarie di altre statistiche\nAbbiamo già analizzato la distribuzione campionaria della media dei campioni. Tuttavia, è possibile costruire distribuzioni campionarie per altre statistiche campionarie. Ad esempio, consideriamo la distribuzione campionaria del valore massimo e della varianza.\n\n46.6.1 Distribuzione campionaria del valore massimo\nSupponiamo di avere una popolazione normalmente distribuita con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Generiamo 10.000 campioni casuali di ampiezza \\(n = 5\\) e calcoliamo il valore massimo per ogni campione.\n\n46.6.1.1 Simulazione e visualizzazione\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\n\n# Simulazione: calcolo del valore massimo per ciascun campione\nn_samples &lt;- 10000\nsample_maxes &lt;- replicate(\n  n_samples, \n  max(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria del valore massimo\nhist(\n  sample_maxes, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria del valore massimo\",\n  xlab = \"Valore massimo\", \n  ylab = \"Densità\"\n)\n\n# Sovrapposizione della distribuzione normale della popolazione\ncurve(dnorm(x, mean = mu, sd = sigma), add = TRUE, col = \"black\", lwd = 2)\n\n\n\n\n\n\n\n\nOsserviamo che il valore atteso della distribuzione campionaria del massimo è maggiore della media della popolazione \\(\\mu\\).\n\n\n\n46.6.2 Distribuzione campionaria della varianza\nUn’altra statistica interessante è la varianza campionaria. La formula della varianza campionaria, basata sulla statistica descrittiva, è:\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nCalcoliamo la distribuzione campionaria della varianza per campioni di ampiezza \\(n = 5\\).\n\n46.6.2.1 Simulazione e visualizzazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza per ciascun campione\nsample_vars &lt;- replicate(\n  n_samples, \n  variance(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria della varianza\nhist(\n  sample_vars, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria della varianza\",\n  xlab = \"Varianza\", ylab = \"Densità\"\n)\n\n\n\n\n\n\n\n\n\n# Media empirica della varianza campionaria\nmean(sample_vars)\n#&gt; [1] 180.6569\n\nSappiamo che la varianza della popolazione è \\(\\sigma^2 = 15^2 = 225\\). Tuttavia, il valore medio empirico delle varianze campionarie calcolate con \\(S^2\\) risulta minore di 225. Questo avviene perché lo stimatore \\(S^2\\) è distorto.\n\n\n\n46.6.3 Correzione della distorsione\nPer eliminare la distorsione, utilizziamo il seguente stimatore della varianza della popolazione:\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n-1}.\n\\]\n\n46.6.3.1 Verifica con simulazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza con la correzione\nsample_vars_unbiased &lt;- replicate(\n  n_samples, \n  var(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria della varianza corretta\nhist(\n  sample_vars_unbiased, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria della varianza (corretta)\",\n  xlab = \"Varianza\", \n  ylab = \"Densità\"\n)\n\n\n\n\n\n\n\n\n\n# Media empirica della varianza corretta\nmean(sample_vars_unbiased)\n#&gt; [1] 225.8211\n\nCon questo stimatore, la media della distribuzione campionaria coincide con la varianza reale della popolazione \\(\\sigma^2 = 225\\).\nIn conclusione:\n\nLa distribuzione campionaria del massimo mostra che il valore massimo dei campioni è, in media, maggiore della media della popolazione.\nLa varianza campionaria non corretta (\\(S^2\\)) è uno stimatore distorto, poiché il suo valore atteso non coincide con la varianza della popolazione.\nLo stimatore corretto \\(s^2\\), che utilizza il divisore \\(n - 1\\), elimina la distorsione e fornisce una stima non distorta della varianza della popolazione.\n\nIn generale, uno stimatore è considerato non distorto quando il valore atteso delle sue stime coincide con il valore reale del parametro. Nel caso della media campionaria e della varianza corretta, entrambi gli stimatori sono non distorti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "title": "46  Introduzione all’inferenza frequentista",
    "section": "46.7 Riflessioni Conclusive",
    "text": "46.7 Riflessioni Conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell’inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\nÈ qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nSì, ma non è uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nSì, ma non è uguale a \\(\\sigma^2\\)\n\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione è la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione è:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "46  Introduzione all’inferenza frequentista",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "title": "46  Introduzione all’inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nIn psicologia, nelle scienze sociali e in altre discipline è in corso una Riforma Metodologica, scaturita da una profonda crisi che ha colpito la scienza contemporanea: la crisi di replicazione dei risultati delle ricerche. Un esempio emblematico è rappresentato dal sito Retraction Watch, che monitora le ritrattazioni di studi scientifici. Questa crisi mina la credibilità della ricerca scientifica e ha spinto a una revisione radicale delle metodologie alla base delle scienze psicologiche e di altre discipline affini (Korbmacher et al., 2023). Le cause della crisi di replicazione sono molteplici: frodi, pratiche di ricerca scorrette e incentivi distorti offerti dal sistema accademico. Una delle cause più rilevanti per un corso sull’analisi dei dati psicologici è l’uso delle tecniche inferenziali di stampo frequentista, che ha contribuito alla proliferazione di pubblicazioni contenenti falsi positivi.\nUn articolo di Altmejd et al. (2019) identifica alcuni fattori semplici ma altamente predittivi della replicabilità degli studi: il campione era di dimensioni adeguate? I ricercatori hanno ottenuto un risultato appena sotto la soglia di significatività di p = 0.05? (Spesso un articolo può rivendicare un risultato “significativo” se questa soglia viene raggiunta, e molti utilizzano vari trucchi statistici per superare tale limite.) Lo studio ha rilevato un effetto sull’intera popolazione studiata o ha individuato un “effetto di interazione” (ad esempio, un effetto presente solo in un segmento più piccolo della popolazione), che è molto meno probabile che si riproduca?\nÈ emerso inoltre che prevedere la replicazione di uno studio è sorprendentemente semplice. Non è necessario un approfondimento della metodologia statistica né un esame rigoroso dei dati, né tantomeno una scrupolosa analisi delle teorie più esoteriche per individuare errori sottili: questi articoli presentano problemi evidenti, a livello superficiale. Uno studio pubblicato su Nature ha coinvolto scienziati in una scommessa su quali studi di scienze sociali sarebbero stati replicati. Camerer et al. (2018) ha scoperto che le previsioni degli scienziati in questo mercato delle scommesse erano estremamente accurate nel determinare quali articoli avrebbero avuto successo nella replicazione.\nUlteriori ricerche hanno dimostrato che non è nemmeno necessario consultare esperti del settore per indovinare quali studi resisteranno a un esame rigoroso. Uno studio di Hoogeveen et al. (2020) ha coinvolto partecipanti senza un background professionale nelle scienze sociali, chiedendo loro di leggere articoli di psicologia e prevedere se questi si sarebbero replicati. “I non-esperti senza una formazione professionale nelle scienze sociali sono in grado di prevedere la replicabilità degli studi con una precisione superiore al caso,” conclude lo studio, “basandosi esclusivamente su semplici descrizioni verbali degli studi.”\nSebbene i non esperti non siano stati altrettanto precisi nelle loro previsioni rispetto agli scienziati nello studio pubblicato su Nature, il fatto che siano comunque riusciti a individuare molte replicazioni fallite suggerisce che molti di questi studi presentano difetti evidenti, riconoscibili anche da chi non è un addetto ai lavori.\nLa pubblicazione di un articolo peer-reviewed non rappresenta l’ultimo passo del processo scientifico. Dopo la pubblicazione, altri studi potrebbero citare l’articolo originale, diffondendo eventuali errori o fraintendimenti. Uno studio di Yang et al. (2020) mostra che non esiste alcuna correlazione tra la replicabilità di uno studio e la sua frequenza di citazione. “Gli studi falliti si diffondono nella letteratura scientifica con la stessa rapidità degli studi replicabili,” affermano Yang et al. (2020). Questo solleva una domanda: se gli scienziati sono abbastanza bravi nel prevedere se uno studio si replicherà, perché sono altrettanto inclini a citare studi non replicabili quanto quelli validi?\nQueste considerazioni suggeriscono che la crisi di replicazione non richiede solo una revisione metodologica, ma è il sintomo di un sistema scientifico che necessita di un ripensamento più ampio. Le riviste scientifiche non sono sufficientemente responsabili per la pubblicazione di articoli discutibili, e il sistema accademico promuove incentivi distorti. In alcuni casi, la cultura accademica sembra addirittura incentivare la produzione di ricerche di bassa qualità. La pressione a pubblicare un elevato numero di articoli favorisce chi riesce a farlo rapidamente, spesso ricorrendo a “scorciatoie”. Di conseguenza, si è creato un sistema in cui gli incentivi continuano a promuovere la cattiva ricerca, nonostante si comprenda sempre meglio cosa costituisca una ricerca di qualità.\nIn questa sezione della dispensa, ci concentreremo su uno dei problemi che stanno alla base della crisi della riproducibilità dei risultati della ricerca, ovvero i limiti dell’inferenza frequentista (Baker, 2016). Analizzeremo gli errori di tipo S e di tipo M, concetti introdotti da Gelman & Carlin (2014), che hanno contribuito a migliorare la comprensione dei limiti della statistica frequentista. Inoltre, discuteremo alcuni possibili metodi per affrontare la crisi e le implicazioni che derivano dall’integrità della ricerca.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Altmejd, A., Dreber, A., Forsell, E., Huber, J., Imai, T., Johannesson, M., Kirchler, M., Nave, G., & Camerer, C. (2019). Predicting the replicability of social science lab experiments. PloS one, 14(12), e0225826.\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nCamerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., et al. (2018). Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015. Nature human behaviour, 2(9), 637–644.\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nHoogeveen, S., Sarafoglou, A., & Wagenmakers, E.-J. (2020). Laypeople can predict which social-science studies will be replicated successfully. Advances in Methods and Practices in Psychological Science, 3(3), 267–285.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nYang, Y., Youyou, W., & Uzzi, B. (2020). Estimating the deep replicability of scientific findings using human and artificial intelligence. Proceedings of the National Academy of Sciences, 117(20), 10762–10768.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html",
    "title": "47  Limiti dell’inferenza frequentista",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nIn questa sezione della dispensa abbiamo esaminato il metodo “tradizionale” per il test di significatività dell’ipotesi nulla (NHST). Comprendere la logica alla base dell’approccio NHST è essenziale poiché questo è stato l’approccio predominante alla statistica inferenziale fin dalla sua introduzione all’inizio del XX secolo e la maggior parte dei ricercatori ancora si affida a questa procedura per analizzare i dati. Tuttavia, recentemente, l’approccio NHST è stato oggetto di aspre critiche, poiché molti ricercatori hanno iniziato a pensare che questo approccio possa creare più problemi di quanti ne risolva. Pertanto, è importante conoscere le critiche mosse alla procedura inferenziale NHST all’interno della comunità scientifica. In questa sezione esamineremo alcuni dei dubbi sorti riguardo a questo approccio.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "47  Limiti dell’inferenza frequentista",
    "section": "47.1 L’uso del valore-\\(p\\) nel mondo della ricerca",
    "text": "47.1 L’uso del valore-\\(p\\) nel mondo della ricerca\nNel suo articolo “Statistical Errors” (2014), Nuzzo evidenzia i limiti dell’approccio NHST nella pratica scientifica Nuzzo (2014). Infatti, sebbene il valore-\\(p\\) sia stato introdotto da Ronald Fisher negli anni ’20, egli non lo ha mai concepito come un test formale. Invece, Fisher lo considerava uno strumento informale per valutare se l’evidenza empirica fosse significativa in un senso colloquiale, ovvero meritevole di attenzione. In pratica, Fisher suggeriva di assumere un’ipotesi nulla e di calcolare la probabilità di osservare un risultato altrettanto estremo o più estremo di quello trovato, se il risultato fosse completamente dovuto alla sola variabilità campionaria. Sebbene sia possibile calcolare il valore-\\(p\\) tramite una procedura matematica, per Fisher esso era solo uno strumento da utilizzare all’interno di un processo decisionale non numerico, in grado di combinare le evidenze empiriche attuali con le conoscenze pregresse del ricercatore. In altre parole, il valore-\\(p\\) rappresentava uno strumento da utilizzare all’interno del processo decisionale, non la conclusione del processo decisionale stesso.\nVerso la fine degli anni ’20, Jerzy Neyman e Egon Pearson, rivali di Fisher, formalizzarono le procedure di decisione statistica con l’obiettivo di renderle “rigorose e oggettive”. In particolare, introdussero i concetti di potere statistico e di falso positivo, ma non utilizzarono la nozione di valore-\\(p\\) come aveva fatto Fisher.\nLe divergenze tra i tre autori portarono a un acceso dibattito, in cui Neyman criticò il lavoro di Fisher come matematicamente “peggiore dell’inutilità”, mentre Fisher definì l’approccio di Neyman “infantile” e “orribile per la libertà intellettuale dell’occidente”.\nDurante questo dibattito, altri autori iniziarono a scrivere manuali di statistica per fornire uno strumento di lavoro ai ricercatori. Poiché molti di questi autori non erano statistici e avevano solo una comprensione superficiale della distinzione tra i vari approcci, crearono un sistema ibrido che utilizzava il valore-\\(p\\) proposto da Fisher all’interno del “sistema rigoroso” proposto da Neyman e Pearson. È in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne definita come “statisticamente significativa”.\nTuttavia, dal punto di vista storico, il valore-\\(p\\) proposto da Fisher aveva un significato molto diverso da quello che viene attribuito oggi nel mondo della ricerca. Come abbiamo visto, il valore-\\(p\\) era solo uno strumento informale utilizzato da Fisher all’interno di un processo decisionale più ampio, e il suo uso all’interno del sistema ibrido creato dai manuali di statistica era privo di giustificazione e fondamento.\nNel 2016 l’American Statistical Association ha pubblicato un articolo nel quale si esprime una grande preoccupazione per l’uso inappropriato che viene fatto del valore-\\(p\\) nella pratica scientifica odierna Wasserstein & Lazar (2016):\n\n\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\nL’articolo prosegue affermando che:\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical “bright-line” rules (such as “\\(p &lt; 0.05\\)”) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‘true’ on one side of the divide and ‘false’ on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‘yes-no’ decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of “statistical significance” (generally interpreted as ) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "title": "47  Limiti dell’inferenza frequentista",
    "section": "47.2 \\(P\\)-hacking",
    "text": "47.2 \\(P\\)-hacking\nLa pratica del \\(P\\)-hacking rappresenta la principale fallacia associata all’utilizzo del valore-\\(p\\) ed è nota anche come “\\(P\\)-hacking”, “data-dredging”, “snooping”, “fishing”, “significance-chasing” o “double-dipping”. Secondo Uri Simonsohn, docente presso l’Università della Pennsylvania, il \\(P\\)-hacking consiste nel tentativo di provare diverse ipotesi finché non si ottiene il risultato desiderato. Ad esempio, si potrebbe dire: “Quel risultato sembra essere stato ottenuto attraverso il \\(p\\)-hacking, gli autori hanno eliminato una delle condizioni in modo che il valore-\\(p\\) complessivo fosse inferiore a 0.05” oppure “Lei è una \\(p\\)-hacker, controlla sempre i dati mentre vengono raccolti”.\nQuesta pratica ha l’effetto di trasformare uno studio esplorativo, che dovrebbe essere sempre interpretato con cautela, in uno studio (apparentemente) confermativo, il cui risultato appare “robusto”, ma che in realtà ha una probabilità pressoché nulla di essere replicato in studi successivi. Secondo le simulazioni di Simonsohn, il cambiamento di poche decisioni nel processo di analisi dei dati può aumentare fino al 60% il tasso di falsi positivi in un singolo studio.\nIl \\(P\\)-hacking è diffuso soprattutto negli studi che tentano di dimostrare piccoli effetti usando dati molto rumorosi. Un’analisi della letteratura psicologica ha mostrato che i valori-\\(p\\) riportati dagli psicologi tendono a concentrarsi su valori appena superiori alla soglia minima dello 0.05. Questo risultato può essere interpretato come conseguenza della pratica del \\(P\\)-hacking: i ricercatori eseguono molteplici test statistici fino a trovare uno che risulta “statisticamente significativo” e poi riportano solo quello. Come mostra la figura seguente, questa pratica non riguarda solo la psicologia, ma è diffusa in tutti i campi della ricerca scientifica.\n\n\n\nDistribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "title": "47  Limiti dell’inferenza frequentista",
    "section": "47.3 Critiche al valore-\\(p\\)",
    "text": "47.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) è stato paragonato a creature noiose e ostinate come le zanzare, ai vestiti nuovi dell’imperatore, ovvero alla tendenza di non voler riconoscere evidenti problemi, ma preferire di far finta di nulla, o ad un intellectual rake sterile, che non porta alcun frutto. Si è anche ironizzato sul fatto che la procedura di statistical hypothesis inference testing venga chiamata così solo per l’acronimo che produce.\nIl valore-\\(p\\) incoraggia un modo di pensare errato, spostando l’attenzione dal problema centrale della ricerca, ovvero la forza della manipolazione sperimentale, alla dimostrazione di una falsa ipotesi che si sa a priori essere falsa (l’ipotesi nulla). Ad esempio, uno studio con più di 19.000 individui ha dimostrato che coloro che incontrano il loro partner online hanno una probabilità minore di divorziare (\\(p &lt;\\) 0,002) e sono più soddisfatti della loro vita matrimoniale (\\(p &lt;\\) 0,001) rispetto a chi non si è conosciuto online. Questo può sembrare un risultato interessante, ma senza considerare la dimensione dell’effetto, ovvero il tasso di divorzio che scende dal 7.67% al 5.96% e l’aumento dell’indice di soddisfazione matrimoniale da 5.48 a 5.64 su una scala a sette punti, il risultato perde di interesse. In generale, la domanda cruciale non è “c’è un effetto o no?” ma piuttosto “qual è la dimensione dell’effetto?”.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "title": "47  Limiti dell’inferenza frequentista",
    "section": "47.4 L’effetto sperimentale è esattamente nullo?",
    "text": "47.4 L’effetto sperimentale è esattamente nullo?\nUna delle critiche più frequenti alla logica di verifica delle ipotesi statistiche riguarda l’assunzione irrealistica che l’effetto della manipolazione sperimentale sia “esattamente” nullo. Ad esempio, la fisica ci insegna che lo spostamento di un grammo di massa in una stella distante qualche anno luce dalla Terra può influenzare il movimento delle molecole di un gas sulla Terra Borel (1914). Questo ci suggerisce che ogni manipolazione sperimentale produca, in qualche modo, un effetto. Pertanto, secondo Andrew Gelman, il problema non è dimostrare falsa l’ipotesi nulla, ovvero che la manipolazione sperimentale non produca alcun effetto, ma piuttosto valutare se la dimensione dell’effetto è sufficientemente grande da avere un impatto pratico e se l’effetto sia riproducibile. In questo senso, la logica di verifica dell’ipotesi nulla può essere problematica, soprattutto quando si lavora con piccoli campioni e piccoli effetti, come nella maggior parte degli studi in psicologia, poiché può portare ad una sovrastima della dimensione dell’effetto e ad una visione binaria del risultato (vero/falso), invece di concentrarsi sulla stima non distorta della dimensione effettiva dell’effetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "title": "47  Limiti dell’inferenza frequentista",
    "section": "47.5 Attenti al valore-\\(p\\)!",
    "text": "47.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema. Eseguiamo un \\(t\\)-test per due campioni indipendenti e sottoponiamo a verifica l’ipotesi nulla dell’eguaglianza delle due medie. Sia \\(\\alpha = 0.05\\). Otteniamo un valore-\\(p\\) di \\(0.04\\). Qual è la probabilità che i due campioni siano tratti da distribuzioni con la stessa media?\n\n\\(19/20; \\quad\\) (b) \\(1/19; \\quad\\) (c) \\(1/20; \\quad\\) (d) \\(95/100; \\quad\\) (e) sconosciuta.\n\nLa risposta corretta è: (e) sconosciuta. La statistica frequentista definisce le probabilità dei dati condizionatamente alle ipotesi (assunte come vere). Non consente di stabilire la probabilità di un’ipotesi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "title": "47  Limiti dell’inferenza frequentista",
    "section": "47.6 La crisi della riprodicibilità dei risultati della ricerca",
    "text": "47.6 La crisi della riprodicibilità dei risultati della ricerca\nNegli ultimi anni, la mancanza di replicabilità dei risultati della ricerca - inclusa la ricerca psicologica - è diventata un tema di grande rilevanza. In questo contesto, è stato evidenziato che alcuni aspetti del metodo scientifico, in particolare il concetto di valore-p e la pratica di verificare la significatività dell’ipotesi nulla (NHST, Null Hypothesis Significance Testing), potrebbero contribuire a questa “crisi della ricerca scientifica”. Un’analisi più approfondita di questo problema è stata fornita da Gelman (2016), il quale sostiene che la pratica della NHST sia intrinsecamente problematica. Infatti, essa incoraggia il ricercatore a cercare di rigettare un’ipotesi “fantoccio” (straw-man) che è certamente falsa a priori o, almeno, poco interessante dal punto di vista scientifico, a favore di un’ipotesi alternativa che il ricercatore preferisce. In generale, sembra più ragionevole affermare che la differenza tra due condizioni sia molto piccola, piuttosto che affermare che sia esattamente uguale a zero.\nSpesso nei libri di statistica viene trasmesso il messaggio che la NHST sia una forma di “alchimia” che cerca di trasformare la casualità in una sorta di certezza, con l’uso di termini come “confidenza” e “significatività” Gelman (2016). Il processo di raccolta dei dati, analisi e inferenza statistica che ne segue viene poi riassunto in una conclusione espressa in termini di valore-p e di intervallo di confidenza che escludono lo zero. Tuttavia, ciò può dare l’impressione errata che il ricercatore abbia una comprensione completa delle proprietà del fenomeno in questione. Il problema principale della NHST è che spesso produce risultati “statisticamente significativi” in situazioni in cui le caratteristiche del fenomeno non giustificano la conclusione a cui il ricercatore arriva. Questo può portare alla non replicabilità dei risultati della ricerca.\nLa comunità degli statistici ha evidenziato come la non replicabilità dei risultati delle ricerche sia particolarmente evidente quando i ricercatori, utilizzando la metodologia NHST, giungono a conclusioni errate basate sull’osservazione di piccoli campioni con effetti di dimensioni ridotte. Queste condizioni, insieme ad altre, rendono estremamente problematica l’applicazione della NHST. Purtroppo, queste situazioni descrivono molte delle ricerche recenti in psicologia.\nLa statistica è stata definita come un metodo per prendere decisioni razionali in situazioni di incertezza. Gli statistici consigliano ai ricercatori di non solo diventare esperti nelle tecniche statistiche, ma anche di imparare a convivere con l’incertezza, nonostante la sempre crescente sofisticazione delle tecniche disponibili. Convivere con l’incertezza implica evitare di pensare che ottenere un valore-\\(p\\) “statisticamente significativo” significhi risolvere un problema scientifico. Come possiamo allora avere fiducia in ciò che abbiamo appreso dai dati? Una possibile strategia è la replicazione e la convalida esterna, ma nella ricerca in psicologia e nelle scienze sociali, questo può spesso essere difficile da perseguire a causa degli oneri elevati che comporta. Il problema di quali strumenti metodologici e metodi statistici siano più appropriati per indagare sui fenomeni psicologici, senza essere ingannati, rimane dunque un problema aperto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "title": "47  Limiti dell’inferenza frequentista",
    "section": "47.7 Commenti e considerazioni finali",
    "text": "47.7 Commenti e considerazioni finali\nNon possiamo concludere senza sottolineare la controversia che circonda la nozione di valore-\\(p\\). Pur essendo ancora ampiamente utilizzato e spesso interpretato erroneamente, il valore-\\(p\\) conferisce solo una patina di legittimità ai risultati di studi dubbi, incoraggia cattive pratiche di ricerca e promuove la produzione di falsi positivi. Inoltre, è difficile comprendere appieno il significato di questa nozione. Anche gli esperti, quando chiamati a fornire una definizione di valore-\\(p\\), spesso sbagliano la risposta. Ciò che i ricercatori vogliono sapere è se i risultati della ricerca sono corretti o meno, ma il valore-\\(p\\) non fornisce questa informazione. Non dice nulla sulla dimensione dell’effetto, sulla forza dell’evidenza o sulla probabilità che il risultato sia stato ottenuto casualmente. Quindi, qual è il suo significato? Stuart Buck risponde così:\n\nImagine that you have a coin that you suspect is weighted toward heads. (Your null hypothesis is then that the coin is fair.) You flip it 100 times and get more heads than tails. The \\(p\\)-value won’t tell you whether the coin is fair, but it will tell you the probability that you’d get at least as many heads as you did if the coin was fair. That’s it – nothing more.\n\nIn sintesi, possiamo concludere che il valore-\\(p\\) risponde a una domanda molto specifica che non ha alcuna rilevanza per la validità scientifica dei risultati della ricerca. In un’epoca in cui la crisi della riproducibilità dei risultati è sempre più evidente Baker (2016), il test dell’ipotesi nulla e gli intervalli di confidenza frequentisti sono stati identificati come una delle principali cause del problema, spingendo molti ricercatori a cercare soluzioni alternative.\n\n\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nBorel, E. (1914). Introduction Géométrique. G. Villars, New York.\n\n\nGelman, A. (2016). Commentary on «Crisis in Science? Or Crisis in Statistics! Mixed Messages in Statistics with Impact on Science». Journal of Statistical Research, 48-50(1), 11–12.\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nNuzzo, R. (2014). Statistical Errors. Nature, 506(7487), 150–152.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html",
    "href": "chapters/epiloque/epiloque.html",
    "title": "Considerazioni Conclusive",
    "section": "",
    "text": "Limiti dell’Inferenza Frequentista\nL’inferenza bayesiana offre un modo rigoroso e trasparente per integrare conoscenze pregresse e dati empirici nell’analisi psicologica. A differenza degli approcci frequentisti, l’approccio bayesiano ci permette di quantificare l’incertezza e di costruire modelli che riflettono le nostre aspettative a priori. Questa flessibilità è particolarmente utile in psicologia, dove le teorie e le ipotesi giocano un ruolo fondamentale nella guida della ricerca. L’approccio bayesiano rende esplicita la nostra assunzione iniziale e ci permette di valutare l’impatto dei dati sulla nostra comprensione dei fenomeni psicologici.\nNel corso di questa trattazione, abbiamo esaminato i limiti dell’inferenza frequentista, in particolare quando viene impiegata come “filtro” per distinguere i risultati scientifici rilevanti da quelli trascurabili. L’eccessiva dipendenza dai valori-p è stata oggetto di critiche per la sua associazione con inferenze inadeguate; gli effetti possono essere notevolmente sovrastimati, talvolta persino nella direzione errata, quando la stima è vincolata alla significatività statistica in presenza di dati altamente variabili (Loken & Gelman, 2017).\nLa persistenza e la resistenza del valore-p come indicatore di significatività sono sorprendenti, nonostante le critiche di lunga data e i dibattiti sul suo uso improprio e sulla sua errata interpretazione (Gardner e Altman, 1986; Cohen, 1994; Anderson et al., 2000; Fidler et al., 2004; Finch et al., 2004). Il continuo uso di questa tenacia può offrire spunti su come tali indici, insieme alle euristiche utilizzate per interpretarli (ad esempio, l’assegnazione di soglie come 0.05, 0.01 e 0.001 per determinati livelli di significatività), siano adottati dai ricercatori per ottenere una comprensione intuitiva, sebbene eccessivamente semplificata, della struttura dei loro dati. Inoltre, l’uso di un simile indice risulta particolarmente rilevante in contesti che richiedono decisioni e relative giustificazioni (ad esempio, in ambito medico).\nPurtroppo, queste euristiche sono diventate estremamente rigide, e il raggiungimento della significatività si è trasformato in un obiettivo fine a se stesso, piuttosto che in uno strumento per comprendere i dati (Cohen, 1994; Kirk, 1996). Ciò è particolarmente problematico considerando che i valori-p possono essere utilizzati solo per rifiutare l’ipotesi nulla e non per accettarla come vera, poiché un risultato statisticamente non significativo non implica l’assenza di differenze tra gruppi o l’assenza di un effetto di un trattamento (Wagenmakers, 2007; Amrhein et al., 2019).\nI fraintendimenti e l’uso improprio dei valori-p, il cosiddetto “p-hacking” (Simmons et al., 2011), hanno incentivato pratiche scientifiche discutibili, contribuendo in modo rilevante alla crisi di riproducibilità nella scienza psicologica (Chambers et al., 2014; Szucs e Ioannidis, 2016).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "href": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "title": "Considerazioni Conclusive",
    "section": "La Crisi della Replicabilità",
    "text": "La Crisi della Replicabilità\nLa crisi della replicabilità rappresenta una sfida non solo per la ricerca psicologica, ma anche per l’applicazione pratica delle sue teorie. Quando i risultati degli studi non possono essere replicati in contesti diversi, si mette in dubbio la validità e l’affidabilità delle teorie psicologiche su cui si basano gli interventi clinici e le politiche pubbliche. Questo non solo mina la fiducia nella scienza psicologica, ma limita anche la capacità dei professionisti di sviluppare trattamenti efficaci e basati sull’evidenza. Pertanto, è fondamentale che la comunità scientifica adotti pratiche di ricerca rigorose e trasparenti per garantire che le scoperte siano replicabili e applicabili nel mondo reale.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#come-uscirne",
    "href": "chapters/epiloque/epiloque.html#come-uscirne",
    "title": "Considerazioni Conclusive",
    "section": "Come uscirne?",
    "text": "Come uscirne?\nL’abbandono dell’inferenza frequentista a favore dei metodi bayesiani, per ragioni quali la maggiore flessibilità, una migliore accuratezza in presenza di dati rumorosi e campioni piccoli, una minore predisposizione agli errori di tipo I, la possibilità di incorporare conoscenze pregresse nell’analisi e la chiarezza e facilità di interpretazione dei risultati (Kruschke, 2010; Kruschke et al., 2012; Etz e Vandekerckhove, 2016; Wagenmakers et al., 2016, 2018; Dienes e Mclatchie, 2018), è una delle strategie proposte per affrontare la crisi della replicabilità nella ricerca psicologica. Tuttavia, sebbene questo cambiamento sia rilevante, non è sufficiente da solo. I problemi più profondi derivano anche da un sistema accademico caratterizzato da incentivi distorti, come la pressione a pubblicare risultati significativi, e dalla riluttanza delle riviste scientifiche a riconoscere e affrontare casi di frode o a ritirare articoli quando necessario.\nUna proposta su cui insiste molto McElreath (2020) è quella di passare da un approccio descrittivo della relazione tra variabili — tipico dei modelli lineari e dei modelli lineari generalizzati — a una prospettiva che miri a descrivere formalmente il meccanismo generatore dei dati sottostante al fenomeno in esame. In questo contesto, il ricercatore dovrebbe formulare ipotesi esplicite sul processo che genera i dati e fornire un test quantitativo di tali ipotesi. Questo approccio porta naturalmente alla pratica del confronto tra modelli, un metodo che abbiamo discusso in diversi capitoli di questo testo. Tale confronto può essere effettuato utilizzando tecniche come la validazione incrociata bayesiana Leave-One-Out (LOO), che permette di valutare la robustezza dei modelli e la loro capacità di generalizzare a nuovi dati. Ma si tengano anche a mente i limiti di tale approccio (Navarro, 2019).\nUn altro approccio attuale per superare la cosiddetta “junk science” (Calin-Jageman & Caldwell, 2014; Gelman & Weakliem, 2009; Jung et al., 2014), che troppo spesso affligge la psicologia e non solo, è la “rivoluzione causale”. Questo movimento si concentra sul tentativo di comprendere e identificare le relazioni causali in contesti naturali, superando l’arbitrarietà e l’artificialità degli esperimenti di laboratorio tradizionali. La “rivoluzione causale” ha molto in comune con l’approccio di McElreath (2020), poiché anche qui si richiede ai ricercatori di formulare ipotesi causali in maniera esplicita e di confrontare modelli alternativi che rappresentano diverse ipotesi sui rapporti causali. Questo approccio non solo migliora la comprensione dei fenomeni studiati, ma aumenta anche la credibilità e la replicabilità dei risultati scientifici.\nQuesti cambiamenti prevedono anche una profonda revisione dei metodi didattici e dei programmi dei corsi, in cui si insegna agli studenti come formulare inferenze basate sui dati empirici raccolti in psicologia. Questo tema è stato approfondito da studiosi come Mine Dogucu [Johnson et al. (2022); dogucu2022current; rosenberg2022making; dogucu2021web]. Come dovrebbe ormai essere evidente al lettore, il presente testo ha accettato questa sfida.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#conclusioni",
    "href": "chapters/epiloque/epiloque.html#conclusioni",
    "title": "Considerazioni Conclusive",
    "section": "Conclusioni",
    "text": "Conclusioni\nL’approccio bayesiano rappresenta una risorsa fondamentale per l’analisi dei dati psicologici, offrendo strumenti avanzati per gestire l’incertezza, integrare conoscenze pregresse e adattarsi a modelli complessi. La sua capacità di fornire previsioni robuste e aggiornare continuamente le ipotesi alla luce di nuovi dati lo rende particolarmente adatto per esplorare e comprendere la mente umana e il comportamento in tutte le loro sfaccettature.\nTuttavia, per affrontare la crisi della replicabilità e migliorare la qualità della ricerca scientifica in psicologia, non è sufficiente adottare esclusivamente metodi bayesiani. È essenziale combinare questi metodi con altre pratiche rigorose e principi metodologici solidi. Tra queste pratiche, la formalizzazione dei modelli generativi consente di descrivere chiaramente i processi sottostanti che generano i dati, migliorando la trasparenza e la validità delle inferenze. Inoltre, il confronto rigoroso tra modelli, ad esempio tramite tecniche di validazione incrociata, aiuta a determinare quale modello meglio rappresenta i dati e a evitare interpretazioni errate.\nInfine, l’adozione di una prospettiva causale esplicita è cruciale per identificare correttamente le relazioni di causa-effetto, evitando l’arbitrarietà e l’artificialità degli esperimenti tradizionali. Solo attraverso un approccio integrato, che combini l’inferenza bayesiana con queste pratiche metodologiche avanzate, sarà possibile progredire verso una scienza psicologica più affidabile e riproducibile, capace di fornire una comprensione più profonda e accurata del comportamento umano.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#bibliografia",
    "href": "chapters/epiloque/epiloque.html#bibliografia",
    "title": "Considerazioni Conclusive",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCalin-Jageman, R. J., & Caldwell, T. L. (2014). Replication of the superstition and performance study by Damisch, Stoberock, and Mussweiler (2010). Social Psychology.\n\n\nGelman, A., & Weakliem, D. (2009). Of beauty, sex and power: Too little attention has been paid to the statistical challenges in estimating small effects. American Scientist, 97(4), 310–316.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nJung, K., Shavitt, S., Viswanathan, M., & Hilbe, J. M. (2014). Female hurricanes are deadlier than male hurricanes. Proceedings of the National Academy of Sciences, 111(24), 8782–8787.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNavarro, D. J. (2019). Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection. Computational Brain & Behavior, 2(1), 28–34.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html",
    "href": "chapters/frequentist_inference/02_conf_interv.html",
    "title": "47  Intervallo di confidenza",
    "section": "",
    "text": "47.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nGli intervalli di confidenza sono uno strumento fondamentale nell’inferenza statistica frequentista. Essi consentono di stimare un parametro sconosciuto di una popolazione, come la media \\(\\mu\\), tenendo conto dell’incertezza derivante dal fatto che la stima si basa su un campione. Questo materiale didattico si propone di spiegare in modo dettagliato e chiaro la costruzione di un intervallo di confidenza per la media di una popolazione, sia nel caso di varianza nota sia in quello di varianza incognita.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-lintervallo-di-confidenza",
    "href": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-lintervallo-di-confidenza",
    "title": "47  Intervallo di confidenza",
    "section": "47.2 Inferenza Statistica Frequentista: L’Intervallo di Confidenza",
    "text": "47.2 Inferenza Statistica Frequentista: L’Intervallo di Confidenza\nL’intervallo di confidenza è un concetto fondamentale nell’approccio frequentista alla statistica. Questo strumento è impiegato per valutare la variabilità della stima di un parametro di interesse all’interno di una popolazione, partendo da un campione di essa.\nAl centro di questo metodo si trova l’errore standard, che misura la deviazione standard della distribuzione campionaria di uno stimatore. Questo indice quantifica quanto la stima del parametro si discosta, in media, dal valore effettivo del parametro nella popolazione. Gli statistici frequentisti sfruttano l’errore standard per definire l’intervallo di confidenza, che rappresenta un intervallo di valori entro cui si ritiene si trovi il vero valore del parametro, come ad esempio la media della popolazione.\nPer comprendere l’intervallo di confidenza da una prospettiva frequentista è essenziale il concetto di “procedura di stima”. In base a questo approccio, l’intervallo di confidenza viene costruito in modo che, se la medesima procedura fosse ripetuta su diversi campioni della stessa popolazione, una determinata percentuale degli intervalli di confidenza (ad esempio, il 95%) includerebbe il vero valore del parametro della popolazione.\nIn terminologia frequentista, quindi, non si afferma che un dato intervallo di confidenza possieda una probabilità del 95% di contenere il vero valore del parametro. Piuttosto, si sostiene che, seguendo lo stesso metodo di stima, il 95% degli intervalli di confidenza derivati da campioni differenti racchiuderebbe il vero valore del parametro.\nIn questo quadro, l’intervallo di confidenza non è una dichiarazione sulla probabilità che un particolare intervallo includa il valore del parametro, ma piuttosto un’affermazione sulla regolarità con cui gli intervalli calcolati in un determinato modo riescono a catturare il valore del parametro quando si ripete il medesimo processo su vari campioni. Questa distinzione è cruciale per una corretta comprensione dell’approccio frequentista all’inferenza statistica.\nMentre quest’interpretazione dell’intervallo di confidenza può apparire controintuitiva e talvolta poco pratica, riflette il contrasto con l’approccio bayesiano, il quale enfatizza l’aggiornamento delle probabilità sulla base di nuove informazioni, a differenza dell’approccio frequentista, che si basa sulla ripetizione degli esperimenti e sulla valutazione della variabilità campionaria.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#determinazione-dellintervallo-di-confidenza-per-una-media",
    "href": "chapters/frequentist_inference/02_conf_interv.html#determinazione-dellintervallo-di-confidenza-per-una-media",
    "title": "47  Intervallo di confidenza",
    "section": "47.3 Determinazione dell’intervallo di Confidenza per una Media",
    "text": "47.3 Determinazione dell’intervallo di Confidenza per una Media\nNei casi in cui la distribuzione delle statistiche campionarie si avvicina a una distribuzione Normale, l’intervallo di confidenza al 95% è calcolato come:\n\\[\n\\hat{\\theta} \\pm 1.96 \\cdot \\text{SE},\n\\]\ndove \\(\\hat{\\theta}\\) rappresenta la stima del parametro e SE l’errore standard.\n\n47.3.1 Derivazione dell’Intervallo di Confidenza per una Popolazione Normale con Varianza Nota\nConsideriamo una popolazione che segue una distribuzione normale con una media nota \\(\\mu\\) e varianza \\(\\sigma^2\\). Prendiamo un campione casuale di dimensione \\(n\\) da questa popolazione, indicato come \\(X_1, X_2, \\dots, X_n\\). Grazie alle proprietà delle distribuzioni normali, la media campionaria \\(\\bar{X}\\) segue anch’essa una distribuzione normale, nello specifico \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma^2/n)\\).\nPasso 1: Standardizzazione della Media Campionaria\nPer standardizzare la media campionaria in una variabile distribuita normalmente standard, sottraiamo la media della popolazione \\(\\mu\\) e dividiamo per lo scarto standard della media campionaria \\(\\sigma/\\sqrt{n}\\). Ciò porta alla seguente trasformazione:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim \\mathcal{N}(0, 1).\n\\]\nPasso 2: Stabilire il Livello di Confidenza\nDefiniamo un livello di confidenza \\(\\gamma = 1 - \\alpha\\), ad esempio \\(\\gamma = 0.95\\) per un livello di confidenza del 95%.\nIdentifichiamo il valore critico \\(z\\), corrispondente al quantile \\((1 - \\alpha/2)\\) della distribuzione normale standard. Il valore \\(z\\) rappresenta il punto di taglio alle estremità della distribuzione:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nPasso 3: Formulazione dell’Intervallo di Confidenza\nCon il valore \\(z\\) definito, formuliamo l’intervallo di confidenza per la media della popolazione:\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\nPasso 4: Manipolazione Algebrica per Definire i Limiti\nRielaboriamo la disuguaglianza per esporre i limiti dell’intervallo di confidenza:\n\\[\n\\begin{align}\n  P\\bigg(-z \\leq &\\frac{ \\bar{X} - \\mu } {\\sigma} \\sqrt{n} \\leq z\\bigg) = \\gamma\\notag\\\\\n  P\\bigg(-z {\\frac{\\sigma}{\\sqrt{n}}} \\leq  &\\bar{X} - \\mu \\leq z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma\\notag\\\\\n  P\\bigg(-\\bar{X}-z {\\frac{\\sigma}{\\sqrt{n}}} \\leq &-\\mu \\leq -\\bar{X} + z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma\\notag\\\\\n  P\\bigg(\\bar{X}+z \\frac{\\sigma}{\\sqrt{n}} \\geq &\\mu \\geq  \\bar{X} -z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma.\\notag\n\\end{align}\n\\]\nPasso 5: Specificazione dei Limiti dell’Intervallo\nDefiniamo i limiti dell’intervallo di confidenza, \\(\\hat{a}\\) e \\(\\hat{b}\\), come segue:\n\\[\n\\hat{a} = \\bar{X} - z \\frac{\\sigma}{\\sqrt{n}},\n  \\quad \\hat{b} = \\bar{X} + z \\frac{\\sigma}{\\sqrt{n}},\n\\]\ncon \\(P(\\hat{a} \\leq \\mu \\leq \\hat{b}) = \\gamma\\).\nIn conclusione, l’intervallo di confidenza \\((\\hat{a}, \\hat{b})\\) racchiude il vero valore della media della popolazione \\(\\mu\\) con una probabilità \\(\\gamma\\).\n\n\n47.3.2 Stima dell’Intervallo di Confidenza per Popolazioni Normali con Varianza Incognita\nIn contesti reali, quando si preleva un campione \\(X_1, \\dots, X_n\\) da una popolazione, la varianza \\(\\sigma^2\\) della popolazione è spesso incognita. Questo aggiunge incertezza riguardo alla media della popolazione \\(\\mu\\), che è il parametro di interesse. In questi casi, si adotta la distribuzione t di Student per la stima dell’intervallo di confidenza della media \\(\\mu\\), a causa della varianza incognita.\nPasso 1: Impiego della Distribuzione t di Student\nApplichiamo la formula seguente per calcolare l’intervallo:\n\\[\nP\\left(−t^{\\ast} \\leq \\frac{\\bar{X} - \\mu}{s/\\sqrt{n}} \\leq t^{\\ast}\\right) = \\gamma,\n\\]\ndove \\(\\gamma = 1 - \\alpha\\) è il livello di confidenza, \\(s\\) è la stima della deviazione standard \\(\\sigma\\) della popolazione, e \\(t^{\\ast}\\) è il quantile di ordine \\(1 - \\alpha/2\\) della distribuzione t con \\(n−1\\) gradi di libertà.\nPasso 2: Determinazione dei Limiti dell’Intervallo di Confidenza\nCalcoliamo i limiti inferiore \\(\\hat{a}\\) e superiore \\(\\hat{b}\\) dell’intervallo di confidenza così:\n\\[\n\\hat{a} = \\bar{X} - t^{\\ast} \\frac{s}{\\sqrt{n}},\n  \\quad \\hat{b} = \\bar{X} + t^{\\ast} \\frac{s}{\\sqrt{n}}.\n\\]\nIn queste circostanze, si sostituisce la varianza sconosciuta \\(\\sigma^2\\) con la sua stima \\(s\\) e si utilizza la distribuzione t di Student invece della normale.\n\n\n47.3.3 Applicabilità e Limitazioni\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e è valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non è normalmente distribuita e la dimensione del campione è ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell’intervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "href": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "title": "47  Intervallo di confidenza",
    "section": "47.5 Livello di Copertura",
    "text": "47.5 Livello di Copertura\nPer interpretare correttamente gli intervalli di fiducia è fondamentale considerare il concetto di “livello di copertura”. Questo livello indica la frequenza con cui l’intervallo di fiducia include il valore reale del parametro della popolazione, in una serie di esperimenti ripetuti.\nEsempio di Livello di Copertura:\n\nSe il livello di copertura è del 95%, significa che, nel lungo periodo, il 95% degli intervalli di fiducia costruiti conterrà il valore vero del parametro.\nImportante: Questo non implica che ci sia una probabilità del 95% che il valore vero del parametro cada in un particolare intervallo di fiducia. Infatti, il parametro della popolazione è un valore fisso e non soggetto a probabilità; piuttosto, l’incertezza risiede nell’intervallo di fiducia stesso.\n\nCome Funziona la Copertura:\n\nNel contesto frequentista, la “probabilità” si riferisce alla frequenza a lungo termine di un certo evento in un gran numero di ripetizioni dell’esperimento.\nNel caso degli intervalli di fiducia, l’“esperimento” è l’estrazione di un campione dalla popolazione, e l’“evento” è la generazione di un intervallo di fiducia che contiene il valore vero del parametro.\nIl livello di copertura, generalmente indicato come \\(1-\\alpha\\), rappresenta la probabilità a lungo termine che intervalli di fiducia costruiti con questa metodologia includano il vero valore del parametro.\n\n\n47.5.1 Simulazione\n\nPer illustrare questo concetto, eseguiamo una simulazione con la popolazione degli adulti maschi italiani, assunta come normalmente distribuita con media 175 cm e varianza 49 cm².\nEseguiamo 1000 ripetizioni di un esperimento, estraendo ogni volta un campione di 30 individui.\nPer ciascun campione, calcoliamo l’intervallo di fiducia al 95% usando la formula:\n\n\\[\n\\bar{X} \\pm t \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) è la media campionaria, \\(s\\) è la deviazione standard campionaria e \\(t\\) è il valore critico della distribuzione t-Student per \\(n-1\\) gradi di libertà al livello di significatività \\(\\alpha/2 = 0.025\\). - Registriamo i limiti di ciascun intervallo e controlliamo quanti di essi includono effettivamente il vero valore medio della popolazione.\nAttraverso questa simulazione, possiamo visualizzare concretamente il concetto di livello di copertura e la sua importanza nella statistica frequentista.\nIn questa simulazione, genereremo 1000 campioni casuali di dimensione \\(n = 30\\) da una distribuzione normale con media \\(\\mu = 175\\) e deviazione standard \\(\\sigma = 7\\). Successivamente, calcoleremo gli intervalli di confidenza al 95% per ciascun campione e valuteremo il livello di copertura.\n\nset.seed(123)  # Per riproducibilità\n\n# Parametri della distribuzione\nmu &lt;- 175\nsigma &lt;- 7\nn &lt;- 30\nn_samples &lt;- 1000\n\n# Generazione dei campioni\nsamples &lt;- replicate(n_samples, rnorm(n, mean = mu, sd = sigma))\ndim(samples)  # Verifica dimensioni: 30 righe per 1000 colonne\n#&gt; [1]   30 1000\n\nIl primo campione di ampiezza \\(n = 30\\) che abbiamo ottenuto è il seguente:\n\nsamples[, 1]  # Primo campione\n#&gt;  [1] 171.0767 173.3888 185.9110 175.4936 175.9050 187.0055 178.2264 166.1446\n#&gt;  [9] 170.1920 171.8804 183.5686 177.5187 177.8054 175.7748 171.1091 187.5084\n#&gt; [17] 178.4850 161.2337 179.9095 171.6905 167.5252 173.4742 167.8180 169.8978\n#&gt; [25] 170.6247 163.1931 180.8645 176.0736 167.0330 183.7767\n\nStampiamo le medie dei primi dieci campioni:\n\nsample_means &lt;- colMeans(samples)  # Medie di tutti i campioni\nsample_means[1:10]  # Prime dieci medie\n#&gt;  [1] 174.6703 176.2484 175.1709 174.3428 173.7149 176.0760 175.1029 174.3725\n#&gt;  [9] 175.3554 177.3568\n\nTroviamo il valore critico della distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libertà e livello di confidenza del 95% (\\(\\alpha = 0.05\\)):\n\nalpha &lt;- 0.05\nt_critical &lt;- qt(1 - alpha / 2, df = n - 1)  # Valore critico\nt_critical\n#&gt; [1] 2.04523\n\nUtilizzando il valore critico \\(t\\), calcoliamo 1000 intervalli di confidenza per la media della popolazione:\n\n# Calcolo della deviazione standard campionaria\nsample_sds &lt;- apply(samples, 2, sd)\n\n# Ampiezza degli intervalli\ninterval_width &lt;- t_critical * sample_sds / sqrt(n)\n\n# Limiti degli intervalli di confidenza\nCI_low &lt;- sample_means - interval_width\nCI_high &lt;- sample_means + interval_width\n\nTroviamo il livello di copertura, ovvero la proporzione di intervalli di confidenza che contengono il vero valore della media della popolazione \\(\\mu\\):\n\ncoverage &lt;- mean(CI_low &lt; mu & mu &lt; CI_high)  # Proporzione di copertura\ncoverage\n#&gt; [1] 0.956\n\nIn conclusione, ripetendo la simulazione per 1000 campioni, abbiamo ottenuto un livello di copertura molto vicino al valore nominale di \\(1 - \\alpha = 0.95\\). Questo risultato dimostra che, con un campione di dimensione \\(n = 30\\), gli intervalli di confidenza al 95% calcolati utilizzando la distribuzione \\(t\\) di Student forniscono stime accurate della media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "href": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "title": "47  Intervallo di confidenza",
    "section": "47.7 Confronto tra Intervalli Frequentisti e Bayesiani",
    "text": "47.7 Confronto tra Intervalli Frequentisti e Bayesiani\nConcludiamo questo capitolo esaminando le differenze tra l’intervallo di confidenza frequentista e l’intervallo di credibilità bayesiano, utilizzando lo stesso set di dati per entrambi i calcoli.\n\n47.7.1 Intervallo di confidenza frequentista\nImmaginiamo di avere un gruppo di 20 osservazioni relative alla performance in un test cognitivo. Il nostro obiettivo è stimare la media della popolazione da cui queste osservazioni sono tratte. Supponiamo che i dati provengano da una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della popolazione\nsample_size &lt;- 20\nmu &lt;- 50\nsigma &lt;- 10\n\n# Simulazione del campione\nsample_data &lt;- rnorm(sample_size, mean = mu, sd = sigma)\nprint(sample_data)\n#&gt;  [1] 44.39524 47.69823 65.58708 50.70508 51.29288 67.15065 54.60916 37.34939\n#&gt;  [9] 43.13147 45.54338 62.24082 53.59814 54.00771 51.10683 44.44159 67.86913\n#&gt; [17] 54.97850 30.33383 57.01356 45.27209\n\nVisualizziamo la distribuzione dei dati:\n\nhist(\n  sample_data, \n  probability = TRUE, \n  main = \"Distribuzione dei dati campionari\", \n  xlab = \"Valori\", \n  ylab = \"Densità\"\n)\n\n\n\n\n\n\n\n\nLa media campionaria (\\(\\hat{\\mu}\\)) viene calcolata come:\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nIn R:\n\nsample_mean &lt;- mean(sample_data)\nsample_mean\n#&gt; [1] 51.41624\n\nLa deviazione standard campionaria (\\(s\\)) si calcola come:\n\\[\ns = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n\\]\nIn R:\n\nvariance &lt;- function(x) {\n  sum((x - mean(x))^2) / length(x)\n}\n\nsample_sd &lt;- sqrt(variance(sample_data))  # Deviazione standard campionaria\nsample_sd\n#&gt; [1] 9.480369\n\nL’errore standard della media (\\(SE\\)) è:\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\]\nIn R:\n\nstandard_error &lt;- sample_sd / sqrt(sample_size)\nstandard_error\n#&gt; [1] 2.119875\n\nUn intervallo di confidenza è definito come:\n\\[\n\\bar{X} \\pm t_{\\text{critico}} \\cdot SE\n\\]\ndove \\(t_{\\text{critico}}\\) è il valore critico della distribuzione \\(t\\) di Student per un livello di confidenza del 95% (\\(\\alpha = 0.05\\)) e \\(n-1\\) gradi di libertà. In R:\n\nalpha &lt;- 0.05\ndf &lt;- sample_size - 1\nt_critical &lt;- qt(1 - alpha / 2, df)\nt_critical\n#&gt; [1] 2.093024\n\nCalcoliamo il margine di errore:\n\nmargin_of_error &lt;- t_critical * standard_error\nmargin_of_error\n#&gt; [1] 4.436949\n\nCalcoliamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\nconfidence_interval &lt;- \n  c(sample_mean - margin_of_error, sample_mean + margin_of_error)\nconfidence_interval\n#&gt; [1] 46.97929 55.85319\n\nPossiamo interpretare questo risultato dicendo che la procedura utilizzata per calcolare l’intervallo include il valore vero della media della popolazione nel 95% dei casi.\nCreiamo un grafico per mostrare la distribuzione dei dati, la media campionaria e l’intervallo di confidenza:\n\nhist(\n  sample_data, \n  probability = TRUE, \n  main = \"Intervallo di Confidenza per la Media\", \n  xlab = \"Valori\", \n  ylab = \"Densità\"\n)\nabline(v = sample_mean, col = \"blue\", lwd = 2, lty = 2)  # Media campionaria\nabline(v = confidence_interval, col = \"darkgreen\", lwd = 2)  # Limiti dell'intervallo\nlegend(\n  \"topright\", \n  legend = c(\"Media campionaria\", \"Intervallo di Confidenza\"),\n  col = c(\"blue\", \"darkgreen\"), \n  lty = c(2, 1), \n  lwd = 2\n)\n\n\n\n\n\n\n\n\nQuesta simulazione mostra come calcolare e interpretare un intervallo di confidenza frequentista per la media della popolazione utilizzando un campione di dimensione \\(n = 20\\).\n\n\n47.7.2 Intervallo di Credibilità Bayesiano\nPer determinare l’intervallo di credibilità bayesiano, utilizziamo un modello Bayesiano che assume una distribuzione normale per i dati osservati. Le distribuzioni a priori sono scelte in modo da riflettere una conoscenza preliminare vaga e non informativa:\n\nDistribuzione a priori di \\(\\mu\\): Normale centrata su \\(\\mu_0 = 0\\) con deviazione standard ampia (\\(\\sigma_0 = 200\\)).\nDistribuzione a priori di \\(\\sigma\\): Normale troncata positiva (\\(\\text{HalfNormal}\\)) con deviazione standard di 100.\n\nQueste scelte sono progettate per minimizzare l’introduzione di bias, mantenendo l’analisi conservativa.\nPrepariamo i dati:\n\n# Simulazione dei dati\nset.seed(123)\nsample_data &lt;- rnorm(20, mean = 50, sd = 10)\n\n# Preparazione dei dati per Stan\nstan_data &lt;- list(\n  N = length(sample_data),\n  Y = sample_data\n)\n\nCompiliamo il modello:\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"chapters\", \"frequentist_inference\", \"bayesian_model.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=1&gt; N;        // Numero di osservazioni\n#&gt;   vector[N] Y;           // Dati osservati\n#&gt; }\n#&gt; parameters {\n#&gt;   real mu;               // Media della popolazione\n#&gt;   real&lt;lower=0&gt; sigma;   // Deviazione standard della popolazione\n#&gt; }\n#&gt; model {\n#&gt;   mu ~ normal(0, 200);               // Prior debole per mu\n#&gt;   sigma ~ normal(0, 100) T[0, ];     // Prior HalfNormal per sigma\n#&gt;   Y ~ normal(mu, sigma);             // Likelihood\n#&gt; }\n\nEseguiamo il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  show_messages = FALSE\n)\n\nEstraiamo i risultati:\n\nposterior &lt;- fit$draws()\n\nCalcoliamo l’intervallo di credibilità al 95%:\n\nposterior_summary &lt;- \n  fit$summary(\n    c(\"mu\", \"sigma\"), ~quantile(.x, probs = c(0.025, 0.5, 0.975))\n  )\n\nposterior_summary\n#&gt; # A tibble: 2 × 4\n#&gt;   variable `2.5%` `50%` `97.5%`\n#&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 mu        46.6   51.4    56.2\n#&gt; 2 sigma      7.58  10.2    14.8\n\nL’intervallo di credibilità calcolato fornisce una gamma di valori entro cui si trova il parametro \\(\\mu\\) con un grado di credenza del 95%, date le informazioni a priori e i dati osservati.\n\n\n47.7.3 Confronto tra i Due Approcci\nIntervallo di Credibilità Bayesiano:\n\nRappresenta il grado di credenza (posteriori) che il parametro \\(\\mu\\) si trovi all’interno dell’intervallo calcolato.\nDipende sia dai dati osservati sia dalle distribuzioni a priori utilizzate nel modello, che possono influenzare il risultato in base alla loro specificità o vaghezza.\n\nIntervallo di Confidenza Frequentista:\n\nNon esprime la probabilità che il parametro \\(\\mu\\) appartenga a un determinato intervallo.\nSi riferisce invece alla procedura di costruzione dell’intervallo: se il campionamento fosse ripetuto infinite volte, il 95% degli intervalli costruiti conterrebbe il vero valore di \\(\\mu\\).\n\nIn sintesi:\n\nL’intervallo di credibilità bayesiano fornisce una stima probabilistica diretta e interpretabile della posizione di \\(\\mu\\), basata su dati osservati e informazioni a priori.\nL’intervallo di confidenza frequentista, invece, valuta la affidabilità della procedura nel lungo termine, senza fare affermazioni dirette sulla probabilità che il parametro rientri nell’intervallo specifico.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#stima-della-media-della-popolazione-con-intervallo-di-confidenza-frequentista",
    "href": "chapters/frequentist_inference/02_conf_interv.html#stima-della-media-della-popolazione-con-intervallo-di-confidenza-frequentista",
    "title": "47  Intervallo di confidenza",
    "section": "47.7 Stima della media della popolazione con intervallo di confidenza frequentista",
    "text": "47.7 Stima della media della popolazione con intervallo di confidenza frequentista\nImmaginiamo di avere un gruppo di 20 osservazioni relative alla performance in un test cognitivo. Il nostro obiettivo è stimare la media della popolazione da cui queste osservazioni sono tratte. Supponiamo che i dati provengano da una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\n\n47.7.1 Generazione dei dati campionari\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della popolazione\nsample_size &lt;- 20\nmu &lt;- 50\nsigma &lt;- 10\n\n# Simulazione del campione\nsample_data &lt;- rnorm(sample_size, mean = mu, sd = sigma)\nprint(sample_data)\n#&gt;  [1] 44.39524 47.69823 65.58708 50.70508 51.29288 67.15065 54.60916 37.34939\n#&gt;  [9] 43.13147 45.54338 62.24082 53.59814 54.00771 51.10683 44.44159 67.86913\n#&gt; [17] 54.97850 30.33383 57.01356 45.27209\n\nVisualizziamo la distribuzione dei dati:\n\nhist(\n  sample_data, \n  probability = TRUE, \n  main = \"Distribuzione dei dati campionari\", \n  xlab = \"Valori\", \n  ylab = \"Densità\"\n)\n\n\n\n\n\n\n\n\n\n\n47.7.2 Calcolo della stima puntuale\nLa media campionaria (\\(\\hat{\\mu}\\)) viene calcolata come:\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nIn R:\n\nsample_mean &lt;- mean(sample_data)\nsample_mean\n#&gt; [1] 51.41624\n\n\n\n47.7.3 Calcolo della deviazione standard campionaria e dell’errore standard\nLa deviazione standard campionaria (\\(s\\)) si calcola come:\n\\[\ns = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n\\]\nIn R:\n\nvariance &lt;- function(x) {\n  sum((x - mean(x))^2) / length(x)\n}\n\nsample_sd &lt;- sqrt(variance(sample_data))  # Deviazione standard campionaria\nsample_sd\n#&gt; [1] 9.480369\n\nL’errore standard della media (\\(SE\\)) è:\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\]\nIn R:\n\nstandard_error &lt;- sample_sd / sqrt(sample_size)\nstandard_error\n#&gt; [1] 2.119875\n\n\n\n47.7.4 Calcolo dell’intervallo di confidenza al 95%\nUn intervallo di confidenza è definito come:\n\\[\n\\bar{X} \\pm t_{\\text{critico}} \\cdot SE\n\\]\nDove \\(t_{\\text{critico}}\\) è il valore critico della distribuzione \\(t\\) di Student per un livello di confidenza del 95% (\\(\\alpha = 0.05\\)) e \\(n-1\\) gradi di libertà. In R:\n\nalpha &lt;- 0.05\ndf &lt;- sample_size - 1\nt_critical &lt;- qt(1 - alpha / 2, df)\nt_critical\n#&gt; [1] 2.093024\n\nCalcoliamo il margine di errore:\n\nmargin_of_error &lt;- t_critical * standard_error\nmargin_of_error\n#&gt; [1] 4.436949\n\nCalcoliamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\nconfidence_interval &lt;- \n  c(sample_mean - margin_of_error, sample_mean + margin_of_error)\nconfidence_interval\n#&gt; [1] 46.97929 55.85319\n\n\n\n47.7.5 Interpretazione dei risultati\nPossiamo interpretare questo risultato dicendo che la procedura utilizzata per calcolare l’intervallo include il valore vero della media della popolazione nel 95% dei casi.\n\n\n47.7.6 Visualizzazione dei risultati\nCreiamo un grafico per mostrare la distribuzione dei dati, la media campionaria e l’intervallo di confidenza:\n\nhist(\n  sample_data, \n  probability = TRUE, \n  main = \"Intervallo di Confidenza per la Media\", \n  xlab = \"Valori\", \n  ylab = \"Densità\"\n)\nabline(v = sample_mean, col = \"blue\", lwd = 2, lty = 2)  # Media campionaria\nabline(v = confidence_interval, col = \"darkgreen\", lwd = 2)  # Limiti dell'intervallo\nlegend(\n  \"topright\", \n  legend = c(\"Media campionaria\", \"Intervallo di Confidenza\"),\n  col = c(\"blue\", \"darkgreen\"), \n  lty = c(2, 1), \n  lwd = 2\n)\n\n\n\n\n\n\n\n\nQuesta simulazione mostra come calcolare e interpretare un intervallo di confidenza frequentista per la media della popolazione utilizzando un campione di dimensione \\(n = 20\\).\n\n\n47.7.7 Intervallo di Credibilità Bayesiano\nPer determinare l’intervallo di credibilità bayesiano, utilizziamo un modello Bayesiano che assume una distribuzione normale per i dati osservati. Le distribuzioni a priori sono scelte in modo da riflettere una conoscenza preliminare vaga e non informativa:\n\nDistribuzione a priori di \\(\\mu\\): Normale centrata su \\(\\mu_0 = 0\\) con deviazione standard ampia (\\(\\sigma_0 = 200\\)).\nDistribuzione a priori di \\(\\sigma\\): Normale troncata positiva (\\(\\text{HalfNormal}\\)) con deviazione standard di 100.\n\nQueste scelte sono progettate per minimizzare l’introduzione di bias, mantenendo l’analisi conservativa.\nPrepariamo i dati:\n\n# Simulazione dei dati\nset.seed(123)\nsample_data &lt;- rnorm(20, mean = 50, sd = 10)\n\n# Preparazione dei dati per Stan\nstan_data &lt;- list(\n  N = length(sample_data),\n  Y = sample_data\n)\n\nCompiliamo il modello:\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"chapters\", \"frequentist_inference\", \"bayesian_model.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=1&gt; N;        // Numero di osservazioni\n#&gt;   vector[N] Y;           // Dati osservati\n#&gt; }\n#&gt; parameters {\n#&gt;   real mu;               // Media della popolazione\n#&gt;   real&lt;lower=0&gt; sigma;   // Deviazione standard della popolazione\n#&gt; }\n#&gt; model {\n#&gt;   mu ~ normal(0, 200);               // Prior debole per mu\n#&gt;   sigma ~ normal(0, 100) T[0, ];     // Prior HalfNormal per sigma\n#&gt;   Y ~ normal(mu, sigma);             // Likelihood\n#&gt; }\n\nEseguiamo il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  show_messages = FALSE\n)\n\nEstrarre i risultati:\n\nposterior &lt;- fit$draws()\n\nCalcolo dell’intervallo di credibilità al 95%:\n\nposterior_summary &lt;- \n  fit$summary(\n    c(\"mu\", \"sigma\"), ~quantile(.x, probs = c(0.025, 0.5, 0.975))\n  )\n\nposterior_summary\n#&gt; # A tibble: 2 × 4\n#&gt;   variable `2.5%` `50%` `97.5%`\n#&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 mu        46.6   51.4    56.2\n#&gt; 2 sigma      7.58  10.2    14.8\n\nL’intervallo di credibilità calcolato fornisce una gamma di valori entro cui si trova il parametro \\(\\mu\\) con un grado di credenza del 95%, date le informazioni a priori e i dati osservati.\n\n\n47.7.8 Confronto tra Intervallo di Credibilità e Intervallo di Confidenza\nIntervallo di Credibilità Bayesiano:\n\nRappresenta il grado di credenza soggettivo (posteriori) che il parametro \\(\\mu\\) si trovi all’interno dell’intervallo calcolato.\nÈ influenzato sia dai dati osservati sia dalle distribuzioni a priori scelte.\n\nIntervallo di Confidenza Frequentista:\n\nNon riguarda la probabilità che il parametro \\(\\mu\\) sia in un dato intervallo.\nIndica che, in un numero infinito di campioni, il 95% degli intervalli calcolati conterrebbe il vero valore di \\(\\mu.\\)\n\nQuindi, mentre l’intervallo di credibilità bayesiano fornisce una misura diretta della credenza nella posizione della media della popolazione, l’intervallo di confidenza frequentista fornisce solo una misura di affidabilità del processo di stima nel lungo termine.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "title": "47  Intervallo di confidenza",
    "section": "47.8 Riflessioni Conclusive",
    "text": "47.8 Riflessioni Conclusive\nCome sottolineato da Hoekstra et al. (2014), è comune riscontrare fraintendimenti riguardo agli intervalli di fiducia. Il “livello di confidenza del 95%” è da interpretarsi come la probabilità a lungo termine che, in una serie di intervalli di fiducia calcolati, il 95% di essi includa il vero valore del parametro sconosciuto. Tuttavia, per un singolo intervallo di fiducia, non è possibile dichiarare con sicurezza che questo contenga effettivamente il parametro di interesse. In altre parole, la certezza sulla presenza del parametro sconosciuto all’interno di un dato intervallo di fiducia non è garantita per ogni singolo caso analizzato.\nÈ inoltre inesatto presumere che esista un legame diretto tra la varianza e la media di un campione, ipotizzando che un intervallo di fiducia più ristretto implichi maggiore precisione. Nella prospettiva frequentista, la “precisione” è strettamente legata al livello di copertura a lungo termine assicurato dal metodo usato per creare gli intervalli di fiducia. Questo concetto non si applica al singolo intervallo di fiducia osservato. Dunque, un intervallo di fiducia che si presenta estremamente ristretto potrebbe in realtà essere significativamente lontano dal valore vero del parametro non noto.\nÈ importante sottolineare che l’approccio frequentista offre un metodo per calcolare gli intervalli di confidenza per una vasta gamma di statistiche. Questo include, ad esempio, la stima dell’intervallo di confidenza per la differenza tra due medie, per una proporzione o per la differenza tra due proporzioni. Ecco le formule per calcolare gli intervalli di confidenza per i casi menzionati:\nIntervallo di confidenza per la differenza tra due medie.\nSe abbiamo due campioni indipendenti di dimensione \\(n_1\\) e \\(n_2\\), con medie \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) e deviazioni standard \\(s_1\\) e \\(s_2\\), l’intervallo di confidenza per la differenza tra le medie è calcolato come:\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}},\n\\]\ndove \\(t_{\\alpha/2}\\) è il valore critico della distribuzione t di Student con \\(\\alpha/2\\) di probabilità di coda e gradi di libertà \\(df = n_1 + n_2 - 2\\).\nIntervallo di confidenza per una proporzione.\nPer stimare l’intervallo di confidenza per una proporzione \\(p\\) in un campione binomiale di dimensione \\(n\\), la formula è:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}},\n\\]\ndove \\(\\hat{p}\\) è la proporzione campionaria e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.\nIntervallo di confidenza per la differenza tra due proporzioni.\nPer stimare l’intervallo di confidenza per la differenza tra due proporzioni \\(p_1\\) e \\(p_2\\) in due campioni binomiali di dimensioni \\(n_1\\) e \\(n_2\\), la formula è:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}},\n\\]\ndove \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) sono le proporzioni campionarie e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "title": "47  Intervallo di confidenza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.8.1.9000 MASS_7.3-61         viridis_0.6.5      \n#&gt;  [4] viridisLite_0.4.2   ggpubr_0.6.0        ggExtra_0.10.1     \n#&gt;  [7] gridExtra_2.3       patchwork_1.3.0     bayesplot_1.11.1   \n#&gt; [10] psych_2.4.6.26      scales_1.3.0        markdown_1.13      \n#&gt; [13] knitr_1.49          lubridate_1.9.3     forcats_1.0.0      \n#&gt; [16] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        \n#&gt; [19] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n#&gt; [22] ggplot2_3.5.1       tidyverse_2.0.0     rio_1.2.3          \n#&gt; [25] here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tensorA_0.36.2.1     gtable_0.3.6         xfun_0.49           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.4       rstatix_0.7.2       \n#&gt;  [7] lattice_0.22-6       tzdb_0.4.0           ps_1.8.1            \n#&gt; [10] vctrs_0.6.5          tools_4.4.2          generics_0.1.3      \n#&gt; [13] parallel_4.4.2       fansi_1.0.6          pacman_0.5.1        \n#&gt; [16] pkgconfig_2.0.3      data.table_1.16.2    checkmate_2.3.2     \n#&gt; [19] distributional_0.5.0 lifecycle_1.0.4      compiler_4.4.2      \n#&gt; [22] farver_2.1.2         munsell_0.5.1        mnormt_2.1.1        \n#&gt; [25] carData_3.0-5        httpuv_1.6.15        htmltools_0.5.8.1   \n#&gt; [28] yaml_2.3.10          Formula_1.2-5        car_3.1-3           \n#&gt; [31] pillar_1.9.0         later_1.4.0          abind_1.4-8         \n#&gt; [34] nlme_3.1-166         mime_0.12            posterior_1.6.0     \n#&gt; [37] tidyselect_1.2.1     digest_0.6.37        stringi_1.8.4       \n#&gt; [40] rprojroot_2.0.4      fastmap_1.2.0        grid_4.4.2          \n#&gt; [43] colorspace_2.1-1     cli_3.6.3            magrittr_2.0.3      \n#&gt; [46] utf8_1.2.4           broom_1.0.7          withr_3.0.2         \n#&gt; [49] backports_1.5.0      promises_1.3.1       timechange_0.3.0    \n#&gt; [52] rmarkdown_2.29       ggsignif_0.6.4       hms_1.1.3           \n#&gt; [55] shiny_1.9.1          evaluate_1.0.1       miniUI_0.1.1.1      \n#&gt; [58] rlang_1.1.4          Rcpp_1.0.13-1        xtable_1.8-4        \n#&gt; [61] glue_1.8.0           jsonlite_1.8.9       R6_2.5.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "href": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "title": "47  Intervallo di confidenza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21(5), 1157–1164.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "href": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "title": "47  Intervallo di confidenza",
    "section": "47.6 Il Concetto di Livello di Confidenza",
    "text": "47.6 Il Concetto di Livello di Confidenza\nGli intervalli di confidenza sono range di valori che, con una certa sicurezza statistica, si ritiene includano il parametro di interesse.\nSecondo l’approccio frequentista, l’intervallo di confidenza si deve considerare come una metodologia:\n\nSe ripetiamo l’esperimento (estrarre un campione e calcolare l’intervallo di confidenza) molte volte, il metodo produce un intervallo che coprirà il valore vero del parametro nel 95% dei casi, assumendo un livello di confidenza del 95%.\n\n\n47.6.1 Un Malinteso Comune nell’Interpretazione degli Intervalli di Confidenza\nÈ inesatto affermare che un determinato intervallo di confidenza contenga il valore vero di un parametro con una probabilità del 95%. Questo è un errore diffuso, persino tra i ricercatori, che spesso interpretano l’intervallo di confidenza come indicativo della probabilità che il parametro (ad esempio, la media della popolazione \\(\\mu\\)) si trovi effettivamente all’interno di un dato intervallo (es. \\([\\hat{a}, \\hat{b}]\\)).\nLa descrizione corretta è la seguente:\n\n“La metodologia impiegata per calcolare l’intervallo \\([\\hat{a}, \\hat{b}]\\) ha il 95% di probabilità di generare un intervallo che include il vero valore del parametro”.\nCiò significa che l’intervallo di confidenza non esprime una probabilità circa la posizione precisa del parametro, ma riflette la probabilità che la procedura adottata per determinarlo generi un intervallo che lo includa.\n\nIn conclusione, l’intervallo di confidenza ci fornisce una garanzia statistica riguardo alla affidabilità del metodo usato per la sua stima, piuttosto che sulla esatta ubicazione del parametro in questione.\n\n\n47.6.2 Fraintendimenti Comuni sugli Intervalli di Confidenza\nNel loro lavoro, Hoekstra et al. (2014) evidenziano come, nonostante l’ampio riconoscimento dei limiti dei test di ipotesi nulle, gli intervalli di confidenza siano spesso consigliati per l’inferenza statistica. Anche l’American Psychological Association (APA) suggerisce che gli intervalli di confidenza siano “in generale, la migliore strategia di reportistica”. Tuttavia, Hoekstra et al. (2014) sottolineano che queste raccomandazioni non considerano la difficoltà nel fornire una corretta interpretazione degli intervalli di confidenza.\nPer indagare l’interpretazione degli intervalli di confidenza, Hoekstra et al. (2014) hanno condotto uno studio con due domande principali:\n\nQuanto frequentemente intervalli di confidenza sono mal interpretati da studenti e ricercatori?\nL’esperienza nella ricerca riduce le interpretazioni errate degli intervalli di confidenza?\n\nPrima di presentare lo studio, {cite}hoekstra2014robust ricordano qual è l’interpretazione corretta degli intervalli di confidenza.\n\nA CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (e.g., Berger & Wolpert, 1988). As is the case with \\(p\\)-values, CIs do not allow one to make probability statements about parameters or hypotheses.\n\nNel loro studio, Hoekstra et al. (2014) hanno presentato un questionario a 596 partecipanti, tra cui studenti universitari e ricercatori, con le seguenti affermazioni riguardanti l’interpretazione degli intervalli di confidenza.\n\nProfessor Bumbledorf conducts an experiment, analyzes the data, and reports: “The 95% confidence interval for the mean ranges from 0.1 to 0.4.” Please mark each of the statements below as ‘true’ or ‘false’.\n\n\n\nThe probability that the true mean is greater than 0 is at least 95%.\nThe probability that the true mean equals 0 is smaller than 5%.\nThe “null hypothesis” that the true mean equals 0 is likely to be incorrect.\nThere is a 95% probability that the true mean lies between 0.1 and 0.4.\nWe can be 95% confident that the true mean lies between 0.1 and 0.4.\nIf we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.\n\n\nSorprendentemente, anche se tutte le sei affermazioni nel questionario sono errate, molti partecipanti hanno concordato con esse. I risultati mostrano che, in media, i partecipanti hanno concordato con circa 3.5 affermazioni errate su 6. Non è stata rilevata una differenza di rilievo nell’interpretazione degli intervalli di confidenza tra studenti e ricercatori, suggerendo che l’esperienza nella ricerca non migliora la comprensione di questo concetto.\nI risultati indicano che molte persone interpretano erroneamente gli intervalli di confidenza, e che anche l’esperienza nella ricerca non garantisce una migliore comprensione. Questo solleva dubbi sull’efficacia degli intervalli di confidenza frequentisti e suggerisce che gli “intervalli di credibilità” bayesiani possano rappresentare un’alternativa più vantaggiosa. Quest’ultimi tendono ad essere più intuitivi e di più facile interpretazione corretta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-una-media",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-una-media",
    "title": "47  Intervallo di confidenza",
    "section": "47.3 Intervallo di Confidenza per una Media",
    "text": "47.3 Intervallo di Confidenza per una Media\nNei casi in cui la distribuzione delle statistiche campionarie si avvicina a una distribuzione Normale, l’intervallo di confidenza al 95% è calcolato come:\n\\[\n\\hat{\\theta} \\pm 1.96 \\cdot \\text{SE},\n\\]\ndove \\(\\hat{\\theta}\\) rappresenta la stima del parametro e SE l’errore standard.\n\n47.3.1 Varianza Nota\nConsideriamo una popolazione che segue una distribuzione normale con una media nota \\(\\mu\\) e varianza \\(\\sigma^2\\). Prendiamo un campione casuale di dimensione \\(n\\) da questa popolazione, indicato come \\(X_1, X_2, \\dots, X_n\\). Grazie alle proprietà delle distribuzioni normali, la media campionaria \\(\\bar{X}\\) segue anch’essa una distribuzione normale, nello specifico \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma^2/n)\\).\nPasso 1: Standardizzazione della Media Campionaria\nPer standardizzare la media campionaria in una variabile distribuita normalmente standard, sottraiamo la media della popolazione \\(\\mu\\) e dividiamo per lo scarto standard della media campionaria \\(\\sigma/\\sqrt{n}\\). Ciò porta alla seguente trasformazione:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim \\mathcal{N}(0, 1).\n\\]\nPasso 2: Stabilire il Livello di Confidenza\nDefiniamo un livello di confidenza \\(\\gamma = 1 - \\alpha\\), ad esempio \\(\\gamma = 0.95\\) per un livello di confidenza del 95%.\nIdentifichiamo il valore critico \\(z\\), corrispondente al quantile \\((1 - \\alpha/2)\\) della distribuzione normale standard. Il valore \\(z\\) rappresenta il punto di taglio alle estremità della distribuzione:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nPasso 3: Formulazione dell’Intervallo di Confidenza\nCon il valore \\(z\\) definito, formuliamo l’intervallo di confidenza per la media della popolazione:\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\nPasso 4: Manipolazione Algebrica per Definire i Limiti\nRielaboriamo la disuguaglianza per esporre i limiti dell’intervallo di confidenza:\n\\[\n\\begin{align}\n  P\\bigg(-z \\leq &\\frac{ \\bar{X} - \\mu } {\\sigma} \\sqrt{n} \\leq z\\bigg) = \\gamma\\notag\\\\\n  P\\bigg(-z {\\frac{\\sigma}{\\sqrt{n}}} \\leq  &\\bar{X} - \\mu \\leq z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma\\notag\\\\\n  P\\bigg(-\\bar{X}-z {\\frac{\\sigma}{\\sqrt{n}}} \\leq &-\\mu \\leq -\\bar{X} + z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma\\notag\\\\\n  P\\bigg(\\bar{X}+z \\frac{\\sigma}{\\sqrt{n}} \\geq &\\mu \\geq  \\bar{X} -z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma.\\notag\n\\end{align}\n\\]\nPasso 5: Specificazione dei Limiti dell’Intervallo\nDefiniamo i limiti dell’intervallo di confidenza, \\(\\hat{a}\\) e \\(\\hat{b}\\), come segue:\n\\[\n\\hat{a} = \\bar{X} - z \\frac{\\sigma}{\\sqrt{n}},\n  \\quad \\hat{b} = \\bar{X} + z \\frac{\\sigma}{\\sqrt{n}},\n\\]\ncon \\(P(\\hat{a} \\leq \\mu \\leq \\hat{b}) = \\gamma\\).\nIn conclusione, l’intervallo di confidenza \\((\\hat{a}, \\hat{b})\\) racchiude il vero valore della media della popolazione \\(\\mu\\) con una probabilità \\(\\gamma\\).\n\n\n47.3.2 Varianza Incognita\nIn contesti reali, quando si preleva un campione \\(X_1, \\dots, X_n\\) da una popolazione, la varianza \\(\\sigma^2\\) della popolazione è spesso incognita. Questo aggiunge incertezza riguardo alla media della popolazione \\(\\mu\\), che è il parametro di interesse. In questi casi, si adotta la distribuzione t di Student per la stima dell’intervallo di confidenza della media \\(\\mu\\), a causa della varianza incognita.\nPasso 1: Impiego della Distribuzione t di Student\nApplichiamo la formula seguente per calcolare l’intervallo:\n\\[\nP\\left(−t^{\\ast} \\leq \\frac{\\bar{X} - \\mu}{s/\\sqrt{n}} \\leq t^{\\ast}\\right) = \\gamma,\n\\]\ndove \\(\\gamma = 1 - \\alpha\\) è il livello di confidenza, \\(s\\) è la stima della deviazione standard \\(\\sigma\\) della popolazione, e \\(t^{\\ast}\\) è il quantile di ordine \\(1 - \\alpha/2\\) della distribuzione t con \\(n−1\\) gradi di libertà.\nPasso 2: Determinazione dei Limiti dell’Intervallo di Confidenza\nCalcoliamo i limiti inferiore \\(\\hat{a}\\) e superiore \\(\\hat{b}\\) dell’intervallo di confidenza così:\n\\[\n\\hat{a} = \\bar{X} - t^{\\ast} \\frac{s}{\\sqrt{n}},\n  \\quad \\hat{b} = \\bar{X} + t^{\\ast} \\frac{s}{\\sqrt{n}}.\n\\]\nIn queste circostanze, si sostituisce la varianza sconosciuta \\(\\sigma^2\\) con la sua stima \\(s\\) e si utilizza la distribuzione t di Student invece della normale.\n\n\n47.3.3 Applicabilità e Limitazioni\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e è valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non è normalmente distribuita e la dimensione del campione è ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell’intervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "href": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "title": "47  Intervallo di confidenza",
    "section": "47.2 Inferenza Statistica Frequentista e Media Campionaria",
    "text": "47.2 Inferenza Statistica Frequentista e Media Campionaria\nQuando estraiamo un campione casuale semplice \\(X_1, X_2, \\dots, X_n\\) da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria \\(\\bar{X}\\) è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nLa media campionaria \\(\\bar{X}\\) è una variabile casuale perché dipende dai valori osservati nel campione, che sono essi stessi casuali. Le proprietà della media campionaria sono le seguenti:\n\nMedia della distribuzione campionaria: \\(E[\\bar{X}] = \\mu\\). La media campionaria è uno stimatore non distorto della media della popolazione.\nVarianza della distribuzione campionaria: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\). Questo significa che la precisione di \\(\\bar{X}\\) come stima di \\(\\mu\\) aumenta con il numero di osservazioni \\(n\\).\n\nQueste proprietà sono fondamentali per calcolare un intervallo di confidenza, poiché ci permettono di descrivere la distribuzione di \\(\\bar{X}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "title": "47  Intervallo di confidenza",
    "section": "47.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota",
    "text": "47.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota\nSupponiamo che la popolazione sia distribuita normalmente con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e che \\(\\sigma^2\\) sia nota. La distribuzione della media campionaria \\(\\bar{X}\\) è anch’essa normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right).\n\\]\n\n47.3.1 Passo 1: Standardizzazione della Media Campionaria\nPer lavorare con una distribuzione normale standard (media 0 e varianza 1), standardizziamo \\(\\bar{X}\\) utilizzando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQui, \\(\\sigma / \\sqrt{n}\\) è la deviazione standard della distribuzione campionaria di \\(\\bar{X}\\).\nDopo questa trasformazione, la variabile \\(Z\\) segue una distribuzione normale standard:\n\\[\nZ \\sim \\mathcal{N}(0, 1).\n\\]\n\n\n47.3.2 Passo 2: Determinazione del Livello di Confidenza\nScegliamo un livello di confidenza \\(\\gamma\\), ad esempio \\(\\gamma = 0.95\\). Per una distribuzione normale standard, troviamo il valore critico \\(z\\) tale che la probabilità tra \\(-z\\) e \\(+z\\) sia pari al livello di confidenza:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nPer un livello di confidenza del 95%, \\(z \\approx 1.96\\).\n\n\n47.3.3 Passo 3: Formulazione dell’Intervallo di Confidenza\nPartiamo dalla probabilità per \\(Z\\):\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nSostituiamo la definizione di \\(Z\\):\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\nMoltiplichiamo tutti i membri per \\(\\sigma / \\sqrt{n}\\) per rimuovere il denominatore:\n\\[\nP\\left(-z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\) a tutti i membri per isolare \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\n\n\n47.3.4 Passo 4: Limiti dell’Intervallo di Confidenza\nDefiniamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\\[\n\\hat{a} = \\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nL’intervallo di confidenza per \\(\\mu\\) è quindi:\n\\[\n(\\hat{a}, \\hat{b}) = \\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "title": "47  Intervallo di confidenza",
    "section": "47.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita",
    "text": "47.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita\nNella maggior parte dei casi pratici, la varianza \\(\\sigma^2\\) non è nota. In questi casi, stimiamo \\(\\sigma\\) con la deviazione standard campionaria \\(s\\) e utilizziamo la distribuzione t di Student, che tiene conto dell’incertezza aggiuntiva.\n\n47.4.1 Passo 1: Distribuzione t di Student\nLa statistica che seguiamo è:\n\\[\nT = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}},\n\\]\ndove \\(T\\) segue una distribuzione t con \\(n-1\\) gradi di libertà.\n\n\n47.4.2 Passo 2: Costruzione dell’Intervallo di Confidenza\nAnalogamente al caso precedente, costruiamo l’intervallo partendo da:\n\\[\nP(-t^\\ast \\leq T \\leq t^\\ast) = \\gamma,\n\\]\ndove \\(t^\\ast\\) è il valore critico della distribuzione t per il livello di confidenza \\(\\gamma\\) e \\(n-1\\) gradi di libertà.\nSostituendo \\(T\\):\n\\[\nP\\left(-t^\\ast \\leq \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}} \\leq t^\\ast\\right) = \\gamma.\n\\]\nMoltiplichiamo per \\(s / \\sqrt{n}\\):\n\\[\nP\\left(-t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\n\n\n47.4.3 Passo 3: Limiti dell’Intervallo\nI limiti dell’intervallo sono:\n\\[\n\\hat{a} = \\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}.\n\\]\nIn conclusione, gli intervalli di confidenza forniscono un modo per quantificare l’incertezza nelle stime di parametri sconosciuti. La loro costruzione dipende dalla distribuzione campionaria dello stimatore e dall’informazione disponibile sulla varianza.\n\n\n47.4.4 Applicabilità e Limitazioni\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e è valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non è normalmente distribuita e la dimensione del campione è ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell’intervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "programmazione2024.html#esame-parziale-e-presentazioni-finali",
    "href": "programmazione2024.html#esame-parziale-e-presentazioni-finali",
    "title": "1  Calendario delle lezioni",
    "section": "1.2 Esame parziale e presentazioni finali",
    "text": "1.2 Esame parziale e presentazioni finali\n\n\n\n\n\n\n\n\n\nIncontro\nData\nArgomento\nOrario\n\n\n\n\n30\n19 maggio\nEsame parziale finale\n8:30-10:30\n\n\n31\n20 maggio\nPresentazioni dei progetti\n8:30-10:30\n\n\n32\n22 maggio\nPresentazioni dei progetti\n11:30-13:30",
    "crumbs": [
      "Programmazione",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Calendario delle lezioni</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html",
    "href": "chapters/frequentist_inference/03_sample_size.html",
    "title": "48  La grandezza del campione",
    "section": "",
    "text": "48.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nLa scelta della dimensione campionaria è cruciale per garantire che i risultati di uno studio siano affidabili, bilanciando precisione e costi. In questo capitolo, analizzeremo come calcolare la dimensione campionaria necessaria per stimare la media di una popolazione con un margine di errore prefissato e un determinato livello di confidenza. Utilizzeremo un esempio psicologico per illustrare il processo e fornire implementazioni in R.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "title": "48  La grandezza del campione",
    "section": "48.2 La Logica Dietro la Scelta della Dimensione Campionaria",
    "text": "48.2 La Logica Dietro la Scelta della Dimensione Campionaria\nIn psicologia, stimare la media di una variabile (ad esempio, il punteggio medio di una scala psicometrica) è un’operazione comune. Campioni più grandi garantiscono:\n\nStime più precise: La varianza dell’estimatore diminuisce con l’aumentare della dimensione campionaria.\nMaggiore fiducia nei risultati: Il margine di errore si restringe.\n\nTuttavia, i campioni più grandi comportano costi più elevati in termini di tempo e risorse. Pertanto, il problema si riduce spesso a determinare il campione più piccolo che garantisce la precisione richiesta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "href": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "title": "48  La grandezza del campione",
    "section": "48.4 Stima della Media del Punteggio di Autostima",
    "text": "48.4 Stima della Media del Punteggio di Autostima\nPer fare un esempio, immaginiamo di voler stimare la media del punteggio di autostima in una popolazione di giovani adulti. Utilizziamo la Rosenberg Self-Esteem Scale (RSES), che assegna un punteggio compreso tra 0 e 30.\nDettagli del problema:\n\nDeviazione standard del punteggio: \\(\\sigma = 6\\) (stimata da studi precedenti).\nMargine di errore massimo accettabile: \\(E = 2\\).\nLivello di confidenza: \\(95\\%\\).\n\nImplementiamo in R la formula derivata in precedenza.\n\n# Parametri del problema\nsigma &lt;- 6     # Deviazione standard del punteggio RSES\nE &lt;- 2         # Margine di errore desiderato\nz_alpha &lt;- qnorm(0.975)  # Quantile superiore della distribuzione normale (95% confidenza)\n\n# Calcolo della dimensione campionaria\nn &lt;- (z_alpha * sigma / E)^2\nn &lt;- ceiling(n)  # Arrotondamento all'intero successivo\nn\n#&gt; [1] 35\n\nIn conclusione, la dimensione campionaria minima necessaria per stimare la media del punteggio di autostima con un margine di errore massimo di 2 punti e un livello di confidenza del 95% è \\(n = 35\\).\n\n48.4.1 Approfondimenti\n\nPrecisione e Livello di Confidenza\nAumentando \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\nQuesto restringe l’intervallo di confidenza e migliora la precisione.\nCosto e Praticità\nUn campione più grande aumenta i costi. È importante trovare il giusto compromesso tra precisione e fattibilità.\nAdattamento ad Altri Livelli di Confidenza\nPer altri livelli di confidenza, basta modificare il quantile \\(z_{\\alpha/2}\\). Ad esempio, per un livello di confidenza del 99%, \\(z_{0.005} \\approx 2.576\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "title": "48  La grandezza del campione",
    "section": "48.5 Riflessioni Conclusive",
    "text": "48.5 Riflessioni Conclusive\nDeterminare la dimensione del campione è essenziale per ogni studio psicologico. Un approccio matematico rigoroso ci permette di bilanciare la precisione delle stime con i vincoli di risorse.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "48  La grandezza del campione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.0       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1 \n#&gt; [37] cli_3.6.3         magrittr_2.0.3    utf8_1.2.4        broom_1.0.7      \n#&gt; [41] withr_3.0.2       backports_1.5.0   promises_1.3.1    timechange_0.3.0 \n#&gt; [45] rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3         shiny_1.9.1      \n#&gt; [49] evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [53] xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#implementazione-in-r",
    "href": "chapters/frequentist_inference/03_sample_size.html#implementazione-in-r",
    "title": "48  La grandezza del campione",
    "section": "48.4 Implementazione in R",
    "text": "48.4 Implementazione in R\n\n# Parametri del problema\nsigma &lt;- 6     # Deviazione standard del punteggio RSES\nE &lt;- 2         # Margine di errore desiderato\nz_alpha &lt;- qnorm(0.975)  # Quantile superiore della distribuzione normale (95% confidenza)\n\n# Calcolo della dimensione campionaria\nn &lt;- (z_alpha * sigma / E)^2\nn &lt;- ceiling(n)  # Arrotondamento all'intero successivo\nn\n#&gt; [1] 35\n\n\n48.4.1 Interpretazione\nLa dimensione campionaria minima necessaria per stimare la media del punteggio di autostima con un margine di errore massimo di 2 punti e un livello di confidenza del 95% è \\(n = 35\\).\n\n\n48.4.2 Approfondimenti\n\nPrecisione e Livello di Confidenza\nAumentando \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\nQuesto restringe l’intervallo di confidenza e migliora la precisione.\nCosto e Praticità\nUn campione più grande aumenta i costi. È importante trovare il giusto compromesso tra precisione e fattibilità.\nAdattamento ad Altri Livelli di Confidenza\nPer altri livelli di confidenza, basta modificare il quantile \\(z_{\\alpha/2}\\). Ad esempio, per un livello di confidenza del 99%, \\(z_{0.005} \\approx 2.576\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria-derivazione-della-formula",
    "href": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria-derivazione-della-formula",
    "title": "48  La grandezza del campione",
    "section": "48.3 Calcolo della Dimensione Campionaria: Derivazione della Formula",
    "text": "48.3 Calcolo della Dimensione Campionaria: Derivazione della Formula\nPer campioni sufficientemente grandi, la media stimata \\(\\bar{X}\\) segue una distribuzione normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n\\]\ndove \\(n\\) è la dimensione del campione, \\(\\mu\\) è la vera media della popolazione e \\(\\sigma^2\\) è la varianza della popolazione.\nIl nostro obiettivo è trovare la dimensione campionaria \\(n\\) tale che:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) \\geq 0.95,\n\\]\ndove:\n\n\\(\\bar{X}\\) è la media campionaria,\n\\(\\mu\\) è la media della popolazione,\n\\(E\\) è il margine di errore massimo accettabile.\n\nSappiamo che, per il teorema centrale del limite o per le proprietà della distribuzione normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n\\]\ndove \\(\\sigma^2\\) è la varianza della popolazione e \\(n\\) è la dimensione campionaria.\nPer trasformare in termini della variabile standardizzata \\(Z\\), utilizziamo:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}},\n\\]\nche implica:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(0, 1\\right).\n\\]\nPertanto, la probabilità richiesta si riscrive:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) = P\\left(|Z| &lt; z_{0.025}\\right),\n\\]\ndove \\(z_{0.025} = 1.96\\) è il quantile superiore della distribuzione normale standard, corrispondente a un livello di confidenza del \\(95\\%\\).\nDalla definizione della variabile standardizzata:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}},\n\\]\npossiamo ricavare la relazione per il margine di errore:\n\\[\n|\\bar{X} - \\mu| &lt; E \\implies Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\implies |\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}| &lt; \\frac{E}{\\sigma / \\sqrt{n}}.\n\\]\nSostituendo la condizione \\(|Z| &lt; z_{0.025}\\), otteniamo:\n\\[\n\\frac{E}{\\sigma / \\sqrt{n}} = z_{0.025}.\n\\]\nMoltiplichiamo entrambi i membri per \\(\\sigma / \\sqrt{n}\\):\n\\[\nE = z_{0.025} \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nIsoliamo \\(\\sqrt{n}\\) dividendo entrambi i membri per \\(z_{0.025} \\cdot \\sigma\\):\n\\[\n\\sqrt{n} = \\frac{z_{0.025} \\cdot \\sigma}{E}.\n\\]\nPer ottenere \\(n\\), eleviamo entrambi i membri al quadrato:\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]\nIn conclusione, la dimensione campionaria minima \\(n\\) necessaria per soddisfare il margine di errore \\(E\\) e il livello di confidenza richiesto è:\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  }
]