# Modello di Poisson (1) {#sec-mcmc-poisson-1}


*Preparazione del Notebook*

```{r}
here::here("code", "_common.R") |> 
  source()

if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(cmdstanr, posterior, bayesplot, ggplot2, tidyverse, tibble)
conflicts_prefer(posterior::ess_bulk)
conflicts_prefer(posterior::ess_tail)
conflicts_prefer(dplyr::count)
```


## Introduzione {.unnumbered .unlisted}

::: {.lead}
In questo capitolo affrontiamo un primo esempio di modellazione con Stan, il linguaggio che useremo per costruire modelli statistici e fare inferenza bayesiana. Riprendiamo un caso già risolto con metodi analitici e con il metodo su griglia — il modello Gamma–Poisson — e lo affrontiamo ora con il campionamento MCMC. In questo modo possiamo confrontare i risultati e, soprattutto, imparare un workflow che useremo anche quando non esistono soluzioni chiuse.
:::


## Dal modello teorico al modello computazionale

Supponiamo di osservare, in otto finestre temporali di pari durata, quante volte si verifica un certo evento (per esempio: il numero di compulsioni in otto momenti della giornata, oppure le chiamate ricevute in otto turni orari). I dati sono:

```{r}
y <- c(2, 1, 3, 2, 2, 1, 1, 1)
```

Abbiamo quindi $N=8$ osservazioni. Vogliamo stimare $\lambda$, il *tasso medio di occorrenza per unità di tempo* (qui: per finestra di osservazione). Per fenomeni di conteggio assumiamo una *distribuzione di Poisson*. In presenza di esposizioni (durate) potenzialmente diverse $t_i>0$, il modello naturale è

$$
y_i \sim \text{Poisson}(\mu_i), 
\qquad \mu_i = \lambda\, t_i,
$$

ossia

$$
P(y_i \mid \lambda) \;=\; \frac{(\lambda\, t_i)^{y_i} e^{-\lambda\, t_i}}{y_i!},
\quad y_i \in \mathbb{N},\ \lambda>0.
$$

Poiché qui tutte le finestre hanno la *stessa durata* ($t_i=1$), la formula si semplifica in

$$
P(y_i \mid \lambda) \;=\; \frac{\lambda^{y_i} e^{-\lambda}}{y_i!},
\qquad \mathbb{E}[y_i]=\lambda,\quad \mathrm{Var}(y_i)=\lambda.
$$

In altre parole, *$\lambda$ coincide con il numero medio di eventi per finestra* (ad es. per turno/ora o per giorno). Da non confondere con i *tempi di attesa* tra eventi: lì la media è $1/\lambda$, ma riguarda il modello esponenziale, non i conteggi.

Per l’analisi bayesiana specifichiamo una *prior coniugata Gamma* in parametrizzazione *shape–rate* $(\alpha,\beta)$, con densità

$$
p(\lambda) \;=\; \frac{\beta^{\alpha}}{\Gamma(\alpha)}\, \lambda^{\alpha - 1} e^{-\beta \lambda},
\quad \lambda>0,
$$

per cui

$$
\mathbb{E}[\lambda] = \frac{\alpha}{\beta}, 
\qquad \mathrm{Var}(\lambda) = \frac{\alpha}{\beta^{2}},
\qquad \mathrm{sd}(\lambda)=\frac{\sqrt{\alpha}}{\beta}.
$$

Nel nostro esempio poniamo $\alpha=9$ e $\beta=2$: la prior ha media $\alpha/\beta=4{,}5$ (circa 4–5 eventi per finestra) e deviazione standard $\sqrt{\alpha}/\beta \approx 1{,}5$, che esprime moderata informazione con adeguata incertezza.


## Scrivere il modello in Stan

Un modello Stan è diviso in blocchi: *data* (dati), *parameters* (incognite), *model* (priori + verosimiglianza). Aggiungiamo anche *generated quantities* per quantità derivate utili al confronto con la soluzione analitica (e, volendo, per LOO).

Per evitare dipendenze da percorsi locali, creiamo e compiliamo il modello direttamente dalla stringa:

```{r}
stan_code <- "
data {
  int<lower=0> N;
  array[N] int<lower=0> y;
  real<lower=0> alpha_prior;
  real<lower=0> beta_prior;
}
parameters {
  real<lower=0> lambda;
}
model {
  lambda ~ gamma(alpha_prior, beta_prior);
  y ~ poisson(lambda);
}
generated quantities {
  real alpha_post = alpha_prior + sum(y);
  real beta_post  = beta_prior + N;
  array[N] real log_lik;
  for (i in 1:N) log_lik[i] = poisson_lpmf(y[i] | lambda);
}
"
```

Compiliamo:

```{r}
#| output: false
mod <- cmdstan_model(write_stan_file(stan_code))
```

Prepariamo i dati:

```{r}
N <- length(y)
alpha_prior <- 9
beta_prior  <- 2

stan_data <- list(N = N, y = y, alpha_prior = alpha_prior, beta_prior = beta_prior)
```

Una volta preparati i dati, lanciamo il campionamento:

```{r}
#| output: false

fit <- mod$sample(
  data = stan_data,
  seed = 123,
  chains = 4,
  parallel_chains = 4,
  iter_sampling = 3000,
  iter_warmup = 2000,
  refresh = 0
)
```

### Analizzare i risultati

Estraiamo i campioni di $\lambda$ e i parametri posteriori teorici:
  
```{r}
lambda_samples <- fit$draws("lambda", format = "df")$lambda

alpha_post <- alpha_prior + sum(y)
beta_post  <- beta_prior + N
```

Istogramma dei campioni MCMC + curva Gamma teorica:
  
```{r}
ggplot(data.frame(lambda = lambda_samples), aes(x = lambda)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = "skyblue", alpha = 0.7) +
  stat_function(
    fun = function(x) dgamma(x, shape = alpha_post, rate = beta_post),
    color = "red", linewidth = 1.2
  ) +
  labs(title = "Distribuzione a posteriori di λ", x = "λ", y = "Densità")
```

Intervallo di credibilità (94% centrale, ad es.):

```{r}
quantile(lambda_samples, probs = c(0.03, 0.97))
```

Diagnostica essenziale:
  
```{r}
posterior::summarise_draws(fit$draws("lambda"), rhat, ess_bulk, ess_tail)

bayesplot::mcmc_trace(fit$draws("lambda")) +
  ggtitle("Traceplot di lambda")
```


## Sparatorie mortali

Nella sezione precedente abbiamo esaminato il processo di derivazione della distribuzione a posteriori per i parametri della distribuzione Gamma, la quale viene impiegata quando si adotta un prior Gamma per una verosimiglianza di Poisson. In questo esempio, useremo tale metodo per affrontare una questione relativa all'analisi di un set di dati reali.

### Domanda della ricerca

Come spiegato [qui](https://github.com/washingtonpost/data-police-shootings), i dati che esamineremo sono raccolti dal Washington Post con lo scopo di registrare ogni sparatoria mortale negli Stati Uniti ad opera di agenti di polizia, a partire dal 1° gennaio 2015. Il Washington Post ha adottato un approccio sistematico e accurato nella raccolta di queste informazioni, fornendo dati che possono essere utili per valutare i problemi legati alla violenza delle forze di polizia negli Stati Uniti.

**Obiettivo.** Stimare, per il periodo 2015–*ultimo anno completo disponibile*, il *tasso medio annuo* e l’*incertezza* associata. Poiché il *2025* è incompleto, lo escludiamo.


### Importazione e pre-processing dei dati

```{r}
# URL del dataset
url <- "https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv"

# Importa i dati
fps_dat <- read_csv(url, show_col_types = FALSE)

# Conversione colonna date
fps_dat <- fps_dat %>%
  mutate(date = ymd(date),
         year = year(date))

# Esamina le colonne disponibili
colnames(fps_dat)

# Filtra eliminando i casi con year == 2025
fps <- fps_dat %>%
  filter(year != 2025)

# Conta le occorrenze per anno
year_counts <- fps %>%
  count(year, name = "events")

# Mostra i risultati
print(year_counts)
```


### Modello di Poisson (pooling completo)

Assumiamo $y_t \sim \text{Poisson}(\lambda)$ con $\lambda$ costante sul periodo:

$$
y_t \,\sim\, \text{Poisson}(\lambda), \quad t=1,\dots,n.
$$

Il supporto di $\lambda$ è $[0,\infty)$.

Si noti che abbiamo considerato i dati come iid. Guardando la serie temporale, però, è ovvio che le cose non stanno così: i valori aumentano nel tempo.


### Prior

Usiamo una *prior coniugata Gamma* su $\lambda$, scelta in modo *debolmente informativo*. Un’ipotesi ragionevole (da verificare e discutere in aula) è una media a priori di *600* eventi/anno, con *deviazione standard 200*. In termini Gamma(shape, rate):

$$
\alpha = (\mu/\sigma)^2,\qquad \beta = \mu/\sigma^2.
$$

Visualizziamo la prior (campionando in R):

```{r}
mu    <- 600
sigma <- 200

# Parametrizzazione Gamma(shape = k, scale = theta) per la simulazione
theta <- sigma^2 / mu
k     <- mu / theta

set.seed(2)
x_draws <- rgamma(50000, shape = k, scale = theta)

ggplot(data.frame(x = x_draws), aes(x = x)) +
  geom_histogram(bins = 30, color = "white") +
  labs(
    x = "Tasso (eventi/anno)",
    y = "Frequenza",
    title = "Prior Gamma su λ (mu = 600, sigma = 200)"
  )
```


### Modello di Poisson con Stan

Qui stimiamo $\lambda$ assumendo lo *stesso tasso* per tutti gli anni (pooling completo). Con prior Gamma in *parametrizzazione (shape, rate)*:

```{r}
stan_code <- "
data {
  int<lower=1> N;                 // numero di anni
  array[N] int<lower=0> y;        // conteggi annuali
  real<lower=0> alpha_prior;      // shape
  real<lower=0> beta_prior;       // rate
}
parameters {
  real<lower=0> lambda;           // tasso medio annuo
}
model {
  lambda ~ gamma(alpha_prior, beta_prior); // prior Gamma(shape, rate)
  y ~ poisson(lambda);                     // verosimiglianza
}
generated quantities {
  real log_lik = poisson_lpmf(y | lambda);
}
"
```

```{r}
# Dati (usa i conteggi 2015...2024 ordinati)
y_vec <- year_counts$events  # ordine per anno; per Poisson i.i.d. l'ordine non incide

# Prior: coerente con la sezione precedente
alpha_prior <- (mu / sigma)^2
beta_prior  <- mu / sigma^2

stan_data <- list(
  N = length(y_vec),
  y = as.integer(y_vec),
  alpha_prior = alpha_prior,
  beta_prior  = beta_prior
)
stan_data
```


Compilazione ed esecuzione:

```{r}
#| output: false
mod <- cmdstan_model(write_stan_file(stan_code))
```


```{r}
#| output: false

fit <- mod$sample(
  data = stan_data,
  iter_warmup = 1000,
  iter_sampling = 4000,
  chains = 4,
  seed = 123,
  refresh = 0
)
```

Riassunto dei parametri:

```{r}
fit$summary("lambda")
```

```{r}
posterior::summarise_draws(
  fit$draws("lambda"),
  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))
)
```

Visualizzazione:

```{r}
bayesplot::mcmc_hist(fit$draws("lambda")) +
  ggtitle("Posterior di λ (tasso annuo)")
```

```{r}
bayesplot::mcmc_areas(fit$draws("lambda"), prob = 0.95) +
  ggtitle("Posterior di λ (ICr 95%)")
```

Il grafico mostra che il tasso di sparatorie fatali ha una media annuale di 1042 con CI [1022, 1062].  

In sintesi, analizzando i dati compresi tra il 2015 e il 2025 e basandoci su una distribuzione a priori che presuppone una sparatoria mortale al mese per stato, possiamo concludere con un grado di certezza soggettivo del 95% che il tasso stimato di sparatorie fatali da parte della polizia negli Stati Uniti sia di 1028 casi all'anno, con un intervallo di credibilità compreso tra 1022 e 1062. 

Diagnostica essenziale:

```{r}
# Indicatori numerici chiave: Rhat ~ 1, ESS adeguati
posterior::summarize_draws(
  fit$draws(c("lambda")), "rhat", "ess_bulk", "ess_tail"
)
```


```{r}
# Traceplot di controllo su OR
bayesplot::mcmc_trace(fit$draws("lambda")) +
  ggtitle("Traceplot di lambda")
```


### Derivazione analitica (Gamma–Poisson)

Con prior $\lambda \sim \text{Gamma}(\alpha,\beta)$ e dati $y_1,\dots,y_n$ i.i.d. Poisson($\lambda$), il posteriore è:

$$
\lambda \mid \mathbf{y} \;\sim\; \text{Gamma}\!\left(\alpha + \sum_{t=1}^n y_t,\;\; \beta + n\right).
$$

Quindi:

* *media posteriore* $\mathbb{E}[\lambda\mid y] = \dfrac{\alpha + \sum y_t}{\beta + n}$;
* *ICr 95%* con i quantili Gamma al 2.5% e 97.5%.


```{r}
# Dati e prior come nella sezione Stan
data_vec <- year_counts$events
n        <- length(data_vec)
sum_y    <- sum(data_vec)

mu    <- 600
sigma <- 200
alpha_prior <- (mu / sigma)^2
beta_prior  <- mu / sigma^2

# Posterior coniugato
alpha_post <- alpha_prior + sum_y
beta_post  <- beta_prior  + n

post_mean <- alpha_post / beta_post
ci95      <- qgamma(c(0.025, 0.975), shape = alpha_post, rate = beta_post)

cat("Posterior mean λ:", round(post_mean, 2), "\n")
cat("95% CrI: [", round(ci95[1], 2), ", ", round(ci95[2], 2), "]\n")
```

La derivazione *analitica* e i risultati *MCMC* coincidono (entro l’errore Monte Carlo).














## Riflessioni conclusive

In questo capitolo abbiamo fatto un passo importante: abbiamo visto come tradurre un modello probabilistico relativamente semplice in Stan, come eseguire il campionamento MCMC, e come confrontare i risultati con la soluzione analitica. Questo esempio ci ha permesso di verificare che Stan funziona correttamente, perché in questo caso conoscevamo già la distribuzione a posteriori esatta.

L’aspetto davvero interessante, però, è che la stessa procedura può essere usata anche quando la soluzione analitica non esiste. Nei capitoli successivi incontreremo modelli più complessi, in cui la coniugatezza non ci aiuta più e non abbiamo formule chiuse per la distribuzione a posteriori. In quei casi, il campionamento MCMC sarà lo strumento indispensabile per fare inferenza bayesiana.


## Informazioni sull’ambiente di sviluppo {.unnumbered .unlisted}

```{r}
sessionInfo()
```


## Bibliografia {.unnumbered .unlisted}

